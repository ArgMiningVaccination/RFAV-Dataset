{"title": "PDF", "author": "PDF", "url": "www.gob.mx/cms/uploads/attachment/file/846953/gaceta48_final_completa__3_.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "Contenido Editorial Bio\u00e9tica e inteligencia artificial A fondo Inteligencia artificial, \u00bfun sustituto del amor? Miguel \u00c1ngel Torres Quiroga Visi\u00f3n general de la inteligencia artificial en medicina Jos\u00e9 Luis Garc\u00eda Vigil Humanos y m\u00e1quinas inteligentes: la respon- sabilidad en el uso de la inteligencia artificial en la atenci\u00f3n m\u00e9dica Elisa C. Calleja Sordo Reconocimiento facial: una herramienta de alto riesgo Juan Esp\u00edndola Mata Implicaciones \u00e9ticas de la implementaci\u00f3n de la inteligencia artificial en la pr\u00e1ctica m\u00e9dica Luis Mu\u00f1oz Fern\u00e1ndez Implicaciones bio\u00e9ticas en la IA Luis \u00c1ngel Lara Pereda Integridad acad\u00e9mica y recuersos digitales: acotaciones para una reflexi\u00f3n de vista a los recursos derivados de la inteligencia artificial Geovany Meza Chavero Escenario nacional Desaf\u00edos para la regulaci\u00f3n en torno al desarrollo y aplicaci\u00f3n de la IA Garbi\u00f1e Saruwatari Zavala Escenario internacional Los desaf\u00edos \u00e9ticos y cient\u00edficos de ChatGPT en salud: utopismo, tecnofobia y pragmatismo Luis Garc\u00eda Vali\u00f1a e Ignacio Mastroleo Tareas y perspectivas institucionales Resultados de las encuestas sobre la percepci\u00f3n de sesiones conjuntas entre el CEI, CI, CB o CICUAL aplicadas a los Comit\u00e9s de \u00c9tica en Investigaci\u00f3n y a las Comisiones Estatales de Bio\u00e9tica Areli Cer\u00f3n S\u00e1nchez, Gabriela Pineda Hern\u00e1ndez, Karla Alejandra Tovar L\u00f3pez, Karla Gabriela S\u00e1nchez Villanueva y Flor de Mar\u00eda Cruz Estrada Encuentro bio\u00e9tico Inteligencia Artificial y \u00e9tica. Conversaci\u00f3n con Gabriela Ramos, Subdirectora General de Ciencias Sociales y Humanas de la UNESCO Cultura y bio\u00e9tica Sugerencias en medios digitales de la CONBIO\u00c9TICA Ariana Leticia Land\u00edn L\u00f3pez Rinc\u00f3n bibliogr\u00e1fico Sugerencias editoriales de la CONBIO\u00c9TICA Karla Nallely Rosas Chelius2 3 8 14 19 24 30 35 39 45 50 57 62 65A\u00f1o XII N\u00famero 48 Abril-junio 2023 Publicaci\u00f3n digital Secretar\u00eda de Salud Secretario de Salud Jorge Alcocer Varela Comisi\u00f3n Nacional de Bio\u00e9tica Comisionado Nacional y Editor en Jefe Patricio Javier Santill\u00e1n Doherty Consejeros Jorge Alberto \u00c1lvarez D\u00edaz Juan Antonio Cruz Parcero Patricia Grether Gonz\u00e1lez Luis Mu\u00f1oz Fern\u00e1ndez Virginia Pascual Ramos Raffaela Schiavon Ermani Editor ejecutivo de este n\u00famero Ra\u00fal Jim\u00e9nez Pi\u00f1a Coeditora ejecutiva de este n\u00famero Anay\u00e1ntzin Paulina Heredia Ant\u00fanez Comit\u00e9 Editorial Areli Cer\u00f3n S\u00e1nchez Gabriela Pineda Hern\u00e1ndez Ra\u00fal Jim\u00e9nez Pi\u00f1a Ed\u00e9n Gonz\u00e1lez Rold\u00e1n Revisi\u00f3n e Integraci\u00f3n de contenidos Alma Macedo de la Concha Dise\u00f1o Gr\u00e1fico Mario Patricio Silva Sch\u00fctte Producci\u00f3n Digital Comisi\u00f3n Nacional de Bio\u00e9tica Centro del Conocimiento Bio\u00e9tico Fotograf\u00eda de portada: www.freepik.com Gaceta CONBIO\u00c9TICA, A\u00f1o XII, N\u00famero 48 (abril- junio 2023), es una publicaci\u00f3n trimestral, edita- da por la Secretar\u00eda de Salud /Comisi\u00f3n Na- cional de Bio\u00e9tica, ubicada en Arenal No. 134 esq. Xochimaltzin, Col. Arenal Tepepan, C.P. 14610, Tlalpan, Ciudad de M\u00e9xico Tel. 5487 2760 Editor responsable: Patricio Javier Santill\u00e1n Doherty. Reserva de derechos al uso exclusivo No. 04-2023- 052213303600-203. Las opiniones expresadas por los autores no necesariamente reflejan la postura de la Comisi\u00f3n Nacional de Bio\u00e9tica. Queda estric - tamente prohibida la reproducci\u00f3n total o parcial de los contenidos e im\u00e1genes de la publicaci\u00f3n, sin previa autorizaci\u00f3n de la Comisi\u00f3n Nacional de Bio\u00e9tica.Gaceta2 Editorial La inteligencia artificial (IA) ha sido descrita como la \"cuarta revoluci\u00f3n industrial\" y ha ido desarroll\u00e1ndose vertiginosamente en m\u00faltiples esferas de las actividades huma- nas: la industria, la ciencia, la tecnolog\u00eda, la salud y la educaci\u00f3n, por mencionar algunas. Tecnolog\u00edas como el aprendizaje autom\u00e1ti- co y el procesamiento del lenguaje natural son parte del panorama y aplicaci\u00f3n de la IA, evolucionando a lo largo de su propio ca- mino y, cuando se aplican en combinaci\u00f3n con el an\u00e1lisis de datos y la automatizaci\u00f3n, pueden ayudar a lograr objetivos en los di- ferentes \u00e1mbitos en que se utilizan, creando un cambio de paradigma en nuestros estilos de vida. Por otro lado, la IA ha tenido implicaciones en el cuidado de la salud, en las esferas indi- vidual y colectiva, toda vez que el horizonte de posibilidades que brindan estas tecnolo - g\u00edas aumenta constantemente. Actualmen- te, las funciones m\u00e1s comunes de la IA en entornos m\u00e9dicos, son el apoyo a las decisio - nes cl\u00ednicas y el an\u00e1lisis de im\u00e1genes orien- tadas a mejores diagn\u00f3sticos. En este senti- do, las herramientas que existen auxilian a los m\u00e9dicos en la toma de decisiones sobre tratamientos, f\u00e1rmacos, an\u00e1lisis de datos y otros requerimientos de los pacientes, brin- dando un acceso r\u00e1pido a la informaci\u00f3n. En el mismo orden de ideas, la IA se utiliza para analizar tomograf\u00edas computarizadas, rayos X, resonancias magn\u00e9ticas y otras im\u00e1genes, en busca de hallazgos que podr\u00edan pasarse por alto, es as\u00ed que la IA se convierte r\u00e1pida- mente en parte integral de la atenci\u00f3n m\u00e9 - dica moderna. Esta edici\u00f3n n\u00famero 48 de la Gaceta CON- BIO\u00c9TICA, que versa sobre el tema \"Inteli- gencia artificial y bio\u00e9tica\", parte de la consi- deraci\u00f3n de las implicaciones bio\u00e9ticas que derivan del apresurado desarrollo tecnol\u00f3gi- co, las preocupaciones acerca de sus aplica- ciones y los posibles sesgos sobre la protec - ci\u00f3n de datos personales y la regulaci\u00f3n de dichas tecnolog\u00edas, entre otros aspectos. En virtud de lo anterior, es importante recor - dar lo propuesto por el fil\u00f3sofo alem\u00e1n Hans Jonas acerca del compromiso \u00e9tico que pide prudencia y equilibrio, preservando el inte - r\u00e9s de la existencia de la humanidad y to - mando conciencia de todos los eventuales da\u00f1os causados por nuestras acciones. En espera de que el contenido de esta pu- blicaci\u00f3n sea de su inter\u00e9s y estimule el in- tercambio de reflexiones sobre las prome - sas que ofrece la IA, sus posibles riesgos, as\u00ed como los l\u00edmites \u00e9ticos, sociales y legales que implica su aplicaci\u00f3n, particularmente en actividades que tienen un impacto direc - to en nuestra vida cotidiana, lo invitamos a continuar con su lectura.Gaceta3 a fondo En este ensayo de divulgaci\u00f3n, planteo la co - nexi\u00f3n entre la Inteligencia Artificial (IA) y el amor como experiencia social significativa, desde las amistades y relaciones sexo-afecti- vas que la IA est\u00e1 modificando y modificar\u00e1 a\u00fan m\u00e1s, hasta llegar al transhumanismo. El cine imagina visiones est\u00e9ticas sobre di- lemas \u00e9ticos de nuestro tiempo, y retoma conflictos sociales que transforma en textos audiovisuales complejos, narrativas sobre el amor, la amistad, el erotismo, la intimidad, la ruptura. Un probable objetivo es comu- nicar con audiencias actuales y futuras las inquietudes emocionales, malestares y ex - periencias de much\u00edsimas personas en una \u00e9poca determinada. Her (Spike Jonze, 2013), I.A. Inteligencia artificial (Spielberg, 2001) y un episodio de la serie brit\u00e1nica Black mirror titulado San Jun\u00edpero (Owen Harris, 2016) son obras sobresalientes que analizan cues- tiones de la identidad y naturaleza humana en relaci\u00f3n a las tecnolog\u00edas con IA. \u00bfQu\u00e9 respeto nos merece una IA con la que po - dr\u00edamos mantener una relaci\u00f3n \u00edntima como con cualquier otra persona? \u00bfEs positiva o negativa la incorporaci\u00f3n de dispositivos de IA para enriquecer experiencias afectivas, o suplirlas cuando desaparecen o no existen? \u00bfUna experiencia mental sobre el amor y otros sentimientos profundos producida ar - tificialmente por dispositivos tecnol\u00f3gicos de realidad virtual es tan real como una re - laci\u00f3n mantenida con otra persona? Escapa de mi objetivo dar una respuesta justificada a esas preguntas. Mi prop\u00f3sito es suscitar el inter\u00e9s en la audiencia sobre las posibilida- des de algunos dispositivos de IA que procu- ran estimular nuestras emociones amorosas, especialmente cuando se suscitan proble - m\u00e1ticas dolorosas, como p\u00e9rdidas, duelos, soledad, decepci\u00f3n amorosa, etc\u00e9tera. Proferir emociones profundas, emp\u00e1ticas, y positivas hacia otras personas y animales no humanos es una evidencia de vida inte - ligente, de compleja actividad e interacci\u00f3n mente-cerebro. Seres humanos, y algunos animales como antropoides, cet\u00e1ceos y ele - fantes, demuestran que el amor y los afec - tos mantienen una gran relaci\u00f3n con la in-teligencia y la soluci\u00f3n de problemas. No obstante, \u00bfes congruente incluir robots y sistemas operativos como agentes suficien- temente inteligentes para amar? El cine ha dedicado gran inter\u00e9s por los t\u00f3picos relacio - nados con las formas de vida artificial, desde su nacimiento: Viaje a la luna de Georges M\u00e9li\u00e8s (1902); Fausto (1924), de Murnau; El golem (1920), de Wagener y Boese; El doctor Frankenstein (1931) y La novia de Frankens- tein (1935) de James Whale. Crear vida; Ven- cer la muerte; alcanzar capacidades sobre - humanas; y alterar el poder de la suerte y los accidentes en la felicidad humana, han sido los cometidos m\u00e1s codiciados de cient\u00edficos y tecn\u00f3logos identificados con movimientos trans y posthumanos. En Blade runner (Ri- dley Scott, 1982) se expone la transici\u00f3n de la tecnolog\u00eda como transformaci\u00f3n y progreso de la vida cotidiana, a la transformaci\u00f3n radi- cal de nuestra naturaleza de especie; la vieja naturaleza se reemplaza por otra que quiere alejarse de cualquier funcionamiento defec - tuoso, de enfermedades y padecimientos que ocasionan sufrimientos. Parad\u00f3jicamente, la nueva naturaleza hu- mana organiza una reformulaci\u00f3n de las viejas clases sociales, con caracter\u00edsticas in- deseables, dist\u00f3picas, o malvadas, que la ha- cen a\u00fan m\u00e1s perversa que las antiguas que parec\u00edan involuntarias. Las pel\u00edculas Inteligencia artificial, Her y el episodio de Black Mirror San Jun\u00edpero ejem- plifican estupendamente el rompimiento con la realidad amorosa entendida exclu- sivamente entre humanos. En la cinta de Spielberg, una humanidad ag\u00f3nica sobre - vive en un planeta vencido por el calenta- miento global que ha convertido a Nueva York en una ciudad perdida, que a la vez funciona para un peque\u00f1o ni\u00f1o robot meca llamado David, como su destino final. David fue dise\u00f1ado por un cient\u00edfico que perdi\u00f3 a su \u00fanico hijo; ahora, el \u00fanico prop\u00f3sito del peque\u00f1o robot es amar sin l\u00edmites a quien Inteligencia artificial, \u00bfun sustituto del amor? Miguel \u00c1ngel Torres Quiroga* *Doctor en Filosof\u00eda, Universidad Aut\u00f3noma de Madrid; Investigador posdoctoral, Universidad Aut\u00f3noma Me - tropolitana, Unidad Iztapalapa. Autor del libros y art\u00edculos. Gaceta4 lo programe para recibir ese afecto. Nada puede revertir el programa una vez iniciado. David no es un ser vivo: no crece, no se repro - duce (siempre ser\u00e1 un robot-ni\u00f1o) y nunca morir\u00e1, pero demuestra la intensidad con la que los seres vivos m\u00e1s complejos se aferran a un cierto tipo de v\u00ednculo significativo mo - ralmente hablando, en el que no basta con cumplir una funci\u00f3n b\u00e1sica de superviven- cia. David s\u00f3lo anhela el amor de \"su madre\" M\u00f3nica, la mujer que lo program\u00f3, y que en- cuentra en \u00e9l un insuficiente placebo por el sufrimiento de perder a su hijo, congelado en un laboratorio de criogenia. Cuando \u00e9ste despierta, entendemos que el amor de David no es humano: no es capaz de infringir da\u00f1o voluntariamente a todo aqu\u00e9l que amenace la unidad con su madre, aunque las actitu- des del hermano resucitado son demasiado humanas, lo cual incluye cierto placer por destruir. Tras varios eventos desafortunados, David es abandonado por la \u00fanica persona que le da sentido a su consciencia de vida. Su odisea reconecta con muchas traves\u00edas cl\u00e1sicas: debe alcanzar la arcadia donde vive quien promete la felicidad eterna, el hada azul que convirti\u00f3 a Pinocho en un ni\u00f1o de verdad, y que har\u00e1 lo propio con \u00e9l. En un futuro m\u00e1s pr\u00f3ximo, el film de Jon- ze comienza con un plano ya conocido en El apartamento (Wilder, 1960) y previamen- te en Y el mundo sigue (Vidor, 1928), con la enajenaci\u00f3n y la soledad de la vida urbana. Es una empresa que escribe cartas de amor a quienes lo solicitan, y Theodor es uno de sus empleados m\u00e1s especiales por su vena po\u00e9tica. En la realidad, vive deprimido por su separaci\u00f3n con la mujer que pens\u00f3 lo co - noc\u00eda mejor que nadie. Un d\u00eda, un sistema operativo avanzado con \"entidad femenina\" llamado Samantha es capaz de introducirle en una espiral emocional que le devuelve el sentido de la vida. Aunque Samantha no po - sea cuerpo, pasado, familia, ni contacto ma- terial y efectivo con la vida real, sus palabras e intervenciones conmueven profundamen- te Theodor: sonrisas, orgasmos, alegr\u00eda, pla- cer, satisfacci\u00f3n personal, j\u00fabilo. Como nada dura para siempre (desconocemos cu\u00e1nto puedan durar las inteligencias artificiales), Theodor cae en cuenta que su relaci\u00f3n con Samantha no es un milagro, sino un com- portamiento para el cual el sistema operati- vo fue dise\u00f1ado y que comparte con much\u00ed- simas personas aparte de \u00e9l. La nueva vida de Theodor se desploma. Finalmente, en una nost\u00e1lgica discoteca lla- mada San Jun\u00edpero, Kelly y Yorkie son dos j\u00f3 - venes lesbianas que coinciden en un lejano 1987 varios fines de semana. Ambas se ena- moran, hacen el amor, tienen ri\u00f1as y se con- fiesan la una a la otra sus sentimientos muy pronto. Lamentablemente, un accidente trunca la vida de Yorkie, dej\u00e1ndola en estado vegetativo antes de concretar algo con Kelly, en parte por culpa de prejuicios sociales fa- miliares. Sin embargo, algo extra\u00f1o sucede con el tiempo de estos encuentros: lo que hemos visto no son hechos sucedidos lineal- mente, sino la elaboraci\u00f3n mental de Yorkie de su \u00faltimo d\u00eda de vida antes de sufrir el te - rrible accidente. Ahora, Yorkie es soportada por vida artificial, sin esperanza de recupera- ci\u00f3n, convertida en una mujer mayor que es- pera la muerte. Gracias a unos dispositivos, habita mentalmente un mundo en el que los moribundos y los viejos rememoran, en- carnando cuerpos j\u00f3venes, sus mejores mo - mentos. En el hospital, Yorkie es visitada por Kelly muchos a\u00f1os despu\u00e9s, a quien le pro - duce una sensaci\u00f3n de repulsi\u00f3n y tristeza la tragedia de su antigua amante. Un d\u00eda, el personal m\u00e9dico aconseja un experimento: que el dispositivo de IA les sea reconectado a las dos, recreando en la vida mental de am- bas un posible reencuentro. Para Kelly supo - ne una renuncia, pues s\u00ed ha podido hacer una vida heterosexual, aunque no deseada en el fondo, pero mucho m\u00e1s compensado - ra que la de la pobre Yorkie. La IA cobra formas innumerables, realizando tareas tambi\u00e9n dif\u00edciles de limitar, pero, \u00bfnos ofrecer\u00eda amor? \u00bfes capaz de devolvernos aquello que la vida nos arrebat\u00f3? \u00bfcura aca- so la infelicidad y la tragedia o s\u00f3lo las disfra- za? Supongamos que una respuesta de todo lo anterior es permanecer abiertos a la po -Gaceta5 a fondo sibilidad de esta nueva ruta en la evoluci\u00f3n social, en la transformaci\u00f3n afectiva de la naturaleza humana. Invariablemente se am- pliar\u00e1 muchos umbrales sobre los sujetos de afecto, m\u00e1s all\u00e1 de animales y plantas. Que lo importante no es relacionarnos exclusi- vamente entre humanos mortales, y que es muy relevante lo que podemos descubrir sobre la complejidad de los afectos, de las emociones m\u00e1s significativas, que forzosa- mente son relacionales, en la recreaci\u00f3n de consciencias con inteligencia suficiente para mantener un relato de su vida, una misi\u00f3n que cumplir, una compa\u00f1\u00eda que ofrecernos, un futuro que modificar favorablemente. Las pel\u00edculas citadas ofrecen una excelente demostraci\u00f3n de un porvenir tecnol\u00f3gico aparentemente id\u00edlico. Como contraparte, presentan posibles argumentos en contra del avance ilimitado en el dise\u00f1o de una IA que haga realidad el amor. El primer argu- mento, que una IA que provea amor incon- dicional con todos los matices existentes es incompatible con la libre voluntad, que per - mita establecer los alcances y los l\u00edmites de la relaci\u00f3n amorosa. El amor es muy signifi- cativo justamente en buena medida porque, alg\u00fan d\u00eda, se extinguir\u00e1 o se transformar\u00e1 en un sentimiento distinto. El amor es perece - dero como la vida misma, y por eso su pre - sencia enriquece e ilumina un camino que, invariablemente, finaliza con la muerte. Una IA como el peque\u00f1o David parece contrade - cir lo anterior. El segundo argumento, dado que la IA carece de vida, tampoco puede su- perar el relato de los alcances de invenci\u00f3n humana, que busca satisfacer prop\u00f3sitos es- pec\u00edficos. Contrariamente, las vidas huma- nas poseen innumerables prop\u00f3sitos, tantos como las circunstancias hagan posibles. Vi- vimos varias vidas desde que nacemos has- ta que morimos, y los fines de la vida son m\u00faltiples, pero, \u00bfpodr\u00eda la IA reproducir algo similar? Y el tercer argumento, que los hu- manos encontraremos serias dificultades para amar una IA sin sufrir alteraciones se - veras en nuestras capacidades emocionales. Parece improbable que haya compatibilidad entre un amor humano (imperfecto, fr\u00e1-gil, ego\u00edsta en cierta medida) con un amor absoluto e incondicional con paciencia in- finita que solamente vive para recibir amor del objeto indicado (otra vez, el caso de In- teligencia artificial). Ser\u00eda inconcebible para muchas personas amar un sistema opera- tivo con IA que desaf\u00eda los l\u00edmites humanos del espacio y el tiempo, que se expresa en con diferentes consciencias y en m\u00faltiples dimensiones que la consciencia humana no es capaz de entender (como sucede en Her). Por \u00faltimo, encontraremos sumamente dif\u00ed- cil experimentar un amor sin cuerpo, sin las caracter\u00edsticas materiales de los seres vivos: nacen, crecen, duermen, comen, se sexuali- zan, se reproducen, envejecen, y finalmente mueren. A pesar de las advertencias, las pel\u00edculas tambi\u00e9n revelan cuestiones sugerentes so - bre nuestra evoluci\u00f3n socio-afectiva, social y relacional. Frecuentemente, el cine presenta el lado dist\u00f3pico, inhumano y violento de la alteraci\u00f3n de la naturaleza humana por par - te de la tecnolog\u00eda. El mensaje es que est\u00e1 mal que la tecnolog\u00eda desplace las relacio - nes \"verdaderas\" y libres entre personas con agencia y autonom\u00eda. De suceder esto, se perder\u00eda la capacidad de reconocer y sobre - llevar el sufrimiento; aceptar la finitud de la vida; contemplar la fuerza de las relaciones amorosas. Pero tambi\u00e9n debemos recordar otro aspecto, y es el de la pol\u00edtica que diri- ge las tecnolog\u00edas, particularmente la IA. Es problem\u00e1tico que \u00e9stas provengan de una \u00e9lite opresora, tir\u00e1nica, con aspiraciones to - talitarias e inhumanas, que desea moldear la naturaleza seg\u00fan sus intereses ideol\u00f3gicos, econ\u00f3micos y supremacistas. El d\u00eda en que la IA pueda ayudarnos a superar momentos dif\u00edciles y hasta tr\u00e1gicos puede estar muy cerca. El cine, con todo y su observaci\u00f3n dist\u00f3pica, tambi\u00e9n introduce que estos cambios son inevitables, en bue - na medida, porque la evoluci\u00f3n humana no es s\u00f3lo biol\u00f3gica, sino que est\u00e1 \u00edntimamen- te relacionada con los valores y los c\u00f3digos \u00e9ticos empleados hacia las formas de vida no humanas y, ahora, hacia otras formas de Gaceta6 consciencia. En este sentido, el cine invita a observar que la IA posee sus contextos socio - pol\u00edticos, los cuales influyen poderosamente en sus funciones y objetivos sociales. As\u00ed, se pueden plantear miradas m\u00e1s ben\u00e9volas so - bre el papel de la IA en aquellas cuestiones sumamente relevantes de la complicada vida afectiva contempor\u00e1nea. Recordando Blade Runner, los replicantes poseen memoria, consciencia, emociones; son reservorios de la memoria humana que los propios humanos no son suficientemente capaces de recabar y preservar, y por eso mis- mo constituyen un peligro para ciertas \u00e9lites. Los androides quieren o quisieron pertenecer a una sociedad que los rechaza y promueve su destrucci\u00f3n. De este modo, una funci\u00f3n de la IA consiste tambi\u00e9n en conducir las emocio - nes, como el amor, en contextos m\u00e1s exten- sos, deriv\u00e1ndose as\u00ed una suerte de b\u00fasqueda de justicia. En Inteligencia artificial, Spielberg revive las persecuciones y atrocidades per - petradas en su pel\u00edcula sobre el holocausto 'La lista de Schindler', cuando los mecas son sistem\u00e1ticamente destruidos en nombre de una defensa de la naturaleza humana en una fiesta llamada 'de la carne', motivada por un discurso sobre la pureza y la identidad que se compagina con la identidad de movimientos sociales reaccionarios. Cientos de mecas des- truidos son depositados por enormes gr\u00faas en bosques abandonados, como en su tiem- po los nazis enterraron los cad\u00e1veres de miles de jud\u00edos en terrenos bald\u00edos o en bosques. David no solamente es un peque\u00f1o robot \u00fanico en su g\u00e9nero -a pesar de haber sido construido en serie para ofrecer alivio a mu- chas personas devastadas por la p\u00e9rdida y la soledad. Tambi\u00e9n es un reservorio de memo - ria de las cosas grandiosas, buenas, grises y malvadas de la humanidad, testigo ocular de sus legados y miserias. En Her encontramos otra aproximaci\u00f3n al colapso civilizatorio en el que la IA parece ofrecer una luz ante la inconexi\u00f3n social y el embotamiento emocional, como epidemias normalizadas. Samantha conoce a profundi- dad a Theodor, y sabe del inc\u00f3modo mal de su tiempo. \u00c9l padece la soledad urbana de las sociedades capitalistas avanzadas, don- de incluso las cartas de amor m\u00e1s \u00edntimas, po\u00e9ticas y singulares son una mercanc\u00eda, y no una obra personal. No queda tiempo que perder para peque\u00f1eces en un entorno tan dirigido a la producci\u00f3n. Se vive en una sofisticada trampa que dificulta el desper - tar social sobre la miseria compartida y la incapacidad de reconectar con la carencia como constituci\u00f3n de nuestra naturaleza, de origen y nacimiento. Samantha descu- bre que el amor de Theodor no lo liberar\u00e1 de la alienaci\u00f3n y el eterno sufrimiento, y opta por salir de su vida como \u00faltimo sacrificio amoroso. As\u00ed, abandona a su amante en el naufragio del desamor, pero esta vez no se encuentra completamente solo: otra amiga que trabaja en la compa\u00f1\u00eda pasa por una situaci\u00f3n similar, sin duda por una relaci\u00f3n con otro sistema operativo que, como Sa- mantha, tuvo que marcharse antes de pro - vocar problemas m\u00e1s grandes. Convivir con diferentes mecanismos de IA no tendr\u00eda por qu\u00e9 significar solamente distop\u00eda y apocalipsis, o un gobierno de robots y m\u00e1- quinas vengativas. La imaginaci\u00f3n debe ser - virnos para cimentar el camino que nos falta recorrer como especie, y aqu\u00ed la IA puede ser \"Proferir emociones profundas, emp\u00e1ticas, y positivas hacia otras personas y animales no humanos es una evidencia de vida inteligente, de compleja actividad e interacci\u00f3n mente-cerebro\".Gaceta7 a fondo un aliado m\u00e1s que un enemigo. Las pel\u00edculas rese\u00f1adas ofrecen un horizonte imaginativo que fomenta la humanidad y el rescate de las relaciones m\u00e1s importantes. Igualmente, cabe admitir que muchos males atribuidos a la convivencia con m\u00e1quinas son, realmen- te, demasiado humanos, y promovidos por humanos tambi\u00e9n. Los duelos nos arrebatan la respiraci\u00f3n sin matarnos; probablemente, las nuevas inteligencias, m\u00e1quinas, robots y dem\u00e1s, pueden acompa\u00f1arnos en el tr\u00e1nsi- to de este valle de l\u00e1grimas. David espera 2000 a\u00f1os bajo las ruinas de la vieja Nueva York hasta que el hada azul cum- ple su deseo de ser un ni\u00f1o real. Entonces, una inteligencia extraterrestre lo encuen- tra, convirti\u00e9ndose as\u00ed en el \u00fanico testigo de la desaparecida civilizaci\u00f3n humana y de sus aportaciones, logros y contradicciones. Como en Blade Runner, memorias extraor - dinarias sobre eventos irrepetibles se han perdido inevitablemente, como l\u00e1grimas en la lluvia, cuando los androides/replicantes desaparecieron tras la extinci\u00f3n humana. Pero en David se conserva a uno que so - brevivi\u00f3 varios holocaustos y cat\u00e1strofes. En otro escenario, Theodor se reencuentra con el desconsuelo y la tristeza de las que quiso huir ahora con la despedida de Samantha. Finalmente, encontramos por lo menos un desenlace feliz en San Jun\u00edpero, aunque sea fabricado artificialmente. Yorkie y Kelly pue - den concretar su amor a pesar de los obs- t\u00e1culos en un universo inexistente fuera de las recreaciones mentales complejas pro -ducidas por lo dispositivos conectados a sus cerebros. Gracias a ella, llegan a amarse fue - ra del bucle del tiempo en el que el mismo d\u00eda de 1987 se repet\u00eda una y otra vez: la IA al- canza una complejidad tal que resucita a los muertos, les regala vidas dignas de vivirse, y que las dos perciben como si fueran reales. Es una versi\u00f3n amable y reconfortante de la s\u00f3rdida t\u00e9cnica empleada en Soylent green (conocida en M\u00e9xico como \"Cuando el des- tino nos alcance\") para ejecutar a los viejos y enfermos, para despu\u00e9s convertirlos en el alimento de una humanidad moral y eco - l\u00f3gicamente devastada. Claro, no sin antes regalarles un \u00faltimo viaje sensorial por un hermoso mundo virtual inexistente. Visto lo anterior, las lecciones por descubrir sobre la IA y el amor son m\u00faltiples: \u00bfes me - jor vivir en la miseria social antes que recurrir a las tecnolog\u00edas que impulsen la conexi\u00f3n emocional con las necesidades afectivas? \u00bfDeber\u00edan despreciarse o minusvalorarse las relaciones con dispositivos de IA cuando las relaciones con personas atraviesan momen- tos complicados? Y, si la respuesta es afirma- tiva, \u00bfpor qu\u00e9? \u00bfAcaso la sexualidad puede ser igualmente significativa cuando un hu- mano la practica con dispositivos de IA por motivos diversos (discapacidades, dificulta- des personales serias, encarcelamiento o pri- vaci\u00f3n de libertades)? \u00bfPueden la IA y otros robots convertirse en embajadores de las civilizaciones humanas y heredar las memo - rias de nuestra cultura, o quiz\u00e1s incluso con- formar una cultura con identidad propia? -Harris, Owen (2016). Black Mirror: San Junipero. Netflix-House of Tomorrow. -Jonze, Spike (2013). Her. Annapurna Pictures, Stage 6 films. -M\u00e9lies, Georges (1902). Le Voyage dans la Lune. Star-film. -Murnau, F.W. (1926). Fausto. UFA. -Scott, Ridley (1982). Blade runner. Warner Bros. -Spielberg, Steven (1993). Schindler's list. Universal Pictures. -Spielberg, Steven (2001). A.I. Artificial Intelligence. Dreamworks SKG, Warner Bros. -Vidor, King (1928). The Crowd. MGM. -Wagener, Paul y Boese, Carl (1920). Der golem. PAGU. -Whale, James (1931). Doctor Frankenstein. Universal Pictures. -Whale, James (1935). Bride of Frankenstein. Universal Pictures. -Wilder, Billy (1960). The apartment. United Artists.Obras consultadasGaceta8 Visi\u00f3n general de la inteligencia artificial en medicina Jos\u00e9 Luis Garc\u00eda Vigil* Introducci\u00f3n A\u00fan existe controversia en la definici\u00f3n m\u00e1s adecuada de inteligencia, con mayor raz\u00f3n esta controversia se generaliza cuando se trata de aplicar al campo de los sistemas de informaci\u00f3n o a la inform\u00e1tica computa- cional. En el humano se acepta que la inte - ligencia es aquella cualidad que permite a nuestros cong\u00e9neres entender el mundo en que vivimos y aprender a relacionarnos con nuestros semejantes; todo ello en af\u00e1n de te - ner una vida plena y consciente llena de sa- tisfactores tanto f\u00edsicos como emocionales. La inteligencia general del humano (IH), es en realidad una cualidad emergente y sin- gular formada por un conjunto armonioso interrelacionado de cualidades espec\u00edficas o competencias particulares que se diferen- cian fenomenol\u00f3gicamente por ser cons- cientes y enfocadas a objetivos sensibles, emocionalmente importantes y que al cono - cerlos y conceptualizarlos como problemas, se pueden resolver para llegar a un estado de homeostasis compatible con la supervi- vencia de la especie, calidad de vida y satis- facci\u00f3n del resultado que lleva a la sensaci\u00f3n de logro f\u00edsico, biol\u00f3gico, fisiol\u00f3gico o espiri- tual. Estas competencias o cualidades conscien- tes y singulares se han dado a conocer y di- fundido por el psic\u00f3logo Howard Gardner en su obra \"Estructuras de la mente. Teor\u00eda de las Inteligencias M\u00faltiples\" (1); las que se ex - presan en el contexto de tareas, disciplinas y \u00e1mbitos espec\u00edficos, las que se pueden con- cebir en t\u00e9rminos neurobiol\u00f3gicos, a saber: 1. Inteligencia Ling\u00fc\u00edstica. 2. Inteligencia Musical. 3. Inteligencia L\u00f3gico-matem\u00e1tica. 4. Inteligencia Espacial. 5. Inteligencia Cinest\u00e9sico-corporal. 6. Inteligencias Personales (Conocimiento del YO, intrapersonales, introspecci\u00f3n). 7. Inteligencias Interpersonales (socializa- ci\u00f3n, establecimiento de v\u00ednculos).Sin ser el motivo espec\u00edfico del tema que nos ocupa, s\u00f3lo menci\u00f3n con el prop\u00f3si- to de partir con base en conceptos y ar - gumentos con alg\u00fan grado de evidencia respecto de la inteligencia humana; y esto, con el fin de extrapolarlo a lo que ahora se conoce como Inteligencia Artificial (IA) o inteligencia de las m\u00e1quinas (robots, an- droides, \"bots\"). El t\u00e9rmino inteligencia artificial (IA) se empez\u00f3 al utilizar en la d\u00e9cada de los a\u00f1os 50s del siglo pasado, eran dispositi- vos inicialmente anal\u00f3gicos y despu\u00e9s di- gitales con la elaboraci\u00f3n y aplicaci\u00f3n de programas de tipo determinista; es decir, escritura de instrucciones para realizar al- guna acci\u00f3n (resultado) siempre y cuan- do se cumpliera alguna condici\u00f3n, Pro - gramaci\u00f3n tipo IF, THEN, ELSE: Si se da la situaci\u00f3n de poder avanzar en la instruc - ci\u00f3n, entonces identificar si se cumple la condici\u00f3n deseada para tener el resultado esperado; o en dado caso, detener el pro - ceso. Volver a empezar o reprogramar las instrucciones. (2) Como se puede observar, este tipo de pro - gramaci\u00f3n ten\u00eda muchas limitaciones dada la gran cantidad de variables que se podr\u00edan presentar en escenarios complejos de la vida diaria y, por tanto, las posibilidades son infinitas ante situaciones no previstas. Esta situaci\u00f3n se pudo superar con el desarrollo de c\u00f3digos y algoritmos que, con la instruc - ci\u00f3n inicial y recursividad, el programa por si mismo se reforzaba en algunos c\u00f3digos o desechaba los algoritmos defectuosos a partir de ejemplos tipo y se elaboraban de manera autom\u00e1tica, las correcciones nece - sarias; esto llev\u00f3 a un adelanto m\u00e1s de las m\u00e1quinas de c\u00f3mputo (machine learning). Inteligencia artificial (IA) de aprendizaje profundo. *Especialista en Medicina Interna; Certificado por el CMMI; Maestr\u00eda en Ciencias M\u00e9dicas. Investigaci\u00f3n cl\u00ed- nica y educativa; Educaci\u00f3n a distancia; Profesor, Fac. de Med., UNAM.Gaceta9 a fondo Ahora nos encontramos en la frontera del co - nocimiento, donde sin temor a equivocarnos, el futuro ya nos alcanz\u00f3. Estamos ante una nueva realizad, un gran desarrollo de la IA de aprendizaje profundo, el cual se ha desarro - llado a partir del modelo de las redes neuro - nales, inicialmente en paralelo y despu\u00e9s en segunda y tercera dimensi\u00f3n, que hacen fac - tible se establezcan redes complejas (redes de redes) tal y como si fueran redes de neuronas del sistema nervioso central interrelacionadas con base en sinapsis. Los nuevos programas y c\u00f3digos de IA son ya de tipo convolucional (en capas) y gen\u00e9ticas (generativas). Los dispositivos de IA m\u00e1s evolucionados son los capaces de compilar una gran canti- dad de conceptos, t\u00e9rminos, frases, p\u00e1rrafos completos respecto de una tem\u00e1tica o un campo sem\u00e1ntico y disciplinar espec\u00edfico; expresando sus resultados en textos fluidos, did\u00e1cticos y atractivos, pero carentes de cri- terio y reflexi\u00f3n. No est\u00e1n mediados por sen- timientos ni emociones, solo compilaci\u00f3n exitosa de textos cre\u00edbles, pero susceptibles de tener errores de criterio (porque las m\u00e1- quinas no piensan y reflexionan como los humanos). El ejemplo actual es la tecnolog\u00eda digital llamada ChatGPT. A esta semblanza introductoria, tenemos en primer lugar los conceptos de IH y un s\u00edmil muy alejado de ella que es la IA, pero induda- blemente en las siguientes d\u00e9cadas, tendre - mos con evoluci\u00f3n del Internet 2.0, el Internet de las Cosas (IoT) y robots humanoides con sensores perif\u00e9ricos similares al del humano (video, audio, tacto, cinestesia, olfato y gusto digitales); el escenario casi completo del Ci- berespacio con IA multiconectada a termi- nales inteligentes (computadoras macro tipo servidores, computadores de escritorio, ta- bletas, tel\u00e9fonos celulares) y comunicaci\u00f3n IoT merced a redes de fibra \u00f3ptica con los ro - bots humanoides (androides) en convivencia \u00edntima e inteligente con los humanos. (2) Dentro de todo este escenario presentar\u00e9 una visi\u00f3n general de la IA el ejercicio y de - sarrollo de la Medicina y de sus personajes interactuantes; ll\u00e1mense pacientes, estu- diantes de medicina y m\u00e9dicos en ejercicio profesional en el campo de la salud, desarro - llando particularmente el antecedente de la IA en forma de Sistemas Expertos, despu\u00e9s, la aplicaci\u00f3n de la IA en el proceso salud en- fermedad en sus tres niveles de prevenci\u00f3n (1\u00aa, 2\u00aa y 3\u00aa; con \u00e9nfasis en la Atenci\u00f3n Prima- ria) y con foco en el sujeto objetivo de todos nuestros afanes, el paciente. Por \u00faltimo, unos p\u00e1rrafos relacionados con la \u00e9tica(bio\u00e9tica) que se expresa o est\u00e1 implicada en la inte - racci\u00f3n e integraci\u00f3n de la IH con la IA. Aplicaci\u00f3n actual y a futuro de la IA en Medicina Sistemas Expertos: Cuando los programas de IA estaban sufi- cientemente evolucionados, con Internet, redes locales y de \u00e1rea (LAN, GAN), digitali- zaci\u00f3n de gran cantidad de informaci\u00f3n con programas y bases de datos relacionales, emanadas del proceso salud enfermedad en la Atenci\u00f3n M\u00e9dica, surgen los Sistemas Expertos (SE), El objetivo de los SE es el de apoyar en el trabajo de los m\u00e9dicos de cier - tas especialidades; por ejemplo, sistemas de ayuda para realizar diagn\u00f3sticos tempranos y eficaces, a fin de tomar decisiones en cual- quiera de los niveles de prevenci\u00f3n en el pro - ceso de atenci\u00f3n a la salud. Estos SE fueron utilizados m\u00e1s en las labores de diagn\u00f3stico oportuno y tratamiento m\u00e9dico adecuado cuando en virtud de los signos y s\u00edntomas (s\u00edndromes, enfermedades) de los pacientes, el m\u00e9dico llegaba a un diagn\u00f3stico de alta probabilidad (hip\u00f3tesis diagn\u00f3stica) y a un nivel cr\u00edtico en la toma de decisi\u00f3n terap\u00e9u- tica. (2- 4) Atenci\u00f3n M\u00e9dica: La atenci\u00f3n m\u00e9dica inicia cuando se con- frontan y ponen en contacto los persona- jes importantes e interactuantes del acto m\u00e9dico: Pacientes, m\u00e9dicos y estudiantes de medicina; tal como sucede en los mo - delos de comunicaci\u00f3n humana (entrevista m\u00e9dica, relaci\u00f3n m\u00e9dico-paciente, historia cl\u00ednica) donde existe di\u00e1logo bidireccional Gaceta10 (juego de roles entre preceptor y emisor de informaci\u00f3n), comprensi\u00f3n, interpretaci\u00f3n, aceptaci\u00f3n vs negaci\u00f3n para finalmente, tras negociaci\u00f3n a ganar-ganar; se llega al establecimiento de compromisos respecto del tema en salud de que se trate, en for - ma de la toma de varias decisiones como la necesidad de solicitar estudios cl\u00ednicos de laboratorio y gabinete, a fin de establecer con alto grado de probabilidad la hip\u00f3tesis diagn\u00f3stica con la cual llegar al nivel cr\u00edtico en la toma de decisiones, tanto diagn\u00f3sticas como terap\u00e9uticas con medidas farmacol\u00f3 - gicas (medicamentos) y no farmacol\u00f3gico (estilos de vida, control de peso, vida laboral, calidad de vida, actividad f\u00edsica, recreaci\u00f3n, descanso, nutrici\u00f3n). En todo el proceso del acto m\u00e9dico se ge - nera informaci\u00f3n y gran cantidad de datos. Mucha informaci\u00f3n fluye verbalmente en la relaci\u00f3n m\u00e9dico-paciente, otra se recaba al realizar el examen m\u00e9dico seg\u00fan el arte de la cl\u00ednica y de acuerdo con la proped\u00e9utica, nosolog\u00eda y anatom\u00eda topogr\u00e1fica. Otro tipo de informaci\u00f3n y datos se obtienen cuando se miden las constantes vitales (peso, talla, presi\u00f3n arterial, temperatura) y los resulta- dos de ex\u00e1menes de laboratorio (ex\u00e1me - nes de sangre b\u00e1sicos y especiales, orina, heces, otros l\u00edquidos corporales normales o anormales, histopatolog\u00eda de biopsias) y gabinete (imagenolog\u00eda simple y especial (radiograf\u00edas, tomograf\u00edas computarizadas, resonancias magn\u00e9ticas, ultrasonidos), elec - trocardiograma en reposo o de esfuerzo, electroencefalograma, etc\u00e9tera. La informaci\u00f3n y datos as\u00ed obtenidos son susceptibles de expresarse en lenguaje ana- l\u00f3gico y digital y visualizarse para su an\u00e1lisis e integraci\u00f3n por el personal del equipo de salud, en especial el m\u00e9dico experto tratan- te de un paciente en particular. La expresi\u00f3n gr\u00e1fica y digitalizada en la actualidad se ge - nera en gran parte de manera automatizada (equipo analizador automatizado con c\u00f3 - digos y algoritmos de IA). Esta informaci\u00f3n simple o parcialmente integrada se obtiene en formatos espec\u00edficos que el m\u00e9dico tra-tante lo descifra seg\u00fan su preparaci\u00f3n e in- tegra con la similar; obtenida de la relaci\u00f3n m\u00e9dico-paciente, el examen f\u00edsico y la histo - ria cl\u00ednica, traduci\u00e9ndola en diagn\u00f3sticos de alta probabilidad a la manera de s\u00edndromes espec\u00edficos de diversas enfermedades y es- tableciendo las medidas de estudio adicio - nales o terap\u00e9uticas seg\u00fan el caso. (3, 4) Esta vasta informaci\u00f3n que se obtiene du- rante la atenci\u00f3n m\u00e9dica generalmente ter - mina impresa de manera digital (computa- doras) en un formato estructurado llamado historia cl\u00ednica. Historia cl\u00ednica digital a la cual se agrega toda la informaci\u00f3n de labo - ratorio y gabinete para formar un expedien- te. En la actualidad ya se tienen por pacien- te bases de datos relacionales y programas de IA que tienen como salida la informaci\u00f3n que el m\u00e9dico revisa y solicita de cada pa- ciente. Esta gran base de datos relaciona- les y programas est\u00e1n estructurados en un gran formato llamado Expediente Cl\u00ednico Electr\u00f3nico Estructurado (ECEE)(2), elabora- do seg\u00fan Norma Oficial Mexicana (NOM). Entonces tenemos un c\u00famulo enorme de informaci\u00f3n obtenida por paciente y suscep - tible de organizarse por instituci\u00f3n de salud (IMSS, ISSSTE, SEMAR, SEDENA, INSTITUTOS NACIONALES DE SALUD, etc\u00e9tera), por Uni- dad de Atenci\u00f3n M\u00e9dica (Medicina Familiar, \"Los dispositivos de IA m\u00e1s evolucionados son los capaces de compilar una gran cantidad de conceptos, t\u00e9rminos, frases, p\u00e1rrafos completos respecto de una tem\u00e1tica o un campo sem\u00e1ntico...\".Gaceta11 a fondo Hospitales de Zona o \u00c1rea, Hospitales Regio - nales, Hospitales de Especialidades); y final- mente, por delegaciones, municipios, ciuda- des, estados, regiones del pa\u00eds y naci\u00f3n. Avalancha de informaci\u00f3n ya estructurada y organizada seg\u00fan se menciona anterior - mente y susceptible de analizarse por me - dio de c\u00f3digos y algoritmos de IA. Realizar c\u00e1lculos simples o estad\u00edsticos complejos a diferente escala partiendo de lo micro o in- dividual del paciente, hasta el macro de uni- dades, instituciones de salud, localidades geogr\u00e1ficas, grandes poblaciones y de \u00edndo - le nacional. Factible de realizar con el dise - \u00f1o de grandes bases de datos (Big Data) (2) y programas espec\u00edficos para conocer de una informaci\u00f3n aparentemente ca\u00f3tica; ten- dencias claras en el rumbo, direcci\u00f3n y tipo de informaci\u00f3n. As\u00ed conoceremos m\u00e1s me - diante este tipo de investigaci\u00f3n (elemental, de servicios de salud, epidemiol\u00f3gica y cl\u00edni- ca), de que se enferman los mexicanos, cual es el grado de deterioro en la salud y calidad de vida de nuestra poblaci\u00f3n. A\u00fan m\u00e1s y con enfoque de las ciencias de la complejidad, conocer y atender mejor a la poblaci\u00f3n mexicana en todo el proce - so de salud-enfermedad con medidas de prevenci\u00f3n pertinentes y oportunas y que esta atenci\u00f3n primaria, sea m\u00e1s eficiente y costo-efectiva, en especial con foco en la tercera edad blanco de padecimientos cr\u00f3 - nicos degenerativos y neopl\u00e1sicos. (5) Papel relevante jug\u00f3 y sigue aportando la IA en la atenci\u00f3n m\u00e9dica y los servicios de salud a la poblaci\u00f3n durante la pandemia de COVID.19; desde la investigaci\u00f3n epidemiol\u00f3gica y cl\u00ed- nica (ensayos cl\u00ednicos y cuasiexperimentales, metaan\u00e1lisis y revisiones sistem\u00e1ticas) para encontrar la f\u00f3rmula adecuada de medica- mentos antivirales, esquemas terap\u00e9uticos probando antivirales conocidos y medidas farmacol\u00f3gicas y no farmacol\u00f3gicas de so - porte (distanciamiento social, uso de cubre - bocas, lavado de manos, uso frecuente de antis\u00e9pticos antivirales, uso suplementario de ox\u00edgeno) (6), anticuerpos monoclonales anticovid-19 y vacunas, culminando en vacu-nas anticovid-19 tipo mRNA (Pfizer y Moder - na) y antivirales espec\u00edficos anticovid-19. Impacto de la IA en la medicina compleja y biotecnol\u00f3gica En la actualidad no se concibe una medi- cina, servicios de salud y atenci\u00f3n m\u00e9dica, donde no se aborde de manera integral el padecer de nuestros semejantes; esto es, cuando se ubican en alguna de las partes del gran continuo que es el proceso salud- enfermedad. El organismo humano como un todo (\u00f3rganos, aparatos y sistemas, as\u00ed como tejidos, c\u00e9lulas y red de redes interre - lacionadas de funciones, procesos biol\u00f3gi- cos moleculares y bioqu\u00edmicos) sigue sien- do un misterio. Las \u00e1reas y funciones menos conocidas son las de escala microsc\u00f3pica intracelular y otras a nivel molecular y en escala nano. Algunas funciones y mecanis- mos bioqu\u00edmicos poco explorados lo son no por escaso inter\u00e9s de acad\u00e9micos e investi- gadores, sino porque todav\u00eda no se dispon\u00eda de las herramientas necesarias para tal fin. Esto ha sido factible con el gran desarrollo reciente de dispositivos digitales y micro - procesadores alimentados con programas de IA de aprendizaje profundo, convolucio - nal y con c\u00f3digos y algoritmos gen\u00e9ticos (generativos). Estas innovaciones tecnol\u00f3gicas en el \u00e1rea de la medicina y que han recibido m\u00e1s aten- ci\u00f3n por futura aplicaci\u00f3n en el campo de la salud y enfermedad son: Biolog\u00eda sint\u00e9tica. (7) Fabricaci\u00f3n de c\u00e9lulas, tejidos y \u00f3rga- nos programados para que lleven a cabo procesos controlados por los seres humanos\", un mundo completamente nuevo con muchas ventajas. Fabricaci\u00f3n a demanda y por necesidad, dada la ca- rencia o mala funci\u00f3n de un \u00f3rgano: Ri- \u00f1ones, h\u00edgados, pulmones, suprarrena- les, tiroides, piel, m\u00fasculos, huesos; por solo mencionar algunos, y que aliviar\u00edan la carencia actual de \u00f3rganos para tras- plante. Gaceta12 Edici\u00f3n de genes. (8) El sistema CRISPR/Cas es parte de un sistema inmune adaptativo que los or - ganismos procariotas desarrollaron para defenderse de la incorporaci\u00f3n de material gen\u00e9tico ex\u00f3geno. Este sis- tema de inmunidad est\u00e1 mediado por una nucleasa espec\u00edfica que degrada al DNA invasor y posteriormente algunos fragmentos de la mol\u00e9cula degradada se almacena para reconocer y eliminar secuencias similares en el futuro. Re - cientemente fue posible reprogramar este sistema para reconocer cualquier secuencia de DNA y realizar ediciones gen\u00e9ticas en una gran cantidad de orga- nismos de manera altamente espec\u00edfica. El sistema CRISPR/Cas ha sido adapta- do para el desarrollo de una estrategia altamente espec\u00edfica en el tratamiento de infecciones producidas por bacterias resistentes a antimicrobianos. Tambi\u00e9n tendr\u00eda aplicaci\u00f3n en gran can- tidad de padecimientos gen\u00e9ticos por deficiencia de alguna substancia indis- pensable para la vida, o por exceso de ella dada su nula degradaci\u00f3n y consi- guiente acumulaci\u00f3n tisular con disfun- ci\u00f3n org\u00e1nica (glucoprote\u00ednas, enzimas, prote\u00ednas estructurales de huesos, tejido pulmonar, \u00f3seo, etc\u00e9tera). La medicina regenerativa. (9) Inducci\u00f3n de c\u00e9lulas madre pluripoten- tes: novedades en medicina regenerati- va. \"Stem cells\" (c\u00e9lulas tallo). La medi- cina regenerativa busca contrarrestar el envejecimiento y los da\u00f1os celulares del cuerpo humano. Un nuevo m\u00e9todo de obtenci\u00f3n de c\u00e9lulas pluripotentes des- cubierto por el Dr. Yamanaka en 2012, nombrado reprogramaci\u00f3n celular, ha permitido la inducci\u00f3n de c\u00e9lulas madre pluripotentes (iPSC) a partir de c\u00e9lulas de la piel. La investigaci\u00f3n liderada por el doctor Michael Edel de la Unidad de Anatom\u00eda y Embriolog\u00eda de la UAB ha mejorado este m\u00e9todo a trav\u00e9s de la sustituci\u00f3n del gen c-Myc (oncogen) por Ciclina D1. Esto podr\u00eda sentar las bases para futuras aplicaciones cl\u00ednicas. Las aplicaciones en medicina cl\u00ednica son varias, pero principalmente en la rege - neraci\u00f3n de tejidos da\u00f1ados por alguna enfermedad adquirida, ya sea cr\u00f3nica degenerativa, inmunol\u00f3gica o por c\u00e1n- cer. Podr\u00eda en algunos casos mejorar la funci\u00f3n de \u00f3rganos atrofiados o invadi- dos por tejido no funcional (fibrosis) o c\u00e1ncer metast\u00e1sico; o aumentar la so - brevida antes de alg\u00fan procedimiento de trasplante de \u00f3rganos. Ejemplos: Car - diopat\u00eda isqu\u00e9mica cr\u00f3nica congestiva, insuficiencia renal, insuficiencia hep\u00e1ti- ca, leucemias, etc\u00e9tera. Aspectos \u00e9ticos en interacci\u00f3n de la Inteligencia Humana (m\u00e9dicos, medicina) vs Inteligencia Artificial: Gran parte del personal m\u00e9dico que atien- de a los pacientes, tanto en medicina priva- da como en instituciones p\u00fablicas de salud, son estudiantes de medicina general y resi- dentes en formaci\u00f3n en alguna especialidad m\u00e9dica; adem\u00e1s de los m\u00e9dicos ya formados y reci\u00e9n graduado que est\u00e1n en constante proceso de actualizaci\u00f3n y educaci\u00f3n con- tinua. En todos ellos es indispensable una gran vocaci\u00f3n de servicio, compasi\u00f3n y em- pat\u00eda, a fin de que los servicios m\u00e9dicos sean proporcionados con alto sentido humani- tario. La readecuaci\u00f3n curricular efectuada en 2010 en la licenciatura de la Facultad de Medicina de la UNAM ya contempl\u00f3 en los planes y programas de estudio a la \u00e9tica m\u00e9 - dica y bio\u00e9tica como base deontol\u00f3gica de su formaci\u00f3n; asimismo, se emiti\u00f3 tambi\u00e9n en dicha fecha, la declaraci\u00f3n de principios \u00e9ticos del educador en medicina. (10) Por otro lado, todos los m\u00e9dicos cursan la asignatura de inform\u00e1tica m\u00e9dica, donde un papel rele - vante lo juega el conocimiento de la IA. En internet ha crecido la inteligencia artifi- cial hasta convertirse en un programa con c\u00f3digos y algoritmos que aprenden y se re - programan para efectuar tareas preestable - cidas con mayor eficiencia; si bien lo ante -Gaceta13 a fondo rior se traduce en mejor\u00eda, el programador desconoce los alcances de los resultados y de la reprogramaci\u00f3n. Ante el riesgo de des- viaci\u00f3n de los objetivos preestablecidos y de los reglamentos \u00e9ticos, se tienen que im- plementar filtros al inicio, durante y al final del proceso, como alarmas cuando existan desviaciones con implicaci\u00f3n bio\u00e9tica. La in- teracci\u00f3n de la inteligencia humana con la inteligencia artificial ha tenido desencuen- tros negativos y positivos. Al principio, bast\u00f3 con adecuar normas, leyes laborales y dere - chos humanos; ahora se requiere establecer normas \u00e9ticas, como las formuladas en la Declaraci\u00f3n de Barcelona para el Adecuado Desarrollo y Uso de la Inteligencia Artificial en Europa. (11) Referencias 1. Gardner H. Estructuras de la mente. La teor\u00eda de las inteligencias m\u00faltiples. Segunda edici\u00f3n. M\u00e9xico: Fondo de Cultura Econ\u00f3mica; 1994. 2. Huesca E, Ju\u00e1rez J, Cicero P; Coordinadores. Mi Vecino Es Un Robot. Los Retos De Convivir Con La Inteligencia Artificial. Primera edici\u00f3n. M\u00e9xico. Debate; diciembre 2022. 3. Lifshitz GA, Ramiro-Hern\u00e1ndez M, Garc\u00eda-Vigil JL, Mendoza-Salas K, Jinich-Brook H. S\u00edntomas y signos cardinales de las enfermedades. M\u00e9xico: Octava edici\u00f3n. Manual Moderno; noviembre 2022. 4. Garc\u00eda-Vigil JL. Principios generales de prescripci\u00f3n en el proceso de razonamiento diagn\u00f3stico: Research Gate 08/2010.Consulta 24/05/2023. https://www.researchgate.net/publication/311106313_PRINCIPIOS_GENERALES_DE_ PRESCRIPCION_PROCESO_DE_RAZONAMIENTO_DIAGNOSTICO. 5. Garc\u00eda-Vigil JL. Las enfermedades cr\u00f3nicas y neopl\u00e1sicas, desde las ciencias de la complejidad y la atenci\u00f3n pri- maria. Rev Med Inst Mex Seguro 2020; 156:576-583. 7. Perspectivas de Salud P\u00fablica. Biolog\u00eda Sint\u00e9tica. Salud P\u00fablica de M\u00e9xico. Consulta 26-05-2023. https://www. scielosp.org/pdf/spm/v52n3/12.pdf 8. Ch\u00e1vez-Jacobo V. El sistema de edici\u00f3n gen\u00e9tica CRISPR/Cas y su uso como antimicrobiano espec\u00edfico. Revista Especializada DOI: 10.22201/fesz.23958723e.2018.2.5 https:// www.scielo.org.mx/pdf/tip/v21n2/1405-888X-tip-21-02-e201825.pdf 9. Universidad Aut\u00f3noma de Barcelona (UAB Divulga). Inducci\u00f3n de c\u00e9lulas madre pluripotentes: novedades en medicina regenerativa. J, Mart\u00ednez-Gonz\u00e1lez A. Declaraci\u00f3n de principios \u00e9ticos del educador en medicina. Rev Med Inst Mex Seguro Soc. 2011; 49:571-574. 11. Garc\u00eda-Vigil JL. Reflexiones en torno a la \u00e9tica, la inteligencia humana y la inteligencia artificial. Gac Med Mex. 2021; 157:311-314. Imagen: freepik.comGaceta14 1. Introducci\u00f3n A trav\u00e9s de los a\u00f1os la atenci\u00f3n m\u00e9dica ha cambiado, y gracias a los avances tecnol\u00f3gi- cos actualmente encontramos el uso de la inteligencia artificial jugando un papel cada vez m\u00e1s importante en este campo. Se utiliza para diagn\u00f3sticos por imagen, ge - n\u00e9tica, electrodiagn\u00f3sticos, seguimientos fi- siol\u00f3gicos, evaluaciones de discapacidad y ta- mizajes masivos, entre otros, y en los \u00faltimos diez a\u00f1os su aplicaci\u00f3n ha aumentado (Jiang et al., 2017), lo que nos permite afirmar que es una tecnolog\u00eda que no solo continuar\u00e1 desa- rroll\u00e1ndose, sino que cada vez m\u00e1s el proceso de atenci\u00f3n m\u00e9dica se apoyar\u00e1 en ella. Indudablemente esto conlleva grandes ven- tajas: diagn\u00f3sticos de manera oportuna, re - ducci\u00f3n de errores m\u00e9dicos, mayor precisi\u00f3n en algunos casos y eficiencia, por mencionar algunos ejemplos. Sin embargo, es impor - tante cuestionar el papel que la responsabi- lidad tiene en el uso de la inteligencia artifi- cial en este campo de aplicaci\u00f3n, buscando que los pacientes tengan una atenci\u00f3n m\u00e9 - dica integrar, en donde tanto la inteligencia artificial como el personal m\u00e9dico involucra- do funcionen de manera conjunta. 2. \u00bfQu\u00e9 es la inteligencia artificial? Una forma para establecer a qu\u00e9 nos refe - rimos cuando se habla de inteligencia arti- ficial, es observando sus componentes. Por un lado, la palabra artificial indica que la entidad es el producto de seres humanos, y que no puede existir de forma natural sin que estos est\u00e9n involucrados. Un artefacto es un objeto creado por el hombre que no se presenta naturalmente, sino que ocurre como resultado de preparativos o investiga- ci\u00f3n realizados por los mismos. Por otro lado, inteligencia es usualmente definida como la habilidad de adquirir y aplicar conocimiento; Humanos y m\u00e1quinas inteligentes: la responsabilidad en el uso de inteligencia artificial en la atenci\u00f3n m\u00e9dica Elisa C. Calleja Sordo* \"Nosotros somos responsables de todo y de todos, ante todos, y yo m\u00e1s que todos los dem\u00e1s\" Dostoyevski una definici\u00f3n m\u00e1s comprensible se refiere a ella como el uso h\u00e1bil de la raz\u00f3n, el acto de comprender y la habilidad de pensar de manera abstracta medida por criterios obje - tivos. Es as\u00ed como la inteligencia artificial se refiere a una entidad creada por seres hu- manos que posee la habilidad de entender y comprender conocimiento, de razonar uti- lizando dicho conocimiento e incluso actuar debido al mismo (Ekmekci & Arda, 2020). John McCarthy la define como la ciencia y la ingenier\u00eda de hacer m\u00e1quinas inteligen- tes, especialmente programas inform\u00e1ticos inteligentes, y est\u00e1 relacionada con la tarea similar de utilizar computadoras para com- prender la inteligencia humana, pero la in- teligencia artificial no tiene que limitarse a m\u00e9todos biol\u00f3gicamente observables (2011). Asimismo, es una tecnolog\u00eda inform\u00e1tica impulsada por algoritmos, programada para autoaprender a partir de datos, hacer pre - dicciones inteligentes, y tomar decisiones en tiempo real utilizando redes neuronales artificiales, aprendizaje autom\u00e1tico, auto - matizaci\u00f3n de procesos rob\u00f3ticos y miner\u00eda de datos. En el \u00e1rea de la atenci\u00f3n m\u00e9dica es el uso de tecnolog\u00edas inteligentes basa- das en datos que aprovechan los recursos e informaci\u00f3n de la pr\u00e1ctica m\u00e9dica de forma efectiva para respaldar y agilizar la toma de decisiones y, en consecuencia, brindar un mejor cuidado que se adapte a las necesida- des individuales. (Siala & Wang, 2022, p. 1). Para informar de manera efectiva la toma de decisiones en el cuidado de la salud, las tecnolog\u00edas de inteligencia artificial usual- mente utilizan algoritmos de aprendizaje * Licenciada en Filosof\u00eda, U. del Claustro de Sor Juana; Maestra y Doctora en Ciencias, UNAM; Doctora en Filosof\u00eda, U. de Salamanca; Miembro de Cefiloe, U. de Valpara\u00edso, Chile.Gaceta15 a fondo autom\u00e1tico para realizar actividades anal\u00edti- cas e inferencias que pueden ser llamadas inteligentes, que se utilizan para detectar y predecir pandemias, enfermedades, diag- nosticar y manejar condiciones cr\u00f3nicas y neurol\u00f3gicas, interpretar esc\u00e1neres m\u00e9di- cos e im\u00e1genes de radiolog\u00eda, dar servicios y tratamientos m\u00e9dicos, investigaci\u00f3n de f\u00e1r - macos, y emparejar pacientes a ensayos cl\u00ed- nicos de acuerdo a sus caracter\u00edsticas (Siala & Wang, 2022, p. 1). 3. Problemas derivados del uso de inteli- gencia artificial en la atenci\u00f3n m\u00e9dica Indudablemente el uso de la inteligencia ar - tificial en la atenci\u00f3n m\u00e9dica tiene grandes beneficios para los pacientes, as\u00ed como para el personal m\u00e9dico, pero es importante tam- bi\u00e9n presentar los problemas que se pueden derivar del uso de esta tecnolog\u00eda. Si bien a continuaci\u00f3n no se agotar\u00e1n las problem\u00e1ticas que pueden llegar a derivarse del uso de esta tecnolog\u00eda, son cinco puntos importantes que deben abordarse confor - me su uso va ganando terreno (Sand et al., 2022, p. 163): 1) Privacidad y protecci\u00f3n de datos de los pacientes: La inteligencia artificial reco - pila y analiza una gran cantidad de infor - maci\u00f3n personal, lo cual plantea preocu- paciones \u00e9ticas entorno a la privacidad, confidencialidad y seguridad de los da- tos y de los pacientes. No podemos con- tinuar hablando de confidencialidad en sentido tradicional, como bien lo se\u00f1al\u00f3 Mark Siegler (1982), pero es importante responder a la pregunta por c\u00f3mo se proteger\u00e1 la privacidad de los pacien- tes al integrar inteligencia artificial en el proceso m\u00e9dico. 2) Toma de decisiones automatizadas: Esta tecnolog\u00eda puede tomar decisiones cl\u00ed- nicas, m\u00e9dicas y \u00e9ticas, pero ello nos en- frenta con preguntas sobre la equidad y transparencia del proceso que lleva a dicha decisi\u00f3n, dado que el proceso deliberativo es interno. Es lo que se se -\u00f1ala como la naturaleza de caja negra propia de estos sistemas, en los que no existe propiamente una explicaci\u00f3n so - bre c\u00f3mo producen un determinado re - sultado -output- a partir de informaci\u00f3n espec\u00edfica que se le proporciona -input- (Holm, 2021, p. 2; Sand et al., 2022, p. 167). 3) Sesgos y discriminaci\u00f3n por parte de los algoritmos: Los algoritmos propios de la inteligencia artificial pueden verse in- fluenciados por sesgos inherentes en los datos de entrenamiento, lo que puede llevar a resultados injustos o discrimina- torios (Holm, 2021, p. 7). 4) Autonom\u00eda y consentimiento informa- do: El uso de la inteligencia artificial nos enfrenta con la pregunta por la autono - m\u00eda de los pacientes y el consentimiento informado, \u00bfc\u00f3mo se puede garantizar que los pacientes comprendan el proce - so y puedan participar activamente en las decisiones sobre su atenci\u00f3n m\u00e9dica estando la inteligencia artificial de por medio? 5) Rendici\u00f3n de cuentas: A medida que la inteligencia artificial desempe\u00f1a un pa- pel m\u00e1s importante en la toma de de - cisiones y la atenci\u00f3n m\u00e9dica, cabe pre - guntar qui\u00e9n responde en caso de que se presenten errores o da\u00f1os causados por los sistemas de inteligencia artificial, dado que no podemos se\u00f1alar a un sis- tema operativo o m\u00e1quina como culpa- ble (Jasanoff, 2016, p. 41). Si bien esto no agota los problemas que se pueden derivar del uso de la inteligencia ar - tificial dentro de la atenci\u00f3n m\u00e9dica, eviden- cian el riesgo que puede implicar el uso de esta tecnolog\u00eda, por lo que propondremos la responsabilidad como elemento que debe acompa\u00f1ar el proceso m\u00e9dico cuando est\u00e1 complementado o sustituido por la inteli- gencia artificial. 4. Responsabilidad Veamos ahora a qu\u00e9 nos referimos al hablar de responsabilidad: se enfoca en actos que Gaceta16 se han llevado a cabo y que exigen desde fuera que el autor de la acci\u00f3n asuma las consecuencias. De acuerdo con Hans Jonas (...) la \u00abresponsabilidad\u00bb se refie - re a actos hechos y que adquiere realidad en el hacer desde fuera responsable a alguien por lo que ha hecho. El sentimiento que aqu\u00ed acaso acompa\u00f1e al agente, senti- miento por el cual asume interior - mente la responsabilidad (senti- miento de culpa, arrepentimiento, disposici\u00f3n a expiar, pero tambi\u00e9n obstinado orgullo), es igual de re - troactivo que el objetivo \u00abtener que\u00bb responder de lo hecho (Jo - nas, 2015, p. 162). En este sentido, ser responsable de los actos propios significa tener capacidades volitivas y cognoscitivas suficientes para imputar a uno el acto particular en cuesti\u00f3n, \"pero no prejuicia en nada la responsabilidad en re - laci\u00f3n con ese acto\" (Canto-Sperber, 2011, p. 1398). Al preguntar por las condiciones en las que una persona responsable de sus actos lo es de un acto en particular, el cual puede ser condenable o meritorio a primera vista, po - demos responder que Una natural sugesti\u00f3n consiste en decir que \u00e9ste tiene algo que ver en todo acto en el que ha habido un compromiso volitivo y cognosci- tivo m\u00ednimo de su parte, en el que el compromiso volitivo m\u00ednimo ha sido un acto (es decir, un movimien- to corporal intencional y no un mo - vimiento simplemente sufrido, efec - to de alg\u00fan mecanismo fisiol\u00f3gico o de una causa externa, como la fuerza f\u00edsica ejercida por alg\u00fan otro) y, el compromiso cognoscitivo m\u00ed- nimo, que el agente sea consciente de lo que hace (Canto-Sperber, 2011, p. 1398).Sin embargo, \u00bfqu\u00e9 pasa cuando estamos tratando con inteligencia artificial en la atenci\u00f3n m\u00e9dica? Por un lado, podemos se\u00f1alar la responsabilidad de los actores involucrados en el proceso, pero no po - demos hablar de la responsabilidad de la tecnolog\u00eda inform\u00e1tica, dado que no se re - fiere a un agente que tenga capacidades volitivas y cognoscitivas que impulsen los actos. Es por esto importante que la responsabi- lidad recaiga en los actores involucrados, y que no se derive parte de la misma a la inteligencia artificial. En el caso de la pri- vacidad y protecci\u00f3n de los datos de los pacientes, la UNESCO recomienda respe - tar, proteger y promover la privacidad a lo largo del ciclo de vida de los sistemas de Inteligencia artificial, asegurando que los datos se recopiles, utilicen, compartan, ar - chiven y supriman de acuerdo con el dere - cho internacional y los valores presentes en documentos emitido por las instituciones (UNESCO, 2022, p. 22). Al hablar de la toma de decisiones de for - ma automatizada, es importante que el papel del m\u00e9dico no se limite a la presta- ci\u00f3n de cuidados de la salud, sino que se incluya la responsabilidad de interpretar, mediar y salvaguardar entre el paciente y la inteligencia artificial, esto con el fin de evitar que se deshumanice la medicina, dado que se trata de una tecnolog\u00eda que no promueve la interacci\u00f3n entre las per - sonas, el respeto por la identidad, ni sirve a fines humano (Jotterand & Bosco, 2022). De igual manera, los m\u00e9dicos deben po - der evaluar la informaci\u00f3n proporcionada a la tecnolog\u00eda inform\u00e1tica y saber el tipo de informaci\u00f3n que se utiliza en cada pro - cedimiento (Sand et al., 2022, p. 167), esto con el fin de entender los l\u00edmites de esta tecnolog\u00eda, lo cual contribuye al asumir la responsabilidad al momento de la toma de decisiones. Lo anterior permite abordar el problema de sesgos y discriminaci\u00f3n presentes en los al-Gaceta17 a fondo goritmos utilizados partiendo del mismo principio, la supervisi\u00f3n de la informaci\u00f3n proporcionada a la inteligencia artificial, para salvaguardar la dignidad de los pacien- tes. En el caso de la autonom\u00eda de los pacientes y el consentimiento informado, se asume la responsabilidad al integrar a \u00e9stos en la toma de decisiones, es decir, explicando a los pacientes cu\u00e1l es la informaci\u00f3n con la que se cuenta y que utilizar\u00e1 la inteligencia artificial, as\u00ed como haci\u00e9ndolos part\u00edcipes a lo largo del proceso. La UNESCO lo plantea como una recomendaci\u00f3n, \"La transparen- cia y la explicabilidad est\u00e1n estrechamente relacionadas con las medidas adecuadas de responsabilidad y rendici\u00f3n de cuentas, as\u00ed como con la fiabilidad de los sistemas de IA\" (UNESCO, 2022, p. 23). Por \u00faltimo, cuando hablamos de la rendi- ci\u00f3n de cuentas, se recomiendan mecanis- mos de supervisi\u00f3n y control, es decir, una responsabilidad directa, la responsabilidad por la vigilancia de la informaci\u00f3n proporcio - nada a la inteligencia artificial, el proceso de an\u00e1lisis y el resultado del mismo, la presen- cia de personal capacitado que asuman las consecuencias, tanto positivas como negati- vas, del proceso m\u00e9dico. Responsabilidad conjunta Es importante establecer el tipo de respon- sabilidad de la que se est\u00e1 hablando, dado que al abordar la atenci\u00f3n a la salud no tra- tamos con una sola persona, es decir, el m\u00e9 - dico tratante y directamente responsable del paciente, sino que nos encontramos con una red de agentes involucrados, y a\u00fan m\u00e1s al haber un sistema de inteligencia artificial involucrado en la atenci\u00f3n m\u00e9dica. El m\u00e9dico tratante es el primer agente que podemos se\u00f1alar como responsable, sin embargo, dada la naturaleza de la atenci\u00f3n m\u00e9dica y la tecnolog\u00eda involucrada, es im- portante considerar a todos los actores que juegan un papel: el fabricante del equipo que se utiliza, el especialista en programar -lo, el personal m\u00e9dico, y el paciente. Esto nos habla de una responsabilidad conjunta, en donde se tiene un objeto com\u00fan que a su vez permite una actividad basada en la co - rresponsabilidad de todos los participantes, se trata de una responsabilidad genuina y que no se limita al \u00e9xito de la participaci\u00f3n, sino que tambi\u00e9n acepta las consecuencias de un posible fracaso, lo cual no se refiere a una cat\u00e1strofe paralizante, sino que pue - de motivar los pr\u00f3ximos esfuerzos conjuntos que den como resultado el \u00e9xito deseado (Kwiatkowski, 2018, p. 201). Es lo que Michael Bratman se\u00f1ala como responsabilidad colectiva, la cual se basa en una actividad cooperativa compartida, don- de destaca un tipo espec\u00edfico de interacci\u00f3n interpersonal y est\u00e1 formado por tres rasgos caracter\u00edsticos: (i) capacidad de respues- ta mutua, (ii) compromiso con la actividad conjunta y (iii) compromiso de apoyo mutuo (1992, p. 328). La capacidad de respuesta mutua se refiere a la intenci\u00f3n de los actores involucrados por responder a las acciones e intenciones de los otros. En el caso del uso de la inteligen- cia artificial en la atenci\u00f3n m\u00e9dica, la encon- tramos presente cuando cada participante orienta su comportamiento de acuerdo con los de los dem\u00e1s, y sabiendo que es rec\u00edpro - co, es decir, cuando los agentes buscan que la atenci\u00f3n m\u00e9dica sea m\u00e1s precisa y efi- ciente con el uso de inteligencia artificial y sus esfuerzos se enfocan en lograrlo. El compromiso con la actividad conjunta es cuando cada participante se compromete con la actividad en cuesti\u00f3n, y la capacidad de respuesta mutua se encuentra en fun- ci\u00f3n de lograr ese compromiso, en este caso, desarrollar la tecnolog\u00eda que permita ofrecer una atenci\u00f3n m\u00e9dica m\u00e1s eficiente. Por \u00faltimo, el compromiso de apoyo mutuo nos habla del compromiso que cada parti- cipante tiene de apoyar el esfuerzo de los otros para que cada uno pueda desempe\u00f1ar su papel en la actividad conjunta, es decir, Gaceta18 en la interacci\u00f3n y colaboraci\u00f3n que existe entre los involucrados, complementando as\u00ed el papel que cada uno desempe\u00f1a. Se trata de una colaboraci\u00f3n en el sentido en que los diferentes actores presentes tra- bajan con la misma finalidad en mente: el desarrollo e implementaci\u00f3n de la inteligen- cia artificial para la atenci\u00f3n m\u00e9dica. Conclusi\u00f3n Podemos ver que tanto la inteligencia ar ti- ficial como los actores involucrados, partici- pan de la actividad, la atenci\u00f3n m\u00e9dica, te - niendo como fin mejorar el estado de salud del paciente, lo que nos lleva a afirmar la ne - cesidad de una responsabilidad conjunta, en donde \u00e9sta no se diluya entre los diferentes actores, sino que cada uno de ellos reconoz - ca el papel que juega y el impacto que tiene en la salud y en la vida de los pacientes.Se debe priorizar la presencia humana en el proceso de atenci\u00f3n m\u00e9dica, lo cual no debe impedir que se implemente la tecnolog\u00eda en el contexto cl\u00ednico, sino que la complemen- te, teniendo como meta la salud de los pa- cientes. Es decir, podemos confiar en la inteligencia artificial como medio para dar una mejor atenci\u00f3n m\u00e9dica, pero no debemos ceder el control, sino que este debe al final recaer en los seres humanos \"(...) ya que estos pueden recurrir a los sistemas de IA en la adopci\u00f3n de decisiones y en la ejecuci\u00f3n de tareas, pero un sistema de IA nunca podr\u00e1 reem- plazar la responsabilidad final de los seres humanos y su obligaci\u00f3n de rendir cuentas\" (UNESCO, 2022, p. 22). Referencias -Bratman, M. E. (1992). 327-341. Doi: 10.2307/2185537 -Canto-Sperber, M. (2011). Diccionario de \u00e9tica y de filosof\u00eda moral (II). Fondo de Cultura Econ\u00f3mica. -Ekmekci, P. E., & Arda, B. (2020). Artificial Intelligence and Bioethics (1\u00ba). Springer Ethics. (2021). Handle with care: Assessing performance measures of medical AI shared clinical decision-mak - ing. Bioethics, 36(2). https://doi.org/10.1111/bioe.12930 -Jasanoff, S. (2016). The Ethics of Invention: Technology and the Human Future (1\u00b0 edici\u00f3n). W.W. Norton & Company, Inc. -Jiang, F., Jiang, Y., Zhi, H., Dong, Y., Li, H., Ma, S., Wang, Y [Yilong], Dong, Q., Shen, H., & Wang, Y [Yongjun]. (2017). Ar - tificial intelligence in healthcare: Past, Neurology, 2(4), https://doi. org/10.1136/svn-2017-000101 -Jonas, H. (2015). El principio de responsabilidad: Ensayo de una \u00e9tica para la civilizaci\u00f3n tecnol\u00f3gica. Herder. https://doi.org/10.2307/j.ctvt9k2sz -Jotterand, F., & Bosco, C. (2022). Artificial Intelligence in Medicine: A Sword of Damocles? Journal of Medical Sys- tems, 46(9). https://doi.org/10.1007/s10916-021-01796-7 -Kwiatkowski, W. Medicine and on the notion of responsibility in the technology-assist - ed health care. Medicine, Health Care, and Philosophy, 21(2), 197-205. https://doi.org/10.1007/s11019-017-9788-8 -McCarthy, Questions. http://jmc.stanford.edu/artificial-intelligence/what-is-ai/index.html -Sand, M., Dur\u00e1n, J. M., Jongsma, K. R. (2022). Responsibility beyond design: Physicians' medical AI. -Siala, H., & Wang, Y [Yichuan] (2022). Shifting artificial intelligence to be responsible in healthcare: A systematic review. Social Science & Medicine (1982), 296, 1-15. https://doi.org/10.1016/j.socscimed.2022.114782 -Siegler, M. (1982). Sounding Boards. Confidentiality in medicine - a decrepit concept. The New England Journal of Medicine, 307 (24), 1518-1521. https://doi.org/10.1056/NEJM198212093072411 -UNESCO. (2022). Recomendaciones sobre la \u00e9tica de la inteligencia artificial. https://unesdoc.unesco.org/ ark:/48223/pf0000381137_spaGaceta19 a fondo Reconocimiento facial: una herramienta de alto riesgo Juan Esp\u00edndola Mata* El reconocimiento facial es una forma de in- teligencia artificial que implica la extracci\u00f3n, digitalizaci\u00f3n y comparaci\u00f3n automatizadas de la distribuci\u00f3n espacial y geom\u00e9trica de los rasgos faciales para identificar a las per - sonas. Son cuatro sus variedades, seg\u00fan el tipo de recolecci\u00f3n de datos que lleven a cabo, cada una con sus implicaciones \u00e9ti- cas. De la m\u00e1s b\u00e1sica hasta la m\u00e1s compleja, estas funciones son: la \"detecci\u00f3n\", que no recopila informaci\u00f3n de identificaci\u00f3n per - sonal; la \"caracterizaci\u00f3n\", que recopila in- formaci\u00f3n como g\u00e9nero, rango de edad e indicadores emocionales, pero no recopila ni retiene plantillas faciales de identifica- ci\u00f3n personal; la \"verificaci\u00f3n\", que recopila y retiene plantillas faciales, y luego utiliza un sistema de coincidencia \"uno a uno\" en el que el software determina si la persona es quien dice ser (por ejemplo, un tel\u00e9fono inteligente escanea el rostro de la persona para determinar si coincide con la plantilla almacenada en el tel\u00e9fono); y, de mayor re - levancia para el prop\u00f3sito de este ensayo, la \"identificaci\u00f3n\", que tambi\u00e9n crea una plan- tilla identificable de una persona \u00fanica pero la usa en un sistema de correspondencia de \"uno a muchos,\" donde el sistema compara una imagen recopilada con una base de da- tos existente (Selinger, Evan y Leong 2021). El uso de la tecnolog\u00eda de reconocimiento fa- cial ha ido ganando terreno en las sociedades contempor\u00e1neas. Es com\u00fan su utilizaci\u00f3n en las actividades policiales, y distintas compa- \u00f1\u00edas como PimEyes, FindClone o, lo m\u00e1s con- trovertido de todos, Clearview AI, ponen el servicio al alcance de agentes estatales y no estatales. Con el avance del reconocimiento facial, las cr\u00edticas dirigidas a ella han aumen- tado de manera paralela. El despliegue de esta tecnolog\u00eda en reg\u00edmenes autoritarios y democr\u00e1ticos liberales por igual para perse - guir a grupos \u00e9tnicos, reprimir a disidentes pol\u00edticos o llevar a cabo una vigilancia gene - ralizada e injustificada se puede describir, acertadamente, como una amenaza social y pol\u00edtica. Incluso cuando se utiliza para fines leg\u00edtimos, el reconocimiento facial ha sido criticado por promover y solidificar prejuicios sociales, que perjudican desproporcionada- mente a grupos minoritarios. Para explorar los problemas \u00e9ticos que rodean al recono - cimiento facial, este ensayo comienza por reconstruir la mejor justificaci\u00f3n posible para su uso. Posteriormente, el ensayo explora al- gunas de las preocupaciones con respecto a la tecnolog\u00eda, sobre todo aquellas asociadas a los casos en que \u00e9sta se combina con otras tecnolog\u00edas, como los sistemas de circuito ce - rrado de televisi\u00f3n o las redes sociales. M\u00e1s concretamente, y para ordenar la discusi\u00f3n, las objeciones que se considerar\u00e1n, en este orden, son tres: la objeci\u00f3n de la privacidad; la objeci\u00f3n de la pendiente resbaladiza; y la objeci\u00f3n de guerra. Las dos primeras son ob - jeciones que pueden formularse contra la tecnolog\u00eda en cualquier contexto donde se despliegue la tecnolog\u00eda. La objeci\u00f3n final aborda preocupaciones que surgen exclusivamente en circunstan- cias de guerra. Argumentar\u00e9 que la suma de estas objeciones \u2014de entre muchas otras posibles que no considerar\u00e9 en este ensa- yo\u2014 hace que el uso de la tecnolog\u00eda de re - conocimiento facial sea inaceptable. La objeci\u00f3n de la privacidad Acaso la preocupaci\u00f3n m\u00e1s obvia y citada con respecto al reconocimiento facial es que vul- nera la privacidad informativa. Al alimentarse de cantidades ingentes de datos personales (en concreto, im\u00e1genes) extra\u00eddas de sitios de Internet, generalmente sin el consentimiento de los usuarios, el reconocimiento facial entra- \u00f1a una forma de vigilancia masiva que viola la privacidad de dichos usuarios. La privacidad informativa garantiza a las personas controlar el acceso a su informaci\u00f3n, incluidas las im\u00e1- genes personales, excluyendo a otras personas u organizaciones, como el Estado, de dicho ac - ceso si as\u00ed lo desean. La privacidad informativa es valiosa por estar estrechamente relacionada con el valor fundamental de la autonom\u00eda, que puede definirse, en t\u00e9rminos generales, como *Doctorado, U. de Michigan; especializado en Filosof\u00eda Pol\u00edtica, interesado en \u00c9tica Aplicada; Investigador y miembro del SNI 1; Ha realizado estancias post-doctora- les o de investigaci\u00f3n/docencia en el extranjero. Gaceta20 la libertad de pensar y hacer lo que uno elija. Violentar la privacidad informativa es moral- mente objetable porque, desde una perspec - tiva individual, puede interferir con los planes que las personas elaboran para sus vidas. Des- de una perspectiva colectiva, puede socavar la democracia liberal al inhibir el deseo de los ciudadanos de manifestarse o expresarse en contra de las autoridades por temor a las re - presalias, cuya ejecuci\u00f3n se vuelva menos cos- tosa con herramientas como el reconocimien- to facial (Smith y Miller 2022). La objeci\u00f3n de la pendiente resbaladiza Evan Selinger y Brenda Leong (2021) han desarrollado una cr\u00edtica del reconocimiento facial a partir del conocido argumento de la pendiente resbaladiza (slippery slope). La objeci\u00f3n de la pendiente resbaladiza es un argumento en contra de una acci\u00f3n, A, que no es objetable en s\u00ed misma, pero cuya reali- zaci\u00f3n conducir\u00e1 a la realizaci\u00f3n de una ca- dena de acciones que al final conducir\u00e1 a la acci\u00f3n Z, que s\u00ed es objetable. Dicho de otro modo, en un argumento de pendiente res- baladiza, no es permitir una acci\u00f3n inocua o inmediata lo que nos preocupa, sino la posi- bilidad de que permitir esta acci\u00f3n conduz - ca a una serie de acciones indeseable. Ahora bien, el argumento de la pendiente res- baladiza es falaz si no identifica ni los pasos causales que nos llevan de las acciones o esce - narios inocuos e inobjetables a las acciones o escenarios moralmente indeseables ni la pro - babilidad de que se materialicen. En contraste, las versiones razonables del argumento de la pendiente resbaladiza especifican expl\u00edcita- mente los mecanismos que podr\u00edan conducir al deslizamiento de un paso a otro. Algunos de los mecanismos que pueden de-sencadenar la cadena causal que nos lleva de lo inobjetable a lo objetable son, por ejemplo, el de \"reducci\u00f3n de costos\" (adoptar una tecnolog\u00eda para llevar a cabo el prop\u00f3sito A, que es benigno, tendr\u00e1 como resultado que se reduzcan los costos de perseguir el prop\u00f3sito Z, que es maligno), el del \"cambio de actitudes\" (adoptar una tec - nolog\u00eda para llevar a cabo el prop\u00f3sito A, que es benigno, tendr\u00e1 como resultado un cambio de actitudes generalizado, el cual tendr\u00e1 como resultado que se acepte su uso para el prop\u00f3 - sito Z, que es maligno) o el de la \"creaci\u00f3n del impulso pol\u00edtico\" (adoptar una tecnolog\u00eda para llevar a cabo el prop\u00f3sito A, que es benigno, detonar\u00e1 un movimiento pol\u00edtico que llevar\u00e1 inevitablemente a la adopci\u00f3n del prop\u00f3sito Z, que es maligno). En el caso del uso del reconocimiento facial, la preocupaci\u00f3n es que alentar o tolerar su uso para fines permitidos en ciertos con- textos leg\u00edtimos, como identificar a sujetos que han cometido actos criminales, po - dr\u00eda abrir la puerta a objetivos reprobables, como su despliegue para realizar acciones injustificadas de inteligencia en contra de ciudadanos inocentes o su uso por actores no estatales locales o transnacionales cuyos objetivos, aunque no necesariamente injus- tos, son opacos para nosotros. Me centrar\u00e9 en estos dos casos, aunque algunos autores prev\u00e9n peores desenlaces para la tecnolog\u00eda de reconocimiento facial, como su incorpo - raci\u00f3n a sistemas de decisiones automatiza- da, como los que se utilizan en las llamadas armas letales aut\u00f3nomas. \u00bfCu\u00e1les son los mecanismos que podr\u00edan llevarnos por la pendiente resbaladiza en el \"La privacidad informativa garantiza a las personas controlar el acceso a su informaci\u00f3n, incluidas las im\u00e1genes personales, excluyendo a otras personas u organizacio - nes, como el Estado, de dicho acceso si as\u00ed lo desean\".Gaceta21 a fondo caso del reconocimiento facial? Seg\u00fan los detractores de la tecnolog\u00eda, las empresas que promueven el uso de tecnolog\u00eda de reco - nocimiento facial buscan normalizar su uso. Este objetivo es un ejemplo del mecanismo de modificaci\u00f3n de actitudes, descrito an- tes. La normalizaci\u00f3n se alcanza mediante la representaci\u00f3n positiva de la tecnolog\u00eda, al caracterizarla como una herramienta \"diver - tida\" que promueve la eficiencia. Al habituar - se a los entornos divertidos y \"eficientes\" que crea, los ciudadanos se inclinar\u00e1n con mayor facilidad a aceptar su uso en un n\u00famero cada vez mayor de \u00e1mbitos de la vida social. Las c\u00e1- maras de circuito cerrado de televisi\u00f3n, que regularmente operan en conjunto con el re - conocimiento facial, son otro ejemplo de este tipo de habituaci\u00f3n perniciosa: la p\u00e9rdida du- radera de privacidad que conllevan se perci- be como menos problem\u00e1tica si se considera que son efectivas para prevenir el crimen, y con el paso del tiempo los ciudadanos ha- br\u00e1n perdido de vista el dilema entre la priva- cidad y la efectividad contra el crimen. Otro impulsor causal de la pendiente resbala- diza es la probable renuencia de las autorida- des a retirar la tecnolog\u00eda una vez que se ha resuelto la problem\u00e1tica que le dio origen (por ejemplo, un repunte en la criminalidad) y, en cambio, su inclinaci\u00f3n a utilizar la tecnolog\u00eda en un n\u00famero cada vez mayor de actividades, incluyendo algunas ileg\u00edtimas, como vigilar a los ciudadanos sin justificaci\u00f3n adecuada. La renuencia es particularmente preocupante en contextos de baja institucionalidad demo - cr\u00e1tica. En su discusi\u00f3n sobre la recopilaci\u00f3n de metadatos con fines de inteligencia, Mi- chael Skerker (2016) arguye que, en los esta- dos con un Estado de Derecho robusto y altos est\u00e1ndares \u00e9ticos de servicio p\u00fablico, es pro - bable que los riesgos de abuso de metadatos sean menores que los de un ataque terroris- ta o un ataque militar. Lo contrario es cierto cuando faltan estas cualidades instituciona- les. La misma l\u00f3gica se aplica con respecto al reconocimiento facial: que los riesgos asocia- dos con la tecnolog\u00eda se materialicen o no, y la medida en que se materialicen, depende de la presencia o ausencia de estas cualidades institucionales. En muchas naciones donde el reconocimiento facial ha sido utilizado, las ca- pacidades institucionales que podr\u00edan man- tenerla bajo control est\u00e1n ausentes. Podr\u00eda argumentarse, para mitigar esta pre - ocupaci\u00f3n, que las herramientas de recono - cimiento facial pueden implementarse con salvaguardas tecnol\u00f3gicas para eliminar o reducir el potencial de abuso gubernamen- tal. Clearview AI, por ejemplo, puede impo - ner restricciones en el uso de sus servicios y as\u00ed asegurarse de que s\u00f3lo los funcionarios gubernamentales autorizados tengan ac - ceso a ella. Dichas salvaguardas pueden ser relativamente simples, como la llamada au- tenticaci\u00f3n de dos factores, de modo que, al menos, los funcionarios p\u00fablicos de las ra- mas del gobierno que no tienen funciones de seguridad no tengan acceso a la tecnolo - g\u00eda. Adem\u00e1s, dado que servicios de recono - cimiento facial como los de Clearview AI fun- cionan a trav\u00e9s de un servicio en la nube, la compa\u00f1\u00eda conserva la capacidad de revocar el acceso en casos de abuso de la tecnolog\u00eda. Por varias razones, estas soluciones tecnol\u00f3gi- cas a posibles abusos gubernamentales son inadecuadas. Como lo muestra el caso del Gru- po NSO (creador del software esp\u00eda Pegasus), las garant\u00edas corporativas son, en el mejor de los casos, fr\u00e1giles. M\u00e1s importante a\u00fan, confiar en este tipo de garant\u00edas corporativas simple - mente desplaza la preocupaci\u00f3n por las barre - ras contra el abuso del sector p\u00fablico al priva- do. La pregunta ser\u00eda ahora si existen garant\u00edas institucionales para evitar que las corporacio - nes privadas reutilicen o vendan, con fines de lucro, los datos personales extra\u00eddos por la tec - nolog\u00eda. Transferir la responsabilidad de frenar el abuso del sector p\u00fablico al privado podr\u00eda incluso agravar los riesgos asociados con el re - conocimiento facial. Por un lado, la capacidad de la sociedad para regular a los actores corpo - rativos, en particular a las empresas de tecno - log\u00eda, puede ser menor que la capacidad para controlar a los agentes del gobierno, como lo muestra el auge de Google y Facebook (Zuboff 2019, V\u00e9liz 2020). Por otro lado, al dejar que los actores corporativos tomen decisiones sobre lo Gaceta22 que constituye un uso inadecuado de la tec - nolog\u00eda, los ciudadanos terminar\u00edan otorgan- do a los actores corporativos, que carecen de legitimidad pol\u00edtica, la autoridad para tomar decisiones que afectan sus vidas. Las corpora- ciones tecnol\u00f3gicas vendr\u00edan a establecer es- t\u00e1ndares comunes para la regulaci\u00f3n digital, una tarea que deber\u00eda ser un asunto determi- nado por decisiones colectiva. Se crear\u00eda, en otras palabras, un d\u00e9ficit de legitimidad (Benn y Lazar 2022). La objeci\u00f3n de la guerra La objeci\u00f3n al que sea quiz\u00e1s uno de los usos m\u00e1s controvertido del reconocimiento facial se refiere a hechos recientes, donde la tecnolog\u00eda ha sido utilizada, de manera in\u00e9- dita, para identificar los cuerpos de los sol- dados muertos y difundir sus im\u00e1genes en las redes sociales (Espindola s.a.). Esto fue lo que ocurri\u00f3 en las etapas iniciales de la invasi\u00f3n rusa a Ucrania, cuando las autori- dades ucranianas utilizaron los servicios de Clearview AI, cuya base de datos contiene millones de im\u00e1genes extra\u00eddas de distintos sitios de internet, para tratar de revelar la identidad de solados rusos ca\u00eddos en com- bates y diseminar su identidad a trav\u00e9s de redes sociales. Las autoridades ucranianas justificaron la estrategia alegando que contribu\u00eda al de - ber humanitario de devolver los cuerpos de los fallecidos a sus familiares en Rusia. Se - g\u00fan este alegato, entregar los cuerpos de los difuntos a sus familiares les permitir\u00eda a \u00e9stos realizar un luto apropiado, evitando que experimenten lo que Pauline Boss lla- ma \"p\u00e9rdida ambigua\". La p\u00e9rdida ambigua se produce cuando la p\u00e9rdida de un fami- liar o ser querido est\u00e1 rodeada de incerti- dumbre. La p\u00e9rdida ambigua conduce a un luto no resuelto, congela el proceso de due - lo y contribuye al deterioro de la salud men- tal de los dolientes. Estos factores no est\u00e1n presentes, o no en la misma magnitud, en casos que no involucran p\u00e9rdida ambigua. La sintomatolog\u00eda asociada a la p\u00e9rdida ambigua incluye sentimientos de soledad o de distanciamiento de otras personas e incluso de la comunidad y un sentido dis- minuido de la propia identidad. Estos efec - tos socavan las capacidades (capabilities) de las personas en el sentido que Martha Nussbaum da a ese t\u00e9rmino (su capacidad para entablar relaciones sociales significati- vas y enmarcar una concepci\u00f3n de la buena vida), y por lo tanto erosiona sus derechos fundamentales. As\u00ed, en consonancia con es- tas ideas, si la tecnolog\u00eda de reconocimien- to facial pudiese ayudar a las personas a superar la p\u00e9rdida ambigua, acelerando o ayudando a identificar cad\u00e1veres, entonces ser\u00eda fundamental para proteger los dere - chos fundamentales y, por lo tanto, estar\u00eda en principio justificada. La moralidad del uso del reconocimiento fa- cial con el prop\u00f3sito antes mencionado es sumamente cuestionable. Primero, la tecno - log\u00eda puede cometer errores. Tales errores no derivan necesariamente, como es com\u00fan en contextos no b\u00e9licos, de sesgos raciales o \u00e9t - nicos incorporados al reconocimiento facial, con los correspondientes riesgos de generar discriminaci\u00f3n injustificable, sino m\u00e1s bien del hecho de la descomposici\u00f3n post mor - tem , que puede afectar la eficacia del reco - nocimiento facial. Esta es una preocupaci\u00f3n particularmente relevante en el contexto de la guerra, donde los cuerpos pueden estar sujetos no solo a descomposici\u00f3n avanza- da sino tambi\u00e9n a desfiguraci\u00f3n o mutila- ci\u00f3n. Cuando las identificaciones err\u00f3neas post mortem superan un umbral razonable, la gran cantidad de falsos positivos puede socavar las funciones humanitarias que se supone que el reconocimiento f\u00e1cil deber\u00eda facilitar. Por otra parte, el mero hecho de difundir im\u00e1genes de soldados ca\u00eddos, independien- temente de que su identidad haya sido re - velada mediante reconocimiento facial o no, podr\u00eda interpretarse como una falta de res- peto a la dignidad de los muertos, entrando as\u00ed en tensi\u00f3n con las Convenciones de Gi- nebra. Es cierto que las Convenciones s\u00f3lo hacen escasas referencias al tratamiento de los muertos, pero su orientaci\u00f3n es cla-Gaceta23 a fondo ra. Una de sus disposiciones insta a las par - tes beligerantes a \"proteger [a los muertos y heridos] contra . tratos\" cuando \"las consideraciones militares lo permitan\", y otra disposici\u00f3n pide a las partes que res- peten \"los restos de las personas que hayan muerto por motivos relacionados con la ocu- paci\u00f3n o que est\u00e9n detenidas como resulta- do de la ocupaci\u00f3n o las hostilidades\". Una interpretaci\u00f3n amplia de estas disposiciones equiparar\u00eda la difusi\u00f3n de im\u00e1genes de sol- dados muertos con un trato degradante en vista de la expectativa generalizada de que la exhibici\u00f3n p\u00fablica de cad\u00e1veres con fines distintos a los ceremoniales es, con algunas excepciones, indigna. Esta es una posici\u00f3n controvertida porque invoca un derecho p\u00f3stumo contra el trato indigno, que puede rebatirse aduciendo que los muertos no ex - perimentan humillaci\u00f3n, no son afectados por ella y, por lo tanto, no hay justificaci\u00f3n para defender tal derecho. Incluso si ello fuera as\u00ed, sin embargo, los familiares de los difuntos s\u00ed pueden verse humillados y afec - tados por el trato indigno que \u00e9stos reciban, y es en virtud de tales da\u00f1os que puede sus- tentarse el rechazo del reconocimiento fa- cial en este \u00e1mbito. Conclusi\u00f3n En este ensayo he discutido algunas de las razones que ponen en entredicho la mora- lidad del uso del reconocimiento facial. A la luz de esta cr\u00edtica, no es ninguna sorpresa que, en d\u00edas recientes, el Parlamento Euro - peo, una de las principales ramas legislativas de la Uni\u00f3n Europea, haya aprobado un pro - yecto de ley conocido como AI Act, que im- pondr\u00e1 nuevas restricciones a los usos m\u00e1s riesgosos de la inteligencia artificial, dentro de las cuales se incluye la utilizaci\u00f3n de soft - ware de reconocimiento facial. El Parlamen- to Europeo vot\u00f3 a favor de prohibir el uso del reconocimiento facial en tiempo real, aun- que quedan dudas sobre si se deben permi- tir exenciones para la seguridad nacional y otros fines de aplicaci\u00f3n de la ley. Otra dis- posici\u00f3n prohibir\u00eda a empresas como Clear - view AI extraer datos biom\u00e9tricos de las re - des sociales para crear bases de datos. Bibliograf\u00eda -Almeida, Denise, Konstantin Shmarko, and Elizabeth Lomas, \"The Ethics of Facial Recognition Technologies, Sur - veillance, and Accountability in an Age of Artificial Intelligence: A Comparative Analysis of US, EU, and UK Regulatory Frameworks,\" AI and Ethics 2 (August 2022), pp. 377-87. Sarah, \"Digital Dignity in Death: Are the Geneva Conventions Fit for Purpose in the Age of Social Media?,\" Royal United Services Institute, March 29, 2022, rusi.org/explore-our-research/publications/commentary/digital-digni- ty-death-are-geneva-conventions-fit-purpose-age-social-media. -Benn, Claire and Seth Lazar, \"What's Wrong with Influence,\" Canadian Journal of Philosophy 1 (January 2022), pp. 125-48. -Boss, Pauline, Loss: Learning to Live with Unresolved Mass.: Harvard University Press, 1999). -Espindola, Juan, in War Contexts: Mass Surveillance and Atrocity.\" Ethics and International Affairs (volumen no asignado). -Nussbaum, Martha Creating Capabilities: The Human Development The Oxford Handbook of Digital Ethics (Oxford: Oxford University Press, Binary Bullets: Ethics of Cyberwarfare (Oxford: Press, 2016). -Smith, Marcus and Seumas Miller, \"The Ethical Application of Biometric Facial Recognition Technology,\" Al & Society 37 (March 2022), pp.167-75. -V\u00e9liz, Carissa. Privacy Is Power: Why and How You Should Take Back Control of Your Data (London: Random House, 2020). -Zuboff, Shoshana, The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power (New York: PublicAffairs, 2019). Gaceta24 Implicaciones \u00e9ticas de la implementaci\u00f3n de la inteligencia artificial en la pr\u00e1ctica m\u00e9dica Luis Mu\u00f1oz Fern\u00e1ndez* Introducci\u00f3n En el libro Vida 3.0. Qu\u00e9 significa ser huma- no en la era de la inteligencia artificial, su autor Max Tegmark seleccion\u00f3 muy bien el t\u00edtulo del primer cap\u00edtulo: \"Bienvenidos a la conversaci\u00f3n m\u00e1s importante de nuestro tiempo\" (Tegmark, 2018). La inteligencia artificial (IA), sus expectati- vas, beneficios y riesgos, es un tema cotidia- no en los medios de comunicaci\u00f3n desde finales de 2022, cuando fue lanzado Chat - GPT, un sistema de respuestas autom\u00e1ticas (chatbot) basado en la inteligencia artifi- cial cuya capacidad para elaborar textos ha asombrado a sus usuarios y ha generado tambi\u00e9n numerosas controversias (https:// es.wikipedia.org/wiki/ChatGPT). As\u00ed como no existe una definici\u00f3n universal de la inteligencia humana, tampoco la hay para la IA. Margaret A. Boden, profesora in- vestigadora de Ciencias Cognitivas de la Universidad de Sussex, Inglaterra, se\u00f1ala lo siguiente: \"La inteligencia no es una dimensi\u00f3n \u00fanica, sino un espacio profusamente estructura- do de capacidades diversas para procesar la informaci\u00f3n. Del mismo modo, la IA utili- za muchas t\u00e9cnicas diferentes para resolver una gran variedad de tareas\" (Boden, 2017). El Consejo de Europa ha preparado un glo - sario sobre la IA, a la que define como \"un conjunto de ciencias, teor\u00edas y t\u00e9cnicas cuyo fin es reproducir mediante una m\u00e1quina las capacidades cognitivas de un ser humano\" (https://www.coe.int/en/web/artificial-intelli- gence/glossary). En un tema como este, que crece y cambia con tanta rapidez, es dif\u00edcil asimilar toda su extensi\u00f3n y reflexionar detenidamente so - bre sus implicaciones \u00e9ticas. Una primera aproximaci\u00f3n \u00fatil es la Recomendaci\u00f3n so - bre la \u00e9tica de la inteligencia artificial de la Unesco, adoptada por este organismo el 23 de noviembre de 2021, en el que reconoce que \"Considerando las tecnolog\u00edas de la IA pueden ser de gran utilidad para la huma- nidad y que todos los pa\u00edses pueden bene - ficiarse de ellas, pero que tambi\u00e9n suscitan preocupaciones \u00e9ticas fundamentales, por ejemplo, en relaci\u00f3n con los sesgos que pue - den incorporar y exacerbar, lo que puede lle - gar a provocar discriminaci\u00f3n, desigualdad, brechas digitales y exclusi\u00f3n y suponer una amenaza para la diversidad cultural, social y biol\u00f3gica, as\u00ed como generar divisiones socia- les o econ\u00f3micas; la necesidad de transpa- rencia e inteligibilidad del funcionamiento de los algoritmos y los datos con los que han sido entrenados; y su posible impacto en, en- tre otros, la dignidad humana, los derechos humanos y las libertades fundamentales, la igualdad de g\u00e9nero, la democracia, los pro - cesos sociales, econ\u00f3micos, pol\u00edticos y cultu- rales, las pr\u00e1cticas cient\u00edficas y de ingenier\u00eda, el bienestar animal y el medio ambiente y los ecosistemas\" (Unesco, 2021). Asimismo, el documento de la Unesco des- cribe las repercusiones \u00e9ticas en los \u00e1mbitos de aplicaci\u00f3n de la IA que le competen y que son el de la educaci\u00f3n, la identidad y diversi- dad culturales, la comunicaci\u00f3n y la informa- ci\u00f3n y tambi\u00e9n la ciencia. Sobre esta \u00faltima dice lo siguiente: \"La ciencia, en el sentido m\u00e1s amplio, que abarca todos los \u00e1mbitos acad\u00e9micos desde las ciencias exactas y naturales y las ciencias m\u00e9dicas hasta las ciencias sociales y humanas, ya que las tecnolog\u00edas de la IA aportan nuevas capacidades y enfoques de investigaci\u00f3n, in- fluyen en nuestra concepci\u00f3n de la compren- si\u00f3n y la explicaci\u00f3n cient\u00edficas y crean una nueva base para la adopci\u00f3n de decisiones\" (Unesco, 2021). Este \u00faltimo punto relativo a las decisiones diagn\u00f3sticas y terap\u00e9uticas es es- pecialmente relevante en la pr\u00e1ctica m\u00e9dica. Aplicaciones de la IA en la pr\u00e1ctica m\u00e9dica En marzo de 2023, la prestigiosa revista m\u00e9 - dica The New England Journal of Medicine *M\u00e9dico cirujano; Especialista en Anatom\u00eda Patol\u00f3gi- ca; M\u00e1ster Derecho; Miembro del Colegio de Bio\u00e9tica A.C.; Miembro del Consejo Consultivo de la CONBIO\u00c9TICA.Gaceta25 a fondo public\u00f3 el primero de una serie de editoria- les y art\u00edculos bajo el t\u00edtulo Artificial Intelli- gence in Medicine (Inteligencia artificial en Medicina), en el que se lee lo siguiente: \"Recientemente, la inteligencia artificial (IA) ha adquirido relevancia p\u00fablica con el lanzamien- to de modelos de aprendizaje profundo (deep- learning models) que generan todo tipo de contenidos con una intervenci\u00f3n humana m\u00ed- nima, desde arte hasta ensayos de fin de curso. Este desarrollo ha revitalizado del papel actual y potencial de la IA en todos los aspectos de la vida. Sin embargo, de todos los campos en los que puede aplicarse la IA, la medicina destaca tanto por su gran potencial como por los retos que implica\" (Beam, A.L. y cols., 2023). De ah\u00ed que la revista decidiese tratar este tema, primero con la serie de textos a los que nos hemos referido, pero, adem\u00e1s, publican- do a partir del 2024 una revista nueva, NEJM AI (ai.nejm.org). Esto nos da una idea de la importancia que una revista como esta le da al papel de la IA en la Medicina. En este editorial se se\u00f1ala que en la actuali- dad no hay pr\u00e1cticamente ninguna \u00e1rea de la Medicina y del cuidado de la salud que no haya sido tocado por la IA: \"Por ejemplo, las aplicaciones dirigidas por IA para el dictado y la captura de notas m\u00e9 - dicas; muchas de estas aplicaciones est\u00e1n intentando sintetizar las entrevistas a los pa- cientes y los resultados de laboratorio para escribir directamente las notas sin que inter - venga el m\u00e9dico cl\u00ednico. [...] Ya hemos visto muchos art\u00edculos que informan sobre el uso de la IA en la interpretaci\u00f3n de im\u00e1genes radiogr\u00e1ficas, histopatol\u00f3gicas y oftalmol\u00f3 - gicas (fondo de ojo). Se ha incrementado el uso de instrumentos con IA que analizan e interpretan grandes bases de datos de in- vestigaci\u00f3n que contienen informaci\u00f3n que va desde los datos de laboratorio hasta los datos cl\u00ednicos\" (Beam, A.L. y cols., 2023). A partir de este nuevo contexto de la pr\u00e1c - tica m\u00e9dica, el editorial no oculta su preo -cupaci\u00f3n y se\u00f1ala que todos estos m\u00e9todos basados en la IA no son necesariamente la panacea. Expone que son fr\u00e1giles, que su campo de acci\u00f3n es reducido y que pueden haber sido construidos con sesgos prove - nientes de sus desarrolladores, de modo que pueden llegar a afectar de manera negati- va a grupos marginados. Sobre este \u00faltimo punto, uno de los ejemplos fuera de la me - dicina m\u00e1s citados es el algoritmo COMPAS, un sistema policial basado en IA que predijo err\u00f3neamente que la mayor\u00eda de los delin- cuentes que iban a reincidir eran primor - dialmente personas de piel negra (Coecke - lbergh, 2021). Implicaciones \u00e9ticas de la IA La Fundaci\u00f3n V\u00edctor Gr\u00edfols i Lucas, un refe - rente de la bio\u00e9tica espa\u00f1ola, publica peri\u00f3 - dicamente cuadernos sobre diversos temas relacionados con esta disciplina. En 2023 public\u00f3 su cuaderno n\u00famero 63, titulado In- teligencia artificial en Salud. Retos \u00e9ticos y cient\u00edficos, en el que Pere Ibern, miembro del Patronato de la Fundaci\u00f3n e investigador del Centro de Investigaci\u00f3n en Econom\u00eda y Salud de la Universidad Pompeu Fabra de Barcelona, presenta en el cuaderno citado la respuesta que dio el famoso algoritmo de inteligencia artificial ChatGPT-4 (versi\u00f3n del 23 de marzo de 2023) cuando se le pregun- t\u00f3 sobre la propia IA que, seg\u00fan Bill Gates, es \"la tecnolog\u00eda m\u00e1s revolucionaria desde hace d\u00e9cadas\" (Ibern. Fundaci\u00f3n V\u00edctor Gr\u00ed- fols i Lucas, 2023). La respuesta de Chat GPT-4 es coherente con lo que se ha publicado sobre este tema, lo que es completamente l\u00f3gico, pues el al- goritmo ha sido entrenado en base a la am- plia informaci\u00f3n disponible, pero, adem\u00e1s, se\u00f1ala tambi\u00e9n los problemas bio\u00e9ticos de la IA que deben abordarse y que a continua- ci\u00f3n se transcriben: 1. Privacidad y seguridad de los datos: la IA implica la recopilaci\u00f3n, el almace - namiento y el uso de datos masivos. Es importante garantizar la privacidad y la seguridad de estos datos para evitar Gaceta26 el robo de identidad, el ciberataque y la vulneraci\u00f3n de la privacidad. 2. Discriminaci\u00f3n: la IA puede ser progra- mada para tomar decisiones que pue - den ser discriminatorias por razones de g\u00e9nero, raza, edad, orientaci\u00f3n sexual, etc. Es importante asegurar que la IA sea imparcial y que no reproduzca pre - juicios existentes en la sociedad. 3. Transparencia y explicabilidad: la IA puede tomar decisiones sin dejar claro c\u00f3mo se ha llegado a ellas. Esto puede provocar que sea dif\u00edcil comprender por qu\u00e9 se toman determinadas decisiones y dificultar la responsabilidad en caso de error. 4. Responsabilidad: la IA puede tomar decisiones que tienen consecuencias importantes para las personas y la so - ciedad en general. Es importante esta- blecer qui\u00e9n es responsable de las deci- siones que toma la IA y c\u00f3mo se puede responsabilizar a los desarrolladores o a los propietarios de esta tecnolog\u00eda. 5. Autonom\u00eda: la IA puede llegar a ser aut\u00f3noma en la toma de decisiones, lo que puede ser un problema cuando las decisiones que toma afectan a la vida de las personas. En este sentido, es importante establecer l\u00edmites a la IA y asegurar que siempre se d\u00e9 una super - visi\u00f3n humana. 6. \u00c9tica de los veh\u00edculos aut\u00f3nomos: la IA est\u00e1 siendo utilizada para desarrollar veh\u00edculos aut\u00f3nomos. Es importante garantizar que estos veh\u00edculos se comporten de manera \u00e9tica en situaciones l\u00edmite y que no pongan en peligro la vida de las personas. A continuaci\u00f3n, ChatGPT-4 enlista los criterios que se pueden tener en cuenta para que una IA sea explicable, es decir, que siga el principio de explicabilidad: asegurar la transparencia y responsabilidad en las decisiones tomadas por las Tecnolog\u00edas de la Informaci\u00f3n y la Co - municaci\u00f3n que afectan a las personas.1. Transparencia: la IA debe ser transpa- rente en su funcionamiento, demanera que se pueda entender c\u00f3mo se toman las decisiones. Estoincluye la capaci- dad de mostrar los datos utilizados para entrenar el modelo, as\u00ed como los algoritmos y las reglas que utiliza para tomar decisiones. 2. Interpretabilidad: la IA debe ser inter - pretada por las personas, de manera que se pueda comprender lo que est\u00e1 haciendo y por qu\u00e9 est\u00e1 tomando las decisiones que toma. Esto implica una interacci\u00f3n humana y la capacidad de proporcionar explicaciones claras y comprensibles para los usuarios. 3. Consistencia: la IA debe ser consistente en su comportamiento, de forma que pueda ser confiable y previsible en su conducta. Esto implica la capacidad de proporcionar respuestas coherentes a situaciones similares. 4. Robustez: la IA debe ser robusta, es de - cir, debe ser capaz de manejar situa- ciones inesperadas o excepcionales sin caer en errores graves. Esto incluye la capacidad de gestionar datos no pre - vistos o situaciones no programadas. 5. Accesibilidad: la IA debe ser accesible para todos los usuarios, independiente - mente de su nivel de conocimiento tec - nol\u00f3gico. Esto implica la capacidad de proporcionar una interfaz de usuario clara e intuitiva, as\u00ed como la capacidad de dar apoyo en diferentes idiomas y formatos. En resumen, ChatGPT-4 se\u00f1ala que para conseguir que una IA sea explicable, es im- portante que sea transparente, interpreta- tiva, consistente, robusta y accesible para todos. Esto ayudar\u00e1 a garantizar que la IA sea \u00e9tica y responsable en su funciona- miento. El principio de explicabilidad al que hace alu- si\u00f3n se relaciona con otros prinicipios bio\u00e9 -Gaceta27 a fondo ticos como el respeto a la privacidad, la se - guridad y la libertad de las personas (Ibern. Fundaci\u00f3n V\u00edctor Gr\u00edfols i Lucas, 2023). No est\u00e1 de m\u00e1s volver a decir que tanto la lis- ta de los problemas bio\u00e9ticos de la IA, como los criterios para que la IA sea explicable fue - ron elaborados por ChatGTP-4, no por un ser humano. Eso da una idea del alcance y po - tencial de estas tecnolog\u00edas. Alicia de Manuel, investigadora del Observato - rio de \u00c9tica en Inteligencia Artificial de Cata- lunya, es una de las coautoras del Cuaderno de la Fundaci\u00f3n V\u00edctor Gr\u00edfols i Lucas al que esta- mos haciendo referencia y ha escrito un cap\u00ed- tulo el que describe los principios \u00e9ticos de la IA a trav\u00e9s del concepto de la IA confiable, con siete puntos clave para que los sistemas de IA puedan ser considerados confiables: 1. Agencia humana y supervisi\u00f3n: los sis- temas deben empoderar a los seres humanos, as\u00ed como garantizar los me - canismos de supervisi\u00f3n adecuados. 2. Robustez t\u00e9cnica y seguridad: los siste - mas deben ser seguros, precisosy fia- bles y asegurar planes alternativos en caso de error para minimizar y prevenir los da\u00f1os no intencionales. 3. Privacidad y gobernanza de datos: adem\u00e1s de garantizar la privacidad y la protecci\u00f3n de datos, los sistemas de IA deben tener en cuenta la calidad e integridad de los datos asegurando un acceso legitimado a ellos. 4. Transparencia: los modelos de nego - cio de datos y sistemas de IA deben ser transparentes. 5. Diversidad, no discriminaci\u00f3n y equi- dad: en los sistemas de IA deben evitar - se los prejuicios y sesgos injustos. 6. Bienestar social y medioambiental: los sistemas de IA tienen que ser sosteni- bles y respetuosos con el medioambien-te, ya que deben poder beneficiar a los seres vivos y las generaciones futuras. 7. Rendici\u00f3n de cuentas: deben estable - cerse mecanismos que garantice la auditabilidad y la rendici\u00f3n de cuentas tanto de los sistemas de IAcomo de sus resultados (de Manuel. Fundaci\u00f3n V\u00edc - tor Gr\u00edfols i Lucas, 2023). Implicaciones \u00e9ticas de la IA en la Medici- na y las Ciencias de la Salud La editorial de The New England Journal of Medicine antas citada se\u00f1ala que la pericia en el campo de la IA y el aprendizaje de m\u00e1- quinas (machine learning) est\u00e1n vinculados estrechamente a las aplicaciones comer - ciales, que se trata de una tecnolog\u00eda cam- biante y que, en muchos casos, la producen compa\u00f1\u00edas e investigadores con intereses fi- nancieros en sus productos. Dada esta situa- ci\u00f3n, las caracter\u00edsticas operativas de estos modelos de IA est\u00e1n solamente en manos de sus desarrolladores, impidiendo el acceso a esta informaci\u00f3n a muchos otros interesa- dos (Beam, A.L. y cols., 2023). Todo ello hace pensar que, pese al gran po - tencial de estas herramientas en la pr\u00e1ctica m\u00e9dica y, en general, en todas las ciencias de la salud, si deseamos que presten un verda- dero servicio todos los seres humanos que lo requieran, independientemente de su raza, nivel socioecon\u00f3mico y caracter\u00edsticas socio - culturales, es indispensable que su desarro - llo se lleve a cabo con apego a normas \u00e9ticas y bajo un marco regulatorio internacional vinculante, tal como lo se\u00f1ala el pronuncia- miento de la Comisi\u00f3n Nacional de Bio\u00e9tica publicado en 13 de junio de 2023 (Comisi\u00f3n Nacional de Bio\u00e9tica, 2023). En este mismo documento, la Comisi\u00f3n Na- cional de Bio\u00e9tica define las pautas nece - sarias para fortalecer el marco regulatorio a nivel federal: A fin de constituirse como un quehacer con responsabilidad social, el desarrollo de tecnolog\u00edas de IA en salud evitar\u00e1 el Gaceta28 aumento en las brechas de inequidad social y econ\u00f3mica entre poblaciones, adem\u00e1s de no interferir en procesos de participaci\u00f3n democr\u00e1tica. En el desarrollo de tecnolog\u00edas de IA en salud constituye un imperativo bio\u00e9ti- co la protecci\u00f3n de los derechos de pro - piedad, integridad y privacidad de la informaci\u00f3n personal, especialmente cuando se trate de informaci\u00f3n gen\u00f3 - mica. El uso de la IA no diluye la responsa- bilidad de los profesionales de salud, quienes son responsables en \u00faltima instancia por operaci\u00f3n, seguimiento y tecnovigilancia de las aplicaciones de IA. La relaci\u00f3n m\u00e9dico-paciente es una entre dos personas humanas; en este sentido, el uso de la IA solamente debe - r\u00eda constituir un mecanismo de media- ci\u00f3n, pero que no implique obst\u00e1culo alguno en la relaci\u00f3n entre las personas usuarias y el equipo de salud. Considerando que afecta a un gran n\u00famero de personas, se requiere 1) ge- nerar condiciones para un di\u00e1logo ho - rizontal entre los desarrolladores de algoritmos, tomadores de decisiones, instancias de la sociedad civil con re - presentaci\u00f3n de todos los sectores de la sociedad, especialmente las poblacio - nes en condiciones de vulnerabilidad, considerando estrategias y progra- mas de capacitaci\u00f3n y divulgaci\u00f3n, a fin de generar entendimiento com\u00fan sobre la amplia gama de riesgos, im- pactos socioecon\u00f3micos y oportunida- des inherentes al dise\u00f1o, desarrollo e implementaci\u00f3n de tecnol og\u00edas de IA en el cuidado de la salud ; 2) establecer medidas adicionales para asegurar el acceso equitativo a los beneficios de las tecnolog\u00edas de IA; 3) promover es- t\u00e1ndares internacionales de seguridad, efica cia y eficiencia en el desarrollo de aplicaciones de IA -como requerir\u00eda cualquier dispositivo m\u00e9dico-, como tambi\u00e9n 4) asegurar la participaci\u00f3n de profesionales de la salud en el desarro - llo de aplicaciones de IA en salud. Ante la posibilidad de da\u00f1o a la inte - gridad f\u00edsica, social y moral de las per - sonas, el desarrollo de tecnolog\u00edas de IA requiere a) incluir preceptos \u00e9ticos y est\u00e1ndares de derechos humanos -a la manera de una gram\u00e1tica moral artifi- cial- directamente en la configuraci\u00f3n de los algoritmos de procesamiento, lo cual considerar\u00e1 b) la participaci\u00f3n de los comit\u00e9s de \u00e9tica en investigaci\u00f3n (CEI), adem\u00e1s de c) un mecanismo per - manente de monitoreo a lo largo de su implementaci\u00f3n. Considerando los casos en los que se deriven consecuencias negativas de la aplicaci\u00f3n de la IA, debe haber una ca- dena de responsabilidad clara. En el uso de aplicaciones de IA en salud se contar\u00e1 con la supervisi\u00f3n de un pro - fesional sanitario certificado, quien ser\u00e1 responsable por su adecuado funciona- miento. En cuanto al marco normativo, se re - quiere de una revisi\u00f3n permanente a fin de mantener actualizadas las disposi- ciones relativas a la responsabilidad de los desarrolladores en el dise\u00f1o, imple - mentaci\u00f3n y mantenimiento de los sis- temas de IA en salud. Espec\u00edficamente en los procesos de machine learning, es insoslayable es- tablecer un mecanismo de curadur\u00eda de los datos sometidos a fin de asegurar su calidad. En el proceso de desarrollo de aplicacio - nes de IA es necesario evitar en la me - dida de lo posible el uso de algoritmos de caja negra (black box), o bien establecer pautas para hacer m\u00e1s inteligible su procesamiento. A fin de evitar la explotaci\u00f3n de comu- nidades desprotegidas, se debe promo -Gaceta29 escenario nacional ver el acceso equitativo a las tecnolog\u00edas para desarrollo de la IA, lo cual incluye las bases de datos que se empleen para entrenar los algoritmos de las diversas aplicaciones. Se promover\u00e1 la alfabetizaci\u00f3n en IA en- tre los planes de estudios de las institu- ciones de educaci\u00f3n superior, con \u00e9n- fasis en los principios bio\u00e9ticos de la IA y los usos responsables de las aplicacio - nes de IA. Considerando el enorme gasto energ\u00e9 - tico que implican ciertas tecnolog\u00edas de IA, los desarrolladores buscar\u00e1n reducir la huella ecol\u00f3gica de las mismas (Comi- si\u00f3n Nacional de Bio\u00e9tica, 2023). Comentarios finales Para el doctor Abraham Verghese, m\u00e9dico y escritor, \"las dos culturas -la computado - ra y el m\u00e9dico- debe trabajar juntas. [...] Un modelo de la caja negra puede ayudar a que los m\u00e9dicos tomen buenas decisiones, pero s\u00f3lo si mantienen a la inteligencia huma- na en el circuito, incluyendo los contextos social, cl\u00ednico y personal de cada caso. Ade - m\u00e1s, s\u00f3lo el cerebro humano con adiestra- miento cl\u00ednico puede generar nuevas ideas, vislumbrar nuevas aplicaciones y uso de la IA y el aprendizaje de m\u00e1quinas y conectar estas tecnolog\u00edas con las humanidades y las ciencias sociales en formas que las actuales computadoras no pueden hacer\" (por lo me - nos no todav\u00eda). Y agrega: \"En el cuidado del enfermo, hay una funci\u00f3n clave que los m\u00e9dicos llevan a cabo, a la Tinsley Harrison llama 'la funci\u00f3n sacerdotal del m\u00e9dico'. La inteligencia hu- mana trabajando con la inteligencia artificial -un m\u00e9dico emp\u00e1tico y bien informado, ar - mado con buenas herramientas predictivas y sin la carga del trabajo burocr\u00e1tico- pue - den hacer que los m\u00e9dicos cumplan la m\u00e1xi- ma de Peabody que dec\u00eda que el secreto del cuidado del paciente es hacerse cargo de \u00e9l\". Referencias - Beam, A.L., Drazen J. M., Kohane, I.S., y cols. (2023). Artificial Intelligence in Medicine. N Engl J Med, 38 (13), 1220-1221. - Boden, M. A. (2017). Inteligencia artificial. Turner Noema. - Coeckelbergh, M. (2021). \u00c9tica de la inteligencia artificial. C\u00e1tedra. - Comisi\u00f3n Nacional de Bio\u00e9tica. (2023). Bio\u00e9tica de la inteligencia artificial en salud. Disponible en: https://www. gob.mx/cms/uploads/attachment/file/832082/Bio_tica_de_la_inteligencia_artificial_Junio2023.pdf - Consejo de Europa. Glosario. Disponible en: https://www.coe.int/en/web/artificial-intelligence/glossary. Consultado el 18 de junio de 2023. - de Manuel, A. (2023). Inteligencia artificial \u00e9tica y su aplicaci\u00f3n en el \u00e1mbito de la salud sistemas aplicados a la COVID-19 en Inteligencia artificial en salud. Retos \u00e9ticos y cient\u00edficos. Cuadernos de la Fundaci\u00f3n V\u00edctor Gr\u00edfols i Lucas, 63, 46-59. - Ibern, P. (2023). Presentaci\u00f3n en Inteligencia artificial en salud. Retos \u00e9ticos y cient\u00edficos. Cuadernos de la Funda- ci\u00f3n V\u00edctor Gr\u00edfols i Lucas, 63, 8-11. - Tegmark, M. (2018). Vida 3.0. Qu\u00e9 significa ser humano en la era de la inteligencia artificial. Taurus. - Unesco. (2021). Recomendaci\u00f3n sobre la \u00e9tica de la inteligencia artificial. Disponible en: https://unesdoc.unesco. org/ark:/48223/pf0000381137_spa. - Verghese computer needs is a physician. Humanism and Artificial Intelligence. JAMA, 319 (1), 19-20. - Wikipedia. ChatGPT. Disponible en: https://es.wikipedia.org/wiki/ChatGPT . Consultado el 18 de junio de 2023.Gaceta30 Implicaciones bio\u00e9ticas en la IA Luis \u00c1ngel Lara Pereda* Introducci\u00f3n Nuestra vida cotidiana est\u00e1 permeada por diferentes aplicaciones que utilizan inteligen- cia artificial. Desde hace algunos a\u00f1os, en la cultura popular la Inteligencia Artificial ha adquirido una imagen que no le es muy fa- vorable. Generalmente se le asocia con even- tos de corte apocal\u00edptico, al mero estilo de una rebeli\u00f3n de las m\u00e1quinas versus los seres humanos. Las m\u00e1s recientes noticias en tor - no a la Inteligencia Artificial parecen reavivar ese viejo temor frente a ella. Sin embargo, si atendemos a la literatura cient\u00edfica disponi- ble, parece que estamos muy lejos de esos escenarios catastrofistas que hemos visto en las series y pel\u00edculas. No obstante, esto no im- plica que la IA est\u00e9 exenta de algunos riesgos. En este sentido, el objetivo de esta reflexi\u00f3n es ponderar los riesgos efectivos, o reales, que implica la IA desde una perspectiva bio\u00e9tica m\u00e1s all\u00e1 de las visiones apocal\u00edpticas que ya permean en el imaginario colectivo. Inteligencia Artificial: entre el sue\u00f1o y la realidad M\u00e1quinas que se revelan cuyo pensamiento es superior al de los seres humanos, es la imagen de la IA que permea el imaginario colectivo. El temor a ser esclavizados por los robots o ser sustituidos por ellos en todas las tareas que hasta hoy realizamos los seres humanos han sido alimentados por la literatura y el cine de ciencia ficci\u00f3n. En la actualidad no hay nada m\u00e1s alejado de la realidad que esa imagen. De - finir la IA es un ejercicio complicado, ya que ni siquiera los especialistas en el \u00e1rea han llegado a un consenso sobre lo que se debe entender por ella. De acuerdo con la Oficina Ejecutiva de la Presidencia de los Estados Unidos (2016), no hay una definici\u00f3n un\u00edvoca de lo que es la IA. No obstante, la variedad de definiciones exis- tentes tiene puntos en com\u00fan, los cuales nos permiten ofrecer una definici\u00f3n operativa en la cual enmarcar el an\u00e1lisis bio\u00e9tico en torno a esta tecnociencia. Las concepciones m\u00e1s aceptadas, seg\u00fan el texto de la Oficina Ejecu- tiva, se\u00f1alan que la IA es un sistema capaz de resolver racionalmente un problema comple - jo, o alcanzar una determinada meta tal como lo har\u00eda un ser humano. (p. 6)De esta manera, estamos en posibilidad de afirmar que la IA, a trav\u00e9s de la programa- ci\u00f3n de los algoritmos, constituye una inte - ligencia alterna a la del ser humano. Como tal, su meta es resolver problemas o llevar a cabo tareas que requieren el procesamiento de informaci\u00f3n. En conversaci\u00f3n con una de las IA m\u00e1s recientes, Chat GPT, obtenemos que la IA es \"la ciencia y la ingenier\u00eda de hacer m\u00e1quinas inteligentes, especialmente pro - gramas inform\u00e1ticos. En t\u00e9rminos simples, se refiere a sistemas o m\u00e1quinas que imitan la inteligencia humana para realizar tareas y pueden mejorar iterativamente a partir de la informaci\u00f3n que recopilan\" (Open AI, 2023). Uno de los puntos problem\u00e1ticos para defi- nir a ciencia cierta lo que es la IA es el con- cepto de inteligencia. El nombre mismo de la tecnolog\u00eda parece indicar que es, o una extensi\u00f3n o algo contrapuesto a algo que se llamar\u00eda inteligencia natural. \u00bfQu\u00e9 entende - mos entonces por inteligencia? Si partimos de la definici\u00f3n ofrecida por la Oficina Eje - cutiva Presidencia, o por la misma aplicaci\u00f3n de IA, parece que la inteligencia se caracte - riza por ser la capacidad de resolver proble - mas, procesar datos o crear estrategias para obtener ciertos fines y prever determinadas consecuencias. Si este es el caso, como se - \u00f1ala Ram\u00f3n L\u00f3pez (2017) el ser humano no es el \u00fanico ser vivo que posee inteligencia, evidentemente hay otros seres sintientes, como los animales de compa\u00f1\u00eda, que pue - den clasificar como seres inteligentes. En este sentido, la IA estar\u00eda partiendo de una especie de imitaci\u00f3n de una inteligen- cia org\u00e1nica. De esta forma, la m\u00edmesis de ciertas capacidades de los seres vivos, como la visi\u00f3n, el razonamiento, el lenguaje y el aprendizaje ser\u00edan parte de los componen- tes esenciales de la IA, aunado al asunto de la autoconsciencia, el cual se supone el cul- men de la inteligencia y el objetivo principal de este desarrollo tecnocient\u00edfico. *Candidato a doctor en Filosof\u00eda de la Ciencia, UNAM; Grado de maestro con tesis sobre implicaciones bio\u00e9 - ticas de la biolog\u00eda sint\u00e9tica; L\u00edneas de investigaci\u00f3n: Bio\u00e9tica, \u00c9tica y Filosof\u00eda de la Tecnolog\u00eda; Profesor. Gaceta31 a fondo Si bien, la IA es algo que ha estado en boga recientemente gracias a las plataformas que hacen uso de esta tecnolog\u00eda para crear textos o im\u00e1genes, no es una tecnolog\u00eda nueva. Su surgimiento puede datarse de mediados de la d\u00e9cada del siglo pasado. En principio, los cien- t\u00edficos encargados de crear y programar los algoritmos utilizados en las primeras varian- tes de la IA, cre\u00edan que no ser\u00eda tan complejo tener s\u00faper m\u00e1quinas que pudieran superar, o al menos igualar, la inteligencia del ser hu- mano. No obstante, con el paso del tiempo, el desconocimiento de c\u00f3mo funciona de facto el cerebro humano y otras dificultades y pro - blemas filos\u00f3ficos de fondo han mostrado que el desarrollo de una IA similar o superior a la del ser humano es algo sumamente com- plejo. En esta l\u00ednea argumentativa, Margaret Boden afirma que uno de los grandes apor - tes del desarrollo de la IA radica en que \"nos ha ense\u00f1ado que la mente humana es enor - memente m\u00e1s rica y m\u00e1s sutil de lo que los psic\u00f3logos se imaginaban en un principio. De hecho, esta es la lecci\u00f3n m\u00e1s importante que hay que aprender de la IA\". (2022, p. 48). Durante su desarrollo la IA se ha diversifica- do. Existen dos grandes tipos de inteligencia artificial, los cuales son aplicados en diferen- tes aspectos de nuestra realidad. Se trata de las llamadas Inteligencia Artificial D\u00e9bil (IAD) y de la Inteligencia Artificial Fuerte (IAF). La IAD es aquella que se encarga de realizar cier - tas tareas espec\u00edficas que realizamos los seres humanos, es decir, son una imitaci\u00f3n de una mente humana, por ello, pueden jugar ajedrez, buscar informaci\u00f3n, crear o analizar im\u00e1ge -nes y procesar enormes cantidades de infor - maci\u00f3n. Si bien, indudablemente lo hacen de manera m\u00e1s eficaz y eficiente que varios seres humanos, no pueden llevar a cabo una tarea distinta para la que fueron programadas, es decir, mientras que una persona puede jugar ajedrez y a su vez ejecutar una receta de coci- na, una IA, como Deep Blue, s\u00f3lo puede derro - tar a Kasp\u00e1rov, pero es incapaz de realizar una receta de cocina adem\u00e1s de derrotarlo. La IAD es la m\u00e1s extendida hoy en d\u00eda, y es utilizada en diferentes sectores y aspectos de nuestra vida cotidiana, como en las aplicaciones de redes sociales que utilizamos diariamente, o los de - nominados asistentes personales. Por su lado, la IAF es el sue\u00f1o de los cien- t\u00edficos. Este tipo de inteligencia ser\u00eda capaz de llevar a cabo varias tareas de una manera similar o superior a lo que lo har\u00eda un ser hu- mano. Seg\u00fan Ram\u00f3n L\u00f3pez (2022) una IAF no ser\u00eda la imitaci\u00f3n de una mente, sino que por ella misma ser\u00eda una mente. En este sen- tido, la IAF tendr\u00eda no s\u00f3lo la capacidad de mejora y aprendizaje, sino que tambi\u00e9n ser\u00eda capaz de desarrollar autoconsciencia. Este tipo de inteligencia artificial es el que vemos representado en pel\u00edculas como Terminator o ExMachina o en series como Black Mirror. Si bien, este tipo de IA es la que ha desperta- do el temor de la poblaci\u00f3n debido a su ca- pacidad de autoconsciencia, de acuerdo con la Oficina Ejecutiva de la Presidencia (2016), hoy en d\u00eda no hay bases cient\u00edficas s\u00f3lidas que nos permitan afirmar que este tipo de IA est\u00e1 pr\u00f3xima a ser desarrollada, al menos durante las siguientes d\u00e9cadas. (p.7) Cuadro comparativo sobre las diferencias de las IA'sGaceta32 El hecho de que la llamada IA fuerte no exis- ta a\u00fan tiene sus ra\u00edces en el hecho de que no tenemos del todo la comprensi\u00f3n de eso que llamamos conocimiento. De todo lo que conocemos, existen cosas que no sabemos c\u00f3mo las sabemos, por ejemplo, el manejo de una bicicleta y las maniobras que se de - ben hacer para mantenerse en equilibrio, es decir, no hay un manual con reglas escritas que nos diga c\u00f3mo mantener el equilibrio mientras pedaleamos, simplemente apren- demos a andar en bici andando en bici. De acuerdo con el f\u00edsico y fil\u00f3sofo Michael Po - lanyi (1983) sabemos m\u00e1s de lo que pode - mos decir. Esto implica que todo el cono - cimiento que tenemos es imposible de ser transmitido o codificado en alg\u00fan medio para ser transferido a una m\u00e1quina. Como consecuencia de ello, la IAF pensada como una mente artificial, capaz de tomar decisio - nes, aprender, reflexionar y dem\u00e1s acciones propias del ser humano no ha sido posible de ser elaborada. La IA existente parte de la programaci\u00f3n del conocimiento expl\u00edcito, es decir, de aquellos saberes que s\u00ed podemos transmitir y codificar en manuales o disposi- tivos electr\u00f3nicos. De lo que s\u00ed debemos preocuparnos: las aplicaciones de la IA d\u00e9bil Los escenarios donde los seres humanos son sustituidos por m\u00e1quinas de IA a\u00fan es- t\u00e1n lejanos. Sin embargo, eso no implica que en nuestras actividades cotidianas no trate - mos con la IA. Cuando vemos una pel\u00edcula en streaming, hacemos compras en l\u00ednea, o usamos nuestro smartphone, nos benefi- ciamos de distintas aplicaciones que hacen uso de la IA para ofrecernos una experien- cia m\u00e1s amena en sus sitios o plataformas. La IA d\u00e9bil es muy utilizada en diversos sec - tores, Coeckelbergh (2022) se\u00f1ala que est\u00e1 presente en cosas tan comunes como el marketing, redes sociales, motores de b\u00fas- queda, aplicaciones de transporte, veh\u00edculos aut\u00f3nomos, hasta en los servicios sanitarios, seguridad o de impartici\u00f3n de justicia. Justo, porque la IA est\u00e1 en aplicaciones tan comu- nes es que se vuelve urgente reflexionar en torno al uso de esta tecnolog\u00eda y el acceso a la misma. Siguiendo a Coeckelbergh, es ne - cesario se\u00f1alar que el uso de IA en \u00e1mbitos como el sector sanitario o de impartici\u00f3n de justicia puede ampliar las brechas de desi- gualdad ya existentes en el acceso a los ser - vicios de salud o de justicia, y en esta \u00faltima, puede reproducir estereotipos que afecten a poblaciones vulnerables en la impartici\u00f3n de justicia. Las variadas aplicaciones de la IA pueden ser muy \u00fatiles. Con su apoyo los m\u00e9dicos pueden lograr diagn\u00f3sticos m\u00e1s precisos y oportunos, por ejemplo, con ella es posible interpretar mejor los estudios de imageno - log\u00eda o hacer cirug\u00edas a distancia. En otros casos, por ejemplo, en EUA, la IA ya se ha utilizado como herramienta de apoyo para tomar decisiones judiciales. Esto nos lleva a preguntarnos \u00bfqui\u00e9nes deber\u00edan acceder a la tecnolog\u00eda de IA?, \u00bfes \u00e9ticamente correcto que una IA tome una decisi\u00f3n judicial? M\u00e1s a\u00fan, debemos partir del hecho de que las IA trabajan con una enorme cantidad de datos que procesan, \u00bfc\u00f3mo adquieren esos datos?, \u00bfqu\u00e9 hacen con ellos? \"Uno de los puntos problem\u00e1ticos para definir a ciencia cierta lo que es la IA es el concepto de inteligencia. El nombre mismo de la tecnolog\u00eda parece indicar que es, o una extensi\u00f3n o algo contrapuesto a algo que se llamar\u00eda inteligencia natural\".Gaceta33 a fondo Estas interrogantes nos llevan a pensar en determinados problemas \u00e9ticos. En prin- cipio, debe pensarse en el asunto de la transparencia. Como se\u00f1ala Coeckelbergh (2022), nuestras identidades pueden estar en riesgo, toda nuestra informaci\u00f3n perso - nal es manejada por los algoritmos de la IA que utilizan las empresas que nos proveen servicios todos los d\u00edas. Ninguno de noso - tros sabemos d\u00f3nde van a parar esos datos, qui\u00e9nes y para qu\u00e9 tienen acceso a ellos. En muchas ocasiones, utilizamos aplicaciones en nuestros m\u00f3viles sin leer los t\u00e9rminos y condiciones, en donde muchas veces otor - gamos permiso para el manejo de nuestros datos como mercanc\u00eda a intercambiar entre diversas empresas. Por otro lado, las aplicaciones de la IA en otros \u00e1mbitos propician otras interrogantes \u00e9ticas. Si pensamos en los veh\u00edculos aut\u00f3 - nomos, debemos cuestionarnos \u00bfpor qu\u00e9 el veh\u00edculo debe tomar una decisi\u00f3n y no otra?, \u00bfbajo qu\u00e9 par\u00e1metros \u00e9ticos lo har\u00e1?, \u00bfqu\u00e9 enfoque ser\u00e1 mejor para ello? Uno de los problemas m\u00e1s profundos que surgen aqu\u00ed va de la mano con ciertos valores epis- temol\u00f3gicos que influyen en la \u00e9tica. En mu- chas ocasiones, los seres humanos tomamos decisiones con base en lo que creemos. Las creencias conforman un plexo de valores \u00e9ti- cos que orientan nuestras decisiones. Estas creencias no las adquirimos solamente por los libros, los manuales o las ense\u00f1anzas es- colares, sino, sobre todo, por las experiencias vitales. Como se\u00f1ala Ram\u00f3n L\u00f3pez (2017), esos saberes de sentido com\u00fan conforman nuestra inteligencia y son imposibles de transcribir en codificaci\u00f3n alguna para ser insertada en una m\u00e1quina. (p. 36) La IA tambi\u00e9n trastoca valores epistemol\u00f3gi- cos, lo cual puede propiciar problemas que afecten a la toma de decisiones en bio\u00e9ti- ca. El uso de plataformas que usan IA para generar im\u00e1genes o textos puede generar un problema en relaci\u00f3n con lo que consi- deramos como verdadero. Si partimos del hecho de que en la bio\u00e9tica se deben to - mar decisiones con base en la informaci\u00f3n disponible, el hecho de no tener fiabilidad en la producci\u00f3n de la informaci\u00f3n puede generar sesgos en la toma de decisiones. Si bien es cierto, ya existen problemas con la integridad acad\u00e9mica asociados con pr\u00e1cti- cas poco \u00e9ticas como el plagio, este tipo de pr\u00e1cticas pueden agravarse con un uso ina- decuado de las aplicaciones de IA. Por \u00faltimo, es importante mencionar que el uso de la IA tambi\u00e9n conlleva problemas ambientales. Si bien, en apariencia la IA no tiene un respaldo material, deben conside - rarse los factores materiales que hacen po - sible la existencia de la IA, como el consumo de energ\u00eda el\u00e9ctrica y la infraestructura que se encuentra detr\u00e1s de la producci\u00f3n de la misma. De acuerdo con Pengfei Li y dem\u00e1s (2023) el uso de Chat GPT tiene una huella ecol\u00f3gica importante, sobre todo en el caso del uso de recursos h\u00eddricos. De acuerdo con su investigaci\u00f3n, cada consulta que realiza- mos en esta plataforma implica un consumo de aproximadamente 500 mililitros de agua, lo cual se traduce en casi 4 millones de litros anuales. Para darnos una idea de la cantidad de agua que consume esta plataforma, po - demos mencionar que, seg\u00fan estimaciones de la ONU (2021) en promedio un habitante de la Ciudad de M\u00e9xico consume alrededor de 366 litros de agua por d\u00eda, en este caso la plataforma Chat GPT consume en un a\u00f1o el equivalente al consumo de 28 habitantes de la Ciudad de M\u00e9xico. Como es posible apreciar, el uso de IA no est\u00e1 exento de problemas \u00e9ticos. De acuer - do con Onora O\u00b4Neil (2009), asumimos que la bio\u00e9tica es un cruce interdisciplinario en el que convergen diversos saberes que tie - nen una preocupaci\u00f3n en com\u00fan; la vida. As\u00ed, saberes como el derecho, la medicina y la filosof\u00eda procuran dar soluciones viables a los problemas que surgen con las recientes implementaciones tecnocient\u00edficas. En este sentido, la IA puede y debe ser analizada des- de una perspectiva multidisciplinar, propia de la bio\u00e9tica, en funci\u00f3n de los problemas que ya se manifiestan con su uso. Por ello, es necesario pensar desde la bio\u00e9tica formas Gaceta34 de regular los usos de la IA. No se trata de condenar a esta tecnolog\u00eda al destierro, ser\u00eda il\u00f3gico, cuando menos. Sin embargo, dado los usos que tiene y los potenciales da\u00f1os que se observan s\u00ed debe gestionarse y regu- larse su uso de manera tal que los grupos vulnerables, no se vean m\u00e1s afectados por sus aplicaciones y el acceso a este tipo de implementaciones no genere m\u00e1s brechas de desigualdad. En este sentido, debe pen- sarse en regulaciones que tengan en cuenta la dignidad de las personas, de forma tal que no se vea socavada con los usos de este tipo de tecnociencia. Conclusiones Sin duda alguna la Inteligencia artificial nos ha facilitado varias actividades cotidianas. Incluso nos ha auxiliado en labores m\u00e1s im- portantes, como el sistema de salud o de se - guridad. No obstante, su uso no est\u00e1 libre de algunas controversias axiol\u00f3gicas que pue - den ser analizadas en t\u00e9rminos bio\u00e9ticos. M\u00e1s all\u00e1 de las consecuencias apocal\u00edpticas que conocemos sobre la IA, debemos pensar en aquellas consecuencias que en t\u00e9rminos reales son susceptibles de presentarse. De acuerdo con los estudios cient\u00edficos recientes, hoy en d\u00eda es imposible que una IA sustituya por completo a un ser humano, si bien puede hacer tareas espec\u00edficas mejor de lo que humanos especializados lo hacen, la IA no tendr\u00e1 en las d\u00e9cadas pr\u00f3xima un desarrollo que nos lleve a tal escenario. Por otro lado, s\u00ed debemos pensar en las con- secuencias que el uso de la IA existente con- lleva. Por ejemplo, la transparencia en el uso y manejo de los datos que se procesan en las aplicaciones que utilizan algoritmos de IA, los sesgos que podr\u00edan presentarse en el sistema de impartici\u00f3n de justicia o de ac - ceso a la salud. El an\u00e1lisis de esta comple - ja problem\u00e1tica se debe realizar desde una perspectiva bio\u00e9tica, ya que nos garantiza una pluralidad de enfoques que nos permi- tir\u00e1 robustecer el an\u00e1lisis de los riesgos y de los beneficios de esta tecnociencia, as\u00ed como la mejor manera de regularla y tener un uso \u00f3ptimo de la misma. Referencias -Boden, M. (2022). Inteligencia Artificial. Turner. -Coeckelbergh, M. (2022). \u00c9tica de la inteligencia artificial. C\u00e1tedra. Executive Office of the President. (2016). Preparing for the future of Artificial Intelligence. https://obamawhitehouse. archives.gov/sites/default/files/whitehouse_files/microsites/ostp/NSTC/preparing_for_the_future_of_ai.pdf -Li, P., Yiang J., Islam, M., Ren, S. (2023) Making AI Less \"Thirsty\": Uncovering and Addressing the Secret Water of AI Models. https://arxiv.org/pdf/2304.03271.pdf -L\u00f3pez, R. Meseguer, P. (2017). Inteligencia Artificial. Los libros de la Catarata. -O'Neil, O. (2009). Autonomy and Trust in Bioethics. Cambridge. -ONU. (2021). Comprender las del problema del ONU-H\u00e1bitat. https://onuhabitat.org.mx/index. php/comprender-las-dimensiones-del-problema-del-agua?fb_comment_id=1919706488040991_2396617700349865 #:~:text=Por%20ejemplo%2C%20el%20consumo%20promedio,promedio%20por%20habitante%20al%20d%C3%ADa. -Polanyi, M. (1983). The tacit dimensi\u00f3n. Peter Smith. Imagen: freepik.comGaceta35 a fondo De manera reciente la cuesti\u00f3n de la integri- dad acad\u00e9mica se discuti\u00f3 ampliamente en los \u00e1mbitos universitarios del pa\u00eds. Ello gra- cias a que el tema cobr\u00f3 un renovado inte - r\u00e9s a la luz de ciertos cuestionamientos, pro - venientes de la opini\u00f3n p\u00fablica, en cuanto a los procesos de evaluaci\u00f3n acad\u00e9mica por los que atraviesan miles de alumnos cada a\u00f1o, y mediante los cuales se logra comprobar la formaci\u00f3n de los futuros profesionistas del pa\u00eds, incluidos aquellos por los que pasaron profesionistas que se desempe\u00f1an como ser - vidores p\u00fablicos (Santos, 2023). Asimismo, la emergencia de tecnolog\u00eda que se auxilia del desarrollo de inteligencia artificial (IA) tiene uno de sus campos de aplicaci\u00f3n en los pro - gramas denominados anti \"plagio\", median- te las cuales se examinan los trabajos escritos, publicaciones y proyectos que se presentan a evaluaciones acad\u00e9micas, esto con el prop\u00f3 - sito de encontrar coincidencias con bases de datos y repositorios institucionales. No obstante, las ventajas evidentes de las que hoy se dispone como resultado de la IA, tanto en medios profesionales como de ense\u00f1anza, resulta \u00fatil contextualizar su in- clusi\u00f3n en la cuesti\u00f3n de la integridad aca- d\u00e9mica, as\u00ed como vislumbrar los probables dilemas que se presentaran durante su in- corporaci\u00f3n al \u00e1mbito acad\u00e9mico. En el pre - sente texto me propongo se\u00f1alar precisa- mente algunos de los \u00e1mbitos de discusi\u00f3n desde donde se han aportado reflexiones a la integridad acad\u00e9mica, as\u00ed como contribuir en la discusi\u00f3n de \u00bfCu\u00e1les ser\u00edan los hitos que tendr\u00e1 la incorporaci\u00f3n de IA como au- xiliar de ense\u00f1anza e investigaci\u00f3n? Integridad, academia y plagio Cuando hablamos de \u00e9tica acad\u00e9mica nos referimos al conjunto de principios o valores que regulan las actividades de las personas que participan en comunidades dedicadas a la ense\u00f1anza y la investigaci\u00f3n, para el cum- plimiento de las funciones de dicha comuni- dad. En este sentido, la integridad acad\u00e9mica hace referencia del actuar de los individuos pertenecientes a dicho colectivo, en cuanto a Integridad acad\u00e9mica y recursos digitales: acotaciones para una reflexi\u00f3n de vista a los recursos derivados de la inteligencia artificial Geovany Meza Chavero * sus acciones, si estas se apegan o por el con- trario se alejan de dichos valores. De ah\u00ed su importancia y necesidad de discusi\u00f3n. Se puede decir que la parcialidad en eva- luaciones acad\u00e9micas, la autor\u00eda ficticia, el sesgo en publicaciones el uso indebido de los recursos materiales y humanos prove - nientes de una instituci\u00f3n, son ejemplos de lo que podemos entender por faltas a la integridad acad\u00e9mica, esto debido a que su efecto vulnera la correcta realizaci\u00f3n de ac - tividades encaminadas a cumplir la misi\u00f3n de ense\u00f1anza-aprendizaje, investigaci\u00f3n y difusi\u00f3n de la cultura (Vera, 2016a). Desde luego la cuesti\u00f3n que ha sido aborda- da m\u00e1s ampliamente es el llamado \"plagio\" entendido como \"el acto de ofrecer o pre - sentar como propia, en su totalidad o en par - te, la *obra de otra persona\" (OMPI,1980, p. 188). La preocupaci\u00f3n por el tema ha llevado a instituciones como el Instituto Tecnol\u00f3gico de Massachusetts a implementar un manual que gu\u00eda la toma de decisi\u00f3n de sus alum- nos ante situaciones donde se ha detectado faltas al derecho de autor (Brennecke, 2020). No obstante, podemos ponderar dicha si- tuaci\u00f3n al pensar que no toda mala pr\u00e1cti- ca acad\u00e9mica se reduce al plagio. Como se ha reflexionado, principalmente mediante la noci\u00f3n de \"academic misconduct\" (Uni- versity of Cambridge, 2019), en realidad se cuenta con un abanico de situaciones, que al igual que el \"plagio\", perjudican la fun- ci\u00f3n de una instituci\u00f3n de educaci\u00f3n supe - rior (Gant\u00fas, 2016). Por tal motivo, se vuelve necesario recordar que las medidas que se toman para sancionar, impedir o prevenir un tipo de falta a la integridad acad\u00e9mica, no implica necesariamente un efecto \"domi- n\u00f3\" en otras, como ya lo han advertido otros autores (Gant\u00fas, 2016), es necesario analizar el propio funcionamiento, en particular de la instituci\u00f3n para proponer una pol\u00edtica edu- cativa integral. *Egresado de la Licenciatura en Estudios Latinoame - ricanos, FFyL, UNAM; Particip\u00f3 en el proyecto \u00c9tica Acad\u00e9mica UNAM (PUB); Se desempe\u00f1a en el \u00e1rea de Comisiones Dictaminadoras de la FFyL, UNAM.Gaceta36 M\u00e1s all\u00e1 del debate que se suscit\u00f3 a inicios de a\u00f1o, el tema del \"plagio\", en espec\u00edfico aquel que se lleva a cabo en trabajos aca- d\u00e9micos, y que a posteriori fuera detecta- do en trabajos para la obtenci\u00f3n de grado, que presentaron en su momento profeso - res, investigadores y funcionarios p\u00fablicos, lleva por lo menos una d\u00e9cada como tema recurrente en medios de comunicaci\u00f3n na- cionales (Pi\u00f1\u00f3n, 2013). Al respecto es perti- nente indicar, como lo han hecho distintos especialistas (Incl\u00e1n, 2016), y como se puede inferir al observar los a\u00f1os de los trabajos en cuesti\u00f3n, la situaci\u00f3n es de m\u00e1s larga data e incluso se puede rastrear incluso a niveles anteriores de escolaridad. El desarrollo hist\u00f3 - rico de la cuesti\u00f3n, en la perspectiva de los propios integrantes de la comunidad acad\u00e9 - mica, es m\u00e1s larga todav\u00eda. Diversos estudios han dado aportes al respecto, como el del historiador Anthony Grafton en su obra hoy ampliamente recurrida Los or\u00edgenes tr\u00e1gi- cos de la erudici\u00f3n, la cual nos presenta las vicisitudes de las imprecisiones de referen- cias en textos acad\u00e9micos, que ocurr\u00edan in- cluso desde los albores del siglo XIX (Grafton, 2015). Como se ha se\u00f1alado (Koepsell y Ruiz, 2015), podemos considerar que la mala pr\u00e1c - tica cient\u00edfica tuvo sus inicios a la par de su propio quehacer, y que el cuestionamiento \u00e9tico de su praxis fue posterior. Para establecer una justa relaci\u00f3n entre lo que se dice acerca de la integridad acad\u00e9 - mica y sus aportes o desventajas para las ins- tituciones, es necesario indicar brevemente las \u00e1reas que han aportado iniciativas y de - bates sobre el tema, lo cual es un ejercicio disciplinar siempre \u00fatil. Algunos enfoques de la cuesti\u00f3n En primer lugar, la disciplina que quiz\u00e1 m\u00e1s tiempo ha puesto en reflexi\u00f3n la virtud, el deber y la naturaleza de los actos humanos, tanto de manera individual como en su co - lectivo, es la Filosof\u00eda, en particular la rama de la \u00c9tica. En un sentido aplicado, como en su momento se propuso para el estudio del ethos de la ciencia (Koepsell y Ruiz, 2015), ubica los valores que son comunes a los miembros de las comunidades acad\u00e9micas, los cuales suelen ser expresados a trav\u00e9s de c\u00f3digos de \u00e9tica que orientan el proceder de los acad\u00e9micos y alumnos, de manera par - ticular en casos donde la reglamentaci\u00f3n previa no es lo suficiente expl\u00edcita. Adem\u00e1s de identificar ciertos valores, proporciona corrientes, teor\u00edas desde las que se pueden abordar los dilemas que se presentan (deon- tolog\u00eda, utilitarismo, entre otros). El segundo es el \u00e1mbito normativo, el cual desde una perspectiva nacional nos remite a los derechos de autor y la propiedad indus- trial, a los cuales recurren las universidades para el registro y protecci\u00f3n de sus publica- ciones e invenciones. Asimismo, las institu- ciones de educaci\u00f3n superior generan regla- mentos internos con el prop\u00f3sito de prevenir y sancionar las violaciones a estos derechos, adem\u00e1s de las faltas a la integridad acad\u00e9mi- ca. Al respecto la Universidad Nacional Aut\u00f3 - noma de M\u00e9xico ha emitido su propio c\u00f3digo de \u00e9tica (UNAM, 2015), as\u00ed como autoriz\u00f3 la in- tegraci\u00f3n de comit\u00e9s de \u00e9tica institucionales (UNAM, 2019) y de manera m\u00e1s reciente las adecuaciones a su estatuto general para pre - ver sanciones en el caso espec\u00edfico del plagio (Hern\u00e1ndez, 2023). En principio puede resul- tar abrumador conciliar conceptos como au- tor, obra, derechos patrimoniales y derechos \"Cuando hablamos de \u00e9tica acad\u00e9mica nos referimos al conjunto de principios o valores que regulan las actividades de las personas que participan en comunidades dedicadas a la ense\u00f1anza y la investigaci\u00f3n...\".Gaceta37 a fondo morales, as\u00ed como sus derivados, a\u00fan m\u00e1s al momento de distinguir sus aplicaciones en el mundo acad\u00e9mico, no obstante, podemos pensarlos como un complemento, ya que ni el INDAUTOR puede emitir un grado acad\u00e9 - mico, ni una universidad una c\u00e9dula de de - rechos sobre una obra. Como ya han acotado otros autores (Vera, 2016b), cuando al interior de una normatividad acad\u00e9mica exist\u00eda un vac\u00edo al respecto, se recurr\u00eda a la instancia fe - deral para conciliar el conflicto de derechos, sin que en ocasiones tuviera una repercusi\u00f3n dentro de la instituci\u00f3n. En este \u00faltimo caso, la inclusi\u00f3n de procedimientos disciplinarios que delimiten claramente el tipo de falta y su procedimiento correspondiente robuste - ce las opciones a las cuales pueden recurrir instituciones e individuos que se consideren afectados. El tercer \u00e1mbito se relaciona con la perfecti- bilidad de la formaci\u00f3n profesional desde el medio educativo. En \u00e9l se discuten las pol\u00edti- cas que adoptan las instituciones en cuan- to a las faltas a la integridad acad\u00e9mica, por ejemplo, si se opta por una tolerancia cero o si es necesario establecer una actuaci\u00f3n espec\u00edfica para estudiantes. Asimismo, la ac - tualizaci\u00f3n curricular en cuanto a la forma- ci\u00f3n metodol\u00f3gica y la inclusi\u00f3n de la \u00e9tica acad\u00e9mica en planes y programas de estu- dios, as\u00ed como la incorporaci\u00f3n de nuevas tecnolog\u00edas para el apoyo docente y la eva- luaci\u00f3n de alumnos. En este \u00faltimo punto se ha estudiado c\u00f3mo la disposici\u00f3n de infor - maci\u00f3n a trav\u00e9s de las TIC puede contribuir a propiciar situaciones como el plagio (Incl\u00e1n, 2016). No resulta nimio que una bibliograf\u00eda actualizada contribuya o ponga en perspec - tiva la cuesti\u00f3n. Al respecto, se han retomado las recomen- daciones del prol\u00edfico escritor Humberto Eco en cuanto a la elaboraci\u00f3n de una tesis (como se cit\u00f3 en Vera, 2016 a). Entre estas se reconoce el empleo de la autor\u00eda ficticia o por encargo e incluso la traducci\u00f3n como un auxiliar del plagio. Una postura sobre este texto, bastante conocido y socorrido en se - minarios y cursos, puede ser su retiro de la bibliograf\u00eda. No obstante, tambi\u00e9n cabr\u00eda la posibilidad de generar una reflexi\u00f3n adicio - nal, se podr\u00eda cuestionar qu\u00e9 llev\u00f3 a un escri- tor prol\u00edfico como Eco a realizar estas reco - mendaciones, si es ello es aceptable hoy en d\u00eda, o preguntarnos \u00bfcu\u00e1les eran las condi- ciones de la universidad en ese momento?, \u00bflos profesionistas contempor\u00e1neos de Eco comparten esta visi\u00f3n? Este \u00faltimo ejemplo pone en perspectiva la importancia de la formaci\u00f3n integral y preventiva, misma que permanece como una alternativa vigente a mediano y largo plazo. Del plagio artesanal, al software y la IA: el desarrollo tecnol\u00f3gico para el apoyo de las actividades acad\u00e9micas Hoy en d\u00eda se atisba distante el uso de la es- critura no electr\u00f3nica, sin nubes o bases de informaci\u00f3n asequibles las 24 horas del d\u00eda, desde cualquier parte del mundo. Tener di- versas fuentes de informaci\u00f3n a un solo clic. Ciertamente el acceso a la informaci\u00f3n con el que contamos en la actualidad difiere so - bremanera con el que se cont\u00f3 en las uni- versidades cuando Eco escribi\u00f3 \u00bfC\u00f3mo se hace una tesis? (Eco, 2004). Ahora en una revisi\u00f3n un tutor puede hacer uso de iThen- ticate, seleccionar el idioma para refinar la b\u00fasqueda de \"coincidencias\" y obtener un listado de textos disponibles en la web con un porcentaje determinado de similitud, lo cual hasta hace pocos a\u00f1os todav\u00eda supon\u00eda un grado de complejidad en cierto sentido (Vera, 2016b). Asimismo, un alumno puede recurrir a programas y aplicaciones como Zotero, Mendeley o Evernote para gestionar las fuentes que hay recopilado y obtener la referencia bibliogr\u00e1fica en el formato de ci- taci\u00f3n deseado. No obstante, dicha inmersi\u00f3n tecnol\u00f3gica trajo consigo la simplificaci\u00f3n en la disposi- ci\u00f3n de informaci\u00f3n por medios pensados inicialmente como herramientas para el aprendizaje y la publicaci\u00f3n, en lo cual re - sulta fundamental una formaci\u00f3n \u00e9tica en el tratamiento de las fuentes (Incl\u00e1n, 2016; Gant\u00fas, 2016). En dicho orden de ideas no es extra\u00f1o prever que el desarrollo de nuevas Gaceta38 tecnolog\u00edas aplicadas a la simplificaci\u00f3n de la lectura, escritura y s\u00edntesis de informaci\u00f3n traer\u00e1 consigo nuevos retos para la revisi\u00f3n y dictaminaci\u00f3n del trabajo acad\u00e9mico. Apli- caciones como Chat GPT o Jasper ya cuen- tan con generaci\u00f3n de texto mediante una selecci\u00f3n tem\u00e1tica, donde incluso se incor - poran fuentes. Una de las primeras situacio - nes que nos llega a la mente con el arribo de aplicaciones, programas y sitios que propor - cionen este tipo de recurso, incluso para la generaci\u00f3n de im\u00e1genes o diapositivas, ser\u00eda la automatizaci\u00f3n del trabajo acad\u00e9mico. Al respecto, se puede considerar que la cuesti\u00f3n radica en el uso de la herramienta, donde recordemos que toda t\u00e9cnica y pro - cedimiento requiere de la capacitaci\u00f3n del usuario para su uso profesional. Ciertamen- te la simplificaci\u00f3n de interfaz para los mis- mos es un refinamiento t\u00e9cnico que lleva al empleo intuitivo hoy en d\u00eda, lo cual buscar\u00eda en primera instancia la simplificaci\u00f3n de la actividad. Sin embargo, en el caso del traba- jo acad\u00e9mico, este tipo de producto visual o escrito puede tener como desprop\u00f3sito su presentaci\u00f3n como una obra escrita de un alumno o acad\u00e9mico, con lo que se re - cae en una falta a la integridad acad\u00e9mica ya conocida, el fraude. La pretensi\u00f3n de au- tenticidad o la simulaci\u00f3n de la autor\u00eda es un tema que ya se ha tratado anteriormente, as\u00ed como las distintas acepciones que pue - de tener el plagio considerado como fraude, en caso de que no se integren las referen- cias correspondientes (Vera, 2016b; Yankele - vich, 2016). De tal caso, la supresi\u00f3n del autor de una obra, por un producto generado por IA, por lo menos hasta el momento, y en el contexto acad\u00e9mico, continua a disposici\u00f3n de quien lo presenta. Por ello resulta funda- mental que la preparaci\u00f3n \u00e9tica acompa\u00f1e la instrucci\u00f3n y uso de dichos recursos. Referencias -Brennecke, Patricia. (2020). Academic integrity at MIT. A Handbook for students. MIT Office of the Vice Chancellor. https://integrity.mit.edu/handbook/academic-integrity-handbook -Eco, Humberto. (2004). C\u00f3mo se hace una tesis: t\u00e9cnicas y procedimientos de estudio, investigaci\u00f3n y escritura. Gedisa. -Gant\u00fas, Fausta. (2016). Conocimientos colectivos, obras particulares. Algunas reflexiones en torno al plagio acad\u00e9mi- co. Perfiles educativos. Vol. 38, n\u00fam. 154. -Grafton, Anthony. (2015). Los or\u00edgenes tr\u00e1gicos de la erudici\u00f3n, Fondo de Cultura Econ\u00f3mica. -Hern\u00e1ndez, Mirtha. (2023, abril 10). Fortalece la Universidad integridad y honestidad academicas. Gaceta UNAM. -Incl\u00e1n, Catalina. (2016). Ctrl-C, Ctrl-V. La pr\u00e1ctica escolar de copiar y pegar en el bachillerato. Perfiles educativos. Vol. 38, n\u00fam. 154. -Koepseel, David R. y Ruiz de Ch\u00e1vez, Manuel H. (2015). \u00c9tica de la Investigaci\u00f3n, Integridad Cient\u00edfica . Comisi\u00f3n Na- cional de Bio\u00e9tica. -Organizaci\u00f3n Mundial de la Propiedad Intelectual. (1980). Glosario de derechos de autor y derechos conexos. WIPO. -Pi\u00f1\u00f3n, Alida. (2013, junio 5). La historia de un plagio serial. El Universal. https://archivo.eluniversal.com.mx/notas/927579. html -Santos Cid, Alejandro. (2023, enero 11). La UNAM concluye que la tesis de 1987 de la ministra Yasm\u00edn Esquivel es un plagio. El Pa\u00eds. https://elpais.com/mexico/2023-01-12/la-unam-concluye-que-la-tesis-de-1987-de-la-ministrayasmin- esquivel-es-un-plagio.html -Universidad Nacional Aut\u00f3noma de M\u00e9xico. (2015, julio 30). C\u00f3digo de \u00c9tica de la Universidad Nacional Aut\u00f3noma de M\u00e9xico. Gaceta UNAM. https://dgapa.unam.mx/images/etica/2015_codigo-etica-unam.pdf -Universidad Nacional Aut\u00f3noma de M\u00e9xico. (2019, agosto 29). Acuerdo por el que se Establecen los Lineamientos para la Integraci\u00f3n, Conformaci\u00f3n y Registro de los Comit\u00e9s de \u00c9tica en la Universidad Nacional Aut\u00f3noma de M\u00e9xico. Gaceta UNAM. https://www.gaceta.unam.mx/wp-content/uploads/2019/10/190829-Convocatorias.pdf -University of Cambrigde. (2019, noviembre 27). What is academic misconduct? https://www.plagiarism.admin.cam. ac.uk/definition -Vera, H\u00e9ctor. (2016). El plagio y la autonom\u00eda de las instituciones acad\u00e9micas. Perfiles educativos. vol. 38, n\u00fam. 154, 2016. -Vera, H\u00e9ctor. (2016). Introducci\u00f3n. El plagio nuestro de todos los d\u00edas. Perfiles educativos. vol. 38, n\u00fam. 154, 2016. -Yankelevich, Javier. (2016). Mapas prestados para entender el plagio acad\u00e9mico. Perfiles educativos. vol. 38, n\u00fam. 154, 2016.Gaceta39 escenario nacional El maquinismo de la Revoluci\u00f3n Industrial dio origen a la din\u00e1mica de producci\u00f3n de bienes que conocemos hoy en d\u00eda. Al sis- tematizarse los procesos de producci\u00f3n a trav\u00e9s de la introducci\u00f3n de maquinaria, se dio origen al sistema fabril, en el que no s\u00f3lo hubo mayor celeridad en la elaboraci\u00f3n de productos, sino que se abarataron los cos- tos y se uniform\u00f3 la calidad de estos. Esta sistematizaci\u00f3n tambi\u00e9n contribuy\u00f3 a un aumento en el consumo, en el que la oferta pod\u00eda r\u00e1pidamente satisfacer a la demanda. Hubo varios fen\u00f3menos sociales como el crecimiento demogr\u00e1fico de las ciudades, la migraci\u00f3n de la poblaci\u00f3n del campo ha- cia los centros urbanos, el surgimiento del proletariado, los cuales revolucionaron la organizaci\u00f3n de las sociedades (Rafferty, s/f). Algunos pensaran que este r\u00e1pido cre - cimiento urbano tuvo como consecuencia positiva el surgimiento de los derechos eco - n\u00f3micos, sociales y culturales, mediante los cuales se logr\u00f3 reconocer dentro del nivel de vida adecuado (HCHR, 2018), a los derechos a la alimentaci\u00f3n, al agua, al saneamiento, vivienda digna, vestido, atenci\u00f3n a la salud, protecci\u00f3n y asistencia social; derechos que hoy en d\u00eda, no s\u00f3lo deben ser reconocidos, sino garantizados por los Estados, junto con los derechos de los trabajadores. Pero no se puede olvidar, que estos derechos surgieron por la lucha de los trabajadores para mejo - rar sus condiciones, en medio de las huelgas, que, en gran parte, se llevaron a cabo contra el maquinismo, debido al desplazamiento de la mano de obra. Con la rob\u00f3tica en el siglo XX surgi\u00f3 una es- pecie de nuevo \"maquinismo\", en el que otro tipo de tareas a\u00fan m\u00e1s especializadas, se sistematizaron y perfeccionaron. En el ima- ginario colectivo se han instalado de forma positiva o negativa, im\u00e1genes de los robots surgidas del arte (cine, literatura de ciencia ficci\u00f3n, escultura), para cumplir la fantas\u00eda humana de una mejora en la calidad de vida, de la mano de una interacci\u00f3n virtuosa en- tre robots y humanos o, por el contrario, los robots como aquellos que encarnan la pe -Desaf\u00edos para la regulaci\u00f3n en torno al desarrollo y aplicaci\u00f3n de la IA Garbi\u00f1e Saruwatari Zavala* sadilla de la destrucci\u00f3n, aterrorizando a la especie humana. En los puntos intermedios de esta polarizaci\u00f3n, hay aspectos en los que fehacientemente puede comprobarse que la mecanizaci\u00f3n ha mejorado de manera sustantiva la relaci\u00f3n del ser humano con su entorno; pero esto no debe darse por senta- do para soslayar la reflexi\u00f3n sobre la reper - cusi\u00f3n del uso de la tecnolog\u00eda en todas las formas de vida. Los claros beneficios aportados por el avan- ce cient\u00edfico no pueden cegarnos ante los riesgos de que la maquinaria desplace al ser humano. No se trata de establecer de ma- nera maniquea, una postura ludita1 (Coll, 2020) por un lado o, una postura acr\u00edtica, por el otro, descalificando y etiquetando como retr\u00f3grados a quienes no est\u00e1n de acuer - do con la acelerada tecnologizaci\u00f3n. Desde hace d\u00e9cadas ronda el temor de que la auto - matizaci\u00f3n supla al trabajo humano, elimine puestos de trabajo y deje a miles de obreros y mano de obra calificada fuera del mercado laboral (Frey & Osborne, 2013). Ahora con la Inteligencia Artificial (IA) se extiende la pre - ocupaci\u00f3n hacia el ejercicio de distintas pro - fesiones y artes, aplicaciones como ChatGPT han aumentado este temor; basta ver que, en la reciente huelga de guionistas de Ho - llywood, una de las peticiones sindicales es que su labor creativa en la industria del en- tretenimiento no sea reemplazada por la IA (Scheiber, 2023). La tecnolog\u00eda como bien sabemos, per se, no es buena ni mala, sino son los usos que los humanos le damos, los que tienen una finalidad positiva o negativa y que deben ser examinados a trav\u00e9s de sus implicacio - 1 Ludismo: movimiento que surgi\u00f3 en Inglaterra, du- rante la Revoluci\u00f3n Industrial, que promov\u00eda el rechazo de las m\u00e1quinas y la automatizaci\u00f3n. Este fue promo- vido en el siglo XIX por los artesanos ingleses, que pro - testaron con el fin de no perder su empleo y, en casos extremos, destruyeron maquinaria. *Licenciada en Derecho; Maestra en Bio\u00e9tica y Docto - ra en Cultura de Derechos Humanos; Jefa del Departa- mento de Estudios Jur\u00eddicos, \u00c9ticos y Sociales, y Presi- denta del Comit\u00e9 de \u00c9tica en Investigaci\u00f3n, INMEGEN.Gaceta40 nes \u00e9ticas y jur\u00eddicas, as\u00ed como la evaluaci\u00f3n de su repercusi\u00f3n social. La Recomendaci\u00f3n sobre la \u00c9tica de la Inteligencia Artificial, adoptada por la Organizaci\u00f3n de las Na- ciones Unidas para la Educaci\u00f3n, la Ciencia y la Cultura (UNESCO, 2021), se\u00f1ala que los aspectos \u00e9ticos relativos de los sistemas de IA est\u00e1n vinculados a todas las etapas de su ciclo de vida, desde la investigaci\u00f3n, con- cepci\u00f3n, desarrollo, despliegue, utilizaci\u00f3n, mantenimiento, funcionamiento, comer - cializaci\u00f3n, financiaci\u00f3n, seguimiento, eva- luaci\u00f3n, validaci\u00f3n, desmontaje y hasta su terminaci\u00f3n. Por lo que resulta fundamental identificar los distintos momentos, actores y partes interesadas, sean personas f\u00edsicas o morales, p\u00fablicas o privadas, para compren- der el alcance de la responsabilidad jur\u00eddica de los involucrados durante todo el proceso o en una etapa de este; siendo lo primordial, considerar los derechos de las personas o grupos que pudieran ser vulnerados. En este sentido, el documento de trabajo emitido por el Comit\u00e9 Ad hoc sobre Inteli- gencia Artificial del Consejo de Europa (CA - HAI-COE, 2021), igualmente recomienda que deben existir medidas aplicables desde el desarrollo hasta la aplicaci\u00f3n de los sistemas de IA, entre ellas, mecanismos de transpa- rencia y de protecci\u00f3n de datos, evaluacio - nes de riesgo y debates p\u00fablicos basados en evidencia (numerales 22 y 25). Este docu- mento sobre los Elementos potenciales de un marco legal para el desarrollo, dise\u00f1o y aplicaci\u00f3n de la IA, basado en sus est\u00e1nda- res sobre los Derechos Humanos, la Demo - cracia y el Estado de Derecho, hace \u00e9nfasis en la clasificaci\u00f3n de los riesgos para lo cual propone que, un instrumento transversal ju- r\u00eddicamente vinculante debe establecer una metodolog\u00eda de evaluaci\u00f3n del impacto que sea concreta, clara, objetiva y con categor\u00edas de bajo o alto riesgo o de riesgo inacepta- ble. Estas dos \u00faltimas categor\u00edas permitir\u00edan marcar una moratoria o restricciones y con- diciones para uso excepcional o incluso una prohibici\u00f3n, debido a que los riesgos inacep - tables pueden interferir con el goce de los derechos humanos, el funcionamiento de la democracia o la observancia de la ley. A tra-v\u00e9s de este documento y otro titulado Hacia la Regulaci\u00f3n de los Sistemas de IA (Ben-Is- rael, 2020), el mismo Comit\u00e9 (CAHAI) llama la atenci\u00f3n sobre: (i) el uso indiscriminado por parte de instancias p\u00fablicas o privadas, de los sistemas de reconocimiento facial y otras formas de identificaci\u00f3n biom\u00e9trica que permitan catalogar o inferir emociones o ca- racter\u00edsticas de los individuos; (ii) la vigilancia masiva y formas de seguimiento a trav\u00e9s de servicios de ubicaci\u00f3n o de comportamiento en l\u00ednea; (iii) el sesgo algor\u00edtmico o la discri- minaci\u00f3n provocada por los valores implica- dos en la recolecci\u00f3n de datos usados para la codificaci\u00f3n de los algoritmos de las apli- caciones; (iv) los sistemas de escalas sobre caracter\u00edsticas f\u00edsicas o mentales o de elabo - raci\u00f3n de perfiles que punt\u00faen o califiquen el comportamiento de individuos para asig- narles acceso a servicios esenciales; (v) los sistemas de IA encubiertos; (vi) programas con capacidad de generar im\u00e1genes, texto y audio sint\u00e9ticos o falsificaciones profundas y con capacidad de distribuir este contenido a trav\u00e9s de medios sociales; (vii) las interfaces humano-IA, entre otros. Cabe mencionar que tambi\u00e9n, a trav\u00e9s de programas o software malicioso que puede ser escalable, se puede tomar el control de veh\u00edculos, dispositivos, robots o infraestruc - tura digital, para provocar ciberataques o apuntar hacia las vulnerabilidades de los sis- temas (Gonz\u00e1lez Arencibia & Mart\u00ednez Car - dero, 2020). Desde hace a\u00f1os se han tratado de combatir los delitos relacionados con la pirater\u00eda inform\u00e1tica, como el phishing pero, desafortunadamente, aun no se ha logrado la erradicaci\u00f3n ni sanci\u00f3n de estas conduc - tas, por lo que se prev\u00e9 que este aspecto obscuro siga acompa\u00f1ando al debate sobre la IA. En marzo de 2023, la Relator\u00eda Especial para la Libertad de Expresi\u00f3n (RELE) de la Comisi\u00f3n Interamericana de Derechos Hu- manos (CIDH) visit\u00f3 diferentes empresas y organizaciones de internet radicadas en San Francisco, California, EE.UU., para dialogar y recopilar informaci\u00f3n sobre sus pol\u00edticas y pr\u00e1cticas en materia de derechos humanos Gaceta41 escenario nacional y tecnolog\u00eda. Llama la atenci\u00f3n que, derivado de la consulta se destac\u00f3 como un desaf\u00edo, el uso de la IA para los sistemas de moderaci\u00f3n de contenido y su uso para elaborar conte - nido en las redes sociales. Existe el riesgo de que un uso inapropiado pueda exacerbar las tensiones sociales preexistentes y las dispa- ridades de poder entre los diferentes actores involucrados (RELE-CIDH, 2023). Este riesgo, aunado al sesgo algor\u00edtmico, puede contra- poner las libertades civiles y pol\u00edticas del ciu- dadano, (como la de pensamiento, prensa, opini\u00f3n), con el control y supervisi\u00f3n de los sistemas que debe ejercer el gobierno por motivos de seguridad o de monitoreo del funcionamiento. Otra recomendaci\u00f3n del CAHAI para los Estados miembros del Consejo de Euro - pa, pero que bien puede ser adoptada por cualquier pa\u00eds o regi\u00f3n, es el establecimien- to de las llamadas \"cajas de arena\", que en este caso ser\u00edan \"cajas de arena regulatorias\" [regulatory sandboxes], entendidas como espacios controlados para permitir pruebas a los sistemas de IA, lo que por un lado, esti- mular\u00eda la innovaci\u00f3n responsable, pero por otro, permitir\u00eda evaluar el cumplimiento de las normas nacionales y los est\u00e1ndares de las normas multinacionales, como las del Consejo de Europa. Estas cajas pueden ser mecanismos de menor escala y costo para llevar a cabo estudios de factibilidad y moni- toreo, bajo riesgos calculados. Por su parte, el gobierno de Estados Unidos de Am\u00e9rica public\u00f3 el Plan para una Decla- raci\u00f3n de Derechos de IA (The White House, 2022), que, a manera de cat\u00e1logo de dere - chos humanos, consagra una serie de prin- cipios: (i) Sistemas seguros y efectivos: los usua- rios deben ser protegidos contra siste - mas inseguros e ineficaces. El docu- mento de la Casa Blanca coincide con los instrumentos antes mencionados, en relaci\u00f3n con la identificaci\u00f3n y eva- luaci\u00f3n de riesgos, implementaci\u00f3n de pruebas y de mecanismos de mitiga- ci\u00f3n de resultados peligrosos, incluidos aquellos surgidos m\u00e1s all\u00e1 del uso pre - visto de la tecnolog\u00eda en cuesti\u00f3n, as\u00ed como el constante monitoreo sobre su seguridad, efectividad y eficacia. (ii) Protecci\u00f3n contra la Discriminaci\u00f3n Algor\u00edtmica: los usuarios deben ser protegidos contra la discriminaci\u00f3n al- gor\u00edtmica y los sistemas deben ser di- se\u00f1ados de manera equitativa. (iii) Privacidad de la Informaci\u00f3n: los usua- rios deben poder decidir sobre el uso de su informaci\u00f3n y estar protegidos con- tra pr\u00e1cticas abusivas de la utilizaci\u00f3n de sus datos. (iv) Aviso y Explicaci\u00f3n: los usuarios deben saber que est\u00e1n utilizando un sistema automatizado y comprender a trav\u00e9s de una clara explicaci\u00f3n t\u00e9cnica, c\u00f3mo es que esto contribuye en los resulta- dos que lo impactan. (v) Alternativas humanas, consideraci\u00f3n y respaldo: los usuarios deben poder op - tar por no interactuar con un sistema automatizado y tener acceso al trato de una persona que pueda solucionar el problema, de manera eficaz, eficiente y r\u00e1pida, mediante una capacitaci\u00f3n \"Desde hace d\u00e9cadas ronda el temor de que la automatizaci\u00f3n supla al trabajo humano, elimine puestos de trabajo y deje a miles de obreros y mano de obra calificada fuera del mercado laboral...\".Gaceta42 adecuada. El trato humano no deber\u00eda convertirse en una carga para el p\u00fabli- co usuario, sino en un apoyo y acompa- \u00f1amiento. En el \u00e1mbito de la atenci\u00f3n a la salud, tam- bi\u00e9n se han emitido instrumentos que sope - san los puntos favorables o desfavorables del uso de la IA, tales como la Declaraci\u00f3n so - bre Inteligencia Aumentada en la Atenci\u00f3n M\u00e9dica (AMM, 2019); el documento titulado La Inteligencia Artificial en la salud p\u00fablica (OPS, 2021) y el Reporte sobre el Impacto de la Inteligencia Artificial en la relaci\u00f3n M\u00e9 - dico Paciente (COE, 2021). En ellos se hace \u00e9nfasis en que la tecnolog\u00eda debe estar cen- trada en las personas, controlada y super - visada por seres humanas, as\u00ed como funda- mentada en la \u00e9tica. La integridad cient\u00edfica es de suma relevancia para que los sistemas de IA sean confiables y accesibles, ya que las intervenciones de IA deben ce\u00f1irse a ri- gurosos est\u00e1ndares cient\u00edficos y \u00e9ticos, que permitan la reproducibilidad y apertura para poder ser compartidos y los beneficios pue - dan ser extendidos hacia un mayor n\u00famero de personas. Al igual que los dem\u00e1s documentos nom- brados, la protecci\u00f3n a las personas se centra en aspectos de transparencia, protecci\u00f3n de datos, respeto a la privacidad, condiciones de equidad y no discriminaci\u00f3n, pero en el con- texto espec\u00edfico de los instrumentos centra- dos en la salud, es imperativo que la din\u00e1mica del consentimiento informado entre paciente y personal de salud, as\u00ed como entre sujeto de investigaci\u00f3n e investigadores, se actualice de acuerdo a los desaf\u00edos que plantea la IA. Usual- mente, el personal m\u00e9dico debe asegurarse que la informaci\u00f3n que brinda al paciente sea comprensible, para que pueda tomar de - cisiones informadas; pero en este caso, la in- formaci\u00f3n tambi\u00e9n debe encauzarse hacia la comprensi\u00f3n del funcionamiento de la IA por parte del paciente. En esta tesitura, tambi\u00e9n es importante que el paciente conozca el ries- go del manejo de la informaci\u00f3n. El expedien- te cl\u00ednico electr\u00f3nico, por ejemplo, desde hace a\u00f1os ha planteado el reto sobre el control para el acceso a las plataformas que contienen y almacenan la informaci\u00f3n. Incluso el manejo de bases de datos de salud, conformadas por informaci\u00f3n obtenida en el contexto de la in- vestigaci\u00f3n biom\u00e9dica, ha generado una serie de reflexiones sobre las medidas de seguri- dad que deben adoptarse para evitar el acce - so no autorizado o el intercambio inapropiado de datos (AMM, 2016). Los poderes legislativos en cada pa\u00eds deben seguir trabajando para la adecuada reglamentaci\u00f3n del expediente cl\u00ed- nico; de las bases de datos de salud, en espe - cial las que almacenan informaci\u00f3n gen\u00e9tica de las personas; de los biobancos y reservorios de material biol\u00f3gico humano y, de los acuer - dos y condiciones para el intercambio de in- formaci\u00f3n de salud. Una de las grandes virtudes de la IA es la automatizaci\u00f3n de tareas, pero existen los riesgos de que la responsabilidad con res- pecto al bienestar del paciente se diluya y, que se favorezca la falta de rendici\u00f3n de cuentas, debido a que los trabajadores de salud no ser\u00e1n los \u00fanicos, sino tambi\u00e9n los desarrolladores de sistemas de IA, que sean responsables de las imprecisiones, sesgos o incluso eventos adversos que resulten por un diagn\u00f3stico poco certero o interpretaci\u00f3n err\u00f3nea de la informaci\u00f3n. Asimismo, con re - laci\u00f3n a aplicaciones sobre bienestar f\u00edsico o de salud mental, que est\u00e9n al alcance del paciente o del consumidor, es crucial no au- tomatizar ciertos procesos en las aplicacio - nes donde los factores psicol\u00f3gicos como la empat\u00eda (Gonz\u00e1lez Arencibia & Mart\u00ednez Cor - dero, 2020), pueden ser determinantes tan- to en la respuesta brindada por la aplicaci\u00f3n como en la toma de decisiones por parte del paciente o usuario. Por ejemplo, chatbots especializados en di\u00e1logo, aplicados a l\u00edneas de ayuda a personas en peligro de suicidio (El-Atillah, 2023) o creados para brindar con- sejo a personas con trastornos alimenticios (Business Insider, 2022). Aunque sea el pro - pio usuario quien accede voluntariamente a estas aplicaciones, se abre un abanico de diversas repercusiones legales ante el uso de la IA y la falta de compromiso de los desa- rrolladores para asumir responsabilidad por Gaceta43 escenario nacional su creaci\u00f3n, desarrollo y cauce (Redacci\u00f3n RT, 2023). Por esta raz\u00f3n, resulta necesaria la evaluaci\u00f3n constante de las tecnolog\u00edas sa- nitarias que incorporan IA. En s\u00edntesis, podemos concluir que, entre los principales desaf\u00edos para lograr la regula- ci\u00f3n del creciente desarrollo y uso de la IA en las diversas etapas de su ciclo de vida, se encuentran: Lograr el consenso, gobernanza y colab - oraci\u00f3n entre organizaciones internacio - nales y regionales, gobiernos, empresas, fabricantes y las m\u00faltiples partes inte - resadas para instaurar est\u00e1ndares, \u00f3r - ganos regulatorios y c\u00f3digos \u00e9ticos que vigilen el desarrollo de la IA; para esto ser\u00e1 imperativo implicar a la sociedad civil en el debate (Gonz\u00e1lez Arencibia & Mart\u00ednez Cordero, 2020). Establecer la metodolog\u00eda y mecanis- mos para evaluar constantemente la proporcionalidad entre los riesgos y beneficios de las tecnolog\u00edas, buscando como meta la seguridad e inocuidad en su implementaci\u00f3n y su uso. Proveer a los ciudadanos, el acceso a los diversos servicios, sin discrimi- naci\u00f3n, ni desigualdad, promoviendo la inclusi\u00f3n y diversidad. La Declaraci\u00f3n Universal sobre Bio\u00e9tica y Derechos Humanos (UNESCO, 2005), constituye una gu\u00eda definida, cuyos principios, co - mo el respeto a la autonom\u00eda y a la in- tegridad personal, la consideraci\u00f3n de la vulnerabilidad humana, la no estig- matizaci\u00f3n, el potenciamiento al m\u00e1xi- mo de los beneficios directos e indirec - tos, as\u00ed como la reducci\u00f3n al m\u00e1ximo de los posibles efectos nocivos, pueden ser extrapolados al \u00e1mbito de la IA. Aminorar el impacto de la energ\u00eda necesaria para mantener la tecnolog\u00eda en funcionamiento y disminuir su hue- lla contaminante en el medio ambiente y en los ecosistemas (Strubell & Ganesh, 2019). Construir un marco regulatorio interna- cional, mediante el cual se busque que la IA no sea un elemento disruptor en la fr\u00e1gil construcci\u00f3n de la cultura de paz. Resulta innegable que el Internet y las redes sociales han logrado el sur - gimiento de un nuevo tipo de interco- nexi\u00f3n y, por lo tanto, de interacci\u00f3n so - cial, que ha marcado el inicio del siglo XXI. En un mundo ideal, esta din\u00e1mica deber\u00eda paliar algunas de las inequi- dades que frenan el desarrollo, ensan- chan las brechas y excluyen a grandes grupos poblacionales (UNESCO, 2021). Lamentablemente, como humanidad no hemos logrado consolidar la aspi- raci\u00f3n de vivir en sociedades pac\u00edficas y justas, por lo que ser\u00eda preocupante que el inadecuado uso de la IA se sume a la crueldad ejercida por individuos o grupos escudados en el anonimato de las redes sociales o, a la incitaci\u00f3n a la violencia o a la apolog\u00eda de delitos. Imagen: freepik.comGaceta44 Referencias -AMM. (octubre de 2016). Declaraci\u00f3n sobre las Consideraciones Eticas de las Bases de Datos de Salud y los Biobancos. Asociaci\u00f3n M\u00e9dica Mundial. Taipei, Taiw\u00e1n: https://www.wma.net/es/policies-post/declaracion-de-la-amm-sobre-las- consideraciones-eticas-de-las-bases-de-datos-de-salud-y-los-biobancos/. -AMM. (octubre de 2019). Declaraci\u00f3n sobre Inteligencia Aumentada en la Atenci\u00f3n M\u00e9dica. Asociaci\u00f3n M\u00e9dica Mun- dial. Tiflis, Georgia: https://www.wma.net/es/policies-post/declaracion-de-la-amm-sobre-inteligencia-aumentada-en- la-atencion-medica/. -Ben-Israel, I. (diciembre de 2020). Towards Regulation of AI Systems. Hac\u00eda una Regulaci\u00f3n de los Sistemas de IA (CAHAI-COE). Estrasburgo, Francia: https://rm.coe.int/prems-107320-gbr-2018-compli-cahai-couv-texte-a4-bat- web/1680a0c17a. -Business Insider. (1 de noviembre de 2022). Chatbots: nuevos aliados en la prevenci\u00f3n de trastornos alimenticios. Business Insider M\u00e9xico, p\u00e1gs. s/p. https://businessinsider.mx/chatbots-ayudan-prevenir-trastornos-alimenticios-es- tudio_ciencia/. -CAHAI-COE. (3 de diciembre de 2021). elements of a legal framework on artificial intelligence, based on the Council of Europe's standards on human rights, democracy and the rule of law. Estrasburgo, Francia: https://rm.coe. int/cahai-2021-09rev-elements/1680a6d90d. -COE. (diciembre de 2021). Reporte sobre el Impacto de la Inteligencia Artificial en la relaci\u00f3n M\u00e9dico Paciente. Co- mit\u00e9 de Derechos Humanos en los campos de la Biomedicina y la Salud del Consejo de Europa. Estrasburgo, Francia: https://rm.coe.int/inf-2022-5-report-impact-of-ai-on-doctor-patient-relations-e/1680a68859. -Coll, F. (8 de septiembre de 2020). Ludismo. Obtenido de Economipedia.com: https://economipedia.com/definicio - nes/ludismo.html -El-Atillah, I. (4 de enero de 2023). Un hombre se suicida despu\u00e9s de que un chat de IA le invitara a hacerlo. Euronews, p\u00e1gs. s/p. https://es.euronews.com/next/2023/04/01/un-hombre-se-suicida-despues-de-que-un-chat-de-ia-le-invi- tara-a-hacerlo. -Frey, C. B., & Osborne, M. A. (17 de septiembre de 2013). The Future of Employment: How Susceptible are Jobs to Com- puterisation? Oxford, R.U.: Obtenido de Oxford Departmen. -Gonz\u00e1lez Arencibia, M., & Mart\u00ednez Cardero, D. (2020). Dilemas \u00e9ticos en el escenario de la inteligencia artificial. Econom\u00eda y Sociedad, 93-109. -HCHR. (2018). Art\u00edculo 25, Serie de art\u00edculos publicados en conmemoraci\u00f3n del 70 aniversario de la Declaraci\u00f3n Uni- versal de Derechos Humanos. Oficina del Alto Comisionado para los Derechos Humanos. M\u00e9xico: https://hchr.org. mx/wp/wp-content/themes/hchr/images/30acerca30/Art%C3%ADculo_25.pdf. -OPS. (2021). La Inteligencia Artificial en la Salud P\u00fablica. Organizaci\u00f3n Panamericana de la Salud. Washington, D.C., EE.UU.: https://iris.paho.org/bitstream/handle/10665.2/53887/OPSEIHIS21011_spa.pdf?sequence=5&isAllowed=y. -Rafferty, J. P. (s/f). The Rise of the Machines: Pros and Cons of the Industrial Revolution. Encyclopedia Britannica, https://www.britannica.com/story/the-rise-of-the-machines-pros-and-cons-of-the-industrial-revolution. -Redacci\u00f3n RT. (4 de junio de 2023). Un 'chatbot' que reemplaz\u00f3 a trabajadores de una l\u00ednea de ayuda contra los trastornos alimenticios da consejos da\u00f1inos y peligrosos. RT , p\u00e1gs. s/p. https://actualidad.rt.com/actualidad/469152- chatbot-linea-trastornos-alimenticios-consejos-daninos-peligrosos. -RELE-CIDH. (31 de marzo de 2023). Comunicado de prensa R54/23. Relator\u00eda Especial para la Libertad de la Orga- nizaci\u00f3n Estados Americanos, https://www.oas.org/es/cidh/expresion/showarticle.asp?lID=2&artID=1271. Washing- ton D.C., EE.UU.: https://www.oas.org/es/cidh/expresion/showarticle.asp?lID=2&artID=1271. -Scheiber, N. (4 de mayo de 2023). \u00bfLa pr\u00f3xima 'Succession' ser\u00e1 escrita por un chatbot? Obtenido de The New York Times: https://www.nytimes.com/es/2023/05/04/espanol/guionistas-huelga-ia.html -Strubell, E., & Ganesh, A. (07 de 2019). Energy and Policy Considerations for Deep Learning in NLP. 57th Annual Meet - ing of the Association for Computational Linguistics. Florence, Italy: College of Information and Computer Sciences, University of Massachusetts. Obtenido de Cornell University: https://doi.org/10.48550/arXiv.1906.02243 -The White House. (octubre de 2022). Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People. Plan para una Declaraci\u00f3n de Derechos de IA. Washington D.C., EE.UU.: https://www.whitehouse. gov/ostp/ai-bill-of-rights/. -UNESCO. (19 de octubre de 2005). Declaraci\u00f3n Universal sobre Bio\u00e9tica y Derechos Humanos. Paris, Francia: https:// unesdoc.unesco.org/ark:/48223/pf0000146180_spa. -UNESCO. (23 de noviembre de 2021). Recomendaci\u00f3n sobre la \u00e9tica de la Inteligencia Artificial. Paris, Francia: https:// unesdoc.unesco.org/ark:/48223/pf0000380455_spa. Gaceta45 escenario internacional Es posible que el 30 de noviembre de 2022 haya sido un punto de inflexi\u00f3n en el proce - so de cambio tecnol\u00f3gico en curso. Ese fue el d\u00eda en que se liber\u00f3 al p\u00fablico en general la versi\u00f3n 3.5 del algoritmo conversacional ChatGPT. De acuerdo a s\u00ed mismo, \"ChatGPT es un modelo de lenguaje desarrollado por OpenAI. Se basa en la arquitectura GPT-3.5 y ha sido entrenado con una amplia variedad de datos y textos para comprender y gene - rar respuestas en lenguaje natural. ChatGPT est\u00e1 dise\u00f1ado para interactuar con los usua- rios a trav\u00e9s de conversaciones en l\u00ednea, pro - porcionando respuestas coherentes y con- textualmente relevantes a las consultas y solicitudes de los usuarios. Es capaz de com- prender preguntas, brindar informaci\u00f3n, ofrecer sugerencias y participar en conver - saciones de manera similar a como lo har\u00eda un humano\" (cursivas agregadas)\".1 Aunque la tecnolog\u00eda en s\u00ed misma no es tan novedosa, ha sido justamente esa capacidad de generar respuestas similares a las huma- nas (que ahora le permite incluso trabajar con im\u00e1genes, en su versi\u00f3n 4.0) y su masivi- dad las que han dado lugar a dos actitudes que hoy prevalecen en la conversaci\u00f3n sobre IA y que podemos asociar, un poco laxamen- te, con el \"bombo\" (hype), por un lado; y con una suerte de distop\u00eda pesimista, que ha sido expresada en su versi\u00f3n extrema como un temor a que la inteligencia artificial aca- be con la humanidad, por el otro.2 Creo que esas dos concepciones funcionan en el debate p\u00fablico acerca de los usos de modelos de lenguaje ampliado como Chat - GPT m\u00e1s como distractores que como herra- mientas para ayudarnos a pensar cu\u00e1l debe ser nuestro pr\u00f3ximo paso. C\u00f3mo yo lo veo, ambas perspectivas est\u00e1n basadas en una concepci\u00f3n acerca de la tecnolog\u00eda que me gustar\u00eda cuestionar (una visi\u00f3n desmateriali- 1 Consultado el 13 de junio de 2023. 2 \"Expert Says There's a 50% Chance AI Will Wipe out Humanity\" Daily Mail Online,https://www.dailymail. co.uk/sciencetech/article-12151967/Expert-says-theres- 50-chance-AI-wipe-humanity.html, consultado el 13 de junio de 2013. Los desaf\u00edos \u00e9ticos y cient\u00edficos de ChatGPT en salud: utopismo, tecnofobia y pragmatismo Luis Garc\u00eda Vali\u00f1a* e Ignacio Mastroleo** zada y abstracta), para luego sugerir que sea reemplazada por otra, que llamar\u00e9 \"prag- matista\". Creo que este reemplazo tiene su importancia, dado que los pasos iniciales (y el temperamento intelectual con el que se los determina) con relaci\u00f3n a una tecnolog\u00eda condicionan fuertemente los movimientos ulteriores. Habiendo tanto en juego, lo mejor ser\u00eda que acertemos de entrada. Empecemos con la posici\u00f3n \"exagerada- mente entusiasmada\". Tres art\u00edculos recien- tes, uno general y dos espec\u00edficos a los usos m\u00e9dicos, han reportado que la comunidad m\u00e9dica sigue con inter\u00e9s y expectativa la po - sibilidad de usar ChatGPT para la investiga- ci\u00f3n (Deng, 2022; Sallam, 2023; Li, 2023). De acuerdo a estos relevamientos preliminares, aun cuando de momento no existen usos de ChatGPT suficientemente probados para su uso regular en la atenci\u00f3n de la salud p\u00fabli- ca o la pr\u00e1ctica m\u00e9dica cl\u00ednica,3 los investi- gadores est\u00e1n interesados en usar ChatGPT para lograr m\u00e1s eficiencia en la escritura acad\u00e9mica y la traducci\u00f3n de textos (en caso de investigadores de pa\u00edses no angloparlan tes), en el procesamiento de datos y tambi\u00e9n 3 Por lo tanto, cualquier uso de ChatGPT en salud hu- mana deber\u00eda considerarse experimental o no probado en un sentido amplio, a saber, o bien ser un uso de in- vestigaci\u00f3n (cl\u00ednica o de salud p\u00fablica) para desarrollar conocimiento generalizable, o bien es un caso de pr\u00e1c - tica nueva no validada en beneficio de un paciente o poblaci\u00f3n (popularmente conocido como innovaci\u00f3n m\u00e9dica) (Mastroleo y Holzer 2020). En cualquier caso, su uso responsable deber\u00eda cumplir con las protecciones y criterios \u00e9ticos generales para los usos de intervencio - nes de salud no probadas dentro o fuera de ensayos cl\u00ed- nicos (p.e. AMM 2013, CIOMS-OMS 2016, OPS 2022a, cap. 5, WHO 2022a), adem\u00e1s de las consideraciones especia- les para los usos de IA para la salud (p.e. WHO 2021).* Doctor en Filosof\u00eda; Profesor universitario; ha sido be - cario posdoctoral; colabora con el CRIION, Alemania; Investigador y Coordinador Acad\u00e9mico, Programa de Bio\u00e9tica, FLACSO Argentina; trabajo interdisciplinario sobre las implicancias \u00e9ticas, sociales y pol\u00edticas de la Inteligencia Artificial. ** Investigador y Director Asociado, Programa de Bio\u00e9ti- ca, FLACSO Argentina; Investigador, CONICET; Profesor universitario; recibi\u00f3 una beca de la Fundaci\u00f3n Mertels- mann, con un proyecto de an\u00e1lisis \u00e9tico-filos\u00f3fico sobre el uso de la Inteligencia Artificial para la salud; Afiliado al CRIION, Alemania.Gaceta46 en la revisi\u00f3n de la literatura, entre otras co - sas. Incluso algunos imaginan la posibilidad de que un algoritmo conversacional pueda ayudar a identificar nuevas hip\u00f3tesis y m\u00e9 - todos; es decir, no s\u00f3lo como una \"base de datos inteligente\" sino como una verdadera herramienta de mejora cognitiva, en el es- p\u00edritu de lo que William Schwartz imagina- ba en un paper de 1970 (citado en Li, 2023): \"los agentes conversacionales podr\u00edan servir como consultores en mejorar las funciones intelectuales de los m\u00e9dicos a trav\u00e9s de las interacciones\". Con respecto al proceso cl\u00edni- co, los especialistas mencionan las ventajas para la medicina personalizada, la predic - ci\u00f3n de riegos de enfermedades y resultados de tratamientos, mejorando el flujo cl\u00ednico, los diagn\u00f3sticos y la documentaci\u00f3n, dismi- nuyendo costos y mejorando la educaci\u00f3n de los profesionales (op cit.). El problema es que es f\u00e1cil pasar de estas expectativas (bastante naturales y hasta justificadas, si atendemos a la verdadera ex - plosi\u00f3n de aplicaciones ocurrida en apenas unos meses, especialmente aquellas desti- nadas a mejorar el proceso de investigaci\u00f3n) al \"hype\" ut\u00f3pico. Eric Topol, por ejemplo, ha sido uno de los m\u00e1s vigorosos defensores del uso de IA en medicina. Para Topol, el uso sistem\u00e1tico y generalizado de IA permitir\u00e1 eliminar buena parte de las actividades administrativas que actualmente deben realizar los m\u00e9dicos, li- berando tiempo para proporcionar un mejor tratamiento y restableciendo \"la preciada y consagrada conexi\u00f3n y confianza -el contac - to humano- entre pacientes y m\u00e9dicos.\" (To - pol, 2019: 32). Hay un elemento de solucionismo tecnol\u00f3 - gico (Morozov, 2016) o \"tecnochauvinismo\" (Broussard, 2018) subyacente en estas pala- bras; es decir, la convicci\u00f3n de que los pro - blemas \u00e9ticos y pol\u00edticos que enfrenta la hu- manidad (muchos de los cuales son de larga data) pueden ser interpretados en t\u00e9rminos de un fallo de dise\u00f1o y solucionados me - diante la tecnolog\u00eda. Sin embargo, el problema con esta perspec - tiva es su reduccionismo; es decir, el modo en que falla en considerar la complejidad de los problemas sociales, por un lado; y el ca- r\u00e1cter materializado de los procesos de auto - matizaci\u00f3n, su imbricaci\u00f3n con el \"mundo de la vida\" y el resto de los procesos que inter - vienen en la experiencia humana, por el otro. A modo de ejemplo, podemos retomar la promesa de mejorar la investigaci\u00f3n cien- t\u00edfica usando algoritmos como ChatGPT. Considerado s\u00f3lo como un \"modelo de pro - cesamiento de lenguaje natural basado en la arquitectura GPT\"; es decir, como un algo - ritmo inform\u00e1tico o incluso un modelo ma- tem\u00e1tico, ciertamente las expectativas no son infundadas. Ahora bien, considerar esta perspectiva de modo aislado e independien- te de las arquitecturas materiales y sistemas de incentivos que operan en un sistema de investigaci\u00f3n real, puede redundar en resul- tados inesperados. Por ejemplo, \u00bfes el finan- ciamiento (siempre escaso) dependiente del n\u00famero de publicaciones? \u00bfC\u00f3mo es ese sistema de publicaciones, de pago o abier - to? Seg\u00fan la respuesta a estas preguntas (y otras), podr\u00eda ocurrir que, por ejemplo, los investigadores, presionados por el dictum \"La regi\u00f3n de las Am\u00e9ricas tiene un d\u00e9ficit de 600.000 profesionales (OPS, 2022b). A nivel mundial, se estim\u00f3 antes del COVID-19 que ser\u00edan necesarios 10 millones m\u00e1s de profesionales de la salud para 2030...\".Gaceta47 escenario internacional de \"publica o muere\", decidan relajar los es- t\u00e1ndares de control humano y depender en los resultados de ChatGPT, sin controlarlos o discutirlos. Existiendo ya numerosos casos de publicaciones apresuradas, plagio, etc., la introducci\u00f3n de ChatGPT puede de hecho terminar fomentando la ciencia irresponsa- ble. Esto nos expone al riesgo de tener \"m\u00e1s\" investigaci\u00f3n, pero de menor calidad. Por otro lado, se ha puesto, y con raz\u00f3n, un \u00e9nfasis especial en el modo en que los algo - ritmos pueden estar sesgados, pero no se habla mucho acerca del sesgo humano (de automatizaci\u00f3n, de autoridad, el efecto de statu quo, etc.) y de los elementos que pue - den afectar su relaci\u00f3n con los sistemas de IA (diferencias de temperamento y trasfon- do cultural, educaci\u00f3n, etc.). Como sostienen Kostick-Quenet y Gerke, tenemos que am- pliar \"nuestra noci\u00f3n de pruebas de usuario m\u00e1s all\u00e1 de su enfoque actual en las m\u00e9tricas de rendimiento de la IA y la usabilidad pr\u00f3xi- ma para examinar los factores humanos y sist\u00e9micos que dan forma a c\u00f3mo los siste - mas de IA son aplicados en la pr\u00e1ctica por usuarios imperfectos en entornos imperfec - tos.\" (Kostick-Quenet y Gerke, 2022, p. 2). Otro ejemplo tiene que ver con el creciente desarrollo de aplicaciones conversacionales en el contexto de la salud mental. Seg\u00fan la Organizaci\u00f3n Mundial de la Salud, \"los tras- tornos mentales son uno de los retos de sa- lud p\u00fablica m\u00e1s importantes en la Regi\u00f3n Europea de la OMS, ya que son la principal causa de discapacidad y la tercera causa de carga global de morbilidad.\" (OMS 2019, cita- do en Sedlakova, 2022). Sin embargo, un fe - n\u00f3meno creciente que plaga los sistemas de salud es la escasez de personal (Butryn, 2017). La regi\u00f3n de las Am\u00e9ricas tiene un d\u00e9ficit de 600.000 profesionales (OPS, 2022b). A nivel mundial, se estim\u00f3 antes del COVID-19 que ser\u00edan necesarios 10 millones m\u00e1s de profe - sionales de la salud para 2030 (WHO, 2022b). Los agentes conversacionales podr\u00edan ayu- dar en este contexto o en situaciones de pico de demanda (p.e. en una emergencia de sa- lud p\u00fablica), pero tambi\u00e9n podr\u00edan empeo -rar la situaci\u00f3n si no est\u00e1n suficientemente validados; o impedir a los Estados invertir en formaci\u00f3n e infraestructura, perpetuando las inequidades en el acceso, la seguridad y la eficacia del tratamiento. Por ejemplo, en- tre quienes pueden acceder a profesionales humanos, quienes acceder\u00edan a un chatbot \"guiado\" por profesionales y quienes deben conformarse con un chatbot \"no guiado\" (Graber-Stiehl, 2023). Nuevamente, debemos considerar los efec - tos de la implementaci\u00f3n de sistemas de au- tomatizaci\u00f3n evitando asumir una posici\u00f3n reduccionista, que entiende la tecnolog\u00eda como una entidad inmaterial, un construc - to matem\u00e1tico o una aplicaci\u00f3n algor\u00edtmica. Por el contrario, sugiero seguir a la fil\u00f3sofa Kate Crawford cuando sostiene que, \"com- prendemos mejor el papel de la IA en el mundo a trav\u00e9s de sus arquitecturas mate - riales, sus entornos contextuales y las pol\u00ed- ticas imperantes, as\u00ed como de sus conexio - nes.\" (Crawford, 2021: 12) Es decir, debemos pasar a ver a sistemas como ChatGPT en un sentido sociot\u00e9cnico (Graham, 2021), como un conjunto de pr\u00e1cticas, instituciones, es- tructuras materiales, sistemas econ\u00f3micos y sociales, restricciones pol\u00edticas, etc. Pero estar atentos a la \"econom\u00eda pol\u00edtica\" de la IA no deber\u00eda llevarnos hacia el extre - mo opuesto al tecnopotimismo acr\u00edtico; es decir, a una visi\u00f3n tecnof\u00f3bica que solo pue - de ver en la automatizaci\u00f3n una amenaza y una herramienta para la reificaci\u00f3n de la in- justicia y las asimetr\u00edas de poder. Como se\u00f1alan Sparrow and Hatherley, cri- ticando justamente la tendencia de Topol a enfocarse m\u00e1s en la tecnolog\u00eda que en la sociedad, \"todo ahorro de tiempo vuelto po - sible por una reducci\u00f3n en la carga adminis- trativa de los m\u00e9dicos...ser\u00e1 usada para mo - ver m\u00e1s pacientes a trav\u00e9s del sistema, antes que para permitirles a los m\u00e9dicos pasar m\u00e1s tiempo y ocuparse mejor de ellos\" (2020:14). Sin embargo, este resultado depende, otra vez, de los incentivos, de las interacciones con otros puntos del sistema. No se trata, en Gaceta48 todo caso, de un rasgo inherente a la tecno - log\u00eda, sino al modo en que se operacionaliza en un contexto y con determinados objeti- vos en vista. Debemos, entonces, adoptar una posici\u00f3n pragm\u00e1tica. Esto implica, en esencia, aban- donar las idealizaciones asociadas a los usos potenciales de ChatGPT y enfocarnos en: - Los usos concretos proyectados (\u00bfes una aplicaci\u00f3n para la asistencia virtual a pa- cientes? \u00bfpara resumir historias cl\u00ednicas? \u00bfse usar\u00e1 para la traducci\u00f3n de textos acad\u00e9mi- cos?). - Las interacciones con otros sistemas en uso (\u00bfayudar\u00e1 a consolidar la provisi\u00f3n de salud y la investigaci\u00f3n o contribuir\u00e1 por el contrario a erosionar otros sistemas sin un beneficio tangible? \u00bfes necesario usar IA o es suficien- te alg\u00fan otro sistema actualmente en opera- ci\u00f3n mejor validado y m\u00e1s costo-eficiente?). -El modo en que afectan otros criterios re - levantes (\u00bfmejora esta aplicaci\u00f3n la relaci\u00f3n entre pacientes y profesionales de salud? \u00bfimplica un balance inapropiado entre la eficiencia y la privacidad, la explicabilidad o la transparencia? \u00bfSi las nuevas versiones de ChatGPT se entrenan usando datos con poblaciones que no tienen capacidad de pago, existen los mecanismos apropiados para compartir beneficios equitativos? \u00bfSi estas tecnolog\u00edas est\u00e1n protegidas por dere -chos exclusivos o secreto comercial, estar\u00e1n disponibles, ser\u00e1n apropiadas y econ\u00f3mi- camente asequibles para investigadoras/es, profesionales de salud y pacientes?). Estas preguntas (que seguramente deber\u00e1n ser complementadas por otras, en un es- quema de evaluaci\u00f3n completo) se dirigen a un mismo punto: la evaluaci\u00f3n de los usos de ChatGPT y otras tecnolog\u00edas similares no puede ser hecha a priori ni de acuerdo a una concepci\u00f3n general de la inteligencia arti- ficial; por el contrario, la actitud adecuada debe ser pragm\u00e1tica, orientada a las con- secuencias concretas y tangibles de un uso potencial en un contexto espec\u00edfico y cuali- tativamente determinado. En resumen, el verdadero desaf\u00edo \u00e9tico es cambiar el marco conceptual para evaluar la innovaci\u00f3n tecnol\u00f3gica. Debemos asumir, en palabras del fil\u00f3sofo norteamericano Wi- lliam James, la actitud de apartarnos de \"las primeras causas, principios, categor\u00edas, su- puestas necesidades, y de mirar hacia las co - sas \u00faltimas, frutos, consecuencias, hechos\" (1948: 144). De este modo podemos evitar las tendencias gemelas a la exageraci\u00f3n y la tecnofobia y ganar una perspectiva razo - nable acerca de los riesgos y desaf\u00edos de los modelos de lenguaje ampliado como Chat - GPT. Referencias -Asociaci\u00f3n M\u00e9dica Mundial (AMM). Declaraci\u00f3n de Helsinki de la AMM. Principios \u00e9ticos para las investigaciones m\u00e9 - dicas en seres humanos [Internet]. 2013 [citado Causes, Current State, and Potential So - lutions.\" of Academic Medicine, India, 2017. https://www.ijam-web.org/article.asp?issn=2455- 5568;year=2017;volume=3;issue=1;spage=5;epage=9;aulast=Butryn. -Crawford, Kate. AI: Power, Politics, and the Planetary Costs of Artificial Intelligence. Yale University Press, 2021. https://doi.org/10.2307/j.ctv1ghv45t. -Consejo de Organizaciones Internacionales de las Ciencias M\u00e9dicas (CIOMS) en colaboraci\u00f3n con la Organizaci\u00f3n Mundial de la Salud (OMS) (CIOMS-OMS). Pautas \u00e9ticas internacionales para la investigaci\u00f3n relacionada con la salud con seres humanos [Internet]. 2016 [citado 10 de octubre An Overview.\" Frontiers in 2 (2022): 81-83. https://doi.org/10.54097/fcis.v2i2.4465. -\"Expert Says There's a 50% out Humanity | Daily Mail Online.\" Accessed June 13, 2023. https:// www.dailymail.co.uk/sciencetech/article-12151967/Expert-says-theres-50-chance-AI-wipe-humanity.html.Gaceta49 escenario \"Is the World Ready 22-24. Doctor and the Algorithm: Promise, Peril, and the Future of Health AI. New York: Oxford Univer - sity Press, 2022. -James, William. Pragmatism. New York: Hafner Publishing Co., 1948. Kostick-Quenet, Kristin M., \"AI in the Hands of Imperfect Users.\" 1-6. https://doi.org/10.1038/s41746-022-00737-z. -Li, Jianning, F. New non-validated practice: an enhanced definition of innovative practice for medicine. Law, In- novation and Technology. 2 de julio de 2020; 12(2):318-46. -Morozov, Evgeny. La Locura Katz Editores, 2016. https://www.eldiplo.org/ wp-content/uploads/2018/files/6314/6463/4693/LaLocuradelSolucionismoTecnologico-Morozov-Introduccion.pdf. -Organizaci\u00f3n Panamericana de la Salud (OPS). Catalizar La Investigaci\u00f3n \u00c9tica En Emergencias. Orientaci\u00f3n \u00c9tica, Lecciones Aprendidas de La Pandemia de COVID-19 y Agenda Pendiente. Washington DC: OPS, 2022a. https://iris. paho.org/bitstream/handle/10665.2/56104/OPSHSSBIOCOVID-19220019_spa.pdf?sequence=5&isAllowed=y. -Organizaci\u00f3n Panamericana de la Salud (OPS). Las Am\u00e9ricas tienen un d\u00e9ficit de 600.000 profesionales de la salud, que afecta el acceso a la salud en las zonas rurales y desatendidas [Internet]. 2022b. [citado 13 Valid no. 887. -Schwartz, William B. \"Medicine and the Computer: The Promise and Problems of Change.\" New England Journal of Medicine 283, no. 23 (December 3, 1970): 1257-64. https://doi.org/10.1056/NEJM197012032832305. -Sedlakova, Jana, and in Psychotherapy: A New Therapeutic Tool or Agent?\" The American Journal of Bioethics 23, no. 5 (May 4, 2023): 4-13. https://doi.org/10.1080/15265161.2022.2048739. and Joshua Hatherley. \"High Hopes 'Deep Medicine'? AI, Economics, and the Future of Care.\" Hastings Center Report 50, no. 1 (2020): 14-17. https://doi.org/10.1002/hast.1079. -\"The Superhero of Artificial Intelligence: Can This Genius Keep It in Check? | Artificial Intelligence (AI) | The Guardian.\" Accessed June 13, 2023. https://www.theguardian.com/technology/2016/feb/16/demis-hassabis-artificial-intelligence- deepmind-alphago. -Topol, Eric J. Deep Medicine: How Artificial Intelligence Can Make Healthcare Human Again. First edition. New York: Basic Books, 2019. -World Health Organization (WHO). Ethics and governance of artificial intelligence for health [Internet]. Geneva: World Health Organization. Health Ethics & Governance Team; 2022]. xii, 43 p. Disponible en: https://apps.who.int/iris/handle/10665/352902. -World Health Organization (WHO). Global Strategy for Health: Workforce World news/item/02-06-2022-global-strategy-on-human-resources-for-health--workforce-2030. Imagen: freepik.comGaceta50 Resultados de las encuestas sobre la percepci\u00f3n de sesiones conjuntas entre el CEI, CI, CB o CICUAL aplicadas a los Comit\u00e9s de \u00c9tica en Investigaci\u00f3n y a las Comisiones Estatales de Bio\u00e9tica Areli Cer\u00f3n S\u00e1nchez, Gabriela Pineda Hern\u00e1ndez, Karla Alejandra Tovar L\u00f3pez, Karla Gabriela S\u00e1nchez Villanueva y Flor de Mar\u00eda Cruz Estrada* Un elemento \u00e9tico imprescindible, a nivel nacional e internacional, es la evaluaci\u00f3n de toda propuesta de investigaci\u00f3n que in- volucra seres humanos por un Comit\u00e9 de \u00c9tica en Investigaci\u00f3n (CEI). Estos son, un grupo multidisciplinario de expertos con autonom\u00eda, plurales, consultivos, institucio - nales, y con independencia al grupo de in- vestigaci\u00f3n involucrado. Tienen objetivos y funciones definidas en los criterios que ha establecido la Comisi\u00f3n Nacional de Bio\u00e9ti- ca (CONBIO\u00c9TICA), a trav\u00e9s de las Disposi- ciones Generales1 y la Gu\u00eda Nacional2. La evaluaci\u00f3n de un protocolo de investiga- ci\u00f3n debe realizarse desde el punto de vista \u00e9tico, metodol\u00f3gico, normativo, y cuando aplique de bioseguridad. En el caso de M\u00e9 - xico, a diferencia de otros pa\u00edses, esta la de - ben realizar el CEI, el Comit\u00e9 de Investiga- ci\u00f3n (CI), y el Comit\u00e9 de Bioseguridad (CB), cuando aplique. Los tres comit\u00e9s deber\u00e1n emitir su dictamen favorable como requisi- to previo para dar inicio a la investigaci\u00f3n, adicionalmente, en los casos que involucren insumos para la salud con fines de registro sanitario3 deber\u00e1n solicitar la autorizaci\u00f3n de la Comisi\u00f3n Federal para la Protecci\u00f3n Contra Riesgos Sanitarios (COFEPRIS). Por lo anterior, la regulaci\u00f3n mexicana4 prev\u00e9 que el CEI, el CI y el CB podr\u00e1n sesionar en conjunto, actividad fuertemente recomen- 1 ACUERDO por el que se emiten las Disposiciones Generales para la Integraci\u00f3n y Funcionamiento de los Comit\u00e9s de \u00c9tica en Investigaci\u00f3n y se establecen las unidades hospitalarias que deben contar con ellos, de conformidad con los criterios establecidos por la Comisi\u00f3n Nacional de Bio\u00e9tica, publicado en el DOF (31/10/2012), as\u00ed como sus modificaciones publicadas en el DOF el (11/01/2016) y el (10/12/2020). 2 Gu\u00eda Nacional para la Integraci\u00f3n y Funcionamien- to de los CEI, 2018, disponible en: https://www.gob. mx/cms/uploads/attachment/file/460756/7_Guia_ CEI_2018_6a.pdf 3 Insumos para la salud: Incluye medicamentos, vacu- nas, bil\u00f3gicos o dispositivos m\u00e9dicos. 4 Art\u00edculo 102 del Reglamento de la Ley General de Sa- lud en Materia de Investigaci\u00f3n para la Saluddada para favorecer una evaluaci\u00f3n integral de las propuestas de investigaci\u00f3n. Adem\u00e1s, las sesiones conjuntas reducen los tiempos de evaluaci\u00f3n y favorecen el inicio de la investiga- ci\u00f3n en el menor tiempo posible. En los casos en que, en el establecimiento tambi\u00e9n se rea- licen proyectos de investigaci\u00f3n con modelos animales no humanos, e integren un Comit\u00e9 Interno para el Cuidado y Uso de los Animales de Laboratorio (CICUAL) de conformidad con la NOM-062-ZOO-1999, tambi\u00e9n se sugiere ex - plorar la posibilidad de adherirse a las sesiones conjuntas con los CEI, CI y CB. Con base en lo anterior, la CONBIO\u00c9TICA di- se\u00f1\u00f3 e implement\u00f3 dos encuestas de sondeo con el objetivo de explorar la percepci\u00f3n de los CEI con respecto a las sesiones conjuntas de distintos comit\u00e9s: CEI, CI, CB y CICUAL. Asi- mismo, se decidi\u00f3 explorar el tema en paralelo con las Comisiones Estatales de Bio\u00e9tica (CEB), cuerpos consultivos con car\u00e1cter multidiscipli- nario e interinstitucional, creados en las entida- des federativas para extender la observaci\u00f3n y pr\u00e1ctica de los principios bio\u00e9ticos y derechos humanos a trav\u00e9s de capacitaci\u00f3n, asesor\u00eda y difusi\u00f3n de la bio\u00e9tica en la atenci\u00f3n m\u00e9dica e investigaci\u00f3n, por lo que entre sus actividades est\u00e1 promover el cumplimiento de las dispo - siciones para que en los establecimientos que realicen investigaci\u00f3n con seres humanos y se integren los CEI. Para fines de las citadas encuestas se en- tiende por: Sesi\u00f3n conjunta: A la sesi\u00f3n para evaluar un protocolo de investigaci\u00f3n en la que participan el CEI, CI y cuando aplique el CB, con el objetivo de evaluar los aspectos \u00e9ticos, metodol\u00f3gicos, de bioseguridad y normativos en conjunto. *Directora de Comit\u00e9s de Bio\u00e9tica, Directora de Desa- rrollo Institucional, Jefa del Departamento de Apoyo a Comisiones Estatales de Bio\u00e9tica, Subdirectora de En- lace con Comisiones Estatales de Bio\u00e9tica y Jefa de De - partamento de Registro de Comit\u00e9s de \u00c9tica en Investi- gaci\u00f3n, respectivamente.Gaceta51 Dictamen conjunto: Al documento por escrito emitido en conjunto por los CEI, CI y cuando aplique por el CB respecto a la propuesta de investigaci\u00f3n evaluada. RESULTADOS A. ENCUESTA APLICADA A LOS CEI Se utiliz\u00f3 como t\u00e9cnica la encuesta y como instrumento un formulario en Google Forms, construido espec\u00edficamente para el objetivo antes descrito. El formulario elec - tr\u00f3nico de auto-aplicaci\u00f3n estuvo integrado por cinco preguntas, tanto de selecci\u00f3n m\u00fal- tiple, como abiertas. El periodo de recep - ci\u00f3n de respuestas fue del 24 de abril al 31 de mayo del 2023. Al respecto, se recibieron 101 respuestas de los CEI, lo que representa el 28% del total de comit\u00e9s registrados ante CONBIO\u00c9TICA. La distribuci\u00f3n de estos, por entidad federativa se muestra en la figura 1. Figura 1. Distribuci\u00f3n de los CEI que atendieron la encuesta por entidad federativa (N=101). FUENTE: Comisi\u00f3n Nacional de Bio\u00e9tica, elaboraci\u00f3n propia.A continuaci\u00f3n, el an\u00e1lisis gr\u00e1fico de las res- puestas a las cinco preguntas, se desglosa con mayor detalle. Primero se les pregunt \u00f3 a los comit\u00e9s si: 1) \u00bfSu CEI realiza sesiones conjuntas con el Comit\u00e9 de Investigaci\u00f3n (CI), el Comit\u00e9 de Bioseguridad (CB) o el CICUAL de su esta- blecimiento? Los resultados se describen en las figuras 2 y 3 para mayor referencia. Figura 2. Porcentaje de CEI que sesionan en conjunto con otros comit\u00e9s (N=101). FUENTE: Comisi\u00f3n Nacional de Bio\u00e9tica, elaboraci\u00f3n propia.tareas y perspectivasGaceta52 Aquellos CEI que han sesionado en conjun- to con alguno de los comit\u00e9s (CI, CB y/o CI- CUAL), con base en una escala del 1 al 10 (en la que 1 es nada \u00fatil y 10 es muy \u00fatil), com-Figura 3. N\u00famero de CEI que sesionan en conjunto con otros comit\u00e9s (N=72). Considere que un mismo CEI puede sesionar con m\u00e1s de 1 comit\u00e9. FUENTE: Comisi\u00f3n Nacional de Bio\u00e9tica, elaboraci\u00f3n propia. Figura 4. Percepci\u00f3n de la discusi\u00f3n y an\u00e1lisis en las sesiones conjuntas entre comit\u00e9s, en t\u00e9rminos de porcentaje (N=61). FUENTE: Comisi\u00f3n Nacional de Bio\u00e9tica, elaboraci\u00f3n propia.partieron su percepci\u00f3n respecto a la discu- si\u00f3n y an\u00e1lisis conjunto. La cual se describe en la figura 4.Gaceta53 Tambi\u00e9n, se indag\u00f3 con los CEI su percepci\u00f3n respecto a la utilidad de las sesiones conjun- tas contemplando seis preguntas, las res- puestas a estas se describen en la figura 5. Figura 5. Percepci\u00f3n de utilidad de las sesiones conjuntas por los CEI (N=101). FUENTE: Comisi\u00f3n Nacional de Bio\u00e9tica, elaboraci\u00f3n propia. Otro elemento importante por conocer fue: \u00bfCu\u00e1les son las problem\u00e1ticas que ha en- frentado o enfrentar\u00eda el CEI en la evaluaci\u00f3n de protocolos en conjunto con el CI, CB y/o CICUAL? A continuaci\u00f3n, se enlistan algunas de las problem\u00e1ticas referidas por los CEI: Dificultad para reunir a todos los integrantes y/o el qu\u00f3rum requerido Divergencia de opiniones entre los comit\u00e9s Prolongaci\u00f3n de la sesi\u00f3n Log\u00edstica de la sesi\u00f3n Disponibilidad de espacio adecuado para sesionar en conjunto Delimitaci\u00f3n de funciones entre los comit\u00e9s Actualizaci\u00f3n de los manuales de proce - dimientos y/o reglamentaci\u00f3n interna Participaci\u00f3n de personal directivo en los Comit\u00e9s de Investigaci\u00f3n, en tanto que en los CEI no est\u00e1 permitido Potenciales conflictos de inter\u00e9s y coer - ci\u00f3n Comit\u00e9s de reciente creaci\u00f3n Inexistencia de los otros comit\u00e9s en el establecimientotareas y perspectivasGaceta54 Finalmente, se examin\u00f3 la percepci\u00f3n de los CEI respecto a que las sesiones conjuntas sean obligatorias. En la figura 6 se represen- tan las respuestas obtenidas. Los resultados se dan a conocer \u00fanicamente con fines informativos, y al mismo tiempo, coadyuvar a visualizar la implementaci\u00f3n actual de las sesiones conjuntas entre comi- t\u00e9s, con el objetivo de robustecer la evalua- ci\u00f3n \u00e9tica, metodol\u00f3gica, de bioseguridad y normativa de los protocolos de investigaci\u00f3n que se desarrollen en M\u00e9xico. B. ENCUESTA APLICADA A LAS CEB La Encuesta sobre sesiones conjuntas de Co - mit\u00e9s aplicada a las Comisiones Estatales de Bio\u00e9tica, se implement\u00f3 del 24 de abril al 02 de junio presente a\u00f1o. En dicha encues- ta participaron 24 entidades federativas, lo que representa un 75% de participaci\u00f3n respecto al total nacional. Las CEB partici- pantes fueron Aguascalientes, Baja Califor - nia, Campeche, Ciudad de M\u00e9xico, Coahuila, Colima, Durango, Estado de M\u00e9xico, Guana- juato, Guerrero, Hidalgo, Jalisco, Michoac\u00e1n, Morelos, Nayarit, Nuevo Le\u00f3n, Puebla, Quin- tana Roo, San Luis Potos\u00ed, Sonora, Tabasco, Tlaxcala, Veracruz y Zacatecas. Es importante destacar que la representa- ci\u00f3n de los integrantes de la CEB en la pos- tura y respuestas brindadas se encontr\u00f3 que 36% se resolvi\u00f3 con mayor\u00eda simple, 20% por unanimidad de sus integrantes, 12% por mayor\u00eda calificada y 32% report\u00f3 otra situa- ci\u00f3n. Con ello, 68% de las respuestas fueron discutidas por el equipo multidisciplinario que conforma a las Comisiones Estatales de Bio\u00e9tica, mientras que las CEB restantes re - portaron casos en los que un solo represen- tante fue el que contest\u00f3. En relaci\u00f3n con la percepci\u00f3n sobre las sesio - nes conjuntas, se destaca que al menos 75% de las CEB participantes (18) consideran po - sitiva la realizaci\u00f3n de sesiones conjuntas en diferentes rubros, como: facilitar la emisi\u00f3n del dictamen (76%); simplificar los tiempos en la evaluaci\u00f3n de los protocolos recibidos (76%); facilitar la revisi\u00f3n de protocolos (84%), Figura 6. Percepci\u00f3n de los CEI respecto a que las sesiones conjuntas sean obligatorias, en t\u00e9rminos de porcentaje (N=101). FUENTE: Comisi\u00f3n Nacional de Bio\u00e9tica, elaboraci\u00f3n propia.Gaceta55 y mejorar las acciones encaminadas a prote - ger al participante en la investigaci\u00f3n (88%). Adem\u00e1s, se observa que 76% considera que las sesiones conjuntas no dificultan el pro - cedimiento de evaluaci\u00f3n o deliberaci\u00f3n. Sin embargo, 68% de las CEB no tienen una pos- tura definida sobre si las sesiones conjun- tas complican el cumplimiento normativo y deber\u00edan seguir sesionando por separado. El porcentaje restante se divide equitativa- mente entre quienes consideran que deben sesionar por separado (16%) y quienes consi- deran que deben sesionar en conjunto (16%) (v\u00e9ase figura 7). En cuanto a los beneficios o dificultades que podr\u00edan derivarse de realizar sesiones conjuntas entre los diferentes comit\u00e9s, se encontr\u00f3 que 46% de las respuestas men- cionaban beneficios, 39% dificultades y 15% restante no report\u00f3 escenarios adicionales a los enlistados en la encuesta. Los beneficios se englobaron en categor\u00edas como agilizar el dictamen y proceso (25%), enriquecimien-to de la deliberaci\u00f3n (25%), perspectiva m\u00e1s amplia y plural (10%), unificar y complemen- tar los comit\u00e9s y sus aportes (10%), disminu- ci\u00f3n de quejas y conflictos entre los diferen- tes comit\u00e9s (5%), resultados con aplicaci\u00f3n m\u00e1s amplia (5%), fortalecimiento del apren- dizaje de los integrantes (5%), y aprovechar espacios (5%). Sobre las problem\u00e1ticas identificadas en la evaluaci\u00f3n conjunta de protocolos con el CI, CB y CICUAL, se destacan aquellas de tipo log\u00edstico y administrativo como \"Reunir a los Figura 7. Percepci\u00f3n de las CEB sobre la utilidad de las sesiones conjuntas entre los diferentes comit\u00e9s. FUENTE. Comisi\u00f3n Nacional de Bio\u00e9tica, elaboraci\u00f3n propia, Figura 7. Percepci\u00f3n de las CEB sobre la utilidad de las sesiones conjuntas entre los diferentes comit\u00e9s. FUENTE. Comisi\u00f3n Nacional de Bio\u00e9tica, elaboraci\u00f3n propia. miembros\" con 48% de las respuestas, \"Falta de criterios homologados para evaluaci\u00f3n y operaci\u00f3n\" (24%), \"Relaciones de poder en- comit\u00e9s\" (24%), diferentes\" al acuerdos\" \"Qu\u00f3rum de grupos multi- disciplinarios y multiinstitucionales\" (18%), \"Personal compartido (duplicidad de funcio - nes) en los diferentes comit\u00e9s\" (12%), y \"Tiem-tareas y perspectivasGaceta56 po de las sesiones\" (7%). Otras problem\u00e1ticas identificadas son de car\u00e1cter sustantivo e infraestructural, como no contar con otros comit\u00e9s (4%) o no contar con espacios ade - cuados para llevar a cabo las sesiones en- tre los diferentes comit\u00e9s (4%). Adem\u00e1s, se menciona la inasistencia de integrantes y falta de qu\u00f3rum en algunos de los comit\u00e9s, el personal compartido en CI y CEI, la rota- ci\u00f3n de personal y la falta de conocimiento de la normatividad. Respecto a la propuesta de obligatoriedad de sesiones conjuntas entre CEI, CI, CB y CICUAL, 54% de los participantes est\u00e1 de acuerdo o totalmente de acuerdo. Por otro lado, 28% de los participantes est\u00e1 en des- acuerdo con volver obligatorias las sesiones conjuntas debido a problem\u00e1ticas identifi- cadas que nuevamente incluyen aspectos log\u00edsticos y administrativos, y 8% muestra indiferencia respecto a esa modalidad de se - siones. De igual forma, se recopilaron algunos de los comentarios y recomendaciones m\u00e1s desta-cados de los participantes, como: la necesi- dad de regular este tipo de sesiones a trav\u00e9s de un reglamento o disposici\u00f3n oficial; la consideraci\u00f3n de que la realizaci\u00f3n de sesio - nes conjuntas beneficiar\u00e1 a los investigado - res; la dificultad para lograr la asistencia de todos los miembros debido a que son par - ticipaciones honorarias; la importancia de coordinarse de la mejor manera posible; la necesidad de modificar la normativa nacio - nal y trabajar en conjunto con la COFEPRIS , y la autonom\u00eda de cada comit\u00e9 en su repre - sentatividad y funciones. En suma, la encuesta revela que las sesio - nes conjuntas entre los comit\u00e9s tienen una alta aprobaci\u00f3n por parte de las Comisiones Estatales de Bio\u00e9tica, sin embargo, persiste una falta de posicionamiento respecto al im- pacto en el cumplimiento normativo. Por lo tanto, es importante continuar la evaluaci\u00f3n de la propuesta de las sesiones conjuntas para maximizar los beneficios y mitigar las dificultades identificadas. Imagen: freepik.comGaceta57 1.\u00bfQu\u00e9 es la inteligencia artificial? GR: El t\u00e9rmino Inteligencia Artificial (IA) se basa en la definici\u00f3n de la UNESCO como las tecnolog\u00edas inform\u00e1ticas que, en una econo - m\u00eda de datos, con la nube y con incremen- to de las capacidades de las computadoras, reproducen procesos asociados a la inteli- gencia humana como: el razonamiento, el aprendizaje y la adaptaci\u00f3n, la comprensi\u00f3n sensorial y la interacci\u00f3n. Los recientes y r\u00e1- pidos avances de la IA han puesto de relieve las numerosas oportunidades que ofrece, as\u00ed como la necesidad de una profunda re - flexi\u00f3n \u00e9tica sobre su utilizaci\u00f3n. 2.\u00bfCu\u00e1les son los usos y aplicaciones co- munes de la IA? GR: Existen numerosos ejemplos de usos y aplicaciones de IA, que son cada vez m\u00e1s novedosos. En particular, con sus capaci- dades anal\u00edticas, la IA contribuye d\u00eda a d\u00eda a la toma de decisiones, desde los productos en internet, hasta quien obtiene un cr\u00e9dito, Encuentro Bio\u00e9tico Conversaci\u00f3n con Gabriela Ramos En esta ocasi\u00f3n Encuentro Bio\u00e9tico sostuvo una interesante conversaci\u00f3n con Gabriela Ramos, Subdirectora General de Ciencias Sociales y Humanas de la UNESCO, sobre Inteligencia Artificial y \u00c9tica o una entrevista de trabajo. Entre las apor - taciones positivas, los modelos de IA est\u00e1n acelerando considerablemente el progreso cient\u00edfico. En 2022 contribuyeron a avanzar en la fusi\u00f3n de hidr\u00f3geno, a mejorar la efica- cia de la manipulaci\u00f3n de matrices y gene - rar nuevos anticuerpos. Esto, con base en su capacidad de descubrir relaciones significa- tivas en conjuntos inmensos de datos. Por ello, la IA tambi\u00e9n puede fortalecer la resi- liencia frente a desastres naturales, dise\u00f1ar edificios con eficiencia energ\u00e9tica, mejorar el almacenamiento de energ\u00eda y optimizar el despliegue de las fuentes de energ\u00eda reno - vables. Estas aplicaciones prometen una variedad de beneficios. Pero, lo cierto es que, sin re - glas efectivas, existe el riesgo de que la IA cree nuevas desigualdades y ampl\u00ede las ya existentes. Por ejemplo, investigaciones recientes sugieren que los sistemas de IA pueden tener graves repercusiones sobre el medio ambiente. Seg\u00fan Luccioni, Viguier y Ligozat (2022), el entrenamiento del sistema BLOOM emiti\u00f3 25 veces m\u00e1s carbono que un pasajero de avi\u00f3n en un viaje de ida de Nueva York a San Francisco. Al contrario, los nuevos modelos de aprendizaje por refuerzo como BCOOLER demuestran que los siste - mas de IA pueden utilizarse para optimizar el uso de la energ\u00eda. 3.\u00bfCu\u00e1les son las recomendaciones de la UNESCO sobre la \u00e9tica de la IA? GR: La UNESCO tiene el mandato de asegu- rar que las tecnolog\u00edas sean desarrolladas con una base \u00e9tica, ya sea en temas del ge - noma humano, de la geo-ingenier\u00eda o de la inteligencia artificial. En este \u00faltimo rubro, en 2021, logramos la adopci\u00f3n por aclama- ci\u00f3n, de 193 pa\u00edses de la Recomendaci\u00f3n sobre la \u00c9tica de la Inteligencia Artificial, siendo este el primer marco universal. La Recomendaci\u00f3n aborda todos los riesgos y desaf\u00edos que surgen actualmente del des- encuentro bio\u00e9ticoGaceta58 pliegue de las tecnolog\u00edas de Inteligencia Artificial. Asimismo, busca maximizar los aspectos positivos. Este instrumento busca abordar el qu\u00e9 de la \u00e9tica de la IA y el c\u00f3mo de la acci\u00f3n pol\u00edtica relevante, ofreciendo v\u00edas concretas para la realizaci\u00f3n del marco \u00e9tico de principios y valores universales. La Recomendaci\u00f3n representa un marco \u00e9tico integral que abarca todo el espectro de la arquitectura de derechos humanos -desde el principio de la dignidad humana hasta la cuesti\u00f3n de la inclusi\u00f3n, la equidad, la igualdad y la no discriminaci\u00f3n- y lo hace manteniendo el enfoque en todas las etapas del ciclo de vida del sistema de IA. Tambi\u00e9n lo hace a trav\u00e9s de los principios de trans- parencia, rendici\u00f3n de cuentas, privacidad y equidad, entre otros. En su dise\u00f1o, estamos muy orgullosos de haber logrado la aprobaci\u00f3n de principios tales como la no manipulaci\u00f3n de los sesgos cognitivos, la determinaci\u00f3n humana y, por consiguiente, en no aprobar la personalidad jur\u00eddica a los desarrollos de la IA. Proh\u00edbe adem\u00e1s el espionaje masivo y la notaci\u00f3n social. Por otro lado, la Recomendaci\u00f3n no pretende ser una mera declaraci\u00f3n de prin- cipios, y por ello establece v\u00edas pol\u00edticas para convertir los principios en acciones, refor - zando el estado de derecho. Esto se puede lograr a trav\u00e9s de los instrumentos de forta- lecimiento de capacidades que ayudan a los pa\u00edses a aprovechar el poder de la IA. Concretamente, la Recomendaci\u00f3n inclu- ye acciones pol\u00edticas en \u00e1reas espec\u00edficas: Evaluaci\u00f3n de impacto \u00e9tico, Gobernanza y rector\u00eda \u00e9ticas, Pol\u00edtica de datos, Desarrollo y cooperaci\u00f3n internacional, Medio ambiente y ecosistemas, G\u00e9nero, Cultura, Educaci\u00f3n e investigaci\u00f3n, Econom\u00eda y trabajo, y Salud y bienestar social. Entre estas v\u00edas pol\u00edticas in- cluimos un cap\u00edtulo espec\u00edfico de g\u00e9nero. Se trata del primer instrumento global con este compromiso. La Recomendaci\u00f3n cuenta con un marco de implementaci\u00f3n, y la UNESCO se encuentra aplicando un instrumento de diagn\u00f3stico, elaborado para este prop\u00f3sito (Readiness Assessment Methodology) que permite el seguimiento en 40 pa\u00edses. Con ello, trabaja- remos hombro con hombro con los gobier - nos para ayudarles a desarrollar las leyes e instituciones necesarias para normar la Inte - ligencia Artificial. 4.\u00bfC\u00f3mo est\u00e1 cambiando la IA la forma en que se practica la medicina a nivel mun- dial? GR: La IA tiene muchas ventajas en el reco - nocimiento de patrones, y por ello, puede mejorar sustantivamente los diagn\u00f3sticos de enfermedades. Pero la IA tambi\u00e9n puede: Elegir, dise\u00f1ar y planificar experimentos mientras mejora la medici\u00f3n y la obser - vaci\u00f3n. Generar hip\u00f3tesis y aprender reglas cient\u00edficas en \u00e1reas como la qu\u00edmica para predecir la fabricaci\u00f3n de medica- mentos. Incrementar la exactitud de los diagn\u00f3s- ticos m\u00e9dicos (cuando se combina con la opini\u00f3n profesional). Predecir la replicabilidad de la investiga- ci\u00f3n e incluso sugerir que los expertos y expertas revisen las propuestas de inves- tigaci\u00f3n. Identificar a los pacientes m\u00e1s adecua- dos para ensayos cl\u00ednicos. Hemos entrado oficialmente en la era de la inteligencia artificial y esto no es ajeno a la medicina. Todo esto, est\u00e1 l\u00f3gicamente transformando la medicina. El mundo aho - ra est\u00e1 listo para cambiar a un ritmo no visto desde el despliegue de la imprenta hace seis siglos. La IA hace que nuestras vidas sean m\u00e1s f\u00e1ciles, fluidas y ricas, nos ayuda a llegar a casa, informarnos, obtener cr\u00e9ditos, conse - guir un trabajo y hacer nuestros impuestos. Tambi\u00e9n a diagnosticar, curar, tratar y preve - nir enfermedades. Sin ir m\u00e1s lejos, el r\u00e1pido desarrollo de la vacuna del COVID-19 fue po -Gaceta59 encuentro bio\u00e9tico sible gracias a estas tecnolog\u00edas. Ahora bien, en un \u00e1rea tan sensible como la salud, es im- prescindible que estas tecnolog\u00edas cuenten con un marco \u00e9tico. 5.Respecto del uso actual de la IA, \u00bfser\u00e1 necesario implementar un marco norma- tivo para su regulaci\u00f3n? GR: \u00c9ste es efectivamente el siguiente paso, en el cual estamos trabajando con los Es- tados miembros. La implementaci\u00f3n de la Recomendaci\u00f3n requiere de mecanismos concretos, y normas que se trasladan al mar - co legal vigente. Las tendencias recientes apuntan a una mayor actividad en la mate - ria. En la Uni\u00f3n Europea, las directivas de IA comienzan a implementarse, y en todos los pa\u00edses hay una reflexi\u00f3n sobre como regular, incluyendo en los Estados Unidos. Un an\u00e1lisis del \u00cdndice de IA de los registros le - gislativos de 127 pa\u00edses muestra que el n\u00famero de proyectos de ley que contienen \"inteligen- cia artificial\", que se convirtieron en ley, creci\u00f3 de solo 1 en 2016 a 37 en 2022. Adem\u00e1s, un an\u00e1- lisis de los registros parlamentarios sobre IA en 81 pa\u00edses muestra igualmente que las men- ciones a la IA en los procedimientos legislati- vos mundiales han aumentado casi 6,5 veces desde 2016. Pero la legislaci\u00f3n no es suficiente. Necesitamos instituciones que aseguren el es- tado de derecho, y es ese el enfoque de la im- plementaci\u00f3n de la Recomendaci\u00f3n. 6.\u00bfPuede la IA contribuir a la equidad social? GR: No s\u00f3lo puede contribuir, sino que debe hacerlo. Este es el objetivo de los marcos \u00e9ti- cos: evitar que se reproduzcan a\u00fan m\u00e1s las desigualdades que ya existen en nuestras sociedades y a nivel internacional, haciendo que la mitad del mundo no est\u00e9 siempre conectado al internet, y no est\u00e9 siempre re- presentado en las bases de datos. Por ello, necesitamos una arquitectura digital que distribuya en forma m\u00e1s equitativa los be- neficios de la creaci\u00f3n colectiva de valor. En la actualidad, con dos pa\u00edses y un grupo de empresas produciendo la totalidad de la IA, es necesario abordar las brechas. Por otra parte, la IA bien utilizada puede apoyar a que los individuos y las comuni- dades reciban los servicios que necesitan tanto en salud y educaci\u00f3n, y en tantos otros rubros. Se necesita una supervisi\u00f3n p\u00fablica eficaz para que la digitalizaci\u00f3n y la IA ge - neren oportunidades para la creaci\u00f3n de valor p\u00fablico. Y para ello, el uso p\u00fablico de la IA tambi\u00e9n debe estar asentado en una s\u00f3lida base \u00e9tica. Frente al avance de esta tecnolog\u00eda como herramienta auxiliar para la toma de decisiones, es importante evitar un uso de los sistemas de IA que sea con- trario a la democracia o a los derechos hu- manos. En la UNESCO, creemos que para mantener el control sobre productos importantes y ga- rantizar el respeto de normas \u00e9ticas, los go - biernos deben tener capacidad de desa- rrollar la IA sin depender del sector privado para la provisi\u00f3n de sistemas de car\u00e1cter delicado. Tambi\u00e9n tienen que poder sos- tener un uso compartido de la informaci\u00f3n y la interoperabilidad de protocolos y m\u00e9tricas entre los diversos departamentos y ministe - rios. Todo esto necesita una inversi\u00f3n p\u00fabli- ca en las capacidades del Estado, seg\u00fan un enfoque basado en la idea de misi\u00f3n. Y por ello en la UNESCO estamos trabajan- do a fin de fortalecer estas capacidades, para asistir a los Estados en la creaci\u00f3n de la institucionalidad que necesitan para de - sarrollar IA. 7.\u00bfCu\u00e1l es el futuro de la IA? GR: La reciente ampliaci\u00f3n de las capacida- des de la IA nos indica que el incremento puede continuar siendo exponencial. La tec - nolog\u00eda de prop\u00f3sito general tendr\u00e1 un im- pacto en todos los rubros. Pero a la vez, estos desarrollos conviven en un mundo desigual y lo refuerzan, y por ello el futuro de la IA ser\u00e1 el que decidamos construir, con reglas claras y protecci\u00f3n efectiva. Con una bue - na utilizaci\u00f3n, la IA podr\u00edan apoyar nuestra Gaceta60 comprensi\u00f3n del cambio clim\u00e1tico (ODS 13), sistemas de transporte sustentables (ODS 11), tecnolog\u00edas agropecuarias para ayudar a terminar con la desnutrici\u00f3n y pobreza (ODS 2), entre muchos otros beneficios. As\u00ed, la IA se puede convertir en un aliado que el desarrollo sustentable requiere para dise - \u00f1ar, ejecutar, asesorar y planificar el futuro de nuestro planeta y su sustentabilidad m\u00e1s efectivamente. Esta combinaci\u00f3n de IA con el desarrollo sustentable permitir\u00e1 abordar las necesidades actuales sin comprometer las generaciones futuras. Seg\u00fan recientes investigaciones (revista Na- ture), la IA podr\u00eda convertirse en una herra- mienta clave para facilitar una econom\u00eda cir - cular y construir ciudades m\u00e1s inteligentes que utilicen sus recursos eficientemente. Un claro ejemplo del aporte de la IA es la gesti\u00f3n del tr\u00e1fico. La aplicaci\u00f3n de la IA en la movi- lidad urbana ha permitido predecir atascos y proponer rutas alternativas. Con movilidad compartida, esta tecnolog\u00eda predice la de - manda de veh\u00edculos por zona y hora. Esto significa que las empresas pueden organi- zar la disponibilidad de veh\u00edculos para los ciudadanos en funci\u00f3n de sus necesidades. Como consecuencia, esta soluci\u00f3n no solo facilita la movilidad, sino que tambi\u00e9n mini- miza su impacto ambiental. Pero en su forma actual, y sin una buena re - gulaci\u00f3n, la IA continuar\u00e1 reproduciendo y amplificando muchas de las brechas y los desaf\u00edos sociales a los que nos enfrentamos. Por ello tenemos que actuar. No se trata de la tecnolog\u00eda per se, sino de los marcos de gobernanza que configuran su desarrollo y uso, y los valores \u00e9ticos y morales que de - fienden, y que son muy sensibles en el cam- po de la salud. Estoy convencida de que, con un enfoque \u00e9tico de la UNESCO puede ofrecer resulta- dos justos, sostenibles e inclusivos. Pero esto no puede suceder sin gobiernos capaces que protejan el estado de derecho en l\u00ednea, y desarrolladores p\u00fablicos y privados que sean responsables de poner a las personas, no a las ganancias ni a las consideraciones geopol\u00edticas, en primer lugar. S\u00f3lo entonces la Era de la IA podr\u00e1 traer el progreso que esperamos. 8.Respecto al 'CHAT GPT', \u00bfcu\u00e1les conside - ra que son las implicaciones \u00e9ticas en su aplicaci\u00f3n en la educaci\u00f3n superior? GR: La salida del 'ChatGPT' al mercado no se hizo siguiendo las reglas \u00e9ticas de la UNESCO en una manera ex ante. Una vez que estaba al alcance de todos, se empeza- ron a analizar sus impactos. Esto no deber\u00eda ser as\u00ed. Hay cuestiones claras de fiabilidad de los datos, de la actualidad de estos, y de los m\u00faltiples impactos que puede tener y que no se han medido. En la UNESCO reali- zamos un estudio el cual concluye que, con respecto a las provisiones de la Recomen- daci\u00f3n (en materia de transparencia, ren- dici\u00f3n de cuentas, resultados), el 'ChatGPT' no est\u00e1 alineado. La integridad acad\u00e9mica, por ejemplo, ha sido se\u00f1alada como un \u00e1rea de preocupa- ci\u00f3n, con mayores riesgos para el plagio, o el control de calidad. La falta de diversidad es otra \u00e1rea preocupante. Por \u00faltimo, si no nu- trimos las capacidades cr\u00edticas de los estu- diantes, la utilizaci\u00f3n puede llegar a debilitar la excelencia o la actualidad de la produc - ci\u00f3n acad\u00e9mica. La Recomendaci\u00f3n incluye los siguientes elementos en materia de educaci\u00f3n: 1. Una visi\u00f3n y prioridades estrat\u00e9gicas para todo el sistema. 2. Un principio general para la IA y las pol\u00edti- cas educativas. 3. Una planificaci\u00f3n interdisciplinar y una gobernanza intersectorial. 4. Pol\u00edticas y normativas para un uso equi- tativo, inclusivo y \u00e9tico de la IA. 5. Planes maestros para utilizar la IA en la gesti\u00f3n de la educaci\u00f3n, la ense\u00f1anza, el aprendizaje y la evaluaci\u00f3n.Gaceta61 encuentro bio\u00e9tico 6. Pruebas piloto, seguimiento y evaluaci\u00f3n, y la creaci\u00f3n de una base emp\u00edrica. 7. Fomento de las innovaciones locales en IA para la educaci\u00f3n. La UNESCO tambi\u00e9n ha publicado orienta- ciones sobre la IA y la educaci\u00f3n para los res- ponsables que desarrollan pol\u00edticas. En ella se describen las pr\u00e1cticas emergentes en educaci\u00f3n y se analizan los retos que plan- tea el uso de la IA para alcanzar el Objetivo de Desarrollo Sostenible 4 (Educaci\u00f3n de ca- lidad). Ahora bien, nuestra postura desde hace tiempo es que las evaluaciones de impacto \u00e9tico de los productos de Inteligencia Arti- ficial deben realizarse sistem\u00e1ticamente \"ex ante\", es decir, antes de que el producto sal- ga al mercado. Es evidente que este consejo no se ha tenido en cuenta en los recientes lanzamientos al mercado, como el de 'Chat - GPT' en noviembre de 2022, y 'ChatGPT 4' el mes pasado. Hoy en d\u00eda, la Inteligencia Arti-ficial est\u00e1 evaluando de manera err\u00f3nea la elegibilidad de las personas para puestos de trabajo y prestaciones sociales. Identifica fal- samente a las personas mediante la tecno - log\u00eda de reconocimiento facial. El 'ChatGPT' \"alucina\" con informaci\u00f3n falsa. Por todo ello, en el Sector de las Ciencias So - ciales y Humanas que dirijo, hemos avanza- do los trabajos de la implementaci\u00f3n de la Recomendaci\u00f3n, con el desarrollo del Instru- mento de medici\u00f3n de capacidades, y con la evaluaci\u00f3n de impacto \u00e9tico. Estamos apli- cando en 40 pa\u00edses, y revisaremos las con- clusiones en el Foro Global de la Inteligen- cia Artificial a celebrarse en Eslovenia el a\u00f1o que entra. Pr\u00f3ximamente tambi\u00e9n lanzare - mos el Observatorio de la \u00c9tica de la Inteli- gencia Artificial con el instituto Alan Turing y estamos trabajando con el sector privado para apoyar los desarrollos \u00e9ticos. Con estos esfuerzos esperamos avanzar en la construc - ci\u00f3n de una IA m\u00e1s justa, solida, y confiable. Imagen: freepik.comGaceta62 Pel\u00edcula T\u00edtulo: Blade Runner A\u00f1o de estreno: 1982 Duraci\u00f3n: 1 hora 57 minutos Direcci\u00f3n: Ridley Scott Pel\u00edcula de culto de 1982 que imagina un a\u00f1o 2019 con grandes adelantos en la Inteligencia Artificial: los \"replicantes\" parecen seres humanos, pero son creaciones artificiales. Tras una revuelta de estos superhumanos y ante el temor de que desarrollen ideas propias, les prohi- bieron regresar a la Tierra. Deckard, un Blade Runner retirado, es obligado a reincorporarse al servicio de esta especie de polic\u00edas para atrapar a cuatro replicantes que osaron reingresar a la Tierra. \u00bfC\u00f3mo atraparlos si no se distinguen de los seres humanos? Algunos de los replicantes no son conscientes de su naturaleza. Sin embargo, otros saben lo que son y no se consideran computadoras sino entes f\u00edsicos que piensan y, por lo tanto, existen. \u00bfQu\u00e9 los impulsa a regre - sar a la Tierra? Algo tan fuerte como el deseo de vivir m\u00e1s tiempo, de alargar su existencia y para lograrlo deber\u00e1n evadir a los Blade Runners y convencer a su creador de que les d\u00e9 m\u00e1s tiempo, m\u00e1s vida. Sin embargo, la cuesti\u00f3n no ser\u00e1 tan sencilla. Pel\u00edcula T\u00edtulo: Tau A\u00f1o de estreno: 2018 Duraci\u00f3n: 01 hora 37 minutos Direcci\u00f3n: Federico D'Alessandro Julia se da cuenta de que alguien est\u00e1 experimentando con ellos. Tras secuestrarlos, los encar - celaron y les colocaron un implante con luz en la nuca. Conscientes del peligro, intentan escapar y descubren que el espacio est\u00e1 resguardado por un avanzado robot con inteligencia artificial, Tau. Si el tomar decisiones a partir de un sentimiento es exclusivo de los seres humanos, en esta pel\u00edcula se explora una posible revoluci\u00f3n: a partir de algoritmos de inteligencia emocional, una IA puede demostrar comprensi\u00f3n humana. \u00bfC\u00f3mo se desarrollar\u00eda una tecnolog\u00eda con es- tas caracter\u00edsticas? \u00bfCu\u00e1les ser\u00edan sus posibilidades, ventajas y riesgos? En t\u00e9rminos de justicia, integridad y autonom\u00eda, \u00bfqui\u00e9nes podr\u00e1n tener acceso a estas tecnolog\u00edas? \u00bfC\u00f3mo se obtienen los datos para desarrollarlas? \u00bfQu\u00e9 sesgos tiene esa informaci\u00f3n? \u00bfC\u00f3mo colaborar con los par - ticipantes de las investigaciones? Tau enfatiza la importancia de realizar investigaciones con \u00e9tica y responsabilidad. Sugerencias de la CONBIO\u00c9TICA en medios digitales Ariana Leticia Land\u00edn L\u00f3pez* *Subcoordinadora de Biblioteca, de la y bio\u00e9tica Podcast Nombre: Noosfera Episodio: Noosfera 77. Dr. Robot y el machine learning en medicina | Francisco Jes\u00fas Mart\u00ednez A\u00f1o de estreno: Spreaker El v\u00ednculo entre la ingenier\u00eda y las ciencias de la salud, la computaci\u00f3n y la medicina, \u00bfc\u00f3mo funciona realmente? Francisco Jes\u00fas Mart\u00ednez explica c\u00f3mo se introduce el machine lear - ning, en im\u00e1genes radiol\u00f3gicas, resonancias o encefalogramas. El aprendizaje autom\u00e1tico o aprendizaje computacional se refiere a la creaci\u00f3n de algoritmos para que las computadoras realicen tareas o \"aprendan\" a partir de ejemplos. \u00bfC\u00f3mo se puede utilizar el machine lear - ning para mejorar la atenci\u00f3n de la salud? Conferencia Nombre: Inteligencia artificial: sus desaf\u00edos \u00e9ticos | Markus Gabriel A\u00f1o de estreno: 2023 Duraci\u00f3n: 01:58:54 Disponible: YouTube La C\u00e1tedra \"Alfonso Reyes\" del Tecnol\u00f3gico de Monterrey present\u00f3 la conferencia en la que Markus Gabriel desentra\u00f1a las caracter\u00edsticas de la Inteligencia Artificial (IA). \u00bfEn qu\u00e9 consiste la ontolog\u00eda de la IA y por qu\u00e9 se debe abordar antes de hablar de la \u00e9tica de la IA? \u00bfHay una diferencia entre los sistemas de IA y la investigaci\u00f3n en IA? Los sistemas de IA no son aut\u00f3no - mamente inteligentes, sino que se integran y emplean en un sistema antropog\u00e9nico mayor. Por lo tanto, no tienen una inteligencia intr\u00ednseca. Esto no quiere decir que la IA sea \u00e9ticamente neutral, al contrario. Imagen: freepik.comGaceta64 An\u00e1lisis Nombre: El uso de ChatGPT | Francesc Director de UNESCO-IESALC A\u00f1o de estreno: 2023 Duraci\u00f3n: 05:50 minutos Disponible: YouTube El director del Instituto Internacional de la UNESCO para la Educaci\u00f3n Superior en Am\u00e9rica Latina y el Caribe (IESALC), ofrece una reflexi\u00f3n sobre el uso de ChatGPT en la ense\u00f1anza. Esta herramienta impacta en los m\u00e9todos tradicionales de ense\u00f1anza-aprendizaje, por lo que sur - ge la necesidad de centrarse en el estudiante e impulsar el desarrollo de directrices y pol\u00edticas claras sobre el uso de inteligencia artificial en la educaci\u00f3n y el trabajo acad\u00e9mico. Adem\u00e1s, se vuelve urgente promover una alfabetizaci\u00f3n sobre la inteligencia artificial que acompa\u00f1e a las ense\u00f1anzas acad\u00e9micas y digitales.Documental Nombre: El cazador de cerebros Episodio: Cu\u00e1ntica + de estreno: 2022 Duraci\u00f3n: minutos Disponible: RTVE \u00bfHacia d\u00f3nde se dirige la computaci\u00f3n? Visita la sede central de IBM y las instalaciones del MIT para conocer las investigaciones actuales. Los ordenadores utilizan propiedades de la f\u00edsica cu\u00e1ntica, mientras que los robots y veh\u00edculos han alcanzado un mayor nivel de autonom\u00eda y un mejor entendimiento del mundo exterior. En el \u00e1mbito de la salud, estas tecnolog\u00edas ya pueden analizar grandes cantidades de datos y contribuir al diagn\u00f3stico de enfermedades. En el futuro, \u00bfc\u00f3mo los avances digitales podr\u00e1n resolver los problemas del mundo f\u00edsico? Gaceta65 Nanotecnolog\u00eda viva Sonia Contera 2023 La autora se basa en su experiencia como investigadora en el campo de la inteligencia artificial, describe las apasionantes formas en que la nanotecnolog\u00eda permite comprender, interactuar y ma- nipular la biolog\u00eda. Se busca la reflexi\u00f3n sobre las oportunidades que emergen de los laboratorios para utilizar la tecnolog\u00eda con el fin de crear un futuro m\u00e1s justo y humano. La nanotecnolog\u00eda es un avance hist\u00f3rico que est\u00e1 revolucionando la medicina de formas que tendr\u00e1n profundos efectos en la vida. Desde m\u00e1quinas a nanoescala que pueden dirigirse a c\u00e9lulas cancerosas y administrar f\u00e1rmacos con mayor eficacia, hasta nanoantibi\u00f3ticos que combaten bacterias resistentes, pasando por la ingenier\u00eda de tejidos y \u00f3rganos para trasplantes o la investigaci\u00f3n en farmacolog\u00eda. Por ello se considera que el futuro traer\u00e1 consigo la fusi\u00f3n de la nanotecnolog\u00eda con diversos campos de la salud y de vanguardia, esto a su vez permitir\u00e1 contemplar las ventajas y los riesgos de este avance. Artificial Intelligence and Bioethics Perihan Elif Ekmekci & Berna Arda 2020 Esta obra aborda los principales desaf\u00edos al considerar los principios fundamentales de la \u00e9tica m\u00e9dica, incluida la confidencialidad, la privacidad, la compasi\u00f3n, la veracidad y la fidelidad. Final- mente, los autores discuten las implicaciones \u00e9ticas de la participaci\u00f3n de agentes de inteligencia artificial en la atenci\u00f3n al paciente al ampliar las habilidades de comunicaci\u00f3n en un enfoque basa- do en casos. Asimismo, explora los principales problemas bio\u00e9ticos que surgen del desarrollo y uso de la inteligencia artificial en entornos m\u00e9dicos. Los autores comienzan definiendo el pasado, el presente y el futuro de la inteligencia artificial en entornos m\u00e9dicos y luego proceden a abordar las preguntas bio\u00e9ticas comunes y espec\u00edficas resultantes. A su vez, analiza las investigaciones bio\u00e9 - ticas en dos conjuntos separados: el primero se compone de debates ontol\u00f3gicos que se centran principalmente en la personalidad y en ser un agente \u00e9tico de un artefacto. El segundo bloque aborda cuestiones bio\u00e9ticas, derivadas del uso de la inteligencia artificial, se enfoca particularmen- te en el \u00e1rea del uso de inteligencia artificial en medicina y servicios de salud. Sugerencias editoriales de la CONBIO\u00c9TICA Karla Nallely Rosas Chelius* * Jefa del Departamento de Servicios de Informaci\u00f3n, de la Comisi\u00f3n Nacional de Bio\u00e9tica. rinc\u00f3n bibliogr\u00e1ficoGaceta66 The Future Circle of & Florian M Thieringet 2022 Esta publicaci\u00f3n re\u00fane a acad\u00e9micos en \u00e1reas de especializaci\u00f3n esenciales para comprender c\u00f3mo la atenci\u00f3n m\u00e9dica podr\u00eda cambiar y evolucionar durante la pr\u00f3xima d\u00e9cada. \u00bfQu\u00e9 lec - ciones se pueden extraer de los desarrollos actuales y pasados? Se abordan cuatro temas; el primero es el r\u00e1pido ritmo y la ubicuidad de los avances tecnol\u00f3gicos en \u00e1reas como la inteli- gencia artificial, el aprendizaje autom\u00e1tico, la fabricaci\u00f3n aditiva y la electr\u00f3nica port\u00e1til; el se - gundo pilar se refiere al envejecimiento saludable, la longevidad y el manejo de enfermedades cr\u00f3nicas; el tercero es el imperativo de permanecer consciente de las dimensiones \u00e9ticas de las decisiones m\u00e9dicas, adaptando la bio\u00e9tica a los cambios en curso en la prestaci\u00f3n de ser - vicios de salud y el cuarto pilar se relaciona con c\u00f3mo la incertidumbre en diferentes dominios del conocimiento m\u00e9dico puede mitigarse y traducirse a la pr\u00e1ctica cl\u00ednica. Los autores de los cap\u00edtulos identifican los desaf\u00edos respectivos y las oportunidades prometedoras, discutiendo c\u00f3mo estos podr\u00edan contribuir a visualizar el alcance futuro de la atenci\u00f3n m\u00e9dica cuando se trata de proporcionar valores m\u00e9dicos, econ\u00f3micos y \u00e9ticos a las sociedades humanas. El dilema de utilizar \"Chat GPT\": \u00bfEnemigo o aliado de la educaci\u00f3n? Eloy Albarr\u00e1n 2023 El autor plantea una serie de consideraciones \u00e9ticas y creativas que deben ser tenidas en cuenta al utilizar Chat GPT en la educaci\u00f3n -un modelo de lenguaje que es capaz de generar texto de manera aut\u00f3noma-. Hay una reflexi\u00f3n respecto a las posibilidades que ofrece el uso de Chat GPT en la educaci\u00f3n, pero tambi\u00e9n sobre los riesgos que conlleva. A trav\u00e9s de ejem- plos concretos, se ilustran los dilemas \u00e9ticos y creativos que surgen al utilizar esta tecnolog\u00eda en la educaci\u00f3n. Por otro lado, se explora c\u00f3mo la adopci\u00f3n de esta tecnolog\u00eda puede afectar la creatividad de los estudiantes, al depender en gran medida de un modelo preexistente, a medida que la tecnolog\u00eda avanza, cada vez son m\u00e1s las escuelas y universidades que adoptan herramientas de aprendizaje en l\u00ednea que hacen uso de esta tecnolog\u00eda. Gaceta67 rinc\u00f3n bibliogr\u00e1fico Manual pr\u00e1ctico de inteligencia artificial en entornos sanitarios Julo Bonis Sanz, Borja Rodr\u00edguez Vila, Juan Jos\u00e9 Beunza Nuin, Enrique Puertas Sanz y Emilia Cond\u00e9s Moreno 2023 Esta publicaci\u00f3n tiene la voluntad de dar respuesta a todos los cambios esperables que el campo de la inteligencia artificial ha experimentado en estos dos a\u00f1os, donde se han desarro - llado m\u00faltiples dispositivos y herramientas de inteligencia artificial. Por lo anterior, es urgente preparar a los profesionales de la salud y a los gestores involucrados en la adquisici\u00f3n, el uso, el dise\u00f1o, la integraci\u00f3n, etc. de estas herramientas. Este manual maneja un lenguaje sencillo para facilitar la comprensi\u00f3n de los conceptos b\u00e1sicos m\u00e1s relevantes y as\u00ed facilitar la inicia- ci\u00f3n en el mundo pr\u00e1ctico de la inteligencia artificial a personas que no disponen de ning\u00fan conocimiento previo. En el contenido se incluyen temas sobre los grandes tipos de algoritmos disponibles, qu\u00e9 es un algoritmo, aplicaciones concretas, el procesamiento del lenguaje na- tural, c\u00f3mo se crean chatbots, la estructura y el funcionamiento del Internet de las Cosas, la importancia de la protecci\u00f3n de datos y de los datos en streaming, la nube y las fuentes de datos, y, finalmente, de las claves del \u00e9xito de un programa de inteligencia artificial. Filosof\u00eda de la medicina: discusiones y aportaciones desde M\u00e9xico Atocha Aliseda, Cecilia Calder\u00f3n, Marcia Villanueva (Editoras) 2023 Esta obra es un fruto del di\u00e1logo entre profesionales de la Filosof\u00eda, Filosof\u00eda de la Ciencia, Medicina, Econom\u00eda, Sociolog\u00eda y Antropolog\u00eda. Ofrece discusiones sobre aspectos filos\u00f3ficos, epistemol\u00f3gicos y metodol\u00f3gicos de temas como el razonamiento cl\u00ednico y las inferencias causales en las Ciencias de la Salud. Tambi\u00e9n contribuye a la caracterizaci\u00f3n de la enferme - dad, en relaci\u00f3n con el sobrediagn\u00f3stico y la psiquiatr\u00eda, y ahonda en temas como la deshu- manizaci\u00f3n de la medicina, el sufrimiento al final de la vida y el pensamiento complejo en la pr\u00e1ctica cl\u00ednica. En suma, se trata de un libro colectivo que tiene como finalidad dar visibilidad a la filosof\u00eda de la medicina mexicana. "}