{"title": "Cap\u00edtulo 33 Sets grandes de datos | Introducci\u00f3n a la ciencia de datos", "author": "Rafael A Irizarry", "url": null, "hostname": null, "description": "Este libro presenta conceptos y destrezas que les ayudar\u00e1n abordar los retos de situaciones actuales del an\u00e1lisis de datos. Cubre conceptos de probabilidad, inferencia estad\u00edstica, regresi\u00f3n lineal y machine learning. Adem\u00e1s, les permitir\u00e1 desarrollar destrezas como la programaci\u00f3n R, el wrangling de datos con dplyr, la visualizaci\u00f3n de datos con ggplot2, la organizaci\u00f3n de archivos con Shell de UNIX / Linux, el control de versiones con GitHub y la preparaci\u00f3n de documentos reproducibles con R markdown.", "sitename": null, "date": "2009-09-21", "cleaned_text": "Cap\u00edtulo 33 Sets grandes de datos Los problemas de machine learning a menudo implican sets de datos que son tan o m\u00e1s grandes que el set de datos MNIST. Existe una variedad de t\u00e9cnicas computacionales y conceptos estad\u00edsticos que son \u00fatiles para an\u00e1lisis de grandes sets de datos. En este cap\u00edtulo, exploramos brevemente estas t\u00e9cnicas y conceptos al describir \u00e1lgebra matricial, reducci\u00f3n de dimensiones, regularizaci\u00f3n y factorizaci\u00f3n de matrices. Utilizamos sistemas de recomendaci\u00f3n relacionados con las clasificaciones de pel\u00edculas como un ejemplo motivador. 33.1 \u00c1lgebra matricial En machine learning, las situaciones en las que todos los predictores son num\u00e9ricos, o pueden representarse como n\u00fameros son comunes. El set de datos de d\u00edgitos es un ejemplo: cada p\u00edxel registra un n\u00famero entre 0 y 255. Carguemos los datos: En estos casos, a menudo es conveniente guardar los predictores en una matriz y el resultado en un vector en lugar de utilizar un data frame. Pueden ver que los predictores se guardan en una matriz: Esta matriz representa 60,000 d\u00edgitos, as\u00ed que para los ejemplos en este cap\u00edtulo, usaremos un subconjunto m\u00e1s manejable. Tomaremos los primeros 1,000 predictores x y etiquetas y: La raz\u00f3n principal para usar matrices es que ciertas operaciones matem\u00e1ticas necesarias para desarrollar c\u00f3digo eficiente se pueden realizar usando t\u00e9cnicas de una rama de las matem\u00e1ticas llamada \u00e1lgebra lineal. De hecho, \u00e1lgebra lineal y notaci\u00f3n matricial son elementos claves del lenguaje utilizado en trabajos acad\u00e9micos que describen t\u00e9cnicas de machine learning. No cubriremos \u00e1lgebra lineal en detalle aqu\u00ed, pero demostraremos c\u00f3mo usar matrices en R para que puedan aplicar las t\u00e9cnicas de \u00e1lgebra lineal ya implementadas en la base R u otros paquetes. Para motivar el uso de matrices, plantearemos cinco preguntas/desaf\u00edos: 1. \u00bfAlgunos d\u00edgitos requieren m\u00e1s tinta que otros? Estudien la distribuci\u00f3n de la oscuridad total de p\u00edxeles y c\u00f3mo var\u00eda seg\u00fan los d\u00edgitos. 2. \u00bfAlgunos p\u00edxeles no son informativos? Estudien la variaci\u00f3n de cada p\u00edxel y eliminen los predictores (columnas) asociados con los p\u00edxeles que no cambian mucho y, por lo tanto, no proveen mucha informaci\u00f3n para la clasificaci\u00f3n. 3. \u00bfPodemos eliminar las manchas? Primero, observen la distribuci\u00f3n de todos los valores de p\u00edxeles. Usen esto para elegir un umbral para definir el espacio no escrito. Luego, cambien cualquier valor por debajo de ese umbral a 0. 4. Binaricen los datos. Primero, observen la distribuci\u00f3n de todos los valores de p\u00edxeles. Usen esto para elegir un umbral para distinguir entre escritura y no escritura. Luego, conviertan todas las entradas en 1 o 0, respectivamente. 5. Escalen cada uno de los predictores en cada entrada para tener el mismo promedio y desviaci\u00f3n est\u00e1ndar. Para completar esto, tendremos que realizar operaciones matem\u00e1ticas que involucran varias variables. El tidyverse no est\u00e1 desarrollado para realizar este tipo de operaciones matem\u00e1ticas. Para esta tarea, es conveniente usar matrices. Antes de hacer esto, presentaremos la notaci\u00f3n matricial y el c\u00f3digo R b\u00e1sico para definir y operar en matrices. 33.1.1 Notaci\u00f3n En \u00e1lgebra matricial, tenemos tres tipos principales de objetos: escalares, vectores y matrices. Un escalar es solo un n\u00famero, por ejemplo \\(a = 1\\). Para denotar escalares en notaci\u00f3n matricial, generalmente usamos una letra min\u00fascula no en negrilla. Los vectores son como los vectores num\u00e9ricos que definimos en R: incluyen varias entradas escalares. Por ejemplo, la columna que contiene el primer p\u00edxel: tiene 1,000 entradas. En \u00e1lgebra matricial, utilizamos la siguiente notaci\u00f3n para un vector la notaci\u00f3n matem\u00e1tica para representar diferentes atributos Si estamos escribiendo una columna, como \\(\\mathbf{X}_1\\), en una oraci\u00f3n, a menudo usamos la notaci\u00f3n: \\(\\mathbf{X}_1 = ( x_{1,1}, \\dots x_{N,1})^\\top\\) con \\(^\\top\\) la operaci\u00f3n de transposici\u00f3n que convierte las columnas en filas y las filas en columnas. Una matriz se puede definir como una serie de vectores del mismo tama\u00f1o unidos \\end{pmatrix} \\] La dimensi\u00f3n de una matriz a menudo es un atributo importante necesario para asegurar que se puedan realizar ciertas operaciones. La dimensi\u00f3n es un resumen de dos n\u00fameros definido como el n\u00famero de filas \\(\\times\\) el n\u00famero de columnas. En R, podemos extraer la dimensi\u00f3n de una matriz con la funci\u00f3n dim: Los vectores pueden considerarse \\(N\\times 1\\) matrices. Sin embargo, en R, un vector no tiene dimensiones: No obstante, expl\u00edcitamente convertimos un vector en una matriz usando la funci\u00f3n as.matrix: Podemos usar esta notaci\u00f3n para denotar un n\u00famero arbitrario de predictores con la siguiente matriz \\(N\\times p\\), por en Ahora aprenderemos varias operaciones \u00fatiles relacionadas con el \u00e1lgebra matricial. Utilizamos tres de las preguntas motivadoras mencionadas anteriormente. 33.1.2 Convertir un vector en una matriz A menudo es \u00fatil convertir un vector en una matriz. Por ejemplo, debido a que las variables son p\u00edxeles en una cuadr\u00edcula, podemos convertir las filas de intensidades de p\u00edxeles en una matriz que representa esta cuadr\u00edcula. Podemos convertir un vector en una matriz con la funci\u00f3n matrix y especificando el n\u00famero de filas y columnas que debe tener la matriz resultante. La matriz se llena por columna: la primera columna se llena primero, luego la segunda y as\u00ed sucesivamente. Este ejemplo ayuda a [5,] 5 10 15] Podemos llenar por fila usando el argumento byrow. Entonces, por ejemplo, para transponer la matriz mat, podemos 7 8 9 10] [#> [3,] 11 12 13 14 15] Cuando convertimos las columnas en filas, nos referimos a las operaciones como transponer la matriz. La funci\u00f3n t se puede usar para transponer directamente una matriz: Advertencia: La funci\u00f3n matrix recicla valores en el vector sin advertencia si el producto de las columnas y las filas no coincide con la longitud del vector: [matrix(my_vector, 4, 5)] [#> Warning in matrix(my_vector, 4, de datos [15] no es] [#> un subm\u00faltiplo o m\u00faltiplo 6 10 14 7 11 15 4] [#> [4,] 4 8 12 1 5] Para poner las intensidades de p\u00edxeles de nuestra, digamos, tercera entrada, que es 4 en la cuadr\u00edcula, podemos usar: Para confirmar que lo hemos hecho correctamente, podemos usar la funci\u00f3n image, que muestra una imagen de su tercer argumento. La parte superior de este gr\u00e1fico es el p\u00edxel 1, que se muestra en la parte inferior para que la imagen se voltee. A continuaci\u00f3n incluimos el c\u00f3digo que muestra c\u00f3mo voltearlo: 33.1.3 Res\u00famenes de filas y columnas Para la primera tarea, relacionada con la oscuridad total de p\u00edxeles, queremos sumar los valores de cada fila y luego visualizar c\u00f3mo estos valores var\u00edan por d\u00edgito. La funci\u00f3n rowSums toma una matriz como entrada y calcula los valores deseados: Tambi\u00e9n podemos calcular los promedios con rowMeans si queremos que los valores permanezcan entre 0 y 255: Una vez que tengamos esto, podemos generar un diagrama de caja: [tibble(labels = = \"boxplot\")] De este gr\u00e1fico vemos que, como era de esperar, los 1s usan menos tinta que los otros d\u00edgitos. Podemos calcular las sumas y los promedios de la columna usando la funci\u00f3n colSums y colMeans, respectivamente. El paquete matrixStats agrega funciones que realizan operaciones en cada fila o columna de manera muy eficiente, incluyendo las funciones rowSds y colSds. 33.1.4 apply Las funciones que acabamos de describir est\u00e1n realizando una operaci\u00f3n similar a la que hacen sapply y la funci\u00f3n map de purrr: aplicar la misma funci\u00f3n a una parte de su objeto. En este caso, la funci\u00f3n se aplica a cada fila o cada columna. La funci\u00f3n apply les permite aplicar cualquier funci\u00f3n, no solo sum o mean, a una matriz. El primer argumento es la matriz, el segundo es la dimensi\u00f3n (1 para las filas y 2 para las columnas) y el tercero es la funci\u00f3n. As\u00ed, por ejemplo, rowMeans se puede escribir como: Pero noten que al igual que con sapply y map, podemos ejecutar cualquier funci\u00f3n. Entonces, si quisi\u00e9ramos la desviaci\u00f3n est\u00e1ndar para cada columna, podr\u00edamos escribir: La desventaja de esta flexibilidad es que estas operaciones no son tan r\u00e1pidas como las funciones dedicadas, como rowMeans. 33.1.5 Filtrar columnas basado en res\u00famenes Ahora pasamos a la tarea 2: estudiar la variaci\u00f3n de cada p\u00edxel y eliminar las columnas asociadas con p\u00edxeles que no cambian mucho y, por lo tanto, no informan la clasificaci\u00f3n. Aunque es un enfoque simplista, cuantificaremos la variaci\u00f3n de cada p\u00edxel con su desviaci\u00f3n est\u00e1ndar en todas las entradas. Como cada columna representa un p\u00edxel, utilizamos la funci\u00f3n colSds del paquete matrixStats: Un vistazo r\u00e1pido a la distribuci\u00f3n de estos valores muestra que algunos p\u00edxeles tienen una variabilidad muy baja de entrada a entrada: Esto tiene sentido ya que no escribimos en algunas partes del cuadro. Aqu\u00ed est\u00e1 la variaci\u00f3n graficada por ubicaci\u00f3n: Vemos que hay poca variaci\u00f3n en las esquinas. Podr\u00edamos eliminar atributos que no tienen variaci\u00f3n ya que estos no nos ayuda a predecir. En la Secci\u00f3n [2.4.7](r-basics.html#matrices), describimos las operaciones utilizadas para extraer columnas: y para extraer filas: Adem\u00e1s, podemos usar \u00edndices l\u00f3gicos para determinar qu\u00e9 columnas o filas mantener. Entonces, si quisi\u00e9ramos eliminar predictores no informativos de nuestra matriz, podr\u00edamos escribir esta l\u00ednea de c\u00f3digo: Solo se mantienen las columnas para las que la desviaci\u00f3n est\u00e1ndar es superior a 60, lo que elimina m\u00e1s de la mitad de los predictores. Aqu\u00ed agregamos una advertencia importante relacionada con el subconjunto de matrices: si seleccionan una columna o una fila, el resultado ya no es una matriz sino un vector. Sin embargo, podemos preservar la clase de matriz usando el argumento drop=FALSE: 33.1.6 Indexaci\u00f3n con matrices Podemos hacer r\u00e1pidamente un histograma de todos los valores en nuestro set de datos. Vimos c\u00f3mo podemos convertir vectores en matrices. Tambi\u00e9n podemos deshacer esto y convertir matrices en vectores. La operaci\u00f3n se realiza por fila: Para ver un histograma de todos nuestros datos predictores, podemos usar: Notamos una clara dicotom\u00eda que se explica como partes de la imagen con tinta y partes sin ella. Si creemos que los valores menor que, digamos, 50 son manchas, podemos cambiarlos a cero usando: Para ver un ejemplo de c\u00f3mo esto ocurre, usamos una matriz m\u00e1s peque\u00f1a: 5 10 15] Tambi\u00e9n podemos usar operadores l\u00f3gicas con una matriz de valores logicos: 33.1.7 Binarizar los datos El histograma anterior parece sugerir que estos datos son principalmente binarios. Un p\u00edxel tiene tinta o no. Usando lo que hemos aprendido, podemos binarizar los datos usando solo operaciones de matrices: Tambi\u00e9n podemos convertir a una matriz de valores l\u00f3gicos y luego forzar una conversi\u00f3n a n\u00fameros como este: 33.1.8 Vectorizaci\u00f3n para matrices En R, si restamos un vector de una matriz, el primer elemento del vector se resta de la primera fila, el segundo elemento de la segunda fila, y as\u00ed sucesivamente. Usando notaci\u00f3n matem\u00e1tica, lo escribir\u00edamos Lo mismo es v\u00e1lido para otras operaciones aritm\u00e9ticas. Esto implica que podemos escalar cada fila de una matriz as\u00ed: Si desean escalar cada columna, tengan cuidado ya que este enfoque no funciona para las columnas. Para realizar una operaci\u00f3n similar, convertimos las columnas en filas usando la transposici\u00f3n t, procedemos como se indica arriba y volvemos a transponer: Tambi\u00e9n podemos usar la funci\u00f3n sweep que funciona de manera similar a apply. Toma cada entrada de un vector y la resta de la fila o columna correspondiente. La funci\u00f3n sweep tiene otro argumento que les permite definir la operaci\u00f3n aritm\u00e9tica. Entonces, para dividir por la desviaci\u00f3n est\u00e1ndar, hacemos lo siguiente: 33.1.9 Operaciones de \u00e1lgebra matricial Finalmente, aunque no discutimos las operaciones de \u00e1lgebra matricial, como la multiplicaci\u00f3n de matrices, compartimos aqu\u00ed los comandos relevantes para aquellos que conocen las matem\u00e1ticas y quieren aprender el c\u00f3digo: 1. La multiplicaci\u00f3n de matrices se realiza con %*%. Por ejemplo, el producto cruzado es: 2. Podemos calcular el producto cruzado directamente con la funci\u00f3n: 3. Para calcular el inverso de una funci\u00f3n, usamos solve. Aqu\u00ed se aplica al producto cruzado: 4. La descomposici\u00f3n QR est\u00e1 f\u00e1cilmente disponible mediante el uso de la funci\u00f3n qr: 33.2 Ejercicios 1. Cree una matriz de 100 por 10 de n\u00fameros normales generados aleatoriamente. Ponga el resultado en x. 2. Aplique las tres funciones de R que le dan la dimensi\u00f3n de x, el n\u00famero de filas de x y el n\u00famero de columnas de x, respectivamente. 3. Agregue el escalar 1 a la fila 1, el escalar 2 a la fila 2 y as\u00ed sucesivamente, a la matriz x. 4. Agregue el escalar 1 a la columna 1, el escalar 2 a la columna 2 y as\u00ed sucesivamente, a la matriz x. Sugerencia: use sweep con FUN = \"+\". 5. Calcule el promedio de cada fila de x. 6. Calcule el promedio de cada columna de x. 7. Para cada d\u00edgito en los datos de entrenamiento MNIST, calcule la proporci\u00f3n de p\u00edxeles que se encuentran en un \u00e1rea gris, definida como valores entre 50 y 205. Haga un diagrama de caja basado en clase de d\u00edgitos. Sugerencia: utilice operadores l\u00f3gicos y rowMeans. 33.3 Distancia Muchos de los an\u00e1lisis que realizamos con datos de alta dimensi\u00f3n se relacionan directa o indirectamente con la distancia. La mayor\u00eda de las t\u00e9cnicas de agrupamiento y machine learning se basan en la capacidad de definir la distancia entre observaciones, utilizando atributos (features en ingl\u00e9s) o predictores. 33.3.1 Distancia euclidiana Como repaso, definamos la distancia entre dos puntos, \\(A\\) y \\(B\\), en un plano cartesiano. La distancia euclidiana entre \\(A\\) y \\(B\\) (A_y-B_y)^2} \\] Esta definici\u00f3n se aplica al caso de una dimensi\u00f3n, en la que la distancia entre dos n\u00fameros es el valor absoluto de su diferencia. Entonces, si nuestros dos n\u00fameros unidimensionales son \\(A\\) y \\(B\\), la distancia es: \\[ \\mbox{dist}(A,B) = \\sqrt{ (A - B)^2 } = | A - B | \\] 33.3.2 Distancia en dimensiones superiores Anteriormente presentamos un set de datos de entrenamiento con matriz para 784 atributos. Con fines ilustrativos, veremos una muestra aleatoria en x y las etiquetas en y. Para el prop\u00f3sito de, por ejemplo, suavizamiento, estamos interesados en describir la distancia entre observaciones; en este caso, d\u00edgitos. M\u00e1s adelante, con el fin de seleccionar atributos, tambi\u00e9n podr\u00edamos estar interesados en encontrar p\u00edxeles que se comporten de manera similar en todas las muestras. Para definir la distancia, necesitamos saber qu\u00e9 son puntos, ya que la distancia matem\u00e1tica se calcula entre puntos. Con datos de alta dimensi\u00f3n, los puntos ya no est\u00e1n en el plano cartesiano. En cambio, los puntos est\u00e1n en dimensiones m\u00e1s altas. Ya no podemos visualizarlos y necesitamos pensar de manera abstracta. Por ejemplo, predictores \\(\\mathbf{X}_i\\) se definen como un punto en el espacio dimensional 784: \\(\\mathbf{X}_i = (x_{i,1},\\dots,x_{i,784})^\\top\\). Una vez que definamos los puntos de esta manera, la distancia euclidiana se define de manera muy similar a la de dos dimensiones. Por ejemplo, la distancia entre los predictores para dos observaciones, digamos observaciones Este es solo un n\u00famero no negativo, tal como lo es para dos dimensiones. 33.3.3 Ejemplo de distancia euclidiana Las etiquetas para las tres primeras observaciones son: Los vectores de predictores para cada una de estas observaciones son: El primer y tercer n\u00famero son 7s y el segundo es un 2. Esperamos que las distancias entre el mismo n\u00famero: sean m\u00e1s peque\u00f1as que entre diferentes n\u00fameros: Como se esperaba, los 7s est\u00e1n m\u00e1s cerca uno del otro. Una forma m\u00e1s r\u00e1pida de calcular esto es usar podemos calcular todas las distancias a la vez de manera relativamente r\u00e1pida utilizando la funci\u00f3n dist, que calcula la distancia entre cada fila y produce un objeto de clase dist: Hay varias funciones relacionadas con machine learning en R que toman objetos de clase dist como entrada. Para acceder a las entradas usando \u00edndices de fila y columna, necesitamos forzar d a ser una matriz. Podemos ver la distancia que calculamos arriba de esta manera: R\u00e1pidamente vemos una imagen de estas distancias usando este c\u00f3digo: Si ordenamos esta distancia por las etiquetas, podemos ver que, en general, los 2s est\u00e1n m\u00e1s cerca uno del otro y los 7s est\u00e1n m\u00e1s cerca el uno del otro: Algo que notamos aqu\u00ed es que parece haber m\u00e1s uniformidad en la forma en que se dibujan los 7s, ya que parecen estar m\u00e1s cercas (m\u00e1s rojos) a otros 7s que los 2s a otros 2s. 33.3.4 Espacio predictor El espacio predictor (predictor space en ingl\u00e9s) es un concepto que a menudo se usa para describir algoritmos de machine learning. El t\u00e9rmino espacio se refiere a una definici\u00f3n matem\u00e1tica que no describimos en detalle aqu\u00ed. En cambio, ofrecemos una explicaci\u00f3n simplificada para ayudar a entender el t\u00e9rmino espacio predictor cuando se usa en el contexto de algoritmos de machine learning. El espacio predictor puede considerarse como la colecci\u00f3n de todos los posibles vectores de predictores que deben considerarse para el reto en cuesti\u00f3n de machine learning. Cada miembro del espacio se conoce como un punto. Por ejemplo, en el set de datos 2 o 7, el espacio predictor consta de todos los pares \\((x_1, x_2)\\) tal que ambos \\(x_1\\) y \\(x_2\\) est\u00e1n dentro de 0 y 1. Este espacio en particular puede representarse gr\u00e1ficamente como un cuadrado. En el set de datos MNIST, el espacio predictor consta de todos los vectores de 784 dimensiones, con cada elemento vectorial un n\u00famero entero entre 0 y 256. Un elemento esencial de un espacio predictor es que necesitamos definir una funci\u00f3n que nos de la distancia entre dos puntos. En la mayor\u00eda de los casos, usamos la distancia euclidiana, pero hay otras posibilidades. Un caso particular en el que no podemos simplemente usar la distancia euclidiana es cuando tenemos predictores categ\u00f3ricos. Definir un espacio predictor es \u00fatil en machine learning porque hacemos cosas como definir vecindarios de puntos, como lo requieren muchas t\u00e9cnicas de suavizaci\u00f3n. Por ejemplo, podemos definir un vecindario como todos los puntos que est\u00e1n dentro de 2 unidades de un centro predefinido. Si los puntos son bidimensionales y usamos la distancia euclidiana, este vecindario se representa gr\u00e1ficamente como un c\u00edrculo con radio 2. En tres dimensiones, el vecindario es una esfera. Pronto aprenderemos sobre algoritmos que dividen el espacio en regiones que no se superponen y luego hacen diferentes predicciones para cada regi\u00f3n utilizando los datos de la regi\u00f3n. 33.3.5 Distancia entre predictores Tambi\u00e9n podemos calcular distancias entre predictores. Si \\(N\\) es el n\u00famero de observaciones, la distancia entre dos predictores, digamos 1 y 2, es: \\[ \\mbox{dist}(1,2) = \\sqrt{ \\sum_{i=1}^{N} (x_{i,1}-x_{i,2})^2 } \\] Para calcular la distancia entre todos los pares de los 784 predictores, primero podemos transponer la matriz y luego usar dist: 33.4 Ejercicios 1. Cargue el siguiente set de datos: Este set de datos incluye una matriz x: con la expresi\u00f3n g\u00e9nica medida en 500 genes para 189 muestras biol\u00f3gicas que representan siete tejidos diferentes. El tipo de tejido se almacena en y: Calcule la distancia entre cada observaci\u00f3n y almac\u00e9nela en un objeto d. 2. Compare la distancia entre las dos primeras observaciones (ambos cerebelos), las observaciones 39 y 40 (ambos colones) y las observaciones 73 y 74 (ambos endometrios). Vea si las observaciones del mismo tipo de tejido est\u00e1n m\u00e1s cercanas entre s\u00ed. 3. Vemos que, de hecho, las observaciones del mismo tipo de tejido est\u00e1n m\u00e1s cercanas entre s\u00ed en los seis ejemplos de tejido que acabamos de examinar. Haga un diagrama de todas las distancias usando la funci\u00f3n image para ver si este patr\u00f3n es general. Sugerencia: primero convierta d en una matriz. 33.5 Reducci\u00f3n de dimensiones Un reto t\u00edpico de machine learning incluir\u00e1 una gran cantidad de predictores, lo que hace que la visualizaci\u00f3n sea algo retante. Hemos mostrado m\u00e9todos para visualizar datos univariados y emparejados, pero los gr\u00e1ficos que revelan relaciones entre muchas variables son m\u00e1s complicados en dimensiones m\u00e1s altas. Por ejemplo, para comparar cada uno de las 784 atributos en nuestro ejemplo de predicci\u00f3n de d\u00edgitos, tendr\u00edamos que crear, por ejemplo, 306,936 diagramas de dispersi\u00f3n. La creaci\u00f3n de un \u00fanico diagrama de dispersi\u00f3n de los datos es imposible debido a la alta dimensionalidad. Aqu\u00ed describimos t\u00e9cnicas eficaces y \u00fatiles para el an\u00e1lisis exploratorio de datos, entre otras cosas, generalmente conocidas como reducci\u00f3n de dimensiones. La idea general es reducir la dimensi\u00f3n del set de datos mientras se conservan caracter\u00edsticas importantes, como la distancia entre atributos u observaciones. Con menos dimensiones, la visualizaci\u00f3n es m\u00e1s factible. La t\u00e9cnica detr\u00e1s de todo, la descomposici\u00f3n de valores singulares, tambi\u00e9n es \u00fatil en otros contextos. El an\u00e1lisis de componentes principales (principal component analysis o PCA por sus siglas en ingl\u00e9s) es el enfoque que mostraremos. Antes de aplicar PCA a sets de datos de alta dimensi\u00f3n, motivaremos las ideas con un ejemplo sencillo. 33.5.1 Preservando la distancia Consideremos un ejemplo con alturas de gemelos. Algunas parejas son adultas, otras son ni\u00f1os. Aqu\u00ed simulamos 100 puntos bidimensionales que representan el n\u00famero de desviaciones est\u00e1ndar que cada individuo tiene respecto a la altura media. Cada punto es un par de gemelos. Utilizamos la funci\u00f3n mvrnorm del paquete MASS para simular datos de distribuci\u00f3n normal de dos variables. [set.seed(1988)] [library(MASS)] [n <- 100] [Sigma <- matrix(c(9, 9 * 1), 2, 2)] [x <- Sigma))] Un diagrama de dispersi\u00f3n revela que la correlaci\u00f3n es alta y que hay dos grupos de gemelos, los adultos (puntos superiores derechos) y los ni\u00f1os (puntos inferiores izquierdos): Nuestros atributos son \\(N\\) puntos bidimensionales, las dos alturas y, con fines ilustrativos, finjiremos como si visualizar dos dimensiones es demasiado dif\u00edcil. Por lo tanto, queremos reducir las dimensiones de dos a una, pero todav\u00eda poder entender atributos importantes de los datos, por ejemplo, que las observaciones se agrupan en dos grupos: adultos y ni\u00f1os. Consideremos un desaf\u00edo espec\u00edfico: queremos un resumen unidimensional de nuestros predictores a partir del cual podamos aproximar la distancia entre dos observaciones. En el gr\u00e1fico anterior, mostramos la distancia entre la observaci\u00f3n 1 y 2 (azul) y la observaci\u00f3n 1 y 51 (rojo). Noten que la l\u00ednea azul es m\u00e1s corta, que implica que 1 y 2 est\u00e1n m\u00e1s cerca. Podemos calcular estas distancias usando dist: Esta distancia se basa en dos dimensiones y necesitamos una aproximaci\u00f3n de distancia basada en solo una. Comencemos con un enfoque simplista de solo eliminar una de las dos dimensiones. Comparemos las distancias reales con la distancia calculada solo con la primera dimensi\u00f3n: Aqu\u00ed est\u00e1n las distancias aproximadas versus las distancias originales: El gr\u00e1fico se ve casi igual si usamos la segunda dimensi\u00f3n. Obtenemos una subestimaci\u00f3n general. Esto no sorprende porque estamos a\u00f1adiendo m\u00e1s cantidades positivas al c\u00e1lculo de la distancia a medida que aumentamos el n\u00famero de dimensiones. Si, en cambio, usamos un promedio, como este: \\[\\sqrt{ \\frac{1}{2} \\sum_{j=1}^2 (X_{1,j}-X_{2,j})^2 la distancia por \\(\\sqrt{2}\\) para lograr la correcci\u00f3n. Esto funciona bastante bien y obtenemos una diferencia t\u00edpica de: Ahora, \u00bfpodemos elegir un resumen unidimensional que haga que esta aproximaci\u00f3n sea a\u00fan mejor? Si consideramos el diagrama de dispersi\u00f3n anterior y visualizamos una l\u00ednea entre cualquier par de puntos, la longitud de esta l\u00ednea es la distancia entre los dos puntos. Estas l\u00edneas tienden a ir a lo largo de la direcci\u00f3n de la diagonal. Noten que si en su lugar graficamos la diferencia versus el promedio: podemos ver c\u00f3mo la distancia entre puntos se explica principalmente por la primera dimensi\u00f3n: el promedio. Esto significa que podemos ignorar la segunda dimensi\u00f3n y no perder demasiada informaci\u00f3n. Si la l\u00ednea es completamente plana, no perdemos ninguna informaci\u00f3n. Usando la primera dimensi\u00f3n de esta matriz transformada, obtenemos una aproximaci\u00f3n a\u00fan mejor: con la diferencia t\u00edpica mejorada aproximadamente un 35%: M\u00e1s tarde, aprendemos que z[,1] es el primer componente principal de la matriz x. 33.5.2 Transformaciones lineales (avanzado) Tengan en cuenta que cada fila de \\(X\\) se transform\u00f3 usando una transformaci\u00f3n lineal. Para cualquier fila \\(i\\), la primera entrada fue: \\[Z_{i,1} y \\(a_{2,1} = 0.5\\). La segunda entrada tambi\u00e9n fue transformaci\u00f3n \\[Z_{i,2} a_{1,2} y \\(a_{2,2} = -1\\). Adem\u00e1s, podemos usar la transformaci\u00f3n lineal para obtener \\(X\\) de \\(Z\\): \\[X_{i,1} = -0.5\\). Si saben \u00e1lgebra lineal, pueden escribir la operaci\u00f3n que acabamos de realizar de esta manera: \\[ Z = X A \\mbox{ with } A = \\, \\begin{pmatrix} 1/2&1\\\\ 1/2&-1\\\\ \\end{pmatrix}. \\] Y que podemos a \\(X\\) multiplicando por \\(A^{-1}\\) as\u00ed: \\[ X = \\begin{pmatrix} 1&1\\\\ 1/2&-1/2\\\\ \\end{pmatrix}. \\] La reducci\u00f3n de dimensiones frecuentemente se puede describir como la aplicaci\u00f3n de una transformaci\u00f3n \\(A\\) a una matriz \\(X\\) con muchas columnas que mueven la informaci\u00f3n contenida en \\(X\\) a las primeras columnas de \\(Z=AX\\), manteniendo solo estas pocas columnas informativas y reduciendo as\u00ed la dimensi\u00f3n de los vectores contenidos en las filas. 33.5.3 Transformaciones ortogonales (avanzado) Noten que dividimos lo anterior por \\(\\sqrt{2}\\) para tomar en cuenta las diferencias en las dimensiones al comparar una distancia de 2 dimensiones con una distancia de 1 dimensi\u00f3n. De hecho, podemos garantizar que las escalas de distancia sigan siendo las mismas si volvemos a escalar las columnas de \\(A\\) para asegurar que la suma de cuadrados es 1: \\[a_{1,1}^2 + a_{2,1}^2 = 1\\mbox{ and } a_{1,2}^2 + a_{2,2}^2=1,\\] y que correlaci\u00f3n a_{1,1} a_{1,2} + a_{2,1} a_{2,2} = 0. \\] Recuerden que si las columnas est\u00e1n centradas para tener un promedio de 0, entonces la suma de los cuadrados es equivalente a la varianza o desviaci\u00f3n est\u00e1ndar al cuadrado. En nuestro ejemplo, para lograr ortogonalidad, multiplicamos el primer set de coeficientes (primera columna de \\(A\\)) por \\(\\sqrt{2}\\) y el segundo por \\(1/\\sqrt{2}\\). Entonces obtenemos la misma distancia exacta cuando usamos ambas dimensiones: Esto nos da una transformaci\u00f3n que preserva la distancia entre dos puntos: y una aproximaci\u00f3n mejorada si usamos solo la primera dimensi\u00f3n: En este caso, \\(Z\\) se llama una rotaci\u00f3n ortogonal de \\(X\\): conserva las distancias entre filas. Tengan en cuenta que al usar la transformaci\u00f3n anterior, podemos resumir la distancia entre cualquier par de gemelos con una sola dimensi\u00f3n. Por ejemplo, una exploraci\u00f3n de datos unidimensionales de la primera dimensi\u00f3n de \\(Z\\) muestra claramente que hay dos grupos, adultos y ni\u00f1os: Redujimos exitosamente el n\u00famero de dimensiones de dos a uno con muy poca p\u00e9rdida de informaci\u00f3n. La raz\u00f3n por la que pudimos hacer esto es porque las columnas de \\(X\\) estaban muy correlacionadas: y la transformaci\u00f3n produjo columnas no correlacionadas con informaci\u00f3n \"independiente\" en cada columna: Una forma en que esta informaci\u00f3n puede ser \u00fatil en una aplicaci\u00f3n de machine learning es que podemos reducir la complejidad de un modelo utilizando solo \\(Z_1\\) en lugar de ambos \\(X_1\\) y \\(X_2\\). Es com\u00fan obtener datos con varios predictores altamente correlacionados. En estos casos, PCA, que describimos a continuaci\u00f3n, puede ser bastante \u00fatil para reducir la complejidad del modelo que se est\u00e1 ajustando. 33.5.4 An\u00e1lisis de componentes principales En el c\u00e1lculo anterior, la variabilidad total en nuestros datos puede definirse como la suma de la suma de los cuadrados de las columnas. Suponemos que las columnas est\u00e1n centradas, por lo que esta suma es equivalente a la suma de las varianzas de cada columna: \\[ y \\(v_2\\) al utilizar: y podemos mostrar matem\u00e1ticamente que si aplicamos una transformaci\u00f3n ortogonal como la anterior, la variaci\u00f3n total sigue siendo la misma: Sin embargo, mientras que la variabilidad en las dos columnas de X es casi la misma, en la versi\u00f3n transformada \\(Z\\), el 99% de la variabilidad se incluye solo en la primera dimensi\u00f3n: El primer componente principal (principal component o PC por sus siglas en ingl\u00e9s) de una matriz \\(X\\) es la transformaci\u00f3n ortogonal lineal de \\(X\\) que maximiza esta variabilidad. La funci\u00f3n prcomp provee esta informaci\u00f3n: Tengan en cuenta que el primer PC es casi el mismo que ese proporcionado por el \\((X_1 + X_2)/ \\sqrt{2}\\) que utilizamos anteriormente (excepto quiz\u00e1s por un cambio de signo que es arbitrario). La funci\u00f3n prcomp devuelve la rotaci\u00f3n necesaria para transformar \\(X\\) para que la variabilidad de las columnas disminuya de m\u00e1s variable a menos (se accede con $rotation) as\u00ed como la nueva matriz resultante (que se accede con $x). Por defecto, prcomp centra las columnas de \\(X\\) antes de calcular las matrices. Entonces, usando la multiplicaci\u00f3n de matrices que se muestra arriba, notamos que las dos siguientes operaciones dan el mismo resultado (demostrado por una diferencia entre elementos de pr\u00e1cticamente cero): La rotaci\u00f3n es ortogonal, lo que significa que el inverso es su transposici\u00f3n. Entonces tambi\u00e9n tenemos que estos dos son id\u00e9nticos: Podemos visualizarlos para ver c\u00f3mo el primer componente resume los datos. En el gr\u00e1fico a continuaci\u00f3n, el rojo representa valores altos y el azul representa valores negativos. M\u00e1s adelante, en la Secci\u00f3n [33.11.1](sets-grandes-de-datos.html#factor-analysis), aprendemos por qu\u00e9 llamamos a estos pesos (weights en ingl\u00e9s) y patrones (patterns en ingl\u00e9s): Resulta que podemos encontrar esta transformaci\u00f3n lineal no solo para dos dimensiones, sino tambi\u00e9n para matrices de cualquier dimensi\u00f3n \\(p\\). Para una matriz multidimensional \\(X\\) con \\(p\\) columnas, se puede encontrar una transformaci\u00f3n \\(Z\\) que conserva la distancia entre filas, pero con la varianza de las columnas en orden decreciente. La segunda columna es el segundo componente principal, la tercera columna es el tercer componente principal y as\u00ed sucesivamente. Como en nuestro ejemplo, si despu\u00e9s de un cierto n\u00famero de columnas, digamos \\(k\\), las variaciones de las columnas de \\(Z_j\\) con \\(j>k\\) son muy peque\u00f1as, significa que estas dimensiones tienen poco que contribuir a la distancia y podemos aproximar la distancia entre dos puntos con solo \\(k\\) dimensiones. Si \\(k\\) es mucho m\u00e1s peque\u00f1o que \\(p\\), entonces podemos lograr un resumen muy eficiente de nuestros datos. 33.5.5 Ejemplo de lirios Los datos del lirio (iris en ingl\u00e9s) son un ejemplo ampliamente utilizado en los cursos de an\u00e1lisis de datos. Incluye cuatro medidas bot\u00e1nicas relacionadas con tres especies de flores: Si imprimen iris$Species, ver\u00e1n que los datos est\u00e1n ordenados por especie. Calculemos la distancia entre cada observaci\u00f3n. Pueden ver claramente las tres especies con una especie muy diferente de las aplicamos PCA, deber\u00edamos poder aproximar esta distancia con solo dos dimensiones, comprimiendo las dimensiones altamente correlacionadas. Utilizando la funci\u00f3n summary, podemos ver la variabilidad dimensiones representan el 97% de la variabilidad. Por lo tanto, deber\u00edamos poder aproximar bien la distancia con dos dimensiones. Podemos visualizar los resultados de PCA: Y ver que el primer patr\u00f3n es la longitud del s\u00e9palo, la longitud del p\u00e9talo y el ancho del p\u00e9talo (rojo) en una direcci\u00f3n y el ancho del s\u00e9palo (azul) en la otra. El segundo patr\u00f3n es la longitud del s\u00e9palo y el ancho del p\u00e9talo en una direcci\u00f3n (azul) y la longitud y el ancho del p\u00e9talo en la otra (rojo). Pueden ver de los pesos que la primera PC1 controla la mayor parte de la variabilidad y separa claramente el primer tercio de las muestras (setosa) de los dos tercios (versicolor y virginica). Si miran la segunda columna de los pesos, observar\u00e1n que separa un poco versicolor (rojo) de virginica (azul). Podemos ver esto mejor al graficar los dos primeros PCs con color que las dos primeras dimensiones preservan la distancia: Este ejemplo es m\u00e1s realista que el primer ejemplo artificial que utilizamos, ya que mostramos c\u00f3mo podemos visualizar los datos usando dos dimensiones cuando los datos eran de cuatro dimensiones. 33.5.6 Ejemplo de MNIST El ejemplo de d\u00edgitos escritos tiene 784 atributos. \u00bfHay espacio para la reducci\u00f3n de datos? \u00bfPodemos crear algoritmos sencillos de machine learning con menos atributos? Carguemos los datos: Debido a que los p\u00edxeles son tan peque\u00f1os, esperamos que los p\u00edxeles cercanos entre s\u00ed en la cuadr\u00edcula est\u00e9n correlacionados, lo que significa que la reducci\u00f3n de dimensi\u00f3n deber\u00eda ser posible. Probemos PCA y exploremos la variaci\u00f3n de los PCs. Esto tomar\u00e1 unos segundos ya que es una matriz bastante grande. Podemos ver que los primeros PCs ya explican un gran porcentaje de solo mirar las dos primeras PCs vemos informaci\u00f3n sobre la clase. Aqu\u00ed hay una muestra aleatoria de 2,000 d\u00edgitos: las combinaciones lineales en la cuadr\u00edcula para tener una idea de lo que se est\u00e1 ponderando: Los PCs de menor varianza parecen estar relacionadas a la variabilidad irrelevante en las esquinas: Ahora apliquemos la transformaci\u00f3n que aprendimos con los datos de entrenamiento a los datos de evaluaci\u00f3n, reduzcamos la dimensi\u00f3n y ejecutemos knn3 en solo un peque\u00f1o n\u00famero de dimensiones. Intentamos 36 dimensiones ya que esto explica aproximadamente el 80% de los datos. Primero, ajuste set de evaluaci\u00f3n: Y estamos listos para predecir y evaluar los Con solo 36 dimensiones, obtenemos una exactitud muy superior a 0.95. 33.6 Ejercicios 1. Queremos explorar los predictores tissue_gene_expression grafic\u00e1ndolos. Procuramos tener una idea de qu\u00e9 observaciones est\u00e1n cercas entre s\u00ed, pero como los predictores son de 500 dimensiones, es dif\u00edcil graficar. Grafique los dos primeros componentes principales con color representando el tipo de tejido. 2. Los predictores de cada observaci\u00f3n se miden en el mismo dispositivo de medici\u00f3n (un microarreglo de expresi\u00f3n g\u00e9nica) despu\u00e9s de un procedimiento experimental. Se utiliza un dispositivo y procedimiento diferente para cada observaci\u00f3n. Esto puede introducir sesgos que afecten a todos los predictores de cada observaci\u00f3n de la misma manera. Para explorar el efecto de este posible sesgo, para cada observaci\u00f3n, calcule el promedio de todos los predictores y luego grafique esto contra el primer PC con el color que representa el tejido. Indique la correlaci\u00f3n. 3. Vemos una asociaci\u00f3n con el primer PC y los promedios de observaci\u00f3n. Vuelva a hacer el PCA pero solo despu\u00e9s de quitar el centro. 4. Para los primeros 10 PCs, haga un diagrama de caja que muestre los valores para cada tejido. 5. Grafique el porcentaje de varianza explicado por el n\u00famero de PC. Sugerencia: use la funci\u00f3n summary. 33.7 Sistemas de recomendaci\u00f3n Los sistemas de recomendaci\u00f3n utilizan clasificaciones que los consumidores le han dado a art\u00edculos para hacer recomendaciones espec\u00edficas. Las compa\u00f1\u00edas que venden muchos productos a muchos clientes y permiten que estos clientes califiquen sus productos, como Amazon, pueden recopilar sets de datos masivos que se pueden utilizar para predecir qu\u00e9 calificaci\u00f3n le otorgar\u00e1 un usuario en particular a un art\u00edculo espec\u00edfico. Art\u00edculos para los cuales se predice una calificaci\u00f3n alta para un usuario particular, se recomiendan a ese usuario. Netflix utiliza un sistema de recomendaci\u00f3n para predecir cu\u00e1ntas estrellas le dar\u00e1 un usuario a una pel\u00edcula espec\u00edfica. Una estrella sugiere que no es una buena pel\u00edcula, mientras que cinco estrellas sugieren que es una pel\u00edcula excelente. Aqu\u00ed, ofrecemos los conceptos b\u00e1sicos de c\u00f3mo se hacen estas recomendaciones, motivados por algunos de los enfoques adoptados por los ganadores del Netflix challenge. En octubre de 2006, Netflix le dio un reto a la comunidad de ciencia de datos: mejoren nuestro algoritmo de recomendaci\u00f3n por un 10% y ganen un mill\u00f3n de d\u00f3lares. En septiembre de 2009, los ganadores se anunciaron [120](#fn120). Pueden leer un buen resumen de c\u00f3mo se cre\u00f3 el algoritmo ganador aqu\u00ed: [http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/](http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/) y una explicaci\u00f3n m\u00e1s detallada aqu\u00ed: [http://www.netflixprize.com/assets/GrandPrize2009_BPC_BellKor.pdf](http://www.netflixprize.com/assets/GrandPrize2009_BPC_BellKor.pdf). Ahora le mostraremos algunas de las estrategias de an\u00e1lisis de datos utilizadas por el equipo ganador. 33.7.1 Datos de Movielens Los datos de Netflix no est\u00e1n disponibles p\u00fablicamente, pero el laboratorio de investigaci\u00f3n GroupLens [121](#fn121) gener\u00f3 su propia base de datos con m\u00e1s de 20 millones de calificaciones para m\u00e1s de 27,000 pel\u00edculas por m\u00e1s de 138,000 usuarios. Ponemos a disposici\u00f3n un peque\u00f1o subconjunto de estos datos a trav\u00e9s del paquete dslabs: Podemos ver que esta tabla est\u00e1 en formato tidy con miles de 2.5 1.26e9] [#> 2 1029 1996 Thril... 1 3 1.26e9] [#> 4 1129 Escape from New York 1981 Actio... 1 2 1.26e9] [#> 5 1172 Cinema Paradiso (Nuovo c... 1989 Drama 1 4 1.26e9] [#> # ... with 99,999 more rows] Cada fila representa una calificaci\u00f3n dada por un usuario a una pel\u00edcula. Podemos ver la cantidad de usuarios \u00fanicos que dan calificaciones y cu\u00e1ntas pel\u00edculas \u00fanicas fueron calificadas: Si multiplicamos esos dos n\u00fameros, obtenemos un n\u00famero mayor de 5 millones. Sin embargo, nuestra tabla de datos tiene aproximadamente 100,000 filas. Esto implica que no todos los usuarios calificaron todas las pel\u00edculas. Por lo tanto, podemos pensar en estos datos como una matriz muy grande, con usuarios en las filas y pel\u00edculas en las columnas, con muchas celdas vac\u00edas. La funci\u00f3n pivot_longer nos permite convertirla a este formato, pero si lo intentamos para toda la matriz, colgaremos a R. Mostremos la matriz para seis usuarios y cuatro pel\u00edculas. Pueden pensar en la tarea de un sistema de recomendaci\u00f3n como completar los NAs en la tabla de arriba. Para ver cu\u00e1n dispersa es la matriz, aqu\u00ed tenemos la matriz para una muestra aleatoria de 100 pel\u00edculas y 100 usuarios con amarillo indicando una combinaci\u00f3n de usuario/pel\u00edcula para la que tenemos una calificaci\u00f3n. Este reto de machine learning es m\u00e1s complicado de lo que hemos estudiado hasta ahora porque cada resultado \\(Y\\) tiene un set diferente de predictores. Para ver esto, tengan en cuenta que si estamos prediciendo la calificaci\u00f3n de la pel\u00edcula \\(i\\) por usuario \\(u\\), en principio, todas las otras clasificaciones relacionadas con la pel\u00edcula \\(i\\) y por el usuario \\(u\\) pueden usarse como predictores, pero diferentes usuarios califican diferentes pel\u00edculas y diferentes n\u00fameros de pel\u00edculas. Adem\u00e1s, podemos usar informaci\u00f3n de otras pel\u00edculas que hemos determinado que son parecidas a la pel\u00edcula \\(i\\) o de usuarios que se consideran similares al usuario \\(u\\). B\u00e1sicamente, toda la matriz se puede utilizar como predictores para cada celda. Veamos algunas de las propiedades generales de los datos para entender mejor los retos. Lo primero que notamos es que algunas pel\u00edculas se eval\u00faan m\u00e1s que otras. A continuaci\u00f3n se muestra la distribuci\u00f3n. Esto no deber\u00eda sorprendernos dado que hay pel\u00edculas de gran \u00e9xito vistas por millones y pel\u00edculas art\u00edsticas e independientes vistas por pocos. Nuestra segunda observaci\u00f3n es que algunos usuarios son m\u00e1s activos que otros en la calificaci\u00f3n de pel\u00edculas: 33.7.2 Sistemas de recomendaci\u00f3n como un desaf\u00edo de machine learning Para ver c\u00f3mo esto se puede considerar machine learning, noten que necesitamos construir un algoritmo con los datos que hemos recopilado que luego se aplicar\u00e1n fuera de nuestro control, a medida que los usuarios busquen recomendaciones de pel\u00edculas. As\u00ed que creamos un set de evaluaci\u00f3n para evaluar la exactitud de los modelos que implementamos. [library(caret)] [set.seed(755)] [test_index <- de que no incluimos usuarios y pel\u00edculas en el set de evaluaci\u00f3n que no aparecen en el set de entrenamiento, eliminamos estas entradas usando la funci\u00f3n semi_join: 33.7.3 Funci\u00f3n de p\u00e9rdida El Netflix challenge us\u00f3 la p\u00e9rdida de error t\u00edpica: decidieron un ganador basado en la desviaci\u00f3n cuadr\u00e1tica media (RMSE por sus siglas en ingl\u00e9s) en un set de evaluaci\u00f3n. Definimos \\(y_{u,i}\\) como la calificaci\u00f3n de la pel\u00edcula \\(i\\) por usuario \\(u\\) y denotamos nuestra predicci\u00f3n con \\(\\hat{y}_{u,i}\\). siendo el n\u00famero de combinaciones de usuario/pel\u00edcula y la suma que ocurre en todas estas combinaciones. Recuerden que podemos interpretar el RMSE de manera similar a una desviaci\u00f3n est\u00e1ndar: es el error t\u00edpico que cometemos al predecir una calificaci\u00f3n de pel\u00edcula. Si este n\u00famero es mayor que 1, significa que nuestro error t\u00edpico es mayor que una estrella, lo cual no es bueno. Escribamos una funci\u00f3n que calcule el RMSE para vectores de clasificaciones y sus predictores correspondientes: 33.7.4 Un primer modelo Comencemos construyendo el sistema de recomendaci\u00f3n m\u00e1s sencillo posible: predecimos la misma calificaci\u00f3n para todas las pel\u00edculas, independientemente del usuario. \u00bfQu\u00e9 n\u00famero deber\u00eda ser esta predicci\u00f3n? Podemos usar un enfoque basado en modelos para responder a esto. Un modelo que supone la misma calificaci\u00f3n para todas las pel\u00edculas y usuarios con todas las diferencias explicadas por la variaci\u00f3n aleatoria se ver\u00eda as\u00ed: \\[ Y_{u,i} = \\mu + \\varepsilon_{u,i} \\] con \\(\\varepsilon_{i,u}\\) errores independientes muestreados de la misma distribuci\u00f3n centrada en 0 y \\(\\mu\\) la calificaci\u00f3n \"verdadera\" para todas las pel\u00edculas. Sabemos que el estimador que minimiza el RMSE es el estimador de m\u00ednimos cuadrados de \\(\\mu\\) y, en este caso, es el promedio de todas las calificaciones: Si predecimos todas las calificaciones desconocidas con \\(\\hat{\\mu}\\), obtenemos el siguiente RMSE: Tengan en cuenta que si usan cualquier otro n\u00famero, obtendr\u00e1m un RMSE m\u00e1s alto. Por ejemplo: Al observar la distribuci\u00f3n de calificaciones, podemos visualizar que esta es la desviaci\u00f3n est\u00e1ndar de esa distribuci\u00f3n. Obtenemos un RMSE de aproximadamente 1. Para ganar el gran premio de $1,000,000, un equipo participante tuvo que obtener un RMSE de aproximadamente 0.857. \u00a1Definitivamente podemos mejorar! A medida que avanzamos, compararemos diferentes enfoques. Comencemos creando una tabla de resultados con este enfoque simplista: 33.7.5 Modelando los efectos de pel\u00edculas Sabemos por experiencia que algunas pel\u00edculas generalmente tienen una calificaci\u00f3n m\u00e1s alta que otras. Esta intuici\u00f3n, que las diferentes pel\u00edculas se clasifican de manera diferente, la confirma los datos. Podemos expandir nuestro modelo anterior agregando el t\u00e9rmino \\(b_i\\) para representar la clasificaci\u00f3n promedio de la pel\u00edcula \\(i\\): \\[ Y_{u,i} = \\mu + b_i + \\varepsilon_{u,i} \\] Los libros de texto de estad\u00edsticas se refieren a \\(b\\)s como efectos. Sin embargo, en los art\u00edculos sobre el Netflix challenge, se refieren a ellos como \"sesgo\" (o bias en ingl\u00e9s; por lo tanto, la notaci\u00f3n \\(b\\)). De nuevo podemos usar m\u00ednimos cuadrados para estimar \\(b_i\\) de la siguiente manera: Como hay miles de \\(b_i\\), a medida que cada pel\u00edcula obtiene una, la funci\u00f3n lm() ser\u00e1 muy lenta aqu\u00ed. Por eso, no recomendamos ejecutar el c\u00f3digo anterior. Pero en esta situaci\u00f3n particular, sabemos que el estimador de los m\u00ednimos cuadrados \\(\\hat{b}_i\\) es solo el promedio de \\(Y_{u,i} - \\hat{\\mu}\\) para cada pel\u00edcula \\(i\\). Entonces podemos calcularlos de esta manera (dejaremos de usar la notaci\u00f3n hat en el c\u00f3digo para representar los var\u00edan sustancialmente: Recuerden \\(\\hat{\\mu}=3.5\\), entonces una \\(b_i = 1.5\\) implica una calificaci\u00f3n perfecta de cinco estrellas. Veamos cu\u00e1nto mejora nuestra predicci\u00f3n cuando usamos \\(\\hat{y}_{u,i} = \\hat{\\mu} mejorar m\u00e1s? 33.7.6 Efectos de usuario Calculemos la calificaci\u00f3n promedio para el usuario \\(u\\) para aquellos que han calificado 100 = \"black\")] Noten que tambi\u00e9n existe una variabilidad sustancial entre los usuarios: algunos usuarios son muy exigentes y otros adoran cada pel\u00edcula. Esto implica que una mejora adicional de nuestro modelo puede ser: \\[ Y_{u,i} = \\] d\u00f3nde \\(b_u\\) es un efecto espec\u00edfico de cada usuario. Ahora, si un usuario exigente (\\(b_u\\) negativo) califica una pel\u00edcula excelente (\\(b_i\\) positiva), los efectos se contrarrestan y podemos predecir correctamente que este usuario le dio a esta gran pel\u00edcula un 3 en lugar de un 5. Para ajustar este modelo, podr\u00edamos nuevamente usar lm as\u00ed: pero, por las razones descritas anteriormente, no lo haremos. En cambio, calcularemos una aproximaci\u00f3n calculando \\(\\hat{\\mu}\\) y \\(\\hat{b}_i\\) y estimando \\(\\hat{b}_u\\) b_i))] Ahora podemos construir predictores y ver cu\u00e1nto mejora el RMSE: 33.8 Ejercicios 1. Cargue los datos movielens. Calcule el n\u00famero de calificaciones para cada pel\u00edcula y luego comp\u00e1relo con el a\u00f1o en que sali\u00f3 la pel\u00edcula. Transforme los datos usando la ra\u00edz cuadrada en los recuentos. 2. Vemos que, en promedio, las pel\u00edculas que salieron despu\u00e9s de 1993 obtienen m\u00e1s calificaciones. Tambi\u00e9n vemos que con las pel\u00edculas m\u00e1s nuevas, a partir de 1993, el n\u00famero de calificaciones disminuye con el a\u00f1o: entre m\u00e1s reciente sea una pel\u00edcula, menos tiempo han tenido los usuarios para calificarla. Entre las pel\u00edculas que salieron en 1993 o m\u00e1s tarde, \u00bfcu\u00e1les son las 25 pel\u00edculas con m\u00e1s calificaciones por a\u00f1o? Adem\u00e1s, indique la calificaci\u00f3n promedio. 3. De la tabla construida en el ejemplo anterior, vemos que las pel\u00edculas mejor calificadas tienden a tener calificaciones superiores al promedio. Esto no es sorprendente: m\u00e1s personas ven pel\u00edculas populares. Para confirmar esto, estratifique las pel\u00edculas posteriores a 1993 por calificaciones por a\u00f1o y calcule sus calificaciones promedio. Haga un gr\u00e1fico de la calificaci\u00f3n promedio versus calificaciones por a\u00f1o y muestre un estimador de la tendencia. 4. En el ejercicio anterior, vemos que entre m\u00e1s se califica una pel\u00edcula, mayor es la calificaci\u00f3n. Suponga que est\u00e1 haciendo un an\u00e1lisis predictivo en el que necesita completar las calificaciones faltantes con alg\u00fan valor. \u00bfCu\u00e1l de las siguientes estrategias usar\u00eda? - Completar los valores faltantes con la calificaci\u00f3n promedio de todas las pel\u00edculas. - Completar los valores faltantes con 0. - Completar el valor con un valor m\u00e1s bajo que el promedio ya que la falta de calificaci\u00f3n se asocia con calificaciones m\u00e1s bajas. Pruebe diferentes valores y eval\u00fae la predicci\u00f3n en un set de evaluaci\u00f3n. - Ninguna de las anteriores. 5. El set de datos movielens tambi\u00e9n incluye un sello de tiempo. Esta variable representa el tiempo y los datos en los que se le dio la calificaci\u00f3n. Las unidades son segundos desde el 1 de enero de 1970. Cree una nueva columna date con la fecha. Sugerencia: use la funci\u00f3n as_datetime en el paquete lubridate. 6. Calcule la calificaci\u00f3n promedio de cada semana y calcule este promedio para cada d\u00eda. Sugerencia: use la funci\u00f3n round_date antes de group_by. 7. El gr\u00e1fico muestra alguna evidencia de un efecto temporero. Si definimos \\(d_{u,i}\\) como el d\u00eda que el usuario \\(u\\) hizo su calificaci\u00f3n de la pel\u00edcula \\(i\\), \u00bfcu\u00e1l de los siguientes modelos es el m\u00e1s apropiado? - \\(Y_{u,i} = \\mu + b_i + + \\varepsilon_{u,i}\\), con \\(f\\) una funci\u00f3n suave de \\(d_{u,i}\\). 8. Los datos movielens tambi\u00e9n tienen un columna genres. Esta columna incluye todos los g\u00e9neros que aplican a la pel\u00edcula. Algunas pel\u00edculas pertenecen a varios g\u00e9neros. Defina una categor\u00eda como cualquier combinaci\u00f3n que aparezca en esta columna. Mantenga solo categor\u00edas con m\u00e1s de 1,000 calificaciones. Luego, calcule el promedio y error est\u00e1ndar para cada categor\u00eda. Grafique estos usando diagramas de barras de error. 9. El gr\u00e1fico muestra evidencia convincente de un efecto de g\u00e9nero. Si definimos \\(g_{u,i}\\) como el g\u00e9nero para la calificaci\u00f3n del usuario \\(u\\) de la pel\u00edcula \\(i\\), \u00bfcu\u00e1l de los siguientes modelos es el m\u00e1s apropiado? - \\(Y_{u,i} = \\mu + b_i b_u + una funci\u00f3n suave de \\(d_{u,i}\\). 33.9 Regularizaci\u00f3n 33.9.1 Motivaci\u00f3n A pesar de la gran variaci\u00f3n de pel\u00edcula a pel\u00edcula, nuestra mejora en RMSE fue solo como 5%. Exploremos d\u00f3nde cometimos errores en nuestro primer modelo, usando solo efectos de pel\u00edcula \\(b_i\\). Aqu\u00ed est\u00e1n los 10 errores Delta\" \"Stalag 17\"] Todas estas parecen ser pel\u00edculas desconocidas. Para muchas de ellas, predecimos calificaciones altas. Echemos un vistazo a las 10 peores y 10 mejores pel\u00edculas basadas en \\(\\hat{b}_i\\). Primero, vamos a crear una base de datos que conecta movieId al t\u00edtulo de la pel\u00edcula: Aqu\u00ed est\u00e1n las 10 mejores pel\u00edculas Todas parecen ser bastante desconocidas. 1 1 1 1 1 1 1 1 1] Las supuestas pel\u00edculas \"mejores\" y \"peores\" fueron calificadas por muy pocos usuarios, en la mayor\u00eda de los casos por solo 1. Estas pel\u00edculas son en su mayor\u00eda desconocidas. Esto se debe a que con solo unos pocos usuarios, tenemos m\u00e1s incertidumbre. Por lo tanto, mayores estimadores de \\(b_i\\), negativo o positivo, son m\u00e1s probables. Estos son estimadores ruidosos en los que no debemos confiar, especialmente cuando se trata de predicciones. Grandes errores pueden aumentar nuestro RMSE, por lo que preferimos ser conservadores cuando no estamos seguros. En secciones anteriores, calculamos el error est\u00e1ndar y construimos intervalos de confianza para tomar en cuenta los diferentes niveles de incertidumbre. Sin embargo, al hacer predicciones, necesitamos un n\u00famero, una predicci\u00f3n, no un intervalo. Para esto, presentamos el concepto de regularizaci\u00f3n. La regularizaci\u00f3n nos permite penalizar estimadores m\u00e1s grandes que se forman utilizando peque\u00f1os tama\u00f1os de muestra. Tienen puntos en com\u00fan con el enfoque bayesiano que redujo las predicciones descritas en la Secci\u00f3n [16.4](models.html#bayesian-statistics). 33.9.2 M\u00ednimos cuadrados penalizados La idea general detr\u00e1s de la regularizaci\u00f3n es restringir la variabilidad total de los tama\u00f1os del efecto. \u00bfPor qu\u00e9 esto ayuda? Consideren un caso en el que tenemos pel\u00edcula \\(i=1\\) con 100 clasificaciones de usuarios y 4 pel\u00edculas \\(i=2,3,4,5\\) con solo una calificaci\u00f3n de usuario. Tenemos la intenci\u00f3n de ajustar el modelo: \\[ Y_{u,i} = \\mu + b_i + \\varepsilon_{u,i} \\] Supongan que sabemos que la calificaci\u00f3n promedio es, digamos, \\(\\mu = 3\\). Si usamos m\u00ednimos cuadrados, el estimador para el primer efecto de pel\u00edcula \\(b_1\\) es el promedio de las 100 calificaciones de los usuarios, \\(1/100 \\sum_{i=1}^{100} (Y_{i,1} - \\mu)\\), que esperamos sea bastante preciso. Sin embargo, el estimador para las pel\u00edculas 2, 3, 4 y 5 ser\u00e1 simplemente la desviaci\u00f3n observada de la calificaci\u00f3n promedio \\(\\hat{b}_i = Y_{u,i} - \\hat{\\mu}\\). Pero esto es un estimador basado en un solo n\u00famero, por lo cual no ser\u00e1 preciso. Tengan en cuenta que estos estimadores hacen el error \\(Y_{u,i} - \\mu + \\hat{b}_i\\) igual a 0 para \\(i=2,3,4,5\\), pero este es un caso de sobreentrenamiento. De hecho, ignorando al \u00fanico usuario y adivinando que las pel\u00edculas 2, 3, 4 y 5 son solo pel\u00edculas promedio (\\(b_i = 0\\)) podr\u00eda ofrecer una mejor predicci\u00f3n. La idea general de la regresi\u00f3n penalizada es controlar la variabilidad total de los efectos de la pel\u00edcula: \\(\\sum_{i=1}^5 b_i^2\\). Espec\u00edficamente, en lugar de minimizar la ecuaci\u00f3n de m\u00ednimos cuadrados, minimizamos una ecuaci\u00f3n que a\u00f1ade + \\lambda \\sum_{i} b_i^2\\] El primer t\u00e9rmino es solo la suma de errores cuadrados y el segundo es una penalizaci\u00f3n que aumenta cuando muchos \\(b_i\\) son grandes. Usando c\u00e1lculo, podemos mostrar que los valores de \\(b_i\\) que minimizan esta d\u00f3nde \\(n_i\\) es la cantidad de clasificaciones hechas para la pel\u00edcula \\(i\\). Este enfoque tendr\u00e1 el efecto deseado: cuando nuestro tama\u00f1o de muestra \\(n_i\\) es muy grande, un caso que nos dar\u00e1 un estimador estable, entonces la penalizaci\u00f3n \\(\\lambda\\) es efectivamente ignorada ya que \\(n_i+\\lambda \\approx n_i\\). Sin embargo, cuando el \\(n_i\\) es peque\u00f1o, entonces el estimador \\(\\hat{b}_i(\\lambda)\\) se encoge hacia 0. Entre m\u00e1s grande encogemos. Calculemos estos estimadores regularizados de \\(b_i\\) utilizando \\(\\lambda=3\\). Para ver c\u00f3mo se reducen los estimadores, hagamos un gr\u00e1fico de los estimadores regularizados versus los estimadores de m\u00ednimos sentido! Estas pel\u00edculas son m\u00e1s populares y tienen m\u00e1s calificaciones. Aqu\u00ed est\u00e1n las 10 peores pel\u00edculas: Effect Model 0.989 #> Movie Effect Model 0.970 estimadores penalizados ofrecen una gran mejora sobre los estimadores de m\u00ednimos cuadrados. 33.9.3 C\u00f3mo elegir los t\u00e9rminos de penalizaci\u00f3n Noten que \\(\\lambda\\) es un par\u00e1metro de ajuste. Podemos usar si bien mostramos esto como una ilustraci\u00f3n, en la pr\u00e1ctica deber\u00edamos usar validaci\u00f3n cruzada completa solo en el set de entrenamiento, sin usar el set de evaluaci\u00f3n hasta la evaluaci\u00f3n final. El set de evaluaci\u00f3n nunca debe utilizarse para el ajustamiento. Tambi\u00e9n podemos utilizar la regularizaci\u00f3n para estimar los efectos del usuario. Estamos minimizando: \\[ \\sum_{u,i} que minimizan esto se pueden encontrar de manera similar a lo que hicimos anteriormente. Aqu\u00ed usamos validaci\u00f3n cruzada para elegir Model||0.881| 33.10 Ejercicios Un experto en educaci\u00f3n aboga por escuelas m\u00e1s peque\u00f1as. El experto basa esta recomendaci\u00f3n en el hecho de que entre las mejores escuelas, muchas son escuelas peque\u00f1as. Simulemos un set de datos para 100 escuelas. Primero, simulemos el n\u00famero de estudiantes en cada escuela. Ahora asignemos una calidad verdadera para cada escuela completamente independiente del tama\u00f1o. Este es el par\u00e1metro que queremos estimar. [mu <- = rank(-mu))] Podemos ver que las 10 mejores escuelas son: Ahora hagamos que los estudiantes en la escuela tomen un examen. Existe una variabilidad aleatoria en la toma de ex\u00e1menes, por lo que simularemos las puntuaciones de los ex\u00e1menes distribuidos normalmente con el promedio determinado por la calidad de la escuela y las desviaciones est\u00e1ndar de 30 son las mejores escuelas seg\u00fan la puntuaci\u00f3n promedio? Muestre solo la identificaci\u00f3n, el tama\u00f1o y la puntuaci\u00f3n promedio. 2. Compare el tama\u00f1o medio de la escuela con el tama\u00f1o medio de las 10 mejores escuelas seg\u00fan la puntuaci\u00f3n. 3. Seg\u00fan esta prueba, parece que las escuelas peque\u00f1as son mejores que las grandes. Cinco de las 10 mejores escuelas tienen 100 estudiantes o menos. \u00bfPero c\u00f3mo puede ser \u00e9sto? Construimos la simulaci\u00f3n para que la calidad y el tama\u00f1o sean independientes. Repita el ejercicio para las peores 10 escuelas. 4. \u00a1Lo mismo es cierto para las peores escuelas! Tambi\u00e9n son peque\u00f1as. Grafique la puntuaci\u00f3n promedio versus el tama\u00f1o de la escuela para ver qu\u00e9 est\u00e1 pasando. Destaque las 10 mejores escuelas seg\u00fan la calidad verdadera. Use la transformaci\u00f3n de escala logar\u00edtmica para el tama\u00f1o. 5. Podemos ver que el error est\u00e1ndar de la puntuaci\u00f3n tiene una mayor variabilidad cuando la escuela es m\u00e1s peque\u00f1a. Esta es una realidad estad\u00edstica b\u00e1sica que aprendimos en las secciones de probabilidad e inferencia. De hecho, noten que 4 de las 10 mejores escuelas se encuentran en las 10 mejores escuelas seg\u00fan la puntuaci\u00f3n del examen. Usemos la regularizaci\u00f3n para elegir las mejores escuelas. Recuerde que la regularizaci\u00f3n encoge las desviaciones del promedio hacia 0. Entonces para aplicar la regularizaci\u00f3n aqu\u00ed, primero debemos definir el promedio general para todas las escuelas: y luego definir, para cada escuela, c\u00f3mo se desv\u00eda de ese promedio. Escriba un c\u00f3digo que calcule la puntuaci\u00f3n por encima del promedio de cada escuela pero dividi\u00e9ndolo por \\(n + \\lambda\\) en lugar de \\(n\\), con \\(n\\) el tama\u00f1o de la escuela y \\(\\lambda\\) un par\u00e1metro de regularizaci\u00f3n. Intente con \\(\\lambda = 3\\). 6. Noten que esto mejora un poco las cosas. El n\u00famero de escuelas peque\u00f1as que no figuran entre las mejores ahora es 4. \u00bfExiste un \\(\\lambda\\) mejor? Encuentre el \\(\\lambda\\) = \\(1/100 \\sum_{i=1}^{100} (\\mbox{quality} - \\mbox{estimate})^2\\). 7. Clasifique las escuelas seg\u00fan el promedio obtenido con los mejores \\(\\alpha\\). Tengan en cuenta que ninguna escuela peque\u00f1a se incluye incorrectamente. 8. Un error com\u00fan al usar la regularizaci\u00f3n es reducir los valores hacia 0 que no est\u00e1n centrados alrededor de 0. Por ejemplo, si no restamos el promedio general antes de reducir, obtenemos un resultado muy similar. Confirme esto volviendo a ejecutar el c\u00f3digo del ejercicio 6, pero sin eliminar la media general. 33.11 Factorizaci\u00f3n de matrices La factorizaci\u00f3n de matrices es un concepto ampliamente utilizado en machine learning. Est\u00e1 muy relacionado con el an\u00e1lisis de factores, la descomposici\u00f3n de valores singulares (singular value decomposition o SVD por sus siglas en ingl\u00e9s) y el an\u00e1lisis de componentes principales (PCA). Aqu\u00ed describimos el concepto en el contexto de los sistemas de recomendaci\u00f3n de pel\u00edculas. Hemos descrito c\u00f3mo el modelo: \\[ Y_{u,i} = \\mu + b_i + b_u + \\varepsilon_{u,i} \\] explica las diferencias de pel\u00edcula a pel\u00edcula a trav\u00e9s de la \\(b_i\\) y las diferencias de usuario a usuario a trav\u00e9s de la \\(b_u\\). Pero este modelo omite una fuente importante de variaci\u00f3n relacionada con el hecho de que los grupos de pel\u00edculas tienen patrones de calificaci\u00f3n similares y los grupos de usuarios tambi\u00e9n tienen patrones de calificaci\u00f3n similares. Descubriremos estos patrones estudiando los residuos: \\[ r_{u,i} = y_{u,i} - \\hat{b}_i - \\hat{b}_u \\] Para ver esto, convertiremos los datos en una matriz para que cada usuario obtenga una fila, cada pel\u00edcula obtenga una columna y \\(y_{u,i}\\) sea la entrada en fila \\(u\\) y columna \\(i\\). Con fines ilustrativos, solo consideraremos un peque\u00f1o subconjunto de pel\u00edculas con muchas calificaciones y usuarios que han calificado muchas pel\u00edculas. Tambi\u00e9n inclu\u00edmos Scent of a Woman ( movieId == 3252) los convertimos en residuos eliminando los efectos de columna y fila: Si el modelo anterior explica todas las se\u00f1ales, y los \\(\\varepsilon\\) son solo ruido, entonces los residuos para diferentes pel\u00edculas deben ser independientes entre s\u00ed. Pero no lo son. Aqu\u00ed hay unos ejemplos: = 3)] Estos gr\u00e1ficos muestran que a los usuarios que les gust\u00f3 The Godfather m\u00e1s de lo que el modelo espera de ellos, seg\u00fan la pel\u00edcula y los efectos del usuario, tambi\u00e9n les gust\u00f3 The Godfather II m\u00e1s de lo esperado. Se observa una relaci\u00f3n similar al comparar The Godfather y Goodfellas. Aunque no es tan fuerte, todav\u00eda hay correlaci\u00f3n. Tambi\u00e9n vemos correlaciones entre You've Got Mail y Sleepless in Seattle. Al observar la correlaci\u00f3n entre pel\u00edculas, podemos ver un patr\u00f3n (cambiamos los nombres de las columnas para ahorrar que personas a las que les gustan las comedias rom\u00e1nticas m\u00e1s de lo esperado, mientras que hay otras personas a las que les gustan las pel\u00edculas de g\u00e1ngsters m\u00e1s de lo esperado. Estos resultados nos dicen que hay estructura en los datos. Pero, \u00bfc\u00f3mo podemos modelar esto? 33.11.1 An\u00e1lisis de factores Aqu\u00ed hay una ilustraci\u00f3n, usando una simulaci\u00f3n, de c\u00f3mo podemos usar un poco de estructura para predecir el \\(r_{u,i}\\). Supongan que nuestros residuos r 2 2.0 1.7 2.0 2.0] Parece que hay un patr\u00f3n aqu\u00ed. De hecho, podemos ver patrones de correlaci\u00f3n crear vectores q y p, que pueden explicar gran parte de la estructura que vemos. Los q se ver\u00edan as\u00ed: y reduce las pel\u00edculas a dos grupos: g\u00e1ngster (codificado con 1) y romance (codificado con -1). Tambi\u00e9n podemos reducir los usuarios a tres grupos: los que les gustan las pel\u00edculas de g\u00e1ngsters y no les gustan las pel\u00edculas rom\u00e1nticas (codificadas como 2), los que les gustan las pel\u00edculas rom\u00e1nticas y no les gustan las pel\u00edculas de g\u00e1ngsters (codificadas como -2), y los que no les importa (codificadas como 0). El punto principal aqu\u00ed es que casi podemos reconstruir \\(r\\), que tiene 60 valores, con un par de vectores que totalizan 17 valores. Noten que p y q son equivalentes a los patrones y pesos que describimos en la Secci\u00f3n [33.5.4](sets-grandes-de-datos.html#pca). Si \\(r\\) contiene los residuos para usuarios \\(u=1,\\dots,12\\) para peliculas \\(i=1,\\dots,5\\), podemos escribir la siguiente \\[ r_{u,i} \\approx p_u q_i \\] Esto implica que podemos explicar m\u00e1s variabilidad modificando nuestro modelo anterior para recomendaciones de pel\u00edculas a: \\[ Y_{u,i} = motivamos la necesidad del t\u00e9rmino \\(p_u q_i\\) con una simulaci\u00f3n sencilla. La estructura que se encuentra en los datos suele ser m\u00e1s compleja. Por ejemplo, en esta primera simulaci\u00f3n supusimos que solo hab\u00eda un factor \\(p_u\\) que determinaba a cu\u00e1l de las dos pel\u00edculas de g\u00e9neros \\(u\\) pertenece. Pero la estructura en nuestros datos de pel\u00edculas parece ser mucho m\u00e1s complicada que las pel\u00edculas de g\u00e1ngsters versus las rom\u00e1nticas. Podemos tener muchos otros factores. Aqu\u00ed presentamos una simulaci\u00f3n un poco m\u00e1s compleja. Ahora agregamos una sexta pel\u00edcula. 1.4 1.5 0.6] Al explorar la estructura de correlaci\u00f3n de este quiz\u00e1s necesitamos un segundo factor para tomar en cuenta el hecho de que a algunos usuarios les gusta Al Pacino, mientras que a otros no les gusta o no les importa. Observen que la estructura general de la correlaci\u00f3n obtenida de los datos simulados no est\u00e1 tan lejos esta estructura m\u00e1s complicada, necesitamos dos factores. Por ejemplo, algo como lo -1] [#> [2,] 1 1 -1 -1 -1 1] con el primer factor (la primera fila) utilizado para codificar las pel\u00edculas de g\u00e1ngster versus las pel\u00edculas rom\u00e1nticas y un segundo factor (la segunda fila) para explicar los grupos de pel\u00edculas con Al Pacino versus los grupos sin Al Pacino. Tambi\u00e9n necesitaremos dos sets de coeficientes para explicar la variabilidad introducida por los tipos de grupos \\(3\\times 3\\): [t(p)] [#> 1 2 3 4 5 6 7 8 9 10 11 12] [#> [1,] 1.0 1.0 1.0 0 0 -1 -1.0 -1.0 -1.0] [#> [2,] -0.5 0.5 0.5 0.5 0 -0.5 -0.5 -0.5] El modelo con dos factores tiene 36 par\u00e1metros que se pueden usar para explicar gran parte de la variabilidad en las 72 clasificaciones: \\[ Y_{u,i} = + \\varepsilon_{u,i} \\] Tengan en cuenta que en una aplicaci\u00f3n de datos real, necesitamos ajustar este modelo a los datos. Para explicar la correlaci\u00f3n compleja que observamos en datos reales, generalmente permitimos que las entradas de \\(p\\) y \\(q\\) sean valores continuos, en lugar de discretos como las que usamos en la simulaci\u00f3n. Por ejemplo, en lugar de dividir las pel\u00edculas en g\u00e1ngster o romance, definimos un continuo. Adem\u00e1s, recuerden que este no es un modelo lineal y para ajustarlo necesitamos usar un algoritmo diferente a ese usado por lm para encontrar los par\u00e1metros que minimizan los m\u00ednimos cuadrados. Los algoritmos ganadores del Netflix challenge ajustaron un modelo similar al anterior y utilizaron la regularizaci\u00f3n para penalizar por grandes valores de \\(p\\) y \\(q\\), en lugar de usar m\u00ednimos cuadrados. Implementar este enfoque est\u00e1 m\u00e1s all\u00e1 del alcance de este libro. 33.11.2 Conexi\u00f3n a SVD y a SVD y PCA. SVD y PCA son conceptos complicados, pero una forma de entenderlos es que SVD es un algoritmo que encuentra los vectores \\(p\\) y \\(q\\) que nos permiten reescribir la matriz \\(\\mbox{r}\\) con \\(m\\) y q_{n,i} \\] con la variabilidad de cada t\u00e9rmino disminuyendo y con las \\(p\\)s no correlacionadas. El algoritmo tambi\u00e9n calcula esta variabilidad para que podamos saber cu\u00e1nta de la variabilidad total de las matrices se explica a medida que vayamos agregando nuevos t\u00e9rminos. Esto nos deja ver que, con solo unos pocos t\u00e9rminos, podemos explicar la mayor parte de la variabilidad. Veamos un ejemplo con los datos de la pel\u00edcula. Para calcular la descomposici\u00f3n, haremos que los residuos con NAs sean iguales a 0: Los vectores \\(q\\) se denominan componentes principales y se almacenan en esta matriz: Mientras que la \\(p\\), o los efectos del usuario, est\u00e1n aqu\u00ed: Podemos ver la variabilidad de cada uno de los vectores: Tambi\u00e9n notamos que los dos primeros componentes principales est\u00e1n relacionados a la estructura en las opiniones sobre pel\u00edculas: Con solo mirar los 10 primeros en cada direcci\u00f3n, vemos un patr\u00f3n significativo. El primer PC muestra la diferencia entre las pel\u00edculas aclamadas por la cr\u00edtica en of the State\" Mientras que el segundo PC parece ir de pel\u00edculas art\u00edsticas e \"Lord of the Rings: Ret...\" \"Dark Knight, The\" \"Speed\" Ajustar un modelo que incorpora estos estimadores es complicado. Para aquellos interesados en implementar un enfoque que incorpore estas ideas, recomendamos el paquete recommenderlab. Los detalles est\u00e1n m\u00e1s all\u00e1 del alcance de este libro. 33.12 Ejercicios En este set de ejercicios, trataremos un tema \u00fatil para comprender la factorizaci\u00f3n de matrices: la descomposici\u00f3n de valores singulares (singular value decomposition o SVD por sus siglas en ingl\u00e9s). SVD es un resultado matem\u00e1tico que se usa ampliamente en machine learning, tanto en la pr\u00e1ctica como para comprender las propiedades matem\u00e1ticas de algunos algoritmos. Este es un tema bastante avanzado y para completar este set de ejercicios tendr\u00e1n que estar familiarizados con conceptos de \u00e1lgebra lineal, como la multiplicaci\u00f3n de matrices, las matrices ortogonales y las matrices diagonales. El SVD nos dice que podemos descomponer un \\(N\\times p\\) matriz \\(Y\\) con \\(p ortogonal \\(D\\) un \\(p \\times p\\) matriz \\[d_{1,1} \\geq d_{2,2} \\geq \\dots d_{p,p}.\\] En este ejercicio, veremos una de las formas en que esta descomposici\u00f3n puede ser \u00fatil. Para hacer esto, construiremos un set de datos que representa las calificaciones de 100 estudiantes en 24 materias diferentes. El promedio general se ha eliminado, por lo que estos datos representan el punto porcentual que cada estudiante recibi\u00f3 por encima o por debajo de la puntuaci\u00f3n promedio de la prueba. Entonces un 0 representa una calificaci\u00f3n promedio (C), un 25 es una calificaci\u00f3n alta (A +) y un -25 representa una calificaci\u00f3n baja (F). Puede simular los datos de .5, .5, 1), 1) es describir el desempe\u00f1o de los estudiantes de la manera m\u00e1s sucinta posible. Por ejemplo, queremos saber si los resultados de estas pruebas son solo n\u00fameros independientes aleatorios. \u00bfTodos los estudiantes son igual de buenos? \u00bfSer bueno en un tema implica ser bueno en otro? \u00bfC\u00f3mo ayuda el SVD con todo esto? Iremos paso a paso para mostrar que con solo tres pares relativamente peque\u00f1os de vectores podemos explicar gran parte de la variabilidad en este \\(100 \\times 24\\) set de datos. Puede visualizar las 24 puntuaciones de las pruebas para los 100 estudiantes al + 0.5, v = cols \u00bfC\u00f3mo datos basados en esta figura? - Las puntuaciones de las pruebas son independientes entre s\u00ed. - Los estudiantes que eval\u00faan bien est\u00e1n en la parte superior de la imagen y parece que hay tres agrupaciones por materia. - Los estudiantes que son buenos en matem\u00e1ticas no son buenos en ciencias. - Los estudiantes que son buenos en matem\u00e1ticas no son buenos en humanidades. 2. Puede examinar la correlaci\u00f3n entre las puntuaciones de la prueba directamente de esta manera: \u00bfCu\u00e1l de las siguientes opciones describe mejor lo que ve? - Las puntuaciones de las pruebas son independientes. - Las matem\u00e1ticas y las ciencias est\u00e1n altamente correlacionadas, pero las humanidades no. - Existe una alta correlaci\u00f3n entre las pruebas en la misma materia pero no hay correlaci\u00f3n entre las materias. - Hay una correlaci\u00f3n entre todas las pruebas, pero es mayor si las pruebas son de ciencias y matem\u00e1ticas e incluso mayor dentro de cada materia. 3. Recuerde que la ortogonalidad significa que \\(U^{\\top}U\\) y \\(V^{\\top}V\\) son iguales a la matriz de identidad. Esto implica que tambi\u00e9n podemos reescribir la descomposici\u00f3n como: \\[ Y V = U D \\mbox{ or } U^{\\top}Y = D V^{\\top}\\] Podemos pensar en \\(YV\\) y \\(U^{\\top}V\\) como dos transformaciones de Y que preservan la variabilidad total de \\(Y\\) ya que \\(U\\) y \\(V\\) son ortogonales. Use la funci\u00f3n svd para calcular el SVD de y. Esta funci\u00f3n devolver\u00e1 \\(U\\), \\(V\\) y las entradas diagonales de \\(D\\). Puede verificar que el SVD funciona al escribir: Calcule la suma de cuadrados de las columnas de \\(Y\\) y gu\u00e1rdelas en ss_y. Luego calcule la suma de cuadrados de columnas del transformado \\(YV\\) y gu\u00e1rdelas en ss_yv. Confirme que sum(ss_y) es igual a sum(ss_yv). 4. Vemos que se conserva la suma total de cuadrados. Esto es porque \\(V\\) es ortogonal. Ahora para comenzar a entender c\u00f3mo \\(YV\\) es \u00fatil, grafique ss_y contra el n\u00famero de columna y luego haga lo mismo para ss_yv. \u00bfQu\u00e9 observa? 5. Vemos que la variabilidad de las columnas de \\(YV\\) est\u00e1 disminuyendo. Adem\u00e1s, vemos que, en relaci\u00f3n con los tres primeros, la variabilidad de las columnas m\u00e1s all\u00e1 del tercero es casi 0. Ahora observe que no tuvimos que calcular ss_yv porque ya tenemos la respuesta \u00bfC\u00f3mo? Recuerde que \\(YV = UD\\) y como \\(U\\) es ortogonal, sabemos que la suma de cuadrados de las columnas de \\(UD\\) son las entradas diagonales de \\(D\\) al cuadrado. Confirme esto graficando la ra\u00edz cuadrada de ss_yv versus las entradas diagonales de \\(D\\). 6. De lo anterior, sabemos que la suma de cuadrados de las columnas de \\(Y\\) (la suma total de cuadrados) se a\u00f1ade a la suma de s$d^2 y que la transformaci\u00f3n \\(YV\\) nos da columnas con sumas de cuadrados iguales a s$d^2. Ahora calcule qu\u00e9 porcentaje de la variabilidad total se explica solo por las tres primeras columnas de \\(YV\\). 7. Vemos que casi el 99% de la variabilidad se explica por las primeras tres columnas de \\(YV = UD\\). Entonces esto implica que deber\u00edamos poder explicar gran parte de la variabilidad y estructura que encontramos al explorar los datos con unas pocas columnas. Antes de continuar, vamos a mostrar un truco computacional \u00fatil para evitar crear la matriz diag(s$d). Para motivar esto, notamos que si escribimos \\(U\\) en sus columnas \\([U_1, U_2,\\dots, calcular \\(UD\\) sin construir diag(s$d) y sin usar multiplicaci\u00f3n de matrices. 8. Sabemos que \\(U_1 d_{1,1}\\), la primera columna de \\(UD\\), tiene la mayor variabilidad de todas las columnas de \\(UD\\). Anteriormente vimos una imagen de \\(Y\\): en la que podemos ver que la variabilidad de estudiante a estudiante es bastante grande y que parece que los estudiantes que son buenos en una materia son buenos en todas. Esto implica que el promedio (en todas las materias) de cada alumno debe explicar en gran medida la variabilidad. Calcule la puntuaci\u00f3n promedio de cada estudiante y graf\u00edquelo contra \\(U_1 d_{1,1}\\). Describa lo que encuentra. 9. Notamos que los signos en SVD son arbitrarios porque: \\[ U D V^{\\top} = (-U) D (-V)^{\\top} \\] Con esto en mente, vemos que la primera columna de \\(UD\\) es casi id\u00e9ntica a la puntuaci\u00f3n promedio de cada estudiante, excepto por el signo. Esto implica que multiplicar \\(Y\\) por la primera columna de \\(V\\) debe realizar una operaci\u00f3n similar a tomar el promedio. Haga un gr\u00e1fico de imagen de \\(V\\) y describa la primera columna en relaci\u00f3n con las otras y c\u00f3mo se relaciona esto con tomar un promedio. 10. Ya vimos que podemos reescribir \\(UD\\) como: \\(U_j\\) la columna j de \\(U\\). Esto implica que podemos reescribir todo el \\(U_1\\), luego grafique \\(V_1^{\\top}\\) usando el mismo rango para los l\u00edmites del eje y, entonces haga una imagen de \\(U_1 d_{1,1} V_1 ^{\\top}\\) y comp\u00e1rela con la imagen de \\(Y\\). Sugerencia: use la funci\u00f3n my_image definida anteriormente y el argumento drop=FALSE para asegurar que los subconjuntos de matrices son matrices. 11. Vemos que con solo un vector de longitud 100, un escalar y un vector de longitud 24, nos acercamos a reconstruir la matriz \\(100 \\times 24\\) original. Esta es explica s $d[1]^2/sum(s$ d^2) * 100 por ciento de la variabilidad total. Nuestra aproximaci\u00f3n solo explica la observaci\u00f3n de que los buenos estudiantes tienden a ser buenos en todas las materias. Pero otro aspecto de los datos originales que nuestra aproximaci\u00f3n no explica es la mayor similitud que observamos dentro de las materias. Podemos ver esto calculando la diferencia entre nuestra aproximaci\u00f3n y los datos originales y luego calculando las correlaciones. Pueden ver esto ejecutando este las = 2)] Ahora que hemos eliminado el efecto general del estudiante, el gr\u00e1fico de correlaci\u00f3n revela que todav\u00eda no hemos explicado la correlaci\u00f3n interna de la materia ni el hecho de que las puntuaciones en matem\u00e1ticas y ciencias son m\u00e1s parecidas entre s\u00ed que a las puntuaciones en las artes. As\u00ed que exploremos la segunda columna del SVD. Repita el ejercicio anterior pero para la segunda columna: grafique \\(U_2\\), entonces grafique \\(V_2^{\\top}\\) usando el mismo rango para los l\u00edmites del eje y, finalmente haga una imagen de \\(U_2 d_{2,2} V_2 ^{\\top}\\) y comp\u00e1rela con la imagen de resid. 12. La segunda columna se relaciona claramente con la diferencia de habilidad del estudiante en matem\u00e1ticas/ciencias versus las artes. Podemos ver esto m\u00e1s claramente en el gr\u00e1fico de s$v[,2]. Sumar las matrices resultantes usando estas dos columnas ayudar\u00e1 con nuestra aproximaci\u00f3n: explicar\u00e1: porcentaje de la variabilidad total. Podemos calcular nuevos residuos as\u00ed: [resid las = 2)] y ver que la estructura que queda es impulsada por las diferencias entre matem\u00e1ticas y ciencias. Confirme esto graficando \\(U_3\\), luego grafique \\(V_3^{\\top}\\) usando el mismo rango para los l\u00edmites del eje y, luego haga una imagen de \\(U_3 d_{3,3} V_3 ^{\\top}\\) y comp\u00e1rela con la imagen de resid. 13. La tercera columna se relaciona claramente con la diferencia de habilidad del estudiante en matem\u00e1ticas y ciencias. Podemos ver esto m\u00e1s claramente en el gr\u00e1fico de s$v[,3]. Agregar la matriz que obtenemos con estas dos columnas ayudar\u00e1 con nuestra aproximaci\u00f3n: que explicar\u00e1: porcentaje de la variabilidad total. Podemos calcular nuevos residuos como este: [resid = 2)] Ya no vemos estructura en los residuos: parecen ser independientes entre s\u00ed. Esto implica que podemos describir los datos con el siguiente modelo: \\[ Y una matriz de errores independientes id\u00e9nticamente distribuidos. Este modelo es \u00fatil porque resumimos observaciones con \\(3 \\times (100+24+1) = 375\\) n\u00fameros. Adem\u00e1s, los tres componentes del modelo tienen interpretaciones \u00fatiles: 1) la capacidad general de un estudiante, 2) la diferencia en la habilidad entre las matem\u00e1ticas/ciencias y las artes, y 3) las diferencias restantes entre las tres materias. Los tama\u00f1os \\(d_{1,1}, d_{2,2}\\) y \\(d_{3,3}\\) nos dicen la variabilidad explicada por cada componente. Finalmente, tengan en cuenta que los componentes \\(d_{j,j} U_j V_j^{\\top}\\) son equivalentes al componente principal j. Termine el ejercicio graficando una imagen de \\(Y\\), una imagen y una imagen de los residuos, todos con el mismo zlim. 14. Avanzado: El set de datos movielens incluido en el paquete dslabs es un peque\u00f1o subconjunto de un set de datos m\u00e1s grande con millones de clasificaciones. Puede encontrar el set de datos m\u00e1s reciente aqu\u00ed: [https://grouplens.org/datasets/movielens/20m/](https://grouplens.org/datasets/movielens/20m/). Cree su propio sistema de recomendaciones utilizando todas las herramientas que le hemos mostrado. "}