{"title": "PDF", "author": "PDF", "url": "https://rua.ua.es/dspace/bitstream/10045/127446/1/PLN_69.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "syntactic BERT models at the interface of dependency resolution and training time Iria de -Dios -Flores, Marcos Garcia .......................................................................................................... 15 Information fusion for mental disorders detection: multimodal BERT against fusioning multiple BERTs Mario , Manuel Montes -y-G\u00f3 mez ..... 27 Un redactor asistido para adaptar textos administrativos a lenguaje claro Iria da Cunha ............................................................................................................................................. 39 Exploiting user -frequency information for mining regionalisms in Argentinian Spanish from Twitter Juan Manuel P\u00e9rez, Dami\u00e1n E. Aleman, Santiago N. Kalinowski, Agust\u00edn Gravano ................................ 51 Reflexive pronouns in Spanish Jasper 63 Multi- label Text Classification Public Procurement in Spanish Maria Navas -Loro, Daniel Garijo, Oscar Corcho ..................................................................................... 73 Selecci\u00f3n de colocaciones acad\u00e9micas en espa\u00f1ol a trav\u00e9s de un filtro de interdisciplinariedad Eleonora Guzzi, Margarita Alonso Ramos ................................................................................................. 83 Compilaci\u00f3n del corpus acad\u00e9mico de noveles en euskera HARTAeus y su explotaci\u00f3n para el estudio de la fraseolog\u00eda acad \u00e9mica Mar\u00eda Jes\u00fas -Pineda, -y-G\u00f3mez ............................... 117 Detecci\u00f3n de Indicios de Autolesiones No Suicidas en Informes M\u00e9dicos de Psiquiatr\u00eda Mediante el An\u00e1lisis del Lenguaje Juan Martinez -Romo, Lourdes Araujo, Bla nca Reneses, J. Sevilla -Llewellyn -Jones , Ignacio Mart\u00ednez - Large Language Models and Compositional Pablo Gamallo, Marcos Garcia, Iria An of Drugs, Diseases, in the CORD -19 Corpus Carlos Badenes -Olmedo, \u00c1lvaro Alo nso, Oscar Corcho ......................................................................... 165 Transformers for Lexical Complexity Prediction in Spanish Language Ortiz -Zambrano, C\u00e9sar Espin- Riofrio, Arturo Montejo -R\u00e1ez ........................................................ 177 Building a comparable corpus and a benchmark for Spanish medical text simplification Leonardo Campillos -Llanos, Ana R. Terroba 189 Ib erLEF 202 2: las tareas de evaluaci\u00f3n ABSAPT 2022 at IberLEF: Overview of the Task on Aspect -Based Sentiment Analysis in Portuguese Felix L. V. da Silva, Guilherme da S. Xavier, Heliks M. Mensenburg, Rodrigo F. Rodrigues, Leonardo P. dos Santos, Ricardo M. Ara\u00fajo, Ulisses B. Corr\u00eaa, Larissa A. of Agg ressive and Violent Incidents from Social Media in Spanish Luis Joaqu\u00edn Arellano, Hugo Jair Escalante, Luis Villase\u00f1or -Pineda, Manuel Montes -y-G\u00f3mez, Fernando Sanchez -Vega ........................................................................................................................... 207 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Natural Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022 ISSN: 1135 -5948 Comit\u00e9 Editorial Consejo de redacci\u00f3n L. Alfonso Ure\u00f1a L\u00f3pez Universidad de Ja\u00e9n laurena@ujaen.es (Director) Patricio Mart\u00ednez Barco Universidad de Alicante patricio@dlsi.ua.es (Secretario) Manuel Palomar Sanz Universidad de Alicante mpalomar@dlsi.ua.es Felisa Verdejo Ma\u00edllo UNED 7553 Dep\u00f3sito Legal : B:3941-91 Editado en: Universidad de Ja\u00e9n A\u00f1o de edici\u00f3n: 2022 Editores: Miguel A. Alonso Universidad de A Coru\u00f1a miguel.alonso@udc.es Margarita Alonso -Ramos Universidad de A Coru\u00f1a margarita.alonso@udc.es Carlos G\u00f3mez-Rodr\u00edguez Universidad d e A Coru\u00f1a carlos.gomez@udc.es David Vilares Universidad de A Coru\u00f1a david.vilares@udc.es Jes\u00fas Vilares Universidad de A Coru\u00f1a jesus.vilares@udc.es Publicado por: Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Natural Departamento de Inform\u00e1tica. Universidad de Ja\u00e9n Campus Las Lagunillas, EdificioA3. Despacho 127. 23071 Ja\u00e9n secretaria.sepln@ujaen.es Consejo asesor Margarita Alonso -Ramos Universidad de A Coru\u00f1a y CITIC (Espa\u00f1a) Xabier Arregi Universidad del Pa\u00eds Vasco (Espa\u00f1a) Manuel de Buenaga Universidad de Alcal\u00e1 (Espa\u00f1a) Jose Camacho Collados Cardiff University (Reino Unido) Sylviane Cardey -Greenfield Centre de recherche en linguistique et traitement automatique des langues (Francia) Irene Castell\u00f3n Universidad de Barcelona (Espa\u00f1a) Arantza D\u00edaz de Ilarraza Universidad del Pa\u00eds Vasco (Espa\u00f1a) Antonio Ferr\u00e1ndez Universidad de Alicante (Espa\u00f1a) Alexander Gelbukh Instituto Polit\u00e9cnico Nacional (M\u00e9xico) Koldo Gojenola Universidad del Pa\u00eds Vasco (Espa\u00f1a) Xavier G\u00f3mez Guinovart Universidad de Vigo (Espa\u00f1a) Carlos G\u00f3mez-Rodr\u00edguez Universidad de A Coru\u00f1a y CITIC (Espa\u00f1a) Jos\u00e9 Miguel Go\u00f1i Universidad Polit\u00e9cnica de Madrid (Espa\u00f1a) Inma Hernaez Universidad del Pa\u00eds Vasco (Espa\u00f1a) Elena Lloret Universidad de Alicante (Espa\u00f1a) \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Natural Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022Ram\u00f3n L\u00f3pez -C\u00f3zar Delgado Universidad de Granada (Espa\u00f1a) Bernardo Magnini Fondazione Bruno Kessler (Italia) Nuno J. Mamede Instituto de Engenharia de Sistemas e Computadores (Portugal) M. Antonia Mart\u00ed Universidad de Barcelona (Espa\u00f1a) M. Teresa Mart\u00edn Valdivia Universidad de Ja\u00e9n (Espa\u00f1a) Patricio Mart\u00ednez -Barco Universidad de Alicante (Espa\u00f1a) Eugenio Mart\u00ednez C\u00e1mara Universidad de Granada (Espa\u00f1a) Paloma Mart\u00ednez Fern\u00e1ndez Universidad Carlos III (Espa\u00f1a) Raquel Mart\u00ednez Unanue Universidad Nacional de Educaci\u00f3n a Distancia (Espa\u00f1a) Ruslan Mitkov University of Wolverhampton (Reino Unido) Manuel Montes y G\u00f3mez Instituto Nacional de Astrof\u00edsica, \u00d3ptica y Electr\u00f3nica (M\u00e9xico) Mariana Lara Neves Bundesinstitut f\u00fcr Risikobewertung (Alemania) Llu\u00eds Padr\u00f3 Universidad Polit\u00e9cnica de Catalu\u00f1a (Espa\u00f1a) Manuel Palomar Universidad de Alicante (Espa\u00f1a) Ferr\u00e1n Pla Universidad Polit\u00e9cnica de Valencia (Espa\u00f1a) German Rigau Universidad del Pa\u00eds Vasco (Espa\u00f1a) Horacio Rodr\u00edguez Universidad Polit\u00e9cnica de Catalu\u00f1a (Espa\u00f1a) Paolo Rosso Universidad Polit\u00e9cnica de Valencia (Espa\u00f1a) Leonel Ruiz Miyares Centro de Ling\u00fc\u00edstica Aplicada de Santiago de Cuba (Cuba) Horacio Saggion Universidad Pompeu Fabra (Espa\u00f1a) Emilio Sanch\u00eds Universidad Polit\u00e9cnica de Valencia (Espa\u00f1a) Encarna Segarra Universidad Polit\u00e9cnica de Valencia (Espa\u00f1a) Thamar Solorio University of Houston (Estados Unidos de Am\u00e9rica) Maite Taboada Simon Fraser University (Canad\u00e1) Mariona Taul\u00e9 Universidad de Barcelona (Espa\u00f1a) Juan-Manuel Torres-Moreno Laboratoire Informatique d'Avignon / Universit\u00e9 d'Avignon (Francia) Jos\u00e9 Antonio Troyano Jim\u00e9nez Universidad de Sevilla (Espa\u00f1a) L. Alfonso Ure\u00f1a L\u00f3pez Universidad de Ja\u00e9n (Espa\u00f1a) Rafael Valencia Garc\u00eda Universidad de Murcia (Espa\u00f1a) Ren\u00e9 Venegas Vel\u00e1sques Pontificia Universidad Cat\u00f3lica de Valpara\u00edso (Chile) Felisa Verdejo Ma\u00edllo Universidad Nacional de Educaci\u00f3n a Distancia (Espa\u00f1a) Karin Vespoor University of Melbourne (Australia) Manuel Vilares Universidad de Vigo (Espa\u00f1a) Luis Villase\u00f1or -Pineda Instituto Nacional de Astrof\u00edsica, \u00d3ptica y Electr\u00f3nica (M\u00e9xico) Revisores adicionales Laura Alonso Alemany Universidad Nacional de C\u00f3rdoba (Argentina) Ana-Maria Bucur University of Bucharest (Ruman\u00eda) \u00d3scar Araque Iborra Universidad Polit\u00e9cnica de Madrid (Espa\u00f1a) Marco Casavantes Instituto Nacional de Astrof\u00edsica, \u00d3ptica y Electr\u00f3nica (M\u00e9xico) Riccardo Cervero Universidad Polit\u00e9 cnica de Val encia (Espa\u00f1a) Elisabet Comelles Universidad de Barcelona (Espa\u00f1a) Laritza Coello Instituto Nacional de Astrof\u00edsica, \u00d3ptica y Electr\u00f3nica (M\u00e9xico) V\u00edctor Manuel Darriba Bilbao Universidad de Vigo (Espa\u00f1a) \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje NaturalAgust\u00edn Daniel Delgado Mu\u00f1oz Universidad Nacional de Educaci\u00f3n a Distancia (Espa\u00f1a) Andr\u00e9s Duqu e Universidad Nacional de Educaci\u00f3n a Distancia (Espa\u00f1a) Miguel Angel Garc\u00eda Cumbreras Universidad de Ja\u00e9n (Espa\u00f1a) Jos\u00e9 Antonio Garc\u00eda -D\u00edaz Universidad de Murcia (Espa\u00f1a) Juan Luis Garc\u00eda Mendoza Instituto Nacional de Astrof\u00edsica, \u00d3ptica y Electr\u00f3nica (M\u00e9xico) Delia Iraz\u00fa Hern\u00e1ndez-Farias Universidad de Guanajuato (M\u00e9 xico) Salud Mar\u00eda Jim\u00e9nez-Zafra Universidad de Ja\u00e9n (Espa\u00f1a) Arturo Montejo-R\u00e1ez Universidad de Ja\u00e9n (Espa\u00f1a) Arantxa Otegi Universidad del Pa\u00eds Vasco (Espa\u00f1a) David Owen Cardiff University (Reino Unido) Jos\u00e9 M. Perea -Ortega Universidad de Extremadura (Espa\u00f1a) Flor-Miriam Plaza -del-Arco Universidad de Ja\u00e9n (Espa\u00f1a) Francisco J. Ribadas-Pena Universidad de Vigo (Espa\u00f1a) Giulia Rizzi Universit\u00e0 degli studi di Milano-Bicocca (Italia) Juan Fernando S\u00e1nchez Rada Universidad Polit\u00e9cnica de Madrid (Espa\u00f1a) David Vilares Universidad de A Coru\u00f1a y CITIC (Espa\u00f1a) \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Natural ISSN: 1135 -5948 Pre\u00e1mbulo La revista Procesamiento del Lenguaje Natural pretende ser un foro de publicaci\u00f3n de art\u00edculos cient\u00edfico-t\u00e9cnicos in\u00e9ditos de calidad relevante en el \u00e1mbito del Procesamiento de Lenguaje Natural (PLN) tanto para la comunidad cient\u00edfica nacional e internacional, como para las empresas del sector. Adem\u00e1s, se quiere potenciar el desarrollo de las diferentes \u00e1reas relacionadas con el PLN, mejorar la divulgaci\u00f3n de las investigaciones que se llevan a cabo, identificar las futuras directrices de la investigaci\u00f3n b\u00e1sica y mostrar las posibilidades reales de aplicaci\u00f3n en este campo. Anualmente la SEPLN (Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Natural) publica dos n\u00fameros de la revista, que incluyen art\u00edculos originales, presentaciones de proyectos en marcha, rese\u00f1as bibliogr\u00e1ficas y res\u00famenes de tesis doctorales. Esta revista se distribuye gratuitamente a todos los socios, y con el fin de conseguir una mayor expansi\u00f3n y facilitar el acceso a la publicaci\u00f3n, su contenido es libremente accesible por Internet. Las \u00e1reas tem\u00e1ticas tratadas son las siguientes: Modelos ling\u00fc\u00edsticos, matem\u00e1ticos y psicoling\u00fc\u00edsticos del lenguaje Ling\u00fc\u00edstica de corpus Desarrollo de recursos y herramientas ling\u00fc\u00edsticas Gram\u00e1ticas y formalismos para el an\u00e1lisis morfol\u00f3gico y sint\u00e1ctico Sem\u00e1ntica, pragm\u00e1tica y discurso Lexicograf\u00eda y terminolog\u00eda computacional Resoluci\u00f3n de la ambig\u00fcedad l\u00e9xica Aprendizaje autom\u00e1tico en PLN Generaci\u00f3n textual monoling\u00fce y multiling\u00fce Traducci\u00f3n autom\u00e1tica Reconocimiento y s\u00edntesis del habla Extracci\u00f3n y recuperaci\u00f3n de informaci\u00f3n monoling\u00fce, multiling\u00fce y multimodal Sistemas de b\u00fasqueda de respuestas An\u00e1lisis autom\u00e1tico del contenido textual Resumen autom\u00e1tico PLN para la generaci\u00f3n de recursos educativos PLN para lenguas con recursos limitados Aplicaciones industriales del PLN Sistemas de di\u00e1logo An\u00e1lisis de sentimientos y opiniones Miner\u00eda de texto Evaluaci\u00f3n de sistemas de PLN Implicaci\u00f3n textual y par\u00e1frasis El ejemplar n\u00famero 6 9 de la revista Procesamiento del Lenguaje Natural contiene trabajos correspondientes a dos apartados diferentes: comunicaciones cient\u00edficas y res\u00famenes de las tareas de evaluaci\u00f3n competitiva de la edici\u00f3n del a\u00f1o 202 2 del foro de evaluaci\u00f3n Iberian Language Evaluation Forum (IberLEF). Todos ellos han sido aceptados mediante el proceso de revisi\u00f3n \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Natural Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022tradicional en la revista. Queremos agradecer a los miembros del Comit\u00e9 Asesor y a los revisores adicionales la labor que han realizado. Se recibieron 40 trabajos para este n\u00famero, de los cuales 30 eran art\u00edculos cient\u00edficos y 10 res\u00fames de las tareas de evaluaci\u00f3n competitiva del foro de evaluaci\u00f3n IberLEF 2022 . De entre los 30 art\u00edculos recibidos, 1 6 han sido finalmente seleccionados para su publicaci\u00f3n, lo cual fija una tasa de aceptaci\u00f3n del 53%. El Comit\u00e9 Asesor de la revista se ha hecho cargo de la revisi\u00f3n de los trabajos. Este proceso de revisi\u00f3n es de doble anonimato: se mantiene oculta la identidad de los autores que son evaluados y de los revisores que realizan las evaluaciones. En un primer paso, cada art\u00edculo ha sido examinado de manera ciega o an\u00f3nima por tres revisores. En un segundo paso, para aquellos art\u00edculos que ten\u00edan una divergencia m\u00ednima de tres puntos (sobre siete) en sus puntuaciones, sus tres revisores han reconsiderado su evaluaci\u00f3n en conjunto. Finalmente, la evaluaci\u00f3n de aquellos art\u00edculos que estaban en posici\u00f3n muy cercana a la frontera de aceptaci\u00f3n ha sido supervisada por m\u00e1s miembros del comit\u00e9 editorial. El criterio de corte adoptado ha sido la media de las tres calificaciones, siempre y cuando hayan sido iguales o superiores a 5 sobre 7. La elaboraci\u00f3n de este n\u00famero ha contado con la aportaci\u00f3n del Vicerrectorado de Pol\u00edtica Cient\u00edfica, Investigaci\u00f3n y Transferencia de la Universidad de A Coru\u00f1a, con cofinanciaci\u00f3n del Convenio de Acciones Estrat\u00e9gicas I+D+i para 2022 entre la Conseller\u00eda de Cultura, Educaci\u00f3n y Universidad de la Xunta de Galicia y la Universidad de A Coru\u00f1a. Septiembre de 2022 Los editores. \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Natural ISSN: 1135 -5948 Preamble The Natural Language Processing journal aims to be a forum for the publication of high- quality unpublished scientific and technical papers on Natural Language Processing (NLP) for both the national and international scientific community and companies. Furthermore, we want to strengthen the development of different areas related to NLP, widening the dissemination of research carried out, identifying the future directions of basic research and demonstrating the possibilities of its application in this field. Every year, the Spanish Society for Natural Language Processing (SEPLN) publishes two issues of the journal that include original ongoing projects, book reviews and published are following: Mathematical and Psychological to and Synthesis Dialogue Systems Machine Translation Disambiguation Machine Learning in NLP Monolingual and multilingual Text Generation Information Extraction and Question Answering Automatic Text Analysis Automatic Summarization NLP Resources for Learning NLP for languages with limited resources Business Applications of Analysis Mining Entailment and Paraphrases The 6 9th issue of the Procesamiento del Lenguaje Natural journal contains scientific papers and summaries of the shared -tasks of the edition of 202 2 of the evaluation forum Ib erian Languages Evaluation Forum (IberLEF). All of these were accepted by a peer review process. We would like to thank the Advisory Committee members and additional reviewers for their work. \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Natural Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022Forty papers were submitted for this issue, from which thirty were scientific papers and ten were summaries of the evaluation tasks of the evaluation forum IberLEF 2022. From these thirty papers, we selected sixteen (53%) for publication. The Advisory Committee of the journal has reviewed the papers in a double -blind process. Under double -blind review the identity of the reviewers and the authors are hidden from each other. In the first step, each paper was reviewed blindly by three reviewers. In the second step, the three reviewers have given a second ove rall evaluation of those papers with a difference of three or more points out of seven in their individual reviewer scores. Finally, the evaluation of those papers that were in a position very close to the acceptance limit were supervised by the editorial board. The cut -off criterion adopted was the mean of the three scores given, as long as it is equal or greater than 5 out of 7. The preparation of this issue has been supported partially by the Vice -Rectorate for Science Policy, Research and Transfer of the University of A Coru\u00f1a, with co-funding from the R&D Agreement on Strategic Actions for 2022 between the Department of Culture, Education and University of the Xunta de Galicia and the University of A Coru\u00f1a. September 2022 Editorial board. \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje NaturalISSN: 1135 -5948 A rt\u00edculos syntactic BERT models at the interface of dependency resolution and training time Iria de -Dios -Flores, Marcos Garcia .......................................................................................................... 15 Information fusion for mental disorders detection: multimodal BERT against fusioning multiple BERTs Mario , Manuel Montes -y-G\u00f3 mez ..... 27 Un redactor asistido para adaptar textos administrativos a lenguaje claro Iria da Cunha ............................................................................................................................................. 39 Exploiting user -frequency information for mining regionalisms in Argentinian Spanish from Twitter Juan Manuel P\u00e9rez, Dami\u00e1n E. Aleman, Santiago N. Kalinowski, Agust\u00edn Gravano ................................ 51 Reflexive pronouns in Spanish Jasper 63 Multi- label Text Classification Public Procurement in Spanish Maria Navas -Loro, Daniel Garijo, Oscar Corcho ..................................................................................... 73 Selecci\u00f3n de colocaciones acad\u00e9micas en espa\u00f1ol a trav\u00e9s de un filtro de interdisciplinariedad Eleonora Guzzi, Margarita Alonso Ramos ................................................................................................. 83 Compilaci\u00f3n del corpus acad\u00e9mico de noveles en euskera HARTAeus y su explotaci\u00f3n para el estudio de la fraseolog\u00eda acad \u00e9mica Mar\u00eda Jes\u00fas -Pineda, -y-G\u00f3mez ............................... 117 Detecci\u00f3n de Indicios de Autolesiones No Suicidas en Informes M\u00e9dicos de Psiquiatr\u00eda Mediante el An\u00e1lisis del Lenguaje Juan Martinez -Romo, Lourdes Araujo, Blanca Reneses, J . Sevilla -Llewellyn -Jones , Ignacio Mart\u00ednez Large Language Models and Compositional Pablo Gamallo, Marcos Garcia, Iria An of Drugs, Diseases, in the CORD -19 Corpus Carlos Badenes -Olmedo, \u00c1lvaro Alonso , Oscar Corcho ......................................................................... 165 Transformers for Lexical Complexity Prediction in Spanish Language Ortiz -Zambrano, C\u00e9sar Espin- Riofrio, Arturo Montejo -R\u00e1ez ........................................................ 177 Building a comparable corpus and a benchmark for Spanish medical text simplification Leonardo Campillos -Llanos, Ana R. Terroba 189 I berLEF 202 2: las tareas de evaluaci\u00f3n ABSAPT 2022 at IberLEF: Overview of the Task on Aspect -Based Sentiment Analysis in Portuguese Felix L. V. da Silva, Guilherme da S. Xavier, Heliks M. Mensenburg, Rodrigo F. Rodrigues , Leonardo P. dos Santos, Ricardo M. Ara\u00fajo, Ulisses B. Corr\u00eaa, Larissa A. of Aggressive and Violent Incidents from Social Media in Spanish Luis Joaqu\u00edn Arellano, Hugo Jair Escalante, Luis Vil lase\u00f1or -Pineda, Manuel Montes -y-G\u00f3mez, Fernando Sanchez -Vega ........................................................................................................................... 207 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Natural Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022Overview of DETESTS at IberLEF 2022: DETEction and classification of racial STereotypes in Spanish Alejandro Ariza -Casabona, Wolfgang S. Schmeisser -Nieto, Montserrat Nofre, Mariona Arag\u00f3n, Mar\u00eda documents: of the LivingNER shared task and resources Antonio Miranda- Escalada, Eul\u00e0lia Farr\u00e9- Maduell, Salvador Lima -L\u00f3pez, Darryl Estrada, Luis G asc\u00f3, Detection in Spanish Shared Task Gemma Bel -Enguix, Gerardo Sierra, Helena G\u00f3mez -Adorno, Juan -Manuel Torres -Moreno, - for Political Ideology Jos\u00e9 Antonio Garc\u00eda- D\u00edaz, Salud Mar\u00eda Jim\u00e9nez -Zafra, Mar\u00eda -Teresa Mart\u00edn Valdivia, Francisco Garc\u00eda -S\u00e1nchez, L. Alfonso Ure\u00f1a- L\u00f3pez, Rafael Valencia- Bouza, Santiago Castro, Etcheverry, Santiago G\u00f3ngora, Santiago Goycoechea, Juan Machado, Guillermo Moncecchi, Jos\u00e9 Prada, Wonsever 273 Reasoning Explanation for Spanish Marco Antonio Sobrevilla Cabezudo, Diego Diestra, Rodrigo L\u00f3pez, Erasmo G\u00f3mez, Arturo Oncevay, Fernando Alva- Manchego ........................................................................................................................ 281 Tourist Texts Miguel \u00c1. \u00c1lvarez -Carmona, \u00c1ngel D\u00edaz -Pacheco, Ram\u00f3n Aranda, Ansel Y. Rodr\u00edguez -Gonz\u00e1lez, Daniel Fajardo- Delgado, Rafae l Guerrero -Rodr\u00edguez, L\u00e1zaro Bustio- Mart\u00ednez ................................................ 289 Informaci\u00f3n General Informaci\u00f3n para los autores .................................................................................................................... 303 Informaci\u00f3n adicional ............................................................................................................................... 304 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje NaturalArt \u00edculos A computational psycholinguistic evaluation of the syntactic BERT models at the interface of dependency resolution and training time Una evaluaci\u00b4 on psicoling\u00a8 u\u00b4 stico-computacional de las capacidades sint\u00b4 acticas de los modelos BERT para el gallego en la intersecci\u00b4 on entre la resoluci\u00b4 on de dependencias y el tiempo de entrenamiento Iria de-Dios-Flores, Marcos Garcia Centro Singular de Investigaci\u00b4 on en Tecnolox\u00b4 as Intelixentes (CiTIUS) Universidade the Galician. We conduct a series prediction experiments in which we manipulate dependency length together with the presence of an attractor noun that acts as a lure. First, we evaluate the over- all performance of the existing monolingual and multilingual models for Galician. Secondly, to observe the effects of the training process, we compare the different de- grees of achievement of two monolingual BERT models at different training points. We also release their checkpoints and results task and provide interesting insights de los modelos Transformer para cap- turar las dependencias de concordancia sujeto-verbo y sustantivo-adjetivo en gallego. Llevamos a cabo una serie de experimentos de predicci\u00b4 on de palabras manipulando la longitud de la dependencia junto con la presencia de un sustantivo intermedio que act\u00b4 ua como distractor. En primer lugar, evaluamos el rendimiento global de los mod- elos monoling\u00a8 ues y multiling\u00a8 ues existentes para el gallego. En segundo lugar, para observar los efectos del proceso de entrenamiento, comparamos los diferentes grados de consecuci\u00b4 on de dos modelos monoling\u00a8 ues BERT en diferentes puntos del entre- namiento. Adem\u00b4 as, publicamos sus puntos de control y proponemos una m\u00b4 etrica de evaluaci\u00b4 on alternativa. Nuestros resultados confirman los hallazgos anteriores de trabajos similares que utilizan la tarea de predicci\u00b4 on de concordancia y proporcionan una visi\u00b4 on interesante sobre el n\u00b4 umero de pasos de entrenamiento que necesita un modelo Transformer para resolver las dependencias de larga distancia. Palabras clave: Modelos BERT, Gallego, evaluaci\u00b4 on sint\u00b4 actica dirigida, depen- dencias de concordancia. 1 Introduction Current on deep neural applications LSTM unlabeled text (Lin, Tan, and Frank, 2019; Hewitt and Manning, 2019). To explore the syntactic capabilities LMs, a Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 15-26 recibido aceptado 23-05-2022 ISSN 1135-5948. DOI 10.26342/2022-69-1 \u00a9 Sociedad task, psycholin- experiments on human sentence pro- cessing, this task consists on comparing the model probabilities for a correct and to the is|*are on the table\", a model that correctly identifies the dependency between the assign higher proba- bility to the than to the plural form (are), despite the presence of an intervening plural the assessment syntactic abilities based RNNs (Devlin et al., 2019). In this respect, recent works are putting the focus on the training the amount of on syntactic probing, while Wei et al. (2021) agreement. However, to the best of our knowledge, are still no studies exploring the models' per- formance along the training process, i.e., how many training steps do they need to solve long-distance dependencies. This is one of the goals of the present work. On the evaluation side, it has been argued that instead of comparing the probability of a single correct|incorrect pair (as is|are in the example above), these experiments use of pairs same phenomena (e.g., exist|exists) to observe the model's systematicity (i.e., in how many pairs a model succeeds) and its likely behaviour (the probability of generating a correct inflec- tion) Nevertheless, type of evaluation requires large sets of target pairs and, what is more substantial, itassumes a total independence between syntax and semantics is contro- versial from point of view. Taking the above into account, in this paper we investigate and tic research, we conduct a series of word prediction experiments using a while also manipulating the of lure (e.g. all performance and multilingual models for Galician. Sec- ondly, in order to observe the effects of the training process, we compare the different degrees of achievement of two monolingual BERT models (which vary on the number of hidden vocabulary evaluation which the focus on the probability distance between the correct and the incorrect alternatives for a given semantic plausible word. This met- Our contributions are the following: (i) 34 checkpoints of two BERT models for Galician which allow to explore the effects of the train- ing steps on different (ii) syntactic (iii) a care- on two agreement analyzing the impact of the learning steps, the amount of training data, the model initialization, and the depth of the neural network. 1Here in early checkpoints when trained on enough data. The rest of this paper is organized as follows: Section neu- ral language models. Then, in Section 3, we present the main characteristics of the mod- els used for the experiments and the differ- ent checkpoints provided by our study. In Section 4 we describe in- 5, while Section 6 draws the conclusions of the 2 intro- duced the number prediction performance long- distance agreement, and their results sug- behaviour of LSTMs models on a variety of languages and syntactic phenomena, ar- guing that these networks 2018). forward, Marvin and Linzen (2018) published a new dataset in English which includes not only subject-verb agreement items, but also other dependencies (e.g. anaphora, RNNs on al. (2019) were able to identify individual cells on a LSTM model which encode information about grammatical number and tively captures some morphosyntactic infor-mation from raw text. The growing interest in this research area motivated the release of SyntaxGym2, an online platform for targeted evaluation of language models (Gauthier et al., 2020), as well as datasets in different languages, such as Garcia and Crespo-Otero (2022) (for Galician and Portuguese), which is the in Unlike LSTMs, Transformer as induced- structure models (Henderson, 2020). On Transformer ar- chitectures, Tran, (2018) outperform Transformers on English subject-verb agree- ment. In this respect, the release of large Transformer-based models, such as BERT (Devlin et al., 2019) and variants, rise Wanner (2021) have shown that more training data yields better performance in most syntac- tic tasks in English, P\u00b4 erez-Mayos et al. (2021) compared multilingual and monolin- English and sults to indicate that multilingual architectures work better than ones in some and vice-versa. More recently, Garcia and Crespo-Otero (2022) evaluated a variety of BERT models for Galician and Portuguese and found that inflected related to our project, Wei et al. (2021) trained BERT models for English con- trolling the training data, and found that word frequency during the learning phase influences the evaluation of the syntactic abilities Galician BERT models at the interface of dependency resolution and training time model on which and Linzen (2018)). How- ever, to the best of our knowledge, there are no studies analyzing the impact of training time on Transformer eral checkpoints at different training steps of BERT models for English). This paper presents a detailed comparison between monolingual and multilingual BERT models for Galician. On the one hand, we explore the models' behaviour regarding lin- guistic properties of the test items, such as the length of the target dependency or the presence of attractors. On the other hand, we compare the models' into account several of layers, the amount of train- ing data, their initialization, or the number of their training steps. 3 Galician BERT models In our experiments following multilin- gual BERT (base, with 12 layers). Bertinho-small (with 6 hidden layers) andBertinho-base (with 12 hidden layers) published by Vilares, Garcia, and G\u00b4 omez-Rodr\u00b4 guez (2021). These two models have a vocabulary of 30k tokens, and have been trained on the Galician Wikipedia (with about 45M words). BERT-small (6 hidden layers) and BERT-base (12 layers) released by Garcia (2021), both trained on a corpus of about 550M tokens. BERT-small has a vocabulary size has been initialized from (which includes Galician as on of its 102 languages). It has a vocabulary size of 119,547 and has trained during we the (Garcia, 2021). These models have been trained on a corpus which combines the Galician Wikipedia (April domains), CC- 100 (Wenzek al., 2020), and other data crawled from online newspapers. It was semi- automatically were trained with a masked language modeling objective on a single Titan XP GPU (12GB), with batch sizes of 208 (small) and 198 (base), and using the transformers library (Wolf et al., 2020). For each model, we saved a check- point every 25k steps (about 12h and 26h for the small models respectively) up to 425k steps.3To avoid confusion and base. 4 Methodology 4.1 Research questions and experimental design This work aims explore the re- these questions, we created a word predic- tion task that we run in the different mod- els under evaluation (i.e. mBERT, Bertinho- small and base, BERT-small and base and the different checkpoints of Check-small and base. Our task had a factorial design which manipulated the type of agreement), the amount of intervening material (short vs. long) and the presence or absence of an inter- vening but structurally irrelevant noun that in (no checkpoints are \u00b4 alto|*alta. yes Oneno que xogaba na on. yes of an attractor word. underlined are attractors, which agree with the wrong alternative marked with *. The base sentence (i.e. short without attractor) for noun-adjective dependencies means \"The boy who subject-verb agreement TV\". sample set of the experimental conditions is shown in Table 1. We will pay particular attention to the models' accuracy for the experimental con- ditions at different steps in the training pro- cess by testing checkpoints at every 25k steps up to 425k for both Check-small and base. This will also allow us to investigate not only the effects of training steps (on the var- ious also others, the following comparisons: (a) the of comparing BERT-small Bertinho- and the de- scribed in the next section. 4.2 The dataset In order to run the experiments described above, we have used a subset the dataset by choosing items with the structure of those was conterbalanced so that half of the items had a feminine target and the other half a mas- of the items had a sin- gular target and the other half a plural one. It is worth noting that, overall, there are less experimental items without an attractor than those with an attractor. This is because are available in Garcia and Crespo- Otero (2022), but it must be noted that to create the dataset, the the vocabulary of the (monolin- gual and multilingual) models in order to al- low the evaluation of all models using the same number of experimental items. 4.3 Evaluation metrics Before moving into the results of the of the syntactic Galician BERT models at the interface of and 'The girls who were playing there yesterday with the other boy *is| thus or a 1), Newman et al. (2021) propose the use of a large set of correct/incorrect pairs on each sentence to probe a model. In this vein, they measure the model's systematicity (in how many pairs per sentence the model prefers the correct alternative) and behaviour (the probability of a inflec- corpus focus on the probability distance between the correct and the incorrect alternatives (e.g. te nen vsten) via percentages, then substract- ing the percentage of the incorrect form from the percentage of the one. The nale behind as for 0.85 Instead, PD accuracies are circumscribed to a probabil- ity space which only includes a semantically plausible target pair, and accuracy is calcu- lated within results a subject- verb long agreement dependency with an tractor for alternative, and would a 1 in both distance the ex- amples such as the one in Table 2). We are only showing BERT-base results for long sen- tences with an attractor for the sake of sim- plicity, as these are the cases where models tend to fail. What can be observed here is that binary metrics will first and discuss the accuracy provided by the five available models and then, we will focus on the results for Check- small and Check-base at different training checkpoints. 5.1 Published models Overall accuracy: Figure 2 shows the overall accuracy for each model for noun- 20 to ques- tions can be tackled at this point: first, there is a decline for models (BERT-base>BERT- most possibly be- cause they have been trained with the same Galician data (Wikipedia) and have a simi- lar architecture (same number of hidden lay- ers and dimensionality). BERT-base and BERT-small show a relatively acceptable performance, while the other three models (Bertinho-base, Bertinho-small and mBERT) are closer to chance performance (see Q1). This is particularly true for subject-verb agreement dependencies, while results for noun-adjective dependencies (see Q2). glish, Bertinho-small Mean accuracy under investigation. Accuracy per condition: Figure 3 pro- vides a closer the models' perfor- mance for noun-adjective and subject-verb dif- ferent experimental conditions. These re- sults tap directly (see short with no attractor were predicted to be the easiest ones, while long sentences with an attrac- tor were predicted to be the hardest ones. This the five mod- els under investigation. ing that BERT of attraction effects is medi- ated by the distance between the head and the target such that longer dependencies are more prone to give rise to attraction effects. Nonetheless, it must be noted that not all models on the of Figure 2. 5.2 Learning curves Overall accuracy: Moving now into the analyses by training checkpoints, Figure 4 shows the overall accuracy for Check-small and Check-base for the two dependencies at every checkpoint, 25k to 425k syntactic Galician BERT models at the interface and training time Figure 4: Mean type and checkpoint for Check-base and Check-small. The horizontal red lines indicate the Figure 2). Check-small: Focusing on the small model (with 6 layers and trained from scratch) represented by the dark line, the re- sults show that it needs relatively few check- points to steps to outperform Bertinho-base and mBERT, both 12 layers. This is even clearer on subject-verb dependencies, as the second checkpoint (75k) already better results than any of the three men- tioned models. When comparing with the re- sults of the published BERT-base and BERT- small (see Figure 2), it is worth noting that these models do not obtain notoriously better results even though they have been trained for a longer period of time. These results sug- gest that the amount of by the dark line, it should be reminded that this model has been ini- tialized with the weights of mBERT, and at the first checkpoint (25k) it already obtains comparable results to that of the final BERT- base model on subject-verb agreement (see Figure 2). On noun-adjective dependencies, the model keeps a more constant learning rate, but it achieves similar performance than BERT-base at around 400k steps. In this case, we may hypothesize that the model is taking advantage of the of other model to Galician steps. constant learning be tal condition for Check-small and Check- base at the different training steps. As ex- pected, contexts and are shown (Figure 4), Check-base overtakes the performance of mBERT on the first check- points, but then the raise of the learning curve is very small, namely for subject-verb agreement. The attrac- tors are present, Check-small is sensitive to them even in short contexts, where it pre- serves the performance again about mod- els seem to have a stable behaviour, as the performance of both of them varies unpre- dictably. This is more noticeable for Check- base, which solves most cases properly but struggles with the more complex structures (i.e. long sentences with 22 Check-base dependency type, experimental condition, and checkpoint. 6 Conclusions and future work This paper has presented a multidimensional evaluation of a variety of BERT models for Galician on two types of agreement de- pendencies, noun-adjective and We compared and monolingual models with diverse properties, including 6 and 12 layers variants, different sizes of training data and vocabu- laries, and two initializations: training from scratch, and fine-tuning a multilingual BERT on Galician data. Our results show a gradient in the abil- ity of Galician BERT LMs models to re- solve agreement dependencies, with BERT- base being at- effects is inverse to accuracy (i.e. less accurate models attraction ef- fects). Last and most important, although training time does seem to have a small ef- fect on the models' accuracy, this factor is far from being comparable with the influence of the size of the training corpus. Besides the results and analyses of the per-formed experiments, we contribute with new 34 checkpoints of BERT models for an under- studied language, Galician, which are freely released with this paper and can hopefully contribute to foster research on languages dif- ferent from English. This exploratory work has opened many lines of inquiry that we aim to explore in fu- ture research. On the one hand, we plan to create new datasets in Galician that do not only overcome some shortcomings observed in the one released by Garcia and Crespo- Otero (2022) but also incorporate new types of linguistic relations. On the other hand, we plan to compare the results obtained for Gali- cian with other order to observe cross-linguistic differences and similarities. Acknowledgements research was funded by project \"N\u00b4 os: Galician in the society and econ- omy of artificial intelligence\" (Xunta de Galicia/Universidade de Santiago Com- postela), ED431G2019/04 (Galician M. A. Solla Portela. 2018. Devel- oping new linguistic resources and tools 23 evaluation of the syntactic abilities of Galician BERT models at the interface of dependency resolution and training time for the Galician language. In Proceed- ings of the Eleventh on Language and Eval- uation (LREC 2018), May. European CSLI Devlin, J., Chang, K. Lee, and K. Toutanova. 2019. Pre-training deep bidirectional transformers for lan- guage understanding. In Proceedings of the 2019 Conference of the North Amer- ican Chapter of the Association for Com- putational Linguistics: Human Language Technologies, Volume 1 , pages 4171-4186, Minneapolis, Minnesota. Association for Computational Linguistics. the repre- sentation study homonymy and syn- onymy. In Proceedings of the tional Linguistics Interna- guage Processing (Volume 1: Long Pa- pers), pages 3625-3640, Online, August. Association for Computational Linguis- tics. Garcia, M. and A. Crespo-Otero. 2022. A Targeted Assessment of the Syntac- tic Abilities of Transformer Models for Galician-Portuguese. In International Conference on Computational Processing of the Portuguese Language (PROPOR 2022), pages 46-56. Springer. Gauthier, J., J. Hu, E. Wilcox, P. Qian, and R. Levy. 2020. SyntaxGym: An online platform for targeted evaluation of language models. In Proceedings of In Proceedings the 2018 Confer- ence of the North American Chapter of the Association for Computational Linguis- tics: Human Language Technologies, Vol- ume 1 (Long Papers) , pages 1195-1205, New Orleans, Louisiana, June. Associa- tion for J. computational in deep learn- ing. In Proceedings of the Annual Meeting of the Association for Computa- tional 6294-6306, On- line, July. Association for Computational Linguistics. Hewitt, J. and C. D. Manning. 2019. A structural probe for finding syntax in word representations. In Proceedings of the 2019 Conference of the North Ameri- can Chapter of the Association for Com- putational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) , pages 4129-4138, Minneapolis, Minnesota, June. Association for Compu- tational Linguistics. Kuncoro, A., C. Dyer, J. Hale, som. 2018a. The perils of natural be- Kuncoro, A., C. Dyer, J. Hale, D. of the Association and syntax units in LSTM language models. InProceedings of the 2019 Conference of the North American Chapter of the As- sociation for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 11-20, Minneapolis, Minnesota, June. Associa- tion for Computational Linguistics. 24 Iria de-Dios-Flores, Marcos Garcia Lin, Y., Y. C. Tan, and R. Frank. 2019. Open sesame: Getting inside BERT's lin- guistic of the 40th Conference of the Cognitive Science Society. arXiv preprint Marvin, R. and 2018. Targeted syntactic evaluation of language models. InProceedings of 2018 Conference on Empirical Methods 2020. Cross- In Proceedings of the 58th Annual Meeting 2021. syntactic Pro- ceedings of the 2021 Conference of the North American Chapter of the Associa- tion for Computational Linguistics: Hu- man for Com- putational Linguistics. L., M. Ballesteros, and L. Wan- ner. 2021. How much pretraining data do language models need to syn- ral , pages 1571-1582, Online and Punta Cana, Dominican Re- public, capabilities of transformer-based multilingual Linguistics: T., S. Yadlowsky, J. Wei, D'Amour, T. Linzen, J. Bastings, I. Turc, J. Eisenstein, D. Das, I. Ten- ney, and E. Pavlick. 2022. The Multi- BERTs: BERT Reproductions for Ro- bustness Analysis. In being recurrent for modeling hierarchical structure. In of the 2018 Conference on Em- pirical Methods Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin. 2017. At- tention Is All You Need. Garrette, Con- ference on Empirical Methods in Natural Language Processing, pages 932-948, On- line and Punta Cana, Dominican Repub- Guzm\u00b4 an, A. Joulin, and E. Grave. 2020. CCNet: Ex- tracting high quality monolingual datasets from web crawl Language Resources and Evalua- tion Conference , pages 4003-4012, Mar- seille, France, Language Resources 25 computational psycholinguistic evaluation of the syntactic abilities of Galician BERT models at the interface of dependency resolution and training time Wolf, T., L. Debut, V. Sanh, J. Chau- mond, C. Delangue, A. Moi, P. Cistac, T. Rault, R. Louf, M. Funtowicz, J. Davi- son, S. Shleifer, P. von Platen, C. Ma, Y. Jernite, J. Plu, C. Xu, T. Le Scao, S. Gugger, M. Drame, Q. Lhoest, and A. Rush. 2020. Transformers: State- of-the-art natural language processing. InProceedings of the Methods Computational Linguistics. 26 Iria de-Dios-Flores, Marcos Garcia Information fusion for mental disorders detection:multimodal BERT against fusioning multiple BERTs Fusi\u00b4 2Centro A.C., Guanajuato, is by the problem of timely detection of mental disorders involves extracting as emotional MMBT, moreover, we further evaluate if regular BERT models could be combined or fused in such a way that could have a chance in a multi-channel arena. For the evaluation, we use recent public data sets for three disorders: De- pression, Anorexia, and Self-harm. Results suggest that BERT models can get on their own a data representation that could be later fusioned and boost the classifi- cation performance by measure, the MMBT. Keywords: Resumen: Dado el creciente n\u00b4 umero de modalidades que ofrecen los problemas de clasificaci\u00b4 on modernos, recientemente se ha propuesto un transformer BERT mul- timodal (MMBT). Una oportunidad interesante para evaluar la eficacia de dicho modelo la plantea el problema de la detecci\u00b4 on oportuna de los trastornos mentales de usuarios de las redes sociales. Para este problema, una perspectiva multicanal implica extraer de cada post de los usuarios diferentes tipos de informaci\u00b4 on, como su contenido tem\u00b4 atico, emocional y estil\u00b4 stico. Este estudio eval\u00b4 ua la idoneidad de abordar este problema mediante el aparentemente ad-hoc MMBT, adem\u00b4 as, evalu- amos si los modelos BERT regulares podr\u00b4 an combinarse o fusionarse de tal manera que pudieran tener una oportunidad en un escenario multicanal. Para la evaluaci\u00b4 on, utilizamos conjuntos de datos p\u00b4 ublicos recientes para tres importantes trastornos mentales: Depresi\u00b4 on, Anorexia y Autolesiones. Los resultados sugieren que los mod- elos BERT pueden obtener por s\u00b4 solos una representaci\u00b4 on de los datos que podr\u00b4 a fusionarse posteriormente y aumentar el rendimiento de la clasificaci\u00b4 on en al menos un 5% en la medida F1, superando incluso al MMBT. Palabras clave: Multicanal, Transformers, Trastornos Mentales. 1 Introduction Over the last few years, millions of people around the world have been affected by one or more mental disorders, for example, in2018 a study of mental disorders in Mexico reveals that 17% of people in the country have at least one mental disorder and one in four will suffer a mental disorder at least Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 27-38 recibido aceptado 23-05-2022 ISSN 1135-5948. DOI 10.26342/2022-69-2 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Naturalonce in their life (Renteria-Rodriguez, 2018). Unfortunately, this a mental disorder causes emotional and physical damage that could make people feel fear to the idea of being vulnerable to criticism, judgment, or opposing opinions. Mental disorders generated excessive stress on the affected person or to a series of different stressful events (World Health Organization, 2019). For instance, some of the causes are mental such depression, anorexia, or self- harm affecting people worldwide (Kessler et al., 2017). A reality nowadays, is that for some peo- ple their social life does not occur in their surroundings or immediate environment, but takes place in a virtual world created by so- cial media platforms like Facebook, Twitter, or Reddit (Baer, 2021). In other words, so- cial media has become a vital link for some of us. This scenario presents opportunities to study and analyze, given the availability of data, how people communicate, and more specifically, how this communication could be associated to possible mental health issues that people are experimenting, contributing in networks have dif- ferent evidence or types (channels or pseudo modalities) of information that may be rel- evant for the detection of mental disorders for example, topics of emotional state, or their writing style. This has motivated us to pro- pose a method that considers these pieces of information and to study how to combine or fusion them. With this in mind, we evalu- ate the plausibility of using the multimodal BERT (MMBT)(Kiela et al., 2019) for this task, being this the first time. In addition, we state the question: whether MMBT is the best option to handle this sensitive task or if multiple BERTs can better exploit the na- ture of the data. Thus, we compare MMBT against on early and late fusion ap- proaches of the popular BERT model. Inthis study we take the text modality and di- vide it into three channels1that focus on dif- ferent aspects of third channel focuses on the writing style, where we want to capture the use of personal ex- pressions and verbs tense, among other as- pects. As could be observed, our hypothesis is that people that present some mental dis- order tend to express differently, at different dimensions, regarding the control group. It is widely known that the BERT model (Devlin et al., 2019) has led to important improvements in representation learning for natural language processing and text classi- fication problems. In a recent work obtain good performance in multimodal fusion. They found that learning to map dense multimodal features to BERT's token embedding different a multichan- nel contextualized representation. The main idea of our work is to find out the best way to combine the different types of information and see if using multimodal BERT is better than considering a fusion of multiple BERTs, each one specialized in a different channel. We can summarize the contributions of our work as follows: 1. We adapt a Multimodal BERT (MMBT) for com- bine these information, considering early and late fusion approaches. 3. We analyze and evaluate in detail these three information channels and the im- portance of their fusion, then conclud- ing about its feasibility of integration to boost classification performance. 1In this work, we define a channel as a different property or view from the same modality (Qianli et al., 2017). Mario Ezra Arag\u00f3n, A. Pastor L\u00f3pez-Monroy, Luis C. Gonz\u00e1lez-Gurrola, Manuel Montes-y-G\u00f3mez2 Related work 2.1 Mental disorders detection In the last few years, the study of public men- tal health through social media has increased. This is mainly because these media provide a source of support for those who suffer from a mental health disorder, like for example, a sense of community, relatedness, and under- standing (Hilton, 2016; Dyson et al., 2016). In general, for the construction of corpora, researchers identify a group of users who ex- pressed in one of their publications having been clinically diagnosed with a mental dis- order and then download all or part of their posts (De Choudhury, Counts, and Horvitz, 2013; and Oliveira, 2019; Van Rijen et al., 2019), explored the analysis of the posts' content. In these works, the au- fication a decision. The shortcoming with strategy is the high overlap in the vocabulary used neu- tral words texts (Kang, Yoon, and Kim, 2016), or on measuring how similar are their words to some reference pos- itive lexicons timents has shown interesting results since it has been found that negative comments are more abundant in people with a declared mental health disorder than in comments generated Dredze, and Harman, 2014; Preotiuc- Pietro et have a LIWC-based representation (Tausczik and Pennebaker, 2010), which consists aim dif- ferences (Coppersmith 2015). 2.2 Fusion approaches for mental disorders detection How to effectively combine information is challenging and has a long history in machine learning (Baltrusaitis, Ahuja, and Morency, 2019). In particular, some recent works on mental disorders detection have considered the deep neural models (Trotzek, Koitka, and Friedrich, 2018). In (Ragheb et al., 2019), the authors combine the tem- poral mood variation an attention-based deep model to construct a representation for the mood variation. Then, in the phase, the model uses to detect clear give a decision based on their combination. In (Ji et al., tion from different channels in a more effec- tive way. For that our multi-channel BERT-based ap- emotional and stylistic views of media users. This proposed model takes inspiration from multi- modal BERT (Kiela et al., 2019) in order to have an adapted version that is able to model individual channels. As our experimental evaluation will show, the proposed strategy improves the classification performance. 3 Information channels representation The fusion strategies that we are going to ex- plore are implemented on the basis of BERT, therefore, the three channels of information are captured by three different representa- tions of the words. The main idea of this approach is to have different views of the con- tent of the users' this we briefly how to generate these three Thematic In multimodal BERT against fusioning multiple BERTs ning, 2014). However, since this type of embeddings does not take into account the context of the words, we decided to also use some contextualized word embeddings, in particular the BERT embeddings (Devlin et al., 2019). For our experiments, we used both separately and evaluated which one con- tributes to the final representation. With contextualized embeddings, words that have similar meaning or show some se- mantic relation are closer to each other. For example, the words \"insecure\" and \"worried\" \"therapy\" and \"treatment\". 3.2 Emotion-based embeddings For this work, use the emotion-based word embeddings that were originally proposed in (Aragon et al., 2019). In short, to construct these vectors, first, we generated groups 2013). achieved this of the lexicon with its FastText embedding (Bojanowski et al., 2016) and then applying a gorithm on them. After obtaining the related to the same emotion, we represented each of them by means of the average vector of its words. Subsequently, and as the last step, for each word in the vocabulary we measured its co- sine similarity with all fine-grained emotions, and assigned to each the embedding because same emo- tion, whereas the word \"magician\" have a slightly different embedding since it corre- sponds to a different subgroup of the same emotion. On the other hand, the words \"ac- complish\" and \"achieve\" will have a com- pletely different embedding as they belong to the Joy emotion. 3.3 Style-based embeddings The third representation of the words particular characteristics of the writ- ing style of social media users. Its idea is to capture how users with mental disorders tend to talk, for example, referring to past events or to uncertainties about the future.To capture the stylistic information, we pro- pose a new word representation inspired by the successful use of character n-grams profiling tasks. To define users' posts, we carried out the following process: 1. Divide word into to its and control users). 3. Obtain the embedding vector of the word by applying a weighted sum of the vectors of its character consid- ering as weights its style-based embedding obtained by the weighted \"epr\", important the style-based embeddings are similar for in past tense, or words with the same root. Take for in- stance the word \"mental\" would be \"dental\", \"mentality\" or \"decremental\". 4 On the fusion of the three channels The objective of our work is to compare dif- ferent ways of combining information from different channels. This is a key stage in the classification process, and have the intuitive idea of learning the relevance of each channel in an automatic way. We use two main strate- gies, firstly, one based on multimodal BERT whose idea is to learn a joint representation of the three types of information, and sec- ondly, different architectures that treat each channel separately early and late fusion techniques. 4.1 al., 2019). The MMBT model starts with pre-trained BERT Mario Ezra Arag\u00f3n, A. Pastor L\u00f3pez-Monroy, Luis C. Gonz\u00e1lez-Gurrola, Manuel Montes-y-G\u00f3mezweights, and These embeddings sum of the segment, po- sition, and token embeddings of each word. Then, the model weights them and project each of the embeddings to a token input. In Figure 1, we can appreciate the components of the architecture of the MMBT model. Al- though proposed for only two modalities, this architecture can be generalized to any num- ber of modalities, assigning a authors input. Instead of image embeddings, we used the sequence of the words for the fine-tuning with our different channels as embeddings. Once we fine-tuned the model with used the first output of the final MMBT layer as input to a Convo- lutional Neural Network (CNN) for feature extraction, and a dense layer for achieving the classification. Figure 2 presents the general architecture of this approach. 4.2 Combining information using multiple BERTs The authors (Kiela et al., 2019) noted that their method is compatible with scenarios where not every modality is present and can be generalized to an arbitrary num- ber of modalities. Then, for the second model, we decided to train individual BERTs and fine-tuning them with each channel sepa- rately. After the training, similar to the first approach, we used the first output of the final layer of each BERT and concatenate them as input for a CNN layer, we will refer to Figure 2: General diagram of the Model 1: Multimodal BERT with vectors of three channels, then a CNN layer, and a classifica- tion layer. this model as BERT-CNN. In Figure 3, we present the general diagram for this process. 3: separately enters to a BERT model, then join vectors feed a single CNN layer, and a classification layer. For the third model, instead of concate- nating the vectors and using a single CNN layer, we separate them into different con- volutional layers and used the output for a dense layer. With this approach, the model obtains for each channel different feature maps of each region and concatenates them together to form a single feature vector. This can be interpreted as summarizing the local information to find patterns, and then com- bining the information. The hypothesis that the local information per channel is impor- tant and should be extracted before it is com- bined, we call this model BERT-3CNN. Fig- ure 4 presents the general diagram for this model. 31 Information fusion for mental disorders detection: multimodal BERT against separately enters a BERT model and a CNN layer, then their outputs are concatenated and fed to a single classifier. One of the challenges of this work is the problem of fusing information. A simple so- lution is to concatenate the representations of each channel into one vector or perform an operation like adding or taking the prod- uct. However, the use of these operations as- sumes that all channels have the same rele- vance, which is usually not the case. In re- cent work (Arevalo et al., 2019), the authors proposed a novel type of hidden unit called Gated Multimodal Unit (GMU). This unit works similarly to the control flow mechanism in gated recurrent units. The gates in the unit let the model regulate the flow of infor- mation into the next one. Figure 5 presents a general overview of the GMU The final fused representation of all modalities is represented GMU tasks, our fourth model takes advantage of it. That is, after the feature extraction, Then, apply a dense layer to classify the final vector with the in- formation of the three channels, we call this model BERT-GMU. Figure 6 describes the process for separately enters a BERT model and a CNN layer, then their outputs are combined by a GMU module, and fed to a single classifier. 5 Experimental settings 5.1 Data sets We performed experiments over data sets from the eRisk 2019 and 2020 evaluation tasks (Losada, Crestani, and Parapar, Losada, Crestani, These data sets consist of the detection of depres- sion, anorexia, and self-harm, and contain the post history of several users from the Reddit platform. For each mental disorder, we have two types of users: 1) the control group, people collected who do not suffer from any mental disorder; and 2) positive users, a group composed of people affected by either depression, anorexia, or self-harm. In the tasks of anorexia and self-harm, the is composed users who explic- mentioned that they were diagnosed by a medical specialist or that they had commit- ted self-harm. On the other hand, the control class for both tasks is composed of random users from the Reddit platform. However, to add realism to the data sets and make the Mario Ezra Arag\u00f3n, A. Pastor L\u00f3pez-Monroy, Luis C. Gonz\u00e1lez-Gurrola, Manuel Montes-y-G\u00f3mezdetection in the threads of anorexia and self- harm. For depression, the organizers of the shared task asked the participants to predict, for each user, the to each in- put of the BDI questionnaire (Beck et al., 1961), which contains 21 questions that allow assessing the level of severity of the depres- sion. In contrast to them, in this work we exclusively consider a binary prediction task, i.e., to distinguish and con- trol users. In particular, the positive class is composed of users that obtained 21 points or more in the final result of the questionnaire (presence of moderate or severe depression), whereas the control class is formed by the rest of the users, having 20 points or fewer in their final result. Table 1 shows how classes distribute within these data sets as well as some general information regarding the collections. For the depression task, we used for training the data set from eRisk 2018 (Losada, Crestani, and Parapar, 2018), this data set was con- structed similarly to anorexia and self-harm data sets. Data set Train Test P C P C Anorexia'19 61 411 1: Data used for experimentation, where P indicates positive users and is for texts removing them before masking texts, but consistently we got slightly lower performances.5.3 Classification The main goal is to classify users into one of the two classes (Depressed / Control, Anorexia / Control, or Self-harm / Control). We separate each post history into For training, we process each part of the post history as an individual input and train the model. For the test, each part receives a label of 1 or 0; then, if the majority of the posts are posi- tive, the user is classified as showing a men- tal disorder. The main idea is to consistently detect the presence of major signs of depres- sion, anorexia, or self-harm through all the user posts. 5.4 Baselines unigrams these are common baseline approaches for text classification. For both approaches, we selected the same some baselines based on deep learning approaches, using a CNN and a Bi-LSTM. The neural networks Glove embeddings with a dimension of 300. For the CNN we use 100 random fil- ters of sizes 1, 2, and 3 (parameters recom- mended in literature). We also add a BERT model with a fine-tuning over the training data set. Additionally, the obtained results precision, and recall over positive class (Losada, Crestani, and Parapar, 2018). 6 Evaluation and For in terms of F1score, precision, and re- call over the positive class to detect Anorexia (eRisk'19), Depression (eRisk'20) and groups: baseline methods, our pro- posal but limited to only one channel, and our proposal using all information channels 33 Information fusion for mental SH Baselines F1 P R architectures based on multiple BERTs. From this evaluation, we observe that most of our based style and emotion information. Unex- pectedly, for the baselines, the performance of deep learning models applied over word- based representations is closer to traditional approaches using a Bag-of-Words. We think this could be due to the small size of the data set and the intersection of thematic con- tent. Something interesting to performance than RNN networks. The latter could be be- cause CNN networks search for the presence of specific local information important for the detection of these disorders. For our representations based on the fu- sion of information, their performance is higher in comparison with the other mod- els, suggesting the relevance of combining the information from different channels. Some- thing interesting to notice is that all models using multiple BERTs outperformed the mul-timodal BERT model in F1, indicating that, for this particular task, and with this way of representing the channels, it is better to independently and com- bine them the model that use the GMU module showed the best aver- age performance, which suggest that weight- ing the information helps to create a better representation of the posts and the users. From these experiments, 3. These results confirms our intuition that learning to combine different types of information is very relevant to capture signs of mental disorders in users. 4. In general, our models obtain an har- monic result between precision and re- call deriving in a better F1 score. Mario Ezra Arag\u00f3n, A. Pastor L\u00f3pez-Monroy, Luis C. Gonz\u00e1lez-Gurrola, Manuel Montes-y-G\u00f3mez6.1 Comparison against the eRisk participants To expand context to the results, we also include a comparison the eRisk tasks. These evaluation forum considers a total of 54 models for the anorexia detection task and 57 for the self-harm detection task in eRisk-19 and 20 2019; and It important to mention that the participants focused on obtaining early both tasks; they first place results in Anorexia, and showed a slightly lower performance than the first place in Self-harm. For the depression task, organizers changed the eRisk task considered the of the level of depression sever- ity for each user. For this reason, we cannot compare against the To understand each information chan- nel contributes to the final decision we will utilize the GMU units in the fourth model (BERT-GMU) and analyze the weighting of the gates, where the gates in the unit let the model regulate the flow of information into the next one. The main idea in a GMU is that the unit learns to weigh the modalities (chan- nels for them according to their relevance. A GMU works similar to a network layer and finds an intermediate rep- resentation based on the the gates' zivalues of the GMU module correspond- ing the test set posts. Figure 7 presents the results for the three each value already takes into account the aver- of all posts. For anorexia, we can ap- preciate that the thematic information con- tributes the most the final decision, fol- lowed by emotion and style information. For depression, we can observe that the thematic information is also the most important and the value highest. In general, it can be no- ticed how the activation for each channel are different depending on the mental disorder. Something interesting is that the thematic channel presents the highest variation, the lowest value self-harm and vari- ation indicates that the posts of users who suffer from anorexia are probably more ho- mogeneous than those who suffer self-harm. For a further analysis of the GMU, Table 3 presents the posts of the depression data set with the highest zivalue for each chan- nel. We can notice that the posts are related to personal opinions, different topics, and in general express negative emotions even when they are not directly related to mental disor- ders. Take for example the emotion channel where the post is related to regrets in life and feelings, or the style channel where the post talks about a mental three tal disorders over the test set instances. 7 Conclusion and future work In this work, we explored the detection of users that suffer anorexia, depression, or self- 35 Information fusion for mental disorders detection: multimodal BERT against fusioning multiple BERTs Channel Post thematic \"...I have no idea what either of them were trying to communicate tbh i was having a really good dayand then you had to bring up hughes...\" emotion \"...take the chance and have no regrets in life, its always bet- ter to know if the other person feels something so that you are not wasting your time...\" style \"...these days parents don't know a whole lot about mental illness they were told it was highest zivalue for each channel over the depression task. harm. For this task, we used the users' the- combine these information channels inspired by the usage of transformers to transformer; this finding its own opens an opportunity to explore models inspired by transformers to create new representations and continue improving the performance in the The results perfor- mance of top eRisk participants. We believe that it is important to mention that these models, although they obtain better results, are extremely resource-consuming (proces- sor, memory, energy, etc.) in comparison with simple models. For future work, we want to explore more sophisticated combi- nation techniques that could example, multi-modal trans- formers. We note that most of the analysis of mental disorders has been made for the English language, then, one of our interests lies in the expansion of this study to Spanish language.References Aragon, M. v., A. Lopez-Monroy, L. Gonzalez-Gurrola, and M. Montes-y Gomez. 2019. Detecting depression in social media using fine-grained emotions. Proceedings of the 2019 Conference of the North American Chapter of the As- sociation for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Arevalo, J., T. Solorio, M. learning: A survey and taxonomy. Analysis and Machine Intelli- gence, . Beck, A., C. Ward, M. Mendelson, Mock, and J. Erbaugh. 1961. Psychiatry 4(6), 561-571 . Bojanowski, E. A. Mikolov. 2016. Enriching word vectors with subword guistics. G., M. Dredze, and C. Har- man. 2014. Quantifying mental health signals twitter. Compu- Hollingshead. 2015. From adhd to sad: analyzing the language of mental health on twitter through self-reported di- agnoses. Proceedings of , S. Counts, and E. Horvitz. 2013. Social media as a measurement tool of depression in popu- lations. In Proceedings of the 5th Annual ACM Web Science Conference . Mario Ezra Arag\u00f3n, A. Pastor L\u00f3pez-Monroy, Luis C. Gonz\u00e1lez-Gurrola, Manuel Montes-y-G\u00f3mezDevlin, J., M. Chang, K. Lee, and K. Toutanova. 2019. Bert: Pre-training of deep bidirectional M., J. Shulhan, A. Chisholm, A. Milne, P. Sundar, S. Scott, and A. Newton. 2016. A system- atic review of social media use to discuss and deliberate self-harm acts. Current Opin- ion in Hilton, C. 2016. Unveiling self-harm be- haviour: what can social media site twit- ter tell us about self-harm? a qualitative exploration. Journal of clinical nursing. Htait, Ji, S., Li, Z. Huang, and E. Cambria. 2020. Suicidal ideation and mental disor- der detection relation net- works. arXiv:2004.07601. Iden- tifying depressive users in twitter using multimodal analysis. In Big Data and Smart Computing (BigComp), 2016 Inter- national Conference on. IEEE, 231-238. Kessler, Inter- action and Language (ViGIL), NeurIPS 2019 Workshop. Losada, D., F. Crestani, and J. Parapar. 2018. Overview of erisk 2018: Early risk prediction on the internet (extended lab overview). Proceedings of the 9th Inter- national Conference of the Associ- ation, CLEF 2018, France.Losada, 2020. Overview of 2020: Conference of the CLEF Association (CLEF 2020). Losada, D. v., F. Crestani, and J. Parapar. 2019. Overview of erisk 2019: Early prediction S. R. Socher, and Manning. Glove: global vectors for word on on Natural Language Processing. Preotiuc-Pietro, D., J. Eichstaedt, G. Park, M. Sap, L. Smith, V. Tobolsky, H. Schwartz, and L. Ungar. 2015. The role of personality, age and gender in tweeting about mental illnesses. In Proceedings of Action recognition from action Inter- national Joint Conference on Artificial In- telligence . Ragheb, W., J. Aze, Ser- vajean. 2019. Attentive multi-stage learn- ing for early risk detection of signs of anorexia and self-harm on social media. Proceedings of the 10th International Con- Switzerland Renteria-Rodriguez, M. 2018. men- tal en mexico. NOTA-INCyTU N \u00b4UMERO 007. Tausczik, Y. J. of words: Liwc and computerized text analysis methods. Journal of Language and Social Psychol- ogy, pages 24-54. 37 Information fusion for mental disorders detection: multimodal BERT against fusioning multiple BERTs Oliveira. 2019. Bioinfo@uavr at erisk 2019: delving into social media texts for the early detection of mental and food disorders. Proceedings of the 10th International Conference of the CLEF Association, CLEF 2019, Lugano, Switzerland. Trotzek, M., S. Koitka, and C. Friedrich. 2018. Word embeddings and linguistic metadata at the clef 2018 tasks for early detection of depression and anorexia. Pro- ceedings of the 9th International Con- ference of the CLEF Association, CLEF 2018, Avignon, France. Uban, A., B. Chulvi, and P. Rosso. 2021. An emotion and cognitive based analysis of mental health disorders from social media data. Future Generation Computer Sys- tems. Van Rijen, P., D. Teodoro, N. Naderi, L. Mot- tin, J. Knafou, M. Jeffryes, and P. 2019. A data-driven approach for measur- ing the the depression using reddit posts. Proceedings of the 10th International CLEF As- sociation, CLEF 2019, Lugano, Switzer- land. Wang, In Proceedings of the Tenth ACM International conference on web search and data mining. World Health Organization, W. Luis C. Gonz\u00e1lez-Gurrola, Manuel Montes-y-G\u00f3mezUn redactor asistido para adap tar textos administrativos a lenguaje claro A writing assistant to adapt administrative texts into plain language Iria da Cunha Universidad Nacional de E ducaci\u00f3n a Distancia iriad@flog.uned.es Resumen: El lengu aje claro ab oga por que los textos dirigidos a los ciudadanos est\u00e9n redactados en un lenguaje m\u00e1s sencillo y transparente, para que estos puedan entender f\u00e1cilmente el mensaje que se les quiere transmitir . En e ste contexto , nuestro objet ivo es desarrollar un redactor asistido para el espa\u00f1ol que ayude al personal de la Administraci\u00f3n p\u00fablica a escribir en lenguaje claro los textos que dirige a la ciudadan\u00eda. El sistema, gratuito y en l\u00ednea , integra diferentes herramientas de Procesamiento de Lenguaje Natural (PLN ) para detectar en los textos escritos por los usuarios los rasgos ling\u00fc\u00edsticos que interfieren con las recomendaciones sobre lenguaje claro . Asimismo, ofrece al usuario informaci\u00f3n para hacer m\u00e1s sencillo su texto. Para ev aluar los algoritmos se emple \u00f3 un corpus anotado manualmente , y las medidas de precisi\u00f3n y cobertura . Los resultados son muy positivos, aunque tambi\u00e9 n ref lejan algunos aspectos que se pueden mejorar en el fut uro. Palabras clave: Lenguaje claro, redacci\u00f3n asistida, Procesam iento (PLN ), Admi should be written in simpler and transparent language, so that they can e asily understand the message to be co nveyed. In this context, our aim is to develop an assisted writing tool for Spanish to help Public Administration staff to write texts addressed to citizens in plain language . The system is free and online . It integrates different Natural Language Processing (NLP) tools to detect the linguisti c features that interfere plain by users. It also provides corpus hlight some aspects that could be improved in the future. Keywords: Plain Language, Assisted Writing , Natural Language Processing (NLP), Public Administration. 1 Introducci\u00f3n El lenguaje claro es u na corriente que aboga por que los textos que se dirijan a los ciudadanos est\u00e9n redactados en un lenguaje m\u00e1s sencillo y transparente, para que estos puedan entender el mensaje que se les quiere transmitir y, as\u00ed , contribui r a que ejerzan sus derechos y a que cumplan con sus obligaciones. Seg\u00fan el sitio web de la International Plain Language Federation , 1 la comunicaci\u00f3n en lenguaje claro tiene unos rasgos concretos: \"A commu nication 1 https://www.iplfederation.org/plain wording, and easily find what they need, understand what they find, and use that information\". Esta corriente adquiere una relevancia especial en el marco de la modernizaci\u00f3n del lenguaje jur\u00eddico y administra tivo, uno de los grandes retos de la Administraci\u00f3n espa\u00f1ola (Cassany, 2005; Montol\u00edo, 2012; Bay\u00e9s, 2021). El reto es cambiar una tradici\u00f3n en la Administraci\u00f3n que hace que los textos que recibe la ciudadan\u00eda (notificaciones, requerimientos, resoluciones, multas, etc.) Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 39-49 recibido aceptado 30-05-2022 ISSN 1135-5948. DOI 10.26342/2022-69-3 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Naturaltengan unas caracter\u00edsticas ling\u00fc\u00edsticas que \"oscurecen\" el texto, como p\u00e1rrafos largu\u00edsimos, oraciones con m\u00faltiples subordinadas e incis os, verbos en voz pa siva, en gerundio y en participio, formas verbales arcaicas, ter minolog\u00eda y fraseolog\u00eda muy compleja, multitud de negaciones y formas subjetivas, entre otros rasgos (De Miguel, 2000; Alcaraz, Hugues y G\u00f3mez, 2014). Por e sta raz\u00f3n , en l os \u00faltim os a\u00f1os se h an elaborado gu\u00edas y manuales para ayudar a redactar en lenguaje claro los textos que se dirigen a los ciudadanos. Algunos ejemplos son las publicaciones de la Comisi\u00f3n Europea (2015), Carretero et al. (2017), y Mont ol\u00edo y Tasc\u00f3n (2017) . Sin embargo, a pesar de estas merito rias aportaciones, son escasos los trabajos que establecen sinergias entre el lenguaje claro en espa\u00f1ol y la tecnolog\u00eda. En este contexto, el objetivo de la presente investigaci\u00f3n es desarrollar el primer redactor asistid o para el espa\u00f1ol que ayude al personal de la Administraci\u00f3n p\u00fablica a escribir en lenguaje claro los textos que dirige a la ciudadan\u00eda. Este redactor asistido se llama \"arText claro \", puede utilizarse grat uitamente y est\u00e1 disponible e n l\u00ednea desde la direcci\u00f3n: http://sistema -artext.com/ . El sistema integra diferentes herramientas de Procesamiento de Lenguaje Na tural (PLN), gracias a las cuales logra detectar en los textos escritos por los usuarios los rasgos ling\u00fc\u00edsticos que interfieren con las recomendaciones sobre lenguaje claro m\u00e1s habituales. Asimismo, ofrece al usuario informaci\u00f3n para hacer m\u00e1s claro y sen cillo su texto. Las recomendaciones que integra el sistema est\u00e1n relacionadas con tres niveles de la lengua: discursivo, morfosint\u00e1ctico y l\u00e9xico. En el apartado 2 se incluye un breve e stado la cuesti\u00f3n sobre herramientas que tienen que ver con la rev isi\u00f3n de textos, especialmente, en relaci\u00f3n con el lenguaje claro. En el apartado 3 se muestran las fases de la metodolog\u00eda de la investigaci\u00f3n . En el apartado 4 se detallan las funcionalida des y la implementaci\u00f3n del redactor asistido. En el apartado 5 se explica la evaluaci\u00f3n del sistema. Finalmente, en el apartado 6, se exponen las conclusiones y se plantean algunas l\u00edneas de trabajo futuro. 2 Estado de la cuest i\u00f3n Actualment e, existen herra mientas tecn ol\u00f3gica s que ayudan a revisar y corregir textos en espa\u00f1ol . Estas herramientas incluyen diferentes funcionalidades relacionadas con diversos niveles de la lengua . Estos niveles pueden ir desde el m\u00e1s simple, como el ortogr\u00e1fico, hasta el m\u00e1s co mplejo, como el discursivo o pragm\u00e1tico, pasando por el l\u00e9xico y el sint\u00e1ctico. A dem\u00e1s del cl\u00e1sico corrector d e los procesadores de textos como W ord y OpenOf fice, hay otros sistema s destacables que se han desarrollado en los \u00faltimos a\u00f1os, como, por ej emplo , LanguageTool , 2 OutWrite ,3 Stilus4 y Estilector .5 Sin embargo, ninguno de estos correctores e st\u00e1 dise\u00f1ado espec\u00edficamente para ayudar a redactar en lenguaje c laro. Para la l engua inglesa, s\u00ed existen algunos ejemplos muy recient es. Por e jemplo, los sistemas comerciales con demos gratuitas Hemingway Editor 6 y VisibleThread .7 Estos sistem as otorgan una puntuaci\u00f3n a la legibilidad o comprensibilidad del texto. Para asignar estas puntuaciones, tiene n en cuenta dife rentes cuestiones gramaticales y de estilo que hacen que los textos resulten m\u00e1s claros. Por ejemplo, recomienda n limitar el uso de los adverbios y de la voz pasiva; propone n alternativas m\u00e1s simples para algunas expresiones utilizadas en el texto; y se\u00f1alan las oraciones que resultan dif\u00edciles de leer para que el usuario las acorte o divida. Cada una de estas cuestiones se marca en el texto con un color diferente. En el \u00e1mbito de las tecnolog\u00edas de la lengua en espa\u00f1ol, hay a\u00fan mucho camino por recorrer en relaci\u00f3n con el lenguaje claro . Por ejemplo , es de destacar la herramienta en versi\u00f3n beta Clara,8 gratuita y en l\u00ednea, que permite realizar un test de claridad a textos en espa\u00f1ol, principalmente documentos administrativos y contratos de servicios. A partir de un texto escrito por el usuario, de un m \u00ednimo de 40 palabras y un m\u00e1ximo de 120, la herramienta ofrece un porcentaje global de claridad . Asimism o, indica un porcentaje espec\u00edfico de claridad para cada una de las m\u00e9tricas que incluye y ofrece propuesta s de mejora. La herramienta inclu ye nueve m\u00e9tricas de evaluaci\u00f3n (Torrijos y Oquendo, 2021: - 124): 2 https://www.langua getool.org 3 ra.comunicacionclara.com/ 40 Iria da Cunha M\u00e9trica uso de palabras f uera del diccionario. M\u00e9trica 2: uso de conectores discursivos. M\u00e9trica 3: uso de la puntuaci\u00f3n. M\u00e9trica 4: citas y referencias a leyes. M\u00e9trica 5: uso de la voz pasiva . M\u00e9trica 6: uso de nexos subordinados. M\u00e9trica 7: uso de tecnicismos financieros y administrativos . M\u00e9tr ica 8 : uso de palabras del ranking de las 1000 m\u00e1s comunes en espa\u00f1ol . M\u00e9trica 9: n\u00famero medio de palabras por fras e. No obsta nte, Clara no marca en el texto escrito por el usuario las cuestiones espec\u00edficas que interfieren con el lenguaje claro, ya que no es un redactor asistido ni un corrector, sino un sistema de medici \u00f3n de la claridad textual . 3 Metodolog\u00eda La metodolog\u00eda de esta investigaci\u00f3n incluye tres fases, que se detallan a continuaci\u00f3n: Fase 1 . B\u00fasqueda de fuentes bibliogr\u00e1ficas sobre leng uaje c laro en el \u00e1mbito administrativo en espa\u00f1ol . Para seleccionar las recomendaciones sobre lenguaje claro que integra el redactor asistido , partimos del t rabajo de Da Cunha y E scobar (2021) . En este estudio se analiz an las principales fuentes sobre lenguaje claro en el \u00e1m bito jur\u00eddico- administrativo en espa\u00f1ol peninsular (Vilches y Sarmiento, 2010; Ministerio de Justicia, 2011 2017; Carretero, 2019) y se cuantifican las recomendaciones que recoge n, para seleccionar las m\u00e1s frecuentes. A continuaci\u00f3n, se dividen las recomendaciones seleccionadas en funci\u00f3n de los tres niveles de la lengua mencionados en el apartado 1: Nivel discursivo . Ejemplo de recomendaci\u00f3n : \"Se recomienda redactar ora ciones cortas\". Nivel morfosint\u00e1ctico. Ejemplo de recomendaci\u00f3n : \"Se recomienda utilizar la voz activa en vez de la voz pasiva\". Nivel l \u00e9xico . Ejemplo de recomendaci\u00f3n : \"Se recomienda evitar los arca\u00edsmos \". Fase 2 . Dise\u00f1o e implementaci\u00f3n de l sistema . Fase 2a. Selecci\u00f3n de herramientas de PLN en abierto para la lengua espa\u00f1ola que permitan un procesamiento ling\u00fc\u00eds tico del texto escrito por el usuario, concretamente: Lematizaci\u00f3n An\u00e1lisis ise\u00f1o de algoritmos que detect en en el texto escrito por el usuario los rasgos ling\u00fc\u00edsticos que interfi eren con el lenguaje claro. Para ello se tienen en cuenta las recomendaciones seleccionadas en la Fase 1 y el resultado del procesamiento ling\u00fc\u00edstico del texto de la Fase 2a. Por ejemplo, en el caso de la recomendaci\u00f3n \"Se recomienda redactar oraciones cortas\", el algoritmo detecta tod as las oraciones del texto y contabiliza las palabras que incluye cada una . Si una oraci\u00f3n supera las 25 palabras, la subraya en amarillo en el texto escrito por el usuario y le ofrece la recomendaci\u00f3n correspondiente para ada ptarla a lenguaje claro. En el caso de la r ecomendaci\u00f3n \"Se recomienda utilizar la voz activa en vez de la voz pasiva\", el algoritmo marca en el texto del usuario los verbos en voz pasiva obtenidos gracias al analizador POS y le ofrece la recomendaci\u00f3n cor respondiente. Fase 2c. Reda cci\u00f3n de las recomendaciones sobre lenguaje claro ofrecidas al usuario . En cada recomendaci\u00f3 n se in cluye la siguiente informaci\u00f3n: T\u00edtulo de la recomendaci\u00f3n. Sugerencia para la adaptaci\u00f3n a lenguaje clar o. Ejemplo (en caso de que se considere neces ario para que el usuario entienda la recomendaci\u00f3n ). En el An exo 1 se detallan todas las recomendaciones que ofrece el sistema. Fase 2d. Implementaci\u00f3n del redactor asistido (los detalles t\u00e9cnicos se incluyen en el apartado 4). Fase 3. Evaluaci\u00f3n del sistema . Para evaluar el sistema, se compi la un corpus de textos del \u00e1mbito de la Administraci\u00f3n , con cretamente, resoluciones del BOAM (Bolet\u00edn Oficial del Ayuntamiento de Madrid) . Una persona con formaci\u00f3n en li ng\u00fc\u00edstica y experiencia en 41 Un redactor asistido para adaptar textos administrativos a lenguaje claro anotaci\u00f3n de corpus anota manualmente en cada texto los diferentes rasgos ling\u00fc\u00edsticos correspondientes a las rec omen dacion es que se quieren evaluar (detallados en el apartado 5). A continuaci\u00f3n, se aplic a el sistema sobre los textos del corpus para obtener autom\u00e1ticamente las recomendaciones sobre lenguaje claro. Finalmente, se calcula la precisi\u00f3n y cobertura de los resultados del sistema en contraposici\u00f3n con la anotaci\u00f3n manual. 4 Funcionalidades e implementaci\u00f3n del redactor asistido El sistema se desarroll\u00f3 en un entorn o Linux con un servidor Apache. T ambi\u00e9n se usaron distintos recursos en el back-end (Bash, Perl y PHP, c on un entorno de trabajo Laravel) y en el front -end (HTML, CSS, JavaScript, con AJAX y jQuery). El sistema est\u00e1 optimizado para utilizarse con el navegador Google Chrome. El redactor integra dos herramientas de PLN existentes para el espa\u00f1o l que perm iten procesar ling\u00fc\u00edsticamente el texto escrito por el usuario : El analizador morfosint\u00e1ctico de Freeling ( Atserias et al. , 2006), medi ante el cual se lematizan todas las unidades l\u00e9xicas del texto y se asigna una categor\u00eda gramatical a cada una de ellas. Este analizador permite detectar rasgos ling\u00fc\u00edsticos que son utilizados por los algoritmos del sistema en las recomendaciones que tienen que ver principalmen te con el nivel morfosint\u00e1ctico, como, por ejemplo, los verbos en voz pasiva, los gerundios, los partici pios, los verbos en futuro de subjuntivo, o los verbos en 1.\u00aa persona del singular y del plural . Un segmen tador discursivo ( Da Cun ha et al. , 2010, 2012b ), que permite dividir el texto en oraciones y, adem\u00e1s, en segmentos discursivos intraoracionales, a partir de la d efinici\u00f3n de Tofiloski et al. (2009, p.77): \" Discourse segmentation is the elemen or clauses in a comple x sentence, and from which discourse trees are constructed\". Este segmentador permite detectar los rasgos utilizados por los algoritmos en las recomend aciones relativas al niv el discursivo, como la segmentaci\u00f3n discursiva de las oraciones largas y la sugerencia de conectores alternativos. Adem\u00e1s de integrar est as do s herramien tas, el sistema incluye diversos algoritmos desarrollados en el marco de nuest ra investigaci\u00f3n. Estos algoritmos toman como entrada el texto procesado ling\u00fc\u00edsticamente por las dos herramientas de PLN mencionadas y detectan en el texto d el usuari o los rasgo s ling\u00fc\u00edsticos necesarios para poder ofrecer las recomendaciones asociadas a cada uno de ellos . Estos rasgos son: P\u00e1rrafos-oraci\u00f3n. P\u00e1rrafos largos, con un umbral de 135 palabras (teniendo en cuenta las fuentes recopiladas en la F ase 1 ). Oracio nes largas, con un umbral de 25 palabras (teniendo en cuenta las fuentes recopiladas en l a Fase 1 ). Conectores discursivos interoracion ales e interoracionales que evidencian ocho relaciones discursivas: ant\u00edtesis, causa, concesi\u00f3n, condici\u00f3n, contrast e, prop\u00f3sito, reformulaci\u00f3n y resumen (Da Cunha et al. , 2012a). Nominal i zaciones verbales. Concretamente, el algoritmo detecta los sustantiv os acabados en -ci\u00f3n (en singular y plural) que comienzan por min\u00fascula, excepto los incluidos en una lista de exclusi\u00f3n predefinida que integra t\u00e9rminos del \u00e1mbito de la Administraci\u00f3n, como \" licita ci\u00f3n\" y \"notificaci\u00f3n \" (Da Cunha , 2022). Unidades que expresan negaci\u00f3n de una lista predefinida , que incluye unidades como \" no\", \"ni\" y \" ninguno\". Unidades l\u00e9xicas que indican subjetividad, como ciertos adjetivos (ej. \"bueno\"), adverbios (ej. \"evidentemente\") y frases (ej. \"sin ninguna duda\"), extra\u00eddas de Otao la (1988). Siglas propias (Girald o, 2008) y sus correspondientes t\u00e9rminos desplegados. Para hacer la correlaci\u00f3n entre la sigla y su t\u00e9rmino desplegado, se tiene en cuenta que la letra inicial de las unidades l\u00e9xicas incluidas en el t \u00e9rmino (excepto las stopwords ) se correspondan, en el mismo orden, con las mismas letras que incluye la sigla. Ej. \"Plan de Emergencias Invernales 42 Iria da Cunha del Ayuntamiento de Madrid\" > \"PEIA M\". T\u00e9rminos dif\u00edciles de entender que tienen una variante sinon\u00edmica m\u00e1s sencilla de una lista predefinida (Da Cunha , 202 2). Por ejemplo, la varian te m\u00e1s s encilla del verbo \"a dverar\" es \"certificar\" y la variante m\u00e1s sencilla del sustantivo \"aquiescencia\" es \"consentimiento \". Expresiones dif\u00edciles de ent ender que tienen una var iante sinon\u00edmica m\u00e1s sencilla de una lista predefinida (Da Cunha , 2022). Por ejemplo, el latinismo \"ad va lorem \" tiene como variante en espa\u00f1 ol \"seg\u00fan en valor \" y la expresi\u00f3n arcaica \" a tenor de \" tiene como variante m\u00e1s clara \" seg\u00fan\". Palabras poco precisas de una lista predefi nida (Da Cunha, 2022), c omo \"cosa\", \"varios \", \"alguno\", \" muy\" y \"poco\". Expresiones redundantes de una lista predefinida (Da Cunha , 2022), como \"est\u00e1 claro que\" , \"mi op ini\u00f3n personal \" y \"como es bien sabido \". Palabras largas que tiene n una variante sinon\u00edm ica m\u00e1s breve de una lista predefinida (Da Cunha , 2022), como \"gratuitamente/g ratis\" y \"encomendar/encargar \". En total, el redactor incluye 22 recomendaciones sobre lenguaje claro . Como se ha indicado, e n el Anexo 1 se detallan todas ellas, divididas en funci\u00f3n de los tres niveles de la lengua mencionados en el apartado 3. En la Figura 1 se ofrece una captura de pantalla de \"arText claro \" en donde se mues tra la recomendaci\u00f3n sobre p\u00e1rrafos largos e n un texto del corpus de evaluaci\u00f3n. En relaci\u00f3n con la exportaci\u00f3n e importaci\u00f3n de documentos, por una cuesti\u00f3n de protecci\u00f3n de datos, se decidi\u00f3 que el sistema no guardase en su servidor los textos escritos por los usuarios. Para ello, existen varias opciones de exportaci\u00f3n de documentos en local: .doc, .pdf, .txt, .html, etc. Para poder importar un texto posteriormente en el redactor, debe utilizare un formato creado espec\u00edficamente para este sistema: .artext. Figura 1: Captura de pantalla de \"arText claro \" en donde se mues tra la recomendaci\u00f3n sobre p\u00e1rrafos largos en un texto del corpus de evaluaci\u00f3n . 5 Evaluaci\u00f3n Como se avanzaba en el apartado 3, una vez implementado el sistema, se llev\u00f3 a cabo una evaluaci\u00f3n data-driven utilizando un corpus formado por 10 resoluciones del BOAM publicadas en el a\u00f1o 2021, que en total suman 8.052 palabras. El texto m\u00e1s corto tiene 436 palabras y el texto m\u00e1s largo, 1398. En el Anexo 2 se recogen los t\u00edtulos de las resolu ciones empleadas. Para comparar los resultados del sistema con los resultados de la anotaci\u00f3n manual, se calcul \u00f3 la precisi\u00f3n y cobertura de los rasgos 43 Un redactor asistido para adaptar textos administrativos a lenguaje claro ling\u00fc\u00edsticos anotados en los textos del corpus . Los rasgos anotados se incluyen en la Tabla 1. Nivel d e Rasgos anotados Discursivo a1. P\u00e1rrafos -oraci\u00f3n a2. P\u00e1rrafos lar gos a3. P\u00e1rrafos que no comienzan por un conector discursivo a4. Oraciones largas a5. Oraciones largas que pueden dividirse en segmentos discursivos a6. Conectores discursi vos que aparecen 3 veces o m\u00e1s a7. Listas Morfo- sint\u00e1ctico b1. Participios b4. Verbos en futuro de subjuntivo b5. Verbos en 1 .\u00aa persona del plural y del singular b6. Nom inalizaciones verbales b7. Unidades que expresan negaci\u00f3n L\u00e9xico c1. Unidades que expresan subjetividad c2. Siglas que no aparecen con su correspondiente t\u00e9rmino desplegado la 1.\u00aa vez que aparecen en el texto c3. T\u00e9rminos desplegados para los que se introduj o su sigla previamente en el texto c4. T\u00e9rminos dif\u00edciles de e ntender que tienen una variante sinon\u00edmica m\u00e1s sencilla c5. Expresiones dif\u00edciles de entender que tienen una variante m\u00e1s sencilla c6. Palabras poco precisas c7. Expresiones redundantes c8. Palabras largas que tienen una variante sinon\u00edmica m\u00e1s bre ve Tabla 1: Rasgos ling\u00fc\u00edsticos anotados manualmente en el corpus de evaluaci\u00f3n. Los resultados de la evaluaci\u00f3n de cada recomendaci\u00f3n se muestran en la Tabla 2 (\"ID\" se refiere al identificador de la recomendaci\u00f3n). ID Preci si\u00f3n Cobertura a1 0,99 0,74 a2 0,7 0,8 a3 0,84 0,71 a4 1 0,7 a5 1 0,89 a6 1 1 0,17 1 b6 1 1 b7 1 1 c1 Rasgo sin ocurrencias en el corpus c2 0,6 1 c3 1 1 c4 1 1 c5 1 1 c6 1 1 c7 Rasgo sin ocurrencias en el corpu s c8 1 1 Tabla 2: Resultados de la evaluaci\u00f3n del sistema. Como puede apreciarse , los resultados obtenidos son, en general , positivos para la mayor parte de las recomendaciones evaluadas. Destaca especialmente que el sistema obtie ne la m\u00e1xima precisi\u00f3n y cobertura en relaci\u00f3n con la detecci\u00f3n de 10 ra sgos: los conectores que aparecen m\u00e1s de tr es veces en el texto, los gerundios, los verbos en futuro de subj untivo, las nominaliza ciones verbales, las unidades que expresan negaci \u00f3n, los t\u00e9rminos desplegado s para los que se in trodujo su sigla previamente en el texto , los t\u00e9rminos dif\u00edciles de entender que tienen una variante sinon\u00edmica m\u00e1s sencilla , las expresiones dif\u00edciles de enten der que tienen una variante m\u00e1s sencilla y las palabras poco precisas. En cuanto a las recomendaciones relacio nadas con los p\u00e1rrafos ( a1, a2, a3), tambi\u00e9n se o btienen resultados positivos , aunque bajan ligeramente. Esto se debe, principalmente , a signos de puntuaci\u00f3n que interfieren en la segmentaci\u00f3n oracional , lo cual tiene consecuencias en la detecci\u00f3n correcta de p\u00e1rrafos: - Citas a art\u00edculos y leyes. Ej. \" los art\u00edculos 8.1 y 46.1 de la Ley\". - Elementos numerados con puntuaci \u00f3n Ej. \"1.\", \"2. \". - Enlaces web \"en la intranet /extranet municipal ayre (https://ayre.madrid.es ) y en la web https://jubilacion.madrid.es\". En cuanto a las recomend aciones relacionadas con la detecci\u00f3n de o raciones largas y segmentaci\u00f3n discusiva (a4, a5), la precisi\u00f3n es muy alta , pero en cambio baja ligeramente la cobertura. El motivo es que en este tipo de textos administrativo s en ocasiones hay oraciones que acaban con una coma o directamente sin ning\u00fan signo de puntuaci\u00f3n. 44 Iria da Cunha Por tanto, el sistema no logra recuperarlas. Por ejemp lo: (1) \"En su virtud, de conformidad con el Acuerdo de 27 de junio de 2019 [...] la competencia para la ejecuci\u00f3n de los planes y programas de formaci\u00f3n de los empleados y directivos del Ayuntami ento de Madr id,\" (2) \"En virtud de las facultades que me han sido conferidas por [..], esta Gerencia\" En cuanto a la detecci\u00f3n de ra sgos morfosint\u00e1cticos, los que no a lcanzan la m\u00e1xima precisi\u00f3n y cobertura son los siguientes: Verbos en voz pasiva (b1). En este caso, los errores en la cobertu ra (0,67) provienen del procesamiento ling\u00fc\u00edstico con Freeling. Por ejemplo , no se detectan las f ormas \"hubiera sido cesado \" o \"han sido conferidas\". Partici pios (b3). En e sta ocasi\u00f3n el problema es de precisi\u00f3n ( 0,86) y se debe a la desambiguaci\u00f3n de Free ling. Por ejemplo, se detecta \"propuesta\" y \"puesto\" como participio s cuando en el texto tiene n funci\u00f3n de sustanti vo (\" la propue sta\", \"el puesto de trabajo \"). Verbos en 1.\u00aa persona del plural y del singular (b5) . Este ha sido el rasg o que ha obtenido peores resultados en la evaluaci\u00f3n , con un 0,17 de pre cisi\u00f3n , debido tambi\u00e9n a problemas en la desambiguaci\u00f3n . Por ejemp lo, se detectan como 1.\u00aa persona del si ngular las formas \"sea\" y \" haga \", cuando en real idad en el texto so n formas de 3\u00aa per sona si ngula r (\"sea esta accidental o intencio nada \", \"cuando la previsi\u00f3n meteorol\u00f3gica haga previsible \"). En relaci\u00f3n con el nivel l\u00e9xico, como se ha visto, se obtiene n muy buenos resultados. \u00danicamente baja la precisi\u00f3n (0,6) en la detecci\u00f3n de siglas que no aparecen con su correspondiente t\u00e9rmino desplegado la primera vez que aparecen en el texto (c2). El mo tivo principal es que en estos documento s suele haber n\u00fameros roma nos (ej. \"III\" , \"IV\") y el sistema los marc a err\u00f3neamente como siglas. Tamb i\u00e9n se\u00f1ala otras secuen cias de letras en may\u00fa scula (como los acr\u00f3nimos ) que s\u00ed aparecen con su t\u00e9rmino desplegado y que, por tanto , no ser\u00eda pertinente marcar en el t exto del usuario . Ej. \"Plan Territorial Superior de la Comunidad de Madrid ( PLATERCAM )\". Finalm ente, como se ob serva en la Tabla 2, hay dos recomendaciones del nivel l\u00e9xico que no se han podido evaluar (c1 y c 7), porque no se han det ectado en el corpus uni dades que expresan subjetividad ni e xpresiones redundantes . 6 Conclusione s y l\u00edneas de traba jo futuro Como se ha vi sto en este trabajo, el lenguaje claro es un tema de investigaci\u00f3n en el que a\u00fan queda mucho por explorar, especialmente desde el punto de vist a del PLN. El objetivo de este trabajo ha sido desarrollar el primer redactor asistido para el espa\u00f1ol para escribir textos administrativos en lenguaje claro. La herramienta desarrollada tiene un gran potencial de aplicaci\u00f3n en las diferentes dependencias de la Administraci\u00f3n p\u00fablica, como ayuntamientos, diputaciones, consejer\u00edas, ministerios, etc. Los empleados p\u00fablicos dispondr\u00e1n, as\u00ed, de una herramienta tecnol\u00f3gica que les ayudar\u00e1 a revisar sus textos y adaptarlos al lenguaje claro. La evaluaci\u00f3n de \" arText claro \" ofrece buenos resultados, aunque a\u00fan quedan cuestiones que se pueden mejorar, c omo la precisi\u00f3n en la detecci\u00f3n de siglas, o las interferencias con l os signos de puntuaci\u00f3n que provocan errores en la detecci\u00f3n de p\u00e1rrafos y oraciones largas. Tambi\u00e9n ser\u00eda interesante ampliar el corpus de evaluaci\u00f3n con m\u00e1s textos anotados manualmente , de otros g\u00e9neros textuales del \u00e1mbito admin istrativo, con el objetivo de validar los resultados obtenidos en esta investiga ci\u00f3n. Con r especto a la metodolog\u00eda, una posible l\u00ednea de trabajo futuro ser\u00eda la aplicaci\u00f3n de estrategias de aprendizaje autom\u00e1t ico. Este enfoque ya es t\u00e1 siendo utilizado en algunas investigaciones, como es el caso del sistema de medici\u00f3n de la claridad textual Clara (Torrijos y Oque ndo, 2021) , mencionado en el apartado 2. La principal dificultad de este enfoque , sin embargo, es la necesidad de contar co n corpus muy extensos de textos originales y sus correspondientes textos clari ficados. Otra de nuestras l\u00edneas de investigaci\u00f3n ser\u00e1 llevar a cabo estudios de evaluaci\u00f3n de la percepci\u00f3n de la claridad y de la comprensi\u00f3n de los textos escritos con la herr amienta por parte de l os destinatarios. Finalmente, nuestro 45 Un redactor asistido para adaptar textos administrativos a lenguaje claro objetivo es implementar el sistema en las dependencias de la Administr aci\u00f3n p\u00fablica espa\u00f1ola. Agradecimientos Este trabajo se deriva del proyecto de investigaci\u00f3n titulado \" Tecnolog\u00edas de la Informaci\u00f3n y la Comunicaci\u00f3n para la e- Administraci\u00f3n: hacia la mejora de la comunicaci\u00f3n entre Administraci\u00f3n y ciudadan\u00eda a trav\u00e9s del lenguaje claro (TIC - eADMIN)\", financiado por el Ministerio de Ciencia, Innovaci\u00f3n e Universidades en la convocatoria 2018 de Proyectos I+D del Subprograma Estatal de Generaci\u00f3n de Conocimiento (referencia PGC2018-099694-A-I00), y desarrollado en el Departamento de Filolog\u00edas Extranjeras y sus Ling\u00fc\u00edsticas de la Facultad de Filolog\u00eda de la Universidad Nacional de Educaci\u00f3n a Distancia (UNED) , en el marco del g rupo de investigaci\u00f3n ACTUALing y en colaboraci\u00f3n con el grupo IULATERM (IULA-UPF). Bibliograf\u00eda Alcaraz, E. , B. Hugue s, y A. G\u00f3mez. 2014. El espa\u00f1ol jur\u00eddico. 3.\u00aa edici\u00f3n. Ariel , Barcelona. Atserias, J. , B. Casas, E. Co melles, M. Gonz\u00e1lez, Ll. Padr\u00f3, y M. Padr\u00f3 . 2006 . FreeLing NLP library . En LREC 2006 Proceedings. 5th Edition of the International Conference on Language Resources and Evaluation , p\u00e1ginas 48-55, European Language Resources Association (Par\u00eds). Da Cunha, I. (Ed.). 2022 . Lenguaje claro y tecnolog\u00eda en la Administraci\u00f3n . Granada, Comares. En prensa . Da Cunha, I . y M. \u00c1 . Escobar . 2021 . Recomendaciones sobre lenguaje claro en espa\u00f1ol en el \u00e1mbito jur\u00eddico - admin istrativo: an\u00e1lisis y clasificaci\u00f3n . Pragmaling\u00fc\u00edstica Moreno, M. T. Cabr\u00e9, y G. Sierra . 2012 a. A Symbolic Approach for Automatic Detection of urse sh. Lecture Notes in E. SanJuan Sys tems with Castell\u00f3n . 2010. DiSeg: Un segmentador discursivo autom\u00e1tico para el espa\u00f1ol . Procesamiento del Lenguaje Natural , 45:145-152. Bay\u00e9s, M. 2021. An\u00e1lisis del impacto de una selecci\u00f3n de (meta)indicaciones de redacci\u00f3n clara en la percepci\u00f3n de claridad de un documento adminis trativo: es tudio de caso. Tesis doctoral , Universitat de Barcelona. Carretero, C. 2019. Comunicaci\u00f3n para juristas . Tirant lo Blanch , Valencia. Carretero, C. , y J. C. Fuentes. 2019 . La claridad del lenguaje jur\u00eddico . Revista del Ministerio Fiscal , 8:7-40. Carrete ro, C. , J. M. P\u00e9rez, L. Lanne -Lenne , y G. de los Reyes. 2017. Lenguaje Claro. Comprender y hacernos entender. Instituto de Lectura F\u00e1cil y Clarity, Se villa, Madrid . Cassany , D. 2005 . Pla in Language in Spain . Clarity , 53:41-44. Comisi\u00f3n Europea. 2015. C\u00f3mo escribir con claridad. Oficina de Publicaciones de la Uni\u00f3n Europea , Luxemburgo. De Miguel, E. 2000. El texto jur\u00eddico- admini strativo: an\u00e1lisis de un a orden ministerial. C\u00edrculo de ling\u00fc\u00edstica aplicada al a comunicaci\u00f3n, 4: e n l\u00ednea. Disponible en: https://webs.ucm.es/info/circulo/no4/demiguel.htm Giraldo, J. J. 2008. An\u00e1lisis y descripci\u00f3n de las siglas en el discurso especializado de genoma humano y medio ambiente . Tesis doctoral . Universitat Pompeu Fabra, Institut de Ling\u00fc\u00edstica Aplicada (IULA) , Barcelona. Jim\u00e9nez Y\u00e1\u00f1ez, R. M. 2016. Escribir bien es de justicia . Aranzadi , Cizur Menor . Ministerio de Justicia . 2011. Informe de la Comisi\u00f3n de modernizaci\u00f3n del lenguaje jur\u00eddico . Ministerio de Justicia , Madrid . En l\u00ednea. 46 Iria da Cunha Montol\u00edo, E. 2012. La modernizaci\u00f3n del discurso jur\u00eddico espa\u00f1ol impulsada por el Ministerio de Justicia. Presentaci\u00f3n y principales aportacio nes del Informe sobre el lenguaje escrito . Revista de Llengua i Dret, 57:95-121. Montol\u00edo, E. Tasc\u00f3n . 2020 . El derecho a entender: la comunicaci\u00f3n clara, la mejor defensa de la ciudadan\u00eda. La Catarata, Madrid. Montol\u00edo, E. y M. T asc\u00f3n . 2017. Comunicac i\u00f3n Clara. Gu\u00eda Pr\u00e1ctica . Ayuntamiento de Madrid, Madrid . Otaola, C. 1988. La modalidad (con especial referencia a la lengua espa\u00f1ola) . Revista de Filolog\u00eda Espa\u00f1ola , 68(1) :97-117. Tofiloski, M. , J. Brooke, A syntactic and lexical -based discourse for Linguistics ). Torrijos , C. y S. Oque ndo. 2021. \u00a1Hola! Soy clara y mido la claridad de tu texto \" Archiletras Ci ent\u00edfica , Vol. V I:119-133. Vilches, F. y Sarmiento. . Manual de lenguaje Jur\u00eddico-Administrativo . Dykinson, Madrid . A Anexo 1: Recomendaciones que ofrece \"arText cl aro\" a) Recomendaciones del nivel discursiv o a1. T\u00edtulo de la recome ndaci\u00f3n: Revisi\u00f3n de p\u00e1rrafos -oraci\u00f3n . Texto de la recomendaci\u00f3n: Parece que los p\u00e1rrafos marcados en el texto solo incluyen una oraci\u00f3n. Ten en cuenta que suele recomendarse que cada p\u00e1rrafo incluya al menos dos oraciones. a2. T \u00edtulo de la recomendaci\u00f3n: Revisi\u00f3n de p\u00e1rrafos largos . Texto de la recomendaci\u00f3n: Parece q ue los p\u00e1rrafos marcados en el texto son bastante largos. Te recomendamos que los dividas en otros m\u00e1s cortos. Recuerda que cada p\u00e1rrafo debe tratar un tema diferent e. a3. T\u00edtulo de la recom endaci\u00f3n: Introducci\u00f3n de conectores al inicio de p\u00e1rrafos . Texto de la recomendaci\u00f3n: Parece que los p\u00e1rrafos marcados en el texto no comienzan con una marca expl\u00edcita que los relacione con su p\u00e1rrafo anterior. Te recomendamos que enlaces los diferentes p\u00e1rrafos a trav\u00e9s de c onectores discursivos. Haz clic en cada acc i\u00f3n para ver sugerencias de conectores que pueden servirte de ayuda para introducir p\u00e1rrafos: Introducir un tema nuevo Marcar un orden Distinguir Seguir el mismo te ma Enfatizar y reformular Detallar Resumir Termi nar Indicar causa Indicar consecuencia Indicar oposici\u00f3n Indicar objeci\u00f3n Mostrar elementos en forma de lista a4. T\u00edtulo de la recomendaci\u00f3n: Revisi\u00f3n de oraciones largas . Texto de la recomendaci\u00f3n: Las orac iones marcadas son muy lar gas. Te recomendamos que las revises. Por ejemplo, podr\u00edas dividi r la oraci\u00f3n en otras m\u00e1s cortas o eliminar la informaci\u00f3n poco relevante. a5. T\u00edtulo de la recomendaci\u00f3n: Divisi\u00f3n de oraciones largas . Texto de la recomendaci\u00f3n: Parece que las oraciones marcadas podr\u00edan dividi rse en otras m\u00e1s cortas. Te recomendamos qu e lo hagas. Haz clic en cada oraci\u00f3n para ver d\u00f3nde podr\u00edas segmentarla. Si decides dividir la oraci\u00f3n en otras m\u00e1s cortas, te recomendamos que utilices conectores. Haz clic en las unidades m arcadas en rojo en el texto para ver sugerencias de conectores al ternativos. a6. T\u00edtulo de la recomendaci\u00f3n: Variaci\u00f3n de conectores . Texto de la recomendaci\u00f3n: Los conectores de la lista sig uiente se repiten varias veces en el t exto. Haz clic en cada con ector para ver sugeren cias de conectores alternativos. a7. T\u00edtul o de la recomendaci\u00f3n: Inclusi\u00f3n de listas . Texto de la recomendaci\u00f3n: Parece que no has incluido ninguna lista en tu texto utilizando las opciones disponibles en la barra superior de herrami entas (numeraci\u00f3n o vi\u00f1etas). Recuerda que las listas, si est\u00e1n b ien construidas, son muy eficaces para transmitir informaci \u00f3n de manera clara. Te recomendamos que a\u00f1adas alguna lista a tu tex to. Ejemplo: Para presentar su solicit ud, debe enviar cuatro documentos: 1. El formulario de solicitud cumplimentado. 2. Una fotocopia de su DNI. 47 Un redactor asistido para adaptar textos administrativos a lenguaje claro 3. Su acta de nacimiento. 4. Su certificado de empadronamiento. b) Recomendaciones del nivel morfosint\u00e1ctico b1. T\u00edtulo de la recomendaci\u00f3n: Uso de la voz pasiva. Texto de la recomenda ci\u00f3n: Las unidades marcadas parecen verbos en voz pasiva. Ten en cuenta que en este tipo de textos es m\u00e1s habitual la voz ac tiva. Ejemplo: La oraci\u00f3n \"El suministro que se contrata fue aprobado por este organismo\" podr\u00eda sustituir se por \"Este organismo aprob\u00f3 el suministro que se contrata\". b2. T\u00edtulo de la recomendaci \u00f3n: Revisi\u00f3n de gerundios . Texto de la recomendaci\u00f3n: Las u nidades marcadas en el texto p arecen verbos en gerundio. Te recomendamos que evites estas formas verbales, ya que pueden causar ambi g\u00fcedades, alargar dema siado la oraci\u00f3n y hacer dif\u00edcil la comprensi\u00f3n. Ejemplo: En la siguiente oraci\u00f3n, no queda claro qui\u00e9 n es el sujeto del gerundio: \"El aspirante a la plaza dio su documentaci\u00f3n al empleado del registro solicitando una copia.\" Si el su jeto es el aspirante, ser\u00eda m\u00e1s conveniente decir: \"El aspirante a la plaza dio su documentaci\u00f3n al empleado del registro, a quien solicit\u00f3 una copia.\" En cambio, si el sujeto es el empleado del registro, ser\u00eda m\u00e1s adecuado decir, por ejemplo: \"El aspirante a la plaza dio su documentaci\u00f3n al empleado del registro y solicit\u00f3 una copia.\" b3. T\u00edtulo de la recomendaci\u00f3n: Revisi\u00f3n de participios . Texto de la r ecomendaci\u00f3n: Las unidades marcadas en el texto parecen verbos en participio. A no ser que sea impresci ndible utilizarlos, te recomendamos que evites estas formas verba les, ya que pueden causar ambig\u00fcedades, alargar demasiado l a oraci\u00f3n y hacer dif\u00edcil la comprensi\u00f3n. Ejemplos: En las siguientes oraciones, no queda claro qui\u00e9n es el sujeto del participio: \"Enviada la resoluci\u00f3n , el aspirante tiene diez d\u00edas para reclama r.\" \"Presentado el documento, se cerr\u00f3 el expediente.\" Podr \u00eda especificarse de la siguiente manera, por ejemplo: \"Una vez el comit\u00e9 evaluador env\u00ede la resoluci\u00f3n, el aspirante tiene diez d\u00eda s para reclamar.\" \"Cua ndo el solicitante present\u00f3 el documento, se cerr\u00f3 el expediente\". b4. T\u00edtulo de la recomendaci\u00f3n: Eliminaci\u00f3n de formas verb ales arcaicas . Texto de la recomendaci\u00f3n: Las formas verbales marcadas en el text o est\u00e1n en desuso y son innecesarias. Te recomendamos que las evites y que utilices en su lug ar otras formas m\u00e1s sencillas y actuales. Ejemplos: En vez de \"si resultare \"si podr\u00eda decirse \"si ario\" T\u00edtulo de la reco mendaci\u00f3n: Sistematici dad en el uso de verbos en 1.\u00aa persona. Texto de la recomendaci\u00f3n: Las unidades marcadas en verde parecen ver bos en 1.\u00aa persona del singular y las marcadas en azul parecen ver bos en 1.\u00aa persona del plural. Si estas formas verbales se ref ieren al emisor del te xto, te recomendamos que optes por el singular o el plural para que el texto sea sistem\u00e1tico. b6. T\u00edtulo de la recomendaci\u00f3n: Revisi\u00f3n de nominalizaciones verbales . Texto de la recomendaci\u00f3n: Parece que algunas de las palabras marcadas en el texto son nom bres derivados de verbos y, por tanto, pueden resultar dif\u00edciles de entender. A no ser que sean t\u00e9rminos de este \u00e1mbito que no s e puedan cambiar, te recomendamos que las su stituyas por sus correspondientes verbos para hacer el texto m \u00e1s claro y din\u00e1mico. Ejemplos: La oraci\u00f3n \"Se llevar\u00e1 a cabo una evaluaci\u00f3n de los riesgos\" podr\u00eda sustituirse por \"Se evaluar\u00e1n los riesgos\" . La orac i\u00f3n \"Se efectu\u00f3 la instalaci\u00f3n de los progra mas inform\u00e1ticos\" podr\u00eda sustituirse por \"Se instalaron inform\u00e1ticos\". b7. T\u00edtulo de la recomendaci\u00f3n: Reformulaci\u00f3n de ideas expresadas en negativo . Texto de la recomendaci\u00f3n : Parece que las palab ras marcadas en el texto indican negaci\u00f3n. T e recomendamos que optes por la formulaci\u00f3n afirmativa de tus ideas en caso de ser posible, puesto que as\u00ed se favorece la legibilidad y la interpretaci\u00f3n del mensaje. Ejemplos: La oraci\u00f3n \"N o es infrecuente que s e acepten nuevos proyectos\" podr\u00eda formulars e en positivo de la siguiente manera: \"Es habitual que se acep ten nuevos proyectos\". 48 Iria da Cunha c) Recomendaciones del nivel l\u00e9xico c1. T\u00edtulo de la recomendaci\u00f3n: Uso de i ndicadores de subjetivida d. Texto de la recomen daci\u00f3n: Las unidades marcadas podr\u00edan indicar subjetividad. Ten en cuenta que este tipo de textos suelen ser objetivos. Te recomendamos que revises estas unidades para confirmar que son adecuadas en tu texto. c2. T\u00edtulo de la recomen daci\u00f3n: Introducci\u00f3n de siglas . Texto de la recomendaci\u00f3n: Las unidades marcadas parecen siglas. Si es as\u00ed, ten en cuenta que la primera vez que se utiliza una sigla en un texto suele ir acompa\u00f1ada del t\u00e9rmino desplegado. Ejemplos: Universidad Nacional de Educaci\u00f3n a Distancia (UNED) EPOC (enfermedad pulmonar obstructiva cr\u00f3nica) c3. T\u00edtulo de la recomendaci\u00f3n: Sistem aticidad en el uso de siglas . Texto de la recomendaci\u00f3n: Las unidades marcadas parecen el t\u00e9rmino desplegado de siglas que utilizas en el texto. Si es as\u00ed, ten en cuenta que, una vez se introduce una sigla en un texto, se suele seguir utilizando la sigla y no el t\u00e9rmino desplegado. c4. T\u00edtulo de la recomendaci\u00f3n: Utilizaci\u00f3n de t\u00e9rminos m\u00e1s transparentes. Texto de la r ecomendaci\u00f3n: Los t\u00e9rmino s de la lista siguient e aparecen en tu texto y pueden resultar dif\u00edc iles de entender. Te recomendamos que los sustituyas por otros m\u00e1s transparentes o que los aclares entre par\u00e9ntesis la primera vez que aparecen. Haz clic en cada u no de ellos para ver sugerencias de t\u00e9rminos al ternativos m\u00e1s claros. c5. T\u00edtulo de la recom endaci\u00f3n: Sustituci\u00f3n de expresiones dif\u00edciles de entender . Texto de la recomendaci\u00f3n: Las expresiones de la lista siguiente aparecen en tu texto y pueden resultar dif\u00edciles de entender, p or ser formas arcaicas , en desuso o latinismos. Te recomendamos que las sustituyas por otras m\u00e1s claras o, si no es posible, que l as expliques en el texto la primera vez que aparecen (entre par\u00e9ntesis o en una nota, por ejemplo). Haz clic en cada una de el las para ver sugerenci as de variantes alternativas m\u00e1s comprensibles o una explicaci\u00f3n de su significado. c6. T\u00edtulo de la recome ndaci\u00f3n: Sustituci\u00f3n de palabras poco precisas . Texto de la recomendaci\u00f3n: Parece que las palabras marcadas en el texto son poco precisas. Te recome ndamos que las elimines o las sustituyas por otras palabras m\u00e1s precisas. Ejemplos: En vez de \"Se trataron a lgunos temas en la reuni\u00f3n\", ser\u00eda m\u00e1s preciso decir \"Se trataron cuatro temas en la reuni\u00f3n\". En vez de \"Dijeron que hab\u00eda que hacer una reuni\u00f3n\", ser\u00eda m\u00e1s preciso decir \"Dijeron que hab\u00eda que convocar una reuni\u00f3n\". c7. T\u00edtulo de la recomendaci\u00f3n: Elimi naci\u00f3n de expresiones redundantes . Texto de la recomendaci\u00f3n: Las expresiones marcadas en el texto in cluyen informaci\u00f3n redundante. Te recomendamos que las elimines para hacer el texto m\u00e1s breve . c8. T\u00edtulo de la recomendaci\u00f3n: Revisi\u00f3n de palabras largas . Texto de la recomendaci\u00f3n: Las palabras de la lista siguiente aparecen en tu texto y tienen variant es alternativas m\u00e1s corta s. Te recomendamos que las utilices para favorecer la legibilidad. Haz clic en cada palabra para ver cu\u00e1l es su alternativa m\u00e1s co rta. B Anexo 2: Resoluciones del BOAM incluidas en el corpus de evaluaci\u00f3n 1. BOAM Resoluci\u00f3n 3120. 49 Un redactor asistido para adaptar textos administrativos a lenguaje claro 50 Exploiting user-frequency information for mining regionalisms in Argentinian Spanish from Twitter Explotando informaci\u0013 on de frecuencia de usuarios para minar regionalismos del espa~ nol de Argentina en Twitter Juan Manuel P\u0013 erez,1;2Dami\u0013 an E. Aleman,1 Santiago N. Kalinowski,3Agust\u0013 \u0010n Gravano4;2 Buenos Aires, \u0010 cas y T\u0013 ecnicas (CONICET), Argentina 3Academia Argentina de Letras, Buenos Aires, Argentina 4Universidad Torcuato Di Tella, Buenos Aires, Argentina heavily depending on the expertise and intuition of the surveyor. The emergence of social media and microblogging services has produced an of regionalisms depended mostly on word frequencies. In this work, we present a novel metric based on Information Theory that incorporates user frequency. We tested this metric on a corpus of Argentinian Spanish tweets in two ways: via man- ual the of the users that use a word is Entropy. Resumen: La tarea de detectar regionalismos (expresiones o palabras utilizadas en determinadas regiones) se ha basado tradicionalmente en el uso de cuestionarios y encuestas, dependiendo en gran medida de la pericia e intuici\u0013 on del investigador. El surgimiento de las redes sociales y los servicios de microblogging ha producido una riqueza de contenido sin precedentes (principalmente textos informales gener- ados por usuarios), lo cual ha abierto nuevas oportunidades para el estudio de la variaci\u0013 on ling\u007f u\u0013 \u0010stica. Estudios previos de la detecci\u0013 on autom\u0013 atica de regionalismos dependen sobre todo de la frecuencia de palabras. En este trabajo presentamos una m\u0013 etrica novedosa basada en la Teor\u0013 \u0010a de la Informaci\u0013 on, que incorpora la frecuencia de usuarios. Ponemos a prueba esta m\u0013 etrica en un corpus de Tweets en espa~ nol argentino de dos maneras: a trav\u0013 es de la anotaci\u0013 on manual de la relevancia de los t\u0013 erminos recuperados, y tambi\u0013 en us\u0013 geolocalizaci\u0013 on casos, nuestra m\u0013 etrica super\u0013 o otras t\u0013 ecnicas basadas en la frecuencia de palabras, lo que sugiere que medir la cantidad de usuarios que usan una palabra es una caracter\u0013 \u0010stica in- formativa. Esta herramienta ha ayudado a lexic\u0013 ografos a descubrir varias palabras no registradas del espa~ nol argentino, as\u0013 \u0010 como signi cados Dialectolog\u0013 trop\u0013 \u0010a. Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 51-62 recibido aceptado 23-05-2022 ISSN 1135-5948. DOI 10.26342/2022-69-4 \u00a9 para Procesamiento del Lenguaje Natural1 Introduction Lexicography has been aided and enriched in the past 30 years by tools and resources from Computational Linguistics, mainly in the form of Rundell, 2008). Statistical analyses of corpora usually result in evidence to support the addition of a word to a dictionary, its re- moval, or its marking as dated or as unused or as regional, among decisions. In the process based on observation of di- alects, it is of paramount importance to es- tablish which words are likely shared by an entire linguistic community and which are used only by smaller groups. In the lat- ter case, word usage descriptions can pro t considerably from information as precise as possible, about geographical extension (re- gion, province, district, city, even neighbor- hood), registry (colloquial, neutral, formal), frequency (current, past or a combination of both depending on the chronological span of and on and expertise of linguists (Almeida and Vidal, 1995; Labov, Ash, and Boberg, 2005). The results of this methodology are of great value to lexicographers, who need evi- dence to support the addition of a word into a regional dictionary, as well as the indica- tion of where it is used. gathered with has et The emergence of social media and mi- croblogging services has produced opened valuable information about location of users. In this sense, social media texts have been used 2016) or to study the di usion of lexical change (Eisenstein et al., 2014), inter alia. problem closely related to (Eisenstein, 2014). A possible way to evaluate dialectological models is to use them in geolocation regionalisms can be seen as location- indicative words (Han, Cook, and Baldwin, 2012). num- ber of users producing them. Also, to our knowledge very little work has been per- formed in Spanish on these topics. In this work, we present an information- theoretic measure to detect regionalisms in social media texts, particularly on Twitter, and we test it against a dataset of tweets in Argentinian Spanish. Our contributions are twofold: a) we introduce a new metric based on Information Theory which can be seen as a mixture of TF-IDF and Informa- tion Gain; and b) we of users is a lexical and on the usage of words priori to be regional vari- These studies 1995). Even pa- pers that analyze data (Huang et al., 2016; the e orts needed to detect them. Two types of approaches exist for this problem: model-based approaches and metric-based approaches (Rahimi, Baldwin, and Cohn, 52 Juan Manuel P\u00e9rez, Dami\u00e1n E. Aleman, Santiago N. and regional variants (Eisenstein et al., 2010; Ahmed, Hong, and Smola, 2013). Typically, these are computationally expensive, which limits the of data that may be processed. Metric-based approaches compute statistics for each word or expression, and use them to create rankings (Cook, Han, and Bald- win, 2014; Chang et al., 2012; Jimenez et al., 2018; Monroe, Colaresi, and Quinn, compare our metrics to while dialectology text into regions (Eisenstein, 2014). Thus, a reasonable way of assessing the performance of a method for discover- ing regional words is to use it as a feature- selection method for a geolocation classi er, as proposed by Han, Cook, and Baldwin (2012). In the present work, we use provinces as our unit of study (see Section 3), but ner grained geolocation could be performed an adaptive et al., 2012). Rahimi, Cohn, and Baldwin (2017) pro- pose a di erent approach to this problem. They train a by analyzing proximities in the embedding space. Information Theory is the basis for many of these methods (Han, Cook, and Baldwin, 2012; Roller et al., 2012; Chang et al., 2012). Other of information theoretic measures include telling whether promoted by by analyzing its dispersion in time and in users (Cui et al., 2012; and Lerman, to user on Twitter sentiment analysis and opin- ion mining (Pak and Paroubek, 2010). The metrics discussed in the next section use this concept of measuring the entropy of the users of a particular word. 3 Materials The territory of Argentina is divided into 23 provinces and the autonomous city of Buenos Aires, with populations ranging from 127,000 (Tierra del Fuego Province) to 15 million (Buenos Aires Province), according to the 2010 National Census.2Provinces are further subdivided into departments, which in some cases are called partidos orcomunas. To gather our data, we rst collected infor- mation of all departments in Argentina from the 2010 National Census and conducted a lookup through the Twitter API for matching those departments. Even not very reliable (Hecht et al., 2011), given that we restrict our search to a xed number of department names, we observe that most of the potential noise is reduced. We used the Python library tweepy to interact with the Twitter Figure distributions user and tweet length. known the For this we decided to take into account only words occurring more than 40 times and users (these values were chosen empirically). This removes 1% of the total words and shrinks the vocabulary from 2.3 (right). 4 Method We can think of a regionalism as a usage concentration is higher in a speci c region. With this in mind, we aim to measure these disorders in word usage { or, more precisely, the entropy of words (Shan- non, 1948). In general, words with high entropy are more likely to be and be regarded as used evenly across the country. low-entropy are used with : l Nbe !2; : : : vocabulary. Ojrefers event that word wj occurred location ne the entropy as Hwords(!j) =\u0000NX i=1p(lijOj)\u0001logp(lijOj):(1) Note that this measure not take into account the actual frequency of words. For instance, if two words !1and!2occur only !1is much more frequent than !2, both still have the same entropy according to Equation 1. In a similar fashion to tf-idf and inspired by Montemurro and Zanette (2010) and Han, Cook, and Baldwin (2012), we de ne measure Iwords(!) for word !as follows: possible 1948), and p(!) is frequency of !in the corpus (0 \u0014 p(!)\u00141). In this way, Iwords(!) will be high for frequent words that accumulate in just a few locations. Another important aspect of a word is the amount of people that use it (Cui et al., 2012). Assuming we now sample Twitter users, let Ujbe the event a uses !j. Then p(lijUj) denotes the probability that the location of user li given the fact that s/he uses word users !in the corpus (0 \u0014q(!)\u00141). Note that will high for words mentioned by several users accumulate in locations. According Zipf's Law, the counts that is also true when users of words. So the p(!) and q(!) terms (2) problem words with high frequencies over- come low entropies. To alleviate this, we performed a normalization on the word frequency as follows. Let M!be the most frequent word, that is, M!= arg max !2W#!; (5) where # !denotes the total number of occur- rences of !in our dataset. Then, the Nor- 54 Juan Manuel P\u00e9rez, Dami\u00e1n E. Aleman, Santiago N. Kalinowski, Agust\u00edn Gravano malized log-frequency log(#M Words with er lit- tle in their values of nwords(!). We de Equations and (4) and arrive at the nal de nition of our Iwords(!) =nwords(!)(log( n)\u0000Hwords(!)) much more often in a certain region than in the rest of the country. We subsequently sort all words in our dataset relative Ranking and Ranking. The words that appear in the rst positions of a ranking are those with high values for the metric, and thus more likely to be regionalisms. 4.1 Lexicographic Validation With these rankings, a team of lexicogra- phers from Academia Argentina de Letras performed a linguistic of the rst qualitative analysis consisted in a de- tailed study, word by word, to determine if the word in question is part of the lexical repertoire of a in lexicography{ al- though many words in this class had metrics. toponyms were sary. The goal of identify not only words there with a di erent meaning. As a result of this process, every word in the top-1000 of each ranking was annotated with `1' if it had lexical relevance as a re- gionalism, `0' procedures 4.2 Feature Selection for Geolocation To assess the usefulness metrics, feature-selection method to space boosting the classi- er performance. approach to de- as information from tweets to predict a location (Zheng, Han, and Sun, 2018). But we empha- size that we are interested our dataset { 7,500 for training and 2,500 for testing. For reference, we compare our results to those obtained using (IGR) metric (Han, Cook, Bald- win, 2012; Cook, Han, and Baldwin, 2014): ifLis a variable denoting the loca- as user-frequency information for mining regionalisms in Argentinian Spanish from Twitter Rank Word User 1 ushuaia chivil 2 rioja ush 3 chivilcoy poec 4 bragado malpegue 5 viedma aijue 6 14 respect of a word (which we ab- breviate \\user frequencies\" for the sake of simplicity), in a similar way to Equation 4. As a baseline for our feature (in order) and then by Term-Frequency (in descending order). Summing up, ve feature selection the province { a fairly good esti- mate, since most of the population concen- trates around those cities. 5 kraka, sanagasta, wika refer to towns, cities and local clubs. Also, some words refer to gentilics rankings even share many words: User-Count and Word-Count have an overlap of 63% in thousand words. Figure 2 shows four scatter plots. A dot in these plots corre- sponds to an individual word in our cor- pus, and is placed along the horizontal axes according corresponding Ad- ditionally, each dot is colored according to the position of the word in one of our rank- ings using a chromatic scale, higher rank. For lighter color) tend to appear closer to the upper-left corner of the plot { that is, such words are more fre- 2d shows a very simi- lar thing, now with respect to the number of users that mention the words: words of users from fewer regions. These two the upper-left corner (words ranked in lighter but colors each word with respect to the Word-Count Ranking. Here we can observe a slight perturbation in the gradient: there are words far from the left-corner that have light colors. From this, we understand that there are words with high Huserandnuser. The perturbation in the words ap- high in the Word-Count Ranking (closer to the top-left corner, see Figure 2a) but low inUser-Count Ranking (darker color). 56 Juan Manuel P\u00e9rez, Dami\u00e1n E. Aleman, Santiago N. Kalinowski, Agust\u00edn Gravano (a) Color scale: Word-Count Ranking (b) Color scale: Word-Count (c) searched for words that have er- ences in logarithm of Word-Count Rank- erence between words ranked very high (e.g., between the word at position 10,000 and another in position 20,000) and ampli es the di erence when one of the ranks is low and the other is high. A close examina- tion of these words and their tweets showed that they were produced by bots (news and accounts, or accounts using tools to gain more followers) or in small niches of fans of some celebrity. From the top-100 words sorted by users than in words. Summing up, when word has a high User-Count Ranking, it also tends to have a high Word-Count Ranking. The reverse is not true, however, as words produced by a small number of words coming from agents, as already done in Cui et al. (2012).Word Word Rank User Rank rioja 2 2499 vto 27 28179 hoa 81 words with the largest gaps between log word rank and log user rank. 5.1 Lexicographic Validation The rst thousand words in the Word-Count analyzed by 21.9% re- gionalisms. Likewise, the rst thousand words in the 57 Exploiting user-frequency information mining regionalisms in from Lexical characterization is illustrated in Table 4, which displays a few examples of groups of regionalisms found thanks to this methodology. A special note is reserved for the group of indigenisms, where a number of words were found coming Quechua (ura). It is worth mentioning that the regions of the words derived from Guaran\u0013 \u0010 { spoken in Northeastern Argentina, Paraguay, Bolivia and Southwest of Brazil { coincide with the region delimited by Vidal de Battini tarefero Table 4: Examples found in the manual analysis. Each group corresponds to a subjective when train si er. axes represent the percent- axes the mean distance error in 3a in the case of 3b. LUF-IG obtains the best performance in the user geolocation task, and stabilizes in a plateau at bag of words (baseline) versus using the di er- ent feature selection methods with 5,000 top words. When comparing our metrics, we note that the ones based on a better frequency counterparts. This is more appar- ent in the case of LTF-IG and LUF-IG, but can also be It suc- cessfully removed from the top of the ranking words likely to come from automatic agents or from small niches of users, and a manual lexicographic validation word-frequency counterpart and IGR metrics from Han, Cook, and Baldwin (2012). This strongly suggests that measuring the disper- sion of users certain word is a very in- formative indicator { both in lexicographic what was already proposed in previous work to detect spam on Twitter (Cui et al., 2012). The proposed metric was developed using the top-5000 words. 58 Juan Manuel P\u00e9rez, Dami\u00e1n E. Aleman, Santiago N. Kalinowski, Agust\u00edn Gravano (a) Mean distance error for geolocation. percentage of the as to train a Multinomial Logistic and Figure b uses accuracy (more is better) This area of the lexicon is most elusive, since its impact on any printed medium arrives no- ticeably late { and in many cases it never reaches it at all. Colloquialisms are a class of words hardly found in any other media. Our best performing the Diccionario del Habla de los Argenti- nos(Academia Argentina de Letras, 2008), a fact that con rms the usefulness of both our metric and Twitter data in general for this task. An outstanding subgroup of words found in the analysis are those coming from theGuaranitic region, in Northeastern Ar- gentina. In particular, three words emblematic because it shows how this type of approach can help overcome the intrinsic limitations of doing regional lexicography. When lexicographers native to only one of the di erent dialects of the region included in a projected dictio- the probability of properly detecting and words of other dialects is slim or depends on mere chance. As the team of lex- icographers expressed when re- mained unknown. Instead of including them in the next edition of the dictionary that at- tempts to describe all regional lexical perpetuating a lexical vari- within provinces, we granularity. If a granularity were necessary the analysis, adaptive par- titioning used de Battini, 1964) indicates that most provinces do not have large dialectal vari- ations within them, this is something that would need to be explored and con rmed in future work. Also, these techniques be other those used in (Roller et al., 2012; Han, Cook, and Baldwin, 2012), to further con rm that they outper- form other feature selection methods. 7 Conclusions In developed compared two novel metrics useful based on tion Theory. Term Frequency-Information Gain, LTF-IG ) and the other on the user frequency of a word ( Log user frequency- Information Gain, LUF-IG ). These information-theoretic measures and clas- sicTF-IDF . We evaluated their performance in two ways. First, a team of lexicographers man- 59 Exploiting user-frequency information from Twitter ually assessed the presence of regionalisms in the rst thousand words ranked by each met- Second, also tested against metrics from previous works (Han, Cook, and Baldwin, 2012; Cook, Han, and Baldwin, 2014). In both evaluation types, metric built users of a word is very informative { perhaps even more than simple word frequency. This method has aided lexicographers in their task, allowing them to propose the ad- dition of a number of words into the Dic- cionario del Habla de los Argentinos . The work behind this particular dictionary relies on a collaborative e ort based on itself to avoiding most of this manual work, which, in and of itself, would already be a sizeable contribution. Since of the lexical repertoire of a community does not make its way across to published materials (which make most of the 300 millions words included to date in, for example, CORPES XXI (Real Academia Espa~ nola, 2013)), the possibility of creating lists of words that are likely to on actual utter- ances written in dictionaries. Even when a regional word is published, and then included in corpora, the task of appropriately isolat- ing it remains largely unchanged, given that the word has to be previously identi ed in or- der to then take advantage of the statistical information available. This work de nes Argentinian provinces as the regional units of analysis, but this could be changed in order to repeat the anal- ysis at di granularity levels. way, it might be possible to study intra- provincial dialectal di erences (e.g., at the department level, see Section 3), although the limited precision of the geolocation of Twit- ter users may complicate this task. its geographical variants. A further challenge triggered by this work allow to the validity of the dialectal regions of Argentina proposed by Vidal de Battini in 1964 (Vidal de Battini, 1964). Spa- tial as a feature se- lection method. Acknowledgments This work was funded in part by CONICET, Universidad de Buenos Aires, and Universi- dad Torcuato Di Tella. We thank Edgar Sued, and re- viewers for valuable suggestions. References Academia Argentina de Letras. 2008. Diccionario del habla de los argentinos . Emec\u0013 e Editores. Ahmed, A., L. Hong, and A. J. Smola. 2013. Hierarchical geographical modeling of user locations from social posts. In Pro- ceedings of the 22nd international confer- ence on World Wide Web, pages 25{36. ACM. Almeida, M. and C. Vidal. 1995. Variaci\u0013 on and M. Rundell. 2008. The Ox- ford guide to practical lexicography. Ox- ford University Press. Bird, S., E. Klein, and E. Loper. 2009. Natural language processing with Python: Analyzing text with the natural language toolkit. O'Reilly Media, Inc. Chang, H.-w., D. Lee, M. Eltaher, and J. Lee. 2012. @Phillies tweeting from Philly? Predicting Twitter user locations with spatial word usage. In Proceedings of the 2012 International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2012), pages 111{118. IEEE Computer Society. 60 Juan Manuel P\u00e9rez, Dami\u00e1n E. Aleman, Santiago N. Kalinowski, Agust\u00edn Gravano Cook, P., B. Han, and T. Baldwin. 2014. Statistical methods for identifying local dialectal terms from GPS-tagged docu- ments. Dictionaries: Journal of the Dictionary Society of North America , 35(35):248{271. Cui, A., M. Zhang, Y. Liu, S. Ma, and K. Zhang. 2012. Discover breaking events with popular hashtags in twitter. In Pro- ceedings of the 21st ACM International Conference on Information and Knowl- edge Management, CIKM 12, pages 1794{ 1798, New York, NY, USA. ACM. Eisenstein, J. 2014. Identifying regional di- alects in online social media. In School of Interactive Computing Faculty Publica- tions. Georgia Institute of Technology. Eisenstein, J., B. O'Connor, N. A. Smith, and E. P. Xing. 2010. A latent variable model for geographic lexical variation. In Proceedings of the 2010 conference on em- pirical methods in natural language pro- cessing, pages 1277{1287. Association for Computational Linguistics. Eisenstein, J., B. O'Connor, N. A. Smith, and E. P. Xing. 2014. Di usion of lex- ical change in PloS 9(11):e113114. lection in regional dialectology. American speech, 88(4):413{440. Han, B., P. Cook, and T. Baldwin. 2012. Ge- olocation prediction in social media Hecht, B., L. Hong, B. Suh, and E. H. Chi. 2011. Tweets from Justin Bieber's heart: the dynamics of the location eld in user pro les. In Proceedings of the SIGCHI conference on human factors in comput- ing systems, pages 237{246. ACM.Huang, Y., D. Guo, A. Kasako , 2016. Understanding US re- gional linguistic variation with Twitter analysis. Computers, Environment and Urban Systems , 59:244{255. Jimenez, S., G. Due~ nas, A. Gelbukh, C. A. Rodriguez-Diaz, and S. Mancera. 2018. Automatic Detection of Regional Words for Pan-Hispanic Spanish on Twitter. In Ibero-American Conference on Arti cial Intelligence , pages 404{416. M. Kalita. 2010. Syntac- tic normalization of Twitter messages. In International conference on natural lan- guage processing, Kharagpur, Kessler, in Irish In Proceedings of the seventh conference on European of the for Morgan Kaufmann Publishers Inc. Labov, W., S. Ash, and C. Boberg. 2005. The atlas of North American English: Phonetics, phonology and sound change . Walter de Gruyter. Monroe, B. L., M. P. Colaresi, and K. M. Quinn. 2008. Fightin'words: Lexical fea- ture selection and evaluation for political con ict. Polit- ical Analysis, 16(4):372{403. Montemurro, M. A. and D. H. Zanette. 2002. Entropic analysis of the role of in complex the quanti cation J., Heeringa, E. Van den Hout, P. Van der Kooi, S. Otten, W. Van de Vis, et al. 1996. Phonetic distance between Dutch dialects. pages 185{202. Pak, A. and P. Paroubek. 2010. Twitter as a corpus for sentiment analysis and opinion mining. In LREc, volume 10, pages 1320{ 1326. Rahimi, A., T. Baldwin, and T. Cohn. for user preprint arXiv:1704.04008. Real Academia Espa~ nola. 2013. Banco de datos (CORPES XXI) [online]. Corpus del espa~ nol del siglo XXI (CORPES). Roller, S., M. Speriosu, S. Rallapalli, B. of the 2012 Joint Conference on Methods in Natural Lan- guage Processing and Computational Learning , pages 1500{1510. Association for Computational Linguis- tics. Shannon, C. E. 1948. A mathematical the- ory of communication. The Bell system technical journal , l\u0013 exica internacional de inves- tigaci\u0013 on l\u0013 exica. In y pistas alisis l\u0013 exico hispano (americano) . Iberoamericana Vervuert, 141{278. Vidal de Battini, B. E. 1964. El espa~ nol en la Argentina. Technical report, Argentina. Zheng, X., J. Han, and A. Sun. 2018. A survey of location prediction on Twit- ter. IEEE Transactions on Knowledge and Data Engineering , 30(9):1652{1671. 62 Juan Manuel P\u00e9rez, Dami\u00e1n E. Aleman, Santiago N. Kalinowski, Agust\u00edn Gravano Reflexive pronouns Spanish Universal Dep endencies: from annotation to automatic morphosyntactic analysis Los pronombres reflexivos en l as Universal Dependencies en espa\u00f1ol: desde la anotaci\u00f3n hacia el an\u00e1lisis morfosint\u00e1ctico -up article of Degraeuwe and Goethals (2020) , we the potentially which yielded weighted F1 scores up 0.88 and 0.98 for the \"Case\" and \"Reflex\" feature s, the dependency relations . the error underline s the (generalisation) potential of the also reveal s some of the remaining issues in the morphosyntactic analysis of Dependencies, morphosyntactic tagging and parsing . Resumen : En est e art\u00edculo de seguimiento de Degraeuwe y Goethals (2020) , presentamos el esquema de anotaci\u00f3n utilizado para reanotar los 7298 pronombres potencialmente reflexivos incluidos en el Universal Dependencies Spanish AnCora v2.6 treebank , lo cual result\u00f3 en un significativo n\u00famero de modificaciones para la caracter\u00edstica ( feature ) de \"Case\" (el 100% cambiado) y las relaciones de dependencia (el 87% cambiado). A continuaci\u00f3n, evaluamos el desempe\u00f1o de spaCy v3.2.2 y Stanza v1.3.0 (ambos entrenados en AnCora v2.8, y, por tanto, basados en nuestras reanotaciones) en el set de prueba de An Cora v2.8, lo cual dio como resultado puntuaciones de F1 ponderado de hasta 0,8 8 y 0,98 para la s caracter\u00edstica s de \"Case\" y \"Reflex\" , respectivamente, y de hasta 0,71 para las relaciones de dependencia. Por \u00faltimo, el an\u00e1lisis de errores de los resultados de spaCy subray a el potencial (generalizador) del modelo, pero tambi\u00e9n desvel a algunos de los problemas pendientes en el an\u00e1lisis morfosint\u00e1ctico autom\u00e1tico de los pronombres reflexivos en espa\u00f1ol, como por ejemplo determinar si las relaci ones de dependen cia expletiva s son de car\u00e1cter impersonal, pasivo o inherentemente reflexivo. Palabras clave : pronombres reflexivos, se, Universal Dependencies , etiquetado y an\u00e1lisis gramatical morfosint\u00e1ctico . 1 Introduction Vasiliev (2020) ), automatic morphosyntactic anal ysis been integrated into a wide range of text- based applications. By means of a simple programming script, for example, raw corpora Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 63-72 recibido aceptado 29-05-2022 ISSN 1135-5948. DOI 10.26342/2022-69-5 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Naturalcan be transformed into intelligent resources containing morphosyntactic information \"enriched corpora\" can then be used as input for corpus query tools or language learning environments , enabling their users to perform much ) taggers use of treebanks as reference data. One of t he most ives concerned with the Dependencies (UD) project, of facilitat ing multilingual parser development, cross -lingual learning, and parsing research from a language retrieved . Together with the growing nu mber of languages included in the project (v2.9 contains cross -linguistically consistent approach of UD has l ed to increasing usage of UD treebanks not only for the development of NLP tools, but also for r esearch purposes (see de Marneffe et al. (2021, p. 304) for an overview). However, the UD initiative is also a \"constantly improving effort\" (Mart\u00ednez Alonso and are regularly annotation may be problematic from both a cross -linguistic and an intra - linguistic perspective. In a previous article (Degraeuwe and Goethals, annotation of the potentially reflexive te, nos, os and se (see also Markovi and Zeman, 2018) in the UD Spanish AnCora treebank (Mart\u00ednez Alonso and Zeman, 2016 ; Taul\u00e9, Mart\u00ed and Recasens , 2008 ). These are very frequent items in Spanish, with se alone occurring in almost 30% of the sentences in the AnCora treebank and bein g ranked eleventh in the list of most common lemmas in CORPES XXI (Real Academia Espa\u00f1ola de la Lengua, 2022). The annotation proposal described in Degraeuwe and Goethals (2020) was the contributor responsible for the AnCora treebank (see sec tions 2.1.1 and 2.1.2 for the details of th e original and revised annotation scheme s), after which all potentially reflexive onwards). In 2021, both spaCy and Stanza (with v1.2. 0) released thoroughly updated versions of their tools trained on higher out both a quantit ative and qualitative analysis of Spanish (see section 3). 2 Literature overview 2.1 Reflexives in Spanish Universal Dependencies The UD framework provides three main annotation layers by which linguistic constructions can progressively defined and differentiated: a morphosyntactic Part -Of- Speech (POS) tag (limited to a universal of tags) , a grammatical (e.g. person the of 2.1.1 Annotation scheme as proposed in Degraeuwe and Goethals (2020) The original proposal (see Tabl e 1) arose from the notion that, as NLP tools become more accessible, more accuracy linguistics ; Maldonado, Peregr\u00edn Otero, 1999). First, the pronouns were disambiguated according to their general reflexive character, distinguishing between me veo ('I see myself') and me ven ('they see me'). In the latter group, the dependency relation is defined reflexive non -reflexive \"obj\" and \"iobj\" have the same dependency label but are distinguished by the \"Reflex\" feature , which is absent in the feature constructions, proposal, many annotation inconsistencies were resolved (e.g. up to 30% and 60% false positives of \"expl:pass\" and \"iobj\", ( en este volumen se ofrecen textos sobre , 'in this volume texts are provided about') and reflexive uses ( Mar\u00eda cargo del beb\u00e9 , 'Mar\u00eda offers herself to take c are of the baby') of the same verb, or between passive ( se incautaron las armas and inherently reflexive constructions se las armas , 'the police seized the guns'). In all these cases, se was label led as \"obj\" , and no differences were to be found between the feature sets of the se instances, nor between the feature sets of the ir verbal . Features Case Reflex Voice Reflexive uses Pass (a) la noticia se public\u00f3 obj Acc Reflex Act (b) Pedro se ve en el espejo Acc Rcp Act (c) Pedro y Juan se vieron en la calle iobj Dat Reflex Act (d) Pedro se quita la ropa Dat Rcp Act (e) Pedro y Juan se dieron la mano expl:impers - Reflex Act (f) se trabaja mucho expl:pv With corresponding non -reflexive transitive verb Acc Reflex Pass (g) el fen\u00f3meno se manifiesta Acc Reflex Act (h) la gente se manifiesta Acc Rcp Act (i) Pedro y Juan se ponen de acuerdo Dat Reflex Act (j) Pedro se da cuenta de que ... Dat Rcp Act [does not occur in Spanish] Com Reflex Act (k) Pedro se llev\u00f3 el regalo With corresponding non -reflexive intransitive verb - Reflex Act (l) Pedro se muere Without corresponding non -reflexive verb Acc Reflex Act (m) Pedro se atreve a ... Non-reflexive uses obj Acc - - (n) me/te/nos/os ven - - (o) me/te/nos/os/se lo dijeron of the sees himself in the mirror ', (c) 'Pedro and Juan see each other on the street ', (d) 'Pedro takes off his clothes ', (e) 'Pedro and Juan shake hands' , (f) 'a lot of work is being done ', (g) 'the phenomenon becomes clear ', (h) 'people are demonstrating and Juan agree 'Pedro realises that ... ', (k) 'Pedro took the present with him ', (l) 'Pedro dies ', (m) 'Pedro dares to ... ', (n) 'they see me/you/us/you ', 'they told it to me/you/us/you/him/her 65 Reflexive pronouns in Spanish Universal Dependencies: from annotation to 2.1.2 drastic modifications, were applying o feedback, the reflexive - reciprocal distinction was dropped : since \"Reflex\" feature showed to be a too subtle one to make for machine learning methods (tested reflexive was also discarded Although these characteristics do seem to be recognisable for machine learning models (average weighted F1 test set score s of 0. 78 for custom model trained with spaCy v3.2.2 architecture and 0. 61 with St anza v1.3.0), t he \"Voice=Pass\" feature was primarily from passive voice morphologically, which is not the case i n . Even though the modifications presented remains very informative different dependency labels, accusative/dative/comitative case distinction and reflexive/non use distinction). the new annotation scheme now adheres very str ictly to the UD and of the 7298 pronouns pre sent in the development, test and training received a new \"Case\" value: The data. Features Case Reflex Reflexive uses expl:pass Acc Yes (a) la noticia se public\u00f3 obj Acc Yes (b) Pedro se ve en el espejo (c) Pedro y Juan se vieron en la calle iobj Dat Yes (d) Pedro se quita la ropa (e) Pedro y Juan se dieron la mano expl:impers - Yes (f) se trabaja mucho expl:pv With corresponding non -reflexive transitive verb Acc Yes (g) el fen\u00f3meno se manifiesta (h) la gente se manifiesta (i) Pedro y Juan se ponen de acuerdo Dat Yes (j) Pedro se da cuenta de que ... Com Yes (k) Pedro se llev\u00f3 el regalo With corresponding non -reflexive intransitive verb - Yes (l) Pedro se muere Without corresponding non -reflexive verb Acc Yes (m) Pedro se atreve a ... Non-reflexive uses obj Acc - (n) me/te/nos/os me/te/nos/os/se lo dijeron expl:pass 301 159 35 1 6 502 (6.9%) iobj 1 17 253 152 43 466 (6.4%) obj 54 2052 2927 628 665 6326 (86.7%) other 0 3 0 1 0 4 (0,1%) Total (AnCora v2.7) 356 pronouns from while the value of 141 instances was modified the other way around from non -reflexive to reflexive. (note that \"expl:pv\" do not occur in the v2.6 treebank). The statistics show a fundamental shift from \"obj\" as the predominant label to a more dispersed distribution, with \"expl:pv\" and \"expl:pass\" being the most important In other words, the reannotation shows that reflexive express use, specifically an reflexive use subject role (\"expl:pass\"). 2.2 Reflexives in machine learning To our knowledge, to date no studies have been performed which focus on the performance of machine learning models at tagging potentially reflexive pronouns in Spanish based on UD treeba nk data. On non -UD data, however, some experiments have been carried out . In Aldama Garc\u00eda and Barbero Jim\u00e9nez (2021 ), for example, a machine learning approach is adopted to predict the dependency label of se in a one -per-sentence 2140 sentences from CORPES XXI (Real Academia Espa\u00f1ola de la Lengua, 202 2). The corpus was annotated according to a four -category annotation (for cases pass ive and impersonal constructions) (for indirect objects) and \"obj\" (for direct objects) labels. Next, nine different machine learning classifiers were applied to the test set of the corp us, with pre-trained language models based on a transformers architecture obtaining the best performance (macro F1 score of 0.7) . Results such as these implement them in real -life scenarios, approaches as in Aldama Garc\u00eda and Barbero Jim\u00e9nez (2021), which are based on a language - specific setup and require a self -compiled and annotated set of trai ning and test data, can be integrated as a custom component for that specific language in NLP tools and Stanza morphosyntactic information offered by the tool's tagger and parser can be complemented by the output of the task -specific model. However, the creation of such models is a very time -consuming operation, especially for non-computational linguists. Therefore, in section 3, we will study the potential of the default taggers and parsers included in spaCy and Stanza (which a re trained on UD data) , and analyse if they would need to be complemented by a task -specific model and where exactly (i.e. for which labels) From section 2.1.2 it can be co ncluded that, in theory, any NLP tool trained on the treebank as input reflexive in claim, we apply pretrained model and the default 67 Reflexive Spanish Universal Dependencies: automatic morphosyntactic analysis Case Reflex Dependency relation Acc Dat NA Yes NA expl:impers expl:pass expl:pv iobj obj #instances 452 47 42 504 37 30 171 50 spaCy F1 0.94 0.62 of Stanza are both trained on the UD Spanish AnCora v2.8 training and development sets, to the corresponding AnCora v2.8 test set. This test data includes 668 pronouns, of which 127 instances are clitic forms such as se in la gente va a la calle a manifestarse ('people go to the streets to demonstrate'). As spaCy does not include a multiword tokeniser (which so -called \"subword tokens\" and t hen analyse these separate of the entire word form ), clitic forms will be excluded order to obtain comparable re sults. Table 4 presents a detailed overview of the morphosyntactic analysis , with F1 as evaluation metric and the number of instances for each label included in the \" #instances \" row . Finally, some architectural characteristics of the NLP tools should e highlighted: in spaCy pipeline , the tagger and parser components listen to the same word embedding component but do not share any information between them, that the features take into account information from the tagger when training its dependency \"Reflex\") Stanza dependency label and to \"expl:pv\" relations are the automatic morphosyntactic . to the top macro F1 score of 0.7 reached in Aldama Garc\u00eda and Barbero Jim\u00e9nez shoul Aldama Garc\u00eda and Barbero Jim\u00e9nez (2021) distinguish only four instead of five categories and exclusively focus on se as potentially reflexive pronoun (and not on me, te, nos and os). Next, the low scores for the \"expl:impers\" and especi ally \"obj\" categor y have to be highlighted. A first possible explanation for this lower performance could be the limited number of training instances in the training and developments sets: 2 68 for \"expl:impers\" (5.07%) and (8.4%). To gain mor e in-depth insights into this matter, and into the errors made by NLP tools in general , an additional analysis is performed based on the contingency tables included in Table 5, which zero in on the performance of spaCy, the best -performing tool. The error analysis will also include a qualitative component, with special attention to the generalisation potential of the tool (i.e. if it has learnt to make predictions based on patterns, not just to predict the most for each word form). For \"C ase\" three extracted from the results: 1. Predicting the correct case of me, te, nos and os when they are used in accusative case is challenging (see (p) and (s) in Table 6 for some examples): together, these pronouns account for 29 of the 452 accusative instances, and 13 68 Jasper Degraeuwe, Patrick Goethals Case predicted correct Acc Dat NA Total Acc 435 14 3 452 Dat 19 28 0 47 NA 23 1 18 42 Total 477 43 21 541 Reflex predicted correct Yes NA Total Yes 496 8 504 NA 2 35 37 Total 498 43 541 Dependency rela tion predicted correct expl:impers expl:pass expl:pv iobj obj other Total expl:impers 14 9 5 1 1 0 30 expl:pass 7 138 24 1 0 1 171 expl:pv 4 39 201 7 3 0 254 iobj 0 5 3 25 3 0 36 obj 0 7 16 14 13 0 50 Total 25 198 249 47 21 1 541 Table 5: Results received the wrong \"Dat\" prediction (which corresponds to 13 of the 17 errors made for th e accus ative label). Importantly, \"expl:pv\") . the case of used in dative case also entails challenges (see (q) in Table 6 for an example) : se accounts for 24 of the 47 dative instances, and 15 of those 24 cases were labelled wrongly as accusative (corresponding to 15 of the 19 errors made for this label). 3.As for the non -cased instances , the errors seem to indicate that the model does not just na\u00efvely link labels to verbal heads , irse/marcharse ('to leave'), which frequently in all circumstances receive the \"NA\" label , 5 incorrect but correct predictions were to be found. This finding can be considered evidence that the model has developed a kind of generalisation procedure ,although it thus results in the errors in the case of irse/marcharse . In this regard, it also appears such head combinations which (almost) do not occur in the training (and development ) data, as was the case with advertir . For this verb, which only occurs once as a verbal head (i.e. the verbal form on which the potentially reflexive pronoun is syntactically dependent) in the training set test sentence Table 6) was wrongly predicted as \"Acc\" , meaning that the model was not able to gen eralise, in this particular case at least, from similar examples with other verbal heads (e.g. contratar as in se contrata a alguien 'someone was given a contract ', which occurs three times in the training data). Next, the (few) errors made for the \"Refle x\" feature (see (s) in Table 6) usually correspond to instances of me, te, nos and os for which the 69 Reflexive pronouns in Spanish Universal Dependencies: from annotation to automatic morphosyntactic analysis model also wrongly predicted both the case (usually instead case ) and the dependency \"iobj\" wrong \"iobj\" prediction provides a plausible explanation for the error in the \"Reflex\" label, as in the training data non-reflexive t dependency relation predictions led to again three main findings: 1. in one of the \"expl\" categories almost always correspond to one of the two other \"expl\" labels (14 of the 16 errors in \"expl:impers\", 31 /33 in \"expl:pass\" and 43 /53 in \"expl:pv\"). In other words, the model has be a less straightforward operation from a machine learning point of view (see sentences (q) an d (r) in Table 6). 2. For \"iobj\", 5 of the 11 errors are \"expl:pass\" predictions . Looking at the sentences, it appears that the model is not able to predict the \"iobj\" label for reflexive pronouns which co -occur with an explicit subject and direct object, as in the examples (t) and (u) in Table 6. 3. Predicting the correct dependency label of me, te, nos and os when they are used as direct object also poses challenges to spaCy's machine learning model (see (p) and (s) in Table 6): together, these pronouns account for 19 of the 50 \"obj\" instances, and 17 of those 19 cases received a wrong dependency relation (which corresponds to 17 of the 37 errors made for the \"obj\" label) . Moreover, all of the 14 cases where an \" iobj\" instance was predicted instead of \"obj\" were to those 17 errors, highlighting the sometimes fuzzy boundary between me, te, nos and os acting as direct or indirect object. Finally, as a general, observation it should be noted that the generalisation the mode l, which was already in the discussion of to the fore with pronoun - verbal head combinations which have multiple possible uses. A good case in point is the combination with the verbal head tratar , which occu rs 111 times as \"expl:impers\" and 2 times as \"expl:pass\" in the training and development data. Despite the imbalanced distribution in the training data, the test sentence containing los temas se tratar\u00e1n ('the topics will still got labelled correctly as \"expl:pass\", which hints at the fact that model has leveraged \"knowledge\" from other \"expl:pass\" training examples to arrive at Acc Dat NA NA obj iobj (q) [...] las carreteras catalanas se cobraron 16 vidas [...] Dat Acc Yes Yes expl:pv expl:pass (r) Si se hubiera a dvertido a la gente [...] NA Acc Yes Yes expl:impers expl:pass (s) [...] no me enga\u00f1o a creer en la existencia de [...] Acc Dat Yes NA obj iobj (t) [...] Beckenbauer se permite bromear [...] Dat Acc Yes Yes iobj expl:pass (u) [...] el affaire Cristo -Rey se tomaba un respiro [...] Dat Acc Yes Yes iobj expl:pass Table 6: Selection errors in Catalan roads claimed 16 lives [...] ', (r) ' If people had been warned [...] ', (s) ' [...] I don't delude myself believing in Degraeuwe, Patrick potential be found in the accuracy rates the model obtain s for the 35 pronoun - verbal head combinations which do not occur at all in the training data : 73% for \"Case\", 97% for \"Reflex\" and 5 4% for the dependency relation s. 4 Conclusion In this article, we built upon Degraeuwe an d Goethals (2020) , in which formulated to reannotate the potentially reflexive pronouns ( me, te, nos, os and se) in the Universal Dependencies Spanish AnCora treebank. These items, and in particular se, occur very frequently i n Spanish, and non-computational linguistics Otero, into account that treebanks used as reference data train models by state-of-the-art NLP tools such as spaCy for , among st other applications , corpus query tools and language learning environments. We presented the slightly \"Reflex\" features some of the remaining analysis of potentially reflexive Spanish (e.g. determining label for \"Reflex\" and 0.71 for dependency relations), there is still for the prediction of dependency relations. Therefore, future could cons ist in studying if a task- specific model ( as in Aldama Garc\u00eda and Barbero Jim\u00e9nez (2021) ) can complement the default taggers and parsers of NLP tools in order to push performance. Furthermore, it is worth considering to implement rule-based predictions for a fixed set of verb s which always yield the same label s when functioning as verbal head of a reflexive pronoun (e.g. for irse and marcharse ), and to define rules which determine the feature values a given Ackno wledgements This research has been carried out as part of a PhD fellowship on the IVESS project (file number Altinok, D. 2021. Mastering practical applications Python ecosystem . Marneffe, M -C., C.D. Man pronouns in nish Universal Dependencies. Procesamiento del Lenguaje Natural , 64: 77 -84. Maldonado, R. 2008. Spanish middle syntax: A usage -based proposal for gram mar teaching. In S. De Knop and T. De Rycker (eds.) Cognitive Approaches to Pedagogical 71 Reflexive pronouns in Spanish Universal Dependencies: from Gruyter . Zeman. 2018. Reflexives in Universal Dependencies. In Proceedings of the 17th on Linguistic Theories (TLT 2018) , pages 131 -146, Oslo University (Oslo). Mart\u00ednez Alonso , H. and D. Zeman. 2016. Universal Dependencies for the AnCora treebanks . Procesamiento de A. 1999 . Construcciones inacusativas y In Gram\u00e1tica descriptiva de la lengua espa\u00f1ola , 2: 1575 - 1629. Espasa Calpe . de Marneffe, F. Ginter, Y. Goldberg, J. Haji, C. Manning, R. McDonald, S. Petrov, S. Pyysalo, N. Silveira, R. Tsarfaty, and D. Zeman. Universal dependencies v1: A multilingual treebank collection. In Proceedings of the International Conference on Language Resources and Evaluation (LREC'16) , 1659 -1666, European Peregr\u00edn Otero, C. 1999 . Pronombres reflexivos y rec\u00edprocos. In Gram\u00e1tica descriptiva de la lengua espa\u00f1ola , 1: 1427 -1518. Espasa Calpe. Real Academia Espa\u00f1ola de la Lengua. 202 2. Banco de datos (CORPES XXI) [online]. Corpus del Espa\u00f1ol del Siglo XXI -xxi. Accessed date: 2 2/02/2022 M. Recasens. 2008. AnCora: Multilevel annotated corpora for Catalan and Spanish. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08) , European Language Resources Association (Marrakech) . Vasiliev, Y. 2020. Natural Language Processing with Python and spaCy: A Practical Introduction. No Starch Press. 72 Jasper Degraeuwe, Goethals Classification for PublicProcurement for a 14% of the annual budget of the different governments of the European Union. and the alerts that by CPV classification is not a trivial task, as there are more than 9,000 different CPV categories, which are often CPV classifier that uses as an input description of the contracting and assigns CPVs from the 45 top-level work only with texts in Spanish, although our approach may be easily extended to other languages. Our results improve the state of the art el 14% del presupuesto anual de la Uni\u00b4 on Europea. En Europa, los procesos de contrataci\u00b4 on se clasifican usando la taxonom\u00b4 a Common Procurement Vocabulary (CPVs), dise nada sticas, las b\u00b4 usquedas y la creaci\u00b4 on de lizar los posibles licitadores. Los c\u00b4 odigos CPV suelen ser asignados manualmente por los empleados p\u00b4 ublicos encargados del proceso de contrataci\u00b4 on. Sin embargo, la clasificaci\u00b4 on de textos de acuerdo con estos c\u00b4 odigos no es trivial, pues existen m\u00b4 as de 9000 CPVs y no siempre se siguen los mismos criterios para su asignaci\u00b4 on. En este art\u00b4 culo se propone un clasificador que utiliza como entrada la descripci\u00b4 on textual del proceso de contrataci\u00b4 on, y produce c\u00b4 odigos de entre las 45 categor\u00b4 as de CPV m\u00b4 as generales de la jerarqu\u00b4 a. Trabajamos s\u00b4 olo con textos en espa nol, aunque nue- stro enfoque puede extenderse f\u00b4 acilmente a otros idiomas. Los resultados obtenidos superan el estado del arte (10% de mejora en F1), y se encuentran disponibles online. Palabras the European Union spend around 14% of the yearly Gross Do- mestic Product (around 2 trillion euros) pur- chasing services, utilities and supplies.1Ac- cess to this data is crucial for enabling a sin- gle digital market in Europe, as well for ac- countability and transparency. Hence portals well as in have de- veloped improve both the efficiency and transparency Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 73-82 recibido aceptado 20-05-2022 ISSN 1135-5948. DOI 10.26342/2022-69-6 \u00a9 to detect procurement processes of interest, public must be manual CPV classification are thousands of possible codes (more than 9000), some of them with similar purposes, making it diffi- cult for those assigning or curating them to decide which codes better suit a specific pro- cess. Second, countries with official with Spain or Belgium, often have offers in different languages (e.g., us- ing more specific codes that shed more light in the type of purchase. This issue is in fact reflected in the European Policy book, specific CPV the assignment of automatically assign high-level CPV codes (i.e., the 45 most general categories) to a pro- curement process. In this paper, we assume that we have the textual description of the process and that the text is in Spanish. Dif- ferent methods have been tested to this end, outperforming previous available results for the Spanish language. We expect this re- search line will help public procurement prac- in humans can use in their decision process. The rest of the paper is 3 summarizes the related work done in text of text classification, as wellas 4 how the cor- pus used to train our classifier was developed, used, and Section code that represents the need main object of the requested contract. Several CPV codes may be used to The format of these first three first four following groups, 1321 classes and 3704 categories. In this paper we focus in classifying CPVs at the division level. 3 Related Work While text classification has been widely ex- plored in the 2021), language has less attention so far. The main multi-label text classifi- cation case presented in this paper and other popular problems like sentiment analysis is the thousands of possible options. In order to target this kind of problems, a new subtask has been defined inside multi- label text classification: extreme text addresses the problem assign- ing to a document its most relevant subset of class labels from an extremely large label collection (Liu et al., 2017). The work by Gargiulo et al. (2019) analyzes the impact of using different word embedding models Similarly, Liu et al. (2017) com- pared CNN to other approaches in XMTC, such as KNN-based approaches like SLEEC tree-based methods like FastXML (Prabhu and Varma, 2014). Finally, Chang et al. (2020) proposed a scalable framework to fine-tune Deep Trans- among 45 different division labels, with an F1 Score 0.68. Industrial problem, first two dig- 4https://huggingface.co/MKaan/ multilingual-cpv-sector-classifierits of the CPV code, 50 models to predict the third code (depending on the first model re- sults) and 250 additional models to predict the fourth digit. Other approaches in the literature include a deep used Linear SVMs in order to predict first the were also used Kayte only model available for reuse and evalua- tion for the Spanish language is the one from Kaan G\u00a8 org\u00a8 un, we use it as a baseline for com- parison against our approach, making both training and model results available to the community. 4 Creating a Spanish CPV Corpus We created our training corpus with open data from historical public procurement from the Spanish Treasury's website (Hacienda5). We decided to use data from 2019, in order to avoid including later data that may have (Atom Syndication different scripts available Spanish information contained in the Atom doc- uments. We only retrieved the textual description of the offers and the differ- ent CPV codes assigned to them. This is represented as a CSV file in order to ease its and scriptions. Additionally, we only keep texts in Spanish func- tionality8). to make the dataset more manageable, we split it into train and test sets (70/30) before uploading it to our public code repository. 4.In-code preprocessing. An additional set of scripts were used alize CPV codes to the division level, which is the one we use in our experi- ments. The result of the first two steps are csv files, available in our repository. The code used for all processing scripts can also be found in the same location. Figure 2 shows the distribution for each of the 45 division la- bels, which are clearly unbalanced. The most frequent label ('45', sion 'works') is present in 16128 instances of the the training set, while label '76' is only present in 13 instances. 5 took structure of 45 available divi- sions (first two digits). We believe this to be a good first step due to the training data available for most categories. The only model openly available to per- form this task is the Kaan G\u00a8 org\u00a8 un (from now, MKaan) Work section. This model also targeted just the first two digits of the CPV code, so we use it as a baseline to compare the different approaches we have tested. In order to perform multi-label classifica- or like Bayes or Another option is to fine-tune ing as done in the approach by MKaan. We briefly present below the differ- ent tried the following Although algorithm relies on probability independence, it works very well even when this assumption is not met. SVM Support Vector Machines (SVM) (Boser, Guyon, and Vapnik, 1992) are lin- ear hyperplane SVM, we also evaluated the performance of an SVM with the Radial Basis Function as kernel, that is: rbf=exx2(1) with of such as high variance. used for (Zhang and Zhou, 2007). The idea be- hind K-NN is to check the K labeled instances that are the closest to the new instance and classify it with the most common label from these neighbours. 9https://scikit-learn.org/ stable/modules/tree.html# tree-algorithms-id3-c4-5-c5-0-and-cart 76 Maria Navas-Loro, Daniel Garijo, Oscar Corcho 45 50 79 71 72 34 85 92 90 33 44 55 30 48 39 60 31 09 66 80 42 98 35 38 32 18 77 15 64 63 03 37 22 70 51 24 14 73 75 43 65 16 19 41 76 Division labels (first two digits)0200040006000800010000120001400016000Amount of instancestrain represent the division label (x axis). Blue bars represents the amount of labels in the training set, while red bars represent the number of instances in the and Schapire, 1997) is a meta-estimator that fits different versions of models using boosting (i.e., different versions of the training dataset). We used the implementation defined in Hastie et al. (2009): AdaBoost-SAMME. For all these approaches do not support multi-label clas- sification, per label is built in order to decide if an instance should be classified with that label or not. 5.2 RoBERTa fine-tuned approach In addition to the decided to fine- namely errez-Fandi no et al., Spanish Public is a transformer-based masked model based on the RoBERTa model and pre-trained us- ing the largest Spanish corpus known to date (570GB), compiled from the annual web crawlings performed by the National Library of Spain (Biblioteca Nacional de Espa na) from 2009 to 2019.10 Table notebook ap- proaches, and discusses them. 6.1 Metrics We use two sets of metrics in our evalua- tion. First, we use general metrics such as the Under the ROC Curve (ROC and of for training the RoBERTa fine-tuned model used in our analysis. Label Ranking Average Precision. We briefly describe all these metrics below. Area Under tinguish between classes. The higher the AUC, the better tinction metrics at the same of predictions error computes the average number of labels that have to be included in the final prediction such that all true labels are predicted. That is, the average amount of ranked labels to take into account to of fRns\u00d7nl ranking a vector), and | \u00b7 |rep- resenting the cardinality of the set. 6.2 Results and Discussion We compare our results against the model by MKaan, since it is the only available model that we have been able to find targeting CPV code assignment or function is provided, we tested different thresholds with most functions and sigmoid). Results are summarized in Table 2 10% the dataset), Table 3 (using the whole dataset). The results clearly show that the RoBERTa fine-tuned model outperforms the rest of the approaches both when training using just a fraction of the dataset and the full dataset. The model by MKann shows a good performance taking into account its multilingual nature (not specific for the Spanish language). However, MKaan is matched and even outperformed by some of the traditional algorithms in both experiments. In particular, classical approaches such as SVM, random that these algorithms are usually less expensive to train, test and use than transformer-based are reasonable candidates for assisting in classification at a low cost. One possible ex- planation for this good performance is that, despite the presence of polysemous words that can be problematic, both the hyper- discrimi- others (that is the strategy usually used to adapt the algorithms 78 the 10% of dataset 79 Multi-label Text Classification for Public Procurement in Spanish 45 79 50 71 72 34 85 90 92 44 33 55 30 39 48 60 31 09 80 66 42 98 35 38 77 32 64 15 18 63 03 70 22 24 37 51 14 73 75 65 43 16 19 41 760.00.20.40.60.81.0 precision recall f1-score Division the RoBERTa fine-tuned model (t=0.5) per label. We preserve the order presented in Figure lack measures for balancing input an excel- lent performance for most categories, and has an acceptable performance for classes with less available We that to number of training instances, the generality of the divisions and the over- lap between them also play a role in leading positives/negatives. In Figure 3, we can in fact confirm of Conclusions Work This paper presents an approach to classify CPV code divisions for Spanish public pro- descriptions. Our work evaluated classical machine learning algorithms, show- the RoBERTa transformed-based model trained on a corpus of the BNE (Span- ish National Library), that outperformed all the previous approaches. All data, data pro- cessing scripts and training notebooks have been made available through a public code repository, Zenodo (Navas-Loro, Garijo, and Corcho, 2022)11and a Research sake of reproducibility. This material is also planned to be used in AI4Gov approach covers only CPV division CPV responsible for categorizing the first two digits of the code, i.e., its division. The next level would attempt to predict the next digit based on For ex- ample, if the first classifier determined a description corresponds to the labels '45' '48', that description would be passed to classifiers that determine the next digit trained with examples of those two codes. disuse are much better suited to the topic of the description). Our future work includes designing a sequence of models that successively classify the digits of CPVs, as classifiers will also to information from contracting processes. These include features such as the cost, that could help in the disambiguation of general words such as \"service\" or \"work\", that can be different situations. Additionally, we will also enhance the preprocessing of the data in or- der to improve the quality in the dataset, awell-known problem positive results are a ward towards the creation of a decision sup- port system to help in CPV classification, al- lowing a more transparent and efficient public procurement in Spain and Europe. Aknowledgments This work has been by NextPro- curement the Multiannual Agreement with Universidad Polit\u00b4 ecnica de Madrid in the line Support for R&D projects for Beatriz Galindo researchers, in the context of the V PRICIT (Regional Programme Research and Innovation). We the of Jennifer Tabita for the preparation of the initial set of notebooks, and the AI4Gov master students from the first cohort for their validation of the approach. Source of the data: Ministerio de Hacienda. References Aggarwal, C. C. and C. Zhai. 2012. A survey of text classification algorithms. In Min- ing text data . Springer, pages 163-222. Ahmia, O. 2020. Assisted strategic monitor- ing on call for tender databases using nat- ural language processing, text mining Ph.D. thesis, Universit\u00b4 e de Bretagne Sud, 03. Bhatia, K., H. Jain, P. Kar, M. Varma, and P. Jain. 2015. Sparse local em- beddings for extreme multi-label classifi- cation. In C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Systems, volume 28. Asso- ciates, Inc. Boser, B. E., I. M. Guyon, and V. N. Vapnik. 1992. A training algorithm for optimal margin classifiers. In Proceedings of the fifth annual workshop on Computational learning theory, pages 144-152. Breiman, L. 2001. Random forests. Machine learning , 45(1):5-32. 81 Multi-label Text Classification for Procurement in Spanish Chang, W.-C., H.-F. Yu, K. Zhong, Y. Yang, and I. S. Dhillon. 2020. Taming pre- trained transformers for extreme multi- label text classification. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 3163-3171. Deloitte. 2020. Study on up-take of in procurement. Tech- nical Schapire. 1997. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of computer and system sciences, 55(1):119-139. Gargiulo, F., S. Silvestri, M. Ciampi, and G. De Pietro. 2019. Deep neural net- work for hierarchical J. Gonzalez- Agirre, C. Armentano-Oller, C. R. Pena- 2021. Spanish lan- guage models. CoRR, abs/2107.07253. Hand, mining. Drug safety, 30(7):621-622. Hastie, T., J. Zhu, and H. Zou. Polarity detection of turkish comments on technology compa- nies. In 2014 International Conference on Asian Language Processing (IALP) , pages 136-139. IEEE. Kayte, S. and P. Schneider-Kamp. 2019. A mixed neural network and support vector machine model for tender cre- ation in the european union ted database. InProceedings of the 11th International Joint Conference on Knowledge Discov- ery, Knowledge Engineering and Knowl- edge Management, pages 139-145. IN- STICC, SciTePress.Liu, J., W.-C. Chang, Y. Wu, and Y. Yang. 2017. Deep learning for extreme multi- label text classification. In Proceedings of the 40th international ACM SIGIR al. 2021. M., D. Garijo, and O. Corcho. 2022. Code repository for multi-label text classification for public procurement in spanish, May. Prabhu, Y. and M. Varma. 2014. Fastxml: A fast, accurate and stable tree-classifier for extreme multi-label learning. In Proceed- ings of the 20th ACM SIGKDD interna- tional conference on Knowledge discovery and data mining , pages 263-272. Quinlan, J. R. 1986. Induction of trees. Machine learning , 1(1):81-106. Siblini, W., F. Meyer. 2018. CRAFTML, an efficient clustering-based random forest for extreme multi-label learning. In J. Dy and A. Krause, editors, Proceedings of the 35th International Con- ference on Machine Learning , volume 80 ofProceedings of Machine Learning Re- search, pages 4664-4673. PMLR. Soylu, A., Corcho, B. Elves\u00e6ter, C. Badenes- Olmedo, F. Yedro-Mart\u00b4 nez, et al. 2022. Data quality barriers for transparency in public Zhang, M.-L. and Zhou. 2007. Ml-knn: A 2048. 82 Maria Navas-Loro, Daniel Garijo, Oscar Corcho Selecci\u00f3n de colocaciones acad\u00e9micas en espa\u00f1ol a trav\u00e9s de un filtro de interdisciplinariedad Selecting Spanish , CITIC eleonora.guzzi@udc.es, margarita.alonso@udc.gal Resumen: En este art\u00edculo se propone una metodolog\u00eda para compilar una lista de colocaciones acad\u00e9micas con base nominal que se integra n en una herramienta l\u00e9xica (Alonso -Ramos, Garc\u00eda-Salido y Garcia, 2017). Para ello, establecemos un filtro que mide la interdisciplinariedad de los nombres acad\u00e9micos a partir de los cuales se extraen las colocaciones (Garc\u00eda-Salido , 2021), con el fin de mantener los nombres frecuentes y bien distribuidos en distintas disciplinas acad\u00e9micas , y descartar aquellos que se adscriben a la terminolog\u00eda o que son m\u00e1s caracter\u00edsticos de la lengua general . Utilizamos tres criterios: (1)el IDF (Jones, 1972); (2) el an\u00e1lisis de la distribuci\u00f3n de colocaciones; (3) el contraste con lista s de vocabulario acad\u00e9mico ingl\u00e9s . Los resultados muestran que estos criterios son \u00fa tiles para identificar los nombres protot\u00edpicos del discurso acad\u00e9mico y permite n filtrar la lista de colocaciones acad\u00e9micas. No obstante , persiste e l problema de c\u00f3mo tratar l a d esambiguaci\u00f3n sem\u00e1ntica en relaci\u00f3n con las diferentes d isciplinas . alabras clave: discurso acad\u00e9mico, interdisciplinariedad , Abstract: In this paper a compile a list of noun- is proposed. To do filter measures the interdisciplinarity are prototypical of general language. T hree criteria were used: (1) the IDF (Jones, 1972 ); (2) an analysis of collocation distributions ; (3) a contrast with vocabulary lists of of academic collocations. However, the problem regarding how to deal with disambiguation in different interdisciplinarity, academic collocations . 1 Introducci\u00f3n Uno de los principales objetivos dentro del \u00e1mbito de las lenguas con fines acad\u00e9micos ha sido el de proporcionar listas de vocabulario acad\u00e9mico para ser utilizadas como recursos pedag\u00f3gicos e integradas en la ense\u00f1anza de la escritura acad\u00e9mica. Este vocabulario incluye unidades y combi naciones l\u00e9xicas que son espec\u00edficas del g\u00e9nero acad\u00e9mico, pero no son terminol\u00f3gicas. A su vez, s e caracterizan por ser m\u00e1s frecuentes en el discurso acad\u00e9mico que en la lengua general o en otros g\u00e9neros . Siguiendo a Tutin (2007a) podemos definir el vocab ulario acad\u00e9mico como aquel vocabulario que hace referencia a los procedimientos y actividades cient\u00edficas del discurso cient\u00edfico, esenciales en la argumentaci\u00f3n y en la estructuraci\u00f3n de los textos acad\u00e9micos (Dr ouin, 2007; Paquot y Bestgen , 2009). Hasta el momento, se han propuesto varias listas de unidades l\u00e9xicas acad\u00e9micas especialmente para el ingl\u00e9s y el franc\u00e9s: Academic Vocabulary List (AVL, Gardner y Davies, 2013), Academic Word List (AWL , Coxhead, 2000), Academic Scientific Lexic on (Hatier et al., 2016), Lexique Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 83-94 recibido aceptado 23-05-2022 ISSN 1135-5948. DOI 10.26342/2022-69-7 \u00a9 Sociedad del Lenguaje NaturalScientifique Transdisciplinaire (LST, Drouin, 200)7 , entre otras. Por otro lado, dentro de las listas de combinaciones l\u00e9xicas destacan la Academic Collocation List (ACL, Ackermann y Chen , 2013) y la Academic English Collocation List (Lei y Liu, 2018), centradas espec\u00edficamente en las colocaciones, as\u00ed como la lista de palabras y colocaciones acad\u00e9micas empleadas para la herramienta lexicogr\u00e1fica Collocaid (Frankenberg-Garcia et al., 2019) . En el \u00e1mbito del espa\u00f1ol, se ha propuesto recientemente una lista de unidades l\u00e9xicas acad\u00e9micas, la Spanish Academic Key Word List (SpAKW L, Garc\u00eda- Salido 202 1), que incluye 1.239 lemas de nombres, adjetivos, verbos y adverbios . A partir de los nombres de esta lista, tambi\u00e9n se ha extra\u00eddo una primera versi\u00f3n de colocaciones acad\u00e9micas con base nominal que se integran en la Herramienta de Ayuda a la Redacci\u00f3n de Textos Acad\u00e9micos (HARTA; Alonso -Ramos, Garc\u00eda -Salido y Garcia, 2017; disponible en: http://www.dicesp.com:8083/). En estos estudios se han aplicado varios criterios estad\u00edsticos para identificar autom\u00e1ticamente el vocabulario interdisciplinar en el discurso acad\u00e9mico. Sin embargo, los criterios pueden diferir entre las listas de diferentes lenguas por los rasgos l\u00e9xicos de las mismas. Por ejemplo, c omo apuntan Cobb y Horst (2004) , existe un continuum entre el vocabulario acad\u00e9mico y no acad\u00e9mico en lenguas como el franc\u00e9s o el espa\u00f1ol debido a que, entre otras razones, el vocabulario greco - latino que es caracter\u00edstico de los textos acad\u00e9mico s, tambi\u00e9n se integra en dominios no acad\u00e9micos. Sin embargo, esto no sucede en ingl\u00e9s, donde los t\u00e9rminos greco -latino s tiene n mucha m\u00e1s presencia en el discurso acad\u00e9mico. En el caso del espa\u00f1ol , adem\u00e1s, aunque una palabra se utilice en la lengua general, se podr\u00eda incluir en las listas acad\u00e9micas si tambi\u00e9n es frecuente en el discurso acad\u00e9mico, debido a que, por un lado, los sentidos de las palabras acad\u00e9micas pueden diferir de los utilizados en los text os que no son acad\u00e9micos (Gilquin, Granger y Paquot, 2007), como, por ejemplo, trabajo ('composici\u00f3n cient\u00edfica o literaria' frente a trabajo como 'empleo ', en la lengua general) y, por otro lado, porque dichas palabras pueden formar parte de combinaciones l\u00e9xicas que son m\u00e1s exclusivas de los textos acad\u00e9micos (Garc\u00eda-Salido , 2021), como la colocaci\u00f3n dato cuantitativo con la palabra dato, frente a dato personal. El objetivo final a la hora de compilar las listas de vocabulario acad\u00e9mico deber\u00eda ser crear un balance entre la especificidad del vocabulario y su productividad. E sto es, se deber\u00eda apuntar a la inclusi\u00f3n de unidades y combinaciones l\u00e9xicas que son productivas para la redacci\u00f3n de textos acad\u00e9micos y que pueden estar en la intersecci\u00f3n, por ejemplo, entre la lengua general y la lengua acad\u00e9mica, pero que excluyen lo que es propio de otros g\u00e9neros. Otras dificultad es a la hora de recoger este vocabulario argum entadas en Hyland y Tse (2007) son la falta de atenci\u00f3n a la posible polisemia y a la variedad disciplinar. La polisemia implica que distintos sentidos sean utilizados en distintas disciplinas acad\u00e9micas: por ejemplo, la palabra volumen puede significar 'capacidad' en F\u00edsica, 'ejemplar de libro' en Biblioteconom\u00eda o 'frecuencia ac\u00fastica' en Ingenier\u00eda . Por otra parte, la variedad disciplinar se asocia a la posibilidad de que determinadas unidades y combinaciones l\u00e9xicas pueden ser acad\u00e9micas, p ero pueden utilizarse con m\u00e1s frecuencia en algunas disciplinas. En definitiva , no existe un consenso com\u00fan que apunte hacia una generalizaci\u00f3n de criterios sobre c\u00f3mo determinar la interdisciplinariedad y obtener vocabulario caracter\u00edstico de textos acad\u00e9micos. Como consecuencia, este trabajo se propone con un doble objetivo: por un lado, ofrecer una lista m\u00e1s refinada de nombres acad\u00e9micos en espa\u00f1ol y, por otro lado, utilizar la lista para filtrar las colocaciones acad\u00e9micas con base nominal que se integran en HARTA. Para alcanzar estos objetivos, seguimos una metodolog\u00eda basada en el refinamiento de l os nombres de la SpAKWL , que implica el descarte de aquellos adscrit os a una disciplina espec\u00edfica o que son significativamente m\u00e1s recurrentes en la lengua general. A continuaci\u00f3n, en la secci\u00f3n 2 presentamos el p roceso de extracci\u00f3n de la SpA KWL y de las colocaciones acad\u00e9micas en espa\u00f1ol ; en la Eleonora Guzzi, Margarita Alonso Ramos 84secci\u00f3n 3 presentamos la metodolog\u00eda empleada para identificar los nombres de la SpA KWL que son interdisciplinares y filtrar las colocaciones que contienen dichos nombres ; en la secci\u00f3n 4 exponemos los resultados obtenidos a partir de los distintos an\u00e1lisis; y, en la secci\u00f3n 5, discutimos los resultados, seguidos de las conclusiones finales. 2 Descripci\u00f3n de los datos: SpAKW L y colocaciones acad\u00e9micas Este estudio parte de la lista de palabras acad\u00e9micas del espa\u00f1ol SpAKWL (Garc\u00eda- Salido, 2021), extra\u00edda siguiendo criterios de especificidad y de distribuci\u00f3n a partir de un corpus acad\u00e9mico, HARTA-Expertos (HE, Alonso -Ramos, Garc\u00eda-Salido y Garcia, 2017). HE contiene 413 art\u00edculos cient\u00edficos publicados, cuya mayor\u00eda proviene de la secci\u00f3n en espa\u00f1ol del corpus Spanish-English Research Articles Corpus (SERAC; P\u00e9rez -Llantada, 2014) , y suma un total de 2.025.092 palabras. Est\u00e1 divido en 4 dominios principales (Artes y Humanidades, Biolog\u00eda y Medicina, Ciencias Sociales y Ciencias F\u00edsicas e Ingenier\u00eda) y 12 subdominios , siguiendo la estructura del SERAC. El proceso de tokenizaci\u00f3n y lematizaci\u00f3n se llev\u00f3 a cabo mediante LinguaKit (Garcia y Gamallo, 2016) y el de etiquetaci\u00f3n con FreeLing (Padr\u00f3 y Stanilovsky, 2012). Para analizar sint\u00e1cticamente el corpus con dependencias universales (Nivre et al., 2016) se utiliz\u00f3 UDPipe (Strak a, Hajic y Strakov\u00e1 , 2016). Para determinar la especificidad e identificar las palabras espec\u00edficas del \u00e1mbito acad\u00e9mico frente a un corpus de referencia, se emple\u00f3 el test estad\u00edstico log -likelihood a partir de las frecuencias absolutas de HE y del corpus de referencia, en este caso, la secci\u00f3n de ficci\u00f3n del corpus de narrativa LEXESP ( Sebasti\u00e1n -Gall\u00e9s et al., 2000 ), de 5 millones de palabras. Como criterio de distribuci\u00f3n, se seleccionaron aquellas palabras con ocurrencias en los 4 dominios y el 10% de palabras con una distribuci\u00f3n m\u00e1s homog\u00e9nea en t\u00e9rminos de DP (Deviation of Proportions, Gries , 2008). La lista de palabras acad\u00e9micas resultante cuenta con 1.239 lemas que se corresponden con nombres, verbos, adverbios y adjetivos. A partir de esta lista, se sel eccionaron los nombres (n=602) que se emplearon como ba ses para extraer autom\u00e1ticamente una primera versi\u00f3n de colocaciones acad\u00e9micas, que est\u00e1n integradas en HARTA. Para este prop\u00f3sito, definimos las colocaciones, dentro del marco de la Lexicograf\u00eda Explicativa y Combinatoria (Mel'uk, 2012), como combinaciones l\u00e9xicas con un significado composicional, que est\u00e1n formadas por una 'base', en este caso, un nombre, y un 'colocativo', y cuyos elementos tienden a coocurrir , como, por ejemplo, alcanzar un objetivo . Para analizar la interdisciplinariedad de las bases y de las colocaciones acad\u00e9micas en espa\u00f1ol, partimos de las colocaciones ya integradas en HARTA y de un segundo grupo m\u00e1s numeroso de colocaciones, que f ue extra\u00eddo a partir de una ampliaci\u00f3n del corpus HE, HARTA-Expertos -Plus (HEP). Este corpus contiene 21.068.482 palabras procedentes de 3.870 art\u00edculos de investigaci\u00f3n: 19.043.390 palabras proceden del corpus acad\u00e9mico - cient\u00edfico Iberia (Ahumada et al., 2011) y 2.025.092 palabras provienen del corpus H E. El corpus HEP se divide en los mismos cuatro dominios principales que HE, a su vez divididos en subdominios . Para los nuevos art\u00edculos, se aplic\u00f3 el mismo proceso de tokenizaci\u00f3n, lematizaci\u00f3n y an\u00e1lisis sint\u00e1ctico que se sigui\u00f3 para HE. Tras replicar los pasos seguidos para obtener la primera versi\u00f3n de colocaciones acad\u00e9micas, en primer lugar, se extrajeron colocaciones de 5 relaciones de dependencias sint\u00e1cticas (N + N, V + Obj, Suj + V, N + Adj, N + Obl) . En segundo lugar , se realiz\u00f3 una extracci\u00f3n autom\u00e1tica, basada en medidas de asociaci\u00f3n estad\u00edsticas (log -likelihood, Informaci\u00f3n Mutua, entre otras), y en criterios de frecuencia (5 ocurrencias) ( Alonso -Ramos, Garc\u00eda -Salido y Garcia, 2017). En tercer lugar, un grupo de anotadores refin\u00f3 manualmente los candidatos extra\u00eddo s autom\u00e1ticamente para obtener las colocaciones acad\u00e9micas, siguiendo criterios fraseol\u00f3gicos que se enmarcan dentro de la Teor\u00eda Sentido -Texto ( Mel'uk, 2012) . A Selecci\u00f3n de colocaciones acad\u00e9micas en espa\u00f1ol a trav\u00e9s de un filtro de interdisciplinariedad 85pesar del refinamiento manual y de las medidas escogidas, tanto en la lista de nombres acad\u00e9micos como en las colocaciones seleccionadas se incluyen casos m\u00e1s asociados a la terminolog\u00eda, como, por ejemplo, la palabra tejido usada con el sentido de Biolog\u00eda ' cada uno de los agregados de c\u00e9lulas de la misma naturaleza' (DLE, s.m, def. 4), o la colocaci\u00f3n ingresar paciente , que no son productiv as para los varios dominios acad\u00e9micos. 3 Metodolog\u00eda Con el fin de descartar los nombres especializados y los que son m\u00e1s frecuentes en la lengua general o en otros g\u00e9neros, en primer lugar, aplicamos la medida IDF (Inverse Document Frequency, Jones 1972) a los 602 nombres de la lista SpAKWL . Esta medida se basa en el c\u00e1lculo de la proporci\u00f3n de documentos que contiene un determinado t\u00e9rmino y se utiliza frecuentemente en el campo de la Extracci\u00f3n de la Informaci\u00f3n p ara identificar palabras clave, esto es, palabras espec\u00edficas de un conjunto de textos que tienen un alto v alor de IDF . Tras calcular el IDF de los nombres, ordenamos los valores de mayor a menor para visualizar en la posici\u00f3n m\u00e1s alta los candidatos m\u00e1s terminol\u00f3gicos. Calculamos la media de IDF (=0,659) y llevamos a cabo una revisi\u00f3n exhaustiva de los nombres situados por encima y por debajo de la misma para seleccionar el punto de corte, en este caso, la palabra potencia (IDF=0,900) . En este estudio, el IDF nos ayud \u00f3 a determinar precisamente las palabras que pueden ser descartadas (n=119) por ser menos interdisciplinares y m\u00e1s caracter\u00edstic as de algunos art\u00edculos, que se corresponden con las ubicadas por encima del punto de corte (ver Anexo 1). A partir de l resultado obtenido, seguimos un proceso de filtrado dividido en diferentes fases para analizar con m\u00e1s profundidad los 119 nombres que se descartar\u00edan por el IDF . En la primera fase (F1), un grupo de anotadores clasific\u00f3 los nombres con IDF 0,900 en dos grupos: los nombres que , tal y como indica esta medida , se descartan por ser especializados o porque pertenecen a la lengua general (G1) y los nombres que deben seguir un proceso de revisi\u00f3n posterior (G2). En la segunda fase (F2) , en la que se incluyen los nombres clasificados en el G2, identificamos las colocaciones extra\u00eddas que contienen dichos nombres como bases para analizar su distribuci\u00f3n y el n\u00famero de colocativos con los que se combina . En este proceso , algunas bases se descart an, otras bases se reincluyen en la lista inicial y otro grupo de bases se seleccio na para revisar en la siguiente fase. Por \u00faltimo, e n la tercera fase (F3) , contrastamos los equivalente s de los nombres en cuatro listas de ingl\u00e9s acad\u00e9mico ( AVL, AWL, AKL, y la lista de palabras acad\u00e9micas de Collocaid). En la Figura 1, exponemos el proceso seguido: Figura 1. Proceso para filtrar los nombres de la SpAKWL En las siguientes secciones, se explica en detalle el proceso que llevamos a cabo en las tres fases. 3.1. C lasificaci\u00f3n de las bases a partir del resultado del IDF Una vez identificados los 119 nombres que est\u00e1n por encima del punto de corte del IDF, un grupo de anotadores conformado por tres ling\u00fcistas los clasific\u00f3 en dos grupos . En el G1 se incluyeron los nombres que, tras observar los ejemplos en contexto en el corpus HE y con la ayuda de los diccionarios para analizar los sentidos y las marcas de especialidad, resultaron ser terminol\u00f3gicos o m\u00e1s asociados a un n\u00famero reducido de disciplinas. Tambi\u00e9n se incluyeron aquellos nombres que presentan una frecuencia elevada en los corpus de lengua genera l, utilizando herramientas de corpus para consultar su frecuencia, como el corpus de esTenTen en IDF F1: Clasificaci\u00f3n de bases F2: An\u00e1lisis de colocaciones F3: Contraste con vocabulario ingl\u00e9s Eleonora Guzzi, Margarita Alonso Ramos 86Sketch Engine (Kilgariff y Renau, 2013) . En el G2 se incluyeron los nombres que , en cambio, requieren un an\u00e1lisis posterior por no mostrar indicios claros sobre su interdiscipli nariedad. En funci\u00f3n de l descarte o mantenimiento, se les asignaron puntuaciones a los nombres . Por ejemplo, encontramos casos como el de la palabra fracci\u00f3n , que se descarta (=0), e indicaci\u00f3n, que pasa a una siguiente fase (=an\u00e1lisis) (Tabla 1) : Fase 1 fracci\u00f3n 0 indicaci\u00f3n an\u00e1lisis Tabla 1. Ejemplo de puntuaci\u00f3n asignada a nombres a descartar o analizar en la F1 . 3.2.An\u00e1lisis de colocaciones En esta fase analizamos las bases clasificadas en el G2 (n=54) , con el fin de llevar a cabo una valoraci\u00f3n acerca del n\u00famero de colocativos, que se asocia a la riqueza del vocabulario, as\u00ed como de la distribuci\u00f3n de las colocaciones que conforman, relacionada con la interdisciplinariedad . En este sentido, una base que se combina con varios colocativos y que forma colocaciones que est\u00e1n bien distribuidas en los textos acad\u00e9micos deber\u00eda incluirse en la lista de nombres acad\u00e9micos. Para analizar la distribuci\u00f3n de las colocaciones, se representa ron las frecuencias de las colocaciones en cada dominio (AH, CS, CF, BM) en forma de porcentajes, se calcul\u00f3 la desviaci\u00f3n est\u00e1ndar (DE), y se indic\u00f3 el n\u00famero de subdominios en los que aparece cada colocaci\u00f3n. Los valores de la DE oscilaro n entre 0,00 y 0,50: cuanto m\u00e1s bajo es el valor, m\u00e1s homog\u00e9nea es la distribuci\u00f3n de la colocaci\u00f3n en los textos de los cuatros dominios. En cuanto a los criterios de an\u00e1lisis de las colocaciones que contienen los nombres acad\u00e9micos, consideramos los tres par\u00e1metros: una colocaci\u00f3n es interdisciplinar si presenta una DE entre 0,00 y 0,24, si se aproxima a un porcentaje de 20% en al menos tres dominios o bien en dos dominios, uno perteneciente a \"ciencias duras\" (CF y BM) y otro a \"ciencias blandas\" (CS y AH) y si aparece en 3 subdominios. Por lo tanto, si las colocaciones analizadas con un nombre del G2 est\u00e1n bien distribuidas, como, por ejemplo, la colocaci\u00f3n alcanzar difusi\u00f3n (Tabla 2), el nombre, en este caso difusi\u00f3n, recibe una puntuaci\u00f3n = 1 y se mantiene: DE Dom. Sub. = alcanzar difusi\u00f3n 0,27 AH 50% 5 Distri. alta CS 12,5% CF 12,5% BM 25% Tabla 2. An\u00e1lisis de una colocaci\u00f3n con distribuci\u00f3n alta (homog\u00e9nea) . Por el contrario, si las colocaciones que se forman a partir de un nombre presentan una DE entre 0,36- 0,50, aproximadamente, una frecuencia de 0% en tres dominios o 90% en un dominio, y aparece solamente en uno o dos subdominios (Tabla 3) , la base, en este caso, abundancia , con una puntuaci\u00f3n = 0, se descarta: DE Dom. Sub. = abundancia mayor 0,47 BM 97% 2 Distr i. baja CF 3% Tabla 3. An\u00e1lisis de una colocaci\u00f3n con distribuci\u00f3n baja ( heterog\u00e9nea). Los nombres que pasan a la siguiente fase de revisi\u00f3n (F3) en la que se contrastan con las posibles equivalencias en las listas de ingl\u00e9s, y que reciben una puntuaci\u00f3n = an\u00e1lisis , son aquellas bases que en este proceso presentan colocaciones que oscilan entre l os l\u00edmite s de una distribuci\u00f3n homog\u00e9nea y heterog\u00e9nea . Esto es, en este grupo se incluyen las bases cuyas colocaciones presentan una DE entre 0,25 y 0,35, aproximadamente, a parecen en dos dominios de un \u00fanico grupo ( \"ciencias \"duras\" / \"ciencias blandas\"), pero con porcentajes equilibrados , o en tres subdominios de forma desequilibrada (Tabla 4): DE Dom . Sub. = indicaci\u00f3n precisa 0,33 CS 18% 3 Distr i. media AH 9% BM 73% Tabla 4. An\u00e1lisis de una colocaci\u00f3n que requiere un an\u00e1lisis posterior. Selecci\u00f3n de colocaciones acad\u00e9micas en espa\u00f1ol a trav\u00e9s de un filtro de interdisciplinariedad 87Asimismo, pasan a la fase de revisi\u00f3n 3 un n\u00famero reducido de bases que no presentan ning\u00fan colocativo productivo a nivel fraseol\u00f3gico de entre todos los candidatos extra\u00eddos, como, por ejemplo, el nombre tipolog\u00eda . Ah\u00ed decidimos su mantenimiento o descarte para formar parte de una nueva lista de nombres acad\u00e9micos. En la siguiente Tabla (5) mostramos las puntuaciones de tres bases que, tras el an\u00e1lisis colocacional, reciben puntuaciones distintas: Fase 1 Fase 2 abundancia 1 0 indicaci\u00f3n 1 an\u00e1lisis difusi\u00f3n 1 1 Tabla 5. Ejemplos de puntuaciones asignadas a bases a descartar, analizar o incluir en la F2 . 3.3. Contraste con listas de vocabulario de ingl\u00e9s acad\u00e9mico En esta \u00faltima fase se analizaron las bases que presentaron dudas tras pasar por el an\u00e1lisis colocacional y aquellos nombres que no han podido analizarse en la fase 2 , debido a que no presentaron ning\u00fan colocativo. Se seleccionaron cuatro listas de palabras acad\u00e9micas en ingl\u00e9s para el an\u00e1lisis: AKL, AVL, AWL y la lista de palabras acad\u00e9micas de Collocaid. A partir de los nombres seleccionados en la fase anterior, se realiz\u00f3 una comparativa con las palabras acad\u00e9micas pertenecientes a las cuatro listas para encontrar su equivalente en ingl\u00e9s. En el proceso de b\u00fasqueda de los equivalentes, se consultaron dos diccionarios, el Oxford English Dictionary y el Cambridge Dictionary, tanto la versi\u00f3n biling\u00fce espa\u00f1ol - ingl\u00e9s como la monoling\u00fce , as\u00ed como el corpus paralelo Linguee para observar ejemplos en contexto. A la hora de buscar la equivalencia de cada nombre , se consideraron las diferentes traducciones posibles debido a la presencia de polisemia. Se considera que una palabra coincide con dos o m\u00e1s listas si en cada lista se presenta la traducci\u00f3n asociada a un mismo sentido, por ejemplo, la palabra cultura presenta su correspondencia en las cuatro listas con el nombre en ingl\u00e9s culture. Sin embargo, se dan otros casos en los que una palabra se traduce de distintas formas dependiendo del sentido que se adopte en cada una de ellas: por ejemplo, la palabra se\u00f1al se traduce en la AVL con el sentido asociado a signal, mientras que en la lista de Collocaid y en la AKL solamente se encuentra el equivalente de otro sentido, indication. En estos casos, se considera el n\u00famero de listas coincidentes para cada sentido: s e\u00f1al puede coincidir con una lista (la AVL) o dos listas (Collocaid y AKL), en funci\u00f3n del sentido. En relaci\u00f3n con el criterio para filtrar la lista de nombres, se estableci\u00f3 un \u00edndice de 2, es decir, si un nombre aparece en al menos dos de las cuatro listas se mantiene. Por el contrario, las palabras que coinciden \u00fanicamente con una lista o que no coinciden con ninguna finalmente sedescartan. Fijamos este \u00edndice debido a que la AWL aplica criterios m\u00e1s restringidos y no incluye palabras que tambi\u00e9n pertenecen a la lengua general, lo que provoca un porcentaje de correspondencia bajo porque en el vocabulario acad\u00e9mico espa\u00f1ol se recogen palabras compartidas con la lengua general. En la Tabla 6 , podemos observar los ejemplos con las respectivas puntuaciones de nombres que se analizan en la fase 3 , que inclu yen tanto nombres que presentaron colocativos en la F2 (ej. indicaci\u00f3n o especificaci\u00f3n ), como aquellos que no presentaron ning\u00fan colocativo (ej. tipolog\u00eda o almacenamiento ): Fase1 Fase2 Fase3 = almacenamiento 1 an\u00e1lisis (no coloc.) 0 1 tipolog\u00eda 1 an\u00e1lisis (no coloc.) 1 2 especificaci\u00f3n 1 an\u00e1lisis 0 1 indicaci\u00f3n 1 an\u00e1lisis 1 2 Tabla 6. Ejemplos de puntuaciones asignadas a nombres a descartar o incluir en la F3 . 4 Resultados La lista resultante se compone de 5 19 nombres acad\u00e9micos (Anexo 2) , en contraste con los 602 nombres iniciales. La clasificaci\u00f3n de los nombres en cada fase ha sido el resultado de las puntuaciones asignadas a cada uno de ellos. Una Eleonora Guzzi, Margarita Alonso Ramos 88 puntuaci\u00f3n final de 2 implic\u00f3 la reinclusi\u00f3n del nombre a la lista inicial y una puntuaci\u00f3n de 0 o 1 conllev\u00f3 su descarte. En la primer a fase (F1), se descartaron 65 nombres, con una puntuaci\u00f3n de 0, entre los cuales encontramos ejemplos como emisi\u00f3n, fracci\u00f3n, tejido, geometr\u00eda, prevenci\u00f3n, infraestructura, etc. Por otra parte, se mantuvieron 54 nombres que pasaron a una siguiente revisi\u00f3n, con una puntuaci\u00f3n de 1, como \u00e9nfasis, concordancia, fiabilidad, puntuaci\u00f3n, descenso, almacenamiento, procesamiento, entre otros . En cuanto a la fase de revisi\u00f3n de las colocaciones (F2), 6 bases se descartaron, como especificaci\u00f3n, asignaci\u00f3n o resto ; 29 bases pasaron a la fase 3, como trayectoria, gr\u00e1fico, indicaci\u00f3n o premisa ; y 19 bases se reincluyeron en la lista inicial por cumplir con el criterio de n\u00famero y distribuci\u00f3n de las colocaciones, como sesgo, producti vidad, predominio o est\u00e1ndar . Por \u00faltimo, en la fase 3, de los nombres que se contrastaron con las listas de palabras acad\u00e9micas en ingl\u00e9s, se descartaron l 2 nombres, entre los cuales encontramos ejemplos como correcci\u00f3n, concordancia y fiabilidad, ya que sus posibles equivalente s en ingl\u00e9s no aparec\u00edan en ninguna lista de ingl\u00e9s y almacenamiento, formulaci\u00f3n, asignaci\u00f3n, acumulaci\u00f3n, regulaci\u00f3n, procesamiento, trayectoria, afirmaci\u00f3n y barrera porque aparec\u00edan \u00fanicamente en una lista. Por ejemplo, de la palabra regulaci\u00f3n \u00fanicamente encontramos un posible equivalente en la AVL como adjustment. Sin embargo, se reincluyeron 17 nombres : gr\u00e1fico, indicaci\u00f3n, reproducci\u00f3n y experto, que aparec\u00edan en dos listas; heterogeneidad, premisa, variante, diferenciaci\u00f3n, bibliograf\u00eda, tipolog\u00eda, desempe\u00f1o, instancia, supuesto y uni\u00f3n, que aparec\u00eda n en tres listas, y paradigma, v\u00ednculo y rol, cuyos equivalentes aparecieron en las cuatro listas. Por ejemplo, la palabra instancia aparece como instance en la AVL, en la AKL y en la lista de Collocaid . A modo de resumen, en la Tabla 7, mostramos el n\u00famero de nombres descartados, analizados o reincluidos en cada fase: F1 F2 F3 TOTAL Descarte 65 6 12 83 An\u00e1lisis 54 29 - 83 Reinclusi\u00f3n - 19 17 36 TOTAL 54 29 119 Tabla 7. N\u00ba de nombres clasificados en cada fase . 5 Discusi\u00f3n La medida IDF ha permitido detectar las palabras clave de determinados documentos del corpus y, en consecuencia, aquellos nombres empleados m\u00e1s espec\u00edficamente en algunas de las \u00e1reas cient\u00edficas en las que est\u00e1 dividido el corpus HE. Cabe destacar que la decisi\u00f3n del punto de corte en la palabra potencia (IDF =0,900) ha implicado que un n\u00famero reducido de nombres, como software o regresi\u00f3n , no se descartaran a pesar de presentar un valor alto de IDF (cerca de 0,800) y de ser especializados. Sin embargo, hemos optado por no establecer un punto de corte m\u00e1s bajo debido a que se habr\u00eda descartado una gran parte de nombres acad\u00e9micos relevantes, como disciplina, discurso, s\u00edntesis, entre otros. De los dos conjuntos de nombres obtenidos con el IDF, contrastamos la dispersi\u00f3n de algunas pal abras con un alto valor de IDF con algunas palabras con valores m\u00e1s bajos en los art\u00edculos de cada subdominio. En efecto, observamos que la frecuencia y distribuci\u00f3n no es proporcionada en el corpus en el primer caso (IDF alto) , pero s\u00ed en el segundo (IDF bajo) . En la Figura 1, podemos observar este comportamiento en una muestra de seis nombres con valores altos de IDF (IDF>1 ,06), es decir, menos distribuidos en los textos, y en la F igura 2, seis nombres con valor es muy bajos (IDF<0.05) . Para facilitar su lectura, presentamos la distribuci\u00f3n de los nombres por subdominio en lugar de por art\u00edculos: Selecci\u00f3n de colocaciones acad\u00e9micas en espa\u00f1ol a trav\u00e9s de un filtro de interdisciplinariedad 89Figura 2. Seis nombres con IDF >1,05 3. Seis nombres con IDF <0,05 . C omo se puede apreciar , los nombres e n la Figura 3 presentan una dispersi\u00f3n m\u00e1s homog\u00e9nea que en la Figura 2. Por ejemplo , el nombre episodio presenta un gran predomi nio en los subdominios de F\u00edsica y Qu\u00edmica y Medicina, y no aparece en 3 de los 12 subdominios, mientras que el nombre an\u00e1lisis est\u00e1 bien distribuido, con ocurrencias proporcionales en los 12 subdominios. En la primera fase de clasificaci\u00f3n d e los posibles nombres que se descartar\u00edan por el IDF , la mayor\u00eda se pudo clasificar en funci\u00f3n de su especificidad en determinadas disciplinas , gracias al an\u00e1lisis de los contextos en los que aparecen dichas palabras en el corpus, as\u00ed como a la ayuda de los diccionarios, como, por ejemplo, los nombres geometr\u00eda o motor . Sin embargo, en l\u00ednea con la problem\u00e1tica expuesta en la secci\u00f3n 1 , se llev\u00f3 a cabo una revisi\u00f3n m\u00e1s exhaustiva especialmente de aquell os nombres que se encuentran en un continuum entre la lengua general y la lengua acad\u00e9mica, p.ej. rol, as\u00ed como de los nombres polis\u00e9micos como barrera, que presenta un s entido m\u00e1s metaf\u00f3rico de 'obst\u00e1culo' , y otro sentido de 'valla [...] u otro obst\u00e1culo semejante con que cierra el paso ' (DLE, f.s., def. 1), con el fin de identificar los sentidos m\u00e1s productivos en el discurso acad\u00e9mico. En relaci\u00f3n con el an\u00e1lisis de las colocaciones (F2), un n\u00famero muy reducido de nombres acad\u00e9micos presentaron \u00fanicamente un colocativo . En estos casos, si la colocaci\u00f3n no present \u00f3 un nivel medio -alto de distribuci\u00f3n, la base se elimin \u00f3. Por ejemplo, con el nombre especificaci\u00f3n , \u00fanicamente se identific\u00f3 el colocativo cumplir , y la colocaci\u00f3n present\u00f3 una distribuci\u00f3n heterog\u00e9nea, con un 93% de ocurrencias en Ciencias F\u00edsicas ( ejemplo 1 ): (1)\"Se dise\u00f1\u00f3 la estructura de pavimentocon agregados de La Calera, por cumplir con todas las especificaciones\". P or otra parte, la gran mayor\u00eda de nombres acad\u00e9micos presentaron 2 colocativo s, por lo que fue necesario un an\u00e1lisis m\u00e1s detallado de la distribuci\u00f3n de cada colocaci\u00f3n para definir una media. Por ejemplo, con la base productividad, se identificaron los colocativos aumento, alta y mayor, que tienen una distribuci\u00f3n medio-alta, como productividad alta, que presenta un 40% de ocurrencias en Ciencias F\u00edsicas, un 40% en Biolog\u00eda y Medicina y un 20% en Artes y Humanidades, una DE de 0,19, y aparece en 3 subdominios. Los casos que conllevaron m\u00e1s dudas se corresponden con aquellas bases que presentan 2 -3 colocati vos y una distribuci\u00f3n media de colocaciones. Por ejemplo, con la base indicaci\u00f3n se identificaron los colocativos clara y precisa : la colocaci\u00f3n indicaci\u00f3n precisa presenta una distribuci\u00f3n homog\u00e9nea, con una DE de 0,3 2, un porcentaje de aparici\u00f3n de un 9% en Artes y Humanidades, un 1 9% en Ciencias Sociales y un 72% en Biolog\u00eda y Medicina, y una aparici\u00f3n en 4 subdominios; sin embargo, la colocaci\u00f3n indicaci\u00f3n clara \u00fanicamente aparece 050100150200250300350400450 premisa especialista sustrato d\u00e9ficit episodio exclusi\u00f3n 05001000150020002500 an\u00e1lisis resumen trabajo tipo forma resultado Eleonora Guzzi, Margarita Alonso Ramos 90 en los dominios de \"ciencias blandas\" , con un 22% de ocurrencias en Artes y Humanidades y un 78% en Ciencias Sociales, una DE de 0,37 y una aparici\u00f3n en 3 subdominios. Debido a que \u00fanicamente se presentan dos colocaciones y la media de su distribuci\u00f3n no proporciona indi cios definitivos sobre su inclusi\u00f3n o descarte como base acad\u00e9mica, en estos casos se contrasta el nombre con las listas de vocabulario acad\u00e9mico en ingl\u00e9s. Cabe destacar que, en esta fase, tambi\u00e9n se identificaron 16 nombres que no presentaron ning\u00fan colocativo y, por lo tanto , no pudieron analizarse y pasaron a la fase 3. Como hemos mencionado en la secci\u00f3n 1, a pesar de que el objetivo principal del presente trabajo sea filtrar la lista de colocaciones acad\u00e9micas, los nombres sin colocativos se incluyen en este an\u00e1lisis con el prop\u00f3sito de obtener tambi\u00e9n una lista completa y m\u00e1s refinada de nombres acad\u00e9micos del espa\u00f1ol. El an\u00e1lisis de las colocaciones tambi\u00e9n ha ofrecido indicios sobre el contraste de uso de las colocaciones en la lengua general y la lengua acad\u00e9mica: la col ocaci\u00f3n jugar un rol no presenta una frecuencia alta ni una buena distribuci\u00f3n en el discurso acad\u00e9mico, pues su uso es m\u00e1s extendido en la lengua general, mientras que desempe\u00f1ar y ejercer un rol presentan una distribuci\u00f3n m\u00e1s homog\u00e9nea entre los dominios y una frecuencia ligeramente mayor en el discurso acad\u00e9mico. A su vez, hemos podido observar casos en los que un nom bre puede combinarse con colocativos y conformar colocaciones que est\u00e1n distribuidas de forma m\u00e1s homog\u00e9nea que con otros colocativos: por ejemplo, con la base puntuaci\u00f3n, identificamos la colocaci\u00f3n otorgar una puntuaci\u00f3n, que presenta una buena distribuci\u00f3n, con un 14% de apariciones en AH, un 57% en CS , y un 39% en CF, y con una DE de 0,24; contrariamente, la colocaci\u00f3n puntuaci\u00f3n m\u00ednima , presenta un distribuci\u00f3n heterog\u00e9nea, con un 14% de ocurrencias en CS y un 86% en CF, una DE de 0,41 y con presencia \u00fanicamente en 2 subdo minios. Estos casos indican que la base debe ser incluida en la list a, ya que es un nombre utilizado frecuentemente en distintos textos acad\u00e9micos, pero constituye colocaciones que se utilizan con m\u00e1s frecuencia en algunas disciplinas que en otras, probablemente debido a la variedad disciplinar. En definitiva, hemos observado que los nombres que han tenido que pasar por distintas fases de an\u00e1lisis se corresponden especialmente con los nombres polis\u00e9micos, que poseen al menos dos sentidos distintos (ej. barrera ) y los nombres que tambi\u00e9n se utilizan frecuentemente en la lengua general y, por lo tanto, no evidencian su especificidad en el discurso acad\u00e9mico, como los nombres uni\u00f3n o rol. 6 Conclusiones En este art\u00edculo se ha presentado una metodolog\u00eda para proponer una lista de nombres del discurso acad\u00e9mico en espa\u00f1ol a partir de la lista SpAKWL (Garc\u00eda-Salido 2021) , aplicando criterios que identifiquen mejor la interdisciplinariedad. Aunque el objetivo principal es obtener una lista de colocaciones acad\u00e9micas que se integrar\u00e1 en HARTA, como objetivo secundario, hemos obtenido una lista de nombres acad\u00e9micos m\u00e1s protot\u00edpicos del discurso acad\u00e9mico. Partiendo de la medida de IDF que es com\u00fanmente utilizada para identificar de forma autom\u00e1tica los nombres m\u00e1s asociados a la terminolog\u00eda, hemos a plicado diferentes an\u00e1lisis para valorar su efectividad y corroborar que los nombres identificados pueden descartarse. Los resultados han demostrado que con esta metodolog\u00eda es posible identificar la interdisciplinariedad y establecer la lista de nombres acad\u00e9micos junto con una lista de colocaciones que puedan ser integradas en una herramienta que ayude a redactar textos acad\u00e9micos (HARTA) . Espec\u00edficamente, se ha obtenido un criterio para eliminar la terminolog\u00eda e identificar el vocabulario que puede ser utilizado independientemente de la disciplina y que ayuda a describir actividades y procesos acad\u00e9mico -cient\u00edficos y a estructurar la argumentaci\u00f3n. No obstante, los resultados siguen remarcando la necesidad de desambiguar los sentidos de las palabras y la posibilidad de que, aunque las bases sean interdisciplinares en Selecci\u00f3n de colocaciones acad\u00e9micas en espa\u00f1ol a trav\u00e9s de un filtro de interdisciplinariedad 91el discurso acad\u00e9mico, las colocaciones pueden utilizarse en unas disciplinas m\u00e1s que en otras. El presente estudio forma parte de un proyecto de investigaci\u00f3n m\u00e1s amplio, en el cual, a partir de este trabajo, planteamos integrar la nueva versi\u00f3n de la SpAKWL en HARTA de manera que, a partir de un texto, la herramienta pueda detectar las palabras acad\u00e9micas y sugerir las colocaciones correspondientes, en l\u00ednea con lo que proponen herramientas como LEAD (Paquot 2012) o Collocaid (Frankenberg-Garci a et al. 2019) para la escritura acad\u00e9mico - cient\u00edfica en ingl\u00e9s . Agradecimientos Este estudio ha sido posible gracias a la financiaci\u00f3n del Ministerio de Ciencia e Innovaci\u00f3n (PID2019- 109683GB -C21) ; del Centro de Investigaci\u00f3n de Galicia \"CITIC\", financiado por la Xunta de Galicia y la Uni\u00f3n Europea (FEDER GALICIA 2014 -2020), con la ayuda ED431G 2019/01; y del Programa de Axudas \u00e1 Etapa predoutoral da Xunta de Galicia, FSE Galicia 2014 -2020. Bibliograf\u00eda Ackermann, K. y Chen, Y.H. 2013. D eveloping the Academic , 12(4) : 235-247. Ahumada, I., Zamorano, J. P., Garc\u00eda, E. D. R. y Lara, I. A. 2011 . Design and development of Iberia: a corpus of scientific Spanish. Corpora, 6 (2): 145-158. Alonso -Ramos, M., Garc\u00eda-Salido, M. Proceedings of eLex 2017 conference, p\u00e1ginas 571- 586. Leiden, the Netherlands. Cambridge Dictionary. Consultado el 27 de marzo de 2022 en: https://dictionary.cambridge.org/us/dicti onary/. Cobb, T., y Horst, M. 2004. Is there room for a n academic word list in French?. En P. Bogaards y B. Laufer (E ds.), Vocabulary in a Second Language. Selection, acquisition, and testing , p\u00e1ginas 13-38, John Benjamins (Amsterdam/Philadelphia). A., R., Roberts, J. C., Rees, G. P., y Sharma, N. 2019. Developing a writing assistant to help EAP writers with collocations in real time. ReCALL, 31(1): -Salido, M. 2021. Vocabulary List of Spanish. Disponible en: https://doi.org/10.13140/RG.2.2.27681.3312 3. Garcia, M. y Gamallo, P. 2016. Yet another suite of multilingual NLP tools. En J. P. Leal J. L. SierraRodr\u00edguez et al. (Eds.), Languages, Appl ications and Technologies. Communications in Computer and Information Science , p\u00e1ginas 65- 75, Springer ( Cham ). Gardner, D., y Davies, list. Applied Linguistics M. 2007 . Learner corpora: The missing link in English for Academic Purposes, Hatier, Augustyn, M., Tran, T. T. H., Yan, R., Tutin, A., y Jacques, M. P. 2016. French cross-disciplinary scientific lexicon: extraction and linguistic Ivane Javakhishvili Tbilisi State University (Tbilsi). Eleonora Guzzi, Margarita Alonso Ramos 92Hyland, K. y Tse, P. 2007 1972 . A statistical interpretation of term specificity and its application in retrieval. Journal of documentation, 11-21. Kilgarriff, A. y Renau, I. 2013. esTenTen , a vast web corpus of Peninsular and -Social Behavioral Kov \u00e1, V., Michelfeit, J. y Suchomel, V. 2014. The Sketch Engine: t en years on. Lexicography , 1(1): 7-36. Lei, L., y Liu, D. 2018. The academic English collocation list: A corpus -driven , 23(2): 216-243. LINGUEE . 2022 en: http://www.linguee.es. Mel'uk, I. 2012. Phraseology in the language, in the dictionary, and in the computer. Yearbook of C. D., Mcdonald, R., Petrov, S., Pyysalo, S., Silveira, N., Tsarfaty, R. y Zeman, D. 2016. Universal Dependencies v1: A Treebank Collection. En Proceedings of onal on Language Resources and Evaluation (LREC 2016), p\u00e1ginas 1659- 1666, European Language Resources Association (ELRA). Oxford English Dictionary. Consultado el 27 de marzo de 2022 en: y https://www.oed.com/ . et al., (Eds.), Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC2012), p\u00e1ginas 2473- 2479, European K. Kredens, y S. Gozdz Roszkowski (Eds.), Practical Applications in L anguage and Computers 2005, p\u00e1ginas 127-140 . Peter Lang (Frankfurt am main). Paq uot, M., y Bestgen, Y. 2009 . Distinctive words in academic Language and Computers , 68(1): 247 2012. The LEAD dictionary -cum- writing aid: An integrated dictionary and corpus tool . En S. Granger y M. Paquot (Eds.), Eletronic lexicography, p\u00e1ginas 161- 186, Oxford University Press (Oxford). Real Academia Espa\u00f1ola: Diccionario de la lengua espa\u00f1ola, 23.\u00aa ed., (versi\u00f3n 23.5 en l\u00ednea). Consultado el 25 de marzo de 2022 en: https://dle.rae.es. Sebasti\u00e1n -Gall\u00e9s, N., Mart\u00ed Anton\u00edn, M.A., Carreiras Vali\u00f1a, M. F., y Cuetos Vega, F. 2000. LEXESP: L\u00e9xico informatizado del espa\u00f1ol . Barcelona: Edicions de la Universitat de Barcelona. Straka, M., Hajic, J. y Strakov\u00e1, J. En Proceedings of the 10th International Conference on Language Resources and Evaluation (LREC 2016), p\u00e1ginas 1659- 1666, A. 5 - 14. A Anexo 1: Nombres descartados a partir del IDF premisa, trayectoria, especialista, d\u00e9ficit, sustrato, concordancia, trabajador, exclusi\u00f3n, ciudadano, episodio, fiabilidad, ejemplar, prioridad, geometr\u00eda, infraestructura, se\u00f1al, madurez, patolog\u00eda, creencia, amplitud, reproducci\u00f3n, paradi gma, procedencia, almacenamiento, implantaci\u00f3n, complicaci\u00f3n, correcci\u00f3n, apertura, desplazamiento, motor, tipolog\u00eda, venta, puntuaci\u00f3n, consenso, Selecci\u00f3n de colocaciones acad\u00e9micas en espa\u00f1ol a trav\u00e9s de un filtro de interdisciplinariedad 93ejecuci\u00f3n, dispositivo, meta, asignaci\u00f3n, autonom\u00eda, lector, continuidad, carencia, compuesto, bibliograf\u00eda, supuesto, costo, normativa, emisi\u00f3n, correspondencia, variante, especificaci\u00f3n, instalaci\u00f3n, reto, experto, descenso, uni\u00f3n, formulaci\u00f3n, expectativa, puesta, mediana, motivaci\u00f3n, v\u00ednculo, inconveniente, departamento, productividad, desempe\u00f1o, incertidumbre, plataforma, tejido, tensi\u00f3n, experimento, diferenciaci\u00f3n, econom\u00eda, barrera, satisfacci\u00f3n, requerimiento, dosis, sesgo, acumulaci\u00f3n, entrevista, fundamento, regulaci\u00f3n, expansi\u00f3n, explotaci\u00f3n, transporte, abundancia, promoci\u00f3n, instancia, eliminaci\u00f3n, separaci\u00f3n, fracci\u00f3n, s\u00edntoma, heterogeneidad, efectividad, espectro, preferencia, difusi\u00f3n, presente, predominio, afirmaci\u00f3n, transferencia, aceptaci\u00f3n, gr\u00e1fico, distinci\u00f3n, prevenci\u00f3n, sugerencia, dispersi\u00f3n, fragmento, \u00e9nfasis, varianza, canal, indicaci\u00f3 n, estadio, iniciativa, rol, procesamiento, transici\u00f3n, est\u00e1ndar, potencia. B Anexo 2: Nombres descartados tras las tres fases emisi\u00f3n, fracci\u00f3n, tejido, geometr\u00eda, puesta, presente, prevenci\u00f3n, ciudadano, compuesto, sustrato, trabajador, infraestructura, transferencia, carencia, explotaci\u00f3n, estadio, transici\u00f3n, transporte, exclusi\u00f3n, varianza, ejemplar, venta, departamento, entrevista, s\u00edntoma , dosis, patolog\u00eda, episodio, creencia, madurez, costo, abundancia, espectro, fragmento, iniciativa, econom\u00eda, aut onom\u00eda, potencia, prioridad, dispositivo, expectativa, incertidumbre, dispersi\u00f3n , preferencia, tensi\u00f3n , inconveniente, d\u00e9ficit, amplitud, desplazamiento, plataforma, requerimiento, expansi\u00f3n, separaci\u00f3n, implantaci\u00f3n, complicaci\u00f3n , concordancia, fiabilidad, trayectoria, resto, afirmaci\u00f3n, barrera, correcci\u00f3n, almacenamiento , formulaci\u00f3n , acumulaci\u00f3n, regulaci\u00f3n , procesamiento, especificaci\u00f3n, efectividad, fundamento, distinci\u00f3n, asignaci\u00f3n. Eleonora Guzzi, Margarita Alonso Ramos 94Compilaci\u00f3n del corpus acad\u00e9mico de noveles en euskera HARTA eus y su explotaci\u00f3n para el estudio de la fraseolog\u00eda acad\u00e9mica Compilation of the academic corpus of novels in Basque HARTAeus and its exploitation for the study Antton Gurrutxaga,2 Igone Centro HiTZ- Ixa, (UPV/EHU) 2 Fundaci\u00f3n Elhuyar {maxux.aranzabe,igone.zabala}@ehu.eus, a.gurrutxaga@elhuyar.eus Resu men: Se ha compilado un corpus acad\u00e9mico de noveles para el e uskera comparable con el corpus HARTA- noveles para el espa\u00f1ol. A partir del corpus se ha extra\u00eddo una lista de vocabulario acad\u00e9mico para el euskera, y sendas listas de colocaciones y f\u00f3rmulas, a las que se les han asignado funciones discursivas. El objetivo \u00faltimo del proyecto HARTAes -vas, en el que se enmarca este trabajo , es dise\u00f1ar una herramienta de ayuda a la escritura acad\u00e9mica para las dos lenguas centrada en las combinaciones l\u00e9xicas acad\u00e9micas, que integre diccionario y corpu s. Palabras clave: corpus acad\u00e9mico, colocaciones, lexical academic corpus of was compiled for Basque, comparable to the corpus HARTA- noveles for Spanish. A list of academic Basque vocabulary, collocations and formulas were e xtracted from the corpus, and then they were assigned discursive functions. The ultimate objective of the HARTAes , in which this work is framed , is to design a tool to help academic writing for Basque and Spanish focused on academic discursive functions. Introducci\u00f3n La introducci\u00f3n del euskera en \u00e1mbitos acad\u00e9micos , incluidos los de la educaci\u00f3n superior, que se produjo a principios de la d\u00e9cada de 1980, ha sido crucial para su revitalizaci\u00f3n (Zabala, 2019), ya que ha contribuido de forma muy significativa al aumento del n\u00famero de hablantes y al desarrollo de los recursos expresivos necesarios para la comunicaci\u00f3n especializada. Sin embargo, \u00bfpodemos decir que el euskera ha \"conquistado\" los dominios acad\u00e9micos en el sentido de Laur\u00e9n et al. (2002)? Dicho en otras palabras, \u00bfel euskera ha desarrollado los recursos expresivos necesarios para la comunicaci\u00f3n acad\u00e9mica en los diferentes \u00e1mbitos de especialidad? Laur\u00e9n et al. (2002) defienden que a esta pregunta se puede responder de forma individual o de forma colectiva. A nivel individual, los estudiantes universitarios adquieren los registros acad\u00e9micos necesarios p ara convertirse en miembros de la comunidad de expertos de su \u00e1rea gracias a numerosas tareas en las que el lenguaje resulta crucial (Biber, 2006). Algunos autores defienden que los textos acad\u00e9micos se elaboran siguiendo esquemas discursivos prefabricados que utilizan unidades fraseol\u00f3gicas semiautom\u00e1ticas (Paquot, 2018), a las que nos referiremos de forma general como combinaciones l\u00e9xicas acad\u00e9micas (CLA). No es de extra\u00f1ar, por tanto, que las CLA del ingl\u00e9s hayan sido el objeto de estudio de numerosas i nvestigaciones de ling\u00fc\u00edstica de corpus con fines aplicados. Este auge es f\u00e1cilmente explicable teniendo en cuenta el rol predominante del ingl\u00e9s como lengua acad\u00e9mica internacional y el gran n\u00famero de hablantes, principalmente, hablantes no-nativos, que necesitan recursos de ayuda para la Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 95-103 recibido aceptado 30-05-2022 ISSN 1135-5948. DOI 10.26342/2022-69-8 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Naturalredacci\u00f3n de art\u00edculos cient\u00edficos y de trabajos acad\u00e9micos en general. Posteriormente, tambi\u00e9n se han ido extendiendo los proyectos de compilaci\u00f3n de corpus ac ad\u00e9micos y de estudio de las CLA a otras lenguas como el fran c\u00e9s, portugu\u00e9s de Brasil, sueco, noruego, dan\u00e9s y espa\u00f1ol (Alonso et al., 2017), ya que numerosos trabajos acad\u00e9micos se producen en las lenguas locales. Si bien podemos pensar que el ser hablante nativo de una lengua es un factor que puede facilitar la pr oducci\u00f3n de textos en dicha lengua, tambi\u00e9n est\u00e1 generalmente aceptado que no hay hablantes nativos de los registros acad\u00e9micos, y que \u00e9stos se adquieren gracias a la experiencia ling\u00fc\u00edstica de lectura y producci\u00f3n de textos acad\u00e9micos. Debido a la interna cionalizaci\u00f3n de la comunicaci\u00f3n acad\u00e9mica y del uso cada vez m\u00e1s extendido del ingl\u00e9s como lengua de instrucci\u00f3n y de elaboraci\u00f3n de trabajos acad\u00e9micos en la educaci\u00f3n superior, existe la preocupaci\u00f3n de que los estudiantes universitarios, e incluso los expertos tengan cada vez m\u00e1s dificultades para adquirir los recursos expresivos necesarios para la comunicaci\u00f3n acad\u00e9mica en L1 diferentes del ingl\u00e9s (Swales, 2000; G\u00f6rlach, 2012; Gotti , 2012). Es por esto que se hace necesario elaborar recursos y herramientas de ayuda a la escritura acad\u00e9mica tambi\u00e9n para otras lenguas. En el caso del euskera, la idea generalizada es que no ha habido suficiente tiempo para el desarrollo y estabilizaci\u00f3n de los registr os acad\u00e9micos (Zabala et al., 2011; Zabala et al., 2021), y la preocupaci\u00f3n por el impacto de la creciente internacionalizaci\u00f3n es a\u00fan mayor. Las CLA son segmentos de palabras recurrentes que pueden o no ser sem\u00e1nticamente composicionales y que cubren funciones ret\u00f3ricas como a\u00f1adir informaci\u00f3n, presentar ejemplos o expresar posibilidad. Incluyen colocaciones ( ondorioak atera \"extraer conclusiones\"), locuciones ( oro har \"en general\") y f\u00f3rmulas, que coinciden en gran medida con las denominadas en la literatura lexical bundles (azpimarratu beharra dago \"hay que remarcar\"). La recurrencia es el resultado de su uso frecuente en discursos compartidos por la comunidad acad\u00e9mica y, por lo tanto, las CLA constituyen un tipo de unidades privilegiadas para el estudio del nivel de desarrollo de los registros acad\u00e9micos del euskera. Este trabajo se enmarca en el proyecto HARTAes -vas, proyecto coordinado entre la Universida de da Coru\u00f1a y la Universidad del Pa\u00eds Vasco (UPV/EHU) y financiado por el Ministerio de Ciencia e Investigaci\u00f3n. El equipo de la Coru\u00f1a cuenta con un corpus de expertos y otro de noveles en espa\u00f1ol, compilados en un proyecto anterior, ha explotado dichos corpus para la extracci\u00f3n y clasificaci\u00f3n de CLA y ha desarrollado una herramienta de consulta de la fraseolog\u00eda acad\u00e9mica en espa\u00f1ol (Herramienta de Ayuda a la Escritura Acad\u00e9mica: HARTA ) 1 (Garc\u00eda - Salido et al., 2018). La colaboraci\u00f3n con el grupo de la Coru\u00f1a es fundamental para poder contar con elementos de comparaci\u00f3n entre dos lenguas que se difer encian por su tipolog\u00eda y por su situaci\u00f3n socioling\u00fc\u00edstica. E n este trabajo describimos el corpus acad\u00e9mico de noveles para el euskera compilado dentro del proyecto HARTAvas y su explotaci\u00f3n para el estudio de la fraseolog\u00eda acad\u00e9mica de cara a crear una herramienta de consulta coordinada con HARTAes , que ayude a la escritura acad\u00e9mica en euskera, y que contribuya al desarrollo y estabilizaci\u00f3n de los registros acad\u00e9micos en dicha lengua. Hemos elaborado un corpus comparable con el corpus HARTA de noveles para el espa\u00f1ol (Villayandre, 2018; Garc\u00eda - Salido et al., 2018) con el fin de poder contrastar los resultados obtenidos para el euskera, que es una lengua aglutinante en proceso de normalizaci\u00f3n, con los obtenidos para el espa\u00f1ol, lengua flexiva y bien desarrollada. En el apartado 2 describimos la constituci\u00f3n del corpus de noveles HARTAeus. El apartado 3 lo dedicamos a la extracci\u00f3n , validaci\u00f3n y an\u00e1lisis de las f\u00f3rmulas y colocaciones acad\u00e9micas a partir del corpus. Finalmente, los apartados 4 y 5 recogen los resultados y conclusiones obtenidos hasta el momento. 2 Cons tituci\u00f3n del corpus HARTA eus El corpus HARTAeus de noveles para el vasco est\u00e1 constituido por Trabajos Fin de Grado (TFG) y Trabajos Fin de M\u00e1ster (TFM), por lo que se puede considerar una mues tra de la escritura acad\u00e9mica de los estudiantes universitarios. A l ser un corpus comparable con el corpus HARTA-noveles del espa\u00f1ol, su dise\u00f1o ha seguido los criterios definidos en la 1 http://www.dicesp.com:8083/search 96 Mar\u00eda Jes\u00fas Aranzabe, Antton Gurrutxaga, Igone Zabala creaci\u00f3n de \u00e9ste \u00faltimo (Villayandre, 2018). De este modo, los textos d el corpus HARTAeus est\u00e1n dividido s en cuatro secciones (Arte y Humanidades, Biolog\u00eda y Ciencias de la Salud, Ciencias F\u00edsicas y Ciencias Sociales) , que se dividen a su vez en distintos dominios tem\u00e1ticos como, por ejemplo, Biolog\u00eda y Medicina en la secci \u00f3n de Biolog\u00eda y Ciencias de la Salud ( ver A nexo 1 para la divisi\u00f3n del corpus en secciones y dominios). El proceso de compilaci\u00f3n ha comprendido seis fases: i) recolecci\u00f3n de documentos para el corpus: los documentos en formato PDF proceden en su mayor\u00eda del repositorio ADDI (Archivo Digital para la Docencia e Investigaci\u00f3n) de la Universidad del Pa\u00eds Vasco/Euskal Herriko Unibertsitatea (UPV/EHU); ii) normalizaci\u00f3n: se ha realizado la conversi\u00f3n al formato DOCX de los documentos originales con el fin de realizar la limpieza y ordenaci\u00f3n de las secciones y p\u00e1rrafos de los textos , y eliminar las marcas sobrantes; iii) codificaci\u00f3n: se han introducido las etiquetas que marcan el inicio y final de las distintas secciones de los textos ( t\u00edtulo, resumen, presen taci\u00f3n, introducci\u00f3n, cuerpo, metod olog\u00eda, resultados y discusi\u00f3n, conclusiones, agradecimientos, notas al pie de p\u00e1gina y anexos); iv) se han incorporado de manera autom\u00e1tica los textos en el entorno de trabajo Garaterm (Zabala et al, 2013) para su poster ior procesamiento; v) almacenamiento: se han anotado los metadatos y las secciones de los textos del corpus de referencia con etiquetas XML. Asimismo, se ha adaptado el conversor de TEI existente en la plataforma Garaterm con el fin de mantener la estructura y las etiquetas de XML utilizadas para marcar los apartados de los documentos originales, y vi) procesamiento: el corpus ha sido tokenizado, lematizado y analizado morfol\u00f3gicamente por medio de Eustagger (Alegr\u00eda et al., 2002), analizador morfol\u00f3gico y etiquetador de partes del discurso para el euskera. Por medio de este proceso se obtiene la informaci\u00f3n del lema y los rasgos morfosint\u00e1cticos necesarios para poder extraer las combinaciones de palabras candidatas a colocaciones: N +N, N+V, N+Adj. El result ado de es te proceso ha sido la creaci\u00f3n de un corpus acad\u00e9mico monoling\u00fce integrado por 398 textos (71 % TFG y 29 % TFM) y 3.285.098 palabras distribuidas en cuatro \u00e1reas de conocimiento (Tabla 1). La distribuci\u00f3n en los distintos dominios tem\u00e1ticos puede verse en el A nexo 1. Secciones del corpus TFG n\u00ba de palabras (n\u00ba de documentos) TFM n\u00ba de palabras (n\u00ba de documentos) Total de palabras y documentos Arte y Humanidades 450.859 (62) 203.831 (12) 654.690 (74) Biolog\u00eda y Ciencias de la Salud 271.932 (65) 153.533 (26) 425.465 (91) Ciencias F\u00edsicas 1.035.599 (121) 378.685 (36) 1.414.284 (157) Ciencias Sociales 559.791 (46) (30) 790.659 (76) Totales 2.318.181 (294) 966.917 (104) 3.285.098 (398) Tabla 1: Distribuci\u00f3n de palabras y documentos por secciones y por tipolog\u00eda de textos (TGF y TFM). Como se puede observar en la Tabla 1, el n\u00famero de TFM es menor que el de TFG . Esto se debe a que el n\u00famero de TFM que se elaboran en euskera es muy peque\u00f1o, a que bastantes trabajos est\u00e1n protegidos po r cl\u00e1usulas de confidencialidad y a que muchos de ellos no se publican en la plataforma ADDI. 3 Extracci\u00f3n y validaci\u00f3n de CLA Para la extracci\u00f3n y validaci\u00f3n de las CLA hemos a\u00f1adido tres m\u00f3dulos al extractor de terminolog\u00eda para el euskera Erauzterm (Alegr\u00eda et al., 2004): un m\u00f3dulo para la identificaci\u00f3n del vocabulario acad\u00e9mico, un segundo m\u00f3dulo para la identificaci\u00f3n de colocaciones acad\u00e9micas y un tercer m\u00f3dulo para la identificaci\u00f3n de f\u00f3rmulas acad\u00e9micas. Debido a las deficiencias del desarrollo d e los registros acad\u00e9micos en euskera, enco ntramos CLA que supera n los umbrales de frecuencia y dispersi\u00f3n establecidos pero que pueden ser consideradas como incorrectas o no \u00f3ptimas. Como quiera que el \u00faltimo objetivo del proyecto es desarrollar una herramienta de ayuda a la escritura, en el proceso de validaci\u00f3n hemos ido identificando las CLA incorrectas y elaborando una tipolog\u00eda de estas. 3.1 Extracci\u00f3n y validaci\u00f3n del vocabulario acad\u00e9mico El m\u00f3dulo para la elaboraci\u00f3n de la lista de vocabulario acad\u00e9mi co utiliza como contraste el corpus Dabilena , 2 obtenido de la web 2 https://dabilena.elhuyar.eus/ 97 Compilaci\u00f3n del corpus acad\u00e9mico de noveles en euskera HARTAeus y su explotaci\u00f3n para el estudio de la fraseolog\u00eda acad\u00e9mica (300.217.903 palabras): es el corpus mayor que tenemos para el euskera y ha sido elaborado por Elhuyar. Los candidatos se pueden filtrar seg\u00fan su categor\u00eda gramatical (N, V, Adj., Adv...) y seg\u00fan varias medidas de frecuencia y dispersi\u00f3n: n\u00ba de dominios y partes del texto, porcentaje de textos del corpus en los que aparecen, as\u00ed como log-likelihood, frecuencia y umbrales de frecuencia esperada. La tarea de identificaci\u00f3n del vocabulario acad\u00e9mi co no es trivial, ya que se trata de identificar los lemas caracter\u00edsticos del discurso acad\u00e9mico, pero descartando los t\u00e9rminos espec\u00edficos de una determinada \u00e1rea de especialidad. Para que la lista obtenida para el euskera sea comparable con la obtenida para el espa\u00f1ol en el proyecto HARTA, se han probado algunas de las medidas descritas en Garc\u00eda- Salido (2021). Se han realizado dos experimentos con 3 condiciones comunes: presencia de los candidatos en las 4 secciones del corpus y en el 20 % de los documentos, y valores de log- likelihood positivos. En el segundo experimento se ha a\u00f1adido la condici\u00f3n de que la frecuencia no sea 3 veces superior a la frecuencia esperada en cada uno de las cuatro secciones del corpus. Los resultados obtenidos se resumen en l as Tablas 2 y 3. Experimento 1 candidatos validados precisi\u00f3n N 443 338 76,30 % V 167 165 98,80 % ADJ 147 128 87,07 % ADV 73 53 72,60 % Total 830 684 82,41 % Tabla 2 : Validaci\u00f3n de los candidatos para la lista de vocabulario acad\u00e9mico: presencia en las 4 secciones del corpus y en el 20 % de los documentos + log-likelihood positiva. Experimento 2 candidatos validados precisi\u00f3n N 160 116 72,50 % V 81 81 100 % Adj. 70 62 88,57 % Adv. 49 34 68,39 % Total 360 293 81,39 % Tabla 3: Va lidaci\u00f3n de los candidatos para la lista de vocabulario acad\u00e9mico: presencia en las 4 secciones del corpus y en el 20 % de los documentos + log- likelihood positiva + F< 3 Fesperada en cada secci\u00f3n . Como se puede ver en las Tablas 2 y 3, la condici\u00f3n a\u00f1adida en el experimento 2, encaminada a descartar los t\u00e9rminos espec\u00edficos de las diferentes \u00e1reas de especialidad, no aumenta la precisi\u00f3n y, adem\u00e1s, disminuye la cobertura en un 57 %. 3.2 Extracci\u00f3n y validaci\u00f3n de colocaciones acad\u00e9micas El m\u00f3dulo de extracci\u00f3n y validaci\u00f3n de colocaciones acad\u00e9micas est\u00e1 conectado con el vocabulario acad\u00e9mico, de tal manera que permite filtrar los candidatos a colocaciones con un solo lema o con los dos lemas incluidos en la lista de vocabulario acad\u00e9mico. Las combinaciones candidatas a colocaciones acad\u00e9micas se extraen utilizando las medidas de asociaci\u00f3n desarrolladas en Gurrutxaga et. al. (2011, 2018) y atienden a los siguientes patrones sint\u00e1cticos: emaitzei DATIVO atender = atender a los resultados\", lanetik atera \" trabajo -ABLATIVO = obtener tama\u00f1o de muestra\" ; laginaren tamaina \" muestra de l a tama\u00f1o = tama\u00f1o de la muestra\"). Se han excluido los nombres ligeros raz\u00f3n de este descarte es que, a pesar de que dan lugar a combinaciones recurrentes con nombres acad\u00e9micos, en la mayor\u00eda de los casos no se trata de colocaciones. En la Tabla 4 se resumen algunos de los resultados obtenidos. El n\u00famero tota l de tokens normalizado es de 9.471 tokens por mill\u00f3n de palabras. Types Tokens N-Modif. 495 13.221 N(pos.)N 142 4.112 Total 1.005 31.114 Ta bla 4: Colocaciones extra\u00eddas d el corpus HARTAeus. 3.3 Extracci\u00f3n y validaci\u00f3n de f\u00f3rmulas acad\u00e9micas Para la detecci\u00f3n de f\u00f3rmulas se han extra\u00eddo n - gramas entre 2 y 5 elementos. Se han filtrado \u00fanicamente los que estaban presentes en las 4 secciones del corpus y cuya frecuencia era igual o superior a 10 apariciones por mill\u00f3n de palabras, criterio generalmente utilizado para la identificaci\u00f3n de lexical bundles (Biber et al., 1999). A la hora de validar los candidatos,hemos asignado una o m\u00e1s funciones discursiva s a cada n -grama validado , siguiendo la tipolog\u00eda usada en el proyecto HARTA parael espa\u00f1ol (Garc\u00eda- Salido et al., 2019), ya que, con el fin de que los usuarios puedan encontrarlas f\u00f3rmulas f\u00e1cilmente en la herramienta deconsulta, es m\u00e1s detallada que la de Biber et al. (2004) y la de Hyland (2008). Adem\u00e1s, una de las tareas principales del proyecto consiste encomparar las f\u00f3rmulas extra\u00eddas de los corpus de noveles vasco y espa\u00f1ol. En el proceso de validaci\u00f3n y de asignaci\u00f3n de funci\u00f3n discursiva a los n- gramas, en algunos casos hemos eliminado alg\u00fan elemento que no aportaba valor sem\u00e1ntico a la funci\u00f3n discursiva, como es la conjunci\u00f3n eta \"y\". As\u00ed por, ejemplo, si un candidato validado era eta hala ere \"y aun as\u00ed\", lo hemos eliminado y hemos mantenido \u00fanicamente la f\u00f3rmula de dos elementos hala ere \"aun as\u00ed\". Con este procedimiento, hemos identificado algunas f\u00f3rmulas monol\u00e9xicas plurimorf\u00e9micas, que en principio no esper\u00e1bamos recoger. Por ejemplo, el n-grama eta ondorioz \"y por consiguiente\" lo hemos validado como la f\u00f3rmula ondorioz \"por consiguiente\" y le hemos asignado la funci\u00f3n \"expresar consecuencia\". Una vez validados los n -gramas y asignadas las funciones discursivas, hemos identificado las variantes de una misma f\u00f3rmula. Por ejemplo, aipatu den moduan \" como se ha mencionado\" y aipatu dugun moduan \"como hemos mencionado\" son dos variantes de la misma f\u00f3rmula, y lo mismo sucede con las f\u00f3rmulas horrek esan nahi \"eso no quiere decir\". En estos casos, las variantes las hemos considera do como un solo type. Se han validado y clasificado 644 f\u00f3rmulas ( types ), 1.028 variantes y 125.398 tokens (38.171 tokens por mill\u00f3n de palabras). Como puede verse en la Tabla 5, a falta de estrategias complementarias para la extracci\u00f3n de f\u00f3rmul as monol\u00e9xicas, las f\u00f3rmulas de 2 palabras son las m\u00e1s numerosas. F\u00f3rmulas acad\u00e9micas N\u00famero de palabras Types 1 palabra 42 2 palabras 490 3 palabras 126 4 palabras 12 5 palabras 4 Totales 644 Tab la 5: N\u00ba de f\u00f3rmulas acad\u00e9micas validadas una vez analizada la variaci\u00f3n. 3.4 Identificaci\u00f3n y clasificaci\u00f3n de CLA incorrectas Algunas colocaciones y f\u00f3rmulas que llegan a los umbrales de frecuencia y dispersi\u00f3n establecidos, pueden considerarse como incorrectas o no \u00f3ptimas. Estas CLA las hemos recogido y clasificado para poder as\u00ed tenerlas en cuenta a la hora de dise\u00f1ar la herramienta de consulta ya que, aunque no son muy numerosas, presentan un importante grado de recurrencia y compiten con forma s m\u00e1s correctas o genuinas. En la Tabla 6, ofrecemos una clasificaci\u00f3n preliminar y algunos ejemplos. 99 Compilaci\u00f3n del corpus acad\u00e9mico de noveles en euskera HARTAeus y su explotaci\u00f3n para el estudio de la fraseolog\u00eda Ortografia no -est\u00e1ndar du esan nahi \"esto no 1er (cat\u00e1fora) horrek ez du esan nahi Demostrativo de de palabras inadecuado Lan honen helburua [...] da \"El ob jetivo es\" Lan honen helburua da [...] Forma aldetik , [...] bestetik , [...] y por el otro [...] \" Asignaci\u00f3n de una funci\u00f3n discursiva incorrecta Hau da \"esto es\" \"expresar causa\" Hau da \"reformular\" Colocaci\u00f3n incorrecta Clasificaci\u00f3n y ejemplos de CLA incorrectas. 4 Resultados y discusi\u00f3n No contamos con un corpus de expertos para el euskera comparable con el corpus HARTA de expertos, por lo que, para analizar los datos obtenidos hasta el momento, los contrastaremos con los ofrecidos en Garc\u00eda- Salido (2021) y en Alonso y Zabala (2022 ). La lista de vocabulario acad\u00e9mico compilada hasta el momento para el euskera cuenta con 684 lemas. Esta lista es bastante m\u00e1s reducida que la obtenida tras contrastar los resultados de diferentes t\u00e9cnicas para el espa\u00f1ol (Garc\u00eda -Salido, 2021): 833 lemas. La diferencia puede estar motivada por el descarte de los lemas con valores de log -likelihood negativos, ya que entre los lemas descartados puede haber algunos que son muy utilizados en textos generales pero que activan significados espec\u00edficos en los discursos acad\u00e9micos. Nuestra idea es seguir completando la lista obtenida hasta el momento, probando otras t\u00e9cnicas y medidas. Sin embargo, la principal aplicaci\u00f3n de la lista de lemas acad\u00e9micos en el proyecto HARTAvas es la extracci\u00f3n de colocaciones acad\u00e9micas. Para ello, es fundamental la lista de nombres , ya que son los que constituyen las bases de las colocaciones, el n\u00famero de N obtenidos para el euskera es menor pero comparable al del espa\u00f1ol: 338 eus / 358 es. El n\u00famero de colocaciones acad\u00e9micas obtenidas es tambi\u00e9n comparable al obtenido a partir de l corpus HARTA de noveles para el espa\u00f1ol (Alonso y Zabala, 2022): 1 .005 types eus / 1.197 es. Aunque hay que tener en cuenta que el corpus del euskera es mayor que el del espa\u00f1ol, que cuenta con 2 M de palabras. Aun siendo menor el n\u00famero de colocaciones extra\u00eddas para el euskera, el n\u00famero de tokens por M de palabras es notablemente superior: 9.471 tokens/M eus / 6.897 tokens/M es. Por lo tanto, como primera aproximaci\u00f3n se puede decir que las colocaciones detectadas para el euskera son m\u00e1s recurrentes que las detectadas para el espa\u00f1ol en el corpus de noveles. El n\u00famero de f\u00f3rmulas (types) extra\u00eddas para el euskera es notablemente superior al obtenido a partir del corpus de noveles en espa\u00f1ol: 644 types eus / 472 types es. Tambi\u00e9n existe diferencia en la frecuencia de dichas f\u00f3rmulas: 38.171 tokens/M eus / 20 .474 tokens/M es. El mayor n\u00famero de f\u00f3rmulas detectadas en euskera podr\u00eda estar relacionado con el menor grado de fijaci\u00f3n de las f\u00f3rmulas acad\u00e9micas en esta lengua, y con la variaci\u00f3n entre f\u00f3rmulas m\u00e1s genuinas y f\u00f3rmulas calcadas del espa\u00f1ol: besteen artean (calco) / besteak beste ; orokorrean (calco) / oro har. El n\u00famero mayor de tokens, podr\u00eda indicar una menor riqueza expresiva de los noveles vascos, que les har\u00eda recurrir m\u00e1s frecuentemente a las mismas secuencias dando lugar a un discurso m\u00e1s repetitivo. De cualquier modo, se requiere un an\u00e1lisis m\u00e1s minucioso de los criterios de validaci\u00f3n que hemos utilizado para una y otra lengua, as\u00ed como de los datos, con el fin de poder hacer una comparaci\u00f3n m\u00e1s precisa de las CLA obtenidas en una y otra lengua de cara al dise\u00f1o de la herramienta de ayuda a la escritura acad\u00e9mica para las dos lenguas. 100 Mar\u00eda Jes\u00fas Aranzabe, Antton Gurrutxaga, Igone Zabala 5 Conclusio nes A pesar de que el euskera es una lengua minorizada que se introdujo hace solo unas d\u00e9cadas en l a ense\u00f1anza superior, hemos logrado compilar un corpus de trabajos acad\u00e9micos en euskera (TFG y TFM) comparable, e incluso algo m\u00e1s extenso, que el corpus de noveles para el espa\u00f1ol. A partir del corpus hemos obtenido una lista de vocabulario acad\u00e9mico en euskera (644 lemas), que aunque debe de considerarse preliminar, nos ha permitido identificar un gran n\u00famero de colocaciones acad\u00e9micas (1 .005 types). Hemos extra\u00eddo tambi\u00e9n n- gramas de 2, 3, 4 y 5 elementos, que hemos validado y a los que hemos asignado f unciones discursivas partiendo de la tipolog\u00eda utilizada para HARTAes. Los n - gramas nos han permitido detectar pero en el proceso de validaci\u00f3n, hemos podi do detectar tambi\u00e9n 42 f\u00f3rmulas monol\u00e9xicas o morphemic bundles como laburbilduz \"en resumen\". As\u00ed hemos obtenido 644 f\u00f3rmulas y 1.028 variantes, a las que les hemos asignado funciones discursivas. Por \u00faltimo, hemos desarrollado una tipolog\u00eda de f\u00f3rmulas incorrectas, de cara a elaborar su tratamien to lexicogr\u00e1fico en la herramienta de consulta. Estamos implementando t\u00e9cnicas de sem\u00e1ntica distribucional, con el fin de utilizar los corpus comparables del espa\u00f1ol y del euskera para la detecci\u00f3n de f\u00f3rmulas, sobre todo f\u00f3rmulas monol\u00e9xicas, y equivalentes de colocaciones y f\u00f3rmulas entre las dos lenguas. Adem\u00e1s, hemos comenzado la tarea de comparaci\u00f3n m\u00e1s minuciosa de las listas de CLA elaboradas para las dos lenguas, con el fin de obtener una clasificaci\u00f3n que tenga en cuenta las caracter\u00edsticas tipol\u00f3gicas del espa\u00f1ol y del euskera. Dicha comparaci\u00f3n nos servir\u00e1 tambi\u00e9n para decidir el dise\u00f1o de la herramienta de consulta para ambas lenguas. Agradecimientos Este trabajo es parte del proyecto HARTAvas (PID2019-109683GB- C22), financiado por el Ministerio de Ciencia e Innovaci\u00f3n. Bibliograf\u00eda Alegria, I., M.J. Aranzabe, A. Ezeiza A., N. Ezeiza, y R. Urizar R. 2002. Robustness and customisation in an analyser/lemmatiser for Basque. En Third International Conference on Language Resources and Evaluation (LREC): Customizing p\u00e1 ginas 1 -6, Las Palmas de Gran Canaria (Spain). Alegr\u00eda, I, A. Gurrutxaga, P. Lizaso, X. Saralegi, S. Ugartetxea, y R. Uriza r. 2004. An Xml -Based Term Extraction Tool for Basque. En Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC'04) , p\u00e1ginas 1733- 1736, Lisboa (Portugal) . Alonso- M., M. Garc\u00eda -Salido, y M. Garcia. 2017. Exploiting a Corpus Proceedings of eLex 2017 conference, p\u00e1ginas 571 -586, Leiden (the Netherlands). Alonso- Ramos, M. y I. Zabala . 2022. HARTAes -vas: Combinaciones l\u00e9xicas para una Herramienta de ayuda a la redacci\u00f3n de textos acad\u00e9micos en espa\u00f1ol y en vasco. En Proceedings of the Annual Conference of the Spanis h Association for Natural Language Processin g: ( Spain). Biber, D. 2006. University Language. A corpus - based study of spoken and written registers. John Benjamins, Amsterdam. Biber, D., E. S. S. Conrad, G. 1999. ofSpoken and Written Englis h. Longman, London. Biber, D., S. Conrad, y C. Viviana. 2004. If you look at...: lexical Alonso- Ramos . 2018. A Lexical Tool for Academic Writing Spanish based on Expert and Novice Corpora. En Calzolari N. et al. (Eds). Proceedings of the Eleventh International Conference on Language 101 Compilaci\u00f3n del corpus acad\u00e9mico de noveles en euskera HARTAeus y su explotaci\u00f3n para el estudio de la fraseolog\u00eda acad\u00e9mica Resources and Evaluation (LREC 2018) , p\u00e1ginas 260-265, Miyazaki (Japan). Garc\u00eda- Salido, M., M. Garcia , y M. Alonso- Ramos. 2019. Identifying lexical bundles for academic writing assistant in Spanish. Corpas Pastor , G. R. (Eds). -Based Phraseology . Volume Lecture Notes in Artificial Intelligence , p\u00e1ginas 144- 158, Springer, Berlin. Garc\u00eda- Salido, M. Vocabulary List Englishes M. Lang (Swi tzerland). Gurrutxaga, e I. Alegria. 2011. Automatic extraction expressions in Basque: basic issu es on n Proceedings of the Workshop on Multiword Expressions: from parsing and generation to the real world , p\u00e1ginas 2 -7, Portland, Oregon (USA) . Gurrutxaga, A., I. Alegria, y X. Artola. 2018. Caracterizaci\u00f3n computacional de la idiomaticidad: aplicaci\u00f3n a la combinaci\u00f3n nombre+verbo en euskera. En Ruiz Miyares, L. (Ed ). Estudios de Lexicolog\u00eda y Lexicograf\u00eda. Homenaje a Elo\u00edna Miyares Berm\u00fadez. Santiago de Cuba (Cuba). Hyland, K. 2008. As can be seen : lexica l bundles and disciplinary Word Lists for Swedish, Laur\u00e9n, J. Myking, y H. Picht. 2002. Language and domains: a proposal for a domain dynamics taxonomy. LSP and Professional Communication, 2(2):23 -30. Paquot, in University Language Tests? Insights from A Study Language of Applied Linguistics, 20:59-76. Villayandre, M. 2018. \" HARTA \" de noveles: un corpus de espa\u00f1ol acad\u00e9mico. CHIMERA: Revista De Corpus De Lenguas Romances Y Estudios Ling\u00fc\u00edsticos , 5(1): 131-140. Zabala, I., I. San Martin, M. Lersundi, y A. Elordui . 2011. Graduate teaching of specialized registers in a language in the normalization process: Towards a comprehensive and interdisciplinary treatment of academic En Maruenda- Bataller , S. y B. Clavel -Arroita (Eds). Multiple voices in academic and professional discourse , p\u00e1ginas 208218, Cambridge Scholars (Newcastle upon Tyne, UK). Zabala, I., M. Le rsundi, I. Leturia, I. garapenaren lan la UPV/EHU (Bilbao). Zabala, I. 2019. The elaboration of Basque in Academic and Professional Domains. En Grenoble, L., P. Lane, y U. R\u00f8yneland (Editor- in-Chief), Igartua, I. y L. O\u00f1ederra Online , M.J. Aranzabe, y I. Aldezabal. 2021. Retos actuales del desarrollo y aprendizaje de los registros acad\u00e9micos orales y escritos del eusker a. C\u00edrculo de Ling\u00fc\u00edstica Aplicada a la Comunicaci \u00f3n, 88: 31-50. A Anexo 1: Corpus HARTA eus Distribuci\u00f3n de palabras y documentos (TFG y TFM) por secciones del corpus y dominios tem\u00e1ticos. 102 Mar\u00eda Jes\u00fas Aranzabe, Antton Gurrutxaga, Igone Zabala Secciones del corpus Dominios de palabras (n\u00ba de documentos ) TFM n\u00ba de palabras (n\u00ba de documentos ) Total de palabras y documentos Arte y Humanidades Arte 42.956 (6) 0 42.956 (6) Ling\u00fc\u00edstica 207.443 (27) 203.831 (12) 411.274 (39) Literatura 90.139 (12) 0 90.139 (12) Historia y Cultura 110.321 (17) 0 110.321 (17) Biblioteconom\u00eda y documentaci\u00f3n 0 0 0 Totales 450.859 (62) 203.831 (12) 654.690 (74 Biolog\u00eda y Ciencias de la Salud Biolog\u00eda 182.906 (44) 153.533 (26) 336.439 (70) Medicina 89.026 (21) 0 89.026 (21) Totales 271.932 (65) 153.533 (26) 425.465 (91) Ciencias F\u00edsicas Ciencias de la Tierra 52.263 (7) 0 52.263 (7) F\u00edsica 113.027 (16) 0 113.027 (16) Ingenier\u00eda 656.156 (69) 20.031 (1) 676.187 (70) Inform\u00e1tica (8) 408.142 Qu\u00edmica (21) 164.665 (24) Totales 1.035.599 (121) 378.685 (36) 1.414.284 (157) Ciencias Sociales Econom\u00eda y Empresa 158.433 (10) 0 158.433 (10) Educaci\u00f3n 102.335 (16) 230.868 (30) (46) Sociolog\u00eda (16) 0 (16) 65.391 0 65.391 (4) Totales 559.791 (46) 230.868 (30) 790.659 (76) 103 Compilaci\u00f3n del corpus acad\u00e9mico de noveles en euskera HARTAeus y su explotaci\u00f3n para el estudio de la fraseolog\u00eda acad\u00e9mica 104 Extraction and Semantic Representation of Spanish Labour Extracci\u00b4 on y representaci\u00b4 on de r elaciones espec\u00b4ficas de dominio en Madrid, Spain artem.revenko@semantic-web.com, patricia.martin@upm.es Abstract: Despite the freedom of information and the development of various open data repositories, the access to legal information to general audience remains hin- dered due to the difficulty of understanding and interpreting it. In this paper we aim at employing modern language models to extract the most important infor- mation from legal documents and structure this information in a knowledge graph. This knowledge graph can later be used to retrieve information and answer legal question. To evaluate the performance of different models we formalize the task as event extraction identifying legal classes and 0.5 F1score for identifying roles in legal relations. We demonstrate how the produced legal knowledge graph could be exploited with 2 example cases. Workers' the fine-tuned open repository. Keywords: Information Extraction. Knowledge Graphs. Semantic Web. Legal Domain. Resumen: A pesar de la actual libertad de informaci\u00b4 on y del desarrollo de difer- entes repositorios de datos abiertos, el acceso a la informaci\u00b4 on jur\u00b4 dica al p\u00b4 ublico general sigue suponiendo un problema debido a la dificultad de comprensi\u00b4 on e in- terpretaci\u00b4 on de dicha informaci\u00b4 on. En este art\u00b4 culo, nuestro objetivo es emplear modelos de lenguaje punteros para extraer informaci\u00b4 on relevante de documentos jur\u00b4 dicos; as\u00b4 como estructurar esta informaci\u00b4 on en un grafo de conocimiento, con el objetivo de que este grafo pueda utilizarse m\u00b4 as adelante para recuperar informaci\u00b4 on y responder preguntas sobre el dominio jur\u00b4 dico. Para evaluar el rendimiento de los diferentes modelos, hemos formalizado este proceso como una tarea como extracci\u00b4 on de eventos, y hemos anotado manualmente 133 instancias. Evaluamos dos modelos: GRIT y Text2Event. El \u00b4 ultimo modelo consigue mejores resultados, de \u00ab0.8F1para identificar clases jur\u00b4 dicas y de 0 .5F1para identificar roles en relaciones jur\u00b4 dicas. Asimismo, ejemplificamos c\u00b4 omo el grafo producido podr\u00b4 a explotarse con diferentes casos de uso. Finalmente, hemos anotado todo el Estatuto de los Trabajadores con el modelo Text2Event y publicado los resultados en un repositorio abierto. Palabras clave: Extracci\u00b4 on de Informaci\u00b4 on. Grafos de Conocimiento. Web Sem\u00b4 antica. Dominio Jur\u00b4 dico. 1 Introduction Due to its specific nature, the legal domain has always been a complex area for non le- gal users. The challenges include preting the document. With the recent rise of the data sharing and open data technolo-gies in the last decade, legal knowledge is more accessible than ever. Well-known legal practitioners have already exposed their in open and machine readable formats, developing platforms such as the Eu- 1https://data.europa.eu/ Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 105-116 recibido aceptado 30-05-2022 ISSN 1135-5948. DOI 10.26342/2022-69-9 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Naturalropean Union and managed by the Publica- tions legal dif- such as justice, legal sys- tem and government. At a national level, one of the most important sources of legal data in Spain is the Official State Gazette2, which is constantly being updated in Spain. contains docu- ments the labour law domain, such as state collective agreements and the Spanish Work- ers Statute. This availability of legal data efficiently task for finding the correct documents and accessing them. Yet, the interpretation of legal data and, there- fore, exploitation of the legal results by gen- eral public remains an important challenge (Robaldo et al., 2019). We are driven by the idea of tackling this challenge and enabling more human-friendly interfaces for accessing this kind of information. We choose the labour law sub-domain for our experimenta- tion as this domain is relevant for everyday use by general audience and the tasks en- abling natural language search, information retrieval, question over the labour law are highly demanded. To solve these kind of tasks and ease the access to legal informa- tion from general audience, we aim at struc- turing legal data into a knowledge graph. Modern (multilingual) language models to tackle our challenge as well. We noticed that most models are trained with and, domain specific annotated corpora and do- main specific language resources published in machine readable formats hinders the fine- tuning of the models. Consequently, the purpose of this paper is twofold: on the one hand, we test different language models on a domain specific corpus to extract relations amongst terms and, on the other hand, we provide annotated data in the labour law domain and structure the re- sults in Semantic Web formats so they can be reused in the future by upcoming researchers. This work (code, input and output data) and published in GitHub repository3. 2https://www.boe.es/ 3https://github.com/pmchozas/term_relex/1.1 A look at the Semantic Web More than 20 years ago, the World Wide Web Consortium (W3C) promoted the publica- tion of data in structured, machine-readable and interlinked formats, in which the mean- ing of data can be interpreted by machines to achieve more complex and effective data un- derstanding. This initiative is known as the Semantic Web or the Web of Data (Berners- Lee, Hendler, and Lassila, 2001). The most common format for publish- ing data on the Semantic Web is the Re- source Description Framework (RDF). RDF is at the core of the Linked Open Data paradigm for publishing information, based on the Linked Data Principles (Berners-Lee, 2006). According to these principles, re- need to be (a unique that follows the HTTP standard web pro- tocols), and that resources need to contain pointers to other resources. The inner structure of certain do- main (Chandrasekaran, and we use of RDF to structure the extracted knowledge following the Linked Data the task of cre- ating legal knowledge graph in one of the pi- lots (Spanish labour law pilot) of the Innovation Action funded by the European to work deeply on the extraction of knowledge over labour law documentation, since several issues were spotted during its development: 1. fact hinders the reuse al- pre-trained language models that are usually trained with texts from the general domain. , Mart\u00edn-Chozas 2. this domain are scarce; even after annotating a part of the Statute, the size of the resulting an- notated corpus model to obtain good results. Therefore, within this paper we tackle those issues trying to untangle labour law data, easing the understanding of duties and rights related to the labour domain to any- one willing to know them. For instance, if we suppose that a worker is in trouble with a company for taking a leave from work, we may want to answer questions such as: Q1) In a right? Q2) When must a worker come back to work after a leave from work? The rest of the paper is divided as fol- Section and annotation process; identifies language models on Semantic Web formats; Section 7 shows examples on how to exploit the result- ing knowledge graph; Section 8 gathers re- lated Section clusions 2 n-Chozas we conceptual rela- tions in legal texts and noticed that labour law texts are full of deontic relations, part of the Hohfeldian fundamental relations (Hohfeld, are divided into two sets of relations: Deontic relations, that are those that Duty, No-Right and Liabil- ity, Disability and Immunity. In work, we focus on the extraction of deontic relations (see Figure 1), since they are the basis of the fundamental relations and the most common within the Spanish labour law. legal relation. How- ever, it is difficult to use this information alone. In fact, more complex use cases, such as question answering over legal texts or the merge of different legal documents into a sin- gle knowledge graph, require following roles of par- objects re- lations relations. These roles correspond to the Model (see Section 6): The subject is the agent of the action, who performs the action. The object is the patient of the action, who receives the action. The complement is the item which is handled in the relation. Consequently, the model should be capa- ble of (1) classifying a string from a legal text into one of Hohfeld relation classes (if there is one); (2) ticipants of to transform the text into structured event records (Doddington et al., 2004; Ahn, 2006). These event records can further be trans- into a relation extraction task (Hendrickx et al., 2019). However, in that case, we need to extract the entities in a separate step and then identify relation be- tween that we want to extract are better described as roles within a sen- tence rather than being in a relation with of these difficulties, refrained of Domain-Specific We illustrate the event extraction task in Fig- ure 2 with an example from Spanish labour law. From the sentence, we extract an event record of type \"Right\" corresponding to the Hohfeld deontic class \"Right\", together with roles of participants. Generally, event extraction allows the def- inition of different sets of roles for each event. For our use case we do not exploit this flex- ibility of task formulation as we define the same set of roles for all event types. Conforme a lo establecido en dicha regulaci\u00f3n, el trabajador podr\u00e1 solicitar de la Administraci\u00f3n p\u00fablica competente la expedici\u00f3n del correspondiente certificado de profesionalidad... In accordance with the provisions of such a regulation, the worker may request the Public Administration the issuance of the corresponding professional certificate from the competent public event from Spanish labour law, with approximate translations. 3 Training Data As mentioned before, this experiment is based on the Spanish Workers' Statute, that is published in the Official State Gazette. The text is the main legislative labour law document in Spain, therefore, it clearly cor- responds to our a representative therefore, any obtained could be extrapolated to other legal divided into three main sec- tions named as \"titles\". The first title cov- ers individual labour relations; the second ti-tle covers the and workers' 92 articles, contain- ing approximately 50.000 tokens. With the current state of analysis we estimate the den- sity of relations in the Spanish labour law to be 3.65 relations per article. Regarding the manual annotation of this document, it started by identifying its most relevant terms. To speed up this process, we made use of an open source terminology extraction tool that extracts the most statute. evaluation of the tool's per- formance, we refer the reader to its research paper (Oliver and V` azquez, 2015).From those most frequent terms, we identified those that could hold the roles of subject and object of a Hohfeld relation. This is, legal such as worker legal entities, the document could also include a complement, usually an object that takes part in the relation. Not only positive sam- with legal entities that do not present any relation at all amongst them. Corpus and annotated data statistics are shown in Table 1. Figure 2 shows an ex- ample of a positive annotation. Regarding the negative ones, we have identified 2 types: 1) Annotations with entities but with relations. Examples of these types are shown below: 1. Mediante los convenios colectivos, y en su \u00b4 ambito correspondiente, los traba- jadores(e1) y empresarios(e2) regulan las condiciones de trabajo y de produc- tividad. (By means of the productivity conditions.) 2. Igualdad de remuneraci\u00b4 on por raz\u00b4 on de sexo. (Equaly pay sex ) 108 Artem Mart\u00edn-Chozas Type of Element Total number Sentences in the corpus 1568 Tokens in the corpus 54849 Annotated samples 133 Positive samples 97 127 Legal 86 Subjects 90 Objects 69 Complements 100 Table 1: Statistics of the corpus and the an- notated data. 4 Models For this work we focused on joint multi-task deep learning classification models as they achieve state of the art results on common event extraction datasets, see also Section 8. As these common datasets are in English, for the final choice of the model it was impor- tant for us that the model code is publicly available, so that we can reuse the model and that the base model is either multilingual or can be changed to multilingual. Finally, Cardie, 2021) and Text2Event (Lu et al., 2021). For both GRIT The model GRIT is a generative role-filler transformer model, i.e. it is capable of identifying the (predefined) roles of entities in text. In order to apply GRIT to event ex- traction task we found it necessary to declare the trigger as a separate role and extend the model to also classify the class (event type) of the input text. The extended model is a joint generative event extraction model. The base model of GRIT is BERT (Devlin et al., 2018), we used the model with BETO (Ca nete et al., 2020) that is a BERT model trained on a big Spanish corpus. Text2Event The event extraction model is Text2Event. This model relies the scription or names of roles, more precisely the names of roles are input to the language model together with the legal text. There- fore, we translated the names of the roles and also the names of the Hohfeld classes to Spanish. As recommended by the authors of the original paper, we have pre-trained the model on ACE dataset, and only thenfine-tuned the model on our dataset6. The base model of Text2Event is T5 (Raffel et al., 2020) with multilingual T5 (mT5) (Xue et al., 2020). Roles The final set of roles for both models consists of trigger, subject, object, and com- plement roles as described in Section 2. 5 Results and Evaluation For the evaluation of the performance of our model we will use well established metrics the gold standard be the correct manu- ally annotated data. Let the true incorrectly predicted negatives (FN) - those cases when a relation is not predicted, though it does exist in the gold standard; true neg- atives (TN) - the relation is not predicted and it does not exist in the gold standard. Then P\"TP TP`FP,R\"TP also It should be correct are For computing the results we used the 126 samples from the training set in the follow- ing split: 116 samples used for training and 10 samples used for development set. The test set consists of 20 samples, all the results are reported for the test set. This setup is applied to both models. The training was performed with default parameters as set by the authors of the original models, except for the extension of GRIT and the change of the base models as described in Section 4. The comparison of the models is in Table 2. The two columns present the F1scores for the task of classifying all roles forms GRIT model by significant gin. of the results confirm this finding. A possible explanation of the difference in performance could by the abil- ity of the Text2Event model to include the 6Though the roles and the language in the ACE dataset are quite different from our use case, we use ACE in the pre-training to enable the model to learn the constrained generative language as suggested by the authors the paper. 109 Extraction and Semantic Representation of Domain-Specific Relations is F1score of extracting all differ- ent including the F1of the legal relation p i.e. \"derecho\", \"sujeto\", etc., as input to the model. This ability allows for pre-training on the large ACE dataset and efficient knowledge trans- fer for the few-shot learning with our labour law dataset even despite the different types of events, different domain and different lan- guage (English) of the pre-training are presented in Table 3. The model can classify and ex- tract triggers with good confidence, however, the model experiences difficulties with other roles, in particular with identifying objects. Manual investigation of the final results re- with F1 in the range of 0.5-0.8, which we con- sider to be reasonably good. 6 Triplification The second part of our work is focused on the publication of the results obtained following Semantic Web formats. Normally, the results of type of experiments are usually pub- lished in unstructured formats, such as txt, or semi-structured, such as csv. In this case, we consider that it is highly important to publish these data in struc- tured, open and machine-readable formats,to support their reuse and update. This is possible thanks to the data models of the Semantic Web. In this specific case, we have combined linguistic data represen- tation models with legal that described in dataset presented in Section 6.1 Ontology mentioned in the Motivation (Section 1.2), the results of this experiment are to be transformed into a labour law knowledge graph, with the aim of generating a rich re- source of concepts and relations that can be applied to other NLP tasks in the future. Therefore, case we would like to include them in the future. On the other hand, to represent the lin- guistic information apply SKOS7and la- belling properties RDF Schema8. In this case, since the envisioned output is a rich terminological resource with many different kind of data, we need both vocabu- laries to represent Schema models9, to add extra this a Hohfeld rela- tion, we a new Hohfeld class with the Provision Model, depending on the nature of needs to our annotations, respectively. These items are represented with the class skos:Concept, and they are linked to the Hohfeld class with properties: prv:hasRightBearer, prv:hasRightCounterpart and prv:hasRightObject. also include the relation trigger in this data model, that is rep- resented with the class schema:Action, and linked or prv:hasPermissionAction. Dataset have split the Statute into individ- ual sentences, that were used one by one as input to our fine-tuned Text2Event Then we For created a subgraph as described in statistics of the resulting dataset are presented in Table 4. Type of Element Total number Hohfeld classes 791 Right 578 Duty 213 Subjects 659 Objects 31 Complements 312 Table 4: Statistics of resulting In section, we translate the questions in natural language formulated at the end of Section 1.2 into SPARQL queries10, exem- plify graph. First, in Listing 1, we collect all the pre- fixes that are needed to formulate the rest of the queries. These prefixes identify the right?. There- fore, we look for something (?s) that is a right (prv:Right), which has a right bearer (prv:hasRightBearer), whose ID we do not know (?bearer), and that has right action (prv:hasRightAction), whose ID we do not know either (?action). However, we do know their labels (rdfs:label), which are trabajador in Spanish (@es) for the bearer, and podr\u00b4 a reclamar in Spanish (@es) for the action. The result of this query are three URIs which are the identifiers of the right the Question 2: When must a worker come back to work after a leave from work? . In this case, we look for something (?s) that is a duty (prv:Duty), with a duty bearer (prv:hasDutyBearer) and a duty action, which is the trigger (prv:hasDutyAction). Here, the label of the duty bearer is tra- bajador, and the label of the duty action, which is of the type schema:Action, is de- ber\u00b4 a reincorporarse. The result of this query is a URI which is the identifier of the right instance that satisfies ID of a given instance, we could make a simple query to retrieve the textual excerpt (with the property skos:note) from which the relation has been extracted, as ex- posed in Listing 4. The result of this query is the following excerpt: En los supuestos de suspensi\u00b4 on por ejercicio de cargo p\u00b4 ublico rep- resentativo o funciones sindicales de \u00b4 ambito provincial o superior, el trabajador deber\u00b4 a reincorporarse en el plazo m\u00b4 aximo de treinta d\u00b4 as naturales a partir de la cesaci\u00b4 on en el cargo o funci\u00b4 on. 8 Related Work Event Extraction In this ceived widespread attention Huang, 111 Extraction and Semantic Representation of Domain-Specific Relations 72.8 54.8 art results on ACE dataset. has focused on the ACE sentence level event task (Walker et al., 2006), which requires the detection of an event trigger and extraction of its arguments from within a single sentence. This dataset consists of 599 documents and includes 8 event types 6000 individual events. Further important dataset is MUC-4 (muc, 1992) with 1700 documents, 400 to- kens per document on average. Note that these datasets are significantly larger than the one we exist- ing event extraction available in event extraction dataset in Spanish is known to us. The most prominent approaches to solving the Huang et al., 2018); 3. Question-answering based approaches (Zhou et al., 2021; Liu et al., 2020); 4. Joint multi-task classification models (Lin et al., 2020; Paolini et al., 2021; Du, Rush, and Cardie, 2021; Lu et al., 2021). Recent state of the art results are achieved by the joint multi-task deep learning models. GRIT (Du, Rush, and Cardie, 2021) achieves joint 5. Legal Ontologies Regarding the represen- tation of legal information in Semantic Web formats, we find many approaches depending on the type of data and on the purpose of the ontology. Likewise, the type of data depends on the legal subarea to which a resource be- longs (labour law, civil law, etc.) and on the type of legal document (provisions, rules, li- censes...). The tostructure the information while others are de- signed to reason over data and infer knowl- most used ontologies legal Union to metadata of legislative documents as Linked Data. To complement the Publications Office of the European Union also applies the Common Data Model for Bibliographic domain such as Akoma Ntoso, which was created as an XML standard and afterwards evolved to an ontol- ogy (Palmirani and Vitali, 2011), and Legal- RuleML (Athan al., 2015), that is able to represent the particularities of the legal normative rules with a rich, articulated, and meaningful markup language. find Ho- hfeld's relations (which are described in Sec- tion 2). In we have mentioned those ontologies that are directly related to our work. For more information about legal on- tologies, we refer the reader to more compre- hensive surveys such as (Valente, 2005) and (de Oliveira Rodrigues et al., 2019). 9 Conclusions and Future Work In this paper we experimented with pre- trained multilingual language models for ex- tracting knowledge from a domain-specific labour law corpus in Spanish. We for- malised the task as sentence-level event ex- traction and two models: GRIT and Text2Event. To train and evaluate the model, annotated the Workers' Statute with 133 sentences the by a margin of around 0.2 of F1scores both on but looses the quality for other roles (F 1\u00ab0.5 for all roles including trigger). Furthermore, we split the Statute into individual and apply the fine-tuned Text2Event model on this Provi- sion Model for Hohfeld relations. The result- ing labour law knowledge graph is publicly available for to be reused by the community. Future Work In the short term, we plan to develop a post-processing script based on NLP rules results the aim of improving precision. This idea is based on the observation that models sometimes agents with relation complement, could be avoided with a role labeling task over the results. Furthermore, we focus on sentence-level roles and relations most relations are expressed in a single sentence. However, we note that the number of relations spanning over multiple sentences is not negligible. Hence, in the future work we also plan to experiment with extracting relations beyond sentence level. Regarding the representation in RDF, we plan to add more linguistic information to the graph, linking it to existing legal resources published in Semantic Web formats, such as EuroVoc12. We may also want to link our labour law graph with more general resources such as Wikidata13, to extend the graph with information from a wider scope. To represent this additional linguistic data we plan Ontolex14to SKOS. This combi- nation is Semantic is for \" being these labels with the been supported by Eu- ropean Union's Horizon 2020 et-` a- LLOD15project, 825182, and by COST (European Cooper- ation in Science and Technology) through NexusLinguarum, the for Web-centred linguistic data Virginia, June 16-18, 1992. Ahn, D. 2006. The stages of event ex- traction. In Proceedings of the Workshop on Annotating and Reasoning about Time and Events, pages 1-8, Sydney, Australia, July. Association for Computational Web School, pages 151-188. Springer. Berners-Lee, T. 2006. Design issues. Berners-Lee, T., J. Hendler, and O. semantic web. the formulation, research and diagnosis of legislation. Ar- tificial Intelligence and Law . Ca nete, J., G. Chaperon, R. Fuentes, J.-H. Ho, H. Kang, and J. P\u00b4 erez. 2020. Span- ish pre-trained bert model In PML4DC at ICLR 2020 . Chandrasekaran, B., J. R. Josephson, and V. R. Benjamins. 1999. What are ontolo- gies, and why do we need them? IEEE Intelligent Systems and their applications . Extraction and and linked with external knowl- edge bases. de Oliveira Rodrigues, C. M., F. L. G. de Fre- itas, E. F. S. Barreiros, R. R. de Azevedo, and A. T. de Almeida Filho. 2019. Legal ontologies over time: A Toutanova. 2018. BERT: Pre-training Deep L. and R. Weischedel. automatic con- tent extraction (ACE) program - tasks, data, and evaluation. In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC'04), Lisbon, Portugal, May. Eu- ropean Language Resources Association A. Rush, of the Association for over normative Semantic D. \u00b4O. S\u00b4 eaghdha, S. le- as applied in judicial rea- soning. Yale Lj, 23:16. Huang, L., H. Ji, K. Cho, I. Dagan, S. Riedel, and C. Voss. 2018. Zero-shot transfer learning for event extraction. In Proceed- ings of 56th the Association Computational Linguistics (Volume for Computational Linguistics. Lin, Y., H. Ji, F. Huang, and L. Wu. 2020. A joint neural model for information extrac- tion with global features. In of July. Association for Computational Linguistics. Liu, J., Y. Chen, K. Liu, W. Bi, and X. Liu. 2020. Event extraction as machine read- ing comprehension. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) , Mart\u00edn-Chozas J., and X. Huang. 2021. An overview of event , page arXiv:2111.03212, November. Lu, Y., H. Lin, J. Xu, X. Han, J. Tang, A. Li, L. Sun, M. Liao, and S. Chen. 2021. Text2Event: the 11th In- ternational Joint Conference on Natural Language Processing (Volume 1: Long Pa- pers), pages 2795-2806, Online, August. Association for Computational Linguis- tics. Ma, J., S. Wang, R. Anubhai, M. Ballesteros, and Y. Al-Onaizan. 2020. Resource- enhanced neural model for event ho- hfeld's relations from spanish labour law. InProceedings of the 2nd International Workshop on Deep Learning meets On- tologies and Natural Language Process- ing A. and M. V` azquez. 2015. Tbxtools: a free, fast and flexible tool for automatic terminology extraction. In Proceedings of the International Conference Recent Ad- vances in Natural Language Processing. Palmirani, M. and F. Vitali. 2011. Akoma- ntoso for legal documents. In Legisla- for semantic Web. Springer, pages 75-100. Paolini, G., B. Athiwaratkun, J. Krone, J. Ma, A. Achille, R. ANUBHAI, C. N. dos Santos, B. Conference on Learning Representations. Raffel, C., N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li,and P. J. Liu. 2020. Exploring the lim- its of transfer learning with a unified text- to-text transformer. Journal of Machine Learning Research, S. Villata, A. Wyner, and M. Grabmair. 2019. Introduction for artificial intelligence and law: special is- sue \"natural language processing for legal texts\". Valente, A. 2005. Types and roles of legal ontologies. In Law and the semantic web . Springer, pages 65-76. Walker, C., S. Strassel, J. Medero, and K. Maeda. 2006. Ace 2005 Data Consor- tium, Philadelphia , 57:45. Xue, L., N. Constant, A. Roberts, M. Kale, R. Al-Rfou, A. Siddhant, A. Barua, December. Zhang, Z., X. Kong, Z. Liu, X. Ma, and E. Hovy. 2020. A two-step approach for of the Association for Computational Linguis- 7479-7485, Online, July. As- sociation for Computational Linguistics. Zhou, Y., Y. Chen, J. Zhao, Y. Wu, J. Xu, and J. Li. 2021. What the role is vs. what plays antica para la Detecci\u00b4 de Categor\u00b4 identifying the categories in an opinion. It is a dicult task because the category must be inferred is a drawback for these models. Motivated by the same idea of identifying and highlighting the importance of terms, this paper can be applied in scenarios with limited training data and can be subtarea dentro del an\u00b4 desentimientos anivelde aspecto. Estasubtareaabordalaidenticaci\u00b4 aquellas categor\u00b4 asde aspecto presentes en una opini\u00b4 on. Se trata de una tareadesaante pues la categor\u00b4 a debe inferirse de los t\u00b4 erminos de la opini\u00b4 on, aunado a esto, una opini\u00b4 on puede incluir evaluaciones de m\u00b4 as de una categor\u00b4 a de aspecto. En los \u00b4 ultimos a nos, el uso de mecanismos de atenci\u00b4 on ha permitido mejorar los resultados en distintas tareas, \u00b4 estos permiten identicar y priorizar los t\u00b4 erminos clave que contribuyen a la clasicaci\u00b4 on. Sin embargo, en problemas multi-etiqueta, como la detecci\u00b4 on de categor\u00b4 as de aspecto, se deben seleccionar diferentes t\u00b4 erminos dependiendo de cada categor\u00b4 a lo cual es un inconveniente para estos modelos. Motivados por esta misma idea de identicar y destacar la importancia de t\u00b4 erminos clave, en este trabajo se propone un esquema que permite enfatizar los t\u00b4 erminos de una opini\u00b4 on en funci\u00b4 on de suproximidad sem\u00b4 antica a cada categor\u00b4 a de aspecto. El esquema propuesto se evalu\u00b4 o en distintos conjuntos de datos de SemEval demostrando su efectividad en este escenario multi-etiqueta. Adem\u00b4 as, es posible aplicarlo a pesar de contar con pocos datos de entrenamiento, y puede combinarse con distintos modelos de clasicaci\u00b4 on, incluyendo redes neuronales profundas. Palabras clave: proximidad sem\u00b4 ponderaci\u00b4 on de t\u00b4 erminos, detecci\u00b4 on de categor\u00b4 as de aspecto. Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 117-127 recibido aceptado 23-05-2022 ISSN 1135-5948. DOI 10.26342/2022-69-10 \u00a9 Sociedad para Procesamiento del Lenguaje Se opinions a a product, service or topic of in- terest (Liu and Zhang, 2012). Dierent con- sumers may have dierent opinions about the same product or service. Through their opinions, consumers express their approval or rejection on particular aspects that they wish to highlight, which poses the challenge of grouping the opinions into opez Ramos and Arco Garc\u00b4 a, 2019). This challenge is tack- led named given the \"the spaghetti was tasteless nice\", named a since more than one aspect can be evaluated to dicult task because the category must be inferred from the con- text. One possibility for this is to observe dierent modiers in an opinion. Through the nature of each category, it is possible to infer the associated terms. example, in \"tasteless\" is to de- scribe the \"food\" a common approach used to attention mechanisms address this exam- ine the context of sentence and the most relevant terms for its clas- sication. In same way, they are like lexicon- based approaches in that they emphasize the most relevant terms associated with a cate- gory, except that these so au- nately, these approaches have some draw- backs for this application. On the one hand, this is a multi-label problem, so jointly iden- tied (Movahedi et al., 2019). On the other hand, like any deep learning approach, they require large training sets to achieve good re- sults (Chaudhari et al., 2021), and for it considers pre-trained embeddings; in a rst step it computes a representative vector for each category, and then, in a second step, it measures the sim- ilarity of each term vector with manner, with multi-label problems, is less sensitive to data scarcity and distribution, datasets from SemEval (Pontiki the two contributions mechanism. experiments, results, and their analysis. Finally, Section 5 points out our conclusions and future work. 2 Related work Aspect category to opinion a, 2019). introduced and entity. Aspect categories are usually not by terms they of overlapping categories\" (Pontiki et al., 2016). Previous research works in this successful lexicon- 2016), (Hercig et al., 2016), (Hetal and others, 2021). Over the last few years, deep learning models have brought signicant advances to the aspect category detection task. For ample, in (Toh and Su, 2016) it is described the construction of a set of binary Network was the best performer at SemEval 2016, and based on the analysis of its results, their authors concluded that the CNN out- put probabilities the most relevant fea- tures, and the combination of machine learning methods is a feasible approach for In networkwith BiLSTM and CNN layers. In addition, this work models the task as a multi-task jointly between both tasks. In (He et al., 2017) it is presented a and improved in (Movahedi et al., 2019). In this last work, instead of training several one-vs-all models, the authors proposed a single attention may not be able provide a based on the dier- ent categories. More recently, and in this direction, in (Zhang et al., 2021) it is pre- sented a multilayer to model to correctly handle short texts, since they provide very limited number of categories. In this way, the terms that could contribute the most to identifying any given as aspect categories in the training set. Themaincomponentsofourmethodare: i) the weighting terms, ii) the construc- components since the y represent the core contribution of our work. For the classication traditional described in Section 4. 3.1 weighting of as Ci, referred as emb(Ci). This vector is computed as the average of the vectors of words the lexicon of the aspect category that is under analysis will have a greater weight than those from less related words. were chosen due to their size so- the well as deep neu- ral networks like a CNN. In the rst case, the SP weights are integrated under the Bag of Words representation, while in the second case these weights are used to alter the em- beddings that feed networks. cases of Words model. Accordingly, is represented by vector the size of anopinionordocumenthaving the form d= [emb(t1),emb(t2),...,emb( tk)]. We pro- pose to alter each of these embeddings by multiplying them by a scalar that indicates the relevance of ti, denoted as emb(ti), is computed as indicated in Formula 4, and the new representation of the opinion dis as indicated in Formula 5. emb(ti) =SPCj(ti)\u00d7emb(ti) (4) which is based on a one-vs-all classication approach; the 4.1 Datasets For the experiments we considered two datasets from SemEval 2016 (Pontiki et al., 2016). Particularly, we used the collections for the restaurant domain in both English and Spanish. Table 1 describes the distri- bution be or automatically dened. For the experiments reported, we extracted lexicons training in interval [0,1] and repre- the termisbelievedtoexclusivelybelongtogiven example, the term \"tequila\" will have the \"drinks\" term \"of\" will have a it test ambience#general 293 126 255 66 dr inks#quality 31 10 47 22 dr inks#style options 29 11 32 12 dr inks#prices 14 10 20 4 fo od#quality 845 291 849 313 fo od#style options 192 69 137 55 fo od#prices 127 41 90 23 re staurant#general 540 222 422 142 re staurant#miscellaneous 14 13 98 33 re staurant#prices 115 39 80 21 se rvice#general 504 222 449 155 lo cation#general 15 18 28 13 Table 1: Aspect categories in aspect categories are formed by entity for the category food#quality, the entity is \"food\" and the attribute is \"quality\"). In particular, for the restaurant data set there are 12 predened aspect categories which are listed dierent es E ={ambience, drinks, each one of the entities and for each one of the attributes, and then we made the corresponding unions to dene lexicons all terms with respect to all categories. In order to only include in the lexicons the terms most strongly ve terms for four dierent lexicons, two in Spanish English. ambience#general food#quality term value term value ambiente 1.000 1.000 tr anquilo 0.976 platos experiments, we the proposed in combination with two each used as SVM: C = 2.5, kernel = linear, and De-gree = 2.5. For this particular case, the terms considered for the BOW represen- tation were those present in training set opinions from category under analy- to create dierent feature maps (Gehrmann et al., The rest settings for them are: activation=relu, pool-size = max length - kernel-size + 1, rides=1. The general settings of CNN architecture are: epochs = =sigmoide, and adam. Due to the fact that the datasets show a high level of imbalance, particularly because the task was approached baseline we but using the tra- ditional representations. That is, used BOW with tf-idf weigths, without including our SP weights. In the case of the CNN, we fed it with the pre- trained Glove embeddings without having al- We also considerthebaselineresultsreportedforeach SemEval 2016 task (Pontiki et al., our results against from state-of-the-art con- In particular, we consid- ered the top 3 results for the Spanish and the English datasets. The works considered are: GTI(Alvarez-L\u00b4 opez et al., 2016). vector machine, but also 3Empty classied as U: Uncon- strained and those that do not use any type of addi- tional resource are classied as debugged list of words ob- tai ned the training set to remove inter-category noise. TGB(C \u00b8etin et al., 2016). It uses rst for entities and are Then, in a second layer, these probabilities are combined to un- derstand which is the best combination of entity and attribute in order to deter- mine the target aspect categories. UWB(Hercig et BUTkn(Mach\u00b4 a It manually category occur- rence of these n-grams. XRCE(Brun, Perez, and a mantic ated in the with to categories are rep- resented. The classication is performed by looking word the opin- ions their relationships with 4.5 Experimental Results Table 3 presents a summary of the best re- sults obtained with our method as well as with the baseline congurations. The sec- ond and third columns refer to the congura- tion of the classier (kind and whether or not oversampling was used), while the fourth usefulness of the proposed method is clearly appreciated. For the Spanish collection, is achieved with the SVM classier using over- sampling, with = 2 and using the Twitter Glove embeddings of 200 dimensions for the computation of the SP weights. For English, the best results were achieved with theCNNarchitecturewithoversampling,and 2 and for the computa- best con- strained results from SemEval 2016 in both Spanish and comparisons ev- idence the relevance of the it shows competitive results in outperforms the posed method does not necessarily need to use external its implementa- example, the can be au- tomatically extracted from the training set, as we did in the experiments. For those cat- egories with a Despite in the to de- termine whether or not a category is in the stitute all category-oriented lexicons Figure 3), we clearly representative this approach is that it can be easily adapted to other do- mains or languages, as was observed in the experiments. To demonstrate the generality of our method, we performed another experiment the laptop dataset. The achieved results are shown in Table 7. In this case, only the best constrained work is taken as a reference for comparison. Our re- sultwasachievedusingtheSVMclassifer,ap- plying oversampling for balancing, and considering SVM - - 64.30 method CNN Yes Twitter 200d = 1 CNN Yes Wikipedia 300d - 60.50 Baseline SVM - - 64.30 method CNN Yes Wikipedia 300d = 2 CNN Yes Wikipedia 300d , for the restaurant domain in Spanish and English. For each method the result of its best conguration is e 4: to the ambience#general 293 40 inks#quality 31 17 10 90.00 dr inks#style options 29 9 11 45.45 dr inks#prices 14 8 10 55.55 fo od#quality 845 17 291 20.66 fo od#style options 192 62 69 58.06 fo od#prices 127 8 41 20.00 re staurant#general 540 23 222 29.22 re staurant#miscellaneous 14 28 13 100.00 re staurant#prices 115 23 39 52.63 se rvice#general 504 31 222 lo best the dataset. beddings of 300 dimensions for the computa- tion of the SP weights. be that, in of the large categories this dataset, aspect categories derived from 22 entities and 9 attributes, for the experiments we did not carried out any additional hyper- parameter adjustment.CategoryTraining inks#quality 47 10 22 45.45 dr inks#style options 32 9 12 58.33 dr inks#prices 20 7 4 75.00 fo od#quality 849 6 313 19.17 fo od#style options 137 6 55 50.91 fo od#prices 90 6 23 47.29 re staurant#general 422 4 142 42.14 re staurant#miscellaneous 98 4 33 78.79 re staurant#prices 80 10 21 47.62 se rvice#general 449 4 155 lo dataset. analysis a detailed analysis of the errors (refer to Tables 5 and 6), it can be noticed that 124 Monserrat V\u00e1zquez-Hern\u00e1ndez, Luis Villase\u00f1or-Pineda, Terms of three category-oriented le xicons of the restaurant domain. there is no a clear relationship between the characteristicsofthedatasetsanderrorrates. For the Spanish tween the from categories with diverse and also because they usu- ally appeared together with others. On the other hand, when correlating the size of the categories' lexicons with r= 0.355, However, analyzing these lexicons in greater and the dierent showed for the smallest cate- gories more than 80% of terms are others. One interesting example is entity category \"drinks\", for which any term was unique; even more, 40% of its terms are also in the lexicons of four or more cat- egories. For English, a similar behavior was observed, but, in addition, we noticed that for the category \"location#general\", with a single term but exclusive to this obtained icons in whole process, as well as dene them more 5 se- mantic proximity of each term in an opinion with respect categories' a non-supervised weighting scheme lexicons, nonetheless, they can it On the other hand, although the method is sensitive to small and imbalanced datasets than other supervised approaches, it is aected it was ob- served, the method achieved better results in Spanish than English, being the latter the collection with less instances and high imbal- ance our in collections having word embeddings due to the generality of the proposed method, we plan to apply provided ing Language Technologies. Alvarez-L\u00b4 Juncal-Mart\u00b4 nez, M. and Brun, J. Semantic Evaluation (SemEval-2016) pages for Computational Montes-y G\u00b4 omez. 2019. A text classication framework for simple and eective early depression detection over social media streams. Expert Systems with Applications , 133:182-197. C \u00b8etin, F. S., E. Yldrm, C. \u00a8Ozbey, 2016. on of models. (TIST) , Gehrmann, S., F. Dernoncourt, Y. Li, E. T. Carlson, J. T. Wu, J. Welt, J. Foote Jr, E. T. Moseley, D. W. Grant, P. D. Tyler, et al. 2018. Comparing deep learning and concept extraction He, R., W. S. Ng, and D. Dahlmeier. 2017. An for tional Brychc\u00b4 L. Svoboda, , 12(13):2348-2364. Liu, B. and L. Zhang. 2012. A survey of opinion mining and sentiment analysis. In Mining text data .Springer, pages415-463. L\u00b4 opez Ramos, D. and L. Arco Garc\u00b4 a. 2019. Aprendizaje profundo para la extracci\u00b4 on de aspectos en opiniones textuales. Re- vista Cubana de Ciencias Inform\u00b4 aticas , 13(2):105-145. Mach\u00b4 a Supervised mantic Evaluation (SemEval-2016) , pages Computational Linguistics. Movahedi, S., C. 2014. Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) Y. Zhao, B. 5: Toh, Semantic Evaluation (SemEval-2016) pages In *SEMEVAL. Xue, W., W. Zhou, Li, and Q. Wang. Mtna: a neural Proceedings of the Eighth In- ternational Joint Conference on Natural Language Processing (Volume 2: Short Papers), pages 151-156. Zhang, X., X. Song, A. Feng, and Z. Gao. Multi-self-attention M\u00b4 edicos de Psiquiatr\u00b4 a Non-suicidal Analysis Juan Martinez-Romo1,2 Lourdes Araujo1,2 1NLP & IR Group Universidad Nacional de Educaci\u00b4 on a Distancia (UNED) 2Instituto San Carlos Madrid imcapella@salud.madrid.org gseara@shealth.eu Resumen: La autolesi\u00b4 on no suicida, a menudo denominada autolesi\u00b4 on, es el acto de da narse deliberadamente el propio cuerpo, como cortarse o quemarse. Normalmente, no pretende ser un intento de suicidio. En este trabajo se presenta un sistema de detecci\u00b4 on de indicios de autolesiones no suicidas, basado en el an\u00b4 alisis del lenguaje, sobre un conjunto anotado de informes m\u00b4 edicos obtenidos del servicio de psiquiatr\u00b4 a de un Hospital p\u00b4 ublico madrile no. Tanto la explicabilidad como la precisi\u00b4 on a la hora de predecir los casos positivos, son los dos principales objetivos de este trabajo. Para lograr este n se han desarrollado dos sistemas supervisados de diferente naturale- za. Por un lado se ha llevado a cabo un proceso de extracci\u00b4 on de diferentes rasgos centrados en el propio mundo de las autolesiones mediante t\u00b4 ecnicas de procesamien- to del lenguaje natural para alimentar posteriormente un clasicador tradicional. Por otro lado, se ha implementado un sistema de aprendizaje profundo basado en varias capas de redes neuronales convolucionales, debido a su gran desempe no en tareas de clasicaci\u00b4 on de textos. El resultado es el funcionamiento de dos sistemas supervisados con un gran rendimiento, en donde destacamos el sistema basado en un clasicador tradicional debido a su mejor predicci\u00b4 on de clases positivas y la mayor facilidad de cara a explicar sus resultados a los profesionales sanitarios. Palabras clave: Detecci\u00b4 on de autolesiones one's own body, such as cutting or burning oneself. It is not usually intended as a suicide attempt. This paper presents a system for detecting signs of non-suicidal self-injury, based on language analysis, on an annotated set of medical reports obtained from the psychiatric service of a public hospital in Madrid. Both explainability and accuracy in predicting positive cases are the two main objecti- ves of this work. In order to achieve this goal, two supervised systems of dierent natures have been developed. On the one hand, a process of extraction of dierent features focused on the world of self-injury itself has been carried out using natural language processing techniques to subsequently feed a traditional classier. On the other hand, a deep learning system based on several layers of convolutional neural networks, due to its high performance in text classication tasks. The result are two supervised systems with high performance, where we highlight the system based on a traditional classier due to its better prediction of positive classes and the greater analysis, learning, neural networks. Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 129-140 recibido aceptado 30-05-2022 ISSN 1135-5948. DOI 10.26342/2022-69-11 \u00a9 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Natural1 Introducci\u00b4 on Los trastornos de salud mental, como las au- tolesiones, son problemas cuya incidencia en la poblaci\u00b4 on aumenta de manera alarmante en los \u00b4 ultimos a nos. Estas afecciones pueden pasardesapercibidasdurantemuchosa nos,lo que hace que las personas que las padecen no reciban la asistencia m\u00b4 edica adecuada. Los problemas de salud mental sin tratar pue- den acarrear graves consecuencias, como el deterioro personal o incluso el suicidio. Las autolesiones, tambi\u00b4 en conocidas como auto- lesiones deliberadas o autoagresiones, son un tipo de problema de salud mental menos co- nocido que afecta principalmente a los j\u00b4 ove- nes (Young et al., 2007). La autolesi\u00b4 on se re- ere al acto de causarse da no corporal a s\u00b4 mismo sin intenci\u00b4 on suicida, como cortarse, quemarse o tirarse del pelo, y se ha relaciona- do con problemas de salud mental subyacen- tes,comoladepresi\u00b4 onylaansiedad(Greaves, 2018b). Entre las diferentes acciones que las personas afectadas llevan a cabo dentro del concepto general de autolesi\u00b4 on, existen gran- des diferencias tanto en los motivos para lle- varlas a cabo, como en el g\u00b4 enero (Rodham, Hawton, y Evans, 2004). La naturaleza a me- nudo impulsiva de estos actos (especialmen- te el auto-corte) signica que la prevenci\u00b4 on en fomentar m\u00b4 etodos alterna- tivos de gesti\u00b4 on de la ansiedad, la resoluci\u00b4 on de problemas y la b\u00b4 usqueda de ayuda antes de que se desarrollen pensamientos de auto- lesi\u00b4 on. Dada la gravedad de los s\u00b4 ntomas y los riesgos, es importante dedicar esfuerzos a detectar mejor los problemas de salud men- tal en la sociedad para que puedan recibir la ayuda que necesitan. Tambi\u00b4 en se han en- contrado diferencias en la forma de comuni- carse y en el lenguaje empleado por las per- sonas que sufren problemas de salud mental (Pennebaker, Mehl, y Niederhoer, 2003). A pesar de que los edicos an ge- neralmente escritos por m\u00b4 edicos, en ocasio- nes tratan de plasmar las ideas subyacentes del paciente e incluso escriben literalmente frases o expresiones utilizadas y que puedan denotar de forma clara estados de \u00b4 animo o pensamientos. De esta forma, el an\u00b4 alisis del lenguaje empleado en estos informes m\u00b4 edi- cos mediante t\u00b4 ecnicas de Procesamiento del Lenguaje Natural (PLN) pueden ayudar a la detecci\u00b4 on temprana de pacientes con otros trastornos previos. Sin embargo, cabe se nalar quelamayor\u00b4 adelosestudiossobredetecci\u00b4 ontemprana de peligros para la seguridad y la salud se han centrado en el texto en ingl\u00b4 es. Por otra parte, hay que se nalar que apenas existen conjuntos de datos (datasets o corpo- ra) para entrenar modelos de identicaci\u00b4 on en las tareas mencionadas, y los existentes se limitan al ingl\u00b4 es y son de tama no reducido, lo cual es un claro indicador del camino que a\u00b4 un queda por recorrer para que los profesionales sanitarios puedan disponer de herramientas maduras de an\u00b4 alisis de textos. En este tra- bajo se presenta un sistema de detecci\u00b4 on de autolesiones en informes m\u00b4 edicos proceden- tes del servicio de psiquiatr\u00b4 a del Hospital Cl\u00b4 nico San Carlos de Madrid. Este sistema de detecci\u00b4 on de autolesiones entrenado y eva- luado sobre un corpus anotado de informes m\u00b4 edicos, tiene el objetivo de aplicarse a cual- quier informe del servicio de psiquiatr\u00b4 a para permitir la detecci\u00b4 on temprana de este tras- torno en pacientes que hayan sido tratados por dicho servicio. De esta forma, pacientes con otro tipo de trastornos de car\u00b4 acter m\u00b4 as leve, podr\u00b4 an ser diagnosticados y recibir tra- tamiento antes de adquirir estos h\u00b4 abitos tan perjudiciales. Y es que la detecci\u00b4 on tempra- na es clave en el tratamiento de los proble- mas de salud mental, ya que una intervenci\u00b4 on r\u00b4 apida mejora las probabilidades de un buen pron\u00b4 ostico. El resto del art\u00b4 culo se organiza de la si- guiente forma: en la Secci\u00b4 on 2 se analiza el estado del arte y trabajos relacionados. en la Secci\u00b4 on 3 se describe el corpus y las t\u00b4 ecnicas utilizadaparaanotarlo.EnlaSecci\u00b4 on de autolesiones. La Secci\u00b4 on 5 se centra en la experimentaci\u00b4 on y el an\u00b4 alisis de resul- tados. Finalmente, en la Secci\u00b4 on 6 se extraen las principales conclusiones y se exponen las l\u00b4 neas de trabajo futuro. 2 Estado del Arte El estudio de las autolesiones y m\u00b4 as concreta- mentedesuinvestigaci\u00b4 onatrav\u00b4 esdelan\u00b4 alisis de textos no es demasiado extenso. Existen trabajos (Baetens et al., 2011) en los que se investigaronlaprevalenciadelasautolesiones no suicidas (NSSI) y las autolesiones suicidas (SSI)enunamuestradeadolescentesdeentre 12 y 18 a nos, as\u00b4 como las diferencias psico- sociales entre los adolescentes que practican NSSI y los que practican SSI. Tambi\u00b4 en hay trabajos (Nicolai, Wielgus, y Mezulis, 2016) que apoyan la teor\u00b4 a de la cascada emocio- 130 Juan Martinez-Romo, Lourdes Araujo, Blanca Reneses, J. Sevilla-Llewellyn-Jones, Ignacio Mart\u00ednez-Capella, Germ\u00e1n Seara-Aguilar nal, en la que la rumiaci\u00b4 on distingue entre las personas que se autolesionan y las que no lo hacen, y hacen especial hincapi\u00b4 e en la re- laci\u00b4 on entre el afecto negativo y las NSSI. Hay trabajos (Burke, Ammerman, y Jaco- bucci, 2019) que se han centrado en abordar las limitaciones de los sistemas de detecci\u00b4 on de riesgo y el tiempo de c\u00b4 omputo utilizan- do herramientas anal\u00b4 ticas avanzadas, como el procesamiento del lenguaje natural (PLN) y el aprendizaje autom\u00b4 atico. Existen estudios centrados en la ideaci\u00b4 on de suicidio que usan enfoques de PLN y que han utilizado en gran medida modelos basados en la historia cl\u00b4 ni- ca electr\u00b4 onica 2017) y mo- delos de predicci\u00b4 on basados en PLN y rasgos ling\u00a8 u\u00b4 sticos(Fernandesetal.,2018;McCoyet al., 2016; Poulin et al., 2014). En 2017, un trabajo (Walsh, Ribeiro, y Franklin, 2017) utiliz\u00b4 o aprendizaje autom\u00b4 ati- co para predecir el riesgo de suicidio en pa- cientes de autolesiones a lo largo del tiempo analizando informes m\u00b4 edicos de una gran ba- se de datos m\u00b4 edica. Tambi\u00b4 en se han usado tests adaptativos informatizados (CAT) para entrenar un \u00b4 arbol de decisi\u00b4 on con el objeti- vo de predecir el riesgo de suicidio (Delgado- Gomez et al., 2016). Otros trabajos (Metz- ger et al., 2017) han empleado algoritmos de clasicaci\u00b4 on como random forest and na\u00a8 ve Bayes sobre informes m\u00b4 edicos para prede- cir demostrando que los m\u00b4 etodos de aprendizaje autom\u00b4 atico pueden mejorar la calidad de los indicadores epidemiol\u00b4 ogicos en comparaci\u00b4 on con la actual vigilancia nacio- nal de los intentos de suicidio de un pa\u00b4 s co- mo Francia. Los \u00b4 arboles de decisi\u00b4 on tambi\u00b4 en se han usado en otros trabajos (Mann et al., 2008) para estudiar la correlaci\u00b4 on entre pa- cientes de psiquiatr\u00b4 a analizando su conducta suicida pasada frente a la ideaci\u00b4 on de suicidio que mostraban en un momento dado. La clasicaci\u00b4 on de textos cl\u00b4 nicos median- te redes neuronales ha resultado una herra- mientadegranutilidadenproblemascomola identicaci\u00b4 on de fenotipos en informes m\u00b4 edi- cos para pacientes con un conjunto determi- nado de signos y s\u00b4 ntomas cl\u00b4 nicos (Obeid et al., 2019). En los \u00b4 ultimos a nos se han produ- cido avances signicativos en los enfoques de aprendizaje profundo, como las redes neuro- nales convolucionales (CNN), y su aplicaci\u00b4 on ha sido un \u00b4 exito en problemas como el pro- cesamiento y la clasicaci\u00b4 on de textos o elreconocimiento del habla (LeCun, Bengio, y Hinton, 2015). Recientemente ha surgido un estudio (Obeid et al., 2020) que aprovecha la infor- maci\u00b4 on de las notas cl\u00b4 nicas utilizando redes neuronales profundas (DNNs) para identi- car los pacientes tratados por autolesi\u00b4 on in- tencional y predecir futuros eventos de au- tolesi\u00b4 on. Los autores utilizaron dos modelos basados en una CNN y en una LSTM con re- sultados prometedores. Tambi\u00b4 en se han usa- do t\u00b4 ecnicas de clasicaci\u00b4 on como el Gradient Boosting para la detecci\u00b4 on de autolesiones e ideaci\u00b4 on suicida en las notas de triaje de los servicios de urgencias (Rozova et al., 2022). En los \u00b4 ultimos a nos han aparecido bastan- tes trabajos en el \u00b4 ambito de las redes sociales y la salud mental. Aunque el formato del tex- to de las redes sociales y en lenguaje escrito en primera persona hacen abordar este pro- blema desde un enfoque diferente, queremos destacar algunos trabajos por su relevancia y su cercan\u00b4 a al problema de las autolesiones. Desde 2017 y de forma anual se celebra la tarea competitiva eRisk (Losada, Cresta- ni, y Parapar, 2019; Parapar dentro del congreso CLEF (Cross Language Evaluation Forum). eRisk trata de avanzar en la predic- ci\u00b4 on temprana en redes sociales de problemas relacionados con la salud mental. Depresi\u00b4 on, anorexia, ludopat\u00b4 a y autolesiones desde el a no 2019 han sido los trastornos elegidos por los organizadores. Dentro de esta competi- ci\u00b4 on, un sistema con resultados prometedores fue el equipo iLab (Martnez-Castano et al., 2020)enelquelosinvestigadorespropusieron un sistema de clasicaci\u00b4 on basado en BERT y transformers. En contraposici\u00b4 on al uso pe- sado de las redes neuronales y los transfor- mers, tambi\u00b4 en resultan interesantes las par- t\u00b4 PLN y an\u00b4 y eciente. Fi- nalmente, un trabajo que obtuvo buenos re- sultados con un sistema innovador fue el del grupo UNSL(Loyola et al., 2021), que emple\u00b4 o pol\u00b4 ticas de alerta, un sistema basado en re- glas y un modelo de aprendizaje por refuerzo. 3 Corpus El corpus de evaluaci\u00b4 on procede de un con- junto de informes m\u00b4 edicos anonimizados pro- 131 Detecci\u00f3n de Indicios de Autolesiones No Suicidas en Informes M\u00e9dicos de Psiquiatr\u00eda Mediante el An\u00e1lisis del Lenguaje cedentes del servicio de psiquiatr\u00b4 a del Hospi- tal Cl\u00b4 nico San Carlos de Madrid en Espa na. La preparaci\u00b4 on de los informes para su an\u00b4 alisis ha sido desarrollada por la Unidad de Innovaci\u00b4 on del Hospital Cl\u00b4 nico San Carlos, a partir de la descarga autorizada de informes informatizados del Servicio de Psiquiatr\u00b4 a co- rrespondientes a un periodo de cuatro a nos. Dicha preparaci\u00b4 on ha consistido en tres fases: limpieza de los informes, compleci\u00b4 on y anoni- mizaci\u00b4 on. Previamente, esta cesi\u00b4 on de datos fue evaluada y aprobada por el Comit\u00b4 e de \u00b4Etica de la Investigaci\u00b4 on (20/586-E). A partir de este conjunto de informes ano- nimizados, se llev\u00b4 o a cabo un proceso de ano- taci\u00b4 on por parte de expertos dando lugar a un corpus de 1252 informes anotados. Los diagn\u00b4 osticos de estos informes son diversos, pero entre ellos no se incluye sufrir autolesio- nes. Por ello ha sido necesaria una anotaci\u00b4 on manual supervisada por los m\u00b4 edicos exper- tos en base al contenido textual de los infor- mes. Tras la anotaci\u00b4 on manual en busca de indicios de autolesiones, 1138 han sido ano- tados como negativos y 114 como positivos. Durante el proceso de anotaci\u00b4 on, se buscaban indicios claros de que el profesional sanitario que hubiera atendido al paciente indicara que las autolesiones se hab\u00b4 an producido. La me- ra ideaci\u00b4 on o pensamiento de esta situaci\u00b4 on fue tratada como un caso negativo. En el ca- so de situaciones en las que las autolesiones ten\u00b4 an un n autol\u00b4 tico tambi\u00b4 en fueron eti- quetadas como casos negativos al buscar otro n diferente al ansiol\u00b4 tico. Estos \u00b4 ultimos ca- sos deber\u00b4 an tratarse en un estudio diferente como parte de los pacientes con riesgo de sui- cidio. Los informes tienen una media de 1310 palabras y 7566 caracteres por cada informe, teniendo el informe de mayor tama no 1639 palabras y 32767 caracteres y el de menor ta- ma no 84 palabras y 510 caracteres. El corpus se ha dividido en dos conjuntos de entrena- miento (80%) y test (20%), resultando dos conjuntos de 1001 y 251 informes respectiva- mente.Ladivisi\u00b4 onsehallevadoacabodefor- ma estraticada para respetar la proporci\u00b4 on de clases en los conjuntos de entrenamiento y test. 4 Sistema de Detecci\u00b4 on de Autolesiones Para la tarea de detecci\u00b4 on de autolesiones se han desarrollado dos sistemas supervisados, uno de ellos basado en la extracci\u00b4 on de ras-gos y la aplicaci\u00b4 on de algoritmos cl\u00b4 asicos de clasicaci\u00b4 on y el otro basado en redes neuro- nales con la aplicaci\u00b4 on de un modelo BERT para el tokenizado. Los dos sistemas desarro- llados solo analizan el texto anonimizado del informesintenerencuentaeldiagn\u00b4 osticoque apareceenotrocampoyques\u00b4 olohasidoteni- do en cuenta en el proceso de anotaci\u00b4 on ma- nual para ayudar a los expertos en caso de duda. 4.1 Sistema de Aprendizaje Autom\u00b4 atico El sistema supervisado est\u00b4 a compuesto de tres m\u00b4 odulos diferentes que se encargan de las tareas de pre-procesamiento, extracci\u00b4 on de rasgos y aplicaci\u00b4 on de algoritmos de clasi- caci\u00b4 on. 4.1.1 Pre-procesamiento de los Informes M\u00b4 edicos En cuanto al pre-procesamiento se han apli- cado las t\u00b4 ecnicas habituales, como son la a min\u00b4 usculas del texto, la elimina- ci\u00b4 on de caracteres especiales, la normaliza- ci\u00b4 on de determinados conectores, el tokeniza- do del texto y el borrado de palabras vac\u00b4 as. Tambi\u00b4 en se ha llevado a cabo un proceso de stemming mediante el segundo algoritmo de Porter para extraer la ra\u00b4 z de las palabras. 4.1.2 Extracci\u00b4 on de Rasgos y Algoritmos de Clasicaci\u00b4 on La extracci\u00b4 on de rasgos se puede agrupar en cinco conjuntos de caracter\u00b4 sticas: CountVectorizer : En primer lugar se ha utilizado la herramienta CountVec- torizer de la biblioteca scikit-learn en Python para obtener vectores de pala- bras a partir de los informes m\u00b4 edicos. Esta herramienta se utiliza para trans- formar un texto dado en un vector sobre la base de la frecuencia de cada palabra que aparece en todo el texto. La funci\u00b4 on crea una matriz en la que cada palabra \u00b4 unica est\u00b4 a representada por una colum- na de la matriz, y cada muestra de texto del documento es una la en dicha ma- triz.Elvalordecadaceldanoesm\u00b4 asque la frecuencia de la palabra en esa mues- tra de texto en particular. Vocabulario de Autolesiones : Se ha compilado un conjunto de 53 palabras relacionadas con el contexto de las auto- lesiones. En este conjunto hay palabras 132 Juan Martinez-Romo, Lourdes Araujo, Blanca Reneses, J. Sevilla-Llewellyn-Jones, Ignacio Mart\u00ednez-Capella, Germ\u00e1n Seara-Aguilar como morder, cortar, pellizcar, etc. Es- te conjunto de palabras, se emplea co- mo entrada del CountVectorizer para no usar todo el vocabulario completo sino solo estas 53 palabras, algo que propor- ciona mayor rapidez y precisi\u00b4 on. Diccionario NSSI: Greaves 2018a) desarroll\u00b4 o un trabajo en el que llev\u00b4 o a cabo la clasicaci\u00b4 on de un con- junto de conceptos relacionados con las autolesiones.Elresultadodeestetrabajo es un diccionario de palabras relaciona- das con la autolesi\u00b4 on llamado Dicciona- rioNon-SuicidalSelf-Injury(NSSI),don- de las palabras se dividen cinco 1) NSSI; utilizados; Razones de NSSI; y (5) T\u00b4 erminos es- pec\u00b4 cos de cortes. De esta forma, se han creado cuatro rasgos de NSSI, uno pa- ra cada categor\u00b4 a. Estas caracter\u00b4 sticas cuentan la frecuencia de las palabras de su categor\u00b4 a en el texto. Distancia de T\u00b4 erminos de Autole- siones: Existen numerosos trabajos que han probado la relevancia de las prime- ras palabras de un documento en rela- ci\u00b4 on al texto completo. En este grupo de rasgos se ha tratado de medir por un la- do la distancia entre el inicio del docu- mento y la primera palabra del vocabu- lario de autolesiones presente en el texto y por otro lado la distancia media entre palabrasdelvocabulariodeautolesiones. Estas medidas se han realizado en fun- ci\u00b4 on del n\u00b4 umero de palabras y del n\u00b4 ume- ro de caracteres, dando lugar a cuatro rasgos. Negaci\u00b4 on : Se ha llevado a cabo un pro- ceso de detecci\u00b4 on de la negaci\u00b4 on median- te una arquitectura (Fabregat, Arau- jo Serna, y Mart\u00b4 nez Romo, 2019; Fa- bregat et al., 2019) basada en aprendi- detecci\u00b4 on de la nega- ci\u00b4 onsehaaplicadoalosgruposderasgos denidos anteriormente para eliminar la presencia de los t\u00b4 erminos de autolesio- nes que han sido negados y de esta for- ma restar su incidencia. Es decir, si en el texto aparece una armaci\u00b4 on como \"No se aprecian cortes\", la detecci\u00b4 on de ne- gaci\u00b4 on evita que el t\u00b4 ermino \"cortes\" se contabilice en ninguno de los rasgos cal- culados en este trabajo.Una vez extra\u00b4 dos los rasgos descritos an- teriormente y con la ayuda del corpus anota- do, se ha llevado a cabo la aplicaci\u00b4 on de los algoritmos m\u00b4 as efectivos seg\u00b4 un el estado del arte en este tipo tareas. 4.2 Sistema basado en Aprendizaje Profundo El segundo sistema usa redes neuronales con una arquitectura en la que se disponen tres capas de redes neuronales convolucionales y para la que se ha adaptado la tecnolog\u00b4 a de BERT (Devlin et al., 2018) para el proceso de tokenizado, que est\u00b4 a basado en la repre- sentaci\u00b4 on de codicadores binarios a partir de Transformers. En este caso, hemos adap- tado esta tecnolog\u00b4 a para la clasicaci\u00b4 on de textos. Aparte de la preparaci\u00b4 on del texto, para el tokenizado de los textos m\u00b4 edicos, hemos usa- do dos modelos pre-entrenados: Un modelo base de BERT1que est\u00b4 a disponible en seis idiomas, incluido el espa nol, y fue creado pa- ra tareas de clasicaci\u00b4 on de textos. Y el mo- delo RoBERTa-base-bne2, que es un modelo de lenguaje enmascarado basado en transfor- mersparaelespa nol.Est\u00b4 abasadoenelmode- lo base de RoBERTa y ha sido pre-entrenado utilizando el mayor corpus en espa nol cono- cido hasta la fecha, con un total de 570GB de texto limpio y procesado expresamente para este trabajo. El texto procede de una com- pilaci\u00b4 on de p\u00b4 aginas web realizada por la Bi- blioteca Nacional Espa nola desde 2009 hasta 2019. De esta forma, se ha adoptado una arqui- tecturaqueconstadetrescapasderedesneu- ronales convolucionales concatenadas. La ar- quitectura del sistema de aprendizaje profun- do usada para este trabajo puede apreciarse enlaFigura1,enlaquesemuestraanivelge- neral la arquitectura de la red neuronal, con tres capas de redes neuronales convoluciona- les (CNN) y dos capas de redes neuronales densamente conectadas, la \u00b4 ultima empleada como capa de clasicaci\u00b4 on. 5 Resultados Para la evaluaci\u00b4 on de los dos sistemas desa- rrollados vamos a usar las medidas tradicio- nales precisi\u00b4 on, cobertura y 2https://huggingface.co/PlanTL-GOB- ES/roberta-base-bne 133 Detecci\u00f3n de Indicios de Autolesiones No Suicidas en Informes M\u00e9dicos de Psiquiatr\u00eda Mediante el An\u00e1lisis del Lenguaje Figura 1: Arquitectura de la red neuronal. me dida-F. Adem\u00b4 as, como la detecci\u00b4 on de ca- sos de autolesiones es una tarea cuyas impli- caciones requieren una gran precisi\u00b4 on, uno de los principales objetivos de este trabajo es la b\u00b4 usqueda de un buen desempe no a la hora de predecir casos positivos. Tambi\u00b4 en el hecho de serunatarearelacionadaconlasalud,requie- re de un grado satisfactorio de explicabilidad de cara a los profesionales que en \u00b4 ultima ins- tancia deben de tomar las decisiones. 5.1 Baselines En primer lugar, hemos desarrollado cuatro baselines para medir la calidad de los siste- mas supervisados. Most frequent Class (MFC): El sis- tema anota todos los casos con la clase m\u00b4 as frecuente, que en este caso es la cla- se negativa. Less frequent Class (LFC): El siste- maanotatodosloscasosconlaclaseme- nos frecuente, que en este caso es la clase positiva. Random prediction: El sistema asig- na una predicci\u00b4 on aleatoria a cada ins- tancia. Random Ratio prediction: El siste- ma asigna mediante una funci\u00b4 on de pro-babilidad una predicci\u00b4 on aleatoria a ca- da instancia, manteniendo el mismo ra- tio (positivas/negativas) de anotaciones que el conjunto de test. La Tabla 1 muestra los resultados tras la aplicaci\u00b4 on de los baselines. Como era de espe- rar, al tratarse de un corpus desbalanceado, el baseline que mejor rendimiento obtiene es aquel que predice como negativos todos los casos al ser la clase mayoritaria. 5.2 Combinaci\u00b4 on de Rasgos En la Tabla 2 se pueden apreciar los resulta- dos obtenidos tras diferentes combinaciones de los rasgos descritos en la secci\u00b4 on 4.1.2. Pa- ra estos resultados se ha aplicado un algorit- mo de regresi\u00b4 on log\u00b4 stica. De forma evidente en cuanto a la hip\u00b4 otesis de partida, los peo- res resultados se obtienen con los vectores de palabras formados por el vocabulario com- pleto del corpus (32K palabras) y los mejo- res se consiguen con la combinaci\u00b4 on de todos los rasgos computados. En cuanto a la parte m\u00b4 as interesante de esta combinaci\u00b4 on, destaca la diferencia entre la mejora obtenida por la clase negativa y la positiva al introducir los rasgos. La clase negativa solo aumenta tres puntossumedida-F,mientrasquelaclasepo- sitiva aumenta 21 puntos al introducir todos los rasgos. Esta diferencia demuestra la e- ciencia de los rasgos introducidos en cuanto al prop\u00b4 osito general de mejorar sobre todo la predicci\u00b4 on de los casos positivos. En cuanto a los rasgos, analizados de manera individual, destaca la aportaci\u00b4 on de los vectores de pala- bras obtenidos a partir del vocabulario com- pilado manualmente de 53 palabras. La dife- rencia entre usar el vocabulario completo o solo las 53 palabras, se refleja en un aumento de 14 puntos en la medida-F de la clase posi- tiva, aumentando tanto la precisi\u00b4 on como la cobertura. Los rasgos que menos aportaci\u00b4 on parecen tener en el c\u00b4 omputo global son las distancias entre t\u00b4 erminos de autolesiones y la negaci\u00b4 on, quiz\u00b4 as debido a que no se produ- cen demasiadas en los informes m\u00b4 edicos o su relevancia es menor de la esperada en cuanto al contexto global del informe. En cuanto a la clase positiva, la precisi\u00b4 on y cobertura au- mentandeformadesigual,teniendolosrasgos computados un impacto mayor en la preci- si\u00b4 on que en la cobertura. Este hecho era de esperar dado que al menos el rasgo que usa los vectores de palabras con un vocabulario 134 Juan Martinez-Romo, Lourdes Araujo, Blanca Reneses, J. Sevilla-Llewellyn-Jones, Ignacio Mart\u00ednez-Capella, Germ\u00e1n Seara-Aguilar BASELINES los casos negativos, F1-weighted Avg: F1-measure media de todo el conjunto de test, P-SI: Precisi\u00b4 on de los casos positivos, R-SI: Recall de los casos positivos reducido implica profundizar en esa direcci\u00b4 on precisamente. 5.3 An\u00b4 alisis de diferentes algoritmos de Clasicaci\u00b4 on En la secci\u00b4 on anterior se emple\u00b4 o un algoritmo de regresi\u00b4 on log\u00b4 stica para la tarea de clasi- caci\u00b4 on. En la Tabla 3 se muestran los resul- tados al aplicar los diferentes algoritmos de clasicaci\u00b4 on que mejor rendimiento han ob- tenido en diferentes trabajos del estado del arte consultados. Para esta comparativa se ha usado la combinaci\u00b4 on de rasgos que me- jor rendimiento obtuvo en la secci\u00b4 on anterior y cuyos resultados se pueden observar en la Tabla 2. Como se puede ver, hay tres algorit- mos (Logistic Regression, Gradient Boosting y SVM) que obtienen los mejores resultados en cuanto a la medida-F global. Sin embar- go, como uno de los objetivos de este trabajo consiste en mejorar la detecci\u00b4 on de la clase positiva, se observa que el algoritmo \"Gra- dient Boosting\" obtiene el mejor rendimien- to en la predicci\u00b4 on de casos positivos. Esto unido a que era uno de los tres algoritmos que de forma global obten\u00b4 an mejores resul- tados lo convierten en la mejor opci\u00b4 on para nuestro sistema. Profundizando en los resul- tados de \"Gradient Boosting\", aparte de ob- tener los mejores resultados en las clases po- sitivas, negativas, y de forma global, obtiene mejor cobertura que ning\u00b4 un otro algoritmo. Esta parece ser su mejor aportaci\u00b4 on, ya que su precisi\u00b4 on en la clase positiva es superada por otros algoritmos. 5.4 Sistema basado en Aprendizaje Profundo En la Tabla 4 se puede observar el rendi- miento de los sistemas basados en redes neu- ronales. Se ha optado por variar dos hiper- par\u00b4 ametros como son el n\u00b4 umero de \u00b4 epocasy el dropout. En todos los experimentos se han usado embeddings de 200 dimensiones. De los resultados obtenidos en cuanto a las diferentes combinaciones no se pueden obte- nerdemasiadasconclusiones.Quiz\u00b4 assepuede observar que dimientoglobalaunquenoesconcluyente.De formageneralpodr\u00b4 adecirsequecinco\u00b4 epocas han funcionado mejor que diez, al igual que ocurre para la clase positiva con la que lige- ramente se observan mejores resultados. En cuanto a la precisi\u00b4 on de los casos positivos, con una combinaci\u00b4 on se obtienen mucho me- jores resultados que con el resto, sin embargo su cobertura y medida-F se ven negativamen- te afectadas. La \u00b4 unica conclusi\u00b4 on evidente a nivel de diferentes combinaciones se produ- ce en la cobertura de la clase positiva. En este caso un menor n\u00b4 umero de \u00b4 epocas y un bajo dropout implican un signicativo mejor rendimiento que los casos opuestos con una diferencia de 50 puntos. 5.5 An\u00b4 alisis Global de Resultados De forma general y tal como se muestra en la Tabla 5, los sistemas desarrollados superan ampliamentealosbaselinespropuestosalini- cio del trabajo. En cuanto a la comparativa entre el mejor sistema supervisado y el me- jor sistema basado en redes neuronales, glo- balmente el sistema de aprendizaje profundo obtiene mejores resultados si atendemos a la medida-F. Sin embargo, la peque na diferen- cia a favor de las redes neuronales en relaci\u00b4 on a la medida-F global y de la clase negativa, se ve ampliamente superada en cuanto a la clase positiva tanto en la medida-F como en la pre- cisi\u00b4 on y la cobertura. Destaca notablemente la diferencia en la precisi\u00b4 on, de forma muy signicativa la medida-F y de forma relevan- te la cobertura, siendo esta \u00b4 ultima la medi- da donde la diferencia de rendimiento es algo 135 Detecci\u00f3n de Indicios de Autolesiones No Suicidas en Informes M\u00e9dicos de Psiquiatr\u00eda Mediante el An\u00e1lisis del Lenguaje COMBINACI \u00b4ON de distancia autolesion, NEG: Negaci\u00b4 on ALGORITMOS DE CLASIFICACI los casos negativos, F1-weighted Avg: F1-measure media de todo el conjunto de test, P-SI: Precisi\u00b4 on de los casos positivos, R-SI: Recall de los casos positivos menor. De esta forma, y teniendo en cuen- ta las implicaciones en cuanto a mejor expli- cabilidad del sistema supervisado basado en el algoritmo \"Gradient Boosting\", considera- mos que la opci\u00b4 on m\u00b4 as \u00b4 optima para la tarea concreta en la que se centra este trabajo es dicho sistema. 5.6 An\u00b4 alisis de la Incidencia de las Categor\u00b4 as de Rasgos Dado que el sistema supervisado ofrece un mejor rendimiento en la detecci\u00b4 on de casos positivos y adem\u00b4 as su grado de explicabili- dad es mayor, hemos decidido profundizar en los rasgos extra\u00b4 dos y su incidencia en los re- sultados. En la gura 2 se muestra un gr\u00b4 a- co de barras que representa la frecuencia de aparici\u00b4 on de los rasgos que componen las di- ferentes categor\u00b4 as en funci\u00b4 on de la clase a la que pertenecen. Dicha frecuencia se ha nor- malizado en funci\u00b4 on del n\u00b4 umero de documen- tos de cada clase y tama no del vocabulario de cada categor\u00b4 a, dado que el corpus est\u00b4 a muy desbalanceado. En esta gura destacan positivamente categor\u00b4 as como el vocabula- rio de autolesiones, los t\u00b4 erminos de NSSI, los conceptos de autolesiones por cortes de NS- SI y la negaci\u00b4 on. En cuanto al vocabulariode autolesiones, se intu\u00b4 a esta diferencia de- bido a los resultados obtenidos. En cuanto a la negaci\u00b4 on, tambi\u00b4 en se observa una gran disparidad. Finalmente en cuanto a los con- ceptos de NSSI, los que mejor parecen repre- sentar a la clase positiva son los \"T\u00b4 erminos\" y el \"Cutting\". Sin embargo, los conceptos de \"Razones\", \"M\u00b4 etodos\" e \"Instrumentos\" ofrecen una menor divergencia. Una posible explicaci\u00b4 on del distinto funcionamiento de es- tos conceptos de NSSI reside en el hecho de quelosinformesm\u00b4 edicostratandereflejarlos hechos m\u00b4 as relevantes representados segura- mente de una forma gen\u00b4 erica y sin profun- dizar en determinados aspectos. De esta for- ma, los conceptos de \"Razones\", \"M\u00b4 etodos\" e \"Instrumentos\" implican un mayor detalle en la descripci\u00b4 on del suceso del que se suele encontrar en un informe. En la gura 3 se observa un gr\u00b4 aco de ba- rras en el que aparecen las ra\u00b4 ces de los t\u00b4 ermi- nos m\u00b4 as frecuentes del vocabulario de auto- lesiones ordenados por su frecuencia norma- lizada de aparici\u00b4 on y en funci\u00b4 on de la clase a la que pertenecen. Como se puede obser- var,ra\u00b4 cescomo\"autolesi\u00b4 on\",\"cort\"y\"rasg\" presentan una gran diferencia a favor de las clases positivas, mientras que otras ra\u00b4 ces co- 136 Juan Martinez-Romo, Lourdes Araujo, Blanca Reneses, J. Sevilla-Llewellyn-Jones, Ignacio Mart\u00ednez-Capella, Germ\u00e1n Seara-Aguilar Red Neuronal F1 Todas F1-NO F1-SI F1-weighted Avg + BERT los casos negativos, F1-weighted Avg: F1-measure media de todo el conjunto de test, P-SI: Precisi\u00b4 on de los casos positivos, R-SI: Recall de los casos positivos. Los sistemas var\u00b4 an en funci\u00b4 on del n\u00b4 umero de \u00b4 epocas (5-10 ep) y el dropout (0.05-0.4 do). COMPARATIVA DE RESULTADOS Sistema F1 Todas los casos negativos, F1-weighted Avg: F1-measure media de todo el conjunto de test, P-SI: Precisi\u00b4 on de los casos positivos, R-SI: Recall de los casos positivos mo \"tir\", e \"inger\" muestran una aparici\u00b4 on m\u00b4 as equilibrada dado los conceptos m\u00b4 as neu- trales que representan en cuanto a las autole- siones. Destaca la ra\u00b4 z \"sangr\", teniendo m\u00b4 as peso en la clase negativa debido seguramente a que las lesiones relacionadas con la sangre no son las m\u00b4 as frecuentes en el problema es- tudiado.6 Conclusiones y trabajo futuro En este trabajo se presenta un sistema de de- tecci\u00b4 on de indicios de autolesiones no suici- das, basado en el an\u00b4 alisis del lenguaje, sobre un conjunto anotado de informes m\u00b4 edicos ob- tenidos del servicio de psiquiatr\u00b4 a de un Hos- pital p\u00b4 ublico madrile no. Dada la naturaleza tan cr\u00b4 tica de la tarea y las implicaciones a 137 Detecci\u00f3n de Indicios de Autolesiones No Suicidas en Informes M\u00e9dicos de Psiquiatr\u00eda Mediante el An\u00e1lisis del Lenguaje Figura 2: Frecuencia normalizada de las dife- re ntes categor\u00b4 as de rasgos en funci\u00b4 on de la clase. Figura 3: Frecuencia normalizada de t\u00b4 ermi- nos de autolesiones en funci\u00b4 on de la clase. la hora de predecir incorrectamente un caso, que realmente tiene detr\u00b4 as a un ser humano real, es necesario tratar este tipo de trabajos desde un punto de vista diferente al mero re- sultado obtenido por un conjunto de m\u00b4 etricas de evaluaci\u00b4 on. Al inicio del trabajo se ja- ron tres objetivos prioritarios: por un lado el sistema deber\u00b4 a obtener un alto rendimiento para impedir en la medida de lo posible las predicciones err\u00b4 oneas, por otro lado la clasi- caci\u00b4 on correcta de los casos positivos deber\u00b4 a ser prioritaria, y nalmente se deber\u00b4 a bus- car la mayor explicabilidad del sistema para que el profesional sanitario pudiera tener la m\u00b4 axima informaci\u00b4 on de cara a tomar una de- cisi\u00b4 on nal. Teniendo en cuenta estos requisi- tos, el trabajo ha cumplido con los objetivos. Por un lado el rendimiento global obtenidoalcanza unos valores de medida-F de 0.95, al- canzando un 0.68 de medida-F para los casos positivos, lo cual es una prueba de su buen funcionamiento. Con la extracci\u00b4 on de un con- junto de rasgos muy focalizados en alcanzar un mayor rendimiento en cuanto a la detec- ci\u00b4 on de los casos positivos, se ha conseguido el segundo objetivo equilibrando y mejoran- do tanto la precisi\u00b4 on como la cobertura de forma signicativa. Y nalmente, gracias al esfuerzo realizado para equiparar un sistema supervisado basado en algoritmos tradiciona- les de clasicaci\u00b4 on a un sistema basado en re- des neuronales, se ha hecho posible el poder elegir el primero de los sistemas ya que con un rendimiento global similar tiene dos ven- tajas como son el mejor rendimiento en cuan- to a la clasicaci\u00b4 on de casos positivos y una mejor explicabilidad debido a que los rasgos obtenidos forman parte de la decisi\u00b4 on toma- da nalmente por el sistema. En este \u00b4 ultimo caso, el sistema basado en redes neuronales, a pesar de tener un ligero mejor rendimiento global, obtiene peores resultados en la clase positiva y adem\u00b4 as sus decisiones a d\u00b4 a de hoy sondif\u00b4 cilesdeexplicardecaraaunpsic\u00b4 ologo o psiquiatra. En cuanto al trabajo futuro, consideramos varias l\u00b4 neas de actuaci\u00b4 on. Por un lado el cor- pus est\u00b4 a desbalanceado y adem\u00b4 as no dispone deungrann\u00b4 umerodecasospositivos.Deesta forma trabajaremos para obtener un corpus de mayor tama no con la esperanza de que un mayor n\u00b4 umero de casos positivos nos ayude a mejorar a\u00b4 un m\u00b4 as la detecci\u00b4 on de este tipo de casos. Por otro lado, debido al gran potencial de tecnolog\u00b4 as como las redes neuronales, tra- bajaremos para optimizar el sistema e incluir transformers con los objetivos de mejorar su rendimiento en cuanto a los casos positivos e iniciar un trabajo de estudio para mejorar la explicabilidad de este tipo de sistemas. Agradecimientos This work has been partially supported by the Spanish Ministry of Science and In- novation within the DOTT-HEALTH Pro- ject (MCI/AEI/FEDER, UE) and the project RAICES 2022). Bibliograf\u00b4 a Ageitos, E. C., J. jo. Nlp-uned harm early risk detection with sentiment 138 Juan Martinez-Romo, Lourdes Araujo, Blanca Reneses, J. Sevilla-Llewellyn-Jones, Ignacio Mart\u00ednez-Capella, Germ\u00e1n Seara-Aguilar analysis Baetens, J. Muehlenkamp, H. Grietens, y Research, 15(1):56-67. Burke, T. A., B. A. Ammerman, y R. Jaco- bucci. 2019. The use of machine learning in the study of suicidal and non-suicidal self-injurious thoughts and adap- a H., L. Serna, y J. Mart\u00b4 nez Romo. 2019. Deep lear- ning approach for negation trigger and scope recognition. Fabregat, H., A. Duque, J. Mart\u00b4 nez-Romo, y L. Araujo. 2019. Extending S. J. Sanyal, R. Stewart, y 2018a. Public Reddit and Tumblr Blog Posts on Non-Suicidal State University.Greaves, M. M. 2018b. A and posts on non-suicidal self-injury. Haerian, Salmasian, y C. Friedman. 2012. Methods for identifying suicide or suicidal ideation in ehrs. annual symposium proceedings 1244. American Medical In- formatics Association. Kessler, R. C., M. B. Stein, M. V. Petukhova, P. Bliese, R. M. Bossarte, E. J. Bromet, C. S. Fullerton, S. E. outpatient tal health visits in study to assess risk and y G. Hinton. 2015. Deep learning. nature, 521(7553):436- 444. Losada, D. E., F. Crestani, y J. Parapar. 2019. Overview of erisk 2019 early risk prediction on the internet. En Interna- tional Conference of p\u00b4 aginas 557- 563. Springer. Loyola, J. M., H. Thompson, L. Cagnina, y M. Errecalde. 2021. Unsl erisk 2021: A of three early alert policies for early risk detection. En Working Notes of CLEF 2021-Conference and Labs of the Evaluation Forum, Buca- rest, Romania. Mann, J. J., S. P. Ellis, C. M. Waternaux, X. Liu, M. A. Oquendo, K. M. Malone, B. S. Brodsky, G. L. Haas, y D. Currier. of CLEF , p\u00b4 agina 16. 139 Detecci\u00f3n de Indicios de Autolesiones No Suicidas en Informes M\u00e9dicos de Psiquiatr\u00eda Mediante el An\u00e1lisis del Lenguaje McCoy,T.H.,V.M.Castro,A.M.Roberson, L. A. Snapper, y R. H. Perlis. 2016. Im- proving prediction of suicide and acciden- tal death after discharge from general hos- pitals a of methods in psychia- tric research, 26(2):e1522. Nicolai, K. A., M. D. Wielgus, y A. Mezu- lis. 2016. Identifying Risk for Self-Harm: J. S., J. Dahne, S. Christensen, S. Ho- ward, T. Crawford, L. J. Frey, T. Stecker, y B. E. Bunnell. 2020. Identifying and Obeid,J.S.,E.R.Weeda,A.J.Matuskowitz, K. Gagnon, T. Crawford, C. M. Carr, y L. J. Frey. 2019. Automated detection of altered mental status 2021:Earlyriskpredictionontheinternet. y K. G. Niederhoer. 2003. Psychological as- pects of natural language use: of psychology Poulin, B. P. Thompson, L. tas, Y. Young-Xu, B. Goertzel, B. Watts, L. Flashman, y T. McAllister. 2014. Predicting the risk of suicide by analy- zing the text of clinical notes. PloS one, 9(1):e85733.Rodham, K., K. Hawton, of adolescents. Jour- nal of & Adolescent Psychiatry , 43(1):80-87. Rozova, V., K. Witt, J. Li, y K. Verspoor. 2022. Detection of self- harm and suicidal ideation in emergency department triage notes. Journal of the American Medical Informatics Associa- tion, 29(3):472-480. Walsh, C. G., J. D. Ribeiro, y J. C. Franklin. 2017. Predicting risk of suicide attempts over time through machine learning. Cli- nical Psychological Science, 5(3):457-469. Young, R., M. Van Beinum, H. Sweeting, y P. West. 2007. Young people who self- harm.The British Journal of Psychiatry , 191(1):44-49. 140 Juan Martinez-Romo, Lourdes Araujo, Mart\u00ednez-Capella, Semantic Las Relaciones Sem\u00e1nticas Predicen la Desamb iguaci\u00f3n Estructural de las Unidades T erminol\u00f3gicas Polil\u00e9xicas con Tres Formantes Juan Rojas -Garcia Universi ty of Granada , Granada, Spain juanrojas@ugr.es Abstract : For English multiword terms (MWTs) of three or more constituents (e.g., sea rise ), a semantic analysis, based on lin guistic and domain knowledge, is necessary to resolve the MWT is reduced to its basic form of modifier+h ead, as in [ sea level ] [rise]. Knowledge of these de pendencies facilitates the comprehension of an MW T and its translation into sentence parsers . paper explored whether the bracket ing of a ternary compound, when used as an argument in a sentence, can be predicted from the semantic information encoded in that sentence. It is shown tha t, with a random forest model, the semantic relation of the MWT to another argument in the same sente nce, the lexical domain of the predicate , and semantic the MWT were t he ternary compounds used in semantic relation term inol\u00f3gicas polil\u00e9xicas ( UTP) con tres o m\u00e1s formantes en leng ua inglesa (p.ej., sea level rise), establecer la dependencia entre dichos for mantes requiere de un an\u00e1lisis ling\u00fc\u00edstico y de conocimiento especializado del \u00e1rea concreta en que se emplean las UTP. Esta desambiguaci\u00f3n estructural , o bracketing , implica el agrupamiento de los form antes para reducir la UTP a su estructura b\u00e1sica de modificador+n\u00facleo, como en [sea level ] [rise]. Conoce r el bracketing de una UTP no solo facilita su compre nsi\u00f3n y traducci\u00f3n a otras lenguas , sino que tambi\u00e9n mejora el desempe\u00f1o de los sistemas de tradu cci\u00f3n autom\u00e1tica y de los analizadores sint\u00e1cti cos. Por tanto, en este art\u00edculo presentamos un estudi o piloto que explora si el bracketin g de un a UTP con tres formantes , al emplearse como argumento en una oraci\u00f3n, puede predecirse a partir de la informaci\u00f3 n sem\u00e1ntica codifi cada en dicha oraci\u00f3n. Se muestra que, con un modelo random forest, la relaci\u00f3n sem\u00e1ntica de la UTP con otro argumento en la misma oraci\u00f3n, el dominio l\u00e9xico del verbo y el rol sem\u00e1ntico de la UTP son capaces de predecir el bracketing de las 190 UTP ternarias que se usan como argumento en una muestra de 188 oraciones , anotadas sem\u00e1ntica mente y extra\u00eddas de un corpus sobre in genier\u00eda de costas (con un valor de F1 del 100 %). Adem\u00e1s, \u00fanicamente la relaci\u00f3 n sem\u00e1ntica que manti ene una UTP ternaria con otro argumento en la misma oraci\u00f3n posee una enorme capacidad para predecir su bracketing mediante un \u00e1rbol de decisi\u00f3n binario (con un valor de F1 del 94, 12 %). Palabras clave : Relaci\u00f3n Sem\u00e1ntica, Desambiguaci\u00f3n Estructural de Unidades T erminol\u00f3gi cas Polil\u00e9xicas, Random Forest, \u00c1 rbol de Decisi\u00f3n. Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 141-152 recibido aceptado 19-05-2022 ISSN 1135-5948. DOI 10.26342/2022-69-12 \u00a9 para el Procesamiento del Lenguaje Natural1 Introduc tion A set of 1,694 sentences from astal Engineering corpus , in which a named river (e.g., Salinas River ) was an argument of the predicate of the sentences, semantically analyzed arguments , domain and the semantic role of the arguments . This paper presents the statistical analysis of those semantic annotations with a view to finding evidence that the stru ctural disambiguation, or bracketing, of a three-component multi word (e.g., [ sand supply ] [decrease]) can be predicted from the semantic information encoded in the sentence where the ternary compound is used as an argument. For this experiment, we as sumed that the context, which constrains the of a ternary compound. This assumption comes from the daily experience of a translator who must deal with te rnary compounds in a specialized text. Although the compounds are somewhat familiar, it is useful to craft definitions for them to facilitate their translation into another language based on their context of use. The rest of this paper is organized as foll ows. Section 2 presents a fundamental background of bracketing of multi word terms . Section 3 provide s literature review models for bracketing , mostly from the perspective of variables and resources used for the task of compound bracketing prediction. Section 4 explain s the materials used in study . Section 5 cover s our approa ch forest t he sample of tern ary compounds , the training and testing phases for the predictive , and the r esults, and bracketing Section 6 th e results and compares them to those outlined in the literature review. Fina lly, Section 7 presents the conclusions derived from this work along with plans for future research. 2 Bracke ting of Multiword Terms When multi word express ions a re used in specialized domains, they are known multi sand refers to the supply of s and, usually provided by rivers, whose grain si ze is appropriate to beach hypernym. For example, beach size sand supply is a type of sand supply since the grain size of the sand is sp ecified . It is the dimension activated to hyponym. For MWTs three more constituen ts, a semantic analysis, based on linguistic and domain knowledge, is necessary resolve so MWT is reduced to its basic form of modifier+head, as in [ beach size ] [sand supply ]. Knowledge of these an MWT before s is often structurally provid es a higher overall accuracy machine translation systems (Green N., 2011), sentence parsers (Vadas D. and Curran J.R., 2008), at determini ng the implicit semantic rel ation holding between modifier and head in MWTs of three or more c omponents (Kim S.N. and Baldwin T., 2013). 3 Review of based on training da ta, containing manually parsed/bracketed compound s, which are used to train an algorithm for predicting compound bracketing). The two basic unsupervised ap proache s are the adjacency model (Marcus M., 1980; Pustejovsky J. et al., 1993) , and the dependency m odel (Lauer M., 1994). For a ternary compound such as sea level rise (i.e., increase in sea leve l), the adjacency model concludes whether level is more closely associated with sea (leading to a left -branched structure) or to rise (leading to a right s tructure). In contrast, the dependency model resolves whether sea is more strongly associated with level (leading to a left-branched structure) or with rise (leading to a right-branched structure). In this case, the correct bracketing of sea level rise is left-branched. The way of measuring the association strength between two of the words (or con stituents) in the compound is based on association measure s estim ated from as frequency , point -wise among others. Resnik P.S.'s (1993) method for ternary compound s, based on the adjacency model and the association measure called selectional association , estima ted from the parsed Wall Street Journal corpus (30 million words), achieved an overall accurac y of 72.6% (with a sample of 157 dependency for his method, based on the ratio of left - to right probability for a ternary compound, method reached an overall accuracy 80 (with a , such as dashes (e.g., beach -sand transport to eft-bracketed compound), possessive city's variable, namely preposition al phra ses (e.g., mouth left-bracketed), a mixture proves that mixture water comp performance when using the chi -square d association measure and the number of web searc h engin e page hits for approximating corpus frequencies, as suggested by Lapata M. and Keller (2004). t method a domain abstracts re trieved from MEDLINE (84% -branched). http://www.gutenber Girju R. ternary compoun machine -learning technique decision They employed a total of 15 variables based on WordNet senses, five variables for each constituent, mely an overall accuracy a of 728 ternary compounds from the Wall S treet Journal component of the Penn Treebank corpus (Marcus M. et al., 1993) , 67.4 % left -branched, and 32.6% ternary compound, and then predicting constitu ent pai r whose semantic relation coincided with that of the ternary compound. When this method was combin ed with that of Nakov P. and Hearst M. (2005) , it achiev ed an overall accuracy of 74.1% with a sample of 1 ,571 ternary compounds from the Wall Street J ournal corpus . However, no information was provided regarding method S. et al. (2010) used both n -gram variables (the logarithm of the frequency of all constituent su bsets a ppearing in the Google V2 corpus), and Boolean lexical variables that indicated the presence o r absence of a par ticular string at a given position in the compound (the constituents and their position, the entire ternary compound, as well as a capita lizatio n pattern of the constituent sequence). As a machine -learning technique, the authors applied t he support overall accuracy of with a sample of 2 ,150 ternary compounds from the Wall Street corpus (70.5% used 88 ,568 variables, an extremely large n umber, which can be summarized as follows: (1) Bigram frequencies e collected from two sources, na mely hit counts from the web search engine Google, and frequencies in the Google Web 1T corpus (Brants T. and Franz A., 1993). (2) The pairs of compound co nstituen ts, and the surface variables by Nakov P. and Hearst M. (2005), were compared according to bo th the adjacency and dependency models means of the chi -square and bigrams in a ternary compound, along with their position within the compound . (4) Contextual variable s, c onsisting of bag-of-word features for both the words in the sentence where the compound is used, and for a two-word window on each side of the compound . (5) For every n -gram and context window feature, their part -of-speech tags and named entity tags we re added. (6) For each sense of each constituent in the ternary compound, a semantic feature for its synset, a s well as the synset of each of its hypernyms up to t he root, were extracted from WordNet, and incorporated into the supervise d model as additiona l variables. This method achieved an F 1-score of , with a of 5 r ight-branched). The system Pitler E. et al. (2010) was able to bracket compound s of three or more constituents (including the conjunction and). Applying the support -vector machine algorithm, the system first calculated the probability that a word sequence, within a compound, was a constituent, given the entire compou nd predicted the bracketing of a compound with the CYK parser (i.e., Cocke -Younger -Kasami algorithm) . As variables f or the system, the authors employed: (1) The position of the proposed bracketing within the compound . (2) The association measure point -wise mutual information (PMI) between all word pairs in the compound, derived from the Google V2 corpus (Lin D. et al., 2010) . (3) Boolean lex ical variables to indicate the presence of a particular word at each position i n the compound . (4) Boolean variables to inform about the shape of the compound, the nformati compound included a named entity. The system reached a n overall accuracy of 95.4% , with a sample of 64 ,844 compounds of three or more constituents from the Penn Treebank corpus, but bracketing -related informat in the form of percentages was not provided. Lazaridou A. et al. (2013) tackled the parsing ternary compound trained on a corpus of 2.8 billion tokens, where the vector of a ternary compoun d was obtained from the combination of the each of its constituen ts. supervised method relied on the support -vector machine algorithm with 14 variables, summarized as follows: (1) 12 variables for representing the s emantic plausibility of e ither the left - or right -bracketing ; (2) two variables for the PMI values of the word pairs in the compound, according to the adjacency model. The method achieved an overall accuracy of with a sample of 2 ,227 the the n ot encod e any word co -occurrence information. Instead, the vector dimensions were Boolean variables that FrameNet (Ruppenhofer J. et al., 2010), and Penn Treeban k. As su ch, the vector length for a single word included a total of 172 ,418 dimensions. The vector of a ternary compound was then obtained by appending the vector of each constituent , which result ed in a ternary compound vector of 517 ,254 dimensions . This combined vector was the input -learning technique of logistic regression, which achiev ed an same sample of ternary compounds collected by Lazaridou A. et al. For the unsupervised method by M\u00e9nard P.A. and Barri\u00e8re C. (2014), the usage of different resources for the bracketing of compounds of three and more constituents was compared, namely the English Google Web N -grams (Lin D. et al., 2010 ), English Google Books Ngrams (Michel J.B. et al., 2010 ), and open link ed data DBpedia (Hellmann S. et al., 2009 ). The association measures chi -square d, PMI, and Dice, and the number of initial list containing all of the word pairs from a compound, which were then sorted in de scend ing order of association scores. A second list of dependencies, which d efined the complete bracketing of the compound, was constructed from the first list. For ternary compounds, the method with the English Google Books N and th e PMI achieved the highest a of on a sample of 2 ,889 tern ary compounds from t compounds of three and more c onstitue nts, Barri\u00e8re C. and M\u00e9nard P.A. (2014) applied the unsupervised method of M\u00e9nard P.A. and Barri\u00e8re C. (2014), but relied on a word a ssociation model that combined the lexical, 144 Juan Rojas-Garcia relational, and coordinate nature of the associations between all pairs of word s within a compound. The information for their word association model was collected from Wiki pedia. The system reached an overall acc uracy of 73.16% , with a sample of 4 ,749 compounds of three and more constituents from the Penn Treebank corpus, but the spe cific accuracy for the subset of ternary compounds was not Le\u00f3n-Ara\u00faz P. -rich method for bracketing specialized ternary in domain energy. The authors used 12 variabl es, mainly paraphrase variables proposed by P. and Hearst M. (2005), which measured frequency counts in a specialized corpus on win d energy. The counts were collected by means of CQL (Corpus Query Language) queries in the S ketch Engine corpus manager. A total of 34 specific CQL queries were designed for the of the structures the results, authors formulated 16 rules to decide on the bracket ing of a ternary com pound. Hence, the final structure was applying the vote the votes of the individual rules. As such, t he CQL queries and rules permit ted the implement ation of a system to automate the compound b racketing task for u sers such translators and with a sample of 103 ternary compounds from the wind energy domain (67% left -branched, and 33% right -branched). In short , previous research focused on semantic information provided by the components of an MWT. The number of used for prediction ranged to features. based on n and semantic has not as yet considered. Th is semantic information was encoded in both the co-text of a ternary compound (i.e., the sentence where the ternary compound was used as an argument) and the ternary compound seen as a unit (i.e., its semantic role ). The set of predictor variables three (i.e., the semantic relation, minimum va riables (Le\u00f3n -Ara\u00faz P. et al., 2021). 4 Materials A set of 1,694 sentences , in which a named river (e.g., Mississippi River) was an argument of the predicate of the sen tences, were and These texts Coastal Engineering, Engineering). part of the English EcoLexicon Corpus (23.1 million words) (see Le\u00f3n-Ara\u00faz P. et al. (2018) for a de tailed description). 5 Semantic Approach for MWT Br (Fillmore could the correct br acketing of a n MWT , when use d as an argument in a sentence, can be predicted from the semantic information encoded in that sentence. In other words, which the structural disambiguation the ternary compound. semantic in a sentence, this pilot study explored the contribution of three semantic variables to the prediction of ternary compound bracketing. These variables were the lexic al domain of the verb, semantic role of the compound, and compou nd the g with the values of the semantic variables anno tated in their corresponding sentence s, were em ployed for the training and testing of two supervised models to predict whether a ternary compound was left -branched. 5.1 Annotation of t he Semantic Variables A set of 1,694 sentences from the co rpus, where 294 different rivers are mentio ned, were annotated by three terminologists fro m the LexiCon research group of the University of Granada (Spain ). They performed the semantic annotation ng domain to the predicate ; (2) semantic role to the arguments of the predicate ; (3) semantic relation to the link between the named riv er and the other arguments in the sentence ; and (4) bracketing (left to in s of these four semantic variables shown in T able , MOVEM ENT, and the ir values. The m ost frequent verbs in the corpus are classification in the lexical domains proposed by Faber P. and Mair al R. within the Functional of , shown Table 1. Specialized knowledge representation includes semanti c properties that help to describe the natur e of entitie s and processe s. These semantic properties are reflected as the relation s between a predicate and its arguments, which are typical semantic roles. The semantic roles used annotate the arguments in our set of sentences largely coincide d with those specified by Kroeger P.R. (2005 : 54-55), and Thompson P. et al. (2009) , and summarized Table 1. , ed by Faber P. et al. (2009) for environmenta l concepts , with additional non-hierarchical annotate the arguments set of sentences , and collected the original annotations were based discussi on between lexical domains, the though plausible, interpretations. A review of he differences between annotators showed that the lexical domains of MOVEMENT POSSESSION prone T he fun damentally potentially belong one lexical domain (e.g., drain and discharge ), as Faber P. and Mairal R. (1999) already To arrive framework was applied to verbs to resolve disagreement s between the annotators. 5.2 Description o f the Sample o f MWT s A selection of 1 0 sentences from the sample, which incorporated ternary c ompounds as arguments, is provided in Table 2. For each of those 1 0 sentences, Table 3 shows the values of the following (1) ); (3) relati on ternary compound and the named r iver (SemRel ); and (4) bracketing of the ternary compound (Brack eting), which was the variable to be predicted.2 The distribution of bracketing struct ures w MWTs the distribut of the 190 MWTs across these variables. Some conclusions could be drawn from aracteristics of included co mpounds sentences whose predicate belonged he lexical of POSSESSION incorporated ternary compounds which were only left-branched. 2 The whole dataset of MWT s, the values of the annotated variables , and the corpus will be available on the website of the LexiCon research group of the University of Granada (Granada, Spain) (http://lexicon.ugr.es/). 146 Juan Rojas-Garcia Sentences from the Sample with as Arguments River been well quantified, models show decreasing sedime nt load in the Blackstone Riv er. (2) The dramatical sediment load variation in the Pearl River , unchanged such effect that human activities can have on river deltas. (3) Muddy silt deposition in the Clyne River discharging into the Swansea Bay would increase . (4) Rising sea levels change thus potentially alter sediment supplies and River no substantial beach size sand to the Littoral Cell because the river gradient has greatly decreased with sea lev el rise, reducing the (6) The coastal lagoons behind the dune calcarenite barriers of Encounter Bay. (7) Not all the sedimen ts drained by the Dee River participate to coastal sediment transport . (8) The field site for this study is the Zuidgors salt mars h, located in the Western Scheldt estuary in The Netherlands. (9) Natural sediment supply within this region is defined by the Ventura River that drain s large watersheds. (10) The average discharge rate of beach size sand in the 65,000 cubic 0 sentences (from the sample of 188 sentences), which for a set of 10 MWTs out of the 190 MWTs that comprised the sample. The semantic information ) POSSESSION 30 0 (15.8% ) CHANGE 30 (15.8% ) EXISTENCE 60 (42.0% ) ACTION 0 10 10 ( 5.3%) (58%) 80 (42%) 190 (100% ) 4: Description of the sample models classification, binary decision tree and random forest were tested to predict ternary compound bracketi ng. Since variables in our dataset were categorical, both tree -based models were adopted because they can efficiently manage qualitative variables (James G. et al., 2015 : 315). A decision -tree model is simple and readily a tree, typically upside down, in the sense that the terminal nodes or leaves, which convey the predictions, are at the bottom of the tree . However, it is usually not competitive with other predictive model s. For that reason, we also experimented with a random forest model, which produces a large number of decision trees, and Namely, each tree in the ensemble (or forest) casts a vote for the bracketi ng of an MWT, which is finally classified into the bracketing structure that has the is difficult obtain insig ht as to how the model makes the predictions. 5.4 Data Splitting For the construction and evaluation of the models, the dataset with the 190 MWTs was divided into two: (1) the training d ataset to create the models (with 133 MWTs, 70% of the original dataset), and (2) the test dataset to qualify model performance ( 57 MWTs, 30% of the original dataset). For both the training and tes t data sets to have the same distribution in the outcome vari able (i.e., Bracketing ) as the right e classes LEFT RIGHT variable the Bracketing 5.5 Model Performance Measures The quality of the two mod els (decision tree and random forest) was assessed by analyzing how well they perform ed on the test data set, which was hidden from the model -building process for evaluation purpos es. As such, the predictions of the model s were compared to the true classes of the test data set (i.e., the true bracketing structures LEFT and RIGHT , recorded in the Bracketing variable of the test data set), and performance measures were calculated . A widely used According to Fern\u00e1ndez A. et al. (20 18: vii), the learning process of most classification algorithms, including tree majority not into the Consequently, in imb alanced scenarios, the accuracy measure may mask a poor classification performance in the minority class. Unfortunately, as al ready seen in the literature review, there is much research on bracketing prediction that still bracketing -imbalanced, we pre ferred to use, in addition to accuracy, other measures that were not sensitive to disparities in the class proportions to evaluate classification performance. Such measures were the area under the ROC curve , and the F1-score (Fern\u00e1ndez A. The receiver characteristic of a two -class predictive model to evaluate its trade -off between both measures. Sensitivity is the fraction of the minority -class instances (in our cas ROC curve (henceforth to as AUC) is a for combining sensitivity and specificity into a single value. AUC ranges from 0 to 1. The higher the AUC, the better the performa nce of the model at distinguishing between the two classes. The F 1-score is the harmonic mean bet precision ong belonging to the minority class, whereas recall the same as sensitivity. Thus, the the -class instances. with the caret package (Kuhn M., 2021 ) for the R programming language . For the random forest, 7-fold cross -validation in the training dataset was used to evaluat e its performance in training. 10 folds are conventionally employed, we chose 7 folds, a divisor of 133, so that the number of instances in all folds would be the was chosen to be maxim ized. Accordingly, the random forest model attain ed in training an AUC value equal to 1.0 when: (1) the splits in the trees were allowe d to use one predictor of a subset of one predictor ; and (2) the number of trees in the forest was, surprisingly, only th ree trees. In the test dataset, the random forest also achieved an AUC value equal were correctly predict ing bracketing in the test dataset with a random forest model. Similarly, for the decision tree, 7-fold cross-validation in the training dataset was employed to evaluate its performance in training. During the process of tuning par ameters, the be maximized. Therefore, the dec ision-tree model yielded in train ing the greatest AUC, equal to 0.9 545, when: (1) the cost -complexity parameter (cp) was equal to cp=0.8392857 ; and (2) the splitting cr iterion for predictors was the information gain , and not the Gini index . In the t est dataset, the performance measures, in the training and test datasets, for the random forest and decision ensembled decision trees ) Train 1.000 0 1.000 0 1.000 0 1.000 0 1.000 0 Test 1.000 0 1.000 0 1.000 0 1.0000 1.000 0 Table 5: Performance measures of the bracketing decision -tree a signific ant AUC in the (AUC=0.95 its only pre diction domain, river w as mentioned), the classification tree of the model, displa yed in F igure 1, can b e interpreted as follows . the most the only model. In ctive power MWT ano ther argu ment in the sa me sentence is so high that the model was obliged to reject the use of the predictors LexDom and SemRol_mwt to overfitting semantic relation to the other argument, filled w ith a nam ed river in ou r case, belonged to the group formed accounted for of these -branched and correctly comprised 4 7% of the sample, and could be right - or left -branched; under these conditions, the model correctly classified all left -branched MWTs ( 11%) as r ight-branched. An analysis the errors made by the decision -tree model revealed that, both in the training and in row 2 of Table 3), were all misclassified as right-branched. 5.7 Baseline Models The resu lts of our semantic approach were compa red to those of four baseline models , namely : (1) adjacency model with the point-wise mutual information (PMI) association measure , as defined by Marcus M. (1980); (2) adjacency model with the chi-squared association measure; (3) dependency model with PMI; and (4) model with chi-squared. These non -supervised widely the literature bracketing prediction to the whole sample of 190 MWTs. Table 6 shows that the two predictive models , explain ed in this forest models to four baseline models. 5.8 Comparison of the Models Despite the that a -depth understanding of the influence of the semantic variables in from a restricted framework in which this research was name d rivers. As far as the selection of the best model is concerned, there are convincing arguments in favor of either model. Since the ra ndom forest model had an error-free performance, it could be used to implement a system for bracketing ternary compounds. Neverthel of model was also fairly good. It visua by same sentence. Discussion Although the comparison of our study with previous research in the literatur e review is far from ideal , it still serves as an indication of the performance o f our semantic approach . For bracketin g prediction, p information by the components of an MWT . The number of variables that they u sed for prediction ranged from 12 to 517,254 features. These mostl y ( : 1909). Other research studies relied on seman tic information not as yet consider ed. The semant ic informatio n was encoded in both the co -text of a t ernary compound (i.e., the sentence where the ternary compound was used as an argument) and the ternary compound seen as a unit (i.e., its semantic role ). The set of varia bles relati (Le\u00f3n -Ara\u00faz P. et al., 2021) . This set of three variables yielded, in the test dataset, an error -free performance with a random for est model, wh ereas the highest overall accuracy achie ved in p research was 95.4 0% with support vector machine (Pitler E. et al., a less interpretable predictive model . ,694 sentences , in w hich a named river was an argume nt of the pre dicate of the sentences, were semantical ly analyzed and of hether the br acketing of a ternary compound, when use d as an argument in a sentence, can be predicted from the semantic information encoded in that sentence. The semantic relation of the M WT to another argument in the same s entence , the lexical domain of the predicate the MWT were t ternary a the 1,694 model, with decis ion trees, achieved in the test dataset an AUC equal to 100% (overall accuracy of 100%). When a decision tree was trained , model only needed in sentence encod ed in the semantic relation of another argument in the sentence , the domain of (Vadas D. and Curran J.R., 2008), and machine translation systems (Green N., 2011 ), this result potentially suggests a novel research direction in f such semantic variables into sy ntactic machine translation applicat ions, in line with Agirre E. et al. (2008), Girju R. et al. (2005), and Kim S.N. and Baldwin T. (2013). Evidently, it is not as yet clear whether MWT size of the MWT sam ple and the restricted framework in which the analysis has bee n conducted, namely specialized ternary named In research, a wider framework shall be established to acquire a more of the influence of the semantic v this study multiword -term bracketing . Acknowledgements This research PID2020 Integration Base on Environment\" (TRANSCULTURE), funded by the Spanish Ministry of Science and Innovation ; and A-HUM -600-UGR20, \"Culture as Transversal Module in a Terminological Knowledge Base on the Environment \" (CULTURAMA ), funded by the Andal usian . 150 Juan Rojas-Garcia References Agirre, E., T. Baldwin, and D. Martinez (2008). Improving parsing and PP attachment performance with sense information. In Proceedings of th e 46th Annu al Meeting of the Language Technologies (pp. 317-325). ACL. Barri\u00e8re, bracketing using Wikipedia . In Proceedings of the First Workshop on Computational App roaches to Compound Analysis ( ComAComA 2014) (pp. 72 -80). ACL. Bergsma, S., E. and D. Lin supervised classifiers web-scale Proceedings of (pp. -874). (2006 ). Web 5 -gram Version 1. Linguistic Data Cons ortium . Faber, P., and R. of English Verbs . Mouton de Gruyter. Faber, P., (2009). Semantic relations, dyna micity, 1-23. . In WordNets. Computers and the Humanities , 32, 209-220. Fern\u00e1ndez, Garc\u00eda , M. Galar, R.C. Prati, B. Krawczyk, and F. Herrera (2018). Learning from Imbalanced Data Sets . Springer. Fillmore, C .J. (1968). The case for case . In E. Bach , and R. Harms ( Eds.), Universals in Linguistic Theory (pp. 1 Rinehart, and Winston. Girju, R., D.I. Moldovan , M. Tatu, and D. Antohe On semantics of noun comp ounds. Computer Speech and Langua ge, 19(4), 479 (2 011). Effects of noun phrase bracketing in dependency parsing and machine translation . In 49th Annual Meeting of the Association for Computational Linguistics: H uman Language Technologies. Proceedings of Student Session (pp. 69-74). ACL. Hellmann, S., C. Stadler , J. Lehma nn, and S. Auer (2009). DBpedia live extractio n. In R. Meersman, T. Dillon, and P. Herrero (Eds.) , On the Move to Meaningful Internet Systems (OT M 2009) (Vol. 5871, pp. 1209-1223). Springer. Lecture Notes in Computer Science . James, G., D. Witten, T. Hastie, and R. Tibshirani (2015). An Introduction to Statistical Learning . Springer. Kim, S.N., and T. Baldwin (2013). A lexical approach to Training . R package version 6.0-90. Lapata, M., and F. Keller (2004). The web as a baseline: Evaluating the performance of unsupervised web-based NLP tasks Proceed ings of the Human Language Tec hnology Conference of the North American Chapter of the ACL (HLT -NAACL 2004) (pp. 121-128). ACL. Lauer, M. Association for Compound Noun Analysis . CoRR. Lauer, M. (1995 ). Corpus Some . (pp. ACL. Lazari A., E.M. Vecchi, and transporters and miracle homes: How compositional distributional semantics can help NP parsing . Proceedings the 2013 Confere nce on Empirical Methods in Natur al Language Processing 20 13) (pp. 1908-1913). ACL. Study of Meaning Penguin. Le\u00f3n-Ara\u00faz, P., A. San Mart\u00edn, and A. Reimerink (2018). The EcoLexicon Engl ish corpus as an open corpus i n Sketch Engine . In Proceedings o f the 18th EURALEX 893-901). K. Dalwani , S. Narsale (2010). New tools f or web-scale n-grams. In Proceedi ngs of the Seventh International Conference on L anguage Resources and Evaluation (pp. 2221-2227). ELRA. Marcus, M. (1980). A Theory of Syntactic Recognition for Natural Language . MIT Press. Marcus, M.P., M.A. Marcinkiewicz, and B. Santorini (1993). Buildin g a of Barri\u00e8re (2014). Linke d open data and web corpus data for noun compound bracketing . In Proceedings of the 9th International Conference on Language Resources and Evalu ation (LREC'14) Nakov, P. , and M. Hearst (2005). Search engine statistics beyond the n -gram: Application to noun compound b racketing . In Proceedings of t he 9th Conference on Computationa l Natural Language Learning (CoN LL) (pp. 17-24). ACL. Pitler, E., S. Bergsma , D. Lin, and K. W. Church (2010). Using web -scale n -grams to improve base NP parsing performance . In Proceedings of t 23rd International terminological knowledge base. and J. Scheffczyk (2010). FrameNet II: Extended Theory and Practice . International Computer Science Institute. Thompson, P., S.A. Iqbal, J. McNaught, and S. Ananiadou (2009). Construction of In Proceedin gs of the Computational Linguistics (pp. 104-112). Proceedings of Meeting of the Association for Computational Linguistics: Human Language Technologies 335 -343). ACL. 152 Juan Rojas-Garcia Evaluating Contextualized Vectors from both Large Language Models and Compositional Strategies Evaluando vectores contextualizados generados a partir de grandes modelos de lenguaje y de estrategias composicionales Pablo Gamallo, Marcos Garcia, Iria de-Dios-Flores Centro de Investigaci\u00b4 on en Tecnolox\u00b4 as Intelixentes from large language means of dependency-based compositional techniques. For this purpose, we make use of a word-in-context similarity task. As all experiments are conducted for the Galician language, we created a new dataset este art\u00b4 culo, comparamos los vectores contextualizados derivados de grandes modelos de lenguaje con los generados mediante t\u00b4 ecnicas de composici\u00b4 on basadas en dependencias sint\u00b4 acticas. Para ello, nos servimos de una tarea de simil- itud de palabras en contextos controldados. Como se trata de una experimentaci\u00b4 on orientada a la lengua gallega, creamos un nuevo conjunto de datos de evaluaci\u00b4 on en gallego para esta tarea sem\u00b4 antica espec\u00b4 fica. Los resultados muestran composicionales derivados de enfoques sint\u00b4 acticos basados en restricciones de selecci\u00b4 on son competitivos con los embeddings contextuales derivados de los modelos de lenguaje de gran tama no basados en arquitecturas neuronales. Palabras clave: Grandes Modelos de Lenguaje, Vectores Contextualizados, Composicionalidad, Similitud Sem\u00b4 antica, Restricciones de Seleccion, Dependencias Sint\u00b4 Models (LLMs) are a disrup- tive breakthrough in Artificial Intelligence that have received an increasing amount of attention in many Natural Language Process- ing (NLP) tasks. As in the case of classical models, it is possible to use two different ap- model itself, without considering any task which may be involved. Extrin- sic evaluation consists of evaluating downstream NLP task. This strategy allows final representation affects the accom- plishment of the target task. Perplexity is one of the most popular metrics for intrinsically evaluating languagemodels. It measures how good a language model at predicting real sentences. Al- though perplexity measurements allow re- searchers to assess the quality of a model in a fast and inexpensive way, it is not considered a fair metric to compare models because easily applied to classical is not for auto- encoding LLM (Salazar et al., 2020), masked language models such as BERT (De- vlin extensive extrinsic eval- also some a costly and computationally slow process, Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 153-164 recibido aceptado 23-05-2022 ISSN 1135-5948. DOI 10.26342/2022-69-13 \u00a9 2022 Sociedad Procesamiento del Lenguaje Naturalsince it requires supervised fine-tuning (i.e., training a new model with annotated exam- ples to adapt it to the task). Second, hyper- parameters for fine-tuning are likely to have an important influence on the results of the evaluations (Shibayama et al., 2020). And third, the most comprehensive datasets to evaluate LLMs are only available for either English a dozen of mid-resource languages et 2021), but not for low-resource languages such as Galician. As an alternative to fine-tuning, which ad- justs the vector weights with new annotated data, it is possible to optimize a pre-trained language model for many different tasks by making use of prompt tuning, which is a sort of zero-shot learning approach based on the optimization of the model by embedding the description of the task in the input. So LLMs can also be externally evaluated through prompted-based tasks. Another way to evaluate LLMs is to do so on the basis of some of their context word are seen as compo- way and allow us to directly generated embeddings. It should be noted that, evaluation is known intrinsic evaluation embeddings, it is actually combine al., (Gamallo et al., 2019; Weir et al., 2016). The aim of this work is to compare contex- tual a word-in-context similar- ity task. To do so is needed dataset in Galician language. In sum, the main contributions of the paper are the fol- lowing: Creation of performance of all these dynamic and contextually sensitive embeddings against the same dataset. The rest of the article is organized as follows. The next section introduces some related work (2). Then, the different types of language models, both LLMs and dependency-based, are defined in Section 3. The results the used Lapata (2008; 2010). The authors did 154 Pablo Gamallo, Marcos de-Dios-Flores not actually use the term contextualized vec- tors for they called the representation of the meaning of sentences in vector space by means of vector composition. In their work, the meaning of phrases or sentences is rep- resented as drawback of this approach is that it is not fully compositional because word order and syntactic functions are not taken into account. The dataset created by Mitchell and and subject-verb- object transitive constructions that differ only in the verb. Yet, unlike the previ- ous work by Mitchell and Lapata, the se- mantic approaches that were evaluated on these The main con- cern with these approaches is that they re- quire instance ballricochet instead of the ball ricocheted. Thus, marginalized syntax- and compositional semantic models. One of the main reasons for the low inter- est in these models is the difficulty to adapt them to open phrases and sentences with any type of syntactic construction. Purely compositional models, due to their linguis- far only successfully used Camacho-Collados, Armendariz et is, al. and Gamallo et al. (2021) for English, and Gamallo et al. (2021) for Por- tuguese and Spanish. probe the composi- tional abilities of LLMs. In this respect, Yu (2020) found that Transformer- based models mostly rely on content, information provided by compositional operations. Finally, recent approaches (Nguyen et Language Models Contextualized word vectors can be derived from different types of language models fol- lowing distributional-based strategies. In our work we explore contextualized word vectors from two types of models for the Galician language, described below: (a) BERT-based LLMs, (mBERT, with 12 hidden layers) provided by we evaluate released by and 6 layers, respectively. Concerning the size of the training corpus of mBERT and Bertinho-base were 155 Evaluating Contextualized both Large Language Models and Compositional Strategies trained on the Wikipedia, which contains about 42M tokens, while the two versions of Bert-Galician were trained on a larger corpus with about 500M tokens. To obtain the contextualized vector of a word in the input sentence, we use the stan- dard approach of adding the last four lay- ers, as they have been found to provide more context-specific representations (Ethayarajh, 2019; Vuli\u00b4 c et a word into several sub-words (or af- first subword is considered since it represents the lexical stem of full We also from LLMs by is the same strategy used by Sentence- BERT for English (Reimers and Gurevych, 2019). The main difference with regard to Sentence-BERT is that the Galician pre- trained models of our experiments are not fine-tuned with annotated collections of se- noun occurring with catch inobjrelation, or being a verbal head occurring with ball The high number of dimensions syntactic 2014; Gamallo, a global, arbitrarily defined constant whoseusual values range from 100 to 1000 (Padr\u00b4 o et al., 2014). The relevance value of a con- text with regard to a word is computed by means of a lexical association measure (e.g., pointwise mutual information, etc.). This an explicit, transparent, and static representation of word meaning, very similar also static word Yih, vectors from these dependency-based se- lectional preference formalized in Erk and Pad\u00b4 o (2008), which states that the two words related by a dependency relation ciation noun ball )> is the set of heading verbs (e.g., catch, throw, orga- nize...) threshold , d )> is the set of dependent nouns (e.g., ball, baseball, cold, drift...) relevant verbs direct object, of relevant nouns appearing as direct ob- catch. In the selectional preferences imposed by the two Once the built, dependent lemmas, giving rise to 156 Pablo Gamallo, Marcos Garcia, Iria de-Dios-Flores two new contextualized vectors: the of the tualized with the selectional (obj,h,ball )=catchhball(obj) (3) ball (obj,catch,d )=balldcatch(obj) (4) At the end compositional two contextualized vectors which are than initial static context of ball some event similar to grab, and not to con- tract as in catch a disease, while ballmeans in the context of catch a spherical object and not and dancing event as in attend a ball . In disambiguated word senses. we have defined the process of com- positional semantics between two dependent words, but process be extended to the sentence level. Given the dependency parse tree of an input sentence, the alization of all constituent result of out by all dependen- cies identified in the parse tree in an iterative and incremental way. Thus, at the end of the process, each word of the sentence, includ- ing the root one, is assigned a contextualized The order in which compositional op- erations are applied is not predetermined and and iterative process can go either from left-to-right or from right-to-left. 3.2.3 Galician Model To build the language model and their corresponding vector space, the Galician Wikipedia (dump file of November is dep(endencies), which makes use of the PoS tagger and lemmatizer modules. Since it is a small corpus con- taining about 42.7 million tokens, we Lemmas The final model resulted in a non- zero matrix of about 50k different lemmas and over 33k different contexts. In total, the vector space consists of a non-zero matrix with about for more details on how on the of an older version that was fully de- scribed in Gamallo (2019). For the Galician corpus, the parameter was set to 0. Previ- ous experiments did not show any improve- ment by assigning positive values to this pa- means that the second selection of relevant contexts made by this parameter is not justified with small corpus sizes such as the one used here. Although the compositional strategy is de- signed to work with any type of sentence, due to the difficulty of the task, the imple- mented version only applies to linguistic ex- pressions tic (e.g., adjective-noun, subject- verb-object, embed- dings use Models and Compositional Strategies was built.3 As it is not possible to make a direct trans- lation of the original English sentences, since the selection preferences are very different from one language to another, we chose anal- ogous examples with 68 different polysemous verbs and nouns in subject and object position. All sentences consist of just one basic nominal phrase as subject, a verb as predicate, and a basic nominal phrase as direct object. In each pair, one transitive sentence con- sisting of a verb with its subject object is compared to another transitive sen- tence combining the same subject object with a semantically related verb that is cho- sen to be either appropriate or inappropri- ate in the same context. For instance, a em- presa compra un pol\u00b4 tico ('the company buys a politician') is semantically appropriate and very close to a empresa suborna un ('the company bribes a synonym ('bribe') in this context, where the sub- ject is a person or organization and the object is also a person or organization. However, the same pair of verbs have a very dissimilar be- havior in a different context, e.g., on /??o on jects the human feature. The selectional preferences imposed by that verb are not fulfilled by the direct object. Unlike the original English dataset from which it is inspired, we created complete sen- tences, and not were (and ex- similarity pair scores annotator respectively. reliability of the ratings 3The dataset is available with the software (Cf. the three pair was com- puted. As in Spearman correla- human scores (the of the three evaluators) and the predictions re- turned by the systems. Both human evalua- tors provide high scores to pairs with used to measure the similarity between two sentences from different points of view. In the following subsections, we define different types of sen- tence similarity depending on which is the the sen- tence. 4.2.1 BERT fully contextu- alized, we assume that any of them can rep- resent the whole sentence semantically from a specific point of view. For example, in the sentence the president signed the decree verb, refers to the president direct ob- ject designates the decree that is the president. So, in a transitive sentence, each of the three contextualized word might be used to compute similarity at the sentence level (and not just at the word level). Moreover, it is also possible to build a new vector ing the whole sentence by combining the em- beddings of its constituent words. In total, we can build the following four vectors: BERT - verb : Contextualized vector of the verb head, resulting from adding the 4 last layers. BERT - subj : Contextualized vector of the subject word, resulting from adding the 4 last layers. BERT - obj : Contextualized vector of the direct object, resulting from adding the 4 last layers. 158 Pablo Gamallo, Marcos Garcia, Iria de-Dios-Flores BERT - sentence : Mean of all output generates fixed sized vectors of sentences in a way that is similar to our BERT-sentence strat- egy. There are, 24 tuned with two very large dataset collections: SNLI con- in an incremental way. Thus, it is sensitive to the order of application of the identified syn- tactic dependencies. The semantic either from left to right (see 5 be- low) or from right to left (see 6), according to the order in which the two dependencies of the sentence are applied: (nsubj, (nsubj, buy, - verb : This builds the com- positional vector of the verb head buy. It results from being contextualized first by the selectional preferences imposed by the nominal subject company and then selectional preferences of the di- rect object : This builds the com- positional vector of the direct object politician. It results contex- tualized left-to-right values (head and dep). right-to-left - verb : This builds the com- positional vector of the verb head buy. It results from being contextualized first by the selectional preferences imposed by the direct object politician and then by the selectional preferences of the subject company. right-to-left - subj : This builds the com- positional vector of the subject company. It results by the preferences The addition of the two previous right-to-left values (head and dep). Note that, in the left-to-right direction, the object is fully contextualized by the verb and the subject. By contrast, the subject is not contextualized by the object, so that this partially contextualized sense of the sub- ject is not used to represent the sentence. The same occurs for the object in the right-to-left compositional processes. The in- cremental and right context in all layers. Hence, any constituent word is con- textualized by the other words in both left- to-right and right-to-left direction. 4.3 Results All the models and their different shows the results of the four BERT models for the four types of contextualized vectors introduced in sys- tem scores and the human evaluators. We observe that the most significant element of the meaning of the sentence is the contextu- alized sense of the verb -something expected because the verb is the syntactic better results than method, as a representative of the whole sentence, in three of the four models. By contrast, the subject tends to be 159 Evaluating Large Models and Compositional be explained by the fact that in transitive constructions the object is mostly restrictive selec- tion preferences) than by the subject. If we focus on the comparison of the four LLMs, we observe that the best one is clearly BERT-base (57 for the verb), followed by BERT-small (46). big differences be- tween these quite baseline strategy of verb vectors out of context. As it was the case with BERT models, the verb is also the most representative con- stituent of the meaning of the sentence: it and 41 correlation in the two di- rections, compared to only 18 and 15 for sub- ject and object respectively. It follows that the verbal root, once contextualized by the sense of the arguments, can be taken as the meaning of the whole sentence. Although they are not totally comparable, we also show in the last rows of the values 2011b) and from have created Galician the in (Wijnholds, Sadrzadeh, and Clark, 2020). 4.4 Discussion The of the results presented in the previous section leads clusions semantic task. It is also important to point out that the best scores of both Bertinho- base and mBERT are still below baseline (28). Concerning the dependency-based strat- egy, its results are comparable to those of BERT-small-Galician, even if they are far from the higher correlation byModels - obj 36 mBERT - obj 24 Bertinho-base pairs. left-to-right - verb 47 left-to-right - obj 15 right-to-left - sentence 32 right-to-left - verb 41 right-to-left - subj 18 Hashimoto and Tsuruoka (2014) 43 (en) Polajnar et al. (2015) 35 (en) Wijnholds et al. (2020) (en) Table quite similar dataset for English (three last rows). BERT-base-Galician. Let us note that the training corpus of the dependency-based method, as well as that of Bertinho-base and mBERT (Galician part) is just the Gali- cian Wikipedia, and this is much smaller than the training corpus used for the two BERT-Galician models: 42 million tokens vs.500 million. As it was already reported, the contextu- alized sense of the verbal root is the most 160 Pablo Gamallo, Marcos Garcia, Iria de-Dios-Flores representative meaning of the sentence better than the other constituents (subject and object), and even than computing a global meaning for the whole sentence. This is a very relevant observation as most systems computing the sentence meaning do not know which is the root word because they do not rely on a de- pendency tree, and so they make use of the vectors of all constituent words. And finally, we must point out that the correlation values obtained here and in other related experiments for other languages are in low to medium ranges. This shows that this is a semantic task of great complexity that still requires with deeper linguis- tic knowledge. 5 Conclusions In this article, we evaluated and compared the performance of contextualized mechanism of attention driven by configura- tions sentence similarity in Galician. It should noted that the computational cost of train- ing compositional models is much lower that of LLMs. In addition, ent than those from the Transformer Transparent easier to explain the errors and successes committed in a particular task, since it is possible to explicitly list the syntac- relies on syntactic parsing, it has a vulnerable exposure to parser errors. Second, this strat- egy cannot be adapted order to overcome these drawbacks, infuture work we will define and implement syntax-based model allowing us to build fully apply the compostional method to any sentence in as similar way as Transformers do. Acknowledgements This research was funded by the project \"N\u00b4 os: Galician in the society and economy of artificial intelligence\", agreement between Xunta de Galicia and University of Santiago de Compostela, and grant ED431G2019/04 by the Galician Ministry of Education, University and Professional Training, and the European Regional Development Fund (ERDF/FEDER program), and Groups of Reference: 2020/21. In M. Ul car, Robnik- I. and Workshop on Se- mantic Evaluation. Asaadi, S., S. Mohammad, and S. Pro- ceedings of the 2019 Conference of the North American Chapter of the Associa- tion for Computational Linguistics: Hu- man Language Technologies, Volume 1 (Long and Short Papers), pages 505-516, Minneapolis, Minnesota, June. Associa- tion for Computational Linguistics. Bai, J., Y. Wang, Y. Chen, Y. Yang, J. Bai, J. Yu, and Y. Tong. 2021. Syntax-BERT: Improving pre-trained transformers with syntax 16th Conference of Chapter of the Association for Computational Linguis- tics: Main Baroni, M., R. Bernardi, and R. Zampar- a framework for lexical of Language 1(1):55-95. Bowman, S. R., G. Angeli, C. Potts, and C. D. Manning. 2015. A large annotated corpus for learning natural language in- ference. In Proceedings of the 2015 Con- ference Methods in Natural Language Processing, Association for Computa- tional Linguistics. Devlin, Chang, K. Pre-training deep for Computational Erk, K. and S. Pad\u00b4 o. 2008. A structured vector space model for word meaning in context. In 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP-2008, pages 897-906, Honolulu, HI. Ethayarajh, K. 2019. How contextual contextualized and gpt-2 embeddings. In K. Inui, J. Jiang, V. Ng, and X. Wan, editors, pages 55-65. Asso- ciation M. Garcia, Pi neiro, R. Martinez-Casta no, and J. C. Pichel. 2018. LinguaKit: A Big Data-Based Mul- tilingual Tool for Linguistic Analysis and Information Extraction. In 2018 Fifth International Conference on Social Net- works Analysis, Management and Security (SNAMS), pages Comparing dependency-based compositional models with contextualized word Agents and Artificial Intel- ligence (ICAART-2021) . Gamallo, P., irr: Various Coefficients of Interrater the repre- sentation of word study homonymy and syn- onymy. In Proceedings of the tional Linguistics Interna- 1: Long Pa- pers) , Online, August. Association Computational Linguis- tics. Grefenstette, E. and M. Sadrzadeh. 2011a. Experimental for a categori- cal compositional distributional model of meaning. In Conference on Empirical Methods in Natural Language Processing (EMNLP 2011), pages and in a discocat. In on Geometri- cal Models of Natural Language Semantics (EMNLP 2011). Kartsaklis, D. and M. Sadrzadeh. 2013) , pages 1590-1601. 162 Pablo Gamallo, Marcos Garcia, Iria de-Dios-Flores Lin, B. Y., S. Lee, X. Qiao, and X. Ren. 2021. Common continuous space word representations. In Proceed- ings of the 2013 Conference of the North American Chapter of the Association for Computational , based models of semantic Language Technologies (ACL-08: HLT) , pages 236- 244, Columbus, Ohio. Mitchell, J. and M. Lapata. 2010. Composi- tion in distributional 34(8):1388-1439. Nguyen, X.-P., S. Joty, S. Tree-structured tion A. Villavicencio, and 2014. Nothing dis- Conference on Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL, pages 419-424. Pilehvar, M. T. In of the 2019 Conference of the North American Chapter of the Association for Compu- tational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) , pages 1267-1273, Minneapo- lis, Minnesota. Association for Siamese 2019 Conference on Empir- ical Methods in Natural Language Pro- cessing and the 9th International JointConference on Natural Language Process- ing (EMNLP-IJCNLP), pages 3982-3992, Hong Kong, China. Association for Com- putational Linguistics. Salazar, J., D. Liang, T. Q. Nguyen, and K. Kirchhoff. 2020. Masked language model scoring. Proceedings of the 58th the Association for Computational Linguistics . Shibayama, N., R. Cao, J. Bai, W. Ma, and H. Shinnou. 2020. Evaluation of pre- trained BERT model by clustering. In Proceedings of 34th on Language, Infor- mation and Hanoi, Vietnam, October. Association c, I., E. M. Ponti, R. Litschko, G. Glava s, and A. Korhonen. 2020. Probing pre- trained language models for lexical seman- 2020 Con- tion for Computational Linguistics. Wang, A., A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman. 2019. GLUE: A multi-task benchmark and natural language under- standing. In ICLR 2019. Weir, D. J., J. Weeds, J. Reffin, and T. Kober. 2016. Aligning Representation learning for type- driven composition. In Proceedings of the 24th Conference on Computational Natural Language Learning , pages 313- 324, Online. Association for Computa- tional Linguistics. Williams, A., N. Nangia, and S. Bowman. A broad-coverage challenge corpus for sentence understanding through infer- ence. In Proceedings of the 2018 Confer- ence of the North American Chapter of the 163 Evaluating Contextualized Vectors from both Large Models and Compositional Association for Computational Linguis- tics: Human Language Technologies, Vol- ume 1 (Long Papers) , pages 1112-1122, New Orleans, Louisiana. Association for Computational Linguistics. Yu, L. and A. Ettinger. 2020. Assess- representation and composi- tion in In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) As- sociation An of Drugs, Diseases, Genes and Proteins in the CORD-19 Corpus Una visi\u00b4 on general de los F\u00b4 armacos, Enfermedades, Genes y Prote\u00b4 nas en el corpus CORD-19 Carlos Badenes-Olmedo, \u00b4Alvaro Alonso, Oscar Corcho Ontology related Among COVID- 19 Open valuable properly managed to and ments proteins mentioned in texts with the of the systems such as MeSH, ICD-10, ATC, SNOMED, ChEBI, We have used the resultant BioNER+BioNEN process normalization, bioentities, document retrieval. Resumen: Durante la pandemia del COVID-19 han surgido varias iniciativas para recopilar publicaciones cient\u00b4 ficas relacionadas con el coronavirus. Entre ellos, el con- junto de datos de investigaci\u00b4 on abierta sobre COVID-19 (CORD-19) ha demostrado ser un recurso valioso que proporciona el texto completo de art\u00b4 culos extra\u00b4 dos de los repositorios PubMed Central, bioRxiv y medRxiv. Una cantidad tan grande de lit- eratura biom\u00b4 edica debe gestionarse adecuadamente para facilitar y promover su uso por parte de los profesionales de la salud, por ejemplo, etiquetando documentos con las entidades biom\u00b4 edicas que aparecen mencionadas. Hemos creado un reconocedor biom\u00b4 edico de entidades nombradas (NER) que normaliza (NEN) los f\u00b4 armacos, enfer- medades, genes y prote\u00b4 nas mencionados en textos con los c\u00b4 odigos de los principales sistemas de estandarizaci\u00b4 on como MeSH, ICD-10, ATC, SNOMED, ChEBI, GARD y NCBI. Se basa en afinar el modelo de lenguaje BioBERT de forma independiente para cada tipo de entidad utilizando conjuntos de datos espec\u00b4 ficos de dominio y una b\u00b4 usqueda de \u00b4 ndice inverso para normalizar las referencias. Hemos utilizado el sistema BioNER+BioNEN resultante para procesar el corpus CORD-19 y ofrecer una visi\u00b4 on general de los f\u00b4 armacos, enfermedades, genes y prote\u00b4 nas relacionados con el coronavirus en los \u00b4 ultimos cincuenta a nos. Palabras clave: identificaci\u00b4 on de entidades, normalizaci\u00b4 on, the Humandata2, focused on COVID- 1https://www.covid19dataportal.org 2https://data.humdata.org/event/covid-19 Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 165-176 recibido aceptado 13-05-2022 ISSN 1135-5948. DOI 10.26342/2022-69-14 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Natural19 cases around the world, are some exam- ples. The Allen Institute for Artificial Intelli- gence created the COVID-19 Open Research Dataset (CORD-19)(Wang et al., 2020). It is a continuously growing corpus with all pub- licly available COVID-19 and coronavirus- related research (e.g. SARS, MERS, etc.) published during the last fifty years, with a huge increase in the last two years. This dataset provides full-text research papers in PDF and JSON format, which can be used as a source of information to extract knowledge related to the infection and disease. At the time of this study (January 2022), it is com- posed of 334,572 scientific articles retrieved from PubMed Central, a corpus maintained by the World Health Organization (WHO), bioRxiv and profes- sionals. Natural Language Processing (NLP) facilitates document analysis through the ex- traction of key information from the under- lying texts and turning them into structured knowledge that can be understood by hu- mans (Pyysalo et al., 2007). One of the main NLP tasks is the recognition of ploration of texts guided by key terms and the discovery of relationships between them. The NER task identifies meaningful terms in a domain, them into predefined entity classes et al., 2020). In the biomedical these entities are medical concepts such as drugs, diseases, or gene mutations, and more as or applied in the biomedical domain, Bio- NEN (Campos, Matos, and Oliveira, 2012). The main objective in BioNEN is to use Chemical reduce ambiguities and to extend the et al., 2004): (1) highly specialized terms (i.e. most of the terms exclusive these kinds of texts, making we performed BioNER and BioNEN tasks on the CORD- 19 corpus, and our analysis of the presence of diseases, drugs, genes and proteins in their texts. genes/proteins6. (Badenes-Olmedo, Alonso, and Corcho, 2022) A statistical analysis of the presence of biomedical entities in the January 2022 edition of the CORD-19 corpus. The paper is structured as follows: Sec- tion 4 details how the CORD-19 corpus has been processed, and show and discuss the re- sults. Final remarks and future work are pre- sented in section 5. 5https://github.com/drugs4covid/bio-ner 6https://doi.org/10.5281/zenodo.6532473 166 Carlos Entity Recognition NER tasks usually follow the 1. The text is pre-processed de- words which com- pose a text span is made, what serves as an input to a NER model which performs the classification of these features to assign tags to the words. Sometimes, in order refine results, a post-processing Biomedical-NER (BioNER) specializes the NER classification task for sometimes, be domain define the different sorts of named entities to rules through automatic patterns and reduces the need for domain knowledge) and Hybrid ap- proaches (i.e. combines methods to leverage benefits from 2020) (Perera, Dehmer, and Emmert-Streib, 2020)(Yadav and Bethard, 2019). 2.1 Our Approach We have created a hybrid system for the normalization (Lee et al., 2020) model pretrained with millions of scientific and biomedical training corpora to extend the task and to cover the BioNEN task mul- tiple external standardization databases. The entity used classes in BioNER for is important to note that these biomedical entities can be mentioned in different ways and this makes it to achieve (.e.g lung infection a different BioNER model was created (see Fig. 2). One model was fine-tuned to recognize disease entities, another for chemical (i.e. genes/proteins. We in task in only one model. The more specific the model is, the better results will be usually obtained for a specific task (Gururangan et al., 2020). Sep- its tagging performance, resulting a system with the better model possible for each of the entities. Our system offers slightly lower performance BioBERT use aim ability to identify as many entities as possible, even at the cost of penalizing the accuracy of the model, since our pipeline incorporates an ad- ditional normalization step where the enti- be The post-processing tasks are based on an inverse index search. The architecture of the system is described in Fig. 2 and further details about each of the components are revised along the follow- ing sections. 2.2 Datasets We have added an untrained fully-connected layer on top of a BioBERT model the fine-tuning. At least three tuning processes been done cover the 7https://www.ebi.ac.uk/chebi 167 An Overview of Drugs, Diseases, tity, two corpora for each entity class supply the model with better generaliza- tion capacity in situations where a never-seen al., 2020). 2.2.1 Diseases Dataset The BC5CDR-Diseases dataset (Li et al., 2016), with around 13,000 annotations, and the NCBI-Diseases dataset (Do gan, Leaman, and Lu, the corpora of 87.4 and 85.8, respectively. This is likely because of the hyperparameter search intensity and because (Krallinger et al.,2015) and BC5CDR-Chemicals (Li et al., 2016) with around 80,000 and 15,000 entities respectively. The largest annotated corpus, BioSemantics (Akhondi et al., was not considered since it is based on patents which could slightly differ from biomedical articles that are the kind of texts in which our system is focused on. The selected datasets were also the most widely adopted corpora in chemical entities the second best result for BC5CDR with 93.47, is result obtained by Blue- (Peng, Yan, Lu, which was 93.5 . Our system obtained F1 is widely adopted most which consider them together Gupta, and Kumar, 2018). The pair of selected datasets were JNLPBA (Kim et al., 2004) and BC2GM (Smith et al., 2008), which offer around 35,000 and 25,000 annotations respectively. The CRAFT et al., 2012), which is the largest Gene/Protein NER corpus, was discarded since most models report results 168 Carlos Badenes-Olmedo, \u00c1lvaro Alonso, Oscar Corcho Year Reference Corpus Name Entities #Annotations #T 2004) Anatom Genes/Proteins 2013) SemEv al2013 - DrugBank Chemicals 15745 65000 Zazo, 2013) SemEv al2013 - Medline 2015) BioNLP13PCGenes/Proteins15901 Diseas e LocT PubMed- a F1 of 80.06. Results from our fine-tuning model were a bit of suben- tity classes which take part within this This amount of some additional steps before having a homogeneous an inverted index search. Each entity is associated search for entities that contain that term in any of their related fields, and we sort that set of candidates based on the BM25 rank- ing function (Robertson et al., 1994). Those with fewer related terms will have greater relevance. Each type of entity has its own database (i.e index). This way, indexes can be built separately curated Multiple term ordescription of the underlying concept (e.g. \"Hydroxychloroquine \") ; (2) a list of syn- onyms that all '); type (e.g. ' Pharmacologic Substance ' ) and (4) a list of identifiers based on MeSH, CUI, ATC, or any of possibilities to refer to the same element (i.e by code, term or synonym) allow choosing the one with the higher search crite- ria (e.g. or similar matches) and filtering criteria based on word order, or terms). result with the higher score is considered. 3.1 Diseases Four different sources the index to normalize disease terms based on the mappings terms used cal and controlled vocabulary produced by the National Library of Medicine (NLM). This thesaurus includes thousands of terms regarding BioPortal includes an ontology version from which have terms have been merged the previous ones through an outer join IDs. DOID: The Human Disease Ontology 11https://www.nlm.nih.gov/mesh 12https://www.omim.org(Schriml et al., 2012) is a comprehensive knowledge base of inherited, developmental and acquired human diseases. It MeSH, to extend terms which were not previously captured by the other sources. The way this was done is through an outer join on MeSH IDs. ICD-10-CM: The hierarchical classifica- tion listed by the World Health Organization (WHO), in which are encoded a wide range of signs, of this classification with a Clinical Modification of the source. Since this its proper BioPortal on- tology, further mapping concepts are added, which case of Unified Medical Lan- guage System identifiers (CUIs). The way this source extends the previous sources is through this CUI since not MeSH IDs are in- cluded. For that purpose, an outer join on this id was done. 3.2 Drugs Five sources were considered to merge chemi- cal terms in a shared index. The main objec- tive was to capture the wide range of possible mentions that this entity class can is the world largest chemistry open database maintained by the National Institute of Health (NIH). Among the classification systems offered to organize the chemical 130000 terms were which have the most widely adopted chemical terms within all the collection. ChEBI: ChEBI is a chemical database mainly focused on small compo- nents of molecular and therefore it complements other types of terms considered the rest of Any present in this join on InChIKey was used for connecting these terms with the ones present in the previous source. InChIKey is a hashed key of InChI, an International Iden- tifier for chemicals, which offers an IUPAC identifier for an standardized codification of 170 Carlos Badenes-Olmedo, - source has been just used to add MeSH IDs and extend information from the previous terms. This source was combined with the previous ones through checking if the term is found either on term field or on the synonyms list. If it is not found, it has been appended to chemical terms. CTD - of BioPortal has been the source considered for ATC since it in- corporates further information and relations with other terms. Information regarding ATC level and ATC code was added to the previously considered terms. If the term is not present, it has been appended. 3.3 Genetics This entity class is composed of a broad se- mantic type since it includes both gene and proteins-related terms. They are close se- mantic types and even in some occasions the use of the same expressions is diffuse. This has led to a wide range of terms within this entity class in which four large and comple- mentary sources were merged in the same et al., 2000) is the largest source for the functions of genes and therefore it has been (He, 2014) genes and genomes certain organisms humans, virus and bacteria. are found range of protein-related entities along with relations between them. This source contains a large amount of terms that covers the a vocabu- lary retrieved from multiple sources with a great variety of genes in multiple species. It has been used to extend the gene terms which were CORD-19 in recognition process was time consuming (approximately 48 days) in a server composed by a 32 CPU-cores In- tel Xeon with 256GB The the (i.e. it requires matrix computation for the transformer-based language models, one for each biomedical concept. The source code is publicly and normalization was done for each paragraph of the scientific article. A first group of labels is created to identify the medical terms as they appear in the text (i.e. diseases ss,chemicals ss, genetics ss), in terms ss,chemical terms ss, group of labels contains the for each all tags indicates that the format is a textual list (i.e. string sequence). Table 3 shows some statistics about entity classes once the corpus was processed. As ex- pected, half of the paragraphs least by Allen AI to filter articles that contain coronavirus- related terms in their title or abstract. This guide the content of the article and also ex- plains why the variety of disease and symp- tom entities (see column dard terms (according to our model) used to refer to drugs, with respect to the rest of biomedical entities. Column Normalization shows the ratio of entities mentioned in the text using any of the terms extracted from the classification systems described in section 3. We think that there is more flexibility in scientific texts to refer to symptoms or dis- eases than to drugs or active ingredients, with respect to the standards (e.g. ATC, MeSH, ICD-10 or SNOMED mainly). Regarding ge- netic information, cause lies in the precision in the recognition of the bound- ary that defines the entity, being sometimes eliminated the chemical expression of 4 tion the entity, the occurrences of these words are given (column Ratio ). This allows us to have an idea about the relevance of the concept in the corpus with respect to the rest of the concepts of the same classification sys- tem. In top cepts related to respiratory difficulties. As we go down in the top, more specific terms begin to appear. In the systems that cover diseases such as MeSH or ICD-10, we can find as the most relevant concept the COVID-19 disease, as and focused genetic protein informa- tion show, with similar relevance, (e.g. in entity recognition sys- tem, we can use the hierarchies defined in the underlying classification system to estab- lish exam- ple, Therapeutic Chemical (ATC) classification system, which is sup- ported by the World Health Organization (WHO) and the organ on which they act and their thera- peutic, pharmacological, and chemical prop- erties. Drugs are classified groups at five different levels. The first one corresponds to main groups, the second one to pharmacolog- ical or therapeutic subgroups, the third and the fourth one are chemical-pharmacological- therapeutic subgroups and the last one is the chemical substance. Once the code of a drug has been identified in this classification sys- tem, we can extend the labels of the text with those groups of the hierarchy, enabling addi- tional ways of exploiting the results of the annotation process. In the following experiment we want to take advantage of the labels generated by our system to treat coron- avirus. do not know a priori which groups of drugs are related in this domain, and we assume that an evidence implies the joint presence of several groups in the same para- graph. Since the ATC classification system is hierarchical and establishes 14 anatomic groups at the first level of drug organiza- tion, we can create a matrix with graphs where drugs are mentioned and the anatomic groups to which they belong. Fig- ure 3 shows the correlation between each groups of mentions of drugs seen how the highest correlation exists between drugs associated with Sensory or- gans and Anti-infectives for systemic use. This may be due to the fact that many of the anti-infective active substances used (i.e. orally or 172 Carlos Badenes-Olmedo, \u00c1lvaro Alonso, Oscar Corcho Entit y Ratio Code Description ICD-1051.1 U07.1 COVID-19 8.0 J12.81 Pneumonia due to SARS-associated coronavirus 3.7 J11.1 Influenza due to unidentified influenza virus with other respiratory manifestations 3.3 factor SNOMED57.4 840539006 Disease c the since they administered by ophthalmic route. Thanks to the tags cre- ated by our it is sufficient to fil- ter the paragraphs most notable is between Anti-infectives for systemic use and substances most used exper- imentally for the treatment of coronavirus were found categories, such as Lopinavir/Ritonavir (anti-infective) and Hy- droxychloroquine (anti-parasitic). Again, we can take advantage of the tags in our system to find texts in the articles that help us vali- date this assumption. 173 An Overview of Drugs, the CORD-19 Figure 3: Correlation matrix of ATC data at Anatomical group level. 5 Conclusions We have created a corpus with the diseases, drugs, genes, and proteins mentioned in in edi- tion of CORD-19 and to take up changes in the CORD-19 dataset. An analysis has been carried out on this corpus to measure the presence and degree of normalization of each type of biomedical a disease only 4% of them were mentioned using any of the standard codes or alias. The behavior in genes and proteins is similar although much lower in terms of presence. Drugs are the least present and most varied type of entity in the corpus. The correlation between the anatomical groups of the drugs has also been measured to value the usefulness of the tags created. The procedureto easily extract the evidence, i.e. on the pre-trained model and combines three different models each of them specialized in the nition biomedical entity: dis- ease, In the future we want to explore the ability of the tags to produce knowledge, either to organize en- tities or to discover relationships that may arise between them, and to take advantage of the knowledge acquired to create a Span- , by investigaci\u00b4 on cient\u00b4 fica SARS-CoV-2 y COVID-19 . 174 Carlos Badenes-Olmedo, \u00c1lvaro Alonso, Oscar Corcho References Akhondi, S. A., A. G. Klenner, C. Tyr- chan, A. K. Manchala, K. Boppana, D. Lowe, M. Zimmermann, S. A. Ja- garlapudi, R. Sayle, J. A. Kors, et al. 2014. Annotated chemical patent corpus: a for text mining. PloS one , 9(9):e107477. Ashburner, M., C. A. Ball, J. A. Blake, D. Botstein, H. Butler, J. M. Cherry, A. P. Davis, K. Dolinski, S. S. Dwight, J. T. Ep- pig, et al. 2000. Gene ontology: tool for the unification of biology. Nature genetics, 25(1):25-29. Bada, M., M. Eckert, D. Evans, K. Gar- cia, K. Shipley, D. Sitnikov, W. A. Baum- gartner, K. B. Cohen, K. Verspoor, J. A. Blake, et al. 2012. Concept annotation in the craft corpus. BMC bioinformatics, 13(1):1-20. Badenes-Olmedo, Alonso, Cor- 2022. Drugs, Diseases, Genes and Proteins in the CORD-19 Corpus, March. S., T. Bobi\u00b4 c, M. biomedical literature. F1000Research , 3. Campos, D., S. Matos, and J. L. Oliveira. 2012. Biomedical named entity recogni- tion: a survey of machine-learning Applications for Advanced Text Mining , 11:175-195. Chatterjee, A., Knowledge graphs for covid-19: An review current landscape. Journal of Personal- ized Medicine, 11(4). Do gan, R. I., R. Leaman, and Z. Lu. 2014. Ncbi disease corpus: Jensen, and B. Rost. 2015. Linked annotations: a middle ground for manual biomedical databases and text corpora. In BMC proceedings, 9, pages 1-3. BioMed Central. , 29:21-43.Gururangan, S., A. Marasovi\u00b4 c, S. Swayamdipta, K. Lo, I. Beltagy, D. Downey, and N. A. Smith. 2020. Don't stop pretraining: Adapt language models to domains and tasks. preprint He, Y., Ogg: a biological ontology S. Landeghem, T. Ohta, Y. Van de Peer, F. Ginter, and S. Pyysalo. 2016. Cell line name recognition in port of the bio-entity recognition task at jnlpba. InProceedings of the international joint workshop on natural language processing in biomedicine and its applications, pages 70-75. Citeseer. Krallinger, M., O. Rabal, F. Leitner, M. Vazquez, D. Salgado, Z. Lu, R. Lea- man, Y. Lu, D. Ji, D. M. Lowe, et al. 2015. The chemdner corpus of chemicals and drugs and its annotation principles. Journal of cheminformatics, 7(1):1-17. Lee, J., W. Yoon, S. Kim, D. Kim, S. Kim, C. H. So, and J. Kang. 2020. Biobert: a pre-trained biomedical pharmacoge- nomics. Scientific data , 7(1):1-13. Li, J., Y. Sun, R. J. Johnson, D. Sciaky, C.-H. Wei, R. Leaman, A. P. Davis, C. J. Mat- tingly, T. C. Wiegers, and Z. Lu. 2016. Biocreative v cdr task corpus: a resource for chemical disease relation extraction. Database, 2016. Li, J., A. Sun, J. Han, and C. Li. 2020. A survey on deep learning for named en- tity recognition. IEEE Transactions on An Overview of Drugs, Diseases, Genes and Proteins in the CORD-19 Corpus Nadeau, D. and S. Sekine. A., C. N. Arighi, J. A. Blake, J. Bona, C. Chen, S.-C. Chen, K. R. Christie, J. Cowart, P. D'Eustachio, Overview of the pathway curation (pc) task of bionlp shared task 2013. In Proceedings of the BioNLP Shared Task 2013 Workshop, pages 67-75. Pafilis, E., S. P. Frankild, L. Fanini, S. Faulwetter, Pavloudi, A. Vasileiadou, C. and L. J. Jensen. 2013. The species and organisms resources for fast and names in text. PloS one, 8(6):e65390. Peng, Y., S. Yan, and Z. Lu. 2019. Trans- fer learning in biomedical natural lan- guage processing: J. Jarvinen, and T. Salakoski. 2007. Bioinfer: a corpus in domain. BMC bioinformatics, BMC bioinformatics, 16(10):1-19.Robertson, S. E., S. Walker, S. Jones, M. Hancock-Beaulieu, and M. Gatford. 1994. Okapi at trec-3. In TREC. Schriml, L. M., C. Arze, S. Nadendla, Y.- W. W. Chang, M. Mazaitis, V. Felix, G. Feng, and W. A. Kibbe. 2012. Computational Linguis- tics. Smith, L., L. K. Tanabe, R. J. nee Ando, C.- J. Kuo, I.-F. Chung, C.-N. Hsu, Y.-S. Lin, R. Klinger, C. K. Ganchev, et al. 2008. Overview biocreative ii gene mention recognition. Genome biol- ogy, 9(2):1-19. Wang, L. L., K. Lo, Y. Chandrasekhar, R. Reas, J. Yang, D. Eide, K. Funk, R. Kinney, Z. Liu, W. Merrill, et al. 2020. CORD-19: The Covid-19 Open Research Dataset. arXiv preprint arXiv:2004.10706. Yadav, and advances in arXiv preprint arXiv:1910.11470. Zhou, G., J. Zhang, J. Su, D. Shen, and C. Tan. 2004. Recognizing names in biomedical texts: a 20(7):1178-1190, May. 176 Carlos Badenes-Olmedo, \u00c1lvaro Alonso, Oscar Corcho Transformers for Lexical Complexity Prediction in Spanish Language Transformers para la Predicci\u00b4 on de la Complejidad L\u00b4 exica en In this article we have presented a contribution to the prediction of the complexity of simple words in the Spanish language whose foundation is based on the combination of a large number of features of different types. We obtained the results after run the fined models based on Transformers and executed on the pre- trained models BERT, XLM-RoBERTa, and RoBERTa-large-BNE in the different datasets Spanish and regression algorithms. The evaluation of the results good performance was achieved with a Mean Absolute Error (MAE) = 0.1598 and Pearson = 0.9883 achieved with the training and evalu- ation of the Random Forest Regressor algorithm for the refined BERT model. As a possible alternative proposal to achieve a better prediction of lexical complexity, we are very interested in continuing to carry out experimentations with data hemos presentado una contribuci\u00b4 on a la predicci\u00b4 on de la complejidad de palabras simples en lengua espa nola cuyo fundamento se basa en la combinaci\u00b4 on de un gran n\u00b4 umero de caracter\u00b4 sticas de distinta naturaleza. Obtuvi- mos los resultados despu\u00b4 es de ejecutar los modelos afinados basados en Transformers y ejecutados sobre los modelos pre-entrenados BERT, XLM-RoBERTa y RoBERTa- large-BNE en los diferentes conjuntos de datos en espa nol y corridos con varios algoritmos de regresi\u00b4 on. La evaluaci\u00b4 on de los resultados determin\u00b4 o que se logr\u00b4 o un buen desempe no con un Error Absoluto Medio (MAE) = 0.1598 y Pearson = 0.9883 logrado con el entrenamiento y evaluaci\u00b4 on del algoritmo Random Forest Regressor para el modelo BERT afinado. Como posible propuesta alternativa para lograr una mejor predicci\u00b4 on de la complejidad l\u00b4 exica, estamos muy interesados en seguir real- izando experimentaciones con conjuntos de datos para espa nol probando modelos de Transformer de \u00b4 ultima generaci\u00b4 on. Palabras clave: 1 Introduction A common assumption is that people who are familiar with the vocabulary of a text can often understand the meaning of the words, even if they have difficulty with grammati- cal structures (Uluslu, 2022). The task of detecting in the content of the documents the words that are difficult or complex to understand by the people of a given groupis known as Complex Word Identification - CWI (Rico-Sulayes, 2020) and it is a task that constitutes a fundamental step in many applications related to natural language, such as Text Simplification. Automatic can (Uluslu, 2022). Deep learning and its revolutionary tech- Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 177-188 recibido aceptado 06-06-2022 ISSN 1135-5948. DOI 10.26342/2022-69-15 \u00a9 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Naturalnology constitute the new state of the art in various Natural Language Processing (NLP) tasks 2021). It is impor- tant to point out that, after the comparison and analysis of other approaches versus deep learning approaches, a viable path of pos- sible solutions is generated for low-resource languages where deep models are not always available or work as well as those of deep learning in English language. Likewise, it should be taken into account that the com- putational requirements for the application of deep learning models turn out to be sig- nificantly higher compared to those used in The field of NLP has shown incredible progress in the last two years, this is par- ticularly due to the Transformer architecture (Vaswani et al., 2017) that takes advantage of large amounts of unlabeled text corpus (Canete et al., 2020). Deep learning mod- els show significant improvement over shal- low machine learning models with the rise of transfer learning and pretrained language models. The deep learning pretrained lan- guage models, pre- dicting the complexity score for single words in the Spanish language, since resources are scarce and are not as numerous as those avail- able for the English language. Our model leverages the combination of advanced NLP techniques of deep learning models based on Transformers: BERT (Liu et al., 2019), XLM-RoBERTa (Conneau et al., 2019), RoBERTa-large-BNE (Guti\u00b4 al., 2021) and pre-trained embeddings together with a set of textual complexity features made by hand (Hand- Crafted Features). For this, we use the cor- pus in Spanish CLexIS2corpus proposed by (Zambrano and Montejo-R\u00b4 aez, 2021). trained model, for which, we follow the research done by (Rojas and Alva-Manchego, 2021). The models used achieve a good perfor- in the MAE and a Person correlation 0.9883 for the identification of simple complex words.2 Related Work In past decades, the application of very ple metrics such the 1969) or ver- ifying whether the word was part of a specific list to classify it as easy or complex (Dale and Chall, 1948) were the techniques that were applied in text legibility tasks. After, a Random Forest classifier (Breiman, 2001) to determine whether a word is complex or not are presented. A total of 45 handwritten features were com- puted in these systems, and modeled a feature (eleven functions), and and corpus frequency functions (four functions) were ap- plied. The best result was and an F-score of 0.292. The investigations in the last years are directed to the Identification of Complex Words - CWI. The objective of these tions the words based on the construction of their features, as exposed in the work carried out by (Shardlow, Cooper, and Zampieri, 2020) presenting their approach on a set of of (Shardlow et al., 2021) developed a system for predicting for the task 2021 task organizers participants the CompLex corpus (Shardlow, Cooper, and Zampieri, 2020) but in its augmented version. The task was located on the Lexical Seman- tics track, which out that was based on 15 linguistic features obtained at the word level and their environment. Trained a supervised 178 Jenny Ortiz-Zambrano, C\u00e9sar Espin-Riofrio, Arturo Montejo-R\u00e1ez algorithm on the set of features. Several runs were made with different values to observe the performance of the algorithm. The best results achieved were a MAE = 0.07347, = 0.00938 and RMSE = 0.096871. In our approach, we review the use of word embeddings from the pre-trained and fine-tuned models, and compare them to a broader list of linguistic features at the lexi- cal level. Our objective is to provide an ex- haustive evaluation that clearly, the executions carried out on several differ- ent data sets in the Spanish language, how the lexical features together with the deep encodings contribute to briefly details about the pre- trained models and their application for the generation of encodings at both the sentence and word levels. Likewise, the data sets that have been used in the different experiments are presented. Finally, the transcripts the recorded classes of the professors of the degrees of Computer Systems Engineering and Software Engineer- ing, two degrees that belong to the Fac- ulty of Mathematical Sciences of the Univer- sity of Guayaquil (Ecuador) (Zambrano and Montejo-R\u00b4 aez, become a resource of great interest and importance, due to the fact that there are few resources in Spanish available for NLP researchers1, and some of them do not usually contain annotations that facili- tate the development of NLP models (David- son et al., 2020). For its construction, the collection presented in the ALexS Annotated computed based on the number of annotators that agreed to consider it as a complex word. Therefore, the task we are facing here can be to evaluate different systems. Table 1 shows some statistics on different type of words present in the CLexIS2dataset. 3.2 Transformer based language models The models were taken from the Transform- ers2library. The pre-trained BERT model that we chose was the one that the Spanish com- munity uses mostly in research work to date, which is bert-base-uncased (BETO) (Canete et al., 2020). BERT-base model has the of layers L=12, the hidden number of self-attention and Parameters=335M model applied was xlm- roberta-base (Conneau et al., 2019). The XLM-RoBERTa-base model has number of layers L=12, H=1024, the A=16, rameters=550M et al., 2019). The RoBERTa-large-BNE model used was being the largest Spanish-specific date XLM-RoBERTa-large is a transformer- based masked language model for the Spanish language. It is based on the RoBERTa large model3. The RoBERTa-large-BNE model has the number of layers Lexical Complexity Prediction to demonstrate how the com- bination of different types of features con- tribute to a better performance in predicting lexical complexity. We base our proposal on several of the works presented at the Inter- national Workshop on Semantic Evaluation - SemEval-2021 (Shardlow et al., 2021) where a total of 198 teams were presented, of which 54 teams officially sent their executions4; but the work that most attracted us due to its methodology was the ity to of the Lexi- cal Complexity Prediction. First, we chose the data sets for training were: the first data set was made up of the linguistic fea- tures made by hand - Hand-Crafted Fea- tures (HCF) and the second data set was made up of the Transformers encodings from the models: BERT in Spanish, multilin- gual XLM-RoBERTa and RoBERTa-grande- BNE. Next, we applied a fitted model top of the previously trained model to demon- strate how running the fitted contributed the different supervised learning algorithms were executed on the training data set to evaluate which of them achieved the best prediction score. ensure that the partitions contained independent data for training and testing. We have used some metrics that were applied to the results of experiments presented in Sem-Eval 2021 (Shardlow text, we perform several experiments apply- a total of 23 linguistic features and com- bine them em- beddings of previously trained deep learning models. 15 pro- posed by (Ortiz-Zambrano and Montejo- aez, 2021) 23 Hand-Crafted Features. We used the Spacy library together with the escore news smto extract these features. of in common parlance a word occurs frequently, it is more likely to be recognized (Rayner and Duffy, 1986) and (Shardlow, Cooper, 2.Relative frequency 3.Word length : the number of characters of the token. The length of the word was calculated in number of its charac- ters. It is often the case that longer length words are more difficult to pro- cess considered Cooper, complexity syllables contained in a word (Shardlow, 2013) (Ronzano et al., 2016) (Shardlow, Cooper, and Zampieri, 2020) (Paetzold and Specia, 2016). 5.Target word position (token-position): the position of the target word in the sentence. Position of the word (Word- Position) (Shardlow, 2013) (Ronzano et al., 2016). 6.Number of words in the sentence : num- (Shard- low, (Ronzano Based on the work proposed by (Ron- zano et frequency of the previous token : the frequency of the word before the token. 9.Relative frequency of the word after the token : the relative frequency of the word after the token. 10.Length of previous word : the number of characters in the word before the token. 11.Length of the after word : the number of characters in the word after the token.12.Lexical diversity - MTDL : the lexical di- Liebeskind, results, generating 8 new features originating from the POS, which were: 1. PROPN - Number of pronouns within the sentence. 2. AUX - Number of auxiliaries within the sentence. VERB - Number of verbs within the sen- tence. 4. ADP - Number of adverbs within the sentence. 5. NOUN - Number of nouns within the sentence. NN - Number 181 Transformers for Lexical Complexity Prediction in Spanish Language 7. SYM - Number of symbols within the sentence. 8. NUM - Number of numbers within the sentence. BERT vector: The bert-base-uncased model from the Hugging Face trans- former library (Wolf et al., 2020) all pre-trained and fine-tuned BERT al., 2018) and added the twenty-three Hand-Crafted Features obtaining a dataset with a linguistic features of different nature. XLM-RoBERTa vector: As in the case of the BERT model, we take all the 768-dimensional numerical repre- sentation produced by the pre-trained RoBERTa model et al., 2019) in the different combinations of sentence and target word encodings, for both the pre-trained model and the model fine- tuned, reaching a total of 1559 linguistic characteristics of different nature. RoBERTa-large-BNE vector: Re- garding this we take all no et al., 2021), in the same way that they were applied in the previous models, the data sets were made up of for the differ- ent combinations of sentence and target word encodings, for both the pre-trained model and the fine-tuned model, reach- ing a total of 2071 linguistic characteris- tics of different nature. 3.3.2 Machine Learning Algorithms Similar to the work done by (Zaharia, Cer- cel, and Dascalu, 2021) in the case of the al- gorithms, the training and evaluation of the different c ombinations o f t he s ets w as car- ried out with a total of eight supervised al- gorithms for the regression, these are: 1. and (Liebeskind, al., - RF) and of where different apply the default values for the algorithms except for the case for tree-based algorithms, achieving to determine the best hyper-parameters number of nodes: AdaBoost with Random nodes. Boosting algorithm with to run them on the pre-trained models. The table 2 table presents the description of the abbreviations that will be used for a better understanding of the features applied to the data below: with the fea- vector corresponding to the target token as word embeddings (BERT word). The Hand-Crafted Features with encod- ings of the [CLS] token and encodings of the target token. The encodings of the [CLS] token. The encodings of the target token. The encodings of the [CLS] token with the encodings of the target token. 182 Jenny Ortiz-Zambrano, models. XLMR sent Sentence encodings from model. Table 2: Description of the Feature sets. For the evaluation of the trained and fine-tuned models, those that were widely applied to al., 2021). 4.2 BERT model pre-trained table 3 shows the eight best exe- cuted with BERT pre-trained. As we can see in the three best results in predicting lexical complexity were achieved by The best performance achieved by Ad- aBoost algorithm presenting the best predic- tion for the Spanish language with a MAE = 0.1632 and a Pearson = 0.999 in the execu- tion with the data set made up of the com- bination of the features generated at the sen- tence level and at the word level - BERT sent BERT word. 4.3 BERT model fine-tuned We have applied the fine-tuned BERT model on top of the pre-trained BERT model for the purpose of the results. The table 4 shows the eight best executions, positioning RFR - Random Forest Regressor algorithm and the GBR - Gradient Boosting Regressor al- gorithm in the first places. The best performance was obtained with the dataset composed of the combination of the with target encodings to- gether with sentence combination fea- tures achieved the best performance in the pre-trained model, but with lower results. It should be noted that the RFR algorithm does not appear within the top eight places in the execution of the pre-trained model, but itachieves its best result when the model is re- fined, placing first and third within the three best executions tuned. RFR presented the best prediction for the Spanish language with a MAE = 0.1592 and a Pearson = 0.988 com- bining BERT sentBERT word. 4.4 XLM-RoBERTa model pre-trained Similar to the BERT model, the top eight sites were taken from all the runs that were done on the different data sets. The results of the best place for the pre-trained XLM- RoBERTa model were achieved by the ABR - AdaBoots algorithm with a MAE = 0.1623 and a Pearson = 0.9973 result of the combi- nation of the features with target word and sentence encodings together with the HCF - XLMR sentXLMR wordHCF, as can be seen in the table 5. It can be clearly shown that the pre-trained XLM-RoBERTa model has a better performance compared to the pre-trained BERT model, achieving a better achieved of the pre-trained model, reaching a MAE = 0.1601 and a Pearson = 0.998 as result of the combination of the features with word together XLMR wordHCF. See table 6. results the BERT and XLM-RoBERTa both tuned models, BERT tuned is so far the one that has an important performance achieved by a MAE = 0.1592 with the execution of the RFR algorithm word. 183 Transformers for Lexical Spanish different nature. BERT model fine-tuned of different nature. 4.6 RoBERTa-large-BNE model pre-trained The novelty of this research is to have incor- porated the executions with the pre-trained model RoBERTa-large-BNE and its adjusted model. The eight best results are displayed in the table 7. The best position were achieved by the ABR-AdaBoost algorithm with a MAE = 0.1609 and a 0.6754 combining the sentence RoBERTa-large-BNE is the that achieves a better prediction for lexical com- plexity in the Spanish language compared to the pre-trained models BERT and XLM- RoBERTa. See 9. 4.7 model RoBERTa-large-BNE an improvement compared to the results of the pre-trained model. The low im- provement, achieving in its performance a MAE = 0.1609 and a Pearson = 0.6754 combining the sentence and HCF - sentRLBNE wordHCF, the second and third places prove it in comparison with the pre- trained model. It should be noted that the tuned model BERT is the one that achieves a better pre- diction for lexical complexity in the Span- ish language the tuned models XLM-RoBERTa and RBNE. See table 10. It can be seen that the fined models based on Transformers make an important contri- bution to the Prediction of Lexical Complex- ity in the Spanish language. The table 11 presents the best five best results of all the ex- periments carried out with the models, both pre-trained and fined. is important to are of words and sev- calculations, have the level of predic- tion of the complexity of the words. 5 Discussion We have applied the BERT, RoBERTa, and RoBERTa-large-BNE models for our research in predicting lexical complexity in several of in LCP task of the SemEval 2021 International Conference (Shardlow et al., 2021) which important TheSpanish in Language Models area of Lexical Simplification for Span- ish. We observe that according to the results of the final evaluation, especially in terms of fine-tuning, Spanish language complexity the proposal presented after the ex- ecution of the manual features-HCF. In the case of the RoBERTa-large-BNE model, we have found a performance that exceeds the rest of the models after the execution of the pre-trained model and even remains within the three best executions in the results of the tuned models, such as the proposals pre- by no et al., 2021) 6 Conclusions and Further Work In this article, we have presented a contri- bution to predict the complexity of simple words in the Spanish language, combining a large number of features of different types. We consider that, after the multiple experi- mentations that we carried out, it allowed us to know the maximum performance for the different combinations of the data sets by ap- plying the regression algorithms. In our experiments, we tures of different nature. generate algo- rithms, which led a MAE = 0.1598 and aPearson of 0.9883 achieved with the evalua- tion and training of the Random Forest Re- gressor algorithm for the tuned model BERT. Additional features can boost pre-trained models to levels of performance close to those of fine-tuned models alone, so it could be a feasible approach when there are not enough computational resources for such a down- stream training. As a possible alternative proposal to achieve a better prediction of lexical complex- ity, we are very interested in continuing to carry out experimentations on data sets for Spanish, testing state-of-the-art Transformer models. To this end, extrinsic evaluation will be overcome, comparing the best systems on task with the possibilities of in- tegrating external features like the work. Acknowledgements We appreciate Jostin Daniel Escobar Suarez, Joel Stalin Sorroza Diego Gabriel Bernal Yucailla y Diana Geovanna Aroca Pincay graduate of the Computer Systems Engineering degree from the University of Guayaquil, for their valuable contribution to the development of our work. This work is partially funded by grants P2000956 (PAIDI McMillan- Major, and S. Shmitchell. 2021. On the Proceedings of ACM Accountability, and Transparency, FAccT '21, page 610-623, New York, NY, USA. Association for Computing Machinery. Bottou, L. 2010. Large-scale ma- chine , 45(1):5-32. Canete, J., G. Chaperon, R. Fuentes, J.-H. Ho, Kang, and J. P\u00b4 erez. 2020. Span- ish pre-trained G. Wenzek, F. Guzm\u00b4 an, E. Grave, M. Ott, Zettlemoyer, and V. and Y. Singer. 2006. Online passive-aggressive algorithms. Journal of Machine Learning Research, 7:551-585. Dale, E. and J. S. Chall. 1948. A formula predicting readability: Instructions. bulletin, pages A. Yamada, P. F. Mira, A. Carando, C. H. S. Gutierrez, and K. Sagae. 2020. Developing nlp tools with a new corpus of learner spanish. In Pro- ceedings of the 12th Language Resources and Evaluation Conference , pages 7238- 7243. Desai, A., deep bidirectional 2018: voting. of the Workshop on NLP for Building Educational Applications, pages 184-194.Guti\u00b4 no, Carrino, C. Armentano-Oller, C. Rodriguez-Penagos, models. Se- mantic Evaluation (SemEval-2021), pages 138-143. Liu, X., P. He, W. Chen, and J. Gao. 2019. Improving multi-task deep neu- ral networks understanding. preprint Mc Laughlin, G. H. 1969. readability formula. Journal of read- ing, 12(8):639-646. Nandy, of alexs 2020: First workshop on lexical analysis at pln. Proceedings of Heavy gauge word vot- ing. In 10th Interna- 187 Transformers for Lexical Workshop on Semantic (SemEval-2016), pages 969-974. Rayner, K. and S. A. 1986. Lexical complexity and fixation times in reading: word 2020), CEUR-WS, Iapucp task 1: Stack- pages 1011-1016. H., S. Mille, L. and B. Mak- ing it simplext: Implementation and eval- uation of a text simplification ACM Transactions on Accessible Computing complex the Association for Computational Linguis- tics Proceedings of the Student Research Workshop, pages 103-109. Shardlow, M., M. Cooper, and M. Zampieri. 2020. Complex: A new corpus for 9:68675-68702. arXiv:2201.05878. Vaswani, A., N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin. 2017. Atten- tion is all you need. In Advances neu- ral information processing systems , pages L. Debut, Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac, T. M. Funtowicz, et al. 2020. Trans- formers: State-of-the-art natural language processing. In Proceedings of the 2020 conference on empirical methods in language processing: system demon- 38-45. Yaseen, T. B., Q. Al- and pre- trained language models. In Proceedings of the 15th International and A. Montejo-R\u00b4 aez. 2021. Clexis2: A new corpus for complex word identification research in comput- ing studies. In Proceedings of the Inter- national Conference on Recent Advances in Natural Language Processing (RANLP 2021), pages 1075-1083. 188 Jenny Ortiz-Zambrano, C\u00e9sar Espin-Riofrio, Arturo Montejo-R\u00e1ez Building a comparable corpus and a benchmark for Spanish medical text simpli cation Construcci\u0013 on de un corpus comparable y un recurso de referencia para la simpli caci\u0013 on de textos m\u0013 Cient\u0013 \u0010 on Rioja Salud 3Unidad de Terminolog\u0013 \u0010a M\u0013 edica, Real Academia Nacional de Medicina de Espa~ na 4Centro de Salud Retiro, Hospital General the collection of the CLARA-MeD comparable corpus, which is made up of 24 298 pairs of professional and simpli ed texts in the medical domain for the Spanish language (>96M tokens). Texts types range from drug lea ets and pairs (149 862 tokens) has been aligned each by 2 experts, with an average inter-annotator score of 0.839 community and contributes with a new benchmark to develop and evaluate automatic medical text simpli Keywords: Comparable corpus. Medical text simpli cation. Biomedical natural language processing. Resumen: Se describe la recogida del corpus comparable CLARA-MeD, formado por 24 298 pares de textos profesionales y simpli cados de dominio m\u0013 edico en lengua espa~ nola (>96M palabras). Los tipos de textos var\u0013 \u0010an desde prospectos m\u0013 edicos y chas t\u0013 ecnicas de medicamentos (10 211 pares de textos, >82M palabras), res\u0013 umenes de revisiones maci\u0013 on sobre el c\u0013 ancer (201 pares de textos, >3M palabras) y anuncios de ensayos cl\u0013 \u0010nicos (5748 pares de textos, 451 690 palabras). alin- eamiento de frases t\u0013 ecnicas realizado a mano por pares de anota- dores. Un subconjunto de 3800 pares de frases (149 862 tokens) se han emparejado, con un acuerdo medio entre anotadores con valor kappa = 0.839 (\u00060.076). Los datos est\u0013 an disponibles en la comunidad y este nuevo recurso permite desarrollar y evaluar sistemas de simpli caci\u0013 on autom\u0013 atica simpli cation is the task of transforming a text into an equivalent which is more under- standable (Saggion et al., 2011). appli- (NLP) 2018), language learn- ing (Petersen and Ostendorf, 2007), users with special reading needs (Barbu et al., 2015) or health literacy (Kindig et al., 2004). Corpus data are required text simpli cation strategies, developing and testing NLP systems. This work introduces Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 189-196 recibido aceptado 27-05-2022 ISSN 1135-5948. DOI 10.26342/2022-69-16 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Naturala new resource made up of documents from the medical domain, which is available at: https://digital.csic.es/handle/10261/269887. 2 Background Text simpli cation order, course of mono- ed) corpora| at present, et Devaraj et (profes- to corpora for the English language (Van den Bercken et al., 2019; Sakakini et et al., 2013), Italian (Tonelli et al., 2016) or French (Grabar and Cardon, 2018; Gala et al., 2020). Other multilingual resources have been released in challenges for complex word identi cation (Yimam et al., 2017) For Spanish, corpus,1 with di erent characteristics compared to the CLARA-MeD text collection. First, the EASIER corpus is a general domain resource; even though some fo- only but fea- tures a sentence-level These data used to enlarge the number of aligned sentences or can annotated in more detail in Several methods applied to col- lect such type of corpora. Wikipedia and Wikipedia have been aligned to ob- tain a parallel corpus in the general do- main (Zhu et al., 2010). However, the correspondence of content between techni- cal/simpli ed versions are often de cient (Xu et al., 2015). Moreover, this method can not be directly extended to languages with- out a simpli ed Wikipedia. In these cases, some teams (Palmero Aprosio et al., 2019; Rauf et al., created Another method ual simpli cation by domain or task which assures lin- guistic but requires an adequate time-consuming. Hybrid meth- ods have also been conducted for glish (Van den Bercken al., 2021). summarizes the comparable resource. We gath- ered readers) from sources recently reported (Moreno-Sandoval et the current stage, we have not used articles from the Medicine category in Wikipedia, given that there is not a Spanish version from Simple Wikipedia. The second stage implied matching pro- fessional and lea ets and summaries of product characteristics The Medicine Online Information Center (Centro de Informaci\u0013 on de Medicamentos, CIMA)2is a drug-related service and knowl- edge database maintained by the Spanish Agency of Medicines and Medical Devices 2https://cima.aemps.es 190 Leonardo Campillos-Llanos, Ana the informa- tion related to drugs prescribed in Spain through a search engine, the Nomenclator re- source (a rich database of medical drugs), and pharmaceutical/pharmacovigilance re- ports. In addition, the information about each medical drug (indication, medical brand, dosage, unit of presentation, is provided in two types of documents: sum- maries of product (written aimed at and terms, and aimed at pa- tients). We downloaded both types of data, and release only cleaned, noise-free texts with both versions available (10 211 texts, 82 907 317 metanal- yses. is the main collection of medi- cal evidence (Sackett et al., 1996), mostly cal trials. Healthcare professionals use this database to keep up to date with the latest evidence to apply in their clinical practice. The Cochrane Library is a multilingual re- source, although not all reviews are available in all languages. Each review presents an ab- stract of the full text and also a summary in plain language, which is aimed at a non- specialist readership. We collected a (9 618 698 words). 3.3 Cancer-related information summaries The National Cancer Institute (NCI) website presents a large volume of bilingual (English and Spanish) information.5Contents revolve texts, the content menus, tables, etc). The cleaned texts level. Clin- ical trials announcements are published both in European language cor- responding to the countries involved in the the public and scienti c ti- tle of the trial, and the public and scienti c indication. To gather these data, we for We also downloaded than 7500 an- nouncements from the website, and selected only those with both a public and scienti c version of the title and/or indication. Af- 3.5 Table 1 includes excerpts of professional and simpli ed versions of each data source. Ta- ble 2 shows the word count of the compara- ble corpus, and Table 3, the average of sen- tences per text and standard deviation, SD). Texts 6https://www.clinicaltrialsregister.eu 191 Building a comparable corpus and a benchmark for Spanish medical text simplification Source Professional version Simpli ed version CIMA La administraci\u0013 on concomitante de metamizol con metotrexato u otros antineopl\u0013 de los particu- metamizole with methotrexate or of particularly in elderly patients.'Si se administra conjuntamente con metotrexato u otros medicamentos para el tratamiento de los tumores (antineopl\u0013 asicos), puede potenciar los efectos t\u0013 oxicos en sangre de los antineopl\u0013 asicos, sobre todo en pacientes de edad avanzada. `If co-administered with methotrexate or other drugs for the treatment of tumors (antineoplastics), it may potentiate the toxic e ects of antineoplastics in the blood, especially in elderly patients.' Cochrane La administraci\u0013 on de suplementos de vitamina D podr\u0013 \u0010a disminuir la necesidad de ventilaci\u0013 on mec\u0013 anica invasiva, pero la evidencia es incierta (evidencia de certeza baja). `Vitamin D supplementation may decrease need for invasive mechanical ventilation, but the evidence is uncertain (low-certainty evidence).'La vitamina D podr\u0013 \u0010a reducir la necesidad de conec- tar a los pacientes a un respirador para ayudarles a respirar, pero se desconoce la evidencia. `Vitamin D may reduce the need for patients to be put on a ventilator to help them breathe, but the evidence is uncertain.' EudraCT Ensayo cl\u0013 \u0010nico aleatorizado, doble ciego, controlado con placebo, para evaluar la e cacia y seguridad de la vacuna COMIRNATY (vacuna COVID-19 ARNm, P zer-BioNTech) en personas con clin- ical trial to evaluate of the COMIRNATY vaccine (COVID-19 mRNA vaccine, P zer-BioNTech) in people with long COVID'El objetivo del estudio es analizar si la administraci\u0013 on de una vacuna contra la infecci\u0013 on COVID19 puede hacer disminuir los s\u0013 \u0010ntomas de COVID persistente. `The aim of the study is to analyze whether the ad- ministration of a vaccine against COVID19 infection can reduce the symptoms of long COVID.' NCI El LH que se diagnostica durante el primer trimestre del embarazo no constituye un indicador absoluto de la necesidad de un aborto terap\u0013 eutico. `HL that is diagnosed in the rst does an absolute indication for therapeutic abortion.'Cuando el linfoma de Hodgkin se diagnostica durante el primer trimestre del embarazo, no siempre signi ca que se aconsejar\u0013 a a la mujer que interrumpa el embarazo. `When Hodgkin lymphoma is diagnosed in the rst trimester of pregnancy, it does not necessarily mean that the woman will be advised to end the pregnancy.' Table 1: Samples of professional and simpli ed versions texts from di erent data sources. from CIMA (drug lea ets and summaries of product characteristics) and NCI (cancer- related summaries) are longer. Professional words per sentence) is generally longer in the professional version of almost all sources (except for CIMA). 3.6 terminologists) matched scienti c and simpli ed versions of speci c sections: the public and scienti c title of the trial, and a public and scienti c indication. We gathered the data from data batch conducted a manual revision. We followed a set of criteria to accept the alignment by extracting, for each professional sentence, the (x3.6.1). the semi-automatic align- ment, we followed the same methodology for two checked texts, all pro- fessional sentences with the amount candidate pairs collected in this way is una ordable to be re- 192 Leonardo Campillos-Llanos, Ana R. Terroba Reinares, Sof\u00eda Zakhir Capllonch-Carri\u00f3n Source Text pairs Professional Simpli ed Total CIMA 10 211 55 463 410 27 443 907 82 907 317 Cochrane abstracts 8138 6 235 454 3 383 244 9 618 698 EudraCT 5748 255 902 195 788 451 690 NCI 201 2 093 569 955 480 3 049 049 Total 24 298 64 048 335 31 978 419 96 022 166 Table 2: Word count per source data of the comparable corpus. Source Professional Simpli ed CIMA alignments. Previous work (Cardon and 2020) has reduced this search space by lever- aging parsing The may tools sentence or the continu- ous similarity analysis model. Another tool al., 2017), computing a TF-IDF-based similarity matrix of items between each pair of texts, a vicinity procedure to professional simpli ed version. We We guidelines of sentences (e.g. identical summarizes medical aspects We aligned a total of represents an almost perfect agreement. 4 Conclusions and future work This work has presented the CLARA-MeD corpus of comparable (professional/laymen) medical texts in contribu- text simpli- tasks. A limitation of our work is the data obtained to train and test data- intensive methods (e.g. deep-learning). More 7https://github.com/lcampillos/CLARA-MeD/ 193 Building a comparable corpus and a benchmark for Spanish medical text simplification 1. We prioritize aligning sentence needs to be aligned with t\u0013 ermino reca\u0013 \u0010da o refractaria indica una enfermedad que vuelve a crecer o no responde al tratamiento (`Follicular lymphoma is a cancer that a ects white relapsed or indicates disease respond to the treatment.') 2. Sentence pairs that only (e.g. preposi- tions or adverbs) are not aligned if the simpli ed version does not have a simpler structure. 3. Simpli ed sentences that have unintelligible acronyms without their explanation or expansion are not desde el colon o el recto (Not aligned) (`CRC is the development of cancer from the colon or rectum') 4. Professional and simpli ed sentences are not aligned if the simpli ed version presents a large loss of essential information that is present in the professional version: P:Tratamiento del s\u0013 \u0010ndrome de Hunter y and cognitive impairment') S:S\u0013 aligned) with incoherent data, imprecise information or contra- between the professional and the simpli ed version: P:Diabetes mellitus tipo 1 (`Type 1 Diabetes Mellitus') S:Altos niveles de azucar (glucosa) en sangre (Not aligned) (`High levels of sugar (glucose) simpli P:Colitis ulcerosa ulcerosa in amatoria intestinal que provoca in amaci\u0013 on en el revestimiento del intestino grueso con irritaci\u0013 on e hinchaz\u0013 on (`Ulcerative Colitis is a type of in ammatory bowel disease that causes the lining of the amed cleaned and revised to be used. More- over, more types of comparable data could be obtained from medical websites with two versions (professional-oriented and patient-oriented contents). In addition to this, the methodology applied by van der Bercken et al. (2019) could be useful to widen the cover- age of Spanish medical texts from Wikipedia, and thus include this source in the cor- 194 Leonardo Campillos-Llanos, Terroba one-to-one correspondence. In a paragraph-level option et com- cation (CWI) tasks. Even so, this is the rst version of a bench- mark for medical text simpli cation in the Spanish language. The high inter-annotator agreement values show a ne sentence-level alignment, which by linguists, a lexicographer and with the advice of a health professional. This ensures that these data are a quality benchmark for developing and test- ing medical text simpli reviewers Martinez- Camara, E., and Urena-L\u0013 opez, L. A. (2015). Language technologies applied to document simpli cation for als corpus corpus parall\u0012 ele \u0012 a partir H. M., Pereira, T. F., Specia, L., Pardo, T. A., Gasperin, C., and Alu\u0013 \u0010sio, S. M. (2009). Building a Brazilian Por- CICLing , 41:59{70. Devaraj, J. J. (2021). Paragraph-level simpli- cation of Javourey-Drevet, T., and Ziegler, J. C. (2020). Alector: A parallel corpus of simpli ed French texts 2020 , page 1353{1361. Grabar, N. and Cardon, R. (2018). CLEAR - Simple corpus for medical French. In Proc. of the 1st Workshop on Automatic Text Adaptation (ATA), pages 3{9. Kindig, D. A., Panzer, A. M., Nielsen- Bohlman, L., et al. (2004). Health literacy: a prescription end confusion. Washing- ton Press. Klaper, D., (2013). Building a German/simple German par- allel corpus for automatic text simpli ca- tion. In Proc. of the 2nd Workshop on Predicting and Improving Text Readabil- ity for Target Reader Populations (PITR 2013), So a, Bulgaria. Martin, L., Fan, A., de la Clergerie, \u0013E., Bor- T., Zhelez- niak, V., Gohil, S., Kor atis, et al. (2021). Towards more patient friendly clinical notes through language models ontologies. In of AMIA Torre-Toledano, D., Valverde-Mateos, A., and Campillos- Llanos, L. (2019). Estudio sobre documentos reutilizables como recursos ling\u007f u\u0013 \u0010sticos en el marco del desarrollo del plan de impulso de las tecnolog\u0013 \u0010as del lenguaje. Procesamiento del Lenguaje Natural, 63:167{170. Paetzold, Alva-Manchego, F., and Spe- M., Negri, M., and Di Gangi Mattia, A. 195 Building a comparable corpus and a benchmark for Spanish medical text simplification Neural Language pages S. E. and Ostendorf, M. (2007). Text simpli cation for language learn- ers: a corpus analysis. In Workshop on speech and language technology in educa- tion. Citeseer. Rauf, Ligozat, and Hamon, T. (2020). automatique de of the 2019 Conference on Empirical Methods in Natural Language Processing, pages 3982{3992. Sackett, D. L., Rosenberg, W. M., Gray, J. M., Haynes, R. B., and Richardson, W. S. (1996). Evidence based medicine: what it is and what it Text simpli cation in simplext: Making Sakakini, T., Lee, J. Y., Duri, A., Azevedo, R. F., Sadauskas, V., Gu, K., Bhat, S., Morrow, D., Graumlich, J., Walayat, S., et al. (2020). Context-aware automatic text simpli cation of health materials in low-resource 11th (2018). simpli- corpus public of LREC 2018, pages 4333{4338. \u0014Stajner, S., Franco-Salvador, M., Rosso, P., and Ponzetto, S. P. (2018). CATS: A tool for customized alignment text simpli (2019). Evaluating text simpli- cation in the medical domain. In Proc. of the World Wide Web Conference, pages 3286{3292. Xu, W., Callison-Burch, C., and Napoles, C. (2015). Problems in current text sim- pli cation research: New data can help. putational Linguistics, of the Int. Conference Recent Ad- vances in Natural Language Processing, RANLP 2017, pages 813{822. Zhu, Z., Bernhard, D., and Gurevych, 2010), pages 196 Leonardo Terroba las tareas 2022 at IberLEF: Overview of the Task onAspect-Based Sentiment Analysis in Portuguese Resumen de la Tarea de An\u0013 alisis de Sentimientos Basado en Aspectos en Portugu\u0013 es (ABSAPT) en IberLEF 2022 Felix L. V. da Silva1, Guilherme da S. Xavier1, Heliks M. Mensenburg1, Rodrigo F. Rodrigues1, Leonardo P. ujo1 2 for Technological Development (CDTec), Federal University of Pelotas (UFPel), Pelotas, RS, Brazil 2Arti cial Intelligence Innovation Hub (H2IA), Federal University of Pelotas, RS, Brazil 3University of S~ ao Paulo, Tarea An\u0013 alisis de Sentimientos basado en Aspectos en Portugu\u0013 es (ABSAPT), realizada en el IberLEF 2022. Les pedimos a los participantes que desarrollaran sistemas capaces de identi car aspectos (AE) y extraer la polaridad (ASC) en textos escritos en portugu\u0013 es. Doce equipos se inscribieron en la tarea, entre los cuales cinco presentaron predicciones e informes t\u0013 ecnicos. El sistema con mejor rendimiento logr\u0013 o un valor de precisi\u0013 on (Acc) de 0,67 para la subtarea de AE (Equipo Deep Learning Brasil) y un valor de precisi\u0013 on equilibrada (Bacc) de 0,82 para la subtarea de ASC (Equipo Deep Learning Brasil). Palabras clave: An\u0013 alisis de Sentimiento basado en Aspectos, Portugu\u0013 es, Rese~ nas de Hoteles. Abstract: This paper presents the task on Aspect-Based of 0.67 Accuracy (Bacc) value of 0.82 Analysis, Portuguese, Hotel Reviews. 1 Introduction Sentiment Analysis (SA) is the eld of valuable information about the consumer's feelings about a par- ticular product or idea, which can help in decisions by companies or governments (Liu, 2015).SA can be done on di sentence level, and as- pect level (de Freitas, 2015). At the aspect level, docu- ment or sentence. erent teams to propose techniques capa- Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 199-205 recibido aceptado 25-07-2022 ISSN 1135-5948. DOI 10.26342/2022-69-17 \u00a9 2022 Sociedad para Lenguaje of extracting aspects and classifying sen- timent of aspects the hotel reviews. The present paper presents an overview of the task. First, we brie y present ysis (ABSA) proposal of our task (Section 3). Section 4 presents the corpora description and the an- notation process. In Section 5, we describe the evaluation Participant systems and the results are discussed in Section 6. Fi- nally, the are done in Section 7. 2 Aspect-Based Sentiment Analysis On this granularity level, opinions any bet- ter understanding of the opinions and entities in the text. To accomplish the analysis on this level, the task used to be broken into for each aspect that has been identi ed in the text. example, in the sentence aspect ` 3 Task People's opinions are a great source of infor- mation for other people and organizations, public or private. Typically works focused on Portuguese perform document level SA. It is hard to nd ABSA approaches or datasets available the identi of aspects in proposes to extract the sentiment orien-tation (polarity) of the review about a aspect it. The availability is scarce, which limits the amount of research done for this language. This task will contribute to the progress of Portuguese NLP, as there is (Pontiki SemEval 2015 (Pontiki et al., 2015), SemEval 2016 (Pontiki et al., 2016) and EVALITA (Mattei et al., 2020) inspired us to develop a speci c task for 2021). corpus is publicly available, so it be used only in (3111 samples from 847 reviews). Corr^ ea's cor- pus is private and will be split into train- ing and test dataset (257 samples to AE and 686 samples to ASC). The full dataset will be available after the event on the website Both annotated same Services Domain Ontology, HOntology The concept hierarchy has a maximum depth of 5. In Figure 1, one can see an overview of the training dataset. The full training dataset contains 77 aspects. Due to space limitation, we present the 40 most frequent aspects and the polarities distribution. In Figure 2, we present an overview of the test dataset. 4.2 Annotation Process The manual annotation of Freitas' corpus (training dataset) was conducted by two an- Felix L. V. da Silva, Guilherme da S. Xavier, Heliks M. Mensenburg, Rodrigo F. Rodrigues, Leonardo P. dos Santos, Ricardo M. Ara\u00fajo, Ulisses B. speakers of Portuguese, one linguist, and computer scientist. And the manual annotation of Corr^ ea's corpus (training and test dataset) was conducted by twelve students and professors of computer science and engineering annotators. Bothused the tool developed in the The annotators (Fre- itas' corpus) was measured with Koch, 1977). The an- notators agreement about ABSA from do- ABSAPT a moderate value. It is also im- portant to note that only in a few cases the annotators disagreed between negative and positive polarities, the was about polar- neutral on April 08th, and participants had sixteen days to train their systems. The test set was released on April 24th, and each participant had submit run. Participating teams will receive training and test datasets. The latter was sent with- out the label of rank competitors. according registered the techni- cal reports. Participants are from universities Felix L. V. da Silva, Guilherme da S. Xavier, Heliks M. Mensenburg, Rodrigo F. Rodrigues, Leonardo P. dos Santos, Ricardo M. Ara\u00fajo, Ulisses B. Corr \u00eaa, UFPR), and deep learning methods as Trans- formers (Team Deep Learning Brasil, Team PiLN, and Team UFPR). Tables 1 and 2 present submitted run. each system, best run is highlighted in bold. Team Deep Learning Brasil, used transformers to achieve an Acc of 0.67 in AE and a Bacc sentence tagging approach, and the ASC tested with two di er- ent strategies, one as a Sentence Pair Classi cation and the other as a Con- Trans- PiLN: The authors simple and 0.76, 0.78 error analysis of and non-detected aspects Pardo, and a pre-trained for Portuguese was used the POS Tagging process. If the Tagging process has a bet- ter adaptation for Portuguese, there a gain in results the CRF perfor- mance. In the pro- posed worst run, 7 Final Remarks Motivated by the necessity of improvements in the ABSA task focused on Portuguese, we proposed a task within the IberLEF 2022. This paper overviews the rst task on ABSA in Portuguese to identify and extract the polarity in hotel The and test) have manually annotated. The inter-annotator ABSAPT 2022 at IberLEF: training and dataset is considered moderate. Team achieved a Bacc of 0.67 for the AE and Acc of 0.82 for the ASC, while the UFSCAR Team achieved a Bacc of 0.59 for the AE and Acc of 0.62 for the ASC. Acknowledgments Thank you to all annotators for their essen- tial work. We gratefully acknowledge the support of NVIDIA Corporation with the do- nation of the Titan X Pascal GPU used for this research. This work was nanced in part by the following Brazilian research agencies: CAPES and CNPq. References Assi, F. M., G. B. Candido, L. N. dos Santos Silva, D. F. Silva, and H. de Medeiros Caseli. 2022. Ufs- car's with the Spanish Society for Natural Lan- guage Processing (SEPLN 2022), Online. CEUR.org. Chaves, M. S., L. A. de Freitas, and R. Vieira. 2012. Hontology: A multilingual on- tology for the accommodation sector in the tourism industry. In J. Filipe and J. L. G. Dietz, editors, KEOD, pages Universidade Sul, Porto Alegre. Demszky, D., D. Movshovitz-Attias, J. Ko, A. Cowen, G. Nemade, and S. Ravi. 2020. GoEmotions: A 76(5):378{382. Gomes, J. R. S., R. C. Rodrigues, E. A. S. Garcia, A. F. B. Junior, D. F. C. Silva, and D. F. Maia. 2022. Deep learning brasil at absapt 2022: Portuguese with the 38th Conference of the Spanish Society for Natural Language Processing (SEPLN 2022), Online. CEUR.org. Heinrich, T. and Conference of the Spanish Society for Nat- ural Language Processing (SEPLN 2022), Online. CEUR.org. Landis, J. R. and G. G. Koch. 1977. The measurement of observer agreement for categorical data. and Emotions . Cambridge University Press. Machado, M. T. and T. A. S. Pardo. 2022. Nilc at absapt 2022: with the 38th Conference Felix L. V. da Silva, Guilherme da S. Xavier, Heliks M. Mensenburg, Rodrigo F. Rodrigues, Leonardo P. dos Santos, Ricardo M. Ara\u00fajo, Ulisses B. Cor r\u00eaa, Larissa A. de Freitas Spanish Society Lan- guage Processing (SEPLN 2022), Online. CEUR.org. Mattei, L. D., G. D. Martino, A. Iovine, A. Miaschi, M. Polignano, and G. Ram- Cam- Natural Language and Speech tools for Italian (EVALITA 2020), Online. CEUR.org. Neto, F. A. R., R. F. de Sousa, R. L. de S. Santos, R. T. Anchi^ eta, and R. S. Moura. 2022. Piln at Lex- 38th Conference of the Spanish Society for Natural Language Processing (SEPLN 2022), Online. CEUR.org . Pontiki, M. Apid- ianaki, X. Tannier, Kotelnikov, Bel, S. M. Jim\u0013 enez- Zafra, and G. Evaluation Linguistics. Pontiki, M., D. based sentiment analysis. In on Se- mantic Evaluation (SemEval 2015) , Linguistics. IberLEF: of Aggressive and Violent Incidents from Social Media in Spanish Resumen de la Tarea DA-VINCIS en IberLEF 2022: Detecci\u00b4 on de Incidentes Violentos en Redes Sociales en Espa nol Luis Joaqu\u00b4 n Arellano1, Hugo del Lenguaje (INAOE), Mexico. 2Centre de Recherche GRAMMATICA (EA 4521), Universit\u00b4 e d'Artois, France 3Mathematics Research Center (CIMAT), Colegio de M\u00b4 exico (COLMEX), Mexico 2022 task, orga- nized at IberLEF 2023 and co-located with the 38th International Conference of the Spanish Society for Natural Language Processing (SEPLN 2022). DA-VINCIS chal- lenged participants to violent events mentioned in social networks. We released a novel corpus collected from Twitter and manually labeled with 4 categories of violent incidents (plus the no-incident label). The shared task focused on the Mexican variant of Spanish and it was divided into two tracks: (1) a binary classification task in which users had to determine whether tweets were associated to a violent incident or not; and (2) a multi-label classification task in which the category of the violent incident should be spotted. More than 40 teams registered for the and the final phase. Very both best results. Corpora and results at DA-VINCIS, violent event detection, text classification. Resumen: Se presenta el resumen de la tarea DA-VINCIS 2022, organizada en IberLEF 2022 junto a la 38 \u00aaConferencia Internacional de la Sociedad Espa nola para el Procesamiento del Lenguaje Natural (SEPLN 2022). DA-VINCIS plantea el reto de detectar autom\u00b4 aticamente piezas de informaci\u00b4 on en redes sociales que est\u00b4 en asociadas a eventos violentos. Se liber\u00b4 o un nuevo corpus para el Espa nol Mexicano que fue etiquetado manualmente con 4 categor\u00b4 as de eventos violentos (adem\u00b4 as de la categor\u00b4 a no-violento). Se propusieron dos subtareas: (1) una tarea de clasificaci\u00b4 on binaria donde se buscaba distinguir tuits asociados a eventos violentos del resto; y otra (2) donde se buscaba identificar la categoria del evento violento. M\u00b4 as de 40 participantes se registraron en el portal y 12 enviaron resultados para la fase final. Los resultados obtenidos fueron muy competitivos para ambas tareas; las soluciones que obtuvieron los mejores resultados se basaron en modelos tipo transformer para el espa nol. El corpus y los resultados detallados pueden consultarse en el sitio web de la tarea: https://codalab.lisn.upsaclay.fr/competitions/2638. Palabras clave: DA-VINCIS, Detecci\u00b4 on de eventos violentos, Clasificaci\u00b4 on de tex- tos. Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 207-215 recibido aceptado 25-07-2022 ISSN 1135-5948. DOI 10.26342/2022-69-18 \u00a9 del Lenguaje Natural1 Introduction Violence has obvious negative effects on those who witness or experience it, im- pact for governments, as they are in charge of security to tracking vi- olence comprise a the detection moni- toring of violent events, as people very often post publications notifying the occurrence of violent events in real time. This represents an important opportunity for IT researchers that can provide solutions based on natural language processing for the timely detection of violent incidents in social networks. Solu- tions this kind could be used by authorities to respond more efficiently to events happen- ing in time, to develop crime preven- tion policies according to such solutions would be very helpful to the population, as one could know what violent events are hap- pening in which zones in real time. We organized a shared task collocated with IberLEF2022 called DA-VINCIS. This task focused on the detection of violent inci- on a violent event or not. For this first edition, the shared task targeted Spanish in its Mexican variant. This is motivated by the lack of resources in Spanish for approaching the task, and the fact that Mexican Span- ish is the most spoken variant of this lan- guage1. We released carefully pro- vided to participants for both tracks for the development of their solutions, and unlabeled data was used for the final evaluation of the corresponding tracks. As far as we know, this was the first shared-task aiming at detecting violent events from social media. This is an issue that has received little the number of native speakers.was to motivate research on a topic little ex- plored in Spanish, but with great potential impact for the whole population and authori- implicit goal raise of Spanish, the ambiguous language inher- ent to Twitter, the high class imbalance ra- tios present in our datasets, among others. We are confident that the shared task will give rise to novel solutions that could be used in the near future for applications of societal impact, for example, generating real-time oc- currence crime maps. Last but not least, we plan to release the associated corpus in the near future so that the community can keep working on it even at the end of the shared task. The remainder of this paper is organized as follows. Section 2 describes the shared task Then, Section 3 introduces the DA-VINCIS corpus. Section outlines 2 description As previously mentioned, the inci- dents from those that are not; and (2) a task that challenged participants to identify the type of violent incident (if any) being re- ported in tweets. The categories considered for the latter The DA-VINCIS corpus, in de- next used for the eval- uation of both subtasks. The challenge was run in the CodaLab platform (Pavao et al., 2022). The shared task was divided into two stages as follows: Development phase. Participants were with labeled able for the set and receive immediate feedback in the Co- daLab site. Final phase. Participants were pro- vided with unlabeled test data. They were able to upload up to five submis- Luis Joaqu\u00edn Arellano, Hugo Jair Luis Fernando 2016)Theft, Crime, Theft with violence, Theft walking, Theftin 2019)Robb ery Theft fraud, on to participants. For subtask 1, recall, precision and f1 score with respect to the violent-incident class were considered as evaluation measures. For subtask 2, macro average recall, precision and f1score were considred. In both cases, the leading evaluation measure was that of f1 score. 3 DA-VINCIS corpus The DA-VINCIS corpus is a collection of tweets2associated to reports of violent inci- dents in Mexican Spanish. The aim of this novel corpus is to boost research in the au- tomated detection and monitoring large to Then, the tweets filtered, and a subset of these was manually labeled. In the remain- der of this section we provide details on the construction of this corpus. A set of categories of violent incidents was defined after a careful analysis of relevant literature, see Table they are finally the criteria of the research group involved. 2Please note that the corpus is formed by both, the text in tweets and their associated images, if any, for this shared task only textual information was con- sidered.The categories considered in the DA- VINCIS corpus are shown in the last row of Theft generic that appeared most frequently among in Twitter accounts associated local in Mex- ico (e.g., Kidnapping ). Finally, our each category. It is important to mention that since the long term goal of this project is the real- time monitoring of violent incidents, the Ac- cident category account. authorities use the same com- munication channels to deal urgent to prevent them. However although there are the internet, these are not frequent, in addition to the fact that these are common topics of conversation and discus- sion, therefore are shown in the retrieval vi- olent incidents tweets, a research work was carried out where 30,000 tweets published in news accounts in Spanish were recovered, 5,000 tweets were manually tagged to iden- tify if news was violent (i.e. binary la- beling) once established, an ML model was applied to label the rest of the corpus, the pseudo labels obtained were used to study the bigrams and tri- grams that provided most information the classification, the most significant words from the top-100 were filtered, these were the keywords used to search for tweets of violent incidents. Once the were obtained, a retrieval was performed using each of the lected keywords, where it was required that (1) tweets had an associated image, (2) lan- guage was Spanish and, (2) the tweet was ge- olocated in approximation to Latin America. The result of this process were 8000 tweets that were of and Violent Incidents from Social in Spanish 209Category Definition Ac cident Even tual event or action that results in involuntary damage to people or things. Homicide Depriv ation of Theft Seizure or willful destruction of someone else's property without the right and without the consent of the person who can legally Depriv ation of liberty. there is ported. Table Definition of the categories consid- ered in the DA-VINCIS corpus. that could no longer recover any of their ele- ments, that were written in a language other than Spanish but that were filtered in the search and the empty elements or that only consisted of a series of filtered dataset text of the tweet and the as- sociated images, if any. However, even having all available, the label- ing process was straightforward cases. Sometimes the images were conducive to confusion or vice versa. example, con- fusing a traffic accident with a homicide with car (cyclist hit assigned the correct label, there were some samples that could be considered noisy, see Section 4. Table 4 shows the pro- portion of samples per class in the dataset. Please note that since categories are not nec- essarily disjoint (except the no-incident one). More than one label can be assigned to a sin- gle tweet, that is why the total number of labels is different from 5000. To analyze the difficulty of the task, the agreement between the annotators was cal- culated. Table 5 noisy annotations, Section 4, evidencing the for the DA- corpus.4 Participants approaches and results In the following subsections we describe the main ideas addressed by the different partici- pants, and present a general analysis of their results. 4.1 Systems' descriptions A total of 12 ad- dressed the subtask 1 and one team only pre- sented a solution for subtask 2. Something interesting to highlight is that the teams with the best performance in each of the two subtasks presented a proposal have their own spe- cific challenges and, therefore, that it is not always convenient to approach them using the same strategy. From the different solutions presented at the DA-VINCIS shared task, we found sev- eral coincidences, which indeed align with some general trends Natural Language Processing. The main shared aspects corre- to take advantage of all the knowledge encoded in their pre- training. Some applied the traditional fine-tuning (Ta et al., 2022; Ta et al., 2022b). On the other hand, some approaches used the pretrained transformer as a frozen the instances and task description using a Prompt-based framework (Qin et al., 2022). Ensembles: Multiple approaches em- ployed ensembles to take advantage of variations of solution mod- els. For the Joaqu\u00edn Arellano, Jair Escalante, Luis Villase\u00f1or-Pineda, Manuel Montes-y-G\u00f3mez, Fernando Sanchez-Vega 210Categories Accident #Ahora Reportan accidente de tr\u00b4 ansito en el ingreso al municipio de Salcaj\u00b4 a. Dos veh\u00b4 culos tipo picop involucrados en el percances. Precauci\u00b4 on al conducir por el sector. Ampliaremos la informaci\u00b4 on. #Stereo100Noticias#Now Car accident is being reported extend information #Stereo100Noticias Homicide La violencia y las ejecuciones contin\u00b4 uan cada d\u00b4 a en la CDMX un hombre fue ejecutado a 2 calles de la alcald\u00b4 a de Cuahut\u00b4 emoc en la calle de everyday in two blocks from Cuahut\u00b4 emoc town hall in Pedro Moreno street Theft Im\u00b4 agenes en las que un sujeto que ingres\u00b4 o a robar a un local ubicado en Av.Tonal\u00b4 a y Madero en la Cabecera Municipal. El hom- bre iba armado y despu\u00b4 es del robo huy\u00b4 o en un auto Kia color gris que lo esperaba afuera del local.footage in which a subject that entered to steal a facility in Av. Tonal\u00b4 a and Madero in the municipality. The man was armed and after the robbery escaped in a grey Kia that was waiting outside the facility. Kidnapping Secuestraron a sujeto frente al palacio mu- nicipal de Coatzacoalcos A plena luz del d\u00b4 a realizan acto delictivo; los detienen y desarticula UECS banda de plagiarios reci\u00b4 formada; se quedan el Cereso Du- port Osti\u00b4 onA man was kidnapped in front of Coatza- coalcos' town all. The criminal act was perfored during daylight; they were ar- rested and the UECS a band of kidnappers just formed; they Table 3: from categories. Monta n\u00b4 es-Salas, Hoyo-Alonso, ensemble learning (Garc\u00b4 a-D\u00b4 az et al., 2022), and a kind of multilevel fusion that incorpo- rates information from multiple sources (Qin subtasks and 2 to carry out some of learning. 2 that is jointly learned in order to incorporate additional information for subtask 1. In contrast, in (Ta et al., 2022b) the predic- tion of each class 5 judgments are shown). formed with MTL on the complete to distinguish real instances from instances generated by a GAN. (DA) was also del Alonso, and Pe na-Larena, Ta et al., 2022b; Ta et al., 2022a), however, some approaches also integrated the ex- amples in the intermediate languages to the augmented data, and models in their train- ing 2022). Preprocessing : operations of and Violent Incidents from Social Media in Spanish 211models to handle the in (Garc\u00b4 et al., 2022). Three approaches show some interesting features that do not fit 2022) carried out a rela- belling process of the training data con- sidering the votes of 5 systems learned from the original noisy data set. They \"corrected\" the instance labels if at least 4 of the 5 systems agreed to do so; using this approach they modified around 5% of the Linguistic et use of a variety of features with the purpose of taking into account multiple the tweets. of 2022) employed a prompt learning module to inject information from a pre-trained language model into the violent event category recognition task. approach incorporates subtask identification incidentes. The teams are sorted by their F1-score over the positive class (i.e., the violent incident class); Precision and Recall are also reported to al- low a better interpretation of these results. At the bottom it is included our baseline3 3Please note that during the final phase of the shared task we uploaded a single run of the baseline that obtained better results. However, in this paper we report the average over 10 runs of the performance of the baseline, which is a more reliable estimate to the Preci- Recall and F1 score in the positive class. result, which corresponds to the direct use of a traditional fine-tuning (i.e., using a sin- gle linear layer and use of softmax for classification) of BETO (Ca nete et al., 2020), a well-known pre-trained language model in Spanish. The best performance in Subtask 1 was obtained by the CIMAT team 2022) followed by VICOMTECH (Tur\u00b4 on et al., 2022) These two approaches have in com- mon that they took advantage of both for subtask 1 some in- formation from subtask 2. The approach (Monta n\u00b4 es-Salas, del Hoyo-Alonso, and similarly CIMAT team, used an ensemble of multiple transformer-based mod- els. the one hand, the CIMAT approach output of three simultaneously learn the subtask 1 of a violent event subcategory classification (i.e., each model is different in the specific event subcategory chosen). On the other diversity the models and not from the data. It should be noted that the different ap- proaches obtained very close results; the best performance is only 6.8% greater than the lowest, and the standard deviation of the set of F1-scores is only 0.015. The results obtained by the event category recognition, are shown in Table 7. The best performance in this subtask corresponds to the GDUT Luis Joaqu\u00edn Arellano, Hugo correspond to the macro average values of Precision, Recall and F1 score. team. Their semantic relations be- text instances and the name of the categories through the application of a Prompt learning module. The second and third best performances were obtained, as in subtask 1, by the VICOMTECH (Tur\u00b4 on et al., 2022) and ITAINNOVA (Monta n\u00b4 es- Salas, del Hoyo-Alonso, and Pe na-Larena, 2022) teams, respectively. Their adequate both tracks suggests the rele- vance and robustness of these two approaches for the task addressed. From the results, it is notorious that sub- task 2 is much more challenging than sub- task 1; something expected due to the high imbalance in some of the categories. This is reflected in a greater standard deviation (0.051) the reported F1-scores, and also between the and worst reported results (in this case, the for- mer is greater than the later). 4.3 provide insights calculated for the 11 Table 6. This index indicates how diverse the errors of each model are with re- spect each other if one would build an indicating diversity (the range of values of CFD is [0,1]), that could be ex- ploited for building a more robust model. On the other hand the maximum possible accu- racy (a tweet is counted as the 11 uate solutions. In order to illustrate the inherent difficul-ties of the shared task, Table 8 shows ex- amples of tweets that were are tweets wrongly labeled by the annotators, for problem highlighted by participants during the challenge (Tur\u00b4 on et al., 2022). Secondly, there are tweets for the an accident happening in the context of an F1 race, it is an accident, but not really relevant for the purpose of the project. Also, tweet 1 refers to a report associated to several violent events happening in different places (we hypothesize this is why it was labeled as Non-violent). Summarizing, a large portion of samples missclassified the could be corpus is a valuable resource that will boost research in this relevant task. 5 Conclusions The DA-VINCIS shared task at IberLEF motes research the identification of vi- olent incidents on social networks, a task with a high social impact. A new dataset for the task of identification of violent in- cidents well as diversity approaches and contrast their effective- ness. Different models, characteristics and techniques of the proposed approaches were presented, contributing to the progress of the identification of violent incidents in Spanish language. The results indicate, as might be ex- pected, that the fine-grained challenging. A strong presence of ap- proaches based on transformers was found, but also there was a vitalizing variety of pro- posals with important novelties such as application of GANs, the automatic correc- tion of instances, and the use of non-learning tools to act as a kind of oracle, all of them introduced to improve the methods' perfor- mance to deal the specific chal- lenges of the task at hand. It was found that having some informa- tion on the subcategory of the general class of interest seems to help to make a better at IberLEF 2022: Detection of Violent Incidents from Social Media in Spanish 213ID Translation Text Category Intense police A member kidnapped person was killed when trying to impede this crime. In Jilotepec was found the vehicle where the person was abducted SPVeracruzUna fuerte movilizaci\u00b4 on policiaca se registr\u00b4 o en el municipio de Coacoatzintla ante el pre- sunto secuestro de un joven. Al tratar de im- pedir el hecho, un familiar fue asesinado. En Jilotepec fue hallado el veh\u00b4 culo en el que se cometi\u00b4 o el il\u00b4 cito SP Ver acruzNon-violen t 2 30y ears now from the Cimitarra massacre, a violence act that left more than 250 thousand deaths turning Colombia into a a huge com- mon grave.A30 a nos de la masacre de Cimitarra, una vi- olencia que dejo m\u00b4 as de 250 mil muertos con- virtiendo a Colombia en una gran fosa com\u00b4 un.Violen t 3 Homicide - In a clinic at #Cartago Bibiana Liseth Guzm\u00b4 an Ord\u00b4 o nez, and of- ficial of the @ipscartago, died, after she was shoot with a firearm. In the same incident a 26 years old man was hurt. The women left a daughter.Homicidio - En una Bibiana Liseth Guzm\u00b4 an Ord\u00b4 o nez de 31 a nos de edad, funcionaria de la @ipscartago luego de que le propinaran varios impactos con arma de fuego. En este mismo hecho result\u00b4 o lesionado un hombre de 26 a nos. La mujer deja una hija.Non-violen t 4 \"The acciden t could have been avoided if they would leave me enough space to take the curve. You need of two persons for this to work, and I felt they throw me away. When we challenge to each other in a race this things can happen, unfortunately.\"\"Elacciden te se pudo haber evitado si me hu- bieran dejado espacio suficiente para tomar la curva. Necesitas 2 personas para que esto fun- cione y yo sent\u00b4 que sacaban. Cuando nos re- tamos mutuamente en una carrera estas cosas pueden pasar, desafortunadamente.\"Violen t Table 8: Examples Learning is strongly po- sitioned as a good alternative that improves performance and takes advantage of the par- allelism between subtasks 1 and 2. These findings open the possibility that other fu- ture approaches could use virtual subtasks with different fine grain levels in order to take advantage of this type of scheme. Likewise, an in depth analysis of the cor- pus revealed that there is room for improve- ment in terms of the quality of annotations. corpus also comprises of studying the potential value using images associated when detecting violent incidents. The corpus will allow us to study the performance of solutions that con- sider multimodal information. Acknowledgements This work was supported by under grant CB-S-26314, Integraci\u00b4 on de Lenguaje mediante Multimodales Aprendidas to thank under grant CB- 2015-01-257383. Additionally, the authors thank CONACYT for through the INAOE Supercomput- ing Laboratory's Deep Learning Platform for Language Technologies. References Ca nete, J., G. Chaperon, R. Fuentes, J.-H. Ho, H. Kang, and J. P\u00b4 erez. 2020. Span- ish pre-trained bert model ICLR 2022), Mata Rivera, M., M. Torres-Ruiz, G. Guzm\u00b4 an, R. Quintero, R. Zagal- Flores, M. Moreno, and E. Loza. 2016. A Mobile Information System Based on Crowd-Sensed and Official Crime Data for Finding Safe Routes: A Case Study of Mexico City. Mobile Information Systems, 2016:1-11, 03. Luis Joaqu\u00edn Arellano, Hugo Jair Escalante, Luis Villase\u00f1or-Pineda, Manuel Montes-y-G\u00f3mez, Fernando n\u00b4 es-Salas, R. M., del Hoyo- Alonso, and P. Pe na-Larena. 2022. ITAINNOVA@DA-VINCIS: A Tale of Transformers and Simple Optimization In of Bar\u00b4 o, H. Escalante, S. Escalera, T. Thomas, and Z. Xu. 2022. CodaLab Competitions: An open source platform to organize report, Universit\u00b4 e Pi a, C. and Ram\u00b4 rez-Ram\u00b4 rez. 2019. Exploring crime patterns in Mex- ico City. Journal of Big Data, 6, 07. Qin, G., J. He, Q. Bai, N. Lin, J. Wang, K. Zhou, D. Zhou, and A. Yang. 2022. Prompt Based Framework for Violent Event Recognition Twitter Posts. 2020 International Conference on Decision Aid Sciences and Application (DASA), pages 1000-1004. Ta, H. T., A. B. S. Rahman, L. Naj- jar, and A. Gelbukh. Social of the Iberian Forum (IberLEF 2022), CEUR Workshop Pro- ceedings. CEUR-WS.org. Ta, H. T., A. B. S. Rahman, L. Najjar, and A. Gelbukh. 2022b. Multi-Task Learning for Detection of and Violent tion of Aggressive and Violent Incidents from Social Media in Spanish using Pre- trained Language Model. In Proceedings N. Perez, A. Garc\u00b4 a-Pablos, E. Zo- tova, and M. Vi- at DA-VINCIS: Detection of Ag- gressive and from So- in In Proceedings of the Iberian Leveraging Events Incidents Spanish 215216Overview of DETESTS at IberLEF 2022:DETEction and classification of racial STereotypes in Spanish Resumen de la tarea de DETESTS en IberLEF 2022: DETEcci\u00b4 on y clasificaci\u00b4 on de eSTereotipos raciales en eSpa nol Alejandro Ariza-Casabona1,, Wolfgang S. Schmeisser-Nieto1,, de Barcelona, Spain 2Research Group in NLP and IR, Universidad Nacional de Educaci\u00b4 on a Distancia, Spain 3PRHLT Research Center, Universitat overview of the DETESTS shared task as part of the IberLEF 2022 Workshop on Iberian Languages Evaluation Forum, within the framework of the SEPLN 2022 conference. We proposed two hierarchical subtasks: For subtask 1, participants had to determine the presence of stereotypes in sentences. For subtask 2, participants had to participate, of which 39 sent runs, and 5 of them sent their working notes. In this paper, we provide information about the training and test datasets, the systems used by the participants, the evaluation presenta un resumen de la tarea DETESTS como parte del workshop IberLEF 2022, dentro de la conferencia SEPLN 2022. Proponemos dos subtareas jer\u00b4 arquicas: En la subtarea 1, los participantes tuvieron que determinar la presencia de estereotipos raciales en oraciones. En la subtarea 2, de las oraciones etiquetadas con estereotipo, los participantes tuvieron que clasificarlas en una o m\u00b4 as de diez categor\u00b4 as. El dataset DETESTS contiene 5.629 oraciones de comentarios que responden a art\u00b4 culos de peri\u00b4 odicos sobre inmigraci\u00b4 on en espa nol. 51 equipos se registraron para participar, de los cuales 39 enviaron predicciones de sistemas y 5 de ellos enviaron art\u00b4 culos. En este art\u00b4 culo presentamos informaci\u00b4 on sobre los datasets de entrenamiento y de prueba, los sistemas utilizados por los participantes, las m\u00b4 etricas de evaluaci\u00b4 on y sus resultados. Palabras clave: y on de focuses comments in Spanish in response to online news articles. The present These authors equally to this work.task evant and relatively novel area of research due to its impact on modern society. Fur- thermore, for comparing the application of deep learning and classical machine learn- ing models to Spanish stereotyped expres- Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 217-228 recibido aceptado 31-07-2022 ISSN 1135-5948. DOI 10.26342/2022-69-19 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Naturalsions under the recently introduced learning with disagreements paradigm (Basile al., 2021; Uma et al., 2021). The following sections of this paper de- scribe the key aspects of this task. Section 2 offers a background on what is understood as stereotypes and the related work on Nat- ural Processing Section both proposed subtasks. Section 4 describes the DETESTS corpus, test datasets and the annotation process. Section 5 presents the systems clusions and draws some lines for future work. 2 Background One of the components that reinforces toxic and hateful speech is stereotypes. cru- cial to tackling this expressed explicitly. The pres- ence of stereotypes on social media and the need to identify and mitigate them is driv- ing the development of systems for au- tomatic detection, especially in news com- ments. Therefore, a new task that is attracting growing interest from the NLP community. A stereotype is defined in social psychol- ogy as a set of beliefs about others who are perceived as belonging to a different social category. The stereotype oversimplifies the group and generalizes a characteristic, apply- ing it to all its members (Allport, Clark, and Pettigrew, 1954). The common assumption in social psychology literature is that some of the behavior toward others degrees to implicit, thereby becoming a complex con- cept when they must be operationalized for natural language processing. In order to nar- row down this concept, we considered some criteria for deciding whether a national or the first cri- terion to observe is whether there is a ho- mogenization of the target group in the com- ment. Homogenization involves a process of the generalization of a feature to the status of a social category, which negates individualdiversity (Tajfel, Sheikh, and Gardner, 1964; In a second criterion, stereo- in language through sev- eral acts, which can ex- and manifest, or implicit, which means that a process of infer- and classification have been carried out, in which specific social groups, e.g., women and immi- grants, have been the focus of research, since they are usually the target of such messages. For instance, Automatic Misogyny 2018) a subtask in which one of the categories of misogyny is Stereotype and Objectification understood as a fixed and oversimplified image or idea of a woman. Last year's IberLEF 2021 edition task EX- IST studies of microportraits in Muslim stereotyping in which a description of the tar- get group is provided in a single text (Fokkens et al., 2019). Sap et al. (2020) approach the problem of stereotypes for several tar- get groups in the Social Bias Frame, a new conceptual formalism that aims to model the pragmatic frames in which on the identification of immigrants, Muslims and Roma (Sanguinetti et al., 2020). Narrowing down on the topic of immigration, S\u00b4 classi- applied in this task is based on work but uses a corpus extracted from comments authored web racial stereotype based on origin, ethnicity, race and religion is associated with a target group. 3 Task Description The aim of the DETESTS task is to detect and classify stereotypes in sentences Alejandro 218comments online related to im- sentence to different cat- egories and, therefore, it may have multiple labels that need to be accurately detected. This scenario is in classification problem. However, interests, the task is designed in chaining two model the binary scenario or of labels provided by the annotators. The gold standard of this subtask is left as a proxy to determine the subset of sentences that will be evaluated in the posterior For subtask, we SemEval 2021 Task 12 (Uma et al., 2021), in which the authors state that there does not necessarily exist a single gold standard for every sample the ten that 'cultural that take advantage 'benefits', a problem for to 'dehu- manization' and 10) 'other' types Since sentence can contain stereotypes belonging 24% of them con- taining stereotypes. It is made up of two parts -one from the NewsCom-TOX corpus (Taul\u00b4 e et al., 2021) (3,306 sentences) and the other the StereoCom corpus (2,323 sentences), which was created especially for Both of comments published in response to different articles from Spanish online newspapers and discussion eame1). of the articles range from August 2017 to Au- gust 2020, while in StereoCom they range from June 2020 to November 2021. the NewsCom-TOX corpus, number of published comments (minimum 50 comments per article). Since the NewsCom- TOX corpus was designed primarily to study toxicity and not stereotypes, we used only the part of the corpus with the highest per- centage of stereotypes, which had to a suffi- cient and balanced data volume in terms of the presence or absence of stereotypes, the same content was also corpus, i.e., comments in response to immigration-related news items in Spanish digital media, selected by subject matter on the basis of a keyword search. The comments were presented in the same order in which they appeared in the tempo- ral web thread, along was to which every sentence belongs and its position within the comment are indicated. The default dataset includes the gold annotation. If the to learning with disagree- ments, we will provide, upon request, the pre- dataset to indicate the presence or absence of stereo- types and the category/ies of the stereotype which they belong. Moreover, we an- notated extra features that could help the participants to train their systems. Since more than one stereotype corresponding to different categories can appear in sen- is a multi-label task. We based our categories on the work pro- posed by anchez-Junquera there was at least one stereotype re- lated to a target group. Stereotype: There is a process of homoge- nization of one characteristic of an individual or part of a group that is applied to the entire group based on their place of origin, ethnic- ity or religion. Stereotypes can be expressed of xenophobia and discrimination. Suffering Victims: are as victims of poverty and violence in their places ori- gin, and as having to face difficult situations in their host countries. Economic Resource: The members of the target group are seen as an economic re- source. They do the jobs that locals do not want to do, pay taxes, and solve problems arising presents a threat due to massive influxes and a lack of control at the borders. Immigrants are illegal and they should be expelled. It is seen as an invasion. Cultural and Religious Differences: The major threat loss 2https://detestsiberlef.wixsite.com/detests/tasksingroup's values and and the should to their host country. Benefits: The target group competes with the ingroup for resources such as public sub- sidies, school places, jobs, health care and pensions. There is a perception of the tar- get group being priveliged over the ingroup. Public Health: sues. Due crease in crime, domestic violence, robbery, drug use, and public disorders. Dehumanization: The members of the target group are seen as inferior beings and are compared with animals, parasites or scum. Their have less value than those of the ingroup. Others: Any other that is not tated with three other labels that may pro- vide extra features at the disposal of the par- ticipants to use to sys- tems. These additional labels are: Racial target: The target group is defined by place of origin, ethnicity or religion. Other target: The target group corre- sponds to other minorities or oppressed groups based on gender, sexual orientation, physical or mental conditions age, others. Implicitness: This category or explicitly. 4.2 Annotation Process Once had defined what we understand by stereotypes, which categories we can observe in our data, and in which ways they can be manifested in texts, we drew up annotation guidelines for the annotators. The annotation process consisted of two stages. In of the Alejandro Ariza-Casabona, Taul\u00e9, of stereo- types. Then, disagreements were discussed by the annotators and a senior annotator was reached. team of in of an inter-annotator agreement (IAA) test was performed once all the sentences had been annotated. As shown in Table 1, overall, high Fleiss' of 0.139. This may be due to the scarcity of data correspond- ing to that feature, since the average pair- wise % agreement is still one of the highest. A similar case, although with higher results, can be observed for the category It worth noticing as that the of stereotypes with less correlate the the distribution Datasets Participants were provided with 70% of the corpus to train and validate their models on (3,817 comments) and the remaining 30% of the corpus (1,812 comments) was used as a test set to evaluate performanceagainst unseen sentences3. In order NewsCom-TOX cor- pus released in the DETOXIS shared task, all test sentences were extracted from the newly added StereoCom corpus in a stratified man- ner to keep a similar label distribution to the one found in the training set. Note that, de- spite the fact that the training gold standard categories (see Sec- in the test set, which merely includes com- sentence of the sentence it replies any), type of stereotype. Table 2 shows the category distribution for the subset examples that are of 5,629), that is, 24.14% of the whole corpus. It is important to mention that, given the multi-label nature of may stereotypes belonging to in the togram and a brief description of the proposed as well as an overview of the by the participants, a regarding their intellectual property rights (IPR), a password to the data sent pri- vately to each participant who was after filling in a registration form. This dataset will only be Spanish 221Figure 1: Multi-label distribution. task, and a short analysis of their multi-label capabilities. A Github repository is certain performance in both subtasks, five different baselines have been considered as reference subtask consists of a hierarchical multi-label classification task, we have extended these baselines in archical fashion by sentence contains one of new baseline classifiers is trained upon those positive cases to to Analogously to AllOnes, this baseline instances negative class. Therefore, this baseline is only consid- ered in subtask 2 in which the negative class is actually accounted for by the evaluation metrics. RandomClassifier: proba- bilities based on the label distribution learnt from the instances with FastText+SVC: This baseline replaces classical TF-IDF vectorizer with a vector extractor based on as of this baseline. All baselines have been implemented us- from 39 1, five of these teams decided to tackle sub- task 2 as well. Participants to to Among the top-performing systems, we ob- serve an extended use of pre-trained language models for the Spanish language including both BERT and RoBERTa. The main dif- ferences that lead to the leaderboard rank- ing presented 4 as data unbalance, of participants, visit task's website9). Despite lower performance, and NLP techniques were considered either as base- DETESTS subtasks are really challenging, especially for those models whose depend mainly features. Another main problem that participants had to face in this compe- tition was the fact that Chulvi, models for Spanish, although continuously increasing, is still very limited. The most proaches in the competition are scoring team (V\u00b4 azquez et al., 2022) opted strategies that representation. the one hand, they tried to balance the dataset with both under- sampling and Bagging of the majority class, and oversampling of the minority class with a double translation from Spanish to English and back. Moreover, I2C III implemented an ensemble architecture combining not models to increase the Jim\u00b4 enez-Zafra, and Valencia-Garc\u00b4 a, use of their own UMUTextStats tool to extract a set of 389 linguistic feature sets that were combined together with modelling using both BETO and RoBERTa. In the end, their model combined these representations via either knowledge integration importance of good selection. is important to note that negation features only boosted their model for subtask 2, which may indi- cate a bigger impact on the discriminative power of the models for stereotype An point regarding submit- models is that none of them tries to en- rich the contextual information by extract- ing representations from other sentences in team plicitness' 'racial target') included in the that participants were provided with. Given the fact that these features were not part of the test dataset, Lak NLP develop a meta-classifier to learn this prediction as auxiliary input to the pre-trained BETO model leading to an overall good performance in subtasks. Furthermore, the participants incorporating Adapters to the fine-tuning strategy of This adapter-based model consists of incorporating bottleneck layers between the existing hidden layers of the selected model (RoBERTa in their case) and freezing pre-existing model weights during fine-tuning. According subtask 1, this approach outperforms other interesting that knowledge least, MALNIS team (Ramirez-Orta1 et al., 2022) approached the DETESTS shared task as a Multi-Task Learning problem in which a final classifica- tion head per stereotype category is stacked on top in the over- all model performance for both subtasks by ranking first in subtask 2. Although not all participants mentioned their preprocessing strategies working may play an important role in the behavior of the models, especially if we are considering classical machine learning models built from scratch. Some of the steps that have been well as spell correction. 5.3 Metrics Subtasks 2 have been Subtask 1 applied. of the previous task or non-stereotype). a second level, the posi- tive class is decomposed into the ten Section 4.1. Spanish 223have discarded this type of metrics as they do not consider the specificity we have consid- ered the following three metrics. The first is label over precision and recall for single class in weighted according to the class propensity pc(Jain, Prabhu, and Varma, 2016). In particular, we have con- sidered the variant proposed by Amig\u00b4 o and Delgado (2022), with s(i) and g(i) being the set of classes assigned to adding cis to capture the specificity with label cin the ob- served ground are computed tor divided the amount of ancestors of the output category and of the gold stan- dard respectively. In our evaluation, when computing the ancestor overlap we consider the common empty label (root class) in order to metrics based Their drawback is that the specificity of categories is not strictly captured since be infrequent whereas leaf cat- egories can be very common in the data set. In order to capture both aspects simulta- neously, the official metric is the Information Contrast Model (ICM) (Amig\u00b4 o and Delgado, 2022), which is a sim- ilarity measure that unifies measures based on both object feature sets and Information Theory (Amig\u00b4 o et al., 2020). Given two class setss(i) (P(X)) of the class set X. The intuition is that the more unlikely the cate- gory sets are to occur simultaneously (large I(s(i)g(i))), the less they are similar. Given a fixed joint IC, the more the category sets are specific ( I(s(i)) and I(g(i))), the more is grounded on simi- larity axioms supported by the information access and cognitive sci- ences (Amig\u00b4 o et al., 2020). According to Amig\u00b4 o and Delgado (2022), the information content of a class set can be ciandcj. Subtask 1 Table 3 shows the ranking of participating systems for subtask 1 according to the the positive class. The table in- cludes the best run per team that sent work- ing notes. All the systems show better results than the baselines. The random classifier is recall scores for every run. As figure shows, some systems manage to distinguish them- selves from the rest in both precision and recall by following the diagonal in the di- Alejandro Ariza-Casabona, Montserrat Ranking Standard 1.0000 1 III point of the gold stan- dard. This distribution indicates official ranking. 5.5 Subtask 2 Table 4 shows the ranking of systems systems. In particular, all possible labels to all items (AllOnes) is penalized by all metrics and especially by ICM since the system introduces a lot of missing informa- tion in relation to specific classes. agree that assigning any option than any arbitrary are determin- This is because the is quite simple and the classes relatively balanced in the data set. However, as Figure 4 shows, there is a slight mismatch between ICM and the other two metrics. This because both HF and item, the set of labels assigned by the system and the set of classes to which it belongs through the F- measure on larity between intersection and one of the sets (system output in the case of Precision and gold standard in the case of Overview of DETESTS at IberLEF 2022: DETEction and classification scheme used in ICM considers the individual sets and their union. In other words, for evaluation purposes, our results suggest that the multi- labeling and the way in which the label sets are compared has more effect than the hier- archical structure or the class balance. 6 Conclusions and Future Work This paper has described the DETESTS chal- lenge the relevant differences that led to the final ranking. It is clear how important pre-trained language models are for complex natural language tasks such as stereotype classification and the fact that checkpoints for the Spanish lan- guage are increasingly being shared, allow- ing participants to achieve better results and come up with innovative solutions that cou- ple well with state-of-the-art systems. Re- garding the actual task, it has been designed as a hierarchical task that aims for Spanish contain to ten different stereotype categories and three additional features are included to aid in the pattern representation of the models. Also, incor- annotators aggregation in case participants want to apply methods of disagree- subtasks tackled the major problems directly. On the one hand, first subtask, III noticed the language models in an ensemble ar- chitecture. On the other hand, for the sec-ond subtask, MALNIS the and Prop-F. of data balanc- ing was not explored for subtask 2 and, thus, remains open for future work. Other future research directions worth following that did not appear in any participant's model includes methods of learning with disagreements, adding more be architectures the \"European Union NextGenerationEU/PRTR\". The work of Paolo Rosso was carried out within the framework of the research project PROM- ETEO/2019/121 (DeepPattern) by the Generalitat Valenciana. References Allport, G. W., K. Clark, and T. Pettigrew. 1954. The nature of prejudice. Addison- wesley Reading, MA. Alejandro Ariza-Casabona, Wolfgang Mariona Taul\u00e9, Enrique Amig\u00f3, Berta Chulvi, Paolo Rosso 226Amig\u00b4 o, E. and A. D. Delgado. 2022. Evaluating extreme hierarchical multi- label classification. In Proceedings of of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022 , pages 5809-5819. Amig\u00b4 o, E., F. Giner, J. Gonzalo, and F. Verdejo. 2020. On the foundations of similarity in information access. Inf. Retr. J., 23(3):216-254. Basile, V., M. Fell, T. Fornaciari, D. Hovy, S. Paun, B. Plank, M. Poesio, and A. to dis- agreement in evaluation. In Proceedings of the 1st on Benchmarking: Past, Present and Future , pages 15-21, Online, August. Association for Compu- tational Linguistics. D., of Association for Com- putational Linguistics. Costa, E. P., A. C. Lorena, A. C. Carvalho, and A. A. Freitas. 2007. A review of per- formance Report Cryan, J., S. Tang, X. Zhang, M. Metzger, H. Zheng, and B. Y. Zhao, for Computing Machinery, New York, NY, USA. Fersini, E., P. Rosso, and M. E. Anzovino. 2018. Overview of the task on automatic misogyny Declerck, H. Mazo, K. Choukri, S. Goggi, J. Mariani, A. N. Calzolari, In Prabhu, multi-label loss functions for rec- ommendation, tagging, ranking & other missing label applications. In Proceed- ings of the 22nd ACM SIGKDD Inter- Data '16, page Computing Machinery. Kiritchenko, S., S. Matwin, and F. Famili. 2004. Hierarchical text categorization as a tool of associating genes with gene on- tology codes. Proceedings of the 2nd Euro- pean Workshop Mining and Text Mining in 01. Laknani, the Spanish 227Rodr\u00b4 guez-S\u00b4 anchez, F., J. C. de Albornoz, L. Plaza, J. Gonzalo, P. Rosso, M. Comet, and T. Donoso. 2021. Overview of exist 2021: sexism identification del Lenguaje Natu- ral, 67(0):195-207. Sanguinetti, M., G. Comandini, E. di Nuovo, S. Frenda, M. Stranisci, C. Bosco, T. Caselli, V. Patti, and I. Russo. 2020. Haspeede 2 @ evalita2020: Overview of the evalita 2020 hate speech detection task. In V. Basile, D. Croce, M. Di Maro, and L. Passaro, editors, Proceedings of the Seventh Evaluation Campaign of Natu- ral Language Processing and Speech Tools for Italian. Final Workshop (EVALITA Workshop Proceedings (CEUR-WS.org). Conference date: 17-12-2020. Sap, M., S. Gabriel, L. Qin, D. Jurafsky, N. A. Smith, and Y. Choi. 2020. So- cial bias frames: Reasoning about Social and power implications of language. In Proceedings of the 58th Annual Meeting of the Association for W., M. Nofre, M. of implicit Conference , pages 753-762, Mar- seille, France, Language Resources Association. S\u00b4 anchez-Junquera, J., B. Chulvi, P. Rosso, and S. P. Ponzetto. 2021. How do humanos y catego- rias sociales. Herder. Tajfel, H., A. A. Sheikh, and R. C. Gardner. 1964. Content of stereotypes and the in- ference groups. Taul\u00b4 e, M., A. Ariza, M. Nofre, E. Amig\u00b4 o, and P. Rosso. 2021: DEtection of In Spanish. Procesamiento del Lenguaje Natural , 67(0):209-221.Uma, A., T. Fornaciari, A. Dumitrache, T. Miller, J. Chamberlain, B. Plank, E. Simpson, and M. Poesio. 2021. SemEval-2021 Task 12: Learning with Disagreements. International Workshop on Semantic Evaluation (SemEval-2021), Linguistics. V\u00b4 azquez, J. M., V. and P. P. within a sentence to visually spot categories the sEXism Identification in Social neTworks (EXIST)2022 challenge, a shared task proposed for the second year at IberLEF. EXIST of tweets and gabs, both in Spanish and English. We have received a total of 45 runs for the sexism identification task and 29 runs for the sexism categorization task, submitted by 19 different teams. In this paper, we present the dataset, the evaluation methodology, an overview of the dataset consists more than 12,000 from two El art\u00b4 culo describe la organizaci\u00b4 on, objetivos y resultados de EXIST 2022 (sEXism Identification in Social neTworks), una competici\u00b4 on que se celebra por segundo a no consecutivo en el foro IberLEF. EXIST 2022 consta de dos tareas: detecci\u00b4 on de sexismo y categorizaci\u00b4 on de sexismo de tweets y gabs, tanto en espa nol como en ingl\u00b4 es. Hemos recibido un total de 45 ejecuciones para la tarea de detecci\u00b4 on de sexismo y 29 ejecuciones para la tarea de categorizaci\u00b4 on de sexismo, enviadas por 19 equipos diferentes. En el presente art\u00b4 culo, presentamos el conjunto de datos, la metodolog\u00b4 a de evaluaci\u00b4 on, una descripci\u00b4 on general de los sistemas propuestos y los resultados obtenidos. El conjunto final de datos consta de m\u00b4 as de 12.000 textos anotados de dos redes sociales (Twitter y Gab) etiquetados siguiendo dos procedimientos diferentes: colaboradores externos y expertos en el dominio. Palabras clave: Detecci\u00b4 on de Sexismo, Twitter, Gab, Espa nol-Ingl\u00b4 es. 1 Introduction The Oxford English Dictionary ism as \"prejudice, stereotyping or discrimi- nation, typically against women, on the of sex\". As stated in (Rodr\u00b4 guez-S\u00b4 anchez, Carrillo-de Albornoz, and 2020), sex- ism is frequently found in many forms in social networks, includes a range forms of sexism are particularly dangerous as they can go unnoticed, and affect women in many facets of their lives (Swim et al., 2001; Berg, 2006). However, research on sexism in online platforms has focused on detecting violent Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 229-240 recibido aceptado 25-07-2022 ISSN 1135-5948. DOI 10.26342/2022-69-20 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Naturalsexism and hate against women (Waseem, 2016; Waseem and Hovy, guez-S\u00b4 anchez automatically detect and in the is shared task on sexism detection in social networks whose aim is to identify and classify sexism in a broad sense. Like its first edition in 2021, EXIST 2022 has been proposed at IberLEF. During the first edition, we received a total of 70 runs for the sexism identification and 61 for categorization by great interest of around sexism detection in social networks. The EXIST 2022 shared task has been focused on the same tasks as its first set labelled by six experts trained to perform the task. Thus, this new edition focuses augmenting Annotators of different age groups were also considered. In this second edition of EXIST, we have received a total of 45 runs for the sexism iden- task submitted by 19 teams. Results have improved with respect to the previous edition for task 1 (sexism identification) and have remained similar for task of mine is a difficult task that requires further research. 2 Tasks 2.1 Task Description The EXIST 2022 shared task is defined as a multilingual classification task. In particu- lar, the EXIST challenge is ing to two main subtasks: sexism iden- tification (task 1), which aims if or post contains sexist and (ii) sexism categorization type of in a given sexist message or post. Partici- pants were welcome to present systems that attempt both subtasks or one of them. Task 1 is defined as a binary classification problem, where every system should deter- mine whether a text or message is sexist or not. It includes any type of sexist expression or related phenomena, like descriptive or re- ported assertions where the sexist message is a report or a description of a sexist event. In particular, we consider the tweet or not express any sexist behaviour or dis- course. Once a message has been classified as sex- ist, task 2 aims to categorize the message according to the type of sexism it encloses. The categorization has been revised by two experts in gender issues, Trinidad Donoso and Miriam Comet from the University of Barcelona, and takes into account the differ- ent aspects of women that are undermined. This task is defined a multi-class classifi- cation where each sexist tweet or one of the 5 following classes: rejects inequality between men and as victims of gender-based oppression. Stereotyping and dominance: The text expresses false ideas about women that suggest they are more suitable to fulfill certain etc), or claims that men are somehow superior to women. Objectification: The text presents women as objects apart from their dig- nity and personal aspects, or assumes or describes certain physical qualities that order to fulfill tra- ditional gender bodies the disposal Laura Plaza, Adri\u00e1n Mendieta-Arag\u00f3n, Julio Gonzalo, Damiano Spina, Paolo Rosso 230Text Task 1 Task 2 Where are all the white women at? non-sexist non-sexist Feminism is a war on men, but it's also a war on women. It's a war on female nature, a war on femininity. but I've never seen an hooker. Not a single one sexist obj ectification Iw anna touch your tits..you can't imagine what I can do on your body. sexist sexual-violence I hate misogyny requests for sexual favors or harassment of a sexual nature (rape or sexual as- sault) are made. Misogyny and non-sexual 1. A substantial difference between EXIST 2022 and its first edition in 2021 is that, in 2022, the test set was labelled by 6 experts trained to perform other hand, presented ger into women and men may dif- fer in their perception of what is sexism, and therefore the annotation group is composed of three women and three men. 2.2 Evaluation Measures and Baselines In order to evaluate the performance of the different approaches proposed by the partici- pants, we will use the Evaluation Framework EvALL2(Amig\u00b4 o 2017; Amig\u00b4 o, Spina, and Carrillo-de Albornoz, 2018; Amig\u00b4 o et al., 2020). Within this framework, we will evalu- ate the system outputs as will and F1. All metrics will be also computed by language. In will use macro-averaged F1-score to rank the sys- tem outputs. Similarly, we will compute other measures such + F1(stereotyping-dominance) We propose two different baselines so that we can establish an expected performance of features each record based the majority class (Majority Class). 3 Dataset The EXIST 2022 shared task employs data from Twitter and Gab in English and Span- ish. In particular, this edition uses the EX- IST 2021 dataset for training and a new test set labeled by experts in the task for testing. Therefore, Twitter data was used for both training and testing while Gab was only in- cluded in the EXIST 2022 training set. This way, participants can analyse whether includ- ing data from a social without \"con- tent control\" in the training phase improves the performance of their systems. In order to build the testing data for both tasks, we em- ployed the same terms used in EXIST In particular, the final set contains 116 seed terms for Spanish and 109 for English. To create the new test set for this edi- tion, we used the Twitter API to search sEXism Identification or Spanish contain- ing some of the selected keywords. The setup 31st of ing 170,210 tweets for Spanish and 206,549 for English. We have removed those with less than 60 tweets to ensure an appropri- ate balance between seeds. The final set of seeds used contains 91 seeds for Spanish and 94 seeds for English. Regarding the sampling process, approx- imately 7 tweets were randomly the from to 31st of January 2022. We randomly re- sampled tweets each language to build the final sampled set composed of tweets. taking different In particular, we considered three main sources: seed, temporal and user bias. We tried to mitigate seed bias by including a range sexist and non-sexist contexts (116 terms for ish and 109 for English). Temporal bias be- tween training and testing data is mitigated since there is a temporal gap of almost one year between both sets. We also checked the temporal gap between tweets for each seed to ensure that data took into account this principle to split the dataset into training and test sets and removed from the test set users who were also present in the training set to avoid user bias. The sampled data set was developed an annotation guide in English and Spanish in which we provided a clear explanation of each label along with a of We presented and ex- plained the guidelines to ensure that all ex- perts understood the task. Then, we did an annotation experiment proposing the 6 ex- perts to annotate the 20% of the test set ob- taining a 0.387 kappa for task 1 and task 2. These results indicated poor were used to annota- tion guide and revise all the problems with the annotators. We repeated the experiment and obtained a 0.57 kappa for task 1 and 0.47for task showing a moderate agreement that aligns with the fact that the sexism detection task from a broad perspective is not simple. Sexism is even more subjective than yny is be- tween the 6 expert annotators in all cases. In the case of a tie, the tweet/gap was dis- carded. The final agreement for the whole dataset was 0.589 kappa for task 1 and 0.485 for task 2. Texts with disagreement for any of the classes were removed. The final EXIST 2022 test set 1058 tweets, where all texts were randomly values Paolo Rosso 232-\"non-sexist\": denotes that the tweet or does not express any sexist behaviours or discourses. Concerning the test data, we removed and \"task2\" labels from the file sisting of tweets. Table 2 summarizes dataset, as well as the number of texts per class for both training and test sets, and the distribution by lan- guage. 4 Overview of the Submitted Approaches 60 groups from 14 countries signed up for EX- IST 2022, 19 of them submitted runs for task 1, and 15 for task 2. In this challenge, each team had the chance to submit a maximum of 6 runs, 3 runs for each task. We received a total of 45 runs for task 1 and 29 runs for task 2. Regarding the classification approaches, all of the participants submitted their results using some sort of transformer-based system for both tasks with the exception of one team. In particular, 18 teams used some sort of transformer architecture, of which 8 teams used BERT (Devlin et al., 2019) (or mul- tilingual BERT - mBERT), 5 used a Span- ish version of BERT called BETO (Canete et al., 2020), 4 used RoBERTa (Liu et al., 2019), 3 used DeBERTa v3 (He, Gao, and Chen, 2021), 2 used a multilingual version of RoBERTa called XLM-R (Conneau et al., 2019) or other transformer versions. (LR) have been adopted by one team. This year, none of the teams experimented with other deep learning methods ory networks - Following, participants the used by each group. 2539404758 participated in both tasks and submitted one run for each task. They fine-tuned BERT for English texts and BETO for Spanish. AI-UPV in both submitted runs for task. Their sys- tem was based on an ensemble of transformer models in a single-language and multilin-gual configuration. In particular, they used BERT, RoBERTa, ELECTRA (Clark et al., 2020) and GPT-2 (Radford et al., 2019) as transformer models. AIT FHSTP in both tasks and submitted a monolingual (English) T5 model (Raffel et al., 2019). To train the models, they used a two step approach. First, un- supervised pre-training with additional data and fine-tuning with ad- ditional as well as augmented HatEval 2019 dataset (Basile et al., 2019) and other hate related avacaondata for each task. Their best approach to the task is based on an en- semble of different transformer models with BERTweet-large (Nguyen, Vu, and Nguyen, 2020), RoBERTa and DeBERTa v3 for En- glish, and BETO, BERTIN (De la Rosa et al., no et al., 2021) and RoBERTuito et al., 2021) for Spanish. Models were trained in two phases. First, a validation set was hyperparameter optimization, second, mod- trained using whole training set. besiguenza submitted one run for each task. Their best system was based on 1 with three different runs. Their best approach consisted in an ensemble of 10 RoBERTuito and 10 BERT models each of them is trained individually using different seeds. CompLingKnJ only participated in task 1 with two different runs. Their best run was based on transformers, where BETO was used for Spanish messages and BERT for English. They experimented with a system based on runs each task. Their system was based in a ensemble of 5 different models for Spanish (XLM-R, RoBERTa and 3 BERT models) and other 5 models for En- Overview of EXIST 2022: sEXism Identification in Social neTworks 233Training Testing Twitter Gab Twitter Spanish English Spanish English Spanish English Total Sexist 2599 2494 265 300 254 215 225 192 271 305 6263 Ideological-inequalit y 695 619 73 100 97 64 1648 Misogyn y-non-sexual-violence 600 436 58 63 32 25 1214 Objectification 368 377 50 29 18 21 863 Sexual-violence 304 494 71 48 44 43 1004 Stereot yping-dominance 632 568 13 60 60 55 Dataset distribution. glish (XLM-R, RoBERTa, BERT, hateBERT (Caselli et al., 2020) and ALBERT (Lan et al., 2019)). Furthermore, they translated all English tweets to Spanish and vice versa and masked randomly selected tokens to augment the data available. I2C participated with 3 runs for task 1 and one run for task 2. For their best sys- tem, they translated all Spanish tweets to English and created an ensemble of 3 models: RoBERTa, BETO and SiEBERT et al., 2020). LPtower submitted 3 runs for each task. For their best run, they translated all tweets to 6 languages (French, Portuguese, Italian, German, Spanish and English) and created an ensemble of 6 models, each of them trained for a different language. multiaztertest submitted two runs for task 1 and one run for task 2. In their best run, they fine-tuned RoBERTa for English texts and BETO for Spanish. NIT Agartala NLP Team submitted one run for each task. two runs for task 1 and one run for task 2. They trained the multilingual model LaBSE (Feng et al., 2020) to classify both English and Spanish tweets. SINAI only participated in task 1 with three different runs. The best run was a sys- tem based on DistilBERT (Sanh et al., 2019). They with other datasets for data augmentation. SINAI-TL only participated in task 1 with three different runs. They followed multi- task learning approach using different auxil-iary tasks. BETO for Spanish and BERT for English were used as base models. Their best run used the emotion detection task as the auxiliary one by training a shared model with the Universal Joy dataset (Lamprinidis et al., 2021) for Spanish and, for English, they used a BERT model without auxiliary. ThangCIC submitted 3 runs for each task. Their best system was based on an majority vote ensemble of a Multi- lingual Universal Sentence Encoder xaiTUD only participated in task 1 with a run. Their system was based on a com- bination of byte-level model al., tabular modeling TabNet (Ark and Pfister, 2021). 5 System Results Tasks 1 and 2 were evaluated independently. In the following subsections, we show the re- sults for each task and language. Teams were ranked by accuracy for task 1 and macro- averaged F1-score (F1) for 2. 5.1 Task 1 19 teams participated in task 1 for both English and Spanish, presenting 45 runs in total. In Table 3, the best run for each team is shown, as well as the two baselines: BASELINE and Majority Class. All runs ranking is available at the task website3. Regarding the best run ranking, 14 teams achieved an Accuracy above the performing team is avacondata, which achieved an overall F1 of 0.7996. This team exploited an ensemble of transformers models for different hyper-parameter configurations. The baseline based on majority vote sepa- rankings language (English and Span- ish) for each task. Table 4 shows the top-10 runs for English and Table 5 for Spanish. Re- garding the English results, the winning team avacaondata achieved the best results an ensem- ble of 10 RoBERTuito and each them accuracy. teams on This may suggest that transformer-based models benefit from train- ing with data from the same source (e.g. Twitter). It is interesting to highlight the perfor- mance difference (around expected, transformer models better in En- since they trained on corpus mainly composed of English texts. However, these datasets, multilingual Plaza, Adri\u00e1n Mendieta-Arag\u00f3n, Task 2 15 teams participated in task 2 for both En- glish and Spanish, for a total of 29 runs. In Table 6, the best run for each team is shown, as well as the two baselines. all achieved task2 BASELINE, only teams were Class baseline, 14 teams achieved a higher F1, whereas 1 is is interesting to highlight the the worst sys- tems. The best performing team for task 2 is again avacaondata. The worst have been learning methods. Further- more, the difference between the first and second team is more significant. This could be due to the fact that, unlike the first task, the second team does not employ a domain- adapted transformer. Tables 7 and 8 show results for the top- 10 teams in English and Spanish, respec-tively. Again, the task winner avacaondata performed better in English than in Span- and by using an ensemble of 5 differ- ent models for Spanish and other 5 models for English. In this task, the difference in performance between English and Spanish is very similar to task 1. However, it is important to notice that most participants achieved relatively low results, demonstrating the difficulty of this task and the need for further research. 6 Conclusion In this paper, we have presented the results of the second shared task on sexism detec- tion in a broad sense, systems in multilingual scenarios (En- glish 2022: sEXism Identification tators). Perhaps its high-quality dataset, which comprises more than 1,000 perform tasks in the We this that the problem identification better ad- dressed by using transformer-based adapted to the Twitter categorization still in edi- tradi- sexism detection in social networks is challenging but there is still room for improvement. Again, the high number of participating teams at EXIST Acknowledgments This work was partially supported by the Spanish Ministry of Science and Innovation under the project \"FairTransNLP: Midiendo y Cuantificando el sesgo y la justicia en sistemas de PLN\"(PID2021-124361OB-C31 and PID2021-124361OB-C32). This work was also partially funded by the Spanish Ministry of Economy and Competitiveness, as part of the research cooperation project \"Space for Observation of RED.ES, M.P., ref. C039/21- OT). The work of Paolo Rosso was in the framework of the research project PROME- TEO/2019/121 (DeepPattern) by J. F. Verdejo. 2017. Evall: Open access evaluation for information access systems. In Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval , pages 1301-1304.Amig\u00b4 o, E., J. Gonzalo, S. Mizzaro, and J. Carrillo-de Albornoz. 2020. An effec- tiveness metric 2018. An In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval , pages 625-634. Ark, S. At- interpretable tabular learning. In AAAI, 6679-6687. Basile, V., C. Bosco, E. Fersini, N. Deb- ora, V. Patti, F. M. R. Pardo, P. Rosso, M. Sanguinetti, et al. 2019. Semeval- 2019 task 5: Multilingual detection of hate speech against immigrants and women in twitter. In 13th International Workshop on Semantic Evaluation , pages 54-63. As- J., G. Chaperon, R. Fuentes, and J. P\u00b4 erez. 2020. Spanish pre-trained bert model and evaluation data. PML4DC at ICLR, 2020. Caselli, T., V. Basile, J. Mitrovi\u00b4 c, and M. Granitzer. 2020. Hatebert: Retrain- ing and M. Coulomb- Gully. 2020. He said \"who's gonna take care of your children when you are at ACL?\": Reported sexist acts are not sex- ist. In Proceedings Annual Meeting of the Association for Computa- tional 4055-4066, Linguistics. Clark, K., M.-T. Luong, Q. V. Le, and C. D. Manning. 2020. Electra: Pre- training A., K. Khandelwal, N. Goyal, V. Chaudhary, G. Wenzek, F. Guzm\u00b4 an, E. Grave, M. Ott, Zettlemoyer, and V. arXiv:1911.02116. De la Rosa, J., E. G. Ponferrada, M. Romero, P. Villegas, P. G. de Prado Salas, and M. Grandury. 2022. Bertin: Efficient pre- training of a spanish language model us- ing perplexity sampling. Procesamiento del Lenguaje Natural, 68:13-23. Devlin, J., M.-W. Chang, K. Lee, and K. Toutanova. Pre-training deep bidirectional transformers for lan- guage understanding. In Proceedings of the 2019 Conference of the North Amer- ican Chapter of the Association for Com- putational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) , pages 4171-4186, Minneapolis, Minnesota, June. Association for Compu- tational Linguistics. Donoso-V\u00b4 azquez, T. and Rebollo-Catal\u00b4 an. 2018. Violencias de g\u00b4 enero en entornos virtuales. Ediciones Octaedro. Feng, F., Y. Yang, D. Cer, N. Arivazhagan, and W. Wang. 2020. Language-agnostic 2019. women: Automatic identifica- tion of misogyny and sexism & Fuzzy , 36(5):4743-4752. Guti\u00b4 Carrino, C. Armentano-Oller, C. Rodriguez-Penagos, M. Villegas. 2021. Spanish language models. arXiv preprint arXiv:2107.07253. Hartmann, J., M. Heitmann, C. 2020. More ing: Accuracy and application of senti- ment analysis. He, Hovy. 2021. Universal joy: In S. Goodman, K. Gimpel, P. Sharma, and R. Soricut. 2019. Albert: A lite for self-supervised learning of language representations. arXiv preprint arXiv:1909.11942. Liu, Y., M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettle- moyer, and V. logic of misogyny. Oxford University Press. Mills, S. 2008. Language and sexism . Cam- bridge University Press. Nguyen, D. Q., T. Vu, and A. T. Nguyen. 2020. Bertweet: A pre-trained language model for english tweets. J. M., D. many, and F. Luque. 2021. Robertu- ito: a pre-trained language model for text in spanish. arXiv preprint arXiv:2111.09453. Radford, A., J. Wu, R. Child, D. D. Amodei, I. Sutskever, et Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu. 2019. Exploring the limits of transfer bornoz, L. Plaza, J. Gonzalo, P. Rosso, M. Comet, and T. Donoso. 2021. Overview of exist 2021: sexism guez-S\u00b4 anchez, F., J. Carrillo-de Al- bornoz, and Plaza. 2020. Automatic classification of sexism in social networks: An empirical study on Access, 2022: sEXism L. Chaumond, and T. Wolf. a Fer- guson. 2001. Everyday sexism: Evidence for its incidence, nature, and psychologi- cal impact from three daily diary studies. Journal of Social Issues , 57:31 - 53. Waseem, Z. 2016. Are racist or am I seeing things? annotator influence on hate speech detection on Twitter. In Pro- ceedings of the First Workshop on NLP and Computational Social Science , of the NAACL Student Re- search Workshop, pages 88-93, San Diego, California, June. Association for Compu- tational Linguistics. Xue, L., A. Barua, N. Constant, R. Al- Rfou, S. Narang, M. Kale, A. Roberts, and C. Raffel. Byt5: a token-free future Linguistics , 10:291-306. Yang, Y., D. Cer, A. Ahmad, M. Guo, J. Law, N. Constant, G. H. Abrego, S. Yuan, C. Tar, Y.-H. Sung, et al. LivingNER shared task and resources Detecci\u00b4 on, normalizaci\u00b4 on y clasificaci\u00b4 on de especies, pat\u00b4 ogenos, humanos y alimentos en documentos cl\u00b4 nicos: resumen de la tarea y los recursos Miranda-Escalada, Eul` alia Farr\u00b4 e-Maduell, Krallinger Barcelona Supercomputing Center, Spain antoniomiresc@gmail.com Abstract: There is a generate tools for finding mentions of species, pathogens, or food from medical texts. To promote the development of such tools we organized the LivingNER task. LivingNER relied on a large Gold Standard corpus of 2000 carefully selected clinical cases in la necesidad de generar herramientas para encontrar y normalizar menciones de especies, pat\u00b4 ogenos o alimentos en textos m\u00b4 edicos. Para promover el desarrollo de tales herramientas hemos organizado la tarea LivingNER. La tarea LivingNER se bas\u00b4 o en un corpus en espa nol de 2000 casos cl\u00b4 nicos cuidadosamente seleccionados, representando una diversidad de especialidades. El corpus fue anotado manualmente por expertos que tambi\u00b4 en asignaron a las menciones sus correspon- dientes identificadores de la NCBI Taxonomy. Adem\u00b4 as, hemos generado versiones de LivingNER para otros 7 idiomas: ingl\u00b4 es, portugu\u00b4 es, gallego, catal\u00b4 an, italiano, franc\u00b4 es y rumano. LivingNER se estructur\u00b4 o en tres subtareas: 1) LivingNER-Species NER (subtarea de detecci\u00b4 on de menciones de especies), 2) LivingNER-Species Norm (detecci\u00b4 on de especies y normalizaci\u00b4 NCBI Taxonomy) y 3) LivingNER-Clinical IMPACT (tarea de clasificaci\u00b4 on relacionada con la detecci\u00b4 on de mascotas, animales causantes de lesiones, alimentos y entidades nosocomiales). Recibimos y evaluamos 62 sistemas de 20 equipos de 11 pa\u00b4 ses a nivel mundial, obteniendo resultados altamente competitivos. Generalmente, los enfoques m\u00b4 as exi- tosos hicieron modificaciones a modelos de lenguaje basados en transformers (BERT, BETO, RoBERTa, etc.) y emplearon m\u00b4 etricas de distancia de embeddings para la normalizaci\u00b4 on de entidades. Corpus LivingNER: doi.org/10.5281/zenodo.6376662 Palabras clave: reconocimiento de entidades nombradas, miner\u00b4 a de textos de pat\u00b4 ogenos, normalizaci\u00b4 on de entidades, NCBI Taxonomy. Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 241-253 recibido aceptado 25-07-2022 ISSN 1135-5948. DOI 10.26342/2022-69-21 \u00a9 Sociedad del Lenguaje Natural1 Introduction The semantic annotation of species or living to scientific disciplines like iden- tifying hierarchical taxonomic relations have been developed over 250 years to determine rules and conventions to catalog species. And al., Federhen, 2012), the Thompson scientific name list, the Catalogue of Life, the Global Names Index database, and the ambiguous EC, which can be used for the LINNAEUS Bergman, 2010) and the SPECIES tool (Pafilis 2013) are capable of men- Additionally, microorgan- isms/species, such Diseases (ID) task of BioNLP 2011 (Pyysalo et al., 2011). And the importance of mentions for gene mention biomedical literature data in English (Krallinger, Leitner, However, adapting these resources to lan- guages other than English and document types different from biomedical literature is not trivial. This is aggravated by the lack of resources, common evaluation scenarios, and shared tasks in other languages. The LivingNER task addressed these four information axes related to is a universal by Nucleotide Sequence Database oratory (EMBL), and DNA Data Bank of Japan (DDBJ) as a single source of taxo- references and standardizes mentions of the different floras of the human organism in preparation for the literature and clinical cases related to the hu- man microbiome. For of Some such as close the same household, and rel- atives. LivingNER is the classifying species and infectious diseases in Spanish-language literature and medical reports. 2 Task Description 2.1 Shared Task goal The LivingNER shared task explores Spanish language, the assignment of NCBI Tax IDs, and the which real- world health use cases. 2.2 Sub-tasks The LivingNER track contains three inde- pendent subtasks built NER mention entity recognition): text clinical case report document collection, participants must return the exact character offsets of all species case report document collection, par- ticipating systems have to return all species track given of plain text documents, systems must (1) Perform a document and farm animals, (B) for food species. single document may belong to several cat- egories. And (2) Retrieve the list NCBI Tax IDs that support the binary classifica- tion. Systems have to the following information axes: Pets and farm animals in close contact the patient (important for Food species. It includes ingested al- iments and any other food mentioned in the document. It excludes ingested items that are food. employed the PathoTagIt-Base system. This competitive baseline is a deep neural network system trained with the LivingNER training dataset. The network is a customiza- tion of the BiLSTM-CRF architecture, and it employs word embeddings optimized for biomedical Spanish language (Soares et al., 2019). For a more in-depth description of Mention detection, normalization task check the PharmaCoNER tagger pa- per (Armengol-Estap\u00b4 e et 2019). The code is available on GitHub (github.com/TeMU- BSC/PharmaCoNER-Tagger). There is also a web demo of the PathoTagIt-Base system (see temu.bsc.es/livingner/). we have Impact subtask. We have trained four different NER systems. The first NER system recognizes pet and farm animal mentions; the second mentions animals causing injuries; the third, food men- tions; and the last, nosocomial entities. The four NER systems were run on the test set documents. The document containing it is automatically classified For instance, in Figure 1 B, as soon as mentions a \"food document\". 3 Corpus and Resources 3.1 LivingNER Gold Standard Corpus The LivingNER corpus is a collection of 2,000 clinical cases in Spanish from 20 med- not the LivingNER shared task. Document selection. The objective of document selection was to obtain a sufficient diversity of mentions representative infections, AIDS, hepatitis C and others, were not excluded from our selection. Corpus annotation. The LivingNER corpus has been annotated and standardized by a domain specialist with the support of a clinical specialist, who was also in charge of reviewing the mentions and their associated codes to arrive at a final version. The process of annotation and normalization of the cor- pus took and 2021, last- ing approximately five months using the brat tool. Before starting the annotation, a first draft of these guides was our the corpus. After several rounds, a total IAA score of of the LivingNER annotation, a random 10% of the papers were thoroughly reviewed to ensure that quality the corpus, especially about difficult and ambiguous cases, with the aim of ing the highest possible quality and usability of the pus citations. The Liv- clin- ical case documents are released text format with UTF-8 encoding. The an- notations are included in a tab-separated document. In the LivingNER-SPECIES NER task, the document), off1 (ending posi- tion in span. The LivingNER-Species Norm file, in addition to these columns, includes four columns: isH span corpus amounts corpus was randomly split into three subsets: training, validation, and test set. The test set is used for evaluation pur- poses of participating teams and consists of 485 records (15 extra records will be re- 3: LivingNER the 9606 and there are other unique codes. See Table 1 for the LivingNER corpus general statistics. The 15 most common SPECIES mentions are shown in Figure 4B. It is noteworthy that seven out of the ten most common have the HUMAN label, despite there being fewer HU- MAN annotations. This is because it is a more homogeneous entity type. Indeed, there are 707 different HUMAN mentions, there are 3818 different SPECIES mentions. In Figure 4.A, the 15 most SPECIES NCBI Tax IDs are displayed. The main term of the code is shown instead of the numeric ID for clarity. While some terms are general results. 45 14 21 80 Animal causing injuries 107 12 22 141 Food species 255 107 163 525 Nosocomial entities 67 21 10 98 Table 1: DrugProt task and resources 4: Number of appearances of (A) the main terms of the 15 most common codes, and (B) the 15 most common entities in the LivingNER Gold Standard. we can find in the terminologies (for in- stance, hepatitis C virus is usually found as acronym, i.e., HCV, and Staphilococcus au- reus as Staph A. and even its vernacular form, i.e., estafilococo). However, language was not the only challenge. We had deter- mine prac- pathognomonic tests could be equated to the and thus the to the human microbiome, ticularly the gut microbiome, since its study has imploded in the last decades, and the use treat other conditions with human flora are der way. microbiology and scien- tific knowledge. 3.3 LivingNER Multilingual Silver Standard To foster the development of multilingual tools and generate systems not only for Span- ish but also for content in English and various Romance languages, annotated (and statis- tics of the Silver Standard are shown in Ta- ble 2. We refer to the DisTEMIST overview paper (Miranda-Escalada et al., 2022) for a complete description of the generation pro- cess since it is equivalent to that corpus. Find the the a Neu- ral Machine Translator fine-tuned for the biomedical domain. It the following columns: taxid(the NCBI Taxonomy txt(the NCBI Taxonomy name), unique name (the unique variant of this name if the name is not unique), name class (synonym, common name, scientific name, ...), Spanish name (the NCBI Taxon- omy name in Spanish). out NCBI Taxonomy scope). The three were added because they appear in the LivingNER corpus, and are present in the browser version of NCBI Taxonomy. The last one ( NOCODE ) is added to identify terms in the LivingNER corpus that are not present in the NCBI Taxonomy. The terminology registered 20 fully or academia) from in- cluding Romania, China and M\u00b4 Table 5 Impact. In this case, participants had to classify the test set documents the document classification task and the document classification + code justification. The baseline system was available for the first task (document classification), and none of the participant teams outperformed it. this in the Discussion section. We must outline that positive There- to interpret. Finally, the shared task and resources 247Team Name Affiliation Country Tasks Ref. Tool URL Vicom tec h NLP Vicomtech Spain NE/No/C (Zotova et al., 2022) - racai Research Institute for Artificial Romania NE (Avram, Mitrofan, and Pais, 2022) - Intelligence \"Mihai Draganescu\" READ-Biomed RMIT University Australia NE (Jimeno Yepes and Verspoor, 2022) - SINAI Universidad de Ja\u00b4 en Spain NE/No/C (Chizhikova et al., 2022) - plncmm CMM, University of Chile Chile NE/No/C (Rojas et al., 2022) (plncmm, 2022) Sumam Francis KU Leuven Belgium NE (Francis and 2022) Clac Concordia University NE/No (Bagherzadeh, Verma, and Bergler, 2022) - john snowlabs John Snow Labs USA NE (Kocaman et al., 2022) - avacaondata IIC (ADIC) Spain NE/No/C (Vaca, 2022) - Pumas Universidad Nacional Aut\u00b4 onoma M\u00b4 exico NE/No/C (del Moral et al., 2022) - IAM University of Bordeaux France NE (Cossin, Diallo, and Jouhet, 2022) (IAM, 2022) IGES IGES Institut GmbH Germany NE/No (Chapman, Schwarz, and - ecnico 2022) (NLP-CIC-WFU, 2022) Wake Forest University Vitor Universidade Federal do Rio de Janeiro Brasil NE - - zzz Yunnan University China NE (Zhu and Wang, 2022) (zzz, 2022) Kformer-OEG Universidad Polit\u00b4 ecnica de Madrid Spain NE - - Mark - - NE (Hanjie and Xiaobing, 2022) (Mark, 2022) Han Yunnan University China NE (Han and Ding, 2022) (tutorial, 2022) Sapphire - - NE - - boun-ner Bogazici University Turkey NE - - Table 3: LivingNER team overview. In the Tasks column, NE stands for LivingNER-Species NER, No for LivingNER-Species Norma and C for LivingNER-Clinical Impact. Pets .0006 .125 .0012 .0088 .1154 .0164 0 0 0 SINAI 0 0 0 0 0 0 0 0 0 0 0 0 plncmm .0317 .3636 .0584 0 0 0 .02 .3846 .038 0 0 0 avacaondata 0 0 0 0 0 0 0 0 0 0 0 0 Pumas .024 .25 .0438 0 0 0 .0211 .2692 .0391 0 .0032 SINAI 0 0 0 0 0 0 0 0 0 0 0 0 0 0 .0021 .125 .0041 0 0 0 0 0 0 Pumas .024 .25 .0438 .0167 .25 .0312 .0211 .2692 .0391 0 0 .8 recall and F1-score. by a dedicated webpage (temu.bsc.es/livingner/results/). by LivingNER participants, and for an in-depth description, we refer to their scientific articles, listed in Table 3. We have observed that the most success- ful approaches to LivingNER-Species NER included non-standard fine-tuning of pre- trained transformer-based language models. Typically, these language models are do- main and language-specific, such as bsc-bio- es occur Norm, participants with the highest the most successful approach has been the baseline: to train a simple NER system to recognize the entities of interest and label as positive any with detected named entity. Antonio Miranda-Escalada, READ-Biomed .954 .9411 - - - .6145 .703BERT(BETO)+BiGRU+ CRF .5399 .1965 - F1-score. 4.4 LivingNER Spanish Silver Standard The LivingNER test set was released together with a background set: an additional collec- tion of 13,000 clinical case documents from various predictions for the test and the background set, although they were only evaluated on the test set predictions in the three subtasks. be harmonized and constitute the Liv- ingNER Spanish Silver Standard corpus, similar to the CALBC initiative (Rebholz- Schuhmann et al., 2010), to Farr\u00b4 Krallinger, 2020), et 2019) shared tasks. Considering the large precision and re- call of most LivingNER systems, the Liv- ingNER Spanish Silver Standard will of task Spanish. to foster the development of species recognition and link- ing resources, as well as more an- notated data. The LivingNER Spanish Sil- ver will released on the Zenodo Medical NLP community. 5 Discussion a and provide access to gies and glossaries for the domain. saries semantic annotation efforts (Villegas et al., 2018). In this direction, the LivingNER initiative pioneers to structure the develop- ment of species NER and linking resources, we have released the LivingNER corpus: the first Gold Standard that made public allow the corpus extension and adaptation to other languages or do- mains. It contains and potential species mentions, and (3) the general lack of annotated data in other languages, we have released the predictions nearly that will be harmonized to create the LivingNER Spanish Silver Standard. These resources can be used to actionable linking is seen in Figure 6, in which Gold Standard SPECIES an- notations are with directions, we plan to generate more granular annotations for Clinical Impact applications lacked enough training and test data, and we plan to correct this issue in the future. Finally, the Multi- lingual We acknowledge the Encargo of Plan TL (SE- DIA) to BSC for funding and the scientific committee for their guidance and help. Due to the relevance of species for biomaterials and implants, this project by the European Union's Horizon Europe Co- ordination & Support Action under Grant Agreement No 101058779. We acknowledge the support from the AI4PROFHEALTH project (PID2020-119266RA-I00). We thank the organization of IberLEF and Bitac for collaboration 250References Armengol-Estap\u00b4 e, J., F. Krallinger. 2019. named-entity spanish J. Llop-Palao, M. Villegas. 2021. Biomedical and clini- cal language models for spanish: D\u00b4 opez, and M. T. Mart\u00b4 n- Valdivia. N. Goyal, V. Chaudhary, G. Wenzek, F. Guzm\u00b4 an, E. Grave, M. Ott, Zettlemoyer, and V. iberlef 2022: Ner of species men- tions. del Moral, Reyes-Aguill\u00b4 on, Murasaki, E. Primo-Pe na, C. Canales, Proceedings. Gerner, M., Bergman. 2010. Linnaeus: a species Marimon, Workshop on BioNLP Open Shared Tasks, pages 1-10. Han, S. 2022. recognition based model and bigru-crf. IAM. 2022. Iamsystem. https://github.com/scossin/IAMsystem. Jimeno Yepes, A. and K. Verspoor. 2022. The read-biomed team in livingner task 1 (2022): Adaptation of an english annota- tion system to spanish. Kocaman, V., G. code changes. Krallinger, M., F. Leitner, and A. Valencia. 2010. Analysis processes using text and occupations from med- ical texts. Procesamiento M., A. Gonzalez-Agirre, A. In- txaurrondo, H. Rodriguez, J. L. Martin, M. Villegas, and M. Krallinger. 2019. Au- tomatic de-identification of and M. Krallinger. 2021. shared In Proceedings the Sixth Social Media Mining for Health (# SMM4H) Workshop and Shared Task, pages 13-20. Miranda-Escalada, A., o, S. Pavloudi, A. Vasileiadou, C. and L. J. Jensen. 2013. The species and organisms resources for fast and Pyysalo, S., T. Ohta, R. Rak, D. Sullivan, C. Mao, C. Wang, B. Sobral, J. Tsujii, and S. Ananiadou. 2011. Overview of the in- fectious diseases (id) task of bionlp shared task 2011. In Proceedings of BioNLP Shared Task 2011 Workshop, pages 26-35. Rebholz-Schuhmann, D., A. J. J. Yepes, E. M. Van Mulligen, N. Kang, J. Kors, D. Milward, P. Corbett, E. Buyko, E. Beisswanger, and U. Hahn. 2010. Calbc silver standard corpus. Journal of bioinformatics and computational biology , 8(01):163-179. Rojas, M., J. S. Kannan, R. Khovan- skaya, D. Leipe, R. Mcveigh, O'Neill, B. Robbertse, et al. 2020. Ncbi taxon- omy: a comprehensive update on cura- tion, resources and tools. Database, 2020. Soares, F., M. Villegas, A. Gonzalez-Agirre, M. Krallinger, and J. Armengol-Estap\u00b4 e. 2019. Medical word embeddings for Span- ish: Development and evaluation. In Pro- ceedings the Clinical Natural Lan- guage Processing Workshop , pages 124- 133, Minneapolis, Minnesota, USA, June. Association for Computational Linguis- tics. Tamayo, A., D. A. Burgos, and mbert 2022. https://github.com/songhan123123/ner. A. Krallinger. 2018. The mespen resource for english- spanish medical machine Wang. 2022. Bert-bilstm model for entity recognition in clinical Garc\u00b4 a-Pablos, P. on, and M. Cuadros. PAR-MEX at Iberlef 2022: Paraphrase Detection Task Resumen de PAR-MEX en IberLEF 2022: Tarea Compartida para la Detecci\u00b4 on Par\u00b4 en Matem\u00b4 aticas Aplicadas y en Sistemas (UNAM) 3Laboratoire Informatique d'Avignon (Avignon Universit\u00b4 e) 4Posgrado en Ciencia guage processing; especially in the Spanish language. In order to address this issue, and contribute to the creation of high-performance paraphrase detection automated systems, we propose a shared task called PAR-MEX. For this task, we created a corpus, in Spanish, with topics in the domain of Mexican gastronomy. Afterwards, the participants in this task submitted their classification results on our corpus. In this paper we explain the steps followed for the creation of the corpus, summa- the results obtained by una tarea importante no resuelta en proce- samiento del lenguaje natural; especialmente en la lengua espa nola. Para atacar este problema, y para contribuir a la creaci\u00b4 on de sistemas de detecci\u00b4 on autom\u00b4 atica que obtengan resultados competitivos, proponemos la tarea compartida llamada PAR-MEX. Para esto, creamos un corpus en espa nol con temas dentro del campo sem\u00b4 antico de gastronom\u00b4 a mexicana. Despu\u00b4 es los participantes en esta tarea en- viaron los resultados de sus sistemas de clasificaci\u00b4 on sobre nuestro corpus. En este paper explicamos los pasos seguidos para la creaci\u00b4 on del corpus, resumimos los resul- tados obtenidos por los participantes, y proponemos algunas conclusiones al respecto de la detecci\u00b4 on de par\u00b4 afrasis when they are semantically equivalent, re- gardless of the cause that led to that equiv- alence (Das and Smith, 2009). Detecting paraphrased text is a task that has aroused the interest of the Natural Language Process- ing (NLP) community, due to the fact that multiple such as plagia- rism detection, question-answering and ma- chine and se- mantic, as are identified ac- Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 255-263 recibido aceptado 21-07-2022 ISSN 1135-5948. DOI 10.26342/2022-69-22 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje NaturalTopic of the document No. of lines sushi 28 molecular cuisine 21 tequila 25 kebab 25 day of the dead 25 vegan food 25 street food 25 Table 1: Topic and number of lines in documents. quisition, back-translation, multiple transla- tions. The PARMEX task has the first time at IberLeF 2022 (Montes- y-G\u00b4 omez et al., 2002), a shared evaluation campaign for NLP systems in Spanish and other iberian languages, which is part of the SEPLN congress. The task is based on the Gastronomy Corpus, by the Lan- guage Engineering Group, which to cuisine, has been manually compiled in therefore, contains some terms sions specific to the Mexican variant of Span- ish. The rest of their paper is organised as follows. Section 2 presents the evaluation framework used at PARMEX 2022. Section 3 shows an overview of different approaches taken to tackle the problem. Section 4 re- ports and analyses the the teams that have participated. Finally, Section 5 presents our conclusions from this shared task. 2 PARMEX 2022 Corpus and evaluation framework For the PAR-MEX at Iberlef 2022 task, we created a corpus comprised of sentence pairs in Mexican Spanish. For the creation of the sentence pairs, first these seven texts had a variable num- ber of lines. On Table 1 the exact number of lines and topics per document are shown. The second step in the creation of the cor- pus was the generation of the paraphrased documents. These new documents were cre- ated by humans with identical semantic con- tent and same number of lines as the orig-TopicNo. of paraphrased documents sushi 7 molecular cuisine 31 tequila 7 kebab 7 day of the dead 8 vegan food 6 street food 6P72 Table 2: Topics docu- an original document with 28 lines, seven paraphrased documents were created. The 28 lines in each one these seven paraphrased documents contained the exact same meaning as the 28 lines in the original document. The process described above was repeated for every one of the seven original documents. Then, we generated a total of 72 paraphrased documents. The exact numbers can be seen on Table 2. The next step in the elaboration of the task's corpus was the creation of the sentence pairs, and their respective labels. For this, we paired each line in every original document with each line in every paraphrased docu- ment. If the sentence pair was made up of a line in an original document with an index ofi, and one line in a paraphrased document with an index i, then it would be labeled as \"paraphrase\". In the opposite case, the one in which a sentence in the original document with index iwas matched with a sentence from another document but with an index of j(given that i=j), then that sentence pair would \"not paraphrase\". It is important to mention that even if the index of an original document and the index of a paraphrased document were equal, it was also verified that the line from the paraphrased document belonged to the same topic as the line from the original document. For exam- ple, if line ifrom document vegan food.txt was line tequila.txt, this pair differ due their topics even though Bel-Enguix, sushi 41 molecular cuisine 214 tequila 84 kebab 63 day of the dead 75 vegan food 42 street food 51P750 Table 3: Number of high-level paraphrase pairs per original same. Therefore, in order to obtain the paraphrase sentence-pairs, the topic and the indices were compared. The final step in the creation of the cor- pus was the addition of the high-level para- phrase pairs. For this, we requested hu- several original documents with high-level paraphrase. During this step, we did not ask them to write paraphrased documents with the same number of lines as the original documents. Once created these novel documents with high-level para- phrases, we extracted some lines and paired them with number of high-level paraphrase-pairs can be observed in Table 3. After the pairing of the sentences, and the creation of their respective labels, a to- tal of 10,298 sentence-pairs were obtained. this set, 1,844 with the remaining 80% labeled as not paraphrase. From this set, we created the training, validation and test partitions. The distribution of these sets is shown on Ta- ble 4. 3 Overview of the Submitted Approaches In this edition, six teams submitted one or more solutions to the task through Number training, validation and evaluation sets. a robust open-source framework for running competitions that involve results or code sub- mission. in consists as input the predictive sys- tems. It returns a performance evaluation based on the metrics defined for each task. This section presents a summary of the submitted in General Clean Data for Paraphrase Identification in Mexican Spanish (Tamayo, Burgos, and Gelbukh, 2022) - Team name: NLP-CIC-TAGE - Summary: The participants pre- sented para- phrase identification data in Spanish. used BERTIN, a pre-trained model on the Spanish portion Overview of PAR-MEX at Iberlef 2022: Paraphrase Detection and parameter logistic regression and forest model (Ta et al., 2022) - Team Summary: The participants used They modified noises for the gen- have a random rate and the exact size of the hidden layer of They also in- cluded a rule pairs in positive examples and additional unlabelled data in the same domain Summary: in the posi- tive examples introducing a tion The participants per- formed and For the final submission, they used the \"bert-base-cased- finetuned-mrpc\" model, which generalization capability. However, they did not present these strategies in the final submission. 4 Experimental Evaluation and Analysis of the Results This reviews lef Paraphrase Detection in Shared and compare the on the paraphrase (P) as the primary performance measure and to rank all the participants. We launched a Codalab competition to manage the shared task stages and compute the performance metric for all submissions. We Representation from Transformer (BERT) model (Devlin et al., 2019). We use the base model for our base- line, consisting of twelve Transformer blocks and the pre-trained model BETO (Ca nete et al., 2020), a BERT model trained on an enor- mous Spanish corpus. We use four epochs and the Adam optimizer for the fine-tuning stage with a learning rate of 2e-5. We use the HuggingFace implementation (Wolf et al., 2020) for Tensorflow (Abadi et al., 2015). In order to have comparable results with the participant submissions, we report the best result in five runs different random seeds. Table 6 the results by each team and our baseline in the PAR- MEX shared task. We report the F1 score in both Paraphrase and Non-paraphrase classes, the macro F1 score, and the accuracy. In this edition of the PAR-MEX shared task, the approach submitted by the NLP-CIC-TAGE team outperformed all the other approaches and the baseline. The NLP-CIC-TAGE team used an approach based architecture; they fine-tuned the RoBERTa model pre-trained in a In the second-best These results show that classic approaches are still competitive for this task compared to deep learning. We use the Maximum Possible Accu- racy (MPA) and Coincident Failure Diversity (CFD) Suganthan, and Yao, 2006) to analyse the complementariness and the diversity of the predictions of the sub- mitted approaches. The MPA is accuracy, defined the correct the correct label to it. MPA metric, we can detect the misclassified instances all teams. The CFD metric has a minimum value of 0 when all classifiers are always correct or when all classifiers are ei- ther correct or wrong. On the other hand, it has a maximum value of 1 when at most one classifier will fail on any randomly chosen in- stance (Kuncheva and Whitaker, 2003). The CFD is defined in equation 1. CFD = 0, p0= 1.0; 1 rics by grouping the proposed approaches on We ate four groups: paper, least two the general approach, tradi- tional machine train these machine learn- ing models complement each other. In the same way, the combination of transformers and machine learning approaches obtain the highest MPA performance and have an av- accuracyMPA CFDNumber systems different proposed approaches. individual approaches. Finally, the values for the CFD score are comparable among ap- proaches, which means predictions that traditional and approaches learn different information from text pairs. Table 8 shows the results of the F1 score for the paraphrase class divided by topic in the test set. The kebab category achieved the highest performance with an average F1 score of 0.9483; on the other hand, the sushi topic had the worst performance with an average F1 score of 0.7659. The NLP-CIC-TAGE team obtained the best performance in two of the seven topics. In contrast, the T\u00a8 u-Par team obtained the best performance in four topics, including the sushi, which is the hard- est. Nevertheless, the difference was in the first place in the PAR-MEX shared task. Tables 9 and 10 show the performance of each team by topic and low-level paraphrase and high-level vegan and food truck topics have examples of the sushi topic only has example of this type of paraphrase. When comparing high- level low-level paraphrase performance, substantial in topic; the average result in high-level paraphrases is while low- level is means a 0.2586 levels. topic balanced, we can conclude that the performance difference is to the difficulty identifying outperform teams in of the three examples; in the remaining topic, Transformers-based and traditional machine learning approaches have the same performance. Therefore, we can conclude that Transformers can learn better features to identify high-level paraphrases. On the other hand, when with paraphrases, a traditional machine learning approach of 7 topics. A Transformers-based approach has the highest performance in test set by topic and low-level paraphrases. three topics. With these results, we can conclude that machine learning models can handle low-level paraphrasing better than complex models like transformers when as shows each team's performance only on the paraphrase type. Again, the results are consistent with what we show in tables 7 and 8. Although the NLP-CIC-TAGE team does not obtain the best result in every topic in the test set, their overall performance is the best on both levels of paraphrasing. 5 Conclusions This paper described the design and re- sults of the PAR-MEX shared task collocated with IberLef 2022. PAR-Mex is focused in paraphrase identification in Mexican Spanish texts. This has been the first edition of the task. The data set of PAR-MEX included both, low-level and high-level pairs of paraphrases, although they were not distinguished for the participants. The analysis of the results shows that, whereas low-level paraphrase iscurrently an easy task for natural language processing (0.90 of average), high-level para- phrase is a problem that has not been conve- niently approached yet. The best results in this shared task were obtained by a team that proposed to ap- proach with strategies similar re- sults. Indeed, while deep learning techniques have the best scores in the sub-corpora of molecular vegan food sushi and food truck, traditional methods lead in day of the dead, kebab and tequila. The only topic in which transformers reach a clearly bet- ter score is food truck. This shows this is a complex task and that collaboration between models and the use of multiple variables can improve the final outcome of the research. Acknowledgments We acknowledge the support of the projects CONACyT CYT the computing resources provided through the Deep the test set by topic and high-level para- phrases. Molecular cuisine, kebab and tequila task on the test set by paraphrase type. guage Technologies of the INAOE E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefow- icz, L. Kaiser, M. Kudlur, J. Levenberg, D. Man\u00b4 e, R. Monga, S. Moore, D. Mur- ray, C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan, F. Vi\u00b4 egas, O. Vinyals, P. Warden, M. Wat- tenberg, M. Wicke, Y. Yu, and X. Zheng. 2015. TensorFlow: Large-scale machine learning on heterogeneous systems. Soft- ware Brando-Le-Bihan, G. Ho, Kang, and J. P\u00b4 erez. 2020. Span- ish pre-trained bert model and evaluation data. In PML4DC at ICLR 2020 . Das, D. and N. A. Smith. 2009. Paraphrase identification as probabilistic quasi-synchronous recognition. In Pro- ceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 468-476, K. Pre-training deep bidirectional transformers for lan- guage understanding. In Proceedings of the 2019 Conference of the North Amer- ican Chapter of the Association for Com- putational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) , pages 4171-4186, Minneapolis, Minnesota, June. Association for Compu- Evaluation Forum (IberLEF 2022) . Kong, L., Z. Han, Y. Han, and H. Qi. 2020. A deep paraphrase of diversity classifier ensembles 51:181-207, 05. Meque, A., F. Balouchzahi, Rangel, Casavantes, \u00b4Alvarez-Carmona, G. Bel-Enguix, and R. Valencia- Garc\u00b4 a. 2002. Proceedings of IberLeF 2002. Rahman, A., H. Ta, L. Languages Evaluation Forum (IberLEF 2022). H., A. Rahman, Najjar, and A. Gel- bukh. 2022. GAN-BERT, Iberian Languages Evaluation Forum (IberLEF 2022). Tamayo, A., D. A. Burgos, and A. Gelbukh. 2022. Using transformers on noisy vs. clean data for paraphrase identification mexican the Iberian Languages Evaluation Forum (IberLEF 2022) . Tang, E. K., P. N. Suganthan, and X. Yao. 2006. An analysis of diversity measures. Machine learning , 65(1):247-271. Wolf, T., L. Debut, V. Sanh, J. Chau- mond, C. Delangue, A. Moi, P. Cis- tac, T. Rault, R. Louf, M. Funtowicz,J. Davison, S. Shleifer, P. von Platen, C. Ma, Y. Jernite, J. Plu, C. Xu, T. L. Scao, S. Gugger, M. Drame, Q. Lhoest, and A. M. Rush. 2020. Transformers: State-of-the-art natural language process- ing. In Proceedings of the Con- ference Spanish Author Profiling for Political Ideology de la tarea PoliticEs 2022: Perfilado del Autor Espa nol por su tica Inform\u00b4 atica, Universidad de Murcia, Campus de Espinardo, 30100, Spain 2Computer Science Department, SINAI, CEATIC, PoliticEs 2022 shared task, organized at Iber- LEF 2022 workshop, within the framework of the 38th International Conference of the Spanish Society for Natural Language Processing. This task aims to extract the political ideology from a given user's set of tweets. Specifically, it focused on the of the gender and the profession, as demographic traits, and 14 presented systems. Most of the teams transformer-based approaches, some of them machine learning algorithms even art\u00b4 culo presenta la tarea PoliticEs 2022, organizada en el taller IberLEF 2022, en el marco de la 38 edici\u00b4 on del Congreso Internacional de la Sociedad Espa nola para el Procesamiento del Lenguaje Natural. Esta tarea tiene como obje- tivo extraer la ideolog\u00b4 a pol\u00b4 tica de un usuario a partir de un conjunto de tuits pub- licados por \u00b4 el. En concreto, se centr\u00b4 o en la identificaci\u00b4 on del g\u00b4 enero y la profesi\u00b4 on, como rasgos demogr\u00b4 aficos, y la ideolog\u00b4 a pol\u00b4 tica desde una perspectiva binaria y multiclase, como rasgo psicogr\u00b4 afico. La tarea PoliticEs atrajo a 63 equipos que se inscribieron a trav\u00b4 es de CodaLab. Finalmente, 20 enviaron resultados y 14 presen- taron art\u00b4 culos describiendo sus sistemas. La mayor\u00b4 a de los equipos propusieron enfoques basados en transformers, aunque algunos de ellos tambi\u00b4 en utilizaron algo- ritmos tradicionales de aprendizaje autom\u00b4 atico o incluso una combinaci\u00b4 on de ambos enfoques. Palabras clave: Perfilado de usuarios, ideolog\u00b4 a pol\u00b4 tica, trait that can be used to understand individual and social behaviour, including moral gathered data 21 countries and found a correlation between political ideology and the big five personality traits.For instance, he found that conscientiousness is strongly correlated right wing, whereas experience agree- ability were notably to the left wing. Moreover, our political ideology has a great influence in our daily lives. For example, Baumgaertner, Carlisle, and Just- wan (2018) found a ideology 2022 (Montes-y G\u00b4 omez et al., 2022) Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 265-272 recibido aceptado 21-07-2022 ISSN 1135-5948. DOI 10.26342/2022-69-23 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Naturalaims to extract political ideology information from texts. For this, an author profiling task is proposed. It is focused on the identification of the gender, the profession, and the polit- several shared tasks have been organized on author analysis under the PAN workshop series (Bevendorff et al., 2021). The novelty of the PoliticEs task is that, to the best of our knowledge, none of these previous tasks have focused on politi- cal ideology. The rest of the paper is organized as fol- lows. Section 2 describes competition. Section summarized the discussion 6 concludes the paper with some in- sights and future works. 2 Task description The PoliticEs shared task consists of extract- ing the gender and profession as and given user's tweets. Political ideology is considered as a binary (pib) and problem shared task are: 1. Extracting political ideology from a text collection. To the best of our knowledge, this is the first Spanish shared task fo- cused on this. 2. Multi-class classification. different The competition par- ticipants were provided with a subset of the training data to familiarize with the train- ing data format, and with a notebook with a baseline based on Bag of Words (BoW) to have a starting point for system development. Later, they were provided with the full train- ing set to develop their approaches. For this, they were allowed to make a maximum of 100 submissions in CodaLab. It should be men- tion the test partition was provided for the participants to label it using the developed systems. This partition was used to evaluate the teams. They were allowed to make a maximum of 10 submissions through CodaLab, from which each team had to select the best one for rank- ing. The ranking was determined using the arithmetic ideology. 3 The dataset for this shared task is an exten- sion of the Spanish PoliCorpus 2022 (Garc\u00b4 a- D\u00b4 az, Colomo-Palacios, and Valencia-Garc\u00b4 a, 2022), which consists of a set of tweets from the timelines of the Twitter accounts of politicians and journalists in Spain. The politicians are members of the government, congress and senate of Spain along to press, from Spanish newspapers such as ABC, El Pa\u00b4 s, ElDiario, El Mundo or La Raz\u00b4 on a binary axis (left, right) and a multi- class axis right, by replacing all mentions with the token @user, except for the real users, that were en- coded with the token @user and a correlative Jos\u00e9 Antonio Garc\u00eda-D\u00edaz, Salud Mar\u00eda Jim\u00e9nez-Zafra, Mar\u00eda-Teresa Mart\u00edn Valdivia, Francisco Garc\u00eda-S\u00e1nchez, L. Alfonso Ure\u00f1a-L\u00f3pez, Rafael We did traits identification. The final dataset is composed around 400 different users with at least 120 tweets. For the shared task, training and test sets were released (80%-20%). We released the dataset in two splits: training and testing. However, in the first stages of the competi- tion, we released an early birds dataset com- posed a subset of 5,000 tweets from the training dataset. It is worth noting that the accounts from training and testing are com- independent trait are shown in Table 1. 4 Participant approaches The shared task attracted 63 teams that registered in CodaLab, of which 20 submitted results and 14 presented working notes describing their systems. The follow- ing brief summary of the participants' proposals: (1st) LosCalis (Carrasco and Rosillo, 2022). This system is based on transformers (Vaswani et al., 2017). It combines BETO nete et al., 2020) and MarIA (Guti\u00b4 errez Fandi no et al., 2022), and employs both architectures for document level characteristics ex- traction together a Multi-Layer Perceptron for labels a pretrained BETO model (Ca nete et al., 2020) in the political domain, based on the use of domain adaptation and test data at a tweet level. These predictions are then merged through a majority vote to deter- mine the labels of a given author based on their tweets. (3rd) Alejando Mosquera (Mos- 2022). He explores the use of L2-regularized logistic regression model based and character n-grams features along with readability features. This work is notable for the analysis of adversarial attacks on the al., de- fines different classification models per each fine- The authors evaluate multiple feature sets, and deep learning and machine learning models. They also explore data augmentation and deep learning ap- proaches. (7th) I2C (Ramos et al., 2022). Their proposal is based on the used of transformers (Vaswani et al., 2017). For gender extraction, they build an ensem- ble as a set of pre-trained transform- ers models (RoBERTa (Liu et al., 2019), ALBERTI1and BERTIN (De la Rosa et al., 2022)). For the identification of the profession, the tweets of each user are merged to binary and multi-class classifica- deep learning (Multi- Finally, use transition point analysis with lem- mas using TF-IDF and Random Forest classifier. For the classification ideology, classification an average Training Test Total GenderMale 177 69 246 Female 136 36 172 ProfessionPolitician 251 80 331 Journalist 61 26 87 Binary ideologyLeft 178 57 235 Right 135 48 183 Multiclass ideologyModerate left 102 36 138 Left 76 21 97 Moderate right 94 31 125 Right 41 17 58 Table 1: Corpus statistics per trait. (9th) consisting fine-tuning (Ca nete et al., 2020) and DistilBETO (Ca nete et al., 2022). (13th) UNED (Rodrigo, Fabregat, and Centeno, 2022). This team ex- plores two approaches. The first is based on second uses taining the best results. (14th) THANGCIC (Ta et al., 2022). They present a system based on multilingual BERT (Kenton and Toutanova, 2019), fine-tuned for and Mart\u00b4 nez Unanue, 2022). This team explores two machine learning gorithms module that combines character and word features with two different with from MarIA (Guti\u00b4 errez Fandi no et al., 2022), a Spanish RoBERTa using Logistic and with a saga solver. INFOTEC-LaBD (Cabrera, Tellez, and Miranda, 2022). The proposal of these authors is based on a low- dimensional stacking and competitive user profiling models. The results of this team were late in the challenge, due to a confusion with the deadline. 5 Results and discussion The official of the PoliticEs shared task is shown in Table 2. It can be seen the results of the 19 participants that submitted results in time, plus the results of the baseline provided as a notebook, plus the results of the INFOTEC-LaBD team, which submitted a few hours late due to a mistake. Jos\u00e9 Antonio Garc\u00eda-D\u00edaz, Salud Mar\u00eda Jim\u00e9nez-Zafra, Mar\u00eda-Teresa Mart\u00edn Valdivia, The system that obtained the overall high- est performance was LosCalis, with an aver- age macro-f1 of 0.90226, combining BETO and MarIA for with a Multi-Layer was followed Alejan- dro with an Alejandro and character per trait, hand, in relation to the demographic traits, gender has been the most difficult for the par- ticipants to classify and, on the other hand, with respect to the psychographic trait, po- litical ideology, the multi-class classification has been the most complex. Concerning the approaches used, most of the teams propose approaches based on tilingual BERT), fine-tuning also ditional machine fre- quent. are models for the identification of each trait, although most use a single model for all of them. Some of them also combine different approaches through ensemble learning and only one team explores data augmentation techniques. 6 Conclusions This paper presents the first edition of the PoliticEs task at IberLEF 2022. It is an au- thor profiling task for political ideology in Spanish. So far, several tasks on author- ship analysis have been organized in the PAN workshop series (Bevendorff et al., 2021), but none of them focuses ide- ology. ideology that to profil- ing research for political ideology in Spanish through the organization of this shared task. We are very pleased with the impact of the PoliticEs task, as 63 regis- tered for it through the competition results and 14 presented working notes to describe their systems, which are summarized in this paper. Overview of solutions presented by ticipating teams, but some of them also used traditional machine learning systems or even a combination of them. Finally, it should be mentioned that gender political have the traits most difficult to classify for the participants. As future work, we plan to extend the dataset by including more users who are ask users to voluntarily sent their tweets at the same time they define their political spec- trum. Another idea is to include more sub- author analysis. For add a subtask related to stance detection, in order to determine which authors are in favor of certain topics and which users are against. We can use this information to define clusters of users and to observe whether there is a relationship be- tween the topics and Europe, and Garc\u00b4 a-D\u00b4 az has been supported by Banco Santander and University of Murcia through the industrial doctorate programme, and Salud Mar\u00b4 a Jim\u00b4 enez-Zafra has been partially supported by a grant from Fondo Social Europeo and Administraci\u00b4 on de la Junta de Andaluc\u00b4 a (DOC 01073). References Baumgaertner, B., J. E. Carlisle, and F. Just- wan. 2018. The influence of political ide- ology and on willingness nate. PloS one, 13(1):e0191728. Bevendorff, J., B. Chulvi, G. L. D. L. Pe na Sarrac\u00b4 en, M. Kestemont, E. Man-javacas, I. Markov, M. Mayerl, M. Pot- thast, F. Rangel, P. Rosso, Cross- Language Evaluation Forum for European Languages, pages 419-431. Springer. Cabrera, H., E. S. Tellez, S. Miranda. 2022. INFOTEC-LaBD at na, . Ca nete, J., G. Chaperon, R. Fuentes, J.-H. Ho, H. Kang, and J. P\u00b4 erez. 2020. Span- ish pre-trained at , 2020:1-10. Ca nete, J., S. Donoso, F. Bravo-Marquez, A. Carvallo, and V. Araujo. 2022. Al- beto and distilbeto: Lightweight span- ish language models. arXiv preprint arXiv:2204.09145. Carrasco, S. S. and R. C. Rosillo. at PoliticEs 2022: Political Au- thor Coru na, Spain . De la Rosa, J., E. G. Ponferrada, M. Romero, P. Villegas, P. G. de Prado Salas, and M. Grandury. 2022. Bertin: Efficient pre- training of a spanish language model us- ing perplexity sampling. Procesamiento del Lenguaje Natural, 68:13-23. Espin-Riofrio, C., J. Ortiz-Zambrano, and A. Jos\u00e9 Antonio Garc\u00eda-D\u00edaz, Salud Mar\u00eda Jim\u00e9nez-Zafra, Mar\u00eda-Teresa Valdivia, Francisco Garc\u00eda-S\u00e1nchez, L. Ure\u00f1a-L\u00f3pez, Rafael Valencia-Garc\u00eda 270evaluation of Nat- Lenguaje 142. on spanish politicians' amies, J. Llop Palao, J. Sil- veira Ocampo, C. Pio Carrino, C. Ar- mentano Oller, C. Rodriguez Penagos, A. Gonzalez Agirre, and M. Villegas. 2022. MarIA: Spanish language models. Procesamiento del Lenguaje Natural , 68. Holgado, C. G. and A. Sinha. 2022. HalBERT at PoliticEs 2022: Are Ma- na, Spain . Kenton, J. C. and K. Toutanova. 2019. BERT: Pre-training of Bidi- Proceedings of HLT, pages 4171-4186. Liu, Y., M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettle- moyer, and V. Spain G\u00b4 M., Gonzalo, F. Rangel, M. Casavantes, M. \u00b4A.\u00b4Alvarez-Carmona, G. Bel-Enguix, H. Jair a, e, and R. Valencia- Forum (IberLEF Alem\u00b4 2022. TeamMX at PoliticEs 2022: Analy- sis of Sets na, Spain. Ramos, P. C., J. M. V\u00b4 azquez, V. P. \u00b4Alvarez, and J. L. na, Spain . Rodrigo, \u00b4A., H. and R. PoliticEs 2022: Test- ing Approximate Nearest Neighbors and Pro- Ideology. S. Montalvo Her- ranz, Santib\u00b4 Coru na, Spain . Ta, H. T., A. B. S. Rahman, L. Najjar, and A. Gelbukh. 2022. THANGCIC at na, . Vaswani, A., N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin. 2017. At- tention is all you need. Advances in neural information processing systems, 30. Verhulst, B., L. J. Eaves, and P. K. Hatemi. 2012. Correlation not causation: The re- lationship between personality traits and political ideologies. American journal of science, 56(1):34-51. Villa-Cueva, E., I. alez-Franco, Spain. Jos\u00e9 Antonio Garc\u00eda-D\u00edaz, Salud Mar\u00eda Jim\u00e9nez-Zafra, Mar\u00eda-Teresa Mart\u00edn Valdivia, Francisco Garc\u00eda-S\u00e1nchez, IberLEF 2022: Preguntas sacastro@umich.edu Abstract: We present the results of the the problem of Question Answering from texts. For both training and evaluation we use the QuALES corpus, a corpus of Uruguayan media news about the Covid-19 pandemic and related topics. We describe the systems developed by seven partici- pants, all of them based on different BERT-like language models. The best results were obtained using the multilingual RoBERTa model pre-trained with SQUAD-Es- V2, fine tuning on the QuALES corpus. Keywords: Question Resumen: Presentamos los resultados de tarea QuALES, que aborda el problema de B\u00b4 usqueda de Respuestas extractiva a partir de textos. Tanto para entrenamiento como para evaluaci\u00b4 on utilizamos el corpus QuALES, un corpus de noticias de medios uruguayos sobre la pandemia por Covid-19 y temas relacionados. Describimos los sistemas desarrollados por siete participantes, todos ellos basados en diferentes mo- delos de lenguaje tipo BERT. Los mejores resultados se obtuvieron usando el modelo RoBERTa multiling\u00a8 ue preentrenado con SQUAD-Es-V2, con una fine tuning sobre el corpus QuALES. Palabras clave: B\u00b4 usqueda de Respuestas en Espa nol, Modelos de Lenguaje, Cor- pus para B\u00b4 usqueda de Respuestas. 1 Introduction Question Answering (QA) is a classical Na- tural that is cu- rrently gaining great semantic analysis, where the question is transformed to a query to a knowledge database; and open domain question answering, where, starting from a question written in natural language and a set of documents, the answer to the question is obtained using methods field (IR) (Manning, Raghavan, and Sch\u00a8 utze, 2010), possibly one of the most widely studied topics in NLP, with web search engines as their most noti- ceable product, b) extracting the answer from those documents. Each of these stages has its own challenges, and the whole task requires a successful outcome for each of them and for their integration. In this task we address the problem of ex- tractive QA in Spanish, based on a corpus of a specific domain: press news about the Covid-19 pandemic. We focus on the second stage of the task: given a text, extracting the Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 273-280 recibido aceptado 24-07-2022 ISSN 1135-5948. DOI 10.26342/2022-69-24 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Naturalanswer to a question, if there is one. The rest of the paper is structured as fo- llows: section 2 Spanish; section 3 describes the created for this task other resources; section 4 the QuALES results; and, finally, section 6 shows some conclusions. 2 Background Starting last decade, along with the of Xiong, Zhong, and Socher, 2017; Seo et al., 2016). All these supervised learning approaches were possible due to the existence oriented publicly These ning, but also constant monitoring of this area's state of the art. Probably the most popular is SQuAD (Rajpurkar et al., 2016). To build this dataset, annotators were pre- sented with a Wikipedia paragraph and as- ked to write questions that could be ans- wered from the given Ques- tions (Kwiatkowski et al., 2019b) was crea- ted from actual Google Search queries, where annotators marked the answer into Wikipe- dia article snippets. TriviaQA et al., of over 100,000 human-generated question- answer pairs, based on set of over 10,000 news articles from CNN. In the last few years, after the publica- tion of models based on the Transformers architecture (Vaswani et al., 2017) for sol- ving sequence to sequence problems, and particularly language models such as BERT (Devlin et al., 2018) and AL- BERT (Lan et al., 2019), there has been a new push in system performance, particu- larly for the English language. These kinds of models are trained in an self-supervised way, using large volumes of data and computingpower. After that stage (called pretraining), they can be easily fine-tuned to apply them to different tasks. Regarding this shared task, we are particularly interested in fine-tuning them to the open domain question answering task. The study of the QA area is currently very active, as evidenced by the inclusion of a tu- torial1on this ACL 2020, the main years, several QA related tasks have been proposed. Since a cer- good, bad, or potential, and answer yes/no questions. The challenge was reranking correct answers recipes and CoQA (Conversational Question Answering) dataset is answers, obtained from text The goal of the CoQA challenge is to measure the ability of machines to un- derstand a text passage and answer a series of interconnected questions that appear in a conversation. The Stanford Data- set (SQuAD) (Rajpurkar et al., 2016) highest systems on Etcheverry, Santiago G\u00f3ngora, Santiago Goycoechea, Juan Machado, Guillermo Moncecchi, Juan Jos\u00e9 Prada, Dina Wonsever 274F1 values (see the next section for a descrip- questions, in- cluding questions that do have dataset. Based on Google's Natural Questions Da- taset (Kwiatkowski 2019a), the machine learning platform includes a Question Answering competition, where the goal is to predict short and long answer res- ponses to real questions about Wikipedia ar- ticles. Using the same dataset, the 2020 Neu- rIPS Conference an open domain question challenge (Min et al., 2021) was also proposed, ques- tion answering systems. For the BioASQ challenge for 2022 proposes a task relative to the composed by biome- dical articles. Spanish evolved much more slowly. However, similar language re- sources have been created for this language, which makes us think it is possible to study and fine-tune current architectures to obtain competitive results. In particular, there BERT for Spa- nish, dubbed BETO (Ca nete et al., 2020), and a version of SQuAD (the main dataset for training and evaluating open domain QA systems) translated to Spanish (Rajpurkar et al., 2016; Carrino, a, Fonollo- sa, texts from a mix from different news-wire and literature sour- ces, and it includes 18,817 questions with the annotation textual contexts (Guti\u00b4 errez Fandi no et 2003 which included Spanish data- sets. For example, together with the CLEF 2009 wering Task over European legislation was (Pe et al., 2009). The task con- sisted of extracting a relevant paragraph of text that included the answer to a natural language question. During CLEF 2010, the task was expanded (Pe nas et al., 2010) to in- clude an answer selection task (i.e. besides paragraph, systems collection (150 aligned language), with 200 question-answer pairs provided for evaluation. Unlike the from the one selected for QuA- In addition, they have worked with sma- ller amounts of training and testing data. So- me of these CLEF tasks have some characte- ristics that differ from as datasets to answer multiple choice questions, language questions to be answered from DBPedia structured data (instead of plain text), among other. 3 Corpus We provided a corpus of around 2,600 question-answer pairs (the QuALES corpus). The training set contains 1,000 of these pairs, while the dev and test sets have around 800 pairs each. Participants could use any other data for training as well, in particu- lar SQuAD (Rajpurkar et al., 2016) or News- QA (Trischler et al., 2016). The data at the Codalab competition site3. The QuALES corpus original and it was created manually by the members of the team and students. It is a Question-Answering cor- pus in Spanish obtained from a set of Covid- 19 related news published in two important news media from Uruguay (La Diaria4and Montevideo Portal5). It consists of a set of factoid questions mostly about Covid-19 and its repercussions in Uruguay and the world. Table 1 shows the statistics of the dataset. The corpus annotation was made in two stages: first, we annotated questions by reading only the title and first sentence of the article; then, we thought of questions de- rived from the reading of the whole article. For each question, we annotated the answer found (if there was any) and the whole sen- tence context which included it. For the an- Dev Test Articles 176 146 143 Questions 948 773 759 Answers 1000 800 821 Empty answers 165 132 103 Table wers) text contained in the sentence that consisted in a complete answer for the question. All the answers were directly ex- tracted from the text. Some questions may have more than one answer in a given text, in such cases, a set of answers is generated for this a set of 25 questions, generating a total of 150 questions with two different annotator answers. We obtained an avera- ge Exact Match of 0.61 and an average F1 of 0.76. These results are quite low, which shows the complexity of the task, even for humans. The difference between Exact Match and F1 shows the difficulty in defining the li- mits of the answer, in general the differences are due to the inclusion or not of elements such as prepositions or determiners. The low F1 shows that selecting the fragment that contains the answer, or deciding that a cer- tain fragment has no answer in the text, is also a highly complex task. We also published some resources to au- tomatically generate a Spanish version of the NewsQA (Trischler et al., 2016) corpus. The complete NewsQA corpus was translated using a machine translation model and after that we aligned the answers. question and answer, the substring corresponding to the answer within the fragment, can be trans- lated differently from the associated answer, which is translated decontextualized. In our translation of the corpus, this alignment pro- blem was detected in 49 % of the cases. To solve this problem we worked on two approa- ches: on the one hand we trained a neural model from pairs of aligned texts, and, the other hand, we tested some heuristics de- fined from the analysis of different examples.In order to evaluate the two approaches, we performed a manual evaluation of a subset of 2,000 question-answer pairs. A this was parameter tuning the it not possible to provide a link to this data- set, but the resources to recreate this process are available at our github repository6. 4 Task The aim of the QuALES task is to develop question answering systems that can answer questions based on news articles written in Spanish. The systems get a full news arti- cle and a question, and must find the shor- test span of text in the article (if it exists) that answers the question. It should be no- ted that for some questions there may not be an answer in the given text. est\u00b4 a hablando. The training, development and test datasets were generated from the QuALES corpus, as mentioned above. we to have seeing that the texts often other topics, we de- cided to annotate only one set. Most of the questions in the dataset are about Covid-19 matters, but some of them are also about other topics. Table 2 shows a sample text with two questions. The answer to one of the questions can be found in the text, while the other is not present. As one of our evaluation metrics, we mea- sure average Exact following the approach of also report, following (Reddy, Chen, and Man- ning, 2019), of word overlap: we compare each individual prediction against the different human gold standard answers and select the maximum value as system F1 score for that instan- ce; the system performance is the macro- average of those F1 in the dataset have more than one possible answer, but the sys- Etcheverry, Santiago G\u00f3ngora, Santiago Goycoechea, Juan Machado, Guillermo Moncecchi, Juan Jos\u00e9 Prada, Dina Wonsever 276Comenzaron las clases presenciales en 344 escuelas rurales, con baja asistencia. A las 8.45 dos perros paseaban por el patio de la escuela rural 27 de La Macana, en Florida. Dos maestras con t\u00b4 unicas blancas y tapabocas esperaban a los alumnos que reanudar\u00b4 an las clases presenciales luego de cinco semanas de conexi\u00b4 on virtual. Ya estaba instalado el micr\u00b4 ofono y el parlante en el patio, hab\u00b4 an llegado los inspectores regionales junto con la directora general del Consejo de Educaci\u00b4 on Inicial y Primaria (CEIP), Irup\u00b4 e Buzzetti, que junto a la prensa local esperaban a los ni nos. De los 28 alumnos que asisten regularmente, 14 hab\u00b4 an dicho que no iban a ir y los otros no hab\u00b4 an confirmado. A las 9.00, cuando deb\u00b4 an comenzar las clases en la escuela de La Macana, no hab\u00b4 a ning\u00b4 un ni no. (...) La situaci\u00b4 on de La Macana se repiti\u00b4 o en varias de las escuelas que abrieron este mi\u00b4 ercoles. De las 547 escuelas habilitadas abrieron 344, confirm\u00b4 o a la diaria Limber Santos, director del departamento de Educaci\u00b4 on Rural del CEIP. De esas escuelas, cerca de 90 no recibieron alumnos; Santos estim\u00b4 o que en la ma nana del mi\u00b4 ercoles 1.030 ni nos concurrieron a las escuelas, de un total de 3.900 que concurren a las 547 habilitadas y de 2.838 alumnos que tienen matriculadas las 344 escuelas que abrieron. La asistencia, por tanto, lleg\u00b4 o a 36 % en el primer d\u00b4 a. Q1:\u00bfCu\u00b4 antas escuelas rurales hay en Uruguay? A1:De las [547] escuelas habilitadas abrieron 344, confirm\u00b4 o a la diaria Limber Santos, director del departamento de Educaci\u00b4 on Rural del CEIP. Q2:\u00bfCu\u00b4 ando vuelven las clases presenciales a todas las A2: -not found in the text- Table 2: Example of a short text that could be found in the corpus, and two possible questions for the text. Q1 has the answer 547, found in the text, but Q2 does not have an answer in the text. one answer. Because of this, when there are multiple answers for a question, the metrics evaluate the answer candidate provided by the system against all the possible answers, and get the maximum value. 5 Competition The was run in two phases: a de- velopment phase, for which we released the annotations of the dataset and a test dataset without annotations. Partici- their as the Spanish ver- sion of SQuAD NewsQA. 5.1 Description of the systems Eighteen participants registered for the com- petition in our Codalab eight of them submitted results for the development phase (73 submissions in total), and seven of them submitted results for the evaluation phase (46 submissions in total). their per-formance. The language model most commonly by the participants was RoBERTa for Spa- nish, trained with the corpus the fine-tuning BETO RoBERTa Spanish on a series of QA datasets. The author found out that the top performance was achieved using RoBERTa first trained on SQAC, then on the Spanish version of SQuAD alvarory (Rodrigo and Pe nas, 2022) tried three main approaches. In the first one they fine-tuned RoBERTa for Spanish (base and large versions) and BETO for 10 epochs on the QuALES training set with datasets containing both training and development splits of the task, for a total of 1,800 question-answer pairs. For the second approach they used even more data than the available in QuALES, in order to study among datasets when using two pretrained BERT. The third approach was based on combining different models for re- turning pre-trained language models in Spanish: MarIA-base, MarIA-large and RigoBERTa. These models were fine-tuned on data from the Spanish version of SQuAD (SQUAD-ES- v2), a Spanish version of NewsQA, generated by the author, and QuALES. The best mo- del is an ensemble that gives scores to each answer based on such as the number of models that predict it and the mo- dels' scores. The final predictions were per- formed of by the count of each answer mul- tiplied by a scaling factor based of the models. The participant Bernardo Spanish the SQAC corpus, and distill- BERT pretrained with SQUAD-ES-v2. His submitted were the me- trics the QuALES corpus. He also tested a model that included a fine tuning stage with 2,000 examples from the Spanish translation of the NewsQA corpus, prior to fine tuning with the QuALES cor- pus, which yielded slightly lower results. 5.2 Results We show the best result for each user for each metric. Please notice that the best exact match and F1 scores might have been obtai- ned in different submissions by the same user. Table 3 shows the best exact match the best F1 overlap As can be seen in the tables, best re- sults achieved (F1: 0.73 and are far from those reported on the SQuAD corpus for English on the official site (F1: 0.93 and EM: 0.91). Our task reported there in that the evaluation texts belong to a specific domain (news about the Covid-19 pandemic), and also in the size of the context provided to search for the ans- wers. In our case, the context is a complete news article, which are longer than the con- texts included in the obtained by sebastianvolti, model is based on RoBERTa pretrained on SQuAD 2.0, fine tuned on the QuALES corpus, and was the only participant who used the multilingual Aiala Ros\u00e1, Etcheverry, Santiago G\u00f3ngora, Santiago Goycoechea, Juan Machado, Guillermo Moncecchi, Juan Jos\u00e9 Prada, Dina Wonsever 278version of RoBERTa, four other participants used RoBERTa for Spanish (trained on the BNE corpus). Also note that none of the systems have reached the inter-annotator agreement levels, both for EM and F1, although for F1 the best submission by sebastianvolti is the closest by around 5 %. 6 Conclusions We presented the results of the QuALES competition partici- pants submitted systems to the competition, and the best systems achieved 0.53 in exact match and 0.73 extractive Q&A task, although wing on the main available benchmark, the SQuAD corpus, still presents great challenges when working with different data and searching for answers larger y. 2015. ling of the question answering task in the yodaqa system. In J. Mothe, J. Savoy, J. Kamps, K. Pinel-Sauvagnat, G. Jones, E. San Juan, L. Capellato, and N. Fe- rro, editors, Carrino, C. P., M. R. Costa-juss` a, and J. A. Fonollosa. 2019. Automatic spanish translation the squad G. Chaperon, R. Fuentes, J.-H. Ho, H. Kang, and J. P\u00b4 erez. 2020. Spanish pre-trained bert iclr , P` amies, J. Llop Palao, Ocampo, Oller, C. Rodriguez Penagos, A. Gon- zalez Agirre, and M. Villegas. 2022. Ma- ria: Spanish language models. Procesa- miento del Lenguaje Natural , 68. Joshi, M., E. Choi, D. S. Weld, and Zettle- Jurafsky, D. and J. H. Martin. 2021. Speech and language processing. 3rd edition draft. US: Prentice Hall. Kwiatkowski, T., J. Palomaki, O. Redfield, M. A. Parikh, C. Alberti, D. Eps- tein, I. Polosukhin, J. Devlin, K. Lee, benchmark for question J. Palomaki, O. C. Alberti, D. Eps- tein, I. Polosukhin, M. Kelcey, J. Devlin, K. Lee, K. N. Toutanova, L. Jones, M.- W. Chang, A. Dai, J. Uszkoreit, Q. Le, and S. Petrov. 2019b. Natural questions: a benchmark for question of the Association of Computational Linguistics . Lan, Z., M. Chen, S. Goodman, K. Gimpel, P. Sharma, and R. Soricut. 2019. Albert: A lite for self-supervised learning of language representations. arXiv preprint arXiv:1909.11942. Le, representations of sentences and docu- ments. , 1188-1196. PMLR. LeCun, Y., Y. Bengio, and G. Hinton. 2015. Deep learning. nature, 521(7553):436- 444. Manning, C., P. Raghavan, and H. Sch\u00a8 utze. 2010. Introduction to information re- trieval. Natural Language Engineering, 16(1):100-103. Min, S., J. Boyd-Graber, C. Alberti, D. Chen, E. Choi, M. Collins, K. Guu, H. Hajishir- zi, K. Lee, L. M` arquez, A. Moschitti, H. nas, A., \u00b4A. Rodrigo, R. Sutclif- fe, C. For ascu, and C. Mota. 2010. Over- A., P. Forner, R. Sutcliffe, \u00b4A. Rodri- go, C. For ascu, I. Alegria, D. Giampiccolo, N. Moreau, and P. Osenova. Over- Rajpurkar, P., J. and P. Liang. 2016. Squad: 100,000+ arXiv:1606.05250. Reddy, S., D. Chen, C. 2019. Coqa: A conversational question answering challenge. Transactions of the Association for Computational Linguis- tics, 7:249-266. Rodrigo, A. and A. Pe nas. 2022. Uned@quales 2022: Testing the per- formance of transformer-based language models for spanish question-answering. Seo, M., A. Kembhavi, A. Farhadi, and H. Hajishirzi. 2016. Bidirectional for machine comprehension. ar- Xiv preprint arXiv:1611.01603.Trischler, A., T. Wang, X. Yuan, J. Harris, A. Sordoni, P. Bachman, and K. Sule- transfor- mer A., N. Shazeer, N. Parmar, J. Usz- koreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems, 30. Xiong, C., V. Zhong, and R. Socher. 2017. preprint arXiv:1711.00106. Yu, L., K. M. Hermann, P. Blunsom, and S. Pulman. 2014. Deep learning for Etcheverry, Santiago G\u00f3ngora, Santiago Goycoechea, Juan Machado, Guillermo Moncecchi, Prada, Wonsever 2022: Comprensi\u00b4 on de Lectura y Explicaci\u00b4 on de Razonamiento en Espa nol Marco Antonio task, organized at IberLEF 2022, within the framework of the 38th edition of the International Conference of the Spanish Society for Natural Language Processing. The main goal of this shared-task is to promote the task of Reading Comprehension and Verbal Reasoning. This task is divided into two sub-tasks: (1) identifying the correct alternative generating the reasoning Reasoning Spanish. Resumen: Este art\u00b4 culo presenta la tarea ReCoRES, organizada en IberLEF 2022, en el marco de la 38 edici\u00b4 on de la Conferencia Internacional de la Sociedad Espa nola para el Procesamiento del Lenguaje Natural. El objetivo de esta tarea es promover la tarea de Comprensi\u00b4 on de Lectura y Razonamiento Verbal. Esta tarea es dividida en dos sub-tareas: (1) la identificaci\u00b4 on de la alternativa correcta en preguntas de comprensi\u00b4 on de lectura y (2) la generaci\u00b4 on del razonamiento usado para seleccionar una alternativa. En general, 3 equipos participaron de este evento proponiendo mayormente modelos neuronales basados en transformers con algunas estrategias adicionales. Los resultados de este evento as\u00b4 como aprendizajes y algunos desaf\u00b4 os son presentados, abriendo un abanico de posibilidades como trabajos futuros. Palabras clave: Comprensi\u00b4 on de Lectura, Explicaci\u00b4 on given a Nat- ural Language question. According to Rogers et al. (2020), QA can be approached from two main perspectives: Open which responses are recovered from several sources such as Web pages and knowledge bases, and Reading Comprehension (RC), where the an- swer is recovered from type: (1)span-selection datasets, where ex- plicitly includes the answer, (2) multiple- choice datasets, where systems have to se- lect an answer from a list of candidates; and (3) freeform answers in with the most pop- ular being SQuAD (Rajpurkar 2016). An explicit limitation of these span-selection datasets is that they can only target infor- mation explicitly mentioned in shallow lexical match- Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 281-287 recibido aceptado 21-07-2022 ISSN 1135-5948. DOI 10.26342/2022-69-25 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Naturaling (Rogers et al., 2020). Using a multiple-choice dataset is a com- mon ing comprehension in humans (Echegoyen, \u00b4Alvaro Rodrigo, and Pe nas, 2020). In ad- dition, Rogers et al. (2020) point out that multiple-choice is a better format to assess language understanding of automatic sys- tems. It is because it requires a high degree of textual inference and the development of strategies for selecting the correct Multiple- Entrance Exams (Pe nas et al., 2011) and QuAIL (Rogers et al., 2020). However, that is not the case for most lan- guages. For Spanish, in particular, (EE) (Pe nas et al., 2011). However, these datasets present some limita- tions originated by the nature of the dataset or some aspects like the size. For a span-based QA dataset, answers are included in the text explic- itly. In the case of EE, it is a choice QA dataset in small (43 texts and 191 questions), constraining the exploration of current State-of-the-Art approaches. In order to contribute to the development of research in Question-Answering/Reading Comprehension for Spanish, this shared-task aims more Description This shared-task consists of two sub-tasks: Sub-task 1 - Machine Reading Compre- hension: given a text, a question, and a set candidate answers, a system the correct answer.Sub-task Reasoning Explanation: given a and a question, a system must generate an explanation for its an- selection 3 dataset used in this ex- tracted actual university entrance ex- aminations were PDF by ap- plying two strategies: (1) using an OCR to convert the PDF documents to TXT format and manually correcting organization (1,073 candidate answer1. Figure 1 shows an example of a long text, a question with five alternatives, and the corresponding reasoning. It is worth noting that texts are a sentence that to be com- 4 Experimental Setup 4.1 Baseline We use two for sub-task 1. The first consists of randomly choosing an answer among the alternatives for question, and the second is a BERT-based baseline2, simi- lar to the one used by Rogers et al. (2020). It works this way: for each answer option, available at https://huggingface.co/dccuchile/bert-base-spanish- wwm-cased. Marco Antonio Sobrevilla Cabezudo, Diego Diestra, Rodrigo L\u00f3pez, Erasmo G\u00f3mez, Arturo Oncevay, Fernando Alva-Manchego 282T ext: \"El trabajo es en primer t\u00e9rmino un proceso entre la naturaleza y el hombre, proceso en que este realiza, regula y controla mediante su propia acci\u00f3n su intercambio de materias con la naturaleza. En este proceso, el hombre se enfrenta como un poder natural con la materia de la naturaleza. Pone en acci\u00f3n las fuerzas naturales que forman su corporeidad, los brazos y las piernas, la cabeza y la mano, para de ese modo asimilarse, bajo una forma \u00fatil para su propia vida, las materias que la naturaleza le brinda. Y a la par que de ese modo act\u00faa sobre la naturaleza exterior a \u00e9l y la transforma, transforma su propia naturaleza, desarrollando las potencias que dormitan en \u00e9l y sometiendo el juego de sus fuerzas a su propia disciplina. Aqu\u00ed no vamos a ocuparnos de las primeras formas de trabajo, formas instintivas y de tipo animal. Aqu\u00ed, partimos del supuesto del trabajo plasmado ya bajo una forma en la que pertenece exclusivamente al hombre. Una ara\u00f1a ejecuta operaciones que semejan a las manipulaciones del tejedor, y la construcci\u00f3n de los panales de las abejas podr\u00eda avergonzar, por su perfecci\u00f3n, a m\u00e1s de un maestro de obras. Pero, hay algo en que el peor maestro de obras aventaja, desde luego, a la mejor abeja, y es el hecho de que, antes de ejecutar la construcci\u00f3n, la proyecta en su cerebro. Al final del proceso de trabajo, brota un resultado que antes de comenzar el proceso exist\u00eda ya en la mente del obrero; es decir, un resultado que ten\u00eda ya existencia ideal. El obrero no se limita a hacer cambiar de forma la materia que le brinda la naturaleza, sino que, al mismo tiempo, realiza en ella su fin, fin que \u00e9l sabe que rige como una ley las modalidades de su actuaci\u00f3n y al que tiene necesariamente que supeditar su voluntad. Y esta supeditaci\u00f3n no constituye un acto aislado. Mientras permanezca trabajando, adem\u00e1s de esforzar los \u00f3rganos que trabajan, el obrero ha de aportar esa voluntad consciente del fin a que llamamos atenci\u00f3n, atenci\u00f3n que deber\u00e1 ser tanto m\u00e1s reconcentrada cuanto menos atractivo sea el trabajo, por su car\u00e1cter o por su ejecuci\u00f3n, para quien lo realiza, es decir, cuanto menos disfrute de \u00e9l el obrero como de un juego de sus fuerzas f\u00edsicas y espirituales.\" Question: Medularmente, el autor intenta dilucidar: Alternatives: A. las diferencias entre lo instintivo y lo planificado. B. la naturaleza del trabajo exclusivamente humano. C. el car\u00e1cter pernicioso del trabajo en la actualidad. D. la supremac\u00eda de la naturaleza frente a la humanidad. E. las etapas que componen el proceso productivo. Answer: B Reason: El autor busca caracterizar el trabajo humano frente a lo instintivo, se\u00f1ala as\u00ed que el trabajo humano est\u00e1 supeditado a un fin.Figure 1: ReCoRES's Example. used as input, and the probabil- ity, and the most likely option is selected as the answer. Among the settings, we train the model for 1 epoch and use a learning rate of 3e-5 with Adam optimizer. The baseline for sub-task 2 is a T5-based one that receives the text and the question as inputs and returns the reason3. In addition, we evaluate a train model, similar to the first baseline. The parameters the best results respectively, a learning rate of 0.003 with Adafactor optimizer, and a batch size of 8 with 4 we freeze the embedding layer. Finally, we select the model with the best perplexity in the development set after 7 epochs. During prediction, we use a beam size of 5. Evaluation Sub-task 1 is evaluated in two ways. Firstly, we will evaluate the accuracy, i.e., the num- ber of correct answers in relation to the total number of questions. The second measure is c@1 (Pe nas and Rodrigo, 2011), used at CLEF (Rodrigo et al., 2015). they are certain. Sub-task 2 is evaluated in two as at Reading Comprehension and for running au- tomatic semantic metrics the generated explanation ual will use this metric instead of classical BLEU (Papineni et al., 2002), or METEOR (Banerjee and Lavie, 2005) be- cause \"reasons\" can be open and diverse. The second one is a manual evaluation of three quality criteria: Accuracy, to measure how orig- inal output; Fluency (Howcroft et al., 2020), that measures the degree to which a text \"flows well\u00a8 and is not e.g. a sequence of unconnected parts. Readability (Howcroft et al., 2020), that measures if the output system is under- standable or easy to read. To perform the manual evaluation, we re- cruit some crowdworkers. In particular, these were undergraduate students who had expe- rience in this 1-5, 1 the worst and 5 the best. 5 Participants In this edition, 3 teams registered on the task and submitted results. However, presented working tems. The proposals submitted: 5.1 MRCPUCP This team only participated in the sub-task 16. They proposed a BERT-based approach in which all text, alternatives, and reason- ing are concatenated and used as input, and the output is one of the alternatives. They used BETO as BERT-based model for Span- ish (similar to the baseline) and finetune the model on the dataset they built. 5.2 SADA (Baggetto et al., 2022) This team only participated in the sub-task 1. The authors explore generative models, generation systems, and dataset expansion. In experiments, the 6This team did not present working notes for the present shared-task.Sub-task 1 Team Nandezgarcia la Rosa Fern\u00b4 andez, 2022) mod- els for the task of approach presents the results for the sub-task 1 and sub-task 2. For sub-task 1 (Reading Comprehension), the best performance was obtained by the MRCPUCP team, and the SADA team obtained the second-best one, only 3 points lower than the first one. It is worth noting that all teams used pre- trained models such as BERT (Devlin et al., 2019) or T5 (Raffel et al., 2020) in conjunc- tion with some additional strategies. Among the strategies, we can highlight the use of reasoning as part of the input and its help- fulness in getting the correct answers in the reading comprehension task. On the other hand, multilingual information has proven to be helpful, even when the domains are differ- ent. Concerning sub-task 2, the in the automatic evaluation was ob- tained by the work of Versae points winning proposal used a zero-shot approach, i.e., no training data of this task was used for learning to generate the reasoning. Due to input texts in our dataset being long, we wonder how much do text length influence the performance? To verify it, we Marco Antonio Sobrevilla Cabezudo, Diego Diestra, Rodrigo L\u00f3pez, Erasmo G\u00f3mez, Arturo Oncevay, Fernando Alva-Manchego 284divide the test set in text subsets according to its length, as shown in the X-axis in Figures 2 and 3. Figure 2 shows how the accuracy changes according to the text length for all proposals (baseline is the BERT-based one). We can note that, as was expected, the performance decreases when the texts are longer, except for the cases where the length is higher than 500 tokens. This result is suspicious most proposals were BERT-based models. Thus, the maximum length was defined as 512 to- kens. However, the proposal of SADA uses a T5-based model that can deal with these lengths. In the case of the longest texts (be- tween 850 and 900 tokens), we must note that the performance was almost 0.25 be- cause the models usually chose an alternative by chance, and it was correct for all questions that had the task according dif- to the text length for all proposals. We note that even when the values obtained by Versae & Nandezgarcia are a bit higher in all subsets, these are almost the same higher than 0.60). These results can sug- gest that models can deal with different text lengths in the same way or that metric is not good enough to determine what is the best proposal. However, a deeper study is neces- sary to determine the actual reason for get- ting these results. Finally, Table 2 scores (almost 4) for all proposals, being a bit better for the proposal of Versae & Nandezgarcia. This is expected as all models shown read- able texts. In the case of accuracy, we can see that the proposal of Versae & Nandezgarcia obtained the best results. However, results are lower than 3, proving that this task is harder and the automatic evaluation met- ric could not be suitable. 7 Conclusion We presented the first edition of the ReCoRES task two sub-tasks: participated in this shared-task: three for sub-task 1 and one for sub-task 2. However, only two teams sent their working notes. All proposals were based on pre-trained language models with some additional strategies. Overall, the winner of sub-task 1 was the MRCPUCP team, and the winner of sub-task 2 was the Versae-Nandezgarcia team. About the results, datasets in the reading task and the need to use more suitable metrics and other strategies to deal with the reasoning explanation task as this one has proven to be complicated. As future work, we plan to extend the cur- both question types according to the tax- onomy proposed by Rogers et al. (2020) to verify what are the actual abilities of pre- trained language models. Besides, we plan to text of an one one used in this shared-task. Acknowledgements The authors acknowledge the support of the undergraduate students at the department of Software Engineering at the Universidad Na- cional Mayor de San Marcos in the manual evaluation. References Baggetto, P., S. Ramos, J. Garc\u00b4 a, and J. R. Navarro. 2022. Study on text comprehen- sion and MCQA in spanish. In Proceed- ings Iberian na, Spain. Proceedings. Banerjee, S. and A. Lavie. 2005. ME- for lation for Computational Linguistics. Carrino, C. P., M. R. Costa-juss` a, and J. A. R. Fonollosa. 2020. Automatic Spanish translation of SQuAD dataset for multi-lingual question answering. In Pro- and Evaluation Conference , pages 5515- 5523, Marseille, France, May. European Language Resources Association. De la Rosa, J. and A. Fern\u00b4 andez. 2022. Zero- shot Workshop Pro- ceedings. Devlin, J., M.-W. Chang, K. Lee, and K. Toutanova. Pre-training of Chapter of the Association for Com- putational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) , pages 4171-4186, Minneapolis, Minnesota, June. Association for Compu- tational Linguistics. Echegoyen, G., \u00b4Alvaro Rodrigo, and 2020. Cross-lingual training for multiple-choice question answering. Procesamiento del Lenguaje Natural 65(0):37-44. D. Gkatzia, S. A. Hasan, S. Mahamood, S. Mille, E. van Miltenburg, S. San- thanam, and V. Rieser. 2020. 13th International Conference on Natu- ral Language Generation , pages 169-182, Dublin, Ireland, December. Association for Computational Linguistics. Lai, G., Q. Xie, H. Y. 2002. Bleu: a method for auto- matic of machine translation. InProceedings of the 40th Annual Meet- ing of the Association for Computational Linguistics, pages 311-318, Philadelphia, Pennsylvania, USA, July. Association for Computational Linguistics. Pe nas, A., E. H. Hovy, P. Forner, \u00b4A. Ro- drigo, R. F. E. Sutcliffe, C. Forascu, and reading P. Forner, and P. D. Clough, editors, CLEF 2011 Labs and Work- shop, Notebook Papers, 19-22 September 2011, Amsterdam, The ume of CEUR Workshop Proceed- ings. CEUR-WS.org. Marco Antonio Sobrevilla Cabezudo, Diego Diestra, Rodrigo L\u00f3pez, Erasmo G\u00f3mez, Arturo Oncevay, Fernando Alva-Manchego 286Pe nas, A. and A. Rodrigo. 2011. A sim- ple measure to assess non-response. In Proceedings of of Association for Computational Lin- guistics: Human Language Technologies , pages Association for Computational Lin- guistics. Raffel, C., N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu. 2020. Exploring the lim- its of transfer learning with a unified text- to-text transformer. Journal of Machine Learning Research , 21(140):1-67. Rajpurkar, P., J. Zhang, K. Lopyrev, and P. Liang. 2016. SQuAD: 100,000+ questions for machine comprehension of text. 2016 Con- ference on Empirical Methods in ral Language Texas, November. Association for Computational Linguistics. Rodrigo, \u00b4A., A. Pe nas, Y. Miyao, E. Kando. 2015. Overview QA entrance exams task 2015. In L. Cappellato, N. Ferro, G. J. F. Jones, and E. SanJuan, editors, Work- ing Notes of CLEF 2015 - Conference and Labs of the Evaluation forum, Toulouse, France, September 8-11, 2015, volume 1391 of CEUR Workshop Proceedings. CEUR-WS.org. Rogers, A., O. Kovaleva, M. Downey, and A. Rumshisky. 2020. Getting closer to ai complete question answering: A set of prerequisite real tasks. 34(05):8722-8731, Apr. Zhang, T., V. Kishore, F. Q. Wein- berger, and Y. Artzi. 2020. Bertscore: Evaluating text generation with bert. InInternational Semaphore for Texts Resumen de la IberLEF 2022: de Recomendaci\u00b4 on, An\u00b4 alisis de Sentimiento y Predicci\u00b4 on de Sem\u00b4 aforo Textos Educaci\u00b4 on Superior de Ensenada 2Consejo Nacional de Ciencia y Tecnolog\u00b4 a 3Tecnol\u00b4 ogico Nacional de M\u00b4 exico Campus Ciudad and results from the Rest-Mex task at IberLEF 2022. This task considered three task consists in predicting the degree of satisfaction that a tourist may have when recommending a destination of Nayarit, Mexico, based on places visited by the tourists and their opinions. On the other hand, the Sentiment Analysis task predicts the polarity of an opinion issued and the attraction by a tourist who traveled to the most representative places in Mexico. have built corpora for both tasks considering Spanish opinions from As the Covid Semaphore Prediction task aims to predict the color of the Mexican Semaphore for each state, according to the Covid news in the state, using data from the Mexican Ministry of Health. This paper compares and discusses the participants' results for Prediction, Mexican Tourist Text. Resumen: Este art\u00b4 culo presenta el marco y los resultados de la tarea Rest-Mex en IberLEF 2022. Esta tarea consider\u00b4 o tres sub tareas: Sistema de recomendaci\u00b4 on, An\u00b4 alisis de sentimiento y Predicci\u00b4 on de sem\u00b4 aforo Covid, utilizando textos de lugares tur\u00b4 sticos mexicanos. La tarea del Sistema de Recomendaci\u00b4 on consiste en predecir el grado de satisfacci\u00b4 on que puede tener un turista al recomendar un destino de Nayarit, M\u00b4 exico, con base en los lugares visitados por los turistas y sus opiniones. Por otro lado, la tarea de An\u00b4 alisis de Sentimiento predice la polaridad de una opini\u00b4 on emitida y la atracci\u00b4 on por parte de un turista que viaj\u00b4 o a los lugares m\u00b4 as representativos de M\u00b4 exico. Hemos construido corpus para ambas tareas teniendo en cuenta las opiniones en espa nol de TripAdvisor. Como novedad, la tarea de Predicci\u00b4 on de Sem\u00b4 aforo Covid tiene como objetivo predecir el color del Sem\u00b4 aforo Mexicano para cada estado, de acuerdo a las noticias Covid en el estado, utilizando datos de la Secretar\u00b4 a de Salud de M\u00b4 exico. Este documento compara y discute los resultados de los participantes para las tres sub tareas. Palabras clave: Rest-Mex 2022, An\u00b4 alisis de sentimientos, Predicci\u00b4 on de covid, Textos Tur\u00b4 sticos Mexicanos. Procesamiento del Lenguaje Natural, Revista n\u00ba 69, septiembre de 2022, pp. 289-299 recibido aceptado 21-07-2022 ISSN 1135-5948. DOI 10.26342/2022-69-26 \u00a9 para el Procesamiento del Lenguaje Natural1 Introduction Tourism is a social, cultural, to people's movement to places outside their of residence for personal or business/professional reasons (Guerrero-Rodriguez et al., 8.7% of national GDP, generating around 4.5 jobs (Arce-Cardenas et al., 2021). In 2021, Rest-Mex emerged, evaluation forum ( \u00b4Alvarez-Carmona et al., 2021). This forum is the first that seeks to specialize in text analysis from tourism to provide solutions to different tasks for Mexi- can Spanish. In its 2021 edition, the Rest- Mex proposed two different tasks. Analy- sis of recommendation systems and sentiment analysis. For both tasks, data was collected from the TripAdvisor site. For this Rest-Mex edition, we proposed three sub-tasks: Recommendation System, Sentiment Analysis on Mexican tourist texts, and as a novelty, the task of Determining the color of the Mexican Covid-19 epidemiologi- cal semaphore is added. For this purpose, 3 data sets have been built. We in Nayarit, Mexico, for the recommendation system task. For the sentiment analysis task, the data is labeled to determine the polarity and origin of each this, 43,150 131,471 news items referring to covid were collected for all the states of the Mexican Republic, grouped into2,656 weeks. The remainder of this paper shows the results by the participants' systems and the analysis. Finally, Section 4 presents the conclusions obtained by this evaluation forum. 1Mexico is in the world's top ten and the second Iberoamerican country related to the arrival of inter- national tourists.2 Evaluation framework measures used for the tasks. 2.1 Recommendation System corpus The first subtask consists of a classification task where the participating system can pre- dict the degree of satisfaction a tourist may have when recommending a destination. Mexico. This col- lection was obtained from the tourists who shared their satisfaction on TripAdvisor be- tween 2010 and 2020. Each integer recommends visit. Location: The place of origin of the tourist (the central, northeast, northwest, west, and southeast re- gions refer to the regions of Mexico). Date: Date when the recommenda- tion was issued. Type: Type of trip that the tourist would do. The type would be in [Family, Friends, Alone, Couple, Business] History: The text de- and a series of rep- resentative characteristics of the place as a type of tourism that can be done there (adventure, beach, relaxation, among others.), If it is a family atmosphere, pri- vate or public, it is free or paid, among others. We use a 70/30 partition to divide into train and test. This means that we used Miguel \u00c1. \u00c1lvarez-Carmona, \u00c1ngel D\u00edaz-Pacheco, Ram\u00f3n Bustio-Mart\u00ednez 290Class Train instances Test instances 1 45 20 2 53 24 3 167 72 4 457 196 5 860 369 1582 681 Table 1: Instances distribution for the rec- unlabeled instances for the test partition. Table 1 shows the distribution of the in- stances for the recommendation system task for the train and test partitions. The class imbalance is clear since class 5 represents around 50 % of the total instances, making this task very difficult. Formally tourist and place, the goal is to automatically obtain the degree of satisfaction (between 1 and 5) the tourist may have when visiting that place.\" 2.2 Sentiment Analysis corpus The second subtask is a classification task where the participating system can predict the polarity and the tourist attraction of an opinion issued by a tourist This col- was from the tourists who TripAdvisor 2002 Good,5: Very good }. Also, the participants must determine attractiveness of the opinion being issued. The possible classes are Hotel and The corpus consists 43,150 opinions shared by tourists. Like the task, we use a 70/30 partition to di- vide into train and test. This means that we used 30,212 labeled stances for the the distribution of the in- stances for the sentiment analysis task for the train and test partitions for polarity and at- traction. As with the recommendation system sub- task, the class imbalance is clear since class 5Pol Attr Class Train Test Class Train Test 1 547 256 Attractive 5197 2216 2 730 315 Hotel 16565 7100 3 2121 884 Restaurant 8450 3622 attraction on sentiment analysis task. and the class Hotel represents around 50 % of the total instances, making this a task with a significant degree of difficulty too. Formally the problem is as: \"Given an opinion about a Mexican tourist place, the goal is to determine the po- larity, between 1 and 5, of the text and the visited attraction, which could be an attrac- tion, a hotel, or a restaurant.\" 2.3 Covid Semaphore Prediction The last subtask is a classification task where the participating system can predict the fu- ture of the covid semaphore through the news. This collection was obtained from news websites that published reports regard- ing covid from June 2020 to December 2021. For this task, 131,471 news items referring to covid were collected for all the states of the Mexican Republic, grouped into 2,656 weeks. Like the previous tasks, a 70/30 partition was made for training and testing. Therefore, 94,540 news items distributed in 1912 weeks were selected for the training cor- pus. The test corpus consists of 36,931 news items distributed over 744 weeks. Each or instance consists of 4 labels. These labels to the semaphore color of the instance after fweeks in the future. The possible colors to detect are: red, orange, yellow, and green, where red is the color that places the most restric- tions on public activities and green is the color that corresponds to the best possi- ble situation. The participants must pre- dict the color of the semaphore for the weeks f={0,2,4,8}. For more information re- garding the covid semaphore, you can con- sult (Alvarez-Carmona and Aranda, 2022), (\u00b4Alvarez-Carmona et al., 2022b). Table 3 shows the distribution 0 f= 2 f= 4 f= 8 Class Train Test Train Test Train Test Train Test Red 248 87 201 71 179 63 139 42 Orange 680 273 680 275 673 261 655 252 Yellow 545 216 554 221 568 227 615 232 Green 439 168 477 177 492 193 503 218 1912 744 1912 744 1912 744 1912 744 Table 3: Instances distribution for semaphore prediction. Like the other tasks, for this corpus, it can be seen that the red class is the minority, which could be the most crucial class to pre- dict, so this task has considerable complexity to solve. Formally problem of this task is de- fined as: \"Given the news set for a week fin a state of the Mexican Republic x, each system must return the color of the covid epidemiological semaphore for weeks f,f+2,f+4, and f+8 for the xstate.\" will rank the submissions for the recommendation system task. MAE are defined as equation 1. MAE Sx=1 nnX i=1|T(i)Sx(i)| (1) Where Sxis result of the instance iaccording to the Ground Truth, and Sx(i) is the output of the participant system x, for instance, i. Finally, nis the number of instances in the collection. We proposed a measure to evaluate the sentiment analysis task for this edition. This measure is defined as shown in F-measure for each class (hotel, restaurant, and attractive), and MAE evaluates the po- larity. Finally, for weight well-ranked to ob- tain a final that the chosen baseline is the majority class for the three tasks. 3 Overview of the Submitted Approaches This section presents the results obtained by the participants for the different tasks. 3.1 Recommendation system overview For this study, three teams have submitted their solutions for the recommendation sys- tem task. The authors of noted for the is 4 a summary of sults obtained by each team for the rec- ommendation system task. The MAE was used to rank participants. The approach of the GPI-CIMAT team (Callejas-Hern\u00b4 andez et al., 2022) obtained the simple approach overcomes the Bert-based approach. Fi- that baseline would not have good results; this is evident since all the experiments surpassed the baseline in this metric, although by 0.05. Also, Table 4 shows the result of the team that obtained the best result in last year's edition. Since this is the only task of this Miguel \u00c1. \u00c1lvarez-Carmona, \u00c1ngel D\u00edaz-Pacheco, Ram\u00f3n Aranda, Ansel Y. Rodr\u00edguez-Gonz\u00e1lez, Guerrero-Rodr\u00edguez, L\u00e1zaro Bustio-Mart\u00ednez 292edition that is identical to that of the pre- vious year, it is possible to make this com- parison. It is possible to see that no team could beat the Alumni-MCE 2GEN team of the 2021 edition (Arreola et al., 2021). Table 5 shows the best F-measure results by class in the recommendation task. These results show that the minority classes (1 and 2) were not well represented, which is why the best result of the 2021 edition is shown. From class 3, it is possible to see that a different team obtains a good result. It is possible to observe that the GPI CIMAT team obtains the best result for class 5, which explains its better MAE result. Something remarkable is task To analyze the complementarity of the pre- dictions by the participants' systems, we built a theoretically perfect ensemble (PA) from their runs, as calculated in (Arag\u00b4 on et al., 2019). We considered that a test in- stance was correctly to create a representa- tion based on the outputs of each system. For this, they implemented a deep learning (DL) architecture like the one proposed in (\u00b4Alvarez-Carmona et al., 2022a). From these results, it is possible to ob- serve that the perfect performance is better participants' approaches, phe- nomenon has already appeared in this type of task and is known as The Phenomenon of Completeness over correctly classified ssystems. That is, when 0, all the instances that were not classified well by any system are shown, while when s= 9, they are the instances that were classified well by all systems. The base 2 logarithm was applied to the number of in- stances to observe the graph better. The sys- tems of this and the previous edition were taken for this exercise. 3.2 Sentiment analysis overview For this study, 13 teams have submitted solutions and descriptions that of possible sys- tems for recommendation. analysis task. For representation completely dominate the first places for task. The UMU team es et al., UG (Barco, Rodr\u00b4 based on Bert. It is possible to observe that these types of methodologies are the ones that obtain the best results since the lowest result, of what transformers applied, is 0.84 when the best result is 0.89, that is, the results are very close to each other. On the other hand, the rest of the works proposed more straightforward meth- ods. ESCOM-IPN-LCD a Logistic classifier to train two models, one for polarity prediction and the other for the attraction type prediction. out by computing the total polarity of the opinions in an intensity spectrum according to the scale of Texts 293Rank Country Institute 4: the Recommendation GPI-CIMAT Table 5: the class. a representation based on Topics extracted by LDA and classified Deep Learning architecture. Finally, DevsEx- Machina (Rivas- \u00b4Alvarez et al., 2022) pro- poses to extract all the terms in each class from one to words (1...4-grams) as po- larity characteristics. Also, they perform a chain of translations of the opinions, from Spanish to other languages and back to Span- ish, to obtain meanings and terms. It is that despite more straightforward, some of the results of the proposals that are not based on Transform- ers obtain close values. This seems ideal for environments with limited memory, time, or data. Table 6 shows a summary of the results team difference with UC3M is 0.002. Due to the closeness of the results, it is possible that there is no statistical sig- nificance between all the methods based on transformers. Table 7 shows the best F-measure results by class in the sentiment analysis task. Inter- estingly, the UMU team does not get the best results for any polarity class. However, it is the best team for all three attraction classes. The DCI UG team obtains the best results for classes 1 and 2, which are the most diffi- 2For systems with *, the authors did not send best result for MCE, in its two attempts, obtains the majority of classes. 3.2.1 Perfect assemble for the sentiment analysis task As in the section 3.1.1, the complementarity of the systems was analyzed for the sentiment analysis task. We calculated the perfect as- semble. Table 6 also shows the perfect assemble (PA) result and the Deep Learning combina- tion systems (DL). As in the recommendation task, it is pos- sible to observe that the perfect ensemble performance is considerably better than the UMU approach, the partic- ipants' systems are complementary to each other again, with an error result very close to zero. The DL approach improves the best result obtained by the shows the number of instances correctly classified by ssystems similar to the color green is the polarity in- stances, whereas the color opinions PA detection task. The pattern of these instances is tourists talking about a hotel restaurant or vice versa, which confuses all systems. For example: Este lugar era estupendo. Un mont\u00b4 on de Miguel \u00c1. \u00c1lvarez-Carmona, \u00c1ngel D\u00edaz-Pacheco, Ram\u00f3n Aranda, Y. Rodr\u00edguez-Gonz\u00e1lez, Daniel Bustio-Mart\u00ednez 294Rank Country Institute Team Measure SMAE P FA PA - - - 0.98 0.03 0.99 DL - - - 0.91 0.19 Esp UC3M Run 1 0.98 HM Mex ITESM MCE-Team Run 2 0.88 0.26 0.98 - Mex ITESM MCE-Team Run 1 0.88 0.26 0.98 - Esp UMU 2 HM Mex/Che 2 - Mex HM Col/Mex SENA Team 0.80 0.47 HM Mex UAEM DevsExMachina Run 2 0.70 - Mex UAEM 1 class Best result Team 1 0.61 DCI-UG Run 1 2 0.37 DCI-UG Run 1 3 UC3M] 4 0.48 5 0.88 UMU-Team Run 1 Hotel Run 1 Restaurant 0.98 UMU-Team Run 1 Table 7: Performance for the Sentiment Analysis task per class. opciones y gran comida fresca. El desayuno buffet era grandes mucha fruta fresca. This instance is a hotel; however, the opin- ion refers to food. Another is: El hotel est\u00b4 a incre\u00b4 ble, pero resalt\u00b4 o el ex- celente servicio en insu sky bar, muchas gra- cias al capit\u00b4 an Iv\u00b4 an, y a su staff Heriberto, Gabriel, Luis, Isidoro y Hugo, las bebidas de Gerardo y Alexis incre\u00b4 bles y la cocina un placer ! En el \u00b4 area de alberca al se nor Wenceslao! Muchas gracias por todo ! Which, although it is inside a hotel, is a restaurant. None of these instances have the attractive label.3.3 Semaphore covid prediction results For this last received from 4 teams. MCE team(Ramos-Zavaleta extracted directly from the news and the other applying transfer learning. First, they propose a system based on CorEx topics, and as a second attempt, they a system based on Bert. Arandanito team (Carmona-S\u00b4 anchez, Carmona, and topic extraction. linear regressions, which serve as input for simple of Rest-Mex at 2022: Recommendation of possible sys- tems for sentiment analysis. The last Team (Romero-Cant\u00b4 et al., 2022) proposes an using the Mutual informa- tion results of the partici- pating teams. It can be seen that both MCE and Arandanito have a very close results to each other. Curiously, both approaches are topic-based. It can be seen that the best results are ob- tained for week 2 in the future. That is, two weeks after the news was published. How- ever, the results of weeks 4 and 8, considering the imbalance and that there are four classes, are competitive. Like the other tasks, all the participants managed to pass the Baseline (BL). Table 9 best results for each class for each evaluated week. For week 0, it is possible to see that MCE obtains all the best results. However, from week 2, it can be seen that Arandanito ob- tains the best result for the Red class. This is the most challenging class because it is the minority class. For all other classes, MCE gets the best result. 3.3.1 semaphore prediction task Table 8 also shows the perfect assembly and the combination of the systems, like the other two tasks. The perfect ensemble is much higher than the best of the individual which in- dicates that these systems also complement each other. On other hand, the Figure 3: Instances that were possible semaphore prediction. two individ- ual Figure correctly classified by ssystems similar to the Figure 1. The color green is Week 0, yellow for 2, blue for 4, and red for 8. For more details of the results of both tasks, it is possible to go to the following web https://sites.google.com/cicese. edu.mx/rest-mex-2022/results. Conclusions This sults of the Rest-Mex shared task collocated IberLef 2022. Rest-Mex stands covid prediction in Span- ish tourists text for three 18 teams participated. in countries as Mexico, Spain, Cuba, Colombia, Belgium, and Switzerland. Thirty-five different systems were received to to of the proposed Rest-Mex 2021. For the recommendation task, a tourist's satisfaction with a recommendation of a tourist place for the state of Nayarit in Mex- ico was evaluated. The best MAE result obtained was that of (Callejas-Hern\u00b4 andez et al., 2022), which belongs to the CIMAT of Mexico. This team proposed a simple sys- tem based on BoW. Although all the partic- ipating outperformed than the 2021 edition. This result indicates that this task still has many challenges to be solved. Miguel \u00c1. \u00c1lvarez-Carmona, \u00c1ngel D\u00edaz-Pacheco, Ram\u00f3n Daniel Bustio-Mart\u00ednez 296Rank Institute 0.92 0.73 9: Performance for the Prediction task per class. sentiment analysis task aimed iden- tify the polarity and of a Mexican tourist destination. The polarity was evaluated with MAE while the origin with F-Measure. The team that got the best performance was (Garc\u00b4 a-D\u00b4 az et al., 2022). This team represents the Uni- versity of Murcia in Spain. They proposed method Bert. Other teams that also implemented Bert obtained results very close to first place. This is further evidence of the importance of transformers in textual Also, tels, restaurants, and attractions is a task that can have very high results, close to 100 %. The task of determining the semaphore covid was a novelty introduced for this year's edition. Based on the news regarding covid, this task consists of determining the color of the epidemiological semaphore for weeks 0, 2, 4, and 8 in the future based on the news publications. The best result obtained for this task can be seen in (Ramos-Zavaleta and Rodr\u00b4 guez, 2022). This team comes from ITESM of Mexico. Their solution is based mainly on extracting topics, although they obtains Bert. Best re- sults are achieved when ranked 2 weeks into the results for 4 weeks alsoseem competitive. The results at 8 weeks suf- fer a drop in the classification. Finally, it is shown that there is signif- systems. In other attempts have been made to mix the par- ticipating systems to obtain better results (\u00b4Alvarez-Carmona et al., 2018), taking the proposal to use a simple deep learning archi- tecture ( \u00b4Alvarez-Carmona et al., 2022a), it was the best results of the three tasks. go rest-mex 2022: Sentiment analysis task. InProceedings of the text mexican tourism. Procesamiento del Lenguaje Natural . \u00b4Alvarez-Carmona, M. \u00b4A., the study of online travel reviews: Many heads are better than one. Computaci\u00b4 on y Sistemas, 26(2). \u00b4Alvarez-Carmona, M. A., R. Aranda, A. Y. Rodr\u00b4 guez-Gonz\u00b4 alez, L. Pellegrin, and H. Carlos. 2022b. Classifying the mexican epidemiological semaphore colour from the covid-19 text spanish news. Journal of Information Science . \u00b4Alvarez-Carmona, M. \u00b4A., E. mexican spanish tweets. In Notebook papers of 3rd se- pln workshop on evaluation of human lan- guage technologies for Springer, pages 57-81. \u00b4A. and R. Aranda. 2022. Determinaci\u00b4 on autom\u00b4 atica del color del sem\u00b4 aforo mexicano del covid-19 a par- tir de las noticias. Arag\u00b4 on, M. E., M. A. \u00b4Alvarez-Carmona, M. Montes-y G\u00b4 omez, H. J. Escalante, L. V. Pineda, and 2019. Overview of mex-a3t at iberlef 2019: Au- IberLEF@ SE- PLN, pages 478-494. Arce-Cardenas, S., system: a study case in mex-ico. In Mexican International Conference on Artificial Intelligence, pages 184-195. Springer. Arreola, J., L. Garcia, J. Ramos-Zavaleta, and A. guez. task at iberlef 2021. ings and D.-I. Hern\u00b4 mission on rest-mex 2022. In the recom- mendation systems shared task @rest mex 2022. In Proceedings the Third Work- 2022. Com- bining linear regressions to determine the future of the covid in mexico from the news. In Proceedings of the Third Work- shop 2022. Automl Guerrero-Rodr\u00edguez, L\u00e1zaro Bustio-Mart\u00ednez 298Guerrero-Rodriguez, R., M. Current issues in tourism, pages 1-16. Jurado-Buch, J. D., L. Bustio-Mart\u00b4 nez, and M. A. \u00b4Alvarez-Carmona. 2022. The role of the topics for the a collec- A. guez. 2022. A transfer learn- ing model for polarity touristic reviews in spanish from tripadvisor. In Pinto-Avenda L\u00b4 opez. 2022. A hybrid rec- ommender model based on information re- trieval for mexican tourism text in rest- mex 2022. In Proceedings of the Third Workshop Rodr\u00b4 2022. mexico's covid traffic light color pre- diction system based on mexican news. InProceedings of the Third supervised in Third Medina-Mart\u00b4 nez, A. andez-Casta neda, J. E. Ruiz-Melo, Casta Y. Nikolaevna-Ledeneva. 2022. at rest-mex 2022 opinion mining of tourism sector through sets of normalized n-grams. InProceedings of the rez-Silva. 2022. Mexican informa- A. Carrillo-Cabrera, Y. A. Castillo-Castillo, D. A. Moctezuma- Ochoa, and V. H. Mu n\u00b4 z S\u00b4 anchez. 2022. Bert model and data augmentation for sentiment analysis in tourism reviews for mexican spanish language. In Proceed- ings of the Third Workshop for tion mexican tourism using natural language process- ing. In Proceedings of the Mexican Tourist Texts 299300 Informaci\u00f3n General Informaci\u00f3n para los Autores Formato de los Trabajos L a longitud m\u00e1xima admitida para las contribuciones ser\u00e1 de 10 p\u00e1ginas DIN A4 (210 x 29 7 m m.), incluidas referencias y figuras. L os art\u00edculos pueden estar escritos en ingl\u00e9s o espa\u00f1ol. El t\u00edtulo, resumen y palabras clav e d eben escribirse en ambas lenguas. E l formato ser\u00e1 en Word \u00f3 LaT eX E nv\u00edo de los Trabajos E l env\u00edo de los trabajos se realizar\u00e1 electr\u00f3nicamente a trav\u00e9s de la p\u00e1gina web de la Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Natural ( http://www.sepln.org) Para los trabajos con formato LaTeX se mandar\u00e1 el archivo PDF junto a todos los fuentes necesarios para compilaci\u00f3n LaTex P ara los trabajos con formato Word se mandar\u00e1 el archivo PDF junto al DOC o RTF P ara m\u00e1s informaci\u00f3n http://www.sepln.org/la -revista/informacion -para-autores \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje NaturalInformaci\u00f3n Adicional Funciones del Consejo de Redacci\u00f3n L as funciones del Consejo de Redacci\u00f3n o Editorial de la revista SEPLN son las siguientes: Controlar la selecci\u00f3n y tomar las decisiones en la publicaci\u00f3n de los contenidos que han d e co nformar cada n\u00famero de la revista Po l\u00edtica editorial P reparaci\u00f3n de cada n\u00famero R elaci\u00f3n con los evaluadores y autores R elaci\u00f3n con el comit\u00e9 cient\u00edfico E l consejo de redacci\u00f3n est\u00e1 formado por los siguientes miembros L.Al fonso Ure\u00f1a L\u00f3pez (Director) Un iversidad de Ja \u00e9n laurena@ujaen.es Patricio Mart\u00ednez Barco (Secretario) Universidad de Alicante patricio@dlsi.ua.es Manuel Palomar Sanz Universidad de Alicante mpalomar@dlsi.ua.es Felisa Verdejo Ma\u00edllo UNED felisa@lsi.uned.es Funciones del Consejo Asesor L as funciones d el Consejo Asesor o Cient\u00edfico de la revista SEPLN son las siguientes: Marcar, orientar y redireccionar la pol\u00edtica cient\u00edfica de la revista y las l\u00edneas de investigaci\u00f3n a potenciar R epresentaci\u00f3n I mpulso a la difusi\u00f3n internacional C apacidad de atracci\u00f3 n de autores E valuaci\u00f3n C omposici\u00f3n Pr estigio Al ta especializaci\u00f3n I nternacionalidad E l Consejo Asesor est\u00e1 formado por los siguientes miembros: Xabier Arregi Universidad del Pa\u00eds Vasco (Espa\u00f1a) Manuel de Buenaga Universidad de Alcal\u00e1 (Espa\u00f1a) Jos\u00e9 Camacho Collados Cardiff University (Reino Unido) Sylviane Cardey -Greenfield Centre de recherche en linguistique et traitement automatique des langues (Francia) Irene Castell\u00f3n Universidad de Barcelona (Espa\u00f1a) Arantza D\u00edaz de Ilarraza Universidad del Pa\u00eds Vasco (Espa\u00f1a) Antonio Ferr\u00e1ndez Universidad de Alicant e (Espa\u00f1a) Koldo Gojenola Universidad del Pa\u00eds Vasco (Espa\u00f1a) Xavier G\u00f3mez Guinovart Universidad de Vigo (Espa\u00f1a) Jos\u00e9 Miguel Go\u00f1i Universidad Polit\u00e9cnica de Madrid (Espa\u00f1a) Inma Hernaez Universidad del Pa\u00eds Vasco (Espa\u00f1a) \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje NaturalElena Lloret Universidad de Alicante ( Espa\u00f1a) Ram\u00f3n L\u00f3pez -C\u00f3zar Delgado Universidad de Granada (Espa\u00f1a) Bernardo Magnini Fondazione Bruno Kessler (Italia) Nuno J. Mamede Instituto de Engenharia de Sistemas e Computadores (Portugal) M. A ntonia Mart\u00ed Anton\u00edn Universidad de Barcelona (Espa\u00f1a) M.T eresa Mart\u00edn Valdivia Unive rsidad de Ja\u00e9n (Espa\u00f1a) Patricio Mart\u00ednez -Barco Universidad de Alicante (Espa\u00f1a) Eugenio Mart\u00ednez C\u00e1mara Universidad de Granada (Espa\u00f1a) Paloma Mart\u00ednez Fern\u00e1ndez Universidad Carlos III (Espa\u00f1a) Raquel Mart\u00ednez Unanue Universidad Nacional de Educaci\u00f3n a Di stancia (Espa\u00f1a) Ruslan Mitkov University of Wolverhampton (Reino Unido) Manuel Montes y G\u00f3mez Instituto Nacional de Astrof\u00edsica, \u00d3ptica y Electr\u00f3nica (M\u00e9xico) Mariana Lara Neves German Federal Institute for Risk Assessment (Alemania) Llu\u00eds Padr\u00f3 Univer sidad Polit\u00e9cnica de Catalu\u00f1a (Espa\u00f1a) Manuel Palomar Unive rsidad de Alicante (Espa\u00f1a) Ferr\u00e1n Pla Universidad Polit\u00e9cnica de Valencia (Espa\u00f1a) German Rigau Universidad del Pa\u00eds Vasco (Espa\u00f1a) Horacio Rodr\u00edguez Universidad Polit\u00e9cnica de Catalu\u00f1a (Espa\u00f1a) Paolo Rosso Universidad Polit\u00e9cnica de Valencia (Espa\u00f1a) Leonel Ruiz Miyares Centro de Ling\u00fc\u00edstica Aplicada de Santiago de Cuba (Cuba) Horacio Saggion Universidad Pompeu Fabra (Espa\u00f1a) Emilio Sanch\u00eds Universidad Polit\u00e9cnica de Valencia (Espa\u00f1a) Encarna Segarra Universidad Polit\u00e9cnica de Valencia (Espa\u00f1a) Thamar Solorio University of Houston (Esta dos Unidos de Am\u00e9rica) Maite Taboada Simon Fra ser University (Canad\u00e1) Mariona Taul\u00e9 Universidad de Barcelona Juan-Manuel Torres-Moreno Laboratoire Informatique d'Avignon / Universit\u00e9 d'Avignon (Francia) Jos\u00e9 Jim\u00e9nez Universidad de Sevilla (E spa\u00f1a) L.Al fonso Ure\u00f1a L\u00f3pez Universidad de Ja\u00e9n (Espa\u00f1a) Rafael Valencia Garc\u00eda Universidad de Murcia (Espa\u00f1a) Ren\u00e9 Venegas Vel\u00e1sques Pontificia Universidad Cat\u00f3lica de Valpara\u00edso (Chile) Felisa Verdejo Ma\u00edllo Universidad Nacional de Educaci\u00f3n a Distanci a (Espa\u00f1a) Manuel Vilares Universidad de Vigo (Espa\u00f1a) Luis Villase\u00f1or -Pineda Institu to Nacional de Astrof\u00edsica, \u00d3ptica y Electr\u00f3nica (M\u00e9xico) Cartas al director S ociedad Espa\u00f1ola para el Procesamiento del Lenguaje Natural Departamento de Inform\u00e1tica. Universidad de Ja\u00e9n Campus Las Lagunillas, Edificio A3. Despacho 127. 23071 Ja\u00e9n secretaria.sepln@ujaen.es M\u00e1s informaci\u00f3n P ara m\u00e1s informaci\u00f3n sobre la Sociedad Espa\u00f1ola del Procesamiento del Lenguaje Natural puede consultar la p\u00e1gina web http://www.sepln.org. Si desea inscribirse como socio de la Socie dad Espa\u00f1ola del Procesamiento del Lenguaje Natural puede realizarlo a trav\u00e9s del formulario web que se encuentra en esta direcci\u00f3n http://www.sepln.org/sepln/la -sociedad Los n\u00fameros anteriores de la revista se encuentran disponibles en la revista electr\u00f3nica: http://journal.sepln.org/sepln/ojs/ojs/index.php/pln/issue/archive Las funciones del Consejo de Redacci\u00f3n est\u00e1n disponibles en Internet a trav\u00e9s de http://www.sepln.org/la -revista/consejo -de-redaccion \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje NaturalLas funciones del Consejo Asesor est\u00e1n disponibles Internet a trav\u00e9s de la p\u00e1gina http://www.se pln.org/la -revista/consejo -asesor La inscripci\u00f3n como nuevo socio de la SEPLN se puede realizar a trav\u00e9s de la p\u00e1gina http://www.sepln.org/sepln/inscripcion -para-nuevos -socios \u00a9 2022 Sociedad Espa\u00f1ola para el NaturalOverview of DETESTS at IberLEF 2022: DETEction and STere in Alejandro Ariza -Casabona, Wolfgang S. Montserrat Nofre, Mariona Arag\u00f3n, Mar\u00eda documents: of the LivingNER shared task and resources Antonio Miranda- Escalada, Eul\u00e0lia Farr\u00e9- Maduell, Salvador Lima -L\u00f3pez, Darryl Estrada, Gasc\u00f3, 202 Paraphrase Detection in Spanish Shared Task Gemma Bel -Enguix, Gerardo Sierra, Helena G\u00f3mez -Adorno, Juan -Manuel Torres -Moreno, - Ideology Antonio Garc\u00eda- D\u00edaz, Salud Mar\u00eda Jim\u00e9nez -Zafra, Mar\u00eda -Teresa Mart\u00edn Valdivia, Francisco Garc\u00eda -S\u00e1nchez, L. Alfonso Ure\u00f1a- L\u00f3pez, Rafael Valencia- Chiruzzo, Bouza, Santiago Castro, Etcheverry, Santiago G\u00f3ngora, Santiago Goycoechea, Juan Machado, Guillermo Moncecchi, Juan Jos\u00e9 Prada, Dina Wonsever .................................................................................................................................................. 273 Over view ReCoRES at IberLEF 2022: Comprehension and Reasoning Explanation for Spanish Marco Antonio Sobrevilla Cabezudo, Diego Diestra, Rodrigo L\u00f3pez, Erasmo G\u00f3mez, Arturo Oncevay, Fernando Alva- Manchego ........................................................................................................................ 281 Tourist Texts Miguel \u00c1. \u00c1lvarez -Carmona, \u00c1ngel D\u00edaz -Pacheco, Ram\u00f3n Aranda, Ansel Y. Rodr\u00edguez -Gonz\u00e1lez, Daniel Fajardo- Delgado, Rafael Guerrero -Rodr\u00edguez, L\u00e1zaro Bustio- Mart\u00ednez ................................................ 289 I nformaci\u00f3n General Informaci\u00f3n para los autores .................................................................................................................... 303 Informaci\u00f3n adicional ............................................................................................................................... 304 \u00a9 2022 Sociedad Espa\u00f1ola para el Procesamiento del Lenguaje Natural "}