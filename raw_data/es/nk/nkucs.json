{"title": "PDF", "author": "PDF", "url": "https://rua.ua.es/dspace/bitstream/10045/11456/1/Tesis_vazquez.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "Resoluci\u00f3n de la ambig\u00fcedad sem\u00e1ntica mediante m\u00e9todos basados en conocimiento y su aportaci\u00f3n a tareas de PLN Sonia V\u00e1zquez P\u00e9rez Resoluci\u00b4 on de la ambig\u00a8 uedad sem\u00b4 antica mediante m\u00b4 etodos basados en conocimiento y su aportaci\u00b4 on a tareas de PLN Tesis Doctoral Autora: azquez P\u00b4 erez Director: Dr. de Lenguajes y Sistemas Inform\u00b4 aticos Universidad de Alicante Alicante, 2009 A mi familia Agradecimientos En primer lugar me gustar\u00b4 a dar mi m\u00b4 as sincero agradecimien- to a todas las personas que me han animado y apoyado en la realizaci\u00b4 on de esta Tesis. En especial, me gustar\u00b4 a agradecer a mi director, Andr\u00b4 es Montoyo, todo el tiempo que ha dedicado a dirigir mis investigaciones y todos los consejos que me ha dado durante toda mi trayectoria como investigadora, los cuales, me han llevado hasta este punto. Tambi\u00b4 en quisiera hacer menci\u00b4 on especial a todos mis com- pa neros del Grupo de Procesamiento del Lenguaje Natural de la Universidad de Alicante, que han aportado su granito de arena en esta Tesis y cuyos consejos han sido fundamentales para la na- lizaci\u00b4 on de este trabajo. Muchos de los avances de esta tesis han sido gracias a los trabajos realizados en colaboraci\u00b4 on con distintos miembros del grupo de donde han surgido muy buenas ideas. Para terminar, no podr\u00b4 a haber llegado hasta aqu\u00b4 sin el apoyo que toda mi familia me ha brindado durante todos estos a nos y sobretodo, gracias a mi marido por su comprensi\u00b4 on y paciencia en este largo camino que sin \u00b4 el habr\u00b4 a sido, sin duda, muy duro. Alicante, 2009 Sonia V\u00b4 azquez \u00b4Indice general 1. Introducci\u00b4 on : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 1 1.1. Problem\u00b4 Estado del arte : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 11 2.1. Descripci\u00b4 on evaluaci\u00b4 on de sistemas de WSD evaluaci\u00b4 on de sistemas . . . . 68 4. Recursos : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 71 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 103 5.1. WSD Experimentaci\u00b4 on y evaluaci\u00b4 on : : : : : : : : : : : : : : : : : : : 151 6.1. Competiciones de resultados y trabajo futuro .201 6.4. Participaci\u00b4 on en Textual . . .206 6.4.1.3.Combinaci\u00b4 on de LSA y 7. Conclusiones y trabajos futuros : : : : : : : : : : : : : : : : : : 233 7.1. evaluaci\u00b4 on en WSD 234 7.1.3. Descripci\u00b4 on l\u00b4 on de los sistemas de : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 243 Bibliograf\u00b4 a : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 247 \u00b4Indice de tablas 2.1. Clasicaci\u00b4 de sentidos y matriz de distancia sem\u00b4 cima de la jerarqu\u00b4 a de WordNet . .76 . on de la polisemia mediante el uso de de la eciencia utilizando como contexto una ventana de eciencia reduciendo el nivel de espe- cializaci\u00b4 de los resultados de los distintos sis- temas participantes en a por separado . .181 6.16. Sistemas no supervisados en la tarea los nom- bres de la McNemar . . . .231 6.34. Notaci\u00b4 on y despu\u00b4 es de la inclusi\u00b4 . . . . relevantes . . .198 Desde la aparici\u00b4 on de las primeras computadoras en los a nos 50, nuestras vidas giran en torno a multitud de dispositivos elec- tr\u00b4 onicos que facilitan nuestra existencia. De hecho, en la actuali- dad, la gran explosi\u00b4 on de tecnolog\u00b4 as relacionadas con las comuni- caciones (internet, telefon\u00b4 a m\u00b4 ovil, etc) ha motivado el desarrollo parejo de otras tecnolog\u00b4 as estrechamente vinculadas a mejorar la comunicaci\u00b4 on hombre-m\u00b4 aquina. Actualmente, los dispositivos GPS utilizan sistemas de comunicaci\u00b4 on que simulan la voz hu- mana, las b\u00b4 usquedas en internet se realizan en cualquier idioma, siendo el buscador capaz de reconocer el idioma y extraer la in- formaci\u00b4 on correspondiente, las traducciones de textos se hacen de forma autom\u00b4 atica con un software especialmente dise nado para ello, etc. Un ejemplo de c\u00b4 omo han evolucionado los sistemas de comunicaci\u00b4 on son los actuales servicios de informaci\u00b4 on automati- zados, donde a trav\u00b4 es del tel\u00b4 efono podemos comprobar en breves segundos si existen atascos, encontrar la farmacia de guardia de un municipio, consultar el pron\u00b4 ostico meteorol\u00b4 ogico, etc. Todas las consultas se hacen como si realmente existiera una persona al otro lado, pero verdaderamente detr\u00b4 as del auricular hay un sistema automatizado muy complejo que procesa la consulta de forma autom\u00b4 atica. A simple vista todo parece muy sencillo, se hace la pregunta, se procesa y se da la respuesta. Pero de hecho, la parte de procesamiento lleva asociada una gran complejidad. 2 Concretamente, en el caso de las consultas telef\u00b4 onicas, para que todo funcione correctamente y se obtenga una respuesta satisfac- toria, es necesario realizar previamente una serie de tareas m\u00b4 as complejas como: determinar el idioma del interlocutor, transfor- mar los sonidos en palabras y frases con signicado, realizar el an\u00b4 alisis sint\u00b4 actico de la pregunta, detectar los nombres propios, seleccionar del sentido correcto de cada palabra dentro de su con- texto, etc. Todas estas tareas requieren de un profundo conoci- miento ling\u00a8 u\u00b4 stico y a la vez en muchos casos, de un elevado coste computacional. Estas necesidades han derivado en una disciplina denominada Ling\u00a8 u\u00b4 stica Computacional o Procesamiento del Len- guaje Natural combina la ling\u00a8 u\u00b4 stica y la inform\u00b4 atica con el n de modelar el lenguaje humano desde un punto de vista computacional. Uno de los motores principales que ha impulsado la necesi- dad actual del tratamiento del lenguaje humano ha sido Internet. La red proporciona una gran cantidad de informaci\u00b4 on sobre mul- titud de tem\u00b4 aticas problema asociado: la informa- ci\u00b4 on est\u00b4 a desestructurada y descentralizada. Existen innidad de p\u00b4 aginas web: de empresas, personales, blogs, foros, p\u00b4 aginas web institucionales... algunas de ellas est\u00b4 an relacionadas y otras no tienen nada en com\u00b4 un. Esta falta de organizaci\u00b4 on requiere la uti- lizaci\u00b4 on de alg\u00b4 un tipo de tecnolog\u00b4 a que gestione de forma ecaz toda la informaci\u00b4 on disponible para que tanto las b\u00b4 usquedas como las consultas sean efectivas. Esta problem\u00b4 atica ha derivado en la utilizaci\u00b4 on de dos tipos de tecnolog\u00b4 as bien diferenciadas: Tecno- log\u00b4 as de Procesamiento de Datos y Tecnolog\u00b4 as de Procesamiento del Lenguaje Natural. Cada una de estas tecnolog\u00b4 as procesa de forma diferente la informaci\u00b4 on. A diferencia de las Tecnolog\u00b4 as de Procesamiento de Datos que se ocupan de reducir el espacio ocu- pado, almacenar de forma \u00b4 optima los datos, ahorrar tiempos de respuesta en la b\u00b4 usqueda de alg\u00b4 un tipo de informaci\u00b4 on, etc, las Tecnolog\u00b4 as de Procesamiento del Lenguaje Natural necesitan un conocimiento m\u00b4 as profundo del lenguaje para poder procesar la informaci\u00b4 on. Esta diferencia puede verse m\u00b4 as clara con el siguiente ejemplo: 1. Introducci\u00b4 on 3 Supongamos que tenemos un programa que puede contar el n\u00b4 umero de l\u00b4 neas, de palabras o de bytes en un chero de texto. Dentro de este programa se utilizan dos t\u00b4 ecnicas distintas. Mien- tras que para contar l\u00b4 neas y n\u00b4 umero de bytes no es necesario ning\u00b4 un conocimiento ling\u00a8 u\u00b4 stico (procesamiento de datos), para contar las palabras s\u00b4 es necesario un conocimiento de qu\u00b4 e signica realmente ser una palabra (procesamiento del lenguaje natural). Este es un peque no ejemplo muy simple y muy pobre en cono- cimiento ling\u00a8 u\u00b4 stico de aplicaci\u00b4 on de procesamiento del lenguaje natural. Por supuesto, actualmente se han desarrollado multitud de aplicaciones mucho m\u00b4 as complejas que abordan diferentes tipos de problemas. Entre este tipo de aplicaciones encontramos: tra- ductores di\u00b4 alo- go, etc. Todos estos sistemas deben profundizar mucho m\u00b4 as en el conocimiento ling\u00a8 u\u00b4 stico para su correcto funcionamiento. Por ejemplo, un sistema de traducci\u00b4 on autom\u00b4 atica deber\u00b4 a ser capaz de traducir correctamente \" I'm in bed because I have a cold \" por \"Estoy en cama porque estoy resfriado\" y no por \"Estoy en cama porque tengo un fr\u00b4 o\". La forma de determinar el signicado de la palabra \" cold\" es utilizar las palabras del contexto que la rodean, para poder decidir qu\u00b4 e sentido es el m\u00b4 as apropiado. Por tanto, cuando necesitamos un conocimiento m\u00b4 as preciso del lenguaje, de las relaciones entre palabras o de las expresiones en diferentes con- textos, hablamos de Tecnolog\u00b4 as de Procesamiento del Lenguaje Natural (PLN). 1.1 Problem\u00b4 atica en PLN Uno de los principales problemas encontrados al tratar tex- to no pre-formateado: el lenguaje humano podemos encontrar m\u00b4 ultiples expresiones y palabras que pueden tener varios signicados distin- tos dependiendo de las circunstancias de uso. Estas caracter\u00b4 sticas hacen que el lenguaje natural se distinga de los lenguajes articia- les por su riqueza (en vocabulario y construcciones), flexibilidad (reglas con m\u00b4 ultiples excepciones), ambig\u00a8 uedad (pudiendo darse 4 1.1 Problem\u00b4 atica en PLN diversos signicados de una palabra o una frase seg\u00b4 un el contex- to), indeterminaci\u00b4 on (permitiendo referencias y elipsis) y distintas interpretaciones del sentido literal seg\u00b4 un la situaci\u00b4 on o el contex- to en que se produce. Lo que son ventajas para la comunicaci\u00b4 on humana se convierten en problemas a la hora de un tratamien- to computacional, ya que implican conocimiento y procesos de razonamiento que son dif\u00b4 ciles de formalizar. Debido a estas ca- racter\u00b4 sticas del lenguaje natural, es necesario utilizar una serie de t\u00b4 ecnicas de PLN para trabajar con texto y expresiones huma- nas que permitan resolver a partir de un an\u00b4 alisis dirigido por el dominio, el uso, el contexto, etc, los distintos problemas de inter- pretaci\u00b4 on que puedan aparecer. En el campo del PLN el problema de la ambig\u00a8 uedad puede tratarse desde distintas perspectivas. Desde la ambig\u00a8 uedad debida a palabras polis\u00b4 emicas, hasta la ambig\u00a8 uedad producida por las distintas interpretaciones que pueda tener una oraci\u00b4 on. Dentro del PLN, por tanto, podemos distinguir tres tipos de ambig\u00a8 uedad: Ambig\u00a8 uedad l\u00b4 ferentes categor\u00b4 as gramaticales. Por ejemplo: La palabra \"para\" puede ser: preposici\u00b4 on, forma del verbo parar o forma del verbo parir. Ambig\u00a8 uedad sint\u00b4 actica o ambig\u00a8 uedad estructural Aparece cuando debido a la forma en que se asocian los distintos cons- tituyentes de una oraci\u00b4 on, podemos interpretarla de varias for- mas distintas. Siendo a veces casi imposible de solucionar. Por ejemplo: Juan vio a su hermana con unos prism\u00b4 aticos (\u00bfJuan us\u00b4 o los prism\u00b4 aticos para ver a su hermana o Juan vio que su hermana ten\u00b4 a unos prism\u00b4 aticos?) Ambig\u00a8 podemos diferenciar tres clases: 1.Ambig\u00a8 uedad debida a las palabras polis\u00b4 emicas. En este caso, una misma palabra puede tener distintos signicados dependiendo del uso que se le est\u00b4 e dando en cada momento. 1. Introducci\u00b4 on 5 Juan vio a su hermana con unos prism\u00e1ticos Juan vio a su hermana con unos prism\u00e1ticos Figura 1.1. Ambig\u00a8 uedad sint\u00b4 actica . (Entidad nanciera) Se sent\u00b4 o en el banco del parque. (Asiento) 2.Ambig\u00a8 uedad debida a encontrar una misma estructura sint\u00b4 actica con diferentes signicados. Por ejemplo: Todos los estudiantes de secundaria hablan dos lenguas . (\u00bfCada estudiante habla dos lenguas o s\u00b4 olo se hablan dos lenguas determinadas?) 3.Ambig\u00a8 uedad referencial. En este caso, es necesario el an\u00b4 ali- sis del texto m\u00b4 as all\u00b4 a de los l\u00b4 mites de la frase, determinan- do los antecedentes referenciales de los pronombres. Por ejemplo: El jam\u00b4 on est\u00b4 a en al jam\u00b4 on o al armario?) La resoluci\u00b4 on de los diferentes tipos de ambig\u00a8 uedades requie- re mucho conocimiento y es necesario aplicar diferentes t\u00b4 ecnicas para solucionar cada caso. Podemos utilizar modelos de Markov (Markov (1971 )) para basadas para resolver la ambig\u00a8 uedad sem\u00b4 antica. El tratamiento de la ambig\u00a8 uedad, es por tanto, una tarea necesaria para cualquier sistema de PLN, 6 1.2 Estructura de un sistema de PLN pero esta tarea no funciona de forma independiente, se comple- menta con otras tareas como el an\u00b4 alisis sint\u00b4 atico que le suministra informaci\u00b4 on muy valiosa. De esta forma, podemos decir que la ta- rea de resoluci\u00b4 on de la ambig\u00a8 uedad es una tarea intermedia que completa un sistema de PLN. 1.2 Estructura de un sistema de PLN Si se analizan en profundidad los actuales sistemas de PLN to- dos ellos comparten una serie de m\u00b4 odulos b\u00b4 asicos para su correcto funcionamiento. La Figura 1.2muestra la estructura general de un sistema de PLN. Texto An\u00e1lisis L\u00e9xico An\u00e1lisis Sint\u00e1ctico An\u00e1lisis Sem\u00e1ntico Unidades l\u00e9xicas (palabras) \u00c1rbol sint\u00e1ctico (Sujeto, predicado, N, V, Adj, Adv) Significado (polisemia) Gram\u00e1tica Diccionario Ontolog\u00eda sem\u00e1ntica Figura 1.2. Estructura de un sistema de PLN Como se puede apreciar en la Figura 1.2y suponiendo que estamos procesando texto, tenemos tres m\u00b4 odulos principal tarea de este m\u00b4 odulo es detectar palabras, es decir, la menor unidad existente con signicado. Dentro del l\u00b4 exico de un lenguaje es necesario de- tectar adem\u00b4 as de las palabras simples, las palabras compues- tas, frases hechas, siglas, pr\u00b4 estamos idiom\u00b4 aticos, etc. Adem\u00b4 as tambi\u00b4 en es necesario diferenciar entre la forma (la palabra tal como aparece) y el lema (la forma can\u00b4 onica de la palabra). El objetivo nal de este m\u00b4 odulo es asociar a cada palabra su lema correspondiente, etiquetar cada palabra con sus posibles categor\u00b4 as l\u00b4 exicas (N, V, Adj, Adv) y a nadir algunos rasgos gramaticales (g\u00b4 enero, n\u00b4 selecciona la eti- queta gramatical m\u00b4 as apropiada para cada palabra, realiza un \"chunking\" del texto (divide el texto en segmentos analiza- bles), utiliza formas l\u00b4 gue al an\u00b4 alisis sint\u00b4 actico. En este caso se ocupa de asignar el sentido correspondiente a cada palabra (resolver la am- big\u00a8 uedad sem\u00b4 antica). Este alisis sint\u00b4 aplicables para uedad: l\u00b4 ogica de predicados, redes sem\u00b4 anticas, grafos de dependencias conceptuales, etc. Seg\u00b4 un la Figura 1.2, los distintos m\u00b4 odulos de un sistema de PLN necesitan fuentes externas tales como diccionarios, gram\u00b4 ati- cas u ontolog\u00b4 as, que se adec\u00b4 uen al idioma o al dominio de los textos a tratar. Estas fuentes externas de conocimiento dotan al sistema de la informaci\u00b4 on necesaria para poder establecer las re- glas de la gram\u00b4 atica, el dominio de aplicaci\u00b4 on de los textos, las relaciones entre palabras a partir de una jerarqu\u00b4 a, etc. Como veremos m\u00b4 as adelante, todos los recursos l\u00b4 exicos uti- lizados por un sistema de en teor\u00b4 as psico- ling\u00a8 u\u00b4 sticas adaptadas al idioma de estudio. En nuestro caso, se han utilizado diversos recursos l\u00b4 exicos externos para realizar la 8 1.3 Objetivo de la Tesis tarea de desambiguaci\u00b4 on, que como indica la Figura 1.2se realiza en el m\u00b4 odulo de an\u00b4 alisis sem\u00b4 antico. 1.3 Objetivo de la Tesis Dada la necesidad actual de tratamiento del lenguaje natural y descubierta la problem\u00b4 atica de la ambig\u00a8 uedad intr\u00b4 nseca en el lenguaje humano, es necesario el tratamiento de forma ecaz de este problema. Como se ha mencionado anteriormente, existen distintos tipos de ambig\u00a8 uedad: l\u00b4 exica, sint\u00b4 actica y distintos tipos de ambig\u00a8 uedad requiere de la aplicaci\u00b4 on de t\u00b4 ecnicas de PLN espec\u00b4 cas. Por tanto, es dif\u00b4 cil intentar abarcar la resoluci\u00b4 on de todos los tipos de ambig\u00a8 uedad utilizando una mis- ma t\u00b4 ecnica, y es por ello, que esta Tesis est\u00b4 a centrada \u00b4 unicamente en la resoluci\u00b4 on de la ambig\u00a8 uedad sem\u00b4 antica, que est\u00b4 vinculada a la aparici\u00b4 on de palabras polis\u00b4 emicas en el lenguaje. El objetivo principal de esta Tesis es desarrollar distintos m\u00b4 eto- dos de resoluci\u00b4 on de la ambig\u00a8 uedad basados en cimiento. Cuando hablamos de m\u00b4 etodos basados en conocimien- to hacemos referencia a aquellos m\u00b4 etodos que no necesitan de corpus extensos para poder funcionar, sino que utilizan recursos l\u00b4 exicos como diccionarios u ontolog\u00b4 as para extraer las relaciones existentes entre palabras y construir estructuras de datos con in- formaci\u00b4 on relevante que determine la similitud entre diferentes contextos, palabras, etc. Se ha demostrado que los resultados ob- tenidos con m\u00b4 etodos basados en conocimiento son relativamente m\u00b4 as bajos que los de otros m\u00b4 etodos basados en t\u00b4 ecnicas de apren- dizaje, pero la ventaja de los m\u00b4 etodos basados en conocimiento radica en que su aplicaci\u00b4 on es muy \u00b4 util en el caso de estudio de lenguas minoritarias, ya que encontrar corpus extensos de estas lenguas es muy complicado. En esta Tesis se presentan varios m\u00b4 etodos basados en cono- cimiento con distintos enfoques, aplicados a la desambiguaci\u00b4 on autom\u00b4 atica: 1. Introducci\u00b4 on 9 WSD DRelevant. las categor\u00b4 as sem\u00b4 anticas de WordNet El objetivo de este m\u00b4 etodo es la determinaci\u00b4 on del sentido correcto de las palabras a partir del establecimiento del dominio contextual donde aparecen. El proceso comienza mediante la obtenci\u00b4 on de un nuevo recurso l\u00b4 exico (Dominios Relevantes) basado en la frecuencia de apa- rici\u00b4 on de las palabras junto a diferentes dominios en WordNet. Este recurso es la base de todo el proceso de desambiguaci\u00b4 on centrado en medidas de frecuencia y co-ocurrencia. WSD DLSA. Basado en la utilizaci\u00b4 on del An\u00b4 alisis de Sem\u00b4 antica Latente. construye un espacio sem\u00b4 antico con diferentes categor\u00b4 as obje- tivo de este m\u00b4 etodo es establecer aquellas relaciones ocultas entre palabras que no pertenecen al mismo dominio o categor\u00b4 a sem\u00b4 antica pero s\u00b4 tienen WSD en la utilizaci\u00b4 on de patrones y dis- criminadores de sentidos. El objetivo de este m\u00b4 etodo es extraer ocurrencias de patrones l\u00b4 exicos a partir de diferentes contex- tos y determinar el sentido de las palabras presentes en dichos patrones utilizando la jerarqu\u00b4 a de WordNet. Todos los m\u00b4 etodos descritos se basan en la premisa de que las palabras que aparecen en un mismo contexto tienden a estar re- lacionadas sem\u00b4 anticamente. Es decir, es m\u00b4 as probable que una palabra que aparezca en contextos similares tenga el mismo senti- do, que esa misma palabra, en contextos dispares tenga el mismo signicado. Asimismo, la ambig\u00a8 uedad en el lenguaje no es un problema aislado en PLN, sino que afecta a diferentes \u00b4 areas: traducci\u00b4 on autom\u00b4 atica, extracci\u00b4 on de informaci\u00b4 on, recuperaci\u00b4 on de documen- tos, etc. Consecuentemente, en esta Tesis se han aplicado las t\u00b4 ecni- cas de desambiguaci\u00b4 on autom\u00b4 atica propuestas, sobre algunas apli- caciones nales de PLN. Entre estas aplicaciones destacamos la detecci\u00b4 on de par\u00b4 afrasis e implicaci\u00b4 on textual o la desambiguaci\u00b4 on y discriminaci\u00b4 on de entidades. El objetivo principal en este \u00b4 area, es demostrar que la inclusi\u00b4 on de sistemas de resoluci\u00b4 on autom\u00b4 ati- ca de la ambig\u00a8 uedad, es necesaria para la obtenci\u00b4 on de buenos 10 resultados. Adem\u00b4 as, el recurso l\u00b4 exico obtenido a partir de los do- minios relevantes de WordNet, es una herramienta muy \u00b4 util y que proporciona informaci\u00b4 on beneciosa para diferentes aplicaciones de PLN. 1.4 Organizaci\u00b4 on de la Tesis Esta Tesis se ha estructurado en siete cap\u00b4 tulos: Cap\u00b4 en el Procesamiento del Len- guaje Natural debida a la ambig\u00a8 uedad del lenguaje, objetivos y estructura de la Tesis. Cap\u00b4 tulo 2: Estado del arte. Descripci\u00b4 on de la evoluci\u00b4 on de los sistemas de desambiguaci\u00b4 on autom\u00b4 atica, evaluaci\u00b4 on de sistemas de WSD. Descripci\u00b4 on de los distintos tipos de anotaciones utilizados pa- ra etiquetar los sentidos de las palabras, corpus, etc. Problemas de establecimiento de los sentidos correctos de las palabras y diferentes medidas de evaluaci\u00b4 on utilizadas. Cap\u00b4 tulo 4: Recursos. Descripci\u00b4 on de recursos l\u00b4 exicos utilizados. Estudio de las ven- tajas e inconvenientes de cada recurso. Combinaci\u00b4 on de recursos con el objetivo de mejorar los resultados obtenidos. Cap\u00b4 tulo 5: tareas de PLN. Cap\u00b4 tulo 6: Evaluaci\u00b4 on. Realizaci\u00b4 on de diversos experimentos para la evaluaci\u00b4 on de los m\u00b4 etodos. Comparativa de los resultados obtenidos con diferen- tes aproximaciones. Cap\u00b4 tulo 7: Conclusiones y trabajos futuros. Aportaci\u00b4 on de esta Tesis al campo de la desambiguaci\u00b4 on autom\u00b4 ati- ca y propuesta de trabajos futuros. Relaci\u00b4 on de publicaciones derivadas de la consecuci\u00b4 on de esta Tesis. Cap\u0013\u0010tulo 2 Estado del arte En este cap\u00b4 tulo se presenta una breve introducci\u00b4 on al proble- ma de la ambig\u00a8 uedad sem\u00b4 antica junto con las distintas aplicacio- nes en las que es necesario la aplicaci\u00b4 on de t\u00b4 ecnicas para resolver este tipo de ambig\u00a8 uedad. Adem\u00b4 as se establece la evoluci\u00b4 on de los diferentes sistemas de resoluci\u00b4 on de la ambig\u00a8 uedad sem\u00b4 antica y su clasicaci\u00b4 on a partir de los recursos que utilizan. 2.1 Descripci\u00b4 on del problema Es muy com\u00b4 un encontrar en cualquier idioma palabras con m\u00b4 ultiples signicados; por ejemplo, \"flojo\" puede signicar algo que est\u00b4 a poco apretado o alguien que es un cobarde. El signica- do particular de una palabra viene determinado por el contexto que la rodea y en muchas ocasiones por la situaci\u00b4 on en que se emplea. Si por ejemplo, decimos: \"Te has dejado los cordones de los zapatos demasiado flojos \", en este caso, sabemos exactamente el signicado asociado a esta palabra. El procedimiento para decidir los signicados de las palabras a partir del contexto que las rodea se conoce como \"desambigua- ci\u00b4 on\" o \"Word Sense Disambiguation\" (WSD). En procesamiento del lenguaje natural las investigaciones en WSD han existido desde la aparici\u00b4 on de este \u00b4 area de investigaci\u00b4 on. 12 2.2 Aplicaciones de WSD Es m\u00b4 as, WSD se ha considerado como una tarea completamen- te distinta a otras dirigidas al usuario nal, como por ejemplo, Traducci\u00b4 on Autom\u00b4 atica. De hecho, para obtener un buen sistema de Traducci\u00b4 on Autom\u00b4 atica es necesario resolver el problema de la ambig\u00a8 uedad, y poder proporcionar de esta forma, una buena comprensi\u00b4 on del lenguaje. A continuaci\u00b4 on se van a describir algunas de los m\u00b4 etodos m\u00b4 as conocidos para resolver el problema de WSD. Adem\u00b4 as, se mostrar\u00b4 an los avances m\u00b4 as recientes en este campo, dentro de una de las competiciones m\u00b4 as importantes: Senseval (Kilgarri autom\u00b4 atica la desambiguaci\u00b4 on es uno de los principales problemas que necesitan tratamiento. Aunque este es uno de los principales usos de WSD tambi\u00b4 en deben considerar- se otras muchas aplicaciones de PLN que necesitan resolver este problema. Recientemente han aparecido nuevas \u00b4 areas de cono- cimiento y el tratamiento autom\u00b4 atico para la resoluci\u00b4 on de la ambig\u00a8 uedad es muy necesario. Entre estas nuevas \u00b4 areas de co- nocimiento encontramos por ejemplo la bioinform\u00b4 atica y la Web Sem\u00b4 antica. A continuaci\u00b4 on vamos a ver qu\u00b4 e necesidades tienen las diferen- tes tareas de PLN y de qu\u00b4 e forma se aplica la desambiguaci\u00b4 on autom\u00b4 atica su correcto funcionamiento: Traducci\u00b4 atica (TA). WSD es necesaria para la selecci\u00b4 on de la correcta traducci\u00b4 on de palabras que pueden tener distintas acepciones seg\u00b4 un el sentido asignado. Por ejemplo, en un texto que necesite ser traducido del ingl\u00b4 es al franc\u00b4 es pode- mos encontrar la palabra \" change \" que puede ser traducida como \"changement \" (transformaci\u00b4 on) o \" monnaie \" (dinero suelto). En TA, los sentidos se representan a menudo como palabras en el len- guaje de traducci\u00b4 on destino. Sin embargo, muchos modelos de TA no utilizan WSD expl\u00b4 citamente. En muchos casos el vocabulario es pre-desambiguado para un dominio determinado, se desarrollan 2. Estado del arte 13 reglas hechas a mano o WSD est\u00b4 a almacenado en un modelo de traducci\u00b4 on estad\u00b4 stico ( Brown et al. (1991 )). Recuperaci\u00b4 on de Informaci\u00b4 on (RI). En este caso, la am- big\u00a8 uedad debe ser resuelta en algunas cuestiones. Por ejemplo, si tenemos una cuesti\u00b4 on en la que aparece la palabra \" depres- sion\", el sistema de RI podr\u00b4 a devolver documentos que hablan sobre enfermedades, el tiempo o econom\u00b4 a. Un problema similar aparece asociado a nombres propios tales como \" Raleigh \" (bici- cleta, persona, ciudad, etc). Los sistemas actuales de RI no utili- zan expl\u00b4 citamente WSD, \u00b4 unicamente se basan en que el usuario d\u00b4 e el suciente contexto en la pregunta para extraer \u00b4 unicamente los documentos relevantes al sentido correcto (ej \" tropical depres- sion\"). Experimentos recientes sugieren que un sistema able de RI necesitar\u00b4 a al menos un 90 % de precisi\u00b4 on en WSD ( Sanderson (1994 )). Recientemente, se ha comprobado que WSD mejora la \"cross-lingual IR\" y la clasicaci\u00b4 on de documentos ( Vossen et al. (2006 ),Bloehdorn y Hotho (2004 ),Clough y Stevenson (2004 )). Otras aplicaciones relacionadas con clasicaci\u00b4 on de documentos y \"cross-lingual IR\" incluyen recomendaci\u00b4 on de noticias, alertas y posicionamiento autom\u00b4 atico de publicidad. Extracci\u00b4 on de Informaci\u00b4 on (EI) y Miner\u00b4 a de Textos. WSD es necesaria para el correcto an\u00b4 alisis de los textos en muchas aplicaciones. Por ejemplo, las investigaciones en bioinform\u00b4 atica requieren establecer las relaciones entre genes y productos gen\u00b4 eti- cos para ser catalogados a trav\u00b4 es de la amplia literatura cient\u00b4 ca. Sin embargo, los genes y sus prote\u00b4 nas a menudo tienen el mis- mo nombre. De forma m\u00b4 as general, la Web Sem\u00b4 antica requiere anotaci\u00b4 on autom\u00b4 atica de documentos de acuerdo a una ontolog\u00b4 a de referencia: todas las referencias textuales deben estar asigna- das a conceptos y estructuras de eventos en la ontolog\u00b4 a ( Dill et al. (2003 )). La clasicaci\u00b4 on de entidades, la determinaci\u00b4 on de co-referencias y la expansi\u00b4 on de acr\u00b4 onimos (MG como magnesio o miligramos) puede tambi\u00b4 en clasicarse como un problema de WSD para nombres propios. Actualmente, WSD est\u00b4 a empezando a aplicarse en estas \u00b4 areas. Lexicograf\u00b4 a. La lexicograf\u00b4 a moderna est\u00b4 a basada en corpus, por tanto, WSD y lexicograf\u00b4 a pueden trabajar conjuntamente, 14 2.3 Sistemas iniciales: el comienzo de forma que WSD proporcione grupos e indicadores contextuales signicativos de sentidos a los lexic\u00b4 ografos, los cuales, producir\u00b4 an mejores inventarios de sentidos y de corpus anotados para WSD. A pesar de este amplio rango de aplicaciones donde WSD mues- tra un gran potencial para ser de utilidad, a\u00b4 un no se ha demostra- do que proporcione mejoras signicativas en este tipo de aplica- ciones. Existen varios resultados aislados que muestran muy pocas mejoras y en algunos casos puede perjudicar el rendimiento como muestra un experimento realizado sobre RI ( Sanderson (1994 )). Existen varias posibles razones para esto. En primer lugar, el do- minio de una aplicaci\u00b4 on a menudo restringe el n\u00b4 umero de sentidos que una palabra puede tener (por ejemplo, no esperar\u00b4 amos tener \"banco\" con el sentido \"Conjunto de peces que van juntos en gran n\u00b4 umero\" en un documento que hable sobre nanzas), por tanto, los lexicones pueden construirse adaptados al dominio. En segun- do lugar, WSD todav\u00b4 a no est\u00b4 a lo sucientemente desarrollada como para mostrar un efecto signicativo. En tercer lugar, tratar la WSD como un m\u00b4 odulo espec\u00b4 co, signica que no puede inte- grarse apropiadamente dentro de una aplicaci\u00b4 on particular o ser entrenada dentro de un dominio espec\u00b4 co. Muchas aplicaciones como TA, no tienen un lugar para un m\u00b4 odulo de WSD, por tanto, o la aplicaci\u00b4 on el m\u00b4 odulo de WSD deben ser redise nados. A pesar de todo ello, queda patente que las aplicaciones requie- ren de WSD de alguna forma. Por ejemplo, en RI, una cuesti\u00b4 on de dos palabras puede desambiguarse impl\u00b4 citamente, debido a que ambas palabras se utilizan juntas en los textos con su correspon- diente sentido asociado (por ejemplo, \" tropical depression \"). El trabajo en WSD puede servir para explorar y remarcar las carac- ter\u00b4 sticas particulares que proporcionen mejores resultados para una desambiguaci\u00b4 on m\u00b4 as precisa. 2.3 Sistemas iniciales: el comienzo Toda \u00b4 area de investigaci\u00b4 on tiene sus comienzos y por supuesto en WSD tambi\u00b4 en existieron los primeros sistemas desarrollados alrededor de los a nos 70 y 80. 2. Estado del arte 15 Uno de los primeros sistemas que trataron de resolver el pro- blema de la ambig\u00a8 uedad l\u00b4 exica fue el creado por ( Wilks (1972 )). En este caso, se utilizaron restricciones de selecci\u00b4 on organizadas jer\u00b4 arquicamente junto con representaciones sem\u00b4 anticas denominadas f\u00b4 ormulas. En este sistema, la hip\u00b4 otesis era que para cada uno de los di- ferentes sentidos de una palabra exist\u00b4 a una f\u00b4 ormula asociada. El sistema inclu\u00b4 jerarqu\u00b4 a ocho caracter\u00b4 sticas HUMAN ,WANT los ad- jetivos conten\u00b4 an las preferencias sem\u00b4 anticas de los nombres a los que pod\u00b4 an acompa nar, al igual que las f\u00b4 ormulas para los verbos que conten\u00b4 an las preferencias de los nombres con los que estaban relacionados. La polisemia ven\u00b4 a determinada al asignar m\u00b4 as de una f\u00b4 ormula a una misma palabra. La forma de obtener los senti- dos de cada palabra era obteniendo una f\u00b4 ormula para cada una de las palabras, que maximizara el n\u00b4 umero de preferencias para una frase determinada. De esta forma, se pod\u00b4 a establecer el sentido de todas las palabras de una frase simult\u00b4 aneamente. Finalmente, la evaluaci\u00b4 on del sistema se realiz\u00b4 o sobre textos obtenidos a partir de art\u00b4 culos de peri\u00b4 odicos. Otro sistema realizado S.(1980 )) ten\u00b4 a como hip\u00b4 otesis que el conocimiento humano sobre el lenguaje se debe principal- mente al conocimiento sobre palabras m\u00b4 as que al conocimiento de reglas ( Small y Rieger (1982 )). Sin embargo, este punto de vista es poco convencional y no se han realizado estudios que sostengan esta teor\u00b4 a psicoling\u00a8 u\u00b4 stica. 2.4 Clasicaci\u00b4 on de sistemas en WSD Desde los primeros sistemas de WSD hasta la actualidad han surgido nuevas propuestas y distintos enfoques para resolver es- te problema. Una forma muy extendida de clasicar los sistemas de WSD es bas\u00b4 andose en la principal fuente de conocimiento uti- lizada para establecer los diferentes sentidos. En primer lugar, tenemos los m\u00b4 etodos que utilizan diccionarios, tesauros y bases de conocimiento l\u00b4 exicas, sin utilizar ning\u00b4 un corpus (etiquetado o 16 2.5 M\u00b4 etodos basados en conocimiento no). Este tipo de m\u00b4 etodos son los denominados \" dictionary-based \" o \"knowledge-based \". Por otra parte, tenemos aquellos m\u00b4 etodos que evitan casi completamente la informaci\u00b4 on externa y traba- jan directamente con corpus sin etiquetar, son los denominados m\u00b4 etodos no supervisados. Dentro de esta categor\u00b4 a encontramos los m\u00b4 etodos que utilizan \" word-aligned corpora \" para acumular \"cross-linguistic evidence \" para discriminaci\u00b4 on de sentidos. Fi- nalmente, tenemos los sistemas supervisados y semi-supervisados, estos utilizan corpus anotados sem\u00b4 anticamente como en- trenamiento, o como fuente de datos en un sistema de \" bootstrap- ping\". Casi todas las aproximaciones de aprendizaje supervisado se han aplicado a WSD, incluyendo algoritmos agregativos y discri- minativos y etc. Los m\u00b4 etodos no supervisados tienen la ventaja de evitar el cuello de botella existente en la adquisici\u00b4 on de nuevo conocimien- to (anotaci\u00b4 on manual) ( Boguraev y Briscoe (1989 Sch\u00a8 utze (1998 )). Estos m\u00b4 etodos son capaces de inducir sentidos de palabras, a partir de textos de entrenamiento, agrupando (mediante clusters) ocurren- cias de palabras y clasicando entonces nuevas ocurrencias en los clusters inducidos. Las propuestas basadas en conocimiento de los a nos 1970 y 1980 est\u00b4 an todav\u00b4 a en proceso de investigaci\u00b4 on. Las principales t\u00b4 ecnicas utilizan restricciones de selecci\u00b4 on, el solapamiento de tex- tos y medidas de similitud sem\u00b4 antica. Actualmente, la tendencia es hacer una inferencia sem\u00b4 antica general utilizando bases de co- nocimiento, obteniendo como resultado una desambiguaci\u00b4 on. En la Tabla 2.1tenemos un resumen de las distintas aproxi- maciones a WSD. 2.5 M\u00b4 etodos basados en conocimiento En esta categor\u00b4 a encontramos diferentes algoritmos para la etiquetaci\u00b4 on autom\u00b4 atica de sentidos. Normalmente, el rendimien- 2. Estado del arte 17 M\u00b4 etodos Procedimiento Basados en conocimiento Creaci\u00b4 on de reglas de desambiguaci\u00b4 on Restricciones de selecci\u00b4 on (o preferencias), utilizadas para ltrar sentidos incongruentes Comparaci\u00b4 on de las deniciones de los diccionarios con el contexto (m\u00b4 etodo de Lesk) Selecci\u00b4 on del sentido m\u00b4 as similar al contexto, utilizando medidas de similitud sem\u00b4 antica Un sentido por discurso y otras heur\u00b4 sticas Basados en corpus no supervisados M\u00b4 etodos no supervisados que clasican palabras o con- textos en diferentes clusters, obteniendo los diferentes sentidos Utilizaci\u00b4 on de corpus paralelos para inferir sentidos en- tre diferentes idiomas Basados en corpus supervisados Aprendizaje autom\u00b4 atico supervisado, utilizando corpus de entrenamiento combinadas con m\u00b4 etodos basados en conocimiento Utilizaci\u00b4 on de m\u00b4 etodos basados en conocimiento para buscar ejemplos que sirvan de entrenamiento en m\u00b4 eto- dos supervisados Utilizaci\u00b4 on de corpus paralelos combinados con m\u00b4 eto- dos basados en conocimiento Tabla 2.1. Clasicaci\u00b4 on de m\u00b4 etodos de WSD to de estos m\u00b4 etodos basados en conocimiento, es menor en com- paraci\u00b4 on con los m\u00b4 etodos basados en corpus. Pero con la salvedad de que los m\u00b4 etodos basados en conocimiento tienen una amplia cobertura ya que pueden aplicarse a cualquier tipo de texto en comparaci\u00b4 on con los basados en corpus que s\u00b4 olo se pueden aplicar a aquellas palabras de las que se dispone de corpus anotados. A continuaci\u00b4 on vamos a enumerar diferentes t\u00b4 ecnicas utiliza- das por los m\u00b4 etodos basados en conocimiento, aplicables sobre cualquier base de conocimiento l\u00b4 exica que dena sentidos de pa- labras y relaciones entre ellas. La base de conocimiento l\u00b4 exica m\u00b4 as utilizada es WordNet ( Miller (1995 )). Vamos a describir 4 tipos diferentes de m\u00b4 etodos basados en conocimiento: 1.El algoritmo de Lesk, en el cual, los sentidos de las palabras de un contexto se identican bas\u00b4 andose en una medida de so- lapamiento contextual entre las deniciones de un diccionario. 18 2.5 M\u00b4 etodos basados en conocimiento 2.Medidas de similitud sem\u00b4 a trav\u00b4 a incluye distancia sem\u00b4 antica existente entre diferentes con- ceptos. Dependiendo del tama no del contexto estas medidas se dividen en dos grandes categor\u00b4 as: M\u00b4 etodos aplicables a un contexto local, donde las medidas de similitud sem\u00b4 antica se utilizan para desambiguar palabras conectadas por relaciones sint\u00b4 acticas o por su localizaci\u00b4 on. M\u00b4 etodos aplicables a contextos globales, donde las cade- nas l\u00b4 exicas son derivadas bas\u00b4 andose sem\u00b4 antica l\u00b4 exica es un hilo de signicado extra\u00b4 do a trav\u00b4 es del texto total). 3.Preferencias de selecci\u00b4 on adquiridas de forma autom\u00b4 atica o semi-autom\u00b4 atica, como una forma de restringir los posibles sentidos de una palabra, basados en la relaci\u00b4 on que \u00b4 esta tiene con otras palabras en el contexto. 4.M\u00b4 etodos heur\u00b4 sticos, que consisten en reglas que pueden asig- nar un sentido a ciertas categor\u00b4 as de palabras, incluyendo: El sentido m\u00b4 as frecuente. Un sentido por colocaci\u00b4 on. Un sentido por discurso. Estos cuatro tipos de m\u00b4 etodos se van a tratar en detalle en las siguientes secciones. 2.5.1 Algoritmo de Lesk El algoritmo de Lesk ( Lesk (1986 )) es uno de los primeros algo- ritmos desarrollados para la desambiguaci\u00b4 on sem\u00b4 antica de todas las palabras en cualquier texto. El \u00b4 unico recurso requerido por el algoritmo es un conjunto de entradas de un diccionario, una por cada posible sentido y conocimiento sobre el contexto inmediato donde se desarrolla la desambiguaci\u00b4 on. Aunque este algoritmo se considera un m\u00b4 etodo basado en dic- cionarios, tambi\u00b4 en es el punto de partida para los algoritmos ba- sados en corpus. Casi todos los algoritmos supervisados se basan de alguna forma en solapamiento contextual, midiendo ese solapa- 2. Estado del arte 19 miento entre el contexto de una palabra ambigua y los contextos espec\u00b4 cos para cada uno de los sentidos de esa palabra. La principal idea de este algoritmo es desambiguar palabras encontrando el solapamiento entre las deniciones de sus sentidos. En otras palabras, dadas dos palabras, W1yW2, cada una con sus respectivos sentidos Nw1yNw2denidos en un diccionario, para cada par de posibles sentidos Wi 1yWj 2,i= 1::Nw1,j= 1::Nw2, primero se determina el solapamiento con las correspondientes deniciones contando el n\u00b4 umero de palabras que tienen en com\u00b4 un. A continuaci\u00b4 on, el par de sentidos con el mayor solapamiento es seleccionado y entonces se le asigna un sentido a cada palabra del par inicial. En la Tabla 2.2se muestran los principales puntos de este algoritmo. (1) Para cada sentido ideW1 (2) Para cada sentido jdeW2 (3) Calcular el solapamiento( i; j), el n\u00b4 umero de palabras en com\u00b4 un entre las deniciones del sentido iy el sentido j (4) Encontrar iyjtales que el solapamiento( i; j) sea el m\u00b4 aximo (5) Asignar el sentido iaW1y el sentido jaW2 Tabla 2.2. Algoritmo de Lesk Un ejemplo representativo de este algoritmo ser\u00b4 a el siguiente: Consideremos que queremos desambiguar las palabras \" pine\" y \"cone\", mediante el par de palabras \" pine cone \". El diccionario Oxford Advanced Learner's dene cuatro sentidos para \" pine\" y tres sentidos para \" cone\", tal y como muestra la Tabla 2.3. En la Tabla 2.4podemos ver el solapamiento existente entre cada sentido de \" pine\" y cada sentido de \" cone\". La primera denici\u00b4 on de \" pine\" y la tercera de \" cone\" tienen el m\u00b4 aximo solapamiento entre todas las posibles combinaciones de sentidos, con dos palabras en com\u00b4 un: \" evergreen \" y \" tree\", por lo tanto, estos son los sentidos seleccionados por el algoritmo de Lesk. Este algoritmo fue evaluado sobre un conjunto de pares de pa- labras ambiguas manualmente anotados, utilizando el diccionario 20 2.5 M\u00b4 etodos basados en conocimiento pine 1* seven kinds of evergreen tree with needle-shaped leaves 2 pine 3 waste away through sorrow or illness 4 pine for something, pine to do something cone 1 solid body which narrows to a point 2 something of this shape, whether solid or hollow 3* fruit of certain evergreen trees (r, pine) Tabla 2.3. para \" pine\" y \" cone\" Pine #1TCone #1 0 Pine #2TCone #1 Pine #3TCone #1 = 0 Pine #4TCone #1 = 0 Pine #1TCone #2 = 0 Pine #2TCone #2 = 0 Pine #3TCone #2 = 1 Pine #4TCone #2 = 0 Pine #1TCone #3 = 2 Pine #2TCone #3 = 1 Pine #3TCone #3 = 0 Pine #4TCone #3 = 1 Tabla 2.4. Solapamiento entre \" pine\" y \" cone\" Oxford Advanced Learner's, obteniendo una precisi\u00b4 on entre 50 y 70 % ( Lesk (1986 )). 2.5.2 Variaciones del algoritmo de Lesk Desde el planteamiento inicial del algoritmo de Lesk en 1986 se han propuesto varias variantes del algoritmo, incluyendo: Versiones del algoritmo que tratan de resolver el problema de la explosi\u00b4 on combinatoria cuando se consideran m\u00b4 as de dos pa- labras. Versiones del algoritmo donde cada palabra de un contexto de- terminado es desambiguada individualmente midiendo el sola- pamiento entre cada denici\u00b4 on del diccionario y el contexto en el cual aparece. 2. Estado del arte 21 Alternativas donde el espacio sem\u00b4 antico de una palabra es aumentado con deniciones de palabras relacionadas sem\u00b4 anti- camente. 2.5.2.1 Simulated Annealing. Una de las principales desventajas del algoritmo de Lesk ini- cial, es que conlleva una explosi\u00b4 on combinatoria cuando se trata de aplicar a la desambiguaci\u00b4 on de m\u00b4 as de dos palabras. Por ejem- plo, podemos considerar el texto \"I saw a man who is 98 years old and can still walk and tell jokes\" , con nueve palabras a de- sambiguar, cada una de ellas con sus correspondientes sentidos: \"see(26)\", \" man(11)\", \" total de 43929600 combina- ciones de sentidos pueden ser posibles para este texto, por lo tanto, el algoritmo de Lesk original no es una aproximaci\u00b4 on \u00b4 optima para este problema. Una soluci\u00b4 on posible ser\u00b4 a utilizar el algoritmo \"simulated , propuesto Cowie et al. ( et al. (1992 )). En esta propuesta, se dene una funci\u00b4 on Eque refleja las combinaciones de sentidos en un texto, y cuyo valor m\u00b4 nimo se corresponde con la selecci\u00b4 on de los sentidos correctos. Para una combinaci\u00b4 on dada de sentidos, se extraen todas las deniciones correspondientes de un diccionario y cada palabra que aparece en una de estas de- niciones recibe un valor igual a su n\u00b4 umero de ocurrencias. Unien- do todos estos valores se obtiene la \"redundancia\" del texto. La funci\u00b4 on Ese dene entonces como la inversa de la redundancia, siendo el objetivo nal encontrar la combinaci\u00b4 on de sentidos que minimice esta funci\u00b4 on. Para este prop\u00b4 osito, se determina una com- binaci\u00b4 on inicial de sentidos (por ejemplo, se recogen los sentidos m\u00b4 as frecuentes para cada palabra), y entonces se realizan varias iteraciones, donde el sentido de una palabra aleatoria en el tex- to se reemplaza con otro sentido distinto, y la nueva selecci\u00b4 on se considera correcta \u00b4 unicamente si reduce el valor de la funci\u00b4 on E. Las iteraciones terminan cuando no existe ning\u00b4 un cambio en la conguraci\u00b4 on de los sentidos. La evaluaci\u00b4 on de este m\u00b4 etodo so- bre 50 frases de ejemplo consigui\u00b4 o un 47 % de precisi\u00b4 on a nivel 22 2.5 M\u00b4 etodos basados en conocimiento de sentidos y un 72 % de precisi\u00b4 on a nivel de hom\u00b4 ografos. Este m\u00b4 etodo re-implementado ( Stevenson y Wilks (2001 )) obteniendo un valor similar de precisi\u00b4 on, en torno a un 65 ;24 % en un corpus etiquetado con los sentidos del Longman Dictionary of Contemporary English1(LDOCE). 2.5.2.2 Algoritmo de Lesk versi\u00b4 on del algoritmo de Lesk, que tambi\u00b4 en trata de re- solver el problema de la explosi\u00b4 on combinatoria, es una variaci\u00b4 on simplicada que utiliza un proceso separado de desambiguaci\u00b4 on para cada palabra ambigua del texto de entrada. En este algorit- mo simplicado, el sentido correcto de cada palabra en un texto, se determina individualmente, encontrando el sentido que lleva al m\u00b4 aximo solapamiento entre las deniciones del diccionario y el contexto actual. Esta aproximaci\u00b4 on toma cada palabra de forma individual, sin tener en cuenta el sentido de las otras palabras que aparecen junto a ella. En la tabla 2.5se muestran los principales pasos de este algoritmo simplicado. (1) Para cada sentido ideW (2) Determinar el Solapamiento( i), el n\u00b4 umero de palabras en com\u00b4 un entre la denici\u00b4 on del sentido iy el contexto donde aparece la palabra (3) Encontrar el sentido icon el m\u00b4 aximo Solapamiento( i) (4) Asignar el sentido iaW Tabla 2.5. Algoritmo simplicado de Lesk Un estudio realizado por ( Vasilescu et al. (2004 )) ha demos- trado que el algoritmo simplicado de Lesk mejora la denici\u00b4 on original del algoritmo en t\u00b4 erminos de precisi\u00b4 on y eciencia. Su evaluaci\u00b4 on se realiz\u00b4 o utilizando los datos de la tarea \"English all- words\" deSenseval-2 , obteniendo un 58 % de precisi\u00b4 on con el algoritmo simplicado, por encima del 42 % obtenido por el algo- ritmo original. 1http://www.longman.com/ldoce 2. Estado del arte 23 Otra versi\u00b4 on del algoritmo de Lesk utiliza corpus anotados pa- ra resolver la ambig\u00a8 uedad de una palabra determinada. En este caso, esta versi\u00b4 on tiene la capacidad de aumentar el contexto de una palabra con ejemplos adicionales etiquetados. Por lo tanto, el sentido seleccionado para la aparici\u00b4 on de una palabra en un nue- vo contexto, ser\u00b4 a aquel que tenga mayor solapamiento con alg\u00b4 un contexto pre-etiquetado anteriormente. En la tabla 2.6se muestran los pasos del algoritmo de Lesk basado en corpus, suponiendo que se dispone de ejemplos etique- tados de la palabra a desambiguar. (1) Para sentido ideW (2) Se establece Peso( i) a 0 (3) Para cada palabra \u00b4 unica wen contexto de W (4) si waparece en los ejemplos etiquetados o en la denici\u00b4 on del diccionario del sentido i (5) Seleccionar el sentido icon el mayor Peso( i) Tabla 2.6. Algoritmo de Lesk basado en corpus ElPeso de una palabra se dene usando una medida extra\u00b4 da de los m\u00b4 etodos de Recuperaci\u00b4 on de Informaci\u00b4 on: Peso (w) es la inversa de la frecuencia en documentos (idf) de la palabra sobre los ejemplos y las deniciones del diccionario. El idf de una palabra es log( p(w)), donde p(w) se dene como la fracci\u00b4 on de ejemplos y deniciones que incluyen la palabra w. Esta nueva aproximaci\u00b4 on ha conseguido los mejores resultados en comparaci\u00b4 on con los m\u00b4 etodos de aprendizaje supervisado. En Senseval-1 (Kilgarri y Rosenzweig (2000 )) la aproximaci\u00b4 on del algoritmo de Lesk basada en corpus obtuvo un 69 ;1 % de preci- si\u00b4 on comparado con el 56 ;6 % obtenido utilizando la heur\u00b4 stica del sentido m\u00b4 as frecuente. En Senseval-2 (Kilgari )) el algoritmo Lesk consigui\u00b4 o resultados similares: 51 ;2 % precisi\u00b4 on comparado con el 64 ;2 % conseguido por el mejor sistema super- visado. 24 2.5 M\u00b4 etodos basados en conocimiento 2.5.2.3 Espacios sem\u00b4 anticos aumentados. Otra variante del algoritmo de Lesk es la propuesta por Ba- nerjee y Pedersen ( y goritmo de Lesk Adaptado . En esta propuesta se utilizan junto con las deniciones de la palabra ambigua, las deniciones de pa- labras relacionas. En este caso, se utiliza una funci\u00b4 on similar a la empleada por ( Cowie et al. (1992 )) para determinar el valor para cada combinaci\u00b4 on posible de sentidos en un texto, y tratar de identicar la combinaci\u00b4 on que lleva al m\u00b4 aximo valor. En esta aproximaci\u00b4 on se tienen en cuenta conceptos relaciona- dos con la palabra ambigua utilizando la de atributos y sus correspondientes denicio- nes, para construir un contexto m\u00b4 as amplio a partir de las deni- sem\u00b4 anticas, la premisa ini- cial es que las palabras de un texto deben relacionarse seg\u00b4 un sus sentidos para obtener un discurso coherente ( Halliday y Hasan (1976 )). Esta premisa es una propiedad natural del lenguaje hu- mano y al mismo tiempo la base para el desarrollo de los sistemas de desambiguaci\u00b4 on autom\u00b4 aticos. Se puede armar, por tanto, que las palabras que comparten un contexto similar est\u00b4 an normal- mente relacionadas y por consiguiente, se pueden seleccionar sus sentidos a partir de la distancia sem\u00b4 antica ( Rada et al. (1989 )). Esta premisa se restringe a un peque no grupo de palabras ex- tra\u00b4 das del contexto m\u00b4 as cercano a la palabra ambigua o a las pa- labras relacionadas sint\u00b4 acticamente con la palabra ambigua. Este tipo de m\u00b4 etodos extrae el contexto local y no introduce infor- maci\u00b4 on contextual adicional obtenida a partir de una ventana de cierto tama no. Existen otros m\u00b4 etodos que utilizan un contexto global y tratan de construir hilos de conocimiento a trav\u00b4 es del texto completo, utilizando para ello ventanas centradas en la palabra ambigua. 2. Estado del arte 25 Al igual que suced\u00b4 a con el algoritmo de Lesk, estos m\u00b4 etodos sufren de un gran coste computacional cuando tratan m\u00b4 as de dos palabras. Para resolver este problema se pueden aplicar las mis- mas soluciones propuestas para el algoritmo de Lesk, como por ejemplo el algoritmo propuesto por ( Agirre y Rigau (1996 )). 2.5.3.1 Medidas de similitud sem\u00b4 antica. Existen diferentes medidas de similitud que tratan de cuanti- car el grado en que dos palabras est\u00b4 an relacionadas sem\u00b4 antica- mente. Muchas de estas medidas se basan en redes sem\u00b4 anticas y siguen la metodolog\u00b4 a original propuesta por ( Rada et al. (1989 )). A continuaci\u00b4 on se muestran una serie de medidas de similitud aplicadas sobre la jerarqu\u00b4 a de WordNet. La mayor\u00b4 a de estas medidas toman como entrada un par de conceptos y devuelven un valor que indica el grado de similitud entre ambas palabras. 1.(Leacock et al. (1998 )). Esta medida determina el camino m\u00b4 nimo entre las dos palabras de entrada. Este valor se nor- maliza atendiendo a la profundidad de la taxonom\u00b4 a. En la Ecuaci\u00b4 on ( 2.1)Camino (C1; C2) representa la longitud del ca- mino que conecta los dos conceptos (es decir, el n\u00b4 umero de arcos en la red sem\u00b4 antica que son atravesados para llegar de C1aC2, yDes la profundidad total de naden a la medida de similitud la direcci\u00b4 on de los enlaces que forman el camino. Adem\u00b4 as de la longitud, el camino no deber\u00b4 a \"cambiar de direcci\u00b4 on fre- cuentemente\". En on ( 2.2)Cykson constantes, el Camino se dene como la ecuaci\u00b4 on ( 2.1) ydrepresenta el de contenido de ci\u00b4 on, que es una medida de la especicaci\u00b4 on de un concep- to determinado, y est\u00b4 a denida en base a su probabilidad de ocurrencia en un corpus extenso. IC(C) =\u00a1log(P(C)) (2.3) Dado un corpus, P(C) es la probabilidad de encontrar una instancia de tipo C. El valor para P(C) es mayor para con- ceptos listados en la parte superior de la jerarqu\u00b4 a y llega a su m\u00b4 aximo valor para el concepto que se encuentra en la cima (si la jerarqu\u00b4 a tiene tiene una \u00b4 unica cima, entonces el valor para este concepto es 1). Resnik dene una medida de similitud sem\u00b4 antica entre dos palabras utilizando el \"Lowest Common Subsumer\" (LCS). El LCS es el primer concepto de la red sem\u00b4 antica que contiene a las dos palabras, es decir, el primer nodo com\u00b4 un para el cual existe un camino desde la palabra W1y la palabra W2. En la Ecuaci\u00b4 on ( 2.4) se muestra esta Similitud =IC(LCS(C1; C2)) (2.4) 4.(Jiang y Conrath (1997 )) presentan una alternativa a la medi- da de Resnik utilizando la diferencia existente en el contenido de informaci\u00b4 on de los dos conceptos para indicar su similitud. Como muestra la Ecuaci\u00b4 on ( 2.5). Similitud (C1; desarrolla f\u00b4 ormula la informaci\u00b4 on de LCS con la informaci\u00b4 on de los conceptos involucrados, seg\u00b4 un la ecuaci\u00b4 Moldovan (1999 )) introducen una nueva f\u00b4 ormula medir la similitud sem\u00b4 antica entre jerarqu\u00b4 as indepen- dientes, incluyendo jerarqu\u00b4 as para diferentes categor\u00b4 as l\u00b4 exi- cas. Todas las medidas de similitud comentadas anteriormente s\u00b4 olo se pueden aplicar a conceptos que est\u00b4 an expl\u00b4 citamente co- nectados por alg\u00b4 un arco en la red sem\u00b4 antica. Con esta nueva medida Mihalcea y Moldovan crean caminos virtuales entre diferentes jerarqu\u00b4 as a trav\u00b4 es de las deniciones de las glosas en WordNet. la Ecuaci\u00b4 2.7)jCD 12jes deniciones en la jerarqu\u00b4 a de C1yC2. descendientes (C2) es el n\u00b4 umero de conceptos en la jerarqu\u00b4 a deC2. YWkes un peso asociado con cada concepto determi- nado como la profundidad del concepto dentro de la jerarqu\u00b4 a. Similitud (C1; C2) =PjCD12j k=1Wk log(descendientes (C2))(2.7) Esta de similitud funciona bastante bien para la de- sambiguaci\u00b4 on de nombres y verbos conectados por una rela- ci\u00b4 on sint\u00b4 actica (por )) introducen la noci\u00b4 on de densidad conceptual, denida como el solapamiento entre la jerarqu\u00b4 a sem\u00b4 antica enraizada por un concepto C, y las palabras en el contexto de C. En la Ecuaci\u00b4 on ( 2.8),mes el n\u00b4 umero total de sentidos en el contexto de Cencontrados en la jerarqu\u00b4 a cuya ra\u00b4 z es C, ydescendientes (C) representa el total del n\u00b4 umero de conceptos en la jerarqu\u00b4 a enraizada por C.Wkes un peso asociado con cada concepto en la jerarqu\u00b4 a ( nhyp es el n\u00b4 umero de hip\u00b4 onimos para un nodo determinado en la jerarqu\u00b4 a, y el valor \u00b4 optimo para \u00aefue determinado emp\u00b4 ricamente a 0 ;20). (C); donde W k=nhypk\u00ae(2.8) Para identicar el sentido de una palabra en un determinado contexto, la f\u00b4 ormula de la densidad conceptual se aplica a to- dos los posibles sentidos de la palabra, escogiendo el sentido cuya densidad conceptual sea mayor. 28 2.5 M\u00b4 etodos basados en conocimiento 2.5.3.2 Similitud sem\u00b4 antica en un contexto local. La aplicaci\u00b4 on de las medidas de similitud mostradas anterior- mente sobre cualquier texto, no es un proceso sencillo. General- mente, en un texto encontramos m\u00b4 as de dos palabras ambiguas, por tanto, debemos tratar con conjuntos de palabras ambiguas donde la distancia de una palabra al resto de palabras en el con- texto influye sobre el sentido adoptado. Los trabajos desarrollados dentro de este \u00b4 area utilizan un con- texto local restringiendo as\u00b4 el n\u00b4 umero de palabras ambiguas den- tro del mismo contexto. ( Patwardhan et al. (2003 )) aplican la pri- mera medida de similitud de la lista anterior para decidir el senti- do correcto de las 1723 instancias de nombres de la tarea \"English Lexical Sample\" deSenseval-2 . En este estudio, se utiliza va- lor acumulativo a nadiendo las distancias sem\u00b4 anticas de la palabra a desambiguar junto con las palabras vecinas (una palabra a la izquierda y una palabra a la derecha). El sentido elegido es aquel cuyo valor acumulado es mayor. Tras el proceso de evaluaci\u00b4 on se determin\u00b4 o que entre las medidas de similitud propuestas, ( Jiang y Conrath (1997 )) alcanzaban la mejor y ( Hirst y St- Onge (1998 )) proporcionaban el mejor funcionamiento a trav\u00b4 es de varias palabras. Las dependencias sint\u00b4 acticas son otra posible restricci\u00b4 on a con- siderar. En este caso, ( Stetina et al. (1998 )) proponen un m\u00b4 etodo basado en las relaciones sint\u00b4 acticas de palabras y una medida muy simple que dene que dos palabras son similares si pertenecen al mismo synset de WordNet. En (Montoyo (2002 )) se propone la identicaci\u00b4 on del sentido correcto de las palabras a trav\u00b4 es del algoritmo de Marcas de Espe- cidad . Este algoritmo utiliza la taxonom\u00b4 a de nombres de Word- Net, sus relaciones de hiponimia e hiperonimia, para desambiguar palabras dentro de un contexto local (oraci\u00b4 on). La hip\u00b4 otesis en la que se basa este algoritmo es que las palabras que aparecen en un mismo contexto tienen sus sentidos relacionados entre s\u00b4 , y por tanto, puede existir un concepto dentro de la red sem\u00b4 anti- ca que relacione todas las palabras del contexto. Este concepto superior es la denominada Marca de Especidad (ME). El proce- 2. Estado del arte 29 so de desambiguaci\u00b4 on es el siguiente: a trav\u00b4 es de la jerarqu\u00b4 a de WordNet y de las palabras del contexto, se obtiene el conjunto de hiper\u00b4 onimos/hip\u00b4 onimos que comparten las palabras. Usando esta informaci\u00b4 on se trata de determinar el concepto superior (ME) que engloba el mayor n\u00b4 umero de palabras del contexto con sus respec- tivos sentidos. Si como resultado para la ME inicial a\u00b4 un existen palabras ambiguas en el contexto, se va descendiendo por la jerar- qu\u00b4 a obteniendo nuevas ME, de forma que se seleccionar\u00b4 a aquella ME que maximice el n\u00b4 umero de palabras del contexto no ME (*) Contexto: plant, tree, leaf, perennial Figura 2.1. Algoritmo Marcas de Especidad 2.5.3.3 Similitud sem\u00b4 antica en un contexto global. Las cadenas l\u00b4 exicas son una de las estructuras de conocimien- to m\u00b4 as comunes. Una cadena l\u00b4 exica es una secuencia de palabras relacionadas sem\u00b4 anticamente, lo cual crea un contexto y contri- buye a la continuidad del conocimiento y de la coherencia de un discurso ( Halliday y Hasan (1976 )). Estas estructuras han sido consideradas muy \u00b4 utiles en diferentes tareas de procesamiento del lenguaje natural, incluyendo resumen autom\u00b4 atico, categorizaci\u00b4 on de textos y desambiguaci\u00b4 on cadenas l\u00b4 exicas se 30 2.5 M\u00b4 etodos basados en conocimiento extraen independientemente de la estructura gramatical del texto y pueden abarcar grandes distancias dentro del texto. Un algoritmo gen\u00b4 erico de creaci\u00b4 on de cadenas l\u00b4 exicas se divide en tres pasos (Figura 2.2): 1.Seleccionar las palabras candidatas del texto. \u00b4Estas son pa- labras a partir de las cuales podemos establecer similitudes sem\u00b4 anticas y por tanto, la mayor parte del tiempo pertenecen a la misma categor\u00b4 a l\u00b4 exica. 2.Para cada una de estas palabras candidatas, y para cada sen- tido, se busca una cadena que reciba el sentido de la palabra candidata, bas\u00b4 andose en una medida de similitud entre los conceptos que ya est\u00b4 an en la cadena y el sentido de la palabra candidata. 3.Si esa cadena se encuentra, se inserta la palabra dentro de la cadena, en otro caso, se crea una nueva cadena. Todas las cadenas que superan un cierto umbral son seleccio- nadas. A very long train traveling along the rails with a constant velocity v in a certain direcction .... train #1: public transport #1: a bar of steel for trains #2: order of things #3: piece undergo transportation rail #1: small bird Figura 2.2. Cadenas l\u00b4 exicas en un contexto global 2. Estado del arte 31 2.5.4 Preferencias de selecci\u00b4 on Algunos de los algoritmos creados inicialmente para WSD se basan en preferencias de selecci\u00b4 on como una forma de restringir los posibles sentidos de una palabra en un contexto determinado. Las preferencias de selecci\u00b4 on capturan informaci\u00b4 on sobre las posibles relaciones entre diferentes categor\u00b4 as de palabras seg\u00b4 un el propio sentido com\u00b4 un. Por ejemplo, COMER-COMIDA o BEBER- L\u00b4IQUIDOS, son muestras de tales restricciones sem\u00b4 anticas, las cuales pueden ser utilizadas para desechar sentidos incorrectos y seleccionar s\u00b4 olo aquellos sentidos que se corresponden con los sen- tidos obtenidos siguiendo las reglas. Por ejemplo, dada la frase \"Mary drunk burgundy\" , el sentido para \"burgundy\" que lo dene como un color, no tiene cabida en este contexto porque el verbo \"drink\" requiere de un l\u00b4 quido como objeto directo. 2.5.4.1 Adquisici\u00b4 on de preferencias de selecci\u00b4 on. A pesar de que las preferencias de selecci\u00b4 on son intuitivas, es muy dif\u00b4 cil ponerlas en pr\u00b4 actica para resolver el problema de WSD. Supongamos, por ejemplo, que queremos obtener un cor- pus anotado sem\u00b4 anticamente. En este caso, el principal problema es la relaci\u00b4 on circular entre las preferencias de selecci\u00b4 on y WSD, ya que, aprender restricciones sem\u00b4 anticas requiere conocimiento sobre los sentidos involucrados en una relaci\u00b4 on y viceversa. En (Brockmann y Lapata (2003 )) se realiz\u00b4 o un estudio sobre m\u00b4 eto- dos que utilizan preferencias de selecci\u00b4 on junto con una evaluaci\u00b4 on de los resultados obtenidos de forma autom\u00b4 atica frente a los re- sultados anotados por un ser humano. Otra alternativa para obtener preferencias de selecci\u00b4 on es par- tir de corpus no anotados sem\u00b4 anticamente. De esta forma se pue- den utilizar t\u00b4 ecnicas estad\u00b4 sticas frec(W1; W2; R) (2.9) 32 M\u00b4 en conocimiento Se determina cu\u00b4 antas veces co-ocurre la palabra W1con la pa- labra probabilidad de aparici\u00b4 on de la relaci\u00b4 on entre dos palabras W1; W2, con respecto a la probabilidad de aparici\u00b4 on de esa misma relaci\u00b4 on Rcon respecto a una de las dos palabras en todo el corpus. Relaciones palabra-clase ( Resnik (1993 )): Se cuantica la contribuci\u00b4 on de una clase sem\u00b4 antica utilizando todos los conceptos que comparte esa clase. A(W1; C2; R) =P(C2jW1; algoritmos utilizados para adquirir preferencias de se- lecci\u00b4 on son los propuestos por: ( Agirre y Martinez (2001 )) donde se utilizan relaciones clase-clase, como por ejemplo, \"ingerir co- mida\" es una relaci\u00b4 on clase-clase para \"comer pollo\" o tambi\u00b4 en son utilizadas las redes bayesianas propuestas por ( Ciaramita y Johnson (2000 )). 2. Estado del arte 33 2.5.4.2 Usando preferencias de selecci\u00b4 on para WSD. Una vez obtenidas las preferencias de selecci\u00b4 on \u00b4 estas pueden ser integradas en un algoritmo de WSD de la siguiente forma. 1.Aprendizaje de un conjunto de preferencias de selecci\u00b4 on para una determinada relaci\u00b4 on sint\u00b4 actica R 2.Dado un par de palabras W1\u00a1W2conectadas mediante una relaci\u00b4 on R 3.Encontrar todas las preferencias de selecci\u00b4 on W1\u00a1Cpalabra- clase o C1\u00a1C2claseclase que se puedan aplicar 4.Seleccionar el sentido de W1yW2basados en la clase sem\u00b4 anti- ca elegida Por ejemplo, si tratamos de desambiguar la palabra \"caf\u00b4 e\" en \"beber caf\u00b4 e\", los posibles sentidos de caf\u00b4 e son: 1. bebida, 2. \u00b4 arbol y 3. color. Utilizando la preferencia de selecci\u00b4 on \"beber bebida\" sticas para Word Sense Disambiguation Una forma sencilla de establecer el sentido correcto de las pa- labras en un texto es utilizar heur\u00b4 sticas basadas en propiedades ling\u00a8 u\u00b4 sticas aprendidas a es de textos. Una de las heur\u00b4 sticas m\u00b4 as utilizadas como fre- cuente\". existen otras dos com\u00b4 unmente utilizadas cuya base es la suposici\u00b4 on de que una palabra siempre tiene el mismo sentido en: todas sus ocurrencias en un mismo dis- curso (\"un sentido por discurso\") o en la misma colocaci\u00b4 on (\"un sentido por colocaci\u00b4 on\") o en el mismo dominio. 2.5.5.1 Sentido m\u00b4 as frecuente. Entre todos los posibles sentidos que puede tener una palabra, generalmente existe uno que ocurre m\u00b4 as a menudo que los otros sentidos. Por lo tanto, un sistema muy simple de desambiguaci\u00b4 on ser\u00b4 a aquel que asignara a cada palabra su sentido m\u00b4 as frecuente. 34 2.5 M\u00b4 etodos basados en conocimiento Este m\u00b4 etodo se utiliza a menudo como baseline para WSD, y de acuerdo a ( Gale et al. (1992b )) \"los sistemas deber\u00b4 an como m\u00b4 nimo a este baseline\". En el gr\u00b4 aco de la Figura 2.3se muestra la distribuci\u00b4 on de sen- tidos en el corpus Semcor. Los sentidos de cada categor\u00b4 a han sido obtenidos a partir de la distribuci\u00b4 on proporcionada por WordNet. 0 0,1 0,2 0,3 0,4 0,5 0,6 0,7 0,8 0,9 1 2 3 4 5 6 7 8 9 10 Sentido Frecuencia Nombre Verbo Adjetivo Adverbio Figura 2.3. Distribuci\u00b4 on de sentidos en Semcor Como se puede apreciar, el sentido m\u00b4 as frecuente para todas las categor\u00b4 as l\u00b4 exicas es el n\u00b4 umero 1. Aunque conceptualmente es muy sencillo, y casi trivial de im- plementar, hay un inconveniente asociado a este m\u00b4 etodo: no siem- pre disponemos de la distribuci\u00b4 on de las ocurrencias de los sen- tidos en todos los lenguajes, ya que, no existen sucientes textos disponibles para extraer esa distribuci\u00b4 on. Adem\u00b4 as, un cambio en el dominio generalmente altera la distribuci\u00b4 on de los sentidos, dismi- nuyendo as\u00b4 los resultados por Mart\u00b4 nez y Agirre (2000 )). Para solventar el problema de la ausencia de textos que permi- tan obtener la distribuci\u00b4 on de los sentidos, existe una alternativa. 2. Estado del arte 35 El m\u00b4 etodo de ( McCarthy et al. (2004 )) propone la forma de utili- zar una medida de similitud entre distintos sentidos de una pala- bra y palabras similares para determinar el sentido predominante en un dominio determinado. El algoritmo utilizado por este m\u00b4 etodo se compone de tres pasos: 1.Dada top kpalabras similares. Nw=fn1; :::; n con las palabras njusando el sentido de njque maximice el valor de similitud. 3.Ordenar los sentidos wsibas\u00b4 andose en el valor de similitud total. Similitud ejemplo, supongamos que queremos determinar el sentido de la palabra \"pipe\" en un texto determinado. Los posibles sen- tidos de pipe son: pipe#1: tobacco pipe. pipe#2: tube of metal or plastic. Las palabras similares detectadas en el texto son las siguientes: N=ftube, cable, wire, tank, hole, cylinder, tting, ... g Para cada palabra Nse calcula el valor de similitud con el sen- tido pipe#i (escogiendo el valor de similitud que maximiza el par). pipe#1 - tube#3 = 0 ;3 36 2.5 M\u00b4 etodos basados en conocimiento pipe#2 - tube#1 = 0 ;6 Se establece el valor de similitud total de cada sentido de pi- pe#i: similitud(pipe#1) = 0 ;25 similitud(pipe#2) = 0 ;73 fue presentado en la tarea de \"English all-words\" deSenseval-2 obteniendo un 64 % de precisi\u00b4 on sobre los nom- bres. 2.5.5.2 Un sentido por discurso. Esta heur\u00b4 stica fue introducida por ( Gale et al. (1992a )), donde se establece que una palabra tiende a preservar su sentido a trav\u00b4 es de todas sus ocurrencias en un discurso determinado. Esta medida permite establecer el sentido de una misma palabra identic\u00b4 andolo una \u00b4 unica vez. Esta heur\u00b4 stica funciona bien con palabras que tienen senti- dos bien diferenciados. En el caso en que tengamos palabras con sentidos con una diferencia muy sutil, este m\u00b4 etodo obtiene peores resultados. En el estudio realizado por ( Krovetz (1998 )) se demos- tr\u00b4 o que palabras polis\u00b4 emicas con sentidos muy similares, pueden tener m\u00b4 as de un sentido por discurso. En concreto, utilizaron el corpus de Semcor, probando que el 70 % de las palabras en este corpus ten\u00b4 a un sentido por discurso. 2.5.5.3 Un sentido por colocaci\u00b4 on. Esta heur\u00b4 stica tiene una hip\u00b4 otesis similar a la heur\u00b4 stica de un sentido por discurso, pero aplicada en un \u00b4 ambito diferente. Fue presentada por ( Yarowsky (1993 )), y supone que una palabra tiende a tener el mismo sentido cuando se utiliza en la misma colocaci\u00b4 on. Es decir, las palabras cercanas dan pistas acerca del sentido de una palabra. Adem\u00b4 as, se ha determinado que este efec- 2. Estado del arte 37 to es mayor para colocaciones adyacentes y empieza a decrecer cuando la distancia entre palabras aumenta. Por ejemplo, la palabra \"plant\" en la colocaci\u00b4 on \"industrial plant\" mantiene su sentido en todas las ocurrencias, independien- temente del contexto en el que aparezca esta colocaci\u00b4 on. Se desarrollaron distintos experimentos con palabras con sen- tidos bien diferenciados y con sentidos muy pr\u00b4 oximos entre s\u00b4 . Al igual que en el caso anterior, los resultados empeoran cuando se consideran palabras con sentidos con diferencias sutiles ( Mart\u00b4 nez y Agirre (2000 )). 2.6 M\u00b4 etodos no supervisados basados en corpus El desarrollo de m\u00b4 etodos que tratan de resolver el problema de la ambig\u00a8 uedad l\u00b4 exica ha supuesto la aparici\u00b4 on de diferentes algoritmos que utilizan una serie de recursos diferentes. Podemos encontrar desde sistemas que utilizan t\u00b4 ecnicas de enriquecimiento de conocimiento utilizando diccionarios, tesauros o jerarqu\u00b4 as de conceptos (los llamados basados en conocimiento), hasta sistemas que utilizan la informaci\u00b4 on de textos anotados sem\u00b4 anticamente (los llamados sistemas supervisados basados en corpus). El \u00b4 unico inconveniente de estos sistemas es que es necesario la creaci\u00b4 on de textos, diccionarios u otras fuentes de informaci\u00b4 on, de forma ma- nual. Esto supone un gran costo en su obtenci\u00b4 on y mantenimiento, adem\u00b4 as de generar dicultades cuando se tratan de anotar textos muy extensos, de un nuevo dominio o de un lenguaje diferente. Para evitar esta dependencia se han desarrollado dos aproxi- maciones diferentes. La primera de ellas trata de establecer distin- ciones entre sentidos bas\u00b4 andose en su distribuci\u00b4 on, determinando por tanto que, palabras que aparecen en contextos similares deben tener sentidos similares ( Harris (1968 ),Miller y Charles (1991 )). La segunda aproximaci\u00b4 on est\u00b4 a basada en equivalencias de traduc- ci\u00b4 on en corpus paralelos, los cuales identican traducciones de una palabra en un lenguaje determinado cuya traducci\u00b4 on depende del sentido de esa palabra en el lenguaje origen. Estas traducciones 38 2.6 M\u00b4 etodos no supervisados basados en corpus dependientes del sentido de una palabra pueden ser utilizadas co- mo una recopilaci\u00b4 on de sentidos para esa palabra en el lenguaje origen. Una de las claves de los m\u00b4 etodos basados en distribuci\u00b4 on, es que no utilizan ning\u00b4 un recopilatorio de sentidos, \u00b4 unicamente clasican palabras bas\u00b4 andose en sus contextos observados en los corpus. Es- ta es una alternativa a los m\u00b4 etodos que dependen de la anotaci\u00b4 on de corpus y que est\u00b4 an restringidos a aquellas palabras que un ex- perto ha clasicado para sus distintos sentidos. En todo caso, a pesar de que exista un repertorio de sentidos, su utilidad depende de las aplicaciones sobre las que se aplique. Las aproximaciones distribucionales no asignan sentidos a las palabras, pero s\u00b4 permiten discriminar entre los sentidos de una palabra identicando clusters en contextos similares, donde cada cluster muestra que una palabra se est\u00b4 a utilizando con un sentido determinado. Estos m\u00b4 etodos presentan una aproximaci\u00b4 on diferen- te a la tarea tradicional de WSD, la cual clasica palabras con respecto a un repertorio de sentidos existente. Los m\u00b4 etodos basados en equivalencias de traducci\u00b4 on se ba- san en el hecho de que los sentidos diferentes de una palabra en un lenguaje origen se pueden traducir en palabras diferentes en el lenguaje destino. Estas aproximaciones tienen dos propieda- des. Primero, autom\u00b4 aticamente derivan un repertorio de sentidos que hace distinciones relevantes para los problemas de traduc- ci\u00b4 on autom\u00b4 atica. Segundo, un corpus etiquetado basado en estas distinciones puede ser creado autom\u00b4 aticamente y utilizado como corpus de entrenamiento para los m\u00b4 etodos tradicionales de apren- dizaje supervisado. Una de las ventajas de utilizar m\u00b4 etodos no supervisados ba- sados en corpus, es que no se basan en ning\u00b4 un diccionario, repo- sitorio de sentidos, tesauro, etc. De forma que no est\u00b4 an restrin- gidos a la interpretaci\u00b4 on de sentidos que el autor del diccionario haya impuesto. Ya que, es muy habitual que diferentes dicciona- rios aporten una distinci\u00b4 on de sentidos m\u00b4 as na o m\u00b4 as compacta, seg\u00b4 un la nalidad para la que est\u00b4 en creados. Al evitar hacer uso de estos recursos, se garantiza la adaptabilidad de estos sistemas a diferentes campos o \u00b4 ambitos. Otra ventaja no menos importante, 2. Estado del arte 39 es que estos m\u00b4 etodos son independientes del lenguaje. Es decir, son f\u00b4 acilmente adaptables a cualquier idioma que disponga de un corpus sobre el que obtener informaci\u00b4 on. 2.6.1 M\u00b4 etodos distribucionales Este tipo de m\u00b4 etodos identican las palabras que suelen apare- cer en contextos similares, sin necesidad de utilizar un repositorio de sentidos. En ( Sch\u00a8 utze (1998 )) por ejemplo, se realiza el proce- so de desambiguaci\u00b4 on en dos pasos. El primer paso, es construir clusters que comparten caracter\u00b4 sticas similares. El segundo pa- so, es etiquetar cada cluster con una denici\u00b4 on que establezca el sentido de la palabra dentro de ese contexto. Esta es una visi\u00b4 on completamente diferente del concepto general de WSD, donde los sentidos se suponen conocidos antes de comenzar el proceso de desambiguaci\u00b4 on. Esta nueva visi\u00b4 on de \"discriminaci\u00b4 on y etiquetaci\u00b4 on\" corres- ponde a la forma ideal de obtener la denici\u00b4 on de una palabra (lexicograf\u00b4 a). Un lexic\u00b4 ografo, seleccionar\u00b4 a diferentes contextos de una palabra determinada, a partir de un corpus extenso y re- presentativo para el usuario nal. Por ejemplo, si hablamos de un diccionario para ni nos, el corpus consistir\u00b4 a en textos escritos para ni nos. Y si hablamos de un diccionario sobre un dominio espec\u00b4 - co el corpus deber\u00b4 an ser textos de esa especialidad en particular. De esta forma el lexic\u00b4 ografo, dividir\u00b4 a los contextos en los que aparece la palabra a estudiar en diferentes clusters, discriminan- do los diferentes sentidos que puede adoptar esa palabra, sin tener ninguna idea preconcebida de cu\u00b4 antos sentidos puede adoptar. El resultado de la discriminaci\u00b4 on es un n\u00b4 umero determinado de clusters que establecen los diferentes sentidos de la palabra, obtenidos \u00b4 estos a partir del corpus de entrada. A partir de aqu\u00b4 , se debe estudiar cada cluster y obtener una denici\u00b4 on que act\u00b4 ue como una etiqueta o un sentido espec\u00b4 co para la palabra. Esta \u00b4 ultima parte, la de asignar una denici\u00b4 on concreta a la palabra en cada cluster es la m\u00b4 as problem\u00b4 atica, dado que en muchas oca- siones es dif\u00b4 cil establecer una denici\u00b4 on a partir de los contextos. Una posible soluci\u00b4 on ser\u00b4 a identicar el conjunto de palabras que 40 2.6 M\u00b4 etodos no supervisados basados en corpus aparecen en un cluster y utilizarlas como una aproximaci\u00b4 on al sentido de la palabra. Por ejemplo, si tenemos la palabra \"l\u00b4 nea\" En este caso, estas palabras son indicativas del sentido asociado a este cluster. De esta forma, si los m\u00b4 etodos no supervisados basados en cor- pus son desarrollados ecientemente, el resultado podr\u00b4 a llegar a ser un proceso independiente del lenguaje que resuelve el proble- ma de la ambig\u00a8 uedad sin tener que recurrir a un repositorio de sentidos. Existen dos aproximaciones distintas para los m\u00b4 etodos distri- bucionales: etodos identican con- juntos (o clusters) de palabras que pueden estar relacionadas entre s\u00b4 debido a su aparici\u00b4 on en contextos similares. Nor- malmente se basan en medidas de similitud entre vectores de co-ocurrencia. Discriminaci\u00b4 on basada en tokens. Estos m\u00b4 etodos agrupan to- dos los contextos donde una palabra determinada aparece, bas\u00b4 andose en la similitud de estos contextos. 2.6.1.1 Discriminaci\u00b4 on basada en tipos. En el caso de los m\u00b4 etodos de discriminaci\u00b4 on basados en tipos, es necesario disponer de corpus extensos para poder extraer la similitud entre diferentes contextos donde aparece la palabra a desambiguar. En estos m\u00b4 etodos la representaci\u00b4 on m\u00b4 as utilizada se basa normalmente en la contabilizaci\u00b4 on de co-ocurrencias o en medidas de asociaci\u00b4 on entre palabras. Usando esta informaci\u00b4 on es posible identicar otras palabras que aparecen en contextos similares y por tanto pueden tener sentidos similares. De esta forma, se pueden extraer los distintos sentidos que puede adoptar una palabra polis\u00b4 emica. Por ejemplo, si seleccionamos la palabra \"l\u00b4 nea\" que puede te- ner varios sentidos (l\u00b4 nea telef\u00b4 onica, trazo, premio en el juego del bingo, etc), y \u00b4 esta aparece en dos contextos distintos: contex- to1(dibujo, trazo, color, coordenada) y contexto2 (auricular, 2. Estado del arte 41 tel\u00b4 efono, comunicar, llamada). Podemos establecer a partir de las palabras extra\u00b4 das del contexto, que en el primer caso \"l\u00b4 nea\" ha- ce referencia a un trazo en un dibujo, y en el segundo caso, hace referencia a una l\u00b4 nea telef\u00b4 onica. Como ya se ha mencionado anteriormente, los m\u00b4 etodos distri- bucionales basados en tipos necesitan de corpus bastante extensos. Es por ello, que la representaci\u00b4 on del espacio contextual se rea- lizar\u00b4 a en matrices de NxN dimensiones, donde N, es el n\u00b4 umero de palabras en el corpus. Cada celda de esta matriz contiene el n\u00b4 umero de veces que las palabras representadas en cada columna y la co-ocurren dentro de una ventana de un tama no especica- do. Cuando no importa el orden en el que aparecen las palabras la frecuencia ser\u00b4 a la misma, pero si hablamos de bigramas, donde el orden s\u00b4 importa, el valor de las celdas ser\u00b4 a distinto. Por tanto, si el orden no importa, se tendr\u00b4 a una matriz cuadrada y sim\u00b4 etrica. Sin embargo, si tenemos en cuenta el orden de aparici\u00b4 on de las palabras, tendremos una matriz rectangular y no sim\u00b4 etrica. Para estas matrices de co-ocurrencia, las celdas pueden alma- cenar el n\u00b4 umero de veces que dos palabras co-ocurren, o tambi\u00b4 en pueden tomar valores m\u00b4 as complejos. Por ejemplo, las celdas de una matriz de co-ocurrencia pueden contener el valor de diferen- tes medidas de asociaci\u00b4 on como: on Mutua ( Church y Hanks (1990 )). Estas medidas indican el grado en que dos palabras co-ocurren con respecto a las dem\u00b4 as palabras del corpus. En el caso de la medida del log-likelihood ratio partimos de una tabla 2 \u00a32 como sigue a continuaci\u00b4 on 2.7. Corpus1 Corpus2 Total Frecuencia de la palabra a b a+b Frecuencia de otras palabras c\u00a1a d\u00a1b c+d\u00a1a\u00a1b Total c d c+d Tabla 2.7. Tabla 2 x2 para log-likelihood ratio En la Tabla 2.7se extraen las frecuencias relativas de una pa- labra entre dos corpus. Se denota por cal n\u00b4 umero de palabras 42 2.6 M\u00b4 etodos no supervisados basados en corpus total del corpus1 y por dal n\u00b4 umero de palabras total del corpus2 (Nen total). Los valores de aybson denotados como valores ob- servados ( O). Por \u00b4 ultimo, queda por denir los valores esperados (E), seg\u00b4 un la F\u00b4 ormula 2.15. Ei=NiX iOi X iNi(2.15) Para la Tabla 2.7N1=cyN2=d. Por lo tanto, para la palabra que estamos tratando: E1=c\u00a4(a+b) (c+d)y E 2=d\u00a4(a+b) (c+d)(2.16) Los c\u00b4 alculos para obtener los valores esperados tienen en cuenta el tama no de los dos corpus. Por tanto, no es necesario normalizar los valores, pudiendo aplicar a continuaci\u00b4 on la medida del valores esperados y los observados son comparables, el valor de G2estar\u00b4 a pr\u00b4 oximo a 0, lo que signica que la palabra ha aparecido junto a otra por casualidad, y no est\u00b4 an relacionadas entre s\u00b4 . Si se obtiene un valor mayor que 0, signica que los valores observados dieren en gran medida de los valores esperados, por lo que las palabras estar\u00b4 an fuertemente relacionadas entre s\u00b4 . 2. Estado del arte 43 Una vez decidido el tipo de medida a utilizar para establecer la co-ocurrencia entre distintas palabras y construida la matriz de co-ocurrencia, cada palabra ser\u00b4 a representada como un vector de N-dimensiones. A partir de cada vector obtenido, se puede medir la similitud contextual entre dos palabras obteniendo el coseno entre los vectores. Para el c\u00b4 alculo del coseno entre dos etodos distribucionales ba- sados en tipos, encontramos distintos algoritmos que pueden ser aplicados. En esta secci\u00b4 on vamos a tratar dos de estos algoritmos: An\u00b4 alisis de la Sem\u00b4 antica by Committee (CBC) ( Pantel y Lin (2002 )). Mediante el algoritmo de LSA se representa un corpus en un espacio multidimensional, usando vectores. Cada vector represen- tar\u00b4 a el contexto en el cual aparece una palabra. En el caso de LSA no se hacen distinciones entre los distintos sentidos de una palabra polis\u00b4 emica, es decir, se formar\u00b4 a un \u00b4 unico vector para ca- da palabra, aunque \u00b4 esta tenga varios sentidos diferentes. Usando la informaci\u00b4 on del contexto, se podr\u00b4 a determinar, por ejemplo, que palabras como: coche, autom\u00b4 ovil, auto... est\u00b4 an relacionadas sem\u00b4 anticamente. Cuando hablamos de LSA, debemos pensar en la representa- ci\u00b4 on del conocimiento como matrices de [ palabras-contextos ]. Para medir el grado de similitud de una palabra con respecto a otras palabras del contexto, se utiliza la medida del coseno entre vectores. Adem\u00b4 as de poder comparar palabras y contextos, tam- bi\u00b4 en se puede medir el grado de similitud entre oraci\u00b4 on-oraci\u00b4 on, contexto-contexto... simplemente calculando el vector resultado de la uni\u00b4 on de cada uno de los vectores que conforman las pala- bras de la oraci\u00b4 on, del contexto, etc. Mediante el algoritmo de CBC se pueden detectar clusters de palabras relacionadas con los distintos sentidos de una palabra polis\u00b4 emica. Por ejemplo, para la palabra \"mu neca\" el algoritmo 44 2.6 M\u00b4 etodos no supervisados basados en corpus de CBC podr\u00b4 a identicar dos clusters, uno asociado con el sen- tido de juguete, con palabras como juego, entretenimiento, ni nos, cochecito, etc, y otro cluster asociado con el sentido de parte del cuerpo humano, con palabras como brazo, extremidad, articula- ci\u00b4 on, etc. Por lo tanto, con el algoritmo de CBC se pueden detec- tar palabras sin\u00b4 onimas asociadas a los diferentes sentidos de una palabra. Ambos algoritmos, tanto LSA como CBC, utilizan representa- ciones multidimensionales de co-ocurrencia de palabras. 2.6.1.2 Discriminaci\u00b4 on basada en tokens. El objetivo de este tipo de m\u00b4 etodos es agrupar los contextos en los que una palabra aparece bajo el mismo sentido. A continuaci\u00b4 on se van a describir m\u00b4 etodos que utilizan ca- racter\u00b4 sticas de primer y segundo orden. Las caracter\u00b4 sticas de primer orden ocurren directamente en un contexto que est\u00b4 a sien- do clasicado, mientras que las caracter\u00b4 sticas de segundo orden son aquellas que ocurren junto con una de primer orden, pero no ocurren en el contexto que est\u00b4 a siendo clasicado. En primer lugar, es necesario establecer c\u00b4 omo se van a repre- sentar los contextos que van a ser clasicados en clusters. Al igual que para los sistemas supervisados, los contextos contienen la pa- labra a desambiguar con la excepci\u00b4 on de que \u00b4 esta no tiene asigna- do ning\u00b4 un sentido. La premisa de los m\u00b4 etodos basados en tokens es que si una palabra aparece en contextos similares \u00b4 esta ha de tener el mismo sentido. Uno de los primeros m\u00b4 etodos que utiliz\u00b4 o discriminaci\u00b4 on basa- da en tokens fue una adaptaci\u00b4 on del algoritmo de LSA usando caracter\u00b4 sticas de segundo orden ( Sch\u00a8 utze (1998 )). En este caso, la representaci\u00b4 on de la matriz de co-ocurrencia en lugar de uti- lizar palabras utiliza contextos completos usando co-ocurrencias de segundo orden de caracter\u00b4 sticas l\u00b4 exicas. Una palabra tiene una co-ocurrencia de segundo orden con otra, cuando ambas no aparecen juntas pero ambas s\u00b4 aparecen junto a otra palabra fre- cuentemente. Por ejemplo, en \"polic\u00b4 a de palabra \"polic\u00b4 a\" es una co-ocurrencia de segundo 2. Estado del arte 45 orden de \"accidente\", porque ambas co-ocurren en primer orden con \"tr\u00b4 aco\". Otro m\u00b4 etodo que utiliza esta aproximaci\u00b4 on es el de ( Peder- sen y Bruce (1997 )). En este caso, utilizan un conjunto reducido de caracter\u00b4 sticas de primer orden para crear matrices que mues- tran la similitud entre contextos. Estas caracter\u00b4 sticas se extraen a partir de las palabras que se encuentran alrededor de la pa- labra a desambiguar e incluyen etiquetas sint\u00b4 acticas y palabras co-ocurrentes. El problema de este tipo de m\u00b4 etodos es la forma de evaluaci\u00b4 on de los resultados. Debido a que la discriminaci\u00b4 on no parte de un conjunto preestablecido de sentidos, no se puede evaluar la forma en que los nuevos sentidos son descubiertos, sobretodo si se est\u00b4 a trabajando en un dominio espec\u00b4 co. 2.7 M\u00b4 etodos supervisados basados en corpus Los m\u00b4 etodos supervisados realizan la desambiguaci\u00b4 on de for- ma autom\u00b4 atica a partir de modelos o reglas obtenidas a partir de textos anotados previamente. Cuando hablamos de textos ano- tados, nos referimos a textos cuyo contenido ha sido etiquetado de forma manual. En este caso, la etiquetaci\u00b4 on se corresponde tanto a la parte de sem\u00b4 antica como a la parte sint\u00b4 actica. Ya que, como se coment\u00b4 o anteriormente se debe identicar el tipo de cate- gor\u00b4 a sint\u00b4 actica de una palabra, para poder establecer su sentido sem\u00b4 antico. En l\u00b4 neas generales los pasos a seguir un m\u00b4 etodo supervi- sado son los siguientes: 1.Seleccionar un conjunto de ejemplos que muestren las distintas clasicaciones de cada elemento. 2.Identicar patrones asociados a cada elemento. 3.Generalizar los patrones en reglas. 4.Aplicar las reglas para clasicar nuevos elementos. Dentro de este tipo de m\u00b4 etodos cabe destacar las t\u00b4 ecnicas basa- ( Mit- 46 2.7 Estas t\u00b4 ecnicas han sido amplia- mente utilizadas en tareas de PLN obteniendo un \u00b4 exito conside- rable. Los problemas iniciales de PLN sobre los que fueron aplicados este tipo de m\u00b4 etodos estad\u00b4 sticos y de aprendizaje autom\u00b4 atico, fueron la resoluci\u00b4 on de la ambig\u00a8 uedad l\u00b4 exi- ca. En este tipo de tareas, se debe seleccionar de entre un conjunto de alternativas, la interpretaci\u00b4 on correcta para una palabra en un contexto determinado. Podemos destacar tareas tales como: selec- ci\u00b4 on de palabras en reconocimiento de autom\u00b4 ati- ca, desambiguaci\u00b4 on autom\u00b4 atica, resoluci\u00b4 on de co-referencias, etc. Este tipo de tareas se consideran adecuadas para un sistema de aprendizaje autom\u00b4 atico porque pueden ser vistas como problemas de clasicaci\u00b4 on, donde el sistema de aprendizaje trata de etique- tar (clasicar) una serie de elementos, utilizando una de entre varias categor\u00b4 as (clases). En este caso, la base de conocimiento del sistema est\u00b4 a formada por ejemplos previamente etiquetados. Actualmente, las t\u00b4 ecnicas de aprendizaje autom\u00b4 atico han sido aplicadas a otros problemas de PLN, los cuales, no se reducen a un simple problema de clasicaci\u00b4 on. Dentro de estas nuevas apli- caciones encontramos: etiquetaci\u00b4 on de secuencias (con entidades, categor\u00b4 acticas, etc) y complejos en extracci\u00b4 on de infor- maci\u00b4 on, etc). En estos casos, se parte de un problema complejo que puede ser descompuesto en esquemas de decisi\u00b4 on simples o se pueden generalizar los conjuntos de clasicaci\u00b4 on para trabajar directamente con representaciones y salidas complejas. En relaci\u00b4 on a WSD, en los \u00b4 ultimos diez a nos, la t\u00b4 ecnica de aprendizaje supervisado, a partir de ejemplos, ha sido una de las que mejores resultados ha obtenido. En este caso, los modelos estad\u00b4 sticos o de clasicaci\u00b4 on se obtienen a partir corpus ano- tados sem\u00b4 anticamente. Normalmente, los m\u00b4 etodos supervisados han obtenido mejores resultados que los no supervisados. Esta armaci\u00b4 on queda demostrada a la vista de los resultados conse- guidos en las \u00b4 ultimas competiciones realizadas para la estos m\u00b4 etodos tienen un grave problema, la necesidad 2. Estado del arte 47 de disponer de corpus lo bastante extensos para poder entrenar los sistemas. A menudo, escasean los corpus anotados debido a su costoso proceso de anotaci\u00b4 on manual, es el conocido problema del cuello de botella de la adquisici\u00b4 on de conocimiento. Esta res- tricci\u00b4 on afecta en gran medida a los sistemas, ya que no tienen la materia prima necesaria para poder trabajar. 2.7.1 El proceso de clasicaci\u00b4 on en aprendizaje supervisado El objetivo principal en el aprendizaje supervisado para la ta- rea de clasicaci\u00b4 on consiste en inducir a partir de un conjunto de entrenamiento C, una aproximaci\u00b4 on (o hip\u00b4 otesis) hde una fun- ci\u00b4 on no conocida fque mapea a partir de un espacio de entrada Ea un espacio de salida S= 1; :::; K . El conjunto Eyy=f(\u00a1 !e). normalmente n), cuyos componentes, lla- mados atributos (features) describen informaci\u00b4 on relevante acerca del ejemplo. Los valores del espacio de salida Sasociados con ca- da ejemplo de entrenamiento se llaman clases (categor\u00b4 as). Por lo tanto, cada ejemplo de entrenamiento est\u00b4 a completamente des- crito por un conjunto de pares atributo-valor y una etiqueta de clase. Seg\u00b4 un la teor\u00b4 a del aprendizaje funci\u00b4 on de distribuci\u00b4 on de pro- babilidad P(X; Y) y los ejemplos de entrenamiento se consideran como una muestra de esa distribuci\u00b4 on. Adem\u00b4 as, Xse identica normalmente con <n, y cada ejemplo\u00a1 !xcomo un punto en <n con un valor real en cada dimensi\u00b4 on. Estas son las dos posibles notaciones que podemos encontrar en este tipo de sistemas. Dado un conjunto de entrenamiento C, un algoritmo de apren- dizaje induce un clasicador denotado como h, el cual es utili- zado como una hip\u00b4 otesis sobre la verdadera funci\u00b4 on f. A partir de aqu\u00b4 el algoritmo de aprendizaje puede seleccionar entre un conjunto de posibles funciones H, a las que se llama espacio de 48 2.7 M\u00b4 etodos supervisados basados en corpus hip\u00b4 otesis . Los algoritmos de aprendizaje se diferencian en base a dos rasgos: el tipo de espacio de hip\u00b4 otesis que manejan: funciones lineales, funciones radiales, etc. O el tipo de algoritmo de selecci\u00b4 on que utilizan para decidir cu\u00b4 al de las hip\u00b4 otesis es la mejor con res- pecto al corpus de entrenamiento: simplicidad, margen m\u00b4 aximo, etc. Dados nuevos vectores\u00a1 !x,hse utiliza para predecir los corres- pondientes valores y. En este caso, se clasican los nuevos ejem- plos, y el resultado se prevee que coincida con fen la mayor\u00b4 a de los casos, o de forma equivalente, que conlleve al menor n\u00b4 ume- ro de errores. La forma de estimar el grado de error en aquellos ejemplos nunca vistos anteriormente se denomina error de gene- ralizaci\u00b4 on . Este tipo de errores no pueden ser minimizados por el algoritmo de aprendizaje, dado que la funci\u00b4 on fo la distribuci\u00b4 on P(X; Y) son desconocidas. Por lo tanto, es necesario un principio de inducci\u00b4 on. La forma m\u00b4 as com\u00b4 un de proceder es minimizar el denominado error de entrenamiento , es decir, el n\u00b4 umero de errores que encontramos en el conjunto de entrenamiento. Esta acci\u00b4 on se conoce como la minimizaci\u00b4 on del riesgo emp\u00b4 rico y proporciona una buena estimaci\u00b4 on del error de generalizaci\u00b4 on con los sucien- tes ejemplos de entrenamiento. Sin embargo, para dominios con pocos ejemplos de entrenamiento, podemos ajustar demasiado los datos de entrenamiento y generalizar err\u00b4 oneamente. El riesgo de ajuste se ve incrementado cuando tenemos datos at\u00b4 picos y ruido. 2.7.1.1 Ejemplo: WSD con aprendizaje autom\u00b4 Supongamos que las diferentes ocurren- cias del verbo \"to know\" en diferentes contextos. En este caso, se considerar\u00b4 an los diferentes sentidos del verbo como las dis- tintas clases del problema de clasicaci\u00b4 on (espacio de salida Y). Adem\u00b4 as, cada ocurrencia del verbo en un corpus previamente ano- tado sem\u00b4 anticamente, ser\u00b4 a codicada como un ejemplo ( xi) para la tarea de entrenamiento. En la Tabla 2.8el verbo \"to know\" tiene once sentidos diferentes seg\u00b4 un las deniciones de WordNet 1.6, con sus correspondientes dominios de WordNet Domains. 2. Estado del arte 49 Synset Dominio Glosa 00401762 know#1 psychology be cognizant or aware a fact or a specic piece of information; possess knowledge or information about; \"I know that the President lied to the peo- ple\"; \"I want to know it's \"She knows how to knit\"; how to cook?\" 00402210 know#3 psychology be aware of the truth of something; have a belief or faith in something; regard as true beyond any doubt; \"I know that I left the key on the table\"; \"Galileo knew moves factotum be ject; stu- dent or character as familiar; Sentidos del verbo \"to know\" en WordNet 1.6 Generalmente, las deniciones de los sentidos de una palabra, tienen asociados ejemplos con informaci\u00b4 on relevante del contexto donde suele utilizarse. Esta informaci\u00b4 on puede usarse para extraer caracter\u00b4 sticas ( Estas caracter\u00b4 sticas son utiliza- das para los ejemplos de entrenamiento mediante vec- tores de ndimensiones, donde nes sticas 50 2.7 M\u00b4 etodos supervisados basados en corpus utilizado. En el caso de los algoritmos de aprendizaje autom\u00b4 atico, es imprescindible obtener la informaci\u00b4 on del contexto que rodea a la palabra ambigua para poder construir los vectores de carac- ter\u00b4 sticas. Normalmente, es necesario realizar un pre-proceso para poder construir estos vectores. Es preciso por una parte, obte- ner las palabras con contenido sem\u00b4 antico que rodean a la palabra ambigua, para ello, se establecen ventanas contextuales de dife- rente tama no, tambi\u00b4 en se utilizan analizadores sint\u00b4 acticos para estudiar los patrones de relaciones sint\u00b4 acticas, se detectan las pa- labras compuestas, etc. Este pre-proceso es necesario para una correcta denici\u00b4 on de las caracter\u00b4 sticas y determinar\u00b4 a el buen funcionamiento del algoritmo de aprendizaje autom\u00b4 atico. Los conjuntos de caracter\u00b4 sticas m\u00b4 as utilizados sint\u00b4 acticas, lemas, palabras junto con su posici\u00b4 on respecto a la palabra a desambiguar. En alguna oca- si\u00b4 on las caracter\u00b4 sticas locales incluyen sacos de palabras o lemas situados en el entorno de la palabra ambigua. Mediante estas caracter\u00b4 sticas se puede capturar el conocimiento sobre colocaciones, relaciones sint\u00b4 acticas, etc. Caracter\u00b4 sticas generales Mediante las caracter\u00b4 sticas genera- les se pueden representar contextos mucho m\u00b4 as generales. La representaci\u00b4 on de estas caracter\u00b4 sticas se realiza mediante sa- cos de palabras (ventana amplia de palabras, oraciones, p\u00b4 arra- fos, documentos...). Usando este tipo de caracter\u00b4 sticas se pue- de capturar el dominio sem\u00b4 antico de un fragmento de texto o de un documento. Dependencias sint\u00b4 acticas Al nivel de una oraci\u00b4 on, las depen- dencias sint\u00b4 acticas se pueden utilizar para modelar relaciones entre diferentes argumentos. Adem\u00b4 as de los vectores de caracter\u00b4 sticas tambi\u00b4 en se suelen utilizar listas de decisi\u00b4 on. En este caso, el algoritmo de aprendizaje se basa en una serie de reglas del tipo: if(caracteristica =valor )then clase 2. Estado del arte 51 En el caso de algoritmos basados en listas de decisi\u00b4 on, cada vez que se trata de clasicar un nuevo ejemplo x, se van ejecutando por orden el listado de reglas hasta que se encuentre una que se pueda aplicar sobre el nuevo ejemplo. Suponiendo que se han obtenido una serie de reglas de decisi\u00b4 on a partir de varios ejemplos de entrenamiento, se podr\u00b4 a ejecutar un algoritmo de decisi\u00b4 on sobre el siguiente ejemplo: \"There is not- hing in the whole spirit\" . La Tabla 2.9muestra las reglas aplicadas junto con una probabilidad de certidumbre para cada regla. Caracter\u00b4 stica Valor Sentido Probabilidad \u00a7ventana de 4 Tabla 2.9. Clasicaci\u00b4 on seg\u00b4 un listas de decisi\u00b4 on de la palabra \"know\" En este ejemplo, se puede observar que la lista de decisi\u00b4 on \u00b4 unicamente establece valores positivos para los sentidos 1 y 4 de \"know\" . Usando esta informaci\u00b4 on, se podr\u00b4 a proponer como sen- tido correcto de \"know\" el 4, debido a que la mayor\u00b4 a de reglas apuntan a este sentido. Para nalizar, recordar que cuando se habla de \"aprendizaje supervisado\" se parte de un corpus de entrenamiento previamente anotado en base a una serie de clases sem\u00b4 anticas. Mientras que cuando se habla de \"aprendizaje no supervisado\" no existe anota- ci\u00b4 on previa y el objetivo nal es, a partir de similitudes sem\u00b4 anticas obtener una serie de clusters para poder ser interpretados como clases sem\u00b4 anticas. 52 2.7 M\u00b4 etodos supervisados basados en corpus 2.7.2 Clasicaci\u00b4 on de m\u00b4 etodos de aprendizaje supervisado A continuaci\u00b4 on se van a describir algunos de los distintos m\u00b4 eto- dos de aprendizaje supervisado utilizados en WSD. Estos m\u00b4 etodos son clasicados atendiendo a la forma que tienen de adquirir los modelos de clasicaci\u00b4 conjunto de par\u00b4 ametros que determinan la probabilidad condicional de las ca- tegor\u00b4 as y los contextos (descritos mediante caracter\u00b4 sticas). Estos par\u00b4 ametros se utilizan para asignar a cada nuevo ejemplo una ca- tegor\u00b4 a que maximice la probabilidad condicional a partir de las caracter\u00b4 sticas observadas anteriormente. El clasicador m\u00b4 as simple que existe es el denominado Na\u00a8 ve Bayes Classier (NBC) ( Duda et al. (2001 )). En este modelo, hay un nodo que representa la variable de clase Cy un nodo para cada atributo xidel ejemplo (ver Figura 2.4). Se parte de la hip\u00b4 otesis de que los valores de los atributos se generan independientemente a partir de la clase Cde acuerdo con las distribuciones indivi- duales P(xijC). Para predecir la clase de un ejemplo, se elige la que maximiza la probabilidad de haber generado el ejemplo ob- servado. Para ello, se utiliza una f\u00b4 ormula derivada a partir del teorema de Bayes. Este algoritmo ha sido usado en distintas ta- reas de PLN para resolver diversos problemas (categorizaci\u00b4 on de documentos ( Lewis y Ringuette on ( et al. (1998 ),Escudero et al. (2000 )) ...) y a pesar de su extrema simplicidad, ha obtenido resultados notables. Adem\u00b4 as, utilizando el NBC se puede combinar informaci\u00b4 on estad\u00b4 stica de distintas fuentes, siempre que sean independientes. La f\u00b4 ormula general para obtener la clasicaci\u00b4 on seg\u00b4 un el clasi- cador bayesiano es la siguiente: 2. Estado del arte 53 C X1 X2 X3 X4 Xn n) (2.20) Dado que los atributos son independientes con respecto a la clase Cse ax valor2CP(X1jC)\u00a3:::\u00a3P(XnjC)\u00a3P(C) (2.22) Para el caso de WSD el sentido correcto para una palabra cualquiera Cser\u00b4 a aquel que hiciera m\u00b4 aximo el resultado de la Ecuaci\u00b4 on 2.22. Por ejemplo, supongamos que tenemos 2000 instancias de la palabra \"bank\" : 1500 para bank#1 (nancial) y 500 para bank#2 (river). En este caso, las probabilidades para cada sentido ser\u00b4 an: P(S= 1) = 1500 =2000 = 0 ;75 P(S= 2) = 500 =2000 = 0 ;25 54 2.7 M\u00b4 etodos supervisados basados en corpus Dada la palabra \"credit\" \u00b4 esta aparece 200 veces con bank#1 y 4 veces con bank#2. P(X1=credit ) = 204 =2000 = 0 = 200 =1500 = 0 ;133 P(X1=creditjC= 2) = 4 =500 = 0 ;08 Dado un texto que contiene la palabra \"credit\" : P(C= 1jX1=credit (0 ;08\u00a30;25)=0;102 = 0 ;20 Por tanto, se deducir\u00b4 a que el sentido correcto para \"bank\" es el n\u00b4 umero 1. La efectividad del clasicador bayesiano \"naive\" ha pro- bada en diferentes estudios ( Mooney (1996 ),Pedersen (1997 )) que demuestran que este clasicador es tan bueno como cualquier otro m\u00b4 etodo. 2.7.2.2 M\u00b4 etodos basados en reglas de discriminaci\u00b4 on. Este tipo de m\u00b4 etodos utilizan las llamadas listas de decisi\u00b4 on (Rivest (1987 )) o \u00b4 arboles de decisi\u00b4 on ( Quillian (1986 ),Quillian (1993 )) donde se utilizan reglas asociadas a cada uno de los di- ferentes sentidos de una palabra. En este caso, dado un ejemplo a clasicar, el sistema selecciona una o m\u00b4 as reglas que son sa- tisfechas por las caracter\u00b4 sticas del ejemplo y asigna un sentido bas\u00b4 andose en sus predicciones. Concretamente, una lista de decisi\u00b4 on es un conjunto ordena- do de reglas de la forma (condici\u00b4 on, clase, peso). Un ejemplo de este tipo de listas se encuentra en la Secci\u00b4 on 2.7.1.1 . Una lista de decisi\u00b4 on con reglas a las que se le asignan pesos establece que las reglas con condiciones excepcionales se sit\u00b4 uan al principio de la lista con un peso elevado, las reglas con condiciones generales se sit\u00b4 uan al nal con un peso bajo y la \u00b4 ultima condici\u00b4 on de la lista es una condici\u00b4 on por defecto que acepta el resto de casos no contemplados. Los pesos se establecen de acuerdo a una funci\u00b4 on que mide el grado de asociaci\u00b4 on entre la condici\u00b4 on y una categor\u00b4 a 2. Estado del arte 55 particular a partir de un corpus de entrenamiento. Para clasicar un nuevo ejemplo, cada regla de la lista se comprueba secuencial- mente y la categor\u00b4 a de la primera regla que cumple la condici\u00b4 on se asigna al nuevo ejemplo. En (Yarowsky (1994b ) se utilizan listas de decisi\u00b4 on para re- solver un tipo espec\u00b4 co de ambig\u00a8 uedad: los acentos en espa nol y franc\u00b4 es. En un trabajo posterior se aplicaron listas de decisi\u00b4 on para WSD ( Yarowsky (1995 )). En este estudio, cada condici\u00b4 on de la lista se correspond\u00b4 a con una caracter\u00b4 stica ( \"feature\" ), donde los valores eran los sentidos de las palabras y los pesos se calcu- laban de acuerdo a una f\u00b4 ormula que estimaba la probabilidad de un sentido con respecto a una determinada caracter\u00b4 stica. En (Mart\u00b4 nez et al. (2002 ),Mart\u00b4 nez (2004 )) las listas de de- cisi\u00b4 on se emplean en un sistema de WSD junto con una serie de nuevas caracter\u00b4 sticas sint\u00b4 (relaciones gramaticales ins- tanciadas, sem\u00b4 anticas (modelos de preferencias de selecci\u00b4 on). Este sistema se ha empleado para de- sambiguar textos en Euskera e Ingl\u00b4 es. En el caso de los \u00b4 arboles de decisi\u00b4 on las reglas de clasicaci\u00b4 on se generan en forma de una estructura n-aria de ramas de un \u00b4 arbol. Cada rama de un \u00b4 arbol de decisi\u00b4 on representa una regla que comprueba un conjunto de caracter\u00b4 sticas (nodos internos) y hace una predicci\u00b4 on de la clase del nodo terminal. Este tipo de estructuras no se han empleado frecuentemente en WSD. En (Mooney (1996 )) se utiliz\u00b4 o el algoritmo de ( Quinlan (1993 )) y se realiz\u00b4 o un estudio comparativo con varios algoritmos de aprendi- zaje autom\u00b4 atico para WSD. Este estudio concluy\u00b4 o que los \u00b4 arboles de decisi\u00b4 on no estaban entre los algoritmos que mejor resolv\u00b4 an el problema de WSD. A pesar de ello, en Senseval-1 (Yarowsky (2000a )) present\u00b4 o un sistema modicado de listas de decisi\u00b4 on con algunas ramas condicionales que obtuvo muy buenos resultados en la tarea \"English Lexical Sample\" . 2.7.2.3 Bootstrapping. Como se ha comentado anteriormente, el problema de los m\u00b4 etodos basados en aprendizaje autom\u00b4 atico es la escasez de cor- 56 2.7 M\u00b4 etodos supervisados basados en corpus pus anotados sem\u00b4 anticamente. Para evitar este problema exis- te un m\u00b4 etodo que requiere de un m\u00b4 nimo conjunto de elementos anotados (sistemas m\u00b4 idea de este m\u00b4 etodo es que a partir de un m\u00b4 nimo conjunto de ejemplos anotados se pueden realizar sucesivos apren- dizajes que se alimentan incrementalmente con el conocimiento adquirido en el anterior. El t\u00b4 ermino \"semilla\" proviene del ini- cio de tal proceso iterativo, que no necesita m\u00b4 as que una m\u00b4 nima cantidad de conocimiento previo para comenzar el aprendizaje. Existen diferentes aproximaciones del m\u00b4 etodo de bootstrap- ping: co-training y self-training. asica para ambas aproximaciones es la siguiente: Se parte de un conjunto EEde Ejemplos de Entrenamiento etiquetados y de un conjunto ENde Ejemplos No Etiquetados. Se dispone de CiClasicadores. Paso 1. Crear un conjunto de ejemplos NE0, eligiendo Pejem- plos aleatorios de NE. Paso 2. Bucle de Iiteraciones: - Entrenar los clasicadores Cisobre el conjunto etiquetado EEy etiquetar el conjunto no etiquetado NE0. - Seleccionar los Mmejores ejemplos y a nadirlos al conjunto EE, manteniendo la distribuci\u00b4 on de EE. - Rellenar el conjunto NE0con ejemplos de NE, manteniendo NE0en un tama no constante P. Un ejemplo del m\u00b4 etodo co-training lo encontramos en ( Blum y Mitchell (1998 )) donde se utilizan dos clasicadores. Y un ejem- plo del m\u00b4 etodo en ( Nigam y unico clasicador. 2.7.2.4 M\u00b4 etodos basados en redes neuronales. Otro tipo de m\u00b4 etodos utilizados para WSD son aquellos ba- sados en algoritmos gen\u00b4 eticos, etc ( Veronis y Ide(1990 )). Una Red Neuronal Arti- cial (RNA) es un modelo de procesamiento de informaci\u00b4 on que est\u00b4 a inspirado en un sistema nervioso biol\u00b4 ogico ( Group (1986 )). 2. Estado del arte 57 \u00b4Este se compone de un gran n\u00b4 umero de elementos de procesamien- to interconectados (neuronas) trabajando conjuntamente para re- solver problemas espec\u00b4 cos. Las RNA aprenden con ejemplos, es por tanto necesaria la utilizaci\u00b4 on de un proceso de aprendizaje para su conguraci\u00b4 on. La principal ventaja de las RNA radica en la resoluci\u00b4 on de problemas demasiado complejos para tecnolog\u00b4 as convencionales, problemas que no tienen un algoritmo de soluci\u00b4 on espec\u00b4 co o que es muy dif\u00b4 cil de encontrar. Entre estos proble- mas se encuentran el reconocimiento de patrones y pron\u00b4 osticos, clasicaci\u00b4 on de datos, optimizaci\u00b4 on... Sin embargo, en el \u00b4 ambito del procesamiento del lenguaje natural a\u00b4 un no han sido sucien- temente explotadas ( Valdivia et al. (2002 )). En (Garc\u00b4 a (2006 )) se propone un sistema de WSD basado en el modelo de red neural de Kohonen ( Kohonen (1989 )), en su variante de Aprendizaje por Cuanticaci\u00b4 on Vectorial (Learning Vector Quantication o LVQ). Como recursos ling\u00a8 u\u00b4 sticos para el aprendizaje de la red se utiliza el corpus de Semcor, que est\u00b4 a eti- quetado con los sentidos de WordNet y el conjunto de p\u00b4 arrafos articiales generado a partir de todas las relaciones de WordNet. Adem\u00b4 as, integra el modelo de espacio vectorial (con vectores ob- tenidos a partir de Semcor) con LVQ para denir las categor\u00b4 as de la red. Este sistema particip\u00b4 o en la tarea English Lexical Sample deSenseval-2 obteniendo una precisi\u00b4 on etodos h\u00b4 bridos Los m\u00b4 etodos que se encuentran dentro de este grupo son aque- llos que no pueden englobarse exactamente dentro de los grupos anteriores. Es decir, son aquellos que utilizan en el proceso de de- sambiguaci\u00b4 on tanto fuentes de conocimiento externas como corpus anotados o no anotados. Un m\u00b4 etodo que combina la utilizaci\u00b4 on de diccionarios con cor- pus no anotados es el ideado por ( Luk(1995 )). Este m\u00b4 etodo utiliza las deniciones de LDOCE para extraer las palabras que identi- can cada sentido, construyendo as\u00b4 para cada sentido una lista de palabras representativas. Utilizando esta informaci\u00b4 on y las oracio- 58 2.8 M\u00b4 etodos h\u00b4 bridos nes del Brown Corpus2(Francis y Kucera (1979 )) no anotado, se expande el conjunto de palabras representativas obtenido a partir de LDOCE, de la siguiente forma: se extraen pares de palabras de cada oraci\u00b4 on del Brown Corpus y se determinan los concep- tos co-ocurrentes mediante un algoritmo que obtiene una tabla de datos conceptuales co-ocurrentes. Esto permite producir un siste- ma que utiliza la informaci\u00b4 on de recursos l\u00b4 exicos como un medio para reducir la gran cantidad de texto necesaria de los corpus de entrenamiento. El proceso de desambiguaci\u00b4 on de una palabra polis\u00b4 emica W sobre un contexto C(la oraci\u00b4 on que contiene a la palabra), co- mienza dando valores a cada sentido SdeW, palabras representativas de LDO- CE pertenecientes al sentido S,C0es el conjunto ampliado de palabras representativas y GlobalCS contiene las deniciones de cada concepto. A partir de estos valores y utilizando la Informa- ci\u00b4 on Mutua entre las diferentes conjuntos de palabras represen- tativas, se selecciona el sentido con mayor valor de Informaci\u00b4 on Mutua. Este sistema obtuvo un 77 % de precisi\u00b4 on sobre las 12 palabras utilizadas en el trabajo de ( Yarowsky (1992 )). Otros m\u00b4 etodos destacables de este tipo son los publicados en: McRoy (1992 ),Dagan et al. (1991 ) yDagan et al. (1994 ). Existen tambi\u00b4 en otros m\u00b4 etodos que utilizan la combinaci\u00b4 on de tesauros y corpus no anotados, como es el caso del m\u00b4 etodo ideado en ( la de bootstrapping consider\u00b4 andolas etiquetadas sem\u00b4 anticamente y esta informaci\u00b4 on se va aumentando utilizando un corpus no anotado. Adem\u00b4 as podemos encontrar tambi\u00b4 en m\u00b4 etodos que ), el n\u00b4 umero de sistemas de WSD surgidos a partir de la combinaci\u00b4 on de diferentes fuentes de conocimiento es muy amplio y ser\u00b4 a imposible citarlos exhaustivamente. 2.9 Otra clasicaci\u00b4 on de sistemas WSD Dada la gran cantidad de m\u00b4 etodos propuestos actualmente pa- ra WSD existe una clasicaci\u00b4 on m\u00b4 as general que engloba \u00b4 unica- mente dos tipos de sistemas: sistemas supervisados y sistemas no supervisados. Esta clasicaci\u00b4 on es la utilizada en la competici\u00b4 on Senseval para la evaluaci\u00b4 on de los distintos sistemas de WSD presentados. Como ya se ha comentado en los puntos anteriores, cuando se ha- bla de sistemas supervisados se hace referencia a aquellos sistemas que necesitan de corpus de entrenamiento anotados sem\u00b4 antica- mente. En cambio, los sistemas no supervisados son aquellos que no necesitan esa anotaci\u00b4 on para poder funcionar correctamente. 2.10 Aplicaciones actuales Aunque no deja de ser importante en el Procesamiento del Len- guaje Natural, WSD se considera una tarea intermedia ( Wilks y Stevenson (1998 )), al igual part-of-speech tagging o alisis sint\u00b4 actico. Decimos que es una tarea interme- dia porque sus resultados \u00b4 unicamente proporcionan informaci\u00b4 on ling\u00a8 u\u00b4 stica y nada tienen que ver con lo que el usuario nal deman- da en \u00b4 ultima instancia. Otras tareas, las llamadas tareas nales, como la traducci\u00b4 on autom\u00b4 atica, extracci\u00b4 on y siste- mas de di\u00b4 alogo, ofrecen unos resultados requeridos por el usuario, al que poco le importa el fondo ling\u00a8 u\u00b4 stico sobre el que este tipo de tareas se apoya. La mayor\u00b4 a de estas tareas nales requieren dife- rentes m\u00b4 odulos que implementen una serie de tareas intermedias necesarias para el correcto funcionamiento de la aplicaci\u00b4 on. 60 2.10 Aplicaciones actuales Esencialmente, existen dos tareas nales que realmente obtie- nen benecios por la utilizaci\u00b4 on de un m\u00b4 de Estamos hablando y recuperaci\u00b4 on de informa- ci\u00b4 on. A pesar de que en recuperaci\u00b4 on de informaci\u00b4 on no est\u00b4 an demostrados los benecios de aplicar WSD s\u00b4 se hace patente la necesidad de su utilizaci\u00b4 on. Por ejemplo, cuando realizamos una b\u00b4 usqueda sobre el \"\u00b4 aguila imperial\", queremos \u00b4 unicamente aque- llos documentos que hablen sobre el ave rapaz, y no sobre peces de la especie raya o sobre un tipo de moneda espa nola o mexicana. En 1992 y 1997 ( Krovets y Croft (1992 ),Krovets (1997 )), en unos estudios realizados con un corpus desambiguado manualmente, se comprob\u00b4 o que un sistema de WSD podr\u00b4 a mejorar la recupera- ci\u00b4 on de informaci\u00b4 on en un 2 %. Otro estudio similar fue el realiza- do por Sanderson ( Sanderson (1994 )), en este caso, se efectuaron una serie experimentos similares a los realizados por Krovets. La \u00b4 unica diferencia fue que en este caso la ambig\u00a8 uedad fue introdu- cida articialmente en los textos. En este caso, se demostr\u00b4 o que el funcionamiento del sistema mejoraba para aquellas consultas que conten\u00b4 an menos de cinco palabras. En ( Pekar et al. (2006 )) se realiza un estudio para mejorar la traducci\u00b4 on de palabras poco frecuentes a partir de una extensi\u00b4 on de la medida de similitud de co-ocurrencia de palabras ( Dagan et al. (1999 )). Sin embar- go, otros autores han corroborado que WSD contribuye de forma satisfactoria a mejorar los resultados de un sistema de RI. Esta armaci\u00b4 on viene corroborada por Sch\u00a8 utze demostraron que con la aplicaci\u00b4 on de WSD mejoraban el sistema de RI en un 14 %. Otros autores (Jing y Tzoukermann (1999 )) tambi\u00b4 en han demostrado que WSD mejora hasta en un 8 ;6 % los resultados en la recuperaci\u00b4 on de in- formaci\u00b4 on. En este caso, utilizan un algoritmo de desambiguaci\u00b4 on que eval\u00b4 ua la similitud en el contexto local de la consulta, la simi- litud de la informaci\u00b4 on en el corpus y las relaciones morfol\u00b4 ogicas entre palabras. Adem\u00b4 as de poder ayudar a las tareas anteriormente mencio- nadas, WSD tambi\u00b4 en puede ser muy \u00b4 util para otras tareas. En el estudio realizado por Yarowsky ( Yarowsky (1996 )) se demuestra c\u00b4 omo WSD puede utilizarse para sistemas de s\u00b4 ntesis de habla 2. Estado del arte 61 o para encontrar la pronunciaci\u00b4 on correcta de hom\u00b4 ofonos, que un sistema de WSD puede ayudar en el reconocimiento de voz a identicar el item l\u00b4 exico correcto para de todas estas aplicaciones WSD tambi\u00b4 en se puede utilizar en otras muchas tareas de procesamiento de textos (Yarowsky (1994b ),Yarowsky (1994a )). En la Tabla 2.10 se muestran algunas de las aplicaciones ac- tuales que pueden obtener benecios tras utilizar un buen sistema de WSD. Aplicaci\u00b4 on Ejemplo de uso de WSD Traducci\u00b4 de informaci\u00b4 on Encontrar todas las web que hablen el respuestas \u00bfCu\u00b4 al es la opini\u00b4 on de George Miller sobre el control de armas? Resultado: \u00bfEl psic\u00b4 ologo o el congresista? Adquisici\u00b4 on de conocimiento A nadir a la base de conocimiento: Herb Bergson es el alcalde de Duluth Resultado: \u00bfMinnesota o Georgia? Tabla 2.10. Utilizaci\u00b4 on en aplicaciones de PLN Cap\u0013\u0010tulo 3 Problem\u00b4 atica en la evaluaci\u00b4 on de sistemas de WSD En este cap\u00b4 tulo se describe la problem\u00b4 atica asociada a la luaci\u00b4 on de sistemas de desambiguaci\u00b4 on autom\u00b4 atica. Los problemas en esta tarea est\u00b4 an centrados en el tipo de anotaci\u00b4 on utilizado pa- ra etiquetar los sentidos de cada palabra, los corpus utilizados, el criterio de selecci\u00b4 on del sentido correcto de una palabra y las medidas de evaluaci\u00b4 on utilizadas. 3.1 Contexto del problema En (Wilks y Stevenson (1998 )) Yorick Wilks y Mark Stevenson, arman que existen diferentes niveles y tipos de desambiguaci\u00b4 on, dependiendo de la proporci\u00b4 on de palabras desambiguadas y el tipo de anotaci\u00b4 on utilizado. Adem\u00b4 as, para la tarea de desambiguaci\u00b4 on autom\u00b4 atica se utilizan distintos tipos de fuentes de informaci\u00b4 on desde los Machine Readable Dictionaries (MRDs) como LDOCE y WordNet hasta los corpus anotados manualmente. Cada clase de sistema de WSD junto con los recursos que utiliza requiere un corpus de evaluaci\u00b4 on diferente. Por ejemplo, un corpus anotado en base a un diccionario particular no podr\u00b4 a ser utilizado por otro sistema que asigna los sentidos de otro diccionario distinto. Este 64 3.1 Contexto del problema tipo de problemas derivan en una escasez de evaluaci\u00b4 on compara- tiva entre distintos sistemas. Para tratar de unicar criterios de evaluaci\u00b4 on y establecer una comparativa entre distintos sistemas siguiendo los mismos est\u00b4 andares, se cre\u00b4 o una tion Exercises for the Semantic Analysis of Text). Su primera edici\u00b4 on fue en 1998 donde se evaluaron distintos sistemas en dis- tintas lenguas: Ingl\u00b4 es, Franc\u00b4 es e Italiano. A partir de los resultados obtenidos y viendo el inter\u00b4 es creado tras la competici\u00b4 on, se han realizado nuevas ediciones (cada 3 a nos), para evaluar la evoluci\u00b4 on de los sistemas de desambiguaci\u00b4 on autom\u00b4 atica. A continuaci\u00b4 on se describir\u00b4 an las dicultades para la evaluaci\u00b4 on y comparaci\u00b4 on de sistemas encontradas hasta la fecha y que han dado lugar a la organizaci\u00b4 on de Senseval . 3.1.1 Mejoras en los criterios de evaluaci\u00b4 on Previamente a Senseval la evaluaci\u00b4 on est\u00b4 andar de los siste- mas de desambiguaci\u00b4 on autom\u00b4 atica era un simple mapeo exacto entre la anotaci\u00b4 on obtenida por el sistema y los sentidos correctos. De forma que la f\u00b4 ormula utilizada era la siguiente: correctas % = 100 \u00a3#sentidos anotados correctamente #sentidos anotados total(3.1) Sin embargo, esta forma de evaluaci\u00b4 on no es del todo adecua- da teniendo en cuenta que un sistema puede devolver una pro- babilidad distinta para cada uno de los sentidos de una palabra polis\u00b4 emica. Por ejemplo, considerando el siguiente fragmento: \"... bought an interest in Lydak Corp ...\" Supongamos que la palabra ambigua \"interest\" es desambigua- da por cuatro sistemas distintos, los cuales, asignan las siguientes probabilidades a los distintos sentidos de \"interest\" (ver Tabla 3.1). Tal y como se aprecia en la Tabla 3.1, todos los sistemas selec- cionan el sentido incorrecto de \"interest#1\" en lugar de \"inter- est#2\" . Sin embargo, el Sistema 1 es capaz de dar una probabili- dad bastante elevada para el sentido correcto #2. A pesar de ello, 3. Problem\u00b4 atica en la evaluaci\u00b4 on de sistemas de WSD 65 Sentido Sistema 1 Sistema 2 Sistema 3 Sistema 4 #1 monetary (e.g. on a loan) 47 85 28 100 #2 stake or share (correcto 42 5 24 0 #3 bebet/advantage/sake 6 5 24 0 #4 intellectual curiosity 5 5 24 0 Tabla 3.1. Distribuci\u00b4 on de probabilidades asignadas por diferentes sistemas con la forma de evaluaci\u00b4 on dada en la Ecuaci\u00b4 on 3.1el Sistema 1 se penaliza de igual forma que el resto de sistemas, a\u00b4 un teniendo en cuenta que ha sido capaz de predecir el sentido correcto con una probabilidad bastante alta. Para evitar que los sistemas que obtienen distintas probabili- dades para los sentidos de una palabra se penalicen de igual forma que los que s\u00b4 olo seleccionan un \u00b4 unico sentido, se utiliza otro tipo de medida adaptable a todo tipo de sistemas: la entrop\u00b4 a cruzada. En este caso, se eval\u00b4 ua la efectividad de las predicciones de un sis- tema con distintas probabilidades para los distintos sentidos. La f\u00b4 ormula de la entrop\u00b4 a cruzada =\u00a11 context i) (3.2) Donde el n\u00b4 umero de instancias de test y Prses la pro- babilidad asignada por el sistema Sal sentido correcto scide la palabra wien el contexto context i. Mediante esta nueva forma de evaluaci\u00b4 on, los sistemas que asignen una probabilidad bastante elevada al sentido correcto, obtendr\u00b4 an mejores resultados que los dem\u00b4 as. La entrop\u00b4 a cruzada como medida de evaluaci\u00b4 on es muy \u00b4 util cuando se tratan palabras con una distinci\u00b4 on de sentidos muy na, donde es posible anotar varios sentidos y que todos se consi- deren correctos. Una variante de la f\u00b4 ormula de la entrop\u00b4 a cruzada ser\u00b4 a f\u00b4 ormula obviando el t\u00b4 ermino logar\u00b4 tmico quedando tal y como muestra la Ecuaci\u00b4 on 3.3. 66 3.1 Contexto del problema Entropia cruzada adapt =1 NNX i=1PrS(scijwi; context i) (3.3) Esta nueva medida puede ser utilizada por cualquier sistema, independientemente de que asigne probabilidades a cada posible sentido o no. En el caso de sistemas que s\u00b4 olo dan como resultado un \u00b4 unico sentido, esta nueva f\u00b4 ormula es equivalente a la 3.1, que \u00b4 unicamente ten\u00b4 a en cuenta el sentido con mayor probabilidad. 3.1.2 Distancia sem\u00b4 antica Otro problema en el proceso de evaluaci\u00b4 on de sistemas de de- sambiguaci\u00b4 on autom\u00b4 atica, es que muchas medidas de evaluaci\u00b4 on no tienen en cuenta la distancia sem\u00b4 antica entre sentidos a la ho- ra de decidir si las palabras est\u00b4 an anotadas correctamente. Esta situaci\u00b4 on es m\u00b4 as evidente cuando hablamos de jerarqu\u00b4 as de sen- tidos. La Tabla 3.2muestra un ejemplo de agrupaci\u00b4 on de sentidos jer\u00b4 arquica para \"bank\" y su correspondiente matriz de distancia sem\u00b4 antica. I. Bank - Repository I.1 Financial bank I.1a I.2 II.1 II.2 III I.1a - the institution I.1a 0 1 2 4 4 4 I.1b - the building I.1b 1 0 2 4 4 4 I.2 General Supply/Reserve I.2 2 2 0 4 4 4 II Bank - Geographical II.1 4 4 4 0 1 4 II.1 Shoreline II.2 4 4 4 1 0 4 II.2 Ridge/Embankment III 4 4 4 4 4 0 III Bank - Array/Group/Row Tabla 3.2. Jerarqu\u00b4 a de sentidos y matriz de distancia sem\u00b4 antica para \"bank\" Si en el proceso de anotaci\u00b4 on se produjera un error al anotar una palabra con el sentido correspondiente a un hermano dentro de la jerarqu\u00b4 a de sentidos, la penalizaci\u00b4 on deber\u00b4 a ser m\u00b4 as baja que si ese error se debiera a una anotaci\u00b4 on entre sentidos que no est\u00b4 an relacionados de ninguna forma. La soluci\u00b4 on podr\u00b4 a ser em- plear una matriz que la distancia sem\u00b4 antica entre sen- 3. Problem\u00b4 atica en la evaluaci\u00b4 on de sistemas de WSD 67 tidos de forma que cada celda ( sentido 1; sentido 2), contendr\u00b4 a el valor de la distancia entre sentidos. Cuanto m\u00b4 as grande sea el va- lor de la celda, mayor ser\u00b4 a la distancia sem\u00b4 antica entre los sentidos que representa. En la parte derecha de la Tabla 3.2se muestra un ejemplo de matriz de distancia sem\u00b4 antica para \"bank\" . Una forma de evaluar los sistemas usando distancias sem\u00b4 anti- cas es modicando la f\u00b4 ormula de la entrop\u00b4 a cruzada, de forma que se trate de minimizar la distancia entre el sentido asignado (sai) y el sentido correcto ( sci), sobre los Nejemplos, tal y como muestra la Ecuaci\u00b4 on 3.4. Entropia cruzada dist =1 NNX i=1Distancia (sci; sai) (3.4) Adem\u00b4 as de tratar de minimizar la distancia sem\u00b4 antica entre sentidos, tambi\u00b4 en se podr\u00b4 a medir la eciencia de los sistemas penalizando las probabilidades asignadas a sentidos incorrectos seg\u00b4 un la Ecuaci\u00b4 j=1Distancia (sci; sj)\u00a3PrS(sjjwi; context i) (3.5) Donde para cada ejemplo i, se consideran todos los posibles sentidos ( sj) de la palabra wi, midiendo las probabilidades que el sistema Sha asignado a sentidos incorrectos PrS(sjjwi; context i) por la distancia sem\u00b4 antica de estos sentidos respecto al sentido correcto. En (Melamed y Resnik (2000 )) se propuso una variante de estas ideas para Senseval , donde se utiliz\u00b4 o el diccionario HECTOR (Atkins (1992 )). La propuesta fue un esquema de distribuci\u00b4 on de probabilidades a trav\u00b4 es de los distintos niveles de la jerarqu\u00b4 a de sentidos, donde adem\u00b4 as se pod\u00b4 an incluir como respuestas v\u00b4 alidas varios sentidos. EnSenseval la evaluaci\u00b4 on de sistemas se ha hecho utilizando diferentes pautas, variando el nivel de granularidad (sentidos de 68 3.2 Un marco com\u00b4 un para la evaluaci\u00b4 on de sistemas bajo nivel frente a sentidos de alto nivel), etiquetaci\u00b4 on \u00b4 unica de sentidos y etiquetaci\u00b4 on m\u00b4 ultiple de sentidos. En la pr\u00b4 actica, la mayor\u00b4 a de sistemas que han participado en Senseval no obtie- nen un conjunto de probabilidades para todos los sentidos, por ello, la evaluaci\u00b4 on normalmente se realiza utilizando la variante de la entrop\u00b4 a cruzada para un solo sentido seg\u00b4 un la Ecuaci\u00b4 on 3.3 comentada anteriormente. 3.2 Un marco com\u00b4 un para la evaluaci\u00b4 on de sistemas Como ya se ha comentado en el cap\u00b4 tulo anterior, los sistemas de WSD supervisados y no supervisados tienen diferentes necesi- dades en cuanto a recursos necesarios para su evaluaci\u00b4 on. A pesar de que los sistemas no supervisados pueden ser evaluados con un corpus etiquetado como Semcor, que contiene una gran canti- dad de palabras polis\u00b4 emicas, los sistemas supervisados necesitan de corpus m\u00b4 as extensos para realizar su correspondiente entrena- miento y evaluaci\u00b4 on. Para establecer una gu\u00b4 a de las necesidades tanto de sistemas supervisados como de sistemas no supervisa- dos se ha desarrollado un protocolo utilizado en Senseval con algunas modicaciones: 1.Obtener un corpus extenso sin anotar (Por ejemplo, de N=1 bill\u00b4 on de palabras). 2.Determinar el repositorio de sentidos a utilizar (WordNet, LDOCE) y sobre el cual se evaluar\u00b4 an los distintos sistemas. 3.Seleccionar un subconjunto de palabras R < N (por ejemplo, 100 millones) en un corpus no anotado y proporcionarlo a los participantes. 4.Seleccionar un peque no subconjunto de palabras S < R < N (por ejemplo, 10 millones), como conjunto de test. Generar el test como sigue: (a) Seleccionar un conjunto M(por ejemplo, 100) palabras ambiguas. Estas palabras ser\u00b4 an la base para la evaluaci\u00b4 on y no ser\u00b4 an reveladas hasta el momento de distribuir el corpus de test. (b) Para cada una de las Mpalabras, anotar 3. Problem\u00b4 atica en la evaluaci\u00b4 on de sistemas de WSD 69 todas las instancias de cada palabra en el corpus de test. (c) Para cada una de las Mpalabras, evaluar la anotaci\u00b4 on hecha por diferentes anotadores y establecer un acuerdo. (d) Para cada una de las Mpalabras, estudiar los casos en los que los anotadores no se ponen de acuerdo y tomar una decisi\u00b4 on, por votaci\u00b4 on si fuera necesario. 5.Advertir a los participantes de no modicar el c\u00b4 odigo de sus sistemas a partir de este punto. 6.Proporcionar a cada participante el corpus de test. 7.Evaluar cada sistema considerando todas las instancias de las Mpalabras anotadas para la evaluaci\u00b4 on. Comparar anotacio- nes de sentidos exactas, entrop\u00b4 a cruzada, etc. 8.Almacenar el corpus utilizado como test para que sea emplea- do por sistemas de WSD supervisados. A partir de este punto podr\u00b4 an participar utilizando el corpus de test como corpus de entrenamiento. 9.Para la siguiente evaluaci\u00b4 on de sistemas ir al paso 3. Concretamente en Senseval se adoptaron algunos aspectos de este protocolo. El corpus del Paso 1 fueron 17 millones de pa- labras extra\u00b4 das del British National Corpus1, que hasta ahora ha ido increment\u00b4 andose hasta 100 millones de palabras. El reposito- rio de sentidos seleccionado del Paso 2 fue la base de datos HEC- TOR ( Senseval-1 . Como el proceso de evaluaci\u00b4 on inclu\u00b4 a tanto sistemas supervisados como no supervisados, los corpus de entre- namiento incluyeron tanto instancias anotadas como no anotadas (al contrario que en el Paso 3), para un conjunto de 29 palabras ambiguas. Para el proceso de creaci\u00b4 on del corpus de test del Paso 4, se seleccionaron 34 palabras ambiguas distribuidas en 8448 ins- tancias. Los participantes fueron advertidos de no modicar sus sistemas tal y como estaba especicado en el Paso 5. La gran diferencia con el protocolo seguido en Senseval fue con respecto a los Pasos 6 y 7, donde los participantes no sab\u00b4 an qu\u00b4 e palabras iban a ser utilizadas para la evaluaci\u00b4 on. Por ello, se hicieron dos grupos, uno para evaluar a los sistemas que s\u00b4 olo de- sambiguaron las palabras del conjunto de test, y otro con los siste- 1http://www.natcorp.ox.ac.uk/ 70 mas que desambiguaron todas las palabras con contenido sem\u00b4 anti- co. Los resultados obtenidos indicaron que los sistemas m\u00b4 as e- cientes eran aquellos que utilizaban corpus de entrenamiento para aprender clasicadores especialmente dise nados para las palabras del corpus de test. En el Cap\u00b4 tulo 6 se describen en profundidad todas las edicio- nes de Senseval hasta la actualidad y algunos de los sistemas m\u00b4 as relevantes en la tarea de WSD. Cap\u0013\u0010tulo 4 Recursos A continuaci\u00b4 on se van a describir los recursos utilizados como base para el desarrollo de nuestros m\u00b4 etodos de desambiguaci\u00b4 on y para la creaci\u00b4 on del nuevo recurso l\u00b4 exico Dominios Relevantes. La elecci\u00b4 on de estos recursos se debe al conjunto de caracter\u00b4 sticas (relaciones sem\u00b4 anticas entre palabras, conexi\u00b4 on con varios idio- mas, adquisici\u00b4 on de conocimiento a trav\u00b4 es de relaciones entre pa- labras, etc) que los hacen id\u00b4 oneos para la WSD. 4.1 WordNet onico siguiendo principios psicoling\u00a8 u\u00b4 sticos. Su contenido se organiza mediante una base de datos l\u00b4 exica donde se agrupan conjuntos de palabras (nombres, verbos, adjetivos y adverbios) en grupos de sin\u00b4 onimos llamados synsets: un synset se codica umero \u00b4 unico de ocho d\u00b4 gitos. Dentro de la base de datos, cada synset representa un concepto distinto y entre cada uno de ellos existen conexiones que expresan relaciones sem\u00b4 anticas, con- ceptuales o l\u00b4 exicas. El resultado de este conjunto de conexiones es una extensa red navegable que proporciona un gran n\u00b4 umero de inter-relaciones entre palabras. Entre este conjunto de relaciones encontramos las siguientes: 72 4.1 WordNet Sinonimia. Dentro de la misma categor\u00b4 a sint\u00b4 actica (nombre, verbo, adjetivo o adverbio), son sin\u00b4 onimas aquellas palabras que pueden sustituirse dentro de un contexto determinado sin alterar su signicado. Por ejemplo, en las frases: \"Me pas\u00b4 o una hoja en blanco\" y \"Me pas\u00b4 o un folio en blanco\". Las palabras \"hoja\" y \"folio\" son sin\u00b4 onimas porque al sustituir una por la otra no se altera el signicado de la frase. l\u00b4 una relaci\u00b4 on en- tre los signicados de las palabras. Estas relaciones se dan \u00b4 uni- camente para los nombres. Por ejemplo: Este tipo de relaci\u00b4 on se conoce tambi\u00b4 en con el nombre de \"IS A\". Se entiende que \"X\" es un hip\u00b4 onimo \"Y\" si \"X es (tipo la inversa de la hi- ponimia. Es decir, Y es un hiper\u00b4 onimo de X si \"X es com\u00b4 relaci\u00b4 on sem\u00b4 anti- ca es como un tipo de v\u00b4 nculo \"HAS A\". Una palabra X es mer\u00b4 onima de Y si \" X es una parte de Y \" . Por ejemplo, p\u00b4 arpado, retina o c\u00b4 ornea son mer\u00b4 onimos de ojo, porque todos son partes del ojo. la inversa de la mero- nimia. Es decir, Y es un hol\u00b4 onimo de X si \" X es una parte de Y \" . Por ejemplo, \"casa\" es y es el equivalen- te de la relaci\u00b4 on de hiponimia ermino implica al otro. Por ejemplo, de ca- da t\u00b4 ermino, WordNet establece una relaci\u00b4 on de orden entre los diferentes sentidos de las palabras, de acuerdo a su frecuencia de aparici\u00b4 on. De esta forma, para \"plant\" en la versi\u00b4 on 2.1 existen 3.f05831211 for disco- very by plant to trick the thieves\"; \"he claimed that the evidence against him was a plant\") 4.f10282477 gplant#4 - (an actor rehearsed but seems concepto asociado al t\u00b4 ermino \"plant\" adem\u00b4 as de tener asociado su indican la frecuencia de aparici\u00b4 on de cada concepto, siendo plant#1 el m\u00b4 as frecuente. Estrechamente vinculada a cada synset existe una denici\u00b4 on o glosa que dene el concepto representado por el sentido espec\u00b4 co de cada t\u00b4 ermino. As\u00b4 para plant#1 su on industrial labor\" de t\u00b4 erminos (synsets), se sit\u00b4 ua la palabra en un contexto (oraci\u00b4 on), 76 4.1 WordNet ejemplicando de esta forma su \"they built a large plant to manufacture automobiles\" . Los conceptos situados en lo alto de la jerarqu\u00b4 a de WordNet de los que derivan el resto de conceptos, son los mostrados en la Tabla 4.1. Concepto Denici\u00b4 on entity that which is perceived or known or inferred to its (living or nonliving) psychological feature a feature of the mental life of a living organism abstraction a general concept formed by extracting common features from specic examples state the way something is with respect to its main attributes; \"the current state of that happens at a given place and time act, human action, human activity something that people do or cause to happen group, grou- ping any number of entities (members) considered as a unit possession anything owned or possessed phenomenon any state or process senses rather than by intuition or reasoning Tabla 4.1. Conceptos en la cima de la jerarqu\u00b4 a de WordNet En la Figura 4.1tenemos una representaci\u00b4 on de la red sem\u00b4 anti- ca para la palabra \"aircraft\" con sentido 1. En esta imagen se pue- de observar la extensi\u00b4 on de las diferentes dimensiones que puede tener un concepto en WordNet. Otro ejemplo de las relaciones sem\u00b4 anticas existentes en Word- Net lo encontramos en la Figura 4.2, donde se muestra un extracto de la relaciones existentes para \"bank#1\" . Como se puede apreciar en la Figura 4.2, para bank#1 exis- ten una serie de sin\u00b4 onimos: concern y depository As\u00b4 como una serie de hip\u00b4 representados mediante flechas de color verde, mer\u00b4 onimos repre- 4. Recursos 77 Figura 4.1. Red sem\u00b4 antica para airplane#1 sentados mediante flechas de color amarillo y hol\u00b4 onimos represen- tados mediante flechas de color morado. Una representaci\u00b4 on m\u00b4 as detallada de esta versi\u00b4 on gr\u00b4 aca de las relaciones existentes para bank#1 se muestra en la Tabla 4.2. 4.2 WordNet Domains WordNet Domains extiende la informaci\u00b4 on proporcionada inclusi\u00b4 on de \"Subject Field Codes\" (SFC) , es decir, conjuntos de palabras relevantes para un dominio es- pec\u00b4 co. Una representaci\u00b4 on de este tipo de informaci\u00b4 on la encon- tramos en las etiquetas de campo sem\u00b4 antico, de uso com\u00b4 un en to- do tipo de diccionarios, por ejemplo: Matem \u0013aticas ,Bot\u0013anica , etc. Por un lado, estas clarican a qu\u00b4 e contexto se reere la denici\u00b4 on que sigue, por ejemplo, la palabra \"anillo\" , pertene- ce a diferentes contextos, tales como, Arquitectura \"Cornisa circular u ovalada\", Bot\u0013anica \"Cada uno Domains Figura 4.2. Relaciones sem\u00b4 anticas para bank#1 79 Relaciones Palabras Glosa Sin\u00b4 onimos Depository nancial institution Bank Banking institution that accepts Home Loan Bank One of 11 regional banks that monitor and make short-term credit advances to thrift institutions in their region Federal Reserve Bank One of 12 regional banks that monitor and act as depositories for banks in their region Member bank A bank that is a member of the Federal Reserve System Agent bank A bank that acts as an agent for a fo- reign bank mand deposits and makes loans . . . . Mer\u00b4 (public or private) that collects funds (from the public or other nan- cial assets) Hol\u00b4 onimos Relaciones existentes para bank#1 conc\u00b4 entricos que forman el tronco de un \u00b4 arbol\" y Matem \u0013aticas \"Conjunto de elementos entre los que se denen dos reglas de composici\u00b4 on\". Por otro lado, estas etiquetas permiten la b\u00b4 usque- da r\u00b4 apida de la acepci\u00b4 on deseada, por ejemplo, si buscamos el signicado de \"disco\" dentro del contexto de la Inform \u0013atica no es necesario ir leyendo todas las acepciones una por una hasta dar con la que deseamos, simplemente basta con mirar la etiqueta del campo sem\u00b4 antico que precede a cada denici\u00b4 on hasta dar con la que nos interesa, en este caso, Inform \u0013atica . Dada su utilidad, los SFC ya han sido usados en Ling\u00a8 u\u00b4 stica y en Lexicograf\u00b4 a para marcar los usos t\u00b4 ecnicos de las palabras. Aunque \u00b4 esta es una informaci\u00b4 on muy \u00b4 util para establecer una 80 4.2 WordNet Domains discriminaci\u00b4 on de sentidos, en los diccionarios generalmente se emplea s\u00b4 olo para una peque na parte del l\u00b4 exico. Un ejemplo lo tenemos en la entrada para la palabra \"bolsa\" , (Tabla 4.3), en el Diccionario de la Lengua de la Real Academia Espa nola (R.A.E). Deniciones de la palabra Bolsa en el R.A.E. 1.f. Especie de talega o saco de tela u otro material, que sirve para llevar o guardar algo. 2.f. Saco peque no de cuero en que se echa dinero, y que se ata o cierra. 3.f. Recipiente de material resistente para guardar, en viajes o traslados, ropa u otras cosas, y que se puede llevar a mano o colgado del hombro. Bolsa de deporte. 4.f.folgo. 5.f. Arruga que hace un vestido cuando viene ancho o no ajusta bien al cuerpo, o la que forman dos telas cosidas cuando una es m\u00b4 as larga o ha dado de s\u00b4 m\u00b4 as que la otra. 6.f. Abultamiento de la piel debajo de los ojos. 7.f. Acumulaci\u00b4 on de un fluido en un determinado lugar. 8.f. Caudal o dinero de una persona. A Juan se le acab\u00b4 o la bolsa. 9.f. Pieza de estera en forma de saco, que pende entre los varales del carro o galera, y debajo de la zaga de los coches o calesas, para colocar efectos. 10.f. Taleguilla de tafet\u00b4 an o moar\u00b4 e negro con una cinta en la parte superior que usaban los hombres para llevar recogido el pelo. 11.f.Dep. Premio en met\u00b4 alico que recibe el ganador de un combate de boxeo. 12.f.Dep. Cantidad que se ofrece a quien participa en otras competiciones. 13.f.Ingen. Parte de un criadero donde el mineral est\u00b4 a reunido con mayor abundancia. 14.f.Med. Cavidad llena de pus, linfa, etc. 15.f.Mil.Situaci\u00b4 on en que queda un ej\u00b4 ercito o una parte de \u00b4 el al ser comple- tamente rodeado por las fuerzas enemigas. 16.f.Am. Cen. yM\u00b4 ex. Bolsillo de las prendas de vestir. 17.f. pl. Cavidades del escroto en las cuales se alojan los test\u00b4 culos. 18.f. pl. u. c. sing. m. vulg. Ven. Persona imb\u00b4 ecil, lerda. Tabla 4.3. Deniciones para la palabra \"bolsa\" del RAE Con el n incorporar la informaci\u00b4 on de las etiquetas sem\u00b4 anticas a WordNet se construy\u00b4 o un pretend\u00b4 a mejorar la distinci\u00b4 on de los sentidos en WordNet, agrupando en muchos casos distintos sentidos bajo un mismo do- minio o categor\u00b4 a sem\u00b4 antica. 4. Recursos 81 Mediante WordNet Domains, se intenta extender la cobertura de las etiquetas de dominio, dentro de una base de datos l\u00b4 exi- ca ya existente: WordNet. En WordNet Domains los WordNet han sido anotados mediante un proceso semiautom\u00b4 atico con una o varias etiquetas de dominio, seleccionadas de entre un conjunto de 200 etiquetas organizadas jer\u00b4 arquicamente. La anotaci\u00b4 on de WordNet mediante SFC's viene motivada por: Crear nuevas relaciones entre palabras. Mediante las eti- quetas de dominio se pueden establecer relaciones entre pala- bras que pertenecen a distintas categor\u00b4 as, ya que, por ejem- plo, en WordNet1.61, no encontramos relaciones entre nom- bres y verbos. Anotar a nivel sem\u00b4 antico. Debido a que los dominios se aso- cian a synsets, la anotaci\u00b4 on se realiza a nivel sem\u00b4 antico y no a nivel de palabra. Obtener recursos multiling\u00a8 ues. LosSFC's son b\u00b4 asicamen- te independientes del lenguaje, por lo que se pueden incluir en recursos multiling\u00a8 ues tales como, EuroWordNet ( Vossen (1998 )). La informaci\u00b4 on aportada por los SFC's es complementaria a la informaci\u00b4 on que tiene WordNet. La primera caracter\u00b4 stica que a naden a WordNet es que dentro de un mismo dominio pueden incluirse synsets que pertenecen a diferentes categor\u00b4 as sint\u00b4 acticas. Por ejemplo, con el dominio Music se han anotado pala- bras pertenecientes a diferentes categor\u00b4 as sint\u00b4 acticas, tal como se muestra en la Tabla 4.4. Una segunda caracter\u00b4 stica que aportan los dominios a Word- Net es que dentro de un mismo dominio pueden aparecer sentidos de palabras pertenecientes a diferentes subjerarqu\u00b4 as de WordNet, es decir, descendientes de diferentes ra\u00b4 ces o de diferentes cheros lexicogr\u00b4 acos. Por ejemplo, el dominio Sport contiene sentidos como athlete#1 , que deriva de life form#1 ,game equipment#1 versi\u00b4 on 2.0. ya se pueden establecer este tipo de relaciones 82 4.2 WordNet Domains Dominio Music Categor\u00b4 a Palabras Glosas Nombres album#1 one or more phonograph records or tape music; \"modulate stro- king a bow (music) at a very fast tempo (faster than allegro) Tabla 4.4. Relaciones entre diferentes categor\u00b4 as sint\u00b4 acticas mediante el uso de dominios. La tercera y \u00b4 ultima caracter\u00b4 stica que a naden los dominios a WordNet, es la posibilidad de reducir el nivel de polisemia de las palabras, es decir, dentro de un mismo dominio se pueden agrupar diferentes sentidos pertenecientes a una misma palabra. Por ejemplo, los dominios asociados a la palabra \"man\" , que en WordNet tiene 10 sentidos, son los que se muestran en la Tabla 4.5. Si se anotan los sentidos utilizando dominios tal y como apa- recen en la Tabla 4.5, se puede reducir el nivel de polisemia de 10 sentidos a 4 sentidos, agrupando aquellos sentidos que pertenecen a un mismo dominio. En este caso, se agrupar\u00b4 an dentro de un \u00b4 unico sentido todos aquellos conceptos pertenecientes al dominio Person : man#1,3,5,6,7,8,9 )Person man#2 )Military man#4 )Factotum Glosa man#1 person an adult male person (as opposed to a woman); \"there were two women and six men on the bus\" man#2 military someone who serves duty\" man#3 person the generic use of the word to refer to any human being; \"it was every man for himself\" man#4 factotum all of the inhabitants of world loves biology, adult male (virile and courageous army will a (husband or lover boyfriend) in the life of a particular woman; \"she takes good care of her man\" man#9 person a manservant who acts as employer; \"Jeeves was Bertie Wooster's ga- mes; \"he taught me the men on the chess board\"; \"he sacriced a piece to get a strategic ad- vantage\" Tabla 4.5. Reducci\u00b4 on de la polisemia mediante el uso de dominios Los dominios se han estructurado desde dos puntos de vista diferentes: jer\u00b4 arquicamente dominios en- contramos diferentes niveles de especicaci\u00b4 on. Por ejemplo, dentro del nivel 1 podemos encontrar dominios de tipo Bo- tany, Linguistics, History y Religion . Sin embargo, dentro del nivel 2 encontramos dominios de tipo Building Industry, Dentistry, Football y Photography . Cuanto m\u00b4 as pro- fundizamos es los niveles de la jerarqu\u00b4 a, mayor es el nivel de especializaci\u00b4 on de los dominios. En la gura 4.3se muestra un peque no fragmento de la Estructuraci\u00b4 de la estructuraci\u00b4 on jer\u00b4 arqui- ca, los dominios se organizan en familias. Una familia es un conjunto de dominios sem\u00b4 anticamente relacionados entre los que no existen relaciones de inclusi\u00b4 on. Mientras que la organi- zaci\u00b4 on jer\u00b4 arquica es ja, la organizaci\u00b4 on por familias se puede reorganizar permitiendo la creaci\u00b4 on de nuevas relaciones in- terdisciplinarias. Entre el conjunto de SFC's encontramos una etiqueta de do- minio denominada Factotum . Este dominio se ha creado exclu- para dos tipos de synsets: Estos synsets son aquellos te se pueden clasicar dentro de alg\u00b4 un dominio en particular. Por ejemplo: act#2: something that people do or cause to hap- pen act#5: a manifestation of insincerity; \"he put on quite an act for her benet\" Stop senses. Son aquellos synsets que aparecen frecuentemen- te en diferentes contextos, tales como n\u00b4 umeros, d\u00b4 as de la se- mana, colores, etc. Estos synsets pertenecen normalmente a palabras monos\u00b4 emicas. El proceso de anotaci\u00b4 on de los synsets de WordNet1.6 mediante SFC's se divide en tres pasos: Paso 1. Un n\u00b4 umero reducido de synsets pertenecientes a los niveles m\u00b4 as altos de la jerarqu\u00b4 a de WordNet son anotados manualmente mediante los SFC's. Paso 2. A partir de la anotaci\u00b4 on obtenida en el paso 1, se ejecu- ta un proceso autom\u00b4 atico que explota las relaciones de Word- Net (hiponimia, troponimia, meronimia, antonimia, etc), para extender on manual a todos aquellos synsets alcan- zables. Paso 3. El \u00b4 ultimo paso es realizar la evaluaci\u00b4 on de los resul- tados obtenidos por el proceso autom\u00b4 atico. Las anotaciones err\u00b4 oneas son detectadas, se corrigen y se vuelve a lanzar el proceso del paso 2 a partir de los nuevos valores. 86 4.3 Extended WordNet 4.3 Extended WordNet Extended WordNet ( Harabagiu et al. (1999 )) es un nuevo re- curso l\u00b4 exico creado en la Universidad de Texas que trata de me- jorar la informaci\u00b4 on proporcionada por WordNet en sus distintas versiones, agregando informaci\u00b4 on sem\u00b4 antica a las glosas. Esta nue- va informaci\u00b4 on se extrae \u00b4 unicamente de la parte de la denici\u00b4 on de las glosas, descartando los ejemplos y las aclaraciones entre par\u00b4 entesis que puedan aparecer. Por ejemplo, pensemos en la glo- sa de la palabra \"man\" :an adult male and courageous \"the army will make a man of you\" . En este caso, \u00b4 unicamente se tendr\u00b4 a en cuenta la informaci\u00b4 on proporcionada en la denici\u00b4 on \"an adult male per- son who has omitiendo la aclaraci\u00b4 on entre par\u00b4 entesis y la frase de ejemplo para este sentido. Para ampliar y mejorar la informaci\u00b4 on proporcionada por WordNet se realizan tres tipos de de las glosas se ha utilizado una versi\u00b4 on mejorada del etiquetador de Brill ( Brill (1995 )). Esta nueva versi\u00b4 on ha sido entrenada sobre WordNet. El resultado obtenido (palabras con su cate- gor\u00b4 a sint\u00b4 actica, g\u00b4 enero, n\u00b4 umero,...), se utiliza como entrada para dos tipos distintos de analizadores sint\u00b4 acticos. Estos ana- lizadores se integran en un esquema de votaci\u00b4 on para tratar de mejorar la calidad de los resultados. Aunque este an\u00b4 ali- sis sint\u00b4 actico, se podr\u00b4 a haber aplicado directamente sobre las glosas de WordNet sin un preproceso inicial, se consider\u00b4 o ne- cesario un tratamiento previo de las glosas para obtener unos resultados m\u00b4 as precisos. Este tratamiento previo consiste en extender el contenido de las glosas de la siguiente forma: \u00b2Adverbios. Las glosas pertenecientes a adverbios se extien- den a nadiendo (el adverbio + is) al principio de la glosa y un punto al nal de la denici\u00b4 on. Por ejemplo, para el ad- verbio \"entirely\" su glosa quedar\u00b4 a como sigue: entirely is without any others being included or involved . 4. Recursos 87 \u00b2Adjetivos. Las glosas pertenecientes a adjetivos se extien- den a nadiendo (el adjetivo + is something ) al principio de la glosa y un punto al nal de la denici\u00b4 on. Por ejemplo, para el adjetivo \"innite\" su glosa quedar\u00b4 a como sigue: innite is something total and all-embracing . \u00b2Verbos. Las glosas pertenecientes a verbos se extienden a nadiendo ( to+ el verbo + is to) al principio de la glosa y un punto al nal de la denici\u00b4 on. Por ejemplo, para el verbo \"hiccup\" su glosa quedar\u00b4 a como sigue: to hiccup spasmodically , and make a sound . \u00b2Nombres. Las glosas pertenecientes a nombres se extien- den a nadiendo (el nombre + is) al principio de la glosa y un punto al nal de la denici\u00b4 on. Por ejemplo, para el nombre \"space\" su glosa quedar\u00b4 a como sigue: space is the unlimi- ted alisis ogico. Muchas de la informaci\u00b4 on pragm\u00b4 atica contenida en los textos. Debido a es- ta necesidad, Extended WordNet incorpora informaci\u00b4 on l\u00b4 ogica a las glosas. Utilizando las glosas conceptuales originales de WordNet, \u00b4 estas se transforman en su forma l\u00b4 ogica correspon- diente. La forma l\u00b4 ogica obtenida paso intermedio entre el an\u00b4 alisis sint\u00b4 actico y una forma sem\u00b4 3) enlaces prepo- sicionales, glo- sas. Estas deniciones (glosas) se encuentran repartidas de la siguiente forma: unas 79000 est\u00b4 an asociadas a nombres, alre- dedor de 13000 a verbos, sobre 18000 a adjetivos y por \u00b4 ultimo unas 3500 a adverbios. En la tarea de an\u00b4 alisis sem\u00b4 antico se han utilizado dos tipos de anotaci\u00b4 on: autom\u00b4 atica y manual. En la anotaci\u00b4 on autom\u00b4 atica han intervenido dos sistemas: uno dise nado de forma espec\u00b4 ca para desambiguar las glosas de WordNet, llamado XWN WSD y un sistema propio para de- sambiguar texto libre. Para decidir el sentido asociado a cada una de las palabras de la glosa, se ha empleado un sistema 88 4.3 Extended WordNet de votaci\u00b4 on entre los dos m\u00b4 etodos autom\u00b4 aticos. De forma que la precisi\u00b4 on estimada cuando los dos m\u00b4 etodos etiquetan una palabra con el mismo sentido es del 90 %. Existen tres cate- gor\u00b4 as de anotaci\u00b4 Cuando el sentido selec- cionado para una palabra se etiqueta como \"GOLD\" quiere decir esa anotaci\u00b4 on se ha comprobado de forma manual. Cuan- do un sentido aparece con la etiqueta \"SILVER\" signica que ha sido etiquetado de forma consensuada por los dos m\u00b4 eto- dos autom\u00b4 aticos de desambiguaci\u00b4 on. Y por \u00b4 ultimo cuando un sentido aparece junto a la etiqueta \"NORMAL\" quiere decir que se ha seleccionado el sentido proporcionado por el sistema autom\u00b4 atico XWN WSD. Cabe considerar que los verbos \"to be\" y \"to have\" se han tratado de forma especial y no se han desambiguado de forma autom\u00b4 atica. El procedimiento segui- do para obtener la desambiguaci\u00b4 on de las glosas de WordNet consta de dos fases: 1.El primer paso consta de la realizaci\u00b4 on de un preproceso sobre las glosas de WordNet para separar la parte de la denici\u00b4 on de la parte de ejemplos. Tambi\u00b4 en se realiza la tokenizaci\u00b4 on, el an\u00b4 alisis sint\u00b4 actico usando el etiquetador de Brill y la identicaci\u00b4 on de conceptos compuestos. 2.El segundo paso, una vez realizado el preproceso, es asignar a cada palabra de la glosa su correspondiente sentido. En esta fase, se utiliza la categor\u00b4 a sint\u00b4 actica obtenida en la fase previa para establecer el sentido correspondiente, ya que, una misma palabra puede actuar como nombre, verbo, adjetivo o adverbio, y por tanto, puede adoptar distintos signicados dependiendo de su categor\u00b4 a. Para poder realizar correctamente el proceso de desam- biguaci\u00b4 on se familia jer\u00b4 arquica: Se identican aquellas pala- bras de la glosa que pertenecen a la misma jerarqu\u00b4 a que el synset de la glosa. 4. Recursos 89 \u00b2Paralelismo l\u00b4 exico: Se identican aquellas palabras que pertenecen a la misma categor\u00b4 a sint\u00b4 actica y que est\u00b4 an separadas por comas o conjunciones. Cuando es posible, se trata de seleccionar los sentidos que pertenecen a la misma jerarqu\u00b4 a. \u00b2B\u00b4 usqueda en Semcor: Dada una palabra de la glosa se forman dos parejas: palabra-palabra siguiente de la glosa palabra anterior de la glosa-palabra. Estos dos pares de palabras se buscan en el corpus de Semcor ( G. Miller y Bunker (1993 )). Si para estos pares de palabras el sentido asignado es siempre el mismo y el n\u00b4 umero de ocurrencias supera un cierto umbral, se le asigna ese sentido. \u00b2Dominio asociado: Cada glosa de WordNet se ha anota- do con un dominio ( Magnini y Strapparava (2000 )). Si la palabra de la glosa tiene alg\u00b4 un sentido anotado con el mismo dominio que el de la glosa, se selecciona ese sentido. \u00b2... Mediante estas heur\u00b4 sticas se han desambiguado el 64 % de las palabras de WordNet con un 75 % de precisi\u00b4 on. El resto de las palabras se han etiquetado con el sentido#1 (el m\u00b4 as frecuente). Adem\u00b4 as del m\u00b4 se ha utilizado otro m\u00b4 etodo autom\u00b4 atico para el proceso de desambiguaci\u00b4 on, el cual, utiliza como base texto libre. Para su aplicaci\u00b4 on fue necesaria la transformaci\u00b4 on de las glosas en oraciones com- pletas. De esta forma, se obtuvo una cobertura de un 100 % y una precisi\u00b4 on del 70 %. Las palabras que se etiquetaron con el mismo sentido por los dos sistemas obtuvieron un 90 % de precisi\u00b4 on. En la Tabla 4.6aparece el resultado obtenido tras realizar los tres tipos de an\u00b4 alisis sobre la glosa asociada al adjetivo \"exce- llent\" (NP (NP (NN (Suggested Upper Ontology) es una ontolog\u00b4 a de nivel superior ( Niles y Pease (2001 )). Esta on- tolog\u00b4 deniciones para t\u00b4 erminos de prop\u00b4 osito gene- ral y puede actuar como base para ontolog\u00b4 as de dominios m\u00b4 as espec\u00b4 cos. SUMO fue creada a partir de la combinaci\u00b4 on de dife- rentes contenidos ontol\u00b4 ogicos en una \u00b4 unica estructura cohesiva y actualmente existen alrededor de 1000 t\u00b4 erminos y 4000 aserciones. Los contenidos a partir de los cuales se obtuvo SUMO proceden de: Ontolingua2, John Sowa's upper level utilizado es una versi\u00b4 on de KIF llamada 3http://www.jfsowa.com/ontology/ 4. Recursos 91 El proceso de creaci\u00b4 on de esta ontolog\u00b4 a consta de varios pasos. Primero, se identicaron todos los contenidos ontol\u00b4 ogicos de alto nivel. Estos contenidos inclu\u00b4 an las librer\u00b4 as de ontolog\u00b4 as dispo- nibles en el servidor Ontolingua y ITBM-CNR, la ontolog\u00b4 a de John Sowa, la ontolog\u00b4 a de Russell y Norvig ( Russell y Norvig (1995 )), los axiomas temporales de James Allen ( Allen (1984 )) y otras representaciones. Una vez extra\u00b4 do todo el contenido rele- vante se transform\u00b4 o al lenguaje SUO-KIF. Una vez realizada la traducci\u00b4 on, el paso m\u00b4 as complicado fue la creaci\u00b4 on de una \u00b4 uni- ca ontolog\u00b4 a que combinara todo el contenido recopilado. Para llevar a t\u00b4 ermino este proceso, en primer lugar, se dividieron los conceptos en dos grupos: conceptos de alto nivel y conceptos de bajo nivel. En el primer grupo, se mantuvo la ontolog\u00b4 a de John Sowa y la ontolog\u00b4 a de Russell y Norvig. En el segundo grupo se incluy\u00b4 o el resto. Tras la divisi\u00b4 on las dos ontolog\u00b4 as de alto nivel ambas se combinaron para obtener una \u00b4 unica estructura concep- tual. El resto del contenido de las clases de bajo nivel fue a nadido tras la combinaci\u00b4 on. La forma de incluir las clases de bajo nivel y los problemas a los que se tuvo que hacer frente est\u00b4 an descritos en (Niles y Pease (2001 )). Para comprender la estructura y el contenido de SUMO pode- mos extraer los conceptos de m\u00b4 as alto nivel, tal y como muestra la Figura 4.4. Al igual que en la mayor\u00b4 a de jerarqu\u00b4 as el concepto de m\u00b4 as alto nivel es \"entity\" y bajo este concepto se encuentran \"physical\" y \"abstract\" . En la Figura 4.6se muestra un ejemplo de la jerarqu\u00b4 a de conceptos y relaciones existentes en SUMO para bank#1. En esta representaci\u00b4 on gr\u00b4 aca existe un c\u00b4 odigo de colores aso- ciado a las distintas clases de elementos y sus relaciones seg\u00b4 un la Figura 4.5. 92 4.4 SUMO (Suggested Upper Ontology) Figura alto nivel en SUMO Figura 4.5. C\u00b4 odigo de colores en la representaci\u00b4 on gr\u00b4 aca de SUMO 4. Recursos 93 Figura 4.6. Jerarqu\u00b4 a SUMO para bank#1 94 4.4 SUMO (Suggested Upper Merged Ontology) La ontolog\u00b4 a SUMO tambi\u00b4 en se ha enlazado con los synsets de WordNet ( Niles y Pease (2003 )). De la misma forma que los Subject Field Codes se integraron en WordNet Domains, los di- ferentes conceptos de la ontolog\u00b4 a de SUMO se han enlazado con los synsets de WordNet. En el proceso de anotaci\u00b4 on de WordNet con la ontolog\u00b4 a SUMO se han utilizado tres tipos de relaciones: sinonimia, hiperonimia e instanciaci\u00b4 on. A continuaci\u00b4 on se muestra un ejemplo para cada una de este tipo de relaciones: Sinonimia. En caso de utilizar relaciones de sinonimia, veamos el ejemplo de la palabra \"plant\" cuyo synset en WordNet 1.6 es 00008864. 00008864 03 n 03 plant 0 flora 0 plant life 0 027 @ . . . \u2014 a living organism lacking the power of locomotion En este caso, el synset 00008864 es sin\u00b4 onimo del concepto de la ontolog\u00b4 a SUMO Plant . Por tanto, la entrada en WordNet se ampl\u00b4 a de la siguiente forma: 00008864 03 n 03 plant 0 flora 0 plant life 0 027 @ . . . \u2014 a living organism lacking locomotion & %Plant= El prejo \"& %\" indica que el concepto se ha obtenido a partir de SUMO y el signo \"=\" indica que el mapeo ha utilizado una relaci\u00b4 on de sinonimia. Hiperonimia. En caso de que un synset de WordNet no tenga una correspondencia exacta con un concepto de la ontolog\u00b4 a de SUMO, se utiliza la relaci\u00b4 on de hiperonimia. Supongamos que tenemos la palabra \"Christian Science\" , cuya entrada en WordNet 1.6 es la siguiente: 04719796 09 n 01 Christian Science 0 001 @ 04718274 n 0000 \u2014 religious system based on teachings of Mary Baker Eddy emphasizing spiritual healing En este caso, no existe un concepto espec\u00b4 co para \"Chris- 4. Recursos 95 tian Science\" , sin embargo, la ontolog\u00b4 a contiene conceptos m\u00b4 as generales, dentro de los cuales se puede incluir este syn- set. La anotaci\u00b4 on quedar\u00b4 a de la siguiente forma: 04719796 09 n 01 Christian Science 0 001 @ 04718274 n 0000 \u2014 religious system based on teachings of Mary Baker Eddy emphasizing spiritual healing & %ReligiousOrganization+ Donde el sujo + indica que el concepto de la ontolog\u00b4 a es un hiper\u00b4 onimo del synset. Instanciaci\u00b4 on. Esta \u00b4 ultima relaci\u00b4 on indica que el synset de WordNet es miembro de un concepto de la ontolog\u00b4 a. Veamos el siguiente ejemplo para la palabra \"Underground Railroad\" : 00034393 04 n 02 Underground Railroad 0 Under- ground Railway 0 001 @ 00032687 n 0000 \u2014 abolitionists secret aid to escaping slaves; pre \u00a1Civil War in US En este caso, el concepto m\u00b4 as apropiado para el synset es Or- ganization . Por tanto, el synset asociado a Underground Railway , es una organizaci\u00b4 on particular. Este tipo de relaci\u00b4 on se mues- tra de la siguiente forma: 00034393 04 n 02 Underground Railroad 0 Under- ground Railway 0 001 @ 00032687 n 0000 \u2014 abolitio- nists secret aid to escaping slaves; pre \u00a1Civil US & %Organization@ Donde s\u00b4 mbolo \"@\" indica una relaci\u00b4 on de instanciaci\u00b4 on respecto al synset. Mediante la inclusi\u00b4 on de los conceptos de la ontolog\u00b4 a SUMO en WordNet, se pueden establecer relaciones entre synsets y ca- tegor\u00b4 as sint\u00b4 acticas al igual que suced\u00b4 a con WordNet Domains. Adem\u00b4 as, mediante el uso de un algoritmo de desambiguaci\u00b4 on se pueden asignar a un contexto determinado los conceptos de SU- MO relacionados. De esta forma, la representaci\u00b4 on conceptual 96 4.5 An\u00b4 alisis de la Sem\u00b4 antica Latente (LSA) puede para facilitar b\u00b4 sem\u00b4 anticas o (LSA) la Sem\u00b4 antica Latente o Latent Semantic Analysis (LSA) es un modelo computacional que explota una caracter\u00b4 stica propia del lenguaje natural: palabras del mismo campo sem\u00b4 antico tienden a aparecer juntas o en contextos similares ( Landauer y Dumais (1997 )). LSA tiene sus or\u00b4 una t\u00b4 ecnica de recuperaci\u00b4 al. (1988 ),Deerwester et al. (1990 )). El objetivo de LSI es mejo- rar la recuperaci\u00b4 on de documentos reduciendo una gran matriz de t\u00b4 ermino-documento en un espacio m\u00b4 as reducido utilizando la t\u00b4 ecnica de SVD (Singular Value Decomposition). LSA utiliza la misma metodolog\u00b4 a pero se diferencia en la representaci\u00b4 on de la matriz. En este caso, LSA utiliza una matriz palabra-contexto. LSA representa un texto como una matriz de co-ocurrencia M\u00a3N, donde las Mlas se corresponden con palabras, y las N columnas se corresponden con una unidad de contexto, ya sea, una frase, un p\u00b4 arrafo, etc. Cada celda de la matriz contiene el n\u00b4 umero de veces que una palabra determinada en la la aparece en el contexto proporcionado por la columna. La Tabla 4.7muestra esta representaci\u00b4 on. C1 C2 C3 C4 C5 W1 1 0 0 2 0 W2 0 4 1 0 0 W3 2 0 0 1 0 Tabla 4.7. Matriz Mw\u00a3c Donde: W:palabras C: contextos 4. Recursos 97 fij: frecuencia de co-ocurrencia LSI y LSA se diferencian principalmente en su denici\u00b4 on de contexto utilizado. Para LSI es un documento, mientras que para LSA es m\u00b4 as flexible, aunque a menudo hace referencia a p\u00b4 arrafos. Si la unidad de contexto de LSA es un documento, entonces LSA y LSI son esencialmente la misma t\u00b4 ecnica. Una vez establecida la frecuencia de co-ocurrencia de cada t\u00b4 ermino con respecto a cada contexto, cada la se interpreta co- mo un vector contextual de ddimensiones. Donde drepresenta el n\u00b4 umero de contextos utilizados. Tras insertar en las celdas correspondientes de la matriz el n\u00b4 umero de ocurrencias de cada palabra con respecto al contexto de su columna correspondiente, la matriz M\u00a3Nobtenida se des- compone utilizando la t\u00b4 ecnica de Singular Value Decomposition (SVD). Mediante SVD se reducen las dimensiones de la matriz inicial para que contextos similares sean redistribuidos unos den- tro de otros. SVD se basa en el hecho de que cualquier matriz rectangular puede ser descompuesta en el producto de otras tres matrices. Esta descomposici\u00b4 on puede obtenerse sin p\u00b4 erdida de in- formaci\u00b4 on si no se utilizan m\u00b4 as factores que el m\u00b4 nimo de Ny M. En estos casos, la matriz original puede ser perfectamente reconstruida. Sin embargo, como ocurre normalmente, LSA reduce una ma- triz de miles de dimensiones a unas pocas centenas. De esta forma, es pr\u00b4 acticamente imposible reconstruir la matriz original. A pesar de que esto pueda sonar a inapropiado, es de hecho esta reduc- ci\u00b4 on el objetivo de LSA. El efecto de esta acci\u00b4 on se traduce en que la p\u00b4 erdida de informaci\u00b4 on producida es debido al ruido. De esta forma, la reducci\u00b4 on de la dimensi\u00b4 on produce que las relaciones de similitud entre palabras y contextos sean mucho m\u00b4 as aparentes. La Figura 4.7representa de forma esquem\u00b4 atica lo que signica la reducci\u00b4 on de dimensiones llevada a cabo por medio de SVD. En la gura de la izquierda, cada t\u00b4 ermino est\u00b4 a representado por cuatro dimensiones, tantas como documentosp\u00b4 arrafos existen en el corpus fd1,d2,d3,d4 g. En la gura de la derecha, los t\u00b4 erminos pasan a estar representados por dos dimensiones abstractas pero de una mayor utilidad funcional. A cada t\u00b4 ermino se le inere una 98 4.5 An\u00b4 alisis de la Sem\u00b4 antica Latente (LSA) probabilidad de estar representado en un concepto. En este caso, se observa c\u00b4 omo al t\u00b4 ermino t2 se le inere cierta probabilidad de salir en el p\u00b4 arrafo d2 aunque como muestra la gura de la izquierda, esto no se produzca (se hace patente la caracter\u00b4 stica de relacionar conceptualmente, t\u00b4 erminos con documentos aunque no aparezcan en ellos). t1 t1 t3 d1 d2 d3 d4 d3 d4 t\u00e9rminosdocumentos t\u00e9rminos conceptos documentos T x D T x C C x C D x C Figura 4.7. Reducci\u00b4 on dimensional de la matriz en LSA En otras palabras, lo que se persigue al reducir las dimensio- nes de la matriz original, no es m\u00b4 as que eliminar el ruido pre- sente en las relaciones entre t\u00b4 erminos y contextos. Esto es debido a que podemos expresar con distintos t\u00b4 erminos el mismo con- cepto. Adem\u00b4 as, LSA no tiene en cuenta la estructura ling\u00a8 u\u00b4 stica de los contextos, simplemente las frecuencias de aparici\u00b4 on y co- ocurrencias de t\u00b4 erminos. Una analog\u00b4 a muy gr\u00b4 aca de c\u00b4 funciona la t\u00b4 ecnica, la pro- porciona un art\u00b4 culo de ( Yu et al. (2004 )): \"Imaginemos que tenemos un acuario de peces tropicales y tan orgullosos estamos de tenerlo que deseamos fotograarlo para una revista especializada. Para capturar la mejor foto, elegiremos el mejor \u00b4 angulo que garantice la mejor toma. Adem\u00b4 as, nos asegura- remos de que en ella salgan visibles el m\u00b4 aximo n\u00b4 umero de peces sin ser solapados por otros peces. Tampoco queremos que los peces salgan todos juntos en una masa sino que los queremos mostrar 4. Recursos 99 bien distribuidos en el agua. Como nuestro acuario es transparen- te, tomaremos diversas fotos desde diferentes puntos de vista y elegiremos la que mejor se adapte a lo antes descrito\". En denitiva, lo que hace la t\u00b4 ecnica es mediante la recursivi- dad (hacer varias fotograf\u00b4 as), buscar las dimensiones que mejor permitan una diferenciaci\u00b4 on de las \"bolsas sem\u00b4 anticas\" (peces) en las que los t\u00b4 erminos participan. Una vez hecho esto, elegiremos s\u00b4 olo las dimensiones que mejor caractericen estas bolsas. En la Figura 4.8se muestra una representaci\u00b4 on de la matriz original desglosada en dos matrices de vectores singulares y una matriz diagonal de valores singulares. A partir de este desglo- se se reducir\u00b4 an las dimensiones seleccionando solamente aquellas que mejor representen las diferentes regiones sem\u00b4 anticas. Estudios realizados han demostrado que la reducci\u00b4 on a 300 dimensiones proporciona los mejores resultados Turney (2004 ). D x C Conceptos C x C (diagonal) = T\u00e9rminos * * T x C T x D c2 Reducci\u00f3n dimensional Documento A Documento A c1 T\u00e9rminos Documentos Conceptos Documentos t1 t2 t3 Figura 4.8. Descomposici\u00b4 on de la matriz en LSA En denitiva, la t\u00b4 ecnica SVD devolver\u00b4 a un desglose de las re- laciones que se mantienen en la matriz original. De esta forma, 100 4.5 An\u00b4 alisis de la Sem\u00b4 antica Latente (LSA) podremos reconstruir la matriz inicial pero tomando en conside- raci\u00b4 on s\u00b4 olo las dimensiones que hacen m\u00b4 as fuerte la relaci\u00b4 on entre t\u00b4 erminos y documentos. Esto se har\u00b4 a tomando los valores singu- lares m\u00b4 as altos y volviendo a multiplicar las tres matrices pero reduciendo sus dimensiones a las mismas que valores singulares hayamos considerado. En (Landauer y Dumais (1997 )) se evalu\u00b4 o la habilidad de LSA para reconocer sin\u00b4 onimos. En este estudio, se utiliz\u00b4 o el Test of English as a Foreign Language (TOEFL) como base para la eva- luaci\u00b4 on del funcionamiento de LSA. El TOEFL es una prueba que consiste en dada una palabra clave, seleccionar de entre cua- tro opciones (palabras) distintas, cu\u00b4 al es m\u00b4 as similar a la palabra clave. Por ejemplo, si \"distant\" es la palabra clave en cuesti\u00b4 on y las cuatro opciones a seleccionar la opci\u00b4 on 2 como la m\u00b4 as similar en cuanto a signicado. Para poder aplicar LSA sobre el tipo de informaci\u00b4 on proporcio- nada por TOEFL y construir la matriz contextual, se utiliz\u00b4 o como corpus la versi\u00b4 on electr\u00b4 onica de la Grolier's Academic American Encyclopedia. En esta enciclopedia hab\u00b4 an alrededor de 30473 art\u00b4 culos, para cada uno de los cuales se extrajeron los primeros 2000 caracteres, con una media de 151 palabras por art\u00b4 culo. Una vez obtenida esta informaci\u00b4 on, los datos se introdujeron en la ma- triz contextual, teniendo \u00b4 esta una columna por art\u00b4 culo (30473 columnas) y alrededor de 60768 las, donde cada la se corres- pond\u00b4 a con una palabra que aparec\u00b4 a en al menos dos art\u00b4 culos (columnas) de la matriz. Inicialmente, las celdas de la matriz con- ten\u00b4 an la frecuencia en que una palabra aparec\u00b4 a en cada art\u00b4 cu- lo. Posteriormente, estos datos se transformaron seg\u00b4 un la f\u00b4 ormu- la ln(1+ frec)=(entrop\u00b4 a de la palabra sobre todos los contextos). La matriz resultante nal fue reducida hasta 300 dimensiones me- diante la t\u00b4 ecnica de SVD, correspondi\u00b4 endose estas dimensiones con los valores singulares m\u00b4 as elevados obtenidos, dando como resultado vectores con 300 valores reales para representar cada palabra. La similitud entre dos palabras se midi\u00b4 o utilizando el coseno entre vectores, de forma que cuanto m\u00b4 as similares fueran dos palabras mayor ser\u00b4 a el coseno obtenido entre ambas. Por lo 4. Recursos 101 tanto, para seleccionar la respuesta correcta de cada pregunta se calcul\u00b4 o el coseno entre la palabra y cada una de las cuatro al- ternativas. Como resultado, la aplicaci\u00b4 on de LSA sobre el test de TOEFL supuso un acierto del 65 %, puntuaci\u00b4 on similar a los resul- tados obtenidos por personas de habla no inglesa que realizaron el test. Esta misma prueba se realiz\u00b4 o sobre la matriz original de 30000\u00a360000, en este caso, la precisi\u00b4 on baj\u00b4 o a un 37 %, sugirien- do estos resultados que la descomposici\u00b4 on de la matriz eliminaba el ruido presente en la matriz original, proporcionando una mejor representaci\u00b4 on de las similitudes entre palabras. El test TOEFL fue utilizado de nuevo por ( Turney (2001 )) pa- ra evaluar los resultados de un sistema que empleaba una t\u00b4 ecnica distinta a LSA. En este caso, el sistema empleado calculaba los valores de la Pointwise Mutual Information (PMI) entre la pala- bra dada y sus cuatro posibilidades, utilizando los resultados de la b\u00b4 usqueda en Alta Vista como base para establecer la frecuencia de aparici\u00b4 on de las palabras. La estrategia utilizada para calcular el grado de similitud entre la palabra clave y las cuatro opciones se muestra en la Tabla 4.8. En este ejemplo se trata de averiguar la palabra m\u00b4 as similar a \"levied\" de . Seg\u00b4 con mayor similitud sem\u00b4 antica es \"imposed\" . Este mismo ejemplo aplicando la t\u00b4 ecnica de LSA obtiene el mismo resultado, tal y como muestra la Tabla 4.9. Es interesante destacar que a pesar de utilizar diferentes fuen- tes de informaci\u00b4 on ambas aproximaciones obtienen el mismo re- sultado. La comparativa sobre las 80 preguntas del TOEFL para cada aproximaci\u00b4 on se muestra en la Tabla 4.10. Como demuestran los resultados, PMI mejora en un 10 % los resultados de LSA. Pero la interpretaci\u00b4 on de estos resultados es complicada debido a que ambas t\u00b4 ecnicas utilizan fuentes de in- formaci\u00b4 on muy distintas y PMI utiliza un contexto mucho m\u00b4 as peque no que LSA. Estos ejemplos, sirven para mostrar dos aproximaciones basa- das en la utilizaci\u00b4 on de grandes cantidades de informaci\u00b4 on para establecer relaciones sem\u00b4 anticas obteniendo resultados muy posi- 102 51.5/80 64.4 % Persona de habla no inglesa 51.6/80 64.5 % Tabla 4.10. Comparativa LSA y PMI sobre tivos. En el siguiente cap\u00b4 tulo estas t\u00b4 ecnicas han sido adaptadas y desambiguaci\u00b4 los m\u00b4 etodos desarrollados a par- tir de los estudios tesis: se clasican dentro del grupo de m\u00b4 etodos basados en conocimiento, ya que, la informaci\u00b4 on necesaria para su correcto funcionamiento procede de corpus y recursos l\u00b4 exicos y no requie- ren ning\u00b4 un proceso de aprendizaje. Adem\u00b4 as de la descripci\u00b4 on de cada m\u00b4 etodo tambi\u00b4 en se presentan las diferentes aproximaciones realizadas, as\u00b4 como la utilizaci\u00b4 on de los diferentes recursos des- critos en el cap\u00b4 tulo DRelevant El m\u00b4 etodo desarrollado en esta secci\u00b4 on se clasica dentro de los m\u00b4 etodos no supervisados basados en conocimiento. Dentro de esta categor\u00b4 a encontramos aquellos m\u00b4 etodos que necesitan de infor- maci\u00b4 on externa procedente de diversas fuentes, ya sea de diccio- narios electr\u00b4 onicos, corpus generales, corpus especializados, etc. A partir de esta informaci\u00b4 on los m\u00b4 etodos no supervisados pueden obtener los datos necesarios para construir sus propias fuentes de conocimiento y relacionar de esta forma palabras a partir de sus contextos y sus apariciones junto a otras palabras sem\u00b4 anticamente relacionadas. 104 5.1 WSD basado en conocimiento: DRelevant La idea principal en la que se basa la implementaci\u00b4 on del m\u00b4 eto- do descrito a continuaci\u00b4 on, es en la utilizaci\u00b4 on de una serie de categor\u00b4 as sem\u00b4 anticas asociadas a los sentidos de las palabras co- mo una aproximaci\u00b4 on para determinar los sentidos de \u00b4 estas. Es decir, a partir de WordNet Domains que est\u00b4 a etiquetado con una serie de categor\u00b4 as o dominios, se extraen de forma estad\u00b4 stica los contextos en los que aparecen las distintas palabras a desambi- guar, y se determina a qu\u00b4 e categor\u00b4 a sem\u00b4 antica pertenecen esos contextos. La base te\u00b4 orica en la que se basa este sistema parte de tres premisas: Primera: Las palabras que pertenecen a diferentes clases con- ceptuales o dominios, como ANIMAL o M \u00b4AQUINA, tienden a aparecer en contextos bien diferenciados. Segunda: Los diferentes sentidos de una palabra tienden a per- tenecer a clases conceptuales diferentes. Tercera: Si se puede construir un discriminador de contextos para diferentes clases conceptuales entonces podremos distin- guir los sentidos de las palabras que pertenecen a esas clases. En la Tabla 5.1podemos apreciar la diferencia existente en- tre los contextos donde aparece la palabra \"crane\" con el sentido asociado de \"gr\u00b4 ua\" y \"crane\" con el sentido de \"grulla\". Ambas acepciones de la misma palabra pertenecen a categor\u00b4 as sem\u00b4 anti- cas distintas. La primera acepci\u00b4 on pertenece a la categor\u00b4 a In- dustry y la segunda a \"cranes\", and closely related to \"cranes\" and rails. They ran \u2014 low At least ve \"crane\" species are in danger. Zoology Tabla 5.1. Contextos asociados a diferentes sentidos de la palabra \"crane\" 5. M\u00b4 etodos 105 En este caso, a partir del contexto que rodea a la palabra \"cra- ne\"podemos seleccionar su sentido correspondiente, utilizando para ello la informaci\u00b4 on procedente de las palabras que la rodean. La utilizaci\u00b4 on de las palabras del contexto como fuente de infor- maci\u00b4 on para establecer el sentido de una palabra y las relaciones sem\u00b4 anticas entre las palabras del contexto, son la base de nuestro m\u00b4 etodo de desambiguaci\u00b4 on autom\u00b4 atica. 5.1.1 Obtenci\u00b4 on y categorizaci\u00b4 on de contextos El objetivo principal en este punto es poder establecer relacio- nes entre palabras a partir de los contextos en los cuales aparecen. Si esos contextos se engloban dentro de una categor\u00b4 a determina- da, podemos establecer, analizando la frecuencia de aparici\u00b4 on de las palabras, si \u00b4 estas pertenecen o no a esa categor\u00b4 a. Para ello, es necesario recopilar cierta informaci\u00b4 on acerca de su frecuencia de aparici\u00b4 on junto a otras palabras y las categor\u00b4 as en las que suelen aparecer. La estrategia seguida para recopilar informaci\u00b4 on relativa a la frecuencia de aparici\u00b4 on consta de tres pasos: 1.Extraer los contextos representativos para cada categor\u00b4 a. 2.Identicar las palabras m\u00b4 as destacadas entre los contextos ob- tenidos y establecer un determinado peso para cada palabra. 3.Utilizar los pesos resultantes para poder determinar la cate- gor\u00b4 a apropiada de una palabra polis\u00b4 emica (con m\u00b4 as de un sentido) dentro de un nuevo contexto. La existencia de palabras polis\u00b4 emicas supone un problema pa- ra el establecimiento de los contextos apropiados para cada cate- gor\u00b4 a. Podemos encontrar por ejemplo, instancias de una misma palabra que corresponden a sentidos diferentes. En este caso, po- demos adquirir informaci\u00b4 on err\u00b4 onea y que produce ruido debido a estas palabras. Normalmente, se puede amortiguar el efecto de es- tos errores de clasicaci\u00b4 on porque suelen distribuirse entre varias categor\u00b4 as. Sin embargo, si una misma palabra atiende a varios sentidos y \u00b4 estos se distribuyen dentro de la misma categor\u00b4 a, dar\u00b4 a lugar a una clasicaci\u00b4 on err\u00b4 onea. Adem\u00b4 as, puede ser que uno de 106 5.1 WSD basado en conocimiento: DRelevant los sentidos de la palabra polis\u00b4 emica aparezca con mayor frecuen- cia en los contextos extra\u00b4 dos, siendo este sentido incorrecto a la categor\u00b4 a que estamos contextualizando. Para minimizar los efectos que producen la aparici\u00b4 on de pa- labras muy frecuentes dentro de cada categor\u00b4 a, se realiza una ponderaci\u00b4 on de los contextos. Es decir, si una palabra aparece muy frecuentemente en una categor\u00b4 a no por ello es signicati- va de esa categor\u00b4 a, ya que, esa misma palabra puede aparecer muy frecuentemente junto a otras categor\u00b4 as. Para evitar este tipo de situaciones se utiliza la siguiente ponderaci\u00b4 on: si una palabra aparece k-veces en el corpus, entonces las palabras que la rodean contribuyen 1 =ka la suma de la frecuencia. 5.1.2 Extracci\u00b4 on de contextos Para poder realizar estimaciones estad\u00b4 sticas de co-ocurrencia de palabras en diferentes contextos, es necesario disponer de un corpus previamente categorizado. El problema que encontramos actualmente es que no existen corpus de \u00b4 ambito general lo su- cientemente extensos para satisfacer la demanda de relaciones entre palabras y categor\u00b4 as. Adem\u00b4 as, la mayor\u00b4 a de corpus exis- tentes se centran en dominios de \u00b4 ambito de aplicaci\u00b4 on espec\u00b4 cos. Debido a estas dicultades, es necesaria la utilizaci\u00b4 on de alg\u00b4 un otro recurso que recoja de forma gen\u00b4 erica las distintas relaciones entre palabras y su pertenencia a diferentes categor\u00b4 as sem\u00b4 anticas. Observando las prestaciones de distintos recursos electr\u00b4 onicos como WordNet Domains o SUMO, donde a partir de las denicio- nes de un diccionario electr\u00b4 onico se a naden etiquetas sem\u00b4 anticas a las palabras, se ha optado por utilizar estos recursos como cor- pus para la categorizaci\u00b4 on de contextos. La estructura de estos recursos ya fue presentada en el cap\u00b4 tulo anterior y a modo de recordatorio se muestra un peque no extracto de su conguraci\u00b4 on en las siguientes guras. La Figura 5.1muestra c\u00b4 omo con WordNet Domains Economy ,Industry yBotany , diferentes categor\u00b4 as sint\u00b4 acticas, como determinar los diferentes sentidos de una palabra polis\u00b4 emica. En la Figura 5.2se muestra c\u00b4 omo en la ontolog\u00b4 a SUMO tam- bi\u00b4 en se pueden agrupar palabras de distintas categor\u00b4 as sint\u00b4 acticas Sal- vo que en no se encuentran verbos relacionados con CurrencyMeasure , esto es debido a que esta ontolog\u00b4 a pre- senta un grado de granularidad m\u00b4 as no que el caso de WordNet Domains y para verbos que en WordNet domains compart\u00b4 an la 108 5.1 WSD basado en conocimiento: DRelevant etiqueta Economy ahora sus diferencias en cuanto a anotaci\u00b4 on, mediante ambos recursos se puede extraer informaci\u00b4 on relacionada con los contextos de cada categor\u00b4 a, utilizando para ello las glosas de WordNet (ya que ambos se basan en su base de datos l\u00b4 exica). Como ya se coment\u00b4 o en el cap\u00b4 tulo anterior, en WordNet, cada palabra tiene asociada una denici\u00b4 on (glosa) que puede adem\u00b4 as incluir algunos ejemplos de uso de la palabra que se est\u00b4 a denien- do. Por ejemplo, el caso de la palabra \"bank\" con la categor\u00b4 a Economy su glosa es: held some gambling games; \"he tried to break the bank at Monte Carlo\" \" . En este caso, adem\u00b4 as de dar una denici\u00b4 on para uno de los sentidos de \"bank\" tambi\u00b4 en se proporciona un ejemplo de una frase donde se utiliza \"bank\" con ese sentido. Para poder determinar los contextos de cada categor\u00b4 a se han agrupado todas las glosas que tienen asociada una misma eti- queta sem\u00b4 antica. De esta forma, se ha obtenido una clasicaci\u00b4 on por categor\u00b4 as de todas las glosas de WordNet, tanto usando las categor\u00b4 as de WordNet Domains como usando las categor\u00b4 as de SUMO. 5.1.3 Obtenci\u00b4 on de las palabras signicativas Una vez determinados los contextos asociados a cada categor\u00b4 a, es necesario determinar de entre todas las palabras que aparecen en las glosas, cu\u00b4 ales son las m\u00b4 as signicativas en relaci\u00b4 on a esa categor\u00b4 a. Cuando hablamos de palabras signicativas nos referimos a aquellas palabras que aparecen m\u00b4 as a menudo en el contexto de una categor\u00b4 a que en cualquier otra parte del corpus. En este caso, se podr\u00b4 a determinar la importancia de una palabra con respecto a una categor\u00b4 a atendiendo a la F\u00b4 ormula up; to two with this person\" 00490924\u2014allow\u2014 give or assign a share of money or time to a particular person or cause; \"I will earmark this money... \"The 01544337\u2014redeem\u2014convert cash; of commercial papers o, as of loans or promissory notes 01544440\u2014pay o\u2014pay o, as of loans or promissory 01544554\u2014ransom\u2014exchange or buy back for money; under threat or buy back a broker ... Figura 5.4. Clasicaci\u00b4 on contextual a partir de SUMO La probabilidad de aparici\u00b4 on de una palabra sobre una cate- gor\u00b4 a P(palabra jcategoria ) normalmente se suele estimar contan- do el n\u00b4 umero de ocurrencias de la palabra en los distintos con- textos de la categor\u00b4 a (contexto local). Pero esta medida no da resultados reales cuando por ejemplo, una palabra es poco fre- cuente. Por lo tanto, se puede suavizar el efecto a nadiendo la frecuencia global de aparici\u00b4 on de la palabra P(palabra ) (contexto global) ( Yarowsky (1992 )). se evita obtener esti- maciones err\u00b4 oneas a partir del contexto local, ya que, los errores que puedan aparecer dentro del contexto global son irrelevantes. 110 5.1 WSD basado en conocimiento: DRelevant En la Tabla 5.2se muestra el resultado obtenido tras analizar la frecuencia de aparici\u00b4 on de la palabra \"plant' ' como nombre en WordNet Domains. 5.1.4 Similitud sem\u00b4 antica Una vez estimada la importancia de cada palabra sobre cada categor\u00b4 a del corpus, es necesario establecer una medida que de- termine el grado de similitud sem\u00b4 antica entre cualquier par de palabras, es decir, si existe alg\u00b4 un tipo de relaci\u00b4 on que las vincule sem\u00b4 anticamente. La similitud entre t\u00b4 erminos de co-ocurrencia estad\u00b4 stica. Se debe matizar que la co-ocurrencia se puede especicar de diferentes formas. De entre todas las for- mas posibles tenemos dos tipos principales: la co-ocurrencia me- dida a partir de las relaciones entre palabras dentro de un rango espec\u00b4 co (ventana) y la co-ocurrencia de palabras como un pa- tr\u00b4 on particular de relaciones gramaticales tales como sujeto-verbo y verbo-objeto. Podemos referirnos a los dos tipos de co-ocurrencia anteriores como medidas de co-ocurrencia de primer orden. Esta denomina- ci\u00b4 on nos servir\u00b4 a para distinguirlas de aquellas medidas a las que denominaremos co-ocurrencia de segundo orden (o indirecta). Es- te \u00b4 ultimo tipo representa una co-ocurrencia de pares de palabras en expresiones comunes. La hip\u00b4 otesis asociada a la co-ocurrencia de primer orden es que las palabras relacionadas sem\u00b4 anticamente tienden a aparecer en contextos de \u00b4 ambito restringido. Mientras que la idea subyacente para la co-ocurrencia de segundo orden es que las palabras sem\u00b4 anticamente similares tienen tendencia a compartir contextos similares. Por ejemplo, \"cerveza\" y \"vino\" se consideran palabras similares porque est\u00b4 an relacionadas sem\u00b4 anti- camente con el verbo \"beber\", ya que, frecuentemente aparecen como su objeto directo y por tanto, comparten un contexto simi- lar. La co-ocurrencia de un par de palabras (o expresiones) pue- de medirse de muchas formas. La medida m\u00b4 as simple es la \"ba- re co-occurrence frequency\" medidas de co-ocurrencia etodos 111 Dominio Frecuencia 0,188509874 body care industry 19 0,004873044 1 0,000256476 2 0,000512952 theatre 1 0,000256476 time period 2 0,000512952 town 0,000512952 zoology 112 5.1 WSD basado en conocimiento: DRelevant sosticadas para pares de palabras est\u00b4 an basadas en sus frecuen- cias de co-ocurrencia y frecuencias independientes. Una medida muy conocida de co-ocurrencia que fue inicialmente utilizada por (Church y Hanks (1990 )) es la llamada Informaci\u00b4 on Mutua (IM) denida seg\u00b4 un la ecuaci\u00b4 on IM(x; de la IM P(x; y) yfreq(x; y) son la probabilidad de co-ocurrencia y la frecuencia de dos eventos xey,P(x) y freq(x) son la probabilidad independiente y frecuencia de x, yN es el n\u00b4 umero total de eventos. Dentro de la lexicograf\u00b4 a computacional podemos utilizar el valor proporcionado por la IM para establecer si existe alg\u00b4 un tipo de relaci\u00b4 on entre diferentes palabras. De forma que: SiIM(w1; w2)\u00c00.Signica que la palabra w1, aparece junto a la palabra w2m\u00b4 as a menudo de lo que a simple vista podr\u00b4 a parecer. SiIM(w1; w2)\u00bf0.Signica que la palabra w1, aparece junto a la palabra w2menos frecuentemente de lo que cabr\u00b4 a pensar. SiIM(w1; w2)\u00bc0.Indica que no existe ninguna evidencia que relacione la palabra w1con la palabra w2. Por ejemplo, en la tabla 5.3se muestra la Informaci\u00b4 on Mu- tua de la palabra \"drink\" junto con sus posibles objetos directos extra\u00b4 dos de una serie de documentos: Podemos observar que existen palabras que aparecen con mu- cha frecuencia junto a \"drink\" como son: \"water\" ,\"beer\" ,\"alco- hol\"... Pero sin embargo, el valor dado por la IM es menor que el obtenido para otras palabras cuya frecuencia de aparici\u00b4 on es menor como: \"martinis\" ,\"cup of water\" ,\"champagne\" ... Esta peculiaridad es debida a que la IM mide las relaciones sem\u00b4 anti- cas entre palabras no s\u00b4 olo a partir de su frecuencia de aparici\u00b4 on local, sino tambi\u00b4 en de su frecuencia de aparici\u00b4 on global. Debido a 5. M\u00b4 etodos 113 Objeto directo IM Frecuencia martinis 12;6 3 cup of water 11;6 3 champagne 10;9 3 beverage 10;8 8 cup of tea 10;6 2 cognac 10;6 2 beer 9;9 29 cup coee 4 water 7;2 43 quantity 7;1 4 Tabla 5.3. IM de la palabra \"drink\" con sus posibles objetos directos ello, las palabras que aparecen casi exclusivamente junto a otras tender\u00b4 an a tener una relaci\u00b4 on sem\u00b4 antica m\u00b4 as fuerte que otras pa- labras demasiado frecuentes en el corpus, lo que indica que tienen un uso gen\u00b4 erico y por tanto, una relaci\u00b4 on sem\u00b4 antica m\u00b4 as d\u00b4 ebil. La medida de la Informaci\u00b4 on Mutua ha sido utilizada pa- ra medir la similitud entre palabras ( Dagan et al. (1993 ), (Lin (1998a de colocaciones ( Church et al. (1991 )). En este trabajo, se utiliza la f\u00b4 ormula de la Informaci\u00b4 on Mutua en una forma m\u00b4 as relajada Yarowsky (1992 ), es decir, nos intere- san aquellas palabras que aparecen m\u00b4 as a menudo en el contexto de un dominio, con respecto a otros (palabras signicativas con respecto a un dominio). 114 5.1 WSD basado en conocimiento: DRelevant P(w) (5.3) En la Tabla 5.4se muestran los resultados obtenidos tras el c\u00b4 alculo de la Informaci\u00b4 on Mutua de la palabra \"plant\" en Word- Net Domains. 5.1.4.1 Perfeccionamiento de la Informaci\u00b4 on Mutua. El valor obtenido por la f\u00b4 ormula de la Informaci\u00b4 on Mutua 5.3, mide la importancia de las palabras frente a un dominio de WND. Pero este valor no refleja exactamente la relevancia que tiene una palabra con respecto a un determinado dominio. Es por tanto necesario establecer la frecuencia local de una palabra con respec- to a cada dominio para poder establecer de forma espec\u00b4 ca la relevancia de esa palabra. Esta nueva forma de establecer la relevancia de una palabra w sobre un dominio Dse mide a trav\u00b4 es de la f\u00b4 ormula del Ratio de Asociaci\u00b4 (1994 )). La f\u00b4 ormula del Ratio de Asociaci\u00b4 on se muestra en 5.4. RA(w; D) =Pr(wjD) log 2Pr(wjD) Pr(w)(5.4) La Tabla 5.5, muestra el resultado tras la uni\u00b4 on de los dos conceptos: importancia (IM) y relevancia (RA) de una palabra frente a un dominio. Los resultados demuestran que existen casos para los que la IM asigna mayor peso y que ahora mediante el RA quedan relegados a posiciones inferiores. V\u00b4 eanse por ejemplo, los resultados referidos al dominio Religion en ambas Tablas 5.4y 5.5: Religion \u00a15;904181(IM) Religion \u00a10;000472(RA). Queda patente por tanto, la necesidad de identicar correcta- mente la relevancia de una palabra con respecto a un dominio, para as\u00b4 evitar una ponderaci\u00b4 on err\u00b4 onea usando la medida IM, que no tiene en cuenta la frecuencia local asociada ( P(wjD)). 5. M\u00b4 etodos 115 RA para WND 116 5.1 WSD basado en conocimiento: DRelevant 5.1.5 Vectores de co-ocurrencia Una vez establecida la medida de co-ocurrencia para determi- nar la similitud entre palabras y dominios ( RA(wjD)), es nece- sario hallar una forma de obtener una medida de similitud entre pares de palabras, contextos, etc. Para este tipo de tarea se utili- zan los vectores de co-ocurrencia. Veamos con un ejemplo sencillo la forma de obtener vectores de co-ocurrencia para una palabra determinada. Supongamos que encontramos el texto de la Figura 5.5. A bottle of tecuino is on the table. Everybody likes tecuino. Tecuino makes you drunk. We make tecuino out of corn. Its bottle can be on the table. Liked by everyone. Makes you drunk. Made out of corn. TEXTO CONTEXTO Figura 5.5. Determinaci\u00b4 on del signicado de \"tecuino\" Dada la palabra \"tecuino\" de la cual no sabemos su signicado, se puede inferir su sentido de acuerdo a las palabras que la rodean: \"You shall know a word by the company it keeps!\" ( Firth (1957 )). En este caso, a partir del contexto podemos deducir que el \"te- cuino\" podr\u00b4 a ser una bebida alcoh\u00b4 olica hecha de ma\u00b4 z. Esta idea intuitiva puede capturarse utilizando un vector cuyas componen- tes podr\u00b4 an ser las palabras que rodean a la palabra \"tecuino\" , pa- ra posteriormente compararlo con vectores de otras palabras como por ejemplo \"beer\", \"wine\" o \"tequila\". De esta forma, se podr\u00b4 a determinar que cualquier tipo de bebida alcoh\u00b4 olica comparte mu- chas de las componentes de la palabra en cuesti\u00b4 on, concluyendo por tanto: \"tecuino\" \u00b4bebida alcoh\u00b4 olica. A partir de esta idea intuitiva se puede representar cualquier palabra con un vector de caracter\u00b4 sticas (features). Estas ca- racter\u00b4 sticas pueden ser las palabras del contexto (usando una ventana de un tama no espec\u00b4 co), las categor\u00b4 as sint\u00b4 acticas, los 5. M\u00b4 etodos 117 objetos directos, etc. Por ejemplo, supongamos que tenemos fi caracter\u00b4 sticas binarias que indican si una palabra west\u00b4 a (1) o no (0) en un contexto XdeNpalabras. Podr\u00b4 amos repre- sentar mediante un vector cualquier palabra w, de forma que:\u00a1 !w=ff1; f2; f3; :::f Ng. Si la del contexto ser\u00b4 cualquier par de palabras ( w1; w2), cada una representada por su vector de caracter\u00b4 sticas (\u00a1 !w1;\u00a1 !w2), se podr\u00b4 a determinar su similitud mediante la utilizaci\u00b4 on de una medida que calcule la proximidad de los dos vectores de caracter\u00b4 sticas. En la Tabla 5.6se muestra de forma intuitiva los vectores de co-ocurrencia de cuatro palabras \"apricot\" \"pineapple\", \"digital\" e\"information\" . Estos ejemplos han sido extra\u00b4 dos utilizando un contexto de dos l\u00b4 neas del Brown Corpus. Partiendo de esta representaci\u00b4 on es evidente la necesidad de una medida que establezca un grado de similitud muy elevado entre \"apricot\" y\"pineapple\" y entre \"digital\" e\"information\" , y adem\u00b4 as devuelva un valor de similitud muy bajo entre los pares de palabras que no tienen nada en com\u00b4 un. arts boil data function large sugar summarized apricot 0 1 0 0 1 1 0 pineapple 0 1 0 0 1 1 0 digital 0 0 1 1 1 0 1 information 0 0 1 1 1 0 1 Tabla 5.6. Vectores de co-ocurrencia Brown Corpus Como conclusi\u00b4 on se extrae que para determinar el grado de similitud entre dos palabras es necesario: 1.Denir el tipo de caracter\u00b4 sticas utilizadas para vec- tores. 2.Denir contextual de extracci\u00b4 on de informaci\u00b4 on. 3.Determinar el valor que se le da a cada caracter\u00b4 stica del vector (binario, frecuencia, Informaci\u00b4 on Mutua...) 118 5.1 WSD basado en conocimiento: DRelevant 4.M\u00b4 etrica que establezca la entre dos vectores (coseno, distancia eucl\u00b4 dea...) 5.1.5.1 WND y SUMO como caracter\u00b4 sticas. En el ejemplo anterior se han utilizado como caracter\u00b4 sticas pa- ra construir el vector de co-ocurrencia, las palabras que aparecen en un contexto de tama no N. La aproximaci\u00b4 on que se propone en este trabajo es la utilizaci\u00b4 on de las categor\u00b4 as sem\u00b4 anticas de WND y SUMO como caracter\u00b4 sticas para construir los vectores de co-ocurrencia. De esta forma, se evita la creaci\u00b4 on de vectores con un elevado n\u00b4 umero de caracter\u00b4 sticas, muchas veces irrelevantes a la hora de establecer la similitud entre dos palabras. A continuaci\u00b4 on se muestra un ejemplo para WND: Dada la frase: \"There are a number of ways in which the chromosome struc- ture can change, which will detrimentally change the genotype and phenotype of the organism\" Los pasos a seguir para obtener el vector de caracter\u00b4 sticas son: Extracci\u00b4 on de palabras del contexto. Se extraen aquellas palabras con contenido sem\u00b4 antico, omitiendo las stop words (art\u00b4 culos, preposiciones, ...). resultado es Asignaci\u00b4 on de dominios relevantes. Para cada una de estas palabras se extraen sus dominios relevantes (calculados previa- mente con el Ratio de Asociaci\u00b4 on). Ponderaci\u00b4 on de dominios. Se establecen cu\u00b4 ales son los domi- nios m\u00b4 as relevantes del contexto. Para ello, se ponderan aquellos dominios que aparecen en mayor n\u00b4 umero de palabras tal y como se muestra en la F\u00b4 ormula 5.5. Peso Dom i=Dom wNX Dom wiRADom i (5.5) Los pesos de aquellos dominios que aparecen en distintas pala- bras se van agregando de forma que, nalmente se obtiene una 5. M\u00b4 etodos 119 lista de dominios no repetidos, de las palabras que intervienen en el contexto. La Figura 5.6muestra el vector de caracter\u00b4 sticas obtenido para el WND Una vez generado el vector de caracter\u00b4 sticas, es necesario me- dir la similitud entre diferentes vectores utilizando alguna m\u00b4 etrica espec\u00b4 ca de comparaci\u00b4 on de vectores. 5.1.6 etricas sobre vectores Gracias al vector de caracter\u00b4 sticas cuya obtenci\u00b4 on se ha co- mentado en la secci\u00b4 on anterior, es posible determinar el grado de similitud entre dos palabras o contextos. Para denir el grado de similitud entre dos palabras wyv, se necesita una m\u00b4 etrica que tenga en cuenta los vectores asociados a\u00a1 !wy\u00a1 !vy obtenga un valor de similitud entre ambos. Las m\u00b4 etricas m\u00b4 as simples utilizadas para medir la distancia (o similitud) entre vectores son la Manhattan y la distancia Eucl\u00b4 dea. En la Figura 5.7se muestra un gr\u00b4 aco intuitivo de ambas m\u00b4 etricas aplicadas sobre dos vectores bidimensionales. La distancia Manhattan tambi\u00b4 en conocida como la distancia de Levenshtein o norma L1 es: Manhattan (\u00a1 !x ;\u00a1 a2 a1 b1 ),(1),( Manhattan == baLba ),(2),(Euclidea =baLba b a Figura 5.7. Distancia Eucl\u00b4 dea y Manhattan La distancia Eucl\u00b4 de que estas dos m\u00b4 etricas proporcionan una medida de similitud muy intuitiva entre vectores, han sido muy poco uti- lizadas para medir similitud entre palabras. Esto es debido a que ambas m\u00b4 etricas son muy sensibles a valores extremos. En lugar de utilizar estas m\u00b4 etricas tan sencillas, la similitud entre palabras est\u00b4 a estrechamente relacionada con las m\u00b4 etricas utilizadas en Extracci\u00b4 on de Informaci\u00b4 on. Dado que los sistemas de extracci\u00b4 on de informaci\u00b4 on funcionan bastante bien a la hora de establecer la similitud entre palabras vamos a describir algunas de estas m\u00b4 etricas. Utilizando como ejemplo el vector de caracter\u00b4 sticas binarias mostrado en la Tabla 5.6, donde la similitud entre dos vectores era justamente el n\u00b4 umero de caracter\u00b4 sticas que ten\u00b4 an en com\u00b4 un, podemos asumir que tenemos un vector binario. De esta forma, se dene la m\u00b4 etrica de similitud utilizando el producto escalar, como sigue: 5. M\u00b4 etodos asume que los vectores son binarios, pe- ro ocurre como hemos visto en la secci\u00b4 on previa, que las carac- ter\u00b4 sticas pueden almacenar valores de asociaci\u00b4 on entre palabras no binarios. Para este caso gen\u00b4 erico el vector denido para (5.9) Ahora se puede aplicar la m\u00b4 etrica del producto escalar sobre vectores que contienen valores de asociaci\u00b4 on, en lugar de valores binarios. Pero el resultado proporcionado tiene un problema: favo- rece a los vectores m\u00b4 as largos. La un vector se dene como: j\u00a1 !vj=vuut NX i=1v2 i (5.10) Un vector puede tener una longitud mayor debido a que tiene m\u00b4 as valores distintos de 0, o porque cada dimensi\u00b4 on tiene un valor m\u00b4 as elevado. Cualquiera de estos casos puede incrementar el re- sultado del producto escalar. Por tanto, si consideramos el vector asociado a una palabra muy frecuente, tendr\u00b4 a un mayor n\u00b4 umero de valores distintos de 0 y tendr\u00b4 a valores mayores en cada dimen- si\u00b4 on (aunque se utilicen valores que controlen de alguna forma la frecuencia). Por tanto, el producto escalar favorece a las palabras m\u00b4 as frecuentes. Debido a este problema, es necesario modicar el producto es- calar de forma que se normalicen los vectores y no se le d\u00b4 e m\u00b4 as importancia a las palabras m\u00b4 as frecuentes. Este producto escalar normalizado es el coseno del \u00b4 angulo formado por los dos vecto- res. Esta medida ha sido utilizada frecuentemente en sistemas de Recuperaci\u00b4 on de Informaci\u00b4 on ( Frakes y Baeza-Yates (1992 y ha 122 5.1 WSD basado en conocimiento: DRelevant sido aplicada para calcular la similitud entre palabras a partir de sus relaciones gramaticales ( Ruge (1992 )). La de los vectores, la m\u00b4 etrica del co- seno no es sensible a valores extremos tal y como ocurr\u00b4 a con la Manhattan y la Eucl\u00b4 dea. El coseno abarca desde 1 para vectores muy pr\u00b4 oximos entre s\u00b4 hasta 0 para vectores ortogonales que no tienen ninguna caracter\u00b4 stica en com\u00b4 un y \u00a11 para vectores apun- tando en direcciones opuestas (en la pr\u00b4 actica los valores tienden a ser positivos). Adem\u00b4 as de la medida del coseno, existen otras medidas de similitud muy utilizadas en el campo de PLN. Entre las medidas m\u00b4 as representativas destacan: la medida de Kullback-Leibler (o entrop\u00b4 a relativa) ( Cover y Thomas (1991 )), la medida de Jensen- Shannon (o radio de informaci\u00b4 la si- militud entre dos distribuciones x=fxigey=fyigy ha sido utilizada en ( Dagan et al. (1994 )) para medir la simili- tud entre palabras. Esta medida no es sim\u00b4 etrica, de forma que, KL(\u00a1 !xjj\u00a1 !y)6=KL(\u00a1 !yjj\u00a1 !x). Los valores que obtiene se encuentran entre 0 e innito y \u00b4 unicamente adopta el valor de 0 cuando las dos distribuciones son exactamente iguales. 5. M\u00b4 5.13, ha sido utilizada para medir la similitud entre palabras en ( Dagan et al. (1997 ),Lee (1997 )). Esta medida es la media de la suma de los dos valores de divergencia de KL entre las distribuciones xey, tomando valores entre 0 y 2 log 2. Jaccard (\u00a1 dos dis- tribuciones de datos. Dados dos conjuntos xeyel resultado de esta medida es la cardinalidad de su intersecci\u00b4 on dividida por la cardinalidad de su uni\u00b4 on. Adem\u00b4 as de las mencionadas anteriormente existen otras pro- puestas de m\u00b4 etricas de similitud. Una comparaci\u00b4 on entre las di- ferentes m\u00b4 etricas de similitud la encontramos en et al. (1999 )) y ( Lee(1999 )). Por su simplicidad y adaptaci\u00b4 on a diferentes tama nos de los contextos, en este trabajo se ha optado por utilizar la m\u00b4 etrica del coseno para evaluar la similitud entre vectores de caracter\u00b4 sticas. 5.1.7 Determinaci\u00b4 on del sentido correcto El objetivo del m\u00b4 etodo DRelevant es determinar el sentido correcto de las palabras polis\u00b4 emicas que aparecen en un contexto determinado. Hasta ahora se han extra\u00b4 do los dominios relevantes a partir de WND y SUMO, se han denido los vectores de ca- racter\u00b4 sticas que van a modelar el espacio sem\u00b4 antico de palabras, frases, p\u00b4 arrafos, etc y por \u00b4 ultimo se ha establecido la m\u00b4 etrica de similitud entre vectores. El \u00b4 ultimo paso es la determinaci\u00b4 on del sentido correcto de cada palabra utilizando toda la informaci\u00b4 on obtenida a partir del contexto y de WND y SUMO. A continuaci\u00b4 on se va a explicar la mec\u00b4 anica del proceso me- diante un ejemplo aplicado 124 5.1 WSD basado en conocimiento: DRelevant 5.1.7.1 Ejemplo ilustrativo sobre WND. Supongamos que queremos desambiguar la palabra \"image\" del siguiente texto extra\u00b4 do del British National Corpus (BNC): \"A successful description of a self-portrait may not be dicult, but an illuminating interpretation may call on many references, especially other artists' pictures of themselves. What can be ced from a self-portrait is often controversial; a critic is especially likely to read into a self-portrait some opinion held about the ar- tist. When, as in the cases of Rembrandt and Van Gogh, there is a whole series of pictures to choose from, books can be written on the self- images of one artist alone. This theme is a useful one for assessing the quality of a critic's writing, since it tempts the rash into speculation, while an impoverished eye will miss rele- vant necessarily absent is the Christian subject of the Madonna and Child.\" El primer paso, es construir el vector de contexto que modela sem\u00b4 anticamente el contenido del p\u00b4 arrafo donde aparece la palabra ambigua. Se utiliza un POS-tagger para obtener los lemas de todas las palabras y extraer sus correspondientes dominios relevantes. El resultado es un vector de caracter\u00b4 sticas obtenido a partir de los dominios relevantes de todas las palabras del contexto. En la Figura 5.8se muestran los lemas obtenidos a partir del contexto. Y en la Figura 5.9se muestra el vector de contexto obtenido a partir de los Dominios Relevantes. El segundo paso, es obtener un segundo vector con el que es- tablecer el grado de similitud con el vector de contexto extra\u00b4 do anteriormente. Dado que se desea obtener el sentido correcto de la palabra \"image\" , es necesario disponer de vectores de carac- ter\u00b4 sticas que modelen cada uno de los posibles sentidos de esta palabra. Para ello, se utilizan las glosas de WordNet. Es decir, para cada uno de los sentidos de \"image\" se extrae su glosa y se construye un vector de caracter\u00b4 sticas, denominado en este caso vector de sentido. 5. M\u00b4 etodos 125 NOMBRES description self portrait interpretation reference artist picture opi- nion case Van rash psychology subject Madonna Child VERBOS be call deduce read hold choose write assess tempt miss ADJETIVOS successful whole useful impoverished relevant personal absent Christian Figura 5.8. Lemas 5.9. Vector de contexto En la Tabla 5.7se muestran los 7 sentidos para \"image\" con sus respectivas glosas. En la Figura 5.10se muestran los vectores de sentido para los 3 primeros sentidos de \"image\" . El tercer paso, una vez obtenidos los distintos vectores de senti- do, es medir el grado de similitud entre cada uno de estos vectores y el vector de contexto. Aquel vector de sentido cuyo coseno con el vector de contexto obtenga el mayor valor, ser\u00b4 a el elegido como el sentido correcto de la palabra \"image\" . En este ejemplo, el sentido correcto para \"image\" es el 2. Tal y como muestra la Figura 5.11, el resultado del coseno entre el vector de contexto y cada uno de los vectores de sentido demuestra que el sentido m\u00b4 as adecuado en este caso ser\u00b4 a el 2. 126 5.1 WSD basado en conocimiento: Synset public image is as fragile... 03118233 factotum image#3 a visual representation of an or person a... image#5 coin bears En la Figura 5.12se muestra gr\u00b4 acamente todo el proceso nece- sario para obtener el sentido de una palabra a partir del contexto que la rodea. Este proceso requiere el establecimiento en primer lugar de la cantidad de palabras que van a formar parte del con- texto (ventana de Npalabras, p\u00b4 arrafo, oraci\u00b4 on...) y a partir de ah\u00b4 comienza la tarea de desambiguaci\u00b4 VS's Contexto Dominios Relevantes POS Tagger WordNet Glosas Vector Contexto Sentido#1 W Vector Sentido#2 Vector Sentido#N Cos(S#1) Cos(S#2) Cos(S#N) W W W W W W W W W Figura 5.12. Sistema DRelevant 128 5.1 WSD basado en conocimiento: DRelevant 5.1.8 Extended WordNet y Dominios Relevantes En el proceso descrito anteriormente para la obtenci\u00b4 on de los Dominios Relevantes a partir de las glosas de WordNet Domains, la hip\u00b4 otesis fundamental era que las palabras de la glosa que de- nen un sentido de una palabra est\u00b4 an relacionadas sem\u00b4 anticamente, y por tanto, es muy probable que compartan el mismo dominio. Como resultado, usando la informaci\u00b4 on proporcionada por el do- minio asociado al sentido de la palabra, se etiquetaron las palabras de la glosa y se extrajeron los Dominios Relevantes para cada pa- labra de WordNet. Sin embargo, este proceso podr\u00b4 a ser mejorado si se tuvieran en cuenta los sentidos correctos de las palabras de las glosas, ya que, de esta forma la anotaci\u00b4 on ser\u00b4 a mucho m\u00b4 as precisa. Dada la gran cantidad de aplicaciones actuales que utilizan WordNet como fuente de informaci\u00b4 on: sistemas de WSD, RI, QA, etc, que requieren de informaci\u00b4 on l\u00b4 ogica y sem\u00b4 antica adicional (de la que WordNet carece), se ha planteado la mejora de este recurso mediante la incorporaci\u00b4 on de informaci\u00b4 on sint\u00b4 actica, l\u00b4 Harabagiu et al. (1999 ),Mihalcea y Moldovan (2001 )). Este nuevo recurso ha incorporado informaci\u00b4 on adicional a las glosas de WordNet, de forma que cada palabra de las glosas viene acompa nada de infor- maci\u00b4 on sint\u00b4 actica, lema, sentido, etc. Un ejemplo de esta nueva anotaci\u00b4 on se muestra en la Figura 5.13. Seg\u00b4 un muestra la Figura 5.13, hay tres fuentes de informaci\u00b4 on a nadidas a la glosa inicial: Informaci\u00b4 on sem\u00b4 antica. Comprendida entre las etiquetas <wsd> </wsd>. A cada palabra de la glosa se le asigna su correspondiente sentido, utilizando para ello un proceso semi- autom\u00b4 atico de desambiguaci\u00b4 on. Informaci\u00b4 on sint\u00b4 actica. Comprendida entre las etiquetas <parse > </parse >. Se extraen las categor\u00b4 as morfosint\u00b4 acticas de cada elemento que conforma la glosa. Informaci\u00b4 on l\u00b4 ogica. Comprendida entre las etiquetas <lft> </lft>. Se transforma cada glosa en su forma (NP (DT the) chief) executive) ) (PP nuestro caso, s\u00b4 olo vamos a utilizar la informaci\u00b4 on sem\u00b4 anti- ca comprendida entre las etiquetas <wsd> </wsd>, para poder realizar una anotaci\u00b4 on m\u00b4 as precisa de los dominios de las glosas de WordNet. As\u00b4 pues, utilizando los sentidos de las palabras de las glosas, se extraen sus dominios asociados. De este modo, el recur- so l\u00b4 exico Dominios Relevantes mejorar\u00b4 a la calidad de anotaci\u00b4 on de las palabras de WordNet. Un ejemplo pr\u00b4 actico que demuestra la diferencia de anotaci\u00b4 on de WordNet Domains frente a Extended WordNet, es el mostrado en la Figura 5.14. En este caso, se tiene la glosa asociada al sentido 3 de la palabra \"president\" , cuyos dominios asociados son Person yPolitics . En la parte de la izquierda se muestra la anotaci\u00b4 on de dominios 130 5.1 WSD basado en conocimiento: DRelevant Synset Dominios Palabra Glosa 09786238 person politics president the chief executive of a republic WordNet 09786238 | president person politics Figura 5.14. Extracci\u00b4 on de dominios con Extended WordNet mediante WordNet Domains, cuyo resultado es la asignaci\u00b4 on de los dominios Person yPolitics a todas las palabras con con- tenido sem\u00b4 antico de la glosa. En la parte derecha se muestra el resultado de anotaci\u00b4 on tras utilizar Extended WordNet. En este caso, al proporcionar el sentido correcto de las palabras de la glo- sa, se pueden extraer los dominos asociados a ellas, mejorando de esta forma la anotaci\u00b4 on. En la Figura 5.15se muestra un ejemplo comparativo de ano- taci\u00b4 on con respecto a la palabra \"president\" usando WordNet Domains y Extended WordNet. Tal y como muestra la Figura 5.15, los Dominios Relevantes para \"president\" dieren dependiendo de la fuente de informaci\u00b4 on utilizada. En ( V\u00b4 azquez et al. (2007 ))se compararon los resultados obtenidos por el m\u00b4 etodo de desambiguaci\u00b4 on DRelevant usando las dos alternativas. El an\u00b4 alisis posterior determin\u00b4 o que se obten\u00b4 an mejores resultados al utilizar los Dominios Relevantes enriqueci- dos con la informaci\u00b4 on de las glosas de Extended WordNet. La evaluaci\u00b4 on del m\u00b4 etodo DRelevant Relevantes ha sido empleado sobre otras 5. etodos 131 DR WND 5.15. Dominios Relevantes (DR) para \"president\" tareas de PLN como la resoluci\u00b4 on de la implicaci\u00b4 on textual. En el Cap\u00b4 tulo de Evaluaci\u00b4 on se muestran los resultados obtenidos. 5.2 WSD basado en conocimiento: DLSA En el cap\u00b4 tulo anterior se hac\u00b4 a a un modelo tacional denominado LSA (An\u00b4 alisis de la Sem\u00b4 antica Latente). La idea de utilizar este modelo computacional para tratar el proble- ma de la ambig\u00a8 uedad sem\u00b4 antica se debe a la capacidad que tiene LSA de adaptarse a cualquier idioma, contexto o circunstancia. Es decir, LSA es una t\u00b4 ecnica basada en modelos estoc\u00b4 asticos del signicado o modelos sem\u00b4 anticos del lenguaje, la cual, no da im- portancia a las categor\u00b4 as l\u00b4 exicas, orden de las palabras, conjuga- ciones verbales, etc. Aunque inicialmente LSA fue concebida como una t\u00b4 ecnica pa- ra Recuperaci\u00b4 on de Informaci\u00b4 on ( Deerwester et al. (1990 fue tarde en ( Landauer y Dumais (1997 )) cuando se propuso la utilizaci\u00b4 on de esta t\u00b4 ecnica para la adquisici\u00b4 on y representa- ci\u00b4 on del conocimiento. A partir de entonces LSA ha sido aplicada a diferentes \u00b4 areas: correcci\u00b4 on de textos en el \u00b4 ambito acad\u00b4 emico (Haley et al. (2005 )), cohesi\u00b4 on y coherencia de textos ( Graesser et al. (2004 )), complemento y Widdows (2003 )), categorizaci\u00b4 on de documentos ( Rosso et al. (2004 )), etc. 132 5.2 WSD basado en conocimiento: DLSA En cuanto a la tarea de WSD, LSA ya ha sido utilizada previa- mente, de forma que a partir de un algoritmo no supervisado se in- ducen las similitudes entre palabras, bas\u00b4 andose en co-ocurrencias entre t\u00b4 erminos y contextos. Tal y como se describi\u00b4 o en el cap\u00b4 tulo anterior, la dimensi\u00b4 on del espacio vectorial inicial de la matriz se reduce utilizando la descomposici\u00b4 on en valores singulares. Final- mente, mediante la utilizaci\u00b4 on de t\u00b4 ecnicas de clustering, se utze (1998 ),Widdows y Peters (2003 )). En nuestro caso de estudio, LSA se utiliza para extraer in- formaci\u00b4 on sem\u00b4 antica a partir de la informaci\u00b4 on contextual y la co-ocurrencia de palabras. Posteriormente, la informaci\u00b4 on propor- cionada por LSA es utilizada como fuente de conocimiento para el nuevo m\u00b4 etodo de desambiguaci\u00b4 datos l\u00b4 exica como fuente de conocimiento A medida que aumenta la cantidad de documentos que intervie- nen en la matriz original de LSA, tambi\u00b4 en aumenta la posibilidad de que un mismo t\u00b4 ermino aparezca en documentos distintos con el mismo signicado (palabras polis\u00b4 emicas). Esta circunstancia pro- duce como consecuencia la introducci\u00b4 on de ruido y confusi\u00b4 on en el espacio conceptual obtenido, ya que, cada documento se consi- dera independiente del resto. Una soluci\u00b4 on a este problema ser\u00b4 a la clasicaci\u00b4 on inicial de los documentos a partir de diferentes t\u00b4 opicos, para as\u00b4 mitigar los efectos de la distribuci\u00b4 on de palabras bajo el mismo sentido en diferentes documentos. Sin embargo, no existen actualmente sistemas lo sucientemente precisos como para realizar esta clasicaci\u00b4 on de forma autom\u00b4 atica, sin un costo computacional excesivo. Adem\u00b4 as del problema de la distribuci\u00b4 on de palabras polis\u00b4 emi- cas existe otro problema asociado a la utilizaci\u00b4 on de documentos como fuente de informaci\u00b4 on: el t\u00b4 opico tratado. Es decir, si para la obtenci\u00b4 on de datos se utilizan documentos relacionados, por ejem- plo, con medicina o biolog\u00b4 a, probablemente la palabra \"planta\" estar\u00b4 a relacionada con palabras como: \"perenne\", \"fotos\u00b4 ntesis\", \"polen\", etc. Quedando relegados el resto de sentidos de la pala- 5. M\u00b4 etodos 133 bra \"planta\" en favor del sentido asociado al t\u00b4 opico o registro de los documentos. Por ello, para paliar los efectos de la utilizaci\u00b4 on de documentos como fuente de informaci\u00b4 on, es necesario utilizar otro tipo de recurso que de alguna forma distribuya seg\u00b4 un crite- rios sem\u00b4 anticos las palabras polis\u00b4 emicas y sea independiente del dominio. Para solucionar los problemas derivados de la utilizaci\u00b4 on de documentos como fuente de informaci\u00b4 on, es necesario utilizar un recurso que agrupe conceptos relacionados sem\u00b4 anticamente bajo una serie de categor\u00b4 as gen\u00b4 ericas. Nuestra propuesta es la utiliza- de las categor\u00b4 as sem\u00b4 anticas de WND o SUMO, como fuente de conocimiento que agrupa palabras relacionadas sem\u00b4 anticamen- te y a partir de las cuales se puede construir una matriz concep- tual. De esta forma, se logra una matriz conceptual independiente del dominio, ya que, se construye sobre una base de datos l\u00b4 exica que utiliza los conceptos de forma gen\u00b4 erica, donde cada aparici\u00b4 on de una palabra bajo una categor\u00b4 a sem\u00b4 antica (dominio) implica la asociaci\u00b4 on de un determinado sentido. Por tanto, se evita por una parte la dependencia del dominio que se daba en el caso de los documentos y adem\u00b4 as se soluciona el problema de la distribuci\u00b4 on de los mismos sentidos en diferentes documentos. 5.2.2 LSA aplicado a WSD La utilizaci\u00b4 on de categor\u00b4 as sem\u00b4 anticas como base para mode- lar los diferentes espacios contextuales de la matriz, proporcio- na informaci\u00b4 on muy \u00b4 util acerca de los sentidos de las palabras. As\u00b4 pues, a partir de los valores de similitud obtenidos tras apli- car LSA sobre palabras, oraciones, o p\u00b4 arrafos, se puede establecer a qu\u00b4 e dominio pertenece un determinado contexto. De esta forma, si se intenta establecer el signicado de una palabra dentro de una frase f1se realiza el c\u00b4 alculo sobre la matriz conceptual, obtenien- do un listado con los dominios m\u00b4 as signicativos en relaci\u00b4 on a esa frase (en lugar de los documentos m\u00b4 as similares). De este modo, es posible establecer el concepto sem\u00b4 antico sobre el que subyace un determinado contexto, y a partir de ah\u00b4 se pueden determinar los sentidos de las palabras que lo componen. 134 5.2 WSD basado en conocimiento: DLSA El m\u00b4 etodo que se propone en esta secci\u00b4 on utiliza como fuente de conocimiento la base de datos l\u00b4 exica WND y el recurso l\u00b4 exico Dominios Relevantes. El proceso es el siguiente: a partir de la in- formaci\u00b4 on proporcionada por las glosas de WordNet Domains se construye la matriz conceptual, donde las columnas se correspon- den con los dominios de la jerarqu\u00b4 a de WND y las las son las palabras de las glosas. Previamente a la obtenci\u00b4 on de la matriz se realiza la lematizaci\u00b4 on de todas las palabras, ya que, LSA con- sidera conceptos distintos, palabras en plural o en singular, o las diferentes conjugaciones verbales. Los experimentos realizados en (V\u00b4 azquez et al. (2006 )), donde se utiliza la t\u00b4 ecnica de LSA para determinar la implicaci\u00b4 on textual, demuestran que tras la lema- tizaci\u00b4 on de las palabras que conforman la matriz conceptual los resultados mejoran. Una vez obtenida la matriz conceptual se realiza su descom- posici\u00b4 on en valores singulares reduciendo las dimensiones de la matriz de 162 a 100. De esta forma, los dominios que est\u00b4 an den- tro de una subjerarqu\u00b4 a se agrupan y as\u00b4 se consigue mantener una mejor cohesi\u00b4 on sem\u00b4 antica en la matriz conceptual. Tras la reducci\u00b4 on de dimensiones ya es posible determinar a qu\u00b4 e categor\u00b4 as sem\u00b4 anticas est\u00b4 on, p\u00b4 arrafo, etc. As\u00b4 pues, se realiza la comparaci\u00b4 on entre el vector de palabras previamente lematizadas del contexto de entrada con la matriz conceptual. El resultado es un listado con las categor\u00b4 as a las que pertenece el contexto de entrada junto con su grado de similitud. A partir de las categor\u00b4 as (dominios) obtenidas como resultado de la aplicaci\u00b4 on de LSA, se han desarrollado una serie de heur\u00b4 sti- cas para determinar el sentido m\u00b4 as apropiado de las palabras del contexto. Todas las heur\u00b4 sticas determinan el sentido de las pa- labras del contexto inicial utilizando como fuente de informaci\u00b4 on los dominios m\u00b4 as signicativos proporcionados por LSA. de Asociaci\u00b4 on. Esta heur\u00b4 stica utiliza los valores del Ratio de Asociaci\u00b4 on de los Dominios Relevantes como base para determinar el sentido de las palabras. En este caso, se extraen los 10 o 20 primeros domi- 5. M\u00b4 etodos 135 nios a partir de LSA. Estos dominios conforman un conjunto que se intersecciona con el conjunto de Dominios Relevantes de cada uno de los posibles sentidos de la palabra ambigua. De esta forma, para cada posible sentido, se seleccionan \u00b4 unicamente los dominios compartidos con el resultado de LSA. El sentido seleccionado es aquel con el valor m\u00b4 as elevado para los diferentes valores de RA obtenidos. 5.2.2.2 Heur\u00b4 stica 2: Similitud LSA. En esta heur\u00b4 unicamente se computan los valores de simi- litud obtenidos por LSA. Cada dominio devuelto por LSA tiene asociado un valor de similitud. En este caso, si el dominio devuelto por LSA se encuentra entre los dominios relevantes de un deter- minado sentido de la palabra, se almacena su valor de similitud. El resultado es el sumatorio de todos aquellos valores de simili- tud cuyos dominios se encuentran entre el listado de los dominios relevantes de cada uno de los sentidos. El sentido elegido es aquel cuyo sumatorio es mayor. 5.2.2.3 Heur\u00b4 stica 3: Similitud Esta \u00b4 ultima heur\u00b4 stica determina el sentido de las palabras a partir del valor obtenido tras multiplicar el valor de similitud ob- tenido por LSA por el RA de los dominios de cada uno de los sentidos. En este caso, se le da preferencia a aquellos dominios cuyo valor de similitud obtenido por LSA es mayor. De esta for- ma, se favorecen los dominios con mayor peso sem\u00b4 antico sobre la matriz conceptual. Como en los casos anteriores el sentido selec- cionado es aquel con mayor valor. 5.2.2.4 Ejemplo ilustrativo. Supongamos que tenemos el siguiente texto del que queremos desambiguar el verbo \"add\": 136 5.2 WSD basado en conocimiento: DLSA \"The dedi- cated pastors community, im- mediately opposed the idea, preaching against it at Sunday masses in the local convent and the school hall. The burden of the mes- sage was that good catholic parents sent their children to catholic schools. The curate to this that those education supporter was of ocial Sinn the Workers' party, appeared to gure in the reasoning, as this party has always been suspected to be an anti - clerical and secu- larist force. In residents' association meetings, the clergy's point of view received vocal support from one or two members of the older village community which preceded the housing estate.\" El primer paso es obtener los lemas de todas las palabras con contenido sem\u00b4 antico (nombres, verbos adjetivos y adverbios). Una vez obtenidos los lemas se establece el grado de similitud entre el vector del contexto donde est\u00b4 a la palabra ambigua con respecto a la matriz conceptual de LSA (ver Figura 5.16). En este caso, el resultado obtenido es: 5.16. Dominios Relevantes seg\u00b4 un LSA Con esta informaci\u00b4 on se procede a realizar la intersecci\u00b4 on con cada uno de los sentidos del verbo \"add\" . Los tres primeros vec- tores de sentidos son los mostrados en la Figura 5.17. 5. M\u00b4 etodos 137 Sentido 1 Sentido 2 Sentido 38 >>>>>>>>>>>>>>>>>>< 0.003351 table Figura 5.17. Vectores de sentidos para \"add\" Tras la comparativa y extracci\u00b4 on de los dominios presentes en la intersecci\u00b4 on de cada vector de sentido con el vector de contexto obtenido a partir de LSA, el resultado utilizando la heur\u00b4 stica 2, es el mostrado en la Figura 5.18. Selecci\u00b4 on del sentido correcto De tal forma, que el sentido seleccionado nalmente como el apropiado para \"add\" es el sentido 1. 5.2.3 LSA aplicado a NED Un campo que actualmente est\u00b4 a teniendo una gran repercusi\u00b4 on es el relacionado con la detecci\u00b4 on y discriminaci\u00b4 on de entidades: nombres propios, lugares, organizaciones, etc. La demanda de sistemas que por ejemplo, clasiquen p\u00b4 aginas web referentes a una determinada persona o una organizaci\u00b4 on, 138 5.3 WSD basado en reglas ling\u00a8 u\u00b4 sticas sobre corpus es cada vez m\u00b4 as elevada. Esta necesidad surge debido a la gran proliferaci\u00b4 on de Internet en los \u00b4 ultimos a nos, la aparici\u00b4 on de blogs, p\u00b4 aginas personales, etc. Al igual que existen palabras polis\u00b4 emicas encontramos enti- dades nombradas que comparten la misma forma nominal pero dieren en signicado. Por ejemplo, las siglas ACM pertenecen a: Association for Computing Machinery, Associaci\u00b4 o Catalana de Municipis i Comarques, Actividades de Carpinter\u00b4 a de Madera, Asociaci\u00b4 on de Cel\u00b4 acos de Madrid, etc. En este caso, un sistema de clasicaci\u00b4 on y discriminaci\u00b4 on deber\u00b4 a distinguir entre las distintas acepciones de ACM, bas\u00b4 andose primordialmente en los contextos de cada p\u00b4 agina. Es por ello, que hemos considerado la idea de aprovechar las ventajas que proporciona LSA para determinar la similitud entre contextos y utilizarla para extraer aquellas p\u00b4 aginas web o documentos que hagan referencia a una misma entidad. En el apartado de Evaluaci\u00b4 on se muestran los resultados tras utilizar la t\u00b4 ecnica de LSA para desambiguaci\u00b4 on y discriminaci\u00b4 on de nombres propios. 5.3 WSD basado en reglas ling\u00a8 u\u00b4 sticas sobre corpus Uno de los principales problemas en la resoluci\u00b4 on autom\u00b4 atica de la ambig\u00a8 uedad sem\u00b4 antica, et al. (2001 ), etc). En la actualidad, la gran mayor\u00b4 a de los sistemas se centran en el desarrollo de complejos algoritmos estad\u00b4 sticos que manejan muy poca cantidad u\u00b4 stica. Conside- rando esta deciencia, on de m\u00b4 as informaci\u00b4 on ling\u00a8 u\u00b4 stica que revele ciertas propiedades y re- laciones en el lenguaje, no evidenciadas a trav\u00b4 es de estimaciones estad\u00b4 sticas. El principal objetivo del m\u00b4 etodo desarrollado en esta secci\u00b4 on es demostrar que mediante la utilizaci\u00b4 on de informaci\u00b4 on ling\u00a8 u\u00b4 sti- ca se obtiene un elevado porcentaje de aciertos en t\u00b4 erminos de precisi\u00b4 on. Este incremento de la precisi\u00b4 on obtenida viene acom- 5. M\u00b4 etodos 139 pa nado de un decremento de la cobertura, debido en gran parte a la escasez de recursos ling\u00a8 u\u00b4 sticos (en espa nol, en nuestro caso), que la obtenci\u00b4 on de informaci\u00b4 on ling\u00a8 u\u00b4 stica a gran escala. A continuaci\u00b4 se exponen las caracter\u00b4 sticas de este m\u00b4 etodo junto con algunos ejemplos de informaci\u00b4 de desambiguaci\u00b4 on autom\u00b4 atica, es debida a la necesidad de evitar, en la medida de lo posible, el uso de par\u00b4 ame- tros estad\u00b4 sticos, frecuencias, medidas de similitud, etc, que llevan asociados un desv\u00b4 o y un margen de error, resultado de tratar los textos desde el punto de vista matem\u00b4 atico. El m\u00b4 etodo presentado en esta secci\u00b4 on utiliza informaci\u00b4 on im- pl\u00b4 cita presente en textos no anotados sem\u00b4 anticamente como base para la adquisici\u00b4 on de conocimiento. De esta forma, no es necesa- ria una anotaci\u00b4 on manual previa del corpus. 5.3.1.1 Adquisici\u00b4 on de informaci\u00b4 on paradigm\u00b4 sintagm\u00b4 atica rela- cionada con los sentidos de las palabras es dif\u00b4 cil de obtener y muy costosa. El t\u00b4 ermino informaci\u00b4 on sintagm\u00b4 atica hace co-ocurren frecuentemente, incluyendo coloca- ciones y restricciones de selecci\u00b4 on. Sin embargo, la informaci\u00b4 on paradigm\u00b4 atica, que hace referencia a palabras que en contextos similares (hip\u00b4 onimos/hiper\u00b4 onimos, mer\u00b4 onimos/hol\u00b4 oni- mos, etc), es m\u00b4 as sencilla de obtener. En esta secci\u00b4 on se va a describir c\u00b4 omo la obtenci\u00b4 on de infor- maci\u00b4 on paradigm\u00b4 on sin- tagm\u00b4 atica. Esta idea est\u00b4 a basada la de que palabras similares sem\u00b4 anticamente (eje paradigm\u00b4 atico) pueden ser sustitui- das en el mismo contexto (eje sintagm\u00b4 atico). Tal y como muestra la Figura 5.19: En este caso, si se ja la secuencia \"obra para \u00b4 organo\" , y se deja libre la posici\u00b4 on ocupada por la palabra \"obra\" , se pueden 140 5.3 WSD basado en reglas ling\u00a8 u\u00b4 sticas sobre corpus obra concierto pieza Relaciones paradigm\u00e1ticas para \u00f3rgano Relaciones sintagm\u00e1ticas Figura 5.19. Relaciones sintagm\u00b4 paradigm\u00b4 pueden intercambiarse entre s\u00b4 , de forma que el contexto mantiene su signicado \"com- posici\u00b4 on musical para un instrumento\" . Seg\u00b4 un el estudio realizado en (Miller y Charles (1991 )), se demuestra que un individuo deter- mina la similitud sem\u00b4 antica entre palabras, tomando como base los contextos en los que se utilizan. 5.3.1.2 Discriminadores de sentidos. A partir de la informaci\u00b4 on paradigm\u00b4 atica proporcionada, se puede establecer el sentido de la palabra ambigua. Es decir, a partir de todas las palabras que conforman el eje paradigm\u00b4 atico, que pueden ponerse en lugar de la palabra ambigua, y usando una fuente de datos l\u00b4 exica que proporcione informaci\u00b4 on para cada uno de los posibles sentidos de la palabra, se puede establecer el sentido m\u00b4 as adecuado de la palabra ambigua. En nuestro caso, la fuente de datos l\u00b4 exica elegida para la obten- ci\u00b4 on de los diferentes sentidos de las palabras, ha sido EuroWord- Net1(Vossen (1998 )). EuroWordNet 5. etodos 141 de para idiomas europeos (ingl\u00b4 es, espa nol, alem\u00b4 an, holand\u00b4 es, italiano, franc\u00b4 es, estonio y checo). Cada synset de los diferentes idiomas se encuentra conectado con el resto, a trav\u00b4 es del llamado \"Inter Lingual Index\" (ILI). En la Figura 5.20 se muestra la interconexi\u00b4 on entre los diferentes idiomas. Italiano W Italiano W Espa\u00f1ol W Espa\u00f1ol W Alem\u00e1n W Alem\u00e1n W Ingl\u00e9s W Ingl\u00e9s W Relaciones sem\u00e1nticas internas ILI Mapeo entre ontolog\u00eda espec\u00edfica del lenguaje y gen\u00e9rica Top concepts Merged Ongology Figura 5.20. esta forma, utilizando EuroWordNet y sus relaciones sem\u00b4 anti- cas, el m\u00b4 etodo desarrollado en esta secci\u00b4 on se va a aplicar sobre el idioma espa nol. Para ello, se va a emplear el conjunto de \"va- riants\"2proporcionados para cada uno de los sentidos de una palabra. As\u00b4 pues, para cada sentido Wide una palabra W, se extraen de EWN el conjunto de synsets con los (hip\u00b4 2Los\"variants\" son las palabras que forman un synset. Por los \"variants\" del synset n\u00b4 EWN reposo, 142 5.3 WSD basado en reglas ling\u00a8 u\u00b4 sticas sobre corpus riants\" que los identican. El resultado nal es la asignaci\u00b4 on al sentido Witodos los \"variants\" Viextra\u00b4 dos relaciones l\u00b4 exi- co sem\u00b4 anticas de EWN. Una vez obtenidos los conjuntos Vipara cada sentido i, el siguiente paso es eliminar aquellos \"variants\" que se encuentren en m\u00b4 as de un sentido, obteniendo de esta forma una serie de conjuntos disjuntos Dicon palabras relacionadas ex- clusivamente con el sentido Wide la palabra. El resultado nal es una serie de conjuntos Didenominados de aqu\u00b4 en adelante como Discriminadores de Sentidos. A continuaci\u00b4 on se muestra el proceso de extracci\u00b4 on de los Dis- criminadores de Sentidos para la palabra \"\u00b4 organo\" que Eu- roWordNet de las organo cosa, en- tidad. los \"variants\" se construye el conjun- toV1=f\u00b4 organo vegetal, objeto inanimado, objeto f\u00b4 sico, objeto, cosa, entidad, estructura reproductiva, l\u00b4 amina, ra\u00b4 z, tronco, tallo, rabillo,... g. Y as\u00b4 para cada uno de los sentidos de \"\u00b4 organo\". Fi- nalmente, se extraen los Discriminadores de Sentidos, quedando el conjunto D1=f\u00b4 organo vegetal, l\u00b4 amina, ra\u00b4 z, tronco, tallo,... g. Para abarcar m\u00b4 as informaci\u00b4 on derivada de las relaciones de EuroWordNet, el conjunto de Discriminadores de Sentidos se ha 5. M\u00b4 etodos 143 ampliado utilizando las relaciones heredadas de hiponimia, man- teniendo la caracter\u00b4 stica de conjuntos disjuntos. De esta forma, a estos nuevos conjuntos ampliados se les denomina DE i(Discri- minadores de Sentidos Extendidos). La obtenci\u00b4 on del sentido de una palabra viene determinado por el n\u00b4 umero de palabras del eje paradigm\u00b4 atico que tiene en com\u00b4 un con cada uno de los conjuntos disjuntos de Discriminadores de Sentidos. A mayor n\u00b4 umero de palabras en com\u00b4 un con el conjunto DE i, mayor probabilidad de que la palabra Wtenga asociado el sentido i. 5.3.1.3 Identicaci\u00b4 on de patrones sintagm\u00b4 aticos. Para la la informaci\u00b4 on paradigm\u00b4 atica es nece- sario el establecimiento, en primer lugar, de una serie de patrones sintagm\u00b4 aticos que identiquen entidades con contenido sem\u00b4 anti- co susceptibles de ser intercambiadas con otras entidades en el mismo contexto (eje sintagm\u00b4 atico). De esta forma, cobra impor- tancia la determinaci\u00b4 on del contexto local para cada ocurrencia y categor\u00b4 a sint\u00b4 actica. La aparici\u00b4 on de una palabra en un contexto determinado pro- porciona informaci\u00b4 on muy \u00b4 util para su desambiguaci\u00b4 on ( Ravin y Leacock (2001 )). Asimismo, existe una interdependencia entre el signicado de una palabra y el signicado de las estructuras sint\u00b4 acticas superiores que la contienen: sintagma y oraci\u00b4 on. Un estudio realizado en ( Miller y Charles (1991 )) demuestra que una ventana de pocas palabras alrededor de la ocurrencia ambigua, es suciente para obtener su signicado. De esta forma, nuestra apro- ximaci\u00b4 on parte de un contexto m\u00b4 nimo para identicar el sentido de la ocurrencia ambigua, para posteriormente ampliarlo hasta obtener un \u00b4 unico sentido posible. Se parte por tanto, de una secuencia sintagm\u00b4 atica reducida que contiene la ocurrencia ambigua, manteniendo jos los dem\u00b4 as ele- mentos y se deja libre la posici\u00b4 on que ocupa la palabra ambigua. De esta forma, se buscan en el corpus palabras que ocupen su lugar manteniendo la misma informaci\u00b4 on sintagm\u00b4 atica original (Ver Fi- gura 5.19). A partir de aqu\u00b4 , se introduce un nuevo concepto, el de 144 5.3 WSD basado en reglas ling\u00a8 u\u00b4 sticas sobre corpus patrones sintagm\u00b4 aticos, que por dos u\u00b4 sticas L1 yL2 de contenido adverbios) y un patr\u00b4 on l\u00b4 exico-sint\u00b4 actico Rque expresa on, l\u00b4 exico-sem\u00b4 antica o de adyacencia) l\u00b4 exicas. La rela- ci\u00b4 onRpuede contener valores nulos, por ejemplo, en el caso de relaciones de adyacencia entre nombres y adjetivos: pasaje -L1\u00ae-Rsubterr\u00b4 acticos). Por ejemplo, corona de bros del comit\u00b4 e (relaciones de meronimia). Ambos tipos de patrones son relevantes para la identicaci\u00b4 on del sentido de la palabra ambigua. En el caso de los patrones sint\u00b4 acticos, el elemento relacional Rse expresa mediante pala- bras funcionales, mientras que en los patrones l\u00b4 exico-sem\u00b4 anticos Rsuele tener una forma m\u00b4 as compleja y puede contener tanto pa- labras funcionales como de contenido l\u00b4 exico. En este trabajo, nos vamos a centrar en los patrones sint\u00b4 acticos, dejando como traba- jo futuro la incorporaci\u00b4 on de patrones l\u00b4 exico-sem\u00b4 anticos. Adem\u00b4 as, vamos a centrar el proceso de desambiguaci\u00b4 on sobre los nombres, por ser esta categor\u00b4 a la m\u00b4 as rica en cuanto a relaciones sint\u00b4 acticas en sus proximidades. Las hip\u00b4 otesis para determinar el sentido de una palabra ambi- gua a partir de patrones sintagm\u00b4 aticos son las siguientes: 1.Dos palabras que comparten un mismo patr\u00b4 on sintagm\u00b4 atico, tienen una alta probabilidad de estar relacionadas sem\u00b4 antica- mente. 2.Dos ocurrencias de una palabra ambigua tienen una alta pro- babilidad de pertenecer al mismo sentido si aparecen en un mismo patr\u00b4 on sintagm\u00b4 atico. Para la identicaci\u00b4 on de patrones sint\u00b4 acticos tienen en cuen- dos criterios: 5. M\u00b4 etodos 145 Estructural (sint\u00b4 Se com- binaciones de categor\u00b4 as morfosint\u00b4 acticas mediante las que se establecen relaciones sint\u00b4 acticas. En este caso, los patrones considerados son los siguientes: N1 (((ADV) ADV) ADJ/VPART), categor\u00b4 as entre par\u00b4 entesis hacen referencia a elementos que pueden estar o no presentes en el patr\u00b4 on. Y las categor\u00b4 as separadas por una barra son alternativas para una misma po- sici\u00b4 on. Los patrones compuestos pueden descomponerse en pa- trones simples mediante unas reglas de descomposici\u00b4 on prede- ejemplo, el patrones que cumplen el criterio estruc- tural se ltran de acuerdo a su frecuencia de aparici\u00b4 on en el corpus. Mediante estos criterios se eliminan aquellas combinaciones in- aceptables de categor\u00b4 as sint\u00b4 acticas y las combinaciones poco fre- cuentes. Una vez detectado el patr\u00b4 on sint\u00b4 actico en el que aparece la pa- labra ambigua y las palabras relacionadas en el eje paradigm\u00b4 atico, se puede establecer el sentido de la palabra ambigua utilizando los Discriminadores de Sentidos a partir de EWN. 5.3.2 Prueba de conmutabilidad El algoritmo utilizado para obtener el sentido correcto de una ocurrencia ambigua es el denominado Prueba de Conmutabilidad. Este algoritmo utiliza la adaptaci\u00b4 on de EWN mediante Discrimi- nadores de Sentidos para determinar el sentido correcto de una palabra. 146 5.3 WSD basado en reglas ling\u00a8 u\u00b4 sticas sobre corpus Este algoritmo est\u00b4 a basado en la hip\u00b4 otesis de que dos palabras que pueden conmutar en un contexto determinado est\u00b4 an relacio- nadas sem\u00b4 Discriminadores de Sentidos denidos anteriormente, si una palabra ambigua puede sustituirse en sus patrones sint\u00b4 acticos por un Discriminador de Sentido, entonces se le puede asignar el sentido correspondiente a ese Discriminador. Para el ejemplo de la Figura 5.19,\"obra para \u00b4 organo\" , si se quiere desambiguar la palabra \"\u00b4 organo\", se deben buscan ocurren- cias en el corpus del patr\u00b4 on [obra - - X], donde X puede sus- tituirse por: viol\u00b4 n, guitarra, piano, etc. Los nombres que pueden sustituir a \"\u00b4 organo\" pertenecen al conjunto de Discriminadores de Sentido de \u00b4 organo#4, y por tanto, \"\u00b4 organo\" podr\u00b4 a tener el senti- do 4. La Figura 5.21muestra de forma gr\u00b4 aca el funcionamiento patr\u00b4 on [Y - R - X] cualquiera, se deja libre la posici\u00b4 on que ocupa la palabra ambigua. Se buscan en el corpus ocurrencias del patr\u00b4 on con palabras que conmutan en el lugar de la palabra ambigua. Esas palabras conmutables se buscan en los Discrimi- nadores de Sentido para cada sentido de la palabra ambigua. El sentido elegido nalmente es aquel que comparte mayor n\u00b4 umero de palabras conmutadas en su conjunto de Discriminadores de Sentido. 5. M\u00b4 etodos 147 Una de las ventajas de este algoritmo es que no necesita cor- pus anotados sem\u00b4 anticamente, ya que act\u00b4 ua directamente sobre palabras y no sobre sus sentidos. La arquitectura del sistema de desambiguaci\u00b4 on autom\u00b4 atica es el la obtenci\u00b4 on de los patrones sint\u00b4 acticos y a la b\u00b4 usqueda en el corpus informaci\u00b4 on paradigm\u00b4 atica es necesa- rio un preproceso del texto. Se deben determinar los lemas de las palabras y sus relaciones sint\u00b4 acticas. Para ello, se utiliza un analizador morfosint\u00b4 actico para espa nol utilizar la paradigm\u00b4 atica obtenida a partir de la sustituci\u00b4 on de la palabra ambigua en el patr\u00b4 on sint\u00b4 actico, se va a utilizar la informaci\u00b4 on proporcionada por la oraci\u00b4 on donde aparece la palabra ambigua. Dado que el contexto donde aparece la palabra ambigua (oraci\u00b4 on) ofrece informaci\u00b4 on 148 5.3 WSD basado en reglas ling\u00a8 u\u00b4 sticas sobre corpus muy valiosa, es interesante utilizar tambi\u00b4 en esta informaci\u00b4 on so- bre los conjuntos de Discriminadores de Sentidos. Se tendr\u00b4 an por tanto, dos fuentes de informaci\u00b4 on: C1:El conjunto de palabras correspondientes a la informaci\u00b4 on paradigm\u00b4 atica obtenida a partir del patr\u00b4 on sint\u00b4 actico donde aparece la palabra ambigua. C2:El conjunto de todos los nombres de la oraci\u00b4 on donde apa- rece la palabra ambigua. Sobre cada fuente de informaci\u00b4 on (C1 y C2) se aplica oraci\u00b4 Cada heur\u00b4 stica intersecta el conjunto C1 o C2 con los con- juntos de Discriminadores de Sentidos de la palabra ambigua. De esta forma, aquella intersecci\u00b4 on que d\u00b4 e como resultado un conjun- to no vac\u00b4 o de elementos ser\u00b4 a el sentido elegido. Si cada heur\u00b4 stica devuelve un sentido distinto, se conservan ambos. El objetivo de este m\u00b4 etodo es el de ltrar los sentidos inadecuados, sin perder el sentido correcto al tratar de elegir una de las posibles opciones en caso de desacuerdo. 5.3.4 Ejemplo de aplicaci\u00b4 on Supongamos que tenemos el siguiente texto del cual queremos obtener el sentido de la palabra \"\u00b4 organo\" : \"Los enormes y continuados progresos cient\u00b4 cos y t\u00b4 ecnicos de la Medicina actual han logrado hacer descender espectacularmente la mortalidad infantil, erradicar multitud de enfermedades hasta hace poco mortales, sustituir mediante trasplante o implantaci\u00b4 on de\u00b4 organos da nados o partes del cuerpo inutilizadas y alargar las expectativas de vida.\" El primer paso es detectar el tipo de patr\u00b4 on sint\u00b4 actico en el que se encuentra la palabra a desambiguar. Para ello se utilizan los patrones sint\u00b4 acticos previamente adquiridos y en el caso de que sea 5. M\u00b4 etodos 149 NACN NA NCN \u00f3rgano da\u00f1ado \u00f3rgano o parte Esquema Reglas de descomposici\u00f3n Resultado Figura 5.23. Extracci\u00b4 on de patrones un patr\u00b4 on compuesto se utilizan las reglas de descomposici\u00b4 on de patrones. La Figura 5.23muestra la extracci\u00b4 on de estos patrones. El siguiente paso, una vez se han extra\u00b4 do los patrones sint\u00b4 acti- cos, es obtener informaci\u00b4 on paradigm\u00b4 atica presente tanto en cor- pus como en el contexto que rodea a la palabra ambigua. La Fi- gura 5.24muestra el resultado de este proceso. Corpus Oraci\u00f3n mediador, terreno, ch\u00f3fer, \u00e1rbol, cabeza, planeta, parte, incremento, totalidad, guerrilla, programa, mitad, pa\u00eds, temporada, art\u00edculo... progreso, cient\u00edfico, mortalidad, multitud, enfermedad, mortal, trasplante, implantaci\u00f3n, \u00f3rgano, parte, cuerpo... expectativa, vida Figura 5.24. Informaci\u00b4 on paradigm\u00b4 atica Una vez extra\u00b4 da la informaci\u00b4 on paradigm\u00b4 atica se compara con los conjuntos de Discriminadores de Sentidos asociados a \"\u00b4 orga- no\". Los cinco conjuntos asociados a cada sentido de \"\u00b4 organo\" se muestran en la Tabla 5.8. 150 \u00b4 organo#1: \u00b4 organo vegetal, espora, flor, pera, manzana, bellota, hi- semilla, poro, p\u00b4 leo, carp\u00b4 oforo, ... \u00b4 organo#2: agencia, unidad administrativa, banco central, servicio secreto, seguridad social, FBI, ... \u00b4 organo#3: parte del cuerpo, trozo, m\u00b4 ... \u00b4 organo#4: instrumento de viento, instrumento musical, mecanismo, aparato, teclado, pedal, corneta, ... \u00b4 organo#5: peri\u00b4 odico, publicaci\u00b4 n\u00b4 umero, 5.8. Discriminadores de Sentidos para \"\u00b4 organo\" Tras comparar el conjunto de palabras del eje paradigm\u00b4 atico con cada uno de los conjuntos de Discriminadores de Sentidos, se aplican las dos heur\u00b4 sticas, tal y como organo#3: A fully dierentiated structural and functional unit in an animal that is specialized for some particular function. Cap\u0013\u0010tulo 6 Experimentaci\u00b4 on y evaluaci\u00b4 on En este cap\u00b4 tulo se describe todo el proceso de evaluaci\u00b4 on de los sistemas de WSD implementados en este trabajo, as\u00b4 como su integraci\u00b4 on y aplicaci\u00b4 on en otras tareas de PLN. La primera parte del cap\u00b4 tulo se centra en el marco de trabajo para la eva- luaci\u00b4 on de sistemas de WSD, presentando las diferentes ediciones de la competici\u00b4 on Senseval1hasta la actualidad . En la segunda parte, se presenta la evaluaci\u00b4 on de nuestros sistemas comparando los resultados obtenidos con otros sistemas participantes en Sen- seval . Finalmente, los sistemas de desambiguaci\u00b4 on se aplican a otras tareas de PLN que requieren de un m\u00b4 odulo de desambigua- ci\u00b4 on sem\u00b4 antica para mejorar sus resultados. 6.1 Competiciones de evaluaci\u00b4 on A continuaci\u00b4 on se describen las tareas que se organizaron en las distintas ediciones de Senseval y algunos de los sistemas que han participado en esta competici\u00b4 on en sus diferentes ediciones. 1http://www.senseval.org 152 6.1 Competiciones de evaluaci\u00b4 on 6.1.1 SENSEVAL: Evaluation Exercises for the Semantic Text Senseval es una competici\u00b4 on de evaluaci\u00b4 on organizada en la l\u00b4 nea de otras competici\u00b4 on se realiz\u00b4 o en el a no 1998 con veinticin- co sistemas participantes clasicados en dos categor\u00b4 as diferentes: sistemas supervisados y sistemas no supervisados. Los sistemas supervisados que participaron requer\u00b4 an unos datos de entrena- miento anotados sem\u00b4 anticamente. Mientras que para los sistemas no supervisados este tipo de informaci\u00b4 on no era necesaria. En es- ta primera edici\u00b4 on se utiliz\u00b4 o un lexicon especial para los distintos conjuntos de sentidos: HECTOR ( Atkins (1992 )), que fue creado por la Universidad de Oxford. A los sistemas participantes se les proporcionaron los datos de entrenamiento, que eran textos ano- tados con el sentido correcto tomando como referencia HECTOR. La evaluaci\u00b4 on se llev\u00b4 o a cabo poniendo a prueba los distintos siste- mas con una serie de ejemplos sin etiquetar, estos ejemplos deb\u00b4 an ser anotados con el sentido correcto de cada palabra. Los idiomas utilizados en esta evaluaci\u00b4 on fueron: Ingl\u00b4 es (18 sistemas), Franc\u00b4 es (5 sistemas) e Italiano (2 sistemas). En esta primera competici\u00b4 on los items a desambiguar se res- tringieron a un conjunto de 40 palabras (tarea \"Lexical Sample\"). Este conjunto de palabras se estableci\u00b4 o de forma aleatoria, de ma- nera que fueron seleccionadas aquellas palabras con suciente con- texto y ejemplos, utilizando la estrategia descrita por ( Kilgarri (1998a )). En (Kilgarri y Palmer (2000 )) se describe el \u00b4 ambito de es- ta competici\u00b4 on as\u00b4 como los problemas surgidos en la elecci\u00b4 on de los corpus y el repositorio de sentidos. Con respecto a la tarea \"English Lexical Sample\" en (Kilgarri y Rosenzweig (2000 )) se realiza un estudio exhaustivo de todos los sistemas propuestos en esta competici\u00b4 on. Los sistemas que mejores resultados propor- cionaron fueron los sistemas supervisados de la Universidad de Durham ( Hawkins y Nettleton (2000 )) y de la Universidad de John Hopkins ( Yarowsky (2000b )). 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 153 Tras esta primera aproximaci\u00b4 on para evaluar los diferentes sis- temas de WSD, se han realizado tres Senseval- 2ACL (2001 ),Senseval-3 ACL (2004 ellas Se- meval ACL (2007 ). 6.1.2 SENSEVAL-2: Second International Workshop on Evaluating Word Sense Disambiguation Systems En esta edici\u00b4 on de Senseval doce idiomas fueron evaluados y se presentaron alrededor de noventa sistemas. Una de las prin- cipales diferencias con la edici\u00b4 on anterior fue la adici\u00b4 on de una nueva tarea: \"All-Words\" , que requer\u00b4 a que los sistemas fueran capaces de etiquetar con el sentido correcto todas las palabras con contenido sem\u00b4 antico de los textos proporcionados. Las tareas propuestas fueron tres (entre par\u00b4 entesis se muestra el n\u00b4 umero de sistemas participantes en cada idioma): Tarea All-words. Checo (1), holand\u00b4 es (datos no disponibles para evaluaci\u00b4 on), ingl\u00b4 es (21) y estonio (2). Tarea Lexical Sample. Euskera (3), ingl\u00b4 es (27), italiano (2), japon\u00b4 es (7), coreano (2), espa nol (12) y sueco (8). Tarea Traducci\u00b4 on. Japon\u00b4 es (9). La tarea \"Lexical Sample\" tiene como objetivo la obtenci\u00b4 on del sentido correcto de una \u00b4 unica palabra por frase, mientras que en la tarea \"All words\" , los sistemas deben desambiguar sem\u00b4 antica- mente todas las palabras, a excepci\u00b4 on de las funcionales (conjun- ciones, preposiciones, art\u00b4 culos, etc.), que aparecen en las frases de los corpus proporcionados. La tarea de traducci\u00b4 on, en la que s\u00b4 olo se particip\u00b4 o con la lengua japonesa, es un subtipo de \"Lexical Sample\" porque s\u00b4 olo hay que desambiguar una \u00b4 unica palabra. La diferencia es que el sentido de la palabra se dene de acuerdo a su traducci\u00b4 on. El repositorio utilizado para establecer los sentidos de las pala- bras fue WordNet 1.7 para el idioma ingl\u00b4 es y EuroWordNet para el resto de idiomas. 154 6.1 Competiciones de evaluaci\u00b4 on 6.1.3 SENSEVAL-3: Evaluation exercises for Word Sense Disambiguation La tercera competici\u00b4 on de Senseval tuvo lugar en Julio de 2004 Barcelona (Espa na). En esta edici\u00b4 on se organizaron catorce tareas: Tarea 1. English all words. (64 sistemas)( Snyder y Palmer (2004 )) Tal y como se hizo en el Senseval2, en esta nueva edici\u00b4 on se etiquetaron aproximadamente 5000 palabras extra\u00b4 das del corpus de Penn Treebank, tomando como referencia WordNet 1.7.1. Se etiquetaron nombres, adjetivos y adverbios haci\u00b4 endose dos revisiones para formalizar criterios. Tarea 2. Italian all words. (7 sistemas) ( Ulivieri et al. (2004 )) En esta edici\u00b4 on adem\u00b4 as de proponer una tarea de \"lexical sam- ple\" para italiano tambi\u00b4 en se propuso la tarea de \"all words\". A cada participante se le proporcion\u00b4 o un peque no conjunto de tex- tos de aproximadamente 5000 palabras extra\u00b4 dos del corpus Ita- lian Treebank. Las palabras etiquetadas fueron nombres, verbos, adjetivos, adverbios y nombres propios, todas ellas atendiendo a la anotaci\u00b4 on de ItalWordNet ( Corazzari y Alonge (8 sistemas) ( Agirre et al. (2004 )) En esta tarea se evaluaron sistemas supervisados y semi- supervisados para WSD. Cada participante fue provisto de un peque no conjunto de ejemplos etiquetados y un conjunto m\u00b4 as amplio de ejemplos no etiquetados para unas 40 palabras. To- das las palabras fueron etiquetadas con la versi\u00b4 on de WordNet 1.6 (aunque se puede obtener f\u00b4 acilmente su equivalente en la versi\u00b4 on de WordNet 1.7). Esta tarea fue coordinada junto con otras tareas de lexical sample (Catal\u00b4 an, Ingl\u00b4 es, Italiano, Ruma- no, Espa nol) para tener en com\u00b4 un al menos 10 de las palabras utilizadas en la evaluaci\u00b4 on. Tarea 4. Catalan lexical sample. (8 sistemas) ( M` arquez et al. (2004b )) Al igual que en caso del Euskera tambi\u00b4 en se hizo una tarea de lexical sample para Catal\u00b4 an. Compartiendo la etique- taci\u00b4 on con WordNet 1.6 y su adaptaci\u00b4 on a WordNet 1.7. Tam- bi\u00b4 en se proporcionaron textos de entrenamiento etiquetados y 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 155 textos no etiquetados para los sistemas supervisados y semi- supervisados que participaron. Tarea 5. Chinese lexical sample. (16 sistemas) En esta tarea se utilizaron tres tipos de datos: diccionario, datos de entrenamien- to y datos de evaluaci\u00b4 on. El diccionario conten\u00b4 a entradas para 20 palabras distintas. Para cada palabra hab\u00b4 an denidos varios sentidos basados en el recurso HowNet ( Gan y Wong (2000 )). Para cada sentido, la entrada del diccionario listaba: un iden- ticador para el sentido, la categor\u00b4 a sint\u00b4 actica de la palabra, una denici\u00b4 on y una traducci\u00b4 on al ingl\u00b4 es, as\u00b4 como alguna in- formaci\u00b4 on adicional. Los datos de entrenamiento consist\u00b4 an en 20-100 ejemplos por palabra, con m\u00b4 as ejemplos para aquellas palabras con un n\u00b4 umero m\u00b4 as elevado de sentidos. Dos conjun- tos de entrenamiento fueron distribuidos: uno con etiquetaci\u00b4 on sint\u00b4 actica y otro sin esa informaci\u00b4 on. Tarea 6. English lexical sample. (65 sistemas) ( Mihalcea et al. (2004a )) Los datos en esta tarea fueron obtenidos a partir de la interfaz del Open Mind Word Expert (OMWE) ( Chklovski y Mihalcea (2002 )). Para abilidad se extrajeron dos etique- tas por item y se realizaron diversos tests con la nalidad de llegar a un acuerdo entre las distintas anotaciones de los eti- quetadores. La elecci\u00b4 on de OMWE como interfaz para obtener los datos de la tarea fue debida a su probada calidad en otras evaluaciones. Se extrajeron alrededor de 60 palabras ambiguas entre nombres, adjetivos y verbos. Parte del test de evaluaci\u00b4 on fue creado por el Departamento de Ling\u00a8 u\u00b4 stica de la Universi- dad del Norte de Texas (UNT). Otra parte del test de evalua- ci\u00b4 on fue extra\u00b4 do a partir de corpus etiquetado de la web. Se utiliz\u00b4 o la versi\u00b4 on de WordNet 1.7.1 para nombres y adjetivos y Wordsmyth2para verbos. Adem\u00b4 as tambi\u00b4 en se distribuyeron los agrupamientos de sentidos que posibilitaban una evaluaci\u00b4 on menos restrictiva (coarse) frente a una evaluaci\u00b4 on m\u00b4 as estricta (ne). Adem\u00b4 as tambi\u00b4 en se distribuy\u00b4 o el mapeo entre la anota- ci\u00b4 on de Wordsmyth y WordNet. 2http://www.wordsmyth.net/ 156 de evaluaci\u00b4 7. Italian lexical sample. (11 sistemas) ( Magnini et al. (2004 )) En esta tarea sigue los mismos principios que las tareas de lexical sample para Euskera y Catal\u00b4 an mencionadas anterior- mente. Se utiliz\u00b4 o para la anotaci\u00b4 on de sentidos el MultiWordNet Italiano ( Pianta et al. (2002 )), que fue especialmente desarro- llado para la tarea. Tarea 8. Romanian sistemas) ( Mihalcea et al. (2004b )) En esta tarea se seleccionaron 50 palabras, cubriendo nom- bres, adjetivos, verbos y adverbios, con distintos grados de am- big\u00a8 uedad. Para cada palabra se extrajeron un conjunto de ejem- plos a partir de un extenso corpus en Rumano. Los sentidos y las expresiones de palabras m\u00b4 ultiples fueron extra\u00b4 dos del Word- Net Rumano o de DEX3un reconocido diccionario del Rumano. Los datos fueron extra\u00b4 dos a partir de la interfaz del OMWE, edici\u00b4 on en rumano. Tarea 9. Spanish lexical sistemas) ( M` arquez et al. Al igual que para Catal\u00b4 an, Euskera, Ingl\u00b4 es e Italiano tambi\u00b4 en se organiz\u00b4 o la tarea lexical sample para Espa nol. El repertorio de sentidos fue obtenido a partir de WordNet 1.6 con su res- pectivo mapeo a WordNet 1.7. Esta tarea se coordin\u00b4 o con las dem\u00b4 as tareas de lexical sample para compartir al menos 10 de las palabras propuestas para desambiguar. Tarea 10. Automatic subcategorization acquisition. (35 siste- mas) ( y Korhonen (2004 En esta tarea se evaluaron diversos sistemas de WSD en el con- texto de subcategorizaci\u00b4 on autom\u00b4 atica. La tarea se restringi\u00b4 o a 30 verbos, de elevada frecuencia de aparici\u00b4 on y con m\u00b4 ultiples sentidos. En este caso se publicaron los 30 verbos de la tarea pero no se proporcion\u00b4 o ning\u00b4 un corpus de entrenamiento. El cor- pus de evaluaci\u00b4 on consisti\u00b4 o en alrededor de 1000 instancias pa- ra cada verbo, que se deb\u00b4 an anotar con el sentido correcto, de acuerdo a la versi\u00b4 on de WordNet 1.7.1. 3http://dexonline.ro/ 6. Experimentaci\u00b4 Multilingual lexical sample. (23 sistemas) ( Chklovski et al. (2004 )) El objetivo de esta tarea era crear un marco de referencia pa- ra la evaluaci\u00b4 on de sistemas de Traducci\u00b4 on Autom\u00b4 atica, cen- tr\u00b4 andose en la traducci\u00b4 on de palabras ambiguas. Esta tarea era muy similar a la tarea lexical sample, excepto que en lugar de utilizar el inventario de sentidos de un diccionario se utiliz\u00b4 o la propuesta de Resnik y Yarowsky usando las traducciones de las palabras en otra lengua como \"inventario\". Los textos originales eran en Ingl\u00b4 es y la anotaci\u00b4 on para las palabras se deb\u00b4 a hacer la traducci\u00b4 on en otro idioma. La tarea se restringi\u00b4 o a textos Ingl\u00b4 es- Franc\u00b4 es e Ingl\u00b4 es-Hindi con alrededor de 50 palabras ambiguas por pareja de idiomas. Tarea 12. WSD of WordNet glosses. (36 sistemas)( Litkowski Net ( Harabagiu et al. (1999 )), un recurso que enriquece la ver- si\u00b4 on inicial de WordNet a nadiendo y sem\u00b4 los t\u00b4 erminos de las glosas de WordNet. El proceso para obtener una buena anotaci\u00b4 on es costoso y en muchos casos se realiza de forma manual. El objetivo de esta tarea era desarro- llar un m\u00b4 etodo de anotaci\u00b4 on autom\u00b4 atica tomando como corpus de evaluaci\u00b4 on las glosas previamente etiquetadas en eXtended WordNet. En el marco de la tarea \"all-words\" , se deb\u00b4 an eti- quetar nombres, verbos, adverbios y adjetivos, con la salvedad de que ning\u00b4 un contexto era proporcionado. Los sistemas parti- cipantes pod\u00b4 an utilizar cualquier informaci\u00b4 on adicional como synsets, la jerarqu\u00b4 a de WordNet y otro tipo de relaciones en WordNet. Tarea 13. Semantic Roles. (36 sistemas) ( Litkowski (2004a )) Utilizando como base una porci\u00b4 on del corpus anotado de Frame- Net, los sistemas deb\u00b4 an realizar la anotaci\u00b4 on de roles sem\u00b4 anti- cos siguiendo las m\u00b4 etricas del estudio de y Jurafsky ( y Jurafsky Forms. (26 sistemas) ( Rus(2004 )) El objetivo de esta tarea era transformar oraciones formuladas en ingl\u00b4 es en su correspondiente notaci\u00b4 on de l\u00b4 ogica de primer orden. Cada 158 6.1 Competiciones de evaluaci\u00b4 on palabra con contenido sem\u00b4 antico \u00b4 ultima edici\u00b4 on Senseval4tuvo lugar en Junio de 2007 en Praga (Rep\u00b4 ublica Checa). En esta edici\u00b4 on se organizaron diecio- cho tareas (la tarea 3 se cancel\u00b4 o): Tarea 1. Evaluating WSD on Cross-Language Information (2 sistemas) ( Agirre et al. (2007 )) Tarea 2. Evaluating Word Sense Induction and Discrimination Systems. (6 sistemas) ( Agirre y Soroa (6 sis- temas) ( Jin et (2007 )) Tarea 6. Word Sense Disambiguation of Prepositions. (5 siste- Grained English All Words Task. (12 sistemas) (Navigli et al. (2007 )) Tarea 8. Metonymy Resolution at SemEval 2007. (5 Multilevel et Tarea 10. English Substitution Task. ( McCarthy y Na- vigli (2007 English Lexical Sample Task via English-Chinese Parallel Text. ( Ng y (2007 )) Tarea 12. Turkish Lexical Sample Task. ( Orhan et al. (2007 )) Tarea 13. Web People Search. ( Artiles et al. (2007 )) Tarea 14. Aective 4http://nlp.cs.swarthmore.edu/semeval/ Experimentaci\u00b4 on y evaluaci\u00b4 on 159 Tarea 16. Evaluation of Wide Coverage Knowledge Resources. (Cuadros y Rigau (2007 )) Tarea Lexical Sample, SRL Words. Labeling. ( Extraction. ( Baker et al. (2007 )) 6.2 Participaci\u00b4 on en Senseval Para la evaluaci\u00b4 on de los diferentes sistemas de WSD, es ne- cesario determinar un inventario de sentidos con el que anotar las palabras polis\u00b4 emicas de los textos. Adem\u00b4 as, se debe denir un conjunto de corpus sobre los que realizar la anotaci\u00b4 on y posterior evaluaci\u00b4 on de los resultados. Junto con el establecimiento de un repositorio de sentidos, se plantean otro tipo de problemas, como por ejemplo, el c\u00b4 omo decidir el grado de distinci\u00b4 on entre un sen- tido u otro. Este problema se denomina nivel de granularidad de sentidos ( Edmonds y Kilgarri (1998 )), con laridad na tienen como caracter\u00b4 stica poseer una divisi\u00b4 on muy detallada de los sentidos pero con un alto nivel de ambig\u00a8 uedad. Sin embargo, los repositorios de sentidos con granularidad grue- sa proporcionan una divisi\u00b4 on muy general de los sentidos con un nivel muy bajo de ambig\u00a8 uedad. Para las diferentes evaluaciones dentro de la competici\u00b4 on Sen- seval , se ha utilizado como repositorio de sentidos WordNet, caracterizado por tener una granularidad na, donde existe una divisi\u00b4 on de los sentidos muy detallada. Todos los sistemas partici- pantes deben anotar una serie de palabras polis\u00b4 emicas de acuerdo a los diferentes sentidos de WordNet. Finalmente, la evaluaci\u00b4 on de la efectividad de cada sistema se realiza estableciendo una com- paraci\u00b4 on con respecto a una anotaci\u00b4 on manual de los corpus de evaluaci\u00b4 on. 160 6.2 Participaci\u00b4 on en Senseval Las medidas utilizadas para la evaluaci\u00b4 on de los sistemas de WSD son las siguientes: Precision =Instancias correctas contestadas Instancias contestadas(6.1) Cobertura =Instancias correctas contestadas Total instancias(6.2) A continuaci\u00b4 on se describen las tareas en las que nuestros siste- mas de WSD han participado, junto con los resultados obtenidos y su clasicaci\u00b4 on respecto a otros sistemas participantes. 6.2.1 DRelevant: All Words La evaluaci\u00b4 on del m\u00b4 etodo de desambiguaci\u00b4 on DRelevant pre- sentado en este trabajo, se ha realizado sobre los textos de la tarea \"English all-words\" deSenseval-2 . Esta tarea consiste en palabras con contenido sem\u00b4 antico (nom- bres, verbos, adjetivos y adverbios), que aparecen en los textos proporcionados, para su posterior evaluaci\u00b4 on. El n\u00b4 umero total de palabras a desambiguar (nombres, verbos, adjetivos y adverbios) supone un total de 2473 instancias. Para evaluar la eciencia del m\u00b4 etodo, se han adoptado diferen- tes criterios atendiendo al tama no del contexto seleccionado y al n\u00b4 umero de dominios empleado para realizar el proceso de desam- biguaci\u00b4 on. En las siguientes secciones se detallan cada una de los experimentos realizados. 6.2.1.1 Experimento 1: Oraci\u00b4 on como contexto. En este primer experimento, el contexto seleccionado para rea- lizar el proceso de desambiguaci\u00b4 on es la oraci\u00b4 on. Es decir, a partir del corpus proporcionado se extraen todas las oraciones, se anali- zan morfol\u00b4 ogicamente mediante el \"Tree-tagger\" y se guardan los nombres, verbos, adjetivos y adverbios de cada oraci\u00b4 on en dife- rentes cheros, que ser\u00b4 an la entrada para el sistema DRelevant. 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 161 En la Tabla 6.1, se muestra la eciencia del m\u00b4 etodo con el criterio de utilizar como contexto la oraci\u00b4 on. Contexto: Oraci\u00b4 on Precisi\u00b4 on Cobertura Cobertura Absoluta 44 % 32 % 73 % Tabla 6.1. Medida de la eciencia utilizando como contexto la oraci\u00b4 on Tras el proceso de desambiguaci\u00b4 on, el n\u00b4 umero de palabras correctamente desambiguadas no super\u00b4 o el 50 % del n\u00b4 umero total de instancias. Estos resultados son debidos en gran medida a la escasa informaci\u00b4 on que aporta el contexto de la oraci\u00b4 on, ya que, el n\u00b4 umero de palabras proporcionadas por la oraci\u00b4 on no es sucien- te para obtener una buena informaci\u00b4 on contextual y determinar correctamente los sentidos. 6.2.1.2 Experimento 2: Ventana de 100 palabras como contexto. En esta segunda prueba, se establece como contexto una venta- na de 100 palabras alrededor de cada palabra ambigua. Es decir, para cada una de las palabras a desambiguar se extraen las 100 pa- labras con contenido sem\u00b4 antico que la rodean (50 palabras previas y 50 palabras posteriores). Por ejemplo, si quisi\u00b4 eramos desambi- guar la palabra 'sound' do ser\u00b4 a el siguiente: \"(50 palabras previas)... Then, at a signal, the ringers begin varying the order in which the bells sound without altering the steady rhythm of the striking...(50 palabras posteriores)\" En caso de que no se pudieran extraer las 50 palabras anterio- res a la palabra a desambiguar, porque se ha llegado al comienzo del texto, el contexto de 100 palabras se completar\u00b4 a con la in- formaci\u00b4 on de las palabras posteriores a la palabra ambigua. Del mismo modo, en caso de que no se pudieran extraer las 50 pala- bras posteriores a la palabra a desambiguar porque se ha llegado 162 6.2 Participaci\u00b4 on en Senseval al nal del texto, el resto, se extraer\u00b4 a a partir de las palabras anteriores a la palabra ambigua. En la Tabla 6.2se muestra la eciencia del m\u00b4 etodo al utilizar como contexto una ventana de 100 palabras. En este caso tanto la precisi\u00b4 on, como la cobertura y la cobertura absoluta sufren un incremento, llegando a alcanzar el 47 %, el 38 % y el 81 % respectivamente. Contexto: Ventana de 100 palabras Precisi\u00b4 on Cobertura Cobertura Absoluta 47 % 38 % 81 % Tabla 6.2. Medida de la eciencia utilizando como contexto una ventana de 100 palabras A la vista de los resultados obtenidos, es evidente la necesidad de disponer de un contexto lo sucientemente amplio, para esta- blecer correctamente los sentidos de las palabras. 6.2.1.3 Experimento 3: Reducci\u00b4 on y agrupaci\u00b4 on de los do- minios. En este experimento, se intenta minimizar el nivel de especiali- zaci\u00b4 on de los dominios. Este proceso se ha realizado partiendo de la estructuraci\u00b4 on jer\u00b4 arquica de los dominios en WordNet Domains. En este caso, se agrupan dentro de un dominio que se encuentra en un nivel superior de la jerarqu\u00b4 a, aquellos subdominios que de- penden de \u00b4 el. Es decir, se agrupan dentro de un mismo dominio el conjunto de dominios que pertenecen a su misma jerarqu\u00b4 a pe- ro que est\u00b4 an en los niveles inferiores. Por ejemplo, en el caso de la jerarqu\u00b4 a del dominio Medicine , se encuentran por debajo de \u00b4 ,Pharmacy ,Psychiatry ,Radio- logy ySurgery dentro del dominio Medicine , y as\u00b4 se reduce el espacio de b\u00b4 usqueda y el grado de especializaci\u00b4 on. Obteniendo nalmente 43 dominios, sobre los 165 dominios iniciales. 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 163 La reducci\u00b4 on del nivel de especializaci\u00b4 on de los dominios requie- re una nueva anotaci\u00b4 on de los sentidos de las palabras de WordNet y por tanto, una nueva obtenci\u00b4 on de los dominios relevantes jun- to con su correspondiente ratio de asociaci\u00b4 on. Esta tarea se ha realizado previamente a la aplicaci\u00b4 on del sistema DRelevant. Dado que los resultados a partir de una ventana contextual de 100 palabras han demostrado obtener mejores resultados en el proceso de anotaci\u00b4 on de sentidos, este experimento, se rea- liz\u00b4 o manteniendo la ventana de 100 palabras y utilizando la re- ducci\u00b4 on del nivel de especializaci\u00b4 on de los dominios. En este caso, tras analizar los resultados obtenidos, se vuelve a incrementar el n\u00b4 umero de palabras correctamente desambiguadas, y por consiguiente, la precisi\u00b4 on tambi\u00b4 en sufre un incremento, tal y como se muestra en la Tabla 6.3. Reducci\u00b4 on del n\u00b4 umero de dominios Precisi\u00b4 on Cobertura Cobertura Absoluta 48 % 41 % 85 % Tabla 6.3. Medida de la eciencia reduciendo el nivel de especializaci\u00b4 on de los dominios Se hace patente, por tanto, que la reducci\u00b4 on del nivel de espe- cializaci\u00b4 on de los dominios, influye positivamente en el proceso de desambiguaci\u00b4 on. 6.2.1.4 Experimento 4: Desambiguaci\u00b4 on a nivel de domi- nio. El \u00b4 ultimo experimento realizado, se basa en la necesidad de reducir el n\u00b4 umero de sentidos de una misma palabra proporcio- nados por WordNet. Es decir, en WordNet, la distinci\u00b4 on entre los distintos sentidos de una palabra es en algunos casos muy dif\u00b4 cil de establecer, es lo que se denomina granularidad na, como se comentaba al principio de esta secci\u00b4 on. Para intentar reducir es- ta granularidad se agrupan aquellos sentidos etiquetados con el 164 6.2 Participaci\u00b4 on en Senseval mismo dominio. De esta forma, el resultado de la desambiguaci\u00b4 on para una palabra, no ser\u00b4 a un \u00b4 unico sentido, sino todos aquellos sentidos de la palabra que tengan asociado el mismo dominio que se obtenga tras el proceso de desambiguaci\u00b4 on. Por ejemplo, su- pongamos que tras el proceso de desambiguaci\u00b4 on de la palabra \"bank\" , se obtiene el dominio Economy , entonces dar\u00b4 amos co- mo resultado los tres asociados a este dominio: bank#1 , bank#3 se realiz\u00b4 o utili- zando los 165 de la jerarqu\u00b4 a de WordNet Domains. La opci\u00b4 on de reducir la granularidad a partir de reducir el nivel de especializaci\u00b4 on de dominios no se ha planteado, porque se reducen dram\u00b4 aticamente el n\u00b4 umero de sentidos de las palabras. En este caso, los resultados obtenidos reportan una precisi\u00b4 on del 54 %, tal y como se muestra en la Tabla 6.4. Desambiguaci\u00b4 on a nivel de dominio Precisi\u00b4 on Cobertura Cobertura Absoluta 54 % 43 % 80 % Tabla 6.4. Medida de la eciencia desambiguando a nivel de dominio As\u00b4 pues, la agrupaci\u00b4 on de sentidos como cab\u00b4 a esperar obtiene mejores resultados. En muchos casos, la distinci\u00b4 on de sentidos es demasiado na, y es muy dif\u00b4 cil establecer la l\u00b4 nea que diferencia un sentido de otro, por tanto, la agrupaci\u00b4 on resuelve este dilema. 6.2.1.5 Comparativa con otros sistemas. La evaluaci\u00b4 on del sistema DRelevant aqu\u00b4 presentado sobre la tarea \"English all-words\" deSenseval-2 , tiene como nalidad el poder establecer una comparativa con el resto de sistemas no supervisados, que participaron en esta edici\u00b4 on. Esta comparaci\u00b4 on se realiza atendiendo a las medidas de precisi\u00b4 on y cobertura. 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 165 En la Tabla 6.5se muestran los resultados obtenidos por los distintos sistemas que participaron en la tarea \"English all-words\" deSenseval-2 6.5. Comparaci\u00b4 on de los resultados de los distintos sistemas participantes en la tarea \"English all-words\" deSenseval-2 . A continuaci\u00b4 on vamos a evaluar la posici\u00b4 on alcanzada por nues- tro sistema en cada uno de los experimentos realizados: Experimento 1. Este experimento trata de evaluar la ecien- cia del m\u00b4 etodo de desambiguaci\u00b4 on propuesto, utilizando como contexto las palabras de la oraci\u00b4 on donde aparece la instan- cia a desambiguar. En este caso, la precisi\u00b4 on obtenida es de 166 6.2 Participaci\u00b4 on en Senseval un 44 % y la cobertura es de un 32 %. Con estos resultados nuestro sistema se situar\u00b4 a en la posici\u00b4 on 14 por delante del sistema de Agirre2-ehu-dlist-all. Experimento 2. En este experimento el contexto utilizado se ampl\u00b4 a mediante la utilizaci\u00b4 on de una ventana de 100 pala- bras alrededor de la instancia a desambiguar. En este caso, la precisi\u00b4 on obtenida es de un 47 % y la cobertura es de un 38 %. Con los resultados obtenidos en este experimento nuestro sis- tema se situar\u00b4 a en la posici\u00b4 on 10 por delante del m\u00b4 etodo de Magnini2-irst-eng-all. Este dato supone que nuestro m\u00b4 etodo mejora los resultados obtenidos por el m\u00b4 etodo de Magnini, e indica que la utilizaci\u00b4 on de las glosas de WordNet Domains pa- ra extraer el recurso l\u00b4 exico Dominios Relevantes y su posterior utilizaci\u00b4 on en un m\u00b4 etodo de WSD ofrece buenos resultados. Experimento 3. En este experimento se reduce el nivel de es- pecializaci\u00b4 on de los dominios y se utiliza una ventana de 100 palabras alrededor de la instancia a desambiguar. Se obtiene un 48 % de precisi\u00b4 on y un 41 % de cobertura. Los resultados obtenidos en este experimento mejoran la precisi\u00b4 on y la co- bertura del experimento anterior, pero no suponen un cambio en la posici\u00b4 on alcanzada por nuestro sistema con respecto a los otros participantes de Senseval-2 Experimento 4. En este experimento se trata de reducir el problema de la granularidad na de WordNet agrupando aquellos sentidos de una misma palabra, que comparten un mismo dominio. En este caso, la precisi\u00b4 on obtenida es de un 54 % y la cobertura es de un 43 %. Aqu\u00b4 ocurre lo mismo que en experimento anterior, los valores de precisi\u00b4 on y cobertura sufren una mejora, pero no lo suciente como para mejorar la posici\u00b4 on de nuestro sistema. En denitiva, la utilizaci\u00b4 on del recurso l\u00b4 exico Dominios aplicaci\u00b4 etodo de WSD, ofrece unos resul- tados prometedores con respecto a los actuales sistemas de de- sambiguaci\u00b4 on autom\u00b4 atica del sentido de las palabras. Adem\u00b4 as, el recurso Dominios Relevantes, ofrece informaci\u00b4 on muy \u00b4 util para re- lacionar sem\u00b4 anticamente diferentes palabras, y puede ser utilizado 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 167 como recurso para otras tareas de PLN, tal y como se demues- tra en las siguientes secciones: reconocimiento de la implicaci\u00b4 on textual, discriminaci\u00b4 on de nombres, etc. 6.2.2 DRelevant mejorado con Extended WordNet El recurso l\u00b4 exico Dominios Relevantes, utilizado como base de conocimiento del m\u00b4 etodo de desambiguaci\u00b4 on DRelevant, puede ser mejorado si se utiliza para su construcci\u00b4 on Extended WordNet en lugar de WordNet Domains. Como ya se coment\u00b4 o en el cap\u00b4 tulo anterior, Extended WordNet proporciona informaci\u00b4 on adicional acerca de los sentidos de las palabras de las glosas. Esta informa- ci\u00b4 on ha sido utilizada para obtener de nuevo el recurso Dominios Relevantes mejorado. Utilizando esta nueva versi\u00b4 on de DR se han realizado los mis- mos experimentos para la tarea all-words obteniendo los resulta- dos mostrados en la Tabla 6.6. Opci\u00b4 on Precisi\u00b4 on Recall Contexto oraci\u00b4 on del num. de dominios 0.62 0.50 a nivel de dominio 0.63 0.56 Tabla 6.6. Evaluaci\u00b4 on de WSD DRelevant usando Extended WordNet A la vista de los resultados, se aprecia una mejora sobre los anteriores experimentos. Se produce un aumento del 12 % a nivel de precisi\u00b4 on en el experimento que toma como contexto la oraci\u00b4 on. Un 4 % de mejora con respecto al experimento que utiliza una ventana de 100 palabras y el experimento que reduce el n\u00b4 umero de dominios, agrupando aquellos que descienden del mismo concepto. Lo mismo ocurre con el \u00b4 ultimo experimento, que trata de evitar la granularidad na de WordNet, desambiguando a nivel de dominio en lugar de a nivel de sentido. Podemos concluir que la elecci\u00b4 on de los contextos y la infor- maci\u00b4 on proporcionada por \u00b4 estos, son fundamentales para la ob- 168 6.2 Participaci\u00b4 on en Senseval tenci\u00b4 on del recurso Dominios Relevantes. Adem\u00b4 as, una buena ca- lidad de los DR supone una mejora de los resultados del sistema WSD Relevant. De esta forma, con los nuevos resultados nuestro sistema escala cinco posiciones con respecto al resto de sistemas participantes en la tarea \"all-words\" . 6.2.3 R2D2: English All Words y del marco del proyecto R2D2 (Recuperaci\u00b4 on de Res- puestas en Documentos Digitalizados)5se particip\u00b4 o en la tercera edici\u00b4 on de Senseval . El objetivo de esta participaci\u00b4 on fue eva- luar el resultado de la combinaci\u00b4 on de diferentes sistemas de WSD dentro de las tareas English All-Words y English Lexical Sample. Para llevar a cabo el experimento se combinaron tanto siste- mas supervisados como sistemas no supervisados. De forma que se intent\u00b4 o paliar la falta en muchos casos de ejemplos de entre- namiento para los sistemas supervisados que imped\u00b4 a la correcta detecci\u00b4 on de los sentidos, incorporando m\u00b4 etodos no supervisados que no necesitaban ejemplos de entrenamiento. Los sistemas participantes para la tarea English All-words fue- ron cuatro: Maximum Entropy, sistemas: La Tabla 6.7muestra las caracter\u00b4 sticas de cada uno de los sistemas participantes. 6.2.3.1 R2D2: English All Words. En la Tabla 6.8se presentan los resultados obtenidos para los diferentes sistemas participantes, tanto supervisados como no su- pervisados. En este caso, se han tomado como v\u00b4 alidas aquellas respuestas anotadas como desconocidas por todos los sistemas. De esta forma, tanto precisi\u00b4 on como cobertura coinciden debido a que siempre se contesta el 100 % de las instancias. El sistema R2D2 resultado de la combinaci\u00b4 on de sistemas WSD supervisados 5Proyecto nanciado por el Ministerio de Ciencia y Tecnolog\u00b4 a. TIC2003-07158- C04-01 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 169 Sistemas Descripci\u00b4 on Maximum entropy Sistema supervisado basado en los modelos de pro- babilidad de M\u00b4 axima entrop\u00b4 a. Este sistema uti- liza un conjunto de caracter\u00b4 sticas y un conjunto de ejemplos de entrenamiento extra\u00b4 dos del cor- pus Semcor para resolver y supervisado basado en modelos especiali- zados ocultos de Markov (Specialized Hidden Mar- kov Models) ( Molina et al. (2002 )). DRelevant Sistema no supervisado basado en la adquisici\u00b4 on de conocimiento a trav\u00b4 es de WordNet Domains (Montoyo et al. (2003 )). CIAOSENSO Sistema no supervisado basado en densidad con- ceptual, frecuencia de sentidos de WordNet y WordNet Domains ( Rosso et al. (2003 )). LVQ-Jaen-ELS Sistema supervisado basado en redes neurona- les utilizando LVQ, integrando Semcor y varias relaciones sem\u00b4 anticas de WordNet ( Vega et al. (2003 )). Tabla 6.7. Sistemas participantes en el equipo R2D2 y no supervisados, se coloca en cuarto lugar respecto al resto de sistemas participantes. El sistema de votaci\u00b4 on utilizado en esta tarea combina los re- sultados de los diferentes sistemas de WSD seg\u00b4 un se muestra en la Figura 6.1. MAX. ENT. UPV-SHMM DRELEVANT CIAOSENSO X X -- -- X -- X -- X -- -- X -- X -- X -- X X -- -- -- X X X -- -- -- -- X -- -- -- -- X -- -- -- -- X 1 2 3 4 5 6 7 8 9 10 Figura 6.1. Sistema de votaci\u00b4 on R2D2 All Words 170 6.2 Participaci\u00b4 on en Senseval Inicialmente se le da preferencia a aquellos sentidos dados como respuesta por la mayor\u00b4 a de sistemas. Pero en caso de no existir acuerdo, se decide el sentido correcto en un m\u00b4 aximo de 10 pasos. Tal y como muestra la Figura 6.1el primer paso da preferencia a los sistemas supervisados, si no existe acuerdo, el segundo paso comprueba el acuerdo entre Max. Ent. y DRelevant... El sistema de votaci\u00b4 on contin\u00b4 ua hasta que en alg\u00b4 un paso exista acuerdo, si no es as\u00b4 , los sentidos que han permanecido sin anotar se deciden en \u00b4 ultima instancia por un solo sistema, dando siempre preferencia a los sistemas supervisados. con validaci\u00b4 on de respuestas no anotadas 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 171 En la Tabla 6.9se muestran los resultados obtenidos, ignoran- do las respuestas no anotadas. De esta forma, ya no existe un 100 % en el n\u00b4 umero de respuestas anotadas, sino que \u00b4 este se redu- ce al no tenerse en cuenta instancias no anotadas con un sentido determinado. De esta forma, la precisi\u00b4 on y cobertura dieren en su valor. En este caso, respecto al sistema R2D2, los resultados no dieren en absoluto de los anteriores, debido a que siempre se responden el 100 % de las instancias, utilizando un m\u00b4 etodo de votaci\u00b4 on entre AllWords sin validaci\u00b4 on de respuestas no anotadas 172 6.2 Participaci\u00b4 on en Senseval 6.2.3.2 R2D2: English Lexical Sample. tarea English Lexical Sample el objetivo es desambiguar una serie de palabras etiquetadas dentro de un corpus: nombres, verbos y adjetivos. El m\u00b4 etodo utilizado para seleccionar el sentido nal de cada palabra, es un sistema de votaci\u00b4 on, donde el sentido m\u00b4 as votado por todos los sistemas es el seleccionado. En caso de no existir acuerdo entre varios sentidos se le da prioridad a los sistemas supervisados debido a que demuestran una mejor precisi\u00b4 on en esta tarea (sistema similar al presentado en la Figura 6.1). La Tabla 6.2.3.2 muestra los resultados obtenidos en esta tarea. Tabla 6.10: Sistemas participantes en la tarea English Lexical Sample de Senseval-3 Fine Coarse System/Team decision lists, SVM, evaluaci\u00b4 on 173 Tabla 6.10: Sistemas participantes en la tarea English Lexical Sample de Senseval-3 (continuaci\u00b4 on) Fine model, and feature se- lection, using a rich feature uses SVM, and combines two with two one trained on the data provided, the other trained on this data, and on pointwise mutual information on a terabyte corpus. Fi- ve basic me maximum entropy classier. 69.3 76.4 en Senseval 6.10: Sistemas participantes en la tarea English Lexical Sample de Senseval-3 (continuaci\u00b4 on) Fine Coarse a con- text Support Vector Machines, using local and tem, with individual modules ba- sed the co-occurrence of nouns and evaluaci\u00b4 on 175 Tabla 6.10: Sistemas participantes en la tarea English Lexical Sample de Senseval-3 (continuaci\u00b4 on) Fine HMM basado en LSA, presentado en el cap\u00b4 tulo anterior ha sido evaluado sobre la m\u00b4 etodo utiliza como base para representar el conocimiento, una matriz [dominios - t\u00b4 erminos], donde cada columna se corresponde con una categor\u00b4 a sem\u00b4 antica de los dominios de WND, y cada la se corresponde con un t\u00b4 ermino (lema). Para la obtenci\u00b4 on de la ma- triz conceptual se utiliza como fuente de informaci\u00b4 on las glosas de WND, ya que, est\u00b4 an anotadas con sus correspondientes categor\u00b4 as 176 6.2 Participaci\u00b4 on en Senseval sem\u00b4 anticas (dominio). Finalmente, tras la obtenci\u00b4 on de la matriz, el espacio conceptual se reduce a una matriz de 100 dimensiones. En el proceso de desambiguaci\u00b4 on se ha utilizado el m\u00b4 etodo DL- SA con dos aproximaciones diferentes: una primera aproximaci\u00b4 on utilizando como matriz conceptual todo el conjunto de palabras con contenido sem\u00b4 antico (nombres, verbos, adjetivos y adverbios) y una segunda aproximaci\u00b4 on restringiendo el tipo de categor\u00b4 as sem\u00b4 anticas en la matriz (s\u00b4 olo nombres, s\u00b4 olo verbos o s\u00b4 olo adje- tivos). El objetivo de estas dos aproximaciones es determinar si existe alguna interferencia motivada por el uso de contextos m\u00b4 as o menos restringidos. 6.2.4.1 Matriz conceptual NVAR. En esta secci\u00b4 on se presentan los resultados obtenidos por el m\u00b4 etodo DLSA utilizando como fuente de informaci\u00b4 on una ma- triz conceptual construida a partir de todos los nombres, verbos, adjetivos y adverbios de las glosas de WordNet. Para realizar la codicaci\u00b4 on de la matriz se han obtenido previamente los lemas de las palabras de las glosas de WordNet. Esto se debe a que LSA toma como datos diferentes un nombre en plural y el mismo nom- bre en singular. Nuestra hip\u00b4 otesis es que ni el tiempo verbal, ni los plurales alteran el contenido sem\u00b4 antico de las palabras de un contexto. Una vez obtenida la matriz inicial con 162 dimensio- nes, cada una de ellas correspondiendo a un dominio de WND, se procede a la reducci\u00b4 on de la matriz a \u00b4 unicamente 100 dimensio- nes. A partir de aqu\u00b4 se han utilizado diferentes heur\u00b4 sticas para determinar el sentido correcto de cada palabra: 20 dominios m\u00b4 as relevantes: Sobre los 20 primeros dominios obtenidos por el algoritmo de LSA. 10 dominios m\u00b4 as relevantes: Sobre los 10 primeros dominios obtenidos por el algoritmo de LSA. Pasos para la obtenci\u00b4 on del sentido correcto DLSA WSD: 1.Aplicar LSA sobre el contexto de la palabra ambigua. Devuelve los dominios con el grado de similitud m\u00b4 as elevado respecto al contexto. 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 177 2.Comparar los dominios obtenidos con LSA con los do- minios relevantes de cada sentido de la palabra ambi- gua. Para cada sentido de la palabra ambigua, se seleccionan aquellos dominios que coinciden con los Dominios Relevantes de ese sentido. 3.Selecci\u00b4 on de heur\u00b4 stica (para cada posible sentido): 3.1. Se suman los valores del Ratio de Asociaci\u00b4 on (RA) para cada uno de los dominios seleccionados. 3.2. Se suman los valores de similitud obtenidos con LSA para los dominios seleccionados (esta heur\u00b4 stica es la que pro- porciona mejores resultados). 3.3 En este tercera heur\u00b4 stica, los dominios obtenidos por LSA tienen asociado un valor de similitud, que ser\u00b4 a m\u00b4 as eleva- do cuanto mayor sea la similitud del contexto con el dominio. Para dar mayor peso a los dominios con mayor valor de simi- litud se ha optado por realizar el producto de los valores de similitud de LSA por el RA. De esta forma se le da prioridad a los dominios con mayor valor de similitud. En la Tabla 6.11 se muestran los resultados obtenidos para cada heur\u00b4 stica. 10 dominios 20 dominos Fine Coarse Fine stica 1 aplicado sobre todas las categor\u00b4 as NVAR Seg\u00b4 un la Tabla 6.11, la Heur\u00b4 stica 2 proporciona los mejores resultados. En este caso, aplicando LSA sobre una matriz concep- 178 6.2 Participaci\u00b4 on en Senseval tual con categor\u00b4 as sem\u00b4 anticas (nombres, verbos, adje- tivos y adverbios), se alcanza una precisi\u00b4 on de alrededor de 45 % en el caso de evaluar el sistema con granularidad na y de un 55 % en el caso de evaluar el sistema con granularidad gruesa. Los valores obtenidos tambi\u00b4 en demuestran que la utilizaci\u00b4 on de los 10 primeros dominios como fuente de informaci\u00b4 on sem\u00b4 antica es su- ciente para alcanzar buenos resultados. En cambio, la utilizaci\u00b4 on de los 20 primeros dominios empeora los resultados gradualmente. 6.2.4.2 Matriz conceptual N-V-A. Los resultados obtenidos tras la evaluaci\u00b4 on de los nombres (aproximaci\u00b4 on matriz con s\u00b4 olo nombres) se reflejan en la Tabla 6.12, donde se muestra el grado de precisi\u00b4 on/recall obtenidos para cada palabra en concreto. En todos nuestros experimentos, siem- pre se han contestado todas las instancias, por tanto, precisi\u00b4 on y recall alcanzan el mismo resultado. Para los verbos y los adjetivos, los resultados individuales ob- tenidos (aproximaci\u00b4 on matriz s\u00b4 olo verbos y s\u00b4 olo adjetivos) son los mostrados en las Tablas 6.13y6.14. En la Tabla 6.15 se muestran los resultados obtenidos para cada heur\u00b4 stica. Al igual que suced\u00b4 a en el experimento anterior, los mejores resultados seg\u00b4 un la Tabla 6.15son los de la Heur\u00b4 stica 2. En este caso se han realizado tres matrices conceptuales distintas, una por cada categor\u00b4 a (N, V, A o R). En este caso, los resultados obteni- dos en este \u00b4 ultimo experimento, mejoran los anteriores. Es decir, especializando las matrices conceptuales y restringiendo el uso de categor\u00b4 as l\u00b4 exicas, se pueden mejorar los resultados en el proceso de desambiguaci\u00b4 on. De esta forma, si se trata de desambiguar un nombre, la informaci\u00b4 on contextual perteneciente a los nombres que lo rodean proporciona un mejor indicativo de sus relaciones sem\u00b4 anticas, que todas las dem\u00b4 as palabras que lo rodean. 6. Experimentaci\u00b4 on y evaluaci\u00b4 on shelter 32.98 sort 82.89 source 68.96 Tabla 6.12. Resultados ELS sobre nombres 6.2.4.3 Comparativa con otros sistemas. En la tarea \"English Lexical Sample\" , participaron tanto sis- temas supervisados como sistemas no supervisados. Los prime- ros obtuvieron mejores resultados alcanzando el mejor sistema un 72.9 % de precisi\u00b4 on y cobertura ( Grozea (2004 )). Con respecto a los sistemas no supervisados, el mejor sistema obtuvo un 66.1 % de precisi\u00b4 on ( Ramakrishnan et al. (2004 )). Dado que DLSA es un sistema no supervisado, realizaremos la comparativa de los resul- tados obtenidos con estos \u00b4 ultimos. En la Tabla 6.16se muestran los resultados obtenidos para cada uno de los sistemas participan- tes junto con una breve descripci\u00b4 on de cada uno de ellos. La heur\u00b4 stica que mejores resultados proporciona para nuestro m\u00b4 etodo DLSA es la heur\u00b4 stica 2, la cual, selecciona el sentido m\u00b4 as adecuado a partir de la intersecci\u00b4 on de los dominios obtenidos por 180 6.2 Participaci\u00b4 on en 98.03 win 50 write 19.09 Tabla 6.13. Resultados ELS sobre verbos 6. Experimentaci\u00b4 on y evaluaci\u00b4 on Tabla 6.14. Resultados ELS sobre adjetivos 10 dominios 20 dominios Fine Coarse Fine Coarse Nombres Heur\u00b4 stica Tabla 6.15. DLSA aplicado sobre cada categor\u00b4 a por separado LSA y los dominios relevantes del vector de sentidos, utilizando \u00b4 unicamente los valores de similitud obtenidos por LSA. El resultado global tras la evaluaci\u00b4 on sobre el corpus de test deSenseval-3 , posiciona nuestro sistema en cuarto lugar con respecto al resto de sistemas no supervisados participantes en la tarea English Lexical Sample. 6.2.5 SenseDiscrim: Spanish reglas ling\u00a8 u\u00b4 sticas aplicadas sobre corpus y en la obtenci\u00b4 on de conjuntos de discriminadores de sentidos sobre WordNet, se ha evaluado sobre el corpus de test deSenseval-3 en la tarea Spanish Lexical Sample. Dado que este sistema actualmente se ha desarrollado para la desambiguaci\u00b4 on de nombres, es necesaria la combinaci\u00b4 on con otro 182 6.2 Participaci\u00b4 on en Senseval Fine Coarse Sistema Descripci\u00b4 on P R P R wsdiit IIT Bombay (Ramakrish- nan et al.) Utiliza la medida de similitud de Lesk entre los contextos de palabras ambi- trop\u00b4 a para clustering University Heur\u00b4 48.9 54.2 54.2 acticas, sem\u00b4 de subcategorizaci\u00b4 on, 45.0 45.0 55.5 55.5 CIAOSENSO U. Genova (Buscaldi) Combina la densidad conceptual con la frecuencia de palabras y la infor- maci\u00b4 on proporcionada por dominios. 50.1 41.7 59.1 49.3 KUNLP Korea U. (Seo) Selecciona el sentido de las palabras utilizando sustitutos a trav\u00b4 es de la je- rarqu\u00b4 a hi- per\u00b4 onimos, etc). selecci\u00b4 a partir de la co-ocurrencia de (Pedersen) Asigna el relacionado con los posibles sentidos de las pala- bras vecinas. Se utilizan las glosas de WordNet para medir la similitud en- tre sentidos. 40.3 38.5 51.0 48.7 DFA-LS- Unsup Combina tres heur\u00b4 sticas: similitud entre sin\u00b4 onimos y el contexto, de acuerdo a la medida de la informa- ci\u00b4 on mutua; patrones l\u00b4 exico-sint\u00b4 acti- cos a de las glosas de WordNet y la heur\u00b4 stica del primer sentido. 23.4 23.4 27.4 27.4 Tabla 6.16. Sistemas no supervisados en la tarea ELS de Senseval-3 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 183 sistema para responder a las instancias referentes a verbos y adje- tivos. En nuestro caso, se ha optado por la utilizaci\u00b4 on del sistema supervisado de M\u00b4 axima trado obtener una alta precisi\u00b4 on en el proceso de desambiguaci\u00b4 on. En la tarea Spanish Lexical Sample se deb\u00b4 an desambiguar 21 nombres: arte, autoridad, banda, canal, circuito, columna, co- raz\u00b4 on, corona, gracia, grano, hermano, letra, masa, mina, natu- raleza, operaci\u00b4 on, \u00b4 organo, partido, pasaje, programa y tabla. De estos 21 nombres s\u00b4 olo se realiz\u00b4 o un an\u00b4 alisis parcial de los 13 nom- bres mostrados en la Tabla 6.17. El objetivo principal de la evaluaci\u00b4 on del sistema SenseDiscrim, es demostrar que mediante la elecci\u00b4 on de un determinado n\u00b4 umero de patrones de los que se puede extraer informaci\u00b4 on paradigm\u00b4 atica y de un conjunto de discriminadores de sentidos, se puede obtener una alta precisi\u00b4 on que supera a la mayor\u00b4 a de sistemas actuales. Para la adquisici\u00b4 on de informaci\u00b4 on paradigm\u00b4 atica a partir de patrones sintagm\u00b4 aticos se ha utilizado el corpus EFE sobre no- ticias en espa nol, junto con un umbral= 5 de frecuencia m\u00b4 nima para la extracci\u00b4 on de informaci\u00b4 on. El procedimiento seguido para la desambiguaci\u00b4 on de nombres es el siguiente: 1.Se identican los 2.Se paradigm\u00b4 atica de los patrones iden- ticados utilizando el corpus EFE como corpus de b\u00b4 usqueda. 3.Se utiliza el algoritmo de Prueba de Conmutabilidad estable- ciendo un sentido para cada patr\u00b4 on identicado en el paso previo. 4.Para cada patr\u00b4 on: se interseccionan las propuestas de sentidos a partir de la informaci\u00b4 on sintagm\u00b4 atica y de la informaci\u00b4 on paradigm\u00b4 atica. El sentido propuesto por la mayor\u00b4 a de los pa- trones es seleccionado. En caso, de no existir acuerdo, se da preferencia al sentido m\u00b4 as frecuente en WordNet. El an\u00b4 alisis posterior de los resultados demuestra que para la mitad de los nombres de la tarea de \"Spanish Lexical Sample\" , no existe informaci\u00b4 on suciente en el corpus EFE que permita 184 6.2 Participaci\u00b4 on en Senseval Palabra Ocurrencias Contestadas Correctas Cobertura Precisi\u00b4 on autoridad 132 38 35 28.79 % 92.11 % canal 131 21 21 16.03 % 100 % circuito 132 3 1 1.52 % 50 % corona 64 0 0 0 % 0 % gracia 38 0 0 0 % 0 % grano 61 2 0 3.28 % 0 % hermano 66 0 0 0 % 0 % masa 85 0 0 0 % 0 % naturaleza 128 0 0 0 % 0 % partido 66 17 14 25.76 % 82.35 % pasaje 111 0 0 0 % 0 % programa 133 26 23 19.55 % 88.46 % tabla 64 0 0 0 % 0 % Tabla 6.17. Resultados del sistema SenseDiscrim para los nombres de la tarea Spanish Lexical Sample de Senseval-3 identicar patrones con un grado de abilidad elevado. En cam- bio, para el resto de nombres identicados, la precisi\u00b4 on obtenida es muy elevada, tal y como se pretend\u00b4 a demostrar. En nuestro caso, mediante la utilizaci\u00b4 on de patrones y la combinaci\u00b4 on de la informaci\u00b4 on paradigm\u00b4 atica y el conjunto de discriminadores de sentidos de WordNet, es posible realizar una desambiguaci\u00b4 on con una alta ecacia. 6.2.5.1 Evaluaci\u00b4 on de los resultados. Los resultados obtenidos tras la evaluaci\u00b4 on fueron de un 84 % de precisi\u00b4 on y un 47 % de cobertura. Cabe destacar que los resul- tados en cuanto a precisi\u00b4 on son excelentes en detrimento de una baja cobertura. Esto es debido en gran parte, a la escasez de cor- pus en espa nol, lo que supone un impedimento para la extracci\u00b4 on de informaci\u00b4 on paradigm\u00b4 atica. La Tabla 6.18 muestra los resultados obtenidos por los siste- mas que participaron en la tarea \"Spanish Lexical Sample\" de Senseval-3 . % 85.98 Tabla 6.18. Resultados de los sistemas participantes en la tarea Spanish Lexical Sample Senseval-3 Los resultados mostrados en la Tabla 6.18se encuentran orde- nados seg\u00b4 un la medida F\u00af=1. Nuestro sistema alcanza la mayor precisi\u00b4 on, sin embargo, obtiene una cobertura muy baja debido a la escasez de corpus de los que extraer patrones e informaci\u00b4 on paradigm\u00b4 atica. El mejor sistema en esta tarea fue IRST ( Strapparava et al. (2004 )) que utilizaba SVM como algoritmo de aprendizaje. Este sistema obtuvo los mejores resultados para las palabras con menos ejemplos por sentido. Los dos \u00b4 ultimos sistemas mostrados en la tabla corresponden a un sistema utilizado como baseline MFC (Most Frequent Sen- se Clasier) y un sistema de votaci\u00b4 on COMB que combina las respuestas de los mejores sistemas en la tarea. 6.2.6 Web People Search En la cuarta edici\u00b4 on de Senseval se present\u00b4 o una nueva tarea denominada \"Web People Search\" (WePS), esta tarea tiene co- mo objetivo la detecci\u00b4 on y clasicaci\u00b4 on de distintos documentos (p\u00b4 aginas web) a partir de los nombres propios que aparecen en ellos. La dicultad de esta tarea viene determinada por la exis- tencia de nombres propios ambiguos que aparecen en diferentes 186 6.2 Participaci\u00b4 on en Senseval contextos. Es por tanto necesario distinguir entre los distintos contextos de los documentos y establecer para cada contexto los nombres propios relacionados con ellos. Debido a la necesidad de utilizar la informaci\u00b4 on contextual co- mo base para la detecci\u00b4 on y distinci\u00b4 on de diferentes entidades, se ha considerado viable la utilizaci\u00b4 on de la t\u00b4 ecnica de LSA para esta tarea. En concreto, se ha utilizado LSA para la agrupaci\u00b4 on de contextos similares a partir de la informaci\u00b4 on sem\u00b4 antica conte- nida. Tras la obtenci\u00b4 on de los contextos similares se ha utilizado una t\u00b4 ecnica de clustering para la creaci\u00b4 on de conjuntos disjuntos de documentos. El sistema presentado en esta tarea consta de varios m\u00b4 odulos. A continuaci\u00b4 on se describen cada uno M\u00b4 odulo de preproceso. El de rea- lizar el preproceso de los documentos de entrada. Dado que todos los documentos son p\u00b4 aginas web, existen etiquetas es- pec\u00b4 cas del lenguaje HTML y c\u00b4 odigo Javascript que no deben tenerse en cuenta. Por tanto, mediante un proceso de detec- ci\u00b4 on y eliminaci\u00b4 on de elementos propios del lenguaje HTML se obtiene \u00b4 unicamente el texto comprendido entre las etiquetas <title> </title >y las etiquetas <body on contextual. En es- te m\u00b4 odulo se utilizan los resultados obtenidos en el m\u00b4 odulo de preproceso para la extracci\u00b4 on de informaci\u00b4 on relevante que ayude a identicar correctamente los diferentes contextos. Es- te m\u00b4 odulo se divide en cuatro sub-procesos: \u00b2Detecci\u00b4 on de nombres. Todos los nombres propios del contexto (personas, organizaciones, lugares, etc), son detec- tados y extra\u00b4 dos. Para esta tarea se ha utilizado la arqui- tectura GATE6(Cunningham (2002 ),Cunningham (2005 )) que integra un odulo de detecci\u00b4 on de entidades. El objeti- vo de este sub-m\u00b4 odulo es obtener los nombres propios de las diferentes categor\u00b4 as y detectar sus ocurrencias en el resto de documentos. De esta forma, documentos que compartan las mismas entidades pueden hacer referencia al mismo in- 6http://gate.ac.uk/ 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 187 dividuo. Este sub-m\u00b4 odulo retorna como salida una matriz de valores binarios, donde 1 signica que los documentos comparados comparten m\u00b4 as de la mitad de sus entidades y 0 cualquier otro caso. \u00b2Identicaci\u00b4 on de enlaces web. Para cada documento se han extra\u00b4 do los enlaces comprendidos entre las etiquetas <a href > </a>. Dado que los enlaces detectados son muy espec\u00b4 cos se ha empleado una funci\u00b4 on que extrae la ra\u00b4 z general de cada uno de los enlaces. Por ejemplo, la direc- ci\u00b4 ond1http://www.cs.ualberta.ca/~lindek/index.htm se transformar\u00b4 a en http://www.cs.ualberta.ca/~lindek . De esta forma si dos direcciones cualquiera d1yd2, compar- ten la misma ra\u00b4 z d1Td2se consideran la misma direcci\u00b4 on. El nivel de profundidad seleccionado de cada enlace es 3 niveles como m\u00b4 aximo y 2 niveles como m\u00b4 nimo. La salida de este sub-m\u00b4 odulo es una matriz de valores binarios con 1 si el par de documentos comparten m\u00b4 as de 3 enlaces y 0 en otro caso. \u00b2Detecci\u00b4 on de t\u00b4 tulos. Para cada documento se han ex- tra\u00b4 do los t\u00b4 tulos comprendidos entre las etiquetas <title> </title >.\u00b4Estos se han introducido en una matriz de uni- gramas utilizada como entrada para un sistema autom\u00b4 atico de clustering SenseClusters7. Mediante un criterio de cluste- ring con parada autom\u00b4 atica se han agrupado los diferentes documentos de acuerdo al contexto de los t\u00b4 tulos. Del resul- tado obtenido se ha generado una nueva matriz de valores binarios con 1 para los pares de documentos situados en el mismo cluster y 0 en otro caso. \u00b2Tratamiento del cuerpo de la p\u00b4 agina web. La parte de texto comprendida entre las etiquetas <body > </body >ha sido tratada para extraer las categor\u00b4 as sint\u00b4 acticas de las pa- labras usando Tree Tagger8. El resultado de este sub-m\u00b4 odulo es la anotaci\u00b4 on del texto con la on en Senseval de esta transformaci\u00b4 on es servir de entrada al m\u00b4 odulo de LSA para poner tener en cuenta las categor\u00b4 as sint\u00b4 acticas de las palabras y poder construir as\u00b4 una matriz conceptual m\u00b4 as precisa, ya que, no es lo mismo encontrar una palabra actuando como nombre (\"water#n\"), que actuando como verbo (\"water#v\"). M\u00b4 odulo de m\u00b4 odulo de cla- sicaci\u00b4 on de documentos en sus correspondientes clusters. En este m\u00b4 odulo se realizan tres sub-tareas. \u00b2LSA. Utilizando LSA, a partir de la codicaci\u00b4 on obtenida en el sub-m\u00b4 odulo de tratamiento del cuerpo de los docu- mentos, se construye la matriz conceptual. En esta matriz las las representan palabras de la colecci\u00b4 on de documentos y las columnas representan los documentos (p\u00b4 aginas web) y las celdas contienen le frecuencia de ocurrencia de cada palabra en cada documento. A continuaci\u00b4 on se ha reducido la matriz a 300 dimensiones para evitar el ruido causado por informaci\u00b4 on irrelevante. Finalmente, la salida de este sub- m\u00b4 odulo es una matriz que representa el grado de similitud entre los diferentes documentos. \u00b2Combinaci\u00b4 on de informaci\u00b4 on contextual. En este sub- m\u00b4 odulo se han combinado los resultados de la extracci\u00b4 on de informaci\u00b4 on referente a entidades, t\u00b4 tulos, enlaces y cuer- po de los documentos. Esta informaci\u00b4 on se ha introducido en una nueva matriz de 100x400 dimensiones. Las las se corresponden con el n\u00b4 umero de documentos y las columnas representan los valores obtenidos para las entidades, t\u00b4 tu- los, enlaces y cuerpo de los documentos. Esta matriz es la entrada a un algoritmo de clustering denominado K-means9 que determina el clustering de documentos a partir de esa informaci\u00b4 on. \u00b2K-means. Para realizar el enKconjuntos Sjque contienen Njpuntos de datos, se utiliza la minimizaci\u00b4 on del cuadrado de sumas 9http://www.cs.waikato.ac.nz/ml/weka/ 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 189 un dato y mujes el centroide geom\u00b4 etri- co de los puntos de datos en Sj. La matriz a partir de la cual se realiza el clustering incluye la informaci\u00b4 on del t\u00b4 tu- lo, enlaces, entidades y cuerpo de las p\u00b4 aginas web. En la implementaci\u00b4 on de K-means no existe un criterio de parada autom\u00b4 atico ( Witten y Frank (1999 )) por lo que se estable- ci\u00b4 o manualmente. La arquitectura del sistema WePS se muestra en la Figura 6.2. 6.2.6.1 Evaluaci\u00b4 on de los sistemas de la tarea WePS. Los datos utilizados para la evaluaci\u00b4 on de los sistemas en la tarea WePS fueron extra\u00b4 dos de Wikipedia, de las personas que participaron en ACL06 y del corpus Web03 ( Mann (2006 )) que contiene 32 nombres aleatorios extra\u00b4 dos del US Census. En la Tabla 6.19se muestra la relaci\u00b4 on de los diferentes nombres propios con su nivel de ambig\u00a8 uedad. Las medidas utilizadas para la evaluaci\u00b4 on de los distintos sis- temas fueron \"Purity\" e \"Inverse Purity\". La medida de \"Purity\" est\u00b4 a relacionada con la medida de Precisi\u00b4 on, muy utilizada en Re- cuperaci\u00b4 on de Informaci\u00b4 on. Esta medida se centra en la frecuencia de las categor\u00b4 as m\u00b4 as comunes en cada cluster y da mayor pun- tuaci\u00b4 on a los sistemas cuya clasicaci\u00b4 on introduce menos ruido en los clusters. Siendo Cel conjunto de clusters a ser evaluados, L el conjunto de categor\u00b4 as (anotadas manualmente) y nel n\u00b4 umero de elementos clasicados, la medida \"Purity\" en Senseval Nombre Entidades Documentos Descartados Wikipedia names Arthur Morgan 19 100 52 James Morehead 48 100 11 James Davidson 59 98 16 Patrick Killen 25 96 4 William Dickson 91 100 8 George Foster 42 99 11 James Hamilton 81 100 15 John Nelson 55 100 25 Thomas Fraser 73 100 13 Thomas Kirk 72 100 20 Average 56.50 99.30 17,50 ACL06 Names Dekang Lin 1 99 0 Chris Brockett 19 98 5 James Curran 63 99 9 Mark Johnson 70 99 7 Jerry Hobbs 15 99 7 Frank Keller 28 100 20 Leon Barrett 33 98 9 Robert Moore 38 98 28 Sharon Goldwater 2 97 4 Stephen Clark 41 97 39 Average 31.00 98.40 12,80 US Census Names Alvin Cooper 43 99 9 Harry Hughes 39 98 9 Jonathan Brooks 83 97 8 Jude Brown 32 100 39 Karen Peterson 64 100 16 Marcy Jackson 51 100 5 Martha Edwards 82 100 9 Neil Clark 21 99 7 Stephan Johnson 36 100 20 Violet Howard 52 98 27 Average 50.30 99.10 14.90 Global 45.93 WePS evaluaci\u00b4 on 191 \u0001B\u00fasqueda Web HTML/XML cleaning Documentos Preproceso Title Body Links Texto Nombres propios Matriz a partir del contexto K-means Cluster analysis WEKA LSA transformaci\u00f3n matricial Informaci\u00f3n contextual Clustering Clusters Figura 6.2. Arquitectura sistema WePS Donde la precisi\u00b4 on de un cluster cluster con m\u00b4 axi- mo \"recall\" para cada categor\u00b4 a, dando mayor puntuaci\u00b4 on a los resultados que proporcionan mayor n\u00b4 umero de elementos para ca- 192 6.2 Participaci\u00b4 on en Senseval da categor\u00b4 a en su correspondiente cluster. Esta medida on nal de los sistemas, se utiliz\u00b4 o la medida arm\u00b4 onica F\u00ae=0;5. o otro valor a \u00aepara dar mayor importancia a la \"Inverse Purity\", \u00ae= 0;2. La idea es que para un busca- dor web, deber\u00b4 a ser m\u00b4 as f\u00b4 acil desechar unas pocas p\u00b4 aginas web incorrectas en un cluster que contenga toda la informaci\u00b4 on nece- saria, que tener que obtener la informaci\u00b4 on a partir de diversos clusters. Por lo tanto, el alcanzar un valor elevado en la \"Inverse Purity\" deber\u00b4 a tenerse tambi\u00b4 en en cuenta a la hora de evaluar los diferentes sistemas. La Tabla 6.20muestra los resultados obtenidos tras la evalua- ci\u00b4 on de nuestro sistema. Como se observa en la Tabla 6.20, la media de efectividad de nuestro sistema est\u00b4 a alrededor del 56 %. Con respecto a los otros participantes de la tarea WePS nuestro sistema se sit\u00b4 ua en la d\u00b4 ecima posici\u00b4 on de entre diecis\u00b4 eis participantes (Ver Tabla 6.21). Tras el an\u00b4 alisis de los resultados obtenidos se detectaron algu- nas limitaciones a la hora de asignar correctamente los clusters. Por ejemplo, exist\u00b4 an muchas p\u00b4 aginas web que no conten\u00b4 an ape- nas informaci\u00b4 on entre las etiquetas <body > </body >, lo que dicultaba el correcto funcionamiento de LSA, ya que, el resulta- do de calcular la similitud de un documento sin informaci\u00b4 on en el cuerpo de la p\u00b4 agina web respecto a otros, daba como resultado 0. Otra limitaci\u00b4 on viene dada por la diferencia de tama no de los contextos de las distintas p\u00b4 aginas web. Una consecuencia de esta variedad es que LSA obtiene peores resultados si los contextos no 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 193 Name 0,23 0,37 0,27 Robert Moore 0,36 0,67 0,47 0,57 Barrett 0,62 0,51 0,56 0,52 Dekang Lin 0,99 0,43 0,60 0,49 Stephen Clark 0,52 0,75 0,62 0,69 Frank Keller 0,38 0,67 0,48 0,58 Jerry Hobbs 0,63 0,61 John Nelson 0,68 0,76 0,72 0,74 0,71 0,64 0,68 Morgan 0,77 0,47 0,59 0,51 Thomas Kirk 0,90 0,41 0,60 Patrick 0,63 0,70 Howard 0,58 0,75 0,65 0,71 Global average 0,58 0,64 0,58 0,60 Tabla 6.20. Resultados evaluaci\u00b4 on WePS son de un tama no semejante. En un futuro se pretende trabajar con una ventana de tama no espec\u00b4 co para cada contexto. Adem\u00b4 as, en WePS el n\u00b4 umero de individuos que comparten el mismo nombre es desconocido. Por tanto, el establecimiento del n\u00b4 umero de clusters es muy complicado y en el caso de K-means que no dispone de un criterio de parada, se debe hacer de forma 194 6.2 Participaci\u00b4 on en Senseval manual. En nuestro experimento, el establecimiento del n\u00b4 umero de clusters se hizo evaluando los resultados obtenidos para dife- rentes rangos sobre el corpus de entrenamiento. Los resultados demostraron que el n\u00b4 umero de clusters id\u00b4 oneo para un correcto funcionamiento se establec\u00b4 a entre 25 y 50. En la Tabla 6.21se pueden consultar los resultados obtenidos por el resto de participantes en la tarea. Macro-averaged evaluaci\u00b4 on sistemas WePS Los resultados presentados en la Tabla 6.21 responden a la medida del macro-promedio10en lugar de a la medida del micro- promedio11. Se opt\u00b4 o por estas medidas porque el macro-promedio 10El macro-promedio viene determinado por calcular el valor de Fpara cada per- sona y despu\u00b4 es calcular la media entre los resultados obtenidos 11El micro-promedio viene determinado por las medidas de Purity e Inverse Purity sobre todas las instancias, para luego calcular el valor de Fsobre esos resultados 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 195 tiene una interpretaci\u00b4 on m\u00b4 as clara: si la medida de evaluaci\u00b4 on es F, entonces se deber\u00b4 a calcular Fpara cada nombre de persona y entonces calcular la media de todos los valores de Fobtenidos. 6.3 Participaci\u00b4 on en iCLEF Dentro del marco de la competici\u00b4 on CLEF (Cross-Language Evaluation Forum) para la evaluaci\u00b4 on de sistemas en espacios multiling\u00a8 ues, se particip\u00b4 o en la tarea espec\u00b4 ca iCLEF ( Gonzalo y Oard (2004 )). En esta tarea (cross-language search system), el objetivo era determinar la forma de proporcionar la mejor asis- tencia a distintos usuarios que formulaban preguntas en su lengua materna y obten\u00b4 an respuestas en otra lengua distinta. El conjunto de preguntas proporcionadas para esta tarea fue- ron extra\u00b4 das de la tarea de Question Answering del CLEF 2004, con el n de comparar los resultados obtenidos por sistemas autom\u00b4 aticos y los obtenidos con los experimentos interactivos. En nuestro caso ( Navarro et al. (2004 )), el sistema proporcio- naba varias respuestas (50 p\u00b4 arrafos) para una misma pregunta, junto con una serie de indicadores que establec\u00b4 an grados de simi- litud entre cada par (pregunta-respuesta). Las preguntas estaban formuladas en espa nol y las respuestas en ingl\u00b4 es. Para lograr el objetivo de asistir a los usuarios a localizar la respuesta correcta, nos centramos en dos ideas: 1.El tipo de informaci\u00b4 on mostrada al usuario. Debe ser suciente para la localizaci\u00b4 on de la respuesta correcta, dado que el usuario no conoce de antemano la respuesta a cada pregunta. Es el usuario el que debe decidir si la respuesta se encuentra en el p\u00b4 arrafo mostrado o no. Por tanto, no s\u00b4 olo se debe mostrar la respuesta de forma expl\u00b4 cita, sino el suciente contexto para poder extraer la respuesta correcta. 2.C\u00b4 omo se muestra la informaci\u00b4 on al usuario. Concreta- mente en qu\u00b4 e lengua se le muestra la informaci\u00b4 on al usuario. Si los usuarios no conocen la lengua de los p\u00b4 arrafos que muestran las respuestas, se les debe proporcionar alguna informaci\u00b4 on ex- tra para localizar la respuesta correcta. 196 6.3 Participaci\u00b4 on en iCLEF A partir de estas premisas, usuarios con poco conocimiento del ingl\u00b4 es podr\u00b4 an establecer la respuesta correcta a partir de resul- tados obtenidos en ingl\u00b4 es y no en su lengua materna. Adem\u00b4 as, mediante el uso de este tipo de sistemas, se podr\u00b4 a evitar la tra- ducci\u00b4 on de grandes vol\u00b4 umenes de datos a diferentes idiomas para satisfacer la demanda de informaci\u00b4 on a partir de otras lenguas. 6.3.1 Desarrollo de los experimentos Con el objetivo de asistir a los usuarios en su b\u00b4 usqueda de informaci\u00b4 on, se han seguido tres pasos para realizar los experi- mentos. 1.Formulaci\u00b4 on de la pregunta y traducci\u00b4 on autom\u00b4 atica. Se extrajeron preguntas en espa nol de la colecci\u00b4 on del CLEF 2004 y fueron traducidas con un sistema autom\u00b4 atico de tra- ducci\u00b4 on a Ingl\u00b4 es12. 2.Extracci\u00b4 on de pasajes relevantes. Para localizar los pa- sajes relevantes de la colecci\u00b4 on de documentos en ingl\u00b4 es se utiliz\u00b4 o un sistema de recuperaci\u00b4 on de informaci\u00b4 on autom\u00b4 atico (Llopis (2003 )). Este sistema extrae pasajes relacionados con la pregunta y los ordena de mayor relevancia a menor relevan- cia. Concretamente, el tama no de cada pasaje extra\u00b4 do fue de 5 frases, tama no m\u00b4 as que suciente para localizar una posible respuesta. 3.Interacci\u00b4 on con el usuario y localizaci\u00b4 on de la respues- ta.Las preguntas en espa nol y los pasajes en ingl\u00b4 es se mos- traron a los usuarios a trav\u00b4 es de una p\u00b4 agina web. Los usuarios deb\u00b4 an de localizar la respuesta correcta entre los diferentes pasajes mostrados. Entonces deb\u00b4 an seleccionar la respuesta (cadena de caracteres) y el pasaje donde aparec\u00b4 a. El problema de esta tarea, tal y como se ha mencionado an- teriormente, es la falta de conocimiento por parte del usuario de la lengua en la que se muestran los pasajes. Es por tanto necesa- ria la incorporaci\u00b4 on de cierta informaci\u00b4 on que ayude al usuario a determinar el pasaje y la respuesta correcta para cada pregunta. 12http://babelfish.yahoo.com/ 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 197 Para ello, se desarrollaron dos m\u00b4 etodos: uno basado en etiquetas sem\u00b4 anticas utiliza el recurso l\u00b4 exico Dominios Relevan- tes para ayudar a la localizaci\u00b4 on de las respuestas por parte de los usuarios. Como ya se explic\u00b4 o en el cap\u00b4 tulo anterior los Do- minios Relevantes (extra\u00b4 dos a partir de WordNet Domains), son aquellos dominios o etiquetas sem\u00b4 anticas m\u00b4 as representativas de un palabra. En este caso, nuestra hip\u00b4 otesis es que si sabemos los dominios relevantes de la pregunta y los dominios relevantes de las respuestas, podemos reducir la colecci\u00b4 on de pasajes a aquellos que compartan ciertos dominios. De esta forma, la respuesta correcta ser\u00b4 a localizada con mayor facilidad y con una alta probabilidad en aquellos pasajes que compartan la mayor cantidad de dominios relevantes respecto a la pregunta en cuesti\u00b4 on. Un ejemplo de la informaci\u00b4 on proporcionada a los usuarios, se muestra en la Figura 6.3. En esta captura de la p\u00b4 agina web mostrada a cada usuario se aprecian: la pregunta en cuesti\u00b4 on, el pasaje seleccionado, los dominios relevantes de la pregunta y los dominios relevantes del pasaje. Para la pregunta \"\u00bfQui\u00b4 en es el director gerente de FIAT?\", los dominios asociados son: Administration ,Economy yTrans- port . Y de entre los dominios mostrados para el pasaje encon- tramos Economy yTransport entre los cinco primeros. Por tanto, este pasaje podr\u00b4 a ser candidato de contener la respuesta correcta. Adem\u00b4 as de proporcionar informaci\u00b4 on \u00b4 util acerca de los domi- nios involucrados en cada consulta, el orden de los pasajes obte- nido por el sistema de recuperaci\u00b4 on fue alterado. De forma que aquellos pasajes con mayor similitud respecto a la pregunta, fue- ron mostrados previamente a aquellos cuya similitud era menor. 198 6.3 Participaci\u00b4 on en iCLEF Figura 6.3. P\u00b4 agina web interactiva M\u00b4 etodo etodo est\u00b4 a basado en patrones sint\u00b4 actico-sem\u00b4 anti- cos. Con este m\u00b4 etodo se muestra al usuario una serie de patrones (SSP) junto con los pasajes en ingl\u00b4 es, donde cada patr\u00b4 on est\u00b4 a for- mado por los verbos y los nombres principales. La hip\u00b4 otesis en este caso es determinar si esta informaci\u00b4 on permite al usuario de- cidir si el pasaje mostrado contiene la respuesta a la pregunta formulada. Intuitivamente cuando un usuario busca la respuesta a una determinada pregunta en una porci\u00b4 on de texto, \u00b4 este presta m\u00b4 as atenci\u00b4 on a los nombres y verbos, intentando localizar ver- bos o nombres similares a los de la pregunta. Con los patrones, los verbos y nombres principales son extra\u00b4 dos autom\u00b4 aticamente, facilitando esta tarea a los usuarios. 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 199 Desde el punto de te\u00b4 orico un patr\u00b4 on por tres componentes: 1.Un verbo con su sentido o sentidos. 2.El marco de subcategorizaci\u00b4 on de ese sentido. 3.Las preferencias de selecci\u00b4 on de cada argumento. Dado que obtener de forma autom\u00b4 atica esta informaci\u00b4 on es un proceso muy costoso, el sistema utiliza una versi\u00b4 on de SSP's me- nos compleja. En este nuevo modelo, el verbo se representa por la palabra y su sentido o sentidos, el marco de subcategorizaci\u00b4 on se representa por el nombre principal de cada argumento (si el argu- mento es una cl\u00b4 ausula, en lugar del nombre se utilizar\u00b4 a el verbo) y las preferencias de selecci\u00b4 on de cada argumento se representar\u00b4 an por el sentido o los sentidos de los nombres principales. En la Figura 6.4se muestra una captura de la p\u00b4 agina web mostrada al usuario. En esta captura se aprecia por una parte la pregunta, el pasaje y los SSP's asociados al pasaje. Figura 6.4. P\u00b4 agina web interactiva para patrones SSP 200 6.3 Participaci\u00b4 on en iCLEF Utilizando los SSP's, s\u00b4 olo la informaci\u00b4 on m\u00b4 as importante de cada frase es mostrada al usuario: los verbos y los nombres prin- cipales y las relaciones sint\u00b4 actico-sem\u00b4 anticas existentes entre ellos. 6.3.2 Resultados En la Figura 6.5se muestran los resultados obtenidos por los usuarios con cada m\u00b4 etodo interactivo. Como se puede observar los usuarios obtuvieron resultados similares con ambos m\u00b4 etodos. \u00b4Unicamente se aprecia una peque na mejora de 0.015 obtenida por el m\u00b4 etodo de patrones. 0,375 0,5 0,453123 0,5625 0 0,1 0,2 0,3 0,4 0,5 0,6 Media por sistema (estricta) Media por sistema (tolerante) Dominios Relevantes SSP's Figura 6.5. Media gen\u00b4 erica Las medidas de efectividad de los sistemas son las mismas uti- lizadas en la tarea de CL-QA (Cross Language Question Answe- ring). La media estricta son las respuestas correctas obtenidas a partir de pasajes que contienen la respuesta. Y la media tolerante, son las respuestas correctas obtenidas por los usuarios indepen- dientemente de encontrarse en el pasaje correcto. 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 201 6.3.2.1 Media por usuario. Las Figuras 6.6y6.7representan la media obtenida por ca- da usuario. La Figura 6.6muestra las respuestas correctas en- contradas por el usuario en un pasaje que realmente contiene la respuesta (estricta). 0,125 0,625 0,625 0 0,75 0 0,1 0,2 0,3 0,4 0,5 0,6 0,7 0,8 1 2 3 4 5 6 7 8 Usuarios Dominios RelevantesSSP's Figura 6.6. Media estricta por usuario La Figura 6.7muestra las respuestas correctas obtenidas por cada usuario, independientemente de seleccionar el pasaje correc- to (tolerante). 6.3.3 Interpretaci\u00b4 on de resultados y trabajo futuro A partir de los resultados obtenidos pueden desprenderse las siguientes conclusiones: Los resultados son bajos quiz\u00b4 as porque no se ha utilizado nin- guna traducci\u00b4 on como ayuda. Podr\u00b4 a incorporarse una pseudo traducci\u00b4 on que realmente ayude a la localizaci\u00b4 on de la respuesta correcta. En el caso de los Dominios Relevantes, este m\u00b4 etodo ayuda a en- contrar la respuesta correcta pero existen algunos errores debido al escaso contexto de las preguntas. Para subsanar esta escasez 202 6.4 Participaci\u00b4 on en 0,75 0 0,1 0,2 0,3 0,4 0,5 0,6 0,7 0,8 1 2 3 4 5 6 7 8 Usuarios Dominios Relevantes SSP's Figura 6.7. Media tolerante por usuario de informaci\u00b4 on, se podr\u00b4 an a nadir m\u00b4 as palabras utilizando rela- ciones de hiperonimia, homonimia, etc. En el caso de los SSP's ser\u00b4 a necesario mejorar la codicaci\u00b4 on de los patrones, ya que, actualmente su interpretaci\u00b4 on resulta complicada, seg\u00b4 un las encuestas realizadas posteriormente a los usuarios. Como trabajos futuros se pretende traducir los patrones obte- nidos a partir de un m\u00b4 etodo basado en alineamiento de verbos. Adem\u00b4 as, se pretende mejorar la extracci\u00b4 on de pasajes del sistema de recuperaci\u00b4 on de informaci\u00b4 on mediante la inclusi\u00b4 on de informa- ci\u00b4 on relativa a los Dominios Relevantes. 6.4 Participaci\u00b4 on en Textual Entailment Recognition Entre las diferentes tareas de PLN, surge la necesidad de iden- ticar similitudes sem\u00b4 anticas entre diferentes fragmentos de texto. Esta tarea recibe el nombre de detecci\u00b4 on de la implicaci\u00b4 on textual o Recognising Textual Entailment (RTE). Nuestra hip\u00b4 otesis es que la utilizaci\u00b4 on de informaci\u00b4 on sem\u00b4 anti- ca, podr\u00b4 a ser muy \u00b4 util para resolver el problema de la implicaci\u00b4 on 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 203 textual. Por ello, se ha desarrollado un sistema de detecci\u00b4 on de la implicaci\u00b4 on textual participando en las competiciones RTE2 y AVE. Adem\u00b4 as, directamente relacionada con la detecci\u00b4 on de la implicaci\u00b4 on textual se encuentra la detecci\u00b4 on de la par\u00b4 afrasis, por ello, tambi\u00b4 en se han realizado varios experimentos que determinan la efectividad de nuestro sistema. 6.4.1 RTE2 PASCAL La detecci\u00b4 on de la implicaci\u00b4 on textual ( Dagan et al. (2005 )) es una tarea que consiste en determinar dados dos fragmentos de texto, si \u00b4 estos proporcionan el mismo contenido sem\u00b4 antico. Es decir, si a partir de textos diferentes se transmite la misma infor- maci\u00b4 on. Por ejemplo, dados los textos \"Muri\u00b4 o debido a la p\u00b4 erdida de sangre\" y \"Se desangr\u00b4 o hasta morir\", denotan la mis- ma informaci\u00b4 on, y se podr\u00b4 a inferir que el primer texto implica el segundo. Para resolver este problema se han realizado diferen- tes aproximaciones ( Akhmatova (2005 ),Andreevska et al. (2005 ), Herrera et al. (2005 )), todas ellas evaluadas dentro del marco de PASCAL (Pattern Analysis, Statistical Modelling and Computa- tional Learning) y m\u00b4 as concretamente en la tarea de Recognising Textual Entailment Challenge (RTE13). En este tipo de problema, es necesario disponer de cierto co- nocimiento sem\u00b4 antico acerca de los dos contextos implicados. Por ello, nuestro estudio se ha centrado en la determinaci\u00b4 on de la influencia de la informaci\u00b4 on sem\u00b4 antica para la detecci\u00b4 on de la im- plicaci\u00b4 on textual. La evaluaci\u00b4 on de las diferentes aproximaciones se ha realizado utilizando el corpus del RTE2 donde los ejemplos proporcionados est\u00b4 an balanceados (50 % son verdaderos y 50 % son falsos). Todos los ejemplos han sido extra\u00b4 dos de aplicaciones reales de Extrac- ci\u00b4 on de Informaci\u00b4 on, Recuperaci\u00b4 on de on de y Res\u00b4 umenes autom\u00b4 aticos. En total se proporciona- ron 1600 ejemplos, de los cuales, 800 se distribuyeron como corpus de preparaci\u00b4 on (development data) y los 800 restantes como cor- 13http://pascallin.ecs.soton.ac.uk/Challenges/RTE2/ 204 6.4 Participaci\u00b4 on en Textual Entailment Recognition pus de evaluaci\u00b4 on (test data). 6.4.1.1 Utilizaci\u00b4 on de diferentes corpus para LSA. Los diferentes experimentos que se han realizado han tenido co- mo objetivo determinar la influencia de la elecci\u00b4 on de un corpus determinado para establecer la correspondencia sem\u00b4 antica entre dos frases. Para ello se han obtenido diferentes espacios sem\u00b4 anticos utilizando la t\u00b4 ecnica de LSA, los cuales se describen a continua- ci\u00b4 on: BNC corpus (LSA BNC NoTag) . Resultados utilizando infor- maci\u00b4 on del corpus BNC palabras lematizadas. (LSA LemaH, LSA NoLemaH) . como corpus las frases H (hip\u00b4 otesis) y construyendo dos matrices diferentes: una con las palabras lematizadas y la otra con las palabras no lematizadas. T sentences (LSA LemaT, LSA NoLemaT) . Resultados utili- zando como corpus las frases T (test) y construyendo dos ma- trices diferentes: una con las palabras lematizadas y la otra con las palabras no lematizadas. Relevant Domains (LSA RD). Resultados utilizando el re- curso Dominios Relevantes de cada frase T y de cada frase H. La medida de evaluaci\u00b4 on utilizada ha sido la \"Accuracy\" seg\u00b4 ormula ejemplos(6.7) En la Tabla 6.22 se muestran los resultados obtenidos para cada uno de los diferentes experimentos realizados. Para cada experimento se han evaluado los resultados de forma independiente para cada tipo de datos de entrada: IE (Extracci\u00b4 on de Informaci\u00b4 on), IR (Recuperaci\u00b4 on de Informaci\u00b4 on), QA (B\u00b4 usque- da de respuestas) y SUM (Resumen autom\u00b4 atico). Como se puede observar, los mejores resultados se han obtenido utilizando las fra- ses de Text (LSA LemaT) y los Dominios Relevantes (LSA RD). 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 205 Datos Acc. diferentes corpus y LSA La primera aproximaci\u00b4 on utiliza como corpus todas las frases de Text y las frases de Hip\u00b4 otesis como entrada al m\u00b4 odulo LSA. En es- te caso, los resultados son 56 ;87 % para los datos de preparaci\u00b4 on y 52;25 % par los datos de evaluaci\u00b4 on. Estos resultados son mejores que los obtenidos en el experimento LSA LemaH porque las frases de Text proporcionan mayor informaci\u00b4 on sem\u00b4 antica. Por lo tanto, para inferir que dos frases tienen el mismo signicado sem\u00b4 antico se necesita una aproximaci\u00b4 on con una base contextual apropiada. La segunda aproximaci\u00b4 on utiliza como corpus el recurso Dominios Relevantes. En este caso, la matriz contextual inicial se ha obteni- do a partir de la informaci\u00b4 on de WordNet Domains. Este espacio sem\u00b4 antico se ha utilizado para extraer la similitud entre cada par de frases H-T. Como resultado, se ha obtenido un 56 ;98 % para los datos de preparaci\u00b4 on y un 54 ;51 % para los datos de evaluaci\u00b4 on. En este caso, los resultados obtenidos han sido bastante buenos debido a que las palabras sem\u00b4 anticamente relacionadas compar- ten las mismas de WordNet Domains y esta informaci\u00b4 on es muy \u00b4 util a la hora de relacionar textos relativos a las tares de QA y SUM. En cuanto al resto de experimentos, se demuestra que no se dispone de suciente informaci\u00b4 on contextual para detectar correctamente la implicaci\u00b4 on textual. 206 6.4 Participaci\u00b4 on en Textual Entailment Recognition 6.4.1.2 Utilizaci\u00b4 on de la medida del coseno. Otra serie de experimentos se ha realizado utilizando la medida de similitud del coseno. En este caso, se ha utilizado la medida tradicional de similitud entre documentos y la adaptaci\u00b4 on de esta medida a los Dominios Relevantes. Los resultados se muestran en la Tabla 6.23. Datos Acc. IE IR measure A la vista de los resultados queda patente el mejor funcio- namiento de la medida del coseno combinada con los Dominios Relevantes. En este caso se alcanza un 54 % tanto para los textos de evaluaci\u00b4 on como de preparaci\u00b4 on. Pero estos resultados demues- tran que la informaci\u00b4 on contextual dada por las frases no es muy representativa y no proporciona suciente conocimiento. Por lo tanto, la medida del coseno podr\u00b4 a utilizarse combinada con otras fuentes de informaci\u00b4 on. 6.4.1.3 Combinaci\u00b4 on de LSA y coseno con un sistema de aprendizaje. Para poder utilizar la informaci\u00b4 on proporcionada por la medida de similitud del coseno y de LSA, \u00b4 estas se introdujeron como nuevas caracter\u00b4 sticas en un sistema de features LSA LemaT) . Resultados del sistema previo MLEnt con LSA. En es- 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 207 te caso, se utiliz\u00b4 o como corpus para la matriz de LSA las frases de Text con las palabras lematizadas. MLEnt with cosine (MLEnt Lex cosine,MLEnt Sem cosine) del sistema previo MLEnt combinado con la medi- da del coseno. En este caso, el coseno se obtiene utilizando el recurso Dominios Relevantes. MLEnt with LSA and cosine (MLEnt Sem . Resultados del sistema pre- vio MLEnt combinando LSA y la medida de similitud del co- seno. En este caso, se utiliz\u00b4 o LSA con las frases de Text y la medida del coseno con los Dominios Relevantes. Los resultados obtenidos se muestran en la Tabla 6.24. Sets Acc. IE IR on de MLEnt con LSA y el coseno Como muestra la Tabla 6.24, los experimentos que se han lle- vado a cabo combinando los valores de LSA y el coseno como nuevas caracter\u00b4 sticas, mejoran los resultados previos del siste- ma MLEnt. Por tanto, podemos concluir que a nadir informaci\u00b4 on sem\u00b4 antica a un sistema de aprendizaje autom\u00b4 atico proporciona mayor efectividad. De hecho, el mejor resultado obtenido es de 208 6.4 Participaci\u00b4 on en Textual Entailment Recognition un 62 % para el conjunto de datos de preparaci\u00b4 on y de un 57 % para el conjunto de datos de evaluaci\u00b4 on. Estos resultados se han obtenido a partir del experimento realizado tras la combinaci\u00b4 on de LSA con el coseno y el sistema MLEnt. 6.4.1.4 Comparativa con otros sistemas participantes. En la competici\u00b4 on para la detecci\u00b4 on de la implicaci\u00b4 on textual RTE2, participaron 23 equipos. Cada equipo pod\u00b4 a enviar hasta dos ejecuciones para evaluar sus resultados. La Tabla 6.25presen- ta los resultados obtenidos en t\u00b4 erminos de la medida de \"Accu- racy\" . Desde el punto de vista sem\u00b4 antico, los resultados obtenidos ofrecen una mejora con respecto al sistema inicial MLEnt. De esta forma, se puede armar que la combinaci\u00b4 on del sistema de apren- dizaje MLEnt con recursos sem\u00b4 anticos tales como, los dominios relevantes y la sem\u00b4 antica latente pone de maniesto la utilidad de a nadir informaci\u00b4 on sem\u00b4 antica para la detecci\u00b4 on de la implicaci\u00b4 on textual. Adem\u00b4 as, analizando los resultados obtenidos con respecto al resto de participantes, la media obtenida ronda el 58 %, por lo que nuestro sistema obtiene resultados signicativos. 6.4.2 AVE CLEF2006 En esta competici\u00b4 on se particip\u00b4 o en la tarea Answer Validation Exercise (AVE) ( Pe nas et al. (2006a )), con el sistema basado en aprendizaje MLEnt desarrollado en ( Kozareva y Montoyo (2006 ), Kozareva et al. (2006 )). Este sistema fue utilizado para la tarea RTE y fue posteriormente adaptado para la tarea AVE. En la competici\u00b4 on AVE el objetivo es determinar si a partir de unsnippet proporcionado por un sistema de b\u00b4 usqueda de respues- tas (T-Texto) se puede extraer la informaci\u00b4 on proporcionada en un texto (H-Hip\u00b4 otesis). De esta forma, se podr\u00b4 a evaluar de forma autom\u00b4 atica el funcionamiento de sistemas de Question Answering. En la edici\u00b4 on de 2006 AVE se plante\u00b4 o como tarea multiling\u00a8 ue para detectar la correcci\u00b4 on de las respuestas dadas por un siste- 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 209 Sistema Acc Adams (Dallas) 0.6262 Bos (Rome & Leeds) - LSA MLEnt - Sem - LSA 0.5618 Combinaci\u00b4 MLEnt - de sistemas en RTE2 210 6.4 Participaci\u00b4 on en Textual Entailment Recognition ma QA idiomas: alem\u00b4 M\u00b4 palabras: Sistema a compuesto de m\u00b4 superpuestas y m\u00b4 odulo de similitud sem\u00b4 antica. Dado que la tarea AVE es una tarea multiling\u00a8 ue, el m\u00b4 odulo de similitud sem\u00b4 antica no se ha utilizado debido a que \u00b4 este utiliza la informa- ci\u00b4 on proporcionada por WordNet y es muy costoso adaptar este m\u00b4 odulo para diferentes idiomas. Los atributos utilizados por el m\u00b4 odulo de palabras superpues- tas son los siguientes: n-gramas. Busca posiciones comunes de unigramas entre el Texto y la Hip\u00b4 otesis. De acuerdo a este atributo el par Texto- Hip\u00b4 otesis ser\u00b4 a correcto si ambos comparten las mismas palabras. De la misma forma, este atributo determina que un par no es correcto si no contienen ninguna palabra en com\u00b4 un. Este atri- buto no considera informaci\u00b4 on de similitud sem\u00b4 antica, as\u00b4 por ejemplo si \"veh\u00b4 culo\" y \"coche\" aparecen respectivamente en T y H son consideradas palabras sin ning\u00b4 un tipo de relaci\u00b4 on y por tanto, totalmente distintas. Otro punto d\u00b4 ebil de este atributo es que no tiene en cuenta el orden de las palabras y la estruc- tura de las frases. En este caso, frases del tipo \"Mary calls the police\" y \" The police calls Mary\", contienen las mismas pala- bras, pero con este atributo el resultado ser\u00b4 a que no ineren el mismo signicado. Para solventar este problema se han creado los siguientes atributos LongCS y skip-gramas. LongCS (Longest Common Subsequence). Obtiene se- cuencias de palabras no consecutivas de cualquier longitud, en- tre el Texto y la Hip\u00b4 otesis. Un valor elevado de LongCS signica sentencias similares. El valor de LongCS entre cada par T(m)- H(n), donde m es la longitud del Texto y n es la longitud de la hip\u00b4 otesis, se determina comoLongCS (T;H) n. 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 211 skip-gramas. Representa cualquier par de palabras en una ora- ci\u00b4 on con un n\u00b4 umero indeterminado de palabras entre ellas. Una vez determinados todos los pares de palabras del Texto y la Hip\u00b4 otesis, se realiza el conteo de los umero de comunes entre T y H, umero de palabras en H y numero skip-gramas se corresponde con el n\u00b4 umero de n-gramas comunes entre T y H. De acuerdo a este atributo el par T-H ser\u00b4 a correcto cuantos m\u00b4 as skip-gramas tengan en com\u00b4 un. Por ejemplo, called Mary\" Mediante el atributo skip-gramas se deduce que las frases S1 y S2 tienen una relaci\u00b4 on de similitud m\u00b4 as fuerte que S1 y S3 o S2 y S3. Sin embargo, los atributos n-gramas y LongCS no son tan efectivos y no pueden determinar la similitud correctamente. mapeo num\u00b4 erico. Se identican los n\u00b4 umeros presentes en T y H y se verican. Para frases donde no existen n\u00b4 umeros, este atributo asigna en valor NO para el par. De acuerdo a este atributo, el par T-H ser\u00b4 a correcto cuanto los n\u00b4 umeros de T y H coincidan. El conjunto de atributos descrito ha sido evaluado \u00b4 unicamente sobre ingl\u00b4 es y espa nol, debido a que s\u00b4 olo se proporcion\u00b4 o corpus de entrenamiento para estos dos idiomas. Para la fase de entre- namiento se utilizaron los clasicadores SVM y kNN, junto con la observaci\u00b4 on de la medida IG (Information Gain), para los dos idiomas y diferentes tama nos de corpus de entrenamiento. IG es una medida que indica a partir de un conjunto de caracter\u00b4 sticas cu\u00b4 ales son las m\u00b4 as importantes. De acuerdo a IG, los dos atributos que proporcionan mejores resultados son LongCS y skip-gramas. Para la caracter\u00b4 stica de solapamiento de palabras, el sistema ge- nera dos salidas, una obtenida a partir del atributo LongCS y otra obtenida por el atributo de skip-gramas. 212 6.4 Participaci\u00b4 on en Textual Entailment Recognition Para el resto de idiomas a los que no se proporcion\u00b4 o corpus de entrenamiento se tuvo que ajustar los atributos LongCS y skip- gramas. Dado que los atributos utilizados dependen de la longi- tud del solapamiento de palabras normalizado por el n\u00b4 umero total de palabras presentes en H, fue posible adaptar estos atributos. As\u00b4 , utilizando las medidas de desviaci\u00b4 on est\u00b4 andar obtenidas para LongCS y skip-gramas en espa nol e ingl\u00b4 es, se adaptaron al resto de idiomas. 6.4.2.2 M\u00b4 odulo de similitud sem\u00b4 antica: LSA. Una de las caracter\u00b4 sticas de LSA es la de detectar similitu- des sem\u00b4 anticas entre textos que aun no compartiendo las mismas palabras, puedan estar relacionados. Esta capacidad ya fue co- mentada en el cap\u00b4 tulo anterior con m\u00b4 as detalle. En nuestro caso, para poder aplicar LSA sobre la tarea AVE se utiliz\u00b4 o como corpus para construir la matriz conceptual las frases del Texto. Esta decisi\u00b4 on fue tomada debido al estudio realizado en (V\u00b4 azquez et al. (2006 )), donde al utilizar las frases de T como corpus, la evaluaci\u00b4 on sobre la tarea de RTE obten\u00b4 a mejores resul- tados. Por tanto, para cada uno de los distintos idiomas - ingl\u00b4 es, espa nol, italiano, alem\u00b4 an, holand\u00b4 es, portugu\u00b4 es y franc\u00b4 es - se cons- truyeron diferentes matrices conceptuales utilizando las oraciones del Texto del corpus proporcionado por AVE. A partir de las matrices conceptuales obtenidas en cada caso, se pueden establecer relaciones de similitud entre t\u00b4 erminos, frases o documentos. En nuestros experimentos, dado que el objetivo nal era determinar si dos frases T-H ten\u00b4 an relaci\u00b4 on sem\u00b4 antica, se utiliz\u00b4 o la similitud entre frases. El resultado tras aplicar cada frase de H sobre la matriz conceptual, es un listado ordenado de mayor a menor similitud con las diferentes frases de T. En los siguientes ejemplos se muestran los datos de entrada. Para cada pregunta Qse proporcionaba un pasaje de texto Tdel cual se deb\u00b4 a inferir H. Los ejemplos muestran una instancia para la que se debe devolver FALSO (ejemplo 1) y otra para la que se debe devolver VERDADERO (ejemplo2). Ejemplo 1: 6. Experimentaci\u00b4 on As- sociated Press NASA briefly lost contact with the space shuttle Atlantis and its six astronauts Sunday because of crossed radio signals. The problem occurred Atlantis switched from one Tracking Data Relay Satellite to another, a routine procedure during Atlantis nor its crew was in any danger, and no science data was lost, said Mis- sion Control with Atlantis was restored after eight minu- tes, but it was an hour before engineers realized crossed signals, </t> <h>Atlantis is ATLANTIS THE LOST </pair > Este es un par T-H extra\u00b4 do de la colecci\u00b4 on de test de AVE, para la cual el sistema debe devolver \"NO\" como respuesta. En este caso, a partir del resultado obtenido por un sistema de QA para la pregunta \"What is Atlantis?\" , se trata de establecer si a partir del texto T se puede inferir la respuesta H. El resultado tras aplicar el M\u00b4 odulo LSA es el valor 0 ;402886, se considera por tanto, que no existe implicaci\u00b4 on entre ambos pares. the space shuttle and its six astronauts Sun- day because space shuttle. </h> </pair > En este ejemplo, el resultado debe ser \"YES\". Para la pregun- ta\"What is Atlantis?\" , y con el par T-H, s\u00b4 se puede inferir el contenido de H a partir de T. En este caso, el m\u00b4 odulo LSA ob- tiene el valor 0 ;905481, por lo que s\u00b4 existe implicaci\u00b4 on para el par. 214 6.4 en Textual Entailment Recognition 6.4.2.3 M\u00b4 odulo combinatorio. El \u00b4 ultimo paso para la obtenci\u00b4 on del sistema nal presentado en AVE es realizar la combinaci\u00b4 on del resultado de los m\u00b4 odulos de las secciones anteriores: m\u00b4 odulo de solapamiento de palabras y m\u00b4 odulo de LSA. La combinaci\u00b4 on de ambos m\u00b4 odulos se realiza mediante una estrategia de votaci\u00b4 on. Para garantizar una buena elecci\u00b4 on en la votaci\u00b4 on se realiza- ron diferentes pruebas para comprobar la compatibilidad de los distintos m\u00b4 odulos. La medida utilizada fue el coeciente Kappa (Cohen (1960 ),Pedersen (2002 )), que permite establecer el grado de acuerdo entre los distintos clasicadores seg\u00b4 un la a (de 1 hasta n) Pi1= proporci\u00b4 on de ocurrencia de la categor\u00b4 a i para el obser- vador 1. Pi2= proporci\u00b4 on de ocurrencia de la categor\u00b4 a i para el obser- vador 2. Un valor de Kappa elevado indica un alto grado de acuerdo entre los clasicadores por lo que no existe una mejora aparente tras aplicar la votaci\u00b4 on. En cambio, un valor de Kappa bajo in- dica un grado de acuerdo muy bajo por lo que se podr\u00b4 a apreciar una mejora tras la combinaci\u00b4 on de los resultados. Landis y Koch (Landis y Koch (1977 )) propusieron unos m\u00b4 argenes para valorar el grado de acuerdo en funci\u00b4 on del \u00b4 ndice Kappa Tabla 6.26. Para cada par T-H de AVE, se obtuvieron diferentes resultados usando LongCS, skip-gramas y LSA. La medida Kappa se uti- liz\u00b4 o evaluando los tres resultados juntos y tambi\u00b4 en se evalu\u00b4 o por pares de resultados. Los experimentos desarrollados para ingl\u00b4 es 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 215 Kappa Grado de acuerdo Sin Insignicante 0;2\u00a10;4 0;4\u00a10;6 Moderado 0;6\u00a10;8 0;8\u00a11 Tabla 6.26. Grado de acuerdo Kappa y espa nol (de los \u00b4 unicos idiomas de los que se dispon\u00b4 a de cor- pus de entrenamiento), demostraron que la mejor combinaci\u00b4 on era LongCS con skip-gramas y LongCS, skip-gramas y LSA. Por tanto, se presentaron dos ejecuciones distintas. Una vez la medida Kappa determin\u00b4 o las salidas que deb\u00b4 an ser combinadas, se aplic\u00b4 o la t\u00b4 ecnica de votaci\u00b4 on. Mediante esta t\u00b4 ecni- ca, se combinaron las distintas salidas en una \u00b4 unica predicci\u00b4 on. Las salidas generadas para LongCS, skip-gramas y LSA fueron evaluadas y se escogi\u00b4 o la respuesta con mayor n\u00b4 umero de votos. Para LongCS y skip-gramas, no se pudo aplicar votaci\u00b4 on dado que s\u00b4 olo hay dos clasicadores. En este caso, se tom\u00b4 o como estrategia que si no hab\u00b4 a acuerdo entre los dos clasicadores se respondie- ra \"NO\", y si hab\u00b4 a consenso se respondiera lo que indicaran los clasicadores. 6.4.2.4 Evaluaci\u00b4 on de resultados. La evaluaci\u00b4 on de los resultados obtenidos se realiz\u00b4 o sobre los di- ferentes idiomas de la tarea AVE: ingl\u00b4 es, espa alem\u00b4 an, franc\u00b4 es, italiano, holand\u00b4 es y portugu\u00b4 es. En la Tabla 6.27se muestran los resultados para las distintas ejecuciones individuales del m\u00b4 odu- lo de solapamiento de palabras y LSA, as\u00b4 como los resultados obtenidos para las dos combinaciones LongCS y skip-gramas y LongCS, skip-gramas y LSA. Para la evaluaci\u00b4 on de los resultados obtenidos se han utilizado las siguientes medidas de evaluaci\u00b4 on: 216 6.4 Participaci\u00b4 on en Textual Entailment Recognition precision =#contestados correctamente ES #total contestados Y ES(6.9) recall =#contestados correctamente =2\u00a4recall \u00a4precision recall +precision(6.11) Estas medidas fueron proporcionadas por los organizadores de la tarea AVE. De acuerdo a un estudio realizado en ( Pe nas et al. (2006b )), el 25 % de los pares son ciertos y el 75 % son falsos. Por tanto, el funcionamiento de los sistemas presentados deber\u00b4 a evaluarse teniendo en cuenta los pares etiquetados como \"YES\". Para los diferentes idiomas desarrollamos a continuaci\u00b4 on una peque na descripci\u00b4 on de las tareas realizadas: Ingl\u00b4 es. Para este idioma, se dispuso de una fase de entrenamien- to utilizando los datos del corpus ENGARTE14proporcionado. Los resultados obtenidos en este experimento se utilizaron como indicadores para seleccionar los mejores atributos del conjunto inicial. El mejor atributo del m\u00b4 odulo de solapamiento de pa- labras fue LongCS tanto para el test como para el corpus de entrenamiento. Esto demuestra que un tercio de de los pares del AVE pueden ser resueltos correctamente, simplemente con- siderando las secuencias solapadas entre dos textos. Los atributos skip-gramas y LSA obtienen alrededor de un 27 % de precisi\u00b4 on. La combinaci\u00b4 on de ambos no supuso ninguna me- jora en el corpus de test pero s\u00b4 se increment\u00b4 o en un 2 % en el corpus de entrenamiento. El mejor resultado para este idioma se obtuvo mediante la combinaci\u00b4 on de LongCS, skip-gramas y LSA. Esto demuestra que el atributo LSA detecta correctamen- te pares que los otros dos atributos no son capaces de clasicar. De acuerdo con la medida estad\u00b4 stica z0con un nivel de con- anza de 0.975 incremento es signicativo. 14http://nlp.uned.es/QA/ave 6. la evaluaci\u00b4 on de AVE 218 6.4 Participaci\u00b4 on en Textual Entailment Recognition Espa nol. Para espa nol se desarroll\u00b4 o otra fase de entrenamiento utilizando como corpus SPARTE. Para el corpus del test los me- jores resultados se obtuvieron con el atributo LongCS llegando a un valor aproximado de 53 %. El resultado tras la aplicaci\u00b4 on de la votaci\u00b4 on sobre la combinaci\u00b4 on de los tres atributos obtuvo el mismo valor que el atributo LongCS por separado. Esto es debido en gran parte a la baja cobertura de LSA, que depende del n\u00b4 umero y tipo de palabras de las frases de Texto. Alem\u00b4 an, franc\u00b4 es e italiano. Para estos tres idiomas los mejo- res resultados se obtuvieron con el atributo LongCS y la combi- naci\u00b4 on de los tres atributos. El rango de valores proporcionados por la medida F-score se sit\u00b4 ua entre 40 % a 47 %. Como se pue- de observar, los resultados de LSA son m\u00b4 as bajos respecto a los obtenidos con los atributos del m\u00b4 odulo de solapamiento. Esto es debido a que el grado de similitud de 0.8 sobre el que se pro- puso determinar si un par T-H era correcto, depende del tipo de palabras contenidas en T y debe ser estudiado con detalle para cada idioma. Holand\u00b4 es y portugu\u00b4 es. Para estos dos idiomas se obtuvieron los peores resultados. Cabe destacar que en el caso del holand\u00b4 es el atributo skip-gramas obtiene mejores resultados que LongCS. Este hecho puede estar relacionado con el origen de este idioma y el orden existente entre las palabras, ya que, los skip-gramas buscan posiciones independientes unas de otras a diferencia de los n-gramas que buscan posiciones contiguas. Para portugu\u00b4 es, LSA obtiene mejores resultados que cualquiera de los atributos del m\u00b4 odulo de solapamiento de palabras. El resultado tras la votaci\u00b4 on para portugu\u00b4 es obtuvo un 4 % de mejora frente a los clasicadores individuales. A la vista de los resultados obtenidos tras la evaluaci\u00b4 on de los distintos atributos o clasicadores por separado o mediante vo- taci\u00b4 on, podemos concluir que \u00b4 estos funcionan correctamente in- dependientemente del idioma utilizado. Adem\u00b4 as, la estrategia de votaci\u00b4 on mejora en la mayor\u00b4 a de los casos los resultados obteni- dos por los clasicadores de forma individual. 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 219 6.4.2.5 Comparativa con otros sistemas participantes. En la competici\u00b4 on AVE participaron 11 equipos diferentes, los cuales, realizaron la evaluaci\u00b4 on de sus sistemas en diferentes idio- mas. En nuestro caso, nuestro sistema se ha adaptado de tal forma que es capaz de trabajar sobre diferentes idiomas, tal y como se ha mostrado en las secciones previas. Sin embargo, debido a las caracter\u00b4 sticas espec\u00b4 cas de cada idioma y a la forma estable- cer conexiones entre palabras, la efectividad del sistema se ve en algunos casos truncada. La Tabla 6.28 muestra los resultados obtenidos por los dife- rentes sistemas, junto con la posici\u00b4 on alcanzada por el sistema denido en las secciones anteriores. A la vista de los resultados obtenidos, podemos concluir que el sistema propuesto, resultado de la combinaci\u00b4 on de recursos de \u00b4 ndole sem\u00b4 antica con un sistema de aprendizaje autom\u00b4 atico, ob- tiene buenos resultados. Cabe destacar que este sistema se ha aplicado a todos los idiomas de la tarea, adaptando en cada ca- so \u00b4 unicamente el m\u00b4 odulo de LSA. Esta adaptaci\u00b4 on simplemente requiere que la codicaci\u00b4 on de la matriz conceptual se realice a partir de la informaci\u00b4 on de los textos de cada idioma respectiva- mente. 6.4.3 Detecci\u00b4 on de par\u00b4 afrasis Estrechamente relacionada con el concepto de Implicaci\u00b4 on Tex- tual se encuentra la par\u00b4 afrasis. Mediante la par\u00b4 sin\u00b4 onimos (par\u00b4 afrasis mec\u00b4 (par\u00b4 afrasis constructi- va), ejemplo, \"veh\u00b4 culo\" y \"coche\", \"X est\u00b4 a casado con Y\" y \"X es el marido de Y\", etc. Existen diferentes aproximaciones que tratan de identicar la par\u00b4 afrasis entre textos. Muchas de ellas se centran en la extrac- ci\u00b4 on de reglas que detectan la par\u00b4 y identican la par\u00b4 afrasis entre textos a partir del solapamiento de 220 6.4 Participaci\u00b4 on en Textual Entailment Recognition participantes en AVE 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 221 palabras o de la similitud entre palabras. El problema de estas aproximaciones es que representan de forma global los conceptos y por tanto, no reflejan realmente el signicado de los contextos. Nuestra propuesta para detectar la par\u00b4 afrasis utiliza como fuente de informaci\u00b4 on el recurso l\u00b4 exico Dominios Relevantes. De esta forma, se pueden establecer las diferentes relaciones sem\u00b4 anti- cas entre diferente segmentos de texto. La hip\u00b4 otesis en la que se basa esta aproximaci\u00b4 on es que las etiquetas sem\u00b4 anticas o dominios determinan la coherencia de los textos, ya que, palabras relaciona- das sem\u00b4 anticamente comparten dominios similares y maximizan la similitud entre textos. Para establecer las similitudes entre los diferentes segmentos de texto se utiliza la t\u00b4 ecnica de LSA, cuya matriz se obtiene tomando como contextos las palabras de las glo- sas de WordNet asociadas a cada uno de los diferentes dominios. 6.4.3.1 Utilizaci\u00b4 on de WordNet Domains y SUMO. Adem\u00b4 as de WND existe otra ontolog\u00b4 a m\u00b4 as general construida sobre las deniciones de WordNet, estamos hablando de la onto- log\u00b4 a SUMO. Esta ontolog\u00b4 a al igual que ocurr\u00b4 a con WND extien- de las relaciones entre palabras utilizando categor\u00b4 as sem\u00b4 anticas o dominios. El objetivo de este estudio es determinar la influen- cia ejercida por el tipo de ontolog\u00b4 a utilizada para establecer las relaciones sem\u00b4 anticas entre diferentes contextos. En la Figura 6.8se muestra una parte de cada una de las jerar- qu\u00b4 as de WND y SUMO. Como se puede apreciar los conceptos representados en la jerarqu\u00b4 a de SUMO son mucho m\u00b4 as gen\u00b4 ericos que los representados en WND. La evaluaci\u00b4 on de este m\u00b4 etodo se ha realizado a partir de la obtenci\u00b4 on de dos matrices conceptuales distintas: una matriz ob- tenida a partir de WND y otra obtenida a partir de SUMO. El proceso de obtenci\u00b4 on de las matrices es b\u00b4 asicamente el mis- mo. El primer paso es obtener los Dominios Relevantes de cada palabra utilizando la jerarqu\u00b4 a de WND y la jerarqu\u00b4 a de SUMO. La obtenci\u00b4 on de los dominios relevantes se realiza a partir de la f\u00b4 ormula del Ratio de Asociaci\u00b4 on, que determina la relevancia de un dominio con respecto a una palabra. Con esta informaci\u00b4 on se 222 6.4 Participaci\u00b4 on en Textual Entailment Entity Physical Object psychoanalysis art dance drawing painting Extracto de la jerarqu\u00eda de SUMO Extracto de la jerarqu\u00eda de WND Figura 6.8. Comparaci\u00b4 on de las jerarqu\u00b4 as SUMO y WND construye la matriz conceptual, utilizando en lugar de documen- tos como columnas, las etiquetas sem\u00b4 anticas de los dominios y como valor en cada celda, el valor del Ratio de asociaci\u00b4 on de cada palabra con respecto a cada dominio. Una vez obtenidas las matrices conceptuales se realiza su des- composici\u00b4 on en valores singulares, reduciendo ambas matrices a 100 dimensiones. 6.4.3.2 Ejemplo ilustrativo. Para ilustrar la aplicaci\u00b4 on de los Dominios Relevantes y LSA se muestra a continuaci\u00b4 on un ejemplo de resoluci\u00b4 on de par\u00b4 afrasis. En este caso, dados dos fragmentos de texto, se van a extraer sus correspondientes espacios conceptuales y se va a determinar un valor de similitud entre ambos. El valor a partir del cual dos tex- tos son considerados como par\u00b4 afrasis uno del otro se ha obtenido emp\u00b4 ricamente a partir de una serie de experimentos previos sobre un corpus de entrenamiento. 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 223 El primer paso, es obtener los lemas de las palabras de los textos implicados (Figura 6.9). Para ello se ha utilizado el ana- lizar sint\u00b4 actico Tree-Tagger. Se ha optado por extraer los lemas debido a que la matriz conceptual de LSA se ha construido a partir de las palabras lematizadas de WordNet. En este ejem- plo, se han extra\u00b4 do los dominios relevantes de nombres, verbos, adjetivos y adverbios, para ambos segmentos. Las palabras que aparecen subrayadas en la Figura 6.9, son aquellas para las que se han considerado sus dominios relevantes. Text Segment 1: Women who eat potatoes and other tuberous vegetables during pregnancy may be at risk of triggering type 1 diabetes in their children , Melbourne researchers believe . Text Segment 2: Australian researchers believe they have found a trigger of type 1 diabetes in children - their mothers eating potatoes and other n\u00b4 umero 1634 del corpus La Figura 6.10 muestra los dominios relevantes de cada una de las palabras de los segmentos seg\u00b4 un la medida del Ratio de Asociaci\u00b4 on. Una vez determinados los dominios relevantes de los dos seg- mentos de texto, es necesario determinar el grado de similitud entre ambos. Para ello, se utiliza la t\u00b4 ecnica de LSA que obtiene los dominios que tienen en com\u00b4 un ambos segmentos de texto (ver Figura 6.29). Con esta informaci\u00b4 on se seleccionan los dominos con la probabilidad m\u00b4 as elevada que coincidan con los dominios relevantes extra\u00b4 dos anteriormente. Finalmente, se obtiene el valor del dominio m\u00b4 as apropriado de acuerdo a los valores de similitud obtenidos. En este caso, el do- minio seleccionado es Applied Science . 6.4.3.3 Evaluaci\u00b4 on. Figura 6.10. Los cinco primeros dominios relevantes de cada palabra 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 225 LSA dominios en segmento 1 LSA dominios en segmento 2 Dominio Similitud Dominio Similitud applied Tabla 6.29. LSA listado con los nuevo dominios relevantes para cada texto Para evaluar la correcci\u00b4 on de los resultados se han realizado diversos experimentos sobre un corpus de par\u00b4 afrasis15. El proce- so de evaluaci\u00b4 on consiste en determinar dados dos segmentos de texto si existe par\u00b4 afrasis entre ambos. El corpus utilizado ( Dolan et al. (2004 )) ha sido extra\u00b4 do de la web. El n\u00b4 umero de instancias de entrenamiento es de 4076 y el n\u00b4 umero de instancias de test es de 1725. Un ejemplo de segmentos de texto es: \"Inhibited children tend to be timid with new with new people and situations.\" Las medidas de evaluaci\u00b4 on utilizadas han sido: precisi\u00b4 on, recall, accuracy y f-measure. Se han desarrollado dos tipos de experimentos. El primero, estudia c\u00b4 omo representar el concepto subyacente a dos segmentos de texto, utilizando WND y SUMO. En el segundo, se estudia si el uso de ontolog\u00b4 as m\u00b4 as gen\u00b4 ericas, produce mejores resultados. Los resultados obtenidos se muestran en la Tabla 6.30. En esta tabla se muestran los resultados obtenidos en el corpus de entrenamiento y en el corpus de test. As\u00b4 como tambi\u00b4 en una serie de umbrales utilizados, con los que se concluye que un umbral de 0.4 es el m\u00b4 as adecuado. 15http://research.microsoft.com/en-us/projects/paraphrase/default.aspx 226 6.4 Participaci\u00b4 on en Textual Entailment Recognition Datos Umb Acc afrasis Para la on propor- no s\u00b4 olo del texto sino tambi\u00b4 en su concepto sem\u00b4 antico global. Durante el proceso de entrenamiento y de test WND y SUMO obtienen resultados similares. Sin embargo, WND proporciona resultados m\u00b4 as precisos. Las diferencias m\u00b4 as notables entre los dos experimentos se muestran con umbrales de valores elevados. Mientras que WND var\u00b4 a alrededor de un 10 % entre los diferentes umbrales, SUMO var\u00b4 a del 16 al 79 %. Esto debido en gran parte a la jerarqu\u00b4 a utilizada en ambas ontolog\u00b4 as. En WND los dominios se pueden solapar con una alta probabilidad mien- tras que en la jerarqu\u00b4 a gen\u00b4 erica de SUMO este solapamiento es menos evidente. En la Tabla 6.30 tambi\u00b4 en se muestra una comparativa con los resultados obtenidos por la aproximaci\u00b4 on mediante similitudes (Corley y Mihalcea (2005 )). Se puede apreciar que nuestra aproxi- maci\u00b4 on obtiene mejores resultados. Ya que, el establecimiento de similitudes palabra \u00a1palabra o texto \u00a1texto, no determinan exac- tamente el signicado del texto. En nuestro caso, se determina la similitud entre palabras pertenecientes a distintas categor\u00b4 as sint\u00b4 acticas en base al concepto sem\u00b4 antico subyacente. 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 227 Algunas limitaciones con respecto a la representaci\u00b4 on concep- tual de los segmentos de texto son debidas a la inclusi\u00b4 on del do- minio Factotum , cuando no se puede clasicar alguna palabra. Con respecto a la ontolog\u00b4 a SUMO se hace patente la necesidad de incorporar m\u00b4 as de 20 dominios representativos, para determi- nar el concepto sem\u00b4 antico de cada segmento de texto ( Kozareva et al. (2007 )). 6.5 Integraci\u00b4 on de DRelevant en un sistema basado en aprendizaje El sistema DRelevant ha sido utilizado para enriquecer el con- junto de caracter\u00b4 sticas de un sistema de aprendizaje autom\u00b4 atico. El objetivo de este experimento es comprobar si la integraci\u00b4 on de la informaci\u00b4 on proporcionada por el sistema DRelevant influye de forma positiva en el proceso de desambiguaci\u00b4 on. Para realizar el experimento, se han utilizado los datos de la tarea English lexical sample de Senseval-2 . 6.5.1 Sistema de aprendizaje inicial El sistema de aprendizaje inicial para el desarrollo de nues- tro experimento es el descrito en ( Su\u00b4 arez (2004 )). Este sistema de aprendizaje supervisado (WSD MAX ENT), est\u00b4 a basado en el entrop\u00b4 a ( Ratnaparkhi (1998 )), donde a partir del modelado de una serie de caracter\u00b4 sticas o atri- butos y del aprendizaje a partir de corpus anotados sem\u00b4 antica- mente trata de resolver el problema de la ambig\u00a8 uedad sem\u00b4 antica. El conjunto de atributos utilizado por el sistema WSD MAX ENT se muestra en la Tabla 6.31. Estos atributos se basan, principalmente, en el conocimiento ling\u00a8 u\u00b4 stico del contexto cercano a la palabra ambigua: palabras y composiciones de palabras que la acompa nan, categor\u00b4 as grama- ticales, rol gramatical, dependencias, etc. La denici\u00b4 on de atributos no tiene por qu\u00b4 e ser exclusivamente autom\u00b4 atica y a partir del corpus de aprendizaje. Tambi\u00b4 en se po- dr\u00b4 a incorporar informaci\u00b4 on externa al corpus si fuera necesaria. 2286.5 Integraci\u00b4 on de DRelevant en un sistema basado en aprendizaje No relajados 0: la palabra ambigua l: lemas (de palabras llenas) en \u00a71,\u00a72,\u00a73 s: palabras en posiciones \u00a71,\u00a72,\u00a73 b: lemas de pares de palabras en (-2, -1), (-1, +1), (+1, +2) c: pares de palabras en (-2, -1), (-1, +1), (+1, +2) p: categor\u00b4 as gramaticales de palabras en \u00a71,\u00a72,\u00a73 km: lemas de nombres que aparecen en al menos el m % de contextos de un sentido r: rol gramatical de la palabra ambigua d: la palabra de la que depende la ambigua m: palabra compuesta a la que pertenece la ambigua Relajados L: lemas (de palabras llenas) en \u00a71,\u00a72,\u00a73 W: palabras llenas en \u00a71,\u00a72,\u00a73 S: palabras en \u00a71,\u00a72,\u00a73 B: lemas de pares de palabras en (-2, -1), (-1, +1), (+1, +2) C: pares de palabras en (-2, -1), (-1, +1), (+1, +2) P: categor\u00b4 as gramaticales en \u00a71,\u00a72,\u00a73 D: la palabra de la que depende la ambigua M: palabra compuesta a la que pertenece la ambigua Tabla 6.31. Conjunto de atributos de WSD MAX ENT Y es en este punto donde a nadimos la informaci\u00b4 on proporcionada por el sistema DRelevant. 6.5.2 Nuevas caracter\u00b4 sticas usando DRelevant Para la incorporaci\u00b4 on de la informaci\u00b4 on del sistema DRelevant en el sistema supervisado WSD MAX ENT se van a utilizar las etiquetas de WordNet Domains del contexto m\u00b4 as cercano a la pa- labra a desambiguar. Concretamente se utilizar\u00b4 an las etiquetas de dominio de las dos palabras situadas a la derecha y a la izquierda de la palabra objetivo. V\u00b4 ease la Figura 6.11. En este caso, la palabra objetivo es \"car\" y se utiliza el sis- tema DRelevant para anotar las cuatro palabras m\u00b4 as cercanas a \"car\" con contenido sem\u00b4 antico (nombres, verbos, adjetivos o ad- verbios) con sus respectivos dominios. Una vez acabado el proceso de desambiguaci\u00b4 on con DRelevant y anotadas las cuatro palabras 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 229 You have to drive fast your to win the race Factotum \u00bfsentido? Transport Sport Sport car Figura 6.11. Anotaci\u00b4 on con DRelevant con sus respectivos dominios, el segundo paso es integrar esta in- formaci\u00b4 on en el corpus de entrenamiento del sistema, como una nueva caracter\u00b4 stica m\u00b4 as para el aprendizaje. El tercer paso es entrenar el sistema supervisado con esta nueva informaci\u00b4 on. Para nalmente evaluar los resultados obtenidos con el corpus de test. Cabe destacar que en el proceso de integraci\u00b4 on de los dominios como nuevos atributos del sistema, no se realiz\u00b4 o ninguna codi- caci\u00b4 on especial, sino que se utilizaron tal cual fueron anotados, lo que puede haber signicado alguna merma en el acierto nal. 6.5.3 Resultados Los resultados tras el enriquecimiento con DRelevant se mues- tran en la Tabla 6.32. Los experimentos se realizaron sobre la tarea English Lexical Sample de Senseval-2 sobre una muestra de 29 nombres. En esta tabla se pueden comparar los resultados obtenidos antes y despu\u00b4 es de a nadir los nuevos atributos. Como se puede apreciar, de los 29 nombres escogidos s\u00b4 olo 4 empeoraron en el proceso de desambiguaci\u00b4 on tras usar los nuevos atributos. Los dem\u00b4 as nombres o mantuvieron los mismos resulta- dos o sufrieron una mejora tras el proceso de desambiguaci\u00b4 on. La raz\u00b4 on de que la mejora total sea de s\u00b4 olo un 2 % se debe principalmente a que gran parte de los nombres no incrementan su acierto. Adem\u00b4 as cabe destacar que el proceso de anotaci\u00b4 on del sistema DRelevant no es correcto al 100 %. Tampoco se se ha te- nido en cuenta si el dominio \"factotum\" (etiqueta de WordNet Domains que indica que cierto nombre resulta inclasicable) debe eliminarse para mejorar el proceso de anotaci\u00b4 on. Incluso se po- dr\u00b4 a probar una ventana de palabras mayor en torno al nombre 2306.5 Integraci\u00b4 on de DRelevant en un sistema basado en aprendizaje Nombres SinDRelevant ConDRelevant Mejora art 68,3 68,3 0 authority 53,8 56,3 2,5 bar 51,9 51 -0,9 bum 86,5 91,9 5,4 chair 89,8 89,8 0 channel 12,5 18,8 6,3 child 61 62,7 1,7 church 60 60 0 circuit 24,5 38,8 14,3 day 64 64,7 0,7 detention 90,9 fatigue 86,8 86,8 0 feeling 6,3 grip 15,8 15,8 0 hearth 79,3 79,3 0 holiday 100 100 0 lady 87,5 90 2,5 material 36,2 51,7 15,5 mouth 56,9 58,8 1,9 nation 72 72 0 nature 43,2 46 2,8 post 51,2 51,2 0 restraint 48,4 51,6 3,2 sense 43,2 48,7 5,5 spade 82,4 88,2 5,8 stress 46 40,5 -5,5 yew 79,2 79,2 0 Total 62 64 2 Tabla 6.32. Enriquecimiento de un sistema basado en aprendizaje con DRelevant objetivo. Adem\u00b4 as, tambi\u00b4 en ser\u00b4 a interesante aplicar estos atribu- tos sobre verbos y adjetivos. Todas estas posibles mejoras quedan pendientes como trabajo futuro. 6. Experimentaci\u00b4 on y evaluaci\u00b4 on 231 6.5.4 Test de McNemar Tras la inclusi\u00b4 on de los dominios como una nueva caracter\u00b4 stica en el sistema supervisado WSD MAX ENT, es necesario determi- nar la signicancia de los cambios producidos. Para ello, se va a utilizar el test de McNemar ( Everitt (1977 )) que determina si los resultados obtenidos antes y despu\u00b4 es de la inclusi\u00b4 on de los domi- nios como nueva caracter\u00b4 stica producen cambios signicativos. La Tabla 6.33muestra la informaci\u00b4 on utilizada para construir la tabla Ejemplos clasicados err\u00b4 oneamente ConDom clasicados correctamente ambos algoritmos no por WSD SinDOm Tabla 6.33. Tabla de contingencia para el test de McNemar Para abreviar, se utilizar\u00b4 a la notaci\u00b4 on de la Tabla 6.34. As\u00b4 se puede de contingencia del test de McNemar La Tabla 6.35 muestra los valores asociados a cada variable tras aplicar ambos algoritmos a las instancias de test de English Lexical Sample Senseval . La suma de todas las variables es el n\u00b4 umero total de ejemplos en el conjunto de instancias de test. En nuestro caso: 447 + 96 + 68 + 685 = 1296. El test de McNemar se utiliza para comparar los resultados de una hip\u00b4 otesis nula o te\u00b4 orica H0, con los resultados de la hip\u00b4 otesis para los valores reales observados H1. La hip\u00b4 otesis nula tiene como 232 447 96 68 685 Tabla 6.35. Valores observados antes y despu\u00b4 es de la inclusi\u00b4 on de los dominios premisa que ambos algoritmos comparten los mismos errores, por tanto, n01=n10. Supongamos que el nivel de signicancia es \u00ae= 0;05 con 1 grado de libertad, por entones p <0;05, concluyendo que la utilizaci\u00b4 on de dominios es signicativa para la mejora del sistema WSD MAX ENT. Cap\u0013\u0010tulo 7 Conclusiones y trabajos futuros En este cap\u00b4 tulo nal y como consecuci\u00b4 on de esta Tesis docto- ral, se presenta una s\u00b4 ntesis sobre el trabajo desarrollado, un an\u00b4 ali- sis de los benecios aportados por la desambiguaci\u00b4 on autom\u00b4 atica a otras de tareas de PLN, una serie de propuestas con vistas al futuro, as\u00b4 como el conjunto de publicaciones relevantes derivadas de este trabajo. 7.1 Aportaciones En esta Tesis se ha presentado la denici\u00b4 on y evaluaci\u00b4 on de varios m\u00b4 dentro de la categor\u00b4 a de m\u00b4 etodos no supervisados, ba- sados en conocimiento. Estos m\u00b4 etodos han sido evaluados seg\u00b4 un las especicaciones de la competici\u00b4 on Senseval mostrando una comparativa respecto a otros sistemas. Adem\u00b4 as, se han integrado una serie de recursos sem\u00b4 anticos (Dominios Relevantes, SUMO) sobre diferentes t\u00b4 ecnicas (LSA, Machine Learning) con el objeti- vo de resolver problemas que afectan a otras tareas de PLN, tales como: reconocimiento de la variabilidad sem\u00b4 antica o detecci\u00b4 on y clasicaci\u00b4 on de nombres propios. Adem\u00b4 as, como consecuci\u00b4 on del estudio de la distribuci\u00b4 on y relaciones entre los sentidos en bases de datos l\u00b4 exicas como WordNet se ha creado un nuevo recurso 234 7.1 Aportaciones l\u00b4 exico: Dominios Relevantes. Este recurso es susceptible de inte- grarse en otros sistemas de WSD o servir de referencia sem\u00b4 antica para otras tareas de PLN. Las principales aportaciones siguiendo la estructura de esta Tesis han sido: 7.1.1 Estudio del estado del arte Estudio de la evoluci\u00b4 on de los sistemas de resoluci\u00b4 on autom\u00b4 ati- ca de la ambig\u00a8 uedad desde los comienzos del PLN hasta la fecha actual. Se ha realizado una clasicaci\u00b4 on de dichos sistemas dentro de distintas categor\u00b4 as, distinguiendo entre sistemas supervisados y sistemas no supervisados. A la vista de los resultados obtenidos en las distintas com- peticiones para evaluaci\u00b4 on de sistemas que resuelven de forma autom\u00b4 atica la ambig\u00a8 uedad en el lenguaje, los sistemas supervi- sados han demostrado ser m\u00b4 as ecientes que los sistemas no su- pervisados. Sin embargo, el principal problema de los sistemas supervisados reside en la escasez de corpus anotados para su en- trenamiento. 7.1.2 Estudio de los sistemas de evaluaci\u00b4 on en WSD Se ha realizado un estudio de la evoluci\u00b4 on de los m\u00b4 etodos de evaluaci\u00b4 on de sistemas de WSD. Originalmente exist\u00b4 a una imposibilidad de realizar estudios comparativos entre diferentes sistemas debido a la utilizaci\u00b4 on de distintos tipos de anotaci\u00b4 on sem\u00b4 antica o de corpus utilizados para la evaluaci\u00b4 on. Ante este problema, desde 1998 hasta la actualidad, la evaluaci\u00b4 on de sis- temas de WSD se realiza bajo un marco com\u00b4 un de evaluaci\u00b4 on: la competici\u00b4 on Senseval . Esta competici\u00b4 on unica criterios de evaluaci\u00b4 on permitiendo de esta forma evaluar distintos sistemas y comparar los resultados obtenidos. 7.1.3 Descripci\u00b4 on de los recursos l\u00b4 exicos utilizados Se han descrito los distintos recursos l\u00b4 exicos utilizados para el desarrollo de los m\u00b4 etodos de WSD presentados en este trabajo. 7. Conclusiones y trabajos futuros 235 En nuestro caso, la base de conocimiento principal sobre la que subyacen todos los m\u00b4 etodos desarrollados es WordNet: una base de datos l\u00b4 exica que sigue una serie de criterios psicoling\u00a8 u\u00b4 sticos, ampliamente utilizada en PLN. A partir de esta base de datos l\u00b4 exica se han utilizado otras ontolog\u00b4 as como SUMO o WordNet Domains que enriquecen las inter-relaciones de palabras presen- tes en WordNet. Adem\u00b4 as, mediante la utilizaci\u00b4 on de una versi\u00b4 on extendida de WordNet, Extended WordNet, se ha mejorado la obtenci\u00b4 on del nuevo recurso l\u00b4 exico Dominios Relevantes. Este re- curso l\u00b4 exico proporciona on relevante acerca de las emicas junto con las categor\u00b4 as sem\u00b4 anticas con las que se relacionan. Adem\u00b4 as, se ha presentado y descrito detalladamente la t\u00b4 ecnica de LSA, que permite extraer relaciones existentes entre palabras a trav\u00b4 es de sus ocurrencias en diferentes contextos. Esta t\u00b4 ecnica ha sido adaptada a nuestras necesidades, transformando el concepto de contextos (documentos) en categor\u00b4 as sem\u00b4 anticas (dominios). 7.1.4 Denici\u00b4 on de los etodos Se han descrito los distintos m\u00b4 etodos de WSD, los cuales, uti- lizan de WordNet, y la t\u00b4 ecnica de LSA. Estos m\u00b4 etodos pueden aplicarse a diferentes lenguas utilizando el enlace ILI de EuroWordNet. \u00b4Unicamente se requiere un prepro- ceso inicial de los textos para obtener los lemas de las palabras del contexto ambiguo. Asimismo, mediante la utilizaci\u00b4 on de la in- formaci\u00b4 on de Extended WordNet se han mejorado los resultados obtenidos en el proceso de desambiguaci\u00b4 on. Todos los m\u00b4 etodos denidos han sido evaluados sobre los cor- pus de Senseval y comparados con el resto de sistemas partici- pantes en las diferentes tareas. 7.1.5 Evaluaci\u00b4 on y aplicaci\u00b4 on de los sistemas de WSD a tareas de PLN Se ha presentado el marco de evaluaci\u00b4 on de sistemas de WSD Senseval , en sus diferentes ediciones. En cada edici\u00b4 on se han 236 7.2 Trabajos Futuros mantenido una serie de tareas relacionadas con WSD ( All Words yLexical Sample en diferentes idiomas) y adem\u00b4 as se han ido a nadiendo progresivamente otro tipo de tareas en las que el pro- ceso de desambiguaci\u00b4 on autom\u00b4 atica es benecioso (Web People Search, desambiguaci\u00b4 on de preposiciones, detecci\u00b4 on de sentimien- tos, etc). Todos los m\u00b4 etodos denidos han sido evaluados siguiendo los criterios de Senseval . Adem\u00b4 as, se ha evaluado la integraci\u00b4 on de estos sistemas no supervisados con otros sistemas de WSD, obteniendo buenos resultados. Dado que la tarea de WSD, no est\u00b4 a considerada como una tarea nal, as\u00b4 como, traducci\u00b4 on autom\u00b4 atica o clasicaci\u00b4 on de do- cumentos, se han realizado una serie de experimentos aplicando los sistemas de WSD sobre otras tareas de PLN. En nuestro caso, se han aplicado para resolver la implicaci\u00b4 on textual, la detecci\u00b4 on de par\u00b4 afrasis o la clasicaci\u00b4 on de nombres propios comunes per- tenecientes a distintas personas. 7.2 Trabajos Futuros Como trabajos futuros queda pendiente la elaboraci\u00b4 on de un sistema de WSD que combine los recursos obtenidos en esta Tesis para crear un sistema de WSD supervisado. El objetivo es deter- minar si el modelado de caracter\u00b4 sticas utilizando un sistema de WSD no supervisado basado en conocimiento, ayuda a un sistema de WSD supervisado. En ( V\u00b4 azquez et al. (2007 )) se describe la propuesta de este sistema. Tambi\u00b4 en queda pendiente mejorar el recurso Relevant Domains incluyendo informaci\u00b4 on relativa a las relaciones existentes entre los dominios y la jerarqu\u00b4 a de relaciones de WordNet: hiponimi- na, meronimia, hiperonimia... As\u00b4 como mejorar la obtenci\u00b4 on de la matriz conceptual utilizada por LSA, incorporando informa- ci\u00b4 on relativa a las relaciones existentes entre palabras: verbos con objetos directos, sintagmas nominales, etc. Adem\u00b4 as, el sistema SenseDiscrim puede ser enriquecido mediante la obtenci\u00b4 on de nue- 7. Conclusiones y trabajos futuros 237 vos patrones que incorporen informaci\u00b4 on relacionada con verbos y adjetivos. Por \u00b4 ultimo, se est\u00b4 a desarrollando la adaptaci\u00b4 on de los m\u00b4 eto- dos descritos en esta Tesis para su aplicaci\u00b4 on a la resoluci\u00b4 on de los tests de TOEFL que tienen como objetivo la detecci\u00b4 on de si- militudes entre pares de palabras. El objetivo de este estudio es determinar si ante la falta de contexto proporcionado, se pueden adaptar los recursos existentes para seleccionar pares de palabras fuertemente relacionadas sem\u00b4 anticamente. 7.3 Producci\u00b4 on cient\u00b4 ca A continuaci\u00b4 on se muestran las publicaciones realizadas como consecuci\u00b4 on de esta Tesis. Todas ellas en orden cronol\u00b4 ogico desde 2002 hasta 2008. 2008 Zornitsa Kozareva, tication Aguascalientes through Semantic and Domain Information. Recent Advances in Natural Language Headline the basis of Name Di- 7. Conclusiones y trabajos futuros 239 antica en un sistema de aprendizaje autom\u00b4 atico para resolver la implicaci\u00b4 on textual. SEPLN 2006. Zaragoza (Espa na). pp: 7.3 Producci\u00b4 on Mu noz. The Role of Temporal Ex- pressions in Word USA). Manchester (Reino Unido). pp: 288- Notes in Computer Science. 2004. Barcelona (Espa na). pp: 147-154. Pro- 7. Conclusiones y trabajos futuros 241 cesamiento del Lenguaje Natural. Vol: V\u00b4 azquez, Andr\u00b4 es Montoyo. Utilizaci\u00b4 on del recurso Dominios Relevantes en WSD. III Jornadas en Tecno- log\u00b4 a del Habla. Valencia (Espa na). Sonia Romero, Armando Su\u00b4 es a, Maria Teresa Mart\u00b4 n, Miguel \u00b4Angel Garc\u00b4 a, Alfonso Ure na, Davide Buscaldi, Paolo Rosso, Antonio Molina, Ferran Pl\u00b4 a, Encarna Segarra. The R2D2 Team at SENSEVAL-3. International Workshop on Evaluating Word Sense Disambiguation Systems (SENSEVAL) in conjunction with the Annual Meeting of for Computational Linguistics. Barcelona (Espa Maria Antonia The Univer- sity of Alicante systems at SENSEVAL-3. International Workshop on Evaluating Word Sense Disambiguation Systems (SENSEVAL) in conjunction with the Meeting of As- sociation for Computational Linguistics. Barcelona (Espa guage Resources and Evaluation (LREC). Lisboa (Portugal). Iulia between lexicon corpus. International Conference on Language Resources and Evaluation (LREC). Lisboa (Portugal). 242 l\u00b4 exico Do- minios Relevantes. SEPLN 2003. Alcal\u00b4 a de Henares (Es- pa na). pp: 141-148. Procesamiento del Lenguaje Natural. Vol: 31. ISSN: 1135-5948. 2002 Sonia V\u00b4 azquez, Susana Soler. The Role of for Multi- lingual Natural Machinery. AR. Association Ratio. AVE . Answer Validation Exercise. BNC Clustering by Committee. CICLING . Architecture for Text Engineering. . Grupo de Procesamiento del Lenguaje Natural. ICAI . International Conference on Articial Intelligence. iCLEF . Interactive track of CLEF ILI. Inter Lingual LREC Language Resources LSA Semantic Conference on Natural Lan- guage to Information Systems. PASCAL . Pattern Analysis, Statistical Modelling and Compu- tational Mutual Information. Question Answering. Espa nola. RANLP . Recent Advances in Natural Language Processing. RI. Recuperaci\u00b4 on de Informaci\u00b4 on. RNA . Red SEPLN . Sociedad Espa nola para el Procesamiento . Subject Field atica. Test de desambiguaci\u00b4 on autom\u00b4 atica ba- sado en modelos de probabilidad de m\u00b4 axima entrop\u00b4 a. Evaluating Word Disambigua- tion . Third In- ternational Workshop on the Evaluation of Systems for the Se- mantic Analysis of Text . ACL , editor (2007). en Rada Mihalcea y Phil Edmonds, editores, Senseval-3: Third International Workshop on the Eva- luation of Systems for the Semantic Analysis of Text , p\u00b4 ags. 1-4, Association for Computational Linguistics, BIBLIOGRAF \u00b4IA Agirre, Eneko Learning\"(CoNLL-2001). Textual Entailment, 2005. , p\u00b4 ags. 61- 64. Allen, James F. (1984). ( (Towards a general theory of action and time Textual Entailment, evaluation: ) ), enProceedings \u00b4IA of Unrestricted Spanish Text) ), enProceedings of First International Conference on Lan- guage Resources and Evaluation (LREC'98) , Granada, Language Processing , Longman, London and New York. Brill, E. (1995). ( (Transformation-based error-driven learning and natural language processing: A A. Della Pietra yVincent J. Della Pietra with mind word expert ) ), enProceedings the monds, editores, Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text , p\u00b4 ags. 5-8, Association for Computational Linguistics, Barcelo- na, Spain. Church, Kenneth ,William Gale ,Patrick yDo- nald Hindle (1991). ( on y desambi- guaci\u00b4 de corpus en espa nol ), Tesis Doctoral. Universidad de Barcelona. (2004). ( Thomas Thomas (1991). Elements of information theory , Wiley-Interscience, New York, NY, USA. Cowie, Jim resources ) ), en Czech Republic. Cunningham, H. (2002). ( (GATE, a General Architecture for Text Engineering ) ),Computers and the Humanities ,36, 223-254. Cunningham, H. (2005). ( (Information Extraction, Automa- tic) ),Encyclopedia of Language and Linguistics, 2nd Edition . D., Harman (1995). (trec-3) ) ), National Institute of Special Publication 500-225, US. D., Harman (1996). (trec-4) ) ), National Institute of Standards and Technology (NIST) Special Publication 500-236, US. Dagan, I. ,A. Itai yU. Schwall languages are one ) ),Proceedings , Entailment . Dagan, Ido yFernando C. (Similarity-based Computational Linguistics , ags. 164-171. Dagan, on Computational Linguistics , Sons. Edmonds, Philip yAdam Kilgarriff (1998). ( (Introduction to ), enProceedings the 14th Articial Intelligence, ECAI-2000 , Berlin, Germany. Everitt, B. S. (1977). The analysis of contingency tables , Chapman and Hall. Electronic Lexi- cal Database , The MIT Press. Firth, J. R. (1957). ( (A synopsis of linguistic theory. studies in William Prentice-Hall. Framis, corpus manual ) ), inf. t\u00b4 ec. , Department of Linguistics, Brown University, Providen- ce, Rhode Island, US. Furnas, George W. ,Scott C. Deerwester ,Susan T. Dumais ,Thomas K. Landauer ,Richard Language Tecnology , p\u00b4 ags. 303-308, Plains- boro, New yD. Yarowsky (1992a). ( corpus ) and the Humanities ,26, 415-439. p\u00b4 ags. cuanticaci\u00b4 Docto- ral. Departamento de Inform\u00b4 atica. Universidad Ja\u00b4 en. Very Large Corpora, ACL. Gonzalo, Julio yDouglas W. Oard Cai (2004). ( (Coh-metrix: Analysis of and language. (Finding ), en Rada Mihalcea y Phil Edmonds, editores, Senseval-3: Third Interna- tional Workshop on the Evaluation of Systems for the Semantic Analysis of Text , p\u00b4 ags. 125-128, Association for Computational Linguistics, Barcelona, Spain. Haley, Debra Trusso ,Pete Thomas ,Anne De Roeck y Marian Petre (2005). (A ) of the International Conference on Recent Advances in Natural Language Processing , p\u00b4 ags. 21-23. lan- guage technology ) ), Morgan comparative de la distribution flo- rale dans une portion des alpes et des jura ) ),Bull Soc Vaudoise Sci Nat ,37, 547-579. 256 BIBLIOGRAF ACM SIGIR Research and develop- ment in information retrieval , p\u00b4 ags. 90-96, ACM Press, New York, NY, (2001). (English lexical sample task p\u00b4 edition , Springer-Verlag New \u0013es Montoyo (2006). ( (Mlent: the university of ali- cante) ), enIn Proceedings of answer 8th Association for Computational Linguis- tic, semantic ), en , p\u00b4 211-240. yG. Koch ( (The natural language processing ) ),CoRR How to an ice cream cone ) ), enProceedings of 1986 p\u00b4 text ) ), In Proceedings of the 3rd Annual Symposium on Document Analysis and Information Retrieval. Lin, Dekang (1997). (Using syntactic ), enProceedings Association for Computational Linguistic and the 8th Conference of Rada Mihalcea y Phil Edmonds, editores, Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of editores, Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text , p\u00b4 ags. 13-16, Association for Linguistics, Fernando ( (Ir-n: Un sistema de recuperaci\u00b4 on de informaci\u00b4 on en pasajes ) ), Tesis Doctoral. Departamen- BIBLIOGRAF \u00b4IA 259 to de y Sistemas Inform\u00b4 aticos, Universidad de Alican- te. Luk, A. Rada Mihalcea y Phil Edmonds, editores, Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text , p\u00b4 ags. 17-20, Senses and Multilinguality , Hong Kong, China. Mann, Gideon S. (2006). ( fact ex- traction Thesis. Manning, D. yH. Sch Foundations of Statis- tical Natural Language Processing , The MIT Markov, A. (1971). ( (Extension of the limit theorems of pro- bability theory to a sum of variables connected in a chain ) ), en Dynamic Probabilistic Systems, y Phil editores, Senseval-3: Third Interna- tional Workshop on the Evaluation of Systems for the Semantic 260 BIBLIOGRAF \u00b4IA Analysis Text , y Phil monds, editores, Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text spanish ) ), en Proceedings Fourth Empirical Methods in Natural Language Proces- sing and Very Large , Hong Kong. Sisteams Inform\u00b4 aticos. Universidad del Pa\u00b4 s Vas- co. McCarthy, ,Julie (2004). Susan Rada Mihalcea y Phil Edmonds, editores, Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text , p\u00b4 ags. 25-28, ), enProceedings of en Rada Mihalcea y Phil Edmonds, editores, Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text , p\u00b4 ags. 29-32, Association for Com- putational Hill. Mitchell, language ) ), p\u00b4 ag. 391. Molina, Antonio ,Ferran Pla yEncarna Segarra (2002). ( (A hidden markov model de Len- guajes An machine 1st Morgan Kaufmann, San CA. ) Mihalcea y Phil Edmonds, editores, Senseval-3: Third International Works- hop on the Evaluation of Systems for the Semantic Analysis of Text, p\u00b4 ags. 33-36, Association for Computational Linguistics, Barcelona, en Morgan editor, Machine Learning . Quinlan, Ross (1993). C4.5: Programs for Machine Learning , Morgan Kaufmann. Rada, R. ,H. Mili ,E. Bicknell yM. Blettner (1989). ( (Development an Application on Semantic Nets ) ), Rada Mihalcea y Phil Edmonds, editores, Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text , p\u00b4 ags. 217-221, Association for Computational Linguistics, Barcelona, R. decomposition, apportionment and Ratnaparkhi, Adwait conjunction with Linguistics (ACL 2000) , p\u00b4 ags. p\u00b4 Rigau, aticos, Universidad Polit\u00b4 ecnica ( (Learning decision lists ) ),Machine Learning ,2, 229-246. ,Francesco ,Davide Buscaldi , Ferran Pla , p\u00b4 Pla ,Daniel Jim\u0013enez yVicente Vidal (2004). ( identi- cation systems ), en Rada Mihalcea y Phil Edmonds, editores, Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of ags. 37-40, Asso- (1995). nal ACM SIGIR Conference on Research and Development in Information Retrieval , p\u00b4 ags. 142-151. ), enProceedings of , p\u00b4 ags. Small, Steven yCharles Rieger (1982). Parsing and com- prehending with word experts (a theory and its realization) p\u00b4 ags. 89-147, Lawrence Lenhert and Martin Ringle ed. Snyder, Benjamin Palmer (2004). ( (The english all-words task ) ), en Rada Mihalcea y Phil Edmonds, editores, Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of en Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text , uedad sem\u00b4 antica de palabras mediante de m\u00b4 axima entrop\u00b4 a ) ), Tesis Doctoral. Departamento de Lenguajes y Sistemas Inform\u00b4 aticos, Universidad de Alicante. Towell, Geoffrey Mihalcea y Phil Edmonds, editores, Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text , Association for Com- putational Linguistics, Barcelona, Spain. diante ),Procesamiento , 29, 39-45. Vapnik, Vladimir ( Disambi- p\u00b4 machine learning system ) ), enMexican International Conferen- ce on Articial Intelligence , Lecture Notes in Computer Science, p\u00b4 ags. 996-1003, Dominic yStanley Peters (2003). (Word Yorick (1972). ( H. yEibe Frank (1999). Data Mining: Practical Machine Learning Tools and Techniques with Java Implementa- tions, Morgan Kaufmann. Yarowsky, David per collocation ) ), enPro- ceedings Spanish French text ) ), en Proceedings of the 2th Annual Workshop ), enProceedings of W. Mellon Foundation . 270 BIBLIOGRAF \u00b4IA Reunido el Tribunal que suscribe en el d\u00b4 a de la fecha acord\u00b4 o otor- gar, por a la Tesis Doctoral de Don =Do na. Sonia V\u00b4 azquez P\u00b4 erez la calicaci\u00b4 on de . Alicante de de El Secretario, El Presidente, UNIVERSIDAD DE ALICANTE Comisi\u00b4 on de Doctorado La presente Tesis de D. Sonia V\u00b4 azquez P\u00b4 erez ha sido registra- da con el no del registro de entrada correspondiente. Alicante de de El Encargado del Registro, La defensa de la tesis doctoral realizada por D =DaSonia V\u00b4 azquez P\u00b4 erez se ha realizado en las siguientes lenguas: y , lo que unido al cumplimiento del resto de requi- sitos establecidos en la Normativa propia de la UA le otorga la menci\u00b4 on de \"Doctor Europeo\". Alicante, de de EL SECRETARIO EL PRESIDENTE "}