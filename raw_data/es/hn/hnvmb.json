{"title": "Difundir desinformaci\u00f3n con IA solo cuesta 400 d\u00f3lares", "author": "Cond\u00e9 Nast; Will Knight; Andrei Osornio", "url": "https://es.wired.com/articulos/difundir-desinformacion-con-ia-solo-cuesta-400-dolares", "hostname": "wired.com", "description": "Como parte de una campa\u00f1a experimental, se utilizaron herramientas de IA disponibles para generar tuits y art\u00edculos contra Rusia, con el fin de evidenciar lo econ\u00f3mico y sencillo que es crear propaganda pol\u00edtica a gran escala.", "sitename": "WIRED", "date": "2023-08-29", "cleaned_text": "En mayo, Sputnik International, un medio de comunicaci\u00f3n ruso de propiedad estatal, public\u00f3 una serie de tuits en los que arremet\u00eda contra la pol\u00edtica exterior de Estados Unidos y atacaba a la administraci\u00f3n Biden. Cada uno de ellos suscit\u00f3 una r\u00e9plica cortante pero bien elaborada de una cuenta llamada CounterCloud, que a veces inclu\u00eda un enlace a una noticia o a un art\u00edculo de opini\u00f3n relevante. Gener\u00f3 respuestas similares a los tuits de la embajada rusa y de medios de comunicaci\u00f3n chinos que criticaban a Estados Unidos. Las cr\u00edticas de Rusia a Estados Unidos no son inusuales, pero el material de CounterCloud s\u00ed: los tuits, los art\u00edculos, e incluso los periodistas y sitios de noticias, fueron elaborados en su totalidad por algoritmos de [inteligencia artificial (IA)](https://es.wired.com/tag/inteligencia-artificial), seg\u00fan la persona que est\u00e1 detr\u00e1s del proyecto, que se hace llamar Nea Paw y asegura que est\u00e1 dise\u00f1ado para evidenciar el peligro de la desinformaci\u00f3n generada en masa por la IA. Paw no public\u00f3 los tuits y art\u00edculos de CounterCloud, pero los facilit\u00f3 a WIRED. Desinformaci\u00f3n al alcance de todos, gracias a la IA Paw afirma ser agente profesional de ciberseguridad y prefiere el anonimato porque algunas personas quiz\u00e1 crean que el proyecto es irresponsable. La campa\u00f1a CounterCloud que hace frente a los mensajes rusos se elabor\u00f3 utilizando la tecnolog\u00eda de generaci\u00f3n de texto de [OpenAI](https://es.wired.com/articulos/openai-y-chatgpt-podrian-tener-su-propia-tienda-de-aplicaciones) (la que est\u00e1 detr\u00e1s de [ChatGPT](https://es.wired.com/tag/chatgpt)) y otras herramientas de IA de f\u00e1cil acceso, para crear fotograf\u00edas e ilustraciones por un costo total de unos 400 d\u00f3lares, seg\u00fan cuenta Paw. Paw sostiene que el proyecto demuestra que las herramientas de IA generativa ampliamente disponibles facilitan enormemente la creaci\u00f3n de campa\u00f1as de informaci\u00f3n sofisticadas que difunden propaganda respaldada por el gobierno. \"No existe una soluci\u00f3n milagrosa para esto, del mismo modo que no hay una para los ataques de phishing, spam o ingenier\u00eda social\", declara Paw en un email. Es posible aplicar medidas correctivas, como educar a los usuarios para que est\u00e9n atentos a los contenidos manipuladores generados por IA, hacer que los sistemas bloqueen sus usos indebidos o dotar a los navegadores de herramientas de detecci\u00f3n. \"Pero ninguna de estas opciones es elegante, econ\u00f3mica o particularmente eficaz\", destaca Paw. En los \u00faltimos a\u00f1os, los investigadores de la desinformaci\u00f3n han advertido de que los modelos de lenguaje de IA podr\u00edan utilizarse para desarrollar campa\u00f1as de propaganda altamente personalizadas y para impulsar cuentas de redes sociales que interact\u00faen con los usuarios de forma avanzada. Renee DiResta, directora de investigaci\u00f3n t\u00e9cnica del Observatorio de Internet de Stanford, y quien realiza un seguimiento de las campa\u00f1as de informaci\u00f3n, resalta que los art\u00edculos y perfiles de periodistas generados como parte del proyecto CounterCloud son bastante convincentes. \"Adem\u00e1s de los actores gubernamentales, las agencias de gesti\u00f3n de redes sociales y los mercenarios que ofrecen servicios de operaciones de influencia sin duda adoptar\u00e1n estas herramientas y las incorporar\u00e1n a sus flujos de trabajo\", observa DiResta. Conseguir que los contenidos falsos se distribuyan y compartan a gran escala es todo un reto, pero es posible pag\u00e1ndole a usuarios influyentes para que los difundan, a\u00f1ade. Ya han aparecido algunas pruebas de campa\u00f1as online de desinformaci\u00f3n impulsadas por IA. Recientemente, unos investigadores acad\u00e9micos descubrieron una [red de bots rudimentaria que promov\u00eda criptomonedas](https://es.wired.com/articulos/estafadores-y-criptomonedas-redes-criminales-usan-chatgpt-para-enganar-a-usuarios-de-x) y que, al parecer, funcionaba con ChatGPT. El equipo se\u00f1ala que el descubrimiento sugiere que es probable que la inteligencia artificial que sustenta el chatbot ya se emplee para iniciativas m\u00e1s elaboradas. Las campa\u00f1as pol\u00edticas leg\u00edtimas tambi\u00e9n han recurrido a la inteligencia artificial antes de las elecciones presidenciales de Estados Unidos de 2024. En abril, el Comit\u00e9 Nacional Republicano produjo un video atacando a Joe Biden que inclu\u00eda im\u00e1genes falsas generadas por IA. Y en junio, una cuenta de redes sociales asociada al gobernador de Florida Ron Desantis present\u00f3 un video elaborado con dicha tecnolog\u00eda para desacreditar a [Donald Trump](https://es.wired.com/articulos/la-foto-de-la-ficha-policial-de-donald-trump-esta-vez-es-de-verdad). La Comisi\u00f3n de Elecciones Federales del pa\u00eds comunic\u00f3 posiblemente limite el [uso de deepfakes](https://es.wired.com/articulos/synthesia-empresa-de-ia-que-vende-deepfakes) en la publicidad de asuntos pol\u00edticos. Micah Musser, un investigador que estudia el potencial de desinformaci\u00f3n en los modelos de lenguaje de IA, prev\u00e9 que las principales campa\u00f1as pol\u00edticas intentar\u00e1n recurrir a ellos para generar contenido promocional, correos electr\u00f3nicos para recaudar fondos o anuncios de ataque. \"Actualmente vivimos un per\u00edodo totalmente inestable, en el que no est\u00e1 muy claro cu\u00e1les son las normas\", opina. Gran parte del texto generado por IA sigue siendo bastante gen\u00e9rico y f\u00e1cil de reconocer, asevera Musser. Pero ese contenido intervenido y refinado por humanos para difundir desinformaci\u00f3n ser\u00eda muy eficaz, y casi imposible de detener aplicando filtros automatizados, subraya. [Sam Altman, CEO de OpenAI](https://es.wired.com/articulos/quien-es-sam-altman-cofundador-de-openai-y-responsable-de-chatgpt), expres\u00f3 en un tuit el mes pasado que le preocupa que la inteligencia artificial de su compa\u00f1\u00eda se emplee para generar desinformaci\u00f3n personalizada y automatizada en un nivel masivo. Cuando OpenAI puso por primera vez a disposici\u00f3n su tecnolog\u00eda de generaci\u00f3n de texto a trav\u00e9s de una interfaz de programaci\u00f3n de aplicaciones, prohibi\u00f3 cualquier uso pol\u00edtico. Sin embargo, este mes de marzo, la empresa actualiz\u00f3 sus t\u00e9rminos para impedir que se implemente en la producci\u00f3n masiva de mensajes para determinados grupos demogr\u00e1ficos. Un reciente art\u00edculo del Washington Post sugiere que el sistema GPT no bloquea por s\u00ed mismo la generaci\u00f3n de ese tipo de material. Kim Malfacini, responsable de la pol\u00edtica de productos de OpenAI, asegura que la empresa est\u00e1 estudiando la forma en que su tecnolog\u00eda de generaci\u00f3n de texto se utiliza con fines pol\u00edticos. La gente a\u00fan no est\u00e1 acostumbrada a asumir que el contenido que ve quiz\u00e1 haya sido creado por una inteligencia artificial, dice. \"Es probable que el uso de herramientas de IA en cualquier n\u00famero de sectores no haga m\u00e1s que crecer, y la sociedad se adaptar\u00e1 a ello\", destaca Malfacini. \"Pero por el momento las personas a\u00fan est\u00e1n en proceso de asimilaci\u00f3n\". Dado que en la actualidad existe una gran cantidad de herramientas de IA similares, incluidos [modelos de c\u00f3digo abierto](https://es.wired.com/articulos/llama-2-el-codigo-abierto-de-meta-es-el-nuevo-caballo-en-la-carrera-de-la-ia) sobre los que se construye con pocas restricciones, los votantes deber\u00edan volverse conscientes del uso de la inteligencia artificial en la pol\u00edtica cuanto antes. Art\u00edculo publicado originalmente en [WIRED](https://www.wired.com/story/400-dollars-to-build-an-ai-disinformation-machine/). Adaptado "}