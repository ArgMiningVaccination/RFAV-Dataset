{"title": "Untitled", "author": null, "url": null, "hostname": null, "description": null, "sitename": null, "date": "1995-01-01", "cleaned_text": "Readings: Mr. Copy, 10th and Dunn Book: Resnick, M. (1994). Turtles, Termites, & Traffic Jams. Cambridge: MIT Press. ____________________________________________________________ Many of our most pressing problems center on systems having parts that evolve and adapt over time. Important problems in psychology, computer science, economics, ecology, and neuroscience depend upon a deeper understanding of the mechanisms that propel these Complex Adaptive Systems. A common feature of these systems is that organized behavior emerges from the simultaneous interactions of many units. Each of these interactions taken by itself is simple and perhaps \"stupid,\" but when combined together, purposeful, intelligent, and highly structured behavior arises. The basic question surrounding this course is: What are the properties of complex systems? To address this question, case studies of several complex systems will be identified, and the mechanisms that determine their behavior will be explored. The central thesis is that widely different systems (from businesses to ant colonies) share fundamental commonalities. Identifying what those commonalities are will be the central task of the course. Although case studies from several different areas will be discussed, this is not intended to be a survey course. The case studies will be examined only from the perspective of how they achieve the properties associated with complex, adaptive systems. Rather than trying to exhaustively cover every instantiation of a complex system, we will focus on four or five examples. The course is built around one issue (the nature of complexity and adaptation), but unlike other TOPICS courses that cover a concrete phenomenon (such as earthquakes or vikings), the single issue covered in this course is abstract, with links to areas across many disciplines. The goals of the course are to: 1) give students an intuitive appreciation for the behavior of complex adaptive systems, 2) present the student with specific case studies of these systems, and 3) describe the formal underpinnings for the complex behavior of these systems. This third goal is essential. The behavior of complex systems is fascinating and provocative. At first, their ability to organize, reproduce, learn, and produce novel behavior seems nothing short of miraculous. The goal of this course is to show how these miracles can be explained in terms of simple principles of mathematics, computation, and mechanics. With luck, the knowledge that these simple formal devices can produce such sophisticated behavior will increase, rather than decrease, your sense of excitement in these systems. Examples of complex systems occur in all of the sciences. In psychology, our sophisticated cognitive abilities arise from neurons passing excitatory and inhibitory impulses to each other. In economics, organized global economies emerge from local commerical transactions between individuals. In biology, the patterns of stripes on a zebra be explained by excitatory and inhibatory interactions between cells that contain pigmentation. In all of these cases, computer models have shed much light on the particular interactions that give rise to global structures. Properties that are shared by many complex adaptive systems include: 1. Emergent behavior. Most complex systems involve a network of many interacting objects (agents, species, antibodies, neurons, etc.). They exhibit a dynamic, aggregate behavior (the GNP of an economy, the flows of material and energy in an ecology, overall immune response, the overt behavior of an organism, etc.). The aggregate behavior can usually be described without reference to behavior of the network's constituent objects. However, understanding only comes when one can describe the way in which that aggregate behavior emerges from the interactions of the constituent objects. Because local interactions in the network are context dependent, involving feedback and anticipation, the action of the whole is more than a simple sum of the actions of the parts. 2. Adaptation. Constituent parts of the system adapt (\"fit\") to each other and to the general surroundings. Adaptation is a familiar biological process. On one scale, adaptation makes it possible for certain bacteria to use sulfur for respiration; on another scale, it encompasses processes such as learning, co-operation, and co-evolution. An adaptive process has three components: (i) a system called an environment, (ii) a system, called an adaptive system, that interacts with the environment, and (iii) a measure of performance (payoff rate, reward, fitness, utility, or error rate) that rates the behavior of the adaptive system in its environment. An adaptive system is said to adapt if it interacts with its environment in a way that increases the value of its performance over time. 3. Specialization. Agents that start out as undifferentiated become specialized with time. The personnel of a business assume more specialized roles as the business becomes larger. A species of animals may, with time, evolve into specialized sub-species that are adapted to particular environments. Cells in our nervous system become specialized with development to handle particular types of information. 4. Dynamic changes. The systems that we discuss change their behavior over time. Complex adaptive systems typically operate far from optimally so that improvement is a continuing possibility. For this reason, standard theories in physics, economics, and elsewhere are of little help because they concentrate on optimal end-points, whereas complex adaptive systems \"never get there.\" They continue to evolve and they steadily exhibit new forms of emergent behavior. History and context play a critical role in the development of these systems. Some agents in the system may settle down temporarily at a local minimum, but they are usually \"dead\" or uninteresting if they remain at that equilibrium for an extended period. 5. Competition and Cooperation. The individual agents that compose a complex adaptive system often enter into patterns of competition and cooperation with each other. Social groups (countries, poltical movements, and clubs) form bonds of cooperation, and enter into competition with other groups. Animals compete for the right to control spatial territories. More abstractly, words compete for the right to cover conceptual territories (we do not use the word \"sheep\" to cover sheeps as they are eaten in restaurants because we have the word \"mutton.\" In French, where there is not this competitor word, the word for \"sheep\" covers living and eaten sheep). Lateral inhibition, the tendency for neighboring neural units (neurons) to compete against each other, can account for our general ability to make clear-cut categorizations between objects and to emphasize important visual properties of our world. By understanding the ways in which agents form and dissolve groups, we can predict many of the behavioral patterns of physical systems, animals, people, and societies. 6. Decentralization. Does every group have a leader? Does every pattern have a central cause? Most people tend to think so. Increasingly, analyses of complex models have begun to question this assumption. There exist highly organized systems that nonetheless have no single agent which is \"in charge.\" Because these systems have no central agent, they are called \"decentralized.\" Certainly grass-roots political movements are examples of decentralized systems, but there are many others: the human system for maintaining balance and coordination, the visual system for recognizing patterns such as dog and table, and the social structure of ant colony (the queen ant plays a unique role in the colony, but is not \"in charge\" of the other ants). This course is intended to expose undergraduate students to the behavior and underlying principles of complex adaptive systems. Complex adaptive systems synthesize research from cognitive psychology, computer science, neuroscience, philosophy, biology, and economics. Special attention will be given to complex adaptive systems in: cognitive neuroscience, perception, human learning, chaos and dynamics, information theory, concept formation, neural networks, and genetic algorithms. The particular complex adaptive systems that we discuss will depend on the professor's expertise, but the same core properties will be found across many areas. Although this course is technically a lecture course, the class is designed to be a discussion-based course. Lectures will be prepared, but the main bulk of the class will depend on your contribution. Class discussions will center on the readings scheduled for the class. Thus, it is imperative that you do the reading, or you will have little to discuss. At many points during the course, class time will be spent demonstrating computer programs that you will be using to explore complex adaptive systems. In the same way that the astronomer uses a telescope and the biologist uses a microscrope, the main occupational tool of scientists interested in complex adaptive systems is computer simulations of natural phenomena. With the advent of fast computer technologies in the last few years, we now have many tools for exploring complex adaptive systems that have never before been available. Throughout the semester, you will be given several homework assignments that involve computer simulations. In these assignments, you will first gain familiarity with the particular theory behind the simulation. Then, you will familiarize yourself with the computer program that embodies this theory. During this time, you will explore different parameters, patterns, and rules for describing the interactions among agents. The single best way to intuitively understand the properties of complex adaptive systems is to explore in an open-ended manner the behavior of the system. This is done by making small changes to the system's variables, and observing the resulting consequences for the global behavior of the system. Finally, you will be given a specific homework assignment to probe your knowledge of the system. The homework assignment will incorporate simple descriptions, (e.g. \"What does the system do when you do this?\"), and short answer questions (e.g. \"Why does this system exhibit this type of property?\"). Breakdown of grade: Exam I - 30% Exam II - 30% (non-cumulative) Computer Lab Assignments - 40% Exams. Exams will consist of short answer, multiple-choice, and fill-in-the-blank questions. You are responsible for everything covered in the textbook and in the lectures. A somewhat greater percentage of the questions will come from lectures as opposed to the textbook/readings. An attempt will be made to design questions that test your knowledge of general concepts and definitions, underlying principles, and important experimental methods and results. You should study and read for comprehension as opposed to brute memorization. Exams will not be graded on a curve, however if the class average is below 75 (a \"C\") on an exam then points will be added to everybody's grade to bring the average up to 75. Thus, everybody could conceivably receive an \"A,\" but everybody could not receive an \"F.\" If you wish to dispute the manner in which a question was graded, give me a written argument for why I was wrong. Computer Laboratory Assignments. There will be 11 computer assignments over the course of the semester. You are expected to complete 9 of these assignments. Each assignment will require you to answer about three or four questions about the operation of a particular complex adaptive system as simulated on a computer. Although creativity may be required in setting up a suitable test of the system, these questions usually have objectively correct or wrong answers, and can be answered in less than two paragraphs each. Laboratory assignments will be due one week after they have been assigned. All of the computer assignments are designed for Macintosh computers. There are several Macintosh computer laboratories around campus. In the first week of this course you should familiarize yourself with these computer laboratories and the Macintosh computer system if you haven't already. Disclaimer. This syllabus is not definitive. Course policies are subject to change at any time. You will be notified of any changes. Getting the most out of the class. This course should be one of the most important and interesting courses you take. The following pointers can help to ensure this. 1. Question your professor, and your readings. True knowledge only comes from an active engagement of the material. Questions in class are welcome, and prolonged class discussions should be looked upon as learning opportunities rather than digressions. 2. Explain the material to yourself. Don't expect the material to seep its way into your head; you must actively carry it in. 3. Apply principles to your everyday life and your other interests. 4. Try to appreciate the deep, underlying issues. Data and experiments are important; getting the details right is critical. But, also consider the motivation, assumptions, and implications of the results. 5. View the field as ongoing investigations, not as solved puzzles. 6. Visit me outside of class. I am eager to meet any students to discuss cognitive science broadly construed. Bak, P. (1994).Self-organized criticality: A holistic view of nature. in G. A. Cowan, D. Pines, & D. Meltzer (Eds.) Complexity: Metaphors, models, and reality. Reading, MA: Addison-Wesley. (pp. 477-495). Best, J. B. (1995). Cognitive Psychology. (Chapter 7, pp. 240-268). Casti, J. L. pp. 212-260). Coveney, P., & Highfield, R. (1995). Frontiers of complexity. New York: Fawcett Columbine. Gilden, D. L., Thornton, T., & Mallon, M. W. (1995). 1/f noise in human cognition. Science, 267, 1837-1839. Gleick, J. (1987). Chaos. New York: Penguin Books. (pp. 59-80) Goldberg, D. E. (1989). Genetic Algorithms. Reading, MA: Addison-Wesley. (Chapter 1. pp. 1-23). Goodwin, B. (1994). How the leapard changed its spots. New York: Touchstone. (Chapter 5, pp. 115-132). Gould, S. J. (1993). Eight Little Piggies. London: Jonathan Cape. (Chapter 6. pp. 108). Holland, J. H. (1992). Genetic Algorithms. Scientific American, July, 66-72. Langton, C. G. (1988). Artificial Life. In C. G. Langton (Ed.) Artificial Life. Redwood City, CA: Addison-Wesley. (pp. 1-47). Levy, S. (1992). Artificial Life. New York: Random House. (pp. 49-83) McClelland, J. L., Rumelhart, D. E., & Hinton, G. E. (1986). The appeal of parallel distributed processing in D. E. Rumelhart & J. L. McClelland (Eds.) Parallel Distributed Processing: Volume 1. (Chapter 1. pp 3-44). Murray, J. D. (1993). How the leopard gets its spots. Scientific American. Resnick, M. R. (1994). Turtles, Termites, and Traffic Jams. Cambridge, MA: MIT Press. (Chapter 1. pp. 3-19). Resnick, M. R. (1994). Turtles, Termites, and Traffic Jams. Cambridge, MA: MIT Press. (Chapter 2. pp. 23-46). Ramachandran, V. S., & Anstis, S. M. (1986). The perception of apparent motion. Scientific American, June, 102-109. Rumelhart, D. E. (1989). The architecture of mind: A connectionist approach. in M. I. Posner (ed.) Foundations of Cognitive Science. Cambridge: MIT Press. (pp. 133-160). Sims, K. (1994). Evolving 3D morphology and behavior by competition. in R. A. Brooks & P. Maes (Eds.) Artificial Life IV: Proceedings of the Fourth International Workshop on the Synthesis and Simulation of Living Systems. Cambridge, MA: MIT Press. (pp. 28-39). Treisman, A. (1986). Features and objects in visual processing. Scientific American, November, 114-125. Waldrop, M. M. (1992). Complexity. New York: Simon & Schuster. Week 1: Introduction to Complex adaptive systems Monday 1/13/97: No reading Wednesday 1/15/97: Resnick, Chapter 1, pp. 3-19 Laboratory 1/17/97: No assignment. Familiarization with computer system Topics: Analogical Reasoning and science. Properties of Complex Adaptive Systems. Traditional Artificial Intelligence. Examples. Advantages of decentralized processes (flexibility, ease of description, self-organization) Week 2: Computer Simulation of Natural Processes Monday 1/20: Langton Wednesday 1/22: Levy of Life: Lifelab Topics: An introduction to computer simulations. Practical information on accessing computers and software at I.U. The goals and tools of computational simulations. Criteria for evaluating simulations. Week 3: Starlogo Monday 1/27: Resnick Chapter 2, pp. 23-46 Wednesday 1/29: Read descriptions of the Starlogo language, and Langton's Ant Laboratory 1/31: Programming Langton's ants with Starlogo, and Ising. Topics: Starlogo programming language. Comparisons to other languages. Commands and program logic. Langton's ants. Week 4: Complex Adaptive Systems in Biology I Monday 2/3: [speaker?] Resnick Chapter 3, pp. 49-95. Wednesday 2/5: Laboratory 2/7: Slime Mold, Ants. Topics: Decentralization in consciousness, industries, and social alliances. Demonstrate flocking behavior. Basic evolutionary theory and invention. Speciation. Week 5: Complex Adaptive Systems in Biology II Monday 2/10: Goodwin [guest speaker?] Wednesday 2/12: Murray article. Laboratory 2/14: Morphogens (Pattern CLA), Rabbits Topics: Cooperation and competition. Cellular Automata. Growth & Form. Goodwin - pine cone's and fibonacci sequence. Differential adhesion model of group formation. Turtles and frogs. Week 6: Natural and Artificial Life Monday 2/17: Gould life systems. Preadaptations. Convergences. Predator-prey relations. Evolution and improvement. Baldwin effect. Speciation, adaptation, resource allocation, co-evolving systems. Properties of evolving systems: fitness, exploration & exploitation. Real Evolution. Sim's evolution of morphology through competition and other videos. Week 7: Chaotic and Dynamic Systems Monday 2/24: Gleick Wednesday 2/26: Laboratory 2/28: Chaos Explorer Topics: definition of chaotic systems. Chaos vs. Randomness. Historical considerations. Chaos Game. Population growth. Bifurcation plots, Cantor sets, escape times. Applications of Chaos in olfaction and forecasting. Week 8: Review and Exam Monday 3/3: Review and Loose ends. Wednesday 3/5: Exam Laboratory 3/7: No assignment. Go over exam Week 9: Genetic Algorithms Monday 3/10: Holland Wednesday 3/12:Goldberg Laboratory 3/14: Travelling Salesman problem, number sorting problem Topics: description of systems, cross-over and mutation, fitness function, building blocks. Schemas. Search. Week 10: Neural Networks that Cooperate and Compete Monday 3/24: McClelland & Rumelhart Wednesday 3/26: Laboratory 3/28: Elementary neuroscience. Activation and inhibition. Emergent schemas. Energy minimization. Distributed memories. Models of the word-superiority effect. Week 11: Neural Networks that Learn I Monday \"Spinning Brain\" description Hebbian Learning. Properties of connectionist systems: graceful degradation, content-addressability, noise tolerance. Week 12: Neural Networks that Learn II Monday 4/7: Rumelhart Wednesday 4/9: Read description of DartNet? Laboratory 4/11: DartNet. Pattern Association and XOR Topics: Supervised Learning. Delta Rule. Single-layer networks. Multiple-layer networks. Developing internal representations. Kohonen Networks. Competitive Learning demonstration. Describing DartNet. Week 13: Human Perception and Cognition Monday 4/14: - Wednesday 4/16: Read \"Feature search laboratory\" description Laboratory 4/18: Feature search experiment in humans Topics: Basic perceptual processes, lateral inhibition, holism and analytic processes, models of pattern recognition. Consciousness. Binding. Demonstration of Optical Character Recognition software and Letter Spirit Week 14: Perceptual Processes Monday 4/21: Ramachandran & Anstis Wednesday 4/23: Read \"Apparent motion Laboratory 4/25: on apparent motion Topics: Three-dimensional perception and stereograms, Top-down effects and bottom-up effects in perception. Cooperation and Competition in creating alignments. Week 15: Emergent Properties Monday 4/28: Casti Wednesday 4/30: Gilden, D. L., Thornton, T., & Mallon, M. W. Laboratory 5/2: Picture cover, Path finder Topics: Emergent phenomena. Self-organized criticality (Bak). Fractal dimensions. 1/f noise. Noise and search. Specialization. Constraint satisfaction. Samuel's checkers machine. Exam: 12:30-2:30, May 7, Psychology 101 "}