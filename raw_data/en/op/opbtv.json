{"title": "PDF", "author": "PDF", "url": "https://biostat.app.vumc.org/wiki/pub/Main/CourseBios6321Spring2020/LN2020.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "Tatsuki Koyama, PhD Department of Biostatistics, Vanderbilt University School of Medicine tatsuki.koyama@vumc.org Spring 2020 Last updated: July 15, 2020 Copyright 2011-2020. T Koyama. All Updated: 7/15/2020 21:20 R version: 4.0.1Contents 1 Introduction: Observational in statistics 8 2.1 Condence interval for crossover design for the comparison of two active treatments and placebo 13916.6 studies and experiments 1.1 Observational studies Observational study A study design in which the investigator does not control the assignment of treatment of individual study subjects (Piantadosi1) Experiment A study in which the investigator makes a series of observations under controlled/arranged conditions. In particular, the investigator controls the treatment applied to the subjects by design. (Piantadosi) Clinical trial A prospective study comparing the effect and value of an intervention against a control in human subjects (Friedman2) Advantages of observational studies include: \u000fLower cost. \u000fGreater timeliness. \u000fA broad range of patients. \u000fGreater application where experiments would be impossible or unethical. 1.1.1 Example: PCOS Prostate cancer is the second leading cause of cancer death among American men behind lung cancer. The common treatment choices for localized disease are surgery, radiation, and observation. 1Clinical Trials: A Methodologic Perspective 2Fundamentals of Clinical Trials 1Suppose we are interested in comparing effectiveness of surgery and radiation therapies. The Prostate Cancer Outcomes Study (PCOS): Subjects were identied through six sites participat- ing in the NCI's SEER ( https://seer.cancer.gov/ ) program. dim(SR) [1] 2091 XRT only 272 373 prop.table(table(SR$Trt, SR$vital), margin = RP only 0.7176 0.2824 XRT only 0.4217 0.5783 Can we conclude that surgery is better? chisq.test(table(SR$Trt, SR$vital), correct = FALSE) Pearson cause-and-effect association from an observational study is difcult because of confounders . Confounder A prognostic factor that is associated with both response (e.g. survival) and explana- tory variable (e.g. treatment choice). N RP only XRT only Test Statistic N= 1445 74% (230) the lower the median b, and the upper quartile cfor continuous variables. Nis the number of non-missing values. Numbers after percents are frequencies. Tests used: 1Pearson test;2Wilcoxon test Table 1.1: PCOS study Let's analyze the data with a method that accounts for the baseline difference in the two treatment groups. 3Survival\u0018Treatment\u0003(Age + PSA + Stage + Tumor grade) How about race? comorbidities? sex? smoking? Many statistical methods exist to establish causal relationship from an observational study such as propensity scores and instrumental variables. Can observational studies establish a cause-effect association? \u000fhttps://www.jti.com/about-us/our-business/our-attitude-to-smoking \u000fhttps://www.pmi.com/our-business/about-us/our-views/health-effects-of-smoking-tobacco Older versions : JTIThe Ministry of Health's claim that smoking is a risk factor for many diseases is primarily based on epidemiological studies of comparisons between smokers and non-smokers on disease rate. Epidemiological studies are useful in establishing exploratory associations between a disease and risk factors, but they can not establish a cause-and-effect association without controlling for other factors such as genetic factors, diet, exercise and stress. Moreover, epidemiological studies are intended to compare populations and do not reveal the risk of disease for individual smokers. \u0001\u0001\u0001no matter how smoking is described, people can stop smoking if they are determined to do so. No one should believe that they are so attached or 'addicted' to smoking that they cannot quit. PMSmoking causes many serious diseases including cardiovascular disease (heart disease), lung cancer, and chronic obstructive pulmonary disease (emphysema, chronic bronchitis). Smokers are far more likely to become sick with one of these diseases than non-smokers. Smoking is also addictive and can be extremely difcult to stop. These are the views of every leading medical and scientic organization around the world. And they are the views of Philip Morris International. 1.2 Clinical trials For a study to be considered as a clinical trial, it must : \u000fbe designed. \u000finvolve human subjects. \u000finvolve intervention. \u000fhave prospective follow-up for a specied outcome. Itusually has comparable treatment groups. 4Examples of study designs that are notclinical trials are: \u000fGeneral observational studies. -Cross-sectional studies -Case-control studies. -Case report. \u000fAnimal studies. Human studies typically have the following characteristics: \u000fLarge variation among subjects. \u000fLengthy disease process. \u000fNon-compliance and dropouts. \u000fEthical issues. \u000fRare disease. Finally, theadvantage of clinical trials is that it can establish a cause-effect association (free of confounding). 1.2.1 Example: PIVOT In Prostate Cancer Intervention Versus Observation Trial3(PIVOT), prostate cancer patients who were good candidates for radical prostatectomy were enrolled from 1994 to 2002. The last observation was made in 2010. The results were presented at American Urological Association Annual Meeting in May, 2011. The inclusion criteria for the study were: \u000f75 years or younger. \u000fLocalized disease. \u000fPSA\u001450mg=mg . 12 months. \u000fRadical prostatectomy candidate. With the all-cause mortality as the primary endpoint, the primary objective was to answer the following question: Among men with clinically localized prostate cancer detected during the early PSA era, does the intent to treat with radical prostatectomy reduce all-cause & prostate cancer mortality compared to observation? \u000f13;022men entered into screening registry. \u000f5;023were eligible. 3Wilt et al. (PIVOT Study Group). \"Radical prostatectomy versus observation for localized prostate cancer\". N Engl the prostatectomy group and 36 (10%) of the observation group. The following table summarized the assigned and received treatments. Actual Treatment Assigned Treatment Surgery Observation Other Surgery 281 (77%) 53 (15%) 30 ( 8%) 364 analysis compares 364surgery patients and 367observation patients based on their assigned treatments. As-treated analysis compares 317surgery patients and 345observation patients based on their received treatments. Per-protocol analysis compares 281surgery patients and 292observation patients who adhered to the protocol. Conclusions: \"Among men with localized prostate cancer detected during the early era of PSA testing, radical prostatectomy did not signicantly reduce all-cause or prostate-cancer mortality, as compared with observation, through at least 12 years of follow-up. Absolute differences were less than 3 percentage points.\" 1.3 Phases of clinical trials Clinical trials are usually classied into phases (I to IV). This classication is increasingly inadequate as objectives and characteristics of these phases have become less distinguished. 1.3.1 Phase I The main objective of phase I clinical trial is to establish safety by estimating the maximum tolerable dose (MTD). The MTD is the highest dose that results in dose-limiting toxicities (DLT) with a preset low probability (e.g., 33%). These studies provide information on the pharmacokinetics and pharmacodynamics of the drug in humans. 6Pharmacokinetics What the body does to drug. The process by which the drug is absorbed, distributed, metabolized, and eliminated by the body. Some commonly used parameters to study pharmacokinetics are: Concentration of drug; Biological half-life, Cmax, the peak plasma concentration of a drug; tmax, time to achieve Cmax. Pharmacodynamics What drug does to the body. Effects of drugs on living organisms and systems. Subjects for phase I study are usually normal healthy volunteers. In cancer studies, patients often participate. Single arm dose escalation (dose determination) trials are common in phase I cancer trials. Historically, 3 + 3 designs have been frequently used; however, Bayesian designs such as the continual reassessment method (CRM) and the modied toxicity probability interval (mTPI) design are gaining popularity. 1.3.2 Phase II Phase II trials primarily look for evidence of efcacy (drug activity); however, safety should also be closely monitored. Sometimes they are divided into phase IIa (safety as the primary goal) and phase IIb (efcacy as the primary goal) trials. Phase II trials in cancer are often single-arm trials, where the response rate is compared to a historical control. Two-stage and multi-stage designs are sometimes applied to expedite a decision of futility. 1.3.3 Phase III Phase III clinical trials are usually considered pivotal, and the new treatment is compared to the standard treatment of placebo to establish its effectiveness. These trials usually involve many sites (multi-center) sometimes spanning more than one country (multi-national). When there is already an effective conventional treatment, establishing noninferiority -as opposed to superiority -, is the primary objective. 1.3.4 Phase IV Phase IV clinical trial is a postmarketing surveillance, often to look for uncommon but serious side effects. Phase I/II and phase II/III trials have become popular. 7Chapter 2 Selected topics in statistics 2.1 Condence interval for a binomial proportion \u000fAsymptotic method. \u000fWilson score method. (See wikipedia for the formula.) \u000fClopper-Pearson (exact) method. SupposeX= phat)/n) 0.1241 (phat + z^2/(2 * n) + c(-1, 1) * z * sqrt(phat * (1 p\u0003values such that H\u0003 0:p=p\u0003would not be rejected by the observed data. pLsatisesP[X\u00158jp=pL] = 0:05, andpUsatisesP[X\u00158jp=pU] = 0:05. f1 <- function(p.star, x = 8, n = 32, alpha = 0.05) 1 - pbinom(x - 1, n, p.star) - alpha ## Note 1-pbinom(x-1, n, p.star) = sum(dbinom(x:n, 1)$root [1] 0.1309 f2 <- function(p.star, x = 8, n = 32, alpha = 0.05) pbinom(x, n, p.star) - alpha ## Note pbinom(x, n, p.star) = sum(dbinom(0:x, = upper = 1)$root [1] 0.4061 To solve for p\u0003in a more straightforward manner, we can use the following relationship between a Binomial random variable and a Beta random variable. If X\u0018Binomial (n;p)andY\u0018Beta (k;n\u0000 k+ 1), then P[X\u0015k] =P[Y\u0014p]: For the lower bound, instead of solving for pLinP[X\u00158jp=pL] = 0:05iteratively, we can solve P[Y\u0014pL] = 0:05, whereY\u0018Beta (8;32\u00008 + 1) . qbeta(0.05, 8, 32 - 8 + 1) [1] 0.1309 For the upper bound, we needed to solve P[X\u00148jp=pU] = 0:05, which isP[X\u00159jp=pU] = 0:95. Instead, we 0:95, whereY\u0018Beta (9;32\u00009 + 1) . - 9 + 1) [1] 0.4061 binconf(x = 8, n = 32, alpha = 0.1, method = \"all\") PointEst Lower Upper Exact 0.25 Asymptotic 0.25 0.1241 0.3759 2.2 Stop when we would like to test H0:p= 0:10;H1:p >0:10by taking a random sample of size 40from aBernoulli (p). UnderH0, the number of successes out of 40 has a Binomial (40;0:10) distribution. Moreover, we compute P0[X\u00158] = 0:04, so the test that rejects H0ifX\u00158has a type I error rate of 0:04. The data were observed sequentially, and the 8th success was observed after N= 32 , and we decided to reject H0and terminate the study. The conclusion was that pwas signicantly greater than 0:10, and ~p= 8=32 8, whereYis number 0:(obs - 1) <- <- obs:N * dnbinom(y - obs, obs, p)) ## dnbinom(x,k,p) ; x is number of failures until k-th ## dnbinom(8,4, 0.2) = choose(8+3,3) * 0.2^3 * one + two seq(0.05, 0.95, by = 0.05) p.tilde <- 0.2 0.4 0.6 0.8 1.00.0000.0050.0100.0150.0200.0250.0300.035 pBias 11This idea is related to stochastic curtailment . 2.3 Repeat until signicance of size 10fromNormal (\u0016;\u001b2). IfH0:\u0016= 0is not rejected, we will take another sample of size 15and test again with n= 25 . If each test has one-sided = 0:05, what is the actual type I error rate of this procedure? \u000fIf we have k(independent) signicance test of size , the probability of at least one false positive result is 1\u0000(1\u0000 )k. For = 0:05, k 1 2 3 0:0975 0:143 0:186 0:226 0:401 Because the rst and second tests are not independent, we need to consider a conditional distribution of ZtgivenZ1=z1. UnderH0, given Z1=z1is P0\u0014 Z2>pntpn2c\u0000pn1pn2z1 Z1=z1\u0015 : And by integrating this conditional type I error rate with respect to the distribution of Z1, we get unconditional type I error rate for the second stage ( 2): 2=Zc \u00001\u0014 1\u0000\b\u0012pntpn2c\u0000pn1pn2z1\u0013\u0015 (z1)dz1: cv = qnorm(0.95)) [1] 0.03325 2.4 Divide by the control mean Suppose we are interested in comparing two treatment groups. Take random samples of size 9 from each group ( x11;\u0001\u0001\u0001;x19;x21;\u0001\u0001\u0001;x29). We want to test H0:\u00161=\u00162. But we may be worried 13that the background noise is different for these two groups, so we take random samples of size 3 representing the background. c11;c12;c13andc21;c22;c23. Then we may \"normalize\" x's by dividing them by the average of the corresponding control group. yij=xij=\u0016ci\u0001.i= 1;2;j= 1;\u0001\u0001\u0001;9. SupposeXi\u0018Normal (\u0016i;\u001b2 x), andCi\u0018Normal (\u0017i;\u001b2 Y? Suppose that \u00161=\u00162= 120 ,\u00171=\u00172= 30 ;\u001bx= 4;\u001bc= 3. Then if we use a t-test onyij, type I error rate is about ... . NxNc\u001bx\u001bc 9 3 4 3 0:69 9 3 4 0 :40:08 9 3 4 0 0:05 90 30 4 3 0:72 9 300 4 3 0:05 A simple remedy is to use a regression approach of variance). 1otherwise. Then the expected group means are Control Treatment Group 1 0 0+ 2 Group 2 0+ 1 0+ 1+ 2+ 12 Interpretation of the regression parameters: 0:Group 1 control mean 1:Difference of control means 2:Treatment - Control in group 1 12:Group 2T - Group 1T - Difference of control means Thus, testing 12= 0is testing for the treatment difference taking into account the control difference. 14Type I error rate by simulation 3 :051 :063 9 3 4 0 :4 0:002 0 :052 0 :053 90 30 4 3 0:024 0 :050 0 :050 200 30 4 3 0:050 0 :051 0 :053 90 200 4 3 0:083 0 :050 0 :055 90 200 4 0 :054 0 :054 If 'fold change' is desired like in this example, perhaps, we can take logarithm of all values before tting the regression model. log(Y) = 0 0+ 0 1Xg+ 0 2Xt+ 0 12XgXt+\u000f0 Then what does 0 12represent? 15Chapter 3 Brief review of Bayesian analysis \u000fWhat are the philosophical differences between Frequentist and Bayesian statistics? To a Frequentist, parameters are xed and unknown numbers. In the Bayesian paradigm, the parameters have distributions like the data. \u000fHow does a Bayesian inference work? -Start with a prior guess of the distribution of the parameter, \u0012. -Update the distribution by combining it with the data X. -Obtain a posterior distribution of \u0012. -Make Statistical inferences using the posterior distribution. \u000fAdvantages of Bayesian approaches. -The relevant prior information can be incorporated in a straightforward way. -Adaptation using the data from the ongoing experiment does not affect the inference in the way Frequentist approaches do. -Interpretation of the result is easier. 3.1 Bayes theorem P(AjB) =P(BjA)P(A) P(B): Using this theorem, we can switch the event of interest and condition. For instance, we are usually interested in P[disease jtest positive], but the observed data are usually P[test positive jdisease]. As long as we can compute P[test positive] and know P[disease], we can make the switch. In terms of updating distributions, the theorem is written as p(\u0012jy) =p(yj\u0012)p(\u0012) p(y); 16wherep(\u0012)is the prior distribution for the parameter, \u0012,p(yj\u0012)is the likelihood of the observed data, ygiven\u0012, andp(\u0012jy)is the posterior distribution for the parameter. It is often written as p(\u0012jy)/p(yj\u0012)p(\u0012): 3.2 Example 3.2.1 Normal distributions Suppose we were interested in the long-term systolic blood pressure (SBP) in mmHg of a particular 60 year old female. We took two independent readings 6 weeks apart, and their mean was 130. We know that SBP is measured with a standard deviation \u001b= 5. (Example taken from \"Bayesian Approaches to Clinical Trials and Health-Care Evaluation\" by Speigelhalter, et al.) With a Frequentist approach, a 95% condence interval is 130\u00061:96(5=p 2) = (123:10;136:90): Using a Bayesian approach, we can incorporate a prior belief that females aged 60 have a mean long-term SBP of 120with standard deviation 10. Let's also assume that the prior distribution is normal. (prior = normal, likelihood = normal), that is, \u0012\u0018N[\u00120;\u001b2=n0]; n0+m;\u001b2 n0+m\u0013 : 17In this example, we have as the prior distribution and the likelihood, \u0012\u0018Normal (120;102) yj\u0012\u0018Normal (130;52=2) How influential was the prior information? Equivalent to n= 0:25 Continuing, we have the = (122:40;135:40), and we say that the probability that\u0012is between 122:40and135:40is95%. 18100 110 120 130 140 Prior distribution 100 110 120 130 140 Likelihood 100 110 120 130 140 Posterior distribution3.2.2 Beta-Binomial In the last example, we started with a normal prior, used a normal likelihood, and arrived at a normal posterior. Things are not always that nice. In general, the posterior distribution does not have a closed form. The last example is a case of a conjugate analysis. Conjugate models occur when the posterior distribution is of the same family as the prior distribution. Three common examples are: prior likelihood posterior Normal Normal Normal Beta Binomial Beta Gamma Poisson Gamma In phase I and II clinical trials, the outcome of interest is often binary, and we would like to use a Binomial distribution to model it. There, a Beta-binomial model can be used. 19Example In a safety study, we aim to estimate the probability of severe adverse events associated with a treatment of interest. We have an access to the data from another similar study that showed 7out of117had a severe adverse event. LetXbe the number of adverse events out of mpatients in our study, and we have Xjp\u0018Binomial (m;p): And let the prior distribution It can be shown that the expectation and variance of a Beta random variable are k,\u0000(a+k) = \u0000(a)a(a+ 1)(a+ 2)\u0001\u0001\u0001(a+k\u00001).) Thus, the posterior (a+x;b+m\u0000x). What doaandbmean in relation to xandm\u0000x? If we chose to use Beta (7;110) as the prior, this prior gives equal weight for the two studies, i.e., a patient in the previous study counts as much as a patient in the new study. If we want to almost completely disregard the prior information, we would use e.g., Beta (1;1), which is equivalent to having a sample size of 2(1adverse event out of 2). Suppose we want to use the prior information, but discount it so that it is only equivalent to 20 patients with P[adverse event ] = 7=117. So the prior distribution of pisBeta (1:20;18:80) 20Let's say in our study with sample of size 40, there were 5adverse events. Then the posterior distribution is f(pjx) =Beta (1:20 + 5;18:80 + 35) = Beta (6:20;53:80). 0.0 0.1 0.2 0.3 0.4 0.5 Prior distribution 0.0 0.1 0.2 0.3 0.4 0.5 Likelihood 0.0 0.1 0.2 0.3 0.4 0.5 Posterior distribution Using the posterior distribution, Beta (6:20;53:80), we can compute E[p] = 6:20=(6:20+53:80) = 0:10. Moreover we can compute the data.a <- x x post.a, [1] 0.1911 This is narrower than the Frequentist counterpart, and it has a nice interpretation. 22Chapter 4 Randomization in clinical trials 4.1 Example: Polio vaccine trial (1954) In 1954, 1:8million children participated in the largest clinical trial to date to assess the effectiveness of the vaccine developed by Jonas Salk in preventing paralysis or death from poliomyelitis. \u000f1:8million children in selected school districts throughout the US were involved in this placebo- controlled trial. -Why was placebo necessary? -60;000cases in 1952; about half of that in 1953. \u000fRandomized trial. -750;000children participated. -They required parents' consent. -Half of the children with consent were randomized into the vaccine group. \u000fNFIP design. -The National Foundation for Infantile Paralysis (NFIP) conducted a study in which all 2nd graders with consent received the vaccine with 1st and 3rd graders acting as control. -1;125;000children participated. -The control children did not require consent. Systematic difference between groups. -No blinding. -Polio is a contagious disease! The results of the SVF trial are tabulated below1. 1Freedman et al. Statistics, 23The design Size Rate\u0003 Treatment 200;000 26 Control 200;000 71 No consent 350;000 46 (\u0003Rate of polio cases per 100;000) The NFIP design Size Rate\u0003 Treatment 225;000 25 Control 725;000 54 No consent 125;000 44 (\u0003Rate of polio cases per 100;000) 4.2 Introduction Randomization Assignment of patients or experimental subjects to two or more treatments by chance alone. Main advantages of randomization \u000fIt removes the potential of bias in the allocation of participants to the intervention group or to the control group (allocation bias). \u000fIt tends to produce similar (compatible) groups in terms of measured as well as unmeasured confounders confounding by indication in observational studies. Randomization is considered so important that the intention-to-treat principle considered sacrosanct: \"Analyze by assigned treatments irrespective of actual treatment received.\" Perceived disadvantages of randomization are often about emotional and ethical issues. !randomization before consent Predecessors to randomization: \u000fAlternating assignments (TCTCTCTC...). \u000fTreatment assignment based on birthday / day of the week. The primary problems with these non-random assignment are the lack of assurance of comparability 24(baseline balance). An additional issue with the \"alternating assignments\" is that if one is unblinded, all the rest are unblinded, too. 4.3 Simple randomization For each subject, flip a coin to determine treatment assignment. P[treatment 1] =\u0001\u0001\u0001=P[treatment k]= 1=k. Problems with simple randomization and how to deal with them. \u000fImbalance in treatment allocation. -Replacement randomization. -Block randomization. -Adaptive randomization. (Biased coin / patient characteristics. -Stratied -Covariate adaptive randomization. 4.4 Imbalance in treatment allocation If the number of patients, Nis20,P[10and10] = 0:18. The probability of 7to13split or worse is 26%. The treatment effect variance 0:92as efcient as 10-10 split. Even if treatment allocation is balanced at the end of trial, there may be a (severe) imbalance at some point. Because we may monitor trials over time, we prefer to have balance over time. 4.4.1 Block randomization To ensure a better balance (in terms of number of patients) across groups over time, consider a block randomization (random permuted blocks). Block randomization ensures approximate balance between treatments by forcing balance after a small number of patients (say 4 or 6). For example, the rst 4 patients are allocated to treatment A or B sequentially based on AABB . 25There are 6 sequences of A,A,B,B, and let each sequence have 1/6 chance of being selected. AABB ABAB ABBA BAAB BABA BBAA for (i in 1:5) f cat(i, sample(rep(LETTERS[1:2], each = 2), 4, replace = FALSE), \" nn\") g 1 A B B A 2 B B A A 3 B A A B 4 A B A B 5 A B A B What's wrong with block size of 2? Block size of 200? Easily applicable to more than 2 groups ( A,B,C) for (i in 1:5) f cat(i, sample(rep(LETTERS[1:3], each = 2), 6, replace = FALSE), \" nn\") g 1 A B C C A B 2 B B C A C A 3 C A B B C A 4 C A A B C B 5 A B C A C B Easily applicable to unequal group sizes ( Na= 40 andNb= 20). for (i in 1:5) f cat(i, sample(rep(LETTERS[1:2], c(4, 2)), 6, replace = FALSE), \" nn\") g 1 A B A A B A 2 A B A A A B 3 B B A A A A 4 A A B B A A 5 A B B A A A Why do we want unequal group sizes? 26\u000fWe may want to have a better estimate of the effect for the new treatment. \u000fTreatment costs may be very different. Given the total sample size and the relative cost of treatment 2 to treatment 1, we can nd the optimal allocation ratio to minimize the total cost. (More in sample size computation) \u000fVariances may be different. Suppose the means, \u00161and\u00162, of treatment groups are being compared using Z=(\u0016X1\u0000\u0016X2)\u0000(\u00161\u0000\u00162)p \u001b2 1=n1+\u001b2 2=n2: For a given N=n1+n2, the test statistic is maximized when the denominator is minimized. Solving @ @n1\u0012\u001b2 1 n1+\u001b2 2 N\u0000n1\u0013 = 0 we get n1 N=\u001b1 \u001b1+\u001b2: Therefore, the optimal allocation ratio is r=n1=n2=\u001b1=\u001b2. Analysis should account for the randomization scheme but often does not. Matts and McHugh (1978 J Chronic Dis ) point out that \u000fbecause blocking guarantees balance between groups and increases the power of a study, blocked randomization with the appropriate analysis is more powerful than not blocking at all or blocking and ignoring it in the analysis. \u000fnot accounting for blocking in analysis is conservative. 4.4.2 Biased coin and urn model These techniques are sometimes classied as \"adaptive randomization\". Allocation of i-th patient depends on how many have been randomized to group A ( na) and group B (nb). Any given time, the probability of allocation to group A may be P[A] =nb na+nb: Or the rule may be to use P[A] = 2=3whennb\u0000na>5, andP[B] = 2=3whenna\u0000nb>5. Characteristics of such a randomization scheme are usually studied by simulations. An urn model is one type of biased coin randomization. 27\u000fPrepare an urn with one Amber ball and one Blue ball. \u000fPick one ball and make the corresponding treatment assignment (A/B). \u000fPut a ball of the opposite color in the urn. urn1 <- function(n) f # randomize n patients into A or B. At any time P[A] = (#B so far + 1) # / (#A so far + 1 + #B so far + 1). out <- data.frame(matrix(0, ncol = 4, nrow 1 g 10) A so far B so far P[A next] Next 1 0 0 0.5000 A 2 1 0 0.3333 A 3 2 0 0.2500 B 4 2 1 0.4000 B 5 2 2 0.5000 A 6 3 2 0.4286 A 7 4 2 0.3750 B 8 4 3 0.4444 B 9 4 4 0.5000 B 10 4 5 0.5455 A 4.5 Imbalance in baseline patient characteristics Block randomization and biased coin model ensure that the group sizes are reasonably balanced. In order to facilitate the comparison of treatment effects, balance on important baseline variables is 28sometimes desired. \u000fRandomization does not guarantee all the measured variables will be balanced. And imbal- ance does not mean randomization did not work. Senn (1994) It is argued that this practice [testing baseline homogeneity] is philosophically un- sound, of no practical value and potentially misleading. Instead it is recommended that prognostic variables be identied in the trial plan and tted in an analysis of covariance regardless of their baseline distribution (statistical signicance). Piantadosi These methods, while theoretically unnecessary, encourage covariate balance in the treatment groups, which tends to enhance the credibility of trial results. An annonymous reviewer Since this is a randomized controlled trial, comparison of baseline characteristics (Table 1) is not necessary. The problem with this approach is that when comparing baseline characteristics we already know that the null hypothesis is true if the randomization was done correctly. Thus, we would expect 1 test in 20 to give a 'signicant' result withp<0:05by chance alone. The best approach is to specify key prognostic factors to include in multivariable models irrespective of their signicance between treatment groups. 4.5.1 Stratied randomization Stratied randomization is applied to ensure that the groups are balanced on baseline variables that are thought to be signicant. \u000fCreate strata based on the variables for which balance is sought. e.g., (Male, 65 or younger), (Male, older), (Female, younger), (Female older) \u000fRandomize to treatments within each stratum. Use block randomization! What's wrong with -using simple randomization within a stratum? -using too many strata? \u000fStratication should accounted for in analysis. -Pre-randomization stratication and post-randomization stratication (at time of analysis) has no clear winner. \u000fIf trial is large, stratication may not be necessary \u000fStratication by center is a good idea from practical viewpoints. -Allows randomization to be hosted at each site -Allows sites to be removed and still maintains balance \u000fBlock randomization is a special type of stratied randomization where strata are dened by ... . \u000fIf each stratum has a target size, plans need to be in place to close down recruitment based on the baseline characteristics. e.g., \"We do not need any more (Male, older)\". 294.5.2 Adaptive and minimization randomization Adaptive randomization can be used to reduce baseline imbalance: \u000fDene an imbalance function based on factors thought to be important \u000fThen use a rule to dene P[treatment A] so that the next assignment is more likely to reduce imbalance. For example, the factors to balance are sex (male/female) and hypertension (yes/no), and let the imbalance function be I= 2\u0002(sex imbalance ) + 3\u0002(hypertension imbalance ): The patients randomized so far are Sex Hypertension Male Female Y es No Group 1 10 3 8 5 Group 2 8 3 6 5 The next patient is male-non hypertensive. The imbalance will be I= 2\u0002(11\u00008) + 3\u0002(6\u00005) = 9 if Group 1, I= 2\u0002(10\u00009) + 3\u0002(6\u00005) = 5 if Group 2. Thus let P[Group 2] = 2=3. Minimization randomization uses the same idea but use P[Group 2] = 1, to eliminate randomness when there is some imbalance. Randomize only when to assign the next patient to either group gives the same value of I. 4.6 Response adaptive randomization As the name suggests, response adaptive randomization methods use the information about the response so far to allocate the next patient. Play the winner : The idea is to allocate more patients in the treatment that seems to be working better. To apply these methods, it is necessary to have a response quickly. Urn model can be used to make treatment assignment imbalance based on the results (success/failure) of each treatment so far. (e.g., put one blue ball if the treatment B yields success.) Instead of updating the probabilities of treatment assignment after each patient, we can update them after a group of patients' results are available to reduce administrative burden. In a phase II clinical 30trial, play the winner design may be used to reduce the number of treatments in consideration. (e.g., Only retain the treatment arms that have P[positive response] >0:4.) 4.6.1 Example: ECMO Bartlett the use of extracorporeal membrane oxygenation (ECMO) to treat newborns with respiratory failure. A play-the-winner design3was used because \u000fthe outcome is known soon after randomization. \u000fmost ECMO patients were expected to survive and most control patients were expected to die. Ethically, the investigators felt obligated not to withhold the lifesaving treatment. Scienti- cally, they felt obligated to perform a randomized study. The randomization plan: \u000fThe rst patient will be randomized to ECMO or the conventional treatment (CT) with equal probability. \u000fFor each patient who survives on ECMO or dies on CT, one ECMO ball is added to the urn. \u000fFor each patient who survives on CT or dies on ECMO, one CT ball is added to the urn. \u000fThe trial will be terminated when 10 balls of one kind have been added, and that treatment will be chosen as the winner. What actually happened: P(ECMO)=1/2 Patient 1 was randomized to ECMO and survived. P(ECMO)=2/3 Patient 2 was randomized to CT and died. P(ECMO)=3/4 Patient 3 was randomized to ECMO and survived P(ECMO)=4/5 Patient 4 was randomized to ECMO and survived P(ECMO)=5/6 Patient 5 was randomized to ECMO and survived P(ECMO)=6/7 Patient 6 was randomized to ECMO and survived P(ECMO)=7/8 Patient 7 was randomized to ECMO and survived P(ECMO)=8/9 Patient 8 was randomized to ECMO and survived P(ECMO)=9/10 Patient 9 was randomized to ECMO and survived 2\"Extracorporeal circulation in neonatal respiratory a prospective randomized study\". (1985) Pediatrics JASA ; Wei and (1978) JASA 31P(ECMO)=10/11 Patient 10 was randomized to ECMO and survived Randomization was stopped when there were 11ECMO patients who survived and 1CT patient who died. Controversies followed because ... fisher.test(cbind(c(11, 0), c(0, 1))) Fisher s Exact Test for Count Data data: cbind(c(11, 0), c(0, 1)) p-value = 0.08 alternative hypothesis: true odds ratio is not equal to 1 95 percent confidence interval: 0.2821 Inf sample estimates: odds ratio Inf In retrospect it would have been better to begin with two or three pairs of balls, which probably would have resulted in more than one control patient. 32Chapter 5 Sample size and power 5.1 Introduction and terminology \u000fType I error rate \u000fType II error rate \u000fPower \u000fEffect size \u000fMinimum clinical signicance Type I error can be controlled regardless of sample size, so sample size calculation is mostly about statistical power. The regulatory body (e.g., FDA) is concerned about the type I error, and the sponsor is concerned, in addition, about the type II error. FDA's main goal is to prevent an ineffective intervention to be claimed effective. If the sample size is smaller than necessary, then a statistically signicant effect may not be observed when the intervention is in fact effective. Sample size calculations are only approximation because ... \u000fThey are based on (hopefully educated) guesses. \u000fThey are based on a mathematical model that are only approximately true. It is usually best to be conservative. There is much to think about when planning a study: \u000fThe main question (hypothesis). \u000fThe endpoint. \u000fStatistical analysis plan. \u000fTreatment effect to detect. (Clinical signicance) Statistical power is a function of type I error rate, sample size, treatment effect under the alternative, 33variance. Sometimes, it is better to compute sample size based on the desired length of condence intervals instead of power. 5.2 Sample size calculation for continuous variables Suppose data are at least approximately normally distributed. Then a test statistic for testing H0:\u0016t\u0000\u0016c=\u000e0 H1:\u0016t\u0000\u0016c>\u000e0 may be Z=\u0016Xt\u0000\u0016Xc\u0000\u000e0p \u001b2 t=Nt+\u001b2c=Nc: To have a type I error rate of and power of 1\u0000 at\u000e1, we To nd the value of rthat minimizes N\u0011Nt+Nc, differentiate the expression (sigt^2 + r * sigc^2)/(r * (d1 - d0)^2) g r <- seq(0.5, 4, by = 0.01) Nc <- ssNorm(d0 = 0, d1 = 1, sigt = 4, sigc = 2, al = 0.025, be = 0.1, r = r) Nt <- Nc * r 350.5 1.0 1.5 2.0 2.5 3.0 3.5 4.00100200300400500 rSample size Total Nc NtNow further suppose that the relative cost of the subjects in treatment group compared to the control group is C(C > 1indicates that the treatment group is more expensive). The total cost ( M) is M=Nc+CNt =Nc(1 +Cr); and the this case is ropt=\u001bt \u001bc1p C: 365.2.2 Sample size calculation for precision For a given sample size, ncandnt, a(1\u0000 )\u0002100% condence interval has can solve M=z1\u0000 =2p \u001bt=nt+\u001bc=ncto compute the necessary sample size to specify the width of this condence interval. Mis the margin of error, and 2Mwill be the length of this condence interval. Letting \u001b=\u001bt=\u001bcandN=nt=ncand solving for ngives n=2z2 =2\u001b2 M2: \u000fThis is (should be) used to compute the necessary number of simulations to run. \u000fWhat is the required sample size to make the width of a condence interval reduced by half? \u000fWhat is the required sample size if \u001bis doubled? 5.2.3 Sample size calculation for paired observations With a paired data set, suppose we would like to test H0:\u0016a\u0000\u0016b= 0. The same formula as two-sample case can be used, but a few points to note are: \u000fna=nb. \u000fUsually\u001ba=\u001bb. \u000fUsually there is a positive correlation between the paired measurements. Let\u001abe the correlation between the paired measurements, and the simple version of the sample size formula (one-sample case) is nb=na=(z +z )2\u001b2 d (\u000e1\u0000\u000e0)2; where\u001b2 is \u001b2 d=\u001b2 b+\u001b2 a\u00002cov(A;B). \u000fWhen is it better to treat the data as independent even when the data are actually paired? 5.3 Binomial outcome variables 5.3.1 One sample problem In many early phase clinical trials, the hypothesis of interest is about a response rate and a one-arm trial may use a historic control: H0:p=p0. 37A test statistic, Z=^p\u0000p0p p0(1\u0000p0)=n; has =p1\u0000p0p p0(1\u0000p0)=n: V[Z] =p1(1\u0000p1)=n p0(1\u0000p0)=n: The as for the normal case leads to n=\u0010 z p p0(1\u0000p0) +z p p1(1\u0000p1)\u00112 (p1\u0000p0)2: 5.3.2 Two sample problem Now suppose we want to test H0:pt=pc, whereptandpcare response rates for the treatment and control groups, respectively. We have Xt\u0018Binomial (nt;pt); Xc\u0018Binomial (nc;pc): And we the test statistic, Z=^pt\u0000^pcp pt(1\u0000pt)=nt+pc(1\u0000pc)=nc; has the standard normal distribution (when sample sizes are large), and it reduces to Z=^pt\u0000^pcp p(1\u0000p)p 1=nt+ 1=nc; (pt\u0000pc)2: 385.3.3 Adjustment for noncompliance Here we assume that a new treatment is being compared to a standard treatment. dropouts those who are randomized to the new treatment but received a standard treatment drop-ins those who are randomized to the standard treatment but received the new treatment When the treatment effect is tested with the intention-to-treat principle, these usually dilute the treatment effect. LetRtcdenote the proportion of dropouts (moving from ttoc), andRctdenote the proportion of drop-ins. Recall the sample size n=\u0010 z p 2\u0016p(1\u0000\u0016p) +z p pt(1\u0000pt) +pc(1\u0000pc)\u00112 (pt\u0000pc)2: Dropouts and drop-ins have a small effect on the numerator but pose a major impact on the denominator, which is the expected difference of the proportions under the alternative, and it gets diluted with dropouts necessary sample size will increase by the factor 1=(1\u0000Rtc\u0000Rct)2. For example, if we estimateRtc= 0:05andRct= 0:10, then the nal sample size will be increased by the factor of 1=(1\u00000:10\u00000:05)2= 1:38. 5.4 Additional topics for binomial responses 5.4.1 Other parameterizations Hypotheses of interest may be specied in terms of difference or ratio of the two proportions or the odds ratios. 39We have seen that even if the hypotheses are written in terms of difference of proportions, we need to specify the location ( pc) to compute the sample size. Once pcandptare set, we can compute the ratio (e.g, risk ratio), =pt=pcand odds ratio, = (pt=(1\u0000pt))=(pc=(1\u0000pc)). If the hypotheses are written in terms of risk ratio or odds ratio, we translate those into statements about difference of proportions and compute the sample size. H0: = 1 H1: = 2 (Odds of the good outcome is twice as likely in the treatment group as in the control group.) pc ratio 2 2 2 2 2 2 2 2 risk ratio H0:p= 0:2,H1:p>0:2. To have a type I error rate of 5%and 80% power atp= 0:35, the necessary (:35\u0000:2)2 0:2 + 1:645p :2\u0002:8=50 = 0:293 \u00190:35\u00000:842p :35\u0002:65=50 This translates to the rejection rule that if we observe 15or more successes, we reject H0. (50\u0002 0:293 = 14:7) And the actual type > r. rej0 <- sum(dbinom((r function(n, p0, alpow) f # Reject if X > r. Find r so that P[X>r] < alpow. r <- 5.4.3 arc sin variable, X\u0018Binomial (n;p), Z= 2pn\u0010 sin\u00001p ^p\u0011 : is approximately normally distributed with mean 2pn(sin\u00001pp)and variance 1. Using the sample size formula for normal distributions, we get n=(z +z )2 4(sin\u00001pp1\u0000sin\u00001pp0)2 For the current example, we have (qnorm(.05)+qnorm(.20))^2 / 4 / (asin(sqrt(.35)) - that under sin\u00001ppt\u0000sin\u00001ppcunderH1, (1:645 + 1:282)2=(2(0:22112)) = 86:7, so ifnt=ncis desired, the sample size is 87each. However, we need to solve for ntandncsatisfyingnt= 1:5\u0002nc. nc= 73 andnt= 110 . 5.5 Sample size using simulation A simulation study is a highly useful tool when computing the sample size and learning operation characteristics of a future design. example Suppose we want to conduct a study to compare two treatments to test H0:\u0016t\u0000\u0016c= 0against H1:\u0016t\u0000\u0016c>0with = 0:025and power = 0:90at\u0016t\u0000\u0016c= 10. Using information from similar studies, we decide to use \u001b= 32. Then the per-group sample size should sample size depends on the estimate of \u001bused. The value of \u001band the sample size are summarized below. ss <- function(alp, bet, sigm, delt) c(32, 36, 40, 44), 10)) [1] 216 273 337 407 round(100 * po(0.025, 216, c(32, 36, 40, 44), 10)) [1] 90 82 74 66 \u001b 32 36 40 44 N 216 273 337 407 power ifN= 216 90% 82% 74% 66% Because we are not condent about our pre-study estimate, \u001b= 32, we plan to (have someone) look at the data and compute the pooled variance, s2 1, when the total sample size is 50. Ifs1>36 then we will recompute the sample size so that the total sample size is N\u0003=(1:960 + 1:282)2(2\u0002s2 1) 102 Simulation results ( B= 1;000) show the ve-number summary (Min-Q1-Med-Q3-Max) UnderH0 UnderH1 \u001btype I Perhaps, the timing of the internal look is too early. Change it to when we have 100observations total. Simulation results ( B= 1;000) 43UnderH0 UnderH1 44Chapter 6 Phase I Clinical Trials 6.1 Introduction Phase I clinical trial is the rst study in which a new drug is administered in humans. The primary objectives of phase I studies are 1) to collect pharmacokinetic and pharmacokynamic data, and 2) to establish safety with a specic goal to estimate the maximum tolerated dose (MTD). \u000fTraditionally, the MTD is the dose level at which the probability of dose-limiting toxicity (DLT) is33% (or maybe 20%). \u000fWe make an assumption that higher doses are more effective. We assume that the highest safe dose is the dose most likely to be effective; in other words, we are using dose-related toxicity as a surrogate for efcacy. Phase I clinical trials are also known as: Treatment mechanism Early developmental trial that investigates mechanism of treatment effect. (e.g., pharmacokinetics) Dose escalation Design that species methods for increase in dose for subsequent subjects. Dose-ranging Design that tests some or all of a prespecied set of doses (xed doses) Dose-nding Design that titrates dose to a prespecied optimum based on biological or clinical considerations In cancer and AIDS trials, only patients participate in phase I trials; however, in other disease areas, safety data may be gathered on healthy volunteers. The primary reason to recruit patients into a phase I clinical trial is known toxicity. (cytotoxic drug) 45Who are the healthy volunteers? \u000fusually 18-35 years \u000fusually male \u000fnon-smoker / non substance abuse \u000fno symptoms of disease \u000fno laboratory abnormalities FDA uses the terminology, \"normal volunteers\" (Guidance for industry: General considerations for the clinical evaluation of drugs), but who are normal? \"With respect to the use of 'normal' subjects it should be recognized that few people are literally normal in all respects. This term should be interpreted with caution and should mean volunteers who are free from abnormalities which would complicate the interpretation of the experiment or which might increase the sensitivity of the subject to the toxic potential of the drug.\" 6.2 Non-cancer, non-AIDS phase I clinical trials Most phase I studies are placebo controlled randomized study to reduce observer bias and facilitate comparison between active drug and placebo. In a typical design, subjects are assigned to a cohort of size 8 to 10; 6 to 8 subjects are assigned to the active treatment (same dose) and 2 to placebo. If deemed safe, the next cohort of the same size are given one higher dose. The trial is stopped when an unacceptable number of adverse events is observed; the highest safe dose is the target dose that will be recommended for future trials. Starting dose One popular starting dose is based on the dose that causes 10% mortality in rodents on a mg=m2 (per body surface) basis ( LD10). We use LD10=10as the starting dose. An FDA document (Guidance for industry. Estimating the maximum safe starting dose in initial clinical trials for therapeutics in adult healthy volunteers) provides a conversion table for this purpose. 46Species mg=kg tomg=m2animalmg=kg to HEDmg=kg Multiply by Multiply by Human 37 - Child ( 20kg)\u000325 - Mouse 3 0:08 Hamster 5 0:13 Rat 6 0:16 Ferret 7 0:54 Monkey 12 0:32 Baboon 20 0:54 Frequentist approaches in oncology phase I trials 6.3.1 Up-and-down designs / 3 + 3 designs Many variations exist to these so-called \"up-and-down designs\" / \"3+3\" designs, but the basic idea is: 1. 3 patients are allocated to a dose level. (a) If there is 0 toxicity reaction then 3 patients will be assigned to the next dose level. (b) If there is 1 toxicity reaction then 3 patients will be assigned to the current dose level. (c)If there are 2 or 3 toxicity reactions, then the current dose will be closed (too toxic) and 3 patients will be assigned to the previous dose level. 2. Continue until \u000fthe next dose already has had 6 patients. \u000fthere is no more higher/lower dose 3.The MTD is the highest dose with at most 1 toxicity reaction out of 6. (Generally, the MTD has to have data from 6 patients.) In general there are four components to the typical dose ranging design: 1. selection of a starting dose 2. specication of the dose increments and cohort sizes 3. denition of dose limiting toxicities Toxicities that, due to their severity or duration, are considered unacceptable and limit further dose escalation within the subject. (These need to be pre-dened.) 4. decision rules for escalation and de-escalation Notes: \u000fThe starting dose is usually the lowest dose, but it does not have to be. 47\u000fThe dose level for the next patient may not be known when he/she is available to be allocated. \u000fThe best outcome is selection of the dose level that is closest but does not exceed the MTD. \u000fThis design is not motivated with statistics in mind. The probability of selecting the right dose can be very low. The right dose may not even have the highest probability of being selected. \u000fEstimation of the true dose or the true probability of a toxicity reaction for a given dose is difcult.This process usually underestimates the MTD. \u000fThe frequency of stopping escalation at a certain dose level depends on toxicity rate at that dose as well as the rates at all levels below. \u000fOn average the dose chosen by the 3+3 design has the probability of toxicity of about 20% to 25%. The operating characteristics studied by Reiner et al. (1999); Lin and Shih (2001); Kang and Ahn (2001, 2002). UseThree3.R function to simulate... See my presentation on 3+3 designs. Modied Fibonacci dosing In addition to arithmetic and geometric sequence, the Fibonacci sequence is often used. Fn= 0;1;1;2;3;5;8;13;21;\u0001\u0001\u0001 Based on this sequence, one possible dose escalation is DoseD2\u0002D 3\u0002D Example: Dose Plan The Phase I Dose Escalation Trial of DRUG.A Administered in Combination with DRUG.B in Patients with .... Cancer The dose of DRUG.B will remain constant while testing six escalating doses of DRUG.A. Dose escalation will proceed according to a standard 3+3 design and each cohort of 3 patients will be fully evaluated for dose limiting toxicity (DLT) before the next cohort can be enrolled. The rst dose level of DRUG.A will be 20mg. Dose escalations will proceed as follows. Three patients will be treated at the rst dose level. If none of these patients experience a DLT, a new cohort of 3 patients will be treated at the next higher dose level. If 1 patient experiences a DLT at the rst dose level, a second cohort of patients will be treated at the rst dose level. Dose 48escalation will precede as long 0 in 3 patients or 1 or fewer patients in 6 patients treated experience a DLT. If 2 or more DLTs are observed in 3 or 6 patients treated, the MTD will be exceeded. The MTD is dened as the highest dose level tested in which fewer than 2 patients in 6 treated at that dose level experience DLT. The MTD determined in the trial will be the recommended phase II dose for subsequent testing. Since the declaration of the MTD requires 6 patients, the minimum sample size would be 6 patients and the maximum sample size required for this phase I study is 36 patients. Phase I Dose Escalation Table of DRUG.A DRUG.A is an oral tablet and will be administered daily for 3 consecutive days, followed by 4 days off on a 21 day cycle. The patient will receive DRUG.A on days 1, 2, 3, 8, 9, 10, 15, 16, and 17 on a 21 day cycle. The Level 1 dose will start at 20mga day. We will enroll three patients per dose level and observe for DLT throughout the rst cycle of therapy. Dose escalation increments will be determined by the toxicity observed at the previous dose level according to Table 1A until the MTD and DLT are dened. We will closely monitor patients for all toxicities that may appear during later cycles of treatment. Dose Level DRUG A dose Number of patients 6.1: The phase I dose escalation schedule of DRUG.A in combination with DRUG.B 6.4 CRM Because of their sequential nature, \"3+3\" design and its variant tend to yield a biased underestimate of the target dose when estimating the MTD. One dose-nding (ranging) design that is not subject to this bias as much is the continual reassessment method (CRM). One obvious advantage of the CRM is its use of an explicit mathematical model describing the relationship between dose and toxicity. Parameters underlying a dose-toxicity curve are given as priors. These prior values are updated sequentially and used to nd the current \"best\" estimate of dose that would produce the acceptable risk of a toxic event. The CRM is an algorithm for updating the best guess regarding the optimal dose. It does not require 49a set of xed dose levels. The CRM algorithms make no assumptions about 1. the actual dose used 2. the cohort size 3. ordering of doses 4. integer responses 6.4.1 Example (Dougherty et al. (2000)) Suppose we want to nd the dose that is associated with 20% toxicity, and the available doses are 0:25,0:50,0:75, and 1:00. The dose-toxicity relationship is written with a one-parameter logistic response model log\u0012pi 1\u0000pi\u0013 = 3 the dose level ( i= 1;2;3;4) andpiis the toxicity probability for dose i, and is an unknown parameter. 0.00.20.40.60.81.0 Dose levelsProbability of toxicity a=0.50 a=0.75 a=1.00 a=1.25 a=1.50 For the prior distribution of we choose to use an exponential distribution with mean 1. The actual prior information is usually written in terms of the prior probabilities of toxicity at each dose. In this 50example, let's say we have 10%,20%,40%, and 80% for each of the four dose levels ( p0 i). Atith dose, we have di=logit(p0 i)\u00003 Dose Prior Level Actual dose p0 i(prior 0:25 of toxicity 3 4Prior (a=1) Other possible model is pi=f(tan\u00001xi+ 1)=2ga: If we let the prior value of a= 1, we can solve for the corresponding xiof eachpi, tan(2p0 a=0.50 a=1.00 a=1.50 a=2.00Steps for updating information 1. Treat a cohort of 1 patient at the lowest dose. 2. Obtain a posterior distribution of . 3. Find the optimal dose that gives 20% toxicity using the posterior distribution. 4. Treat another patient at the dose closest to the optimal dose. 5. Repeat steps 2, 3, 4. The trial continues until a predetermined xed sample size is reached, or some other trial terminating condition is satised. With regard to step 2 (nding the posterior distribution), we only need the expected value of so that it can be plugged into the dose-toxicity equation, and expectation of is E[ ] =R1 0 L( ;~dj;~tj)g( )d R1 0L( ;~dj;~tj)g( )d ; whereLis likelihood for + dj) 1 +exp(3 + dj): This is usually beyond analytical solution, so we use simulations. One result from such simulation is given below: Dose Prior Observed data Posterior Level Actual dose p0 i(prior guess) di # patients # toxicity mean sd 1 0:25 0:10\u00005:20 4 0 0:10 0:03 \u000fThe means of pishow strong agreement with the prior. \u000fThe actual doses do not enter into the model. \u000fA tolerability for dose 4 is estimated with considerable accuracy, even though no one was ever given the dose. -!This method should be used with great caution. The CRM method is sometimes criticized for begin falsely precise. However, it has been demon- strated that the CRM is more efcient and less biased than classic designs. Using R A number of packages and functions are available in R. Over a hundred packages are listed on cran.r-project.org/web/views/Bayesian.html . For analysis (as opposed to design) of the data, bcrm (Bayesian continuous reassessment method) seems comprehensive and easy to use. Let's continue with the same example with four dose levels. Recall the prior guess of toxicity probabilities are 10%,20%,40%, and 80% for each of the four dose levels. Doses are 0:25,0:50, 0:75,1:00. 54Chapter 7 Phase II Clinical Trials 7.1 Introduction Phase II clinical trial A clinical trial designed to test the feasibility of, and level of activity of, a new agent or procedure. (safety and activity) Some typical characteristics of a typical phase II clinical trial include: \u000fIt includes a placebo and two to four doses of the test drug. \u000fWhen the response is observed quickly, adaptive designs may be benecial and used because they may -improve quality of estimation of the MED (minimum effective dose (lowest dose of a drug that produces the desired clinical effect). -increase number of patients allocated to MED. -allow for early stopping for futility. The primary objectives of phase II trials are: \u000fTo determine whether the drug is worthy of further study in phase III trial. Signicant treatment effect? / dose-response relationship? \u000fTo gather information to help design phase III trial. -Determine dose(s) to carry forward -Determine the primary and secondary endpoints -Estimate treatment effects for power/sample size analysis -Estimate recruitment rate -Examine feasibility of treatment (logistics of administration and cost) -Learn about side effects and toxicity In phase II clinical trials, parallel group designs, crossover designs, and factorial designs are often 55used. 7.2 Phase II trials in oncology A phase II clinical trial in oncology generally uses a xed dose chosen in a phase I trial. The primary objective is to assess therapeutic response to treatment. In the simplest case, a single treatment arm is compared to a historical control. In other cases, a control group and/or multiple doses are included. The treatment efcacy is often evaluated on surrogate markers for a timely (quick) evaluation of efcacy. Surrogate outcome An outcome measurement in a clinical trial that substitutes for a denitive clinical outcome or disease status. \u000fCD4 counts in AIDS study. \u000fPSA (prostatic specic antigen) in prostate cancer study. \u000fBlood pressure in cardiovascular disease. \u000f3 months survival (binary) for survival. \u000fTumor shrinkage for survival. Tumor response to treatment is evaluated according to Response Evaluation Criteria in Solid Tumors (RECIST) Complete response (CR) Disappearance of all target lesions. Partial response (PR) At least a 30% decrease in the sum of the longest diameter (LD) of target lesions, taking as reference the baseline sum LD. Stable disease (SD) Neither sufcient shrinkage to qualify for PR nor sufcient increase to qualify for PD, taking as reference the smallest sum LD since the treatment started. Progressive disease (PD) At least a 20% increase in the sum of the LD of target lesions, taking as reference the smallest sum LD recorded since the treatment started or the appearance of one or more new lesions. Generally, objective tumor response is dened as CR or PR in RECIST so that the response variable has a binary endpoint. In the rest of chapter, we will consider a single arm trial with a binary response. The hypothesis of interest is one-sided H1:p>p 0, and the type I error rate is usually 5to10%. The power is usually 80to90%. 567.3 Classical (old) two-stage designs It is crucial that these phase II studies have an opportunity to stop early for toxicity, and that is accomplished by Data Monitoring Committee (DMC), aka, Data and Safety Monitoring Board (DSMB). It is also desired to discard ineffective treatment early, and two-stage designs with a futility stop has been popular. We will discuss the designs proposed by Gehan (1961), Fleming (1982), and Simon (1989), using the following unied notation: \u000fstage I sample size I critical value \u0001\u0001\u0001r1so that ifX1\u0014r1then terminate the study for futility. \u000fstage II sample size value \u0001\u0001\u0001rtso that ifXt\u0014rtthen the study for futility, otherwise conclude efcacy. 7.3.1 Gehan's design It is old (1961) and outdated but may be ok to use in limited situations. The design calls for the rst stage withn1= 14 andr1= 0, i.e., if no positive response is observed in 14, then stop for futility. The rational is that if true response rate is at least 20%, thenX1= 0is unlikely. In fact, it is 0:044. The second stage sample size depends on the desired precision for estimating p, and it ranges between 1and86. A typicaln2is14so thatnt= 28. 7.3.2 Fleming's design Fleming (1982) proposed a multistage design for phase II clinical trials. One of its key characteristics is stopping early for efcacy. Example H0:p= 0:15,H1:p= 0:30. 36:6 36:9 7.4 Simon's design In his 1989 paper, Simon introduced two criteria to choose a 2 stage design for single arm and one sided test. The optimal design has the smallest expected sample size under H0(n1+Ep0[n2]), and the minimax design has the smallest 0:00 7.4.1 Conditional power To nd a good design (sample sizes and critical values), we need to understand the conditional power of a design. The conditional power is the probability of rejecting H0(in stage 2) given the stage 1 result, i.e., conditioned on X1=x1. Clearly, when X1> rt, conditional power is 1, and whenX1\u0014r1(futility stop), conditional power is 0. function of p,x1andn2as well asrt To obtain the unconditional power, we need to integrate (sum) the conditional power over all that \u001a(p0)\u0014 and\u001a(p1)\u00151\u0000 . 58Unlike in a single-stage situation, there may be more than one good design. Simon used the optimal andminimax to choose two reasonable designs among many satisfying the type I error rate and power constraints. Expected sample size under the null can be written as Ep0[nt] =n1+n2P[continue nt, rt, p0, p1, pl = TRUE, simple = FALSE) f # x1 <= r1 stop for futility en1 <- n1 data.frame(n1, r1, nt, p0 = = 2, format = \"f\"), p1 = formatC(p1, digit = 2, format \"b\") lines(out1$x1, out1$cp1, col = 2, type = \"b\") out2, g simon.d(n1 = 23, r1 = 3, nt = 48, rt = 11, p0 = 0.15, p1 = 0.3) 150.00.20.40.60.81.0 x1conditional power Given a design, computing operational characteristics such as type I error rate, power, expected sample size is not difcult; however, solving for the optimal, minimax, and other preferable designs is not trivial. Simon's original papers show how to do this. A very good webpage by Anastasia Ivanova at UNC is at http://cancer.unc.edu/biostatistics/ program/ivanova/SimonsTwoStageDesign.aspx . 617.4.3 Something in between The two criteria, optimal and minimax, give two designs that are extreme, and neither may t the investigators' needs. For example, for testing H0:p= 0:3with = 0:05and The optimal design tends to have a small n1and the minimax design tends to have a large n1. Therefore, a simple approach to nd a good alternative design is to force n1=n2. (balanced design of Y e and Shyr, 2007) simon.d(n1 = 40, r1 = 13, nt = 110, rt = 40, p0 = 0.3, p1 = 0.45, pl = FALSE, simple = TRUE) [[1]] n1 r1 nt rt p0 p1 1 18, nt = 106, rt = 39, p0 = 0.3, p1 = 0.45, pl = FALSE, simple = TRUE) [[1]] n1 r1 nt rt p0 p1 1 more systematic approach is to express the criteria for optimization as q(w) =w\u0002(nt) + (1\u0000w)\u0002E0[N]; where 0\u0014w\u00141.q(0)andq(1)correspond to the optimal and minimax designs, respectively. Computation shows that the minimax design is the best design with respect to q(w)forw2(0:827;1]. 62In between the optimal and minimax designs, the following \"admissible\" designs exist that optimize q(w)for certain ranges of w. (Jung, Lee, Kim, George, 2004) n1r1ntrt 1\u0000 E0[N]pet0w 0:903 60:8 0:70 (0:006;0:136) 0:901 61:3 0:75 (0:136;0:182) 0:902 62:8 0:58 (0:182;0:303) 0:00 7.5 Data analysis following a two-stage design in phase II clinical trials The primary objective of a (cancer) phase II clinical trial is to make a correct \"go/no-go\" decision; however, making a good inference for pis advantageous for planning the following phase III trial. We have seen before that when we terminate a study based on an interim summary of the data, a usual statistic that we often compute may be biased. In this section, we will look at the issue of bias in two-stage design in phase II clinical trial in detail. Simon's design will be our focus, but many general discussions can be applied to other designs as well. 7.5.1p-value If we ignore the fact that the data were gathered in a two-stage design and compute a p-value as if X\u0018Binomial (nt;p), it is bigger than the true p-value with the following denition/interpretation. p-value the probability under the null hypothesis that we would observe the data as or more extreme than what we have observed The term \"as or more extreme\" can be interpreted as \"as big or bigger evidence against H0\". In a simple single-stage design, the meaning of this is usually straightforward. We can all agree that Z= 2:0is more extreme (more evidence against H0) thanZ= 1:9. However, in two-stage designs, understanding sometimes gets tricky. H0:p= 0:3,H1:p>0:3; 63simon.d(n1 = 15, r1 = 5, nt = 46, rt = 18, p0 = 0.3, p1 = 0.5, pl = FALSE, simple = TRUE) [[1]] n1 r1 nt rt p0 p1 1 we observe X1= 7in stage 1 so that we move on to the second stage. And in stage 2, we observe additional 12positive responses in n2= 31 patients ( 19in46total) so that H0is rejected because Xt= 19>rt. If we compute a p-value without taking into account the study design, we might greater than as shown below: 1 - pbinom(18, 46, 0.3) [1] 0.06805 To see this inconsistency clearly, we will rewrite above as pc=P0[X\u001519] =15X x1=0P0[X2\u001519\u0000x1jX1=x1]P0[X1=x1]: From this expression we see that in computing pc, we include sample paths that can not be realized with this Simon's design, namely, X1= 0,X2\u001519;X1= 1,X2\u001518;\u0001\u0001\u0001;X2= 5,X2\u001514. A properp-value that takes into account the actual sampling scheme used may be pp=15X x1=6P0[X2\u001519\u0000x1jX1=x1]P0[X1=x1]: 64In general, for calculated pp=n1X x1=r1+1P0[X2\u0015xt\u0000x1jX1=x1]P0[X1=x1]; ifx1>r1(i.e., if there is a second stage). The following simple R script computes this n1, pc g c(p.val = p.val, pc = pc) g pp(n1 = 15, r1 = 5, nt = 46, rt = 18, x1 = 7, xt = 19, p0 = 0.3) p.val pc 0.04987 0.06805 Whenx1\u0014r1so that the trial is terminated in stage 1, we can dene pp=P0[X1\u0015x1]: Thus we think that \"moving on to the second stage\" has more evidence against H0than \"terminating in the rst stage for futility\", which makes sense. Theproperp-value (pp) has the following characteristics: \u000fIt is always smaller than or equal to pc. \u000fIt is consistent with the hypothesis testing, i.e., pp\u0014 if and only if H0is rejected. \u000fIfXt=rt+ 1, thenppis equal to the level of the test (so-called the actual type I error rate). \u000fIt does not distinguish different sample paths that lead to the same Xt. That is, evidence againstH0is identical if xtis the same regardless of x1. For example, X1= 8,X2= 12 andX1= 10,X2= 10 yield same p-values. When does this ( pp) break down? It breaks down when we allow n2to be different for various values of X1. In some modications of 65Simon's design (e.g., Banerjee A, Tsiatis AA. Stat Med 2006), the stage 2 sample size varies with x1. Then,ppcan not be computed because we cannot order the sample paths simply based on Xt. A bigger concern is that this ppcannot be used when n2is changed from that planned. An even bigger concern is if the actual n2is different from that planned, how can we re-compute the critical value,rt, to control type I error rate? The answer is not simple! 7.5.2 Point estimate Because the results from a phase II clinical trial are often used in planning a phase III clinical trial, a good estimate of pis often of interest. MLE In a single stage design, the MLE of pis^p=x=n. For a Simon's design, we can write the likelihood, lettingYidenote the individual datum from for \u0019is ^p(x) =( x1=n1ifx1\u0014r1 xt=ntifx1>r1 We have seen before that this ^p(x)has a downward bias, i.e., Ep[^p(x)]\u0014p. A simple explanation is that when ^pis small at the end of stage 1, we tend to terminate the study, and this downward bias tends to remain; however when ^pis large at the end of stage 1, more data are gathered and the upward bias of stage 1 tends to be corrected. Example :p0= 0:3,p1= 0:5, = 0:05, = ^p=20 39= 0:513: 66Whitehead of MLE estimator as: B(p) =Ep[^p(x)]\u0000p: So a good estimator would be \u0015p= ^p\u0000B(p): However,B(p)is unknown, so we need to estimate it. Let's use the current estimate of pinB(p). That is ^pw= ^p\u0000B(^pw): This is Whitehead's We ^p\u0000E^pw[^p(x)] leads to E^pw[^p(x)] = ^p: To nd ^pw, ^pw= 0:520. Koyama We can write the bias of the MLE estimator as: B(p) =Ep[^p(x)]\u0000p: So a good estimator so let's use B(^p), that is ^pk= ^p\u0000B(^p): 67This is simpler and more straightforward than Whitehead's We can write ^pk= ^p\u0000E^p[^p(x)] + ^p = the current example, ^pk= 0:521. Unbiased estimator For a general multistage design with early stopping for futility and efcacy, Jung and Kim (2004 Stat Med) found the unbiased estimator of p. They showed that the pair ( M,S), whereMis the number of stage (when terminated) and Sthe number of successes, is complete and sufcient for p. And clearlyx1=n1is unbiased for p, the uniformly minimum variance unbiased estimator (UMVUE) is found through Rao-Blackwell theorem. The for ^pubis complex, but for Simon's two-stage design (two-stage with only futility stop), it p\u0003 0such that the p-value for testing H0:p=p\u0003 0is0:5by the realized sample path. Many adaptive designs for phase II clinical trials were originally motivated as a hypothesis testing procedure, and computing this estimator should be fairly simple in many designs. 68If the test statistic is continuous, this estimator is known as the median unbiased estimator (Cox and Hinkley 1974). It is unbiased for the true median. The proof uses the fact that the p-value is distributed Unif (0;1)underH0. To compare these methods, we compute the bias of each estimator for various true values of p. Use bias and mean squared error = var + bias2to compare them. For each estimator, compute ^p(X)for every sample path (dened by Xin[0;nt]) and compute Ep[^p(X)] =ntX x=0^p(x)Pp[X=x]: computed by MSEp[^p(X)] =Ep[(^p(X)\u0000p)2] =ntX x=0(^p(x)\u0000p)2Pp[X=x]: The following two plots show bias and MSE for the current example. 690.2 0.3 0.4 0.5 0.60.030.020.010.000.01 true pbias MLE Whitehead Unbiased Koyama Median 0.2 0.3 0.4 0.5 0.60.0060.0070.0080.0090.0100.011 true pMSE MLE Whitehead Unbiased Koyama Median70Chapter 8 Non-inferiority 8.1 Introduction In a phase III clinical trial, the objective may be to show the experimental treatment is non-inferior to the active control . Active control is a conventional treatment that has been shown to be effective. Non-inferiority trial aims to show that the experimental treatment is clinically and statistically not inferior in effectiveness compared to an active control. When there is no proven treatment, placebo-controlled trials are generally not controversial; how- ever, when a proven effective treatment exists, the ethics of placebo-controlled clinical trials are questionable. Declaration of Helsinki (https://www.wma.net/policies-post/wma-declaration-of-helsinki-ethical-principles-for-medical-research-involving-human-subjects/ is a set of ethical principles regarding human experimentation developed for the med- ical community by the World Medical Association. It is regarded as the cornerstone document on human research ethics. (wikipedia) Article II.3 of Declaration of Helsinki stated (until 2000), \"In any medical study, every patient - including those of a control group, if any- should be assured of the best proven diagnostic and therapeutic method. This does not exclude the use of inert placebo studies where no proven diagnostic or therapeutic methods exists\". 71Currently, paragraph 33 states, \"The benets, risks, burdens and effectiveness of a new inter- vention must be tested against those of the best proven intervention(s), except in the following circumstances: \u000fWhere no proven intervention exists, the use of placebo, or no intervention, is acceptable; or \u000fWhere for compelling and scientically sound methodological reasons the use of any inter- vention less effective than the best proven one, the use of placebo, or no intervention is necessary to determine the efcacy or safety of an intervention \u000f... The terms, \"equivalence\" and \"non-inferiority\" are sometimes used interchangeably; however, their objectives are different. 8.2 Hypotheses and multiplicity Superiority The objective is to show that the test treatment is better than the control. H0:\u0016t\u0000\u0016c= 0 H1:\u0016t\u0000\u0016c>0 Power is set at some \u000es>0. Non-inferiority The objective is to show that the test treatment is not inferior to the control. (\"Not much worse than\") H0:\u0016t\u0000\u0016c=\u0000\u000eI H1:\u0016t\u0000\u0016c>\u0000\u000eI for some\u000eI>0. Power is usually set at 0. The value, \u000eIis called, \"non-inferiority margin\" and needs to be specied a priori. Equivalence The objective is to show that the test treatment is equivalent to the control. This is rarely used for efcacy, but in studies of pharmacokinetics, equivalence hypothesis testings may be useful (Bioequivalence). H0:\u0016t\u0000\u0016c<\u0000\u000eeor\u000ee<\u0016t\u0000\u0016c H1:\u0000\u000ee\u0014\u0016t\u0000\u0016c\u0014\u000ee for some\u000ee>0. Power is usually set at 0. Sample size for an equivalence trial ( \u000ee=\u000e) with and (power at 0) is equal to that for a superiority test with and =2(power at\u000e). Equivalence trials are inherently different from the other two; superiority and non-inferiority can be asked sequentially. 72\u000fNow that we have shown Tis non-inferior to C, can we test superiority using the same data? \u000fWe did not have enough evidence to say Tis better than C, can we try and at least say Tis non-inferior to C? There is no penalty in terms of type I error rate inflation, and superiority should always be tested after non-inferiority is established. Non-inferiority can be tested when superiority is not shown ifthe non-inferiority margin is dened a priori and stated in the protocol. There is no multiplicity when testing both superiority and non-inferiority because \u000fonly one (superiority or non-inferiority) can be true. \u000fwe can test both hypotheses with 1condence interval. Conclusion Superiority Non-inferiority but not superiority Inferiority Truth Superiority Correct type II error type II error Non-inferiority but not superiority type I error Correct type II error Inferiority type I error type I error Correct 73Confidence interval and conclusion 0 0 0 0 0 0 0 0 8.3 Unique problems with non-inferiority trials Choice of non-inferiority margin \u000fThe non-inferiority margin must not be larger than the control treatment effect. Otherwise, the new treatment may be as effective as placebo and yet non-inferior to the active control. \u000fThe non-inferiority margin should be based on both statistical reasoning and clinical judge- ment. The rst point will require us to be conservative in selecting the non-inferiority margin (pick a small \u000eI). This leads to a large sample size. http://www.ema.europa.eu/docs/en_GB/document_library/Scientific_guideline/2009/09/ 74WC500003636.pdf Assay sensitivity is a property of a clinical trial dened as the ability of a trial to distinguish an effective treatment from a less effective or ineffective intervention. In a superiority test, assay sensitivity is not an issue because concluding superiority automatically establishes assay sensitivity. However, in a non-inferiority trial, showing non-inferiority does not show assay sensitivity. In other words, Tmay be non-inferior to C, but it may not be better than a placebo. Including a placebo arm will address the issue if it is ethical to do so. Assay sensitivity is not shown but assumed. \u000fHistorical evidence of sensitivity to drug effects. -Appropriately designed and conducted trials in a particular disease with a specic active drug reliably show an effect. This is an abstract concept about trials of a drug in a particular disease whereas assay sensitivity is a characteristic of a particular trial. \u000fThere are some conditions where treatment responses are large and clearly greater than placebo effect, and there are other cases evidence from many studies are consistent. -However, this may not be applicable to the new clinical trial. \u000fHigh quality study. Factors that may reduce assay sensitivity includes -Poor compliance -Crossovers (switching treatments) -Poor diagnostic criteria (patient reported outcomes) Example Suppose we are to show non-inferiority of Intervention Tto an active control C. The data are assumed to come from X\u0018Normal (\u0016t;\u001b2)andX\u0018Normal (\u0016c;\u001b2), where\u001b= 32 . The non-inferiority at \u000eI= 10, that is, H0:\u0016t\u0000\u0016c=\u000010 H1:\u0016t\u0000\u0016c>\u000010 The clinical trial is designed with the one-sided type I error rate of = 0:03and power of 0:90at \u0016t\u0000\u0016c= 0. The test statistic is Z=Xt\u0000Xc+\u000eIp 2\u001b=pn And the required sample size is I =2(322)(1:96 + 1:28)2 102= 216: simulation. simulation.NI <- function(muc, mut, sig, n, del0 = 10, B) f ## del0 > 0. muc and mut are true values. numeric(B) simulation.NI(muc = 20, mut = 10, sig = 32, n = 216, del0 = 10, B = 1000) table(outNULL < 0.025) FALSE TRUE 976 24 set.seed(7914) outALT <- simulation.NI(muc = 20, mut = 20, sig = 32, n = 216, del0 = 10, B = 1000) table(outALT < 0.025) FALSE TRUE 107 893 Now suppose that 10% of groupTswitched to C, and of intention2treat function(muc, mut, del0 = 10, Rtc, Rct, B) f ## Rtc is % of T group who switched to C. Rct is % of C group who ## switched to T. p.value intention2treat(muc = 20, mut = 10, sig = 32, n = 216, del0 = 10, Rtc = 0.1, Rct = 0.12, B = 1000) table(outNULL2 < 0.025) FALSE TRUE 899 101 set.seed(71122) outALT2 <- intention2treat(muc = 20, mut = 20, sig = 32, n = 216, del0 = 10, Rtc = 0.1, Rct = 0.12, B = 1000) table(outALT2 < 0.025) FALSE TRUE 99 901 In a non-inferiority trial, the intention-to-treat analysis is anti-conservative. 77Chapter 12 Treatment effects monitoring 12.1 Introduction A phase III clinical trial (comparative treatment efcacy phase) is a type of trial design that assesses the efcacy of a new treatment relative to an alternative, placebo, standard therapy, or no treatment. DSMB Data and safety monitoring board DMC Data monitoring committee TEMC Treatment effects monitoring committee \u000fDMC should have no formal involvement with subjects or investigators. \u000fDMC should interact actively in data analysis, request additional analyses if necessary. \u000fDMC usually meets two to three times a year (or after set number of patients contribute the data). Motivations for monitoring treatment effects \u000fCheck protocol compliance (baseline variables). Baseline imbalances alone are not likely to be a cause for much concern, but it can undermine the credibility of a trial, some intervention might be proposed to correct them. \u000fReview accrual Accrual tends to be slow at the beginning of the trial. The dropout rate may be higher than expected and/or the event rate may be lower than planned. Remedial actions include to prolong the accrual length and to add study centers. \u000fReview resource availability Money! Human resources (loss of irreplaceable expertise), difculty obtaining rare drugs. 78\u000fReview data quality DMC checks patient eligibility (minor deviations are common), minor deviations in baseline data acquisition, randomization, misdiagnosis. Deviations occurring more than 10% of all patients may be a sign of internal quality control problem. Treatment compliance/adherence. \u000fReport adverse events Frequent side effects of low intensity may trigger dose reduction. A rarely occurring fatal toxicity could be intolerable in studies where patients are basically healthy / have a long life expectancy. \u000fMonitor treatment efcacy After all the previously mentioned checks are cleared, TEMC assesses efcacy differences. \u000fCheck \u000fShould the trial continue? There may be secondary outputs from the trial such as secondary questions, database. \u000fShould the protocol modied? e.g., terminating one of many arms; adjusting timing or frequency of diagnostic tests changing consent process, improving quality of data collection, ... \u000fDoes the TEMC need other views of the data? \u000fShould the TEMC meet more/less frequently? If the timing is based on \"information time\" the meeting may not occur at the recommended intervals (calendar time). Reasons for stopping a trial (Table 14.1 in Piantadosi) \u000fTreatments are found to be convincingly different. \u000fTreatments are found to be convincingly not different. \u000fSide effects are too severe. \u000fThe data are of poor quality. \u000fAccrual is too slow. \u000fDenitive information about the treatment becomes available making the study unethical or unnecessary. \u000fThe scientic questions are no longer important. \u000fAdherence to the treatment is unacceptably poor. \u000fResources to perform the study are no longer available. \u000fThe study integrity has been undermined. Factors to consider before terminating a study \u000fDelays in reporting. \u000fBaseline differences. \u000fBias in response assessment. \u000fMissing data. \u000fCredibility of results if stopped early. 79Reasons for not stopping early: Increasing precision and reducing errors Subgroup analyses, interaction effects, secondary endpoints 12.1.1 Composition and organization of TEMC = DMC TEMC is intellectually and nancially independent of the study investigators so that it can provide objective assessments. Who should TEMC make recommendations to? Trial sponsor or trial investigators or both? \"The TEMC has an obligation to inform the investigators of their opinions and recommendations about actions that carry ethics implications.\" FDA's 1989 guideline has a very brief description of data monitoring and DMCs. NIH policy (1998) \u000fAll sponsored trials must have a monitoring system for safety, efcacy and validity. ICH guidelines (1998) \"When a sponsor assumes the role of monitoring efcacy or safety comparisons and therefore has access to unblinded comparative information, particular care should be taken to protect the integrity of the trial...\" \"Any interim analysis that is not planned appropriately (with or without the consequences of stopping the trial early) may flaw the results of a trial and possibly weaken condence in the conclusions drawn.\u0001\u0001\u0001If unplanned interim analysis is conducted, the clinical study report should explain why it was necessary, the degree to which blindness had to be broken, provide an assessment of the potential magnitude of bias introduced, and the impact on the interpretation of the results.\" \"The IDMC should have written operating procedures and main records of all its meetings, ...\" \"The IDMC is a separate entity from an Institutional Review Board (IRB) or an Independent Ethics Committee (IEC), and its composition should include clinical trial scientists knowledgeable in the appropriate disciplines including statistics.\" DMC membership Data monitoring is a complex decision process and requires a variety of expertise in medicine, basic science, biostatistics, epidemiology, and medical ethics. (Additionally representative from a regulatory body) DMC condentiality In general, interim data must remain condential. DMC rarely releases interim data, and its 80members must not share interim data with anyone outside of DMC. Data leaks may affect \u000fPatient recruitment. \u000fProtocol compliance. \u000fOutcome assessment. \u000fMarket value. Then why not have DMC only use blinded data? Complete objectivity 6=ethical Revisit the question, \"Should DMC include the study investigators?\" FDA draft guidance \"Knowledge of unblinded interim comparisons from a clinical trial is not necessary for those con- ducting or those sponsoring the trial; further, such knowledge can bias the outcome of the study by inappropriately influencing its continuing conduct or the plan of analyses. Therefore, interim data and the results of interim analyses should generally not be accessible by anyone other than DMC members.\" Guessing the between-group difference only using blinded data. Suppose in order to check data quality, the pooled variance was computed and reported in the DMC. For example, \"We originally anticipated \u001b2= 20; however, the pooled variance after n1= 50 from each group was s2 1p= 25 . If the clinical trial scientist or the sponsor has an access to this information how bad is it? By itself it is not too bad; if data are from normal populations, variance estimate and mean estimate are independent. However, without breaking the blind, the overall mean data -Sponsor, Executive committee, DMC, SAC. \u000fClosed session -Unblinded session -DMC only. \u000fDebrieng session -DMC chair, Sponsor representative, Executive committee representative. 81Chapter 13 Group Sequential Method 13.1 Introduction Fully sequential method A test of signicance is repeated after each observation. Group sequential method A test of signicance is repeated after a group of observations. Some basic characteristics of a group sequential method \u000fThe response variable needs to be observed immediately. \u000fNumber of stages (or looks) can be 2 to 20. \u000fLooks are equally spaced. (This is not a critical requirement.) \u000fAt each interim (and nal) analysis, compute summary statistic based on the cumulative data. \u000fA group sequential method is a strategy to stop early as opposed to an \"adaptive design\", which is often viewed as a strategy to extend the study if necessary. \u000fA set of critical values are computed so that the overall is as specied. -Haybittle-Peto (1971) This is an ad hoc method in which a very conservative critical value (e.g., Z > 3) is used at every interim test. At the nal analysis, no adjustment is used (i.e., Z >\u00001:96) It is highly unlikely to stop early. -Pocock (1977) A \"repeated test of signicance\" at a constant signicance level to analyze accumulating data. -O'Brien-Fleming (1979) The signicance levels increase as the study progress. 8213.2 Example For testing \u0016t\u0000\u0016c= 0 \u0016t\u0000\u0016c>0 With = 2, alpha = 0.025, beta = 0.1, delta0 = 0, delta1 = 0.25, n.fix = \"OF\") x.po <- gsDesign(k = 5, test.type = 2, alpha = 0.025, beta = 0.1, delta0 = 0, delta1 = 0.25, n.fix = 1, sfu = \"Pocock\") 830.0 0.4 0.6 0.8 1.0 1.242024 Information FractionBoundary Pocock O'BrienFlemingSample size is expressed in terms of ratios to the sample size of the conventional single-stage design. ## Pocock x.po Symmetric two-sided group sequential design with 90 % power and 2.5 % Type I Error. Spending computations assume trial stops if a bound is crossed. Sample Size Analysis Ratio* Z Nominal p Spend 841 0.241 2.41 0.0079 spending: Pocock boundary. * Sample size ratio compared to fixed design with no interim Boundary crossing probabilities and expected sample size assume any cross stops the trial Upper boundary (power or Type I Error) Analysis Theta 1 2 3 4 5 Total (futility or Type II Error) Analysis Theta 1 2 3 4 5 Total sequential design with 90 % power and 2.5 % Type I Error. Spending computations assume trial stops if a bound is crossed. Sample Size Analysis Ratio* Z Nominal p Spend 1 0.205 4.56 0.0000 boundary. * Sample size ratio compared to fixed design with no interim Boundary crossing probabilities and expected sample size assume any cross stops the trial Upper boundary (power or Type I Error) Analysis Theta 1 2 3 4 5 Total (futility or Type II Error) Analysis Theta 1 2 3 4 5 Total 0.000 0 p is simplyP[Z >z ], whereZ\u0018Normal (0;1). \u000fSpend is the type I error probability that has been spent by the end of each stage, and it is based on conditional probability. For example, for the second stage of the Pocock design, it is 0:01. It can be computed as follows: P[Z2>2:41j\u00002:41\u0014Z1\u00142:41]: 13.3 General applications Letk= 1;\u0001\u0001\u0001;Kbe cumulative sample sizes for the treatment and control groups. Note that this is not a conditional distribution but a marginal distribution. Dene \"information\" as Ik= (\u001b2=ntk+\u001b2=nck)\u00001. Roughly speaking, information is square of what appears in the denominator of the test statistic, Z. Whennk=ntk=nck,Ik= (2\u001b2=nk)\u00001. The test statistic normal distribution because each Zkis a linear combi- nation of the independent normal variates XtiandXci. The marginal distribution of Zkis Zk\u0018Normal\u0010 is 87After group k= 1;\u0001\u0001\u0001;K\u00001 ifjZkj\u0015ckstop and reject H0. otherwise continue to group k+ 1. After group K ifjZkj\u0015cKstop and reject H0. otherwise stop for futility. The test's type I error rate can be expressed as PfjZkj\u0015ckfor somek= 1;\u0001\u0001\u0001;Kg: The critical values, ck, are chosen so that the above probability is equal to . And the power of the study at\u000e1is P(K[ k=1(jZjj<cj;forj= 1;\u0001\u0001\u0001;k\u00001andjZkj\u0015ck)) : Evaluation of this probability requires knowing the distribution of (Z1;\u0001\u0001\u0001;ZK). Refer to tables of cKvalues or a computer software. \u000fFor a Pocock method, the critical values are constant, so ck=CP(K; ). That is, specifying andKuniquely determines the critical values. \u000fFor the previous example, CP(5;0:03) = 2:41. \u000fFor an O-Fleming method, the critical values have the form, ck=CB(K; )p K=k \u000fFor the same example, CB(5;0:03) = critical values different, use Ik, that is,ck=CB(K; )p IK=Ik. 13.3.1 Beta blocker heart attack trial Seven analyses (including the nal one) were planned (corresponding to the timing of the Data Monitoring Committee meetings) using O'Brien-Fleming bounds with two-sided type I error rate of 885%. The primary outcome was survival, and log-rank test was used. If Pocock boundary had been used, N= 7and = 0:05giveZ= 2:485. Therefore, the trial would have been stopped at the same point. 13.3.2 non-Hodgkin's lymphoma Pocock 1983 Clinical Trials: A Practical Approach . A trial was conducted in patients with non- Hodgkin's lymphoma for two drug -CVP-). The primary endpoint was tumor shrinkage (Y es/No). Statistical analyses were planned after approximately 25 patients. With 5 looks and one-sided = 0:05. The Pocock procedure requires a signicance level of 0.02 at each analysis. 2tests without the continuity correction were performed at each of the 5 scheduled analyses. gsDesign(k = 5, test.type = 1, alpha = 0.05, n.fix = 1, sfu = \"Pocock\") One-sided group sequential design with 90 % power and 5 % Type I Error. Sample 89Size Analysis Ratio* Z Nominal p Spend 1 0.246 spending: Pocock boundary. * Sample size ratio compared to fixed design with no interim Boundary crossing probabilities and expected sample size assume any cross stops the trial Upper boundary (power or Type I Error) Analysis Theta 1 2 3 4 5 Total better than the CP , but difference was not statistically signicant. Further analyses of secondary endpoints convinced the researchers that the CVP was better than the CP . 13.4 Alpha-spending \"Classical\" group sequential designs have equal information (sample size) at every stage, but we may want to be a little more flexible. And when Ikis not a constant we might want to change spent accordingly. 90Decompose the rejection region. alpha-spending approach is its flexibility; neither the number nor timing of the interim analyses need to be specied in advance. The monitoring plan can be changed during the trial and still type I error rate is preserved. The power depends relatively little on the number and timing of the interim looks1. Alpha-spending = 2\u0002 1\u0000\b\u0000 trials ed)\" by Friedman LM, Furberg CD, DeMets DL 0.6 0.8 1.00.0000.0050.0100.0150.0200.025 Information fractionalpha spendingOF Pocock Power (1) Power (4)alpha spending functions13.5 One-sided test If \"stop for futility\" is not an option, the same boundary can be used. If a futility stop is an option, then After group k= 1;\u0001\u0001\u0001;K\u00001 ifZk\u0015bkstop and reject H0. ifZk\u0014akstop for futility After group K ifZk\u0015bKstop and reject H0. ifZk<aKstop for futility. Note thataK=bKensures that the test terminates at analysis K. 9213.6 Repeated condence intervals If we compute unadjusted condence intervals \u0016Xso far\u00061:96\u001b=pnso far at the end of each stage, we get low coverage probabilities. Armitage, McPherson, Rowe (\"Repeated signicance tests on accumulating data\". JRSS-A 1969) computed the actual coverage probabilities (Table 2). Number of looks Overall probability that all intervals contain \u0012 1 0 :95 2 0 :92 3 0 :89 4 0 :87 5 0 :86 10 0 :81 20 0 :75 50 0 :68 1 0 The idea of repeated condence intervals (RCIs) is to use an adjusted value, ck( ;K), instead of 1:96so that the overall coverage probability is 1\u0000 =2. The value of ck( ;K)is the critical value (border) for each stage and depends on andKif Pocock boundary is used, and additionally kif O'Brien-Fleming boundary is used. Example: Suppose we use a 6-stage group sequential design of O'Brien-Fleming type with a two-sided = 5% . The critical values are: gsDesign(k = 6, test.type = 2, alpha = 0.025, sfu = \"OF\") Symmetric two-sided group sequential design with 90 % power and 2.5 % Type I Error. Spending computations assume trial stops if a bound is crossed. Sample Size Analysis Ratio* Z Nominal p Spend 1 0.172 5.03 0.0000 spending: O Brien-Fleming boundary. * Sample size ratio compared to fixed design with no interim Boundary crossing probabilities and expected sample size assume any cross stops the trial Upper boundary (power or Type I Error) Analysis Theta 1 2 3 4 5 6 Total E{N} (futility or Type II Error) Analysis Theta 1 2 3 4 5 6 Total 0.000 0 2.053 First, critical values have the form ck=COB(K; )p IK=Ik. The nal critical valueCOB(6; ) = 2:05, and assuming the looks are equi-distant (same group sample Then after stage 1, we would use 5:03in place of the regular 1:96when computing a 95%condence interval. In general (\u0016xkt\u0000\u0016xkc)\u0006ckp 2\u001b2 p mk; wheremis per-group sample size for each stage. This method (RCI) is consistent with the corresponding hypothesis testing. Only when is H0rejected in stagek, the condence interval for that stage will exclude the null value. Thus, we can use the idea of \"inverting hypothesis test\" to get the same condence interval. (more later) 9413.7 P-values Recall how we construct a proper p-value for a Simon's two-stage design in phase II methodology. We needed to dene \"more or as extreme as the observed data\". To be able to do this, we need to have an ordering of all the sample paths. In a simple single-stage design, the ordering is usually based onz-values (or absolute value of z-values if two-sided test), i.e., the bigger the observed z, the stronger the evidence against H0. Then a one-sided p-value is computed by p=P0[Z\u0015z]: With a group sequential design, or more generally, with a multi-stage design with pre-specied group-wise sample sizes, the value). 3.k0>kandz0\u0014ak(lower critical value). \u000fMLE ordering. (k0;z0) (k;z)ifz0=pIk0>z=pIk. Originally proposed in connection with a test for a binomial proportion The bigger value of the MLE gets a higher order. Sometimes called \"sample mean ordering\" because this is equivalent to ordering based on the sample mean (one-sample) or the difference of sample means (two-samples). \u000fLikelihood ratio ordering. (k0;z0) (k;z)ifz0>z. (Stages do not matter.) \u000fScore test ordering. (k0;z0) (k;z)ifzpIk0>zpIk. Whichever ordering is used, we can compute a one-sided p-value is P0[(T;ZT) (k\u0003;z\u0003)] For example, if we use a stage-wise ordering gk(z;\u0012)is a density function of zin stagek. Conceptually, the density function of zinkstage depends on all the data in the previous stages, 1\u0001\u0001\u0001k\u00001, requiring multivariate integration. 95Armitage, McPherson, Rowe (1969) derived a recursive formula so that the computation is much simplied, requiring only a k1, and \u0001kis the increment information, Ik\u0000Ik\u00001. If stage-wise ordering is used, it automatically ensures that item the p-value is less than the signicance level if and only if H0is rejected. Once we dene the ordering to use with the group sequential test then we can compute a p-value for testingH0:\u0012= 0by \"inverting hypothesis 0such thatH0 0:\u0012=\u00120 0would be accepted with the observed sample path. (More details with general adaptive designs.) 96Chapter 14 Two-stage adaptive designs 14.1 Introduction Much of discussion in the literature for flexible designs in phase III clinical trial methodologies revolves around 2 stage designs. Practically speaking, implementing flexible clinical trials beyond two stages is difcult, and perhaps these multi-stage flexible designs add only little to the designs with just two stages. Moreover, phase III clinical trials are for conrmatory purposes, and adaptively changing the design more than once in the middle of a conrmatory trial is not seen favorably by the regulatory gure. So we will only consider two-stage adaptive designs. Two-stage group sequential designs are examples of such designs. 14.2 Background We will look at unmasked (unblinded) two-stage designs in which all the information from stage 1 is available. Design of the second stage (sample size and critical value) may be specied as functions of stage 1 data. If both sample size and critical value are constants in stage 1 data, then it reduces to a two-stage group sequential design. Adaptive designs can be categorized into the following two types: \u000fPrespecied designs Design of the second stage (e.g., sample size and critical value) is specied before the rst stage. There is nothing to decide at the end of stage 1. The design of the second stage is dened flexibly as functions of stage 1 data. Group sequential designs fall into this category. 97\u000fUnspecied designs Design of the second stage is not specied in advance and determined after stage 1 data are observed. Characteristics of these types of designs: Prespecied designs \u000fType I error can be controlled. \u000fType II error can be controlled. \u000fY ou can compute design characteristics of the design (e.g., Expected and maximum sample sizes) prior to initiation of the study. Unspecied designs \u000fType I error can be controlled. \u000fThese designs give much flexibility to handle unexpected situations (e.g., Variance is much bigger than anticipated). Something in between: Not specifying the stage 2 sample size is unrealistic because it makes it impossible to budget such a clinical trial. Instead of leaving the stage 2 unspecied, maybe we should specify the maximum sample size. And perhaps, we may want to specify the minimum conditional power for the second stage, P[RejectH0in stage 2jStage 1 data]. With these specications, unspecied designs start to look like prespecied ones. What do they say about adaptive designs PhRMA (2006) \"... a clinical study design that uses accumulating data to decide how to modify aspects of the study as it continues, without undermining the validity and integrity of the trial.\" \"... Changes are made by design, and not on an ad hoc basis; therefore, adaptation is a design feature aimed to enhance the trial, not a remedy for inadequate planning.\" EMA (2006) \"A study design is called 'adaptive' if statistical methodology allows the modication of a design element (e.g. sample-size, randomisation ratio, number of treatment arms) at an interim analysis with full control of type I error rate.\" \"... adaptive designs should not be seen as a means to alleviate the burden of rigorous planning of clinical trials.\" FDA (2010) \"... Adaptive design clinical study is dened as a study that includes a prospec- tively planned opportunity for modication of one or more aspects of the study design and hypotheses based on analysis of data (usually interim data) from subjects in the study.\" 9814.3 Set up What are good two-stage adaptive designs? \u000fWhat do we use to compare different designs? -Power between \u00160and\u00161 -Expected sample size at different \u0016's. \u000fDesign of stage 1 tends to be more influential in terms of these characteristics. \u000f\"Optimality\" is not the only driving force to choose a design. A design with a very small n1may have different objectives than those with a large n1. (Ambitious designs vs. Insurance-type designs) To testH0:\u000e= 0, where\u000e=\u0016t\u0000\u0016c, we take random samples from Xt\u0018Normal (\u0016t;\u001b2 t) Xc\u0018Normal (\u0016c;\u001b2 c): and known: \u001b2 t=\u001b2 c=\u001b2. Also assume the sample sizes are equal in the control and treatment groups: n1t=n1c=n. Then \u0016X1t\u0018Normal Also dene \u0010=pn1\u0018for the stage 1. In stage 1, we observe Z1and use the following decision rule: \u000fIfZ1<k1, stop for futility. \u000fIfZ1>k2, stop and reject H0. \u000fIfk1<Z 1<k2then continue to stage 2. In stage 2, we take a sample of size n2(z1)from each arm, and dene Z2=p n2(z1)(\u0016X2t\u0000\u0016X2c)p 2\u001b: Conditioned on Z1=z12(k1;k2), Z2\u0018Normal (p n2(z1)\u0018;1): The decision rule at the end of stage 2 is: 99\u000fIfZ2\u0014c(z1), stop and conclude futility. \u000fIfZ2>c(z1), stop and conclude efcacy. We can use Z1andZ2to construct a two-stage design, and we can also construct a test statistic that combines the test statistics from both stages. Let Zw=Z1+Z2p 2: IfZ1andZ2are independent Zw\u0018Normal \u0018pn1+p n2(z1)p 2;1! UnderH0,Zwhas the standard normal distribution. Zwis rarely used because it weights stage 1 and stage 2 data differently. To give equal weight to every datum, we should construct a test statistic then we have Zu\u0018Normal\u0010p n1+n2(z1)\u0018;1\u0011 ; ifZ1andZ2are independent. It is useful to write of Z1andZ2as follows: Zu=pn1p n1+n2(z1)Z1+p n2(z1)p n1+n2(z1)Z2 100Because even the existence of the second stage depends on Z1, we need to think about stage 2 conditioned on stage 1 data. Conditioned original decision rule at the end of stage 2 was written in terms of Z2, i.e.,Z2> c(z1)then rejectH0. This can be written in terms of Zu. Suppose the critical value that goes with Zuiscu(z1). Conditioned on Z1=z1we have cu(z1) =pn1p n1+n2(z1)z1+p n2(z1)p n1+n2(z1)c(z1): The decision rule at the end of stage 2 can be written in terms with Z2andZu. There exist many different normalization schemes. For example, Zucan be rescaled to have a n2(z1)Zu\u0018Normal pn1p n2(z1)z1+p n2(z1)\u0018;1! 14.4 Conditional power functions Conditional power is the probability of rejecting H0in stage 2 conditioned on the rst stage data. LetA(z1;\u0018)to denote the conditional power at \u0018givenZ1=z1. Then we have A(z1;\u0018) =P\u0018[Z2>c(z1)jZ1=z1]: The conditional distribution A(z1;\u0018) = 1\u0000\bh c(z1)\u0000p n2(z1)\u0018i The conditional type I error rate is A(z1;\u00180). Specically, when \u00180= 0, we have A(z1;0) = 1\u0000\b 101The conditional is A(z1;\u00181) = 1\u0000\bh c(z1)\u0000p n2(z1)\u00181i : To specify a design that has type I error rate of , we need to pick the conditional power functions (and other design parameters such as critical values and sample sizes) so that =Z1 k2g1(z1;\u00180)dz1+Zk2 k1A(z1;\u00180)g1(z1;\u00180)dz1 = 1+Zk2 k1A(z1;0)g1(z1;0)dz1; whereg1(z1;\u0018)is the probability Z1\u0018Normal (pn1\u0018;1). k2g1(z1;\u00181)dz1+Zk2 1 is already designed ( n1,k1andk2), we can choose to use any A(z1;0)andA(z1;\u00181) as long as they satisfy these and\u001aconditions. Then we can nd the critical value and sample size for stage 2 using A(z1;\u00180) = 1\u0000\bh c(z1)\u0000p n2(z1)\u00180i A(z1;\u00181) = 1\u0000\bh c(z1)\u0000p A(z1;\u0018)functions and solve for n2(z1)andc(z1); however, we can specify any two of the four \"design elements\" and solve for the remaining two. Perhaps, we want to specify A(z1;\u00180)so that the type I error rate is controlled and n2(z1)so that the sample size is controlled. In this case, we have <- 0 To testH0:\u0016t\u0000\u0016c= 0andH1:\u0016t\u0000\u0016c>0. Assume\u001bis known to be 4. We want one sided to be 0:03and power to be ceiling((qnorm(alp) + qnorm(bet))^2/xi1^2) For a single stage design, the sample size is N=(z0:03+z0:10)2 0:18= 337 n1 <- round(N * 0.4) Let's decide to look at the data when n1= 135 observations are available from each group. (approximately 40% ofN) alp1 <- 0.01 bet1 <- 0.025 We also need to decide how much of and we want to \"spend\" in stage 1. Let's choose let's set the maximum sample size to be 500(approximately 50% increase from N). First, let's look at some stage 1 design characteristics: - fut1 - stage 1 characteristics Stage 1 \u0016 \u0018 \u0010 Accept Continue we will select the conditional power functions. The unconditional type I error rate for the second stage is (alp2 <- alp - alp1) [1] 0.015 Similarly, the unconditional power (at the original alternative) for the second stage is 105(pow2 <- pow - rej1) [1] 0.507 If we are to use a flat A(z1\u00180), we need the conditional type I error rate power is Aflat(z1;\u00181) = (0:90\u00000:39)=0:58 = 0:87 TheseA-functions give A0and flatA1 Stage 1 Stage 2 This design Single stage \u0016 \u0018 n 1Accept Continue Reject form A(z1;\u00180) =a0+a1(z1\u0000k1)2andA(z1;\u00181) =b0+b1(z1\u0000k1). We can use any Afunctions as long as they satisfy and power conditions. 106a0 <- 0.002 First we pick a0(the value = k2, k = k1, a0 = a0, a1 = <- = = 0.1, k1 = k1, k2 = k2, The above numerical integration found 0:04. A(z1;\u00180) = 0:00 + 0:04(z1\u00000:09)2: can compute n2(z1), and it turns out maxfn1+n2(z1)g>500, and we need to modify the design a little. It is relatively simple to make small modications to the design because we understand how the design elements A(z1;\u00180),A(z1;\u00181),n2(z1), andc(z1), are interrelated. First while xing A(z1;\u00180), we \"tap\"n2(z1)so that maxfn1+n2(z1)g= 500 . This action changes A(z1;\u00181)slightly resulting a smaller power than 0:90. To make the power 0:90again, we add a constant to the new A(z1;\u00181)but capping the resulting n1+n2(z1)at500. The nal design is shown below graphically. 1080.0 0.5 1.0 1.5 2.00100200300400500 z1n1+n2(z1) 0k1 1k2n1NDesign with flat A0and flatA1 Stage 1 2 This design Single stage \u0016 \u0018 n 1Accept Continue Reject the quadratic A0and linear A1 Stage 1 Stage 2 This design Single stage \u0016 \u0018 n 1Accept Continue Reject literature, many specic Afunctions have been proposed. A few examples (1995) power under the current trend\" 14.5 Unspecied designs The minimum requirement to control type I error rate is to pre-specify A(z1;\u00180)function that satises condition. Then after the rst stage, when the actual z1from the data are available, pick n2(z1)so that conditional powers at any a value of \u0018(other than \u00180) can be set. If we allow even A(z1;\u00180)to be specied after the st stage, type I error rate cannot be controlled. There exist many (in fact innite number of) A(z1;\u00180)functions that give the desired value of 1 (0:01in our example). Depending on z1the required sample size to guarantee a certain conditional power differs. We cannot choose an A(z1;\u00180)function that gives the minimum sample size for the observedz1. Roughly speaking, when the conditional type I error rate at the observed z1is large, the required sample size is small for the same conditional power. All three conditional type I error rates in the following plot give = 0:025. 1100.0 0.5 1.0 1.5 2.00.000.050.100.150.200.25 z1Conditional power 0k1 1k214.6 Ordering of sample space To compute p-values and condence interval (through inverting hypothesis tests), we need to dene an ordering of sample space. However, this task is difcult because of sample size difference for potential values of z1. One useful fact (not too difcult to show) is that the decision rule, \"reject if Z2>c(z1)\" is equivalent to the rule \"reject if stage 2 conditional p-value is less than A(z1;\u00180)evaluated at the observed z1.\" So we can compute a conditional p-value just using the stage 2 data, P0[Z2>z2], and compare it to the conditional type I error rate computed at the observed z1. Different example! Suppose the following conditional type I error rate is used: 1110.0 0.5 1.0 1.5 2.0 stage be rejected because this p-value is less than A(z1;\u00180)i.e., below the red line. \u000fifz1= 1:0and stage 2 conditional p-value is 0:10thenH0will not be rejected. Therefore, we need an ordering of the sample space that takes into account not only the sample size of stage 2, n2(z1), but also the conditional type I error rate for the stage 2, A(z1;\u00180). Suppose we choose to use A(z1;\u00180)andA(z1;\u00181)shown in the plot below. And let's consider the following 5 sample paths indicated by the conditional pvalues. Can we order the strength of evidence against H0for these data? 1120.0 0.5 1.0 1.5 2.0 2.50.00.20.40.60.81.0 Z1Conditional PowersA(z1,0)=.005+.1118(z 1k1)2\u000fWhenz1is the same, the second stage sample size is the same, so it should be simple to order the sampling paths. The smaller the pvalue, the stronger the evidence against H0. Blue Red Y ellow. \u000fWhen the conditional pvalues are the same, then we can order them by the strength of evidence in the rst stage. Blue Black Green. \u000fThe black and red dots should indicate equal strength of evidence because they both result in \"just\" rejecting H0. So in the above picture, the only unclear ordering is between Green and Y ellow. The third rule gives a hint as to how to proceed; the data leading to the black and red dots indicate that those data have just enough evidence to reject H0. The blue dot is for a sampling path that gives stronger evidence against H0; we could reject H0 0that is more extreme. We can nd a value of \u0018\u0003 0(equivalently, \u0016\u0003 0) so thatA(z1;\u0018\u0003 0)goes through the blue dot, and say we could have rejected H\u0003 0:\u0016=\u0016\u0003 0. Technically speaking, we can nd 113Note that a value of z1is observed, we can evaluate c(z1)andn2(z1), so the only unknown quantity in the above expression is \u0018\u0003 0. 0.0 0.5 1.0 1.5 2.0 2.50.00.20.40.60.81.0 Z1Conditional A(z1,.29) A(z1,0) A(z1,.22) we know the ordering is: Blue Red =Black Green Yellow. And \"some as or more extreme\" than the observed is anything on and below the line, and we can compute the p-value by computing Z1 k2g1(z1;\u00180)dz1+Zk2 k1A(z1;\u0018\u0003 0)g1(z1;\u00180)dz1 This method (ordering) guarantees that the p-value and the corresponding hypothesis testing are consistent ( p-value< iffH0is rejected). And it can be shown that when n2(z1)andcu(z1)fcritical value for the combined statistic gare constants, this ordering reduces to the stage-wise ordering. 11414.7 Predictive power With an unspecied design, some people are reluctant to use the conditional power to determine the design of the second stage. One issue is that where to compute the conditional power is not always clear. The original alternative is usually a reasonable choice ( A(z1;\u00181)). However, when the observed z1 is much different (smaller) from \u00181we may not be interested in the conditional power at \u00181but at some smaller value that is still clinically meaningful. (Minimum clinically relevant alternative =\u0018y 1) Another popular choice is ^\u0018\u0011z1=pn1(\"alternative under the current trend\"). Or maybe we should compute the conditional power at somewhere in between \u00181and\u0018y 1. Average? Now we are talking like a Bayesian because we are talking about an average of \u0018s which are, for a frequentist, parameters. Maybe we have a prior distribution of \u0018(or equivalently \u0016). And a posterior distribution of \u0018after the rst stage, \u0019(\u0018jz1), and we can compute a weighted average of the conditional powers with respect to the posterior distribution. Something like Z1 \u00001A(z1;\u0018)\u0019(\u0018jz1)d\u0018; and this is often called a predictive power given the stage one data. The conditional power is a frequentist concept, and it is computed at one value of \u0018. The predictive power is a Bayesian concept, and it is a weighted average of the conditional power with respect to a posterior distribution of \u0018. 115Chapter 15 Factorial design 15.1 Introduction Factorial clinical trials (Piantadosi) Experiments that test the effect of more than one treatment using a design that permits an assessment of interactions among the treatments The simplest example of a factorial design is 2 treatment, 2 treatment groups (2 by 2) designs. With this design, one group receives both treatment, a second group receives neither, and the other two groups receive one of A or B. Treatment B Treatment A No Y es Total Non n 2n Y esn n 2n Total 2n 2n 4n Four treatment groups and sample sizes in a 2\u00022balanced factorial design. Alternatives to a 2\u00022factorial design \u000fTwo separate trials (for A and for B) \u000fThree arm trial (A, B, neither) Two major advantages of factorial design (but not simultaneously): \u000fAllows investigation of interactions (drug synergy). Drug synergy occurs when drugs interact in ways that enhance effects or side-effects of those drugs. \u000fReduces the cost (sample size) if the drugs do not interact. 116Some requirements for conducting a clinical trial with factorial design: \u000fThe side effects of two drugs are not cumulative to make the combination unsafe to administer. \u000fThe treatments need to be administered in combination without changing dosage of the individual drugs. \u000fIt is ethical not to administer the individual drugs. A and B may be given in addition to a standard drug so all groups receive some treatment. \u000fWe need to be genuinely interested in studying drug combination , otherwise some treatment combinations are unnecessary. Some terminology \u000fFactors (how many different treatments are in consideration) \u000fLevels (2 if yes/no) \u000f2kfactorial studies have kfactors, each with two levels (presence/absence) \u000fFull factorial design has no empty cells. \u000fUnreplicated study has one sample per cell (obviously not very common in clinical studies) \u000fFractional factorial designs (some cells are left empty by design) \u000fComplete block designs / Incomplete block designs \u000fLatin squares 15.2 Notation and assumptions Treatment B Treatment A No Y es No\u0016 \u0016 + Y es\u0016+ \u0016 + + + With this formulation, is the effect of treatment A, is the effect of treatment B, and is the interaction effect. (If the effects of A and B are additive with no interaction, then = 0.) For a continuous outcome and large sample sizes (may be different for each group), we have the following for the observed sample cell 11715.3 Test for the interaction effect In a factorial design, we usually test the presence of interaction effect rst. H0: = 0 H1: 6= 0 The observed mean responses are: Treatment B Treatment A No Y es NoY0YB Y esYAYAB The interaction effect may be estimated by ^ = (\u0016YAB\u0000\u0016YB)\u0000(\u0016YA\u0000\u0016Y0); and Var(^ ) =4\u001b2 n: (Why is this known, then Z=^ 2\u001b=pn hasNormal (0;1)distribution under have to estimate \u001b2and assume within-group variances are equal, we 6= 0 The treatment A effect can be estimated as ^ =\u0016YA\u0000\u0016Y0; and its variance is Var(^ with df= 2(n\u00001)underH0. Constructing the test for is exactly the same. 15.4.2 = 0 If no interaction is present then = 0, and ~ =\u0016YAB\u0000\u0016YBcan also be used to estimate . If we use the average of ^ and~ to estimate , this estimator has a the test for is exactly the same. In order to have the same efciency in a two-arm trial (A vs placebo), we would need 2npatients in each treatment arm. var(^ 1) =2\u001b2 2n=\u001b2 n: So if we were to test A and B in two separate experiments we would need 2nper arm\u00024 arms (A and placebo, B and placebo), totaling 8nsubjects. Noticing we are repeating the placebo in these hypothetical experiments, we decide to use a 3-arm experiment with A, B, and placebo arms. Then we would require a total of 6nsubjects for the same precision. 15.5 Examples The group means are: Treatment B Treatment A No Y es No 10 40 Y es 30 60 If there is a synergistic effect, then \u001111>60. Treatment B Treatment A No Y es No 10 40 Y es 30 80 Treatment B Treatment A No Y es No 10 40 Y es 30 120 In the last situation, the treatment effects may be multiplicative. 120Treatment B Treatment A No Y es No log(10) = 1 log(40) = 1 :60 Y es log(30) = 1 :48 log(120) = 2 :08 Suppose the samples of size 20yield the following estimates of the cell means. Treatment B Treatment A No Y es No 9:83 40:05 Y es 28:94 59:76 Assuming no interaction, to estimate the drug A effect we compute either ^ 1=\u0016YA\u0000\u0016Y0= 28:94\u00009:83 = 19:11 or ~ 1=\u0016YAB\u0000\u0016YB= 59:76\u000040:05 their average (19:11 + 19:71)=2 = 19:41. How bad is it to estimate 1this way when there is actually a Example: the Physician's Health Study I (1989) Read all about it on http://phs.bwh.harvard.edu/ . The Physician's Health Study was a randomized clinical trial designed to test the following two theories: \u000fDaily low-dose aspirin use reduces the risk of cardiovascular disease. \u000fBeta carotene reduces the risk of cancer. Population hierarchy: \u000f261,248 US male MDs aged 40 to 84. \u000f112,528 responded to questionnaires. 121\u000f59,285 willing to participate. \u000f33,332 willing and eligible MDs enrolled in run-in (18 weeks of active aspirin and beta-carotene placebo). Run-in period Eligible patients are monitored for treatment compliance. \u000f22;071randomized Beta-carotene Aspirin Active Placebo Total stopped the aspirin arm several years ahead of schedule on 1988/1/25 because it was clear that aspirin had a signicant effect on the risk of a rst myocardial infarction. (It reduced the risk by 44%.) -Did it change the sample sizes for the Beta-carotene components? (Next homework?) \u000fThere were too few strokes or deaths to base sound clinical judgement regarding aspirin and stroke or mortality. \u000fThe beta-carotene arm terminated as scheduled on 1995/12/12 with the conclusion that 13 years of supplementation with beta-carotene produced neither benet nor harm. Beta- carotene alone was not responsible for the health benet seen among people who ate plenty of fruits and vegetables. \u000fOver 300 other ndings have emerged from the trial so far. 15.6 Treatment interactions Factorial designs are the only way to study treatment interactions. Recall the interaction term is estimated by ^ = (\u0016YAB\u0000\u0016YB)\u0000(\u0016YA\u0000\u0016Y0), and its variance is Var(^ ) = 4\u001b2=n. This variance is 2 times as large as that of AandBmain effects, and to have the same precision for an estimate of an interaction effect, the sample size has to be 4 times as large. This means, the two main advantages of the factorial designs (efciency and interaction objectives) cannot be satised simultaneously. When there is an ABinteraction, we cannot use the estimators, \u0014 and\u0014 , which are only valid with no interaction effect. In fact, we cannot talk about an overall main effect in the presence of an interaction. Instead, we can talk about the effect of Ain the absence of B, =\u0016YA\u0000\u0016Y0; 122or the effect of Ain the presence of B 0= + =\u0016YAB\u0000\u0016YB: Some additional notes \u000fIn the 2\u00022\u00022design ( 23design), there are 3 main effects and 4 interactions possible. The number of high order interactions will grow quickly with k, but oftentimes, they are (assumed to be) 0. \u000fA \"quantitative\" interaction does not affect the direction of the treatment effect. For example when treatment B is effective either with or without treatment A, but the magnitude of its effectiveness changes. \u000fWith a \"qualitative\" interaction, the effects of A are reversed with the presence of B. In this case, an overall treatment A effect does not make sense. \u000fThe factorial design can be analyzed with linear models (analysis of variance models). Limitations of factorial designs \u000fA higher level design can get complex quickly. \u000fTest for interaction requires a large sample size (or have a very low power if the study is powered for the main effects). \u000fCombination therapy may be considered as a treatment in its own right. Of further interest... \u000fPartial (fractional) factorial designs have missing cells by design (especially when higher order interactions are assumed to be zero) 123Chapter 16 Crossover design Crossover trials are those in which each patient is given more than one treatment, each at different times in the study, with the intent of estimating differences between them. In a simple 2\u00022design (or AB/BA design), patients are randomized to either \"A then B\" group or \"B then A\" group. Period Group I II AB Treatment A Treatment B BA Treatment B Treatment A2 Treatments / 2 Periods / 2 Sequences P1P2 S1A Bn1 S2B An2 P1P2P3P4 S1A B A B n1 S2B A n2 12416.1 Some characteristics of crossover design \u000fAll subjects receive more than one treatment (not simultaneously). \u000fEach subject acts as own control. Therefore, the treatment groups are comparable without relying on randomization. -Treatment periods (order of AandB) are often randomly assigned. -Baseline characteristics are identical with regard to many patient characteristics, but not with regard to their recent history of exposure to other potentially effective treatments. carryover effects -The comparability of the treatment groups is not guaranteed by the structure of the trial alone. The investigators need to estimate the carryover effects. \u000fCrossover designs are not used ... -with any condition that treatment could effect considerable change. -for acute illness. \u000fCrossover designs are most suitable for treatments intended for rapid relief of symptoms in chronic diseases, where the long-term condition of the patient remains fairly stable. Precision The primary strength of crossover trials is increased efciency. Suppose the treatment effects are Yt\u0018Normal (\u0016t;\u001b2); Yc\u0018Normal (\u0016c;\u001b2); and we are interested in \u0016t\u0000\u0016c. In a parallel design (with per group sample size of n), we have ^\u0001 =Yt\u0000Yc\u0018Normal\u0012 \u0016t\u0000\u0016c;2\u001b2 n\u0013 : With aTC=CT =2\u001b2 n(1\u0000\u001atc); where\u001atcis the treatments TandC. Therefore, a crossover design is more efcient than a parallel design given \u001atc>0. Recruitment Some patients may hesitate to participate in a clinical trial if there is a 50% probability of not receiving any effective treatment. With a crossover design, everyone is guaranteed to receive the test drug. On the other hand, the patients may hesitate to participate in a crossover trial because they will go through more than one treatment, especially when outcomes are assessed with diagnostic procedures such as X-ray, blood drawing, lengthy questionnaires. 125Carryover effects The biggest concern is the possibility that the treatment effect from one period might continue to be present during the following period. A sufciently long \"washout\" period between the treatments may prevent signicant carryover effects (but how long is sufciently long?). If there are baseline measurements that represent patient's disease status, this can be checked against their baseline levels. If the treatment effects a permanent change or cure in the underlying condition, the treatment given after could look articially superior. Dropouts In a crossover design, the trial duration tends to be longer than a comparable study using indepen- dent groups, which may cause more dropouts. Also because every patient take more than one treatment, dropouts due to severe side effects may also increase. The consequences of dropouts are more severe in crossover trial; a simple analysis cannot use only the data from the rst period. 16.2 Analysis of 2\u00022crossover design treatment to B. 2\u0001\u0001\u0001Carryover effect of treatment A 3\u0001\u0001\u0001Increment carryover effect of treatment B TreatmentBeffect is 0+ 1, and the carryover effect due to treatment Bis 2+ 3. The primary hypotheses to test are: H0: 1= 0 H1: 16= 0 And how to conduct this test (how to estimate 1) depends on whether 3= 0. (We'll see why later.) Step 0 : Assumptions 1. Sample is Test 0 Note that under H0: 3= 0, we have\u0016A1+\u0016B2=\u0016B1+\u0016A2. Thus, we can use Z1=(YB1+YA2)\u0000(YA1+YB2)q Var(YB1+YA2) +Var(YA1+YB2) to test these hypotheses (assuming \u001b2is known). Why is this good (convenient)? Because we don't have to worry about the correlations when computing Z1. Instead, we can compute the within-subject difference sum. Let's say !i1= yA1i+yB2iand!j2=yB1j+yA2j. Then we have Z1=!2\u0000!1p Var(!2) +Var(!1) If we don't assume \u001b2is known, is this bad? Step 2a (If 3= 0) We can estimate 1and test ifH0: 1= 0. Let's say\u000ei1=yB2i\u0000yA1iand\u000ej2=yA2j\u0000yB1j. Let's conrm that the following test statistic can be used to test this hypothesis. t2=\u000e1\u0000\u000e2p 2s\u000e=pn; 127wheres2 \u000e= (s2 \u000e1+s2 \u000e2)=2. What's the degree of freedom? We are interested in estimating 1. Note that ^ 1= (\u000e1\u0000\u000e2)=2. So a 95% condence interval s2 \u000e=(2n) Step test ifH0: 2= 0. Note that ^ 2= (\u000e1+\u000e2)=2andse(^ \u000e1+\u000e2 2\u0006t0:975;2(n\u00001)q s2 \u000e=(2n) But we are not that interested in estimating 2. Step 2c (If 3= 0) Maybe we want to estimate 0. We have two estimates of 0, and we can take the average of them to get see if 0= 0by testing H0:\u0016B1+\u0016A2=\u0016B2\u0000\u0016A1 H1:\u0016B1+\u0016A26=\u0016B2\u0000\u0016A1 Constructing the relevant ttest statistic is not as straightforward as the previous steps because we cannot assume the true variances of !2and\u000e1are equal. We can n; 128which follows a tdistribution approximately with estimated degrees of freedom given by the Satterthwaite formula. To estimate 0with a condence interval n rst (applying unequal-varince and divide it by 2. Step 2d (If 3= 0) Maybe we want to estimate 0+ 1. Again we can use the average of same process as in step 2c. Step 3 (If 3 6= 0) Because the carryover affects S1andS2differently, we cannot eliminate we did before. 1+^ 2 YB1\u0000YA2=^ 1\u0000^ 2\u0000^ 3 Taking the within-individual difference is not going to help, so we cannot take an advantage of the correlated endpoint. In this case, we ignore the data from the second period. ^ 1=YB1\u0000YA1 Var(^ 1) =2\u001b2 n Treat the study as a two sample test with sample size =nper group. Moreover, we can estimate the treatment effects with ^ 0=YA1 ^ 0+^ 1=YB1 12916.2.1 3 ^ 1=YB1\u0000YA1 Var(^ 1) =2\u001b2 ^ 0and ^ 0+^ 1are the same. Varf^ 3gis at least twice as large as Varf^ 2gfor\u001a\u00150. Therefore, any crossover trial designed to detect the differential treatment effects will have lower power for difference of the carryover effects, which is critical to detect the subsequent analysis and interpretation of the trial will be different. With the presence of a clinically important carryover effect difference, a crossover design is no more efcient than an independent-groups trial. A two-stage procedure may be used: the difference of carryover effects is tested rst with a type I error rate of 10\u001820% before moving on to the primary hypothesis testing of the treatment effects. Estimates will be different depending on the conclusion from the rst stage. 16.3 Examples Capecitabine/Erlotinib Followed of Gemcitabine Versus Gemcitabine/Erlotinib Followed of Capecitabine http://clinicaltrials.gov/ct2/show/NCT00440167 This crossover trial is performed in advanced and metastatic pancreatic cancer not previously exposed to chemotherapy. The study compares a standard arm with gemcitabine plus erlotinib to an experimental arm with capecitabine plus erlotinib. It is the rst trial of its kind to incorporate second-line treatment into the study design. Patient who fail on rst-line therapy are switched to the comparator chemotherapy without erlotinib. The trial therefore not only compares two different regimens of rst-line treatment, it also compares two sequential treatment strategies. Colchicine Double-Blind Controlled Disease http://clinicaltrials.gov/ct2/show/study/NCT00700297 Method: patients were randomized at the study entry to take either colchicine or placebo. At 4 months, they were crossed over. Those who were taking colchicine went on placebo and those on placebo went on colchicine. Each patient tried therefore, both colchicine and placebo. The primary outcome was the effect of colchicine on the disease activity index, the IBDDAM (16-17). To calculate the overall IBDDAM of the baseline, the IBDDAM of the last 12 months (prior to the study) of each manifestation was calculated and added together. The overall disease activity index was then divided to the number of months (12 months) to have the mean activity index per month. IBDDAM was then measured every 2 months (in the middle and at the end, in each arm of the study). The total IBDDAM of the 4 months was then divided by 4 to have the mean activity index per month. The secondary outcome was to see how the individual symptoms responded to colchicine (IBDDAM of each manifestation). Statistical analysis: The analysis was done by the intention to treat method. As the difference between IBDDAM before and after treatment had normal distribution Student T test for paired samples were used to evaluate the outcome in the colchicine and the placebo group. As the 131Levene's test showed the homogeneity of variance, ANOVA (one way) was used to test the effect of treatment (colchicine and placebo) and gender on patients' outcome. The dependent variable was the difference between IBDDAM (before and after the treatment). The independent variables were the treatment, and the gender. SPSS 15 was used for all statistical calculations. A Placebo-Controlled, Cross-Over Trial of Aripiprazole http://clinicaltrials.gov/ct2/show/record/NCT00351936 Primary endpoint: Evaluate the effects of aripiprazole on weight, Body Mass Index (BMI), and waist/hip circumference. This study is a ten-week, placebo-controlled, cross-over, randomized trial of the aripiprazole, added to 20 obese stable olanzapine-treated patients with schizophrenia or schizoaffective disorder. The advantage of the crossover design is that each subject will act as their own control and fewer subjects will be required. The double-blind, placebo-controlled, crossover study will consist of two random order 4-week treatment arms (aripiprazole 15 mg or placebo) separated by a 2-week adjuvant treatment washout. Following baseline, subjects will be randomized, double-blind, to either aripiprazole or placebo for 4 weeks. After the initial 4 weeks of medication patients will be reassessed, have a 2-week washout period and then crossover to the other treatment for another 4 weeks. Data management and statistical analysis will be provided by Dr. David Schoenfeld from the Massachusetts General Hospital, Biostatistics Center. 16.4 Examples 16.4.1 Cushny and Peebles Cushny Physiology .32: 501-510. \u000fClinical trial of the effect of 3 hypnotic drugs on duration of sleep -Study population: inmates of the Michigan Asylum for Insane -Patients were given an active treatment on each alternate evening. A typical treatment plan was: X C X C X C Y C Y C Y C Z C Z C Z C X Y Z X Y Z X Y Z, where 'C' is the control evening where no treatment was given. \u000fThese data were used in \"The probable error (1908) Biometrika .6(1): 1-25. 132sleep <- cbind(c(0.6, 3, 4.7, 5.5, 6.2, 3.2, 2.5, 2.8, 1.1, 2.9), c(1.3, 1.4, 4.5, 4.3, 6.1, 6.6, 6.2, 3.6, 1.1, 4.9), c(2.5, 3.8, 5.8, 5.6, 6.1, 7.6, 8, 4.4, 5.7, 6.3), c(2.1, 4.4, 4.7, 4.8, 6.7, 8.3, 8.2, 4.3, 5.8, Y Z 1 0.6 1.3 2.5 2.1 2 3.0 1.4 3.8 4.4 3 4.7 4.5 5.8 4.7 4 5.5 4.3 5.6 4.8 5 6.2 6.1 6.1 6.7 6 3.2 6.6 7.6 8.3 7 2.5 6.2 8.0 8.2 8 2.8 3.6 4.4 4.3 9 1.1 1.1 5.7 5.8 10 2.9 4.9 6.3 6.4 13302468Hours of sleep 12345678910Student's paper t 1, df = 9, p-value = 0.2 alternative hypothesis: true mean is not equal to 0 95 percent confidence interval: -0.53 2.03 sample estimates: mean t 4, df = 9, p-value = 0.005 alternative hypothesis: true mean is not equal to 0 13595 percent confidence interval: 0.898 3.762 sample estimates: mean of x 2.33 Remarks \u000fEthical issues? Potential risks of giving drugs to the mentally ill subjects. \u000fThe primary interest was to study differences between treatments; treatment sequences were of incidental interest. \u000fDrug X seems to have no effect, and Drugs Y and Z seem to have about the same positive influence in inducing sleep. \u000fSequences were not wisely chosen. \u000fPatients did not receive an equal number of treatments (missing data?) 16.4.2 Hills and Armitage Hills M, Armitage P \u000fChildren with enuresis were treated with a new drug or placebo for 14 days \u000fThe primary data are number of dry nights out of 14. An estimate of within-subject differences (treatment effects) is \u000e=YA\u0000YB. The carryover effects may be estimated by Z1=\u000e1\u0000\u000e2q var(\u000e1) +var(\u000e2); andZis approximately normally distributed under H0. Similarly the overall treatment effect can be estimated by Z2=\u000e1+\u000e2q var(\u000e1) +var(\u000e2); and this is approximately normal under H0. 136d0 <- c(8, 5, 12, 11, 14, 10, 8, 0, 6, 8, 9, 7, 11, 6, 13, 9, 3, 5, 8, 8, 6, 0, 8, 9, 0, 0, 4, 8, 8, 14, 13, 12, 2, 4, 10, 2, 7, 5, 8, 13, 13, 13, 8, 10, 9, 7, 7, 7, 9, 0, 7, 10, 10, 6, 2, 2, 7, 6) pat <- rep(1:29, each = 2) period <- rep(1:2, 29) placebo.first <- c(2, 5, 8, 10, 12, 14, 15, 17, 20, 23, 26, 29) group <- rep(1, 29) = pat, group = rep(group, each = 2), period = period, trt = c(t(trt)), dry = d0)) id group period trt dry 1 1 1 1 1 8 2 1 1 2 0 5 3 2 2 1 0 12 4 2 2 2 1 11 5 3 1 1 1 14 6 3 1 2 0 10 7 4 1 1 1 8 8 4 1 2 0 0 9 5 2 1 0 6 10 5 2 2 1 8 11 6 1 1 1 9 12 6 1 2 0 7 13 7 1 1 1 11 14 7 1 2 0 6 15 8 2 1 0 13 16 8 2 2 1 9 17 9 1 1 1 3 18 9 1 2 0 5 19 10 2 1 0 8 20 10 2 2 1 8 21 11 1 1 1 6 22 11 1 2 0 0 23 12 2 1 0 8 24 12 2 2 1 9 25 13 1 1 1 0 26 13 1 2 0 0 13727 14 2 1 0 4 28 14 2 2 1 8 29 15 2 1 0 8 30 15 2 2 1 14 31 16 1 1 1 13 32 16 1 2 0 12 33 17 2 1 0 2 34 17 2 2 1 4 35 18 1 1 1 10 36 18 1 2 0 2 37 19 1 1 1 7 38 19 1 2 0 5 39 20 2 1 0 8 40 20 2 2 1 13 41 21 1 1 1 13 42 21 1 2 0 13 43 22 1 1 1 8 44 22 1 2 0 10 45 23 2 1 0 9 46 23 2 2 1 7 47 24 1 1 1 7 48 24 1 2 0 7 49 25 1 1 1 9 50 25 1 2 0 0 51 26 2 1 0 7 52 26 2 2 1 10 53 27 1 1 1 10 54 27 1 2 0 6 55 28 1 1 1 2 56 28 1 2 0 2 57 29 2 1 0 7 58 29 2 2 1 6 # Group 1: trt -> two-period crossover design for the comparison of two active treatments and placebo By GG Koch, IA Amara, BW Brown, T Colton, and DB Gillings (1989). Consider sequences of treatments TT, TC, and CT. 1. The rst period is parallel group design to address direct use in all patients 2.The second period for TT versus TC is a parallel group comparison design to address T versus C for patients who received T during the rst period. 3.The second period for TT versus CT enables \"delayed start\" assessment of T relative to C if dropout during the rst period is minimal and non-informative. 4.The second period for CT versus TC is for assessment of T relative C if carryover effects are small. 5.If T\u0000C from 1, 2, 4 are similar (carryover effects of T to T, T to C, C to T are small), then an overall analysis of treatment effect differences have a very high power. 6. More patients are allocated to receive T within each period. P1 P2 S1=CT 0 effect to T. 2\u0001\u0001\u0001Carryover effect for C 3\u0001\u0001\u0001Increment of carryover effect for T could represent additional treatment effects for longer duration. Period 1 comparison between T and C is for primary treatment effects, and period 2 comparisons address effects of delayed start (CT vs. TT) and of long-duration effects. Now consider TT, TC, CT, and CC. 1. This design can estimate all the parameters in the TT, TC, CT case. 2. CC vs. CT enables estimation of treatment effects with run-in period. 3. Relatively unethical to have many patients assigned to receive C. P1 P2 S0=CC 0 0+ due to T. 2\u0001\u0001\u0001Carryover effect for C 3\u0001\u0001\u0001Carryover effect for T could represent additional treatment effects for longer duration. Example: Pincus T et al. (2004) \"Patient preference for placebo, acetaminophen (paracetamol) or celecoxib efcacy studies (PACES): two randomised, double blind, placebo controlled, crossover clinical trials in patients with knee or hip osteoarthritis\". Ann Rheum Dis .63: 931-939. 16.6 Latin squares When there are ktreatments and each patient is to receive all ktreatments. Then there are k! possible sequences. Three treatments yield 6sequences, four treatments yield 24, and ve yield 120. k= 3: ABC, ACB, BAC, BCA, CAB, CBA 140The idea is to use a reduced number of sequences (reduced sample size) but maintain a good \"representation\", i.e., every treatment is represented in every period with the same frequency. P1P2P3 S1A B C S2B C A S3C A BP1P2P3 S1A C B S2B A C S3C B A There are 6!=(3!)(3!) = 20 ways to choose 3 sequences from 6, but only 2 of those are Latin squares. 16.7 Optimal designs There is an extensive literature on optimal choice of sequences for measuring treatment effects in the presence of carryover. \u000fMore advanced theory \u0001\u0001\u0001 \u000fOptimality depends on assumptions about carryover effects Concerns about carryover can be reduced by using designs with more than two periods. (Laska E, Meisner M, Kushner HB. (1983) This design is not uniquely optimal, but it can be used to estimate treatment effects with more efciency than using data from period the period effect, is the treatment effect, and \u0015is the carryover effect. To obtain an unadjusted (for carryover effect) treatment effect ( B\u0000A), form a contrast B\u0000A. \u000fWeights When carryover effects are present, we can construct weights so that carryover effects will be eliminated. P1P2P3P4 AABB\u0000w1\u0000w2w3w4 BBAAw1w2\u0000w3\u0000w4 the number of patients per sequence. slightly higher but it is unbiased with presence of carryover. William's square When an even number of treatments are considered in the same number of periods, William's square gives an optimal design. (Williams EJ (1949). \"Experimental designs balanced for the estimation of residual effects of treatments\". Australian Journal of Scientic Research. Series A2 . 149-168.) It is a Latin square design in which every treatment precedes every other treatments exactly once. P1P2P3P4 sequence 1 A B C D sequence 2 B D A C sequence 3 C A D B sequence 4 D C B A Latin square designs are a special type of incomplete block design. Example : An experiment was conducted to study the effects of different types of background music on the productivity ( Y) of bank tellers. The treatments were dened as ve combinations of temp and style of music: A: slow, instrumental and vocal B: medium, instrumental and vocal C: fast, instrumental and vocal D: medium, instrumental only E: fast, instrumental only There are 120 possible sequences of these treatments. 143Chapter 17 Meta analysis 17.1 Introduction Meta analysis is a comprehensive re-analysis of published and unpublished studies, based on obtaining individual patient data or summary statistics, to investigate and quantify consistency or lack of consistency among study results. It is also referred to as \"overview\", \"systematic review\", and \"research synthesis\". Some characteristics of meta analysis \u000fThere is rich history in social sciences, relatively new to medical research. \u000fThe number of randomized clinical trials probably approaches 10,000 per year, so synthesizing results can be informative but difcult and confusing. \u000fWhen individual patient data are available, a meta analysis will be simpler. \u000fCochrane collaboration ( www.cochrane.org ). \u000fThe primary purpose of a meta analysis is analytic rather than descriptive (as opposed to experts' review of the eld). -Use formal statistically sound methods to combine treatment effects. (Do not plan an underpowered study just for a meta analysis.) -Statistical power of a meta analysis is usually very high, and reliable assessment of secondary endpoints may be possible. Basic steps 1. Formulation of a purpose (hypothesis) and specication of an outcome. 2. Identication of relevant studies. 3. Establishing inclusion/exclusion criteria of studies. 4. Data abstraction and acquisition. 1445. Data analysis. 6. Dissemination of results and conclusions 17.2 Literature search and publication bias MEDLINE, EMBASE, the Cochrane Controlled Trials Registry, and ClininicalTrials.gov are some of very useful databases. In all cases, well-dened terms such as Medical Subject Heading (MeSH) should be used. The published literature is not a complete repository of studies actually performed. Publication bias A selection bias in the published literature such that publication of research depends on the nature and direction of the study results. Studies that failed to show positive results are less likely to be published, and combining the information from published studies may be biased in the positive direction. 17.2.1 Funnel plot \u000fSample size tends to be associated with publication bias. -Small studies produce highly variable effect size estimates, and if every study is pub- lished, there should be an association between reported effect size and sample size. -A very large study without statistically signicant result may still be published, but a small non-signicant study may not be published. \u000fA funnel plot is one way to visually examine publication bias. The rst funnel plot shows the association between the effect sizes (observed correlation coef- cients) and sample sizes. 1450.2 0.0 0.2 0.4 0.6020406080100120 Correlation coefficientSample sizeFunnel plot 1The data are from a meta analysis of studies of student ratings of their instructor and average achievement (grades) of the students. \u000fIf no bias is present, this plot should be shaped like a funnel, with the spout pointing up. A broad spread of points for the highly variable small studies at the bottom and decreasing spread as the sample size increases. \u000fThe mean effect size should be the same regardless of sample size. One should be able to draw a vertical line through the mean effect size, and the points should be distributed on either side for all sample sizes. \u000fFor this particular example, the range of sample sizes is so narrow that the demonstration of a trend would be unlikely. 1460.6 0.4 0.2 0.0 0.2 0.4 0.6 Effect sizeStandard Error 0.400.350.300.250.200.150.100.050.00Funnel plot 2The second example is from a meta analysis of the effects of teacher expectancy on pupil IQ. \u000fThe standard error of the effect size is plotted against the effect size. \u000fLarge studies (i.e., small standard error) seem to be clustered around the null. \u000fSmall studies (i.e., large standard error) at the bottom are skewed toward a positive effect. \u000fA classic pattern of publication bias where small and/or negative studies are not published. 17.2.2 The le-drawer method Rosenthal R (1979), \"The 'le-drawer problem' and tolerance for null results\". Psychological Bulletin . 86. 638-641. Suppose a meta analysis results in a statistically signicant effect, using a test based on combining 147thezscores of the individual (published) studies. That is, the overall zscore, Z=kX i=1Zip k; is greater than z1\u0000 =2. The goal of the 'le-drawer' method is to determine the number of unpublished studies with an average observed effect of 0to make the zscore greater than z1\u0000 =2so that the test is no longer signicant. Ifk\u0003is sufciently large for the relevant research domain that it is unlikely that so many unpublished studies exist, then we can conclude that the signicance of the observed effects is unchallengeable. For the data shown in the second funnel plot, kX i=1Zip k=11:02p 19= 2:53 It is simple to solve for k\u0003to get k\u0003>13: So if there are at least 13unpublished studies with average effect size at the null value, then the apparent statistical signicance of the analysis would be reversed. While this method is simple to apply and to interpret, a disadvantage is that it relies on the assumption that the results of the missing studies are centered on the null hypothesis. 17.3 Study selection Once all relevant studies are identied, the researcher needs to establish eligibility criteria for including studies in their meta analysis. \u000fRelevant studies may have slightly different treatment regimen, various dose levels, various study populations. Oftentimes, studies with broader denition of \"treatment\" may be included in a meta analysis. 148\u000fthe Early Breast Cancer Trialists' Collaborative Group (EBCTCG) performed a large and important meta analysis looking at the benet of chemotherapy in breast cancer, and for some of their analysis, the chemotherapy combination did not have to be identical or given at the same dose. (EBCTCG (1990). \"Treatment of early breast cancer, vol I: Worldwide evidence 1985-1990\". Oxford University Press) \u000fSometimes it is reasonable to exclude studies employing a very small sample size or those with limited follow-up. 17.4 Statistical analysis Some of the primary issues in statistical analysis are \u000fChoosing an effect estimate. -Standardized mean differences -Risk ratios / hazard ratios -Correlations -p-values \u000fDeciding on the unit of analysis (trial or individual patient). \u000fQuality scoring of studies (the newer the better? Often subjective) \u000fSelecting statistical methods. 17.4.1 Summarizing the data using observed and expected The \"observed minus expected\" method can be based on statistics such as number of events, survival rates, or other clinical endpoints. Suppose that number of events is the primary outcome measure for studies comparing treatment versus control. For the i-th study, Oiis the random variable (number of successes in treatment) Niis the total sample size niis the sample size of the treatment group Kiis the total number of event of interest piis the overall event rate pi=Ki=Ni. For thei-th study Under the null assumption of no difference, the number of observed events in the treatment group, Oifollows a distribution Oi=x n i Control Ni\u0000ni Total KiNi\u0000KiNiResult Group Success Failure Total Treatment aibiai+bi Control cidici+di Total mi The expected value is E[Oi] =nipi; E =(ai+ci)(ai+bi) i=1Vi. statistic from M studies is ZMH= (O\u0000E)=p V; which has a standard normal distribution under H0(independence of columns and rows). 624 -8.5 29.9 2 129 847 185 878 -25.2 64.2 3 244 1620 77 406 -12.7 43.3 88 758 110 771 -10.2 43.1 7 39 317 49 309 -5.6 18.9 8 102 813 130 816 -13.8 49.8 9 38 365 57 362 -9.7 20.7 10 65 672 106 668 -20.8 37.3 11 9 40 19 40 -5.0 4.6 As an example, the rst row is computed follows: Cx mi ai + bi + ci + di EO <- (ai + ci) * (ai + bi)/mi ai - EO [1] -8.51 (VO <- (ai + ci) * (bi + di) * (ai + bi) * (ci + di)/mi^2/(mi - 1)) [1] 29.9 ZMH= (O\u0000E)=p V =\u0000160:30=23:70 =\u00006:80 The Peto-Yusuf method estimates the pooled odds ratio, ORp, as ORp= exp[(O\u0000E)=V]; and peto.yusuf.sd) [1] 0.692 0.817 In general, when we have Group Success Failure Treatment n11n12 Control n21n22 An estimate of log odds ratio with a continuity correction is ^\u0012= log ((n11+ orf + 0.5, nt + 1, xc + 0.5, nc + 1) # with continuity correction sdt <- sqrt(orv(xt + 0.5, nt + 1, xc + 0.5, nc + 1)) ## sd for log odds ratio Odds RatioObserved odds ratios n = 80n = 1340n 727n 1629n = 1725n = 123915417.4.2 Methods for summarizing signicance values kis the number of studies, and \u0003is the signicance level of the meta analysis. (p1;\u0001\u0001\u0001;pk) \u0016z=s\u0016z>tk\u00001( \u0003) Sum of logs \u0000P2 log(pi)> 2 2k( \u0003) (Fisher) Weighted sum of 155 "}