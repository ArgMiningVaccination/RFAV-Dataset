{"title": "PDF", "author": "PDF", "url": "https://www.beckershospitalreview.com/docs/iomdiagnosticerrors.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "Chasm Series Impro Erin P PREPUBL Ioving Committ B ICATION C ODiagn ee on Diag n Bryan T. M oard on H e Institu t OPY: UNCO R nosis i nostic Err o Miller, an d ealth Care te of Medi c RRECTED P Rin He a or in Healt d John R. B Services cine ROOFS alth C th Care Ball, Edito Care ors PREPUBLICATION COPY: UNCORRECTED PROOFS THE NATIONAL ACADEMIES PRE SS 500 Fifth Street, NW Washington, DC 20001 This activity was supported by Contr acts HHSH25034020T and 200-2011-38807, TO#20 between the National Academy of Sciences and Agency for Healthcare Research and Quality and Centers for Disease Control and Prevention respectively. Th is study was also supported by the American College of Radiology, American Society for C linical Pathology, Cau tious Patient Foundation, College of American Pathologis ts, The Doctors Company Foundation, Janet and Barry Lang, Kaiser Permanente National Community Benefit Fund at the East Bay Community Foundation, and Robert Wood Johnson Foundation. Any opinions, findings, conclusions, or recommendations expressed in this publication are those of the authors and do not necessarily reflect the views of the organizations or agencies that provid ed support for the project. International Standard Book Number 0-309-0XXXX-X Library of Congress Catalog Card Number 97-XXXXX Additional copies of this report are available for sale from the National Academies Press, 500 Fifth Street, NW, Keck 360, Washington, DC 20001; (800) 624-6242 or (202) 334-3313; http://www.nap.edu/. Copyright 2015 by the National Academy of Sciences. All rights reserved. Printed in the United States of America Cover credit: LeAnn Locher & Associates Suggested citation: National Academies of Sciences, Engineering, and Medicine. 2015. Improving diagnosis in health care. Washington, DC: The Na tional Academies Press. The Nati Presiden related t contribu t Nati National Member s Mote, Jr . The Nati 1970 un d and healmedicin e The threand Me d conduct Academi knowled g medicin e Learn m o www.na onal Acade t Lincoln, a s to science a n tions to res e onal Acade Academy o f s are electe d ., is preside onal Acade der the char th issues. M e and healt h e Academie icine to pr o other activi es also enc o ge, and inc r e. ore about t h tional-acad PREPUBL Imy of Scie n s a private, nd technolo earch. Dr. R a my of Engi n f Sciences t o d by their p e nt. my of Medi c ter of the N embers are h. Dr. Victor s work toge ovide indep e ties to solv e public he National A was es t nongovern m gy. Membe r alph J. Cic e neering was o bring the p eers for ext r cine (forme ational Aca d elected J. Dzau is p ther as the endent, obj e e complex p ation and r e understand Academies o OPY: UNCO R tablished in mental insti t rs are elect e erone is pre s establishe d practices of raordinary c rly the Insti t demy of Sci e their peers f president. National A c ective analy s roblems an d esearch, rec ing in matt e of Sciences, RRECTED P R1863 by an A tution to ad v ed by their p sident. d in 1964 un d engineerin g contribution s tute of Med ences to ad v for distingu i cademies o f sis and advi c d inform pu b cognize outs t ers of scien c Engineerin g ROOFS Act of Cong vise the nat i peers for ou t der the cha r g to advisin g s to engine e icine) was e vise the nat i ished contri f Sciences, E ce to the n a blic policy d tanding con ce, enginee r g, and Medi c ress, signed ion on issue s tstanding rter of the g the nation ering. Dr. C. established i ion on medi butions to Engineerin g ation and ecisions. T h tributions t o ring, and cine at by s . D. in cal g, he o V PREPUBLICATION COPY: UNCORRECTED PROOFS COMMITTEE ON DIAGNOSTIC ERROR IN HEALTH CARE JOHN R. BALL (Chair), Executive Vice President Emeritus, American College of Physicians ELISABETH BELMONT, Corporate Counsel , MaineHealth ROBERT A. BERENSON, Institute Fellow , The Urban Institute PASCALE CARAYON, Procter & Gamble Bascom Professor in Total Quality, Director, Center for Quality and Productivity Improvement, University of Wisconsin-Madison CHRISTINE K. CASSEL, President and Chief Executive Officer, National Quality Forum CAROLYN M. CLANCY , Chief Medical Officer, Veterans Health Administration, U.S. Department of Veterans Affairs MICHAEL B. COHEN, Medical Director, Anatomic Pathology and Oncology Division, ARUP Laboratories, Professor and Vice Chair for Faculty Development, Ombudsperson, Health Sciences Center, University of Utah School of Medicine PATRICK CROSKERRY, Professor of Emergency Medicine, Director, Critical Thinking Program, Dalhousie University Medical School, Dalhousie University THOMAS H. GALLAGHER, Professor and Associate Chair, Department of Medicine and Director, Hospital Medicine and Center for Scholarship in Patient Care Quality and Safety, University of Washington CHRISTINE A. GOESCHEL, Assistant Vice President, Quality, MedStar Health MARK L. GRABER, Senior Fellow, RTI International HEDVIG HRICAK, Chair, Department of Radiology, Me morial Sloan-Kettering Cancer Center ANUPAM B. JENA, Assistant Professor of Health Care Po licy and Medicine, Harvard Medical School ASHISH K. JHA, Professor of Health Policy and Manageme nt, Harvard School of Public Health MICHAEL LAPOSATA, Professor and Chair, Department of Pathology, University of Texas Medical Branch at Galveston KATHRYN M CDONALD, Executive Director and Senior Scholar, Center for Health Policy and Center for Primary Care and Outcomes Research, Stanford University ELIZABETH A. M CGLYNN, Director, Center for Effectiveness and Safety Research, Kaiser Permanente MICHELLE ROGERS, Associate Professor, Drexel University URMIMALA SARKAR, Associate Professor, University of California, San Francisco GEORGE E. THIBAULT, President, Josiah Macy Jr. Foundation JOHN B. WONG, Chief, Division of Clinical Decision Making, Tufts Medical Center Study Staff ERIN BALOGH, Study Director BRYAN MILLER, Research Associat e (from August 2014) SARAH NAYLOR, Research Associate (until August 2014) KATHRYN ELLETT, Research Associate (from April 2015 to July 2015) CELYNNE BALATBAT, Research Assistant (until June 2015) PATRICK ROSS, Research Assistant (from April 2015) LAURA ROSEMA, Christine Mirzayan Science and Technol ogy Policy Graduate Fellow (from January to April 2014) BEATRICE KALISCH, Nurse Scholar-in-Residence (until August 2014) PATRICK BURKE, Financial Associate ROGER HERDMAN, Director, Board on Health Care Services (until June 2014) SHARYL NASS, Director, Board on Health Care Services (from June 2014); Director, National Cancer Policy Forum VII PREPUBLICATION COPY: UNCORRECTED PROOFS REVIEWERS This report has been reviewed in draft form by individuals chosen for their diverse perspectives and technical expertise, in accordance with procedur es approved by the NRC's Report Review Committee. The purpose of this independent review is to prov ide candid and critical comments that will assist the institution in making its published report as sound as possible and to ensure that the report meets institutional standards for objectivity, evidence, a nd responsiveness to the study charge. The review comments and draft manuscript remain confidential to pr otect the integrity of the deliberative process. We wish to thank the following individuals for their review of this report: SUZANNE BAKKEN, Columbia University DONALD BERWICK, Institute for Healthcare Improvement PAUL CHANG, University of Chicago Hospitals JAMES J. CIMINO, University of Alabama at Birmingham SARA J. CZAJA, University of Miami Miller School of Medicine GURPREET DHALIWAL, University of California, San Francisco and San Francisco VA Medical Center TEJAL GANDHI, National Patient Safety Foundation HELEN HASKELL, Mothers Against Medical Error JOHN M. HICKNER, University of Illinois at Chicago MICHELLE MELLO, Stanford Law School JEFFREY MEYERS, University of Michigan MARGARET E. O'KANE, National Committee for Quality Assurance GORDON SCHIFF, Brigham and Women's Hospital and Harvard Medical School SUSAN SHERIDAN, Patient-Centered Outcomes Research Institute HARDEEP SINGH, Houston Veterans Affairs Health Se rvices Research Center for Innovations, Michael E. DeBakey Veterans Affairs Medical Center and Baylor College of Medicine BRIAN R. SMITH, Yale University School of Medicine LAURA ZWAAN, Erasmus Medical Center Although the reviewers listed above have provide d many constructive comments and suggestions, they were not asked to endorse the conclusions or re commendations nor did they see the final draft of the report before its release. The review of this report was overseen by BRADFORD H. GRAY , Editor Emeritus, The Milbank Quarterly, Senior Fellow, Urban Institute and KRISTINE GEBBIE , Flinders University School of Nursing and Midwifery Adel aide, South Australia. Appointed by the National Research Council and Institute of Medicine, they were responsible for making certain that an independent examination of this report was carried out in accordan ce with institutional procedures and that all review comments were carefully considered. Responsibility for the final content of this report rests entirely with the authoring committee and the institution. IX PREPUBLICATION COPY: UNCORRECTED PROOFS ACKNOWLEDGMENTS We thank the following individuals w ho spoke at the committee's meetings: Bibb Allen, American College of Radiology Leonard Berlin, Skokie Hospital, Rush Medical College, University of Illinois Barbara Brandt, National Center for Interprofessional Practi ce and Education, University of Minnesota David Classen, Pascal Metrics and University of Utah School of Medicine Gurpreet Dhaliwal, University of California, San Francisco and San Francisco VA Medical Center Paul Epner, Society to Improve Diagnosis in Medicine Tejal Gandhi, National Patient Safety Foundation Emmy Ganos, Robert Wood Johnson Foundation David Gross, College of American Pathologists Kerm Henriksen, Agency for Healthcare Research and Quality Devery Howerton, Centers for Disease Control and Prevention Heidi Julavits, Columbia University Allen Kachalia, Brigham and Women's Hospital, Harvard Medical School and Harvard School of Public Health Jerome Kassirer, Tufts University School of Medicine Steven Kroft, American Society for Clinical Pathology Michael Millenson , Cautious Patient Foundation Elizabeth Montgomery, Cautious Patient Foundation Jeffrey Myers, University of Michigan David E. Newman-Toker, Johns Hopkins University School of Medicine Harold Pincus, New York-Presbyterian Hospital, Colu mbia University, and RAND Corporation Donald Redelmeier, University of Toronto Eduardo Salas, University of Central Florida Nadine Sarter, University of Michigan Gordon Schiff, Brigham and Women's Hospital and Harvard Medical School Hardeep Singh, Houston Veterans Affairs Health Services Research Center for Innovations, Michael E. DeBakey Veterans Affairs Medical Ce nter and Baylor College of Medicine Stephen Teret, Johns Hopkins University Eric Thomas, University of Texas Houston Medical School Robert Trowbridge, Maine Medical Center and Tufts University School of Medicine David Troxel, The Doctors Company Foundation We would also like to thank a number of i ndividuals who submitted written input or provided public comments at the committee meetings that informed the committee's deliberations. These individuals included: Melissa Anselmo, OpenNotes Signall Ann Bisantz, University at Buffalo Dennis Boyle, COPIC John E. Brush, Jr., Eastern Virginia Medical School and Sentara Healthcare, Norfolk Virginia Olle ten Cate, University Medical Center Utrecht Tom Delbanco, OpenNotes Gerri Donohue, Physicians' Reciprocal Insurers Steven J. Durning, Uniformed Services University of the Health Sciences Gary Klein, MacroCognition X PREPUBLICATION COPY: UNCORRECTED PROOFS Alan Lembitz, COPIC George Lundberg, Medscape David L. Meyers, American College of Emergency Physicians Harold Miller, Center for Healthcare Quality and Payment Reform Geoff Norman, McMaster University Carolyn Oliver, Cautious Patient Foundation Alan Schwartz, University of Illinois, Chicago Dana Siegal, CRICO Frank Papa, University of North Texas Health Science Center P. Divya Parikh, PIAA W. Scott Richardson, GRU/UGA Medical Partnership Campus Meredith Rosenthal, Harvard School of Public Health Bill Thatcher, Cautious Patient Foundation Bill Thorwarth, American College of Radiology David Troxel, The Doctors Company Jan Walker, OpenNotes Saul Weiner, University of Illinois, Chicago, Jesse Brown VA Medical Center David Wennberg, Northern New England Accountable Care Collaborative Funding for the study was provided by the Agency for Healthcare Research and Quality, American College of Radiology, American Society for Clinical Pathology, Cautious Patient Foundation, Centers for Disease Control and Prevention, College of American Pathologists, The Doctors Company Foundation, Janet and Barry Lang, Kaiser Permanente National Community Benefit Fund at the East Bay Community Foundation, and Robert Wood Johnson Foundation. The committee appreciates the support extended by these sponsors for the development of this report. We would also like to thank the individuals w ho shared their experiences with diagnosis in the dissemination video: Sue, Jeff, and Carolyn. Finally, many within the National Academies of Sciences, Engineering, and Medicine were helpful to the study staff. We would like to tha nk Clyde Behney, Chelsea Frakes, Greta Gorman, Laurie Graig, Julie Nicole Joy, Ellen Kimmel, Ka tye Magee, Fariha Mahmud, Abbey Meltzer, Jonathan Phillips, and Jennifer Walsh. XI PREPUBLICATION COPY: UNCORRECTED PROOFS Preface Fifteen years ago, in its landmark report, To Err Is Human: Building a Safer Health System, the Institute of Medicine (IOM) dramatically e xposed the issue of patient safety in health care. Stating the obvious\u2014that human beings ma ke errors\u2014but highli ghting the theretofore rarely discussed fact that those of us in hea lth care also make errors , the report began a quiet revolution in the way in which health care organi zations address the safety and quality of care. This report, Improving Diagnosis in Health Care, is a follow-up to the earlier report and the most recent in the IOM's Quality Chasm Series. This report has three major themes. First, Improving Diagnosis in Health Care exposes a critical type of error in health care\u2014diagnostic error\u2014that has received relati vely little attention since the release of To Err Is Human. There are several reasons w hy diagnostic error has been underappreciated, even though the correct diagnosis is a critical aspect of hea lth care. The data on dia gnostic error are sparse, few reliable measures exist, and often the error is identified only in retrospect. Yet the best estimates indicate that all of us will likely e xperience a meaningful diagnostic error in our lifetime. Perhaps the most significant contribution of this report is to hi ghlight the importance of the issue and to direct discussi on among patients and health care professionals and organizations on what should be done about this complex challenge. Second, patients are central to the solution. The report defines diagnostic error from the patient's viewpoint as \"the failure to (a) es tablish an accurate and timely explanation of the patient's health problem(s) or (b) comm unicate that explanation to the patient. \" The report's first goal centers on the need to establish partnerships with patients and their families to improve diagnosis, and several recommendations aim to facilitate and enhance such partnerships. Third, diagnosis is a collaborative effo rt. The stereotype of a single physician contemplating a patient case and discerning a diagnosis is not alwa ys true; the diagnostic process often involves intra- and interp rofessional teamwork. Nor is di agnostic error always due to human error; often, it occurs because of errors in the health care system. The complexity of health and disease and the increasing complex ity of health care demands collaboration and teamwork among and between health care profe ssionals, as well as with patients and their families. In addition to these major themes, the report highlights several key i ssues that must be addressed if diagnostic erro rs are to be reduced: Health care professional educat ion and training does not take fully into account advances in the learning sciences. The report emphasizes training in c linical reasoning, teamwork, and communication. Health information technology, while potentially a boon to quality health care, is often a barrier to effective clinic al care in its current fo rm. The report makes several recommendations to improve the utility of health information technology in the diagnostic process specifically and the clinical process more generally. XII PREPUBLICATION COPY: UNCORRECTED PROOFS There are few data on diagnostic error. The re port recommends, in addition to specified research, the development of approaches to monitor the diagnostic process and to identify, learn from, and reduce diagnostic error. The health care work system and culture do not sufficiently support the diagnostic process. Echoing previous IOM work, the repo rt also recommends the development of an organizational culture that values open discussion and feedback on diagnostic performance. In addition, the report highli ghts the increasingly important role of radiologists and pathologists as integral memb ers of the dia gnostic team. There were also areas where the committee th at developed the report wished we could go further but found that there are insufficient da ta currently to support strong recommendations. One of those areas is the paymen t system, now evolving from fee- for-service to more value- and population-based. Research on the effects of nove l payment systems on diagnosis is sorely needed. Another area is that of medical liab ility. The report recommends the adoption of communication and resolution programs as a key le ver to improve the disclosure of diagnostic errors to patients and to facilitate improved organizational lear ning from these events. However, other approaches for the resolution of medical injuries, such as sa fe harbors for the adherence to clinical guidelines and administ rative health courts, hold promise. More needs to be known of their effect on the diagnostic process, and the report recommends demonstration projects to expand the knowledge base in these areas. A final area of potential cont roversy is the measurement of diagnostic errors for public reporting and accountability purposes. The committee believed that, given the lack of an agreement on what constitutes a diagnostic error, th e paucity of hard data, and the lack of valid measurement approaches, the time was simply not ripe to call for mandato ry reporting. Instead, it is appropriate at this time to leverage the intrinsic motivation of health care professionals to improve diagnostic performance and to treat di agnostic error as a key component of quality improvement efforts by health care organiza tions. Better identific ation, analysis, and implementation of approaches to improve dia gnosis and reduce diagnos tic error are needed throughout all sett ings of care. As chair of the committee, I thank all the members of the committee for their individual and group contributions. I am grateful for the time, energy, and diligence, as well as the diversity of experience and expertise, they all brought to the process. When a diverse group of good people with good intent come together for a co mmon purpose, the process is richer and more enjoyable, and the product more likely to be worthwhile. None of the work of the committee would have been possible without the professional IO M staff, led by the study director, Erin Balogh. Both personally and on behalf of the committee, I thank them for a truly collaborative, incredibly responsive, and productive process. John R. Ball Chair Committee on Diagnostic Error in Health Care XIII PREPUBLICATION COPY: UNCORRECTED PROOFS CONTENTS ACRONYMS xix SUMMARY S-1 1 INTRODUCTION Context of the Study, 1-3 Origin of Task and Committee Charge, 1-3 Methods of the Study, 1-4 Conceptual Model, 1-5 Examples of Diagnosis and Diagnostic Error, 1-5 Organization of the Report, 1-7 References, 1-7 1-1 2 THE DIAGNOSTIC PROCESS Overview of the Diagnostic Process, 2-1 Important Considerations in the Diagnostic Process, 2-14 Clinical Reasoning and Diagnosis, 2-18 The Diagnostic Evidence Base and Clinical Practice, 2-30 References, 2-32 2-1 3 OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE Definition of Diagnostic Error, 3-1 Overutilization in the Diagnosti c Process and Overdiagnosis, 3-9 Measurement and Assessment of Diagnostic Error, 3-11 References, 3-43 3-1 4 DIAGNOSTIC TEAM MEMBER S & TASKS: IMPROVING PATIENT ENGAGEMENT AND HEALTH CARE PROFESSIONAL EDUCATION AND TRAINING IN DIAGNOSIS The Diagnostic Process as a Team Endeavor, 4-2 Patient Engagement in Diagnosis, 4-13 Health Care Professional E ducation and Training, 4-26 Recommendations, 4-41 References, 4-42 4-1 5 TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS Design of Health IT for th e Diagnostic Process, 5-4 Interoperability of Health IT, 5-18 5-1 XIV PREPUBLICATION PROOFS Safety of Health in Diagnosis, 5-21 Other Diagnostic Technologies, 5-24 Recommendation, 5-28 References, 5-28 6 ORGANIZATIONAL CHAR ACTERISTICS, THE PHYSICAL ENVIRONMENT, AND THE DIAGNOSTIC PROCESS: IMPROVING LEARNING, CULTURE, AND THE WORK SYSTEM Organizational Learning to Improve Diagnosis, 6-2 Organizational Characteri stics for Learning and Improved Diagnosis, 6-13 A Supportive Work System to Facilitate Diagnosis, 6-19 Recommendations, 6-23 References, 6-24 6-1 7 THE EXTERNAL ENVIRONM ENT INFLUENCING DIAGNOSIS: REPORTING, MEDICAL LIABILITY, AND PAYMENT Reporting and Learning From Diagnostic Errors, 7-2 Medical Liability, 7-6 Risk Management, 7-14 Payment and Care Delivery, 7-15 Recommendations, 7-22 References, 7-23 7-1 8 A RESEARCH AGENDA FOR THE DIAGNOSTIC PROCESS AND DIAGNOSTIC ERROR A Federal Research Agenda, 8-1 Public-Private Collaboration on Research, 8-3 Recommendation, 8-7 References, 8-7 8-1 9 THE PATH TO IMPROVE DIAG NOSIS AND REDUCE DIAGNOSTIC ERROR Overarching Conclusions, 9-1 Recommendations, 9-3 References, 9-27 9-1 Appendixes A Glossary, A-1 B Committee Members and Staff Biographies, B-1 C Previous Diagnostic Error Frameworks, C-1 D Examples of Diagnostic Error, D-1 XV PREPUBLICATION COPY: UNCORRECTED PROOFS BOXES, FIGURES, AND TABLES BOXES S-1 Goals for Improving Diagnosis and Reducing Diagnostic Error, S-6 1-1 Charge to the Committee on Dia gnostic Error in Health Care, 1-4 1-2 Patient and Family Expe riences with Diagnosis, The Work System, 2-4 Laboratory Medicine, Anatomic and Medical Imaging, 2-8 2-3 Molecular Diagnostics, 2-10 2-4 Models of Clinical Reasoning, 2-19 2-5 Individual Characteristics that Influence Clinical Reasoning, 2-26 2-6 Examples of Probabilis tic (Bayesian) Reasoning, 2-29 3-1 Types of Errors Described in To Err is Human: Building a Safer Health System , 3-2 3-2 Overutilization of Diagnostic Team-Based Health Care, 4-3 4-2 Suggested Actions for Nurses to Improve Diagnosis and Reduce Diagnostic Error, 4-10 4-3 Challenges to Effective Patient and Family Engagement in the Diagnostic Process, 4-14 4-4 Checklist for Getting the Right Diagnosis, 4-19 4-5 Smart Partners About Your Health, 4-20 4-6 Attributes of Health Literate Health Care Organizations, 4-24 4-7 The Learning Sciences, 4-27 4-8 Situation-Background-Assessment-Recomm endation Tool to Improve Communication Among Health Care Professionals, 4-34 4-9 Examples of Accreditation Organizations for Health Care Professional Education and Training Programs, 4-39 4-10 Six Core Competencies Developed by the American Board of Medical Specialties and the Accreditation Council for Gradua te Medical Education, 4-39 5-1 Recommendations from Health IT and Patient Safety: Building a Safer Health System , 5-2 5-2 American Medical Association's Improving Ca re: Priorities to Improve Electronic Health Record Usability, 5-7 5-3 Categories Describing Diffe rent Steps in Diagnosis Targeted by Diagnostic Health Information Technology Tools, 5-14 5-4 A Case of Diagnostic Error: Delaye d Diagnosis of Ebola Virus Infection, 5-17 5-5 Recommendations from an American Me dical Informatics Association Special Task Force on Health Information Technology Contracts, 5-22 6-1 Characteristics of a Continuously Learning Health Care Organization, 6-3 6-2 Characteristics of Effective Feedback Interventions, 6-11 6-3 Important Cultural Values for Continuous ly Learning Health Care Systems, 6-16 XVI PREPUBLICATION COPY: UNCORRECTED PROOFS High-Value Health Care, 6-18 7-1 Description of Alternative Approach es to the Medical Liability System, 7-8 7-2 Payment and Care Delivery Reforms and Their Potential Impact on Diagnosis, 7-19 8-1 Potential Areas of Research, 8-5 9-1 Goals for Improving Diagnosis and Reducing Diagnostic Error, 9-3 TABLES 2-1 Examples of Entities Involved in Qualit y Improvement and Oversight of Clinical and Anatomic Laboratories, 2-11 2-2 Heuristics and Biases that Influence Decision Making, 2-21 3-1 Methods for Estimating the Incidence of Diagnostic Errors, 3-15 3-2 Methods for Detecting Failures Across the Diagnostic Process, 3-33 3-3 Methods for Assessing the Effect of th e Work System on Diagnostic Errors, 3-36 5-1 Opportunities to Reduce Diagnostic Error through Electronic Clin ical Documentation, 5-4 FIGURES S-1 The diagnostic process, S-3 S-2 The work system in which the diagnostic process takes place, S-4 S-3 The outcomes from the diagnostic process, S-5 2-1 The committee's conceptualizati on of the diagnostic process, 2-3 2-2 The dual process model of diagnostic decision making, 2-23 2-3 Calibration in the di agnostic process, 2-25 2-4 Number of journal articles published on h ealth care topics per year from 1970 to 2010, 2- 30 3-1 Outcomes from the diagnostic process, 3-8 3-2 Places in the diagnostic process where fa ilures can occur that contribute to diagnostic errors, 3-31 4-1 This chapter addresses two elements of th e work system in which the diagnostic process occurs: diagnostic team members and the tasks they perform, 4-1 4-2 Teamwork in the diagnostic process in cludes the collaboration of patients and their family members, diagnosticians, and health care professionals who support the diagnostic process, 4-6 4-3 An example of diagnostic teamwork and the potential participan ts in the diagnostic process, 4-8 XVII PREPUBLICATION COPY: UNCORRECTED PROOFS 5-1 Technologies and tools are one important element of the work system in which the diagnostic process occurs, 5-1 6-1 Organizational characteristi cs and the physical environment are two elements of the work system in which the diagnostic process occurs, 6-2 7-1 The diagnostic process is influen ced by the external environment, 7-2 7-2 Rates of use of medical imaging services and diagnostic testing co mpared with rates of other clinician-ordered services, ACRONYMS AAFP American Academy of Family Physicians ABMS American Board of Medical Specialties ACGME Accreditation Council fo r Graduate Medical Education ACO accountable care organization ACR American College of Radiology AHRQ Agency for Healthcare Research and Quality AMA American Medical Association ANTS Anesthetists' Non-Technical Skills AOA American Osteopathic Association APN advanced practice nurse ASCP American Society for Clinical Pathology CAD computer-aided detection CAP College of American Pathologists CBE competency-based evaluation CCNE Commission on Collegiate Nursing Education CDC Centers for Disease Control and Prevention CDS clinical decision support CEO chief executive officer CLIA Clinical Laboratory Improvement Amendments CLIAC Clinical Laboratory Improvement Advisory Committee CMS Centers for Medicare & Medicaid Services CPG clinical practice guideline CPT current procedural terminology CRP communication and resolution program CT computed tomography DMT diagnostic management team DOD Department of Defense DRG diagnosis-related group DSM Diagnostic and Statistical Manual of Mental Disorders E&M evaluation and management ED emergency department EHR electronic health record EKG electrocardiogram FDA Food and Drug Administration FFS fee-for-service FMEA failure mode and effect analysis HFAP Healthcare Facil ities Accreditation Program HHS Department of Health and Human Services XX PREPUBLICATION COPY: UNCORRECTED PROOFS HIMSS Healthcare Information Management Systems Society HIV human immunodeficiency virus HRO high reliability organization ICD International Classification of Disease ICU intensive care unit IOM Institute of Medicine IPU integrated practice unit IT information technology IVD in vitro diagnostic test LCME Liaison Committee on Medical Education LDT laboratory developed test LOINC Logical Observation Identifiers Names and Codes MCAT Medical College Aptitude Test MI myocardial infarction MIPPA Medicare Improvements for Patients and Providers Act MOC maintenance of certification MQSA Mammography Quality Standards Act MRI magnetic resonance imaging NCQA National Committee for Quality Assurance NDC National Drug Code NIH National Institutes of Health NLM National Library of Medicine NLNAC National League for Nu rsing Accrediting Commission NPDB National Practitioner Data Bank NPSD Network of Pa tient Safety Databases ONC Office of the National Coordi nator for Health Information Technology PA physician assistant PCMH patient-centered medical home PCORI Patient-Centered Outcomes Research Institute PET positron emission tomography PRI Physician Reciprocal Insurers PSO patient safety organization PSO PPC PSO Privacy Protection Center PSQIA Patient Safety and Quality Improvement Act PT proficiency testing RSNA Radiological So ciety of North America XXI PREPUBLICATION COPY: UNCORRECTED PROOFS TeamSTEPPS Team Strategies and Tools to Enhance Performance and Patient Safety VA Department of Veterans Affairs S-1 PREPUBLICATION COPY: UNCORRRECTED PROOFS Summary The delivery of health care has proceeded for decades with a blind spot: Diagnostic er- rors\u2014inaccurate or delayed diagnoses\u2014persist th roughout all settings of care and continue to harm an unacceptable number of patients. For example: A conservative estimate found that 5 percent of U.S. adults who seek outpatient care each year experience a diagnostic error. Postmortem examination research spanning decades has shown that diagnostic errors contribute to approximately 10 percent of patient deaths. Medical record reviews suggest that diagnostic errors account for 6 to 17 percent of hos- pital adverse events. Diagnostic errors are the leading type of paid medical malpractice claims, are almost twice as likely to have resulted in the patient 's death compared to other claims, and repre- sent the highest proport ion of total payments. In reviewing the evidence, the committee conclude d that most people will experience at least one diagnostic error in th eir lifetime, sometimes with devast ating consequences. Despite the per- vasiveness of diagnostic errors and the risk for serious patient harm, dia gnostic errors have been largely unappreciated within the quality and patie nt safety movements in health care. Without a dedicated focus on improving diagnosis, these errors will likely worsen as the delivery of health care and the diagnostic process conti nue to increase in complexity. Getting the right diagnosis is a key aspect of health care\u2014it provides an explanation of a patient's health problem and informs subsequent health care decisions. Diagnostic errors stem from a wide variety of causes, including: inadequate collaborati on and communication among clinicians, patients, and their families;1 a health care work system that is not well designed to support the diagnostic process; lim ited feedback to clinicians about diagnostic performance; and a culture that discourage s transparency and disclosure of diagnostic errors\u2014impeding attempts to learn from these events and improve diagnosis . Diagnostic errors may result in different out- comes, and as evidence accrues, these outcomes will be better characterized. For example, if there is a diagnostic error, a pa tient may or may not experience harm. Errors can be harmful be- cause they can prevent or delay appropriate treatment, lead to unnecessary or harmful treatment, or result in psychological or fina ncial repercussions. Harm may not result, for example, if a pa- tient's symptoms resolve even with an incorrect diagnosis. Improving the diagnostic process is not only possible, but it al so represents a moral, pro- fessional, and public health imperative. Achiev ing that goal will require a significant re- envisioning of the diagnostic process and a wi despread commitment to change among health care professionals, health care organizations, patients and their families, researchers, and policy makers. 1The term family is used for simplicity, but the term is meant to encompass all individuals who provide support or informal caregiving to patients in the diagnostic process. S-2 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRRECTED PROOFS DEFINITION AND CONCEPTUAL MODEL The committee concluded that a sole focus on diagnostic error reduction will not achieve the extensive change necessary; a broader focus on improving diagnosis is warranted. To provide a framework for this dual focus, the committee developed a conceptual model to articulate the diagnostic process (Figure S-1), de scribe work system factors that influence this process (Figure S-2), and identify opportunities to improve the diagnostic process and outcomes (Figure S-3). The diagnostic process is a complex and collaborative activity that unfolds over time and occurs within the context of a h ealth care work system. The diagnosti c process is iterative, and as information gathering continues, the goal is to reduce diagnostic uncer tainty, narrow down the diagnostic possibilities, and deve lop a more precise and complete understanding of a patient's health problem. The committee sought to develop a definition of diagnostic error that reflects the iterative and complex nature of the diagnos tic process, as well as the need for a diagnosis to convey more than simply a label of a disease. The term \"health problem\" is used in the definition, because it is a patient-centered and inclusive term to describe a patient's overall health condition. The com- mittee's definition of diagnostic error is the failure to (a) establish an accurate and timely ex- planation of the patient's health problem(s) or (b) communicate that explanation to the pa- tient. The definition employs a patient-centered perspective because patients bear the ultimate risk of harm from diagnostic e rrors. Timeliness means that the diagnosis was not meaningfully delayed; however, timeliness is context-dependent . While some diagnoses may take days, weeks, or even months to establish, timely may mean qu ite quickly (minutes to hours) for other urgent diagnoses. A diagnosis is not accu rate if it differs from the true condition a patient has (or does not have) or if it is imprecise and incomplete. The inclusion of communication is distinct from previous definitions, in recogni tion that communicati on is a key responsib ility throughout the diagnostic process. From a patient's perspective, an accurate and timely explanation of the health problem is meaningless unless this information r eaches the patient so that a patient and health care professionals can act on the explanation. 2 In addition to defining and identifying diagnostic errors in clinical practice, the report places a broader emphasis on improving the diagnostic process. Analyzing failures in the diag- nostic process can provide important opportunities for learning and continued improvement. Some failures in the diagnostic process will lead to diagnostic errors; however, other failures in the diagnostic process will not ul timately lead to a diagnostic erro r, because subsequent steps in the process compensate for the initial failure. In this report, the committee describes \"failures in the diagnostic process that do not lead to diagnostic errors\" as near misses. A related but distinct concept to diagnostic error is overdiag nosis, defined as when a con- dition is diagnosed that is unlikely to affect the individual's health a nd well-being. While overdi- agnosis represents a true challenge to health care quality, it is not a diagnostic error. Overdiagno- sis is only detectable in populat ion-based analyses\u2014it is virtually impossible to assess whether overdiagnosis has occurred for an individual pa tient. However, improving the diagnostic pro- cess\u2014such as reducing unnecessary diagnostic testing\u2014may help avert overdiagnosis. 2 Because not all patients will be able to participate in the communication pro cess, in some instances communication would be between the health care professionals and a patient's family or designated health care proxy. SUMM FIGU MMARY URE S-1 The d S-2 The w PREPUBL Iork system i ICATION CO Pin which the IM PY: UNCOR R diagnostic p MPROVING D RRECTED P Rprocess tak e DIAGNOSIS I PROOFS es place. IN HEALTH C CARE SUMM FIGU MMARY URE S-3 The o u utcomes from t h PREP Uhe diagnostic p r UBLICATION RECTED PROO HEALTH CARE PREPUBLICATION COPY: UNCORRRECTED PROOFS RECOMMENDATIONS The committee's recommendations address eigh t goals to improve diagnosis and reduce diagnostic error (see Box S-1). These recommenda tions apply to all diagnostic team members and settings of care. Given the early state of the field, the evid ence base for some of the recom- mendations stems from the broader patient safety and quality improvement literature. Patients and patient advocates have much to offer on how to implement the committee's recommenda- tions; leveraging the expertise, power, and influe nce of the patient community will help spur progress. BOX S-1 Goals for Improving Diagnosis and Reducing Diagnostic Error Facilitate more effective teamwork in the diagnostic process among health care profes- sionals, patients, and their families Enhance health care professional education and training in the diagnostic process Ensure that health information technologies support patients and health care profession- als in the diagnostic process Develop and deploy approaches to identify, learn from, and reduce diagnostic errors and near misses in clinical practice Establish a work system and culture that supports the diagnostic process and improve- ments in diagnostic performance Develop a reporting environment and medical lia bility system that facilitates improved diagnosis through learning from diagnostic errors and near misses Design a payment and care delivery environment that supports the diagnostic process Provide dedicated funding for research on the diagnostic process and diagnostic errors Facilitate More Effective Teamwork in the Diagnostic Process among Health Care Professionals, Patients, and their Families The diagnostic process requires collaboration among health ca re professionals, patients, and their families. Patients and their families are cr itical partners in the diagnostic process; they contribute valuable input that facilitates the di agnostic process and ensures shared decision mak- ing about the path of care. Health care professionals and organizations3 are responsible for creat- ing environments in which patients and their fa milies can learn about and engage in the diagnos- tic process and provide feedback about their expe riences. One strategy is to promote the use of health information technology (hea lth IT) tools that make a patie nt's health information more accessible to patients. Involving patients and their fa milies in efforts to improve diagnosis is also 3 The term health care organization is used for simplicity, but is meant to encompass all settings in which the diag- nostic process takes place, including integr ated care delivery settings, hospitals, clinician practices, retail clinics, and long term care settings. SUMMARY S-7 PREPUBLICATION COPY: UNCORRRECTED PROOFS critical, because they have unique insights into the diagnostic process and the occurrence of di- agnostic errors. The diagnostic process hinges on successful intra- and interpro fessional collaboration among health care professionals, including primary ca re clinicians, physicians in various special- ties, nurses, pharmacists, technolog ists, therapists, social workers, patient navigators, and many others. Thus, all health care professionals need to be well prepared and supported to engage in diagnostic teamwork. The roles of some health car e professionals who par ticipate in the diagnos- tic process have been insufficiently recognized. Th e fields of pathology and radiology are critical to diagnosis, but professionals in these fields are not always engaged as full members of the di- agnostic team. Enhanced collaboration among pathol ogists, radiologists, other diagnosticians, and treating health care professionals4 has the potential to im prove diagnostic testing.5 In addi- tion, nurses are often not recognized as collaborators in the diagnosti c process, despite their criti- cal roles in ensuring communication, care coordination, and patient education; monitoring a pa- tient's condition; and identifying and pr eventing potential di agnostic errors. Goal 1: Facilitate more effective teamwork in the diagnostic proc ess among health care professionals, patients, and their families Recommendation 1a: In recognition that the di agnostic process is a dynamic team-based activity, health care organizations should ensure that health care professionals have the appropriate knowledge, skills, resources, and support to engage in teamwork in the diag- nostic process. To accomplish this, they should facilitate and support: Interprofessional and intra-professional teamwork in the diagnostic process. Collaboration among pathologists, radiologists, other diagnosticians, and treating health care professionals to improv e diagnostic testing processes. Recommendation 1b: Health care professionals and organizations should partner with pa- tients and their families as diagnostic team members and facilitate patient and family en-gagement in the diagnostic process, aligned with their needs, values, and preferences. To accomplish this, they should: Provide patients with opportunities to learn about the diagnostic process. Create environments in which patients and their families are comfortable engaging in the diagnostic process and sharing feedba ck and concerns about diagnostic errors and near misses. Ensure patient access to electronic health records (EHRs), including clinical notes and diagnostic testing results, to facilitate patient engagement in the diagnostic pro- cess and patient review of health records for accuracy. Identify opportunities to include patients a nd their families in ef forts to improve the diagnostic process by learning from diagnostic errors and near misses. 4 Treating health care professionals are clinic ians who directly interact with patients. 5 The term diagnostic testing is broadly inclusive of all types of testing, including medical imaging, anatomic pa- thology and laboratory medicine, as well as other types of testing, such as mental health assessments, vision and hearing testing, and neurocognitive testing. S-8 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRRECTED PROOFS Enhance Health Care Professional E ducation and Training that Supports Diagnosis Getting the right diagnosis depends on all hea lth care professionals involved in the diag- nostic process receiving appropr iate education and training. Th e learning sciences, which study how people learn, can be used to improve educ ation and training. For example, feedback\u2014or information about the accuracy of a clinician's diagnosis\u2014is e ssential for improved diagnostic performance. The authenticity of the learning environment can a ffect the acquisition of diagnos- tic skills; better alignment of training environments with clinic al practice promotes development of diagnostic skills. Opportunities to improve education and traini ng in the diagnostic process include: greater emphasis on teamwork and communication with patie nts, their families, and other health care professionals; appropriate use of diagnostic testing and the applica tion of test results to subse- quent decision making; and the use of health IT . In addition, the lack of focus on developing clinical reasoning and understand ing the cognitive contributions to decision making represents a major gap in education within all health care prof essions. Proposed strategies to improve clinical reasoning include instruction and practice on generating and refining a differential diagnosis, generating illness scripts, devel oping an appreciation of how diagnostic errors occur and strate- gies to mitigate them, and engaging in metacognition and debiasing strategies. Oversight processes play a cri tical role in promoting competency in the diagnostic pro- cess. Many accreditation organizations already requi re skills important for diagnostic perfor- mance, but diagnostic competencies need to be a larger priority within these requirements. Or- ganizations responsible for licensu re and certification can also he lp ensure that health care professionals have achieved and maintain compet ency in the skills essential for the diagnostic process. Goal 2: Enhance health care professional educ ation and training in the diagnostic process Recommendation 2a: Educators should ensure th at curricula and training programs across the career trajectory: Address performance in the diagnostic proces s, including areas such as clinical rea- soning, teamwork, communication with pati ents, their families, and other health care professionals, appropriate use of diagn ostic tests and the application of these results on subsequent decision making, and use of health IT. Employ educational approaches that are al igned with evidence from the learning sciences. Recommendation 2b: Health care professional certification and accreditation organizations should ensure that health care professionals have and maintain the competencies needed for effective performance in the diagnostic process, including the areas listed above. SUMMARY S-9 PREPUBLICATION COPY: UNCORRRECTED PROOFS Ensure that Health Information Techno logies Support Patients and Health Care Professionals the Diagnostic Process Health IT has the potential to improve diagnosis and reduce diagnostic errors by facilitat- ing timely and easy access to information; co mmunication among health care professionals, pa- tients, and their families; clinical reasoning; and feedback and follow-up in the diagnostic pro- cess. However, many experts are concerned that hea lth IT currently is not effectively facilitating the diagnostic process and may even be contributing to diagno stic errors. Challenges include problems with usability, poor integration into cl inical workflow, difficulty sharing a patient's health information, and a limited ability to support clinical reasoning and id entification of diag- nostic errors in clinical practice. Better alignment of health IT with the diagnostic process is war- ranted. Because the diagnostic process occurs over ti me and can involve multiple health care professionals across different care settings, the free flow of inform ation is critical. Improved in- teroperability across health ca re organizations and across labo ratory and radiology information systems is needed to achieve this information flow. Although there may be patient safety risks in the diagnostic process related to the use of health IT, it is difficult to determine the extent of the problem. Health IT vendors often limit the sharing of information about these risks. A prev ious IOM report recomm ended that the Depart- ment of Health and Human Services (HHS) ensu re insofar as possible that health IT vendors support the free exchange of information about pa tient safety and not pr ohibit sharing of such information. The present committee endorses this recommendation and highlights the need for shared information about user experiences with health IT used in the diagnostic process. Inde-pendent evaluations of health IT products could also identify poten tial adverse cons equences that contribute to diagnostic errors. Goal 3: Ensure that health information techno logies support patients and health care pro- fessionals in the diagnostic process Recommendation 3a: Health IT vendors and th e Office of the National Coordinator for Health Information Technology (ONC) should work together with users to ensure that health IT used in the diagnostic process de monstrates usability, incorporates human fac- tors knowledge, integrates measurement capab ility, fits well within clinical workflow, pro- vides clinical decision support, and facilitates the timely flow of information among pa- tients and health care professional s involved in the diagnostic process. Recommendation 3b: ONC should require health IT vendors to meet standards for in-teroperability among different health IT system s to support effective, efficient, and struc- tured flow of patient information across care settings to facilitate the diagnostic process by 2018. Recommendation 3c: The Secretary of HHS should require health IT vendors to: S-10 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRRECTED PROOFS Routinely submit their products for independent evaluation and notify users about potential adverse effects on the diagnostic process related to the use of their prod- ucts. Permit and support the free exchange of information about rea l-time user experi- ences with health IT design and implementation that adversely affect the diagnostic process. Develop and Deploy Approaches to Identify, Learn From, and Reduce Diagnostic Errors and Near Misses in Clinical Practice Due to the difficulty in identifying diagnostic errors and competing demands from existing quality and safety improvement priorities, very fe w health care organizati ons have processes in place to identify diagnostic errors and near misses. Nonetheless, identifying these experiences, learning from them, and implementing changes will improve diagnosis and reduce diagnostic errors. Health care organizations can also ensure that systematic feedback on diagnostic perfor-mance reaches individuals, care team s, and organizational leadership. Postmortem examinations are a critical source of information on the epidemiology of diag- nostic errors, but the number of postmortem examinations has d eclined precipitously. A greater emphasis on postmortem examination research\u2014inc luding more limited approaches to postmor- tem examinations\u2014is warranted to better understa nd the incidence of dia gnostic errors and the role of postmortem examinations in modern clinical practice. Health care professional socie ties can be engaged to identify high-priority areas to improve diagnosis, similar to the Choosing Wisely initia tive on avoiding unnecessary care. Early efforts could focus on identifying the most common dia gnostic errors, \"don't miss\" health conditions that may result in patient harm, or diagnostic errors that are relativ ely easy to address. Goal 4: Develop and deploy approaches to id entify, learn from, and reduce diagnostic er- rors and near misses in clinical practice Recommendation 4a: Accreditation organizations and the Medicare conditions of partici-pation should require that health care organizat ions have programs in place to monitor the diagnostic process and identif y, learn from, and reduce diagnos tic errors and near misses in a timely fashion. Proven approaches should be incorporated into updates of these re-quirements. Recommendation 4b: Health care organizations should: Monitor the diagnostic process and identi fy, learn from, and reduce diagnostic er- rors and near misses as a component of their research, quality improvement, and patient safety programs. Implement procedures and practices to pr ovide systematic feedback on diagnostic performance to individual health care prof essionals, care teams, and clinical and organizational leaders. SUMMARY S-11 PREPUBLICATION COPY: UNCORRRECTED PROOFS Recommendation 4c: HHS should provide funding for a designated subset of health care systems to conduct routine postmo rtem examinations on a repres entative sample of patient deaths. Recommendation 4d: Health care professional societies should identify opportunities to improve accurate and timely diagnoses and re duce diagnostic errors in their specialties. Establish a Work System and Culture that Supports the Diagnostic Process and Improvements in Diagnostic Performance Health care organizations influence the work system in which diagnosis occurs and play a role in implementing change. The work systems of many health care organizations could better support the diagnostic process, for example, by in tegrating mechanisms to improve error recov- ery and resiliency in th e diagnostic process. The culture and leadership of health care or ganizations are key factors in ensuring con- tinuous learning in the diagnostic process. Orga nizations need to promote a non-punitive culture in which clinicians can identify and learn from diagnostic errors. Organizational leadership can facilitate this culture, provide resources, and set priorities for achieving progress in diagnostic performance and reducing diagnostic errors. Health care organizations can also work to a ddress diagnostic challenges related to frag- mentation of the broader health care system. Although improved teamwork and interoperability will help with fragmentation in health care, orga nizations need to recognize that patients cross organizational boundaries and that this has the pot ential to contribute to diagnostic errors and failures to learn from them. Strengthening communi cation and reliable diagnostic test reporting is one area where this can be addressed. Goal 5: Establish a work system and cultu re that supports the diagnostic process and im- provements in diagnostic performance Recommendation 5: Health care organizations should: Adopt policies and practices that promote a non-punitive culture that values open discussion and feedback on diagnostic performance. Design the work system in which the diagnostic process occurs to support the work and activities of patients, their families, and health care professi onals and to facili- tate accurate and timely diagnoses. Develop and implement processes to ensure effective and timely communication be- tween diagnostic testing health care prof essionals and treating health care profes- sionals across all health care delivery settings. Develop a Reporting Environment and Medical Liability System that Facilitates Improved Diagnosis by Learning from Diagnostic Errors and Near Misses S-12 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRRECTED PROOFS Reporting Conducting analyses of diagnostic errors, near misses, and advers e events presents the best opportunity to learn from such experiences and implement changes to improve diagnosis. There is a need for safe environments, without the thre at of legal discovery or disciplinary action, to analyze and learn from these events. Previously, the IOM recommended that Congress extend peer review protections to data that are collected for improving the safety and quality of care. Subsequent legislation established the Agency for Healthcare Research and Quality- (AHRQ-) administered Patient Safety Or ganization (PSO) program which conferred privilege and confi- dentiality protections to patient safety information that is shared with PSOs. The PSO program is an important national leve r to increase voluntary error reporting and analysis, but progress has been impeded by seve ral challenges. For example, AHRQ developed common formats to encourage standardized event reporting, but the use of these formats is vol- untary, and there is no common format specific to diagnostic error. Concern that the federal priv- ilege protections do not protect organizations from state repor ting requirements could also pre- vent voluntary submissions to PSOs and decrea se the potential for impr oved learning. Given the PSO program's potential to improve learning about diagnostic errors and near misses, it is im- portant to evaluate the program. Medical Liability The core functions of medical liability are to compensate negligently injured patients and to promote quality by encouraging clinicians and organizations to avoid medical errors. The current approach for resolving medical liability claims sets up barriers to improvements in quality and patient safety. In addition, patients and their fam ilies are poorly served by the current system. While medical liability is broade r than diagnosis, diagnostic errors are the leading type of paid medical malpractice claims. Traditional medical liability reforms have not been effective in compensating negligently in- jured patients or deterrin g unsafe care. Alternative approaches are needed that enable patients and clinicians to become allies in making health care safer by encouraging transparency and dis- closure of medical errors. These reforms can enab le prompt and fair compensation for avoidable injuries, while turning errors into opp ortunities for learning and improvement. Communication and resolution prog rams (CRPs) provide a prag matic approach for changing medical liability, in that they are the most likely to be implem ented. Safe harbors for adherence to evidence-based clinical practi ce guidelines could also help f acilitate improvements in diagnos- tic accuracy by incentivizing the use of evidenced-based diagnos tic approaches; however, there are few clinical practice guidelines available for diagnosis, and implementation is complex. Ad- ministrative health courts offer a fundamental change that would promote a more open environ- ment for identifying, studying, and learning from e rrors, but implementation is very challenging because of their operational complexity and re sistance from stakeholders who are strongly com- mitted to preserving the current tort-based system. Risk Management Professional liability insurance carriers and he alth care organizations that participate in captive or other self-insurance arrangements have an inherent interest and expertise in improving SUMMARY S-13 PREPUBLICATION COPY: UNCORRRECTED PROOFS diagnosis. Improved collaboration between health professional li ability insurance carriers and health care professionals and organizations could support education, training, and practice im- provement strategies focused on improving di agnosis and minimizing diagnostic errors. Goal 6: Develop a reporting environment and medical liability system that facilitates im- proved diagnosis by learning from diagnostic errors and near misses Recommendation 6a: AHRQ or other appropriat e agencies or independent entities should encourage and facilitate the voluntary reporting of diagnostic errors and near misses. Recommendation 6b: AHRQ should evaluate the effectiveness of PSOs as a major mecha-nism for voluntary reporting and learning fr om these events and modify the PSO common formats for reporting of patient safety events to include diagnostic errors and near misses. Recommendation 6c: States, in collaboration with other stakeholders (health care organi- zations, professional liability insurance carri ers, state and federal policy makers, patient advocacy groups, and medical ma lpractice plaintiff and defense attorneys), should promote a legal environment that facilita tes the timely identification, disclosure, and learning from diagnostic errors. Specifically, they should: Encourage the adoption of CRPs with legal protections for disclosures and apologies under state laws. Conduct demonstration projects of alternativ e approaches to the resolution of medi- cal injuries, including administrative health courts and safe harbors for adherence to evidenced-based clinic al practice guidelines. Recommendation 6d: Professional liability insu rance carriers and captive insurers should collaborate with health care professionals on opportunities to impr ove diagnostic perfor- mance through education, training, and prac tice improvement approaches and increase participation in such programs. Design a Payment and Care Delivery Environment that Supports the Diagnostic Process Fee-for-service (FFS) payment has long been reco gnized for its inability to incentivize well- coordinated, high-quality, and effici ent health care. There is limite d information about the impact of payment and care delivery models on diagnosis, but it likely influences the diagnostic process and the occurrence of diagnostic errors. For example, FFS payment lacks financial incentives to coordinate care among clinicians involved in th e diagnostic process, such as the communication among treating clinicians, pathologists, and radiol ogists about diagnostic te st ordering, interpre- tation, and subsequent decision making. For all medical specialties, there are well-docum ented fee schedule distortions that result in more generous payments for procedures and diag nostic testing interpretations than for evaluation and management services (E&M) services. E&M services reflect the cognitive expertise and skills that all clinicians use in the diagnostic pr ocess, and these distorti ons may be diverting at-S-14 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRRECTED PROOFS tention and time from important tasks in the diagno stic process. Realigning relative value fees to better compensate clinicians for cognitive work in the diagnostic process has the potential to im- prove diagnosis while reducing incen tives that drive inappropriate di agnostic testing utilization. E&M documentation guidelines have been critici zed as onerous, often i rrelevant to patient care, and preventing clinical reas oning in the diagnostic process. Payment and liability concerns, facilitated by the growth in EHRs, have result ed in extensive clinical documentation that ob- scures key information in patient s' medical records, results in inaccuracies in patients' EHRs, and can contribute to diagnostic errors. Due to the limitations in FFS payment, a number of alternative paymen t and care delivery models are under evaluation; for example, half of Medicare payments are expected to be based on alternative models by 2018. There is limited ev idence concerning the impact of payment and care delivery models\u2014including FFS\u2014on the diagnos tic process and the accuracy of diagnosis, and this represents a fundamental research nee d. Even when alternativ e approaches to FFS are employed, they are often influenced by FFS. Thus , the current challenges with FFS will need to be addressed, even with the implementation of alternative payment and care delivery models. Goal 7: Design a payment and care delivery en vironment that supports the diagnostic pro- cess Recommendation 7a: As long as fee schedul es remain a predominant mechanism for de- termining clinician payment, the Centers for Medicare & Medicaid Services (CMS) and other payers should: Create current procedural terminology (CPT ) codes and provide coverage for addi- tional evaluation and management activiti es not currently coded or covered, includ- ing time spent by pathologists, radiologists, and other clinicians in advising ordering clinicians on the selection, use, and int erpretation of diagnostic testing for specific patients. Reorient relative value fees to more appropriately value th e time spent with patients in evaluation and management activities. Modify documentation guidelines for evaluation and management services to im- prove the accuracy of information in the EHR and to support decision making in the diagnostic process. Recommendation 7b: CMS and other payers shou ld assess the impact of payment and care delivery models on the diagnostic process, th e occurrence of diagnostic errors, and learning from these errors. Provide Dedicated Funding for Research on the Diagnostic Process and Diagnostic Errors The diagnostic process and diagnostic errors have been neglected areas within the national research agenda; federal resources devoted to diagnostic research are overshadowed by those de-voted to treatment. A major barrier to research is the organization and funding of the National Institutes of Health by disease or organ systems, which facilitates the study of these specific are-SUMMARY S-15 PREPUBLICATION COPY: UNCORRRECTED PROOFS as but impedes research efforts that seek to provide a more comprehens ive understanding of di- agnosis as a distinct research area. Given the potential for fede ral research on diagnosis and di- agnostic error to fall between institutional missions , collaboration among agencies is needed to develop a national research agenda on these topi cs. Because overall federal investment in bio- medical and health services rese arch is declining, funding for di agnosis and diagnostic error will draw federal resources away from other prioritie s. However, given the co nsistent lack of re- sources for research on diagnosis, and the potential for diagnostic errors to contribute to patient harm and health care costs, funding for this re search is necessary for broader improvements to the quality and safety of health care. In addi tion, improving diagnosis co uld potentially lead to cost savings by preventing diagnos tic errors, inappropriate treatmen t, and related adverse events. In addition to federal-level research, there is an important role for public-private collabora- tion and coordination among the federal governme nt, foundations, industry, and other stakehold- ers. Collaborative funding efforts extend the exis ting financial resources and reduce duplications in research efforts. Parties can unite around area s of mutual interest a nd spearhead progress. Goal 8: Provide dedicated funding for researc h on the diagnostic process and diagnostic errors Recommendation 8a: Federal agencies, includin g HHS, the U.S. Department of Veterans Affairs, and the U. S. Depar tment of Defense, should: Develop a coordinated research agenda on the diagnostic process and diagnostic er- rors by the end of 2016. Commit dedicated funding to implementing this research agenda. Recommendation 8b: The federal government sh ould pursue and encourage opportunities for public-private partnerships among a broad range of stakeholders, such as the Patient-Centered Outcomes Research Institute, foundat ions, the diagnostic testing and health IT industries, health care organizations, and profe ssional liability insurers to support research on the diagnostic process and diagnostic errors. 1-1 PREPUBLICATION COPY: UNCORRECTED PROOFS 1 Introduction For decades the delivery of health care has proceeded with a blind spot: Diagnostic errors\u2014inaccurate or delayed diagnoses\u2014persis t throughout all care se ttings and harm an unacceptable number of patients. Getting the right di agnosis is a key aspect of health care, as it provides an explanation of a pa tient's health problem and informs subsequent health care decisions (Holmboe and Durning, 2014). Diagnostic errors can lead to negative health outcomes, psychological distress, and financial costs. If a diagnostic error occurs, inappropriate or unnecessary treatment may be given to a pati ent, or appropriate\u2014a nd potentially lifesaving\u2014 treatment may be withheld or delayed. However, efforts to identify and mitigate diagnostic errors have so far been quite limited. Absent a spotlight to illuminate this crit ical challenge, diagnostic errors have been largely unappreciated within the quality and patient safety movements. The result of this inattention is signi ficant: It is likely that most people will experience at least one diagnostic error in their lifetime, some times with devasta ting consequences. The topic of diagnosis raises a number of clin ical, personal, cultural, ethical, and even political issues that commonly capture public interest. Members of the public are concerned about diagnosis and many have reported experien cing diagnostic errors. Fo r example, a survey by Isabel Healthcare found that 55 percent of a dults indicated that their main concern when visiting a family practitioner was being correc tly diagnosed (Isabel He althcare, 2006). A poll commissioned by the National Patient Safety Foundation found that approximately one in six of those surveyed had experience with diagnostic er ror, either personally or through a close friend or relative (Golodner, 1997). More recently, 23 percent of people surveyed in Massachusetts stated that they or someone close to them ha d experienced a medical error, and approximately half of these errors were diagnos tic errors (Betsy Lehman Center for Patient Safety and Medical Error Reduction, 2014). In the United Kingdom, the country's Nati onal Health Service concluded that diagnosis\u2014incl uding diagnostic error\u2014was the most common reason individuals complained about their health care, accounti ng for approximately 35 percent of complaints (Parliamentary and Health Service Ombudsman, 2014). In addition to diagnostic errors, the public is concerned about other aspects of diagnosis, such as the value of making and communicating diagnoses at early stages in conditions such as Alzheimer's disease and amyotrophi c lateral sclerosis (Lou Gehrig's disease) for which there is currently no known cure (Hamilton, 2015). Ther e is also a growing concern about overdiagnosis, such as the assignment of diagnostic la bels to conditions that are unlikely to affect the individual's health and we ll-being (Welch et al., 2011); the focus of clinical attention on making new diagnoses in older patie nts while ignoring limitations to their daily living that need immediate attention (Gawande, 2014; Mechanic, 2014); and the elevation of common behavioral traits to the level of formal diagnoses, with the attendant treatment and confidentiality implications (Hazen et al., 2013; Kavan a nd Barone, 2014; NHS, The (IOM) report Beyond Myalgic Encephalomyelitis/Chronic Fatigue Syndrome: 1-2 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Redefining an Illness brought attention to the problem that individuals with debilitating but previously non-recognized symptom complexes may be given inadequate a ttention by clinicians or ignored altogether because a diagnosis is lacking (IOM, 2015a; Re hmeyer, 2015). Diagnoses also affect the health care that patients receiv e, eligibility for social security and veterans disability benefits, as well as health care research and education priorities. The widespread challenge of di agnostic errors frequently rises to broad public attention, whether the widely reported di agnostic error of Ebola virus infection in a Dallas hospital emergency department or in the occasional report of an extraordinarily high malpractice award for failure to make a timely dia gnosis of cancer or some other life threatening disease (Pfeifer, 2015; Upadhyay et al., 2014; Wachter, 2014). The s ubjects of diagnosis and diagnostic error have captured media interest, as indicated by television shows and columns about perplexing diagnoses and coverage of pa tient experiences with diagnos is 2014; Washington Post, 2014). For example, Harper's Magazine featured an essay that chronicled one pa tient's diagnostic journe y and experience with diagnostic error through multiple clinicians, intern et searches, conversations with friends and family, and decision support tools (Julavits, 2014). Books featuring patients' experiences with diagnosis and the health care system have al so been published (Cahalan, 2012; Groopman, 2007; Sanders, 2010). Given the importance of diagnosis to patients and to health care decision making, as well as the pervasiveness of diagnostic errors in prac tice, it is surprising that this issue has been neglected within the quality improvement and patient safety movement (Gandhi et al., 2006; Graber et al., 2012; Newman-Toker and Pronovost, 2009; Singh, 2014). There are a number of reasons for the lack of attention to diagnostic erro rs. Major contributors ar e the lack of effective measurement of diagnostic error and the difficulty in detecting these errors in clinical practice (Graber et al., 2012; Singh, 2013). Even if they can be measured or identified, diagnostic errors may not be recognized, for example, when the error is identified by a second clinician and feedback about the error is not provided to the original clinician. There may also be debate about what constitutes a diagnostic error; even after an extensive review of a patient's chart, expert reviewers often disagree about wh ether or not an error has oc curred (Wachter, 2010; Zwaan and Singh, 2015). Diagnostic errors may also be perceived as too difficult to address because the reasons for their occurrence are often complex and multifaceted (Berenson et al., 2014; Croskerry, et al., 2005; Zwaan et al., 2009). This difficulty in identifying the etiology of errors, combined w ith a lack of feedback on diagnostic performance in many health care settings, limits understa nding and makes it more difficult to prioritize improving diagnosis and reducing di agnostic errors. Other factors th at contribute to the limited focus on diagnostic error include a lack of awar eness of the problem, attitudes and culture that encourage inaction and tolerance of errors, poorly understood characteristics of the diagnostic and clinical reasoning processes, and the need for financial and other re sources to address the problem (Berenson et al ., 2014; Croskerry, 2012). Although diagnostic error has been largely und erappreciated in efforts to improve the quality and safety of health care, this issue ha s garnered national attent ion, and there is growing momentum for change (Graber et al., 2012; Schiff and Leape, 2012; Wa chter, 2010). Emerging research has found new opportunities for the identific ation of diagnostic errors and has led to a better understanding of the epidemiology and e tiology of these errors and of potential interventions to improve diagnosis (Singh et al ., 2014; Tehrani et al., 201 et al., 2010; Zwaan and Singh, 2015). Pa tients and families who have experienced INTRODUCTION 1-3 PREPUBLICATION COPY: UNCORRECTED PROOFS diagnostic error have become increasingly vocal a bout their desire to shar e their unique insights to help identify patterns and improve the diagno stic process for future patients (Haskell, 2014; McDonald et al., 2013). Efforts to accelerate progress toward impr oving diagnosis can leve rage four important movements in health care\u2014the m ovements to improve patient safe ty, increase pati ent engagement, foster professionalism, and encourage collaboratio n. Diagnostic erro r has even been called the next frontier in patient safety, even though the challenge of diagnostic error will have benefits beyond the realm of patient safety, as such errors are a majo r challenge to th e quality of patient care (Newman- Toker and Pronovost, 2009). Patient engagement and the impo rtance of shared d ecision making are recognized as critical aspects of improving health care quality (IO M, 2001). The current focus on professionalism emphasizes health care professionals' intrinsic motivation and commitment to provide patients with high-quality, patient-centered care (Berwick, 2015; Chassin an d Baker, 2015; Madara and Burkhart, 2015). The growing recognition of health care as a te am-based activity has led to greater collaboration among health care professi onals, both intra- and in ter-professionally (IOM, 2001; Josiah Macy Jr. Fo undation and Carnegie Foundation for the Advancement of Teaching, 2010). These four movements have collectively transformed the way that health care is provided in the United States, and progress toward improvin g diagnosis and reducing diagnostic errors is a natural outgrowth of thes e movements. This repo rt by the IOM Committee on Diagnostic Error in Health Care synthesizes current knowledge about diagnostic error and ma kes recommendations on how to reduce diagnostic errors and improve diagnosis. CONTEXT OF THE STUDY This study is a continuation of the IOM Quality Chasm Series, which focuses on assessing and improving the quality and safety of health care. It includes the IOM reports To Err Is Human: Building a Safer Health System and Crossing the Quality Chasm: A New Health System for the 21st Century. The first report was a call to action: The committee concluded that the care patients receive is not as safe as it should be (IOM, 2000). Estimating that tens of thousands of lives are lost each year because of medical errors, the report catalyzed a movement to improve the safety of health care in Amer ica. The second report de fined high-quality care broadly and set out a vision to close the chasm between what wa s known to be high-quality care and what patients received in practice (IOM, 2001). Together these reports stimulated widespread scrutiny of the health care system and brought about large-scale efforts to improve the quality and safety of care. However, these reports focused primarily on th e quality and safety of medical treatment rather than on the diagnostic process. The majority of quality improvement and patient safety efforts that have since followed have been fo cused on improving the delivery of evidence-based care, preventing the adverse outcomes of treatment, such as medication and surgical errors, and health care-associated infections. ORIGIN OF TASK AND COMMITTEE CHARGE In the summer of 2013, the Society to Im prove Diagnosis in Medicine requested that the IOM Board on Health Care Serv ices undertake a study on diagnostic error as a continuation of the IOM's Quality Chasm Series. With support from a broad coalition of sponsors\u2014the 1-4 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Agency for Healthcare Research and Quality, the American Colle ge of Radiology, the American Society for Clinical Pathology, the Cautious Pa tient Foundation, the Centers for Disease Control and Prevention, the College of American Pathologists, The Doctors Company Foundation, Janet and Barry Lang, Kaiser Permanente National Community Benefit Fund at the East Bay Community Foundation, and the Robert Wood Jo hnson Foundation\u2014the study began in January 2014. The IOM appointed an independent committee w ith a broad range of expertise, including diagnostic error, patient safety, health care quality and measurement, patient engagement, health policy, health care professional education, cogn itive psychology, health disparities, human factors and ergonomics, health information t echnology (health IT), decision analysis, nursing, radiology, pathology, law, and health economics. Br ief biographies of the 21 members of this Committee on Diagnostic Error in Health Care are presented in Appendix B. The charge to the committee was to synthesize what is known about di agnostic error as a quali ty of care challenge and to propose recommendations for improving diagnosis (see Box 1-1). BOX 1-1 Charge to the Committee on Diagnostic Error in Health Care An ad hoc committee of the Institute of Medicine will evaluate the existing knowledge about diagnostic error as a quality of care challenge; current definitions of diagnostic error and illustrative examples; and areas where additional research is needed. The committee will examine topics such as the epidemiology of diagnostic error, the burden of harm and economic costs associated with diagnostic error, and current efforts to address the problem. The committee will propose solutions to the problem of diagnostic error, which may include: clarifying definitions and boundaries; integrating educational approaches; addressing behavioral/cognitive processes and cultural change; teamwork and systems engineering; measures and measurement approaches; research; changes in payment; approaches to medical liability; and health information technology and other technology changes. The committee will devise conclusions and recommendations that will propose action items for key stakeholders, such as patients/advocates, health care providers, health care organizations, federal and state policy makers, purchasers and payers, credentialing organizations, educators, researchers, and the diagnostic testing and health information technology industries to achieve desired goals. METHODS OF THE STUDY The committee deliberated during five in-per son meetings and numerous conference calls between April 2014 and April 2015. At three of the meetings, the committee invited a number of speakers to inform its deliberations. These speak ers provided invaluable input to the committee on a broad range of topics, including patient expe riences with diagnostic error; the measurement, reporting, and feedback of diagnostic error; he alth IT design and d ecision support; diagnostic errors in pathology and radiology; patient safety culture; teams in dia gnosis; psychiatry and diagnostic error; legal issues in diagnosis; a nd the prioritization of diagnostic error. The committee also held a webinar with experts in cognition and health care professional education. INTRODUCTION 1-5 PREPUBLICATION COPY: UNCORRECTED PROOFS A number of experts and organi zations provided written input to the committee on a broad array of topics. In addition to receiving this expert input, the committee reviewed an extensive body of literature to inform its deliberations. CONCEPTUAL MODEL To help frame and organize its work, the co mmittee developed a conceptual model that defined diagnostic error and also illustrated the di agnostic process, the work system in which the diagnostic process occurs, and the outcomes that result from this process (see Chapters 2 and 3 for detailed information on the conceptual mode l). The committee developed a patient-centered definition of diagnostic error: the failure to (a) establish an a ccurate and timely explanation of the patient's health problem(s) or (b) co mmunicate that explanation to the patient . EXAMPLES OF DIAGNOSIS AND DIAGNOSTIC ERRORS To illustrate the complexity of the diagnostic process and the range of diagnostic errors that can occur, the committee has included a variet y of examples of experiences with diagnosis and diagnostic error. The committee was honored to hear patients' and family members' experiences with diagnosis, both positive and negative; three of these experiences are described in Box 1-2. During the committee's deliberations, th e United States experienced its first case of Ebola virus infection; because th e diagnosis was initially missed in the emergency department, it illustrated a high-profile example of diagnostic error with importa nt public health implications (Upadhyay et al., 2014) (see Chapter 5). Appendix D includes additional examples of diagnostic error in order to convey a broa der sense of the types of dia gnostic errors that can occur. BOX 1-2 Patient and Family Experiences with Diagnosis Jeff Jeff was driving home from work when he started experiencing sharp chest pains. Because he was close to the local hospital, he decided to drive directly to the emergency department (ED). Jeff entered the ED stating that he believed he was having a heart attack. He was immediately provided aspirin and nitroglycerin. An electrocardiogram (EKG) was performed, with normal results. Jeff continued to have chest pain. Because of his ongoing symptoms, the clinicians told Jeff that they would ready the hospital's helicopter in case he needed to be quickly transported to another hospital for heart surgery. Jeff then started complaining of pain in his leg to his wife, who had by then arrived at the hospital, and she told the nurse that something must really be wrong because Jeff rarely complained of pain. Upon further examination, clinicians found that Jeff's left foot and leg were swollen, and a CT scan of Jeff's chest was performed. The CT scan showed that Jeff had an aortic dissection, \"a serious condition in which there is a tear in the wall of the major artery carrying blood out of the heart\" (MedlinePlus, 2015). His clinicians immediately put him in a helicopter and flew him to another hospital, where he underwent an extensive surgery to repair the aortic dissection and repair damage to his leg. Jeff cited the willingness of his clinicians to listen to him and his wife and to continue investigating his symptoms despite his normal EKG results as major contributors to his rapid 1-6 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS diagnosis. Because aortic dissections are life-threatening events that require urgent treatment, the quick action of the ED to get Jeff to surgery also contributed to the successful outcome. Before his aortic dissection, Jeff was in good health. He now has several ongoing medical conditions as well as continued surveillance and treatment related to the dissection. He sees a number of health care professionals on a regular basis. Jeff's experience has taught him the importance of communicating with one's health care professionals. He now proactively educates himself on his health conditions, speaks up when he has a concern, prepares questions in advance when he has an appointment, and continues to seek answers to questions that he feels are not adequately addressed. Carolyn Carolyn came to the ED with chest pain, nausea, sweating and radiating pain through her left arm, which are often considered classic symptoms of a heart attack. The ED clinicians ordered an EKG, blood tests, a chest X-ray, and a treadmill stress test; all of these tests came back normal. Her ED clinician diagnosed her as having acid reflux, noting she was in the right demographic for this condition. When she asked the ED doctor about the pain in her arm, he was dismissive of the symptom. Privately, a nurse in the ED asked Carolyn to stop asking questions of the doctor, noting that he was a very good doctor and didn't like to be questioned. Carolyn was released from the hospital less than 5 hours after the onset of her symptoms, feeling embarrassed about making a \"big fuss\" ov er a relatively common condition. Over the next 2 weeks, she developed increasingly debilitating symptoms, which prompted her return to the ED where she received a diagnosis of signifi cant heart disease. Carolyn had a myocardial infarction caused by 99 percent blocked artery\u2014what clinicians still call the \"widow maker\" heart attack. Sue and her family Sue's son, Cal, was born healthy in a large hospital, but jaundice appeared soon afterwards. Jaundice, or yellowing of the skin, occurs when many red blood cells break down and release a chemical called bilirubin into the bloodstream. Cal's father, Pat, and Sue were informed that treatment for such newborn jaundice isn't usually necessary. (Unfortunately, because of an incorrect entry of the family blood types into Cal's medical record, the hospital's clinicians had not recognized that a common blood incompatibility existed and could lead to serious elevations in Cal's bilirubin levels.) Within 36 hours, Cal's jaundice had deepened and spread from head to toe. Nevertheless, without measuring his bilirubin level, the hospital discharged Cal to home and provided Pat and Sue with reassuring information about jaundice, never mentioning that high levels of bilirubin in the blood can cause damage to the brain (Mayo Clinic, 2015). Four days later, Cal was more yellow, lethargic, and feeding poorly. His parents took him to a pediatrician, who noted the jaundice, still did not do a bilirubin test, and advised them to wait 24 more hours to see if Cal improved. The next day, at the request of his parents, Cal was admitted to the hospital, and a blood test showed that the bilirubin level in Cal's blood was dangerously high. Over the next few days while Cal was in the hospital, Pat and Sue reported to staff that he was exhibiting worrisome new behaviors, such as a high-pitched cry, respiratory distress, increased muscle tone, and arching of the neck and back. They were told not to worry. Later it became clear that Cal was experiencing kernicterus, a preventable form of brain damage caused by high bilirubin levels in the blood of newborns. As a result, at age 20, Cal now has significant cerebral palsy, with s pasticity of his trunk and limbs, marked impairment of his speech, difficulty aligning his eyes, and other difficulties. Several years after Cal's birth, Pat experienced progressively severe neck pain, and a scan showed a mass on his cervical spine. While removing the mass, the neurosurgeon sent a tissue sample to a hospital pathologist, who examined the sample and called back to the INTRODUCTION 1-7 PREPUBLICATION COPY: UNCORRECTED PROOFS operating room to report that it was an atypical spindle cell neoplasm. Assuming that this meant a benign mass, the surgical team completed the operation and declared Pat cured. Following the operation, however, the hospital pathologist performed additional stains and examinations of Pat's tissue, eventually determining that the tumor was actually a malignant synovial cell sarcoma. Twenty-one days after the surgery, the pathologist's final report of a malignant tumor was sent to the neurosurgeon's office, but it was somehow lost, misplaced or filed without the neurosurgeon seeing it. The revised diagnosis of malignancy was not communicated to Pat or to his referring clinician. Six months later, when his neck pain recurred, Pat returned to his neurosurgeon. A scan revealed a recurrent mass that had invaded his spinal column. This mass was removed and diagnosed to be a recurrent invasive malignant synovial cell sarcoma. Despite seven additional operations and numerous rounds of chemotherapy and radiation, Pat died 2 years later at 45 years old with a 4-year-old daughter and a 6-year-old son. Cal's and Pat's (and Sue's) experiences are ex amples of diagnostic errors that led to inadequate treatment with major adverse consequences\u2014all enabled by poor communication and uncoordinated care by multiple health care pr oviders. Based on her family's experiences, Sue believes that health care systems, providers, patient advocates, payers and regulators have a responsibility to collaborate to reduce diagnostic errors by: Improving the processes of\u2014and the acc ountability for\u2014secure intra- and inter- professional communication of patients' clinical information. Engaging patients more actively as true partners with their health care providers\u2014with improved information-sharing, joint decisi on making, and self monitoring and reporting of health conditions and symptoms. SOURCE: Personal communications with Jeff, Ca rolyn, and Sue (last names are not provided for anonymity). ORGANIZATION OF THE REPORT The report is organized into three major sectio ns. Section I consists of Chapters 2 and 3 and provides an overview of the diagnostic proce ss and diagnostic error in health care. Section II, or Chapters 4 through 8, describes the cha llenges of diagnosis and is organized by the elements of the work system: Chapter 4 discus ses the diagnostic team members and the tasks they perform in the diagnostic process; Chapter 5 discusses the technology and tools (specifically health IT) used in the diagnostic process; Ch apter 6 focuses on health care organizations and their impact on the diagnostic process and diagno stic error; Chapter 7 describes the external elements that influence diagnosis, including pa yment and care delivery, reporting, and medical liability; and Chapter 8 highlights the research needs concerning the diagnostic process and diagnostic errors, as drawn from the previous Ch apters. Section III (Chapt er 9) synthesizes the committee's main conclusions and recommenda tions for improving diagnosis and reducing diagnostic error. REFERENCES Berenson, R. A., D. K. Upadhyay, and D. R. Kaye. 2014. Placing diagnosis errors on the policy agenda . Washington, DC: Urban Institute. http://www.urban.o rg/research/publication/placing-diagnosis-errors- policy-agenda (accessed May 22, 2015). Berwick, D. M. 2015. Postgraduate education of physicians: Professional self-regulati on and external accountability. JAMA 313(18):1803-1804. 1-8 DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Betsey Lehman Center for Patient Safety and Medical Error Reduction. 2014. The public's views on medical error in Massachusetts. Cambridge, MA: Harvard School of Public Health. Cahalan, S. 2012. Brain on fire . New York: Simon & Schuster. Chassin, M. R., and D. W. Baker. 2015. Aiming high er to enhance professionalism: Beyond accreditation and certification. JAMA 313(18):1795-1796. Croskerry, P. 2003. The importance of cognitive errors in diagnosis and strategies to minimize them. Academic Medicine 78(8):775-780. Croskerry, P. 2012. Perspectives on diagnostic failure and patient safety. Healthcare Quarterly 15(Special issue) April:50-56. Dwyer, J. 2012. An infection, unnoticed, turns unstoppable. The New York Times , July 11. www.nytimes.com/2012/07/12/nyregion/in-rory-stauntons-fight-for-his-life-signs-that-went- unheeded.html?pagewanted=all&_r=0 (accessed December 5, 2014). Gandhi, T. K., A. Kachalia, E. J. Thomas, A. L. Puopolo, C. Yoon, T. A. Brennan, and D. M. Studdert. 2006. Missed and delayed diagnoses in the ambulatory setting: A study of closed malpractice claims. Annals of Internal Medicine 145(7):488-496. Gawande, A. 2014a. Being mortal: Medicine and what matters in the end . New York, NY: Metropolitian Books. Genzlinger, N. 2012. A medical guessing game, with life as the ultimate prize. The New York Times, June 24. http://www.nytimes.com/2012/06/25/arts/television/d iagnosis-dead-or-alive-on-discovery-fit-health.html (accessed August 5, 2014). Golodner, L. 1997. How the public perceives patient safety. Newsletter of the National Patient Safety Foundation 1(1):1-4. Graber, M. L., N. Franklin, and R. Gordon. 20 05. Diagnostic error in internal medicine. Archives of Internal Medicine 165(13):1493-1499. Graber, M., R. Wachter, and C. Cassel. 2012. Bringi into the quality and safety equations. JAMA 308(12):1211-1212. Groopman, J. 2007. How doctors think, 2nd ed. New York: Mariner Books. Gubar, S. 2014. Missing a cancer diagnosis. The New York Times , January 2. http://well.blogs.nytimes.com/2014/01/02/missing-a-cancer-diagnosis/?_php=true&_type=blogs&_r=0 (accessed December 5, 2014). Hamilton, J. 2015. Many doctors who diagnose Alzheimer's fail to tell the patient. NPR , March 24. http://www.npr.org/sections/health-shots/2015/03/24 /394927484/many-doctors-who-diagnose-alzheimers- fail-to-tell-the-patient. ( accessed August 5, 2015). Haskell, H. W. 2014. What's in a story? Lessons from patients who have suffered diagnostic failure. Diagnosis 1(1):53-54. Hazen, E. P., C. J. McDougle, and F. R. Volkmar. 2013. Change s in the diagnostic criteria for autism in DSM-5: Controversies and concerns. Journal of Clinical Psychiatry 74(7):739-740. Holmboe, E. S., and S. J. Durning. 2014. Assessing clinical reasoning: Moving from in vitro to in vivo. Diagnosis 1(1): 111-117. IOM (Institute of Medicine). 2000. To err is human: Building a safer health system . Washington, DC: The National Academies Press. IOM. 2001. Crossing the quality chasm: A new health system for the 21st century . Washington, DC: The National Academies Press. IOM. 2015a. Beyond myalgic encephalomyelitis/chronic fatigue syndrome: Redefining an illness. Washington, DC: The National Academies Press. Isabel Healthcare. 2006. Misdiagnosis is an overlooked and growing patient safety issue and core mission of isabel healthcare. www.isabelhealthcare.com/home/u spressrelease (accessed December 4, 2014). Josiah Macy Jr. Foundation and Carnegie Foundation for the Advancement of Teaching. 2010. Educating nurses and physicians: Towards new horizons. Advancing inter-professional education in academic health centers, Conference summary. Ne w York: Josiah Macy Jr. Foundation. http://www.macyfoundation.org/docs/macy_pubs/J MF_Carnegie_Summary_WebVersion_%283%29.pdf (accessed June 5, 2015). Julavits, H. 2014. Diagnose this! How to be your own best doctor. Harper's Magazine , April 2014, 25-35. Kavan, M. G., and E. J. Barone. 2014. Grief and major depression\u2014Controversy over changes in DSM-5 diagnostic criteria. American Family Physician 90(10):690-694. Madara, J. L., and J. Burkhart. 2015. Professionalism, self-r egulation, and motivation: How did health care JAMA 313(18):1793-1794. INTRODUCTION 1-9 PREPUBLICATION Infant jaundice: Definition. www.mayoclinic.org/diseases-conditions/infant- jaundice/basics/definition/con-20019637 (accessed May 8, 2015). McDonald, K. M., C. L. Bryce, and M. L. Graber. 2013 . The patient is in: Patient involvement strategies for diagnostic error mitigation. BMJ Quality & Safety 22(Suppl 2):ii33-ii39. Mechanic, M. 2014. Atul Gawande: \"We have medicalized ag ing, and that experiment is failing us.\" Mother Jones, October 7. http://www.motherjones.com/media/2014/10 /atul-gawande-being-mortal-interview-assisted- living (accessed August 2015). MedlinePlus. 2015 . Aortic dissection. www.nlm.n ih.gov/medlineplus/ency/article /000181.htm (accessed May 8, 2015). New York Times. 2014. Diagnosis: A collection of \"diagnosis\" columns published in the New York Times. http://topics.nytimes.com/top/news/health/columns/dia gnosis/index.html (accesse d December 5, 2014). Newman-Toker, D., and P. J. Pronovost. 2009. Diagnostic errors\u2014The next frontier for patient safety. JAMA 301(10):1060-1062. NHS (National Health Service). 20 13. News analysis: Controversial mental health guide DSM-5. www.nhs.uk/news/2013/08august/pages/controversy-mental-health-diagnosis-and-treatment- dsm5.aspx#two (accessed May 13, 2015). Parliamentary and Health Service Ombudsman. 2014. Complaints about acute trusts 2013-14 and Q1, Q2 2014-15 United Kingdom: Parliamentary and Health Service Ombudsman. Pfeifer, S. 2015. Kaiser ordered to pay woman more than $28 million. LA Times, March 26. http://www.latimes.com/business/la-fi-jury-awards-kaiser-cancer-patie nt-20150326-story.html (accessed August 5, 2015). Rehmeyer, J. 2015. A disease doctors refuse to see. New York Times , February, 25. http://www.nytimes.com/20 15/02/25/opinion/understanding-chronic -fatigue.html (accessed August 5, 2015. Sanders, L. 2010. Every patient tells a story: Medical mysteries and the art of diagnosis . New York: Harmony. Schiff, G. D., and L. L. Leape. 2012. Commentary: How can we make diagnosis safer? Academic Medicine 87(2):135-138. Schiff, G. D., S. Kim, R. Abrams, K. Cosby, B. Lambert, A. S. Elstein, S. Hasler, N. Krosnjar, R. Odwazny, M. F. Wisniewski, and R. A. McNutt. 2005. Diagnosing di agnosis errors: Lessons from a multi-institutional collaborative project. In Henriksen, K., J. B. Ba ttles, E. S. Marks, and D. I. Lewin (eds.), Advances in patient safety: From research to implementation (Volume 2: Concepts and methodolgy) (pp. 255-278). AHRQ Publication No: 05-0021-1: Rockville, MD : Agency for Healthcare Research and Quality. Singh, H. 2013. Diagnostic errors: Moving beyond \"no respect\" and getting ready for prime time. BMJ Quality & Safety 22(10):789-792. Singh, H. 2014. Editorial: Helping health care organizations to define diagnostic errors as missed opportunities in diagnosis. Joint Commission Journal on Quality and Patient Safety 40(3):99-101. Singh, H., A. N. Meyer, and E. J. Thomas. 2014. The frequency of diagnostic errors in outpatient care: Estimations from three large observational studies involving U.S. adult populations. BMJ Quality & Safety 23(9):727- 731. Tehrani, A. S., H. Lee, S. C. Mathews, A. Shore, M. A. Makary, P. J. Pronovost, and D. E. Newman-Toker. 2013. 25-year summary of U.S. malpracti ce claims for diagnostic errors, 1986-2010: An analysis from the National Practitioner Data Bank. BMJ Quality & Safety 22(8):672-680. Trowbridge, R. L., G. Dhaliwal, and K. S. Cosby. 2013. Educational agenda for diagnostic error reduction. BMJ Quality & Safety 22(Suppl 2):ii28-ii32. Upadhyay, D. K., D. F. Sittig, and H. Singh. 2014. Ebola U. S. Patient Zero: Lessons on misdiagnosis and effective use of electronic health records. Diagnosis 10.1515/dx-2014-0064. Wachter, R. M. 2010. Why diagnostic errors don't get any respect\u2014and what can be done about them. Health Affairs (Millwood) 29(9):1605-1610. Wachter, R. M. 2014. What Ebola error in Dallas shows. USA Today, October 13, www.usatoday.com/story/opinion/2014/10/12/what-ebola-error-in-dallas-shows-column/17159839/ (accessed December 5, 2014). Washington Post. 2014. Medical mysteries. www.washin gtonpost.com/sf/national/collection/medical-mysteries/ (accessed December 5, 2014). Welch, H. G., L. Schwartz, and S. Woloshin. 2011. Overdiagnosed: Making people sick in the pursuit of health . Boston, MA: Beacon Press. 1-10 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Zwaan, L., and H. Singh. 2015. The challenges in defining and measuring diagnostic error. Diagnosis. Epub ahead of print. www.degruyter.com/view /j/dx.2015.2.issue-2/dx-2014-0069/dx -2014-0069.xml (accessed June 1, 2015). Zwaan, L., A. Thijs, C. Wagner, G. van der Wal, and D. R. Timmermans. 2009. Design of a study on suboptimal cognitive acts in the diagnostic process, the effect on patient outcomes and the influence of workload, fatigue and experience of physician. BMC Health Services Research 9:65. Zwaan, L., M. de Bruijne, C. Wagner, A. Thijs, M. Sm its, G. van der Wal, and D. R. Timmermans. 2010. Patient record review of the incidence, consequences, and causes of diagnostic adverse events. Archives of Internal Medicine 170(12):1015-1021. 2-1 PREBUBLICATION COPY: UNCORRECTED PROOFS 2 The Diagnostic Process This chapter provides an overview of diagnosis in health care, including the committee's conceptual model of the diagnostic process and a review of clinical reasoning. Diagnosis has important implications for patient care, research, and policy. Diagnosis has been described as both a process and a classification scheme, or a \"pre-existing set of cat egories agreed upon by the medical profession to designate a specific condition\" (Jutel, 2009). 1 When a diagnosis is accurate and made in a timely manner, a patient has the best opportunity for a positive health outcome because clinical decision making will be tailored to a correct understanding of the patient's health problem (Holmboe and Durning, 2014). In addition, public policy decisions are often influenced by diagnostic information, such as setting payment policies, resource allocation decisions, and research pr iorities (Jutel, 2009; Rosenberg, 2002; WHO, 2012). The chapter describes important considerations in the diagnostic pr ocess, such as the roles of diagnostic uncerta inty and time. It also highlights the mounting complexity of health care, due to the ever-increasing options for diagnostic testing2 and treatment, the rapidly rising levels of biomedical and clinical evidence to inform clinical practice, and the frequent comorbidities among patients due to the aging of the population (IOM, 2008, 2013b). The rising complexity of health care and the sheer volum e of advances, coupled with clinician time constraints and cognitive limitations, have out stripped human capacity to apply this new knowledge. To help manage this complexity, the ch apter concludes with a discussion of the role of clinical practice guidelines in informing decision making in the diagnostic process. OVERVIEW OF THE DIAGNOSTIC PROCESS To help frame and organize its work, the committee developed a conceptual model to illustrate the diagnostic process (Figure 2-1). The committee concluded that the diagnostic process is a complex, patient-cente red, collaborative activity that involves information gathering and clinical reasoning with the goal of determining a patient's health problem. This process occurs over time, within the cont ext of a larger health care work system that influences the diagnostic process (see Box 2-1). The committee's depiction of the diagnostic process draws on an adaptation of a decision-making model that describes the cyclical process of information 1 In this report, the committee employs the terminology \"the diagnostic process\" to convey diagnosis as a process. 2 The committee uses the term diagnostic testing to be incl usive of all types of testing, including medical imaging, anatomic pathology and laboratory medicine, as well as other types of testing, such as mental health assessments, vision and hearing testing, and neurocognitive testing. 2-2 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS gathering, information integr ation and interpretation, and forming a working diagnosis (Parasuraman et al., 2000; Sarter, 2014). The diagnostic process proceeds as follows: Firs t, a patient experiences a health problem. The patient is likely the first person to consider his or her symptoms and may choose at this point to engage with the health care system. Once a pa tient seeks health care, there is an iterative process of information gathering, information in tegration and interpretation, and determining a working diagnosis. Performing a clinical history and interview, conducting a physical exam, performing diagnostic testing, and referring or consulting with ot her clinicians are all ways of accumulating information that may be relevant to understanding a patient's health problem. The information gathering approaches can be employed at different times, and diagnostic information can be obtained in different orders. The continuo us process of information gathering, integration, and interpretation involves hypothesis generati on and updating prior prob abilities as more information is learned. Communication among health care professionals, the patient, and the patient's family members is critical in this cy cle of information gather ing, integration, and interpretation. The working diagnosis may be either a li st of potential diagnoses (a differential diagnosis) or a single potential diagnosis. Typically, clinicians will consider more than one diagnostic hypothesis or possibility as an explan ation of the patient's symptoms and will refine this list as further informati on is obtained in the diagnostic process. The working diagnosis should be shared with the pati ent, including an explanation of the degree of uncertainty associated with a working diagnosis. Each time ther e is a revision to the working diagnosis, this information should be communicated to the patient . As the diagnostic pro cess proceeds, a fairly broad list of potential diagnoses may be narrowed into fewer potential options, a process referred to as diagnostic modification and refinement (Kassirer et al., 2010) . As the list becomes narrowed to one or two possibilities, diagnostic refinement of the working diagnosis becomes diagnostic verification, in which th e lead diagnosis is checked for its adequ acy in explaining the signs and symptoms, its coherency with the pati ent's context (physiology, risk factors), and whether a single diagnosis is appropriate. When considering invasive or risky additional diagnostic testing or treatment options, the diagnostic verification step is particularly important so that a patient is not exposed to these risks without a reasonable chance that the testing or treatment options will be informative and will likely improve patient outcomes. Throughout the diagnostic process, there is an ongoing assessment of whether sufficient information has been collected. If the diagnos tic team members are no t satisfied that the necessary information has been collected to expl ain the patient's health problem or that the information available is not consistent with a diagnosis, then the process of information gathering, information integra tion and interpretation, and developing a working diagnosis continues. When the diagnostic te am members judge that they ha ve arrived at an accurate and timely explanation of the patient's health probl em, they communicate that explanation to the patient as the diagnosis. T F THE DIAGNOS T FIGURE 2-1 T TIC PROCESS he committee's PREPconceptualizat PUBLICATION the diagn process. ECTED PROOF S DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS It is important to note that clinicians do not need to obtai n diagnostic certa inty prior to initiating treatment; the goal of information gath ering in the diagnostic process is to reduce diagnostic uncertainty enough to make optimal d ecisions for subsequent care (Kassirer, 1989; see section on diagnostic uncertain ty). In addition, the pr ovision of treatment can also inform and refine a working diagnosis, which is indicated by the feedback loop from treatment into the information gathering step of the diagnostic proce ss. This also illustrates the need for clinicians to diagnose health problems that may arise during treatment. The committee identified four types of information gathering activities in the diagnostic process: taking a clinical history and inte rview; performing a physical exam; obtaining diagnostic testing; and sending a pa tient for referrals or consulta tions. The diagnostic process is intended to be broadly appli cable, including the provision of mental health care. These information-gathering processes are di scussed in further detail below. BOX 2-1 The Work System The diagnostic process occurs within a work sy stem that is composed of diagnostic team members, tasks, technology and tools, organizational factors, the physical environment, and the external environment (see Figure) (Carayon et al., 2006, 2014; Smith and Sainfort, 1989): Diagnostic team members include patients and their families and all health care professionals involved in their care. Tasks are goal-oriented actions that occur within the diagnostic process. Technologies and tools include health information technology (IT) used in the diagnostic process. Organizational characteristics include culture, rules and procedures, and leadership and management considerations. The physical environment includes elements such as layout, distractions, lighting, and noise. The external environment includes factors such as the payment and care delivery system, the legal environment, and the reporting environment. THE DIA All comp process \u2014 of health system p 2014). T h occur\u2014f o departm e includes technolo g the natu r the work detail in C A determi n clinician listen to y begins w verifies t are accu r medical h medicati o T communpatient's GNOSTIC P R onents of th \u2014e.g., a ch a IT, and a c h provides the here is a ra n or example, ents, inpatie the six com gies, organi z re of the co m system an d Chapters 4- 7 Acquiring a c ning a diagn o and the pat i your patient with an inter v hat the deta i rate. A patie n history, fam i ons (prescri p The process o ication, acti v needs, valu e ROCESS PREPUBL Ie work syst e ange in the p hange in th e context in w nge of settin g outpatient p nt hospital s ponents of a zation, phys mponents m a d how they a 7. C clinical hist o osis and als o ient. A com m , he is tellin g view of the p ils of the pa t nt's clinical ily history, s ption and o v of acquiring ve listening es, and pref e ICATION C Oem interact, physical env i e diagnostic t which the di a gs (i.e., wor k primary or s p settings, lon g a work syst e ical environ m ay differ am o re related t o Clinical Hi s ory and inter v establishes mon maxim g you the di a patient, whe n tient's histo r history incl u social histor y ver-the-coun t a clinical hi skills, and t a erences. Th e OPY: UNCO Rand each c o ironment m a team may a f agnostic pro c k systems) i pecialty car e g term care f em\u2014diagno s ment, tasks, ong and bet w o diagnosis a story and I n viewing a p a a solid fou n in medicine agnosis\" (G a n a clinician ry already c o udes docum e y, and other ter) and diet story and in t ailoring co m e National I n RRECTED P Romponent c a ay affect the ffect the as s cess occurs n which the e office setti n facilities, an stic team m e , ndation for t h attributed t o andhi, 2000, compiles a p ontained in t h entation of t h relevant in fo ary supple m terviewing a mmunication nstitute on A ROOFS an affect th e usefulness signment of t (Carayon e t diagnostic p ngs, emerg e d retail clini c embers, tool s al environm e gs. The six c stic error are des importa n he relations h o William O , p. 1087). A patient's m e he patient's he current c o formation, s u ments. a patient req u to the patie n ging, in gui d e diagnostic and access tasks. The w t al., 2006, process can ency cs. Each of t s and ent\u2014althou g component s described i n nt informati o hip between Osler is: \"Jus t An appointm e edical histor y medical rec o oncern, pas t uch as curre n uires effecti v nt based on t dance for 2-5 ibility work these gh s of n on for a t ent y or ord t nt ve the 2-6 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS conducting a history and interview, suggests that clinicians should avoid interrupting, demonstrate empathy, and establish a rapport with patients (NIA, 2008). Clinicians need to know when to ask more detailed questions and how to create a safe environment for patients to share sensitive information about their health and symp toms. Obtaining a history can be challenging in some cases, for example, in working with older a dults with memory loss, with children, or with individuals whose health problems limit communicat ion or reliable self-re porting. In these cases it may be necessary to include family members or caregivers in the history-taking process. The time pressures often involved in clinical appoi ntments also contribute to challenges in the clinical history and interview. Limited time for c linical visits, partially attributed to payment policies (see Chapter 7) may lead to an incomple te picture of a patient' s relevant history and current signs and symptoms. There are growing concerns that traditiona l \"bedside evaluation\" skills (history, interview, and physical exam) have received less attention due the large growth in diagnostic testing in medicine. Verghese and colleagues note d that the these methods were once the primary tools for diagnosis and clinical evaluation, but \"the recent explosion of imaging and laboratory testing has inverted the diagnos tic paradigm. [Clinicians] ofte n bypass the bedside evaluation for immediate testing\" (Verghese et al., 2011, p. 550). The interview ha s been called a clinician's most versatile diagnostic and th erapeutic tool, and the clinical history provides direction for subsequent information gathering activities in the diagnostic process (Lichstein, 1990). An accurate history facilita tes a more productive and efficient physical exam and the appropriate utilization of diagnostic testi ng (Lichstein, 1990). Indeed, Kass irer on a personal inte raction of a [clinician] with a patient, the sufficiency of communication between them, the accuracy of the patient's history and physical examination, and the cognitive energy necessary to synthesize a vast array of information\" (Kassirer, 2014, p. 12). Physical Exam The physical exam is a hands-on observationa l examination of the patient. First, a clinician observes a patient's demeanor, comple xion, posture, level of distress, and other signs that may contribute to an understanding of the health problem (Davies and Rees, 2010). If the clinician has seen the patient before, these observations can be wei ghed against previous interactions with the pa tient. A physical exam may include an analysis of many parts of the body, not just those suspected to be involved in the patient's current complaint. A careful physical exam can help a clinician refine the next steps in the diagnostic process, ca n prevent unnecessary diagnostic testing, and can aid in building trust with the patie nt (Verghese, 2011). There is no universally agreed upon physical examination checklist; myriad versions exist online and in textbooks. Due to the growing emphasis on diagnostic test ing, there are concerns that physical exam skills have been underemphasized in current health care professional education and training (Kassirer, 2014; Kugler and Ve rghese, 2010). For example, Kugler and Verghese have asserted that there is a high degree in va riability in the way that trainees elicit physical signs and that residency programs have not done enough to eval uate and improve physical exam techniques. Physicians at Stanford have developed the \"Sta nford 25,\" a list of physic al diagnostic maneuvers that are very technique-depe ndent (Verghese and Horwitz, 20 09). Educators observe students THE DIAGNOSTIC PROCESS 2-7 PREPUBLICATION COPY: UNCORRECTED PROOFS and residents performing these 25 maneuvers to ensu re that trainees are ab le to elicit the physical signs reliably (Stanford Me dicine 25 Team, 2015). Diagnostic Testing Over the past 100 years, diagnostic testing has become a critical feature of standard medical practice (Berger, 1999; European Soci ety of Radiology, 2010). Diagnostic testing may occur in successive rounds of information gathering, integra tion, and interpretation, as each round of information refines the working diagno sis. In many cases, diagnostic testing can identify a condition before it is clinically appare nt; for example, coronary artery disease can be identified by an imaging study indicating the pres ence of coronary artery blockage even in the absence of symptoms. The primary emphasis of this section fo cuses on laboratory medicine, anatomic pathology, and medical imaging (see Box 2-2). Ho wever, there are many important forms of diagnostic testing that extend beyond these fields, and the committee's conceptual model is intended to be broadly applicable. Aditional form s of diagnostic testing include, for example, screening tools used in maki ng mental health diagnoses (S AMHSA and HRSA, 2015), sleep apnea testing, neurocognitive assessment, and vision and hearing testing. Although it was developed specifically for labor atory medicine, the brain-to-brain loop model is useful for describing the general pro cess of diagnostic testi ng (Lundberg, 1981; Plebani et al., 2011). The model includes nine steps: test selection and orde ring, sample collection, patient identification, sample transportation, sample prepara tion, sample analysis, result reporting, result interpretation, and clinical action (Lundberg, 1981). These steps occur during five phases of diagnostic testing: pre-pre-analytic, pre-analytic, analytic, post-analytic, and post- post-analytic phases. Errors related to diagnostic testing can occur in any of these five phases, but the analytic phase is the least susceptible to errors (Eichbaum et al ., 2012; Stratton, 2011) 3). The pre-pre-analytic phase, which involves clin ician test selection and ordering, has been identified as a key point of vulnerability in the work process due to the large number and variety of available tests, which makes it difficult for non- specialist clinicians to accurately select the correct test or series of te sts (Hickner et al., 2014; Laposata and Dighe, 2007). The pre-analytic phase involves sample collec tion, patient identification, samp le transportation, and sample preparation. During the analytic phase, the specimen is tested, examined, or both. Adequate performance in this phase depends on the correct execution of a chemical analysis or morphological examination (Hollensead et al., 2004) , and the contribution to diagnostic errors at this step is small. The post-analytic phase includes the generation of results, reporting, interpretation, and follow-up. Ensuring timely and accurate reporting from the laboratory to the ordering clinician and patient is central to this phase. During the post-post-analytic phase, the ordering clinician, sometimes in consultation with pa thologists, incorporates the test results into the patient's clinical context, considers the probabili ty of a particular diagnos is in light of the test results, and considers the harms and benefits of future tests and trea tments, given the newly acquired information. Possible factors contributing to failure in this phas e include an incorrect interpretation of the test result by the ordering clinician or pathologist and the failure by the ordering clinician to act on the test results\u2014e.g., not ordering a follow- up test or not providing treatment consistent with th e test results (Hickner et al ., IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS The medical imaging work process parallels the work process described for pathology. There is a pre-pre-analytic phase (the selection and ordering of medical imaging), a pre-analytic phase (preparing the patient for imaging), an anal ytic phase (image acquisition and analysis), a post-analytic phase (the imaging results are inte rpreted and reported to th e ordering clinician or the patient), and a post-post-analyti c phase (the integration of resu lts into the patient context and further action). The relevant differences between the medical imaging and pathology processes include the nature of the examination and th e methods and technology us ed to interpret the results. BOX 2-2 Laboratory Medicine, Anatomic Pathology, and Medical Imaging Pathology is usually separated into two disciplines: laboratory medicine and anatomic pathology. Laboratory medicine, also referred to as clinical pathology, focuses on the testing of fluid specimens, such as blood or urine. Anatomic pathology addresses the microscopic examination of tissues, cells, or other solid specimens. Laboratory medicine is a medical subspecialty concerned with the examination of specific analytes in body fluids (e.g., cholestero l in serum, protein in urine, or glucose in cerebrospinal fluid), the specific identification of microorganisms (e.g., disease-causing bacteria in sputum, human immunodeficiency virus in blood, or parasites in stool), the analysis of bone marrow specimens (e.g., the identification of a specific of type of leukemia), and the management of transfusion therapy (e.g., cross-matching blood products, or plasmapheresis). Generally, clinical pathologists, except t hose with blood banking and coagulation expertise, do not interact directly with patients. Anatomic pathology is a medical subspecialty concerned with the testing of tissue specimens or bodily fluids, typi cally by specialists referred to as anatomic pathologists, to interpret results and diagnose diseases or health conditions. Some anatomic pathologists perform postmortem examinations (autopsies). Typically, anatomic pathologists do not interact directly with patients, with the notable exception of the performance of fine needle aspiration biopsies. Laboratory scientists, historically referred to as medical technologists, may contribute to this process by preparing and collecting samples and performing tests. Especially for laboratory medicine, the ordering of diagnostic tests and the interpretation of results are usually performed by the patient's treating clinician, although pathologists have much to offer in these areas. It is worth mentioning that with the advent of precision medicine, molecular diagnostic testing is not specifically aligned with either clinical or anatomic pathology (see Box 2-3). Medical imaging, also known as radiology, is a medical specialty that uses imaging technologies (such as X-ray, ultrasound, computed tomography [CT], magnetic resonance imaging [MRI], and positron emi ssion tomography [PET]) to diagnose diseases and health conditions. For many conditions, it is also used to select and plan treatments, monitor treatment effectiveness, and provide long-term follow up. Image interpretation is typically performed by radiologists or, for selected tests involving radioactive nuclides, nuclear medicine physicians. Technologists support the process by carrying out the imaging protocols. Most radiologists today have subspecialty training (e.g., in pediat ric radiology or neuroradiology), while the remainder (about 18 percent) are generalists (Bluth et al., 2014). Specialists in other clinical disciplines, such as emergency medicine physicians and cardiologists, may be trained and credentialed to perform and interpret certain ty pes of medical imaging. This can include imaging (such as ultrasound) to localize tissue targets during biopsy. A new subspecialty in radiology is molecular imaging, which involves the use of THE DIAGNOSTIC PROCESS 2-9 PREPUBLICATION COPY: UNCORRECTED PROOFS functional MRI techniques as well as MRI, PET/CT, or PET/MRI with molecular imaging probes. Several new molecular imaging probes have recently been approved for clinical use, and a growing number are entering clinical trials. The field of radiology also includes interventional radiology, which offers image-guided biopsy and diagnostic procedures as well as image-guided, minimally invasive treatments. Laboratory Medicine an d Anatomic Pathology In 2008 a CDC report described pathology as an \"essential element[s] of the health care system,\" stating that these di sciplines were \"integral to ma ny clinical deci sions, providing physicians, nurses, and other he alth care providers with ofte n pivotal information for the prevention, diagnosis, treatment, and management of disease\" (CDC, 2008, p. 19). Primary care clinicians order laboratory tests in slightly less than one thir d of patient visits (CDC, 2010; Hickner et al., 2014), and direct-to- patient testing is becoming incr easingly prevalent (Wolcott et al., 2008). There are now thousands of molecular di agnostic tests available, and this number is expected to increase as the mech anisms of disease at the mol ecular level are better understood (Johansen Taber et al., 2014; Wolc ott et al., 2008) (see Box 2-3). The task of selecting the appr opriate diagnostic testing is challenging for clinicians, in part because of the sheer volume of choices. Fo r example, Hickner and colleagues (2014) found that primary care clinicians report uncertainty in ordering laboratory medicine tests in approximately 15 percent of diagnostic encoun ters. Choosing the appropriate test requires understanding the patient's history and curren t signs and symptoms, as well as having a sufficient suspicion or pre-test probability of di sease or a condition (see section on probabilistic reasoning) (Pauker and Kassirer, 1975, 1980; Sox, 1986). The likelihood of disease is inherently uncertain in this step, e.g., the clinician's patient population may not reflect epidemiological data, and the patient's history can be incomplete or otherwise complicated. Advances in molecular diagnostic technologies and new have introduced another layer of complexity. Many clinicians are struggling to keep up with the gr owing availability of such tests, and have uncertainty about the best applic ation of these tests in screening, diagnosis, and treatment (IOM, 2015a; Johansen Taber et al., 2014). Diagnostic tests have \"operating parameters,\" including sensitivity and specificity that are particular to the diagnostic test for a spec ific disorder (see section below on probabilistic reasoning). Even if a test is performed correctly, there is a ch ance for a false positive or false negative result. Test interpretation involves review ing numerical or qualitativ e (yes or no) results and combining those results with patient histor y, symptoms, and pretest disease likelihood. Test interpretation needs to be patient-specific and to consider information learned during the physical exam and clinical history and interview. Severa l studies have highlight ed test interpretation errors, such as the misinterpretation of a fa lse positive human immunodeficiency virus (HIV) screening test for a low-risk pa tient as indicative of HIV infe ction (Gigerenzer, 2013; Kleinman et al., 1998). In addition, test performance may only be charact erized in a limited patient population, leading to challenges with generalizability (Whiting et al., 2004). 2-10 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS BOX 2-3 Molecular Diagnostics The President's Precision Medicine Initiative highlighted the growing interest in taking individual variability into account when defining disease, tailoring treatment, and improving prevention (NIH, 2015). This initiative hinges on recent advances in molecular and cellular biology, which have provided insights into the mechanisms of disease at the molecular level. These advances have contributed to the development of molecular diagnostic testing, which analyzes a patient's biomarkers in the genome or proteome. Concurrently, the role of pathology has expanded from morphologic observations into comprehensive analyses using combined histological, immunohistochemical, and molecular evaluations. The use of molecular diagnostics is a rapidly developing area. Molecular diagnostic tests are being developed and used to diagnose and monitor disease, assess risk, inform whether a particular therapy is likely to be effective in a specific patient, and predict a patient's response to therapy (AvaMedDx, 2013). Molecular diagnostic testing can identify a variety of specific genetic alterations relevant to diagnosis and treatment; molecular diagnostic techniques are also used to detect the genetic material of organisms caus ing infection. Panels of biomarkers are being developed into molecular diagnostic tests (omics-based tests) that are used to assess risk and inform treatment decisions, such as Oncoty pe DX and MammaPrint in breast cancer (IOM, 2012). Molecular diagnostic testing is expected to improve patient management and outcomes. The potential advantages of molecular diagnostics include: (1) providing earlier and more accurate diagnostic methods, (2) offering information about disease that will better tailor treatments to patients (3) reducing the occurrenc e of side effects from unnecessary treatments, (4) providing better tools to for the monitoring of patients for treatment success or disease recurrence, and (5) improving patient outcomes and quality of life. However, the translation of molecular diagnostic technologies into clinical practice has been a complex and challenging endeavor. Next generation sequencing technologies, for example, may frequently identify new genetic variants in which their impact on health outcomes is unknown (ACMG Board of Directors, 2012). One major challenge is the development and rigorous evaluation of molecular diagnostic tests bef ore their implementation in clinical practice. The development pathway is often time-consuming, expensive, and uncertain. In addition, there are underdeveloped and inconsistent standards of evidence for evaluating the scientific validity of tests and a lack of appropriate study designs and analytical methods for these analyses (IOM, 2007, 2010, 2012). Ensuring that diagnostic tests have adequate analytical and clinical validity is critical to preventing diagnostic errors. For example, in 2005 the Centers for Disease Control and Prevention and the Food and Drug Administration issued a warning about potential diagnostic errors related to false positives caus ed by contamination in a Lyme disease test (Nelson et al., 2014). As molecular diagnostic testing becomes increasingly complex (such as the movement from single biomarker tests to omics-based tests that rely on high-dimensional data and complex algorithms), there is considerable interest in ensuring their appropriate development and use (IOM, 2012). Molecular diagnos tic testing presents many regulatory, clinical practice, and reimbursement challenges; an Institute of Medicine study is looking into these issues and is expected to release a report in 2016 (IOM, 2015b). For example, one regulatory issue is the oversight of laboratory-developed tests, an area that has been met with considerable controversy (see Table 2-1) (Evans and Watson, 2015; Sharfstein, 2015). THE DIAGNOSTIC PROCESS 2-11 PREPUBLICATION COPY: UNCORRECTED PROOFS The laboratories that conduct diagnostic te sting are some of the most regulated and inspected areas in health care (s ee Table 2-1). Some of the rele vant entities include The Joint Commission and other accreditors, the federal government, and various other organizations, such as the College of American Pathologists (CAP) and American Society for Clinical Pathology. There are many ways in which quality is assesse d. Examples include proficiency testing of clinical laboratory assays a nd pathologists (e.g. Pap smear prof iciency testing), many of which are regulated under the Clinical Laboratory Im provement Amendments, and inter-laboratory comparison programs (e.g. CAP's Q-Probes, Q-Monitors, and Q-Tracks programs). TABLE 2-1 Examples of Entities Involved in Quality Improvement and Oversight of Clinical and Anatomic Laboratories Entity Role in Quality or Oversight Centers for Disease Control and Prevention (CDC) The CDC performs research on laboratory testing processes, including quality improvement studies, and develops tec hnical standards and laboratory practice guidelines (CDC, 2014). The CDC also manages the Clinical Laboratory Improvement Advisory Committee (CLIAC), a body that offers guidance to the federal government on quality improvement in the clinical laboratory and revising Clinical Laboratory Improveme nt Amendments (CLIA) standards. Centers for Medicare & Medicaid Services (CMS) CMS regulates laboratories under CLIA (CMS, 2015b). To ensure CLIA compliance, laboratories undergo review of results reporting, laboratory personnel credentialing (i.e., competency assessment), quality control efforts, and procedure documentation. Laborator ies are also required to perform proficiency testing (PT), a process in which a laboratory receives an unknown sample to test and report the findings back to the PT program, which evaluates the laboratory's performance. CMS grants states or accreditation orga nizations the authority to deem a laboratory as CLIA-compliant. In most cases the laboratory is deemed compliant by virtue of being accredited by the accreditation organization. Accreditation organizations with deeming authority for CLIA include The Joint Commission, the Healthcare Facilities Accreditation Program, and the College of American Pathologists. CMS also approves programs to perform PT. Food and Drug Administration (FDA) FDA reviews and assesses the safety, efficacy, and intended use of in vitro diagnostic tests (IVDs) (FDA, 2014a). FDA as sesses the analytical validity (i.e., analytical specificity and sensitivity, accuracy, and precision ) and clinical validity (i.e., the accuracy with which the test identifies, measures, or predicts the presence or absence of a clinical condition or predisposition), and it develops rules and guidance for CLIA complexity categorization. One subset of IVDs, laboratory developed tests (LDTs), has been granted enforcement discretion from FDA; in 2014 FDA stated its intent to begin regulating LDTs (FDA, 2014b). American Academy of Family Physicians (AAFP) The AAFP offers a number of CMS-approved PT programs (AAFP, 2015). 2-12 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS American Society for Clinical Pathology (ASCP) ASCP certifies medical laboratory professionals. ASCP also manages a CMS-approved PT program for gynecologic cytology (ASCP, 2014). College of American Pathologists (CAP) CAP accreditation ensures the safety and quality of laboratories and satisfies CLIA requirements. CAP also offers an inter-laboratory peer PT program (CAP, 2013, 2015). This program includes: Q-Tracks: a continuous quality monitoring process Q-Probes: a short-term study that provides a time slice assessment of performance Q-Monitors: customized programs that address process-, outcome-, and structure-oriented quality assurance issues Healthcare Facilities Accreditation Program (HFAP) HFAP accreditation ensures the safety and quality of laboratories and satisfies CLIA requirements (HFAP, 2015). The Joint Commission The Joint Commission accreditation ensures the safety and quality of laboratories and satisfies CLIA requireme nts (The Joint Commission, 2015). Medical Imaging Medical imaging plays a critical role in establishing the diagnoses for innumerable conditions and it is used routin ely in nearly every branch of medicine. The advancement of imaging technologies has improved the ability of clinicians to detect, diagnose, and treat conditions while also allowing pati ents to avoid more invasive procedures (European Society of Radiology, 2010; Gunderman, 2005). For many conditions (e.g., brain tumors), imaging is the only non-invasive diagnostic method available. The appropriate choice of imaging modality depends on the disease, organ, and specific clin ical questions to be addressed. Computed tomography (CT) and magnetic resonance imagi ng (MRI) are first-line methods for assessing conditions of the central and peri pheral nervous system, while fo r musculoskeletal and a variety of other conditions, X-ray and ultrasound are often employed first because of their relatively low cost and ready availability, with CT and MRI be ing reserved as problem-solving modalities. CT procedures are frequently used to assess and di agnose cancer, circulatory system diseases and conditions, inflammatory diseases, and head and internal organ injuries. A majority of MRI procedures are performed on the spine, brain, an d musculoskeletal system, although usage for the breast, prostate, abdominal, and pelv ic regions is rising (IMV, 2014). Medical imaging is characterized not just by the increasingly precise anatomic detail it offers, but also by an increasing capacity to illu minate biology. For example, magnetic resonance spectroscopic imaging has allowed the assessmen t of metabolism, and a growing number of other MRI sequences are offering information a bout functional characteristics, such as blood perfusion or water diffusion. In addition, severa l new tracers for molecular imaging with PET (typically as PET/CT) have recently been approved for clinical use, and more are undergoing clinical trials, while PET/MRI was recently intr oduced to the clinical setting. Functional and molecular imaging data may be assessed qualita tively, quantitatively, or both. Although other forms of diagnostic testing can identify a wide ar ray of molecular markers, molecular imaging is unique in its capacity to non-invasi vely show the locations of molecular processes in patients, THE DIAGNOSTIC PROCESS 2-13 PREPUBLICATION COPY: UNCORRECTED PROOFS and it is expected to play a critical role in a dvancing precision medicine, particularly for cancers, which often demonstrate both intra- and inter-tumoral biological hetero geneity (Hricak, 2011). The growing body of medical knowledge, the variety of imag ing options available, and the regular increases in the amounts and kinds of data that can be captured with imaging present tremendous challenges for radiologists, as no indi vidual can be expected to achieve competency in all of the imaging modalities. General radiologists continue to be essential in certain clinical settings, but extended training a nd sub-specialization are often n ecessary for optimal, clinically relevant image interpretation, as is involvement in multidisciplinary disease management teams. Furthermore, the use of structur ed reporting templates tailored to specific examinations can help to increase the clarity, thoroughness, and clinical relevance of im age interpretation (Schwartz et al., 2011). Like other forms of diagnos tic testing, medical imaging has limitations. Some studies have found that between 20 and 50 percent of a ll advanced imaging results fail to provide information that improves patient outcome, alt hough these studies do not account for the value of negative imaging results in infl uencing decisions about patien t management (Hendee et al., 2010). Imaging may fail to provide useful info rmation because of m odality sensitivity and specificity parameters; for example, the spatia l resolution of an MRI may not be high enough to detect very small abnormalities. Inadequate patient education and preparati on for an imaging test can also lead to suboptimal imaging quali ty that results in diagnostic error. Perceptual or cognitive errors made by radiologists are at times a source of diagnostic error (Berlin, 2014; Krupinski et al., 2012). In addition, incomplete or incorrect patient information, as well as insufficient sharing of pa tient information, may lead to the use of an inadequate imaging protocol, an in correct interpretation of imaging results, or the selection of an inappropriate imaging test by a referring clinic ian. Referring clinicians often struggle with selecting the appropriate imaging test, in part because of the large number of available imaging options and gaps in the teaching of radiology in medical schools. Although consensus-based guidelines (e.g., the various \"appropriateness cr iteria\" published by the American College of Radiology [ACR]) are available to help sel ect imaging tests for many conditions, these guidelines are often not followed. The use of clin ical decision support sy stems at the point of care as well as direct consultations with radiol ogists have been proposed by the ACR as methods for improving imaging test selection (Allen and Thorwarth, 2014). There are several mechanisms for ensuri ng the quality of medical imaging. The Mammography Quality Standards Act (MQSA)\u2014overseen by the Food and Drug Administration\u2014was the first government-manda ted accreditation progra m for any type of medical facility; it was focused on X-ray imag ing for breast cancer. MQSA provides a general framework for ensuring national quality standards in facilities that perform screening mammography (IOM, 2005). MQSA requires all personnel at facilities to meet initial qualifications, to demonstrate continued experience, and to complete continuing education. MQSA addresses protocol selection, image acquisition, interpretation and report generation, the communication of results, and recommendations. In addition, it provides facilities with data on diagnostic performance that can be used for benchmarking, self-monitoring, and improvement. MQSA has decreased the variab ility in mammography performed across the United States and improved the quality of care (Allen and Thorwa rth, 2014). However, the ACR noted that MQSA is complex and specified in great detail, which makes it inflexible, leading to administrative burdens and the need for extensive training of staff for implementation (Allen and Thorwarth, 2014). It also focuses on only one medical imaging modality in one disease area; thus it does not 2-14 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS address some of the new screening technologi es (IOM, 2005). The Medicare Improvements for Patients and Providers Act (MIPPA)3 requires that private outpatient facilities that perform CT, MRI, breast MRI, nuclear medicine, and P ET exams be accredited. The CMS requirements include personnel qualifications, image quality, e quipment performance, safety standards, and quality assurance and qualit y control (ACR, 2015a). Ther e are four CMS-designated accreditation organizations for medical imaging: ACR, The Joint Commission, the Intersocietal Accreditation Commission, and Ra dSite (CMS, 2015a). MIPPA also mandated that, beginning in 2017, ordering clinicians will be required to cons ult appropriateness criteri a to order advanced medical imaging procedures, and the act called for a demonstration project evaluating clinician compliance with appropriateness criteria (Timbie et al., 2014). In addition to these mandated activities, societies such as ACR and the Ra diological Society of North America (RSNA) provide quality improvement programs and resources (ACR, 2015b; RSNA, 2015). Referral and Consultation Clinicians may refer to or consult with other clinicians (formally or informally) to seek additional expertise about a patient's health proble m. The consult may help to confirm or reject the working diagnosis or may provide information on potential treatment options. If a patient's health problem is outside a clinician's area of e xpertise, he or she can refer their patient to a clinician who holds more suitable expertise. Clin icians can also recommend that the patient seek a second opinion from another clinician to verify their impressions of an uncertain diagnosis or if they believe that this would be helpful to the patient. Many groups raise awareness that patients can obtain a second opinion on their own (A MA, 1996; CMS, 2015c; PAF, 2012). Diagnostic consultations can also be arranged through the use of integrated practice units (IPUs) or diagnostic management teams (DMTs). IPUs ar e groups charged with providing care for a specific medical condition or a closely related se t of conditions (Porter, 2010). DMTs serve as a model for more closely involving pathologists and radiologists in the diagnostic process. DMTs can provide consultations on diagnostic testing, such as selecting the appropriate test or image and understanding these results (Gov ern, 2013). Both of these models are discussed in Chapter 4. IMPORTANT CONSIDERATIONS IN THE DIAGNOSTIC PROCESS The committee elaborated on several aspects of the diagnostic process: diagnostic uncertainty time population trends language, health liter acy, and culture mental health 3 Public Law 110-275 (July 15, 2008). THE DIAGNOSTIC PROCESS 2-15 PREPUBLICATION COPY: UNCORRECTED PROOFS Diagnostic Uncertainty One of the complexities in the diagnostic pro cess is the inherent uncertainty in diagnosis. As noted in the committee's conceptual model of the diagnostic process, an overarching question throughout the process is whether sufficient inform ation has been collected to make a diagnosis. This does not mean that a diagnosis needs to be ab solutely certain in order to initiate treatment. Kassirer concluded that: \"Absolute certainty in diagnosis is unatta inable, no matter how much information we gather, how many observations we make, or ho w many tests we perform. A diagnosis is a hypothesis about the nature of a patient's illness, one that is derived from observations by the use of inference. As the inferential proces s unfolds, our confidence as [clinicians] in a given diagnosis is enhanced by the gathering of data that either favor it or argue against competing hypotheses. Our task is not to attain certainty, but rather to reduce the level of diagnostic uncertainty enough to make optimal therapeutic decisions\" (Kassirer, 1989, p. 1489). Thus, the probability of disease does not have to be equal to one (diagnos tic certainty) in order for treatment to be justified (Pauker and Kassirer, 1980). The d ecision to begin treatment based on a working diagnosis is informed by: (1) the degree of certainty abou t the diagnosis, (2) the harms and benefits of treatment; and (3) the harms and benefits of further information gathering activities, including the impact of delaying treatment. The risks associated with diagnostic test ing are important considerations when conducting information gathering activities in the diagnostic process. While underuse of diagnostic testing has been a l ong-standing concern, overly aggressi ve diagnostic strategies have recently been recognized for their risks (see Chapte r 3) (Zhi et al., 2013). Overuse of diagnostic testing has been partially attributed to clin icians' fear of missing something important and intolerance of diagnostic uncertain ty: \"I am far more concerned about doing too little than doing too much. It's the scan, the test, the operation that I should have done that sticks with me\u2014 sometimes for years...By contrast, I can't remember anyone I sent for an unnecessary CT scan or operated on for questionable reasons a decade ago\" (Gawande, 2015). However, there is growing recognition that overly aggressive diagnostic pursuits are putting patients at greater risk for harm, and they are not improving diagnostic certainty (Kassirer, 1989; Welch, 2015). When considering diagnostic testing options, the harm from the procedure itself needs to be weighed against the potential information that could be gained. For some patients, the risk of invasive diagnostic testing may be inappropriate due to the risk of mortality or morbidity from the test itself (such as cardiac catheterization or inva sive biopsies). In addition, the risk for harm needs to take into account the cascade of dia gnostic testing and treatmen t decisions that could stem from a diagnostic test result. Included in these assessments are the potential for false positives and ambiguous or slightly abnormal test resu lts that lead to further diagnostic testing or unnecessary treatment. There are some cases in which treatment is initiated even though there is limited certainty in a working diagnosis. For example, an individua l who has been exposed to a tick bite or HIV may be treated with prophylactic antibiotics or antivirals, becaus e the risk of treatment may be felt to be smaller than the risk of harm from tick-borne diseas es or HIV infection. Clinicians sometimes employ empiric treatm ent strategies\u2014or the provision of treatment with a very 2-16 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS uncertain diagnosis\u2014and use a patient's respons e to treatment as an information gathering activity to help arrive at a work ing diagnosis. However, it is impor tant to note that response rates to treatment can be highly variable, and the failure to respond to treatment does not necessarily reflect that a diagnosis is inco rrect. Nor does improvement in th e patient's condition necessarily validate that the treatment conferred this benef it, and therefore that the empirically tested diagnosis, was in fact correct. A treatment that is beneficial for some patients might not be beneficial for others with the same condition (Kent and Hayward, 2007), he nce the interest in precision medicine, which is hoped to better ta ilor therapy to maximize efficacy and minimize toxicity (Jameson and Longo, 2015). In addition, th ere are isolated cases where the morbidity and the mortality of a diagnostic procedure and th e likelihood of disease is sufficiently high that significant therapy has been given empirically. Moroff and Pauker (1983) described a decision analysis in which a 90 year old practicing lawy er with a new 1.5 cm lung nodule was deemed to have a sufficiently high risk for mortality fr om lung biopsy and high likelihood of malignancy that the radiation oncologists fe lt comfortable treating the patient empirically for suspected lung cancer. Time Of major importance in diagnosis is the elemen t of time. Most diseas es evolve over time, and there can be a delay between the onset of disease and the onset of a patient's symptoms; time can also elapse before a patient 's symptoms are recognized as a specific diagnosis (Zwaan and Singh, 2015). Some diagnoses can be determined in a very short timeframe, while months may elapse before other diagnoses can be made. This is partially due to the growing recognition of the variability and complexity of disease presentati on. Similar symptoms may be related to a number of different diagnoses, and symptoms may evolve in different ways as a disease progresses, e.g., a disease affecting multiple organs may initially i nvolve symptoms or signs from a single organ. The thousands of different diseases and health conditions do not present in thousands of unique ways; there are only a finite num ber of symptoms with which a patient may present. At the outset, it can be very difficult to determine which particular diagnos is is indicated by a particular combination of symptoms, especial ly if symptoms are nonspecific, such as fatigue. Diseases may also present atypically, with an unusual and unexpected constellation of symptoms (Emmett, 1998). Adding to the complexity of the time-depe ndent nature of diagnosis are the numerous settings of care in which diagnosis occurs and the potential involvement of multiple settings of care within a single diagnostic process. Henriksen and Brady noted that this process\u2014for patients, their families, and clinicians alike\u2014can often feel like \"a disjointed journey across confusing terrain, aided or impe ded by different agents, with no destination in sight and few landmarks along the way\" (Henriksen and Brady, 2013, p. ii2). Some diagnoses may be more important to establish immediately than others. These include diagnoses that can lead to significant patient harm, if not r ecognized, diagnosed, and treated early, such as anthrax, aortic dissec tion, and pulmonary embolism. Sometimes making a timely diagnosis relies on the fast recognition of symptoms outside of the health care setting (for example, public awareness of stroke symptoms ca n help improve the speed of receiving medical help and increase the chances of a better recovery) (National Str oke Association, 2015). In these cases, the benefit of treating the disease promp tly greatly exceeds the potential harm from unnecessary treatment. Conseque ntly, the threshold for orderi ng diagnostic testing or for initiating treatment becomes quite low for such disorders (Pauker and Kassirer, 1975, 1980). In THE DIAGNOSTIC PROCESS 2-17 PREPUBLICATION COPY: UNCORRECTED PROOFS other cases, the potential harm from rapidly a nd unnecessarily treating a diagnosed condition can lead to a more conservative (or higher-threshol d) approach in the diagnostic process. Population Trends Population trends, such as the aging of the population, are adding significant complexity to the diagnostic process and require clinicians to consider complicati ng factors in diagnosis, such as comorbidity, polypharmacy and attendant me dication side effects as well as disease and medication interactions (IOM, 2008, 2013b). Diagnosis can be especially challenging in older patients because classic presentations of disease are less common in older adults (Jarrett et al., 1995). For example, infections such as pneumonia or urinary tract infections often do not present in older patients with fever, cough, and pain but rather with symptoms such as lethargy, incontinence, loss of appetite, or disruption of cognitive function (Mouton et al., 2001). Acute myocardial infarction (MI) may present with fatig ue and confusion rather than with typical symptoms such as chest pain or radiating arm pa in (Bayer et al., 1986; Qu reshi et al., 2000; Rich, 2006). Sensory limitations in older adults, such as hearing and vision impairments, can also contribute to challenges in making diagnoses (C ampbell et al., 1999). Physical illnesses often present with a change in cognitive status in older individuals without dementia (Mouton et al., 2001). In older adults with mild to moderate dementia, such illnesses can manifest with worsening cognition. Older patients who have multiple comorbidities, medications, or cognitive and functional impairments are more likely to have atypical disease presentations, which may increase the risk of experiencing diagnostic errors (Gray-Miceli, 2008). Language, Health Literacy, and Culture Communicating with diverse populations can al so contribute to the complexity of the diagnostic process. Language, heal th literacy, and cultural barriers can all affect clinician-patient encounters and increase the potential for challe nges in the diagnostic process (Flores, 2006; IOM, 2003; The Joint Commission, 2007). There are i ndications that biases influence diagnosis; one well-known example is the diffe rential referral of patients fo r cardiac catheterization by race and gender (Schulman et al., 1999). In addition, women are more likel y than men to experience a missed diagnosis of heart attack, a situation that ha s been partly attributed to real and perceived gender biases, but which may also be the resu lt of physiologic differen ces, as women have a higher likelihood of presenting with atypical symp toms, including abdominal pain, shortness of breath, and congestive heart fa ilure (Pope et al., 2000). Mental Health Mental health diagnoses can be particularly challenging. Mental hea lth diagnoses rely on the Diagnostic and Statistical Manual of Mental Disorders (DSM); each diagnosis in the DSM includes a set of diagnostic criteria that indicate the type and length of symptoms that need to be present, as well as the symptoms, disorders, and conditions that cannot be present, in order to be considered for a particular diagnosis (APA, 2015). Compared to physical diagnoses, many mental health diagnoses rely on patient reports and observation; there are few biological tests that are used in such diagnoses (Pincus, 2014). A key challenge can be distinguishing physical 2-18 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS diagnoses from mental health di agnoses; sometimes physical condi tions manifest as psychiatric ones, and vice versa (Croskerry, 2003a; Hope et al., 2014; Pincus, 2014; Reeves et al., 2010). In addition, there are concerns about missing psychi atric diagnoses, as we ll as overtreatment concerns (Bor, 2015; Meyer and Meyer, 2009; Pi ncus, 2014). For example, clinician biases toward older adults can contribute to misse d diagnoses of depression, because it may be perceived that older adults are likely to be depressed, lethargic, or have little interest in interactions. Patients with mental health-relat ed symptoms may also be more vulnerable to diagnostic errors, a situati on that is attributed partly to clin ician biases; for example, clinicians may disregard symptoms in patients with previous diagnoses of mental illness or substance abuse and attribute new physical symptoms to a psyc hological cause (Croskerry, 2003a). Individuals with health problems that are difficult to diagnos e or those who have chronic pain may also be more likely to receive psychiatric diagnoses erroneously. CLINICAL REASONING AND DIAGNOSIS Timely, accurate, and patient-centered diagnos is relies on proficiency in clinical reasoning, which is often regarded as the clin ician's quintessential competency. Clinical reasoning is the \"the cognitive process that is necessary to evaluate and manage a patient's medical problems\" (Barrows, 1980, p. 19). Understa nding the clinical reasoning process and the factors that can impact it are important to improving diagnosis, given that clinical reasoning processes contribute to diagnostic errors (Croskerry, 2003a; Graber, 2005). Health care professionals involved in the dia gnostic process have an obligati on and ethical responsibility to employ clinical reasoning skills: \"As an expandi ng body of scholarship further elucidates the causes of medical error, including the considerable extent to which medical errors, particularly in diagnostics, may be attributable to cognitive so urces, insufficient progress in systematically evaluating and implementing suggested strategi es for improving criti cal thinking skills and medical judgment is of mounting concern\" (Sta rk and Fins, 2014, p. 1). Clinical reasoning occurs within clinicians' minds (facil itated or impeded by the work system) and involves judgment under uncertainty, with a consideration of possibl e diagnoses that might explain symptoms and signs, the harms and benefits of diagnostic testin g and treatment for each of those diagnoses, and patient preferences and values. The current understanding of clinical reason ing is based on the dual process theory, a widely accepted paradigm of d ecision making. The dual process theo ry integrates analytical and non-analytical models of decision making (see Bo x 2-4). Analytical models (slow system 2) involve a conscious, deliberate process guided by critical thinking (Ka hneman, 2011). Non- analytical models (fast system 1) involve unconscious, intuitive, and automatic pattern recognition (Kahneman, 2011). THE DIAGNOSTIC PROCESS 2-19 PREPUBLICATION COPY: UNCORRECTED PROOFS BOX 2-4 Models of Clinical Reasoning Analytical models (slow system 2). Hypothetico-deductivism is an analytical reasoning model that describes clinical reasoning as hypothesis testing (Elstein et al., 1978, 1990). The steps involved in hypothesis testing include: 1. Cue acquisition: Clinicians obtain contextual information by taking a history, performing a physical examination, administering diagnostic tests, or consulting with other clinicians. 2. Hypothesis generation (working diagnoses): Clinicians formulate alternative diagnostic possibilities. 3. Cue interpretation (diagnostic modification and refinement): Clinicians interpret the consistency of the information with each of the alternative hypotheses under consideration. 4. Hypothesis evaluation (diagnostic verification): The data are weighed and combined to evaluate whether one of the working diagnoses can be confirmed. If not, further information gathering, hypothesis generation, interpretation, and evaluation is conducted until verification is achieved (Elstein and Bordage, 1988). These models have several additional characteristics. First, the generation of a set of hypotheses that occurs after cue acquisition fa cilitates the construction of a differential diagnosis, with evidence suggesting that the consideration of potential hypotheses prior to gathering information can improve diagnostic accuracy (Kostopoulou et al., 2015). Second, in order to supplement hypotheses retrieved from memory, some clinicians may employ clinical decision support tools. Third, the evolving list of diagnostic hypotheses determines subsequent information gathering activities (Kassirer et al., 2010). Fourth, the entire process involves, either explicitly or implicitly, clinicians assigning and updating the probability of each potential diagnosis, given the available data (Kassirer et al., 2010). This analytical model holds that clinical problem-solving tasks, such as diagnosis, require deliberate, logically sound reasoning by clinicians. Thus, clinical reasoning can be improved by developing the critical thinking ski lls (Papp et al., 2014). This model also implies that clinical reasoning uses the presence or absence of specific signs or symptoms to be evidence that either confirms or disproves a diagnosis. Studies have shown that clinicians do participate in analytical reasoning (Barrows et al., 1982; Elstein et al., 1978; Neufeld et al., 1981). However, studies also suggest that experi ence is crucial to the development of expertise and general problem-solving skills, such as hypothesis testing, cannot account for differences in clinical reasoning skills between experts and novices (Elstein and Schwarz, 2002; Groen and Patel, 1985; Neufeld et al., 1981; Norman, 2005). These findings support a role for non-analytical models of clinical reasoning and the importance of content knowledge and clinical experience. Non-analytical models (fast system 1). Broadly construed through a pattern-recognition framework, non-analytical models attempt to understand clinical reasoning through human categorization and classification practices. These models suggest that clinicians make diagnoses and choose treatments by matching presenting patients to previously stored mental models of diseases. Although the nature of these mental models remain under debate most assume that they are either exemplars (specific patients seen previously and stored in memory as concrete examples) or prototypes (an abstrac t disease conceptualization that weighs disease features according to their frequency) (Bordage and Zacks, 1984; Norman, 2005; Rosch and Mervis, 1975; Schmidt et al., 1990; Smith and Medin, 1981, 2002). Expert pattern matching by experienced clinicians may involve illness scripts, in which 2-20 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS elaborated disease knowledge includes enabling conditions or risk factors (e.g., physical contact with the Ebola virus); the pathophysiology of the disease (Ebola virus replication, invasion and destruction of endothelial surfaces); and the signs and symptoms of the disease (bleeding from Ebola) (Boshuizen and Schmidt, 2008). After encountering a patient, a clinician may activate a single, or multiple, illness scripts. As the diagnos tic process evolves, the clinician matches the activated scripts against the presenting signs and symptoms, with the best matching script offered as the most likely diagnosis. Illness scri pts differ from exemplars and prototypes by having more extensive knowledge stored for each disease. While exemplars, prototypes, and illness scrip ts are assumed to encode different types of information about disease conditions\u2014i.e., actual instances versus typical presentation versus multi-dimensional information\u2014pattern recognition models assume them to play the same role in diagnosis. Fast system 1 (non-analytical, intuitive) automatic processe s require very little working memory capacity. They are often triggered by stim uli or result from overlearned associations or implicitly learned activities.4 Examples of such system 1 processes include the ability to recognize human faces (Kanwisher and Yovel, 2006), the diagnosis of Lyme disease from a bull's-eye rash, or decisions based on heuristics (mental shortc uts), intuition, or repeated experiences. In contrast, slow system 2 (reflective, analytical) processing places a heavy load on working memory and involves hypothetical and counterfactual reasoning (Evans and Stanovich, 2013; Stanovich and Toplak, 2012). System 2 processi ng requires individuals to generate mental models of what should or should not happen in part icular situations, in or der to test possible actions or to explore alternat ive causes of events (Stanovich, 2009). Hypothetical thinking occurs when one reasons about what should occur or be observable if some condition held\u2014e.g., if this patient has diabetes, then the blood sugar level should exceed 126 mg/dl after an 8-hour fast, or if prescribed a diabetes medication, the suga r level should improve. Counterfactual reasoning occurs when one reasons about what should occur or be evident if the situation differed from how it actually is. The deliberate, conscious, and reflective nature of both hypothetical and counterfactual reasoning illustrates the analytical nature of system 2. Heuristics\u2014cognitive strategies or ment al shortcuts that are automatically and unconsciously employed\u2014are particularly impor tant for decision making (Gigerenzer and Goldstein, 1996). Heuristics can faci litate decision making but can al so McDonald, 1996). When a heuristic fa ils, it is referred to as a cogni tive bias. Cognitive biases, or predispositions to think in a way that leads to failures in judgment, can also be caused by affect and motivation (Kahneman, 2011). Pr olonged learning in a regular and predictable environment increases the successfulness of heuristics, wherea s uncertain and unpredictable environments are a chief cause of heuristic failure (Kahneman, 2011; Kahneman and Klein, 2009). There are many heuristics and biases that aff ect clinical reasoning and decisi on making (see Table 2-2 for medical and non-medical examples). Additional exam ples of heuristics and biases that affect decision making and the potential for diagnostic errors are described below (Croskerry, 2003b): The representativeness heuristic answers th e question, \"how likel y is it that this patient has a particular disease?\" by asse ssing how typical the patient's symptoms 4 The term \"system 1\" is an oversimplification because it is unlikely there is a single cognitive or neural system responsible for all intuitive, system 1 cognitive processes. THE DIAGNOSTIC PROCESS 2-21 PREPUBLICATION COPY: UNCORRECTED PROOFS are for that disease. If the symptoms are highly typical (e.g., fever and nausea after contact with an individual from We st Africa with Ebola virus), then it is likely the patient will be diagnosed as having that condition (e.g., Ebola virus infection). The representativeness bias re fers to the tendency to make decisions based on a typical case, even when this may lead to an incorrect judgment. The representativeness bias helps to explain why an incorrect dia gnosis (e.g., a patient diagnosed as not having Ebola virus infection) is made when presenting symptoms are atypical (e.g., no fever or na usea after contact with a person from West Africa). Base-rate neglect describes the tendency to ignore the prevalence of a disease in determining a diagnosis. For example, a c linician may think the diagnosis is acid reflux because it is a prevalent condition, even though it is actu ally an MI, which can present with similar symptoms (e .g., chest pain), but is less likely. The overconfidence bias reflects the unive rsal tendency to believe that we know more than we do. This bias encourages individuals to diagnose a disease based on incomplete information; too much faith is placed in one's opinion, rather than on carefully gathering evidence. This bias is es pecially likely to develop if clinicians do not have feedback on their diagnostic performance. Psych-out errors describe the increased susceptibility of people with mental illnesses to clinician biases and heuristics, due to their mental health conditions. Patients with mental health issues may have new physical symptoms that are not considered seriously because their clinicians attribute them to their mental health issues. Patients with physical symptoms that mimic mental illnesses (hypoxia, delirium, metabolic abnormalities, central nervous infections, and head injuries) may also be susceptible to these erro rs and experience diagnostic errors. Although the use of heuristics of ten leads to the corre ct diagnosis, it can fail, especially when patients present with atypi cal symptoms. In addi tion to cognitive biases, research suggests that fallacies in reasoning, ethica l violations, and financial and non- financial conflicts of interest can influence medical decision making (Seshia et al., 2014a, 2014b). These factors, collectively referred to as \"cognitive biases plus,\" have b een identified as potentially undermining the evidence that informs clinical deci sion making (Seshia et al., 2014a, 2014b). TABLE 2-2 Heuristics and Biases that Influence Decision Making Heuristic or Bias Medical Example Non-Medical Example Anchoring is the tendency to lock onto salient features in the patient's initial presentation and failing to adjust this initial impression in the light of later information. A patient is admitted from the emergency department with a diagnosis of heart failure. The hospitalists who are then taking care of the patient don't pay adequate attention to new findings that suggest another diagnosis We buy a new car based on excellent reviews and tend to ignore or downplay negative features that are noticed. Affective bias refers to the many different ways that our emotions, feelings, and biases affect judgment. New complaints from patients known to be \"frequent flyers\" in the emergency department aren't We may have the belief that people who are poorly dressed are not articulate or intelligent 2-22 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS taken seriously Availability bias refers to our tendency to more easily recall things that we've seen recently or things that are common or that impressed us A clinician who just recently read an article on the pain from aortic aneurysm dissection may tend toward diagnosing it in the next few patients he sees who present with non-specific abdominal pain, even though aortic dissections are rare Because of a recent news story on a tourist kidnapping in Country \"A,\" we change the destination we've chosen for our vacation to Country \"B\". Context errors reflect instances where we misinterpret the situation, leading to an erroneous conclusion. We tend to interpret that a patient presenting with abdominal pain has a problem involving the gastrointestinal tract, when it may be something else entirely, for example an endocrine, neurologic or vascular problem We see a work colleague picking up two kids from an elementary school and assume they have children, when they are instead picking up someone else's children. Search satisficing , also known as premature closure , is the tendency to accept the first answer that comes along that explains the facts at hand, without considering whether there might be a different or better solution. The emergency department clinician seeing a patient with recent onset of low back pain immediately settles on a diagnosis of lumbar disc disease without considering any other possibilities in the differential diagnosis We want a plane ticket that costs no more than $1,000 and has no more than one connection. We perform an online search and purchase the first ticket that meets these criteria without looking to see if there is a cheaper flight or one with no connections. The interaction between fast system 1 and sl ow system 2 remains controversial. Some hold that these processes are constantly occurring in parallel and that any conflicts are resolved as they arise. Others have argued that system 1 processes generate an individual's default response and that system 2 processes may or may not intervene and override system 1 processing (Evans and Stanovich, 2013; Ka hneman, 2011). When system 2 overrides system 1, this can lead to improved decision making, because engaging in analytical reasoning may correct for inaccuracies. It is important to note that slow system 2 processing does not guarantee correct decision making. For instance, clincians with an inadequate knowledge base may not have the information necessary to make a correct decisi on. There are some instances when system 1 processing is correct, and the override from sy stem 2 can contribute to incorrect decision making. However, when system 1 ov errides system 2 processing, this can also result in irrational decision making. Intervention by system 2 is lik ely to occur in novel situati ons when the task at hand is difficult, when an individual has minimal knowle dge or experience (Evans and Stanovich, 2013; Kahneman, 2011), or when an individual deliber ately employs strategies to overcome known biases (Croskerry et al., 2013). M onitoring and intervention by syst em 2 on system 1 is unlikely to catch every failure because it is inefficient and would require sustained vigilance, given that system 1 processing often leads to correct so lutions (Kahneman, 2011). Factors that affect working memory can impede the ability of syst em 2 to monitor and, when necessary, intervene THE DIA on syste m elements processi n S System 1 uncertai n perform s T (Crosker r colleagu e as they i t evolve t h FIGUR E presentin g initial dat to illness whereas imay eve n arrows st e processes decision m overrule s processes decision m making p r calibratio n SOURC E of bias a n GNOSTIC P R m 1 process e in the wor k ng needs to b ystem 1 an d 1 performs b n and irregu l s best in rela x This section a ry, 2009a, 2 es provide a terate throu g heir workin g E 2-2 The du g on the left a a include sy m scripts. If th e f they are no t ntually be rec o em from syst e are slow an d making. The e system 1 deci to ove rrule s maker may e m rocess. The m n of a clinici a E: Adapted by nd theory of d ROCESS PREPUBL Ies (Croskerr y k system, th e be reconsid e d system 2 p e est in highl y lar settings ( K xed and un h Du applies the d 009b; Nor m framework gh informati o g diagnoses ( al process m o and the result i mptoms and s i symptoms a n t recognized, ognized as a n em 1 process e d serial, only o executive ov e sion making. ystem 2 anal y mploy both f a manner in wh i an's diagnost i y permission f ebiasing. P. C ICATION C Oy, 2009b). F y may fail t o ered (Croske r erform opti m y reliable an d Kahneman a hurried envir ual Process T dual process man and Eva, for underst a on gatherin g (Figure 2-2) odel of diagn o ing diagnosis igns of illnes s nd signs of il l system 2 pro c new pattern a n es to depict i n one arrow ste erride pathwa y The irration a ytical decisio n ast system 1 a ich data are p r ic performan c from BMJ Pu b Croskerry, G. OPY: UNCO Ror example, o recognize w rry, 2009b). mally in diff e d predictabl e and Klein, 2 0 onments. Theor y and theory of cl i 2010; Pela c anding the c o g, informatio (Croskerry e ostic decisio n on the right. s, which can r lness are rec o cesses are us e nd subseque n ntuitive, fast, p ms from syst y shows that al override p a n making. T h and slow syst e rocessed thr o ce. blishing Gro u Rif clinician s when a deci erent types o e environm 009; Stanov i d Diagnosis inical reaso n et al., 2 0 ognitive acti v on integratio n et al., 2013) . n making, be g When a pati e range from si ognized, syst e ed. Repetitio n ntly processe d parallel deci s tem 1 process system 2 sur v athway show s he toggle arro em 2 process e ough system 1 up Limited. C d S. Mamede. ROOFS s are tired o r ison provide d of clinical p r ents but falls ich, 2009). S ning to the d 011). Crosk e vities that o c n, and inter p . ginning with a ent presents t o ingle charact e em 1 process e n of data to s y d through sys t sion making. ses, depicting veillance has s the capabili t ow (T) illustr a es throughou t 1 and system 2 Cognitive deb 22(Suppl 2): i r distracted b d by system ractice setti n short in System 2 diagnostic pr o erry and ccur in clini c pretation an d a patient o a clinician, eristics of dis e es are used, ystem 2 proc e tem 1. Multi p Because syst e analytical the potential ty for system ates how the t the decision 2 determines iasing 1: Ori g ii58-ii64. 20 1 2-23 by 1 ngs. ocess cians d the ease esses ple em 2 to 1 - the gins 13. 2-24 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS When patients present, clinicians gather information and compare that information with their knowledge about various diseases (exemplars, protot ypes, or illness scripts).5 This initial pattern matching is an instance of fast system 1 processing. If a sufficiently unique match occurs, then a diagnosis may be made w ithout involvement of system 2. However, some symptoms or signs may not be recognized (i.e., matched to a clinician's mental model for a disease), or they may trigger mental models for several diseases at once. When this happens, slow system 2 processing may be engaged, and the clinic ian will continue to gather, integrate, and interpret potentially re levant information until a working diagnosis is generated and communicated to the patient. When the information gathering, integration, and interpretation process triggers pattern matches for several diseas e mental models (i.e., stored disease constructs in memory), a differential diag nosis is developed. At th is point, the diagnostic process shifts to slow system 2 analytical r easoning. Based on their knowledge base, clinicians then use deductive reasoning : If this patient has disease A, wh at clinical history and physical examination findings might be expected, and doe s the patient have them? This process is repeated for each condition in the differential diagnosis and may be augmented by additional sources of information, such as diagnostic te sting, further history gathering or physical examination, or referral or consultation. The c ognitive process of reassessing the probability assigned to each potential diagnosis involves inductive reasoning6 in going from observed symptoms and signs to the likelihood of each disease to determine which hypothesis is most likely (Goodman, 1999). This can help refine a nd narrow the differential diagnosis. Further information gathering activities or treatment coul d provide greater certain ty regarding a working diagnosis or suggest that altern ative diagnoses be considered. Th roughout this process, clinicians need to communicate with patients about the wo rking diagnosis and the degree of certainty involved. Task complexity and expertise affect which cognitive system is dominantly employed in the diagnostic process. Novice clinicians and medical students are more likely to rely on analytical reasoning throughout the diagnostic pr ocess compared to experienced clinicians (Croskerry, 2009b; Elstein and Schwartz, 2002 ; Kassirer, 2010; Norman, 2005). Expert clinicians possess better developed mental models of diseases, which support more reliable pattern matching (system 1 processes) (Crosker ry, 2009b). System 1 processing is also more likely to be used when patients present with ty pical signs and symptoms of disease. However, slow system 2 processing is lik ely to intervene in situations marked by novelty and difficulty, when patients present with atypical signs and symptoms, or when clinicians lack expertise (Croskerry, 2009b; Evans and St anovich, 2013). As a clinician accumulates experience, the repetition of system 2 processing can expand pattern matching possibilities by building and storing in memory mental models for additiona l diseases that can be triggered by patient symptoms. The ability to create and develop mental models through repetition explains why expert clinicians are more likel y to rely on pattern recognition when making diagnoses than are novices or early practitioners\u2014cont inuous engagement with disease conditions allows the expert to develop more reliable mental models of disease conditions\u2014by retaining more exemplars, creating more nuanced prototypes, or developing more detailed illness scripts. 5 Stored mental models are the result of both analytical reasoning and expe rience since both can play a role in weighing the features of prototypes and/or matching examples to a category. 6 Inductive reasoning involves probabilistic reasoning (see the following section). THE DIA T inform a calibrati o limitatio n 4) and i n ultimate clinician s FIGURE feedback and lead t SOURC E W and task s the exter n includin g discusse s health I T factors. B also affe c GNOSTIC P R The way in w clinician's s on, or the pr o ns through fe n learning he diagnoses w s can assess 2-3 Calibrat i and improve to poor calibr a E: Adapted fr o Work syste m s, technolog i nal environ m g lighting, n o s how healt h T (including c Box 2-5 des c ct clinical r e ROCESS PREPUBL Iwhich infor m subsequent d ocess of a cl feedback. Fe e alth care sy s with the diag n their diagn o ion in the dia g clinician cali ation. om Croskerr y factors infl u ies and tool s ment. For ex oise, and la y h IT can imp r clinical dec i cribes how c easoning. ICATION C Omation is pro c diagnostic p e inician bec o edback mec h stems (Chap t noses that t h ostic accura c e diagn s, organizati o ample, Cha p yout, can inf l rove or deg 6)\u2014allo w hey provide d cy and impr o ess. Favorabl e en the outco m ostic t RRECTED P Rugh system 1 Figure 2-3 i e of his or h e oth in the e d w clinicians d to those pa t ove their fut u e or unfavora b me is unknow n ing, includi n eristics, the p bes how the cal reasonin g reasoning, d ation into cl i teristics of d ROOFS and syste m illustrates th e er diagnostic ducational s e to compare tients. Thro u ure perform a ble outcomes n, it will be tr e ng diagnosti c physical en v physical e n g. In additio n depending o n inical work fl diagnostic te m 2 processe s e concept o f abilities an d ettings (Cha p their patien t ugh calibrat i ance. provide goo d eated as favo r c team mem b vironment, a nvironment, n, Chapter 5 n the usabil i flow, and ot h am member 2-25 s f d pter ts' ion, d rable bers and 5 ity of her s can 2-26 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS BOX 2-5 Individual Characteristics that Influence Clinical Reasoning There are a number of individual characteristics that can affect clinical reasoning, including intelligence, age, gender, affect, physical state, and environment. Intelligence and knowledge Intelligence refers to individuals' abilities to engage in high-level cognitive tasks such as reasoning, problem solving, and decision making (Croskerry and Musson, 2009). High scores on intelligence tests indicate that an individual is adept at these cognitive tasks and is more likely to engage system 2 processes to monitor and, when necessary, override system 1 processing (Croskerry and Musson, 2009; Eva, 2002; Evans and Stanovich, 2013). Although intelligence that allows one to monitor and override system 1 processing is important, it rarely suffices by itself for good clinical reasoning. A sufficiently large knowledge base of both biological science and disease conditions is also important. The extent of a clinician's knowledge base depends on memory capacity and training, two factors that can vary among individual clinicians. Age It is likely that clinician age has an impact on clinical reasoning abilities (Croskerry and Musson, 2009; Eva, 2002; Singer et al., 2003; Sma ll, 2001). For instance, as clinicians age, they tend to have more trouble considering alternatives and switching tasks during the diagnostic process (Croskerry and Musson, 2009; Eva, 2002). Not all individuals experience cognitive or memory decline at the same rate or time, though many people start to experience moderate declines in analytical reasoning capacit y at some point in their 70s (Croskerry and Musson, 2009). Affect Affective factors such as mood and emotional state often play a role (both positive and negative) in clinical reasoning and decision making (Blanchette and Richards, 2009; Croskerry, 2002, 2004; Slovic and Peters, 2006; Vohs et al., 2007). When an obvious solution to a problem is not present, emotions may help direct people toward an outcome that is better than one that would be produced by random choice (Johnson-Laird and Oatley, 1992; Stanovich, 2009). Decision making guided by one's emotional response to a si tuation is decision making mediated by the affect heuristic (Slovic et al., 2002). In cases where precision is important or when an emotional response is unlikely to be a reliable indicator, the affect heuristic can lead to negative consequences. For instance, clinicians may unwittingly allow emotional responses toward their patients to guide their clinical reasoning, even though these feelings are an unreliable indicator of their patients' health problems. In these cases, the clinicians' reasoning is said to be subject to the affect bias (Croskerry et al., 2008). Affective states such as irritation and stress due to environmental conditions can also affect reasoning, primarily through decreasing the ability of system 2 processes to monitor and override system 1 processes (Croskerry et al., 2008, 2010). Experience Novices and experts employ different decision-making practices (Kahneman, 2011). Such differences also occur in the way that expert and novice clinicians reason about their patients' health problems (Eva et al., 2010). Expert nurses, for instance, have been found to collect a wider range of cues than their novice counterparts when diagnosing patients (Hoffman THE DIAGNOSTIC PROCESS 2-27 PREPUBLICATION COPY: UNCORRECTED PROOFS et al., 2009). Expert clinicians are more likley to rely on system 1 processing during the diagnostic process, while novice practioners and medical students rely more on conscious, explicit, linear analytical reasoning. Furthermore, expert clinicians are likely to be more accurate than novices when they employ system 1 processes because t hey have larger stores of developed mental models of disease conditions. While some have argued that experts are more susceptible to premature closure (i.e., accepting a diagnosis before it has been sufficiently verified), there is evidence that experience is more likely to lead to diagnostic flexibility than an explicit metacognitive rule requiring one to \"consider alternatives\" (Eva et al., 2010; Eva and Cunnington, 2006; McSherry, 1997). Personality, physical state, and gender Individual personality influences clinical reasoning and decision making (Croskerry and Musson, 2009). Arrogance, for instance, may lead to clinician overconfidence, a personality trait identified as a source of diagnostic error (Berner and Graber, 2008; Croskerry and Norman, 2008). Other personality traits, such as openness to experiences and agreeableness, could improve decision making in some individuals if it increases their openness to divergent views and feedback. A clinician's physical state can also influence reasoning. Fatigue and sleep deprivation have been found to impede system 2 processing interventions on system 1 processes (Croskerry and Musson, 2009; Zwaan et al., 2009). Additionally, some studies suggest that there are gender-specific effects associated with reasoning, including a male tendency towards risk-taking (Byrnes et al., 1999). Other studies have failed to replicate this proposed gender effect (Croskerry and Musson, 2009). Probabilistic (Bayesian) Reasoning As described above, the diagnostic process i nvolves initial informa tion gathering that leads to a working diagnosis or differential diag nosis. The process of ruling in or ruling out a diagnosis involves probabilistic re asoning as findings are integrated and interpreted. Probabilistic or Bayesian reasoning provides a formal method to avoid some cognitive biases, such as base rate neglect or anchoring, when integrating and interpreting information. For instance, when patients present with typical symp toms but the disease is rare (e.g., the classic triad of headache, sweating, and rapid heart rate for pheochr omocytoma), base rate neglect and the representativeness bias may lead clinicians to overestimate the likelihood of pheochromocytoma among patients presenting with high blood pressu re. Using Bayesian reasoning and formally revising probabilities of the various diseases und er consideration helps clinicians avoid these errors. Clinicians can then decide whether to pursue additional information gathering or treatment based an accurate estim ate of the likelihood of disease, the harms and benefits of treatment, and patient preferences (Kassire r et al., 2010; Pauker and Kassirer, 1980). Bayesian or probabilistic reasoni ng is most often considered in the context of diagnostic testing, but the presence or absenc e of specific symptoms and signs can also help to rule in or rule out diseases. The likelihood of a positive find ing (the presence of symptoms or signs or a positive test) when disease is present is referred to as sensitivity. The likelihood of a negative finding (the absence of symptoms, signs, or a negative test) when a disease is absent is referred to as specificity. If a symptom, sign, or test is always positive in the presence of a particular disease (100 percent sensitivity), then the absence of that symptom, sign, or test rules out disease (e.g., absence of pain or stiffness means the patie nt does not have polymyalgia rheumatica). If a 2-28 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS symptom, sign, or test is always negative in th e absence of a particular disease (100 percent specificity), then the presence of that symptom, sign, or test ru les in disease (e.g., all patients with Kayser-Fleischer rings have Wilson's dis ease; all patients with Koplik's spots have measles). However, nearly all signs, symptoms, or test results are neither 100 percent sensitive or specific. For example, studies suggest exceptions for findings such as Kayser-Fleischer rings with other causes of liver disease (Frommer et al., 1977; Lipman and Deutsch , 1990) or Koplik's spots with parvovirus B19 or echoviru s (Suringa et al., 1970) and for Reed- cells for Hodgkin' s lymphoma (Azar, 1975). Bayes' theorem provides a framework for clinicia ns to revise the probability of disease, given disease prevalence, as well as the presence or absence of clinical findings or positive or negative test results (Grimes and Schulz, 2005; Gr iner et al., 1981; Pauker and Kassirer, 1980). Bayesian calculators are av ailable to facilitate th ese probability revision analyses (Simel and Rennie, 2008). Box 2-6 works through two examples of probabilistic reasoning. While most clinicians will not formally calculate probabilities, the logical principles behind Bayesian reasoning can help clinicians consider the tr ade-offs involved in further information gathering, decisions about treatme nt, or evaluating clinically ambiguous cases (Kassirer et al., 2010). The committee's recomme ndation on improving diagnostic competencies includes a focus on diagnostic test ordering a nd subsequent decision making, which relies on the principles of proba bilistic reasoning. THE DIAGNOSTIC PROCESS 2-29 2-6 Examples of Probabilistic (Bayesian) Reasoning Suppose a clinician considers the possibility of Group A -hemolytic streptococcus (GABHS) infection in a patient presenting with pharyngitis (sore throat). The absence of nasal congestion occurs in 51 percent of patients with GABHS and in 42 percent of patients without GABHS (Centor et al.,1980). GABHS causes about 10 percent of acute pharyngitis, thus 90 percent of pharyngitis is not due to GABHS (e.g., viral) (Snow et al., 2001). The likelihood of having GABHS and the absence of nasal congestion is then 5.1 percent (51 percent of 10 percent) and of non-GABHS and the absence of nasal congestion is 37.8 percent (42 percent of 90 percent). Bayesian reasoning then calculates the likelihood of GABHS among those without nasal congestion to be 11.9 percent (5.1 percent divided by [5.1 percent plus 37.8 percent]). The absence of nasal congestion does not help distinguish GABHS from non-GABHS but does illustrate how the absence of a symptom can raise the probability of disease. However, fever occurs in 24 percent of those with GABHS and 11 percent of those without GABHS (Centor et al., 1980), so 2.9 percent have GABHS without nasal congestion but with fever (11.9 percent with GABHS without nasal congestion times 24 percent), whereas 9.7 percent have non-GABHS without nasal congestion but with fever (88.1 percent with non-GAHBS without nasal congestion times 11 percent). Thus among patients with an initial 10 percent chance of GABSH, the likelihood of GABHS rises to 23 percent in patients without nasal congestion but with fever (2.9 percent divided by [2.9 percent + 9.7 percent]). Consequently, fever is a distinguishing symptom; if present, it doubles the likelihood of GBHS, and, conversely, its absence would only reduce the likelihood of GBHS to 10.3 percent because it is not a very sensitive symptom (present in only 24 percent of patients with GABHS). The presence of three additional distinguishing symptoms (tonsillar exudates, no cough and swollen tender anterior cervical nodes) would raise the likelihood of GABHS to 70 percent, and if those three additional distinguishing symptoms were absent, the likelihood of GABHS would fall to 3 percent (Centor et al., 1980; Snow et al., 2001). To provide a second example, suppose a woman has a 0.8 percent risk of having breast cancer. Among women with breast cancer, a mammogram will be positive in 90 percent (sensitivity). Among women without breast cancer, a mammogram will be positive in 7 percent (false positive rate or 1 minus a specificity of 93 percent). If the mammogram is positive, what is the likelihood of this woman having breast canc er? Bayes' rule provides the answer. Among 1,000 women, 8 (0.8 percent of 1,000) will have breast cancer and about 7 (90 percent of 8) would have a true positive mammogram. Among the 992 without breast cancer, 69 (7 percent of 992) will have a false positive mammogram. Thus among the 76 women with a positive mammogram, 7\u2014or 9 percent \u2014will have breas t cancer. When a very similar question was presented to practicing physicians with an average 14 years of experience, their answers ranged from 1 percent to 90 percent, and very few answered correctly (Gigerenzer and Edwards, 2003). Thus, a better understanding of probabilistic reasoning can help clinicians apply signs, symptoms, and test results to subsequent decision making (such as refining or expanding a differential diagnosis, determining the likelihood that a patient has a specific diagnosis on the basis of a positive or negative test result, deciding whether retesting or ordering new tests is appropriate, or beginning treatment) (see Chapter 4). 2-30 A and treat m Rehm, 2 0 coupled w capacity 1956; O s report Be conclud e rate, pla c effective n diagnos e conditio n and arou n and dise a W 2-4), he a knowled g need to rcolleagu e recomm e evidenc e One of t h individu a resource s systemat in order t FIGURE Publicati o SOURC E THE DI A Advances in b ment, with a 013; Lee an d with clinici a to apply thi s stbye et al., 2 est Care Lo w ed that \"diag n cing new str e ness and ef f s illustrates ns categoriz e nd 13,000 i n ases added e With the rapi alth care pro f ge in their s p ead for an e s es (2003) fo u ended diagn o base and a r he ways that als to teams s and expert i ic reviews a n to inform cl i 2-4 Number ons have incr e E: IOM, 2013 a PREPUBL IAGNOSTI C biology and a deluge of i n d Levy, 201 2 an time cons t s new know l 2005; Tomb u wer Cost: T h nostic and t r esses on cli n ficiency of c a this comple x ed in the Na t n Internatio n very year ( M dly increasi n fessionals h a pecialties. F o stimated 62 7 und that A m ostic proces s re well-equi p this is acco m of health ca r ise to suppo r nd clinical p inical practi c of journal ar t eased steadil y a. ICATION C OC EVIDEN C medicine h a nnovations i 2). The risin traints and c ledge (IOM, u et al., 201 1 he Path to C o reatment op t nicians and p are delivery \" xity: There a tional Libra r nal Classific a Medicaid.go v ng number o ave difficult y or example, 7.5 hours pe r mericans rec e ses. Thus, cl pped to deli v mplished is t re professio n rt care (Gitt e practice gui d ce decision m ticles publis h y over 40 yea r IM OPY: UNCO RCE BASE A N ave led to i m in diagnosti c g complexit y cognitive li m 2011a, 201 3 1; Yarnall e t ontinuously L tions are ex p patients, as w \" (IOM, 201 are thousan d ry of Medici ation of Dis e v, 2015). of published y keeping u p to remain u p r month (Al p eive only ab o inicians nee ver care that through tea m nals, patient s ell et al., 20 1 delines (CP G making (IO M hed on health rs. MPROVING D RRECTED P RND CLINI C mprovement s c testing (IO M ty and sheer mitations, ha v 3a; Marois a t al., 2003). T Learning H e panding and well as pote n 3a, p. 10). T ds of disease ine's medic a ease 9th Edi t scientific a r p with the b r p to date, pr i per et al., 2 0 out half of r e d approach e reflects the m-based car e s can benefi t 10) (see Ch a Gs) help syn t M, 2011a, 2 0 care topics p e DIAGNOSIS I ROOFS CAL PRA C s in preventi o M, 2000, 2 0 volume of t h ve outstripp e and Ivanoff, The Institut e ealth Care i n changing at ntially impa c The sheer n u s and relate d al subjects h e tion, with n e rticles on he a readth and d e imary care c 004). McGl y ecommende d es to ensure t most up-to- d e; by movin g t from a bro a apter 4). In a thesize avail 011b). er year from 1 IN HEALTH C CTICE on, diagnos i 013a; Korf a n hese advanc ed human 2005; Mill e e of Medici n n America an accelera t cting the umber of pot e d health eadings syst e ew conditio n alth (see Fi g epth of clinicians w o ynn and d care, incl u they know t h date inform a g from ader set of ddition, able inform a 1970 to 2010CARE is, nd es, er, ne ting CPGs came into prominence partly in respons e to studies that f ound excessive variation in diagnostic and treatment-related care pract ices, indicating that in appropriate care was occurring (Chassin et al., 1987; IOM, 1990; Kos ecoff et al., 1987; Lin et al., 2008; Song et al., 2010). CPGs are defined as \"statements that include recommendations intended to optimize patient care that are informed by a systematic re view of the evidence and an assessment of the benefits and harms of alternat ive care options\" (IOM, 2011a, p. 4). CPGs can include diagnostic criteria for specific conditions as well as approaches to in formation gathering, such as conducting a clinical history and interview, the physical exam, diagnostic testing, and consultations. CPGs translate knowledge into clinical care decisions, and adherence to evidence-based guideline recommendations can improve health car e quality and patient outcomes (Bhatt et al., 2004; IOM, 2011a; Peterson et al., 2006). However, there have been a number of challenges to the development and use of CPGs in clinical practice (IOM, 2011a, 2013a, 2013b; Kahn et al., 2014; Timmermans and Mauck, 2005). Two of the prim ary challenges are th e inadequacy of the evidence base supporting CPGs and determining the applicability of guidelines for individual patients (IOM, 2011a; 2013b). For example, in patient-centered care, individual patient preferences for the possible hea lth outcomes may vary, and with the growing prevalence of chronic disease, patients often have comorbidities or competing causes of mortality that need to be considered. CPGs may not factor in these pa tient-specific variables (B oyd et al., 2005; Mulley et al., 2012; Tinetti et al., 2004). In addition, th e majority of scientific evidence about any diagnostic test typically is focuse d on test accuracy and not on the impact of the test on patient outcomes (Brozek et al., 2009; Tr ikalinos et al., 2009). This makes it difficult to develop guidelines that inform clinicians about the role of diagnostic tests within the diagnostic process and about how these tests can influence the path of care and health outcomes for a patient (Gopalakrishna et al., 2014; Hsu et al., 2011). Furthermore, diagnos is is generally not a primary focus of CPGs; diagnostic testing guidel ines typically account for a minority of recommendations and often have lower levels of evidence supporting them than treatment- related CPGs (Tricoci et al., 2009). The adopti on of available clini cal practice guideline recommendations into practice remains suboptimal, due to concerns about the trustworthiness of the guidelines as well as the ex istence of varying and conflicti ng guidelines (Ferket et al., 2011; Han et IOM, 2011a; Le nzer et al., 2013; Pronovost, 2013). Health care professional so cieties have also begun to develop appropriate use or appropriateness criteria as a way of synthesizing the available scie ntific literature and expert opinion to inform patient-specific decision making (Fitch et al., 2001). With the growth of diagnostic testing and substantial geographic variation in the utilization of th ese tools (due in part to the limitations in the evidence base supporting their use), hea lth care professional societies have developed appropriate use cr iteria aimed at better matching patients to specific health care interventions (Allen and Thorwa rth, 2014; Patel et al., 2005). Checklists are another approach that has been implemented to improve the safety of care by, for example, preventing health care-acquired infections or erro rs in surgical care. C hecklists have also been proposed to improve the diagnosti c process (Ely et al., 2011; Schiff and Leape, 2012; Sibbald et al., 2013). Developing checklists fo r the diagnostic process may be a significant undertaking; thus far, checklists have been developed for discrete, observable tasks, but the complexity of the diagnostic process, including the associated cognitive tasks, may represent a fundamentally different type of ch allenge (Henriksen and Brady, 2013). 2-32 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS REFERENCES AAFP (American Academy of Family Physicians). 2015. About the AAFP proficiency testing program. www.aafp.org/practice-management/labs/about.html (accessed May 15, 2015). ACMG Board of Directors. 2012. Poin ts to consider in the clinical application in genomic sequencing. Genetics in Medicine Quality & safety. www.acr.or g/Quality-Safety (accessed May 22, 2015). Allen, B., and W. T. Thorwarth. 2014. Comments from the American College of Radiology. Input submitted to the Committee on Diagnostic Error in Health Care, November 5, 2014, Washinton, DC. Alper, B., J. A. Hand, S. G. Elliott, S. Kinkade, M. J. Hauan, D. K. Onion, and B. M. Sklar. 2004. How much effort is needed to keep up with the literature relevant for primary care? Journal of the Medical Library Association 92(4):429-437. AMA (American Medical Association). 1996. AMA code of ethics. www.ama-assn.org/ama/pub/physician- resources/medical-ethics/code-medical-ethic s/opinion8041.page (acces sed March 22, 2015). APA (American Psychiatric Associatio n). 2015. DSM. www.psychiatry.org/p ractice/dsm (accessed May 13, 2015). ASCP (American Society for Clinical Pathol ogy). 2014. Patient access to test results. www.ascp.org/Advocacy/Patient-Access-to-T est-Results.html ( accessed 3-16-2015. AvaMedDx. 2013. Introduction to essentials of diagnostics series. http://advameddx.org/download/file s/AdvaMedDx_DxInsight s_FINAL(2).pdf (acces sed May 22, 2015). Azar, H. A. 1975. Significance of the Reed-Sternberg cell. Human Pathology 6(4):479-484. Barrows, H. S. 1980. Problem-based learning: An approach to medical education: New York: Springer. Barrows, H. S., G. R. Norman, V. R. Neufeld, and J. W. Feightner. 1982. The clinical reasoning of randomly selected physicians in general medical practice. Clinical & Investigative Medicine 5(1):49-55. Bayer, A. J., J. S. Chadha, R. R. Farag, and M. S. Pathy. 1986. Changing presentation of myocardial infarction with increasing old age. Journal of the American Geriatrics Society 34(4):263-266. Berger, D. 1999. A brief history of medical diagnosis and the birth of the clinical laboratory. Part 4\u2014Fraud and abuse, managed-care, and lab consolidation. Medical Laboratory Observer 31(12):38-42. Berlin, L. 2014. Radiologic errors, past, present and future. Diagnosis 1(1):79-84. Berner, E. S., and M. L. Graber. 2008. Overconfid ence as a cause of diagnostic error in medicine. The American Journal of Medicine 121(5):S2-S23. Bhatt, D. L., M. T. Roe, E. D. Peterson, Y. Li, A. Y. Chen, R. A. Harrington, A. B. Greenbaum, P. B. Berger, C. P. Cannon, D. J. Cohen, C. M. Gibson, J. F. Saucedo, N. S. Kleiman, J. S. Hochman, W. E. Boden, R. G. Brindis, W. F. Peacock, S. C. Smith , Jr., C. V. Pollack, Jr., W. B. Gibler, E. M. Ohman, and CRUSADE Investigators. 2004. Utilization of early invasive mana gement strategies for high-risk patients with non-ST- segment elevation acute coronary syndromes: Results from the CRUSADE Quality Improvement Initiative. JAMA 292(17):2096-2104. Blanchette, I., and A. Richar ds. 2009. The influence of affect on higher level cognition: A review of research on interpretation, judgement, decision making and reasoning. Cognition and Emotion 24(4):561-595. Bluth, E. I., H. Truong, and S. Bansal. 2014. The 2014 ACR Commission on Human Resources Workforce Survey. Journal of the American College of Radiology 11(10):948-952. Bor, J. S. 2015. Among the elderly, many mental illnesses go undiagnosed. Health Affairs (Millwood) 34(5):727- 731. Bordage, G., and M. Lemieux. 1991. Semantic structures and diagnostic thinking of experts and novices. Academic Medicine 66(9 Suppl):S70-S72. Bordage, G., and R. Zacks. 1984. The structure of medi cal knowledge in the memories of medical students and general practitioners: categories and prototypes. Medical Education 18(6):406-416. Boshuizen, H. P. A., and H. G. Schmidt. 2008. The develo pment of clinical reasoning expertise; Implications for teaching. In J. Higgs, M. Jones, S. Loftus, and N. Christensen (eds.), Clinical reasoning in the health prof essions (pp. 113-121). Oxford: Butterworth Heinemann/Elsevier. Boyd, C. C. Boult, L. P. Fried, L. Boult, and A. W. Wu. 2005 . Clinical practice guidelines and quality of care for older patients with multiple comorbid diseases: Implications for pay for performance. JAMA PROCESS 2-33 PREPUBLICATION COPY: J. L., E. A. Akl, R. Jaeschke, D. M. Lang, P. Bo ssuyt, P. M. Helfand, E. Ueffing, P. Alonso- Meerpohl, B. Phillips, A. R. Horvath, J. Bousquet, G. H. Gu yatt, H. J. Schunemann, and G. W. Group. 2009. Grading quality of evidence and strength of recommendations in clinical practice guidelines: Part 2 of 3. The GRADE approach to grading quality of evidence about diagnostic tests and strategies. Allergy 64(8):1109-1116. Byrnes, J. P., D. C. Miller, and W. D. Schafer. 1999. Gender differences in risk taking: A meta-analysis. Psychological Bulletin 125(3):367. Campbell, V.A., J. E. Crews, D. G. Moriarty, M. M. Zack, and D. K. Blackman. 1999. Surveillance for sensory impairment, activity limitation, and health-related quality of life among older adults\u2014United States, 1993-1997. Morbidity and Mortality Weekly Report 48(SS08):131-156. CAP (College of American Pathologists). 2013. Guide to CAP proficiency testing/external quality assurance for international participants. www.cap.org/apps/docs/pr oficiency_testing/cap_proficiency_testing_guide.pdf (accessed May 15, 2015). CAP. 2015. Proficiency testin g. www.cap.org/web/home/lab/pr oficiency-testing?_adf.ctrl- state=146u5nip6d_4&_afr Loop=77333689866130 Hundt, B. T. Karsh, A. P. Gurses , C. J. Alvarado, M. Smith, and P. Flatley Brennan. 2006. Work system design for patient safety: The SEIPS model. Quality & Safety in Health Care 15(Suppl 1):i50-i58. Carayon, P., T. B. Wetterneck, A. J. Rivera-Rodriguez, A. S. Hundt, P. Hoonakker, R. Holden, and A. P. Gurses. 2014. Human factors systems approach to healthcare quality and patient safety. Applied Ergonomics 45(1):14-25. CDC (Centers for Disease Control and Prevention). 2008. Laboratory medicine: A national status report. Falls Church, VA: The Lewin Group CDC. 2010. National hospital ambulatory medical care su rvey. Hyattsville, MD: Ambulatory and Hospital Care Statistics Branch, National Center for Health Statistics. CDC. 2014. Clinical Laboratory Im provement Amendments (CLIA). wwwn.cdc.gov/clia/ (accessed May 15, 2015). Centor, R. M., J. M. Witherspoon, H. P. Dalton, C. E. Brody, and K. Link. 1980. The diagnosis of strep throat in adults in the emergency room. Medical decision making: an international journal of the Society for Medical Decision Making 1(3):239-246. Chassin, M. R., J. Kosecoff, D. H. Solomon, and R. H. Brook. 1987. How coronary angiography is used: Clinical determinants of appropriateness. JAMA 258(18):2543-2547. CMS (Centers for Medicare & Medicaid Services). 20 15a. Advanced diagnostic imaging accreditation www.cms.gov/Medicare/Pr ovider-Enrollment-and- Certification/MedicareProviderS upEnroll/AdvancedDiagnos ticImagingAccreditation.html (accessed May 22, Laboratory Improvement Amendments (CLIA). www.cms.gov/Regulations-and- Guidance/Legislation/CLIA/index.html?red irect=/clia/ (accessed May 15,, 2015). CMS. 2015c. Getting a second opinion before surgery. www.medicare.gov/what-medicare-covers/part-b/second- opinions-before-sur gery.html (accessed March 30, 2015). Cosmides, L., and J. Tooby. 1996. Are humans good intuitive statisticians after all? Rethinking some conclusions from the literature on judgment under uncertainty. Cognition 58(1):1-73. Croskerry, P. 2000. The feedback sanction. Academic Emergency Medicine 7(11):1232-1238. Croskerry, P . 2003a. The Importance of cognitive er rors in diagnosis and strategies to minimize them. Academic Medicine 78(8):775-780. Croskerry, P. 2003b. Cognitive forcing strategies in clinical decisionmaking. Annals of Emergency Medicine 41(1), 110-120. Croskerry, P. 2009a. Clinical cognition and diagnostic error: Applications of a dual process model of reasoning. Advances in Health Sciences Education 14(Suppl 1):27-35. Croskerry, P. 2009b. A universal model of diagnostic reasoning. Academic Medicine 84(8):1022-1028. Croskerry, P., and D. Musson. 2009. Individual factors in patient safety. In P. Croskerry, K. S. Cosby, S. M. Schenkel, and R. L. Wears (eds.), Patient Safety in Emergency Medicine (pp.269-276). Philadelphia, PA: Lippincott, Williams & Wilkins. Croskerry, P., and G. Norman. 2008. Over confidence in clinical decision making. American Journal of Medicine 121(5 Suppl):S24-S29. Croskerry, P., A. A. Abbass, and A. W. Wu. 2008. How doctors feel: affective issues in patients' safety. Lancet 372(9645):1205-1206. 2-34 IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Croskerry, P., A. A. Abbass, and A. W. Wu. 2010. Emotional influences in patient safety. Journal of Patient Safety 6(4):199-205. Croskerry, P., G. Singhal, and S. Mamede. 2013. Cognitive debiasing 1: Origins of bias and theory of debiasing. BMJ Quality and Safety 22(Suppl 2):ii58-ii64. Davies, R. H., and B. Rees. 2010 . Include \"eyeballing\" the patient. BMJ 2010;340:c291. Eichbaum, Q., G. S. Booth, and P. S. Young (eds.). 2012. Transfusion medicine: Quality in laboratory diagnosis . Edited by M. Laposata. New York: Demos Medical. Elstein, A. S., and G. Bordage. 1988. Psychology of c linical reasoning. In J. Do wie and A. Elstein (eds.), Professional judgment: A reader in clinical decision making (pp. 109-129). New York: Cambridge University Press. Elstein, A. S., and A. Schwartz. 2002. Clinical problem solving and diagnostic decision making: Selective review of the cognitive literature. BMJ 324(7339):729-732. Elstein, A. S., L. Shulman, and S. Sprafka. 1978. Medical problem solving: An an alysis of clinical reasoning . Cambridge, MA: Harvard University Press. Elstein, A. S., L. S. Shulman, and S. A. Sprafka. 1990. Medical problem solving: A ten-year retrospective. Evaluation & the Health Professions 13(1): 5-36. Ely, J. W., M. L. Graber, and P. Croskerry. 2011. Checklists to reduce diagnostic errors. Academic Medicine 86(3):307-313. Emmett, K. R. 1998. Nonspecific and atypical presentation of disease in the older patient. Geriatrics 53(2):50-52, 58-60. Epner, P. L., J. E. Gans, and M. L. Graber. 2013. When diagnostic testing leads to harm: A new outcomes-based approach for laboratory medicine. BMJ Quality and Safety 22(Suppl 2):ii6-ii10. European Society of Radiology. 2010. The future role of radiology in healthcare. Insights into Imaging 1(1):2-11. Eva, K. W. 2002. The aging physician: Changes in cognitive processing and their impact on medical practice. Academic Medicine 77(10 Suppl):S1-S6. Eva, K. W., and J. P. W. Cunnington. 2006. The difficu lty with experience: Does practice increase susceptibility to premature closure? Journal of Continuing Education in the Health Professions 26(3):192-198. Eva, K., C. Link, K. Lutfey, and J. McKinlay. 2010. Sw apping horses midstream: Factors related to physicians changing their minds about a diagnosis. Academic Medicine 85:1112-1117. Evans, J. P., and M. S. Watson. 2015. Genetic testing and FDA regulation: Overregula tion threatens the emergence of genomic medicine. JAMA 313(7):669-670. Evans, J. S. B. T., and K. E. Stanovich. 2013. Dual-process theories of higher cognition: Advancing the debate. Perspectives on Psychological Science 8(3):223-241. FDA (Food and Drug Administration). 2014a. In vitro diagnostics. www.fda.gov/MedicalDevices/Produ ctsandMedicalProcedures/InVitroD iagnostics/default.htm (accessed May 15, 2015). FDA. 2014b. Laboratory developed tests. www.fda.gov/MedicalDevices/ProductsandMedicalProcedures/InVitroDiagnostics/ucm407296.htm (accessed May 15, 2015). Ferket, B. S., T. S. Genders, E. B. Colkesen, J. J. Visse r, S. Spronk, E. W. Steyerberg, and M. G. Hunink. 2011. Systematic review of guidelines on imaging of asymptomatic coronary artery disease. Journal of the American College of Cardiology 57(15):1591-1600. Fitch, K., S. J. Bernstein, M. D. Aguila r, B. Burnand, J. R. LaCalle, P. Lazaro, M. v. h. Loo, J. McDonnell, J. Vader, and J. P. Kahan. 2001. The RAND/UCLA appropriateness method user's manual. www.rand.org/pubs/mono graph_reports/MR1269 ( accessed May 13, 2015). Flores, G. 2006. Language barriers to health care in the United States. New England Journal of Medicine 355(3):229-231. Frommer, D., J. Morris, S. Sherlock, J. Abrams, and S. Newman. 1977. Kayser-Fleischer-like rings in patients without Wilson's disease. Gastroenterology 72 (6):1331-1335. Gandhi, J. S. 2000. Re: William Osler: A life in medicine: Book review. BMJ 321:1087. Gawande, A. 2015. Overkill. The New Yorker, May 11. www.newyorker.com/magazine/2015/05/11/overkill-atul- gawande (accessed July 13, 2015). Gigerenzer, G. 2000. Adaptive thinking: Rationality in the real world . New York: Oxford University Press. Gigerenzer, G. 2013. HIV screening: Helping clinic ians make sense of test results to patients. BMJ 347:f5151. Gigerenzer, G. 2014. Breast cancer screening pamphlets mislead BMJ 348:g2636. THE DIAGNOSTIC PROCESS 2-35 PREPUBLICATION COPY: UNCORRECTED PROOFS Gigerenzer, G., and A. Edwards. 2003. Simple tools for understanding risks: From innumeracy to insight. BMJ 327(7417):741-744. Gigerenzer, G., and D. G. Goldstein. 1996. Reasoning the fast and frugal way: Models of bounded rationality. Psychology Review 103:650-669. Gittell, J. H., R. Seidner, and J. Wimbush. 2010. A re lational model of how high-performance work systems work. Organization Science 21(2):490-506. Goodman, S. N. 1999. Toward evidence-based medical statistics. 1: The P value fallacy. Annals of Internal Medicine 130(12):995-1004. Gopalakrishna, G., R. A. Mustafa, C. Davenport, R. J. P. M. Scholten, C. Hyde, J. Brozek, H. J. Schunemann, P. M. M. Bossuyt, M. M. G. Leeflang, and M. W. Langendam. 2014. Applying Grading of Recommendations Assessment, Development and Evaluation (GRADE) to diagnostic tests was challenging but doable. Journal of Clinical Epidemiology 67(7):760-768. G\u00f8tzsche, P. C. 2012. Mammography screening: Truth, lies, and controversy. Lancet 380(9838):218. Govern, P. 2013. Diagnostic management efforts thrive on teamwork. Vanderbilt University Medical Center Reporter , March 7. http://news.vanderbilt.edu/2013/0 3/diagnostic-management-efforts-thrive-on- teamwork/ (accessed February 11, 2015). Graber, M. L. 2005. Diagnostic error in internal medicine. Archives of Internal Medicine 165(13): 1493-1499. Gray-Miceli, D. 2008. Modification of assessment and atypical presentation in older adults with complex illness. New York: The John A. Hartford Foundation Institute for Geriatric Nursing. Grimes, D. A., and K. F. Schulz. 2005. Refini ng clinical diagnosis with likelihood ratios. Lancet 365(9469):1500- 1505. Griner, P. F., R. J. Mayewski, A. I. Mushlin, and P. Greenl and. 1981. Selection and interpretation of diagnostic tests and procedures: Principles and applications. Annals of Internal Medicine 94(4 Pt 2):557-592. Groen, G. J., and V. L. Patel. 1985. Medical problem solving: Some questionable assumptions. Medical Education 19(2):95-100. Gunderman, R. B. 2005. The medical community's changing vision of the patient: The importance of radiology. Radiology 234(2):339-342. Han, P. K., C. N. Klabunde, N. Breen, G. Yuan, A. Gr auman, W. W. Davis, and S. H. Taplin. 2011. Multiple clinical practice guidelines for breast and cervical cancer screening: perceptio ns of U.S. primary care physicians. Medical Care 49(2):139-148. Hazen, E. P., C. J. McDougle, and F. R. Volkmar. 2013. Change s in the diagnostic criteria for autism in DSM-5: Controversies and concerns. Journal of Clinical Psychiatry 74(7):739-740. Hendee, W. R., G. J. Becker, J. P. Bo rgstede, J. Bosma, W. J. Casarella, B. A. Erickson, C. D. Maynard, J. H. Thrall, and P. E. Wallner. 2010. Addressing overutilization in medical imaging. Radiology 257(1):240-245. Henriksen, K., and J. Brady. 2013. The pursuit of better diagnostic performance: A human factors perspective. BMJ Quality and Safety 22(Suppl 2):ii1-ii5. HFAP (Healthcare Facilities Accred itation Program). 2015. Notice of HFAP approval by CMS. www.hfap.org/AccreditationPrograms/Labs CMS.aspx (accessed May 15,, 2015). Hickner, J., P. J. Thompson, T. Wilkinson, P. Epner, M. Sh aheen, A. M. Pollock, J. Lee, C. C. Duke, B. R. Jackson, and J. R. Taylor. 2014. Primary care physicians' challenges in orderi ng clinical laboratory tests and interpreting results. Journal of the American Board of Family Medicine 27(2):268-274. Hoffman, K. A., L. M. Aitken, and C. Duffield. 2009. A comparison of novice and expert nurses' cue collection during clinical decision-making: Verbal protocol analysis. International Journal of Nursing Studies 46(10):1335-1344. Hollensead, S. C., W. B. Lockwood, and R. J. Elin. 2004. Errors in pathology and laboratory medicine: Consequences and prevention. Journal of Surgical Oncology 88 (3):161-181. Holmboe, E. S., and S. J. Durning. 2014. Assessing clinical reasoning: Moving from in vitro to in vivo. Diagnosis 1(1): 111-117. Hope, C., N. Estrada, C. Weir, C. C. Teng, K. Damal, an d B. C. Sauer. 2014. Document ation of delirium in the VA electronic health record. BMC Research Notes 7:208. Hricak, H. 2011. Oncologic imaging: A guiding hand of personalized cancer care. Radiology 259(3):633-640. Hsu, J., J. L. Brozek, L. Terracciano, J. Kreis, E. Compal ati, A. T. Stein, A. Fiocchi, and H. J. Schunemann. 2011. Application of GRADE: Making ev idence-based recommendations about diagnostic tests in clinical practice guidelines. Implementation Science 6:62. 2-36 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS IMV. 2014. Ready for replacement? New IMV survey finds aging MRI scanner installed base. http://www.imvinfo.com/user/documents/content_documents/abt_prs/2014_02_03_16_51_22_809_IMV_ MR_Outlook_Press_Releas e_Jan_2014.pdf (acce ssed May 3, 2015). IOM (Institute of Medicine). 1990. Clinical practice guidelines: Directions for a new program . Washington, DC: National Academy Press. IOM. 2000. Medicare laboratory payment policy: Now and in the future . Washington, DC: National Academy Press. IOM. 2003. Unequal treatment: Confronting racial and ethnic disparties in health care . Washington, DC: The National Academies Press. IOM. 2005. Improving breast imaging quality standards . Washington, DC: The National Academies Press. IOM. 2007. Cancer biomarkers: The promises and challenges of improving detection and treatment . Washington, DC: The National Academies Press. IOM. 2008. Retooling for an aging America: Building the health care workforce . Washington, DC: The National Academies Press. IOM. 2010. Evaluation of biomarkers and surrogate endpoints in chronic disease . Washington, DC: The National Academies Press. IOM. 2011a. Clinical practice guidelines we can trust . Washington, DC: The National Academies Press. IOM. 2011b. Finding what works in health care : Standards for systematic reviews . Washington, DC: The National Academies Press. IOM. 2012. Evolution of translational omics: Lessons learned and the path forward . Washington, DC: The National Academies Press. IOM. 2013a. Best care at lower cost: The path to continuously learning health care in America. Washington, DC: The National Academies Press. IOM. 2013b. Delivering high-quality cancer care: Charting a new course for a system in crisis . Washington, DC: The National Academies Press. IOM. 2015a. Improving genetics education in graduate and continuing health professional education: Workshop summary. Washington, DC: The National Academies Press. IOM. 2015b. Policy issues in the clinical development and us e of biomarkers for molecularly targeted therapies. www.iom.edu/Activities/Research/BiomarkersforMolecularlyTargetedTherapies.aspx (accessed May 22, 2015). Jameson, J. L., and D. L. Longo. 2015. Precision medicine\u2014Personalized, problematic, and promising. New England Journal of Medicine 372(23): 2229-2234. Jarrett, P. G., K. Rockwood, D. Carver, P. Stolee, and S. Cosway. 1995. Illness presentation in elderly patients. Archives of Internal Medicine 155(10):1060-1064. Johansen Taber, K. A., B. D. Dickinson, and M. Wilson. 2014. The promise and challenges of next-generation genome sequencing for clinical care. JAMA Internal Medicine 174(2):275-280. Johnson-Laird, P. N., and K. Oatley. 1992. Basic emotions, rationality, and folk theory. Cognition & Emotion 6(3- 4):201-223. Jutel, A. 2009. Sociology of diagnosis: A preliminary review. Sociology of Health and Illness 31(2):278-299. Kahn, J. M., M. K. Gould, J. A. Krishnan, K. C. Wilson, D. H. Au, C. R. Cooke, I. S. Douglas, L. C. Feemster, R. A. Mularski, C. G. Slatore, and R. S. Wiener. 2014. An official American thoraci c society workshop report: Developing performance measures from clinical practice guidelines. Annals of the American Thoracic Society 11(4):S186-195. Kahneman, D. 2011. Thinking, fast and slow. New York: Farrar, Straus and Giroux. Kahneman, D., and G. Klein. 2009. Conditions fo r intuitive expertise: A failure to disagree. American Psychologist 64(6):515-526. Kanwisher, N., and G. Yovel. 2006. The fusiform face area: A cortical region specialized for the perception of faces. Philosophical Transactions of the Royal Society B: Biological Sciences 36 1(1476):2109-2128. Kassirer, J.P. 1989. Our stubborn quest for diagnostic certainty. A cause of excessive testing. The New England Journal of Medicine 320(22)1489-1491. Kassirer, J. P. 2010. Teaching clinical reasoning: Case-based and coached. Academic Medicine 85(7):1118-1124. Kassirer, J. P. 2014. Imperatives, expediency, and the new diagnosis. Diagnosis 1(1):11-12. Kassirer, J. P., J. Wong, and R. Kopelman. 2010. Learning clinical reasoning . Baltimore: Williams & Wilkins. Kent, D. M., and R. A. Hayward. 2007. Limitations of ap plying summary results of clinical trials to individual patients: The need for risk stratification. JAMA 298(10): 1209-1212. Klein, G. 1998. Sources of power: How people make decisions. Cambridge, MA: MIT Press. THE DIAGNOSTIC PROCESS 2-37 PREPUBLICATION COPY: UNCORRECTED PROOFS Kleinman, S., M. P. Busch, L. Hall, R. Thomson, S. Gl ynn, D. Gallahan, H. E. Ownby, and A. E. Williams. 1998. False-positive HIV-1 test results in a low-risk screening setting of voluntary blood donation: Retrovirus Epidemiology Donor Study. JAMA 280(12):1080-1085. Korf, B. R., and H. L. Rehm. 2013. New approaches to molecular diagnosis. JAMA 309(14):1511-1521. Kosecoff, J., M. R. Chassin, A. Fink, M. F. Flynn, L. Mc Closkey, B. J. Genovese, C. Oken, D. H. Solomon, and R. H. Brook. 1987. Obtaining clinical data on the appr opriateness of medical car e in community practice. JAMA 258(18):2538-2542. Kostopoulou, O., A. Rosen, T. Round, E. Wright, A. Douiri, and B. Delaney. 2015. Early diagnostic suggestions improve accuracy of GPs: A randomised controlled trial using computer-simulated patients. British Journal of General Practice 65(630):e49-54. Krupinski, E. A., K. S. Berbaum, R. T. Caldwell, K. M. Schartz, M. T. Madsen, and D. J. Kramer. 2012. Do long radiology workdays affect nodule detection in dynamic CT interpretation ? Journal of the American College of Radiology 9(3):191-198. Kugler, J., and A. Verghese. 2010. The physical exam and other forms of fiction. Journal of General Internal Medicine 25(8):756-757. Laposata, M. 2010. Coagulation disorders: Quality in laboratory diagnosis New York: Demos Laposata, M., \"post-post\" analytical error: High-incid ence patient safety hazards involving the clinical laboratory. Clinical Chemistry and Laboratory Medicine 45(6):712-719. Lee, D. W., F. Levy. 2012. The sharp slowdown in grow th of medical imaging: an early analysis suggests combination of policies was the cause. Health Affairs(Millwood) 31(8):1876-1884. Lenzer, J., J. R. Hoffman, C. D. Furberg, and J. P. Ioannidis, on behalf of the Guideline Panel Review Working Group. 2013. Ensuring the integrity of clinical practice guidelines: A tool for protecting patients. BMJ 347:f5535. Lichstein P. R. 1990. The medical interview. In H.K. Walker, W. D. Hall, and J.W. Hurst (eds.), Clinical Methods: The History, Physical, and Laboratory Examinations, 3rd edition . Boston: Butterworths. Lin, G. A., R. A. Dudley, F. L. Lucas, D. J. Malenka, E. Vittinghoff, and R. F. Redberg. 2008. Frequency of stress testing to document ischemia prior to elective percutaneous coronary intervention. JAMA 300(15):1765- 1773. Lipman, R. M., and T. A. Deutsch. 1990. A yellow-green posterior limbal ring in a patient who does not have Wilson's disease. Archives of Ophthalmology 108(10):1385-1385. Lipshitz, R., G. Klein, J. Orasanu, and E. Salas. 2001. Taking stock of naturalistic decision making. Journal of Behavioral Decision Making 14(5):331-352. Loewenstein, G., and J. S. Lerner. 2003. The role of affect in decision making. In R. J. Davidson, K. R. Scherer and H. H. Goldsmith (eds.), Handbook of affective sciences (pp. 619-642). New York: Oxford University Press. Lundberg, G. D. 1981. Acting on significant laboratory results. JAMA 245(17):1762-1763. Marois, R., and J. Ivanoff. 2005. Capacity lim its of information processing in the brain. Trends in Cognitive Sciences 9(6):296-305. McDonald, C.J. 1996. Medical heuristics: the silent adjudicators of clinical practice. Annals of Internal Medicine 124(1 Pt 1):56-62. McGlynn, E. A., S. M. Asch, J. Adams, J. Keesey, J. Hicks, A. DeCristofaro , and E. A. Kerr. 2003. The quality of health care delivered to adults in the United States. New England Journal of Medicine 348(26):2635-2645. McSherry, D. 1997. Avoiding premature closure in sequential diagnosis. Artificial Intelligence in Medicine 10(3):269-283. D-9.html (accessed June 23, 2015). Meyer, F., and T. D. Meyer. 2009. The misdiagnosis of bi polar disorder as a psychotic disorder: Some of its causes and their influence on therapy. Journal of Affective Disorders 112(1-3):174-183.Miller, G. A. 1956. The magical number seven plus or minus two: Some limits on our capacity for processing information. Psychological Review 63(2):81-97. Moroff, S. V., and S. G. Pauker. 1983. What to do when the patient outlives the literature. Medical Decision Making. 3(3): 313-338. Mouton, C. P., O. V. Bazaldua, B. Pierce, and D. V. Espino. 2001. Common infections in older adults. American Family Physician 63(2):257-268. Mulley, A. G., C. Trimble, and G. Elwyn. 2012. Stop the silent misdiagnosis: Patients' preferences matter. BMJ 2-38 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS National Stroke Association. 2015. Act FAST. www.stroke.org/understand-stroke/recognizing-stroke/act-fast (accessed May 14, 2015). Nelson, C., S. Hojvat, B. Johnson, J. Petersen, M. Schriefe r, C. B. Beard, L. Petersen, and P. Mead. 2014. Concerns regarding a new culture method for Borrelia burgdorferi not approved for the diagnosis of Lyme disease. Morbidity and Mortality Weekly Report 63(15):333. Neufeld, V., G. Norman, J. Feightner, and H. Barrows. 1981. Clinical problem solving by medical students: A crosssectional and longitudinal analysis. Medical Education 15(5):315-322. NIA (National Institute on Aging). 2008. A clinician's handbook: Talking with your older patient. Bethesda, MD: National Institutes of Health. Nichols, J. H., and C. A. Rauch (eds.). 2013. Clinical chemistry . New York: Demos Medical. NIH (National Institutes of Health). 2015. Precision Medicine Initiative. ww w.nih.gov/precisionmedicine/ (accessed May 22, 2015). Norman, G. R. 2005. Research in clinical reasoning: Past history and current trends. Medical Education 39(4):418- 427. Norman, G. R., and K. W. Eva. 2010. Di agnostic error and clinical reasoning. Medical Education 44(1):94-100. Ostbye, T., K. S. Yarnall, K. M. Krause, K. I. Pollak, M. Gradison, and J. L. Mich ener. 2005. Is there time for management of patients with chronic diseases in primary care? Annals of Family Medicine 3(3):209-214. PAF. 2012 . Second opinions . www.patientadvocat e.org/help.php/index.php?p=691 (accessed March 30, 2015). Papp, K. K., G. C. Huang, L. M. Lauzon Clabo, D. Delva, M. Fischer, L. Konopasek, R. M. Schwartzstein, and M. Gusic. 2014. Milestones of critical thinking: A developmental model for medicine and nursing. Academic Medicine 89(5):715-720. Parasuraman, R., T. B. Sheridan, and C. D. Wickens. 2000. A model for types and levels of human interaction with automation. IEEE Transactions on Systems, Man and Cybernetics--Part A: Systems and Humans 30(3):286-297. Patel, M. R., J. A. Spertus, R. G. Brindis, R. C. Hendel, P. S. Douglas, E. D. Peterson, M. J. Wolk, J. M. Allen, and I. E. Raskin. 2005. ACCF proposed method for evaluating the appropriateness of cardiovascular imaging. Journal of the American College of Cardiology 46(8):1606-1613. Pauker, S. G., and J. P. Kassirer. 1975. Therap eutic decision making: A cost-benefit analysis. New England Journal of Medicine 293(5):229-234. Pauker, S. G., and J. P. Kassirer. 1980. The th reshold approach to clinical decision making. New England Journal of Medicine 302(20):1109-1117. Pelaccia, T., J. Tardif, E. Triby, an d B. Charlin. 2011. An analysis of c linical reasoning through a recent and comprehensive approach: The dual-process theory. Medical Education Online , March 14: 16. Peterson, E. D., M. T. Roe, J. Mulgund, E. R. DeLong, B. L. Lytle, R. G. Brindis, S. C. Smith, Jr., C. V. Pollack, Jr., L. K. Newby, R. A. Harrington, W. B. Gibler, and E. M. Ohman. 2006. Association between hospital process performance and outcomes among patients with acute coronary syndromes. JAMA 295(16):1912- 1920. Pincus, H. 2014. Diagnostic error: Issues in behavioral health. Presentation to the Committee on Diagnostic Error in Health Care, November 6, 2014, Washington, DC. Plebani, M., and G. Lippi. 2011. Closing the brain-to-brain loop in laboratory testing. Clinical Chemistry and Laboratory Medicince 49(7):1131-1133. Plebani, M., M. Laposata, and G. D. Lu ndberg. 2011. The brain-to-brain loop concept for laboratory testing 40 years after its introduction. American Journal of Clinical Pathology 136(6):829-833. Pope, J. H., T. P. Aufderheide, R. Ruthazer, R. H. Woolard, J. A. Feldman, J. R. Beshans ky, J. L. Griffith, and H. P. Selker. 2000. Missed diagnoses of acute cardiac ischemia in the emergency department. New Eng land Journal of Medicine 342(16):1163-1170. Porter, M. E. 2010. What is value in health care? New England Journal of Medicine 363(26):2477-2481. Pronovost, P. J. 2013. Enhancing physicians' use of clinical guidelines. JAMA 310(23):2501-2502. Qureshi, A. M., L. McDonald, and W. R. Primrose. 2000. Management of myocardial infarction in the very elderly\u2014Impact of clinical effectiveness on practice. Scottish Medical Journal 45(6):180-182. Reeves, R. R., J. D. Parker, R. S. Burke, and R. H. Hart. 2010. Inappropriate psychiatric admission of elderly patients with unrecognized delirium. Southern Medical Journal 103(2):111-115. Rich, M. W. 2006. Epidemiology, clinical features, and prognosis of acute my ocardial infarction in the elderly. American Journal of Geriatric Cardiology 15(1):7-11; quiz 12. Rosch, E., and C. B. Mervis. 1975. Family resemblan ces: Studies in the internal structure of categories. Cognitive Psychology 7(4):573-605. THE DIAGNOSTIC PROCESS 2-39 PREPUBLICATION COPY: UNCORRECTED PROOFS Rosenberg, C. E. 2002. The tyranny of diagnosis: Specific entities and individual experience. Milbank Quarterly 80(2):237-260. RSNA (Radiological Society of North America). 2015. QI tools . http://www.rsna.org/QI_Tools.aspx (accessed May 22, 2015). SAMHSA (Substance Abuse and Mental Health Services Administration) and HRSA (Health Resources and Services Administration). 2015. Screening tools. www.integration.samhsa.gov/clinical-practice/screening- tools (accessed May 22, 2015). Sarter, N. 2014. Use(r)-centered design of health IT: Challenges and lessons learned. Presentation to the Committee on Diagnostic Error in Health Care, August, 7, 2014, Washington, DC. Schiff, G. D., and L. L. Leape. 2012. Commentary: How can we make diagnosis safer? Academic Medicine 87(2):135-138. Schmidt, H. G., G. R. Norman, and H. P. A. Boshuizen. 1990. A cognitive perspective on medical expertise: Theory and implications. Academic Medicine 65:611-621. Schulman, K. A., J. A. Berlin, W. Harless, J. F. Kerner, S. Sistrunk, B. J. Gersh, R. Dube, C. K. Taleghani, J. E. Burke, S. Williams, J. M. Eisenberg, and J. J. Escar ce. 1999. The effect of r ace and sex on physicians' recommendations for cardiac catheterization. New England Journal of Medicine 340(8):618-626. Schwartz, L. H., D. M. Panicek, A. R. Berk, Y. Li, and H. Hricak. 2011. Improving communication of diagnostic radiology findings through structured reporting. Radiology 260(1):174-181. Seshia, S. S., M. Makhinson, D. F. Phillips, and G. B. Young. 2014a. Evidence informed person centered healthcare (part I): Do \"cognitive biases plus\" at organizational levels influence quality of evidence? Journal of Evaluation in Clinical Practice 20(6):734-747. Seshia, S. S., M. Makhinson, and G. B. Young. 2014b. Evidence informed person centred health care (part II): Are \"cognitive biases plus\" underlying the EBM paradigm responsible for undermining the quality of evidence? Journal of Evaluation in Clinical Practice 20(6):748-758. Sharfstein, J. 2015. FDA regulation of la boratory-developed diagnostic tests: Protect the public, advance the science. JAMA 313(7):667-668. Sibbald, M., A. B. de Bruin, and J. J. van Merrienboer. 2013. Checklists improve experts' diagnostic decisions. Medical Education 47(3):301-308. Simel, D., and D. Rennie. 2008. The rational clinical examination: Evidence-based clinical diagnosis . McGraw Hill Professional. Singer, T., P. Verhaeghen, P. Ghisletta, U. Lindenberger, and P. B. Baltes. 2003. The fate of cognition in very old age: Six-year longitudinal findings in the Berlin Aging Study (BASE). Psychology and Aging 18(2):318- 331. Slovic, P., and E. Peters. 2006. Risk perception and affect. Current Directions in Psychological Science 15(6):322- 325. Slovic, P., M. L. Finucane, E. Peters, and D. G. MacGregor. 2002. Rational actors or rational fools: Implications of the affect heuristic for behavioral economics. Journal of Socio-Economics 31(4):329-342. Slovic, P., M. L. Finucane, E. Peters, and D. G. MacGrego r. 2004. Risk as analysis and risk as feelings: Some thoughts about affect, reason, risk, and rationality. Risk Analysis 24(2):311-322. Small, S. A. 2001. Age-related memory declin e: Current concepts and future directions. Archives of Neurology 58(3):360-364. Smith, E. E., and D. L. Medin. 1981. Categories and concepts . Cambridge, MA: Harvard University Press. Smith, E. E., and D. L. Medin. 2002. The exemplar view. In D. J. Levitin (ed.), Foundations of cognitive psyc hology: Core readings (pp. 277-292). Cambridge, MA: Bradford. Smith, M. B., and P. C. Sainfort. 1989. A balance theory of job design for stress reduction. International Journal of Industrial Ergonomics 4(1):67-79. Snow, V., C. Mottur-Pilson, R. J. Cooper, and J. R. Hoffman . 2001. Principles of approp riate antibiotic use for acute pharyngitis in adults. Annals of Internal Medicine 134(6):506-508. Song, Y., J. Skinner, J. Bynum, J. Sutherland, J. E. We nnberg, and E. S. Fisher. 2010. Regional variations in diagnostic practices. New England Journal of Medicine 363(1):45-53. Sox, H. C., Jr. 1986. Probability theory in the use of di agnostic tests. An introduction to critical study of the literature. Annals of Internal Medicine 104(1):60-66. Stanford Medicine 25 Team. 2015. St anford medicine 25. http://stanfordmedicine25.stan ford.edu/about/ (accessed July 27, 2015). Stanovich, K. E. 2009. Decision making and rationality in the modern world . New York: Oxford. 2-40 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Stanovich, K. E., and M. E. Toplak. 2012. Defining features versus incidental correlates of Type 1 and Type 2 processing. Mind & Society 11(1):3-13. Stark, M., and J. J. Fins. 2014. The ethical imperative to think about thinking\u2014Dia gnostics, metacognition, and medical professionalism. Cambridge Quarterly of Healthcare Ethics 23(4):386-396. Stratton, C. W. 2011. Clinical microbiology: Quality in laboratory diagnosis . New York: Demos Medical. Suringa, D. W. R, L. J. Bank, and A. B. Ackerman. 1970. Role of measles virus in skin lesions and Koplik's spots. New England Journal of Medicine 283(21):1139-1142. The Joint Commission. 2007. \"What did the doctor say?\" Improving health literacy to protect patient safety. www.jointcommission.org/What_Did_the_Doctor_Say/default.aspx (accessed May 11, 2015). The Joint Commission. 2 015. Eligibility for labo ratory accreditation. www.jointcommission.org/eligibility_f or_laboratory_accreditation/defaul t.aspx (accessed May 15,, 2015). Timbie, J. W., P. S. Hussey, L. F. Burgette, N. S. Wenger, A. Rastegar, I. Brantely, D. Khodyakov, K. J. Leuschner, B. A. Weidmer, and K. L. Kahn. 2014. Medicare imaging demonstration final evaluation: Report to Congress . Santa Monica, CA: RAND. Timmermans, S., and A. Mauck. 2005. The promises and pitfalls of evidence-based medicine. Health Affairs (Millwood) 24(1):18-28. Tinetti, M. E., S. T. Bogardus, Jr., an d J. V. Agostini. 2004. Potential pitf alls of disease-specific guidelines for patients with multiple conditions. New England Journal of Medicine 351(27):2870-2874. Tombu, M. N., C. L. Asplund, P. E. Dux, D. Godwin, J. W. Martin, and R. Marois. 2011. A unified attentional bottleneck in the human brain. Proceedings of the National Academies of Sciences USA 108(33):13426- 13431. Tricoci, P., J. M. Allen, J. M. Kram er, R. M. Califf, and S. C. Smith, Jr. 2009. Scientific evidence underlying the ACC/AHA clinical practice guid elines.[Erratum appears in JAMA, 2009, 301(15):1544]. JAMA 301(8):831-841. Trikalinos, T. A., U. Siebert, and J. Lau. 2009. Decision-analytic modeling to evaluate benefits and harms of medical tests: Uses and limitations. Medical Decision Making 29(5):E22-29. Verghese, A. 2011. Treat the patient, not the CT scan. The New York Times, February 26. http://www.nytimes.com/2011/02/ 27/opinion/27verghese.html (accessed August 5, 2015). Verghese, A., and R. I. Horwitz. 2009. In praise of the physical examination. BMJ 339:b5448. Verghese, A., E. Brady, C. C. Kapur, and R. I. Horwitz. 2011. The bedside evaluation: ritual and reason. Annals of Internal Medicine 155(8):550-553. Vohs, K. D., R. F. Baumeister , and G. Loewenstein. 2007. Do emotions help or hurt decision making? A hedgefoxian perspective . New York: Russell Sage Foundation. Welch, H. G. 2015. Less medicine more health: 7 assumptions that drive too much medical care . Boston, MA: Beacon Press. WHO (World Health Organization). 2012. International classification of diseases (ICD) . Geneva: World Health Organization. Whiting, P., A. W. S. Rutjes, J. B. Reltsma, A. S. Gl as, P. M. M. Bossuyt, and J. Kleljnen. 2004. Sources of variation and bias in studies of diagnostic accuracy. Annals of Internal Medicine 140(3): 189-202. Yarnall, K. S., K. I. Pollak, T. Ostbye, K. M. Krause, an d J. L. Michener. 2003. Primar y care: Is there enough time for prevention? American Journal of Public Health 93(4):635-641. Zhi, M., E. L. Ding, J. Theisen-Toupal, J. Whelan, and R. Ar naout. 2013. The landscape of inappropriate laboratory testing: A 15-year meta-analysis. PLoS One 8(11):e78962. Zwaan, L., and H. Singh. 2015. The challenges in defining and measuring diagnostic error. Diagnosis 2(2):97-103. Zwaan, L., A. Thijs, C. Wagner, G. van der Wal, and D. R. Timmermans. 2009. Design of a study on suboptimal cognitive acts in the diagnostic process, the effect on patient outcomes and the influence of workload, fatigue and experience of physician. BMC Health Services Research 9:65. 3-1 PREPUBLICATION COPY: UNCORRECTED PROOFS 3 Overview of Diagnostic Error in Health Care This chapter explains the committee's defi nition of diagnostic e rror, describes the committee's approach to measurement, and reviews the available information about the epidemiology of diagnostic error. The committ ee proposes five purposes for measurement: to establish the incidence and nature of the problem of diagnostic e rror; to determine the causes and risks of diagnostic error; to ev aluate interventions; for educa tion and training purposes; and for accountability purposes. Because diagnostic errors have been a very challenging area for measurement, the current focus of measuremen t efforts has been on understanding the incidence and nature of diagnostic error and determining the causes and risks of diagnostic error. The committee highlighted the way in which various measurement approaches could be applied to develop a more robust understandin g of the epidemiology of diagnos tic error and the reasons that these errors occur. DEFINITION OF DIAGNOSTIC ERROR The Institute of Medicine (IO M) has defined quality of car e as \"the degree to which health services for individuals and populations increas e the likelihood of desired health outcomes and are consistent with current professional knowledge\" (IOM, 1990, p. 5). The IOM's report Crossing the Quality Chasm further elaborated on high-quali ty care by identifying six aims of quality: \"[H]ealth care should be (1) safe\u2014avoidi ng injuries to patients from the care that is intended to help them; (2) effective\u2014 providing services based on scientific knowledge to all who could benefit and refraining fr om providing services to thos e not likely to benefit; (3) patient-centered\u2014providing care that is respectful of and respons ive to individual preferences, needs, and values, and ensuring that patient va lues guide all clinical decisions; (4) timely\u2014 reducing waits and sometimes harmful delays for both those who receive and those who give care; (5) efficient\u2014avoiding wast e, including waste of equipment, supplies, ideas, and human resources; and (6) equitable\u2014pr oviding care that does not vary in quality because of personal characteristics, such as gender, ethnicity, geography, and socioeconomic status\" (IOM, 2001, p. 6). Communicating accurate and tim ely diagnoses to patients is an important component of providing high-quality care; errors in diagnosis ar e a major threat to ach ieving high-quality care. The IOM defines an error in medicine to be the \"failure of a planned action to be completed as intended (i.e., error of execution) and the use of a wrong plan to achieve an aim (i.e., error of planning) [com mission]\" (IOM, 2004, p. 30). The definition also recognizes the failure of an unplanned action that should have been completed (omission) as an error (IOM, 2004). The IOM report To Err Is Human: Building A Safer Health System distinguished among four types of error: diagnostic, treatment, prev entive, and other (see Box 3-1). An adverse event is \"an event that results in unintended harm to the patient by an act of commission or omission rather than by the underlying disease or condition of the patient\" (IOM, 2004, p. 32). 3-2 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS BOX 3-1 Types of Errors Described in To Err Is Human: Building a Safer Health System Diagnostic Error or delay in diagnosis; failure to employ indicated tests; use of outmoded tests or therapy; failure to act on results of monitoring or testing Treatment Error in the performance of an operation, procedure, or test; error in administering the treatment; error in the dose or method of using a drug; avoidable delay in treatment or in responding to an abnormal test; inappropriate (not indicated) care Preventive Failure to provide prophylactic treatment; inadequate monitoring or follow-up of treatment Other Failure of communication; equipment failure; other system failure SOURCE: IOM, 2000, p. 36. The committee's deliberations were inform ed by a number of existing definitions and definitional frameworks on diagnostic error (s ee Appendix C). For instance, Graber and colleagues used a classification of error from th e Australian Patient Safe ty Foundation to define diagnostic error as a \"diagnosis that was unint entionally delayed (sufficient information was available earlier), wrong (another diagnosis was made before the correct one), or missed (no diagnosis was ever made), as judged from the eventual appreciation of more definitive information\" (Graber et al., 2005, p. 1493). They furt her divided diagnostic error into three main categories: no-fault errors, system-related errors, and cognitive errors. No-fault errors, which were originally described by Kassirer and Kope lman (1989), stem from factors outside the control of the clinician or the health care sy stem, including atypical disease presentation or patient-related factors such as providing misl eading information. The second category, system- related errors, can include technical or orga nizational barriers, such as problems with communication and care coordinatio n; inefficient processes; technical failures; and equipment problems. Finally, there are cognitive errors that clinicians may make. The causes of these can include inadequate knowledge, poor critical thinking skills, a lack of competency, problems in data gathering, and failing to s ynthesize information (Chimowitz et al., 1990). Each of these errors can occur in isolation, but they often interact with one anot her; for instance, system factors can lead to cognitive errors. Schiff and colleagues (2009, p. 1882) defined dia gnostic error as \"any mistake or failure in the diagnostic process leading to a misdiagnos is, a missed diagnosis, or a delayed diagnosis.\" Schiff and colleagues (2005) divide the diagnosti c process into seven stages: (1) access and presentation, (2) history taking/c ollection, (3) the physical exam, (4) testing, (5) assessment, (6) referral, and (7) follow-up. A diagnostic error can occur at any stage in the diagnostic process, and there is a spectrum of patient consequences related to these errors ranging from no harm to severe harm. Schiff and colleagues noted that not all diagnostic process errors will lead to a missed, delayed, or wrong diagnosis, and not all errors (either in the diagnos tic process or related to misdiagnosis) will result in patient harm. Relating this model to Donabedian's structure-process-outcome framewor k, Schiff and colleagues consider diagnosis to be an intermediate OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-3 PREPUBLICATION COPY: UNCORRECTED PROOFS outcome of the diagnostic process, and any resul ting adverse patient harm would be considered true patient outcomes (Schiff et al., 2009; Schiff et al., 2005; Schiff and Leape, 2012). In describing diagnostic error, Singh focu sed on defining missed opportunities, where a missed opportunity \"implies that so mething different could have been done to make the correct diagnosis earlier... Evidence of omission (failure to do the righ t thing) or commission (doing something wrong) exists at the particular poin t in time at which the 'error' occurred\" (Singh, 2014, p. 99). Singh's definition of a missed opportunity takes into account the evolving nature of a diagnosis, making the determination of a mi ssed opportunity dependent on the temporal or sequential context of events. It also assumes that missed opportunities could be caused by individual clinicians, the care team, the system, or pati ents. Singh focused on preventable diagnostic harm, or when a missed opportunity resu lts in harm from delayed or wrong treatment or test, as being the best opportunity to intervene. Newman-Toker (2014a, b) developed a con ceptual model of di agnostic error that attempted to harmonize the current definitional frameworks. His framing distinguished between diagnostic process failures and diagnostic labeling failures. Di agnostic process failures include problems in the diagnostic workup, and may include both cognitive and system errors. Diagnosis label failures occur when the diagnosis that a pa tient receives is incorre ct or when there is no attempt to provide a diagnosis label. Newman-T oker identified preventa ble diagnostic error as the overlap between a diagnostic pro cess failure and a diagnostic labe l failure, and noted that this is similar to Singh's conceptu alization of a missed opportunity (Singh, 2014). A preventable diagnostic error differs from a near-miss proce ss problem, which is a failure in the diagnostic process without a diagnostic labeling failure. Newman-Toke r also identifies unavoidable misdiagnosis, which is a diagnostic labeling failure that may occur in the absence of a diagnostic process failure and corresponds to the no-fault category described earlie r. Furthermore, his model illustrates that harm may\u2014or may not\u2014r esult from diagnostic process failures and diagnostic labeling failures. In reviewing the diagnostic error literature, the committee concluded that there are varying definitions and terminology currently in use to describe diagnostic error. For example, there is disagreement about exactly what constitutes a diagnostic error as well as about the precise meanings of a delayed diagnosis, a missed diagnosis, and a misdiagnosis (Newman- Toker, 2014b). Some treat the \"diagnosis error\" rather than \"diagnostic erro r\" because they conclude that diagnostic error should refer to the process of a rriving at a diagnosis, whereas di agnosis error should refer to the final multifactorial outcome, of which the diagnos tic process is only one factor (Berenson et al., 2014). Some use the term \"missed diagnosis\" solely for situations in which the diagnosis was found upon autopsy (Graber et al., 2005; Newman -Toker, 2014b). While some definitions of diagnostic error include unavoidabl e errors, others conceptualize diagnostic error as something that stems from a failure in the diagnostic process (Graber et al., 2005; Newman-Toker, 2014b; Schiff et al., 2009). In part, the various definitions that have aris en reflect the in trinsic dualistic nature of the term \"diagnosis,\" which has been used to refer both to a process and to the result of that process. Definitions of dia gnostic error can also vary by stakeholder; for example, a patient's definition of a diagnostic error may be different from a clinician or research-oriented definition of diagnostic error. Other terms used in the diag nostic error literature in clude diagnostic accuracy (Wachter, 2014), misdiagnosis-related harm (Ne wman-Toker diagnostic erro rs DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Because of this lack of agreement, the co mmittee decided to formulate a new definition of diagnostic error. The committee's patient-c entered definition of diagnostic error is: the failure to (a) establish an accurate and timely explanation of the patient's health problem(s) or (b) communicate that explanation to the patient. The definition frames a diagnostic error from the patient's perspective, in recognition that a patient bears the ultimate risk of harm from a diagnostic error. The committee's definition is two-pronged\u2014if there is a failure in either part of the definition, a diagnostic error results. It also conveys that each arm of the defi nition may be evaluated separately for measurement purposes (see the section on measurement and asse ssment of diagnostic error). The first part of the committee's definiti on focuses on two major characteristics of diagnosis: timeliness and accuracy. Timeliness mean s that the diagnosis was not meaningfully delayed. However, the committee did not specif y a time period that would reflect \"timely\" because this is likely to depend on the nature of a patient's condition as well as on a realistic expectation of the length of time needed to make a diagnosis. Thus, the term \"timely\" will need to be operationalized for different health problems. Depending on the circumstances, some diagnoses may take days, weeks, or even months to establish, while timely may mean quite quickly (minutes to hours) for other urgent di agnoses. The other characteristic the committee highlighted was accuracy. A diagnosis is not acc urate if it differs from the true condition a patient has (or does not have) or if it is imprecise and incomplete (lacking in sufficient detail). It is important to note that a working diagnosis, described in Chapter 2, may lack precision or completeness, but is not necessari ly a diagnostic error. The nature of the diagnostic process is iterative, and as information ga thering continues, the goal is to reduce diagnostic uncertainty, narrow down the diagnostic possib ilities, and develop a more preci se and complete diagnosis. The second part of the committee's definition focuses on communication. A fundamental conclusion from the committee's deliberations was that communication is a key responsibility in the diagnostic process. From a patient's perspe ctive, an accurate and timely explanation of the health problem is meaningless unless this inform ation reaches the patient so that a patient and health care professionals can act on the explanation. The phrase \"explanation of the patient's health problem(s)\" was chosen because it was meant to describe the health problem (or problems) involved as well as the manner in which the information is conveyed to a patient. The explanation needs to alig n with a patient's level of health literacy and to be conveyed in a way that facilitates patient understanding. Because not all patients will be able to participate in the communication process, there will be some situations where the explanation of the health problem may not be feasible to convey or be fully appreciated by the patient (for example, pediatric patients or patients whose health problems limit or prevent communication). In these circumstances, the communication of the health problem would be between the health care professionals and a patient's family or designa ted health care proxy. Ther e may also be urgent, life-threatening situations in which a patient's health problem will need to be communicated following treatment. However, even in these urgent situations, patients and their families need to be informed about new developments, so that decision making reflects a patient's values, preferences, and needs. Timely communication is also context- dependent: with some health problems, providing an explanation to a patient ca n take weeks or months to establish. However, throughout this time clinicians can communicat e the working diagnosis, or the current OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-5 PREPUBLICATION COPY: UNCORRECTED PROOFS explanation of the patient's health problem, as well as the degree of certainty associated with this explanation. The phrase \"failure to establish\" is include d in the definition because it recognizes that determining a diagnosis is a pro cess that involves both the passag e of time and the collaboration of health care professionals, patients, and th eir families to reach an explanation. The committee chose the term \"health problem\" because it is more inclusive than the term \"diagnosis\" and often reflects a more patient-centered approach to unde rstanding a patient's ov erall health condition. For example, a health problem could include a pr edisposition to developing a condition, such as a genetic risk for disease. In addition, there ar e circumstances when it is important to focus on resolving the symptoms that ar e interfering with a patient's basic functioning, described as \"activities of daily living,\" rather than focusing exclusively on identifying and following up on all of a patient's potential diagnoses (Gawande , 2007). Individual patient preferences for possible health outcomes can vary substantially, and w ith the growing prevalence of chronic disease, patients often have comorbidities or competing caus es of mortality that need to be taken into consideration when defining a patient's health pr oblem and subsequent plan for care (Gawande, 2014; Liss et al., 2013; Mu lley et al., 2012). There could be situations in which clinicia ns and health care or ganizations, practicing conscientiously (e.g., following clinical practice guid elines or established standards of care), may be unable to establish a definitive diagnosis. So metimes a health care professional will need to acknowledge an inability to establish a diagnosis and will need to refer the patient to other specialists for further assessment to continue the diagnostic process. However, in some cases, this iterative process may still not lead to a fi rm diagnosis. For example, individuals may have signs and symptoms that have not been recogn ized universally by the medical community as a specific disease. From the patient's perspective, this could be a diagnostic error, but medicine is not an exact science, and documenting and ex amining such instances could provide an opportunity to advance medical knowledge and u ltimately improve the diagnostic process. The committee's definition reflects the six ai ms of high-quality ca re identified by the IOM (2001). It specifically refers to effectiveness and efficiency (i.e., accuracy), timeliness, and patient-centeredness as important aspects of diagnosis, while assuming safety and equity throughout the diagnostic process. Patients and thei r families play a key role in the diagnostic process, but a patient's care team is ultimately responsible for facilitating the diagnostic process and the communication of a diagnosis (see Chapter 4). The committee's definition of diagnostic error di ffers from previous definitions in that it focuses on the outcome from the diagnostic proce ss (the explanation of the patient's health problem provided to the patient). Other definitions of diagnostic error focus on determining whether or not process-related factors resulted in the diagnostic error. For example, Singh's definition focuses on whether there was a missed opportunity to make a diagnosis earlier (Singh, 2014). Likewise, Schiff and colleagues' (2009) definition of diagnostic error requires a determination that there was a mistake or failu re in the diagnostic process. The committee's focus on the outcome from the diagnostic process is important, because it reflects what matters most to patients\u2014the communication of an accurate , timely explanation of their health problem. However, identifying failures in the diagnostic process is also critically important, which is reflected in the committee's dual focus on improving the diagnostic process and reducing diagnostic errors. The committee's discussi on of measurement includes an emphasis on understanding where failures in the diagnostic process can occur and the work system factors 3-6 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS that contribute to these failures (see section on Determining the Causes and Risks of Diagnostic Error). Analyzing failures in the dia gnostic process provide important information for learning how to improve the work system and the diagnostic process. Some failures in the diagnostic process will lead to diagnostic errors; however, ot her failures in the diagnostic process will not ultimately lead to a diagnostic error. In this report, the committee describes \"failures in the diagnostic process that do not lead to diagnostic errors\" as near misses.1 In other words, a near miss is a diagnosis that was almost erroneous. For example, it would be considered a near miss if a radiologist reported no significan t findings from a chest x-ray, but a primary care clinician reviewing the image identified something that required further follow up (Newman-Toker, 2014b). While there may have been a failure in the diagnostic process, the patient nonetheless received an accurate and timely explanation of the health problem. Examining near misses can help identify vulnerabilities in the diagnostic process as well as strengths in the diagnostic process that compensate for thes e vulnerabilities (see Chapter 6's discussion of error recovery). Likewise, several of the committee's recommendations focus on identifying both diagnostic errors and near misses, because they both serv e as learning opportunities to improve diagnosis. The diagnostic process can lead to a number of outcomes (see Figure 3-1). An accurate, timely diagnosis that is communicated to a pati ent presents the best opportunity for a positive health outcome, because clinical decision maki ng will be tailored to a correct understanding of the patient's health problem. Diagnostic errors an d near misses can stem from a wide variety of causes and result in multiple outcomes, and as evidence accrues, a more nuanced picture of diagnostic errors and near misses will develop. For example, further research can be directed at better understanding the causes of di agnostic errors and vulnerabilitie s in the diagno stic process. Some of the reasons diagnostic errors and near misses occur may be more remediable to interventions than others. In addi tion, determining which types of diagnostic errors are priorities to address, as well as which interventions could be targeted at preventing/mitigating specific types of diagnostic errors, will be inform ative in improving the quality of care. A better understanding of the outcomes resulti ng from diagnostic errors and near misses will also be helpful. For example, if there is a diagnostic error, a patient may or may not experience harm. The potential harm from dia gnostic errors could range from no harm to significant harm, including morbidity or death. Erro rs can be harmful becau se they can prevent or delay appropriate treatment, lead to unn ecessary or harmful treatment, or result in psychological or financial repercussions. Harm may not result, for example, if a patient's symptoms resolve even with an incorrect diagnosis. Diagnostic e rrors and near misses may also lead to inefficiency in health care organiza tions (e.g., the provision of unnecessary treatments) and increase system costs unnecessarily (covering the costs of otherwise unnecessary care or 1 The term \"near miss\" is used within many fields\u2014including health care\u2014with varying definitions. For example, an IOM report defined a near miss as \"an act of commission or omission that could have harmed the patient but did not cause harm as a result of chance, prevention, or mitigation\" (IOM, 2004, p. 227). Because diagnostic errors can have a range outcomes (including no harm), this defin ition of near miss is not consistent with the committee's definition of diagnostic error. However, the committee's con ceptualization of a near miss is similar to previous uses. For example, the 2004 IOM report states that most definitions of a near miss imply an incident causation model, in which there is a causal chain of events that leads to th e ultimate outcome: \"Near misses are the immediate precursors to later possible adverse events\" (IOM, 2004, p. 227). Ra ther than focus on adverse events as the outcome of interest, the committee's outcome of interest is diagnostic error. Thus, the committee's de finition of a near miss is a failure in the diagnostic process that does not lead to diagnostic error. OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-7 PREPUBLICATION COPY: UNCORRECTED PROOFS medical liability expenses). Diagnostic errors and near misses influence both the morale of individuals participating in the diagnostic process and public tr ust in the hea lth care system. Correct diagnoses, diagnostic erro rs, and near misses can be used as opportunities to learn how to improve the work system and the diagnostic process (Klein, 2011, 2014). 3 F 3-8 FIGURE 3-1 O Outcomes from t PREPhe diagnostic p IMPRO V PUBLICATION Crocess. VING DIAGNOS COPY: UNCORR E IS IN HEALTH C ECTED PROO FS CARE S OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-9 PREPUBLICATION COPY: UNCORRECTED PROOFS OVERUTILIZATION IN THE DIAGNOSTIC PROCESS AND OVERDIAGNOSIS There is growing recognition that overdiagnosis is a serious pr oblem in health care today, contributing to increased health care costs, ove rtreatment, and the associated risks and harms from this treatment (Welch and Black, 2010; Welch, 2015). Overdiagnosis ha s been described as \"when a condition is diagnosed that would othe rwise not go on to cause symptoms or death\" (Welch and Black, 2010, p. 605). Chiolero and coll eagues note that advances in prevention and diagnosis \"have changed the dia gnostic process, expanding the possibilities of interventions across asymptomatic individuals and blurring th e boundaries between healt h, risk, and disease\" (Chiolero et al., 2015, p. w14060). Over diagnosis has been attributed to the increased sensitivity of diagnostic testing (e.g., impr oved radiographic resolution), the identification of incidental findings, the widening boundaries or lowered th resholds for defining what is abnormal (e.g., hypertension, diabetes, or choles terol levels), clinic ians' concerns about missing diagnoses and subsequent medical liability risks (see Chap ter 7 for a discussion of defensive medicine concerns) (Chiolero et al., 2015; Ga wande, 2015; Moynihan et al., 2012). Recent discussions in the diagnos tic error community have draw n attention to the issue of overdiagnosis and whether overdiagnosis should be defined and classified as an error (Berenson et al., 2014; Newman-Toker, 2014b; Zwaan and Singh, 2015). Although overdiagnosis is a complex and controversial topic, it is distinct from diagnostic e rror. For example, Chiolero and colleagues (2015, p. w14060) state: \"Overdiagnosis is ... neith er a misdiagnosis (diagnostic error), nor a false positive result (positive test in the absence of a real abnormality).\" Similarly, Gawande makes the distinction between overdia gnosis and diagnostic error: \"Overtesting has also created a new, unanticipated problem: overdiagnosis. This isn't misdiagnosis\u2014the erroneous diagnosis of a disease. This is the correct di agnosis of a disease th at is never going to bother you in your lifetime\" (Gawande, 2015). Challenges in terminology and the blurry distinctions between diagnosis and treatment add to the confusion between overdiagnosis and diagnostic error. Recent reports in the literature have used th e term \"overdiagnosis\" broadly to incorporate the concept of overmedicaliz ation, including overdet ection, overdiagnosis, overtreatment, and overutilization (Carter et al., 2015). For example, widening the criteria used to define a disease may raise important concerns about overmedicalization, but if a diagnosis is consistent with consensus guidelines for medical practice, it would not constitute a diagnostic error as defined by the IOM committee. A major reason overdiagnosis is not characteri zed as an error is because it is found primarily with population-base d estimates\u2014it is virtually impossible to assess whether overdiagnosis has occurred for an indivi dual patient (Welch and Black, 2010). Our understanding of biology and disease progression is often not advanced enough to determine which individuals are going to be harmed by their health condition, versus the health conditions that are never going to lead to patient harm (e.g., thyroid, breast, and pr ostate cancers). Thus, clinicians are treating patients based on uncerta in prognoses, and many more people are treated compared to those who actually benefit from treatmen t. Likewise, screening guidelines are intended to identify populations that will most likely benefit from screening, but not all individuals who undergo screening will benefi t. For example, screening mammography\u2014like many interventions\u2014is an imperfect test with asso ciated harm s and benefits; some breast cancers will be missed, some women will die from breast cancer regardless of being screened, and some 3-10 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS cancers that are identifie d will never lead to harm (Pace a nd Keating, 2014). Because current diagnostic testing technologies of ten cannot distinguish the cancer s that are likely to progress and lead to patient harm from t hose that will not, inevitably clin icians treat some patients with breast cancer who will not benef it from the treatment (Esserman et al., 2009). It would be incorrect (and largely impossible) to classify th ese cases as errors because clinicians are basing screening and treatment decisions on the best available medical knowledge, and the assessment of overdiagnosis is dependent on population-ba sed analysis. For example, once diagnosed and treated for cancer, it is impossible to know wh ether the patient's outcome would have been different if the tumor (which may have been indole nt rather than life-thre atening) had never been diagnosed. However, overdiagnosis represents a true ch allenge to health care quality, and further efforts are warranted to prevent overdiagnosis and associated overtreatment concerns. Reducing overdiagnosis will likely require improved unders tanding of disease biology and progression, as well as increased awareness of its occurrence among health care pr ofessionals, patients, and their families (Chiolero, 2015). In addition, an impor tant strategy that has been suggested for preventing overdiagnosis and associated overtre atment is avoiding unnecessary and untargeted diagnostic testing (Chiolero, 2015). Box 3-2 provides an overview of overutilizati on of diagnostic testing in health care. Based on the committee's definition of diagnosti c error, which focuses on the outcomes for patients, overutilization of diagnostic testing is not necessarily a diagnostic error. Based on the committee's conceptual model, overutilization of diagnostic testing would be considered a failure in the diagnostic process (failure in information gather ing\u2014see the measurement section below). Overutilization is a serious concern, and efforts to improve diagnosis need to focus on preventing inappropriate overutilization of dia gnostic testing (Newman-To ker et al., 2014a). Improving diagnosis should not imply the adoption of overly a ggressive diagnostic strategies. Chapter 2 highlights that the goal of diagnostic testing is not to reduce diagnostic uncertainty to zero (an impossible task), but ra ther to optimize decision making by judicious use of diagnostic testing (Newman-Toker et al., 2013; Kassirer, 1989). Th is is also why the committee highlighted iterative information gather ing and the role of time in the diagnostic process; oftentimes it is not appr opriate to test for everything at the outset\u2014further information gathering activities can be inform ed by test results, time, and a patient's response to treatment. The committee makes a number of recommendations that are targeted at preventing overutilization in the diagnostic process throughout the report, in cluding improved collaboration and communication among treating clin icians and pathologists, radi ologists, and other diagnostic testing health care professionals, as well as increased emphasis on diagnostic testing in health care professional education (see Chapters 4 and 6). BOX 3-2 Overutilization of Diagnostic Testing While diagnostic testing has brought many improvements to medical care, advances in diagnostic testing have also led to some problems, including an under-reliance on more traditional diagnostic tools, such as careful history taking and the physical exam, and the inappropriate utilization of diagnostic testing (Iglehart, 2009; Newman-Toker et al., 2013; Rao and Levin, 2012; Zhi et al., 2013). Inappropriate use has included both overutilization (testing when it is not indicated) and underutilization (not testing when it is indicated). The use of diagnostic testing to rule out conditions, clinicians' intolerance of uncertainty, OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-11 PREPUBLICATION COPY: UNCORRECTED PROOFS an enthusiasm for the early detection of disease in the absence of symptoms, and concerns over medical liability can all contribute to overutilization (Grimes and Schulz, 2002; Newman- Toker et al., 2013; Plebani, 2014). In one survey of physicians in specialties at high risk of litigation (emergency medicine, general surgery, orthopedic surgery, neurosurgery, obstetrics/gynecology, and radiology), 59 percent of respondents reported that they ordered more tests than were medically indicated (Studdert et al., 2005). In an analysis that examined patient understanding of medical interventions, researchers identified a complex array of reasons for overuse, including payment systems that favor more testing over patient interaction, the ease of requesting tests, and patient beliefs that more testing and treatment is equivalent to better care (Croskerry, 2011; Hoffmann and Del Mar, 2015). When a clinician does not have enough time to discuss symptoms and potential diagnoses with a patient, ordering a test is sometimes considered more straightforward and less risky (Newman-Toker et al., 2013). Another contributing factor is an overestimation of the benefits of testing; for example, patients often overestimate the benefits of mammography screening (Gigerenzer, 2014; Hoffmann and Del Mar, 2015). The overutilization of medical imaging techniques that employ ionizing radiation (such as computed tomography [CT]) is of special concern and has gained considerable attention in the wake of research showing a marked increase in radiation exposure from medical imaging in the U.S. population (Hricak et al., 2011). Epidemiological studies have found reasonable, though not definitive, evidence that exposure to ionizing radiation (organ doses ranging from 5 to 125 mSV) result in a very small but statistically si gnificant increase in cancer risk (Hricak et al., 2011). Children are more radiosensitive than adults, and cancer risks increase with cumulative radiation exposure. In addition to age at exposure, genetic considerations, sex, and fractionation and protraction of exposure may influence the level of risk. Medical imaging needs to be justified by weighing its potential benefit against its potential risk. It is important to be sure that imaging is truly indicated and to consider alternatives to the use of ionizing radiation, especially for pediatric patients and those with a history of radiation exposure. In 2010 the Food and Drug Administration launched the Initiative to Reduce Radiation Exposure, aimed at promoting the justification of all imaging examinations and t he optimization of imaging protocols so as to minimize radiation doses (FDA, 2015). Studies have shown that the use of clinical decision support and guidelines can minimize unnecessary radiation exposure and that they could prevent as many as 20 to 40 percent of CT scans without compromising patient care (Hricak et al., 2011). MEASUREMENT AND ASSESSMENT OF DIAGNOSTIC ERROR For a variety of reasons, diagnostic errors ha ve been more challenging to measure than other quality or safety concep ts. Singh and Sittig (2015, p. 103) note that \"[c]ompared with other safety concerns, there are al so fewer sources of valid and re liable data that could enable measurement\" of diagnostic erro rs. Studies that have evaluated diagnostic errors have employed different definitions, and the use of varying de finitions can lead to challenges in drawing comparisons across studies or synthesizing the available information on measurement (Berenson et al., 2014; Schiff and Leape, 2012; Singh, 2014). Even when there is agreement on the definition of diagnostic error, there can be ge nuine disagreement over wh ether a diagnostic error actually occurred, and there are often blurry boun daries between differe nt types of errors (treatment or diagnostic) (Singh et al., 2012a; Singh and Sittig, 2015). 3-12 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS The complexity of the diagnostic process it self, as well as the inherent uncertainty underlying clinical decision making, makes meas urement a challenging task (Singh, 2014; Singh and Sittig, 2015). The committee's conceptual model illustrates the complex, time-dependent, and team-based nature of the diagnostic proce ss as well as all of the potential work system factors that can contribute to the occurrence of diagnostic error. The temporal component of the diagnostic process can complicate measurement since the signs and symptoms of a health condition may evolve over time, and there can be disagreement about what an acceptable timeframe is in which to make a timely diagnosis (Singh, 2014; Zwaan and Singh, 2015). Clinical reasoning plays a role in diagnostic errors, but clinical reasoning processes are difficult to assess because they occur in clinicians' mi nds and are not typically documented (Croskerry, 2012; Wachter, 2010). Similarly, some measurem ent approaches, such as medical record reviews, may not identify diagnostic errors because information related to diagnosis may not be documented (Singh et al., 2012a). Furthermor e, many people recover from their health conditions regardless of the treatment or diagnosis they receive, so a diagnostic error may never be recognized (Croskerry, 2012). The Purposes of Measurement There are a variety of ways that measurement can be used in the context of the diagnostic process and in assessing the occurrence of diagnostic errors. The committee identified five primary purposes for measuring diagnostic errors: establishing the magnitude and nature of the problem of diagnostic error, de termining the causes and risks of diagnostic error, evaluating interventions to improve diagnosis and reduce diagnostic errors, as well as for educational and training purposes and for accountability purposes (e.g., performance measurement). Each of these purposes is described in greater detail below. (1) Establish the incidence and nature of the problem of diagnostic error. Today this task is primarily the province of research and is likely to remain that way for the foreseeable future. Researchers have used a variety of methods to assess diagnostic errors. Attention to harmonizing these approaches and recognizing what each method contributes to the overall understanding of diagnostic error may better characterize the size and dimensionality of the problem and may facilitate assessment of diagnostic error rates over time. (2) Determine the causes and risks of diagnostic error. This use of measurement and assessment is also primarily undertaken in research settings, and this is also likely to continue. Previous research has provided numerous insights into causes and risks, but moving from these insights to constructing approaches to prevent or detect problems more rapidly will require additional work. (3) Evaluate interventions. This report should stimulate the development of programs designed to prevent, detect, and correct diagnostic erro rs across the spectrum, but these programs will require appropriate measurement tools (both quantitative and qualitative) to allow a rigorous assessment of whether the interventions worke d. This will be particularly challenging for measuring prevention, as is always the case in medical care. Research needs to focus on the required attributes of these measur ement tools for this application. (4) Education and training . Given the importance of lifelong learning in health care, it will be useful to have measurement tools that can assess the initial training of health care professionals, the outcomes of ongoing educa tion, and the competency of health care professionals. For this application, these tools need to provide an opportunity for feedback and perhaps decision support assistance in identifying pot ential high risk areas. In this instance, the OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-13 PREPUBLICATION COPY: UNCORRECTED PROOFS measurement tools need to include both the assessme nt of whether an event o ccurred or is at risk for occurring, and also effective methods fo r feeding back information for learning. (5) Accountability. In today's environment, significant pressure exists to push toward accountability through public repor ting and payment for every area in which a potential problem has been identified in health care. As an aspi ration, the committee recogni zes that transparency and public reporting are worthy goals for helping patients identify and receive high-quality care. However, current pushes for accountability neglec t diagnostic performance, and this is a major limitation of these approaches. The committee's a ssessment suggests that it would be premature either to adopt an accountability framework or to assume that the traditional accountability frameworks for public reporting and payment will be effective in reducing diagnostic error. A primary focus on intrinsic motivation\u2014unleashing the de sire on the part of n early all health care professionals to do the right thing\u2014may be more effective at improving diagnostic performance than programs focused on public reporting and payment. Public awareness may also be a key leverage point, but at this point measurement appr oaches that reveal weak spots in the diagnostic process and identify errors reliably are lack ing. For both health care professionals and for patients, it is critical to develop measurement approaches that engage all parties in improving diagnostic performance. With this in mind, the following discussion elaborates on three of the purposes of measurement: establishing the incidence and nature of diagnostic error, determining the causes and risks of diagnostic error, and evaluati ng interventions. This section summarizes the approaches to measurement that are best matched to each purpose. All of the data sources and methods that were identified have some limitations for the committee-defined purposes of measurement. Issues related to assessing the competency of health care professionals are addressed in Chapter 4; because the committee determined that it is premature to consider diagnostic error from an accountability framework, measurement for the purpose of accountability is not described further in this chapter. Establishing the Incidence and Nature of the Problem of Diagnostic Error A number of data sources and methods have been used to unders tand the incidence and nature of diagnostic error, in cluding postmortem examinati ons (autopsy), medical record reviews, malpractice claims, health insurance claims, diagnostic testi ng studies, patient and clinician surveys, among others (Berner and Graber, 2008; Graber, 2013; Singh and Sittig, 2015). Before reviewing each of these approaches, the committee sought to identify or construct a summary, population-based estimate of the frequency with which di agnostic errors occur. Such a number can underscore the importance of the problem and, over time, be used to evaluate whether progress is being made. To arrive at such a number, the committee considered the necessary measurement requirements to establish th e incidence and nature of diagnostic errors. First, one would need an estimate of the numbe r of opportunities to make a diagnosis each year (denominator) and the number of times the diag nosis (health problem) is not made in a timely and accurate manner or is not communicated to the patient. This formulation takes into consideration the fact that patients may experience multiple health problems for which a diagnosis is required during any given year; each represents an opportunity for the health care 3-14 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS system to deliver a timely and accurate explana tion of that health problem. About one-third of ambulatory visits are for a new health problem (CDC, 2015). The formulation also reflects the fact that the final product (the e xplanation of the patient's health problem) needs to be free of defects; that is, it needs to m eet all elements of a correct di agnosis (timeliness, accuracy, and communication). The committee recognized that, perhaps not surp risingly, the available research estimates were not adequate to extrapolate a specific estimate or range of the incidenc e of diagnostic errors in clinical practice today. Even less information is available to assess the severity of harm caused by diagnostic errors. Part of the challenge in gath ering such data is the variety of settings in which these errors can occur; these settings in clude hospitals, emergency departments, a variety of outpatient settings (such as primary and specia lty care settings and retail clinics), and long- term-care settings (such as nursing homes and rehabilitation centers). A second part of the challenge is the complexity of the diagnostic pr ocess itself. Although there are data available to examine diagnostic errors in some of these settings, ther e are wide gaps and much variability in the amount and quality of information available. In addition, a number of problems arise when aggregating data across the various research methods (such as postmortem examinations, medical record reviews, and malpractice clai ms). Each method captures information about different subgroups in the population, different dime nsions of the problem, and different insights into the frequency and causes of diagnostic error. Taken together, however, the committee concluded that the evidence suggests that di agnostic errors are a significant and common challenge in health care and that most people will experience at le ast one diagnostic error in their lifetime. The committee based this observation on its collective assessment of the available evidence describing the epidemiology of diagnos tic errors. In each data source that the committee evaluated, diagnostic errors were a consistent quality and safety challenge. The committee anticipates that its definition of diagnostic error w ill inform measurement activities. The two components of the defini tion\u2014(a) timeliness and accuracy and (b) communication\u2014will likely have to be accounted for separately. For example, it is often difficult to determine from a medical record review whet her the diagnosis has been communicated to the patient. Other data sources, such as patient surv eys, may be helpful in making this determination. Alternatively, medical record charting practices could be improved to emphasize communication, because of its importance in improving diagnosis and subsequent care. Measuring each arm of the definition is also consistent with the committee's approach to identifying failures in the diagnostic process; the committee specifies that each step in the diagnostic process can be evaluated for its suscep tibility to failures (ple ase see section below). To better understand both the challenges and the opportunities associat ed with the various measurement methods, for each of the data sources the committee examined (1) the mechanism by which eligible patients were identified for assessment (denominator) and (2) the way that diagnostic errors were identifie d (numerator). The results are summarized in Table 3-1. In the sections following the table, the committee describe s each data source, high lights the features of the data source that enhance or limit its utility for estimating the incidence of diagnostic error, describes the methods that have been used in stud ies to select cases for re view (the denominator), and describes the methods for determining if an error occurred (numerator). Next, a summary of what is known about the incidence of diagnostic errors from studies that use those data sources is offered. Each section ends with a discussion of potential improvements to the methods that use each data source. OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-15 PREPUBLICATION COPY: UNCORRECTED PROOFS TABLE 3-1 Methods for Estimating the Incidence of Diagnostic Errors Data Source Key Features of the Data Source Method(s) for Selecting Cases for Review (Denominator) Method for Determining if Error Occurred (Numerator) Postmortem examination (Autopsy) Deaths only Limited number of reviews Selection bias (typically focused on unexpected deaths) Limited workforce Consecutive series with criteria Convenience samples Pre-specified criteria Requests (from clinicians) Comparison to another data source (medical record, interview, location/circumstance of death) Cause of death determination Effects or indication of disease Medical records Rely on documentation (what was recorded, such as clinical history and interview, physical exam, and diagnostic testing) Pre-specified criteria (e.g., trigger tool) Random sample Implicit review/expert assessment Explicit criteria Malpractice claims Requires claim to be filed; more likely for negligent care Most studies done on closed claims Classification criteria (typically based on claim made in suit) Claims adjudication process (including courts) Health insurance claims Requires a billable event Relies on documentation necessary for payment Criteria-based algorithm (selected) Universe of claims Criteria-based algorithm Diagnostic testing Source data available for review Applies only to diagnoses for which diagnostic testing data are a key factor Focus on interpretation Random sample Pre-specified criteria Expert assessment compared to original Medical imaging Source data available for review Applies only to diagnoses for which medical imaging data are a key factor Focus on interpretation Random sample Pre-specified criteria Expert assessment compared to original Surveys of clinicians Subject to non-response bias May be difficult to Sample receiving survey Descriptive statistics on self-report 3-16 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS validate Surveys of patients Subject to non-response bias May be difficult to validate Sample receiving survey Descriptive statistics on self-report Postmortem Examinations Description of the data source Postmortem examinations, often referred to as autopsies, are highly specialized surgical proc edures that are conducted to determine the cause of death or extent of disease. Hoyert (2011, p. 1) identi fies two primary types of postmortem exams conducted in the United States,: (1 ) \"hospital or clinical autopsie s, which family or physicians request to clarify cause of deat h or assess care,\" and (2) \"medicolegal autopsies, which legal officials order to further investigate the circ umstances surrounding a death.\" Postmortem exams may vary from an external-only exam to a full external and internal exam, depending on the request. While this chapter focuses on full- body postmortem exams, Chapter 6 describes the potential future state of postmortem examinations, which may include more minimally invasive approaches, such as medical imaging, la paroscopy, biopsy, histology, and cytology. Notes about the data source Postmortem exams are considered a very strong method for identifying diagnostic errors because of the extensiveness of the examination that is possible (Graber, 2013; Shojania, 2002). However, there are some limitations to this data source for the purpose of estimating the incidence of diagnos tic error. Postmortem exams are conducted on people who have died; thus, the re sults can only provide informati on about diagnostic errors that led to the patient's death and about other diseases present that had not been previously identified, whether or not they contributed to the patient 's death. A very limited number of postmortem exams are performed annually, and postmortem ex am rates can also vary geographically and institutionally. Little information is available for characterizing the relationship between those who receive postmortem exams and the potential number of eligible cases, but the committee observed that those who undergo autopsy are more li kely to have experien ced a diagnostic error and that error is more likely to have contributed to the patient's (premature) death (an example of selection bias) (Shojania, 2002). Methods for identifying case s for review (denominator) The decision about whether an individual patient will receive a postmortem exam is based on requests from clinicians or family members as well as on local criteria set by corone rs or medical examiners. With the exception of postmortem examinations done for criminal forens ic purposes, family memb ers must consent to having the procedure done. There is no systematic information on the frequency with which the request for an autopsy is refused (which w ould introduce response bias into results). The performance of postmortem exams has declined s ubstantially in the United States in recent decades (Lundberg, 1998). National data on postmort em exams have not been collected since 1994; at that time, fewer than 6 percent of non-forensic deaths underwent a postmortem exam (Shojania et al., 2002). OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-17 PREPUBLICATION COPY: UNCORRECTED PROOFS Research studies that have used postmortem exam results have used consecutive series, pre-specified criteria (including randomly selected autopsies), or convenience samples (Shojania, 2002). Methods for determining if an error occurred (numerator) The results of the postmortem exam typically provide a cause of death and a de scription of the presence and severity of other diseases. These results are compared to anothe r data source, typically medical records or interviews with treating clinicians or family members. Discrepancies between what was found in the postmortem exam and what was known prior to that are the basis for determining the occurrence of a diagnostic error. Such determinati ons are subject to the re liability and validity of both the postmortem exam findings and the results from the data collected from the original sources. What is known Postmortem examinations have been described as an important method for detecting diagnostic errors (B erner and Graber, 2008; Graber , 2013). In data, Shojania and collea gues concluded that \"the autopsy continues to detect important errors in c linical diagnosis\" (Shojania et al., 2002, p. 51). On average, 10 percent of postmortem exams were associated with diagnostic erro rs that might have affected patient outcomes (i.e., Class I errors). 2 They estimated that the prevalence of major errors (i.e., Class I and II errors) related to the principal diagnosis or the cause of death was 25 percent. Some incidental findings found dur ing postmortem exams should not be classified as diagnostic errors; of primary importance is identifying diagnos tic errors that contribu ted to a patient's death (Class I errors).3 Shojania and colleagues not ed that some selection bias is reflected in this estimate because the cases in which there was mo re uncertainty about the diagnosis were more likely to undergo postmortem exam. A systematic re view of diagnostic erro rs in the intensive care unit found that 8 percent of postmortem exams revealed a Class I error and that 28 percent identified at least one diagnostic error (Winters et al., 2012). Acco rding to Shojania et al. (2003, p. 2849), the rates of autopsy-iden tified diagnostic errors have declined over time but remain \"sufficiently high that encouraging ongoing use of the autopsy appears warranted.\" Based on their findings, they estimated that among the 850,000 individuals w ho die in U.S. hospitals each year, approximately 8.4 percent ( 71,400 deaths) have a major dia gnosis that remains undetected (Shojania et al., 2003). Opportunities for improvement The committee concluded that postmortem exams play a critical role in understanding the epidemiology of diagnostic errors and that increasing the number of such exams is warranted. In addition, tracking the number of deaths, those eligible and selected for postmortem exams, and the re fusal rate among family members would enable the development of better national estimates of diagnostic error incidence. The committee weighed the relative merits of increasing the number of postmortem examinations conducted throughout the United States versus a more target ed approach. The committee concluded that it 2 A Class I error is a major diagnostic e rror that likely played a role in the patie nt's death. A Class II error is a major diagnostic error that did not contribute to the patient's deat h. A Class III error is a minor diagnostic error that is not related to the patient's cause of death but is related to a terminal disease. A Class IV error is a missed minor discrepancy (Winters et al., 2012). 3 For example, incidental findings of prostate cancer that are not relevant to the patient's provision of health care, terminal disease, or death may not be appr opriate to classify as diagnostic error. 3-18 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS would be more efficient to have a limited number of systems who are highly qualified in conducting postmortem exams participate to prod uce research-quality information about the incidence and nature of diagnostic errors among a representative sample of patient deaths. The committee recognized that this approach reflects both financ ial realities and workforce challenges (i.e., a limited number of pathologists being available and willing to conduct a large number of such exams) (see also Chapter 6). The systems that are selected to routinely conduct postmortem exams could also investigate how new, minimally invasive postmortem approaches compare with full-body postmortem exams. Medical Records Description of the data source A medical record is define d as a documented account of a patient's examination and treatment that include s the patient's clinical history and symptoms, physical findings, the results of diagnostic testing, and medications and therapeutic procedures. The medical record can exist in either paper or electronic form. Notes about the data source Medical records exist only for pa tients who have sought care from a clinician, team, or facility. Although there ar e some common conventions for structuring medical records (both in paper and electronic fo rmats), much of the content of the record depends on what the clinician choos es to include, and thus there ma y be variations in the extent to which clinical reasoning is documented (e.g., what alternative diagnoses were considered, the rationale for ordering [or not orde ring] certain tests, and the way in which the information was collected and integrated). Both regulatory and local ru les affect which members of the diagnostic team contribute to the documentation in a medi cal record and how they contribute. Except in highly integrated systems, patients typically have a separate medi cal record associated with each clinician or facility from which they have sought care. When patients change their source of care, the information from medical records maintained by the previous clinicians may or may not be incorporated into the new record. Methods for identifying cases for review (denominator) The most common methods for identifying cases for review are either to dr aw a random sample of records from a facility (especially hospitals), clinic, or clinician practice or to assemble a criteria-based sample (e.g., a trigger tool). The criteria-based tools typically se lect events that have been associated with a higher probability of identifying a diagnostic error, such as unplanned readmissions to a hospital, emergency department visits after an outpatient visit, or the failure of a visit to occur after an abnormal test result. Estimates of the inciden ce of diagnostic errors based on medical records need to account for the probability that an individual is included in the study sample and the likelihood that a visit (or set of visits) requires that a dia gnosis be made. Since these factors likely vary by geography and patient populations , arriving at national es timates from studies done in limited geographic areas is difficult. Methods for determining if an error occurred (numerator) There are two common methods for determining if an error occurred: implicit and explicit. In the implicit method, an expert reviewer, taking into account all of the information that is av ailable in the medical record, determines whether or not an accurate or timely diagnosis was made and, if a defect in the process occurred, the nature of that problem. In the explicit met hod, specific criteria are developed and data are abstracted from the medica l record to determine whether or not an error occurred. The reliability of imp licit and explicit m ethods for assess ing quality of care and patient OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-19 PREPUBLICATION COPY: UNCORRECTED PROOFS safety has been studied. Genera lly, implicit methods have been found to be less reliable than explicit methods (Hofer et al., 2004; Kerr et al., 2007). In th e Utah and Colorado Medical Practice Study, which was one of the sources for estimating medical errors in IOM's To Err Is Human report, the inter-rater reliability (agreement among reviewers) was =0.40-0.41 (95 percent confidence interv al, 0.30-0.51) for identifying adverse events and =0.19-0.24 (95 percent confidence interv al, 0.05-0.37) for identifying negligent adverse events (Thomas et al., 2002). These rates are considered moderate to p oor (Landis and Koch, 1977) . The reliabilities for the Harvard Medical Practice study were in the same range (Brennan et al., 1991). Zwaan et al. (2010) reported a reliability of =0.25 (95 percent c onfidence interval, 0.05-0.45) (fair) for identifying adverse events and of =0.40 (95 percent confidence interval, 0.07-0.73) (moderate) for whether the event was preventable. Reliability in turn can affect the event rate that is reported. By contrast, the inter-rater reliability fo r explicit review of records for quality studies has been reported at approximately 0.80 (McGlynn et al., 2003). What is known Two studies based on medical record re views reported in the literature in the 1990s and early 2000s estimated that diagnostic errors account for 7 and 17 percent of adverse events in hospitalized patients, respectively. In the Harvard Medi cal Practice Study of more than 30,000 patient records, diagnostic errors were iden tified in 17 percent of the adverse events (Leape et al., 1991). A review of 15,000 records from Colorado and Utah found that diagnostic errors constituted 6.9 percent of a dverse events (Thomas et al., 2000). More recently, Zwaan and collea gues conducted a retrospective patient record review to assess the occurrence of diagnosti c adverse events (harm associated with a diagnostic error) within hospitals in the Netherlands (Zwaan et al., 2010). Those researchers found that diagnostic adverse events occurred in 0.4 percent of all hospital admissions and that diagnostic adverse events accounted for 6.4 percent of all adverse events. The researchers had reviewers classify the causes of diagnostic adverse events by human, or ganizational, technical, patient-related, and other factors (Zwaan et al., 2010). They further divided the \"human\" cat egory into knowledge- based, rule-based, skill-based, or other (such as violations or failures by deliberate deviations from rules or procedures). They found that human failures were the main cause of diagnostic adverse events\u201496.3 percent of these events had a human cause. 4 However, organizational and patient-related factors were present in 25.0 perc ent and 30.0 percent of di agnostic adverse events, respectively. The researchers found that the prim ary causes of diagnostic adverse events were knowledge-based failures (physicians did not have sufficient knowledge or applied their knowledge incorrectly) and informa tion transfer failures (physici ans did not receive the most current updates about a patient). In another study by Zwaan and colleagues (2012 ), rather than focusing exclusively on adverse events, the researchers ha d four internists review 247 patie nt medical records for patients with dyspnea (shortness of breat h) symptoms. The reviewers us ed a questionnaire to identify failures in diagnostic reasoning, diagnostic erro rs, and harm. They found that failures in diagnostic reasoning occurred in 66 percent of the cases, that di agnostic errors occurred in 13.8 percent of all cases, and that the patient was harmed in 11.3 pe rcent of cases. Although cases with diagnostic errors and patient harm had more failures in diagnostic reasoning, in 4 percent of the cases diagnostic errors o ccurred in the absence of di agnostic reasoning failures. 4 It is likely that the \"human failures\" identified in this study actually related to work system factors. 3-20 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Singh et al. (2014) estimated the frequency of diagnostic error in th e outpatient setting using data from three prior studies (Murphy et al., 2014; Singh et al., 2012a; Singh et al., 2010a). Two of the studies used \"triggere d\" electronic queries to identif y suspected cases of diagnostic error. In one study these triggers identified medical re cords in which a patient had a primary care visit followed by an unplanned hospitalization or unscheduled follow-up appointment, while the other study looked for a lack of follow up for a bnormal colorectal cancer findings. The third study examined consecutive cases of lung cancer. Physicians reviewed medical records to determine if there was a diagnosti c error (defined as a missed oppor tunity to make or pursue the correct diagnosis when adequate data were availa ble at the index [i.e., fi rst] visit) (Singh, 2012a). The combined estimate of diagnostic error base d on these three datasets was about 5 percent. Extrapolating to the entire U.S. population, Singh et al. (2014) estimated that approximately 12 million adults (or 1 in 20 adults) experience a diagnostic error each year; the researchers suggested that about half of these errors could be potentially harmful. Due to the definition of diagnostic error that Singh and colleagues empl oyed, they asserted\u2014as have other researchers\u2014 that this number may be a conservative estimat e of the rate of outpatient diagnostic errors (Aleccia, 2014). Opportunities for improvement Medical records will continue to be an important source of data for assessing diagnostic errors. The advent of electronic forms that make some methods more cost-efficient, combined with mechanisms such as health information exchanges that may make it easier to assemble the entire patient di agnostic episode, may enhance the use of these methods. Developing a standard method that coul d be applied to a random sample of records (either nationally or in pre-sp ecified settings) would enhance opportunities to learn about both the incidence and the variation in the likelihood of patients ex periencing a diagnostic error. Greater attention to the reliabi lity with which the method is applied, particularly through the use of explicit rather than implic it methods, would also enhance the scientific strength of these studies. Medical Malpractice Claims Description of the data source Medical malpractice claims are defined as the electronic and paper databases maintained by prof essional liability insurers on claims that have been filed by patients or their families seeking compensation fo r alleged medical errors, including diagnostic errors; the information in support of the claims (medical records, depositions, other reports); and the final determination, whether achieved through a settlement or court ruli ng. In addition to files maintained by insurers, the U.S. Health Res ources and Services Administration, an agency within the Department of Health and Human Services, maintains the National Practitioner Data Bank (NPDB). The NPDB is a repository of clinician names, affiliations, and malpractice payments that have been made since 1990. It se rves primarily as a sy stem to facilitate comprehensive review of the credentials of c linicians, health care entities, providers, and suppliers, but it has been used for research as well. Many states also re quire claim reporting for purposes of maintaining a state-level database of paid claim information. Notes about the data source For a diagnostic error to be included in malpractice claims datasets, a patient must have filed a claim, which is a relatively rare event (Localio et al., 1991), and is more likely if the patient has experienced significant harm or if neg ligence is a factor. For OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-21 PREPUBLICATION COPY: UNCORRECTED PROOFS example, one study using data from the Harv ard Medical Practice St udy estimated that the probability of negligent injury was 0.43 percent and that the probability of non-negligent injury was 0.80 percent (Adams and Garber, 2007). Furtherm ore, the probability that a claim would be filed was 3.6 percent if a negligent injury occu rred and 3.2 percent if a non-negligent injury occurred. The probability that a claim would be paid was 91 percen t for negligent injury claims and 21 percent for non-negligent injury claims. T hus, malpractice claims data provide a small window into the problem of diagnostic errors a nd are biased toward more serious diagnostic errors. For diagnosis-related claims, an average of 5 years elapses between the incident and the settlement of the claim (Tehrani et al., 2013). Th e validity of claims is uncertain\u2014some claims will be filed and closed when no error occurr ed. Many, if not most, errors do not lead to malpractice claims. Cases may also be dismissed even when a true dia gnostic error occurred. Methods for identifying case s for review (denominator) Studies of diagnostic error using malpractice claims data use all malpractice claims (any allegation) as the denominator. Methods for determining if an error occurred (numerator) In malpractice claims, the allegation in the claim is the basis for a determination; multiple allegations can be associated with a single claim. A number of studies have assessed the validity of malpractice claims (Localio et al., 1991; Studdert et al., 2000, 2006). Generally speak ing, studies use only closed claims, that is, those for which the insurer has determined that no further legal action will be taken (claims may be closed due to settlement , verdict, dismissal, abandonment, or other reasons). Data from CRICO's Comparative Benc hmarking System indicate that 63 percent of closed diagnosis-related cases we re withdrawn, denied, or dismi ssed with no indemnity payment (CRICO, 2014). What is known Tehrani et al. (2013) analyzed 25 years of closed medical malpractice claims from the National Practitioner Data Bank in order to characterize the frequency, patient outcomes, and economic consequences of diag nostic errors. The researchers found that diagnostic errors were the lead ing type of paid malpractice claims (28.6 percent) and were responsible for the highest propor tion of total payments (35.2 pe rcent) (Tehrani et al., 2013). Diagnostic errors were almost twice as likely to be associated with patient death as other allegation categories (such as treatment, surger y, medication, or obstetrics claims). Almost 70 percent of diagnostic error claims were from the outpatient setting, but inpatient diagnostic error claims were more likely to be associated with patient death. The researchers estimated that the 2011 inflation-adjusted mean and median pe r claim payout for diagnostic error was $386,849 and $213,250, respectively. Schiff and colleagues (2013) reviewed closed primary care malpractice claims in Massachusetts from 2005 to 2009. During that 5- year period, 551 medical malpractice claims were from primary care practices. More than 70 percent of the allegations were related to diagnosis. The diagnoses most often appearing in these claims were cancer , heart diseases, blood vessel diseases, infections, and stroke. CRICO has conducted comprehensiv e analyses of its claim f iles and associated medical records for diagnostic errors (CRICO, 2014; Sieg al, 2014). CRICO's database represents about 30 percent of the National Practitioner Data Bank and includes around 400 hospitals and health care entities and 165,000 physicians. In CRICO's anal ysis of data from 2008 to 2012 (including 3-22 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS more than 4,500 cases and more than $1 billion total incurred losses), the organization reported that diagnosis-related claims represented 20 percent of cases by volume and 27 percent of indemnity payments. It found that diagnostic errors are more common in the ambulatory care setting than in the inpatient or emergency depa rtment setting (56 percent versus 28 percent and 16 percent, respectively). Within the inpatient se tting, the top diagnoses represented in closed malpractice claims included myocardial infarcti on (MI) and cardiac events, complications of care (failure to rescue), and inf ections/sepsis (Siegal, 2014). In the ambulatory care setting, cancer, cardiac care (including MI), a nd injury (orthopedic, head, an d spine) represented the top diagnoses in paid claims. CRICO found that cancer represente d almost one-third of all the diagnosis-related medical malpractice claims. The Doctors Company, another large nationa l medical liability insurer, compiled information from its 2007-2013 claims database for the IOM committee. In its analysis of diagnosis-related claims, the Doctors Compa ny included information from ten medical specialties (internal medicine, family medicine, obstetrics, cardiology, gynecology, general surgery, emergency medicine, orthopedics, pedi atrics, and hospital medicine). For the ten specialties, diagnosis-related claims constituted between 9 percent (obstetrics) and 61 percent (pediatrics) of total claims. The analysis included the top five diagnoses associated with each specialty's malpractice claims. That analysis indicated that over half of the diagnoses appeared within multiple specialties and generally were for commonly encountered diseases (such as acute MI, acute cerebral vascular a ccident, cancer, and appendicitis). Opportunities for improvement For malpractice claims to be useful for estimating the incidence of diagnostic error, it will be neces sary to develop a better understanding of the underlying prevalence of diagnostic error as well as of the probability that a claim will be filed if an error has occurred and the likelihood that a filed claim will be se ttled. This will require significant research activity, and such research would have to explore variations by geography, specialty, type of error, and ot her factors. Databases from malp ractice insurers contain much more clinical detail than the National Practitioner Data Bank and are likely to be more useful in describing patterns of diagnostic errors, such as the steps in the diagnosti c process that present the highest risk for different diagnoses. CRICO 's benchmarking studies demonstrate the utility of these data for understanding where in the diagno stic process errors are most likely to occur and what factors contributed to the error. This can be useful for designing both monitoring and improvement programs. Health Insurance Claims Description of the data source The data source consists of el ectronic databases maintained by health insurance companies that contain the details of bills submitted by health care professionals and organizations for payment of services deliv ered. Both public (e.g., Medicare, Medicaid) and private (e.g., Blue Cross, United Healthcare, Aetn a) entities maintain such databases on the individuals with whom they have a contractua l arrangement to provide payment. Typically, providers bill multiple insurers for services. Notes about the data source For information to be present in the database, a patient has to have used a service, a claim must have been filed, th e service must have been covered, and (usually) payment must have been made . Claims are based on structured coding systems (ICD-9/10, CPT-OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-23 PREPUBLICATION COPY: UNCORRECTED PROOFS IV, NDC, DRG) and do not generally include clini cal details (e.g., results of history and physical examinations, diagnostic testing re sults) except as categorical c odes. Because data are available electronically and represent the universe of claims filed for any insurer, the probability that a patient or episode of care has been selected for analysis can be calculat ed. Because health care professionals and organizations bill multiple insu rance companies, each of which has different rules, it can be difficult to understand the hea lth care professionals' and organizations' overall practices with data from a single source. Methods for identifying case s for review (denominator) Although a random sample of claims or groups of claims could be selected, it is mo re common to focus studies on those with patterns of care consistent with the possibility that a diagnostic error occurred. Methods for determining if an error occurred (numerator) Frequently, an algorithm is developed to determine when an error likely occurred, such as cases in which there is no evidence that a diagnostic test was done prior to a new diagnosis being made (e.g., breast cancer diagnosis in the absence of a screening mammogram). Health in surance claims data may be linked to other data sources (e.g., National Deat h Index, diagnostic testing results, medical records) to make a determina tion that an error occurred. What is known Within the quality and safety field, improvements in the measurement of both process and outcome measures of quality have been made possible by the expanding use of health information technology (health IT) and ad ministrative claims databases over the past several decades. For example, administrative cl aims databases linked to validated federal death registries have made possible the measurement of 30-day mortality for acute MI, heart failure, and pneumonia, all of which are considered as outcome measures of quality. Similar databases provide the backbone for measuring process quality measures (such as 30-day re- hospitalizations, appropriate asse ssment of left ventricular func tion in patients with congestive heart failure, and retinopathy screening among patie nts with diabetes). There are a few examples of the use of these data for investigating di agnostic error. Newman-Toker and colleagues (2014) identified patients who were admitted to the hospital with a diagnosis of stroke who in the previous 30 days had been treated and released from an emergency department for symptoms consistent with a stroke. They found that 12.7 percent of stroke admissions reflected potential missed stroke diagnoses and 1.2 percent refl ected probable missed diagnoses. These rates suggest that 15,000 to 165,000 stroke diagnoses are missed annually in the United States, with a higher risk for missed diagnoses among younger, female, and white patients. The researchers note that their estimates of diagnos tic error are inferred rather than confirmed because of the lack of clinical detail in health insurance claims. Opportunities for improvement Administrative claims databases maintained by the Centers for Medicare & Medicaid Services (CMS) and by commercial insure rs offer the possibility of measuring certain types of diagnostic errors, identifying their downstream clinical consequences and costs, and understanding the system-, health car e professional-, and patie nt-level factors that are associated with these errors. For example, analyses of claims data could be used in \"look back\" studies to identify the frequency with which acute coronary syndrome is misdiagnosed. Specifically, for those enrollees 3-24 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS who are ultimately diagnosed with acute cor onary syndrome, analys ts could explore how frequently these beneficiaries were seen by health care professionals in the week prior to ultimate diagnosis (either in outpatient, emergency department, or hospital settings), the incorrect diagnoses that were made, and the factors associated with the dia gnostic error. For instance, this epidemiologic approach using large administ rative databases would make it possible to determine whether the diagnostic error occurs more frequently in specific hospitals, among specific types of clinicians or practice settings, or during part icular days of the week when staffing is low or the volume of patients treated is unexpectedly high. Th e strength of this approach to understanding the epidemiology of dia gnostic error is its ability to provide national estimates of diagnostic error rates across a vast array of conditions, to understand how these diagnostic error rates vary across geography and specific settings of care, to study the impact of specific care delivery models on diagnostic erro r rates (e.g., Do accountable care organizations lower diagnostic errors?), and to update measurem ents as quickly as the administrative data are themselves collected. The main critique of this approach concerns the validity of the findings because of the limited availability of the clinical data necessary to confirm a diagnosis. Thus, this data source may be most useful in combination with other sources. Diagnostic Testing (Anatomic and Clinical Pathology) Description of the data source Diagnostic testing includes the examination of secretions, discharges, blood, or tissue usi ng chemical, microscopic, immunol ogic or pathologic methods for the purposes of making or ruling out a diagnosis. Analysis of the data may involve automated processes or a visual examination by trained he alth care professionals (clinical and anatomic pathologists). Notes about the data source A unique feature of this type of data is that the original source data (the samples) are frequently available for re-analysis or inspection by another health care professional, thus allowing for an independent assessment based on the same data. For the committee's purposes, the focus is on those diagno ses for which diagnostic testing findings are a key information source. A common taxonomy in this field distinguishes between five phases: pre-pre-analytic (i.e., deciding whet her or not to order a particular test), pre-analytic (i.e., sample labeling and acquisition, test perfor mance), analytic (i.e., the accur acy of the test or examination of the sample), post-analytic (i.e., the results are reported correctly, in terpreted correctly, and communicated back to the ordering clinician in a timely way) and post-post-analytic (i.e., the ordering clinician uses test results to inform pa tient care) (Plebani et al., 2011). For the purpose of examining the incidence of di agnostic error, the committee focused on those circumstances in which diagnostic testing results are a key inform ation source. One study estimated that at least 10 percent of diagnoses require diagnos tic testing results in order to be considered final; this number is likely higher today (Epner et al., 2013; Hallworth, 2011; Pete rson et al., 1992). Primary care clinicians order tests in about one-third of patient visits (Hic kner et al., 2014). For anatomic pathology specimens, which requir e visual inspection and clini cal judgment, second reviews by another pathologist offer in sight into the poten tial ra te of diagnostic error. Methods for identifying case s for review (denominator) Two methods are commonly used to identify cases: random samples and pre-specified criteria. Both methods allow for the OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-25 PREPUBLICATION COPY: UNCORRECTED PROOFS denominator to be characterized (i.e., the probability that a case wa s reviewed, the characteristics of the cases reviewed as compared to all cases). Methods for determining if an error occurred (numerator) Because testing involves multiple steps, there are many different methods for identif ying errors, including an examination of other data sources such as medical records, malprac tice claims, or pharmacy databases (Callen et al., 2011). For second review studies, an error is ty pically defined as a discrepancy between the findings of the first pathologist and the second pathologist. This review can identify errors in which a finding that leads to a diagnosis was mi ssed and errors in which a finding was inaccurate (i.e., no disease was found by the second reviewer). Second review studies t ypically assume that the second review is more accurate, but these stud ies do not typically link to patient outcomes. When second reviews are linked to patient outco mes, Renshaw and Gould (2005) concluded that in many cases, the first reviewer was correct. For other diagnostic tests, errors may be detected in the interpretation or communication of results in a timely manner. What is known Plebani reported that errors in laborator y medicine studies vary greatly because of the heterogeneity in study desi gns and the particular step or steps in the process that were examined (Plebani, 2010). A considerable focus on the analytic phase has led to substantial reductions in errors in that step; the pre- and post- analytic phases are seen as more vulnerable to error. A review published in 2002 found that 32 to 75 percent of errors occurred in the pre- analytic phase, 13 to 32 percent in the analytic phase, and 9 to 31 percent in the post-analytic phase (Bonini et al., 2002). One study estimated that 8 percent of erro rs had the potential to result in serious patient harm (Goldschmidt a nd Lent, 1995). A study of urge nt diagnostic testing orders in the hospital found that 62 percent of errors were in the pr e-analytic phase, 15 percent in the analytic phase, and 23 per cent in the post-analytic phase (Carraro and Plebani, 2007). A systematic review of the literature on follow-up of test results in the hospital found failure rates of 1 to 23 percent in inpatients and 0 to 16.5 perc ent in emergency department patients (Callen et al., 2011). As Berner and Graber (2008) note, second re views in anatomic pathology reveal varying discrepancy rates. The College of American Pathologists and the Associ ation of Directors of Anatomic and Surgical Pathology recently published guidelines based on a systematic review of the literature which found a medi an rate of major discrepancie s in 5.9 percent of cases (95 percent confidence interval, 2.1-10. 5 percent) (Nakhleh et al ., 2015). The study also reported variations in the rate by the se rvice performed (surgical pathology versus cytology), the organ system (single versus multiple), and the type of review (internal versus external). Kronz and Westra (2005) report a diagnostic discrepancy rate for the head and neck revealed by second review of between 1 and 53 percent for surgical pathol ogy and 17 to 60 percent for cytopathology. A 2013 study by Gaudi and coll eagues found that pathologists with dermatopathology fellowship training were more likely to disagree with preliminary diagnoses provided by non-specialist pathol ogists (Gaudi et al., 2013). Opportunities for improvement The contribution of diagnostic testing to diagnosis is substantial, but it has not been systematically quantified recently. The understanding of this critical information source could be improved by developing be tter m ethods for identifying and enumerating the diagnoses for which such testin g is critical, mechanisms for evaluating the 3-26 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS appropriateness of test ordering, and methods for determining the impact on patient outcomes. Additionally, studies that use di agnostic variance as a surrogate for accuracy (second reviews in which the second reviewer is considered more accurate) could benefit from the inclusion of patient outcomes. Subsequent sections of this chapter focus on the causes and risks associated with diagnostic error as well as better understanding th e work systems that are used to produce diagnoses and diagnostic testing will be highlighted there. Medical Imaging Description of the data source The data are visual representa tions of the interior of the body generated using a variety of methods (e.g., X-ray, ultrasound, computed tomography (CT), magnetic resonance imaging, and positron emission tomography) that are collected for the purpose of diagnosis; these visual representations generally require interp retation by a radiologist or, in certain circumstances, physicians in nucl ear medicine, emergency medicine, or cardiology. In this context, the medical imaging data are reviewed by at least one other clinician, and the findings of all health care professionals are recorded. Notes about the data source As with anatomic pathology, a unique feature of this data type is the availability of the original images for review by a second ra diologist. The focus is on those diagnoses for which medical imaging results are a key information source. In approximately 15 percent of office visits, an imaging study is or dered or provided (CDC, 2010), whereas one or more medical imaging studies is ordered in a pproximately 47 percent of emergency department visits (CDC, 2011). In both settings, X-rays are the most common imaging method used. Methods for identifying case s for review (denominator) Typically a random sample of cases is selected for second review, although some st udies have included pre- specified criteria (e.g., cases known to have higher potential rates of erro r in interpretation, or abnormal findings only). Methods for determining if an error has occurred (numerator) An error is assumed to have occurred whenever a discrepancy exists between the two clinicians in interpreting the medical imaging study. Some studies have also involved radiol ogists conducting a second review of their own previously completed studies. What is known Berlin noted that medical imaging di screpancy rates as indicated by second review have not changed much over the past 60 years (Berlin, 2014). For instance, a study by Abujudeh and colleagues explored intra- and inter-observer vari ability in medical imaging by having three experienced radiologi sts review 30 of their own previously interpreted CT exams and 30 CT exams originally interpreted by othe r radiologists (Abujudeh et al., 2010). They found a major discrepancy rate of 26 percent for in terobserver variability and 32 percent for intraobserver variability. Velmahos and collea gues (2001) found an 11 percent discrepancy rate between the preliminary and final readings of CT scans of trauma patients. Discrepancy rates were negatively associated with level of expe rience\u2014the lower the leve l of experience of the preliminary reader, the more likely there was to be a discrepancy. In many of the second review studies in imaging, high error rates resulted from using a denominator that consisted only of abnormal cases. Studies that look at real time errors\u2014i.e., that de vise an error rate using both OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-27 PREPUBLICATION COPY: UNCORRECTED PROOFS normal and abnormal exams as the denominator\u2014sugge st an error rate in the 3 to 4.4 percent range (Borgstede et al., 2004). Opportunities for improvement Medical imaging plays a key role in many diagnoses, and errors in the use and interpretati on of these studies can contribute to diagnostic error. For the purposes of estimating the incidence of diagnostic error due to errors related to medical imaging, it would be useful to identify the subset of diagnoses for which medical imaging results are central to making the diagnosis and to conduct st udies to determine the likelihood of errors, the nature of those errors, and the variation in the circumstances under which errors occur. The role of second reviews in error recovery\u2014identifying and \"intercepting\" errors before they affect patient outcomes\u2014both for medical imaging and anatomic pathology is discussed in Chapter 6. Clinician Surveys Description of the data source The data come from questio nnaires (written, telephone, interview, web-based) that obtain clinicians' self -reports about diagnostic e rrors they have made or what they know about diagnostic errors made by other clinicians. The information content of such surveys can vary. Notes about the data source As with all surveys, the result s can be affected by a number of biases, including non-response bias (non-respond ers being systematical ly different from responders, such as being more or less likely to have committed a diagnostic error) or reporting bias (systematic differences in the information that is revealed or suppressed, such as not reporting more serious errors). Unless the self-re port can be compared to an authoritative source, it is difficult to determine the validity of rates based solely on self-report. Surveys usually have the advantage of anonymity, which might make re spondents more likely to report their errors accurately than other methods. Methods for identifying case s for review (denominator) Surveys are frequently conducted on random samples of clinicians, making the implic it denominator the number of opportunities a clinician had to make a diagnosis in the st udy period. Convenience samples are also used (e.g., surveys of clinicians participati ng in a continuing medical educa tion course). Reports of survey findings have used different denominators, but of ten the denominator is th e number of clinicians responding to the survey. Methods for determining if an error occurred (numerator) An error is judged to have occurred when a clinician self-reports having made one or more diagnostic errors in the study time-frame. Some studies have asked about erro rs known to the clinician that were made by other clinicians or experien ced by family members. This approach makes estimating the incidence rate nearly impossible, as the true denominator is unknown. What is known Schiff et al. (2009) surveyed physicians and asked them to recall instances of diagnostic error. In their analysis of 583 reports of diagnostic error, they found that physicians readily recalled instances of diagnostic error; th e most commonly reported diagnostic errors were pulmonary embolism, drug reactions, cancer, acute coronary syndrome, and stroke. Singh and 3-28 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS colleagues (2010b, p. 70) surveyed pediatricians a bout diagnostic errors and found that \"more than half of respondents reported that they made a diagnostic error at least once or twice per month.\" In another survey of physicians, 35 percent re ported that they ha d experienced medical errors either in their own or a family member's care (Blendon et al., 2002). Opportunities for improvement For the purposes of making nati onal estimates of the incidence of diagnostic errors, it would be useful to have more clearly defined sampling frames, more detailed questions about the natu re of the errors and the circum stances surrounding the error, and an opportunity to compare this method to other me thods that use different data sources. Surveys have the advantage of being a potentially easy way to get a snapshot of diagnostic error rates, but the quality of the information may make this sour ce less useful for other a pplications. The biases that are inherent in surveys are difficult to overcome and likely limit the utility of this source. Patient Surveys Description of the data source The data come from questio nnaires (written, telephone, interview, web-based) that obtain patients' se lf-reports about diagnosti c errors they have experienced or their awareness of diagnostic errors experienced by others. The information collected can vary. Notes about the data source As with all surveys, the resu lts can be affected by non-response bias and by reporting bias. Unless there are oppo rtunities to compare answers to other data sources, it may not be possible to confirm the va lidity of the responses. Patient definitions of diagnostic errors might vary from the definitions of health care pr ofessionals. Patient surveys can be very useful in determining whether a new h ealth problem was explained to the patients and whether they understood the explanation. Methods for identifying case s for review (denominator) Surveys are usually conducted on a sample of patients that is randomly drawn fr om some population (e.g., geographic area, members of a health plan, and patients w ho utilize a specific car e setting) or selected so that the patients meet certain criteria (s imilar to the trigger tool s discussed above). Convenience samples are also used. Methods for determining if an error occurred (numerator) The determination of an error is based on self-report by the patient. Some studies inquire about both the pa tient's own experience and that of others known to the patient. The latte r approach makes it impossible to estimate a true incidence rate because of uncertainty around the real size of the denominator. What is known In one survey of patients, 42 percent reported that they had experienced medical errors either in their own or a family member's care (Blendon et al., 2002). A poll commissioned by the National Patient Safety Foundation found that approximately one in six of those surveyed had experience with diagnostic error, either personally or through a close friend or relative (Golodner, 1997). More recently, 23 percent of people surveyed in Massachusetts indicated that they or someone close to them had experienced a medical error, and approximately half of these errors were diagnostic errors (Betsey Lehman Center for Patient Safe ty and Medical Error Reduction, 2014). Weissman and colleagues (2008) surveyed patients about adverse events OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-29 PREPUBLICATION COPY: UNCORRECTED PROOFS during a hospital stay and compared survey-detecte d adverse events with medical record review. Twenty-three percent of surveyed patients reported at least one adverse event, compared to 11 percent identified by medical record review. Opportunities for improvement The particular value of patient surveys is likely to be related to understanding failures at the front end of the diagnostic process (f ailure to engage) and in the process of delivering an explanation to the patient. Both are crit ical steps, and patients are uniquely positioned to report on those elements of diagnostic performance. The committee did not have examples of this application, and pot ential future uses are discussed in Chapter 8. Other Methods A variety of other methods have been empl oyed to examine different dimensions of diagnostic error. These methods were not included in the table because they are unlikely to be a major source for estimating the incidence of error. Patient actors, or \"standardized patients,\" ha ve been used to asse ss rates of diagnostic error. Patient actors are asked to portray typica l presentations of diseas e, and clinicians are assessed on their diagnostic performance. In one study in internal medicine, physicians made diagnostic errors in 13 percent of interactions with patien t actors portraying four common conditions (Peabody et al., 2004). In a more r ecent multicenter study with unannounced patient actors, Weiner et al. (2010) looke d at both biomedical-related errors (such as errors in diagnosis and treatment) and context-related errors (such as the lack of recognition that a patient may be unable to afford a medicine based on certain pa tient cues) in patient management. They found that physicians provided care that was free from errors in 73 percent of the uncomplicated encounters but made more errors in more complex cases (Weiner et al., 2010). Many health care organizations in the United States have systems in place for patients and health care professionals to report minor and major adverse events. However, voluntary reporting typically results in unde rreporting and covers only a limited spectrum of adverse events (AHRQ, 2014b). For example, one study found that over half of voluntary reports concentrated on medication/infusion adverse events (33 percent) , falls (13 percent), and administrative events, such as discharge process, documentation, and communication (13 percent) (Milch et al., 2006). In Maine, the use of a physician champion to en courage voluntary diagno stic error reporting was implemented in 2011. During the 6-month pilot, ther e were 36 diagnostic erro rs reported. Half of the diagnostic errors were associated with modera te harm, and 22 percent of the diagnostic errors were classified as causing se vere harm (Trowbridge, 2014). Direct observation is another method that ha s been used to identify medical errors. Andrews and colleagues (1997) conducted observa tional research within a hospital setting, and found that approximately 18 percent of patients in the study experienced a serious adverse event. There have also been efforts to assess dis ease-specific diagnostic error rates, using a variety of data sources and methods. Berner a nd Graber (2008) and Sc hiff and colleagues (2005) provide examples of diagnostic errors in a variety of disease conditions. Summary of Approaches to Assess the Incidence of Diagnostic Error 3-30 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS A number of methods have been used to asse ss the frequency with which diagnostic error occurs. Based on the committee's review, the most promising methods for estimating incidence are postmortem exams, medical record reviews, and malpractice claims analysis, but none of these alone will give a valid estimate of the inci dence of diagnostic error. This conclusion is consistent with studies in the broader area of medical errors and adverse events. For example, the Office of the Inspector General of the U.S. Department of Health and Human Services completed an analysis that compared different measurement methods (nurse reviews, analysis of administrative claims data, patient interviews, anal ysis of incident report s, and an analysis of patient safety indicators) and found that 46 percen t of patient safety events were identified by only one of the methods (Office of Inspector Ge neral, 2010). Levtzion -Korach and colleagues (2010) compared information gathered with fi ve different measuremen t approaches\u2014incident reporting, patient complaints, risk management, medical malpractice claims, and executive walk rounds\u2014and concluded that each measurement method identified different but complementary patient safety issues. In a re lated commentary, Shojania concl uded that \"it appears that a hospital's picture of patient safety will depend on the method used to generate it\" (Shojania, 2010, p. 400). This suggests that no one method will perfectly capture the nature and the magnitude of medical errors and adverse events in health care: \"[A] compelling theme emerged . . . . different methods for detecting patient sa fety problems overlap very little in the safety problems they detect. These methods complement each other and should be used in combination to provide a comprehensive safety picture of th e health care organization\" (Shekelle et al., 2013, p. 416). This likely applies to the measurement of diagnostic errors; with the complexity of the diagnostic process, multiple approaches will be necessary to provide a more thorough understanding of the occu rrence of these errors. Determining the Causes and Risks of Diagnostic Error This section describes how measurement can be used to better characterize diagnostic errors by identifying the causes and the risks associated with diagnostic error. Characterization of diagnostic errors requires understanding (1) wh ich aspects in the di agnostic process are susceptible to failures and (2) what the contribu ting factors to these failures are. The committee used its conceptual model and input from other frameworks to provide a context for the measurement of the causes and risks of diagnos tic error. Measurement can focus on diagnostic process steps, the work system components, or both in order to identify causes and risks of diagnostic error. Diagnostic Process and Measurement Approache s to Identifying Potential Failures Because the diagnostic process is a complex, te am-based, iterative process that occurs over varying time spans, there are numerous opportunitie s for failures. The failures can include: (1) the step never occurring, (2) the step being done incompletely or incorrectly (accuracy), and (3) a meaningful delay in taking a step (timeliness). In Figure 3-2 the committee's conceptual model is used to identify where in the di agnostic process these failures can occur, including the failure of engagement in the health care system, failure in the diagnostic process, failure to establish an explanation of the health problem, and failure to communicate the explanation of the health problem. O F OVERVIEW OF D FIGURE 3-2 P l DIAGNOS TIC ER laces in the dia g RROR IN HEAL T PREPgnostic process w TH CARE PUBLICATION Cwhere failures c COPY: UNCORR E can occur that c o ECTED PROO FSontribute to dia g S gnostic errors. IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Table 3-2 is organized around the major steps in the diagnostic process and adapts Schiff and colleagues' (2009) framework to the failures associated with each of these steps. For example, diagnostic testing is part of severa l diagnostic steps where failures may happen\u2014i.e. during information gathering, inte gration, and interpretation. The la st column identifies some of the methods that can be used to identify failures in actual practice settings. Experimental laboratory methods are a complementary approach to the methods in Table 3-2 to understand potential failures related to reasoning (Kostopoulou et al., 2009, 2012; Zwaan et al., 2013). The following discussion includes more information a bout the measurement approaches that can be used at each of these steps. Failure of engagement This step primarily involves either patients not recogni zing symptoms or health risks rapidly enough to access the health care system or patients experiencing significant barriers to accessing health care. Health care organizations are familiar with routine measures of eligible patients presenting for common screening tests; these syst ems can be extended to detect other failures to engage (or re-engage) related to routine monitoring for disease progress, follow- up of abnormal test results, and so on (Kanter, 2014; Singh et al., 2009). Surveys and interviews with patients can be used to identify appro aches that are likely to be successful (and unsuccessful) in reducing dela ys and increasing engagement . The CRICO benchmarking study found that 1 percent of ma lpractice claims had an error asso ciated with a failure to engage (CRICO, 2014). Failure in information gathering The information gathering step can involve failures to elicit key pieces of information, a failure to order the right diagnostic testing (i n the right sequence or with the right specification), or technical errors in the way that samples are handled, labeled, and processed. The CRICO benchmarking study found that 58 percent of cases had one or more errors in the initial diagno stic assessment (CRICO, 2014). Failure to order appropriate diagnostic tests has been found to account for 55 percent of missed or delayed diagnoses in malpractice claims in ambulatory care (Gandhi et al., 2006) and 58 percent of errors in emergency departments (Kachalia et al., 2006). In their exam ination of physician-reported cases of error, Schiff and colleagues (2009) found that a failure or delay in ordering needed tests was the second most common factor contributing to a diagnostic error. Methods of rapid detection might include random reviews, diagnostic tri gger tools, checklists, observation, video or audio recording, and feedback. Failure in interpretation Inaccurate or failed attempts to inte rpret information gathered in the diagnostic process can involve such things as diagnostic tests, clin ical history and interview, or information received from referral and consultati on with other clinicians. CRICO reported that 23 percent of cases in its malpractice benc hmarking study had errors in diagnostic test interpretation; 49 percent had er rors in medical imaging, 20 per cent in medicine, 17 percent in pathology, and 8 percent in surgery (CRICO, 2014) . Schiff and colleagues (2009) reported that an erroneous laboratory or radiol ogy reading of a test contribute d to 11 percent of the diagnostic errors that they examined. Studies have shown that an incorrect interpretation of diagnostic tests occurs in internal medicine (38 percent reporte d in Gandhi et al., 2006) and emergency medicine (37 percent reported in Kachalia et al., 2006) . Hickner and colleague s (2008) found that 8.3 percent of surveyed primary care physicians re ported uncertainty in interpreting diagnostic OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-33 PREPUBLICATION COPY: UNCORRECTED PROOFS testing. Failure in interpretati ons for medical imaging and anatomic pathology can be identified through second reviews conducted by expert clinicians. Failure in integration Integration failures can be divided in to failures in hypothesis generation, the suboptimal weighting and prioritization of information gathered in the diagnostic process, and the failure to recognize or weight urgency of clinical signs or symptoms. In examining major diagnostic errors, Schiff and colleagues (2009) found that 24 percent were the result of a failure to consider or a delay in considering the corr ect diagnosis. Potential approaches to measuring failure in integration include stru ctured debriefings with the clinicians involved, conferences that review diagnostic e rrors (such as morbidity and mortality conferences and root cause analyses), and random reviews. Failure to establish an explanation (diagnosis) Failures can also occur when there is a failure to establish the explanation of the patient' s health problem. This can include suboptimal weighting and prioritization of c linical signs and symptoms, delays in considering a diagnosis, or failing to follow up with patients (including fail ing to create and implement an appropriate follow-up plan). CRICO (2014) found that referral errors were common in cancer cases in which there were diagnostic errors (48 percent of cases lacked appropriate referrals or consults). Methods for identifying these failures include random reviews and the analysis of expected follow up, such as Kaiser Permanente's SureNet system (Graber et al., 2014). Failure to communicate the explanation Failures to communicate the explanation of a patient's health problem can include cases in which no communication was attempted, in which there was a delay in communicating the e xplanation, or in which the co mmunication occurred but it was not aligned with a patient's he alth literacy and language need s and was not understood. CRICO (2014) reported that 46 percent of cases in its benchmarking study involved a failure in communication and follow-up, including 18 percent of cases where the clinician did not follow- up with the patient and 12 percent of cases wher e the information was not communicated within the care team. Potential measurement methods for this step include video recording and debriefing, patient surveys, medical record reviews, and shared decision-making results. TABLE 3-2 Methods for Detecting Failures Across the Diagnostic Process Where in the Diagnostic Process the Failure Occurred Nature of Failure a Methods for Detecting Failures Failure to engage in the health care system or in the diagnostic process Delay in patient presenting Patient unable to access care Analysis of emergency department, urgent care, and other high-risk cohorts Surveys to determine why and what could be done differently Failure in information gathering Failure/delay in eliciting key history, physical exam finding Failure to order or perform needed tests Random reviews Diagnostic trigger tools (e.g., high-risk cohort algorithms and missed opportunity targets) 3-34 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Failure to review test results Wrong tests ordered Tests ordered in the wrong sequence Technical errors in the handling, labeling, processing of tests Comparison to checklists Video recording and debriefing (e.g., \"stimulated recall\") Failure in interpretation Inaccurate or failed interpretation of history, physical exam findings, test results Second review of samples Failure in integration Failures in hypothesis generation Suboptimal weighting and prioritization Failure to recognize or weight urgency Debriefing Diagnostic conferences Random exams Failure to establish an explanation (diagnosis) Suboptimal weighting and prioritization Delay in considering diagnosis Failure to follow up Scientific knowledge limitations (e.g., signs and symptoms that have not been recognized as a specific disease) Random reviews Examination of expected follow-up (e.g., Kaiser Permanente's SureNet system) Postmortem examinations Failure to communicate explanation to patient Patient not notified Delay in notification Incomplete explanation Patient does not understand explanation Video recording and debriefing Survey patients Medical record review Shared decision making result a Adapted from Schiff et al. (2009). Other researchers have employed different classification schemes to illustrate where in the diagnostic process failures occur. For example, some researchers have classified the diagnostic process into three phase s: initial diagnostic assessme nt; diagnostic test performance, interpretation, and results reporting; gnostic follow-up and c oordination (CRICO, 2014; Lyratzopoulos et al., 2015). Another framework that is useful to de pict the steps in the diagnostic testing process where failures can occur is the brain-to-brain l oop model described in Chapter 2. The nine-step process was origin ally developed in the laborato ry medicine setting (Lundberg, 1981; Plebani et al., 2011), but it can be applied to anatomic pathology and medical imaging as well. These nine steps occur duri ng five phases of testing: pre- pre-analytical (clinician test selection and ordering), pre-analytical (sample preparation), analytical (testing and examination), post-analytical (the generation of results, repor ting, interpretation, and fo llow-up), and post-post- analytical phases (the integra tion of results into the patient context and subsequent decision making). Targeted measurement has shown that the phases of the process that are most prone to errors occur outside of the anal ytical phase and incl ude test ordering (part of the diagnostic process information-gathering step) and subseq uent decision making on the basis of the test OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-35 PREPUBLICATION COPY: UNCORRECTED PROOFS results (part of et al., 2013; Hi ckner et al., 2014; Plebani et al., 2011). Work System and Measurement Approaches to Id entifying Potential Vu lnerabilities and Risk Factors In considering the options for making significant progress on the pr oblem of diagnostic error, it is important to understa nd the reasons why these failures occur. For this discussion, the committee draws on the general patient safety lit erature, and applies it specifically to the challenge of diagnostic error. Traditional approa ches to evaluating medical errors have focused on identifying individuals at fault. However, the modern patient safety movement has emphasized the importance of a systems approach to understanding medical errors. According to the IOM report To Err Is Human: Building a Safer Health System : The common initial reaction when an error occurs is to find and blame someone. However, even apparently single events or errors are due most often to the convergence of multiple contributing factors. Blaming an individual does not change these factors and the same error is likely to recur. Preventing errors and improving patient safety for pa tients require a systems approach in order to modify the conditions that c ontribute to errors. People working in health care are among the most educat ed and dedicated workforce in any industry. The problem is not bad people; the problem is that the system needs to be made safer (IOM, 2000, p. 49). Often, a diagnostic error has multiple contributing factors. One analogy that has been employed to describe this phenomenon is the Swiss cheese model developed by psychologist James Reason (AHRQ, 2015a; Reason, 1990). In this model, a component of the diagnostic process would represent a slice of cheese in a stack of slices . Each component within the diagnostic process has vulnerabiliti es to failure (represented by the holes in a slice of Swiss cheese); in a single step of the diagnostic proces s, this may not affect the outcome. However, if the vulnerabilities (hol es in the Swiss cheese) align, a diagnostic error can result. Another way to think about the causes of diagnostic error is to distinguish between active errors and latent errors. Active e rrors typically involve frontline clin icians (sometimes referred to as the \"sharp end\" of patient safety) (IOM, 2000) . In contrast, latent errors are more removed from the control of frontline clinicians and can include failures in organi zations and design that enable active errors to cause harm (often calle d the blunt end of patie nt safety) (AHRQ, 2015a; IOM, 2000). In the event of a medical error, too often the focus is on identifying active errors, especially within health care organizations wi th punitive cultures that focus on individual blame and punishment. But the IOM noted that: Latent errors pose the greatest threat to safety in a complex system because they are often unrecognized and have th e capacity to result in multiple types of active errors. . . . Latent errors ca n be difficult for people working in the system to notice since the errors ma y be hidden in the design of routine processes in computer programs or in the structure or management of an 3-36 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS organization. People also become accust omed to design defects and learn to work around them, so they are ofte n not recognized (IOM, 2000, p. 55). In line with the IOM's ea rlier work, the committee took a systems approach to understanding the causes and risks of diagnostic errors. Consistent with the committee's conceptual model, measurement for this purpose examines the different dimensions of the work system to identify the circumstances under which diagnostic errors are more (and less) likely to occur and to identify the risk f actors for such errors. Factors cont ributing to diagnostic errors can be mapped along the components of the work sy stem, including diagnostic team members and their tasks, technologies and tool s, organizational characteristics and the physical environment, and the external environment. Some of the more familiar approaches for assessing the system causes of medical errors are morbidity and mortality conferences that appl y a modern patient safety framework (a focus on understanding contributing factor s rather than a focus on indi vidual errors and blame) (Shojania, 2010) and root cause analyses (AHR Q, 2015b). For example, root cause analysis methods were applied to identify the factors that contributed to de lays in diagnosis in the U.S. Department of Veterans Affairs system (Giardina et al., 2013). Diagnostic e rrors have also been evaluated in morbidity and mortality conferences (Cifra et al., 2015). As the committee's conceptual model shows, the diagnostic process is imbedded in a work system. Examining how the various dimensions of the work system contribute to diagnostic errors or how they can be configured to enhance diagnostic performance leads to a deeper understanding of the complexity of the process. Table 3-3 identifies the di mensions of the work system, the contribution each makes to diagnostic errors, and examples of measurement methods that have been used to assess each area. A lthough diagnostic team members are a critical component of the work system, approaches to en suring diagnostic competency are addressed in Chapter 4 and they are not included here. The focu s here is on the specific measurement tools that are available to help health care organizations better identify aspects of the work system that present vulnerabilities for diagnos tic errors. A distinctive feature of some of these methods is that they can be used proactively to identify risk s before an error occurs, versus the measurement methods described above that examine steps lead ing to an error that has already occurred. TABLE 3-3 Methods for Assessing the Effect of the Work System on Diagnostic Errors Work System Dimension Contribution to Diagnostic Errors Examples of Methods for Assessing Effects Tasks and workflow Problems with information o Amount o Accuracy o Completeness o Appropriateness Communication issues Task complexity Situation awareness Poor workflow design Interruptions Inefficiencies Workload Information gathering Information integration Information interpretation Information visualization (where, when, and how the information is received in the system) Fragmented workflow and lack of support for timely and accurate information flow Workaround strategies that increase risk Cognitive task and work analysis methods (e.g., decision ladder model) Observation of care process: e.g., work sampling; task analysis; video recording of care process and debriefing, e.g., stimulated recall Situation awareness OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-37 PREPUBLICATION COPY: UNCORRECTED PROOFS Workflow modeling Proactive risk assessment, including failure mode and effect analysis Technology Inappropriate technology selection Poor design Poor implementation Use error o Failure to use technology o Failure to respond to signals Failure of technology (breakdown) Misuse of automation Lack of support for stages/steps of diagnostic process: information gathering, information integration, information interpretation Data overload Information visualization (where, when, and how the information is received in the system) Usability evaluation Observation of technology in use Proactive risk assessment, including failure mode and effect analysis Organizational characteristics Culture Leadership and management Staffing Work organization (distribution of roles, rounding process, etc.) Scheduling Not supporting work system design efforts aimed at improving the diagnostic process and preventing/mitigating diagnostic errors Conflicting messages about regulations across the organization Confusion about responsibilities for tasks with unclear roles Reluctance to question people with greater authority Culture surveys Surveys aimed at assessing leadership and management in quality/safety improvement Interviews or focus groups with clinicians and patients Physical environment Noise Lighting Poor physical layout Additional stressors on diagnostic team members that can affect cognitive tasks in diagnostic process: information gathering, information integration, and information interpretation Physical human factors/ergonomics methods, e.g., direct assessment of noise and lighting (with equipment), survey of diagnostic team members regarding physical environment Link analysis for assessment of physical layout and team communication 3-38 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Tasks and workflow The diagnostic process involve s a series of tasks and an implicit or explicit workflow that contains and connects those tasks. A variety of challenges can occur with the tasks and workflow that are required to make a dia gnosis, including: problems with the information (amount, accuracy, completeness, appropriateness), communication issues, the complexity of the task, a lack of situational aw areness, poor workflow design, in terruptions, and inefficiencies. These issues contribute to diagnos tic error at each step in the information gathering, integration, and interpretation process; they can contribute to problems with the timeliness of information availability, and they can lead to problems in cognitive processing. There are a variety of measurement approaches that can be used to evaluate tasks and workflow. It should be noted that these are best applied in the real world environment in which the diagnosis is being made. The methods include cognitive task and work analysis (Bisantz and Roth, 2007; Rogers et al., 2012; Roth, 2008), observation of care processes (Carayon et al., 2014), situation awareness in team performance (Carayon et al., 2014; Salas et al., 1995), workflow modeling (Kirwan and Ainsworth, 199 2), and proactive risk assessment methods, including failure mode and effect analysis (Carayon et al., 2014). These methods are briefly described below. Cognitive task and work analysis The purpose of cognitive task and work analysis is to identify and describe the cognitive skills that are required to perform a pa rticular task, such as making a diagnosis. The most common method used for such an analysis is an in-depth interview combined with observations of the specific task of interest (Schraagen et al., 2000). Because cognitive errors are an important contributing factor to diagnostic errors (Croskerry, 2003) these methods are likely to have considerable utili ty in efforts to reduce errors. Koopman and colleagues (2015) used cognitive task analysis to examine the relationship between the information needs that clinicians had in prep aring for an office visit and the information presented in the electronic heal th record. They found a significa nt disconnect between clinician needs and the amount of information and the ma nner in which it was presented. This disconnect can lead to cognitive overload, a known contribu tor to error (Patel et al., 2008; Singh et al., 2013). The researchers recommended significant ree ngineering of the clinical progress note so that it matched the workflow and inform ation needs of primary care clinicians. Observations of care processes Process observation is a means of verifying what exactly occurs during a particular process (CAHPS, 2012). Freq uently, these observations are documented in the form of process maps, which are graphical re presentations of the va rious steps required to accomplish a task. The approach is able to capt ure the complex demands imposed on members of the diagnostic team, and allows for the \"documentation of th e coordination and communication required between clinicians to complete a task, use their expertise, tools, information and cues to problem solve\" (Rogers et al., 2012). For exampl e, Fairbanks and colleagues (2010) used this method to examine workflow and information flow in an emergency department's use of digital imaging by applying both hierarchical task analysis and information process diagrams. The analysis identified gaps in how the informati on system for imaging supported communication between radiologists and emergency department phys icians. In analyzing diagnostic error, this technique can identify the role that contextual or social factors play in assisting or impeding problem resolution (Rogers et al., 2012). Observations of care pr ocess es can also provide input for other work system analysis methods, such as cognitive task and work analysis as well as failure mode and effect analysis. OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-39 PREPUBLICATION COPY: UNCORRECTED PROOFS Situation awareness Endsley (1995, p. 36) defined situati on awareness as \"the perception of elements in the environment within a volume of time and space, the comprehension of their meaning, and the projection of their status in th e near future.\" Situation awareness has been applied at the individual, team, and system level. There are a variety of approaches to measuring situational awareness, including objective and subjective measures , performance and behavioral measures, and process indices. Because of the multidimensional nature of the construct, a combination of approaches is likely most usef ul. Examples of measurement tools in medicine include the Anesthetists' Non-Technical Skills (ANTS) measure (Fletcher et al., 2003), the Ottawa Global Rating Scale (Kim et al., 2006), and an instrument to measur e pediatric resident's self-efficacy skills (which include situational awareness) in crisis resource management (Plant et al., 2011). Workflow modeling Workflow modeling is a form of prospective analysis used to describe the processes and activ ities involved in completing clin ical tasks. In contrast to observing work processes, modeling techniques a llow for quantitative and qualitative estimations of tasks and of the possible path s that can be taken to complete them (Unertl et al., 2009). Challenges to workflow modeling in health care\u2014 and diagnosis in particular\u2014include the fact that clinicians must remain flexible because of the need to respond to non-routine presentation of symptoms, results, and events as well as the vari ability in workflow across different health care organizations. Resulting models can be adapted and modified as necessary to reflect observations of care processes. Numerous methods for wo rkflow modeling exist. Carayon et al. (2012) describe 100 methods in 12 categories (e.g., data display/organizati on methods and process mapping tools) for workflow modeling of the im plementation of health IT. Jun et al. (2009) focus on eight workflow or process modeling methods that have been used in quality improvement projects; these include flowchar ts and communication diagrams. These methods have great potential for help ing to understand the dynamic se quences of tasks performed by various team members in the diagnostic process. Prospective risk assessment The term \"prospective risk asse ssment\" refers to a variety of methods that are used to identify, evaluate, a nd minimize potential risks or vulnerabilities in a system. An example of such a method is Failure Mode and Effect Analysis (FMEA). Several steps are involved in FMEA, including graphicall y describing the process, observing the process to ensure that the diagram is an accurate re presentation, brainstorming about failure modes, conducting a hazard analysis (i.e., di fferent ways in which a particul ar process can fail to achieve its purpose), and development of a plan to address each failure mode along with outcome measures. DeRosier and colleagues (2002) describe the use of this method by the VA National Center for Patient Safety and provide c oncrete examples of its application. Technology A variety of technologies are used in the diagnostic process, and these can contribute to diagnostic errors for a variety of reasons, in cluding inappropriate technology selection, poor design, poor implementation, use error, technology breakdown or failure, and misuse of automation. Technology failures contribute to problems in information gathering, interpretation, and integration; they may also produce information overload and may interfere with cognitive processes because of problems w ith the way the information is received and displayed. 3-40 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Methods for improving the selection, desi gn, implementation, and use of technology involve some of the methods described above, such as workflow modeling, FMEA, and other proactive risk assessment methods. In particul ar, many health care organizations have been concerned about whether enough attention is being paid to the usability of health IT. For example, Friedberg and colleagues (2013) in a st udy of physician job sati sfaction found that a number of factors related to electronic health records (EHR s) had a substantial impact on satisfaction, including: poor usab ility, the time required for data entry, interference in patient interactions, greater inefficiencies in work flow, less fulfilling work content, problems in exchanging information, and a degradation of c linical documentation. This study used a mixed- method design which included semi-structured and structured interviews with physicians. Its findings were consistent with re search using other methods to a ssess the extent to which EHRs are enhancing care delivery (Armijo et al., 2009 ; Unertl et al., 2009). The American Medical Informatics Association Board of Directors issued recommendations about improving the usability of EHRs which were ba sed in large part on usability st udies that had been conducted by Middleton and colleagues (2013). Th e use of various usability ev aluation methods can help in ensuring that usability concerns are addressed as early as possi ble in the design process. For example, Smith and colleagues incorporated us ability testing into the design of a decision- support software tool to catch missed follow-up of abnormal cancer test results in the VA (Smith et al., 2013). These various possi ble usability evaluation methods include heuristic evaluation methods, scenario-based usability evaluation, user testing, and the observation of technology in use (Gosbee and Gosbee, 2012). Organizational characteristics Culture, leadership, and management are some of the organizational characteristics that can affect the diagnostic process. Some of the culture-related issues that can contribute to diagnostic error are a lack of organizational support for improvements, conflicting messages about regulations, confusion about task responsibilities, and the perception by people that they should not speak up even when they know a problem is occurring. These issues have been identified in the broade r context of patient safety but are likely to affect diagnostic processes as well. The main mechanisms for assessing these organizational characteristics are surveys (about culture, leadersh ip, management, collaboration, co mmunication) and focus groups. For instance, Shekelle and colleague s (2013) identified a number of su rvey-based measures in these areas as part of a report on the context-sensitivity of patient safety practices. Physical environment Various characteristics of the physic al environment (e.g., noise, lighting, layout) may affect the dia gnostic process (Alvarado, 2012; Parsons, 2000). The physical environment places additional stresses on a diagnos tic team that can aff ect the performance of cognitive tasks and information gathering, interpretation, and integration. For example, the layout and lighting of the radiology reading room may hinder accurate viewing of screens. Emergency departments are another example of a place where it makes sense to examine the effects of the physical environment on di agnostic errors (Campbell et al., 2007). Human factors/ergonomics methods can be used to evaluate the physical environment. These methods include, for example, making a direct assessment of noi se and lighting with specific equipment (e.g., a light meter) and observing care processes in situ in order to identify challenges related to layout. For instance, obser ving the physical m ovements of clinicians can help identify communication among team memb ers and the barriers posed by the physical OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-41 PREPUBLICATION COPY: UNCORRECTED PROOFS environment (e.g., lack of available equipment or poorly located equipment; see Potter et al., 2004; Wolf et al., 2006.) In additi on, surveys can also be used to gather data from a larger population of staff and patients about environmenta l characteristics, such as the adequacy of lighting and the perception of noise and its impact. In an exam ple of this approach, Mahmood and colleagues surveyed nurses about the aspects of their physical environment that affected the risk of medication errors (Mah mood et al., 2011). Many of these factors contribute to latent errors\u2014for example, creating conditions under which cognitive functioning is impaired because of the work environment itself. Summary The committee reviewed a number of methods for assessing the e ffects of the work system on diagnostic error. This section of the chapter highlights a number of those methods and illustrates how they have been applied in various health care settings to develop insights into the risks of error and to identify potential areas for improvement. The methods have in common the fact that they combine observation of the act ual processes (tasks, co mmunication, interaction with technology) with documenta tion of those processes. These methods can be relatively labor intensive, and they tend to require application at the individual site level, which implies that this is work that all teams and settings in which diag noses are made need to become more skilled at undertaking. While standardized tools exist (surveys, methods of observation, and analysis of teams) and might be applied to samples of diffe rent types of teams a nd settings to identify particular vulnerabilities for diagnostic error, the most usef ul application of these methods is typically for improvement at the local level. The human factors science in this area suggests that a number of likely problems can be readily iden tified\u2014that is, that deep study may not be necessary\u2014but the complexity of the interactions among these vari ous factors suggests that high levels of vigilance and attention to measuremen t will likely be necessary throughout the health care system. Evaluating Interventions Measurement will be critical to assessing whether changes that are intended to improve diagnosis and reduce diagnostic e rrors are effective. Changes can be implemented and evaluated as part of a quality improvement program or a research project. For bot h purposes it would be helpful to develop assessment tools that can be implemented within routine clinical practice to rapidly identify potential failures in the diagnostic process, to alert clinicians and health care organizations to diagnostic errors, and to as certain trend changes over time. For quality improvement approaches, establishing a baseline (knowing the current rate of failure in a particular step in the diagnostic process using some of the measurement methods in Table 3-2) will provide the main method for understanding whether interventions are having the desired effect. For research studies, the specific aims and change strategy under evaluation will indicate what measurement choice should be made from a broader set or possibilities (e.g., long-term clinical outcomes, diagnostic errors, diagnostic process failur es, and contextual variables hypothesized or known to influence diagnostic performance). In some cases the aim of measurement will be to assess whether interventions designed to address specific failures are resulting in lower failure rates. In other cases th e aim of measurement will be to assess whether a global intervention reduces multiple causes simu ltaneously. This purpose relates to the work system focal point for analysis and intervention (Table 3-3 measur es). An important contribution 3-42 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS to research in this area will be the identifica tion of approaches that can reduce the risk for diagnostic error. There have been few studies that have eval uated the impact of interventions on improving diagnosis and reducing diagnos tic error. McDonald and colleagues (2013) conducted a systematic review to identify interventions ta rgeted at reducing diagnostic error. They found more than 100 evaluations of interventions a nd grouped them into six categories: \"techniques (changes in equipment, procedures, and clinical approaches); personnel changes (the introduction of additional health care professionals or the replacement of certai n health care professionals for others); educational interventions (residency training, curricula, and maintenance of certification changes); structured process changes (implementation of feedback mechanisms); technology- based interventions (clinical decision support, text messaging, and pager alerts); and additional review methods (independent reviews of test results)\" (McDonald et al., 2013, p. 383). The measures used in these intervention studies in cluded diagnostic accuracy, outcomes related to further diagnostic test use, outco mes related to further therapeu tic management, direct patient- related outcomes, time to correct therapeutic management, and time to diagnosis; 26 of the 100 intervention studies examined diagnostic delays. The researchers identified 14 randomized trials (rated as having mostly a low to moderate risk of bias), 11 of which reported interventions that reduced diagnostic errors. The evidence appe ared to be strongest for technology-based interventions and specific techniques. The resear chers found that very few studies evaluated the impact of the intervention on patient outcomes (e.g., mortality, morbidity ), and they suggested that further evaluations of pr omising interventions should be conducted in large studies across diverse settings of care in order to enhan ce generalizability (McD onald et al., 2013). Two previous evaluated the impact of \"system-related interventions\" and \"cognitive interventions\" on the reduction of dia gnostic errors (Graber et al., 2012; Singh et al., colleagues concl uded, \"Despite a number of suggested interventions in the literature, few empirical studies have tested interventions to reduce diagnostic error in the last d ecade. Advancing the science of diagnostic error prevention will require more robust study designs and rigorous definitions of diagnostic processes and outcomes to measure intervention effects\" (Singh et al., 2012b, p. 160). Grab er and colleagues identified a variety of possible approaches to reducing cognitive errors in diagnosis. Not all the suggested approaches had been tested, and of those that had been tested, they generally involved observing trainees in artificial settings, making it difficult to extrapolate the results to actual practice. \"Future progress in they concl uded, \"will require methodol ogical evaluating interventions alr eady suggested\" (Graber et al., 2012, p. 535). The three systematic reviews of diagnostic interventions draw sim ilar conclusions about the heterogeneity of measures used as well as the dearth of patient-reported outcomes. Synthesizing information from the available inte rventions is difficult because of the lack of comparable outcomes across studies. As with othe r areas of quality and patient safety, improved patient outcomes is a common goal, but it may not be practical to assess such patient outcomes during limited-time intervention studies (or quality improvement efforts). Intermediate measures that assess process failures (e.g., the developmen t of algorithms to identify and quantify missed opportunities for making a specific diagnosis among an at-risk population) or cognitive problems (e.g., debriefing to determine what biases are at pl ay and at what frequenc y) will continue to provide useful information for understanding the in fluence of an intervention at its point of expected action (as part of the di agnostic process or other compone nt of the work system , or at OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-43 PREPUBLICATION COPY: UNCORRECTED PROOFS the sharp or blunt end of care). As with other areas of patient safety research and quality improvement, evidence connecting any intermedia te measures to patient outcomes will need proper attention. Another key area of attention for patient safe ty intervention research, which applies to diagnostic error measurement, is context-sensitivit y. As noted in the section on identifying risks for diagnostic error, work system dimensions have the potential to contribut e to diagnostic error. For any diagnostic error reducti on intervention, measurement focused on context variables (e.g., dimensions of the work system, as noted in Tabl e 3-3) will allow testi ng of the hypothesized role of these variables in diagnostic error. Shekelle and colleagues (2013) pointed to the need for evidence about the context in which safety strategi es have been adopted and tested in order to help health care organizations understand what wo rks and under what circumstances, so that the intervention strategy can be ad apted appropriately to local needs. McDonald summarized domains and measurement options for studying c ontext in relation to quality improvement interventions, which could be extended to new ar eas such as diagnostic safety interventions. She noted that \"efficient and effective means to incor porate the domain of context into research . . . has received relatively minimal attention in hea lth care, even though the salience of this broad topic is well understood by practitioners and policy makers\" (McDonald, 2013, p. S51). In summary, there are a multitude of specifi c measurement choices when developing and testing interventions for quality improvement or research, but no single repository of options exists. Funders and researchers have developed repositories of measurement tools for various other topics and applications. For example, the Agency for Healthcare Research and Quality's Care Coordination Measures Atlas is a resource that incl udes a measurement framework, identified measures with acceptable performance ch aracteristics, and maps of these measures to framework domains (AHRQ, 2014a). A similar res ource would be useful for those involved in diagnostic error interventions from proof of concept through the spread of successful interventions with widespread applicability (i.e., cases in which an intervention exhibits limited context sensitivity or the cases in which an intervention works well within many contexts). Such a resource could build on the domains and measur es shown in Tables 3-2 and 3-3, as well as other sources from quality improvement and patient safety research applicable to diagnostic error. REFERENCES Abujudeh, H. H., G. W. Boland, R. Kaewlai, P. Rabiner, E. F. Halpern, G. S. Gazelle, and J. H. Thrall. 2010. Abdominal and pelvic computed tomography (CT) interpretation: Discrepancy rates among experienced radiologists. European Radiology 20(8):1952-1957. Adams, J. L., and S. Garber. 2007. Reducing medical malpractice by targeting physicians making medical malpractice payments. Journal of Empirical Legal Studies 4(1):185-222. AHRQ (Agency for Healthcare Research and Quality). 2014a. Care Coordination Measures Atlas update. www.ahrq.gov/professionals/preventio n-chronic-care/improve/coordinati on/atlas2014/inde x.html (accessed May 26, 2015., 2015.). AHRQ. 2014b. Patient Safety Network: Voluntary pa tient safety event reporting (incident reporting). http://psnet.ahrq.gov/prim er.aspx?primerID=13 ( accessed May 8, 2015). AHRQ. 2015a. tient safety primers. er.aspx?primerID=21 2015b. Patient Safety Network: Root cause analysis. www.psnet.ahrq.gov/primer.aspx?primerID=10 (accessed May 8, 2015). 3-44 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED J. 2014. Misdiagn osed: Docs' a ffect 12 million a year. NBC News . April 16. www.nbcnews.com/health/health-news/misdiagnosed -docs-mistakes-affect-1 2-million-year-n82256 (accessed October 30, 2014). Alvarado, C. J. 2012. The physical environment in health care. In P. Carayon (ed.), Handbook of human factors and ergonomics in health care and patient safety (pp. 215-234) . Boca Raton, FL, Taylor & Francis Group. Andrews, L.B., C. Stocking, T. Krizek , L. Gottlieb, C. Krizek, T. Vargish, and M. Siegler. 1997. An alternative strategy for studying advers e events in medical care. Lancet 349(9048):309-313. Armijo, D., C. McDonnell, and K. Werner. 2009. Electronic health record usability: Electronic and use case framework. AHRQ Publication No. 09(10)-0091-1-EF. Ro ckville, MD: Agency for Healthcare Research and Quality. Berenson, R. A., D. K. Upadhyay, and D. R. Kaye. 2014. Placing diagnosis errors on the policy agenda. Washington, DC: Urban Institute. http://www.urban.org/res earch/publication/placing-diagnosis-errors- policy-agenda (accessed May 22, 2015). Berlin, L. 2014. Radiologic errors, past, present and future. Diagnosis 1(1):79-84. Berner, E. S., and M. L. Graber. 2008. Overconfid ence as a cause of diagnostic error in medicine. American Journal of Medicine 121(5 Suppl):S2-S23. Betsey Lehman Center for Patient Safety and Medical Error Reduction. 2014. The public's views on medical error in Massachusetts. Cambridge, MA: Harvard School of Public Health. Bisantz, A., and E. Roth. 2007. Analysis of cognitive work. Reviews of Human Factors and Ergonomics 3(1):1-43. Blendon, R. J., C. M. DesRoches, M. Brodie, J. M. Benson, A. B. Rosen, E. Schneider, D. E. Altman, K. Zapert, M. J. Herrmann, and A. E. Steffenson. 2002. Views of practicing physicians and the public on medical errors. New England Journal of Medicine 347(24):1933-1940. Bonini, P., M. Plebani, F. Ceriotti, and F. Ru bboli. 2002. Errors in laboratory medicine. Clinical Chemistry 48(5):691-698. Borgstede, J., R. Lewis, M. Bhargavan, and J. Su nshine. 2004. RADPEER quality assurance program: A multifacility study of interpretive disagreement rates. Journal of the American College of Radiology 1(1):59-65. Brennan, T. A., L. L. Leape, N. M. Laird, L. Hebert, A. R. Localio, A. G. Lawthers, J. P. Newhouse, P. C. Weiler, and H. H. Hiatt. 1991. Incidence of adverse events and negligence in hospitalized patients: Results of the Harvard Medical Practice Study I. New England Journal of Medicine 324(6):370-376. CAHPS (Consumer Assessment of Healthcare Providers and Systems). 2012. The CAHPS improvement guide. www.facs.org/~/media/files/advo cacy/cahps/improvement %20guide.ashx (accessed July 12, 2015). Callen, J., A. Georgiou, J. Li, and J. I. Westbrook. 2011. The safety implications of missed test results for hospitalised patients: A systematic review. BMJ Quality & Safety in Health Care 20(2):194-199. Campbell, S. G., P. Croskerry, and W. F. Bond. 2007. Profiles in patient safety: A \"perfect storm\" in the emergency department. Academic Emergency Medicine 14(8):743-749. Carayon, P., R. Cartmill, P. Hoonakker, D. Krueger, L. Snellman, T. N. Thuemling, and T. B. Wetterneck. 2012. Human factors analysis of workflow in health information technology implementation. In P. Carayon (ed.), Handbook of human factors and ergonomics in health care and patient safety (pp. 507-521). Boca Raton, FL: Taylor & Francis Group. Carayon, P., Y. Li, M. M. Kelly, L. L. DuBenske, A. Xi e, B. McCabe, J. Orne, and E. D. Cox. 2014. Stimulated recall methodology for assessing work system barrier s and facilitators in family-centered rounds in a pediatric hospital. Applied Ergonomics 45(6):1540-1546. Carraro, P., and M. Plebani. 2007. Errors in a stat laboratory: Types and frequencies 10 years later. Clinical Chemistry 53(7):1338-1342. Carter, S. M., W. Rogers, I. Heath, C. Degeling, J. Doust, and A. Barratt. 2015. The challenge of overdiagnosis begins with its definition. BMJ 350:h869. CDC (Centers for Disease Control and Prevention). 2010. National Ambulatory Medical Care Survey: 2010 summary tables. www.cdc.gov/nchs/data/ahcd/na mcs_summary/2010_namcs_web_tables.pdf (accessed May 26, 2015). CDC. 2011. National Hospital Ambulatory Medical Care Survey: 2011 emergency department summary tables. www.cdc.gov/nchs/data/ ahcd/nhamcs_emergency/2011_ed_web_t ables.pdf (accessed May 26, 2015, 2015). CDC. 2015. Ambulatory health care data. www.cdc.gov /nchs/ahcd.htm (acce ssed May 18, 2015). Chimowitz, M. I., E. L. Logigian, and L. R. Caplan. 1990. The accuracy of bedside neurological diagnoses. Annals of Neurology 28(1):78-85. OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-45 COPY: UNCORRECTED PROOFS Chiolero, V. Santschi, and N. Rodondi. 201 5. How to prevent overdiagnosis. Swiss Medical Weekly 145:w14060. Cifra, C. L., K. L. Jones, J. A. Ascenzi, U. S. Bhalala, M. M. Bembea, D. E. Newman-Toker, J. C. Fackler, and M. R. Miller. 2015. Diagnostic errors in a PICU: Insi ghts from the Morbidity and Mortality Conference. Pediatric Critical Care Medicine 16(5):468-476. CRICO. 2014. Annual benchmarking report: Malpractice risks Cambridge, http://www.rmfstrategies .com/benchmarking (acce ssed June 4, 2015). Croskerry, P. 2003. The importance of cognitive errors in diagnosis and strategies to minimize them. Academic Medicine 78(8):775-780. Croskerry, P. 2011. Commentary: Lowly interns, more is merrier, and the Casablanca Strategy. Academic Medicine 86(1):8-10. Croskerry, P. 2012. Perspectives on diagnostic failure and patient safety. Healthcare Quarterly 15(Special issue):50-56. DeRosier, J., E. Stalhandske, J. P. Bagian, and T. Nudell. 2002. Using health care failure mode and effect analysis: The VA National Center for Patient Safety's prospective risk analysis system. Joint Commission Journal on Quality and Patient Safety 28(5):248-267. Endsley, M. R. 1995. Toward a theory of situation awareness in dynamic systems. Human Factors 37(1):32-64. Epner, P. L., J. E. Gans, and M. L. Graber. 2013. When diagnostic testing leads to harm: A new outcomes-based approach for laboratory medicine. BMJ Quality & Safety 22(Suppl 2):ii6-ii10. . Esserman, L., Y. Shieh, and I. Thompson. 2009. Rethin king screening for breast can cer and prostate cancer. JAMA 302(15):1685-1692. FDA (Food and Drug Administration). 2015. Initiative to reduce unnecessary radiation exposure from medical imaging. www.fda.gov/Radiation- EmittingProducts/RadiationSafety/ RadiationDoseReducti on/ucm2007191.htm (accessed May 3, 2015). Fairbanks, Guarrera, A. Bisantz, M. Venturino, and P. Westesson. 2010. Opportunities in IT support of workflow & information flow in the emergency department digital imaging process. Proceedings of the Human Factors and Ergonomics Society Annual Meeting 54(4):359-363. Fletcher, G., R. Flin, P. McGeorge, R. Glavin, N. Maran, and R. Patey. 2003. Anaesthetists' Non Technical Skills (ANTS): Evaluation of a behavioural marker system. British Journal of Anaesthesia 90(5):580-588. Friedberg, M. W., P. G. Chen, K. R. Van Busum, F. Aunon, C. Pham, J. Caloyeras, S. Mattke, E. Pitchforth, D. D. Quigley, and R. H. Brook. 2013. Factors affecting physician professional satisfaction and their implications for patient care, health systems, and health policy : Santa Monica, CA: RAND Corporation. Gandhi, T. K., A. Kachalia, E. J. Thomas, A. L. Puopolo, C. Yoon, T. A. Brennan, and D. M. Studdert. 2006. Missed and delayed diagnoses in the ambulatory setting: A study of closed malpractice claims. Annals of Internal Medicine 145(7):488-496. Gaudi, S., J. M. Zarandona, S. S. Raab, J. C. English, and D. M. Jukic. 2013. Discrepancies in dermatopathology diagnoses: The role of second review policies and dermatopathology fellowship training. Journal of the American Academy of Dermatology 68(1):119-128. Gawande, A. 2007. The way we age now: Medicine has incr eased the ranks of the elderly. Can it make old age any easier? The New Yorker , April 30. www.newyorker.com/magazine/2007/04/30/the-way-we-age-now (accessed May 18, 2015). Gawande, A. 2014. Being mortal: Illness, medicine, and what matters in the end . London, UK: Wellcome Collection. Gawande, A. 2015. Overkill. The New Yorker, May 11. www.newyorker.com/magazine/2015/05/11/overkill-atul- gawande (accessed July 13, 2015). Giardina, T. D., B. J. King, A. P. Ign aczak, D. E. Paull, L. Hoeksema, P. D. Mills, J. Neily, R. R. Hemphill, and H. Singh. 2013. Root cause analysis reports help identify common factors in delayed diagnosis and treatment of outpatients. Health Affairs (Millwood) 32(8):1368-1375. Gigerenzer, G. 2014. Breast cancer screening pamphlets mislead women. BMJ 348:g2636. Goldschmidt, H. M. J., and R. W. Lent. 1995. From data to information: How to define the context? Chemometrics and Intelligent Laboratory Systems 28(1):181-192. Golodner, L. 1997. How the public perceives patient safety. Newsletter of the National Patient Safety Foundation 1(1):1-4. 3-46 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Gosbee, J., and L. L. Gosbee. 2012. Usability evaluation in health care. In P. Carayon (ed.), Handbook of human factors and ergonomics in health care and patient safety , 2nd ed. (pp. 543-555). Boca Raton, FL: Taylor & Francis Group. Graber, M. L. 2013. The incidence of diagnostic error in medicine. BMJ Quality and Safety 22(Suppl 2):ii21-ii27. Graber, M. L., N. Franklin, and R. Gordon. 20 05. Diagnostic error in internal medicine. Archives of Internal Medicine 165(13):1493-1499. Graber, M. L., S. Kissam, V. L. Payne, A. N. Meyer, A. Sorensen, N. Lenfestey, E. Tant, K. Henriksen, K. Labresh, and H. Singh. 2012. Cognitive interventions to reduce diagnostic error: A narrative review. BMJ Quality and Safety 21(7):535-557. Graber, M. L., R. Trowbridge, J. S. Myers, C. A. Um scheid, W. Strull, and M. H. Kanter. 2014. The next organizational challenge: Finding and addressing diagnostic error. Joint Commission Journal on Quality and Patient Safety 40(3):102-110. Grimes, D. A., and K. F. Schulz. 2002. Uses and abuses of screening tests. Lancet 359(9309):881-884. Hallworth, M. J. 2011. The \"70% cl aim\": What is the evidence base? Annals of Clinical Biochemistry 48(6):487- 488. Hickner, J., D. G. Graham, N. C. El der, E. Brandt, C. B. Emsermann, S. Dovey, and R. Phillips. 2008. Testing process errors and their harms and consequences reported from family medicine practices: A study of the American Academy of Family Physicians National Research Network. Quality and Safety in Health Care 17(3):194-200. Hickner, J., P. J. Thompson, T. Wilkinson, P. Epner, M. Sh eehan, A. M. Pollock, J. Lee, C. C. Duke, B. R. Jackson, and J. R. Taylor. 2014. Primary care physicians' challenges in orderi ng clinical laboratory tests and interpreting results. Journal of the American Board of Family Medicine 27(2):268-274. Hofer, T., S. Asch, R. Hayward, L. Rubenstein, M. Hogan, J. Adams, and E. Kerr. 2004. Profiling quality of care: Is there a role for peer review? BMC Health Services Research 4(1):9. Hoffmann, T. C., and C. Del Mar. 2015. Patients' expectations of the benefits and harms of treatments, screening, and tests: A systematic review. JAMA Internal Medicine 175(2):274-286. Hoyert, D. L. 2011. The changing profile of autopsied deaths in the United States, 1972-2007. NCHS Data Brief 67(August). Hricak, H., D. J. Brenner, S. J. Adelstein, D. P. Frush, E. J. Hall, R. W. Howell, C. H. McCollough, F. A. Mettler, M. S. Pearce, O. H. Suleiman, J. H. Thrall, and L. K. Wagner. 2011. Managing radiation use in medical imaging: A multifaceted challenge. Radiology 258(3):889-905. Iglehart, J. K. 2009. Health insurers and medical-imaging policy\u2014A work in progress. New England Journal of Medicine 360(10):1030-1037. IOM (Institute of Medicine). 1990. Medicare: A strategy for quality assurance (2 vols.). Washington, DC: National Academy Press. IOM. 2000. To err is human: Building a safer health system . Washington, DC: National Academy Press. IOM. 2001. Crossing the quality chasm: A new health system for the 21st century . Washington, DC: National Academy Press. IOM. 2004. Patient safety: Achieving a new standard for care . Washington, DC: The National Academies Press. Jun, G. T., J. Ward, Z. Morris, and J. Clarkson. 2009. Health care process modelling: Which method when? International Journal for Quality in Health Care 21(3):214-224 . Kachalia, A., T.K. Brennan, and D.M. Studdert. 2006. Missed and delayed diagnoses in the emergency department: A study of closed malpractice claims from 4 liability insurers. Annals of Emergency Medicine 49(2): 196-205. Kanter, M. H. 2014. Diagnostic errors\u2014Patient safety. Pr esentation to the Committee on Di agnostic Error in Health Care, August 7, 2014, Washington, DC. Kassirer, J.P. 1989. Our stubborn quest for diagnostic certainty. A cause of excessive testing. The New England Journal of Medicine 320(22)1489-1491. Kassirer, J. P., and R. I. Kopelman. 1989. Cognitive er rors in diagnosis: Instantiation, classification, and consequences. American Journal of Medicine 86(4):433-441. Kerr, E. A., T. P. Hofer, R. A. Haywar d, J. L. Adams, M. M. Hogan, E. A. McGlynn, and S. M. Asch. 2007. Quality by any other name? A comparison of three profiling systems for assessing health care quality. Health Services Research 42(5):2070-2087. Kim, J., D. Neilipovitz, P. Cardinal, M. Chiu, and J. Clinch. 2006. A pilot study using high-fidelity simulation to formally evaluate performance in th e resuscitation of critically ill pa tients: The University of Ottawa OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-47 PREPUBLICATION COPY: UNCORRECTED PROOFS Critical Care Medicine, High-Fidelity Simulation, and Crisis Resource Management I Study. Critical Care Medicine 34(8):2167-2174. Kirwan, B. E., and L. K. Ainsworth (eds.). 1992. A guide to task analysis: Th e Task Analysis Working Group . Boca Raton, FL: Taylor & Francis Group. Klein, G. 2011. What physicians can learn from firefighters. Paper presented at the 4th International Diagnostic Error Conference, October 23-26, 2011, Chicago, IL. Klein, G. 2014. Submitted input. Inpu t submitted to the Committee on Diagno stic Error. Decem ber, 20, 2014, Washington, DC. Koopman, R. J., L. M. Steege, J. L. Moore, M. A. Clar ke, S. M. Canfield, M. S. Kim, and J. L. Belden. 2015. Physician Information needs and elect ronic health records (EHRs): Time to reengineer the clinic note. Journal of the American Board of Family Medicine 28(3):316-323. Kostopoulou, O., C. Mousoulis, and B. C. Delaney. 2009. Information search and information distortion in the diagnosis of an ambiguous presentation. Judgment and Decision Making 4(5):408-418. Kostopoulou, O., J. E. Russo, G. Keenan, B. C. Delaney, and A. Douiri. 2012. Information distortion in physicians' diagnostic judgments. Medical Decision Making 32(6):831-839. Kronz, J. D., and W. H. Westra. 2005. The role of second opinion pathology in the management of lesions of the head and neck. Current Opinion in Otolaryngology and Head and Neck Surgery 13(2):81-84. Landis, J. R., and G. G. Koch. 1977. The measurem ent of observer agreement for categorical data. Biometrics 33(1):159-174. Leape, L. L., T. A. Brennan, N. Laird, A. G. Lawthers, A. R. Localio, B. A. Barnes, L. Hebert, J. P. Newhouse, P. C. Weiler, and H. Hiatt. 1991. The nature of adverse ev ents in hospitalized patients: Results of the Harvard Medical Practice Study II. New England Journal of Medicine 324(6):377-384. Levtzion-Korach, O., A. Frankel, H. Al calai, C. Keohane, J. Orav, E. Graydon- Baker, J. Barnes, K. Gordon, A. L. Puopulo, E. I. Tomov, L. Sato, and D. W. Bates. 2010. Integrating incident data from five reporting systems to assess patient safety: Making sense of the elephant. Joint Commission Journal on Quality and Patient Safety 36(9):402-410. Liss, M. A., J. Billimek, K. Osann, J. Cho, R. Moskowitz, A. Kaplan, R. J. Szabo, S. H. Kaplan, S. Greenfield, and A. Dash. 2013. Consideration of comorbidity in risk stratification prior to prostate biopsy. Cancer 119(13):2413-2418. Localio, A. R., A. G. Lawthers, T. A. Brennan, N. M. Lair d, L. E. Hebert, L. M. Peterson, J. P. Newhouse, P. C. Weiler, and H. H. Hiatt. 1991. Relation between malpr actice claims and adverse events due to negligence. Results of the Harvard Me dical Practice Study III. New England Journal of Medicine 325(4):245-251. Lundberg, G. D. 1981. Acting on significant laboratory results. JAMA 245(17):1762-1763. Lundberg, G. D. 1998. Low-tech autopsies in the era of high-tech medicine: Continued value for quality assurance and patient safety. JAMA 280(14):1273-1274. Lyratzopoulos, G., P. Vedsted, and H. Singh. 2015. Understanding missed opportunities for more timely diagnosis of cancer in symptomatic patients after presentation. British Journal of Cancer 112:S84-S91. Mahmood, A., H. Chaudhury, and M. Valente. 2011. Nurses' perceptions of how physical environment affects medication errors in acute care settings. Applied Nursing Research 24(4):229-237. McDonald, K. M. 2013. Considering context in quality improvement interventions and implementation: Concepts, frameworks, and application. Academic Pediatrics 13(6):S45-S53. McDonald, K. M., B. Matesic, D. G. Contopoulos-Ioannidis, J. Lonhart, E. Schmidt, N. Pineda, and J. P. Ioannidis. 2013. Patient safety strategies targeted at diagnostic errors: A systematic review. Annals of Internal Medicine 158(5 Pt 2):381-389. McGlynn, E. A., S. M. Asch, J. Adams, J. Keesey, J. Hicks, A. DeCristofaro , and E. A. Kerr. 2003. The quality of health care delivered to adults in the United States. New England Journal of Medicine 348(26):2635-2645. Middleton, B., M. Bloomrosen, M. A. Dente, B. Hashmat, R. Koppel, J. M. Overhage, T. H. Payne, S. T. Rosenbloom, C. Weaver, and J. Zhang. 2013. Enhancing patient safety and quality of care by improving th e usability of electronic health record systems: Recommendations from AMIA. Journal of the American Medical Informatics Association 20(e1):e2-e8 . Milch, C. E., D. N. Salem, S. G. Pauker, T. G. Lund quist, S. Kumar, and J. Chen. 2006. Voluntary electronic reporting of medical errors and adverse events. Journal of General Internal Medicine 21(2):165-170. Moynihan, R., J. Doust, and D. Henry. 2012. Preventing overdiagnosis: How to stop harming the healthy. BMJ 344:e3502. 3-48 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Mulley, A. G., C. Trimble, and G. Elwyn. 2012. Stop the silent misdiagnosis: Patients' preferences matter. BMJ 345(1):e6572. Murphy, D. R., A. Laxmisan, B. A. Reis, E. J. Thomas, A. Esquivel, S. N. Forjuoh, R. Parikh, M. M. Khan, and H. Singh. 2014. Electronic health reco rd-based triggers to detect potential delays in cancer diagnosis. BMJ Quality and Safety 23(1):8-16. Nakhleh, R. E., V. Nos\u00e9, C. Colasacco, L. A. Fatheree, T. J. Lillemoe, D. C. McCr ory, F. A. Meier, C. N. Otis, S. R. Owens, S. S. Raab, R. R. Turner, C. B. Ventura, and A. A. Renshaw. 2015. Interpretive diagnostic error reduction in surgical pathology and cytology: Guideline from the College of American Pathologists Pathology and Laboratory Quality Center and the Association of Directors of Anatomic and Surgical Pathology. Archives of Pathology & Laboratory Medicine . Epub ahead of print. http://dx.doi.org/10.5858/arpa.2014-0511-SA. Newman-Toker, D. E. 2014a. Prioritization of diagnos tic error problems and solutions: Concepts, economic modeling, and action plan. Input submitted to the Committee on Diagnostic Error in Health Care, August 7, 2014, Washington, DC. Newman-Toker, D. E. 2014b. A unified conceptual model for diagnostic errors: Underdiagnosis, overdiagnosis, and misdiagnosis. Diagnosis 1(1):43-48. Newman-Toker, D. E., and P. J. Pronovost. 2009. Diagnostic errors: The next frontier for patient safety. JAMA 301(10):1060-1062. Newman-Toker, D. E., K. M. McDonald, and D. O. Meltzer. 2013. How much diagnostic safety can we afford, and how should we decide? A health economics perspective. BMJ Quality and Safety 22(Suppl 2):ii11-ii20. Newman-Toker, D. E., E. Moy, E. Valente, R. Coffey, an d A. L. Hines. 2014. Missed diagnosis of stroke in the emergency department: A cross-sectional analysis of a large population-based sample. Diagnosis 1(2):155- 166. Office of Inspector General. 2010. Adverse events in hospitals: Methods for identifying events. Washington, DC: Office of Inspector General. https ://oig.hhs.gov/oei/reports/oei-06-08-00221.pdf (accessed June 4, 2015). Pace, L. E., and N. L. Keating. 2014. A systematic assessment of benefits and risks to guide breast cancer screening decisions. JAMA 311(13):1327-1335. Parsons, K. C. 2000. Environmental ergonomics: A review of principles, methods and models. Applied Ergonomics 31:581-594. Patel, V. L., J. Zhang, N. A. Yoskowitz, R. Green, an d O. R. Sayan. 2008. Translational cognition for decision support in critical care environments: A review. Journal of Biomedical Informatics 41(3): 413-431. Peabody, J. W., J. Luck, S. Jain, D. Bertenthal, and P. Glassman. 2004. Assessing th e accuracy of administrative data in health information systems. Medical Care 42(11):1066-1072. Peterson, M. C., J. H. Holbrook, D. Von Hales, N. L. Sm ith, and L. V. Staker. 1992. Contributions of the history, physical examination, and laboratory investigation in making medical diagnoses. Western Journal of Medicine 156(2):163-165. Plant, J. L., S. M. van Schaik, D. C. Sliwka, C. K. Bo scardin, and P. S. O'Sullivan. 2011. Validation of a self- efficacy instrument and its relationship to perf ormance of crisis resource management skills. Advances in Health Sciences Education 16(5):579-590. Plebani, M. 2010. The detec tion and prevention of errors in laboratory medicine. Annals of Clinical Biochemistry 47(2):101-110. Plebani, M. 2014. Defensive medicine and diagnostic testing. Diagnosis 1(2):151-154. Plebani, M., M. Laposata, and G. D. Lu ndberg. 2011. The brain-to-brain loop concept for laboratory testing 40 years after its introduction. American Journal of Clinical Pathology 136(6):829-833. Potter, P., S. Boxerman, L. Wolf, J. Marshall, D. Grayso n, J. Sledge, and B. Evanoff. 2004. Mapping the nursing process: A new approach for understanding the work of nursing. Journal of Nursing Administration. 34(2):101-109. Rao , V. M., and D. C. Levin. 2012. The overuse of diagnostic imaging and the Choosing Wisely initiative. Annals of Internal Medicine 157(8):574-576. Reason, J. 1990. Human error . New York: Cambridge University Press. Renshaw, A. A., and E. W. Gould. 2005. Comparison of disagreement and error rates for three types of interdepartmental consultations. American Journal of Clinical Pathology 124(6): 878-882. Rogers, M. L., E. S. Patterson, and R. M. L. 2012. Cogn itive work analysis in health care. In P. Carayon (ed.), Handbook of human factors and ergonomics in health care and patient safety , 2nd ed.(pp. 465-474). Boca Raton, FL: Taylor & Francis Group. Roth, E. M. 2008. Uncovering the requirements of cognitive work. Human Factors 50(3):475-480. OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-49 PREPUBLICATION COPY: UNCORRECTED PROOFS Salas, E., C. Prince, D. P. Baker, and L. Shrestha. 1995. Situation awareness in team pe rformance: Implications for measurement and training. Human Factors 37(1):123-136. Schiff, G. D., and L. L. Leape. 2012. Commentary: How can we make diagnosis safer? Academic Medicine 87(2):135-138. Schiff, G. D., S. Kim, R. Abrams, K. Cosby, A. S. Elstei n, S. Hasler, N. Krosnjar, R. Odwanzy, M. F. Wisniewsky, and R. A. McNutt. 2005. Diagnosing diagnosis errors: Lessons from a multi-institutional collaborative project for the diagnostic error evaluation and research project investigators . Rockville, MD: Agency for Healthcare Research and Quality. Schiff, G. D., O. Hasan, S. Kim, R. Abrams, K. Cosby, B. L. Lambert, A. S. Elstein, S. Hasler, M. L. Kabongo, N. Krosnjar, R. Odwazny, M. F. Wisniewski, and R. A. McNutt. 2009. Diagnostic error in medicine: Analysis of 583 physician-reported errors. Archives of Internal Medicine 169(20):1881-1887. Schiff, G. D., A. L. Puopolo, A. Huben-Kearney, W. Yu, C. Keohane, P. McDonough, B. R. Ellis, D. W. Bates, and M. Biondolillo. 2013. Primary care closed claims e xperience of Massachusetts malpractice insurers. JAMA Internal Medicine 173(22):2063-2068. Schraagen, J. M., S. F. Chipman, and V. L. Shalin. 2000. Cognitive task analysis . New York: Psychology Press. Shekelle, P. G., R. M. Wachter, P. J. Pronovost, K. Schoelles, K. M. McDonald, S. M. Dy, K. Shojania, J. Reston, Z. Berger, B. Johnsen, J. W. Larkin, S. Lucas, K. Martinez, A. Motala, S. J. Newberry, M. Noble, E. Pfoh, S. R. Ranji, S. Rennke, E. Schmidt, R. Shanman, N. Sulliv an, F. Sun, K. Tipton, J. R. Treadwell, A. Tsou, M. E. Vaiana, S. J. Weaver, R. Wilson, and B. D. Winters. 2013. Making health care safer II: An updated critical analysis of the evidence for patient safety practices. Evidence Reports/Technology Assessments No. 211. Rockville, MD: Agency for Healthcare Research and Quality. Shojania, K. G. 2010. The elephant of patient safety: What you see depends on how you look. Joint Commission Journal on Quality and Patient Safety 36(9):399-401. Shojania, K. G., E. C. Burton, K. M. McDonald, and L. Goldman. 2002. The autopsy as an outcome and performance measure. AHRQ Publication No. 03-E002. Rockville, MD: Agency for Healthcare Research and Quality. Shojania, K. G., E. C. Burton, K. M. McDonald, and L. Goldman. 2003. Changes in rates of autopsy-detected diagnostic errors over time: A systematic review. JAMA 289(21):2849-2856. Siegal, D. 2014. Analysis of diagno sis-related medical malpractice claims : Input submitted to the IOM Committee on Diagnostic Error in Health Care. Singh, H. 2014. Helping health care organizations to defi ne diagnostic errors as missed opportunities in diagnosis. Joint Commission Journal on Quality and Patient Safety 40(3):99-101. Singh, H., and D. F. Sittig. 2015. Advancing the science of measurement of diagnostic errors in healthcare: The Safer Dx Framework. BMJ Quality and Safety 24(2):103-110. Singh, H., A. D. Naik, R. Rao, and L. A. Petersen. 2008. Reducing diagnostic errors through effective communication: Harnessing the power of information technology. Journal of General Internal Medicine 23(4):489-494. Singh, H., K. Daci, L. A. Petersen, C. Collins, N. J. Petersen, A. Shethi a, and H. B. El-Serag. 2009. Missed opportunities to initiate endoscopic evaluation for colorectal cancer diagnosis. American Journal of Gastroenterology 104(10):2543-2554. Singh, H., K. Hirani, H. Kadiyala, O. Rudomiotov, T. Davi s, M. M. Khan, and T. L. Wahls. 2010a. Characteristics and predictors of missed opportunities in lung cancer diagnosis: An electronic health record-based study. Journal of Clinical Oncology 28(20):3307-3315. Singh, H., E. J. Thomas, L. Wilson, P. A. Kelly, K. Pietz, D. Elkeeb, and G. Singhal. 2010b. Errors of diagnosis in pediatric practice: A multisite survey. Pediatrics 126(1):70-79. Singh, H., T. D. Giardina, S. N. Forjuoh, M. D. Reis, S. Kosmach, M. M. Khan, and E. J. Thomas. 2012a. Electronic health record-based surveillance of diagnostic errors in primary care. BMJ Quality and Safety 21:93-100. Singh, H., M. L. Graber, S. M. Kissam, A. V. Sorensen, N. F. Lenfestey, E. M. K. Henriksen, and K. A. LaBresh. 2012b. System-related interventions to reduce diagnostic errors: A narrative review. BMJ Quality and Safety 21(2):160-170. Singh, H., C. Spitzmueller, N. J. Petersen, M. K. Saw hney, and D. F. Sittig. 2013. Information overload and missed test results in electronic h ealth record-based settings. JAMA Internal Medicine 173(8): IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Singh, H., A. N. Meyer, and E. J. Thomas. 2014. The frequency of diagnostic errors in outpatient care: Estimations from three large observational studies involving U.S. adult populations. BMJ Quality and Safety 23(9):727- 731. Smith, M., D. Murphy, A. Laxmisan, D. Sittig, B. Reis, A. Esquivel, and H. Singh. 2013. Developing software to \"track and catch\" missed follow-up of abnormal test results in a co mplex sociotechnical environment. Applied Clinical Informatics 4(3):359-375. Studdert, D. M., E. J. Thomas, H. R. Burstin, B. I. Zbar, E. J. Orav, and T. A. Brennan. 2000. Negligent care and malpractice claiming behavior in Utah and Colorado. Medical Care 38(3): 250-260. Studdert, D. M., M. M. Mello, W. M. Sage, C. M. DesR oches, J. Peugh, K. Zapert, and T. A. Brennan. 2005. Defensive medicine among high-risk specialist phys icians in a volatile Mello, A.A. Kachalia, C. Yoon, AL. Puopolo, and T. A. Brennan. 2006. Claims, errors, and compensation payments in medical malpractic litigation. New England Journal of Medicine 354(19):2024-2033. Tehrani, A., H. Lee, S. Mathews, A. Shore, M. Ma kary, P. Pronovost, and D. Newman-Toker. 2013. 25-year summary of U.S. malpractice clai ms for diagnostic errors 1986-2010: An analysis from the National Practitioner Data Bank. BMJ Quality and Safety 22:672-680. Thomas, E. J., D. M. Studdert, H. R. Bu rstin, E. J. Orav, T. Zeen a, E. J. Williams, K. M. Howard, P. C. Weiler, and T. A. Brennan. 2000. Incidence and types of advers e events and negligent care in Utah and Colorado. Medical Care 38(3):261-271. Thomas, E. J., S. R. Lipsitz, D. M. Studdert, and T. A. Brennan. 2002. The reliability of medical record review for estimating adverse event rates. Annals of Internal Medicine 136(11):812-816. Trowbridge, R. 2014. Diagnostic performance: Measur ement and feedback. Presenta tion to the Committee on Diagnostic Error in Health Care. August 7, 2014, Washington, D.C. Unertl, K. M., M. B. Weinger, K. B. Johnson, and N. M. Lorenzi. 2009. Describing and modeling workflow and information flow in chronic disease care. Journal of the American Medical Informatics Association 16(6):826-836. Velmahos, G. C., C. Fili, P. Vassiliu, N. Nicolaou, R. Radin, and A. Wilcox. 2001. Around-the-clock attending radiology coverage is essential to avoid mistakes in the care of trauma patients. American Surgeon 67(12):1175-1177. Wachter, R. M. 2010. Why diagnostic errors don't get any respect\u2014and what can be done about them. Health Affairs (Millwood) 29(9):1605-1610. Wachter, R. M. 2014. Diagnostic errors: Central to patient safety, yet still in the peripher y of safety's radar screen. Diagnosis 1(1):19-21. Weiner, S. J., A. Schwartz, F. Weaver, J. Goldberg, R. Yu dkowsky, G. Sharma, A. Binn s-Calvey, B. Preyss, M. M. Schapira, S. D. Persell, E. Jacobs, and R. I. Abrams. 2010. Contextual errors and failures in individualizing patient care: A multicenter study. Annals of Internal Medicine 153(2):69-75. Weissman, J. S., E. C. Schneider, S. N. Weingart, A. M. Epstein, J. David-Kasdan, S. Feibelmann, C. L. Annas, N. Ridley, L. Kirle, C. Gatsonis. 2008. Comparing patient -reported hospital advere events with medical record review: Do patients know something that hospitals do not? Annals of Internal Medicine 149(2): 100-108. Welch, H. G. 2015. Less medicine more health: 7 assumptions that drive too much medical care . Boston, MA: Beacon Press. Welch, H. G., and W. C. Black . 2010. Overdiagnosis in cancer. Journal of the National Cancer Institute 102(9):605-613. Winters, B., J. Custer, S. M. Galvagno, E. Colantuoni, S. G. Kapoor, H. Lee, V. Goode, K. Robinson, A. Nakhasi, and P. Pronovost. 2012. Diagnostic errors in the in tensive care unit: A systematic review of autopsy studies. BMJ Quality and Safety 21(11):894-902. Wolf, L., P. Potter, J. A. Sledge, S. B. Boxerman, D. Grayson, and B. Evanoff. 2006. Describing nurses' work: Combining quantitative and qualitative analysis. Human Factors 48(1):5-14. Zwaan, L., and H. Singh. 2015. The challenges in defining and measuring diagnostic error. Diagnosis 2(2):97-103. Zwaan, L., M. de Bruijne, C. Wagner, A. Thijs, M. Sm its, G. van der Wal, and D. R. Timmermans. 2010. Patient record review of the incidence, consequences, and causes of diagnostic adverse events. A rchives of Internal Medicine 170(12):1015-1021. Zwaan, L., A. Thijs, C. Wagner, G. van der Wal, and D. R. Timmermans. 2012. Relating faults in diagnostic reasoning with diagnostic errors and patient harm. Academic Medicine 87(2):149-156. OVERVIEW OF DIAGNOSTIC ERROR IN HEALTH CARE 3-51 PREPUBLICATION COPY: UNCORRECTED PROOFS Zwaan, L., G. D. Schiff, and H. Singh. 2013. Advancing the research agenda for diagnostic error reduction. BMJ Quality and Safety 22:Suppl 2 (2013):ii52-ii57. Zhi, M., E. L. Ding, J. Theisen-Toupal, J. Whelan, and R. Arnaout. 2013. The landscape of inappropriate laboratory testing: A 15-year meta-analysis. PLoS One 8(11):e78962. D En T clinician s that heal t accurate their fa m the focu s (health c a diagnost i improvi n professi o FIGUR E process oDiagnost i ngagem e This chapter d s partnering th care prof e and timely d mily member s s of this cha p are professi o ic process ( s ng teamwor k onals effe h occurs: diag n PREPUBL Iic Tea m ent and H T describes th e with patien t essionals ne e diagnoses re s. In terms o pter is on tw o onals, patie n ee Figure 4 - k and patien t ctively parti c hapter addr e nostic ICATION Memb e Health C Trainin g e team-based ts and their f ed to partici p quires team w of the comm i o of the ele m nts, and thei r -1). The co m t engageme n cipate in the esses two el e members an d 4-1 OPY: UNCO R4 ers & T a Care Pro f g in Dia g d nature of t h families thr o pate effectiv e work amon g ittee's conc e ments of the r families) a n mmittee mak e nt in the dia g diagnostic p ements of th e d the tasks t h RRECTED P Rasks: Im p fessiona l gnosis he diagnost i oughout the p ely in the di g health care eptual mode l work syste m nd the tasks t es two reco m gnostic proc e process. e work syst e hey perfor m ROOFS proving P l Educa t ic process, t h process, an d agnostic pr o profession a l of the diag n m: diagnosti c that they pe r mmendation ess and prep a em in which m. Patient tion and he importan c d the prepar a ocess. Maki n als, patients, nostic proc e c team mem b rform in the s targeted a t aring health the diagnos t ce of ation ng and ess, bers t care tic 4-2 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS THE DIAGNOSTIC PROCESS AS A TEAM ENDEAVOR This study was originally titled \"Diagnostic Error in Medicine,\" but based on discussions at its first meeting, the committee concluded that \"Diagnostic Error in Health Care\" was a more accurate description because it better reflected the patient-centered and teamwork-oriented aspects of the diagnostic process. This conceptualization of dia gnosis grew out of the recognition that too often the diagnostic process is characterized as a solitary activity, taking place exclusively within an individua l physician's mind. While the task of integrating relevant information and communicating a diagnosis to a patient is often the responsibility of an individual clinician, the diagnostic process id eally involves collaboration among multiple health care professionals, the patient, and the patient's family. Patients and their families play a pivotal role in the diagnostic process. Thus, arriving at timely and accurate diagnoses, even those made by an individual clinician working with a singl e patient involves teamwork. The number of health care professionals involve d in the diagnostic process can vary substantially, depending on the nature of the patient's health problem: for example, McDonald (2014) noted that a diagnostic process could involve a single c linician if the suspected diagnosis is considered something straightforward, such as a common cold. Howeve r, at the other end of the spectrum, the diagnostic process could be quite complex and involve a broad array of health care professionals, such as primary care clinicians, diagnostic tes ting health care professionals, multiple specialists if different organ systems are suspected to be involved, nurses, pharmacists, and others. Even though some diagnoses continue to be made by individual clinicians working independently, this solita ry approach to the diagnostic process is likely to be insufficient given the changing nature of health care (see Chapte r 2). The mounting complexity of health care, including ever-increasing options for diagnostic testing and treatment and the movement toward precision medicine, the rapidly risi ng levels of biomedical and clinical evidence to inform clinical practice, and the fr equent comorbidities among patie nts due to the aging of the population will require greater reliance on team-based diagnosis (IOM, 2008, 2013b). To manage the increasing complexity in health care a nd medicine, clinicians will need to collaborate effectively and draw upon the knowledge and expertise of other health care professionals, as well as patients and families, throughout the diagnos tic process. The committee recognizes that reframing the diagnostic process as a team-based activity may require changing norms of health care professional roles and respons ibilities and that th ese changes may take some time and may meet some resistance. Nevertheless, the comm ittee concluded that improving diagnosis will require a team-based approach to the diagnostic process, in which all individuals collaborate toward the goal of timely and accurate diagnos es. Consistent with the committee's conclusion, recent reports in the literature make the case that the diagnostic process is a team-based endeavor (Graedon McDonald, 2014). For example, Schiff noted that the new paradigm fo r diagnosis is that it is carried out by a well- coordinated team of people work ing together through reliable pro cesses; in this view, diagnosis is the collective work of the te am of health care professionals and the patient and his or her family (Schiff, 2014b). In health care, teamwork has been descri bed as a \"dynamic pro cess involving two or more health [care] professionals with comple mentary backgrounds and skills, sharing common health goals and exercising con certed physical and mental effort in assessing, planning, or evaluating patient care. This is accomplished through interdependent collaboration, open communication and shared decision-making\" (Xyrichis and Ream, 2008, p. 238). Five principles DIAGNOSTIC TEAM MEMBERS & TASKS 4-3 PREPUBLICATION COPY: UNCORRECTED PROOFS of team-based care have been identified by the In stitute of Medicine (IOM): shared goals, clear roles, mutual trust, effective communication, and measureable processe s and outcomes (see Box 4-1). Research by a number of organizations, in cluding the IOM, has highlighted the important role that teamwork plays in health care (Borrill et al., 2000; Boult et al., 2009; IOM, 2001, 2013a, 2013b; Naylor, 2010; Josiah Macy Jr. Foundation and Carnegie Foundation for the Advancement of Teaching, 2010; WHO, 2010). A report commissioned by the Robert Wood Johnson Foundation identified severa l factors that are important to fostering and sustaining interprofessional collaboration: patient-cente redness, leadership commitment, effective communication, awareness of role s and responsibilities, and an organizational structure that integrates interprofessional practice (CFAR et al., 2015). A re view by the United Kingdom's National Health Service found that teamwork has \"been reported to reduce hosp italization time and costs, improve service prov ision, [and] enhance patient sa tisfaction, staff motivation and team innovation\" (Borrill et al ., 2000, p. 14). One study found that a \"culture of collaboration\" is a key feature shared by academic medical centers c onsidered to be top-performers in quality and safety (Keroack et al., 2007), and a literature review found moderate evidence for an association between teamwork and positive patient outcomes, with the most consistent evidence from the intensive care unit setting (Sorbe ro et al., 2008). Another study f ound that surgical teams that did not engage in teamwork had worse patient out comes, including a higher likelihood of death or serious complications (Mazzocco et al., 2009). Thes e findings are consistent with those from other sectors. For example, in aviation and in the nuclear power industr y teamwork and training in team-based skills have been found to impr ove performance and reduce errors related to communication and coordination problems (Leonard et al., 2004; Salas et al., 2008; Weaver et al., 2014). BOX 4-1 Principles of Team-Based Health Care Shared goals: The team\u2014including the patient and, where appropriate, family members or other support persons\u2014works to establish shared goals that reflect patient and family priorities and that can be clearly articulated, understood, and supported by all team members. Clear roles: There are clear expectations for each team member's functions, responsibilities, and accountabilities, which optimizes the team's efficiency and often makes it possible for the team to take advantage of a division of labor, thereby accomplishing more than the sum of its parts. Mutual trust: Team members earn each others' trust, creating strong norms of reciprocity and greater opportunities for shared achievement. Effective communication: The team prioritizes and continuously refines its communication skills. It has consistent channels for candid and complete communication, which are accessed and used by all team members across all settings. Measurable processes and outcomes: The team agrees on and implements reliable and timely feedback on successes and failures in both the functioning of the team and achievement of the team's goals. These are used to track and improve performance immediately and over time. SOURCE: Adapted from IOM, 2012c. 4-4 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Compared to teamwork in other areas of hea lth care, teamwork in the diagnostic process has not received nearly as much attention. Team work in diagnosis is likely to be somewhat distinct from the teamwork that occurs after a diagnosis is made , in part due to the fluid, or unstable, collection of health care professionals involved in the diagnostic process. Fluid team membership has been recognized as a strategy to deal with fast-paced, complex tasks such as diagnosis where pre-planned coordination may not be possible and where communication and coordination are a necessity (Bushe and Chu, 2011; Edmonds on, 2012; Vashdi et al., 2013). Fluid team membership can introduce new challenge s, such as a reduced sense of belonging to the team and a decrease in team efficacy (Bus he and Chu, 2011; Dineen and Noe, 2003; Shumate et al., 2010). A number of strategies have been identified as ways to le ssen the negative impacts of fluid teams, including standardizing roles and skills, reducing task interdependence, and increasing health care professi onals' understanding of others ' roles (Bushe and Chu, 2011). Although teams focused on patient treatment may also exhibit fluidity, the uncertainty and complexity of the diagnostic process make unstable team membership more likely in the diagnostic process. The committee concluded that literature on the role of teams in diagnosis is limited and that lessons from teamwork in other settings, including the treatment setting, are applicable to the diagnostic process. In testimony to the committee, Eduardo Salas of the University of Central Florida said that teamwork was likely to improve diagnosis and reduce diagnostic errors because teamwork has been found to mitigate communication and coordination challenges in other areas of health care. These same challenges have been found to have an impact on diagnostic performance (Gandhi, 2014; IOM, 2013b; Schiff, 2014a; Singh, 2014; Sutcliffe et al., 2004; The Joint Commission, 2014). Emerging research also suggests that teamwork will improve the diagnostic process; one study found that medi cal students working in teams made fewer diagnostic errors than those working individually , and other research has found that collaboration among treating clinicians and clinic al pathology teams resulted in be tter diagnostic test selection (Hautz et al., 2015; Seegmiller et al., 2013). Diagnosis depends on health care professionals with differing edu cational and training backgrounds working together and practicing to the full extent of their education and training (IOM, 2001, 2012c). Having clear roles and responsibil ities leaves \"those with greater training or responsibility free to perform tasks or to solve problems for which they are uniquely equipped\" (Baldwin and Tsukuda, 1984, p. 427), while other tasks in the diagnostic process can be distributed to health care professionals within their own scope of practice (Baldwin and Tsukuda, 1984; IOM, 2011a). Improving diagnostic performa nce requires participating individuals to recognize the importance of teamwork as well as the contributions of other health care professionals to the diagnostic process. In recognition that the diagnostic process is a dynamic team-based activity, health care organizations should ensure that health care professionals have the appropriate knowledge, skills, resources, and support to en gage in teamwork in the diagnostic process. Ensuring that individuals particip ating in the diagnostic process have the appropriate resources and support extends beyond the purview of this chapter and requires a systems approach to diagnosis, including consideration of health information technol ogy (health IT) resources (see Chapter 5), an organizational cultu re and work system that supports teamwork (see Chapter 6), and payment and care delivery models that pr omote teamwork (see Chapter 7). This chapter focuses on describing the individuals involved in the diagnostic process, identifying opportunities to facilitate patient engagement and intra- and interprofessional collaboration in the DIAGNOSTIC TEAM MEMBERS & TASKS 4-5 PREPUBLICATION COPY: UNCORRECTED PROOFS diagnostic process, and ensuring th at team members have and main tain appropriate competencies in the diagnostic process. Participants in the Diagnostic Process The committee described diagnostic teamwork as the collaboration of interrelated individuals working toward the goal of esta blishing and communicating an accurate and timely explanation of a patient's heal th problem (Salas et al., 2008). Teamwork in the diagnostic process involves the collaboration of patients and their families; diagnosticians, such as physicians, physician assistants (PAs), and adva nced practice nurses (APN s); and health care professionals who support the diagnostic proce ss, such as nurses, pharmacists, laboratory scientists, radiology technologists, medical assistan ts, and patient navigators. the rela tionship among individuals part icipating in the diagnostic process. Patients and their family members are located at the center because the ultimate goal of the diagnostic process is to explain a patient's health problem and to inform subsequent decision making about a patient's care. Surrounding patients and their families are diagnosticians, health care professionals whose tasks include making diagnoses. Encircling the diagnosticians are health care professionals who s upport the diagnostic process. Although Figure 4-2 distinguishes between diagnosticians and health care professi onals who support the dia gnostic process, this distinction may be less clear in practice. For example, triage\u2014a complex cognitive nursing task designed to identify patients needing immediate medical care\u2014has not ty pically been included as a component in the diagnostic process, but it can often play a de facto role, since a nurse may identify a suspected diagnosis during this proces s (Soni and Dhaliwal, 2012). Similarly, incorrect triage decisions can also introduce cognitive biases (such as framing or anchoring effects) that can contribute to diagnos tic errors (see Chapter 2). The overla pping nature of the diagnostic team members in Figure 4-2 reflects the importance of effective communication and collaboration among all individuals in th e diagnostic process. 4-6 FIGUR E family m process. T instead, p areas of e engages t Figure 4 - or her pr i primary c radiolog i care. Fig u interact d process. coordina t patients' coordina t primary c Patients The goalpatients a E 4-2 Team w members, dia g Teamwork i n participatio n expertise ar e the diagnos t -3. If there i s imary care t e care team c a ists, and spe c ure 4-3's de p during the d i For exampl e tion becaus e electronic h tion (Boden h care, which and Their F of patient e n and their fa m PREPUBL Iwork in the d gnosticians, n the diagno s n in diagnosi e needed to d tic process. T s good care c eam. If a pa t an collabora t cialty care c l piction of t h iagnostic pr o e, patients a n e of the frag m health recor d heimer, 200 can hinder c Family Mem b ngagement i milies to co n ICATION C Odiagnostic p r and health c stic process r s is often d y diagnose a s p The teamwo r coordinatio n tient develo p te with othe r linicians) in he various w a ocess is like l nd their fam i mentation o f ds (EHRs), a n 8; Press, 20 1 care coordin a bers in diagnosis ntribute valu a IM d and f pecific patie rk involved n, a partners h ps symptom s r health care the diagnos ays that pati ly an idealiz a ilies will oft e f the health c nd payment 14). In addit i ation efforts is to impro v able input t h MPROVING D RRECTED P Rdes the coll a ionals who s ves static, fi x fluctuates o v ent and whe r in the diagn hip is forme d s that requir e profession a tic process a ents and he a ation of wh a en take on a care system, incentives t h ion, patient s (CDC, 201 4 ve patient c a hat will facil i DIAGNOSIS I ROOFS aboration of p support the d xed diagnos t ver time, de p re and how t h ostic proces d between a e further ev a als (such as p and coordin a alth care pro at happens i n a significant b a lack of in t hat do not p r s may lack a 4; HHS, 201 are and outc o itate an acc u IN HEALTH C patients an d diagnostic tic teams; pending on w he patient s is illustrat e patient and aluation, the pathologists , ate subsequ e fessionals n the diagno s burden of c a teroperabili t romote care usual sourc 3). omes by ena b urate and ti m CARE d their what ed in his , ent stic are ty of e of bling mely DIAGNOSTIC TEAM MEMBERS & TASKS 4-7 PREPUBLICATION COPY: UNCORRECTED PROOFS diagnosis and improve shared decision-making a bout the path of care. Because patients are a heterogeneous population with vary ing needs, values, and preferen ces, their roles in diagnosis need to be individually tailored. Patients hold critical knowledge that informs the diagnostic process, such as knowledge of th eir health history, their symptoms , their exposure to individuals or environmental factors, the course of their c ondition, the medications they are taking, as well as knowledge gained from information searches that they conducted in advance of their appointment. In addition, patients and their familie s may also maintain more complete version of their own medical records, and they can help ensu re that test results ar e received and facilitate communication among their clin icians (Gruman, 2013). Diagnosticians Diagnosticians are health care professionals (physicians, PAs, APNs, and others) who are educated and licensed to provide patients with diagnoses. Alth ough a diagnostician is defined as any health care professional with diagnosis in hi s or her scope of work, in general physicians are expected to deal with a greater complexity of diagnostic tasks than other diagnosticians. In addition to diagnosing patients' he alth problems, diagnosticians ofte n participate in a variety of other health care tasks, such as the provision of preventive care and the management of patients' chronic and acute health conditions . Diagnosticians work in all hea lth care settings and include both general and specialist practitioners. Their clin ical reasoning skills come into play as they collect and integrate information from a patient 's clinical history, interview, physical exam, diagnostic testing, and consultations with or referrals to other he alth care professionals (see Chapter 2). Pathologists and radiologis ts are diagnosticians who provide information and consultations that are critical to diagnosing patients' health problems, such as advising on the appropriate diagnostic testing for a particular patient and conveyi ng the implications of the test results to treating health care professionals. 1 Despite the important roles that laboratory medicine, anatomic pathology, and medical imag ing play in a diagnos is, pathologists and radiologists have sometimes been treated as ancillary or support services. Expert testimony to the committee found that many pathologists and radiologists have not been adequately engaged in the diagnostic process and th at better collaboration among all diagnostic team members is necessary (Allen and Thorwarth, 2014; Kroft, 2014) . The committee concluded that a culture that perpetuates the notion of anat omic pathology, laboratory medicine, and medical imaging as ancillary health care services will inhibit efforts to improve diagnosis. Thus, the committee recommends health care organizations should facilitate and support collaboration among pathologists, radiologists, other diagnosticians, and treating health care professionals to improve diagnostic testing processes. This includes collaborati on throughout the testing process, including the ordering of appropriate tests or images, analysis and interpretation, the reporting and communication of results, and subsequent decision making. Depending on a patient's health problem, treating clinicians may also need to work collaboratively with other diagnosticians, such as sleep specialists, card iologists, and others. E ducation and training of health care professionals also needs to ensure that they are prepared to work in this manner. 1 Treating health care professionals are clinic ians who directly interact with patients. 4 F i 4-8 FIGURE 4-3 A illustrate the im p An example of d i portance of co m PREPiagnostic team w mmunication be t IMPRO V PUBLICATION Cwork and the po t tween team me m VING DIAGNOS I COPY: UNCORR Etential C PROOF Snts in the diagn o CARE S ostic process. T The arrows in th ee figure DIAGNOSTIC TEAM MEMBERS & TASKS 4-9 PREPUBLICATION COPY: UNCORRECTED PROOFS Health Care Professionals Who Support the Diagnostic Process In addition to diagnosticians, the diagnostic pr ocess may involve an array of health care professionals, including nurses, medical assistants, radiology technologists, laboratory scientists, pharmacists, patient navigators, social workers, therapists, nutritionists, and many others. These health care professionals play a crucial role by facilitating th e diagnostic process through the performance of their tasks. Nurses in particular play a key role in the diagnostic process (see Box 4-2). Nurses may ensure communication and care coordination among diagnostic team members, monitor a patient over time to see if the patient's course is c onsistent with a working diagnosis, and identify potential diagnostic errors. Nurs es facilitate patient engageme nt in the diagnostic process by communicating with patients about their history, actively listening to patients' descriptions of their reasons for a visit, documenting patient s' symptoms, assessing vital signs, and conveying this information to other clinicians. Nurses need to be full and active members of the diagnostic team, with opportunities to presen t their observations and conclusi ons to other team members. The committee's understanding of nurses as crucia l contributors to the diagnostic process builds on the recommendations of the IOM report The Future of Nursing: Leading Change, Advancing Health (IOM, 2011a). This report provided a roadma p for transforming nur sing practice in the United States. To achieve the necessary changes, the report offered four key recommendations (IOM, 2011a): Nurses should practice to the full exte nt of their educa tion and training. Nurses should achieve higher levels of education and training through an improved education system that promotes seamless academic progression. Nurses should be full partners, with physicians and other health professionals, in redesigning health care in the United States. Effective workforce planning and policy ma king require better data collection and an improved information infrastructure. In the five years since the report's release, there has been increased awareness of and growing support for these recommendations in nursing schools, health care professional societies, and health care or ganizations. For example, AARP and the Robert Wood Johnson Foundation recently launched the \"Future of Nu rsing: Campaign for Action,\" an initiative designed to drive implementation of the report's recommendations. 2 Despite these efforts, progress in the implementation of these reco mmendations has been uneven. Re-envisioning the roles that nurses play in the diagnostic process is one componen t of these larger efforts to transform the practice of nursing in the United States. 2 www.campaignforaction.org 4-10 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS BOX 4-2 Suggested Actions for Nurses to Improve Diagnosis and Reduce Diagnostic Error 1. Know the major diagnoses of your patients. 2. Be the voice of your patients and their advocate in navigating their health care. 3. Be the eyes of the diagnostic team in detecting, reporting, and documenting changes in your patients' symptoms, signs, complaints, or conditions. 4. Be the monitor of the diagnostic team. Is your patient responding to treatment as expected? 5. Help optimize communication between your patient and the care team: a. Help patients tell their story and relate all of their symptoms. b. Check patients' understanding of their diagnoses and what they've been told. 6. Be the watchdog for appropriate care coordination. 7. Educate patients about the diagnostic process. 8. Learn about how diagnostic errors arise and how they can be avoided. 9. Educate patients about diagnostic tests and explain why they are needed, what the patient will experience, and what the results will reveal. 10. Help patients with the emotional and psychological difficulties that arise when a diagnosis is not yet known or is known to be bad. SOURCE: Adapted from SIDM and NPSF, 2014. Reprinted, with permission, from the Society to Improve Diagnosis in Medicine and National Patient Safety Foundation. Radiology technologists and labor atory scientists also play important roles in the diagnostic process. In some cases radiology technologists take images and make decisions, such as how many and what type of images to take. For example, ultrasound technologists will capture images of normal structures and take additional images of any abnormalities they find. If the radiology technologist does not notice an ab normality, important information may not be conveyed to the radiologist, which may negativel y impact the diagnostic process. Laboratory scientists are tasked with procuring samples, preparing samples for analysis, performing analyses, and ensuring that th e testing tools are functioning properly. In some cases these scientists may detect a specimen abnormality during the analysis process that suggests an unsuspected diagnosis or necessitates further investigation. Pharmacists can make important contributions to the diagnostic pro cess, especially in identifying and averting health problems that stem from drug side effects and interactions (Hines and Murphy, 2011; Malone et al., 2005). Pharmacist s and treating clinicians can collaborate to identify whether a patient's symptoms may be due to the side effects of a particular drug or the interaction of multiple medications. Because clin icians may not be aware of all possible drug side effects or interactions, pharmacists may also provide input in the selection of medications for a patient's health problem. Facilitating Teamwork in Clinical Practice Health care organizations play a critical role in ensuring effective teamwork. Thus, the committee recommends that health care organizations should facilitate and support interprofessional and intra-professional teamwork in the diagnostic process. There are a number of strategies that health care organi zations can employ to improve teamwork in the diagnostic process. Creating a cultu re that encourages intra- a nd interprofessional collaboration DIAGNOSTIC TEAM MEMBERS & TASKS 4-11 PREPUBLICATION COPY: UNCORRECTED PROOFS is critical, as is designing a work system that is supportive of effective teamwork, including the use of results reporting tools that convey importa nt information to the diagnostic team members (see Chapter 6). For example, the use health IT and telemedicine may help facilitate communication and collaboration among team member s, especially when geographically distant health care professionals are involved in the diagnostic process (see Chapter 5). The following section describes several opportunities for impr oving collaboration, such as care delivery reforms, treatment planning conferences, diagnostic management teams, integrated practice units, morbidity and mortality conferences, and multidisciplinary rounds. Care Delivery Reforms Two care delivery reforms\u2014patient-centered medical homes (PCMHs) and accountable care organizations (ACOs) \u2014have recently been implemented across the country as a means to improve patient care coordination and increase communication among hea lth care professionals (see Chapter 7). PCMHs are designed to improve th e quality of primary care by fostering a sense of partnership among patients and clinicians and by designating a particular health care practice as being accountable for a patient's care (Hea lth Affairs, 2010; Schoen et al., 2007). PCMHs can improve team-based care by acting as the nexus of coordination and communication for a patient and their health care professionals; recent evidence suggests that attempts to improve primary care by enhancing its role in coordination have shown some success in improving patient and staff experiences and reducing hospitalization (AHRQ, 2010a). Some PCMH demonstrations are still under evaluation, and other PCMHs are tryi ng new formats; for example, Maryland Blue Cross Blue Shield is offering incentives for physicia ns to form virtual panels that serve as de facto PCMHs (CMS, 2013; Dentzer, 2012). Barrier s to PCMHs include the high up-front costs associated with implementing the health IT infrastructure necessary for improved communication and collaboration and also difficulties in incentivizing outside clinicians to work with those in the PCMH (Crabtree et al., 2010; Rittenhouse et al., 2009). ACOs are organized groups of health care prof essionals, practices, or hospitals that work together to assume responsibility for and provide cost effective care to a defined population of beneficiaries. The Affordable Care Act created ACOs to address delivery system fragmentation and to align incentives to im prove communication and collab oration among health care professionals (Berwick, 2011). Alth ough the evidence needed to eval uate the impact of ACOs on improved communication and care coordination is still being collected, there are early indications that ACOs can improve patient ca re. For example, the Medicare Physician Group Practice, the predecessor to ACOs, demonstrated achievement of 29 of 32 quality measures (Iglehart, 2011), and an early study shows that so me Pioneer ACOs were able to reduce overall costs (CMS, 2013). As with PCMHs, high initial co sts associated with IT implementation are a barrier to the implementa tion of ACOs (Kern, 2014). Treatment Planning Conferences Treatment planning conferences (also referred to as tumor boards) are a form of case review in which a multidisciplin ary team of health care profe ssionals \"review and discuss the medical condition and treatment options of a patient\" (NCI, 2015). Treatment planning conferences are often held for specific types of cancers, and their pa rticipants may include surgeons, medical oncologists, radi ologists, radiation oncologists, pathologists, nurses, and DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS collaborating health care professionals. These boards generally serve two purposes\u2014to help diagnose complex cases involving ca ncer and to consider treatmen t options for patients with a cancer diagnosis. An advantage of this approach is that it provides a collaborative environment where an intra- and interprofessional team of clinicians can collaborate and share information and opinions. The evidence on whether treatme nt planning conferences improve patient outcomes is inconclusive; although a number of studies have found that a small percentage of initial cancer diagnoses changed after review in a treatment pl anning conference (Chang et al., 2001; Newman et al., 2006; Pawlik et al., 2008; Cohen et al., 2009; Santoso et al., 2004), a multi-site study found that treatment planning co nferences did not significantly improve the quality of care of patients (Kea ting et al., 2012). Despite the mixe d evidence, treatment planning conferences may help to identify and avoid pot ential diagnostic errors by bringing multiple perspectives to challenging diagnoses. This appro ach could also be applied to diagnoses other than cancer, especially ones with serious health consequences or complex symptom presentations. Diagnostic Management Teams Health care organizations can support teamwo rk among pathologists, radiologists, other diagnosticians, and treating health care profe ssionals by forming diagnostic management teams (DMTs). For example, Vanderbil t University's DMT is designe d to improve diagnosis through improved communication and access to diagnostic speci alists; it offers participating health care professionals assistance in select ing appropriate diagnostic tests and interpreting diagnostic test results (Govern, 2013). DMT consulta tions consider a patient's clin ical information to provide a context for the test result, and th ey ensure that a clinically valuable interpretation is included in the test result report. Clinicians who participate in this process report a favorable view of DMTs, and although perceived high initial costs are a potential barrier, there is so me evidence that DMTs can lower overall costs (Seegmiller et al., 2013). Integrated Practice Units Integrated practice units (IPUs) have been proposed as a way to improve the value of health care and to address the communication pr oblems that result from system fragmentation (Porter, 2010; Porter and Lee, 2013). An IPU is a group of clinicians a nd non-clinicians who are responsible for the comprehens ive care of a specific medical condition and the associated complications or for a set of closely related conditions (Porter and Lee, 2013). The members of an IPU have expertise in the rele vant condition and work together as a team to provide total care for patients, including inpatient care, outpatient care, and health care education. The IPU model, which has been applied to such conditions as breast cancer and joint replacement, has been shown to improve patient outcomes. For example, patients treated by a spinal care IPU were found to miss fewer days of work, require fewe r physical therapy visits, and fewer magnetic resonance images to evaluate their back problems (Porter and Lee, 2013). Morbidity and Mortality Conferences Morbidity and mortality conferences (M&M conf erences) are forums that bring clinicians together to review cases invol ving medical errors and adverse events that have occurred. M&M DIAGNOSTIC TEAM MEMBERS & TASKS 4-13 PREPUBLICATION COPY: UNCORRECTED PROOFS conferences have been used to better understand how errors occur and to help health care organizations identify work system failures and develop interventions to address these failures (AHRQ, 2008b). These conferences have been used to elucidate the causes of diagnostic error and to help improve diagnostic performance (Cifra et al., 2014: Cifra et al., 2015). Multidisciplinary Rounds Multidisciplinary rounds (also referred to as interdisciplinary rounds) bring health care professionals from different disciplines together to consider the diagnosis and treatment of specific patients. These rounds may involve interacting with patients, or may be part of a lecture with a patient-actor. They provide an opportunity for health care professionals to learn how other health care professionals approach medical issues and to interact with h ealth care professionals from different disciplines. Mult idisciplinary rounds have been associated with improvements in care quality, shortened length of stays, and enha ncements in resident education (O'Mahony et al., 2007). Chapter 6 provides additional inform ation on the potential for multidisciplinary rounds and M&M conferences to im prove the diagnostic process. PATIENT ENGAGEMENT IN DIAGNOSIS The IOM report Crossing the Quality Chasm: A New Health System for the 21st Century highlighted patient-centeredness as a core aim of the health care system and defined it as \"providing care that is respectful of and responsive to individual patient preferences, needs, and values and ensuring that patient values guide all clin ical decisions\" (IOM, 2001, p. 6). A critical feature of patient-centeredness is the active engagement and shar ed decision making of patients and their families in the patients' health care. Patient engagement has been defined as \"actions [people] take to support their health and benefit from health care\" (CFAH, 2015) and has been shown to increase patient satisfaction with care an d to improve health outcomes (Boulding et al., 2011; Etchegaray Weinga rt, 2013). The goal of patient enga gement in diagnosis is to improve patient care and outcomes by enabling patients and their families to contribute valuable input that will facilitate an accu rate and timely diagnosis and improve shared decision-making about the path of care. There are a variety of factors that present challenges to patient engagement in diagnosis, and the committee makes one recommendation to improve patient and family engagement in the diagnostic process. Challenges to Patient Engagement in Diagnosis Patients and their families may not be effectiv ely engaged in the diagnostic process for a variety of reasons, including both patient-related factors and hea lth care professional and system factors (see Box 4-3). 4-14 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS BOX 4-3 Challenges to Effective Patient and Family Engagement in the Diagnostic Process Patients and families may: Fear complaining and being seen as difficult Feel a lack of control or vulnerability for many reasons (sick, scared, social status) Not always take their own problems seriously enough Lack understanding of the health care system or opportunities to become involved Encounter inexperienced health care professionals Have language and health literacy barriers Be unsure how to seek resolution to a problem when issues are not resolved at the point of care Health care professionals may: Dismiss patients' complaints and knowledge Act on implicit or explicit biases and stereotypes Incorrectly assume that a patient does not want to be involved in his or her care Health care systems may exhibit: Disjointed care through a lack of coordination and teamwork Breakdowns in communication among health care professionals Failure to transmit information to patients Failure to adequately review or follow up on diagnostic testing results Lack of disclosure or apology after diagnostic errors SOURCE: McDonald et al., 2013. Adapted by permission from BMJ Publishing Group Limited. The patient is in: Patient involvement strategies for diagnostic error mitigation. McDonald, K. M., C. L. Bryce, and M. L. Graber. 22(2):30-36. 2013. Patient-Related Factors The patient-related factors that prevent activ e engagement in the diagnostic process can include unfamiliarity with and poor access to the health care system; difficulty with communication due to language, heal th literacy, and cultural barrier s; and a patient's lack of comfort in taking an active role in diagnosis. Patients are a heteroge neous population, and their needs, values, preferences, and ability to engage in the diagnostic process vary considerably. Some patients may fear asserting themselves in the diagnostic process because they do not want to appear to be difficu lt and risk alienating their clinicia n, which could affect the quality of their care (Frosch et al., 2012). In one st udy involving cancer patient s who thought there had been a serious breakdown in their care, 87 percent did not formally report their concern to the health care organization (Mazor et al., 2012). A patient may also feel uncomfortable asking for a referral to seek a second opinion or asking to see a more experience d clinician (Entwistle et al., 2010). The stress that patients feel related to their health, to navi gating the health care system, to missing work, or to dealing with insurance issues can make them less likely to participate in their DIAGNOSTIC TEAM MEMBERS & TASKS 4-15 PREPUBLICATION COPY: UNCORRECTED PROOFS own care (Evans, 2013). A patient's symptoms and severity of illness ca n also prevent active engagement in the diagnostic process. Access to the health care system varies acr oss patients, depending on factors such as health insurance coverage, socioeconomic status a nd the affordability of health care, and health care delivery system attributes, which in turn can affect the patient's care. For example, the location of health care faci lities and the hours of availability for patient care can affect a patient's access to health care. Poor access to, and unfam iliarity with, the heal th care system may contribute to delays in seeking care for symptoms, which can re sult in a disease being more advanced when it is diagnosed, leading to a wors e prognosis or a more invasive treatment which could have been avoided. Certain populations ar e more likely to have difficulty obtaining care, including racial and ethnic minorities and indi viduals of low socioeconomic status (AHRQ, 2013a, 2013b). Cultural and language barriers can be signifi cant challenges which prevent patients from fully engaging in the diagnostic process. A pproximately 22 percent of the 60 million people living in the United States who speak a language other than English at home report not being able to speak English well or at all (Ryan, 2013). The IOM report Unequal Treatment: Confronting Racial and Ethnic Disparities in Health Care noted that \"Language barriers may affect the delivery of adequate care through poor exchange of information, loss of important cultural information, misundersta nding of physician instruction, poor shared decision making, or ethical compromises (e.g., difficulty obtaining informed consent)\" (IOM, 2003b, p. 17). In addition, the Joint Commission has found that miscommunications and misunderstandings increase the risk for adverse events in health care (Joint Commission, 2007). These barriers have also been associated with di agnostic errors (Flores, 2006; Marcus, 2003; Price-Wise, 2008). To meet the needs of patients with limited English pr oficiency, some health care organizations have instituted policies to ensure th at language services, such as those provided by interpreters, are available and that educational literature is provided in langua ges other than English (HHS, 2015). Despite these steps, a study found that ev en when hospitals have a policy regarding language services, they often do not provide staff with the training necessary to access language services, assess the competency of interpreters, a nd there is little oversight of the quality of the translated literature (Wilson-Stronks, 2007). Even if a patient speaks the same language as his or her clinicians, there can be communication challenges if the patient has limited health literacy or if clinicians use unfamiliar medical terminology. In the United States more than 80 million adults have a poor level of health literacy, which has been defined as \"the degree to which individuals have the capacity to obtain, process, and understand basic health information a nd services needed to ma ke appropriate health decisions\" (AHRQ, 2011, pp.ES-1). Health literacy requires applying a complex set of skills involving reading, listening, anal ysis, and decision making to health settings (NNLM, 2013). Patients lacking health literacy skills may be limited in their ability to participate in the diagnostic process and in decisi on making about the planned path of care (Peters et al., 2007). A recent study indicated that a group of medical tr ainees including PA and MD students lacked confidence in their ability to co mmunicate effectively with low- health-literacy patients (Ali et al., 2014). There is a tremendous amount of information and resources available on the Internet and mobile apps to help patients identify potential diagnoses a nd to plan for health care appointments. A 2013 Pew Research Center study found that 35 percent of American adults have used online resources to diagnose a condition in them selves or someone else (Fox and Duggan, 4-16 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS 2013). These resources have varying levels of accuracy, and patients may have difficulty assessing the quality of the information availa ble to them (NLM, 2012b; Semigran et al., 2015). Clinicians may also react negatively to patients' use of this information in clinical visits (Julavits, 2014). Patients' level of comfort with actively engaging in care decisions, such as asking questions, stating preferences, or seeking alternative opinions, ma y differ considerably from one patient to another. Some patients may prefer to be actively involved in all aspects of the decision-making process, while others would rather defer to their clinic ians' judgment (Fowler, 2011). In a national survey, the majority of respondents reported that they would like clinicians to effectively engage them in health care decision making by ta lking about their diagnosis and explaining the options available, including the risks and their im pact on quality of life and the costs associated with them (IOM, 2012b). Another survey f ound that 96 percent of respondents desired to be asked questions a nd to be given choices regardi ng their care, and approximately half preferred to have their clinicians make the final decision s (Levinson et al., 2005). Clinicians may not be aware of\u2014or they may misjudge\u2014the role that a patient desire s to play in decision making, and as a result they may make decisions th at are misaligned with patient preferences, a phenomenon that has been referred to as a pref erence misdiagnosis (Mulley et al., 2012). Factors such as age, gender, medical history, familiarity with the health care system, socioeconomic status, and cultural issues can factor in to patie nts' preferences regarding engagement and shared decision making (Boyer et al., 2001 ; Cox et al., 2012; Lipson et al., 2003; Longtin et al., 2010). Several studies have found that female patien ts who are younger and have more education tend to prefer a more active role in decisions regarding their h ealth (Arora and McHorney, 2000; Deber et al., 2007; Say al., 2006 ). A survey of low-income pa tients faced with major medical decisions found that 75 percent wanted to be very involved in the decision-making process (BSCF, 2014). Health Care Professional and System Factors A major concern cited by health care professi onals is a lack of time to truly engage patients in the diagnostic process (Anderson and Funnell, 2005; Sark ar et al., 2012, 2014; Stevenson, 2003). Compared to more procedure-or iented tasks, fee-for-service payment does not incentivize the time spent on evaluation and mana gement services that reflect the cognitive expertise and skills that clinicians employ in the diagnos tic process (National Commission on Physician Payment Reform, 2013). This creates an environment in which communication, such as the clinical history and inte rview, may be rushed and patien ts may not have time to thoroughly discuss their symptoms and health concerns, a lthough new models of payment and care delivery may make this a higher priority (see Chapter 7) (AHRQ, 2014c; Cosgrove et al., 2013; Roades, 2013). Time pressures may also lead to an overreliance on diagnostic testing in place of patient engagement, even when these may be inappropria te (see Chapter 2) (N ewman-Toker et al., 2013; Rao and Levin, 2012; Zhi et al., 2013). The use of EHRs may also lead to problems with patient engagement, as health care professionals may be distracted from communicating with patients as they enter information in the EHR (see Chap ter 5) (O'Malley et al., 2010; Spain, 2014). Although many clinicians are positive about engaging with their patients (Stevenson, 2003), there are indications that som e may be resistant to activ e patient involvement with patients, certain clinician behaviors can discourage open communication and patient engagement, DIAGNOSTIC TEAM MEMBERS & TASKS 4-17 PREPUBLICATION COPY: UNCORRECTED PROOFS including being dismissive of a patient's complaints and their knowledge of their symptoms, not listening, or interrupting frequen tly (Dyche and Swiderski, 2005; Marvel et al., 1999; McDonald et al., 2013). For example, one study found that af ter a clinician entered the room, patients spoke uninterrupted for an average of only 12 seconds; the clinicians frequently in terrupted the patients before they had finished speaking (Rhoades et al., 2001). Clinicians' vulnerability to cognitive and affective biases may also contribute to behaviors that hinder patient engagement and contribute to diagnostic errors (Croskerry, 2013; Klein, 2005). Clinic ians may exhibit biases in regard to gender, race, ethnicit y, sexual orientation, age, obesit y, a patient's health problem (e.g., chronic pain, mental health) or othe r factors (IOM, 2003b, 2011b, 2011c, 2012e; Puhl and Brownell, 2001; Schwartz et al ., 2003). For example, clinicians may be judgmental or blame patients for their illnesses, and this could affect a patient's willingness to participate in the diagnostic process (Croskerry, 2003) . Patients may fear disclosing sensitive information to their clinicians, such as their sexual orientation, due to a fear that such disclosure could negatively affect their care (IOM, 2011b; Durso and Meyer, 2013; Foglia and Fredriksen-Goldsen, 2014). If this information is not disclosed, Foglia and Fred riksen-Goldsen (2014) note that it could result in diagnostic error, such as a delay in diagnosing a serious health problem. The Unequal Treatment report found that \"bias, stereoty ping, prejudice, and clinical uncertainty on the part of health care providers may contri bute to racial and ethnic disp arities in healthcare\" (IOM, 2003b, p. 12). For example, one study found that a patien t's race and gender independently influenced how physicians managed chest pain; physicians were significantly more likely to refer white men exhibiting signs of coronary artery disease for ca rdiac catheterization than to refer black women with the same symptoms (Schulman et al., 1999). Clinicians may also disregard symptoms in patients with previous diagnoses of mental illn ess or substance abuse and may attribute new physical symptoms to a psychological cause without a proper evaluation. Alternatively, clinicians may incorrectly diagnose or assume ps ychiatric, alcohol, or drug abuse diagnoses for serious medical conditions, such as hypoxia, deliri um, metabolic abnormalities, or head injuries, a mistake known as a \"psych-out error\" (Croskerry, 2003). Fragmentation of health care organizations and poor coordi nation of care hinder patient engagement and can contribute to errors in di agnosis (CFAH, 2014c; Gandhi et al., IOM, 2013a; Schiff, 2008; Starfi eld, 2000). In cases where there is poor care coordination and communication among a patient's clinicians, patients an d their families may need to convey their information among their health care professionals. For example, one survey reported that approximately 25 percent of patients re ported that a test had to be repeated because the results had not been shared w ith other health care professionals involved in a patient's care (Stremikis, 2011). Limited interoperability among EHRs and laboratory and medical informatics systems also prevents the flow of information among clinicians and health care settings (see Chapter 5). Improving Patient Engagement in the Diagnostic Process Patients and their families play a crucial role in the diagnostic process, and the ultimate responsibility for supporting and enabling patient and family engagement in the diagnostic process rests with health care professionals and organizations. Thus, the committee recommends that health care professionals and organizations should partner with patients and their families as diagnostic team members and facilitate patient and family engagement in the diagnostic process, aligne d w ith their needs, values, and preferences. Health care professionals need to embrace patients and their families as essential partners in the 4-18 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS diagnostic process, with valuable contributions that can improv e diagnosis and avert diagnostic errors. Learning about the Diagnostic Process To facilitate patient and family engage ment, the committee recommends that health care professionals and organizations provide pati ents with opportunities to learn about the diagnostic process. One of the challenges that patients and their families face with diagnosis is their unfamiliarity with the process; thus, inform ing patients and their fam ilies about it has the potential to improve engagement and reduce diagnostic errors. Pa tients may be unfamiliar with the terminology related to the dia gnostic process, such as a \"di fferential diagnosis\" or a \"working diagnosis,\"3 and also with the role of time in the pro cess. For example, a health care professional may propose a working diagnosis if there is some uncertainty in the diagnosis, and this may change with new information. For some health problems, watchful waiting is appropriate, and patients need to be informed that time can give clinicians a better unders tanding of their health problem. It is also important that patients unders tand when and who to contact if their symptoms do not resolve or if they experience new sympto ms that do not seem to fit with a working diagnosis. Providing information explaining the roles and tasks of the various individuals involved in diagnosis could also facilitate more active engagement in the diagnostic process. A number of groups have deve loped information and resource s to help patients become more actively involved in their health care, including the diagnostic process (CFAH, 2014c; Lucian Leape Institute, 2014; Josiah Macy Jr. Foundation, 2014) . The Center for Advancing Health has developed a variety of resources to help patients gain maximum benefit from their health care, including informati on about communicating with clin icians, organizing health care, seeking knowledge about health, and other topics (CFAH, 2014a, 2014b). The Speak Up Program offers materials to help patients become more actively involved in their care and avoid errors (Joint Commission, 2015) . The National Patient Safety Foundation, the Society to Improve Diagnosis in Medicine, and Kaiser Pe rmanente have developed resources to help patients get the right diagnosis (see Boxes 4-4 and 4-5) (Kaiser Permanente, 2012; NPSF and SIDM, 2014). The actions suggested in the ch ecklists include having a thorough knowledge of medical history, formulating notes about symptoms and questions to bring to appointments, and maintaining a list of medications (such as prescriptions, over the counter medica tions, dietary supplements, and complementary and alternative medicines). Health ca re professionals and organizations can also inform patients and famili es about the reliability and accuracy of online resources and direct them to reputable s ources (FamilyDoctor.org, 2014; Mayo Clinic, 2015; NLM, 2012a, 2012b; Semigran et al., 2015). 3 A differential diagnosis is a list of possible diagnoses ranked from most probable to least probable based on the available information. A working diagnosis is a preliminary or provisional diagnosis, and may be in the form of a differential diagnosis. DIAGNOSTIC TEAM MEMBERS & TASKS 4-19 PREPUBLICATION COPY: UNCORRECTED PROOFS BOX 4-4 Checklist for Getting the Right Diagnosis 1. Tell Your Story Well: Be clear, complete, and accurate when you tell your clinician about your illness. Be Clear - Take some time to think about when your symptoms star ted, what made your symptoms better or worse, or if your symptoms were related to taking medications, eating a meal, exercising, or a certain time of day. Be Complete - Try to remember all of the important information about your illness. Write down some notes and bring them with you. A family member may be able to help you with this. Be Accurate - Sometimes you may see multiple clinicians during a medical appointment. Make sure your clinicians hear the same story regarding your illness. 2. Be a Good Historian: Remember what treatments you have tried in the past, if they helped, and what, if any, side effects you experienced. Think about how your illness has progressed over time. Think about your family's medical history and if you may be at risk for similar illnesses. 3. Keep Good Records: Keep your own records of test results, referrals, and hospital admissions. Keep an accurate list of your medications. Bring your medication list with you w hen you see your clinician or pharmacist. 4. Be an Informed Consumer: Learn about your illness by looking at reliable sources on the Internet or visit a local library. Learn about the tests or procedures you are having done. Learn about your medications: o Know the names of your medicati ons (both generic and brand names). For example: Tylenol (brand name) and acetaminophen (generic name) o Know what the medication is for o Know the amount (dose) you need to take o Know the time(s) you need to take it during the day o Know the side effects to watch for and report to your clinician o Know if the medication interacts with any food or drugs 5. Take Charge of Managing Your Health: When meeting with your clinician , use the Ask Me 3 brochure, Good Questions for Getting the Right Diagnosis : 1. What could be causing my problem? 2. What else could it be? 3. When will I get my test results, and what should I do to follow up? If you have more than one clinician, make sure each clinician knows what the other person is thinking and planning. Make sure each clinician knows all of your test results, medications, or other treatments. Be informed and involved in decisions about your health. 4-20 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS 6. Know Your Test Results: Make sure both you and your clinician get the results from any tests that are done. Don't assume that no news is good news; call and check on your test results. Ask what the test results mean and what needs to be done next. 7. Follow Up: Ask when you need to make another appointment (follow up) with your clinician once you start treatment. Ask what to expect from the treat ment or what it will do for you. Ask what you need to do if you get new symptoms or start to feel worse. 8. Make Sure it is the Right Diagnosis: Sometimes your diagnosis is the most \"likely\" thing that is wrong, but it may not be the \"right\" diagnosis. Don't be afraid to ask \"What else could this be?\" Encourage your clinicians to think about other possible reasons for your illness. 9. Record Your Health Information and Monitor Your Progress: Track your health information and share it with your health care team in a structured format.a a One available resource is SIDM's patient toolkit 2014b; NPSF, 2015a. Reprinted, with permission, from the National Patient Safety Foundation and Society to Improve Diagnosis in Medicine. Ask Me 3 is a registered trademark of Pfizer Inc. and is licensed to the National Patient Safety Foundation. BOX 4-5 Smart Partners About Your Health SMART CHECKLIST Symptoms Tell your clinician what's currently wrong . . . why you are here. Is this a new symptom, when did it start, what home remedies have you tried? Medical/medication history Provide medical information about your past. Be prepared to discuss your current medications and over-the-counter medicines or supplements that you take (Ibuprofen, vitamins, etc.) with your clinician. Assessment Describe what you think is going on. Express your feelings and your concerns. Review After your clinician diagnoses your condition, ask if it could be something else. Make sure you understand what is causing your symptoms. In your own words describe the diagnosis back to your clinician. Talk about things that might keep you from following your treatment plan. To do DIAGNOSTIC TEAM MEMBERS & TASKS 4-21 PREPUBLICATION COPY: UNCORRECTED PROOFS Make sure you understand what you need to do next. Repeat your treatment plan and the information you received from your clinic ian. Be sure to ask for your after-visit summary and follow all your clinician's instructions or let him or her know if you can't. SMART SCRIPT Symptoms \"I'm concerned about . \" Medical/medication history \"Some of my medical history that might be important includes (a close family member had cancer). To help me remember I have a list of my current medications and supplements.\" Assessment \"I'm worried I might have ___ and I have tried . . . \" After your clinician diagnoses your condition, ask questions and verify next steps. Review \"Could you tell me what else it could be or if more than one thing is going on?\" To do \"Just to make sure I haven't missed anything, I need to . . . \" BEFORE YOUR VISIT THINK ABOUT . . . What you want to talk about during your visit What symptoms are you having? How long have you had them? Do they go away? Have you tried any home treatments? If so, what? Inviting someone to go with you Bringing someone to your appointment can help you to answer questions and give your clinician information. Write down your questions or some words that will help remind you What concerns do you have about your symptoms? What concerns are most important to you? Be prepared Be prepared to go over your medications, vitamins, and supplements. Make sure you mention any changes that you have made. DURING YOUR VISIT . . . Confirm with your clinician why you are there Your symptoms When did your symptoms start? Do they go away? Where are they located? How do they affect your daily activities? Share what home treatments you have tried Did they help or make your symptoms worse? Share your worries about your symptoms Share what you think might be going on YOUR DIAGNOSIS: CONSIDER ASKING THE CLINICIAN: What else could it be? 4-22 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Do all my symptoms match your diagnosis? Could there be more than one thing going on? AT THE END OF YOUR VISIT . . . Make sure you understand what you need to do next Repeat your treatment plan and the informati on you received from your clinician. If you don't understand ask your clinician to explain any words or ideas that are confusing. Talk about things that you feel might keep you from following the treatment plan. Talk about other treatment plans or options. Be sure to ask for your after-visit summary Follow all your clinician's instructions or let them know if you can't SOURCE: Reprinted, with permission, from Kaiser Permanente. Copyright 2012 by Kaiser Permanente. Health Care Environments that are Suppor tive of Patient and Family Engagement Health care professionals a nd the organizations in which they practice can facilitate patient engagement in the diagnostic proce ss by improving communicatio n and shared decision making and by addressing h ealth literacy barriers. Thus, the committee recommends that health care professionals and organizations should create environments in which patients and their families are comfortable engaging in the diagnostic process and sharing feedback and concerns about diagnostic errors and near misses. Health care organizations will need to carefully consider whether th eir care delivery systems and processes fully support patient engagement and work to improve systems and pr ocesses that are oriented primarily toward meeting the needs of health care professionals rather than patients. One of the most important actions that health care professionals can take to implement this recommendation is to improve their communication skills because effective pa tient-clinician communication is critical to making accurate diagnoses and to averting diag nostic errors. Several organizations offer communication training courses for clinicians, including the Institute for Healthcare Communication and the American Academy on Communication in Heal thcare (AACH, 2015; ICH, 2015). There are several techniques and strategies that clinicians can use to improve communication and patient engagement. One of the most well-known methods is teach-back, which involves a clinician explaining a concept and then asking the patient to repeat in his or her own words what was said (Nouri and Rudd, 2015; Schillinger et al., 2003). The clinician can then evaluate whether the patient has a good understanding and, if the patient does not, can explain the concept further using a different approach in order to improve the patient's comprehension. Patient-clinicia n communication can also be improved by using clear and simple language, encouraging questions, listening actively, allowing the patie nt to speak without interruption, and responding to the patient's emotions. Such techniques may also help some patients overcome their fear of discussing their concerns and become more likely to share sensitive information that could provide valuable input to the diagnostic process. If patients are upset or anxious, they may be less likely to give a thorough and accu rate account of their symptoms and health concerns. In clusion of a patient's family in a patient's care may also facilitate engagement and comprehension. DIAGNOSTIC TEAM MEMBERS & TASKS 4-23 PREPUBLICATION COPY: UNCORRECTED PROOFS Supportive health care environments are pl aces where patients and families feel comfortable sharing their concerns about diagnostic errors, near misses, and providing feedback on their experiences with diagnosis. As discusse d in the education sect ion of this chapter, providing feedback to health care professionals about the accuracy of their diagnoses can help improve their diagnostic performance. However, health care professiona ls often do not have opportunities to hear from patients about their diagnostic performance (Berner and Graber, 2008; Schiff, 2008). For example, a patient discharged from the emergency department may then see a primary care clinician, and the emergency depart ment clinician may never hear whether the diagnosis on discharge was correct. To im prove diagnostic performance, health care professionals and organizations should encourage patients and their families to follow up with their health care professionals to let them know about th eir experiences. Health care organizations can facilitate feedback from patients and their families by, for example, implementing procedures to follow up with patients after their visits. This feedback could also be used as a routine part of assessing patient sa tisfaction with clinicians and the health care organization. In order to establish environments where patients and families can share their concerns, clinicians need to be ready to communicate w ith patients about the oc currence of diagnostic errors. A study involving 13 focus groups found th at patients who have experienced a medical error wanted clinicians to disc lose all harmful erro rs (Gallagher et al., 2003). These patients sought information about what happened, why the error happened, how to mitigate the consequences of the error, and how clinicians would prevent recurrences (Gallagher et al., 2003). Clinicians have been reluctant to disclose medical errors to patients and their families because of the fear of litigation as well as anxiety ove r communicating these erro rs; however, disclosing errors has been broadly recognized as the right thing to do (AHRQ, 2014a). There is evidence that disclosure improves patient outcomes and may reduce malpractice claims and costs (see Chapter 7) (AHRQ, 2014a; Hendr ich et al., 2014; Kachalia et al., 2003; Mello et al., 2014). Fostering shared decision making, which is defined as \"a collaborative process that allows patients and their providers to make health care decisions together, taking into account the best scientific evidence available, as well as the patient's values and preferences\" (IMDF, 2014), can also improve patient and family engagement in the diagnostic process. Tools to promote shared decision making are decisi on aids, which provide objective, evidence-based information on options that patients may ha ve so that they can make informed decisions (IMDF, 2014; MedPAC, 2010). Although many deci sion aids are focused on treatment and screening decisions, some have been developed for diagnostic situatio ns, such as an evaluation for low back pain or whether to do imaging studies for chest discomfort (Ronda et al., 2014; SCAI, 2014). Addressing health literacy barriers may also improve patient and family engagement in the diagnostic process. Acknowledging that the health care system can place unreasonably high health literacy demands on patients and familie s, an IOM discussion paper identified 10 attributes of health-literate h ealth care organizations, summarized in Box 4-6 (IOM, 2012a). For example, health care organizations can encourag e the use of tools\u2014such as Speak Up, Ask Me Three, Getting the Right Diagnosis, and Smart Pa rtners About Your Health\u2014in order to improve communication among patients and thei r clinicians. If health care organizations make it easier for patients and families to navigate, understand, and use health care serv ices, then patients and their families can become more engaged in th e diagnostic process. In addition, health care professionals and organizations can ensure that h ealth care environments reflect cultural and language competencies (AHRQ, 2012). The IOM recommended the broader use of interpretation 4-24 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS services where community need exists (IOM, 20 03b), and the U.S. Department of Health and Human Services (HHS) has esta blished national standards for culturally and linguistically appropriate care (HHS, 2015). Many health care professional school s offer cultural competency courses, and there are continuing education programs designed to increase cultural competency and sensitivity. Some health care organizations have instituted policies to ensure that language services, such as those provided by interpreters, ar e available and that educational literature is provided in languages other than English. Though there is evidence that improving cultural competency can improve patient satisfaction with care (Castro and Ruiz, 2009; Paez et al., 2009), the evidence connecting cultural competency w ith improvements in patient outcomes is limited (Beach et al., 2005; Lie et al., 2011). BOX 4-6 Attributes of Health Literate Health Care Organizations A health literate organization: 1. Has leadership that makes health literacy integral to its mission, structure, and operations 2. Integrates health literacy into planning, evaluation measures, patient safety, and quality improvement 3. Prepares the workforce to be health literate and monitors progress 4. Includes populations served in the design, implementation, and evaluation of health information and services 5. Meets the needs of populations with a range of health literacy skills while avoiding stigmatization 6. Uses health literacy strategies in interpersonal communications and confirms understanding at all points of contact 7. Provides easy access to health information and services and navigation assistance 8. Designs and distributes print, audiovisual, and social media content that is easy to understand and act on 9. Addresses health literacy in high-risk situations, including care transition and communications about medicines 10. Communicates clearly what health plans will cover and what individuals will have to pay for services SOURCE: IOM, 2012a. Health care organizations can al so facilitate patients' re-engagement with the health care system for unresolved symptoms or in other in stances (such as a missed follow-up appointment). For example, Kaiser Permanente's SureNet Pr ogram identifies people who have inadvertent lapses in care and uses electronic surveillance an d staff to follow up with these patients (Kanter, 2014). Closed-loop communication systems that re quire all information from referrals and consultations to be relayed to the referring clinic ian may also help ensure that patients re-engage the health care system when necessary (see Chapter 6) (Gandhi, 2014; Schiff, 2014a). Patient Access to Their Electronic Health Information Another opportunity to encourage patient e ngagement in the diagnostic process is to make a patient's health information more accessi ble and transparent. One way to accomplish this DIAGNOSTIC TEAM MEMBERS & TASKS 4-25 PREPUBLICATION COPY: UNCORRECTED PROOFS is through open medical records, or records that \"patients, and others authorized by them, are allowed to read...When used properly, they let pa tients see themselves through the eyes of their caregivers and give them insight into diagnos es and treatment options. Having access to such information permits patients to take a more ac tive role in decisions a bout their care\" (Frampton et al., 2009, p.59). Thus, the committee recommends that health care professionals and organizations should ensure patient access to EHRs, including clinical notes and diagnostic testing results, to facilitate patient engagement in the diagnostic process and patient review of health records for accuracy. The Office of the National Coordi nator for Health Information Technology's Meaningful Use 2 requirements incl ude patient access to their electronic health information (such as medication lists, diagnostic test results, allergie s, and clinical problem lists), and organizations have begun to em ploy patient portals in order to enable patient access to this information (Adler-Milstein et al., 2014; Bruno et al., 2014; Furukawa et al., 2014; HealthIT.gov, 2015). Unfortunately, many organizations are having trouble meeting the Meaningful Use 2 requirement that five percent of patients \"v iew, download, or transmit their health information\" (Adler-Milstein, 2015). The OpenNotes initiative, available to almost five million patients, has promoted even greater transparency of patients' health information by inviting patients to view the notes recorded by health care professionals during a clinical visit (OpenN otes, 2015a). In an analysis of patients who were invited to read their notes over the course of a year, approximately 70 to 80 percent surveyed said that they read their notes, understood their care plan better, and were better prepared for visits (Delbanco et al., 2012; Bell et al., 2014). Clinicians re port that implementing OpenNotes results in few, if any, disruptions to their practice (Bell et al ., 2014; Walker et al., 2014). In input that was provided to the committee, the OpenNotes developers suggested that initiatives like OpenNotes have the potential to reduce diagnostic errors by enabling patients and families to catch errors within clinician not es, by encouraging patients to speak up, and by preventing diagnostic delay by helping patients be tter remember recommendations for tests and procedures. In addition, the devel opers cited transparency as a means to help patients better understand their clinicians' thought pr ocesses, to enhance trust, and to engage family caregivers. In a pilot study, the developers found that patie nts with access to their medical information were more likely than those without such access to have questions, to identify inaccuracies, and to offer additional information regarding the da ta in their health records (NORC, 2014). Direct patient access to diagnostic testing result s is also important to patient engagement because diagnostic errors commonly occur within the testing steps of the diagnostic process (Gandhi et al., 2006; Schi ff et al., 2009). In 2014, HHS strengthe ned patients' righ ts to directly access their laboratory test results (HHS, 2014). Prior to the impleme ntation of this regulation, an analysis found that only 3 in 10 laboratories allowed patients or their legal representatives access to their clinical test results (Swain and Pa tel, 2014). Similarly, the Mammography Quality Standards Act mandated the direct reporting of mammography results to patients with a summary of the report written in easily understood terms. A st udy found that direct reporting improved patient satisfaction with mammography and the timeliness of the results reporting, although it did not significantly reduce patient anxiety or impr ove patient adherence to the recommendations (Priyanath et al., 2002). Although there is som e concern that providing patients direct access to diagnostic testing results before they cons ult with their clinician may not be appropriate in all cases (for ex ample, for worrisome test results or for test results that patients may have difficulty in interpreting), there are a number of advantages to direct patient access, 4-26 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS including reducing the likelihood that patients do not receiv e a test result and improving subsequent decision making and treatment (ASCP, 2014). Some organizati ons have implemented time delays to enable clinicians to communicate directly with patients before the patients access their diagnostic testing results electronically (Butcher, 2014). Involvement of Patients and Families in Efforts to Improve Diagnosis Patients and their families have unique insights into the diagnostic process, their health outcomes, and the occurrence of diagnostic errors (Etchegaray et al., 2014; Gertler et al., 2014; Schiff et al., 2014). Their perspe ctives are critical to identifying errors and near misses, especially ones that health care professionals may not be aware of, and they can also inform efforts to improve the diagnostic process (G ertler et al., 2014; We ingart et al., 2005). Thus, the committee recommends that health care professionals and organizations should identify opportunities to include patients and their fa milies in efforts to improve the diagnostic process by learning from diagnostic errors and near misses. Some of the opportunities for learning include participation in root cause anal yses and M&M et al., 2014; NPSF, 2015b).4 For example, patients and family members may have information that is unav ailable to health care pr ofessionals that can be used during a root cause analysis to identify contributors to a di agnostic error (Etchegaray et al., 2014). Participation in these events may also be satisfying to patients and their families, because they have an opportunity to help improve sa fety and reduce the chan ce of future errors (Zimmerman and Amori, 2007). However, it is impor tant for health care organizations to tailor patient and family involvement according to indivi dual needs and preferences and to be aware of the legal constraints to involving patien ts and families in these efforts. Health care organizations can also create pa tient and family advisory councils and use their input to design more patient-centered diagnostic processes. Patient and family advisory councils may be involved in the development, implementation, or evaluation of new programs, the design of materials or tools to improve pati ent-clinician relationships, and other activities (AHRQ, 2014b). These councils can involve patients and families in the design of care and can leverage their experiences in order to implem ent patient-centered changes, including changes that may reduce diagnostic errors (Coulter et al., 2008; IOM, 2013a ). For example, a patient and family advisory council at Inova Health System played a role in de signing a shift-change procedure for nursing staff that could reduce the pot ential for errors related to care transitions (Friesen et al., 2013). HEALTH CARE PROFESSIONAL EDUCATION AND TRAINING There are indications that heal th care professionals may not receive adequate preparation to function optimally in the diagnostic 2013). Education and training-related challenges include methods that have not kept pace with advances in the learning sciences5 and an insufficient focus on areas critical to the di agnostic process, such as clinical reasoning, 4 Root cause analysis is a problem-solving method that atte mpts to identify the factors that contributed to an error. Morbidity and mortality conferences are forums that allow clinicians to discuss and learn from errors that have occurred within an organization. 5 The learning sciences study how people lear n in order to optimize education and training. DIAGNOSTIC TEAM MEMBERS & TASKS 4-27 PREPUBLICATION COPY: UNCORRECTED PROOFS teamwork, communication, and the use of diagnostic testing and health IT. Because there is limited research on how education and training ca n affect diagnosis, the committee drew from a broader literature that included research on the impact of educati on and training in other areas of health care, in other industries, as well as submitted expert input to the committee. Education and training across the career trajectory plays an im portant role in improving the diagnostic process and reducing diagnostic errors and near misses. Th is section describes th e challenges to health care professional education and training and presents the committee's recommendation. Though the focus is on leveraging changes in educati on and training to improve diagnosis, recommended actions could also have broader im pact on clinical practice. For ex ample, ensuring that clinicians have clinical reasoning skills may also improve clin icians' abilities to treat and manage patients' health problems. Although this section's empha sis is on diagnosticians , the challenges and solutions are relevant to many health care professiona ls who participate in th e diagnostic process. Educational Approaches The learning sciences are an interdisciplinary field that studies learning methods and principles in an effort to unde rstand how to optimize learning (Torre et al., 2006). The findings from this field\u2014including the importance of developing deep concep tual understandings, participative learning, building on prior knowledg e, the use of reflection, and appropriate learning environments\u2014are relevant to health ca re professional educa tion and training (see Box 4-7) (Sawyer, 2006). For example, students often gain deeper knowledge when their learning involves activities that mimic thos e of professionals engaged in th e relevant discipline, a learning style that has been described as \"authentic pr actice\" (Sawyer, 2008). The learning sciences have also found that some learning styles are better su ited for some individuals than others (Dunn et al., 2002; Lujan and DiCarlo, 2006). BOX 4-7 The Learning Sciences The following are important aspects of learning, identified by the learning sciences, for individuals engaged in knowledge work\u2014i.e., professions that rely on using, manipulating, and generating knowledge. 1. Developing deeper conceptual understanding Students can apply learned material more broadly and across contexts if they have developed a deep conceptual understanding of the material. A deeper understanding requires learners to: (1) relate novel ideas to previous knowledge, (2) integrate knowledge into conceptual systems, (3) seek out patterns and connecting principles, (4) consider new ideas critically, (5) understand the structure of arguments and the process through which knowledge is generated, and (6) reflect on how they learn and what they understand. 2. Focusing on learning Students learn in different ways and these differences need to be considered as educational programs are designed and implemented. Programs that include participatory learning may benefit students and should be considered. 3. Creating learning environments Specifically designed learning environments can positively impact the learning process. 4-28 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS 4. Building on prior knowledge Learning processes that move from concrete to abstract facts facilitate the knowledge integration and retention necessary to develop deep conceptual understandings. 5. Reflecting on one's knowledge Taking time to reflect on one's state of knowledge enhances the learning process. SOURCE: Sawyer, 2006. Health care professional education progr ams may not be adequately informed by advances in the learning scienc es (Cooke et al., 2010; Rolf e and Sanson-Fisher, 2002). For example, programs may continue to emphasize me morization without help ing students develop the deeper conceptual understa ndings that are needed to apply knowledge in novel, practice- based situations (Myers, 2013). This may result in them having difficulty diagnosing conditions in non-standard contexts, such as cases involving atypical presentations or comorbidities. Educational experts have asserted that there is a tendency to focus lear ning on prototypical and representational cases of disease, rather than on real-life presentati ons (AHRQ, 2010b; Papa, 2014a). While this may be appropriate for the earl y stages of learning, students need exposure to actual patient cases, including atyp ical cases, in order to be prepared to diagnose disease in practice (Dhaliwal, 2014). Programs that delay student interacti on with patients until the later stages of education also miss opportunities to pr ovide students with au thentic practice (Cate, 2014). Given the mismatch of training and practice environments, it may be challenging to provide students with authentic practice; for exam ple, a majority of graduate medical education (GME) training occurs in inpatient settings, ev en though many physicians will work in outpatient settings (ACGME, 2015; Cooke et al., 2010; IOM, 2014; Josiah Macy Jr. Foundation, 2011). Some health care professional education programs may not be providing learners adequate opportunities to achieve expertise in diagnosis. For example, educators may attempt to teach students to think like experienced clinicia ns even though they lack the experience and knowledge base necessary to function in this manner (Cate, 2014). Programs may also place insufficient emphasis on developing the skills an d methods required to pursue self-motivated, lifelong learning. Individuals who lack these sk ills may find it more difficult to develop diagnostic skills beyond the formal education setti ng, leading to challenges in remaining abreast of findings throughout a clinicia n's career (IOM, 2010, 2011a). The evaluation of students may need to be be tter aligned with best practices from the learning sciences. Some health care professiona l schools rely on training time as a means of evaluating student performance, but it has been suggested that competency-based evaluation (CBE), which evaluates students based on their co mpetency in certain areas, may be a better method because it is a better predic tor of future performance (Hol mboe et al., 2010). CBE is still in development, however, and there is some di sagreement about using it exclusively to assess learners' abilities. There is limited eviden ce connecting CBE to improvements in student learning, and it is difficult to a ssess certain characteristics, such as professionalism, through a competency-based approach (Jarvis-Selinger et al., 2012; Lurie, 2012 ; Morcke et al., 2013). A number of methods to assess competency have been proposed, in cluding written and computerized testing, performance appraisals, medical record reviews, and simulations; some methods may be better suited for assessing specific competencies than others (Kak et al., 2001). Psychometric testing methods such as multiple choice and vignette based exams have been used to evaluate clinicians' medical knowledge, thoug h they often do not capture key aspects of clinical reasoning that c ontribute to diagnostic e xpertise (see Chapter 2) (Holmboe and Durning, DIAGNOSTIC TEAM MEMBERS & TASKS 4-29 PREPUBLICATION COPY: UNCORRECTED PROOFS 2014). Given the importance of clinical reasoning to practice, there is now a growing movement to develop assessment methods that are better able to evaluate clinical reasoning competencies (ABIM, 2014; Holmboe and Durning, 2014). For ex ample, the American Board of Internal Medicine's Assessment 2020 Initiative is focused on improving cognitive assessment in internal medicine. It is evaluating the ro le of computer-based clinical simulations, in which a simulated patient's condition changes as clinicians make decisions in the diagnostic and treatment processes (ABIM, 2015). Oral exams, such as ch art stimulated recall and case-based discussions, as well as audio and video review s of actual clinical encounters have also been suggested as assessment methods for clinical reasoning (Holmboe and Durning, 2014). Simulation exercises have been used to assess teamwork skills a nd communication competencies (Scalese et al., 2008). Experts who provided input to the committee focused on the us e of feedback to improve diagnostic performance and promote self-refl ection (Schiff, 2014a; Singh, 2014; Trowbridge, 2014). Feedback is an integral pa rt of continuous learning and can help health care professionals understand how well they are perf orming (Croskerry, 2000b). However, there are indications that current educational settings are not providing sufficient opportuni ties for learners to receive timely feedback, and students often perceive that they receive inadequate feedback (Hekelman et al., 1993; Milan et al., 2011; Nutter, 2001). Insuffici ent time for feedback, te acher reluctance to provide feedback, a lack of c ontinuity in the learner-teacher relationship, and a lack of observation time necessary for feedback may all contribute to an inadequate focus on providing feedback (Bernard et al., 2011; Schiff, 2008). A recent IOM report concluded that continui ng education is also disconnected from theories of how adults learn and from the deliv ery of patient care (IOM, 2010). Many continuing education requirements and evaluations focus on achieving credit hours instead of on educational outcomes and competencies (IOM, 2009). The result is a continuing education system that does not meet the needs of health care professionals in practice; for example, didactic activities such as lectures are large components of continui ng education, even though participatory learning opportunities may be more approp riate (Hager et al., 2008). In light of these findings, the committee concluded that health care professional education and training needs to better refl ect findings from the learning sciences. Thus, the committee recommends that educators should en sure that curricula and training programs across the career trajectory employ educational approaches that are aligned with evidence from the learning sciences. Given the heterogeneity of learners and the variety of educational objectives, it is important that educational programs consider the spectrum of learning sciences approaches when developing curricula and tr aining opportunities. Although it is beyond the committee's charge to recommend specific change s that should be made in health care professional education, the committee identified a number of opportunitie s for educators to consider. For example, programs may need to ac commodate different learning styles, to include mechanisms to provide immediate feedback to le arners (both positive and negative), to use CBE to assess performance, to increase the time allotted for clinical experien ce and patient interaction, and to place a larger emphasis on self-directed learning (Cooke et al., 2010; Hirsh et al., 2014; McLaughlin et al., 2014; Trowbridge, 2014). It may also be n ecessary to develop more effective forms of instruction and instructional medi a (Mayer, 2010), including the use of simulation- based exercises (McGaghie et al., 2011; Patel et al., 2009a). Employing deliberate practice approaches that focus on \"frequent practice, rapi d feedback to understand and correct errors, and raising bars with new attempts\" may also be helpful (Cate, 2014; Durning, 2014). Changes to 4-30 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS could include replacing bloc k rotations with longitudinal integrated clerkships in order to improve relationship building sk ills, both interprofessionally and among patients and clinicians (Cate, 2014; Teherani et al., 2013; Thibault, 2013). In addition, the IOM report The Future of Nursing: Le ading Change, Advancing Health recommended the development and implementation of nursing reside ncy programs to facilitate nursing graduates' transition to practice and to ensu re that nurses develop the knowle dge and skills to deliver safe, high-quality care (IOM, 2011a). This report also emphasized the importance of developing an expectation for lifelong learning. A number of academic institutions have implemented changes in their health professional programs, including a major shift toward incorporating more authentic practice. For example, most medical schools have introduced clinical practice experience mu ch earlier in their curriculum, rather than delaying this experien ce until after students have completed the basic sciences training. Programs are also experiment ing with innovative ways to help students develop a deeper conceptual understanding of human biology and disease, including an increased emphasis on individualized learni ng, self-teaching and a ssessment, and an exposure to more and varied cases of disease (OHSU, 2014). Northwestern University's Feinberg School of Medicine is adopting CBE, removing time requirements fo r degree completion, and moving from lecture- based instruction to small group and practice- based learning (Feinberg School of Medicine, 2015). There is a growing recognition of the need to better align training and practice environments. For example, the Health Resources and Services Administration's Teaching Health Center Graduate Me dical Education program is providing more opportunities for authentic practice by funding community-based primary care residency programs (HRSA, 2015). The IOM report Graduate Medical Education that Meets the Nation's Health Needs concluded that the Medicare GME payment system discourag es physician training outside of the hospital setting and may not provide graduates the skills necessary for office-based practice, even though most are likely to practice in community settings (IOM, 2014). In addition, The Future of Nursing report highlighted the need to develop nursing expertise ou tside of hospital-based care settings. Because of the aging of the population and the shift from hospital-based to community-based care settings, there is a greater \"need for nursing expertis e in chronic illness management, care of older adults in home settings, and transitional services \" (IOM, 2011a, p. 121). Though many programs are beginning to initiate changes that better align with current knowledge about health care professional education, a larger focus on aligning education with the learning sciences is warra nted across the career trajectory. This includes a focus on continuing education to ensure that individua ls maintain and continue to develop the competencies necessary for the diagnostic pro cess. Models of continuing education that are competency based or that focus on quality im provement have been proposed and may improve the effectiveness of continuing education (Cam pbell et al., 2010; Shojania et al., 2012). The Diagnostic Process Improving the content of health care prof essional education can improve diagnostic performance and reduce the potential for diagnostic errors and near misses. Thus, the committee recommends that educators should ensure that cu rricula and training programs across the career trajectory address performan ce in the d iagnostic process. The committee identified a number of areas of performa nce that could be improved. These are DIAGNOSTIC TEAM MEMBERS & TASKS 4-31 PREPUBLICATION COPY: UNCORRECTED PROOFS Clinical reasoning Teamwork Communication with patients, thei r families, and other health care professionals Appropriate use of diagnostic tests a nd the application of these results on subsequent decision-making Use of health IT Clinical Reasoning Clinical reasoning, including di agnostic decision-making, is underemphasized in current health care professional education and training (Cate, 2014; Gr aber et al., 2012; IOM, 2011a; Richardson, 2014; Stark and Fins, 20 14; Trowbridge et al., 2013). Th is lack of focus on clinical reasoning and on the development of critical thinking skills thr oughout the education process is a contributor to diagnostic e rror (Brush, 2014; Cate, 2014; Du rning, 2014; Richardson, 2007). A recent study found that a majority of the academic difficulties that medical students face \"are of a cognitive nature and include difficulties in clin ical reasoning\" (Aud\u00e9tat et al., 2012, p. 217). Poor performance in clinical reasoni ng is generally discovered during later stages of training, which makes remediation more difficult (Aud\u00e9tat et al., 2012; Hauer et al., 2007). In recognition of the importance of clinical reasoning in health car e professional educati on, the Medical College Aptitude Test (MCAT) recently a dded a critical analysis and r easoning skills section (AAMC, 2015a). As discussed in Chapter 2, health care prof essionals have an ethical responsibility to improve clinical reasonin g skills in order to improve diagnos tic performance and avert diagnostic errors (Stark and Fins, 2014). Thus, educators need to ensure that students receive education and training opportunities that deve lop these skills\u2014both \"fast\" system 1 processes and 2014; Cate , 2014; Durning, 2014; Richardson, 2014). The development of clinical reasoning includes critic al thinking skills such as analysis, evidence evaluation, and interpreta tion (Papp et al., 2014). Opportunities to improve clinical reasoning include instruction and practice on how to develop and refine a differential diagnosis and a focus on developing probabilistic reason ing skills (see Chapter 2) a nd also an understanding of likelihood ratios (Brush, 2014).6 Students also need feedback a nd training in self-assessment and cognitive reflection in order to identify mistakes in their clinical reasoni ng and to assess their diagnostic performance. Without this, they may have trouble with calibration, or the development of an accurate sense of one's diagno stic abilities. Poor cal ibration contributes to clinician diagnostic errors (Berner a nd Graber, 2008; Croskerry and Norman, 2008; Yang et al., 2012; Meyer et al., 2013). The success of diagnostic reas oning often depends on one's knowledge base of disease and the accompanying illness scripts7 (Cate, 2014; Durning, 2014; Norman et al, 2014). Students need this wide knowledge base, especially to de velop \"fast\" system 1 processes that rely on 6 The prior probability of a diagnosis is the probability assigned before new information regarding the patient is used to \"update\" the probability in order to arrive at the po sterior probability. \"A likelihood ratio is defined as the percentage of diseased patients with a given test result divi ded by the percentage of well people with that same test result\" (Brush, 2014). 7 Illness scripts are mental models that include information about a disease, including potential causes of the disease, the pathophysiological process, and signs and symptoms of the disease (Boshuizen and Schmidt, 2008). 4-32 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS pattern recognition. However, ther e are concerns that the expos ure that students receive to disease cases, actual or simulated, is inadequate to develop effective diagnostic decision making based on pattern recognition (Cate, 2014; Dhaliwal, 2014; Eva, 2005; Norman et al, 2014; Trowbridge et al., 2013). Early clinical experience , either through simulations or with patients, as well as an exposure to a variety of cases, in cluding atypical cases, can help develop this knowledge base (Cate, 2014; Papa, 2014b; Richardson, 2014). Equally important, students need to unde rstand and become co mfortable with the uncertainty that is inherent in the diagnostic process (Durning, 2014; Kassirer, 1989). Developing a better sense of and comfort with uncertainty may help clinicians avoid diagnostic errors related to premature closure as well as inappropriate use of di agnostic testing. Improved understanding of diagnostic uncertainty can help clinicians make decisions about whether further diagnostic testing or treatment is warranted. This could also facilitate improved collaboration with other health care professionals and better communication with patients and their families about the nature of a working diagnosis. Students also need exposure to easy-to-miss diagnoses and common causes of diagnostic error (Graber et al., 2012). This includes a focus on the work syst em factors that can contribute to diagnostic errors, such as communication an d collaboration challenge s among diagnostic team members; health IT tools that are not supporti ve of clinical reasoni ng activities; cultural, organizational, and physical environmental factor s; and the impact of re porting, medical liability, and payment. In addition, there also needs to be a focus on heuristics (mental shortcuts) and biases, which play a role in clinical reasoning and presen t a major challenge to diagnosis (see Chapter 2) (Croskerry, 2003a, 2009, 2014; Eva and Norm an, 2005; Kahneman, 2011; Klein, 1993). Education and training that focuses on the cogni tive heuristics and biases that can affect diagnosis and on how to counteract their effects are particularly important. Debiasing strategies, such as engaging in metacognition (i.e., critical ly thinking about one's thinking, reasoning, and decision making) have been proposed as a means to address the negative effect that heuristics can have on decision making. A nu mber of debiasing strategies have been proposed, including considering the opposite, debiasi ng through awareness of bias, becoming aware of what one does not know, and others (Hirt and Markman, 1995; Hodges et al., 1995; Mussweiler et al., 2000; Redelmei er, 2005). There is some debate about the effectiveness and feasibility of debiasing strate gies (Cate, 2014; Norman et al, 2014); for example, monitoring every decision to ensure that no bias has occurr ed would be inefficient since heuristics work most of the time. However, because heuristics te nd to fail in predictable ways, it is possible to determine the types of situations in which so me heuristics are likely to lead to error. For example, heuristic failure is likely to o ccur in the emergency medicine setting, given that this environment is highly complex, inconsta nt, and uncertain, and that emergency clinicians often work under time constraints that force them to rely heavily on heuristics (Croskerry, 2000a, 2002a). Given the susceptibility of this environm ent to heuristics failu re, several proposed solutions focus on the use of debiasing strate gies in emergency medicine (Croskerry, 2000a, 2002; Pines, 2006). Additional strategi es to reduce errors related to heuristics and biases include a greater focus on the development of expertise, of fering clinicians mo re realistic training settings, providing decision suppor t tools, and ensuring that th e work system in which the diagnostic process occurs better supports deci sion making (see Chapter 6) (Eva and Norman, 2005; Gigerenzer, 2000; Gigerenz 2012; Wegwarth et al., 2009; Weed and Weed, 2014). B ecause there is uncertainty regarding which DIAGNOSTIC TEAM MEMBERS & TASKS 4-33 PREPUBLICATION COPY: UNCORRECTED PROOFS strategies are best at reducing th e impact of bias on diagnostic d ecision-making, it is an area that needs further research (C roskerry et al., 2013a, 2013b). Several medical programs have begun offering clinical reasoning c ourses. For example, Dalhousie University offers a critical thinki ng course for medical students that teaches how decision making occurs, discusses cognitive biases and potential debiasing strategies, and provides students with tools for improved sel f-assessment and critical thinking development (Dalhousie University, 2015). Dalhous ie also offers an online faculty development course to improve the education and training that medical students receive. Developing clinical reasoning sk ills is important for practicing health care professionals who are beyond formal education and training settings. Continuing health care professional education can be leveraged to de velop clinical reasoning skills as a lifelong competency. There are several continuing education opportunities available that fo cus on clinical reasoning and diagnosis, but a greater focus on them is needed (Cruz et al., 2009). Teamwork and Communication Despite widespread attention to the impor tance of teamwork skills, health care professionals are not adequately prepared to employ these skills in practice (IOM, 2014; Patel et al., 2009a; Pecukonis et al., 2008; Schmitt et al., 2011). The focus in this report on improving education and training in teamwork skills build s upon earlier IOM work. For example, the study on continuing education concluded that professional de velopment activities should ensure that health care professionals are prof icient in the collaborative skills required for team-based care (IOM, 2010), and another study high lighted the need for transfor ming nursing education in order to prepare nurses to engage other health care professionals in a collaborative manner (IOM, 2011a). In addition, the IOM recen tly highlighted the importance of evaluating interprofessional education approaches, and made recommendations on generating evidence to better identify successful interprofessional educ ation practices (IOM, 2015). Several leading organizati ons have concluded that in terprofessional and teamwork training opportunities have been slow to materialize (Josiah M acy Jr. Foundation and Carnegie Foundation for the Advancement of Teaching, 2 010). Barriers to teamwork and team-based education include \"logistical challenges inherent in coor dinating between two or more autonomous health professions schools, deep-root ed cultural differences between the health professions, differences in the educational cu rricula and pathways of the various health professions, and issues around pr ogram sustainability and funding\" (Josiah Macy Jr. Foundation and Carnegie Foundation for the Advancement of Teaching, 2010, p. 3). Academic institutions and training program s are beginning to offer more opportunities for health care professionals to improve thei r teamwork skills. As of 2012, 76 percent of medicals schools required students to participat e in interprofessional education (AAMC, 2015b). The goals of the interprofessiona l education programs varied, but most aimed to familiarize students with the roles of other health care prof essionals (89 percent) and to teach students teamwork skills (76 percent) (AAMC, 2015b). Edu cational settings also varied, with schools offering training in classroom programs (77 per cent), simulation center programs (60 percent), and clinical practice settings (44 percent) (AAMC, 2015b). For example, the University of Virginia's Center for Academic and Strategic Pa rtnerships for Interprofessional Research and Education offers workshops and clinical programs to improve teamwork skills and provides workshops for clinician-educators. Other progra ms offer courses taught jointly with students 4-34 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS from both nursing and medical schools, provide inte rdisciplinary team-based training for the care of individuals with advanced il lness, and use interactive inte rdisciplinary Web-based learning modules (Josiah Macy Jr. Foundation and Ca rnegie Foundation for the Advancement of Teaching, 2010). Academic centers have also been implementing simulation-based team training opportunities, which have shown promise in improving team performance and in the development of teamwork sk ills (Patel et al., 2009b). Although these efforts are encouraging, the committee concluded that a much greater empha sis on developing teamwork skills is needed. Rather than each program developing its own curriculum on an ad hoc basis, health care professional educators could co llaborate in the developmen t of curricula and training opportunities in teamwork. An important teamwork skill in diagnosis is communication with patients, their families, and other health care professionals. Communication failures between health care professionals are recognized as a leading cause of patient ha rm and error, while poo r communication between clinicians and patients is recognized as a ba rrier to accurate and timely diagnoses (AHRQ, 2008a; IHC, 2011). Although interpersonal communica tion skills are listed as a competency by the Accreditation Council for Graduate Medi cal Education (ACGME) and most medical specialty boards recognize communication as a co re competency for practice, these skills may not be taught to students in a focused and sta ndardized manner (Rider and Keefer, 2006). Health care professionals need to receive training in in terpersonal communication skills to ensure that they can function effectively in teamwork sett ings. For example, one study found that students receiving communication training exhibited impr oved communication skills, such as relationship building and shared decision-making (Yedidia et al., 2003). Effective communication training programs tend to last at least a day, to involve fe edback, and to include role play and small group discussions (Berkhof et al., 2011). Tools to improve commu nication among health care professionals, such as the Situation-Bac kground-Assessment-Recommendation Tool, help clinicians convey the most important informa tion in an organized manner (Haig et al., 2006; Leonard et al., 2004) (see Box 4-8). Health care professionals also need training in how to communicate openly and effectively with patients and their families. This training may include an emphasis on basic communication skills and also on topics such as communication with patients who are perceived as difficult, culturally and lingui stically appropriate communication, interviewing techniques, history-taking skills, and de livering difficult diagnoses (Smith and Longo, 2012; AHRQ, 2015b). Other relevant strategies that could receive more attention include the teach-back method described in the patient engagement section of th is chapter, encouraging questions from patients, and responding to patient emotions. In recognition of the importance of patient-clinician communication, a number of schools have implemented curricula designed to improve this communication (Georgetown University, 2015; University of Pittsburgh, 2015). BOX 4-8 Situation-Background-Assessment-Recommendation Tool to Improve Communication Among Health Care Professionals Before you call, be prepared! Be clear, concise, focus on the problem & only report what is relevant to the current situation! Be sure you do the following: DIAGNOSTIC TEAM MEMBERS & TASKS 4-35 PREPUBLICATION COPY: UNCORRECTED PROOFS Assess the patient. Determine the appropriate person to call. Have the medical record available when you call. Review appropriate parts of the medical record (e.g., flow sheet, medication administration record, clinic ian notes/orders, labs). Use the following form to organize your conversation. Situation: 5-10 second \"punch line\" - What is happening now? What are the chief complaints or acute changes? This is __________. I'm calling about ______________________________________________ Background: What factors led up to this event? Pertinent history (e.g., admitting diagnosis) & objective data (e.g., vital signs, labs) that support how patient got here. The patient has ________________________________________________________________ Assessment: What do you see? What do you think is going on? A diagnosis is not necessary; include the severity of the problem. I think the problem is ___________________________________________________________ Recommendation: What action do you propose? State what the patient needs (get a time frame). I request that you ______________________________________________________________ SOURCE: Adapted from AHRQ, 2008a. Outside of formal education settings, hea lth care organizations can play a role in improving teamwork performance through team-based training practices (Salas et al., 2008). For example, a recent literature review found \"modera te-to-high-quality evidence suggest[ing] team- training can positively impact healthcare team pro cesses and, in turn, clinical processes and patient outcomes\" (Weaver et al., 2014, p. 369). A training program designed by the Department of Defense and the Agency for Healthcare Resear ch and Quality (AHRQ), Team Strategies and Tools to Enhance Performance and Patient Safe ty (TeamSTEPPS), has been used to improve teamwork in health care environments by incr easing team awareness, clarifying roles and responsibilities, improving inform ation sharing, and building effici ent teams that optimize people and information to provide high quality care (AHRQ, 2015a; Straus et al., 2014). The system is at various stages of implementation in numerous facilities throughout the M ilitary Health System (King et al., 2008). In recent ye ars, AHRQ has launched a nati onwide implementation program that trains master trainers to work with heal th care organizations interested in implementing TeamSTEPPS. Diagnostic Testing Diagnostic testing has become an integral component of the diagnostic process, yet medical school curricula have not kept pace with the advances in diagnostic testing and with how these advances affect diagnosis (Hallworth, 2011 ; Laposata and Dighe, 2007; Smith et al., 2010). A 2009 report from the Centers for Diseas e Control and Prevention on laboratory medicine noted that there is inadequate atte ntion and emphasis on laboratory testing in the medical school curriculum, even though it plays a central role in medical practice (CDC, 2009). 4-36 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Another survey detailed the lack of emphasis on laboratory medicine within medical training programs: Although approximately 78 percent of medical schools require coursework in laboratory medicine, the median time dedicated to this topic is 12.5 hours, not including exposure to laboratory medicine gained through clini cal rotations. However, training during clinical rotations is problematic because it is not standardized and may rely on clinician- educators who do not have an adequate backgro und in laboratory medicine (Smith et al., 2010). Many of the processes within laboratory medicine\u2014such as ordering the correct tests, understanding test performance char acteristics (sensitivity and specificity), a nd interpreting tests results and, subsequently, making decisions\u2014ca nnot be addressed using the teaching methods that many programs employ (Wilson, 2010). The shortcomings in laboratory medicine e ducation are well recognized by clinicians. According to several surveys, clinicians and stud ents report feeling uncer tain about which tests to order because of naming conventions, unfamiliar ity with the available tests, and the rapid development of new diagnostic tests (Hickner et al., 2014; Laposata a nd Dighe, 2007). One of the largest sources of error in the test-ordering phase is health care prof essionals requesting an incorrect test (Laposata and Di ghe, 2007). Clinicians order labor atory tests in 31.4 percent of primary care visits, however, they report uncertainty when orderi ng tests 14.7 per cent of the time and confusion about interpreting results in 8.3 percent of the cases where they ordered tests (Hickner et al., 2014). There is al so uncertainty among clinicians about applying test results to subsequent decision making, such as refining or expanding a diffe rential diagnosis, determining the likelihood that a patient has a specific diagno sis on the basis of a positive or negative test result, deciding whether retesti ng or ordering new tests is appr opriate, and beginning appropriate treatment. There are indications that students an d practicing clinicians struggle with concepts like sensitivity and specificity and lack an unde rstanding of how disease prevalence contributes to making decisions about a patient's diagnos is (Kroenke, 2013; Manrai et al., 2014; Ross, 2014). In a small survey of health care professi onals, three-quarters of respondents failed to correctly calculate the positive predictive value of a test result for a specific disorder (Manrai et al., 2014). Similar surveys completed several decades ago found that many health care professionals had trouble applying statistical methods and unders tanding statisti cal concepts, suggesting that this may be a l ongstanding gap in health care professional edu cation (Casscells et al., 1978; Berwick et al., 1981).Anot her study found that medical st udents are generally able to describe Bayes theorem but are subsequently unab le to apply this theore m to clinical practice (Bergus et al., 2004). These educational gaps negatively affect a clinician's ability to appropriately assign and update diagnostic probabilities in light of test findings. In addition, there are concer ns about an inadequate focus on anatomic pathology in medical education (Magid and Cambor, 2012). While aspects of anatomic pathology are covered in the medical school curriculum, the amount has decreased significantly over the years, particularly as medical schools ha ve adopted integrated curricula (Talbert et al., 2009; Taylor et al., 2008). An inadequate understanding of anatom ic pathology m ay negatively affect clinical decision making and the diagnostic process. Fo r example, inadequate understanding of the mechanisms underlying inflammation might affect the ability to recognize diseases or disease processes and the selection of appropriate treatment to address inflammation. In addition, students may not understand the limitations of cert ain anatomic pathology tests (e.g., the limited sensitivity of Pap smears) and how to collect, prepare, and transport specimens (Magid and Cambor, 2011). DIAGNOSTIC TEAM MEMBERS & TASKS 4-37 PREPUBLICATION COPY: UNCORRECTED PROOFS The use of medical imaging as a diagnostic tool has also increased substantially, and for many symptoms, medical imaging has become an integral part of the diagnostic process. Although many clinicians request medical imaging fo r their patients, the ordering of this imaging and the application of medical imaging interpretations to subs equent decision making are not emphasized in the medical school curriculum and subsequent traini ng (Kondo and Swerdlow, 2013; Rubin and Blackham, 2015). Errors in imagi ng can occur during all phases of the process, from the ordering and selection of medical im aging to the interpretation of results and subsequent decision making. The majority of al lopathic and osteopathic medical schools do not have a focused course on medical imaging, and me dical imaging rotations are required in only 29 percent of medical sc hools (Rubin and Blackham, 2015). Typi cally, for most medical students medical imaging instruction is integrated into other coursework or clini cal rotations in a very limited fashion (Kondo and Swerdlow, 2013; R ubin and Blackham, 2015). The teaching of important concepts in medical imaging, such as the scientific principles of imaging techniques, radiation safety, modality differences, and the us e of contrast materials, is limited (Rubin and Blackham, 2015). A recent survey of fourth-year medical school st udents noted that the majority of students underestimated the risks associated with medical imaging techniques and were not informed about the American College of Radiology Appropriateness Criteria (Prezzia et al., 2013; Rubin and Blackham, 2015). Ma ny medical schools do not follow the radiology-dedicated curriculum designed by the Alliance of Medical School Educators in Radiology (Rubin and Blackham, 2015). Thus, health care professionals need improve d education and training on the appropriate use of diagnostic tests and the application of these results to subsequent decision making. The committee recognizes that, given the growing number and complexity of the options available, it is not feasible to expect that clinicians will be familiarized with every available diagnostic test procedure. Therefore, in addition to impr oved education in diagnostic testing, improved collaboration among treating clinicians and pathol ogists and radiologists is warranted. Education and training focused on how to most effec tively convey findings from pathologists and radiologists to treating clinicians may alleviate some of the ch allenges clinicians face with respect to understanding results and subsequent decision making. Health Information Technology Health IT is an important co mponent of the diagnostic pro cess, including the involvement of EHRs, laboratory and medical imaging information systems, and decision support tools (see Chapter 5). As health IT becomes increasingly integrated into all aspects of health care, clinicians will likely rely mo re on it to facilitate diagnostic decision making and communication and collaboration among health care professionals and patients (Thibault, 2013). Thus, clinicians need to develop competencies in the use of health IT tools; however, many health care professionals do not receive adequate education a nd training in the use of health IT (Graber et al., 2012; McGowan et al., 2007). Individuals who l ack competencies in health IT use will be unable to take advantage of thes e opportunities to improve diagnos is and reduce diagnostic error. Training health care professionals to work with health IT has been found to be a major challenge (NIST, 2010). In an effort to address this, th e Office of the National Coordinator has been working with licensing bodies and me dical societies to better integr ate health IT into the medical education curriculum (Buntin et al., 2010). The Patient Protection and Affordable Care Act includes provisions to incorporate he alth IT training into the education of primary care clinicians 4-38 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS (Buntin et al., 2010). The IOM report Health IT and Patient Safety also emphasized the importance of improving workforce education an d training on safe health IT use, using mechanisms such as formal education and pos tgraduate training as well as health care organization-facilitate d training (IOM, 2012d). Ensuring Competency in the Diagnostic Process In addition to improving the content and t eaching methods for health care professional education and training, oversight processes can help ensure that individuals achieve and maintain competency in the diagnostic process, incl uding clinical reasoning, teamwork, communication, and the use of diagnostic testing and health IT . Health care professiona l oversight processes include education and training program accreditation, licensure, and certification. These oversight processes act as levers to induce ch ange in the health care system: \"Educational accreditation serves as a leverage point for the in clusion of particular educational content in a curriculum. Licensure assesses that a student has understood and mastered formal curricula. Certification ensures that a practitioner main tains competence in a given area over time\" (IOM, 2003a, p. 5). The committee received input suggesting that accreditation, licensure, and certification processes can be intr oduced to help ensure that health care professionals possess diagnostic competencies thr oughout the career trajectory (Brush, 2014; Papa, 2014a, 2014b). Organizations that accredit hea lth care professional education and training programs (see Box 4-9) can use their accredita tion requirements as a mechanism to ensure that these programs include appropriate curricular c ontent to prepare students in the areas of the diagnostic process that the committee has articulated. Accreditation organizations for all levels of health care professional education and trai ning\u2014i.e., undergraduate, gradua te, and continuing education\u2014 need to address diagnostic competencies. Many a ccreditation organizations already include skills important for diagnostic performance in their ac creditation requirements, but these organizations can make competencies in the diagnostic process a larger priority within their requirements. For example, the IOM report The Future of Nursing: Le ading Change, Advancing Health recommended that the \"Commission on Collegiate Nursing Education [CCNE] and the National League for Nursing Accrediting Commission [NLN AC] should require that all nursing students demonstrate a comprehensive set of clinical performance competencies that encompass the knowledge and skills needed to provide care acro ss settings and the lifespan\" (IOM, 2011a, p. 282). Building on this recommendation, the CCNE a nd NLNAC could require nursing schools to offer interprofessional collaboration education an d training opportunities focused specifically on the diagnostic process and the role of team s in achieving diagnostic accuracy. The Liaison Committee on Medical Education (LCME) and the ACGME include diagnostic competencies in accreditation requirements. For example, the LCME requires medical education programs to prepare students to \"recognize and interpret sy mptoms and signs of disease\" and \"develop differential diagnoses and treatment plan s\" (LCME, 2015, p. 10). The ACGME and the American Board of Medical Specialties (ABMS) ha ve identified six core competencies that all physicians should acquire during residency a nd fellowship programs and should maintain throughout practice (see Box 4-10) (ACGME, 2015). The ACGME is beginning to use milestones to evaluate performance on these comp etencies; several of these competencies are applicable to those the committee articulated (Nasca et al., 2012). For example, the ACGME requires that participating pr ograms provide their students wi th opportunities to develop the skills necessary for lifelong, self-m otivated learning; communicati on with patients, families, and DIAGNOSTIC TEAM MEMBERS & TASKS 4-39 PREPUBLICATION COPY: UNCORRECTED PROOFS other health care professionals; and a systems understanding of health care, including the importance of coordination and interprofessiona l and intra-professiona l teamwork (ACGME, 2015). BOX 4-10 Six Core Competencies Developed by the American Board of Medical Specialties and the Accreditation Council for Graduate Medical Education 1. Practice-Based Learning and Improvement: Show an ability to investigate and evaluate patient care practices, appraise and assimilate scientific evidence, and improve the practice of medicine. 2. Patient Care and Procedural Skills: Provide care that is compassionate, appropriate, and effective treatment for health problems and to promote health. BOX 4-9 Examples of Accreditation Organizations for Health Care Professional Education and Training Programs Liaison Committee on Medical Education, which is sponsored by the American Medical Association and the Association of American Medical Colleges, accredits medical education programs. For accreditation, programs must demonstrate that their graduates achieve the competencies necessary for subsequent training and for ensuring continuous learning and proficient practice (LCME, 2015). American Osteopathic Association's (AOA) Commission on Osteopathic College Accreditation accredits osteopathic medical schools, and the AOA Council on Continuing Medical Education accredits continuing medical education activities (AOA, 2015). American Association of Colleges of Nursing's Commission on Collegiate Nursing Education accredits baccalaureate, graduate, and residency nursing programs (AACN, 2015). Accreditation Commission for Education in Nursing uses a core of standards to evaluate and accredit nursing education programs (ACEN, 2013). Accreditation Review Commission on Education for the Physician Assistant accredits physician assistant education programs (ARC-PA, 2015). Accreditation Council for Graduate Medical Education accredits graduate medical education programs (i.e., residency and fellowship programs) for physicians. Student performance on milestones or time-based competencies are used to assess graduate medical education programs (ACGME, 2015). Accreditation Council for Continuing Medical Education evaluates and accredits institutions and organizations offering continuing medical education for physicians and other health care professionals (ACCME, 2015). 4-40 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS 3. Systems-Based Practice: Demonstrate awareness of and responsibility to the larger context and systems of health care. Be able to call on system resources to provide optimal care (e.g., coordinating care across sites or serving as the primary case manager when care involves multiple specialties, professions, or sites). 4. Medical Knowledge: Demonstrate knowledge about established and evolving biomedical, clinical, and cognate sciences and their application in patient care. 5. Interpersonal and Communication Skills: Demonstrate skills that result in effective information exchange and teaming with patients, their families, and professional associates (e.g., fostering a therapeutic relationship that is ethically sound, uses effective listening skills with nonverbal and verbal communication; working as both a team member and at times as a leader). 6. Professionalism: Demonstrate a commitment to carrying out professional responsibilities, adherence to ethical principles, and sensitivity to diverse patient populations. SOURCES: ABMS, 2015; ACGME, 2015. Organizations responsible for health care professional licensure and certification can help ensure that individual health ca re professionals have achieved and maintain competency in the skills essential for diagnosis. For example, the United States Medical Licensing Exam for physicians and the Uniform Licensure Require ments for practicing nurses could emphasize diagnostic competencies tailored to the scope of work of th ese professions (NCSBN, 2015). The ABMS, which grants board certif ication in more than 150 medical specialties and subspecialties, could ensure competencies in the diagnostic proc ess in both initial board certification and in the maintenance of certification efforts. For exampl e, some specialty boards have begun assessing clinical reasoning skills through cognitive knowledge testing that requires clinicians to evaluate clinical scenarios in a ddition to content knowledge (Graber et al., 2012). Initial certification of health care professionals is impor tant, but it may be insufficient to ensure sustained diagnostic competency throughout the career tr ajectory. Due to advances in the biomedical sciences, the knowledge required to maintain competency is rapi dly growing; at the same time health care professionals may also experien ce knowledge decay or the loss of previous ly learned knowledge (Cassel and Holmboe, 2008; IOM, 2013a; Su et al., 2000). Thus, many health care professional organizations, such as ABMS and the American Association of Physic ian Assistants, have developed renewal and maintenance of certif ication (MOC) programs (AAPA, 2015; ABMS, 2015). Though there has been controversy surrounding MOC, recent evidence suggests that it can improve performance (Iglehart and Bar on, 2012; O'Neill and Puffer, 2013; Teirstein, 2015). Meaningful and effective continui ng education is important for all clinicians, and MOC efforts can ensure that clinicians have the appropriate competencies in the diagnostic process throughout the career trajectory. Many health care organizations now require MOC as a precondition for renewing staff privileges. Other licensure and certification organizati ons, including those for other health care professions, can also emphasi ze competency in the diagnostic process. The committee concluded that oversight organizations, including accreditation organizations and professional licen sure and certification bodies, can play an important role in improving diagnostic performance. Thus, the committee recommends that health care professional certification and accreditation or ganizations should ensure that health care professionals have and maintain the competencies needed for effective performance in the diagnostic process, including Clinical reasoning DIAGNOSTIC TEAM MEMBERS & TASKS 4-41 PREPUBLICATION COPY: UNCORRECTED PROOFS Teamwork Communication with patients, thei r families, and other health care professionals Appropriate use of diagnostic tests a nd the application of these results on subsequent decision making Use of health IT RECOMMENDATIONS Goal 1: Facilitate more effective teamwork in the diagnostic proc ess among health care professionals, patients, and their families Recommendation 1a: In recognition that the di agnostic process is a dynamic team-based activity, health care organizations should ensure that health care professionals have the appropriate knowledge, skills, resources, a nd support to engage in teamwork in the diagnostic process. To accomplish this, they should facilitate and support: Interprofessional and intra-professional teamwork in the diagnostic process. Collaboration among pathologists, radiologi sts, other diagnosticians, and treating health care professionals to improv e diagnostic testing processes. Recommendation 1b: Health care professional s and organizations should partner with patients and their families as diagnostic te am members and facilitate patient and family engagement in the diagnostic process, aligned with their need s, values, and preferences. To accomplish this, they should: Provide patients with opportunities to learn about the diagnostic process. Create environments in which patients a nd their families are comfortable engaging in the diagnostic process and sharing fee dback and concerns about diagnostic errors and near misses. Ensure patient access to EHRs, including clinical notes and diagnostic testing results, to facilitate patient engagement in the diagnostic process and patient review of health records for accuracy. Identify opportunities to include patients a nd their families in efforts to improve the diagnostic process by learning from diagnostic errors and near misses. Goal 2: Enhance health care professional educ ation and training in the diagnostic process Recommendation 2a: Educators should ensure th at curricula and training programs across the career trajectory: Address performance in the diagnostic proc ess, including areas such as clinical reasoning, teamwork, communication with pa tients, their families, and other health care professionals, appropriate use of diagn ostic tests and the application of these results on subsequent decision making, and use of health IT. Employ educational approaches that are alig ned with evidence from the learning sciences. Recommendation 2b: Health care professional certification and accreditation organizations should ensure that health care professionals have and maintain the competencies needed for effective performance in the diagnostic process, including the areas listed above. 4-42 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS REFERENCES AACH (American Academy on Communication in Healthca re). 2015. American Acad emy on Communication in Healthcare. www.aac honline.org (accessed March 16, 2015). AACN (American Assocation of Colleges of Nursing). 2015. American Association of Colleges of Nursing. www.aacn.nche.edu/ (accessed May 10, 2015). AAMC (Assocation of American Medical Colleges). 2015a. About the MCAT exam. www.aamc.org/students/applying/mcat/about/ (accessed March 18, 2015). AAMC. 2015b. Curriculum inventory and reports: Interprofessional education. www .aamc.org/initiatives/cir/ (accessed March 18, 2015). AAPA (American Academy of Physician Assistants). 2015. American Academy of Physician Assistants. www.aapa.org/ (accessed March 12, 2015). ABMS (American Board of Medical Specialties). 2015. Based on core comp etencies. http://www.abms.org/board- certification/a-trusted-credenti al/based-on-core-competencie s/ (accessed July 24, 2015). ABIM (American Board of In ternal Medicine). 2014. ABIM announces initiative to seek input on physician knowledge and skill assessment approaches. http://w ww.abim.org/news/abim-initiative-seek-input-on- physician-knowledge- skill-assessment-appr oaches.aspx (accessed July 24, Assessment 2020: Feedback in action. http://assessment2020.abim .org/projects/ (accessed July 24, 2015). ACCME (Accreditation Council for Continuing Medical Edu cation). 2015. Accreditation Council for Continuing Medical Education. www.accme.org/ (accessed March 12, 2015). ACEN (Accreditation Commission for Education in Nurs ing). 2013. Accreditation Commission for Education in Nursing. www.acenursing .org/?refreshed (accessed June 5, 2015). ACGME (Accreditation Council for Graduate Medical Edu cation). 2015. Accreditation Council for Graduate Medical Education. www.acgme.org/ acgmeweb/ (accessed March 12, 2015). Adler-Milstein, J. 2015. America's health IT transformati on: Translating the promise of electronic health records into better care. Paper presented at U.S. Senate Committee on Health, Education, Labor and Pensions, March 17. Adler-Milstein, J., C. M. DesRoches, M. F. Furukawa, C. Worzala, D. Charles, P. Kralovec, S. Stalley, and A. K. Jha. 2014. More than half of U.S. hospitals have at least a basic EHR, but stage 2 criteria remain challenging for most. Health Affairs 33(9):1664-1671. AHRQ (Agency for Healthcare Research and Quality). 2008a. Improving patient safety through provider communication strategy enhancements . In K. Henriksen, J.B. Battles, M. A. Keyes, and M.L. Grady (eds.), Advances in patient safety: New directions and alternative approaches (Vol. 3: Performance and tools) (pp. 90-107). AHRQ publication no. 08-0034-3: Rockville, Quality. patient-safety-2/vol3/Advances-Dingl ey_14.pdf (accessed June 5, 2015) AHRQ. 2008b. Transforming the morbidity and mortality conference into an instrument for systemwide improvement. In K. Henriksen, J. B. Battle s, M. A. Keyes, and M. L. Grady (eds.), Advances in patient safety: New directions and approaches (Vol.2. Culture and redesign) (pp. 357-363). AHRQ Publication No. 08-0034-2: Research and Quality. www.ncbi.nlm.nih.gov /books/NBK43710/?report=reader#_NBK4371 0_pubdet_ (accessed July 2, 2015). AHRQ. 2010a. The roles of patient-centered medical homes and accountable care organizations in coordinating patient care. AHRQ publication no. 11-M005-EF. Rockville , MD: and -and-accountable-care- organizations-coordinating-patient (accessed June 5, . . Pat Croskerry, MD , PhD. Web M&M morbidity mortality rounds on the web. http://webmm.ahrq.gov/pe rspective.aspx?persp ectiveID=87 (accesse d July 24, 2015). AHRQ. 2011. Health literacy interventions and outcomes: An updated systematic review. AHRQ Publication No. 11-E006: Rockville, MD: Agency for Healthcare Research and Quality. AHRQ. 2012. Improving patient safety systems for patients with limited english proficiency. AHRQ Publication No. 12-0041. Rockville, MD: Agency for Healthcare Research and Quality. http://www.ahrq.gov/professionals/s ystems/hospital/lepguide/lepguide.p df (accessed July 24, 2015). AHRQ. 2013a. 2012 healthcare disparities report. AHRQ publication no. 13-0003. Rockville, MD: Agency for Healthcare Research and Quality. DIAGNOSTIC TEAM MEMBERS & TASKS 4-43 PREPUBLICATION COPY: UNCORRECTED PROOFS AHRQ. 2013b. AHRQ publication no. 13-0002. Rockville, MD: Agency for Healthcare Research Quality. AHRQ. 2014a. Error disclosure. h ttp://psnet.ahrq.gov/primer .aspx?primerID=2 (acces sed March 16, 2015). AHRQ. 2014b. Patient and family advisory councils. https://cahps.ahrq.gov/quality-improvement/improvement- guide/browse-interventions/Customer-Service/Listeni ng-Posts/Advisory-Councils.html (accessed March 18, 2015). AHRQ. 2014c. Patient centered medical home resource center. http://pcmh.ahrq.gov/page/defining-pcmh (accessed April 9, 2014). AHRQ. 2015a. About TeamSTEPPS. h ttp://teamstepps.ahrq.gov/about-2cl _3.htm (accessed March physicians' co mmunication skills. https://cahps.ahrq.gov/quality- improvement/improvement-guide/browse-interventions/Communication/Physicians-Comm- Training/index.html (accessed March 26, 2015). Allen, B., and W.T. Thorwarth. 2014. Comments from the American College of Radiology. Input submitted to the Committee on Diagnostic Error in Health Care, November 5, 2014, Washington, DC. Ali, N. K., R. P. Ferguson, S. Mitha, and A. Hanlon. 2 014. Do medical trainees feel confident communicating with low health literacy patients? Journal of Community Hospital Internal Medicine Perspective 4(2). Alper, B., J. A. Hand, S. G. Elliott, S. Kinkade, M. J. Hauan, D. K. Onion, and B. M. Sklar. 2004. How much effort is needed to keep up with the literature relevant for primary care? Journal of the Medical Library Association 92(4):429-437. Anderson, R. M., and M. M. Funnell. 2005. Patient empowerment: Reflections on the challenge of fostering the adoption of a new paradigm. Patient Education and Counseling 57(2):153-157. AOA (American Osteopathic Association). 2015. Ameri can Osteopathic Associati on. www.osteopathic.org/ (accessed March 12, 2015). ARC-PA (Accreditation Review Commission on Education for the Physician Assistant). 2015. Accreditation Review Commission on Education for the Physician Assistant. www.arc-pa.org/ (accessed March 12, 2015). Arora, N. K., and C. A. McHorney. 2000. Patient preferences for medical decision making: Who really wants to participate? Medical Care 38(3):335-341. ASCP (American Society for Clinical Pathol ogy). 2014. Patient access to test results. www.ascp.org/Advocacy/Patient-Access-to-Test- Results.html (accessed March 16, 2015). Aud\u00e9tat, M.-C., V. D. N. Junod Perron, and B. Charlin. 2012. What is so difficult about managing clinical reasoning difficulties? Medical Education 46(2):216-227. Baldwin, D. C. , and R. A. W. Tsukuda. 1984. Interdisci plinary teams. In C. K. Cassel and J. R. Walsh (eds.), Geriatric medicine: Volume York: Springer- Verlag. Beach, M. C., E. G. Price, T. L. Ga ry, K. A. Robinson, A. Gozu, A. Pala cio, C. Smarth, M. W. Jenckes, C. Feuerstein, E. B. Bass, N. R. Powe, and L. A. Coop er. 2005. Cultural competence: A systematic review of health care provider educational interventions. Medical Care 43(4):356-373. Bell, S., M. Anselmo, J. Walker, and T. Delbanco. 2 014. Submitted input. Input submitted to the Committee on Diagnostic Error in Healthcare, December 2, 2014, Washington, DC. Bergus, G., S. Vogelgesang, J. Tansey, E. Franklin, and R. Feld. 2004. Appraising and applying evidence about a diagnostic test during a performance-based assessment. BMC Medical Education 4:20. Berkhof, M., H. J. van Rijssen, A. J. M. Schellart, J. R. Anema, and A. J. van der Beek. 2011. Effective training strategies for teaching communicatio n skills to physicians: An over view of systematic reviews. Patient Education and Counseling 84(2):152-162. Bernard, A. W., N. E. Kman, and S. Khandelwal. 2011. Feedback in the emergency medicine clerkship. Western Journal of Emergency Medicine 12(4):537-542. Berner, E. S., and M. L. Graber. 2008. Overconfid e nce as a cause of diagnostic error in medicine. American Journal of Medicine 121(5 Suppl):S2-S23. Berwick, D. M. 2011. Launching accountable care orga nizations\u2014The proposed rule for the Medicare Shared Savings Program. New England Journal of Medicine 364(16):e32. Berwick, D. M., H. V. Fineberg, and M. C. Weinstein. 1981. When doctors meet numbers. The America Journal of Medicine 71(6):991-998. Bodenheimer, T. 2008. Coordinating care\u2014A perilous journey through the health care system. New England Journal of Medicine 358(10):1064-1071. 4-44 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Borrill, C. S., J. Carletta, A. J. Carter , J. F. Dawson, S. Garrod, A. Rees, A. Richards, D. Shapiro, and M. A. West. 2000. The effectiveness of health care teams in the National Health Service. Birmingham, UK: University of Aston in Birmingham. Boshuizen, H. P. A., and H. G. Schmidt. 2008. The develo pment of clinical reasoning expertise: Implications for teaching. In J. Higgs, M. Jones, S. Loftus, and N. Christensen (eds.), Clinical reasoning in the health professions (pp. 113-121) Oxford: Butterworth Heinemann/Elsevier. Boulding, W., S. W. P. Manary, K. A. Schulman, and R. Staelin. 2011. Relationship between patient satisfaction with inpatient care and hospital readmission within 30 days. American Journal of Managed Care 17(1):41-48. Boult, C., A. F. Green, L. B. Boult, J. T. Pacala, C. Snyder, and B. Leff. 2009. Succes sful models of comprehensive care for older adults with chronic conditions: Evidence for the Institute of Medicine's \"Retooling for an Aging America\" report. Journal of the American Geriatrics Society 57(12):2328-2337. Boyer, L., M. Williams, L. Callister, and E. Marshall. 2001. Hispanic women's perceptions regarding cervical cancer screening. Journal of Obstetrics, Gynecologic, and Neonatal Nursing 30(2):240-245. Bruno, M. A., J. M. Petscavage-Thomas, M. J. Mohr, S. K. Bell, and S. D. Brown. 2014. The \"open letter\": Radiologists' reports in the era of patient web portals. Journal of the American College of Radiology 11(9):863-867. Brush, J. E. 2014. Forming good habits to decrease diagnostic error: A case for likelihood ratios. Input submitted to the Committee on Diagnostic Error in Health Care, October 21, 2014, Washington, DC. BSCF (Blue Shield of California Foundation). 2014. Engaging California patients in major medical decisions. San Francisco, CA: Blue Shield of California Foundation . Buntin, M. B., S. H. Jain, and D. Blumenthal. 2010. Health information technology: Laying the infrastructure for national health reform. Health Affairs 29(6):1214-1219. Bushe, G. R., and A. Chu. 2011. Fluid teams: Solutions to the problems of unstable team membership. Organizational Dynamics 40(3):181-188. Butcher, L. 2014. The patient portal to the futu re. Healthcare Financial Management Association. www.hfma.org/Leadership/Archives/2014/Spring/The_Patient_Portal_to_the_Future/ (accessed May 11, 2015). Campaignforaction.org. 2012. Campaign for Action. http ://campaignforaction.org/ (accessed July 26, 2015). Campbell, C., I. Silver, J. Sherbino, O. T. Cate, an d E. S. Holmboe. 2010. Comp etency-based continuing professional development. Medical Teacher 32(8):657-662. Casscells, W., A. Schoenberger, and T. B. Graboys. 1978. Interpretation by physicians of clinical laboratory results. New England Journal of Medicine 299(18):999-1001. Cassel, C. K., and E. S. Holmboe. 2008. Profession alism and accountability: The role of specialty board certification. Transactions of the American Clinical and Climatological Association 119:295-304. Castro, A., and E. Ruiz. 2009. The effects of nurse prac titioner cultural competence on Latina patient satisfaction. Journal of the American Academy of Nurse Practitioners 21(5):278-286. Cate, O. t. 2014. Advice to the Institute of Medicine Committee on Diagnostic Error. Input submitted to the Committee on Diagnostic Error in Health Care, November, 25, 2014, Washington, DC. CDC (Centers for Disease Control and Prevention). 2009. Patient-centered care and laboratory medicine:National status report: 2008-2009 update. CDC. 2014. Early Release of Selcted Estimates Based on Data From the National Health Information Survey, January-Septmeber 2014: Usual place to go for medical care. www.cdc.gov/nchs/data/nhis/earlyrelease/earlyrelease201503_02.pdf (accessed May 7, 2015). CFAH (Center for Advancing Health). 2014a. Be a prepared patient. www.cfah.org/prepared-patient/ (accessed March 18, 2015). CFAH. 2014b. Center for Advancing Health engagement behavior framework. www.cfah.org/engagement/research/engagement-behavior-framework (accessed April 3, 2014). CFAH. 2014c. What does it take for all Americans to find good health care and make the most of it? www.cfah.org/about/about-us (accessed April 3, 2014). CFAH. 2015. Patient engagement. www.cfah.o rg/engagement/ (accesse d March 16, 2015). CFAR, J. Tomasik, and C. Fleming. 2015. Lessons from the field: Promising interprofessional collaboration practices. White Paper, Robert Wood Johnson Foundation. www.rwjf.org/content/dam/farm/re ports/re ports/2015/rwjf418568 (accessed June 5, 2015). Chang, J. H., E. Vines, H. Bertsch, D. L. Fraker, B. J. Cz erniecki, E. F. Rosato, T. Lawt on, E. F. Conant, S. G. Orel, L. Schuchter, K. R. Fox, N. Zieber, J. H. Glick, and L. J. Solin . 2001. The impact of a multidisciplinary DIAGNOSTIC TEAM MEMBERS & TASKS 4-45 PREPUBLICATION COPY: UNCORRECTED PROOFS breast cancer center on recommendations for patie nt management: The University of Pennsylvania experience. Cancer 91(7):1231-1237. Cifra, C. L., K. L. Jone s, J. A. Ascenzi, U. S. Bhal ala, M .M. Bembea, J. C. Fackle r, and M. R. Miller. 2014. The morbidity and mortality conference as an adverse event surveillance tool in a paediatric intensive care unit. BMJ Quality & Safety 23(11):930-938. Cifra, C. L., K. L. Jones, J. A. Ascenzi, U. S. Bhalala, M. M. Bembea, D. E. Newman-Toker, J. C. Fackler, and M. R. Miller. 2015. Diagnostic Errors in a PICU : Insights From the Morbidity and Mortality Conference. Pediatric Critical Care Medicine: A Journal of the Society of Critical Care Medicine and the World Federation of Pediatric Intensive and Critical Care Societies 16(5):468-476. CMS (Centers for Medicare & Medicaid Services). 2013 . Pioneer accountable care organizations succeed in improving care, lowering costs. Baltimore, MD: U.S. Department of Health and Human Services. https://www.cms.gov/Newsroom/Media ReleaseDatabase/Press-releases /2013-Press-releases-items/2013- 07-16.html (accessed June 5, 2015). Cohen, P., A. L. Tan, and A. Penman. 2009. The multid isciplinary tumor conference in gynecologic oncology\u2014 Does it alter management? International Journal of Gynecological Cancer 19(9):1470-1472. Cooke, M., D. M. Irby, and B. C. O'Brien. 2010. Summary of educating physicians: A call for reform of medical shool and residency. San Francisco, CA: Jossey-Bass. Cosgrove, D. M., M. Fisher, P. Gabow, G. Gottlieb, G. C. Halvorson, B. C. Jame s, G. S. Kaplan, J. B. Perlin, R. Petzel, G. D. Steele, and J. S. Toussaint. 2013. Ten strategies to lower costs, improve quality, and engage patients: The view from leading health system CEOs. Health Affairs 32(2):321-327. Coulter, A., S. Parsons, and J. Askham. 2008. Where are the patients in decision-making about their own care? Copenhagen, Denmark, June 25-27: World Health Organization Regional Office for Europe. Cox, E. D., K. A. Nackers, H. N. Young, M. A. Moreno, J. F. Levy, and R. M. Mangione-Smith. 2012. Influence of race and socioeconomic status on enga gement in pediatric primary care. Patient Education and Counseling 87(3):319-326. Crabtree, B. F., P. A. Nutting, W. L. Miller, K. C. Stange, E. E. Stewart, and C. R. Ja\u00e9n. 2010. Summary of the National Demonstration Project and recommendatio ns for the patient-centered medical home. Annals of Family Medicine 8(Suppl 1):S80-S90. Croskerry, P. 2000a. The cognitive imperative: Thinking about how we think. Academic Emergency Medicine 7(11):1223-1231. Croskerry, P. 2000b. The feedback sanction. Academic Emergency Medicine 7(11):1232-1238. Croskerry. 2003. The importance of cognitive errors in diagnosis and strategies to minimize them. Academic Medicine 78(8):775-780. Croskerry, P. 2009. A universal model of diagnostic reasoning. Academic Medicine 84(8):1022-1028. Croskerry, P. 2013. From mindless to mindful prac tice\u2014Cognitive bias and clinical decision making. New England Journal of Medicine 368(26):2445-2448. Croskerry, P. 2014. Bias: A normal operating characteristic of the diagnosing brain. Diagnosis 1(1):23-27. Croskerry, P., and G. Norman. 2008. Over confidence in clinical decision making. American Journal of Medicine 121(5 Suppl):S24-S29. Croskerry, P., G. Singhal, and S. Mame de. 2013a. Cognitive debiasing 1: Origins of bias and theory of debiasing. BMJ Quality and Safety 22(Suppl 2):ii58-ii64. Croskerry, and S. Ma mede. 2013b. Cognitive debiasing 2: Impediments to and strategies for change. BMJ Quality and Safety 22(Suppl 2):ii65-ii72. Cruz, D. M., C. M. Pimenta, and M. Lunney. 2009. Improving critical thinking and clinical reasoning with a continuing education course. Journal of Continuing Education in Nursing 40(3):121-127. Dalho usie University. 2015. Dalhousie University Medical School critical thinking program. http://medicine.dal.ca/departments/ core-units/DME/critical-thinking. html (accessed March 26, 2015). Deber, R. B., N. Kraetschmer, S. Urowitz, and N. Sharpe. 2007. Do people want to be autonomous patients? Preferred roles in treatment decision-ma king in several patient populations. Health Expectations 10(3):248-258. Delbanco, T., J. Walker, S. K. Bell, J. D. Darer, J. G. Elmore, N. Farag, H. J. Feldman, R. Mejilla, L. Ngo, J. D. Ralston, S. E. Ross, N. Trivedi, E. Vodicka, and S. G. Leveille. 2012. Inviting patients to read their doctors' notes: A quasi-experimental study and a look ahead. Annals of Internal Medicine 157(7):461-470. Dentzer, S. 2012. One payer's attempt to spur primary care doctors to form new medical homes. Health Affairs 31(2):341-349. 4-46 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Dhaliwal, G. 2014. Blueprint for diagnostic excellence. Pr esentation to the Committee on Diagnostic Error in Health Care, November 21, 2014, Washington, DC. Dineen, B. R., and R. A. Noe. 2003 . The impact of team fluidity and its implications for human resource management research and practice. In J. J. Martocchio and G. R. Ferris (eds.), Research in personnel and human resources management, Vol. 22 (pp. 1-37). Oxford, England: Elsevier Science Ltd. Dunn, R., J. S. Beaudry, and Klavas.Angela. 200 2. Survey of research on learning styles. California Journal of Science Education 2(2):75-98. Durning, S. J. 2014. Submitted input. Input submitted to the Committee on Diagnostic Error in Health Care, October 24, 2014, Washington, DC. Durso, L. E., and I. H. Meyer. 2013. Patterns and predic tors of disclosure of sexual orientation to healthcare providers among lesbians, gay men, and bisexuals. Sexuality Research and Social Policy 10(1): 35-42. Dyche, L., and D. Swiderski. 2005. The effect of physician solicitation appr oaches on ability to identify patient concerns. Journal of General Internal Medicine 20(3):267-270. Edmondson, A. C. 2012. Teaming: How organizations learn, innovate, and compete in the knowledge economy . San Francisco: Jossey-Bass. Entwistle, V. A., D. McCaughan, I. S. Watt, Y. Birks, J. Hall, M. Peat, B. Williams, J. Wright, and Patient Involvement in Patient Safety Group. 2010. Speakin g up about safety concerns: Multi-setting qualitative study of patients' views and experiences. Quality and Safety in Health Care 19:1-7. Etchegaray, J. M., M. J. Ottosen, L. Burress, W. M. Sa ge, S. K. Bell, T. H. Gallagher, and E. J. Thomas. 2014. Structuring patient and family involvement in medical error event disclosure and analysis. Health Affairs (Millwood) 33(1):46-52. Eva, K. W. 2005. What every teacher ne eds to know about c linical reasoning. Medical Education 39(1):98-106. Eva, K. W., and G. R. Norman. 2005. Heuristics and biases\u2014A biased perspective on clinical reasoning. Medical Education 39(9):870-872. Evans, M. 2013. Doctors argue for decision aids to promote patient engagement. Modern Healthcare. http://www.modernhealthcar e.com/article/20131127/M AGAZINE/311309982 (accesse d April 4, 2014). FamilyDoctor.org. 2014. Health information on the web: Finding reliable information. http://familydoctor.org/familydoctor/ en/healthcare-management/self-care/ health-information-on-the-web- finding-reliable-information.printerview.all.html (accessed March 16, 2015). Feinberg School Medicine. 2015. Education: MD curriculum at Feinburg. http://www.feinberg .northwestern.edu/education/curriculum/index. html (accessed March 16, 2015). Flores, G. 2006. Language barriers to health care in the United States. New England Journal of Medicine 355(3):229-231. Foglia, M. B., and K. I. Fredriksen Goldsen. 2014. Health disparities among LGBT older adults and the role of nonconscious bias. Hastings Center Report 44(s4):S40-S44. Fowler, F. 2011. Patients want to be involved. http://informedmedicaldecisions.org/wp- content/uploads/2011/05/Perspectives_Patient _Involvement.pdf (acce ssed June 5, 2015). Fox, S., Duggan. 2013. Health online 2013. www.p ewinternet.org/2013 /01/15/health-onlin e-2013/ (accessed March 18, 2015). Frampton, S. B., S. Horowitz, and B. J. Stumpo. 2009. Open medical records. The American Journal of Nursing 1 09(8):59-63. Friesen, M. A., A. Herbst, J. W. Turner, K. G. Speroni, and J. Robinson. 2013. Developing a patient-centered ISHAPED handoff with patient/family and parent advisory councils. Journal of Nursing Care and Quality 28(3):208-216. Frosch, D. L., S. G. May, K. A. S. Rendle, C. Tietbohl, and G. Elwyn. 2012. Authoritarian physicians and patients' fear of being labeled 'difficult' among key obstacles to shared decision making. Health Affairs (Millwood) 31(5):1030-1038. Furukawa, M. F., J. King, V. Patel, C. J. Hsiao, J. Adle r-Milstein, and A. K. Jha. 2014. Despite substantial progress in EHR adoption, health information exchange and patient engagement remain low in office settings. Health Affairs 33(9):1672-1679. Gallagher, T. H., A.D. Waterman, A.G. Ebers, V.J. Fraser, and W. Levinson. 2003. Patients' and physicians' attitudes regarding the disclosure of medical errors. JAMA 289(8):1001-1007. Gandhi, T. K. 2014. Focus on diagnostic errors: Unders tanding and prevention. Pres entation to the Committee on Diagnostic Error in Health Care, August 7, 2014, Washington, DC. Gandhi, T. K., and T. H. Lee. 2010. Patient safety beyond the hospital. New England Journal of Medicine 363(11):1001-1003. DIAGNOSTIC TEAM MEMBERS & TASKS 4-47 PREPUBLICATION COPY: UNCORRECTED PROOFS Gandhi, T. K., A. Kachalia, E. J. Thomas, A. L. Puopolo, C. Yoon, T. A. Brennan, and D. M. Studdert. 2006. Missed and delayed diagnoses in the ambulatory setting: A study of closed malpractice claims. Annals of Internal Medicine 145(7):488-496. Georgetown University. 2015. First year curriculum module: Physician-patient communication. https://som.georgetown.edu/medical education/curriculum/firstyearm odules/modules/ppc (accessed March 26, 2015). Gertler, S. A., Z. Coralic, A. Lopez, J. C. Stein, and U. Sarkar. 2014. Root cause analysis of ambulatory adverse drug events that present to the emergency department. Journal of Patient Safety . February 27. Epub ahead of print. Gigerenzer, G. 2000. Adaptive thinking: Rationality in the real world . New York: Oxford University Press. Gigerenzer, G., and D. G. Goldstein. 1996. Reasoning the fast and frugal way: Models of bounded rationality. Psychology Review 103(4):650-669. Glickman, S. W., W. Boulding, M. Manary, R. Staelin, M. T. Roe, R. J. Wolosin, E. M. Ohman, E. D. Peterson, and K. A. Schulman. 2010. Patient satisfaction and its rela tionship with clinical quality and inpatient mortality in acute myocardial infarction. Circulation: Cardiovascular Quality and Outcomes 3(2):188-195. Govern, P. 2013. Diagnostic management efforts thrive on teamwork. http://news.vanderb ilt.edu/2013/03/diagnostic -management-efforts-thri ve-on-teamwork/ (accessed February 11, 2015). Wachter, and C. Cassel. 2012. Bringi ng into the quality and safety equations. JAMA 308(12):1211-1212. Graedon, T., and J. Graedon. 2014. Let patients help with diagnosis. Diagnosis 1(1):49-51. Gruman, J. C. 2013. An accidental tourist finds her way in the dang erous land of serious illness. Health Affairs 32(2):427-431. Hager, M., S. Russell, and S. W. Fletcher. 2008. Continuing education in the health professions: Improving healthcare through lifelong learning, Proceedings of a conference sponsored by the Josiah Macy, Jr. Foundation . Bermuda. New York: Josiah Macy, Jr. Foundation. www.josiahmacyfoundation.org (accessed June 5, 2015). Haig, K. M., S. Sutton, and J. Whittington. 2006. SBAR: A shared mental model for improving communication between clinicians. Joint Commission Journal on Quality and Patient Safety 32(3):167-175. Hallworth, M. J. 2011. The \"70% cl aim\": What is the evidence base? Annals of Clinical Biochemistry 48(6):487- 488. Haskell, H. W. 2014. What's in a story? Lessons from patients who have suffered diagnostic failure. Diagnosis 1(1):53-54. Hauer, K. E., A. Teherani, K. M. Kerr, P. S. O'Sullivan , and D. M. Irby. 2007. Student performance problems in medical school clinical skills assessments. Academic Medicine 82(10 Suppl):S69-72. Hautz, W. E., J. E. K\u00e4mmer, S. K. Schauber, C. D. Spies, and W. Gaissmaier. 2 015. Diagnostic performance by medical students working individually or in teams. JAMA 313(3):303-304. Health Affairs. 2010. Patient-centered me dical homes: Health affairs policy brief. Health Affairs . September 14. http://healthaffairs. org/healthpolicybriefs/brief_p dfs/healthpolicybrie f_25.pdf (accessed June 5, 2015). HealthIT.gov. 2015. Patient ability to electronically vi ew, download & transmit (VDT) health information. www.healthit.gov/providers-profe ssionals/achieve-meaningful-use/core-measures-2/patient-ability- electronically-view-download-tr ansmit-vdt-health-information (accessed March 15, 2015). Hekelman, F. P., E. Vanek, K. Kelly, and S. Alemagno. 1 993. Characteristics of family physicians' clinical teaching behaviors in the ambulatory setting: A descriptive study. Teaching and Learning in Medicine: An International Journal 5( 1):18-23. Hendrich, A., C. K. McCoy, J. Gale, L. Sparkman, and P. Santos. 2014. Ascension Health's demonstration of full disclosure protocol for unexpected events during labor and delivery shows promise. Health Affairs 33(1):139-145. Henriksen, K., and J. Brady. 2013. The pursuit of better diagnostic performance: A human factors perspective. BMJ Quality and Safety 22(Suppl 2):ii1-ii5. HHS (Department of Health and Human Services). 2013. Usual source of care: Women's health USA: An illustrated collection of current and historical data, published annually. http://mchb.hrsa.gov/whusa13/health- services-utilization/p/usual-source-care.html (accessed May 7, 2015). HHS. 2014. HHS strengthens patients' right to access lab test reports. www.hhs.gov/news/press/2014pres/02/20140203a.html ( accessed June 5, 2015). 4-48 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS HHS. 2015. What are the national CLAS standards? www.thinkculturalhealth.hhs.gov /Content/clas.asp#clas_standards (accessed May 11, 2015). Hickner, J., P. J. Thompson, T. Wilkinson, P. Epner, M. Sh aheen, A. M. Pollock, J. Lee, C. C. Duke, B. R. Jackson, and J. R. Taylor. 2014. Primary care physicians' challenges in orderi ng clinical laboratory tests and interpreting results. Journal of the American Board of Family Medicine 27(2):268-274. Hines, L. E., and J. E. Murphy. 2011. Potentially harmful drug-drug interactions in the elderly: A review. The American Journal of Geriatric Pharmacotherapy 9(6):364-377. Hirsh, D. A., E. S. Holmboe, and O. ten Cate. 2014. Time to trust: Longitudinal integrated clerkships and entrustable professional activities. Academic Medicine 89(2):201-204. Hirt, E., and K. Markman. 1995. Multiple explanation: A co nsider-an-alternative strategy for debiasing judgments. Journal of Personality and Social Psychology 69:1069-1086. Hodges, B., G. Regehr, and D. Martin. 2001. Difficulties in recognizing one's own incompetence: Novice physicians who are unskilled and unaware of it. Academic Medicine 76(10 Suppl):S87-S89. Holmboe, E. S., and S. J. Durning. 2014. Assessing clinical reasoning: moving from in vitro to in vivo. Diagnosis 1(1):111-117. Holmboe, E. S., J. Sherbino, D. M. Long, S. R. Swing, and J. R. Frank. 2010. The role of assessment in competency-based medical education. Medical Teacher 32(8):676-682. HRSA (Health Resources and Services Administration). 2015. Teaching health center graduate medical education (THCGME). http://bhpr.hrsa.gov /grants/teachinghealthcenters/ (accessed March 16, 2015). Iglehart, J. K. 2011. Assessing an aco prototype\u2014Medicare's physician group practice demonstration. New England Journal of Medicine 364(3):198-200. Iglehart, J. K., and R. B. Baron. 2012. Ensuring ph ysicians' competence\u2014Is main tenance of certification the answer? New England Journal of Medicine 367(26):2543-2549. IHC. (Institute for Healthcare Communication). 2 011. Impact of communication in healthcare. http://healthcareco mm.org/about-us/impact-of- communication-in-hea lthcare/ (accessed March 26, 2015). IMDF (Informed Medical Decisions Foundation). 2014. What is shared decision making? www.informedmedicaldecisions.org/what-is-shared- decision-making/ (accessed March 18, 2015). Institute for Healthcare Communication. 2015. Institute for Healthcare Communication. www.healthcarecomm.org (accessed March 16, 2015). IOM (Institute of Medicine). 2001. Crossing the quality chasm: A new health system for the 21st century . Washington, DC: National Academy Press. IOM. 2003a. Health professions education: A bridge to quality. Washington, DC: The National Academies Press. IOM. 2003b. Unequal treatment: Confronting racial and ethnic disparties in health care . Washington, DC: The National Academies Press. IOM. 2004. Health literacy: A prescription to end confusion . Washington, DC: The National Academies Press. IOM. 2008. Retooling for an aging America: Building the health care workforce . Washington, DC: The National Academies Press. IOM. 2010. Redesigning continuing education in the health professions . Washington, DC: The National Academies Press. IOM. 2011a. The future of nursing: Leading change, advancing health . Washington, DC: The National Academies Press. IOM. 2011b. The health of lesbian, gay, bisexual, and transgender people: Building a foundation for better understanding. Washington, DC: The National Academies Press. IOM. 2011c. Relieving pain in America: A blueprint for transforming prevention, care, education, and research. Washington, DC: The National Academies Press. IOM. 2012a. 10 attributes of a health literate organization. Discussion paper. Washington, DC: Institute of Medicine IOM. 2012b. Communicating with patients on health care evidence: Discussion paper . Washington, DC: Institute of Medicine. IOM. 2012c. Core principles and values of effective team -based health care: Discussion paper. Washington, DC: Institute of Medicine. IOM. 2012d. Health IT and patient safety: Building safer systems for better care . Washington, DC: The National Academies Press. IOM. 2012e. The mental health and substance use workforce for older adults: In whose hands? . Washington, DC: The National Academies Press. IOM. 2013a. Best care at lower cost: The path to continuously learning health care in america . Washington, DC: The National Academies Press. DIAGNOSTIC TEAM MEMBERS & TASKS 4-49 PREPUBLICATION COPY: UNCORRECTED PROOFS IOM. 2013b. Delivering high-quality cancer care: Charting a new course for a system in crisis . Washington, DC: The National Academies Press IOM. 2014. Graduate medical education that meets the nation's health needs . Washington, DC: The National Academies Press. IOM. 2015. Measuring the impact of interprofessional education on collaborative practice and patient outcomes . Washington, DC: The National Academies Press. Jarvis-Selinger, S., D. D. Pr att, and G. Regehr. 2012. Competency is not enough: Integrating identity formation into the medical education discourse. Academic Medicine 87(9):1185-1190. Joint Commission. 2007. \"What did the doctor say?\" Improving health literacy to protect patient safety. www.jointcommission.org/What_Did_the_Doctor_Say/default.aspx (accessed May 11, 2015). Joint Commission. 2014. Sentinel event data: Root causes by event type 2004-2q2014. http://www.jointcommission.org/Se ntinel_Event_Statistics/ (acce ssed February 4, 2015). Joint Commission. 2015. Speak Up initiatives. www.jointcommission.org/spea kup.aspx (accessed March 16, 2015). Josiah Macy Jr. Foundation. 2011 . Ensuring an effective physician workforce for the United States: Recommendations for graduate medical education to meet the needs of the public, the second of two conferences\u2014The content and format of GME, chaired by Debra Weinstein, M.D. May, 2011, Atlanta, GA. New York: Josiah Macy Jr. Foundation Josiah Macy Jr. Foundation. 2014. Partnering with patients, families, and communities: An urgent imperative for health care, Conference recommendations. New York: Josiah Macy Jr. Foundation. http://macyfoundation.org/publications/publication/partnering-with-patients-families-and-communities-an-urgent-imperative-for (accessed June 5, 2015). Josiah Macy Jr. Foundation and Carnegie Foundation for the Advancement of Teaching. 2010. Educating nurses and physicians: Towards new horizons. Advancing inter-professional education in academic health centers, Conference summary. New York: Josiah Macy Jr. Foundation. http://www.macyfoundation.org/docs/macy_pubs/J MF_Carnegie_Summary_WebVersion_%283%29.pdf (accessed June 5, 2015). Julavits, H. 2014. Diagnose this! How to be your own best doctor. Harper's , April: 25-35. Kachalia, A., K. G. Shojania, T. P. Hofer, M. Piotrowski, and S. Saint. 2003. Does full disclosure of medical errors affect malpractice liability? The jury is still out. Joint Commission Journal on Quality and Patient Safety 29(10):503-511. Kahneman, D. 2011. Thinking, fast and slow. New York: Farrar, Straus and Giroux. Kaiser Permanente. 2012. Smart partners ab out your health, edited by K. Permanente. http://c.ymcdn.com/sites/www. npsf.org/resource/collectio n/930A0426-5BAC-4827-AF94- 1CE1624CBE67/SMART-Partners-Guide 1.pdf (accessed June 26, 2015). Kak, N., B. Burkhalter, and M. Cooper. 2001. Measuring the competence of healthcare providers. Bethesda, MD: Published for USAID by the Center for Hu man Services, Quality Assurance Project. Kanter, M. 2014. Diagnostic errors\u2014Patient safety. Pres entation to the committee on Diagnostic Error in Health Care, August 7, 2014, Washington, DC. Kassirer, J. P. 1989. Our stubborn quest for diagnostic certainty. A cause of excessive testing. The New England Journal of Medicine 320(22)1489-1491. Keating, N. L., M. B. Land rum, E. B. Lamont, S. R. Bozeman, L. N. Shulman, and B. J. McNeil. 2012. Tumor boards and the quality of cancer care. Journal of the National Cancer Institute . doi: 10.1093/jnci/djs502. http://jnci.oxfordjournals.org/cont ent/early/2012/12/24/jnci.djs502 (accessed June 5, 2015). Kern, C. 2014. ACOs face barriers to implementing h ealth IT. www.healthitoutcomes. com/doc/acos-face-barriers- to-implementing-health-it-0001 (accessed March 25, 2015). Keroack, M. A., B. J. Youngberg, J. L. Cerese, C. Krsek, L. W. Prellwitz, and E. W. Trevelyan. 2007. Organizational factors associ ated with high performance in quality and safety in academic medical centers. Academic Medicine 82(12):1178-1186. King, H. B., J. Battles, D. P. Baker, A. Alonso, E. Salas, J. Webster, L. Toomey, and M. Salisbury. 2008. TeamSTEPPS: Team strategies and tools to enhance performance and patient safety. In K. Henriksen, J.B. Battles, M.A. Keyes, and M.L. Grady (eds.), Advances in pateint safety: New directions and alternative approaches (Vol. 3: Performance and tools) . AHRQ publication no. 00-0034-3: Rockville, MD: Agency for Healthcare Research and Quality. http://www.ahrq.gov/professionals/quality-patient- safety/patient-safety-resources/resources/advances-in-patient-safety-2/vol3/Advances-King_1.pdf (accessed June 5, 2015). 4-50 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Klein, G. 1993. Sources of error in naturalistic decision making tasks. Proceedings of the Human Factors and Ergonomics Society, 37th Annual Meeting , 368-371. Klein, J. G. 2005. Five pitfalls in d ecisions about diagnosi s and prescribing. BMJ 330(7494):781-783. Kondo, K. L., and M. Swerdlow. 2013. Medical student radiology curriculum: What skills do residency program directors believe are essential for medical students to attain? Academic Radiology 20(3):263-271. Kroenke, K. 2013. Diagnostic testing and the illusory reassurance of normal results: Comment on \"Reassurance after diagnostic testing with a low pr etest probability of serious disease.\" JAMA Internal Medicine 173(6):416-417. Kroft, S.H. 2014. Statement of Steven H. Kroft, American Society for Clinical Pathology (ASCP). Presentation to the Committee on Diagnostic Error in Hea lth Care, April 28, 2014, Washington, DC. Laposata, M., and A. Dighe. 2007. \"Pre-pre\" and \"post-post\" analytical error: High-incid ence patient safety hazards involving the clinical laboratory. Clinical Chemistry and Laboratory Medicine 45(6):712-719. LCME (Liaison Committee on Medical Education). 2015. Functions and structure of a medical school: Standards for accreditation of medical education programs leading to the M.D. Degree. Liaison Committee on Medical Education. http://www.lcme.org/publications.htm#standard s-section (accessed July 24, 2015). Leonard, M., S. Graham, and D. Bonacum. 2004. The human factor: The critical importa nce of effective teamwork and communication in providing safe care. Quality and Safety in Health Care 13(suppl 1):i85-i90. Levinson, W., A. Kao, A. Kuby, and R. A. Thisted. 2005. Not all patients want to participate in decision making. Journal of General Internal Medicine 20(6):531-535. Lie, D. A., E. Lee-Rey, A. Gomez, S. Bereknyei, and C. H. Braddock, 3r d. 2011. Does cultural competency training of health professionals improve patient outcomes? A systematic review and proposed algorithm for future research. Journal of General Internal Medicine 26(3):317-325. Lipson, J. G., H. M. Weinstein, E. A. Gladstone, and R. H. Sarnoff. 2003. Bosnian and Soviet refugees' experiences with health care. Western Journal of Nursing Research 25(7):854-871. Longtin, Y., H. Sax, L. L. Leape, S. E. Sheridan, L. Dona ldson, and D. Pittet. 2010. Patient participation: Current knowledge and applicability to patient safety. Mayo Clinic Proceedings 85(1):53-62. Lucian Leape Institute. 2014. Safety is personal: Partnering with patients and families for the safest care. Report of the Roundtable on Consumer Engagement in Patient Safety. Boston, MA: National Patient Safety Foundation. Lujan, H. L., and S. E. DiCarlo. 2006. First-year medical students prefer multiple learning styles. Advances in Physiological Education 30(1)_13-16. Lurie, S. J. 2012. History and practice of competency-based assessment. Medical Education 46(1):49-57. Magid, M. S., and C. L. Cambor. 2011. The integration of pathology into the clinical y ears of undergraduate medical education: a survey and review of the literature. Human Pathology 43(4):567-576. Malone, D. C., D. S. Hutchins, H. Haupert, P. Hansten, B. Duncan, R. C. Van Bergen, S. L. Solomon, and R. B. Lipton. 2005. Assessment of potential drug-drug inte ractions with a prescription claims database. American Journal of Health-System Pharmacy 62(19):1983-1991. Manrai, A. K., G. Bhatia, J. Strymish, I. S. Kohane, and S. H. Jain. 2014. Medicine's uncomfortable relationship with math: Calculating positive predictive value. JAMA Internal Medicine 174(6):991-993. Marcus, E. 2003. Cases: When a patient is lost in the translation. The New York Times , April 8. Marewski, J. N., and G. Gigerenzer. 2012. Heuristic decision making in medicine. Dialogues Clinical Neuroscience 14(1):77-89. Marois, R., and J. Ivanoff. 2005. Capacity lim its of information processing in the brain. Trends in Cognitive Sciences 9(6):296-305. Marvel, M. K., R. M. Epstein, K. Flowers, and H. B. Beckman. 1999. Soliciting the patient's agenda: Have we improved? JAMA 281(3):283-287. Mayer, R. E. 2010. Applying the science of learning to medical education. Medical Education 44(6):543-549. Mayo Clinic. 2015. Patient care and health information. www.mayoclinic.org/patient-care-and-health-information (accessed March 26, 2015). Mazor, K. M., D. W. Roblin, S. M. Greene, C. A. Lemay, C. L. Firneno, J. Calvi, C. D. Prouty, K. Horner, and T. H. Gallagher. 2012. Toward patient-centered cancer care: Patient perceptions of problematic events, impact, and response. Journal of Clinical Oncology 30(15):1784-1790. Mazzocco, K., D. B. Petitti, K. T. Fong, D. Bonacum, J. Brookey, S. Graham , R. E. Lasky, J. B. Sexton, and E. J. Thomas. 2009. Surgical team behaviors and patient outcomes. American Journal of Surgery 197(5):678- 685. McDonald, K. M. 2014. The diagnostic field's players and interactions: From the inside out. Diagnosis 1(1):55-58. DIAGNOSTIC TEAM MEMBERS & TASKS 4-51 PREPUBLICATION COPY: UNCORRECTED PROOFS McDonald, K. M., C. L. Bryce, and M. L. Graber. 2013 . The patient is in: Patient involvement strategies for diagnostic error mitigation. BMJ Quality and Safety 22(2):30-36. McGaghie, W. C., S. B. Issenberg, E. R. Cohen, J. H. Barsuk, and D. B. Wayne. 2011. Does simulation-based medical education with deliberate practice yield better results than traditional clinical education? A meta- analytic comparative re view of the evidence. Academic Medicine 86(6):706-711. McGowan, J., M. Passiment, and H. M. Hoffman. 2007. Educating medical students as competent users of health information technologies: The MSOP data. Studies in Health Technologies and Informatics 129(Pt 2):1414-1418. McLaughlin, J. E., M. T. Roth, D. M. Glatt, N. Gharkholonarehe, C. A. Davidson, L. M. Griffin, D. A. Esserman, and R. J. Mumper. 2014. The flipped classroom: A course redesign to fo ster learning and engagement in a health professions school. Academic Medicine 89(2):236-243. MedPAC (Medicare Payment Advisory Commission). 2010. Shared decision making and its implications for Medicare. In MedPAC, Report to the Congress: Aligning incentives in medicine (pp. 191-210). Washington, DC: MedPAC. http://www.medpac.gov/documents/reports/Jun10_Ch07.pdf?sfvrsn=0 (accessed June 5, 2015). Mello, M. M., R. C. Boothman, T. McDonald, J. Driver, A. Lembitz, D. Bouwmeester, B. Dunlap, and T. Gallagher. 2014. Communication-and-resolution programs: The challenges and lessons learned from six early adopters. Health Affairs 33(1):20-29. Meyer, A. N. D., V. L. Payne, D. W. Meeks, R. Ra o, and H. Singh. 2013. Physicians' diagnostic accuracy, confidence, and resource requ ests: a vignette study. JAMA internal medicine 173(21): 1952-1958. Milan, F. B., L. Dyche, and J. Fletcher. 2011. \"How am I doing?\" Teaching medical students to elicit feedback during their clerkships. Medical Teacher 33(11):904-910. Miller, G. A. 1956. The magical number seven plus or mi nus two: Some limits on our capacity for processing information. Psychological Review 63(2):81-97. Morcke, A., T. Dornan, and B. Eika. 2013. Outcome (compete ncy) based education: An exploration of its origins, theoretical basis, and empirical evidence. Advances in Health Sciences Education 18(4):851-863. Mulley, A. G., C. Trimble, and G. Elwyn. 2012. Stop the silent misdiagnosis: Patients' preferences matter. BMJ 345(1). Mumma, G., and W. Steven. 1995. Procedural debiasing of primary/anchoring effects in clinical-like judgments. Journal of Clinical Psychology 51(6):841-853. Mussweiler, T., F. Strack, and T. Pfeiffer. 2000. Over coming the inevitable anchoring effect: Considering the opposite compensates for selective accessibility. Personality and Social Psychology Bulletin 26(9):1142- 1150. Myers, L. 2013. Medical student perspective: Memory mountain: A more pleasurable route. www.acponline.org/medical _students/impact/archive s/2013/07/perspect/ (accessed March 16, 2015). Nasca, T. J., I. Philibert, T. Brigham, and T. C. Flynn. 2012. The next GME accreditation system\u2014Rationale and benefits. New England Journal of Medicine 366(11):1051-1056. National Commission on Physician Payment Reform. 2013. Report of the National Commission on Physician Payment Reform . Washington, DC: National Commission on Physician Payment Reform. Naylor, M. D., Coburn, K. D., Kurtzman, E. T., Buck, H., Van Cleave, J., and Cott, C. 2010. Inter-professional team-based primary care for chronically ill adults: State of the science . Unpublished white paper presented at the ABIM Foundation meeting to Advance Team-B ased Care for the Chronically Ill in Ambulatory Settings, March 24-25, 2010, Philadelphia, PA. NCI (National Cancer Institute). 2015. NCI dictionary of cancer terms: Tumor board review. http://www.cancer .gov/dictionary?cdrid=322893 (accessed March 16, 2015). NCSBN (National Council of State Boards of Nursing). 2015. National Council of State Boards of Nursing. www.ncsbn.org/i ndex.htm (accessed June 5, 2015). Newman, E. A., A. B. Guest, M. A. Helvie, M. A. Roubidoux, A. E. Chang, C. G. Kleer, K. M. Diehl, V. M. Cimmino, L. Pierce, D. Hayes, L. A. Newman, and M. S. Sabel. 2006. Changes in surgical management resulting from case review at a breast cancer multidisciplinary tumor board. Cancer (107):2346-2351. Newman-Toke, D. E., K. M. McDonald, and D. O. Meltzer. 2013. How much diagnostic safety can we afford, and how should we decide? A health economics perspective. BMJ Quality and Safety 22(Suppl 2):ii11-ii20. NIST (National Institute of Standards and Te chnology), J. Redish, and S. Lowry. 2010. Usability in health IT: Technical strategy, research, and implementation. Rockville, MD: National Institute of Standards and Technology. Summary of Workshop and Usability in Health IT, Washington, DC, July 13. 4-52 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS NLM (National Library of Medicine). 2012a. Evaluating Internet health information: A tutorial from the National Library of Medicine. www.nlm.nih.gov/medlineplus/webeval/webeval.html ( accessed March 16, 2015). NLM. 2012b. MedlinePlus guide to healthy Web surfing www.nlm.nih.gov/medlineplus/healthywebsurfing.html (accessed February 11, 2015). NNLM (National Network of Libraries of Medicine ). 2013. Prevalence of low health literacy. nnlm.gov/outreach/consu mer/hlthlit.html#A3 (accessed April 4, 2014). NORC. 2014. Demonstrating the effectiv eness of patient feedback in improving the accuracy of medical records. Chicago, IL: NORC. http ://www.healthit.gov/sites/default/files/20 120831_odrfinalreport508.pdf (accessed June 5, 2015). Norman G. 2014. Diagnostic errors. Input submitted to the Committee on Diagnostic Error in Health Care, October 24, 2014, Washington, DC. Nouri, S. S., and R. E. Rudd. 2015. Health literacy in the \"oral exchange\": An important element of patient-provider communication. Patient Education and Counseling 98(5):565-571. NPSF. 2015a. Ask me 3. www.npsf.org/?page=askme3 (accessed March 25, 2015). NPSF. 2015b. RCA2:Improving root cause npsf.org/resource/resmgr /PDF/RCA2_first-online- pub_061615.pdf?hhSearchTerms=%22r ca%22 (accessed July, 6 2015). NPSF (National Patient Safety Foundation) and SIDM (Soc iety to Improve Diagnosis in Medicine. 2014. Checklist for getting the right diagnosis http://www.npsf.org/?page=rightdiagnosis and http://c.ymcdn.com/sites/www. npsf.org/resource/collectio n/930A0426-5BAC-4827-AF94- 1CE1624CBE67/Checklist-for-Gettin g-the-Right-Diagnosis.pdf (accessed June 26, 2015). Nutter, D. W., M. . 2001. The AAMC Project on the Clinical Education of Medical Students. Washington, DC: Association of American Medical Colleges. O'Mahony, S., E. Mazur, P. Charney, Y. Wang, and J. Fine. 2007. Use of multidisciplinary rounds to simultaneously improve quality outcomes, enhance resident education, and shorten length of stay. Journal of General Internal Medicine 22(8):1073-1079. O'Malley, A. S., G. R. Cohen, and J. M. Grossman. 2010. Electronic medical records and communication with patients and other clinicians: Are we talking less? Center for Studying Health System Change, Issue Brief No. 131:1-4. http://www.h schange.com/CONTENT/1125/ (accessed June 5, 2015). O'Neill, T. R., and J. C. Puffer. 2013. Maintenance of certification and its association with the clinical knowledge of family physicians. Academic Medicine 88(6):780-787. OHSU (Oregon Health & Science University). 2014. A bo ld new curriculum aligns physician education with our health care future. School of Medicine , Oregon Health & Science University. http://www.ohsu.edu/xd/education/schools /school-of-medicine/about/curriculum- transformation/upload/SoM-Curric ulum-transformation-interactive- OpenNotes? http://www.my opennotes.org/about-opennotes/ (accessed January 2, 2015). Ostbye, T., K. S. Yarnall, K. M. Krause, K. I. Pollak, M. Gradison, and J. L. Mich ener. 2005. Is there time for management of patients with chronic diseases in primary care? Annals of Family Medicine 3(3):209-214. Paez, K., J. Allen, M. Beach, K. Carson, and L. Cooper. 2009. Physician cultural compet ence and patient ratings of the patient-physician relationship. Journal of General Internal Medicine 24(4):495-498. Papa, F. J. 2014a. Learning sciences principles that can inform the construction of new approaches to diagnostic training. Diagnosis 1(1):125-129. Papa. 2014b. A response to the IOM's ad hoc Committee on Di agnostic Error in Health Care. Input submitted to the Committee on Diagnostic Error in Health Care, October 24, 2014, Washington, DC. Papp, K. K., G. C. Huang, L. M. Lauzon Clabo, D. Delva, M. Fischer, L. Konopasek, R. M. Schwartzstein, and M. Gusic. 2014. Milestones of critical thinking: A developmental model for medicine and nursing. Academic Medicine 89(5):715-720. Patel, V., N. A. Yoskowitz, and J. F. Arocha. 2009a. Towards effective evaluation and reform in medical education: A cognitive and learning sciences perspective. Advances in Health Sciences Education 14(5):791-812. Patel, V., N. A. Yoskowitz, J. F. Aroc ha, and E. H. Shortliffe. 2009b. Cognitive and learning sciences in biomedical and health instructional design: A review with lessons for biomedical informatics education. Journal of Biomedical Informatics 42(1):176-197. Pawlik, T. M., D. Laheru, R. H. Hruban, J. Coleman, C. L. Wolfgang, K. Campbell, S. Ali, E. K. Fishman, R. D. Schulick, J. M. Herman, and the Johns Hopkins Multid isciplinary Pancreas Clinic Team. 2008. Evaluating DIAGNOSTIC TEAM MEMBERS & TASKS 4-53 PREPUBLICATION COPY: UNCORRECTED PROOFS the impact of a single-day multidisciplinary c linic on the management of pancreatic cancer. Annals of Surgical Oncology 15(8):2081-2088. Pecukonis, E., O. Doyle, and D. L. Bliss. 2008. Reducing barriers to interprofessional training: Promoting interprofessional cultural competence. Journal of Interprofessional Care 22(4):417-428. Peters, E., J. Hibbard, P. Slovic, and N. Dieckmann. 2 007. Numeracy skill and the communication, comprehension, and use of risk-benefit information. Health Affairs 26(3):741-748. Pines, J. M. 2006. Profiles in patient safety: Confirmation bias in emergency medicine. Academic Emergency Medicine 13:90-94. Porter, M. E. 2010. What is value in health care? New England Journal of Medicine 363(26):2477-2481. Porter, M. E., and T. H. Lee. 2013. The strategy that will fix health care. Harvard Business Review 91(10):50-70:. Press, M. J. 2014. Instant replay\u2014A quarterback's view of care coordination. New England Journal of Medicine 371(6):489-491. Prezzia, C., G. Vorona, and R. Green span. 2013. Fourth-year medical stude nt opinions and basic knowledge regarding the field of radiology. Academic Radiology 20(3):272-283. Price-Wise, G. 2008. Language, culture, and medical tragedy: The case of Willie Ramirez. http://healthaffairs.org/blog/2008/11/19/language-cultu re-and-medical-tragedy-t he-case-of-willie-ramirez/ (accessed May 11, 2015). Priyanath, A., J. Feinglass, N. C. Dolan, C. Havile y, and L. A. Venta. 2002. Patient satisfaction with the communication of mammographic results before and after the Mammography Quality Standards Reauthorization Act of 1998. American Journal of Roentgenology 178(2):451-456. Puhl, R., and K. D. Brownell. 2001. Bias, discrimination, and obesity. Obesity Research 9(12):788-805. Rao, V. M., and D. C. Levin. 2012. The overuse of diagnostic imaging and the Choosing Wisely Initiative. Annals of Internal Medicine 157(8):574-576. Redelmeier, D. A. 2005. The cognitive psychology of missed diagnoses. Annals of Internal Medicine 142(2):115- 120. Rhoades, D. R., K. F. McFarland, W. H. Finch, and A. O. Johnson. 2001. Speaking and interruptions during primary care office visits. Family Medicine 33(7):528-532. Richardson, W.S. 2014. Twenty suggestions that could improve clinical diagnosis and reduce diagnostic error. Input submitted to the Committee on Diagnostic Error in Health Care, October 24, 2014, Washington, DC. Richardson, W. S. 2007. We should overcome th e barriers to evidence-based clinical diagnosis! Journal of Clinical Epidemiology 60(3):217-227. Rider, E. A., and C. H. Keefer. 20 06. Communication skills competencies: Definitions and a teaching toolbox. Medical Education 40(7):624-629. Rittenhouse, D. R., S. M. Shortell, and E. S. Fisher. 2009. Primary car e and accountable care\u2014Two essential elements of delivery-system reform. New England Journal of Medicine 361(24):2301-2303. Roades, C. 2013. The new imperative of patient engagement for hospitals and health systems. Health Affairs Blog. http://healthaffairs.org/blog/2013/02/15/the-new-im perative-of-patient-engagement-for-hospitals-and- health-systems/ (acce ssed April 9, 2014). Rolfe, I. E., and R. W. Sanson-Fisher. 2002. Translatin g learning principles into practice: A new strategy for learning clinical skills. Medical Education 36(4):345-352. Ronda, G., J. Grispen, M. Ickenroth, G.-J. Dinant, N. De Vries, and T. Van der Weijden. 2014. The effects of a Web-based decision aid on the intention to diagnostic self-testing for cholesterol and diabetes: A randomized controlled trial. BMC Public Health 14(1):1-12. Ross, J. S. 2014. Editor's note: Ensuring corr ect interpretation of diagnostic test results. JAMA Internal Medicine 174(6):993. Rubi n, Z., and K. Blackham. 2015. The state of radiologic teaching practice in preclinical medical education: Survey of American medical, osteopat hic, and podiatric schools. Journal of the American College of Radiology 12(4):403-408. Ryan, C. 2013. Language use in the United States: 2011, American community survey reports. www.census.gov/prod/2013pubs/acs-2 2.pdf (accessed July 25, 2015). Safran, D. G., M. Kosinski, A. R. Tarlov, W. H. Rogers, D. H. Taira, N. Lieberman, and J. E. Ware. 1998. The primary care assessment survey: Tests of data quality and measurement performance. Medical Care 36(5):728-739. Salas, E., D. DiazGranados, S. J. Weaver, and H. King. 2008. Does team training work? Principles for health care. Academic Emergency Medicine 15(11):1002-1009. 4-54 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Santoso, J. T., B. Schwertner, R. L. Coleman, and E. V. Hannigan. 2004. Tumor board in gynecologic oncology. International Journal of Gynecological Cancer 14(2):206-209. Sarkar, U., D. Bonacum, W. Strull, C. Spitzmueller, N. Jin, A. Lopez, T. D. Giardina, A. N. Meyer, and H. Singh. 2012. Challenges of making a diagnosis in the outpa tient setting: A multi-site survey of primary care physicians. BMJ Quality and Safety 21(8):641-648. Sarkar, U., B. Simchowitz, D. Bonacum, W. Strull, A. Lopez, L. Rotteau, and K. Shojania. 2014. A qualitative analysis of physician perspectives on missed and delayed outpatient diagnosis: The focus on system-related factors. Joint Commission Journal on Quality and Patient Safety 40(10):461-470. Sawyer, K. R. 2008. Optimising learning: Implications of learning sciences research . Paris: OECD. www.oecd.org/edu/ceri/40805146.p df (accessed June 5, 2015). Sawyer, R. K. (ed.). 2006. The Cambridge handbook of the learning sciences . New York: Cambridge University Press. Say, R., M. Murtagh, and R. Thoms on. 2006. Patients' preference for invo lvement in medical decision making: A narrative review. Patient Education and Counseling 60(2):102-114. SCAI (Society for Cardiovascular Angiography and Interventions). 2014. SCAI expands auc calculator app to support clinical decision making for diagnostic catheterization and imaging for heart failure: Society for Cardiovascular Angiography and Interventions. http://www.scai.org/Press/detail.aspx?cid=edaf8ad9-4d7a- 4147-ac4f-4d62 ssed June Scalese, R., V. Obeso, and S. B. Issenberg. 2008. Simulation technology for skills training and competency assessment in medical education. Journal of General Internal Medicine 23(Suppl 1):46-49. Schiff, G.D. 2008. Minimizing diagnostic error: The importance of follow-up and feedback. American Journal of Medicine 121(5):S38-S42. Schiff. G.D. 2014a. Presentation. Pres entation to IOM Committee on Diagnostic Error in Health Care, August 7, 2014, Washington, DC. Schiff, G. D. 2014b. Diagnosis and diagnostic errors: ti me for a new paradigm. BMJ Quality and Safety 23(1):1-3. Schiff, G. D., O. Hasan, S. Kim, R. Abrams, K. Cosby, B. L. Lambert, A. S. Elstein, S. Hasler, M. L. Kabongo, N. Krosnjar, R. Odwazny, M. F. Wisniewski, and R. A. McNutt. 2009. Diagnostic error in medicine: Analysis of 583 physician-reported errors. Archives of Internal Medicine 169(20):1881-1887. Schiff, G., P. Griswold, B. R. Ellis, A. L. Puopolo, N. Br ede, H. R. Nieva, F. Federi co, N. Leydon, J. Ling, D. Wachenheim, L. L. Leape, and M. Biondolillo. 2014. Doing right by our patients when things go wrong in the ambulatory setting. Joint Commission journal on quality and patient safety/Joint Commission Resources 40(2): 91-96. Schillinger, D., J. Piette, K. W ilson, C. Daher, K. Leong-Gro tz, C. Castro, and A. B. Bindman. 2003. Closing the loop: Physician communication with diabetic patients who have low health literacy. Archives of Internal Medicine 163(1):83-90. Schmitt, M., A. Blue, C. A. Aschenbrener, and T. Viggiano. 2011. Core competen cies for interprofessional collaborative practice: Reforming h ealth care transforming heal th professionals' education. Academic Medicine 86(11):1351. Schoen, C., R. Osborn, M. M. Doty, M. Bishop, J. Pe ugh, and N. Murukutla. 2007. Toward higher-performance health systems: Adults' health care experiences in seven countries, 2007. Health Affairs 26(6):w717-w734. Schulman, K. A., J. A. Berlin, W. Harless, J. F. Kerner, S. Sistrunk, B. J. Gersh, R. Dub\u00e9, C. K. Taleghani, J. E. Burke, S. Williams, J. M. Eisenberg, W. Ayers, and J. J. Escarce. 1999. The effect of race and sex on physicians' recommendations for cardiac catheterization. New England Journal of Medicine 340(8):618- 626. Schwartz, M. B., H. O'Neal Chambliss, K. D. Brownell, S. N. Blair, and C. Billington. 2003. Weight bias among health professionals specializing in obesity. Obesity Research 11(9):1033-1039. Seegmiller, A. C., A. S. Kim, C. A. Mosse, M. A. Levy, M. A. Thompson, M. K. Kressin, M. H. Jagasia, S. A. Strickland, N. M. Reddy, E. R. Marx, K. J. Sinkfield, H. N. Pollard, W. D. Plummer, W. D. Dupont, E. K. Shultz, R. S. Dittus, W. W. Stead, S. A. Santoro, and M. M. Zutter. 2013. Optimizing personalized bone marrow testing using an evidence-based, interdisciplinary team approach. American Journal of Clinical Pathology 140(5):643-650. Semigran, H. L., J. A. Linder, C. Gidengil, and A. Mehrotra. 2015. Evaluation of symptom checkers for self diagnosis and triage: Audit study. BMJ 351:h3480. Sequist, T., E. Schneider, M. Anastari o, E. Odigie, R. Marshall, W. Rogers, and D. Safran. 2008. Quality monitoring of physicians: Linking patients' experiences of care to clinical quality and outcomes. Journal of General Internal Medicine 23(11):1784-1790. DIAGNOSTIC TEAM MEMBERS & TASKS 4-55 PREPUBLICATION COPY: UNCORRECTED PROOFS Shojania, K. G., I. Silver, and W. Levinson. 2012. Continuing medical education and quality improvement: A match made in heaven? Annals of Internal Medicine 156(4):305-308. Shumate, M., R. Ibrahim, and R. Levitt. 2010. Dynamic in formation retrieval and allocation flows in project teams with discontinuous membership. European Journal of International Management 4(6):556-575. SIDM (Society to Improve Diagnosis in Medicine) and NPSF (National Patient Safety Foundation). 2014. Reducing diagnostic error: Nurses and clinical staff: Ten things I could do tomorrow. http://c.ymcdn.com/sites/www. npsf.org/resource/collectio n/0716DBAD-99BB-460E-9837- 1E357423C51C/Reducing-Diagnostic-Error-Nurses-and-Clinical-Staff-Ten-Things-I-Could-Do- Tomorrow.pdf (accessed May 11, 2015). SIDM. 2015. Patient Toolkit. http://www.improvediagnosis.org/?page=PatientToolkit (accessed August 27, 2015). Singh, H. 2014. Building a robust conceptual foundation for defining and measuring diagnostic errors. Presentation to the Committee on Diagnostic Error in Health Care, August 7, 2014, Washington, DC. Smith, B. R., M. Aguero-Rosenfeld, J. Anastasi, B. Baron, A. Berg, J. L. Bock, S. Campbell, K. P. Crookston, R. Fitzgerald, M. Fung, R. Haspel, J. G. Howe, J. Jhan g, M. Kamoun, S. Koethe, M. D. Krasowski, M. L. Landry, M. B. Marques, H. M. Rinder, W. Roberts, W. E. Schreiber, S. L. Spitalnik, C. A. Tormey, P. Wolf, and Y. Y. Wu. 2010. Educating medical students in laboratory medicine: A proposed curriculum. American Journal of Clinical Pathology 133(4):533-542. Smith, T. J., and D. L. Longo. 2012. Talking with patients about dying. The New England Journal of Medicine 367(17):1651. Soni, K., and G. Dhaliwal. 2012. Misleading complaint: Commentary Soni, M.D., M.B.A., and Gurpreet Dhaliwal, M.D. http://w ebmm.ahrq.gov/case.aspx?caseID= 273 (accessed June 5, 2015). Sorbero, M. E., D. O. Farley, S. Mattke, and S. L. Lovejoy. 2008. Outcome measures for effective teamwork in inpatient care: Final report. Santa Monica, CA: RAND Corporation. Spain, E. 2014. Do doctors spend too much time looking at computer screen? Gazing at electronic health records diverts doctors' attention from patients. Northwestern University, January 23. www.northwestern.edu/newscenter/stories/2014/01/do-doctors-spend-too-much-time-looking-at-computer- screen.html (accessed June 5, 2015). Starfield, B. 2000. Is U.S. health really the best in the world? JAMA 284(4):483-485. Stark, M., and J. J. Fins. 2014. The ethical imperative to think about thinking: Diag nostics, metacognition, and medical professionalism. Cambridge Quarterly of Healthcare Ethics 23(4):386-396. Stevenson, F. A. 2003. General practitioners' views on shared decision making: A qualitative analysis. Patient Education and Counseling 50(3):291-293. Straus, C. M., E. M. Webb, K. L. Kondo, A. W. Phillips, D. M. Naeger, C. W. Carrico, W. Herring, J. A. Neutze, G. R. Haines, and G. D. Dodd, 3rd. 2014. Medical student radiology education: Summary and recommendations from a national survey of medical school and radiology department leadership. Journal of the American College of Radiology 11(6):606-610. Stremikis, K., Schoen, C., Fryer, A.K. 2011. A call for change: The 2011 Common wealth Fund survey of public views of the U.S. health system. Commonwealth Fund issue brief. http://www.commonwealthfund.org/~/media/Files/Pub lications/Issue%20Brief/2011/Apr/1492_Stremikis_ public_views_2011_survey_ib.p df (accessed June 5, 2015). Su, E., T. A. Schmidt, N. C. Mann, and A. D. Zechnich . 2000. A randomized controlle d trial to assess decay in acquired knowledge among paramedics completing a pediatric resuscitation course. Academic Emergency Medicine 7(7):779-786. Sutcliffe, K. M., E. Lewton, and M. M. Rosenthal. 20 04. Communication failures: An insidious contributor to medical mishaps. Academic Medicine 79(2):186-194. Swain, M., and V. Patel. 2014. Patient access to test results among clinical la boratories. ONC Data Brief No. 13:1-9. Washington, DC: Office of the National Coordinator for Health Information Technology. http://www.healthit.gov/sites/default/f iles/onc-data-brief-13-labsurveydat abrief.pdf (accessed June 5, 2015). Swensen, S., M. Pugh, C. McMullan, and A. Kabcenell. 2013. High-impact leadership : Improve care, improve the health of populations, and reduce costs. White Paper. Institute for Healthcare Improvement. Talbert, M. L., E. R. Ashwood, N. A. Brownlee, J. R. Clar k, R. E. Horowitz, R. B. Lepoff, A. Neumann, C. N. Otis, S. Z. Powell, and T. M. Sodeman. 2009. Resident preparation for practice: a white paper from the College o f American Pathologists and Association of Pathology Chairs. Archives of Pathology & Laboratory Medicine 133(7):1139-1147. 4-56 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Taylor, C. R., B. R. DeYoung, and M. B. Cohen. 2008. Pathology education: quo vadis?. Human Pathology 39(11):1555-1561. Teherani, A., D. M. Irby, and H. Loeser. 2013. Outcomes of different clerkship models: Longitudinal integrated, hybrid, and block. Academic Medicine 88(1):35-43. Teirstein, P. S. 2015. Boarded to death\u2014Why maintenance of certification is bad for doctors and patients. New England Journal of Medicine 372(2):106-108. Thibault, G. E. 2013. Reforming health professions edu cation will require culture chan ge and closer ties between classroom and practice. Health Affairs 32(11):1928-1932. Torre, D. M., B. J. Daley, J. L. Sebastian, and D. M. Elnicki. 2006. Overview of current learning theories for medical educators. American Journal of Medicine 119(10):903-907. Trowbridge, R. 2014. Diagnostic perf ormance: Measurement and feedback. Presentation to the Committee on Diagnostic Error in Health Care, August 7, 2014, Washington, DC. Trowbridge, R., G. Dhaliwal, and K. Cosby. 2013. Educational agenda for diagnostic error reduction. BMJ Quality and Safety 22(Suppl 2):ii28-ii32. University of Pittsburgh. 2015. Institu te for Doctor-Patient Communication. www.dom.pitt.edu/dgim/IDPC/about.h tml (accessed March 26, 2015). Vashdi, D. R., P. A. Bamberger, and M. Erez. 2013. Can surgical teams ever learn? The role of coordination, complexity, and transitivity in action team learning. Academy of Management Journal 56(4):945-971. Walker, J., J. D. Darer, J. G. Elmore, and T. Delbanco. 2014. The road toward fully transparent medical records. New England Journal of Medicine 370(1):6-8. Weaver, S. J., S. M. Dy, and M. A. Rosen. 2014. Team-training in healthcare: A narrative synthesis of the literature. BMJ Quality and Safety 23(5):359-372. Weed, L. L. and L. Weed. 2014. Diagnosing diagnostic failure. Diagnosis 1(1):13-17. Wegwarth, O., W. Gaissmaier, and G. Gigerenzer. 2009. Smart strategies for doctors and doctors-in-training: Heuristics in medicine. Medical Education 43(8):721-728. Weingart, S. N. 2013. Patient engagement and patient safety. Agency for Healthcare Quality and Research. http://webmm.ahrq.gov/perspec tive.aspx?perspectiv eID=136 (accessed February 7, 2014). Weingart, S. N., O. Pagovich, D. Z. Sands, J. M. Li , M. D. Aronson, R. B. Davis, D. W. Bates, and R. S. Phillips. 2005. What can hospitalized patients tell us about adverse events? Learning from patient-reported incidents. Journal of General Internal Medicine 20(9):830-836. WHO (World Health Organization). 2010. Framework for action on interprofessional education and collaborative practice. Geneva: World Health Organization. Wilson, M. L. 2010. Educating medical students in laboratory medicine. American Journal of Clinical Pathology 133(4):525-528. Wilson-Stronks, A., and E. Galvez. 2007. Hospitals, language, and culture: A snapshot of the nation, exploring cultural and linguistic services in the nation's hospitals . The Joint Commission. http://www.jointcommission.org/ assets/1/6/hlc_paper.pdf (accessed June 5, 2015). Xyrichis, A., and E. Ream. 2008. Teamwork: A concept analysis. Journal of Advanced Nursing 61(2):232-241. Yarnall, K. S., K. I. Pollak, T. Ostbye, K. M. Krause, an d J. L. Michener. 2003. Primar y care: Is there enough time for prevention? American Journal of Public Health 93(4):635-641. Yang, H., C. Thompson, and M. Bland. 2012. The effect of clinical experience, judgme nt task difficulty and time pressure on nurses' confidence calibration in a high fidelity clinical simulation. BMC Medical Informatics and Decision Making 12(1):113. Yedidia, M. J., C. C. Gillespie, E. Kachur, M. D. Schwar tz, J. Ockene, A. E. Chepaitis, C. W. Snyder, A. Lazare, and M. Lipkin Jr. 2003. Effect of communications training on medical student performance. JAMA 290(9):1157-1165. Zhi, M., E. L. Ding, J. Theisen-Toupal, J. Whelan, and R. Arnaout. 2013. The landscape of inappropriate laboratory testing: A 15-year meta-analysis. PLoS One 8(11):e78962. Zimmerman, T. M., and G. Amori. 2007. Including patients in root cause and system failure analysis: Legal and psychological implications. Journal of Healthcare Risk Management 27(2):27-34. Zimring, C., A. Joseph, and R. Choudhary. 2004. The role of the physical environment in the hospital of the 21st century: A once-in-a-lifetime opportunity . Concord, CA: The Center for Health Design. A Figure 5 - tools. H e health re c provider exchang e process: diagnost i testing r e process. this cha p process. FIGUR E diagnost i Tech n A wide varie t -1), but the p ealth IT cov e cords (EHR s order entry, es, and med i information ic process, i n esults; and t h Other techn o pter briefly r e E 5-1 Techn o ic process o c PREPUBL Inology a ty of techno l primary foc u ers a broad r a s), clinical d laboratory a ical devices. exchange; t ncluding th e he shaping o ologies, suc h eviews the u ologies and t ccurs. ICATION C Oand Too l logies and t o us of the cha p ange of tec h decision sup p and medical Health IT p the capturin g e clinical his t f a clinician h as diagnos use of mobil e tools are on e 5-1 OPY: UNCO R5 s in the D ools are inv o pter is on h e nologies us e port, patient imaging in f plays key rol e g of informa t tory and int e 's workflo w tic testing, a e health app s e important e RRECTED P RDiagno s olved in the d ealth inform a ed in health c engagemen t formation s y es in variou s tion about a erview, phy s w and decisi o are discusse d s and telem e element of t h ROOFS stic Pro c diagnostic p r ation techno care, includ i t tools, com p ystems, heal t s aspects of t patient that sical exam, a on making i n d in Chapter edicine in th e he work sys cess rocess (see logy (healt h ing electron i puterized th informati o the diagnos t informs the and diagnos t n the diagno s 2. In additi o e diagnostic tem in whic h h IT) ic on tic tic stic on, h the 5-2 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS The committee concluded that health IT has the potential to impact the diagnostic process in both positive and negative ways . When health IT tools suppor t diagnostic team members and tasks in the diagnostic process and reflect human-centered design principles, health IT has the potential to improve diagnosis and reduce diagnostic errors. De spite this potential, however, there have been few demonstra tions that health IT actually improves diagnosis in clinical practice (El-Kareh et al., 2013). I ndeed, many experts are concerned that current health IT tools are not effectively facilitating th e diagnostic process and may be c ontributing to diagnostic errors (Basch, 2014; Berenson et 2014b; Verghese, 2008). This chapter discusses th e design of health IT for the diagnostic process, the interoperability of patient health information, patient safety issues related to the use of health IT, and the potential fo r health IT to aid in the meas urement of diagnostic errors. The committee makes one recommendation aimed at ensu ring that health IT tools and technologies facilitate timely and accurate diagnoses. This content builds on earlier Institute of Medicine (IOM) work, including the report Health IT and Patient Safety: Building a Safer Health System (IOM, 2012a), which highlighted the impact of health IT on patient safety. That report emphasized that health IT functions within the context of a larger socio- technical system involving the technology itself, the people who work within the system, the workflow (or actions and procedures clinicians are anticipated to perform as they deliver care), the organi zation using the technology, and the external environment. Box 5-1 includes the recommendations from the 2012 report; this chapter's text references these recommendations where relevant. BOX 5-1 Recommendations from Health IT and Patient Safety: Building a Safer Health System Recommendation 1: The Secretary of Health and Human Services (HHS) should publish an action and surveillance plan within 12 months that includes a schedule for working with the private sector to assess the impact of health IT [health information technology] on patient safety and minimizing the risk of its implementation and use. The plan should specify: a. The Agency for Healthcare Research and Quality (AHRQ) and the National Library of Medicine (NLM) should expand their funding of research, training, and education of safe practices as appropriate, including measures specifically related to the design, implementation, usability, and safe use of health IT by all users, including patients. b. The Office of the National Coordinator (ONC) for Health Information Technology should expand its funding of processes that promote safety that should be followed in the development of health IT products, including standardized testing procedures to be used by manufacturers and health care organizations to assess the safety of health IT products. c. The ONC and AHRQ should work with health IT vendors and health care organizations to promote post-deployment safe ty testing of EHRs for high-prevalence, high-impact EHR-related patient safety risks. d. Health care accrediting organizations should adopt criteria relating to EHR safety. e. AHRQ should fund the development of new methods for measuring the impact of health IT on safety using data from EHRs. Recommendation 2: The Secretary of HHS should ensure insofar as possible that health IT vendors support the free exchange of information about health IT experiences and issues and TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS 5-3 PREPUBLICATION COPY: UNCORRECTED PROOFS not prohibit sharing of such information, including details (e.g., screenshots) relating to patient safety. Recommendation 3: The ONC should work with the private and public sectors to make comparative user experiences ac ross vendors publicly available. Recommendation 4: The Secretary of HHS should fund a new Health IT Safety Council to evaluate criteria for assessing and monitoring the safe use of health IT and the use of health IT to enhance safety. This council should operate within an existing voluntary consensus standards organization. Recommendation 5: All health IT vendors should be required to publicly register and list their products with the ONC, initially beginning with EHRs certified for the meaningful use program. Recommendation 6: The Secretary of HHS should specify the quality and risk management process requirements that health IT vendors must adopt, with a particular focus on human factors, safety culture, and usability. Recommendation 7: The Secretary of HHS should establish a mechanism for both vendors and users to report health IT-related deaths, serious injuries, or unsafe conditions. a. Reporting of health IT-related adverse events should be mandatory for vendors. b. Reporting of health IT-related adverse events by users should be voluntary, confidential, and non-punitive. c. Efforts to encourage reporting should be developed, such as removing the perceptual, cultural, contractual, legal, and logistical barriers to reporting. Recommendation 8: The Secretary of HHS should recommend that Congress establish an independent federal entity for investigating patient safety deaths, serious injuries, or potentially unsafe conditions associated with health IT. This entity should also monitor and analyze data and publicly report results of these activities. Recommendation 9a: The Secretary of HHS should monitor and publicly report on the progress of health IT safety annually beginning in 2012. If progress toward safety and reliability is not sufficient as determined by the Secretary, the Secretary should direct the Food and Drug Administration (FDA) to exercise all available authorities to regulate EHRs, health information exchanges, and personal health records. Recommendation 9b: The Secretary should immediately direct FDA to begin developing the necessary framework for regulation. Such a framework should be in place if and when the Secretary decides the state of health IT safety requires FDA regulation as stipulated in Recommendation 9a above. Recommendation 10: HHS, in collaboration with other research groups, should support cross-disciplinary research toward the use of health IT as part of a learning health care system. Products of this research should be used to inform the design, testing, and use of health IT. Specific areas of research include a. User-centered design and human factors applied to health IT, b. Safe implementation and use of health IT by all users, c. Socio-technical systems associated with health IT, and 5-4 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS d. Impact of policy decisions on health IT use in clinical practice. SOURCE: IOM, 2012a. DESIGN OF HEALTH IT FOR THE DIAGNOSTIC PROCESS The design of health IT has th e potential to support the diagno stic process. In particular, by supporting the individuals involved in the di agnostic process and the tasks they perform, health IT may improve diagnostic performance and reduce the potential for diagnostic errors. The increasing complexity of health care has re quired health professionals to know and apply vast amounts of information, and these demands are outstripping human cognitive capacity and contributing to challenges in diagnosis (see Chapte r 2). El-Kareh et al. (2013, p. ii40) asserted that \"[u]naided clinicians often make diagnostic errors\" because they are \"[v]ulnerable to fallible human memory, variable disease presentation, clinical disease processes plagued by communication lapses, and a series of well-documen ted 'heuristics,' biases and disease-specific pitfalls.\" It is widely recognized that health IT has the potential to he lp health professionals address or mitigate these human limitations. Although health IT interventions are not appropr iate for every quality-of-care challenge, there are opportunities to improve diagnosis through appropriate use of health IT. For instance, a well-designed health IT system can facilitate timely access to information; communication among health care professionals, patients, and th eir families; clinical reasoning and decision making; and feedback and follow-up in the diagno stic process (El-Kareh et al., 2013; Schiff and Bates, 2010). Table 5-1 describes a number of opportunities to reduce di agnostic errors through the use of health IT. The range of these suggest ions is broad; some are pragmatic opportunities for intervention and others are mo re visionary, given the limitations of today's health IT tools. TABLE 5-1 Opportunities to Reduce Diagnostic E rror through Elect ronic Clinical Documentation Role for Electronic Documentation Goals and Features of Redesigned Systems Providing access to information Ensure ease, sp eed, and selectivity of information searches; aid cognition through aggregation, trending, contextual relevance, and minimizing of superfluous data. Recording and sharing assessments Provide a space for recording thoughtful, succinct assessments, differential diagnoses, contingencies, and unanswered questions; facilita te sharing and review of assessments by both patient and other clinicians. Maintaining dynamic patient history Carry forward information for recall, avoiding repetitive patient querying and record ing while minimizing copying and pasting. Maintaining problem lists Ensure that problem lists are integrated into workflow to allow for continuous updating. Tracking medications Record medications th at the patient is actually taking, patient responses to medications, and adverse effects in order to avert misdiagnoses and ensure timely recognition of TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS 5-5 PREPUBLICATION COPY: UNCORRECTED PROOFS medication problems. Tracking tests Integrate management of diagnostic test results into note workflow to facilitate review, assessment, and responsive action as well as documentation of these steps. Ensuring coordination and continuity Aggregate and integrate data from all care episodes and fragmented encounters to permit thoughtful synthesis. Enabling follow-up Facilitate patient education about potential red-flag symptoms; track follow-up. Providing feedback Automatically provide feedback to clinicians upstream, facilitating learning from outco mes of diagnostic decisions. Providing prompts Provide checklists to minimize reliance on memory and directed questioning to aid in diagnostic thoroughness and problem solving. Providing placeholder for resumption of work Delineate clearly in the record where clinician should resume work after interruption, preventi ng lapses in data collection and thought process. Calculating Bayesian probabilities Embed calculator into notes to reduce errors and minimize biases in subjective estimati on of diagnostic probabilities. Providing access to information sources Provide instant access to knowledge resources through context-specific \"infobuttons\" triggered by keywords in notes that link user to rele vant textbooks and guidelines Offering second opinion or consultation Integrate immediate online or telephone access to consultants to answer questions related to referral triage, testing strategies, or definitive diagnostic assessments. Increasing efficiency More thoughtfu l design, workflow integration, and distribution of documentati on burden could speed up charting, freeing time for communication and cognition. SOURCE: Schiff and Bates, 2010. New England Journal of Medicine G. Schiff and D. W. Bates. Can electronic clinical documentation help prevent diagnostic e rrors? 362(12):1066-1069. 2010. Massachusetts Medical Society. Reprinted with permission from Massachusetts Medical Society. A number of researchers have identified patient safety risks that may result from poorly designed health IT tools (Ha rrington et al., 2011; IOM, 2012a; Meeks et al., 2014; Sittig and Singh, 2012; Walker et al., 2008). In recognition of these risks, the 2012 IOM report described the key attributes of safe h ealth IT, including (IOM, 2012a, p.78): Easy retrieval of accurate, timely, and reliable native and imported data; A system the user wants to interact with; Simple and intuitive data displays; Easy navigation; Evidence at the point of car e to aid decision making; Enhancements to workflow, automating mundane tasks, and streamlining work, never increasing physical or cognitive workload; Easy transfer of information to and fro m other organizations and clinicians; and No unanticipated downtime. 5-6 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS If health IT products do not have these features, it may be diff icult for users to effectively interact with the technology, contributing to workarounds (alternate pathways to achieve a particular functionality) or unsaf e uses of the technology, as well as errors associated with the correct use of the technology. A lthough many of these risks apply to health care broadly, the committee concluded that health IT risks are par ticularly concerning for the diagnostic process. Poor design, poor implementation, and poor use of health IT can impede the diagnostic process at various junctures throughout the process. For in stance, a confusing or cluttered user interface could contribute to errors in information integrat ion and interpretation that result in errors in diagnosis. Poor integration of health IT tool s into clinical workfl ow may create cognitive burdens for clinicians that take time away from clinical reasoning activities. To ensure that health IT suppor ts patients and health care pr ofessionals in the diagnostic process, collaboration between the federal government and the health IT industry is warranted. The 2012 IOM report concluded that the safety of health IT is a shared responsibility and described the ways in which health IT vendors, users, governmental agencies, and others can collaborate to improve the safety of health IT. For example, by working with users, health IT vendors can work to improve safety during all phases of the design of their products, from requirements gathering to product testing. In ad dition, the report called on the Office of the National Coordinator for Health Information Technology (ONC) to expand funding for processes that promote safety in the developmen t of health IT products (IOM, 2012a). In line with these recommendations, the committee recommends that health IT vendors and ONC should work together with users to ensure that health IT used in the diagnostic process demonstrates usability, incorporates human factors knowledge, integrates measurement capability, fits well within clinical workfl ow, provides clinical decision support, and facilitates the timely flow of information among patients and health care professionals involved in the diagnostic process. Collaboration among health IT vendors, ONC, and users can help to identify best practices in the desi gn, implementation, and use of health IT products used in the diagnostic process. Further research in designing health IT fo r the diagnostic process is also needed (see Chapter 8). The sections below describe the importance of these various features in the design of health IT for the dia gnostic process. The comm ittee did not want to impose specific requirements for how this recommendation is implemented, because the approach would be too proscriptive. The committee's recommendation emphasizes that collaboration is needed among the health IT ve ndor community, ONC, and users, and it outlines the essential characteristics of health IT to improve diagnosis and reduce diagnostic errors. Users include a wide variety of clinicia ns (such as treating health care professionals and clinicians with diagnostic testing expertise), as well as patients and their families (HIMSS, 2014). Usability and Human Factors The potential benefits of health IT for im proving diagnosis cannot be realized without usable, useful health IT systems. Usability has b een defined as \"the exte nt to which a product can be used by specified users to achieve specified goals with effectiveness, efficiency, and satisfaction in a specified context of use\" (ISO, 1998). According to the Healthcare Information Management Systems Society (HIMSS), a system e xhibits good usability when it is \"easy to use and effective. It is intuitive, forgiving of mi stakes and allows one to perform necessary tasks quickly, efficiently and with a minimum of ment al effort. Tasks which can be performed by the TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS 5-7 PREPUBLICATION COPY: UNCORRECTED PROOFS software . . . are done in the background, improv ing accuracy and freeing up the user's cognitive resources for other tasks\" (HIMSS, 2009, p. 3). Recent discussions of usability have focuse d on the importance of incorporating design principles that take human factors1 into account (Middleton et al ., 2013). A number of terms have been used to describe the optimal desi gn approach, including human-centered design, user- centered design, use-centered design, and partic ipatory design. The committee opted for the more inclusive term, human-centered design, to describe how the involvement of all stakeholders, rather than just users, is affect ed by the health IT system. A human-centered design approach balances the requirements of both the t echnical system of comput ers and software with the larger socio-techni cal system (Gasson, 2003). Although some health IT vendors have adopted human-centered design principles , the practice is not universal (AHRQ, 2010). Furthermore, usability challenges may be an emergent property that only be comes evident after the system was implemented or after it was in widespread use. Accordingly, it is important to make continuous improvements to the design, implementation, and use of health IT (Carayon et al., 2008). Opportunities to assess the effects of technology on the diagnostic process are discussed in Chapter 3. Although clinicians have reported a high level of use and satisfaction with certain health IT features, such as electronic prescribing (Mak am et al., 2013), a number of challenges with usability remain, and the National Institute of Standards and Technology has indicated that usability is often overlooked in the adoption of EHR systems (NIST, 2015). Health IT that is not designed and implemented to support the diagnos tic process can increase vulnerability to diagnostic errors. The American Medical Associ ation (AMA) recently rel eased a statement that health IT is misaligned with the cognitive and workflow requirements of medicine and listed eight priorities for improving the usabili ty of EHRs (see Box 5-2) (AMA, 2014). BOX 5-2 American Medical Association's Improving Care: Priorities to Improve Electronic Health Record Usability Enhance physicians' ability to provide high-quality patient care. Effective communication and engagement between patients and physicians should be of central importance in EHR design. The EHR should fit seamlessly into the practice and not distract physicians from patients. Support team-based care. EHR design and configuration must (1) facilitate clinical staff to perform work as necessary and to the extent their licensure and privileges permit and (2) allow physicians to dynamically allocate and delegate work to appropriate members of the care team as permitted by institutional policies. Promote care coordination. EHRs should have an enhanced ability to automatically track referrals and consultations as well as to ensure that the referring physician is able 1 Human factors (or ergonomics) is defined as \"the scientific discipline concerned with the understanding of interactions among humans and other el ements of a system, and the profession that applies theory, principles, data and methods to design in order to optimize human well- being and overall system performance. Practitioners of ergonomics and ergonomists contribute to the design and evaluation of tasks, jobs, products, environments and systems in order to make them compatible with the needs, abilities and limitations of people\" (IEA, 2000). 5-8 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS to follow the patient's progress/activity throughout continuum of care. Offer product modularity and configurability. Modularity of technology will result in EHRs that offer the flexibility necessary to meet individual practice requirements. Application program interfaces can be an important contributor to this modularity. Reduce cognitive workload. EHRs should support medical decision making by providing concise, context-sensitive, and real-time data uncluttered by extraneous information. EHRs should manage information flow and adjust for context, environment, and user preferences. Promote data liquidity. EHRs should facilitate connected health care\u2014interoperability across different venues such as hospitals, ambulatory care settings, laboratories, pharmacies and post-acute and long-term-care settings. This means not only being able to export data but also to properly incorporate external data from other systems into the longitudinal patient record. Data sharing and open architecture must address EHR data \"lock in.\" Facilitate digital and mobile patient engagement. Whether for health and wellness or the management of chronic illnesses, interoperability between a patient's mobile technology and the EHR will be an asset. Expedite user input into product design and post-implementation feedback. An essential step to user-centered design is incorporating end-user feedback into the design and improvement of a product. EHR technology should facilitate this feedback. SOURCE: Copyright 2014 American Medical Association. All Rights Reserved. As mentioned in Box 5-2, a major issue relate d to health IT is how it will affect the patient-clinician relationship. The hope is that health IT will enhance patient and clinician communication by, for example, improving the co llaboration and engagement between them by facilitating patient access to health information a nd clinical visit notes (s ee Chapter 4). However, this needs to be facilitated by health IT tools that assist patients and their families in engaging in the diagnostic process. As disc ussed in Recommendation 1, patient access to clinical notes is critical, but it is hoped th at health IT tools will facilitate engagement in the diagnostic process. For example, patient portals provide patients with access to their medical information, but poor usability\u2014including navigational problems and un met expectations about functionality\u2014can hinder adoption of such tools among patients (Greenhalgh 2010). Additional patient-facing health IT tools include mHealth applications, such as symptom checkers, but concerns about their validity are ongoing (see section on mHea lth) (Jutel and Lupton, 2015; Semigran et al., 2015). In addition, there are concer ns that clinicians may be un willing or not know how to act on information collected by patients though mHealt h, wearable technologie s, or other forums (Dwoskin and Walker, 2014; Ramirez, 2012). Furthermore, there are also si gnificant concerns that \"tec hnology is cleaving the sacred bond between doctor and patient\" and that the EHR distracts clinicians from patient-centered care (Wachter, 2015). One article suggested that the EHR has negatively affected the clinician- patient bond by prioritizing the computer above the patient. In this view, the patient is no longer the most important thing in the examining room b ecause the machine, rather than the patient, has TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS 5-9 PREPUBLICATION COPY: UNCORRECTED PROOFS become the center of the clinician's focus (Obe r, 2015). Verghese descri bed this phenomenon as the emergence of the iPatient (or the EHR as a surrogate for a real patient), arguing that there is a real danger to reducing the atten tion paid to the patient: \"If one eschews the skilled and repeated examination of the real patient, then simple diagnoses and new developments are overlooked, while tests, consultations, and procedures that might not be needed are ordered\" (Verghese, 2008). An important component of usability is whet her it supports teamwork in the diagnostic process. Health IT has the potential to streng then intra- and interp rofessional teamwork, by providing structural support for enhanced coll aboration among the health care professionals involved in the diagnostic process. There is evid ence that EHRs facilitate primary care teamwork via enhanced communication, redefined team role s, and improved delegation (O'Malley et al., 2015). However, this is not the case across the board; the American Medical Association has noted that many EHR systems \"are not well configur ed to facilitate team-based care and require physicians to enter data or perform tasks that other team members should be empowered to complete\" (AMA, 2014, p. 5). Reducing the cognitive burdens on clinicians is another key f eature of usable health IT systems. Health IT has the potential to support clinicians in the diagnos tic process by managing information flow and filtering and presenting information in a way that facilitates decision making. A thoughtfully designed user interface has th e potential to help clinicians develop a more complete view of a patient's condition by capturing and presenting all of the patient's health information in one place. In particular, the problem lis t feature of EHRs can help clinicians to quickly see a patient's most important health problem; it is a way of organizing a patient's health information within the health record. The problem list deri ves from the problem-oriented medical record (POMR), developed by Lawrence Weed (Jacobs, 2009). \"Problem-oriented\" has two interrelated meanings (Weed and Weed, 2011, p. 134): the information in the medical record is organized by the patient problem to which the information relates (as disti nguished from the traditional arrangement by source, with doctors' notes in one place, nurses' notes in another, lab data in another, etc.), and problems are defined in terms of the patient 's complete medical needs rather than providers' beliefs or specialty orientati on (thus, for example, the record should cover not just the 'chief complaint' bu t all identified medical needs, and those needs should be defined in terms of th e problems requiring solution, not in terms of providers' diagnostic hypothe ses or treatment plans). The problem list includes all pa st and present diagnoses, as we ll as the time of occurrence and whether the problem was resolved, and links to further information on each entry in the list (Weed, 1968; AHIMA, 2011). Although studies have shown that use of high- quality problem lists is associated with better patient care (Hartung 2005; Simborg 1976), va riability in the structure and content of problem lists has limited its effectiveness in improving patient care (Holmes 2012; AHIMA 2011). There is a move to standardize the structur e and content of problem lists in EHRs through the use of diagnostic and problem codes (AHIMA , 2011). To encourage this change, meaningful 5-10 IMPROVING DIAG NOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS use criteria require that participants maintain up-to-date, coded problem list for at least 80 percent of their patients (AHIMA, 2011). Unfortunately, poorly designed health IT systems, such as those with confusing user- interfaces and disorganized patient information, may contribute to cognitive overload rather than easing the cognitive burden on clinicians. Poorly designed systems can detract from clinician efficiency and impede information integration and interpretation in th e diagnostic process. A recent analysis of the graphical display of diagnos tic test results in EHRs found that few of the current EHRs meet evidence-based criteria fo r how to improve comprehension of such information (Sittig et al., 2015). For example, one EHR system graphed diagnostic testing results in reverse chronological order; non e of the EHRs in the analysis had graphs with y-axis labels that displayed both the name of the variable and the units of measur ement. Human factors engineering approaches, such as a heuristic evaluation or an asse ssment of how well a particular interface design complies with established design principles for usability, could help identify usability problems and guide the design of us er interfaces (CQPI, 2015). Future research on health IT usability will be important (see Chap ter 8). One key feature of an effective user interface is simplicity. \"Simplicity in design refers to everything from lack of visual clutter and concise information display to in clusion of only functionality that is needed to effectively accomplish tasks\" (HIMSS, 2009). Clinicians have expressed dissatisfaction about EHR screens being too busy due to a high degree of display cl utter (or the high density of objects). In their review, Moacdieh and Sarter (2014) found: \"Displays described as cluttered have been shown to degrade the ability to monitor a nd detect signal changes, to dela y visual search, to increase memory load, to instill confidence in wrong judgments, to lead to confusion, and to negatively affect situational awareness, reading, and linguistic processing\" (p. 61). Another principle of usability is efficiency (HIMSS, 2009). Inefficient health IT tools may impede diagnosis by adding to clinicians' wo rk burdens, leaving them with less time for the cognitive work involved in dia gnosis and communicating with patie nts and the other health care professionals who are involved in th e patients' care. Clinicians need to be able to complete a task without having to undergo extra steps, such as clicking, scrolling, or switching between a keyboard and mouse; however, many health IT t ools are cumbersome to navigate. One study of emergency department clinicians found that inpu tting information consumed more of their time than any other activity, including patient care (H ill et al., 2013). By counting computer mouse \"clicks,\" the researchers who perf ormed that study found that it took si x clicks to order an aspirin tablet, eight clicks to order a chest x-ray, fifteen clicks to provide a patie nt with one prescription, and forty clicks to document the exam of a hand and wrist injury. Hill and colleagues (2013) estimated that a clinician could make 4,000 clicks in one 10-hour shift. EHRs may also present clinicians with more alerts than they can e ffectively manage. For example, many comprehensive EHR systems automatically generate alerts in response to abnormal diagnostic testing results, but Singh and colleagues (2013) found that informati on overload may contribute to clinicians missing test results. Almost 70 percent of clinicians surveyed said that they received more alerts than they could effectively manage, and almost 30 percent of clinicians reported that they had personally missed alerts that re sulted in patien t care delays. Makam and colleagues (2013) found that clinicians spend an appreciable amount of time using EHRs outside of their clinic hours. Almost half of the cl inicians they surveyed reported that completing EHR documentation for each schedul ed half-day clin ic session required one or more extra hours of work, and 30 percent re ported they spent at least one extra hour communicating electronically with patients, even though they may not get paid for this time. TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS 5-11 PREPUBLICATION COPY: UNCORRECTED PROOFS Howard and colleagues (2013, p. 107) found mixed re sults on work burden when they studied small, independent, community-based primary car e practices; \"EHR use reduced some clinician work (i.e., prescribing, some lab-related task s, and communication within the office), while increasing other work (i.e., char ting, chronic disease and preven tive care tasks, and some lab- related tasks).\" Measurement Capability Health IT can also be used to measure errors in diagnosis by leveraging the vast amounts of patient data contained in h ealth IT databases (Shenvi and El-Kareh, 2014; Singh et al., 2012; Singh et al., 2007b). For instance, algorithms can be developed that periodically scan EHRs for diagnostic errors or clinical scen arios that suggest a diagnostic error has occurred. An example of the former would be cases of patients with ne wly diagnosed pulmonary embolism who were seen in the 2 weeks preceding diagnosis by an outpatient or emergency department clinician with symptoms that may have indicated pulmonary embolism (e.g., cough, shortness of breath, chest pain). An example of the latter may be patients who are hospitalized or seen in the emergency department within 2 weeks of an unscheduled ou tpatient visit, which may be suggestive of a failure to correctly diagnosis th e patient at the first visit (Sin gh et al., 2012; Singh et al., 2007b; Sittig and Singh, 2012). In both of these instances, health IT systems need to incorporate user- friendly platforms that enable hea lth care organizations to measure diagnostic errors or surrogate measures. For health IT systems that are used by multiple health care organizations or across multiple settings (inpatient and outpatient), co mmon platforms for measuring diagnostic errors will permit comparisons of dia gnostic error rates across organi zations and settings. Improving the identification of diagnostic errors is a main recommendation of this committee (see Chapter 6), and health IT vendors should facilitate effo rts to do so by developing tools that enable organizations to more easily determine the rates of diagnostic errors, especially those that are common and that have serious implications for patients (e.g., pulmonary embolism, acute myocardial infarction, and stroke). Fit Within Clinical Workflow The diagnostic process is not a single task, but rather a series of tasks that involve multiple people across the health care continuum. Clinical workflow, or the sequence of physical and cognitive tasks performed by various people w ithin and between work environments, affects the diagnostic process at many j unctures (Carayon et al., 2010). A critical element of workflow is health IT: Effective integration of health IT into the clinical workflow is essential for preventing diagnostic errors. However, integr ating health IT into the clin ical workflow is made more difficult by the wide range of workflows used by different individuals participating in the diagnostic process, both within one setting and across care settings. According to HIMSS, there are more than 50 physician specialties, and each of these specialties has its own software needs, including the unique software n eeds of the other health care pr ofessionals involved in that specialty (e.g., nurses, pharmaci sts, physical therapists, respir atory therapists, and medical dieticians). Each specialty may have different tasks that require a range of software interface designs (HIMSS, 2009). Furthermore, the actual clinical workflow does not always follow a formal, linear process; for example, orders may need to be executed before the proper administrative data, such as a patient's social secu rity number, is entered or even known (Ash et al., 2004). As a result, health IT systems need both flexibility and modularity, so that they can be 5-12 IMPROVING DIAG NOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS tailored to specific workflow needs. Additiona lly, the time spent implementing and maintaining health IT systems may negatively impact workfl ow and even contribute to error (IOM, 2012a). For instance, EHR systems may become temporaril y inaccessible because of software updates or network failure. Clinical Documentation Clinical documentation is central to patient care and often occupies a significant amount of clinicians' time (Hripcsak et al., 2011). Clinical documentati on has been defined as \"the process of recording historical data, observations, assessments, interventions, and care plans in an individual's health record. Th e purpose of documentation is to facilitate clinical reasoning and decision making by clinicians and promote communication and coordination of care among members of the care team\" (Kuperman and Rosenbloom, 2013, p. 6). Beyond supporting patient care, clinical documentation also needs to meet re quirements outside of the clinical care setting, including billing, accreditati on, legal, and research purposes (Hripcsak and Vawdrey, 2013). Clinical documentation is used to justify the le vel of service billed to insurers, to collect information for research or quality improvement pur poses, and to inform a legal record in case of litigation (Rosenbloom et al., 2011). For exampl e, the electronic documentation of clinical decisions and activity, incl uding both user-entered data and meta data, \"may affect the course of malpractice litigation by increasi ng the availability of documentation with which to defend or prove a malpractice claim\" (Magnalmurti et al., 2010, p. 2063). Payment and liability concerns, in combination with the growth in EHRs, have resulted in extensiv e and growing clinical documentation\u2014sometimes referred to as \"note bloat\"\u2014that has led to a situation in which key information in a patient's medical record can be obscured (Kuhn et al., 2015). A number of clinicians have expressed concer n that clinical documentation is not promoting high-quality diagnosis and is instead primarily centered around billing and legal requirements, forcing clinicians to \"focus on ticking boxes rather th an on thoughtfully documenting their clinical thinking\" (Schiff and Bates, 2010, p. 1066). In ad dition, research has shown that electronic documentation adds to clinicians' work burden: intensive care unit re sidents and physicians spend substantially more time on clinical revi ew and documentation after EHR implementation (Carayon et al., 2015). For example, extensive c linical documentation for justifying payment, facilitated by the copy/paste f eature of EHRs, can contribute to cognitive overload and impede clinical reasoning. Chapter 7 further elaborat es on how documentation guidelines for billing interfere with the diagnostic process and pres ents the committee's recommendation for how to better align documentation guidelines w ith clinical reasoning activities. A major goal of using data coll ected within EHRs for legal, billing, and population-wide health management has led to a profusion of st ructured clinical documentation formats within health IT tools. For instance, Chapter 7 discusses the excessive information that has resulted from cut and paste functionalities and the need to ensure that the information contained in EHRs justifies legal and billing purposes. However, stru ctured documentation may cause problems for clinicians because they \"value di fferent factors when writing clin ical notes, such as narrative expressivity, amenability to the existing workflow, and usability\" (Rosenbloom et al., 2011, p. 181). Clinicians need to be able to record informa tion efficiently and in ways that render it useful to other health care professionals involved in caring for a patient. Research has found \"that in a shared context, concise, unconstrained, free -text communication is most effective for coordinating work around a complex task\" (Ash et al., 2004, p. 106). There are also concerns TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS 5-13 PREPUBLICATION COPY: UNCORRECTED PROOFS that overly structured data entry has impacted clinicians' cognitive focus and abilities to focus on and attend to relevant information in the EHR (Ash et al., 2004). Tools, such as speech recognition technology, ha ve been developed to assist clinicians with clinical documentation, with varying degr ees of success. Though several studies have found that voice recognition technology can improve th e turnaround time of results reporting (Johnson et al., 2014; Prevedello et al., 2014; Singh and Pal, 2011), there are a number of issues associated with this technology that make it difficult to im plement or may negatively impact the diagnostic process. This includes high implementation costs, the need for extensive user training, decreased report quality due to technology-re lated errors, and workflow inte Yoshihashi, 2010; Johnson et al., 2014 Quint et al., 2008). Another technology that may help address the challenges of clinical documentation is natural language processing (Hripcsak and Vawdrey, 2013). Natural language processing extracts data from free text, converting clin icians' notes and narratives into structured, standardized formats. When the task is sufficien tly constrained and when there is sufficient time to train the system, natural language processing systems can extract information with minimal effort and very high performance (Uzuner et al., 2008). Health IT vendors have begun to incorporate natural language processing software into EH Rs. Additional technologies, particularly data mining, hold promise for improv ing clinical documentation in the future. Data mining \"relies on the collective experience of all previous notes to steer how data should be entered in a new note\" (Hripcsak and Vawdre y, 2013, p. 2). These technologies also hold promise for improving clinical de cision support, discussed below. Clinical Decision Support in Diagnosis Health IT has the potential to support the diagnostic process through clinical decision support (CDS) tools. CDS provides clinicians an d patients \"with knowledge and person-specific information [that is] intelligently filtered or pres ented at appropriate times, to enhance health and health care\" (HealthIT.gov, 2013). A number of studies have shown that clinical decision support systems can improve the rates of certain desirabl e clinician behaviors such as appropriate test ordering, disease management, and patient ca re (Carayon et al., 2010; Lobach and Hammond, 2003; Roshanov et al., 2011; Sequist et al., 2005). Diagnostic decision support tools can pr ovide support to clinicians and patients throughout each stage of the diagnostic proc ess, such as during information acquisition, information integration and inte rpretation, the formati on of a working diagnosis, and the making of a diagnosis (Del Fiol et al., 2008; Zakim et al., 2008). Box 5- 3 categorizes health IT tools according to the tasks they assist with in the diagnostic process (El-Kareh et al., 2013). Tools such as infobuttons can be integrated into EHRs and provide links to relevant online information resources, such as medical textbooks, clinical practice guidelines, and ap propriateness criteria; there is evidence that infobuttons can help clinic ians answer questions at the point of care and that they lead to a modest increase in the effi ciency of information de livery (Del Fiol et al., 2008). CDS can also facilitate the ordering of the diagnostic tests that he lp physicians develop accurate and timely diagnoses. In its input to th e committee, the American College of Radiology stated that structured decision support for imag e ordering and reporting is critical for reducing diagnostic errors (Allen and Thorwarth, 2014). The Protecting Access to Medicare Act, passed in 2014, includes a provision that re quires clinicians to use spec ified criteria when ordering advanced imaging procedures and directs the U.S. Department of Health and Human Services to 5-14 IMPROVING DIAG NOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS identify CDS tools to help clinicia ns order these imaging procedures.2 Given the growth of molecular testing and advanced im aging techniques, the importance of clinical decision support in aiding decisions involving this aspect of the diagnostic process is likely to increase. BOX 5-3 Categories Describing Different Steps in Diagnosis Targeted by Diagnostic Health Information Technology Tools Tools that assist in information gathering Cognition facilitation by enhanced organization and display of information Aids to the generation of a differential diagnosis Tools and calculators to assist in weighing diagnoses Support for the intelligent selection of diagnostic tests/plan Enhanced access to diagnostic reference information and guidelines Tools to facilitate reliable follow-up, assessment of patient course, and response Tools/alerts that support screening for the early detection of disease in asymptomatic patients Tools that facilitate diagnostic collaboration, particularly with specialists Systems that facilitate feedback and insight into diagnostic performance SOURCE: El-Kareh et al., 2013. Reproduced from Use of health information technology to reduce diagnostic error. R. El-Kareh, O. Hasan, and G. Schiff. 22(Suppl 2):ii40-ii51 with permission from BMJ Publishing Group Ltd. Although decision support technologies have been around for quite some time (Weed and Zimny, 1989; Weed and Weed, 2011), there is still much room for progress. Questions about the validity and utility of diagnostic decision suppor t tools still remain. A number of studies have assessed the performance of diagnostic decision support tools. Researchers such as Ramnarayan et al. (2003) have developed scor es to measure the impact of diagnostic decision support on the quality of clinical decision making. These scor es assess the performan ce of clinical decision support tools based on how often the \"correct\" di agnosis is produced by either the decision support system or by the clinicians after using the decision support; the scores also take into account the rank of the correct diagnosis on the li st of differential diagnoses. There may be problems with these criteria, however . In particular, rare diagnoses may be less likely to be considered because of a lower ranking. More rece ntly, a review of four differential diagnosis generators found these tools to be \"subjectively assistive and functi onal for clinical diagnosis and education\" (Bond et al., 2012). On a five-point scale (5 when the actual diagnosis was suggested on the first screen or in the first 20 suggestions , and 0 when no suggestions were close to the clinical diagnosis), the differential diagnosis generators received scores ranging from 1.70 to 3.45. Additional studies suggest th at diagnostic decision support tools have the potential to improve the accuracy of diagnosis (Grabe r and Mathew, 2008; Kostopoulou et al., 2015; Ramnarayan et al., 2006, 2007). However, the stud ies assessing diagnostic decision support tools were conducted in highly controlled research settings; further rese arch is needed to understand the performance of diagnostic decision support tools in clini cal practice (see Chapter 8). 2 Protecting Access to Medicare Act of 2014: https://www.c ongress.gov/bill/113th-co ngress/house-bill/4302 TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS 5-15 PREPUBLICATION COPY: UNCORRECTED PROOFS Though relatively early in its development, the application of new computational methods, such as artificial inte lligence and natural language processing, has the potential to improve clinical decision support (Arnaout, 2012) . For instance, these approaches can analyze large amounts of complex patient data (such as patient notes, diagnostic te sting results, genetic information, as well as clinical and molecular prof iles) and compare the resu lts to \"thousands of other patient EHRs to identify si milarities and associations, thus, elucidating trends in disease course and management\" (Castaneda, 2015, p. 12). In addition to these efforts involving generali zed decision support tools, there are also ongoing efforts to use decision support in radiol ogy. One such decision support tool is computer- aided detection (CAD), which is designed to help radiologists during mammography interpretation by analyzing mammogram images for patterns associated with underlying breast cancer. Despite the broad acceptance and use of C AD, there is mixed evidence demonstrating its effectiveness (Rao et al., 2010). Although CAD is not yet matu re, the technology holds promise for improving detection. Challenges with the usability and acceptability of diagnostic decision support have hindered adoption of these tools in clinical practice (Berner, 2014). For these tools to be useful, they need to be used only when appropriate, to be understandable, and to enable clinicians to quickly determine the level of urgency and relevancy. Decision s upport must functio n within the workflow and physical environment of the diagno stic process, which may include distractions and interruptions. If decision support tools are to be optimally designed, it will be necessary to consider tailoring the support to different users based on such factors as experience and workload. For example, a highly trained or high ly experienced user may be better able to navigate a computer interface that is cu mbersome than a less experienced user.3 And the more experienced clinicians may need su pport to avoid pitfalls in diagnos is due to the use of system 1 processes, whereas more novice clinicians may need access to additional information to support system 2 processes. Research on how clinicians use technology may pr ovide insight into the ways that human-automation intera ctions may be contributing to errors. EHR systems log users' actions through both user-entered data (i.e., tim ing of events and who performed them) and metadata. EHRs can also measure the rate at which clinicians override alerts and medication- dose defaults. In addition, there are a number of potential patient safety ri sks associated with decision support. A systematic review found that an overr eliance on decision suppor t has the potential to reduce independent clinician j udgment and critical thinking (G oddard et al., 2012). A decision support tool could provide incorrec t advice if it has incomplete in formation or applies outdated treatment guidelines (AHLA, 2013). This may place a clinician in a position in which he or she believes the decision support is correct, and discounts their own assessment of the issue. Although Friedman and colleagues (1999) found that the use of clinical decision support was associated with a modest increase in diagnosti c accuracy, in 6 percen t of cases clinicians overrode their own correct decisi ons due to erroneous advice fr om the decision support system. The presentation of information, as well as inform ational content, can lead to adverse events related to the use of decision support: \"unintended consequences relating to content are grouped around three themes: (a) the elimination or cha nging roles of clinicians and staff; (b) the currency of the [clinical decision support (CDS )] content; and (c) wrong or misleading CDS content\", while those relating to pr esentation are associated with \"(a) the rigidity of systems; (b) sources of alert fatigue; and (c) sources of potential errors\" (Ash et al., 2007, pp. 27-28). 3 A cumbersome interface may also be challenging to an experienced user. 5-16 IMPROVING DIAG NOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Timely Flow of Information The timely and effective exchange of information among health care professionals and patients is critical to improving diagnosis, and breakdowns in that communication are a major contributor to adverse events, including diagnostic errors (Gandhi et al., 2000; Poon et al., 2004; Schiff, 2005; Singh ). Health IT has the poten tial to reduce communication breakdowns, including breakdowns in intra- and interpersonal communication, in communication among patients and health care prof essionals, and in information exchange (e.g., the reporting of test results) (Singh et al., 2008). As discusse d in Chapter 4, improved patient access to EHRs, including diagnostic testing results as well as clinical notes, can promote improved engagement in the diagnostic process and facilitate more timely information flow between and among patients and health care profe ssionals. Health IT can also assist with the tracking of test results and follow up (see Chap ter 6). For example, the AMA (2014) concluded that EHRs can support care coordination if they \"automatically track refe rrals and consultations as well as ensure that the referring physician is easily able to follow the patient's progress/activity throughout th e continuum of care\" (p. 5). However, health IT tools may not be f acilitating optimal communication among health care professionals, and they may even contribute to communication breakdowns. For example, Parkash and colleagues (2014) found that EHRs may not alert physicians when surgical pathology reports have been amended, which may resu lt in an incorrect diagnosis that is based on the original pathology report, an incorrect treatment plan, and the potential for serious consequences for a patient. A lack of interoperability (discussed below) can also prevent the timely flow of information am ong health care professionals. Furthermore, another effect of health IT tools may be a reduction in informal, in-person collaborations between radiologists and treating clinicians that can facilitate insights into the diagnostic process. In-person consultation be tween treating clinicians and the radiology department was common prior to the computeri zation of radiology and the introduction of the picture archiving communications system (Wachter, 2015). With the transition to filmless radiology systems, there has been a decrease in in-person cons ultations with the radiology department (Reiner et al., 1999). An example of the importance of the timely flow of information is illustrated by the diagnostic error of Ebola in a Dallas emergency department (see Box 5-4). As the committee was deliberating in 2014, the most widespread outbreak yet seen of the Ebola virus occurred (CDC, 2015). Although the epidemic was primarily localized to several West African countries, the United States experienced its first case of E bola virus in September 2014. The delayed diagnosis of Ebola in a Dallas hospital was a highly publici zed example of diagnostic error. The committee included this case because it dem onstrates the complex etiology of diagnostic error, including the roles that health IT and interprofessional comm unication play in conveying information in the diagnostic process. TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS 5-17 PREPUBLICATION COPY: UNCORRECTED PROOFS BOX 5-4 A Case of Diagnostic Error: Delayed Diagnosis of Ebola Virus Infection Case History Thomas Eric Duncan traveled from Liberia to the United States in September 2014. He visited a Texas area emergency department on September 25, presenting with non-specific symptoms, including fever, nausea, abdominal pain, and a severe headache, symptoms that can be attributed to a number of common acut e illnesses (Upadhyay et al., 2014). Mr. Duncan informed the triage nurse of his recent travel from Africa (Dunklin and Thompson, 2014). The electronic health record (EHR) indicated that Mr. Duncan arrived with a fever of 100\u00b0 F, which spiked to 103\u00b0 F, and then dropped to 101\u00b0 F prior to discharge (Energy & Commerce Committee, 2014; Dallas Morning News, 2014; Upadhyay et al., 2014). The physician who evaluated Mr. Duncan during this visit was not aware of his travel history (Dallas Morning News, 2014). Mr. Duncan underwent a series of tests, including a computed tomographic scan, and was released with a diagnosis of sinusitis, but a later evaluation found that the imaging results were not consistent with this diagnosis (Upadhyay et al., 2014). Mr. Duncan returned to the hospital on September 28 via ambulance (Energy & Commerce Committee, 2014; Upadhyay et al., 2014). On September 30 he was confirmed to have the Ebola virus (Energy & Commerce Committee, 2014), and on October 8 Mr. Duncan died from this infection. The hospital accepted responsibility for the diagnostic error (Upadhyay et al., 2014). The chief clinical officer of Texas Health Resources stated in testimony to the U.S. Congress, \"Unfortunately, in our initial treatment of Mr. Duncan, despite our best intentions and a highly skilled medical team, we made mistakes . We did not correctly diagnose his symptoms as those of Ebola. We are deeply sorry\" (Energy & Commerce Committee, 2014). Discussion Current evidence suggests that patients seen in the emergency department are at high risk of experiencing diagnostic errors because of the range of conditions seen, the time pressures involved, and complexity of the work system environment (Campbell et al., 2007). As illustrated in this case of diagnostic error, a number of factors typica lly contribute to many adverse safety events (Graber, 2013). Patient history and physical exam often suggest the correct diagnosis (Peterson et al., 1992). In this example, Mr. Duncan's travel hi story was especially relevant to his medical condition (Dallas Morning News, 2014). Although the travel history was obtained by the nurse, the physician examining Mr. Duncan told the Dallas Morning News that the \"travel information was not easily visible in my standard workflow\" (Dallas Morning News, 2014). Communication breakdowns likely contributed to this diagnostic error: The travel history may not have been communicated or communicated adequately among the patient and his care team. Additionally, the significance of this information may not have been considered during the diagnostic process (Dunklin and Thompson, 2014; Upadhyay et al., 2014). Without knowledge of the travel history, the physician chose a much more common condition as the possible explanation (Dunklin and Thompson, 2014). Although most diagnostic errors involve common conditions, this case illustrates the problem of diagnosing rare diseases (zebras), when much more common diseases (horses) could explain similar symptoms. There is no ea sy solution to this problem. The challenge has been well described in Atul Gawande's book Complications , when he compared a necrotizing fasciitis diagnosis with cellulitis . In considering such a rare diagnosis, he said, \"I felt a little foolish considering the diagnosis\u2014it was a bit like thinking the Ebola virus had walked into the ER\" (Gawande, 2002, p. 233). CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Understanding the information flow and communication breakdowns in this case is a more challenging task (Upadhyay et al., 2014). The nurse documented the travel history in her note, which was not considered by the physician. This raised a number of questions: Was documentation in the EHR sufficient to convey this information? When is verbal communication of key facts necessary? Was the EHR designed appropriately to support sharing of important information? Are the notes in EHRs too hard to locate and share in the typical workflow of a busy emergency department? Are notes valued appropriately by members of the care team? Does the format of a nursing note (template vs. unstructured) influence how key information is communicated? After the diagnostic error of Ebola occurr ed, Texas Presbyterian implemented a number of organizational and technological changes intended to reduce the risk of similar errors in the future. A public statement outlining the lessons learned and responses to this diagnostic error included: \"Upgraded medical record software to highlight travel risks New triage procedures initiated to quickly identify at-risk individuals A triage procedure to move high-risk patients immediately from the emergency department A final step for cleared patients: 30 minutes prior to discharge, vital signs will be rechecked. If anything is abnormal, the physician will be notified Increased emphasis on face-to-face communication\" (Watson, 2014) Teaching points 1. Although diagnostic errors typically involve common conditions, patients with unusual or rare conditions are at high risk for diagnostic error if their symptoms mimic those of more common conditions. 2. The etiology of a diagnostic error is typically multi-factorial. The various contributions of the work system factors, including the cognitive characteristics of clinicians, and the complex interactions between them can best be understood by adopting a human factors perspective. 3. Breakdowns in information flow and communication are the most common factor identified in cases of diagnostic error, just as they are in other major patient safety adverse events. 4. Although EHR technology provides many advantages to the diagnostic process, it can also cause a predisposition to certain types of errors, such as ineffective search for important information. INTEROPERABILITY OF HEALTH IT Another health IT-related challenge in the diagnostic process is the lack of interoperability, or the inabil ity of different IT systems and software applications to communicate, exchange data, and use the inform ation that has been exchanged (HIMSS, 2014). It is not unusual for the dia gnostic process to occur over a pr otracted period of time, with multiple clinicians across different care settin gs involved in the process. A free flow of information is critical to ensuri ng accurate and timely diagnoses since in order for health care TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS 5-19 PREPUBLICATION COPY: UNCORRECTED PROOFS professionals to develop a complete picture of a patient's health problem , all relevant health information needs to be available and accessible. A lack of interoperability can impede the diagnostic process because it can limit or delay a ccess to the data available for clinical decision making. When health care systems do not exchange data, clinical information may be inaccurate or inadequate. For instance, one version of a patient's EHR may exist on the primary clinical information system while a variety of outdated or partial versions of the record are present in other places. Furthermore, the record on the pr imary clinical information system may not necessarily be complete. Given the importance of the free flow of in formation to diagnosis, the Office of the National Coordinator for Health Information T echnology (ONC) can play a critical role in improving interoperability. The vision that ONC has articulated for the inter operability of health IT is of an \"ecosystem that makes the right data available to the right people at the right time across products and organizations in a way that can be relied upon and meaningfully used by recipients\" (ONC, 2014a, p. 2). By 2024, ONC anticipates that individuals, clinicians, communities, and researchers will have access to a variety of interoperable products. However, the progress toward achieving hea lth information exchange and in teroperability has been slow (CHCF, 2014). For example, office-based exch ange of information remains low; a study conducted by Furukawa et al. ( 2014) found that only 14 percent of the clinicians surveyed reported sharing data with clin icians outside their organizatio n. Recognizing that progress in interoperability is critical to improving the di agnostic process, the committee calls on ONC to more rapidly require that health IT systems meet interoperability requirements. Thus, the committee recommends that ONC should require he alth IT vendors to meet standards for interoperability among different health IT systems to support effective, efficient, and structured flow of patient information across care settings to faci litate the diagnostic process by 2018. This recommendation is in line with the recent legislation that repealed the sustainable growth rate, which included a provi sion that declared it a national objective to \"achieve widespread exchange of health inform ation through interoperable certified electronic health records (EHR) technol ogy nationwide by December 31, 2018.\" 4 The law requires the Secretary of Health and Human Services (HHS) to develop metrics to evaluate progress on meeting this objective by July 2016. Furthermore, the legislation stipulates th at if interoperability has not been achieved by 2018, the secretary is required to submit a repo rt to Congress in 2019 that identifies the barriers and makes recommen dations for federal government action to achieve interoperability, including adjusting payments fo r not being meaningful EHR users and criteria for decertifying certified EHR technology products. Improved interoperability across different health care organizations\u2014as well as across laboratory and radiology information systems\u2014is critical to improving th e diagnostic process. Challenges to interoperability include the in consistent and slow a doption of standards, particularly among organizations th at are not subject to EHR certi fication programs, as well as a lack of incentives, including a business model that generates re venue for health IT vendors via fees associated with transmitting and receivi ng data (Adler-Milstein, 2015; CHCF, 2014). The IOM report Health IT and Patient Safety: Building a Safer Health System recognized interoperability as a key feature of safely functioning health IT and noted that interoperability needs to be in place across the entire health care continuum: \"Currently, laboratory data have been relatively easy to exchange because good standards exist such as Logical Observation Identifiers Names and Codes (LOINC) and are wi dely accepted. However, important information 4 Medicare Access and CHIP Reauthorization Act of 2015. P.L. 114-10 (April 16, 2015). 5-20 IMPROVING DIAG NOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS such as problem lists and medication lists (which exist in some health IT products) are not easily transmitted and understood by the receiving health IT product because existing standards have not been uniformly adopted\" (IOM, 2012a, p. 86). Although laboratory data may be relatively easy to exchange, a recent report noted that the l ack of incentives (or pena lties) for organizations that are not subject to the EHR certification process under th e Medicare and Medicaid EHR Incentive Programs (such as clinical laboratorie s) also contributes to poor interoperability (CHCF, 2014). Additionally, the interface between EHRs and laborat ory and radiology information systems typically has limited clinical inform ation, and the lack of sufficiently detailed information makes it difficult for a pathologist or radiologist to determine the proper context for interpreting findings or to decide whether diagnostic testing is appropriate (Epner, 2015). For example, one study found that important non-onc ological conditions (such as Crohn's disease, human immunodeficiency virus, an d diabetes) were not mentioned in 59 percent of radiology orders and the presence of cancer was not mentioned in 8 percent of orders, demonstrating that the complete patient context is not getting receiv ed (Obara, et.al. 2014). Insufficient clinical information can be problematic as radiologists an d pathologists often use this information to inform their interpretations of images and suggest ions for next steps (Alkasab et al., 2009; Obara et al., 2014). There have been some efforts to im prove the transmission of clinical context with diagnostic testing orders; for example, a quality improvement initiative in the outpatient and emergency department settings was able to impr ove the consistency with which radiology orders were accompanied by a complete clinical history (Hawkins et al., 2014). In addition, the Centers for Disease Control and Prevention's Clinical Laboratory Improvement Advisory Committee (CLIAC) expressed concern over th e patient safety risks regard ing the interoperability of laboratory data and display discrepancies in EHRs (CDC, 2014; CLIAC, 2012). They recommended that laboratory health care professi onals collaborate with other stakeholders to \"develop effective solutions to reduce identified pa tient safety risks in and improve the safety of EHR systems\" regarding laboratory data (CDC, 2014, p. 3). Another emerging challenge is the interope rability between EHRs and patient-facing health IT, such as physical activity data, gluc ose monitoring, and other health-related mobile health applications (Marceglia et al,, 2015; Otte-Trojel et al., 2014). 5 Patient-facing technologies are discussed further later in the chapter. Economic incentives are another barrier to achieving interoperability. Current market conditions create business incentives for information blocking, that is, \"when persons or entities knowingly and unreasonably in terfere with the exchange or use of electronic health information\" (ONC, 2015, p. 8). A variety of pers ons or entities may engage in information blocking practices, but most complaints of information blocking are re lated to the actions of health IT developers. Health IT vendors may \"charge fees that make it cost-prohibitive for most customers to send, receive, or export electro nic health information stored in EHRs , or to establish interfaces that enable such information to be exchanged\" ( ONC, 2015, p. 15). For instance , clinicians generally pay $5,000 to $50,000 each to secure the right to set up connections that allow them to transmit information regularly to laboratories, health information exchanges, or governments (Allen, 2015). Additional fees may be charged each time a c linician sends, receives or even searches for (or \"queries\") data (ONC, 2015). Health care organizations are also capable of engaging in information blocking. For instance, larger hos pital systems that al ready capture a large 5 Interoperability is one challenge surrounding patient facing technologies; there are also other important considerations, such as vetting the quality of patient reported data. TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS 5-21 PREPUBLICATION COPY: UNCORRECTED PROOFS proportion of patients' clinical information inte rnally may be less motivated to join health information exchanges. In such instances, \"informati on is seen as a tool to retain patients within their system, not as a tool to im prove care\" (Tsai and Jha, 2014, p. 29). Issues related to data security and privacy w ill need to be considered as interoperability and health information exchange increases. The personal information stored within health IT systems needs to be secure. However, these data also need to be easily available when patients move from one system to another. Transpar ency will become increasingly important as interoperability improves and as data aggrega tion for quality improvement and population health management becomes more common. The ONC rec ognizes that it will be important to \"support greater transparency for individuals regarding bu siness practices of entities that use their data, particularly those that are not covered by the HIPAA Privacy and Security Rules\" (ONC, 2014a, p. 5). SAFETY OF HEALTH IT IN DIAGNOSIS Patient safety risks related to the use of health IT in the diagnostic process are another important concern because there is growing reco gnition that health IT can result in adverse events (IOM, 2012a; ONC, 2014b; Walker et al., 2008), including sentinel ev ents that result in permanent patient harm or death (Joint Commi ssion, 2015b). Such health IT safety risks have been described in the context of a socio-tec hnical system, in which the system components (including technology, people, workfl ow, organizational factors, a nd external environment) can dynamically interact and contribute to advers e events (IOM, 2012a; Sittig and Singh, 2010). A number of health IT-related patient safety risks may affect the diagnostic process and the occurrence of diagnostic errors. Fo r example, challenges with the usability of EHRs have led to workarounds from their intended use; although ma ny of these workarounds are benign, there is the potential for negative effects on patient safety and diagnosis (Ash et al., 2004; Friedman et al., 2014; IOM, 2012a; Koppel et al., 2008). Clinical documentation in the EHR and the use of the copy/paste functionality of EH Rs are areas of increased con cern. While the use of copy/paste functionality may increase effici ency by saving time that would ot herwise be spent retyping or reentering information, it carries with it a number of risks, incl uding redundancy that contributes to lengthy notes and cognitive overload as well as the spreading of inaccurate, outdated, or incomprehensible information (AHIMA, 2014; Kuhn et al., 2015; Jo int Commission, 2015a). New safety risks may also include errors related to entering and retrieving information (such as juxtaposition errors), errors in communication and coordination (mistaking information entry into an EHR system as a successful communicati on act), and health IT system maintainability (Ash et al., 2004). For instance, a pathologist may assume that the entry of new test results into an EHR system means that the re sults have been communicated to the clinician, even though this may not be the case (documentation in the EHR is not necessarily equivale nt to communication). Unfortunately, contractual provisions, intended to protect vendors' intellectual property interests and liability from th e unsafe use of health IT products, limit the free exchange of information about health IT-related patient sa fety risks (IOM, 2012a). Specifically, \"some vendors require contract clauses that force [health IT] system purchasers to adopt vendor-defined policies that prevent the disclosure of errors, bug s, design flaws, and other HIT-software-related hazards\" (Goodman et al., 2011, p. 77). These contra ctual barriers facing health IT vendors and users may propagate safety risks and pose significant challenges to the use of data for future patient safety and quality improvement res earch (IOM, 2012a). In recognition of these 5-22 IMPROVING DIAG NOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS challenges, the American Medical Informatics A ssociation board of directors convened a task force to help resolve issues surrounding vendor-user contra cts and made a number of suggestions for improving health IT contract lang uage (see Box 5-5). Westat prepared a report for ONC that provides an overview of the key cont ract terms for health car e organizations to be aware of when negotiating agreements with health IT vendors (Westat, 2013). BOX 5-5 Recommendations from an American Medical Informatics Association Special Task Force on Health Information Technology Contracts 1. Contracts should not contain language that pr events system users, including clinicians and others, from using their best judgment about what actions are necessary to protect patient safety. This includes freedom to di sclose system errors or flaws, whether introduced or caused by the vendor, the client, or any other third party. Disclosures made in good faith should not constitute violations of HIT [health information technology] contracts. This recommendation neither entails nor requires the disclosure of trade secrets or of intellectual property. 2. Hospitals, physician purchasers, and other users should understand that commercial products' screen designs and descriptions of software-supported workflows represent corporate assets developed at a cost to software vendors. Unless doing so would prematurely prevent disclosure of flaws, users should consider obligations to protect vendors' intellectual property and proprietary materials when disclosing (potential) flaws. Users should understand and accept their obligation to notify vendors before disclosing such features, and be aware of the range of remedies available to both the purchaser and the vendor in addressing safety issues. Equally, or more important, users should consider obligations to protect patient safety via such disclosures. 3. Because vendors and their customers share responsibility for patient safety, contract provisions should not attempt to circumvent fault and should recognize that both vendors and purchasers share responsibility for su ccessful implementation. For example, vendors should not be absolved from harm resulting from system defects, poor design or usability, or hard-to-detect errors. Similarly, purchasers should not be absolved from harm resulting from inadequate training and education, inadequate resourcing, customization, or inappropriate use. 4. While vendors have legitimate corporate interests and duties (e.g., to shareholders), contract language should make explicit a commitment by all parties to patient care and safety, and, as applicable, to biomedical research and public health. 5. Vendors should be protected from claims in which a facility (hospital, medical office, practitioner, etc.) causes errors that cannot reasonably be attributed to a defect in the design or manufacture of a product, or to vendor-related problems in installation, updating, or configuration processes. Similarly, vendors should not be held responsible for circumstances in which users make foolish or intentional errors. 6. \"Hold harmless\" clauses in contracts between electronic health application vendors and purchasers or clinical users, if and when they absolve the vendors of responsibility for errors or defects in their software, are unethical. Some of these clauses have stated in TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS 5-23 PREPUBLICATION COPY: UNCORRECTED PROOFS the past that HIT vendors are not responsible for errors or defects, even after vendors have been informed of problems. 7. A collaborative system or process of third- or neutral-party dispute resolution should be developed. Contracts should contain language de scribing a process for timely and, as appropriate, transparent conflict resolution. 8. Contracts should make explicit a mechani sm by which users/clients can communicate problems to the company; and vendors should have a mechanism for dealing with such problems (compare in this regard the processes in place for adverse event and device failure tracking by implantable medical device manufacturers). 9. Contracts should require that system defects, software deficiencies, and implementation practices that threaten patient safety should be reported, and information about them be made available to others, as appropriate. Vendors and their customers, including users, should report and make available salient information about threats to patient safety resulting from software deficiencies, im plementation errors, and other causes. This should be done in a way easily accessible to customers and to potential customers. This information, when provided to customers, should be coupled with applicable suggested fixes, and should not be used to penalize those making the information available. Disclosure of information should not create legal liability for good-faith reporting. Large HIT systems undergo thousands of revisions when looked at on a feature-by-feature basis. Requirements that the vendor notify every customer of every single feature change on a real-time basis would have the unintended result of obscuring key safety risks, as customers would have to bear the expense of analyzing thousands of notifications about events which are typica lly rare. Therefore, vendors should notify customers as soon as possible about any product or configuration issues (1) of which they are aware and (2) which pose a risk to patients. SOURCE: K. W. Goodman, E. S. Berner, M. A. Dente, B. Kaplan, R. Koppel, D. Rucker, D. Z. Sands, and P. Winkelstein, Challenges in ethics, safety, best practices, and oversight regarding HIT vendors, their customers, and patients: A report of an AMIA special task force, Journal of the American Medical Informatics Association , 2011, 18(1):77-81, by permission of the American Medical Informatics Association. In line with the movement toward more tr ansparency, the IOM report on patient safety and health IT recommended that the Secretary of HHS \"should ensure insofar as possible that health IT vendors support the fr ee exchange of information about health IT experiences and issues and not prohibit sharing of such informa tion, including details (e. g., screenshots) relating to patient safety\" (IOM, 2012a, p. 7). The committee endorses this recommendation and further recommends that the Secretary of HHS should require health IT vendors to permit and support the free exchange of information about real-time user experiences with health IT design and implementation that ad versely affect the diagnostic process. Health IT users can discuss patient safety concerns related to health IT products us ed in the diagnostic process in appropriate forums. Such forums include the forthcoming ONC national patient safety center or patient safety organizations (RTI Internationa l, 2014; Sittig et al., 2014a). In addition, the Agency for Healthcare Research and Quality ha s developed a common format reporting form for 5-24 IMPROVING DIAG NOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS health IT adverse events and ONC is beginning to evaluate patient sa fety events related to health IT (ONC, 2014b). Because the safety of health IT is critical for improvement s to the diagnostic process, health IT vendors need to proact ively monitor their pr oducts in order to identify potential adverse events, which could contribute to diagnostic errors and challe nges in the diagnostic process (Carayon et al., 2011). To ensure that their produc ts are unlikely to contribute to diagnostic errors and adverse events, vendors need to have independent, third-part y evaluations performed on whichever of their health IT products are used in the diagnostic process. Thus, the committee recommends that the Secretary of HHS should require health IT vendors to routinely submit their products for independent evaluation a nd notify users about potential adverse effects on the diagnostic process related to the use of their products. Health IT vendors may consider using self-assessment tools, such as the SAFER guides, to prepare for the evaluations (Sittig et al., 2014b). If health IT products have the potential to contribute to diagnostic errors or have other adverse effects on the diagnostic process, health IT vendors have a responsibility to communicate this information to their customers in a timely manner. OTHER DIAGNOSTIC TECHNOLOGIES In addition to health IT, several emerging technologies present opportunities to improve the diagnostic process, such as telemedicine/t elehealth and mHealth/wea rable technologies. This section examines the use of these technologies by health care professionals and patients to improve the diagnostic process.6 Telemedicine Although the definitions vary, telemedicine and telehealth generally refer to the delivery of care, consultations, and information using communications technology (American Telemedicine Association, 2015). A 2012 IOM workshop defined both telemedicine and telehealth, saying that they \"describe the use of medical information exchanged from one site to another via electronic communicat ions to improve the patient 's health status. Although evolving, telemedicine is sometimes associated with direct patient clinical services and telehealth is sometimes associated with a broa der definition of remote health care services\" (IOM, 2012b, p. 3). Telemedicine encompasses an in creasing array of applications and services, such as \"two-way video, e-mail, smart phone s, wireless tools, and other forms of telecommunication technology\" (American Telemedicine Association, 2015). Telemedicine typically is used in two settings: (1) between a clinician and a patient who is in a different location or (2) between two c linicians for consultati ons. The transmission of images, data, and sound can take place either synchronously (real-time), where the consulting clinician participates in the examination of the patient while diagnostic information is collected and transmitted, or asynchronously (anytime) , through store-and-forward technology that transmits digital information for the consulti ng clinician to review at a later time. As new payment and care delivery models ar e being implemented and evaluated, there is a growing recognition of the potential for tec hnological capabilities to improve patient 6 The use of emerging technologies in diagnosis and treatment raise a number of regulatory, legal and policy issues that are beyond the scope of this discussion (such as privacy and security concerns, payment, credentialing, licensure, program integrity issues, liability, and others). TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS 5-25 PREPUBLICATION COPY: UNCORRECTED PROOFS accessibility to health care services and also to improve care coordination and affordability. Telemedicine can create additional options for how individuals receive health care, while lessening the dependence on traditional in-perso n methods of receiving medical treatment. Telemedicine arrangements have emerged in a number of medical specialties (e.g., radiology, pathology, dermatology, ophthalmology, cardiology, neurology, geriatrics, and psychiatry), certain hospital service lines (e.g., home health and dentistry), and certain patient populations (e.g., prison inmates). Telemedicine poses a number of challenges in the diagnostic pro cess that may differ from those in traditional health care visits. For example, in the absence of a prior patient- clinician relationship, a clinicia n may not know enough details about the patient's history to ask pertinent questions, which may lead clinicians to over-utilize diagnostic testing (Huff, 2014). In addition, telemedicine approaches can limit a c linician's ability to perform a comprehensive physical exam; certain medical conditions cannot be diagnosed effectively via a telemedicine encounter (Robison, 2014). There is also th e potential for technological failures and transmission errors during a telemedicine encounter that can impair the diagnostic process and medical evaluation (Carranza et al ., 2010). It is important that bot h patients and clinicians fully understand the telemedicine proce ss and its associated limitations and risks, including the scope of the diagnostic health care services that can be delivered safely through this medium. Additionally, health care professi onals may need to document their findings differently in the absence of face-to-face interac tions, given the absence of a comprehensive physical exam. Clinicians participating in telemedicine need to be attuned to care continuity and coordination issues and to effectively convey to their patients who has accountability over their care and whom they should contact for fo llow-up. Finally, health care prof essionals will need to keep abreast of professional standards of care and the relevant state laws that create heightened requirements for a particular telemedicine activity and which may affect the diagnostic process. The following text provides an overview of telemedicine appli cations in radiology, pathology, and neurology. Teleradiology a forerunner in te lemedicine arrangements \"with on-call emergency reporting being used in over 70 percent of radiology practices in the United States and general teleradiology by 'nighthawk servi ces' around the world\" (Krupinski, 2014, p. 5). In these arrangements, outsourced, o ff-hour radiology interpretations are provided by physicians credentialed in the United States who are either located within the United States or abroad. Continuous developments in picture archiv ing and communication systems and radiology information systems, have strengthened the overall teleradiology pr ocess, including image capture, storage, processing, and reporting. In res ponse to such developments, there has been an increase in the subspecialization of radiologists along systems- a nd disease-related specialties. Greater sub-subspecialization has led to increased expansion and utilization of teleradiology in major urban as well as rural and medically underserved areas (Krupinski, 2014). Telepathology Telepathology is currently being used in se lect locations for a variety of clinical applications, including the diagnosis of frozen section speci mens, primary histopathological diagnoses, second opinion diagnoses, and subs pecialty pathology c onsultations, although telemedicine approaches could al so be considered for clinical pathology purposes (Dunn et al., 5-26 IMPROVING DIAG NOSIS IN HEALTH CARE al., al., 2000; et al Telepathology involves a hub-site pathologist that can acce ss a remote-site microscope and has the ability to control the movement of the slide and adjust magnification, focus, and lighti ng, while the images are viewed on a computer screen (Dunn et al., 2009). Because the field selection is accomplished by the consultant, the information obtained, except for di gital imaging capabilities, is functionally the same as the consultant would obtain using a micr oscope in his or her own office. By providing immediate access to off-site pathologists as well as direct access to subs pecialty pathologists, telepathology has the potential to improve both diagnostic speed (turn-around time) and accuracy for the patients at the remote site. Moreover, a telepathology consulta tion allows the local pathologist and consulting pathologist to examine the case at the same time, which could improve the educational potential of the intera ction since the local pa thologist can observe firsthand the diagnostic approach employed by the consulting pathologist (Low, 2013). Teleneurology One application of telemedicine in neurol ogy is telestroke, a wi despread and growing practice model (Krupinski, 2014; Silva et al., 20 12). Successful management of acute ischemic stroke is extremely time-dependent, which makes it particularly important to have technological tools that can facilitate acute stroke evaluation and management in rural areas and other areas underserved by neurologists and thus improve post-stroke outc omes (Rubin and Demaerschalk, 2014). A recent Mayo Clinic study explored the effici ency of remote neurological assessments in diagnosing concussions in football players on th e sidelines of games in rural Arizona. For the study, an off-site neurologist used a portable unit to perform ne urological exams on players who had suffered possible head injuries and recommende d whether the players were safe to return to the field (Vargas et al., 2012). Th ese types of innovations may help facilitate the diagnostic process, especially for time-sensitive medical conditions. mHealth and Wearable Technologies Mobile health (mHealth) applications 7 and wearable technologies8 are transforming health care delivery for both health care profession als and patients, and they have the potential to influence the diagnostic process. The recent prolifer ation of mHealth applications has resulted in a broad and evolving array of mHea lth applications that are ava ilable to both clinicians and patients. mHealth applications ar e often designed to assi st clinicians at th e point of care and include drug reference guides, medical calculat ors, clinical guidelin es, textbooks, literature search portals, and other d ecision support aids. Other mobile applications are designed specifically for patients and facili tate the gathering of diagnostic data or assist patients in coordinating care by keeping track of their medical conditions, diagnostic tests, and treatments. mHealth applications may augment traditional health care professional education by providing opportunities for interactive teaching a nd more personalized educational experiences for students, and have the potenti al to support clinical decision making at the point of care (Boulos et al., 2014). A systematic review found an increase in the approp riateness of diagnostic and treatment decisions when mobile devices we re used for clinical decision support, but the 7 Mobile applications are software programs that have been developed to run on a computer or mobile device to accomplish a specific purpose. 8 Electronics embedded in watchbands, clothing, contact lenses, or other wearable equipment. TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS 5-27 PREPUBLICATION COPY: UNCORRECTED PROOFS researchers who performed the st udy noted that the evidence was limited; thus, more research will be needed to draw reliable conclusions concerning whether and how these mobile devices help and in what circumstances and how they s hould be used (Divall et al., 2013). Other mHealth applications designed for clinicians may serve as an alternative to traditional health IT tools and have the potential to improve di agnosis in emergency or low-re source settings. For example, tablets could be used to view medical images, and recent evidence suggests that they are comparable to conventional picture archiving and communications systems or liquid-crystal display monitor systems in diagnosing several conditions, although further research is needed (Johnson et al., 2012; Mc Laughlin et al., 2012; Park et al., 2013). Smart phones have been used in conjunction with specialized attachments to make certain laboratory- based diagnostics more accessible (Laksanasopin et al., 2015). For exam ple, an adaptor with electrocardiogram electrodes may transmit electrical data that can be used to detect abnormal heart rhythms (Lau et al., 2013). Future generations of such technologie s may be even more advanced; there is an ongoing Qualcomm Tricorder XPRIZE in which team s are competing to build a device that can accurately diagnose 16 health conditions and assess five vital signs in real time (XPRIZE, 2015). In response to an increasing demand from patie nts for self-monitoring tools, a plethora of patient-centered mHealth applications have beco me available. They can perform a variety of functions related to such lifestyle factors as weight management, activity levels, and smoking cessation. Patients may also leverage certain mHealth applications to actively participate in the diagnostic process, such as cons umer symptom checkers, which offer patients access to targeted searches based on their symptoms and enable patients to compile their own differential diagnoses, print out the results, a nd compare their findings with their clinicians' findings. Other mHealth applications for patients, such as wearable technologies, are intended to f acilitate data collection, and they offer an additional source of patient data which may improve clinicians' ability to diagnose certain conditions. For exampl e, patients with diabetes may synchronize a glucometer attachment to their mobile device to track blood glucose a nd upload the data through an Internet connection (Cafazzo et al., 2012). Despite the potential for mHealth applica tions to improve diagnosis, a number of challenges remain. In particular, the quality of mobile applications can be quite variable, and there are concerns about the accuracy and safety of these applications, especially about how well they conform to evidence-based recommendations (Chomutare et al., 2011; Powell et al., 2014). For example, Semigran and colleagues (2015) eval uated available symptom trackers for patients, and concluded that \"symptom checkers had deficits in both triage and di agnosis.\" The evaluation found that the symptom checkers iden tified the correct diagnosis firs t in 34 percent of the cases, and listed the correct diagnosis w ithin the top 20 list in 58 percent of the cases (Semigran et al., 2015). Jutel and Lupton (2015, p. 94) call for further re search of these apps given their variable development and quality, \"the sheer number and constant proliferation of medical apps in general pose difficulties for regulatory agencies to maintain oversight of their quality and accuracy,\" as well the impact of these apps on the patient-clinician relationship. Furthermore, there is a lack of data that support or identify th e best practices for their use, including integrating such technologies with EHRs , patient monitoring systems, and other health IT infrastructure (Mosa et al., 2012 ). Issues related to usability a nd health literacy will also need to be addressed in order to en sure that mHealth applications effectively meet user needs and facilitate the diagnostic process. The rapid pace of innovation and the evolving regulatory framework for mHealth are other ch allenges (Cortez et al., HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS RECOMMENDATION Goal 3: Ensure that health information tech nologies support patients and health care professionals in the diagnostic process Recommendation 3a: Health IT vendors and ONC should work together with users to ensure that health IT used in the diagnostic process demonstrates usability, incorporates human factors knowledge, integrates measurement capability, fits well within clinical workflow, provides clinical decision support, a nd facilitates the timely flow of information among patients and health care professionals involved in the diagnostic process. Recommendation 3b: ONC should require heal th IT vendors to meet standards for interoperability among different health IT systems to support effective, efficient, and structured flow of patient information across care settings to faci litate the diagnostic process by 2018. Recommendation 3c: The Secretary of HHS should require health IT vendors to: Routinely submit their products for indepe ndent evaluation and notify users about potential adverse effects on the diagnosti c process related to the use of their products. Permit and support the free exchange of information about real-time user experiences with health IT design and implementation that ad versely affect the diagnostic process. REFERENCES Adler-Milstein, J. 2015. America's health IT transformati on: Translating the promise of electronic health records into better care. Paper presented at U.S. Senate Committee on Health, Education, Labor and Pensions, March 17. http://www.help.senate.gov/imo/media/doc/Adle r-Milstein.pdf (accessed June 5, 2015). AHIMA (American Health Information Management A ssociation). AHIMA Workgroup. 2011. Problem List Guidance in the EHR. Journal of AHIMA 82(9):52-58. AHIMA. 2014. Appropriate use of the copy past e functionality in electronic health records. www.ahima.org/topics/ehr (accessed March 27, 2015). AHLA (American Health Lawyers Association). 2013 . Minimizing EHR-Related Serious Safety Events. http://www.mmicgroup.com/resources/industry-news-and-updates/2013/ 369-ahla-resource-to-minimize- ehr-related-serious-safety-even ts (accessed July 29, 2015). AHRQ (Agency for Health Research and Quality). 2010. El ectronic Health Record Usability: Vendor Practices and Perspectives. AHRQ Publication No. 09(10)-0091-3-EF: Rockville, MD: Agency for Healthcare Research and Quality. Alkasab, Tarik K., Jeannette Ryan Alkasab, and Hani H. Abujudeh. 2009. Effects of a computerized provider order entry system on clinical histories provided in emergency department radiology requisitions. Journal of the American College of Radiology 6(3):194-200. Allen, A. 2015. Doctors say data fees are blocking health reform. Politico , February 23 . www.politico.com/story/2015/02/data- fees-health-care-refo rm-115402.html (accesse d June 6, 2015). Allen, B., and W. T. Thorwarth. 2014. Comments from the American College of Radiology. Input submitted to the Committee on Diagnostic Error in Health Care, November 5, 2014, Washinton, DC. AMA (American Medical Assocation). 2014. Improving care : Priorities to improve electronic health record usability. www.ama-assn.org/ama/pub/about-ama/strategi c-focus/enhancing-profe ssional-satisfaction-and- practice-sustainability.page ( accessed February 9, 2015). TECHNOLOGY TOOLS IN THE DIAGNOSTIC PROCESS 5-29 PREPUBLICATION COPY: UNCORRECTED PROOFS www.americantelemed.org/about- telemedicine/what-is-telemedicine#.V WHni0b9x7x (accessed May 24, 2015). Arnaout, R. 2012. Elementary, my dear doctor watson. Clinical chemistry, 58(6): 986-988. Ash, J. S., M. Berg, and E. Coiera. 2004. Some unintended consequences of information technology in health care: The nature of patient care info rmation system-related errors. Journal of the American Medical Informatics Association 11(2):104-112. Ash, J. S., D. F. Sittig, E. M. Campbe ll, K. P. Guappone, and R. H. Dykstra. 2007. Some unintended consequences of clinical decision support systems. AMIA Annual Symposium Proceedings :26-30. Basch, P. 2014. ONC's 10-year roadmap towards interoperability requires changes to the meaningful use program. http://healthaffairs.org/blog/2014/11/03/oncs-10-ye ar-roadmap-towards-interoperability-requires-changes- to-the-meaningful-use-program / (accessed March 27, 2015). Bhan, S. N., Coblentz, C. L., & Ali, S. H. (2008). Effect of voice recognition on radiologist reporting time. Canadian Association of Radiologists Journal 59(4): 203-209. Berenson, R. A., Sussex. 2011. Revisiting E&M visit guidelines\u2014A missing piece of payment reform. New Engl Journal of Medicine 364(20):1892-1895. Berner, E. S. 2014. What can be done to increase the use of diagnostic decision support systems? Diagnosis 1(1):119-123. Bond, W. F., L. M. Schwartz, K. R. Weaver, D. Levick, M. Giuliano, and M. L. Graber. 2012. Differential diagnosis generators: An evaluation of curr ently available computer programs. Journal of General Internal Medicine 27(2):213-219. Boulos, M. N., A. C. Brewer, C. Karimkhani, D. B. Bulle r, and R. P. Dellavalle. 2014. Mobile medical and health apps: State of the art, concerns, re gulatory control and certification. Online Journal of Public Health Informatics 5(3):229. Brown J. S., A. Collins, and P. Duguid. 1989. Situated cognition and the culture of learning. Educational Researcher 18:32-42. Cafazzo, J. A., M. Casselman, N. Hamming, D. K. Katzman, and M. R. Palmert. 2012. Design of an mHealth app for the self-management of adolesce nt type 1 diabetes: A pilot study. Journal of Medical Internet Research 14(3):e70. Campbell, S. G., P. Croskerry, and W. F. Bond. 2007. Profiles in patient safety: A \"perfect storm\" in the emergency department. Academic Emergency Medicine 14(8):743-749. Carayon, P., T. B. Wetterneck, A. S. Hundt, S. Rough, and M. Schroeder. 2008. Continuous technology implementation in health care: The case of advanced IV infusion pump technology. In K. Zink (ed.), Corporate sustainability As a challenge for comprehensive management (pp. 139-151). New York: Springer. Carayon, P., B.-T. Karsh, and R. S. Cartmill. 2010. Incorporating health information technology into workflow redesign: Summary report . AHRQ Publication No. 10-0098-EF: Rockville, MD: Agency for Healthcare Research and Quality. October 2010. Carayon, P., H. Faye, A. S. Hundt, B.-T. Karsh, and T. Wetterneck, T. 2011. Patient safety and proactive risk assessment. In Y. Yuehwern (ed.), Handbook of Healthcare Delivery Systems (pp. 12-1-12-15). Boca Raton, FL: Taylor & Francis. Carayon, P., T. B. Wetterneck, B. Alyouse f, R. L. Brown, R. S. Cartmill, K. McGuire, P. L. Hoonakker, J. Slagle, K. S. Van Roy, J. M. Walker, M. B. Weinger, A. Xie, and K. E. Wood. 2015. Imp act of electronic health record technology on the work and workflow of physicians in the intensive care unit. International Journal of Medical Informatics 84(8):578-594. Carranza, N., V. Ramos, F. G. Lizana, J. Garcia, A. del Pozo, and J. L. Monteagudo. 2010. A literature review of transmission effectiveness and electromagnetic compatibility in home telemedicine environments to evaluate safety and security. Telemedicine Journal and E Health 16( 7):818-826. Castaneda, C., K. Nalley, C. Mannion, P. Bhattacharyya, P. Blake, A. Pecora, A. Goy, and K. S. Suh. 2015. Clinical decision support systems for improving diagnostic accuracy and achieving precision medicine. Journal of Clinical bioinformatics 5(1):4. CDC (Centers for Disease Control and Prevention). 2014. The Essential Role of Laboratory Professionals: Ensuring the Safety and Effectiveness of Laboratory Data in Electronic Health Record Systems. http://www.cdc.gov/la bhit/paper/Laboratory_Data _in_EHRs_2014.pdf (acce ssed July 27, 2015). eak in West Africa. www.cdc.gov/vhf/ebo la/outbreaks/2014-wes t-africa/ (accessed May 4, 2015). HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS CHCF (California HealthCare Foundation). 2014. Ten y ears in: Charting the progress of health information exchange in the U.S. www.chcf.org/~/media/MEDIA%2 0LIBRARY%20Files/PDF/T/PDF%20TenYearsProgressHIE.pdf (accessed February 9, 2015). Chomutare, T., L. Fernandez-Luque, E. Arsand, and G. Hartvigsen. 2011. Features of mobile diabetes applications: Review of the literature and analysis of current ap plications compared agains t evidence-based guidelines. Journal of Medical Internet Research 13(3):e65. CLIAC (Clinical Laboratory Improvement Advisory Committee). 2012. Le tter to HHS Secretary. https://wwwn.cdc.gov/CLIAC/pdf/2012_Oct_CLIAC_%20t o_Secretary_re_EHR.pdf (accessed August 11, 2015) Cortez, N. G., I. G. Cohen, and A. S. Kesselheim. 2014. FDA regulation of mobile health technologies. New England Journal of Medicine 371(4):372-379. CQPI (Center for Quality and Productivity Improvement ). 2015. Usability tools. www.cqpi.wisc.edu/usability- tools.htm (accessed May 3, 2015). Dallas Morning News. 2014. Full transcript: Dr. Joseph Ho ward Meier's responses to questions from The Dallas Morning News. www.dallasnews.com/ ebola/headlines/20141206- full-transcript-dr.-joseph-howard-meier- s-responses-to-questions-from-the-dallas-morn ing-news.ece (accessed March 30, 2015). Dehling, T., F. Gao, S. Schneider, and A. Sunyaev. 2015. Exploring the far side of mobile health: Information security and privacy of mobile health apps on iOS and Android. JMIR mHealth and uHealth 3(1):e8. dela Cruz, C. Shabosky, M. Albrecht, T. R. Clar k, J. C. Milbrandt, S. J. Markwell, and J. A. Kegg. 2014. Typed Versus Voice Recognition for Data Entry in El ectronic Health Records: Emergency Physician Time Use and Interruptions. Western Journal of Emergency Medicine 15(4):541-547. Del Fiol, G., P. J. Haug, J. J. Cimino, S. P. Narus, C. Norlin, and J. A. Mitchell. 2008. Effectiveness of topic- specific infobuttons: A randomized controlled trial. Journal of the American Medical Informatics Association 15(6):752-759. Divall, P., J. Camosso-Stefinovic, and R. Baker. 2013. The use of personal digital assistants in clinical decision making by health care professionals: A systematic review. Health Informatics Journal 19(1):16-28. Dwoskin, E., and J. Walker. 2014. Can data from your fitbit transform medicine? The Wall Street Journal, June 23. /www.wsj.com/articles/health-data-at-hand-with -trackers-1403561237 (accessed July 30, 2015). Dunklin, R., and S. Thompson. 2014. ER doctor discusses role in Ebola patient's initial misdiagnosis. Dallas Morning News , December 6. http://www.dalla snews.com/ebola/headlines/20141206-er-doctor-discusses- role-in-ebola-patients-initial-misdiagn osis.ece (accessed August 11, 2015). Dunn, B. E., H. Choi, D. L. Recla, S. E. Kerr, and B. L. Wagenman. 2009. Robotic surgical telepathology between the Iron Mountain and Milwaukee Department of Veterans Affairs Medical Centers: A twelve year experience. Seminars in Diagnostic Pathology 26(4):187-193. El-Kareh, R., O. Hasan, and G. Schiff. 2013. Use of health information technology to reduce diagnostic error. BMJ Quality and Safety 22(Suppl 2):ii40-ii51. Energy & Commerce Committee. 2014. Examining the U.S. public health response to the Ebola outbreak. Hearing. U.S. House of Representatives, Committee on Energy and Commerce, Subcommittee on Oversight and Investigations. October 16. http://energycommer ce.house.gov/hearing/examining-us-public-health- response-ebola-outbreak (accessed June 6, 2015). Epner, P. 2015. Submitted input. Input submitted to the Committee on Diagnostic Error in Health Care. January 13, 2015, Washington, DC. Fratzke, J., S. Tucker, H. Shedenhelm, J. Arnold, T. Belda, and M. Petera. 2014. Enhancing Nursing Practice by Utilizing Voice Recognition for Direct Documentation. Journal of Nursing Administration 44(2):79-86. Friedman, C. P., A. S. Elstein, F. M. Wolf, G. C. Murphy, T. M. Franz, P. S. Heckerling, P. L. Fine, T. M. Miller, and V. Abraham. 1999. Enhancement of clinicians' diagnostic reasoning by computer-based consultation: A multisite study of 2 systems. JAMA 282:1851-1856. Friedman, A., J. C. Crosson, J. Howard, E. C. Clark, M. Pe llerano, B. T. Karsh, B. Crabtree, C. R. Jaen, and D. J. Cohen. 2014. A typology of electr onic health record workarounds in small-to-medium size primary care practices. Jo urnal of the American Medical Informatics Association 21(e1):e78-83. Furukawa, M. F., J. King, V. Patel, C. J. Hsiao, J. Adle r-Milstein, and A. K. Jha. 2014. Despite substantial progress in EHR adoption, health information exchange and patient engagement remain low in office settings. Health Affairs (Millwood) 33(9):1672-1679. Gandhi, T. K., D. F. Sittig, M. Franklin, A. J. Sussman, D. G. Fairchild, and D. W. Bates. 2000. Communication breakdown in the outpatient referral process. Journal of General Internal Medicine 15(9):626-631. TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS 5-31 PREPUBLICATION COPY: UNCORRECTED PROOFS Gasson, S. 2003. Human-centered vs. user-centered approaches to information system design. Journal of Information Technology Theory and Application 5(2):29-46. Gawande, A. 2002. Complications: A surgeon's notes on an science . New York: Picador. Goddard, K., A. Roudsari, and J. C. Wyatt. 2012. Automation bias: A systematic review of frequency, effect mediators, and mitigators. Journal of the American Medical Informatics Association 19(1):121-127. Goodman, K. W., E. S. Berner, M. A. Dente, B. Kaplan, R. Koppel, D. Rucker, D. Z. Sands, P. Winkelstein, and AMIA Board of Directors. 2011. Challenges in ethics, safety, best practices, and oversight regarding HIT vendors, their customers, and patients: A re port of an AMIA special task force. Journal of the American Medical Informatics Association 18(1):77-81. Graber, M. 2013. The incidence of diagnostic error in medicine. BMJ Quality and Safety 22(Suppl 2):ii21-ii27. Graber, M. L., and A. Mathew. 2008. Performance of a web- based clinical diagnosis support system for internists. Journal of General Internal Medicine 23(Suppl 1):37-40. Graham, A. R., A. K. Bhattacharyya, K. M. Scott, F. Lian, L. L. Grasso, L. C. Richter, J. B. Carpenter, S. Chiang, J. T. Henderson, A. M. Lopez, G. P. Barker, and R. S. Weinstein. 2009. Virtual slide telepathology for an academic teaching hospital surgical pathology quality assurance program. Human Pathology 40(8):1129- 1136. Greenhalgh, T., S. Hinder, K. Stramer, T. Bratan, and J. Russell. 2010. Adoption, non-adoption, and abandonment of a personal electronic health record: case study of HealthSpace. BMJ 341:c5814. Harrington, L., D. Kennerly, and C. Johnson. 2011. Safety issues related to the electr onic medical record (EMR): Synthesis of the literature from the last decade, 2000-2009. Journal of Healthcare Management 56(1):31- 43; discussion 43-34. Hartung, D. M., J. Hunt, J. Siemienczuk, H. Miller, and D. R. Touchette. 2005. Clinical implications of an accurate problem list on heart failure treatment. Journal of general internal medicine 20(2):143-147. Hawkins C.M., C. G. Anton, W. M. Ba nkes, A. D. Leach, M. J. Zeno, R. M. Pryor, and D. B. Larson. 2014. Improving the availability of clinical history accompanying radiographic ex aminations in a large pediatric radiology department. American Journal of Roentgenology 202(4):790-796. HealthIT.gov. 2013. Clinical decision support (CDS). www.healthit.gov/policy-researchers-implementers/clinical- decision-support-cds ( accessed June 6, 2015). Hill, R. G., Jr., L. M. Sears, and S. W. Melanson. 2013. 4000 clicks: A productivity analysis of electronic medical records in a community hospital ED. American Journal of Emergency Medicine 31(11):1591-1594. HIMSS (Healthcare Information and Ma nagement Systems Society). 2009. Defining and testing EMR usability: Principles and proposed methods of EMR usability evaluation and rating. Chicago, IL: HIMSS. HIMSS. 2014. Patient Engagement Framework. http://files.himss.org/HIM SSorg/NEHCLibrary/HIMSS_Foundation_ Patient_Engagement_Framework.pdf 27, 2015). HIMSS. 2014. What is interoperability? www.himss.org/lib rary/interoperability-standards/what-is-interoperability (accessed February 9, 2015). Holmes, C., M. Brown, D. St Hilaire, and A. Wright. 2 012. Healthcare provider attitudes towards the problem list in an electronic health record: a mixed-methods qualitative study. BMC Medical Informatics and Decision Making 12(1):127. Houston, J. D., and F. W. Rupp. 2000. Experience with implementation of a radiology speech recognition system. Journal of Digital Imaging 13(3):124-128. Howard, J., E. C. Clark, A. Friedman, J. C. Crosson, M. Pellerano, B. F. Crabtree, B. T. Karsh, C. R. Jaen, D. S. Bell, and D. J. Cohen. 2013. Electronic health record impact on work burden in small, unaffiliated, community-based prim ary care practices. Journal of General Internal Medicine 28(1):107-113. Hoyt, R., and A. Yoshihashi. 2010. Lessons learned from implementation of voice recognition for documentation in the military electronic health record system. Persp ectives in health information management/AHIMA, American Health Information Management Association 7 (Winter). Hripcsak, G., and D. K. Vawdrey. 2013. Innovations in clinical documentation. Paper presented at HIT Policy Meaningful Use and Certification /Adoption Workgroups Clinical Documentation Hearing. Arlington, Virginia, February 13, 2013. Hripcsak, G., D. K. Vawdrey, M. R. Fred, and S. B. Bost wick. 2011. Use of electronic cl inical documentation: Time spent and team interactions. Journal of the American Medical Informatics Association 18(2):112-117. Huff, C. 2014. Virtual visits pose real issues for physicians. www.acpinternist.org/archives/2014/11/virtual-visit.htm (accessed 2015, May 24). 5-32 IMPROVING DIAG NOSIS IN disciplin e of ergonomics. www.iea.cc/ (accessed April 10, 2015). IOM (Institute of Medicine). 2012a. Health IT and patient safety: Building safer systems for better care . Washington, DC: The National Academies Press. IOM. 2012b. The role of telehealth in an evolving health care environment . Washington, DC: The National Academies Press. ISO (International Organization for Standardization). 1998. Ergonomic requirements for office work with visual display terminals (VDTs)\u2014Part 11: Guidance on usab ility. www.iso.org/obp/ui/# iso:std:iso:9241:-11:ed- 1:v1:en (accessed 25, 2015). Jacobs, L. 2009. Interview with Lawr ence Weed, MD\u2014The father of the prob lem-oriented medical record looks ahead. The Permanente Journal 13(3):84-89. Johnson, M., S. Lapkin, V. Long, P. Sanchez, H. Suominen, J. Basilakis, and L. Dawson. 2014. A systematic review of speech recognition technology in health care. BMC Medical Informatic s and Decision Making 14(94). Johnson, P. T., S. L. Zimmerman, D. Heath, J. Eng, K. M. Horton, W. W. Scott, and E. K. Fishman. 2012. The iPad as a mobile device for CT display and interpretation: Diagnostic accuracy for id entification of pulmonary embolism. Emergency 19(4):323-327. Jutel, A. and D. Lupton. (2015). Digitizing diagnosis: A re view of mobile applications in the diagnostic process. Diagnosis 2(2):89-96. Kayser, K., M. Beyer, S. Blum, and G. Kayser. 2000. Rece nt developments and present status of telepathology. Analytical Cellular Pathology 21(3-4):101-106. Koppel, R., T. Wetterneck, J. L. Telles, and B. T. Karsh. 2008. Workarounds to barcode medication administration systems: Their occurrences, causes , and threats to patient safety. Journal of the American Medical Informatics Association 15(4):408-423. Kostopoulou, O., A. Rosen, T. Round, E. Wright, A. Douiri, and B. Delaney. 2015. Early diagnostic suggestions improve accuracy of GPs: A randomised controlled trial using computer-simulated patients. British Journal of General Practice 65(630):e49-54. Krupinski, E. A. 2014. Teleradiology: Current perspectives. Reports in Medical Imaging 2014(7):5-14. Kuhn, T., P. Basch, M. Barr, and T. Yackel. 2015. Clinical documentation in the 21st century: Executive summary of a policy position paper from the American College of Physicians. Annals of Internal Medicine 162(4):301-303. Kuperman, G., and S. T. Rosenbloom. 2013. Paper presented at HIT Policy Meaningful Use and Certification / Adoption Workgroups Clinical Documentation Hearing. Arlington, Virginia, February 13, 2013. Laksanasopin, T., T. W. Guo, S. Nayak, A. A. Sridhara, S. Xie, O. O. Olowookere, P. Cadinu, F. Meng, N. H. Chee, J. Kim, C. D. Chin, E. Munyazesa, P. Mugwaneza, A. J. Rai, V. Mugisha, A. R. Castro, D. Steinmiller, V. Linder, J. E. Justman, S. Nsanzimana, and S. K. Sia. 2015. A smartphone dongle for diagnosis of infectious diseases at the point of care. Science Translational Medicine 7(273):273re1. Lau, J. K., N. Lowres, L. Neubeck, D. B. Brieger, R. W. Sy, C. D. Galloway, D. E. Albert, and S. B. Freedman. 2013. iPhone ECG application for community screening to detect silent atrial fibrillation: A novel technology to prevent stroke. International Journal of Cardiology 165(1):193-194. Lobach, D. F., and W. E. Hammond. 19 97. Computerized decisi on support based on a clinical practice guideline improves compliance with care standards. American Journal of Medicine 102(1):89-98. Low, J. 2013. Telepathology: Guidance from The Royal College of Pathologists. www.rcpath.org/Resources/RCPath/Migrated%20Resources/Documents/G/G026_Telepathology_Oct13.pdf (accessed May 24, 2015). Makam, A. N., H. J. Lanham, K. Batchelor, L. Samal, B. Moran, T. Howell-Stampley, L. Kirk, M. Cherukuri, N. Santini, L. K. Leykum, and E. A. Halm. 2013. Use and satisfaction with key functions of a common commercial electronic health record: A survey of primary care providers. BMC Medical Informatics and Decision Making 13:86. Marceglia, S., Fontelo, P., Ackerman, M.J. 2015. Transforming consumer health informatics: Connecting CHI applications to the health-IT ecosystem. Journal of the American Medical Informatics Association 22(e1):e210-212.. Massone, C., H. P. Soyer, G. P. B. Bugatti, Canzonieri, Ferrara, K. Ko d ama, D. Mehregan, F. Rongioletti, S. A. Janjua, V. Mashayekhi, I. Zelger, B. Zgavec, L. Cerroni, and H. Kerl. 2007. Feasibility and diagnostic agreement in teledermatopathology using a virtual slide system. Human Pathology 38(4):546-554. TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS 5-33 PREPUBLICATION COPY: UNCORRECTED PROOFS McLaughlin, P., S. O. Neill, N. Fanning, A. M. Mc Garr igle, O. J. Connor, G. Wyse, and M. M. Maher. 2012. Emergency CT brain: Preliminary interpretation w ith a tablet device: Image quality and diagnostic performance of the Apple iPad. Emergency Radiology 19(2):127-133. Meeks, D. W., M. W. Smith, L. Taylor, D. F. Sittig, J. M. Scott, and H. Singh. 2014. An analysis of electronic health record-related patient safety concerns. Journal of the American Medical Informatics Association 21(6):1053-1059. Meigs, J. B., E. Cagliero, A. Dubey, P. Murphy-Sheehy, C. Gildesgame, H. Chueh, M. J. Barry, D. E. Singer, and D. M. Nathan. 2003. A controlled trial of web-based diabetes disease management: The MGH diabetes primary care improvement project. Diabetes Care 26(3):750-757. Middleton, B., M. Bloomrosen, M. A. Dente, B. Hashmat, R. Koppel, J. M. Overhage, T. H. Payne, S. T. Rosenbloom, C. Weaver, J. Zhang, and American Medical Informatics Association. 2013. Enhancing patient safety and quality of care by improving the usability of electronic health record systems: Recommendations from AMIA. Journal of the American Medical Informatics Association 20(e1):e2-8. Moacdieh, N., and N. B. Sarter. 2014. Display clutter: A review of definitions and measurement techniques. Human Factors 0018720814541145, first published on July 3, 2014. Mosa, A. S., I. Yoo, and L. Sheets. 2012. A systematic review of healthcare applications for smartphones. BMC Medical Informatics and Decision Making 12:67. NIST (National Institute of Standards and Technolo gy). 2015. Usability. www.nist.gov/healthcare/usability/ (accessed April 6, 2015). O'Malley, A. S., K. Draper, R. Gourevitch, D. A. Cross, and S. H. Scholle. 2015. Electronic health records and support for primary care teamwork. Journal of the American Medi cal Informatics Association 22(2):426- 434. Obara, P., M. Sevenster, A. Travis, Y. Qian, C. Westin, and P. J. Chang. 2015. Evaluating the referring physician's clinical history and indication as a means for communi cating chronic conditions that are pertinent at the point of radiologic interpretation. Journal of digital imaging 28(3):272-282. Ober, K. P. 2015. The electronic health record: Are we the tools of our tools? The Pharos 78(1):8-14. ONC (Office of the National Coordinator for Health Information Technology). 2014a. Connecting health and care for the nation: A 10-year vision to achieve an interoperable health IT infrastructure . Washington, DC: The Office of the National Coordinator for Health Information Technology. http://www.healthit.gov/ sites/default/files/ONC10year InteroperabilityConceptPaper .pdf (accessed February 9, 2015. ONC. 2014b. Health information technology adverse event reporting: Analysis of two databases. Washington, DC: The Office of the National Coordinator for Health Information Technology. ONC. 2015. Report on health information blocking. Washington, DC: The Office of the National Coordinator for Health Information Technology. http://healthit.gov/s ites/default/files/reports/info_blocking_040915.pdf (accessed April 10, 2015). Otte-Trojel, T., A. de Bont, J. van de Klundert, and T. G. Rundall. 2014. Characteristics of patient portals developed in the context of health information exchanges: Early policy effects of incentives in the meaningful use program in the United States. Journal of Medical Internet Research 16(11):e258. Park, J. B., H. J. Choi, J. H. Lee, and B. S. Kang. 2013. An assessment of the iPad 2 as a CT teleradiology tool using brain CT with subtle intracranial hemorrhage under conventional illumination. Journal of Digital Imaging 26(4):683-690. Parkash, V., A. Domfeh, P. Cohen, N. Fischbach, M. Pronovost, G. K. Haines 3 rd, and P. Gershkovich. 2014. Are amended surgical pathology reports getting to the correct responsible care provider? American Journal of Clinical Pathology 142(1):58-63. Peterson, M. C., J. H. Holbrook, D. Von Hales, N. L. Sm ith, and L. V. Staker. 1992. Contributions of the history, physical examination, and laboratory investigation in making medical diagnoses. Western Journal of Medicine 156(2):163-165. Poon, E. G., J. S. Haas, A. Louise Puopolo, T. K. Gandhi, E. Burdick, D. W. Bates, and T. A. Brennan. 2004. Communication factors in the follo w-up of abnormal mammograms. Journal of General Internal Medicine 19(4):316-323. Powell, A. C., A. B. Landman, and D. W. Bates. 2014. In search of a few good apps. JAMA 311(18):1851-1852. Prevedello, L. M., S. Ledbetter, C. Farkas, and R. Khorasani. 2014. Impl ementation of Speech Recognition in a Community-based Radiology Practice: Effect on Report Turnaround Times. Journal of the American College of Radiology 11(4):402-406. 5-34 IMPROVING DIAG NOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Ramirez. E. 2012. Talking data with your doc: The do ctors. http://quantifiedself.com/2012/04/talking-data-with- your-doc-the -doctors/ (accessed July 30, 2015). Quint, L. E., D. J. Quint, and J. D. Myles. 2008. Frequency and spectrum of errors in final radiology reports generated with automatic sp eech recognition technology. Journal of the American College of Radiology 5(12):1196-1199. Ramnarayan, P., R. R. Kapoor, J. Coren, V. A. Tomlinson, P. M. Tayl or, J. C. Wyatt, and J. Britto. 2003. Measuring the impact of diagnostic decision support on the quality of clinical decision making: Development of a reliable and valid composite score. Journal of the American Medical Informatics Association 10:563-572. Ramnarayan, P., G. C. Roberts, M. Core n, V. Nanduri, A. Tomlinson, P. M. Taylor, J. C. Wyatt, and J. F. Britto. 2006. Assessment of the potential impact of a reminder system on the reduction of diagnostic errors: A quasi-experimental study. BMC Medical Informatic s and Decision Making 6:22. Ramnarayan, P., N. Cronje, R. Brown, R. Negus, B. Coode, P. Moss, T. Ha ssan, W. Hamer, and J. Britto. 2007. Validation of a diagnostic reminder system in emergency medicine: A multi-centre study. Emergency Medicine Journal 24(9):619-624. Rao, V. M., D. C. Levin, L. Parker, B. Cavanaugh, A. J. Frangos, and J. H. Sunshine. 2010. How widely is computer-aided detection used in screening and diagnostic mammography? Journal of the American College of Radiology 7(10):802-805. Reiner, B., E. Siegel, Z. Protopapas, F. Hooper, Ghebrekidan, and M. Scanlon. 1999. Impact of filmless radiology on frequency of clinician consultations with radiologists. American Journal of Roentgenology 173(5):1169-1172. Robison, J. 2014. Two major insurers recognize telemedicine. Las Vegas Review-Journal, October 5. www.reviewjournal.com/business/tw o-major-insurers-recognize-telemed icine (accessed May 24, 2015). Rosenbloom, S. T., J. C. Denny, H. Xu, N. Lorenzi, W. W. Stead, and K. B. Johnson. 2011. Data from clinical notes: A perspective on the tension between structure and flexible documentation. Journal of the American Medical Informatics Association 18(2):181-186. Roshanov, P. S., J. J. You, J. Dhaliwal, D. Koff, J. A. Mackay, L. Weise-Kelly, T. Navarro, N. L. Wilczynski, and R. B. Haynes. 2011. Can computerized clinical deci sion support systems improve practitioners' diagnostic test ordering behavior? A decision-maker-researcher partnership systematic review. Implementation Science 6:88. RTI International. 2014. RTI International to de velop road map for health IT safety center. www.rti.org/newsroom/news.cf m?obj=FCC8767E-C2DA-EB8B-AD7E 2F778E6CB91A (accessed March 27, 2015). Rubin, M. N., and B. M. Demaerschalk. 2014. The use of telemedicine in the management of acute stroke. Neurosurgery Focus 36(1):E4. Schiff, G. D. 2005. Introduction: Communicating critical test results. Joint Commission Journal of Quality and Patient Safety 31(2):63-65. Schiff, G., and D. W. Bates. 2010. Can electronic clin ical documentation help pr event diagnostic errors? New England Journal of Medicine 362(12):1066-1069. Semigran, H.L., J.A. Linder, C. Gidengil, and A. Mehrotra. 2015. Evaluation of symptom checkers for self diagnosis and triage: Audit study. BMJ 351:h3480. Sequist, T. D., T. K. Gandhi, A. S. Karson, J. M. Fiskio , D. Bugbee, M. Sperling, E. F. Cook, E. J. Orav, D. G. Fairchild, and D. W. Bates. 2005. A randomized trial of electronic clinical reminders to improve quality of care for diabetes and coronary artery disease. Journal of theAmerican Medi cal Informatics Association 12(4):431-437. Shenvi, E., and R. El-Kareh. 2014. Clin criteria to screen for inpatient diagnostic errors: A scoping review. Diagnosis 2:3-19. Silva, G. S., S. Farrell, E. Shandra, A. Viswanathan, an d L. H. Schwamm. 2012. The Status of telestroke in the United States: A survey of currently active stroke telemedicine programs. St roke 43:2078-2085. Simborg, D. W., B. H. Starfield, S. D. Horn, and S. A. Yourtee. 1976. Information fa ctors affecting problem follow- up in ambulatory care. Medical Care 14(10):848-856. Singh, H., H. S. Arora, M. S. Vij, R. Rao, M. M. Khan, and L. A. Petersen. 2007a. Communication outcomes of critical imaging results in a co mputerized notification system. Journal of theAmerican Medical Informatics Association 14(4):459-466. Singh, H., E. J. Thomas, M. M. Khan, and L. A. Petersen . 2007b. Identifying diagnostic errors in primary care using an electronic screening algorithm. Archives of Internal Medicine 167(3):302-308. TECHNOLOGY AND TOOLS IN THE DIAGNOSTIC PROCESS 5-35 PREPUBLICATION COPY: UNCORRECTED PROOFS Singh, H., A. D. Naik, R. Rao, and L. A. Petersen. 2008. Reducing diagnostic errors through effective communication: harnessing the power of information technology. Journal of General Internal Medicine 23(4):489-494. Singh, H., T. Giardina, S. Forjuoh, M. Reis, S. Kosmach, M. Khan, and E. Thomas. 2012. Electronic health record- based surveillance of diagnost ic errors in primary care. BMJ Quality and Safety 21:93-100. Singh, H., C. Spitzmueller, N. J. Petersen, M. K. Saw hney, and D. F. Sittig. 2013. Information overload and missed test results in electronic h ealth record-based settings. JAMA Internal Medicine 173(8):702-704. Singh, M., and T. R. Pal. 2011. Voice recognition technology implementation in surgical pathology: Advantages and limitations. Archives of Pathology & Laboratory Medicine 135(11):1476-1481. Sittig, D., and H. Singh. 2010. A new sociotechnical model for studying health information technology in complex adaptive healthcare systems. Quality and Safety in Health Care 19:i68-i74. Sittig, D. F., and H. Singh. 2012. Electronic h ealth records and national patient-safety goals. New England Journal of Medicine 367(19):1854-1860. Sittig, D. F., D. C. Classen, and H. Singh. 2014a. Patient safety goals for the proposed Federal Health Information Technology Safety Center. Journal of the American Medical Informatics Association. amiajnl-2014. Siitig, D.F., J.S. Ash, and H. Singh. 2014b. The SAFER guides: empowering organizations to improve the safety and effectiveness of elect ronic health records. American Journal of Managed Care 20(5):418-423. Sittig, D. F., D. R. Murphy, M. W. Smith, E. Russo, A. Wri ght, and H. Singh. 2015. Graphical display of diagnostic test results in electronic health r ecords: A comparison of 8 systems. Journal of the American Medical Informatics Association, March 18 [Epub ahead of print]. Joint Commission. 2015a. Preventing the EHR. www.jointcommission.org/issues/article.aspx?Ar ticle=bj%2B%2F2w37MuZrouWveszI1weWZ7ufX%2FP 4tLrLI85oCi0%3D (acce ssed March 27, Sentinel event alert. www.join tcommission.org/assets/1/18/SE A_54.pdf (accessed April 30, 2015). Tsai, T. C., and A. K. Jha. 2014. Hospital consolidation, competition, and quality: Is bigger necessarily better? JAMA 312(1):29-30. Upadhyay, D. K., D. F. Sittig, and H. Singh. 2014. Ebola US Patient Zero: Lessons on misdiagnosis and effective use of electronic health records. Diagnosis October 23 [Epub ahead of print]. Uzuner, O., I. Goldstein, Y. Luo, and I. Kohane. 2008. Identifying patient smoking status from medical discharge records. Journal of the American Medical Informatics Association 15(1):14-24. Vargas, B. B., D. D. Channer, D. W. Dodick, and B. M. Demaerschalk. 2012. Teleconcussion: An innovative approach to screening, diagnosis, and management of mild traumatic brain injury. Telemedicine and E Health 18(10):803-806. Verghese, A. 2008. Culture shock--patient as icon, icon as patient. New England Journal of Medicine 359(26):2748- 2751. Wachter, R. M. 2015. The digital doctor . New York: McGraw Hill. Walker, J. M., P. Carayon, N. Leveson, R. A. Paulus, J. Tooker, H. Chin, A. Bothe, Jr., and W. F. Stewart. 2008. EHR safety: The way forward to safe and effective systems. Journal of the American Medical Informatics Association 15(3):272-277. Watson, W. 2014. Texas Health Presbyterian Hosp ital Dallas implements changes after Ebola event. www.texashealth.org/news/ ebola-update-c hanges-implemented-af ter-ebola-event (a ccessed April 7 2015, 2015). Weed, L. L. 1968. Medical R ecords That Guide and Teach. New England Journal of Medicine 278(11):593-600. Weed, L.L. and N.J. Zimny. 1989. The problem-oriented system, problem-knowledge coupling, and clinical decision making. Physical Therapy 69 (7):565-568. Weed, L. L., and L. Weed. 2014. Diagnosing diagnostic failure. Diagnosis 1(1):13-17. Weed, L.L., and L. Weed. 2011. Medicine in denial USA: Createspace. Westat. 2013. EHR contracts: Key cont ract terms for users to understand. www.healthit.gov/.../ehr_contracting_terms_final_508_compliant.pdf (accessed May 25, 2015). XPRIZE. 2015. The prize: Empowering personal healthcare. h ttp://tricorder.xprize.org/ about/overview (accessed May 24, 2015). Zakim, D., N. Braun, P. Fritz, and M. D. Alscher. 2008 . Underutilization of information and knowledge in everyday medical practice: Evaluation of a computer-based solution. BMC Making 8:50. 6-1 PREPUBLICATION COPY: UNCORRECTED PROOFS 6 Organizational Characteristics, the Physical Environment, and the Diagnostic Process: Improving Learning, Culture, and the Work System INTRODUCTION This chapter focuses on the actions that hea lth care organizations can take to design a work system that supports the di agnostic process and reduces di agnostic errors (see Figure 6-1). The term \"health care organization\" is meant to encompass all settings of care in which the diagnostic process occurs, such as integrated car e delivery settings, hospita ls, clinician practices, retail clinics, and long-te rm care settings, such as nursing and rehabilitation centers. To improve diagnostic performance, health car e organizations need to engage in organizational change and participate in continuous learning. The committee r ecognizes that health care organizations may differ in the challenges they face related to diagno sis and in their capacity to improve diagnostic performance. They will need to tailor the committee's recommendations to their resources and challenges with diagnosis. The first section of this chapter describe s how organizational learning principles can improve the diagnostic process by providing feedb ack to health care professionals about their diagnostic performance and by better characterizi ng the occurrence of and response to diagnostic errors. The second section highlights organizatio nal characteristics\u2014in pa rticular, culture and leadership\u2014that enable organizational change to improve the work system in which the diagnostic process occurs. The third section discu sses actions that health care organizations can take to improve the work system and support th e diagnostic process. For example, the physical environment (i.e., the design, layout, and ambient conditions) can affect diagnosis and is often under the control of heal th care organizations. 6-2 FIGUR E the wor k In clinical p (IOM) r e continuo u improve , that do n organiza t their suc c patient o u continuo u A diagnosi s al., 2014process, h near mis s E 6-1 Orga n k system in w ORG A n any health practice (Da v eport Best C a us learning a systematic a ot practice c tions ensure cesses and m utcomes (D a usly learnin g A focus on c o s and reduc e ; IOM, 201 3 health care o ses and to i m PREPUBL Inizational c h which the di a ANIZATIO N care organi z vies and Nu t are at Lowe r are able to m ally and sea m continuing l e that indivi d mistakes and avies and N u g health car e ontinuous le a e diagnostic e 3; Trowbrid g organizatio n mplement fe e ICATION C Oharacteristic s agnostic pro c NAL LEA R zation, prior tley, 2000; I O r Cost concl u more \"consis t mlessly, wit h earning (IO M dual health c a also use thi utley, 2000) . e organizati o arning in th e errors (Dix o ge, 2014). T o ns need to es t edback mec h IM OPY: UNCO Rs and the p h cess occurs. RNING TO itizing conti OM, 2013; W uded that h e tently deliv e h each care e M, 2013, p. 1 are professi o s informati o Box 6-1 de on. e diagnostic on-Woods et o support co n tablish appr o hanisms d E inuous learn i WHO, 2006 ) ealth care or g er reliable p e experience a 1). These le a onals and he on to suppor t scribes the c process has al., 2011; G ntinuous le a oaches to id e diagnostic p e DIAGNOSIS I ROOFS ronment are E DIAGNO S ing is key t o ). The Instit u ganizations f erformance, and transitio n arning healt h alth care te a t improved p characteristi c the potenti a Gandhi, 201 4 arning in the entify diagn o erformance. IN HEALTH C two eleme n SIS o improving ute of Medi c focused on and consta n n\" than syst e h care ams learn fr o performance cs of a al to improv e 4; Grumbac h diagnostic ostic errors a The challe n CARE nts of cine ntly ems om and e h et and nges ORGANIZATIONAL CHARACTERISTICS AND THE PHYSICAL ENVIRONMENT 6-3 PREPUBLICATION COPY: UNCORRECTED PROOFS related to identifying an d learning from diagnostic errors and near misses, as well as actions health care organizations and health care professional societies can take to achieve this goal, are discussed below. BOX 6-1 Characteristics of a Continuously Learning Health Care Organization Science and Informatics Real-time access to knowledge \u2014A learning health care organization continuously and reliably captures, curates, and delivers the best available evidence to guide, support, tailor, and improve clinical decision making and the safety and quality of care. Digital capture of the care experience\u2014A learning health care organization captures the care experience on digital platforms for the real-time generation and application of knowledge for care improvement. Patient-Clinician Partnerships Engaged, empowered patients \u2014A learning health care organization is anchored on patient needs and perspectives and promotes the inclusion of patients, families, and other caregivers as vital members of the continuously learning care team. Incentives Incentives aligned for value \u2014In a learning health care organization, incentives are actively aligned to encourage continuous improvement, identify and reduce waste, and reward high-value care. Full transparency \u2014A learning health care organization sy stematically monitors the safety, quality, processes, prices, costs, and outcomes of care and makes information available for care improvement and informed choices and deci sion making by clinicians, patients, and their families. Culture Leadership-instilled culture of learning \u2014A learning health care organization is stewarded by leadership committed to a culture of teamwork, collaboration, and adaptability in support of continuous learning as a core aim. Supportive system competencies \u2014In a learning health care organization, complex care operations and processes are constantly refined through ongoing team training and skill building, systems analysis and information development, and the creation of feedback loops for continuous learning and system improvement. SOURCE: IOM, 2013. Identifying, Learning From, and Re ducing Diagnostic Errors and Near Misses Diagnostic errors have long been an understu died and underappreciated quality challenge in health care 2005; She nvi Edna and El-Kareh, 2015; Wachter, presentation to the committee, Paul Epner repo rted that the Society to Improve Diagnosis in Medicine \"know[s] of no effort initiated in any health system to routinely and effectively assess diagnostic performance\" (2014; see also Graber et al., 2014). The paucity of attention on 6-4 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS diagnostic errors in clinical pr actice has been attributed to a number of factors. Two major contributors are the lack of ef fective measurement of diagnosti c error and the difficulty in detecting these errors in clinical practice (Berenson et al ., 2014; Graber et al., 2012b; Singh and Sittig, 2015). Additional f actors may include a health care or ganization's competing priorities in patient safety and quality improvement, the percep tion that diagnostic errors are inevitable or that they are too difficult to a ddress, and the need for financial resources to address this problem (Croskerry, 2003, 2012; Graber et al., 2005; Schi ff et al., 2005; Singh and Sittig, 2015). These challenges make it difficult to iden tify, analyze, and learn from diagnostic errors in clinical practice (Graber, 2005; Grab er et al., 2014; Henriksen, 2014; Singh and Sittig, 2015). Compared to diagnostic erro rs, other types of medical errors\u2014including medication errors, surgical errors, and health care-acquire d infections\u2014have historically received more attention within health care organizations (Graber et al ., 2014; Kanter, 2014; Singh, 2014; Trowbridge, 2014). This is partly attributable to the lack of fo cus on diagnostic errors within national patient safety and quality improvement e fforts. For example, the Agency for Healthcare Research and Quality's (AHRQ's) Patient Safety Indicators and the Joint Commission's list of specific sentinel events do not focus on di agnostic errors (AHRQ, 2015b; Joint Commission, 2015a; Schiff et al., 2005). The National Quality Fo rum's Serious Reportable Events list includes only one event closely tied to diagnostic error, whic h is \"patient death or serious injury resulting from a failure to follow up or communicate laboratory, pathology, or radiology test results\" (NQF, 2011). The neglect of diagnostic performance measures for accountability purposes means that hospitals today could meet standard s for high-quality care and be rewarded through public reporting and pay-for-performance initiatives even if they have major challenges with diagnostic accuracy (Wachter, 2010). While current research estimates indicate that diagnostic errors ar e a common occurrence, health care organizations \"do not have the tools and strategies to measure diagnostic safety and most have not integrated diagnostic error into their existing patient sa fety programmes\" (Singh and Sittig, 2015, p. 103). Identifying diagnostic erro rs within clinical pr actice is critical to improving diagnosis for patients, but measuremen t has become an \"una voidable obstacle to progress\" (Singh, 2013, p. 789). The lack of comprehensive information on diagnostic errors within clinical practice perpetuates the belief that these errors are unc ommon or unavoidable and impedes progress on reducing diagnostic errors . Improving diagnosis will likely require a concerted effort among all health care organiza tions and across all set tings of care to better identify diagnostic errors and near misses, learn from them, and, ultimately, take steps to improve the diagnostic process. Thus, the committee recommends that health care organizations monitor the diagnostic proc ess and identify, learn from, and reduce diagnostic errors and near misses as a comp onent of their research, quality improvement, and patient safety programs. In addition to identifying near misses and errors, health care organizations can also benefit from evaluati ng factors that are c ontributing to improved diagnostic performance. Given the nascent field of measurement of the diagnostic process, the committee concluded that bottom-up experimentation will be necessary to develop approaches for monitoring the diagnostic process an d identifying diagnostic errors a nd near misses. It is unlikely that one specific method will be successful at identifying all diagnostic e rrors and near misses; some approaches may be more appropriate than others for specific organizational settings, types of diagnostic erro rs, or for identifying specific causes. It may be necessary for health care organizations to use a variety of methods in or der to have a better sens e of their diagnostic ORGANIZATIONAL CHARACTERISTICS AND THE PHYSICAL ENVIRONMENT 6-5 PREPUBLICATION COPY: UNCORRECTED PROOFS performance (Shojania, 2010). As further information is collected regarding the validity and feasibility of specific methods for monitoring the diagnostic process a nd identifying diagnostic errors and near misses, this information will need to be disseminated in order to inform efforts within other health care organizations. The dissemi nation of this information will be especially important for health care organizations that do not have the financial and human resources available to pilot-test some of the potential methods for the identif ication of diagnostic errors and near misses. In some cases, small group practices may find it useful to pool their resources as they explore alternative approaches to identify errors and near misses and monitor the diagnostic process. As discussed in Chapter 3, there are a numbe r of methods being employed by researchers to describe the incidence and nature of diagnostic errors, in cluding postmortem examinations, medical record reviews, health insurance claims analysis, medical malpractice claims analysis, second reviews of diagnostic testing, and survey s of patients and clinic ians. Some of these methods may be better suited than others for identifying diagnostic erro rs and near misses in clinical practice. Medical record reviews, medica l malpractice claims analysis, health insurance claims analysis, and second reviews in diagnostic testing may be more pragmatic approaches for health care organizations because they leverage readily available data sources. Patient surveys may also be an important mechanism for health car e organizations to consid er. It is important to note that many of the methods described below ar e just beginning to be applied to diagnostic error detection in clinical practice; very few ar e validated or available for widespread use in clinical practice (Bhise and Singh, 2015; Graber, 2013; Singh and Sittig, 2015). Medical record reviews can be a useful met hod to identify diagnostic errors and near misses because health care organizations can leve rage their electronic hea lth records (EHRs) for these analyses. The committee's recommendation on health information technology (health IT) highlights the need for EHRs to include user- friendly platforms that enable health care organizations to measure diagnostic errors (see Chap ter 5). Trigger tools, or algorithms that scan EHRs for potential diagnostic errors, can be used to identify patie nts who have a higher likelihood of experiencing a diagnostic error. For example, they can identify patients who return for inpatient hospitalization with in two weeks of a primary care visit or patients who require follow-up after abnormal diagnostic testing results. Review of thei r EHRs can evaluate whether a diagnostic error occurred, using explicit or implicit criteria. Fo r diagnostic errors, these tools have been piloted primarily in outpatient settin gs, but they are also being considered in the inpatient setting (Murphy et al., 2014; Shenvi Edna and El-Kareh, 2015; Singh et al., 2012a). EHR surveillance, such as Kaiser Permanente's SureNet System, 1 is another opportunity to detect patients at risk of experiencing a dia gnostic error (Grabe r et al., 2014; HIMSS Analytics, 2015; Kanter, 2014). The SureNet System identifies patients who may have inadvertent lapses in care (such as a patient with iron deficiency an emia who has not had a colonoscopy to rule out colon cancer) and ensures that follow-up occurs by proactively reaching out to affected patients and members of their care team. Medical malpractice claims analysis is anot her approach to identif ying diagnostic errors and near misses in clinical practice. Chapte r 7 discusses the importance of leveraging the expertise of professional liability insurers in efforts to im prove diagnosis and reduce diagnostic errors and near misses. Health care organizatio ns can collaborate with professional liability insurers in efforts to identify diagnostic errors a nd near misses in clinical practice; because of the richness of the data source, this method could also be helpful in iden tifying the reasons why 1 Kaiser Permanente's SureNet System was previously known as the SafetyNet System. 6-6 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS diagnostic errors occur. However, there are lim itations with malpractice claims data, because these claims may not be repres entative\u2014few people who experience adverse events file claims, and the ones who do are more likely to have experienced serious harm. Although there are few examples of using hea lth insurance claims data to identify diagnostic errors and near misses, this may be a useful method, especially if it is combined with other approaches (e.g., if it is linked to medical re cords or diagnostic testi ng results). One of the advantages of this data source is that it makes it possible to assess the downstream clinical consequences and costs of errors. It also enables comparisons across different settings, types of clinicians, and days of the week (which can be important because there may be some days when staffing is low and the volume of patients unexpectedly high). Second reviews of diagnostic te sting results could also help health care organizations identify diagnostic errors and n ear misses related to the interpretive aspect of the diagnostic testing processes. A recent guideline recommen ded that health care organizations use second reviews in anatomic pathology to identify disa greements and potential interpretive errors (Nakhleh et al., 2015). The guideline notes that or ganizations will likely need to tailor the second review process that they employ and the number of reviews they conduct to their specific needs and resources (Nakhleh et al., 2015). Some or ganizations include anatomic pathology second reviews as part of their quality assurance a nd improvement efforts. The Veteran's Health Administration requires that \"[a]t least 10 perc ent of the cytotechnologi st's gynecologic cases that have been interpreted to be negative are routinely rescreened, and are diagnosed and documented as being negative by a qualifie d pathologist\" (VHA, 2008, p. 32). Though the infrastructure for peer review in radiology is st ill evolving, there are now frameworks specific to radiology for identifying and learning from dia gnostic errors (Allen and Thorwarth, 2014; Lee et al., 2013; Provenzale and Kranz, 2011). In addition to the use of peer re view in identifying errors, there is an increasing emphasis on using p eer review tools to promote peer learning and improve practice quality (Alle n and Thorwarth, 2014; Brook et al., Nagy, 2012; Iyer et al., 2013; Kruskal et al., 2008). Organizations can participate in the American College of Radiology's RADPEERTM program, which includes a second review process that can help identify diagnostic performance issues rela ted to medical image interpretation (ACR, 2015). Patient surveys represent anothe r opportunity. The use of such surveys is in line with the committee's recommendation to create environments in which patients and their families feel comfortable sharing their feedb ack and concerns about diagnos tic error and near misses (see Chapter 4). Eliciting this information via surveys may be helpful in identifying errors and near misses, and it can also provide useful feedback to the organization and h ealth care professionals (see section below on feedback). For example, a recent patient-initiated voluntary survey of adverse events found that harm was commonly a ssociated with reported diagnostic errors and identified actions that patients believed coul d improve care (Southwick et al., 2015). In addition to identifying diagnostic errors that have already occurred, some methods used to monitor the diagnostic process and iden tify diagnostic errors can be used for error recovery. Error recovery is the process of identifying failures early in the diagnostic process so that actions can be taken to reduce or avert negative effects resulting from the failure (IOM, 2000). Methods that identify failures in the diagnostic process or catch diagnostic errors before significant harm is incurred could make it possibl e to avoid diagnostic errors or to intervene early enough to avert significant harm. By scanning medical record s to identify la pses in care, the SureNet system supports error recovery by id entifying patients at ri sk of experiencing a ORGANIZATIONAL CHARACTERISTICS AND THE PHYSICAL ENVIRONMENT 6-7 PREPUBLICATION COPY: UNCORRECTED PROOFS diagnostic error (HIMSS Analytics, 2015; Kant er, 2014) (see also th e section on a supportive work system). Beyond identifying diagnostic erro rs and near misses, organizational learning aimed at improving diagnostic performance and reducing di agnostic errors will also require a focus on understanding where in the diagnost ic process the failures occur, the work system factors that contribute to their occurrence, what the outcomes were, and how these failures may be prevented or mitigated (see Chapter 3). For example, the committee's conceptual model of the diagnostic process describes the steps with in the process that are vulnera ble to failure: engagement, information gathering, integrati on, interpretation, establishing a diagnosis, and communication of the diagnosis. If a health care organization is evaluating where in the diagnostic testing process a failure occurs, the brain-to-brain loop model may be helpful in conduc ting these analyses, in particular by articulating the five phases of testing: pre-pre-analytical, pre-analytical, analytical, post-analytical, and post-post-analytical (Ple bani et al., 2011; Pleb ani and Lippi, 2011). It is also important to determine the work system factors that c ontribute to diagnostic errors and near misses. Some of the data sources and methods mentioned above, such as malpractice claims analyses and medical record reviews, can provide valu able insights into the causes and outcomes of diagnostic errors. Health care organizations can also employ formal error analysis and other risk assessment methods to un derstand the work system factors that contribute to diagnostic errors and near misses. Relevant analytical methods include root cause analysis, cognitive autopsies, and morbidity and mortalit y conferences (Gandhi, 20 14; Graber et al., 2014; Reilly et al., 2014). Root cause analysis is a pr oblem-solving method that attempts to identify the factors that contributed to an e rror; these analyses take a system s approach by trying to identify all of the underlying factors ra ther than focusing exclusively on the health care professionals involved (AHRQ, 2014b). Maine Me dical Center recently conducte d a demonstration program to inform clinicians about the root causes of di agnostic errors. They created a novel fishbone root cause analysis procedure, which visually repres ents the multiple cause and effect relationships responsible for an error (Trowbridge, 2014). Or ganizations and individuals can also take advantage of continuing educati on opportunities focused on using root cause analysis to study diagnostic errors in order to improve their ab ility to identify and understand diagnostic errors (Reilly et al., 2015). The cognitive autopsy is a variation of a root cause analysis that involves a clinician reflecting on the reasoni ng process that led to the error in order to identify causally relevant shortcomings in reasoning or d ecision making (Croskerry, 2005). Morbidity and mortality conferences bring a diverse group of hea lth care professionals to gether to learn from errors (AHRQ, 2008). These can be useful, especial ly if they are framed from a patient safety perspective rather than focusing on attributing blame. Other anal ytical methods used in human factors and ergonomics research could also be ap plied in health care organizational settings to further elucidate the work system components that contribute to diagnostic errors (see Chapter 3) (Bisantz and Roth, 2007; Carayon et al., 2014; Kirw et al., 2012; Roth, 2008; Salas et al., 1995). As health care organizations develop a better understanding of diagnostic errors within their organizations, they can begin to implement a nd evalua te interventions to prevent or mitigate these errors as part of their pa tient safety, research, and quality improvement efforts. To date, there have been relatively few studies that ha ve evaluated the impact of interventions on improving diagnosis and reducing diagnostic errors and near misses; three recent systematic reviews summarized current interv entions (Graber et al., 2012a; Mc Donald et al., 2013; Singh et al., 2012b). These reviews found that the measures us ed to evaluate the interventions were quite 6-8 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS heterogeneous, and there were concerns about th e generalizability of so me of the findings to clinical practice. Health care organizations can take into consideration some of the methodological challenges identified in these reviews in order to ensure that their evaluations generate much-needed evidence to identify successful interventions. The Medicare conditions of participation and accreditation organizations can be leveraged to ensure that health care organizations have appropriate programs in place to identify diagnostic errors and near misses, learn from them, and improve the diagnostic process. The Medicare conditions of participati on are requirements that health ca re organizations must meet in order to receive Medicare and Medicaid paym ent (CMS, 2015a). State survey agencies and accreditation organizations (such as the Joint Commission, the Healthcare Facilities Accreditation Program, the Accreditation Commission for Health Care, the College of American Pathologists, and Det NorskeVeritas-Germanisch er Lloyd) determine whet her organizations are in compliance with the Medicare conditions of participation through surveys and site visits. Some of these organizations accr edit the broad range of health care organizations, while others confine their scope to a single type of health care organization. Other accreditation bodies, such as the National Committee for Quality Assurance (NCQA), provide administrative and clinical accreditation and certification of health plans and provider organizations. NCQA, for example, offers accountable care organization (ACO) accr editation, which evaluates an organization's capacity to provide the coordina ted, high quality care and performan ce-reporting that is required of ACOs (NCQA, 2013). Accreditation processes, federal oversight, and quality improvement efforts specific to diagnostic tes ting can also be used to ensure quality in the diagnostic process (see Chapter 2). By leveraging the Medicare c onditions of participa tion requirements and accreditation processes, it may be possible to use th e existing oversight programs that health care organizations have in place to monitor the diagnos tic process and to ensure that the organizations are identifying diagnostic errors and near misses, learning from them, and making timely efforts to improve diagnosis. Thus, the committee recommends that accreditation organizations and the Medicare conditions of participation should require that health care organizations have programs in place to monitor the diagnostic process and identify, learn from, and reduce diagnostic errors and near misses in a timely fashion. As more is learned about successful program approaches, accreditation organiz ations and the Medicare conditions of participation should inco rporate these proven approaches into updates of these requirements. Postmortem Examinations The committee recognized that many approach es to identifying diagnostic errors are important, but the committee though t that the postmortem examination (also referred to as an autopsy) warranted additional committee focu s because of its role in understanding the epidemiology of diagnostic error. Postmortem exam inations are typically performed to determine cause of death and can reveal discrepancie s between premortem and postmortem clinical findings (see Chapter 3). However, the number of postmortem examinations performed in the United States has declined substantially si nce the 1960s (Hill and Anderson, 1988; Lundberg, 1998; MedPAC, 1999). One of the contributors to the decline is that in 1971 the Joint Commission eliminated the requirement that hos pitals conduct these exam inations on a certain percentage of deaths in thei r facility\u201420 per cent in community hospitals and 25 percent in teaching facilities\u2014in order to receive accreditation (Allen, 2011; CDC, 2001). Cost is another factor; according to a survey of medical institutions in eight states, researchers in 2006 estimated ORGANIZATIONAL CHARACTERISTICS AND THE PHYSICAL ENVIRONMENT 6-9 PREPUBLICATION COPY: UNCORRECTED PROOFS that the mean cost of performing a postmor tem examination was $1,275 (Nemetz et al., 2006). Insurers do not directly pay for postmortem exam inations, as they typically limit payment to procedures for living patients. Medicare bundles payment for postmortem examinations into its payment for quality improvement activities, wh ich may also disincentiv ize their performance (Allen, 2011). Given the steep decline in postmortem examinat ions, there is interest in increasing their use. For example, Hill and Anderson (1988) recomm ended that half of all deaths in hospitals, nursing homes, and other accredited medical f acilities receive a postmortem examination. Lundberg (1998) recommended reinstating the manda te that a percentage of hospital deaths undergo postmortem examination, either to meet Medicare conditions of participation or accreditation standards. The Medicare Payment Advisory Commission proposed a number of recommendations designed to increase the postmortem examination rate and evaluate their potential for use in \"quality improvement a nd error reduction initiatives\" (MedPAC, 1999, p. xviii). The committee concluded that a new appro ach to increasing the use of postmortem examinations is warranted. The committee weighed the relative merits of increasing the number of postmortem examinations conducted throughout the United States versus a more targeted approach. The requirements for postmortem examina tions in the current Me dicare conditions of participation state that postmortem examinations should be performed when there is an unusual death; in particular, these requi rements state that \"medical staff should attempt to secure an autopsy [postmortem examination] in all case s of unusual death and of medical-legal and educational interest\" (CMS, 2015b, p. 210). In th ese circumstances, the committee concluded that health care organizations should continue to perform th ese postmortem examinations. In addition, the committee concluded that it is ap propriate to have a limited number of highly qualified health care systems participate in conducting routine postmortem exams that produce research-quality information about the inci dence and nature of diagnostic errors. Thus, the committee recommends that the U.S. Departme nt of Health and Hu man Services (HHS) should provide funding for a designated subset of health care systems to conduct routine postmortem examinations on a repres entative sample of patient deaths. To accomplish this, a subset of health care systems (which reflect a broad array of different settings of care) could receive funding to perform routin e postmortem examinations in a representative sample of patient deaths. A competitive grant process co uld be used to identify these systems. In recognition that not all patients' next of kin will cons ent to the performance of a postmortem examination, these systems can charact erize the frequency with which the request for a postmortem examination is refused and thus better describe the risk of response bias in results. This approach will likely provide better epidemiologic data than current practice and represent an advance over curr ent selection methods for performing postmortem examinations, because clinicians do not seem to be able to predict cases in which diagnostic errors will be found (Shojania et al., 2002; Shojania et al., 2003). The committee recognizes that the data collected from health care systems that ar e highly qualified to conduct routine postmortem examinations may not be representative of all systems of care. However, the committee concluded that this is a more feasible approach, given the fina ncial and workforce demands of conducting postmortem examinations. Findings from the health care systems that pe rform routine postmortem examinations can then be disseminated to the broader health care community. Participating health care systems could be required to produce annual reports on the epidemiology of diagnostic errors, the value 6-10 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS of postmortem examinations as a tool for identif ying and reducing such errors, and, if relevant, the role and value of postmortem examina tions in quality improvement efforts. These health care systems could also i nvestigate how new, minimally invasive postmortem approaches compare with trad itional full body postmortem examinations. Less invasive approaches include the use of me dical imaging, laparoscopy, biopsy, histology, and cytology. Given the advances in molecular diagno stics and advanced imaging techniques, these new approaches could provide useful insights into the incidence of diagnostic error and may be more acceptable options for patients' next of kin. For example, instead of conducting a full body postmortem exam, pathologists could biopsy tissu e samples from an organ where disease is suspected and conduct molecular analysis (van der Linden et al., 2014). Some studies suggest that minimally invasive postmortem examinati ons (including a combination of medical imaging with other minimally invasive postmortem investigations) have been found to have accuracy similar to that of conventiona l postmortem examinations in fetuses, newborns, and infants (Lavanya et al., 2008; Pichereau et al., et al.; Weustink et al., 2009). Postmortem imaging in adults has shown less promise for replacing postmortem exams, but these techniques continue to be activel y explored (O'Donnell and Woodford, 2008; Roberts et al., 2012). A concern with mini mally invasive postmortem imaging is that it may be subject to similar limitations that affect imaging in liv ing patients, and may not detect pre- and post- mortem discrepancies. Further understanding the benefits and limitations of minimally invasive approaches may provide critical information moving forward. If successful approaches to minimally invasive postmortem examinations are found, they could play a role in re-establishing the practice of routine postmortem inves tigation in medicine (Saldiva, 2014). Improving Feedback Feedback is a critical mechanism that health care organizatio ns can use to support continuous learning in the diagnostic process. The Best Care at Lower Cost report called for the creation of feedback loops that support co ntinuous learning and system improvement (IOM, 2013). As it relates to diagnosis, feed back entails informing an individu al, team, or organization about its diagnostic performance, including its successes, near misses, and diagnostic errors (Black, 2011; Croskerry, 2000; Gandhi, 2014; Gandhi et al., 2005; Schiff, 2008, 2014; Trowbridge, 2014). The committee received substantial input indicating th at there are limited opportunities for feedback on diagnostic performance There ar e often not systems in place to provide clinicians with input on whether they made an accurate, timely diagnosis or if their patients experienced a diagnostic error. The failure to follow up with patients about their diagnosis and treatment\u2014both in the near term and long term\u2014is a major gap in improving diagnosis. The committee concluded that improving diagnostic performance requires feedback at all levels of health care. Feedb ack can help clinicians assess how well they are performing in the diagnostic process, correct overconfidence, identi fy when remediation efforts are needed, and reduce the likelihood of repeated mistakes (B erner and Graber, 2008; Croskerry and Norman, 2008). Feedback on diagnostic performance can also provide opportunities for health care organizational learning and improvements to the work system (Plaza et al., 2011). To improve the opportunities for feedback, the committee recommends that health care organizations should implement procedures and practices to provide systematic fe edback on diagnostic performance to individual health care prof essionals, care teams, and clinical and organizational leaders. ORGANIZATIONAL CHARACTERISTICS AND THE PHYSICAL ENVIRONMENT 6-11 PREPUBLICATION COPY: UNCORRECTED PROOFS Box 6-2 identifies some characteristics for effective feedback interventions (Hysong et al., 2006; Ivers et al., 2014). Fee dback interventions in high-perf orming organizations have been found to share a number of characteristics, incl uding being actionable, timely, individualized, and non-punitive; a non-punitive culture helps foster an environment in which mistakes can be viewed as opportunities for grow th and improvement (Hysong et al., 2006). Other studies have found that feedback is likely to have the largest effect when baseline performance is low and feedback occurs regularly (Iver s et al., 2012; Lopez-Campos et al., 2014). Tailoring the feedback approach to the individual re cipient and choosing an appropr iate source of feedback (e.g., supervisor versus a peer as the provider of feedback) are important variables in determining how well recipients will resp ond (Ilgen et al., 1979). Health care organizations need to be aware of the factors that can im pede the provision of feedback, such as the fragmentation of the health care system, resistance to critical feedback from clinicians, and the lack of time to fo r follow-up (Schiff, 2008). In addition, improving feedback will likely require health care organizati ons to invest additional time and resources into developing systematic feedback mechanisms. BOX 6-2 Characteristics of Effective Feedback Interventions Feedback Is non-punitive Is actionable Is timely Is individualized Comes from the appropriate individual (i.e., a trusted source) Targets behavior that can be affected by feedback Is provided to recipients who are responsible for improvement Includes a description of the desired performance/behavior SOURCE: Hysong et al., 2006, and Ivers et al., 2014. There are many opportunities to provide fee dback in clinical practice. Methods to monitor the diagnostic process and identify diagnostic erro rs and near misses can be leveraged as mechanisms to provide feedback. Feedback opportunities include disseminating postmortem examination results to clinicians who were involve d in the patient's care; sharing the results of patient surveys, medical record reviews, or in formation gained through follow-up with the health care professionals; using patient actors or simula ted care scenarios to assess and inform health care professionals' diagnostic performance; a nd others (Schwartz et al., 2012; Schwartz and Saul, 2014; Southwick et al., 2015; Weiner et al., 2010). As discussed in Chapter 4, patients and their families have unique insights into the dia gnostic process and the occurrence of diagnostic error; therefore, following up with patients a nd their families about their experiences and outcomes will be an important source of fee dback (Schiff, 2008). Morbidity and mortality conferences, root cause analyses, departme ntal meetings, and leadership \"WalkRounds\" 2 provide 2 Leadership WalkRounds are a tool to connect leadership with frontline clinicians and health care professionals. They consist of leadership (senior executives, vice-presi dents, etc.) making announced or unannounced visits to different areas of the organi zation to engage with frontline employees (I nstitute for Healthcare Improvement, 2004). 6-12 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS additional opportunities to provide feedback to health care professionals, care teams, and leadership about diagnostic performance. Performance monitoring programs designed to satisfy the requirements of the Mammography Quality Standards Act have been used to improve feedback on diagnostic performance on mammography to radiologists an d medical imaging facilities (Allen and Thorwarth, 2014). AHRQ recently pr oposed recommendations for the development of consumer and patient safety reporting systems, which or ganizations can use for feedback and learning purposes (AHRQ, 2011). Peer review processe s, including second reviews of anatomic pathology specimens and medical images, can also be utilized for feedback, and there is an increasing emphasis on using peer-review tools to promote peer learning and improve practice quality (Allen and Thorwarth, 2014; Brook et al ., Iyer et al., 2013; Kruskal et al., 2008). For example, RADPEERTM allows anonymous peer review of previous image interpretations by integrating previous images into current workflow to allow for a non-disruptive peer review proce ss. Summary statistics of image reviews are made available to participating groups and clinicians to im prove performance (ACR, 2015). As of 2013, 16,450 clinicians in 1,127 groups were enrolled in the RADPEERTM program; 1,218 clinicians had used or were using the program as part of the American Board of Radi ology's Practice Quality Improvement project for maintena nce of certification (ACR, 2013). Leveraging Health Care Professional So cieties' Efforts to Improve Diagnosis Health care organizations can leverage external input from h ealth care professional societies to inform the organizations' efforts to monitor and improve the diagnostic process. Health care professional socie ties can facilitate improvement s in the diagnostic process by appealing to intrinsic motivation and professionalism. Prioritization efforts are an opportunity to engage health care professional societies and th eir members in the development of diagnosis- improvement approaches speci fic to their specialties. Thus, the committee recommends that health care professional societies should iden tify opportunities to improve accurate and timely diagnoses and reduce diagnostic errors in their specialties. Such an effort could be modeled on the C hoosing Wisely Campaign, which was initiated by the American Board of Internal Medicine F oundation to encourage patient and health care professional communication as a way to ensu re high-quality, high-value care. The campaign invited health care professional so cieties to each develop a list of five services (i.e., tests, treatments, and procedures) that are commonly used in practice, but may be unnecessary or not supported by the evidence as improving patient care . These lists were made publicly available as a way of encouraging discussions about appropria te care between patients and health care professionals. Choosing Wisely received nationa l media attention and engaged more than 50 health care professional societies (Choosing Wi sely, 2015). A major lesson from the Choosing Wisely Campaign is the importance of beginning with a small group of founding organizations and then expanding membership. Engaging consumer groups as the program progressed was also an important component of the campaign. One f actor in the campaign's success was that it allowed flexibility within limits; participating health care professional societies and boards were given flexibility in identifying their \"Top 5\" serv ices, but items on each list had to be evidence- based and within the purview of that particular society. Early efforts on prioritization could focu s on identifying the most common diagnostic errors and \"don't miss\" health conditions, such as those that present the greatest likelihood for diagnostic errors and harm (Newman-Toker et al., 2013). For example, stroke, acute myocardial ORGANIZATIONAL CHARACTERISTICS AND THE PHYSICAL ENVIRONMENT 6-13 PREPUBLICATION COPY: UNCORRECTED PROOFS infarction, or pulmonary embolism may be importan t areas of focus in the emergency department setting while cancer is a frequently missed di agnosis in the ambulator y care setting (CRICO, 2014; Gandhi et al., 2006; Newman-Toker et al., 2013; Schiff et al., 2013). Efforts to improve diagnosis can include both improving the quality and safety of diagnosis and increasing efficiency and value, such as identifying inapprop riate diagnostic testing. Another approach may be for societies to identify \"low-hanging fruit,\" or targets that are easily remediable, as a high priority. Doing this may increase the likelihood of having early successes that can contribute to the long-term success of the effort (Kotter, 1995). Some groups may identify particular actions, tools, or approaches to reduce errors associated with a part icular diagnosis within their specialties (such as checklists, second reviews, or decision support tools). Each society could identify five high-priority ar eas to improve diagnosis. The gr oups would need to be given latitude in the identifi cation of their targets, and, as was th e case in Choosing Wisely, a primary constraint could be that ther e must be evidence indicating that adopting the recommendation would result in improving diagnosis or reducing diagnostic error. This could also be an opportunity for health care profession al societies to collaborate, es pecially in cases of diagnoses that may be missed because of the inappropriate isolation of symptoms among specialties. For example, urologists, primary care clinicians, an d neurologists could collaborate to make the diagnosis of normal pressure hydrocephalus (sym ptoms include frequent urination, a type of balance problem, and some memory loss) a \" not to be missed\" di agnosis (McDonald, 2014). ORGANIZATIONAL CHARACTERISTICS FOR LEARNING AND IMPROVED DIAGNOSIS Health care organizations influence the work system in which diagnosis occurs and also play a vital role in implementing changes to improve diagnosis and prevent diagnostic errors. The committee identified organizational culture and organizational leadership and management as key characteristics for ensuring continuous le arning from and improvements to the diagnostic process. Health care organizations are responsible for developing a culture that promotes a safe place for all health care professiona ls to identify and learn from diagnostic errors. Organizational leaders and managers can facilitate this cultur e and set the priorities to achieve progress in improving diagnostic performance and reducing diagnostic errors. The committee drew upon the broader quality and patient safety literature to inform their disc ussion of leadership and culture change to improve diagnosis. Making connections to previous efforts to improve quality and safety are particularly important, given the li mited focus on improving diagnosis in the patient safety and quality improvement literature. The committee concluded that many of the findings from the broader fields of quality improvement and patient safety have the potential to reduce diagnostic errors and improve diagnosis. However, this also represents a research need\u2014further studies need to evaluate the ge neralizability of these findings to diagnosis (see Chapter 8). Promoting a Culture for Improved Diagnosis As discussed in Chapter 1, health care orga nizations can leverage four major cultural movements in health care\u2014patient safety, professionalism, patient engagement, and collaboration\u2014to create a local environment that supports con tinuous learning and improvement in diagnosis. Organizational culture refers to an organization's norms of be havior and the shared basic assumptions and values that sustain t hose norms (Kotter, 2012; Schein, 2004). Though the 6-14 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS cultures in most health care orga nizations exhibit common elements, they can differ considerably due to varying missions, values, a nd histories. Another factor that makes culture in health care organizations more complicated is the presence of subcultures (multiple distinct sets of norms and beliefs within a single organization) (Sch ein, 2004). Subcultures can reflect the individual attitudes of a nurse manager on a specific hospital floor or inte rprofessional differences that spring from the long history and social concerns of each health care pr ofession (Hall, 2005). The existence of multiple cultures within a single h ealth care organization may make it difficult to promote the shared values, goals, and appr oaches necessary for improving diagnosis. Some aspects of culture may promote di agnostic accuracy, such as the intrinsic motivation of health care professionals to deliver high-quality care and the dedicated focus on quality and safety found in some health care or ganizations. Other aspects of culture may be detrimental to efforts to improve diagnosis, including the persistence of punitive, fault-based cultures; cultural taboos on providi ng peer feedback; hierarchical attitudes that are misaligned with team-based practice; and the acceptance of th e inevitability of errors. Punitive cultures that emphasize discipline and punishment for those who make mistakes are not conducive to improved diagnostic performance; this type of culture thwarts the learning process because health care professionals fear the consequences of reporting errors (Hoffman and Kanzaria, 2014; Khatri et al., 2009; Larson, 2002; Schiff, 1994). Clinicians within thes e settings may also feel uneasy about provid ing feedback to colleagues about th eir diagnostic performance or the occurrence of diagnostic erro rs (Gallagher et al., 2013; Tucker and Edmondson, 2003). There have been multiple calls for health care organizations to create non-punitive cultures that encourage co mmunication and learning (IOM, 2000, 2004, 2013). Despite these efforts, a punitive culture persists within some health care organizations (Chassin, 2013; Chassin and Loeb, 2013). For example, a recent survey found th at less than half (44 percent) of health care professionals perceived th at their organizations had a non-punitive response to error (AHRQ, 2014a). The fault-based medical liabilit y system and, in rare cases, clinicians who exhibit unprofessional or intimidating behavior al so contribute to the persistence of punitive cultures (Chassin, 2013; Chassin and Loeb, 2013). Cultures that continue to view diagnosis as a solitary clinicia n activity discount the important roles of teamwork and collaboration. A culture that validates the perspective that diagnostic errors are inevitable may also pose problems. When these cu ltural attitudes are pervasive within health care organizations, a ttempts to improve diagnosis are challenging (Berner and Graber, 2008). Changing an organization's culture is ofte n difficult, and there are many opportunities throughout the change process where failure can occur (Kotter, 1995). Heal th care organizations may be hesitant to attempt culture change because of system inertia, concern that benefits due to the present culture could be lost, or because ther e is uncertainty regarding which approaches to improving culture work best in a given orga nizational setting (Chassin, 2013; Coiera, 2011; Parmelli et al., 2011). Organizations may attemp t to implement multiple change processes simultaneously, and this can lead to change fatigue, where employees experience burnout and apathy (Perlman, 2011). Other factors may include: the failure to convey the urgent need for change; poor communication of the successes that have resulted from change; the inadequate identification, preparation, or re moval of barriers to change; a nd insufficient involvement of leadership and management in the change initi ative (Chassin, Kotter, 2012). Although the challeng es to cultural change can be significant, the committee concluded that addressing organizati onal culture is central to improving diagnosis ORGANIZATIONAL CHARACTERISTICS AND THE PHYSICAL ENVIRONMENT 6-15 PREPUBLICATION COPY: UNCORRECTED PROOFS (Gandhi, 2014; Kanter, 2014; Thomas, 2014). Thus, the committee recommends that health care organizations should adopt policies and pr actices that promote a non-punitive culture that values open discussion and fe edback on diagnostic performance. There are a variety of approaches that can be employed to improve culture (Davies et al., 2000; Etchegaray et al., 2012; Schein, 2004; Schiff, 2014; Williams et al., 2007). The measurement of an organization's culture is often a first step in the improvement process because it facilitates the identification of cultural challe nges and the evaluation of interventions (IOM, 2013). A number of measurement tools are available, including surveys to identify health care professionals' perception of their organizati on's culture (AHRQ, al., 2007; Sexton et al., 2006; Watts et al., 2010). Organizations can create a cu lture that supports learning and continual improvement by implementing a just culture, also referred to as a culture of safety (IOM, 2004); Kanter, 2014; Khatri et al., 2009; Larson, 2002; Milstead, 2005). A just culture balances competing priorities\u2014learning from error a nd personal accountability\u2014by understanding that health care is a complex activity involving imperf ect individuals who will make mistakes, while not tolerating reckless behavior (AHRQ, 2015a). The just cult ure approach distinguishes between \"human error\" (an inadvertent act by a cl inician, such as a slip or lapse), \"at-risk behavior\" (taking shortcuts, violat ing a safety rule without perceiving it as likely to cause harm), and \"reckless behavior\" (conscious choices by clinicians to engage in behavior they know poses a significant risk, such as ignor ing required safety steps). The just culture model recommends \"consoling the clinician\" involve d in human error, \"coaching the clinician\" who engages in at- risk behavior, and reserving disc ipline only for clinicians whos e behavior is truly reckless. Further refinements to this approach employ a \"substitution test\" (i.e., would three other clinicians with similar skills and knowledge do the same in similar circumstances?) to identify situations in which system flaw s have developed that create pr edisposing conditions for the error in question to occur. Finally, whether or not the clinician has a history of repeatedly making the same or similar mistakes is considered in fo rmulating an appropriate response to error. Health care organizations can also look to high reliability organizations (HROs), which operate in high-stakes conditions but maintain high safety levels (such as those found in the nuclear power and aviation industr ies). Health care organizations can benefit from adapting the traits of HRO cultures, such as rejecting complacency and focusing on error reduction (Chassin and Loeb, 2011; Singh, 2014; Thomas, 2014; Weick and Sutcliffe, 2011). The involvement of supportive and committed leadership is another co mponent of successful attempts to improve culture and is a key component of HRO succe ss (Chassin, Kotter, 1995; Kotter, 2012). Health care organizations can espouse cultural values that su pport the open di scussion of diagnostic performance and improvement (Davie s and Nutley, 2000) (see Box 6-3). The culture needs to promote the discussion of error and o ffer psychological safety (Jeffe et al., 2004; Kachalia, 2013). Successes need to be celebrated, and mistakes need to be treated as opportunities to learn and improve. Complacency w ith regard to current diagnostic performance needs to be replaced with an enduring desi re for continuing improvement. An emphasis on teamwork is critical, and it can be facilitated by a culture that values the development of trusting, mutually respectful relationships among health care professionals, patients and their family members, and organizational leadership. 6-16 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS BOX 6-3 Important Cultural Values for Continuously Learning Health Care Systems Celebration of success. If excellence is to be pursued with vigor and commitment, its attainment needs to be valued within the organizational culture. Absence of complacency. Learning organizations value innovation and change\u2014they are searching constantly for new ways to improve their outcomes. Recognition of mistakes as opportunities to learn. Learning from failure is a prerequisite for achieving improvement. This requires a culture that accepts the positive spin-offs from errors, rather than seeking to blame. This does not imply a tolerance of routinely poor or mediocre performance from which no lessons are learned or of reckless disregard for safe practices. Belief in human potential. It is people who drive success in organizations\u2014using their creativity, energy, and innovation. Therefore the culture within a learning organization values people and fosters their professional and personal development. Recognition of tacit knowledge. Learning organizations recognize that those individuals closest to processes have the best and most intimate knowledge of their potential and flaws. Therefore, the learning culture values tacit knowledge and shows a belief in empowerment (the systematic enlar gement of discretion, responsibility, and competence). Openness. Because learning organizations try to foster a systems view, sharing knowledge throughout the organization is one key to developing learning capacity. \"Knowledge mobility\" emphasizes informal c hannels and personal contacts over written reporting procedures. Cross disciplinary and multifunction teams, staff rotations, on-site inspections, and experiential learning are essential components of this informal exchange. Trust. For individuals to give their best, take risks, and develop their competencies, they must trust that such activities will be appreciated and valued by colleagues and managers. In particular, they must be confident that should they err, they will be supported, not castigated. In turn, managers must be able to trust that subordinates will use wisely the time, space, and resour ces given to them through empowerment programs\u2014and not indulge in opportunistic behavior. Without trust, learning is a faltering process. Outward looking. Learning organizations are engaged with the world outside as a rich source of learning opportunities. They look to their competitors for insights into their own operations and are attuned to the experiences of other stakeholders, such as their suppliers. In particular, they are focused on obtaining a deep understanding of clients' needs. SOURCE: Davies and Nutley, 2000. Adapted by permission from BMJ Publishing Group Limited. Developing learning organizations in the new NHS , H. T. O. Davies and S. N. Nutley, 320, 998-1001, 2000. Despite the difficulties one faces in imp lementing culture change, health care organizations have begun to make changes that can improve patient safety (Chassin and Loeb, 2013). For instance, changing culture was a critical factor in sustaining th e reduction in intensive care unit-acquired central line bloodstream infec tions in Michigan state hospitals (Pronovost et al., 2006, 2008, 2010). Cincinnati Children's Hospital has focused on better process design that ORGANIZATIONAL CHARACTERISTICS AND THE PHYSICAL ENVIRONMENT 6-17 PREPUBLICATION COPY: UNCORRECTED PROOFS leverages human factors expertis e and on building a culture of reliability (Cincinnati Children's Hospital, 2014). A number of health care or ganizations have undert aken the process of instituting a just culture by pr ioritizing learning and fairness a nd creating an atmosphere of transparency and psychological safety (Marx, 200 1; Wyatt, 2013). For example, after two high- profile medical mistakes, the Dana-Farber Cancer Institute implemented a pl an to develop a just culture in order to improve learning from error and care performance (C onnor et al., 2007). Its plan centered on incorporating a se t of principles into practice th at promoted learning, the open discussion of error, individual accountability, and program evalua tion; this plan was endorsed and supported by organizational leadership (Connor et al., 2007). Organiza tions can explore the strategies that are best suited to their needs and aims (e.g., sp ecific strategies for small practices to improve culture) (Gandhi and Lee, 2010; Shostek, 2007). Leadership and Management Organizational leaders are responsible for se tting the priorities and expectations that guide a health care organization and for determin ing the rules and policie s necessary to achieve the organization's goals. Orga nizational leaders can include the health care organization's governing body, the chief executive officer and othe r senior managers, a nd clinical leaders; collaboration among these leaders is critical to achieving the organization's quality goals. According to the Joint Commission (2009, p. 3), only \"the leaders of a hea lth care organization have the resources, influence, and control\" to ensure that an organization has the right elements in place to meet quality and safety priorities , including a non-punitive cultu re, the availability of appropriate resources (including human, financial, physical, and informational), a sufficient number of competent staff, and an ongoing evaluation of the quality and safety of care. In particular, health care organizati on governing boards have an oblig ation to ensure the quality and safety of care within their organizations (Arnwine, 2002; Callender et al., 2007; Joint Commission, 2009). 3 As a part of their oversight func tion, governing boards routinely identify emerging quality of care trends and can help prior itize efforts to address these issues within an organization. The involvement of organizational leaders and managers is crucial fo r successful change initiatives (Dixon-Woods et al., Brightman, 2000; Silow-Carro ll et al., 2007). In many health care organizations, organizational leaders have not focused significant attention on improving diagnosis and reducing diagnosti c errors (Gandhi, al., 2013) . However, facilitating change will require the support and involvement of these leaders. To start, health care governing boards can prioritize diagnosis and can support senior manage rs in implementing polic ies and practices that support continued learning and improved diagnostic performance. For example, potential policies and practices could focus on team-based care in diagnosis, the adoption of a continuously learning culture, opportunities to provide feedback to clinicians, and approaches to monitor the diagnostic process a nd identify diagnostic e rrors and near misses. All organizational leaders can raise awareness of the quality and safety challenges re lated to diagnostic error as well as dispelling the myth that diagnostic erro rs are inevitable (Leape , 2010; Wachter, 2010). Importantly, organizational leaders can appeal to the intrinsic motivation of health care professionals to drive improvements in diagnosis. 3 42 C.F.R. \u00a7482.12(a)(5); Caremark International Inc. Derivative Litigation, 698 A. 2d 959 (Del. Ch. 1996). 6-18 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Focusing on improving diagnosis and reducing diagnostic error is necessary to improve the quality and safety of care; in addition, it has the potential to re duce organizational costs (IOM, 2013). For example, a recent study identifi ed a link between inpatient harm and negative financial consequences for hospita ls (Adler et al., 2015). The downstream effects associated with diagnostic error, including patient harm, malpractice claims, and inappropriate use of resources, suggest that organizations that focus on im proving diagnosis could extend benefits beyond patient outcomes to include reducing costs. Res earch that evaluates the economic impact of diagnostic errors may be helpful in building the business case for prioritizing diagnosis within health care organizations (see Chapter 8). There are a variety of strategi es that can be drawn upon as le aders chart a course toward improved diagnostic performance, including six-sigma and lean management principles (Chassin and Loeb, 2013; Jimmerson et al., Gamm , 2009). Involving leadership in WalkRounds, morbidity and mortality conferences, and departme ntal meetings can help increase leadership visibility as diagnostic performance improveme nts are implemented (Frankel et al., 2003, 2005; Thomas et al., 2005). It may also be beneficial for leaders to pur sue improvement efforts that are person-centered and community-driven, contribute to shaping the desired culture, and leverage interdisciplinary relationships (Swensen, 2013). Insi ghts from HROs and just culture may also be useful as leaders consider the opportunities to improve diagnosis (Pr onovost et al., 2006). In addition, leaders could adapt the IOM's CEO Checklist For High Value Health Care for improving diagnosis (see Box 6-4) (IOM, 2012). Becau se a majority of change initiatives fail, leaders need to be aware of the reasons for failure and take precautions to ensure that efforts to improve diagnosis are feasible and sustainable (Coiera, 2011; Etheridge et al., 2013; Henriksen and Dayton, 2006; Kotter, 1995). Ongoing evaluation of the change effort is also warranted. BOX 6-4 A CEO Checklist for High-Value Health Care Foundational elements Governance priority\u2014visible and determined l eadership by chief executive officer (CEO) and board Culture of continuous improvement\u2014commitment to ongoing, real-time learning Infrastructure fundamentals Information technology (IT) best practices\u2014automated, reliable information to and from the point of care Evidence protocols\u2014effective, efficient, and consistent care Resource utilization\u2014optimized use of personnel, physical space, and other resources Care delivery priorities Integrated care\u2014right care, right setting, right clinicians, right teamwork Shared decision making\u2014patient-clinician collaboration on care plans Targeted services\u2014tailored community and clinic interventions for resource-intensive patients Reliability and feedback Embedded safeguards\u2014supports and prompts to reduce injury and infection Internal transparency\u2014visible progress in performance, outcomes, and costs SOURCE: Adapted from IOM, 2012.ORGANIZATIONAL CHARACTERISTICS AND THE PHYSICAL ENVIRONMENT 6-19 PREPUBLICATION COPY: UNCORRECTED PROOFS A SUPPORTIVE WORK SYSTEM TO FACILITATE DIAGNOSIS Many components of the work system are under the purview of health care organizations. Thus, organizations can implement changes that ensure a work system that supports the diagnostic process. The committee recommends that health care organizations should design the work system in which the diagnostic proce ss occurs to support the work and activities of patients, their families, and health care pr ofessionals and to facilitate accurate and timely diagnoses. The previous section described how health care organizations can use organizational culture, leadership, and manageme nt to facilitate organizational change. This section considers additional ac tions that organizations can ta ke, including a focus on error recovery, results reporting and communication, and ensuring that additional work system elements (i.e., diagnostic team members and thei r tasks, the tools and technologies they employ, and the physical and external environm ent) support the diagnostic process. Error Recovery One principle that health care organizations can apply to the design of the work system is error recovery (IOM, 2000). Ther e are a variety of opportunities fo r health care organizations to improve error recovery and resiliency in the di agnostic process. For example, improved patient access to clinical notes and diagnos tic testing results is a form of error recovery; this gives patients the opportunity to identify and correct errors in their medical record s that could lead to diagnostic errors, potentially before any harm results (see Chapter 4) (Bell et al., 2014). Informal, real-time collaboration among profe ssionals, including face-to face and virtual communication, presents another opportunity for error detecti on and recovery. Wachter (2015) noted that before the computer ization of medical imaging, trea ting health care professionals often collaborated with radiologists in readi ng rooms while reviewing films together, whereas today communication is primarily facilitated electroni cally, through the radiology report. Health care organizations can consider how to promote these types of opportunitie s for clinicians to discuss cases and to facilitate more collaborati ve working relationships during the diagnostic process. For example, some organizations are no w situating medical imaging reading stations in clinical areas, such as the emergency departme nt and the intensive care unit (Wachter, 2015). The thoughtful use of redundancies, such as s econd reviews of anatomic pathology specimens and medical images, consultations, and second opin ions in challenging cases or complex care environments, are also a form of error recovery that health care organizations can consider (Durning, 2014; Nakhleh et al., 2015). For example, the tele-intensive care unit (tele-ICU) is a telemedicine process that helps support clinicia ns' care for acutely ill patients by using off-site clinicians and software systems to provide a \"second set of eyes\" to remotely monitor ICU patients (Berenson et al., 2009; Khunlertkit and Carayon, 2013). Results Reporting and Communication The Joint Commission has identified improved co mmunication of critical test results as a key safety issue and urges organizations to \"[r] eport critical results of tests and diagnostic procedures on a timely basis\" (Joint Comm ission, 2015b, p. 2). Input to the committee echoed this call and emphasized the importance of impr oving communication between treating health 6-20 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS care professionals, pathologists, radiologists, and clinicians (Allen and Thorwarth, 2014; Epner, 2015; Gandhi, 2014; Myers, 2014). To facilitate the timely collaboration among health care professional s in the diagnostic process, the committee recommends that health care organizations should develop and implement processes to ensure effective and timely communication between diagnostic testing health care professionals and treating health care professi onals across all health care delivery settings. For example, closed loop reporting systems for diagnostic testing and referral can be implemented to ensure that test results or spec ialist findings are report ed back to the treating health care professional in a timely manner (G andhi, 2014; Gandhi et al., 2005; Myers, 2014; SHIEP, 2012). These systems can also help to ensure that relevant information is being communicated among the appropriate health care pr ofessionals. Recent efforts to improve closed loop reporting include the American Medical A ssociation's Closing th e Referral Loop Project and the Office of the National Coordinator for Health Information Technology's 360X Project, which aim to develop guidelines for closed loop referral system implementation (AMA, 2015; Williams, 2012). Early lessons from the 360X Project include the importance of seamless workflow integration, tailoring the amount of information transmitted between clinicians and specialists, and the importance of national standards for system interoperability (SHIEP, 2012). A task force comprised of pathologists, radiologists, other clinicians, risk managers, patient safety specialists, and IT specialists recommen ded four actions to improve communication and follow-up related to clinically significant test results: (1) standardize policies and definitions across networked organizations, (2) identify the pa tient's care team, (3) results management and tracking, and (4) develop shared quality a nd reporting metrics (Roy et al., 2013). Health care organizations can leverage h ealth IT resources to improve communication and collaboration among pathologists, radiologists, and treating health care professionals (Allen and Thorwarth, Gandhi, 2014; Kroft, 2014; Schiff et al., 2003). HHS' Tests Results Reporting and Follow-Up SAFER Guide offers insight on how to use EHRs to safely facilitate communication and the reporting of results (HHS, 2015). Some cl osed loop reporting systems include an alert notification m echanism designed to inform ordering clinicians when critical diagnostic testing results are available (Lacson et al., 2014a; La cson et al., 2014b; Singh et al., 2010). Dalal and colleagues (2014) identified an automated email notification system as a \"promising strategy for managing\" the results of tests that were pending when the patient was discharged. There is some evidence that the use of alert notification mechanisms improves timely communication of results reports (Lacson et al., 2014a; Lacson et al., 2014b). However, closed loop reporting systems need to be carefully designed to support clinicia n cognition and workflow in the diagnostic process; if there are a high volume of alerts, a cl inician may experience cognitive overload, which can limit the effectivene ss of such alerts (Singh et al., 2009; Singh et al., 2010). The use of standard formats may also improve the communication of test results. Studies have shown that structured radiology reports are more complete, have more relevant content, and greater clarity than free-form reports (Marco vici and Taylor, 2014; Sc hwartz et al., 2011). Similar to a checklist, structured reports have a template with standardi zed headings and often use standardized language. Input to the committee suggests that similar standardized formats for anatomic and clinical pathology results reports are likely to improve communication (Gandhi, 2014; Myers, 2014). Encouraging the use of simple r and more transparent language in results reports may also improve communicati on between health care professionals. ORGANIZATIONAL CHARACTERISTICS AND THE PHYSICAL ENVIRONMENT 6-21 PREPUBLICATION COPY: UNCORRECTED PROOFS Additional Work System Elements In addition to improving error recovery a nd results reporting and communication, health care organizations can focus more broadly on impr oving the work system in which the diagnostic process occurs. To ensure that their work system s are designed to support the diagnostic process, health care organizations need to consider all th e elements of the work system and recognize that these elements are interrelated and dynamically interact. For example, a new EHR system (tools and technology) will be most beneficial when an organization ensures that its health care professionals are trained on how to use the syst em (team members and tasks), when the system meets usability standards (externa l environment), and when the tool is located in the appropriate location (physical environment). The following sect ions highlight some of the ways in which health care organizations can improve the desi gn of work systems for improved diagnostic performance. The actions discussed are not meant to be exhaustive; rather they are offered as examples of steps organizations can take. Disc ussions in Chapters 4, 5, and 7 further augment these discussions. In addition to improving a specific work system , health care organizations also need to recognize that patients may cross organizati onal boundaries when seeking a diagnosis. This fragmentation has the potential to contribute to diagnostic errors and the failures to learn from them. Though health care organizatio ns are not solely responsible for this problem, they have a responsibility to ensure, to the best of their abilities, that th e health care system as a whole supports the diagnostic process. Teamwork and hea lth IT interoperability will help, but to meet this responsibility, organizations will need to ta ke steps to improve communication with other organizations. One mechanism, which was discussed earlier, focuses on improving the communication of diagnostic tes ting results and referrals. Implementing systematic feedback mechanisms that track patient outcomes over time could also identify diagnostic errors that transcend health care organization boundaries. In addition, payment and care delivery reforms that incentivize accountability a nd collaboration may alleviate some of the challenges that the fragmented nature of the health care system presents for diagnosis (see Chapter 7). Physical Environment The design and characteristics of the phys ical environment can influence human performance and the quality and safety of health care (Caray on, 2012; Hogarth, 2010; Reiling et al., 2008). Elements of the physical environment include the layout and ambient conditions such as distractions, noise, temperat ure, and lighting. Researchers have focused primarily on the design of hospital environments and how these environments may influence patient safety, patient outcomes, and task performance. For example, a review of 600 ar ticles on the impact of physical design found three studies that linked medication errors with factors in the hospital environment, including lighting, distractions, and interruptions (Ulrich et al., 2004). Another study found that operational failu res occurring in two large ho spitals were the result of insufficient workspace (29 percent), poor process desi gn (23 percent), and a lack of integration in the internal supply chains (23 pe rcent); only 14 percent of the fa ilures could be attributed to training and human erro r (Tucker et al., 2013). Although the impact of the physical environm ent on diagnostic error has not been well studied, there are indications that it may be an important contri butor to diagnostic performance. For example, the emergency department has be en described as a challenging environment in which to make diagnoses because of the presence of high-acuity illness, incomplete information, time constraints, and frequent interruptions a nd distractions (Crosker ry and Sinclair, 2001). 6-22 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Cognitive performance is vulnerable to distractions and interruptions, which influence the likelihood of error (Chisholm et al., 2000). Othe r physical environment factors that could influence the diagnostic process include the location of health technologies designed to support the diagnostic process, adequate space for team members to complete their tasks related to the diagnostic process, and ambient conditions that can affect cognition, such as noise, lighting, odor, and temperature (Chellappa et al., 2011; Johnson, 2011; Mehta et al., 2012; Parsons, 2000; Ward, 2013). Poorly designed systems that require health care professionals to traverse long distances to perform their tasks may increase fatigue and reduce face-to-face time with patients (Ulrich et al., 2004). To address the challenges associated with the physical environment, health care organizations can design workplaces that align with work patterns and support workflow, can locate health technology near th e point of care, and can reduc e ambient noise (Durning, 2014; Reiling et al., 2008; Ulrich et al., 2004). Other possible actions include using the appropriate lighting, providing adequate ventilation, and main taining an appropriate temperature to ensure that the ambient conditions do not negatively affect diagnostic pe rformance. Studies suggest that such changes may improve both patient outcomes and patient and family satisfaction with care provision (Reiling et al., 2008; Ulrich et al., 2004). Diagnostic Team Members and their Tasks Health care organizations need to ensure that their clinicians have the needed competencies and support to perf orm their tasks in the diagno stic process. Health care professional certification and accreditation standards can be leveraged to ensure that health care professionals within an organization are well pr epared to fulfill their roles in the diagnostic process. Health care organizations can also o ffer more opportunities for team-based training in diagnosis and can expand the use of integrated practice units, treatmen t planning conferences, and diagnostic management teams (see Chapter 4) . Ensuring adequate supe rvision and support of health care professionals\u2014especia lly the many health care professi onal trainees involved in the diagnostic process\u2014is another way for health ca re organizations to improve the work system (ACGME, 2011; IOM, 2009). For example, many health care organizations have adopted policies to address patient safe ty risks caused by fatigue (including decision fatigue), sleep deprivation, and sleep debt for medical resi dents (Croskerry and Musson, 2009; IOM, 2009; Zwaan et al., 2009). Health care professionals who work in high-stress environments may also experience mental health difficulties and burnout 4 which can increase the chance of error (AHRQ, 2005; Bakker et al., 2005; Dyrbye and Shanafelt, 2011). Several studies have identified certain characteristics of the workplace and high pa tient care demands as a cause of this stress and have suggested workforce and culture change s as potential solutions (AHRQ, 2005; Bakker et al., 2005; Dyrbye and Shanafelt, 2011). For ex ample, work scheduling practices can ensure that a health care organization has the appropria te clinicians for facilitating the diagnostic process (both amount of clinicians an d appropriate areas of expertise). Health care organizations can also make improvements to the work system to better involve patients and their familie s in the diagnostic process and in efforts to improve diagnosis (Kelly et al., 2013). For example, health care organizations can improve patient access to their EHRs, incorporate patient and family advisory gr oups, and involve patients and their families in 4 Occupational stress resulting from demanding and emotiona l relationships between health care professionals and patients that is marked by emotional exhaustion, a negative attitude towards one's patients, and the belief that one is no longer effective at work with patients (Bakker et al., 2005). ORGANIZATIONAL CHARACTERISTICS AND THE PHYSICAL ENVIRONMENT 6-23 PREPUBLICATION COPY: UNCORRECTED PROOFS processes to learn about errors when appropriate. In addition, these organizations can offer patients and their families more opportunities to provide feedback on their experiences with diagnosis (see Chapter 4). Tools and Technologies Health care organizations will need to consider how the tools and technologies they provide for the delivery of health care affect the diagnostic pr ocess. For example, Chapter 5 highlights the need for health IT tools to incor porate human-centered design principles, fit within clinical workflow, provide decisi on support, and facilitate the timel y flow of information. Health care organizations can consider these issues when choosing hea lth IT tools to incorporate, considering implementation issues, and ensuring th at use is safe and aligned with clinical workflow. Some organizations may need to c onsider workflow redesign when adopting new health IT. Resources are available to guide health care organizations as they integrate new health IT or redesign their workflow (HealthIT.gov, 2013). External Environment External environmental factors can influence th e work system in which diagnosis occurs, and although they are typically not under the control of health care or ganizations, they need to be taken into account as efforts to improve the work system are implemented at the level of health care organizations (Chapter 7). RECOMMENDATIONS Goal 4: Develop and deploy approaches to identify, learn from, and reduce diagnostic errors and near misses in clinical practice Recommendation 4a: Accreditation organizat ions and the Medicare conditions of participation should require that health care organizations have programs in place to monitor the diagnostic process and identify, learn from, and reduce diagnostic errors and near misses in a timely fashion. Proven appr oaches should be incorporated into updates of these requirements. Recommendation 4b: Health care organizations should: Monitor the diagnostic process and iden tify, learn from, and reduce diagnostic errors and near misses as a component of their research, quality improvement, and patient safety programs. Implement procedures and practices to pr ovide systematic feedback on diagnostic performance to individual health care prof essionals, care teams, and clinical and organizational leaders. Recommendation 4c: HHS should provide funding for a designated subset of health care systems to conduct routine postmo rtem examinations on a repres entative sample of patient deaths. 6-24 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Recommendation 4d: Health care professional societies should identify opportunities to improve accurate and timely diagnoses and re duce diagnostic errors in their specialties. Goal 5: Establish a work system and cult ure that support the diagnostic process and improvements in diagnostic performance Recommendation 5: Health care organizations should: Adopt policies and practices that promote a non-punitive culture that values open discussion and feedback on diagnostic performance. Design the work system in which the diagnostic process occurs to support the work and activities of patients, their famili es, and health care professionals and to facilitate accurate and timely diagnoses. Develop and implement processes to ensure effective and timely communication between diagnostic testing health care pr ofessionals and treating health care professionals across all health care delivery settings. REFERENCES ACGME (Accreditation Council for Graduate Medical Education). 2011. The ACGME 2011 duty hour standards: enhancing quality of care, supervision, and resident professional development . Chicago, IL: Accreditation Council for Graduate Medical Education. ACR (American College of Radiology). 2013. RADPEERTM marks a decade of servi ce. 15, 2015). ACR. 2015. RADPEER. http://www. acr.org/Quality-Safety/RADPEER (accessed June 7, 2015). Adler, L., D. Yi, M. Li, B. McBroom, L. Hauck, C. Samm er, C. Jones, T. Shaw, and D. Classen. 2015. Impact of inpatient harms on hospital finances and patient clinical outcomes. Journal of Patient Safety , March 23 [Epub ahead of print]. AHRQ (Agency for Healthcare Research and Quality). 2005. Organizational climate, stress, and error in primary care: the MEMO Study. In K. Henriksen, J. B. Battles, E. S. Marks, and D. I. Lewin (eds.), Advances in patient safety: From research to impl ementation (Vol. 1: 65-77). AHRQ Publication no. 05-0021-1: Rockville, MD: Agency for Healthcare Research and Quality. AHRQ. 2008. Transforming the morbidity and mortality conference into an instrument for systemwide improvement. In K. Henriksen, J. B. Battle s, M. A. Keyes, ad M. L. Grady (eds.), Advances in patient safety: New directions and alternative approaches (Vol. 2: Culture and redesign) (pp. 357-363). AHRQ Publication No. 08-0034-2: Rockville, and Quality. nt-safety-resources/resour ces/advances-in-patient- safety-2/vol2/advances-deis_82. pdf (accessed June 7, 2015). AHRQ. 2011. Designing consumer reporting systems for patient safety events. AHRQ Publication no. 11-0060-EF: Rockville, MD: Agency for Healthcare Research an d Quality. http://www.ahrq.gov/professionals/quality- patient-safety/patient-safety-resources/resources/consumer-experience/reporting/11-0060-EF.pdf AHRQ. 2014a. Hospital survey on patient safety culture : 2014 user comparative database report . AHRQ Publication no. 14-0019-EF: Rockville, MD: Ag ency for Healthcare Research and Quality. http://www.ahrq.gov/professionals/quality-patient-safety/patientsafetyculture/hospital/2014/hsops14pt1.pdf (accessed February 25, 2014). AHRQ. 2014b. Patient safety primers: Root cause an alysis. www.psnet.ahrq.gov/primer.aspx?primerID=10 (accessed May 25, 2015). AHRQ. 2014c. Surveys on patient safety culture. www.ahrq.gov/professionals/quality-patient- safety/patientsafetyculture/ (accessed 2015). AHRQ. 2015a. Glossary entry: Just culture. http://psnet.ahrq. gov/popup_glossary.aspx?name=justculture (accessed June 7, 2015). ORGANIZATIONAL CHARACTERISTICS AND THE PHYSICAL ENVIRONMENT 6-25 PREPUBLICATION COPY: UNCORRECTED PROOFS AHRQ. 2015b. Patient safety indicators overview. www.q ualityindicators.ahrq.gov/modules/psi_resources.aspx (accessed April 6, 2015). Allen, B., and W. T. Thorwarth. 2014. Follow-up comments from the American College of Radiology submitted to the Committee on Diagnostic Error in Health Care : Responses to questions from the Committee Meeting November 5-6, 2014. Inpu t submitted to the Committee on Diagnostic Error in Health Care, December 29, 2014, Washington, DC. Allen, M. 2011. Without autopsies, hospitals bury their mistakes. ProPublica , Dec. 15. www.propublica.org/article /without-autopsies-hospita ls-bury-their-mistakes (accessed May 4, 2015). AMA (American Medical Association). 2015. Closing the Referral Loop project. www.ama- assn.org/ama/pub/physician-resources/physician-consortium-performance-improvement/about-pcpi/focus- on-quality/quality-improvement/closing-refe rral-loop.page? (accessed March 27, 2015). Arnwine, D. L. 2002. Effective governance: The roles and responsibilities of board members. Proceedings (Baylor University. Medical Center) 15(1):19-22. Bakker, A. B., P. M. Le Blanc, and W. B. Schaufeli. 2005. Burnout contagion among intensive care nurses. Journal of Advanced Nursing 51(3):276-287. Bell, S., M. Anselmo, J. Walker, and T. Delbanco . 2014. OpenNotes. Input submitted to the Committee on Diagnostic Error in Health Care, December 2, 2014, Washington, DC. Berenson, R. A., J. M. Grossman, and E. A. November. 2009. Does telemonitoring of patients\u2014the eICU\u2014improve intensive care? Health Affairs 28(5):w937-w947. Berenson, R. A., D. Upadhyay, and D. R. Kaye. 2014. Placing diagnosis errors on the policy agenda . Washington, DC: Urban Institute. http://www.urban.org/research/ publication/placing-diagnosis-errors-policy-agenda (accessed June 7, 2015). Berner, E. S., and M. L. Graber. 2008. Overconfid ence as a cause of diagnostic error in medicine. American Journal of Medicine 121(5 Suppl):S2-S23. Bhise, V., and H. Singh. 2015. Measuring diagnostic safe ty of inpatients: Time to set sail in uncharted waters. Diagnosis 2(1):1-2. Bisantz, A., and E. Roth. 2007. Analysis of cognitive work. Reviews of Human Factors and Ergonomics 3(1):1-43. Black, L. M. 2011. Tragedy into policy: A quantitative study of nurses' attitudes toward patient advocacy activities. American Journal of Nursing 111(6):26-35; quiz 36-37. Brook, O. R., J. Romero, A. Brook, J. B. Kruskal, C. S. Yam, and D. Levine. 2015. The complementary nature of peer review and quality assurance data collection. Radiology 274(1):221-229. Callender, A. N., D. Hastings, M. Hemsle y, L. Morris, and M. Peregrine. 2007. Corporate responsibility and health care quality: A resource for health care boards of directors. Washington, DC: Department of Health and Human Servies Office of the In spector General and American Health Lawyers Association. Carayon, P. 2012. The physical environment in health care. In C. J. Alvarado (ed.), Handbook of human factors and ergonomics in health care and patient safety (pp. 215-234). Boca Raton, FL: Taylor & Francis Group. Carayon, P., Y. Li, M. M. Kelly, L. L. DuBenske, A. Xi e, B. McCabe, J. Orne, and E. D. Cox. 2014. Stimulated recall methodology for assessing work system barrier s and facilitators in family-centered rounds in a pediatric hospital. Applied Ergonomics 45(6):1540-1546. CDC. 2001. The autopsy, medicine, and mortality statistics. Vital Health Statistics 3(32). Hysattsville, MD: Center for Disease Control and Prevention. Chassin, M. R. 2013. Improving the quality of health care: What's taking so long? Health Affairs 32(10):1761-1765. Chassin, M. R., and J. M. Loeb. 2011. The ongoing quality improvement journey: Next stop, high reliability. Health Affairs 30(4):559-568. Chassin, M.R. 2013. High reliability health care: Getting there from here. Milbank Quarterly 91(3):459-490. Chellappa, S. L., M. Gordijn, and C. Cajochen. 2011. Can light make us bright? Effects of light on cognition and sleep. Progress in Brain Research 190:119-133. Chisholm, C. D., E. K. Collison, D. R. Nelson, and W. H. Cordell. 2000. Emergency department workplace interruptions: Are emergency physicians \"interrupt-driven\" and \"multitasking\"? Academic Emergency Medicine 7(11):1239-1243. Choosing Wisely. 2015. Choosing Wisely: An initiative of the ABIM Foundation. www.choosingwisely.org (accessed March 3, 2015). Cincinnati Children's Hospital. 2014. Becoming a high reliability organization. www.cincinnatichildrens.org/ser vice/j/anderson-center/safety/m ethodology/high-reliability/ (accessed March 9, 2015). 6-26 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS CMS (Centers for Medicare & Medicaid Services). 2015a. Conditions for coverage (CfCs) & Conditions of Participations (CoPs). www.cms.gov/Regulations-and- Guidance/Legislation/CFCsAndCoPs/index.html?redirect=/cfcsandcops/16_asc.asp (accessed March 26, 2015). CMS. 2015b. State Operations Manual, Appendix A - Survey Protocol, Regulations and Interpretive Guidelines for Hospitals. www.cms.gov/Regulations-and-Guidance/Guidance/Manuals/Down loads/som107ap_a_hospitals.pdf (accessed June 30, 2015). Coiera, E. 2011. Why system inertia makes health reform so difficult. BMJ 342:d3693. Connor, M., D. Duncombe, E. Barclay, S. Bartel, C. Borden, E. Gross, C. Mille r, and P. R. Ponte. 2007. Creating a fair and just culture: One institution's path toward organizational change. Joint Commission Journal on Quality and Patient Safety 33(10):617-624. CRICO. 2014. Annual benchmarking report: Malpractice risks Cambridge, http://www.rmfstrategies .com/benchmarking (acce ssed June 4, 2015). Croskerry, 2000. The feedback sanction. Academic Emergency Medicine 7(11):1232-1238. Croskerry, P. 2003. The importance of cognitive errors in diagnosis and strategies to minimize them. Academic Medicine 78(8):775-780. Croskerry, P. 2005. Diagnostic failure : A cognitive and affective approach. In Advances in patient safety: From research to implementation, Vol. 2 (pp. 241-254). AHRQ Publication Nos. 050021: Rockville, MD: Agency for Health Care Research and Quality. Croskerry, P. 2012. Perspectives on diagnostic failure and patient safety. Healthcare Quarterly 15(Special Issue):50-56. Croskerry, P., and D. Musson. 2009. Individual Factors in Patient Safety. In P. Croskerry, K. S. Cosby, S. M. Schenkel, and R. L. Wears (eds.) Patient Safety in Emergency Medicine (pp. 269-276). Philadelphia, PA: Lippincott Williams and Wilkins. Croskerry, P., and G. Norman. 2008. Over confidence in clinical decision making. American Journal of Medicine 121(5 Suppl):S24-S29. Croskerry, P., and D. Sinclair. 2001. Emergency medicine: A practice prone to error. Canadian Journal of Emergency Medicine 3(4):271-276. Dalal, A. K., C. L. Roy, E. G. Poon, D. H. Williams, N. Nolido, C. Yoon, J. Bu dris, T. Gandhi, D. W. Bates, and J. L. Schnipper. 2014. Impact of an automated email notification system for results of tests pending at discharge: a cluster-randomized controlled trial. Journal of the American Medical Informatics Association 21(3):473-480. Davies, H. T. O., and S. M. Nutley. 2000. Developing learning organisations in the new NHS. BMJ 320(7240):998- 1001. Davies, H. T. O., S. M. Nutley, and R. Mannion. 20 00. Organisational culture and quality of health care. Quality in Health Care 9(2):111-119. Dhaliwal, G. 2014. Blueprint for diagnostic excellence. Pr esentation to the Committee on Diagnostic Error in Health Care, November 21, 2014, Washington, DC. Dixon-Woods, M., C. Bosk, E. Aveling, C. Goeschel, and P. Pronovost. 2011. Explaining Michigan: Developing an ex-post theory of a quality improvement program. Milbank Quarterly 89(2):167-205. Durning, S. J. 2014. Submitted input. Input submitted to the Committee on Diagnostic Error in Health Care, October 24, 2014, Washington, DC. Dyrbye, L. N., and T. D. Shanafelt. 2011. Physician burnout: A po tential threat to successful health care reform. JAMA 305(19):2009-2010. Epner, P. 2014. An Overview of Diagnostic Error in Medi cine. Presentation to the Committee on Diagnostic Error in Health Care, April 28, 2014, Washington, DC. Epner, P. 2015. Submitted input. Input submitted to the Committee on Diagnostic Error in Health Care, January 13, 2015, Washington, DC. Etchegaray, J. M., T. H. Gallagher, S. K. Bell, B. Dunl ap, and E. J. Thomas. 2012. Error disclosure: A new domain for safety culture assessment. BMJ Qua lity & Safety 21(7):594-599. Etheridge, F., Y. Couturier, J.-L. Denis, L. Tremblay, and C. Tannenbaum. 2013. Explaining the success or failure of quality improvement initiatives in long-term care organizations from a dynamic perspective. Journal of Applied Gerontology 33(6):672-689. Farley, D. O., M. S. Ridgely, P. Mendel, S. S. Teleki, and C. L. Damberg. 2009. Assessing patient safety practices and outcomes in the US health care system . Santa Monica, CA: RAND Corporation. ORGANIZATIONAL CHARACTERISTICS AND THE PHYSICAL ENVIRONMENT 6-27 PREPUBLICATION COPY: UNCORRECTED PROOFS Firth-Cozens, J. 2004. Organisational trust: The keystone to patient safety. Quality and Safety in Health Care 13(1):56-61. Fotenos, A., and P. Nagy. 2012. What are your goals for peer review? A framework for understanding differing methods. Journal of the American College of Radiology 9(12):929-930. Frankel, A., E. Graydon-Baker, C. Neppl, T. Simmonds, M. Gustafson, and T. K. Gandhi. 2003. Patient safety leadership WalkRounds. Joint Commission Journal on Quality and Patient Safety 29(1):16-26. Frankel, A., S. P. Grillo, E. G. Baker, C. N. Huber, S. Abookire, M. Grenham, P. Console, M. O'Quinn, G. Thibault, and T. K. Gandhi. 2005. Patient safety leadership WalkRounds at Partners HealthCare: Learning from implementation. Joint Commission Journal on Quality and Patient Safety 31(8):423-437. Gallagher, T. H., M. M. Mello, W. Levinson, M. K. Wynia, A. K. Sachdeva, L. Snyder Sulmasy, R. D. Truog, J. Conway, K. Mazor, A. Lembitz, S. K. Bell, L. Sokol-Hessner, J. Shapiro, A. L. Puopolo, and R. Arnold. 2013. Talking with patients about other clinicians' errors. New England Journal of Medicine 369(18):1752-1757. Gandhi, T. K. 2014. Focus on diagnostic errors: Unders tanding and prevention. Pres entation to the Committee on Diagnostic Error in Health Care, August 7, 2014, Washington, DC. Gandhi, T. K.., and T. H. Lee. 2010 . Patient safety beyond the hospital. New England Journal of Medicine 363(11):1001-1003. Gandhi, T. K., E. Graydon-Baker, C. Neppl Huber, A. D. Whittemore, and M. Gustafson. 2005. Closing the loop: Follow-up and feedback in a patient safety program. Joint Commission Journal on Quality and Patient Safety 31(11):614-621. Gandhi, T. K., A. Kachalia, E. J. Thomas, A. L. Puopolo, C. Yoon, T. A. Brennan, and D. M. Studdert. 2006. Missed and delayed diagnoses in the ambulatory setting: A study of closed malpractice claims. Annals of Internal Medicine 145(7):488-496. Gittell, J. H., R. Seidner, and J. Wimbush. 2010. A re lational model of how high-performance work systems work. Organization Science 21(2):490-506. Graber, M. L. 2005. Diagnostic erro rs in medicine: A case of neglect. Joint Commission Journal on Quality and Patient Safety 31(2):106-113. Graber, M.L. . 2013. The incidence of diagnostic error in medicine. BMJ Quality & Safety 22(Suppl 2):ii21-ii27. Graber, M. L., N. Franklin, and R. Gordon. 20 05. Diagnostic error in internal medicine. Archives of Internal Medicine 165(13):1493-1499. Graber, M. L., S. Kissam, V. L. Payne, A. N. D. Meyer, A. Sorensen, N. Lenfestey, E. Tant, K. Henriksen, K. LaBresh, and H. Singh. 2012a. Cognitive interventions to reduce diagnostic error: A narrative review. BMJ Quality & Safety 21(7):535-557. Graber, M. L., R. M. Wachter, and C. K. Cassel. 2012b. Bringing diagnosis into the quality and safety equations. JAMA 308(12):1211-1212. Graber, M. L., R. Trowbridge, J. S. Myers, C. A. Um scheid, W. Strull, and M. H. Kanter. 2014. The next organizational challenge: Finding and addressing diagnostic error. Joint Commission Journal on Quality and Patient Safety 40(3):102-110. Grumbach, K., C. R. Lucey, and S. C. Johnston. 2014. Transforming from centers of learning to learning health systems: The challenge for academic health centers. JAMA 311(11):1109-1110. Hall, P. 2005. Interprofessional teamwo rk: Professional barriers. Journal of Interprofessional Care 19(Suppl 1):188-196. HealthIT.gov. 2013. What is work flow redesign? Why is it important ? http://www.healthit.gov/providers- professionals/faqs/ehr-workflow-redesign (accessed May 1, 2015). Henriksen, K. 2014. Improving diagnostic performance: Some unrecognized obstacles. Diagnosis 1(1):35-38. Henriksen, K.., and E. Dayton. 2006. Organizational silence and hidden threats to patient safety. Health Services Research 41(4p2):1539-1554. Henriksen, K., J. B. Battles, E. S. Marks, and D. I. Lewin. 2005. Advances in patient safety: From research to i mplementation, Volume 2: Concepts and methodology . Rockville, MD: Agency for Healthcare Research and Quality. HHS (Department of Health and Human Services). 2015. Test results reporting and follow-up. www.healthit.gov/safer/ guide/sg008 (accessed April 9, 2015). Hill, R. B., and R. E. Anderson. 1988. The autopsy\u2014Medical practice and public policy . Butterworths: Boston. HIMSS Analytics. 2015. HIMSS analytics stage 7 Case study: Kaiser Permanente. http://himssanalytics.org/case- study/kaiser-permanente-stage-7-cas e-study (accessed May 10, 2015). 6-28 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Hines, S., K. Luna, J. Lofthus, M. Marquardt, and D. Stelmokas. 2008. Becoming a high reliability organization: Operational advice for hospital leaders . Rockville, MD: Agency for Healthcare Research and Quality. Hoffman, J. R., and H. K. Kanzaria. 2014. Intolerance of error and culture of blame drive medical excess. BMJ 349:g5702. Hogarth, R. 2010. On the learning of intuition. In H. Plessner, C. Betsch and T. Betsch (eds.), Intuition in judgment and decision making (pp. 91-105). New York, NY: Taylor & Francis. Hysong, S. J., R. G. Best, and J. A. Pugh. 2006. Audit and feedback and clinical practice guideline adherence: Making feedback actionable. Implementation Science 1(9):5-3. Ilgen, D. R., C. D. Fisher, and M. S. Taylor. 1979. Consequences of individual feedback on behavior in organizations. Journal of Applied Psychology 64(4):349-371. Institute for Healthcare Improvement. 2004. Patient safety leadership WalkRounds. http://www.ihi.org /resources/Pages/Tools/PatientSafetyLeader shipWalkRounds.aspx (accessed June 7, 2015). IOM (Institute of Medicine). 2000. To err is human: Building a safer health system . Washington, DC: National Academy Press. IOM. 2004. Patient safety: Achieving a new standard for care . Washington, DC: The National Academies Press. IOM. 2009. Resident duty hours: Enhancing sleep, supervision, and safety . Washington, DC: The National Academies Press. IOM. 2012. A CEO checklist for high-value health care. Discussion paper. Washington, DC: The National Academies http://nam.edu/wp -content/uploads/2015/06/CEOHighValu eChecklist.pdf (accessed July 25, 2015). IOM. 2013. Best care at lower cost: The path to continuously learning health care in America . Washington, DC: The National Academies Press. Ivers, N., G. Jamtvedt, S. Flottorp, J. M. Young, J. Odg aard-Jensen, S. D. French, M. A. O'Brien, M. Johansen, J. Grimshaw, and A. D. Oxman. 2012. Audit and feedba ck: Effects on professiona l practice and healthcare outcomes. Cochrane Database Systematic Reviews Issue 6:Cd000259. Ivers, N., A. Sales, H. Colquhoun, S. Michie, R. Foy, J. Francis, and J. Grimshaw. 2014. No more \"business as usual\" with audit and feedback interventions: Towards an agenda for a reinvigorated intervention. Implementation Science 9(1):14. Iyer, R. S., J. O. Swanson, R. K. Otto, and E. Weinberg er. 2013. Peer review commen ts augment diagnostic error characterization and departmental quality assuran ce: 1-year experience From a children's hospital. American Journal of Roentgenology 200(1):132-137. James, B. C., and L. A. Savitz. 2011. How Intermount ain trimmed health care costs through robust quality improvement efforts. Health Affairs (Millwood) 30(6):1185-1191. Jeffe, D. B., W. C. Dunagan, J. Garbutt, T. E. Burroughs, T. H. Gallagher, P. R. Hill, C. B. Harris, K. Bommarito, and V. J. Fraser. 2004. Using focus groups to understand physicians' and nurses' perspectives on error reporting in hospitals. Joint Commission Journal on Quality and Patient Safety 30(9):471-479. Jimmerson, C., D. Weber, and D. K. Sobek. 2005. Reducing waste and errors: Piloting lean principles at Intermountain Healthcare. Joint Commission Journal on Quality and Patient Safety 31(5):249-257. Johnson, A. J. 2011. Cognitive facilitati on following intentional odor exposure. Sensors 11(5):5469-5488. Joint Commission. 2009. Leadership in healthcare organizations: A guide to joint commission leadership standards. www.jointcommission.org/Leadership_in_Healthcare_Organizations/ (accessed may 1, 2015). Joint Commission. 2015a. Sentinel Event Policy and Procedures. www.jointcommission.org/Sentinel_Event_Policy_and_Procedures/ (accessed March 26, 2015). Joint Commission. 2015b. National Patient Safety Goals Effective January 1, 2015 www.jointcommission.org/assets/1/6/2015_NPSG_HAP.pdf Kachalia, A. 2013. Improving patient safety through transparency . Presentation to the Committee on Diagnostic Error in Health Care, August 7, 2014, Washington, DC. Kanter, M. H. 2014. Diagnostic errors\u2014Patient safety. Pr esentation to the Committee on Di agnostic Error in Health Care, August 7, 2014, Washington, DC. Kelly, M. M., A. Xie, P. Carayon, L. L. DuBenske, M. L. Ehlenbach, and E. D. Cox. 2013. Strategies for improving family engagement during family-centered rounds. Journal of Hospital Medicine 8(4):201-207. Khatri, N., G. D. Brown, and L. L. Hicks. 2009. From a blame culture to a just culture in health care. Health Care Management Review 34(4):312-322. Khunlertkit, A., and P. Carayon. 2013. Contributions of tele -intensive care unit (Tele-ICU) technology to quality of care and patient safety. Journal of Critical Care 28(3):315.e311-312. ORGANIZATIONAL CHARACTERISTICS AND THE PHYSICAL ENVIRONMENT 6-29 PREPUBLICATION COPY: UNCORRECTED PROOFS Kirwan, B., and L. K. Ainsworth (eds.). 1992. A guide to task analysis: The task analysis working group . Boca Raton, FL: CRC Press. Kotter, J. P. 1995. Leading change: Why transformation efforts fail. Harvard Business Review. January 2007. https://hbr.org/2007/01/leading-change-why-transformation-efforts-fail (accessed June 29, 2015). Kotter, J. P. 2012. The key to changing organizational culture. Forbes , September 27. www.forbes.com/sites/johnkotter/20 12/09/27/the-key-to-changing-organi zational-culture/ (accessed March 9, 2015). Kroft, S. 2014. American Society for Clinical Pathology. Input submitted to the Committee on Diagnostic Error in Health Care, April 28, 2014, Washington, DC. Kruskal, J. B., B. Siewert, S. W. Anderson, R. L. Eisenberg, and J. Sosna. 2008. Managing an acute adverse event in a radiology department. RadioGraphics 28(5):1237-1250. Lacson, R., S. D. O'Connor, K. Andriole, L. M. Prev edello, and R. Khorasani. 2014a. Automated critical test result notification system: Architecture, design, and assessment of provider satisfaction. American Journal of Roentgenology 203(5):W491-W496. Lacson, R., L. M. Prevedello, K. P. Andriole, S. D. O'C onnor, C. Roy, T. Gandhi, A. K. Dalal, L. Sato, and R. Khorasani. 2014b. Four-year impact of an alert notification system on closed-loop communication of critical test results. American Journal of Roentgenololgy 203(5):933-938. Larson, E. B. 2002. Measuring, monitoring, and reduci ng medical harm from a systems perspective: A medical director's personal reflections. Academic Medicine 77(10):993-1000. Lavanya, T., M. Cohen, S. V. Gandhi, T. Farrell, and E. H. Whitby. 2008. A case of a Dandy-Walker variant: The importance of a multidisciplinary team approach using complementar y techniques to obtain accurate diagnostic information. British Journal of Radiology 81(970):e242-e245. Leape. L. 2010. Q&A with Lucian Leape, M.D., professor of health policy, Harvard University. www.commonwealthfund.org/publications/newsletters /states-in-action/2010/jan/january-february- 2010/ask-the-expert/ask-the-expert (accessed September 23, 2014). Lee, C. S., P. G. Nagy, S. J. Weav er, and D. E. Newman-Toker. 2013. Cognitive and system factors contributing to diagnostic errors in radiology. American Journal of Roentgenology 201(3):611-617. Lopez-Campos, J. L., M. I. Asensio-Cruz, A. Castro-Acosta, C. Calero, and F. Po zo-Rodriguez. 2014. Results from an audit feedback strategy for chronic obstructiv e pulmonary disease in hospital care: A joint analysis from the AUDIPOC and European COPD Audit Studies. PloS One 9(10):e110394. Lundberg, G. D. 1998. Low-tech autopsies in the era of high-tech medicine: Continued value for quality assurance and patient safety. JAMA 280(14):1273-1274. Marcovici, P. A., and G. A. Taylor. 2014. Structured radiology reports are more complete and more effective than unstructured reports. American Journal of Roentgenology 203(6):1265-1271. Marx, D. A. 2001. Patient safety and the \"just cultur e\": A primer for health care executives. Medical Event Reporting System-Transfusion Medicine. http://www.safer.h ealthcare.ucla.edu/safer/archive/ahrq/Final PrimerDoc.pdf (accesse d June 7, 2015). McDonald, K. M. 2014. The diagnostic field's players and interactions: From the inside out. Diagnosis 1(1):55-58. McDonald, K. M., B. Matesic, D. G. Contopoulos-Ioannidis, J. Lonhart, E. Schmidt, N. Pineda, and J. P. A. Ioannidis. 2013. Patient safety strategies targeted at diagnostic errors: A systematic review. Annals of Internal Medicine 158(5 Part 2):381-389. MedPAC (Medicare Payment Advisory Commission). 1999. Report to the Congress: Selected Medicare issues . Washington, DC: MedPAC. http://medpac.gov/docum ents/reports/Jun99Entir ereport.pdf?sfvrsn=0 (accessed June 7, 2015). Mehta, R., R. Zhu, and A. Cheema. 2012. Is noise always bad? Exploring the effects of ambient noise on creative cognition. Journal of Consumer Research 39( 4):784-799. Milstead, J. A. 2005. The culture of safety. Policy, Politics, & Nursing Practice 6(1):51-54. Modak, I., J. B. Sexton, T. Lux, R. Helmreich, and E. Thomas. 2007. Measuring safety culture in the ambulatory setting: The Safety Attitudes Questionnaire\u2014Ambulatory Version. Journal of General Internal Medicine 22(1):1-5. Moran, J. W., and B. K. Brightman. 2000. Leading organizational change. Journal of Workplace Learning 12(2):66- 74. Murphy, D. R., A. Laxmisan, B. A. Reis, E. J. Thomas, A. Esquivel, S. N. Forjuoh, R. Parikh, M. M. Khan, and H. Singh. 2014. Electronic health reco rd-based triggers to detect potential delays in cancer diagnosis. BMJ Quality & Safety 23(1):8-16. 6-30 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Myers, J. 2014. Diagnostic errors in (. . . and around) pathology. Presentation to the Committee on Diagnostic Error in Health Care, August 7, 2014, Washington, DC. Nakhleh, R. E., V. Nose, C. Colasacco, L. A. Fatheree, T. J. Lillemoe, D. C. McCr ory, F. A. Meier, C. N. Otis, S. R. Owens, S. S. Raab, R. R. Turner, C. B. Ventura, and A. A. Renshaw. 2015. Interpretive Diagnostic Error Reduction in Surgical Pathology and Cytology: Guideline From the College of American Pathologists Pathology and Laboratory Quality Center and the Association of Directors of Anatomic and Surgical Pathology. Archives of Pathology and Laboratory Medicine , May 12 [Epub ahead of print]. NCQA (National Committee for Quality Assurance). 2 013. Accountable care organization accreditation. www.ncqa.org/Programs/Accreditati on/AccountableCareOrganizationACO .aspx (accessed May 1, 2015). Nemetz, P. N., E. Tangalos, L. P. Sands, W. P. Fisher Jr, W. P. Newman III, and E. C. Burton. 2006. Attitudes toward the autopsy\u2014An 8-state survey. Medscape General Medicine 8(3):80. Newman-Toker, D. E., K. M. McDonald, and D. O. Meltzer. 2013. How much diagnostic safety can we afford, and how should we decide? A health economics perspective. BMJ Quality & Safety 22(Suppl 2):ii11-ii20. NQF (National Quality Forum). 2011. Serious reportable events in healthca re--2011 update: A consensus report. Washington, DC: National Quality Forum. O'Donnell, C., and N. Woodford. 2008. Po st-mortem radiology\u2014A new Baillie, M. Schaafsma, and M. Eccles. 2011. The effectiveness of strategies to change organisational culture to improve healthcare performance: A systematic review. Implementation Science 6(1):33. Parsons, K. C. 2000. Environmental ergonomics: A review of principles, methods and models. Applied Ergonomics 31(6):581-594. Perlman, K. 2011. Change fatigue: Taking its toll on your employees? Forbes , September 15. www.forbes.com/sites/johnkotter/2011/09/15/can-i-use-this-method-for-change-in-my-organization/ (accessed April 29, 2011). Pichereau, C., E. Maury, L. S. Bourcier L. Arriv\u00e9. 2015. Post-mortem CT scan with contrast injection and chest compression to diagnose pulmonary embolism. Intensive Care Medicine 41(1):167-168. Plaza, C., L. Beard, A. D. Fonzo, M. D. Tommaso, Y. Mujawaz, M. Serra-Julia, and D. Morra. 2011. Innov ation in healthcare team feedback. Healthcare Quarterly 14(2):61-68. Plebani, M., and G. Lippi. 2011. Closing the brain-to-brain loop in laboratory testing. Clinical Chemisty and Laboratory Medicine 49(7):1131-1133. Plebani, M., M. Laposata, and G. D. Lu ndberg. 2011. The brain-to-brain loop concept for laboratory testing 40 years after its introduction. American Journal of Clinical Pathology 136(6):829-833. Pronovost, P. J., S. M. Berenholtz, C. A. Goeschel, D. M. Needham, J. B. Sexton, D. A. Thompson, L. H. Lubomski, J. A. Marsteller, M. A. Makary, and E. Hunt. 2006. Creating high reliability in health care organizations. Health Services Research 41(4p2):1599-1617. Pronovost, P. J., S. M. Berenholtz, and D. M. Needham. 2008. Translating evidence into practice: a model for large scale knowledge translation. BMJ 337:a1714. Pronovost, P. J., C. A. Goeschel, E. Colantuoni, S. Watson , L. H. Lubomski, S. M. Berenholtz, D. A. Thompson, D. J. Sinopoli, S. Cosgrove, J. B. Sexton, J. A. Marsteller, R. C. Hyzy, R. Welsh, P. Posa, K. Schumacher, and D. Needham. 2010. Sustaining reductions in catheter related bloodstream infections in Michigan intensive care units: Observational study. BMJ 340:c309. Provenzale, J., and P. Kranz. 2011. Understanding errors in diagnostic radiology: proposal of a classification scheme and application to em ergency radiology. Emergency Radiology 18(5):403-408. Reiling, J., G. Hughes, and M. Murphy. 2008. Chapter 28: The impact of facility design on patient safety. In R. G. Hughes (ed.), Pa tient safety and quality: An evidence-based handbook for nurses (pp. 700-725). Rockville, MD: Agency for Healthcare Research and Quality. Reilly, J. B., J. S. Myers, D. Salvador, and R. L. Trowbr idge. 2014. Use of a novel, modified fishbone diagram to analyze diagnostic errors. Diagnosis 1(2):167-171. Reilly, J. B., M. L. Graber, and R. L. Trowbridge. 2015. How to do a root cause analysis of diagnostic error. http://c.ymcdn.com/sites/www.nps f.org/resource/collection/ A81D4178-F1E9-4F87-8A85- CA89DEBB953F/How_to_Do_a_Root_Cause_Analysis_of_Diagnostic_Error_Handout_Slides.pdf (accessed March 2, 2015). ORGANIZATIONAL CHARACTERISTICS AND THE PHYSICAL ENVIRONMENT 6-31 PREPUBLICATION COPY: UNCORRECTED PROOFS Roberts, I. S. D., R. E. Benamore, E. W. Benbow, S. H. Lee, J. N. Harris, A. Jackson, S. Mallett, T. Patankar, C. Peebles, C. Roobottom, and Z. C. Traill. 2012. Post-m ortem imaging as an alternative to autopsy in the diagnosis of adult deaths: A validation study. The Lancet 379(9811):136-142. Rogers, M. L., E. S. Patterson, and M. L. Render. 2012. Cognitive work analysis in health care. In P. Carayon (ed.), Handbook of human factors and ergonomics in health care and patient safety (pp. 465-474). Boca Raton, FL: Taylor & Francis Group. Roth, E. M. 2008. Uncovering the requirements of cognitive work. Human Factors: The Journal of the Human Factors and Ergonomics Society 50(3):475-480. Roy, C. L., J. M. Rothschild, A. S. Dighe, G. D. Sc hiff, E. Graydon-Baker, J. Lenoci-Edwards, C. Dwyer, R. Khorasani, and T. K. Gandhi. 2013. An initiative to improve the management of clinically significant test results in a large h ealth care network. Joint Commission Journal on Quality and Patient Safety 39(11):517- 527. Ruegger, C., C. Bartsch, R. Martinez, S. Ross, S. Bolliger , B. Koller, L. Held, E. Bruder, P. Bode, R. Caduff, B. Frey, L. Schaffer, and H. Bucher. 2014. Minimally invasive, imaging guided virtual autopsy compared to conventional autopsy in foetal, newborn and infant cases: Study protocol for the paediatric virtual autopsy trial. BMC Pediatrics 14(1):15. Salas, E., C. Prince, D. P. Baker, and L. Shrestha. 1995. Situation awareness in team pe rformance: Implications for measurement and training. Human Factors: The Journal of the Human Factors and Ergonomics Society 37(1):123-136. Saldiva, P.H.N. 2014. Minimally invasive auto psies: A promise to revive the procedure. Autopsy and Case Reports 4(3). Schein, E. H.. 2004. Organizational culture and leadership , 3rd ed. San Francisco, CA: John Wiley & Sons. Schiff, G. D. 1994. Commentary: Diagnosis tracking and health reform. American Journal of Medical Quality 9(4):149-152. Schiff, G. D. 2008. Minimizing diagnostic error: The importance of follow-up and feedback. American Journal of Medicine 121(5):S38-S42. Schiff, G. D. 2014 . Presentation. Presentation to the Committee on Dia gnostic Error in Health Care, August 7, 2014, Washington, DC. Schiff, G. D., D. Klass, J. Peterson, G. Shah, and D. W. Bates. 2003. Linking laboratory and pharmacy: Opportunities for reducing errors and improving care. Archives of Internal Medicine 163(8):893-900. Schiff, G. D., S. Kim, R. Abrams, K. Cosby, A. S. Elstei n, S. Hasler, N. Krosnjar, R. Odwanzy, M. F. Wisniewsky, and R. A. McNutt. 2005. Diagnosing diagnosis erro rs: Lessons from a multi-institutional collaborative project for the diagnostic error evaluation and research pr oject investigators. In K. Henrikson, J. B. Battles, E. S. Marks, and D. I. Lewin (eds.), Advances in Patient Safety: From Research to Implemenation , (Volume 2: Concepts and methodology) (pp. 255-278). Rockville, MD: Ag ency for Healthcare Research and Quality. Schiff, G. D., A. L. Puopolo, A. Huben-Kearney, W. Yu, C. Keohane, P. McDonough, B. R. Ellis, D. W. Bates, and M. Biondolillo. 2013. Primary care closed claims e xperience of Massachusetts malpractice insurers. JAMA Internal Medicine 173(22): 2063-2068. Schwartz, A., and S. J. Weiner. 2014. The value of direct observation and feedback on provider performance in diagnosis: Input to the cognition and education group of the IOM Study on Diagnostic Error in Health Care. Input submitted to the Committee on Diagnostic Error in Health Care, October 24, 2014, Washington, DC. Schwartz, A. W., S. J. Weiner, F. Weaver, R. Yudkowsky, G. Sharma, A. Binns-Calvey, B. Preyss, and N. Jordan. 2012. Uncharted territory: Measuring costs of di agnostic errors outside the medical record. BMJ Quality & Safety 21(11):918-924. Schwartz, L. H., D. M. Panicek, A. R. Berk, Y. Li, and H. Hricak. 2011. Improving communication of diagnostic radiology findings through structured reporting. Radiology 260(1):174-181. Sexton, J., T. Neilands, K. Rowan, K. Vella, J. Boyden, P. Roberts, and E. Thomas. 2006. The Safety Attitudes Questionnaire: Psychometric properties, benchmarking data, and emerging research. BMC Health Services Rese arch 6(1):1-10. Shenvi, E. C., and R. El-Kareh. 2015. Clinical criteria to screen for inpatient diagnostic errors: A scoping review. Diagnosis 2(1):3-19. SHIEP (State Health Information Exch ange Program). 2012. Getting to impact: Harnessing health information technology to support improved care coordination. http://healthit.gov/sites/default/files/bright-spots- synthesis_care-coordination- part-i_final_012813.pdf (accessed June 8, 2015). 6-32 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Shojania, K. G. 2010. The elephant of patient safety: What you see depends on how you look. Joint Commission Journal of Quality and Patient Safety 36(9):399-401. Shojania, K., E. Burton, K. McDonald, and L. Goldman. 2002. The autopsy as an outcome and performance measure. AHRQ Publication No. 03-E002: Rockville, MD: Agency for Healthcare Research and Quality. Shojania, K. G., E. C. Burton, K. M. McDonald, and L. Goldman. 2003. Changes in rates of autopsy-detected diagnostic errors over time: A systematic review. JAMA 289(21):2849-2856. Shostek, K. 2007. Developing a culture of safety in ambulatory care settings. Journal of Ambulatory Care Management 30(2):105-113. Silow-Carroll, S., T. Altera s, and J. A. Meyer. 2007. Hospital quality improvement: Strategies and lessons from U.S. hospitals. The Commonwealth Fund. http://www.commonwealthfund.org/~/media/files/publications/fund -report/2007/apr/hospital-quality- improvement--strategies-and-le ssons-from-u-s--hospitals/silow- carroll_hosp_quality_improve_str ategies_lessons_1009-pdf.pdf (accessed June 7, H. 2013. Diagnostic errors: Moving beyond \"no respect\" and getting ready for prime time. BMJ Quality & Safety 22(10):789-792. Singh, H. 2014. Building a robust conceptual foundation for defining and measuring diagnostic errors. Presentation to the Committee on Diagnostic Error in Health Care, August 7, 2014, Washington, DC. Singh, H., and D. F. Sittig. 2015. Advancing the science of measurement of diagnostic errors in healthcare: The Safer Dx framework. BMJ Quality & Safety 24:103-110. Singh, H., E. J. Thomas, S. Mani, D. Sittig, H. Arora, D. Espadas, M. M. Khan, and L. A. Petersen. 2009. Timely follow-up of abnormal diagnostic imaging test results in an outpatient setting: Are electronic medical records achieving their potential? Archives of Internal Medicine 169(17):1578-1586. Singh, H., E. J. Thomas, D. F. Sittig, L. Wilson, D. Espadas, M. M. Khan, an d L. A. Petersen. 2010. Notification of abnormal lab test results in an electronic medi cal record: Do any safety concerns remain? American Journal of Medicine 123(3):238-244. Singh, H., T. D. Giardina, S. N. Forjuoh, M. D. Reis, S. Kosmach, M. M. Khan, and E. J. Thomas. 2012a. Electronic health record-based surveillance of diagnostic errors in primary care. BMJ Quality and Safety 21(2):93- 100. Singh, H., M. L. Graber, S. M. Kissam, A. V. Sorensen, N. F. Lenfestey, E. M. K. Henriksen, and K. A. LaBresh. 2012b. System-related interventions to reduce diagnostic errors: A narrative review. BMJ Quality and Safety 21(2):160-170. Southwick, F. S., N. M. Cranley, an d J. A. Hallisy. 2015. A patient-initiate d voluntary online survey of adverse medical events: The perspective of 696 injured patients and families. BMJ Quality & Safety : 1-10. Swensen, S., M. Pugh, C. McMullan, and A. Kabcenell. 2013. High-impact leadership : Improve care, improve the health of populations, and reduce costs. White Paper. Institute for Healthcare Improvement. Thayyil, S., N. J. Sebire, L. S. Chitty, A. Wade, W. K. Chong, O. Olsen, R. S. Gunny, A. C. Offiah, C. M. Owens, D. E. Saunders, R. J. Scott, R. Jones, W. Norman, S. Addison, A. Bainbridge, E. B. Cady, E. D. Vita, N. J. Robertson, and A. M. Taylor. 2013. Post-mortem MRI versus conventional autopsy in fetuses and children: a prospective validation study. The Lancet 382(9888):223-233. Thomas, E. J. 2014. Safety culture and diagnostic error: A rising tide lifts all boats . Presentation to the Committee on Diagnostic Error in Health Care , November 5, 2014, Washington, DC. Thomas, E. J., J. B. Sexton, T. B. Neilands, A. Frankel, and R. L. Helmreich. 2005. The effect of executive walk rounds on nurse safety climate attitudes: A randomized trial of clinical units. BMC Health Services Research 5(1):28. Todnem By, R. 2005. Organisational change management: A critical review. Journal of Change Management 5(4):369-380. Trowbridge, R. 2014. Diagnostic performance: Measur ement and feedback. Presenta tion to the Committee on Diagnostic Error in Health Care, August 7, 2014, Washington, DC. Tuc ker, A., and A. C. Edmondson. 2003. Wh y hospitals don't learn from failures. California Management Review 45(2):55-72. Tucker, A., W. S. Heisler, and L. D. Janisse. 2013. Organi zational factors that contribute to operational failures in hospitals. Harvard Business School Working Paper: http://hbswk.hbs.edu/item/ 7352.html (accessed June 29, 2015) van der Linden, A., B. M. Blokker, M. Kap, A. C. Weustink, P. H. J. Riegman, and J. W. Oosterhuis. 2014. Post- Mortem tissue biopsies obtained at minimally invasive autopsy: An RNA-quality analysis. PloS One 9(12):e115675. PHYSICAL ENVIRONMENT 6-33 PREPUBLICATION COPY: UNCORRECTED PROOFS Varkey, P., M. K. Reller, and R. K. Resar. 2007 . Basics of quality improvement in health care. Mayo Clinic Proceedings 82(6):735-739. Vest, J., and L. Gamm. 2009. A critical review of the re search literature on Six Sigma, Lean and StuderGroup's Hardwiring Excellence in the United States: The need to demonstrate and communicate the effectiveness of transformation strategies in healthcare. Implementation Science 4(35):1-9. VHA (Veterans Health Administration). 2008. Pathology and laboratory medicine service procedures. Washington, DC: Department of Veterans Affairs, Veterans Health Administration. Wachter, R. M. 2010. Why diagnostic errors don't get any respect\u2014and what can be done about them. Health Affairs 29(9):1605-1610. Wachter, R.M. 2015. The digital doctor: Hope, hype, and harm at the dawn of medicine's computer age . New York: McGraw Hill. Ward, A. F. 2013. Winter wakes up your mind--and warm weather makes it harder to think straight. Scientific American , February 12. http://www.sci entificamerican.com/article/war m-weather-makes-it-hard-think- straight/ (accessed June 7, 2015). Watts, B. V., K. Percarpio, P. West, and P. D. Mills. 2010 . Use of the Safety Attitudes Questionnaire as a measure in patient safety improvement. Journal of Patient Safety 6(4):206-209. Weick, K. E., and K. M. Sutcliffe. 2011. Business organizations must learn to operate ''mindfully'' to ensure high performance. www.bus.umich.edu/FacultyResearch /Research/ManagingUnexpected.htm (accessed May 26, 2015). Weiner, S. J., A. Schwartz, F. Weaver, J. Goldberg, R. Yu dkowsky, G. Sharma, A. Binn s-Calvey, B. Preyss, M. M. Schapira, and S. D. Persell. 2010. Contextual errors and failures in individualizing patient care: A multicenter study. Annals of Internal Medicine 153(2):69-75. Weustink, A. C., M. G. M. Hunink, C. F. v. Dijke, N. S. Renken, G. P. Krestin, and J. W. Oosterhuis. 2009. Minimally invasive autopsy: An alternative to conventional autopsy? Radiology 250(3):897-904. WHO (World Health Organization). 2006. The world health report 2006: Working together for health . Geneva: World Health Organization. Williams, C. 2012. Health information exchange: It should just work. www.healthit.gov/buzz-blog/state-hie/health- information-exchange-work/ (accessed March 27, 2015). Williams, E. S., L. B. Manwell, T. R. Konrad, and M. Linzer. 2007. The relationship of organizational culture, stress, satisfaction, and burnout with physician-reporte d error and suboptimal patient care: Results from the MEMO study. Health Care Management Review 32(3):203-212. Wyatt, R. M. 2013. Blameless or blameworthy errors-Does your organization make a distinction? Joint Commission Physician Blog , December 18. http://www.jointcommission.org/jc_phy sician_blog/blameless_or_blamewor thy_errors/ (accessed June 7, 2015). Ulrich, R., X. Quan, C. Zimring, A. Joseph, and R. Choud hary. 2004. The role of the physical environment in the hospital of the 21st century: A once-in-a-lifetime oppor tunity. Designing the 21st Century Hospital Project. https://www.healthdesign.org/sites/default/files/ Role%20Physical%20Environ%20in%20the%2021st%20C entury%20Hospital_0.pdf (accessed June 7, 2015). Zwaan, L., A. Thijs, C. Wagner, G. van der Wal, and D. R. Timmermans. 2009. Design of a study on suboptimal cognitive acts in the diagnostic process, the effect on patient outcomes and the influence of workload, fatigue and experience of physician. BMC Health Services Research 9:65. Zwaan, L., G. D. Schiff, and H. Singh. 2013. Advancing the research agenda for diagnostic error reduction. BMJ Quality & Safety 22(Suppl 2):ii52-ii57. 7-1 PREPUBLICATION COPY: UNCORRECTED PROOFS 7 The External Environment Influencing Diagnosis: Reporting, Medical Liability, and Payment This chapter focuses on the external environm ent and how it contribute s to the diagnostic process and the occurrence of diagnostic errors (see Figure 7- 1). The category of external environmental factors is quite broad and may include: error reporting, medical liability, payment and care delivery, and oversight processes (suc h as accreditation, certific ation, and regulatory requirements). While the committee does consid er oversight processes to be external environmental factors, they are discussed in th e sections on health car e professional education and competency in Chapter 4 and in the section on the oversight of health care organizations in Chapter 6. In this chapter the committee emphasizes the need for safe environments for voluntary error reporting, without the threat of legal discovery or discipli nary action, where health care organizations can analyze and learn from diagnostic errors in order to improve diagnosis. The role of medical liability reform is also describe d as an opportunity to in crease the disclosure of diagnostic errors as well as to promote improved reporting, analys is, and learning from diagnostic errors. The committee highlights the potential for payment models\u2014both current and new\u2014to incentivize improved diagnostic performance. Importantly, this chapter reflects the committee's commitment to consider recommendations from both a pragmatic and an aspirational perspective. The committee's recomme ndations balance the urgent need to improve diagnosis by identifying immediate opportunities for improvement while also considering more fundamental changes that are likely to take si gnificant effort and time to achieve. As noted elsewhere in the report, the co mmittee's recommendations to improve diagnosis in this chapter may also improve patient safety and health care more generally. For exam ple, the evaluation of the Patient Safety Organization program is likely to be informative for error reporting broadly; adoption of Communication and Re solution Programs has the poten tial to improve disclosure and error analysis for all types of errors in health care; and reform ing fee-for-service (FFS) payment and documentation guidelines could also benefit the health care system more broadly. 7-2 FIGUR E factors s u T organiza t adverse e best opp o diagnost i System (2 Various g Affairs, a which c o reportin g to constr u the resul t if health people f r E 7-1 The di uch as pay m REPO R The committ e tions an d pro events, and n ortunity to l e ic process. T 2000) repor t groups, incl u and patient s ollect differe n g systems in c uctive resp o ts of reporti n care organi z reportin PREPUBL Iagnostic pr o ment, reporti n RTING AN D ee conclude d ofessionals t near misses. earn from s u The Institute t recommen d uding indivi d safety organ i nt types of i n clude: the re p nses; adequ a ng can be di s zations focu s g because t h ICATION C Oocess is infl u ng, medical l D LEARNI d that there n to share and Conductin g uch experien c of Medicin e ded that rep o dual states, t izations (PS O nformation f porting is s a ate expertis e sseminated ( s on punishi n hey fear that IM OPY: UNCO Ruenced by th e liability, an d NG FRO M need to be s a learn from t systems- bas ces and to i m e's (IOM) To orting syste m the Joint Co m Os), have d e for different afe for those e and resour c (Barach and ng individu a a report ma y MPROVING D RRECTED P Re external e n d oversight p M DIAGNO S afe, confide n their experi e sed analyse s mplement c h o Err Is Hum ms be used t o mmission, t h eveloped a n purposes. C individuals ces enable l e Small, 200 0 als who ma k y be used as DIAGNOSIS I ROOFS nvironment, processes. STIC ERR O ntial places f ences of dia g s of these e v hanges to i m man: Buildi n o collect thi s he Departm e number of re p Characteristi c who report; earning fro m 0; WHO, 20 0 ke mistakes, i s evidence o f IN HEALTH C including ORS for health c a gnostic error vents presen t mprove the ng a Safer H s informatio n ent of Veter a porting syst e cs of succes s reporting l e m reporting; a 05). In cont r it will preve f fault, coul d CARE are s, ts the Health n. ans ems sful eads and rast, ent d THE EXTERNAL ENVIRONMENT INFLUENCING DIAGNOSIS 7-3 PREPUBLICATION COPY: UNCORRECTED PROOFS precipitate lawsuits, or could result in disciplinary action by st ate professional licensing boards and employers (IOM, 2012; WHO, 2005) . Thus, there is a need for safe environments in which there is not the threat of legal discovery or disciplinary action, where diagnostic errors, adverse events, and near misses can be analyzed and learned from in order to improve the quality of diagnosis and prevent future diagnostic errors. In line with the To Err Is Human report, the committee recommends that the Agency for Healthcare Research and Quality (AHRQ) or other appropriate agencies or independent entities should encourage and facilitate the voluntary reporting of diagnosti c errors and near misses. Unfortunately, it is often difficult to create e nvironments where dia gnostic errors, adverse events, and near misses can be shared and disc ussed. Health care organi zations and clinicians have been challenged by the limitations of inc onsistent and individual st ate-enacted peer review and quality improvement processes for the protec tion of information relating to adverse events and medical errors, the external use of such information, and what benefits the health care organizations and clinicians receive from reporting. In response to this challenge, the To Err Is Human report recommended that \"Congress should pass legislation to extend peer review protections to data related to patient safety and quality impr ovement that are collected and analyzed by health care organizations for internal us e or shared with others solely for purposes of improving safety and quality\" (IOM, 2000, p. 10) . In 2005 the Patient Safety and Quality Improvement Act (PSQIA) was passed by Congress; the act confers privilege and confidentiality protections to health care organi zations that share specific types of patient safety information with federally listed PSOs (HHS, 2015). Accordin g to AHRQ, which shares responsibility for implementing PSQIA with the Office for Civil Ri ghts, \"The Act promotes increased patient safety event reporting and analysis, as advers e event information reported to a... PSO is protected from disclosure in medical malpractice cases. This legislation supports and stimulates advancement of a culture of safety in health care organizations across the country, leading to provision of safer care to pa tients\" (AHRQ, 2015a, p. 23). Th e PSO program provides an important national lever to increase voluntary e rror reporting and analysis which is well aligned with the committee's recommendation. However, progress in implementing the PSO program has been slow (AHRQ, 2015a; GAO, 2010). The co mmittee is concerned that a number of challenges with the current program may limit the extent to which it can facilitate much-needed voluntary reporting, analysis, and learning of diagnostic errors and near misses (see section below on the evaluation of the PSO program). Due to this concern, the committee's recommen dation recognizes that additional federal efforts across the U.S. Department of Health and Human Services ( HHS), as well as the involvement of other independent entities, need to be considered in orde r to prioritize voluntary event reporting for diagnostic errors and near misses. Support of this recommendation can be found in the IOM report Health IT and Patient Safety: Bu ilding Safer Systems for Better Care , which reviewed the existing reporting systems in health care and concluded that despite the various reporting systems and numerous calls fo r change, adverse event reports are not being collected and analyzed in a comprehensive ma nner (IOM, 2012). The report concluded that \"learning from these systems is limited because a m ultitude of different data is collected by each system, hampering any attempt to aggregate data between reporting systems\" (IOM, 2012, p. 152). After reviewing the opportunities to improve adverse event reporting, the committee that produced the 2012 report made a recommendation for a new entity, akin to the National Transportation Safety Board, that could investigat e \"patient safety deaths, serious injuries, or potentially unsafe conditions\" and report resu lts of these activities (IOM, 2012, p. 11). That 7-4 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS committee suggested that this entity's purview could include: (1) collec ting reports of adverse events; (2) analyzing collected re ports to identify patterns; (3) i nvestigating reports of patient deaths or serious injuries related to health IT; (4) investig ating trends of reports of unsafe conditions; (5) recommending corrective actions ; (6) providing fee dback based on these investigations; and (7) disclo sing the results of the inves tigations to the public. Because efforts to improve voluntary reporting and analysis at the national level have been slow, the current committee also recognized the potential for more localized efforts that could be carried out while national efforts c ontinue to be developed and improved. In the interim, smaller-scale efforts to improve volunt ary reporting and learning from diagnostic errors, adverse events, and near misses may be helpful for generating and sharing the lessons learned from such efforts. For instance, at the level of health care organizati ons, quality and patient safety committees can incorporate the analysis of and learning from diagnostic errors, and these activities may be protected from disclosure by stat e statutes. In an integrated delivery system in Maine, for example, a surgical quality collabora tive was established to review the quality and safety of surgical care, compare results to nati onal and regional data, and provide feedback to participating organizations.1 Another option that some orga nizations (including PSOs) are incorporating is the us e of \"safe tables\" forums (WSHA, 2014), which are \"members-only, shared learning meeting[s] of healthcare peers to exchange patient safety experiences, discuss best practices and learn in an open, uninhibited and legally protected environment\" (MHA PSO, 2015). The limitation to this approach is that th e best practices and le ssons learned cannot be shared beyond the participants. Evaluation of the PSO Program The PSO program enables public or private or ganizations to be lis ted as a PSO, provided that they meet certain qualifications articulate d in the patient safety rule (AHRQ, 2015e). PSO designation indicates that an or ganization is \"authorized to se rve providers as independent patient safety experts and to rece ive data regarding patient safety events that will be considered privileged and confidential\" (GAO, 2010, p. 2). PSOs do not receive federal funding, but they can recruit health care organizations and clin icians to join their PSO. When health care organizations or health care professionals join a PSO, they can then voluntarily send patient safety data to the PSO for analysis and feedback on how to improve care. Additionally, PSOs can send de-identified patient safety data to the Network of Patient Safety Databases (NPSD) overseen by AHRQ. The intent of the program is that AHRQ will then analyze the aggregated data and publish reports (GAO, 2010). A provision in the Affordable Care Act will likely increase the number of hospita ls who join PSOs; per the HHS 2015 Payment Notice, hospitals with more than 50 beds will be required to join a PSO by January 2017 in order to contract with health plans in insurance exchanges\" (AHRQ, 2015). 2 There is very limited information about the impact that PSOs have on learning and im proving the quality and safety of care. The Government Accountability Office concluded in 2010 that it was too ear ly to evaluate the effectiveness of the PSO program (GAO, 2010). AHR Q is still in the process of implementing 1 The MaineHealth Surgical Quality Collaborative was deve loped in accordance with the provisions of the Maine Health Security Act , 24 Me.Rev.Stat.Ann. \u00a7 2501, et seq to maintain the confidentiality of information and data reviewed. 2 https://www.federalregister.gov/articles/2013/12/02/2013- 28610/patient-protection-and-affordable-care-act-hhs- notice-of-benefit-and-payment-parameters-for-2015 THE EXTERNAL ENVIRONMENT INFLUENCING DIAGNOSIS 7-5 PREPUBLICATION the NPSD, aggregated informa tion collected from PSOs has not been analyzed or shared. Currently there are more than 80 listed PSOs, and the PSO network is active in sharing information with their members about strategies to mitigate patient safety events, as evidenced by PSO websites (AHRQ, 2015c). AHRQ has also de veloped Common Formats, or generic- and event-specific forms, to encourage standard ized event reporting among PSOs (AHRQ, 2015b). However, use of the Common Formats is volunt ary, and some organizations are implementing these variably or using legacy reporting form ats (ONC, 2014). To facilitate the aggregation of patient safety data, \"AHRQ established the PSO Privacy Protection Center (PSO PPC) to receive data from PSOs, facilitate the use of the common formats, de-identify data in a standardized manner, validate the quality and accuracy of PSO data , provide technical assistance to PSOs and other users of the Common Formats, and transm it non-identifiable data to the NPSD\" (AHRQ, 2015a, p. 53). The PSO PPC works with individual PSOs th at wish to submit de-identified patient safety event information. In order to submit reports, PSOs are required to sign a data use agreement with the PSO PPC. By the end of fiscal year 2014, 20 of 76 listed PSOs had established data use agreemen ts with the PSO PPC (AHRQ, 2015a). AHRQ reports that while these data use agreements \"grew in number in FY 2014, and some data were transmitted to the PSO PPC, none have been of sufficient quality a nd volume to ensure that data transmitted to the NPSD is both accurate and non-identifiable\" ( AHRQ, 2015a, p. 53). For fiscal year 2015, AHRQ expects the volume of data submission to the PS O PPC and the quality of the data submitted to increase significantly. AHRQ's goal is to gather \"sufficient patient safety event reports to transmit to the NPSD,\" and the fiscal year 2015 ta rget is to transfer 25,000 patient safety event reports to the NPSD (AHRQ, 2015a, p. 53). There are concerns that the federal priv ilege protections exte nded by PSQIA are not shielding organizations from state reporting requirements; a recent ruling by the Kentucky Supreme Court found that the inform ation a hospital is re quired to generate under state law is not protected by PSQIA, even if it is shared with a PSO. 3 This type of court decision could undermine the creation of safe environments for sharing this information and thus make voluntary submissions to PSOs much less likely. Given that the PSO program has the potential to improve learning about diagnostic errors and to expedite the implementation of solutions and adoption of best practice s, it is important to evaluate whether the program is meeting the st atutory objectives of PSQIA\u2014namely, that the PSO program is creating opportunities to exam ine and learn from medical errors, including diagnostic errors. Thus, the committ ee recommends that AHRQ should evaluate the effectiveness of PSOs as a major mechanism for voluntary rep orting and learning from these events. Given the concern over the er osion of PSQIA privilege protections at the state level, the evaluation could also focus on whether these protections are cons istent with Congress's intent in enacting the legislation. While the ev aluation of the PSO program is ongoing, PSOs can help support voluntary reporting e fforts by educating their member s about the applicable state 3 Tibbs v. Bunnel, Ky., 2012-SC-000603-MR (Aug. 21, 2014). The Kentucky Supreme Court \"held that the incident report developed by the University of Kentucky Hospital' s patient safety evaluation system (PSES), following the death of a patient was not protected as patient safety wo rk product (PSWP) under the Patient Safety and Quality Improvement Act of 2005. While this case may not set any official precedent in other states, it will be considered persuasive case law. Organizations that have established a PSES for reporting to a PSO need to explore any state-mandated safety and quality regulations to ensure that the collection of such information is conducted in harmony with the PSES to ensure protection as PSWP.\" 7-6 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS peer review protections as well as about the PSQIA privil ege protections. Health care organizations participating in PSOs can also take steps to ensure that any information and data shared with PSOs are protected by defining their patient safety evaluations systems broadly and by carefully analyzing the information they intend to submit to a PSO in order to minimize the chance that the PSQIA privilege is abrogate d (or invalidated) at the state level. The evaluation of the PSO program could also explore how the PSO program influences efforts to improve transparency within health care organizations. According to a recent report, \"PSOs have the potential to foster transparency through increased reportin g of complications and errors, and identification and sharing of learning and best practices; however, it remains to be seen how successfully these groups can balance the need for a protected space to which organizations can voluntarily report errors and th e need for open sharing of information outside the organization\" (National Patient Safety F oundation Lucian Leape Institute, 2015, p. 16). The committee recognizes that efforts to improve diagnosis can include both a focus on improving the disclosure of medical errors to patients and their families (see discussion on communication and resolution programs) and efforts to improve voluntary reporting and learning. In addition, AHRQ's evaluation needs to fo cus on how AHRQ and PSOs can improve the voluntary reporting of diagnostic errors and learni ng from those errors, which have not been a major focus within PSOs to date. The committee recommends that AHRQ should modify the PSO common formats for reporting of patient safety events to include diagnostic errors and near misses. To implement common formats specific to diagnostic error, AHRQ could begin with high-priority areas (suc h as the most frequent diagnostic errors or \"don't miss\" health conditions that may result in signi ficant patient harm, such as stroke, acute myocardial infarction, and pulmonary embolism). AHRQ could also consid er whether other PSO activities, such as discussions during annual PSO meetings, could focus atte ntion on diagnos tic errors. MEDICAL LIABILITY The two core functions of the medical liability system are to compensate negligently injured patients and to promote quality by enc ouraging clinicians and organizations to avoid medical errors. Although the medical liability system may act as a generalized deterrent to medical errors, it is not well aligned with the pr omotion of high-quality, safe care (Mello et al., 2014b). Concerns about medical liab ility prevent clinicians from disclosing medical errors to patients and their families, despite calls from nume rous groups that full disclosure is an ethical necessity (Hendrich et al., 2014; Sage et al., 2014) and despite the fact that such disclosures are a requirement for Joint Commission accreditation. Clinicians often struggle to fulfill this responsibility (Gallagher et al., 2007; Gallagher et al., 2013; Joint Commission, 2005). There is limited guidance for clinicians about how to disc lose this information effectively, and a number of factors, including embarrassment , inexperience, lack of confid ence, and mixed messages from risk managers and health care organizations' senior leadership, can thwart disclosures to patients and their families (Gallagher et al., 2013; Schiff, 2014). The current tort-based judicial system for resolving medical liability claims creates barriers to improvements in quality and patient sa fety and stifles continuous learning. Medical malpractice reform could be designed to permit patients and health professionals to become allies in trying to make health care safer by en couraging transparency about errors. Such an approach would allow patients to be promptly a nd fairly compensated for injuries that were THE EXTERNAL ENVIRONMENT INFLUENCING DIAGNOSIS 7-7 PREPUBLICATION COPY: UNCORRECTED PROOFS avoidable while at the same time turning errors into lessons to improve subsequent performance (Berenson, 2005; Mello et al., 2014a ; Mello and Gallagher, 2010). The IOM report Fostering Rapid Advances in Hea lth Care: Learning from System Demonstrations concluded that there are numerous chal lenges to the current medical liability system, including the many instances of neg ligence that do not result in litigation and, conversely, the many malpractice claims that are not the result of negligent care as well as judgments that are inconsistent with the evid ence base and highly variable compensation for similar medical injuries (IOM, 2002). Patients and their families are poorly served by the current system; only a fraction of negligently injured patients receive compensation, typically after a protracted and adversarial l itigation process (AHRQ, 2014; K achalia and Mello, 2011). One analysis found that fewer than 2 percent of patients who experienced adverse events due to medical negligence actually filed malpractice cl aims (Localio et al., 1991); another analysis found that the rates of paid medical malpractice claims have steadily de clined since the early 2000s (Mello et al., 2014b). An ongoing medical liability concern is the practice of defensive medicine. Defensive medicine \"occurs when doctors order tests, proce dures, or visits, or avoi d high-risk patients or procedures, primarily (but not necessarily so ley) to reduce their exposure to malpractice liability\" (OTA, p. 13, 1994). The practice of defensive medicine is a barrier to high-quality care, because it can lead to overly aggressive and unnecessary care. For example, clinicians who practice defensive medicine may order more dia gnostic tests than are necessary. (Hoffman and Kanzaria, 2014; Kessler, 2006; Mell o et al., 2010). Overtesting in the diagnostic process has the potential to cause patient harm\u2014both from the risk of the diagnostic test itself, as well as the resulting cascade of diagnostic a nd treatment decisions that stem from the test result (see also Chapter 3) (Hoffman and Kanzaria, 2014). Diagnostic errors are a leadi ng cause of malpractice claims , and these claims are more likely to be associated with patient deaths than other types of medical errors (Tehrani et al., 2013). Reforming the medical liability system, th erefore, has the potential to improve learning from diagnostic errors and to faci litate the disclosure of diagnostic e rrors to patients and their families as well as to produce fairer outcomes in the medical injury resolution processes. The committee recommends that states, in collaboration with other stakeholders (health care organizations, professional liability insuranc e carriers, state and federal policy makers, patient advocacy groups, and medical malpract ice plaintiff and defens e attorneys), should promote a legal environment th at facilitates the timely id entification, disclosure, and learning from diagnostic errors. There have been many calls for changes to the medical liability system. Traditional mechanisms to reform the liability system\u2014s uch as imposing barriers to bringing lawsuits, limiting compensation, and changing the way that damage awards are pai d\u2014have not resulted in improvements in either compensating negligently in jured patients or deterring unsafe care (Mello et al., 2014b). Thus, the committee concluded that th ese stakeholders need to consider alternative approaches to improving the legal environment and promoting learning from diagnostic errors. The To Err is Human report concluded that a lternative approaches to the resolution of medical injuries could reduce the incentive to hide medi cal injuries, and in 2002 the IOM proposed state- level demonstration projects to explore alternative approaches to the current liability system that are patient-centered and focused on patient sa fety (IOM, 2000, 2002). In 2010, AHRQ allocated approxim ately $23 million in funding for demonstration and planning gran ts aimed at finding ways to improve medical injury compensation and patient safety (AHR Q, 2015d; Kachalia and 7-8 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Mello, 2011). Five of the seven demonstration grants (totaling $19.7 mill ion in awarded funds) that were funded by AHRQ focused on communi cation and resolution programs (CRPs), one on safe harbors for following evidence-based clinical practice guidelines, and one on judge-directed negotiation. The 13 planning grants (totaling $3.5 million) were diverse and included CRPs, safe harbors, and other formats (AHRQ, 2015d). These demonstration and planning grants were somewhat limited, however, because they could not involve approaches that required legislative changes (such as administrative health court demonstrations) (Bovbjer g, 2010). Furthermore, while the Affordable Care Act authorized $50 million to test new approaches to the resolution of medical injury disputes, this funding was never appropriated. Although enthusiasm for alternativ e approaches to the current medical liability system is growing, in general the progress to ward such approaches has been slow, especially for those that involve more fundamental changes to the medi cal liability system. Thus, the committee took both a pragmatic and aspirational approach to considering which changes to medical liability could promote improved disclosure of diagnostic errors and opportunities to learn from these errors. A number of alternative approaches to the current medical liability system were evaluated, and the committee concl uded that the most promising approaches included CRPs, the use of clinical practice guidelines as safe harbor s, and administrative health courts (see Box 7-1). CRPs represent a more pragmatic approach in that they are more likely to be implemented in the current medical liability climate, and they ha ve a strong focus on improving patient safety as well as on reducing litigation . Thus, the committee recommends th at states, in collaboration with other stakeholders (health care organizations, professional liability insurance carriers, state and federal policy makers, patient advoc acy groups, and medical malpractice plaintiff and defense attorneys), should encourage the adoption of CRPs with legal protections for disclosures and apologies under state laws. Safe harbors for adherence to clinical pract ice guidelines may also help facilitate improvements in diagnostic accu racy by encouraging clinicians to follow evidenced-based diagnostic approaches; however, most clinic al practice guidelines address treatment, not diagnosis. Moreover, implementing safe harbors for adherence to these guidelines will be administratively complex. Administrative health c ourts offer a fundamental change that would promote a more open environment for identifyin g, studying, and learning from errors, but their implementation will be a major challenge due to operational complexity and to resistance from stakeholders who are strongly committed to preserving the current tort-based system. Thus, the committee concluded that these changes are mo re aspirational, and recommends that states and other stakeholders should conduct demonstr ation projects of alternative approaches to the resolution of medical injuries, including ad ministrative health courts and safe harbors for adherence to evidence-based clinical practice guidelines. The following sections describe the alternative approaches, the challenges infl uencing their implementa tion, and the potential benefits for improving diagnosis. BOX 7-1 Description of Alternative Approaches to the Medical Liability System Communication and resolution programs (CRPs) are principled comprehensive patient safety programs in which health care professionals and organizations openly discuss adverse outcomes with patients and proactively seek resolution while promoting patient-centeredness, learning, and quality impr ovement. CRPs typically incorporate the THE EXTERNAL ENVIRONMENT INFLUENCING DIAGNOSIS 7-9 PREPUBLICATION COPY: UNCORRECTED PROOFS following elements: o Early reporting of adverse events to the health care organization or liability insurer for rapid analysis using human factorsa and other advanced event analysis techniques o Developing plans for preventing recurrences and communicating this plan to patients and their families o Open communication with patients and their families about unanticipated care outcomes and adverse events o Proactively seeking resolutions, including offering an explanation as to why the event occurred and an acknowledgement of responsibility and/or an apology o Initiating support services, both emotional and other types of support, for the patient, family, and care team o Where appropriate, offering timely reimbursement for medical expenses not covered by insurance or compensation for economic loss or other remedies Safe harbors for adherence to evidence-based clinical practice guidelines are laws that provide health care professionals and organizations a defense against a malpractice claim if they can show that they followed a clin ical practice guideline in providing care for a patient. Safe harbors: o Create an affirmative defense for health care professionals who adhered to an accepted, applicable clinical practice guideline designated in advance o May create a rebuttable presumption (i.e., it is introduced as evidence of the standard of care, but is not dispositive) or irrefutable presumption of non-negligence Administrative health courts offer a system of administrative compensation for medical injuries which has the following components: o Injury compensation decisions are made outside the regular court system by specially trained judges o Compensation decisions are based on a standard of avoidability of medical injuries rather than a standard of negligence\u2014claimants must show that the injury would not have occurred if best practices had been followed or an optimal system of care had been in place, but they need not show that care fell below the standard expected of a reasonably prudent health care professional o Compensation decisions are guided by previous determinations about the preventability of common medical adverse events; this knowledge, coupled with precedent, is converted to decision aids that allow fast-track compensation decisions for certain types of injury o Previous determinations also inform decisions about the amount of the award for economic and non-economic damages a Human factors (or ergonomics) is: \"the scientific discipline concerned with the understanding of interactions among humans and other elements of a system, and the profession that applies theory, principles, data and methods to design in order to optimize human well-being and overall system performance. Practitioners of ergonomi cs and ergonomists contribute to the design and evaluation of tasks, jobs, products, environm ents and systems in order to make them compatible with the needs, abilities and limitations of people\" (IEA, 2000). SOURCES: Chow, 2007; Jost, 2014b; Peters, IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Communication and Resolution Programs CRPs have recently garnered significant atten tion as a means of improving the disclosure and resolution of medical in juries and improving patient safety. Several of the AHRQ demonstration projects focused on CRPs, and orga nizations such as the American College of Physicians and the American Co llege of Surgeons have called for continued experimentation (ACP, 2014; ACS, 2015). At 14 hospitals in thre e health care systems across the country AHRQ is currently developing and fiel d testing an educational toolk it on CRPs which teaches about the best practices from those CRP-focused demo nstration projects (AHR Q, 2015a). CRPs offer a principled, comprehensive, and systematic appr oach to responding to patients who have been harmed by their health care. They are an integral com ponent of a larger commitment to patient quality and safety. CRPs seek to meet the needs of the affected patient and their family; it is the health care organization's essen tial responsibility to address the quality issues and safety gaps that caused the event. While some of the sp ecifics related to CRP implementation may vary based on an organization's circumstances, Box 7-1 describes the essential components of a CRP. CRPs could improve patient safety generally and reduce diagnostic errors in several ways. CRPs rely on creating transparent health ca re cultures in which the early reporting of adverse events is the norm and is coupled with systems-based event analysis designed to understand the root causes of the event and to aid in the development of plans for preventing recurrences. Increased transparency surrounding di agnostic errors can help foster an improved culture of reporting, which in turn can promote learning about and identifying interventions to improve the safety and quality of diagnosis (Mello et al., 2014a). CRPs also emphasize remaining transparent about adverse events\u2014incl uding diagnostic errors\u2014w ith patients and their families. The disclosure of me dical errors also can also impr ove outcomes for patients, their families, and health care professionals (Delbanc o et al., 2007; Helmchen et al., 2010; Hendrich et al., 2014; Lopez et al., 2009). In some cases, clinician disclo sure of medical errors to patients is associated with higher ratings of quality care by patients (Lop ez et al., 2009). When a CRP was implemented at the University of Michigan Heal th System (UMHS), it was associated with fewer malpractice claims, faster claims processing times , and reduced liability costs, and settlement amounts (Boothman, 2009, 2012; Kachalia, 2010). Safe ty culture scores at UMHS also improved with the implementation of the CRP; however, it is difficult to at tribute causation to the CRP program (Boothman, 2012). Mello and colleagues found that CRPs \"appear to be effective in improving communication with patients and famili es. Disclosure reportedly became more routine and robust in implementing hospitals after clinic ians were given disc losure training and risk managers began more closely monitoring whether and how disclosures were carried out\" (2014b, p. 2150-2151). CRPs continue to expand in the United Stat es. For example, the Massachusetts Alliance for Communication and Resolution following Me dical Injury (MACRMI) is committed to spurring adoption of CRPs and sharing lessons le arned to improve the dissemination of CRPs throughout Massachusetts (MACMRI, 2015). MA CRMI supported enabling legislation that adopted the UMHS CRP model, including a six-month pre-litigation pe riod, protections for disclosures and apologies (MACRMI, 2015). Although establishing CRPs does not require le gislative changes, CRP adoption could be facilitated by changes to state laws, such as la ws protecting disclosures and apologies (Sage et al., 2014). For example, the American College of Physicians has called for \"strong, broad legal protections that ensure apologi es from physicians and other health care professionals are THE EXTERNAL ENVIRONMENT INFLUENCING DIAGNOSIS 7-11 PREPUBLICATION COPY: UNCORRECTED PROOFS inadmissible\" in a subsequent medical malp ractice action (ACP, 2014). Though more than two- thirds of states have apology laws, the majority only protect the clinic ian's voluntary expression of sympathy from use by a patient in malpracti ce litigation (Mastroianni et al., 2010). A small number of states also pr otect explanations of the event or ex pressions of fault, or both; however, Sage and colleagues concluded that no states protect \"the full scope of information that patients report needing when an unexpected outcome arises : a preliminary explanation of what happened; an expression of sympathy; an admission of respons ibility; and a final analys is of the causes and consequences of the event, with information about remedial actions taken to prevent such incidents in the future\" (Sage et al., 2014, p. 14). Of the nine states that have disclosure laws, a majority require health care organizations to notify patients when an event has caused serious harm. \"States vary on whether the disclosure receives protection from subsequent use by a plaintiff in malpractice litigation. For the most part, states provide lim ited, if any, procedural guidance; some states require written\u2014versus oral\u2014communication or timely communication\" (Mastroianni et al., 2010, p. 1614). The implementation of CRPs faces a number of challenges. One challenge is HHS's recent interpretation of the reporting requireme nts to the National Practitioner Data Bank (NPDB). Federal law requires that medical liability insurers report malpractice payments to the NPDB, which was initially established to preven t clinicians from concealing disciplinary and malpractice histories as they moved across state lines (Sage et al., 2014). An Oregon law attempted to assert that NPDB reporting was not required if a settlement resulted from a mediation mechanism, such as a CRP (Rob eznieks, 2014), but HHS concluded that any payments stemming from written demands (whether part of mediation mechanisms or not) are required to be submitted to the NPDB (HHS, 2014). There are concerns that these reporting requirements will prevent participation in CRP s: \"Physicians worry that CRPs will offer compensation when the physician was not at fault, either as a compassionate gesture or because the hospital or insurer deems it pr udent to settle, and that, as a result, physicians will be reported to the NPDB more often\" (Sage et al., 2014, p. 16). The reporting of settlements arising from mediation mechanisms to the NPDB could have negative effects on c linicians' reputations, credentialing, or disciplin ary actions, and at least one medical specialty society, the American College of Physicians, recommends that the repor ting requirement be altered to encourage CRP participation (ACP, 2014). Other considerations will influence the im plementation and effectiveness of CRPs, including the presence of organizational champions and a culture that supports the reporting of medical errors; a focus on coaching and support services to help clinic ians participate in disclosures and the CRP processes; and buy-in from and coordinati on with health care organizations and professional liability in surance carriers (Me llo et al., 2014a). Of particular interest is th e potential for CRPs to promot e widespread learning following adverse events. As growing numbers of health care organizations and professional liability insurers adopt CRPs, close collaboration among these programs and between these programs and PSOs could help ensure that the lessons learned from adverse events are shared widely within and outside the organizations where the even ts occurred. The establishment of a national collaborative of CRPs could be one way to accelera te the spread of CRPs a nd to fully realize the quality and safety benefits of these programs. 7-12 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Safe Harbors for Adherence to Evidence- Based Clinical Practice Guidelines Safe harbors for following evidence-based clin ical guidelines have th e potential to raise the quality of health care by cr eating an incentive\u2014liab ility protection\u2014for clinicians to follow evidence-based clinical practice guidelines.4 Safe harbors can create an affirmative defense for health care professionals who a dhered to accepted and applicable clinical practice guidelines. Input to the committee suggested that safe harb ors, unlike other approaches to improving the medical liability environment, offer direct oppor tunities to improve di agnosis (Kachalia, 2014). While other approaches to improving medical liability focus on improving learning through improved disclosure, safe harbors focus on al igning clinical care with best practices. Available evidence suggests that creating national standards of care against which clinicians are judged in malpractice claims can improve quality of care. Providing standardized guidelines for certain diagnostic work-ups and hold ing these to be the st andard of care has the potential to reduce diagnostic error. Despite calls for safe harbors (ACP, 2014; Mello et al., 2014b), there is limited information about how eff ective safe harbors are in minimizing medical errors, partly because there have been relatively few pilot programs and those programs have had poor clinician participation (Kachalia et al ., 2014; Mello et al., 2014b). A recent simulation analysis evaluated the potential impact of safe harbors and concluded th at they constitute a promising approach to driving improvements in the quality of patient care, but their impact on liability costs and patient outcomes is likel y to be minimal (Kachalia et al., 2014). There are a number of implementation challenge s related to a safe harbor for adherence to clinical practice guidelines. For example, it requires state endorsement of specific clinical practice guidelines for use in ma lpractice litigation. Fu rthermore, safe harbor programs may be administratively complex because they require de termining which clinical practice guidelines apply, when they apply, and who makes the dete rmination. Also, given the constantly changing evidence base, ensuring the timely updating of a pproved guidelines and making clinicians aware of the updates could be challenging (Bovbjerg and Berenson, 2012) . Clinician acceptability is another concern. Clinicians may find it burdensome to have to co mply with additional clinical practice guidelines for improving diagnostic pe rformance and avoiding liability. Clinicians already encounter multiple guidelines from specialty associations, insurers, health care organizations, hospitals, and others, and these gu idelines are likely not all in alignment. Additionally, recent policy changes add to the resist ance of using clinical practice guidelines for legal purposes. The legislation that repealed the sustainable growth rate included a provision that prevents the use of guidelines or standards used in federal programs as proof of negligence: The \"development, recognition, or implementation of any guideline or other standard\" under the Medicare and Medicaid programs and any provision in the Affordable Care Act \"shall not be construed to establish th e standard of care or duty of care owed by a health care provider to a patient in any medical malp ractice or medical product liability action or claim.\" 5 4 Safe harbors for adherence to clinical practice guidelines differ from the current use of clinical practice guidelines in the courts. Typically, malpractice litigation uses expert testimony to determine whether the care provided by a clinician fell below the standard of care (what would be expected of a reasonably prudent clinician). Expert witnesses can introduce clinical practice guidelines as legal evidence, but many states permit defendants to escape liability if they demonstrated customary care, even if it is not considered optimal care (IOM, 2011). This is partly due to variability in how states define the standard of care . Some states employ a national standard (clinicians would be held to the same degree of care and skill that a reason ably competent health care professional in the same field would exercise under similar ci rcumstances). Other states use a local standa rd of care (clinicians would be held to the degree of knowledge and skill that is generally exercise d by the same professionals in the community where they practice). 5 Medicare Access and CHIP Reauthorization Act of 2015. P.L. 114-10. (April 16, 2015). THE EXTERNAL ENVIRONMENT INFLUENCING DIAGNOSIS 7-13 PREPUBLICATION COPY: UNCORRECTED PROOFS Administrative Health Courts Administrative health courts have been proposed as a way to provi de injured patients with expedited compensation decisions for certain types of medical errors and to promote the disclosure of medical errors (s uch as diagnostic errors). Admini strative health courts are a non- judicial way of handling medical injuries, in which cases are filed through an administrative process. The goal in using these courts is to qu ickly and equitably compensate patients who have experienced avoidable injuries w ithout requiring the patients to become plaintiffs within the medical liability system who must prove neg ligence in an adversarial proceeding (Berenson, 2005). There are various versions of how such an approach might work. In one version, specially trained judges preside and are assisted by invest igations and opinions prov ided by neutral experts on the matter under consideration. Administrative heal th courts also take fault\u2014or negligence\u2014 terminology out of the determination of liability a nd substitute it with the concept of avoidability (IOM, 2002; Mello et al., 2006). \"[A] system ba sed on an avoidability standard would award compensation to claimants who could show that their injury would not have occurred in the hands of the best practitioner or system\" (Kachalia et al., 2008, p. 388). Proving negligence requires evidence that a clinician failed to meet a standard of care, is very fact-specific, and is more challenging to demonstrate; on the other ha nd, avoidability represents complications that generally should not occur under competen t medical care (Berenson, 2005). Although substituting the negligence standard with an avoidability standard will lower the threshold for making these determinations, claimants will still have to establish cause\u2014that their injuries were the result of their car e, rather than their underlying illnesses (Kachalia et al., 2008). The establishment of administrative health courts could help to reduce process inefficiencies and inequities in compensation cau sed by shortcomings in the current system of tort liability, and adjudicated ca ses could be used to inform and foster the development of mechanisms to identify and mitigate medical errors (IOM, 2002; Mello et al., 2006). Administrative health courts have been describe d as holding theoretic app eal because \"the model addresses some of the most im portant problems with the U.S. medical malpractice system, including the difficulty that pa tients have filing and prevailin g in claims, the duration of litigation, the substantial overh ead costs, the unpredictability of damages awards, and the punitive effect felt by physicians\" (Mello et al., 2014b). Health courts have been used in other countries, including Sweden, New Zealand, and Denmark, and evidence suggests that they provide compensation to a greater number of claimants and are able to reach conclusions more quickly and at lower costs th an tort-based mechanisms (ACP, 2006; Bovbjerg and Sloan, 1998; Mello et al., 2011). Health courts appear to ha ve bipartisan support in the United States: A nationwide poll conducted in 2012 found that 68 percent of Re publicans, 67 percent of Democrats, and 61 percent of independents surv eyed support the creation of health courts (Howard, 2012). Legislation to experiment wit h, or create, health courts ha s been proposed in a number of states\u2014including Georgia, Maryland, New Yo rk, Oregon, and Virginia\u2014but none has passed (Peters, 2008). Several organizations and experts have r ecommended pilot-testing or using health courts in the United States, but very few systems have been imple mented or even tested (ACP, 2014; Howard and Maine, 2013; IOM, 2002; Mello et al., 2014b; Peters, 2008). There are only two state sys tems that implement the principles of health courts, and these uses are confined to cases involving neurological birth injury (H oward and Maine, 2013; Mello et al., 2014b). 7-14 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS There are several challenges associated w ith health courts, including the need for legislative action, which has been difficult to achieve (Mello et al., 2014b; Peters, 2008). As mentioned earlier, resistance from stakeholders strongly committed to pres erving the current tort- based system will be a major challenge to overcome. Another issue that needs to be considered is how a health court should make information on pa id claims of avoidable injuries available to state professional licensing boards, state hospital licensing agencies, medical specialty boards, and the NPDB. Such reporting could have a chilling effect on clinician disclosure of diagnostic errors; however, there is a competing concern ab out limiting the transparency of information on potentially substandard care practices. RISK MANAGEMENT Professional liability insurance carriers and he alth care organizations that participate in captive or other self-insurance arrangements have an inherent interest in improving diagnosis. Many of these organizations are actively expl oring opportunities to improve diagnosis and reduce diagnostic errors. According to input the committee received, \"[M]edical liability serves as a rich training area for reducing diagnostic error\" (Lembitz and Boyle, 2014, p. 1). Given the expertise of professional liability insurance carriers and captive insurers in understanding the contributing factors to diagnostic errors, they ca n bring an important perspective to efforts to improve diagnosis, both those focused on individual health care professionals and those focused on the work system components that ma y contribute to diagnostic errors. Thus, the committee recommends that professional liability insu rance carriers and captive insurers should collaborate with health care professional s on opportunities to improve diagnostic performance through education, training, a nd practice improvement approaches and they should increase participation in such programs. One way in which these groups are helping improve diagnosis is by conducting data analyses that characterize the reasons that dia gnostic errors occur. PIAA, the industry trade association representing companies in the medical liability insurance field, has a data sharing project that gathers and analyzes data on medi cal professional liability claims submitted by its members (Parikh, 2014).6 The project's findings are used to identify opportunities to reduce risk and improve patient safety in health care organizations. Individual carriers can also provide information to help improve the understanding of di agnostic errors that lead to medical liability claims. For example, Physician Reciprocal Insu rers (PRI), CRICO, and The Doctors Company have gathered data on submitted and paid malpractice claims that suggest that diagnostic errors are the cause of around 20 percent of all submitted claims and 52 percent of all paid claims (CRICO, 2014; Donohue, 2014; Tr oxel, 2014). CRICO synthesize s information on important issues in medical injury claims and produces reports on these issues (such as a report on diagnostic errors in ambulatory care settings) (CRICO, 2014). Pr ofessional liability insurers often have rich data because they have collected a variety of informati on (e.g., information from electronic health records [EHRs], st atements from various participan ts in the diagnostic process, and information from court documents) in the course of preparing fo r medical malpractice lawsuits. This information can lead to important, albeit potentially non-representative, insights about the vulnerabilities in the diagnostic process and about potential areas on which to focus in order to improve care. Improved voluntary participation in malp ractice claims databases among 6 As discussed in Chapter 3, one of the limitations of malpractice claims data is that it is not necessarily representative of diagnostic error in clinical practice; in one analysis, fewer than 2 percent of patients who experienced adverse events due to medical negligence filed malpractice claims (Localio et al., 1991). THE EXTERNAL ENVIRONMENT INFLUENCING DIAGNOSIS 7-15 PREPUBLICATION COPY: UNCORRECTED PROOFS all professional liability insurance carriers and captive insurers could be helpful for aggregating information and sharing lessons learned. Many professional liability insurers offer risk management educational services that are designed to improve diagnostic performance. The associated activities include seminars, workshops, team training, residency training programs, and newsletters (Donohue, 2014; Lembitz and Boyle, 2014). COPIC, a provider of me dical liability insuran ce, reported that it conducts over 2,000 practice site visits each year, in which speci ally trained nurses use explicit criteria to identify patient safety and risk i ssues, including vulnerability to systems errors, communication failures, information transfer, EHR issues and standardized processes (Lembitz and Boyle, 2014). In some cases, incentives such as discounted insurance premiums are offered to individuals to induce participation (D onohue, 2014; Lembitz and Boyle, 2014). Surveys suggest that clinicians perceive these educational and training approaches as beneficial; for example, Physicians Reciprocal In surers reported that 94 percent of the clinicians participating in their case review exercise believ e that it will reduce th e risk of diagnostic errors occurring in their practice (Donohue, 2014). Unfortunately, because of measurement difficultie s, there is little information on the impact of these educational a pproaches on the occurrence of diagnostic error (Donohue, 2014; Lembitz and Boyle, 2014). However, the committee concluded that the expertise of health professional liability insurance carriers should be leveraged to improve the diagnostic process. Improved collaboration betw een health professional liability insurance carriers and health care professionals and organizations could help to identify resources, prioritize areas of concern, and devise in terventions. Collaboration among health care professional educators and profe ssional liability insurance carri ers also could be helpful in developing interventions for trainees. An ex ample of collaborative efforts among medical liability insurers and educators is the recent grant from The Doctors Company Foundation to the Society to Improve Diagnosis in Medicine (S IDM, 2015; TDCF, 2015). This grant will provide funding for diagnostic training, with a focus on cl inical reasoning and methods to communicate with patients about diag nostic errors (SIDM, 2015). PAYMENT AND CARE DELIVERY FFS payment, the predominant form of payment for health care services in the United States, pays health care profe ssionals for each service they provide. FFS payment has long been recognized for its inability to in centivize well-coordinated, high-qua lity, and efficient health care (Council of Economic Advisors, 2009; IOM, 2001, 2013a; National Commission on Physician Payment Reform, 2013). There is relatively little information about the impact of payment on the diagnostic process. However, the committee conclude d that payment is likely to have an impact on the diagnostic process, and several paymen t experts who provided input to the committee helped elaborate on some of these conseque nces (Miller, 2014; Rose nthal, 2014; Wennberg, 2014). In general, FFS payment may not incentivize a high-quality, efficient diagnostic process because the more services the diagnostic proc ess entails, the more remuneration will result. There is no disincentive for orde ring unnecessary diagnostic testi ng that could lead to false positive results and diagnostic errors (Miller, 2014; Wennberg, 2014). There is also a financial incentive to provide treatment to patients, rath er than determining that patients do not have health problems; thus inappropria te diagnoses are better compensated than determining that a patient does not have a health problem. Likewise, accuracy in the diagnostic process is not 7-16 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS explicitly rewarded by FFS payment: Clinicians who interpret diagnostic testing or provide a diagnosis during a patient visit receive paymen t whether the work was done adequately to support accurate interpre tation and diagnosis and whether the interpretations and diagnoses are accurate or not (Miller, 2014). Given the importance of team-based care in th e diagnostic process, the lack of financial incentives in FFS payment to coordinate care may contribute to challenges in diagnosis and diagnostic errors, particularly delays in di agnosis (Rosenthal, 2014). FFS Medicare and most commercial payers do not pay for time that a cl inician spends contacti ng other clinicians by phone or email to facilitate the diagnostic process, for example, by helping determine the appropriate diagnostic tests for a patient. In addition, clinicians are not reimbursed for proactive outreach to patients to obtain dia gnostic testing, schedule visits w ith specialists, or make follow- up appointments (Miller, 2014). To improve teamwork and care coordination in the diagnostic process, the committee recommends that the Centers for Medicare & Medicaid Services (CMS) and other payers should create current procedural terminology (CPT) codes and provide coverage for additional evaluation and management activities not currently coded or covered, including time spen t by pathologists, radiologists, and other clinicians in advising ordering clinicians on the selection, use, and interpretation of diagnostic testing for specific patients. New CPT codes can help incentivize communication and collaboration among treating clinicians and clinicians wh o conduct diagnostic testing in order to improve the diagnostic testing process for patients (Allen and Thorwarth, 2014; Kroft, 2014; Miller, 2014). These codes could be modeled on current CPT codes that compensate coordination and planning activities that are r ecognized for payment by Me dicare and some other payers (e.g., CPT codes for radiation thera py planning, post-discharg e transitional care coordination, and complex chronic care co ordination) (AAFP, 2013; ASTRO, 2014; Bendix, 2013; Blue Cross 2013, 2014b; Landon, 2014; Nicoletti, 2005; Texas Medical A ssociation, 2013). The committee recognized that the proposed new codes are not meant to capture every discussion among c linicians; they are meant to capture discrete work that does not o ccur routinely in normal in teractions to encourage more collaborative activity in the diagnostic process. The Medicare physician fee schedule sets paym ent rates based on rela tive value units that are meant to reflect the level of time, effort, skill, and stress associated with providing each service (MedPAC, 2014). Fee schedule services can include evaluation and management services (\"E&M services,\" such as office, inpatient, or emergency department visits), diagnostic testing, and other procedures. For all medical special ties, there are well documented fee schedule distortions that result in more generous payments (in relation to the costs of production) being made for procedures and diagnostic testing interpreta tions than for E&M services (Berenson, 2010; The National Commission on Physician Paym ent Reform, 2013). The existence of these distortions has coincided with a large growth in diagnostic testing in hea lth care (see Figure 7-2); for example, the percent of patients presenting to the emergency department with dizziness who underwent computed tomography (CT) scans rose from 9 percent in 1995 to 40 percent in 2013, but this has not increased dia gnoses of stroke or other neurologic diseases (Iglehart, 2009; Newman-Toker et al., 2013). THE EX T FIGUR E rates of o From N e policy\u2014 A Society. T problem a and skill s divertin g patient's diagnost i relative v and ma n cognitiv e also red u E of accur a diagnost i time and shorter a p patient w practice w 4 E&M v revenue p T and to thSchiff et TERNAL EN V E 7-2 Rates o other clinici a ew England J A work in p Reprinted w The lower re l atic for imp r s that all cli n g attention a n clinical his t ic process. T value fees t o nagement a c e work in th e ucing incent i E&M payme n ate, timely d i ic process f o complexity , ppointment who is billed will receive visit instead per hour (M i Time pressur e e occurrenc e al., 2009; S i VIRONMENT PREPUBL Iof use of m e an-ordered s e Journal of M rogress, 36 0 with permiss i lative value a roved diagn o nicians have nd time fro m tory and int e Thus, the co o more app r ctivities. Rea e diagnostic ives that dri v nt policies a n iagnosis. E & or an individ u , and practi c lengths. For as a level 3 25 percent l of 15 minut e iller, 2014). es in clinica l e of errors ( D ingh et al., 2 INFLUENC I ICATION C imagi n ervices, per Medicine, J. K 0(10), 1030 - ion from M a afforded to E ostic perfor m and use in t m important t erview, cond u mmittee re c ropriatel y v aligning rel a process has ve the inapp r nd docume n &M paymen t ual patient. T ces receive b example, i n E&M visit r ess revenue es for a leve l visits can c Durning, 20 1 2013). Altho u ING DIAGN O OPY: UNCO Rng services a Medicare B e Copy r assachusetts M E&M servic mance. M the diagnost i tasks in the d ucting a ph y commends t value the ti m ative value fe the potenti a ropriate utili ntation ts penalize c There are di etter compe n n Medicare, i rather than s p per hour; if l 3 visit, the contribute to 14; Kostis e t ugh there is OSIS RRECTED P Rand diagnos t eneficiary ( 2 Health insur right 2009 M Medical So c es versus pr o M services re f ic process, a diagnostic p r ysical exam, that CMS a me spent wi t fees to bette r al to improv e ization of di a elines also a r clinicians fo r fferent leve l nsation if th if a clinicia n pending jus t a clinician s practice wi l o various ch a t al., 2007; S evidence th a ROOFS tic testing c o 2000-2007) . rers and me d Massachuset t ciety. ocedure-ori e flect the co g and these dis t rocess, suc h and decisio n and other p a th patients r compensat e e accuracy i n agnostic tes t re misaligne d r spending e x ls of E&M v ey see more n spends 20 m t 15 minute s spends 25 m ll receive 11 allenges in c l Sarkar et al., at the lengt h ompared wit h . dical-imagin g care i s gnitive expe r tortions ma y h as perform i n making in ayers reori e in evaluati o e clinicians f n diagnosis w ting. d with the g o xtra time on visits based o patients wi t minutes wit h s, the clinici a minutes for a percent les s linical reaso 2012, 2014 ; h of clinical 7-17 h g s rtise y be ing a the ent on for while oal the on th h a an's level s oning ; 7-18 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS appointments have not generally declined,7 there are concerns that the rising complexity of health care, the growth in patients with co mplicated health conditions, and increased EHR- related tasks are contributing to increased time pressures. The aging U.S. population contributes to added complexity for patient care decisions , due to the need for understanding the various factors that may be contributing to an older ad ult's health, such as multiple comorbidities and polypharmacy (IOM, 2008, 2013b). While unlimited time is neither the objective nor realistic, it is important to make time for effectively addr essing these complex care decisions. Making more effective use of the time available will be critical, as will making improvements to the work system in which the diagnostic process occurs (such as disseminating an organizational culture that is supportive of t eamwork in the diagnostic process, the better allocation of tasks, and ensuring that health information technology (health IT) is supportive of the di agnostic process). In addition to modifying payment policie s, the documentation guidelines for E&M services could also be improved to support the diagnostic process. Docu mentation guidelines for E&M services were created to ensu re that the services performed were consis tent with insurance coverage; to validate specific info rmation, such as the site of se rvice, the appropriateness of the care, and the accuracy of the reported information; and to prevent fraud and abuse (see Chapter 5) (Berenson, 1999; CMS, 2014a). Documentation guidelines specify the extent of a patient's clinical history and interview, the physical ex am, and the complexity of medical decision making involved in the E&M visit (Berenson et al., 2011 ; HHS, 2010). There are a number of criticisms of the documentation guidelines; th e primary argument is that the level of detail required is onerous, is often irrelevant to pa tient care, and shifts the purpose of the medical record toward billing rather than facilitating clinical reasoning (Berenson et al., 2011; Brett, et al., 2015; Schiff and Bates, 2010). The documentation guidelines have become an even greater concern with the broad implementation of EHRs because EHR design has focused on fulfilling documentation and legal requirements and not on facilitating the diagnos tic process (Berenson et al., 2011; Schiff and Bates, 2010). EHRs tend to lack a cohesive patient narrative, which will include nuance, details, and important contextual information that all help clinicians make accurate and timely diagnoses. The orientation of EHRs to documentation, their overreliance on templates, and the cut-and-paste functionalities within EHR capabilities have re sulted in \"EHR-generated data dumps, including repetitive documentation of elements of patie nts' histories and physic al examinations, that merely result in electronic versions of clini cally cumbersome, uninformative patient records\" (Berenson et al., 2011, p. 1894). Generating doc umentation to support E&M coding (or higher levels of E&M coding than are warranted, which is called \"upcoding\") can result in inaccuracies in the patient's EHR that can cont ribute to diagnostic errors. A number of payment and care delivery reform s aimed at countering the limitations of the FFS payment system are actively being consid ered, implemented, and evaluated (see Box 7- 2). These include capitation/global payments , shared savings, bundled episodes of care, accountable care organizations, pa tient-centered medical homes, and pay for performance (which Medicare refers to as \"value-based purchasing\"). Box 7-2 includes both potential benefits of new payment models on improving diagnosis, as well as some of the potential drawbacks (see also Himmelstein and Woolhandler [2014] for a disc ussion of the potential limitations of new payment models). Salary is not described as a payment model, because the committee focused on third party payments rather than provider organization compensation. 7 For example, the National Ambulatory Medical Care Survey found that in 1992 most visits lasted 15 minutes or less; by 2010, only half of clinician visits were that short (Rabin, 2014). THE EXTERNAL ENVIRONMENT INFLUENCING DIAGNOSIS 7-19 PREPUBLICATION COPY: UNCORRECTED PROOFS CMS recently announced that it plans to have 30 percent of Medicare payments based on alternative models by the end of 2016 and 50 per cent of payments by th e end of 2018 (Burwell, 2015). The Medicare Access and CHIP Reauthorization Act of 2015 (which repealed the sustainable growth rate) continues down th e path toward alternative payment models, particularly for the payment of Medicare clinicians.8 While the impact of alternative payment and delivery systems on quality are actively being investigated (e.g., the Blue Cross Blue Shield of Massachusetts Alternative Qual ity Contract, as well as patient -centered medical homes), there is very limited evidence on what impact such payment and delivery models will have on the diagnostic process and on the accuracy of diagnosis , and this represents a fundamental research need. Thus, the committee recommends that CM S and other payers should assess the impact of payment and care delivery models on the diagnostic process, the occurrence of diagnostic errors, and learning from these errors. Assessing the impact of payment and care delivery reforms, including FFS, on the diagnostic process, diagnostic errors, and learning are critical areas of focus as these models are ev aluated more broadly. CMS' Innovation Center is testing many of the alternative payment models, and is well suited to evaluate the impact of these models on the diagnostic pr ocess and the occurrence of diagnostic errors. While new payment models have the potential to reduce diagnostic errors, the committee also recognized that these models may also cr eate incentives for clinicians and health care organizations that could reduce us e of appropriate testing and c linician services (e.g., specialty consultations) that may inadvertently lead to greater diagnostic erro rs. To address these possibilities, the committee recognized that not only is direct evaluation of the impact of payment models on diagnostic errors important, but also there is a need for better measurement tools to identify diagnostic errors in clinical practi ce (see Chapters 5 and 6). Additionally, the committee asked for input from payment and delivery experts about the potential effects of new models on diagnosis an d diagnostic error. Rose nthal (2014) suggested that global payment and meaningf ul use incentives have the potential to improve diagnosis by promoting the adoption of diagnostic test and referral tracking systems that better connect health care professionals throughout the continuum of care. Mille r (2014) suggested that the development of measures for diagnostic accuracy be developed to provide feedback and reward clinicians for diagnostic accuracy. Wennberg (2 014) suggested that population-based payment models, including capitation and gl obal budgets, have the greatest potential to reduce diagnostic errors. BOX 7-2 Payment and Care Delivery Reforms and Their Potential Impact on Diagnosis Global Payment, Capitation, and Per-Member Per-Month o Definition: \"A single per-member per-month payment is made for all services delivered to a patient, with payment adjustments based on measured performance and patient risk\" (Schneider et al., 2011, p. 13). o Potential impact on diagnosis: Broader adoption could enhance provider activities that improve diagnostic accuracy and reduce diagnostic errors because the capitated, at-risk organization bears the cost of diagnostic error if there are immediate costs associated with the error. For diagnostic errors that do not necessarily lead to higher costs for the organization, investment into lowering 8 Medicare Access and CHIP Reauthorization Act of 2015. P.L. 114-10. (April 16, 2015). 7-20 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS these errors (e.g., more vigilant evidence-based cancer scre ening which could increase costs due to treatment of newfound cancers) may be suboptimal. The use of quality measures and reporting may incentivize organizations to detect the underuse of these screening activities, to reengineer care, to invest in electronically based decision support and artificial intelligence which could improve accuracy, to engage clinicians in ongoing activities to improve diagnostic skills, and to engage in systems approaches to mitigating harm from potential diagnostic errors. Accountable Care Org anizations oDefinition: \"G roups of providers that voluntarily assume responsibility for the care of a population of patient s\" (Schneider et al., 201 1, p. 13). oPotential impact on diagnosis: The quality of care in Account able Care Organizatio ns (ACO) is assessed through a set of quality measures, but none of them involve accuracy or timeliness of diagnosis, for the reasons descr ibed in Chapter 3. ACOs have the potential infrastructure to provide a base of activity to improve dia gnostic accuracy for their constituent or affiliated clinicians. So far, most ACOs do not accept risk, so the potential of non-fee-for-service fina ncial incentives h as not yet been realized. Nevertheless, the stru cture of an ACO and its need to credential it s members and engage in quality and safety improvement programs can provide a new source of interest a nd provider expertise in engaging in the problem of diagnostic errors. To date, payers have not determined that diagnost ic errors are a priority quality and safety problem that needs attent ion. ACOs, for example, would be well positioned to administe r and promote follow-up and feedback ap proaches and to develop a culture in which these appro aches are welcomed and routine. Bundled Payment or Episode-Based Paymen t oDefinition: A \"single 'bundled' payment, which may include multiple providers in multiple car e settings, is made for services delivered during an episode of care related to a medical condition or procedure\" (Schneider et al., 2011, p. 13 ). oPotential impact on diagnosis: By definition, bundled payment would se em to apply mostly to well esta blished, \"correct\" diagnoses, for which efficiencies of care can be further gained, and it remains volume-based (i.e., the finan cial incentive is t o produce more, efficiently provided episodes). This raises th e importance of addressin g appropriateness of the bundled episode proced ure being perfor med. Appropriateness is relevant to the topic of diagnostic e rror in the sense of needing to determine acuity of the condition as part of the diagnostic process. For chronic conditions, episode-based payment runs the risk of non- holistic care. For example, the clinici ans receiving the episode -based payment for a condition such as diabetes may not be as attuned to diagnosis and management of comorbidities that may arise in the course of managemen t of the index condition. Pay for Performance or Value-Bas ed Purchasing oDefinition: \"physicians receive diffe rential payments for meeting or missing performance benchmarks\" (Schneid er et al., 201 1, p. 14). oPotential impact on diagnosis: Theoretically this can be a useful payment tool for focusing pro vider attention on important quality problems that can be measured accurately a nd then financially rewarded and pen alized. Overall, the effects ofTHE EXTERNAL ENVIRONMENT INFLUENCING DIAGNOSIS 7-21 PREPUBLICATION COPY: UNCORRECTED PROOFS pay for performance on outcomes remain unsettled, with con c erns about the effects on important elements of care that are not being measured. Current pushes for accountability neglect performance measures for diagnosis, and that is a major limitation of these approaches. Patient-Centered Medica l Homes oDefinition: \"a physician practice or other provider is eligible to receive additional payments if medical home criteria are met. Payment may include calculations based on qu ality and cost performance using a P4 P-like mechanism\" (Schneider et al., 2011, p. 13). Although not an inherent part of the definition, most medicalhome initiatives are taking place in primary care practices. oPotential impact on diagnosis: A well functioning medical home, teamwo rk, longstandin g relationships with patients as the center for care and care coordination , and ultimately, reliance on improved electronic health record s and interoperability of patient information to inform clinical decision making has thepotential to improve diag nostic performance. There are concer ns, however, that medical home performance will be assessed using measures that do not include those relate d to diagnostic performance, although it is known that there is a significant p roblem of diagnostic error in primary care (Ely et al., 2012; Singh et al., 2013). Shared Sav ings oDefinition: \"a payment strategy that offers incentives for providers to redu ce health care spending for a defined pa tient population by offering them a percentage of net savings realized as a result of their efforts\" (Bailit and Hughes, 2011, p. 1). oPotential impact on diagnosis: As a payment method, there are no directincentives to focus on improving diagnostic accuracy. The impact depend s largely on the objectives of the underlying organization to which the payme nt is being applie d. For example, shared savings has become the primary met hod for rewarding ACOs for spending less t han a target spending am ount. Theoretically, at least, the ACO should be interested in diagnostic accura cy if by getting the diagnosis correct, subsequent spending can be promptly reduced. So the focus would be on efforts to make correct diagnoses of acute, urge nt presentations of illness in emergency departments and primary ca re practices and for commonly misdiagnosed condition s such as stroke and co ngestive heart failure. Conversely, based on incentives alone, the organization might be less in terested in efforts to make accurate and timely diagnoses of condition s whose costs would not be borne for many months or y ears. To date, ther e seems to be little attention paid to diagnostic accura cy as a mechanism for achi eving savings. Even when alternate paym ent and care de livery approaches to FFS are employed, they are often based on or influenced by existing c oding and payment rules (Berenson et al., 2011). For example, bundled payments are combinations of current codes. Thus, the current distortions in the fee schedule and other volume-based paym ent approaches, such as diagnosis-related group coding, will remain a dominant component of pa yment and care delivery models in the near future and need to be addressed. As long as fee schedules re main a predominant mechanism for determining clinician payment, the comm ittee recommends that CMS and other payers should modify documentation guidelines fo r evaluation and management services to 7-22 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS improve the accuracy of information in the EHR and to support decision making in the diagnostic process. RECOMMENDATIONS Goal 6: Develop a reporting environment a nd medical liability system that facilitates improved diagnosis by learning from diagnostic errors and near misses Recommendation 6a: AHRQ or other appropriat e agencies or independent entities should encourage and facilitate the voluntary reporting of diagnostic errors and near misses. Recommendation 6b: AHRQ should evaluate the effectiveness of PSOs as a major mechanism for voluntary reporting and learning from these events and modify the PSO common formats for reporting of patient safety events to include diagnostic errors and near misses. Recommendation 6c: States, in collaboration with other stakeholders (health care organizations, professional liability insura nce carriers, state and federal policy makers, patient advocacy groups and medical malpractic e plaintiff and defense attorneys), should promote a legal environment that facilitates the timely identification, disclosure, and learning from diagnostic errors. Specifically, they should: Encourage the adoption of CRPs with legal protections for disclosures and apologies under state laws. Conduct demonstration projects of alternat ive approaches to the resolution of medical injuries, including administrative health courts and safe harbors for adherence to evidenced-based clin ical practice guidelines. Recommendation 6d: Professional liability insu rance carriers and captive insurers should collaborate with health care professional s on opportunities to improve diagnostic performance through education, training, and practice improvement approaches and increase participation in such programs. Goal 7: Design a payment and care delivery environment that supports the diagnostic process Recommendation 7a: As long as fee sche dules remain a predominant mechanism for determining clinician payment, CMS and other payers should: Create CPT codes and provide coverage for additional evaluation and management activities not currently coded or covered, including time spent by pathologists, radiologists, and other clinicians in advising ordering clinicians on the selection, use, and interpretation of diagnostic testing for specific patients. Reorient relative value fees to more appropriately value th e time spent with patients in evaluation and management activities. Modify documentation guidelines for evaluation and management services to improve the accuracy of information in th e EHR and to support decision making in the diagnostic process. THE EXTERNAL ENVIRONMENT INFLUENCING DIAGNOSIS 7-23 PREPUBLICATION COPY: UNCORRECTED PROOFS Recommend ation 7b: CMS and other payers should assess the impact of payment and care delivery models on the diagnostic process, th e occurrence of diagnostic errors, and learning from these errors. REFERENCES AAFP (American Association of Family Physicians). 2013. Frequently asked que stions: Transitional care management. http://www.aafp.org/dam/AAFP/documen ts/practice_managemen t/payment/TCMFAQ.pdf (accessed June 8, 2015). ACP (American College of Physicians). 2006. Exploring the use of health courts\u2014Addendum to \"Reforming the medical professional liability system.\" www.acponline.org/acp_po licy/policies/health_courts_reform_me dical_liability_2006.pdf (accessed May 24, 2015). ACP. 2014. Medical liability reform: Innovative solutions for a new health care system: A position paper. Philadelphia: American College of Physicians. www.acponline.org/acp_po licy/policies/medical_liability_reform_ 2014.pdf (accessed June 8, 2015). ACS (American College of Surgeons). 2015. Statement on medical liability. http://bulletin.facs.org/2 015/03/statement-on-medical-liabil ity-reform/ (accessed May 16, 2015). AHRQ (Agency for Healthcare Research and Quality). 2014. Medical liability reform and patient safety initiative. www.ahrq.gov/professionals/quality-p atient-safety/patient-safety-reso urces/resources/liability/ (accessed April 10, 2015). AHRQ. 2015a. Agency for Healthcare Research and Qua lity: Justification of estimates for appropriations committees. www.ahrq.gov/sites/default/files/wysi wyg/cpi/about/mission/budget/2016/cj2016.pdf (accessed May 3, 2015). AHRQ. 2015b. Common formats. rq.gov/common (accessed 2015c. Federally liste PSOs. www.pso.ahrq.gov/liste d (accessed May 3, 2015). AHRQ. 2015d. Medical liability reform and patient safety initiative progress report. www.ahrq.gov/professionals/quality-patient-safety/patient-safety- resources/resources/liab ility/medliabrep.html (acce ssed May 24, 2015). AHRQ. safety organization (PSO) program: Frequently asked questions. www.pso.ahrq.gov/faq#WhatisaPSO (accessed May 3, 2015). AHRQ. 2015f. Patient safety organization (PSO) program: Reducing unnecessary hospital readmissions: The role of the patient safety organization . www.pso.ahrq.gov/Topics (accessed May 3, 2015). Allen, B. 2014. Comments from the American College of Radiology. Presentation to the Committee on Diagnostic Error in Health Care, November 5, 2014, Washington, DC. ASTRO. 2014. Basics of RO coding. www.astro.org/Practice-Management/Reimbursement/Basics-of-RO- Coding.aspx (accessed March 26, 2015). Bailit, M., and C. Hughes. 2011. Key design elements of shared-savings payment arrangements . The Commonwealth Fund Publication No. 1539. www.commonwealthfund.org/~/media/Files/Publica tions/Issue%20Brief/2011/Aug/1539_Bailit_key_desig n_elements_sharedsavings_ib_v2. pdf (accessed June 8, 2015). Barach, P., and S. D. Small. 2000. Reporting and preventing medical mishaps: Lessons from non-medical near miss reporting systems. BMJ 320(7237):759-763. Bendix, J. 2013. Making sense of the new transitional care codes. Medical Economics, March 10. http://medicaleconomics.modernmedicine.com/medi cal-economics/news/user-defined-tags/99495/making- sense-new-transitional-care-codes?pa ge=full (accessed March 26, 2015). Berenson, R. A. 1999. Evaluation and management guidelines. New England Journal of Medicine 340(11):889; author reply 890-881. Berenson, R. A. 2005. Malpractice makes perfect. The New Republic, October 10. /www.newrepublic.com/article/health-c are-malpractice-bush-frist (accessed. Berenson, R. A. 2010. Out of whack: Pricing di stortions in the medicare physician fee schedule. Expert Voices, September. www.nihcm.org/pdf/NIHCM-EV-Berenson_FINAL.pdf (accessed June 8, 2015). Berenson, R. A., P. Basch, and A. Sussex. 2011. Revisiting E&M visit guidelines--A missing piece of payment reform. New England Journal of Medicine 364(20):1892-1895. 7-24 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Blue Cross Blue Shield of North Carolina. 2015. Corporate medical policy: E-visits (online medical evaluations). www.bcbsnc.com/assets/services/public/pdfs/medi calpolicy/evisits_online_medical_evaluation.pdf (accessed June 8, 2015). Boothman, R. C., A. C. Blackwell, D. A.Campbell Jr, E.Commiskey , and S. Anderson. 2009. A better approach to medical malpractice claims? The University of Michigan experience. Journal of Health & Life Sciences Law 2(2): 125-159. Boothman, R. C., S. J. Imhoff, D. A. Campbell Jr. 2012. Nurturing a culture of patient safety and achieving lower malpractice risk through disclosure: Lessons learned and future directions. Frontiers of Health Services Management 28(3): 13-28. Bovbjerg, R. R., and F. A. Sloan. 1998. No fault for medical injury: Theory and evidence. University of Cincinnati Law Review 67. http://ssrn.com/abstract=1 47016 (accessed June 6, 2015). Bovbjerg, R. R. 2010. Will the Patient Protection and Af fordable Care Act address problems associated with Insitu te. www.urban.org/research/publi cation/will-patient-protection-and- affordable-care-act-address-probl ems-associated-medical-malprac tice 3, 2015). Bovbjerg, R. R., and R. Berenson. 2012. The value of c linical practice guidelines as malpractice \"safe harbors.\" Urban Institute. www.rwjf.org/content/dam/farm/repor ts/issue_briefs/2012/rwjf72667 (accessed June 8, 2015). Brett, A. S. 1998. New guidelines for codi ng physicians' services\u2014A step backward. New England Journal of Medicine 339(23):1705-1708. Burwell, S. M. 2015. Setting value-based payment goals\u2014HHS efforts to improve U.S. health care. New England Journal of Medicine 372(10):897-899. Chow, E. 2007. Health courts: An extreme makeover of medical malpractice with potentially fatal complications. Yale Journal of Health Policy, Law, and Ethics 7(2):387-427. CMS (Centers for Medicare & Medicaid Services). 2013. Telehealth services . Department of Health and Human Services. http://www.cms.gov/Outreach-and- Education/Medicare-Learning-Network- MLN/MLNProducts/downloads/T elehealthSrvcsfctsht.pdf (accessed June 8, 2015). CMS. 2014a. Evaluation and management services guide: Official CMS informatio n for Medicare fee-for-service providers . Washington, DC: Centers for Medicare & Medicaid Services. CMS. 2014b. Policy and payment changes to the Medicare physician fee schedule for 2015. www.cms.gov/newsroom/mediareleas edatabase/fact-sheets/2014-Fact-s heets-items/2014-10-31-7.html (accessed March 26, 2015). Council of Economic Advisors. 2009. The economic case for health care reform . http://www.whitehouse.g ov/assets/documents/CEA_Health_Care_Re port.pdf (accessed March 17, 2015). CRICO. 2014. 2014 annual benchmarking report: Malpractice risks in the diagnostic process. CRICO Strategies. http://www.rmfstrategies .com/benchmarking (acce ssed June 8, 2015). Delbanco, T., and S. K. Bell. 2007. Guilty, a fraid, and alone\u2014struggling with medical error. New England Journal of Medicine 357(17): 1682-1683. Donohue, G. 2014. PRI medical liability insurance. Input submitted to the Committee on Diagnostic Error in Health Care, November 25, 2014, Washington, DC. Durning, S. J. 2014. Submitted input. Input submitted to the Committee on Diagnostic Error in Health Care, October 25, 2014, Washington, DC. Edwards, S. T., and B. E. Landon. 2014. Medicare's chronic care ma nagement payment\u2014Payment reform for primary care. New England Journal of Medicine 371(22):2049-2051. Ely, J. W., L. C. Kaldjian, and D. M. D'Alessandro. 201 2. Diagnostic errors in pr imary care: Lessons learned. Journal of the American Board on Family Medicine 25 (1):87-97. Evans, W. N., and B. Kim. 2006. Patient outcomes when hospitals experience a surge in admissions. Journal of Health Economics 25(2):365-388. Gallagher, T. H., C. Denham, L. Leape, G. Amori, and W. Levinson. 2007. Disclosing unanticipated outcomes to patients: The art and practice. Journal of Patient Safety 3(3):158-165. Gallagher, T. H., J. Etchegaray, B. Bergstedt, A. Chappelle, M. Ottosen, E. W. Sedlock, E. J. Thomas. In review. Improving stakeholder understanding of accountability following medical injury using a patient-created simulation exercise. Gallagher, T. H., M. M. Mello, W. Levinson, M. K. Wynia, A. K. Sachdeva, L. Snyder Sulmasy, R. D. Truog, J. Conway, K. Mazor, A. Lembitz, S. K. Bell, L. Sokol-Hessner, J. Shapiro, A.-L. Puopolo, and R. Arnold. 2013. Talking with patients about other clinicians' errors. New England Journal of Medicine 369(18):1752-1757. THE EXTERNAL ENVIRONMENT INFLUENCING DIAGNOSIS 7-25 PREPUBLICATION COPY: UNCORRECTED PROOFS GAO (Government Accoun tability Office). 2010. Patient Safety Act: HHS is in the process of implementing the act, so its effectiveness cannot yet be evaluated . Washington, DC: Government Accountability Office. Helmchen, L. A., M. R. Richards, and T. B. McDonald. 20 10. How does routine disclosu re of medical error affect patients' propensity to sue and their assessment of provider quality? Evidence from survey data. Medical Care 48(11):955-961. Hendrich, A., C. K. McCoy, J. Gale, L. Sparkman, and P. Santos. 2014. Ascension health's demonstration of full disclosure protocol for unexpected events during labor and delivery shows promise. Health Affairs 33(1):39-45. HHS (Department of Health and Human Services). 2010. Improper payments for evaluation and management services cost Medicare billions in 2010 . Washington, DC: HHS Offi ce of Inspector General. HHS. 2014. Decision on appropriate me dical malpractice payment reporting. www.citizen.org/documents/2211%20Enc losure.pdf (accessed May 16, 2015). HHS. 2015. Patient safety and quality improvement act of 2005 statute and rule. www.hhs.gov/ocr/privacy/psa/regulation/ (accessed March 29, 2015). Himmelstein, D. U., and S. Woolhandler. ,(2014). Global Amnesia: Embracing Fee-For-Non-Service\u2014Again. Journal of General Iinternal Medicine, 29(5), 693. Hoffman, J. R., & Kanzaria, H. K. (2014). Intolerance of error and culture of bl ame drive medical excess. BMJ, 349, g5702. Howard, P. 2012. The growing bipartisan support for health courts. Health Affairs Blog , October 2. http://healthaffairs.org/ blog/2012/10/02/the-growing- bipartisan-support-for-health -courts/ (accessed June 8, 2015). Howard, P., and R. G. Maine. 2013. Health courts ma y be best cure for what ails the liability system. Bulletin of the American College of Surgeons , March 2. http://bulletin.facs.org/2013 /03/health-courts-best-cure/ (accessed June 8, 2015). IEA (International Ergonomics Association). 2000. The di scipline of ergonomics. www.iea.cc/whats (accessed April 10 2015). Iglehart, J. K. 2009. Health insurers and medical-imaging policy\u2014A work in progress. New England Journal of Medicine 360(10):1030-1037. IOM (Institute of Medicine). 2000. To err is human: Building a safer health system . Washington, DC: National Academy Press. IOM. 2001. Crossing the quality chasm: A new health system for the 21st century . Washington, DC: National Academy Press. IOM. 2002. Fostering rapid advances in health care: Learning from system demonstrations : National Academy Press. IOM. 2008. Retooling for an aging america: Building the health care workforce . Washington, DC: The National Academies Press. IOM. 2012. Health IT and patient safety: Buil ding safer systems for better care . Washington, DC: The National Academies Press. IOM. 2013a. Best care at lower cost: The path to continuously learning health care in America : The National Academies Press. IOM. 2013b. Delivering high-quality cancer care: Charting a new course for a system in crisis . Washington, DC: The National Academies Press. IOM. 2011. Clinical practice guidelines we can trust . Washington, DC: The National Academies Press. Jena, A. B., E. C. Sun, and J. A. Romley. 2013. Mortality among high-risk patients with acute myocardial infarction admitted to U.S. teaching-intens ive hospitals in July: A retros pective observational study. Circulation 128( 25):2754-2763. Joint Commission. 2005. Health care at the crossroads: Strategies for improving the medical liability system and preventing patient injury . The Joint Commission. www.jointcommission.org/assets/1/18/Medical_Liability.pdf (accessed June 8, 2015). Jost, T. 2006. Health courts an d malpractice claims adjudication through Medicare: Some questions. Journal of Health Care Law & Policy 280. Kachalia, A. 2014. Legal issues in diagnostic error. Pr esentation to the Committee on Diagnostic Error in Health Care, August 7, 2014,Washington, DC. Kachalia, A., and M. M. Mello. 2011. New directions in medical liability reform. New England Journal of Medicine 364(16):1564-1572. 7-26 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Kachalia, A. B., M. M. Mello, T. A. Brennan, and D. M. Studdert. 2008. Beyond negligence: Avoidability and medical injury compensation. Social Science and Medicine 66(2):387-402. Kachalia, A., A. Little, M. Isavoran, L. M. Crider, and J. Smith. 2014. Greatest im pact of safe harbor rule may be to improve patient safety, not reduce liability claims paid by physicians. Health Aff (Millwood) 33(1):59-66. Kachalia, A., S. R. Kaufman, R. Boothman, S. Anderson, K. Welch, S. Saint, M. A. Rogers. 2010. Liability claims and costs before and after implementation of a medical error disclosure program. Annals of Internal Medicine 153(4):213-221. Kassirer, J. P., and M. Angell. 1998. Evaluation and management guidelines\u2014Fatally flawed. New England Journal of Medicine 339(23):1697-1698. Kessler, D. P., Summerton, N., & Graham, J. R. (2006). Effects of the medical liability system in Australia, the UK, and the USA. The Lancet, 368(9531), 240-246. Kostis, W. J., K. Demissie, S. W. Marcella, Y. H. Shao, A. C. Wilson, and A. E. Moreyra. 2007. Weekend versus weekday admission and mortality from myocardial infarction. New England Journal of Medicine 356(11):1099-1109. Kroft, S. H. 2014. Statement of Steven H. Kroft, MD, FASCP, American Society for Clinical Pathology (ASCP). Input submitted to the Committee on Diagnostic Error in Health Care, April 28, 2014, Washington, DC. Kuhn, T., P. Basch, M. Barr, and T. Yackel. 2015. Clinical documentation in the 21st century: Executive summary of a policy position paper from the American College of Physicians. Annals of Internal Medicine 162(4):301-303. Lembitz, A., and D. Boyle. 2014. COPIC medical liab ility insurance. Input submitted to the Committee on Diagnostic Error in Health Care, Noevrmber 25, 2014, Washington, DC. Localio, A. R., A. G. Lawthers, T. A. Brennan, N. M. Lair d, L. E. Hebert, L. M. Peterson, J. P. Newhouse, P. C. Weiler, and H. H. Hiatt. 1991. Relation between malpr actice claims and adverse events due to negligence. New England Journal of Medicine 325(4):245-251. Lopez, L., J. S. Weissman, E. C. Schneider, S. N. Weingart, A. P. Cohen, and A. M. Epstein. 2009. Disclosure of hospital adverse events and its association with patients' ratings of the quality of care. Archives of Internal Medicine 169(20):1888-1894. Mastroianni, A. C., M. M. Mello, S. Sommer, M. Hardy, and T. H. Gallagh er. 2010. The flaws in state \"apology\" and \"disclosure\" laws dilute their in tended impact on malpractice suits. Health Affairs 29(9):1611-1619. MedPAC. 2014. Physician and other health professional payment systems. www.medpac.gov/-documents-/payment- basics/page/2/ (accessed March 17, 2015). Mello, M. M., and T. H. Gallagher. 2010. Malpractice reform\u2014Opportunities for leadership by health care institutions and liability insurers. New England Journal of Medicine 362(15):1353-1356. Mello, M. M., D. M. Studdert, A. B. Kachalia, and T. A. Brennan. 2006. \"Health courts\" and accountability for patient safety. Milbank Quarterly 84(3):459-492. Mello M., Chandra A, Gawande A. and Studdert D,. 2010. National Costs Of The Medical Liability System . Health Affairs, 29(9):1569-1577. Mello, M. M., A. Kachalia, and D. Studdert. 2011. Administrative compensation for me dical injuries: Lessons from three foreign systems. Commonwealth Fund. Mello, M. M., R. C. Boothman, T. McDonald, J. Driver, A. Lembitz, D. Bouwmeester, B. Dunlap, and T. Gallagher. 2014a. Communication-and-resolution programs: The challenges and lessons learned from six early adopters. Health Affairs 33(1):20-29. Mello, M. M., D. M. Studdert, and A. Kachalia. 2014b. The medical liability climate and prospects for reform. JAMA 312(20):2146-2155. MHA PSO (Michigan Health Hospital Association Patient Safety Organization). 2015. Safe tables. www.mhapso.org/safetables/ (accessed April 10, 2015). Miller, H. D. 2014. How healthcare pa yment systems and benefit designs can support more accurate diagnosis. Input submitted to the Committee on Diagnostic Error in Health Care, December 29 , 2014, Washington, DC. National Commission on Physician Payment Reform. 2013. Report of the National Commission on Physician Payment Reform . http://physicianpaymentcommission.or g/report/ (access e d March 17, 2015). National Patient Safety Foundation, Lucian Leape Institu te. 2015. Shining a Light: Safer Health Care Through Transparency. http://c.ymcdn. com/sites/www.npsf.org/resour ce/resmgr/LLI/Shining-a- Light_Transparency.pdf (accessed July 24, 2015). Newman-Toker, D. E., K. M. McDonald, and D. O. Meltzer. 2013. How much diagnostic safety can we afford, and how should we decide? A health economics perspective. BMJ Quality and Safety 22(Suppl 2):ii11-ii20. Nicoletti, B. 2005. How to document and bill care plan oversight. Family Practice Management 12(5):23-25. THE EXTERNAL ENVIRONMENT INFLUENCING DIAGNOSIS 7-27 PREPUBLICATION COPY: UNCORRECTED PROOFS ONC (Office of the National Coordinator for Health Information Technology). 2014. Health information technology adverse event reporting: Analysis of two databases. Washington, DC: The Office of the National Coordinator for Health Information Technology. Parikh, P. D. 2014. PIAA medical liability insurance. In put submitted to the Committee on Diagnostic Error in Health Care, February 25, 2014, Washington, DC. Peters, P. G. 2008. Health courts? Boston University Law Review 88:227-289. Rabin, R. C. 2014. 15-minute visits take a toll on the doctor-patient relationship. Kasier Health News , April 21. http://khn.org /news/15-minute-doctor-visits / (accessed June 8, 2015). Robeznieks, A. 2014. Malpractice claims can be kept out of court, but not the NPDB. Modern Healthcare, August 13.www.modernhealthcare.com/article/20140813/NEWS/308139939 (accessed June 8, 2015) . Rosenthal, M. 2014. Comments to the Institute of Medicine. Input submitted to the Committee on Diagnostic Error in Health Care, December 29, 2014, Washington, DC. Sage, W. M., T. H. Gallagher, S. Armstrong, J. S. Cohn, T. McDonald, J. Gale, A. C. Woodward, and M. M. Mello. 2014. How policy makers can smooth the way for communication-and-resolution programs. Health Affairs 33(1):11-19. Sarkar, U., D. Bonacum, W. Strull, C. Spitzmueller, N. Jin, A. Lopez, T. D. Giardina, A. N. Meyer, and H. Singh. 2012. Challenges of making a diagnosis in the outpa tient setting: A multi-site survey of primary care physicians. BMJ Quality and Safety 21(8):641-648. Sarkar, U., B. Simchowitz, D. Bonacum, W. Strull, A. Lo pez, L. Rotteau, and K. G. Shojania. 2014. A qualitative analysis of physician perspectives on missed and delayed outpatient diagnosis: The focus on system-related factors. Joint Commission Journal on Quality and Patient Safety 40(10):461-470. Schiff, G., Griswold, P., Ellis, B. R., P uopolo, A. L., Brede, N., Nieva, H. R ., ... & Biondolillo, M. 2014. Doing right by our patients when things go wrong in the ambulatory setting. Joint Commission Journal on Quality and Patient Safety/Joint Commission Resources, 40(2), 91-96. Schiff, G. D., and D. W. Bates. 2010. Can electronic clinical documentation help prevent diagnostic errors? New England Journal of Medicine 362(12):1066-1069. Schiff, G. D., O. Hasan, S. Kim, R. Abrams, K. Cosby, B. L. Lambert, A. S. Elstein, S. Hasler, M. L. Kabongo, N. Krosnjar, R. Odwazny, M. F. Wisniewski, and R. A. McNutt. 2009. Diagnostic error in medicine: Analysis of 583 physician-reported errors. Archives of Internal Medicine 169(20):1881-1887. Schneider, E. C., P. S. Hu ssey, and C. Schnyer. 2011. Payment reform: Analysis of models and performance measurement implications. Santa Monica, CA: RAND Corporation. Singh, H., T. D. Giardina, A. N. Meyer, S. N. Forjuoh, M. D. Reis, and E. J. Thomas. 2013. Types and origins of diagnostic errors in primary care settings. JAMA Internal Medicine 173(6):418-425. Society to Improve Diagnosis in Medicine (SIDM), 2015. $200K Breakthrough Grant Elevates Diagnostic Training.. http://www.improvediagnosis.org/blogpost/950784/221522/200K-Breakthrough-Grant-Elevates- Diagnostic-Training (acces sed July 22, 2015). Tehrani, A., H. Lee, S. Mathews, A. Shore, M. Ma kary, P. Pronovost, and D. Newman-Toker. 2013. 25-year summary of U.S. malpractice clai ms for diagnostic errors, 1986-2010: An analysis from the National Practitioner Data Bank. BMJ Quality and Safety 22:672-680. Texas Medical Association. 2013. Coding for telephon e consultations. www.texmed.org/template.aspx?id=5422 (accessed April 10, 2015). TDCF (The Doctors Company Foundation), 2015. Grants awarded. http://www.tdcfoundation. com/Grants/index.htm (accessed July 22, 2015). Timm, N. T. 2010. From damages caps to health courts: Continuing progress in medical malpractice reform. Michigan State Law Review 2010:1211-1236. Troxel, D. 2014. The Doctors Company. Input submitted to the Committee on Diagnostic Error in Health Care, April 28, 2014,Washington, DC. U.S. Congress, Office of Technology Assessment, Defens ive Medicine and Medical Malpractice, OTA-H--6O2 (Washington, DC: U.S. Government Printing Office, July 1994). Wennb erg , D. 2014. Comments for the Institute of Medicine 's Committee on Diagnostic Error in Health Care. Input submitted to the Committee on Diagnostic Error in Health Care, December 29, 2014,Washington, DC. WHO (World Health Organization). 2005. WHO draft guidelines for adverse event reporting and learning systems . Geneva, Switzerland: World Health Organization. WSHA (Washington State Hospital Association). 2014. WS HA safe tables and webcasts. www.wsha.org/0518.cfm (accessed April 10, 2015). 8-1 PREPUBLICATION COPY: UNCORRECTED PROOFS 8 A Research Agenda for the Diagnostic Process and Diagnostic Error Progress toward improving diagnosis and redu cing diagnostic error will be significantly hampered without a dedicated fo cus on research. A primary reason that diagnostic errors have remained an underappreciated quality challenge is the lack of information specifying the full extent of the problem. To underscore the importa nce of this issue, the committee sought to identify or construct an estimate of the frequenc y of diagnostic errors. A ll of the research the committee reviewed indicated that diagnostic erro rs are a significant a nd pervasive challenge, but the available research estimates were inadeq uate to establish a prec ise understanding of the incidence and nature of diagnostic errors in clinical practice today. Absent this quantification, other issues in health car e quality and safety have overshadowed diagnostic errors. And while the issue of diagnostic e rror has been gaining momentum in areas of patient safety and quali ty improvement efforts, the relative lack of attention has resulted in substa ntial gaps in what is known about the diagnostic process and diagnostic error in health care today. These know ledge limitations affect not only the field of diagnosis, but also the broader research enterp rise. A substantial body of research relies on\u2014and in some cases assumes that\u2014diagnoses are correct. In research studies evaluating interventions, for example, incorrect diagnoses threaten the validity of the study outcomes and conclusions. An improved understanding of diagnos is and diagnostic error has th e potential to inform and improve all areas of health research. Thus, the committee concluded that that ther e is an urgent need for research on the diagnostic process and diagnostic errors. Previous chapters have highlighted the challenges to diagnosis that arise from specific elements of the health care work system. The lack of research on the diagnostic process and diagnostic error is an overarching challenge th at affects all aspects of the diagnostic process and all elements within the work system. This chapter outlines the impediments to research on the di agnostic process and diagnostic error. The committee calls for a coordinated federal research agenda, co mmitted funding, and significant public-private collaborations to enhance research in this critical area. A FEDERAL RESEARCH AGENDA The diagnostic process and the ch allenge of diagnostic errors have been neglected within the national health care research agenda (Berenson et al., 2014; Wachter, 2010; Zwaan et al., 2013). Input provided to the committee concluded that \"although correct treatment presumes a correct diagnosis, federal resources devoted to diagnostic research are vastly eclipsed by those devoted to treatment\" (Newman-Toker, 2014, p. 12). There are a number of reasons why diagnosis and diagnostic errors ma y be underrepresented in current research activities, including 8-2 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS the dearth of sources of valid and reliable da ta for measuring diagnos tic error, a lack of awareness of the problem, the perceived inevita bility of the problem, the poor understanding of the characteristics of the diagnostic and clini cal reasoning processes, a lack of applicable performance measures on diagnosis, and the need for financial and other re sources to address the problem (Berenson et al ., 2014; Croskerry, 2012). A major barrier to research on diagnosis a nd diagnostic error is the disease-focused approach to medical research f unding. For example, the National Institutes of Health's (NIH's) structure and funding mechanisms are often organized by disease or organ systems, which facilitates the study of th ese specific areas but im pedes research efforts th at seek to provide a more comprehensive understanding of diagnosis as a distinct research area. Newman-Toker (2014, p. 12) asserted that diagnostic research \"invariably fall s between rather than within individual Institute missions.\" As such, the topic of diagnosis, which cuts across all diseases and body parts, is not centralized within the NIH re search portfolio, and av ailable research funding for diagnosis often targets the diagnosis of speci fic diseases, but not diagnosis as a whole, the diagnosis of several diseases with similar presentations, or the diagnostic process itself. Diagnosis and diagnostic error are not a focus of federal health services research efforts, with the exception of two special emphasis notices from the Agency for Healthcare Research and Quality (AHRQ) for diagnostic error whic h were published in 2007 and 2013 (AHRQ, 2007, 2013). In 2015, AHRQ posted an R01 grant oppo rtunity for \"understanding and improving diagnostic safety in ambulatory care: incidence and contributing factors\" (AHRQ, 2015a) and an R18 grant opportunity on identify ing strategies and interventions to improve diagnostic safety in ambulatory care (AHRQ, 2015b). Although these initial steps are promising, the av ailable funding for research into diagnostic error is not in alignment with the scope of th e problem or with the resources necessary to improve diagnosis. The committee concluded that there is an urgent need for dedicated, coordinated federal funding for research on diagnosis and diagnostic error. Thus, the committee recommends that federal agencies, including the Department of Health and Human Services (HHS), the U.S. Department of Ve terans Affairs (VA), and the United States Department of Defense (DOD), should develop a coordinated research agenda on the diagnostic process and diagnos tic errors by the end of 2016. Within HHS there are a number of agencies with the diagnostic process and diag nostic errors within th eir purview, including the National Institutes of Health, AHRQ, the Center s for Disease Control and Prevention, and the Centers for Medicare & Medica id Services. The VA and DOD should also be engaged in developing this research agenda. An example of cross-governmental collaboration is the joint effort by AHRQ and the National Science Founda tion to evaluate how industrial and systems engineering contribute to bette r health care delivery. Following a workshop that outlined a research agenda, these agencies released a joint grant solicitation to fill the gaps identified during the course of the workshop (Valdez, 2010). Given the potential for federal research in diagnosis and diagnostic error to fall between institutional missions, federal agencies need to collaborate to develop a coordinated national research agenda that addresses diagnosis and diagnostic error. Because of the urgent need for research in these areas, federal agencies shou ld commit dedicated funding to implementing this research agenda. Because overall federal investment in biomedical and health services research is declining (Moses et al., 2015), the committee recognizes that funding for diagnosis and diagnostic error will likely dr aw resources away from other important priorities. However, given the consistent lack of resources for research on diagnosis, and the potential for diagnostic A RESEARCH AGENDA 8-3 PREPUBLICATION COPY: UNCORRECTED PROOFS errors to contribute to significant patient harm, the committee concluded that this prioritization is necessary in order to achieve broader improvement s in the quality and sa fety of health care. Furthermore, because much of health care (both in research and in clin ical practice) relies on correct diagnoses, research in this area is likely to enhance the effectiveness of ot her efforts (e.g., those focused on treatment and management), and it could also potentially lead to cost savings by preventing diagnostic errors, inappropriate treatment, and related adverse events. PUBLIC-PRIVATE COLLABORATION ON RESEARCH In addition to federal-level research on di agnosis and diagnostic errors, there is an important role for public-private collaboration and coordination among the federal government, foundations, industry, and other or ganizations. Collaborative f unding efforts help extend the existing financial resources and re duce duplications in research e fforts. Interested parties can unite around areas of mutual in terest and spearhead progress. Foundations, industry, and other stakeholders can make important contributions\u2014financially and w ithin their areas of expertise\u2014 to enhance knowledge in this area. Thus, the committee recommends that the federal government should pursue and encourage opportunities for public-private partnerships among a broad range of stakeholders, such as the Patient-Centered Outcomes Research Institute (PCORI), foundations, the diagnostic testing and health IT industries, health care organizations, and professional liability insurers to support research on the diagnostic process and diagnostic errors. The scientific literature includes descriptions of various types of collaborative models that have been employed to share information, res ources, and capabilities (A ltshuler et al., 2010; Portilla and Alving, 2010). Organiza tions like Grantmakers in Hea lth coordinate corporate and foundation funding efforts to improve health a nd health care delivery (GIH, 2015). An example of a public-private partnershi p that could be leveraged is the National Center for Interprofessional Practice and Educ ation, which takes a cross-cutti ng view of health systems and health care professional education (NCIPE, 2015). Another example is the Centers for Medicare & Medicaid Services (CMS) Innovation Center's Health Care Payment Learning and Action Network, launched in the spring of 2015 (CMS, 2015). This model will support HHS's efforts to move from paying for volume to paying for the va lue of services provid ed (Burwell, 2015). As a part of this effort, organizations can collaborate to generate evidence. In line with Recommendation 7b from the previous chapter, this could include generating evidence about how new payment models influence the diagnost ic process and the o ccurrence of diagnostic errors. Zwaan and colleagues (2013) outlined potential research opportunities broadly which were classified into three areas: th e epidemiology of diagnos tic errors, the causes of diagnostic error, and error prevention strategies. The Society to Improve Diagnosis in Medicine has formed a research committee to bring together multidisciplinary perspectives in order to advance a research agenda that seeks to address critical gaps in the evidence base (SIDM, 2015). Building on this work, the committee identified additional areas of research that could help shape a national research agenda on diagnosis and diagnostic error (see Box 8-1). This list is not exhaustive\u2014instead, it is meant to highlight some of the issues that were raised during committee discussions. The committee concluded th at it was not feasible to prioritize specific research areas in diagnosis and diagnostic error; such prioritization will re quire additional time and effort beyond the scope of the study. 8-4 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Because this has been an underemphasized area in research and health care delivery, there are many promising avenues for research. Chap ter 3 describes the committee's proposed five purposes of measurement; research in each of th ese areas could be very helpful. Additional research could better define the scope of the problem, identify vulnerabilities in the diagnostic process, describe the work system factors that contribute to e rrors, and evaluate interventions. Further measurement research could advance e fforts to assess diagnostic performance in education and training environments and could consider issues related to measurement for accountability. An important area of research will be the economi c impact of diagnostic errors. Today, there is limited information about the economic consequences of diagnostic errors for patients and their families, for health care orga nizations, and for the country as a whole. As discussed in Chapter 4, it is also critical to carry out more research on teamwork in the diagnostic process, patient engagement, and heal th care professional education. There has been limited research done on teamwork in the diagnos tic process, and future research efforts could help identify best practices to facilitate and support such teamwork. Furthermore, diagnostic research that includes patient and family pers pectives will be critical to increasing the effectiveness of interventions, since patient actions are often needed to achieve correct diagnoses, especially in outpatient settings (Gandh i et al., 2006). To better enable patient and family engagement in the diagnostic process, fu rther research could al so elaborate on methods and tools that effectively engage patients and their families as true partners. In the area of health care professional education, rese arch on methods to assess diagnostic competencies among health care professionals and best practices for developing clinical reasoning and other competencies essential to the di agnostic process is warranted. Chapter 5 describes the use of health inform ation technology (health IT ) in the diagnostic process. A major area of research is understandi ng how to effectively leverage health IT to support all diagnostic team members in the diagnos tic process, especially in supporting clinical reasoning tasks. For example, diagnostic decisi on support tools are still relatively early in development, and a better understanding of the performance of these tools in clinical practice is needed. In addition, research that identifies the potential advers e effects of health IT on the diagnostic process can be helpful to ensure the safe design, implementation, and use of health IT. Given the growth of mHealth applications and wearable technologies, research could also provide information on how these can be effectiv ely incorporated in th e diagnostic process. In Chapter 6, the committee calls on health care organizations to begin monitoring the diagnostic process and identify, learn from, and re duce diagnostic errors in clinical practice. Since there has been limited measurement of this information in clinical practice, health care organizations will need to experiment and assess which approaches are effective for monitoring the diagnostic process and identifying, anal yzing, and reducing dia gnostic errors. Further research on developing systematic feedback mech anisms on diagnostic performance and research on best practices for the delivery of this feedback to individuals, care teams, and leadership will also be necessary. Research can also inform the design of a health care organization's work system so that it supports the work a nd activities of the diagnostic process. Chapter 7 describes how voluntary reporting, medical liabil ity, and payment and care delivery can influence the diagnostic process. Ther e are several topics that deserve research in this area, including demonstration projects to ev aluate how alternative approaches to medical liability\u2014such as administrative h ealth courts and safe harbors fo r adherence to clinical practice guidelines\u2014influence the occurrence and disclosure of diagnostic errors and also influence the analysis of and learning from these errors. As m entioned previously, ther e is also a need to A RESEARCH AGENDA 8-5 PREPUBLICATION COPY: UNCORRECTED PROOFS understand how payment and care delivery influen ce the diagnostic process, diagnostic errors, and learning. Achieving progress in reducing diagnostic erro rs and improving diagnosis will require an emphasis on collaboration. Collabora tive research in diagnosis and diagnostic error will require the involvement of multiple disciplines, and it will benefit from the use of multiple and mixed methods (Creswell et al., 2011). For instance, qu alitative approaches su ch as cognitive work analyses of the human factors/ergonomics discip line could provide in-depth information on the types of diagnostic errors identi fied by health services research ers (Bisantz and Roth, 2007). This type of multidisciplinary mixed-methods research can provide the type of information that is needed to further quantify and understa nd the nature of diagnostic errors. BOX 8-1 Potential Areas of Research Patient and Family Engagement and the Diagnostic Process Effective strategies for partnering with patients in the diagnostic process; approaches for reaching diverse population groups, including those who are diverse in language, culture, and individual values, preferences, and needs. Development of patient-focused educational resources and shared decision-making tools/strategies in the diagnostic process. Patient-centered priorities in reducing diagnostic errors. Identification of multiple perspectives to better understand and mitigate diagnostic error (including the patient, family, primary care clinicians, specialists, other health care professionals, organizational leaders, risk management perspectives, and others). The impact of patient variables on the diagnostic process and outcomes. Disparities in timely and accurate diagnosis and on the populations at highest risk, including those with health literacy limi tations, socioeconomic disadvantages, limited English proficiency, and racial/ethnic minority populations. Health Care Professional Education and Training How health care professional schools currently train and evaluate students for diagnosticcompetency. Effective practices to teach and evaluate clinical reasoning. The use of simulation training to improve diagnostic performance. Etiology of cognitive errors (inadequate knowledge and shortcomings in cognitiveprocesses). Components of intra- and interprofessional training that improve the diagnostic process. Health Information Technology (Health IT) Understand how health IT can be better leveraged to support the identification ofdiagnostic errors by analyzing large quantities of data to find trends, patterns, and anomalies that would not be visible otherwise. Development of strategies for the identification and remediation of health IT functionalityand usability issues affecting diagnosis (diffi culties navigating, seeing, understanding, or interacting with user interfaces/displays). Investigation of how health IT can be leveraged to narrow the gap between patients' actual health literacy level and that required to navigate the diagnostic process. Examination of the impact of computer-assisted diagnosis technology on diagnostic8-6 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS accuracy in medical imaging. Evaluation of the relation ship between t he amount of clinical context provi ded by diagnostic t est orders a nd diagnostic error. Development of health IT tools to efficiently extract information from the electronic hea lth record that is relevant to an individu al patient's specific diseases and cond itions, allowing the clinicians to expend more of their efforts on test interpretation and integration o f the results to provide a personalized diagnosis. Potential for artificial intelligence, big data, and analytics appr oaches to improve the diagnostic p rocess and identify diagnostic errors and near misses. Identification, Analysis, and Reduction of Diagnostic Errors National studies/surveys of health care organizations to docum ent: Current approaches and progress in the identification of diag nostic errors. Evidence to improve diagnosis and reduce diagnostic errors. The relationship between diagnostic variance and patient out comes. A national effort to capture diagnostic delays and errors could be considered as a pa rt of ongoing surveillance through the National Center for Health Statistics, such as the National Ambulatory Medical Care Survey and National Hospital Ambulatory MedicalCare Survey. Longitudinal analysis of diagnostic errors to determine when improvement efforts are succeedin g. Disease-specific analyses of diagnostic errors an d near misses Development of tools and methods that can identify diagnostic errors in practice. oThe necessary structures (Are the right tools in place to incr ease the likelihood of accurate an d timely diagnoses?), pr ocesses (Are the appropriate steps undertaken t o ensure that a diagnosis is accurate and timely?) and patie nt outcomes (Are both clin ical outcomes and patie nt-reported outcomes about how the diagnost ic error affected them noted?). oVariations research (similar to geographic variations research to identif y variability of diagnostic a ccuracy across regions, organization s, health care professionals, setting s of care, etc.). oThe specific elements of diagnostic error associated with different setting s of care (includ ing inpatient, outpatient, extended care, home, and communi ty settings). oMethods to assess the diagnostic pe rformance of diagnostic team members. oAssessment of the elements of organizational culture that promote improv ed diagnostic p erformance. oEffective and cost-effective approaches for identifying diagnostic errors. oIdentify priority conditions for which known approaches to im prove diagnostic accuracy an d timeliness would have high impact. oMitigation of potential adverse consequences related to assessing diagno stic errors. oIdentification of tools that can measure interventions. Work System Improvements Research o n the work system factors that contribute to poor diagnostic performance, diagnostic e rrors, and near misses in current practice. Research exploring the generalizability of findings on teamwork, culture, leadership, and education fr om other disciplines and from broader health care quality and patient safety settings to t he diagnostic process.A RESEARCH AGENDA 8-7 PREPUBLICATION COPY: UNCORRECTED PROOFS Identification of cultural and other organizational characteristics of health care organizations that improve diagnosis and reduce diagnostic errors. Interventions that redesign the work system and assess their effects on diagnosis. External Environment Impact of payment, care delivery model s, and coding practices on the diagnostic process and the accuracy of diagnosis. Economic consequences of diagnostic errors for patients and their families, health care organizations, and nationally. Mechanisms to improve voluntary reporting. Alternative approaches to medical liability to improve disclosure, learning, and theprevention of diagnostic errors. RECOMMENDATION Goal 8: Provide dedicated funding for researc h on the diagnostic process and diagnostic errors Recommendation 8a: Federal agencies, in cluding HHS, VA, and DOD, should: Develop a coordinated research agenda on the diagnostic process and diagnostic errors by the end of 2016. Commit dedicated funding to implementing this research agenda. Recommendation 8b: The federal government sh ould pursue and encourage opportunities for public-private partnerships among a broad range of stakeholders, such as PCORI, foundations, the diagnostic testing and health IT industries, health care organizations, and professional liability insurers to support res earch on the diagnostic process and diagnostic errors. REFERENCES AHRQ (Agency for Healthcare Research and Quality). 2007. Special emphasis notice (SEN): AHRQ announces interest in research on diagnostic errors in ambulatory care settings. http://grants.nih.gov/gr ants/guide/notice-files/NOT-HS-08-002.html ( accessed May 5, 2015). AHRQ. 2013. AHRQ announces interest in research to improve diagnostic performance in ambulatory care settings. http://grants.nih.gov/gran ts/guide/notice-files/NOT -HS-13-009.html (accessed February 4, 2015). AHRQ. 2015a. Understanding and improving diagnostic safety in ambulatory care: Incidence and contributing factors (R01). http://grants.nih.gov/grants/g uide/pa-files/PA-15-180.ht ml (accessed May 3, 2015). AHRQ. 2015b. Understanding and improving diagnostic safety in ambulatory and interventions (R18). http://grants.nih.gov/gr ants/guide/pa-files/ PA-15-179.html S., E. Balogh, A. D. Barker, S. L. Eck, S. H. Friend, G. S. Ginsburg, R. S. Herbst, S. J. Nass, C. M. Streeter, and J. A. Wagner. 2010. Open ing up to precompetitive collaboration. Science Translational Medicine 2(52):52cm26. Berenson, R. A., D. K. Upadhyay, and D. R. Kaye. 2014. Placing diagnosis errors on the policy agenda. Timely Analysis of Immediate Health Policy Issues, April. Washington, DC: Urban Institute. http://www.urban.org/sites/default/files/alfresco/publication-pdfs/413104-Placing-Diagnosis-Errors-on-the-Policy-Agenda-brief.pdf (accessed June 9, 2015). Bisantz, A., and E. Roth. 2007. Analysis of cognitive work. Reviews of Human Factors and Ergonomics 3(1):1-43. Burwell, S. M. 2015. Setting value-based payment goals\u2014HHS efforts to improve U.S. Health care. New England Journal of Medicine 372(10):897-899. 8-8 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS CMS (Centers for Medicare & Medicaid Services). 2015. Health care payment learning and action network. http://innovation.cms.gov/in itiatives/Health-Care-Paymen t-Learning-and-Action-Network/ (accessed May 5, 2015). Creswell, J. W., A. C. Klassen, V. L. Plano-Clark, and K. C. Smith. 2011. Best practices for mixed methods research in the health sciences. Office of Behavioral and Social Sciences Research. http://obssr.od.nih.gov/mixed_methods _research/ (accessed May 27, 2015). Croskerry, P. 2012. Perspectives on diagnostic failure and patient safety. Healthcare Quarterly 15(Special issue):50-56. Gandhi, T. K., A. Kachalia, E. J. Thomas, A. L. Puopolo, C. Yoon, T. A. Brennan, and D. M. Studdert. 2006. Missed and delayed diagnoses in the ambulatory setting: A study of closed malpractice claims. Annals of Internal Medicine 145(7):488-496. GIH (Grantmakers in Health). 2015. Grantmakers in Health. www .gih.org (accesse d May 26, 2015). Moses, H., 3rd, D. H. Matheson, S. Cairns-Smith, B. P. George, C. Palisch, and E. R. Dorsey. 2015. The anatomy of medical research: U.S. and international comparisons. JAMA 313(2):174-189. NCIPE (National Center for Interprofe ssional Practice and Education). 2015. National Center for Interprofessional Practice and Education. https://nexusipe.org/ (accessed May 27, 2015). Newman-Toker, D. 2014. Prioritization of diagnostic erro r problems and solutions: Concepts, economic modeling, and action plan. Presentation to the Committee on Diagnostic Error in Health Care, August 7, 2014, Washington, DC. Portilla, L. M., and B. Alving. 2010. Reaping the benef its of biomedical research: Partnerships required. Science Translational Medicine 2(35):35cm17. SIDM (Society to Improve Diagnosis in Medicine). 2015. Diagnostic error resources. www.improvediagnosis.org/?page=Saf etyToolkit (accessed March 15, 2015). Valdez, R. S. 2010. Industrial and systems engineering and health care: Critical areas of research\u2014Final report . Rockville, MD: Agency for Healthcare Research and Quality. Wachter, R. M. 2010. Why diagnostic errors don't get any respect\u2014and what can be done about them. Health Affairs (Millwood) 29(9):1605-1610. Zwaan, L., G. D. Schiff, and H. Singh. 2013. Advancing the research agenda for diagnostic error reduction. BMJ Quality & Safety 22(Suppl 2):ii52-ii57. 9-1 PREPUBLICATION COPY: UNCORRECTED PROOFS 9 The Path to Improve Diagnosis and Reduce Diagnostic Error Illuminating the blind spot of diagnostic erro r and improving diagnosis in health care will require a significant re-envisioni ng of the diagnostic process and widespread commitment to change. Diagnostic error is a complex and multif aceted problem; there is no single solution that is likely to achieve the changes that are need ed. To address this challenge and to improve diagnosis for patients and their families, the committee makes eight recommendations. This chapter highlights the overarchi ng conclusions from the committee' s deliberations and presents these recommendations. OVERARCHING CONCLUSIONS Several major conclusions emerged from the committee's discussions. The first conclusion is that urgent change is needed to ad dress the issue of diagnos tic error, which poses a major challenge to health care quality. Diagnostic errors persist throughout all settings of care, involve common and rare diseases, and continue to harm an unacceptable number of patients. Yet, diagnosis\u2014and, in particular, the occurrence of diagnostic errors\u2014is not a major focus in health care practice or research. The result of this inattention is signi ficant: It is likely that most people will experience at least one diagnostic error in their lifetim e, sometimes with devastating consequences. The committee drew this conclusion based on the its collective assessment of the available evidence describing the epidemiology of diagnostic errors . In every research area that the committee evaluated, diagnostic errors were a consistent quality and safety challenge. For example, a recent study estimated that 5 percen t of U.S. adults who seek outpatient care experience a diagnostic error, and the researcher s who conducted the study noted that this is likely a conservative estimate (Singh et al., 2014). Postmortem examination research that spans several decades has consistently shown that diagnostic errors contribute to around 10 percent of patient deaths (Shojania et al., 2002; Shojania et al., 2003). The Harvar d Medical Practice Study, which reviewed medical records, found diagnostic errors in 17 percent of the adverse events occurring in hospitalized patients (Leape et al., 1991), and a more recent study in the Netherlands found that diagnostic errors comprised 6.4 percen t of hospital adverse ev ents (Zwaan et al., 2010). Analyses of malpractice claims data indicate that diagnostic errors ar e the leading type of paid claims, represent the highest proportion of total payments, and are almost twice as likely to have resulted in the patient' s death compared to other cl aims (Tehrani et al., 2013). However, the committee concluded that the available research estimates were not adequate to extrapolate a specifi c estimate or range of the incide nce of diagnostic errors within clinical practice today. There is even less info rmation available with which to assess the 9-2 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS frequency and severity of harm related to diagnostic errors. Part of the challenge is the variety of settings in which these errors can occur, includi ng hospitals, emergency departments, a variety of outpatient settings (such as primar y and specialty care settings a nd retail clinics), and long-term care settings (such as nursing hom es and rehabilitation centers), combined with the complexity of the diagnostic process itself. Although there are more data available to examine diagnostic errors in some of these settings, there are wide ga ps in the information and great variability in the amount and quality of information available. In addition, aggregating data from various research methods\u2014such as postmortem examinations, medical record reviews, and malpractice claims\u2014is problematic. Each method captures information about different subgroups in the population, different dimensions of the problem, and differe nt insights into the frequency and causes of diagnostic error. Nonetheless, the committee co ncluded that, taken together, the evidence suggests that diagnostic errors are a signi ficant and common challe nge in health care necessitating urgent attention. The second conclusion is that it is very impor tant to consider diagnosis from a patient- centered perspective, as patients bear the ultimate risk of harm from diagnostic errors. Thus, patients should be recognized as vital partners in the diagnostic proc ess and the health care system needs to encourage and support their enga gement and to facilita te respectful learning from diagnostic errors. The committee's definition of diagnostic error\u2014 the failure to (a) establish an accurate and timely explanation of the patient's hea lth problem(s) or (b) communicate that explanation to the patient \u2014reflects a patient-centered approach and highlights the key role of communication among the patient and the hea lth care professionals involved in the diagnostic process. The term \"e xplanation\" is included in the definition to highlight the manner in which a diagnosis is conveyed to a patient, such that it facilitates patient understanding and aligns with a pati ent's level of h ealth literacy. The committee concluded that a sole focus on reducing diagnostic errors will not achieve the extensive change that is needed. Reducing diagnostic errors will require a broader focus on improving diagnosis in health care. This conclusion refl ects the input provided to the committee by Gary Klein, a senior scientist at MacroCogni tion, who argued that improvements in diagnosis will require balancing two, interdependent effo rts: reducing diagnosti c errors and improving diagnostic performance (Klein, 2014). Related input from David Newman-Toker, an associate professor at Johns Hopkins University, suggested that improving diagnostic performance will require addressing diagnostic qu ality and efficiency in order to achieve high-value diagnostic performance (Newman-Toker, 2014; Newm an-Toker et al., 2013). Thus, many of the recommendations focus on improving diagnosis and the diagnostic process as well on the identification and mitigation of diagnostic errors. To provide a framework for this dual focus, the committee developed a conceptual model to articulate the diagnostic process, identify the factors that in fluence this process, and identify opportunities to improve the diagno stic process and outcomes. This conceptual model highlights the committee's conclusion that diagnosis is a team -based process that occurs within the context of a broader system. This system involves the dyn amic interaction of the participants in the diagnostic process (which are infl uenced by the participants' cogni tive, perceptual, and affective factors), the tasks that they perform, the technol ogy and tools they utilize, the organization and physical environment in which diagnosis takes place, and the external environmental factors involved, such as oversight pro cesses, error reporting, medical liability, and the payment and care delivery environment. THE PATH TO IMPROVE DIAGNOSIS AN D REDUCE DIAGNOSTIC ERROR 9-3 PREPUBLICATION COPY: UNCORRECTED PROOFS RECOMMENDATIONS The committee's recommendations focus on ach ieving eight goals to improve diagnosis and reduce diagnostic error (see Box 9-1). These r ecommendations are meant to be applicable to all diagnostic team members and settings of care; thus, some of the committee's recommendations are intentionall y broad. Given the early state of the field, the committee also sought to develop recommendations that were no t overly proscriptive. Im portantly, the evidence base for some recommendations stems from the broader patient safety and quality improvement literature. Making connections to previous efforts is important, given the limited focus on diagnosis and its relevance to overall health care quality. Patien ts and patient advocates have much to offer on how to implement the committ ee's recommendations. Leveraging the expertise, power, and influence of the patient community will help spur progress. BOX 9-1 Goals for I mproving Diagnosis and Reducing Diagnostic Error Facilitate more effective teamwork in the diagnostic process among health care professional s, patients, and their fa milies Enhance health care professional education and training in th e diagnostic process Ensure health information technologies that support patients and health care professionals in the diag nostic proces s Develop and deploy approaches to identify, learn from, and reduce diag nostic errors and near misses in clin ical practice Establish a work system and culture that supports the diagnostic process and improve ments in diagno stic performance Develop a reporting environment and medical lia bility system that facilitates improved diagnosis th rough learning from diagnostic errors and near misses Design a payment and care delivery environment that supports the diagnostic proces s Provide dedicated funding for research on the diagnostic process and diagnostic erro rs Facilitate More Effective Teamwo rk in the Diagnostic Process Among Health Care Professionals, Patients, and their Families The diagnostic process is a collaborative ac tivity. Making accurate and timely diagnoses requires teamwork among health care professionals, patients, and their family members. The committee's focus on teamwork in diagnosis grew out of the recognition that too often diagnosis is characterized as a solitary activity, taking place exclusively within an individual physician's mind. While the task of integra ting relevant information and communicating a diagnosis to a patient is often the responsibility of an indi vidual clinician, the di agnostic process ideally involves collaboration among multiple health care professionals, the patient, and the patient's family. Consistent with the committee's conclusion, recent reports in the lite rature make the case that the diagnostic process is team-based endeavor (Graedon and For example, Schiff noted that the new paradigm for diagnosis is that it is carried out by a well-coordinated team of people working together through reliable processes; in this view, diagnosis is the collective work of the team of health care professionals and the pati ent and his or her family (Schiff, 2014a). 9-4 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Patients and their families are critical partne rs in the diagnostic process. The goal of patient engagement in diagnosis is to improve patient care and outcomes by enabling patients and their families to contribute valuable input that will facilitate an accu rate and timely diagnosis and improve shared decision-making about the path of care. There are indi cations, however, that patients and families are not routinely engaged as true partners in the diagnostic process and that they face challenges in engaging in the dia gnostic process (Haskell , 2014; Julavits, 2014; McDonald, 2014). Two of the more significant challenges involve unf amiliarity with the diagnostic process and health car e environments that are not s upportive of patient engagement. The committee identified several opportunities to improve patient and family engagement in the diagnostic process. First, patients and their families could benefit from having a better overall understanding of the dia gnostic process. Learning opport unities that describe what to expect during this process, th e roles of specific diagnostic team members, and materials that facilitate patient and family participation in th e process could all be helpful. For example, the National Patient Safety Foundation, the Society to Improve Diagnos is in Medicine, and Kaiser Permanente have developed resources to help pati ents partner with their clinicians to receive a correct diagnosis (Kaiser Permanente, 2012; NPSF and SIDM, 2014). Health care organizations and health care professionals have the responsibility to create envi ronments that are receptive to and supportive of patient engagement in the diagnostic process. This includes recognizing that patients and their families have varying needs, va lues, and preferences in regard to engagement and being responsive to the desired level of involvement. Furthermore, the health care environments need to encourage patients and fam ilies to share feedback about their experiences with diagnosis and thei r concerns about diagnostic errors and near misses. Although there are limited systematic mechanisms for patients to provide feedback to health care professionals about the accuracy of their dia gnoses, establishing opportunities to provide patient feedback is critical to improving diagnostic performance (Schiff, 2008). This feedback could also become a routine aspect of assess ing patient satisfaction. An important opportunity to improve enga gement is through the use of health information technology (health IT) tools that make a patient's health information more accessible and transparent, including clinical notes and diag nostic testing results. Th e Office of the National Coordinator for Health Information Technology' s Meaningful Use 2 requirements include patient's having access to their electronic health in formation, such as medication lists, diagnostic test results, allergies, and clinical problem lis ts; organizations have begun to employ patient portals in order to provide pati ents with access to this informa tion (Adler-Milstein et al., 2014; Bruno et al., 2014; Furukawa et al., 2014; Heal thIT.gov, 2015). The OpenNotes initiative, which is available to almost 5 million patients, has promoted even greater transparency of a patient's health information by inviting patients to view the notes recorded by health care professionals during the patients' clinical visit. Initiatives li ke OpenNotes may promote patient engagement in the diagnostic process and also serve as a mechanism for patients and thei r families to identify and avert diagnostic errors (Bell et al., 2014; Delbanco et al., 2012; Delbanco et al., 2010). Health care professionals and organizations can also involve patients and their families in organizational learning efforts ai med at analyzing the causes of diagnostic errors and identifying interventions that could improve the diagnostic process. Patients and their families have unique insight into the diagnostic proce ss, their outcomes, and the occurrence of diagnostic errors; thus, their perspectives are critical to improving th e diagnostic process (Etchegaray et al., 2014; Gertler et al., 2014; Weingart et al., 2005). Whe n a diagnosti c error occurs, health care organizations can identify opportuniti es to involve a patient and his or her family in efforts to THE PATH TO IMPROVE DIAGNOSIS AN D REDUCE DIAGNOSTIC ERROR 9-5 PREPUBLICATION COPY: UNCORRECTED PROOFS learn from the error, using mechanisms such as root cause analyses, morbidity and mortality conferences, and patient and family advisory councils (AHRQ, 2014c ; Gertler et al., 2014; Zimmerman and Amori, 2007). In addition to patient engagement, the comm ittee highlighted the ro les of health care professionals in the diagnostic process and the need for improved intra- and interprofessional collaboration. Depending on a patient's health problem, the diagnostic process can involve various types of health care professionals, such as primary care clinicians (physicians, advance practice nurses [APN], physician assistants [PAs]), physicians in a broad range of specialties (including radiology, pathology, an d other disease-focused areas), nurses, technologists, therapists, social workers, pharmacists, and patient navigators. For simplicity, the committee's conceptual model articulates two main types of health care profe ssionals: diagnosticians, or those who make diagnoses, such as physicians, APNs, a nd PAs; and the health care professionals who support the diagnostic process. Inadequate teamwork and comm unication are major contributors to medical errors, including di agnostic errors (Baker et al., 2006; CRICO, 2014; Dingley et al., 2008; Singh et al., 2008). Because a patient's diagnosis can hinge on the successful collaboration among these health care professionals, it is important that all health care professionals are well- prepared and supported to engage in diagnostic teamwork. Recognition that interprofessional education an d training is critical to the delivery of high-quality care has been gaining widespread tr action; however, health care professionals are still not adequately prepared for this team-based practice (IOM, 2014; Patel et al., 2009; Pecukonis et 2008; Schmitt et al., 2011). Oppor tunities for interprofessional training have been slow to materialize because of a host of di fferent issues, including logistical challenges, deep-rooted cultural differences among the health care professions, differences in educational curricula and trajectory, and costs (Macy Foundation and Carnegie Foundation for the Advancement of Teaching, 2010). Furthermore, in tra-professional collaboration can be difficult to achieve in practice, and the way that physicia ns are prepared today may be hindering their ability to engage in teamwork and coopera tion (Hughes and Salas, 2013). For example, the traditional hierarchy among medical students, resi dents, and experienced physicians may prevent the more junior clinicians from speaking up a bout a potential error (S orra et al., 2014). In addition, the roles of some health care prof essionals who participat e in the diagnostic process have been insufficiently recognized in current practice. For example, the fields of pathology and radiology are critic al to diagnosis, but these hea lth care professionals have sometimes been referred to as ancillary services and are not always engaged as full members of the diagnostic team despite thei r significant contributions to di agnosis. Enhanced collaboration has the potential to improve all aspects of the diagnostic testing process, includi ng test ordering, analysis and interpretation, reporting and communicat ing the results, and the subsequent decision making (Allen, 2014; Kroft, 2014; Epner, 2015). One opportunity to better in tegrate these health care professionals into the dia gnostic process is the diagnostic management team model; these integrated teams feature collaboration among pat hologists, radiologists, and the treating health care professionals in order to ensure that the correct diagnostic tests ar e ordered and that the results are correctly interpre ted and acted upon (Govern, 2013). 1 In addition, nurses are often not recognized as collaborators in the diagnostic pr ocess, despite their cr itical roles in ensuring proper communication and care coordination among the health care professionals and between the professionals and the patien t and his or her family, monito ring the patient's condition over time to see if the patient's course of treatment aligns with the working diagnosis, and identifying 1 Personal communication, M. Laposata. August 8, 2014. 9-6 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS and preventing potential diagnosti c errors. Depending on a particul ar patient's needs, many other health care professionals can play key roles in the diagnostic proce ss, and they also need to be engaged to improve diagnosis. Goal 1: Facilitate more effective teamwork in the diagnostic proc ess among health care professionals, patients, and their families Recommendation 1a: In recognition that the di agnostic process is a dynamic team-based activity, health care organizations should ensure that health care professionals have the appropriate knowledge, skills, resources, a nd support to engage in teamwork in the diagnostic process. To accomplish this, they should facilitate and support: Interprofessional and intra-professional teamwork in the diagnostic process. Collaboration among pathologists, radiologists, other diagnosticians, and treating health care professionals to improv e diagnostic testing processes. Recommendation 1b: Health care professional s and organizations should partner with patients and their families as diagnostic te am members and facilitate patient and family engagement in the diagnostic process, aligned with their need s, values, and preferences. To accomplish this, they should: Provide patients with opportunities to learn about the diagnostic process. Create environments in which patients and their families are comfortable engaging in the diagnostic process and sharing feedba ck and concerns about diagnostic errors and near misses. Ensure patient access to electronic health records, including clinical notes and diagnostic testing results, to facilitate pa tient engagement in th e diagnostic process and patient review of health records for accuracy. Identify opportunities to include patients a nd their families in ef forts to improve the diagnostic process by learning from diagnostic errors and near misses. Enhance Health Care Professional Educ ation and Training in the Diagnostic Process Getting the right diagnosis depends on all he alth care professionals receiving appropriate education and training. There are indications, howev er, that health care professionals, including diagnosticians, are not prepared to function op timally in the and training-related challenges include me thods that have not kept pace with advances in the learning sciences 2 and have an insufficient focus on areas critical to the di agnostic process. It was not within the committee's charge to define the specific curriculum for all health care professionals\u2014the content of the curriculum and training will need to be tailored to the needs of specific health care professionals. However, the committee recognized se veral areas that are important to the diagnostic process, such as education and training in clinical reasoning, teamwork, communication, and the use of diagnostic testing and health IT. 2 The learning sciences study how people lear n in order to optimize education and training. THE PATH TO IMPROVE DIAGNOSIS AN D REDUCE DIAGNOSTIC ERROR 9-7 PREPUBLICATION COPY: UNCORRECTED PROOFS Numerous experts in health care professiona l education provided input to the committee; a common theme of this input was that health ca re professional education and training is not adequately preparing individuals to become skilled diagnosticians. One of the criticisms is that current approaches to education do not take a dvantage of advances in the learning sciences, which have found that learners need to develop a deep conceptual unders tanding of their content area and to have opportunities to reflect on their knowledge; furt hermore, educators need to consider factors such as the learning environment, building on prior knowledge, and focusing on learning, in addition to teaching. The lack of feedback\u2014or information on the accuracy of a clinician's diagnosis\u2014in the cu rrent training environment can result in few opportunities to reflect on one's state of knowledge. This can lead to poorly calibrated clinicians, who are unaware of their diagnostic performance and ove rly confident in their diagnoses (Berner and Graber, 2008). In addition, the auth enticity of the learning environm ent can affect the acquisition of diagnostic skills, and a better alignment of traini ng environments with clinical practice can improve the development of diagnostic skills. Fo r example, clinicians often learn from case studies that reflect prototypical cases, but they are faced with the complexities of real patient cases in their clinical practice (Papa, 2014). There are a number of possi ble opportunities to improve th e content of health care professional education and training in the diagnos tic process, include placing a greater emphasis on teamwork and communication with patients , their families, and other health care professionals; providing more training in the ordering of diagnostic testing and in the application of these results to subsequent de cision making; and offering more tr aining in the use of health IT. In addition, current health car e professional education and tr aining underemphasizes clinical reasoning, including critical thinking skills and decision making in the diagnostic process (Brush, 2014; Cate, 2014; Durning, 2014; Richardson, 2014) . Although diagnosticians are trained to make diagnoses, few programs feature explicit tr aining in various aspects of clinical reasoning, such as the dual process theory, heuristics, and biases. This lack of fo cus on clinical reasoning and on understanding the cognitive contributions to decision making represents a major gap in health care professional education for all dia gnostic team members. Among the strategies proposed to improve clinical r easoning education and training are instruction and practice on generating and refining a differential diagnosis, developing an appreciation of how diagnostic errors occur and of the strate gies to mitigate them, engaging in metacognition and debiasing strategies, and fostering intuition and progres sive problem solving (Eva and 2013; Wegwarth et al., 2009). Oversight processes, such as education a nd training program accreditation, licensure, and certification, can help ensure that health care professionals achi eve and maintain competency in the diagnostic process. Many acc reditation organizations alrea dy include skills important for diagnostic performance in their accreditation requ irements, but diagnostic competencies need to be a larger priority within those requiremen ts. Organizations responsible for health care professional licensure and certification can also help ensure that individual health care professionals have achieved and maintain competen cy in the skills essential for diagnosis. For example, the American Board of Medical Specialt ies, which grants board certification in m ore than 150 medical specialties and s ubspecialties, could use its cer tification processes to assess competencies in the diagnostic process in both in itial board certification and in maintenance of certification efforts. 9-8 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Goal 2: Enhance health care professional educ ation and training in the diagnostic process Recommendation 2a: Educators should ensure th at curricula and training programs across the career trajectory: Address performance in the diagnostic proc ess, including areas such as clinical reasoning, teamwork, communication with pa tients, their families, and other health care professionals, appropriate use of diagn ostic tests and the application of these results on subsequent decision making, and use of health IT. Employ educational approaches that are al igned with evidence from the learning sciences. Recommendation 2b: Health care professional certification and accreditation organizations should ensure that health care professionals have and maintain the competencies needed for effective performance in the diagnostic process, including the areas listed above. Ensure Health Information Technologies that Support Patients and Health Care Professionals in the Diagnostic Process Health IT plays a critical ro le in the diagnostic process a nd includes such technologies as electronic health records (EHRs), health information exchanges, laboratory and medical imaging information systems, clinical decision support, patient engagement tools, computerized provider order entry, and medical devices. When health IT tools support the dia gnostic team members and tasks in the diagnostic process and reflect human-centered design principles, health IT has the potential to improve diagnosis and reduce diagnostic errors. For example, health IT can facilitate timely access to information; improve communica tion among health care professionals, patients, and their families; aid in clinical reasoning and decision making; and help provide feedback and follow-up in the diagnostic process (El-Kareh et al., 2013; Schiff and Bates, 2010). Despite this potential, there have been few de monstrations that health IT improved diagnosis in clinical practice. Indeed, many experts are concerned that current health IT tools are not effectively facilitating the diagnostic process and that they may even be c ontributing to diagnostic errors (Basch, 2014; Berenson et 2010; Verghese, 2008). The major challenges of health IT in the di agnostic process include problems with the usefulness and usability of health IT tools, poor integration into clinical workflow, difficulty sharing information among diagnostic team me mbers and settings, limitations in supporting clinical reasoning in the diagnostic process, and a lack of opportunities to measure diagnostic errors through health IT tools. In particular, clinicians have expresse d concern that clinical documentation in EHRs is not promoting high-quali ty diagnosis, but is in stead aimed at meeting billing and legal requirements, forcing clinicia ns to \"focus on ticking boxes rather than on thoughtfully documenting their clin ical thinking\" (Schiff and Ba tes, 2010, p. 1066) (see also Recommendation 7). Collaborati on among health IT vendors, us ers, and the Office of the National Coordinator for Health Information T echnology (ONC) is warranted to ensure that health IT tools are better aligne d with the diagnostic process. Another health IT-related challenge in th e diagnostic process is the lack of interoperability, or the inability for different IT systems and software applications to communicate, exchange data, and use informa tion effectively (Basch, 2014; CHCF, 2014; THE PATH TO AN REDUCE DIAGNOSTIC ERROR 9-9 PREPUBLICATION COPY: UNCORRECTED PROOFS HIMSS, 2014). Because the diagnostic process o ccurs over time and can involve multiple health care professionals across different care settings, the free fl ow of information is critical. In order for health care professionals to develop a comple te picture of a patient' s health problem, it is crucial that all relevant health information is available and easily accessible. However, progress toward achieving health interoperability has been slow (CHCF, 2014). Only 30 percent of clinicians and hospitals are able to exchange clinical data with other clinicians electronically (Adler-Milstein and Jha, 2014). Similarly, a recen t survey of office-based physicians found that while 67 percent were able to view lab results electronically, only 42 percent were able to incorporate lab results into their EHR, and only 31 percent of the physicians exchanged patient clinical summaries with other clinicians (Patel et al., 2013). Challenges to interoperability include the inconsistent and slow adoption of standards, particularly among organizations that are not subject to EHR certificati on programs, as well as a lack of incentives, such as a business model that would generate revenue for health IT vendors via fees associated with transmitting and receiving data (Adler-M ilstein, 2015; CHCF, 2014). Among the federal efforts to improve interoperability are programs to support the development of flexible interoperability sta ndards and meaningful use incentives. Given the importance of interoperability to diagnosis, th e Office of the National Coordinator for Health Information Technology (ONC) can play a critic al role in accelerating progress toward interoperability by ensuring th at health IT vendors meet these requirements by 2018. This recommendation is in line with the recent legislation that repeal ed the sustainable growth rate, which included a provision that declared it a na tional objective to \"achieve widespread exchange of health information through in teroperable certified el ectronic health r ecords (EHR) technology nationwide by December 31, 2018.\"3 Improving interoperability across different he alth care organizations as well as across laboratory and radiology information systems will be critical to improving the diagnostic process. One challenge will be specifying the sc ope of interoperable information. For example, the interface between EHRs a nd laboratory and radiology inform ation systems typically has limited clinical information, and the lack of suffi cient patient information makes it difficult for a pathologist or radiologist to determine whether diagnostic testing is appr opriate or to understand the context for interpreting findings (Epner, 2014; 2015). Another emerging challenge is establishing interoperability between EHRs and patient-facing health IT , including health-related mobile health applications such as those that ke ep track of physical activity and glucose levels (Dehling, 2015; Marceglia, 2015; Otte-Trojel et al., 2014). Patient safety risks in the di agnostic process related to the use of health IT are another important concern, because there is growing recogn ition that the use of h ealth IT can result in adverse events (IOM, 2012; ONC, 2014). Health IT safety risks have been identified in the context of system components (including techno logy, people, workflow, organizational factors, and external environment) that can dynamically in teract and contribute to adverse events (IOM, 2012; Sittig and Singh, 2010). A number of health IT-related patient safety risks may affect the occurrence of diagnostic errors. For example, two areas of increased concern are clinical documentation and the use of the copy/paste func tionality of EHRs. While the use of copy/paste functionality may increas e efficiency by saving time spent retyping or reentering information, it carries with it a number of risks, including re dundancy that contribute s to lengthy notes and cognitive overload and the propagation of inaccura te, outdated, or incomprehensible information (AHIMA, 2014; Kuhn et al., 2015; The Joint Commission, 2015). 3 Medicare Access and CHIP Reauthorization Act of 2015. P.L. 114-10. (April 16, 2015). 9-10 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Unfortunately, contractual provisions, designe d to protect vendors' intellectual property interests and liability from unsaf e use of health IT products end up limiting the free exchange of information about health IT-related patient sa fety risks (IOM, 2012). Sp ecifically, \"some vendors require contract clauses that fo rce [health IT] system purchasers to adopt vendor-defined policies that prevent the disclosure of errors, bugs, de sign flaws, and other [health IT]-software-related hazards\" (Goodman et al., 2011, p. 77). These contra ctual barriers among health IT vendors and users may propagate safety risks and pose significant challenges to the use of data for future patient safety and quality improvement research (IOM, 2012). Thus, the Institute of Medicine (IOM) report Patient Safety and Health IT recommended that \"the Secretary of the Department of Health and Human Services should ensure in sofar as possible that health IT vendors support the free exchange of information about health IT experiences and issues and not prohibit sharing of such information, including details (e.g., scre enshots) relating to patient safety\" (IOM, 2012, p. 7 and 128). The committee endorses this recommendation and adds that the Secretary of Health and Human Services (HHS) should requ ire health IT vendors to permit and support the free exchange of information on users' experien ces with health IT design and implementation that contribute to adverse effects on the diagnos tic process. Health IT users can discuss these patient safety concerns in a ppropriate forums, such as the forthcoming ONC national patient safety center or patient safety organizations (PSOs) (RTI International, 2014; Sittig et al., 2014a). The Agency for Healthcare Research and Quality (AHRQ) ha s developed a common format reporting form for health IT adverse ev ents, and HHS is beginning to evaluate patient safety events related to health IT (ONC, 2014; RTI Intern ational, 2014). Because the safety of health IT is critical for improvements to the diagnostic process, health IT vendors need to proactively monitor th eir products in order to identify potential adverse events, which could contribute to diagnostic erro rs and challenges in the diagnostic process (Carayon et al., 2011). To ensure that these vendors' products ar e unlikely to contribute to diagnostic errors and adverse even ts, independent, routine third-pa rty evaluations of health IT products used in the diagnostic process need to be performed. If health IT products have the potential to contribute to dia gnostic errors or have other a dverse effects on the diagnostic process, health IT vendors have a responsibility to communicate this information to their users in a timely manner. Goal 3: Ensure that health information tech nologies support patients and health care professionals in the diagnostic process Recommendation 3a: Health IT vendors and ONC should work together with users to ensure that health IT used in the diagnostic process demonstrates usability, incorporates human factors knowledge, integrates measurement capability, fits well within clinical workflow, provides clinical decision support, a nd facilitates the timely flow of information among patients and health care professionals involved in the diagnostic process. Recommendation 3b: ONC should require heal th IT vendors to meet standards for interoperability among different health IT systems to support effective, efficient, and structured flow of patient information across care settings to faci litate the diagnostic process by 2018. THE PATH TO IMPROVE DIAGNOSIS AND REDUCE DIAGNOSTIC ERROR 9-11 PREPUBLICATION COPY: UNCORRECTED PROOFS Recommendation 3c: The Secretary of the U.S. Department of Health and Human Services should require health IT vendors to: Routinely submit their products for independent evaluation and notify users about potential adverse effects on the diagnost ic process related to the use of their products. Permit and support the free exchange of information about real-time user experiences with health IT design and implementation that ad versely affect the diagnostic process. Develop and Deploy Approaches to Identify, Learn From, and Reduce Diagnostic Errors and Near Misses in Clinical Practice Diagnostic errors are an understudied and undera ppreciated quality challenge in health care organizations (Graber, 2005; Wachter, 2010). Very few health care organizations have focused on the identification of diagnostic errors and near misses in clinical prac tice (Graber et al., 2014; Kanter, 2014; Singh, 2014; 2014). In a presentation to the committee, Paul Epner reported that the Society to Improve Diagnosis in Medicine \"know[s] of no effort initiated in any health system to routinely and effectively a ssess diagnostic performance\" (Epner, 2014). Thus, \"the true prevalence of diagnostic error is unknown\" (Singh et al., 2008, p. 489). The paucity of attention on diagnostic errors in clinical practice has been attributed to a number of factors. Two major contributors are the lack of effective measurement of diagnostic error and the difficulty in detecting these errors in clinical practice (Berenson et al ., 2014; Graber et al., 2012; Singh and Sittig, 2015). Additional f actors may include a health care or ganization's competing priorities in patient safety and quality improvement, the percep tion that diagnostic errors are inevitable or that they are too difficult to a ddress, and the lack of financial resources to address this problem (Croskerry, 2003; Graber, 2005; Graber et al., 2014; Henrik sen, 2014; Singh and Sittig, 2015). These challenges make it difficult to identify, an alyze, and learn from diagnostic errors in clinical practice. Compared to diagnostic errors , other types of medical erro rs\u2014including medication errors, surgical errors, and health care-acquired infectio ns\u2014have historically received more attention within health care organizations (Graber et al., 2 014; Kanter, 2014). This is partly attributable to the lack of focus on diagnostic errors within national patient safety and quality improvement efforts. For example, the Agency for Healthcare Research and Quality's Patient Safety Indicators and the Joint Commission's list of specific sentinel events do not focu s on diagnostic errors (Schiff et al., 2005; Joint Commission, 2014). Th e National Quality Forum's Serious Reportable Events include 29 endorsed events, but only one of those is closely tied to diagnostic error: \"Patient death or serious injury resulting from a failure to fo llow up or communicate laboratory, pathology, or radiology test results\" (National Quality Forum, 2011, p. 10). The neglect of diagnostic performance measures for accountability purposes means that hospitals today could meet standards for high-quality care and be re warded through public reporting and pay-for- performance initiatives even if they have majo r challenges with diagnostic accuracy (Wachter, 2010). Identifying diagnostic errors with in clinical practice is critic al to improving the quality of diagnosis for patients; however, measurement ha s become an \"unavoidable obstacle to progress\" (Singh, 2013, p. 789). The lack of comprehensive information on diagnostic errors within clinical practice perpetuates the belief that these errors are uncommon or unavoidable and 9-12 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS impedes progress on reducing diagnostic errors . Improving diagnosis will likely require a concerted effort among all health care organiza tions and across all set tings of care to better identify diagnostic errors and near misses, to learn from them, a nd, ultimately, to take steps to improve the diagnostic process. In addition to identifying near misses and errors, health care organizations can also benefit from evaluati ng factors that are c ontributing to improved diagnostic performance. Given the nascent field of measurement of th e diagnostic process, bottom-up experimentation will be necessary to develop approaches for monitoring the diagnostic process and identifying diagnostic errors and near misses. It is unlikely that any one specific method will be successful at identifying all diagnostic errors and near misses; some approaches may be more appropriate than others for specific organizational settings, types of diagnostic errors, or for identifying factors that contributed to these errors. It may be necessa ry for health care organizations to use a variety of methods to develop a better sense of their diagnostic perf ormance (Shojania, 2010). Medical record reviews, medical malpractice claims an alysis, health insurance claims analysis, and second reviews in diagnostic testing may be more pragmatic approaches for health care organizations because they leverage readily avai lable data sources. Patient surveys may also be an important mechanism for health care organiza tions to consider; this is in line with the committee's recommendation to create environments in which patients and their families feel comfortable sharing their feedback and concerns about diagnostic error. It is important to note that many of these methods are just beginning to be applied to diagnos tic error detection in clinical practice; very few are validated or av ailable for widespread use in clinical practice (Bhise and Singh, 2015; Graber, 2013; Singh and Sittig, 2015). Beyond identifying diagnostic erro rs and near misses, organizational learning to improve diagnostic performance and reduce diagnostic erro rs will require a focus on understanding where in the diagnostic process these errors occurred, th e work system factors th at contributed to their occurrence, and what the outcomes were and how these errors may be prevented or mitigated. Health care organizations can employ formal erro r analysis and other risk assessment methods to understand the work system factors that underlie these events. Analytical methods employed in human factors and ergonomics research could be applied to further understand the work system components that contribute to diagnostic errors . Once health care organizations have a better understanding of diagnostic errors within their organization, they will need to implement and evaluate interventions to prev ent or mitigate these errors. Accreditation organizations a nd Medicare conditions of participation should ensure that health care organizations' programs are achieving improvements in the quality and safety of diagnosis, including appropriate monitoring, careful analysis of diagnostic errors, and system changes in response to these errors and near misses. Postmortem examinations are an importan t method for identifying diagnostic errors because these examinations can, in many cases , determine the cause of death and reveal discrepancies between premortem and postmorte m clinical findings (Shojania et al., 2002). However, the number of postmortem examinations performed in the United States has declined substantially since the 1960s becau se of a range of medical, legal, social, and economic factors (Lundberg, 1998; Shojania et al., 2002). The committee concluded that a new appro ach to increasing the use of postmortem examinations is warranted. The committee weighed the relative merits of increasing the number of postmortem examinations conducted throughout the United States versus a more targeted approach. The current requirements for postmorte m examinations under the Medicare conditions THE PATH TO IMPROVE DIAGNOSIS AND REDUCE DIAGNOSTIC ERROR 9-13 PREPUBLICATION COPY: UNCORRECTED PROOFS of participation already state th at postmortem examinations shoul d be performed when there is an unusual death or a death of medical-legal and educational interest, and the committee concluded that health care organizations should continue to perf orm the examinations in these circumstances. In addition, the committee conclude d that it is appropriate to have a limited number of highly qualified health care system s participate in conduc ting routine postmortem exams that produce research-quality information about the incidence and nature of diagnostic errors. To accomplish this, a subset of health care systems (which re flect a broad array of different settings of care) could receive fundi ng to perform postmortem examinations in a representative sample of patient deaths.4 This approach will likely provide better epidemiologic data than current practice a nd represent an advance over cu rrent selection methods for performing postmortem examinations, because clinicia ns do not seem to be able to predict cases in which diagnostic errors will be found (Shojania et al., 2002; Shojania et al., 2003). The committee recognizes that the data collected from health care systems that are highly qualified to conduct routine postmortem examinations may not be representative of all systems of care. However, the committee concluded that this approach is a more feasible approach, given the financial and workforce demands of conducting postmortem examinations. These health care organizations could also investigate how new, minimally invasive postmortem approaches compare with full-body postmortem examinations. Less invasive approaches include medical imaging, laparo scopy, biopsy, histology, and cytology. Given the advances in molecular diagnostics and advan ced imaging techniques, these new approaches could provide useful insights on the incidence of diagnostic error and may be more acceptable options for patients' next of kin. Further unders tanding the benefits and limitations of minimally invasive approaches may provide critical information moving forw ard. If successful approaches to minimally invasive postmortem examinations are found, they could play a role in re-establishing the practice of routine po stmortem investigation in medicine. Health care organizations can also impleme nt mechanisms that improve systematic feedback at all levels. Feedback entails informing individuals, teams, or organizations about their diagnostic performance, including their succes ses, near misses, and diagnostic errors. The committee received substantial input indicating th at there are limited opportunities for feedback on diagnostic performance. Feedback can help cl inicians assess how well they are performing in the diagnostic process, correct overconfidence, identify when remediation efforts are needed, and reduce the likelihood of repeated mistakes. Feedback on diagnostic performance can also provide opportunities for health care orga nizational learning and improvements to the work system. Characteristics of effective feedback m echanisms include being actionable, timely, individualized, and non-punitive (Hysong et al., 2006). Health care organizations also need to be aware of the factors that can impede the provision of feedback, such as the fragmentation of the health care system, resistance to critical feedback from clinicia ns, and the lack of time to for follow-up (Schiff, 2008). There are many opportunities to provide fee dback in clinical practice. Methods to monitor the diagnostic process and identify diagnostic erro rs and near misses can be leveraged as mechanisms to provide feedback. Feedback opportunities include disseminating postmortem examination results to clinicians who were involve d in the patient's care; sharing the results of patient surveys, medical record reviews, or in formation gained through follow-up with the health 4 Not all patients' next of kin will consent to the perf ormance of a postmortem examination; these systems can characterize the frequency with which the request for a postmortem examination is refused and better describe the risk of response bias in results. 9-14 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS care professionals; using patient actors or simula ted care scenarios to assess and inform health care professionals' diagnostic performance; and others. Because patients and their families have unique insights into the diagnos tic process and the occurrence of diagnostic error, following up with patients and their families about their experiences and outcomes will be an important source of feedback (Schiff, 2008). Another example of feedback is RADPEER, a program developed by the American College of Radiology that allows anonymous peer review of previous image interpretations to be conducted during the interpre tation of current images. Summary statistics of these reviews are made available to participati ng groups, and they can be used as feedback to improve individual and group practice performan ce (Allen and Thorwarth, 2014). Morbidity and mortality conferences, root cau se analyses, departmental me etings, and WalkRounds provide additional opportunities for feedback to different groups in health care. There is also an opportunity to improve dia gnosis by engaging hea lth care professional societies in identifying areas w ithin their specialties to reduc e diagnostic errors and improve diagnostic performance. This can facilitate improvements in diagnosis based on intrinsic motivation and professionalism, rather than other incentives or disincentives. Efforts to improve diagnosis can include both efforts to improve the quality and safety of diagnosis and efforts to increase efficiency and value by minimizing ina ppropriate diagnostic test ing. This effort could be modeled on the Choosing Wisely Campaign, which was initiated by the American Board of Internal Medicine Foundation to encourage patient and health care professional communication as a means to ensure high-quality, high-valu e care. The campaign in vited each health care professional society to identify a list of five serv ices (i.e., tests, treatmen ts, procedures) that are commonly used in practice but may be unneces sary or not supported by the evidence as improving patient care. These lists were made publicly available as a way of encouraging discussions about appropriate ca re between patients and heal th care professionals. Choosing Wisely received widespread national media atte ntion and engaged more than 50 health care professional societies (Choosing Wisely, 2014). A major lesson from the Choosing Wisely Campaign was the importance of beginning with a small group of founding organizations and then expanding membership. Engaging consumer groups as the program pr ogressed was also an important component of the campaign. One factor in the campaign's success was that it allowed flexibility within limits; partic ipating health care professional societies and boards were given flexibility in identifying their \"Top 5\" services, but items on each list had to be evidence-based and within the purview of that particular society. A similar effort engaging health care prof essional societies could focus on prioritizing diagnostic errors. Early effort s on prioritization could focus on identifying the most common diagnostic errors and \"don't miss\" health conditions, such as t hose that present the greatest likelihood for diagnostic errors a nd harm (Newman-Toker et al., 2013). Each organization could be asked to identify five high-pr iority areas to improve diagnosi s. These groups could be given latitude in how they chose to identify their targ ets, as in Choosing Wisely. Efforts to improve diagnosis can include both improving the quality and safety of diagnosis and increasing efficiency and value, such as identifying inapprop riate diagnostic testing. Another approach may be for societies to identify \"low-hanging fruit,\" or targets that are easily remediable, as a high priority. This strategy could increase the likelihoo d of creating early wins that would contribute to the long-term success of this type of effort . Some groups might identify particular actions, tools, or approaches to reduce diagnostic errors w ith a particular dia gnosis within their specialties (such as checklists, second reviews, or decision support tools). THE PATH TO IMPROVE DIAGNOSIS AND REDUCE DIAGNOSTIC ERROR 9-15 PREPUBLICATION COPY: UNCORRECTED PROOFS This could also be an opportunity for health care professional societies to collaborate, especially on diagnoses that may be missed due to an inappropriate isolation of symptoms. For example, urologists, primary care clinicians, an d neurologists could collaborate to make the diagnosis of normal pressure hydrocephalus (w hose symptoms include frequent urination, balance problems, and memory loss) a \"not to be missed\" dia gnosis (McDonald, 2014). Goal 4: Develop and deploy approaches to identify, learn from, and reduce diagnostic errors and near misses in clinical practice Recommendation 4a: Accreditation organizations and the Medicare conditions of participation should require that health care organizations have programs in place to monitor the diagnostic process and identify, learn from, and reduce diagnostic errors and near misses in a timely fashion. Proven approac hes should be incorporated into updates of these requirements. Recommendation 4b: Health care organizations should: Monitor the diagnostic process and iden tify, learn from, and reduce diagnostic errors and near misses as a component of their research, quality improvement, and patient safety programs. Implement procedures and practices to pr ovide systematic feedback on diagnostic performance to individual health care profes sionals, care teams, and clinical and organizational leaders. Recommendation 4c: HHS should provide funding for a designated subset of health care systems to conduct routine postmo rtem examinations on a repres entative sample of patient deaths. Recommendation 4d: Health care professional societies should identify opportunities to improve accurate and timely diagnoses and re duce diagnostic errors in their specialties. Establish a Work System and Culture that Supports the Diagnostic Process and Improvements in Diagnostic Performance Testimony to the committee indicated that the work systems of many health care organizations could do a better job of supporti ng the 2014b). Health care organi zations influence the work system in which diagnosis occurs and play a role in impleme nting changes to improve diagnosis and avert diagnostic errors. The committee focused on organizational cu lture as well as the leadership and management of an organization as key characte ristics for ensuring con tinuous learning and improvements to the diagnostic proc ess. Health care organizations are responsible for developing a culture that promotes a safe place for all heal th care professionals to identify and learn from diagnostic errors. Organizational leaders and managers can facil itate this culture and set the priorities to achieve progress in improving diag nostic performance and reducing the occurrence of diagnostic errors. 9-16 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Organizational culture refers to an organizatio n's norms of behavior and the shared basic assumptions and values that sustain those norms (Kotter, 2012; Schein, 2004). Some aspects of culture in health care organizations, such as an emphasis on quality and safety and health care professional values promote diagnostic performance, but there are other aspe cts of culture that do not promote improved diagnostic performance, such as an emphasis on blame and punishment and a lack of emphasis on the team-based nature of the diagnostic process. A recent survey of more than 400,000 staff at 653 hospitals found that fewer than half of all surveyed staff members perceived that their organization had a non-puniti ve response to error (AHRQ, 2014a). A culture that emphasizes discipline and punishment for th ose who make mistakes presents a significant barrier to the reporting of errors , which in turn thwarts the le arning process. Cultural taboos on providing feedback to colleagues can further hinder efforts to iden tify and learn from diagnostic errors. To improve diagnosis, health care orga nizations need to develop non-punitive cultures that promote open discussion and feedback on diagnostic performance (Gandhi, 2014; Kanter, 2014; Thomas, 2014). Organizations can create a culture that supports learning and continual improvement in diagnostic performance by implemen ting a just culture (Kanter, 2014; Khatri et al., 2009; Larson, 2002; Marx, 2001; Milstead, 2005) or by adapting the traits of high reliability organizations, which operate in hi gh-stakes conditions but maintain high safety levels (such as those found in nuclear power and aviation indus tries) (Chassin and Loeb, 2011; Singh, 2014; Thomas, 2014; Weick and Sutcliffe, 2011). The involvement of supportive and committed leadership is another component of successful attempts to im prove culture (Chassin, 2013; Hines et al., 2008; IOM, Kotter, 2012). Collaboration among organizati onal leaders is critical to achieving a health care organization's quality goals. Leaders communi cate the priorities of the organization, set expectations, and ensure that the rules, policies, and res ources encourage and support the improvement of diagnostic performance. The involvement of organi zational leaders and managers is crucial for successful change ini tiatives (Dixon-Woods et and Brightman, 2000; Silow-Carroll et al., 2007). In many health care organizations, or ganizational leaders have not yet focused significant attention on improving diagnosis a nd reducing diagnostic al., 2013). However, facilitating change will require their support and involvement, and it may also include prioritizing diagnosis and supporting senior managers in implementing policies and practices that support continued learning and improved diagnostic performance, adop ting a continuously lear ning culture, raising awareness of the quality and safety challenges re lated to diagnostic error, and dispelling the myth that diagnostic errors are inevit able (Leape, 2010; Wachter, 2010). Many components of the work system are under the purview of health care organizations. Thus, organizations can implement changes that ensure a work system that supports the diagnostic process. One principle that health care organizations can apply to the design of the diagnostic work system is \"error re covery,\" which refers to the early identificat ion of an error so that actions can be taken to mitigate or avert negative effects resulting from the error (IOM, 2000). There are a variety of opportunities for health care organizations to improve error recovery and resiliency in the diagnostic pro cess. For example, improved patient access to clinical notes and re sults from diagnostic testing is one form of error recovery; providing this access gives patients the opportunity to identify and correct errors in their m edical records that could lead to a diagnostic error, potentially before any harm results. Thoughtful use of redundancies, such as second re views of anatomic pathology specimens and medical images, THE PATH TO IMPROVE DIAGNOSIS AND REDUCE DIAGNOSTIC ERROR 9-17 PREPUBLICATION COPY: UNCORRECTED PROOFS consultations, and second opinions in challenging cases or comple x care environments, is also a form of error recovery that health care organizations can consider. In addition, organizations can ensure that workforce staffing and supervision policies support human performance and address patient safety risks caused by fatigue (including decision fatigue), sleep deprivation, and sleep de bt (IOM, 2009). Health care organizations can also focus on improvements in workflow design, care transitions, and setti ngs of care (such as emergency departments and outpatient settings) that are prone to diagnostic errors. Technologies that support the diagnost ic process, such as clinical decision support, can also be considered. Health care organizations can ensure that the design and characteristics of the physical environments in which diagnosis takes place su pport the diagnostic proc ess. Elements of the physical environment, including layout, distrac tions, noise, and lighting, can have an impact on human performance and, thereby, the quality a nd safety of care (Carayon, 2012; Hogarth, 2010; Reiling et al., 2008). Although the impact of the physical environment on diagnostic error has not been well studied, there are in dications that it may be an im portant contributor to diagnostic performance. For example, the emergency department has been described as a challenging environment in which to make accurate and time ly diagnoses because of the presence of high- acuity illness, incomplete information, time constraints, and freque nt interruptions and distractions (Croskerry and Si nclair, 2001). Cognitive performance is vulnerable to distractions and interruptions, which influence the likelihood of error. Other physical environment factors that are likely to influence the diagnostic pro cess include the placement of health technologies that support the diagnost ic process, the presence of noise that interferes with clinical reasoning and communication among the diagnostic team, a nd the amount of space available for team members to complete tasks related to the diagnostic process. Health care organizations can also make concerted efforts to address diagnostic challenges related to fragmentation within th e broader health care system. Although improved teamwork and interoperability will help w ith systemic fragmentation in health care, organizations need to recognize that patients may traverse organizati onal boundaries, and this has the potential to contribute to diagnostic errors and failures to learn from them. It is important to developing approaches within health care orga nizations to identify potential vulnerabilities to fragmentation. For example, the committee heard testimony that one important area to address is strengthening communication with pathologists and radiologist s to improve diagnostic test selection and result interpreta tion. Closed-loop reporting systems ar e one mechanism that can be used to reduce diagnostic errors due to communication and resu lt reporting failures (Lacson et al., 2014). Goal 5: Establish a work system and cult ure that supports the diagnostic process and improvements in diagnostic performance Recommendation 5: Health care organizations should: Adopt policies and practices that promote a non-punitive culture that values open discussion and feedback on diagnostic performance. Design the work system in which the diagnostic process occurs to support the work and activities of patients, their famili es, and health care professionals and to facilitate accurate and timely diagnoses. 9-18 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Develop and implement processes to ensure effective and timely communication between diagnostic testing health care pr ofessionals and treating health care professionals across all health care delivery settings. Develop a Reporting Environment and Medical Liability System that Facilitates Improved Diagnosis by Learning from Diagnostic Errors and Near Misses Reporting The committee concluded that there is a need for safe places where health care organizations and professionals can share and learn from their experiences with diagnostic errors, near misses, and adverse events. Performi ng analyses of these events presents the best opportunity to learn from such experiences and to implement changes to improve the diagnostic process. To Err is Human (2000) recommended that reporting syst ems be used to collect this information. Various groups, including individual states, the Joint Commission, the Department of Veterans Affairs, and AHRQ have developed a number of reporting systems, which collect different types of information for different purposes. Characteristics of successful reporting systems include: \"reporting is safe for the i ndividuals who report, reporting leads to a constructive response, expertise and adequate fi nancial resources are available to allow for meaningful analysis of reports, and the repor ting system must be capable of disseminating information on hazards and recommendations for changes\" (WHO, 2005, p. 49; see also Barach and Small, 2000). In contrast, systems that focus on punishing individuals will prevent people from reporting because they fear that their reports may be used as evidence of fault, could precipitate lawsuits, or could result in disciplinary action by st ate medical boards and employers (IOM, 2012; WHO, 2005). Thus, there is a need fo r safe environments, without the threat of legal discovery or disciplinary action, where di agnostic errors, adverse events, and near misses can be analyzed and learned from in order to improve the quality of diagnosis and prevent future diagnostic errors. It is often difficult to create environments where diagnostic errors , adverse events, and near misses can be shared and discussed. Health care organizations and clinicians have been challenged by the limitations of the inconsistent and individual peer revi ew processes that have been enacted by various states fo r the protection of information relating to adverse events and medical errors, for the external use of such information, and for the benefits they receive from reporting. In response to this challenge, the To Err is Human report recommended, \"Congress should pass legislation to extend pe er review protections to data related to patient safety and quality improvement that are collected and analyz ed by health care organizations for internal use or shared with others solely for purposes of improving safety and quali ty\" (IOM, 2000, p. 10). In 2005 the Patient Safety and Quality Improvement Act (PSQIA) was passed by Congress; it provides privilege and confidentialit y protections to health care or ganizations that share specific patient safety information with federally lis ted PSOs (HHS, 2015). The PSO program, which is overseen by AHRQ, is an important national to ol for increasing voluntary error reporting and analysis. The PSO program enables public or private orga nizations to be listed as PSOs provided they meet certain qualifications articu lated in the Patient Safety Rule (AHRQ, 2015d). If health care organizations or health care professionals join a specific PSO, they can then voluntarily send THE PATH TO IMPROVE DIAGNOSIS AND REDUCE DIAGNOSTIC ERROR 9-19 PREPUBLICATION COPY: UNCORRECTED PROOFS patient safety data to the PSO for analysis and feedback on how to improve care. Additionally, PSOs can send de-identified patient safety data to patient safe ty databases overseen by AHRQ. The intent of the program is for AHRQ to anal yze the aggregated data and to publish reports based on those analyses (GAO, 2010). Progress in implementing the PSO program has been slow, and there is very limited information about the impact of PSOs on learning about and improving the quality and safety of care. The Government Accountability Office concl uded in 2010 that it was too early to evaluate the effectiveness of the program (GAO, 2010). Cu rrently, there are more than 80 PSOs, and the PSO network is active, as evidenced by the PSOs' websites, which share information with their members about strategies to mitigate patient safety events (AHRQ, 2015c). A provision in the Affordable Care Act will likely increase the numbe r of hospitals that join PSOs; hospitals with more than 50 beds will be required to join a PSO by January 2017 in order to contract with health plans in insurance exch anges (AHRQ, 2015e; CMS, or generic- and event-specific forms, to encourage standardized event reporting among PSOs (AHRQ, 2015b). However, these formats are voluntary, and some organizations are implem enting them variably or using legacy reporting formats (ONC, 2014). In addition, there are no co mmon formats for diagnostic errors (PSO Privacy Protection Center, 2014); in order to promote voluntary reporting efforts, common formats for diagnostic errors and near misse s are needed. AHRQ could begin with common formats for high-priority areas such as the mo st frequent diagnostic errors and \"don't miss\" health conditions that may result in significant patient harm, such as stroke, acute myocardial infarction, and pulmonary embolism. In 2015, AHRQ noted that no data were submitted to the network of patient safety databases for aggregation and analysis because th e data have not been of sufficient quality or volume to ensure accuracy and de-identification. In addition, fewer than half of PSOs (27 of 76) signed data use agreements with AHRQ by the end of 2014; signing a user agreement is a requirement for sending data to be aggregated for analysis (AHRQ, 2015a). There are also concerns that the federal privilege protections extended by PSQIA are not shielding organizations from state reporting requirements. A recent ruling by the Kentucky Supreme Court found that information that a hosp ital is required to generate under state law is not protected by PSQIA, even if it is shared with a PSO. 5 This type of court decision could undermine the creation of a safe environment to share this information and prevent voluntary submissions to PSOs. Given that the PSO program has potential to im prove learning about di agnostic errors and to expedite the implementation of solutions and adoption of best practices, it is important to evaluate whether the program is meeting the st atutory objectives of PSQIA, namely, that the PSO program is creating opportunities to exam ine and learn from medical errors, including diagnostic errors. The committee is concerned that a number of challenges that the current program is facing may limit its ability to facilitate much-needed voluntary reporting, analysis, and learning from diagnostic errors and near misses. Because of this concern, the committee recognizes that additional federal efforts acro ss HHS\u2014including AHRQ\u2014as well as the involvement of other independent entities may need to be considered in order to prioritize voluntary event reporting for diagnostic errors and near misses. For example, the IOM report, Health IT and Patient Safety: Building Safer Systems for Better Care , made a recommendation for a new entity, akin to 5 Tibbs v. Bunnel, Ky., 2012-SC-000603-MR (Aug. 21, 2014). 9-20 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS the National Transportation Safety Board, that could investigate patient d eaths, serious injuries, and potentially unsafe conditions , and report the results of th ese activities (IOM, 2012). Smaller-scale or more localized efforts to en courage voluntary reporting of diagnostic errors and near misses could also be implemented. Fo r example, at the level of a health care organization, quality and patient safety committees can analyze and learn from diagnostic errors, as these activities may be protected from disclosure by state statutes. Medical Liability The two core functions of the medical liability system are to compensate negligently injured patients and to promote quality by enc ouraging clinicians and organizations to avoid medical errors. Although the medical liability environment may act as a generalized deterrent to medical errors, it is not well aligned with the pr omotion of high-quality, safe care. Concerns over medical liability prevent clinicians from disclosing medical errors to patients and their families despite calls from numerous groups about the ethical necessity of full disclosure and a requirement for Joint Commission accreditation (H endrich et al., 2014; Sa ge et al., 2014). In spite of this, clinicians often struggle to fulf ill this responsibility (Gallagher et al., 2007, 2013; Joint Commission, 2005). There is limited guidance for clinicians concerning how to disclose this information effectively; a number of factors, including embarrassment, inexperience, lack of confidence, and mixed messages from risk ma nagers and health care organizations, can discourage clinicians from making disclosures to patients and their families (Gallagher et al., 2013). The current tort-based system for resolving me dical liability disputes sets up barriers to improvements in quality and patient safety and s tifles continuous learni ng. Medical malpractice reform could be designed to permit patients and health care professionals to become allies in trying to make health care safer by encouraging transparency with regard to errors. Such an approach would allow patients to be promptly and fairly compensated for any injuries that were avoidable, while turning errors into lessons to improve subsequent performance (AHRQ, 2014b; Berenson, 2005; Kachalia and Mello, 2011). Diagnostic errors are a leadi ng type of malpractice claim, and these claims are more likely to be associated with patient deaths than other types of medical errors (Tehrani et al., 2013). Reforming the medical liability system, th erefore, has the potential to improve learning from diagnostic errors and increase the disclosu re of diagnostic errors to patients and their families as well as to lead to fairer treatment in the medical injury resolution processes. There have been many calls for changes to the medical liability system. Traditional mechanisms to reform the liability system\u2014such as imposing barriers to bringing lawsuits, limiting compensation, and changing the way that damage awards are paid\u2014have not contributed to improvements in either compensating negligently in jured patients or deterring unsafe care (Mello et al., 2014). Thus, the committee concluded that stakeholders need to consider alternative approaches to improving the legal environment and promoting learning from diagnostic errors. The To Err is Human report concluded that alte rnative approaches to th e resolution of medical injuries could resolve the incentive to hide medical injuries, and in 2002 the IOM proposed state-level demonstration projects to explore alternative approaches to the current liability system that are patient-centered and focused on patient safety (IOM, 2000, 2002). Although enthusiasm for alternativ e approaches to the current medical liability system is growing, in general progress has be en slow, especially toward mo re fundamental changes to the THE PATH TO IMPROVE DIAGNOSIS AND REDUCE DIAGNOSTIC ERROR 9-21 PREPUBLICATION COPY: UNCORRECTED PROOFS medical liability system. Thus, the committee took both a pragmatic and aspirational approach to considering changes to medical liability that would promote the improved disclosure of diagnostic errors as well as oppor tunities to learn from these errors. A number of alternative approaches to the current medical liability sy stem were evaluated, and the committee concluded that the most promising approaches include communication and resolution programs (CRPs), the use of evidence-based clinical practice guidelines as safe harbors, and administrative health courts. CRPs represent a more pr agmatic approach, in that they are the more likely to be implemented in the current medi cal liability climate, and they have a strong focus on improving patient safety as well as reduci ng litigation. States, in collabor ation with other stakeholders, should encourage the adoption of CRPs with legal protections for disclosures and apologies under state laws. Safe harbors for adherence to clinical practice guidelines and administrative health courts are challenging in regard to impl ementation, and more information is needed about their impact on improving diagnosis. Thus, further demonstrations of these two approaches are warranted. CRPs are principled comprehensive patient safety programs in which health care professionals and organizations openly discuss ad verse outcomes with pati ents and proactively seek resolution while promoting patient-centere dness, learning, and quality improvement. CRPs rely on creating transparent health care cultures in which the early reporti ng of adverse events is the norm and is coupled with systems-based event analysis that is designed to understand the root causes of adverse events and to deve lop plans for preventing recurrences. Improved transparency surrounding diagnostic errors can he lp foster an improved culture of reporting, which can in turn promote learning about and id entification of interven tions to improve the safety and quality of diagnosis (Mello et al ., 2014). Although CRPs do no t require legislative changes, CRP adoption could be facilitated th rough changes to state laws, such as laws protecting disclosures and apologies (Sage et al ., 2014). In addition, a national collaborative of CRPs could help accelerate the spread of CRPs and help disseminate learning from these programs widely. Safe harbors for following evidence-based clin ical guidelines have th e potential to raise the quality of health care by cr eating an incentive (liability protection) for clinicians to follow evidence-based clinical practice guidelines. Unli ke the case with other approaches to improving the medical liability environment, input to the committee suggested that safe harbors would offer direct opportunities to improve diagnosis (Kachalia, 2014). Howe ver, there are few clinical practice guidelines available for diagnosis, and imp lementing safe harbors for adherence to these guidelines is administratively complex. Administrative health courts have been proposed as a way to provi de injured patients with expedited compensation decisions for certain types of medical errors and to promote the disclosure of medical errors (suc h as diagnostic errors). Administ rative health courts provide a non-judicial process of handli ng medical injuries, in whic h cases are filed through an administrative process. The goal in using these c ourts is to quickly and equitably compensate patients who have experienced avoidable injuri es without requiring the patients to prove negligence in an adversarial proceeding (Berenson, 2005). The establishm ent of these courts would represent a fundamental change that would promote a more open environment for identifying, studying, and learning from errors. Ho wever, implementing administrative health courts would pose a number of challenges, includ ing the need for legislative action, the courts' operational complexity, and the presence of re sistance from stakeholders who are strongly committed to preserving the current tort-based system. 9-22 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Risk Management Professional liability insurance carriers and he alth care organizations that participate in a captive insurance program or other self-insurance arrangement have a vested interest in improving diagnosis. Many of these carriers and organizations are actively exploring opportunities to improve diagnosis and reduce diagnostic errors. Given their expertise in understanding the contributors to di agnostic errors, they bring an im portant perspective to efforts to improve diagnosis, both those focused on i ndividual health care pr ofessionals and those focused on the work system components that ma y contribute to diagnosti c errors. The expertise of health professional liability insurance carriers needs to be le veraged to improve the diagnostic process. Improved collaboration between health professional liability insurance carriers and health care professionals and orga nizations could help to identify resources, prioritize areas of concern, and devise interventions. Collaborati on among health care professional educators and professional liability insurance carriers could al so be helpful in developing interventions for trainees. Goal 6: Develop a reporting environment a nd medical liability system that facilitates improved diagnosis by learning from diagnostic errors and near misses Recommendation 6a: AHRQ or other appropriat e agencies or independent entities should encourage and facilitate the voluntary reporting of diagnostic errors and near misses. Recommendation 6b: AHRQ should evaluate the effectiveness PSOs as a major mechanism for voluntary reporting and learning from these events and modify the PSO common formats for reporting of patient safety events to include diagnostic errors and near misses. Recommendation 6c: States, in collaboration with other stakeholders (health care organizations, professional liability insura nce carriers, state and federal policy makers, patient advocacy groups and medical malpractic e plaintiff and defense attorneys), should promote a legal environment that facilitates the timely identification, disclosure, and learning from diagnostic errors. Specifically, they should: Encourage the adoption of CRPs with legal protections for disclosures and apologies under state laws. Conduct demonstration projects of alternat ive approaches to the resolution of medical injuries, including administrative health courts and safe harbors for adherence to evidenced-based clin ical practice guidelines. Recommendation 6d: Professional liability insu rance carriers and captive insurers should collaborate with health care professional s on opportunities to improve diagnostic performance through education, training, and practice improvement approaches, and increase participation in such programs. THE PATH TO IMPROVE DIAGNOSIS AND REDUCE DIAGNOSTIC ERROR 9-23 PREPUBLICATION COPY: UNCORRECTED PROOFS Design a Payment and Care Delivery Environment that Supports the Diagnostic Process Fee-for-service (FFS) payment, the predominant form of payment for health care services in the United States, pays health care professionals for each service they provide. FFS payment has been long-recognized for its inability to incentivize well-coordinated, high-quality, and efficient health care (Council of Econ omic Advisors, 2009; IOM, 2001, 2013; National Commission on Physician Payment Reform, 2013). Th ere is relatively little information about the impact of payment on the diagnostic proce ss. However, the committee concluded that it is likely to have an impact, and several payment experts who provided input to the committee helped elaborate on some of the likely conseque nces (Miller, 2014; Ro senthal, 2014; Wennberg, 2014). In general, FFS payment may not incentivize a high-quality, efficient diagnostic process, because the more services the diagnostic process takes, the more remunera tion will result. There is no disincentive for ordering unnecessary diagnostic testing that could lead to false positive results and diagnostic errors (M iller, 2014; Wennberg, 2014). There is also a financial incentive to provide treatment to patients rather than de termining that a patient does not have a health problem; thus, inappropriate diagnoses are better compensated than determining that a patient does not have a health problem. Likewise, accuracy in the diagnostic process is not incentivized by FFS payment: Clinicians who interpret diagnostic tests or provide a diagnosis during a patient visit receive payment regardless of whether th e work was done adequately to support accurate interpretation and diagnosis and regardless of whether the interpretati ons and diagnoses were accurate (Miller, 2014). Given the importance of team-based care in th e diagnostic process, the lack of financial incentives in FFS payment to coordinate care can contribute to challe nges in diagnosis and diagnostic errors, particularly delays in di agnosis (Rosenthal, 2014). FFS Medicare and most commercial payers do not pay for a clinician's time spent contacti ng other clinicians by phone or e-mail to facilitate the diagnostic process, fo r example, by helping determine the appropriate diagnostic testing procedures for a patient. In addition, clinicians are not reimbursed for proactive outreach to patients to obtain diagnostic testing, schedul e visits with specialists, or make follow-up appointments (Miller, 2014). To im prove teamwork and care coordination in the diagnostic process (Allen and Thorwarth, 2014 ; Kroft, 2014; Miller , 2014), new current procedural terminology (CPT) codes can be de veloped and compensated, such as codes for communication among treating clinic ians, pathologists, and radiol ogists about diagnostic testing ordering, interpretation, and the subsequent de cision making. These codes could be modeled on existing Medicare codes that compensate clin icians' time for coordination and planning activities, such as th e codes for radiation th erapy planning, post-disch arge transitional care coordination, and complex chronic care coordination (ASTRO, 2014; Bendix, 2013; CMS, 2014b; Edwards and Landon, 2014). The Medicare physician fee schedule sets paym ent rates based on rela tive value units that are meant to reflect the level of time, effort, skill, and stress associated with providing each service (MedPAC, 2014). Fee schedule services can include evaluation and management services (\"E&M services,\" such as office, inpatient, or emergency department visits), diagnostic testing, and other procedures. For all medical specialti es, there are well-documented fee schedule distortions that result in more generous payments (in relation to the costs of production) for procedures and also for diagnostic testing interp retations compared to E&M services (Berenson, 2010; National Commission on Physician Paymen t Reform, 2013). These distortions have 9-24 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS coincided with a large growth in diagnostic testin g in health care; for example, the percent of patients presenting to the emergency department with dizziness who underwent CT scans rose from 9 percent in 1995 to 40 percent in 2013, alth ough there has been no increase in diagnoses of stroke or other neurologic diseases (Ig lehart, 2009; Newman-Toker et al., 2013). The lower relative value afforded to E&M serv ices versus procedure-oriented care is an obstacle to improved diagnostic performance. E&M services reflect the c ognitive expertise and skills that all clinicians have and use in the diagnostic process, and the distortions may be diverting attention and time from important tasks in the diagnostic process, such as performing a patient's clinical hi story and interview, conducting a phys ical exam, and thoughtful decision making in the diagnostic process. Realigning relative value fees to better compensate clinicians for the cognitive work in the di agnostic process has the potent ial to improve accuracy in diagnosis while reducing the incentives that driv e inappropriate utilizatio n of diagnostic testing in the diagnostic process. E&M payment policies and documentation guidelin es are also misaligned with the goal of accurate and timely diagnosis. E&M payments penalize clinicians for spending extra time on the diagnostic process for individual patients. Th ere are different levels of E&M visits based on time and complexity, and clinicians receive better compensation if they see more patients with shorter appointment lengths. For example, in Me dicare if a clinician spends 20 minutes instead of 15 minutes with a pati ent billed as a level 3 E&M visit, th e clinician will receive 25 percent less revenue per hour; if a clinician spends 25 minutes for a level 4 E&M visit instead of 15 minutes for a level 3 visit, the clinician will receive 11 percent less revenue per hour (Miller, 2014). Input to the committee noted that time pressu res in clinical visits can contribute to challenges in clinical reasoning and to the occurrence of errors (Durning, 2014; Evans and Kim, 2006; Jena et al., 2013; et al., 2007; Sarkar et al., 2012, 2014; Schiff et al., 2009; Singh et al., 2013). Documentation guidelines for E&M services were created to ensure that the services performed were consistent with the insurance coverage; to validat e specific information, such as the site of service, the appropria teness of the care, and the accur acy of the reported information; and to prevent fraud and abuse (Berenson, 1999; CMS, 2014a). Documentation guidelines also specify the extent of a patient's clinical hist ory and physical exam and the complexity of the medical decision making involved in the E&M visit (Berenson et al., 2011; HHS, 2010). There are a number of criticisms of the documentation guidelines. The primary criticism is that the level of detail required is onerous, often irrelevant to patient care, and sh ifts the purpose of the medical record toward billing rather than on f acilitating clin ical reasoning 2015; Schiff and Bates, 2010). The documentation guidelines have become an even greater concern with the broad implementation of EHRs, because EHR design emphasizes fulfilling documentation and legal requirements rather than facilitating the dia gnostic process (Berenson et al., 2011; Schiff and Bates, 2010). The orientation of EHRs to doc umentation, their overreliance on templates, and their cut-and-paste functionalities have resulted in \"EHR-generated data dumps, including repetitive documentation of elements of patie nts' histories and physic al examinations, that merely result in electronic versions of clini cally cumbersome, uninformative patient records\" (Berenson et al., 2011, p. 1894). Generating docum entation to support E&M coding (or assigning higher levels of E&M coding than warranted\u2014know n as \"upcoding\") can result in inaccuracies in the patient's EHR that can cont ribute to diagnostic errors. A number of payment and care delivery refo rm s to counter the limitations of the FFS payment system are now actively being consider ed, implemented, and evaluated. These include THE PATH TO IMPROVE DIAGNOSIS AND REDUCE DIAGNOSTIC ERROR 9-25 PREPUBLICATION COPY: UNCORRECTED PROOFS capitation/global payments, shared savings , bundled episodes of care, accountable care organizations, patient-centered medical homes, and pay for performance (which in Medicare is labeled \"value-based purchasing\"). The Centers for Medicare & Medicaid Services (CMS) recently announced that it plans \"to have 30 percent of Medicare fee-for-service payments tied to quality or value thr ough alternative payment models by the end of 2016, and 50 percent of payments by the end of 2018\" (Burwell, 2015). The Medicare Access and CHIP Reauthorization Act of 2015 (the repeal of the sustainable grow th rate) also continue s down the path toward alternative payment models, particularly for the payment of Medicare clinicians. 6 There is very limited evidence concerning the impact of new payment and delivery models on the diagnostic process and the accuracy of diagnosis, and this represents a fundamental research need. Assessing the impact of paymen t and care delivery reforms, including FFS, on the diagnostic process, diagnostic errors, and le arning are critical areas of focu s as these models are evaluated more broadly. The committee asked for input from payment and deliv ery experts about the potential effects of new models on diagnosis an d diagnostic error. Rose nthal (2014) suggested that global payment and meaningf ul use incentives have the potential to improve diagnosis by promoting the adoption of diagnostic test and referral tracking systems that better connect health care professionals throughout the continuum of care. Mille r (2014) suggested that the development of measures for diagnostic accuracy could be used to also provide feedback and reward clinicians for diagnostic accuracy. We nnberg (2014) suggested that population-based payment models, including capita tion and global budgets, have the greatest potential to reduce diagnostic errors. While new payment models ha ve the potential to reduce diagnostic errors, these models may also create incentives for clinic ians and health care or ganizations that could reduce use of appropriate testi ng and clinician services (e.g., sp ecialty consultations) that may inadvertently lead to greater diagnostic errors. Thus, research in this area will be helpful in assessing the impact of payment a nd care delivery models on diagnosis. Even when alternate payment and care de livery approaches to FFS are employed, they are often based on or influenced by existing c oding and payment rules (Berenson et al., 2011). For example, bundled payments are combinations of current codes. Thus, the current distortions in the fee schedule and other volume-based paym ent approaches, such as diagnosis-related group coding, will remain a dominant component of pa yment and care delivery models in the near future and need to be addressed. Goal 7: Design a payment and care delivery environment that supports the diagnostic process Recommendation 7a: As long as fee sche dules remain a predominant mechanism for determining clinician payment, CMS and other payers should: Create CPT codes and provide coverage for additional evaluation and management activities not currently coded or covered, including time spent by pathologists, radiologists, and other clinicians in advising ordering clinicians on the selection, use, and interpretation of diagnostic testing for specific patients. Reorient relative value fees to more appropriately value th e time spent with patients in evaluation and management activities. 6 Medicare Access and CHIP Reauthorization Act of 2015. P.L. 114-10. (April 16, 2015). 9-26 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Modify documentation guidelines for evaluation and management services to improve the accuracy of information in th e EHR and to support decision making in the diagnostic process. Recommendation 7b: CMS and other payers shou ld assess the impact of payment and care delivery models on the diagnostic process, th e occurrence of diagnostic errors, and learning from these errors. Provide Dedicated Funding for Research on the Diagnostic Process and Diagnostic Errors The diagnostic process and the ch allenge of diagnostic errors have been neglected within the national health care research agenda (Berenson et al., 2014; Wachter, 2010; Zwaan et al., 2013). Input provided to the committee concluded that \"although correct treatment presumes a correct diagnosis, federal resources devoted to diagnostic research are vastly eclipsed by those devoted to treatment\" (Newman-Toker, 2014, p. 12). There are a number of reasons why diagnosis and diagnostic errors ma y be underrepresented in current research activities, including a lack of awareness or the perceived inevitabil ity of the problem, attitudes and a culture that encourage inaction and tolerance of errors, poorly understood characteristics of the diagnostic and clinical reasoning processes, and the lack of financial and other resources needed to address the problem (Berenson et al., 2014; Croskerry, 2012). A major barrier to research on diagnosis a nd diagnostic error is the current disease- focused approach to medical research f unding. For example, the structure and funding mechanisms of the National Institutes of Health (NIH) are often organized by disease or organ systems, which facilitates the study of these specif ic areas but impedes research efforts that seek to provide a more comprehensive understanding of diagnosis as a dis tinct research area. Newman-Toker (2014, p. 12) asserted that diagnos tic research \"invariably falls between rather than within individual Institute missions.\" As such, the topic of diagnosis, which cuts across various diseases and body parts, is not central ized within the NIH re search portfolio, and available research funding for diagnosis often ta rgets specific diseases but not diagnosis as a whole or the diagnosis of several diseases with similar presentations. Diagnosis and diagnostic error are not a major focus of federal health serv ices research efforts, with the exception of two special emphasis notices from AHRQ for di agnostic error in 2007 and 2013. The 2013 research notice focused on understanding diagnostic errors in the ambulatory care setting, including research on the \"incidence, cost, determinants, and strategies for preventing or mitigating [these] errors\" (AHRQ, 2013). In 2015, AHRQ posted an R01 grant opportunity for \"understanding and improving diagnostic safety in ambulatory care: incidence and contribut ing factors\" (AHRQ, 2015f) and an R18 grant opportunity for identifying strategies a nd interventions to improve diagnostic safety in ambulatory care (AHRQ, 2015g). Although these initial steps are promising, the committee concluded that there is an urgent need for dedicated, coor dinated federal funding for research on diagnosis and diagnostic error. Given the potential for federal research fo r diagnosis and diagnostic error to fall between institutional missions, federal agencies need to co llaborate to develop a na tional research agenda that addresses diagnosis and diagnostic error by 2016. Zwaan and colleagues (2013) outlined potential research opportunities that were broadly classified into three categories: the epidemiology of diagnostic errors, the causes of diagnostic error, and error preven tion strategies. The Society to Improve Diagnosis in Medicine has formed a research committee to bring THE PATH TO IMPROVE DIAGNOSIS AND REDUCE DIAGNOSTIC ERROR 9-27 PREPUBLICATION COPY: UNCORRECTED PROOFS together multidisciplinary perspectives to advance a research agenda derived from critical gaps in the evidence base. Building on this work, the committee identified additional areas of research that could help shape a nationa l research agenda on diagnosis and diagnostic error (see Chapter 8). The federal government should commit dedicated funding to implementing this research agenda. Because the rate of growth in overall federal investments in biomedical and health services research are declining (Moses et al ., 2015), the committee recognizes that funding for diagnosis and diagnostic error will likely draw federal resource s away from other important priorities. However, given the c onsistent lack of resources for research on diagnosis and the potential for diagnostic errors to contribute si gnificant patient harm, the committee concluded that this is necessary for broader improvements to the quality and safety of health care. In addition, improving diagnosis could also lead to potential cost savings by preventing diagnostic errors, inappropriate treatment, and related adverse events. In addition to federal-level research on di agnosis and diagnostic errors, there is an important role for public-private collaboration and coordination among the federal government, foundations, industry, and other or ganizations. Collaborative f unding efforts help extend the existing financial resources and re duce duplications in research e fforts. Interested parties can unite around mutual interests and spearhead progr ess toward a specific cause. Foundations and industry can make important contributions\u2014financially and within their areas of expertise\u2014to the field of diagnosis and di agnostic errors that can enha nce the medical community's knowledge in this area. Various types of collabora tive models that have been employed to share information, resources, and capabilities have been described in the litera ture (Altshuler et al., 2010; Portilla and Alving, 2010). Goal 8: Provide dedicated funding for researc h on the diagnostic process and diagnostic errors Recommendation 8a: Federal agencies, includin g HHS, the U.S. Department of Veterans Affairs, and the United States De partment of Defense, should: Develop a coordinated research agenda on the diagnostic process and diagnostic errors by the end of 2016. Commit dedicated funding to implementing this research agenda. Recommendation 8b: The federal government sh ould pursue and encourage opportunities for public-private partnerships among a broad range of stakeholders, such as the Patient-Centered Outcomes Research Institute, foundat ions, the diagnostic testing and health IT industries, health care organizations, and profe ssional liability insurers to support research on the diagnostic process and diagnostic errors. REFERENCES Adler-Milstein, J. 2015. America's health IT transformati on: Translating the promise of electronic health records into better care. Paper presented at U.S. Senate Committee on Health, Education, Labor and Pensions, March 17. . http://www.help.senate.gov/imo/media/doc/Adl er-Milstein.pdf (accessed June 5, 2015). Adler-Milstein, J., C. M. DesRoches, M. F. Furukawa, C. Worzala, D. Charles, P. Kralovec, S. Stalley, and A. K. Jha. 2014. More than half of U.S. hospitals have at least a basic EHR, but stage 2 criteria remain challenging for most. Health Affairs (Millwood) 33(9):1664-1671. Adler-Milstein, J., and A. Jha. 2014. Health information exchange among U.S. hospitals: Who's in, who's out and why? Healthcare 2(1):26-32. 9-28 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION UNCORRECTED PROOFS AHIMA (American Health Information Management Asso ciation). 2014. Appropriate use of the copy past functionality in electronic health records. www.ah ima.org/topics/ehr (acce ssed March 27, 2015). AHRQ (Agency for Healthcare Research and Quality). 2013. AHRQ announces interest in research to improve diagnostic performance in ambulatory care settings http://grants.nih.gov/grants/guide/notice-files/NOT-HS- 13-009.html (accessed February 4, 2015). AHRQ. 2014a. Hospital survey on patient safety culture: 2014 user comparative database report: Chapter 5. Overall results. www.ahrq.gov/professionals/quality-patient- safety/patientsafetyculture/hospital/2014/hos p14ch5.html (accessed February 25, 2014). AHRQ. 2014b. Medical Reform & Patient Safety Initiative. www.ahrq.gov/professionals/quality-patient- safety/patient-safety-resources/resou rces/liability/ (accesse d 2015, April 9). and family advisory councils. https://cahps.ahrq.gov/quality-improvement/improvement- guide/browse-interventions/Customer-Service/Listeni ng-Posts/Advisory-Councils.html (accessed May 26, 2015). AHRQ. 2015a. Agency for Healthcare Research and Qua lity: Justification of estimates for appropriations committees. www.ahrq.gov/sites/default/files/wysi wyg/cpi/about/mission/budget/2016/cj2016.pdf (accessed May 3, 2015). AHRQ. 2015b. Common 2015c. Federally-liste www.pso.ahrq.gov/liste d (accessed May 3, 2015). AHRQ. 2015d. Patient Safety Organization (PSO) Program: Frequently asked questions. www.pso.ahrq.gov/faq#WhatisaPSO (accessed May 3, 2015). AHRQ. 2015e. Patient Safety Organization (PSO) Program: Reducing unnecessary hospital readmissions: The role of the patient safety organization. www.pso.ahrq.gov/Topics (accessed May 3, 2015). AHRQ. 2015f. Understanding and improving diagnostic safety in ambulatory care: Incidence and contributing factors (R01). http://grants.nih. gov/grants/guide/pa-files/PA-15- 180.html (accessed May 3, 2015). AHRQ. 2015g. Understanding and improving diagnostic safety in ambulatory and interventions (R18). http://grants.nih.gov/gr ants/guide/pa-files/ PA-15-179.html (acce ssed May 3, 2015). Allen, B., 2014. Comments from the American College of Radiology. Presentation to the Committee on Diagnostic Error in Health Care, November 5, 2014, Washington, DC. Allen, B. T., William T. 2014. RE: Committee on Diagnos tic Error Meeting November 5-6, 2014: Input submitted to the Committee on Diagnostic Error in Health Care, December 29, 2014, Washington, DC. Altshuler, J. S., E. Balogh, A. D. Barker, S. L. Eck, S. H. Friend, G. S. Ginsburg, R. S. Herbst, S. J. Nass, C. M. Streeter, and J. A. Wagner. 2010. Open ing up to precompetitive collaboration. Science Translational Medicine 2(52):52cm26. ASTRO (American Society for Oncology). 2014. Basics of RO coding. www.astro.org/Practice- Management/Reimbursement/Basics-of-RO- Coding.aspx (accessed March 26, 2015). Baker, D. P., R. Day, and E. Salas. 2006. Teamwork as an essential component of high-reliability organizations. Health Services Research 41(4p2):1576-1598. Barach, P., and S. D. Small. 2000. Reporting and preventing medical mishaps: Lessons from non-medical near miss reporting systems. BMJ 320(7237):759-763. Basch, P. 2014. ONC's 10-year roadmap towards interoperability changes to the meaningful use program. http://healthaffairs.org/blog/2014/11/03/oncs-10-ye ar-roadmap-towards-interoperability-requires-changes- to-the-meaningful-use-program / (accessed March 27, 2015). Bell, S., M. Anselmo, J. Walker, and T. Delbanco. 2014. Information on OpenNotes. Input submitted to the Committee on Diagnostic Error in Health Care, December 2, 2014, Washington, DC. Bendix, J. 2013. Making sense of the new transitional care codes. http://medicaleconomics.modernmedicine.com/medi cal-economics/news/user-defined-tags/99495/making- sense-new-transitional-care-codes?pa ge=full (accessed March 26, 2015). Berenson, R. A. 1999. Evaluation and management guidelines. New England Journal of Medicine 340(11):889; author reply 890-891. Berenson, R. A. 2005. Malpractice makes perfect. The New Republic , October 10. www.newrepublic.com/article/health-care-malp ractice-bush-frist (acces sed May 26, 2015). Berenson, R. A. 2010. Out of whack: Pricing distortions in the Medicare physician fee schedule. Expert Voices, Sept ember. www.nihcm.org/pdf/NIHCM-EV-Berenson_FINAL.pdf (accessed June 8, 2015). Berenson, R. A., P. Basch, and A. Sussex. 2011. Revisiting E&M visit guidelines\u2014A missing piece of payment reform. New England Journal of Medicine 364(20):1892-1895. THE PATH TO IMPROVE DIAGNOSIS AND REDUCE DIAGNOSTIC ERROR 9-29 PREPUBLICATION COPY: UNCORRECTED PROOFS Berenson, R. A., D. K. Upadhyay, and D. R. Kaye. 2014. Placing diagnosis errors on the policy agenda. Washington, DC: Urban Institute. http://www.urban.o rg/research/publication/placing-diagnosis-errors- policy-agenda (accessed June 7, 2015). Berner, E. S., and M. L. Graber. 2008. Overconfid ence as a cause of diagnostic error in medicine. American Journal of Medicine 121(5):S2-S23. Bhise, V., and H. Singh. 2015. Measuring diagnostic safe ty of inpatients: Time to set sail in uncharted waters. Diagnosis 2(1):1-2. Brett, A. S. 1998. New guidelines for codi ng physicians' services\u2014A step backward. New England Journal of Medicine 339(23):1705-1708. Bruno, M. A., J. M. Petscavage-Thomas, M. J. Mohr, S. K. Bell, and S. D. Brown. 2014. The \"open letter\": Radiologists' reports in the era of patient web portals. Journal of the American College of Radiology 11(9):863-867. Brush, J. E. 2014. Forming good habits to decrease diagnos tic error: A case for likelihood ratios. Paper presented at Commitee on Diagnostic Error in Health Care, October 21, 2014, Washington, DC. Burwell, S. M. 2015. Setting value-based payment goals\u2014HHS efforts to improve U.S. health care. New England Journal of Medicine 372(10):897-899. Carayon, P. 2012. The physical environment in health care. In C. J. Alvarado (ed.), Handbook of human factors and ergonomics in health care and patient safety (pp. 215-234). Boca Raton, FL: Taylor & Francis Group. Carayon, P., H. Faye, A. S. Hundt, B.-T. Karsh, and T. Wetterneck, T. 2011. Patient safety and proactive risk assessment. In Y. Yuehwern (ed.), Handbook of Healthcare Delivery Systems (pp. 12-1 to 12-15.). Boca Raton, FL: Taylor & Francis. Cate, O. t. 2014. Advice to the Institute of Medicine Committee on Diagnostic Error. Input submitted to the Committee on Diagnostic Error in Health Care, November 28, 2014, Washington, DC. Chassin, M. R. 2013. Improving the quality of health care: What's taking so long? Health Affairs (Millwood) 32(10):1761-1765. Chassin, M. R., and J. M. Loeb. 2011. The ongoing quality improvement journey: Next stop, high reliability. Health Affairs (Millwood) 30(4):559-568. CHCF (California HealthCare Foundation). 2014. Ten y ears in: Charting the progress of health information exchange in the U.S. www.chcf.org/~/media/MEDIA%2 0LIBRARY%20Files/PDF/T/PDF%20TenYearsProgressHIE.pdf (accessed February 9, 2015). Choosing Wisely. 2014. Lists. ww w.choosingwisely.org/doctor-patient-lists/ ( accessed May 26, 2015). CMS (Centers for Medicare & Medicaid Services).2013. Patie nt Protection and Affordable Care Act; HHS Notice of Benefit and Payment Parameters for 2015. Federal Register. https://www.federalregister .gov/articles/2013/12/02/2013-28610/patient-protection-and-affordable-care- act-hhs-notice-of-benefit-and-payment-parameters-for-2015 CMS. 2014a. Evaluation and management services guide: Official CMS informatio n for Medicare fee-for-service providers . Washington, DC: CMS. CMS. 2014b. Policy and payment changes to the Medicare physician fee schedule for 2015. www.cms.gov/newsroom/mediareleas edatabase/fact-sheets/2014-Fact-s heets-items/2014-10-31-7.html (accessed March 26, 2015). Council of Economic Advisors. 2009. The economic case for health care reform . www.whitehouse.gov/assets/documents/CEA_Health_Care_Report.pdf (accessed March 17, 2015). CRICO. 2014. Analysis of Diagnosis-Related Medical Ma lpractice Claims. Input submitted to the Committee on Diagnostic Error in Health Care, August 4, 2014, Washington, DC. Croskerry, P. 2003. The importance of cognitive errors in diagnosis and strategies to minimize them. Academic Medicine 78(8):775-780. Croskerry, P. 2012. Perspectives on diagnostic failure and patient safety. Healthcare Quarterly 15(Special issue):50-56. C roskerry, P., and D. Sinclair. 2001. Emergency medicine: A practice prone to error. Canadian Journal of Emergency Medicine 3(4):271-276. Dehling, T., Gao, F., Schneider, S., & Sunyaev, A. . 2015. Exploring the far side of mobile health: Information security and privacy of mobile health apps on iOS and Android. JMIR mHealth and uHealth 3(1):e8. Delbanco, T., J. Walker, J. D. Darer, J. G. Elmore, H. J. Feldman, S. G. Le veille, J. D. Ralston, S. E. Ross, E. Vodicka, and V. D. Weber. 2010. Open notes: doctors and patients signing on. Annals of Internal Medicine 153(2):121-125. 9-30 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Delbanco, T., J. Walker, S. K. Bell, J. D. Darer, J. G. Elmore, N. Farag, H. J. Feldman, R. Mejilla, L. Ngo, J. D. Ralston, S. E. Ross, N. Trivedi, E. Vodicka, and S. G. Leveille. 2012. Inviting patients to read their doctors' notes: A quasi-experimental study and a look ahead. Annals of Internal Medicine 157(7):461-470. Dhaliwal, G. 2014. Blueprint for diagnostic excellence. Presentation to the Committee on Diagnostic Error in Health Care, November 21, 2014, Washington, DC. Dingley, C., K. Daugherty, M. K. Derieg, and R. Persing. 2008. Improving patient safety through provider communication strategy enhancements. In Advances in Patient Safety: New Directions and Alternative Approaches (Vol. 3: Performance and Tools) . Rockville, MD: Agency for Healthcare Research and Quality. http://www.ahrq.gov/professionals/quality-patient-safety/patient-safety- resources/resources/advances-in-patie nt-safety-2/vol3/Advances-Dingley_1 4.pdf (accessed June 11, 2015). Dixon-Woods, Bosk, E. Aveling, C. Goeschel, and P. Pronovost. 2011. Explaining Michigan: Developing an ex-post theory of a quality improvement program. Milbank Quarterly 89(2):167-205. Durning, S. J. 2014. Submitted input. Input submitted to the Committee on Diagnostic Error in Health Care, October 24, 2014, Washington, DC. Edwards, S. T., and B. E. Landon. 2014. Medicare's chronic care ma nagement payment\u2014Payment reform for primary care. New England Journal of Medicine 371(22):2049-2051. El-Kareh, R., O. Hasan, and G. Schiff. 2013. Use of health information technology to reduce diagnostic error. BMJ Quality and Safety 22(Suppl 2):ii40-ii44. Epner, P.2014. An Overview of Diagnostic Error in Medi cine. Presentation to the Committee on Diagnostic Error in Health Care, April 28, 2014, Washington, DC. Epner, P. 2015. Written input. Input submitted to the Co mmittee on Diagnostic Error in Health Care, January 13, 2015, Washington, DC. Etchegaray, J. M., M. J. Ottosen, L. Burress, W. M. Sa ge, S. K. Bell, T. H. Gallagher, and E. J. Thomas. 2014. Structuring patient and family involvement in medical error event disclosure and analysis. Health Affairs (Millwood) 33(1):46-52. Eva, K. W., and G. R. Norman. 2005. Heuristics and biases\u2014A biased perspective on clinical reasoning. Medical Education 39(9):870-872. Evans, W. N., and B. Kim. 2006. Patient outcomes when hospitals experience a surge in admissions. Journal of Health Economics 25(2):365-388. Firth-Cozens, J. 2004. Organisational trust: The keystone to patient safety. Quality & Safety in Health Care 13(1):56-61. Furukawa, M. F., J. King, V. Patel, C. J. Hsiao, J. Adle r-Milstein, and A. K. Jha. 2014. Despite substantial progress in EHR adoption, health information exchange and patient engagement remain low in office settings. Health Affairs (Millwood) 33(9):1672-1679. Gallagher, T., C. Denham, L. Leape, G. Amori, and W. Levinson. 2007. Disclosing unanticipated outcomes to patients: The art and practice. Journal of Patient Safety 3:158-165. Gallagher, T. H., M. M. Mello, W. Levinson, M. K. Wynia, A. K. Sachdeva, L. Snyder Sulmasy, R. D. Truog, J. Conway, K. Mazor, A. Lembitz, S. K. Bell, L. Sokol-Hessner, J. Shapiro, A.-L. Puopolo, and R. Arnold. 2013. Talking with patients about other clinicians' errors. New England Journal of Medicine 369(18):1752-1757. Gandhi, T. 2014. Focus on diagnostic errors: understa nding and prevention. Presentation to the Committee on Diagnostic Error in Health Care, August 7, 2014,Washington, DC. GAO (Government Accoun tability Office). 2010. Patient Safety Act: HHS is in the process of implementing the act, so its effectiveness cannot yet be evaluated . GAO 10-281. Washington, DC: Government Accountability Office. Gertler, S. A., Z. Coralic, A. Lopez, J. C. Stein, and U. Sarkar. 2014. Root cause analysis of ambulatory adverse drug events that present to the emergency department. Journal of Patient Safety . February 27. Epub ahead of print. Gigerenzer, G. 2000. Adaptive thinking: Rationality in the real world . New York: Oxford University Press. Gigerenzer, G., and D. G. Goldstein. 1996. Reasoning the fast and frugal way: Models of bounded rationality. Psychology Review 103:650-669. Goodm an, K. W., E. S. Berner, M. A. Dente, B. Kaplan, R. Koppel, D. Rucker, D. Z. Sa nds, P. Winkelstein, and A. B. o. Directors. 2011. Challenges in ethics, safety, best practices, and oversight regarding HIT vendors, their customers, and patients: A report of an AMIA special task force. Journal of the American Medical Informatics Association 18(1):77-81. THE PATH TO IMPROVE DIAGNOSIS AND REDUCE DIAGNOSTIC ERROR 9-31 PREPUBLICATION COPY: UNCORRECTED PROOFS Govern, P. 2013. Diagnostic management efforts thrive on teamwork. http://news.vanderb ilt.edu/2013/03/diagnostic-man agement-efforts-thrive-on-teamwork/ (accessed May 26, 2015). Graber, M. L. 2005. Diagnostic erro rs in medicine: A case of neglect. Joint Commission Journal on Quality and Patient Safety 31(2):106-113. Graber. 2013. The incidence of diagnostic error in medicine. BMJ Quality and Safety 22(Suppl 2):ii21-ii27. Graber, M. L., R. M. Wachter, and C. K. Cassel. 2012. Bringing diagnosis into the quality and safety equations. JAMA 308(12):1211-1212. Graber, M., R. Trowbridge, J. Myers, U. CA., W. Strull, and M. Kanter. 2014. The next organizational challenge: Finding and addressing diagnostic error. Joint Commission Journal on Quality and Patient Safety 40(3):102-110.. Graedon, T., and J. Graedon. 2014. Let patients help with diagnosis. Diagnosis 1(1) :49-51. Haskell, H. 2014. What's in a story? Lessons from patients who have suffered diagnostic failure. Diagnosis 1(1):53- 54. HealthIT.gov. 2015. Patient ability to electronically vi ew, download & transmit (VDT) health information. www.healthit.gov/providers-profe ssionals/achieve-meaningful-use/core-measures-2/patient-ability- electronically-view-download-tr ansmit-vdt-health-information (accessed March 15, 2015). Hendrich, A., C. K. McCoy, J. Gale, L. Sparkman, and P. Santos. 2014. Ascension health's demonstration of full disclosure protocol for unexpected events during labor and delivery shows promise. Health Affairs (Millwood) 33(1):39-45. Henriksen, K. 2014. Improving diagnostic performance: some unrecognized obstacles. Diagnosis 1(1) :35-38. Henriksen, K., and J. Brady. 2013. The pursuit of better diagnostic performance: a human factors perspective. BMJ Quality & Safety 22(Suppl 2):ii1-ii5. HHS (Department of Health and Human Services). 2010. Improper payments for evaluation and management services cost Medicare billions in 2010 . Washington, DC: HHS Offi ce of Inspector General. HHS. 2015. Patient Safety and Quality Improvement Act of 2005 Statute and Rule. www.hhs.gov/ocr/privacy/psa/regulation/ (accessed March 29, 2015). HIMSS (Healthcare Information and Management Syst ems Society). 2014. What is interoperability? www.himss.org/library/interoperability-standards/what-is-interope rability (accessed February 9, 2015). Hines, S., K. Luna, J. Lofthus, and e. al. 2008. Becoming a high reliability organization: Operational advice for hospital leaders. . Rockville, MD: Agency for Healthcare Research and Quality. Hirt, E., and K. Markman. 1995. Multiple explanation: A co nsider-an-alternative strategy for debiasing judgments. Journal of Personality and Social Psychology 69:1069-1086. Hodges, B., G. Regehr, and D. Martin. 2001. Difficulties in recognizing one's own incompetence: Novice physicians who are unskille d and unaware of it. Academic Medicine 76(10 Suppl):S87-89. Hogarth, R. 2010. On the learning of intuition. In H. Plessner, C. Betsch and T. Betsch (eds.), Intuition in judgment and decision making (pp. 91-105). New York: Taylor & Francis. Hughes, A. M., and E. Salas. 2013. Hierarchi cal medical teams and the science of teamwork. AMA Journal of Ethics 15(6):529-533. h ttp://virtualmentor.ama-assn.org/2013/06/msoc1-1306.html (accessed May 26, 2015). Hysong, S. J., R. G. Best, and J. A. Pugh. 2006. Audit and feedback and clinical practice guideline adherence: Making feedback actionable. Implementation Science 1(9):5-3. http://www.implementationscience. com/content/pdf/1748- 5908-1-9.pdf (accessed June 10, 2015).. Iglehart, J. K. 2009. Health insurers an d medical-imaging policy\u2014A Work in Progress. New England Journal of Medicine 360(10):1030-1037. IOM (Institute of Medicine). 2000. To err is human: Building a safer health system . Washington, DC: National Academy Press. IOM. 2001. Crossing the quality chasm: A new health system for the 21st century . Washington, DC: National Academy Press. IOM. 2002. Fostering rapid advances in health care: Learning from system demonstrations . Washington, DC: The National Academies Press. IOM. 2009. Resident duty hours: Enhancing sleep, supervision, and safety . Washington, DC: The National Academies Press. IOM. 2012. Health IT and patient safety: Buil ding safer systems for better care . Washington, DC: The National Academies Press. IOM. 2013. Best care at ower cost: The path to continuously learning health care in America : The National Academies Press. 9-32 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS IOM. 2014. Graduate medical education that meets the nation's health needs . Washington, DC: The National Academies Press. Jena, A. B., E. C. Sun, and J. A. Romley. 2013. Mortality among high-risk patients with acute myocardial infarction admitted to U.S. teaching-intens ive hospitals in July: A retros pective observational study. Circulation 128(25):2754-2763. Joint Commission. 2005. Health care at the crossroads: Strategies for improving the medical liability system and preventing patient injury . The Joint Commission. www.jointcommission.org/assets /1/18/Medical_Liability.pdf (accessed April 9, 2015). Joint Commission. 2014. Sentinel event policy and procedures. www.jointcommission.org/Sentinel_Event_Policy_and_Procedures/ (accessed June 11, 2015). Joint Commission. 2015. Preventing copy-and-paste errors in the EHR . www.jointcommission.org/issues/article.aspx?Ar ticle=bj%2B%2F2w37MuZrouWveszI1weWZ7ufX%2FP 4tLrLI85oCi0%3D March 27, 2015). Julavits, H. 2014. Diagnose this! How to be your own best doctor. Harper's , April: 25-35. Kachalia, A. 2014. Legal issues in diagnostic error. Pr esentation to the Committee on Diagnostic Error in Health Care, August 7, 2014,Washington, DC. Kachalia, A., and M. M. Mello. 2011. New directions in medical liability reform. New England Journal of Medicine 364(16):1564-1572. Kaiser Permanente. 2012. Smart Partners Ab out Your Health, edited by K. Permanente. Kanter, M. 2014. Diagnostic errors\u2014Patient safety. Pres entation to the Committee on Diagnostic Error in Health Care, August 7, 2014,Washington, DC. Kassirer, J. P., and M. Angell. 1998. Evaluation and management guidelines\u2014Fatally flawed. New England Journal of Medicine 339(23):1697-1698. Khatri, N., G. D. Brown, and L. L. Hicks. 2009. From a blame culture to a just culture in health care. Health Care Management Review 34(4):312-322. Klein, G. 2014. A naturalistic perspective. Input submitte d to the Committee on Diagnostic Error in Health Care, December 20, 2014, Washington, DC. Kostis, W. J., K. Demissie, S. W. Marcella, Y. H. Shao, A. C. Wilson, and A. E. Moreyra. 2007. Weekend versus weekday admission and mortality from myocardial infarction. New England Journal of Medicine 356(11):1099-1109. Kotter. 1995. Leading change: Why transformation efforts fail. Harvard Business Review . 73(2): 59-67. Kotter, J. 2012. The key to changing organizational culture. Forbes , September 27. www.forbes.com/sites/johnkotter/20 12/09/27/the-key-to-changing-organi zational-culture/ (accessed March 9, 2015. Kroft, S. H. 2014. Statement of Steven H. Kroft, MD, FASCP, American Society for Clinical Pathology (ASCP). Presentation to the Committee on Diagnostic Error in Health Care, April 28, 2014, Washington, DC. Kuhn, T., P. Basch, M. Barr, and T. Yackel. 2015. Clinical documentation in the 21st century: Executive summary of a policy position paper from the American College of Physicians. Annals of Internal Medicine 162(4):301-303. Lacson, R., L. M. Prevedello, K. P. Andriole, S. D. O'C onnor, C. Roy, T. Gandhi, A. K. Dalal, L. Sato, and R. Khorasani. 2014. Four-year impact of an alert notification system on closed-loop communication of critical test results. American Journal of Roentgenology 203(5):933-938. Larson, E. B. 2002. Measuring, monitoring, and reduci ng medical harm from a systems perspective: A medical director's personal reflections. Academic Medicine 77(10):993-1000. Leape. 2010. Q&A with Lucian Leap e, M.D., adjunct professor of h ealth policy, Harvard University. www.commonwealthfund.org/publications/newsletters /states-in-action/2010/jan/january-february- 2010/ask-the-expert/ask-the-expert (accessed September 23, 2014). Leape, L. L., T. A. Brennan, N. Laird, A. G. Lawthers, A. R. Localio, B. A. Barnes, L. Hebert, J. P. Newhouse, P. C. Weiler, and H. Hiatt. 1991. The nature of adverse ev ents in hospitalized patients: Results of the Harvard Medical Practice Study II. N ew England Journal of Medicine 324(6):377-384. Lundberg, G. D. 1998. Low-tech autopsies in the era of high-tech medicine: Continued value for quality assurance and patient safety. JAMA 280(14):1273-1274. Macy Foundation and Carnegie Foundation for the Advancement of Teaching. 2010. Educating nurses and physicians: Towards new horizons. Advancing inter-professional education in academic health centers , conference summary. June 16-18, 2010, Palo Alto, California. THE PATH TO IMPROVE DIAGNOSIS AND REDUCE DIAGNOSTIC ERROR 9-33 PREPUBLICATION COPY: UNCORRECTED PROOFS Marceglia, S., Fontelo, P., Ackerman, M.J. 2015. Transforming consumer health informatics: Connecting CHI applications to the health-IT ecosystem. Journal of the American Medical Informatics Association 22(e1):e210-212. Marewski, J. N., and G. Gigerenzer. 2012. Heuristic decision making in medicine. Dialogues Clinical Neuroscience 14(1):77-89. Marx, D. A. 2001. Patient safety and the \"just cultur e\": A primer for health care executives. Medical Event Reporting System-Transfusion Medicine. http://www.safer.h ealthcare.ucla.edu/safer/archive/ahrq/Final PrimerDoc.pdf (accesse d June 7, 2015). McDonald, K. M. 2014. The diagnostic field's players and interactions: From the inside out. Diagnosis 1(1) :55-58. MedPAC (Medicare Payment Advisory Commission). 2014. Physician and other health professional payment system. www.medpac.gov/ -documents-/payment-basics/pag e/2/ (accessed March 17, 2015). Mello, M. M., D. M. Studdert, and A. Kachalia. 2014. The medical liability climate and prospects for reform. JAMA 312(20):2146-2155. Miller, H. D. 2014. How healthcare pa yment systems and benefit designs can support more accurate diagnosis. Input submitted to the Committee on Diagnostic Error in Health Care, December 29 , 2014, Washington, DC. Milstead, J. A. 2005. The culture of safety. Policy, Politics, & Nursing Practice 6(1):51-54. Moran, J. W., and B. K. Brightman. 2000. Leading organizational change. Journal of Workplace Learning 12(2):66- 74. Moses, H., 3rd, D. H. Matheson, S. Cairns-Smith, B. P. George, C. Palisch, and E. R. Dorsey. 2015. The anatomy of medical research: U.S. and international comparisons. JAMA 313(2):174-189. Mumma, G., and W. Steven. 1995. Procedural debiasing of primary/anchoring effects in clinical-like judgments. Journal of Clinical Psychology 51:841-853. Mussweiler, T., F. Strack, and T. Pfeiffer. 2000. Over coming the inevitable anchoring effect: Considering the opposite compensates for selective accessibility. Personality and Social Psychology Bulletin 26(9):1142- 1150. National Commission on Physician Payment Reform. 2013. Report of the National Commission on Physician Payment Reform . Washington, DC: National Commission on Physician Payment Reform. http://physicianpaymentcommission.org/ report/ (accessed March 17, 2015). National Quality Forum. 2011. Serious reportable events in healthcare\u20142011update: A consensus report . Washington, DC: National Quality Forum. http://www.qualityforum.org/projects/hacs_and_sres.aspx (accessed June 11, 2015). Newman-Toker, D. 2014. Prioritization of diagnostic erro r problems and solutions: Concepts, economic modeling, and action plan. Presentation to the Committee on Diagnostic Error in Health Care, August 7, 2014, Washington, DC. Newman-Toker, D. E., K. M. McDonald, and D. O. Meltzer. 2013. How much diagnostic safety can we afford, and how should we decide? A health economics perspective. BMJ Quality and Safety 22(Suppl 2):ii11-ii20. NPSF (National Patient Safety Foundation) and SIDM (Soc iety to Improve Diagnosis in Medicine. 2014. Checklist for getting the right diagnosis http://www.npsf.org/?page=rightdiagnosis and http://c.ymcdn.com/sites/www. npsf.org/resource/collectio n/930A0426-5BAC-4827-AF94- 1CE1624CBE67/Checklist-for-Gettin g-the-Right-Diagnosis.pdf (accessed June 26, 2015). Ober, K. P. 2015. The electronic health record: Are we the tools of our tools? The Pharos 78(1):8-14. ONC (Office of the National Coordinator for Health Information Technology). 2014. Health information technology adverse event reporting: Analysis of two databases. Washington, DC: The Office of the National Coordinator for Health Information Technology. Otte-Trojel, T., A. de Bont, J. van de Klundert, and T. G. Rundall. 2014. Characteristics of patient portals developed in the context of health information exchanges: Early policy effects of incentives in the meaningful use program in the United States. Journal of Medical Internet Research 16(11):e258. Papa, F. 2014. A response to the IOM's ad hoc committee on Diag nostic Error in Health Care. Input submitted to the Committee on Diagnostic Error in Health Care, October 24, 2014, Washington, DC. Patel, V., N. Yoskowitz, and J. Arocha. 2009. Towards e ffective evaluation and reform in medical education: A cognitive and learning sciences perspective. Advances in Health Sciences Education 14(5):791-812. Patel, V., M. J. Swain, J. King, and M. F. Furukawa. 201 3. Physician capability to electronically exchange clinical information, 2011. American Journal of Managed Care 19(10):835-843. Pecukonis, E., O. Doyle, and D. L. Bliss. 2008. Reducing barriers to interprofessional training: Promoting interprofessional cultural competence. Journal of Interprofessional Care 9-34 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Portilla, L. M., and B. Alving. 2010. Reaping the benef its of biomedical research: Partnerships required. Science Translational Medicine 2(35):35cm17. PSO Privacy Protection Center. 2014. AHRQ Common Formats. https://www.psoppc.org/web/patientsafety (accessed August 10, 2015). Redelmeier, D. A. 2005. Improving patient care. The cognitive psychology of missed diagnoses. Annals of Internal Medicine 142(2):115-120. Reiling, J., G. Hughes, and M. Murphy. 2008. Chapter 28: The impact of facility design on patient safety. In R. G. Hughes (ed.), Patient safety and quality: An evidence-based handbook for nurses (pp. 700-725). Rockville, MD: Agency for Healthcare Research and Quality (US). Richardson, W. S. 2007. We should overcome th e barriers to evidence-based clinical diagnosis! Journal of Clinical Epidemiology 60(3):217-227. Richardson, W. S. 2014. Twenty suggestions that could improve clinical diagnosis and reduce diagnostic error. Input submitted to the Committee on Diagnostic Error in Health Care, October 23, 2014, Washington, DC. Rosenthal, M. 2014. Comments to the Institute of Medicine Committee on Diagnostic Error in Health Care. Iinput submitted to the Committee on Diagnostic Error in Health Care, December 29 , 2014, Washington, DC. RTI International. 2014. RTI International to de velop road map for health IT safety center. www.rti.org/newsroom/news.cf m?obj=FCC8767E-C2DA-EB8B-AD7E 2F778E6CB91A (accessed March 27, 2015). Sage, W. M., T. H. Gallagher, S. Armstrong, J. S. Cohn, T. McDonald, J. Gale, A. C. Woodward, and M. M. Mello. 2014. How policy makers can smooth the way for communication-and-resolution programs. Health Affairs (Millwood) 33(1):11-19. Sarkar, U., D. Bonacum, W. Strull, C. Spitzmueller, N. Jin, A. Lopez, T. D. Giardina, A. N. Meyer, and H. Singh. 2012. Challenges of making a diagnosis in the outpa tient setting: A multi-site survey of primary care physicians. BMJ Quality and Safety 21(8):641-648. Sarkar, U., B. Simchowitz, D. Bonacum, W. Strull, A. Lo pez, L. Rotteau, and K. G. Shojania. 2014. A qualitative analysis of physician perspectives on missed and delayed outpatient diagnosis: The focus on system-related factors. Joint Commission Journal on Quality and Patient Safety 40(10):461-470. Sarter, N. 2014. Use(r)-centered design of health IT: Challenges and lessons learned. Presentation to theCommittee on Diagnostic Error in Health Care, August 7, 2014,Washington, DC. Schein. 2004. Organizational culture and leadership, 3rd ed .San Francisco, CA: Jossey-Bass. Schiff, G. D. 2008. Minimizing diagnostic error: The importance of follow-up and feedback. American Journal of Medicine 121(5):S38-S42. Schiff, G. D. 2014a. Diagnosis and diagnostic errors: time for a new paradigm. BMJ Quality and Safety 23(1):1-3. Schiff, G. D.. 2014b. Presentation to IOM Committee on Di agnostic Error in Health Care. Presentation to the Committee on Diagnostic Error in Health Care, August 7, 2014,Washington, DC. Schiff, G. D., and D. W. Bates. 2010. Can electronic clinical documentation help prevent diagnostic errors? New England Journal of Medicine 362(12):1066-1069. Schiff, G. D., S. Kim, R. Abrams, K. Cosby, A. S. Elstei n, S. Hasler, N. Krosnjar, R. Odwanzy, M. F. Wisniewsky, and R. A. McNutt. 2005. Diagnosing diagnosis errors: Lessons from a multi-institutional collaborative project for the diagnostic error evaluation and research project investigators . Rockville, MD: Agency for Healthcare Research and Quality. www.ahrq.g ov/qual/advances/ (accessed June 10, 2015). Schiff, G. D., O. Hasan, S. Kim, R. Abrams, K. Cosby, B. L. Lambert, A. S. Elstein, S. Hasler, M. L. Kabongo, N. Krosnjar, R. Odwazny, M. F. Wisniewski, and R. A. McNutt. 2009. Diagnostic error in medicine: Analysis of 583 physician-reported errors. Archives of Internal Medicine 169(20):1881-1887. Schmitt, M., A. Blue, C. A. Aschenbrener, and T. Viggiano. 2011. Core competen cies for interprofessional collaborative practice: reforming health care by transforming health professionals' education. Academic Medicine 86(11):1351. Shojania, K., E. Burton, K. McDonald, et al. 2002. The autopsy as an outcome and performance measure. AHRQ Publication No. 03-E002. Rockville, MD: Agency for Healthcare Research and Quality. Shojania, K. G., E. C. Burton, K. M. McDonald, and L. Goldman. 2002. Autopsy as an outcome and performance measure. Rockville, MD: Agency for Healthcare Research and Quality. Shojania, K. G. 2010. The elephant of patient safety: What you see depends on how you look. Joint Commission Journal of Quality and Patient Safety 36(9):399-401. Shojania, K. G., E. C. Burton, K. M. McDonald, and L. Goldman. 2003. Changes in rates of autopsy-detected diagnostic errors over time: A systematic review. JAMA 289(21):2849-2856. THE PATH TO IMPROVE DIAGNOSIS AND REDUCE DIAGNOSTIC ERROR 9-35 PREPUBLICATION COPY: UNCORRECTED PROOFS Silow-Carroll, S., T. Altera s, J. A. Meyer. 2007. Hospital quality improvement: Stra tegies and lessons from U.S. hospitals. The Commonwealth Fund. http://www.commonwealthfund.org/~/media/files/publications/fund- report/2007/apr/hospital-quality-improvement--strategies-and-lessons-from-u-s--hospitals/silow- carroll_hosp_quality_improve_str ategies_lessons_1009-pdf.pdf (accessed June 7, 2015). Singh, H. 2013. Diagnostic errors: Moving beyond \"no respect\" and getting ready for prime time. BMJ Quality & Safety 22(10):789-792. Singh, H. 2014. Building a robust conceptual foundation for defining and measuring diagnostic errors. Presentation to the Committee on Diagnostic Error in Health Care, August 7, 2014,Washington, DC. Singh, H., and D. F. Sittig. 2015. Advancing the science of measurement of diagnostic errors in healthcare: The Safer Dx framework. BMJ Quality & Safety 24:103-110. Singh, H., A. D. Naik, R. Rao, and L. A. Petersen. 2008. Reducing diagnostic errors through effective communication: Harnessing the power of information technology. Journal of General Internal Medicine 23(4):489-494. Singh, H., T. D. Giardina, A. N. D. Meyer, S. N. Forjuoh, M. D. Reis, and E. J. Thomas. 2013. Types and origins of diagnostic errors in primary care settings. JAMA Internal Medicine 173(6):418-425. Singh, H., A. N. D. Meyer, and E. J. Thomas. 2014. The frequency of diagnostic errors in outpatient care: Estimations from three large observational studies involving US adult populations. BMJ Quality & Safety 23(9). DOI: 10.1136/bmjqs-2013-002627.Sittig, D. F., and H. Singh. 2010. A new sociotechnical model for studying health information technology in complex adaptive healthcare systems. Quality and Safety in Health Care 19(Suppl 3):i68-i74. Sorra, J., T. Famolaro, N. D. Yount, and e. al. 2014. Hospital Survey on Patient Safety Culture\u20142014 user comparative database report. AHRQ Publication No. 14-0019-EF. Ro ckville, MD: Agency for Healthcare Research and Quality. Tehrani, A., H. Lee, S. Mathews, A. Shore, M. Ma kary, P. Pronovost, and D. Newman-Toker. 2013. 25-year summary of U.S. malpractice clai ms for diagnostic errors 1986-2010; An analysis from the National Practitioner Data Bank. BMJ Quality and Safety 22:672-680. Thomas, E. J. 2014. Safety culture and diagnostic error: A rising tide lifts all boats. Presentation to the Committee on Diagnostic Error in Health Care, November 5, 2014,Washington, DC. Trowbridge, R. 2014. Diagnostic performance: Measur ement and feedback. Paper presented to the Committee on Diagnostic Error in Health Care, August 7, 2014,Washington, DC. Trowbridge, R., G. Dhaliwal, and K. Cosby. 2013. Educational agenda for diagnostic error reduction. BMJ Quality and Safety 22(Suppl 2):ii28-ii32. Verghese, A. 2008. Culture shock--patient as icon, icon as patient. New England Journal of Medicine 359(26):2748- 2751. Wachter, R. M. 2010. Why diagnostic errors don't get any respect\u2014And what can be done about them. Health Affairs (Millwood) 29(9):1605-1610. Wegwarth, O., W. Gaissmaier, and G. Gigerenzer. 2009. Smart strategies for doctors and doctors-in-training: Heuristics in medicine. Medical Education 43(8):721-728. Weick, K. E., and K. M. Sutcliffe. 2011. Business organizations must learn to operate \"mindfully\" to ensure high performance. http://www.bus.umich.edu/FacultyRes earch/Research/ManagingU nexpected.htm (accessed May 26, 2015). Weingart, S. N., O. Pagovich, D. Z. Sands, J. M. Li , M. D. Aronson, R. B. Davis, D. W. Bates, and R. S. Phillips. 2005. What Can hospitalized patients tell us about adverse events? Learning from patient-reported incidents. Journal of General Internal Medicine 20(9):830-836. Wennberg, D. 2014. Comments for the Institute of Medicine 's Committee on Diagnostic Error in Health Care. Input submitted to the Committee on Diagnostic Error in Health Care, December 29, 2014,Washington, DC. WHO (World Health Organization). 2005. WHO draft guidelines for adverse event reporting and learning systems . Geneva, Switzerland: WHO. Zimmerman, T. M., and G. Amori. 2007. Including patients in root cause and system failure analysis: Legal and psychological implications. Journal of Healthcare Risk Management 27(2):27-34. Zwaan, L., M. de Bruijne, C. Wagner, A. Thijs, M. Sm its, G. van der Wal, and D. R. Timmermans. 2010. Patient record review of the incidence, consequences, and causes of diagnostic adverse events. A rchives of Internal Medicine 170(12):1015-1021. Zwaan, L., G. D. Schiff, and H. Singh. 2013. Advancing the research agenda for diagnostic error reduction. BMJ Quality & Safety 22(Suppl 2):ii52-ii57. A-1 Appendix A Glossary Active error \u2014an error involving frontline clinicians (sometimes referred to as an error occurring at the \"sharp end\" of patient safety) (IOM, 2000). Adverse event\u2014 \"an event that results in un intended harm to the patient by an act of commission or omission rather than by the underlying diseas e or condition of the patient\" (IOM, 2004, p. 32). Burnout\u2014 condition due to occupational stress re sulting from demanding and emotional relationships between health care professiona ls and patients that is marked by emotional exhaustion, a negative attitude towards one's pa tients, and the belief that one is no longer effective at work with pa tients (Bakker et al., 2005). Calibration\u2014the process of a clinician becoming aware of his or her dia gnostic abilities and limitations through feedback. Clinical decision support (CDS)\u2014 a health information technology component that \"provides clinicians, staff, patients or other individuals with knowledge and person-specific information, intelligently filtered or presented at appropriate times, to enhance health and health care. CDS encompasses a variety of tools to enhance decisi on making in the clinical workflow. These tools include computerized alerts and reminders to ca re providers and patients ; clinical guidelines; condition-specific order sets; focused patient data reports and summaries; documentation templates; diagnostic support; and contextually relevant reference information, among other tools\" (HealthIT.gov, 2014). Clinical reasoning \u2014\"the cognitive process that is necessary to evaluate and manage a patient's medical problems\" (Barrows, 1980, p. 19). Cognitive autopsy \u2014a form of cognitive and affective root cause analysis that focuses on factors that can affect cognition such as ambient cond itions, physical state (fatigue), and cognitive heuristics (Croskerry, 2005). Cognitive bias \u2014a predisposition to think in a way that leads to systematic failures in judgment. Cognitive biases often result from heuristics that fail in a predictable manner, but they can also be caused by affect and motivation (Kahneman, 2011). Communication and resolution program \u2014a program that encourag es \"the disclosure of unanticipated care outcomes to affected patien ts and their families and proactively seek[s] A-2 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS resolutions, which may include providing an apology; an explanation; and, where appropriate, an offer of reimbursement, compensation, or both\" (Mello et al., 2014, p. 20). Defensive medicine \u2014\"occurs when doctors order tests, pro cedures, or visits, or avoid high-risk patients or procedures, primarily (but not n ecessarily solely) to reduce their exposure to malpractice liability\" (OTA, 1994, p. 13). Diagnosis\u2014 the explanation of a pa tient's health problem. Diagnostic process \u2014a complex, patient-centered, collabo rative activity that involves information gathering and clini cal reasoning with the goal of de termining a patient's health problem. Diagnostic error\u2014 the failure to (a) establish an accurate and timely explanation of the patient's health problem(s) or (b) communicate that explanation to the patient. Diagnostic management team\u2014 a group of diagnostic specialist s (pathologists, radiologists, and other diagnosticians) that offer participating health care professionals assistance in selecting appropriate diagnostic tests and interpreting diagnostic te st results (Govern, 2013). Dual process theory \u2014a model of cognition that proposes tw o processes\u2014fast, intuitive system 1, and slow, analytic system 2 processes\u2014are responsible for human reasoning and decision making. Electronic health record (EHR)\u2014 a real-time, patient-centered reco rd that contains information about a patient's medical history, diagnoses, medications, immunizati on dates, allergies, radiology images, and lab and te st results (HealthIT.gov, 2013). Error\u2014 \"failure of a planned act ion to be completed as intended (i.e., error of execution) and the use of a wrong plan to achieve an aim (i.e., error of planning). It also includes failure of an unplanned action that should have been co mpleted (omission)\" (IOM, 2000 and 2004, p. 330). Error recovery \u2014refers to the early identification of an error in the diagnostic process so that actions can be taken to reduce or avert negativ e effects resulting from the error (IOM, 2000). Feedback \u2014information on the accuracy of diagnosi s and diagnostic performance that is provided to individual health ca re professionals, care teams, or organizatio nal leaders. Harm\u2014 \"hurtful or adverse outcomes of an action or event, whether temporary or permanent\" (IOM, 2011, p. 240). Clinician survey\u2014a questionnaire (writte n, telephone, interview, We b-based) that obtains clinicians' self-reports about di agnostic errors they have ma de or what they know about diagnostic errors made by other clinicians. GLOSSARY A-3 PREPUBLICATION COPY: UNCORRECTED PROOFS Health information technology\u2014 \"a technical system of computers and software that operates in the context of a larger sociotechnical system; that is, a collection of hardware and software working in concert within an organization that includes people, proces ses, and technology\" (IOM, 2012, p. 2). Health literacy\u2014 \"the degree to which indivi duals have the capacity to obtain, process, and understand basic health information and services needed to make appropriate health care decisions and services needed to pr event or treat illness\" (HRSA, 2015). Heuristic \u2014a special type of system 1 process that can facilitate decision making but can also lead to errors. Sometimes referred to as cognitive strategies or mental s hortcuts, heuristics are automatically and unconsciously employed durin g reasoning making (Cosmides and 1994, 1996; Gigerenzer, 1996; Klein, 1998, Lipshitz et al., 2001). Human factors (or ergonomics) \u2014\"the scientific disc ipline concerned with the understanding of interactions among humans and other elements of a system, and the profession that applies theory, principles, data, and methods to desi gn in order to optimi ze human well-being and overall system performance. Ergonomists contribute to the design and evaluation of tasks, jobs, products, environments, and systems in order to ma ke them compatible with the needs, abilities, and limitations of people\" (IEA, 2000). Integrated practice unit\u2014 a group of clinicians and non-clinic ians who are responsible for the comprehensive care of a specific me dical condition and the associat ed complications, or a set of closely related conditions (Porter, 2010). Interoperability \u2014the ability of different informa tion technology systems and software applications to communicate, exchange data, and use the information that has been exchanged (HIMSS, 2014). Inter-rater reliability\u2014 the degree to which two or more i ndependent raters can consistently and systematically apply a rubric to assign scor es to observations (or participants) based on a pre-established scoring protoc ol (or rubric) (Stemler, 2007). Intra-rater reliability\u2014 the degree of agreement among mu ltiple repetitions of a scoring protocol performed by a single rater. Latent error\u2014 \"errors in the design, organization, traini ng, or maintenance that lead to operator errors and whose effects typically lie dormant in the system for lengthy periods of time\" (IOM, 2000, p. 210). Latent errors are more removed from the control of frontline clinicians and can include failures in organizations and design that enable active erro rs to cause harm (often called the blunt end of patient sa fety) (AHRQ, 2015; IOM, 2000). Learning sciences \u2014the multidisciplinary science that st udies how people learn in order to optimize education and training. A-4 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Morbidity and mortality conferences \u2014forums that allow clinicians to discuss and learn from errors that have occurred within an organization. Near miss\u2014a failure in the diagnostic process that does not lead to a di agnostic error. Overdiagnosis\u2014 \"when a condition is diagnosed that would otherwise not go on to cause symptoms or death\" (Welch and Black, 2010, p. 605) Patient portal\u2014\" Secure, online patient access to health in formation and serves as an interface to provide useful information to both patie nts and health professionals\" (IOM, 2012, p. 118). Patient safety\u2014 \"freedom from accidental injury; ensuring patient safety involves the establishment of operational systems and proces ses that minimize the likelihood of errors and maximizes the likelihood of in tercepting them when they occur\" (IOM, 2000, p. 211); the prevention of harm caused by errors of commission and omission (IOM, 2004). Patient survey \u2014a questionnaire (written, telephone, interview, web-based) that obtains patients' self-reports about diagnostic errors they have experienced or thei r awareness of di agnostic errors experienced by others. Postmortem examination (autopsy)\u2014 \"an external and internal examination of the body after death using review of medical r ecords, surgical techniques, mi croscopy, and laboratory analysis. It is performed by a pathologist, a medical doctor specially trained for the procedure who is able to recognize the effects of disease on the body\" (CAP, 2014). Quality of care\u2014\"degree to which health services for individuals and populations increase the likelihood of desired health outcomes and are co nsistent with current professional knowledge\" (IOM, 1990, p. 211 p. 128). Root cause analysis (RCA)\u2014 \"a structured method used to an alyze serious adverse events. Initially developed to analyze industrial accidents, RCA is now widely deployed as an error analysis tool in health care\" (AHRQ, 2012). Safe\u2014 \"avoiding injuries to patients from the care that is intended to help them\" (IOM, 2001, p. 39). Safe care\u2014 \"involves making evidence-based clinical decisions to maximize the health outcomes of an individual and to minimize the pot ential for harm. Both errors of commission and omission should be avoided\" (IOM, 2004, p. 334). Second review \u2014a process used in pathology and radi ology in which a second health care professional reviews the same inform ation as the first health care professional in order to detect discrepancies in results that may be indicative of error. Simulation \u2014\"allows researchers and practitioners to test new clinical processes and enhance individual and team skills before encountering patients. Many simulation applications involve GLOSSARY A-5 PREPUBLICATION COPY: UNCORRECTED PROOFS mannequins that present with symptoms and re spond to the simulated treatment, analogous to flight simulators used by pilots\" (AHRQ, 2014). Standardized patient \u2014\"a person carefully recruited and trai ned to take on the characteristics of a real patient thereby affording the student an op portunity to learn and to be evaluated on learned skills in a simulated clinical environment\" (Johns Hopkins, 2015). System\u2014 \"set of interdependent elements interacti ng to achieve a common aim. These elements may be both human and nonhuman (equipment, technologies, etc.)\" (IOM, 2000, p. 211). System 1\u2014fast (non-analytical, intuitive) automatic cogni tive processes that require very little working memory capacity and are often trigge red by stimuli or result from overlearned associations or implicitly learned activities. System 2\u2014slow (reflective, analytical) cognitive processes that pl ace a heavy load on working memory and involve hypothetical and counterfactual reasoning (Evans and Stanovich, 2013; Stanovich and Toplak, 2012). Usability\u2014 \"the extent to which a product can be used by specified users to achieve specified goals with effectiveness, effici ency and satisfaction in a spec ified context of use\" (ISO, 1998). Voluntary reporting\u2014\"those reporting systems for which the reporting of patient safety events is voluntary (not mandatory). Generally, reports on all types of events are accepted\" (IOM, 2004, p. 335). Workflow \u2014the sequence of physical and cognitive tasks performed by various people within and between work environm ents (Carayon et al., 2010). REFERENCES AHRQ (Agency for Healthcare Research and Quality). 2012. Patient safety primers: Root cause analysis. http://psnet.ahrq.gov/prim er.aspx?primerID=10 ( accessed 04/11/14, 2014). 2014. Improving patient safety through simulation research. www.ahrq.gov/research/findings/factsheets/errors-safet y/simulproj11/index.html (accessed April 10, 2015. AHRQ. 2015. Patient safety network: Patient safety primers. Systems approach. http://psnet.ahrq.gov/prim er.aspx?primerID=21 ( accessed May 8, 2015). Bakker, A. B., P. M. Le Blanc, and W. B. Schaufeli. 2005. Burnout contagion among intensive care nurses. Journal of Advanced Nursing 51(3):276-287. Barrows, H. S. 1980. Problem-based learning: An approach to medical education. New York: Springer Publishing Company. CAP (College of American www.cap.org/apps//cap.portal?_nfpb=true&cntvwrP tlt_actionOverride=%2Fpor P., B. T. Karsh, R. Cartmill, et al. 2010. Incorporating health information technology into workflow redesign: Request for information summary report. Rockville, MD: Agency for Healthcare Research and Quality. Cosmides, L., and J. Tooby. 1994. Better than rational: Evolutionary psychology and the invisible hand. American Economic Review . 84(2):327-332. A-6 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Cosmides, L.,. 1996. Are humans good intuitive statisticians after all? Rethinking some conclusions from the literature on judgment under uncertainty. Cognition 58(1):1-73. Croskerry, P. 2005. Diagnostic failu re: A cognitive and affective approach. Advances in Patient Safety 2:241-254. Evans, J. S. B. T., and K. E. Stanovich. 2013. Dual-process theories of higher cognition: Advancing the debate. Perspectives on Psychological Science 8(3):223-241. Gigerenzer, G. 2000. Adaptive thinking: Rationality in the real world . New York: Oxford University Press. Gigerenzer, G., and D. G. Goldstein. 1996. Reasoning the fast and frugal way: Models of bounded rationality. Psychology Review 103:650-669. Govern, P. 2013. Diagnostic management efforts thrive on teamwork. http://news.vanderb ilt.edu/2013/03/diagnostic -management-efforts-thri ve-on-teamwork/ (accessed February 11, 2015). HealthIT.gov. 2013. Learn EHR basics. www.healthit.gov/p roviders-professionals/learn-ehr-basics (accessed March 11, 2014). HealthIT.gov. 2014. Clinical decision support. www.hea lthit.gov/policy-researchers-implementers/clinical-decision- support-cds (accessed April 9, 2014). HIMSS (Healthcare Information and Management Syst ems Society). 2014. What is interoperability? www.himss.org/library/interoperability-standards/what-is-interope rability (accessed February 9, 2015). HRSA (Health Resources and Services Admi nistration). 2015. About health literacy. www.hrsa.gov/publichealth/h ealthliteracy/healthlitabout.html (accessed August 10, 2015). IEA (International Ergonomics Associa tion). 2000. The discipline of ergonom ics. www.iea.cc/ (accessed April 10 2015). IOM (Institute of Medicine). 1990. Medicare: A strategy for quality assurance, Volume II . Washington, DC: National Academy Press. IOM. 2000. To err is human: Building a safer health system . Washington, DC: National Academy Press. IOM. 2001. Crossing the quality chasm: A new health system for the 21st century . Washington, DC: National Academy Press. IOM. 2004. Patient safety: Achieving a new standard for care . Washington, DC: The National Academies Press. IOM . 2011. Finding what works in health care: Standards for systematic reviews . Washington, DC: The National Academies Press. IOM. 2012. Health IT and patient safety: Buil ding safer systems for better care . Washington, DC: The National Academies Press. ISO (International Organization for Standardization). 1998. Ergonomic requirements for office work with visual display terminals (VDTS)\u2014Part 11: Guidance on usability . www.iso.org/obp/ui/#iso:std:iso:9241:-11:ed- 1:v1:en (accessed February 25, 2015). Johns Hopkins. 2015. Standardized patient program. www.hopkinsmedicine.org/simulati on_center/training/standardized_pa tient_program/ (accessed April 10, 2015). Kahneman, D. 2011. Thinking fast and slow . New York: Farrar, Strauss and Giroux. Klein, G. 1998. Sources of power: How people make decisions. Cambridge, MA: MIT Press. Klein, G. 2003. The power of intuition . New York, NY: Doubleday. Lipshitz, R., G. Klein, J. Orasanu, and E. Salas. 2001. Taking stock of naturalistic decision making. Journal of Behavioral Decision Making 14(5):331-352. Mello, M. M., R. C. Boothman, T. McDonald, J. Driver, A. Lembitz, D. Bouwmeester, B. Dunlap, and T. Gallagher. 2014. Communication-and-resolution programs: The challenges and lessons learned from six early adopters. Health Affairs 33(1):20-29. Office of Technology Assessment. 1994. Defensive Medicine and Medical Malpractice, OTA-H--6O2. Washington, DC: U.S. Government Printing Office. Porter, M. E. 2010. What is value in health care? New England Journal of Medicine 363(26):2477-2481. Stanovich, K. E., and M. E. Toplak. 2012. Defining features versus incidental correlates of type 1 and type 2 processing. Mind & Society 11(1):3-13. Stemler, S. E. 2007. Interrater reliability. In N. J. Salkind (ed.), Encyclopedia of Measurement and Statistics . Thousand Oaks, CA: SAGE Publications. Welch, H. G., and W. C. Black . 2010. Overdiagnosis in cancer. Journal of the National Cancer Institute 102(9):605-613. B-1 PREPUBLICATION COPY: UNCORRECTED PROOFS Appendix B Committee Member and Staff Biographies COMMITTEE MEMBER BIOGRAPHIES John R. Ball, M.D., J.D., (Chair) is an executive vice president emeritus of the American College of Physicians. He is a graduate of Emor y University, received a J.D. and an M.D. from Duke University, and was a Robert Wood Johns on Clinical Scholar at George Washington University. After a residency in internal medicine at Duke University, he held several health policy positions in the U.S. Public Health Service and was a senior policy analyst in the Office of Science and Technology Policy, Executive Office of the President. Dr. Ball originated the Washington office of the American College of Physicians and served as its executive vice president for 8 years. He subsequently was pres ident and chief executive officer of Pennsylvania Hospital and an executive vice president and chie f executive officer of the American Society for Clinical Pathology. In retirement, he has recently served as interim president of the Milbank Memorial Fund, on whose board he also serves. He is also a member of the board of Mission Health System in Asheville, North Carolina, wher e he resides. Dr. Ball was elected a member of the National Academy of Medicine in 1992. Elisabeth Belmont, Esq., serves as the corporate counsel for MaineHealth, which is ranked among the nation's top 100 integrated health ca re delivery networks and has combined annual revenues of nearly $2 billion. Sh e has significant experience in the defense of professional liability claims and educates health care provider s on using \"lessons learne d\" from such claims to inform quality improvement and patient safe ty initiatives to minimize medical errors. Ms. Belmont's practice also focuses on electronic health information network strategy development and implementation to support inno vations in care delivery and pa yment models as well as the use of \"big data\" to enhance care processes a nd clinical outcomes. She has participated in a number of national initiatives where quality impr ovement, patient safety and health information technology intersect including ev ents sponsored by the Department of Health and Human Services (HHS) Office of the National Coordina tor, HHS Office of the Inspector General, American Health Lawyers Association, American Society of Healthcare Risk Management, and American Association for the A dvancement of Science. Ms. Belmont is a member of the Board on Health Care Services of the Institute of Me dicine of the National Academies. She co-chairs the National Quality Forum's Health IT Patient Safety Measures Standing Committee. Additionally, Ms. Belmont serves as a member of the Editorial Advisory Board of Bloomberg BNA's Health Law Reporter. Ms. Belmont is a past president of the American Health Lawyers Association, a former chair of the association's health information and technology practice group, and a former chair of the association's Qual ity in Action Task Force. She also served as principal investigator for a re search study funded by the American Society of Healthcare Risk Management, Minimizing EHR-related Serious Safety Events and Related Medical Malpractice B-2 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS Liability. Ms. Belmont is the recipient of numerous honors, including being named by Modern Healthcare as one of the 2007 Top 25 Most Powerful Women in Healthcare and being selected to receive the 2014 David J. Greenburg Service Awa rd. She is a nationally recognized author and lecturer on a myriad of health law topics. Robert A. Berenson, M.D., is an Institute Fellow at the Urban Institute. He is an expert in health care policy, particularly Me dicare, with experience practici ng medicine, serving in senior positions in two Administrations, and helping organize and manage a successful preferred provider organization. His primary research and policy interests cu rrently are in the areas of payment reform, provider and plan pricing power, quality improvement, performance measurement, and delivery system reform. Dr. Berenson recently completed a three year term on the Medicare Payment Advisory Commission (Med PAC), the last two as Vice-Chair. From 1998-2000, he was in charge of Medicare payment pol icy and private health plan contracting in the Centers for Medicare and Medi caid Services. Previously, he se rved as an Assistant Director of the Carter White House Domestic Policy Sta ff. Dr. Berenson is a board-certified internist who practiced for twenty years, the last twelve in a Washington, D.C. group practice, and while practicing helped organize and manage a success ful preferred provider or ganization serving the Washington, D.C. metropolitan area. He was co-author, with Walter Zelman, of The Managed Care Blues & How to Cure Them , and, with Rick Mayes, Medicare Prospective Payment and the Shaping of U.S. Health Care . He is a graduate of the Mount Sinai School of Medicine, a Fellow of the American College of Physicians, and on the adjunct faculty of the George Washington University School of Public Health. Pascale Carayon, Ph.D., is the Procter & Gamble Bascom Professor in Total Quality in the Department of Industrial and Systems Engineering and the director of the Center for Quality and Productivity Improvement at the University of Wisconsin-Madison. She leads the Systems Engineering Initiative for Patient Safety (S EIPS) at the University of Wisconsin-Madison (http://cqpi.engr.wisc.edu/seips_home). SEIPS is an internationally known interdisciplinary research program that brings together rese archers from human factors and ergonomics with researchers from medicine, surgery, nursing, pharmacy, and health se rvices research. Dr. Carayon received her engineer diploma from the Ecole Centrale de Paris, France, in 1984 and her Ph.D. in industrial engin eering from the University of Wisconsin-Madison in 1988. Dr. Carayon's research belongs to the discipline of human factors engineering, in particular, macroergonomics. Her scholarly contributions aimed at modeling, assessing, and improving work systems (i.e., the systems of tasks performe d by individuals using vari ous technologies in a physical and organizational environment) in orde r to improve system performance and worker well-being. Her research has been funded by the Agency for Healthcare Research and Quality, the National Science Foundation, the National Ins titutes for Health, the National Institute for Occupational Safety and Health, the Department of Defense, va rious foundations, and private industry. She is a fellow of the Human Fact ors and Ergonomics Society and a fellow of the International Ergonomics Association. She is th e recipient of the In ternational Ergonomics Association Triennial Distinguished Service Award (2012) and is th e first woman to receive this prestigious award. She has published more than 100 papers and over 220 conference papers and 30 technical reports, and she is curre ntly the co-editor-in-chief of Applied Ergonomics . She is the edito r of the Handbook of Human Factors and Ergonomics in Health Care and Patient Safety . She is a member of the National Research C ouncil Board on Human-S ystems Integration. COMMITTEE MEMBERS AND STAFF BIOGRAPHIES B-3 PREPUBLICATION COPY: UNCORRECTED PROOFS Christine K. Cassel, M.D., is president and chief executive officer of the National Quality Forum. Previously she served as president and chief executive officer of the American Board of Internal Medicine. Dr. Cassel is a member of the President's C ouncil of Advisors on Science and Technology (PCAST). She is the co-chair and ph ysician leader of PCAST working groups that have made recommendations to the President on i ssues relating to health information technology, scientific innovation in drug deve lopment, and systems engineeri ng in health care delivery. She was a member of the Commonwealth Fund's Co mmission on a High Performance Health System and has served on Institute of Medicine co mmittees that wrote the influential reports To Err is Human and Crossing the Quality Chasm. She is an adjunct professor of medicine and a senior fellow in the Department of Medi cal Ethics and Health Policy at the University of Pennsylvania School Of Medicine, a former d ean of medicine at Oregon Hea lth and Science University, the chair of geriatrics at Mount Sinai School of Me dicine in New York, and the chief of general internal medicine at the Universi ty of Chicago. Dr. Cassel is a prolific scholar, having authored and edited 14 books and over 200 published articles. Carolyn M. Clancy, M.D., is the chief medical officer of th e Veterans Health Administration. Previously, she was appointed the assistant de puty under secretary for health (ADUSH) for quality, safety, and value (QSV) for the Depart ment of Veterans Affairs. Prior to her appointment as ADUSH for QSV, Dr. Clancy served as the director of the Agency for Healthcare Research and Quality (AHRQ) fr om February 2003 to August 2013. Dr. Clancy, a general internist and health services research er, is a graduate of Boston College and the University of Massachusetts Medical School. Foll owing clinical training in internal medicine, she was a Henry J. Kaiser Family Foundation Fello w at the University of Pennsylvania. Before joining AHRQ in 1990, she was also an assistant professor in the Department of Internal Medicine at the Medical College of Virginia. Dr. Clancy holds an academic appointment at George Washington University School of Medicine (clinical associate prof essor, Department of Medicine) and serves as a se nior associate editor at Health Services Research. She serves on multiple editorial boards, including those for JAMA, Annals of Family Medicine , American Journal of Medical Quality , and Medical Care Research and Review . She is a member of the National Academy of Medicine and was elected a Ma ster of the American College of Physicians in 2004. In 2009 she was awarded the 2009 William B. Graham Prize for Health Services Research . Her major research interests include improving health care quality and patient safety and reducing disparities in care associated with patients' race, ethnicity, gender, income, and education. As director of AHRQ, she launched the first annual report to the Congress on health care disparities and health care quality. Michael B. Cohen, M.D., is a medical director in the Anatomic Pathology and Oncology Division at ARUP Laboratorie s, a professor and vice chai r for faculty and house staff development at the University of Utah School of Medicine, and the ombudsperson for the University of Utah Health Sciences Center. Dr. Cohen received his M.D. from Albany Medical College, and completed his anatomic pathology resi dency at the University of California, San Francisco (UCSF). Dr. Cohen has been on the facu lty at Columbia, UCSF, and the University of Iowa; he was chair of the Department of Pathol ogy at Iowa for more than a dozen years. In addition, he has served on nume rous editorial boards. He has been a National Institutes of Health-funded investigator and ha s published extensively in the field of prostate cancer and B-4 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS pathology. He is the recipient of multiple honor s, including the Regents Award for Faculty Excellence at the University of Iowa and the Leonard Tow Humanism in Medicine Award. Dr. Cohen has been included in Castle Connolly Am erican's Top Doctors since 2007 and America's Top Doctors for Cancer since 2005; Consumer s' Research Council of America Guide to America's Top Pathologists since 2007; and Best Doctors in America list since 2005. Patrick Croskerry M.D., Ph.D., FRCP(Edin) is a professor in emergency medicine and in the Division of Medical Education at Dalhousie University, Halifax, Nova Scotia, Canada. He was appointed the director of the new Critical Thinking Program at Dalhousie Medical School in 2012. In addition to his medical training, he holds a doctorate in experimental psychology and a fellowship in clinical psychology. His research is principally concerned with clinical decision making, specifically on diagnostic error. He was on the organizing committee of the first national conference on diagnostic error in 2008 and the s econd one in 2009; he has contributed at each international conference since. He has published over 80 journal articles and 30 book chapters in the area of patient safety, clinical decision ma king, and medical education reform. He was the senior editor on a major text, Patient Safety in Emergency Medicine (2009). Thomas H. Gallagher, M.D., FACP, is a general internist who is professor and associate chair of the Department of Medicine at the University of Washington, wh ere is also professor in the Department of Bioethics and Humanities. Dr. Gallagher received his medical degree from Harvard University, completed his residency in Internal Medicine at Barnes Hospital, Washington University, St. Louis, and comple ted a fellowship in the Robert Wood Johnson Clinical Scholars Program, UCSF. Dr. Gallagher 's research addresses the interfaces between health care quality, communication, and transp arency. Dr. Gallagher has published over 95 articles and book chapters on patient safety and e rror disclosure, which have appeared in leading journals including JAMA, New England Journal of Me dicine, Health Affairs, Surgery, Journal of Clinical Oncology, Archives of Internal Medi cine, Archives of Pediatric and Adolescent Medicine, and the Joint Commissi on Journal. His work in error disclosure received the 2004 Best Published Research Paper of the Year award from the Society of General Internal Medicine, as well as the 2012 MITSS Hope Award. He also received a Robert Wood Johnson Foundation Investigator Award in Health Policy Research. He has been principal investigator on multiple grants from the Agency for Healthcare Resear ch and Quality, including a patient safety and medical liability demonstration project entitl ed \"Communication to Prevent and Respond to Medical Injuries: WA State Collaborative.\" He also was principal investigat or on grants from the National Cancer Institute, the Robert W ood Johnson Foundation, and the Greenwall Foundation. He is senior author of the book \"Talking with Patients and Families About Medical Errors: A Guide for Education and Practice,\" publishe d in 2011 by The Johns Hopkins University Press. At the University of Washington, he directs the UW Medi cine Center for Scholarship in Patient Care Quality and Safety, and also directs the UW Program in Hospital Medicine. He is an appointed Commissioner on the National Comm ission on Physician Payment Reform. Dr. Gallagher is an active member of many professional organiza tions, including the American College of Physicians (Fellow), the Society fo r General Internal Medicine, and the American Society of Bioethics and Humanities. Christine A. Goeschel, ScD., M.P.A., M.P.S., R.N., F.A.A.N., is a health services researcher and the assistant vice president for quality at MedStar Health, a 10-hospi tal, $4.6 billion health COMMITTEE MEMBERS AND STAFF BIOGRAPHIES B-5 PREPUBLICATION COPY: UNCORRECTED PROOFS system in the mid Atlantic, where she oversees quality for both the acute and non-acute care services. She is a fellow of the American Academy of Nursing, a Nati onal Baldrige Examiner, and associate faculty in the Johns Hopkins Bl oomberg School of Public Health, where she teaches a required course in the master of hosp ital administration program. Formerly the director of strategic research initiatives at the Johns Hopkins Armstrong In stitute, Dr. Goeschel serves on the board of the Maryland Patient Safety Center and is the author of several book chapters and over 65 peer-reviewed articles on to pics ranging from implementation of large-scale clinical improvement projects to leadership for advancing the science of h ealth care delivery and creating a culture of accountability in health care. Previo us experience includes responsibility for quality, risk management, and service excellence in a Midwest teaching hospital and serving as an advisor to the World Health Organization Patient Safety Program. She served on the National Quality Forum (NQF) National Steering Committee for Serious Reportable Events and Healthcare Associated Conditi ons and currently serves on an NQF panel exploring linkages between cost and quality. She is increasingly in terested in the study of diagnostic errors\u2014both their etiology and understanding the relationship of diagnostic error with preventable morbidity, mortality, and costs of care. Mark L. Graber, M.D., FACP, is a senior fellow at RTI Inte rnational and professor emeritus of medicine at the State University of New York at Stony Brook. He retired as the chief of medicine at the Northport VA Medical Center in 2011. Dr. Graber ha s an extensive background in biomedical and health services research, with over 80 peer-r eviewed publications. He is a national leader in the field of patient safety and originated Patient Safety Awareness Week in 2002, an event now recognized intern ationally. Dr. Graber has also been a pioneer in efforts to address diagnostic errors in medicine. In 2008 he convened and chaired the Diagnostic Error in Medicine conference series, a nd in 2011 he founded the Societ y to Improve Diagnosis in Medicine ( www.improvediagnosis.org ). In 2014 he became the founding editor of a new journal, Diagnosis , devoted to improving the quality and safe ty of diagnosis, and received the John M. Eisenberg Award for Individual Achievement in Advancing Patient Safety from the National Quality Forum and The Joint Commission. Hedvig Hricak M.D., Dr. Med. Sc. (Ph.D.), Dr.h.c. is the chair of the De partment of Radiology at Memorial Sloan-Kettering Ca ncer Center, a professor in the Gerstner Sloan-Kettering Graduate School of Biomedical Sciences, and a professor of radiol ogy at the Weill Medical College of Cornell University. She also hol ds a senior position within the Molecular Pharmacology and Chemistry Program of the Sloan- Kettering Institute. Previously, she was chief of the uroradiology and abdominal imaging secti ons of the Department of Radiology, University of California, San Francisco. She earned her M.D. degree from the University of Zagreb in Zagreb, Croatia, and her Dr. Me d. Sc. (Ph.D.) from the Karolin ska Institute in Stockholm, Sweden. Her research and clinical expertise is in the use of diagnostic im aging, specifically for the detection and assessment of genitourin ary and gynecological cancers. She has worked continuously to develop and promote the use of ev idence-based imaging algorithms to assist in cancer management, focusing on the development and validation of biomarkers from cross-sectional (ultrasound, MRI, CT) and molecu lar (DCE-MRI, MR spectroscopy, PET/CT and PET/MRI) imaging. Over the last 20 years, whil e serving in administrative leadership positions, she has been actively engaged in continuous proc ess improvement and quality assurance efforts. Dr. Hricak served on the National Institutes of Health, Board of Scientific Counselors, the B-6 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS National Cancer Institute (NCI) board of scien tific advisors and the Advisory Council of The National Institute of Biomedical Imaging and Bi oengineering. She is a member of the National Academy of Medicine (NAM) of the National A cademy of Sciences (NAS). She served on the IOM committee that produced the report, A National Cancer Clinical Trials System for the 21st Century: Reinvigorating the NCI Cooperative Group Program. Since 2008 she has been a member of the Nuclear Radiation Studies Boar d of the NAS. She chaired the NAS Committee on the State of the Science of Nuclear Medi cine, which wrote th e highly-cited report Advancing Nuclear Medicine Through Innovation . In addition, she chaired the 2009 Beebe symposium of the NAS, which focused on radiation exposures from imaging and image-guided interventions. The many leadership posts she has held in prof essional organizations include president of the California Academy of Medicine and president of the Radiologi cal Society of North America board of directors. Over the course of her career, she has received numerous honors and awards, including foreign membership in both the Croatian Academy of Arts and Sciences and the Russian Academy of Medicine, and an honorary do ctorate in medicine from Ludwig Maximilian University in Munich, Germany. Anupam B. Jena, M.D., Ph.D. is an assistant professor of h ealth care policy and medicine at Harvard Medical School and an attending physic ian in the Department of Medicine at Massachusetts General Hospital, where he pract ices general inpatient medicine and teaches medical residents. He is also a faculty rese arch fellow at the Nati onal Bureau of Economic Research. As an economist and a physician, Dr. Jena 's research involves several areas of health economics and policy, including medical malpracti ce, the economics of medical innovation and cost effectiveness, the economics of physician behavior, and the effect on physician quality of reforms to medical education. Dr. Jena gradua ted Phi Beta Kappa fr om the Massachusetts Institute of Technology with majors in biology a nd economics. He received his M.D. and Ph.D. in economics from the University of Chicago. He co mpleted his residency in internal medicine at Massachusetts General Hospital. In 2007 he was awarded the Eugene Garfield Award by Research America for his work demonstrati ng the economic value of medical innovation in HIV/AIDS. In 2013 he received the NIH Director's Early Indepe ndence Award to fund research on the physician determinants of health car e spending, quality, and patient outcomes. Ashish K. Jha, M.D., M.P.H. is a professor of h ealth policy and management at the Harvard School of Public Health and a practicing general internist with a clinical focus on hospital care. Over the past 6 years he has served as a seni or advisor for quality and safety to the U.S. Department of Veterans Affair s (VA). Dr. Jha received his M.D. from Harvard Medical School in 1997 and trained in internal medi cine at the University of Calif ornia, San Francisco, where he also served as the chief medical resident. He completed his general medicine fellowship from Brigham and Women's Hospital and Harvard Medical School and received his M.P.H. in clinical effectiveness from the Harvard School of Public Health in 2004. He joined the faculty in July 2004. The major themes of his research include th e impact of public polic y on the health care delivery system with a focus on patient safety, cl inical outcomes, and costs of care. Much of his work has focused on understa nding how policy efforts such as public reporting, pay-for- performance, and the promo tion of the use of health informati on technology affect clinical quality, patient safety, and health care co sts. Dr. Jha's most recent work has focused on key levers for improvement including organizational leadership a nd how it affects the delivery of saf e, effective, and efficient care. COMMITTEE MEMBERS AND STAFF BIOGRAPHIES B-7 PREPUBLICATION COPY: UNCORRECTED PROOFS Michael Laposata, M.D., Ph.D. is the chair of the Department of Pathology at the University of Texas Medical Branch at Galveston. He recei ved his M.D. and Ph.D. from Johns Hopkins University School of Medicine and completed a postdoctoral rese arch fellowship and residency in Laboratory Medicine (Clinical Pathology) at Washington Universi ty School of Medicine in St. Louis. He took his first faculty position at the Un iversity of Pennsylvania School of Medicine in Philadelphia in 1985, where he was an assistant professor and director of the hospital's coagulation laboratory. In 1989 he became the director of clinical laboratories at the Massachusetts General Hospital and was appointed to the faculty in pathology at Harvard Medical School, where he became a tenured full professor of pathology. His research program, with more than 160 peer reviewed publications, has focused on fa tty acids and their metabolites. His research group is currently focused on the study of fatty acid alterations in cystic fibrosis. Dr. Laposata's clinical expertise is in the field of blood coagulation, with a special expertise in the diagnosis of hypercoagulable stat es. Dr. Laposata implemented a system whereby the clinical laboratory data in coagulation and other areas of laboratory medicine are systematically interpreted with the generation of a patient-specific narrative paragraph by a physician with expertise in the area. This servi ce is essentially identical to the service provided by physicians in radiology and anatomic pathology ex cept that it involves clinical laboratory test results. In 2005, Dr. Laposata was recognized by the Institute of Quality in Laboratory Medicine of the Centers for Disease Control and Prevention for this innov ation. Dr. Laposata is th e recipient of 14 major teaching prizes at Harvard, the Massachusetts General Hospital, and the University of Pennsylvania School of Medicine. His recognitions include the 1989 Lind back award, a teaching prize with competition across the entire Univers ity of Pennsylvania system; the 1998 A. Clifford Barger mentorship award from Harvard Medical School; election to th e Harvard Academy of Scholars in 2002 and to the Vanderbilt University School of Medicine Academy for Excellence in Teaching in 2009; and the highest award\u2014by vot e of the graduating class\u2014for teaching in years 1 and 2 at Harvard Medical School in 1999, 2000, and 2005. Kathryn McDonald, M.M., has over 20 years of experience in h ealth care, working in a variety of settings: industry, hospitals, a nd academia. She is the executiv e director of the Center for Health Policy and the Center for Primary Care and Outcomes Research (CHP/PCOR) at Stanford University, a senior scholar at the centers, and the associate director for the Stanford-UCSF Evidence-Based Practice Center (with RAND). Her research focu ses on evidence-based health care quality measures and interv entions, with an emphasis on organizational context and key health care stakeholders (patients/families, clin icians, systems administrators). Her research portfolio includes initial and ongoing development of the publicly released Agency for Healthcare Research and Quality (AHRQ) Patient Safety and Quality Indicators (www.qualityindicators.ahrq.gov), reviews of patient safety practices (Making Healthcare Safer I and II), and two series of evidence reports on quality improvement strategies ( Closing the Quality Gap, Quality Kaleidoscope ). She continues to lead a multi-institution measure development team for support of and expansions to the AHRQ Quality Indicators. She is the lead author of the Care Coordination Measures Atlas ( www.ahrq.gov/qual/careatlas/ ). She has published over 100 peer-reviewed articles and evidence reports, presents regularly at national meetings, and collaborates with a wide network of investigators, health care practitioners, and patients and their families. McDonald has a strong service record, currently as the chair of the Patient Engagement Committee of the Society to Improve Diagnosis in Medicine and the B-8 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS associate editor of the journal Diagnosis . Previously, she was the president of the Society for Medical Decision Making and member of an Institute of Medicine Committee that issued the report Child and Adolescent Health and Health Care Quality: Meas uring What Matters . She holds a master of management degree (M.B.A. equivalent) from Northwestern University's Kellogg School of Management, with an emphasis on the health care industry and organizational behavior, and she holds a B.S. in chemical engineering from Stanford University. Elizabeth A. McGlynn, Ph.D. , is the director of Kaiser Perm anente's Center for Effectiveness and Safety Research (CESR). She is responsible for the strategic direction and scientific oversight of CESR, a virtual cente r designed to improve the health and well-being of Kaiser's 9 million members and the public by conducting compar ative effectiveness and safety research and implementing findings in policy and practice. Dr . McGlynn is an internationally known expert on methods for evaluating the appropriateness, quality, and efficiency of health care delivery. She has conducted research in the United States and in other countries. Dr. McGlynn has also led major initiatives to evaluate hea lth reform options under consideration at the federal and state levels. Dr. McGlynn is a member of the Nationa l Academy of Medicine. She serves as the secretary and treasurer of the American Board of Internal Medicine Foundation board of trustees. She is on the board of AcademyHea lth, the Institute of Medicine Bo ard of Health Care Services, and the Reagan-Udall Foundation for the Food and Drug Administration. She chairs the scientific advisory group fo r the Institute for Healthcare Improvement. She co-chairs the coordinating committee for the National Quality Forum's Measures Application Partnership. She serves on the editorial boards for Health Services Research and The Milbank Quarterly and is a regular reviewer for many lead ing journals. Dr. McGlynn receive d her B.A. in international political economy from Colorado College, her M.P.P. from the University of Michigan's Gerald R. Ford School of Public Policy, and her Ph.D. in public policy analysis from the Pardee RAND Graduate School. Michelle Rogers, Ph.D., is an associate professor in the College of Computing and Informatics at Drexel University. She has more than 10 years of experience using hu man factors engineering methods and socio-technical systems theory to st udy the impact of health information technology (HIT) on clinical workflow and the usability of technology in order to support patient safety and reduce human error. Over her career, her project s focused on understanding the impact of HIT on clinical workflow and patient safety, as is de monstrated in her work with the Computerized Patient Record System, the Bar-Code Medicati on Administration system and MyHealthVet (VA patient portal) in use at the Veterans Health Administration where she was a faculty research scientist. Her current work involves applying human factors engineering methods to study healthcare practices, information and data needs re lated to maternal/child care as well as the implementation and use of electronic medical re cords at Makerere University in Uganda. Urmimala Sarkar, M.D., M.P.H ., is associate professor of Me dicine at the University of California, San Francisco (UCSF) in the Division of General Internal Medicine, a core faculty member of the UCSF Center for Vulnerable P opulations, and a primary care physician at San Francisco General Hospital's Richard H. Fine Pe ople's Clinic. Dr. Sarkar's research focuses on patient safety in outpatient settings, incl uding adverse drug events, missed and delayed diagnosis, failures of treatment monitoring, hea lth inform ation technology and social media to improve the safety and quality of outpatient care, and implementation of evidence-based COMMITTEE MEMBERS AND STAFF BIOGRAPHIES B-9 PREPUBLICATION COPY: UNCORRECTED PROOFS innovations settings. She is the prin cipal investigator of a Patient Safety Learning Laboratory which applies design thinking and interdisciplinary, iterative approaches to characterize and address safety gaps in outpatient settings (Agency for Healthcare Research and Quality P30HS023558), and of an implementation and dissemination network to support innovations to improve the safety and quality of care in safety-net settings across California (Agency for Healthcare Research and Quality R24HS022047). Dr. Sarkar is an associate editor for Patient Safety Net (psnet .ahrq.gov), the most comprehensive national web- based resource for patient safety, and a member of the editorial board of the Joint Commission Journal of Quality and Patient Safety. Dr. Sarkar completed clinical training in internal medicine and health services research fellowship tr aining at UCSF, holds an M.P.H. degree in epidemiology at University of Ca lifornia, Berkeley, an M.D. degree at University of California, San Diego, and BS degree with honors in biolog ical sciences from Stanford University. George E. Thibault, M.D., became the seventh president of the Josiah Macy Jr. Foundation in January 2008. Immediately prior to that, he served as the vice president of clinical affairs at Partners Healthcare System in Boston and the director of the Academ y at Harvard Medical School (HMS). He was the first Daniel D. Fe derman Professor of Medicine and Medical Education at HMS and is now the Federman Profe ssor, Emeritus. Dr. Thibault previously served as the chief medical officer at Brigham and Women's Hospital and as the chief of medicine at the Harvard-affiliated Brockton/West Roxbury VA Hospital. He was the associate chief of medicine and the director of the Internal Me dical Residency Program at the Massachusetts General Hospital (MGH). At the MGH he also served as the director of the Medical ICU and the founding director of the Medical Practice Evaluation Unit. For nearly four decades at HMS, Dr. Thibault played leadership roles in many as pects of undergraduate and graduate medical education. He played a central ro le in the New Pathway curriculum reform and was a leader in the new integrated curriculum reform at HMS. He was the founding director of the Academy at HMS, which was created to recognize outsta nding teachers and to promote innovations in medical education. Throughout his ca reer he has been recognized for his roles in teaching and mentoring medical students, residents, fellows, a nd junior faculty. In addi tion to his teaching, his research has focused on the evaluation of practic es and outcomes of medi cal intensive care and variations in the use of cardia c technologies. Dr. Thibault is chair of the board of the MGH Institute of Health Professions , and he serves on the boards of the New York Academy of Sciences, the New York Academy of Medicine, the Institute on Medicine as a Profession, the New York Academy of Medicine, and the Lebane se American University. He serves on the President's White House Fellows Commission, and for 12 years he chaired the Special Medical Advisory Group for the Department of Veteran's Af fairs. He is past president of the Harvard Medical Alumni Association and past chair of alumni relations at HMS. He is a member of the National Academy of Medicine. Dr. Thibault graduated summa cum laude from Georgetown University in 1965 and magna cum laude from Harvard Medical School in 1969. He completed his internship and residency in medicine and fe llowship in cardiology at Massachusetts General Hospital (MGH). He also trained in cardiology at the National Heart and Lung Institute in Bethesda and at Guys Hospital in London, and he se rved as chief resident in medicine at MGH. Dr. Thibault has been the recipient of nume rous awards and honors from Georgetown (Ryan Prize in Philosophy, Alumni Prize, and Cohongaroton Speaker) and Harvard (Alpha Omega Alpha, Henry Asbury Christian Award and Society of Fellows). He has been a visiting scholar B-10 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS both at the Institute of Medicine and Harvar d's Kennedy School of Government and a visiting professor of medicine at nu merous medical schools in the United States and abroad. John B. Wong, M.D., FACP is a practicing general internist, the chief of the Division of Clinical Decision Making at Tu fts Medical Center, the director of Comparative Effectiveness Research at Tufts Clinical Tran slational Science Inst itute, and a distinguished professor of Medicine at Tufts University Sc hool of Medicine. A gr aduate of Haverford College, he received his M.D. from the University of Chicago follo wed by internal medicine residency and medical informatics fellowship in Clinical Decision Making at Tufts Medical Center . A past president of the Society for Medical Decision Making, he ha s participated in consensus conferences, guideline development and appropriateness use criteria assessment for the World Health Organization, National Institutes of Health, Center s for Disease Control and Prevention, Agency for Healthcare Research and Quality, American Association for the Study of Liver Diseases, American Heart Association, American College of Cardiology, European League Against Rheumatism and OMERACT. Besides translatin g guidelines into quality improvement and performance measures in the American Me dical Association Physician Consortium for Performance Improvement Work Groups, he ha s developed award winni ng decision aids for shared decision making with the Informed Medical Decisions Foundation. Dr. Wong's research focuses on the application of decision analysis to help patients, physicians, and policymakers choose among alternative tests, treatments, and policies, thereby promoting rational evidence- based efficient and effective patien t-centered care. A coauthor of Learning Clinical Reasoning and Decision Making in Health and Medicine and over 150 scientific publications and book chapters including the Reference Manual on Scientific Evidence for the National Academy of Science, his research areas in clude clinical and diagnostic re asoning, decision sciences, test interpretation, Bayesian methods, quality and appropriateness of care, health economics, patient centeredness, shared decision maki ng, and evidence-based medicine. IOM STAFF BIOGRAPHIES Erin Balogh, M.P.H., is a program officer for the Institute of Medicine (IOM) Board on Health Care Services and the National Cancer Policy Forum (NCPF). She has directed NCPF workshops on patient-centered cancer treatment planni ng, affordable cancer care, precompetitive collaboration, combination cancer therapies, a nd reducing tobacco-related cancer incidence and mortality. She staffed consensus studies focusing on the quality of cancer care, omics-based test development, the national clinical trials system , and the evaluation of biomarkers and surrogate endpoints. She completed her M.P.H. in health management and policy at the University of Michigan School of Public H ealth, and she graduated summa cum laude from Arizona State University with bachelor's degrees in micr obiology and psychology. Ms. Balogh interned with AcademyHealth in Washington, D.C., and worked as a research site coordinator for the Urban Institute in Topeka, Kansas. Previously, Ms. Balogh was a management in tern with the Arizona State University Office of University Initiati ves, a strategic planning group for the university. She was the 2014 recipient of the IOM Above and Beyond award and the 2012 recipient of the IOM staff team achievement award. COMMITTEE MEMBERS AND STAFF BIOGRAPHIES B-11 PREPUBLICATION COPY: UNCORRECTED PROOFS Bryan Miller, Ph.D., is a research associate for the IOM Board on Health Care Services. He earned an M.A. from the Brains and Behavior program at Geor gia State University in 2007 and completed his Ph.D. in philosophy of science at Johns Hopkins University in the summer of 2014. He has performed research at the Berlin Sc hool of Mind and Brain and Charit\u00e9 University Hospital in Berlin and taught courses in the philosophy of science, th e philosophy of psychology, and bioethics at several universities in the Baltimore-Washington, D.C., area. Sarah Naylor, Ph.D., completed a Ph.D. in developmental biology at Washington University in 2012 and earned a B.S. with distinction in bioe ngineering from the University of Illinois. She performed postdoctoral research at the National Ins titutes of Health and worked as an intern in the Office of Autism Research Coordination within the National Institute of Mental Health. She is currently a AAAS Science & Technology Policy Fellow in Evaluation and Assessment in the Office of the Assistant Di rector for Engineering. Kathryn Garnham Ellett, M.P.P., is a policy analyst the Assistant Secretary for Financial Resources at the U.S. Department of Health and Human Services (HHS), where she has been working on (Centers for Medica re & Medicaid Services (CMS ) policy since 2010. She was on detail as a research associate for the Institute of Medicine Board on Health Care services from April through July 2015. At HHS her portfolio includes Medicare post-acute care and hospice, Medicare Quality Improvement Organizations, a nd CMS' survey and certification program. She completed her M.P.P. at the University of Toronto in 2010 and her bachelor's degree at Queen's University in Kingston, Ontario. Prior to her time at HHS she worked in home health care. She also worked for a hospital system implementing an eldercare access strategy in emergency rooms and has researched nursing home staffing and palliative care. Celynne Balatbat is the special assistant to the presiden t of the National Academy of Medicine. Previously, she was a research a ssistant with the Institute of Medicine Board on Health Care Services. She received her B.A. in neuroscience and behavior from Vassar College in 2013. Before coming to the Academies, she interned in the advocacy department at AARP California and worked as a laboratory a ssistant in a medical microbiol ogy lab at the University of California, Davis. Patrick Ross is a research assistant with the Institut e of Medicine (IOM) Board on Health Care Services, where he has worked with the National Cancer Policy Forum. Patrick graduated from Concordia College in Moorhead, Minn., in 2013 w ith a bachelor of arts in psychology with minors in biology and chemistry, where his senior research project focused on bacteriocins in Neisseria meningitidis . Before joining the IOM, Patrick worked in various health advocacy groups, including Families USA. Laura Rosema, Ph.D. joined the Institute of Medicine Board on Health Care Services as part of the Winter 2015 Christine Mirzayan Science and Technology Policy Fellowship class. Prior to the fellowship, she served as the scientific advisor for Bill Gates' Gl obal Good Fund, a private initiative chartered to commercialize inventions in devel oping countries. At Global Good, Laura advised on investment strategy a nd technical directions for the fund. She has led evaluations on topics that include using biom etric signatures for health reco rd tracking, implantable medical devices, and diagnostic development for malaria e limination programs. She received her Ph.D. in B-12 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS chemistry from the University of Washington and earned her master's degree and bachelor's degree in inorganic chemistr y from Bryn Mawr College. She is currently a AAAS Science & Technology Policy Fellow serving within the NIH Office of Science Policy, in the Office of Science Management and Reporting. Beatrice Kalisch R.N., Ph.D., FAAN is the 2013 AAN, ANF, AN A Distinguished Nurse Scholar in residence at the Inst itute of Medicine and the Titus Professor at the University of Michigan in Ann Arbor. She has conducted numerous research studies on such subjects as nursing teamwork, missed nursing care (errors of omission), the image of the nurse, and the impact of U.S. federal funds on nursing edu cation and practice. Dr. Kalisch has published extensively, authoring 10 books and over 150 peer-reviewed articles. She has made over 800 presentations of her research th roughout the world. She serves on the editorial boa rds of several national and international journals. Dr. Kalisch has also served as a visiti ng professor at several institutions, including Huazhong University of Science and Technology, Tongji Medical College, Wuhan, China, and the University of Sao Paulo, Brazil. She is listed in numerous bibliographies, such as Who's Who in America and Who's Who of American Women , Who's Who in the World, Foremost Women of the Twentieth Century , and Community Leaders of the World . Dr. Kalisch is a fellow in the American Academ y of Nursing and a member of Phi Kappa Phi. She serves as a member as well as leader in numerous local, state and national advisory committees addressing health policy and nursing i ssues. Dr. Kalisch has been the recipient of many awards, including distinguished alumna at both the University of Maryland and the University of Nebraska, the Shaw Medal from the President of Boston College, the Department of Labor research award, Joseph L. Andrew s Bibliographic Award from the American Association of Law Libraries, book of the year awards, nurse researcher award from the American Organization of Nurse Executives, and the Sigma Theta Tau Award for Excellence in Nursing. Roger Herdman, M.D., was the director of the Institute of Medicine (IOM) Board on Health Care Services until June 2014. He received his undergraduate and medical school degrees from Yale University. Following an internship at the University of Minnesota and a stint in the U.S. Navy, he returned to Minnesota, where he comple ted a residency in pedi atrics and a fellowship in immunology and nephrology, and also served on th e faculty. He was a professor of pediatrics at Albany Medical College until 1979. In 1969, Dr. Herdman was appointed director of the New York State Kidney Disease Instit ute in Albany, New York, and s hortly thereafter was appointed deputy commissioner of the New York State Depa rtment of Health, a position he held until 1977. That year he was named New York State's dire ctor of public health. From 1979 until joining the U.S. Congress Office of Technology Assessment (O TA), he served as a vice president of Memorial Sloan Kettering Cancer Center in New York City. In 1983, Dr. Herdman was named assistant director of OTA, where he subsequen tly served as director from 1993 to 1996. He later joined the IOM as a senior scholar and direct ed studies on graduate medical education, organ transplantation, silicone breast implants, and the Department of Veterans Affairs national formulary. Dr. Herdman was appointed director of the IOM/National Res earch Council National Cancer Policy Board from 2000 through 2005. From 2005 until 2009, Dr. Herdman directed the IOM National Cancer Policy Forum. In 2007, he wa s also appointed director of the IOM Board on Health Care Services. During his work at the IOM, Dr. Herdman has worked closely with the U.S. Congress on a wide variety of health care policy issues. COMMITTEE MEMBERS AND STAFF director of the Institute of Medicine's Board on Health Care Services and the director of the National Cancer Policy Forum. Over the past 15 years her work at the IOM has focused on a broad range of topics wh ich includes the quality of cancer care, cancer clinical trials, developing cancer biomarkers and omics-based tests to guide patient care, strategies for large-scale biomedical science, developing technologies for the early detection of breast cancer, improving breast imaging quality standards, the impact of the HIPAA Privacy Rule on health research, and cont raceptive research and developm ent. With a Ph.D. in cell and tumor biology from Georgetown University a nd postdoctoral training at the Johns Hopkins University School of Medicine, she has author ed papers on the cell and molecular biology of breast cancer. She also holds a B.S. in geneti cs and an M.S. in endocrinology/reproductive physiology, both from the University of Wi sconsin-Madison. In addition, she studied developmental genetics and molecular biology at the Max Planck Institute in Germany under a fellowship from the Heinrich Hertz-Stiftung Foundation. Dr. Nass was the 2007 recipient of the Cecil Award for Excellence in Health Policy Re search, the 2010 recipien t of a Distinguished Service Award from the National Academies, and the 2012 recipient of the IOM staff team achievement award. FIGURE delayed, o resulting f error], re s surgery w due to pr o patient h a misdiagn o or other s y SOURC E C-1 Venn d i or wrong dia g from erro r-rel sulting in wr o with adverse o ocess error (p o as no sympto m oses but no i d ymptoms tha o PREPUBL g ong patient be utcome [adv e ositive urine c ms or advers e dentifiable pr o t were misse d om Schiff et a ICATION C OAp n dverse a event]). G culture overl o e consequenc e ocess error ( d d). C G logy specime n agnosis of ca n Group B repr e ooked, thus a es). Group C r death from ac u d Schiff and L RRECTED P RC r Frame w n errors in th Group A rep r ns erroneous l ncer [misdiag n esents delay e urinary tract represents a d ute myocardi a Leape (2012). ROOFS works e diagnostic p resents adver s ly mixed up [ d nosis] who t h ed diagnoses o infection is n dverse events al infarction b process; miss se outcomes diagnostic pr o hen undergoe s or misdiagno s not diagnose d due to but no chest p ed, ocess s ses d but pain C-2 FIGURE opportun i earlier.\" SOURC E Oakbroo k (100). Fi g FIGUREsystem in improve d SOURC E with per m C-2 Singh's ity\" to imply \" E: \u00a9 Joint Co m k Terrace, IL: gure. Reprint e C-3 Singh a n which diagn o diagnosis an d E: Reproduce d mission from B PREPUBL I(2014, p. 10 0 \"that someth i mmission Re Joint Comm i ed with perm i nd Sittig's (2 0 osis occurs a n patient and s d from BMJ Q BMJ Publish i ICATION C O0) diagnostic ing different c sources: Join t ission on Ac c ission. 015) diagnos t nd opportuni t system outco m Quality and S ing Group Li m I M OPY: UNCO Rerror frame w could have b e t Commissio n creditation of tic error fra m ties to measu r mes. afety, H. Sin g mited. MPROVING D RRECTED P Rwork, which e m een done to m n Journal on Q fHealthcare O mework, whic h re and learn fr gh and D. F. S DIAGNOSIS I ROOFS mploys the t e make the corr e Quality and P Organizations h illustrates t h from diagnost Sittig, 24(2), IN HEALTH C erm \"missed ect diagnosis Patient Safety . , (2014), 40( 3 he sociotech n ic errors to 103-110, 20 1 CARE . 3), nical 15 PREVIO U FIGUR E diagnost i SOURC EUS DIAGNO S E C-4 New m ic error as t h E: Reprinted, w STIC ERROR PREPUBL Iman-Toker' s he overlap b e with permiss i FRAMEWO R ICATION C Os (2014) dia g etween diag n ion, from Da v RKS r Rr framework , ss failures a n Toker 2014. ROOFS , which defi n nd diagnost i Copyright 2 0 nes prevent a ic label fail u 014 by DeGr u C-3 able ures. uyter. C-4 FIGURE process a n SOURC E Newman- T m Schiff, G. D (2 Schiff, G. D W co P Pu ht Singh, H. 2 di Singh, H., Sa C-5 Newma nd optimal di E: Reprinted, w Toker, D. E. 2 0 misdiagnosis. D D. and L. L. L 2):135-138. D., S. Kim, R. Wisniewski, an d ollaborative pr o atient Safety: F ublication No. ttp://www.ncb i Editoria l iagnosis. Joint and D. F. Sitti afer Dx frame w PREPUBL In-Toker's (2 agnostic pro c with permiss i 014. A unified Diagnosis 1(1): 4 eape. 2012. C o Abrams, K. C d R. A. McNu t oject. In K. H e From Researc h 05-0021-2: R o i.nlm.nih.gov/ b l: Helping hea l Commission J g. 2015. Adva n work. BMJ Qu ICATION C O014) framew o cess, as well a ion, from Da v REF conceptual m o 43-48. ommentary: H o osby, B. Lam b tt. 2005. Diag n enriksen, J. B. B h to Implemen t ockville, MD: A books/NBK20 4 lth care organi z Journal on Qu a ncing the scie n ality and Safe ty I M OPY: UNCO Rork of diagn o as FERENCE S odel for diagn o ow can we ma k bert, A. S. Elst e nosing diagnos i Battles, E. S. M tation (Volum e Agency for H e 492/pdf/Book s zations to defi n ality and Patie e ty 24(2):103-1 MPROVING D RRECTED P Rostic error, c and unavoida b Toker 2014. S ostic errors: U n ke diagnosis s a ein, S. Hasler, is errors: lesso n Marks, and D. I e 2: Concepts a ealthcare Rese a shelf_NBK20 4 ne diagnostic e nt Safety 40(3 ) ement of diagn o 10. DIAGNOSIS I ROOFS cluding subo p ble diagnosti c Copyright 2 0 nderdiagnosis, afer? Academi c N. Krosnjar, R ns from a mul t I. Lewin (eds. ) and Methodolo arch i 492.pdf errors as misse d ):99-101. ostic errors in h IN HEALTH C ptimal diagn o c error. 014 by DeGr u overdiagnosis c Medicine 87 R. Odwazny, M tiinstitutional ), Advances in ogy). AHRQ s healthcare: Th CARE ostic uyter. e D-1 PREPUBLICATION COPY: UNCORRECTED PROOFS Appendix D Examples of Diagnostic Error Whereas the title of the Institute of Medicine (IOM) report To Err Is Human: Building a Safer Health System focused on human error, the primary fo cus of that report was describing the range of work system factors that can affect errors (IOM, 2000). The repo rt emphasized the need to go beyond acute failure and the need to unde rstand latent failures and the range of work system factors that contribute to errors over time . Consistent with the earlier IOM report, this report on diagnostic error in health care also emphasizes the ne ed to look at errors in the diagnostic process, which is embe dded in a larger work system. The case studies presented in this appendi x provide snapshots of various diagnostic errors. It is important to understa nd that a range of work system f actors could have contributed to these diagnostic errors. As hi ghlighted in the conceptual mo del (Figures S-1 and S-2) and described in Chapters 2 and 3, the diagnostic proc ess unfolds over time; various people and care settings are involved (e.g., outpatient care setti ngs, hospitals, emergency departments, and long- term care settings), and multiple work systems factors (e.g., information flow and communication, the engagement of patients, cultur e, training and education, usable and useful technology) can contribute to di agnostic errors, including those briefly de scribed in Box D-1. BOX D-1 Examples of Diagnostic Error Lack of appreciation for significant elements of the patient's history and physical led to a missed pulmonary embolism A 33-year-old obese patient with remote history of asthma, and on oral contraceptives, presented to her primary care clinician with a three-day complaint of right thigh pain, swelling, and red streaking on her skin. On exam, her right inguinal lymph nodes were enlarged and antibiotics were prescribed. Three days later, she returned with complaint of new onset shortness of breath, chest pain, and rapid heart rate. The patient had diminished breath sounds. Her physician thought she was having an asthma flare and advised her to continue antibiotics and asthma medications. Later the same day, emergency personnel were called to the patient's home after she fell. She was brought to a lo cal Emergency Department where she quickly decompensated and died. Autopsy revealed a large pulmonary thromboembolism. SOURCE: CRICO, 2014. Reprinted with per mission from CRICO/Risk Management Foundation of the Harvard Medical Institutions. A misread X-ray of patient with pneumonia led to respiratory failure and death A 55-year-old male was diagnosed by his primary care clinician with sinusitis and prescribed an antibiotic. Six days later, he was evaluated in an urgent care clinic for shortness of breath, labored breathing, extreme fatigue, and chest pain with cough. The patient had a temperature, a fast heart rate, and low oxygen saturation. After he was treated with an aerosolized nebulizer D-2 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS his oxygen saturation improved. Based on her negative interpretation of a chest X-ray, the urgent care clinician diagnosed a viral [upper respiratory infection] and instructed the patient to see his family doctor the next day. Two days later, the X-ray was read by a radiologist with impression of pneumonia. The clinic called the patient and instructed him to go to his local Emergency Department for evaluation and treatment. Before he could get to the ED, the patient died of respiratory failure associated with pneumonia. SOURCE: CRICO, 2014. Reprinted with per mission from CRICO/Risk Management Foundation of the Harvard Medical Institutions. Multiple missteps in the referral process preceded patient's death from cardiac failure A 51-year-old female with a history of att ention deficit disorder and hyperlipidemia had been treated by her primary care physician for 14 years. Her high cholesterol was treated with medications and she was otherwise asymptomatic. D ue to a family history of cardiac disease, the patient requested a cardiology referral for evaluation. Her [primary care provider] PCP ordered the referral and a stress test. The office reports sending the referral information to the patient, however, the patient did not receive it. After the patient called the practice multiple times, a referral was scheduled (three months after initial request). On the day she was to have her cardiology appointment, the patient died. Her death was attributed to significant coronary artery disease, with hyperlipidemia noted. SOURCE: CRICO, 2014. Reprinted with permission from CRICO/Risk Management Foundation of the Harvard Medical Institutions. Radiology results not communicated Mr. J, a patient with severe degenerative joint disease who is cared for by a rural physician, is referred to an orthopedist at an urban center. He receives a chest x-ray as part of the preoperative evaluation for knee replacement. The chest x-ray shows a mass, and his knee surgery is cancelled. The orthopedic surgeon is on vacation the following month, and the radiology report is never sent to the primary ca re physician. Mr. J follows up three months later with his primary care physician, who learns of t he chest x-ray from Mr. J. He is found to have a primary lung cancer, which is successfully removed with surgery. SOURCE: Sarkar et al., 2009. \u00a9 Joint Commission Resources: Joint Commission Journal on Quality and Patient Safety. Oakbrook Terrace, IL: Joint Commission on Accreditation of Healthcare Organizations, (2009), 35(7), (378). Case study. Reprinted with permission. Poor care coordination and recognition of medication-related symptoms Mr. F, who has diabetes, hypertension, and heart failure, sees a primary care physician, an endocrinologist, and a cardiologist. All three adjust his medications. When he presents for a scheduled primary care visit, he does not have his medicines, so the primary care physician does not have an accurate accounting of Mr. F's current drug regimen. Also, Mr. F did not submit to laboratory tests as requested at his prior primary care visit. His daughter, who cares for him, states that his endocrinologist had ordered laboratory tests the prior month, so she thought he did not need any more blood drawn. He reports feeling generally weak and unwell, so his primary care physician orders laboratory tests done the same day, and he is found to have dangerously low serum sodium. SOURCE: Sarkar et al., 2009. \u00a9 Joint Commission Resources: Joint Commission Journal on Quality and Patient Safety. Oakbrook Terrace, IL: Joint Commission on Accreditation of Healthcare Organizations, (2009), 35(7), (378-379). Case study. Reprinted with permission. Diagnostic failure due to intuitive biases A 28-year-old female patient is sent to an emergency department from a nearby addictions treatment facility. Her chief complaints are anxiety and chest pain that have been going on for EXAMPLES OF DIAGNOSTIC ERROR D-3 PREPUBLICATION COPY: UNCORRECTED PROOFS about a week. She is concerned that she may have a heart problem. An electrocardiogram is routinely done at triage. The emergency physician who signs up to see the patient is well known for his views on \"addicts\" and others with \"self-inflicted\" problems who tie up busy emergency departments. When he goes to see the patient, he is informed by the nurse that she has gone for a cigarette. He appears angry, and verbally expresses his irritation to the nurse. He reviews the patient's electrocardiogram, which is normal. When the patient returns, he admonishes her for wasting his time and, after a cursory examination, informs her she has nothing wrong with her heart and discharges her with the advice that she should quit smoking. His discharge diagnosis is \"anxiety state.\" The patient is returned to the addictions centre, where she continues to complain of chest pain but is reassured that she has a normal cardiogram and has been \"medically cleared\" by the emergency department. Later in the evening, she suffers a cardiac arrest from which she cannot be resuscitated. At autopsy, multiple small emboli are evident in both lungs, with bilateral massive pulmonary saddle emboli. SOURCE: Croskerry, 2012. Reprinted, with permission, from P. Croskerry 2012. Copyright 2012 by Longwoods Publishing. Cognitive failures lead to insufficient search A 21-year-old man is brought to a trauma center by ambulance. He has been stabbed multiple times in the arms, chest, and head. He is in no significant distress. He is inebriated but cooperative. He has no dyspnea or shortness of breath; air entry is equal in both lungs; oxygen saturation, blood pressure, and pulse are all within normal limits. The chest laceration over his left scapula is deep but on exploration does not appear to penetrate the chest cavity. Nevertheless, there is concern that the chest cavity and major vessels may have been penetrated. Ultrasonography shows no free fluid in the chest; a chest film appears normal, with no pneumothorax; and an abdomi nal series is normal, with no free air. There is considerable discussion between the resident and the attending physician regarding the management of posterior chest stab wounds, but eventually agreement is reached that computed tomography (CT) of the chest is not indicated. The remaining lacerations are cleaned and sutured, and the patient is discharged home in the company of his friend. Five days later, he presents to a different hospital reporting vomiting, blurred vision, and difficulty concentrating. A CT of his head reveals the track of a knife wound penetrating the skull and several inches into the brain. SOURCE: Croskerry, 2013. From New England Jour nal of Medicine. P. Croskerry. From mindless to mindful practice\u2014Cognitive bias and clinical decision making. 368(26):2445-2448. 2013. Massachusetts Medical Society. Reprinted with permission from Massachusetts Medical Society. Incomplete patient history A 45-year-old woman presents to the emergency department in an agitated state. She is holding a large empty bottle of aspirin and says that she has taken all of the pills a few hours ago to 'end it all'. Her breathing and heart rate are fast; she is nauseated and complains of ringing in her ears. Blood is drawn for testing that includes a toxic screen, intravenous lines are started and treatment is begun for salicylate poisoning. Within an hour, the laboratory reports that her salicylate level is at a toxic level. Although her condition initially showed some marginal improvement, when she is reassessed by the emergency physician after two hours, the impre ssion is that she is not progressing as well D-4 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS as expected. She now appears confused and her monitor shows a marked tachycardia. While the physician is reflecting on her condition, the patient's partner comes to the emergency department to enquire how she is doing. The physician tells him that she is not doing as well as expected but, given that she has taken a major overdose of salicylate, she may take a little time to stabilise. Her partner pulls an empty bottle of a tricyclic antidepressant out of his pocket and says that he found it on the bedroom floor when he got home from work. He wonders if this is important. Shortly afterwards, the patient becomes hypotensive, with the monitor showing an intraventricular conduction delay with wide QRS, first-degree block and a prolonged QT interval; she then has seizures. She is intubated and transferred to the intensive care unit. SOURCE: Croskerry and Nimmo, 2011. Reprinted, with permission, from Croskerry P, Nimmo G. Journal of the Royal College of Physicians of Edinburgh 2011; 41(2): 155-62. Copyright 2011 Journal of the Royal College of Physicians of Edinburgh. Poor management plan and bias A 32-year-old female presents to the emergency department with complaints of abdominal pain and vomiting. She is black, obese, schizophrenic and has poor personal hygiene. She does not communicate very well. She is treated with intravenous fluids, analgesics and anti-emetics. Her blood work-up and urinalysis are within normal limits. A diagnosis of gastroenteritis is made and she is mobilised for discharge, but she begins to vomit again. It is getting late in the evening and the emergency physician decides to keep her overnight and arranges an ultrasound of her abdomen and repeat blood work for the morning. The following morning, the ultrasound is reported as normal, but her white cell count has gone up to 13,000/mm3. Abdominal X-rays are done and appear normal. Her condition does not improve through the day and in the late afternoon a computed tomography exam of her abdomen reveals a four-inch-long metallic/plastic foreign body, a hair clasp, in her stomach. This is removed several hours later by endoscopy. There were four handovers during the course of 28 hours in the emergency department before the correct diagnosis was made. SOURCE: Croskerry and Nimmo, 2011. Reprinted, with permission, from Croskerry P, Nimmo G. Journal of the Royal College of Physicians of Edinburgh 2011; 41(2): 155-62. Copyright 2011 Journal of the Royal College of Physicians of Edinburgh. Rushed communication leads to error The doctor informs the patient to refrain from aspirin ingestion prior to a particular laboratory test involving platelets. The consultation with the pati ent is rushed, and the physician fails to explain to the patient that aspirin is present in many medicines and that the patient should determine whether any over-the-counter product contains aspirin prior to using it. When the assay is performed, the result is incorrect. When the patient is asked about aspirin ingestion, she reports she has taken Alka-Seltzer within the past 24 ho urs, inadvertently ingesting an over-the-counter product containing aspirin. This necessitates a repeat performance of a complicated assay. SOURCE: Laposata, 2010. Republished with permission of Demos Medical Publishing, from Coagulation disorders: Quality in laboratory diagnosis, M. Laposata, 2010; permission conveyed through Copyright Clearance Center. Poor Emergency Department Diagnostic Test Tracking and Reporting A young woman with a complicated medical history, including systemic lupus erythematosis (lupus), presented to the ED with severe ankle pain, thought to be a partial Achilles tendon tear. She also had ulcerations of both of her palms. The physician performed an examination and EXAMPLES OF DIAGNOSTIC ERROR D-5 PREPUBLICATION COPY: UNCORRECTED PROOFS ordered routine blood work and blood cultures. The gram stain showed gram + cocci in clusters; the final blood culture report revealed staphylococcus aureus. The CBC with differential and urinalysis were abnormal. The lab called the results to the ED, but a new charge nurse skipped the physician's review and the standard ED al ert system. The patient went home, became septic, endured a prolonged hospital stay, and is now considered totally disabled. SOURCE: MagMutual, 2014. Reprinted, with per mission from, MagMutual Insurance Company, Atlanta, GA, 2015 Diagnosis that is beyond current medical knowledge Although alarmed at the sight of a red stream instead of straw-colored urine, Dunham Aurelius didn't realize that he needed to see a doctor. An endurance runner and triathlete in his early 20s, he brushed off the physical discomfort and reasoned that he may have pushed too hard on a long Sunday run. When the bleeding persist ed, Aurelius made an appointment with a urologist, a specialist in diseases of the urinary tract and reproductive organs. The doctor diagnosed a kidney stone, the first of many that Aurelius would endure throughout his 20s and 30s. He became an all-too-frequent patient of urologists, as well as of endocrinologists and nephrologists, who specialize, respectively, in diseases of endocrine glands and kidneys. Aurelius' kidneys formed stones at a size and frequency that surprised his doctors. He has passed more than 15 stones; one calcium phosphate mass in his kidney measured three centimeters. His doctors detected high vitamin D levels in his blood but they weren't sure of its significance or why he developed these stones. Aurelius expelled many kidney stones without re course to medical intervention. Once, he brought a bag of stones to his urologist, who hailed him as an ultimate fighter of the kidney stone world. Some stones, however, required painful and sometimes dangerous procedures. The problem worsened to the point that Aurelius was having multiple surgeries a year. He started to become desperate for a diagnosis at age 38, almost 20 years after his first stone. In 2008, Aurelius' endocrinologist at the University of New Mexico Health Sciences Center learned about the Undiagnosed Diseases Program (UDP), a new NIH program. The UDP was recruiting patients whose conditions were unexplained despite doctors' best efforts to make a diagnosis. The new program would accept referrals if there were some clue for a multidisciplinary team of doctors at NIH to follow up. In Aurelius' case, the clue was his high vitamin D levels. In 2009, he became the 37th of 75 patients evaluated in the first year of the UDP, during a week-long visit to the NIH Clinical Center. Through genomic analysis conducted in subsequent months, NIH doctors ultimately discovered that mutations in Aurelius' DNA caused loss in the function of an enzyme called CYP24A1, which results in high vitamin D levels. With his wife's help, Aurelius made dietary changes that ha ve brought about vast improvements in his condition (MacDougall, 2013). REFERENCES CRICO. 2014. 2014. Annual benchmarking report (2014): Malpractice risks in the diagnostic process. Cambridge, MA: CRICO Strategies. http://www .rmfstrategies.com/benchmarking (accessed June 11, 2015). Croskerry, P. 2012. Perspectives on diagnostic failure and patient safety. Healthcare Quarterly 15(Special issue) April:50-56. Croskerry, P. 2013. From mindless to mindful prac tice\u2014Cognitive bias and clinical decision making. New England Journal of Medicine 368(26):2445-2448. Croskerry, P., and G. Nimmo. 2011. Better clinical decision making and reducing diagnostic error. Journal of the Royal College of Physicians of Edinburgh 41(2):155-162. D-6 IMPROVING DIAGNOSIS IN HEALTH CARE PREPUBLICATION COPY: UNCORRECTED PROOFS IOM (Institute of Medicine). 2000. To err is human: Building a safer health system . Washington, DC: The National Academies Press. Laposata, M. 2010. disorders: Quality in laboratory diagnosis . New York: Demos Medical Publishing. MacDougall, R. 2013. Expanding the limits of modern me dicine: NIH Undiagnosed Diseases Network will address abundance of mystery cases. http://www.genome.go v/27552767 (accessed A ugust 18, 2015). MagMutual. 2014. Poor ED lab tracking and reporting system results in sepsis treatment delay. www.magmutual.com/sites/default/files/PoorEDLabTrack _SepsTreatmDelay.pdf (accessed July 23, 2015). Sarkar, U., R. M. Wachter, S. A. Schroeder, and D. Sc hillinger. 2009. Refocusing the lens: Patient safety in ambulatory chronic disease care. Joint Commission Journal on Quality and Patient "}