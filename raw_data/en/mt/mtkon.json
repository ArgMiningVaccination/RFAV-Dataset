{"title": "PDF", "author": "PDF", "url": "https://www.cs.uic.edu/~dasgupta/book-dasgupta-liang.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "Bhaskar DasGupta Department of Computer Science University of Illinois at Chicago Chicago, IL 60607 Jie Liang Department of Bioengineering University of Illinois at Chicago Chicago, IL 60607 A JOHN WILEY & SONS, INC., PUBLICATIONCopyright \u00a92011 by John Wiley & Sons, Inc. All rights reserve d. Published by John Wiley & Sons, Inc., Hoboken, New Jersey. Published simultaneously in Canada. No part of this publication may be reproduced, stored in a ret rieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, rec ording, scanning, or otherwise, except as permitted under Section 107 or 108 of the 1976 United States C opyright Act, without either the prior written permission of the Publisher, or authorization thro ugh payment of the appropriate per-copy fee to the Copyright Clearance Center, Inc., 222 Rosewood Drive, D anvers, MA 01923, (978) 750-8400, fax (978) 646-8600, or on the web at www.copyright.com. Requ ests to the Publisher for permission should be addressed to the Permissions Department, John Wiley & Son s, Inc., 111 River Street, Hoboken, NJ 07030, (201) 748-6011, fax (201) 748-6008. Limit of Liability/Disclaimer of Warranty: While the publi sher and author have used their best eorts in preparing this book, they make no representations or warran ties with respect to the accuracy or completeness of the contents of this book and specically di sclaim any implied warranties of merchantability or tness for a particular purpose. No warr anty may be created or extended by sales representatives or written sales materials. The advice and strategies contained herin may not be suitable for your situation. You should consult with a profe ssional where appropriate. Neither the publisher nor author shall be liable for any loss of prot or a ny other commercial damages, including but not limited to special, incidental, consequential, or o ther damages. For general information on our other products and services p lease contact our Customer Care Department with the U.S. at 877-762-2974, outside the U.S. a t 317-572-3993 or fax 317-572-4002. Wiley also publishes its books in a variety of electronic for mats. Some content that appears in print, however, may not be available in electronic format. Library of Congress Cataloging-in-Publication Data: Models and Algorithms for Biomolecules and Molecular Netwo rks / Bhaskar DasGupta and Jie Liang p. cm.\u2014(Wiley series in survey methodology) \"Wiley-Interscience.\" Includes bibliographical references and index. Printed in the United States of America. 10 9 8 7 6 5 4 3 2 1Dedicated to our spouses and studentsCONTENTS List of Figures xi List of Tables xvii Foreword xix Acknowledgments xxi 1 Geometric models of protein structure and function predic tion 1 1.1 Introduction 1 1.2 Theory and model 2 1.2.1 Idealized ball model 2 1.2.2 Surface models of proteins 3 1.2.3 Geometric constructs 4 1.2.4 Topological structures 6 1.2.5 Metric measurements 9 1.3 Algorithm and computation 12 1.4 Applications 15 1.4.1 Protein packing 15 1.4.2 Predicting protein functions from structures 16 1.5 Discussion and summary 18 References 23 Exercises 26 vvi CONTENTS 2 Scoring functions for predicting structure and binding of proteins 29 2.1 Introduction 29 2.2 General framework of scoring function and potential function 31 2.2.1 Protein representation and descriptors 31 2.2.2 Functional form 31 2.2.3 Deriving parameters of potential functions 32 2.3 Statistical method 32 2.3.1 Background 32 2.3.2 Theoretical model 32 2.3.3 Miyazawa-Jernigan contact potential 34 2.3.4 Distance dependent potential function 41 2.3.5 Geometric potential functions 44 2.4 Optimization method 47 2.4.1 Geometric nature of discrimination 48 2.4.2 Optimal linear potential function 50 2.4.3 Optimal nonlinear potential 51 2.4.4 Deriving optimal nonlinear scoring function 52 2.4.5 Optimization techniques 53 2.5 Applications 53 2.5.1 Protein structure prediction 53 2.5.2 Protein-protein docking prediction 54 2.5.3 Protein design 56 2.5.4 Protein stability and binding anity 57 2.6 Discussion and summary 58 2.6.1 Knowledge-based statistical potential functions 58 2.6.2 Relationship of knowledge-based energy functions and further development 61 2.6.3 Optimized potential function 63 2.6.4 Data dependency of knowledge-based potentials 64 References 67 Exercises 75 3 Sampling techniques: Estimating evolutionary rates and g enerating molecular structures 77 3.1 Introduction 77 3.2 Principles of Monte Carlo sampling 79 3.2.1 Estimation through sampling from target distribution 79 3.2.2 Rejection sampling 80 3.3 Markov chains and Metropolis Monte Carlo sampling 81 3.3.1 Properties of Markov chains 81 3.3.2 Markov chain Monte Carlo sampling 83CONTENTS vii 3.4 Sequential Monte Carlo sampling 84 3.4.1 Importance sampling 85 3.4.2 sequential importance sampling 85 3.4.3 Resampling 89 3.5 Applicatoins 90 3.5.1 Markov Chain Monte Carlo for evolutionary rate estimation 90 3.5.2 Sequentail chain growth Monte Carlo for estimating conformational entropy of RNA loops 93 3.6 Discussion and summary 94 References 97 Exercises 99 4 Stochastic molecular networks 103 4.1 Introduction 103 4.2 Reaction system and discrete chemical master equation 104 4.3 Direct solution of chemical master equation 106 4.3.1 State enumeration with nite buer 106 4.3.2 Generalization and Multi-Buer dCME method. 107 4.3.3 Calculation of steady state probability landscape 108 4.3.4 Calculation of dynamically evolving probability landscape108 4.3.5 Methods for state space truncation for simplication 108 4.4 Quantifying and controlling errors from state space truncation 111 4.5 Approximating discrete chemical master equation 113 4.5.1 Continuous chemical master equation 113 4.5.2 simulation 117 4.6.1 Reaction probability 117 4.6.2 Reaction trajectory 117 4.6.3 Probability of reaction trajectory 118 4.6.4 Stochastic simulation algorithm 118 4.7 Applications 120 4.7.1 Probability landscape of a stochastic toggle switch 121 4.7.2 Epigenetic decision network of cellular fate in phage lambda 121 4.8 Discussions and summary 125 References 127 Exercises 130 5 Cellular interaction networks 133viii CONTENTS 5.1 Basic Denitions and Graph-theoretic Notions 134 representation representation 135 5.1.3 Topological representation of dynamical models 137 5.2 Boolean interaction networks 137 5.3 Signal transduction networks 139 5.3.1 Synthesizing signal transduction networks 140 5.3.2 Collecting data for network synthesis 142 5.3.3 Transitive reduction and pseudo-node collapse 144 5.3.4 Redundancy and degeneracy of networks 149 5.3.5 Random interaction networks and statistical evaluations 153 5.4 Reverse engineering of biological networks 155 5.4.1 Modular response analysis approach 156 5.4.2 Parsimonious combinatorial approaches 163 5.4.3 Evaluation of quality of the reconstructed network 166 References 168 Exercises 173 6 Dynamical systems and interaction networks 177 6.1 Some basic control-theoretic concepts 179 6.2 Discrete-time Boolean network models 180 6.3 Articial neural network models 181 6.3.1 Computational powers of ANNs 183 6.3.2 Reverse engineering of ANNs 184 6.3.3 Applications of ANNmodels in studying biological networks 185 6.4 Piecewise linear models 186 6.4.1 Dynamics of Plmodels 187 6.4.2 Biological application of Plmodels 188 6.5 Monotone 193 6.5.1 Denition of Algorithmic issues in computing the degree of monotonicity M 199 References 201 Exercises 207 7 Case study of biological models 209 7.1 Segment polarity network models 209 7.1.1 Boolean network model 210CONTENTS ix 7.1.2 Signal transduction network model 210 7.2 ABA-induced stomatal closure network 211 7.3 Epidermal growth factor receptor signaling network 212 7.4 C. elegans metabolic network 214 7.5 Network for T cell survival and death in large granular lymphocyte leukemia 215 References 216 Exercises 217 Glossary 219 Index 221LIST OF FIGURES 1.1 Geometric models of protein surfaces. 3 1.2 Geometry of a simplied two dimensional model molecule. 5 1.3 The family of alpha shapes or dual simplicial complexes for a two-dimensional toy molecule. 7 1.4 An illustration of a family of alpha shapes of HIV-1 protease and flips. 8 1.5 An example of analytical area calculation. 10 1.6 Discrete flow of empty space illustrated for two dimensional disks . 12 1.7 The computed surface pockets of binding sites on Ras21 protein and FtsZ protein. 12 1.8 An illustration of locally Delaunay edge andflips. 13 1.9 Scaling of voids and pockets of a set of 636 proteins representin g most of the known protein folds. 15 1.10 Protein function prediction as illustrated by the example of alpha amylases. 19 2.1 The Miyazawa-Jernigan model of chemical reaction. 36 2.2 Schematic drawing of the Delaunay complex and the alpha shape of a two-dimensional molecule. 45 xixii LIST OF FIGURES 2.3 Schematic illustration of non-interacting pairs of residues. 46 2.4 Geometric views of the inequality requirement for protein scoring function. 49 2.5 Recognition of binding surface patch of protein targets using geometric potential function. 55 3.1 The Ising model of 30 \u00d730 size, with a total of 30 \u00d730 = 900 sites. 80 3.2 Illustration of rejection sampling. 81 3.3 Generating self-avoiding chain by sequential importance sampling . 88 3.4 An example of a phylogenetic tree. 91 4.1 The stochastic network of a toggle switch. 120 4.2 The steady state probability landscape of a toggle switch. 120 4.3 Dierent selection of cell fate of E. coliinfected by phage lambda and a model of the epigenetic circuit for lysogeny maintenance. 122 4.4 The probability landscape of the epigenetic circuits of lysogeny maintenance in phage lambda. 123 4.5 Instability, shallow threshold, and switching ineciency of the network against fluctuation in UV irradiation in mutant phage lambda. 124 5.1 Illustration of the labeled directed graph representation for a molecular interaction network. The arc BAindicates a negative influence of BonA,i.e., an increase in the amount of protein Bcauses a decrease in the amount of protein A. The pathway BCADinduces a positive influence of BonD since the product of labels of its arcs is 1 \u00d7(1)\u00d7(1) = 1. 135 5.2 A Boolean circuit composed of logical AND, OR and NOT gates that encodes relationships between three proteins and two genes . For example, either Protein B must be absent or Protein C must be present (or both) to activate Gene Y. 135 5.3 (a)A Boolean network with three binary states s1,s2,s3.(b) The associated directed graph. A xed point of the network is given by/vector s=/parenleftbig s1,s2,s3/parenrightbig = (0,1,0). 138 5.4 An algorithmic framework for synthesizing signal transduction networks [5]. The optimization steps involving TrandPncare explained in Section 5.3.3. 141 5.5 Dynamic programming algorithm to nd all reachabilities. 143 5.6 Pictorial illustration of the iterative calculations of the dynamic programming algorithm in Fig. 5.5. 143 5.7 The transitive reduction ( Tr) problem. 145LIST OF FIGURES xiii 5.8 An example of obtaining a reduced network via transitive reduction. The obtained network is not minimal (see Exercise 5.4).1 45 5.9 A greedy algorithm to solve Tr. 146 5.10 An example of a family of graphs for which the greedy algorithm has an approximation ratio of 2. The greedy algorithm may remove the arcs vivi+1fori= 1,2,...,n1 providing a solution with 2 narcs, but an optimal solution with n+ 1 arcs is possible by selecting the arcs v0v1,vivi+1for i= 1,2,...,n1, andvnv0. 147 5.11 The pseudo-node collapse ( Pnc) problem [5]. 148 5.12 A system of seven elements. 150 5.13 Equivalence of dynamical properties may depend on node funct ions.152 5.14 (a)The Markov-chain algorithm for generating random networks by arc swapping. (b)A pictorial illustration of arc swapping. 155 5.15 A schematic diagram for the overview of the Mraapproach. 156 5.16 Linear algebraic formulation of the experimental design questio n for the Mraapproach. 158 5.17 A combinatorially equivalent reformulation of (5.6). 161 5.18 Two well-known algorithms to solve SC1[84]. 161 5.19 Improved randomized approximation algorithm for SC[14]. 162 5.20 (a)Measurements of 5 genes /BZ1, /BZ2, /BZ3,/BZ4and /BZ5at two successive time steps; variable xicorrespond to gene /BZi.(b)A causal relationship and Boolean formula that explains the causal relationship of other variables to x5based only on the data shown in (a).(c)Another causal relationship and Boolean formula for /BZ5that is consistent with the data in (a).163 5.21 (a)Data matrix X=/parenleftbig xi,j/parenrightbig (quantized to four values) for measurement of expression levels of m= 5 genes at n+1 = 4 time points. (b)The universe and sets corresponding to gene /BZ2 in the hitting set formulation of Fig. 5.22 (a). 164 5.22 (a)A hitting set formulation of the combinatorial approach for gene /BZi.(b)A greedy algorithm for HSthat iteratively selects a new element of the universe that hits a maximum number of sets not hit yet. 165 5.23 Two dimensional Rocspace obtained by plotting FPRversus TPRvalues. 168xiv LIST OF FIGURES 5.24 Three n-node graphs (shown for n= 8) discussed in Exercise 5.6. 175 5.25 Contraction of a cycle of length 4. 176 6.1 A Boolean network of two species interaction. 181 6.2 A discrete-time sigmoidal neural network and its graphical representation. 182 6.3 (a)The threshold gate function. (b)The sigmoidal gate function. 182 continuous-state discrete-time ANNwith gate functiong.(b)The dierence equation model corresponding to theANNin (a).Riis the maximum rate of synthesis of gene vi,iis the degradation rate of the product from gene vi, and the threshold isummarizes the eect of general transcription factors on gene vi.(c)The specic activation function gused by Kyoda et al.[62].(d)The the model in (b)indicating excitory and inhibitory eects. 186 6.5 Rectangular partition of state space induced by system (6.7). 190 6.6 (a)An example of a Nfa. The input 0101 is accepted by theNfasince there is a directed path from the initial state q0to a nal state q2labeled 0101. (b)An example of a piecewise-linear hybrid automata ( Plha) with two continuous state variables and no inputs. A hypothetical trajectory of the dynamics is shown by thick black lines with arrows. 191 6.7 Hexagonal lattice of cells for Delta-Notch protein signalling. A cell with its six neighbors is shown amplied. 192 6.8 A system composed of ve interconnected subsystems. 193 6.9 Two signed graphs. The graph in (a)is sign-consistent, but the graph in (b), which diers in just one edge from (a), is not sign-consistent since it has two paths in its undirected version with dierent parity between nodes x1x4, namely a direct path of odd parity and a path of even parity transversing node x5. Self-loops, which in biochemical systems often represent degradation terms, are ignored in the denition. 197 6.10 Denition of the sign consistency problem. 198 6.11 Deletion of the arc/parenleftbig x2,x4/parenrightbig makes the given signed graph consistent. The node labels are shown besides the nodes. 198 7.1 A schematic diagram of the early development of a Drosophila embryo. Each hexagon represents a cell, and neighboring cells interact to form a collective behavior. In this gure, an initial striped pattern of the genes enandwginduces the production of the gene hh, but only in those cells that are producing en. 210LIST OF FIGURES xv 7.2 [8] The Drosophila segment polarity regulatory network for one cell with the interpretation of the regulatory role of PTCon the reaction CICNasPTCCNandPTCCI. 211 7.3 A 1-dimensional 3-cell Drosophila segment polarity regulatory network with cyclic boundary conditions. 212 7.4 A pictorial representation of the network manually synthesized by Liet al.[15]. Nodes in the network correspond to proteins, genes and other small molecules ( e.g.,RAC1is a small GTPase protein). 213LIST OF TABLES 2.1 Miyazawa-Jernigan contact energies in kTunits. 40 2.2 Recognition of native binding surface of CAPRI targets by alpha potential function. 56 xviiFOREWORD The subjects of this book are biomolecules and biomolecular networks. The rst part of the book will cover surface and volume representatio n of the structures of biomolecules based on the idealized ball model. The underly ing geometric con- structs as well as their computation will then be discussed. This will be followed by the chapter on constructing eective scoring functions in d ierent functional forms using either the statistical approach or the optimization a pproach, with the goal of identifying native-like protein structures or protein- protein interfaces, as well as constructing a general tness landscape for protein design . The topic of sampling and estimation that can be used to generate biomolecular str uctures and to esti- mate their evolutionary patterns are then discussed, with e qual emphasis on the Metropolis Monte Carlo (or Markov Chain Monte Carlo) approa ch and the chain growth (or sequential Monte Carlo) approach. This is follow ed by a chapter cov- ering the topic of stochastic networks formed by interactin g biomolecules and the framework of discrete chemical master equations, as well as computational meth- ods for direct numerical computation and for sampling react ion trajectories of the probabilistic landscape of these networks. The second part of the book will cover interaction networks o f biomolecules. We will discuss stochastic models for networks with small copy numbers of molecular species, as those arising in genetic circuits, protein synt hesis, and transcription binding, and algorithms of computing the properties of stoc hastic molecular net- works. We will then cover signal transduction networks that arise, for example, in complex interactions between the numerous constituents su ch as DNAs, RNAs, pro- teins and small molecules in a complex biochemical system su ch as a cell. We will also discuss the experimental protocols and algorithmic me thodologies necessary to xixxx FOREWORD synthesize these networks. Of special interest will be the s ynthesis these networks from double-causal experimental evidences and methods for reverse engineering of such networks based on suitable experimental protocols. This book is written for graduate students, upper division u ndergraduate stu- dents, engineers, and scientists in academia and industrie s from a variety of disci- plines, such as bioengineering, biophysics, electric engi neering, chemical engineer- ing, mathematics, biology, and computer science. It may als o serve as a useful reference for researchers in these disciplines, including professional engineers, pro- fessional statisticians, as well as practicing scientists in pharmaceutical industry and biotechnology industry. This book may be used as a monogr aph for learning important research topics, and for nding algorithms and so lutions to problems encountered in research and in practice.ACKNOWLEDGMENTS For DasGupta, this book could not have been written without c ollaboration with a large number of collaborators from dierent research area s, and he thanks all of them for their involvements. Special thanks go to his coll eagues R\u00e9ka Albert, Piotr Berman and Eduardo Sontag for their enormous patience and contribution during collaborations. He would like to thank individually all the students and post-doctoral fellows involved in these projects and German Enciso). DasGupta thankfully acknowledge generous nancial support from the National from the DIMACS Center of Rutg ers University during his Sabbatical leave through their special focus on c omputational and math- ematical epidemiology. Last, but not the least, DasGupta th anks his wife Paramita Bandopadhyay for her help, understanding and cooperation w hile the book was being written. For Jie Liang, the material in this book draws on research col laborations with many colleagues, to whom he is grateful. Special thanks go to Rong Chen, Ken Dill, Linda Kenney, Herbert Edelsbrunner, and Shankar Subr amaniam, with whom he has worked with when embarking on new research directions . He also has the good fortunate of working with a group of talented students a nd postdoctoral re- searchers, who have contributed to research projects, some of which are reflected in material described in this book: Larisa Adamian, n Terebus, Wei Tian, Jerey Tseng, Yaron Turpaz, Yu n Xu, Jian Zhang, and Jinfeng Zhang. Jie Liang also thanks students at the Univ ersity of Illinois at Chicago who have taken the bioinformatics courses he taught . Jie Liang thanks Xiang Li for co-writing the material for the chapter on scori ng function together, and Ke Tang for help in preparing the gures. Jie Liang also ac knowledges gener- ous research support from the National Institute of Health ( GM079804, GM086145, GM68958, and DBI-0646035, and search (N000140310329 and N00014-06), the Whittaker Found ation, the Chicago Biomedical Consortium, and the Petroleum Research Fund (PR F#35616-G7). Fi- nally, he wishes to thank his wife Re-Jin Guo for her understa nding and patience during the period when the book is being written. B. D. and J. L.CHAPTER 1 GEOMETRIC MODELS OF PROTEIN STRUCTURE AND FUNCTION PREDICTION 1.1 Introduction Three-dimensional atomic structures of protein molecules provide rich information for understanding how these working molecules of a cell carr y out their biological functions. With the amount of solved protein structures rap idly accumulating, computation of geometric properties of protein structure b ecomes an indispensable component in studies of modern biochemistry and molecular b iology. Before we discuss methods for computing the geometry of protein molec ules, we rst briefly describe how protein structures are obtained experimental ly. There are primarily three experimental techniques for obta ining protein struc- tures: X-ray crystallography, cently electron microscopy (cryo-EM). In X- ray crystallography, the diraction patterns of X-ray irradiation of a high quality c rystal of the protein molecule are measured. Since the diraction is due to the sca ttering of X-ray by the electrons of the molecules in the crystal, the position, the intensity, and the phase of each recorded diraction spot provide information for the reconstruction of anelectron density map of atoms in the protein molecule. Based on independent information of the amino acid sequence, a model of the protei n conformation is then derived by tting model conformations of residues to the ele ctron density map. An iterative process called renement is then applied to improve the quality of the t of the electron density map. The nal model of the protein con formation consists of the coordinates of each of the non-hydrogen atoms [46]. Models and Algorithms for Biomolecules and Molecular Netwo rks, rst edition. By Bhaskar DasGupta and Jie Liang Copyright \u00a9 2015 John Wiley & S ons, Inc.12GEOMETRIC MODELS OF PROTEIN STRUCTURE AND FUNCTION PREDICT ION The solution NMR technique for solving protein structure is based on measuring the tumbling and vibrating motion of the molecule in solutio n. By assessing the chemical shifts of atomic nuclei with spins due to interacti ons with other atoms in the vicinity, a set of estimated distances between speci c pairs of atoms can be derived from NOSEY spectra. When a large number of such dista nces are obtained, one can derive a set of conformations of the protein molecule , each being consistent with all of the distance constraints [10]. Although determi ning conformations from either X-ray diraction patterns or NMR spectra is equivale nt to solving an ill- posed inverse problem, technique such as Bayesian Markov ch ain Monte Carlo with parallel tempering has been shown to be eective in obtainin g protein structures from NMR spectra [53]. 1.2 Theory and model 1.2.1 Idealized ball model The shape of a protein molecule is complex. The chemical prop erties of atoms in a molecule are determined by their electron charge distribut ion. It is this distribution that generates the scattering patterns of the X-ray diract ion. Chemical bonds between atoms lead to transfer of electronic charges from on e atom to another, and the resulting isosurfaces of the electron density distribu tion depend not only on the location of individual nuclei but also on interactions betw een atoms. This results in an overall complicated isosurface of electron density [2 ]. The geometric model of macromolecule amenable to convenien t computation is an idealized model, where the shapes of atoms are approxim ated by three- dimensional balls. The shape of a protein or a DNA molecule co nsisting of many atoms is then the space-lling shape taken by a set of atom bal ls. This model is often called the interlocking hard-sphere model , thefused ball model , thespace lling model [32,47,50,52], or the union of ball model [12]. In this model, details in the distribution of electron density ( e.g., the dierences between regions of covalent bonds and non-covalent bonds) are ignored. This idealizati on is quite reasonable, as it reflects the fact that the electron density reaches maxi mum at a nucleus and its magnitude decays almost spherically away from the point of the nucleus. De- spite possible inaccuracy, this idealized model has found w ide acceptance, because it enables quantitative measurement of important geometri c properties (such as area and volume) of molecules. Insights gained from these me asurements correlate well with experimental observations [9,21,32,49-51]. In this idealization, the shape of each atom is that of a ball, and its size parameter is the ball radius or atom radius. There are many possible cho ices for the parameter set of atomic radii [48,57]. Frequently, atomic radii are as signed the values of their van der Waals radii [7]. Among all these atoms, hydrogen atom has the smallest mass, and has a much smaller radius than those of other atoms. For simplication, the model of united atom is often employed to approximate the union of a heavy atom and the hydrogen atoms connected by a covalent bond. In this case, the radius of the heavy atom is increased to appr oximate the size of the union of the two atoms. This practice signicantly reduc es the total number of atom balls in the molecule. However, this approach has bee n questioned for possible inadequacy [61].THEORY AND MODEL 3 The mathematical model of this idealized model is that of the union of balls [12]. For a molecule Mofnatoms, the i-th atom is modeled as a ball bi, whose center is located at ziR3, and the radius of this ball is riR, namely, we have bi{x|xR3,||xzi||ri}parametrized by (zi,ri). The molecule Mis formed by the union of a nite number nof such . It creates a space-lling body corresponding to the union of the excluded volumes vol/parenleftbig/uniontextn i=1/braceleftbig bi/bracerightbig/parenrightbig [12]. When the atoms are assigned the van der Waals radii, the boundary surface /uniontextBof the union of balls is called the van der Waals surface. 1.2.2 Surface models of proteins Protein folds into native three-dimensional shape to carry out its biological func- tional roles. The interactions of a protein molecule with ot her molecules (such as ligand, substrate, or other protein) determine its functio nal roles. Such interactions occur physically on the surfaces of the protein molecule. The importance of protein surface was recognized very early on. Lee and Richards developed the widely used solvent accessible surface (SA) model, which is also of- ten called the Lee-Richards surface model [32]. Intuitively, this surface is obtained by rolling a ball of radius rseverywhere along the van der Waals surface of the molecule. The center of the solvent ball will then sweep out t he solvent accessible surface. Equivalently, the solvent accessible surface can be viewed as the boundary surface/uniontextBrsof the union of a set of inflated balls Brs, where each ball takes the position of an atom, but with an inflated radius ri+rs(Fig. 1.1 a). b a c Figure 1.1 Geometric models of protein surfaces. a. The solvent accessible surface (SA surface) is shown in the front. The van der Waals surface (ben eath the SA surface) can be regarded as a shrunken version of the SA surface by reducing a ll atomic radii uniformly by the amount of the radius of the solvent probe rs= 1.4Angstrom. The elementary pieces of the solvent accessible surface are the three convex spher ical surface pieces, the three arcs, and the vertex where the three arcs meet. b. The molecular surface (MS, beneath the SA surface) also has three types of elementary pieces: the conv ex spherical pieces, which are shrunken version of the corresponding pieces in the solvent accessible surface, the concave toroidal pieces, and concave spherical surface. The latter two are also called the re-entrant surface. c. The toroidal surface pieces in the molecular surface, corr espond to the arcs in the solvent accessible surface, and the concave spherical s urface to the vertex. The set of elements in one surface can be continuously deformed to the s et of elements in the other surface. The solvent accessible surface in general has many sharp cre vices and sharp corners. In hope of obtaining a smoother surface, one can tak e the surface swept4GEOMETRIC MODELS OF PROTEIN STRUCTURE AND FUNCTION PREDICT ION out by the front instead of the center of the solvent ball. Thi s surface is the molecular surface (MS model), which is also often called the Connolly's surface after Michael Connolly who developed the rst algorithm for computing molecular surface [9]. Both solvent accessible surface and molecular surface are formed by elementary pieces of simpler shape. Elementary pieces. For the solvent accessible surface model, the boundary sur- face of a molecule consists of three types of elements: the co nvex spherical surface pieces, arcs or curved line segments (possibly a full circle ) formed by two intersect- ing spheres, and a vertex that is the intersection point of th ree atom spheres. The whole boundary surface of the molecules can be thought of as a surface formed by stitching these elements together. Similarly, the molecular surface swept out by the front of th e solvent ball can also be thought of as being formed by elementary surface piec es. In this case, they are the convex spherical surface pieces, the toroidal surfa ce pieces, and the concave or inverse spherical surface pieces (Fig. 1.1 b) . The latter two types of surface pieces are often called the \"re-entrant surfaces\" [9,50]. The surface elements of the solvent accessible surface and t he molecular surface are closely related. Imagine a process where atom balls are s hrunk or expanded. The vertices in solvent accessible surface becomes the conc ave spherical surface pieces, the arcs becomes the toroidal surfaces, and the conv ex surface pieces become smaller convex surface pieces (Fig. 1.1 c). Because of this m apping, these two type of surfaces are combinatorially equivalent and have simila r topological properties, i.e., they are homotopy equivalent. However, the SA surface and the MS surface dier in their metr ic measurement. In concave regions of a molecule, often the front of the solve nt ball can sweep out a larger volume than the center of the solvent ball. A void of s ize close to zero in solvent accessible surface model will correspond to a void o f the size of a solvent ball (4r3 s/3). It is therefore important to distinguish these two types o f measurement when interpreting the results of volume calculations of pro tein molecules. The intrinsic structures of these fundamental elementary piec es are closely related to several geometric constructs we describe below. 1.2.3 Geometric constructs Voronoi diagram. Voronoi diagram (Fig. 1.2 a), also known as Voronoi tessella - tion, is a geometric construct that has been used for analyzi ng protein packing in the early days of protein crystallography [18,20,47]. For t wo dimensional Voronoi diagram, we consider the following analogy. Imagine a vast f orest containing a number of re observation towers. Each re ranger is respons ible for putting out any re closer to his/her tower than to any other tower. The se t of all trees for which a ranger is responsible constitutes the Voronoi cell a ssociated with his/her tower, and the map of ranger responsibilities, with towers a nd boundaries marked, constitutes the Voronoi diagram. We formalize this for three dimensional space. Consider the point setSof atom centers in three dimensional space R3. The Voronoi region orVoronoi cell Viof an atombiwith atom center ziR3is the set of all points that are at least as closeTHEORY AND MODEL 5 void a c b Figure 1.2 Geometry of a simplied two dimensional model molecule, to i llustrate the geometric constructs and the procedure mapping the Voronoi diagram to the Delaunay triangulation. a. The molecule formed by the union of atom disks of uniform siz e. Voronoi diagram is in dashed lines. b. The shape enclosed by the boundary polygon is the convex hull. It is tessellated by the Delaunay triangulation .c. The alpha shape of the molecule is formed by removing those Delaunay edges and triangles whose corresponding Voronoi edges and Voronoi vertices do not intersect with the body of the mol ecule. A molecular void is represented in the alpha shape by two empty triangles. tozithan to any other atom centers in S: Vi={xR3|||xzi||||xzj||,zjS}. We can have an alternative view of the Voronoi cell of an atom bi. Considering the distance relationship of atom center ziwith the atom center zkof another atom bk. The plane bisecting the line segment connecting points ziandzkdivides the fullR3space into two half spaces, where points in one half space is c loser tozi than tozk, and points in the other allspice is closer to zkthan tozi. If we repeat this process and take zkin turn from the set of all atom centers other than zi, we will have a number of halfspaces where points are closer to zithan to each of the atom center zk. The Voronoi region Viis then the common intersections of these half spaces, which is convex (see exercises). When we consid er atoms of dierent radii, we replace the Euclidean geometric construct that is closely related to the Voron oi diagram (Fig. 1.2 b). In general, it uniquely tessellates or tile up the space of the convex hull of the atom centers in R3with tetrahedra. Convex hull for a point set is the smallest convex body that contains the point set1. The Delaunay tetra- 1For a two dimensional toy molecule, we can imagine that we put nails at the locations of the atom centers, and tightly wrap a rubber band around these nai ls. The rubber band will trace out a polygon. This polygon and the region enclosed within is the convex hull of the set of points corresponding to the atom centers. Similarly, imagine if we can tightly wrap a tin-foil around a set of points in three dimensional space, the resulting con vex body formed by the tin-foil and space enclosed within is the convex hull of this set of points inR3.6GEOMETRIC MODELS OF PROTEIN STRUCTURE AND FUNCTION PREDICT ION hedrization of a molecule can be obtained from the Voronoi di agram. Consider that the Delaunay tetrahedrization is formed by gluing four type s of primitive elements together: vertices, edges, triangles, and tetrahedra. Her e vertices are just the atom centers. We obtain a Delaunay edge by connecting atom center sziandzjif and only if the Voronoi regions ViandVjhave a common intersection, which is a planar piece that may be either bounded or extend to innity. We obta in a Delaunay tri- angle connecting atom centers zi,zj, andzkif the common intersection of Voronoi regionsVi,VjandVkexists, which is either a line segment, or a half-line, or a li ne in the Voronoi diagram. We obtain a Delaunay tetrahedra conn ecting atom centers zi,zj,zkandzlif and only if the Voronoi regions Vi,Vj,VkandVlintersect at a point. 1.2.4 Topological structures Delaunay complex. The structures in both Voronoi diagram and Delaunay tetra- hedrization are better described with concepts from algebr aic topology. We focus on the intersection relationship in the Voronoi diagram and introduce concepts for- malizing the primitive elements. In R3, between two to four Voronoi regions may have common intersections. We use simplices of various dimensions to record these intersection or overlap relationships. We have vertices 0as 0-simplices, edges we use 0-simplices to represent the Voronoi cells, and add them to the simplices induced by the intersection relations hip, we can think of the Delaunay tetrahedrization as the structure obtained by \"gluing\" these simplices properly together. Formally, these simplices form a simplicial complex K: K={|I|1|/intersectiondisplay iIVi\\e}io\\slsh=}, whereIis an index set for the vertices representing atoms whose Vor onoi cells overlap, and|I|1is the dimension of the simplex. Alpha shape and protein surfaces. Imagine we can turn a knob to increase or decrease the size of all atoms simultaneously. We can then ha ve a model of growing balls and obtain further information from the Delaunay comp lex about the shape of a protein structure. Formally, we use a parameter Rto control the size of the atom balls. For an atom ball biof radiusri, we modied its radius riat a particular value tori() = (r2 i+)1/2. Whenri< <0, the size of an atom is shrunk. The atom could even disappear if <0and||> ri. With this construction of , the weighted Voronoi diagram is invariant with regard to (see exercises). We start to collect the simplices at dierent value as we increase fromto+(see Fig. 1.3 for a two-dimensional example). At the beginni ng, we only have vertices. When is increased such that two atoms are close enough to intersect, we collect the corresponding Delaunay edge th at connects these two atom centers. When three atoms intersect, we collect the cor responding DelaunayTHEORY AND MODEL 7 a b c d e f Figure 1.3 The family of alphashapes or dual simplicial complexes for a two-dimensional toy molecule. a. We collect simplices from the Delaunay triangulation as at oms grow by increasing the value. At the beginningas grows from , atoms are in isolation and we only have vertices in the alpha shape. bandc. Whenis increased such that some atom pairs start to intersect, we collect the corresponding Dela unay edges. d. When three atoms intersect as increases, we collect the corresponding Delaunay triangle s. When = 0, the collection of vertices, edges, and triangles form the du al simplicial complex K0, which reflecting the topological structure of the protein molecul e.e. More edges and triangles from the Delaunay triangulation are now collected as atoms c ontinue to grow. f. Finally, all vertices, edges, and triangles are now collected as atoms ar e grown to large enough size. We get back the full original Delaunay complex. triangle spanning these three atom centers. When four atoms intersect, we collect the corresponding Delaunay tetrahedron. At any specic value, we have a dual simplicial complex oralpha complexK formed by the collected simplices. If all atoms take the incr emented radius of ri+rs and= 0, we have the dual simplicial complex K0of the protein molecule. When is suciently large, we have collected all simplices and we g et the full Delaunay complex. This series of simplicial complexes at dierent value form a family of shapes (Fig. 1.3), called alpha shapes , each faithfully represents the geometric and topological property of the protein molecule at a particula r resolution parametrized by thevalue. Fig. 1.4 illustrates an example of the alpha shapes of the HIV-1 protease at dierent values. An equivalent way to obtain the alpha shape at = 0is to take a subset of the simplices, with the requirement that the corresponding intersections of Voronoi cells must overlap with the body of the union of the balls. We o btain the dual8GEOMETRIC MODELS OF PROTEIN STRUCTURE AND FUNCTION PREDICT ION Figure 1.4 An illustration of a family of alpha shapes of HIV-1 protease asvalue increases from left to right and top to bottom. As increases, more edges, triangles, and tetrahedra enter the collection of simplices. At each value, the collected simplices form a simplicialcomplex. When issucientlylarge, weobtainthefullDelaunaytetrahedri zation. complex or alpha shape K0of 0(Fig. 1.2 c): K0=/braceleftigg |I|1/vextendsingle/vextendsingle/vextendsingle/intersectiondisplay iIVi/uniondisplay B\\e}io\\slsh=/bracerightigg . Alpha shape provides a guide map for computing geometric pro perties of the structures of biomolecules. Take the molecular surface as a n example, the re-entrant surfaces are formed by the concave spherical patch and the to roidal surface. These can be mapped from the boundary triangles and boundary edges of the alpha shape, respectively [14]. Recall that a triangle in the Dela unay tetrahedrization corresponds to the intersection of three Voronoi regions, i.e., a Voronoi edge. For a triangle on the boundary of the alpha shape, the correspond ing Voronoi edge intersects with the body of the union of balls by denition. I n this case, it intersects with the solvent accessible surface at the common intersect ing vertex when the three atoms overlap. This vertex corresponds to a concave sp herical surface patch in the molecular surface. For an edge on the boundary of the al pha shape, the corresponding Voronoi plane coincides with the intersecti ng plane when two atoms meet, which intersect with the surface of the union of balls o n an arc. This line segment corresponds to a toroidal surface patch. The remain ing part of the surface are convex pieces, which correspond to the vertices, namely , the atoms on the boundary of the alpha shape.THEORY AND MODEL 9 The numbers of toroidal pieces and concave spherical pieces are exactly the numbers of boundary edges and boundary triangles in the alph a shape, respectively. Because of the restriction of bond length and the excluded vo lume eects, the number of edges and triangles in molecules are roughly in the order ofO(n)[38]. 1.2.5 Metric measurements We have described the relationship between the simplices an d the surface elements of the molecule. Based on this type of relationship, we can co mpute eciently size properties of the molecule. We take the problem of volum e computation as an example. Consider a grossly incorrect way to compute the volume of a pr otein molecule using the solvent accessible surface model. We could dene t hat the volume of the molecule is the summation of the volumes of individual at oms, whose radii are inflated to account for solvent probe. By doing so we would have signicantly inflated the value of the true volume, because we neglected to consider volume overlaps. We can explicitly correct this by following the in clusion-exclusion formula: when two atoms overlap, we subtract the overlap; when three a toms overlap, we rst subtract the pair overlaps, we then add back the triple overl ap,etc. This continues when there are four, ve, or more atoms intersecting. At the c ombinatorial level, the principle of inclusion-exclusion is related to the Gaus s-Bonnet theorem used by Connolly [9]. The corrected volume V(B)for a set of atom balls then V(B) =/summationdisplay vol(/intersectiontextT)>0 degree, TBis a subset of the balls with non-zero volume overlap: vol(/intersectiontextT)>0. However, the straightforward application of this inclusio n-exclusion formula does not work. The degree of overlap can be very high: theoretical and simulation studies showed that the volume overlap can be up to 7-8 degrees [29,45 ]. It is dicult to keep track of these high degree of volume overlaps correctly during computation, and it is also dicult to compute the volume of these overlaps because there are many dierent combinatorial situations, i.e., to quantify how large is the k-volume overlap of which one of the/parenleftbig7 k/parenrightbig or/parenleftbig8 k/parenrightbig overlapping atoms for all of k= 2,\u00b7\u00b7\u00b7,7[45]. It turns out that for three-dimensional molecules, overlap s of ve or more atoms at a time can always be reduced to a \" +\" or a \"\" signed combination of overlaps of four or fewer atom balls [12]. This requires that the 2-bod y, 3-body, and 4-body terms in Equation (1.1) enter the formula if and only if the co rresponding edge ijconnecting the two balls (1-simplex), triangles ijkspanning the three balls (2-simplex), and tetrahedron ijklcornered on the four balls (3-simplex) all exist in the dual simplicial complex K0of the molecule [12,38]. Atoms corresponding to these simplices will all have volume overlaps. In this case, we have the simplied10 GEOMETRIC MODELS OF PROTEIN STRUCTURE AND FUNCTION PREDICT ION b1b2b3 b4 Ab1b2b3 b4 B Figure 1.5 An example of analytical area calculation. A. Area can be computed using the direct inclusion-exclusion. B. The formula is simplied without any redundant terms when using alpha V(B) =/summationdisplay iKvol(bi)/summationdisplay ijKvol(bibj) +/summationdisplay ijkKvol(bibjbk)/summationdisplay ijklKvol(bibjbkbl). The same is applicable for the calculation of surface ar ea of molecules. An example. An example of area computation by alpha shape is shown in Fig. 1.5. Letb1,b2,b3,b4be the four disks. To simplify the notation we write Aifor the area ofbi,Aijfor the area of bibj, andAijkfor the area of bibjbk. The total area of the union, b1b2b3b4, is Atotal= (A1+A2+A3+A4) (A12+A23+A24+A34) +A234. We add the area of biif the corresponding vertex belongs to the alpha complex (Fig. 1.5), we subtract the area of bibjif the corresponding edge belongs to the alpha complex, and we add the area of bibjbkif the corresponding triangle belongs to the alpha complex. Note without the guidance of th e alpha complex, the inclusion-exclusion formula may be written as: Atotal= (A1+A2+A3+A4) (A12+A13+A14+A23+A24+A34) terms: A13=A123,A14=A124, andA134= A1234. Computing these terms would be wasteful. Such redundancy d oes not occur when we use the alpha complex: the part of the Voronoi re gions containedTHEORY AND MODEL 11 in the respective atom balls for the redundant terms do not in tersect. Therefore, the corresponding edges and triangles do not enter the alpha complex. In two dimensions, we have terms of at most three disk intersection s, corresponding to triangles in the alpha complex. Similarly, in three dimensi ons the most complicated terms are intersections of four spherical balls, and they co rrespond to tetrahedra in the alpha complex. Voids and pockets. Voids and pockets represent the concave regions of a protein surface. Because shape-complementarity is the basis of man y molecular recognition processes, binding and other activities frequently occur i n pocket or void regions of protein structures. For example, the majority of enzyme r eactions take place in surface pockets or interior voids. The topological structure of the alpha shape also oers an e ective method for computing voids and pockets in proteins. Consider the Delau nay tetrahedra that are not included in the alpha shape. If we repeatedly merge an y two such tetrahedra on the condition that they share a 2-simplex triangle, we wil l end up with discrete sets of tetrahedra. Some of them will be completely isolated from the outside, and some of them are connected to the outside by triangle(s) on th e boundary of the alpha shape. The former corresponds to voids (or cavities) i n proteins, the latter corresponds to pockets anddepressions in proteins. A pocket diers from a depression in that it must have an openi ng that is at least narrower than one interior cross-section. Formally, the discrete flow [17] explains the distinction between a depression and a pocket. In a two di mensional Delaunay triangulation, the empty triangles that are not part of the a lpha shape can be classied into obtuse triangles and acute triangles. The la rgest angle of an obtuse triangle is more than 90 degrees, and the largest angle of an a cute triangle is less than 90 degrees. An empty obtuse triangle can be regarded as a \"source\" of empty space that \"flows\" to its neighbor, and an empty acute triangl e a \"sink\" that collects flow from its obtuse empty neighboring triangle(s). In Fig. 1 .6 a, obtuse triangles 1, 3, 4 and 5 flow to the acute triangle 2, which is a sink. Each of the discrete empty spaces on the surface of protein can be organized by the flow systems of the corresponding empty triangles: Those that flow together belong to the same discrete empty space. For a pocket, there is at least one sink among the empty triangles. For a depression, all triangles are obtuse, and t he discrete flow goes from one obtuse triangle to another, from the innermost region to outside the convex hull. The discrete flow of a depression therefore goes to inn ity. Fig. 1.6 b gives an example of a depression formed by a set of obtuse triangles. Once voids and pockets are identied, we can apply the inclus ion-exclusion prin- ciple based on the simplices to compute the exact size measur ement ( e.g., volume and area) of each void and pocket [17,39]. Fig. 1.7 shows the c omputed binding surface pockets on Ras21 protein and FtsZ protein. The distinction between voids and pockets depends on the spe cic set of atomic radii and the solvent radius. When a larger solvent ball is us ed, the radii of all atoms will be inflated by a larger amount. This could lead to two die rent outcomes. A void or pocket may become completely lled and disappear. On the other hand, the inflated atoms may not ll the space of a pocket, but may clo se o the opening of the pocket. In this case, a pocket becomes a void. A widely u sed practice in the past was to adjust the solvent ball and repeatedly comp ute voids, in the hope that some pockets will become voids and hence be identi ed by methods12 GEOMETRIC MODELS OF PROTEIN STRUCTURE AND FUNCTION PREDICT ION 1 23 4 51 345Infinity 2 a b Figure 1.6 Discrete flow of empty space illustrated for twodimensional disks.a. Discrete flow of a pocket. Triangles 1, 3, 4 and 5 are obtuse. The free vol ume flows to the \"sink\" triangle 2, which is acute. b. In a depression, the flow is from obtuse triangles to the outs ide. Figure 1.7 The computed surface pockets of binding sites on Ras21 prote in and FtsZ protein. designed for cavity/void computation. The pocket algorith m [17] and tools such as CastP [11,40] often makes this unnecessary. 1.3 Algorithm and computation Computing Delaunay tetrahedrization and Voronoi diagram. It is easier to discuss the computation of tetrahedrization rst. The in cremental algorithm developed in [16] can be used to compute the weighted tetrahe drization for a set of atoms of dierent radii. For simplicity, we sketch the out line of the algorithm below for two dimensional unweighted Delaunay triangulati on. The intuitive idea of the algorithm can be traced back to the o riginal observation of Delaunay. For the Delaunay triangulation of a point set, t he circumcircle of an edge and a third point forming a Delaunay triangle must not co ntain a fourth point. Delaunay showed that if all edges in a particular tria ngulation satisfy this condition, the triangulation is a Delaunay triangulation. It is easy to come up with an arbitrary triangulation for a point set. A simple alg orithm to covert thisALGORITHM AND COMPUTATION 13 triangulation to the Delaunay triangulation is therefore t o go through each of the triangles, and make corrections using \"flips\" discussed bel ow if a specic triangle contains an edge violating the above condition. The basic in gredients for computing Delaunay tetrahedrization are generalizations of these ob servations. We discuss the concept of locally Delaunay edge and the edge-flip primitive operation below. Locally Delaunay edge. We say an edge abis locally Delaunay if either it is on the boundary of the convex hull of the point set, or if it belon gs to two triangles abcandabd, and the circumcircle of contain d(e.g., edgecdin Fig. 1.8 a). 1to3 flipb 2to2 flip ab cd ab cda Figure 1.8 An illustration of locally Delaunay edge andflips.a. For the quadrilateral abcd, edgeabis circumcircle passing throug h edgeaband a third pointccontains a fourth point d. Edgecdis locally Delaunay, as bis outside the circumcircle adc. Anedge-flip or2-to-2 flip replaces edge abby edge cd, and replace the original two triangles abcandadbwith two new triangles acdandbcd.b. When a new vertex is inserted, we replace the old triangle containingthis new vertex with t hree new triangles. This is called 1-to-3flip. Edge-flip. Ifabis not locally Delaunay (edge abin Fig. 1.8 a), then the union of the two triangles abcabdis a convex quadrangle acbd, and edge cdis locally Delaunay. We can replace edge abby edgecd. We call this an edge-flip or2-to-2 flip, as two old triangles are replaced by two new triangles. We recursively check each boundary edge of the quadrangle abcdto see if it is also locally Delaunay after replacing abbycd. If not, we recursively edge-flip it. Incremental algorithm for Delaunay triangulation. Assume that we have a nite set of points (namely, atom centers) S={z1,z2,\u00b7\u00b7\u00b7,zi,\u00b7\u00b7\u00b7,zn}. We start with a large auxiliary triangle that contains all these points. W e insert the points one by one. At all times, we maintain a Delaunay triangulation Diup to insertion of pointzi. After inserting point zi, we search for the triangle i1that contains this new point. We then add zito the triangulation and split the original triangle i1into three smaller triangles. This split is called 1-to-3 flip , as it replaces one old triangle with three new triangles. We then check if each of the three ed ges ini1still satises the locally Delaunay requirement. If not, we perfo rm a recursive edge-flip. This algorithm is summarized in Algorithm I. InR3, the algorithm of tetrahedrization becomes more complex, b ut the same basic ideas apply. In this case, we need to locate a tetrahedr on instead of a triangle that contains the newly inserted point. The concept of local ly Delaunay is replaced by the concept of locally convex , and there are flips dierent than the 2-to-2 flip inR3[16]. Although an incremental approach ( i.e., sequentially adding points) is not necessary for Delaunay triangulation in R2, it is necessary in R3to avoid non-14 GEOMETRIC MODELS OF PROTEIN STRUCTURE AND FUNCTION PREDICT ION Algorithm I Delaunay triangulation. Obtain random Delaunay do flipabto other diagonal cd(2-to-2 edge flip); end while end for flippable cases and to guarantee that the algorithm will term inate. This incremental algorithm has excellent expected performance [16]. The computation of Voronoi diagram is conceptually easy onc e the Delaunay triangulation is available. We can take advantage of the mat hematical duality and compute all of the Voronoi vertices, edges, and planar faces from the Delaunay tetrahedra, triangles, and edges (see exercises). Because one point zimay be an vertex of many Delaunay tetrahedra, the of zitherefore may con- tain many Voronoi vertices, edges, and planar faces. The ec ient quad-edge data structure can be used for software implementation [24]. Volume and area computation. LetVandAdenote the volume and area of the molecule, respectively, Kfor the alpha complex, for a simplex inK,ifor a vertex,ijfor an edge, ijkfor a triangle, and ijklfor a tetrahedron. The algorithm for volume and area computation can be written as Algorithm I I. Algorithm II Volume and area measurement V:=A:= for ifis a tetrahedron ijklthen V:=Vvol(bibjbkbl);A:=Aarea(bibjbkbl); end if end for Additional details of volume and area computation can be fou nd in [14,38]. Software. TheCastP webserver pocket computation can be found at cast. engr.uic.edu . There are other studies that compute or use Voronoi diagram s of protein structures [8,23,25], although not all computes th e weighted version which allows atoms to have dierent radii.APPLICATIONS 15 In this short description of algorithm, we have neglected ma ny details important for geometric computation. For example, the problem of how t o handle geometric degeneracy, namely, when three points are co-linear, or whe n four points are co- planar. Interested readers should consult the excellent mo nograph by Edelsbrunner for a detailed treatise of these and other important topics i n computational geom- etry [13]. 1.4 Applications 1.4.1 Protein packing An important application of the Voronoi diagram and volume c alculation is the measurement of protein packing. Tight packing is an importa nt feature of pro- tein structure [47,49], and is thought to play important rol es in protein stability and folding dynamics [33]. The packing density of a protein i s measured by the ratio of its van der Waals volume and the volume of the space it occupies. One approach is to calculate the packing density of buried resid ues and atoms using Voronoi diagram [47,49]. This approach was also used to deri ve radii parameters of atoms [57]. Number of ResiduesNum of Voids and Pockets 0 200 600 10000 50 100 150 A x 1000V x 1000 0 200 400 600 8000 100 300 500 Figure 1.9 Voids and pockets for a set of 636 proteins representing most of the known protein folds, and the scaling behavior of the geometric pro perties of proteins. (on the left) The number of voids and pockets detected with a 1.4 Angstrom p robe is linearly correlated with the number of residues in a protein. Only proteins with l ess than 1,000 residues are shown. Solid triangles and empty circles represent the pock ets and the voids, respectively. (on the right) The van der Waals ( vdw) volume and van der Waals area of proteins scale linearly with each other. Similarly, molecular surface ( ms) volume also scales linearly with molecular surface area using a probe radius of 1.4 Angstrom. (Data not shown. Figure adapted after [37]) Based on the computation of voids and pockets in proteins, a d etailed study surveying major representatives of all known protein struc tural folds showed that there is a substantial amount of voids and pockets in protein s [37]. On average, every 15 residues introduces a void or a pocket (Fig. 1.9 (lef t side)). For a perfectly16 GEOMETRIC MODELS OF PROTEIN STRUCTURE AND FUNCTION PREDICT ION solid three-dimensional sphere of radius r, the relationship between volume V= 4r3/3and surface area A= 4r2is:VA3/2. In contrast, Fig. 1.9 (right side) shows that the van der Waals volume scales linearly with the v an der Waals surface areas of proteins. The same linear relationship holds irres pective of whether we relate molecular surface volume and molecular surface area , or solvent accessible volume and solvent accessible surface area. This and other s caling behavior point out that protein interior is not packed as tight as solid [37] . Rather, packing defects in the form of voids and pockets are common in proteins. If voids and pockets are prevalent in proteins, an interesti ng question is what is then the origin of the existence of these voids and pockets . This question was studied by examining the scaling behavior of packing densit y and coordination number of residues through the computation of voids, pocket s, and edge simplices in the alpha shapes of random compact chain polymers [63]. Fo r this purpose, a 32-state discrete state model was used to generate a large en semble of compact self- avoiding walks. This is a dicult task, as it is very challeng ing to generate a large number of independent conformations of very compact chains that are self-avoiding. The results in [63] showed that it is easy for compact random c hain polymers to have similar scaling behavior of packing density and coordi nation number with chain length. This suggests that proteins are not optimized by evo lution to eliminate voids and pockets, and the existence of many pockets and voids is ra ndom in nature, and is due to the generic requirement of compact chain polymers. Th e frequent occurrence and the origin of voids and pockets in protein structures rai se a challenging question: How can we distinguish voids and pockets that perform biolog ical functions such as binding from those formed by random chance? This question is related to the general problem of protein function prediction. 1.4.2 Predicting protein functions from structures Conservation of protein structures often reveals very dist ant evolutionary relation- ship, which are otherwise dicult to detect by sequence anal ysis [56]. Comparing protein structures can provide insightful ideas about the b iochemical functions of proteins ( e.g., active sites, catalytic residues, and substrate interact ions) [26,42,44]. A fundamental challenge in inferring protein function from structure is that the functional surface of a protein often involves only a small n umber of key residues. These interacting residues are dispersed in diverse region s of the primary sequences and are dicult to detect if the only information available i s the primary sequence. Discovery of local spatial motifs from structures that are f unctionally relevant has been the focus of many studies. Graph based methods for spatial patterns in proteins. To analyze local spatial patterns in proteins. Artymiuk et al. developed an algorithm based on subgraph plied pseudo-atoms, a molecular graph is constructed to re present the patterns of side-chain pseudo-atoms and their inter-atomic distanc es. A user dened query pattern can then be searched rapidly against the Protein Dat a Bank for similarity relationship. Another widely used approach is the method of geometric hashing. By examining spatial patterns of atoms, Fischer et al. developed an algorithm that can detect surface similarity of proteins [19,43]. This met hod has also been applied by Wallace et al. for the derivation and matching of spatial templates [60]. R ussellAPPLICATIONS 17 developed a dierent algorithm that detects side-chain geo metric patterns common to two protein structures [54]. With the evaluation of stati stical signicance of measured root mean square distance, several new examples of convergent evolution were discovered, where common patterns of side-chains were found to reside on dierent tertiary folds. These methods have a number of limitations. Most require a us er-dened tem- plate motif, restricting their utility for automated datab ase-wide search. In addi- tion, the size of the spatial pattern related to protein func tion is also often restricted. Predicting protein functions by matching pocket surfaces. Protein func- tional surfaces are frequently associated with surface reg ions of prominent concav- ity [30,40]. These include pockets and voids, which can be ac curately computed as we have discussed. Computationally, one wishes to automati cally identify voids and pockets on protein structures where interactions exist wit h other molecules such as substrate, ions, ligands, or other proteins. Binkowski et al. developed a method for predicting protein function by match ing a surface pocket or void on a protein of unknown or undetermin ed function to the pocket or void of a protein of known function [4,6]. Initiall y, the Delaunay tetra- hedrization and alpha shapes for almost all of the structure s in the PDB databank are computed [11]. All surface pockets and interior voids fo r each of the protein structure are then exhaustively computed [17,39]. For each pocket and void, the residues forming the wall are then concatenated to form a sho rt sequence fragment of amino acid residues, while ignoring all intervening resi dues that do not partici- pate in the formation of the wall of the pocket or void. Two seq uence fragments, one from the query protein and another from one of the protein s in the database, both derived from pocket or void surface residues, are then c ompared using dynamic programming. The similarity score for any observed match is assessed for statistical signicance using an empirical randomization model constr ucted for short sequence patterns. For promising matches of pocket/void surfaces showing sign icant sequence sim- ilarity, we can further evaluate their similarity in shape a nd in relative orientation. The former can be obtained by measuring the coordinate root m ean square distance (rmsd) between the two surfaces. The latter is measured by rst pla cing a unit sphere at the geometric center z0R3of a pocket/void. The location of each residuez= (x,y,z)Tis then projected onto the unit sphere along the direction of the vector from the geometric center: u= (zz0)/||zz0||. The projected pocket is represented by a collection of unit vectors located on the unit sphere, and the original orientation of residues in the pocket is preserved . The rmsd distance of the two sets of unit vectors derived from the two pockets are t hen measured, which is called the o rmsd fororientation rmsd [4]. This allows similar pockets with only minor conformational changes to be detected [4]. The advantage of the method of Binkowski et al. is that it does not assume prior knowledge of functional site residues, and does not require a priori any similarity in either the full primary sequence or the backbone fold struct ures. It has no limitation in the size of the spatially derived motif and can successful ly detect patterns small and large. This method has been successfully applied to dete ct similar functional18 GEOMETRIC MODELS OF PROTEIN STRUCTURE AND FUNCTION PREDICT ION surfaces among proteins of the same fold but low sequence ide ntities, and among proteins of dierent fold [4,5]. Function prediction through models of protein surface evol ution. To match local surfaces such as pockets and voids and to assess t heir sequence sim- ilarity, an eective scoring matrix is critically importan t. In the original study of Binkowski et al.,Blosum matrix was used. However, this is problematic, as Blosum matrices were derived from analysis of precomputed large qu antities of sequences, while the information of the particular protein of interest has limited or no influence. In addition, these precomputed sequences in clude buried residues in protein core, whose conservation reflects the need to main tain protein stabil- ity rather than to maintain protein function. In references [58, 59], a continuous time Markov process was developed to explicitly model the su bstitution rates of residues in binding pockets. Using a Bayesian Markov chain M onte Carlo method, the residue substitution rates at functional pocket are est imated. The substitution rates are found to be very dierent for residues in the bindin g site and residues on the remaining surface of proteins. In addition, substituti on rates are also very dif- ferent for residues in the buried core and residues on the sol vent exposed surfaces. These rates are then used to generate a set of scoring matrice s of dierent time in- tervals for residues located in the functional pocket. Appl ication of protein-specic and region-specic scoring matrices in matching protein su rfaces result in signi- cantly improved sensitivity and specicity in protein func tion prediction [58,59]. In a large scale study of predicting protein functions from s tructures, a subset of 100 enzyme families are collected from a total of 286 enzym e families containing between 10-50 member protein structures with known Enzyme C lassication (E.C.) labels. By estimating the substitution rate matrix for resi dues on the active site pocket of a query protein, a series of scoring matrices of di erent evolutionary time is derived. By searching for similar pocket surfaces from a dat abase of 770,466 pockets derived from the CastP database (with the criterion that each must contain at least 8 residues), this method can recover active site surfaces on enzymes similar to that on the query structure at an accuracy of 92% or higher. An example of identifying human amylase using template surfaces from B. subtilis and from barley is shown in Fig. 1.10. The method of surface matching based on evolutionary model i s also especially eective in solving the challenging problems of protein fun ction prediction of orphan structures of unknown function (such as those obtained in st ructural genomics projects), which have only sequence homologs that are thems elves hypothetical proteins with unknown functions. 1.5 Discussion and summary A major challenge in studying protein geometry is to underst and our intuitive no- tions of various geometric aspects of molecular shapes, and to quantify these notions with mathematical models that are amenable to fast computat ion. The advent of the union of ball model of protein structures enabled rigoro us denition of impor- tant geometric concepts such as solvent accessible surface and molecular surface. It also led to the development of algorithms for area and volu me calculations of proteins. Deep understanding of the topological structure of molecular shapes isDISCUSSION AND SUMMARY 19 Figure 1.10 Protein function prediction as illustrated by the example o f alpha amylases. Two template binding surfaces are used to search database of protein surfaces to identify protein structures that are of similar functions. (a) The ph ylogenetic tree for the template Pdbstructure 1bagfromB. subtilis . (b) The template binding pocket of alpha amylase on 1bag. (c) A matched binding surface on a dierent protein structu re (1b2yfrom human, full sequence identity 22%) obtained by querying with 1bag. (d) The phylogenetic tree for the template structure 1bg9fromH. vulgare . (e) The template binding pocket on 1bg9. (f) A matched binding surface on a dierent protein structure ( 1u2yfrom human, full sequence identity 23%) obtained by querying with 1bg9(Adapted from [59]). also based on the idealized union of ball model [12]. A succes s in approaching these problems is exemplied in the development of the pocket algo rithm [17]. Another example is the recent development of a rigorous denition of protein-protein binding or interaction interface and algorithm for its computation [3].20 GEOMETRIC MODELS OF PROTEIN STRUCTURE AND FUNCTION PREDICT ION Perhaps a more fundamental problem we face is to identify imp ortant structural and chemical features that are the determinants of biologic al problems of interest. For example, we would like to know what are the shape features that has signicant influences on protein solvation, protein stability, ligand specic binding, and protein conformational changes. It is not clear whether our current geometric intuitions are sucient, or are the correct or the most relevant ones. There may still be important unknown shape properties of molecules that elude us at the mo ment. An important application of geometric computation of prote in structures is to detect patterns important for protein function. The shape o f local surface regions on a protein structure and their chemical texture are the bas is of its binding interac- tions with other molecules. Proteins fold into specic nati ve structure to form these local regions for carrying out various biochemical functio ns. The geometric shape and chemical pattern of the local surface regions, and how th ey change dynamically are therefore of fundamental importance in computational s tudies of proteins. Another important application is the development of geomet ric potential func- tions. Potential functions are important for generating co nformations, for distin- guishing native and near native conformations from other de coy conformations in protein structure predictions [34, 36, 55, 64] and in protei n-protein docking [35]. They are also important for peptide and protein design [27,3 5]. We have not described in detail the approach of studying prot ein geometry using graph theory. In addition to side-chain pattern analysis br iefly discussed earlier, graph based protein geometric model also has lead to a number of important in- sights, including the optimal design of model proteins form ed by hydrophobic and polar residues [28], and methods for optimal design of side- chain packing [31,62]. Further development of descriptions of geometric shape and topological struc- ture, as well as algorithms for their computation will provi de a solid foundation for studying many important biological problems. The other important tasks are then to show how these descriptors may be eectively used to d eepen our biological insights and to develop accurate predictive models of biolo gical phenomena. For example, in computing protein-protein interfaces, a chall enging task is to discrim- inate surfaces that are involved in protein binding from oth er non-binding surface regions, and to understand in what fashion this depends on th e properties of the binding partner protein. Undoubtedly, evolution plays central roles in shaping up th e function and stabil- ity of protein molecules. The method of analyzing residue su bstitution rates using a continuous time Markov models [58,59], and the method of su rface mapping of conservation entropy and phylogeny [22,41] only scratches the surface of this im- portant issue. Much remains to be done in incorporating evol utionary information in protein shape analysis for understanding biological fun ctions. Remark. The original work of Lee and Richards surface can be found in [ 32], where they also formulated the molecular surface model [50] . Michael Connolly developed the rst method for the computation of the molecul ar surface [9]. Tsai et al. described a method for obtaining atomic radii parameter [57 ]. The math- ematical theory of the union of balls and alpha shape was deve loped by Herbert Edelsbrunner and colleagues [12,15]. Algorithm for ing weighted Delaunay tetrahedrization can be found in [16], or in a concise monogr aph with in-depth dis- cussion of geometric computing [13]. Details of area and vol ume calculations can be found in [14, 38, 39]. The theory of pocket computation and applications can be found in [17,40]. Richards and Lim oered a comprehensive review on proteinDISCUSSION AND SUMMARY 21 packing and protein folding [51]. A detailed packing analys is of proteins can be found in [37]. The study on inferring protein function by mat ching surfaces is de- scribed in [4,59]. The study of the evolutionary model of pro tein binding pocket and its application in protein function prediction can be fo und in [59]. Summary. The accumulation of experimentally solved molecular struc tures of pro- teins provides a wealth of information for studying many imp ortant biological problems. With the development of a rigorous model of the str ucture of protein molecules, various shape properties, including surfaces, voids, and pockets, and measurements of their metric properties can be computed. Ge ometric algorithms have found important applications in protein packing analy sis, in developing po- tential functions, in docking, and in protein function pred iction. It is likely further development of geometric models and algorithms will nd imp ortant applications in answering additional biological questions.REFERENCES 1. P. J. Artymiuk, A. R. Poirrette, H. M. Grindley, D.W. Rice, and P. Willett. A graph- theoretic approach to the identication of three-dimensio nal patterns of amino acid side-chains in protein structure. J. Mol. Biol. , 243:327-344, 1994. 2. R.F.W. Bader. Atoms in Molecules: A Quantum Theory . The international series of mongraphs on chemistry, No. 22. Oxford University Press, 19 94. 3. Y. Ban, H. Edelsbrunner, and J. Rudolph. Interface surfac es for protein-protein complexes. In RECOMB , pages 205-212, 2004. 4. T. Binkowski, L. Adamian, and J. Liang. Inferring funct ional relationship of proteins from local sequence and spatial surface patterns. J. Mol. Biol. , 332:505-526, 2003. 5. pvSOAR: Detecti ng similar surface pat- terns of pocket and void surfaces of amino acid residues on pr oteins. Nucleic Acid Research , 32:W555-W558, 2004. 6. T.A. Binkowski, A. Joachimiak, and J. Liang. Protein surf ace analysis for function an- notation in high-throughput structural genomics pipeline .Protein Sci , 14(12):2972- 81, 2005. 7. A. VDW volumes and J. Phys. Chem. , S. Chakravarty, A. Bhinge, and R. Varadarajan. A procedur e for detection and quantitation of cavity volumes proteins. Application to me asure the strength of the hydrophobic driving force in protein folding. J Biol Chem , 277(35):31345-53, 2002. 9. M. L. Connolly. Analytical molecular surface calcultion .J. Appl. Cryst. , 16:548-558, 1983. 10. G. M. Crippen and T. F. Havel. Distance Geometry and Molecular Conformation . J. Wiley & Sons, 1988. Models and Algorithms for Biomolecules and Molecular Netwo rks, rst edition. By Bhaskar DasGupta and Jie Liang Copyright \u00a9 2015 John Wiley & S ons, Inc.2324 REFERENCES 11. J. Dundas, Z. Ouyang, J. Tseng, A. Binkowski, Y. Turpaz, a nd J. Liang. CASTp: computed atlas surface topography of proteins with struc tural and topographi- cal mapping of functionally annotated residues. Nucleic Acids Res , 34(Web Server issue):W116-8, 2006. 12. H. Edelsbrunner. The union of balls and its dual shape. Discrete Comput. Geom. , 13:415-440, 1995. 13. H. Edelsbrunner. Geometry and Topology for Mesh Generation . Cambridge University Press, 2001. 14. H. Edelsbrunner, M. Facello, P. Fu, and J. Liang. Measuri ng proteins and voids in proteins. In Proc. 28th Ann. Hawaii Int'l Conf. System Sciences , volume 5, pages 256-264, Los Alamitos, California, 1995. IEEE Computer Sco and 16. H. Edelsbrunner and N.R. Shah. flipping works for regular Algorithmica , 15:223-241, 1996. 17. H. Edeslbrunner, M. Facello, and J. Liang. On the deniti on and the construction of pockets in macromolecules. Disc. Appl. Math. , 88:18-29, 1998. 18. J. L. Finney. Volume occupation, environment and access ibility in proteins. The problem of the protein surface. J. Mol. Biol. , 96:721-732, 1975. 19. D. Fischer, R. Norel, H. Wolfson, and R. Nussinov. Surfac e motifs by a computer vision technique: searches, detection, and implications f or protein- ligand recognition. Proteins: Structure, Function and Genetics , 16:278-292, 1993. 20. B. J. Gellatly and J.L. Finney. Calculation of protein vo lumes: an to the Voronoi procedure. J. Mol. Biol. , 161:305-322, 1982. 21. M. Gerstein and F. M Richards. Protein Geometry: Distances, Areas, and Volumes , volume F, chapter 22. International Union of Crystallograp hy, 1999. 22. F. Glaser, T. Pupko, I. Paz, R.E. Bell, D. Shental, E. Mart z, and N. Ben-Tal. Consurf: identication of functional regions in proteins by surface -mapping of phylogenetic information. Bioinformatics , 19(1):163-4, and C Fr\u00f6mmel. Voronoi cell: New met hod for allocation of space among atoms: Elimination of avoidable errors in calcu lation of atomic volume and density. Journal of computational chemistry , 18(9):1113-1123, 1997. 24. L. Guibas and J. Stol. Primitives for the manipulation o f general subdivisions and the computation of Voronoi diagrams. ACM Transactions Harpaz, M Gerstein, and C Chothia. Volume changes on pro tein folding. Structure (London, England : 1993) , 2(7):641-649, 1994. 26. L. Holm and C. Sander. New structure: Novel fold? Structure , 5:165-171, 1997. 27. C. Hu, X. Li, and J. Liang. Developing optimal nonlinear s coring function for protein design. Bioinformatics , 20:3080-3098, 2004. 28. J. Kleinberg. Ecient algorithms for protein sequence d esign and the analysis of certain evolutionary tness landscapes. In RECOMB , pages 205-212, 2004. 29. K. W. Kratky. Intersecting (and spheres) and stati stical matical basis. J. Stat. Phys. 25:619-634, 1981. 30. R. A. Laskowski, N. M. Luscombe, M. B. Swindells, and J. M. Thornton. Protein clefts in molecular recognition and function. Protein Sci. , 5:2438-2452, 1996.REFERENCES 25 31. A. Leaver-Fay, B. Kuhlman, and J. Snoeyink. An adaptive d ynamic programming algorithm for the side chain placement problem. In Pacic Symposium on Biocom- puting , pages 17-28, 2005. 32. B. Lee and F. M. Richards. The interpretation of protein s tructures: estimation of static accessibility. J. Mol. Biol. , 55:379-400, 1971. 33. M. Levitt, M. Gerstein, E. Huang, S. Subbiah, and J. Tsai. Protein folding: the endgame. Annu Rev Biochem , 66:549-579, 1997. 34. X. Li, C. Hu, and J. Liang. Simplicial edge representatio n of protein structures and alpha contact potential with condence measure. Proteins , 53:792-805, 2003. 35. X. Li and J. Liang. Computational design of combinatoria l peptide Biocomput , pages 28-39, 2005. 36. X. Li and J. Liang. Geometric cooperativity and anticoop erativity of three-body interactions in native proteins. Proteins , 60(1):46-65, 2005. 37. J. Liang and K. A. Dill. Are proteins well-packed? Biophys. J. , 81:751-766, 2001. 38. J. Liang, H. Edelsbrunner, P. Fu, P. V. Sudhakar, and S. Su bramaniam. Analytical shape computing of macromolecules I: Molecular area and vol ume through alpha- shape. Proteins , 33:1-17, 1998. 39. J. Liang, H. Edelsbrunner, P. Fu, P. V. Sudhakar, and S. Su bramaniam. Analytical shape computing of macromolecules II: Identication and co mputation of inaccessible cavities inside proteins. Proteins , 33:18-29, 1998. 40. J. Liang, H. Edelsbrunner, and C. Woodward. Anatomy of pr otein pockets and cavities: Measurement of binding site geometry and implica tions for ligand design. Protein Sci , 7:1884-1897, 1998. Lichtarge, H.R. Bourne, and F.E. Cohen. An evolutiona ry trace method denes binding surfaces common to protein families. J Mol Biol , 257(2):342-58, 1996. 42. A. C. R. Martin, C. A. Orengo, E. G. Hutchinson, A. D. Michi e, A. C. Wallace, M. L. Jones, and J. M. Thornton. Protein folds and functions. Structure , 6:875-884, 1998. 43. R. Norel, D. Fischer, H. J. Wolfson, and R. Nussinov. Mole cualr surface recognition by computer vision-based technique. Protein Eng. , 7, 1994. 44. C. A. Orengo, A. E. Todd, and J. M. Thornton. From protein s tructure to function. Curr. Opinion Structural Biology , 9(4):374-382, 1999. 45. M. Petitjean. On the analytical calculation of van der wa als surfaces and volumes: some numerical aspects. J. Comput. Chem. , 15:507-523, 1994. 46. G. Rhodes. Crystallography Made Crystal Clear: A Guide for Users of Mac romolec- ular Models . Academic Press, 1999. 47. F. M. Richards. The interpretation of protein structure s: total volume, group volume distributions and packing density. J. Mol. Biol. , 82:1-14, 1974. 48. F. M. Richards. The interpretation of protein structure s: total volume, group volume distributions and packing density. J. Mol. Biol. , 82:1-14, 1974. 49. F. M. Richards. Areas, volumes, packing, and protein str uctures. Ann. Rev. Biophys. Bioeng. , 6:151-176, 1977. 50. F. M. Richards. Calculation of molecular volumes and are as for structures of known geometries. Methods in Enzymology , 115:440-464, 1985. 51. F. M. Richards and W. A. Lim. An analysis of packing in the p rotein folding problem. Q. Rev. Biophys. , 26:423-498, 1994.26 REFERENCES 52. T. J. Richmond. Solvent accessible surface area and excl uded volume in proteins: analytical equations for overlapping Inferential struct ure determination. Science , 309(5732):303-6, 2005. 54. R. Russell. Detection of protein three-dimensional sid e-chain patterns: New examples of convergent evolution. J. Mol. Biol. , 279:1211-1227, 1998. 55. R. I. I. Vaisman. Delaunay s.J. Comp. Bio. , 3:213-221, 1996. 56. A. E. Todd, C. A. Orengo, and J. M. Thornton. Evolution of f unction in protein superfamilies, from a structural perspective. J. Mol. Biol. , 307:1113-1143, 2001. 57. J. Tsai, R. Taylor, C. Chothia, and M. Gerstein. The packi ng density Biol , 290(1):253-66, 1999. 58. Y.Y. Tseng and J. Liang. Estimating evolutionary rate of local protein binding surfaces: a bayesian monte carlo approach. Proceedings of 2005 IEEE-EMBC Con- ference , 2005. 59. Y.Y. Tseng and J. Liang. Estimation of amino acid residue substitution rates at local spatial regions and application in protein function infere nce: A Bayesian Monte Carlo approach. Mol. Biol. Evol. 23(2):421-436, Feb 2006. 60. A. C. Wallace, N. Borkakoti, and J. M. Thornton. TESS: a ge ometric hashing algo- rithm for deriving st ructural databases. Appli- cation to sites. 1997. 61. J.M. S.C. Richar dson. Asparagine and glu- tamine: using hydrogen atom contacts hain amide orientation. J Mol Biol , 285(4):1735-47, 1999. Xu. Rapid via tree decompo sition. In RECOMB , pages 423-439, 2005. 63. J. Zhang, R. Chen, C. Tang, and J. Liang. Origin of scaling behavior of protein packing density: A sequential monte carlo study of compact l ong chain polymers. J. Chem. Phys. , 118:6102-6109, 2003. 64. W. Zheng, S. J. Cho, I. I. Vaisman, and A. Tropsha. A new app roach to protein fold recognition based on Delaunay tessellation of protein stru cture. In R.B. Altman, A.K. Dunker, L. Hunter, and Klein, editors, Pacic Symposium on Biocomputing'97 , pages 486-497, Singapore, 1997. World Scientic. EXERCISES 1.1 For two points x1,x2Rd, the line through x1andx2can be written as: joining x1andx2is: [x1,x2] ={x|x= (1)x1+x2,01}. Similarly, an ={x|x= (1)x1+x2,0<<1}. A setSRdis convex if the closed line segment joining every two points ofSis inS. Equivalently, Sis convex if for in Show with proof that: a) Both an open halfspace and a closed halfspace are convex. b) IfA1,...,A nis a family of convex sets in Rd, then their intersection/intersectiontextn i=1Aiis a convex set. Specically, the intersection of a set of hal f spaces, e.g., a Voronoi cell, is convex. 1.2 We can follow the dual relationship to compute the Voronoi di agram from the constructed Delaunay triangulation. In three-dimensiona l space, a Delaunay vertex corresponds to an atom ball, a Delaunay edge corresponds to a Voronoi plane, a Delaunay triangle corresponds to a Voronoi edge, and a Dela unay tetrahedron corresponds to a Voronoi vertex. To v= (v1,v2, at zi,zj,zkandzl, with radii ri, rj, rkandrl, respectively, we use the fact that the power distance i(v)||vzi||2r2 i fromvtobi(zi, ri)is the same as j(v),k(v), andl(v). Denote this power distance as R2. a) Write down the set of quadratic equations whose solution w ill provide r= the system of quadratic equations into a system o f linear equa- tions, whose solution will give randR2. c) Write down the set of linear equations that determine the V oronoi line dual to a Delaunay triangle. d) Write down the linear equation that determines the Vorono i plane dual to a Delaunay edge. 1.3 By growing atom balls using a parameter , we can generate a family of unions of balls, in which the size of each atom is inflated from ritori() = (r2 i+ )1/2[12,15]. We now examine the corresponding Voronoi diagrams . a) In the Voronoi diagram, every point xon the separator surface for the two original atoms (zi,ri)and(zj,rj)has equal power distances i(x)28 REFERENCES andj(x)to the two atoms. Write down the equation for the separator surface. Is the separator surface elliptic, parabolic, or p lanar? b) Now we inflate both atoms by such that we have two new balls with dierent radii (zi,ri())and(zj,rj()). Write down the equation for the separator surface. c) What is the relationship between these two separator surf aces? What is the relationship between the two corresponding Voronoi dia grams? 1.4 The Voronoi diagrams can be generalized using dierent dist ance functions. When considering atoms of dierent radii, instead of replac ing the Euclidean dis- tance||xzi||with distance i(x), can use the additive distance: di(x)||xzi||ri. The resulting Voronoi diagram is called the additively-wei ghted Voronoi diagram. a) Write down the equation for the separator surface formed b y the set of points with equal additive distances to the two atoms (zi, ri)and(zj, rj). Is the separator surface elliptic, parabolic, or planar? b) Now we inflate both atoms by such that we have two new balls with dierent radii (zi,ri+)and(zj,rj+). Write down the equation for the separator Is the separator surface elliptic, para bolic, or planar? c) Is there a simple relationship between these two separato r surfaces or be- tween the two corresponding Voronoi diagrams?CHAPTER 2 SCORING FUNCTIONS FOR PREDICTING STRUCTURE AND BINDING OF PROTEINS 2.1 Introduction In the experimental work that led to the recognition of the 19 72 Nobel prize, Chris- tian Annsen showed that a completely unfolded protein ribo nuclease could refold spontaneously to its biologically active conformation. Th is observation indicated that the sequence of amino acids of a protein contains all of t he information needed to specify its three-dimensional structure [5,6]. The auto matic in vitro refolding of denatured proteins was further conrmed in many other pro tein systems [52]. Annsen's experiments led to the thermodynamic hypothesis of protein folding, which postulates that a native protein folds into a three-di mensional structure in equilibrium, in which the state of the whole protein-solven t system corresponds to the global minimum of free energy under physiological condi tions. Based on this thermodynamic hypothesis, computational stu dies of proteins, including structure prediction, folding simulation, and p rotein design, all depend on the use of a potential function for calculating the eective energy of the molecule. In protein structure prediction, a potential function is us ed either to guide the conformational search process, or to select a structure fro m a set of possible sampled candidate structures. Potential function has been develop ed through an inductive approach [117], where the parameters are derived by matchin g the results from quantum-mechanical calculations on small molecules to exp erimentally measured thermodynamic properties of simple molecular systems. The se potential functions are then generalized to the macromolecular level based on th e assumption that the Models and Algorithms for Biomolecules and Molecular Netwo rks, rst edition. By Bhaskar DasGupta and Jie Liang Copyright \u00a9 2015 John Wiley & S ons, Inc.2930 SCORING FUNCTIONS FOR PREDICTING STRUCTURE AND BINDING OF P ROTEINS complex phenomena of macromolecular systems result from th e combination of a large number of interactions as found in the most basic molec ular systems. For example, a version of the potential function in the Charmm force eld takes the term accounts for bond stretching, with kbthe bond force constant andb0the resting bond distance. The second term accounts for the b ond angles, withkthe angel force constant and 0the stationary angle between three atoms. The third term accounts for the dihedral angles, with kthe dihedral force constant, nthe multiplicity of the function, the dihedral angle, and the phase shift. The fourth term accounts for improper out of plane bending, with kthe bending force constant, and 0the out of plane bending angle. The fth term account for Urey-Bradley cross-term angle bending, with kuthe force constant and uu0 the distance in the harmonic potential. The sixth term takes the form of the Lennard-Jones potential and account for the van der Waals in teractions between the(i, j)pair of atoms, which are separated by at least three bonds. Th e last term is to account for the electrostatic energy and takes the form of a Coulombic potential [16]. Such potential functions are often referred to as \"physics- based\", \"semi-empirical\" eective potential function, or a force eld [16,57,72,92, 134]. The physics-based po- tential functions have been extensively studied, and has fo und wide uses in protein folding studies [16,30,69]. Nevertheless, it is dicult to use physics-based potential functions for protein structure prediction, because they a re based on full atomic model and therefore require high computational costs. In ad dition, such potential function may not fully capture all of the important physical interactions. Another type of potential function is developed following a deductive approach by extracting parameters of the potential functions from a d atabase of known pro- tein structures [117]. Because this approach incorporates physical interactions (electrostatic, van der Walls, cation- interactions) only implicitly and the ex- tracted potentials do not necessarily reflect true energies , it is often referred to as \"knowledge-based eective \"empirical p otential function\", or \"scor- ing function\". This approach became attractive partly due t o the rapidly growing database of experimentally determined three-dimensional protein structures. Suc- cesses in protein folding, protein-protein docking, and pr otein design have been achieved using knowledge-based scoring functions [50,53, 102,104,129]. An exam- ple of the empirical potential function used in the Rosetta software for protein structure prediction and design is described in details in [ 102]. In this chapter, we focus our discussion on this type of potential functions. We rst discuss the theoretical frameworks and methods for d eveloping knowledge- based potential functions. We then discuss in some details t he Miyazawa-Jernigan contact statistical potential, distance-dependent stati stical potentials, as well asGENERAL FRAMEWORK OF SCORING FUNCTION AND POTENTIAL FUNCTI ON31 geometric statistical potentials. We also describe a geome tric model for develop- ing both linear and non-linear potential functions by optim ization. Applications of knowledge-based potential functions in protein-decoy d iscrimination, in protein- protein interactions, and in protein design are then descri bed. Several issues of knowledge-based potential functions are further discusse d. 2.2 General framework of scoring function and potential fun ction Dierent approaches have been developed to extract knowled ge-based scoring func- tions or potential functions from protein structures. They can be categorized into two groups. One prominent group of knowledge-based potenti als are those de- rived from statistical analysis of database of protein stru ctures [82, 89, 106, 119]. In this class of potentials, the interacting potential betw een a pair of residues are estimated from its relative frequency in database when comp ared with that of a reference state or a null model [54,71,82,90,106,112,118, 133]. A dierent class of knowledge-based potentials are based on the principle of op timization. In this case, the set of parameters for the potential functions are optimi zed by some criterion, e.g., by maximizing the energy gap between known native conforma tion and a set of alternative (or decoy) conformations [8,28,29,43,50,8 3,86,121,123,130,131]. There are three main ingredients for developing a knowledge -based potential function. We rst need protein descriptors to describe the sequence and the shape of the native protein structure in a format that is suitable f or computation. We then need to decide on a functional form of the potential function. Finally, we need amethod to derive the values of the parameters for the potential function. 2.2.1 Protein representation and descriptors To describe the geometric shape of a protein and its sequence of amino acid residues, a protein can be represented by a d-dimensional descriptor cRd. For example, a widely used method is to count non-bonded contacts of 210 ty pes of amino acid residue pairs in a protein structure. In this case, the count vectorcRd,d= 210 , is used as the protein descriptor. Once the structural confo rmation of a protein s and its amino acid sequence ais given, the protein descriptions f: (s,a)msoRd will fully determine the d-dimensional vector c. In the case of contact descriptor, fcorresponds to the mapping provided by specic contact den ition, e.g., two residues are in contact if their distance is below a cut-o th reshold distance. At the residue level, the coordinates of of C,C, or side-chain center can be used to represent the location of a residue. At the atomic level, the coordinates of atoms are directly used, and contact may be dened by the spatial pr oximity of atoms. In addition, other features of protein structures can be use d as protein descriptors, including distances between residue or atom pairs, solvent accessible surface areas, dihedral angles of backbones and side-chains, and packing d ensities. 2.2.2 Functional form The form of the potential function H:RdmsoRdetermines the mapping of a d- dimensional descriptor cto a real energy value. A widely used functional form for potential function His the weighted linear sum of pairwise contacts [82, 89, 106,32 SCORING FUNCTIONS FOR PREDICTING STRUCTURE BINDING OF P 119,123,130]: H(f(s,a)) =H(c) ciis the number of occurrence of the i-th type of descriptor. Once the weight vector wis specied, the potential function is fully dened. In subsection 2.4.3, we will discuss a nonli near form potential function. 2.2.3 Deriving parameters of potential functions For statistical knowledge-based potential functions, the weight vector wfor linear potential is derived by characterization of the frequency d istributions of structural descriptors from a database of experimentally determined p rotein structures. For optimized knowledge-based linear potential function, wis obtained through opti- mization. We describe the details of these two approaches be low. 2.3 Statistical method 2.3.1 Background In statistical methods, the observed frequencies of protei n structural features are converted into eective free energies, based on the assumpt ion that frequently ob- served structural features correspond to low-energy state s [89,116,120]. This idea was rst proposed by Tanaka and Scheraga in their work to esti mate potentials for pairwise interaction between amino acids [120]. Miyaza wa and Jernigan (1985) signicantly extended this idea and derived a widely-used s tatistical potentials, where solvent terms are explicitly considered and the inter actions between amino acids are modeled by contact potentials. Sippl (1990) and ot hers [82, 106, 146] derived distance-dependent energy functions to incorpora te both short-range and long-range pairwise interactions. The pairwise terms were further augmented by in- corporating dihedral angles [59,97], solvent accessibili ty and hydrogen-bonding [97]. Singh and Tropsha (1996) derived potentials for higher-ord er interactions [114,115]. More recently, Ben-Naim (1997) presented three theoretica l examples to demon- strate the nonadditivity of three-body interactions [10]. Li and Liang (2005) iden- tied three-body interactions in native proteins based on a n accurate geometric model, and quantied systematically the nonadditivities o f three-body interac- tions [77]. 2.3.2 Theoretical model At the equilibrium state, an individual molecule may adopt m any dierent confor- mations or microscopic states with dierent probabilities . It is assumed that the distribution of protein molecules among the microscopic st ates follows the Boltz- mann distribution, which connects the potential function H(c)for a microstate c to itsprobability of occupancy (c). This probability (c)or the Boltzmann factor is: (c) = exp[H(c)/kT]/Z(a), (2.3)STATISTICAL METHOD 33 wherekandTare the Boltzmann constant and the absolute temperature mea sured in Kelvin, respectively. The partition function Z(a)is dened as: Z(a)/summationdisplay cexp[H(c)/kT]. (2.4) It is a constant under the true energy function once the seque nceaof a protein is specied, and is independent of the representation f(s,a)and descriptor cof the protein. If we are able to measure the probability distri bution(c)accurately, we can obtain the knowledge-based potential function H(c)from Boltzmann distribution: H(c) =kTln(c)kTlnZ(a). (2.5) The partition function Z(a)cannot be obtained directly from experimental mea- surements. However, at a xed temperature, Z(a)is a constant and has no eect on the dierent probability of occupancy for dierent confo rmations. In order to obtain an knowledge-based potential function th at encodes the sequence- structure relationship of proteins, we have to remove backg round interactions H(c) that are independent of the protein sequence and the protein structure. These generic energetic contributions are referred collectivel y as that of the reference state[116]. An eective Z(a)], sequence adopting a conformation spe cied by the vector cin the reference state. Since Z(a)andZ(a)are both constants, kTln(Z(a)/Z(a))is also a constant that does not depend on the descriptor vectorc. If we assume that Z(a)Z(a)as in [116], the energy can be H(c) =kTln/bracketleftbigg(c) (c)/bracketrightbigg . (2.7) To calculate (c)/(c), one can further assume that the probability distribution of each descriptor is independent, and we have (c)/(c) =/producttext i/bracketleftig (ci) (ci)/bracketrightig . Further- more, by assuming of the independent, type struc- tural feature in native proteins and the reference state, re spectively. In a linear potential function, the right-hand side of Equation (2.7) c an be calculated as: kTln/bracketleftbigg(c) (c)/bracketrightbigg =kT/summationdisplay iciln/bracketleftbiggi eective potential ener gyH(c)of the system, one often assumes that H(c)can be decomposed into various basic energetic terms. For a linear potential function, H(c)can be calculated as: H(c) =/summationdisplay iH(ci) =/summationdisplay iciwi. (2.9)34 FUNCTIONS FOR PREDICTING STRUCTURE AND BINDING OF P ROTEINS If the distribution of each ciis assumed to be linearly independent to the others in the native protein structures, we have: wi=kTln/bracketleftbiggi i/bracketrightbigg . (2.10) In another word, the probability of each structural feature in native protein struc- tures follows the Boltzmann distribution. This is the Boltzmann assumption made in nearly all statistical potential functions. Finkelstei n (1995) summarized protein structural features which are observed to correlate with th e Boltzmann distribu- tion. These include the distribution of residues between th e surface and interior of globules, the occurrence of various ,, angles, cisandtrans prolines, ion pairs, and empty cavities in protein globules [34]. The probability ican be estimated by counting frequency of the i-th struc- tural feature after combining all structures in the databas e. The probability iis determined once a database of crystal structures is given. T he probability iis calculated as the probability of the i-th structural feature in the reference state. The choice of the reference state has important eects and is critical for developing knowledge-based statistical potential function. 2.3.3 Miyazawa-Jernigan contact potential Because of the importance of the Miyazawa-Jernigan model in developing statistical knowledge-based potential and its wide use, we discuss the M iyazawa-Jernigan con- tact potential in details. This also gives an exposure of di erent technical aspects of developing statistical knowledge-based potential func tions. Residue representation and contact denition. In the Miyazawa-Jernigan model, the l-th residue is represented as single ball located at its side -chain center zl. If thel-th residue is a Gly residue, which lacks a side chain, the pos itions of the Catom is taken as zl. A pair of residues (l,m)are dened to be in contact if the distance between their side-chain centers is less tha n a threshold = 6.5A. Neighboring residues landmalong amino acid sequences ( |lm|= 1) are excluded from statistical counting because they are likely to be in sp atial contact that does not reflect the intrinsic preference for inter-residue inte ractions. Thus, a contact between residues. Hence, the total number count of (i,j)contacts of residue type iwith the residue type of the l-th amino acid residue. The total number count of (i,j)contacts in all proteins are then: n(i,j)=/summationdisplay pn(i,j);p, i,j= 1,2,\u00b7\u00b7\u00b7,20. (2.12) Coordination and solvent of dierent types of pair- wise residue-residue contacts n(i,j)can be counted directly from the structure of proteins following Equation (2.12). We also need to count th e number of residue- solvent contacts. Since solvent molecules are not consiste ntly present in X-ray crystal structures, and therefore cannot be counted exactl y, Miyazawa and Jerni- gan made an assumption based on the model of an eective solve nt molecule, which has the volume of the average volume of the 20 types of residue s. Physically, one ef- fective solvent molecule may represent several real water m olecules or other solvent molecules. The number of indice the types of amino acids; n(i)is the number of residue type i in the set of proteins; qiis the mean coordination number of buried residue i, calculated as the number of contacts formed by a buried resid ue of typeiaveraged over a structure database. Here the assumption is that resid ues make the same number of contacts on average, with either eective solvent molecules (rst term in Equation (2.13), or other residues (second term in Equation (2.13)). For convenience, we calculate the total numbers of residues n(r), of residue- residue contacts n(r,r), of residue-solvent contacts n(r,0), and Jernigan (1985) developed a physical model based on hypothetical chemical reactions. In this mod el, residues of type iandjin solution need to be desolvated before they can form a conta ct. The overall reaction is the formation of (i,j)contacts, depicted in Fig. 2.1. The total free energy change to form one pair of (i,j)contact from fully solvated residues of iandjis (Fig. 2.1 a): e(i,j)= (E(i,j)+E(0,0))(E(i,0)+E(j,0)), (2.14)36 SCORING FUNCTIONS FOR 0i i + + jj + +0 00 + (b) (a)2+ (1) desolvation(2) mixing Figure 2.1 The Miyazawa-Jernigan model of chemical reaction. Amino ac id residues rst go through the desolvation process, and then mix together to form pair contact interactions. The associated free energies of desolvation e(i,i)and mixing e (i,j)can be obtained from the equilibrium constants of these two processes. whereE(i,j)is the absolute contact energy between the i-th andj-th types of residues, and E(i,j)=E(j,i);E(i,0)are the absolute contact energy between the i-th residue and eective solvent, and E(i,0)=E(0,i); likewise for E(j,0);E(0,0)are the absolute contact energies of solvent-solvent contacts (0,0). The overall reaction can be decomposed into two steps (Fig. 2 .1 b). In the rst step, residues of type iand typej, initially fully solvated, are desolvated or \"demixed from to form self-pairs (i,i)and(j,j). The free energy changes e(i,i)ande(j,j)upon this desolvation step can be seen from the desolvation p rocess (horizontal box) in Fig. 2.1 as: e(i,i)=E(i,i)+E(0,0)2E(i,0); e(j,j)=E(j,j)+E(0,0)2E(j,0),(2.15) whereE(i,i),E(j,j)are the absolute contact energies of self pair (i,i)and(j,j), respectively. In the second step, the contacts in (i,i)and(j,j)pairs are broken and residues of type iand residues of type jare mixed together to form two (i,j) pairs. The free energy change upon this mixing step 2e (i,j)is (vertical box in Fig. 2.1): 2e (i,j)= 2E(i,j)(E(i,i)+E(j,j)). (2.16) Denote the free energy changes upon the mixing of residue of t ypeiand solvent as e (i,0), We have: 2e (i,0)=e(i,i)and2e (j,0)=e(j,j), (2.17) which can be obtained from Equation (2.15) and Equation (2.1 6) after substituting \"j\" with \"0\". Following the reaction model of Fig. 2.1 b, the total free e nergy changeSTATISTICAL METHOD 37 to form one pair of energy model. The total energy of the system is due to the contacts energies E(i,j)is dicult to measure and knowledge of this value is unnecessary for studying the dependence of e nergy on protein con- formation, we can simplify Equation (2.19) further. Our goa l is to separate out terms that do not depend on contact interactions and hence do not depend on the conformation of the molecule. Equation (2.13) and Equation (2.14). Here only the s econd terms in Equation (2.20a) and (2.20b) depend on protein conformatio ns. Therefore, one needs only to estimate either e(i,j)ore (i,j). Since the number of residue-residue contacts can be counted directly while the number of residue -solvent contacts is more dicult to obtain, Equation (2.20a) is more convenient for calculating the total contact energy of protein conformations. Both e(i,j)ande (i,j)are termed as eective contact energies and their values were reported in [90]. Estimating eective contact energies: quasi-chemical app roximation. The eective energies e(i,j)in Equation (2.20a) can be estimated in kTunit by assuming that the solvent and solute molecules are in quasi- chemical equilibrium for the reaction depicted in Fig. 2.1 a: e(i,j)=ln[m(i,j)/m(\u00b7,\u00b7)][m(0,0)/m(\u00b7,\u00b7)] [m(i,0)/m(\u00b7,\u00b7)][m(j,0)/m(\u00b7,\u00b7)]=lnm(i,j)m(0,0) m(i,0)m(j,0)(2.21) wherem(i,j), m(i,0), andm(0,0)are the pairs between residue typeiandj, residue type iand solvent, and solvent and solvent, respectively. m(\u00b7,\u00b7) is the total number of contacts in the system and is canceled o ut. Similarly, e (i,j)38 SCORING FUNCTIONS FOR PREDICTING STRUCTURE AND BINDING OF P ROTEINS ande (i,0)can be estimated from the model b: 2e (i,j)=ln[m(i,j)]2 m(i,i)m(j,j)(2.22a) 2e (i,0)=ln[m(i,0)]2 m(i,i)m(0,0)(2.22b) Based dierent techniques have been dev eloped to obtain eective contact energy parameters. Following the hypothe tical reaction in Fig. 2.1 (a),e(i,j)can be directly estimated from Equation (2.21), as was done b y Zhang and Kim [138]. Alternatively, one can follow the hypothetic al two-step reaction in Fig. 2.1 b and estimate each term in Equation (2.18b) for e(i,j)by using Equa- tion (2.22). Because the second approach leads to additiona l insight about the desolvation eects ( e (i,0)) and the mixing eects ( e (i,j)) in contact interactions, we follow this approach in subsequent discussions. The rst ap proach will become self-evident after our discussion. Models of reference state. In reality, the true fractionm(i,j) m(\u00b7,\u00b7)of contacts of (i,j) type among all pairwise contacts (\u00b7,\u00b7)is unknown. One can approximate this by calculating its mean value from sampled structures in the da a biased estimation of e (i,j)ande(i,j). When eective solvent molecules, residues of i-th andj-th types are randomly mixed,e (i,j)will not equal to 0 as should be because of dierences in amino acid composition among proteins in the database. Therefore, a re ference state must be used to remove this bias. In the work of Miyazawa and Jernigan, the eective contact en ergies for mixing two types of residues e (i,j)and for solvating a residue e (i,0)are estimated based on two dierent random mixture reference states [89]. In both c ases, the contacting pairs in a structure are randomly permuted, but the global co nformation is retained. Hence, the total number of residue-residue, residue-solve nt, solvent-solvent contacts remain unchanged. The rst random mixture reference state for desolvation con tains the same set of residues of the protein pand a set of eective solvent molecules. We denote the overall number of (i,i),(i,0),(0,0)contacts in this random mixture state after sum- ming over all proteins as c (i,i),c (i,0), andc (0,0), and assumed that the average coordi nation number of residueiin all proteins is qi. Therefore, a residue of type imakesqini;pnumber of contacts in protein p. Similarly, the number of (i,0)contactsc (i,0)can be kqknk;p n(\u00b7,0);p. (2.24) From the horizontal box in Fig. 2.1, the eective contact ene The second random mixture reference state for mixing contai ns the exact same set of residues as the protein p, but have all residues randomly mixed. We denote the number of (i,j)contacts in this random mixture as c(i,j);p. The overall number of(i,j)contacts in the full protein set n(\u00b7,\u00b7);p/bracketrightbigg \u00b7n(\u00b7,\u00b7);p. in Fig. 2.1, the eective contact energ (2.27) The compositional bias is removed by the denominator in Equa tion (2.27), and e (i,j)now equals to 0. Althoughc (0,0)can be estimated from Equation (2.22b) by assuming that e (i,0)= 0in a reference state, Zhang and DeLisi simplied the Miyazaw a-Jernigan process by further assuming that the numbers of solvent-solvent con tacts in both reference states to be the same as in the native state [143]: c (0,0)=n(0,0). (2.28) Therefore,c (0,0)andn(0,0)are canceled out in Equation (2.25) and not needed for calculating e (i,0). This treatment systematically subtracts a constant scali ng energy from all eective energies e(i,j), and should produce exactly the same relative energy values for protein conformations as Miyazawa-Jernigan's o riginal work, with the dierence of a constant oset value. In fact, Miyazawa and Je rnigan (1996) showed that this constant scaling energy is the eective contact en ergyerrbetween the average residue rof the 20 residue types, and suggested that e(i,j)errbeing used to measure the stability of a protein structure [90]. Hydrophobic nature of Miyazawa-Jernigan contact of terms: the desolvation termse (i,0)ande (j,0)and the mixing term term of residue typei, that is,e (i,0)ore(i,i)/2(Fig. 2.1), is the energy change due to the desolva-40 SCORING FUNCTIONS FOR PREDICTING STRUCTURE AND BINDING OF P ROTEINS Table 2.1 Miyazawa-Jernigan contact energies in kTunits;e(i,j)for upper half and diagonal and e (i,j)for lower half (from [90]) Cys Met Phe Ile Leu Val Trp Tyr Ala Gly Thr Ser Asn 0.13 0.04 0.14 0 .18-0.08 0.14 0.07 0.15-0.05-0.04-1.75 tion of residue i, the formation of the i-iself-pair, and the solvent-solvent pair. The value of this term e(i,i)/2should correlate well with the hydrophobicity of residue typei[74,89], although for charged amino acids this term also inc orporates unfa- vorable electrostatic potentials of self-pairing. The mix ing terme (i,j)is the energy change accompanying the mixing of two dierent types of amin o acids ofiandjto form a contact pair i-jafter breaking self-pairs i-iandj-j. Its value measures the tendency of dierent residues to mix together. For example, the mixing between two residues with opposite charges are more favorable than m ixing between other types of residues, because of the favorable electrostatic i nteractions. Important insights into the nature of residue-residue cont act interactions can also be obtained by a quantitative analysis of the desolvati on terms and the mixing terms. Among dierent types of contacts, the average diere nce of the desolva- tion terms is 9 times larger than that of the mixing terms (see Table 2.1 taken from [90]). Thus, a comparison of the values of (e(i,i)+ejj)/2ande (i,j)shows that the desolvation term plays the dominant role in determi ning the energy dif- ference among dierent conformations. The importance of hy drophobicity the Miyazawa-Jernigan contact energies reveals that hydropho bic eect is the dominant driving force for protein folding. This conclusion justie s the HP model proposed bySTATISTICAL METHOD 41 Chan and Dill (1990) where only hydrophobic interactions ar e included in studies of simple models of protein folding [21]. 2.3.4 Distance dependent potential function In the Miyazawa-Jernigan potential function, interaction s between amino acids are assumed to be short-ranged and a distance cuto is used to de ne the occurrence of a contact. This type of statistical potential is referred to as the \"contact poten- tial\". Another class of statistical potential allows model ing of residue interactions that are distance-dependent. The distance of interactions are usually divided into a number of small intervals or bins, and the potential functi ons are derived by applying Equation (2.10) for individual distance interval s. Formulation of distance-dependent potential functions. In distance-dependent statistical potential functions, Equation (2.10) can be wr itten in several forms. To follow the conventional notations, we use (i,j)to represent the k-th protein descrip- torckfor pairwise interactions between residue type iand specic residue pair (i,j)at distanced,H(i,j;d)is the the contribution from the (i,j)type of residue pairs at distance d,(\u00df,j;d)and(i,j;d)are the observed and expected probabilities of this distance-dependent interaction, respectively, n(i,j;d)the observed number of(i,j;d)interactions, nthe observed total number of all pairwise interactions in a database, n (i,j;d)the expected number of (\u00df,j;d)interactions when the total number of all pairwise interactions in reference state is se t to ben. Since the expected joint probability (i,j;d)for the reference is not easy to estimate, Sippl and expected probability of interaction of residue pairs (i,j)given the distance interval d, respectively; n(d)is the observed total number of all pairwise interactions at th e distanced;n (i,j;d)= (i,j|d)\u00b7n(d)is the expected number of (i,j)interactions at dwhen the total number of all pairwise interactions at this distance din the reference state is set to n(d). There are several variations of potential function of this form, including the \"Knowledge-Based Potential function\" (KBP) by Lu and Skolnick (2001) [82]. In the work of developing tory (1998) alternatively re placed42 SCORING FUNCTIONS FOR PREDICTING STRUCTURE AND BINDING OF and expected probability of interaction at the distance dfor a given pair of residues (i,j), respectively; n(i,j)is the observed total number of interactions for (i,j)pairs regardless of the distance. n (i,j;d)=(d|i,j)\u00b7n(i,j)is the expected number of (i,j)interactions at distance dwhen the total number of (i,j)interactions in the reference state is set to n(d). The knowledge-based potential functions of Equation (2.29 a), 2.29b, and 2.29c can all be written using the unifying formula based on the num ber counts of inter- actions: H(i,j;d) =ln[n(i,j;d) n (i,j;d)]. (2.30) Clearly, the dierent ways of assigning n (i,j;d)make the potential functions dier from each other signicantly, since the method to calculate n(i,j;d)is essentially the same for many potential functions. In other words, the model of reference state used to compute n (i,j;d)is critical for distance-dependent energy functions. Dierent models of reference states. Sippl (1990) rst proposed the \"uniform density\" model of reference state, where the probability de nsity function for a pair of contacting residues (i,j)is uniformly distributed along the distance vector con- necting them: (i,j|d) =(i,j)[116]. Lu and Skolnick made use of this type of reference state to calculate the expected number of (i,j)interactions at distance d as [82]: n (i,j;d)=(i,j|d)\u00b7n(d)=(i,j)\u00b7n(d). The expected probability (i,j)is estimated mation as: iandj, respectively. Samudrala and Moult (1998) made use of another type of refere nce state, where the probability of the distance between a pair of residues (i,j)beingdis independent of the contact types (i,j)[106]: (d|i,j) =(d). The expected number of (i,j)interactions (2.29c) be- (i,j;d)=(d|i,j)\u00b7n(i,j)=(d)\u00b7n(i,j), where(r)is estimated from (r): (d) =(d) =n(d)/n.STATISTICAL METHOD 43 Ideal gas reference state. In the uniform density model of Sippl, the same density of a particular residue pair (i,j)along a line could result from very dierent volume distribution of (i,j)pairs in specic regions of the protein. For example, one spherical shell proximal to the molecular center could b e sparsely populated with residues, and another distant shell could be densely po pulated, but all may have the same density of (i,j)pairs along the same radial vector. Zhou and Zhou (2002) developed a new reference state (called Dfire for \"Distance-scaled, Finite Ideal-gas REference state\") where residues follow uniform distribution everywhere in the protein [146]. Assuming that residues can be modeled a s noninteracting points ( i.e., as ideal gas molecules), the distribution of non-interact ing pairs should follow the uniform distribution not only along any vector li nes, but also in the whole volume of the protein. When the distance between a pair of residues (i,j)is at a threshold distance d= 14.5A, the interaction energy between them can be considered to b e 0. Therefore, residue type iand typejform pairs at the distance dpurely by random chance, and the observed number of (i,j)pairs at the distance dcan be considered the same as the expected number of (i,j)pairs at the distance din the reference state. Denote vdas the volume of a spherical shell of width dat a distance d from the center. The expected number of interactions (i,j)at the distance dafter volume correction is: n (i,j;d)=n(i,j;d)\u00b7vd d=n(i,j,d)\u00b7/parenleftbiggd d/parenrightbiggd d. For a protein molecule, n (i,j;d)will not increase as r2because of its nite size. In addition, it is well-known that the volume of protein molecu le cannot be treated as a solid body, as there are numerous voids and pockets in the in terior. This implies that the number density for a very large molecule will also no t scale asd2[78]. Zhou and Zhou (2002) assumed that n (i,j;d)increase in drather than d2, where the exponent needs to be determined. To estimate the value, each protein pin the database is reshaped into a ball of radius cpRg;p, whereRg;pis the radius of gyration of the protein p, and residues are distributed uniformly in this reshaped ball. Herecptakes the value so that in the reshaped molecule, the number o f total interacting pairs at ddistance is about the same as that observed in the native proteinp, namely:/summationdisplay (i,j)n (i,j;d)=/summationdisplay (i,j)n(i,j;d) for protein p. Once the value of cpis determined and hence the eective radius cpRg;pfor each native protein is known, the number of interacting p airsn(d)at distancedcan be counted directly from the reshaped ball. Zhou and Zhou further dened a reduced distance-dependent function f(d) =n(d)/dand the relative fluctuation off(d): =/bracketleftigg 1 nb/summationdisplay d(f(d)\u00aff)2/(\u00aff)/bracketrightigg1/2 ,44 SCORING FUNCTIONS FOR PREDICTING STRUCTURE AND BINDING OF P ROTEINS where\u00aff=/summationtext df(d)/nb, andnbis the total number of distance shells, all of which has the same thickness. is then estimated by minimizing the relative fluctuation . The rationale is that since idealized residues are points a nd are uniformly dis- tributed in the reshaped ball, should be 0. In their study, was found to be 1.61[146]. 2.3.5 Geometric potential functions The eectiveness of potential function also depends on the r epresentation of protein structures. Another class of knowledge-based statistical potentials is based on the computation of various geometric constructs that reflect th e shape of the protein molecules more accurately. These geometric constructs inc lude the Voronoi dia- gram [84], the Delaunay triangulation [20,67,114,144], an d the alpha shape [75-77] of the protein molecules. Geometric potential functions ha s achieved signicant successes in many elds. For example, the potential functio n developed by Mc- Conkey et al. is based on the Voronoi diagram of the atomic structures of pr oteins, and is among one of the best performing atom-level potential functions in decoy discrimination [84]. Because the alpha shape of the molecul e contains rich topologi- cal, combinatorial, and metric information, and has a stron g theoretical foundation, we discuss the alpha potential functions in more detail belo w as an example of this class of potential function. Geometric model. In Miyazawa-Jernigan and other contact potential function s, pairwise contact interactions are declared if two residues or atoms are within a spe- cic cut-o distance. Contacts by distance cut-o can poten tially include many implausible non-contacting neighbors, which have no signi cant physical interac- tion [14]. Whether or not a pair of residues can make physical contact depends not only on the distance between their center positions (such as Cor C, or geometric centers of side chain), but also on the size and the orientati ons of side-chains [14]. Furthermore, two atoms close to each other may in fact be shie lded from contact by other atoms. By occupying the intervening space, other re sidues can block a pair of residues from direct interacting with each other. In clusion of these ctitious contact interactions would be undesirable. The alpha potential solves this problem by identifying inte racting residue pairs following the edges computed in the alpha shape. When the par ameteris set to be 0, residue contact occurs if residues or atoms from non-bo nded residues share a Voronoi edge, and this edge is at least partially contained in the body of the molecule. Fig. 2.2 illustrates the basic ideas. Distance and packing dependent alpha potential. For two non-bonded residue balls biof radiusriwith its center located at ziandbjof radiusrjat zj, they form an alpha contact (i,j|)if their Voronoi regions intersect and these residue balls also intersect after their radii are inflated t ori() = (r2 i+)1/2and rj() = (r2 j+)1/2, respectively. That is, the alpha (i,j|)exists when: |zizj|<(ri2+)1/2+(rj2+)1/2, i,jKand|ij|>1. We further dene the 1-star for residue ball bias:St1(bi) ={(bi,bj)K, namely, the set of 1-simplices with bias a vertex. The near = 0 = 4 = Figure 2.2 Schematic drawing of the Delaunay complex and the alpha shap e of a two- dimensional molecule. The Voronoi region of a ball is the set of points closest to it when measured in power distance. If two Voronoi regions share a bo undary, i.e., if there is a Voronoi edge (dashed line), we draw a Delaunay edge (solid li ne in grey or black) between these two Voronoi vertices. A Delaunay edge is therefore the dualof a Voronoi edge. All Delaunay edges incident to ball residue biform the 1-starforbi, denoted as St1(bi). When the balls are inflated by increasing the value, more balls overlap, and more Voronoi edges intersect There are six alpha edges: 0,1,0,2,0,3,0,4,0,4,0,5,and 6,7. For a ball bi, the set of residue balls connected to it by alpha edges are ca lled the near neighbors of the ball. The number of this set of residue balls is dened as the degree of near neighbors of the residue ball bi, denoted as i. For example, 0= 5, and7= 1.(c)When =, all the Delaunay edges become alpha edges ( = 16.0is used for drawing). Hence, all long-range interactions not intervened by a third resid ue are included. derived from St1(bi)and are dened as: N(bi){bj|i,jK}, = 4.0. and the degree of near neighbors iof residuebiis dened as the size of this set of residues: i|N(bi)|, = 4.0. The degree of near neighbors iis a parameter related to the local packing density and hence indirectly the solvent accessibility around the r esidue ball bi(Fig. 2.2 b). A large ivalue indicates high local packing density and less solvent acces- sibility, and a small ivalue indicates low local packing density and high solvent accessibility. Similarly, the degree of near neighbors for a pair of residues is dened as: (i,j)|N(bi,bj)|=|N(bi)|+|N(bj)|, = 4.0. Reference state and collection of non-interacting pairs. We denote the shortest path length between residue biand residue bjasL(i,j), which is the fewest number of alpha edges ( = 4)that connects biandbj. The reference state of the46 SCORING FUNCTIONS FOR PREDICTING STRUCTURE AND BINDING OF P ROTEINS bbb bb 78 23 1b64bb5 Figure 2.3 Schematic illustration non-interacting pairs of residu es.(b1,b4)is considered as a non-interacting pair because the shortest l engthL(1,4)is equal to three, i.e., the interaction between b1andb4is blocked by two residues b7andb8. Likewise, (b3,b6)is considered as a non-interacting pair as well. alpha potential is based on the collection of all non-intera cting residue pairs (i,j): {(i,j)|L(i,j)= 3}. Any(i,j)pair in this reference state is intercepted by two residues ( Fig. 2.3). We assume that there is no attractive or repulsive interaction s between them, because of the shielding eect by the two intervening residues. Name ly, residueiand residue jform a pair only by random chance, and any properties associa ted withbi, such as packing density, side-chain orientation, are independe nt of the same properties associated with bj. Statistical model: pairwise potential and desolvation pot ential. Accord- ing to Equation (2.10), the packing and distance-dependent statistical potential of residue pair (k,l)at the packing environment (k,l)and the distance number of residue pair (k,l)at the packing environment (k,l)and the distance specied by , andn()is the total number of residue pairsOPTIMIZATION METHOD 47 at the distance specied by . number of residue pair (k,l)at the packing environment (k,l)in reference state, and nis the total number of non-interacting residue pairs at the reference state. The desolvation potential of residue type kto havenear neighbors H(|k)is (|k)=[n(k,)/n(k)] [n(r,)/n(r)], (2.34) whererrepresent all 20 residue types. For a protein structure, the total internal energy is estima ted by the summa- tion of the desolvation energy and pairwise interaction k,H(|k)\u00b7n(k,) +1 2/summationdisplay There are several drawbacks of knowledge-based potential f unction derived from statistical analysis of database. These include the neglec t of chain connectivity in the reference state, and the problematic implicit assumpti on of Boltzmann distri- bution [11,121,122]. We defer a detailed discussion to Sect ion 2.6.1. An alternative method to develop potential functions for pr oteins is by optimiza- tion. For example, in protein design, we can use the thermody namic hypothesis of Annsen to require that the native amino acid sequence aNmounted on the native structure sNhas the best (lowest) tness score compared to a set of altern ative sequences (sequence decoys) taken from unrelated proteins known to fold into a dierent foldD={sN,aD}when mounted on the same native protein structure sN: H(f(sN,aN))<H(f(sN,aD))for all(sN,aD)D. Equivalently, the native sequence will have the highest pro bability to t into the specied native structure. This is the same principle descr ibed in [26, 73, 109]. Sometimes we can further require that the dierence in score must be greater than a constantb>0[108]: H(f(sN,aN))+b<H(f(sN,aD))for all(sN,aD)D. Similarly, for protein structure prediction and protein fo lding, we require that the native amino acid sequence aNmounted on the native structure sNhas the lowest energy compared to a set of alternative conformations (stru ctural decoys)D=48 SCORING FUNCTIONS FOR PREDICTING STRUCTURE P ROTEINS {sD,aN}: H(f(sN,aN))<H(f(sD,aN))for allsDD. and H(f(sN,aN))+b<H(f(sD,aS))for all(sD,aN)D. when we insist to maintain an energy gap between the native st ructure and decoy conformations. For linear potential function, we have: w\u00b7cN+b<w\u00b7cDfor allcD=f(sD,aN) (2.36) Our goal is to nd a set of parameters through optimization fo r the potential function such that all these inequalities are satised. There are three key steps in developing eective knowledge- based scoring func- tion using optimization: (1) the functional form, (2) the ge neration of a large set of decoys for discrimination, and (3) the optimization t echniques. The initial step of choosing an appropriate functional form is importan t. Knowledge-Based pairwise potential functions are usually all in the form of w eighted linear sum of interacting residue pairs. In this form, the weight coecie nts are the parameters of the potential function to be optimized for discriminatio n. This is the same func- tional form used in statistical potential, where the weight coecients are derived from database statistics. The objectives of optimization a re often maximization of energy gap between native protein and the average of decoy s, or energy gap between native and decoys with lowest score, or the z-score of the native pro- tein [8,28,43,45,62,63,83,86,87,121,123,130,131]. 2.4.1 Geometric nature of discrimination There is a natural geometric view of the inequality requirem ent for weighted linear sum scoring functions. A useful observation is that each of t he inequalities divides the space of Rdinto two halves separated by a hyperplane (Fig. 2.4a). The hy - perplane for Equation (2.36) is dened by the normal vector (cNcD)and its distanceb/||cNcD||from the origin. The weight vector wmust be located in the half-space opposite to the direction of the normal vector (cNcD). This half-space can be written as w\u00b7(cNcD)+b<0. When there are many inequalities to be satised simultaneously, the intersection of the half-spa ces forms a convex polyhe- dron [32]. If the weight vector is located in the polyhedron, all the inequalities are satised. Scoring functions with such weight vector wcan discriminate the native protein sequence from the set of all decoys. This is illustra ted in Fig. 2.4a for a two-dimensional toy example, where each straight line rep resents an inequality w\u00b7(cNcD)+b<0that the scoring function must satisfy. For each native protein i, there is one convex polyhedron Piformed by the set of inequalities associated with its decoys. If a scoring function can discriminate simultaneously nnative proteins from a union of sets of sequence decoys, the w eight vectorwmust be located in a smaller convex polyhedron Pthat is the intersection of thenconvex polyhedra: wP=n/intersectiondisplay i=1Pi.OPTIMIZATION METHOD 49 4 0 2 44 2 0 2 4 w1w2a 1.0 0.0 1.01.0 0.0 1.0 x1x2b 3 1 1 2 33 1 0 1 2 3 w1w2c 5 0 55 0 5 x1x2d Figure 2.4 Geometric views of the inequality requirement for protein s coring function. Here we use a two-dimensional toy example for illustration. a. In the rst geometric view, the space R2ofw= (w1,w2)is divided into two half-spaces by an inequality requiremen t, represented as a hyperplane w\u00b7(cNcD)+b <0. The hyperplane, which is a line in R2, is dened by the normal vector (cNcD), and its distance b/||cNcD||from the origin. Here this distance is set to 1.0. The normal vector is represe nted by a short line segment whose direction points away from the straight line. A feasib le weight vector wis located in the half-space opposite to the direction of the normal vecto r(cNcD). With the given set of inequalities represented by the lines, any weight vector wlocated in the shaped polygon can satisfy all inequality requirement and provides a linea r scoring function that has perfect discrimination. b. A second geometric view of the inequality requirement for l inear protein scoring function. The space R2ofx= (x1,x2), wherex(cNcD), is into two +b <0. Here the hyperplane is dened by the normal vector wand its distance b/||w||from the origin. The origin corresponds to the native protein. All points {cNcD}are located on one side of the hyperplane away from the origin, therefore satisfying the inequality requireme nt. A linear scoring function wsuch as the one represented by the straight line here can have perf ect discrimination. c. In the second toy problem, aset of inequalitiesare represented by aset of straight linesaccordingto the rst geometric view. A subset of the inequalities requir e that the weight vector wto be located in the shaded convex polygon on the left, but another subset of inequalities require thatwto be located in the dashed convex polygon on the top. Since th ese two polygons do not intersect, there is no weight vector wthat can satisfy all inequality requirements. That is, no linear scoring function can classify these decoys fro m native protein. d. According to the second geometric view, no hyperplane can separate all po ints{cNcD}from the origin. But a nonlinear curve formed by a mixture of Gaussian kernels can have perfect separation of all vectors {cNcD}from the origin: It has perfect discrimination.50 SCORING FUNCTIONS FOR PREDICTING STRUCTURE AND BINDING OF P ROTEINS There is yet another geometric view of the same inequality re quirements. If we now regard (cNcD)as a point in Rd, the relationship w\u00b7(cNcD) +b <0 for all sequence decoys and native proteins requires that al l points{cNcD}are located on one side of a dierent hyperplane, which is dened by its normal vector wand its distance b/||w||to the origin (Fig. 2.4b). We can show that such a hyperplane exists if the origin is not contained within the c onvex hull of the set of points{cNcD}[50]. The second geometric view looks very dierent from the rst v iew. However, the second view is dual and mathematically equivalent to the rst geometric view. In the rst view, a point cNcDdetermined by the structure-decoy pair cN= (sN,aN)andcD= (sN,aD)corresponds to a hyperplane representing an inequal- ity, a solution weight vector wcorresponds to a point located in the nal convex polyhedron. In the second view, each structure-decoy pair i s represented as a point cNcDinRd, and the solution weight vector wis represented by a hyperplane separating all the points C={cNcD}from the origin. 2.4.2 Optimal linear potential function Several optimization methods have been applied to nd the we ight vector wof linear scoring function. The Rosenblatt perceptron method works by iteratively updating an initial weight vector w0[86, 130]. Starting with a random vector, e.g.,w0=0, one tests each native protein and its decoy structure. When ever the relationship w\u00b7(cNcD) +b <0is violated, one updates wby adding to it a scaled violating vector \u00b7(cNcD). The nal weight vector is therefore a linear combination of protein and native proteins, and Dis the set of decoys. The set of coecients {N}{D}gives a dual form representation of the weight vector w, which is an expansion of the training examples including both native an d decoy structures. According to the rst geometric view, if the nal convex poly hedronPis non- empty, there can be an innite number of choices of w, all with perfect discrimi- nation. But how do we nd a weight vector wthat is optimal? This depends on the criterion for optimality. For example, one can choose th e weight vector wthat minimizes the variance of reference [123], or minimizing the Z-score of a large set of native proteins, or minimizing the Z-score of the native protein and an ensemble of decoys [22,87 ], or maximizing the ratio Rbetween the width of the distribution of the score and the average score dierence between the native state and the unfolded ones [43,47]. Eective linear sum scoring functions can be obtained by usi ng perceptron learning and other optimization techniques [28,35,43,123,130] There is another optimality criterion according to the seco nd geometric view [50]. We can choose the hyperplane (w,b)that separates the set of points {cNcD}withOPTIMIZATION METHOD 51 the largest distance to the origin. Intuitively, we want to c haracterize proteins with a region dened by the training set points {cNcD}. It is desirable to dene this region such that a new unseen point drawn from the same protei n distribution as {cNcD}will have a high probability to fall within the dened region . Non-protein points following a dierent distribution, which is assumed to be centered around the origin when no a priori information is available, will have a high probability to fall outside the dened region. In this case, we are more in terested in modeling the region or support of the distribution of protein data, ra ther than estimating its density distribution function. For linear scoring functio n, regions are half-spaces dened by hyperplanes, and the optimal hyperplane (w,b)is then the one with maximal distance to the origin. This is related to the novelt y detection problem and single-class support vector machine studied in statistica l learning theory [107,127, 128]. In our case, any non-protein points will need to be dete cted as outliers from the protein distribution characterized by {cNcD}. Among all linear functions derived from the same set of native proteins and decoys, an op timal weight vector wis likely to have the least amount of mis-labellings. The opt imal weight vector w therefore can be found by solving the following quadratic pr ogramming problem: the distance b/||w||of the plane (w,b)to the origin. We obtained the solution by solving the following support vect or machine problem: Minimize1 2brdblwbrdbl2 subject to w\u00b7cN+d1 satises the constra ints in Inequalities (2.39), since subtracting the second inequ ality here from the rst inequality in the constraint conditions of (2.40) will give usw\u00b7(cNcD)+20. 2.4.3 Optimal nonlinear potential function It is possible that the linear weight vector wdoes not exist, i.e., the nal convex polyhedronP=/intersectiontextn i=1Pimay be an empty set. This occurs if a large number of native protein structures are to be simultaneously stabili zed against a large number of decoy conformations, no such potential functions in the l inear functional form can be found [123,131]. According to our geometric pictures, there are two possible scenarios. First, for a specic native protein i, there may be severe restriction from some inequality constraints, which makes Pian empty set. Some decoys are very dicult to dis- criminate due to perhaps deciency in protein representati on. In these cases, it is impossible to adjust the weight vector so the native protein has a lower score than the sequence decoy. Fig. 2.4 c shows a set of inequalities rep resented by straight lines according to the rst geometric view. In this case, the re is no weight vector that can satisfy all these inequality requirements. That is , no linear scoring func- tion can classify all decoys from native protein. According to the second geometric52 SCORING FUNCTIONS FOR PREDICTING STRUCTURE AND BINDING OF P ROTEINS view (Fig. 2.4d), no hyperplane can separate all points (bla ck and green){cNcD} from the origin, which corresponds to the native structures . Second, even if a weight vector wcan be found for each native protein, i.e.,w is contained in a nonempty polyhedron, it is still possible t hat the intersection of n polyhedra is an empty set, i.e., no weight vector can be found that can discriminate all native proteins against the decoys simultaneously. Com putationally, the ques- tion whether a solution weight vector wexists can be answered unambiguously in polynomial time [56]. If a large number ( e.g., hundreds) of native protein structures are to be simultaneously stabilized against a large number o f decoy conformations (e.g., tens of millions), no such potential functions can be found computation- ally [123,131]. Similar conclusion is drawn in a study for pr otein design, where it was found that no linear potential function can simultaneou sly discriminate a large number of native proteins from sequence decoys [50]. A fundamental reason for such failure is that the functional form of linear sum is too simplistic. It has been suggested that additional des criptors of protein struc- tures such as higher order interactions ( e.g., three-body or four-body contacts) should be incorporated in protein description [13, 94, 145] . Functions with poly- nomial terms using up to 6 degree of Chebyshev expansion has a lso been used to represent pairwise interactions in protein folding [33]. We now discuss an alternative approach. Let us still limit ou rselves to pairwise contact interactions, although it can be naturally extende d to include three or four body interactions [77]. We can introduce a nonlinear potent ial function or scoring function analogous to the dual form of the linear function in Equation (2.37), which takes the following form: H(f(s,a)) =H(c) =/summationdisplay DDDK(c,cD)/summationdisplay NNNK(c,cN), (2.41) whereD0andN0are parameters of the scoring function to be determined, andcD=f(sN,aD)from the set of decoys D={(sN,aD)}is the contact vector of a sequence decoy Dmounted on a native protein structure sN, andcN=f(sN,aN) from the set of native training proteins N={(sN,aN)}is the contact vector of a native sequence aNmounted on its native structure sN. In the study of [50], all decoy sequence {aD}were taken from real proteins possessing dierent fold structures. The dierence of this functional form from line ar function in Equa- tion (2.37) is that a kernel function K(x,y)replaces the linear term. A convenient kernel function Kis: K(x,y) =e||xy||2/22for any vectors xandyN/uniontextD, where2is a constant. Intuitively, the surface of the scoring funct ion has smooth Gaussian hills of height Dcentered on the location cDof decoy protein D, and has smooth Gaussian cones of depth Ncentered on the location cNof native structures N. Ideally, the value of the scoring function will be 1for contact vectors cNof native proteins, and will be +1for contact vectors cDof decoys. 2.4.4 Deriving optimal nonlinear scoring function To obtain the nonlinear scoring function, our goal is to nd a set of parameters {D,N}such thatH(f(sN,aN))has value close to 1for native proteins, andAPPLICATIONS 53 the decoys have values close to +1. There are many dierent choices of {D,N}. We use an optimality criterion originally developed in stat istical learning the- ory [19, 107, 126]. First, we note that we have implicitly map ped each structure and decoy from R210through the kernel function of K(x,y) =e||xy||2/22to another space with dimension as high as tens of millions. Sec ond, we then nd the hyperplane of the largest margin distance separating prote ins and decoys in the space transformed by the nonlinear kernel. That is, we searc h for a hyperplane with equal and maximal distance to the closest native protei ns and the closest de- coys in the transformed high dimensional space. Such a hyper plane can be found by obtaining the parameters {D}and{N}from solving the following Lagrange dual form of a constant that limits the influence of each m isclassied protein or decoy [19,107,126-128], and yi=1ifiis a native protein, and yi= +1 ifiis a decoy. These parameters lead to optimal discrimination of an unseen test set [19,107,126-128]. When projected back to the space of R210, this hyperplane becomes a nonlinear surface. For the toy problem of Fig. 2.4, Fig. 2.4d shows that such a hyperplane becomes a nonlinear curve in R2formed by a mixture of Gaussian kernels. It separates perfectly all vectors {cNcD}(black and green) from the origin. That is, a nonlinear scoring function can have perfe ct discrimination. 2.4.5 Optimization techniques The techniques that have been used for optimizing potential function include per- ceptron learning, linear programming, gradient descent, s tatistical analysis, and support vector machine [8,9,50,123,131,135]. These are st andard techniques that can be found in optimization and machine learning literatur e. For example, there are excellent linear programming solvers based on simplex m ethod, as implemented inClp,Glpk , andlp_solve [12], and based on point imple- mented in the Bpmd [85], the Hopdm and the PCxpackages [24]. We neglect the details of these techniques and point readers to the excelle nt treatises of [98,125]. 2.5 Applications Knowledge-Based potential function has been widely used in the study of protein structure prediction, protein folding, and protein-prote in interaction. In this sec- tion, we discuss briefly some of these applications. 2.5.1 Protein structure prediction Protein structure prediction is a complex task that involve s two major components: sampling the conformational space and recognizing the near native structures from the ensemble of sampled conformations.54 SCORING FUNCTIONS FOR PREDICTING STRUCTURE AND BINDING OF P ROTEINS In protein structure prediction, methods for conformation al sampling generates a large number of candidate protein structures. These are of ten called decoys . Among these decoys, only a few are near native structures tha t are very similar to the native structure. Many decoy sets have been developed which are used as objective benchmarks to test if an knowledge-based potenti al function can success- fully identify the native and near native structures. For ex ample, Park and Levitt (1996) constructed a 4-state-reduced decoy set. This decoy test set contains native and near-native conformations of seven sequences, along wi th about 650 misfolded structures for each sequence. In a successful study of struc ture predictions, an knowledge-based potential function then can be used to disc riminate the near na- tive structures from all other decoys [7]. Furthermore, kno wledge-based potential function can be applied not only at the end of the conformatio n sampling to rec- ognize near native structures, but can also be used during co nformation generation to guide the ecient sampling of protein structures [46,54] . 2.5.2 Protein-protein docking prediction Knowledge-based potential function can also be used to stud y protein-protein inter- actions. Here we give an example of predicting the binding su rface of antibody or antibody related proteins ( e.g., Fab fragment, T-cell receptor) [76]. When docking two proteins together, we say a cargo protein is docked to a xed seatprotein. To determine the binding surfaces on the cargo protein, we can e xamine all possible surface patches on the unbound structure of cargo protein as candidate binding interfaces. The alpha knowledge-based potential function is then used to identify native or near native binding surfaces. To evaluate the perf ormance of the potential function, we assume the knowledge of the binding interface o n the seat protein. We further assume that the degree of near neighbors for interfa ce residues is known. We rst partition the surface of the unbound cargo protein in to candidate surface patches, each has the same size as the native binding surface ofmresidues. A candidate surface patch is generated by starting from a surf ace residue on the cargo protein, and following alpha edges on the boundary of the alp ha shape by breadth- rst search, until mresidues are found (Fig. 2.5). We construct ncandidate surface patches by starting in turn from each of the nsurface residue on the cargo protein. Because each surface residue is the center of one of the ncandidate surface patch, the set of candidate surface patches cover exhaustively the whole protein binding interface. Second, we assume that a candidate surface patch on the cargo protein has the same set of contacts as that of the native binding surface. Th e degree of near neighbors for each hypothetical contacting residue pair is also assumed to be the same. We replace the mresidues of the native surface with the mresidues from the candidate surface patch. There arem!/producttext20 i=1mi!dierent ways to permute the m residues of the candidate surface patch, where miis the number of residue type ion the candidate surface patch. A typical candidate surface patch has about 20 residues, therefore the number of possible permutation i s very large. For each candidate surface patch, we take a sample of 5,000 random per mutations. For a candidate surface patch SPi, we assume that the residues can be organized so that they can interact with the binding partner at the lowest ener gy. Therefore, theAPPLICATIONS 55 Native antibody interface Best scored patch (a) (b) Figure 2.5 Recognition of binding surface patch of protein targets usi ng geometric potential function. (a)Boundary of alpha shape for a cargoprotein. Each node represents a surface residue, and each edge represents the alpha edge be tween two surface residues. A candidate surface patch is generated by starting from a surf ace residue on the cargo protein, and following alpha edges on the boundary of the alpha shape b y breadth-rst search, until mresidues are included. (b)Native interface and the surface patch with the best score on the antibody of the protein complex. Only heavy chain (in red ) and light chain (in blue) of the antibody are drawn. The antigen is omitted from this illu stration for clarity. The best scored surface patch (in green) resembles the native interf ace (in yellow): 71% residues from this surface patch are indeed on the native binding interfac e. The residue in white is the starting residue used to generate this surface patch with th e best score. binding energy E(SPi)is estimated as: E(SPi) = min kE(SPi)k, k= residue-level packing and distan ce-dependent potential for the k-th permutation. The value of E(SPi)is used to rank the candi- date surface patches. We can assess the statistical potential by taking antibody/ antigen protein in turn as the seat protein, and the antigen/antibody as cargo p rotein. The native interface on the seat protein is xed. We then test if our stat istical potential can discriminate native surface patch on the cargo protein from the set of candidate surface patches. We can also test if the best scored patch res embles the native patch. An example of the predicted antigen-binding interfa ce of T02 is shown in Fig. 2.5 (b). For ve out of the seven protein complexes, the n ative patches on both the antibody and the antigen are successfully predicte d (Table 2.2). Over 50% of the residues from the best scored patch overlaps with c orresponding native patch. The statistical potential does not work as well for T0 4 and T05, because the antibodies of these two complexes do not use their CDR dom ains to recognize the antigens as an antibody usually does, and such examples a re not present in the dataset of the 34 antibody-antigen complexes, based on whic h the alpha potential function was obtained.56 SCORING FUNCTIONS FOR PREDICTING STRUCTURE AND BINDING OF P ROTEINS Table 2.2 Recognition of native binding surface of CAPRI targets by al pha potential function. . AntibodyaAntigen Target on the antibody molec ule are evaluated by the scoring function, while the native binding surface on the an tigen remains unchanged. \"Antigen\": similarly dened as \"Antibody\". bRanking of the native binding surface among all candidate su rface patches. cFraction of residues from the best candidate surface patch t hat overlap with residues from the native binding surface patch. dThe rst number is the rank of native binding surface and the s econd number is the number of total candidate surface patches. 2.5.3 Protein design Protein design aims to identify sequences compatible with a given protein fold but incompatible to any alternative folds [60,61]. The goal is t o design a novel protein that may not exist in nature but has enhanced or novel biologi cal function. Several novel proteins have been successfully designed [25,48,68, 81]. The problem of protein design is complex, because even a small protein of just 50 res idues can have an astronomical number of sequences ( 1065). This clearly precludes exhaustive search of the sequence space with any computational or experimenta l method. Instead, protein design methods rely on potential functions for bias ing the search towards the feasible regions that encode protein sequences. To sele ct the correct sequences and to guide the search process, a design potential function is critically important. Such a scoring function should be able to characterize the gl obal tness landscape of many proteins simultaneously. Here we briefly describe the application of the optimal nonli near design poten- tial function discussed in Section 2.4.3 [50] in protein des ign. The aim is to solve a simplied protein sequence design problem, namely, to dist inguish each native se- quence for a major portion of representative protein struct ures from a large number of alternative decoy sequences, each a fragment from protei ns of dierent fold. To train the nonlinear potential function, a list of 440 prot eins was compiled from theWhatif98 database a set of 0,766 sequence decoys was obtained. The entries in Whatif99 database that are notAPPLICATIONS 57 present in Whatif98 are used as a test set. After cleaning-up, the test set consis ts of 194 proteins and 3,096,019 sequence decoys. To test the design scoring functions for discriminating nat ive proteins from se- quence decoys, we take the sequence afrom the conformation-sequence pair (sN,a) for a protein with the lowest score as the predicted sequence . If it is not the native sequence aN, the discrimination failed and the design scoring function does not work for this protein. The nonlinear design scoring function is capable of discrim inating all of the 440 native sequences. In contrasts, no linear scoring funct ion can succeed in this task. The nonlinear potential function also works well for t he test set, where it succeeded in correctly identifying 93.3% (181 out of 194) of native sequences in the independent test set of 194 proteins. This compares favo rably with results obtained using optimal linear folding scoring function tak en as reported in [123], which succeeded in identifying 80.9% (157 out of 194) of this test set. It also has better performance than optimal linear scoring function ba sed on calculations using parameters reported in reference [8], which succeeded in id entifying 73.7% (143 out of 194) of proteins in the test set. The Miyazawa-Jernigan st atistical potential succeeded in identifying 113 native proteins out of 194) (su ccess rate 58.2%). 2.5.4 Protein stability and binding anity Because the stability of protein in the native conformation is determined by the distribution of the full ensemble of conformations, namely , the partition function Z(a)of the protein sequence a, care must be taken when using statistical potentials to compare the stabilities of dierent protein sequences ad opting the same given conformation as in protein design [90,116]. This issue is di scussed in some detail in Subsection 2.6.1. Nevertheless, it is expected that statistical potential sh ould work well in estimat- ing protein stability changes upon mutations, as the change in partition functions of the protein sequence is small. In most such studies and those using physics-based empirical potential [15]), good correlation coecient (0. 6-0.8) between predicted and measured stability change can be achieved [15,39,40,44 ,49,146]. Several studies have shown that statistical potentials can also be used to pre- dict quantitative binding free energy of protein-protein o r protein-ligand interac- tions [27,80,88,93,142]. In fact, Xu et al. showed that a simple number count of hydrophilic bridges across the binding interface is strong ly correlated with binding free energies of protein-protein interaction [136]. This s tudy suggests that bind- ing free energy may be predicted successfully by number coun ts of dierent types of some distance thresho ld. Such number count studies provide a useful benchmark to quantify the improvem ent in predicting bind- ing free energy when using statistical potentials for dier ent protein-protein and protein-ligand complexes. Similar to prediction of protei n stability change upon mutation, knowledge based potential function also played a n important role in a successful study of predicting binding free energy changes upon mutation [64,65].58 SCORING FUNCTIONS FOR PREDICTING STRUCTURE AND BINDING OF P ROTEINS 2.6 Discussion and summary 2.6.1 Knowledge-based statistical potential functions The statistical potential functions are often derived base d on several assumptions: (a) protein energetics can be decomposed into pairwise inte ractions; (b) interactions are independent from each other; (c) the partition function in native proteins Zand in reference states Zare approximately equal; (d) the probability of occupancy o f a state follows the Boltzmann distribution. These assumpti ons may be unrealistic, which raises questions about the validity of the statistica l potential functions: Can statistical potential functions provide energy-like quan tities such as the folding free energy of a protein, or the binding free energy of a protein-p rotein complex [122]? Can statistical potential functions correctly recognize t he native structures from alternative conformations? The assumptions of statistical knowledge-based potential functions. From Equation (2.5), we can obtain the potential function H(c)by estimating the prob- ability(c). However, we need a number of assumptions for this approach t o work. We need the independency assumption to have: (c) =/productdisplay i(ci) i-th structural feature, e.g., number of a specic residue pair contact; iis the probability of i-th structural feature in the database. That is, we have to assume that the distribution of a specic structural feature is independent and not influenced by any other featur es, and is of no conse- quence for the distribution of other features as well. We als o need to assume that cprovides an adequate characterization of protein interact ions, and the functional form ofw\u00b7cprovides the correct measurement of the energy of the intera ctions. We further need to assume that the energy for a protein-solvent system is decompos- able,i.e., the overall energy can be partitioned into many basic energ y terms, such as pairwise interactions and desolvation energies. Moreov er, the partition functions Zin a chosen reference state are approximately equal to the pa rtition functions Zin native proteins. These assumptions go along with the assu mption that their structural features contained in the protein database are c orrectly sampled under the Boltzmann distribution. For any protein descriptor, we have: iexp(wi). To calculate iin practice, we have to rely on another assumption that all pr otein structures are crystallized at the same temperature. There fore, the distribution iis reasonably similar for all proteins in the database, and hen ce the frequency counts of protein descriptors in dierent protein structures can b e combined by simple summation with equal weight. Clearly, none of these assumptions are strictly true. Howev er, the success of many applications of using the statistical knowledge-base d potentials indicate that they do capture many important properties of proteins. The q uestion for improv- ing statistical potential function is, how seriously each o f these assumptions is violated and to what extent it aects the validity of the pote ntial function. A fewDISCUSSION AND SUMMARY 59 assumptions specic to a particular potential function (su ch as the coordination and solvation assumptions for the Miyazawa-Jernigan's rea ction model) have been described earlier. Here we discuss several assumptions in d etails below. Interactions are not independent. Using a HP (hydrophobic-Polar) model on two-dimensional lattice, Thomas and Dill (1996) tested the accuracy of Miyazawa- Jernigan contact potentials and Sippl's distance-depende nt potentials. In HP model, a peptide chain contains only two types of monomer: HandP. The true energies are set asH(H,H)=1,H(H,P)= 0andH(P,P)= 0. Monomers are in contact if they are non-bonded nearest neighbors on the lattice. The co nformational space was exhaustively searched for all sequences with the chain l ength from 11 to 18. A sequence is considered to have a native structure if it has a u nique ground energy state. All native structures were collected to build a struc ture database, from which the statistical potentials are extracted by following the M iyazawa-Jernigan or the Sippl method. The extracted energies are denoted as e(H,H),e(H,P), ande(P,P). It was found that neither of these two methods can extract the correct energies. All extracted energies by these two methods depend on chain l ength, while the true energies do not. Using Miyazawa-Jernigan's method, the (H,H)contact is correctly determined as dominant and attractive. However, the estima ted values for e(H,P) ande(P,P)are not equal to zero, whereas the true energies H(H,P)andH(P,P)are equal to zero. Using Sippl's method, the extracted potentia ls erroneously show a distance-dependence, i.e.,(H,H)interactions are favorable in short-distance but unfavorable in long-distance, and conversely for (P,P)interactions, whereas the true energies in the HP model only exist between a rst-neigh bor(H,H)contact, and become zero for all the interactions separated by two or m ore lattice units. These systematic errors result from the assumption that the pairwise interactions are independent, and thus the volume exclusion in proteins c an be neglected [122]. However, (H,H)interactions indirectly aects the observed frequencies o f(H,P) and(P,P)interactions. First, in both contact and distance-depende nt potentials, because only a limited number of inter-residue contacts can be made within the restricted volume at a given distance, the high density of (H,H)pairs at short distances is necessarily coupled with the low density (rela tive to reference state) of(H,P)and(P,P)pairs at the same distances, especially at the distance of on e lattice unit. As a result, the extracted (H,P)and(P,P)energies are erroneously unfavorable at short distance. Second, for distance-depen dent potentials, the energy of a specic type of pair interaction at a given distance is in fluenced by the same type of pair at dierent distances. For example, the high den sity of(H,H)pairs at short distances causes a compensating depletion (relati ve to the uniform density reference state) at certain longer distances, and converse ly for(H,P)and(P,P) interactions. Admittedly this study was carried out using m odels of short chain lengths and a simple alphabet of residues where the foldable sequences may be very homologous, hence the observed artifacts are profound , the deciencies of the statistical potentials revealed in this study such as the ex cluded volume eect is likely to be signicant in potential functions derived from real proteins. Pairwise interactions are not additive. Interactions stabilizing proteins are often modeled by pairwise contacts at atom or residue level. An assumption as- sociated with this approach is the additivity of pairwise in teractions, namely, the60 SCORING FUNCTIONS FOR PREDICTING STRUCTURE AND BINDING OF P ROTEINS total energy or tness score of a protein is the linear sum of a ll of its pairwise interactions. However, the non-additivity eects have been clearly demon strated in cluster formation of hydrophobic methane molecules both in experim ent [10] and in ulation [23, 100, 110, 111]. Protein structure renement wi ll likely require higher order interactions [13]. Some three-body contacts have bee n introduced in several studies [31,41,42,103], where physical models explicitly incorporating three-body interactions are developed. In addition, several studies o f Delaunay four-body in- teractions clearly showed the importance of including high er order interactions in explaining the observed frequency distribution of residue contacts [20,36,67,94,114, 144]. Li and Liang (2005) introduced a geometric model based on the Delaunay tri- angulation and alpha shape to collect three-body interacti ons in native proteins. A nonadditivity coecient compare the (i,j,k)= exp[e(i,j,k)]/exp[(e(i,j)+e(i,k)+e(j,k))]. There are three possibilities: (1) = 1: interaction of a triplet type is additive in nature and can be well approximated by the sum of three pair wise interactions; (2) >1: three-body interactions are cooperative and their associ ation is more favorable than three independent pairwise interactions; 3) <1: the nonadditive eects o f all1,540three-body contacts, it was found that hydrophobic interactions and hy drogen bonding inter- actions make nonadditive contributions to protein stabili ty, but the nonadditive nature depends on whether such interactions are located in p rotein interior or on protein surface. When located in interior, many hydrophobi c interactions such as those involving alkyl residues are anti-cooperative, name ly <1. Salt-bridge and regular hydrogen-bonding interactions such as those invol ving ionizable residues and polar residues are cooperative in interior. When locate d on protein surface, these salt-bridge and regular hydrogen bonding interactio ns are anti-cooperative with <1, and hydrophobic interactions involving alkyl residues be come cooper- ative [77]. Sequence dependency of the partition function Z(a).We can obtain the total eective energy E(s,a)given a structure conformation sand its amino occurrence of the i-th descriptor, e.g., the total number of i-th type of pairwise contact. The summation involving Z(a)and Z(a)is ignored during the evaluation of H(ci)by assuming Z(a)Z(a).DISCUSSION AND SUMMARY 61 It is clear that both Z(a)andZ(a)do not depend on the particular structural conformation s. Therefore, the omission of the term of the partition functi ons kTln/parenleftig Z(a) Z(a)/parenrightig will not aect the rank ordering of energy values of dierent con- formations ( i.e., decoys) for the same protein sequence. On the other hand, it is also clear that both Z(a)andZ(a)depend on the specic sequence aof a protein. Therefore, there is no sound theoretical basis to compare th e stabilities between dierent proteins using the same knowledge-based potentia l function, unless the ratio ofZ(a)/Z(a)for each individual sequence is known and is included during the evaluation [89, 106, 116]. Notably, Dfire and other statistical energy func- tions have been successful used to predict binding anities across dierent protein- protein/peptide complexes. Nevertheless, the theoretica l basis is not certain either, because the values of partition function Z(a)s for dierent protein complexes can be very dierent. It remains to be seen whether a similarly su ccessful prediction of binding anities can be achieved just by using the number o f native interface contacts at some specic distance interval, i.e., the packing density along the native interface. This omission is probably not seriously detrime ntal for the problem of predicting free energy change of a protein monomer or bindin g free energy change of a protein-protein complex upon point mutations, because the distribution of the ensemble of protein conformations may not change signican tly after one or several point mutations. Evaluating potential function. The measure used for performance evaluation of potential functions is important. For example, z-score of native protein among decoys is widely-used as an important performance statisti c. However, z-score strongly depends on the properties of the decoy set. Imagine we have access to the true energy function. If a decoy set has a diverse distributi on in true energy values, thez-score of the native structure will not be very large. Howeve r, this should not suggests that a knowledge-based energy function that gi ves a larger z-score for native protein is better than the true energy function. Alte rnative measures may provide more accurate or useful performance evaluation. Fo r example, the correla- tionrof energy value and crmsd may be helpful in protein structure prediction. Since a researcher has no access to the native structure, (s) he has to rely on the guidance of an energy function to search for better structur es with lower crmsd to the unknown native structure. For this purpose, a potential function with a large rwill be very useful. Perhaps the performance of a potential f unction should be judged not by a single statistic but comprehensively by a num ber of measures. 2.6.2 Relationship of knowledge-based energy functions and further develop- ment The Miyazawa-Jernigan contact potential is the rst widely used knowledge-based potential function. Because it is limited by the simple spat ial description of a cut-o distance, it cannot capture the ner spatial details. Sever al distance-dependent po- tentials have been developed to overcome this limitation, a nd in general have better performance [82,106,146]. A major focus of works in this are a is the development of models for the reference state. For example, the use of the ideal gas as refer- ence state in the potential function Dfire signicantly improves the performance in folding and docking decoy discrimination [139].62 SCORING FUNCTIONS FOR PREDICTING STRUCTURE AND BINDING OF P ROTEINS Because protein surface, interior, and protein-protein in terface are packed dier- ently, the propensity of the same pairwise interaction can b e dierent depending on whether the residues are solvent-exposed or are buried. T he contact potential of Simons et al. considers two types of environment, i.e., buried and non-buried environments separately [113]. The geometric potential fu nction [76] in incorporates both dependencies ce and packing, resulting in signicant improvement in performan ce. Knowledge based potential has also been developed to account for the loss of b ackbone, side-chain, and translational entropies in folding and binding [4,70]. Another emphasis of recent development of potential functi on is the orientational dependency of pairwise interaction [17, 18, 66, 91]. Kortem meet al. developed an orientation-dependent hydrogen bonding potential, whi ch improved prediction of protein and specic protein-protein [66]. Miyazawa and Jernigan developed a anisotropic distance-dependen t potential, with drastic improvements in decoy discrimination over the original Miy azawa-Jernigan contact potential [91]. Computational Eciency. Given current computing power, all potential func- tions discussed above can be applied to large-scale discrim ination of native or near- native structures from decoys. For example, the geometric p otential requires com- plex computation of the Delaunay tetrahedrization and alph a shape of the molecule. Nevertheless, the time complexity is only O(NlogN), whereNis the number of residues for residual-level potentials or atoms for atom-l evel potentials. For com- parison, a naive implementation of contact computing witho ut the use of proper data structure such as a quad-tree or k-d tree isO(N2). In general, atom-level potentials have better accuracy in r ecognizing native struc- tures than residue-level potentials, and is often preferre d for the nal renement of predicted structures, but it is computationally too expe nsive to be applicable in every step of a folding or sampling computation. Potential function for membrane protein. The potential functions we have discussed so far are based on the structures of soluble prote ins. Membrane pro- teins are located in a very dierent physico-chemical envir onment. They also have dierent amino acid composition, and they fold dierently. Potential functions de- veloped for soluble proteins are therefore not applicable t o membrane proteins. For example, Cys-Cys has the strongest pairing propensity beca use of the formation of disulde bond. However, Cys-Cys pairs rarely occur in membr ane proteins. This and other dierence in pairwise contact propensity between membrane and soluble proteins are discussed in [2]. Nevertheless, the physical models underlying most potenti al functions developed for soluble proteins can be modied for membrane proteins [1 -3,51,99]. For exam- ple, Sale et al. used the Mhip potential developed in [2] to predict optimal bundling of TM helices. With the help of 27 additional sparse distance constraints from ex- periments reported in literature, these authors succeeded in predicting the structure of dark-adapted rhodopsin to within 3.2 Angstrom of the crys tal structure [105]. The development of empirical potential function for -barrel membrane proteins based on the reference state using the internal random model or the permutation model enabled successes in high-resolution structure pred ictions of the transmem-DISCUSSION AND SUMMARY 63 brane regions of -barrel membrane proteins, including those of novel archit ecture and those from eukaryotic cells [51,55,79,96]. The empiric al potential function has also been successfully applied to predict the oligomerizat ion states [95], in iden- tication of the protein-protein interaction interfaces [ 95], as well as in discovery of mechanisms of stabilization of -barrel membrane proteins [95]. The stability calculation based on such empirical potential function has also been successfully applied to design the oligomerization state of the OmpF prot ein [37], as well as in identifying the biochemical mechanism of the VDAC proteins [38]. 2.6.3 Optimized potential function Knowledge based potential function derived by optimizatio n has a number of char- acteristics that are distinct from statistical potential. We discuss in detail below. Training set for optimized potential function. Unlike statistical potential functions where each native protein in the database contrib ute to the knowledge- based scoring function, only a subset of native proteins con tribute. In an optimized potential function, in addition, a small fraction of decoys also contribute to the scoring function. In the study of [50], about 50%of native proteins and <0.1%of decoys from the original training data of 440 native protein s and 14 million sequence decoys contribute to the potential function. As illustrated in the second geometric views, the discrimin ation of native proteins occurs at the boundary surface between the vector points and the origin. It does not help if the majority of the training data are vector points aw ay from the boundary surface. This implies the need for optimized potential to ha ve appropriate training data. If no a priori information is known, it is likely many decoys ( >millions) will be needed to accurately dene the discrimination bound ary surface, because of the usually large dimension of the descriptors for proteins . However, this imposes signicant computational burden. Various strategies have been developed to select only the mo st relevant vector points. One may only need to include the most dicult decoys d uring training, such as decoys with lower energy than native structures, decoys w ith lowest absolute energies, and decoys already contributing to the potential function in previous iteration [50,86,124]. In addition, an iterative training process is often necessary [50, 86,124]. Reduced nonlinear potential function. The use of nonlinear terms for poten- tial function involves large datasets, because they are nec essary a priori to dene accurately the discrimination surface. This demands the so lution of a huge opti- mization problem. Moreover, the representation of the boun dary surface using a large basis set requires expensive computing time for the ev aluation of a new unseen contact vector c. To overcome these diculties, non-linear potential funct ion needs to be further simplied. One simple approach is to use alternative optimal criterion , for example, by min- imizing the distance expressed in 1-norm instead of the stan dard 2-norm Euclidean64 SCORING FUNCTIONS FOR PREDICTING STRUCTURE AND BINDING OF P ROTEINS distance. The resulting potential function will automatic ally have reduced terms. Another promising approach is to use rectangle kernels [137 ]. Potential function by optimal regression. Optimized potential functions are often derived based on decoy discrimination, which is a form of binary classication. Here we suggest a conceptual improvement that can signican tly improve the de- velopment of optimized potential functions. If we can measu re the thermodynamic stabilities of all major representative proteins under ide ntical experimental condi- tions ( e.g., temperature, pH, salt concentration, and osmolarity), we can attempt to develop potential functions with the objective of minimi zing the regression errors of tted energy values and measured energy values. The resul ting energy surface will then provide quantitative information about protein s tabilities. However, the success of this strategy will depend on coordinated experim ental eorts in protein thermodynamic measurements. The scale of such eorts may ne ed to be similar to that of genome sequencing projects and structural genomics projects. 2.6.4 Data dependency of knowledge-based potentials There are many directions to improve knowledge-based poten tial functions. Often it is desirable to include additional descriptors in the ene rgy functions to more accurately account for solvation, hydrogen bonding, backb one conformation ( e.g., andangles), and side chain entropies. Furthermore, potential functions with dierent descriptors and details may be needed for dierent tasks ( e.g., backbone prediction vsstructure renement [101]). An important issue in both statistical potential and optimi zed potential is their dependency on the amount of available training data and poss ible bias in such data. For example, whether a knowledge-based potential derived f rom a bias data set is applicable to a dierent class of proteins is the topic of sev eral studies [58, 141]. Zhang et al. further studies the eect of database choice on statistical poten- tial [140]. In addition, when the amount of data is limited, o ver-tting is a serious problem if too many descriptors are introduced in either of t he two types of po- tential functions. For statistical potential, hierarchic al hypothesis testing should help to decide whether additional terms is warranted. For op timized potential, cross-validation will help to uncover possible overtting [50]. Summary. In this chapter, we discussed the general framework of devel oping knowledge- based potential functions in terms of molecular descriptor s, functional form, and pa- rameter calculations. We also discussed the underlying the rmodynamic hypothesis of protein folding. With the assumption that frequently obs erved protein features in a database of structures correspond to low energy state, f requency of observed interactions can be converted to energy terms. We then descr ibed in details the models behind the Miyazawa-Jernigan contact potential, di stance dependent poten- tials, and geometric potentials. We also discussed how to we ight sample structures of varying degree of sequence similarity in the structural d atabase. In the section of optimization method, we describe general geometric mode ls for the problem of obtaining optimized knowledge-based potential functions , as well as methods for developing optimal linear and nonlinear potential functio ns. This is followed by a brief discussion of several applications of the knowledge -based potential func-DISCUSSION AND SUMMARY 65 tions. Finally, we point out general limitations and possib le improvements for the statistical and optimized potential functions. Remark. Annsen's thermodynamic hypothesis can be found in [5, 6]. M ore technical details of the Miyazawa-Jernigan contact potent ial are described in [89,90]. Distance dependent potential function was rst proposed by Sippl in [116], with further development described in [82,106]. The developmen t of geometric potentials can be found in [20,67,75,84,144]. The gas-phase approxima tion of the reference state is discussed in [146]. Thomas and Dill oered insightf ul comments of knowledge-based statistical potential funct ions [122]. The development of optimized linear potential functions can be found in [86, 123,132]. The geometric view for designing optimized potential function and the non linear potential function are based on the results in [50].REFERENCES 1. L. Adamian, R. Jackups, T. A. Binkowski, and J. Liang. High er-order interhelical spatial interactions in membrane proteins. J Mol Biol. , 327:251-272, 2003. 2. L. Adamian and J. Liang. Helix-helix packing and interfac ial pairwise interactions of r esidues in membrane proteins. J. Mol. Biol. , 311:891-907, 2001. 3. L. Adamian and J. Liang. Interhelical hydrogen bonds and s patial in 4. L. M. Amzel. Calculation of entropy changes in biological processes: folding, binding, and oligomerization. Methods Enzymol , 323:167-77, 2000. 5. C. Annsen, E. Haber, M. Sela, and F. White. The kinetics of formation of native ribonuclease during oxidation of polypeptide c hain. Acad. Sci., 47:1309-1314, 1961. 6. C. B. Annsen. Principles that govern the folding of prote in chains. Science , 181:223-230, 1973. 7. Park B. and Levitt M. Energy functions that discriminate x -ray and near-native folds from well-constructed 8. J. Farwer, E. W. Knapp, and M. Vendruscolo. Ho w to guarantee optimal stability for most representative structurs in the protein data bank. Proteins , 44:79- 96, 2001. 9. U. Bastolla, M. Vendruscolo, and E. W. Knapp. A statistica l mechanical method to optimize energy functions for protein folding. Proc Natl Acad Sci USA , 97:3977- 3981, 2000. Ben-Naim. Statistical potentials extracted from prot ein structures: Are these meaningful potentials? J. Chem. Phys. , 107:3698-3706, 1997. Models and Algorithms for Biomolecules and Molecular Netwo rks, rst edition. By Bhaskar DasGupta and Jie Liang Copyright \u00a9 2015 John Wiley & S ons, Inc.6768 REFERENCES 11. A. Ben-Naim. Statistical potentials extracted from pro tein structures: Are these meaningful potentials? J. Chem. Phys. , 107:3698-3706, 1997. 12. M Berkelaar. LP_Solve package. 2004. 13. M. R. Betancourt and D. Thirumalai. Pair potentials for p rotein folding: Choice of reference states and sensitivity of predicted native sta tes to variations in the interaction schemes. Protein Sci. , 8:361-369, 1999. 14. J. R. Bienkowska, R. G. Rogers, and T. F. Smith. Filtered n eighbors threading. Proteins , 37:346-359, 1999. 15. A. J. Bordner and R. A. Abagyan. Large-scale prediction o f protein geometry and stability changes for arbitrary single point mutations. Proteins , 57(2):400-13, 2004. 16. B.R. Brooks, C.L. L Bartels, Boresch, A. Caflisch, L. C aves, Q. Cui, A.R. Dinner, M. Feig, S. Fischer, J. Gao, M. Hodoscek, W. Im, K. Kuc zera, T. Lazaridis, J. Ovchinnikov, E. Pastor, C.B. B. Tidor, R.M. Venable, H.L. Woodcock, X. Wu, W. Yang, D. M. York, and M. Karplus. CHARMM: The biomolecular simulation program. J. Computational Chem. , 30:1545-1614, 2009. 17. N. V. Buchete, J. Straub, and D. Thirumalai. Anisotrop ic coarse-grained sta- tistical potentials improve the ability to identify native like protein structures. The Journal of Chemical Physics , 118:7658-7671, 2003. 18. N. V. Buchete, J. E. Straub, and D. Thirumalai. Orientati onal potentials extracted from protein structures improve native fold recognition. Protein Sci. , 13:862-74, 2004. 19. C. J. C. Burges. A Tutorial on Support Vector Machines for Pattern Recognition. Knowledge Discovery and Data Mining , 2(2), 1998. 20. C. W. Carter Jr., B. C. LeFebvre, S. A. Cammer, A. Tropsha, and M. H. Edgell. Four-body potentials reveal protein-specic correlation s to stability changes caused by hydrophobic core mutations. J. Mol. Biol. , 311(4):625-638, 2001. 21. H. S. Chan and K. A. Dill. Origins of structure in globular proteins. Proc. Natl. Acad. Sci. , 87(16):6388-6392, 1990. 22. T. L. Chiu and R. A. Goldstein. Optimizing energy potenti als for success in protein tertiary structure prediction. Folding Des. , 3:223-228, 1998. 23. C. Czaplewski, S. Rodziewicz-Motowidlo, A. Liwo, D. R. R ipoll, R. J. Wawak, and H. A. Scheraga. Molecular simulation study of cooperati vity in hydrophobic association. Protein Sci , 9:1235-1245, 2000. 24. J. Czyzyk, S. Mehrotra, M. Wagner, and S. Wright. PCx pack age. 2004. 25. B. I. Dahiyat and S. L. Mayo. De Novo protein design: Fully automated sequence selection. Science , 278:82-87, 1997. 26. J. M. Deutsch and T. Kurosky. New algorithm for protein de sign.Phys. Rev. Lett. , 76(2):323-326, 1996. 27. R. S. DeWitte and E. I Shakhnovich. SMoG: de novo design me thod based on simple, fast and accurate free energy estimates. 1. Methodology and supporting evidence. J. Am. Chem. Soc. , 118:11733-44, 1996. 28. J. R. Dima, R. I. Banavar and A. Maritan. Scoring function s in protein folding and design. Protein Sci. , 9:812-819, 2000. 29. H. Dobbs, E. Orlandini, R. Bonaccini, and F. Seno. Optima l potentials for inter-helical packing in transmembrane proteins. Proteins , 49(3):342-349, 2002.REFERENCES 69 30. Y. Duan and P. A. Kollman. Pathways to a protein folding in termediate observed in a 1-microsecond simulation in aqueous solution. Science , 282(5389):740-744, 1998. 31. M. P. Eastwood and P. G. Wolynes. Role of explicitly coope rative interactions in protein folding funnels: A simulation study. J Chem Phys , 114(10):4702-4716, 2001. 32. H. Edelsbrunner. Algorithms in combinatorial geometry . Springer-Verlag, Berlin, 1987. 33. B. Fain, Y. Xia, and M. Levitt. Design of an optimal Chebys hev-expanded discrim- ination function for globular proteins. Protein Sci. , 11:2010-2021, 2002. 34. A. V. Finkelstein, A. Ya. Badretdinov, and A. M. Gutin. Wh y have boltzmann-like statistics? Proteins. , 23(2):142-50, 1995. 35. M. S. Friedrichs and P. G. Wolynes. Toward protein tertia ry structure recognition by means of associative memory hamiltonians. Science , 246:371-373, 1989. 36. H. H. Gan, A. Tropsha, and T. Schlick. Lattice protein fol ding with two and four- body statistical potentials. Proteins , 43(2):161-174, 2001. 37. D. Gessmann, F. Mager, H. Naveed, T. Arnold, S. Weirich, D . Linke, J. Liang, and S. Nussberger. Improving the resistance of a eukaryotic beta-barrel protein to thermal and chemical perturbations. J Mol , 413(1):150-161, Oct 2011. of Biological Chemistry , 287(3):2179-2190, 2012. 39. D. Gilis and M. Rooman. Stability changes upon mutation o f solvent-accessible residues in proteins evaluated by database-derived potent ials. J Mol Biol , 257(5):1112-26, 1996. 40. Gilis and M. Rooman. Predicting protein stability cha nges upon mutation using database-derived potentials: solvent accessibility dete rmines the importance of local interactions along the sequence. J Mol Biol , 272(2):276-90, Skolnick. Topology ngerp rint approach protein folding J Mol Biol , 227(1):227-238, 1992. 42. in globular Natl Sci, 89(24):12098-102, 1992. 43. R. Z. A. Luthey-Schulten, and P. G. Wolynes. P rotein tertiary structure recognition using optimized hamiltonians with local inter actions. Proc. Natl. Acad. Sci. USA , 89:9029-9033, 1992. 44. R. Guerois, J. E. Nielsen, and L. Serrano. Predicting cha nges in the stability of proteins and protein complexes: a study of more than 1000 mut ations. J Mol Biol , 320(2):369-87, 2002. 45. M. H. Hao and H. A. Scheraga. How optimization of potentia l functions aects protein Natl. Acad. Sci. 93(10):4984-89, 1996. 46. M-H. Hao and H. A. Scheraga. Designing potential energy f for protein Struct. 47. Designing potential energy fu nctions for protein fold- ing.Curr Opinion Structural Biology , 9:184-188, 1999. 48. R. B. Hill, D. P. Raleigh, A. Lombardi, and W. F. DeGrado. De novo design of helical bundles as models for understanding protein foldin g and function. Acc Chem Res., 33:745-754, 2000.70 REFERENCES 49. C. Hoppe and D. Schomburg. Prediction protein thermos tability with direction- and distance-dependent knowledge-based potential. Protein Sci , 14:2682-92, 2005. 50. C. Hu, X. Li, and J. Liang. Developing optimal non-linear scoring function for protein design. Bioinformatics , 20(17):3080-98, 2004. 51. R. Jackups Jr and J. Liang. Interstrand pairing patterns in beta-barrel membrane proteins: the positive-outside , 354(4):979-93, Prog. Biophys. Mol. J. Moult, L. T. Eyck, M. J. Sternberg , S. Vajda, I. Vakser, and S. J. Wodak. CAPRI: a Critical Assessment of PRedicted Inter actions. Proteins , 52(1):2-9, 2003. 54. R. L. Jernigan and I. and Jie Liang. Combinatorial analysi s for sequence and spatial motif discovery in short sequence fragments. IEEE/ACM Transactions on Compu- tational Biology and Bioinformatics M. Karplus and G. A. Petsko. Molecular dynamics simulati ons in biology. Nature , pages 631-639, 1990. 58. J. Khatun, S. D. Khare, and N. V. Dokholyan. Can contact po tentials reliably predict stability of proteins? J. Mol. Biol. , 336:1223-1238, 2004. 59. J. A. Rooman, and S. J. Wodak. Factors influen cing the ability of knowledge-based potentials native sequence-s tructure matches. J. Mol. Biol., 235:1598-1613, 1994. 60. P. Koehl and M. Levitt. De Novo protein design. I. In search of stability and specicity. J. Mol. Biol. , 293:1161-1181, 1999. 61. P. Koehl and M. Levitt. De Novo protein design. II. Plasticity of protein sequence. J. Mol. Biol. , 293:1183-1193, 1999. 62. K. K. Koretke, Z. Luthey-Schulten, and P. G. Wolynes. Sel f-consistently optimized statistical mechanical energy functions for sequence stru cture alignment. Protein Sci, 5:1043-1059, 1996. 63. K. K. Koretke, Z. Luthey-Schulten, and P. G. Wolynes. Sel f-consistently optimized energy functions for protein structure prediction molec ular dynamics. Proc. Natl. Acad. Sci. , 95(6):2932-7, 1998. 64. T. Kortemme and D. Baker. A simple physical model for bind ing energy hot spots in protein-protein complexes. Proc Natl Acad Sci , 99:14116-21, 2002. 65. Kortemme, D. E. Kim, and D. Baker. Computational alani ne scanning of protein- protein interfaces. Sci 2004:pl2, 2004. 66. T. Kortemme, A. V. Morozov, and D. Baker. An orientation- dependent hydrogen bonding potential improves prediction of specicity and st ructure for proteins and protein-protein complexes. J Mol Biol , 326:1239-59, 2003. 67. B. Krishnamoorthy and A. Tropsha. Development of a four- body statistical pseudo- potential to discriminate native from non-native protein c C. Ireton, G. Varani, B. L. Stodd ard, and D. Baker. Design of a novel globular protein fold with atomic-level ac curacy. Science , pages 1364-8, 2003. 69. T. Lazaridis and M. Karplus. Eective energy functions f or pre- diction. Curr Opin Struct Biol , 10:139-145, 2000. 70. K. H. Lee, D. Xie, E. Freire, and L. M. Amzel. Estimation of changes in side chain congurational entropy in binding and folding: general met hods and application to helix formation. Proteins , 20:68-84, 1994. 71. C. M. R. Lemer, M. J. Rooman, and S. J. Wodak. Protein-stru cture prediction by threading methods - evaluation of current techniques. Proteins , 23:337-355, 1995. 72. M. Levitt and A. Warshel. Computer simulation of protein folding. Nature. , 253:694- 8, 1975. 73. H. Li, R. Helling, C. Tang, and N. Wingreen. Emergence of p referred structures in a simple model of protein folding. Science , 273:666-669, 1996. 74. H. Li, C. Tang, and N. S. Wingreen. Nature of driving force for protein folding: A result from analyzing the statistical potential. Phs. Rev. Lett. , 79:765-768, 1997. 75. X. Li, C. Hu, and J. Liang. Simplicial edge representatio n of protein structures and alpha contact potential with condence measure. Proteins , 53:792-805, 2003. 76. X. Li and J. Liang. Computational design of combinatoria l peptide library for modulating protein-protein interactions. Pacic Symposium of Biocomputing , pages 28-39, 2005. 77. X. Li and J. Liang. Geometric cooperativity and anti-coo perativity of three-body interactions in native proteins. Proteins , 60:46-65, 2005. 78. J. Liang and K. A. Dill. Are proteins well-packed? Biophys. J. , 81:751-766, 2001. 79. J. Liang, H. Naveed, D. Jimenez-Morales, L. Adamian, and M. Lin. Computational studies of membrane proteins: Models and predictions for bi understanding. Biochimica et Biophysica Acta - Biomembranes , 1818(4):927-941, 2012. 80. S. Liu, C. Zhang, H. Zhou, and Y. Zhou. A physical referenc e state unies the structure-derived potential of mean force for protein fold ing and binding. Proteins , 56:93-101, 2004. 81. L. L. Looger, M. A. Dwyer, J. J. Smith, and H. W. Hellinga. C omputational design of receptor and sensor proteins with novel functions. Nature , 423:185-190, 2003. 82. H. Lu and J. Skolnick. A distance-dependent atomic knowl edge-based potential for improved protein structure selection. Proteins , 44:223-232, 2001. 83. V. N. Maiorov and G. M. Crippen. Contact potential that pe cognizes the correct folding of globular proteins. J. Mol. , 227:876-888, 1992. 84. B. J. McConkey, V. Sobolev, and M. Edelman. Discriminati on of native pro- tein structures using atom-atom contact scoring. Proc. Natl. Acad. Sci. M\u00e9sz\u00e1ros. Fast Cholesky factorization for interio r point methods of linear programming. Comp. Math. Appl. , 31:49 - 51, 1996. 86. C. Micheletti, F. J. R. Banavar, and A. Maritan. Lea iterative s.Proteins , 42(3):422-431, 2001. 87. L. A. Mirny and E. I. Shakhnovich. How to derive a protein f olding potential? a new approach to an old problem. J. Mol. Biol. , 264:1164-1179, 1996.72 REFERENCES 88. B. O. Mitchell, R. A. Laskowski, A. Alex, and J. M. Thornto n. BLEEP: potential of mean force describing protein-ligand interactions: II. Ca lculation of binding energies and comparison with experimental data. J. Comp. Chem. , 20:1177-85, 1999. 89. S. Miyazawa and R. L. Jernigan. Estimation of eective in terresidue L. Jernigan. Residue-residue potenti als with a favorable contact pair term and an unfavorable high packing density term. J. Mol. Biol. , 256:623-644, 1996. 91. S. Miyazawa eective for fold reco gnition is a poten- tial of mean force that includes relative orientations betw een contacting residues in proteins? The Journal of Chemical Physics , 122:024901, 2005. 92. F. A. Momany, R. F. McGuire, A. W. Burgess, and H. A. Schera ga. Energy parame- ters in polypeptides. VII. Geometric parameters, partial a tomic charges, nonbonded interactions, hydrogen bond interactions, and intrinsic t orsional potentials for the naturally occurring amino acids. J. Phys. Chem. , 79(22):2361-2381, 1975. 93. I. Muegge and Y. C. Martin. A general and fast scoring func tion for protein-ligand interactions: a simplied potential approach. J Med Chem , 42:791-804, 1999. 94. P. J. Munson and R. K. Singh. Statistical signicane of hi erarchical multi-body potential based on delaunay tessellation in sequence-structure alignment. , 6:1467-1481, 1997. 95. H Naveed, R Jackups, Jr, and J Liang. Predicting weakly st able regions, oligomer- ization state, and protein-protein interfaces in transmem brane domains of outer membrane proteins. Proceedings of the National Academy of Sciences of the Unite d States of America , 106(31):12735-12740, 2009. 96. Hammad Naveed, Yun Xu, Ronald Jackups, and Jie Liang. Pre dicting three- dimensional structures of transmembrane domains of \u00ce-bar rel membrane proteins. Journal of the American Chemical Society , 134(3):1775-1781, January 2012. 97. K. Nishikawa and Y. Matsuo. Development of pseudoenergy potentials for assessing protein 3-D-1-D compatibility and detecting weak homologi es.Protein Eng. , 6:811- 820, 1993. 98. C. H. and K. Steiglitz. Combinatorial optimization: algorithms and complexity . Dover, 1998. 99. Y. Park, M. Elsner, R. Staritzbichler, and V. Helms. Nove l scoring function transmembrane alpha-heli ces.Proteins , 57(3):577-85, 2004. 100. J. A. Rank and D. Baker. A desolvation barrier to hydroph obic cluster formation may contribute to the rate-limiting step in protein folding .Protein Sci , 6(2):347-354, 1997. 101. C. A. Rohl, C. E. Strauss, K. M. Misura, and D. Baker. Prot ein structure prediction using rosetta. Methods Enzymol , 383:66-93, 2004. 102. Carol A. Rohl, Charlie E. M. Strauss, Kira M. S. Misura, a nd David Baker. Protein Structure Prediction Using Rosetta , volume 383 of Methods in Enzymology , pages 66-93. Elsevier, Department of Biochemistry and Howard Hug hes Medical Institute, University of Washington, Seattle, Washington 98195, USA. , 2004. 103. A. Rossi, C. Micheletti, F. Seno, and A. Maritan. A self- consistent to protein design. Biophys J , 80(1):480-490, 2001.REFERENCES 73 104. W. P. Russ and R. Ranganathan. Knowledge-based potenti al and M. M. Young. bundling of transmembrane helices using sparse distance co nstraints. Protein Sci , 13(10):2613-27, 2004. 106. R. Samudrala and J. Moult. An all-atom distance-depend ent conditional probability discriminatory function for protein structure prediction .J. Mol. Biol. , 275:895-916, 1998. 107. B. Sch\u00f6lkopf and A. J. Smola. Learning with kernels: Support vector machines, regularization, optimization, and beyond . The MIT Press, Cambridge, MA, 2002. 108. E. I. Shakhnovich. Proteins with selected sequences fo ld mation. , 1994. 109. E. I. Shakhnovich and A. M. Gutin. Engineering of stable and fast-folding sequences of model proteins. Proc. Natl. Acad. Sci. USA. , 90:7195-7199, 1993. 110. H. S. Chan. Anti-cooperativity in hydrop hobic interactions: A simulation study of spatial dependence of three-body eect s and beyond. J Chem Phys, 115(3):1414-1421, 2001. 111. S. Shimizu and H. S. and coope rativity in hydrophobic in- teractions: Three-body free energy landscapes and compari son with implicit-solvent potential functions for proteins. Proteins , 48:15-30, 2002. 112. K. T. Simons, I. Ruczinski, C. Kooperberg, B. Fox, C. Bys tro, and D. Baker. Im- proved recognition of native-like protein structures usin g a combination of sequence- dependent and sequence-independent features of proteins. Proteins , 34:82-95, 1999. 113. K. T. Simons, I. Ruczinski, C. Kooperberg, B. Fox, C. Bys tro, and D. Baker. Im- proved recognition of native-like protein structures usin g a combination of sequence- dependent and sequence-independent features of proteins. Proteins , 34:82-95, 1999. 114. R. K. Singh, A. Tropsha, and I. I. Vaisman. Delaunay tess ellation dues. J Comput Biol , 3(2):213-221, 1996. 115. R. I. I. Vaisman. Delaunay s.J. Comp. Bio. , 3:213- 221, 1996. 116. M. J. Sippl. calculation of conformational ensembles f rom potentials of the main force. J. Mol. Biol. , 213:167-180, 1990. 117. M. J. Sippl. Boltzmann's principle, knowledge-based m ean elds and protein folding. an approach to the computational determination of protein s tructures. J Comput Aided Mol Des. , 7(4):473-501, 1993. Opin. Struct. Biol. 1995. 119. S. H. A. Scheraga. Medium- and long-range int eraction parameters between amino acids for predicting three-dimensional stru ctures of proteins. Macro- molecules , 9:945-950, 1976. 120. S. Tanaka and H. A. Scheraga. Medium- and long-range int eraction parameters between amino acids for predicting three-dimensional stru ctures of proteins. Macro- molecules , 9:945-950, 1976. 121. P. D. Thomas and K. A. Dill. An iterative method for extra cting PNAS , 93(21):11628-33, 1996.74 REFERENCES 122. P. D. Thomas and K. A. Dill. Statistical potentials extr acted from protein structures: How accurate are they? J. Biol. Linial, and R. Elber. On the desig n and analysis of protein folding potentials. Proteins , 40:71-85, 2000. 124. D. Tobi, G. Shafran, N. Linial, and R. Elber. On the desig n and analysis of protein folding potentials. Proteins , 40:71-85, 2000. 125. R. J. Vanderbei. Linear Programming: Foundations and Extensions . Kluwer Aca- demic Publishers, 1996. 126. V. Vapnik. The Nature of Statistical Learning Theory . Springer, N.Y., 1995. 127. V. Vapnik and A. Chervonenkis. A note on one class of perc eptrons. Automation and Remote Control , 25, 1964. 128. V. Vapnik and A. Chervonenkis. Theory of Pattern Recognition [in Russian] . Nauka, Fidelis, and J. Moult. Compar performance in successive CASP experiments. Proteins 45:163-170, 2003. 130. M. Vendruscolo and E. Domanyi. Pairwise contact potent ials are unsuitable for protein folding. J. Chem. Phys. , 109:11101-8, 1998. 131. M. Vendruscolo, R. Najmanovich, Domany. Can a pai rwise contact poten- tial stabilize native protein folds against decoys obtaine d by threading? Proteins , 38:134-148, 2000. 132. M. Vendruscolo, R. Najmanovich, E. Domany. Can a pai rwise contact poten- tial stabilize native protein folds against decoys obtaine d by threading? Proteins: Structure, Function, and Genetics , 38:134-148, 2000. 133. S. J. Wodak and M. J. Rooman. Generating and Curr. N. Onuchic, and D. Thirumalai. Navigat ing the folding routes. Science , 267:1619-20, 1995. 135. Y. Xia and M. Levitt. Extracting knowledge-based energ y functions from protein structures by error rate minimization: Comparison of metho ds using lattice model. J Chem. Phys. , 113:9318-9330, 2000. 136. D. Xu, S. L. Lin, and R. Nussinov. Protein binding versus protein folding: the role of hydrophilic bridges in protein associations. J Mol Biol , 2651:68-84, 1997. 137. Y. Xu, C. Hu, Y. Dai, and J. Liang. On simplied global non linear function for tness landscape: A case study of inverse protein folding. Plos One , submitted. 138. C. Zhang and S. H. Kim. Environment-dependent residue c ontact energies for pro- teins. PNAS , 97(6):2550-2555, 2000. 139. C. Zhang, S. Liu, H. Zhou, and Y. Zhou. An accurate, resid ue-level, pair potential of mean force for folding and binding based on the distance-sca led, ideal-gas reference state. Protein Sci , 13:400-411, 2004. 140. C. Zhang, S. Liu, H. Zhou, and Y. Zhou. The dependence of a ll-atom statistical potentials on structural training database. Biophys J , 86(6):3349-58, 2004. 141. C. Zhang, S. Liu, and Y. Zhou. The dependence of all-atom statistical potentials on training structural database. Biophys. J. , 86:3349-3358, 2004. 142. C. Zhang, S. Liu, Q. Zhu, and Y. Zhou. A knowledge-based e nergy function for 2005.EXERCISES 75 143. C. Zhang, G. Vasmatzis1, J. L. Cornette, and C. DeLisi. D etermination of atomic desolvation energies from the structures of crystallized p roteins. J. Mol. Biol. , 267, 1997. 144. W. Zheng, S. J. Cho, I. I. Vaisman, and A. Tropsha. A new ap proach to protein fold recognition based on delaunay tessellation of protein structure. Pac Symp Biocomput , pages 486-497, 1997. 145. W. Zheng, S. J. Cho, I. I. Vaisman, and A. Tropsha. A new ap proach to pro- tein fold recognition based on Delaunay tessellation of pro tein structure. In R.B. Altman, A.K. Dunker, L. Hunter, and T.E. Klein, editors, Pacic Symposium on Biocomputing'97 , pages 486-497, Singapore, 1997. World Scientic. 146. H. Y. Zhou and Y. Q. Zhou. Distance-scaled, nite ideal- gas reference state improves structure-derived potentials of mean force for structure s election and stability pre- diction. Protein Sci. , 11:2714-26, 2002. EXERCISES 2.1 To capture higher order interactions in proteins, one can co nstruct the three- body propensity function. The propensity P(i,j,k)for residues of type i,j,kto interact can be modeled as the odds ratio of the observed prob abilityq(i,j,k)of a three-body (triple) atomic contacts involving residue i,j, andk, and the expected probability p(i,j,k)P(i,j,k)q(i,j,k) p(i,j,k). To compute probability q(i,j,k) =a(i,j,k)//summationtext i,j,ka(i,j,k), wherea(i,j,k)is the residue types i,jandk, and/summationtext i,j,ka(i,j,k) is the total number of all atomic three-body contacts. For th e random probability p(i,j,k), let us assume it is the probability that three atoms are pick ed from a residue of type i, a residue of type j, and a residue of type k, when chosen ran- domly and independently from the pooled database of protein structures. Denote the number of interacting residues of type iasNi, the number of atoms residue of typeihas asni, and the total number of interacting atoms as n. a) Assume all three interacting residues are of dierent typ es,e.g.,i\\e}io\\slsh=j\\e}io\\slsh=k, what is the probability that we rst pick up an atom from a resi due of typei, then an atom from a residue of type j, and with the third atom picked up to be from a residue of type k? b) Now consider all other possible sequences of picking up an atom each from ani,j, andkresidue type. Write down the formula for p(i,j,k). c) When two of the three interacting residues are of the same t ype,i.e., i=j\\e}io\\slsh=k, what is the formula for p(i,j,k)? d) When all three residues are of the same type, i.e.,i=j=k, what is the formula for p(i,j,k)?. 2.2-barrrel membrane proteins are found in a large number of pat hogeneic gram-negative bacteria. Their transmembrane (TM) segment s are-strands. We can obtain the empirical propensity P(X,Y)for interacting pairs of residue types XandYon neighboring -strands as P(X,Y) =fobs(X,Y)/E[f(X,Y)], where fobs(X,Y)is the observed count of X-Ycontacts in the strand pair, and E[f(X,Y)] is the expected count of X-Ycontacts in a null model.76 REFERENCES As the TM strands are short, there are strong coupling betwee n presence and absence of residues residing on the same strand. Commonly us ed techniques such as the2-distribution, in which normality is assumed, or the Bernou lli model, in which residues are drawn with replacement, are not valid. One can u se the permutation model or the internally random model , in which residues within each of the two interacting strands are permuted exhaustively and indepen dently, and hence are drawn without replacement. Each permutation is assumed to o ccur with equal probability. In this model, an X-Ycontact forms if in a permuted strand pair two interacting residues happen to be of type Xand typeY.E[f(X,Y)]is then the expected number of X-Ycontacts in the strand pairs. a) We rst examine the simpler cases when Xis the same as Y,i.e.,X-X pairs. Letx1be the number of residues of type Xin the rst strand, x2 the number of residues of type Xin the second strand, and lthe common length of the strand pair. We randomly select residues from o ne strand to pair up with residues from the other strand. We wish to know the probability of exactly i=f(X, X)number ofXXcontacts. How many ways are there to place the x2residues of type Xin the second strand? b) How many ways are there to have each of the iresidues to be paired with one of thex1residues of type Xon the rst strand? c) How many ways are there to have each of the x2iresidues be paired with one of the lx1non-Xresidues? d) What is the probability PXX(i)ofi=f(X,X)number ofX-Xcontacts in a strand pair? What type of distribution is this? e) What is the expected number of (X,X)contacts? f) If the two contacting residues are not of the same type, i.e.,X\\e}io\\slsh=Y, what is the probability PXY(i)ofi=f(X,Y)number of X-Ycontacts in a strand pair? (Hint: Consider f(X,Y|Xs1,Ys2)for the case the typeXresidues the rst strand s1and typeYin the second strands2, andf(X,Y|Xs2,Ys1)for the other the type Yresidues are in s1and typeXins2. ) g) What is the probability PXY(m)that there are a total of i+j=m X-Y contacts? Note the complication that the variables f(X,Y|Xs1,Ys2) andf(X,Y|Xs2,Ys1)are dependent, i.e., the placement of an X-Y pair may aect the probability of a Y-Xpair in the same strand pair. 2.3 For a potential function in the form of weighted linear sum of interactions, show proof that a decoy always has energy values higher than t he native structure by at least an amount of b>0,i.e., w\u00b7(cDcN)>b for all{(cDcN)|DDandNN} (2.43) if and only if the origin 0is not contained within the convex hull of the set of points {(cDcN)|DDandNN}, namely, the smallest convex body that contain all {(cDcN)}. Note that by the denition of convexity, any point xinside or on the convex hullAcan be expressed as a convex combination of points on the conv ex hull, namely x=/summationdisplay (cDcN)AcDcN\u00b7(cDcN),and/summationdisplay cDcN= 1, cDcN>0.CHAPTER 3 SAMPLING TECHNIQUES: ESTIMATING EVOLUTIONARY RATES AND GENERATING MOLECULAR STRUCTURES 3.1 Introduction Many problem encountered in computational studies of biolo gical system can be formulated as characterization of its ensemble properties , such as those of a pop- ulation of molecules or cells. For example, we may need to eva luate the expected energy value of protein molecules in a population of conform ations; or we may be interested in estimating the concentration of a key regulat or that controls whether a cell switches to a dierent lifestyle. What lies at the hear t of solving these prob- lems is to arrive at an accurate estimation of the ensemble pr operties of the system. This often requires the application of Monte Carlo sampling techniques. Denote the state of the biological system as x, and assume it follows some distri- bution(x). If the property associated with the system at state xcan be expressed using a scalar function f(x), our task is than to estimate: E[f(x)] =/integraldisplay xRf(x)(x)dx, (3.1) whereRis the region of the state space of interests. A key problem is to properly generate samples that follow the probability distribution (x). Below we discuss a few specic examples arising from studies in bioinformatic s and systems biology. Example 1. Evolution of biomolecules . Sequence alignment is a widely used method to infer biological information about a biomole cule. A key ingredient Models and Algorithms for Biomolecules and Molecular Netwo rks, rst edition. By Bhaskar DasGupta and Jie Liang Copyright \u00a9 2015 John Wiley & S ons, Inc.7778 SAMPLING TECHNIQUES: ESTIMATING EVOLUTIONARY RATES AND GE NERATING MOLECULAR STRUCTURES for alignment is the scoring matrices used to evaluate simil arity between sequences, which are derived based on an evolutionary model of the biomo lecules [3,12,29]. Assuming the evolutionary process of a protein molecule can be described by a continuous time Markov process, we can derive scoring matri ces from the underlying amino acid substitution rates of the evolutionary process [ 13,28,30,31]. Denote the 20\u00d720substitution rates in the matrix form as QR20\u00d7R20, and assume that we have a set of multiple-aligned sequences Sand a phylogenetic tree T. Our task is then to estimate the distribution (Q|S,T)thatQfollow. Following the Bayesian framework, the distribution (Q|S,T)can be calculated as: (Q|S,T)/integraldisplay P(S|T,Q)\u00b7(Q)dQ, where the probability P(S|TQ)of obtaining a set of aligned sequences for a given set of substitution rates Qand a phylogenetic tree Tcan be evaluated through the underlying Markovian model. Additional information of prior knowledge of the likely values of Qcan be incorporated in the prior distribution (Q). Example 2. Loop entropy . Conformational entropy is an important fac- tor that contributes to the stability of biomolecules. For e xample, loops located on the surface of a protein often are flexible, and their confo rmational entropy may influence the stability of the protein. Similarly, loops in dierent types of RNA secondary structures may influence the nal structure an d stability of RNA molecules [34]. The problem of estimating loop entropy can be formulated as f ollows. Let the conformation of a loop of length lto bex= (x0,\u00b7\u00b7\u00b7,xl), wherexiR3is the coordinates of the i-th residue or nucleotide. The positions of the rst residue x0 and the last residue xlare xed. The probability (x)that a chain of length lwith only one end xed closes up so its l-th residue is at the correct position of xlgives the conformational entropy sof the loop: s=/integraldisplay (x)ln(x)dx, The task is then to accurately estimate (x). Example 3. Biological systems such as gene circuits and protein-prote in inter- action networks have often been ne tuned through evolution to be robust against fluctuations in environmental conditions, such as nutrient concentration and dam- aging factors such as UV irradiation. Despite the intrinsic stochastic nature of many biological processes, they often behave consistently and reliably. However, when the system behavior deviates signicantly from the nor m, a cell often en- ters into an abnormal or emergent state, which may manifest a s a disease state at organismic level. We can formulate a simplied model of this problem. The state of a biological network system can be represented by the amount of relevant m olecular species. Assume there are mmolecular species, and the vector xof their concentrations or copy numbers is x= (x1,\u00b7\u00b7\u00b7,xm). Let the regionRnforxrepresent the region of normal states, and Rdrepresent the region of a disease state. The probability tha tPRINCIPLES OF MONTE CARLO SAMPLING 79 the system will be in the normal state at time tcan be calculated as: [x(t)Rn|x(0)] =/integraldisplay x(t)Rn[x(t)|x(0)]dx(t). Similarly, the probability that the system will be in the dis ease state is: [x(t)Rd|x(0)] =/integraldisplay x(t)Rd[x(t)|x(0)]dx(t). We may also be interested in assessing the probability of rar e event that the system moves from the normal state to a disease state. This can be cal culated as: [x(t)Rd|x(0)Rn] =/integraldisplay x(t)Rd;x(0)Rn;[x(t)|x(0)]dx(t). The primitive for studying these problems is to assess the pr obability[x(t)|x(0)] that the system will be in state x(t)at timet, given an initial condition x(0). 3.2 Principles of Monte Carlo sampling 3.2.1 Estimation through sampling from target distributio n To estimate properties of a biological system, our task is to generate samples follow- ing the distribution (x)we are interested in, which is called the target distribution . For example, calculating E[f(x)] =/integraldisplay xRf(x)(x)dx depends on the ability to generate proper samples from the di stribution(x). If we are able to generate msuch samples, we can have our estimation as: E[f(x)]1 m[f(x(1))+\u00b7\u00b7\u00b7+f(x(m))]. (3.2) This can be a very challenging task, as we may have diculty in sampling suf- ciently in high dimensional space, a frequently encounter ed problem. As an ex- ample, a 2-dimensional Ising model with 30 \u00d730 lattice sites has a magnetic spin in each site (Fig. 3.1). A spin can take either an up(+1) ordown(1) position, which is denoted as x{+1,1}. The overall energy H(x)of the system is deter- mined by the magnetic eld heach spinexperiences, and the interactions each spin has with its four neighbors: H(x) =J/summationdisplay xx+/summationdisplay hx. HereJis the strength of interactions between neighboring spins, his the magni- tude of the external magnetic eld, and the state x= (x1,\u00b7\u00b7\u00b7,x900)can take any of 2900congurations. The task of estimating physical properties is to compute inter- nal energy<u>=E[H(x)], the free energy F=kTlog[/summationtext xexp(H(x)/kT)], and80 SAMPLING TECHNIQUES: ESTIMATING EVOLUTIONARY RATES AND GE NERATING MOLECULAR STRUCTURES 30 30 Figure 3.1 The Ising model of 30 \u00d730 size, with a total of 30\u00d730 = 900 sites. The spin at each site can adopt either an \"up\" or a \"down\" state , with a total of 2900 possible congurations. Integration in this high dimensio nal space of this simple example is challenging. the specic heat C=<u> T, all require summation in the 900 dimensional space, which is a challenging task. There may be other diculties in integrating Equation (3.1) . We may have good models of the underlying physical processes, but we may have no knowledge of the explicit form of the distribution function (x). Even if we know the functional form of(x), sampling from this distribution can be quite dicult. For e xample, the regionRof interests where we need to sample from may be of very constr ained in high dimensional space, and it would be dicult to generate s amples from it. 3.2.2 Rejection sampling Computing the probability (x)of a state xis challenging, but often we can evalu- ate the relative probability of a state x, namely,(x)up to a constant, c(x), where the value of the constant cis unknown. If we can generate samples from a trial dis- tributiong(x)(also called a sampling or aproposal distribution ), such that it covers c(x)after multiplication by a constant M. That is, we have Mg(x)c(x)for allx. We can use the rejection sampling method to obtain samples from the target distribution (x). This is summarized in Algorithm 3.2.2. The accepted sample s following this procedure will correctly follow (x). The principle behind rejection sampling is illustrated in F ig. 3.2. Note that Mg(x)coversc(x)everywhere. After we draw a sample xfromg(x), we will only accept it with a probability. The acceptance ratio r, which isc(x) Mg(x), will remove excessive samples beyond the target distribution c(x). The nal accepted samples xwill therefore follow the correct target distribution (x), up to a constant c.MARKOV CHAINS AND METROPOLIS MONTE CARLO SAMPLING 81 Algorithm 3.2.2 Rejection Sampling. repeat Sample a candidate new state xfrom a proposal distribution function g(x) Compute the ratio r=c(x) Mg(x) DrawufromU[0,1] if(ur)then Accept else Rejectx end if until convergency Mg(x) c(x) Figure 3.2 Illustration of rejection sampling. The target distributi on up to a constant c(x)is covered everywhere by the sampling distribution Mg(x). As samples are generated atxfromMg(x), it is dierent from c(x). By accepting only a fraction ofc(x) Mg(x)of the generated samples at x, namely, by taking samples to the proportion of those under t he shaded area, the correct distribution (x)can be sampled up to a constant. 3.3 Markov chains and Metropolis Monte Carlo sampling 3.3.1 Properties of Markov chains A more general framework to obtain samples from a specic tar get distribution is that of the Markov chain Monte Carlo (MCMC) method. Monte Car lo integration of Equation (3.2) can be achieved by running a cleverly const ructed Markov chain. This technique can be used to study many complex problems. Conditions on Markov Model We rst discuss Markov chains informally. Give a set of states, a Markov process or Markov chain moves successive ly from one state xi to another state xj, with a transition probability (xj|xi). It is assumed that the Markov property holds, namely, (xj|xi)does not depend on any state the process visited before xi.82 SAMPLING TECHNIQUES: ESTIMATING EVOLUTIONARY RATES AND GE NERATING MOLECULAR STRUCTURES To apply the MCMC method, the Markov process need to satisfy c ertain condi- tions. We assume that the Markov process obeys the irreducib ility condition, the recurrent state condition, and the aperiodicity condition . The irreducibility condi- tion dictates that it is possible to travel from any state to a ny other state, albeit through perhaps many time steps. With the recurrent state co ndition, all states have the property that the expected number of visits to this s tate is innite. With the aperiodicity condition, there is always a non-zero prob ability to be at any state after a certain number of steps of Markov chain. Steady stateof Markovchain If a Markov chain satises the above three conditions, it will converges to a steady state probability distributio n as time increases. Denote the probability distribution at the i-th step of a Markov chain as i(x), we have: lim nn(x) = lim n0(x)Pn=(x), wherePis the Markov transition probability matrix, with the trans ition probability pi,jas its(i,j)-th element, and (xi)>0as every state is recurrent. Hence, this Markov chain will converge to a steady state distribution (x), which is unique and will not depend on the initial distribution 0(x).(x)is the unique solution of(x)P=(x), and for each state xi, we have: lim npi,j=(xj),for anyi. This suggests that once we are able to generate a random sampl exat timet from the stationary distribution (x), all subsequent (correlated) samples are also generated from (x). Solution to (x)P=(x)further implies that after a long duration, the probability of nding the process in stat exjisj, regardless of the starting state. That is, (xj)is the long run mean fraction of time that the process is in state xj. Time reversibility Time reversibility plays a central role in constructing a Ma rkov chain for Monte Carlo simulation. When a movie is played back ward, we immedi- ately take notice. However, there are processes which are im possible to distinguish by observing their trajectories if it is played forward or ba ckward in time. These are time reversible processes. Specically, if the joint probability a Markov process take s the sequence of states (x0,x1,\u00b7\u00b7\u00b7,xn)at time(0,1,\u00b7\u00b7\u00b7,n)is the same as it takes the sequence of states (xn,xn1,\u00b7\u00b7\u00b7,x1)at time(0,1,\u00b7\u00b7\u00b7,n)for arbitrary n, namely: (x0,x1,\u00b7\u00b7\u00b7,xn) =(xn,xn1,\u00b7\u00b7\u00b7,x1,x0), this Markov process is time reversible . For time reversible process, if x1=x0, we will have 1(x) =0(x). Since 1(x) =o(x)P, we have 0(x) =0(x)P, namely, the initial distribution is stationary. In addition, since the joint probability (x0=i,x1=j) =(x1= i,x0=j)for time reversible Markov chain, we have: (i)pi,j=(j)pj,ifor alli,j. This is called the detailed balance condition.MARKOV CHAINS AND METROPOLIS MONTE CARLO SAMPLING 83 Overall, one can show that the Markov chain is time-reversib le if and only if the detailed balance condition is satised and the initial stat e is already in the steady state. 3.3.2 Markov chain Monte Carlo sampling The basis of Markov chain Monte Carlo simulation, also calle d Metropolis Monte Carlo, is that if a Markov chain satises the conditions disc ussed above, it will converge to the stationary distribution (x). Therefore, we can obtain dependent samples following (x). Assuming it takes msteps for the Markov chain to reach the stationary state, we can discard the rst msamples, and obtain our estimates of Equation (3.2) as: E[f(x)] =n/summationdisplay m+1f(xi). The key issue is then, how can we construct a Markov chain such that its stationary distribution is the same as the distribution (x)of our interest, namely, the target distribution. The basic idea was laid out by Metropolis and colleagues in th e 1950's, which was further developed by Hastings in the 1970's. Briefly, we samp le a candidate state yfrom a proposal distribution q(\u00b7|xt).yis accepted as xt+1, (x,y): (x,y) = 1,(y)q(x|y) (3.3) We method as Algori x0; repeat Sample a candidate new yfrom a proposal function until convergency Here the proposal distribution q(y|x)can have any form, but the stationary dis- tribution will always be (x). It is remarkable that this seemingly simple approach works. We now discuss the rationale behind MCMC. The transition pro bability for the Markov chain to travel from xtto a dierent state xt+1can be decomposed into two events. First, we generated xt+1with the proposal probability q(y|xt). Second, yis then accepted as xt+1with the probability (x,y). When xt+1\\e}io\\slsh=x, the transition probability p(xt+1|xt)is the product q(y|xt)\u00b7(x,y). When xt+1=84 SAMPLING TECHNIQUES: ESTIMATING EVOLUTIONARY RATES AND GE NERATING MOLECULAR STRUCTURES x, the transition probability p(xt+1|xt)isI(xt+1=xt)/bracketleftig 1/integraltext y/ne}ationslash=xq(y|xt)(x,y)/bracketrightig From Equation we have: (xt)q(xt+1xt)(xt,xt+1) =(xt+1)q(xt|xt+1)(xt+1,xt), which is the same as the detailed balance condition: (xt)p(xt+1|xt) =(xt+1)p(xt|xt+1). (3.4) With the detailed balance condition satised, if we integra te both sides of Equa- tion (3.4) with regard to xt, we have: /integraldisplay (xt)p(xt+1|xt)dxt=(xt+1). That is, if xtis drawn from the stationary distribution (x), thenxt+1is also drawn from the stationary distribution. We have now shown th at once a sample is generated from the stationary distribution (x), all subsequent samples will be from that distribution. Remark. Although Markov chain Monte Carlo sampling has found wide ap plica- tions, there are a number of issues: sometimes it is dicult t o assess whether the Markov chain has reached the stationary distribution, or wh ether adequate sam- pling is achieved. It is also often dicult to ensure that sam ples drawn from the steady state distribution have small variance. A critical c omponent of an eective sampling strategy is the design of the trial function or prop osal function q(\u00b7|bxt), often also called the move set, which generates candidate xt+1. A well designed move set will increase the convergence rate signicantly. H owever, this often re- quires expertise and specic consideration of the problem a nd is a challenging task. 3.4 Sequential Monte Carlo sampling The sequential Monte Carlo (SMC) method oers another gener al framework to obtain samples from a target distribution. It has its origin in early studies of chain polymers, where a growth strategy was used to generate self-avoiding poly- mer chains, with chains grown one monomer at a time until the d esired length is reached [26]. By generating many independently grown chain s, estimation such as Equation (3.1) can be made. This approach was subsequently e xtensively studied and extended with wide applications [1,4,8,14-16,19,20,2 2,23,33,34]SEQUENTIAL MONTE CARLO SAMPLING 85 3.4.1 Importance sampling Because of the high dimensionality, sampling is more eecti ve if we focus on impor- tant regions instead of uniformly sampling everywhere. If o ur goal is to generate samples from the target distribution (x), it would be more productive to sample more frequently in regions where (x)has larger values. It is often easier to sample from a trial distribution g(x)than from the desired target distribution (x). The distribution g(x)should be designed such that it has the same support as (x)and is as close in shape to f(x)(x)as possible. In fact, it is possible a well-designed g(x)is a better distribution than (x)to sample from for estimating E[f(x)]. Asg(x)is usually dierent from (x), correcting its bias is necessary. In the rejection sampling method discussed earlier, this was achi eved by accepting only a fraction of generated samples. A more general approach is t o assign weights to generated samples. When drawing samples x(1),x(2),\u00b7\u00b7\u00b7,x(m)from a trial distri- butiong(x), we calculate the importance weight associated with each sa mple: w(j)=(x(j)) g(x(j)). The estimation of Equation (3.1) can then be calculated as: E[f(x)]/bracketleftbiggw(1)\u00b7f(x(1))+\u00b7\u00b7\u00b7+w(m)\u00b7f(x(m)) w(1)+\u00b7\u00b7\u00b7+w(m)/bracketrightbigg (3.5) 3.4.2 sequential importance sampling Designing an eective trial distribution or sampling distr ibutiong(x)can be very challenging. A problem is the high dimension of x. For example, to sample confor- mations of a chain polymer such as a model protein molecule, w e need to consider the congurations of many monomers (residues). One approac h is to decompose the chain into individual monomers or residues, and adopt the ch ain growth strategy. By growing the chain one monomer at a time, we can adaptively b uild up a trial function, one monomer at a time. Specically, we can decompose a high-dimensional random va riablexas:x= (x1,\u00b7\u00b7\u00b7,xd).In the case of chain polymer, xis the conguration of the full length chain, andxiR3is the coordinates of the i-th monomer. We can build up a trial distribution as: g(x) =g1(x1)g2(x2|x1)\u00b7\u00b7\u00b7gd(xd|x1,\u00b7\u00b7\u00b7,xd1), whereg1(x1)is the trial distribution to generate x1, andgi(xi|x1,\u00b7\u00b7\u00b7,xi1)is the trial distribution to generate xicondition on already generated (x1,\u00b7\u00b7\u00b7,xi1). The target distribution can also be written analogously as: (x) =1(x1)2(x2|x1)\u00b7\u00b7\u00b7d(xd|x1,\u00b7\u00b7\u00b7,xd1), (3.6)86 SAMPLING TECHNIQUES: ESTIMATING EVOLUTIONARY RATES AND GE NERATING MOLECULAR STRUCTURES The weight for a sample can be written as: w(j)=(x(j)) g(x(j))=1(x1)2(x2|x1)\u00b7\u00b7\u00b7d(xd|x1,\u00b7\u00b7\u00b7,xd1), g1(x1)g2(x2|x1)\u00b7\u00b7\u00b7gd(xd|x1,\u00b7\u00b7\u00b7,xd1). It is more convenient to calculate the weight by incremental ly updating the weight as more components are added. At an intermediate step t, we can have the weight as: wt=wt1\u00b7(xt|(x1,\u00b7\u00b7\u00b7,xt1) g(xt|(x1,\u00b7\u00b7\u00b7,xt1). As we sequentially add xi, the ideal decomposition of the target distribution shown in Equation (3.6) is dicult to compute, as the target d istribution at any intermediate step t, namely,(xt) =1(x1)2(x2|x1)\u00b7\u00b7\u00b7t(xt|x1,\u00b7\u00b7\u00b7,xt1) =/integraltext(x1,\u00b7\u00b7\u00b7,xd)dxt+1\u00b7\u00b7\u00b7dxd,can only be computed through integrating out all other components, an often no less challenging task than the problem we set out to solve itself. We can introduce instead an intermediate distribution t(x1,\u00b7\u00b7\u00b7,xt)when adding thet-th component/monomer, which can be viewed as an approximat ion to the marginal distribution of the partial sample xt= (x1,\u00b7\u00b7\u00b7,xt): t(x1,\u00b7\u00b7\u00b7,xt)/integraldisplay (x)dxt+1\u00b7\u00b7\u00b7dxd. When all components are added or the chain grown to its full le ngth, the interme- diate distribution coincides with our target distribution : d(x1,\u00b7\u00b7\u00b7,xd) =(x1,\u00b7\u00b7\u00b7,xd). It is natural to use t(x1,\u00b7\u00b7\u00b7,xt)to design the trial sampling distribution. For example, we can have our trial distribution as: g(xt|x1,\u00b7\u00b7\u00b7,xt1) =t(xt|x1,\u00b7\u00b7\u00b7,xt1). To correct the bias in sampling using these intermediate dis tributions, we can calculate the weight incrementally as we add xt: wt=wt1t(x1,\u00b7\u00b7\u00b7,xt) t1(x1,\u00b7\u00b7\u00b7,xt)\u00b71 gt(xt|x1,\u00b7\u00b7\u00b7,xt1). Using the intermediate distributions t(x1,\u00b7\u00b7\u00b7,xt)has a number of advantages. Ast(x1,\u00b7\u00b7\u00b7,xt)more or less tracks the target distribution (x1,\u00b7\u00b7\u00b7,xd), we can judge the quality of samples before they are completed. For e xample, we can improve computing eciency by eliminating further simulat ion if a sample has very smallwtbefore nishing adding all components to xd. Overall, the sampling process is carried out sequentially: We rst draw x1from g1(x1), than draw x2condition on the existing x1fromg2. This is repeated until xdis drawn. In the example of generating chain polymer, we rst drawx1for the placement of the rst monomer, then add the second monomer to the location x2, which is drawn from g2, until the chain reaches the full length d. To sample xfromSEQUENTIAL MONTE CARLO SAMPLING 87 (x), the individual gi()s are to be designed so the joint trial distribution g(x) resembles(x)orf(x)(x)as much as possible. The sequential Monte Carlo algorithm be summarized as Draw position x(j) end for Self-avoiding walk in two-dimensional lattice As an illustration, we examine the problem of estimating the average end-to-end distance of a c hain polymer of length N, which is modeled as a self-avoiding walk on a planar lattice . The conguration of the molecule is denoted as i-th monomer (a,b), the coordinates of the monomer. As a chain poly- mer, distances between neighboring monomers xiandxi+1are exactly 1. As this molecule have excluded volume, none of the lattice sites can be occupied by more than one monomers. Our goal is to estimate the average end-to-end distance E(||xNx1||2)of the self-avoiding walks under the uniform distribution (x) =1/ZN, whereZNis the total number of SAWs. If we use the approach of Metropolis Mon te Carlo, we would start with a particular conguration, for example, an exten ded chain, and apply various moves, and run the simulation for a long period to ens ure the stationary distribution is reached, and then calculate E(||xNx1||2)from collected correlated samples. Here we discuss how to apply the chain growth based sequentia l Monte Carlo technique to solve this problem. This is a widely used approa ch to study chain poly- mers [8,14-16,26,33,34]. Naively, we can start at (0,0), and repeatedly choose with equal probability one of the three neighboring sites for pla cing the next monomer. If a site is already occupied, we go back to the origin and star t with a new chain, until the surviving chain reaches the full length. However, the success rate of this approach is very small, as most attempts will end up with runn ing into an occupied site prematurely. This approach, due to Rosenbluth et al., is to look one-step ahead when placing a monomer. At step t, we examine all neighboring sites of xt= (i,j)at(i\u00b1 1,j)and(i,j\u00b11). If all neighbors have been visited, this chain is terminate d, with an assigned weight of 0. Otherwise, we select one of the available site with equal probability to place the next monomer. Specically, w e draw the position of xt+1condition on current conguration of the chain (x1,\u00b7\u00b7\u00b7,xt)according to the88 SAMPLING TECHNIQUES: ESTIMATING EVOLUTIONARY RATES \u0001\u0002\u0006 s ampling. Following Rosenbluth [26], samples of self-avoiding walks are grown f rom 2-mer to 5-mer by adding a monomer at each of the unoccupied neighboring site with equ al probability. To draw samplesfromtheuniformdistributionof5-mers, allofthe2 5conformationsshouldhaveequal probability of 1/25to be generated. However, the conformations are generated w ith unequal probability. For example, some are generated with the proba bility of1/3\u00b71/3\u00b71/2=1/18, and others are generated with the probability of1/3\u00b71/3\u00b71/3=1/27. Such bias can be corrected by assigning a proper weight to each of the conformations. probability distribution: (xt+1) =p[(k,l)|x1,\u00b7\u00b7\u00b7,xt] =1 nt where(k,l)is one of the unoccupied neighbor, and ntis the total number of such unoccupied neighbors. Fig. 3.3 illustrates this approach, where the process of gen- erating all 5-mers starting from a 2-mer is shown. However, samples generated are not uniformly distributed. When growing a 2- mer to all possible 5-mers (Fig. 3.3), as there are a total of 2 5 5-mers that canSEQUENTIAL MONTE CARLO SAMPLING 89 be generated from the initial dimer, each chain should be gen erated with an equal probability of 1/25as the uniform distribution is our target distribution. How ever, these 5-mers will be generated with unequal probability. Fo r the uniform target distribution, we should have (x)1, but the chains are sampled dierently, with x(n1\u00d7n2\u00d7\u00b7\u00b7\u00b7\u00d7nN1)1, withnibeing the number of empty sites neighboring the last added monomer at step i. Such bias can be corrected by assigning a weight to each chain generated, which is w(x) =n1\u00d7n2\u00d7\u00b7\u00b7\u00b7\u00d7nN1. Within the sequential importance sampling framework, is, if there are empty sites neighboring xt1,xtthen occupies one of the nt1 available sites. The sequence of intermediate distributio n functions are t(xt), t= 1,\u00b7\u00b7\u00b7,N1,which is a sequence of uniform distribution of SAWs with t-monomers: t(xt) =1 Zt, whereZtis the total number of tmonomers. 3.4.3 Resampling As more components or monomers are added, these unnished pa rtial samples may have very diverse weights. Many samples may have very small w eights, while a few may have very large weights. Samples with small weights will contribute little to our estimation of Equation (3.1). Samples with very small va lues off(x)will also have little contributions if our task is to estimate E[f(x)]. In the case of growing polymer chain, we may nd that the chain has reached a dead-en d and can no longer be grown further. It may be more protable to replace t hese samples with other more promising samples. The technique of resampling can be used to reduce sample vari ance. We can rst assign a resampling probability to each of the current s ample. The assigned values reflect our preference to either encourage or discour age this sample to be taken again. Let the set of msamples be{x(j) t},j= 1,\u00b7\u00b7\u00b7,m, and We drawnsamplesx(j) tfrom the existing set of msamples according to probabilities ((1),\u00b7\u00b7\u00b7,a(m)). A new weight w(j) t=w(j) t (j)is then assigned to the resampled x(j) t. The resulting samples will be properly weighted according to the target distribution (x). The resampling algorithm can be summarized as shown in Algorithm 3.4.3. As our goal is to prune away poor samples, it is important to de sign eective resampling probabilities {(j)}. One generic approach is to set (j)as a monotonic function of w(j). For targeted resampling, we will choose (j)based on the objective of interest. Physical considerations and future informati on often can help to design (j). We will also need to balance the desire to have diverse sampl es and to have many samples with large weights.90 SAMPLING TECHNIQUES: ESTIMATING EVOLUTIONARY RATES AND GE NERATING MOLECULAR probabilities {(j)}m j=1 Each sample in the newly formed sample is assigned a new weigh t j-th chain in new sample is a copy of k-th chain in original sample w(j)w(k)/(k) end for 3.5 Applicatoins 3.5.1 Markov Chain Monte Carlo for evolutionary rate estima tion We now discuss how Markov chain Monte Carlo can be applied usi ng the example of estimating substitution rates of amino acid residues, an im portant task in analysis of the pattern of protein evolution. Protein function prediction. When a protein is found to be evolutionarily related to another protein, for example, through sequence alignmen t, one can often make inference on its biochemical functions. The success in dete cting such evolutionary relationship between two proteins depends on the use of a sco ring matrix to quantify the similarity between two aligned sequences. Scoring matrices can be derived from analysis of substituti on rates of amino acid residues. The widely used PamandBlosum scoring matrices are based on empirical models of amino acid residue substitutions [2,12 ]. A more recent approach is to employ an explicit continuous time Markov process to mo del the history of evolution of the specic protein of interests [29, 30, 32]. W e discuss below how Markov chain Monte Carlo can be used to estimate substitutio n rates of amino acid residues. Continuous time Markov process for residue substitution. Assuming that a phyloge- netic tree is given, which captures the evolutionary relati onship between protein sequences, we can use a reversible continuous time Markov pr ocess to model sub- stitutions of amino acid residues [6,31]. The model paramet ers are the 20\u00d720rate matrixQ, in which the entries qijs are instantaneous substitution rates of amino acid residues for the set Aof 20 amino acid residues, with the diagonal element taken asqi,i=/summationtext i,j/ne}ationslash=iqi,j. This matrix of instantaneous rates can be used to calculate the transition probabilities after time t[17]: P(t) ={pij(t)}=P(0)exp(Q\u00b7t), whereP(0) =I. Herepij(t)represents the probability that a residue of type iwill mutate into a residue of type jafter timet. Likelihood function of a xed phylogeny. For sequence kand sequence lseparated by divergence time tkl, the time reversible probability of of a phylogenetic tree. The branching topology of the tree represents the ancestor and descendent relationship. The l ength of the edge represents the evolutionary time in relative units. positionhinkand residue xlat the same position a setSofsmultiple-aligned sequences (x1,x2,\u00b7\u00b7\u00b7,xs)of lengthnamino we assume that a reasonably accurate phyloge netic tree is known. We denote the tree as T= (V,E). HereVis the set of sequences, namely, the union of the set of observed ssequencesL(leaf nodes), and the set of s1ancestral sequencesI(internal nodes). Eis the set of edges of the tree, where each edge represents a ancestor-descendent relationship, with edge length representing the evolutionary time. Let the vector xh= (x1,\u00b7\u00b7\u00b7,xs)Tbe the observed residues at positionh, withh{1,\u00b7\u00b7\u00b7,n}for thessequences. The probability of observing s number of xhat position haccording to (i,j)Epxixj(tij) after summing over the set Aof all possible residue types for the internal nodes I. The probability P(S|T,Q)of observing all residues in the aligned region is: P(S|T,Q) =P(x1,\u00b7\u00b7\u00b7,xs|T,Q) =n/productdisplay h=1p(xh|T,Q).92 SAMPLING TECHNIQUES: ESTIMATING EVOLUTIONARY RATES AND GE NERATING MOLECULAR STRUCTURES Bayesian estimation of instantaneous rates. We adopt a Bayesian approach to esti- matedQ. We describe the instantaneous substitution rate Q={qij}by a poste- rior distribution (Q|S,T). We use a prior distribution (Q)to encode our past knowledge of amino acid substitution rates for proteins. (Q|S,T)summarizes prior information available on the rates Q={qij}and the information contained in the observations SandT. It can be estimated up to a constant as: (Q|S,T)/integraldisplay P(S|T,Q)\u00b7(Q)dQ. Markov chain Monte Carlo. We can run a Markov chain to generate samples drawn from the target distribution (Q|S,T). Starting from a rate matrix Qtat timet, we generate a new rate matrix Qt+1using the proposal function T(Qt,Qt+1).The proposed new matrix Qt+1will be either accepted or rejected by the acceptance ratior(Qt,Qt+1). Specically, we have: Qt+1=A(Qt,Qt+1) =T(Qt,Qt+1)\u00b7r(Qt,Qt+1). To ensure that the Markov chain will reach stationary state, we need to satisfy the requirement of detailed balance, i.e., (Qt|S,T)\u00b7A(Qt,Qt+1) =(Qt+1|S,T)\u00b7A(Qt+1,Qt). This is achieved by using the Metropolis-Hastings acceptan ce ratior(Qt,Qt+1) discussed earlier to either accept or reject Qt+1, depending on whether the following inequality holds: 1,(Qt+1|S,T)\u00b7T(Qt+1,Qt) (Qt|S,T)\u00b7T(Qt,Qt+1)/bracerightbig , drawn from the uniform distribution U[0,1]. With the assumption that the underlying Markov process satisfy t he conditions outlined earlier, a Markov chain generated following these rules wil l reach the stationary state [9,25]. Once the stationary state is reached, we can collect mcorrelated samples of the Qmatrix. The posterior means of the matrix can then ated as: E(Q)m/summationdisplay i=1Qi\u00b7(Qi|S,T). Ratematrixandscoringmatrix. With derive scoring matrices of dierent evolutionary time intervals [13]. The (i,j)-th entrybij(t)of a scoring matrix between residues be factor.APPLICATOINS 93 Sequential chain growth Monte Carlo for estimating co nformational en- tropy of RNA loops Conformational entropy makes important contribution to th e stability and folding of biomolecule, but it is challenging to compute conformati onal entropy. Here we study the problem of computing RNA loop entropy. Using a disc retek-state model for each nucleotide of the RNA molecule, we can model loops as self-avoiding walks in three-dimensional space, and calculate the loop entropy using sequential Monte Carlo. For a loop of length n, wherenis the number of unpaired nucleotides, possible conformations of a random coil o f length n, andloopis the number of loop conformations that are compatible with the stem that closes the loop. We use the sequential Monte Carlo algorithm to calculate the RNA loop entropy. During the process of chain growth, we generates a set of prop erly weighted con- formations with respect to the target distribution of unifo rmly distributed RNA molecules, along with correct weights of the conformations . We use the following scheme: 1.Initialization. We set the initial sampling size to m1= 1, with weight w(1) 1= 1. At step t1, we have grown conformation S(j) t1, we exhaustively test all possible attachments of the next nucleotide, with a total ofk(j) tdierent possibilities. This will generate no greater than conforma- tions of L=/summationtextmt1 j=1k(j) t. 3.Resampling. IfLm, which is the upper bound of Monte Carlo sample size, we keep all of the samples and their corresponding weights an d setmt=L. IfL > m , we choose mt=mdistinct samples with marginal probabilities proportional to a set of priority scores (l) t. Intuitively, the priority score t(St)reflects the chain's \"growth perspective\", and is used to enc ourage the growth of chain Stto specic directions. 4.Estimation. When the target loop length nis coilis estimated as/summationtextmn j=1w(j) nI(S(j) n), wheremnis the number of samples at length n,w(j) nis the importance weight of samples S(j) n, andI()is the identity function of 1. Details of the resampling strategy, including the design of the priority scores can be found in [34].94 SAMPLING TECHNIQUES: ESTIMATING EVOLUTIONARY RATES AND GE NERATING MOLECULAR STRUCTURES The calculated loop entropy for hairpin loops of length 3-50 has excellent agree- ment with values extrapolated from the Jackson-Stockmayer model. However, cal- culations reveal that loop entropies of more complex RNA sec ondary structures are signicantly dierent from the extrapolated values for lon g internal loops. Overall, conformational entropy of dierent RNA secondary structur es with loops can be calculated with accuracy beyond extrapolation of simplie d theoretical models. 3.6 Discussion and summary In this chapter, we discussed the general problem of charact erizing ensemble proper- ties of biological systems through integration by sampling , along with the diculties of sampling in high dimensional space. We briefly examined th e approach of re- jection sampling, and discussed in more details two general frameworks in Monte Carlo sampling, namely, the Markov chain Monte Carlo (MCMC) or Metropolis Monte Carlo method, and the sequential Monte Carlo method. W e discussed basic concepts such as sampling from a desired target distributio n, properties of Markov chains, time reversibility, detailed balance, and the stat ionary state. This was fol- lowed by the example of estimating evolutionary substituti on rates of amino acids. For sequential Monte Carlo, we discussed the general princi ple of importance sam- pling, the approach of sequentially building up the target d istribution, and the technique of resampling for variance reduction. The applic ations in generating self- avoiding walks for studying chain polymers and calculating RNA loop entropy were then presented. Remark. Generating samples from a target distribution for tasks suc h as Equa- tion (3.1) is a fundamental problem in science and engineeri ng. Among the two general frameworks of Monte Carlo sampling, the Metropolis Monte Carlo or the Markov chain Monte Carlo (MCMC) method can generated correl ated samples from a target distribution, and the sequential Monte Carlo or the sequential importance sampling method can generated samples from a trial distribu tion dierent from the target distribution. Samples are then adjusted according t heir importance weights so they follow the target distribution. The MCMC method has its origin in the 1950s [24], where the ide a of an evolv- ing Markov chain was rst introduced for sampling from a targ et distribution. The extension to allow non-symmetric transition rules was m ade by Hastings [11]. Multilevel sampling methods were subsequently developed, including the umbrella sampling method [27] and parallel tempering or replica exch ange sampling meth- ods [5,7]. The application of MCMC for studying molecular ev olution can be found in [29]. The sequential importance sampling method was rst describ ed in the work of Rosenbluth et al. in generating chain polymers using a chain growth strategy [ 26]. Further development of the look-ahead strategy was subsequ ently developed in [23]. The theory of sequential importance sampling with resampli ng was developed by Liu and Chen in [18] and in simulating chain polymers by Grass berger [8]. The topic of proper rejection control can be found in [22]. The ge neral theoretical framework of sequential Monte Carlo can be found in [19, 21]. Further studies of chain polymers, including those under severe constraints, including void formation, protein packing, generating conformations from contact ma ps, generating transi- tion state ensemble of protein folding can be found in [14-16 , 33]. Loop entropyDISCUSSION AND SUMMARY 95 calculation for various RNA secondary structures using seq uential Monte Carlo can be found in [34]. A study on the eects of spatial connement o f cell nucleus in de- termining the folding landscape, including scaling behavi or of long range chromatin interactions is described in [10].REFERENCES 1. R. Chen and J. Liu. Sequential monte carlo methods for dyna mic systems. Journal of American Statistical Association , 93:1032-1043, 1998. 2. M. O. Dayho, R. M. Schwartz, and B. C. Orcutt. Atlas of Protein Sequence and Structure . National Biomedical Research Fundation, Washington, D.C , 1978. 3. M.O. Dayho, R.M Schwartz, and B.C Orcutt. Atlas of Protein Sequence and Struc- ture, vol.5, suppl. 3. , chapter A model of evolutionary change in proteins, pages p p. 345-352. National Biomedical Research Foundation, Washin gton, D.C, 1978. 4. A. Doucet, N. De Freitas, Gordon N., and A. Smith. Sequential Monte Carlo Methods in Practice . Springer Verlag, 2001. 5. David J. Earl and Michael W. Deem. Parallel tempering: The ory, applications, and new perspectives. Phys. Chem. Chem. Phys. , 7:3910-3916, 2005. 6. J. Felsenstein. Evolutionary trees from DNA sequences: a maximum likelihood ap- proach. J. Mol. Evol. , 17:368-376, 1981. 7. C.J. Geyer. Markov chain Monte Carlo maximum likelihood. InProceedings of the 23rd Symposium on the Interface , page 156, New York, 1991. American Statistical Association. 8. P. Grassberger. Pruned-enriched Rosenbluth method: Sim ulation of polymers of up to 1,000,000. Phys. Rev. E. , 56:3682-3693, 1997. 9. G. R. Grimmett and D. R. Stizaker. Probability and Random Processes . Oxford University Press, New York., 2001. 10. G. G\u00fcsoy, Y. Xu, A.L. Kenter, and J. Liang. Spatial conne ment is a major deter- minant of the folding landscape of human chromosomes. Nucleic Acid Res. , 42:8223- 8230, 2014. Models and Algorithms for Biomolecules and Molecular Netwo rks, rst edition. By Bhaskar DasGupta and Jie Liang Copyright \u00a9 2015 John Wiley & S ons, Inc.9798 REFERENCES 11. W. K. Hastings. Monte Carlo sampling methods using marko v chains and their applications. Biometrika , 57:97-109, 1970. 12. S. Heniko and J. G. Heniko. Amino acid substitution mat rices from protein blocks. Proc. Natl. Acad. Sci. , 89:10915-10919, 1992. 13. S. Karlin and S. F. Altschul. Methods for assessing the st atistical signicance of molecular sequence features by using general scoring schem es.Proc. Natl. Acad. Sci. , 87:2264-2268, 1990. 14. J. Liang, J. Zhang, and R. Chen. Statistical geometry of p acking defects of lattice chain polymer from enumeration and sequential Monte Carlo m ethod. J. Chem. Phys., 117:3511-3521, 2002. 15. M. Lin, H.M. Lu, R. Chen, and J. Liang. Generating properl y weighted ensemble of conformations of proteins from sparse or indirect distance constraints. J Chem Phys , 129(9):094101, 2008. 16. M. Lin, J. Zhang, H.M. Lu, R. Chen, and J. Liang. Constrain ed proper sampling of conformations of transition state ensemble of protein fo lding. J Chem Phys , 134(7):075103, Feb 2011. 17. P. Li\u00f2 and N. Goldman. Models of molecular evolution and p hylogeny. Genome Res. , 8:1233-1244, 1998. 18. J. S. Liu and R. Chen. Blind deconvolution via sequential imputations. Journal of the American Statistical Association , 90:567-576, 1995. 19. J. S. Liu and R. Chen. Sequential monte carlo methods for d ynamic systems. Journal of the American Statistical Association , 93:1032-1044, 1998. 20. J. S. Liu, R. Chen, and T. Logvinenko. A theoretical frame work for sequential im- portance sampling and resampling. In J.F.G. de Freitas A. Do ucet and N. Gordon, editors, Sequential Monte Carlo Methods in Practice . Cambridge University Press, 2000. 21. J. S. Liu, R. Chen, and T. Logvinenko. A theoretical frame work for sequential impor- tance sampling and resampling. In A. Doucet, J. F. G. de Freit as, and N. J. Gordon, editors, Sequential Monte Carlo in Practice . Springer-Verlag, New York, 2001. 22. J. S. Liu, R. Chen, and W. H. Wong. Rejection control and im portance sampling. Journal of American Statistical Association , 93:1022-1031, 1998. 23. H. Meirovitch. A new method for simulation of real chains : Scanning future steps. J. Phys.A: Math. Gen. , 15:L735-L741, 1982. 24. N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, A.H. T eller, and E. Teller. Equations of state calculations by fast computing machines .J. Chem. Phys , 21:1087- 1091, 1953. 25. C. P. Robert and G. Casella. Monte Carlo Statistical Methods . Springer-Verlag Inc., New York., 2004. 26. M. N. Rosenbluth and A. W. Rosenbluth. Monte Carlo calcul ation of the average extension of molecular chains. J. Chem. Phys. , 23:356-359, 1955. 27. G. Torrie and distribu tions in Monte Carlo free- Umbrella sampling. Journal of Computational Physics , 23(2):187- 199, February 1977. 28. Y. Y. Tseng and J. Liang. Are residues in a protein folding nucleus evolutionarily conserved? J. Mol. Biol. , 335:869-880, 2004. 29. Y.Y. Tseng and J. Liang. Estimation of amino acid residue substitution rates at local spatial regions and application in protein function infere nce: A Bayesian Feb 2006.EXERCISES 99 30. S. Whelan and N. Goldman. A general empirical model of pro tein evolution derived from multiple protein families using a maximum-likelihood approach. Mol. Biol. Evol., 18:691-699, 2001. 31. substitut ion.J. Mol. Evol. , 39:105-111, 1994. 32. Z. Yang, R. Nielsen, and M. Hasegawa. Models of amino acid substitution and applications to mitochondrial protein evolution. Mol. Biol. Evol. , 15:1600-1611, 1998. 33. J. Zhang, R. Chen, C. Tang, and J. Liang. Origin of scaling behavior of protein packing density: A sequential monte carlo study of compact l ong chain polymers. J. Chem. Phys. , 118:6102-6109, 2003. 34. J. Zhang, M. Lin, R. Chen, and J. Liang. Discrete state mod el and accurate estimation of loop entropy of rna secondary structures. J. Chem. Phys. , 128(125107):1-10, 2008. EXERCISES 3.1 In the Markov chain Monte Carlo method, the nal stationary d istribution reached after the chain convergency is the desired target co ntribution: /integraldisplay (x)A(x,y)dx=(y), wherexis the state variable, A(x,y) =T(x,y)\u00b7r(x,y)is the actual transition function, the product of the proposal function T(x,y), and an acceptance-rejection ruler(x,y). The proposal function T(x,y)suggests a possible move from xto y. The acceptance-rejection rule decides whether the propos ed move to ywill be accepted: Draw a random number ufrom the uniform distribution U[0,1]. If ur(x,y), the move is accepted and yis taken as the new position. Otherwise stay with x. In the original Metropolis Monte Carlo method, the proposal function is sym- metric:T(x,y) =T(y,x), and the acceptance-rejection rule is simply: r(x,y) distribution is the Boltzmann distributi on(x)exp(h(x)), whereh(x)is an energy function, the acceptance rule is often written a s:u r(x,y) = exp([h(y)h(x)]). This strategy will work, for example, if the proposal function gives equal probability 1/n(x)to each of the n(x)conformations that can be reached from conformation x: T(x,y) = 1/n(x), and ifn(x) =n(y)forxandythat are connected by a move. However, the number of possible moves for a conformation xfrequently depends on the local geometry. For example, it is more dicult in prot ein simulation to move an amino acid residue that is buried in the interior than moving a residue located in a loop region. In other words, the number of allowe d moves is dierent: n(x)\\e}io\\slsh=n(y), although each can be computed exactly.100 REFERENCES Whenn(x)\\e}io\\slsh=n(y), what rules can you devise to generate a Markov chain such that its stationary distribution is the same Boltzman distr ibution. First, write your answer in pseudocode, second, show that indeed your strateg y works. 3.2 Hastings rst realized that the proposal distribution does not need to be symmetric, but can be arbitrarily chosen so long as the condi tion of detailed balance is satised. His generalization leads to more flexible and ecient sampling strategy can be develop ed, which still gener- ates samples following the desired target distribution. An swer the following ques- tions and show your proofs: a) Show that Hasting's rule satises the detailed balance co ndition(x)A(x,y) = (y)A(y,x). b) Why does Hasting's rule work? That is, why is the equilibri um distribution the same as the desired target distribution? c) According to the same principle, will the following trial acceptance rule work? ur(x,y) = min/braceleftbigg 1,(x)T(y,x) (y)T(y,x)+(y)T(x,y)/bracerightbigg d) below? ur(x,y) = min/braceleftbigg 1,(y)T(y,x) (y)T(y,x)+(x)T(x,y)/bracerightbigg 3.3 Here we use Monte Carlo method to fold a sequence of a simplie d protein model on a two-dimensional lattice. The conformation of a pr otein of length the i-th residue in the 2-d lattice. The energy function of this HP model is:H(x) =/summationtext i+1<j(xi,xj), where(xi,xj) = 1 ifxiandxjare non-bonded spatial neighbors, and if both are Hresidues. Otherwise, (xi,xj) = 0. We can use the move sets of end move, corner move, crank-shift move, and pivot move. For the end move, the ends of the chain move to an empty adjacen t site. For the corner move, a single monomer is flipped. For the crankshaft m ove, two monomers are simultaneously moved. For pivot move, we choose a node al ong the chain as a pivot, and apply a symmetry operation to the rest of the chai n subsequent to the pivot. On a two dimensional lattice, symmetry operation include rotation and reflection. Our goal is to search for this sequence the conformation of th e lowest energy, namely, we want to fold this model protein. The conformation s follow the Boltz- mann distribution exp{U(x)/T}, whereTis temperature. Starting from an extended conformation and write a program implementing the Metropolis-Hastings algorithm (or the Markov chain Monte Carlo method) with simu lated annealing for this problem. Use dierent temperatures as needed, for exam ple, a temperature ladder ofT0= 2,T1= 0.9\u00b7T0,.... Be careful to allow enough burn-in period.EXERCISES 101 Specify the actual move sets you used. Write down your transition rules. Write down your acceptance criterion for a move. Justication for the choice of burning-period. You should run the simulation as many times as you can aord, a nd keep the conformation and energy value of your best result for some of the chains you run. Your output for a chain should include: A drawing of the folded conformation with the lowest energy f ound, and printed energy value. Select 4 temperature values that are most interesting to you , and plot the trajectory of the energy values of the protein starting at th e end of the burning period. 3.4 In importance sampling, it is essential to keep samples prop erly weighted, as this enables one to calculate many macroscopic properties o f the target population. In model studies of protein folding, one approach to estimat e thermodynamic prop- erties of HP model proteins is to sample from the uniform dist ributionu(x)of all SAWs on a lattice, using a sampling distribution function g(x). 1. What would be the proper weight wiof each sampled conformation xi? 2. If the goal is to estimate properties of the Boltzman distr ibution(x)which HP molecules follow, write down how you would re-adjust the w eight of samples properly weighted for the uniform distribution {(x1,w1),\u00b7\u00b7\u00b7,(xm,wm)}? 3. Now you decides to sample conformations of HP sequence dir ectly from the Boltzmann distribution (x). Write down the incremental weight one has to keep at each step of the growth where dimension increases b y one. Here sampling is based on the trial function gi(xi)using the sequence of auxiliary functionsi(xi).CHAPTER 4 STOCHASTIC MOLECULAR NETWORKS 4.1 Introduction Biomolecular networks formed by interacting biomolecules form the basis of regu- latory machineries of many cellular processes. Stochastic ity plays important roles in many networks. These include networks responsible for ge ne regulation, pro- tein synthesis, and signal transduction [3,21,32,38,44]. The intrinsic stochasticity in these cellular processes originates from reactions invo lving small copy numbers of molecules. It frequently occurs in a cell when molecular c oncentrations are in the range of\u00b5M to nM [3,40]. For example, the regulation of transcription s depends on the binding of often a few proteins to a promoter site. The s ynthesis of protein peptides on a ribosome involves a small numbers of molecules . Patterns of cell dierentiation also depend on events with initially a small number of molecules. In these biological processes, fluctuations intrinsic in lo w copy number events play important roles. With the importance of stochasticity in cellular functions well recognized [39,44, 46,61,62], it is important to understand the stochastic nat ure and its consequences in cellular processes. In this chapter, we rst discuss the b asic theoretical framework of the probability landscape of a stochastic network and the underlying discrete chemical master equation (dCME). We then discuss a computat ional method that optimally enumerate the state space essential for solving t he dCME, as well as methods for calculating the steady state and the dynamicall y evolving probability landscape. We will then describe approaches to simplify the state space. We further Models and Algorithms for Biomolecules and Molecular Netwo rks, rst edition. By Bhaskar DasGupta and Jie Liang Copyright \u00a9 2015 John Wiley & S ons, Inc.103104 STOCHASTIC MOLECULAR NETWORKS discuss the formulation of the continuous chemical master e quation (cCME), which approximates the dCME, as well as its further simplication s in the form of Fokker- Planck and Langevin models. This is followed by a discussion of the approach of Monte Carlo simulations to study stochastic network, with t he Gillespie algorithm discussed in some details. 4.2 Reaction system and discrete chemical master equation Molecular species and reactions. We assume a well-stirred system with a con- stant volume at a constant temperature. It contains nmolecular species X= {X1,\u00b7\u00b7\u00b7,Xn}, withXidenoting the label of the i-th molecular species. There aremchemical reactions R={R1,\u00b7\u00b7\u00b7,Rm}in the network. We denote the copy number of the i-th molecular species as xi. The combination of the copy numbers at timetis a vector of integers x(t) = (x1(t),\u00b7\u00b7\u00b7,xn(t))Nn. We call x(t)the microstate of the system at time t. The probability for the system to be in state x(t)is denoted as p(x,t). The setof all possible combinations of copy numbers, ={x(t)|t(0,)}, is the state space of the system. The collection of probabilities associated w ith each of the microstate in at timetis the probability landscape p(t). The time-evolving probability landscape p(t)provides a full description of the properties of a stochasti c molecular network [2,9,11,28,52]. Stoichiometry. A written as: c1(k)X1+c2(k)X2+\u00b7\u00b7\u00b7+cn(k)Xnc n(k)Xn. xj. dimension as the microstate, and skcan admit 0 entries if a molecular species does not participate in the reaction. As an example, the reaction A+2BC reduces the number of AandBby 1 and 2, respectively, and increase the number ofCby Its stoichiometry vector has cA= +1,cB= +2,cC=1, (+1,+2,2). If there are other molecular species, their coecients are all0for this reaction. By treating microscopic states of reactants expl icitly, linear and nonlinear reactions, such as synthesis, degradation, dimeric bindin g, and multimerization, can all be modeled as transitions between microstates. Reaction rate. The reaction rate Ak(xi,xj), namely, the transition probability per unit time from xitoxjdue to thek-th reaction that connects state xito state xjis determined by the intrinsic reaction rate constant rk, and the copy numbers of relevant reactants at the beginning of the reaction, whic h is given by l=1/parenleftbiggxl cl(k)/parenrightbigg , (4.2)REACTION MASTER EQUATION 105 assuming the convention/parenleftbig0 0/parenrightbig = 1. The intrinsic transition rate rkis determined by the physical properties of the molecules and the cell envi ronment [18], and the reaction rate A(xi,xj)only depends on the starting state xi. If thek-th reaction can lead the system from state xito state xj, we have Ak(xi,xj)>0, otherwise Ak(xi,xj) = 0. Although often only one reaction occurs to connect two microstates, in principle it is possible to ha ve more than one reaction connecting xitoxj. Therefore, we have the overall reaction rate that brings th e system from xitoxjas: A(xi,xj) =/summationdisplay RkRAk(xi,xj). Overall, we have the transition rate matrix: A={A(xi,xj)}, (4.3) where the diagonal elements are dened as: A(xi,xi) =/summationdisplay i/ne}ationslash=jA(xi,xj). (4.4) Discrete chemical master equation. The chemical master equation that governs the change of the probability landscape can be written as: dp(x,t) dt=/summationdisplay x/bracketleftig A(x,x)p(x,t)A(x,x)p(x,t)/bracketrightig . (4.5) Here the probability p(x,t)is continuous in time, but the states are discrete. We call this the discrete chemical master equation (dCME). In matrix form, it can be written as: dp(t) dt=Ap(t). (4.6) The dCME describes the gain and loss in probability associat ed with each mi- crostate due to chemical reactions. These chemical reactio ns can be regarded as jump processes upon rings of reactions, which bring the sys tem from one combina- tion of copy number of molecular species to a dierent combin ation of copy number of molecular species. The dCME fully accounts for the stocha stic jumps between states, regardless whether the copy numbers xiandxjare small or large. The over- all stochasticity due to small copy number events is therefo re fully described. It provides a fundamental framework to study stochastic molec ular networks [18,58]. However, it is challenging to study a realistic system using the dCME. Analytical solutions exists only for very simple cases, such as self-re gulating genes [23,60], or for small problems with strong assumptions of separation of reaction rates [28,52]. Exact numerical solution of the dCME is also dicult, as a non trivial number of species of small copy numbers may be involved. A major hurdle is the expected exponential increase in the size of the state space when the n umber of molecular species and their copy numbers increase, and when the networ k becomes complex.106 STOCHASTIC MOLECULAR NETWORKS 4.3 Direct solution of chemical master equation 4.3.1 State enumeration with nite buer The technique of optimally enumerating microstates for a gi ven initial condition now allows certain realistic systems to be studied using dCME, u nder the condition of nite buer [11]. Below we describe how microstates can be en umerated optimally. For a network with nmolecular species and mreactions, we calculate all mi- crostates that the network can reach starting from a given in itial condition, under thenite buer constraint. We use a buer of nite capacity to represent a re ser- voir of molecules, from which synthesis reactions generate new molecules, and to which degradation reactions deposit molecules removed fro m the network. Synthe- sis reaction is allowed to occur only if the buer capacity is not exhausted. This is necessary due to the limitation of computing resources. A s the microstate of a specic combination of copy numbers is x= (x1,...,x n), we addxn+1to denote the current buer capacity, namely, the number of net new mol ecules that can still be synthesized at this microstate. A synthesis reaction occ urs only if xn+1>0 when using the state enumeration algorithm. Under these conditions, the set of all possible microstates that can be reached from an initial condition constitute the state space of the system. The set of allowed transitions is T={tij}, in whichtijmaps the microstate xibefore the reaction to the microstate xjafter the reaction. The initial condition of the reaction system is now given as: x(0) = (x1(0),x2(0),...,x n(0),xn+1(0)), wherexi(0)is the initial copy number i-th at time t= 0, =Bis the predened buer capacity. The algorithm enumerating state space is summarized as Algorithm 4.3.1. After initialization, it starts with the given initial micr ostatex(0). Each reaction is than examined in turn to determine if this reaction can occ ur for the current microstate. If so, and if the buer is not used up, the state th at this reaction leads to is generated. If the newly generated state was never encou ntered before, we declare it as a new state and add it to our collection of states for the state space. We repeat this process for all new states, with the aid of a sta ck data structure. This process terminates when all new states are exhausted [1 1]. Under the nite buer constraint, the time complexity of thi s algorithm is opti- mal. Since only unseen state will be pushed onto the stack, ev ery state is pushed and popped at most once, and each state will be generated/vis ited at most twice before it is popped from the stack. As access to each state and to push/pop opera- tions takeO(1)time, the total time required for the stack operations is O(||). As the algorithm examines each of the reactions for each reache d state, the complex- ity of total time required is O(m||), wheremis usually a modest constant ( e.g., <50). Based on the same argument, it is also easy to see that the algorithm is optimal in storage, as only valid states and valid transitio ns are recorded. Using this algorithm, all states reachable from an initial condit ion within the nite buer constraint will be accounted for, and no irrelevant states w ill be included. Further- more, all possible transitions will be recorded, and no infe asible transitions will be attempted [11]. With this optimal method for enumerating the microstates of a nite system, numerical methods for solving large linear systems can be ap plied to solve theDIRECT SOLUTION OF CHEMICAL MASTER EQUATION capacity: x(n+1)(0)B; generates uknew molecules then xn+1xn+1uk ifxn+10then Generate state xjthat is reached by following reaction Rkfromxi; StateGeneratedTRUE end if else ifreactionRkis a degradation reaction and breaks down ukmolecules then xn+1xn+1+uk end if Generate state xjthat is reached by following reaction Rkfromxi; if end if end for end while Assign all diagonal elements of Ausing Eqn (4.2). Output,TandA={ai,j}. dCME equation. Very realistic systems can now be directly st udied, such as the decision network of phage lambda [9,11]. 4.3.2 Generalization and Multi-Buer dCME method. Reaction rates in a network can vary greatly: many steps of fa st reactions can occur within a given time period, while only a few steps of slow reac tions can occur in the same time period. The eciency of state enumeration can b e greatly improved when memory allocation is optimized based on dierent behav ior of these reactions.108 STOCHASTIC MOLECULAR NETWORKS The nite buer method can be further extended for accurate s olution of the chemical master equation [10]. A reaction network can be dec omposed into com- ponents of birth and death processes, which are the only reac tions that can add or remove molecules from the system. If we regard reactions as a set of vertices V, and a pair of reactions RiandRjare connected by an edge eijif they share either reactant(s) or product(s), we can then construct an undirec ted reaction graph GR. It can be decomposed into unumber of disjoint independent reaction components {Hi}:GR=/uniontextu i=1Hi, withE(Hi)E(Hj) =fori\\e}io\\slsh=j. We focus on those independent Hjs, called independent Birth-Death (iBD) com- ponents{HiBD j}, which contain at least one synthesis reaction. The multi-b uer algorithm for state enumeration is a generalization of the nite-buer algorithm, in which each iBD is equipped with its own buer queue. This le ads to improved eciency and increases size reduction in enumerated state s pace. Details can be found in reference discussing the Acme method [10]. 4.3.3 Calculation of steady state probability landscape We can obtain a Markovian state transition matrix Mfrom the reaction rate matrix A:M=I+A\u00b7t[26], where Iis the identity matrix, and tis the time increment that satises t <min{1/A0(xi)}. The steady state probability landscape over the microstates, namely, the probability distribution fun ctionp(t=)of the microstates at time t=can be obtained by solving the system of equations: p() =Mp(). These linear equations can be solved using iterative solver s such as the simple Jacobi algorithm or more advanced algorithms. A GPU-based algorit hm solving such large linear systems can lead to speed up of 30times [37]. 4.3.4 Calculation of dynamically evolving probability lan dscape The solution to the dCME dp(t) dt=Ap(t) can be written in the form of exponential: p(t) =eAtp(0), of the dynamically evolving probability lands capep(t)below. 4.3.5 Methods for state space truncation for simplication For large systems, the dCME can be solved numerically if the d imension of the state space can be reduced. This can be achieved by projecting the h igh dimensional state space to a lower dimensional nite space. Krylov subspace method. The rate matrix Ahas a very large dimension but is sparse. This is because a microstate will have mreactions leading to mDIRECT SOLUTION OF CHEMICAL MASTER EQUATION 109 dierent microstates. One can convert the costly problem of exponentiating a large sparse matrix to that of exponentiating a small dense matrix . This can be achieved by projecting the original matrix Ato the Krylov subspace Kk, which is easy to compute [36]: Km(At,(0))Span{(0),\u00b7\u00b7\u00b7,(At)d1(0)}. (4.8) The Krylov subspace used is of a very small dimension of d= 3060, although the resulting matrix is dense. Denoting ||\u00b7||2as the 2-norm of a vector or matrix, the approximation then becomes p(t)||p(0)||2Vd+1exp/parenleftbig Hd+1t/parenrightbig e1, wheree1is the rst unit basis vector, Vd+1is formed by the orthonormal basis of the Krylov subspace, and Hd+1the upper Heisenberg both can be from an Arnoldi algorithm [15]. The error is bounde d by O(edt||A||2(t||A||2/d)d). One only needs to compute explicitly exp/parenleftbig Hd+1t/parenrightbig . This is a much simpler problem asdis much smaller. A special form of the Pad\u00e9 rational of polyno mials instead of Taylor expansion can be used to avoid numerical instabili ty, which arises when summing terms with The Expokit software an excellent implementation of t he Krylov subspace method for computing matrix exponential [54]. This approac h has been shown to be very eective in studying large dynamic system ( n= 8.0\u00d7105) such as protein folding [26], macromole cular assembly of GroEL- GroES [9] . The Krylov subspace method concurrently evaluate the matri x exponential. The overall scheme can be expressed as: p(t)exp(TA)...exp(0A)p(0), witht=/summationtextK i=0i, in which the evaluation is from right to left. Here {i}are the sizes of time steps, and Tis the total number of time steps [36]. MacNamara et al. further extended the Krylov subspace method by splitting the rate matrix A. In some case, one can divide the states into the \"fast partit ion\" and the \"slow partition\" [6]. Here the condition is that two s tates belong to the same subset of the fast partition if and only if one can be reac hed from the other via a sequence of nite fast reactions [6]. Correspondingly , the matrix can be split into two: A=Af+As, whereAfcorresponds to the fast CME, and Ascorresponds to the slow CME. We have: dpf(t) dt=Afpf(t)110 STOCHASTIC MOLECULAR NETWORKS and dps(dt) t=Asps(t). With this deliberate separation, both AfandAsshould maintain the important property of being innitesimal generators of continuous ti me Markov processes by themselves [6]. With more elaborated splitting scheme for a ggregation of Markov processes, the Krylov subspace projection method have shown to be compu- tationally very ecient [36]. Finite State Projection. When the state space is too large and enumeration is no longer feasible, another approach is simply including only a subset of the original microstates [43]. Munsky and Khammash made two insightful o bservations. Denote two sets of indices of the microstates being chosen as J1andJ2, and assume J1J2. The reduced rate matrix obtained by selecting states in J1andJ2areAJ1andAJ2, respectively. The rst observation is: [eAJ2]J1eAJ10. (4.9) This assures that [eAJ2t]J1p(xJ1,0)(eAJ1t)p(xJ1,0) This inequality implies that by increasing the size of the se lected subset of states, the approximation improves monotonically. The second obse rvation is, if one ob- tains a reduced state space by selecting states contained in the index set J, and if 1TetAJp(xJ,0)1for>0, then: etAJp(xJ,0)p(xJ,t)etAJp(xJ,0)+1 (4.10) That is, starting with the initial probability of the reduce d vector p(xJ,0), we can compute the probability vector in the reduced space etAJp(xJ,0)at timetusing the reduced rate matrix AJ. If the inner-product of this vector with 1is no less than1, the dierence of this vector from the projected true vector p(xJ,t)of the true probability p(x,t)is also no more than 1. This inequality guarantees that the approximation obtained with reduced state space will ne ver exceed the actual solution, and its error is bounded by [43]. These key observations led to the Finite State Project algor ithm, which itera- tively adds new states to an initial reduced state space, unt il the approximation error is within a prescribed bound [43]. The original Finite State Projection method was further extended [42], and it was recommended that the in itial non-sparse prob- ability vector p(x,0)should be determined by running a few steps of stochastic simulation discussed in a later section. However, there are no known general strategy as to what state s to add to a nite projection to most eectively improve the approximation ac curacy. Furthermore, as an absorption state is introduced to account for all microst ates not included in the reduced state space in calculation, the nite state project ion method is not appro- priate for computing the steady state probabilistic landsc ape, as the approximation of the absorption state will lead to errors that increases ra pidly with time.QUANTIFYING AND CONTROLLING ERRORS FROM STATE SPACE TRUNCA TION111 4.4 Quantifying and controlling errors from state space tru ncation Analysis based on the multi-buer algorithm for state enume ration enables the establishment of upper bounds of errors resulting from stat e space truncation, which is inevitable when solving the discrete CME of a complex netw ork. For ease of discussion, we examine networks with only one iBD component and therefore one buer queue. We can factor the enumerated states intoN+1groups of subsets by the net number of tokens of the buer queue in use: {G0,G1,\u00b7\u00b7\u00b7,GN}. We can further construct a permuted transition rate all transitions from states in factored groupGito states in factored group Gj. Furthermore, we can construct an aggregated continuous-ti me Markov process with a rate matrix B(N+1)\u00d7(N+1)on the partition{G0,G1,\u00b7\u00b7\u00b7,GN}. The steady state probability of the aggregated Markov process gives th e same steady state probability distribution as that given by the original matr ixAon the partitioned groups{Gs}. rate (N) ifor the groupGiand the aggregated degradation rate (N) i+1for the groupGi+1at the steady state two constants: (N) i /BDTAT i,i+1(Gi)/BDT(Gi)and(N) i+1 /BDTAT i+1,i(Gi+1)/BDT(Gi+1), (4.13) in which vector (Gi)and(Gi+1)are the steady state probability vector over the permuted microstates in the group GiandGi+1, respectively [10]. This is equivalent to transforming the transition rate matr ixAin Equation (4.11) toBby substituting each block sub-matrix Ai,i+1of synthesis reactions with the corresponding aggregated synthesis rate (N) i, and each block Ai+1,iof degradation reactions with the aggregated degradation rate (N) i+1, respectively. The steady state112 STOCHASTIC MOLECULAR NETWORKS probability (N) iof the aggregated state Githen can be written as (N) N=N1/producttext (4.14) based on well-known analytical solution to the steady state probability distribution of simple birth-death processes [56]. The error due to state truncation asymptoti- cally obey the following inequality when innity: Err(N)() N () N+1 1() N () N+1\u00b7(N) N. (4.15) We can construct bounds to the right-hand side of Equation (4 .15). The maxi- mum aggregated synthesis rates from the block aggregated from the block sub-matrix Ai+1,i matrix A is dened. An upper-bound Ncan Equations (4.16) and (4.17), an a symptotic error bound (4.19) This can be estimated a priori , without costly trial solutions to the dCME. Gener- alization to truncating state space to all buer queues can b e found in [10].APPROXIMATING DISCRETE CHEMICAL MASTER EQUATION 113 Remark. Studying the behavior of a stochastic network is challengin g. Even with a correctly constructed stochastic network, it is generall y not known if an accurate solution to the dCME has been found. For example, it is dicul t to know if all major probabilistic peaks have been identied or important ones with signicant probability mass in the usually high dimensional space are u ndetected. It is also dif- cult to know if the locations of identied probabilistic pe ak are correctly mapped. One also does not know if a computed probabilistic landscape s is overall erroneous and how such errors can be quantied. Furthermore, the best p ossible accuracy one can achieve with nite computing resources is generally unknown. We also do not know what computing resource is required so solutions wi th errors within a predened tolerance can be obtained. The development of the ory and methods for error estimations such as those described here can help to re solve these important issues. 4.5 Approximating discrete chemical master equation There exists a large body of work in formulating stochastic d ierential equations to study reaction networks. Below we discuss several well know n approaches, which can be viewed as approximations of varying degrees to the dCM E. 4.5.1 Continuous chemical master equation If we treat the state space as continuous, that is, if we assum e the amount of a molecular species xiis measured by a real value (such as concentration) instead o f an integer (copy numbers), the vector x(t)becomes a real-valued vector x(t)Rn. We then have the continuous chemical master equation, which is equivalent to the dCME of Equation (4.5): p(x,t) t=/integraldisplay x[A(x,x)p(x,t)A(x,x)p(x,t)]dx, (4.20) where the kernel A(x,x)represents the transition probability function per unit time from xtox. We call this the continuous Chemical Master Equation (cCME ). The cCME in this form is equivalent to the Chapman-Kolmogoro v equation fre- quently used to describe continuous Markov processes [27]. The continuous state space version of the CME requires stron g assumptions. It is only appropriate if one can assume that the dierence in the a mount of molecules in neighboring states is innitesimally small, which is valid only if the copy number of the molecular species in the system is much larger than 1, and also much larger than the changes in the numbers of molecules when a reaction occur s. cCME therefore cannot be used when the total amount of molecules involved is very small, for example, in systems of a single or a handful of particles. In t hese cases, dCME should oach one can further approximate the cC ME with various formulations of Stochastic Dierential Equations (SDEs). One such formulation114 STOCHASTIC MOLECULAR NETWORKS Fokker-Planck equation. Similar to the cCME, it descr ibes the evolution of probability landscape of the system, but with the transitio n kernel in the CME replaced by a dierential operator of second order. We follow the disposition of van Kampen [59] and briefly descr ibe how the Fokker-Planck equation is related to the cCME, with discuss ion on additional as- sumptions and approximations involved beyond those necess ary for the cCME. 4.5.2.1 Assumptions of Fokker-Planck equation. To approximate the cCME, the rst assumption we make is that the jumps between states desc ribed in Equa- tion (4.5) must be small, namely, the \"before\" and the \"after \" states are in close neighborhood: ||xjxi||<, whereRis innitesimally small. Second, the transition probabili ty A(x,y)A(x,y),if||xx||and||yy||. Third, the probability p(x,t)must also vary slowly: p(x,t)p(x,t),if|xx|. As a consequence of these assumptions, the transition kerne lA(x,y)is dierentiable to a high order. It is clear that the cCME cannot be used to stud y discrete jump processes. With these assumptions, the rst term in Equation (4.20), wh ere the full detail of the transition kernel A(x,x)is needed, can be approximated. The goal is to replace A(x,x)with its Taylor expansion centered around x. For ease of illustration, we express transitions as a function of the starting point and t he jump. We rst reparameterize A(x,x)asA(x;s), wheres=xx. Similarly, for A(x,x)in the second term, we have A(x,x) =A(x;s). Equation around xusing MASTER EQUATION 115 Putting it back to Equation (4.21), and approximating by dro pping terms higher than second order, we is that of the Langevin equation. When t he macroscopic behavior of a reaction system can be determined, a general ap proach to study its stochastic behavior is to combine a diusion term descri bing the macroscopic behavior with a separate noise term describing the stochast ic fluctuations of the system. Random fluctuations in the copy numbers of molecules occur be cause of the random jumps due to spontaneous rings of reactions. Such re actions will introduce changes in the copy numbers of molecular species, e.g., by the amount of sk for each ring of the k-th reaction. Assuming that the jump is small, namely, x(t+t) =x(t)skx(t), and reaction Rkoccurs during a small time interval dtatt+t. These assumptions would result in unchanged reaction rate : Ak(x(t+t))Ak(x(t)) =rkn/productdisplay l=1/parenleftbiggxl clk/parenrightbigg (4.25) With these assumptions, the vector of the amount of molecula r species x(t+t) at timet+tcan be written as: x(t+t) =x(t)/summationdisplay RkRnk(x,t)\u00b7sk, assuming several reactions may occur. Here nk(x,t)is the number of reaction Rkoccurs during the period t. Under the assumption x(t+t)x(t), the copy numbers of molecular species for calculating reaction rate using Equation (4.25) do not change during t, therefore, the reaction rates also do not change during t. With this assumption, all reactions occurring during tcan be considered independent of each other. This assumption is valid only if the copy numbers in x(t)are large, so the sto- ichiometry coecients ciforming the jump vector skare all comparatively small. Such an assumption breaks down when the copy number of molecu lar species is not116 STOCHASTIC MOLECULAR NETWORKS signicantly larger than the stoichiometry coecients, an d therefore this approxi- mation cannot be employed to describe systems of a handful of particles. We now introduce further approximations. A reasonable mode l for the random variablenk(x,t)is that of a Poisson process: nkP(k), wherek=Ak(x(t))\u00b7 t. With the additional assumption that tis suciently long such that a large number (1) of reactions occur during t, the Poisson distribution for the number of spontaneous reactions can be approximated by a Gaussian d istribution [17]. Note this assumption is contradictory to the earlier assumption of small jumps (changes inxis small). Approximating the Poisson distribution by a Gaus sian distribution will be accurate when kis large, e.g.,k>1,000. With this, we now have nkN(\u00b5,2), with\u00b5=2=k, or alternatively, nkk+1/2 kN(0,1) = Ak(x(t))\u00b7t+[Ak(x(t)\u00b7t]1/2N(0,1). Under these assumptions, the fluctuations of the amount of mo lecules follow m independent Gaussian processes, one for each reaction: x(t+t) =x(t)/summationdisplay RkRAk(x(t))\u00b7t\u00b7sk/summationdisplay referen ce [17]. 4.5.4 Other approximations are alternatives to the Fokker-Planck and Langevin ap proaches to account for the stochasticity dierently. One can replace the dius ion term with a term for the variance-covariance between pairs of the molecular rea ctions [20], or between concentrations of dierent molecular species [57], withou t the explicit inclusion of a random process. Here the magnitude of the covariance is det ermined by the Hes- sian matrix of the second-order partial derivative of the pr opensity functions of the reactions [20,57]. This inclusion of the second moments to a ccount for the stochas- ticity is the basis of the stochastic kinetic model [20] and t he mass fluctuation kinetic model (MFK) [57]. These approaches can model reacti ons involving one or two molecules well [20,57]. They are similar in spirit to the Fokker-Planck equa- tion model by including a second moment term for better appro ximation, but are fundamentally dierent as they are macroscopic in nature an d do not involve any random processes. Yet another approach is to directly model explicitly the stochas- tic coupling of the macroscopic concentrations of molecula r species, in addition to the Gaussian noise of the original Langevin model [12].STOCHASTIC SIMULATION 117 4.6 Stochastic simulation A widely used method to study stochastic networks is to carry out Monte Carlo simulations. By following the trajectories of reactions, o ne can gather statistics of reaction events at dierent time to gain understanding of th e network behavior [18, 41]. We discuss the underlying algorithm, called the stochastic simulation algorithm (SSA) , which is also known as the Gillespie algorithm . 4.6.1 Reaction probability We denote the probability that after the last reaction at t, the rst reaction, which happens to be the k-th reaction, occurs during dtat an innitesimally small time intervaldtaftert+tto be: p[x(t+t),t,k|x(t)]dt. If we divide the time interval tintoHsubintervals, and assume that the occurrence of reactions following a Poisson process, the pr obability that none of themreactions have occurred during the time prior to the end of a s mall time interval= t/His: m/productdisplay k=1[1Ak(x(t))]m/summationdisplay k=1[1Ak(x(t))]. As the probability of no reactions for each of the Hintervals is the same, no reactions have occurred during tis: lim Hm/summationdisplay k=1[1Ak(x(t))]H=eA(x(t))t. As the instantaneous state we have: p[x(t+t),t,k|x(t)] =Ak[x(t+t)]eA(x(t))tdt. 4.6.2 Reaction trajectory Let the state the system is in at time tto bex(t). After a time interval t, reactionkoccurs at an innitesimally small time interval dtatt+ t, and the system is brought to the state x(t+ t). We can observe the trajectory of a sequence of such reactions. Starting from state x(t0)at timet0, after a series of time intervals (t0,t1,\u00b7\u00b7\u00b7,tT1), the system reaches the state x(tT), after traversing the sequence of states (x(t0),x(t1),\u00b7\u00b7\u00b7,x(tT1)), with reactions k0,k1,\u00b7\u00b7\u00b7,kT1 occurring along the way. Let (t1,t2,\u00b7\u00b7\u00b7,tT)be the sequence of time points when a reaction occurs. The trajectory of reactions can be denoted as: [x(t0);x(t1),k0;\u00b7\u00b7\u00b7;x(tT1),kT2;x(tT),kT1] Alternatively, we can denote the time intervals by its incre ments(t0,\u00b7\u00b7\u00b7,tT1).118 STOCHASTIC MOLECULAR NETWORKS 4.6.3 Probability of reaction trajectory Assuming a Markovian process, namely, future reactions dep ends only on the cur- rent state but not on any past state, the probability associa ted with a time trajec- tory is: [x(t0);x(t1),k1;\u00b7\u00b7\u00b7;x(tT1),kT1;x(tT),kT] = [x(t1),t0,k0|x(t0)].[x(t2),t1,k1|x(t1)]\u00b7\u00b7\u00b7[x(tT),tT1,kT1|x(tT1)] (4.28) In principle, the probability of starting from state x(t0)and reaching state x(tT) can then be obtained by integrating over all possible paths: [x(tT)|x(t0)] =/summationdisplay (t1,\u00b7\u00b7\u00b7,tT1),(k1,\u00b7\u00b7\u00b7,kT)[x(t0);x(t1),k1;\u00b7\u00b7\u00b7;x(tT1),kT1;x(tT),kT]. 4.6.4 Stochastic simulation algorithm If generate many independent samples of reaction traj ectories that follow a proper probabilistic model starting from the same initial condition ( e.g., Equa- tion (4.28)), we can collect the reaction trajectories at th e same sampling time intervals. These properly sampled trajectories can then be used to study the be- havior of the stochastic network. The Stochastic Simulation Algorithm (SSA) or the Gillespie algorithm was de- signed to perform such simulations [18]. It summarized in Algorithm of sampling time (t1,t2,\u00b7\u00b7\u00b7,tT) t0 whilet<tTorA(x(t))\\e}io\\slsh=0do Generate a pair of random variables the occurred reaction k if tt+t end while 4.6.4.1 Generating random variables (t,k)A key component of the Gillespie algorithm is to generate a pair of random variables (t,k), the time interval t until the next reaction occurs, and the specic k-th reaction as the reaction that actually occurred next. We have (t,k) =1(t)\u00b72(k|t),STOCHASTIC SIMULATION 119 where1(t)is the probability that the next reaction, regardless which specic one, will occur at t+t+dt, and2(k|t)is the probability that the next reaction will be thek-th reaction. As 1(t) =/summationtext i(i,t), where(i,t)is the t+t+dt, we have:2(k|t) =(k,t)/summationtext i(i,t). As we we have: 1(t) =A(x(t))eA(x(t))t,and2(k|t) =Ak(x(t)) A(x(t)) That is, if we can generate a random variable tfollowing1(t), and another random integer kaccording to 2(k|t), the resulting pair (t,k)will follow the desired distribution (t,k). Assume we can generate a random number rfollowing the uniform distribution rU[0,1]. A general approach to obtain a random variable xthat follows a distri- butionFis to calculate the transformation of rthrough the t=1 A(x(t))ln1 r1,wherer1U[0,1]. To sample the next reaction k, we can generate again rst a uniformly distributed random variable r2U[0,1]. We can take the k-th reaction such that k1/summationdisplay i=1Ai(x(ti))<r2A(x(t))k/summationdisplay i=1Ai(x(ti)). Another approach to generate a pair of random variable (t,k)is to rst calcu- late the probability at time t+tfor a reaction ito occur during an innitesimally small time interval at t+t+dt, assuming that there were no changes between x(t) andx(t+t), namely, there is no occurrence of other reactions. We can ge nerate a tentative reaction time tlfor reaction las: tl=1 Al(x(t)ln1 rl,whererlU[0,1]. From this set of pairs of random variables (l,tl), we select the pair of random variables of the shortest time t, at which the next reaction kwould occur: t= min{tl} and k= arglmin{tl}. as the next reaction k. Remark. There are a number of issues in carrying out studies using sto chastic sim- ulation, as adequate sampling is challenging when the netwo rk becomes complex. There is no general guarantee that simulation can provide a f ull account of the net- work stochasticity, as it is dicult to determine whether si mulations are extensive enough for accurate statistics. It is also dicult to determ ine whether adequate120 STOCHASTIC MOLECULAR NETWORKS sampling has been achieved for individual trajectory. In ad dition, it is often di- cult to characterize rare events that may be biologically im portant, as simulations follow high probability paths. Much recent work has been foc used on improving SSA, for example, by introducing data structure so the gener ation of the two ran- dom variables of and reaction kis more ecient [16]. In addition, an approach to speed up SSA is to nd the best time step such that the copy numbers of the molecular species, hence the reaction rates, do not change m uch, so the simulation can leap forward with large time step [7]. Recent interests i n introducing bias in selection of the next reaction, and in altering the reaction rate showed promise in improved sampling of rare events [14,31,51]. Adaptively ad justed bias of reactions based on look-ahead strategy showed that barrier-crossing can be engineered for ecient and accurate sampling of rare events [8]. 4.7 Applications We now discuss how stochastic networks can be modeled by dire ctly solving the underlying chemical master equation using two biological e xamples. Figure 4.1 The stochastic network of a toggle switch. a. The topology of the network and the reaction rates. b. The corresponding chemical reactions of the 8 stochastic processes.nA0 50 100 nB0 50 100Probability 0.0000.0010.0020.0030.0040.005 off/off on/onon/off off/on Figure 4.2 The steady state probability landscape of a toggle switch. A toggle switch has four dierent states, corresponding to dierent binding state of genes A and B. At the condition of small value of u/b, the o/o state is strongly suppressed for any value of u/d, and the system exhibits bi-stability.APPLICATIONS 121 4.7.1 Probability landscape of a stochastic toggle switch Toggle switch is one of the smallest genetic networks that ca n present bistabil- ity [52]. It is a small network consisting of two genes, say, A and B. Single copies of gene A and gene B in the chromosome each encode a protein pro duct. The pro- tein product of each gene represses the other gene: When two p rotein monomers associate, they bind to the appropriate operator site and re press the transcription of the other gene. The molecular species and the network topology of a toggle sw itch model are shown in Fig. 4.1a. The stochastic processes include: the sy nthesis and degradation of proteins A and B, with reaction constants denoted as sandd, respectively; the binding and unbinding of the operator site of one gene by the p rotein products of the other gene at rate bandu, respectively (Fig. 4.1 b). The binding states of the two operator sites are \"on-on/unbound-unbound\", \"on -o/unbound-bound\", \"o-on/bound-unbound\", and \"o-o/bound-bound\". The syn thesis rates of both proteins A and B depend on the binding state of the operator si tes [11,52]. Even for this simple network, no general exact solutions are know n. The exact probably landscape of the toggle switch model at st eady state can be computed numerically. We can choose the parameter values as s= 100d,u=d/10, andb=d/100,000in units of degradation rate d, and set the initial condition to: 1 copy of unbound gene A, 1 copy of unbound gene B, 0 copies o f bound gene A and bound gene B, 0 copies of their protein products, an d the buer size for the total protein A and protein B combined that can be synt hesized of 300. We then enumerate the state space of the toggle switch using t he nite buer algorithm. The steady state probability landscape of the ne twork can then be computed (Fig. 4.2). It is clear that a toggle switch has four dierent states, corresponding to the \"on/on\", \"on/o\", \"o/on\" and \"o/o\" states. With these chosen parameters, the toggle/switch exhibits clear bi-st ability, namely, it has high probabilities for the \"on/o\" and \"o/on\" states, but has a l ow probability for the \"on/on\" state. The \"o/o\" state is severely suppressed [11 ]. 4.7.2 Epigenetic decision network of cellular fate in phage lambda Bacteriophage lambda is a virus that infects E. coli cells (Fig. 4.3). Of central importance is the molecular circuitry that controls phage l ambda to choose between two productive modes of development, namely, the lysogenic phase and the lytic phase (Fig. 4.3 A). In the lysogenic phase, phage lambda repr esses its developmental function, integrates its DNA into the chromosome of the host E. coli bacterium, and is replicated in cell cycles for potentially many genera tions. When threatening DNA damage occurs, for example, when UV irradiation increas es, phage lambda switches from the epigenetic state of lysogeny to the lytic p hase and undergoes massive replications in a single cell cycle, releases 50-10 0 progeny phages upon lysis of the E. coli cell. This switching process is called prophage induction [49]. The molecular network that controls the choice between thes e two dierent phys- iological states has been studied extensively [1,4,5,24,2 5,34,48,49,49,53]. All of the major molecular components of the network have been identi ed, binding constants and reaction rates characterized, and there is a good experi mental understanding of the general mechanism of the molecular switch [49]. Theor etical studies have122 STOCHASTIC MOLECULAR NETWORKS Figure 4.3 Dierent selection of cell fate of E. coliinfected by phage lambda and a model of the epigenetic circuit for lysogeny maintenance. A. The lysogenic and lytic phases of phage lambda. B. A simplied model of the epigenetic switch for lysogeny mai ntenance. also contributed to the illumination of the central role of s tochasticity [4] and the stability of lysogen against spontaneous switching [5,63] . To study how lysogeny is maintained and how it transitions to the lytic state, we can use a simplied stochastic model for the molecular reg ulatory network that controls the epigenetic switch in phage lambda (Fig. 4.3 b) [ 9]. Using a total of 54 biochemical reactions involving 13 molecular species, thi s model explicitly includes key components, essential reactions, and cooperativities of the phage lambda deci- sion circuitry. The eects of UV irradiation can be modeled b y increasing the CI degradation rates kddue to the response of the SOS system. This epigenetic net- work model can reach around 1.7 million microstates. The ste ady state probability associated with each of these microstates can be computed fr om dCME after nite buer algorithm [9] . Fig. 4.4 (row 1) shows the probability landscape of the phage lamed at ve dierent UV irradiation conditions, each modeled with a di erent CI degradation ratekd. Although there are 13 molecular species, we can project the landscape to the 2-dimensional subspace and record the total copy number s of CI 2dimer and Cro2dimer molecules. With a high copy number of CI 2repressor, the lysogenic phase of the phage lambda is maintained, whereas a high copy n umber of Cro 2 protein signies the lytic phase [25]. A clear picture of the landscape in lysogeny,APPLICATIONS 123 Figure 4.4 The probability landscape of the epigenetic circuits of lys ogeny maintenance in phage lambda. (Row 1) For wild type phage lambda, at the CI d egradation rate of kd= 7.0\u00d7104/s, probability landscape centers at locations with high co py numbers of CI2and close to 0 copy of Cro 2. This corresponds to the lysogenic phase of phage lambda. Whenkdincreases from kd= 1.8\u00d7103/s to2.2\u00d7103/s, the peak located at lysogenic phase gradually diminishes, whereas the peak located at lyt ic phase gradually increases. At aboutkd= 2.0\u00d7103/s, phage lambda has about equal probability to be in either l ysogenic or lytic phase. When CI is degraded at a faster rate of kd= 3.6\u00d7103/s, the probability landscape centers at locations where there are higher copy n umbers of Cro dimer and close to 0 copy of CI. This corresponds to the lytic phase of phage la mbda. (Row 2) When all cooperativities are removed from the model, lysogeny canno t be achieved. (Row 3) When only the cooperativity of G12is restored, wild-type behavior is largely restored. (Row 4 ) When all other cooperativities except G12are restored, lysogeny still cannot be achieved. at the start of transition, during mid-transition, at the en d of transition, and in lysis can be seen. The stochastic network models can also be used to aid in under standing of the mechanism of how the decision network works. It is well known that cooperativity among proteins play important roles. After removing all coo perativities between neighboring proteins in the model, phage lambda cannot ente r lysogeny regardless the dosage of the UV irradiation (Fig. 4.4, row 2). However, w hen the cooperativity124 STOCHASTIC MOLECULAR NETWORKS Figure 4.5 Instability,shallowthreshold,andswitchingineciency ofthenetworkagainst fluctuation in UV irradiation in mutant phage lambda, in whic h the wild type operators are mutated (3'-2-3'), or their locations permuted (1-2-1, 3-2 -3, and Wild type phage with operator site OR3-OR2-OR1 (3-2-1) maintains a st able level of CI 2, but respond to further UV irradiation after a set point and switches to ly tic phage eciently. In contrast, mutant 1-2-1, where an OR3 is replaced by an OR1, and mutant 3' -2-3' (slighted mutated OR3 replacing original OR1 and OR3) do not maintain a stable l evel of CI 2. They are leaky and responds gradually to graded changes in kd. Their thresholds and that of mutant 3-2-3 for lytic transition are much shallower. Mutant 1-2-3 does n ot maintain a sucient amount of CI2, and therefore cannot maintain lysogeny. G12between two CI dimer proteins when binding to operator sites are restored, the lysogeny is largely restored (Fig. 4.4, row 3). In contra st, if all other coopera- tivities are restored except G12, phage lambda still lacks the ability to enter the lysogeny phase (Fig. 4.4, row 4). These calculations sugges t that the cooperativity G12plays key roles in maintaining the properties of the network . An important property of biological stochastic network is i ts robustness against changes in the molecular components of the epigenetic netwo rk. Experimental stud- ies showed that when the ordering of operator sites are chang ed, mutants of phage lambda all have functional epigenetic circuits, but have ma rkedly dierent toler- ance to UV irradiation. Calculations from solving the dCME m odel showed that the wild-type lysogen has a high threshold towards lysis, an d is overall insensitive to fluctuation of UV dosage, if it is below certain threshold ( Fig. 4.5). That is, the switching network of phage lambda is very stable and is st rongly buered with a high threshold against fluctuations in CI degradation rate due to environmental changes in UV irradiation. This high threshold against envi ronmental fluctuations is important for the self-perpetuating nature of the epigen etic state of E. coli cells, allowing lysogeny to be passed on to its ospring. Once the de gradation rate of CI reaches a threshold, phage lambda switches very eciently t o the lytic phase, and this eciency is not built at the expense of stability agains t random fluctuation. Wild type phage lambda therefore can integrate signaling in the form of dierent CI degradation rates and can distinguish a true signal above the high threshold from random noise fluctuating below this threshold. In contrast, all mutant variants exhibit the behavior of a ha ir trigger, and require much less UV irradiation for the onset of lysis induction (Fi g. 4.5). In addition, they are \"leaky\", and respond in a graded fashion towards inc rease UV irradiation, instead of the well-behaved threshold behavior observed in wild type phage lambda. In the case of mutant 1-2-3, the mutant phage lambda cannot en ter lysogenic state. These results are in full agreement with experimental ndin gs [9,34].DISCUSSIONS AND SUMMARY 125 4.8 Discussions and summary In this chapter, we have discussed the signicance of the che mical master equation (CME) as a theoretical framework for modeling nonlinear, bi ochemical reaction networks. This formulation provides a foundation to study s tochastic phenomena in biological networks. Its role is analogous to that of the S chr\u00f6dinger equation in quantum mechanics [50]. Developing computational solut ions to the CME has important implications, just as the development of computa tional techniques for solving the Schr\u00f6dinger equation for systems with many atom s is [29, 30]. By computing the time-evolving probability landscape of cell ular stochastic networks, we may gain understanding of the possible mechanisms of cell ular states, as well as the inheritable phenotypes with a distributive epigenetic code, in which the network architecture and its landscape dictate the physiological m etastases of the cell under dierent conditions [47,63]. Overall, studying the behavior of a stochastic network is ch allenging. and solving a given CME is a computationally challenging task. We have ou tlined several key diculties, as well as some of the progresses that have be en made so far. The nite buer algorithm allows direct numerical solution to the discrete CME, and can be applied to study stochasticity of systems with a ha ndful of particles, as well as larger networks arising from very realistic biolo gical problem, such as that of the lysogeny-lysis control circuit of the phage lamb da [9]. As an exact method, it can also be used to study model systems of nite siz e to gain insight into stochastic behavior of networks. The ability to comput e error due to state truncation a priori enables ability to ensure the correctness of the computatio nal solution to the dCME, as well as knowledge of its level of accu racy. Furthermore, it provide means to develop optimized strategies to minimize t runcation error when nite computing resources is given. The stochastic simulat ion algorithm oers the approach of studying the network through simula tions. The formulation of stochastic dierential equation such as the Langevin equ ation allows exploration of more complex stochastic systems, at the expense of less ri gorous assumptions and perhaps more errors. An important task is to integrate dierent stochastic metho ds for ecient com- putational solution of complex stochastic networks at larg e scale, with controlled accuracy. For example, one may apply the nite buer algorit hm to solve dCME directly for certain critical parts of the network, where ra re events need to be as- sessed very accurately. One may use Langevin stochastic equ ation to study other parts of the network where general stochastic behavior need s to be determined. In addition, one may also wish to apply the stochastic simulati on algorithm to certain parts of the network to probe their behavior. Further more, o ne may wish to apply ordinary dierential equation (ODE) models to study parts o f the system where copy numbers of molecules are large and there are little stoc hastic eects. A great challenge is to develop a general strategy so the best methods can be applied to specic parts of the network and the results integ rated to provide an overall picture of the stochastic dynamic behavior of the ne twork. It would be desirable that the resulting errors due to approximations o f varying degree are bounded within a tolerance level, while maintaining necess ary computing speed and resource requirement. A further challenge is to develop such hybrid methods to compute the overall spatio-temporal stochastic dynamic properties of dierent cellular consi deration of dierent spatial126 STOCHASTIC MOLECULAR NETWORKS distribution or gradient of molecules such as oxygen, nutri ent, morphogenes, and other signaling factors, all with stochasticity appropria tely considered. The complex nature of the stochastic dynamics arising from b iochemical net- works bears some resemblance to another complex system, nam ely, that of protein folding. Both have very large space of micro-states, and bot h can be modeled by transitions between micro-states using master equations [ 13,26,45]. However, these two systems dier in several important aspects. First, whil e protein folding can be modeled as a relaxation process towards the equilibrium s tate, biochemical net- works are intrinsically open, with synthesis and degradati on of molecules an integral part of the system, hence there are no equilibrium states. In stead, one frequently seeks to study the non-equilibrium steady state. Second, on ce the energy of a pro- tein conformation is known, the relative probability of its sequence adopting this conformation in the equilibrium state can be calculated fro m the Boltzmann dis- tribution, without the need of knowing all other possible co nformations and their associated probabilities. In contrast, it is not possible t o calculated the relative probability of a specic microstate of copy numbers a priori without solving the entire CME, as the probability distribution of network stat es do not generally fol- low any specic analytical forms, and there are no detailed b alance and there exists cyclic probability fluxes [33].REFERENCES 1. L.M. Anderson and H. Yang. DNA looping can enhance lysogen ic CI transcription in phage lambda. Proc Natl Acad Sci U S A , 105(15):5827-5832, Apr 2008. 2. P. Ao, C. Kown, and H. Qian. On the existence of potential la ndscape in the evolution of complex systems. Complexity , 12:19-27, 2007. 3. A. Arkin, J. Ross, and H.H. Stochastic kinetic lambda-infected Escheric coli cells. Genetics , 149(4):1633-1648, 1998. 4. Adam Arkin, John Ross, and Harley H. McAdams. Stochastic k , 149:1633-1648, 1998. 5. Erik Aurell, Stanley Brown, Johan Johanson, and Kim Snepp en. Stability puzzles in phage.Physical Review E , 65(5):051914, 2002. 6. Y. Cao, D.T. Gillespie, and L.R. Petzold. The slow-scale Phys , D.T. Gillespie, and L.R. Petzold. Ecient step siz e selection for the tau- leaping simulation method. J Chem Phys , 124(4):044109, Jan 2006. 8. Y. Cao and J. Liang. Adaptively biased sequential importa nce sampling for rare events in reaction networks with comparison with exact solu tions from nite buer dCME method. J Chem Phys , In press:x, 2013. 9. Y. Cao, H.M. Lu, and J. Liang. Probability landscape of her itable and robust epige- netic state of lysogeny in U S A , 107(43):18445- 18450, Oct 2010. 10. Y. Cao, A. Terebus, and J. Liang. Accurate chemical maste r equation solution with multi-nite buers for time-evolving and steady state prob ability landscapes and rst passage times. Submitted , 2015. Models and Algorithms for Biomolecules and Molecular Netwo rks, rst edition. By Bhaskar DasGupta and Jie Liang Copyright \u00a9 2015 John Wiley & S ons, Inc.127128 REFERENCES 11. Y. Cao and J. Liang. Optimal enumeration of state space of nitely buered stochastic molecular networks and exact computation of steady state la ndscape probability. BMC Systems Biology , 2:30, 2008. 12. Y. Cao and J. Liang. Nonlinear coupling for improved stoc hastic network model: A study of Schnakenberg model. Proceedings of 3rd Symposium on Optimization and Systems Biology (OSB) , 2009. 13. M. Cieplak, M. Henkel, J. Karbowski, and J. R. Banavar. Ma ster equation approach to protein folding and kinetic traps. Phys. Review Letters , 80:3654-3657, 1998. 14. B.J. Daigle, Jr., M.K. Roh, D.T. Gillespie, and L.R. Petz old. Automated estimation of rare event probabilities in biochemical systems. J Chem Phys , 134(4):044110, Jan 2011. 15. B. N. Datta. Numerical linear algebra and applications . Brooks/Cole Publishing Company, 1995. 16. M.A. Gibson and J. Bruck. Exact stochastic simulation of chemical systems with many species and many channels. J. Phys. Chem. , 105:1876-89, 2000. 17. D.. T. Gillespie. The chemical langevin equation. Journal of Chemical Physics , 113:297-306, 2000. 18. D.T. Gillespie. Exact stochastic simulation of coupled chemical reactions. Journal of Physical Chemistry , 81:2340-2361, 1977. 19. G.H Golub and C.F. Van Loan. Matrix computations . Johns Hopkins University Press, 1996. 20. J. Goutsias. Classical versus stochastic kinetics mode ling of biochemical reaction systems. Biophys J , 92(7):2350-65, 2007. 21. J. Hasty, J. Pradines, M. Dolnik, and J.J. Collins. Noise -based switches and ampliers for gene expression. Proc Natl Acad Sci U S A , 97(5):2075-80, 2000. 22. R. A. Horn and C. R. Johnson. Topics in Matrix Analysis . Cambridge University Press, 1991. 23. J.E. Hornos, D. Schultz, Soft Matter Phys , 72(5 Pt 1):051907, 2005. 24. F. Jacob and J. Monod. Genetic regulatory mechanisms in t he synthesis of proteins. J Mol Biol , 3:318-356, an ecient molecula r Nature , 294(5838):217-223, Nov 1981. 26. S. Kachalo, H.M. Lu, and J. Liang. Protein folding dynami cs via quantication of kinematic energy landscape. Phys , 96(5):058106, 2006. 27. S. Karlin and H.M. Taylor. A First Course in Stochastic Processes . Academic Press, 2nd edition, 1975. 28. K.Y. Kim and J. Wang. Potential energy landscape and robu stness of a Electronic Calculations for Solids and Molecule s: Theory and Computational Methods . Cambridge University Press, 2006. 30. W. Kohn and L.J. Sham. Self-consistent equations includ ing exchange and eects. Phys. 1965. 31. H. Kuwahara Mura. An ecient and exact stochastic s imulation method to analyze rare events in biochemical systems. J Chem Phys , 129(16):165101, Oct 2008.REFERENCES 129 32. M.D. Levin. Noise in gene expression as the source of non- genetic individuality in the chemotactic response of Escherichia coli. FEBS Lett , 550(1-3):135-138, 2003. 33. J. Liang and H. Qian. Computational cellular dynamics ba sed on the chemical mas- ter equation: A challenge for understanding complexity. J. Computer Sci. Tech. , 25(1):154-168, 2010. 34. J. W. Little, D. P. Shepley, and D. W. Wert. Robustness of a gene regulatory circuit. The EMBO Journal , 18(15):4299-4307, 1999. 35. H.-M. Lu and J. Liang. Perturbation-based markovian tra nsmission model for probing allosteric dynamics Comput Burrage, and R.B. Sidje. S to the stochastic simu- master equation. J , 129(9):095105, 2008. 37. M. Maggioni, T. Berger-Wolf, and J. Liang. GPU-based ste ady-state solution of the chemical master equation. In 12th IEEE International Workshop on High Perfor- mance Computational in gene Natl Acad D. an d A. van Oudenaarden. Predicting stochastic gene expression dynamics in single c ells.Proc Natl Acad Sci U S A, 103(19):7304-7309, 2006. 40. Y. Morishita and K. Aihara. Noise-reduction through int eraction in gene expression and biochemical reaction processes. J Theor Biol , 228(3):315-325, 2004. 41. Y. Morishita, T.J. Kobayashi, and K. Aihara. An optimal n umber of molecules for signal amplication and discrimination in a chemical casca de.Biophys J , 91(6):2072- 2081, 2006. 42. B. Munsky and M. Khammash. A multiple time interval nite state projection al- gorithm for the solution to the chemical master equation. J Computational Physics , 226:818-835, 2007. 43. B. Munsky and M. Khammash. The nite state projection alg orithm for the solution of the chemical master equation. J Chem Phys , 124(4):044104, 2006. 44. E.M. Ozbudak, M. Thattai, I. Kurtser, A.D. Grossman, and A. van Oudenaarden. Regulation of noise in the expression of a single gene. Nat Genet , 31(1):69-73, 2002. 45. S. B. Ozkan, I. Bahar, and K. A. Dill. Transition states an d the meaning of -values in protein folding kinetics. Folding & Design , 3:R45-R58, 1998. 46. J. Paulsson and M. Ehrenberg. Random signal fluctuations can reduce random fluc- tuations in regulated components of chemical regulatory ne tworks. Phys Rev Lett , 84(23):5447-5450, 2000. 47. M. the word 'epigenetic'. Curr Biol Autoregulation and function a repressor in bacter lambda. Science , 194(4261):156-161, Oct 1976. 49. M. Ptashne. A Genetic Switch: Phage Lambda Revisited. Cold Spring Harbor Labo- ratory Press; 3 edition, 2004. 50. H. Qian and D. Beard. Chemical Biophysics: Quantitative Analysis of Cellular Sy s- tems. Cambridge University Press, 2010.130 REFERENCES 51. M.K. Roh, B.J. Daigle, Jr., D.T. Gillespie, L.R. Petz events. J Chem Wolynes. Understandi ng stochastic genetic networks. J Chem Phys , 126(24):245102, 2007. 53. M. A. Shea and G. K. Ackers. The OR control system of bacter iophage lambda a physical-chemical model for gene regulation. Journal Molecular Biology , 181(2):211- 230, 1985. 54. R. B. Sidje. Expokit: a software package for computing ma trix exponentials. Trans. Math. Softw. , 24(1):130-156, 1998. 55. E. Sontag. Lecture notes on mathematical systems biolog y, 2013. 56. H.M. Taylor and S. Karlin. An Introduction to Stochastic Modeling, 3rd Ed. Academic Press, 1998. 57. C.A. Uribe and G.C. Verghese. Mass fluctuation kinetics: capturing stochastic eects in systems of chemical reactions through coupled mean-vari ance computations. J Chem Phys , 126(2):024109, 2007. 58. Van Kampen. Stochastic processes in physics and chemistry . North Holland, Amsterdam, 1992. 59. N.G. Van Kampen. Stochastic processes in physics and chemistry, 3rd Edition . Else- vier Science and Technology books, 2007. 60. M. Vellela and H. Qian. A quasistationary analysis of a st ochastic chemical reaction: Keizer's paradox. Bulletin of Mathematical Biology , 69:1727-1746, 2007. 61. D. Volfson, J. Marciniak, W.J. Blake, N. Ostro, L.S. Tsi mring, and J. Hasty. Origins of extrinsic variability in eukaryotic gene expression. Nature , 439(7078):861-864, 2006. 62. T. Zhou, L. Chen, and K. Aihara. Molecular communication through stochastic synchronization induced by extracellular fluctuations. Phys Rev Lett , 95(17):178103, 2005. 63. X.M. Zhu, L. Yin, L. Hood, and P. Ao. Robustness, stabilit y and eciency of phage lambda , EXERCISES 4.1 If of a stochastic network can be enumerated , one can solve the underlying dCME directly. For a network with mmolecular species with r reactions, assume each molecular species can have at most ncopies of molecules. a) Without knowing the details of the reactions if one ignore s all dependency between molecules and allow the possibility that all molecu lar species may simultaneously have the maximum of ncopies of molecules. Provide an upper bound on the size of the state space. b) As dierent molecular species are coupled through chemic al reactions, they are not independent. Because of these couplings, the eecti ve number of independent species is less than m. Let the stoichiometry matrix of theEXERCISES 131 network be C, which is an m\u00d7rmatrix, with its k-th column repre- senting the k-th stoichiometry vector skas dened in Equation (4.1). C describes the coupling between dierent molecular species of the network. The degree of reduction in independent molecular species du e to coupled reactions is specied by the rank of C, denoted as rank C[55]. How can you make a better estimation of the size of the state space? 4.2 We examine a model of stochastic reactions in some details. a) Suppose the k-th reaction can be written as: cAA+cBB+cCCcDD+cEE. It has an intrinsic rate of rk. Please write down the rate of the reaction Ak(x)that depends on the state of the system, for example, the copy numbers (xA,xB,xC)of the system. b) Assuming a Poisson process. Show that the probability of n o reaction occurring during tiseA(x)\u00b7t, whereA(x) =/summationtext kAk(x). We rst dividetintoHintervals of small durations = /H. 1. What is the approximate probability that none of the mreactions have oc- curred during the time prior to the end of the rst time interv al? You can ignore the higher order terms. 2. What is the approximate probability that none of the react ions have occurred duringt? 3. Show that when taking the limit with H, this probability is eA(x)\u00b7t. 4.3 In the stochastic simulation algorithm, one needs to update the rates of all reactions after each time step. Namely, one needs to recalcu lateA(x(t+t), as the vector of copy numbers of molecules is altered after each sam pled reaction. This is computationally expensive. To speed up the calculation, on e can choose to update the reaction rates only after a time interval , when the accumulated error would otherwise exceed some tolerance. That is, we can leap the sys tem forward by without updating the copy numbers of the molecular species [ 7]. Suppose a tolerance threshold iis specied to indicate the acceptable level of errorixiin the copy number xiof thei-th molecular species, such that during the interval of , we have ximax{ixi,1}. What is overall the best one can use so errors in all species are within tolerance? 4.4 The Langevin equation of Equation (4.26) assumes that the nu mbernk(x,t) of spontaneously red reactions Rkoccurring during tfollows a Gaussian distri- bution. This is valid only when many reactions occur during t. A more realistic model is to assume nk(x,t)follows a Poisson distribution, if the copy numbers of molecules do not change signicantly, and hence the react ion rates also do not change signicantly during t, as discussed above. a) Describe in pseudocode a method for generating a random va riablenk(x,t) that follows the appropriate Poisson distribution. You can use the inverse function method or any other method. b) During t, all of the rreactions can occur. They are red randomly fol- lowingrindependent Poisson processes. Modify the standard Langev in132 REFERENCES formula in Equation (4.26) so the random fluctuation follows Poisson pro- cesses. 4.5 In the stochastic simulation algorithm, one needs to genera te two random variables: the time interval tuntil the next reaction occurs, and the specic reac- tionkthat would occur. Although the stochastic simulation algor ithm by Gillespie is accurate, it samples reaction trajectories according to their overall probabilities, and therefore can be very inecient in sampling rare events. a) One can bias towards a reaction by articially accelerate its reaction rate. Instead of sampling tkfor reaction kfollowingAk(x(t))eA(x(t))t, one can bias to accelerate the reaction by introducing an inflati on constant k, so the time interval tkwill be selected following the modied probability k\u00b7Ak(x(t))eA(x(t))t. However, this bias needs to be corrected. Modify Algorithm 2 in pseudo- code so appropriate bias k(as input) is introduced, and the nal results are appropriately corrected. b) One can also improve the sampling eciency by introducing desirable bias towards specic reactions that would otherwise occur rarel y. Instead of selecting the k-th reaction as the next reaction according to the probabil- ityAk(x(t)) A(x(t)), one can bias towards/away from this reaction by introducin g an inflation/deflation factor k, so thek-th reaction will be selected fol- lowing the modied probability k\u00b7Ak(x(t)) A(x(t)). Again, this bias needs to be corrected. Modify Algorithm 2 in pseudo-code so appropriat e biask(as input) is introduced, and the nal results are appropriatel y corrected. c) Write down in pseudocode a modied stochastic simulation algorithm in- corporating both bias factors kandk, and describe how to ensure proper corrections are included.CHAPTER 5 CELLULAR INTERACTION NETWORKS Cells are the fundamental and smallest units of life that are capable of independent functioning. A living organism may uni- or multi-cellular, and is made up of one of two basic types of cells, the prokaryotic cells and the eukaryotic cells, that evolved from a common ancestor cell but still share many common featu res. The biological functioning and life of a cell is controlled by signaling and energy transfer interac- tions among its numerous constituents such as proteins, RNA s, DNAs, and other small molecules, allowing them to adapt to changing environ ments [1, 25]. Such interactions may involve a cascade of biochemical reactions. Systematic approaches to understanding cellular interaction networks involve se veral steps such as data collection and integration of available information, adop ting an appropriate model for the system, experimenting on a global level, and generat ion of new hypotheses about the interaction patterns. With the advancement in dig ital and computing technologies in the last few decades, it is now possible to pe rform genome-wide ex- perimental studies to identify interactions among thousan ds of proteins and genes via DNA micro-arrays, florescent proteins and Western blots . This in turn has already generated massive amounts of interaction data. As stated above, after data collection and integration, an i nvestigation of a molec- ular interaction network is continued by selecting, implic itly or explicitly, a model to characterize the interactions between components of the cellular environment. Naturally, the selection of the model depends on several fac tors such as the level of details desired, the characteristics of the particular i nteraction data studied, and Models and Algorithms for Biomolecules and Molecular Netwo rks, rst edition. By Bhaskar DasGupta and Jie Liang Copyright \u00a9 2015 John Wiley & S ons, Inc.133134 CELLULAR INTERACTION NETWORKS the overall goal of the investigation. In very broad terms, t here are two types of models for interaction, which we will discuss in the next two sections. 5.1 Basic Denitions and Graph-theoretic Notions We briefly review some basic graph-theoretic concepts befor e proceeding any fur- ther; see standard textbooks such as [17] for a more comprehe nsive discussion of these and related concepts. A directed or undirected graph G= (V,E)consists of a setVof nodes, and a set Eof directed edges (also called arcs) or undirected edges (which we will simply refer to as edges). An edge e={u,v}Eor an arc e= (u,v)Edenotes an edge between the nodes uandvor an arc directed from nodeuto nodev, respectively. We will also denote an edge {u,v}or an arc (u,v)by uvoruv, respectively. A pathof lengthkis (for undirected graphs)/parenleftbig u1u2,u2u3,...,u k1uk,ukuk+1/parenrightbig , or an ordered sequence of arcs (for directed graphs)/parenleftbig u1u2,u2u3,...,u k1uk,ukuk+1/parenrightbig ; a cycle is a path for which uk+1=u1. A directed graph G= (V,E)isstrongly connected provided, for anypairs of nodes uandv, there exists a path from utov and also a path from vtou. 5.1.1 Topological representation In this type of representation, the physical, chemical, or s tatistical dependencies among various components in the molecular network is repres ented by ignoring the kinetic ( i.e., time-varying) components of the interactions. Typically , such a model is represented by a directed or undirected graph G= (V,E)in which the cellular components are the set of nodes V, and the arcs or edges in Eencode the causal or statistical interaction between the components. The simplest case is when Gis an undirected graph. This happens when infor- mation about the directionality of the interaction is unkno wn or irrelevant. For example, protein-protein interaction ( PPI) graphs, encoding physical interactions among proteins, are often undirected in part due to the limit ations of the current experimental technologies [29]. On the other hand, other ty pes of molecular biolog- ical graphs such as transcriptional regulatory networks, m etabolic networks, and signaling networks are represented by directed graphs in wh ich each arc represents positive (also called excitory) or negative (also called in hibitory) regulation of one node by another node. This nature of regulation is formally i ncorporated in the graph-theoretic framework by allowing each arc eEto have a label ewhich is either1and1, where a label of 1(respectively,1) represents a positive (respec- tively, negative) influence. In such a topological represen tation, a path Pfrom node uto nodevis often referred to as a pathway , and the excitory or inhibitory nature ofPis specied by the product of labels ePeof edges in the path. Fig. 5.1 shows an illustration of such a labeled directed graph. The g raph-theoretic nature of such a representation allows for ecient computational complexity analysis and algorithmic design by using techniques from theoretical co mputer science. A ma- jor disadvantage of such a representation is that it conside rs the interactions to be static and time-invariant, i.e., all arcs in the graph are assumed to be present simultaneously at any time .BASIC DEFINITIONS AND GRAPH-THEORETIC NOTIONS 135 Another relevant static model is the Boolean circuits model . Now, the state of each node is binary ( 0or1), and each node computes a Boolean function of the states of the nodes to which it is connected. Fig. 5.2 illustr ates a Boolean model of three nodes involving three proteins and two genes. The Bool ean model is restricted in the sense that the state of any node is restricted to be bina ry and each node can compute only a Boolean function. Boolean models are disc ussed further in Section 5.2. AB C D111111 111111 111 Figure 5.1 Illustration of the labeled directedgraph representation for a molecular interaction network. The arc BAindicates a negative influence of BonA,i.e., an increase in the amount of protein Bcauses a decrease in the amount of protein A. The pathway BCAD induces a positive influence of Bon Dsince the product of labels of its arcs is1\u00d7(1)\u00d7(1) = 1.ANDOR\u00ac\u00ac\u00acNOTProtein A Protein B Protein C Gene X Gene Y Figure 5.2 A Boolean circuit composed of logical AND, OR and NOT gates that encodes relationships between three proteins and two genes. For example, either Protein B must be absent or Protein C must be present (or both) to activate Gene Y. 5.1.2 Dynamical representation This type of representation, unlike the ones in the previous section, incorporates the (discrete or continuous) time-varying behavior of dieren t molecular components in the network, and thus provides a more accurate representation of the underlying biological mechanism. Dynamical representations are very suitable for simulating the biological system under study via dierent choices of va lues for parameters corresponding to unknown system characteristics or enviro nmental conditions, and then comparing the simulated dynamics with experimental me asurements to rene the parameters of the model further. A widely used continuous-time representation of this type i s obtained via systems of ordinary dierential equations ( ODE) of the following nature in the formalism of136 CELLULAR INTERACTION NETWORKS In this formalism, x(t) =/parenleftbig x1(t),x2(t),...,x n(t)/parenrightbig indicates the concentration of n molecular components at time t, each off1,f2,...,f nare functions of nvariables, andu(t) =/parenleftbig u1(t),u2(t),...,u m(t)/parenrightbig areminputs corresponding to external stimuli to the cellular system. In the concise vector form of represe ntation,fis the vector of functions and the dotover the vector of variables xindicates the vector of time derivatives of each component of the vector x(t). Many applications of this for- malism require a few mildtechnical assumptions, such as/parenleftbig x1(t),x2(t),...,x n(t)/parenrightbig must evolve in an open subset of Rn, thefi's must be dierentiable, and/or so- lutions of the above system of ODEmust be dened for allt0. In addition, for the purpose of measurement, one usually designates a sub set of the variables x1(t),x2(t),...,x n(t)asoutputs whose values can be recorded by reporting de- vices such as florescent proteins. Variations or specic cas es of the above general formalisms, based on dierent natures of the system dynamic s, are also possible. Some examples are: The time variable could be continuous (e.g., given via ODEas above, or via delay equations) or discrete (e.g., given via dierence equations or discretiza- tion of continuous variables). For discrete time systems, t he left-hand side of Equation (5.1), namely thedxi(t) dtterm, is replaced by xi(t+1)wheret+1is the next time step after t. Also, for discrete systems, two choices are possible for updating the values of the xi(t+ 1)'s from the corresponding set of val- ues ofxi(t)'s at every discrete time instance: a synchronous update (in which allxi(t+1)s update simultaneously ), or an asynchronous update (in which a selectedxi(t+1)updates and the rest remains the same). The state variables could be continuous ,discrete , orhybrid (i.e., some discrete and some continuous). The model could be deterministic orprobabilistic (e.g., the functions fiin the formulation are probabilistic functions). In addition, one can also devise hybrid models, e.g., by combining continuous and discrete time-scales, or by combining continuous and discr ete time variables.BOOLEAN INTERACTION NETWORKS 137 5.1.3 Topological representation of dynamical models Often in the study of dynamical representation of a biologic al system, it is possible to relate its dynamical properties under investigation by a ssociating the dynamics with a corresponding topological representation. For exam ple, one such version that will be very useful later in Section 6.5 in studying the \" monotonicity\" of the dynamics of a biological system is obtained by a signed graph representation in the following manner [9, 22, 75]. Consider the time-varying sys tem dened by Equa- tion (5.1) without the convenience, letx(t) allx(t)orfj xi0for allx(t). Then, the system modeled by (5.1) can be as- sociated with a directed interaction graph G(referred to as the \"associated signed graph\") in the following manner: The n}. iffj xi0for xi>0for some xitoxjwithei,j= 1. iffj xi0for allx(t)andfj xi<0for some then there is an arc ei,jinG directed from xitoxjwithei,j=1. 5.2 Boolean interaction networks The well-studied Boolean interaction network model is gene rally used in analyz- ing the dynamics of gene regulatory networks in which the gen e expression levels arebinarized ,i.e., the expression levels are either 0indicating not expressed or 1 indicating expressed. Such a model was rst proposed by Kau man in1969as random models of genetic regulatory networks [46], and can b e formally dened as follows. A Boolean variable is a variable that is either 0or1, and a function f:{0,1}nmso{0,1}overnBoolean variables is called a Boolean function. Denition 1 A boolean network \\}brckele{/vector s,/vectorf\\}brckeri}hconsists of the following each fi:{0,1}n {0,1}is a Boolean function. (c)An update rule that species the dynamics of the network. Let si(t)and/vector s(t) denote the values of siand/vector sat timet, respectively. An update rule species how the value of each si(t+1)is computed from /vector s(t). Two popular update update their states simultaneously at time t+1based on their states at timet. Asynchronous update: A specic variable, say sj, is selected such that sj(t)\\e}io\\slsh= fj(/vector s(t)), and then the new value of this variable is updated as sj(t+ 1) = fj(/vector s(t))(if no such node exists, the update procedure terminates). In o ther138 randomly among all possible candidate variab les, or it may be selected based on some pre-dened rules such as the lexi cographically rst variable among all candidate variables. In the same spirit as in Section 5.1.3, one may also associate a directed graph G/vector s,/vectorf=/parenleftbig V/vector s,/vectorf,E/vector s,/vectorf/parenrightbig V/vector s,/vectorf={v1,v2,...,v state variable si. E/vector s,/vectorfcontains an arc (vi,vj)for each pair of indices iandjsuch that the functionfjdepends on the state whichG/vector cycles is known as a feed-forward Boolean network; see Fig. 5.2 for an example. In the next denition, the notation /vector s(t+ 1) =/vectorf/parenleftbig /vector s(t)/parenrightbig is used to indicate the state vector /vector s(t+1)is obtained from /vector s(t)by following an appropriate update rule. Denition 2 (limit cycle) A limit cycle of length kis an ordered sequence of state vectors/parenleftbig /vector equilibrium point is a limit cycle of length 1. Limit cycles are also called \"attractors\" of a Boolean netwo rk. Fig. 5.3 shows a Boolean network with its associated directed graph and an at tractor. f1=s1s3 f2=s2(s3s1) f3=s1s2 (a)v1v1v1 v2v2v2v3v3v3 (b) Figure 5.3 (a)A Boolean network with three binarystates s1,s2,s3.(b)The associated directed graph. A xed point of the network is given by /vector s=/parenleftbig s1,s2,s3/parenrightbig = (0,1,0). Attractors are of considerable interest in Boolean genetic regulatory network models by associating them with dierent types of cells iden tied with specic patterns of gene activities . For example, reference [10] describes how to associate limit cycles with cellular cycles and reference [37] associ ates xed points with cell proliferation and apoptosis. Boolean networks are not the main focus of this chapter, so we refer the reader to a textbook such as [19] for further discussions on this mod el.SIGNAL TRANSDUCTION NETWORKS 139 5.3 Signal transduction networks Cells acquire many biological characteristics via complex interactions between its numerous constituents [1], and use signalling pathways and regulatory mechanisms to coordinate multiple functions, allowing them to respond to and acclimate to an ever-changing environment. Genes and gene products in cell s interact on several levels. For example, at a genomic level , transcription factors can activate or in- hibit the transcription of genes to give mRNA. Since these tr anscription factors are themselves products of genes, the ultimate eect is that genes regulate each others expressions as part of a complex network. Similarly, proteins can participate in diverse post-translational interactions that lead to mo died protein functions or to formation of protein complexes that have new roles. In m any cases dier- ent levels of interactions are integrated, e.g., the presence of an external signal may trigger a cascade of interactions of dierent types. Rec ent advances in exper- imental methodologies in bioinformatics have led to develo pment genome-wide experimental methods resulting in identication of intera ctions among thousands of proteins, genes and other components. Signal transducti on network models dis- cussed in this chapter are topological models that provide a concise summary of these interactions via labeled directed graphs. A major advantage of this model is that one can use powerful graph-theoretic techniques to ana lyze these networks. On the other hand, signal transduction networks only repres ent a network of pos- sibilities, and not all edges are present and active in vivo i n a given condition or in a given cellular location; therefore, an integration of t ime-dependent interaction may be necessary to more accurately predict the dynamical pr operties of these interactions. Formally, a signal transduction network is dened by a edge- labeled directed graphG= (V,E,L)where each node vVrepresents an individual component of the cellular interaction, and each arc (directed edge) (u,v)Eindicates that nodeuhas an influence on node v. The edge-labeling function L:Emso{1,1} indicates the \"nature\" of the causal relationship for each a rc, withL(u,v) = 1 indi- cating that uhas an excitory (positive) influence on v,e.g., increasing or decreasing the concentration of uincreases or decreases the concentration of v, respectively, whereasL(u,v) =1indicating that uhas an inhibitory (negative) influence on v, e.g., increasing or decreasing the concentration of udecreases or increases the con- centration of v, respectively. We will use the following notations and term inologies in the sequel. An excitory arc (u,v)will also be denoted by u1vor simply by uvwhen the excitory nature is clear from the context. An inhibitory arc(u,v)will also be denoted by u1voruv. ofPisL(P) =/producttextk1 i=1yi{1,1}. A path of parity 1(resp.,1) is called a path of even (resp, odd) parity. The notation uyvdenotes a path from utovof parityy{1,1}. If we do not care about the parity, we simply denote the path as uv. Similarly, an arc will be denoted by uyvoruv.140 CELLULAR INTERACTION NETWORKS For a subset of arcs EE,reachable (E)is the set of all ordered triples (u,v,y)such thatuyvis a path of the arc-induced subgraph (V,E). We will sometimes simply say uyvis contained in Eto meanuyvis a path of the subgraph (V,E). 5.3.1 Synthesizing signal Microbe Microarrays ,NASCArrays , orGene Expression Omnibus contain expression information for thousands of genes unde r tens to hundreds of experimental conditions. Following the approach in [4, 5, 43], interaction information between components in these type o f databases can be partitioned into three main categories. ( /A0/CP)Biochemical evidence that provides information on enzymati c activity or protein- protein interactions ,e.g., binding of two proteins or a transcription factor acti- vating the transcription of a gene or a chemical reaction wit h a single reactant and single product. These interactions are direct interactions. ( /A3/CQ)Pharmacological evidence, in which a chemical is used either to mimic the elim- ination of a particular component, or to exogenously provide a certain compo- nent,e.g., binding of a chemical to a receptor protein or observing gen e tran- scription after exogenous application of a chemical. This t ype of experimental observation leads to observed relationships that are notdirect interactions but indirect causal eects most probably resulting from a chain of interactions and reactions. ( /A0 )Genetic evidence of dierential responses to a stimulus in w ild-type organisms versus a mutant organism . In a minority of cases this type of experimental observation may correspond to a single reaction (namely, wh en the stimulus is the reactant of the reaction, the mutated gene encodes the en zyme catalysing the reaction and the studied output is the product of the reac tion), but more often it is a chain of reactions. As mentioned above, the last two types of experimental evide nces may not give di- rect interactions but indirect double-causal relationshi ps that correspond to reach- ability relationships in an (yet) unknown interaction netw ork. Direct and indi- rect (pathway-level) information can synthesized into a co nsistent network that maintains all the reachability relationships by the algori thm shown in Fig. 5.4. In Step ( /BD), we incorporate biochemical interactions or single causal evidences as labeled arcs, noting the \"mandatory arcs\" corresponding to conrmed direct inter- actions. In Step ( /BE), we incorporate double-causal relationships of the generi c form Ax(ByC)by(i)adding a new arc AxBifByCis a mandatory arc, (ii) doing nothing if existing paths in the network already expla in the relationship, or (iii)adding a new \"pseudo-node\" and three new arcs. To correctly i ncorporate the parity of the AxyCrelationship, excitory ByCpaths withy= inhibitory ByCpaths with y=1will be broken into an excitory a= 1) and an inhibitory edge ( b=1), summarized in a concise way by the equation b=ab=y.SIGNAL TRANSDUCTION NETWORKS 141 synthesize single causal relationshipsoptimize (Tr)synthesize causal Biochemical and pharmacological evidences that dene comp onent-to- component relationships, namely relationships of the form \"ApromotesB\" or \"AinhibitsB\", are incorporated (in arbitrary order) as arcs A1Bor A1B, respectively. If the interaction is known to be a direct interaction with concrete evidence , then the arc is marked as a \"mandatory arc\". Let Exeddenote the set of all [encoding Ax(ByC), wherex,y {1,1}, in any arbitrary order. Add new nodes and/or arcs in the netw ork based on the following cases: IfByCExed, then add the arc AxB. Otherwise, if there is nosubgraph (in the network constructed so far) of the formA x BaDbCfor some node Dwhereb=ab=y, then add to the network the subgraphA x BaPbCwhere P is a new \"pseudo-node\", and b=ab=y. Figure 5.4 An algorithmic framework for synthesizing signal transduc tion networks [5]. The optimization steps involving TrandPncare explained in Section 5.3.3.142 CELLULAR INTERACTION NETWORKS A computer implementation of the framework in Fig. 5.4 needs an ecient algo- rithm for the following problem: given two nodes uiandujandy {1,1}, does there exist a path from uito ujof parity y? A straightforward solution is so-called Floyd- Warshall transitive clo- sure algorithm for directed Let the nodes of Gbeu1,u2,...,u n, and letibe called as the \"index\" of node ui. Dene the following quantities: N(i,j,k,x) = 1,if there is a path of parity xfromuitouj using intermediate nodes of indices no higher than k 0,otherwise P(i,j,k,x) =/braceleftigg a path of parity xfromuitouj, if such a path exists , otherwise Then, the dynamic programming algorithm in Fig. 5.5 can be us ed to compute N(i,j,k,x)andP(i,j,k,x)for alli,j,k andx; the intuition behind the iterative calculations are shown pictorially in Fig. 5.6. The nal ans wer is obtained by check- ingN(i,i,n,x)andP(i,i,n,x)for eachi{1,2,...,n}and eachx{1,1}. It is O/parenleftbig n3/parenrightbig time andO/parenleftbig n3/parenrightbig space, both of which may be prohibitive for large networks. Exercise 5.11 explores s ome practical methods to reduce the running time and space requirements; further h euristic improvements are possible and were incorporated in the software reported in [43]. A software named NET-SYNTHESIS for synthesis of networks based on the frame- work in Fig. 5.4 was reported in [43]; detailed discussion ab out usage of this software can be found in [6]. The network synthesis framework in Fig. 5 .4 was used suc- cessfully in [5, 43] to synthesized a network of about hundre d nodes for Abscisic Acid(ABA)-induced stomatal closure of the model plant Arabidopsis Thaliana . The NET-SYNTHESIS software was further used in [87] to build a network model to study the signalling components that eect the survival of c ytoxic Tlymphocytes inLGL-leukemia. 5.3.2 Collecting data for network synthesis A starting point of gathering relevant data for synthesizin g a signal transduction network is to read thoroughly relevant literatures concern ing the signal transduc- tion pathways of interest, and then to assess if sucient inf ormation is available such that network synthesis is indeed necessary. For exampl e, if all that is known about a system is that component Xactivates component Ywhich in turn inhibits component Z, drawing a simple linear network and deducing that knockout ofY will eliminate signaling suces, and a more formal analysis is hardly required. In assessing the literature, the focus should be specically o n experiments that pro- vide information of the type relevant to network constructi on. Experiments that identify nodes belonging to a signaling pathway and their re lationships include the following types of data. (1)In vivo or in vitro experiments which show that the propertie s (e.g., activity or sub-cellular localization) of a protein change upon appl ication of the inputSIGNAL TRANSDUCTION Figure 5.6 Pictorial illustration of the iterative calculations of th e dynamic programming algorithm in Fig. 5.5. signal, or upon modulation of components already denitively known to be associated with the input signal. (2)Experiments that directly assay a small molecule or metabol ite (e.g., imaging of cytosolic Ca2+ concentrations) and show that the concent ration of that metabolite changes upon application of the input signal or m odulation of its associated elements.144 CELLULAR INTERACTION NETWORKS (3)Experiments that demonstrate physical interaction betwee n two nodes, such as protein-protein interaction observed from yeast two-hybr id assays or in vitro or in vivo co-immunoprecipitation. (4)Pharmacological experiments which demonstrate that the ou tput of the path- way of interest is altered in the presence of an inhibitory ag ent that blocks signaling from the candidate intermediary node ( e.g., a pharmacological in- hibitor of an enzyme or strong buering of an ionic species). (5)Experiments which show that articial addition of the candi date intermedi- ary node ( e.g., exogenous provision of a metabolite) alters the output of t he signaling pathway. (6)Experiments in which genetic knockout or over-expression o f a candidate node is shown to aect the output of the signaling pathway. Usually, (1)-(3)correspond to single causal (direct) inferences; (3)may also cor- respond to mandatory arcs. On the other hand, (4)-(6)usually correspond to double-causal (indirect) inferences. Some choices may have to be made in distilling the relationsh ips, especially in the case where there are conflicting reports in the literature. For example, suppose that in one report it is stated that proteins XandYdonotphysically interact based on yeast two-hybrid analysis, while in another report it is sta ted that proteins XandY dointeract based on co-immunoprecipitation from the native t issue. One will then need to decide which information is more reliable, and proce ed accordingly. Such aspects dictate that human intervention will inevitably be an important component of the literature curation process, as indicated by the \"int eractions with biologists\" in Fig. 5.4, even as automated text search engines such as GEN IES [31,40,59] grow in sophistication. 5.3.3 Transitive reduction and pseudo-node collapse The network obtained by steps ( /BD)and( /BE)of the algorithm in Fig. 5.4 is \"not reduced\", i.e., it may contains arcs and pseudo-nodes which can be systemat ically removed without changing the reachability relations betwe en nodes (note, however, that no mandatory arc can be removed). In this section we desc ribe two methods to nd a minimal network, in terms of the number of pseudo-nodes and the numbe r of non-mandatory arcs, that is consistent with all reachabili ty relationships between non-pseudo-nodes. The algorithmic methodologies describ ed are of two kinds: transitive reduction to reduce the number of non-mandatory arcs, and pseudo-node-collapse to reduce the number of pseudo-nodes. Applications of these methods do not necessarily imply that real signal transduction networks are the sparsest possible, but instead the goal is t o minimize false positive (spurious) inferences even if risking false negatives, i.e., the goal of these methods is to produce a network topology that is as close as possible t o atreetopology while supporting all experimental observations. The implicit as sumption of \"chain-like\" or \"tree-like\" topologies permeates the biology literature: signal transduction and metabolic pathways are assumed to be close to linear chains, andSIGNAL TRANSDUCTION NETWORKS 145 genes are assumed to be regulated by one or two transcription factors [1]. According to current observations the reality is not far: the average in/out degree of the transcriptional regulatory networks [56,74] and the mammalian signal transduction network [58]is close to 1. Philosophically, the approach of obtaining a sparse network is similar to the parsimony approach used in the construction of phylogenies and elsewhere, and can be linked to transitive reduction (Tr) problem in the context of our signal transduction networks i s shown in Fig. 5.7, and an illustration of a solution of this problem for an examp le network is shown in Fig. 5.8. Note that an exact or an approximate solution of t heTrproblem may notbe unique; alternate solutions represent alternate interp retations of the same data. Transitive reduction are usually applied to the netwo rk synthesis procedure outlined in Fig. 5.4 after Step ( /BD) and after Step ( /BE). Instance: A directed graph G= (V,E)with an arc labeling function L:Emso{1,1}, and a set of mandatory arcs EmE. Valid Solutions: A subgraph G= (V,E)whereEmEE, and reachable (E) problem. v1 v2v3 v4 v5v6 edge selected for v2v3 v4 v5v6 v1 v2v3 v4 v5v6 Figure of obtaining a reduced network via transitive red uction. The obtained network is not minimal (see Exercise 5.4). The idea of a transitive reduction, in a more simplistic sett ing or integrated in an approach dierent from what has been described, also appe ared in other papers than the ones already mentioned. For example, Wagner [85] pr oposed to nd a net- work from the reachability information by constructing uni formly random graphs and scale-free networks in a range of connectivities and mat ching their reachability information to the range of gene reachability information f ound from yeast per- turbation studies. In contrast, in the Trproblem we consider the reachability information but with the additional information about the nature of interaction146 CELLULAR INTERACTION NETWORKS (excitory or inhibitory) for each path along with a subset of pre-specied manda- tory edges, and wish to actually reconstruct the network and not only nd a range of networks that have a given mean reachability. Another imp ortant dierence be- tween the two approaches is in the number of isolated nodes an d weak subgraphs. Wagner's networks have a huge number of sub-networks many of which are isolated . The network synthesis method in Fig. 5.4 does aim for sparsen ess, but does notal- low isolated nodes if their reachabilities are non-zero. As another example, Chen et al.in [18] used time-dependent gene expression information to determine candidate activators and inhibitors of each gene, and then removed edg es by assuming that no single gene functions both as activator and inhibitor. Liet al. in [57] used the greedy procedure in Fig. 5.9 for Trwithin the network synthesis procedure to manually create a network for ABA-induced stomatal closure: Denition an arcuxvis redundant if there is an alternate path uxv Algorithm while there exists a redundant arc delete the redundant arc Figure 5.9 A greedy algorithm to solve Tr. This greedy procedure for Tris in fact optimal if the graph is a directed acyclic graph ( DAG),i.e., ifGhas no cycles [4]. But even very special cases of Tr, namely when all edges are excitory, Em=andGdoes not have a cycle of length more than 4, are known to be NP-hard [51], eectively ending the possibility of an ecient exact solution of Trfor general graphs under the assumption of P\\e}io\\slsh=NP. Thus, the best one could hope is that the greedy algorithm in Fig. 5. 9 delivers a good approximate solution for Tron arbitrary graphs. An approximation algorithm for a minimization problem has a n approximation ratio of1(or is an-approximation) if it is a polynomial-time algorithm thatalways provides a solution with a value of the objective function th at isat mosttimes the optimal value of the objective function (thus, for example, 1- approximation is an exact solution). The following result w as shown in [5]. Theorem 5.1 [5]The greedy algorithm in Fig. 5.9 is a3-approximation. There are input instances of Trfor which the greedy algorithm has an approxi- mation ratio of at least2; Fig. 5.10 shows such an example. The idea behind a proof of Theorem 5.1 is to rst prove that the greedy procedure is a 3-approximation if the input graph Gis strongly connected, and then to extend the result for the c ase whenGmay not be strongly connected. The idea behind a proof of 3-approximation of the greedy algorithm when Gis strongly connected is as follows. Let opt(G)de- notes the number of edges in an optimal solution of TrforG= (V,E). It is not dicult to observe that opt(G)|V|(see Exercise 5.12). For a graph H, letH+1 be the graph obtained from Hby setting all arc labels to 1, and an arc einH+1 is called superfluous if it would be removed by the greedy algorithm in H+1but not inH. LetGgreedy be the graph obtained from Gby the greedy algorithm. The proof uses the following sequence of steps. Show a2-approximation for the case when Em=in the following way:SIGNAL TRANSDUCTION NETWORKS 147 (i)rst show that G+1 greedycontains at most 1superfluous arc, and then (ii)show that using (i)it follows that the number of arcs in Ggreedy is at most 2|V|+1. Show that the constraint Em\\e}io\\slsh=adds at most 1to the approximation ratio. v0 v1v2.........vn1vn output of greedy 2narcs......... optimal n+1arcs Figure 5.10 An example of a family of graphs for which the greedy algorith m has an approximation ratio of 2. The greedy algorithm may remove the arcs vivi+1fori= 1,2,...,n1providing a solution with 2narcs, but an optimal solution with n+1arcs is possible by selecting the arcs v0v1,vivi+1fori= 1,2,...,n1, andvnv0. Approximation algorithms with approximation ratios bette r than the greedy ap- proach are possible and described in references [4, 13, 43]; currently the best pos- sible approximation ratio achievable is 3/2as described in reference [13], but the algorithm is too complicated for ecient implementation. E xercise 5.13 explores a possible improvement over the greedy approach. A software for solving the Tr problem was reported in [6,43]; extensive empirical evalua tions in [43] showed that in practice the redundancy value calculated is almost alway s close to optimal. 5.3.3.2 Pseudo-node collapse (Pnc)The denition of the pseudo-node collapse (Pnc) problem in the context of our signal transduction network s ynthesis pro- cedure is shown in Fig. 5.11. Intuitively, the Pncproblem reduces the set of pseudo-nodes to a minimal set while maintaining that the gra ph is consistent with all experimental observations. As in the case of the Trproblem, our goal is to minimize false positive inferences of additional componen ts in the network. Unlike the Trproblem, the Pncproblem can be easily solved in polynomial time in the following manner as outlined in [5]. It is not dic ult to see that the \"permissibility of collapse\" relation is in fact an equivalence relation on the set of nodes. Thus, we can partition the nodes into equivalence cla sses such that two nodesuandvare in the same partition provided in(u) =in(v)andout(u) =out(v). It can be easily seen if two such nodes uandvin the same partition are collapsed into a new node wthen the resulting equivalence partition is same as before e xcept that the two nodes uandvare replaced by a new node win the same equivalence partition. Thus, an optimal solution would consist of colla psing all pseudo-nodes with one arbitrary real-node (if it exists) in each equivale nce partition.148 CELLULAR INTERACTION NETWORKS Instance: A directed graph G= (V,E)with an arc labeling function L:Emso{1,1}, and a subset VpseudoVof nodes called pseudo- nodes. For convenience, the nodes in V\\Vpseudo are called \"real\" nodes. are not real nodes, in(u) =in(v), and out(u) =out(v). If permissible, the collapse of two nodes uandvcreates a new nodew, makes every incoming (respectively, outgoing) arc to (re- spectively, from) either uorvan incoming (respectively, outgo- ing) arc from w, removes all parallel arcs that may result from the collapse operation and also removes both the nodes uandv. Valid Solutions: A graphG= (V,E)obtained from Gby a sequence of permissible pseudo-node collapse operations. Objective: minimize|V|. Figure 5.11 The pseudo-node collapse ( Pnc) problem [5]. 5.3.3.3 Other network reduction rules In addition to TrandPnc, depending on the particular application in mind, it is possible to have ad ditional rules to minimize the synthesized network. For example, [5] formalized the fo llowing additional rule in relation to enzyme-catalyzed reactions specic to the co ntext of synthesizing a consistent guard cell signal transduction network for ABA-induced stomatal closure of Liet al. [57]. Li et al. [57] represent each of these reactions by two mandatory arcs, one from the reaction substrate to the product and one f rom the enzyme to the product. As the reactants (substrates) of the reactions in [57] are abundant, the only way to regulate the product is by regulating the enzyme. The enzyme, being a catalyst, is always promoting the product's synthesis, th us positive double-causal regulation of a product was interpreted as positive regulat ion of the enzyme, and negative indirect regulation of the product was interprete d as negative regulation of the enzyme. In our graph-theoretic terms, this leads to th e following rule. We have a subset EenzEmof arcs that are all labeled 1. Suppose that we have a pathAaXbB, and an arc C1BEenz. Then, one can identify the node C with nodeXby collapsing them together to a node XC, and set the labels of the arcsAXCandXCBbased on the following cases: ifab= 1thenL(A,XC) =1. 5.3.3.4 Other applications of TrandPnc In addition to the network synthesis procedure in Fig. 5.4, the Trproblem can be very useful in many other types ofSIGNAL TRANSDUCTION NETWORKS 149 analysis of biological networks. For example, Wagner [85] a pplied a very special case of Trthat included calculations of reachabilities only (withou t the activa- tion/inhibition information) to determine network struct ure from gene perturba- tion data, and Chen et al. [18] used a so-called \"excess edge deletion\" problem to identify structure of gene regulatory networks. In Section 5.3.4, we will explain how Trcan be used to provide a measure of redundancy for biological networks. Although the original motivation in Section 5.3.1 for intro ducing pseudo-nodes was to represent the intersection the two paths correspon ding to3-node infer- ences, Pnccan also be used in a broader context of network simplicatio n. In many large-scale regulatory networks only a subset of the nodes a re of inherent interest (e.g., because they are dierentially expressed in dierent exog enous conditions), and the rest serve as backgrounds or mediators. One can therefore designate nodes of less interest or condence as pseudo-nodes and then colla pse them, thereby mak- ing the network among high-interest/condence nodes easie r to interpret. Using this idea, PncwithTrcan be used to focus on specic pathways in disease net- works to better understand the molecular mechanism of the on set of the disease and therefore help in drug target designs . This approach was used by Kachalo et al.[43] to focus on pathways that involve the 33known T-LGLderegulated proteins in a cell-survival/cell-death regulation-related signal ing network synthesized from theTranspath 6.0database. LGLs are medium to large size cells with eccentric nuclei and abundant cytoplasm. LGLleukemia is a disordered clonal expansion of LGL, and their invasions in the marrow, spleen and liver. Curren tly, there is no standard therapy for LGLleukemia, and thus understanding the mechanism of this disease is crucial for drug and therapy development. Rasis a small GTPase which is essential for controlling multiple essential signaling pa thways, and its deregulation is frequently seen in human cancers. Activation of H-Rasrequires its farnesylation, which can be blocked by Farnesyltransferase inhibitiors ( FTIs). This envisions FTIs as future drug target for anti-cancer therapies, and severa lFTIs have entered early phase clinical trials. One of these FTIis tipifarnib, which shows apoptosis induction eect to leukemic LGLin vitro. This observation, together with the nding that Ra s is constitutively activated in leukemic LGLcells, leads to the hypothesis that Ras plays an important role in LGLleukemia, and may functions through influencing Fas/FasLpathway. The approach used by Kachalo et al. [43] was to focus special interest on the eect of Rason apoptosis response through Fas/FasLpathway by designating nodes that correspond to \"proteins with no evid ence of being changed during this eect\" as pseudo-nodes, and simplifying the net work via iterations of PncandTr. Although performing comprehensive Pncin this manner may lead to a drastic reduction of the network, a drawback of such a dra matic simplication is that pairs of incoherent arcs (i.e., two parallel arcs with opposite labels) can ap- pear among pairs of nodes. While incoherent paths between pa irs of nodes are often seen in biological regulatory networks, interpretation of incoherent arcs is dicult without knowledge of the mediators of the two opposite regul atory mechanisms. Thus, optimal simplication in this manner may require more careful selection of pseudo-nodes in Pncalgorithms. 5.3.4 Redundancy and degeneracy of networks The concepts of degeneracy and redundancy are well known in i nformation theory. Loosely speaking, degeneracy refers to structurally dierent elements performing the150 CELLULAR INTERACTION NETWORKS same function, whereas redundancy refers to identical elements performing the same function. In electronic systems, such a measure is useful in analyzing properties such as fault-tolerance. It is an accepted fact that biological n etworks do notnecessarily have the lowest possible degeneracy or redundancy; for exam ple, the connectivities of neurons in brains suggest a high degree of redundancy [49] . However, as has been observed by researchers such as Tononi, Sporns and Edelman [ 82], specic notions of degeneracy and redundancy have yet to be rmly incorporat ed into biological thinking, largely because of the lack of a formal theoretica l framework. A further reason for the lack of incorporation of these notions in biol ogical thinking is the lack of ecient algorithmic procedures for computing these measures for la rge- scale networks even when formal denitions are available. T herefore, studies of degeneracy and redundancy for biological networks are ofte n done in a somewhat ad- hoc fashion [69]. There do exist notions of \"redundancy\" for undirected graphs centrality me asures [24]. However, such notions may not be appropriate for the analysis of biolo gical networks where one must distinguish positive from negative regulatory int eractions, and where the study of dynamics of the network is of interest. XXX O Figure 5.12 A system of seven elements. 5.3.4.1 f or biological systems were proposed in [80-82] based on the so-called mutual-information (MI)content access to suitable perturbation experim ents and corresponding accurate measurements of the relevant parameters. Conside r a system consisting ofnelements that produces a set of outputs Ovia a xed connectivity matrix from a subset of these elements (see Fig. 5.12 for an illustra tion). The elements are described by a jointly distributed random vector Xthat represents steady-state activities of the components of the system. The degeneracy D(X;O)of the system is then expressed as the average mutual information ( MI) shared between Oand the \"perturbed\" bi-partitions of Xsummed over all ofXcomposed of kelements, and MIP(A;O)is the between a subset of elements Aand anSIGNAL TRANSDUCTION NETWORKS 151 output setOwhenAis injected with a small xed amount of uncorrelated noise. MIP(A;O)is given by the equation MIP(A;O) =H(A)+H(O)H(A,O) whereH(A)andH(O)are entropies of AandOconsidered independently, and joint entropy of the subset of elements Aand the output set O. The above denition of the degeneracy measure is mathematicall y precise, but a signif- icant computational diculty in applying such a denition i s that the number of possible bi-partitions could be astronomically large even for a modest size network. For example, for a network with 50nodes, the number of bi-partitions is roughly 250>1015. Measures avoiding averaging over all bi-partitions were a lso proposed in [82], but the computational complexities and accuracies of these measures still remain to be thoroughly investigated and evaluated on large r networks. Similarly, the redundancy /recipe (X;O)of a system Xcan be dened as the dierence between summed mutual information upon perturbation betwe en all subsets of size up to1andO, and the mutual information between the entire system and O,i.e., /recipe(X;O)n/summationdisplay j=1MIP/parenleftbig X1 j;O/parenrightbig MIP/parenleftbig X;O/parenrightbig A is that it only prov ides a number, but does not indicate which subset of elements are redundant. Id entifying redundant elements is important for the interpretation of results, an d may also serve as an important step of the network construction and renement pr ocess. 5.3.4.2 Topological redundancy topological redundancy measure of degeneracy or redundanc y should have a few desirable properties: ( /C8/BD)The measure must not just reflect simple connectivity proper ties such as degree-sequence or average degree, but also should incorpo ratehigher-order connectivity properties. ( /C8/BE)The measure should not just provide a number, but also should indicate candidate subsets of components that are redundant or degen erate. ( /C8/BF)The measure must be eciently computable so that it can be com puted for large-scale networks. Based on the Trproblem, Albert et al. in [3] proposed a new topological measure of redundancy that is amenable to ecient algorithmic analy sis. Note that any solution of Trdoes not change pathway level information of the network sin ce it removes only those arcs from one node to another when similar alternate pathways exist, thus truly removing redundant connections. Thus, |E|/|E|provides a measure of global compressibility of the network and a topological r edundancy measure /recipe Tr can be dened as /recipeTr= 1|E| |E| where the|E|term in the denominator of the denition is just a \"min-max no r- malization\" of the measure [36] to ensure that 0</recipeTr<1. Note that the higher152 CELLULAR INTERACTION NETWORKS the value of /recipe Tris, the more redundant the network is. The Trproblem used in computing /recipe Tractually nds a subset of redundant arcs and, in the case of mu ltiple minimal networks of similar quality, can also nd multiple d istinct subsets of redun- dant arcs by randomization of the greedy selection step in th e algorithm in Fig. 5.9. /recipeTralso satises Property ( /C8/BD) since paths of arbitrary length are considered for removal of an arc and thus, for example, /recipe Trisnotnecessarily correlated to either the degree sequence (cf. Exercise 5.6.a) or the average degr ee (cf. Exercise 5.6.b) of the network. Based on the evaluations of the above redundancy measure on s even biological networks of various types, Albert et al.[3] provided a few interesting biological and computational conclusions such as: /recipeTrcan be computed quickly for large networks and is statistica lly signicant. Transcriptional networks are less redundant than networks. Topological redundancy of the C. elegans metabolic network is largely due to its inclusion of currency metabolites such as ATPandADP. Calculations of /recipe Trand corresponding minimal networks provide insight into a predicted orientation of protein-protein-interaction n etworks by determining whether the predicted oriented network has a level of redund ancy similar to those in known related biological networks. Correlation between /recipeTrand network dynamics It is of interest to determine if a topologically minimal network has similar dynamical or fun ctional properties as the original network such as stability and response to exter nal inputs, when such properties are available for the original network. When the network has designated outputs or read-outs, such as gene expression rates in trans criptional networks, it may be of interest to characterize the behavior of these outp uts as a function of the inputs. A topologically minimal network such as the one u sed in this section does have the same input-output connectivity as the origina l network, and thus the excitory or inhibitory influence between each input-output pair is preserved. Such a reduced network is minimal in an information-theoretic se nse:any network with the same input-output behavior must be of at least this size . a b c (i)a b c(ii) Figure 5.13 Equivalence of dynamical properties may depend on node func tions. However, one may ask if a topologically minimal network also has a \"similar\" output behavior as the original one for the same input ? For some dynamical prop- erties, the question can be answered; correla tion of /recipe Trwith the monotonicity of dynamics is explored in Section 6.5. In gene ral, however, such a question does not have a well-dened answer since the dynami cs depend on what type of functions are used to combine incoming connections t o nodes and the \"timeSIGNAL TRANSDUCTION NETWORKS 153 delay\" in the signal propagation, both of which are omitted i n the graph-theoretic representation of signal transduction networks. Therefor e, deleting redundant arcs may result in functionalities that may or may not be the same . For example, con- sider the two networks shown in Fig. 5.13 in which network (ii)has a redundant connection ac. The functions of these two circuits could be dierent, howe ver, depending on the function used to combine the inputs acandbcin net- work(ii)(cf. Exercise 5.7). However, despite the fact that a minimal network may not preserve alldynamic properties of the original one, a signicant applic ation of nding minimal networks lies precisely in allowing one to identify redundant connections (arcs). In this application, one may focus on in vestigating the func- tionalities of these redundant arcs, e.g., identifying the manner in which their eect is cumulated with those of the other regulators of their targ et nodes could be a key step toward understanding the behavior of the entire networ k. Thus, the measure developed here is of general interest as it not only provide a quantied measure of overall redundancy of the network, but also allow identi cation of redundancies and hence help direct future research toward the understand ing of the functional signicance of the redundant arcs. 5.3.5 Random interaction networks and statistical evaluati ons A comprehensive statistical evaluation of any network meas ure such as the redun- dancy value /recipe Trdiscussed in the previous section require the following ing redients: (a)generation of an ensemble of random networks (the \"null hypo thesis model\") on which the measure can be computed, (b)if necessary, appropriate normalization of values of the me asure on random networks to correct statistical bias, and (c)checking appropriate statistical correlation (\"null hypo thesis testing\") between these random network measures with the measure on the given n etwork. 5.3.5.1 Null hypothesis models Ideally, if possible, it is preferable to use an accu- rate generative null model for highest accuracy, since such a model may be ame nable to more rigorous mathematical analysis [68]. For signaling and transcriptional bi- ological networks Albert et al. [5], based on extensive literature review of similar kind of biological networks in prior literature, arrived at the characteristics of a generative null model that is described below. One of the mos t frequently reported topological characteristics of biological networks is the distribution of in-degrees and out-degrees of nodes, which may be close to a power-law or a mixture of a power law and an exponential distribution [2,33,55]. Speci cally, in biological ap- plications, metabolic and protein interaction networks ar e heterogeneous in terms of node degrees, and exhibit a degree distribution that is a m ixture of a power law and an exponential distribution [2,33,41,55,58], whereas transcriptional regulatory networks exhibit a power-law out-degree distribution and a n exponential in-degree distribution [56,74]. Thus, usually a researcher is expect ed to use his or her judge- ment to select an appropriate degree distribution and other necessary parameters that is consistent with the ndings in prior literature for a n accurate generative null model. Based on the known topological characterizatio ns, Albert et al. [5] arrived at the following degree distributions for generati ng random transcriptional and signaling networks:154 CELLULAR INTERACTION NETWORKS The distribution of in-degree is truncated exponential , namely, Pr[ in-degree = x]=c1ec1xwith1/2<c1<1/3and1x12. out-degree is governed by a truncated power-law , namely, and -for1x200, Pr[out-degree =x]=c2xc2. Parameters in the distribution are adjusted to make the sum o f in-degrees of all nodes equal to the sum of out-degrees of all nodes, and the exp ected number of arcs in the random network is the same as that in G. The percentages for activation, inhibition and mandatory e dges in the random network are the same as in G, and distributed over the arcs randomly. Several methods are known in the literature to generate rand om directed graphs with specic degree distributions. For example, Newman, St rogatz and Watts [68] suggest the following method. Suppose that the parameters o f the degree distribu- tions are appropriately adjusted such that the averages of t he in-degree distribution and the out-degree distribution is almost the same. Let v1,v2,...,v nbe vi\\e}io\\slsh=vjsuch thatdin i,dout j>0, add the arc(vj,vi)and decrease both din jby1. Repeat the procedure until the in-degree and out-degree of every node is zero. See [66] for s ome other methods. For the case when generative null models are not possible, al ternate methods are available to generate random networks that preserve the rst-order topological characteristics (such as the degree sequence) but randomiz es higher-order statistics (such as distribution of paths). We review two such alternat e methods below. The Markov-chain algorithm for generating random networks [44] starts with the given network G= (V,E), and repeatedly swaps randomly chosen similar pairs of connections as illustrated in Fig. 5.14. This kind of algori thm was used in papers such as [3,74]. The percentage of arcs swapped depends on the application, e.g., Shen-Orr et al. [74] considered swapping about 25% of the arcs. Newman and others in several publications [34, 54, 64, 65, 67 ] have suggested using the following null model Ggenerated from the degree-distribution of the given graphG= (V,E).Gis a random graph with the same set of nodes as the given graphG. Every possible directed edge (u,v)inGis selected with a udin vare the out-degree of node uand the in- degree of node v, respectively, in G. The original denition also allows selection of self-loops, i.e., edges(u,v)withu=v; in that case this null model preserves in expectation the distribution of the degrees of each node in the given grap hG,i.e., /summationtext vVpu,v=dout u/summationtext vVpv,u=din u(5.2) This null very popular in many biological applicati ons [34,35,71].REVERSE ENGINEERING OF BIOLOGICAL NETWORKS 155 repeat choose two arcs axb,cydErandomly (x,y{1,1}) ifx=yanda\\e}io\\slsh=candb\\e}io\\slsh=d andaxd\\e}io\\slshEandcyb\\e}io\\slshE then add the arcs axdandcyb remove the arcs axbandcyd endif until a specied percentage of arcs of G has been swapped (a) (b) Figure 5.14 (a)The Markov-chain algorithm for generating random networks by arc swapping. (b)A pictorial illustration of arc swapping. 5.3.5.2 Correction of bias of empirical null model attributes This is a very standard task in statistical data mining, and the reader is referred t o suitable textbooks such as [53]. We illustrate one such method for the correction of b ias in computation of /recipe Trfor random networks. Suppose that we generated prandom networks redundancy values /recipe1 Tr, /recipe2 Tr,..., /recipep Trand let\u00b5andbe the mean and standard deviation of these pvalues. We can rst compute the standardized value/recipej Tr\u00b5 for the observed value /recipej Tr. Then, we can calculate the standardized range (dierence between maximum and minimum) of these standardized values, and normalize the standardized values by dividing them by this standardized r ange. 5.3.5.3 Null hypothesis testing Given theprandom measures, say r1,r2,...,r p, and the value of measure for the given network, say r, this step essentially involves determining the probability that rcan be generated by a distribution that ts the data points r1,r2,...,r p. There are a variety of standard statistical tests ( e.g., one-sample student's t-test) that can be used for this purpose. 5.4 Reverse engineering of biological networks In previous sections we discussed how signal transduction n etworks can be syn- thesized based on available interaction data. However, in m any situations, such interaction data are unavailable. Instead, for many biolog ical systems, data are available about some characteristics of the system. Informally, the \"reverse engi- neering\" problem for biological networks is to unravel the i nteractions among the components of the network based on such observable data abou t the characteristics of the system, and may be dicult to approach by means of stand ard statistical and machine learning approaches such as clustering into co-exp ression patterns. Infor- mation on direct functional interactions throws light upon the possible mechanisms and architecture underlying the observed behavior of compl ex molecular networks, but an intrinsic diculty in capturing such interactions in cells by traditional ge- netic experiments, RNA interference, hormones, growth fac tors, or pharmacological156 CELLULAR INTERACTION NETWORKS interventions is that any perturbation to a particular gene or signaling component may rapidly propagate throughout the network, thus causing global changes which cannot be easily distinguished from direct (local) eects. Thus, a central goal in reverse engineering problems in biology is to use the observ ed global responses (such as steady-state changes in concentrations of activat ed activities of proteins, mRNA levels, or transcription rates) in order to infer the lo cal interactions between individual nodes. This section focuses on several computat ional issues in reverse- engineering of a biological system and, quoting [23], can be very broadly described asthe problem of analyzing a given system in order to identify, from biological data, the components of the system and their relationships . In general, application of a specic reverse engineering me thod depends upon several factors such as: ( /C9/BD)The type of interactions to be reconstructed, e.g., statistical correlations, causal relationships etc. ( /C9/BE)The type of data or experiments that the modeller has access t o,e.g., input- output behaviour on perturbations, gene expression measur ements etc. ( /C9/BF)The quality of the expected output of the method, e.g., the nature (excitory or inhibitory) of the interaction versus the actual strengt hs of the interactions. For example, in [11,26,32,63,70,72,86,88], interactions represent statistical corre- lation between variables whereas in [23,30,38,39,52] inte ractions represent causal relationships among nodes. Depending upon the type of netwo rk analyzed, quality and availability of data, network size, and so forth, diere nt reverse engineering methods oer dierent advantages and disadvantages relati ve to each other. In the next two sections we discuss two reverse engineering a pproaches. The rst one is the so-called modular response analysis approach that relies on availability of perturbation experiments. The second approach is a colle ction of parsimonious combinatorial approaches that rely on the availability of time-varying me asurements of relevant parameters of the system. 5.4.1 Modular response analysis approach known prior informationlinear algebraic A schematic diagram for the overview of the Mraapproach.REVERSE ENGINEERING OF BIOLOGICAL NETWORKS 157 Themodular response analysis (Mra) approach for reverse engineering of net- works was originally introduced in [47, 48] and further elab orated upon in [8, 21, 78, 79]. In this approach, the architecture of the network is inferred on the basis of observed global responses (namely, the steady-state con centrations in changes in the phosphorylation states or activities of proteins, mR NA levels, or transcrip- tion rates) in response to experimental perturbations (rep resenting the eect of hormones, growth factors, neurotransmitters, or of pharma cological interventions). TheMratechnique was employed in [73] in order to discover positive and negative feedback eects in the Raf/Mek/Erk MAPK network in rat uncover connectivity dierences depe nding on whether the cells are stimulated by epidermal growth factor ( EGF) or by neuronal growth factor (NGF), with perturbations consisting of downregulating prote in levels by means of RNAi. A schematic diagram for the Mra approach is shown in Fig. 5.15. Before describing the methodology, we rst describe the ingredien ts of the method. The model ( /C9/BD)The model of the biological system considered in the Mra ap- proach is the dierential equation model described in Secti on via =/parenleftbig n(t)/parenrightbig , represent quantities that can be measured , such as the levels of activity of selected pro- teins or transcription rates of certain genes. The paramete rs (inputs) ui's, collected into a vector u=/parenleftbig u1,...,u m/parenrightbig , represent quantities that can be per- turbed, perhaps indirectly, such as total levels of protein s whose half-lives are long compared to the rate at which the variables evolve, but, once changed, they remain constant for the duration of the biological expe riment. A basic assumption in this approach is that states converge to stead y state values, and these are the values used for network reconstruction (bu t see [78] for a time-dependent analysis). There is also a reference value \u00af uofu, which repre- sents \"wild type\" ( i.e., normal) conditions, steady state \u00afx; mathematically, f/parenleftbig \u00af x,\u00af u/parenrightbig = 0. A mild technical assumption that is necessary is that, for each vector of parameters uin a neighborhood of \u00af u, there is a unique steady state (u)of the system where is a dierentiable function. Required biological experiments ( /C9/BE)The required experimental protocol al- lows one to perturb any one of the parameters, say uj, while leaving the re- maining ones constant. For the perturbed vector u\u00af u, measurements are done of the perturbed steady state vector x=(u), which is an unique func- tion ofu. This read-out might be done through methods such as Western blots or DNA microarrays. When the parameter ujis perturbed, numbers into an\u00d7mmatrixB=/parenleftbig bi,j/parenrightbig . This approach makes a general position as- sumption that all subsets of ncolumns of Bare linearly independent; this entails notheoretical loss of generality since the entries of Bcorrespond to experimental data; however in actual implementations this may lead to nu-158 CELLULAR INTERACTION NETWORKS merical instabilities (see [78] for an analysis of numerica l aspects as well as the eect of errors and noise). Quality of output of the approach ( /C9/BF)This approach is expected to obtain information regarding the signsandrelative magnitudes of the partial deriva- tivefi xj(\u00af x,\u00af another variablexi,e.g.,fi xj>0means that xjhas a catalytic (excitory) of formation of xi, whilefi xj<0indicates inhibition. Known prior information The critical assumption is that, while one may not know the algebraic form of the vector eld fin system (5.1), often it is known which parameters pjdirectly aect which variables xi. For example, ximay be the level of activity of a particular protein and pjmight be the total amount (active plus inactive) of that protein in a cell. This prior i nformation is sum- marized by xbe the Jacobian matrix with respect to state variables, and l etC be the negative off u, the Jacobian matrix with respect to the parameters. Since f((u),u)is identically zero, we may take derivatives with respect to u, and use the chain rule of derivatives to obtain that C=AB. The experimental design question we need to address is as fol lows. We wish to obtain as much information as possible about the matrix A. However, each parameter perturbation experiment involves a cost(resources, experimental di- culties, etc.), which we would like to minimize . We can think of these experiments as \"queries\" that return a column BiofBif theithparameter uiis perturbed. Observe that the matrix C0tells us which rows of Ahave zero inner product with whichBi. This leads us to the linear algebraic question shown in Fig. 5.16. Instance : two matrices ARn\u00d7nandBRn\u00d7msuch that Ais unknown; Bisinitially unknown but each of its mcolumns, denoted asB1,B2,...,B m, can be retrieved with a unit-cost query , the columns of Bare in general position, and the zero structure of the matrix C=AB=/parenleftbig ci,j/parenrightbig is known, i.e., a binary matrix C0=/parenleftbig i,j= 0. Goal: obtain as much information as possible about Awhile perform- ing as few queries as possible. Figure 5.16 Linear algebraic formulation of the experimental design qu estion for the Mraapproach.REVERSE ENGINEERING OF BIOLOGICAL NETWORKS 159 The question is: exactly how much information about Awe can obtain in the above formulation ? Notice that there are always intrinsic limits to what can be accomplished: if we multiply each row of Aby some non-zero number, then the zero structure of Cis unchanged. To help the reader appreciate this question, w e discuss the following concrete example from [14]. Consider the following instance of the linear algebraic formulation: C0= 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 , A= 1 1 3 21 4 0 01 , B= 4 3 37 1 10 4 5 52 2 16 0 05 01 and suppose that we perform four queries corresponding to th e columns 1,3,4and 5ofBto obtain the following data: 4 37 1 10 4 52 2 16 05 01 (5.3) Let us rst attempt to identify the rst row A1ofA. The rst row of the matrix C0tells us that the vector A1is orthogonal to the rst and second columns of (5.3) (which are the same as the rst and third columns of B, respectively). This is the onlyinformation about Athat we have available, and it is notenough information touniquely determineA1, because there is an entire line that is orthogonal to the plane spanned by these two columns. However, we can still nd some non-zero vector in this line, and conclude that A1is an unknown multiple of this vector. This non-zero vector may be obtained by simple linear algebr a manipulations (cf. Exercise 5.14). Similarly, we may use the last two columns of (5.3) to estimate the second row of A, again only up to a multiplication by a constant, and the rst and third columns of (5.3) to estimate the third row of A. Thus, as in the example, the best that we can hope for is to identify the rows of Aup to scalings, or in other words the signs of the entries of A, which is precisely what the Mra approach promises. At this point, two important questions remain to be answered : ( /A0/CP)How much prior information via the matrix C0(i.e., how many zero entries in C0) is needed to determine A, exactly or almost exactly, up to scalings? ( /A3/CQ)Assuming we have sucient prior information as suggested by an answer to ( /A0/CP), how do we nd a minimal or near-minimal set of perturbation ex periments to determineA? To assist us in answering these questions, we reformulate th e linear algebraic version of the problem in Fig. 5.16 in the following manner. Let Aidenote theithrow ofA. Then the specication of C0amounts to each pair iandjfor whichc0 \"\" indicates the orthogonal complement operation. Now if the set of indices Jhas the property i= 1,2,...,n:/vextendsingle/vextendsingleJi/vextendsingle/vextendsinglenk (5.4) for some given integer kthen, via the general position assumption, the space HJ,i has dimension of at leastnk, and hence the space H J,ihas a dimension of at mostk. We now discuss the answers to questions ( /A0/CP) and ( /A3/CQ) for various values of k. The case of k= 1 This is the most desirable special case since the dimension o f H J,ibeing at most 1implies that each Aiisuniquely determined up to a scalar multiple, providing the best possible answer to question ( /A0/CP). Assuming that the degenerate caseH J,i=/braceleftbig 0/bracerightbig does not hold (which would determine Ai= 0), once an arbitrary non-zero element vin the lineH J,ihas been picked, there are only two sign patterns possible for Ai(the pattern of vand that ofv). If, in addition, one knows at least one nonzero sign in Ai, then the sign structure of the whole row has been uniquely determined. For the Mra setup, typically one such sign is indeed known; for example, the ithelement of each Aiis known to be negative as it represents a degradation rate. Thus, to settle question ( /A3/CQ), we need to solve the 1,2,...,m/bracerightbig such that/vextendsingle/vextendsingleJ/vextendsingle/vextendsingleis minimum ( i.e., dierent experiments have a dierent associ- ated cost), this problem must be modied to that of minimizin g a suitable linear combination of costs, instead of the number of queries. The more general case of k >1More generally, suppose that the queries that we performed satisfy the constraint/vextendsingle/vextendsingleJi/vextendsingle/vextendsinglenkwithk >1but still small k. It isno longer true that there are only two possible sign patterns for any given Ai. However, Berman et al. [14-16] show that the number of possibilities is still small. We refer the reader to [14-16] for precise bounds that answers question ( /A0/CP). To answer question ( /A3/CQ), we need to solve a more general version of Problem (5.5), namely the following: It is possible to show by a simple transformation that (5.6) can be written down in the form of t he combinatorialREVERSE ENGINEERING OF BIOLOGICAL NETWORKS 161 combinatorially equivalent reformulation (5.6). (*comment : greedy approach *) I=, uncovered =U while uncovered select program ( LP) minimize/summationtextm j=1xj subject to uiU:/summationtext j:uiSjxj1 j {1,2,...,m}:xj0 the repeat Figure 5.18 Two well-known algorithms to solve SC1[84]. problem in Fig. 5.17 (cf. Exercise 5.15). Problem SCis in fact the (unweighted) set multicover in the combinatorial algorithms commun ity [84]; SC1is simply called the set cover problem. Let = max i{1,2,...,m}/braceleftbig/vextendsingle/vextendsingleSi/vextendsingle/vextendsingle/bracerightbig denote the maximum number of elements in any set. Two well-known alg orithms for solving SC1are as follows: The greedy approach shown in Fig. 5.18 (a)that repeatedly selects a new set that covers a maximum number of \"not yet covered\" elements. T his algorithm is known to have an approximation ratio of (1+ln)[42,84]. The randomized algorithm shown in (b)is a-approximation with high probability where E[] =O(logn). The rst step in the algorithm is to solve a linear program ( LP) that is a relaxation of an integer linear program (ILP) forSC1. The best way to understand the LPformulation is to imagine as if each variable xjis binary ( i.e., takes a value of 0or1) and interpret the1and the 0value as the set Sjbeing selected or not. There are ecient solutions for any LPproblem [45,60]. However, a solution of the LPmay provide162 CELLULAR INTERACTION NETWORKS non-binary real fractional values for some variables, and t he remaining steps are \"randomized rounding\" steps that transform these real f ractional values to binary values ( 0or1). It is also known that the above approximation bounds for SC1are in fact the best possible theoretical guarantees for SC1[28,83]. select a positive constant to uiU:/summationtext j:uiSjxj j {1,2,...,m}:xj0 let the solution vector be (x 1,x 2,...,x n) form the indices of a family of sets I0={j:cx j1} form the indices of a family of sets 1,2,...,m/bracerightbig \\I0by selecting a set Sj forj/braceleftbig 1,2,...,m/bracerightbig \\I0with probability cx j form the indices a family of sets I2by greedy choices: ifanuiUbelongssets injI0I1Sjand < then choose any sets containing uifrom the remaining sets whose index is not in I0I1 endif I=I0I1I2 Figure 5.19 Improved randomized approximation algorithm The greedy approach shown in Fig. 5.18 (a)can be easily generalized for >1 by selecting at each iteration a new set that covers the maxim um number of those elements that has not been covered at least times yet; the resulting algorithm still has an approximation ratio An improved randomized approximation algorithm for SCwhen >1was provided by Berman et al. [14] and is shown in Fig. 5.19. This algorithm has an approximation NETWORKS 163 Note that, if k= 1then=n1and consequently 1; thus, in this case the algorithm in Fig. 5.19 returns an almost optimal solution in expectation . 5.4.2 Parsimonious combinatorial approaches In this section, we discuss a few parsimonious combinatoria l approaches for reverse engineering causal relationships between components of a b iological system. These methods make use of time-varying measurements of relevant v ariables ( e.g., gene expression levels) of the system. The causal relationships reconstructed can be synthesized to a Boolean circuit, if needed. Before going into the details of the method and its ingredien ts, we explain a key idea behind the method using an example. Suppose that we a re measuring the expression levels of 5genes /BZ1, /BZ2, /BZ3, /BZ4and /BZ5to determine their causal relationships. Consider two adjacent times of measurement s, sayt=andt=+1, and suppose that the measurements are as in Fig. 5.20 (a). measurements t= t=+1 variablesx1 3 2 x2 1 1 x3 /BZ2, variable xicorrespond to gene /BZi.(b)A causal relationship and Boolean formula that explains the causal relationship o f other variables to x5based only on the data shown in (a).(c)Another causal relationship and Boolean formula for /BZ5that is consistent with the data in (a). Suppose that we wish to reconstruct a causal relationship of every other gene to gene /BZ5that is consistent with this given data. Note that the variab lex5changes its value between the two successive time intervals and this cha ngemustbe caused by other variables. The variable x2retains the same value 1during the two successive time intervals, so the change of value of x5must be caused by at least one of the three other variables x1,x3andx4. Intuitively, this explanation of observed data makes the assumption that the regulatory network for x1,...,x ncan be viewed as adynamical system that is described by a function f:XnmsoXnthat transforms an \"input\" state x=/parenleftbig x1,x2,...,x n/parenrightbig XnNnof the network at a step to an \"output\" state x=/parenleftbig x 1,...,x n/parenrightbig of the network at the nexttime step, and a directed edge xixjin the graph for the network topology of this dynamical system indicates that the value of xjunder the application of fdepends on the value ofxi. Thus, our reconstructed causal relationships can be summa rized by the arcs shown in Fig. 5.20 (b), where the presence of an arc, say x1x5, indicates164 CELLULAR INTERACTION NETWORKS thatx1may have an influence on x5. A Boolean formula that explains this also be obtained. Notice that a reconstructed causal relationship may notbe unique. For example, Fig. 5.20 (c)shows that omitting the dependency of x5onx3still explains the ob- served data in Fig. 5.20 (a)correctly. In fact, the most that such a reconstruction method can claim is that x5should depend on at least one of the three variables x1,x3orx4. The combinatorial approaches discussed in this section ar e ofparsimo- nious nature in the sense they attempt to choose a network with a minimal number of causal relationships that explains the given data; for th e example in Fig. 5.20 (a) such a method will select only one of the three possible causa l relationships. A min- imal network can be recovered by using the so-called hitting set problem. However, as we have already observed in Section 5.3.4, biological net works do not necessarily have the lowest possible redundancy, and thus we will need su itable modications to the approach to introduce redundancy. We now discuss more details of the two combinatorial approac hes based on the above ideas which have been used by other researchers. 5.4.2.1 Approach by Ideker et al. [38] In this approach, a set of sparse networks, each from a dierent perturbation to the genetic network und er investigation, is generated, the binarized steady-states of gene expression proles of these networks are observed, and then, using the idea explained in the previ ous section, a set of Boolean networks consistent with an observed steady-sta tes of the expression proles is estimated. Next, an \"optimization step\" involvi ng the use of an entropy- based approach is used to select an additional perturbation experiment in order to perform a selection from the set of predicted Boolean networ ks. Computation of the sparse networks rely upon the hitting set problem. To acc ount for non-minimal nature of real biological networks, one can modify the hitti ng set algorithm to add redundancies systematically by allowing additional parameters to control the extra connections. X= 0 1 2 3 0 1 2 0 0 0 3 1 1 0 0 0 0 1 2 1 0 1 1 1 (a)measurements over time t/BZ=/braceleftig/BZ 1, xi,j/parenrightbig (quantized to four values) for measurement of expression levels of m= 5genes at n+ 1 = 4 time points. (b)The universe and sets corresponding to gene /BZ2in the hitting set formulation of Fig. 5.22 (a). 5.4.2.2 Approach by Jarrah et al. [39] This approach uses one or more time courses of observed data on gene expression levels. Such dat a can be represented by am\u00d7(n+ 1)matrixX=/parenleftbig xi,j/parenrightbig wheremis number of variables (molecularREVERSE ENGINEERING NETWORKS 165 species) and n+ 1is the number of points of times at which observations were made. For example, a m= 5species data (quantized to four values) at n+1 = 4 time instances is shown in Fig. 5.21 (a). Suppose that we wish to construct a causal relation for gene /BZicorresponding to the ithrow ofX. Consider two Ti j= /braceleftbigg/BZ /vextendsingle/vextendsingle/vextendsingle/vextendsinglex,j1\\e}io\\slsh=x,jand\\e}io\\slsh=i/bracerightbigg ,ifxi,j1\\e}io\\slsh=xi,j , otherwise Then, at least one gene in Ti jmust have a causal eect on /BZi. Repeating the argument for j= 1,3,...,n , we arrive at the so-called hitting set problem shown in Fig. 5.22 (a). Problem name: Hitting set the combinatorial approach for gene /BZi. (b)A greedy algorithm for HSthat iteratively selects a new element of the universe that hits a maximum number of sets not hit yet. HSis the combinatorial dual of the SC1problem introduced in Fig. 5.17. The duality transformation between HSandSC1is ,j:uSj /BZ jTi (5.7) Thus, to solve HS, we can simply transform it to an equivalent instance of SC1 and use the methods described before. A more direct greedy ap proach to solve HSis shown in Fig. 5.22 (b): we repeatedly pick a new element that is contained in a maximum number of sets none of whose elements have been se lected yet. This greedy algorithm can be shown to have an approximation r atio of\u00b5, where166 CELLULAR INTERACTION NETWORKS \u00b5= max 1m/vextendsingle/vextendsingle/vextendsinglej/vextendsingle/vextendsingle/BZ Ti j/vextendsingle/vextendsingle/vextendsingleis the maximum number of sets in which an element belongs [84]. Finally, to allow for non-minimal nature of real biological networks, redundancy can be easily introduced by allowing additional edges in the network in a \"con- trolled\" manner that is consistent with the given data. For t his purpose, we need to generalize the HSproblem to \"multi-hitting\" version when more than one ele- ment from each may need to be picked. Formally, let = (1,2,..., n)Nnbe a vector whose components are positive integers; the positi ve integerjindicates that at least jelements need to be selected from the set Ti j. Then, HScan be generalized to the problem HS by replacing the each constrain/vextendsingle/vextendsingleF/intersectiontextTi j/vextendsingle/vextendsingle1 in Fig. 5.22 (a)by/vextendsingle/vextendsingleF/intersectiontextTi j/vextendsingle/vextendsinglej. It is easy to modify the greedy algorithm for HSin Fig. 5.22 (b)to nd a valid solution of HS . 5.4.2.3 Comparative analysis of the two approaches DasGupta et al. in [23] com- pared the two combinatorial reverse engineering approache s discussed in Section 5.4.2.1 and Section 5.4.2.2 on the following two biological network s: (1)An articial gene regulatory network with external perturb ations generated using the software package in [61]. The interactions betwee n genes in this regulatory network are phenomenological, and represent th e net eect of tran- scription, translation, and post-translation modicatio ns on the regulation of the genes in the network. (2)Time courses from a Boolean network of segment polarity gene s responsible for pattern formation in the embryo of Drosophila melanogaster (fruit fly). This Boolean model, based on the binary ON/OFFrepresentation of mRNA and protein levels of ve segment polarity genes, was validated and analyzed by Albert and Othmer in [7]. For the approach by Ideker et al., the redundancy vector used was of the form (r,r,...,r )forr= 1,2,3. For network (1), Jarrah et al.'s method obtained better results than Ideker et al.'s method, although both fare very poorly. In contrast, for network (2), Jarrah et al.'s method could not obtain any results after running their method for over 12hours, but Ideker et al.'s method was able to compute results for such network in less than 1minute, and the results of Ideker et al.'s method improved slightly for larger values of r. The reader is referred to [23] for further details about the comparison. 5.4.3 Evaluation of quality of the reconstructed network By the very nature, the reverse-engineering problems are hi ghly \"ill-posed\" in the sense that solutions are far from unique . This lack of uniqueness stems from the many sources of uncertainty such as: measurement error, stochasticity of molecular processes, hidden variables, i.e., lack of knowledge of allthe molecular species that are involved in the behavior being analyzed.REVERSE ENGINEERING OF BIOLOGICAL NETWORKS 167 Thus, reverse-engineering methods can at best provide approximate solutions for the network that is to be reconstructed, making it dicult to evaluate their perfor- mance through a theoretical study. Instead, their performa nce is usually assessed empirically in the following two ways. 5.4.3.1 Experimentaltestingofpredictions After a network has been reconstructed, the newly found interactions or predictions can be tested ex perimentally for network topology and network dynamics inference, respectively. 5.4.3.2 Benchmark testing This type of performance evaluation consists on mea- suring how close the reverse engineering method under investigation is from re- covering a known network, usually referred to as the \"gold standard\" network . In the case of dynamical models, one evaluates the ability of th e method of interest to reproduce observations that were not taken into account i n the training phase involved in the construction of the model. For methods that o nly reconstruct the network topology, a variety of standard metrics, such as the ones described below, may be applied. Metrics for network topology benchmarking LetGis the graph representing the network topology of a chosen gold standard network, and Let /tildewideGbe the graph representing the network topology inferred by the reverse e ngineering method. Each interaction in/tildewideGcan be classied into one of the following four classes when comparing to the gold standard: True positive ( TP):exists both in Gand in/tildewideG. False positive ( /tildewideGbut not in G. True negative ( TN):does not exist both in Gand in/tildewideG. False negative ( FN):does not exist in /tildewideGbut exists in G. LetnTP,nFP,nTN,nFNandntotalbe the number of true positives, false positives, true negatives, false negatives and total number of possibl e interactions in the network, respectively. Four standard metrics for benchmar king are as follows: recall rate or true positive rate TPR=nTP nTP+nFN false positive rate FPR=nFP nFP+nTN accuracy rate ACC=nTP+nTN precision or positive predictive value PPV=nTP nTP+nFP Since reverse-engineering problems are under-constraine d, usually the network reconstruction algorithm will have one or more free paramet ers that helps to select a best possible prediction. For example, components of redu ndancy vector in the hitting set approach could be a set of such type of parameters . In this case, a more objective evaluation of performance needs to involve a range of parameter values. A standard approach to evaluate performance across the rang e of parameters is the receiver operating characteristic (Roc) method based on the plot of FPRversus168 CELLULAR INTERACTION NETWORKS TPRvalues. The resulting Rocplotdepicts relative trade-os between true posi- tive predictions and false positive prediction across die rent parameter values; see Fig. 5.23 for an illustration. An alternative plot is the recall precision plot obtained by plotting TPRversus PPVvalues. random guess performance better than random performance same performance as random guess worse than random performance Figure 5.23 Two dimensional Rocspace obtained by plotting FPRversus TPRvalues. Examples of gold standard networks We give two examples of gold standard net- works that can be used for benchmark testing of reverse engin eering methods. Further discussion on generation of gold standard networks can be found later in Section 6.3.3.1. ( /A6/CX)Gene regulatory networks with external perturbations can b e generated from the dierential equation models using the software package in [61]. ( /A6/CX/A6/CX)Time courses can be generated from the Boolean model of netwo rk of segment polarity genes involved in pattern formation in the Drosophila melanogaster embryo. This model was proposed by Albert and Othmer [7]; the network for each cell has 15nodes. REFERENCES 1. B. Alberts. Molecular biology of the cell, New York: Garla nd Publishers, 1994. 2. R. Albert and A.-L. Barab\u00e1si. Statistical mechanics of co mplex networks, Reviews of Modern Physics, 74 (1), 47-97, 2002. 3. R. Albert, B. DasGupta, A. Gitter, G. G\u00fcrsoy, R. Hegde, P. P al, G. S. Sivanathan and E. Sontag. A New Computationally Ecient Measure of Topo logical Redun- dancy of Biological and Social Networks, Physical Review E, 84 (3), 036117, 2011. 4. R. Albert, B. DasGupta, R. Dondi and E. Sontag. Inferring ( Biological) Signal Transduction Networks via Transitive Reductions Direct ed Graphs, Algorith- mica, 51 (2), 129-159, 2008.REVERSE ENGINEERING OF BIOLOGICAL NETWORKS 169 5. R. Albert, B. DasGupta, R. Dondi, S. Kachalo, E. Sontag, A. Zelikovsky and Novel Method for Signal Transduction Netwo rk Inference from Indirect Experimental Evidence, Journal of Computational Biology, 14 (7), 927- 949, 2007. 6. R. Albert, B. DasGupta and E. Sontag. Inference of signal t ransduction networks from double causal evidence, in Methods in Molecular Biolog y: Topics in Compu- tational Biology, D. Fenyo (ed.), 673, Chapter 16, Springer , 2010. 7. R. Albert and H. Othmer. The topology of the regulatory int eractions predicts the expression pattern of the segment polarity genes in Drosophila melanogaster , Journal of Theoretical Biology, 223, 1-18, 2003. 8. M. Andrec, B. N. Kholodenko, R. M. Levy, and E. D. Sontag. In ference of Sig- naling and Gene Regulatory Networks by Steady-State Pertur bation Experiments: Structure and Accuracy, Journal of Theoretical Biology, 23 2, 427-441, 2005. 9. D. Angeli and E.D. Sontag. Monotone control systems, IEEE Transactions on Automatic Control, 48, 1684-1698, 2003. 10. J. Aracena, M. Gonz\u00e1lez, A. Zu\u00f1iga, M. M\u00e9ndez and V. Cambi azo. Regulatory network for cell shape changes during Drosophila ventral fu rrow formation, Journal of Theoretical Biology, 239 (1), 49-62, 2007. 11. M.J. Beal and F. Falciani. A Bayesian approach to reconst ructing genetic regula- tory networks with hidden factors, Bioinformatics, 21 (3), 349-356, 2005. 12. N. Beckage, L. Smith and T. Hills. Semantic network conne ctivity is related to vo- cabulary growth rate in children, Annual Meeting of The Cogn itive Science Society, 2769-2774, 2010. 13. P. Berman, B. DasGupta and M. Karpinski. Approximating T ransitive Reduction Problems for Directed Networks, Algorithms and Data Struct ures Symposium, F. Dehne, M. Gavrilova, J.-R. Sack and C. D. T\u00f3th (eds.), LNCS 56 64, 74-85, 2009. 14. P. Berman, B. DasGupta and E. Sontag. Randomized Approxi mation Algorithms for Set Multicover Problems with Applications to Reverse En gineering of Protein and Gene Networks, Discrete Applied Mathematics, 155 (6-7) , 733-749, 2007. 15. P. Berman, B. Sontag. Computational Comp lexities of Combina- torial Problems With Applications to Reverse Engineering o f Biological Networks, in Advances in Computational Intelligence: Theory and Appl ications, F.-Y. Wang and D. Liu (editors), Series in Intelligent Control and Inte lligent Automation Vol- ume 5, World Scientic publishers, 303-316, 2007. 16. P. Berman, B. DasGupta and E. Sontag. Algorithmic Issues in Reverse Engineering of Protein and Gene Networks via the Modular Response Analys is Method, Annals of the New York Academy of Sciences, 1115, 132-141, 2007. 17. J. A. Bondy and U. S. R. Murty. Graph Theory, Springer, 200 8. 18. T. Chen, V. Filkov and S. Skiena. Identifying Gene Regula tory Networks from Experimental Data, Third Annual International Conference on Computational Moledular Biology, 94-103, 1999. 19. D.-Z. Cheng, H. Qi, and Z. Li. Analysis and control of bool ean networks: A semi- tensor product approach, London: Springer, 2011. 20. T. H. Cormen, C. E. Leiserson, R. L. Rivest and C. Stein. In troduction to Algo- rithms, The MIT Press, 2001. 21. E. J. Crampin, S. Schnell, and P. E. McSharry. Mathematic al and computational techniques to deduce complex biochemical reaction mechani sms, Progress in Bio- physics & Molecular Biology, 86, 77-112, 2004.170 CELLULAR INTERACTION NETWORKS 22. B. DasGupta, G. A. Enciso, E. Sontag and Y. Zhang. Algorit hmic and complex- ity results for decompositions of biological networks into monotone subsystems, Biosystems, 90 (1), 161-178, 2007. 23. B. DasGupta, P. Vera-Licona and E. Sontag. Reverse Engin eering of Molecular Networks from a Common Combinatorial Approach, in Algorith ms in Computa- tional Molecular Biology: Approaches ications, M. and A. Zomaya (editors), 941-955, Chapter 40, John Wiley & So ns, Inc., 2011. 24. L. Dall'Asta, I. Alvarez-Hamelina, A. Barrata, A. V\u00e1zqu ezb and A. Vespignania. Exploring with traceroute-like probes: Theory an d simulations, Theoret- ical Computer Science, 355, 6-24, 2006. 25. E. H. Davidson. The regulatory genome, Academic Press, 2 006. 26. N. Dojer, A. Gambin, A. Mizera, B. Wilczynski and J. Tiury n. Applying dynamic Bayesian networks to perturbed gene expression data, BMC Bi oinformatics, 7 (1), 249, 2006. 27. G. Enciso and E. Sontag. On the stability of a model of test osterone dynamics, Journal of Mathematical Biology, 49, 627-634, 2004. 28. U. Feige. A threshold for approximating set cover, Journ al of the ACM, 45, 634-652, 1998. 29. S. Fields. High-throughput two-hybrid analysis: the pr omise and the peril, FEBS Journal, 272 (21), 5391-5399, 2005. 30. N. Friedman, M. Linial, I. Nachman and D. Pe'er. Using Bay esian Networks to Analyze Expression Data, Journal of Computational Biology , 7 (3-4), 600-620, 2000. 31. C. Friedman, P. Kra, H. Yu, M. Krauthammer and A. Rzhetsky . GENIES: a natural-language processing system for the extraction of m olecular pathways from journal articles, Bioinformatics, 17 (Suppl 1), S74-82, 20 01. 32. A. de la Fuente, N. Bing, I. Hoeschele and P. Mendes. Disco very of meaningful associations in genomic data using partial correlation coe cients, Bioinformatics, 20, 3565-3574, 2004. 33. L. Giot, J. S. Bader, C. Brouwer, A. Chaudhuri, B. Kuang, Y . Li, Y. L. Hao, C. E. Ooi, B. Godwin, E. Vitols, G. Vijayadamodar, P. Pochart, H . Machineni, M. Welsh, Kong, B. Zerhusen, R. Malcolm, Z. Varrone, A. Colli s, M. Minto, S. Burgess, L. McDaniel, E. Stimpson, F. Spriggs, J. Williams, K. Neurath, N. Ioime, M. Agee, E. Voss, K. Furtak, R. Renzulli, N. Aanensen, S. Carr olla, E. Bickelhaupt, Y. Lazovatsky, A. DaSilva, J. Zhong, C. A. Stanyon, R. L. Finl ey, K. P. White, M. Braverman, T. Jarvie, S. Gold, M. Leach, J. Knight, R. A. Sh imkets, M. P. McKenna, J. Chant and J. M. Rothberg. A protein interaction m ap of Drosophila melanogaster, Science, 302 (5651), 1727-1736, 2003. 34. M. Girvan and M. E. J. Newman. Community structure in soci al and biological networks, Proceedings of the National Academy of Sciences U SA, 99, 7821-7826, 2002. 35. R. Guimer\u00e0, M. Sales-Pardo and L. A. N. Amaral. Classes of complex networks dened by role-to-role connectivity proles, Nature Physi cs, 3, 63-69, 2007. 36. J. Hann and M. Kamber. Data Mining: Concepts and Techniqu es, Morgan Kauf- man Publishers, 2000. 37. S. Huang. Gene expression proling, genetic networks an d cellular states: an integrating concept for tumorigenesis and drug discovery, Journal of molecular medicine, 77 (6), 469-480, 1999.REVERSE ENGINEERING OF BIOLOGICAL NETWORKS 171 38. T. E. Ideker, V. Thorsson and R. M. Karp. Discovery of regu latory interactions through perturbation: inference and experimental design, Pacic Symposium on Biocomputing, 5, 305-316, 2000. 39. A. S. R. Stigler and M. Stillman . Reverse-engineering polynomial dynamical systems, Advances in Applied Mathema tics, 39 (4) 477-489, 2007. 40. L. J. Jensen, J. Saric and P. Bork. Literature mining for t he biologist: from infor- mation retrieval to biological discovery, Nature Review Ge netics, 7 (2), 119-129, 2006. 41. H. Jeong, B. Tombor, R. Albert, Z. N. Oltvai and A.-L. Bara b\u00e1si. The large-scale organization of metabolic networks, Nature, 407, 651-654, 2000. 42. D. S. Johnson. Approximation Algorithms for Combinator ial Problems, Journal of Computer and Systems Sciences, 9, 256-278, 1974. 43. S. Kachalo, R. Zhang, E. Sontag, R. Albert and B. DasGupta . NET-SYNTHESIS: A software synthesis, gnal transduction net- works, (2), S. Vempala. Markov-chain algori thms for generating bipartite graphs and tournaments, Random Structures and Al gorithms, 14, 293- 308, 1999. 45. N. Karmarkar. A New Polynomial-time Algorithm for Linea r Programming, Com- binatorica, 4, 373-395, 1984. 46. S. A. Kauman. Metabolic stability and epigenesis in ran domly constructed genetic nets, Journal of Theoretical Biology, 22, 437-467, 1969. 47. B. N. Kholodenko, A. Kiyatkin, J. Wires: A Novel Strategy to Trace Func tional Interactions in Signaling and Gene Networks, Proceedings of the National Academy of Sciences USA, 99, 12841-12846, 2002. 48. B. N. Kholodenko and E.D. Sontag. Funct physics/0 205003, May 2002. 49. B. Kolb and I. Q. Whishaw. Fundamentals of Human Neuropsy chology, Freeman, New York, 1996. 50. S. Khuller, B. Raghavachari and N. Young. On strongly con nected digraphs with bounded cycle length, Discrete Applied Mathematics, 69 (3) , 281-289, 1996. 51. S. Khuller, B. Raghavachari and N. Young. Approximating the minimum equivalent digraph, SIAM Journal of Computing, 24 (4), 859-872, 1995. 52. B. Krupa. On the Number of Experiments Required to Find th e Causal Structure of Complex Systems, Journal of Theoretical Biology, 219 (2) , 257-267, 2002. 53. R. J. Larsen and M. L. Marx. An Introduction to Mathematic al Statistics and Its Applications, Third Edition, 2000. 54. E. A. Leicht and M. E. J. Newman. Community Structure in Di rected Networks, Physical Review Letters, 100, 118703, 2008. 55. S. Li, C. M. Armstrong, N. Bertin, H. Ge, S. Milstein, M. Bo xem, P.-O. Vidalain, J.-D. J. Han, A. Chesneau, T. Hao, D. S. Goldberg, N. Li, M. Mar tinez, J.-F. Rual, P. Lamesch, L. Xu, M. Tewari, S. L. Wong, L. V. Zhang, G. F. Berr iz, L. Jacotot, P. Vaglio, J. Reboul, T. Hirozane-Kishikawa, Li, H. W. Gab el, A. Elewa, B. Baumgartner, D. J. Rose, H. Yu, S. Bosak, R. Sequerra, A. Fras er, S. E. Mango, W. M. Saxton, S. Strome, S. van den Heuvel, F. Piano, J. Vanden haute, C. Sardet,172 CELLULAR INTERACTION NETWORKS M. Gerstein, L. Doucette-Stamm, K. C. Gunsalus, J. W. Harper , M. E. Cusick, F. P. Roth, D. E. Hill, and M. Vidal. A map of the interactome ne twork of the metazoan C. elegans , Science, 303, 540-543, 2004. 56. T. I. Lee, N. J. Rinaldi, F. Robert, D. T. Odom, Z. Bar-Jose ph, G. K. Gerber, N. M. Hannett, C. T. Harbison, C. M. Thompson, I. Simon, J. Zei tlinger, E. G. Jennings, H. L. Murray, D. B. Gordon, B. Ren, J. J. Wyrick, J.- B. Tagne, T. L. Volkert, E. Fraenkel, D. K. Giord, and R. A. Young. Transcri ptional networks in Saccharomyces cerevisiae , Science, 298 (5594), 799-804, 2002. 57. S. Li, S. M. Assmann and R. Albert. Predicting Essential C omponents of Signal Transduction Networks: A Dynamic Model of Guard Cell Abscis ic Acid Signaling, PLoS Biology, 4(10), e312, 2006. 58. A. Ma'ayan, S. L. Jenkins, S. Neves, A. Hasseldine, E. Gra ce, B. Dubin-Thaler, N. J. Eungdamrong, G. Weng, P. T. Ram, J. J. Rice, A. Kershenba um, G. A. Stolovitzky, R. D. Blitzer and R. Iyengar. Formation of Regu latory Patterns During Signal Propagation in a Mammalian Cellular Network, Scienc e, 309 (5737), 1078- 1083, 2005. 59. E. M. Marcotte, I. Xenarios D. Eisenberg. Mining lite rature for protein-protein interactions, Bioinformatics, 17 (4), 359-363, 2001. 60. N. Megiddo. Linear programming in linear time when the di mension is xed, Jour- nal of ACM, 31, 114-127, 1984. emical Trends in Biochemical Sciences, 22, 361-363, 1997 . 62. J. D. Murray. Mathematical Biology, I: An introduction, New York, Springer, 2002. 63. N. Nariai, Y. Tamada, S. Imoto and S. Miyano. Estimating g ene regulatory net- works and protein-protein interactions of Saccharomyces c erevisiae from multiple genome-wide data, Bioinformatics, 21 (suppl 2), ii206-ii2 12, 2005. 64. M. E. J. Newman. The structure and function of complex net works, SIAM Review, 45, 167-256, 2003. 65. M. E. J. Newman. Detecting community structure in networ ks, European Physics Journal B, 38, 321-330, 2004. 66. M. E. J. Newman and G. T. Barkema. Monte Carlo Methods in St atistical Physics, Oxford University Press, 1999. 67. M. E. J. Newman and M. Girvan. Finding and evaluating comm unity structure in networks, Physical Review E, 69, 026113, 2004. 68. M. E. J. Newman, S. H. Strogatz and D. J. Watts. Random grap hs with arbitrary degree distributions and their applications, Physical Rev iew E, 64 (2), 026118- 026134, 2001. 69. J. A. Papin and B. O. Palsson. Topological analysis of mas s-balanced signaling networks: a framework to obtain network properties includi ng crosstalk, Journal of Theoretical Biolology, 227 (2), 283-297, 2004. 70. I. Pournara and L. Wernisch. Reconstruction of gene netw orks using Bayesian learning and manipulation experiments, Bioinformatics, 2 0 (17), 2934-2942, 2004. 71. E. Ravasz, A. L. Somera, D. (5586), 1551-1555, 2002. Y. Tu and G. Stolovitzky. Reconstructing biol ogical networks using con- ditional correlation analysis, Bioinformatics, 21 (6), 76 5-773, 2005.EXERCISES 173 73. S. D. M. Santos, P. J. Verveer, and P. I. H. Bastiaens. Grow th factor-induced MAPK network topology shapes Erk response determining PC-1 2 cell fate, Nature Cell Biology, 9, 324-330, 2007. 74. S. S. Shen-Orr, R. Milo, S. Mangan and U. Alon. Network mot ifs in the transcrip- tional regulation network of Escherichia coli , Nature Genetics 31, 64-68, 2002. 75. H. L. Smith. Monotone Dynamical Systems, Providence, R. I., AMS 1995. 76. E. D. Sontag. Mathematical Control Theory: Determinist ic Finite Dimensional Systems, Springer, New York, 1998. 77. E. D. Sontag. Molecular systems biology and control, Eur opean Journal of Control, 11 (4-5), 396-435, 2005. 78. E. D. Sontag, A. Kiyatkin and B. N. Kholodenko. Inferring Dynamic Architecture of Cellular Networks Using Time Series of Gene Expression, P rotein and Metabolite Data, Bioinformatics, 20, 1877-1886, 2004. 79. J. Stark, R. Callard and M. Hubank. From the Top Down: Towa rds a Predictive Biology of Signalling Networks, Trends in Biotechnology, 2 1, 290-293, 2003. 80. G. Tononi, O. Sporns and G. M. Edelman. A measure for brain complexity: relating functional segregation and integration in the nervous syst em, Proceedings of the National Academy of Sciences USA, 91 (11), 5033-5037, 1994. 81. G. Tononi, O. Sporns and G. M. Edelman. A complexity measu re for selective matching of signals by the brain, Proceedings of the Nationa l Academy of Sciences USA, 93, 3422-3427, 1996. 82. G. Tononi, O. Sporns and G. M. Edelman. Measures of degene racy and redundancy in biological networks, Proceedings of the National Academ y of Sciences USA, 96, 3257-3262, 1999. 83. L. Trevisan. Non-approximability results for optimiza tion problems on bounded- degree instance, Thirty third ACM Symposium on Theory of Com puting, 453-461, 2001. 84. V. Vazirani. Approximation Algorithms, Springer-Verl ag, 2001. 85. A. Wagner. Estimating Coarse Gene Network Structure fro m Large-Scale Gene Perturbation Data, Genome Research, 12 (2), 309-315, 2002. 86. J. Yu, V. Smith, P. Wang, A. Hartemink and E Jarvis. Advanc es to Bayesian network inference for generating causal networks from obse rvational biological data, Bioinformatics, 20, 3594-3603, 2004. 87. R. Zhang, M. V. Shah, J. Yang, S. B. Nyland, X. Liu, J. K. Yun , R. Albert and T. P. Loughran, Jr. Network Model of Survival Signaling in LGL Leu kemia, Proceedings of the National Academy of Sciences USA, 105 (42), 16308-163 13, 2008. 88. M. Zou and S. D. Conzen. A new dynamic Bayesian network (DB N) approach for identifying gene regulatory networks from time course micr oarray data, Bioinfor- matics, 21 (1), 71-79, 2005. EXERCISES 5.1 Suppose that your data suggests that Protein A inhibits the t ranscription of the RNA that codes Protein B, whereas Protein B in turn enhanc es the production174 CELLULAR INTERACTION NETWORKS of Protein A. Give a two node regulatory network that is consi stent with this information. 5.2 Consider the following biological Draw the associated signed graph of this model. 5.3 Consider ve genes /BZ1, /BZ2, /BZ3, /BZ4and /BZ5, and suppose that each gene switches its state if the remaining four genes are not in iden tical states. a) Write down the Boolean network and its associated directe d network for the interaction of the ve genes described above. b) Does the Boolean network in 5.3.a has a xed point? If so, sh ow one xed point. 5.4 Show that the reduced network in Fig. 5.8 is not minimal by giv ing a minimal network in which morethan two arcs are removed. 5.5 Consider the following subset of the evidence gathered for t he signal trans- duction network responsible of abscicic acid induced . Follow the network synthesis approach in Fig. 5.4 to synthesize a minimal netwo rk. 5.6 [3] Consider the three signal transduction networks shown i n Fig. 5.24. a) Verify that the two networks shown in (i)and(ii)has the same in-degree and out-degree sequence, the network in (i)and /recipe Tr=3/11 for the network in (ii). Can you give an exact expression of the value of /recipeTrfor the network in (ii)when generalized to have nnodes?EXERCISES v1v1v1v2v2v2v4v4v4v3v3v3v5v5v5v6v6v6v8v8v8v7v7v7 (ii) v6v6v6v7v7v7v8v8v8(iii) Figure 5.24 Threen-node graphs (shown for n= 8) discussed in Exercise 5.6. b) Verify that higher average degree does not necessarily im ply higher values of /recipe Trby showing that the network in (ii), generalized on nnodes, has an average degree below 2, but the graph in (iii), generalized on nnodes, has an average degree of n/2but a redundancy value of 0. 5.7 Argue that the dynamics of the two networks in Fig. 5.13 compu te dierent functions if an ORgate is used to combine the inputs to node c, and all arcs have the same time delay. 5.8 Prove Equation (5.2). 5.9 Convince yourself that Problem (5.6) is indeed a correct for mulation for the case of arbitrary k. 5.10 Show the validity of the equivalence shown in (5.7) between SC1andHS. In other words, show that, assuming the equivalence condition s hold,Si1,Si2,...,S it is a valid solution of SC1if and only if /BZ i1, /BZ i2,..., /BZ itis a valid solution of HS. 5.11 This problems explores some possibilities to improve the ti me and space requirements of the dynamic programming algorithm in Fig. 5 .5 a) Suppose that we remove the third index (corresponding to t he variable kin the loop) from the variable NandP,i.e., instead of N(i,j,k,x)we simply useN(i,j,x)etc. Note that the space requirement is now O/parenleftbig n2/parenrightbig instead ofO/parenleftbig n3/parenrightbig all reachabilities corre ctly? b) In practice, the variable kin the forloop may not need to go until it reaches the value of n. Suggest how we can abort the loop for k= based on the calculations performed during the executing of the loop with k=1. 5.12 In Section 5.3.3.1 we claimed that opt(G)|V|. Prove this. 5.13 Consider the special case of the Trproblem when every arc is excitory (i.e., whenL(u,v) = 1 for every arc (u,v)E). The goal of this problem is to design176 CELLULAR INTERACTION NETWORKS an algorithm for this special case that improves upon the app roximation ratio of 3 of the greedy approach as stated in Theorem 5.1. a) [5] Show that the problem can be solved in polynomial time i f the given graphGhas no cycles of with more than 3arcs. abc abc Figure 5.25 Contraction of a cycle of length 4. b) By contraction of an arc (u,v)Ewe mean merging nodes uandvto a single node, and deleting any resulting self-loops or para llel arcs. By contraction a cycle we mean contraction of every arc of the cy cle; see Fig. 5.25 for an illustration. Consider the following algor ithm: select an integer constant k >3 fori=k,k1,...,4 whileGcontains a cycle Cof at least iedges contract Cand select the edges of Cin our solution endwhile endfor (*comment : nowGcontains no cycle of more than 3edges *) use the algorithm in part a)to solve the Trproblem on Gexactly and select the edges in this exact solution output all selected edges as the solution (i)Show that the above algorithm returns a valid solution of Tr. (ii)[51] Show that if Em=andGis strongly connected then the above algorithm has an approximation ratio of =2 61 36+1 k(k1) 1.617+1 k(k1). c) Use part b) (ii) to provide an algorithm with an approximation ratio of 1+ifEm\\e}io\\slsh=. 5.14 [14] In the example explaining the linear algebraic formula tion of Mra on page 159, we claimed that we can nd a non-zero vector by simpl e linear algebra manipulations such that A1is an unknown multiple of this vector. Show how to nd such a non-zero vector. 5.15 [14] Show that Problem (5.6) can be written down as a problem o f the form shown in Fig. 5.17.CHAPTER 6 DYNAMICAL SYSTEMS AND INTERACTION NETWORKS In this chapter, we view biological models in the framework o f dynamical systems. In this framework, the biological system has a vector x(t) =/parenleftbig x1(t),x2(t),...,x n(t)/parenrightbig ofntime-dependent state variables ( e.g., indicating the concentration of the n proteins in the model at time t), a vector u(t) =/parenleftbig u1(t),u2(t),...,u m(t)/parenrightbig ofmtime- dependent input variables for stimuli to the sy stem, andnfunctions f1,f2,...,f nwherefigoverns the evolution of the state variable xi. Dierent types of system dynamics can be obtained by varying the nature of th ese variables and functions. Discrete versus continuous state variables x1,x2,...,x nThe state variables could be continuous (i.e., real-valued) or discrete (e.g., binary). When state vari- ables are continuous, the evolution of cellular components are assumed to be contin- uous functions of time. In contrast, when the state variable s are discrete, each com- ponent is assumed to have a small number of qualitative state s, and the regulatory interactions are typically described by logical functions such as Boolean circuits; examples of such models are discussed in references [2,19,2 1,34,42,60,72,84,102]. Discrete versus continuous time variable tThe time variable tcan be con- tinuous ordiscrete . Continuous-time models can describe dynamics such as mass - action kinetics ( e.g., see [50, 81, 100]) via dierential equations (such as via sy s- tem (5.1) discussed in Chapter 5) or by delay equations if del ays are important. Discrete-time models involve dierence equations, or they may arise as quantized Models and Algorithms for Biomolecules and Molecular Netwo rks, rst edition. By Bhaskar DasGupta and Jie Liang Copyright \u00a9 2015 John Wiley & S ons, Inc.177178 DYNAMICAL SYSTEMS AND INTERACTION NETWORKS descriptions of continuous-variable systems ( e.g., see [37]). For example, the dis- crete time version of system (5.1) of Chapter 5 using a simple \"Jacobi-type\" iteration with synchronous updates can be concise vector form x(t+1) =f(x(t),u(t))orx+++=f(x,u) Communication delays Delays may result in cellular systems due to dierences in times for transcription, translation, degradation and oth er biochemical processes. Delays can be implemented, for example, by appropriate modi cations of Equa- tions (5.1) or (6.1). For example, in the context of Equation (6.1) suppose that the output of variable xiis delayed by time units to reach variable xj. Then, the modied equation for change of xjcan be written as: xj(t+1) =fj/parenleftbig ......,x i(t+1),....../parenrightbig It is not dicult to see that delays may aect the dynamic beha vior in a non-trivial manner (cf. Exercise 6.1). Deterministic versus stochastic dynamics In a deterministic model, the rules of the evolution of the system is deterministic in nature. In contrast, stochastic models may address the deviations from population homogene ity by transforming reaction rates into probabilities and concentrations into numbers of molecules ( e.g., see [79]). It is also possible to consider \"hybrid\" models that may comb ine continuous and discrete time-scales or continuous and discrete variables (e.g., see [4,13,20,22,40]). The choice of a model for a specic application depends on sev eral factors such as simplicity of the model, accuracy of prediction and compu tational aspects for simulating the model. Sometimes more than one model may be us ed to model the same biological process at dierent levels. For example, the seg ment polarity gene network has been investigated using a continuous-state mod el with13equations and48unknown kinetic parameters in [100] and also using a synchro nous Boolean model in [2].SOME BASIC CONTROL-THEORETIC CONCEPTS 179 6.1 Some basic control-theoretic concepts We illustrate some basic control-theoretic concepts and de nitions used in the study of dynamical systems. Consider the discrete-time model, a s pecial case of the system (6.1) with the explicit variable vector zRpfor thepoutput measurements =Cx(t)(6.2) whereARn\u00d7n,BRn\u00d7mandCRp\u00d7n. Recall that a directed graph of nnodes is strongly connected if and only if, for any pair of nodes uandv, there exists a path from utovusing at most n1edges. An analog of similar kind of behavior is captured by the deni tion of controllability of a dynamical system. Denition 3 (Controllability) The system (6.2)is said to be controllable if, for every initial condition x(0)and every vector yRn, there exist a nite time t0 and input (control) vectors u(0),u(1),...,u(t0)Rmsuch that y=x(t0)when the system is started at x(0). Intuitively, controllability means the ability to reach an y nal state yfrom any initial state x(0)by timet0without posing any conditions of the trajectory of the dynamics or any constraints on the input vectors u(t). For system (6.2), a necessary and sucient condition for controllability can be easily de duced in the following manner. We rst unwind the evolution of the system by using th e NETWORKS Thus, for the system to be controllable, there must be a solut ion to the following set of linear equations where we treat is clearly when the n\u00d7nmcontrollability matrix (also called the Kalman matrix)Z=/parenleftig B AB A2B......An1B/parenrightig has a full rank of n. Another useful control-theoretic aspect of dynamical syst ems is the observability property. Intuitively, observability is a quantication o f how well the internal states of a system can be distinguished or identied by observing it s external outputs. There are several possibilities for such a quantitative de nition; below we state one such denition. Let the notation z(t)/vextendsingle/vextendsingle x,u0,...,ut1denote the value of the output vectorz(t)with the initial state vector x(0) =xand A state vector system (6.2)is called unobservable said to be observable if it has no unobservable state. It is not very dicult to see that if the system (6.2) is observ able as dened in Denition 4, then this also implies that the initial state x(0)can be uniquely determined. Exercise 6.8 asks the reader to verify that if a s ystem is observable then all states are observable within the time duration/bracketleftbig 0,n/bracketrightbig . Using a similar type of recurrence unravelling as was done for the controllabili ty case, it can be see that system (6.2) is observable if and only if the matrix/parenleftig C CA CA2... CAn1/parenrightig has a rank of n. In this remainder of this chapter, we discuss several dynami cal models that are typically used in modelling cellular processes and interac tions. 6.2 Discrete-time Boolean network models Discrete-time Boolean networks were introduced in Section 5.2. In our dynamical systems framework, a discrete-time Boolean network is desc ribed by setting time variablestto have discrete values such as 0,1,2,...in a system of dierence equa- example, the reverse engineerin g method of Jarrah et al. in Section 5.4.2.2 reconstructed a Boolean network, and the model for the segment polarity gene network in Drosophila melanogaster given in [2] is a Boolean network model.ARTIFICIAL NEURAL NETWORK MODELS 181 x1 x2NOT NOTFigure 6.1 A Boolean network of two species interaction. (x1,x2) = (0,1)and(x1,x2) = (1,0)are the xed points of this network. If synchronous update rule is used, then the Boolea n system is dened by x1(t+1) =x2(t), x2(t+1) =x1(t) and thus the state vector (1,1)does not lead to a xed point. On the other hand, suppose that the following asynchronous upd ate rule is state vector (1,1)leads to the xed point (0,1). Note that the dynamics in (6.1) are described by simultaneously updating the state of all the variables in the network (the so-called \"syn chronous update\" rule). In reality, however, the rates of transcription, translati on, degradation and other biochemical processes can vary widely from gene to gene, thu s giving rise to the so-called \"asynchronous update\" rule where not all variabl es update themselves at each time step. Asynchronous behavior can be formally incor porated in a Boolean model by following the formalism of Thomas [95]. In this form alism, each compo- nent of the cellular system is associated with two variables , an usual state variable, and an image variable corresponding to each logical functio n in the Boolean model (which takes appropriate state variables as its input), and depending on the asyn- chronous update rule the value of the image variable is copie d (or not copied) to the corresponding state variable. The xed points (also cal led steady states) of a Boolean model remain the same regardless of the update method [16, page 431]. But, other aspects of the dynamic behavior of a Boolean netwo rk may drastically change by using asynchronous as opposed to synchronous upda tes, resulting in the same initial state leading to dierent steady states or limi t cycles (see Fig. 6.1 for an illustration). On the other hand, asynchronous update ru les provide more real- istic modelling of biological processes by allowing indivi dual variability of the rate of each process and thus allowing for decision reversals. Fo r example, it becomes possible to model the phenomena of overturning of mRNA decay when its tran- scriptional activator is synthesized, a phenomena that syn chronous updates cannot model. Several asynchronous versions of the synchronous Bo olean model for the segment polarity network in [2] appear in [21,22]. 6.3 Articial neural network models Articial neural network ( ANN) models were originally used to model the connec- tivities of neurons in brains and thus, in contrast to cellul ar signaling networks, ANN models generally have a less direct one-to-one correspondence to biological data. In the framework of dynamical systems, ANNmodels are discrete-time dy- namical systems where each function fiapplies a suitable transformation to a linear182 DYNAMICAL SYSTEMS AND INTERACTION NETWORKS discrete-time sigmoidal neural network and its graphical representation. combination of its inputs, i.e.,fiis of the form fi/parenleftbig x1(t),x2(t),...,x n(t)/parenrightbig =g n/summationdisplay where the wi,j's andi's are real or integral-valued given parameters. The global function gis commonly known as the \"activation\" function or the \"gate function\" in the ANNliterature. Some popular choices for the functionHand the sig- moidal function(illustrated in Fig. 6.3); , . Often an ANNis pictorially represented by a directed graph Gin which there is a node vicorresponding to each variable xi, the node viis labeled with its \"threshold\" parameter i, and a directed arc/parenleftbig vi,vj/parenrightbig is labeled by its \"weight\" wi,j; see Fig. 6.2 for an illustration. The topology of Gis usually referred to as the architecture of the ANN. AnANNis classied as a feed-forward orrecurrent type depending on acyclic or not. For acyclic feed-forward ANNs, thedepth of the network is usually dened to be the length (number of no des) in a longest directed path in the directed graph representation of the ne twork. (a)1 2 0 1 function. (b)The sigmoidal gate function. Often ANN models are used for computing a function. For this purpose, o ne designates a specic variable xp{x1,x2,...,x n}as the output of the function; if computation of a Boolean function is desired and the variabl es are real-valued, then the output of the function is obtained by a suitable discreti zation of the output variablexp,e.g., designatingH/parenleftbig xp/parenrightbig as the output of the function for someARTIFICIAL NEURAL NETWORK MODELS 183 suitable threshold value . In this setting, the ANNis said to compute a function f(t) is not dicult to see that Boolean networks are special cas es of the ANNmodels with threshold or sigmoidal functions (cf. Exercise 6.3). T he simplest type of feed- forward ANN is the classical perceptron model [73] consisting of n+ 1variables x1,x2,...,x + w2x2(t) +\u00b7\u00b7\u00b7+wnxn(t)/parenrightbig for some real numbers w1,w2,...,w nand. Such a model has a rather limited computational power [73]. Howeve r, for more complex feed-forward ANNs, computational powers for ANNmodels far exceed than that of the Boolean networks discussed in Sections 5.2 and 6.2. Comp utational powers of ANNs depend heavily on the nature of the activation function as w ell as whether the network is feed-forward or recurrent. 6.3.1.1 Feed-forward ANNsThreshold networks, i.e., feed-forward ANNs with threshold gate function, have been studied in considerable details by the theoretical computer science research community, and upper and lower bo unds on depth and number of nodes (variables) required for these types of circ uits to compute vari- ous Boolean functions (such as computing the parity functio n and computing the multiplication of binary numbers) have been obtained in com putational complexity research areas, e.g., see [46,52,77,80]. However, it is more common in practice to use ANNs with continuous activation functions such as the sigmoidal function. It is known that fe ed-forward ANNs of onlydepth2but with arbitrarily large number of variables (nodes) can a pproxi- mateanyreal-valued function up to anydesired accuracy using a continuous gate function such as the sigmoidal function [26,61]; however, t hese proofs are mostly non-constructive . It is known that feed-forward ANNs with sigmoidal gate function are more pow- erful in computing functions than feed-forward ANNs of having the same number of variables with Heaviside gate function [29,67]. A more deta iled theoretical compar- ison of the computational powers of ANNs with various types of activation functions are provided in [28,29]; in particular, [29] showed that any polynomial of degree nwith polynomially bounded coecients can sigmoidal ANNs with a polynomial number of nodes. 6.3.1.2 Recurrent ANNsInvestigations of the computational powers of recurrent ANNs were initiated in [86, 87]; [85] provides a thorough discus sion of recurrent ANNs and analog computation in general. Recurrent ANNs gain considerably more computational power compared to the feed-forward ANNs with increasing compu- tation time. In the following discussion, for the sake of con creteness, assume that the initial values of the variables at t= 1are binary, the sigmoid function is used as the gate function, and the output of the ANNis binarized for computing a function on its inputs. If all the weights and thresholds are integers , then the recurrent ANNs turn out to be equivalent to nite automata and thus they rec ognize exactly the class of regular language over the binary alphabet {0,1}. In contrast, recurrent ANNs whose weights and thresholds are rational numbers are, up t o a polynomial184 DYNAMICAL SYSTEMS AND INTERACTION NETWORKS time computation, equivalent to a Turing machine. Irration al weights provide an evenfurther boost in computation power in the sense that, if the ANNs are al- lowed exponential computation time, then arbitrary Boolea n functions (including non-computable functions) are recognizable [86]. Finally, a precise theory of what can be computed by noisy ANNs has not very satisfactorily developed yet. Especially when dealing wit h continuous variables, one should also allow for noise due to continuous-valued distur bances, which may lead to stringent constraints on what can be eectively computed [68]. 6.3.2 Reverse engineering of ANNs In the context of ANNmodels, reverse engineering is most commonly performed in alearning theory framework. In this framework, the architecture of the unkno wn ANNis given a priori , and the goal is to \"learn\" or reverse-engineer the weights a nd thresholds of all nodes in the architecture. Assume for conc reteness that the ANNis used to compute that provides the output at a specic time tout>0, and the set of all possible inputs to the ANN come from some probability distribution D. Just as our reverse-engineering problems for Boolean or signal transduction networks in Section 5.4 used biological experiments such as perturbation or knock-out experiments to generate t he necessary data, it is assumed that we have available a set of sinput-output pairs x1,x2,...,xsare drawn from the set of all possible inputs based on the distribution D. The reverse en- gineering process involves determining the values of weigh ts and thresholds of the ANN based on these ssamples. The nal outcome of such a process provides a function/hatwidef/parenleftbig x1,x2,...,x n/parenrightbig computed by the ANNbased on the determined valued of the weights and the thresholds. Let the error probability be dened as error-probDdefPrD/bracketleftig /hatwidef/parenleftbig x/parenrightbig \\e}io\\slsh=f/parenleftbig x/parenrightbig/bracketrightig where the notation Pr Dis used the clarify that probabilities are calculated with respect to the distribution D. Typically, the reverse engineering process is con- sidered to be possible (or, in the terminologies of learning theory, the function f isprobably-approximately-correctly learnable ) if there exists a nite ssuch that for every0<,< 1the following holds: PrD[errror-probD>]< (6.3) In the case when reverse engineering is possible, the functi ons/parenleftbig ,/parenrightbig which provides, for any given and, thesmallest possiblessuch that Equation (6.3) holds, is called the sample complexity of the class of functions in which fbelongs. It can be proved that learnability is equivalent to niteness of a c ombinatorial quantity called the Vapnik-Chervonenkis (Vc)dimensionFof the class of functions Fin whichfbelongs. In fact, s/parenleftbig ,/parenrightbig is bounded by a polynomial in 1/and1/, and is proportional to Fin the following sense [18,98]: s/parenleftbig ,/parenrightbig = O(( F/)log(1/)+(1/)log(1/))ARTIFICIAL NEURAL NETWORK MODELS 185 A specic set of weights and threshold values, denoted by w i,j's and i's, can be computed by solving the so-called \"loading problem\" [30] th at ts these samples xi/parenrightbig =f/parenleftbig xi/parenrightbig , the reverse engineering of real-valued (as opposed to Boolean) functions, by evaluation of the so-called \"pseudo-dimensi on\" are also possible ( e.g., see [53,65]). The Vcdimension appears to grow only moderately with the complex- ity of the topology and the gate function for many types of ANNs. For example: TheVcdimension of the class of functions computed by any feed-for ward ANNwithprogrammable parameters showed polynomial up per bounds of the Vcdimension of the class of functions computed by feed-forwar dANNs with piecewise-polynomial a O/parenleftbig w2n2/parenrightbig upper bound on the Vc dimension for the class of functions computed by any feed-fo rward ANNwith the sigmoidal activation function, where wis the number of programmable parameters and nis the number of variables. Unfortunately, solving Equation (6.4) exactly to nd an app ropriate set of weights and thresholds may turn out to be NP-hard even for a simple 3-variable ANN with threshold or piecewise-linear gate function [17,31]. Thus, in practice, various types of optimization heuristics such as back-propagation [83] are used to obtain an approximate solution. 6.3.3 Applications of ANNmodels in studying biological networks Although ANNmodels were originally inspired by the interconnectivity p atterns of neurons in brains, they have also been successfully applied to model genetic circuits. We review two such applications below. 6.3.3.1 Application in reverse engineering of gene regulatory networks [62] In this application, an ANNmodel is to used to reverse engineer a genetic regulatory net - work from steady state wild type versus mutant gene expressi on data. We described a framework for reverse engineering in Section 5.4.2 to cons truct the causal relation- ships between genes from such data. As we commented in Sectio n 5.4.3.2, testing such methods requires the generation of the so-called gold s tandard networks. Ky- odaet al. [62] used an extended ANNmodel with a continuous gate function for obtaining the dierential equation models of such gold-sta ndard networks. An il- lustration of this application is shown in Fig. 6.4. Perturbation experimental data via gene knock-outs can be g enerated from the model in the following manner. We may start with an equilibri um point, say \u00af x= (\u00afx1,\u00afx2,\u00afx3,\u00afx4), of the model as the wild type. To knock out the gene vi, we can remove the node viand its associated arcs from the network, start the network at \u00af x, and run the network dynamics until it reaches a new equilibr ium point/tildewidex= (/tildewidex1,/tildewidex2,/tildewidex3,/tildewidex4). To generate time series data we can simply start the network at a prescribed initial state and run it for a specic number of time steps.186 Figure g.(b)The dierence equation model corresponding to the ANNin (a).Riis the maximum rate of synthesis of gene vi,iis the degradation rate of the product from gene vi, and the threshold isummarizes the eect of general transcription factors on ge nevi.(c)The specic activation function gused by Kyoda et al.[62].(d)The (b)indicating and eects. 6.3.3.2 Application in crop simulation modelling Accurate modelling of the genetic regulatory mechanism leading to flowering time is critical i n crop modeling for nding time intervals during which growth and yield-genera ting processes operate. Welch et al. [101] provided a simple 8-node ANNwith the sigmoidal gate function to model the control of inflorescence transition in the plant Arabidopsis thaliana . 6.4 Piecewise linear models An ane map hover a vector space z=/parenleftbig z1,z2,...,z n/parenrightbig is given by h(z) n/parenrightbig is a vector. Piecewise linear ( systems, in the sense dened in [91], are discrete-time systems described by equations x(t+ 1) =P(x(t),u(t)) (or, in more concise notation, \" x+=P(x,u)\") for which the transition mapping P is aPlmap,i.e., there is a decomposition of the state space xand the input vector spaceuintonitely many pieces such that, in each of these pieces, the mapping P is given by an ane map. The decomposition is required to be polyhedral , meaning that each piece is described by a set of linear equalities and inequalities. Explicit constraints on controls and states are included as part of th e specication of a Pl system. Thus, the state space and input value sets are subset s ofRnandRm, respectively, indicating a priori restrictions on the allo wed ranges of variables, and to make the dynamics remain piecewise linear, these sets are required to be denable in terms of a nite number of linear equalities and inequalit ies.PIECEWISE LINEAR MODELS 187 Linear systems arise in the special case in which there is just oneregion. But thePlsystem paradigm includes many more situations of interest, such as: linear systems such as x+=Ax+Bsat(u)whose actuators are subject to uration, ui,otherwise, systems x+=Aix+Biu, where the choice of matrix pair (Ai,Bi) depends on a set of linear constraints on current inputs and s tates, and systemsx+= sat(Ax+Bu)for which underflows and overflows in state vari- ables must be taken into account. Plsystems are the smallest class of systems which is closed under interconnections and which contains both linear systems and nite automata. 6.4.1 Dynamics of Plmodels it was shown in [14] that the general class of hybrid \"Mixed Lo gical Dynamical\" systems introduced in [15] is in a precise sense equivalent t o thePlsystems. Based on this equivalence, and using tools from piecewise ane sys tems, the authors of [14] studied basic system-theoretic properties, and suggested numerical tests based on mixed-integer linear programming for checking controllab ility and observability. Another basic question that is often asked about the Plclass of systems is the one regarding equivalence ,i.e.,given two systems, do they represent the same dynamics under a change of variables ? Indeed, as a preliminary step in answering such a question, one must determine if the state spaces of both systems are isomorphic in an \"appropriate sense\". That is, one needs to know if an inv ertible change of variables is at all possible, and only then can one ask if the e quations are the same. For classical nite dimensional linear systems, this quest ion is trivial since only the dimensions must match. For nite automata, similarly, the q uestion is also trivial, because the cardinality of the state set is the only property that determines the existence of a relabeling of variables. For other classes of systems, however, the question is not as trivial, and single numbers such as dimens ions or cardinalities may not suce to settle this isomorphism ( i.e., state-equivalence) problem. For example, if one is dealing with continuous-time systems de ned by smooth vector elds on manifolds, the natural changes of variables are smo oth transformations, and thus a system whose state space is a unit circle cannot be equivalent to a system whose state space is the real line, even though both systems h ave a dimension of 1. As another example, for systems whose variables are require d to remain bounded, for instance, because of saturation eects, a state-space l ike the unit interval [1,1] looks very dierent from the unbounded state-space R, even though both have dimension 1. To provide a precise denition of equivalence between two Plsystems, we start with an equivalent alternate denition of Plsets and maps. The Plsubsets of Rnare those belonging to the smallest Boolean algebra that contains all the open half-spaces of Rn. A maph:XYbetween two PlsubsetsXRaandYRb is aPlmapif its graph is a Plsubset of Ra\u00d7Rb. By a Plsetone means a Pl188 DYNAMICAL SYSTEMS AND INTERACTION NETWORKS subset of some Rn. Then, a Plsystem is a discrete-time system x+=P(x,u)with Plstate and input value sets and Pltransition matrix P. Viewed in this manner, twoPlsetsXandYarePl-isomorphic if there are Plmapsh1:XYand h2:YXsuch thath1h2andh2h1both equal to the identity mapping, i.e., y=h1(x)is a bijective piecewise linear map. An elegant geometric interpretation of Pl-isomorphism was provided in [32] and is summarized below. Geometrically, a Pl-isomorphism is a sequence of operations of the following type: make a nite number of cuts along a set of lines (or segments), apply an ane transformation to each piece (without droppin g any lower- dimensional pieces), and paste it all together. For example, consider the interior of the triangle in R2obtained as the interior of the convex hull of the points (0,0),(1,1)and(2,0), and the interior /square/square/squareof the open square with and(1,0). Then,isPl-isomorphic to/square/square/squareas shown below: Sontag in [92] introduced developed a logic formalism of thePlsystems (\" Pl algebra\") to help in classifying Plsets that are equivalent under isomorphism. The critical step in this classication was to associate to each PlsetXa \"label\" with the property that two PlsetsXandYare isomorphic if and only if their labels are related in a certain manner. Subsequent algorithmic dev elopments on this type of equivalence checking procedures are described in [32]. 6.4.2 Biological application of Plmodels Plsystems are quite powerful in modelling biological systems since they may be used as identication models (by means of piecewise linear a pproximations), or as controllers for more general systems. Arbitrary interconn ections of linear systems and nite automata can be modeled by Plsystems, and vice-versa. More precisely, given any nite automaton with state space Q, input alphabet , and state tran- sition function :Q\u00d7Q, we allow the state qQof the nite automaton to control switching among |Q|possible linear of the linear systems. We now discuss two specic applications of Plsystems in modelling biological processes.PIECEWISE LINEAR MODELS 189 6.4.2.1 Plmodels for genetic regulatory networks Plmodels for regulatory net- works can be built starting with the formulations proposed o riginally by Glass and Kauman [43]. Such an approach was illustrated and investig ated by Casey, Jong, and Gouz\u00e9 in [20]. We illustrate the approach by starting wit h the special form of omitted the input vector under the assumption that t he state vector x can itself be influenced externally. The parameter irepresents the degradation rate of the ithmolecular component ( e.g., protein). The function firepresenting the synthesis rate of the ithmolecular component is approximated by the piecewise- linear function by taking a linear of regulation. The Boolean reg - ulatory functions /A6/D6i,jmodel the conditions of regulation of xiby the remaining variables, and is written as an appropriate combinations of the Heaviside (thresh- old) functionsH/parenleftbig /braceleftbig 1,2,...,n/bracerightbig , where 's are appropriate threshold concentration parameters. As an illustration, suppose that we want to model the followi ng regulatory mech- anism: gene x1is expressed at the rate of 0.23if the concentration of protein x2 is above 0.3and the concentration of protein x3is below 0.9; otherwise gene x1is not expressed. This is equation: fi/parenleftbig (x1(t),x2(t),x3(t))/parenrightbig = 0.23H/parenleftbig x20.3/parenrightbig/bracketleftig 1H/parenleftbig x30.9/parenrightbig/bracketrightig It is easy to verify that the above kind of system partitions t he entiren-dimensional state space into a nite number of n-dimensional hyper-rectangular regions (\"pieces\") and within each such region the behavior of the dynamics is li near. For example, consider the following system: the two-dimensional state space is partitioned as shown in Fig. 6.5. 6.4.2.2 Hybrid automata for delta-notch protein signalling Several cellular pro- cesses, such as pattern formation due to lateral inhibition [41, 64], involve the so-called Delta-Notch protein signaling mechanism . A model for the regulation of intracellular protein concentrations in this signallin g mechanism through the feedback system was described in [40] using the experimenta lly observed rules for the associated biological phenomenon. In this model, each c ell was implemented as190 DYNAMICAL SYSTEMS AND INTERACTION of the hyperplane (colored black) function Figure 6.5 Rectangular partition of state space induced by system (6.7). a piecewise linear hybrid automaton with 4states. In this section, we review this application after dening a piecewise linear hybrid automa ta. Recall that a standard non-deterministic is dened [56] as a5-tuple/parenleftbig Q,,,q0,F/parenrightbig whereQis a nite set of states, is a nite input alphabet, :Q\u00d7mso2Qis the state transition map where 2Qdenotes the power set of Q, q0Qis the initial state, and FQis the set of nal (accepting) states. See Fig. 6.6 (a)for an illustration. This Nfamodel can be combined with a piecewise- linear dynamics to obtain a piecewise-linear hybrid automa ta (Plha) [5, 40] as discussed below. InPlha, the set of states Qare of two types: a set of mdiscrete state variables such that every state variable qQcassumes a real value. We also have a set of mdiscrete inputs =/braceleftbig These functions are used to dene linear constraints that decide the boundaries of the p iecewise-linear system and associate discrete states with these regions in the foll owing manner. Let a \"sign pattern\" s=/parenleftbig s1,s2,...,s (a)An example of a Nfa. The input 0101is accepted by the Nfasince there is a directed path from the initial state q0to a nal state q2labeled0101.(b)An example of a piecewise-linear hybrid automata ( Plha) with two continuous state variables and no inputs. A hypothetical trajectory of the dynamics is s hown by thick black lines with arrows. half-spaces involving sj Then, each discrete state qQdis associated with a distinct sign-vector s(q)such that the state qis active if all the corresponding half-space constraints a re satis- ed. We can then dene adjacency of two states as being the adj acency of their corresponding geometric regions in the n-dimensional space, e.g., two states may be adjacent if their sign patterns dier in exactly one coordinate. It is possible in practice to design algorithms to check this kind of geomet ric adjacency in the n-dimensional space [40]. The state transition map :Qd\u00d7Qc\u00d7mso2Qd\u00d7Qcnow involves both discrete and continuous states by allowing a s witch from a discrete state to another adjacent discrete state at the boundary of t he two regions corre- sponding to the two states. At the \"inside\" of the region for a discrete state q, the192 DYNAMICAL SYSTEMS AND INTERACTION NETWORKS continuous state variables x=/parenleftbig x1,x2,...,x n/parenrightbig evolve in a linear by specifying an initial condition Qd 0\u00d7Qc 0of the discrete and continuous states. Fig. 6.6 (b)illustrates a Plha. More discussions related to various abstractions of hybrid automata and their decidability issues can be found in [5]. In particular, the f ormalism described above allows symbolic description of many parameters without specic numerical instan- tiation, e.g., the elements aq,1,...,a q,ncan be represented symbolically using a few free parameters and constraints over these parameters. For example, an exponen- tial decay with a rate of rfor a continuous state variable xjQcin a discrete stateqQdcan be obtained by specifying aq,j=rxj+rwhererdetermines the boundary condition. === Figure 6.7 Hexagonal lattice of cells for Delta-Notch protein signall ing. A cell with its six neighbors is shown amplied. Ghosh and Tomlin used the Plha model in [40] to study the Delta-Notch protein signaling mechanism that is responsible for many cellular p rocesses. The cells are assumed to be packed in a hexagonal lattice with each cell (ex cept those at the boundary of the lattice) having six neighboring cells (see F ig. 6.7). The parameters of the Plha for each cell are as of various parameters are as fo llows: Qd:four discrete states to switch ON or OFF the production of the Delta protein or the Notch protein individually x1andx2:concentrations of Delta and Notch proteins, respectively uDanduN:inputs to physically realize the biological constraint tha t production of Notch protein in a cell is turned ON by high levels of the Del ta protein in the immediate neighbourhood of the cell, and the p roduc- tion of the Delta protein is switched ON by low levels of the No tch protein in the same cell xDelta,i:value of x1in theithneighboring cell DandN:decay constants for Delta and Notch proteins, respectively RDandRN:constant production rates for Delta and Notch proteins, res pectively hDandhN:switching thresholds for productions of Delta and Notch pro teins, respectively Note that cells influence and are influenced by their six neigh boring cells via the inputuNand the variables xDelta,jforj= 1,2,...,6. Empirical estimates for the thresholds hDandhNare provided in [41]. A major goal of [40] in formu- lating the above Plha model for Delta-Notch signalling was to determine initial conditions from which specic equilibrium points of the dyn amics are reachable (the so-called \"backward reachability\" problem). To this e ect, Ghosh and Tom- lin [40] designed and implemented an ecient heuristic algo rithm for the backward reachability problem model. 6.5 Monotone systems sub-system1sub-system2 sub-system3sub-system4 sub-system 5Inputs to the systemOutputs from the systemInput to sub-system 222 Output from sub-system 111 Figure 6.8 A system composed of ve interconnected subsystems. One approach to mathematical analysis of complex biologica l systems relies upon viewing them as made up of sub-systems whose behavior is simp ler and easier to understand. Coupled with appropriate interconnection r ules, the hope is that emergent properties of the complete system can be deduced fr om the understanding of these subsystems. Diagrammatically, one can picture thi s as in Fig. 6.8, which shows a full system as composed of ve interconnected sub-sy stems. An interesting class of biological systems with simpler beh aved dynamics are systems with monotone dynamics (or, simply, the monotone systems ) [54,55,89].194 DYNAMICAL SYSTEMS AND INTERACTION NETWORKS Monotone systems constitute a nicely behaved class of dynam ical systems in sev- eral ways. For example, for these systems, pathological beh aviors of dynamics (e.g., chaotic attractors) are ruled out. Even though they may hav e arbitrarily large dimensionality, monotone systems behave in many ways like one-dimensional systems, e.g., bounded trajectories generically converge to steady stat es, and there are no stable oscillatory behaviors (limit cycles). Monoto nicity with respect to orthant orders is equivalent to the non-existence of negati ve loops in systems; analyzing the behaviors of such loops is a long-standing top ic in biology in the context of regulation, metabolism and development, starti ng from the work of Monod and Jacob in 1961[74], and culminating in many subsequent works such as [7, 9, 23,63, 71,78,82, 90,96]. An interconnection of mon \"positive feedback\" monoton icity, Thus, oscillators such as circadian rhythm generators require negative feedback loops in order for periodic orbits to aris e, and hence are not themselves monotone systems; however they can be decompose d into monotone subsystems [10]. Theoretical characterizations of the beh avior of non-monotone interconnections are available in [6,8,35,38,39]. A key point brought up in [93,94] is that new techniques for mo notone systems in many situations allow one to characterize the behavior of an entire system, based upon the \"qualitative\" knowledge represented by gene ral network topology and the inhibitory or activating character of interconnect ions, combined with only a relatively small amount of quantitative data. The latter data may consist of steady- state responses of components (dose-response curves and so forth), and there is no need to know the precise form of dynamics or parameters such a s kinetic constants in order to obtain global stability conclusions. 6.5.1 Denition of monotonicity Recall that a partial order recedesequlover a setUis a binary relation that is reflexive (i.e., urecedesequlufor everyuU),antisymmetric (i.e., ifurecedesequluandurecedesequluthenu=u), and transitive ( i.e., ifurecedesequluandurecedesequluthenurecedesequlu). For example, the \u00f7relation on the set of positive integers Ndened by \" a\u00f7bif and only if ais an integral multiple ofb\" is a partial order relation. For easier understanding, we illustrate the denition of mo notonicity of dynamics of a system when it is expressed via the dierential equation model (5.1) with no inputs, i.e., dxi(t) dt=fi/parenleftbig x1(t),x2(t),...,x n(t)/parenrightbig , i= 1,2,...,n or, in concise vector notation, x=f(x)(6.8) However, much of the discussion also applies to more general types of dynamical systems such as delay-dierential systems or certain syste ms of reaction-diusion partial dierential equations. We will discuss in Section 6 .5.2.1 how to incorporate control inputs (and outputs) in our denitions of monotonic ity. An additional requirement that we need before giving the de nition of a mono- tone system is that, for each iandj, eitherfj xi0for allxorfj xi0for allx. In other words, in our model the direct eect that one given vari able has over another variable is unambiguous in the sense that it is always inhibitory or always excitory. Thus, for example, if protein binds to the promoter region of another gene, weMONOTONE SYSTEMS 195 assume that it does so either to prevent the transcription of the gene or to facilitate it irrespective of the respective concentrations. As expla ined in details in [22], this requirement is nota severe restriction. Firstly, note that this unambiguity a ssump- tion does notprevent a protein from having an indirect influence, through other molecules, that can ultimately lead to the opposite eect on a gene from that of a di- rect connection. Secondly, in biomolecular networks, ambi guous signs in Jacobians often represent heterogeneous mechanisms, and introducin g a new species into the model ( i.e., an additional variable for this intermediate form) reduce s the original system to an equivalent new system in which the signs of the Ja cobian entries are unambiguous. Finally, small-scale negative loops that are abundant in nature often represent fast dynamics which may be collapsed into self-lo ops via time-scale de- composition (singular perturbations or, specically for e nzymes, \"quasi-steady state approximations\") and hence may be viewed as diagonal terms, but the requirement of a xed sign for Jacobian entries is notimposed on diagonal elements. The dynamics of a monotone system preserves a specic partial order of its inputs over time. More precisely, monotonicity is dened as follow s. Denition 5 [55,75] Given a partial order recedesequloverRn, system (6.8)is said to be monotone y1(0),...,y n(0)/parenrightbig , respectively. Of course, whether a system is monotone or not depends on the p artial order being considered. We will consider the following partial or der that has been inves- tigated in previous research works such as [9,27,89]. Denition (orthant order) For an \"cooperative order\" which is the partial order recedesequlsfors= (1,1,...,1),i.e.,xrecedesequl1,1,...,1yi:xiyi; in traditional compu- tational geometry literature the cooperative order is also known as the dominance relationship between n-dimensional points [49]. In the rest of our discussions on monotone systems, we will us e the term \"mono- tone systems\" with the assumption that the monotonicity is w ith respect to some xed orthant order recedesequls.196 DYNAMICAL SYSTEMS AND INTERACTION NETWORKS 6.5.2 Combinatorial characterizations and measure of mono tonicity The reader can easily verify the following characterizatio n of monotone systems [75]. (Kamke's condition) order recedesequlsgenerated by s=/parenleftbig s1,...,s n/parenrightbig . Then, the system (6.8) is monotone with respect to recedesequlsif and only if 1i\\e}io\\slsh=jn:sisjfj xi0 Based on Kamke's condition, et an elegant graph- theoretic characterizations of monotonicity of the system (6.8) that may be sub- jected to algorithmic analysis. For this characterization , we consider the sys- tem (6.8) and its associated signed (directed) graph G= (V,E)as dened in Section 5.1.3. To provide an intuition behind the rst chara cterization, consider the following biological system associated signed graph for this system is as shown below : x1x1x1 x2x2x2 x3x3x3 It is possible to show that the system (6.9) is notmonotone with respect to recedesequls for anys(cf. Exercise 6.10). But, if we remove the term/parenleftbig x3(t)/parenrightbig3in the rst equation, we obtain a system that ismonotone with respect to recedesequl1,1,1. A cause of non-monotonicity of the system is the existence of sign-inconsistent paths between two nodes in an undirected version of the signed graph, i.e., the existence of both an activation and an inhibitory path between two nodes when the directions of the arcs are ignored . Dene a closed undirected chain inGas a sequence of nodes xi1,...,x irsuch thatxi1=xir, and such that for every t= 1,...,r1either (xit,xit+1)Eor(xit+1,xit)E. The graph Gis said to be sign-consistent if all paths between any two nodes have the same parity or, equiv alently, all closed undirected chains in Ghave a parity of 1(i.e., all closed undirected chains have an even number, possibly zero, of arcs labeled 1). The following characterization now holds [27,33,88]. (Combinatorial characterization of monotonicity) System (6.8) is monotone with respect to some orthant order i f and only if Gis sign-consistent, i.e., all closed undirected chains of its associated signed graphGhave parity 1. Fig. 6.9 illustrates the above combinatorial characteriza tion of monotonicity. Of course, one should not expect complex biological systems to have a associated signed graph that is consistent. However, if the number of in consistent pairs of path in the undirected versions of a sign graph is small, it may well be the case that theMONOTONE SYSTEMS 197 x1x1x1x2x2x2x3x3x3x4x4x4 x5x5x5 (a)x1x1x1x2x2x2x3x3x3x4x4x4 x5x5x5 (b) Figure 6.9 Two signed graphs. The graph in (a)is sign-consistent, but the graph in (b), which diers in just one edge from (a), is not sign-consistent since it has two paths in its undirected version with dierent parity between node sx1x4, namely a direct path of odd parity and a path of even parity transversing node x5. Self-loops, which in biochemical systems often represent degradation terms, are ignored in t he denition. network is in fact consistent in a practical sense. For examp le, a gene regulatory network represents all potential eects among genes. These eects are mediated by proteins which themselves may need to be activated in orde r to perform their function, and this activation may, in turn, depend on certai n extracellular ligands being present. Thus, depending on the particular combinati on of external signals present, dierent subgraphs of the original signed graph de scribe the system under those conditions, and these graphs may individually be cons istent. For example, in Fig. 6.9 (b), the edges x4x1andx4x5may be present under completely dierent environmental conditions AandB. Thus, under either of the conditions A orB, the signed graph would be consistent, even though the entir e signed graph is not consistent. Evidence that this is indeed the case is prov ided by [69], where the authors compare certain biological networks and appropria tely randomized versions of them and show that the original networks are closer to bein g consistent. Thus, we are led to the computational problem of computing the smal lest number of arcs that have to be removed so that there remains a consistent gra ph. We formalize this computational question as the sign consistency (Sgn-Const ) problem (see Fig. 6.10) to determine how close to being monotone a system i s [27, 57]. For example, for the particular signed graph shown in Fig. 6.11, removal of just one arc/parenleftbig x2,x4/parenrightbig suces (in this case, the solution is unique: no single other arc would suce; for other graphs, there may be many minimal solutions ). We remind the reader that the above combinatorial character ization of mono- tonicity is via the absence of undirected closed chains of parity 1. Thus, in particular, any monotone system has (i)nonegative feedback loops, and (ii)noincoherent feed-forward-loops. However, some systems may not be monot oneeven if (i)and (ii)hold; the following example was shown in [1]:198 DYNAMICAL SYSTEMS AND INTERACTION NETWORKS Problem name: sign Sgn-Const ) Instance: a function L:Emso/braceleftbig 1,1/bracerightbig whereF=/braceleftbig (u,v)E/vextendsingle/vextendsingleL(u,v) =(u)(v)/bracerightbig is the set of consistent arcs for the node labeling function . Figure 6.10 Denition of the sign consistency problem. x1x1x1+1+1+1x2x2x2111 x3x3x3+1+1+1 x4x4x4111 Figure 6.11 Deletion of the arc/parenleftbig x2,x4/parenrightbig makes the given signed graph consistent. The node labels are shown besides the nodes. A B C D Based on the formulation of the Sgn-Const problem, Albert et al. [1] dened thedegree of monotonicity of a signed graph to be M=/vextendsingle/vextendsingleFopt/vextendsingle/vextendsingle /vextendsingle/vextendsingleE/vextendsingle/vextendsingle(6.10) whereFoptEis the set of consistent arcs in an optimal node labeling opt, and the|E|term in the denominator in Equation (6.10) is a min-max norma lization to ensure that 0<M1. Note that the higher the value of Mis the more monotone the network is. An interesting interpretation of the Sgn-Const problem in statistical mechanics terms was discussed in [27]. We briefly recount the interpret ation here. Think of the arc labels as \"interaction energies\", and node labels in theSgn-Const problem as the (magnetic) \"spin congurations\". Note that an arc/braceleftbig u,v/bracerightbig Eis consistent in a node labeling providedL(u,v)uv= 1. A graph with \u00b11arc labels is called an Ising spin-glass model in statistical physics. A \" non-frustrated\" spin- glass model is one for which there is a spin conguration for w hichevery arc is consistent [11, 24, 36,58]. This is the same as a consistent g raph in our previous discussion. Moreover, a spin conguration that maximizes t he number of consistent edges is a \"ground state\", namely one for which the \"free ener no exteriorMONOTONE SYSTEMS 199 magnetic eld/parenleftbig /summationtext (u,v)EL(u,v)uv/parenrightbig is minimized. Thus, solving the Sgn- Const problem amounts to nding ground states. 6.5.2.1 Incorporatingcontrolinputs As we illustrated in Fig. 6.8, a useful approach to the analysis of biological systems consists of decomposi ng a given system into an interconnection of monotone subsystems. The formulatio n of the notion of in- terconnection requires subsystems to be endowed with \"inpu t and output channels\" through which information is to be exchanged. In order to add ress this we may use the \"controlled\" dynamical systems dened by Equation ( 5.1) in Section 5.1.2, namely x=f/parenleftbig x,u/parenrightbig Specifying the time-dependency of the input vector uby a function u(t)Rmfor t0, it follows that each input denes a time-dependent dynamic al system in the usual sense. We associate a feedback function h:RnmsoRmwith system (5.1) to create the closed loop system x=f/parenleftbig x,h(x)/parenrightbig . Finally, if xRnanduRmare ordered by the orthant orders recedesequl(g1,...,gn)andrecedesequl(q1,...,qm)respectively, then we say that the system is monotone if it satises Kamke's condition for every u, and also k,j:qkgjfj uk0 See [9] for further discussions on this. 6.5.3 Algorithmic issues in computing the degree of monoton icityM To calculate the degree of monotonicity Mvia Equation (6.10), we obviously need to develop an ecient algorithm to compute an exact or approxim ate solution to the Sgn-Const problem. A special case of Sgn-Const , namely whenL(u,v) every edge problem ( e.g., see [99]) which is NP-hard. Thus, we cannot hope for an ecient algorithm to nd an exact solution forSgn-Const when the size of the signed graph is large. Sgn-Const can be posed as a special type of \"constraint satisfaction pr oblem\" in the following manner. Let :{1,1}mso{0,1}be the linear transformation dened by(x) =1x 2. Then,(1) = 0 ,(1) = L(u,v) equivalent Thus, Sgn-Const can be posed as an optimization problem in which we have |E|linear equations over GF (2)involv- ing|V|Boolean variables, with one equation per arc and each equati on involving exactly two variables, and the goal is to assign truth values to the Bo olean variables to satisfy a maximum number of equations. For algorithms and lower-bound result s for general cases of these types of problems, such as when the equations are over GF(p)for an arbitrary prime por when there are an arbitrary number of variables per equation or when the goal is to minimize the number of unsa tised equations, see references such an approxim ation algorithm for Sgn-Const used by DasGupta et al. [27] based on the semidenite programming (SDP) technique used by Goemans and Williamson for MAX-CUT in [44]; readers not very familiar with the SDPtechnique are also referred to an excellent treatment of this technique in the book by Vazirani [99].200 DYNAMICAL SYSTEMS AND INTERACTION NETWORKS The starting point in applying the SDPmethod is to observe that Sgn-Const can be written down as the following QIPformulation is also NP-hard, we cannot solve it directly. Thus, we \"relax\" this to a \"vector program\" ( VP) by allowing each variable vto be a real vector vover ann-dimensional unit-norm hyper-sphere in the following mann er vR|V|(6.12) The above vector program can in fact be solved exactly in polynomial time. For this purpose we rst formulate the following can be solved exactly in polynomial time using any existing algorithm for SDPusing ellipsoid, interior-point or convex- programming methods [3,48,75,76,97], or by using any exist ing software for solving SDPoptimization problems ( e.g.,SDPoptimization solving semidenite Since any solution matrix Yto (6.13) is positive semi-denite, such a solution matrixYcan be written as Y=BTBfor some real matrix BR|V|\u00d7|V|. Such a decomposition of Ycan be found by the well-known Cholesky decomposition algorithm [47] ( Matlab provides an implementation algorithm). the matrixBis found, the solution vectors/braceleftig v/vextendsingle/vextendsinglevV/bracerightig to (6.12) can be found by setting vto the column of Bthat consists of the entries/braceleftbig yu,v|uV/bracerightbig . What remains now is to compute mappings Pv: vmso{1,1/bracerightbig for everyvV such that the set of values/braceleftbig v=Pv/parenleftbig v/parenrightbig/vextendsingle/vextendsinglevV}provide a solution of (6.11) of desired Pvis computed by sphere uniformly at random . For example, this can be done by sampling r j, forMONOTONE SYSTEMS 201 each1j|V|, from a normal distribution of zero mean and unit standard deviation ( i.e.,Pr/bracketleftbig ar jb/bracketrightbig =/integraltextb a(1/ 2) ex2/2dxfor any/bracketleftbig a,b/bracketrightbig and then normalizing the coordinates so that the 2-norm of the an optimum node labeling function for Sgn-Const with/vextendsingle/vextendsingleFopt/vextendsingle/vextendsingleconsis- tent edges. It can be shown that the above randomized algorit hm provides a node labeling function approx toSgn-Const using ele- mentary calculus that >0.87856 ; thus on an average the approximate solution retains at least87.85% of the number of consistent edges in an optimal solution. The above randomized approach to compute the mappings Pvcan be made deter- ( [70], but the derandomization pro cedure is complicated. Instead, one usually runs the randomized algo rithm for computing thePvs many times and accepts the best of these solutions; it can be shown that such an approach retains at least fraction of the optimal number of consistent edges with very high probability [84]. REFERENCES 1. R. Albert, B. DasGupta, A. Gitter, G. G\u00fcrsoy, R. Hegde, P. P al, G. S. Sivanathan and E. Sontag. A New Computationally Ecient Measure of Topo logical Redun- dancy of Biological and Social Networks, Physical Review E, 84 (3), 036117, 2011 2. R. Albert and H. Othmer. The topology of the regulatory int eractions predicts the expression pattern of the segment polarity genes in Drosophila melanogaster , Journal of Theoretical Biology, 223, 1-18, 2003. 3. F. Alizadeh. Interior point methods in semidenite progr amming with applications to combinatorial optimization, SIAM Journal on Optimizati on, 5, 13-51, 1995. 4. R. Alur, C. Ivanc, V. Kumar, M. Mintz, G.J. Pappas , H. Rubin and J. Schlug. Hybrid modeling and simulation of biomolecular n etworks, in M. D. Di Benedetto and A. Sangiovanni-Vincentelli (editors), Hybr id Systems: Computation and Control, Lecture notes in computer science, 2034, 19-32 , Springer Verlag, 2001. 5. R. Alur, Laerriere and G. J. Pappas. Disc rete abstractions of hybrid systems, Proceedings of the IEEE, 88(7), 971-984, 20 00. 6. D. Angeli, P. De Leenheer and E. D. Sontag. A small-gain the orem for almost global convergence of monotone systems, Systems and Control Lette rs, 51, 185-202, 2004. 7. D. Angeli, J. E. Ferrell Jr. and E. D. Sontag. Detection of m ulti-stability, bi- furcations, and hysteresis in a large class of biological po sitive-feedback systems, Proceedings of the National Academy of Sciences USA, 101, 18 22-1827, 2004.202 DYNAMICAL SYSTEMS AND INTERACTION NETWORKS 8. D. Angeli and E.D. Sontag. Monotone control systems, IEEE Transactions on Automatic Control, 48, 1684-1698, 2003. 9. D. Angeli and E. D. Sontag. Multistability in monotone I/O systems, Systems and Control Letters, 51, 185-202, 2004. 10. D. Angeli and E. D. Sontag. An analysis of a circadian mode l using the small- gain approach to monotone systems, IEEE Conference on Decis ion and Control, 575-578, 2004. 11. F. Barahona. On the computational complexity of Ising sp in glass models, Journal of Physics A: Mathematical and General, 15 (10), 3241-3253, 1982. 12. E. B. Baum and D. Haussler. What size net gives valid gener alization?, Neural Computation, 1, 151-160, 1989. 13. C. Belta, Finin, L. C. G. J. M. Habets, A. Halasz, M. Imie linksi, V. Kumar and H. Rubin. Understanding the bacterial stringent respon se using reachability analysis of hybrid systems, in R. Alur and G. Pappas (editors ), Hybrid Systems: Computation and Control, Hybrid Systems: Computation and C ontrol, Lecture notes in computer science, 2993, 111-125, Springer Verlag, 2004. 14. A. Morari. Observa bility and controllability of piecewise ane and hybrid systems, IEEE Transactions on A utomatic Control, 45 (10), 1864-1876, 2000. 15. A. Bemporad and M. Morari. Control of systems integratin g logic, dynamics, and constraints, Automatica, 35, 407-428, 1999. 16. D. P. Method. Prentice Hall, Englewood Clis, New Jersey, 19 89. 17. A. Blum and R. L. Rivest. Training a 3-node neural network isNP-complete, Neural Networks, 1992. A. Ehrenfeucht, D. Haussler, and M. Warmuth. L earnability and the Vapnik-Chervonenkis dimension, Journal of the ACM, 36, 929 -965, 1989. 19. J. W. Bodnar. Programming the drosophila embryo, Journa l of Theoretical Biology, 188, 391-445, 1997. 20. R. L. Casey, H. L. Jong, and J. L. L. Gouz\u00e9. Piecewise-line ar models of genetic reg- ulatory networks: Equilibria and their stability, Journal of Mathematical Biology, 52, 27-56, 2006. 21. M. Chaves, R. Albert and E. D. Sontag. Robustness and frag ility of boolean models for genetic regulatory networks, Journal of Theoretical Bi ology, 235, 431-449, 2005. 22. M. Chaves, E.D. Sontag, and R. Albert. Methods of robustn ess analysis for boolean models of gene control networks, IEE proceedings of Systems Biology, 153 (4), 154- 167, 2006. 23. O. Cinquin and J. Demongeot. Positive and negative feedb ack: striking a balance between necessary antagonists, Journal of Theoretical Bio logy, 216, 229-241, 2002. 24. B.A. Cipra. The Ising Model Is NP-Complete, SIAM News, 33 (6), 2000. 25. N. Creignou, S. Khanna and M. Sudan. Complexity classic ations of Boolean con- straint satisfaction problems, SIGACT News, 32 (4), 24-33, 2001. 26. G. Cybenko. Approximation by superposition of a sigmoid al function, Mathematics of Control, Signals, and System, 2, 303-314, 1989. 27. B. DasGupta, G. A. Enciso, E. Sontag and Y. Zhang. Algorit hmic and complex- ity results for decompositions of biological networks into monotone subsystems, Biosystems, 90 (1), 161-178, 2007.MONOTONE SYSTEMS 203 28. B. DasGupta and G. Schnitger. The Power of Approximating : A Comparison of Activation Functions, in C. L. Giles. S. J. Hanson and J. D. Co wan (editors), Ad- vances in Neural Information Processing Systems, 5, Morgan Kaufmann Publishers, 615-622, 1993. 29. B. DasGupta and G. Schnitger. Analog versus Discrete Neu ral Networks, Neural Computation, 8 (4), 805-818, 1996. 30. B. DasGupta, H. T. Siegelmann and E. Sontag. On the Intrac tability of Loading Neural Networks, in V. P. Roychowdhury, K. Y. Siu and A. Orlit sky (editors), The- oretical Advances in Neural Computation and Learning, Kluw er Academic lishers, 357-389, 31. B. DasGupta, T. Siegelmann E. Sontag. On the Comple xity of Training Neural Networks with Continuous Activation Functions, IEE E Transactions on Neural Networks, 6 (6), 1490-1504, 1995. 32. B. DasGupta and E. D. Sontag. A polynomial-time algorith m for checking equiva- lence semiring congruences motivated by the s tate-space isomorphism problem for hybrid systems, Theoretical Computer Science, 262, 161-189, 2001. 33. D. L. DeAngelis, W. M. Post and C. C. Travis. Positive Feed back in Natural Systems, Springer-Verlag, New York, 1986. 34. H. de Jong. Modeling and simulation of genetic regulator y systems: A literature review, Journal of Computational Biology, 9 (1), 67-103, 20 02. 35. P. De Leenheer, D. Angeli and E.D. Sontag. On predator-pr ey systems and small- gain theorems, Journal of Mathematical Biosciences and Eng ineering, 2, 25-42, 2005. 36. C. De Simone, M. Diehl, M. Junger, P. Mutzel, G. Reinelt an d G. Rinaldi. Exact ground states of Ising spin glasses: New experimental resul ts with a branch and cut algorithm, Journal of Statistical Physics, 80, 487-496 , 1995. 37. R. Edwards, H. T. Siegelmann, K. Aziza and L. Glass. Symbo lic dynamics and computation in model gene networks, Chaos, 11 (1), 160-169, 2001. 38. G. Enciso and E. Sontag. Global attractivity, I/O monoto ne small-gain and biological systems, Discrete and Continuous Dyna mical Systems, 14, 549-578, 2006. 39. T. Gedeon and E. D. Sontag. Oscillation in multi-stable m onotone system with slowly varying positive feedback, Journal of Dierential E quations, 239, 273-295, 2007. 40. R. Ghosh and C. J. Tomlin. Symbolic reachable set computa tion of piecewise ane hybrid automata and its application to biological modeling : Delta-notch protein signaling, IEE proceedings on Systems Biology, 1, 170-183, 2004. 41. R. Ghosh and C. J. Tomlin. Lateral inhibition through Del ta-notch signaling: A piecewise ane hybrid model, in M. D. D. Benedetto and A. San giovanni- Vincentelli Springer Verlag, 2001. 42. A. Ghysen and R. Thomas. The formation of sense organs in d rosophila: A logical approach, BioEssays, 25, 802-807, 2003. 43. L. Glass and S. A. Kauman. The logical analysis of contin uous, non-linear bio- chemical control networks, Journal of Theoretical Biology , 39 (1), 103-129, 1073. 44. M. Goemans and D. Williamson. Improved approximation al gorithms for maximum cut and satisability problems using semidenite programm ing, Journal of the ACM, 42 (6), 1115-1145, 1995.204 DYNAMICAL SYSTEMS AND INTERACTION NETWORKS 45. P. Goldberg and M. Jerrum. Bounding the Vapnik-Chervone nkis dimension of con- cept classes parameterized by real numbers, Machine Learni ng, 18, 131-148, 1995. 46. M. Goldmann and J. On the power of small-depth thr eshold circuits, Computational Complexity, 1 (2), 113-129, 1991. 47. G. H. Golub and C. F. Van Loan. Matrix computations, 3rdedition, Johns Hopkins University Press, 1996. 48. M. Gr\u00f6tschel, L. Lov\u00e1sz and A. Schrijver. Geometric Algo rithms and Combinatorial Optimization, Springer-Verlag, New York, 1988. 49. P. Gupta, R. Janardan, M. Smid and B. DasGupta. The rectan gle enclosure and point-dominance problems revisited, International Journ al of Computational Ge- ometry and Applications, 7 (5), 437-455, 1997. 50. V. V. Gursky, J. Reinitz and A. M. Samsonov. How gap genes m ake their domains: An analytical study based on data driven approximations, Ch aos, 11, 132-141, 2001. 51. J. H\u00e5stad and S. Venkatesh. On the advantage over a random assignment, Random Structures & Algorithms, 25 (2), 117-149, 2004. 52. A. Hajnal, W. Maass, P. Pudlak, M. Szegedy and G. Turan. Th reshold circuits of bounded depth, Journal of Computer and System Sciences, 46, 129-154, 1993. 53. D. Haussler. Decision theoretic generalizations of the PAC model for neural nets and other learning applications, Information and Computat ion, 100, 78-150, 1992. 54. M. Hirsch. Systems of dierential equations that are com petitive or cooperative II: Convergence almost everywhere, SIAM Journal of Mathema tical Analysis, 16, 423-439, 1985. 55. M. Hirsch. Dierential equations and convergence almos t everywhere in strongly monotone flows, Contemporary Mathematics, 17, 267-285, 198 3. 56. J. E. Hopcroft, R. Motwani and J. D. Ullman. Introduction to Automata Theory, Languages, and Computation, Addison Wesley; 3 edition, 200 6. 57. F. H\u00fcner, N. Betzler and R. Niedermeier. Optimal edge de letions for signed balancing, 6thWorkhop on Experimental Algorithms, LNCS 4525, 297-310, Springer-Verlag, 2007. 58. Istrail. ity and NP-Completeness: I. Universality of Intractability of the Partition Functions of the Ising Model Across Non-Planar Lattices, Thirty-Second Annual ACM Symposium o n Theory of Com- puting, 87-96, 2000. 59. M. Karpinski and A. Macintyre. Polynomial Bounds for VC D imension of Sigmoidal and General Pfaan Neural Networks, Journal of Computer and Systems Science, 54, 169-176, 1997. 60. S. Kauman, C. Peterson, B. Samuelsson, and C. Troein. Ra ndom boolean net- work models and the yeast transcriptional network, Proceed ings of the National Academy of Sciences USA, 100, 14796-14799, 2003. 61. A. N. Kolmogorov. On the representation of continuous fu nctions of several vari- ables by superposition of continuous functions of one varia ble and addition, Dok- lady Akademii Nauk (proceedings of the Russian Academy of Sc iences), 114, 953- 956, 1957. 62. K. M. Kyoda, M. Morohashi, S. Onami and H. Kitano. A gene ne twork inference method from continuous-value gene expression data and mutants, Genome Informatics, 11, 196-204, 2000.MONOTONE SYSTEMS 63. Slack and L. Wolpert. Thresholds in develo pment, Journal of The- oretical Biology, 65, 579590, 1977. 64. G. Marnellos, G. A. Deblandre, E. Mjolsness, and C. Kintn er. Delta-notch lateral inhibitory patterning in the emergence of ciliated cells in Xenopus: Experimental observations and a gene network model, Pacic Symposium on B iocomputing, 326- 337, 2000. 65. W. Maass. Perspectives of current research about the com plexity of learning in neural nets, in Theoretical Advances in Neural Computation and Learning, V. P. Roychowdhury, K. Y. Siu, and A. Orlitsky (editors), Kluwer A cedemic Publishers, 295-336, 1994. 66. W. Maass. Bounds for the computational power and learnin g complexity of analog neural nets, SIAM Journal of Computing, 26 (3), 708-732, 199 7. 67. W. Maass, G. Schnitger, and E. D. Sontag. On the computati onal power of sigmoid versus boolean threshold circuits, proceedings of the 32ndannual IEEE symposium on Foundations of Computer Science, 767-776, 1991. 68. W. Maass and E. D. Sontag. Analog neural nets with gaussia n or other common noise distributions cannot recognize arbitrary regular la nguages, Neural Computa- tion, 11 (3), and E.D. Sontag. Intracellular Reg ulatory Networks are close to Monotone Systems, IET Systems Biology, 2, 103-112, 2008. 70. S. Mahajan and H. Ramesh. Derandomizing semidenite pro gramming based ap- proximation algorithms, SIAM Journal of Computing, 28 (5), 1641-1663, 1999. 71. H. Meinhardt. Space-dependent cell determination unde r the control of morphogen gradient, Journal of Theoretical Biology, 74, 307321, 197 8. 72. L. Mendoza, D. Thiery, and E. R. Alvarez-Buylla. Geneti c control of flower mor- phogenesis in arabidopsis thaliana: a logical analysis, Bi oinformatics, 593-606, 1999. 73. M. Minsky and S. Papert. Perceptrons, The MIT Press, 1988 . 74. J. Monod and F. Jacob. General conclusions: telenomic me chanisms in cellular metabolism, growth, and dierentiation, Cold Spring Harbo r Symposium on Quan- titative Biology, 26, 389-401, 1961. 75. Y. Nesterov and A. Nemirovskii. Self-Concordant Functi ons and Polynomial Time Methods in Convex Programming, Central Economic and Mathem atical Institute, USSR Academy of Science, 1989. 76. Y. Nesterov and A. Nemirovskii. Interior Point Polynomi al Methods in Convex Programming, Society of Industrial and Applied Mathematic s, Philadelphia, 1994. 77. I. Parberry. A Primer on the Complexity Theory of Neural N etworks, in Formal Techniques in Articial Intelligence: A Sourcebook, R. B. B anerji (editor), Elsevier Science Publishers B. V. (North-Holland), 217-268, 1990. 78. E. Plathe, T. Mestl loops, stab ility and multistation- arity in dynamical systems, Journal of Biological Systems, 3, 409413, 1995. 79. C. V. Rao, D. M. Wolf and A. P. Arkin. Control, exploitatio n and tolerance of intracellular noise, Nature, 420, 231-237, 2002. 80. J. H. Reif. On threshold circuits and polynomial computa tion, SIAM Journal on Computing, 21 (5), 896-908, 1992. 81. J. Reinitz and D. H. Sharp. Mechanism of eve stripe format ion, Mechanisms of Development, 49 (1-2), 133-158, 1995.206 DYNAMICAL SYSTEMS AND INTERACTION NETWORKS 82. E. B. Mosse, C. Chaouiya and D. Thiery. A descripti on of dynamical graphs associated to elementary regulatory circuits, Bioi nformatics, 19 (Suppl. 2), ii172ii178, 2003. 83. D. E. Rumelhart and J. L. McClelland. Parallel Distribut ed Processing: Explo- rations in the Microstructure of Cognition, The MIT Press, 1 986. 84. L. S\u00e1nchez and D. Thiery. A logical analysis of the droso phila gap-gene system, Journal of Theoretical Biology, 211, 115-141, 2001. 85. H. T. Siegelmann. Neural Networks and Analog Computatio n: Beyond the Turing Limit, Birkh\u00e4user publishers, 1998. 86. H. T. Siegelmann and E. D. Sontag. Analog computation, ne ural networks, and circuits, Theoretical Computer Science, 131, 331-360, 199 4. 87. H. T. Siegelmann and E. D. Sontag. On the Computational Po wer of Neural Nets, Journal of Computer and System Sciences, 50, 132-150, 1995. 88. H. L. Smith. Systems of ordinary dierential equations w hich generate an order- preserving flow: A survey of results, SIAM Reviews, 30, 87-11 1, 1988. 89. H. L. Smith. Monotone Dynamical Systems, Providence, R. I., AMS 1995. 90. E. H. Snoussi. Necessary conditions for multistationar ity and stable periodicity, Journal of Biological Systems, 6, 39, 1998. 91. E. D. Sontag. Nonlinear regulation: The piecewise linea r approach, IEEE Trans- action on Automatic Control, 26 (2), 346-358, 1981. 92. E. D. Sontag. Remarks on piecewise-linear algebra, Paci c Journal of Mathematics, 98, 183-201, 1982. 93. E. D. Sontag. Molecular systems biology and control, Eur opean Journal of Control, 11, 396-435, 2005. 94. E. D. Sontag. Some new directions in control theory inspi red by systems biology, Systems Biology, 1, 9-18, 2004. 95. R. Thomas. Boolean formalization of genetic control cir cuits, Journal of Theoretical Biology, 42, 563-585, 1973. 96. R. Thomas. Logical analysis of systems comprising feedb ack loops, Journal of The- oretical Biology, 73, 631656, 1978. 97. P. Vaidya. A new algorithm for minimizing convex functio ns over convex sets, Mathematical Programming, 73 (3), 291-341, 1996. 98. V. N. Vapnik and A. Chervonenkis, Theory of Pattern Recog nition (in Russian), Moscow, Nauka, 1974. 99. V. V. Vazirani. Approximation Algorithms, Springer-Ve rlag, Berlin, 2001. 100. G. von Dassow, E. Meir, E. M. Munro and G. M. Odell. The seg ment polarity network is a robust developmental module, Nature, 406, 188- 192, 2000. 101. S. M. Welch, J. L. Roe and Z. Dong. A genetic neural networ k model of flowering time control in arabidopsis thaliana , Agronomy Journal, 95, 71-81, 2003. 102. C. H. Yuh, H. Bolouri, J. M. Bower, and E. H Davidson. A log ical model of cis- regulatory control in a eukaryotic system, in Computationa l Modeling of Genetic and Biochemical Networks, J. M. Bower and H. Bolouri (editor s), 73-100, The MIT Press, 2001.EXERCISES 207 EXERCISES 6.1 Convince yourself that delays may aect the dynamic behavio r in a non- trivial manner by considering the and observing the asymptotic behaviors of x1(t)andx2(t). Can you give an estimate of the asymptotic growth of the two variables (as a function of t) in the two systems? 6.2 Determine if the following system is 91/bracketrightigg/bracketleftigg u1(t) u2(t)/bracketrightigg 6.3 Show that a Boolean network can be simulated by a ANN with threshold gate function by showing that each of the logical gates AND,OR, and NOT can be simulated by a node with threshold gate function by approp riately choosing the parameters of the threshold function. 6.4 Consider the network model shown in Fig. 6.4. a) Starting with the initial states x1(0) =x2(0) =x3(0) =x4(0) = 1/2, generate a time-series data by running the network for 4time steps. Now, use the method of Jarrah et al. (discussed in Section 5.4.2.2) to reverse engineer a causal network and its corresponding Boolean cou nterpart. b) Repeat Exercise 6.4.a by running the network for 10time steps. Is there any improvement in the quality of the reconstructed network ? 6.5 The goal of this exercise is to convince the reader that Plsystems can sim- ulate Boolean circuits. a) Consider the Boolean ANDfunction on nBoolean inputs: x+ n+1=x1 x2\u00b7\u00b7\u00b7xn. Assume that each Boolean variable xi{0,1}is obtained from a corresponding real-valued variable 0yi1by the thresholding ruleyi=H(xi1/2), whereHis the threshold function described in Fig. 6.3. Write down a Plsystem of the form as shown in Equation (6.6) that produced the output of the ANDgate ony1,y2,...,y n. b) Repeat Exercise 6.5.a for a Boolean ORgate:x+ n+1=x1x2\u00b7\u00b7\u00b7xn. 6.6 Show that Nfas and the Plsystems (6.6) are subclasses of the Plhas. 6.7 Prove that transformations of the form outlined in Equation (6.5) can be used to simulate an arbitrary interconnection of linear sys tems and nite automata by aPlsystem.208 DYNAMICAL SYSTEMS AND INTERACTION NETWORKS 6.8 Suppose that Denition 4 is used for the denition of observa bility of the system (6.2). Show that if an initial state x(0)is unobservable for the time duration/bracketleftbig 0,n/bracketrightbig then it is unobservable over any time duration. 6.9 Write a computer program in your favorite programming langu age to simulate the dynamics of the Plha model for Delta-Notch signalling for one cell (thus, xi,Delta= 0fori= 1,2,...,6). Test your program with various initial conditions. 6.10 Show that the system (6.9) is not monotone with respect to recedesequlsfor anys.CHAPTER 7 CASE STUDY OF BIOLOGICAL MODELS In the preceding two chapters, we have seen the underlying pr inciples behind synthe- sizing and analyzing several types of biological models. In this chapter, we discuss dynamical and topological properties of a few specic biological models. Our goal in this chapter is not to provide every possible details of th ese models, but rather to point out salient features of these models that have made the m attractive in their applications. 7.1 Segment polarity network models An important part of the development of the early Drosophila (fruit fly) embryo is the dierentiation of cells into several stripes (\"segment s\"), each of which eventu- ally gives rise to an identiable part of the body such as the head, thewings and theabdomen . Each segment then dierentiates into a posterior and an anterior part, in which case the segment is said to be polarized ; this dierentiation process continues up to the point when all identiable tissues of the fruit fly have devel- oped. Dierentiation at this level starts with diering con centrations of certain key proteins in the cells; these proteins form striped patterns by reacting with each other and by diusion through the cell membranes (see Fig. 7. 1 for an illustration). The genes involved in the process include engrailed (en),wingless (wg),hedgehog (hh),patched (ptc),cubitus interruptus (ci) and sloppy paired (slp), coding for the proteins (denoted by corresponding capitalized names) EN,WG,HH,PTC,CIand Models and Algorithms for Biomolecules and Molecular Netwo rks, rst edition. By Bhaskar DasGupta and Jie Liang Copyright \u00a9 2015 John Wiley & S ons, Inc.209210 CASE STUDY OF BIOLOGICAL MODELS SLP, respectively. Two additional proteins resulting from tra nsformations of the protein CIalso play important roles: CImay be converted into a transcriptional activator CIA, or may be cleaved to form a schematic diagram of the early development of a Drosophila embryo. Each hexagon represents a cell, and neighboring cells interact t o form a collective behavior. In this gure, an initial striped pattern of the genes enandwginduces the production of the genehh, but only in those cells that are producing en. 7.1.1 Boolean network model Albert and Othmer [4] developed and analyzed a Boolean model based on the binary ON/OFF representation of mRNA and protein levels of ve segm ent polarity genes. This model was constructed based on the known topology and wa s validated using published gene and expression data. The expressions of the s egment polarity genes occur in stripes encircling the embryo. The key features of t hese patterns can be represented in one dimension by a line of 12interconnected cells, grouped into 3parasegment primordia, in which the genes are expressed in e very fourth cell. In Albert and Othmer's model, parasegments are assumed to be identical, and thus only one parasegment of four cells is considered. There fore, in their model the Boolean variables are the expression levels of the segme nt polarity genes and proteins in each of the four cells. For further details, the r eader is referred to [4]. 7.1.2 Signal transduction network model In the gene regulatory network model for segment polarity, t he interactions incor- porated include translation mRNA ), are inter-cellular , namely the proteins WGandHHmay leave the cell in which they are produced and interact with receptor proteins in the membranes of neighboring cells. The network for a single cell was rst published in [8] and later appeared in slightly modied form in [4,12]. Fig. 7.2 shows the network.ABA-INDUCED STOMATAL CLOSURE NETWORK 211 membranehhciEN 7.2 [8] The Drosophila segment polarity regulatory network for one cell with the interpretation of the regulatory role of PTCon the reaction CICNasPTCCNand PTCCI. As illustrated in papers such as [2,7], one can build a 1-dimensional multi-cellular version of this network by considering a row of ncells, each of which has separate variables for each of the compounds, and letting the cell-to -cell interactions be as shown in Fig. 7.3 using cyclic boundary conditions. One can c alculate the degrees of monotonicity and redundancy for this network as follows: Albert et al. [2] show that, for n>1, /recipeTr>3/11. DasGupta et al. [7] show that the 1-dimensional network follows a monotone dynamics if we remove 3edges from the network for every cell (and, similarly, remove3nedges from the n-node network). 7.2 ABA-induced stomatal closure network Microscopic stomatal pores of plants have a surrounding pai r ofguard cells . It is known that plants take in carbon dioxide as well as lose water through these pores, and this process is controlled by the surrounding guard cell s [11]. During drought, the plant hormone abscisic acid (ABA) inhibits stomatal opening and promotes stomatal closure, thereby promoting water conservation. Dozens of cellular components have been identied to functi on in ABA regulation of guard cell volume and thus of stomatal aperture [6,10,16] . Based on these and other known interactions, Li et al.[15, Table S1] compiled a list of about 140direct interactions and double-causal inferences, both of type \" Apromotes B\" and \" C promotes process ( Apromotes B)\", and manually synthesized a network of 54nodes and92(activation or inhibitory) arcs that accurately portrays t he dynamics of the regulation (see Fig. 7.4). Because the interaction data con tains both direct and double-causal interactions, with additional information about interactions that are known to be direct with absolute certainty (\"mandatory\" edg es in the terminology in Chapter 5.3.1), Albert et al.[1,3] were able to exploit the algorithmic framework212 CASE STUDY OF BIOLOGICAL MODELS Cell 1 Cell regulatory network with cyclic boundary conditions. shown in Fig. 5.4 and use this framework in their NET-SYNTHESIS software [14] to automatically generate a slightly more minimal network of 57nodes and 84edges. 7.3 Epidermal growth factor receptor signaling network Epidermal Growth Factor (EGF) is a protein that is frequently stored in skin and other epithelial tissues, and is released when rapid cell di vision is needed ( e.g., after an injury). The function of EGFis to bind to a receptor, the Epidermal Growth Factor Receptor (EGFR), on the membrane of the cells. The EGFR, on the inner side of the membrane, has the appearance of a scaol d with dozens of docks to bind with numerous agents, and starts a large number of reactions at the cell level that ultimately induces cell division. In 2005, Oda et al. [17] integrated the information about this process from multiple sources to dene a network with 330known molecules under 211chemical reactions. Each reaction in the network classies the molecules as reactants, products, and/or mod iers (enzymes). The network was made available in the supplementary material of [17] in SBML1format. For the purpose of analyzing the monotonicity of dynamics of the above biochem- ical network, DasGupta et al. [7] imported the information the classication B iology M arkup L anguage, see http://www.sbml.org al.[15]. Nodes in the network correspond to proteins, genes and other small molecules ( e.g.,RAC1 is a small GTPase protein). of the molecules as reactants, products or enzymes to Matlab using the Systems Biology Toolbox, and dened a network Gin the following manner: ( /A3/CQ)The network has which were added in the following manner: ( /A3/CQ/BD)If there exists a reaction in which mjis a product and miis either a reactant or a modier, then we add the arc vivjto the network. ( /A3/CQ/BE)If there exists a reaction in which mjis a reactant and miis either a reactant or a modier, then we add the arc vivjto the network. ( /A3/CQ/BF)If both the arcs vivjandvivjexists by ( /A3/CQ/BD) and ( /A3/CQ/BE) for any pair of nodes viandvj, then we remove both the arcs vivjandvivj from the network (in the terminology of [7], both the arcs are removed and an arc from vitovjis added with the label \"undened\" ( NaN)). There are exactly7such pairs of nodes in the network. ( /A3/CQ/BG)In a few reactions there was a modier or a reactant involved w hich had aninhibitory eect in the reaction, but the eect of this compound on the remaining participants of the reaction was the opposite fro m that described214 CASE STUDY OF BIOLOGICAL MODELS above. In such cases, the network was corrected manually by l ooking at theannotations given for each reaction. Gas constructed above has more arcs than the digraph displaye d in [17]. The reason for this is as follows: if molecules miandmjare both reactants in the same reaction, then the presence of miwill have an indirect inhibiting eect on the concentration of mj, since it would accelerate the reaction which consumes mj (assumingmjis not also a product). Therefore an inhibitory arc must also appear frommitomj, and vice versa. Similarly, modiers have an inhibiting ee ct on reactants. DasGupta et al.[7] applied the algorithmic procedures discussed in Chapte r 6.5.3 and found that the network can be made monotone by deleting 219arcs, and thus the entire network can be decomposed as the feedback loo p of a controlled monotone system using 219inputs. To check whether removing signicantly fewer than219arcs may also provide a monotone network, DasGupta et al.[7] suggested the following two heuristic approaches: For a suitable positive integer k, consider the knodes with the highest out- degrees (\"hubs\"), and eliminate all the outgoing arcs assoc iated to these hubs from the reaction network Gto form a new network G. Then, use the al- gorithm for the combinatorial characterization via the sig n-consistency ( Sgn- Const as discussed 6.5.2 on Gto nd a node labeling functionVof the nodes and a set of marcs that can be removed to eliminate all remaining undirected closed chains of parity 1. Finally, put back to the reduced network among those arcs that were taken out the ones which are consistent with respect to the node labels induced by V. Make suitable changes of variables in the original system us ing the mass con- servation laws. Such changes of variables are discussed in m any places, e.g., see [5,19]. In terms of the associated signed graph, the resu lt of the change of variables is often the elimination of one of the cycles. The s implest target for a suitable change of variables is a set of three nodes that form part of the same chemical reaction, for instance two reactants and one produ ct, or one reactant, one product and one modier. It is easy to see that such nodes a re connected in the associated signed graph by a cycle of three arcs. To the extent to which most of these triangles can be eliminated by suitable change s of variables, this can yield a much lower number of arcs to be removed. 7.4C. elegans metabolic network This network was constructed and studied by Jeong et al. [13] and was also subse- quently investigated by other researchers such as [2,9]. Data-sources for the C. elegans metabolic network includes two types of nodes, namely the metabolites andreaction nodes, and the arcs are directed either from those metabolites that are the reactants of a reaction to the reaction node, or from the reaction node to the products of the reaction. The ne twork constructed in [13] had 651nodes and about 2040arcs (after removal of duplicate arcs). Thus, the network is dense with an average degree of 3.13. Albert et al. [2] found by empirically evaluation that for this network the degree of r edundancy /recipe Tris0.669 and the degree of monotonicity Mis0.444.NETWORK FOR T CELL SURVIVAL AND DEATH IN LARGE GRANULAR LYMPH OCYTE LEUKEMIA 215 The degree of redundancy of the metabolic network is surpris ingly high among similar biological networks. A biological basis for this co uld be due to the exis- tence of currency metabolites . Currency metabolites (also called carrier orcurrent metabolites) are abundant in normal cells and occur in widel y dierent exchange processes. For example, ATPcan be seen as the energy currency of the cell. Be- cause of their wide participation in diverse reactions, cur rency metabolites tend to be the highest degree nodes of metabolic networks. For the me tabolic network, redundant arcs appear if both (one of) the reactant(s) and (o ne of) the product(s) of a reaction appear as reactants of a dierent reaction, or c onversely, both (one of) the reactant(s) and (one of) the product(s) of a reaction app ear as products of a dierent reaction. Thus, intuitively, metabolites that pa rticipate in a large number of reactions will have a higher chance to be the reactant or pr oduct of redundant arcs. Based on their empirical analysis, Albert et al. [2] concluded that the high redundancy of the C. elegans metabolic network is in fact mostly due to inclusion of currency metabolites. 7.5 Network for T cell survival and death in large granular ly mphocyte leukemia Large Granular Lymphocytes ( LGL) are medium to large size cells with eccentric nuclei and abundant cytoplasm. In normal adults, LGL compri se about 10%to 15%of the total peripheral blood mononuclear cells. LGLcan be further divided into two major lineages: CD3-natural-killer (NK) cell line age, which comprises mediates non-major histocompatibility CD3+ lineage, comprises 15% of LGL and re presents activated cytotoxic T cells. LGLleukemia is a type of disordered clonal expansion of LGLand their invasions in the marrow, spleen and liver. LGLleukemia was further divided into T-cell LGLleukemia and NK-cell LGLleukemia. Rasis a small GTPase which is essential for controlling multiple essential signaling pa thways, and its deregulation is frequently seen in human cancers. Activation of H-Rasrequires its farnesylation, which can be blocked by farnesyltransferase inhibitiors ( FTIs). This envisions FTIs as future drug target for anti-cancer therapies. One such FTIis tipifarnib, which shows apoptosis Rasis constitutively activated in leukemic LGLcells, leads to the hypothesis that Rasplays an important role in LGLleukemia, and may functions through influencing Fas/FasLpathway. Kachalo et al. [14] synthesized a cell-survival/cell-death 6.0database with ad- ditional information manually curated from literature sea rch. The 359nodes of this network represented proteins/protein families and mR NAs participating in pro-survival and Fas-induced apoptosis pathways, and the 1295arcs in the net- work represented regulatory relationships between these n odes, including protein interactions, catalytic reactions, transcriptional regu lation (for a total of 766di- rect interactions), and known indirect causal regulation. The approach used by Kachalo et al. [14] was to focus special interest on the eect of Ras on apopt o- sis response through Fas/FasL pathway by designating nodes that correspond to proteins with no evidence of being changed during this eect as pseudo-nodes and simplifying the network via iterations of the PncandTroperations described in216 CASE STUDY OF BIOLOGICAL MODELS Sections 5.3.3.1 and 5.3.3.2 to simplify the network to cont ain267nodes and 751 arcs. Saadatpour et al. [18] further investigated the T-LGLnetwork and found that 14nodes of the network have high importance in the sense that bl ocking any of these nodes disrupts (almost) all signaling paths from the c omplementary node to apoptosis, thus providing these nodes as possible candidat e therapeutic targets. All of these nodes are also found to be essential for the T-LGLsurvival state according to a dynamic model, i.e., reversing their states causes apoptosis to be the only possible outcome of the system. Moreover, experimental verication of the importance of these nodes exists for 10of the14nodes [18]. REFERENCES 1. R. Albert, B. DasGupta, R. S. Kachalo, E. Sontag, A. Zelikovsky and Novel Method for Signal Transduction Netwo rk Inference from Indirect Experimental Evidence, Journal of Computational Biology, 14 (7), 927- 949, 2007. 2. R. Albert, B. DasGupta, A. Gitter, G. G\u00fcrsoy, R. Hegde, P. P al, G. S. Sivanathan and E. Sontag. A New Computationally Ecient Measure of Topo logical Redun- dancy of Biological and Social Networks, Physical Review E, 84 (3), 036117, 2011 3. R. Albert, B. DasGupta and E. Sontag. Inference of signal t ransduction networks from double causal evidence, in Methods in Molecular Biolog y: Topics in Compu- tational Biology, D. Fenyo (ed.), 673, Chapter 16, Springer , 2010. 4. R. Albert and H. Othmer. The topology of the regulatory int eractions predicts the expression pattern of the segment polarity genes in Drosophila melanogaster , Journal of Theoretical 1-18, 2003. D. Angeli and E.D. Sontag. Monotone control systems, IEEE Transactions on Automatic Control, 48, 1684-1698, 2003. 6. M. R. Blatt and A. Grabov. Signal redundancy, gates and int egration in the control of ion channels for stomatal movement, Journal of Experimen tal Botany, 48, 529- 537, 1997. 7. B. DasGupta, G. A. Enciso, E. Sontag and Y. Zhang. Algorith mic and complex- ity results for decompositions of biological networks into monotone subsystems, Biosystems, 90 (1), 161-178, 2007. 8. G. von Dassow, E. Meir, E. M. Munro, and G. M. Odell. The segm ent polarity network is a robust developmental module, Nature, 406, 188- 192, 2000. 9. J. Duch and A. Arenas. Community identication using extr emal optimization, Physical Review E, 72, 027104, 2005. 10. L. M. Fan, Z. Zhao and S. M. Assmann. Guard cells: A dynamic signaling model, Current Opinions in Plant Biology, 7, 537-546, 2004. 11. A. M. Hetherington and F. I. Woodward. The role of stomata in sensing and driving environmental change, Nature, 424, 901-908, 2003. 12. N. T. Ingolia. Topology and robustness in the Drosophila segment polarity network, PLoS Biology, 2 (6), e123, 2004. 13. H. Jeong, B. Tombor, R. Albert, Z. N. Oltvai and A.-L. Bara basi. large-scale organization of Nature, 407, 651-654, 2000.EXERCISES 217 14. S. Kachalo, R. Zhang, E. Sontag, R. Albert and B. DasGupta . NET-SYNTHESIS: A software synthesis, gnal transduction net- works, Bioinformatics, 24 (2), 293-295, 2008. 15. S. Li, S. M. Assmann and R. Albert. Predicting Essential C omponents of Signal Transduction Networks: A Dynamic Model of Guard Cell Abscis ic Acid Signaling, PLoS Biology, 4(10), e312, 2006. 16. E. A. MacRobbie. Signal transduction and ion channels in guard cells, Philosophical Transactions of the Royal Society B: Biological Sciences, 3 53, 1475-1488, 1998. 17. K. Oda, Y. Matsuoka, A. Funahashi and H. Kitano. A compreh ensive pathway map of epidermal growth factor receptor signaling, Molecul ar Systems Biology, 1 (1), 2005. 18. A. Saadatpour, R. S. Wang, A. Liao, X. Liu, T. P. Loughran, I. Albert and R. Al- bert R. Dynamical and Structural Analysis of a T Cell Surviva l Network Identies Novel Candidate Therapeutic Targets for Large Granular Lym phocyte Leukemia, PLoS Computational Biology, 7, e1002267, 2011. 19. A. I. Volpert, V. A. Volpert and V. A. Volpert. Traveling W ave Solutions of Parabolic Systems, volume 140of Translations of Mathematical Monographs, American Mathematical Society, 2000. EXERCISES 7.1 The purpose of this exercise is to get the reader familiar wit h the algorithmic framework shown in Fig. 5.4 and the NET-SYNTHESIS software in [14] that uses this algorithmic framework. Consider the following small s ubset of the of the following tasks, report the network generate d and verify that it is correct. a) Generate the network using only the direct interactions a nd perform tran- sitive reduction on the graph ( e.g., in NET-SYNTHESIS software, select \"Reduction (slower)\" from the Action menu). b) Add double-causal inferences to the network ( e.g., in NET-SYNTHESIS software, select \"Add pseudonodes\" from the Action menu).218 CASE STUDY OF BIOLOGICAL MODELS c) Perform pseudo-node collapse ( e.g., in NET-SYNTHESIS software, select \"Collapse pseudonodes\" from the Action menu). d) Perform a follow-up round of binary transitive reduction and pseudo-node collapse until the graph cannot be reduced further. 7.2 Collect5biological networks from existing bioinformatics literat ure. For each network, do the following. a) Explain in details the biological process that is modeled by the network. b) Investigate topological and dynamical properties such a s degree distribution and connectivity, degree of redundancy /recipe Tr, degree of monotonicity M. 7.3 Show that Tr>3/11for the1-dimensional GF(2) Galois eld of two elements 0and1. The addition rule for this eld isc=a+b(mod 2) and the multiplication rule is c=ab. R Set of real numbers. Rnn-dimensional space whose each component is a real number. e Base of natural logarithm. g1g2 The composition of two functions g1andg2,i.e.,g1g2(x) = g1/parenleftbig g2(x)/parenrightbig . Apoptosis Programmed cell-death. Chemical reactions, reactants and products A chemical reaction is a chemical transformation in which a s et of substances (called reactants) together produce another set of substances (called products). Currency metabolites Currency metabolites (sometimes also referred to as carrier orcur- rentmetabolites) are ubiquitous substrates having a high turno ver and occurring in widely dierent exchange processes. For ex am- ple,ATPcan be seen as the energy currency of the cell. There is some discussion in the literature on how large the group of cu r- rency metabolites is, but the consensus ADP,NADand its variants, NH4+ , and PO43(phosphate). Equivalence relation Models and Algorithms for Biomolecules and Molecular Netwo rks, rst edition. By Bhaskar DasGupta and Jie Liang Copyright \u00a9 2015 John Wiley & S ons, Inc.219220 GLOSSARY A relationRon a setXis a set of ordered pairs of elements of X. Ris an equivalence relation if it is reflexive ( i.e.,(x,x)Rfor everyxX), symmetric ( i.e.,(x,y)Rimplies(y.x)R) and transitive equivalence relation produced a partition of Xwhere elements in the same partition are mutually related to each other. Hyper-rectangle A generalization of two-dimensional rect angles to more than two dimensions. A n-dimensional hyper-rectangle is a Cartesian prod- uct ofnintervals. Occam's razor The general principle that recommends select ion among competing hypotheses the one that makes the fewest new assumptions. Pocket A pocket on a protein is a concave unlled region conne cted to the outside with a constriction, namely, it has an opening th at is narrower than one interior cross-section. Power set of a set SThe set of all subsets of S. Rational number A number of the form p/qwherepandqare integers and q\\e}io\\slsh= 0. T-LGL T-cell large granular lymphocyte leukemia represent s a spectrum of lympho-proliferative diseases. Void A void inside a protein is a connected interior empty spa ce fully buried from the outside of the protein.Index Ane map, 186 Alpha shape, 6 alpha complex, 7 dual simplicial complex, 7 Amino acid residue substitution rates, 78 Approximation algorithm, 146 approximation ratio, 146 Articial neural networks, 181 application to cellular networks, 185 crop simulation modelling, 186 reverse engineering of gene regula- tory networks, 185 architecture, 182 computational power, 183 feed-forward networks, 183 recurrent networks, 183 depth, 182 feed-forward, 182 function computation, 182 gate function, 182 sigmoidal, 182 threshold, 182 recurrent, 182 reverse engineering (learning), 184 loading problem, 185 probably-approximately-correctly learn- able, 184 pseudo-dimension, 185 Vapnik-Chervonenkis dimension, 184 Basic graph-theoretic concepts, 134Biomolecular networks, 103 phage lambda, 121 cooperativity, 123 epigenetic decision network, 121 lysogeny maintenance, 122 robustness, 124 state, 78 toggle switch, 121 Boolean networks, 137 asynchronous update, 137 denition, 137 Feed-forward Boolean network, 138 limit cycle, 138 synchronous update, 137 Cell, 133 eukaryotic, 133 prokaryotic, 133 Chain polymer, 84, 85 chain growth, 85, 87, 93, 94 conguration, 85, 87 conformational entropy, 78 excluded volume, 87 generating chain polymer, 86 growth strategy, 84 loop entropy, 78 monomer, 85, 87, 89 coordinates, 87 self-avoiding polymer chains, 84, 87 self-avoiding walk, 87 Models and Algorithms for Biomolecules and Molecular Netwo rks, rst edition. By Bhaskar DasGupta and Jie Liang Copyright \u00a9 2015 John Wiley & S ons, Inc.221222 INDEX end-to-end distance, 87 Chemical reaction, 104 Continuous time Markov process, 78 Decoys sequence decoys, 47 structural decoys, 47 Discrete chemical master equation, 105 ACME, 107 approximation, 113 continuous chemical master equa- tion, 113 Fokker-Planck approach, 113 Gaussian process, 116 Langevin 115 Langevin approach, 115 Poisson process, 116 stochastic dierential equation, 113 Taylor expansion, 114 direct solution, 106 nite buer, 106 buer capacity, 106 nite buer algorithm, 106, 121, 122 iBD, 107 independent birth-death component, 107 multi-nite buer, 107 optimal state enumeration, 106 reaction network decomposition, 107 truncation error, 111 Dynamical systems, 177 Boolean models, 180 communication delays, 178 control-theoretic concepts, 179 controllability, 179 observability, 180 deterministic vs. stochastic dynamics, 178 discrete vs. continuous state variables, 177 discrete vs. continuous time variables, 177 monotone dynamics, 193 algorithmic issues in computing the degree of monotonicity, 199 characterizations, 196 denition, 194 degree of monotonicity, 198 Ensemble properties, 77 Geometric constructs, 4 computing Delaunay tetrahedrization, 12 edge flip, 13 incremental algorithm, 12, 13 locally Delaunay, 13 computing Voronoi diagram, 14 discrete flow, 11 convex hull, 5Delaunay tetrahedrization, 5 Delaunay triangulation, 5 power distance, 5 Voronoi cell, 4 Voronoi diagram, 4 Voronoi region, 4 Interaction networks models, 133 dynamical, 135 continuous state, 136 continuous time, 136 dierential equations model, 135 discrete state, 136 discrete time, 136 hybrid state, 136 signed graphs, 137 associated signed graph, 137 topological, 134 directed graphs, 134 Ising model, 79 energy, 79 Marginal distribution, 86 Markov chain, 81 conditions, 81 aperiodicity, 82 irreducibility, 82 recurrent state, 82 detailed balance, 82, 84 property, 81 steady state, 82 time reversibility, 82 time reversible processes, 82 transition probability, 81 transition probability matrix, 82 Markov process, 81 MAX-CUT problem, 199 Molecular species, 104 Non-deterministic nite automata ( Nfa), 190 Piece-wise linear model, 186 biological applications, 188 delta-notch protein signalling, 189 genetic regulatory networks, 189 dynamics, 187 Pl-isomorphism, 188 equivalence, 187 piecewise-linear hybrid automata, 189 Potential function, 29 assumptions, 58 binding free energy, 57 Boltzmann assumption, 34 Boltzmann distribution, 33 data dependency, 64 deriving parameter values, 31 distance and packing dependent alpha potential, 44 eective potential energy, 33INDEX 223 empirical potential function, 30 from optimization, 47 functional form, 31 weighted linear sum, 31 general framework, 31 optimization, 31 statistical analysis, 31 geometric potential function, 44 geometric view, 48 knowledge-based eective energy func- tion, 30 membrane proteins, 62 Miyazawa-Jernigan contact potential, 34 hydrophobic nature, 39 non-additivity, 59 nonlinear potential function, 52 derivation, 52 optimality criterion, 50 optimization techniques, 53 partition function, 33, 57, 58 sequence dependency, 60 physics-based potential function, 30 probability of occupancy, 32 protein design, 56 protein stability, 57 protein structure prediction, 53 protein-protein docking prediction, 54 reference states, 33, 42, 45, 62 ideal gas, 43 internal random model, 62 permutation model, 62 Rosenblatt perceptron method, 50 theoretical model, 32 three-body interactions, 60 Protein descriptors, 31 Protein design, 47 Protein folding, 29 thermodynamic hypothesis, 29 Protein function prediction, 16 enzyme function prediction, 18 evolution of protein surfaces, 18 graph based methods, 16 matching pocket surfaces, 17 Protein representation, 31 Protein structure, 1 computing surface area, 14 computing volume, 14 packing analysis, 15 atom ball, 2 atom radius, 2 computing surface area, 9 computing volume, 9 Connolly's surface, 4 crystallography, 1 depressions, 11 distinction between voids and pockets, 11 electron density map, 1elementary surface pieces, 4 experimental techniques, 1 fused ball model, 2 hard sphere model, 2 idealized ball model, 2 Lee-Richards surface, 3 metric measurement, 9 molecular surface, 4 nuclear magnetic resonance (NMR), 1 pockets, 11 re-entrant surfaces, 4 renement, 1 size properties, 9 solvent accessible surface, 3 space lling model, 2 surface, 3 union of ball model, 3 united atom, 2 van der Waals radius, 2 voids, 4, 11 Protein structure and function, 16 Protein structures near neighbors, 44 degree of near neighbors, 45 Quadratic integer programming, 200 semi-denite optimization, 200 Cholesky decomposition, 200 vector program, 200 Rare event, 79 Reaction, 104 linear and nonlinear reactions, 104 reaction probability, 117 reaction rate, 104 intrinsic reaction rate, 104 reaction trajectory, 117 trajectory, 117 Markovian process, 118 probability of reaction trajectory, 118 Sampling technique, 77 importance sampling, 85 bias correction, 85, 89 weights, 85, 86, 89 bias correction, 86 joint trial distribution, 87 Markov chain Monte Carlo, 83 Metropolis Monte Carlo, 81, 83 move set, 84 proposal function, 84 proposal probability, 83 trial function, 84 partial sample, 86 proposal distribution, 80 rejection sampling, 80 sampling distribution, 80, 85, 89 sequential importance sampling, 85, 89 sequential Monte Carlo, 84, 87224 INDEX look-ahead, 87 partial sample, 89 prune, 89 resampling, 89 resampling probability, 89 sample variance, 89 weights, 89 target distribution, 79, 83-86, 89 decomposition, 86 intermediate distribution, 86, 89 trial distribution, 80, 85, 86 Scoring function, 30 Scoring matrices, 78 Signal transduction networks, 139 NET-SYNTHESIS software, 142 biochemical evidence, 140 correlation between dynamic and re- dundancy, 152 data Collection, 142 excitory and inhibitory influence, 139 genetic evidence of dierential responses, 140 graph-theoretic notations and termi- nologies, 139 null hypothesis model, 153 degree distribution, 153 null hypothesis testing, 155 null model bias correction, 155 other network reduction rules, 148 pharmacological evidence, 140 pseudo-node collapse, 147 random networks, 153 redundancy and degeneracy, 149 information theoretic measures, 150 topological measure, 151 reverse engineering, 155 combinatorial approach, 163 modular response analysis, 156 quality evaluation, 166 synthesis, 140 transitive reduction, 145 greedy approach, 146 Specic biological models, 209 C. elegans metabolic network, 214 T-LGLcell survival and death network, 215 ABA-induced stomatal closure network, 211 Drosophila segment polarity model, 209 Boolean, 210 Signal transduction, 210 EGFR signaling network, 212 Stochasticity, 103 microstate, 104 Monte Carlo simulation, 117 probability landscape, 104, 121 dynamically evolving probability land- scape, 108GPU-based solver, 108 iterative solver, 108 matrix exponential, 108 phage lambda, 122 steady state probability landscape, 108 small copy numbers, 103 state space, 106 nite state projection, 110 Krylov subspace method, 108 simplication, 108 truncation error, 111 stochastic simulation, 117 Gillespie algorithm, 118 stochastic simulation algorithm, 118 theoretical framework, 104 transition rate, 105 transition rate matrix, 105, 108 Stoichiometry, 104 stoichiometry vector, 104 Testosterone dynamics, 174 Topological structures of molecules, 6 Delaunay complex, 6 simplices, 6 simplicial complex, 6 Two-species interaction, 207 Uniform distribution, 87, 89 "}