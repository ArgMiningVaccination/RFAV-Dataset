{"title": "PDF", "author": "PDF", "url": "https://files.eric.ed.gov/fulltext/ED265245.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "ED OthersYouth Employment and Training Programs. The YEDPAYears.National Academy of Sciences - National ResearchCouncil, Washington, DC. Commission on Behavioral andSocial Sciences and Education.Department of Labor, Washington, D.C.ISBN-0-309-03595-38599-3-3239-75-120-01532p.National Academy Press, is an evaluation of the Youth Employmentand Demonstration Projects Act (YEDPA) which was in effect from1977-1981. The first chapter summarizes the youth employment problemand draws conclusions and makes recommendations based upon the data in the report. The next chapter draws a detailed picture of the youthunemployment problem, showing the widening yap between black andother youth in finding and keeping jobs, ac well as the increasingproblems for Hispanics and children from low income families. Chapter 3 describes the implementation of YEDPA and shows how the legislativemandates, time schedules, and program and policy environment in whichit operated determined the course of its progrp,,s and created constraints o' its operation. Chapter 4 outlines the procedures used in evaluatirthe effectiveness of the progimns. Chapters 5-8 reporton the effectiveness of the occupational skills training, labormarket preparation, temporary jobs, and job placement programs. Chapter 9 summarizes the research on program effectiveness derivedfrom large, representative national samples, using national databases. Appendices which are half of this report include: (1)\"Standardized Data Collection for Large-Scale Program Evaluation: AnAssessment of the YEDPA-SAS Experience\" (Charles F. Turner); (2) A list of reports considered by the committee in itsassessment--150-item bibliography; (3) \"Implications of the YouthEmployment Experience for Improving Applied Research and EvaluationPolicy\" (Robert Boruch); and (4) \"Estimates of Effects of Employment and Training Programs Derived from National Longitudinal Surveys and Continuous Longitudinal Manpower Survey\" (Valerie Nelson and Charles F. Turner). These reports are followed by five commissioned papers: \"Knowledge Development under the Youth Employment and DemonstrationProjects Act, 1977-1981\" (Richard F. Elmore); \"The Social Context of Youth Employment Programs\" (Elijah Anderson); \"Youth Joblessness andRace: Evidence from \"Hispanic Youthin the Labor Market: High School and Beyond\" (R...bertoFernandez; and \"The Participation of Young Women in Employment andTraining Programs\" (Margaret Simms). The study includes a brief index. (CG) (CG) (RUTHEMPLOYMEN,NDTRAININGROGRAMSTHEYEDPA YEARS Charles L. Betsey, Robinson G. Hollister, Jr.,and Mary R. Papageorgiou, editors Committee on Youth Employment ProgramsCommission on Behaviors i and Social Sciencesand EducationNational Research Council NATIONAL ACADEMY PRESSWashington, D. C. 1985 3 National Academy Press2101 Constitution Avenue, NW Washington, DC 20418 NOTICE The project that is the subject of this report was approved by the Governing Board of the National ResearchCouncil, whose members are drawn from the coe nails of the National Academy of Sciences, the Nahonal Academy ofEngineering, and the lnshtute or Medicine. The members of the ccmmittee responsible for the report were chosen for theirspecial competences and with regard for appropriate balanceThis report has been reviewed by a group other than the authors according to procedures approved by a Report ReviewCommittee consishng of members of the National Academy of Sciences, the Nahon.il Academy of Engineenng, and theInstitute of MedicineThe Nation.. Rc-earch Council was establishes ;-,y the Nahonal Academy of Sciences in 1916 to associate the broadcommunity of science and technology with the Academy's purposes of furthenng knowledge and of advising the federalgovernment The Council operates in accordance with general policies determined by the Academy under the authonty ofits congressional charter of 1863, which establishes the Academy as a pnvate, nonprofit, self-governing membershipcorporahon The Council has become the pnncipal operahng agency of both the Nahonal Academy of Sciences and theNational Academy of Engineering in the conduct of their services to the government, the public, and the scientific andengineenng communihes It is administered jointly by both Academies and the lnshtute of Medicine The NationalAcademy of Engineenng and the Inshtute of Medicine were established in 1964 and 1970, re.spechvely, under the charter ofthe National Academy of SciencesThis project has been funded with federal funds from the U S Department of Labor under contract number 99-3- 3239 -75-120 -01 The contents of this publicahon do not necessanly reflect the views or policies of the Department of Labor. Library of Congress Cataloging-in-Publication DataMain entry under titleYouth Robinson G.II. Papageorgiou, Mary R. IV. National (U.S.). Committee on Youth Employment Programs.HD6273.Y6548 1985331.3'42592'097385-25856ISBN 0-309-03595-3 Praited in the Uniteu States of America 4 COMMITTEE ONYOUTH EMPLOYMENT PROGRAMS ROBINSON G. HOLLISTER, JR. (Chair), Department of Economics, SwarthmoreCollegeROBERT F. BORUCH, Department of Psychology, Northwestern UniversityRAYMOND J. CARROLL, Department of Statistics, University of North CarolinaJAMES S. COLEMAN, Department of Sociology, University of ChicagoROBERTO M. FERNANDEZ, Department of Sociology, University of ArizonaJUDITH M. GUERON, Manpower Demonstration Research Corporation, New YorkJOEL F. HANDLER, School of Law, University of California, Los AngelesPATRICK W. MOORE, San Diego Regional Employment and Training ConsortiumRONALD L. OAXACA, Department of Economics, University of ArizonaJOHN OGBU, Department of Anthropology, University of California, BerkeleyPAUL OSTERMAN, Department of Economics, Boston UniversityPAUL E. PETERSON, Brookings Institution, Washington, D.C.HARRIET B. PRESSER, Department of Sociology, University of MarylandWILLIAM J. WILSON, Department of Sociology University of ChicagoDAVID A. WISE, John F. Kennedy School of Government, Harvard UniversityCHARLES L. BETSEY, Study DirectorMARY R. PAPAGEORGIOU, Research AssociateCHARLES TURNER, Senior Research Associate iii t-j Contents Preface vii 1Summary, Conclusions, and Recommendations 12Youth Employment and Unemployment 343Implementation of the Youth Employment and Demonstration Piojects Act 694Procedures Used in Evaluating the Effectiveness of YEDPA Programs 995Effectiveness of Occupational Skills Training Programs 1086Effectiveness of Labor Market Preparation Programs 1197Effectiveness of Temporary Jobs Programs 1378Effectiveness of Job Placement Programs 1619Evidence of Program Effectiveness From National Data Bases 175References 183Appendices 193A Standardized Data Collection for Large-Scale the YEDPA-SAS Experience 193Charles F. TurnerBReport List 220C Implications of the Youth Employment Experience for Improving AppliedResearch and Evaluation Policy 231Robert BoruchD Estimates of Effects of Employment and Training Programs Derived fromNational Longitudinal Surveys and Continuous Longitudinal ManpowerSurvey 254Valerie Nelson and Charles F. Turner v 6 Commissioned Papers 281Knowledge Development Under the Youth Employment and DemonstrationProjects Act, 1977-1981 281Richard F. ElmoreThe Social Context of Youth Employment Programs 348El iali AndersonYouth Joblessness and Race: Evidence from the 1980 Census 367George CaveHispanic Youth in the Labor Market: An Analysis of High School andBeyond 410Roberto FernandezThe Participation of Young Women in Employment and Training Programs 462Margaret SimmsIndex 487 vi '7 Preface In October 1983 the U.S. Department of Labor requested that the National ResearchCouncil undertake a study assessing knowledge about youth employment and trainingprograms, based primarily on programs carried out under the Youth Employment andDemonstration Projects Act (YEDPA). The Committee on Youth Employment Programs wasformed in the Commission on Behavioral and Social Sciences and Education to carry out thattask and worked on it from fall 1983 through spring 1985. This report is the result of thecommittee's efforts.The rationale of this report can best be understood in light of the charge to the committee,the nature of the Youth Employment and Demonstration Projects Act activities, and thefashion in which the committee went about its work.The committee's charge covered four tasks:To review what is known about the effectiveness of the principal types of YEDPAprograms;To assess existing knowledge regarding the implementation of youth employment pro-grams;To evaluate the YEDPA research strategy;To summarize the lessons learned from YEDPA for future policy development andprogram implementation.The Youth Employment and Demonstration Projects Act was passed by Congress andsigned into law by President Jimmy Carter in late 1977. The programs grouped under this actran approximately from 1978 through 1981, after which they were terminated or reorganizedby the n.w administration.YEDPA represented a substantial and rapid increase in expenditures by the federal gov.2rn-ment on youth employment and training programs, and YEDPA activities encompassedseveral different major types of programs. The diversity of programs was further increased bythe explicit injunction in the legislation \"to test the relative efficacy of different ways ofdealing with these [youth employment problems] in different local contexts\" and the result-ing substantial allocation of money to demonstration and research activities that were in-tended to demonstrate a wide variety of program concepts and attempt to assess them. It isestimated that over the 4-year period of YEDPA operations, about $600 million was allocatedfor explicit demonstration programs and their related research and that, even in the first year,1978, as many as 60 distinct demonstrations were funded in about 300 sites. The Office ofYouth Programs, which administered YEDPA, stressed the \"knowledge development\"aspects of these demonstration and research activities and sponsored extensive reporting anddata gathering concerning them.It is not surprising, then, that our committee found itself faced with more than 400 reports,vii gathered by the Employment and Training Administration of the Departmer t of Labor,which became the basic raw materials for our review of YEDPA. We found this mass of material both too much and too little. It was too much in the sense of presenting a seriouschallenge to the committee to design a strategy that would make it possible to assess so much material thoroughly and in the time available. It was too little in that such reports onindividual programs were not likely to provide broad and comprehensive views of either thenature of youth employment problems or the nationwide operations of YEDPA. In thispreface I attempt to indicate how we sought to solve these problems and, at the same time, to outline for the reader the structure and rationale of the report.As a first step, the committee members and staff sought to review and summarize theresearch on the nature of the youth employment problem; some of the research had been sponsored by YEDPA, but much of it was carried out independently, or under other spon-sorship, by scholars and research groups. The fruits of this work are represented in Chapter 2.This task was made considerably easier by the existence of several excellent overviews ofresearch in this field (which are referenced in Chapter 2). When entangled in a review of the details of YEDPA processes and programs, it is easy to lose sight of the very seriousemployment difficulties faced in 1978 by those youths whom YEDPA was designed to serve, problems that youths in 1985 appear to face in roughly the same degree. For that reason thecommittee found the material in Chapter 2 both a very important background and a reminder, as we proceeded through the rest of our work, not to lose sight of the situation of thepopulation at risk. We hope readers will find that material useful in a similar fashion.A second element in our strategy was to seek to deal with the more than 400 reports Thecommittee developed a set of criteriastandards of evidenceaccording to which the reportswere to be vetted. The standards constituted the minimum required for a report to be judgedgood social science evidence of the effects of a program on its participants. The staff, assistedby several outside consultants, screened all the reports according to the standards and thenclassified those meeting the standards according to program type and target groups served.(This screening process is described in Chapter 4.) This process resulted in a severe reduction in the number of projects that were to be reviewed in depth: only 28 projects met ourstandards for in-depth committee review. This sharp reduction in the number and scope ofprojects that met even our minimal standards of evidence greatly surprised us, and it must be discouraging for those who had hoped for morein terms of sheer volume of resultsfromthe YEDPA knowledge development process.The committee then turned to an in-depth review of those projects. This was accomplishedby dividing into four subcommittees, one for each of the four major categories of programtypes: occupational skills training, labor market preparation, temporary jobs, and job place-ment. The subcommittees and staff thoroughly reviewed all the reports, and the committeethen held a five-day working conference to review and debate the subcommittee conclusionsand begin drafting what eventually became Chapters 5 through 8. Those chapters contain ourreview of what is known and not known about the effectiveness of youth employment andtraining programs, based primarily, though not exclusively, on the YEDPA experience. Thedraft reports of ....le subcommittees were edited, amended, supplemented, and converted intothe present report chapters primarily by staff member Charles Betsey. Important additio lalwork on assessing the sizable data base on YEDPA programs created by the EducationalTesting Service was undertaken by staff member Charles Turner and appears as Appendix A. Chapters 5 through 8 represent the bulk of the committee's work, and we have chosen topresent that work in considerably greater detail than is the practice in more general reviews.We felt it was important to make it possible for readers to find the details of evidence uponwhich our conclusions and recommendations are based and to lay bare the unevenness in coverage and weaknesses of the material we used, as well as the strengths.We also faced, as part of our charge, the task of drawing lessons about the implementationAli 9 of youth programs from the YEDPA experience. This called for assessments of implementa-tion both at the national level of YEDPA design and at the local level of program realization.The latter assessment could, to some degree, be drawn from the mass of 400 reports onYEDPA activities. Thus, as the reports were screened according to our criteria of effective-ness, we also noted those cases in which the reports appeared to provide useful informationregarding program implementation. These reports provided a body of material on specificprogram implementation, but we wanted to supplement this material to broaden our view ofimplementation.This desire led us to the third major element of our strategy: to reach outside the committeeand its staff. To deal with the task of drawing general conclusions about implementation atthe local level, we commissioned three short papers based on the material identified duringour screening process and the authors' own experiences with youth employment and trainingprograms. These papers by Erik Butler, James Darr, and Philip Moss providcu useful addi-tions to our own review. We also wanted to obtain a very broad perspective on the design andimplementation of YEDPA at the national level. To this end, at a relatively early stage in ourdeliberations, we asked Richard Elmore to carry out a substantial review of the developmentand administration of YEDPA. This review was critical for the committee both because of itscomprehensiveness and quality and because of its timeliness; it appears as the first of thecommissioned papers in this volume.Elmore was able to provide the committee with a draft of his review prior to our five-dayworking conference and to attend the conference for a few days to discuss the details of hisreview with the committee. Many committee members, myself included, found his paper avery important part of our education about YEDPA; it brought together many elements of thedevelopment and administration of YEDPA at the national revel and presented the views ofmany of the key actors in those events. This does not mean that the committee endorses all thecharacterizations of events or conclusions about processes given in Elmore's paper, but webelieve it is a valuable paper for understanding the YEDPA experience, and it was helpful tous in drafting Chapter 3 (as well as other sections of our report). Chapter 3, then, provides thedetails of our review of implementation of YEDPA programs, based on the program reportsthemselves and the other materials. The chapter was largely drafted by staff member MaryPapageorgiou.The third element of our strategyreaching beyond the committee for assistance in fillinggaps in information and knowledgeinvolved not only the papers on issues of implementa-tion but also on other topics for which the committee felt its own expertise was lacking or forwhich reviews of the literature proved insuffident to fill important gaps. It should be notedthat all of the papers we commissioned were written under considerable time pressure, as inmost cases we did not identify the gaps in knowledge until our deliberations were well underway. In those cases in which we felt the commissioned papers not only served the immediateneeds of the committee but also were likely to be of general interest to readers of this report,they are included in this volume.We reached outside the committee and staff not only through papers but also throughpersonal contacts. At a very early stage of our work, Andrew Sum of Northeastern Universi-ty, who has had a broad and continuing acquaintance with youth employment and trainingprograms, met with the committee and provided an overview of programs and youthemployment problems that helped many of us to become quickly acquainted with develop-ments in this field. Seymour Brandwein of the Depa:tment of Labor, who was at the NationalResearch Council as a visiting scholar during our study, provided continuing advice andguidance to the committee and staff on the basis of his long and thoughtful experience withemployment and training programs. Several committee members and staff met with staffmembers of two other organizations that had been involved in reviews of YEDPA programeffectiveness: Andrew Hahn and Robert Lerman of Brandeis University and Linda Cole,ix 1 u Norman Freeberg, Jules Goodison, and Donald Rock of the Educational Testing Service. Bothgroups gave generously of their time, as well as of materials they had developed for their ownreviews.In addition to reaching beyond the mass of reports on YEDPA programs through commis-sioned papers and personal contacts, we felt it important to consider other sources of data thathad been, or could be, used to assess the effectiveness of youth employment and trainingprograms. Conspicuous among these sources were two national data bases, the ContinuousLongitudinal Manpower Survey (CLMS) and the special youth sample of the NationalLongitudinal Surveys (NLS). Our review and assessment of studies based on these two majordata bases is provided in Chapter 9, which was largely drafted by Valerie Nelson, who servedas a consultant throughout the project, and staff member Charles Turner. While this review ofstudies from CLMS and NLS did not alter in any respect our conclusions about the effective-ness of youth programs, it did provide some very important information bearing on appropri-ate methods of evaluation of youth programs that we believe significantly strengthens thebasis for our recommendations on the use of random assignment.Now, at last, we come to the rationale for the chapter that we have placed first, \"Summary,Conclusions, and Recommendations.\" This chapter constitutes the committee's response tothe charge with which we began our work, which is the principal reason we have elected toput it at the front of our report. Readers will find in this chapter the committee's majorfindings, conclusions, and recommendations about the nature of the youth employmentproblem, the implementation of youth employment and training programs, the effectivenessof different types of programs for different segments of the youth population problem, thestrengths and weaknesses of methods of research on and evaluation of youth programs, andthe future evolution of youth employment and training programs and research on them. Weare grateful to staff member Mary Papageorgiou for drafting and redrafting many versions ofthis chapter as the committee debated the issues.Chapter 1 obviously cannot stand entirely on its own, but depends on the detailed materialthat is provided in the rest of the report. However, as I noied above, because the material thatthe committee was asked to assess was so sizable and complex, we felt that the main chaptersof the report had to have greater detail than is usual in such reports. Since not all readers willwant to work their way tlrough that detail in order to reach our summary statements, wechose to broaden the opening chapter of conclusions and recommendations to provide areprise of major themes and to make explicit the limitations of our review and the referencesto the particular programs upon which each conclusion is based.In cddition to the efforts of the committee and its staff, the contributions of several otherpeople should be acknowledged. Fred Romero and William Showier of the U.S. Departmentof Labor provided essential support to the project and access to the materials on which thereport is based. David A. Goslin, Executive Director of the Commission on Behavioral andSocial Sciences and Education provided useful guidance at several critical junctures. EugeniaGrohman, Associate Director for Reports of the commission, worked with the authors and theNational Academy Press to edit and produce this volume. Jean Shirhall provided additionaleditorial assistance, and Deborah Faisson prepared the manuscript through many revisions.This report would not exist without the contributions of these people.In closing this preface, I would like to emphasize that the committee and staff membershave been motivated throughout our work by awareness of, and concern about, the continu-ing problems of young people in our societyparticularly those who have dropped out ofschool, black and Hispanic youths, and women, especially those who are unmarried andhave childrenin obtaining and holding a decent job. We have not hesitated to indicate whenevidence is inadequate, or completely lacking, to point the way toward more effective policiesand programs, and we have tried to draw the lessons from past experiences that may help to avoid the repetition of past mistakes. Since, however, the problems persist, we are concernedx 11 that the identification of mistakes of the past not become a basis for failure to act in thepresent. We must continue to try to enhance youth employment opportunities. It is c Ar hopethat this report helps to delineate such a path for continuing efforts. xi 12Robinson Hollister\"., ChairCommittee on YouthEmployment Programs OUTHEMPLOYMENNDTAININGROGRAMSTHEYEDPA YEARS 13 1Summary, Conclusions, andRecommendations In response to high levels of unemployment and other employment-related problems of American youth, the federal government enacted theYouth Employment and Demonstration Project:, Act (YEDPA; P.L. 95-93) in1977.This legislation established a vari ty of employment, training,and demonstration programs for youth. With the passage of YEDPA,federal spending on employment programs earmarked for youth approxi-mately doubled, bringing the total to about $2 billion per year.Besides this substantial commitment of funds, YEDPA was unique in itsexplicit commitment of substantial resources to research and evaluationefforts intended to test alternative ways of meeting the needs of youth.YEDPA programs ended in 1981 with the change in presidentialadministration. At that time the products of YEDPA's research had notbeen comprehensively evaluated, and there were questions about what hadbeen learned from this undertaking. Two years later the U.S. Departmentof Labor (DOL) requested that the National Researc.. Council (NRC) reviewthe products of the YEDPA research effort. The following eight chaptersdetail the findings from that review; this chapter summarizes ourfindings, conclusions, and recommendations. THE NATURE OF THE YOUT - EMPLOYMENT PROBLEMIn focuLdng on the nature of ith employment problem at theend of the 1970s, as YEDPA began, -s helpful to note that themajority of out-of-school youths found jobs and, when they lost or lefta job, found another one without a long period of unemployment. It haslong been recogr. zed, however, that youth employment is more sensitiveto the cycles of economi,- activity (secession and expansion) than isthat of adults: the pa centage decline in employment during a recessionis generally greater for youths than for adults, but the percentageincrease in employment during recovery is also greater than for adults.What was much more disturbing was the worsening long -term trend--whichemerged clearly in the 1970s--in the employment rates of youths relativeto adults, even when measured from the peak of expansion of one businesscycle to the next. Furthermore, the data reveal substantial differencesin that trend according to the race and sex of the youths; the long-term 1 14 2 trend in employment was much worse for minority, principally black,groups than it was for the white majority.The most revealing picture emerges from data on employment-to-population rates that separate subgroups of the youth population byrace, sex, and school status. Those data show that from 1964 to 1978there was a growing gap between the employment-to-population ratios ofwhite and black youths, for both in-school and out-of-school youths.For in-school youths, employment rates for whites were growing whilerates for black males were falling and those for black females were notgrowing as fast, yielding an increasing black-white gap in employmentrates.While some may regard in-school employment opportunities oflesser importance, researchers have found that, holding measured char-acteristics constant, those youths who work during school years havehigher employment rates and wages after their school years. Thisfinding may simply reflect that youths who are more motivated (anunmeasured characteristic) both seek work more energetically while inschool and seek, find, and perform work better after school, but thepossibility cannot be excluded that the in-school work experience perse eahances later employment and earnings. If so, the growing black-white in-school employment gap foreshadows a later out-of-schoolblack-white gap in employment and earnings.The black-white employment gap for out-of-school youths also grewduring this period for both males and females. And this occurred whilethe previously existing gap between blacks and whites in years ofschooling attained was substantially reduced. Given the generallyacknowledged positive relationship between years of schooling attainedand employment and earnings, this reduction should have narrowed theemployment gap between blacks and whites; however, it did not do so, ornot sufficiently to offset other factors widening the gap. Researchfurther shows that within this out-of-school group, employment problems(lower chances of getting a job, lower wages when a job is obtained,higher chances of losing a job, longer periods of remaining without ajob having lost one) are highly concentrated among minority-group,inner-city, low-income, and high school dropout youths. For those withcombinations of these characteristics the problems are compounded.Finally, it is apparent that young unwed mothers have very serious andspecial problems in qualifying for, finding, and holding jobs, espe-cially at earnings sufficient for their families' economic viability.Since the end of YEDPA in 1981 the United States has experiencedboth the deepest recession since the 1930s, which reached its trough in1983, and a sharp economic recovery. There has also been a notabledecline in the absolute size of the youth population since it reachedits peak in the early 1980s. It seems reasonable to ask in light ofthese events if the nature of the youth employment problem has sub-stantially changed, in its general configuration, from what it was in1978, as outlined above, when YEDPA began. Although exact comparisonscannot be made (comparable data are not yet available), it appears thatet the beginning of 1985 the employment problems of youths were ofabout the same magnitude and configuration as they were in 1978,including racial differentials. 15 3LTMITATIONS OF THIS REVIEW Our ability to respond to our charge was necessarily constrained bythe nature of the material we had to work with. Although we searchedthe literature available beyond the reports generated as part of theYEDPA process and consulted with people experienced with youth programsand related research, we had to rely almost exclusively on the reportsof particular YEDPA youth demonstration projects to assess the effec-tiveness of youth programs. The exceptions were studies of threeprograms that began before YEDPA, the Job Corps, the Summer YouthEmployment Program, and Supported Wok.We have attempted to test the iniividual YEDPA research reportsagainst reasonable standards of scientific quality with respect to boththe data collected and the methods c6ed to me Sure program effects.The reports that met such standards were not necessarily evenly dis-tributed over the range of youth programs and target groups. Thus wecould not address certain issues with respect to the role and effec-tiveness of youth employment and training programs because of a lack ofreliable evidence.Since we were always in the position of examining these programsthrough the lens of their respective research reports, it is importantthat we clearly distinguish between the quality of the research and the(sometimes unobservable) quality of the programs them:elves. In someinstances wt found reliable evidence, both positive and negative, fromwhich to draw conclusions; in ot'er instances the available evidencewas not sufficienhly reliable for us to draw any conclusion, one way orthe other.ReadeLs should be careful not to confuse a conclusion aboutthe failure of research to provide adequate evidence with a c:mclus anthat a particular program, itself, was ineffective or failed in somemanner.A conclusion of noneffectiveness requires evidence, just as aconclusion of effectiveness does. In the absence of reliable evidence,no inference is possible.In addition to the above limitations, our ability to draw firmconclusions was further constrained by two conditions that affected theimplementation of YEDPA and, particularly, the conduct of the research.First, YEDPA programs and research were mounted in considerable hasteand in a period in which many other employment ana training and researchefforts were going on, so that both program and research resources werestretched very thin. (There are a few nctable exceptions to thisgeneralization, e.g.,, Job Corps and Supported Work.) Second, with thechange of administration in 1981, less than 3 years after YEDPA's quickstart-up and troubled implementation, both programs and evaluationefforts were abruptly halted.As a consequence of these two factors, most of the data on whichevaluations were based, again with a few notable exceptions, weregathered at a stage at which Programs had not been stabilized. As afurther consequence, relatively few program evaluations provide datafor long postprogram periods: virtually all of the YEDPA only 3- to 8-month postprogram follow-ups. Only twoevaluations had as long as a 3-year follow-up (Job Corps and SupportedWork).Our review suggests that longer-term follow-ups are important 16 4 in determining the time pattern of program effects, some of which decayrapidly and some of which emerge slowly.Further limiting our ability to draw firm conclusions were theserious problems of researchers in creating reasonable comparison groupsand preventing sample attrition over waves of the data collection.These problems sharply reduced the number of studies we could reviewand put in question the reliability of the results of several others.As a result of these limitations, our coverage of YEDPA programs isuneven and not necessarily representative of overall youth programactivity during that period. In many cases conclusions about theeffects of specific types of programs are based on only one or twoevaluations, in other cases there is no reliable evidence for any con-clusion of program effect. In addition, the quality of evidence varies,sometimes supporting strong conclusions, sometimes meroly suggestingthe direction of program effects. In presenting our conclusions,therefore, we try to indicate the source of the evidence an4 the degreeof its reliability, and we distinguish lack of reliable evidence fromlack of evidence per se.A final limitation of this review concerns the very magnitude ofYEDPA and Comprehensive Employment and Training Act (CETA) programsfrom 1977 through 1981. It has been estimated that in 1979 as much astwo-fifths of all jobs held by black teenagers were in governmentemployment and training programs. Thus; even when comparison groupswere reasonably created, there may well have been substantial anountsof employment, training, and related effects from federal programsamong the comparison group members. To the degree this problem isserious and undetected in the evaluation data, the participant-comparison contrasts will underestimate the impact of the programs. FINDINGS AND CONCLUSIONS ON PROGRAM IMPLEMENTATION The conditions under which YEDPA was implemented severely con-strained both the potential effectiveness of the programs themselves inreaching their objectives and the related research and demonstrationactivities that sought to evaluate program effects and to create areliable knowledge base for future youth programs. Implementation wasaff2cLed by:(1) the size and implicit duality of the YEDPA service-research mandate; (2) the congressional and executive time schedulesimposed on YEDPA program operations and research results; and (3) theinstabilitl of the service delivery system due to fluctuations inemployment and training policy, regulations, and funding levels. Thecombination of these three factors was significant in determining thecourse of YEDPA at both the national and local levels.The duality of the YEDPA mandate, which was inherent it theenabling legislation, stemmed from the charge to mount new and verylarge service delivery programs quickly and at the same time co designand conduct comprehensive research and evaluation. Either of thesetasks by itself would have been a sizable and complex endeavor; takentogether they burdened the system not only by their sheer magnitude, 17 5but by their diversity of purpose, at times pitting the interests ofprogram delivery against those of research and knowledge development.The imposition of two consecutive time limits also constrained theimplementation of YEDPA programs and research. The first, imposed bythe legislation itb required that YEDPA be sufficiently operationalwithin 1 year of passage to warrant congressional reauthorization; andthe second, imposed by the executive office, required that within 2years the results of YEDPA program research be adequate to inform theVice President's Task Force on Youth Employment for its subsequentreport to Congress. These limits put tremendous pressure on thenational office of the Department of Labor to get both the programs andthe research under way immediately and foreshortened the time availablefor careful planning of either the programs or the research on theireffects.The third major factor constraining YEDPA was one that overridesYEDPA itself, and of which, in fact, YEDPA is a prime example: thetremendous fluctuations from one administration to the next, and oftenfrom one fiscal year to the next, in employment and training policy,regulations, and most importantly, funding levels. This instability,perhaps r-'re than any other factor, undermined the employment andtraining system, particularly at the local level, where in response tosuch changes adjustments in all aspects of program operations ultimatelyhave to be made. Such fluctuations precluded a more stable and orderlydevelopment and institutionalization of the youth employment system.Given the instability of the employment and training system, togetherwith the implementation requirements of YEDPA, it was somewhat unreal-istic to expect that within 3 years these programs would be fullyoperational and ready to prove their effectiveness.CONCLUSION:The YEDPA le islation created a rram thatcombined too short a ttme schedule with too many differentprogram elements and objectives. The demand to quickly implement the full range of elsyIeualitofmany of the programs. In addition, the pressure to obtain awide range of rf.earch results on those r rams within a shorttime compounded Ile problem and resulted/ in many cases, inpoor reseax:th on hastily constructed programs. It may be thatthe lack of proven effectiveness of many programs is due asmuch to the instability of the system as to the inherent natureof the programs. National Office Management of YEDPAThe tasks of designing and implementing YEDPA programs and researchactivities strained the capacity of DOL's Office of Youth Programs(OYP) given its very small staff and limited research capability. Inresponse to these demands OY1 created a system of indirect management,delegating substantial responsibility for the design, implementation,management, and evaluation of major YEDPA demonstration programs toprivate nonprofit intermediary organizations. In addition OYP extended 18 6the staff's research capability through agreements with other researchunits within the Department of Labor, with the Educational TestingService (ETS), and with Brandeis University's Center for Employment andIncome Studies (CEIS). Agreements with other federal agencies tooperate other portions of YEDPA were another means of expanding theYEDPA management structure.As a means of quickly disbursing funds and implementing programsunder severe time constraints, the agreements with other parties wereexpedient.As a means of managing programs and research, however, thatapproach was not very effective. Of the four intermediary organiza-tions, only two, the Manpower Demonstration Research Corporation (MDRC)and the Corporation for Public/Private Ventures (CPPV), producedcompetent research on program impacts on participants. The results orprograms operated by the other two intermediaries, the Corporation forYouth Enterprises (CYE) and Youthwork, organizations created to manageYEDPA demonstrations, are largely unknown because those organizations,although they did produce reports, did not attempt to assess programimpact in a quantitative manner that could be evaluated. The resultsof programs operated under interagency agreements are also unknowneither because no program research was conducted or because researchreports failed to meet our criteria of scientific evidence. Ingeneral, consideri'g the amount of YEDPA funds channeled throughintermediaries and interagency agreements, remarkably little is knownabout the programs or their results.The results of OYP's other agreements were also mixed. Agreementswith other ETA research units to incorporate a youth sample in theNational Longitudinal Survey (NLS) and YEDPA samples in the ContinuousLongitudinal Manpower Survey (CLMS) data bases produced useful results.The agreement with the Educational Testing Service to establish a largenational data base on YEDPA programs and participants, however, waspoorly planned and implemented. The support provided by the Center forEmployment and Income Studies was effective in documenting and assessingYEDPA programs, but CEIS's technical assistance and oversight of YEDPAresearch were not--and given the scale of the task, could not havebeen--sufficient to ensure the comprehensiveness of its research designor the quality of its execution, at least as evidenced by our review.CONCLUSION:The resources provided to the Office of YouthPrograms were woefully insufficient to its charge to mount andmanage YEDPA programs and research. Lacking research staff andresourcesOYP dele ated resnsibilit for the desi n andevaluation of large portions of the YEDPA demonstration researchagenda to parties outside the Department of Labor. Theresulting management structure lacked sufficient control at thecenter to provide coherence in program objectives and policiesto monitor developments, and to ensure accountability.These conditions had their greatest impact at the local level.With its additional reporting requirements, increased federal controlover program design and target groups, increased services to youths,and the demands of research and demonstration, YEDPA imposed substan- 19 7 tial administrative burdens on local prime sponsors.The competingdemands of a substantially increased Public Service Employment ?rogramand the regular programs under the Comprehensive Employment andTraining Act (CETA) placed YEDPA in a strained local environment.The demands of the YEDPA agenda and the time schedule for theirimplementation severely hampered local program planning and assembly.The increased federal program requirements compressed the alreadyshortened planning and approval process, which was complicated by thelack of clear guidance from the national office. To the extent thatthese conditions interfered with the careful planning of se-vices,selection of program operators, coordination with other parties it thelocal service delivery network, identification and recruitment ofparticipants, and assessment of local need for these programs, therewere consequences for each subsequent stage of program operations and,ultimately, for the success of the programs.Despite these problems, YEDPA did succeed in mounting new programs,at double the size of previous youth programs, and in providing largenumbers of disadvantaged youths with jen. Furthermore, the evidenceindicates that those jobs were generally well supervised and worthwhileexperiences for both the participants and their employers. Targeting, Recruiting, and Retaining YouthsResearch on YEDPA programs cites numerous problems with targetingand recruiting sufficient numbers of eligible youths from the designatedtarget groups:in-school and out-of-school youths meeting criteria ofeconomic disadvantage. This problem was attributed in part to theshort planning time and the resulting tendency of prime sponsors tobase needs assessments on outdated information and to overestimatetarget group size. In addition, a legislative requirement that youthsin regular CETA programs be served at the same levels as previously andthe strict eligibility requirements for some YEDPA programs may haveresulted in a shortage of eligible youths in some local areas.A related problem cited in many reports was the tendency of programoperators to serve the least disadvantaged of the eligible youths,leaving the most disadvantaged and needy without services. Thisphenomenon, known as \"creaming,\" reflects the tradeoff that manyprogram operators perceived between serving those most in need versusthose more likely to succeed. It raises both equity and efficiencyissues to the extent that the less disadvantaged might have achievedthe same employment results without benefit of the programs.An example of this tradeolf, and one representing a major dilemmafor YEDPA, was the targeting of services for dropout versus in-schoolyouths.An inherent tendency of many YEDPA programs was to gravitateto the in-school population. A 22 percent YEDPA set-aside for linkageswith the schools was an additional incentive for local prime sponsorsto target in-school youths. The dilemma was that the group most inneed of employment services--the dropout population --was also the groupthat was hardest to recruit and to serve successfully. Conversely, thegroup most easily recruited and served--the in-school population--was 20 the group for which services were less critical (or at least for whomthe problem was less clearly defined).Though it is widely recognized that of all youth employment problemsthose of school dropouts are the most serious, there appears to be atendency for employment and training programs to avoid serving thisgroup.Many programs designed specifically to serve dropouts (eitherthrough school-conditioned work or through alternative education,training, or work settings) often had difficulties recruiting them and,once they were recruited, experienced difficulties retaining them inthe programs.Other projects designed to serve either in-school orout-of-school youths, facing similar difficulties, evolved towardserving in-school youths, recasting the dropout problem in terms ofprevention instead of zemediation.CONCLUSION:In meetirthe increased * rollment youthstended to focus resources on the in-school population. Evenwhen programs were specifically targeted to dropouts, theyoften had difficulty in recruiting and retaining them. As aresult, the question of how to L.:ach and serve dropout youthseffectively was largely unanswered by YEDPA. Enrollment of Young WomenMost of the youth programs we reviewed enrolled substantial numbersof young women, and evidence from some programs suggests more p.rsitiveeffects for young women than for young men. Mans of the programs, how-ever, encountered difficulties maintaining enrollment of economicallydisadvantaged young women, apparently because of the high incidence ofteenage pregnancy and childbearing. Most program operators andevaluators apparently overlooked this characteristic of the targetpopulation, and so there is little direct evidence on the effect ofpregnancy and childbearing on program participation or on the effect ofprogram participation u,a subsequent pregnancy and childbearing.Evidence from one demonstration program designed to serve pregnantand parenting teenagers under the age of 18 (Project Redirection) isequivocal on the effect of a service-coordination strategy in reducingpregnancy and increasing subsequent employment and earnings. Neitheris there evidence to date that would allow clear distinctions to bemade as to the effects of alternative decisions abour pregnancy resolu-tion, i.e., birth, adoption, rr abortion, on other program outcomes.CONCLUSION:Most youth programs hadvoung women.Many, especially thoseencountered difficulties maintainingdisadvantaged young women because ofchildbearing.substantial enrollmentsenrollment of economicallYthe high incidence of 21 9 FINDINGS AND CCNCLUSIONS ON PROGRAM EFFECTIVENESSOur conclusions are based on a review of 28 programs, includingboth demonstration projects and regular youth programs.In this reviewwe proceed by type of program and within type of program by targetgroup, out-of-school youths (both dropouts and graduates) or in-school youths. Occupational Skills Training ProgramsOur conclusions on skills training are based on evaluations of onlytwo programs, the residential Job Corps program for out-of-school,mainly dropout, youths and an apprenticeship program for in-schoolyouths. Occupational Skills Training Programs for Out-of-School Youths:The Job CorpsThe Job Corps stands out in our review as a program for which thereis strong evidence regarding program effectiveness. The quality of theevaluation reviewed, in terms of sample sizes, comparison group method-ology, sample attrition, and the measurement of outcome variables,lends confidence to these conclusions.The Job Corps is a comprehensive program providing occupationalskills training, basic (and remedial) ed.: ation, counseling, healthcare, and job placement to youths more disadvantaged than typicalparticipants in youth programs. Although the contribution of eachcomponent part of the program is not known, it is clear that as a wholethe program has provided positive benefits to participants in terms ofemployment, earnings, and education.On average, for up to 3-1/2 years after participation, Job Corpsenrollees earned 28 percent more per year ($567 in 1977 dollars) andworked 3 weeks more per year than nonparticipant comparisons. Inaddition, participation reduced receipt of welfare and unemployment by2 weeks and 1 week per year, respectively.CONCLUSION:Job Corps participation resulted in gains inemployment and earnings in the postprogram period and indeclines in receipt of welfare and unemployment payments.These positive effects persisted at a relatively stable ratefor up to 4 years after youths left the program. Participation in the Jobs Corps increased the probability that JobCorps enrollees would receive a high school diploma or a GeneralEquivalency Diploma (GED). Specifically, the probability was .24 forparticipants compared with .05 for comparisons.CONCLUSION:Job Corps participation resulted in gains ineducational attainment during the program as measured bycompletion of GEDs. 22 10The Job Corps evaluation measured criminal activity and found thatJob Corps participation significantly reduced the criminal activity ofparticipants.CONCLUSION:Jobs Corps participation resulted in decreases incriminal activity, as indicated by rates of arrest duringprogram participation and decreases in seriousness of crimes inthe postprogram period.In addition, although the Job Corps by far exceeded the per-participant costs of other youth programs, the benefit-cost analysisindicated a net benefit.CONCLUSION:The benefits of Job Corps participation in termsof increased employment and earnings and decreased crime andtransfer payments exceeded the costs by a sizable margin(62,300) per enrollee. Other Occupational Skills Training Programs Although there is substantial evidence on the effectiveness of theJob Corps, it is not known which of its several component parts con-tribute to which effects; how much (if any) is due to the self-selectionfactors of youths who enroll in the program; or how program componentsand participant characteristics interact. The residential requirementof the Job Corps, in particular, is untested as a factor in explainingthe program's effectiveness and precludes generalizing its results tononresidential settings. Nonresidential skills training would certainlybe less expensiie to operate than the Job Corps; however, YEDPAproduced no reliable evidence on the effectiveness of occupationalskills training provided in a nonresidential setting for out-of-schoolyouths generally or for the severely disadvantaged population ofout-of-school youths served by the Job Corps. Occupational Skills Training Programs for In-School YouthsThe committee found tew studies of occupational skills trainingprograms operated under YEDPA. This was due, at least in part, to aconcern that participants require a sufficiently high level of academicpreparation to be able to gain from such training.We reviewed only one program providing occupational skills trainingto in-school youths. This program (New Youth Initiatives in Apprentice-ship) was designed to prepare high school seniors for registeredapprenticeships after graduation.CONCLUSION:There is only very limited evidence from YEDPA onthe effectiveness of skills training for in- school youths. Theonly program that provided evidence of reasonable qualityshowed no effect on participants' postprogram earnings or 23 11employment rates. However, this program was so special innature and participant characteristics that one would not wishto base general conclusions about skills training for in'- schoolyouths on the evidence from this program alone. Labor Market Preparation ProgramsThe programs classified as labor market preparation programs in ourreview were very heterogeneous in terms of their services andactivities, but they shared the long-term goal of preparing youths fortheir future work livP7 by improving their personal skills, knowledge,and attitudes toward the work place. Activities ranged from careerexploration and job search assistance to remedial education andcombinations of work experience and classroom training. The programsalsc varied greatly in intensity and duration, ranging from 5 to 35hours per week and from 10 weeks to 1 year. Programs for Out-of-School YouthsStudies of labor market preparation programs serving out-of-schoolyouths tended to provide sounder evidence on program effectiveness thandid studies of programs serving in-:school youths. In the 3- to 8-monthpostprogram period, participants often exhibited significantly betteremployment outcomes than nonparticipants. It is particularly trouble-some, however, that the term \"out-of-school youths\" is used to refer tohigh school graduates as well as dropouts: the programs providingreliable evidence served varying mixtures of the two groups and did notproduce separate analyses of effects. This lack of separate analysisfor dropouts and graduates conditions our confidence in the evidencebecause program outcomes (e.g., employment and earnings, and educationalattainment) might be influenced by whether the youths had completedhigh school.CONCLUSION:YEDPA programs providing labor market preparationfor out-of-school youths resulted in some positive effects onemployment in the 3 to 8 months following program participation(Alternative Youth Employment Strategies, the Recruitment andTraining Program, Project STEADY). There are no reliable data,however, to determine whether these short-term gains aresustained over the long run or whether such programs had anyeffects on educational attainment or other goals, such asreduced crime and substance abuse. Programs for In-Schoo7 Youths Some of the reports on in-school programs we reviewed indicatedthat program operators did not expect to directly affect the youths'postprogram earnings or employment; instead, they concentrated on other 24 12 program goals, such as improving reading, mathematics skills, workattitudes, and other skills measured by the Standardized AssessmentSystem, a battery of tests developed by the Educational TestingService.Although numerous programs under YEDPA provided labor marketpreparation services to in-school youths, the research on the effectsof these programs was of low quality. Even for the few researchreports of sufficient quality to be reviewed in depth (OpportunitiesIndustrialization Centers of America, National Puerto Rican ForumNPRFProject Redirection) each was so seriously flawed in onerespect or another that we could draw no conclusions regarding theeffects of such in-school labor market preparation programs onemployment, earnings, educational attainment, or other goals. Temporary Jobs Programs Programs providing temporary subsidized employment have untilrecently, with the passage of the Job Training Partnership Act (JTPA),been a major focus cf employment and training policy for youths. Theobjectives of these programs were to solve the immediate employment(and income) needs of disadvantaged youths and to provide them withwork experience which would be a basis of future employment. Inaddition, under YEDPA a major thrust was the testing of an entitlementto subsidized jobs for economically disadvantaged youths (YouthIncentive Entitlement Pilot Projects), which was designed to encouragethem to remain in or return to school. Programs for Out-of-School Youths Two subsidized jobs programs operated under YEDPA, Ventures inCommunity Improvement (VICI) and Supported Work, showed that partici-pants experienced increased employment and earnings during the programcompared with a similar grcup of nonparticipants.CONCLUSION:Temporary jobs programs for out-of-school youthsthat were operated during the YEDPA period were effective inincreasing participants' employment and earnings during theperiod of program participation.The types of subsidized job opportunities provided in YEDPAdemonstration programs varied widely. Most, as required under CETA,were in the public sector. YEDPA, however, for the first time allowedwork experience placements in private for-profit businesses. Evidencefrom the Public Versus Private Sector Jobs Demonstration Projecttentatively indicates that while it was possible to create subsidizedemployment in the private s6,tor, substantially more effort wasrequired to do so. This finding is not surprising considering the lackof experience of prime sponsors in developing private sector jobs andthe lack of experience of the employers in working with government-sponsored programs. Evaluations of Supported Work and VICI programs 25 13indicate that jobs provided were often of high quality and producedoutput that was of value to the employing agency and to society ingeneral. CONCLUSION:Subsidized jobs programs for out-of-school youthscan be effectively operated in the public and private sectors,though substantially more effort is required to enlist privatesector employers. Such jobs need not be \"make-work\" but canprovide output of positive social and economic value.Probably the most important goal of temporary jobs programs forout-of-school youths is to provide an experience that will raise thepostprogram employment and earnings of participants over what theywould have been without that experience. Unfortunately, the onlyevidence on this issue that we found reliable was that for SupportedWork.The Supported Work program served a severely disadvantagedsegment of dropout youths and, therefore, the degree to which itsfindings can be generalized to the wider out-of-school youth populationis not known.However, the long postprogram follow-up study (15 to 67months) provided strong evidence of no long-term gains in postprogramemployment and earnings.CONCLUSION:The evaluation of the Supported Work program forseverely disadvantaged school dropouts provided strong evidenceof no long -term gains in employment and earnings.In addition to their value as a source of immediate employment andas a bridge to longer-term unsubsidized employment, temperary jobsprograms have sometimes been seen as yielding social value in the formof return to school by dropouts or entrance in alternative education(GED) programs or through deterrence of crime and substance (drug andalcohol) abuse. The only temporary jobs program for out-of-schoolyouths reviewed here for which evidence on these measures was foundreliable (Supported Work) seemed to have no such effects.CONCLUSION:A temporary jobs program for severelydisadvantaged out-of-school youths (Supported Work) had noeffect on educational attainment nor on reducing crime oralcohol and drug abuse.The entitlement program, which guaranteed jobs for dropouts if theyreturned to school, provides evidence on the effects of temporary jobsprograms on school completion. Its eifectiveness is discussed in thenext section. Programs for In-School Youths Temporary jobs programs for in-school youths under YEDPA wereprovided to meet the immediate part-time employment needs of schoolyouths both during the school year and in the summer. Like temporary 26 14 jobs programs for out-of-school youths, the in-school programs weriviswed, i.e,, entitlement and the Summer Youth Employment Program(SYEP), were effective in increafl.ng participants' employment andearnings during the period cf program participation.These findings, and the entitlement results in particular, refutethe hypothesis that the employment problems of these youths are afunction of their high rese:/ation wage (that is, tnat jobs areavailable but not sought or filled by :.:hose youths because the wagesare too low', since large numbers took up these jobs when they weremade available through the programs. Overall, the entitlement programsignificantly reduced unemployment.There was also some evidence that under such programs jobs ofreasonable quality could be provided. As with the out-of-schoolprogram-, work experience placements in the private sector were4evelopad, but they required greater effort than public sectorplacements and resulted in some degree of job substitution anddisplacement (more in private than in public sector jobs). CONCLUSIONSoperated during the YEDPA period (entitlement and SYEP) wareeffective in increasin participants' em lo ent and earnin sduring the period of program participation.The entitlement prograt: demonstrated the ability of a governmentprogram to eliminate black-white employment rate differences amongin-school y'iths. This effect may be viewed by some as contributing tothe goal of greater social equity and as of sufficient merit, initself, to justify the program regardless of other benefits. Othersmay believe, however, }hat an important objective of temporary jobsprograms, even for in-snool youths, is improvement in postprogramemployment and earnings.CONCLUSION:For one program ( entitlement) effects were ofsufficient magnitude to eliminate the employment andunemployment differences between black and white youths whowere eligible for the program. In addition, there is evidencethat these jobs were of reasonable quality.In the immediate postprogram period observed for the entitlementprogram (2 months after entitlement ceased operation), there was someevidence of increased weekly earni-gs of eligible youths. Whenexamined by urban versus rural sites, however, it was apparent thatthis effect was due largely to the results in the rural Mississippisite. CONCLUSION:A major temporary jobs program (entitlement)appears to have been effective in increasing the earnings ofeli ible youths in the immediate Aastrram period, but thiseffect was dominated by results in one rural site. 27 15Unfortunately, none of the research on the YEDPA temporary jobsprograms for in-school youths produced reliable long-term follow-updata that would permit determination of the long-term effects onemployment and earnings.CONCLUSION:YEDPA produced no reliable evidence on the effectof temporary jobs programs on the long-run postprogramemployment and earnings of in-school youths. One of the purposes of temporary jobs programs for in-school youthswas to prevent youths from dropping out of school in order to findemployment.The entitlement project in fact set school enrollment asan eligibility requirement for a subsidized job and had as a majorobjective the retention of youths in school. Comparison of schoolretention rates in entitlement and nonparticipant sites, however,indicates that the program had no effect on school retention. TheSummer Youth Employment Program also emphasized return to school as anobj ztive but there are no reliable data on the effect of SYEP onschool return or retention.CONCLUSION:A major program (entitle :t) offering temporary'obs toouths on the condition that the remain in school wasnot effective in increasing school retention. An express aim of the entitlement program was not only to preventdropouts but also to encourage those who had already dropped out toreturn to school by offering them a subsidized part-time ;ob during theschool year and a full-time job during the summer, both conditional oncontinued enrollment in school. This incentive, though it did encouragesome dropouts to return to school initially, was ineffective in retain-ing them--comparison of entitlement and nonparticipant sites indicatesno differences in school completion rates.CajorprentitlezONCLUSION:AmmItemporarjobs to school dropouts on the condition that they return toschool did not increase school completion among these youths. Job Placement Programs Job placement programs, which provided job search assistance,career information, and job placement to youths, were designed to easethe labor market exchange between potential employees and employers.Such programs were thought to increase employment and earnings ofyouths through more efficient operation of the labor market. Althoughjob placement was often a component of other more comprehensiveprograms, the programs considered here offered only job placement. Theconclusions drawn, therefore, do not necessarily apply to job placementas a support service in other programs.Conclusions on the effectiveness of job placement programs forout-of-school youths are based on evaluation of two projects, 70001 and 23 lE the Job Factory. Conclusions on programs for in-school youths arebased on evaluations of Jobs for America's Graduates (JAG) and Jobs forrelaware Graduates (JOG).Both the clientele and the costs of the programs we reviewed variedwidely.Jobs for Delaware Graduates served largely nondisadvantaged,noncollege bound in-school youths and offered no stipends for partici-pation.The 70001 program, funded with YEDPA money, serveddisadvantaged youths, both in-school and out-of-school, and providedstipends.In general, the effect of these job placement programs for bothin-school and out-of-school youths was to produce short-term increasesin the rates of employment and earnings of participants over those ofsimilar youths not receiving such services. There is evidence thatthese effects lasted for the first year after program participation,decayed, and then disappeared by the end of the second year.CONCLUSION:Programs designed to provide job placementassistance to in-school and out-of-school youths were effectivein increasing employment for the first year after programparticipation. This effect decayed gradually and disappeared,ntirely by 2 years after program com Benefit-Cost EstimatesAfter a review of the effects of YEDPA program, it is natural toask about the efficiency with which the programs achieved thoseeffects.The most rigorous way to formulate a response to thisquestion is in terms of a comprehensive benefit-cost analysis.In order to make a complete benefit-cost analysis of a program itis necessary, first, to have reliable estimates of the effects of the-gram and, second, to have an appropriate accounting framework thattranslates those estimates of effects into benefits and costs. Many ofthe programs we reviewed lacked the first element and, except for JobCorps and Supported Work (programs that predated YEDPA), even whenreliable estimates of effects were available, they were not translatedinto benefit and cost estimates. ror Job Corps and Supported Work, wefound the benefit-cost analyses reliable and comprehensive: for JobCorps, the social benefits were found to exceed social costs; forSupported Work, the social costs were found to exceed social benefits.With the exception of two programs (Job Corps and Supported Work), wecould not find sufficient reliable evidence to assess the efficiency,in terms of social benefits and social costs with whichouthsprograms achieved their effects. FINDINGS AND CONCLUSIONS ON YEDPA RESEARCHWe often found it difficult, as noted above, to reach firmconclusions about the effectiveness of YEDPA programs given the qualityof the available evidence. Indeed, the difficulty in making inferences 29 17arose largely from the paucity of reliable evidence from the YEDPAresearch effort. Careful readings even of the few reports that didmeet minimal standards of methodological adequacy frequently revealedimportant flaws in the reported research.It would be unfortunate, however, to conclude that rigorousresearch cannot be conducted on youth programs. On the contrary, wefound several examples of research studies on youth employment andtraining rrograms that provided strong evidence, both positive andnegative, on program effectiveness (Job Corps, Supported Work, andAlternati7e Youth Employment Strategies). These examples !idicate thatgiven 1.,_asonable time for design and planning, attention to researchstandards, care in coordinating wit,. program operators and in programimplementation and follow-up, good evaluations of employment andtraining efforts can be executed for both small- and large-scaleprograms.While it is relatively easy to point out the methodologicalproblems in YEDPA research programs, it is more difficult to identifytheir causes.In the interests of improving the quality of futureresearch, we describe below sane of the common inadequacies of theYEDPA research effort and some of the conditions that, we believe,contributed to those failings.There were a wide variety of problems in YEDPA research. Many areobviuus and reflect the difficulty of meeting established researchstandards for complete reporting of research results, documentation ofprocedures for sample definition, presentation of details of statisticalanalyses, adequate coverage of the target population in data gathering,and minimal sample attrition. Low rates of initial sample coverage andhigh rates of sample attrition, for example, were among the most commonflaws of the YEDPA research reports we screened. Other problems,however, are less easily resolved and appear to be inherent in publicpolicy research. Comparison and Control Group MethodologyDifficulties in identifying equivalent comparison or control groupsflawed many YEDPA studies. Very few of the studies we reviewed usedrandom assignment to create participant and control groups. A morefrequent strategy was to define or construct a comparison group that,except for program participation, was presumed to diffe: in noimportant way from the participant group. Differences in measuredoutcomes were then attributed to the effects of program participation.In some cases, statistical techniques were used to control for measureddifferences between participants and nonparticipants.Our review of research that used such constructed comparison groupsrevealed two basic problems that repeatedly jeopardized the validity ofthe inferences to be drawn. The most frequent problem was the use ofcomparison groups that differed markedly in background characteristicsfrom participant groups. Given an adequate theoretical model, differ-ences in measured characteristics can be controlled for statistically.However, when there are substantial differences in measured character- 30 18 istics one becomes uneasy about the adequacy of the theoreticalassumptions and statistical adjustments and is left won'ering aboutmajor differences in unmeasured characteristics that may be correlatedwith the outcome measures. A second common problem was the use oftreated comparison groups, i.e., groups receiving services similar tothose provided to the YEDPA participants but in a different program.Both of these problems undermined the besic purpose of a comparison orcontrol group and made the attribution of program effects questionable.The research reviewed in this report demonstrates the causes for concernabout bias in estimated effects from use of such comparison groups.Because of these problems we frequently found that purported evidenceof YEDPA program effects might plausibly be ascribed to the non-equivalence of tne comparison and participant groups, even whenstatistical methods to control for such differences were used.Even in the methodologically sophisticated work cond'icted on theCMS data base, there is convincing evidence that the constructedcomparison groups that were equated on common socioeconomic variablescould differ markedly on important unmeasured variables. The Job Corpsevaluation also, despite efforts to correct for biases in the con-structed comparison group, was ultimately less convincing in itsestimates of effects than would have been the case had randomassignment been used.CONCLUSION:YEDPA research did not make sufficient use ofrandom assignment in defining participant and control groups.Our review of the research on YEDPA shows dramatically thatcontrol groups created by random assignment yield researchfindings about employment and tLaining programs that are farless biased than results based on any other method. The fact that some studies successfully used random assignmentsuggests that this procedure is feasible and presents no serioustechnical difficulties in execution. It is evident that if randomassignment. had consistently been used in YEDPA research much more wouldhave been learned. (The use of random assignment in public policyresearch is discussed in Appendix C.) Measures of ImplementationIn a real-world experiment involving a social program one does nothave a single, standardized treatment. Hence, evaluation of theoutcomes of such social experiments must carefully take into accountthe nature of the treatment(s) given and variations between thetreatments received by different individuals. Without paying attentionto matters of implementation one cannot know whether a given programwas successfully delivered. If no program approximating that intendedby its designers was implemented at a given site, for example, there isno reason to treat the results as a \"test\" of the outcomes arising fromthe program.We found that although YEDPA produced several studies ofprogram implementation, YEDPA research gave insufficient consideration 31 `es 19 to measures of the extent of program implementation in interpreting orqualifying program results.The YEDPA research plan envisioned gathering a standard set of dataabout the process of program implementation. This plan included infor-mation on the nature of the services offered by different programs andsites, the gearing up and scaling down of operations over time, theturnover of staff, the distribution and magnitudes of program expendi-tures, and so forth. Unfortunately, this effort was neither wellplanned nor well executed (see Appendix A). Length of Follow-up PeriodA major shortcoming of theoretical importance in YEDPA research wasthe very short postprogram period over which outcomes were measured.For most programs, follow-up measures were available only at 3 or 8months after program completion; Job Corps and Supported Work, withover 3-year follow-ups, were notable exceptions. Given the employmentobjectives of most YEDPA programs, a more reasonable test would haveconsidered longer-term outcomes.The Job Corps experience of initial declines in employment andearnings in the first months after termination, followed by significantlonger-term gains, suggests that, a; least for some programs, additionaltime may be required for effects to emerge. On the other hand, thereare examples (70001 and JAG) indicating that early program effects maydecay rapidly.Thus, there is evidence that short-term follow-ups maylead to incorrect inferences, both positive and negative.CONCLUSION:For the most part, YEDPA program evaluationresearch suffered seriously from the lack of outcome datacollected over a sufficiently long period following programcompletion.For some 'rograms it appears that there was neverany serious intention to collect data beyond 8 months post-program; for other programs, the abrupt cutoff of funds in 1981precluded any attempt at further follow-up. It is clear thatthe long-term effects of programs cannot be measured when thereare no data beyond 8 months. Neither policy makers norresearchers are well served by such truncated evaluationstudies. Use of Subjective Measurements as Proxy VariablesMany YEDPA research projects used subjective meaLurements, such asmeasures of work-related attitudes and job-holding skills, as proxiesfor longer-term outcomes. As with all such measures, the link betweenthe proxy variable (the social attitude or skill) and the unmeasuredlong-term outcome variable (increased employment and earnings) issubject to empirical verification. It is important to ask how wellthese variables serve as proxies for the variables of primary interest.(Appendix A reviews the correlations between the subjective measures 32 20 used as proxies in YEDPA research and measures of employment andearnings variables.) We found that these measurements showed relativelylow correlations with the objective variables for which they wereintended to serve as proxies and that the reliability of these YEDPAmeasurements was rather low. Furthermcre, an earlier analysis of dataon the same measures collected prior to the 3- and 8-month datacollection periods was predictive of these low correlations andreliabilities.CONCLUSION:YEDPA evaluations invested large amounts ofresources in measurement of proxy variables rather than thereal variables that were the goals of the programs. Moreover,most of these were subjective measures known to have onlymodest levels of association with the ob'ective outcomes thatwere the implicit long-term goals of the YEDPA programs--futureemployment and earnings. Sample Undercoverage and Attrition Sample undercoverage and sample attrition were two of the mostcritical and frequent problems with YEDPA research. Indeed, attritionbetween waves of a study was second only to lack of impact data as areason for excluding reports from our review. In addition, over therange of YEDPA programs covered by the Standardized Assessment System,it is estimated that data were gathered from less than half of thetarget sample. This undercoverage makes it impossible to generalize tothe total population of participants in YEDPA demonstration projectsunless one makes highly unrealistic assumptions, for example, thatnonresponders were a random sample of program participants.CONCLUSION:Many YEDPA research projects gave inadequateattention to sample design and execution, including definingthe sampled population, obtaining data from all members of thetarget sample, and preventing sample attrition between waves ofthe longitudinal data gathering.It is important that the foregoing catalog of problems with YEDPAresearch not lead readers to the despairing conclusion that suchproblems are unavoidable for all evaluation research in the employmentand training field. We found that these problems were not predestinedby the nature of the questions being posed, but rather were caused bythe demands of Congress for research results and the failure of theresearches to recognize the limits imposed by YEDPA conditions andscale the research accordingly. The research tools available are ade-quate to the task, but suitable conditions for their use must beprovided.These conditions include adequate time for design andexecution of the research, reasonable stability of the programs beingevaluated, provision of adequate resources for the research, and apolitical commitment on the part of those commissioning the research toallow adequate time not only for careful planning at the beginning, but 33 21 also for enough time at the end to see the research through to itsconclusion and to obtain the full ',enefits. OVERALL CONCLUSIONS: DID YEDPA ACHIEVE ITS GOALS?The YEDPA legislation had four major objectives that broadlydefined its scope: (1) to address the immediate employment needs ofyouths through job creation efforts; (2) to conduct research anddemonstration as a means of identifying methods of dealing with thestructural employment problems of youths; (3) to involve otheragencies, nationally and locally, in the planning and delivery of youthemployment services as a means of exploring the effectiveness ofalternative service delivery mechanisms; and (4) to increasecooperation between the schools and the employment and training systemas a means of addressing the problems of disadvantaged youths. Wepresent here our conclusions on the extent to which these objectiveswer-: met. Job CreationA key objective of YEDPA, the one on which the most funds werespent, was providing young people with jobs. In response to high youthunemployment in the 1970.;, federal outlays for youths in the first yearof YEDPA doubled what they had been, and in its course YEDPA servedover 6 million youths. Previous efforts at large-scale jobs programs(SYEP and Public Service Employment) were widely criticized for theirpoor administration and poor job quality (U.S. General AccountingOffice, 1979). Evaluations of massive jobs programs under YEDPA (SYEPand entitlement) showed major ' ,Lovements in job supervision and jobquality.There is evidence not only that very large numbers of jobswere provided to youths under YEDPA, but also that the quality of thejobs was more than \"make-work.\"CONCLUSION:A major achievement of YEDPA was that it succeededin providing large numbers of disadvantaged youths with jobsthat were more than make-work. YEDPA demonstrated the capacityof the employment and training system to mount and runlarge-scale jobs programs for young people. Research and Demonstration Although the employment and training system under YEDPA was able todemonstrate its capacity for implementation and operation of large-scale programs, it was hampered in its response to its second majorobjective--conducting research and demonstration aimed at solving thestructural employment problems of youths. Our review suggests that theinstitutional capacity for research and demonstration was insufficientto the objectives of YEDPA knowledge development. The knowledge 34 22development agenda itself was too ambitious given the rapid timeschedule of YEDPA and the other demands of large jobs programs. Interms of the results of YEDPA research, the youth employment situationtoday is not very different from what it was before YEDPA began.CONCLUSION:Rapid program expansion in a period of considerablesocial program activity severely hampered the planning, imple-mentation, and evaluation of YEDPA demonstration research. Theabrupt halt of research activity in 1981 did not help. As aresult, despite the magnitude of the resources ostensiblydevoted to the objectives of research and demonstration, thereis little reliable information on the effectiveness of theprograms in solving youth employment problems. Developing the SystemThe youth employment and training system has long suffered from itsisolation from major economic and educational institutions. Thisisolation is due to a number of factors, most importantly the characterof its client population and its lack of a stable institutional base.The YEDPA legislation required the involvement of private employers,the schools, and other established agencies, both public and private,in planning and delivering youth services in order to explore alter-native mechanisms for more effective service delivery and to encouragethe integration of employment and training services into the mainstreamof the society.Our review of numerous reports on program effectiveness andimplementation suggests that although the involvement of these partieswas effective in making better use of local resources, it complicatedthe planning and delivery process and did not on the whole achieve itsgoals of improving service delivery and integrating either the programsor their participants into the larger society.Given the nature of the youth employment problem, the goals ofequity and efficiency argue for targeting services to disadvantagedyouths.At the same time, however, our review suggests that the youthemployment and training system continues to suffer from a marginalstatus that is due in part to such targeting.CONCLUSION:Despite YEDPA efforts to improve the servicedelivery system, employment and training services for youthsremain economically, socially, and racially isolated from thelarger society and its institutions. This isolation hasstigmatized the programs and undercut their ability to recruitstaff, motivate participants, and involve employers. The Schools and School DropoutsThe YEDPA requirement that 22 percent of the funds for YETP be setaside for programs coordinated with the local school system was an 35 23 attempt to influence the schools to broaden their constituency toinclude disadvantaged youths. Despite the agreements negotiated underYEDPA to involve the schools in youth employment programs, we foundlittle evidence of successful mutual efforts.CONCLUSION:The relationship between the employment andtraining system and the school system remains problematic.Despite some common objectives and client groups and efforts tobring the two systems together in the service of thoseobjectives and clientauthey remain largely separate, and thepotential benefits of mutual efforts are largely unrealized.An example of this problem, and one of great importance to thiscommittee, is the problem of school dropouts--a group of legitimateconcern to both the schools and the employment and training system anda group that neither has been able to serve effectively. No otheryouth group faces the employment problems, both immediate and longterm, faced by school dropouts, and particularly those who are minoritygroup members.The YEDPA approach to the dropout problem was twofold: (1)prevention of the problem by targeting services to youths at risk ofdropping out and giving them incentives to remain in school and (2)remediation of the problem by targeting services directly to dropoutsin a way that encouraged return to school or an alternative education.Our review of youth programs found no evidence of effective means ofeither dropout prevention or remediation. We observed instead thesevere problems of schools and other program operators in recruitingand retaining dropout youths and the tendency of those programs tofocus their services on the more easily recruited and served populationof in-school youths.CONCLUSION:Of all youth groups Lschool dropouts face the mostserious employment problems. Because of problems in recruitingand serving dropouts, however, the focus of Youth research anddemonstration under YEDPA was unduly directed to in-schoolyouths and high school graduates. As a result, the question ofhow to reach and serve dropout youths remains unanswered. IMPLICATIONS AND RECOMMENDATIONSTwo basic issues--the problem of school dropouts and the relationsbetween the schools and the employment and training system--remain, inthe committee's view, fundamental dilemmas confronting the youth employ-ment and training system in the United States. We begin our discussionof implications with our recommendations for future youth policy withregard to dropouts.We recognize that there is a long history of research and programattempts to understand and deal with the problems of school dropouts.And yet, as our review strongly suggests, dropouts, particularlyminority group dropouts, remain as the segment of the youth population 36 24with the most serious employment problems. Attempts, both preventiveand remediative, to address the employment problems of this group, withthe exception of the Job Corps, have been ineffective. Despite theseefforts we know little more about dropouts now than we did beforeYEDPA, not only in terms of their responses to employment and trainingprograms, but more fundamentally in terms of the factors--economic,social, and psychological--affecting their dropout and subsequenteducational and employment behaviors.RECOMMENDATION: The committee strongly recommends that schooldropouts be given priority status for employment and trainingprograms and research. Program efforts should be shaped totest systematically the alternative methods of addressing theeducation and employment needs of these youths, and researchshould focus on the underlying determinants of the dropoutphenomenon.Anothe, major implication of our review concerns the marginal roleof the youth employment and training system, its relation to the schoolsystem, and the two systems' relation to the broader society inaddressing youths' educational and employment needs. We recognize theinherent tension between e above recommendation to give prioritystatus to dropouts and th. suggestion that the employment and trainingsystem, partly because of such targeting of services, has isolateditself from the broaaer society. This is a complex problem to which wehave no solution. We believe, however, that it is an important aspectof the youth employment problem and that it bears serious considerationand further study.RECOMMENDATION: In order to rid employment and training pro-grams of the stigma which has plagued them and their partici-pants, the committee strongly recommends that attempts be madeto target services for disodvantaged youths in ways that willnot isolate them but rather integrate them into mainstreaminstitutions and activities. The role of the school system andthe relation between the schools and the youth employment andtraining system are critical in resolving this problem. Thecommittee therefore recommends a direct study of theappropriate role of the youth employment and training system,and its relation to the educational system, in alleviating theemployment problems of those youths most in need of assistance. Youth ProgramsCommittees such as ours invariably recommend further programresearch and testing. Unless the problems addressed by the programshave disappeared or been substantially ameliorated or unless socialpriorities have shifted sharply, such recommendations should in goodconscience be made. We are hesitant, however, to prescribe programapproaches and techniques as lessons from experience. In our con- 37 25 sidered judgment, the clearest lesson from the YEDPA experienceconcerning effective programs is that much remains to be learned aboutdealing with youth employment problems. In our judgment, it is betterby far to admit that knowledge is lacking than to assume on the basisof scant knowledge that we know what works best for whom. Therefore,our recommendations on programs and program research are closely tiedto the evidence we reviewed. In this section we first present ourprogram recommendations for out-of-school youths, then for in-schoolyouths, and finally for programs serving women. Programs for Out-of-School Youths The results of our review and the present conditions of the new JobTraining Partnership Act (enacted in 1982) suggest the followingprogram areas for research for out-of-school, dropout youths: basicremedial education, occupational skills training, and financialassistance. Basic Education Although there is no evidence on the effect of labormarket preparation programs on basic skills acquisition, there isevidence from the Job Corps and 70001 that programs placing a strongemphasis on GED training can substantially increase the educationalattainment of out-of-school youths, as measured by GED attainment.RECOMMENDATION: The importance of basic education as acomponent of programs for out-of-school youths should be testedsystematically. Many programs have placed heavy emphasis onthe attainment of a GED (or other educational interventionssuch as competency-based instruction) for this group and aserious attempt should be made to determine whether theincrease in basic education rovided throu h r. rams does infact have long-term payoffs for these youths. Occupational Skills Training The results of the Job Corps evaluationsuggest that occupational skills training programs can be an effectivemeans of solving some of the structural employment problems of dis-advantaged out-of-school youths, at least of that population ofdisadvantaged dropout youths served in residential Job Corps centers.The fact that the research to date has not explained the Job Corps'effects in terms of the individual contribution of its many programcomponents or the totality of its residential services, limits thegeneralizability of the results to other disadvantaged youths in othersettings.RECOMMENDATION: Opportunities to enroll in the Job Corpsshould continue to be provided for the out-of-school youthpopulation. 38 26RECOMMENDATION: The effectiveness of the Job Corps should befurther studied through systematic evaluations using randomassignment.These evaluations should attempt not only toassess the overall effectiveness of the program but also todetermine which components of the program are most effectivefor which groups of youths. Attainment of this latterobjective will require some use of random assignment toalternative components within the Job Corps program.RECOMMENDATION: Nonresidential skills training programs forout-of-school youths should be systematically tested andevaluated. Financial Assistance There is a serious question of whether employmentand training programs can effectively enroll the out-of-school youthsmost seriously in need of assistance and hold them in the program for areasonable amount of time without providing some form of financialassistance.In our review we found no good evidence on this question.RECOMMENDATION: An attempt should be made to test how thenumber and characteristics of those enrolled in youthemployment programs are affected by the provision of financialassistance and whether the length of participation variesaccording to whether assistance is provided. Programs for In-School Youths General research, sponsored in part by YEDPA, highlighted twoimportant facts regarding in-school youths and employment. First, inthe last few decades, employment for in-school youths has grown sub-stantially for white youths while black in-school youths have notexperienced a similar growth in employment (and for black males theextent of employment while in school actually declined). Second, thereis a high correlation between employment while in school and employmentand earnings after school.The second point is recognized to be correlational and possibly notcausal, but it raises the question of whether providing the means forincreasing employment while in-school would reduce the incidence ofemployment problems after school. The entitlement program provided thepotential to give this hypothesis a meaningful test, but that potentialcould not be fully realized. The entitlement program did show, however,that meaningful, minimum-wage jobs could be provided and that youthswould take the jobs in sufficient numbers to change the relative black-white in-school employment rates. Given this step, it seems eminentlyworthwhile to test the hypothesis further.A test of the effects of in-school employment on later employmentneed not, however, necessarily come in the form of an entitlement-typeprogram.Indeed, in terms of testing for the effects of such anexperience, the research inferences can be more powerful if access tothe job experience is provided through random assignment of individuals 39 27to eitheL the program or to a control group. Even with random assign-ment to a limited number of part-time jobs for in-school youths duringthe school year, if the program is focused on those areas where ethnicdifferentials in employment of in-school youths are high, the resultsof the test programs would provide evidence as to whether a narrowingof in-school employment differentials will lead to a subsequentnarrowing of postschool employment differentials.RECOMMENDATION: Programs should be designed to test whetherincreased in-school employment leads to greater postschoolemployment.The tests should be conducted in a form thatrequires random assignment of individuals to the program or acontrol group.The evaluation of the test programs shouldprovide sufficiently long-term follow-up data for botharticipants and control rou members to determine lon -termpostschool effects.The Summer Youth Employment Program seems to have sufficientpolitical popularity to survive regardless of evaluation researchfindings or nonfindings. Therefore, attempts should be made torestructure segments of SYEP to provide an opportunity to learn moreabout whether its resources can be used more effectively.RECOMMENDATION: Attempts should be made to restructure someelements of the Summer Youth Employment Program to systemati-cally test whether SYEP elements can be used to enhance basiceducation sufficiently to reduce school dropout rates or, atleast, improve employment chances for those who do drop outanyway.Elements of SYEP could be structured so some skillstraining is added to the pure work experience in order todetermine whether such training enhances the long-termemployment effects of the program. Women in Youth Employment Programs Although women constitute half of the participants in employmentand training programs, little attention has been given to sexdifferences either in terms of program needs or outcomes. Yet it isclear that the distinct needs and characteristics of this group haveimplications for program design.RECOMMENDATION: Programs should be designed to recognize morefully the fact that teenage parenthood often results inrestricting the educational, training, and employment oppor-tunities of young women. The benefits of providing child careto encourage greater participation of teenage mothers and morefavorable program outcomes should be rigorously tested.In addition, while there is some indication that women benefit morefrom participation in employment and training programs than men, there 4 28is also evidence that such programs may perpetuate occupationalsegregation.RECOWNDATION: More research should be done on selectivefactors that affect the recruitment of women into youthemployment programs and the differential treatment by sex inoccupational training once in programs. More research is alsorequired on potential nonemployment outcomes of job trainingfor women, such as increased educational attainment, reducedwelfare dependency, and reduced early chilc.oearing. A Gewral Research Strategy Under JTPAHaving made a series of reccamendatixls regarding typef programswhich might be tested, we must hasten to state that we are 'Jlly awareof the clanged environment in which employment an4 training programscurrently operate under the Joh Training Partnership Act (JTPA).Recom-mendations for demonstrations and research must be fra\",ed in light ofthat environment.When considering JTPA from the perspective which has ieen theprimary concern of this committee, three features stand out: 1.The resources dovoted to employment and training are con-siderably less than those- devoted to YEDPA even though the magnitude ofthe youth employment problem is at least ,a great today is it was inthe year preceding YEDPA.2.The continued concern with the employment problems of youths isdicated by the fact that a substantial proportion of the greatly_educed training resources are earmarked for programs enrolling youths.3.The control of the content of programs and any research to bedone concerning them is placed almost completely in the hands of thelocal Private Industr! Councils and Service Delivery Areas (and thestate agencies guiding them). In light of these features, we must ask what is likely to belearned from .7:IA about how to alleviate the employment problems ofyouths, \"what works for whom\" among the youth population. Our answermust, in all honesty, be \"very little.\" The YEDPA experience amplydemonstrates that completely decentralized research efforts executedwith a minimum of central coordination and technical assistance arelikely to yield very little hard evidence on program effectiveness.On the other hand, the very fact that there is a considerablereduction in program activity in the field may create an opportunityfor more careful planning and execution of evaluation research than waspossible under YEDPA and a greater likelihood of finding the sort ofresearch resources which' will generate evidence of high quality. Webelieve that with relatively small amounts of central resourles, astrategy and mechanism for evaluation research under JTPA can beimplemented which will considerably enhance the likelihood thatreliable evidence on youth programs will be derived from JTPA. 41 29 The strategy would be to provide through some central mechanism theresearch designs and technical assistance that would be necessary toadd evaluation components to youth programs being underwritten by localPrivate Industry Councils (PICs) and Service Delivery Areas (SDAs)through JTPA.Adding a small amount or program funds, allocated on adiscretionary basis to those PICs and SDAs that agree to cooperate,might induce the localities to make the slight alterations in theirprogram content or procedures necessary for evaluation research.The central agency would have the overall perspective the localPICs and SDAs may lack as to the range of program types that are beingundertaken in various localities and would ensure that a reasonableportfolio of quality evaluations was being mounted so that the relativeeffectiveness of different program types could be assessed. Havingthis perspective would also enable the central agency to provide infor-mation and technical assistance to the local PICs and SDAs concerningalternative program types, better program procedures, and so on. Thecentral agency would also help to ensure that at least a central coreof the evaluation research information collected across sites wasreasonably comparable so that cross-program comparisons couldeventually be made.The central agency need not be in the federal government itself.The experience with the use of intermediary organizations to organizert.:earch and technical assistance under YEDPA, while it was not allpositive, was sufficiently good in a number of casts to suggest thatthis might be an effective medium through which to interject thisevaluation research into the JTPA framework. Such organizations nowhave experience in negotiating with local operating agencies, adaptingresearch designs to local constraints, and combining technicalassistance with research guidance. While the major activity could becarried out through an intermediary, some guidance and oversight fromthe Department of Labor is necessary, as we noted in our earlierdiscussion of YEDPA; it is not wise to devolve responsibility totallyto an intermediary. But with a level of research and evaluationactivity that would be only a small fraction of that undertaken underYEDPA, the Department of Tabor staff required to oversee inter-mediarieactivities could be quite small.We note also that good evaluative research could provide a sou.derbasis for the setting of performance standards, a key feature of JTPA.What is important for performance is value added, the improvement inemployment and earnings over what it would have been in the absence ofthe progrzn, and we would argue that this can best (and perhaps only)be established through evaluation research using randomly assignedcontrol groups.! ese then are just the rough outlines of a strategy and mechanismfor evaluation research on youth programs under JTPA. WP believe theyare compatible with the basic design of JTPA itself and could yieldgood evidence from the JTPA experience about how an employment andtraining system can better help alleviate the continuing seriousemployment problems of sizable proportions of our youths. We muststress that in the absence of such a strategy and mechanism, we believethat severe; years from now the nation will find itself with several 42 30years of JTPA experience but knowing little more about whether or howsuch programs might help reduce youth employment problems. Research MethodsBeyond the general strategy and mechanism just suggested forresearch and demonstrations under JTPA to test the types of programcomponents we have recommended, we have specific recommendations tomake about the actual conduct of research and evaluation activities.The results of our review of YEDPA programs make it obvious thatquality in the design and execution of a research project affects thequality of the data and the reliability of any conclusions that aredrawn from those data. Poor research designs can make programs lookworse than they are, or better than they are, or yield uninterpreLableevidence.Poor execution will compromise even the best design. Random Assignment Our review of YEDPA research strongly suggests that much more couldhave been learned, and more confidence placed in the results, if randomassignment had more frequently been used. We believe that not only hasthe feasibility of random assignment in program research been demon-strated, but that in situations in which program resources are scarceand program effectiveness unproven, it is ethical (see Appendix C).RECOMMENDATION: Future advances in field research on theefficacy of employment and training programs will require amore conscious commitment to research strategies using randomassignment.Randomized experiments should be explicitlyauthorized as a device for estimatinj the effects of newprojects, program variations, and program components.Furthermore, funding authorities should back this explicitauthorization wL:b firm indications that this is the method ofevaluation which is expected. Implementation ResearchThe need for measurement of program implementation in evaluationresearch is clear. It is as important in social program evaluation asis measurement of dose level in evaluating new drugs. Federal agencieshave had substantial experience in eliciting such information, but thisinformation has not always been reasonable in quality, judging from ourreview of youth employment program evaluations.RECOMMENDATION: Systematic and verifiable information onprogram implementation should be collected in future research.Better and less expensive methods for obtaining and reportingsuch information need to be developed. 43 31 Use of Subjective Measurements as Proxy VariablesWhile one cannot fault a research program for using subjectivemeasurements as proxies for other outcomes, it is a theoretical andmethodological challenge to develop measures that have substantialvalidity and reliability. Indeed, the treatment of subjectivemeasurements has been reconsidered in recent years, and it is generallyrecognized that corn ,esearch practices ignore the complexity of therelationships between objective and subjective measurements.RECOMMENDATION: Future researchers should avoid overrelianceon subjective measures of program outcomes and devote moreresources to studying the relationships that exist betweensub'ective indicators and key objective outcome variables. Postprogram Follow-up The Job Corps evaluations suggest that some program effects thatare not apparent at short-term follow-ups may emerge in the longerterm.Research on job placement programs suggests that some, moreimmediate, postprogram effects may decay rapidly. Together, thesepieces of evidence suggest that short-term follow-up data may erreither positively or negatively in predicting longer-term programeffects.RECOMMENDATION: Future research on the effectiveness of youthemployment and tr' ing programs should, at least in selectedstudies, estimatelonger-term ettectmsbcollecting follow-up data for at least 2 years postprogram. Benefit-Cost Studies When evaluations demonstrate that prograAs have a positive outcome,researchers should recognize that the next question raised will bewhether this positive outcome was worth what it cost to produce it.Thus evaluators should anticipate the eventual need for benefit-coststudies.Such studies, however, need not be a component of everyevaluation nor of entire programs, since doing adequate benefit-coststudies is both difficult and costly. The Job Training Longitudinal Survey Data Base One fea,ure of JTPA that is important in regard to program researchis the plan to rely heavily on analysis of national data bases todetermine the effectiveness of JTPA programs. Present plans are tomodel the Job Training Longitudinal Survey (JTLS) data base after theprevious CLMS.Although its data gathering appeared technicallyexcellent, the CLMS strategy of using nonrandom comparison groups for 44 32program evaluation suffered from substantial problems with potentialunmeasured blase:3 in its comparison groups. Furthermore, we believethat the plan to use the same strategy in designing the JTLS as a meansof obtaining evidence on \"what works for whom\" is misguided. Theevaluations we reviewed that are based on constructed comparison groupsprovide strong evidence that this approach to program evaluation isseriously flawed; the question of bias in comparison groups so con-structed is vir'ually impossible to dispel. We believe that theplanned JTPA evaluations using the new JTLS will suffer from the sameproblems.RECOMMENDATION: Planning for the JTLS should give very seriousconsideration to the selection of randomized control groups.In conclusion, we believe that quality research ought to be recog-nized and ought to be explicit in congressional and agency oversightpolicy.Special efforts should be made to improve the quality ofresearch and evaluation designs for estimating the impact of youthemployment projects. Existing professional guidelines can be used toinfluence quality of design as well as quality of research executionand reporting.RECOMMENDATION: The committee recommends the followingconditions as necessary but not sufficient for quality research:(1) the use of random assignment to participant and controlgroups and to program variations; (2) reasonable operationalstability of the program prior to final assessment of effec-tiveness; (3) adequate sample coverage and low rates of sampleattrition' (4) outcome measures that adequately represent theprogram objectivearboth immediate and longer term; and (5) afollow-up period that allows adequate time for program effectsto emerge or decay. The General Conduct of Public Policy Research One of the major implications of our review of YEDPA programs andresearch concerns the conduct of national public policy research anddemonstration programs. It was very apparent in our review that manyof the problems we faced in attempting to draw inferences from YEDPAresearch resulted from the fact that under YEDPP attempts were mad tocombine numerous research objectives with massive service delivery.The consequent tensions, conflicts, and overload on the system inter-fered with the careful planning and conduct of the research anddemonstration activities, with the result that the research findingsfall short in informing the public policy issues from which YEDPAoriginated. RECOMMENDATION: In future efforts the objectives of researchand demonstration should be more clearly and selectivelyfocused on essential public policy issues and clearly separated 45 33 from the objectives of massive service delivery. The magnitudeof the effort and the ex ctation of results should be more inscale with limitations of time, money, and staff resources. Dilemmas Confronting tr loyment and Training SystemIn closing, we return to tile two fundamental dilemmas with which webegan this discussion of implications and recommendations for thesystem of employment and training in the United States. The employmentand training system is trying in large part to do what the educationsystem should be doing but, for some significant segment of the youthpopulation, apparently fails to do. Yet the employment and trainingsystem has not attained stability of funding, professionalization ofstaff, and delineation of authority, in short, institutionalization ofthe sort that has given the educational system its accepted place inthe mainstream of American life. As a result, in most communities,organizations involved in employment and training are consideredmarginal.The educational system, on the other hand, should not betaken as an exact model for the institutionalization of the employmentand training system, since it has not yet found an effective way toprepare a substantial segment of the youth population for lateremployment.For the most part, the youth programs of the employment andtraining system have been specifically targeted toward special segmentsof the youth population, often those perceived as most disadvantaged.Given that the major rationale for youth programs within the employmentand training system is to assist those whom the educational system hasfailed to prepare for work, this target seems a sensible means to focusresources on those in greatest need. The problem is that this verytargeting tends to create an image of the programs as designed only for\"failures=\" both the programs themselves and their clientele becomestigmatized in the process. The staff of the programs may come to feelstigmatized as well and this can exacerbate problems of recruitment,ret^ntion, and management. Even the potential target group members cancome to share the views of the broader community about the inherentmarginality of these programs and the stigmatizing effects of partici-pating in them, and it becomes increasingly difficult to enlist them inthe programs and to keep them participating for sufficient time for the\"program treatment to take hold.\" Yet, experience has shown that whenprograms are not targeted, the resources tend to be shifted rapidly tothe more advantaged, better prepared, easier to handle segment of theyouth population--those who have far less need for help with potentialemployment problems.These fundamental dilemmas pose a major impediment to solving theserious unemployment problem of youths, and we emphasize again the needfor a direct study of the roles and relationships of the education andthe employment and training systems. 46 2Youth Employment and Unemployment THE YOUTH EMPLOYMENT PROBLEM: ITS NATURE AND DIMENSIONSUnemployment RatesThe United States recently experienced its most serious unemploymentproblems since the Great Depression of the 1930s. In the depths ofthis recession, in December 1982, the overall unemployment rate reacheda postwar high of 10.8 percent. But the unemployment rate for teenagerswas 24.5 percent--more than twice the overall rate--and the unemploymentrate for black teenagers was 49.5 percent. Since the trough of therecession, the national employment situation has improved somewhat, sothat during 1984 the unemployment rate averaged 7.5 percent. The ratefor teenagers was still substantially higher--18.9 percent--and therate for black teenagers had improved only slightly, to 42.7 percent.The youth employment problem is not due merely to the greatervulnerability of young workers to the swings of the business cycle.There has been a long-term upward trend in youth unemployment ratesover the last several decades (Congressional Budget Office, 1982).Table 2.1a provides statistics for four periods from 1957 to 1984:1957, 1964, and 1978 were chosen because they were years of relativelyhigh economic activity and had identical unemployment rates for adultwhite men aged 35-44.Over the period spanned by these statistics, the unemployment ratefor all youths climbed steadily. In addition, the gap between whiteand nonwhite youths that was evident in 1957 became much larger overthese decades.Thus, even among the more \"settled\" 20- to 24-year-oldyouths, the 1957 unemployment rate for white males was 7.1 percentwhile the rate for nonwhites was 12.7 percent; by 1984, this gap hadexpanded to 9.8 percent for whites and 24.5 percent for nonwhites. Forwomen aged 20-24, the unemployment gap had expanded similarly, from 5.1percent for whites and 12.2 percent for nonwhites in 1957 to 8.8 percentfor whites and 23.5 percent for nonwhites in 1984.Table 2.1b, which compares the unemployment rates for young whitemales with other youths, shows that nonwhite females aged 20-24 were1.7 times as likely as white males to be unemployed in 1957; by 1984they were 2.4 times as likely to be unemployed. In contrast, whitefemales have in most years been less likely to be unemployed than white 34 47 35TABLE 2.1aYouth Unemployment Rates in the CivilianPopulation for Selected Years (in percentages) GroupYear1957196419781984 Adult white males35-44 years old 2.52.52.54.6All youths16-17 years old 12.517.819.321.218-19 years old 10.914.914.217.420-24 years old 7.18.39.611.5White males16-17 years old 11.916.116.919.718-19 years old 11.213.410.815.020-24 years old 7.17.47.79.8Nonwhite males16-17 years old 16.325.939.839.818-19 years old 20.023.130.738.520-24 years old 12.712.620.024.5Hispanic males16-17 years old aa27.530.518-19 years old aa13.921.620-24 years old aa9.412.1White females16-17 years old 11.917.117.117.818-19 years old 7.913.212.413.620-24 years oid 5.17.18.38.8Nonwhite females16-17 years old 18.336.541.542.218-19 years old 21.329.236.336.620-24 years old 12.218.321.323.5Hispanic females16-17 years old aa29.925.218-19 years old aa16.621.420-24 years old aa13.012.5 NOTE:The years 1957, 1964, and 1978 were selected because ineach of these years the unemployment rate for white males aged35-44 was an identical 2.5 percent and the business cycle wasabout at its peak; 1984 was selected to provide a view ofrecent youth unemployment.allo data for persons of Hispanic origin are available for1957 or 1964. SOURCE:Data from U.S. Department of Labor (1982, 1985b). 48 36TABLE 2.1bRatios Between Unemployment Rates for Young White Males and Other Groups YearGroup 1957196419781984 White males16-17 years old old old aa1.541.43 20-24 years old aa1.691.28 NOTE:The years 1957, 1964, and 1978 were selected becausein each of these years the unemployment rate for whitemales aged 35-44 was an identical 2.5 percent and thebusiness cycle was about at its peak; 1984 was selected toprovide a view of recent youth unemployment. allo data for persons of Hispanic origin are available for1957 of 1964.SOURCE:Data from U.S. Department of Labor (1982, 1985b). 4 37 males, but between 1957 and 1984 this ratio approached parity: for 20-to 24-year-old white females, the ratio of unemployment rates was 0.7in 1957 and 0.9 in 1984. (Although comparable historical data are notavailable for Hispanic youths, the available data indicate thatHispanic males aged 20-24 were 1.2 times as likely as white males to beunemployed in 1984, and Hispanic females were 1.3 times as likely to beunemployed as white males.)These continuing trends in the relative unemployment rates of youngAmericans were a primary motivation for the launching in the late 1970sof federally funded programs designed to provide employment and trainingservices to disadvantaged youths. Yet, as the last column of Table2.1a indicates, the gap between white and nonwhite unemployment rateshas persisted: in 1984 unemployment among white youths aged 20-24 was9.8 percent for males and 8.8 percent for females; for nonwhite youthsthe rates were 24.5 and 23.5 percent, respectively.While the unemployment rates and ratios shown in Tables 2.1a anti2.1b demonstrate that young people's problems have been increasing, theunemployment rate can sometimes be a misleading indicator, particularlywhen applied to the youngest segment of the labor force (Hahn andLerman, 1983:2). To be counted as unemployed a person must indicate inanswer to a survey question that (1) she or he is not currently employedand (2) she or he is currently looking for work. People who are notworking and who say they are not actively looking for work are countedas \"out of the labor force\" rather than unemployed. The unemploymentrate is calculated by dividing the number of people who are unemployedby the number of people in the labor force (defined as the sum of theemployed [E] and unemployed [U]): unemployment rate = U/(U + E)It can be seen that the unemployment rate can rise ever though thenumber of employed (E) stays constant. And, given the gay in which oneis defined as being \"in the labor force,\" it is not necessary thatthere be any change in the number of people who are not working. Theunemployment rate may rise simply because more people begin looking forwork (or at least say they are looking for work), thereby increasingthe size of the labor force. [See Bailar and Bothwell (1984) andNational Commission on Employment and Unemployment Statistics (1979)for discussions of this and other aspects of unemployment measurements.]The unemployment rate is particularly ambiguous as an indicator ofemployment problems in the youth population because it becomes entangledwith school attendance. When young people scy that they are lookingfor work even though they are also enrolled in school, they are none-theless counted as unemployed. This method of counting raises seriousquestions of interpretation since full-time students, it can be argued,already have a full-time though unpaid occupation, attending school.This component of youth unemployment statistics is not insubstantial:for example, almost half of the 1978 teenage unemployment shown inTable 2.1a is generated by youths who were enrolled in school. It isthus necessary to examine other measures to better understand thenature and scope of youth employment problems. 50 38TABLE 2.2aCivilian Employment-to-Population Rates forSelected Groups (in males35-44 years 95.695.193.991.6All youths16-19 43.937.348.543.720-24 years males16-19 52.445.056.349.020-24 years males16-19 48.037.829.825.220-24 years females16-19 38.332.248.747.020-24 years females16-19 years old 26.521.823.521.820-24 years old 40.943.745.446.3 NOTE:The years 1957, 1964, and 1978 were selected becausein each of these years the unemployment rate for whitemales aged 35-44 was an identical 2.5 percent and thebusiness cycle was about at its peak. In 1984 the rate ofunemployment among white males aged 35-44 was 4.6 percent. SOURCES:Data from U.S. Department of Labor (1979, 1980a,1985b); Bureau of Labor Statistics (1983). Employment-to-Population RatesTable 2.2a presents the employment-to-population rates (the numberof employed divided by the total civilian population) for youths in thesame years for which the unemployment rates are presented. Over theperiod 1957 to 1978, the employment rate in the youta populationactually increased from 52.0 to 59.9 percent, although it then declinedslightly to 58.3 percent in 1984 (not shown in the table). Theincrease in employment rates between 1957 and 1978 was more marked for 51 39TABLE 2.2bRatio of Civilian Employment-to-Population Rates forYoung White Males to Other Young Groups YearGroup 1957196419781984 White males16-19 years old 1.01.01.01.020-24 years old .92.84.53.5120-24 years females16-19 .73.72.87.9620-24 years females16-19 years old .51.48.42.4420-24 years old .51.55.60.59 NOTE:The years 1957, 1964, and 1978 were selected because ineach of these years the unemployment rate for white males aged35-44 was an identical 2.5 percent and the business cycle wasabout at its peak. In 1984 the rate of unemployment among whitemales aged 35-44 was 4.6 percent.SOURCES:Data from U.S. Department of Labor (1979, 1980a, 1985b);Bureau of Labor Statistics (1983). the older youth group, aged 20-24, than for the younger group, and thedecline from 1978 to 1984 was steeper for the younger group.At a more detailed level, the trends for various demographic groupsare not homogeneous. For example, there wa a large increase in theemployment re:es of white women aged 20-24 from 43 percent in 1957 to66 percent in 1984), but there was also a substantial decline in theemployment rates for nonwhite men of the same age group (from 78.2 to58.3 percent). Table 2.2b presents the ratios of the employment ratesof each group to the employment rate for white males. From 1957 to1984 this ratio declined markedly for nonwhite males. For nonwhitefemales the ratios declined for the younger group, while they increasedsomewhat for 20- to 24-year-olds. Nonetheless, in all years for bothage groups, the likelihood that nonwhite females would be employed wasless than 0.6 times the likelihood that white males would be employed.For white females, the ratios showed steady increases from 1964 to1984, with the ratio for the most recent year approaching parity for16- to 19-year-olds; however, it was somewhat lower (0.85) for 20- to24-year-olds. 52 40 Employment of In-School and Out-of-School Youths Any discussion of employment-to-population rates runs the risk ofconfusing trends in school attendance with trends in employment.' Inthe present case, this is a particularly worrisome possibility. Whilethe employment rate for nonwhite youths has declined over the lest 3decades (as shown in Table 2.2a), the school enrollment rate fornonwhite youths has increased during these same decades. The rate ofhigh school completion among black men and women aged 25-29 rose from47.7 percent in 1960 to 65.4 percent in 1970 and to 79.4 percent in1S33.The employment patterns of youths who are enrolled in school are,of course, considerably different from those who are out of school.Table 2.3 provides a breakdown by school enrollment of the employmentrates for 1964, 1978, and 1981 for all youths aged 16-24.2 As onewould expect, in-school youths are less likely to be employed thanout-of-school youths. However, there are significant differences inthese rates over time for different groups. For white males, theemployment rates increased for in-school youths from 34.0 percent in1964 to 43.4 percent in 1981, while the rate for out-of-school youthswas stable at approximately 87 percent between 1964 and 1978 and thendeclined slightly during the economic downturn in 1981. In contrast,the employment rates of black males have shown a marked decline forboth in-school and out-of-school youths: the rate for those out ofschool was 80.5 percent in 1964, 67.8 in 1978, and 57.8 in 1981; therate for those in school dropped from 30 percent in 1964 to 20 percentin 1978 and was still at 20 percent in 1981.2 'Ideally, one would like to examine trends in employment statusbroken down by school enrollment, race, sex, age, presence ofdependents, and living arrangements. Unfortunately, tabulations ofemployment statistics (e.g., the Employment and Earnings series and theHandbook of Labor Statistics) do not provide the appropriate detail.Indeed, even .pith the 60,000+ sample size of the Current PopulationSurvey, we suspect it would be difficult to obtain reliable estimatesfor all the cells of such a cross-tabulation. Consequently we use thestrategy of examining the employment status of older, out-of-schoolyouths as a crude substitute.2The years 1964 and 1978 were selected to provide consistency withother tables in this chapter. Appropriate data were not published in1957 (or earlier years). No data are currently available for 1984;consequently, we have used the most recent published statistics, for1981.'In this discussion of Tables 2.3 and 2.4 we used statistics forblack youths rather than for nonwhite youths. Thia reflects thecategorization used in the published statistics.Federal statistics for recent yearp generally divide the populationby black and white and include counts for the total population (sononwhite statistics can be computed). For earlier years it is often 53 41TABLE 2.3Employment-to-Population Rates for In-School andOut -of- Statistics (1982:Table C-42). Comparing the data for young males, one finds that in 1964 theemployment rates of both in-school and out-of-school black males wereroughly 90 percent as large as those of white males. However, by 1981this gap had widened enormously: in-school black males were less than50 percent as likely to be employed as white males, and out-of-schoolblack males were only 71 percent as likely to be employed as whitemales.For young females, the data for blacks and whites also show verydifferent trends. Both in-school and out-of-school white femalesregistered roughly a 20 percentage point increase in their employment- the case that only statistics for whites and nonwhites were published.It is thus impossible to produce long time series (e.g., 1950-1980)that describe the black youth population. Nonetheless, the nonwhitestatistics, while less than ideal, do capture much of what is importantsince blacks constitute the vast majority of the nonwhites in theUnited States. In 1980 the nonwhite population included: 26.5 millionblacks; 3.5 million Asians and Pacific Islanders; 1.4 million AmericanIndians, Eskimos, and Aleuts; and 6.8 million persons whose race wasclassified as \"other.\" 54 42TABLE 2.4Employment-to-Populai.ion Rates for Out-of-SchoolYouths between 1964 and 1981. For the in-school group,their employment rate in 1981 was virtually identical co that of whitemales.For out-of-school females, their employment rates were con-sistently below those of young white males, although they increasedsignificantly between 1964 and the later two years. For black females,there was a ',light upward trend in employment while in school duringthe period 1964 to 19817 for the out-of-school group, the rate declinedslightly over the period, from 48 percent in 1964 to 43 percent in 1981.Table 2.4 disaggregates the employment-to-population rate.: ofout-of-school youths by age. This breakdown shows that the aggregateresults hold for all age groups of out-of-school youths. including theoldest.Many researchers .argue that unemployment among these older,out-of-schoel. youths is of particular concern because they are morelikely to have dependents to support and to be living outside theirparental home.This group shows the familiar pattern of rather highemployment rates among white males (90.0 percent in 1964, 84.0 percentin 1981) and consistently lower rates for blacks and females. Forout-of-school black males aged 20-24, the employment-to-population ris*4in 1964 (81.6 percent) approaches that of white males, but the ratedeclines by over 20 perc-ntage points in the following decade.Whitefemales in this age grout, how increasing rates of employment, but theyare still less likely to be employed than white males (47.3 percent of 55 43 TABLE 2.5aCivilian Labor Force Participation Rates byAge, Race, and Sex (in percentages) YearGroup 1957196419781984 All youths16-17 years old 40.235.148.642.418-19 years old 60.457.267.364.920-24 old 64.066.376.877.6White 89.689.477.577.2White females16-17 years old 32.129.548.844.818-19 years old 52.649.664.665.220-24 years old 45.848.869.372.5Nonwhite females16-17 years old 24.119.527.724.718-19 years old 42.846.548.445.820-24 years old 46.653.662.660.5 NOTE:The years 1957, 1964, and 1978 were selected becausein each of these years the unemployment rate for whitemales aged 35-44 was an identical 2.5 percent and thebusiLess cycle was at about its peak. In 1984 the rate ofunemployment among white males aged 35-44 was 4.6 percent.SOURCE:Data from U.S. Department of Labor (1982, 1985b). white females were employed in 1964 and 68.3 percent in 1981). Forblack females aged 2U -24, the employment rate rises from 50.2 percentin 1964 to 63.4 pemmt in 1978 and then declines to 48.5 percent in1981. Labor Forcl Participation Rates and Summary of Employment DataTables 2.5a and 2.5b provide complementary information on theaggregate civilian labor force participation rates of youths by age,sex, and race. (The civilian labor force participation rate is theratio of employed and unemployed people to the total nonmilitary 56 44TABLE 2.5bRatio of Civilian Labor Participation Rates forSelected Groups to Rate for White Males GroupYear1957196419781984 White males16-17 years old 1.01.01.01.018-19 years old 1.01.01.01.020-24 years 1.01.01.01.0 Nonwhite males16-17 .96.86.60.5718-19 1.0n1.00.78.7820-24 females16-17 years years .60.70.64.6520-24 years old .54.63.72.70 NOTE:The years 1957, 1964, and 1978 were selected becausein each of these yeare the unemployment rate for whitemales aged 35-44 was an identical 2.5 percent and thebusiness cycle was at about its peak. In 1984 the rate ofunemployment among white males aged 35-44 was 4.6 percent.SOURCE:Data from U.S. Department of Labor (1982, 1985b). population; as noted above, the labor force statistics exclude personswho are unemployed and not looking for work.) A comparison of therates in Tables 2.1a through 2.2b and Tables 2.5a ano 2.5b suggest thatyouth unemployment is generated by somewhat different tnderlying trendsfor males and females and whites and nonwhites. For that reason it isuseful to discuss each group separately. White Males The labor force participation rates for white males fluctuated overthe 1957-1984 period. They were up in 1957 and 1978 (particularly for16- to 17-year-olds) but declined in 1964 and 1984. There was also anupward movement in the employment-to-population rate between 1957 and 57 45 1978 for yo..aths aged 16-19, but the employment rate for youths aged20-24 declined from 80 percent to 76 percent in 1978 then rose to 78percent in 1984. The unemployment rate for the younger group hasincreaseo because the labor force participation rate of the group aged16-17 has increased by more than the employment-to-population rate. Nonwhite MalesFor nonwhite males the story is s.:ark and consistent. During theperiod from 1957 to 1984, the labor force participation rates of youngnonmhite males of every age group declined considerably, and theiremployment-to-population rates also dropped markeu_y. The proportionof those aged 16-19 who were employed declined from 48 to 25.2 percent;for those aged 20-24 it declined from 78.2 to 58.3 percent. Thus thelarge increases shown in Table 2.1a for the unemployment rater ofnonwhite males understate the labor market difficulties faced by thisgroup:had their labor force participation rates not declined from1957 to 1984, their unemployment rates would have been even higher thanshown in Table 2.1a. White FemalesWhite females sharply increased their labor force participationfrom 1957 to 1984. For 20- to 24-year-olds, the rate of participationincreased from 45.8 to 72.5 percent, and the gap between white male andfemale levels of participation decreased substantially. The employment-to-population rates for this group also increased during this period,from 43.4 to 66.1 percent for those aged 20-24, and as a result theirunemployment rate increased. The overall picture for white females isone of an improving employment situation, but one that has not improvedrapidly enough to keep pace with their increasing desire (and need) toparticipate in the labor force. Nonwhite FemalesThe labor force participation rates of nonwhite females increasedless rapidly than did the rates for white females, although the increasefor 20- to 24-year-olds is still quite sharp, from 46.6 percent in 1957to 60.5 iercent in 1984. During the entire period, nonwhite femaleshave had lower labor force participation rates than all other subgroups.The employment-to-population rate for nonwhite females declined forthose aged 16-19 and increased for those aged 20-24. For the entireperiod nonwhite females had lower employment-to-population rates thanall other subgroups. Thus, despite some signs of improvement inabsolute levels for those aged 20-24, the employment rates reveal thevery serious situation of nonwhite females in comparison with othegroups of the youth population. 58 46Hispanic Youths There are no adequate historical data to perform similar analysesfor Hispanic youths, and so we are unable to assess the dynamics thatmay account for the Hispanic unemployment rates shown in Table 2.1a.Those rates are higher than those for white youths but lower than thosefor nonwhite youths: as shown, for males aged 20-14, the uremploymentrates in 1984 were 9.8 percent for white males, 12.2 percent forHispanic males, and 24.5 percent for black males. Inactivity RatesThe above analyses suggest that when one looks beyond the unemploy-ment rate, a more complex picture of the nature of the youth unemploy-ment problem emerges. The most striking features of this picture arethe changing dynamics of female employment (particularly among whites)and the stark contrast between the employment statistics for youngblack men and women and those faced by other groups.These differencescan be seen even more clearly in \"inactivity rates,\" the numbers o:youths who are neither in school, nor in the military, nor employedrelative to their population. Table 2.6a presents inactivity rates forseveral demographic groups for the years 1964, 1978, and 1983. Foralmost every group the inactivity rates were lower in 1978 than theywere in 1964; the major exception is for nonwhite males aged 20-24,whose inactivity rate during this period climbed from 10.5 to 15.9percent.It should also be noted that the inactivity rates for both whiteand nonwhite women aged 20-24 remained strikingly higher than those forwnite and nonwhite males. As shown in Table 2.6a, the inactivity ratesfor nonwhite females in 1978 were 19-year-oldsand 33.5 percent for 20- to 24-year-olds.In 1983 the inactivity rates of almost al] groups were higher than in 1978.This reflects the depressed state of the national economy in1983, which is also reflected in the rise in the rate of unemploymentfor 35- to 44-year-old white males from 2.5 percent in 1978 to 5.2percent in October 1983. During this period the inactivity rates fornonwhite females took especially large leaps: in 1983 more than 40percent of nonwhite women aged 18-24 were out of work and out of school.While inactivity rates for all groups rose in 1983, becauseinactivity rates for white males rose faster than did those of othergroups, the situation of nonwhites of both sexes and white femalesshowed some improvement relative to that el white males; see Table2.6b.For example, among 20- to 24-year-ol3s, the inactivity ratesrelative to white males declined from 2.69 to 2.33 for nonwhite males,from 4.08 to 2.16 for white females, and from c.68 to 3.93 for nonwhitefemales.However, the inactivity rates for both male and f salencnwhites and for white females are still higher than those for whitemales.Over the entice period 1964 to 1983, the lowest inactivityrates for every age group are those for white males. 59 47TABLE 2.6aInactivity Rates for Youths by Race and Sex YearGroup 196419781983a White males16-17 years old 3.33.64.518-19 years old 8.04.713.120-24 old 6.15.911.6Nonwhite males16-17 years old 8.43.74.718-19 years old 14.613.229-320-24 years (42.5)20-24 years old 45.733.545.6 (45.6) NOTE:7.nactivity rates are the percentage of thepopulation that is neither employed, serving in themilitary, nor enrolled in school. The years 1964 and1978 were selected because the unemployment rate forwhite males aged 35-44 was an ieentical 2.5 percent andthe business cycle was about at its peak. October 1983is the most recent date for which comparable rates canbe computed.In October 1983 the rate of unemploymentamong white males aged 35-44 was 5.2 percent (notseasonally adjusted).aFor 1983, fl3ures in parentheses are femaleinactivity rates calculated to take account of militaryservice by females. SOURCES:Data for 1964 and 1978 from OngressionalBudget Office (1982); data for 1983 computed from Bureauof Labor Statistics (1984) and unpublished tabulation ofmilitary enrollment by age, race, and sex. (Data for1984 are not currently available.) GO 48TABLE 2.6bPatio of Inactivity Rates for Other Groupsto Those 2or White Males YearGroup 196419781983a White males16-17 1.01.01.018-19 old 1.01.07.020-24 old 1.01.01.0Nonwhite males16-17 years old 2.551.031.0418-19 years years years 7.195.683.93 (3.93) NOTE:Inactivity rates are the percentage of thepopulation that is neither employed, serving in themilitary, nor enrolled in school. The years 1964 and1978 were selected because the unemployment Late forwhite males aged 35-44 was an identical 2.5 percent andthe business cycle was about at its peak. October 1983is the most recent date for which comparable rates canbe computed.In October 1983 the rate of unemploymentamong white males aged 35-44 was 5.2 percent (notseasonally adjusted). aFor 1983, figures in parentheses are femaleinactivity rates calculated to take account of militaryservice by females. SOURCES:Data for 1964 and 1978 from CongressionalBudget Office (1982); data for 1983 computed from Bureauof Labor Statistics (1984) and unpublished tabulation ofmilitary enrollment by age, race, and sex. (Data for1964 are not currently available.) 61 49As the ratios presented in Table 2.6b make clear, the disparitiesin inactivity rates are often quite large. For females, even thoughthe disparities in inactivity declined between 1964 and 1983, inactivityrates for those aged 20-24 were still 2.16 (for whites) and 3.93 (fornonwhites) times as large as those of white males. (It is unfortunatethat oe are unable to disaggregate this result to determine the portionof female \"inactivity\" that represents women who are at home with youngchildren.Because some of this female \"inactivity\" represents child-bearing, readers are advised to interpret the inactivity rates inconjunction with *he unemployment rates shown in Table 2.1.) Fornonwhite males, the trends across time show increasing disparity foryouths aged 18-24. While the ratio of inactivity rates was 1.82 (firthose 18-19) and 1.72 (for those 20-24) in 1964, it had increased to2.24 and 2.33 by 1983, and the disparity was even higher during 1978, atime of increased economic activity. The sole exception to thisdisturbing picture is found among the youngest group of nonwhite males.Their ratio declined from 2.55 in 1964 to approximate parity in 1978 (aratio of 1.03) and remained at that level in 1983 (a ratio of 1.04).This improvement relative to white males is attributable to increasedlevels of school enrollment and roughly constant rates of militaryenlistment for young black males. A similar trend can be observed for16- to 17-year-old females, although in 1983 both white and nonwhitefemales were still approximately 1.3 times as likely to be out ofschool and out of work as white maled3. Entry, Turnover, and UnemploymentAnother way to understand the nature of the youth employment problemis to study the nature of the events that lead to unemployment. Ananalysis by Freeman and Medoff (1982) provides some insight into theprocesses that lead to youth unemployment (see Table 2.7). The salientfeature of Table 2.7 is the sizable proportion of young people whoseunemployment is associated with entry into the labor force--either forthe first time, as new entrants, or reentry after a period out of thelabor force.The high proportion of new entrants among youths is notsurprising.The high proportion of reentrants reflects the fact thatteenagers tend to drop out of the labor force after a period of unem-ployment.As youths get older, however, their unemployment is lesslikely to be due to entry or reentry into the labor market.ThuFin 1978, for those aged 16-17, entrants into the labor marketaccounteu Lor the vast majority of the unemployed--39.8 percentagepoints of the 44.0 percent unemployment rate of blacks and 11.0percentage points of the 13.8 percent unemployment rate of whites in1978.Among those aged 18-19 entrants into the labor market accountedfor 30.5 percentage points of the 38.0 percent unemployment rate forblacks and 4.5 percentage points of the 9.0 percent rate for whites.By the age of 2C-24, most of the unemployed youths have left or losttheir jobs:entrants into the labor market account for only 7.9percentage points of the 18.8 percent black unemployment rate and 2.3percentage points of the 6.6 percent white unemployment rate. 62 50TABLE 2.7Direct Causes of Youth Unemployment, Males and Females: 1969-1978 and Status 16-17 Earnings) donot provide age breakdowns for 16- to 17- and 18- to 19-year-olds Thus there are no readily accessible tabulations for years after 1978.aThis rate is reported as .05 in Freeman and Medoff (1982). This appears to be a typographical error; it has been corrected to 0.5, which would be consistent with the published rates for total entrants and reentrants.SOURCE:Freeman and Medoff (1982). A second important cause of unemployment as shown in Table 2.7 isthe high percentage of job losers; for all but one group (blacks aged20-24 in 1969), job lasers exceed job leavers. In contrast to theusual view that youths have high unemployment rates because they quit jobs more often than adults, these data indicate that their problemsarise primarily because they lose jobs or tend to find jobs for which the probability of firing or layoffs is higher. 63 51TABLE 2.8Ratios of the Median Usual Weekly Earnings of Out-of-SchoolMales to Earnings of Male Workers Aged 25 and Older, by Race: 1967-77 Earnings of Full-TimeYoung White Men/Earnings In an interesting analysis of the black/white differential inunemployment, Freeman and Medoff (1982) demonstrate that much of thegap is due to the longer time it takes young black men and women tofind a job on entry into the labor force, in addition, among youthsaged 20-24, the higher black unemployment rate is partly due to ahigher job loss rate than for whites, Black youths appear to have botha harder time finding a first job and a greater likelihood of losing ajob than whites (Freeman and Medoff, 1982).Entry and job turnover figures cannot, however, be used to discountthe unemployment problem as a whole, since a subset of youths areunemployed for long periods of time and bear a disproportionate shareof the burden.Feldstein and Ellwood (1982), using 1976 CurrentPopulation Survey data on out-of-school teenagers, estimate that 8.3percent of the youths were unemployed f. more than 26 weeks andaccount for 52 percent of total unemployment days among that group.Lerman (1980a) estimates, using 1977 data, that 70-80 percent )f totalyouth unEmployment (including that of in-school youths) was borne byyouths with 15 or more weeks of unemployment. Wages and Earnings While many employment problems can be measured in terms ofnonemployment of one type or another, a full picture of the youthemployment predicament also requires consideration, of wages andearnings.Table 2.8 presents data on the earnings of male youths as apercentage of earnings of white males aged 25 and over. Two featuresof these data should be noted: First, over the decade from 1967 to1977, the earnings of young me, relative to those of adult men declined. 64 52Second, the extent of the decline was greater for white than nonwhiteyouths and, therefore, the earnings of young black men grew relative tothose of young white men. Thus, we see both a general deterioration ofearnings of ,oung males and a relative increase in earnings (actually asmaller decrease) fo: young black males compared with young white males.Moreover, when variot3 individual characteristics are controlled, theaverage wages for young black males are not significantly differentfrom those of young white males.The observed difference in total earnings is due primarily to thefact that the probability of a young black male with a given set ofcharacteristics obtaining a job is much lower than that of a youngwhite male with similar characteristics (Freeman, 1980). Unfortunately,there is no comparable analysis for the earnings of young women, andthus we do not know if a similar finding would result. CAUSES AND CONSEc'ENCES OF YOUTH EMPLOYMENT PROBLEMS The previous section has documented unemployment rates and othermeasures of employment for youths and differences among blacks andwhites, males and females, atd other groups for the past 2 decades. Ithas also raised a score of questions. What explains the high unemploy-ment rate of youths compared with adults? Why have rates of unemploy-ment been rising? Why has the gap between blacks and whites widened?How do these trends relate to the relative decline in earnings foryoung full-time workers and the narrowing gap in earnings between youngwhite and black full-time workers? What is the source of the male/female differences in youth employment experiences?Researchers typically discuss a number of supply and demand factorsthat might contribute to continuing high unemployment rates for youths(e.g., Ellwood and Wise, 1983). On the demand side the factors include:poor macroeconomic performance; shifting geographical and industrialdistribution of jobs; minimum wage laws and other government interven-tions in the labor market; discrimination in hiring; and demand formilitary o,I.rsonnel. On the supply side the factors includes the babyboom bulge and other demographic factors; unrealistic expectations ofyouths, And the \"reservation\" wage; and mismatchej jobs and educationalqualifications. Each of these factors is discussed in this section, inturn, along with recent empirical evidence and the nature of continuingdisagreements among researchers. At the end of this section, we alsoconsider other factors that do not fit neatly into the demand andsupply categories.At the outset it should be kept in mind that it is not possible todiscriminate accurately among all these causes given the availabledata.If time-series data are used, there are too many overlapping andcorrelated trends to distinguish among thcms for example, the babyboom bulge coincided with \"stagflation\" and poor macroeconomic per-formance in the 1970s. It is also very -ifficult to measure or dis-tinguish between the effects of subjective variables such asdiscrimination on the demand side or low motivation or lack of generalskills on the supply side. 65 53Factors Affecting the Demand for LaborMacroeconomic Conditions The unemployment rates of youths are more sensitive to macro-economic conditions than are those of adults. Comprehensive studies oftime-series data by the Congressional Budget Office and the Council ofEconomic Advisors suggest that a 1 percent change in the unemploymentrate for adult males is matched by a 1.5 percent change for whiteyouths and a 2.5 percent change for black youths (e.g., CongressionalBudget Office, 1978). Freeman (1982) has argued and we agree that theemployment-to-population ratio is a more reliable indicator of youthactivity.In both time-series and cross-sectional data, he finds thata 1 percent change in the total male unemployment rate leads to a 1.7to 2.4 percent change in the employment-to-population ratio for youthsaged 16-19 and a 1.5 to 3.4 percent change for those aged 20-24(Freeman, 1980). Bowers has reviewed the employment experiences ofblacks, teenagers aged 16-19, and women during all business cycles from1948 to 1980, and he also concludes (Bowers, 1981) that teenagers andblacks, both in the aggregate economy and in key cyclical sectors,suffer a disproportionate share of the decline in employment thatoccurs during economic recessions.It should be noted that when the adult male unemployment rate wastrending upward over the past 2 decades (even from peak to peak in thebusiness cycles), the foregoing relationships imply that there would bean even Greater deterioration in the employment situation for theteenage group.Such data provide only a crude indicator, of course, ofthe complex relationships that exist between the employment problems ofteenagers and the evolution of the macroeconomic situation in thenation.Nonetheless, there appears to be substantial agreement amongmost researchers that a relatively high level of economic activity isessential for any long-term improvement in the youth employmentsituation. Industrial and Geographical Shifts in the EconomyFrom year to year, the American economy changes. Wealth increasesand tastes change, new technologies are discovered and brought on line,old factors of production or natural resources are used up and new onesfound, foreign trade opens up opportunities for some U.S. goods andcreates intense competition for others. At the same time, broad shiftsmay occur in where people want to live, from one region to another orfrom cities to suburbs or from suburbs to rural areas. These changesare very likely to lead to shifts in the demand for young workers overtime, although the precise links may be hard to trace. If wage ratesor other factors of production were totally flexible--as in classicaleconomic models--supply and demand would quickly adjust, but such isnot the case in reality.The decline of agriculture and the movement of black families fromsouthern rural areas to northern cities explains some of the widening 66 54black/white youth unemployment gap in the 1950s and early 1960s. Cogan(1982), Lerman (1980a), and Mare and Winship (1983), among others, havepointed out that in 1950 young black men in farm areas of the Southexperienced minimal unemployment (e.g., 3 percent for 18- to 19-year- olds).At the same time, the unemployment rate for urban youngblack men was 20 percent, substantially higher than for whites. Thelarge-scale flow of blacks northward and from rural to urban areaswould thus, all else being equal, contribute to an increased disparitybetween the unemployment rates of white and black males (since theblack migrants would now, presumably, suffer from unemployment at thehigher rate characteristic of black urban residents). However, since1970 migratory patterns have eaanged, and the racial differential hasbeen increasing in all regions. Migration alone cannot explain thisphenomenon.Another possible cause of a downward shift in demand for youths,particularly for blacks, is the movement of jobs from the inner citiesto the suburbs and beyond (a move resulting in large part because landand other costs are lower). This is a matter of some dispute in theeconomics literature. Leonard (1984) has found, for example, that theratio of black to total employment in any given firm in Los Angeles orChicago in the 1970s varied inversely with distance from the blackghetto.Over time, the loss of employment in the cities has resultedin an appreciable loss of jobs for blacks wh apparently because ofracial discrimination, do not follow the jobs as they move into thesuburbs and nonmetropolitan areas. However, this movement of jobs awayfrom where blacks live cannot explain the bli 3k/white differential thatpersists within inner cities. Ellwood (1983), for example, has shownthat in Chicago distance from jobs was a weak predictor of employment:for black and white youths living in adjacent neighborhoods, blackyouth employment could be as much as 20 percent lower than white youthemployment; similarly, blacks in neighborhoods near jobs were no morelikely to be employed than blacks in neighborhoods far away from jobs. Minimum Wage Laws and Other Government Interventions Low wages are an unfortunate fact of life for many young workers inAmerica.Since low-wage workers are more likely to have their jobsaffected by the statutory minimum wages, much of the concern about thepolicy implications of minimum wages has focused on the impact ofminimum wages on the youth labor market. There have been severalcomprehensive reviews of the impact of minimum wage laws on the youthlabor market (Brown et al., 1982; Freeman, 1982; Report of the Minimumwage Study Commission, 1981; Welch and Cunningham, 1978; Mincer, 1976;Rosters and Welch, 1972). Most estimates of the disemployment effectsare relatively small. The estimates from time-series data indicatethat the disemployment effects for white males resulting from a 10percent increase in the statutory minimum would reduce the level ofemployment by 1-3 percent (Freeman, 1980). For young blacks and women,there are larger, estimated effects, and the greatest effects onemployment are for the youngest workers. Theoretically, nonwhites 67 55should experience greater levels of disemployment, but Brown, Gilroy,and Kohen (1982) could find no convincing evidence that this occurs.Economic researchers have also become interested in the nonemploy-mert influences of a statutory minimum wage. Hashimoto (1982), Lazearand Miller (1981), aad Fleisher (1981) have argued that, in addition towhatever disemployment effects are caused, the minimuld wage will alsoprevent young people from being able to engage in on-the-job training.These human capital theorists propose a model in which an employee'sfull wage has a market wage and an unmeasured component of on-the-jobtraining that shows up in future wage growth. Using the NationalLongitudinal Survey (NLS) between 1966 and 1969, Hashimoto (1982)estimates that the loss in earnings growth would be between 2.7 and 15percent of the observed wage of workers. It seems unlikely, however,that the minimum wage could explain the increasing gap in employmentbetween adults and youths (particularly minorities and women) since, inreal terms, the minimun wage has been declining in recent years.\" niscrimination Discrimination could contribute to youth employment problems in theform of discrimination on the basis of age or on the basis of race or In addition to whatever disemployment or nonemployment is caused bythe minimum wage on the demand side, the existence of income maintenanceprograms may work (along with minimum wage laws) to provide an alterna-tive to work for children of families receiving income maintenance.Thus, these government interventions might affect the supply of labor.Betsey and Dunson (1981) find that part of the estimated minimum wageimpact may be attributable to increases in welfare payments. It isclear that in trying to assess the impact of minimum wages one has toalso consider changes in other income maintenance programs.Venti (1984) has estimated the disemployment effects caused by oneincome maintenance program, using data from the Seattle-Denver IncomeMaintenance Experiment. This experiment offered benefits well inexcess of contemporary welfare programs (e.g., financial support levelsfor a family of four of $3,800, $4,800, and $5,600 in constant 1971dollars).Venti finds that this income maintenance program had largedisemployment effects, but that when one considers the choice as ajoint one with the decision to go to school, almost all of thedisemployment is a movement into schooling, not into idleness. Ventiand Wise (1984) argue that interpretation of these results requires anallowance for schooling decisions becaure analysis of the simple workeffect may be an incomplete indicator of the social and economicconsequences of an income maintenance program.\" Of course, in turn,one doeE not know whether some of this movement into schooling mayrepresent disguised idleness: Are youths using their time to gain realmarket skills through schooling or simply disguising their problem withunproductive schooling? 6S 56 sex.That employers prefer older workers to younger workers seems tobe well established. However, whether this preference constitutesdiscrimination dep.:nds on whether there are in fact differences inproductivity, costs of trainag, and turnover associated with youngerworkers (Freeman, 198C). There have been few attempts to establishsuch relationships empirically. Discrimination studies have con-sistently shown black adult workers to have lower earnings than whitesafter the measured individual charaeteriErcics have been controlled for;a large part of t: earnings differential is associated with theprobability of emp. ,sent rather than differences in wages.Willi respect to wages and earnings (net of weeks worked) and commonhuman rvital variables (e.g., education), economists have generallyfound substantial evidence of discrimination in wages prior to themid-1960s, but in more recent years the available evidence suggeststhat discrimination in wage rates by race has been narrowed (Reimers,1983) or effecti.-el: ended (Osterman, 1980; Freeman, 1973). For womenworkers, however, the situation is quite different. Among full-time,year - round workers, the earnings of women average less than 60 percerof those of men, and young women (age 20-24 years) earn approximately87 percent as much as young men. A National Research Council review ofdiscriminaticu in wage-setting found that thy: evidence \"suggests thatonly a small part of the earnings differences between ren and women canbe accounted for by differences in education, labor bocce experience,labor force commitment, or other human capital type factors believed tocontribute to productivity differences among workers\" (Treiman andHartman, 1981). A major confounding factor is the suostantial occupa-tional segregation of the work force--with women being concentrated inoccupations that are low paying.With respect to employment--in contrast to wages--efforts have beenreported by Csterman (1980.: to account for the disparity in unemploy-ment rates between whites and blacks on V baais of standard humancapital variables. He found that about one-half of the gem in unemploy-ment rates between yoL'ng black and white workers could be accountedfor:if one followed the convention used in the earnings literature,the residual gap would be attributed to discrimination (Osterman,1980b).The actual mechanics by which this discrimination operates aredifficult to specify. Culp and Duneon (1983) present findings from apilot study suggesting that treatment of job applicants with the samebackgrounds and qualifications may depend in many crucial ways on therace of the applicant. There is also evidence (Rossi and Ornstein,1973) suggesting that the social networks and friendships csed to findjobs are segregated by race, resulting in some disadvantage to nonwhiteyouths.discrimination may account for differences between blacks andwhites at a given point in time, it is more difficult to establish thatincreases in discrimination in the late 1960s and the 1970s were animportant factor in explaining the increasing differential in employmentbetween young blacks and young whites. 63 57 Antidiscriminatio.1 Laws and Enforcement The three key pie-es of statutory and administzative policy thataffect the level of discrimination in society--Title VII of the 1964Civil Rights Act, Executive Order 11246, and the Equal Pay Act of1962emphasize the job market opportunities of entrants or reentrantsinto the job market. All three were enacted or issued before theemployment problem: of young people were generally viewed as centralissues in the society.Analysts disagree on how effective Title VII (and other measures)can be for young minority and female workers. The statute exempts manysmall employers from the statutory scheme. When the act becameeffective on July 2, 1965, it applied only to employers of 100 workersor more.The current limit is 15 workers, which still excludes coveragefor many young people employed in small stores and restaurants. Morethan one-third of all youths aged 16-24 work in retail trade, includingrestaurants, and many of these are small operations not covered byTitle VII.In addition to jobs not being covered by Title VII cc correspondinglimitations in Executive Order 11246, many young workers may find thecost of litigation to be too great, given their lack of commitment to aparticular job. In order to bring pressure on a recalcitrant employer,someone must be willing to complain and involve himself or herself inthe expensive and time-consuming process of enforcing the statute'sprohibitions against discrimination. One would expect the willingnessto finance and bring suits to be positively related to expected lengthof job tenure and the relative attractiveness of that job in comparisonwith other possible job opportunities for the potential complainant.Both of these factors tend to be lacking in many jobs that young peoplehave.Questions have sometimes been raised about potential disemploymenteffects of antidiscrimination laws and affirmative action programs. Byraising black youths' wages, have they reduced employment? Freeman andHolzer (1985) reply to this question by noting that the laws and pro-grams are intended to change the demand for labor, aot wages: theyassume nondiscrimination in wage netting and attem,t to increase thedemand for minority and female workers. According to Freeman andHolzer (1985) the most reliable assessments of the effects of affirma-tive action programs indicate that the programs do increase employmentof these groups, although this claim has been disputed in the economicsliterature. Demand for Military PersonnelService in the military ha; long been an important employmentexperience for young w.ies, although the proportion of youths servingin the armed forc=es has been declining since the late 1960s. Despitethis decline, the availability of employment in the military is impor-tant for some groups of the y \"uth population. In 1984, 9 p.arcent ofnonwhite males aged 18-24 number of 7o 58approximately 224,000 is quite substantial when viewed in perspectivewith the number of nonwhite male youths of the same age who wereemployed in civilian occupations (1.1 million). Changing patterns of military service by different racial groups masked some of the differ-ential in civilian employment between black and white youths.Duringthe 1970s white youths' participation in the military declines' sub-stantially while clack youths' participation remained approximatelyconstant (Ellwood and Wise, 1983). If, after 1972, the proportion ofblack youths in the military had declined in proportion to th, whitedecline, the proportion of black youths without work in 1982 would havehave risen by about 3 percent (Mare and Winship, 1983). (Participationin military service by females involved only 0.6 percent of whitefemales cnd 1.4 percent of nonwhite females in 1984.) Factors Affecting the Supply of Labornemographic TrendsDuring the 1970s several demographic trends might have affectedyouth employment. First, and most prominent, was the entry of themassive baby-boom generation into the labor force. Theory suggeststhat as the supply of young workers rises relative to the supply oftroth older workers and other factors of production, youth wages oremployment will fall relative to that of older workers. Indeed, in across-sectional analysis of standard metropolitan statistical areas,Freeman (1982) found that as the youth share of the populationincreased, employment prospects declined by a moderate amount,particularly for those aged 16-17. However, analysis by Wachter andKim (1982) suggests that, at a national level and orer time, theprimary effect appears to have been on cages.For example, as shown inTables 2.2a and 2.2b, during the period of rapid expansion o_ the youthlabor force, 1957 to 1978, the employment-to-population rate for white youths stabilized Or actually increased. In contrast, Table 2.8 showsthat during the 1970s the wages of white youths declined relative to adult wages.Whatever the effects of this large demographic bulge, itclid not overcome other factors tending to raise the employment-to-population rate for white youths, but it may have played a role inlowering their relative wages. Among black youths, howet,er, thepattern appears different: relative wages over those years declined byless than those of white youths, but unemployment rose and employmentrates fell substantially.Two other factors increased the supply of labor during the same period:the sharp and continuing rise in the labor force participation of adult women (see Hahn and Lerman, 1983) and the influx of immigrant workers into the United States. Each of those groups might draw jobsaway from youths if they enter the labor market in part-time or low-skill jobs (particularly if employers prefer to discriminate in their favor or can pay lower wages to these groups). It is possible thatincreased numbers of women in the labor foica may have worsened theemployment prospects and lowered the wage rates of youths (Borjas, 591983), although there have been few studies of such effects. Estimatingthe employment interactions between youths and immigrants has beendifficult because of the lack of reliable data on the illegal componentof the immigrant work force. However, Freeman and Holzer (1985) reportthat there is no evidence to support the view that increases in theHispanic population (which accounts for a zubstantial number ofimmigrants) have hurt job opportunities for black youths, since blackyouth unemployment rates are similar in cities with large and smallHispanic populations.A fourth demographic development of considerable importance is thechange in childbearing and marital patterns in the youth population.During the 1970s there was both a decline in the rate of marriage amongyouths and an increase in divorce among those who did marry. It ispossible that these changes might increase the supply of female labor.While childbearing declined sharply among young married women, it didnot decline among unmarried women. Births to unmarried women tripledas a share of all births between 1960 and 1979 (although their numberdid not rise). In 1983 among married and unmarried women aged 18-24,there were 965 births per 1,000 female high school dropouts and 506births per 1,000 female high school graduates who did not attendcollege (U.S. Bureau of the Ctasus, 1984:Table 4).Since young, unmarried women with children have disproportionatelylower incomes and consequently may have difficulty obtaining affordablechild care, they may have more difficulty in finding and holding jobsthan other young people. However, while the magnitude of this effecthas not been estimated for youths, there is evii.ence that lack ofsatisfactory child care is a restraint on women's employment (Presserand Baldwin, 1980). (As noted in Chapter 1, research on this importanttopic should be encouraged.)As we noted above, there has been a substantial expansion of theyouth labor supply over the last several eecades, resulting fromchangei in birth rates during the immediate postwar period and sub-stantial increases in the number of young women who entered the labormarket.To the extent that an excess of \"supply\" is (by definition) aprerequisite for unemployment, it is prudent to ask whether this growthin the supply of young workers will continue in the next decade.Since one aspect of such a forecast involves making assumptionsabout the future decisions of millions of young women, any answer wouldbe quite speculative. It may not be unreasonede to expect the rate offemale participation in the labor force to approximate that of men, butit may also not be unreasonable to speculate that traditional patternswill die hard, thus restraining further large jumps in the rate offemale participation in the labor market.There is, however, one aspect of a forecast about which we do havesome \"hard\" evidence: the 1990s \"supply\" of teenagers has already beenborn, and barring massive changes in death rates or patterns of migra-tion, one can venture a prospective count of their numbers. Figure 2.1shows the actual and projected size of the older teenage population for1960-2000.For the period 1960 through 1982, thie segment of thepopulation grew from roughly 13 million to more than 21 ,pillion in 1980and then began to decline. In 1982 the totaled 72 20 150E0z10 a0a560 01---I trends in the youth population aged15-19, 1960-2000. NOTE:The 1970 and 1980 figures are population counts from decennialcensuses reported in U.S. Department of Commerce (1985:Table 30). The1960 figures are population counts from the 1960 decennial census asreprinted in Bureau of the Census (1973:Table 189). The 1975, 1981,and 1982 figures are estimates based on Current Population Surveysample surveys of population as reported in Bureau of the Census (1979,1982).The 1985-2000 figures are population projections (middleseries) made by and repotted in Bureau of the Census (7982). 19.8 million.When the size of this population group is projected tolater years, it shows continuing declines through 1995; at that time itis roughly 80 percent of its peak (1980) size. Thus, on the supplyside, the demographic projections indicate that there will be a steadydecline in the number of potential participants in the labor marketthrough 1995. Enrollment in School .hanges in school enrollment patterns could have a direct effect onthe measured extent of unemployment problems among youths (Hahn lndLerman, 1983). During the 1960s and 1970s, the enrollment rates forwhite males declined somewhat and those for white women and blacks of 61TABLE 2.9Perlentage of Persons Aged16-24 Enrolled in School, by Race and Sex Group 196419741983 White males 51.045.844.7Nonwhite males 39.448.545.4White females 36.439.140.7Nonwhite females 34.138.640.9 SOURCE:Data from Bureau of LaborStatistics (1982, 1984). both sexes increased (see Table 2.9). The difference in the patternsof school enrollment between blacks and whites contributed in part tothe growing differential in employment-to-population ratios betweenblack and white youths (Freeman, 1980). The declining school enroll-ment rate of whites would tend to increase their employment rates sincethe employment rate for those out of school is generally higher ttanthat for those in school. However, most of the increased employmentfor young whites in the past two decades came from rising employmentrates for in-school youths.More interesting than the question of enrollment status is thedegree to Oich educational attainme has an effect on the labormarket experiences of youths. ManyAdies indicate that dropouts havea more difficult time in the labor market than do high school graduates.These effects are seen in difficulties in obtaining the first job, induration of un!mployment between jobs; and in wage rates. Academicperformance appears to be positively related to both number of weeksemployed and wage rates for youths. Other studies find that vocationaltraining in high school appears to be unrelated to employment and wagerates, while there are some indications that vocational training afterhigh school may have some positive effects (Freeman and Wise, 1982).These findings on the effects of education on employment experi-ences may help to explain the distribution of employment and unemploy-ment among youth groups, but they do not appear to lelp to explain thegrowing differential between black and white youths. One explanationthat has been put forward is that differences in the quality of educa-tion are responsible for the growing differential. The validity ofthis explanation is difficult to test. Studies of functional literacydo sts'w thet literacy rates are lower among blacks than among whites,but there is no indication that this gap has widened over recentyears.Similarly, while there has been some overall decline in theScholastic Aptitude Test (SAT) and other test scores, there is noindication that racial differentials in test scores have increased overtime (Hahn and Lerman, 1983). 74 62 Youths' Expectations and the Reservation Wage The \"reservation wage\" of a person is defined as the lowest wage atwhich that person would be willing to take a job.It has been suggestedthat some of the employment problems of youths may be related to areservation wage that is too high. In addition, some analysts arguethat increasing incomes throughout the society have caused the level ofthe reservation wage to rise over time to a greater degree thanwarranted by the increasing skills of the labor force.Data on reservation wages have not been collected over long enoughperiods of time for conclusions to be drawn as to whether risingreservation wages have been a Aajor cause of increased unemployment foryounger workers. On the whole, recent studies find (e.g., Freeman andHolzer, 1985) that the reservation wages of unemployed younger workersappear on average to be quite realistic: both white and black youthsappear to have reservation wages that are quite close to the prevailingfederal minimum wage.While the reservation wages of white and black male youths areabout the same, Freeman and Holzer suggest that the fact that theemployment prospects for blacks are worse means that their reservationwages are higher relative to the actual wages they are likely to beable to obtain. And reservation wages for specific low-wage jobs aregenerally lower for blacks than for whites. Reservation wages of youngblacks appear to have the effect of lengthening the period of nonemploy- ment but also of increasing subsequent wages. The reservation wages ofyoung whites have somewhat less effect on the duration of nonemploymentbut greater effects on their subsequent wages. Summing Individual EffectsThus far we have been serially reviewing possible causes of thetrends in youth employment problems within a framework of demand andsupply factors. Two sets of researchers, Ellwood and Wise (1983) andMare and Winship (1983), have independently sought to bring togethermost of the factors covered above in a consistent accounting frameworkin order to see what proportion of the growth in the gap in black/whiteyouth employment rate.. can be explained by the sum of the individualeffects of ell the factors. Though their accountin ameworks arequite different, both sets of researchers conclude they canaccount for onll about 50 percer.'z of the diverging racial employmentpatterns among youth: in the 19i9s.In discussing each factor separately we have also not touched uponpossible (nonadditive) interactions among factors; such interactionsmight yield results that are different from the simple sum of eachindividual factor. Two hypothetical examples can illustrate suchinteractions.It was previously noted that increases in the supply ofyoung workers seem to be related to increases in employment rates anddecreases in wages (relative to adults) for young white males, but theyseem to be related to sharp decreases in employment rates and smallerrelative wage decreases for young black males. These differences might 7 63 be due to the interaction of the increased supply of labor and theexistence of minimum wage rates and increased civil rights enforcementand affirmative action programs. The wages of young black males werealready closer to the minimum wage than were those of young whites, sowhen the youth labor supply increased employers had less room tocompress black wages than white wages. [Hall (1982) suggests thispossibility in his commentary on the research of Wachter and Kim(1982).]A second possible interaction is between the demographic increasein supply and employer discrimination. Even if the desire to discrimi-nate on the part of employers was not increasing during recent decades,the increase in the supply of both young whites and blacks may haveincreased the scope for the exercise of discriminatory hiring byemployers.sThis theoretical possibility was emphasized in theearliest exposition of an economic theory of discrimination by Becker(1957).While these higher-order interactions generate interestinghypotheses, they are extraordinarily difficult to assess empirically,particularly when they involve such factors as the minimum wage ordiscrimination, which have proved challenging to assess even assingular first-order factors. Other Influences on Youth EmploymentSeveral reseaLlh findings do not fit neatly into the supply anddemand framework we have used in the preceding sections of thischapter.We note several of these briefly and then turn to a dis-cussion of social context. Family Influences and Teenage ExperiencesFamily background has a positive relationship to the probabilitythat a young person is employed, and Meyer and Wise (1932) find that anincrease of $5,000 in parental income is associated with an increase ofmore than three weeks in the number of weeks worked by teenagers.Other family structure factors do seem to affect employmentprobabilities (see Rees and Gray, 1982; Corcoran, 1982). Youths withsiblings working are more likely to be working themselves, suggestingthe importance of family connections for information or tole models. sSimilarly, in the increasing concern with civil rights andaffirmative action there may have been greater pressure for equal wagetreatment, leading employers to make more of their adjustment toincreased supply by decreased hiring of blacks. Freemen ;1985) rejectsthis hypothesis, arguing that affirmative action increases relativeemployment of blacks by punishing discrimination in employment as wellas in wage setting. 76 64 Youths from female-headed families tr families on welfare have slightlylower probabilities of being employed.A somewhat surprising ani potentially important finding in severalstudies (e.g., Meyer and Wise, 1982; Stevenson, 1980) is that there isa strong relationship between hours worked while in high school andlater employment and wage rates. Whether the relationship is reallycausal or simply correlative (i.e., due to a common underlying factorsuch as motivation) remains unclear. Obviously, for those interestedin the potential benefits from employment and training programs forin-school youths, this finding is intriguing.A final finding that has drawn the attention of many analysts isthat the long-term (i.e., 4-5 years later) effects of unemploymentduring younger years appear to be rather less than had been previouslysuggested.Once individual characteristics have been controlled for,the experience of early unemployment does not appear to raise theprobability of unemployment in the following 4-5 years.This resultappeals to hold for both young men and young women (Ellwood, 1982;Corcoran, 1982). In addition, once individual characteristics are heldconstant, initial wage levels seem to have little relationship to wagelevels 4-5 years later. These relatively encouraging findings abouttheeffects of early unemployment and wages are, however,counterbalanced by another finding: early unemployment experience doesseem to affect wage levels 4-5 years later, and this effect appears tobe stronger and more substantial for youths with lower levels ofeducation. Social Context We conclude by noting a final factor that may stron.y influencethe employment experiences of young minority youths: ti ! socialcontext that has formed their perceptions and responses. We havechosen to discuss this issue of social context in the final part ofthis section because it affects both the supply and the demand forlabor and because the effects may be strong. The residue of past andcurrent discrimination finds its expression on the demand aide indiminished opportunities for minority youths in the labor market(because of the attitudes of employers); and, to the extent that thesocial context affects the perceptions, attitudes, and responses ofyouths, it can have a quite fundamental impact un the supply of labor.The long history of the exclusion of blacks from social andeconomic power, government, and prestigious occupations affects youthsin many ways.As Ogbu (1985a, 1985b) has observed in his study ofminority youths in Stockton, California, there is a racial or castelikestratification between blacks and whites that historically foundexpression in such things as job ceilings for black workers. A pilotproject by Culp and Dunson (1983) finds evidence of such stratificationin the treatment of matched young black and white \"auditors\" whoapplied for jobs at fiiats in the Newark, New Jersey, area.Theauditors were recent high school graduates who were trained to makesystematic observations of their treatment. Although the study was77 65 only a pilot project and the samples were too small for statisticaltesting, the results suggested that black youths may be treated W.thless courtesy and may be less likely to be informed of job prospects(Culp and Dunson, 1983). Other independent anthropological studies(e.g., found evidence of negative stereotyping oflow-income blacks.The collective adaptation of black youths to this and other featuresof a stratification system may be a source of the disproportionaterates of black school failure and unemployment. In the fixe of bleakfuture prospects, diligence in school may not appear to be adaptive tosocial reality, but rather may be seen as \"doing the white man's thing\"(Ogbu 1985a; Anderson, in this volume; and Foster, stratification of minorities has effects beyond thoseof youths' perceptions. The historic exclusion of minorities from someoccupations deprives them of the chance to learn the requirements ofsuch employment and to undertake the necessary preparation. Minoritychildren will be limited in their opportunity to observe role modelspursuing such occupations, and parent:, having been excluded by pastdiscrimination, will often be unable to guide and advise their childrenon the preparations required for such occupations. This may result ina dearth of knowledge on the part of the child and entirely inappro-priate preparation for desired \"mainstream\" occupations. In one sttdy(Ogbu, 1985a), it was reported that black high school students desiringto become doctors, engineers, and teachers were as likely to cxce she)))courses as those desiring office ;ork. Similarly, minority youths whoaspired to be engineers took no more mathematics courses in high schoolthan youths wishing to become physical education teachers. What suchfindings make clear is not only that children did not learn about therequirements of those occupations in their home environment, but alsothat the schools did little, if anything, to convey crucial information.Anderson (in this volume) emphasizes the increasing significance ofclass factors in determining the social context in which black andother minority inner-city youths are raised. The substantial increasein the size of the black middle and upper classes in recent years hasresulted in greater residential dispersion of higher-income blackswithin the metropolitan area: black inner-city communities haveexperienced a loss of leadership and important role models that hascontributed to the problems faced by th'4 remaining youths. DEVELOPMENTS SINCE 1980As the Youth Employment and Demonstration Projects Act (YEDPA)programs ended in 1981, the U.S. economy had begun its descent into theworst recession since the 19302. The economy bottomed out at the endof 1982 with overall unemployment at a post-World War II high of 10.8percent.The unemployment rate of youths aged 16-19 was more thandouble that at 24.5 percent.The greater sensitivity of youth employment to the business cyclenoted previously can be seen for this period as well in the data onemployment-to-population rates given in Table 2.10. In 1978 the 78 66TABLE 2.10Employment-to-Population Rates for TotalCivilian Population and for All Civilian (1985:Table B-12). employment-to-population rates for all civilian workers (column 1) was59.3, while the employment-to-population rate for youths aged 16-19 was48.3 (column 2); hence, the youth rate was 81.4 percent of that for allworkers (column 3). By 1982 the employment-to-population rate for allworkers had fallen sharply, to 57.8, but the rate for youths had falleneven more precipitously, to 41.5, so that the youth rate was only 71.8percent of the rate for all workers. It is also of some interest tonote that in 1982 the employment-to-population rate for all workers wasat about the same level as in 1977 (57.8 and 57.9), but the youth ratewas considerably lower in 1982 than in 1977 (41.5 compared with 46.1).For black youths the employment situation in 1982 was disastrous:their employment-to-population rate was only 19.0 percent.The economic recovery began in 1983 and continued through 1984. Onthe upswing youth employment again showed greater sensitivity so thatby 1984 the youth employment-to-population rate had recovered more thanthat for all workers: it was 73.4 percent of the rate for all workers(:ompared with 71.8 percent at the bottom of the recession in 1982).However, if one compares the situation in 1984 with that in 1978, it isclear that, despite the recovery, the youth employment-to-populationsituatE has deteriorated both absolutely--from 48.3 in 1978 to 43.7in 1984--and relative to the rest of the labor force--from 81.4 percentof the rate for all workers in 1978 to 73.4 percent in 1984.If one looks back to Tables 2.2a and 2.2b, it is apparent that theemployment-to-population rate for nonwhite males (both those aged 16-19and 20-24) is not only worse in 1984 than it was in 1978 but has furtherdeteriorated relative to white male youths, while the employment-to-population rates of nonwhite females remain the lowest of the youthgroups.These very summary data indicate both that, as would be expected,the recession hurt youth employment seriously and also that even withthe economic recovery youth employment problems remain very serious. 79 67 Compared either with 1977, just before YEDPA started, or 1978, thefirst year of the program, the youth employment problem in 1984 was asbad, or worse.Even more disturbing, the employment situation of blackyouths, particularly males, has worsened even more relative to whiteyouths, apparently continuing the long-term trend observed up to 1978.While our committee has not tried to assess systematically theeconomic outlook for the future and its implications for youth employ-ment problems, we do wish tc comment on one feature that has sometimesbeen pointed to as a possibly important sensitive development, namely,the decline in the absolute size of the youth cohort. In the previoussection, it was noted that one of the possible causes of youth employ-ment problems was the massive, unprecedented rise in the size of theyouth cohort, both absolutely and relative to the adult worker popula- tion (shown in Figure 2.1). Over the 15 years from 1980, when the sizeof the youth population reached its absolute peak, to 1995, the youthcohort will decline from 21 million to about 17 million. It has beensuggested that this decline will significantly improve the employmentsituation for youths.We have two observations to make about this suggestion. First,while there are some indications that the youth demographic bulge mayhave contributed to youth employment problems, the evidence is by no means overwhelming. If it is hard to find the effects of this dramaticbulge in relative supply on youth employment problems, it seems unwiseto count on the decline in relative supply of youths to have over-whelming effects in reducing youth employment problems over the nextdecade.Second, by 1985 two-thirds of the total projected decline inthe size of the youth population will have occurred. The figures justreviewed above give no indication that this relative supply effect iscurrently having a substantial impact on youth employment problems. Ifreductions in relative supply of youths have been having some positiveeffect, they have not been substantial enough to overcome othernegative factors. POSTSCRIPTWhen focus:mg on the youth unemployment problem, there is atendency to lose sight of the fact that the majority of teenagers findjobs relatively easily and that, when they leave or lose one job, theyoften find another without a long period of unemployment. As Freeman and Wise (1982) observe: \"constant references to the youth employmentproblem, as if all the majority of young persons had troubleobtaining jobs, appear to misinterpret Lhe nature of the difficulty.Youth joblessness is in fact concentrated among a small group who lackwork for extended perAs of time.\"The vexing problem about the \"youth unemployment problem\" is thatfor some groups of youths--disproportionately black youths--finding anyjob, remaining employed, and finding a new job when necessary is amajor and continuing difficulty. Throughout this chapter, it hasbecome apparent that blacks suffer inordinately from unemployment. Butwhile table after table has shown a widening gap between white and 80 68 black unemployment, inactivity, etc., it is not only the blackpopulation among whom unemployment is concentrated. In 1978 Hispanicsexperienced long-term unemployment at 1.3 times the rate of thepopulation as whole, children from poverty families at 1.6 times thenational rate, and those living in inner cities at 1.4 times thenational rate (Congressional Budget Office, 1982).It was against this background that Congress enacted YEDPA in1977.This act instructed the Secretary of Labor to establish avariety of employment and training programs to explore the methods ofdealing with the structural unemployment problems of the Nation'syouth.\"In the following chapters we review the implementation andeffects of ttese programs. In Chapter 3 we describe the YEDPA programsand their implementation. In Chapters 4 through 9 (and relatedappendixes), we review the effectiveness of those programs and thescientific adequacy of the research which was conducted to evaluatethem. 81 3Implementation of theYouth Employment andDemonstration Projects Act In July and August of 1977, under strong political pressure,Congress passed and President Carter signed tne Youth Employment andDemonstration Projects Act (YEDPA). The law (P.L. 95-93), initiated byCongress, substantially increased authorizations for two existing youthemployment programs that were part of the Comprehensive Employment andTraining Act (CETA), the Job Corps and the Summer Youth EmploymentProgram (SYEP), and created four new programs, the Youth CommunityConservation and Improvement Projects (YCCIP), the Youth Employment andTraining Program (YETP), the Young Adult Conservation Corps (YACC), andthe Youth Incentive Entitlement Pilot Projects (YIEPP), a nationaldemonstration program designed to encourage diopoutz, to return andpotential dropouts to remain in school using guaranteed work as anincentive.The broad purpose of the legislation as a whole was to provideemployment, training, and demonstration programs aimed at the struc-tural unemployment problems of youths. The more apecific purpose ofthe demonstration programs was \"to test the relative efficacy ofdifferent ways of dealing with these problems in different localcontexts.\"This charge was backed by substantial discretionaryauthority and mosey, granted to the Secretary of Labor and delegated tothe Office of Youth Programs, to conduct research, demonstration, andevaluation activities. In addition to substantial funds for YIEPP,both YCCIP and YETP included discretionary funds for demonstrationprograms.This demonstration purpose, however, was not to preclude theprovision of employment and training programs aimed at the immediateemployment needs of youths.Under YEDPA annual outlays for youth programs were double what theyhad been in previous years. In fiscal 1977, the year before YEDPAbegan operations, federal outlays for youth employment programs totaled$955 million and served 1.2 million youths.' Beginning in 1978 These were programs serving youths only. Additional expenditures of$827 million served another 0.8 million youths in adult programs underthe Omprehensive Employment and Training Act; these programs continuedding the YEDPA years. 6982 70annual outlays for youth programs averaged $2 billion and served anaverage of 1.5 million youths per year Oyer the next 4 fiscal years,from 1978 through 1981, YMPA outlays .:8 billion and served 6.1million youths. Although .arge -pa efforts, on total $8 billion, $628 million was spPnt for discretionaryand demonstration projects, including both the operation cf the youthprogtiros which accounted for most of the expenditures) and theaccompanying research and evaluation activities. This outlay is one ofthe largest short-term investments in social research and demonstrationever undertaken by the federal government. The scale \"Ind complexity ofits research activities, imposed on a massive service delivery system,created competing functions ti:at had major consequences for both theresearch effort and program operations. The 7:eJlearch orogram, designedto provide a \"knowledge base for improving ?view c. rograku chs'ter provicles a context for interpreting the results ofYEDPA programs a.d research in terms of the conditions under which theact was legislated and implemented. This context is considered in foursections:the legislative background of the act; the national imple-mentation of YEDPA programs; the local implementation of YEDPA programsand research activities; and the implementation rf .he knowledgedevelopment research effort. This chapter relies heavily on thebackground paper by Richard Elmore, \"Knowledge Development under theYouth i'mployment and Demonstration Projects Act\" (in this volume). LEGISLATIVE BACKGROUNL 1F YEDPA Shortly after the inauguration of President Jimmy Carter in 1977,at the 'nstigation of several senior Senators of both parties, dis-cussions were held with new administration appointees regarding a newyouth employment bill, several proposals for which had been circulatingin the Senate.With the cooperat_on of presidential appointees in theDepartment of Labor, a joint Senate-administracin proposal was draftedand introduced. The proposed lecIrlati:1 contained several keyelements, representing the inter a of its various Sena eponsr:s:afocus on school dropouts and thus: at risk of dropping out of school.;improved cooperation between schools and the employment and trainingsystem; and job training and work opportunities that would prep)youths for work in the real world\" and provide them access to jobs.Despite 4ts involvement in the youth employment the Carteradministration's read domestic. priority at that time was elsewhere, oncontrolling inflation \"rd r'sing unemployment. To deal with thelatter, the $20 er.argency economic stimulus package that thePresio:14t introduced immediately after his inauguration created $8billion in additiona. public service jobs as part of the CETA prJgram.One result of this approach was to increase the emphasis in theEmployment and Training Administration (ETA) of the Departmen.: of Laboron public empl'..yment. The burden of this massive public jobs programat the local level and the pu is image it created of CETA were to83 71become issues it both the local operation of YEDPA and its reauthoriza- tion as a part of CETA.With its attention elsewhere and without a specific youth proposalof its own, the administration accepted the Senate version of the youthemployment 'ill. The joint Senate-administration proposal requestedauthorize._n for the establishment of three new youth programs, theYoung Adult Conservation Corps, the Youth Community ConservationImprovement Program, and the Youth Employment and Training Program; itprovided fur joint projects by schools and CETA prime sponsors; and itprovided for a large discretionary budget (50 percent of ?ETP), ae amechanism to adjust the formula-funded allocations to the needs ofvarious constituencies. The House of Representatives, having been leftout of the early negotiations, introduced the Senate-administrationbill and then immediately proceeded to write its own alternate youthproposal.Common to both Senate and House proposals was an initial A.-yearauthorilaesn.With the entire CETA legislation due to erpire in 1978,the plan was to integrate the youth programs into CETA in a 1978reauthorization bill. The HouLe proposal, like the Senate one, alsoincluded discretionary demonstration activity, but as a mechanism tolearn ',hat programs work best and to apply that knowledge in 1; 'er youth program legislation.The House hill's emphasis on research and demonstretioL was itshallmark, indicating uncertainty about what types of programs wouldmost effeczively address the problem; of youth unemployment and acommitment to research and experimentation as a basis for futurerrogrP planning. One of the purposes of the demonstration approachWOp tO dreven'. funds from being locked into certain programs thatresearch might suggest were not effective. \"pis approach was in markedcontrast to the Senate proposal, which would more f.rmly establish newyouth programs. Another key difference between the House and Senateproposals was the House's Youth Incentive Entitlement Pilot Project(YIEPP), a program designed to bring dropouts back into school and prevent others from dropping out by guaranteeing a job on the con-ditions of school and job performance.Despite a lack of clarity about the demonstration programs, theSenate conceded to the House's approach. The Confe !noe Report, whLchstated the terms of compromise between the House anu Senate versions ofthe bill, used the House language An stating that the purpose of thelaw was the \"establishment of pilot, demonstration and experimentalerograms to test the efficacy of different ways of dealing with theproblem of youth unemployment,\" however, the report also stipulatedthat the statement of purpose contain language \"specifying that avariety of employment and training programs, as well as demo_Jiationprograms, are authorized\" (U.S. Congress, 1977:35). Thus, Congressavoided conflict between the two fairly distinct approaches by adoptingboth, i.e., research and demonstration together with new and large-scale service programs.Several less-Itentious issues, representing the interests of both the Senate and t; muse, were addressed in the compromise bill:increased cooperation, through the YIEPP (entitlement 'rogram) and a CETA and educ tional systemsas means of addressing the dropout problem; involvement of labororganizations in youth programs, in particular in developing andrestructuring job classifications, as a means of preventing wage andjob displacement of adult workers by youth programs; involvement ofcommunity-based organizations (CB0s) and other local, skate, andnationally organized groups in the planning and delivery of YEDPAprograms, as a means of maintaining constituency support in the CETAsystem; and involvement of other federal agencies in the administrationof YEDPA programs as a means of coordinating diverse federal activitiesaround the youth employment issue.In its final form the YEDPA legislation was an assemblage of themany and somewhat divergent congressional interests from which itoriginated.It charged the Department of Labor with two functions: toconduct research and demonstration projects in coordination withdiverfederal, state, and local organizations, in order to find outwhat methods work best For youths; and, at the same time, to mountlarge-scale new programs to meet the immediate employment reeds ofyouths.YEDPA provided substantial resources and discret unaryauthority; specification of whom to serve, Imo' little guidance as tohow; and a one-year time limit. THE IMPLEMENTATION OF YEDPA NATIONALLYSeveral conditions that characterized the CETA system during theperiod of YEDPA implementation and early operations strained thecapability of the system nationally and locally to both administerregular CETA programs and mount the new YEDPA programs. These con-ditions also limited what could reasonably be expected from YEDPA'srather ambitious research and demonstration agenda.The passage of YEDPA in 1977 represented a reversal of the controlof employment and training programs granted to local prime sponsors 4years earlier. With the enactment of CETA in 1973, C mgress hadeffectively turned federal employment and training prrjrame over tolocal control by changing from categorical to block-grant funding.This grant of authority to stater and localities was reinforced inother federal programs as categorical programs were switched to blockgrants.The YEDPA legislation, with its increased program requirementsand target group specifications, challenged this (relatively new)control of local prime sponsors over which parts of the youthpopulation to serve and how. It also significantly increased theirworkload as new reporting requirements for these programs were imposedan a system geared to different requirements.In addition to the YEDPA mandate to serve specific target groups ofyouths, which many considered a recategorization of youth services,YEDPA required that prime sponsors also maintain se_vices to youthparticipants in regular CETA provrame At their previously establishedlevels.Many state and local administrators perceived this effectiveincrease in services to youths as disproportionate when other subgroupswere also in need of services. Although YEDPA substantially increasedRr 73resources at the local level, it also increased federal management,through program and reporting requirements, and reduced local flexibil-ity in determining the allocation of services to various target groups. The net effects at the local level were 1--ceased competition betweenYEDPA and regular CETA resources and a burdening of the system as ittried to manage two types of programs with different administr,cive andoperating requirements.At the same time that YEDPA was being implemented, CETA .ime spon- sors were facing another new demand. As noted above- the President'semergency economic stimulus package had substantially increasti CETA'sPublic Service Employment (PSE) Program, more than doubling the numberof public service jobs. Locally, the management demands of PSE competedwith YEDPA and regular CETA for limited staff time and resources.Nationally, PSE created an image of CETA as a public jobs program,dwarfing the less visible training programs, and subsequently, becauseof various repotts of fraud and abuse in the PSE program, damagedsupport for CETA in general.These conditions prevailed through the first year of YEDPAoperations and as the 1978 CETA reauthorization proceedings began in Congress.At the same time, the administration's focus on the PSEprogram and welfare reform had effectively pushed YEDPA into thebackground at the Department of Labor. It was not until late 1978,after the dem'ae of the Carter welfare reform proposal and the publicoutcries over misuse of PSE funds, that youth employment came into public focus.Then, with YEDPA alrea6y under way, the Presidentcreated the Vice President's Task Force on Youth Employment, giving theissue top domestic priority for the 1980 election. This dramatic shift in the administration's focus on youth employment was to have signifi-cant effects on the administration of YEDPA, particularly on theresearch and demonstration activities, which were expected to informthe Vice President's Task Force in its 1980 report to Congress. YEDPA Expenditures and Participation YEDPA mandated four new programs and e.cpansion of the two existingCETA youth programs, the Job Corps and Summer Youth Employment Program. In 1978, three of the four new programs, the Youth Employment andTraining Programs, the Youth Community Conservation and Improvement Frojects,t.ie Youth Incentive Entitlement Pilot Projects werereauthorized as n amendment to Title IV of CETA, along with the JobCorps and SYEP. Under the Office of Youth Programs, which had beencreated in the Employment and Training Administratioa to administeryouth programs, the Job Corps and SYEP were incorporated in the YEDPAeffort.The Young Adult Conservation Corps, which was reauthorizedunder Title VIII begpse it was not directed principally atdisadvantaged youths and because of its operation by other federalagencies, renained separate from the larger YEDPA effort.Each of these youth programs represented a di:ferent approach tothe problem of youth employment and included programs and servicesdesigned to meet the needs of the particular youth groups.Table 3.1 86 87TABLE 3.1Youth Program Adrini3tered Under Target Administration Youth 14-21, least 85 per- Classroom or on-the-job Three-fourths of funas administered onand Training cent economically training, work experience, formula basis to all CETA primeProyrams (YETP) disadvantaged, in-school and out-of-pre-employment skills,emphasis on including 22 percent earmarkedfor cooperative programs with localschool youths school to work educational agencies; about one-fifthof funds for discretionary researchand demonstrationYouth Community 16-21, unemployed, Supervised work in projects Three-fourths of funds administer, jnConservation and out-of-school serving community needs; formula-basis to all CETA primeImproverent disadvantaged youths emphasis on building trades sponsors, about one-fifth of funds forProjects (YCCIP) and conservation discretioh-ry research and demonstrationYouth Incentive 6-19, economically Demonstration of a 2-year A national experiment operated throughEntitlement disadvantaged in-school job guarantee designed to federally selected sites in 17 primePi2ot Projects(YIEPP)and dropout youths increase return, retention,and completion of highschool conditional onsatisfactory performance inschool and worksponsor locations Young Adult 16-23, out-of-school Work for up to 1 year on Operated by Departments of AgricultureConservation Corps(YACC) Job Corps Summer projects Residential p-ogram ofvocational skills training,remedial education, healthcare, counseling, and othersupport services Summer work experience inpublic or private nonprofitagencies with some educa-tional enrichmentand Interior in consultation withDepartment of Labor; 70 percent of fundsallocated to federal and 30 percentto state programs National program administered incooperation with Departments of Interiorand Agriculture, through contracts withstates, regional offices, and progrlm operatedby CETA sponsors 75TABLE 3.2YEDPA Expenditures and of Labor (1979,1980, 1981, 1982). describes the target group, program approach, and administration ofeach of these youth programs. Table 3.2 shows YEDPA expenditures andthe number of youths served from fiscal 1978 through the termination ofYEDPA in 1981.As shown in Table 3.2, outlays increased substantiallyevery year, peaking in 1980, while enrollments were steady until 1981when YEDPA programs were being terminate...By themselves, the YEDPA utlays and participant levels describe arise and fall in activity level as expected over the lifetime of aprogram.When measured against the CETA totals for tha same period,however, it is apparent that over ite lifetime YEDPA accounted for anincreasing share of employment and training activities. Table 3.3compares fc]eral outlays for all CETA titles with those for YEDPAduring the same years. As total CETA expenditures declined, YEDPAoutlays increased, from 16 percent of the total in 1978 to 30 percent TABLE 3.3YEDPA 1982). 89 76TABLE 3.4Comparison of Total :'nd 1980, 1981, 1982). in 1981.Similarly, YEDPA participants accounted for an increasingshare of program participants, from 37 percent in 1978 to 48 percent in1981.When the number of youths served in adalt-oriented CETA programsis added to the totals for the youth-only programs (the four YEDPAprograms, Joh Corps, and the Summer Youth Employment Program), thepercentage of employment and training slots allocated to youths becomeseven larger.Table 3.4 compares the total number of participants(rdults and youths) in all titles with the total number of youths inall titles.During the YEDPA period, the number of youths as apercentage of total participants increased from 51 percent in 1978 to69 percent in 1981; the majority of these youths, 60-70 percent, wereer.rolled in YEDPA programs.Tables 3.5 and 3.6 show expenditure and participant levels,respectively, for each of the six youth programs for fiscal 1978through fiscal 1981. In the four new YEDPA programs, outlays almostdoubled from 1978 to 1979 and peaked in 1979 and 1980. Participationin the same programs increased moro gradually, but also peaked in 1979and 1980, except for YACC, whict, had increased participation -,rough1981 (even though it had been scheduled in 1980 for a 1982 tE ninationdue to problems in impineentation and placement). Increased outlaysfor the Job Corps under YzvpA were aimed at doubling the enrollment byfiscal 1978 to 88,000. his objective was achieved in fiscal 1979,with continued expansion of services through 1981. The summer program,which had served 1 million youths in fiscal 1977 with additionaleconomic stimulus package funds, reached ita all-time peak of more than1 million in 1978. In the same year, educational enrichment of thesummer program began, funded with discretionary money and governorsgrants. 90 77TLBLE 3.5Outlays for Federal 1981 at$167 million.bThe totals for YCCIP and YIEPP assume that $43 million of the $167million from 1981 went to YIEPP and the remaining $124 million to YCCIP.This assumption is based on separate budget sources stating that totaloutlays for YIEPP for all fiscal years were $240 million (Gueron, 1984).SOURCE:Data from U.S. Department of Labor (1979, 1980, 1981, 1982). Discretionary and Demonstration ProjectsThe Office of Youth Programs (OYP) emphasized research anddemonstration as an integral part of YEDPA program operations as ameans of exploring various program approaches and testing theirrelative effect!'eness. The amounts of money to be allocated to theentitlement demonstration and to other discretionary research anddemonstration activity was specified in rather complicated formulas inthe YEDPA legislation (Elmore, in this volume). Based on theseformulas the Office of Youth Programs structured its knowledgedevelopment plans. In fiscal 1978 and 1979, $437.3 million wasallocated to discretionary demonstration and research activities,$222.2 million to the entitlement project, and $215.1 million to otherdiscretionary projects (YETP, YCCIP, and SYEP) and research (U.S.Department of Labor, 1900a).Although the discretionary projects emphasize-i research andevaluation, according to OYP most of the discretionary money was spentfor the direct provision of programs and services to youths (U.S.Department of Labor, 1980a). In 1979 and 1980, 78 percent of thediscretionary money was for programs and services; 6 percent was fortechnical assistance and linkages to support those programs; 1 percentwas cnr the evaluation of regular youth programs (i.e., Job Corps andSYEA7 percent was for the evaluation of the demonstration projects;and 7 percent was for basic research on youth employment problems,. 91 78TABLE 3.6 Participation in Federal Youth Employment Programs(in thousands) FiscalYearYETPYCCIPYIEPPaYACCJob CorpsSYEP 1978359.228.736.851.972.01,009.31979413.638.553.467.285.0888.01980463.043.050.066.51C3.8825.01981393.7bb68.0114.4774.0 Total1,629.5125.6c163.0c253.6375.23,496.: NOT...earticipation is defined as the total nur_er served in each fiscalyear, not new enrollees served; figures include participants carried overfrom the previous year.aA total of 76,000 youths were served in YIEPP between March 1978 andAugust 1980.Figures shown above include carry-overs.bParticipation for YCCIP and YIEPP was reported jointly for 1981 at38,400.cTotals for YCCIP and YIEPP assume that 23,000 of the 38,400participants enrolled in 1981 were enrolled in YIEPP, and the remaining15,400 in YCCIP. The 23,000 figure is based on GLeron (1, 4). SOURCE:Data from U.S. Department of Labor (1979, 1980, 1981, 1982). A 1985 accounting of actual expenditures for YEDPA activitiesindicates that the total for discretionary program operations andresearch was $628 million. Table 3.7 shows these expenditures byfiscal year.Overall, nearly 15 percent ($92.2 million) was forresearch activities, and 85 percent was for program operations(including technical assistance); these proportions are the same asthose reported by OYP in 1980.In 1978, when the majority of discretionary projects wereinitiated, more than 60 major demonstrations were funded in about 300sites.The continued funding of these same projects accounted for themajority of discretionary activity through the next 3 years. YIEPPalone accounted for $240 million of the $628 million in discretionaryand demonstration expenditures. In fiscal 1978 and 1979 the plannedbudget for YETP demonstrations totaled $135 million. The major YETPdemonstration projects included an exemplary in-school youthdemonstration, several career exploraltion and development projects, twoplanned variations of program approaches and ;service mixes, two majorprivate sector project , and a community service project as analternative to regular work experience. The YCCIP budget plan fordemons - rations during the same period totaled $47 million. Majorprojects included three conservation and community improvement projectsoperated through various local community organizations, two housingprojects, and four projects focused on improvements in railroads, dams, 92 79 TABLE 3.7YEDPA Expenditures for DiscretionaryP.ogram Operations and Research by Fiscal Year SOURCE:Data provided by the Office of InformationResources Management, Employment and TrainiloAdministration, U.S. Department of Labor, April 1985. and agriculture. Discretionary funds were also used for the SYEPenrichment projects. In 1978 and 1979 planned budgets for thesetotaled $34 million and supported career orientation and educationalactivities for summer youths.2Of the 60 major demonstrations initiated in 1978 and 1979, 22 wereoperated through agreements with six other federal agencies: ACTION,the Community Services Agency, the National Institute of Education, andthe Jepartments of Energy; Health, Education, and Welfare (now Healthand Human Services); and Housing and Urban Development. Budgets forthese projects totaled $48.8 million (see !able 3.8). The majorinteragency agreement in terms of total budget was YACC, operatedjointly by the Departments of Interior and Agriculture and totaling$820 million.Becausi, of its operational independence from the 2The figures presented here are based on the planned expenditures forlse activities as described in the youth knowledge developmentr..xt, Knowledge Development Activities for Fiscal Years 1978 and 1979(U.S. Department of Labor, 1980). With the exception of YIEPP andtotal fiscal year expenditures as presented in Table 3.7, a preciseaccounting of actual expenditures for individual discretionary projectsis not available. 93 TABLE 3.8Knowledge Development Activities With Other Organizations OrganizationAmounta andYear Committed Tasks Interagency AgreementsACTION Community ServicesAdministration (CSA) Health, Education, andWelfare (FW) Housing and UrbanDevelopment$8,000,000(1979)1,311,402(1979)1,298,704(1979)4,C00,000(1978-1979)1,200,000b(1978)400,000b(1979)1,500,000(1979)1,051,000(1979) 4,777,700(1978)317,792(1979)1,000,000(1979) 632,600(1979) 359,025(1979)8,000,000(1978) 9,234,089(1978)4,479,000(1979)Test feasibility of national youth service--communityinternships; one projectTest feasibility of transferring urban communityservice project to rural setting; one projectTest feasibility of one-on-one volunteers in assistingyouths to find employment; 14 projects\"'est feasibility of youth employment in rural housingprograms; in collaboration lith Department ofAgriculture; 13 sitesTest feasibility and effectiveness of, year-roundprogram for out-of-school youths Lacommunity development projects; 3 projectsTest feasibility of incorporating youth employment andtraining into HEN-run Runaway Youth Centers; 11 projectsEstablish, support, and test effectiveness projects tolink post-secondary educational institutions to CETAagencies; 20 projects; administered by Fund for theImprovement of Post-Secondary EducationTest feasibility of replicating and evaluate effectivenessof Career Intern Program in Opportunities Industrializa-tion Center sites; 4 sites; a4Ilinistered byNational Institute of Education feasibility ef.ectiveness of ocationaleducation linked to summer work; 6 projects;administered by Bureau of Occupationaland Adult EducationPart-time work for 1,000 Upward Bound participants;9 projects; administered by Bureau of Higherand Continuing EducationTeat feasibility and effectiveness of summer programof education and work experience in energy fieldImplement and evaluate youth employment inpublic housing projects as a means of crimereductionTest feasibility of youth employment in communitydevelopment projects as a means of improvinglocal communities94 IntermediariesManpower DemonstrationResearch results; 17 sites Develop, test, and document programs for private sectoremploymentReplicate community home repair program;assess its effectiveness Identify exemplary creation ofyouth-run enterprises; design demonstrationprojects; assess effectiveness; 7 projects Expand National Longitudinal Survey (NLS) Expand Continuous Longitudinal ManpowerSurvey to assess impact of YCCIP and YETPon youthsProcess evaluation of local implementation ofYEDPA; contracted to National Council onEmployment PolicyBasic research on youth employment; contractedto the University of California, Los Angeles,National Bureau of Economic Research,and various other, organizations 250,000 Technical assistance in research(1978) design to exemplary projects;775,651 processes for retrieval, dissemination,(1979) and utilization of findings 95 TABLE 3.8 (continued) Amounta andOrganization Year Committed Tasks Educational Testing 3,500,000Service (1978-1981) National Council onEmployment Policy Constituency SupportU.S. Conference of MayorsCreation of a uniform national data b- .e toassess YEDPA demonstration projects;responsible for design of standat sizedassessment instruments, overseeingdata collection, data processing andanalyses, and finalevaluation reports on the effective*, of26 YEDPA projects76,294 Review and analysis of selected(1978) program activities, including state -of- the -art review of programs ofdisadvantaged youths and assessment ofwork-education councils 168,100 Identify exemplary programs; provide(1978) technical (1979)Recruitment National Forum, National Women, NationalCouncil of La RazeIdentify exemplary programs; providetechnical assistance to prime sponsors Identify model programsDemonstration projects onparticipation of community-basedorganizations in school-work linkages aThese figures for fiscal 1978 and 1979 represent the total amount budgeted for each program, includingprogram operations and services, as well as the amount paid that organization for its role in projectoperations.bAlso see CYE below. SOURCES:Elmore (in this volume, Table 7); U.S. Department of Labor (1980b).96 83 Department of Labor, however, YACC was not counted in the discretionaryresearch and demonstration effort of the Office of Youth Programs.In addition to agreements with other federal agencies, OYP turnedto institutions outside the government for assistance in managing thedemonstration projects and the accompanying research and evaluationefforts.Four intermediary organizations, private nonprofit corpora-tions, were contracted to design, implement, and evaluate various typesof demonstration projects. Three of these hitermediaries were createdexpressly for this purpose, one to manage private-sector programs,another for youth enterprise projects, and the third for in-schoolyouth programs. Together these three managed $42.7 million indiscretionary funds (see Table 3.8). The fourth intermediary, ManpowerDemonstration Research Corporation (MDRC), an 'stablished corporationwith previous experience in demonstration efforts, managed the YIEPP. LOCAL IMPLEMENTATION OF YEDPA YEDPA discretionary activities, both the programs and theiraccompanying research, were planned and managed by the Office of YouthPrograms and implemented through the local CETA prime sponsor network.The knowledge development agenda (described in t'le next section) wassupposed to provide the structure for a cooroinated, coherent plan ofprogram and research activities. OYP's plan was to distribute thefunds and implement the programs through the CETA system and then tomanage and shape that system through research and evaluation. Thus, itwas at the local level that the duality of YEDPA program operations andresearch had to be combined successfully to meet YEDPA's goals.The first section of this chapter noted the constraints of thisdual operations and research endeavor, exaceibated by the demands ofregular CETA operations and the increased Public Service Employmentprogram.This section describes in more detail the effects of thisduality at the local level and the costs it may have imposed in termsof the ultimate effectiveness of YEDPA programs.The local implementation of YEDPA programs discussed in terms offive bastasks:(1) planning and assembling programs; (2) targeting,recrui,g, and enrolling participants; (3) s affing and organizingprogram activities; (4) assessing participant needs and matching themto program services; and (5) monitoring quality of programs andservices.This discussion is based on reports on the implementation ofseveral demonstration projects, case studies of implementation offormula-funded YEDPA programs, and reports on program impact thathighlighted implementation issues. Although some of the projectsdiscussed here also appear in the reviews of program effectiveness,many, due to the nature of the implementation problems, were excludedfrom those reviews (see Appendix B for the list of reports included inthe implementation and effectiveness reviews). Since these data werenot systematically collected, we do not know how representative theyare of YEDPA programs and demonstration activities. Hence, thisdiscussion is presented here as an indication of the general nature and 9 7' 84range of the problems encountered in implementing YEDPA at the locallevel. Task 1:Planning and Assembling ProgramsYEDPA, with a 1-year authorization, congressionally mandated programfeatures, and significant increases in level of program funding, putinordinate pressure on the planning and implementation of programs atthe local level. The process of designing and communicating theregulations and budgets from Washington to the local level was slow anduncertain; the information needed for planning was often late gettingto prime sponsors and shortened the time available for planning andassembling programs.Uncertainties in regulations and budgets were common Some YEDPAinnovations depended on the waiver of established CETA regulations.The placement of youths in work positions in private for-profit firms,for instance, was prohibited by CETA regulation, but encouraged underYEDPA.To waive this regulation, however, each prime sponsor had toapply for permission to the national office. The approval processcomplicated local planning and discouraged some prime sponsors from theuse of this option.Even after the first year, budget delays and uncertaintiesthreatened program operations with the end of almost every federalfiscal year.For example, the Employment and Training Administration'sannouncement at the end of fiscal 1979 that no funds could be expendedin the new fiscal year pending congressional authorizations createdhavoc with local prime sponsors, who ware forced to negotiate interimcontracts, budget extensions, and make-shift arrangements with theirlocal program operators to prevent program termination.YEDPA broadened the base of local organizations involved in planningand operating youth programs with its requirements to involve community-based organizations, the schools, unions, and private employers. Togain cooperation and there/ ease implementation and operation, programoperators tried to involve all of the major parties in the planningstage.It was assumed that such involvement in planning would expandPnd ease the flow of resources throughout the local service system.Planning by consensus, however, complicates the decision-making processand can undermine efforts to change the direction or nature of theservice delivery system; yet such change may be desired when theexisting system does not address important aspects of the problem. Inthe Career Intern Program, for instance, a program fraught with seriousimplementation problems, there were seven parties to each programdecision:the Department of Labor, the National Institute of Education,the national and local offices of the Opportunities IndustrializationCenter (OIC), the school system, the prime sponsor, and the programevaluator.The involvement of the school systems in planning and operatingyouth programs was considered an important link in local youth networks.The YEDPA legislation mandated that 22 percent of YETP funds, thelargest formula-funded program, be spent in negotiated agreements with 98 85the schools.The entitlement program (YIEPP) also required closerelations with the schools since satisfactory school attendance andperformance was a condition of the job guarantee. In addition, severaldemonstration projects required agreements with schools in runningalternative education and school-to-work transition projects. And, ofcourse, schools were also an imdortant source for the recruitment ofeligible in-school youths for various programs.The results of experien 4th schools confirm in general thestatus quo thesis suggested :although the 22 percent mandate didencourage the schools to coll. .,rate with CETA, it did not changeeither the nature of the services provided by the educational system orhe youths whom it served. The schools, although they did provideaccess to certain youth groups, maintained their focus on in-schoolyouths and provided essentially the same set of educational services asusual.The lack of influence of YEDPA (or CETA) on schools may beattributed largely to the schools' resistance to allocating servicesaccording to income and to a basic difference in their perception oftheir mission and constituency. In addition, schools, although theybenefit from CETA funds, are not dependent on them for their existenceand therefore are not as willing as other organizations to adapt toCETA's short-term and unsteady funding cycles.Results of collaboration with CBOs, also mandated by YEDPA, weresimilar to those with schools. Although the CEOs were more dependenton these funds than schools and therefore more amenable to YEDPA'sapproach, it was difficult to effect changes in their approach and inthe target groups traditionally served by some CBOs, each of which hadits own constituency. Moreover, because of their dependence on unsteadyfunding sources, many CBOs had difficulty in recruiting and retainingqualified staff.The involvement of unions and private employers in planning andprogram a-sembly was limited. The requirement that unions review primesponsor plans assured compliance with the Davis-Bacon Act and ensuredthat union jobs would not be undercut by YEDPA subsidies to youths.Some agreements were negotiated for union involvement in work-train zigdemonstration projects. Although private employers were not activelyinvolved in program planning, they did participate in some work experi-ence projects, notably the entitlement program and the Public VersusPrivate Sector Jobs Demonstration. The effect of union and privatebusiness participation in program operations is discussed in Task 3.In general, a tradeoff was made at the planning and assembly stage( which continued throughout operation of the programs): a tradeoffbetween smoothness of implementation and changing the direction ofservices and opportunities. What was done most often was to expand theexisting set of opportunities by involving the major participants inthe community service network. This strategy avoidef the pitfalls ofbypassing existing organizations and creating resistance that couldstall implementation, but at the cost of reform or change in the typeof opportunities available.Case study reports of the implementation of formula-funJed programs(YETP, YCCIP, and SYEP) (National Council on Employment Policy, 1980a,1980b, 1980c, 1980d) and of the entitlement program provide rore detail 93 86on the effects of these conditions on YEDPA planning and programassembly in terms of the planning of program services, the selection ofprogram operators, the assessment of participant needs, the hiring andtraining of staff, the creation of reporting and information systems,and, not least of all, the ability or willingness of the prime sponsorsto cooperate with any additional research requirements of the knowledgedevelopment plan. Task 2:Targeting, Recruiting, and Enrolling Participants The target group for YEDPA programs was defined broadly as eco-nomically disadvantaged youths. For each part of YEDPA, the definitionwas more specific in terms of age, employment and school status, andthe Bureau of Labor Statistics' living standard (see Table 3.1). Insome parts, the entitlement program (YIEPP), for example, eligibilitycriteria were stricter than in other parts or titles. Within thelegislated target group definitions, local prime sponsors were a3ked toidentify \"significant segments\" of particularly disadvantaged youthsfor more emphasis.Two factors constrained the targeting and recruiting of youths forYEDPA programs. First, because of the short planning period for YEDPA,many prime sponsors based their target-group designations (i.e., sizeand characteristics of population) on information that was out ofdate.In addition, to ensure adequate funding in the event of a greatdemand for the program, some prime sponsors tended to overestimateenrollments.The result was that actual enrollments were often lessthan planned enrollments.Second, because of YEDPA's maintenance-of-effort requirement (thatregular services to youths in other titles not be curtailed because ofthe availability of YEDPA funds), many prime sponsors reported diffi-culty in recruiting the required numbers of youths for some YEDPAdemonstration projects (e.g., the Career Intern Program, the MixedIncome Experiment, the Bureau of Apprenticeship Training Project,Opportunities to Learn and Earn, and Job Factory). This problem wassometimes most pronounced in programs targeted to the nost disadvan-taged.These factors, together with a perceived disc-epancy betweenthe demands of the labor market and the characteristics of the youthsserved, gave rise to a tradeoff between serving those most in need in atarget group (i.e., the most disadvantaged of in-school or out-of-school youths) and serving those whom it was thought could get thegreatest benefit from the program (usually the least disadvantaged).The involvement of private employers in youth programs was anadditional impetus for many program operators to select the relativelyless disadvantaged because they were thought to be more capable andattractive to employers. This practice of \"creaming\" raises questionsof equity and efficiency !f one assumes that many of these relativelyless disadvantaged youths would have obtained jobs without t3e aid ofthe programs. 100 87The Role of Schools The recruitment of in-school youths, particularly when recruitingor program operations involved the cooperation of the school system,was especially subject `- creaming. Some school officials reportedlyviewed program participation as a reward for the most promising among11w-income youths. The identification of a particularly importantin-school group--those \"at risk\" of dropping out of school--forinstance, was subject tc wide interpretation. Case studies indicatethat although a few schools turned to school records as a means ofidentifying potential dropouts, many schools identified such youthsthrough lass objective means. Depending on how youths \"at risk\" wereidentified, the target groups served in different areas may have been Mte different from each other.The recruitment of school dropouts, as distinct from those at riskof dropping out, presented even more of a problem for local programoperators.Moss. schools, because they were not actively involved withdropouts, found it difficult to recruit them, and, if they recruitedthem, found it difficult to adjust their programs to accommodate them.The entitlement program, for example, which was designed to servedropouts willing to return to school as well as in-school youths, endedup serving primarily in-school youths thought to be at risk of droppingout.The difficulty the entitlement program encountered in keepingreturned dropouts in school, even with a job guarantee, suggests thegreat difficulty of providing educational services for this group. Itis not clear from the available reports whether schools resistedtargeting and service to dropouts simply because they saw their missionand constituency as different from CETA's or because the requirementsof recruiting and serving such youths were too burdensome.The patterns of participation of in-school compared with out-of-school youths were also a function of the type of program offered.YETP, although targeted to both in-school and out-of-school youths,enrolled primarily in-school youths, and as suggested above, notnecessarily the most disadvantaged youths. On the other hand, YCCIPwhich was targeted to out-of-school, unemployed youths, enrolledprimarily high school dropouts who were more economically disadvantagedthan YETP participants. The image of YCCIP as an unadorned workexperience program of low-skill level may account for this. It is alsointeresting that despite the traditionally male jobs developed in YCCIP(e.g., weatherization, maintenance, rehabilitation, and landscaping),25 percent of the participants were female. The Role of Other Agencies The high participation rates of in-school youths in YEDPA programsin part reflects the chronic problem of recruiting out-of-schoolyouths, particularly dropouts. Many prime sponsors have relied onemployment security offices and certain CBOs to recruit dropouts for 101 88youth programs. Even these agencies, however, have had difficulties inrecruiting dropouts; and even when they have been successful in recruit-ment, they have had difficulties in actually enrolling and then servingdropouts.Many CBOs, by tradition. have p.ovided specialized services(e.g., skills training, career exploration, and basic education) forcertain target groups (e.g., women, refugees, and ethnic minorities)and were used in reaching those target populations. Like the schools,however, the goals of the CBOs at times diverged from those of theYEDPA programs. causing similar implemen`ation problems. The CBO-runCareer Intern Program, for instance, found few dropouts willing toparticipate in their alternative education program; many youthsindicating their preference for a faster Graduate Equivalency Diploma(GED) program.The involvement of other federal agencies in youth employment, asmandated by YEDPA, did not occur at the local level to the same degreethat collaboration with schools and CBOs did. With the exception ofdemonstration projects funded under interagency agreements, about whichlittle is known due to lack of evaluations of program impact, therewere only scattered examples of efforts to involve other units of localgovernment (e.g., welfare and juvenile service agencies) in youthprograms.The role of another part of the Department of Labor, the EmploymentService, for instance, was limited. With the exception of ProjectSTEADY, which was designed and operated by the Employment Service toprovide assessment services to youths, the local offices did littlemore than refer job seekers to CETA programs and verify the eligibilityof CETA applicants. The Employment Service has traditionally beenviewed as a means of recruiting out-of-school youths, but its role oroverall effectiveness in providing this service for YEDPA is not known.The repeated failures of programs to ;:each the dropout populationexplains the general tenden:y of programs designed to serve dropouts toredirect their efforts to more easily recruited in-school youthsidentified as potential dropouts. Although this approach may preventsome youths from dropping out, it does not address the needs of thosewho already have. The emphasis on in-school youths also fits thehistorical trend of employment and training programs to serve this morereachable target group and to orient 4.ts programs to them. The Economic and Racial Isolation of Youth Employment ProgramsAnother problem faced by prime sponsors in the recruitment of YEDPAparticipants was the strict income eligibility requirement and theimage it created of YEDPA as a poverty program, and by association inmany urban areas, a black program. One consequence, particularly inareas where school integration had created friction, was the difficultyof recruiting white youths.The participation patterns in the entitlement program illustrate 102 89 the influence of several other factors on program participation andreinforce the findings of other YEDPA programs that participation ishigher among in-school than out-of-school youths and higher amongblacks and Hispanics than among whites. These patterns appear to beinfluenced by the job and program alternatives available to thoseyouths, the amount and type of recruitment, and the image of theprograms in those communities.The higher participation of blacks than Hispanics in part reflectsthe alternatives available to these two groups in their local com-munities.In the entitlement program areas, eligible Hispanics hadhigher employment rates and lower school enrollment rates than didblacks; in-school blacks, who had fewer employment opportunities,tended to enroll in the entitlement program, while out-of-schoolHispanics had more alternatives for employment outside the program.The low participation of white youths, and the difficulty of someprograms in recruiting them, is a function of the coincidence of rai.eand eligibility criteria. The fact that the entitlement program hadstricter income eligibility requirements (i.e., generally requiredlower family income) than other YEDPA prcgrams resulted in a largeconcentration of minorities in the eligible population. In addition,in those sites where the entire city was not the focus of theentitlement program, existing residential segregation combined with therequirement of residency in the entitlement area to increase theminority racial and ethnic character of the eligible pool.Thus, even if the programs were as attractive to white as to blackor Hispanic youth:\" $he latter groups would have represented asubstantial share of participants in many areas and a majority in some(e.g., Baltimore and Detroit). These situations were exacerbated bythe image of these programs as black poverty programs. Attempts totest the effects on these programs of economic isolation by mixingparticipants of various income levels, es in the Mixed IncomeDemonstration, were frustrated by difficulties in recruiting sufficientnumbers of nondisadvantaged youths.In summary, several general points emerge from the evidence ontargeting and recruitment. First, the criterion of economic disad-vantage is increasingly difficult to implement at the increasinglydisadvantaged levels. Second, many of these programs tend to recruitand enroll more in-school than out-of-school, particularly dropout,youths, partly because dropouts are outside the established educationand social service network and therefore are difficult to reach, andpartly because many youth program operators have historically gearedtheir services to in-school youths and resist adjusting to other,.oups.Those programs that did enroll large numbers of dropoutsgenerally experienced higher turnover of participants and underspenttheir funds, indicating that a workable approach to serving the dropoutpopulation had not been found. Third, it appears that targetingprograms to economically disadvantaged youths tends to isolate thoseprograms socially, racially, and economically, perhaps limiting theireffectiveness. 103 90 Task 3:Staffing and Organizing Program Activities StaffingThe quality and stability of program staff are important factors inthe operation of youth programs. Numerous program evaluations citestaff characteristics as contributing to program success and programfailure.Although quantitative data are not abundant, conventionalwisdom and the observations of program personnel and evaluators alikesuggest the important role played by the staff in programs in whichpersonal motivation and morale are critical to participants' success.The summer program is an example of improvement in program quality whenthe quality of the work-site supervision is enhanced.The staffing of youth programs has been constrained by the instabil-ity of funding and the isolation of the programs from mainstream socialinstitutions.Staff positions in employment and training programs havecharacteristically been low paying and offer limited opportunity foradvancement.Given such conditions, it has been difficult to recruitand retain quality staff. These characteristics, plus the limitedduration of many youth projects, have created high turnover in bothprime sponsor and program operator staff, which in turn create aprogram environment of discontinuity and impermanence. Several casestudies cite staff turnover in excess of 50 percent and others note thecomplete turnover of top administrative staff (Taggart, 1980). Program Activities The formula-funded programs operated under YEDPA, YETP, and YCCIPwere organized and implemented much as they nad been under regular CETAyouth programs. The time pressure under which programs were startedand the YEDPA requirement that funds be given to programs with\"demonstrated effectiveness\" reinforced prime sponsors' reliance onestablished programs and providers, a reliance that case study reportssuggest was warranted (National Council on Employment Policy, 1980b,1980c).Other, more basic problems with these program operations,however, included the restriction of work activities imposed by theDavis-Bacon Act. This law, written to prevent the displacement ofunionized workers by nonunion workers, requires that constructionworkers employed under federally funded projects be paid union wagerates even if they are not union members. Tnis provision effectivelylimited the activities allowed in work programs, sometimes adverselyaffecting their quality.Restrictions on the allowable use of employment and training fundscreated another limitation. YCCIP projects, for instance, were suppo_edto employ youths in community improvement and conservation projects,but there were no funds for supplies or equipment so programs had toobtain supplemental funds from other lrcal sources. Placement of youthsin private businesses was not to involve any work that would contributeto the profit of the firm, which made it difficult to provide youthswith meaningful work. The requirement that YACC projects not contribute 104 91to tasks that the federal agency would have done at its own expensemeant that those tasks were, like the tasks in private businesses, oflow priority.These requirements presente.' r:hallenges that were met with varying degrees of success.Some of the demonstration projects provide examples of the effectsof restrictions on program operations. In one YCCIP demonstrationproject, Ventures in Community Improvement (VICI), funds for suppliesand equipment were obtained from local sources, with such success thatfive of the eight VICI sites continued operations with local support after YEDPA funds were gone. A study of the involvement of privatebusiness in the entitlement program (YIEPP) found that the higher thequality of work, the higher the :Iisplacement of nonsubsidized workers,suggesting the inconsistency between the provision that jobs not bemake-work and the Davis-Bacon no-displacement requirement.The involvement of private businesses in youth programs met withmixed success.The entitlement program (YIEPP) recruited nearly 6,000businesses as work sponsors, representing 55 percent of all work spon-sors (public and private) participating and 20 percent of youth jobhours.However, even when offered a full subsidy at the minimum wageand relieved of overhead costs, only 18 percent of the employers sampled in a survey of private businesses (Ball et al., 1981) would agree to accept an entitlement program youth. At a 75 percent wagesubsidy, the agree-to-participate rate dropped to 10 percent, and at a50 percent subsidy it cropped to 5 percent. On the whole, however, theemployers in the entitlement program reported satisfaction with theyouths placed with them, and one in five hired that person after thesubsidy ended. The Corporate Career Demonstration Project, on theother hand, which was to train youths in corporate careers throughplacement in entry-level positions in participating businesses, couldnot recruit youths of the appropriate skill level for the program.Theprivate employers were unwilling to participate when the participants' lack of basic skills became apparent. Task 4:Assessing Participant Needsand Matching Them to Program ServicesThere are two basic ways of assessing needs and prescribingservices for youths: according to their membership in broadly definedgroups or as particular individuals. The first method considers suchcharacteristics as age, school status, or family status (e.g.,motherhood).These categories may then be connected to broadcategories of program components suited in'general to members of thegroup--providing skills training, for example, to groups of olderyouths, with or without particular services, such as child care.Distinctions among these groups of people can be made on the basis ofobjective characteristics and appropriate assignment can be maderoutinely.This was perhaps the predominant method of assessing needs in YEDPA, particularly in the formula-funded programs.The secondmethod, based on individual needs, considers such issues as educationaldeficiencies, career aptitudes and interests, and social, family, or 105 92legal problems. Obviously, mechanisms to assess such individual needsrequire more resources.Because of planning and funding schedules in CETA, target-groupneeds were assessed prior to recruitment and enrollment of participants.Individual needs assessment, when available, was provided after enroll-ment and usually by a smaller program operator subcontracted for thisservice.There is little evidence ..hat prime sponsors designed servicesto meet the individually assessed needs of participants, probablybecause initial funding decisions tended to lock in specific servicesprior to such assessments. It was possible, however, to use individualneeds assessments to assign participants to available program andservice options.Under YEDPA the assessment of individual participant needs wasgenerally restricted to demonstration programs, there being littleprovision for such services in formula-funded programs. Some of theProject STEADY sites, Project Redirection, and the Consolidated YouthEmployment Demonstration Project are examples of YEDPA demonstrationprojects that offered such services. In these cases the individualassessments took the form of \"employability development plans\" andprescriptions for various programs and support services tailored to theindividual.One source reports that in the Consolidated YouthEmployment Project the more complete assessment practices did notaffect how services were provided or who was given what services (Hahnand Lerman, 1983).There is a general lack of evidence as to the effectiveness ofindividual needs assessment in terms of participant outcomes. Forin-school youths, individual needs are probably most closely related totheir educational situation and best handled by the schools themselves.Attempts at assessing individual career interests of in-school youthsfor the purpose of placement in work experience, for instance, isprobably premature for this age group (Osterman, 1980b), and it iscostly to operate beyond a limited scale.For out-of-school youths, however, individual assessments of educa-tional and employment reeds appear to be more important and potentiallyhave more payoff. With the exception of the Job Corps, however, therewere no major efforts under YEDPA to provide such individual services.YCCIP, for instance, which served largely out-of-school youths, was anunadorned work program with no provision for such extra services. Task 5:Monitoring Quality of Programs and ServicesThe Department of Labor continually exhorted prime sponsors to beattentive to the quality of programs, in particular as indicated byproject size and number of supervisors. Case study reports of theformula-funded programs (National Council on Employment Policy, 1980b,1980c) suggest that the overall quality of work experience under YEDPAwas better than it had been in earlier youth programs. Evaluations ofthe entitlement program also indicated that the quality of work experi-ences in the opinion of evaluators, supervisors, and participants wasgenerally good. 106 93 This general improvement in work quality during YEDPA in comparisonwith earlier CETA programs was due largely to a 1979 report (U.S.General. Accounting Office, 1979) on the summer youth program and theextensive monitoring of programs that followed. The report citednumerous problems in the summer program, notably the poor quality ofsupervision, the meaningless make-work jobs to which the youths wereassigned, and the failure of work site supervisors to require attendance as a condition of payment. The public outcries caused by this reportprompted the creation of an extensive monitoring system involvingnational and regional offices, prime sponsors and program operators,and the establishment of standards for work site supervision, qualityof work assignment, and time and attendance procedures.The sustained pressure from the national office on local programsto establiea and enforce standards of quality in program operations andthe capacity for self-evaluation that it created were importantcontributions to the youth employment and training system. YEDPA RESEARCH: THE YOUTH KNOWLEDGE DEVELOPMENT PLANThe YEDPA research agenda, known as the youth knowledge developmentplan, was designed and administered by the national Office of YouthPrograms and implemented through agreements with local CETA primesponsors and contracts with various public and private research agentsand \"intermediaries.\" This effort consisted of various demonstrationprojects and of research and evaluation studies of them and of someformula-funded programs.Two major factors constrained the design and conduct of YEDPAresearch activities: first, the competing demand, both nationally andlocally, to mount four new youth programs, at roughly double the levelof previous funding, within the extremely short time limits imposed bythe initial 1-year congressional authorization; and then, second, thedemands of the Vice President's Task Force on Youth Employment for theresults of the YEDPA research. This section describes how, operatingunder these constraints, OYP first designed the knowledge development plan and then implemented it. Design of the PlanThe YEDPA legislation provided tip! Department of Labor and its newOffice of Youth Programs with a mandate to test the relative efficacyof different methods of dealing with the employment problems of youngAmericans.The legislative concern with learning what works for whomwas consistent with the frequently stated contention that decades offederal funding for similar programs had not yielded much in the way ofreliable knowledge. The YEDPA research plan was designed as a sys-tematic exploration and assessment of alternatives for meeting the goal of knowledge development.The 1978 Employment and Training Report of the Preside,': (U.S.Department of Labor, 1978:77) noted that despite \"numerous public 94policy initiatives\" over the decade from 1963 to 1973, youth unemploy-ment remained at the sme high levels that had led t, the creation ofprograms for youths in the early 1960s. Among the factors cited aspossible explanations was that \"tbe rapid expansion of programinitiatives hampered program planning, smooth implementation, andthorough evaluation.* The commentary on the research conducted priorto YEDPA was quite specific in its catalog of shortcomings (U.S.Department of Labor, 1978:79): Researchers are not unanimous in their conclusions about theeffectiveness of employment and training programs because manyevaluations have been imperfectly designed, lacked sufficientfollowup data, or were unsuccessful in isolating programeffects from other factors. The failure to find a suitablymatched control group, whose earnings and job success could becompared with those of enrollees . .. flawed at least onemajor cost-benefit study.A major review (Perry et al., 1975) of 252 evaluations of employ-ment and training programs conducted ander the Manpower Development andTraining Act of 1962 and the Economic Opportunity Act of 1964 indicatedthat the problems associated with evaluation research were not uniqueto youth programs. This review found that the majority of employmentevaluation studies were little more than descriptive analyses ofprogram operations and of the characteristics of enrollees, with littlepostprogram follow-up data. Moreover, fewer than 1 in 10 of theevaluation reports used a control group and \"in alm.st every case inwhich a cortrol group was used there were valid reasons to question thecomparability of the controls and the treatment groin)* (Perry et al.,1975:139).These authors concluded that although tiv:re were a largenumber of evaluations of government employment programs in the 1960sand early 1970s, \"few [were] very useful as a reliable base ofinformation from which to draw firm conclusions regarding [their]economic impact. ...\"(p. 138).Familiar with these shortcomings, the designers of the first OYPknowledge development plan identified the potential snares and basiclimitations of the plan's efforts (U.S. Department of Labor, 1980c:5-7): First, new programs take time to jell. ..What initialstudies can do is identify who is enrolled, the services theyreceive, the immediate outcome on termination, and the\"correctable\" operational problems. ...They can indicatethe practicality of some designs. [But] they cannotdetermine long-run impacts. Second efforts to trackpostprogram effects on participants require considerable time....Particularly for youth, the concern is with evenlonger-run impacts. It takes from five t) ten years for the\"Lasting\" effects to surface, as youths mature into adultworkers.Third, estimation of the impacts on participantsrequires a comparison group to indicate what would havehappened otherwise. ...Development and tracking of a 108 95comparison group is technically difficult, costly, and oftenhas not yielded reliable results. ...Fourth, cost-benefitanalyses to determine if benefits of programs expressed inmonetary terms exceed the costs, are attractive in principlebut difficult in practice.This premonition of the snares awaiting such research enterprises was,as the following chaptern document, fully borne out.YEDPA's initial research plan was based on eight questions, posedby OYP in response to the structur' of the YEDPA legis;.tion and itsfunding formula (U.S. Department o, Labor, 1980c):Does subsidized employment help youths complete theirschooling cu,d does increased schooling increase the employability ofpotential dropouts and the disadvantaged?Can the school-to-work transition process be irproved?What work experiences are iorthwhile and meaningful for youths?Does structured, disciplined work experience have a differentimpact on the employment prospects of youths than other types ofemployment services?Are there better ways of delivering employment and trainingservices to youths than those now in use?To what extent do short-term interventions yield longer termresults (e.g., on employment in adulthood)?What works best for whom?What are the costs of fully employing youths?Though revised and expanded over time (see Elmore, in this volume)these eight questions, vague and imprecise as they are, remained as theessential issues of the YEDPA research effort. A later plan describeshow specific demonstration projects were designed in response to thesebasic questions, but it provides no overall framework specifyingresearch design, methodology, standards, or pracedures for drawingtogether the rather disparate pieces of resea-nh to address the majorresearch issues. The YEDPA research strategy was criticized from thebeginning as overly complex and ambitious; over time, rather thanevolving toward a clarification of major problems and solutions, itbecame even more complex, with changing program designs, researchissues and methods, and expectations of results.The knowledge development plan was based on a developmentalmanagement view of research and evaluation--as a tool for institutingnew programs and then ahaping and monitoring them as they developed.Early studies were to focus primarily on process and project imple-mentation data. As weaknesses in program design or procedu_es werediscovered, adaptations were to be made to improve the programs. Asprograms evolved, their objectives, expected outcomes, and evaluationswere to be changed. This developmental approach to research andprogram operations, although it complicated the research agvada andtended to make interpretation of results more difficult, ser%ad animportant management function for OYP as it undertook the admiristra-tion of the enormous youth employment program. Unfortunately, in many 109 96projects the formative evaluation process was not completed beforeYEDPA was terminated. Implementation of the PlanOne of the major problems in implementing the knowledge developmentplan was the sheer magnitude of tie effort in relation to the size ofthe OYP staff.The demands of mounting expanded and new serviceprograms for youths along with the design and implementation of acomplex research program necessitated a tradeoff between carefulresearch design an4 rapid project implementation to maximize economicimpact.This pressure was intensified by the expectation that someresults would be available in time for the CETA reauthorizationproceedings in late 1978. The subsequent and equally unrealisticexpectation of more detailed research results by the fall of 1979 toinform the Vice President's Task Force on Youth Employment served tomaintain the time pressure throughout the course of YEDPA operations.The feasibility of the research effort was perhaps doubtful fromthe outset even under the most generous assumptions of staff time andcapability:however, the OYP staf.: was small in relation to the sizeof the effort and also for the most part inexperienced in research andresearch management. These constraints, together with the legislativecharge to involve other federal agencies and community-based organiza-tions in YEDPA programs, led OYP to delegate the management of largepieces of YEDPA activity to organizations outside the Department ofLabor.This strategy of indirect management involved five different typesof negotiated agreements: with \"irtermediaries,\" other federalagencies, other parts of the Department of Labor, other organizationsfor staff support, and other organizations for constituency support.In addition to increasing OYP's staff capability in administeringYEDPA, these arrangements were designed to expand the institutionalcapacity of the youth employment system for future programs.Thebnckground and functions of each of these organizational arrangementsare described in elP in Elmore (in this volume) and summarizedherein.Table 3.\" 7.4.ts data on the program budgets and tasksadministered thr .:h arrangement.The intermediary agreements with four private nonprofit corpora-tions were negotiated for the design, management, and evaluation ofv-lious demonstration projects. The agreement with the ManpowerDJmonstration Researt'h Corporation, a previously established firm, tomanageentitlement demonstration program, served as the model.Three oner intermediaries were created to manage the private sectoryouth employment demonstrations, the exedtplary programs to link schooland work, and, through an interagency agreement with the CommunityServices Agency (CSA), demonstrations of youth-run chterprises.Interagency agreements were negotiated with several federal agenciesto meet congressional expectations of broader government involvement insolving youth employment problems. Projects funded through ACTION;CSA; and the Departments of Housing and Urban Development; Health, 110 97Education, and Welfare; Agriculture; Energy; and Interior were designedto meet youth employment objectives through means compatible with eachagency.Intraagency projects managed by the Office of the AssistantSecretary for Policy, Evaluation, and Research (ASPER) and by theOffice of Policy Evaluation and Research (OPER) brought the expertiseof established Department of Labor research units into the YEDPA effortand incorporated a YEDPA sample into the established ContinuousLongitudinal Manpower Survey and a youth sample into the NationalLongitudinal Survey (see Chapter 9 and Appendix D).External staff support was provided primarily through the BrandeisUniversity Center for Employment and Income Studies (CEIS), which wasresponsible for the analysis, dissemination, and policy utilization ofthe research findings. (CEIS subsequently became part of the uni-versity's Center for Human Resources.) In responding to its firstcharge, CEIS criticized the knowledge development plan for its complex-ity and lack of coherent framework, criticisms that the results ofYEDPA research suggest were warranted, but which unfortunately wereunheeded,Their role in the retrieval, synthesis, and dissemination ofYEDPA research was more effectively executed and became critical in theclosing days of YEDPA when OYP was disbanded before the research wascomplete.Another important external support function was to have beenprovided by the Educational Testing Service, for the design andanalysis of a national YEDPA data base. The data were generated byapplication oo: the Standard Assessment System, a battery of instrumentsadministered to participants and program operators to measure theeffectiveness of YEDPA across sites and programs (see Chapter 9 andAppendix A).Results of many of the youth projects funded through agreementswith outside agencies are unknown. Only two of the four intermediariesproduced reports on program effectiveness that this committee could usein its review.The vast majority of projects funded under interagencyagreements were not evaluated. The intraagency projects, particularlythose that supported national data bases, were among the most successfulof the knowledge development activities in terms of theft methodologicalrigor.Overall, this management structure, although effective in quicklyinitiating programs and research activfties on a large scale, was toodecentralized to manage the direction of the programs effectively or toanalyze the research activities in a coherent way. Given the level ofresponsibility and authority delegated to the various parties, it isnot surprising that they became almost immune to centralized control oftheir operations. And, given the overload at the center, it is notsurprising that OYP could not maintain control in response to problemsarising in various parts of the structure. Toward the end of YEDPA,but primer to the completion of many projects and their research reports,the central control literally fell apart, first with the resignation ofthe dityctor of OYP and later with the disbanding of OYP under the newReagan administration. It was at that point, with many project reports 111 98 outstanding, that CEIS assumed its critical role in retrieving,synthesizing, and disseminating the research. SUMMARYThe conditions under which YEDPA was implemented, in terms of itslegislative mandates, its time schedules, and the program and policyenvironment in which it operated, were significant in determining thecourse of YEDPA programs and the outcomes of its research. From itslegislative beginnings, YEDPA was constrained by two competing demands:to mount four new, Large-scale jobs programs and, at the p.ne time andthrough the same delivery system, to design and conduct a comprehensiveresearch and demonstration eff,-t aimed at ameliorating the structuralemployment problems of youths.The imposition of the research and demonstration activities on thealrea'y burdened service delivery system taxed the resources availablefor both the national management and local operation of YEDPA. Theadditional pressure to launch these programs and obtain researchresults within 1 and 2 T4ars, respectively, of the passage of YEDPAfurther increased the pressures of implementation. The severeconsequences of all of these conditions for YEDPA program operationsand research, though not quanti.Uable, were readily apparent in thenumerous reports reviewed by this committee in its task of assessingprogram effectiveness. The conditions characterizing the implementa-tion of YEDPA from its start in 1977 through its abrupt halt in 1981were described here to provide readers with a context for betterunderstanding the results of our review of the effect ;:gness of theYEDPA programs, which we present in the chapters that follow. 112 4Procedures Used in Evaluatingthe Effectiveness of YEDPA Programs An explicit purpose of YEPDA was the establishment of a variety ofprograms to explore alternative means of dealing with yoth employmentproblems.Implicit in the legislation was the concept that programs beevaluated to determine their relative effectiveness or \"what works bestfor whom.\"To date, the only effort to provide a systeme-Ac evaluation of theproducts of the YEDPA research effort is that conducted by Hahn andLerman (1983) of Brandeis University. Their assessment yielded whatare described as \"representative\" findings from the YEDPA evaluations,based on a review of the significant findings, where significance wasdefined \"in terms of the reliability of the research reviewed and theimportance of the policies addressed by the findings\" (Hahn and Lerman,1983:4).The results of the Brandeis evaluation focused attention onthe studies undertaken under YEDPA and led, at least indirectly, tothis committee's creation. SOURCES OF DATA AND CRITERIA USED IN SELECTING REPORTSThe major source of information that the committee used forassessing the effectiveness of the YEDPA programs was the research andevaluation reports commissioned by the Office of Youth Programs (OYP)as part of its discretionary knowledge development effort. A collectionof over 400 reports, compiled by the Employment and Training Administra-tion (ETA), had been forwarded to ua for review. We also searched theavailable literature beyond the reports generated as part of the YEDPAprocess (see, for example, the discussion of national data bases inChapter 9) and consulted people who had experience with youth programsand related research. Even so, with the exception of studies of tworegular CETA programs (the Job Corps and the Summer Youth EmploymentProvam) and Supported Work, programs that predated YEDPA, we reliedalmost exclusively on the reports of particular youth demonstrationprojects carried out under YEDPA to assess the effectiveness of youthprograms.We first screened the documents obtained for review to identifyreports meeting two criteria: (1) that the report be on a youthemployment program that had actually been implemented and was in 99113 100operation during the YEDPA period (roughly 1977 to 1981) and (2) thatthe report contain quantitative data on the effectiveness of that pro-gram, be it at any stage from implementation to program completion orfollow-up.As a result of this screening, we eliminated about 170repo i:ma further consideration. These were reports on subjects notspecifically related to any implemented programs, for example, tech-nical assistance guides, conference proceedings, and program plans anddescriptions of a general nature. Some of these reports met the firstcondition, that is they reported on youth programs actually implemented,but were not evaluations of program effectiveness. Some others pur-ported to be effectiveness evaluations, but were so lacking in data onprogram outcomes that they could not be evaluated by the committee.About 200 reports on youth projects met the initial screeningcriteria.For each project the reports variously described programimplementation, in-program effects, and outcome evaluations. Theseproject reports were then classified according to program type and thetarget group(s) served (the classification framework is described laterin this chapter). The most comprehensive renort on each project wasthen subjected to a second screening to identify reports of sufficientscientific merit to be reviewed in more depth by the committee as thebasis for judging the effectiveness of YEDPA programs.Reports were screened using the following criteria: 1.that there be preprogram ana postprogram measurement of majorprogram objectives;2.that comparable comparison group data be presented; and3.that initial sample sizes and response rates for participantand control groups be of sufficient size, preprogram and postprogram,to allow usual standards of statistical significance to be applied tomeasured program effects, and to alleviate concern for attrition bias.Subcommittees defined by the four major program types reviewed indepth the project reports that met the three criteria and assessedtheir effectiveness. Reports of interest for the information theyproviCeJ on program implementation, whether or not they met theeffec...veneds criteria, were included in the implementation reviewreported in Chapter 2. A list of all reports considered by thecommittee for the effectiveness and implementation reviews appears inAppendix B. COMPARISON OF PROJECTS REVIEWEDAND PROJECTS EXCLUDED FROM REVIEWThe projects included in the effectiveness review were select\u00b0d onthe basis of the scientific merit of their research reports. Theprojects that form the basis of this review, therefore, may notnecessarily be .epresentative of 111 of the various youth employmentprojects operated under YEDPA, either discretionary or formula funded.Table 4.1 shows the major YEDPA discretionary demonstrationprojects by subpart and funding )evel and the disposition of reports on 114 TABLE 4.1Disposition of Reports on Major Discretionary Projects, by YEDPA Subpart and Funding Level,Fiscal 1978 and 1979 Project DispositionNo Report Excluded ExcludedYLLPA Subpart': Total Available at 0.4 NOTE:Includeu as major projects are those funded at a minimum ofreports were not available, two excluded at initial screening, and$200,000.Excludedone excluded afterfrom thisrevic4.table ...re nine$100,000projects,sixfor which aSubpart titles are Youth Incentive Entitlement Pilot Projects (YIEPP), Youth Employment and Training Program (YETP), Youth Community Conservationnd Improvement Project (YCCIP), and Summer Youth Employment Program (SYEP).b Interagency agreements were signed with Action, Community Aervices Administration (CSA), the nepartment of Health, Education, and Welfare (HEW),the Department of Housing and Urban Development (HUD), and the Department of Energy. SOURCE:U.S. Department of Labor (1980). 115 116 102 their effectiveness in our review process. The 61 projects shown(column 1) are those funded in fiscal 1978 and 1979 at amounts of$200,000 Ci above, and they include all of tie major demonstrationprojects operated under YEDPA through fiscal 1981. Of these 61projects, 17 (column 2) could not be reviewed for their effectivenessbecause reports on their program impacts either were not commissionedOr not produced. Nlne of the 17 projects were operated under inter-agency agreement and accounted for $34.5 million in funding. Twocommunity conservation projects (operated by the Department of Housingand Urban Development) alone accounted for $21.7 million in funding.The committee screened reports on all 44 projects for which reportswere available (columns 3, 4, and 5). Of these projects, eight wereexcluded at the initial screening stage due to lack of effectivenessdata (column 3). Two of these projects alone accounted for $30 millionin funding; both were man-led and .aluate thest demonstrations.Of the remaining 36 ajects (columns 4 and 5) 20 upon furtherreview did not meet estaulished criteria for comparison groups (pre-program to nostprogram), sample coverage, and attrition, and they wereexcluded from further consideration (column 4). Five of these projects,account ..ng for $15 million in fundi.j, were operated under interagencyagreements, including the Youth Community Services Demonstration andthe Career Intern Program. Also exclude& was the VocationalExploration Demonstration, a major project funded at $8.7 million.In addition to the projects shown in Table 4.1, we reviewed andexcluded five other demonstration projects not included in the1978-1979 funding. None of these represented a major budget amount.Our review indicated that reports on 16 projects (column 5, met theestablished criteria, and they were therefore included in our review ofYEDPA program effectiveness. These 16 projects represent about 63percent of YEDPA discretionary funding, including the entitlementprogram (YIEPP). The projects include YIEPP ($240.2 million), Vnturesin Community Improvement ($10.8 million), the Youth Career DevelopmentProject for School-t--Work Transition ($9.6 million), three SummerCareer Exploration Projects ($6.8 million), the Public Versus PrivateSector Jobs Demonstration ($7.6 million), and the Service Mix Alter-natives Demonstration ($5.3 million).In addition to the discretionary projects listed in this table, wealso included in our review the two largest regular CETA youth programs,the Job Corps and the Summer Youth Employment Program, as well as theyouth portion of the Supported Work demonstration project. Alsoincluded but not shown in this table were nine other discretionaryprojects not included in the 1978-1979 fundings. These additionalprojects bring the total number of projects included in our review to28, representing every subpart of YEDPA (with the exception of theYoung Adult Conservation Corps), including the Job Corps and the summeryouth program. 7 102ON3RALL FRAMEWORK FOR EVALUATION Our framework for evaluating the effectiveness of YEDPA programsdraws together three major dimensions. program goals, program types,and target groups. We organized our review primarily according toprogram type, noting, in addition, the target groups served andassessing the degree to which the programs affected each of the givenprogram goals (when measurements bearing on each were provided). There-fore, the discussion of program effectiveness appearing in Chapters 5through 8 is presented largely in terms of program types. In thesections that follow we discuss each of these dimensions briefly. Program GoalsThe YEDPA legislation states a variety of goals for youth programs(see Elmore in this volume). Goals or outcomes can be divided intointermediate goals and long-run or ultimate goals. The long-run goalsof different employment and training programs are generally similar;most, if not all, programs intend to effect longer-term improvement inparticipants' employment stability, earnings, family stability, and soforth.Intermediate program goals, such as ..ncreased educationalattainment, work experience, knowledge of and attitudes about theworkplace, and short-run increases in employment and earnings, varyacross programs.Long-run program goals are of ult'sate interest from both socialand policy perspectives. Intermediate goals, while not usually ends inthemselves, may serve as indicators of long-run outcomes to the extentthat they are expected to affect longer-term goals. Ultimately, whetherintermediate goals are reliable indicators of longer-range outcomes isan empirical question.' Program Types Under YEDPA an attempt was made to ensure that a wide array ofprogram types were tested, covering in one fasnion or another most ofthe concepts about appropriate program types that would emerge from asystematic analysis of goals (U.S. Department of Labor, 1980b). How-ever, even the documents describing the knowledge development effort donot provide a categorization of program types that lends itself readilyto a classification scheme useful for evaluating the effectiveness ofYEDPA programs. Others who have reviewed youth programs have used 'This formulation of program goals relies heavily on Barth (1972).As will be discussed in detail in subsequent chapters, YEDPAdiscretionary projects devoted substantial resources to the collectionof data on measures of intermediate goals, much of it (such as attitudemeasures) subjective in nature. 118 104TABLE 4.2Youth Program Classifications PIQ ServiceCategoriesaService Category ClassificationsCommittee placementpreparation program NOTE:This chart compares the program classifications used by Hahn and Lerman (1983)and the committee. The first column presents the In service activities from theProcess Information Questionnaires (PIQ) of the Standard Assessment System (SAS), andthe columns to the right indicate how Hahn and Lerman and CYEP classify each PIQservice category for assessment purposes. The CEO (1982) in its analysis of youthprograms classified program activities as demand side (i.e., to increase employmentdemand for the target group), supply side (i.e., to increase employability of youthsthrough training, education, and employment experience), or transition (i.e.,improving exchange of labor through job search and placement). aOther authors have used classifications based on amounts of time in various PIQcategories for analysis of youth programs (Cole et al., 1982; Fuller and Nelson,1982; Rock et al., 1982).b Not classified. different classifications from those used in the knowledge developmentdocuments (e.g., Hahn and Lerman, 1983; Rock et al., 1982; and Congres-sional Budget Office, 1982; see Table 4.2).None of the classifications of program types developed and utilizedby others seemed appropriate for our task. These classifications wereoften based on combinations of specific program activities and services 119 105(e.g., work experience, on-the-job training, classroom training, skillstraining, counseling, and participant assessment), on the one hand, andclient group characteristics, on the other. On examination, we foundthat most YEDPA programs provided combinations of services to a mix ofclient groups. Thus, reviews based on classifications with finebreakdowns of service type and client group were forced to discuss agiven program repeatedly under different classifications of services(e.g., Hahn and Lerman, 1983).In designing the classifications of programs for this review wesought to minimize complexity without obscuring essential differencesbetween programs. To this end, we chose four broad program typesdefined on the basis :A intermediate goals. Each program evaluationreport was placed in only one type, according to its intermediate goal: 1.Occupational skills training: to equip youths with specificoccupational skills and knowledge as a prerequisite either to furthertraining or job placement in that occupational field. (Examples includeboth on-the-job and classroom training in such fields as welding,drafting, carpentry, health, and computer occupations.)2.Labor market preparation: to improve attitudes, knowledge, andbasic skills as preparation for entering employment. This categoryencompasses such programs as career exploration and world-of-worxorientation and programs designed to enhance youths' general educationallevel and ski-ls, thereby improving their future career possibilities.(Examples of the latter are basic--remedial--education and GEDprograms.)3.Temporary jobs: to provide youths with employment and generalwork experience in temporary subsidized jobs, either full time or parttime.(Examples of such programs include work experience programs andthe Summer Youth Employmen Program.)4.Job placement: to place youths in unsubsidized jobs. Servicesprovided may include job search assistance, placement, and follow-upactivities. Target Groups At the outset, our evaluative framework cross-classified programsby the four broad program types just described and by the target groupsserved, as classified by school status and age. School status distingu-ished in-school youths from out-of-school youths, the latter beingfurther subdivided into those who had graduated from high school andthose who had dropped out. The age groups, defined to correspondroughly with grade level, were 14-15, 16-18, and 19-21. The racial,ethnic, and sex composition of program participants were also indicated.It was our hope that this specification of target groups, cross-classified with program typf;s, would allow us to address the questionof what works best for wi,cm.In practice, while we did take note of the details of participanttarget groups, we found it was not possible to carry out separateanalysis according to all of these target group categories. This was 120 106primarily due to the fact that most of the programs contained mixes ofparticipants from the different categories and few of the evaluationreports on which our assessments were based provided separate outcomeanalyses for different categories of participants conforming to ourdetailed classification. As a result, while our reviews of programeffectiveness provide as detailed information as the source materialallows, our summary conclusions distinguish only between in-school andout-of-school youths, cross-classified by program type. LIMITATIONS OF THIS REVIEWOur ability to draw firm conclusions about the effectiveness ofyouth employment and training programs was constrained by two conditionsthat affected the implementation of YEDPA and particularly the conductof research.First, YEDPA programs and research were mounted in con-siderable haste in a period in which many other employment and trainingand research efforts were ongoing, so that both program and researchresources were stretched very thin. Second, in 1981, less than 3 yearsafter their quick start-up and troubled implementation, many programsand evaluation efforts were abruptly halted with the change of adminis-tration.As a consequence of these factors, most of the data on which evalu-ations were based, with a few exceptions, were gathered at a stage atwhich programs had not yet become stabilized. As a further consequence,relatively few program evaluations provide data for long postprogramperiods; virtually all of the YEDPA project evaluations had postprogramfollow-ups of only 3 to 8 months. Only two evaluations had as much asa 3-year follow-..p, and both of those were of pre-YEDPA programs (theJob Corps and Supported Work).Further limiting our ability to draw firm conclusions were theserious problems many YEDPA researchers apparently had in creatingreasonable comparison groups and preventing sample attrition over waves of the data collection. These problems sharply reduced the number ofstudies that could be reviewed and put in question the reliability ofthe results of several others.A final limitation of this review concerns the very magnitude ofYEDPA and CETA programs from 1977 through 1981. It has been estimatedthat in 1978 as much as one-half of all jobs held by black teenagersduring the summer were in the summer program and as much as two-fifthsof jobs held in 1979 were in government employment and training programs(Crane and Ellwood, 1984; Elmore, in this volume). Thus, even whencomparison groups were reasonably created, there may well have beensubstantial amounts of employment and training among the comparisongroup members. To the degree this program participation is undetectedin the evaluation data. the participant-comparison contrasts willunderestimate the impact of these programs.We have attempted to test the individual YEDPA research reportsagainst reasonable standards of scientific quality with respect to boththe data collected and the methods used to measure program effects.The reports that met such standards were not necessarily evenly 121 107distributed over the range of operational youth programs or targetgroups being served. Thus, there are issues with respect to the roleand effectivenes3 of youth employment and training programs that wecould not address due to a dearth of reliable evidence. In addition,the quality of the available evidence varies, sometimes supportingstrong conclusions, sometimes merely suggesting the direction ofprogram effects.Our assessments of the effectiveness of youth programs derive fromexamining published evaluation reports on these efforts rather than ourown evaluation of the programs themselves. Since it is possible thatpoorly executed or poorly presented research reflects unfairly on theprograms being examined, it is important that we clearly distinguishbetween the quality of the research and the (possibly unobserved)quality of the programs.While we have attempted to avoid drawing inferences about programeffectiveness on the basis of research quality, and are fairly confidentthat we have been successful in doing so, we caution the reader to bearin mind that to make a determination of either effectiveness orineffectiveness requires credible evidence. Lack of evidence oneffectiveness is not synonymous with lack of effectiveness.In our evaluation of the effectiveness of youth employment andtraining programs, issues related to the adequacy of the evidence oftenovershadowed those related to the policy or practical significance ofthe magnitudes of reported effects. The question of the reliability ofestimated effects is logically prior to a consideration of their policyimportance.Consequently, when &esults fail the test of reliability(in an evaluative or statistical sense), further discussion of theirimplications for policy is rendered moot. Because many of C.:: reportswe reviewed did not provide reliable estimates of program effects, weoften could not address the issue of the policy significance of thefindings. 122 5Effectiveness of Occupational SkillsTraining Programs Skills training programs are generally designed to impart skillsrelevant to obtaining work in specific occupations. We found that fewyouth programs exclusively devoted to skills training were undertakenwith YEDPA discretionary funds. Moreover, there is a paucity of YEDPAevaluation reports on such programs relative to the number of reportson other types of program. We are left, in effect, with only twoprograms--the Job Corps (which was developed prior to YEDPA) and NewYouth Initiatives in Apprenticeship--that had substantial skillstraining components e d were sufficiently well evaluated and documentedto be subjects for our review. Yet each of these programs had specialfeatures that limit its applicability to broad segments of the youthpopula'ton:the Job Corps is a residential program for out-of-schoolyouths that includes much more than skills training; and the apprentice-ship program required a close .?lationship between employers and schoolprograms dealing -4th specialized skills. Table 5.1 presents the char-acteristics of these two programs; Table 5.2 summarizes the researchdesign and results of their evaluations.That few skills training programs were developed under YEDPA--whichis consistent with a frequently voiced criticism of all CETA programsoperating during the 1970s--apparently grew out of sevc-:al concerns ofprogram administrators. One concern was the belief that below a certainage young people tend to lack the seriousness to make good use of skillstraining because they have not committed themselves to a particularoccupational direction. Another concern is that participants require asufficiently high level of academic preparation to be able to partici-pate effectively in any but the most general training, and many programapplicants lack this level of preparation. In fact, as was noted inChapter 4 and is discussed in Chapters 7 and 8, some program effortsinitially designed to provide skills training were redesigned when itbecame clear that participants were primarily in need of more basiceducational skills training. 108123 4. TABLE 5.1Occupation-1 Skills Training Programs: Program Characteristics skillstraining; ofProgram Participation Sites x = 30 and Results Sample SizeCon' ,l/ComparisonYouth ProgramPar'icipantControlGroup methodology Program EffectsFollow-upResponse Rate 4-yearfollow-up)Matched comparison participationRedured seriousness ofcrime postprogramIncreased follow-up At time of interview40% of sample were only6 months out of highschool and only 14% were1-1/2 years out; Timingmay not have allowedadvantages 1977 dollars.126 BEST COPY AVAILABLE127 111PROGRAM FOR OUT-OF-SCHOOL YOUTHS Job Corps The Job Corps is in many respects unique. It is distinguished bythe population it serves, the comprehensive nature of the services itoffers, its stability as a program, and the quality of the evaluationthat is available on it. We note that these last two points areprobably not unrelated.The Job Corps is a largely residential program for out-of-school,economically disadvantaged youths between 14 and 21 years old. Itprovides a range of services including remedial (basic) education,vocational skills training, and health care to enrollees for about 30weeks (the average stay during the subject evaluation).The Job Corps serves a severely disadvantaged population: about 90percent of Job Corps enrollees were either from households below thepoverty line or receiving welfare benefits; more than 75 percent wereminorities, and 30 percent were female. Moreover, despite the factthat the median age of Job Corps enrollees was about 18, median readinglevels were at or below the sixth-grade level.The Job Corps has existed for 20 years; few programs have had suchstability.The program served about 102,000 youths in fiscal 1985 in41,000 slots; enrollees averag-d just under 5 months participation. Atthe time of the evaluation we reviewed, about 70,000 participants werebeing served per year.Although the Job Corps has been substantially modified since it wasfirst established in 1964, most evaluations of the program prior to the1982 study we reviewed were based on the experience of those who par-ticipated in the Job Corps during the mid-1960s. A series of surveysby Louis Harris and Associates served as the primary data source forresearchers attempting to estimate the impact of Job Corps. Theseearly studies had conflicting findings. For example, one study (Cain,1968) found that participants earned $188 to $260 per year more than\"no- shows\" (those who enrolled but never participated) 6 months post-program.Another study (Woltman and Walton, 1968) found no significantdifference between the earnings of Job Corps enrollees and earlyterminees (those who remained in the program less than 3 months) 18months after participation. Taken together, these early findingssuggested that Job Corps had a short-term impact that decayed (faded)fairly quickly (Goldstein, 1973).Our assessment of the Job Corps is based on an evaluation conductedby Mathematica Policy Research, Inc. (Haller et al., 1982). Thisevaluation was the most extensive and sophisticated of the studies ofthe Job Corps undertaken over the years. And, unlike most evaluationsof other youth employment programs that we reviewed, this study:was based on a large sample of program participants (2,800)and nonparticipants (1,000) who were similar in most respects to JobCorps participants. The nonparticipants were youths eligible for JobCorps who were residing in geographic areas where Job Corps enrollmentwas low. 128 112 gathered data on the participant and comparison groups for areasonably long time after the program so that it was possible toestablish the degree to which postprogram effects exist and persist ordecay.The third follow-up interview was conducted 42-54 months afterthe program period.had low rates of attrition in the follow-up samples ofparticipant and comparison group members. The third follow-up surveywas completed by 70 percent of those who completed the originalbaseline questionnaire (65 percent of participants and 75 percent ofcomparison group members).took measurements on a wide variety of factors that could beaffected by, or affect, the Job Corps experience, including educationalattainment, the value of economic production by Job Corps participants,receipt of welfare and other transfers, the extent of criminalactivity, unemployment rates, employment rates, hours worked, and wagerates.used a comparison group methodology in a way that was ascareful and technically sound as the state of the art permitted.The essential finding of the Mathematica evaluation is that the JobCorps \"works.\" In particular:On average, participants in the Job Corps were employed about3 weeks per year (13 percent) more than nonparticipants up to 3-1/2years postprogram, and their earnings gains after leaving the Job Corpswere estimated to be $567 per year higher in 1977 dollars (28 percent)for enrollees than they would have been in the absence of the Job Corpsexperience.The amount of time that Job Corps enrollees received cashwelfare or unemployment compensation benefits was lower by 2 weeks peryear and 1 week per year, respectively, compared with nonparticipants.Tate 5.3 presents evaluation results up to 4 years after Job Corpsparticipation.Participants' educational attainment increased substantiallywhile they were in the Job Corps: the probability that enrollees wouldreceive a high school diploma or its equivalent (General EquivalencyDiploma) within the first six months after leaving the Job Corps was.24 for enrollees compared with .05 for comparison group members.Overall, the health of Job Corps participants was better thanthat of nonparticipants after the program; participants reported about1 week less per year of serious health problems.Criminal activity, as indicated by rates of arrest, wassignificantly lower for participants during the period of the program,and after leaving the program participants had fewer arrests forserious rimes than nonparticipants.After an initial 6-month postprogram period, when enrolleesfared worse than the comparison group in terms of employment andearnings, the aggregate positive effects of Job Corps emerged andpersisted at a relatively stable rate throughout the 4-year follow-upperiod.This outcome suggests that the main effects of Job Corps donot stem from job placement. 129 113TABLE 5.3Estimated Job Corps Effects on Employment and Earnings,Including Military Sector: First Through Fourth Postprogram level or below in a two-tailed test.SOURCE:Data from Mailer et al. (1982:Tables IV.10 and IV.11). These overall effectiveness estimates included all participants,early leavers as well as those who followed the Job Corps course tocompletion.The study also provides estimates of differences in effectsaccording to categories of program completion. Program completerscomposed 40 percent of the sample, while partial completers and earlydropouts each accounted for 30 percent. Program completers benefitedmost.Partial program completers, those who stayed at least 90 daysand completed at least one specific segment of a vocational or educa-tional program but not an entire program, benefited about one-third asmuch as completers. Early .copouts were found to benefit little or notat all.The authors note, however, that econometric methods for con-trolling for bias in selection into the three completion categorieswould not prove effective.Program effects were estimated separately for males (representing70 percent of corps members and 70 percent of the follow-up sample),females without children (21 percent of the follow-up sample), andfemales with children present (9 percent of the follow-up sample).The estimated effects on employment and earnings are similar inoagnitude for males and females without children, though somewhat moreerratic over the postprogram period for females. For females withchildren present, the employment and earnings effects are both lowerand more erratic than for the other two groups. The authorshypothesize that the lower effect for women with children may be due tothe higher proportion of very young children among the participantsthan among the comparisons. This difference is apparently due todelays in childbearing by participants during the in-program period,followed by a higher rate of postprogram births than among comparisongroup members.The result is the presence of a greater number of youngchildren among participants in the postprogram period. 130 114Effects of the program on crime are estimated from self-reportedarrest data gathered in interviews with participants and comparisongroup members.The major effects are estimated to occur during theperiod in which participants are in the program, when total arrests andincarcerations were significantly lower for Job Corps members than forthe comparison group. In the postprogram period, the estimates show anoverall reduction in arrests (statistically significant for males), areduction in theft arrests, an increase in auto-related arrests, and noeffect on time in jail.When the benefits and costs of the program were estimated--in aquite detailed and sophisticated benefit-cost analysis--the study foundthat from the view of society as a whole, the net present value ofbenefits exceeded costs by $2,300 per enrollee (in 1977 dollars). Fromthe view of the participants, benefits exceeded costs by $2,400 onaverage.For nonparticipants (i.e., private benefits and costs), a netcost of $115 per enrollee was incurred, representing a net redistribu-tion of resources from nonparticipants to Job Corps participants.The estimated magnitude of the benefit-cost difference isparticularly sensitive to the assumptions regarding the magnitude ofthe effect of the program in reducing crime. The evaluation assumesthat actual arrests were underreported by 70 percent among members ofthe Job Corps samples this assumption is based on a study done for theevaluation of the Supported Work program.Considerable attention has been devoted to the issue of thecorrelation between self-reports and official reports of criminalityand arrests in the criminal justice field. There is no generallyaccepted differential between self-reported and official data oncriminality that supports the use of any given numerical factor toincrease the self-reported incidence of arrests.1 However, even whenit is assumed that no postprogram crime-reductit- '-.enefits areassociated with Job Corps, the net present value of the program tosociety is still positive, about $500 per enrollee.The Job Corps evaluation was extensively reviewed by outsideexperts in 1982 at the request of the Office of Management and Budget.The reviewers did not find any major problems, though one had somedoubts about the adequacy of the selection bias corrections. We havesome remaining reservations about the Job Corps evaluation that arelargely technical in nature.Random assignment to the Job Corps and to a control group was ruledout by the Department of Labor at the outset. Given that constraint,the comparison group strategy seems to have been well conceived and, 1A recent summary of research on the use of self-reported measures ofdelinquency indicates widely varying estimates of underreportingdepending on method of administratior (questionnaire or interview) andsample characteristics (sex, race, socioeconomic background, schoolstatus, and previous contact with police). Underreporting appears mostserious among black males with previous delinquent offenses (Hindelanget al., 1981). 131 115 ior the most part, well executed. Comparison group members were drawnfrom geographical areas that were similar to the home areas of JobCorps members but that had low rates of previous enrollment in the JobCorps.Within these areas, sample members were drawn with selectionprobabilities in proportion to their similarity to Job Corps partici-pants in terms of age, poverty status, race, and education.Beyond controlling for measured characteristics when estimatingeffects, the evaluation attempted to control for selection bias bymodeling the selection process using the methods suggested by Heckman(1979).While the selection bias correction appears to have workedwell, more detailed information than that available in the report Isrequired to remove some residual doubts as to whether this correctiondealt completely with self-selection problems. The efforts at correc-tion go considerably beyond those usually applied when dealing withcomparison groups (rather than randomly assigned controls groups), butthe nature of the comparison group renders the evidence of programeffects less convincing than it would be had a randomly assignedcontrol group methodology been used.The Job Corps provides a comprehensive set of services and whetherthe comprehensiveness is central to the effectiveness of the programhas not been directly evaluated. Apparently, earlier reports didprovide some estimates of the difference in impact according to themembers' exposure to par' Zcular components, but those results were notreported in the Mathematica study and mention is made of selection biasproblems in making assessments. Since participants are not randomlyassigned to the various components, self-selection factors seem likelyto be confounded with the actual effects of the component in which aparticipant is enrolled. We do not have sufficiently detailed evidencethat allows us to isolate the elements of the Job Corps program anddetermine whether (or for whom) the residential element of the programis critical; whether the health component is essential; or whether theskills training offered adds to any effects that the basic educationelements may have created--or vice versa.Since women represent about 30 percent of Job Corps enrollees, thedesire to obtain reliable estimates by sex led to the selection of acomparison group that was 50 percent female. Unfortunately, it appearsthat the enrollee and comparison groups for women were not adequatelymatched on child-responsibility status. According to the finalfollow-up report, almost none of the female corps member sampleinitially had children present, but by the time of the final follow-upinterview approximately 50 percent of the women had children present.Thus, female Job Corps members with children represented about 2 percentof the sample in the first 6 months of the postprogram period and 15percent of the sample during the last 6 months of the study period(42-48 months after leaving the program).In fact, baseline data from an earlier report indicate significantdifferences between participant and comparison group members, particu-larly among females (Kerachsky and Mallar, 1977). Approximately 3percent of the female participants were pregnant at the baseline com-pared with 12 percent of comparison group females. Female participantswere significantly more likely to be black, Hispanic, or members of 130 116 other minority groups than females in the comparison group (84 percentcompared with 62 percent) and also more likr,ly to never have beenmarried (94 percent compared with 73 percent).The Job Corps studies are among the few we reviewed that did notpresent data on the characteristics of participants and comparisongroup members at various stages of the evaluation. Therefore, we are not able to determine the levels of childbearing among comparison groupwomen over the study period. This makes the fertility and family-formation outcomes of Job Corps particularly difficult to interpret: since the participant and comparison groups were apparently notinitially comparable, later differences may indicate the presence ofself-selection bias. Other studies show that more highly motivatedwomen tend to postpone childbearing and marriage and that the presenceof children inhibits program participation. The evaluation design usedfor the Job Corps does not allow one to determine whether Job Corpsparticipation actually induced delays in childbearing and familyformation (see Margaret Simms, in this volume).he differences in measured characteristics between Job Corpsparticipants and comparison groups members suggest that there may alsobe differences in unmeasured characteristics (e.g., motivation andaspirations).The possibility of self-selection into the program is a strong argument fc he use of a random assignment experimental design,since statistical t ,hniques may not adequately control for the factorsthat determine program entry and postprogram outcomes. PROGRAM FOR IN-SCHOOL YOUTHSNew Youth Initiatives in ApprenticeshipThe New Youth Initiatives in Apprenticeship program sought to pro-mote the use of registered apprenticeship positions, outside theconstruction trades, by developing linkages between the schools andemployers with registered apprenticeship positions. Employers werebrovided subsidies for one-half of apprentice wages, up to a maximum of$1,700 per student apprentice year.The program began operation in four sites in 1977 under the sponsor- ship of the Department of Labor's Bureau of Apprenticeship Training;one of those sites operated for only 1 year. Four additional siteswere funded by the Office of Youth Programs in 1978, bringing the totalnumber of sites operating in 1978 to seven.According to the evaluation (Williams et al., 1981:6): \"The new [OYP] projects included targetingeconomically disadvantaged students to participate as student appren-tices, an activity not specifically mandated in the original demonstra- tion effort.\"Despite this, the data indicate that the newer projectsmay have been less successful in enrolling minorities than the moreestablished projects.The New Youth Initiatives in Apprenticeship program was reviewed intwo reports.The report by Williams et al. was more comprehensive andcompetent, and we based our assessment on that report alone.Thefollow-up analysis was based on samples of about 600 student- 133 117 apprentices and 500 matched comparison group members. The data on thestudent apprentices indicate that they were generally nonminority (80percent) and male (89 percent) and had a grade average of B- in highschool and a high rate of graduation from high school (96 percent).This program does not appear, therefore, to have reached the heavilydisadvantaged segment of the youth population. The results of theparticipant-comparison group contrasts show, on average, small and notstatistically significant differences in annual earnings ($290 abovethe $10,000 annual average) or wage rates. Apprentices tended to bemore concentrated in machine trades occupations and comparison groupmembers in clerical and sales occupations.The evaluation study also surveyed several hundred employers of thestudent apprentices in the eight sites where the program operated. Theemployer survey indicated that three-fourths of cooperating employerswere small businesses, employing fewer than 50 workers. Employersappeared to be more attracted by the screening and training functionsperformed by the program than by the wage subsidies provided. Employerswere predominantly in manufacturing (44 percent) and services (38percent); only 10 percent had unionized work forces. A multivariateanalysis indicated that the number of apprentices employed in thepostprogram period was positively and significantly related to fourfactors:the total number of employees; being a manufacturing firm;being a union firm; and the number of years the program had been inoperation in the site. Though the evidence was ambiguous, it suggestedthat those employers who rated stipends as important retained fewerapprentices.Two aspects of the research design seem worthy of note. First, allof the postprogram interviews were conducted in the last six months of1980, which provided only 6 months of post-high school data for the 40percent of the sample from the new sites and, at most, 1-1/2 years ofpost-high school information for 14 percent of the group. With such aheterogeneous group and relatively short follow-up period, one cannotbe sure whether sufficient time had elapsed for progr,a effects toemerge.Second, the comparison group sample was drawn (after the programbegan) from the same high schools as the participants. It is naturalto questien whether there is some selection bias--despite matching oncharacteristics - -since the members of the comparison group presumablyeither had an opportunity to join the apprenticeship program and didnot do so or were specifically not chosen to participate in theprogram.Since so few significant findings emerged from theparticipant-comparison contrasts, we did not pursue this issue further.Because of the characteristics of the participants we cannotdetermine whether this type of program might be more effective amongmore disadvantaged youths. In addition, it is difficult to tellwhether the failure to enroll significant numbers of more disadvantagedyouths is inherent in the nature of the program or simply due to thecharacteristics of the sites where it was implemented.Given the character of the participant population and the nature ofthe program, no generalizations can be drawn from the evaluation of the 134 118New Youth Initiatives in Apprenticeship program to youth employment andtraining efforts generally. CONCLUSIONSWhile it would be misleading to attribute the Job Corps results toskills training efforts in general, the measured effects of Job Corpsindicate that effective skills training can be provided foreconomically disadvantaged youths. At the same time it is clear on thebasis of both Job Corps and the less effective New Youth Initiatives inApprenticeship program that the staff canacity and other resources needed to mount skills training efforts are not acquired quickly or inexpensively. 135 6Effectiveness of Labor MarketPreparation Programs The YEDPA studies we reviewed represented three basic approaches tolabor market preparation for youths: (1) career exploration programs,which usually provided information on occupational opportunities andrequirements, work habits and attitudes, and job search techniques andsometimes included ability and interest testing; (2) basic educationalskills training, usually remedial, which often included GeneralEquivalency Diploma (GED) preparation; and (3) direct work experience,usually combined with some orientation to the \"world of work.\" Mostprograms offered some combination of the first two approaches, and afew were designed as systematic variations of work and classroominstruction as tests of their relative effectiveness.'The implicit long-term goal of many of the programs, especially theprograms focused on out-of-school youths, was to increase the employmentopportunities and economic self-sufficiency of youths. It was assumedthat certain deficiencies--in work habits and attitudes, basic educa-tional skills, and understanding of job interests and options--werebarriers for disadvantaged youths in achieving economic self-sufficiencyand that the correction of these deficiencies would solve the problem.Correction or amelioration of these deficiencies, therefore, became theinterim objectives of the programs, as well as steps toward thelonger-term employment goal.Labor market preparation programs under YEDPA were provided to bothin-school and out-of-school youths, but the majority served in-schoolyouths.Unfortunately, most of the studies on the in-school projectsdid not meet the committee's criteria of scie,.tific evidence and so arenot included in this review. For example, we were not able to evaluatesummer programs designed to maintain or improve educational skills ofyouths over the school vacation or the many career exploration programsoffered as a supplement to regular school programs. In terms ofnumbers of participants, the programs that met our criteria for 1It is not entirely clear how some programs should be classified,particularly those that provided several alternative treatments (suchas the AYES project). We decided to classify them here. 119 120inclusion and are reviewed here largely involved out-of-school youths, both dropouts and graduates.Several of the reports reviewed by the committee indicated that the programs being evaluated, while initially designed to provide occupational skills training, were revised to offer more basiceducational and prevocational skills. These changes were necessary because the youths enrolled lacked the skills required for more specific vocational training. PROGRAMS FOR OUT-DF-SCHOOL YOUTHSPrograms seining out-of-school youths ,,enerally scr,-ad both dropouts though the relative proportions 'variedconsiderably across the programs.We reviewed four pi :ams for our -of- school youths that we found deserving of sent` ;Alternative Youth Yaployment Strategies (AYES), Recruitment and Tr..ining Program (RTP) Career Exploration Program, Project STEADY (Special Training and Employment Assistance for Disadvantaged Youth), and the Job CorpsEducational Improvement Effort (EIE). Table 6.1 details the characteristics of each of these programs; Table 6.2 details theresearch design and results of the evaluations of the programs. Alternative Youth Employment StrategiesThe Alternative Youth Employment Strategies (AaX) project was designed to test the efficacy of three alternative models for providing youth employment programs to a particularly high-risk, hard-to-reachgroup:unewployed, out-of-school (largely dropout) 16- to 21-year-olds, many referred by the juvenile and criminal justice systems.The model treatments were: (1) full-time work experience, with counseling andplacement services; (2) full-time classroom instruction in basic educa-tional, vocational, or prevocational training, with counseling, ser- vices; and (3) a mixed model of part-time work, part-time training, counseling, and placement. AYES was implemented using randomassignment at sites in three cities (New York City, Miami, andAlbuquerque) and involved about 1,100 youths.The Vera Institute study of AYES was of particularly high quality.Although not tree of problems, the research seemed to have beenconducted as carefully as conditions permitted, given sone problems ofimplementation. Its major finding was that a 26-week, full-timeprogram that cone:entrated its services on high -risk youths enhancedtheir chances of securing full-time employment. Differences in employ- ment rates of approximately 10 percentage points were found between participants and a randomly selected control group approxima.ely 8 months after program participation (see discussion of Career Explora- tion Program below). Positive effects were found at all three sites: the largest program effects were found in New York City and the smallest effects in Albuquerque. At the same time, the demographic nature of the samples varied considerably across the sites, making it 1 3 7 TABLE 6.1Labor Market Preparation Programs for Out-of-School Youths: Program to Ohio 10 sites 11 Job Corpssites 13 BEST COPY AVAILABLE 139 TABLE 6.2Labor Market Preparation Programs for Out-of-School Youths: Research Design and ResultsYouthProgramSample Size Control/Comparison employment 891versus 51% (control group)3 months employment + 7.5%8 in andjob-seekinc skills at project yearsProgram effects whendisaggregated by sitewere significant inonly 2 of the sites Selectivity bias, seriousanalytical flaws leaveresults difficult tointerpret141 123virtually impossible to distinguish the independent effects ofethnicity and site.Differences in outcomes were not accompanied by any changes in themeasured attitudes and orientations reported on a series of testsdeveloped by the Educational Testing Service (ETS) that were adminis-tered at the conclusion of Ft.- nrogram. Nor did these differences inmeasured attitudes affec ypes of jobs that participants obtained.Three interpretations are (1) changes in reported orienta-tions toward employment are weakly related to changes in job-relatedbehalior; (2) the tests were administered immediately after programcompletion (when attrition rates were relatively lower for both theexperimtntal and control groups, 16 and 45 percent, respectively)rather than at 8 months postprogram, when the job placement comparisonswere made (when attrition rates among the experimental and controlgroups were 31 and 42 percent, respectively); and (3) the tests them-selves may be of questionable validity in measuring the attitudes andknowledge they purport to assess.The Vera Institute study of AYES compared the relative effectivenessof the three treatment strategies at each site. No difference in theeffects of the alternative treatment strategies could be discerned. Inseveral other studies, similar null findings for alternative treatmentswere also found. Indeed, this is the one finding that was fairly robustthroughout the studies of labor market preparation programs we reviewed.The only exception was the Special Project for Indochinese Youth. Itappeared to show English-language training for Indochinese youths to bemore effective if bared in the classroom instead of in a job context.This null finding parallels a similar finding in educationalresearch that shows little difference in the employment effects ofvocational and general education. Three explanations are possible:(1) the types of instruction have equal effects; (2) students selectthe type of program best suited to their needs (a choice among thethree types of programs was generally left to the individual), andeffects appear equal because each type of instruction is provided tothat group of students for whom it is best suited; and (3) sample sizesare too small to detect small differences in outcomes controlling forsite, treatment, and other variables. RTP Career Exploration Program The Recruitment Training Program (RTP) Career Exploration Programprovided summer instruction in career preparation to economicallydisadvantaged, unemployed out-of-school youths, both dropouts andgraduates, in several cities. Services, including occupationalinformation, job search information, and basic skills instruction, wereprovided to 16- to 21-year-olds during the summers of 1979 and 1980.The study of RTP shows positive effects of the program. Partici-pants showed larger gains on a variety of ETS-developed measures of jobsatisfaction and vocational aspiration than a randomly selected controlgroup.In addition, participants were more likely to be employed fulltime at program completion than control group members, 89 percent 142 124compared with 53 percent. The favorable full-time employment experienceof participants persisted at the time of the 3- and 8-month follow-upsand even increased slightly: a difference of 7.5 percentage points at3 months and of 8.2 percentage points at 8 months.The gains reported for this less intensive summer program were aslarge as the gains reported for the full 6-month AYES program studiedby Vera.The findings could be attributed to the fact that the RTPCareer Exploration Program addressed a less disadvantaged population:approximately 25 percent of treatment and control group members wereenrolled in college at the 3- and 8-month follow-ups. It is alsolikely that the assignment of youths to participant and control groupsin the Career Exploration Program was not Arictly random -- sizabledifferences in the two populations can be discerned on the basis ofpreprogram characteristics within sites, such as high school graduation,welfare recipiency, ethnicity, and age (20 to 30 percent of partici-pants and controls were 20-21 years of age). These considerations,combined with the fact that the analysis takes no explicit account ofthe program year or site, suggests that the findings in this case arenot as reliable as those from the Vera study. Project STEADYSpecial Training and Employment Assistance for Disadvantaged Youth,Project STEADY, operated during the summer of 1980. Its purpose was todetermine the feasibility and effectiveness of the employment service'slocal office efforts to increase the employment and employability ofunemployed out-of-school (graduate and dropout) youths who had nofurther educational plans and no immediate employment prospects.Participants, whose ages ranged from 16 to 21 and who were otherwiseeligible for the Summer Youth Employment Program, were required toparticipate 35 hours per week at the minimum wage ($3.10 per hour) forup to 12 weeks. Program activities included aptitude and achievementtesting, counseling, labor market information, job search training, andreferral to and placement in unsubsidized jobs. Ten sites were selectedfor the project. The nature of the treatment varied considerablyacross the sites; site directors had complete discretion in selectingthose services, materials, and emphases they thought most appropriate.The evaluation of Project STEADY is based on data for approximately600 participants and 400 controls at 3 months postprogram. Data from alonger term follow-up are not available. Personal characteristics ofboth controls and participants varied a great deal among the sites,although the initial assignments to control and participant groupswithin a site were random: program applicants were initially testedand then randomly assigned to participant and control groups. Attemptswere made to make up for participant attrition by accepting controlgroup individuals as participants. The author of the evaluation reporthad no information as to how control group members were selected to beparticipants.in addition, attrition in the 3-month follow-up periodwas significantly higher among control group members (about one-third)compared with participants (one- fifth). 143 125Project STEM employed two measures from the Standard AssessmentSystem (SAS) as appropriate to both the target 1-Jpulation and theprogram objectives: job-holding skills and jc'- seeking skills. Both apretest and a posttest consisting of the two SAS measures were adminis-tered to the participants and controls. Performance outcome measureswere used in a program completion survey administered to participantsafter 12 weeks of program participation and in a control group statussurvey administered to controls at the same time. In addition,performance outcome measures were used in follow-up surveys (3 months)after termination of program participation for participants and at thesame time for controls. Information on individual characteristics ofparticipants and controls was taken from the individual participantprofile of SAS.There were relatively small numbers of participants and controls atany given site. Alternative statistical tests were used to gauge theeffectiveness of Project STEADY. Statistically significant gains forparticipants relative to controls were found in both job-holding skillsand job-seeking skills when sites were pooled. However, on anindividual-site basis, only 2 of 1G sites revealed statisticallysignificant gains for participants relative to controls in job-holdingskills and job-seeking skills. At most of the remaining sites, thegains of participants relative to controls were not statisticallysignificant.The 3-month follow-up survey revealed that when all sites werepooled, the percentage of participants who were employed full timeexceeded that of the controls by a large and statistically significantamount:the adjusted probabilities of full-time employment areestimated to be 29 and 17 percent for participants and controls,respectively.On an individual-site basis, only the three sites withlarge samples exhibited statistically significant full-time employmentdifferences, all in favor of participants. The percentage of par-ticipants reporting being employed in jobs of higher status exceededthat of the controls by a statistically significant amount when poolingall sites.On an individual-site basis, however, there were nostatistically significant differences in job status. There were alsono significant differences in earnings or in job satisfaction betweenparticipants and controls.After adjusting for heterogeneity between the participant andcontrol groups at the 3-month survey, the evaluators found that of the40 possible outcomes included, 10 yielded statistically significantdifferences, all in favor of participants (relative job status was nolonger significantly different). These outcomes included full-timeemployment, financial contribution to one's family, two measures offuture job quality, and getting along with one's family.Very little information pertaining to race, sex, or age differencesin program gains is available from the evaluation of Project STEADY. Amultiple regression analysis was conducted in which posttest scoreswere regressed on pretest scores and demographic characteristics. Forall sites taken together, females experienced statistically significantsmaller gains than males in both job-holding and job-seeking skills.Practically, however, these meant small actual differences in scores. 144 126On the other hand, there were no statistically significant differences by race and age.There were certain implementation problems associated with ProjectSTEADY as a demonstration project that need not occur under a permanentprogram.Due to the brief start-up time, there was diff:.culty inrecruiting participants. Lack of time and resources caused difficultiesregarding planning, curriculum development, and the necessary outreachto potential participants, as well as the creation of a trill controlgroup (as discussed above).Overall, the evidence indicates some positive effects of projectSTEADY on the short-term employment prospects of youths. While theprecision of the estimated gains is questionable because of data dif- ficulties, the qualitative effects can probably be accepted. However,statistical significance, where found, was typically the result ofpooling the data across sites, and therefore we have questions aboutwhether the evaluation of Project STEADY demonstrated that the programcould have a substantial positive impact on a significant number ofyoung people facing employment difficulties. Job Corps Educational Improvement EffortThe purpose of the Educational Improvement Effort (EIE) was toimprove the educational offerings of Job Corps to provide corps members with the best opportunities for learning at all levels. To meet these objectives, new or revised curricula were developed for basic skills inreading and mathematics and high school level skills in all areas.Programs were tested in an experimental design to provide information concerning their effects on educational progress and process (Argento et al., 1982).The Job Corps Educational Improvement Effort (EIE) isnoteworthy in its attempt to use random assignment of Job Corps par-ticipants to treatment and control groups to test alternative teachingtechniques.The programs evaluated included: (1) a reading curriculum thatused materials revised from earlier Job Corps reading programs; (2) acalculator mathematics program that provided instruction and experiencein the use of hand-held calculators; (3) a reading program using \"peeraides\" to help instructors in the reading program deal with the instruc-tional needs of their students; (4) a program offering participants the opportunity to obtain a regular high school diploma rather than a GED;(5) a GED program that used televised instruction; (6) a computer-assisted education program using the Comprehensive Computer Program to help students with reading and mathematics; (7) the PLATO system ofcomputer-assisted instruction; (8) two curriculums to help students with learning disabilities--one developed by the University of Florida and the second by the University of Kentucky; and (9) two curriculumsdesigned to improve the \"employability skills\" of participants, theAdkins Employability Skills Series Program and the American Preparatory Institute Program. 145 127 Over 7,000 Job Corps members in 11 centers took part in one or moreof these programs. Because participants could enter or leave theprogram at any time, attrition in posttest data was substantial formany treatments and sites: for example, 74 percent among controls inthe mathematics component of the Comprehensive Computer Program model(Argento et al., 1982:Table 1.4-1).The assignment of participants to treatment and control groups isdescribed as follows (Argento et al., 1982:1-5):Potential participants were randomly assigned to either theexperimental group or the control group, to the extent possible.Unfortunately random selection was not always possible. In onelarge Job Corps Center, for example, a decision was made toplace all students in the same vocational training area in thesame educational classes. Thus all students interested inautomobile mechanics were in one mathematics class, all thoseinterested in nursing in another, and so on. With this system,it was impossible to maintain true randomization. ... While the report is forthright about such problems, it does not presentseparate analyses for the \"true\" random assignments, and so it is not'possible to estimate the biases that might have been introduced by such:;administrative decisions to abandon randomization at some sites.The key analysis performed for each of the programs uses preprogramto postprogram differences in Stanford Achievement Test (SAT) scores asthe dependent variable in an analysis of covariance in which\"\"treatment\" is the independent factor and the covariates include sex,age, race/ethnicity, highest grade completed in school, hometown size,'whether family receives welfare, and score on SAT pretest. The'reported analyses do not consistently include all variables, apparentlybecause a stepwise inclusion procedure was used.Gains in test scores are measured in 'grade equivalent\" years inorder to gauge treatment effects on educational attainment. Thus,postprogram minus preprogram scores are divided by the number of hoursin the program: a 100-hour program that raised performance by twogrades would show a gain of 2/100, or .02. Gatn scores are thenadjusted for the covariates included in the analysis.Few of the treatments produced significant results; for those thatdo appear significant selectivity bias cannot be ruled out as animportant factor. Thus, we did not find the evidence on the differ-ential effectiveness of the Job Corps EIE convincing. PROGRAMS FOR IN-SCHOOL YOUTHSThis sec*.ion discusses three programs that predominantly orexclusively served in-school youths: the Career Exploration Program,the School-to Work Transition program, and Project Redirection. Table6.3 details program characteristics; Table 6.4 presents the researchdesign and results of the program evaluations. 146 147TABLE 6.3Labor Market Preparation Programs for In-School Youths: self-as a means of awareness, pre-easing transition employment skills,from school to job explorationwork Comprehensive Educational, health,counseling and family planning,support services and employment-Cor statuslower cognitive skillmeasures inChicago, JerseyCity/Hoboken, N.J.;and South Bronx, N.Y. 2 schools each inHartford, Conn., andSan Juan, Puerto Rico,added; 1 school inJersey City Mass,; Phoenix, Ariz.;and Riverside, Calif. BEST AVAILABLE148 TABLE 6.4Labor Market Preparation Programs for In-School Youths: Research Design and Results Sample Size Control/ComparisonYouth Program ParticipantControlGroup Methodology Program EffectsFollow-upResponse Rate Comments OIC/A Career 1,500800Varied by site-- School retentionExploration some random, some not P = 73%Program C = 62%Significant reductionin crime NPR ForumSchool 12 93%24 afterenrollmentP and controls.24-month pools2 periods of operation. 149BEST COPY AVAILABLE 150 130OIC/A Career Exploration Program The Opportunities Indus`rialization Centers o: Amecir.a, IrT.!OIC/A) operated the Career Exploration Program in seven sites erring1920.The eesign of the OIC/A program was similar in many respects tothat of programs offered by MP and other community-based organizatJ s;it involved a 10-week summer program providing classroom instructicfor 2 hours per day and career exposure site experience (work experi-ence) for 4 hours per day. A follow-up component extended for 8 monthsafter the summer program and included review classes, counseling,referral servi..:es, and a newsletter designed to reinforce skillslearn(] in the program.The OTC/A program served a predominantly minority clientele (78percent black, 13 percent Hispanic) of : to 21-year-olds; near y halfof the participants were female (48 percent). Because an express aimof the program was to serve nigh -risk youths, about 24 percent of theparticipan*-1 were ex.offenJers and 19 percent were dropouts; 75 percentof the participants were high school students, 4 percent were graduates, and 1 percent had received GED degrees. No data were provided oncross-site differences in participant characteristics.While participant and control group members were similar in termsof age and economic status, they differed significantly in otherpreprogram characteristics. Participants were more likely to be female(48 percent of participants compared with 37 percent of controls);attending high school (75 percent compared witn 68 percent), and blackor Hispanic (90 percent compared with 84 percent). By design, controlswere .tore likely to be youth offenders than were participants, thoughthe actual proportions differed from the planned 50 percent and 33percent:49 percent of controls were offenders while only 24 percentof participants were.The differences between the two groups suggest that random assign-ment was not strictly followed, at least at some of the sites, and theevaluation report itself suggests as much. While overall attrition at8 months was reasonable for studies of this kind (23 percent for par-ticipants and 20 percent for.1/4;ontrols), differential attrition amongblack participants eliminated the sicnificant difference in racialcomposition that had existed earlier between the experimental and control groups.The evaluation results indicate that the participants' schoolattendance improved and their criminal recidivism was reduced at 3 and8 months postprogram ccupared with a randomly assigned control group.The analy-is by the Center for Studies in Social Policy of the data fornearly 1,500 participants and 800 controls at 8 months postprogvAindicates that continued school attendance was significantly higher .participants than co:Itrols: 73 percent compared with 62 percent.Given the initial differences between the two groups on school .-ndoffender status, however, and the fact that being in school at pry :4111entry was found to be positively associated with being in school at the follow-up, it may not surprising that participants compare favorablywith controls on this &demure. Because it is not clear that randomassignment was effectively carried out and the results are confounded 151 131with prcprogram characteristics, it may be erroneous to treatpostprogram differences as program outcomes. National Puerto Rican ForumThe National Puerto Rican Forum's (NPRF) School-to-Work Transitionprogram was designed to serve approximately 150 (largely) Puerto Ricanin-school youths in each of various sites to \"enable the participantsto better understand and identify their strengths and weaknesses,facilitate the transition from school to work, and enhance theirability to select a career\" (Murphy and Appel, 1981:13). Services wereintended to include workshops in self-awareness, preemployment skills,and job exploration for 5 hours per week during the school year.Actual contact hours averagcl fewer than 30 in each site.In the iaitiaL year of the program, 1975, services were provided tohigh school senio:s attending two schools in each of three sites,Chicago, Jersey City/Hoboken, and New York (South Bronx). In thefollowing year, apparently due to a concern that many needy PuertoRican youths leave school before senior year, the program shifted itsfocus to serving high school freshmen, lost one of the Jersey Cityschools, and added four high schools, two in Hartford and two in SanJuan.Because of the program's focus on high school seniors, it may beappropriate to view the 1979 program as similar to job placementefforts (such as Jobs for Delaware Graduates or Project BEST, discussedin Chapter 9).As such, the nature of the comparison group and therelative experiences of the two groups become important. Whileinitially based on an experimental design, random assignment wasabandoned due to insufficient sample sizes, and all ysaths expressingan interest in the program were allowed to participate. Comparisongroup members were high school seniors from the same schools asparticipants.No information is available on the procedures used toselect comparison group members, who differed considerably fromparticipants:comparison group members included fewer Hispanics andmore blacks, had higher family economic status, and had less prioremployment.Attrition among both participant and omparison group members atthe 6-month follow-up (50 and 62 percent, respectively) was par-ticularly high for participants who were Hispanic and from low economicstatus households, while attrition among comparisons was highest forblack males.Duc to the attrition pattern, the initial differences incharacteristics between the tuo groups largely disappeared. Moreover,the resulting sample sizes, 102 participants and 130 comparisons, wereinadequate f,r reliable quantitative analysis. Therefore, no validinferences can be drawn about the effectiveness of the 1979 NPRFprogram.The program that operated during the 1980-1981 academic year servedhigh school freshmen for an average of 33 contact hours during theschool year (Trismen, 1982). About 83 percent of participants wereHispanic, 57 percent were female, and 85 percent were from families 152 132with incomes no higher than 70 percent of the lower living standard ofthe Bureau of Labor Statistics. While no information is provided onhow comparison group members were chosen, the demographic character-istics of the comparison group very closely matched those of partici-pants.Participants and comparisons in the second year program were,of course, younger than those who participated the previous year theywere also of lower economic status, had less prior employment experi-ence, and scored lower on pretests on a variety of cognitive measures.At program exit, participants exhibited significantly larger gainsthan did comparisons on each of the seven items in the SAS testbattery.2This is in contrast to a finding of no significantdifferences in gains for participant and comparison group membersduring the previous year's program.Postprogram results are available only at 3 months after programcompletion for 61 percent of participants (260) and 65 percent ofcomparison group members (102). Statistically significant findingsthat favored the participent group related to the degree of jobknowledge, the proportion working full time or part time (40 percentand 29 percent), and the extent to which family members felt good aboutthe program (or \"how you've been doing\" for controls). As seemsappropriate for a serving in-school youths, the employmentoutcome largely rfflects part-time employment.At the time of at 3-month follow up in early fall of 1981, about86 percent of the respondents were in school. While participants weresignificantly less likely to be in school at the follow-up thancomparison group members, other things equal, the actual difference wassmall: 85 percent compared with 87 percent. Overall, participants inthe 1980-1981 program performed significantly better immediatelypostprogram than nonparticipants on a variety of cognitive measuresThree months postprogram, participants were somewhat more likely thancomparisons to be employed full time (2 percent compared with 1percent) and much more likely to be employed either part time or fulltime (40 percent compared with 29 percent), but they were also somewhatless likely than comparison group members to be enrolled in school.Thus whether the program intended to or not, it did not increase schoolretcltion.Although the evaluation of the 1980-1981 NPRF programprovided promising results, it provided insufficient information on howthe comparison group was formed. Therefore, we cannot be confidentabout the results for either year of the NPRF program's operation. -A---'Gains were measured in terms of percentages of standard deviations,and the magnitudes averaged 34-65 percent across all sites (Murphy andAppel, 1981).Gains of 10 percent or more were considered to navepractical significance. 153 133 Project Redirection Project Redirection was designed to provide pregnant uld parentingwomen aged 17 and younger who had not yet graduated from high schoolwith educational, health, family planning, and employment-relatedservices for up to 18 months. Its goal was long-term personal andeconomic self-sufficiency. It operated in four sites--koston, New York(Harlem), Phoenix, and Riverside (California)--from mid-1980 to 1983.About 48 percent of participants were black, 38 percent were Hispanic, and 13 percent non-Hispanic whites. The average age of participantswas 16, 56 percent were pregnant (not yet parents), and 52 percent were3n school at the time of the baseline interviewProject Redirection was noteworthy for its development of acomprehensive program of counseling and supportive cervices for youngwomen from low-income backgrounds who were pregnant or mothers.Whilethe program seemed innovative and promising, the evaluation findingsare unclear.The interim report on program effectiveness consideredabot.t 180 participants and 200 comparisons at only 12 me-ths afterenrollment in the program, when most young women were still partici-pating or had only recently left the program.The findings indicatedthat participants were less likely to have a repeat pregnancy (17percent compared with 22 percent) ant more likely to be enrolled inschool or have completed school or a GED program (66 and 50 percent, respectively).However, a later report at 24 months after enrollment in theprogram showed Project Redirection youths on the whole fared nodifferently than comparison group youths on a variety of outcomes.There were no significant differences in the number of repeatpregnancies, in school enrollment or completion, or in employment.While the evaluation design of Project Redirection was superior tothat of other programs for pregnant and parenting youths, severalshortcomings limit our confidence in the findings. The comparisongroup approach used matched sites in the same regions, but severalsignificant differences between comparison and participant groupmembers at baseline suggest that the two groups were not comparable.For example, controls were more likely to he attending school (70percent compared with 52 percent), had had more pregnancies, and hadpreviously enrolled in a teen parent program (44 percent compared with23 percent).Attempts to adjust for selectivity bias produced nodifference in the results.In addition, the comparison group members received many of the sameservices provided to participants in Project Redirecion. Thus, ratherthan being a test of the effect of providing services, per, se, thedemonstration is more appropriately ceen as the test of the relativeeffect of the Project Redirection service provision strategy comparedwith others.The possibility therefore exists that the resultsunderstate the true program effects.In order to enlarge the participant sample by nearly one-half (from180 to 350 participants), a second sample was formed with treattentgroup members who participated in the program between March 1981 andJanuary 1982, about a year after the original sample members were givenbaseline interviews. They were added to the analysis along with154 134 TABLE 6.5Selected Project Redirection Outcoae interview 9* - 8at 24-month + 2Percentage with live birthsubsequent to baselineat 24-month interview - 9 baselineand 24-month interview +11* +25*Percentage employed at24-month interview + 1 - 4 NOTE:Adjusted participant group mean minus comparison group mean. *Statistically significant at the .05 level or below in atwo-tailed test.SOURCE:Polit et al. (1985). additional comparison group members. The numbers of additional samplemembers were not uniform across the sites. Variousechniques wereused to overcome the lack of comparable baseline data for members ofthe second sample, including the use of retrospective data andestimation.The data for the two samples are pooled in most of the analyseseven though the treatment period covered different time periods (andtherefore possibly somewhat different program offerings) and members ofthe second sample participated for a significantly shorter period oftime, 9.9 compared with 12.9 months. The pooling of the two samplesmay account, in part, for the apparent decline in program effectsbetween the 12-month and 24-month result. The interim report resultsrely exclusively on data from the initial sample whf.le the 24-monthresults include data from the second nample, which account for asignificant share (40 percent) of the '-otal. When results at 24 monthsare reported separately for the two samples, participant outcomes forthe first sample are generally more favoizhle with respect to thecomparison croup than those of the second sample: forxample, outcomesare better in terms of the number of repeat pregnancies, the number oflive births, whether the participant is employed, and a variety ofother measures (see Table 6.5). 155 135Although the overall attrition rate of 14 percent for the firstsample was relatively low for a study covering 2 years, there wassignificantly more attrition among participants (21 percent) than among comparison group members (7 percent). Attrition rates for members ofthe second sample are more problematic: only 55 percent of those whoparticipated were given the 24-month interview. Attempts to adjust forattrition bias using the Heckman (1979) procedure produced no changesin estimated program effects, although this was as likely due to thedifficulty of modeling attrition as to any other explanation.'?inally, due to the nature of the sample design, site effects areconfounded with race/ethnicity effects. The Harlem site was largelyblack (92 percent), Boston was predominantly Puerto Rican (96 percent),and Phoenix and Riverside were the only sites with white non-Hispanicparticipants (9 and 40 percent, respectively) an- with significantnumbers of Mexican-American participants (42 and 24 percent, respectively).Because of the many methodological difficulties inherent in theevaluation, we do not believe that reliable conclusions about the effectiveness of Project Redirection can be drawn. CONCLUSIONPrograms offering labor market preparation were tLe largest singlecategoL, of programs we reviewed. Although 15 reports met the com-mittee's standards of evidence for determining program effectiveness,many suffered from serious methodological deficiencies that led toquestions about their results.The results of several studies (mostly of programs for out-of-school youths) were of sufficient reliability to be examined for their implications fcz youth policy: the Alternative Youth EmploymentStrategies (AYES) project, some career exploration programs (thoseoperated by OIC/A and RTP, in particular), and Project STEADY.Overall, the results of these studies suggest that most labor market preparation programs for out-of-school youths have at best onlymarginal effects on employment, and there is some hint that the effectsmay decay fairly rapidly (3 to 8 months) after participants leave theprogram.A comparison of the 26 -reek program with programs of 10 to 12weeks suggests that the same marginal gains in employment can be 'As a practical matter, it is when the use of these techniquesproduces change in the estimated results that the presence of selection bias is indicated. When selection bias adjustment techniques produceno change in the estimates, it can either be due to the absence ofselection bias or the inability to properly identify the factors thatdifferentiate participants from nonparticipants. Thus, when the application of these techniques produces no change in the estimatedeffects, it implies nothing about the presence or absence of selection bias. 156 136achieved as well by a shorter program, although differences in targetgroup characteristics and treatments suggest caution in generalizingthis particular finding. The effects of the programs on job attitudeand orientation, if reliably measured, are also marginal. The lack ofa relationship between these measures and employment gains raisesinteresting issues about the goals of these programs (many of whichwere supposed to have focused on changing youths' attitudes andmotivations) about attitude measurement, and about the relation of jobattitudes to employment.The results of these studies raise many other interesting questionsthat, unfortunately, we cannot answer because of tieficincies in theresearch.Programs were operated in many sites, with variations inprogram approach and target group characteristics, but when the datawere analyzed and the results presented, those differences were notexamined, often because of insufficient sample sizes. Across andwithin sites, different groups of participants received similarservices, perhaps with varying effects, but again most evaluations didnot include separate analyses: for instance, for in-school comparedwith out-of-school youths; for dropouts compared with high schoolgraduates; for males compared with females; or by racd and ethnicsubgroups.When a program has an effective outcome, we know littleabout why it works or for whom. Similarly, when there is no effect orno difference in effect, as in the AYES project, we cannot identify theroarons for the particular finning. Yet such information would helpidentify possible effective approaches to youth employment problems.Many of the labor market preparation studies produced by the YEDPAknowledge development effort are not discussed in this report becausewe found their methodological deficiencies too serious to allow reliableinterpretations of their results. The most common shortcomings inthese evaluations were the inadequacy of the control or comparisongroups and sample attrition. In most cases, the \"control\" group wassufficiently different from the participant group in important char-acteristics that there was reason to suspect differences in unmeasuredcharacteristics as well, which makes the attribution of changes inoutcomes as due to the program questionable. In many other cases,although a requirement for random selection was stated as a plannedfeature of the research design, the randomization of participants andcontrols was abandoned. In still other cases, the comparison groupconsisted of participants in another program, resulting in probableunderestimates of program effects relative to those based on a trulyuntreated control group. Appropriate techniques for following upprogram participants and comparison group members were rarely used.Not only was attrition in the 3- to 8-month period following programcompletion often in excess of one-third, but differential patterns ofattrition raised serious questions about the validity of purportedresults. 157 7Effectiveness of TemporaryJobs Programs Programs providing temporary subsidized employment have been amainstay of youth employment and training efforts in the United Statessince the War on Poverty. The committee reviewed five reports on YEDPAprograms that provided temporary jobs for youths.Three served out-oplchool youths exclusively: Ventures in Community Improvement(VICM,Supported Work, and the Public Versus Private Sector Jobs DemonStration Project. Two were designed primarily for in-school youthiithe Summer Youth Employment Program (SYEP) and the Youth IncentiVe Entitlement Pilot Projects (YIEPP). PROGRAMS FOR OUT-OF-SCHOOL YOUTHSTable 7.1 presents the characteristics of the three programsserving out-of-school youths. Table 7.2 summarizes the research designand results of the evaluations of those programs. Ventures in Community ImprovementVentures in Community Improvement was a demonstration project operated under the Youth Community Conservation and ImprovementProjects (YCCIP) pact of YEDPA. The target population consisted ofyouAls aged 16-19 who were out of school, had employment difficulties,or were economically disadvantaged (eligible for CETA). The programprovided participants with up to 12 months of work experience (onaver.participants stayed for 6 months) on construction projects toimprove public or low-income housing. Participants were supervised byunion journeymen at a ratio of 6 to 1. Job placement assistance wasprovided to those completing the program, and participants were activelyencouraged to complete a General Equivalency Diploma (GED) program.One objective of the project was to determine the impact of the programon participants' subsequent labor market outcomes. Other objectives were to test the feasibility of replicating the program model on a broader scale and to find a way to measure the value of the communityhousing improvements produced under the program.In all, there were eight sites involving a total of 1,500 participants.The demonstration137158 TABLE 7.1Temporary Jobs Programs for constructionImprovement onconstruction sites construction skillsand months to 12-18 monthsdepending on site8 5 25 weeks (44% completed 5the program) BEST COPY AVAILABLE 15J TABLE 7.2Temporary Jobs Programs for Out-of-School Youths:Research Design and Results YouthProgramSample SizeParticipantControlControl/ComparisonGroup Methodology Program EffectsFollow-upResponse Rate Comments Ventures in8051,244Comparison groups of Community HUD and other YCCIP Improvement make resultshighly questionable High attrition seriouslycompromises reliabilityof results aBased on long-term follow-up survey up to 4-1/2 yL.rs after enrollment (see Maynard et al., 1982). bResults are presented for total sample and for those who completed the program. Since attrition in the total sample is high (57%) only the results of program completers are reported here.11)0 BEST COPY AVAILABLE161 140was implemented between September 1978 and February 1979 and concludedin all sites in September 1980.Comparison groups were derived from three sources: participants inYCCIP programs run by the Department of Housing and Urban Development(HUD; operating under an interagency agreement with the Department ofLabor) in four sites that overlapped VICI; youths in formula-fundedYCCIP construction programs in three sites; and youths randomly selectedfrom VICI waiting lists after the programs were fully enrolled withyouths judged to be the most motivated. According to the evaluationreport, objections raised by the Department of Labor and a pressingneed to launch the VICI project without further delay were cited as thereasons for not following a true randomized evaluation design. Unfor-tunately, few detailed data on participants in non-VICI programs areprovided and no data are provided on comparison group members drawnfrom the VICI waiting lists.Postprogram follow-up data were obtained from interviews adminis-tered to comparison groups as well as the VICI participants at 1 month,3 months, and 8 months postprogram. Final samples used for estimatingeffects varied from 160 to 500 VICI participants and from 160 to 650comparison group members.Although long-term program effects could not be estimated, thestatistically significant estimated short-term effects of VICI relativeto individuals drawn from VICI waiting lists were (1) an increasedt.._probability of employment; (2) an increased probability of being in anapprenticeship position or on an apprenticeship waiting lAst; and (3)higher quarterly earnings (a maximum of $1,350 with an average effectof $322).'Not surprisingly, comparisons among VICI, HUD, and otherYCCIP participants failed to identify a dominant program. All of theeffects of VICI participation were estimated after controlling fordemographic characteristics, geographical location, and the date of theparticipant's most recent interview. The evaluation report states thatpersonal characteristics did not exhibit statistically significanteffects on outcomes, while site differences did, but these results arenot shown in the report.The evaluation design of the study is seriously flawed in severalrespects.The nature of the various programs used to make comparisonswith VICI, as well as the participants, differed from VICI. The YCCIP 'The analyses of outcomes are based on multivariate tech-niques, including binomial logit, log-linear regression, and tobitanalysis.The interpretation of the program effects therefore varies.For example, the finding with respect to employment is that thelikelihood of employment is 111 percent higher among VICI participantsthan among \"controls.\" This finding implies that for a participantwhose probability of employment was 0.5 prior to the program theprobability would be about 0.68 after participating; one whoseemployment probability was 0.9 prior to participating would have aprobability of 0.95 of being employed after participating in the VICIprogram. 162 141programs often served 10 or fewer youths, and the F ' and VICI programsusually enrolled more, up to 120 and 60, respectivelj.In addition,both the supervisory ratios in the programs and the nature of the work differed from VICI. VICI programs were construction oriented; the HUD and YCCIP programs included less skilled activities, usuallylandscaping and neighborhood cleanup (in YCCIP). VICI participantswere older and less likely to be enrolled in school.Becaus' of high sample attrition (only 37 percent of the VICIparticipants and 35 percent of the combined comparison groups were interviewed at the 8-month follow-up), the data actually used forassessing program effects consisted of the most recent interview datafor each participant who was interviewed at least once after program completion.In addition to the lack of equivalence in geographicalcoverage, the follow-up sample for VICI participants differed not only from the general VICI participant population but also from the HUD and YCCIP comparison groups. The study could not determine what, if any, biases would be present as a result of differences between thefollow-up samples and the total client populations.Given the severe shortcomings of the evaluation design, what, ifanything, can be learned? The report may provide reliable insights anddocumentation regarding implementation and program delivery issues. Some attention was paid in the report to the optimal degree of siteadherence to a standard plan and latitude for acro-site variations to accommodate local conditions. The report clearly identifies the factthat referral agencies had little incentive to refer potential clientsto the competing VICI project. The educational is shown to be weak:educational institutions had little incentive to play an important role in the project. Moreover, participants lacked theenergy and motivation to pursue adult education at the end of a day on a construction project. The involvement of union journeymen as crew supervisors turned out to be particularly helpful in job placements because of the journeymen's knowledge of the informLi labor market andtheir contacts; their referrals and recommendations carried more weightthan comparable activities by CETA job developers.although an evaluation of the long-term program effects is ruledout by the small sample size and limited follow-up period, the study does attempt a benefit-cost analysis of the program from a societal point of view.Under a variety of alternative assumptions, the present value of the benefits consistently exceeds the present value of the costs.However, benefit-cost calculations are only as credible as theunderlying estimated program effects, and the evaluation study fails to provide reliable evidence on the effectiveness of the VICI program inchanging the employment and earnings prospects of disadvantaged young people. Supported WorkSupported Work was a national demonstration program begun in 1975. The program concentrated on four target groups: women who had been receiving Aid to Families with Dependent Children (AFDC) for several 163 142years; ex-addicts; ex-offenders; and young (17- to 20-year-old) highschool dropouts. Five of the 15 sites enrolled dropouts. Dropoutsparticipating in the program had no immediate plans for further educa-tion and were without immediate employment prospects; many had ahistory of delinquency. Supported Work sought to inculcate participantswith the necessary work habits, desire for employment stability, skills,etc., for future labor market success; these were to be achieved throughsubsidized work experiences that would be gradually more demanding andapproximate regular unsubsidized employment.Three aspects distinguish the Supported Work programs (1) peergroup support; (2) graduated stress; and (3) close supervision. Thepeer group aspect was implementei trough the assignment of individualsto work crews consisting mainly of program participants, and thisaspect was accomplished in s more or less consistent fashion acrosssites.Graduated stress was intended to expose the participant toincreasiagly higher performance standards that eventually correspondedto those typical of regular, unsubsidime0 jobs. There was a good dealof variation across sites In how this program aspect was actuallyimplemented.Close supervision was designed to facill Ite the transferand then development of skills, proper work habits, and properattitudes.Supervisors could be either program staff or nonprogramsupervisors from the host employer.All five Supported Work sites that had youth enrollees participatedin the evaluation. Applicants were randomly assigned to experimentaland control groups. Those in the experimental group could participatein the program for a maximum period of 12 to 18 months, depending onthe site.Both experimentals and controls in the sample wereinterviewed at baseline and then at 9-month intervals that continuedfor up to 36 months for some sample members.2 For purposes of theevaluation study, the enrollment period started in the second quarterof 1975 and lasted until the second quarter of 1977. The maximumlength of the postprogram period covered by interviews was determinedby when an individual enrolled. On average, youths in the program leftit well in advance of the maximum period allotted for participation;only about 18 percent of the enrollees left to take other jobs or toenroll in an educational or training program (Maynard, 1980:Table111.2).The statistically significant positive effects of Supported Work onemployment rates, hours of work, and earnings were largely confined tothe period of participation in the program (see Table 7.3). During thefirst 3 months following enrollment, program participation increasedaverage monthly earnings of participants by $289 (389 percent), averagehours worked by 112 hours per month (459 percent), and the probability 2A special resurvey was conducted over the period July 1980-January1981.This resurvey provided data covering a period of 38-67 monthsfollowing initial enrollment. The results of the study did notsubstantially alter the conclusions reached in the original study(Maynard et al., 1982). 164 143TABLE 7.3Selected Supported Work Outcome Differences For Young Dropouts MonthsAfter participant group mean minus control group mean.*Statistically significant at ti- ,05 level or below in a two-tailed test. SOURCES:Data for months 1-15 from Maynard (1980); data for m,nths 16 and beyond from Maynard et al. (1982). of employment by 68 percentage points (335 percent) relative tocontrols.By 10 to 12 months following enrollment, these positiveeffects attenuated dramatically: program participation raised averagemonthly earnings by $92 (56 percent), average hours worked per month by29 hours (58 percent), and the probability of employment by 19 per-centage points (52 percent). Beyond 13 months from the date of initialenrollment, program participation had no overall statisticallysignificant effects on labor market outcomes as compared with members of the control group. The fact that exrerimentals had longer jobtenure than controls because of program participation had no impact onpostprogram employment rates, hours of work, or wage rates (Table 7.3).Statistically significant program gains in hours or work during theperiod of actual participation tended to be larger among youngerparticipants, females, white:., the more educated, those who left schoolbecause they wanted a job, those living with their parents, those 165 144 raisvd by both parents, and those with greater job training in the yearprior to enrollment. '-upported Work had no long-term impact on educa-tion and training decisions or on drug use. Similarly, there wereminimal long-term program effects on welfare dependence for youths, andcriminal activity was not reduced by the program.Results of the benefit-cost analysis of the program indicate thatfrom the societal viewpoint estimated costs exceeded estimated benefisby $1,465 per youth participant. While net costs were found to be quitesensitiveto the method of estimee-ing the value of output and projectcosts, none of the alternatives reversed the benefit-cost result.'Overall, the evaluation study appears to have been very careful inits attention to conditioning factors, random assignment, and the useof appropriate statistical techniques. We are therefore confident inthe stated finding of no postprogram effect for the severely dis-advantaged youths who participated in Supported Work. Supported Work Youth VariationStarting in July 1979 four Supported Work sites were selected toparticipate in a special variation of the program, the Supported WorkYouth Variation (Scharfman, 1981). The specia. variation was directedtoward 17- to 20-year-old high school dropouts, many of whom had ahistory of delinquency. Their experiences in the conventional SupportedWork program were unfavorable compared with the outcomes for othertargeted groups participating in the program. The variation sought toincorporate features not generally provided in the regular program,e.g., counseling, vocational education, skills assessment, andtraining; to extend the length of the program to 24 months; and toestablish a tangible link to long-term labor market success and therebyimprove in-program performance. Unfortunately, there was no comparisongroup for this follow-up study and therefore we did not find thereported results meaningful. On the basis of a special verification study conducted in threesites among ex-addicts and ex-c:ffenders in the sample, self-reportedarrests were found to be underreported by 46 percent, on average, byboth experimentals and controls. The study notes that the measuredunderreporting among those subgroups may or may not be generalizable tothe youth sample (Maynard, 1980). Before estimating the value ofreduced criminal activity, a factor of 1.7 is applied to the control-experimental arrest differential to correct for underreporting in thebenefit-r,,at calculations. As noted in regard to the Job Corpsevaluation (sec Chapter 6), no underreporting factor is generallyaccepted in the criminal justice literature. 166 145Public Versus Private Sector Jobs Demonstration ProjectThe Public Versus Private Sector Jobs Demonstration Project focusedon differences in postprogram employment and earnings between partici-pants in fully subsidized public sector jobs and those in fully sub- sidized private sector jobs. The target population was 16- to21-year-old, out -of- school youths eligible to participate in the YouthEmployment and Training Program (YETP) portion of CETA. Five YETPsites that were operating from January 1979 to April 1980 were selected for the demonstration project. Eligible youths who had completedpreliminary forms were matched in pairs within each site on the basisof age, race, sex, and their scores on a reading test and then randomlyassigned to a fully subsidized job slot in either the public or privatesector.The subsidized jobs paid the minimum wage and the 100 percentsubsidy lasted 25 weeks. A total of 2,100 participants began theprogram.As is typical, there was participant heterogeneity across the five sites.Information provided for our review documents the degree of effortrequired at each site to develop job slots with public and privateemployers.This information was disaggregated by industry for privateemployers and by functional areas for public sector employers. In general, more effort was required to place youths in private sectorqvbsidized jobs than in public sector subsidized employment.Forty-four percent (921) of the participants completed 25 weeks in the program.Completion rates were higher among females, blacks, andthose in public sector jobs (49 percent) than in private sector jobs(38 percent).Immediate postprogram information was gathered at the end of theprogram period and at 3 and 8 months after program termination. At the3-month follow-up only about 43 percent of the original sample could be located and interviewed (54 percent of completers and 34 percent ofnoncompleters). Among completers the full-time job rate was 50 :ercent for public sector participants compared with 64 percent for private sector participants. On the other hand the part-time job rate was 16to 17 percent for both public sector and private sector participants.Public sector participants exhibited a higher rate of enrollment ineducational or training classes (26 percent) than private sectorparticipants (18 percent). After controlling for various individualcharacteristics, private sector participation continued to beassociated with higher postrrogram employment rates.Results from the 8-month follow-up are derived from the approxi-mately 35 percent of the original sample who were located and inter-viewed (42 percent of completers and 29 percent of noncompleters).Although multiple regressions are not available for this period, theresults continue the earlier patterns among program completers: the full-time job rate was higher among private sector participants (61percent) than among public sector participants (52 percent), and thepart-time job rates were much the same for public sector (23 percent)and private sector (25 percent) participants. By the time of the8-month follow-up, none of the private sector rarticipants and only 4 percent of the public sector participants was in an educational or 167 146 training program. At the time of the 8-month follow-up, there wasvirtually no difference in the employment rate for completers (80percent) and noncompleters (78 percent), though the high attritionmakes even this statement problematic.We cannot conclude on the basis of the evaluation that there wasany difference in the effects of subsidized employment in the publicversus the private sector. Although private sector participation wasconsistently associated with higher rates of subsequent employment,adjustments for nonprogram-related characteristics considerablynarrowed the private sector advan*Ige. The evaluation of thisdemonstration project offers no basis on which to decide whether theeffort required to secure subsidized jobs in the private sector wasworth the additional cost. Although the study appeared to be verypromising in terms of both the nature of the project it described a41its re5eatch design, sample attrition severely limits the reliabilityof the reported findings. We are not confident, therefore, aboutdrawing conclusions about the effectiveness of the project. or about theissue of the desirability of subsidizing public sector compared withprivate sector jobs. PROGRAMS SERVING IN-SCHOOL YOUTHSTable 7.4 presents the characteristics of the two programs servingin-school youths. Table 7.5 summarizes the research design and resultsof the evaluations of those programs. Summer Youth Employment ProgramThe objective of SYEP was to provide economically disadvantagedyouths (14- to 21-year-olds) with summer work experience in order to\"assist these youths to develop their maximum occupational potentialand to obtain employment not subsidized under\" CETA (P.L. 95-524, Sec.481(b)).Program emphasis varied across sites. Some sites offeredvocational training, others provided job counseling, some a combinationof both.Time and resourze constraints were cited as the reasons fornot recording the precise program elements to which each participantwas exposed.Consequently, not ing can be learned about what sorts ofinterventions were particularly effective or ineffective in accomplish-ing program objectives. Sites also differed in terms of geographiccharacteristics, i.e., urban, suburban, and rural, and in terms ofadherence of eligibility criteria.The evaluation we considered is of the SYEP conducted at eightsites chosen by the Department of Labor in the summer of 1979. It isbased on data for approximately 2,000 youths who were ostensiblyrandomly chosen to participate or, if not accepted into the program ongrounds other than eligibility, to be in the comparison group. Approxi-mately 250 youths were divided betwen the participant and comparisongroups in each site. The treatment and comparison groups differedsignificantly in terms of some personal characteristics both across and 168 tj,t 17i1 TABLE 7.4Temporary Jobs Programs for In-School Youths: Program Characteristics Youth Project/ Program Services Target GrotT Length of ProgramEvaluator Approach Provided Characteristics Participbon Summer Youth Summer subsidized- Some supplemental In-school and out-of-school youths 10-week summerLmployment wurk experience services, such as 14-21 (SYEP)/ job counseling 47% blackA.L. Hispanic54% Part-time work during In-school and out-of-school youths x = 15 months Entitlement conditional on school year, full- 16-19 years oldPilot Project school enroll- time during summer 7.5Temporary Jobs Programs for In-School and Results YouthProgramSample SizeParticipant Control Comments In-program Fall 1979b Due to site implementationearnings (school year) total74%problems and other concerns+46% to +161% black = analysis to +65%Fall 1980total = youths = 34%increased employment-to-population comparabilityof control groups weakencredibility of results. aReters to all survey respondents in pilot sites where progr, operated, whether they participated or not. bRefers to total response rate, not necessarily the analysisample. BEST COPY AVAILABLE172 149within sites:participants were older, :ass likely to be black, andmore likely to have previously participated in CETA programs thancomparison group members.A specially designed time-use nonparticipants indicated that participants' emlloyment during theprogram war considerably greater than that of nonparticipants (100percent compared with 20 percent). Unfortunately, sample sizes in thetime-use study were quite small (68 participants and 65 nonparticipants)anc, therefore, the results are probably not very reliable (A.L. Nellum and Associates, 1980).Sample data were collected at the beginning and end of SYEP and at3 months postprogram. A program comp]etion survey instrument wasadministered to participants at the end of the program, but no surveywas administered to the comparison group at the corresponding point oftime.The 3-month follow-up su-vey was administered to both thetreatment and comparison groups. The postprogram analysis sample wascomposed of approximately 800 participants and 700 nonparticipants,which indicates that sample attrition was greater among nonparticipants.Attrition was not uniform across sites, however. The New York siteapparently had the worst experience--attrition among nonparticipantswas higher th;_il 70 percent. Cluster analysis was used within each siteto identify comparable subsets of experimentals and controls. Thisprocedure reduced the sample size by one-third to about 600individuals--14 cluster groups emerged from the analysis. Because of the degree of subjective data transformation present, the results ofthe cluster analysis are at best suggestive and at worst statisticalartifacts.A stepwise regression analysis of the determinants of hours spentin the program indicated that older youths, those with previopq CETAexperience, those with higher reading scores, and those withasseducation tended to spend more hours in the program.Race ah' sex aswell as Standard Assessment System measures had no significant effectson program hours per participant.At the pretest there were no significant differences between par-ticipants and controls in plans to return to school. At the time ofthe follow-up, 3 percent more of the participants than the controlswere in school. Although this difference turns out to be statisticallysignificant, it is of negli,ible magnitude. The overall imputedfavorable effect of SYEP on school attendance varied by cluster.SYEPappeared to be particula-ly successful in this regard for nondisadvan-taged 17-year-old black males, and particularly unsuccessful for 15- to16-year-old disadvantaged white males.Although the general emphasis of SYEP was to encourage continuedenrollment in school rather than to prepare participants for immediateentry into full-time employment upon program completion, the informationavailable did permit an examination of the immediate labor marketeffects of SYEP participation. Overall, at the follow-up there was nosignificant difference between participants and controls in the rate offull-time employment, but th_re was a relatively large and statisticallysignificant difference in part-time employment between participants (25percent) and controls (19 percent). This result is consistent with 173 150SYEP's goal of encouraging youths to return to school. The dataindicate that the program was particularly successfe. in raising thepart-time employment rate of severely disadvantaged 1J- year -old blackmales during the subsequent school year and particularly unsuccessfulin bringing about part-time employment fot severely disadvantaged15-year-old females.Overall, the p:ogram seemed to have no significant effect on thelikelihood of contact with the criminal justice system. Also, there isno evidence of program effects on attitudes toward such contact. Theresults did indicate mutually negative attitudes by participants andprogram personnel toward each other.It is not legitimate to treat the evaluation results as if theywere produced by a random experimental/control group design. Themanner in which participants and nonparticipants were chosen variedacross sites.Also, the evaluation report does not explain why theyouths who were eligible for SYEP, who constituted the compari-group, were not accepted for participation in SYEP. Although Lase studysuggests program participants gained in employment during the programand in part-time employment after the program, the evaluation designgoes not allow reliable inferences to be drawn about the effectivenessof the SYEP.As with other public employment and training programs in the 1970s,the question of displacement received come attention with regard toSYEP.The number of jobs provided in a public sarloyment program maynot be the net number of jobs created as a result of the programbecause some of the jobs would have existed even if there had been nospecial jobs program and because the participants who have jabs maydisplace others wno would have had the jobs had the program notexisted.To the extent that displacement occurs, it is argued, theusual estimates of the social benefits of the program may beoverestimates.The determination of whether displacement occurs for employment andtraining programs and, if so, to 'hat degree and in what ci-cumstances,is quite complex at both a practical and a theoretical level. Itshould be noted that while theory suggests that there may be displace-ment leading to overestimates of benefits as conventionally measured,there is also a theoretical possibility of replacement, if programparticipants are moved from a labor surplus market to a labor shortagemarket, in which case convectional methods woull overestimate costsand, thereby, underestimate the nct social benefits of the program[.scc, fyi c'ample, Johnson (1979) and Kemper (1980) for discussion ofthis issue].While estimating the degree of displacement is par-ticularly relevant in the context of estimating the net social benefitsand costs of a given program, society may still ask what proportion ofprogram output is over and above what would have existed in the absenceof the program.We reviewed two attempts to estimate displacement in the Sun 'rYouth Employment Program; one (Zimmerman, 1980) relied on data c,i-lected from personal interviews with program operators, and one (Craneand Ellwood, 1984) was based on aggregate data relating state-levelemployment to enrollment in SYEP and other variables. The study by 174 151Zimmerman is based to a considerable degree on supervisors' judgmentsabout what projects would have been undertaken in the absence of theprogram in the eight sites. It concludes that in 30 percent of thecases the output produced by SYEP project participants wculd have beenproduced at the same scale by elternative suppliers in the absence ofthe project\" (Zimmerman, 1980:77).The study by Crane and Ellwood takes an entirely different approach.Tha authors used vnpublished data from the Current Population Surveyfor the 12 largest scate., for 1972-1978, for the months of April, July,and October, in order to measure employment by race and age group, andunpublished program data for SYEP placements by race and age for thesame states over the same time period. The analysis relates employment-to-population rates for nonwhite 16- to 19-year-olds by state to of per civilian nonwhite 16- to 19-year-olds for thk,state, using various other employment and school measures to controlfor what employment would have been i- the absence of SYEP.In such a regression, the coefficient of the SYEP placement variableprovides an estimate of how much each SYEP placement increased theemployment rate for nonwhites aged 16-19 across the 12 states duringthat time period. Theoretically, if the SYEP job caused total displace-ment, the coefficient of the SYEP variable would be approximately zero;if there were no displacement the coefficient would be close to 1. Theauthors conclude (Crane and Ellwood, 1984:23): \"Regardless of thespecification, estimated supplementation effects of SYEP seemed to fallbetween .5 an .75. Thus our best estimates is that for each SYEP jobprovided to nonwhite youths, one-third of a job is lost in the privatesector for this group.\" Despite their assertion, oidy one of the fourequations yields an estimate that is significantly different from both1.0 and zero.Because of reservations we have about the precision of the estimatesand their statistical significance, we are not inclined to accept theestimates of displacement derived from this study. Overall, we do notbelieve that either the Zimmerman or Crane and Ellwood study providereliable estimates of the magnitude of displacement in the Summer YouthEmployment Program. Youth Incentive Entitlement Pilot ProjectsThe You:-. Incentive Entitlement Pilot Projects, which was mandatedunder YEDPA, was the largest YEDPA demonstration program. It costapproximately $240 million--$224 million for stipends and local programoperations and $16 million for monitoring and research (Disz et al.,1982:150)- and lasted 2-1/2 years (early spring 1978-August 1980) withan additional phase-out period of a year (fall 1980-summer 1981).Low-income youths aged 16-19 who had not yet graduated from high schoolconstituted the eligible target population for the program. The keyinnovation of the program was that all eligible youths who lived in thetarget area were entitled to a job if they met enrollment conditions.Eligible youths were guaranteed minimum-wage jobs, part-time during theschool year and full-time during the summer months.175 152To continue their participation in the program, participants wererequired to be enrolled in school or in an approved alternativeeducational program and to be making satisfactory progress toward ahigh school diploma. The short-run goals of the program were to reduceschool dropout rates, raise high school graduation rates, provide workexperience, and provide income during the program participation phase.The longer-term goal was to improve life-cycle labor market outcomes asa result of staying in school and receiving work experience (Farkas etal., 1984).In all there were 17 demonstration projects across the country, andmore than 70,000 youths participated. As implemented, the program hadfour major characteristics: 1.the average 15- to 16-year-old was enrolled in the program for15 months (13.4 in the full program plus 1.6 in the transition year);2.71 percent of the work experience jobs were in the publicsector;3.beyond provision of the job itself, very few services andlittle training was provided: two-thirds of the youths in the programreceived orientation, one-fourth were tested, and one-half receivedemployment counseling;4.the enrollment requirement was enforced but the schoolattendance and performance requirements were generally not enforced.YIEPP was not a skills training, job search, or behaviormodification program. Thus, any effects observea are due to the workexperience and school enrollment aspects of the program. In effect,the youths were provided with jobs and then left on their own tobenefit or not.The entitlement program was designed to saturate an area withjobs.Consequently, the prestnce of the program could have an effecton the employment of eligible youths even if they did not participatein the program since the total number of jobs available in the localarea would have increased. To account for this, an innovative approachwas taken in designing the evaluation--use of matched sites.Four of the largcscale sites were selected as pilot sites forevaluation purposes. Pour sites that did not have the entitlementprogram were selected as comparison sites. Cincinnati, a program site,was matched with Louisville; Baltimore with Cleveland; rural Mississippicounties with other rural Mississippi counties; and Denver with Phoenix.The evaluation technique was to estimate regressions on outcomes (e.g.,employment); the independent variables were individual characteristics(to control for factors nc,t accounted for by the match) and a dummyvariable indicating whether the person was in a program site; thecoeffic.-nt on the dummy variable is the program effect. Clearly, inusing this approach the quality of the match becomes critical.The evaluation was also designed to include all eligible youths,both participants and nonparticipants, in the pilot-site study group.This evaluation strategy can counter the selectivity bias that plaguesevaluations based on nonrandom selection of participants and controlsbecause those choosing not to participate can differ in signiiicant 176 153ways from those choosing to participate. This method also yieldsinformation on what the program participation rate might be given apermanent, ongoing program. Stratified random samples of eligibleyouths from the pilot sites and youths from the comparison sites whowould have been eligible had YIEPP operate. in their areas wereselected as the interview sample for the evaluation.Youths who were aged 15-16 at the start of the program constitutedthe study group for the final report so the steady state effects of apermanent program for 16- to 19-year-olds could be determined. Thisgroup was also selected because it was believed that older youths hadalready made career decisions prior to being aware of the program andthat this would contaminate pure program effects. In addition, theprogram participation rates of older youths were lower than those forthe younger group, e.g., through summer 1980 cumulative participationrates were 66 percent among 15- to 16-year olds and 46 percent among17- to 20-year olds.The sample for the final analysis was limited to blacks aged 15-16at the time of program enrollment because they constituted the over-whelming majority of participants and because most Hispanic youths tothe final evaluation sample were residents of Denver, a site that hadhad substantial implementation problems. In addition, white youths inthe sample were considered too small in number and too heavily concen-trated in the Cincinnati/Louisville pair (where a school busing con-troversy led to substantial changes in white school attendance) toprovide reliable separate estimates. The sample of black youths num-bered about 1,400 (excluding Denver/Phoenix); about 40 percent werefrom Baltimore/Cleveland and 30 percent each from Cincinnati/Louisvilleand rural Mississippi.Because. other large YEDPA programs were operating in the comparisonsites, the test was not one of the entitlement program compared with nothing.While the evaluation provides no way of judging how uignifi-cant a factor this characteristic is, as in other evaluations it wouldprobably lead to an underestimate of program effects since youths inthe matched comparison sites were able to participate in otheremployment and training programs.As noted above, he program was run as a full - fledged entitlemehtbetween spring 1978 and August 1980. During the transition periodbetween August 1980 and August 1981, the program operated at a reducedlevel with a limited number of openings. The true postprogramfollow-up period, as defined for purposes of the evaluation, was thepostoperation period during the fall semester of 1981.The follow-up period troublesome in several regare. First, itis not a long period in wh,ch to, observe postprogram effects, and itraises ser7ous concerns about taL extent to which effects that areobserved muy p sist over time. Second, the final interview coveredless that 2 months of the postprogram (i.e., postoperation) period forG2 r-rcent of the sample. While most youths for the programdinot rceive entitlement jobs during the transition period, theanalysis design depends on defining the postoperation period as thepostprogrperiod, since in theory the employment of eligible youthsmight be affected by the availability of an entitlement job. The 177 154 evaluation design does not permit examination of changes in programaffects over time because tine since leaving the program cannot be avariable in this design.There are statistically significant in-program and postprogrameffects on weekly earnings, largely attributable to enhanced employmentrates, but also due in a modest way to small but statistically sig-nificant increases in hours worked and wage rates received (in thepostprogram period). In-program earnings effects during the schoolyear were estimated to range between 46 and 161 percent higher thanweekly earnings in the absence of the program. Comparable earningseffects during the summer periods vary between 48 and 65 percent.During operation, the entitlement program significantly loweredunemployment rates and raised employment and labor force participationrates for young blacks as well as for all youths. The magnitude of theeffect was sufficient to eliminate substartially the employment andunemployment differentials between black and white youths eligible forthe program.Thus, employment-to-population rates for blacks increasedfrom 21.1 to 41.3 percent, and those of whites increased from 31.2 to37.4 percent during the program (Farkas et al., 1982). Unemploymentrates decreased during the program, from 72.1 to 51.7 percent amongblack eligibles and from 61.1 to 54.8 percent among white eligibles.An important finding of the YIEPP evaluation is that approximatelytwo-thirds of the youths eligible for the program did participate atsome time.This finding means, in part, that youths are willing towork at the minimum wage but thAt in the absence of a program likeYIEPP employers are unwilling to hire as many (at the minimum wage) whowish to work.It may also mean, in part, that in the absence of such aprogram in-school youths are not as likely to be in the labor force.YIEPP demonstrated that a system can be found to employ significantnumbers of disadvantaged youths.YIEPP jobs were largely in the public sector; private sectorinvolvement increased over time, but the participation rate of privatebusiness was generally low. The percentage of all youth job hoursspent working for private work sronsors increased from 14 percent inSeptember 1978 to 23 percent in June 1980.Although not empirically tested under entitlement, the effect ofvarying subsidy rates on __rate employers' willingness to participatewas estimated in Baltimore and Detroit using employers' responses tohypothetical questions: \"Would you be willing to act as a work sponsorat a 50 percent subsidy, a 75 percent subsidy, etc.\"? No comparisonwas made between expressed willingness to participate and actualbehavior (Ball et al., 1981). Only 5 percent of businesses said theywould participate if offered a 50 percent subsidy; 10 percent said yeswith a 75 percent subsidy. Even at a 100 percent subsidy, only 18percent of private employers surveyed said that they wouldparticipate.While the elasticity of the employer participation ratewith respect to changes in the subsidy rate appea-s high, i.e., adoubling of the subsidy rate more than doubles the indicated 178 155participation rate, this was not a true experimental test ofparticipation since there were no observations of actual behavior.The overall effects of YIEPP on secondary school enrollment andgraduation were generally inlonsequentlal, statist! ..111:! black females in 1981, a _atisticalYy signifi-cant reduction in college enrollment; otherw-se, the overall collegeenrollment effects are statistically insignificant, with some variationacross s-zes.This particular program effect is troubling and deservesfurther ocrutiny.In the postprogram follow-up semester, program earnings effectswere estimated to be 39 percent above weekly earnings in ''re absence ofthe program.These figures took the sites as the unit of observationand are based on average earnings. increases for all youths in the siteregardless of participation. If one assumes that the observed effectspersist for a year, there would be an estimate_ incre,lse r : $545 inannual earnings furDuring the rostprogram in the fall of 1981, labor forceparticipation _ztes rt2 the full youth cohort were higher than those ofthe comparison group, but unemployment rates were not significantlydifferent.Among young black eligibles, unemployment and labor forceparticipation rates were not significantly different from those of thecomparison group.Because of the scale of the entitlement effort and its potential asa model for future programs serving a substantial portion of the youthpopulatior, we devoted considerable effort to our review of thisevaluatie....We concluded that the YIEPP evaluation was a sound one andthat meticulous attention was paid to the problems inherent in thequasi-experimental (matched sites) design use3 in the evaluation. Thedrifting apart of mate' pairs of pilot and zomparison sites overtime, i.e., the Baltimore/Cleveland and Cincinnati/Louisville pairs,was recognf '.ed. The potential bias induced by attrition was sys-tematically investigated through a special attrition sample and foundnot to change the essential conclusions of the study.Although not enough information is available to determine thelong -germ afects of YIEPP, the finding that ther ass noteworthypositive in-program effects on the employment rates of black and whiteyouths is c)nvincing. Correction c,,rogram effects for ine-vidualcharacteristics using regression era-ft:Jig does not change theresults.Unfortlately, it is not possible to 'le as confident aboutother in-program effects or about effects generally for Hisparic orwhite youths because problems with the Denver/Phoenix andCincinnati/Louisville pairs severely reduced the number o. Hispanicsand whites in the study.Related to the discus.4on cc the magnitude of employmenteffects of the entitlement prrdgram is the issue of displacement or netjob creatThe report on in-program effects (Parkas et al., 1982) 15E.estimates that one new job was created for each 1.4 entitlement jobsfunLad in the public sects- and for each 2.2 jobs funded in the privatesector.The report also indicates that these assessments may be con-servative in the rense that they only measure the extent of displacementamong program-elijible youths and do i.)t include a measure of displace-ment of ineligible people (e.g., nondisadvantaged or out-of-schoolyouths or adults) who might otherwise have been hired.If these estimates are accurate, approximately 40 percent of themeasured employment change resulted from shifting people who would havebeen employed in the absence of the program. Such a fthding would haveimportant implications for the net effects of the program in terms ofjob creation, as well as obvious cost implications.We discussed earlier the complexities involved in estimating dis-placnment in connection with our review of the Summer Youth EmploymentProgram above, and many of those concerns apply here as well. lecausesamples of youths were drawn both in the entitlement pilot sites -.Ind inthe matched comparison sites, one could in theory capture one majorelement of the degree of displacement by usinj the comparison sitefigures to estimatn what the employment of entitlement-age youths wouldhave been had there been no entitlement project.This is essentially what Farkas et al. (1983) did by comparing theemployment rates in the pilot sites with thoszi in 1:ne comparison sitesduring the period of program operation for similar age-race groups andthen dividing the differences in employment by she number of entitlementjohs in the pilot sites to measure net job creation displacement. Theirestimate of the magnitude of net job creation is about 70 percent,implying displacement of round 30 percent. At the same time, controlsites probably had substantial numbers of youths in YEDPA and otherfederal employment and training programs, and so the lemming of fIEPPdisplacement, even if accurately measur,d, is not clearAnother study of displacement in the entitlement program 0:41ould etal., 1982) surveyed a sample of private firms, both those that hadactually provided jobs for entitlement participants and thoLa that hadnot.Information was gathered on the levels cf output and employmentin these firms before, during, and fter the period of the entitlementprogram.Using the data from the period before entitlement and forthose firms not directly hiring partici-flats, the authors developedeconometric models that provided estimates of what employment in thefirms would have beeA 'sad there not been an entitlement project. (Theanalysis was complicated by the fact that even in the preprogram periodmany of the employers had other subsidized workers, presumably fromCETA programs, in their firms.) The authors estimate that about 40percent of the jobs created through entitlement resulted in displa rment.While this was an imaginative and interesting effort, severalfeatures of it could lead one to question the precise matinitude of theestimate of displacement. First, the response rate to the initialsurvey was rather low (54 percent). Second, we have some doubts aboutthe ability of the econometric model based on limited preprogram datato e'ate what employment ..ould have been in the absence theprog.io when operating with a small sample of highly individualized 180 157firms in particular localities. Third, and perhaps most important,this method provides no indication of what happened to those workersand resources that were displaced from these particular firms. Didthey find alternative employment or remain unemployed? Since there isno market-wide measure of the degree of shortage, this important elementin the determination of the final degree of displacement is missing.We believe that the technical problems with each of the Ltudiesestimating displacement in the entitlement program are sufficient toprevent confidence in accepting any given point estimate of itsmagnitude.There remain several other concerns about the entitlement evalua-tion's findings. The in-program and postprogram findings vary con-siderably by site. As noted above, we are convinced that the positivein-program effects are sound, but we are not so convinced with regardto postprogram effects. The postprogram results for weekly earningsshow a ne:dye effect for Baltimore (relative to Cleveland), whileCincinnati had an equal absolute value positive effect (relative toLouisville) with a smalle sample size than 3altimore, and thf effectfor rural Mississippi was positive. Hence, the finding of ah overallpositive postprogram effect is influenced considerably by the resultsfor Mississippi.In other words, if the analysis is limited to urban sites, theaverage effect is zero or slightly negative. The researchers explainthe negative Baltimore effect by noting an unexpectedly healthyCleveland economy that might diminish the quality of the match overtime.Howt..er, Baltimore was described as the best run of theprograms.Because of across-site disparities in results and tscause itdoes not seem plausible to average rural and urban sites, theentitlement program results are most appropriately viewed is separatecase studies.It is therefore difficult to see how to extract resultson postprogram effects that are generalizeelle to the nation as a whole.The estimated postprogram effects of the entitlement program varyconsiderably across demographic subgroups as well as sites. Thepostprogram earnings effects for young black males are (nminaily)twice those for young black females, $13.66 and $6.13 respectively, butthe estimates for females are not significantly different from zero.The postprogram effect on weekly earnings fo older (17- to 20-year-old)black youths was $4.14, and the effect for 15- to 16-year-old whitesand Hispanics was one-sixth the size of the effect for comparableblacks, approximately $1.53 per week. 13oth effects were statistically'ignificant.\" \"Thies 'exult is based on the weighted averages of estimated weekly..\"-rlinga effects. The weekly earnings effect of $9.11 for the youngblack cohort (Denver/Phoenix included) declines to $7.4E for the fully,ung _ohort, i.e., when Hispanic and whit youths are added (Parkas etal., 1984).Using the sample weights, we computed the estimatedearnings effect for white and Hispanic youths (combined) as9.11 ni + X n2 $7.45, 181 158 Besides weekly earnings effects, other opt....xnes also differedconsiderably by sex. The school enrollment/graduation outcomes forfemales did not appear to follow any pattern. Overall the programappears to have reduced coliacre enrollment for females in two of thethree sites.There is no readily apparent explanation for this result,since high school graduation rates are not significantly lower in thosesites.Between the first interview and the last, the proportion ofyoung black females with one or more children . creased from 6 to 48percent in one site and varied substantially across the eites. TheestiL,ted employment-related effects for young neck women relative tomen are probably influenced to some degree by the high rates ofchildbearing that characterized young black females in the sample. SUMMARYThe evaluations of temporary jobs programs con2istently foundevidence that in-program earnings and employment were higher as aresult of the program. The findings of the Summer Youth EmploymentProgram evaluation tentatively suggested in-program gains in employ-ment, but we have only limited confidence in the evaluation. TheSupported Work and entitlement evaluations provided the strongestacidence on this issue.In the case of Supported Work, a program serving severely Cs-advantaged dropout youths, monthly in-program earnings of participantswere $?89 above those earned by the control group during the initial 3months after enrollment in the program. Youths eligible for theentitlement program earned, on average, up to $9 more per week duringthe School year than the comparison group and up to $10 more per weekduring the summer. Earnings of the black youth cohort were as much as$12-$13 higher than the comparison group's during both he school yearand the summer months (Farkas et al., 1982).For participants in Supported Work, 97 percent were employed duringthe first 3 months after enrollment: compared with 29 percent ofnonparticipants. Employment rates of young blacks in the entitlementprogram were up to 26 percentage points (235 percent) higher during theprogram than those of youths in the comparison sites.From this evidence we can generally conclude that temporary jobsprograms effectively increased employment for participante and, hence,served an income transfer goal that has been an underlying rationale inm 'y such programs. Without regard to the merits of thin particular where, n1 equals black youth cohort weight, n2 equals white andHispanic youth cohort Height, and X equals weekly earnings effect forwhite and Hispanic youths: $9.11 (.761) $0.335X - $1.52 182 159program goal, the extent to which the estimated employment effects of ajobs program translate into an increase in the total number of jobsavailable, an increase in the number of employed persors, or a decreasein the number of unemploytd persons may vary.While there is considemole disagreement about the proper way toestimate displacement in job creation programs, and a correspondingdistrust of any given point estimate of its magnitude, most researchersand policy makers acknowledge the displacement problem.' Fromsociety's point of view the nature of displacement may be as importantas its level.Thus, if a program displaces people who are moreadvantaged than participants, and who could easily find alternativeemployment, it may be considered less a problem than if the programdisplaces individuals who are equally disadvantaged (Masters, 1981).The estimated in-program effects on labor market outcomes otherthan employment rates and earnings were variable among the programs andfor lifferent target groups within most of the programs. The entitle-ment program significantly lowered unemployment rates and raised laborforce participation rates for all eligibles in the young cohort. AmongSupported work participants, gains in hours worked tended to be largeramong those who were younger, females, white, and more educated.Neither the Public Versus Private Sector Jobs Demonstration Project norVICI provided much information on in-program effects.Because the research design of the entitlement program required theability to measure postprogram effects it an entire youth labcr market(not only for participants), the postprogram period was defined as thetime following the close of the program. Thus, the postprogram periodfor the entitlement program was the fall semester of 1981, and 62percent of the black youth sample well interviewed within 2 months ofthe time the progr4m terminated.The entitlement program increased postprogram earnings of eligibleblack youths by the equivalent of $545 per year (assuming measuredpostprogram gains persisted) and raised postprogram hours worked foremployed black youths by 6 percent (from 32 to 34 hours per week).Employment rates were higher among blacks and 1.bor force participationwas higher for the full youth cohort. Neither labor force participation 'For example, the YEDPA authorizing legislation and the 1978 CETAamendments required the Secretary of Labor to make periodic reports onvarious aspects of the entitlement program, including displacement.Reports were to include findings leth respect to enrollment; costs; thedegree to which out-of-school youths returned to school or othersremained in school; the percentage of eligible youths participating;the kinds of jobs provided and a description of the employers--publicand private; the degree to which on-the-job or apprenticeship trainingwas offered; the estimated cost of extending the program to all areas;the effect of the program in reducing youth unemployment in the pilotareas; and the effect of program job opportunities on other oppor-tunities for youths in the area [P.L. 95-93 (YEDP:9, Sec. 420]. 183 160rates nor unemployment rates of the young black cohort of entitlementeligibles were significantly different from those of the comparisongroup in the short postprogram period (Farkas et al , 1982).There is lirited evidence on the long-term effects of participationin temporary jobs programs. The Supported Work program clearlyindicated no such effect for the severely disadvantaged dropouts itserved.The evidence frum the other studies is less clear, for avariety of methodological reasons. Most of the other studies analyzeda maximum of 8 months of postprogram experience, some as little as 3months.The VICI evaluation was designed to measure effects 8 monthsafter program participation, but was generally unconvincing.The studies of temporary jobs programs that we examined were notvery encouraging about the goal of raising school attendance rates,lowering drug abuse, or reducing negative encounters with the criminaljustice system. With respect to school retention, ..he summer jobsprogram evaluation offered questicnable evidence in support ofincreased school participation. The entitlement program had no effecton either school retention of youths already ill school or schoolcompletion by dropouts who had returned. 1 8 4 8Effectiveness ofJob Placement Programs The final type of program reviewed by the committee attempted toaid youths directly in finding employment. The programs usually^ffered some services in addition to job referral: workshops onpreparing resumes, instruction in appropriate behavior during a jobinterview, and support groups ;or job seekers supplemented the moretraditional job referral activities. While these programs offered somesvices that overlapped those we have previously termed labor marketpreparation, they are distinguished by their very concrete focus onsecuring employment, within a specified time period, for the youths indiaprogram.In addition, wage s'sidies (sometimes to emfloyers andibketimes to the youths themselves) were occasionally used as atnsitional device t( get youths situated in suitable jobs; the hopewas that the job would continue after the subsidy ended.Overall, the evaluation reports in the job placement category were,wtth one exception, generally weaker in methodological rigor than thoseOrressing other program goals. Ns a consequence, conclusions aboutthb effectiveness of job placement efforts are at best tentative. PROGRAMS FOR OUT-OF-SCHOOL YOUTHS Among the reports that passed ot: initial screening w. those offour projects that represented job placement efforts servi out-of-school youths:70001, Job Factory, Job Factory Voucher Program, andJob Track.Table 8.1 details the characteristics of each of theseprograms; Table 8,2 details the research design and results of theevaluations of the programs. 7000170001 was a job search program for out-of-school youths aged16-21.Enrollment was 60 percent female and 87 percent mincrity; theaverage participant was 18 years old; only 1 percent he3d high schooldegrees.The program consisted of an average of 32 hour: of treatmentinvolving job preparation workshops, jib search training, and thelike.Similar to other job search programs, it attempted to teach 161185 TABLE 8.1.Job Placement Programs for Out-of-School onbasis of theirrelative success)83 hours over 4 weeks Cambridge 104 hours over 4 weeks Cambridge 2-day program San Francisco 18r) BEST COPY AVAILAC' E187do TABLE 8.2Job Placement Programs Results SizeParticipantControl Rate Comments Comparison groupmatched ondemographiccharacteristics Random assignment Random assignmentto treatment andcontrol groups in 6 weeks 36 both an Increased empl?vmentvoucher only:70%voucher and jobsearch:58%control:51: employmentat 12 weekspostprogramFemale very make resultsquestionable BEST COPY AVAILABLE 189 164youths what employer3 expected, to teach them job search skills, and tomotivate them. Unlike some other programs, the evaluation reportindicates that the staff lid some (unspecified) amount of follow-upwith the youths after they had found a job.The research design by the Corporation for Public,-Irivate Ventures(CPPV) is a matched comparison of youths in five program cities; all ofthe evaluations were operated by the central organization. The samplesize was approximately 500 participants (all program entrants in thefive cities between January 1979 and April 1980) and 400 comparisonsdrawn from a variety of sources, including Employment Service registers,school dropout lists, and other sources. The report notes that anearlier evaluation with a shorter follow-up period found significantinitial gains followed by equally large decay effects for a similar jobsearch program (Jobs For Youth), while the initial gains for 7P\"?1 didnot appear to decay. An important question was whether this e,fect wasan artifact of the sampling procedure (program termination dates areuncertain and the follow-up may work to keep youths in jobs) or whetherthe effects persisted.The placement rate was 50 percent, and the cost per enrollee (in1979) was $1,351. The initial difference in earnings betweenparticipants and comparisons ($12 per week more or 35 percent higher)is statistically significant, but by 24 to 40 months after starting theprogram there is no significant difference between the earnings ofparticipants and comparisons. The evidence thus suggests that theprogram may provide a brokcring or screening function in hJping youthsto obtain job placements and that this effect decays with timenonparticipants' earnings eventually reach parity. The decay etfectpersists in multiple regression analyses controlling for variousindividual characteristics and does not change for various age, sex, orrace groups.With respect to job quality, at the 24- to 40-month follow-up, 25percent of the male participants and 5 percent of the female partici-pants held skilled jobs. For the comparison group, the figures were 21percent and 19 percent. The authors attribute the female pattern to ahigher rate of childbearing by the participants, but even when theanalysis is limited to women with no children, the comparison groupdoes as well as the participants.The program stressed completion of Lhe General Equivalency Diploma(GED), and there appears to be a significant long-term impacts 31percent of the participants received a GED compared with 12 percent ofthe comparison group. However, only 3 percent of the participantsreceived a regular high school degree compared with 9 percent of thecomparison group. Hence, the comparative results for educationalattainment are slightly lower than the GED results imply, but stillfavor the participants by a statistically significant amount. Thereare no other noticeable effects with respect to training, militaryservice, crime reduction, or the like.The report :autions that the evaluation sites were known to performbetter in terms of job placement than sites not chosen. Thus, thesample may not be representative of all 70001 programs operating duringthe 1979-1980 period. The response rate at 24-40 weeks postprogram was 165 87 percent, and there appears to be no substantial attrition bias(efforts were made to control for attrition bias).Participants and comparisons appeared to be matched closely interms of most demographic characteristics with the exception that atentry female participants had significantly fewer dependents thancomparison group females. The difference was no longer significant atthe 24- to 40-month follow-up, apparently because of higher rates ofchildbearing among participants. Female participants were alsosignificantly younger than nonparticipants.Overall, we believe that the results of the evaluation of the 70001sites studied are reliable, but the results may not be generalizable toall sites because the sample sites were known to be better than averageprior to selection. Job Factory Brandeis University evaluated job search assistance programs thatoperated in Cambridge, Massachusetts, and Wilkes-Barre, Pennsylvapia,from 1979 to 1980. However, because of severe implementation &if-3-culties with the program in Wilkes-Barre, we disregarded the portion ofthe report dealing with that program. The Cambridge program, the JobFactory, enrolled 50 youths in each of five cycles. The first and lastcycles were for graduating high school seniors and began the first weekin June of 1979 and 1980, respectively. The middle cycles were fordropouts.Youths in the first cycle and one of the middle ones receivedstipends of $3.10 per hour while the others did not. Each cycle lastedfour weeks and youths received an average of 83 hours of mo ivation,job search preparation, and role- playing.The research design used random assignment. The sample size wasapproximately 203 participants and 165 control individuals. Data werecollected on a variety of outcomes including the job finding rate, jobcharacteristics, job-finding methods used, and results of various testsin YEDPA's Standardized Assessment System (SAS) battery.Data from the first follow-up interview at 6 weeks postprogramindicated that, overall, participants were about one-third more likelyto be employed than controls (64 percent and 48 percent). By the timeof the final follow-up, at 36 weeks postprogram, the job finding rateswas slightly higher for the controls (82 percent were employed comparedwith 79 percent of participants).The quality of the first postprogram job did not differ a greatdeal between the two groups. A somewhat larger proportion of partici-pants were employed full time (67 percent compared with 53 percent).Differences in hourly wages appeared to favor participants slightly($3.50 compared with $3.40 per hour). Although the participants' jobsappear to be slightly better, this may be understood by the slightlylarger percentage of participants in jobs that were subsidized bypublic funds (20 percent and 16 percent). Of the seven psychometricscale items in the SAS battery only three were statistically sig-nificant at the .05 el and none was correlated with outcomes. 191 166The results for the seniors in the first cycle who received stipend..exhibited the same time pattern as did the results for dropouts. Aslightly higher percentage of the seniors held jobs over the course ofthe follow-up, but the differences were not great: e.g., athe finalfollow-up, job holding for seniors was 83.3 percent for participantsand 84.2 percent for controls; for dropouts, the numbers were 73.9percent and 78.6 percent, respectively.Various cost calculations indicate that the average cost per par-ticipant was $989, the cost per employed youths was $1,441, a:.the netshort-run cost per new job (i.e., jobs that would not have otherwisebeen found within the first 6 weeks postprogram) was $4,468.Attrition in the analysis sample was substantial. Responses to theinterview at 6 weeks postprogram were obtained from 64 percent of theparticipants and 52 percent of the controls; at 20 weeks postprogramresponse rates were 41 percent and 34 percent, respectively; by 36weeks postprogram the response rates were 26 percent and 20 perc..nt,respectively, with a total of 53 observations for participants and 33for controls.Significance tests of the differences in the mean characteristicsof jobs between controls and participants were not presented in theevaluation report. Given the small sample size, it is unlikely thatthe reported differences are statistically significant at conventionallevels, and we therefore cannot be very confider' about program effects,especially after 6 weeks. Job Factory Voucher ProgramThe Job Factory Voucher Program was a variation of the Job Factcrymodel in which youths received a wage subsidy if they found employmentquickly.The supplement was $1.50 an hour for the first 2 weeks ofwork and $1 an hour extra for weeks 3-12. Youths were recilited foreach of six 4-week cycles of the program between November 1980 andDecember 1981 and randomly assigned to one of three treatments: JobFactory plus voucher, voucher only, or no treatment.1The results show a peculiar pattern of effects. At 4 weeks post-program the full-treatment group does better than the voucher-onlygroup and the control (no-treatment) group. By 12 weeks thefull-treatment and voucher-only groups are eNal, and by 20 weeks thevoucher-only group does better than the full-treatment group. Fifty-eight percent of the full-treatment group worked between the second andthird follow-up compared with 70 percent of tne voucher-only group and51 percent of the control group. 1A Wilkec -Barre program that provided subsidies to employers was alsoevaluated,(Rivera-Casale et al., 1982) but because it experiencedsevere imrlementation problems and did not use a comparison group ofyouths not participating in the program, the committee decided that theresults did not provide reliable evidence. 192 167Attrition and resulting small sample sizes may account for some ofthe findings.Between the initial data collection and 20 weeks afterenrollment, attrition among participants in the full-treatment groupwas 20 percent, among the voucher-only group it was 82 percent, andamong the control group it was 38 percent. Final analyses are based onobservations for 60 controls, 23 participants in the voucher-onlygroup, and 128 in the full-treatment group.A number of other methodological problems in the evaluation arecause for concern: administrative implementation difficulties,changing characteristics of the youths over the course of the program,and interaction among youths in the different treatment groups.Consequently, we are not confident in the results of the Job FactoryVoucher Program evaluation. Job Tack Job Track was a job search assistance program that offered 2 daysof job search training followed by 3 days of support services toout-of-school youths who applied to local Employment Service offices.Participants were 16- to 21-year-old, out-of-school youths. Theprogram operated from July to December 1980 in San Francis..... OlympusResearch Centers was responsible for both operating the program anddoing the evaluation.Participant outcomes were compared with those of a matched compari-son group of nonparticipants. The evaluation sample was originallycomposed of 136 comparison group members and 103 participants, but theanalyses were actually based on 88 participants and 76 comparison groupyouths at the 6-week follow-up and 80 participants and 69 comparisongroup youths at the 12-week follow-up. The regression-adjusted resultsat 6 weeks postprogram suggest that participants were more likely thannonparticipants to be employed (46 percent compared with 28 percent).At the 12-week postprogram follow-up, the employment rates of the twogroups were 66 percent and 49 percent, but the difference was notstatistically significant. There were no apparent differenr 3 in jobsearch intensity or he number of methods used. About 5n percent ofthe youths in the ogram found employment without going through aformal interview procedure.Comparison group members differed from participants in two majorrespects that would suggest that comparisons were more employable: 30percent of comparison group members compared with 18 percent ofparticipants were independent (that is, neither family' heads nor familymembers), and 22 percent of comparison group members and 13 percent ofparticipants had some college training. We have limited confidence inthe findings of the effects of the original Job Track program.A modified program, Job Track II, operated for 10 weeks betweenMarch and June 1982. The new program offered a sOpend of $50, extendedthe program to 2 weeks, and differed from the earlier version in severalother respects. The Job Track II evaluation did not use a comparisongroup, but compared the outcomes of participants in the new programwith those in the earlier one. Therefore, we did not consider thefindings of the Job Track II program. 193 168PROGRAMS FOR IN-SCHOOL YOUTHSThe committee reviewed reports on three programs that provided jobplacement services for in-school youths: Jobs for Delaware Graduates,Jobs for America's Graduates, and Project Best. Table 8.3 details thecharacteristics of each of these programs; Table 8.4 details theresearch design and results of the evaluations of the programs. Jobs for Delaware Graduates Jobs for Delaware Graduates is a school-to-work transition programfor high school seniors. Begun in Delaware, it is currently beingreplicated throughout the country by a central organization, Jobs forAmerica's Graduates. We reviewed two evaluations: one of the originalDelaware program done by Temple University (discussed in this section)and one based on four sites done by Northeastern University (discussedin the next section).In the Jobs for Delaware Graduates (and Jobs for America'sGraduates) program, high schools first develop lists of seniors who arein the bottom of their class and who are eligible for the program. Theseniors participate in as many as three rounds of interviews and thenare selected to enter the program (34 percent of those interviewed wereselected in the programs that Temple University examined). The programconsists of job preparation workshops (e.g., resume writing andinterview techniques), a support club, assistance in job finding, andfollow-up after job finding by program counselors.The Temple evaluation for 1980 Delaware graduates used comparisongroups drawn from other Delaware high schools that were consideredcomparable but did not have the program. By 1981 too many high schoolsin Delaware had the program, so for the evaluation of that year Templeexamined the estimated changes in program effects from 1 year to thenext.This latter evaluation was of limited usefulness both becausefurther changes may have occurred and be-ause this methodology cannoteliminate effects of changes in the economy between the two periods.Hence our analysis focused only on the study of 1980 graduates.The researchers conducted follow-up interviews 3 and 8 months aftergraduation, but the program was still in effect even after 8 monthsbecause the counselors maintained some follow-up contact. Also, giventhe findings from other projects concerning decay, 8 months may not bea long enough follow-up period to assess postprogram effects.The differences in outcomes between participants and comparisongroup members at the time of the 3-month interview are all significantat the 1 percent level or better. The results indicate that partici-pants were more likely to be employed full time at the time of theinterview (56 percent compared with 36 percent), more likely to haveheld a full-time job (75 percent compared with 49 percent), an morelikely to have been employed since graduation, (84 percent comparedwith 73 percent). The results at 8 months postprogram indicate thatparticipants still fared significantly better than nonparticipants interms of employment, though the difference was smaller than at 3 months 194 TABLE 8.3Job Placement Programs for In-School Youths: Program aoncollege-bound high schoolseniorsServices Target Group Length of ProgramProvided Characteristics Participation Sites Job preparation Jrk-In-school youths 61 hours average Delaware JDGshops, job search high school seniors over school year sites andassistance, andfollow-up20-25% economicallydisadvantagedcompanion sites20% from familiesc' public School-to-work Job preparation work-37% minority44% maleIn-school youths Not specified JAG participatingtransition program shops, job search (participants and comparisons sites in Arizona,for noncollege- assistance, and combined) Massachusetts,bound high school follow-up x family income = $11,000 195 COPY AVAILABLEPhiladelphia inner-city high school 19ti A TABLE 8.4Jobs Placement Programs for In-School Youths: Research Design and Results YouthProgramSample Size Control/Comparison Follow-upParticipantControlGroup Methodology Program Effects Response Rate Comments Jobs for 666182Comparison groups At 3 months 3 months andDelaware's drawn from comparable employed full time +19% 8 months post-Graduates schools without JDG employed full time since graduation +25%(JDG) since graduation +25% .!.t 8 months 3 monthsemployed FT +9% P = 76%employed FT since C = 59%graduation +17%8 months= No differences in tenure, P72%wages, or type of jobs C = 67%until 8 months whenComparison group differed school year.111980-1981 school year.19Li 171postprogram (e.g., 58 percent of participants and 48 percent of nonpar-ticipants were employed full time at the 8-month interview).2The jobs held by participants and nonparticipants were similar interms of hours per week, skill level, and tenure. However, at 3 monthspostprogram participant wages on the most recent job were insignifi-cantly below those of the comparison group, but at 8 months theparticipants had an edge of 38 cents an hour (participants received$3.90 an hour in the late fall of 1980), and this was statisticallysignificant at the 10 percent level. Unfortunately, this is the onlyinstance of a statistically significant difference in the nature ofjobs held and hence should be viewed cautiously.There were no differences between the two groups in terms of theEducational Testing Service's (ETS) measures of job knowledge, workattitudes, or self-esteem. There was a significant difference in ameasure of job-seeking skills at 8 months postprogram that favoredparticipants.The job-holding gains of the participants were offset bythe nominally higher but statistically insignificant postgraduationschool attendance rates of the comparison group.Participants in the Jobs for Delaware Graduates programs differedin important respects from those in other programs whose evaluations wereviewed.All were high school seniors, so no dropouts were included,and potential dropouts may have been screened out. Only 20 to 25percent of participants were economically disadvantaged. The programinvolved an extensive preselection process that may lead to creaming,i.e., selection of those applicants who might be easiest to place. Atthe same time, the youths in these programs were not in college prepara-tory or vocational programs and were at the bottom of the class rankingin the general curriculum.The sample of participants was 25 percent economically disadvan-taged, 37 percent minority, and 56 percent female; 25 percent had pre-viously had a skilled or semiskilled job, and 72 percent had previouslyworked in a job paying at least $3.17 an hour. Participants' scoresfor the SAS reading test indicated a reading level of eighth grade orhigher.The comparison group had a higher percentage of minorityyouths (47) and a higher percentage of limited English speakers (6.3compared with 2.6), both of which might bias the results in favor ofthe program, but the comparison group had a better work history (81percent had previously worked and 48 percent had held skilled orsemi-skilled jobs).While the results were less favorable at 8 months than at 3 months,attrition may play an important role. Attrition among participants was24 percent 3 months after graduation and 28 percent 8 months aftergzaduation; among comparison group youths attrition was 31 percent at 3 2The L.ummary of the published report (Elegy and Leone, 1982) statesthat some key findings are insignificant while the body of the textstates that they are significant (Eleey and Leone, 1982); these incon-sistencies were corrected in an errata sheet from the authors that saysthe findings are statistically significant. 199 172months and 33 percent at 8 months after graduation. There is no indica-tion that attempts were made to adjust for possible attrition bias.Thus, differences in attrition rates may contribute to the measureddifferences in postgraduation experiences between participants andnonparticipants. Another potentially troubling issue on which thereport is silent is the treatment of dropouts. Since the participantsample includes only graduates, the appropriate comparison would benonparticipant graduates. Inclusion of nongraduates in the comparisonsample would probably tend to overstaue program effects on employment.The report presents what we found to be convincing evidence ofshort-term, i.e., 3-month, postprogram effects in increasing employment.The 8-month findings indicate a smaller effect and are less convincing.Because of sample attrition it is possible that what appears as a decayeffect is due at least in part to attrition. Jobs for America's GraduatesThe Northeastern University study of Jobs for America's Graduateswas sponsored by Jobs for America's Graduates and was a 6-monthfollow-up of spring 1982 graduates in four states: Arizona, Massachu-setts, Missouri, and Tennessee. The study used a matched comparisongroup methodology with a sample of 1,106 participants and 410 compari-sons.The total sample was 53 percent female, average family incomewas $11,000, and 95 percent of the sample were high school graduates.Data on participants were collected by program counselors during the 9montns of postgraduation follow-up visits.The results indicate that during fall 1982 participants fared sig-nificantly better than nonparticipants with respect to the probabilityof being employed, weeks employed, hourly wage rates. and weekly earn-ings.No analysis of intersite differences is provided, but based onother studies there is reason to believe that there would besubstantial variation across sites.Several considerations make us skeptical of accepting the resultsof the evaluation of Jobs for America's Graduates. First, the attritionrate at the 6-month follow-up was 6 percent for participants but 40percent for the comparison group; no adjustments were made for possibleattrition bias, and no data are presented that allow examination of theeffect of attrition on the match between participants and nonpartici-pants.Even if the results reported were robust, studies of similarprograms indicate that a 6-month follow-up period is too short to allowvalid inferences to be drawn about long-term program effects, which aresusceptible to decay. Finally, the extensive preselection proceduresused may have produced a participant group that is not generallyrepresentative of non-college-bound high school seniors, Project BESTThe Better Employment through Skills Training Project (ProjectBEST) involved 1 hour per day of labor-market oriented classroom 200 173training in conjunction with counseling and \"job shadowing\" for disad-vantaged minority high school seniors in an inner-city Philadelphiahigh school.The Temple University study of the project is of interestbecause it did not find employment gains for participants relative tothe comparison group at 3 and 11 months postprogram.The program operated during the 1979-1980 and 1980-1981 academicyears and served about 350 students. While the study suggests that theproject's job placement strategy was ineffective, its findings cannotbe taken as conclusive, inasmuch as the comparison group was not ran-domly selected (they were students at other Philadelphia high schools)and program participants were self-selected. While the evaluatorsacknowledged the selectivity bias inherent in this approach, they madeno explicit correction for it. SUMMARYWhile most of the evaluations of programs offering job placementservices to youths found the programs to be effective in securingemployment for participants, most of the evaluations had seriousmethodological flaws and therefore do not provide reliaUe evidence onthe question of effectiveness. Consequently, we do not believe one candraw strong inferences about program effects on the basis of thesestudies.Of all the evaluations of YEDPA job placement programs servingout-of-school youths, the CPPV study of 70001 comes closest to providingtrustworthy evidence of program effectiveness. The program reported a50 percent success rate in placing participants in jobs, and programcosts averaged $1,351 per enrollee. vor the demographic characteristicsreported in the evaluation, there is a reasonably close match betweenthe comparison and the participant groups. The only major differencebetween groups was that female participants in the 70001 program hadfewer dependents than the comparison group.Even for this study, however, we have questions. Besides the con-cerns generated by the use of a constructed comparison (rather than arandomly assigned control group), the selection of sites in the 70001evaluation is a cause for concern. The chosen sites were known to bebetter performers in terms of job placement. The resultant evaluationdata may thus provide an upper-bound estimate of what the 70001 programsachieved.While the design of the 701)01 evaluation is somewhat problematic,the execution and reporting of the research were rigorous (see CPPV,1983).In contrast to most of the studies we reviewed, the CPPVevaluators and their subcontractor, Institute for Survey Research,Temple University, obtained an 86 percent response rate at 24+ monthspostprogram.Moreover, the report is appropriately candid about thedesign problems of the study, and it presents detailed calculations anddiscussions of the potential effects of selection and attrition bias.Nine months after completion of 70001, participating youths earnedan average of $12 per week more than the comparison group. Thisdifference in earnings arose from increased employment rather than 2.11 174 differences in wage rates: 41 percent of 70001 youths and 29 percentof the comparison group were employed. A subsequent follow-upconducted 24-40 months after participation in 70001 found that thisprogram effect had decayed entirely: employment rates were 38 percentfor 70001 participants and 42 percent for the comparison group.On the basis of the 70001 study and other evaluations, there isevidence that the effects of job placement programs decay over time, sothat after 24 months there is no discernible difference betweenparticipants and nonparticipants on most outcomes.Two highly regarded programs for in-school youths, Jobs for DelawareGraduates and Jobs for America's Graduates, served a segment of theyouth population that was least in need of assistance in locatingsuitable employment--high school graduates, 75 percent of whom camefrom families that were not economically disadvantaged. While we foundthe evidence of short-term program effects convincing, any inferencethat results from such a program could be realized with economicallydisadvantaged populations or with school dropouts is highly speculative. 202 9Evidence of Program Effectivenessfrom National Data Bases In addition to the program-specific evaluations of YEDPA effective-ness that were reviewed in Chapters 5 through 8, there are severalevaluations that attempted to use large, representative nationalsamples to derive estimates of the impact of all federally fundedemployment and training programs. The most prominently used data basesin these studies were the Continuous Longitudinal Manpower Survey(CLMS) and a special youth sample of the National Longitudinal Survey(NLS).Both of these data bases involve relatively large samples- morethan 60,000 in the CLMS and more than 12,000 in the NLS--that are drawnin a manner designed to permit generalizations, for CLMS, to the uni-verse of participants in CETA programs, and, for NLS, to all Americanyouths.There was also a YEDPA attempt to collect data on the progressof its participants and activities. While the major charge of ourcommittee was to focus on the YEDPA knowledge development activities,we also reviewed the findings from studies using these other databases, and we evaluated the quality of YEDPA's Standardized AssessmentSystem.The results of our review of this research are presented in detailin Appendices A and D. In this chapter we summarize our conclusionsregarding this evidence. THE CLMS AND NLS DATA BASESThe studies based on the CLMS and the NLS use data gathered in adifferent manner and have a somewhat different (and wieer) focus thanthe program-specific evaluations, and so provide an important supple-mentary perspective on the substance and problems of the individualYEDPA evaluations we reviewed. Moreover, these studies use dataderived from samples with high sample-coverage rates and low sampleattrition, and consequently they can provide a more adequate evidentiarybasis (at least in respect to sampling mechanics) than many of theindividual program studies we reviewed.Both the CLMS and the NLS are full probability samples whosesampling designs appear to have been well executed. Sample coverageappears high, and the available documentation shows considerableattention to important methodological details, such as adequacy of 175203 176sampling frame, careful screening of respondents to ensure that theyare within the universe being sampled, extensive follow-up to ensure ahigh response rate, and so forth.For both the NLS and CLMS, comparison groups must be constructed.The basic goal in selecting a comparison group is to find a sample ofindividuals who closely resemble the participants in employment anetraining programs. Lacking an experimental design, in which individualsare randomly assigned to parcir_pant and control groups, a comparisongroup strategy is a next-best approach. (The problems inherent in thisstrategy are discussed below.)There are, nonetheless, important limitations to these data bases.First, they are not targeted on specific programs, aria so the estimatesof aggregate program effects may lump together the effects of effectiveand ineffective programs. Second, the data bases (particularly CLMS)limit the extent to which one can take account of the effects of locallabor market conditions. And tnird, the data were not derived fromexperiments in which subjects were randomly assignee to take part in aprogram; consequently, the estimates of program effectiveness requirestrong assumptions about the adequacy of model specification andmatching procedures used to construct synthetic control groups.Finally, we should point out that we received the CLMS -based reports indraft form late in the course of our work, and thus our evaluation ofthem has not been as intensive as that of the individual YEDPA reports. Findings From the CLMS The data from the CLMS have been analyzed by researchers fromWestat, Inc. (who concentrated mainly on adult participants in CETA),SRI International, and the Urban Institute. For youth participants inCETA programs, Westat (1984) reported that youth work-experienceprograms have statistically insignificant effects on employment andearnings for all cohorts and all postprogram years and did not resortother specific youth-related findings. The Urban Institute (Bassi etal., 1984:47), however, characterizes Westat's results from earlierreports as follows:In looking at youth, Westat (1982) has found that for thoseyoungsters 14 to 15 years old, CETA has had little over-Illimpact.For other young workers net gains are found, beinghighest once again for OJT [on-the-job training], followed byPSE [public service employment] and classroom training, andbeing negligible for work experience. The results found foryoung workers also tend to persist in the second postprogramyear.Westat (1981) also produced a technical paper focusingon youth in CETA in which net gains were broken down by sex.As with adults, net gains were greatest for young females,being negligible or insignificant for males. After classifyingyouth according :o their attachment to the labor force, netearnings gains were found to be greatest among structurallyunemployed or discouraged workers. 204 177SRI's analysis (Dickinson et al., 1984) differs from Westat's intwo key respects: the selection of the comparis-n group and thesampling frame, SRI's estimates of program effects were substantiallylower than Westat's (ak summarized by the Urban Institute (Bassi etal., 1984)], for both adults and youths, and the authors spend con-siderable time in identifying the sources of the differences. Fromtheir analyses, the SRI authors conclude that most of the differencescould be attributed to choices made in the sampling frame and to an,pdating of 1979 Social Security earnings.SRT's findings for 1976 CETA enrollees ere as follows:Participation in CETA results in significantly lower post-program earnings for adult men (-$690) and young men (-$591) andstatistically insignificant gains for adult women (+$13) and youngwomen (+$185).All program activities have negative effects for men, whileadult women benefit from Public Service Employment and young women fromon-the-job training. Work experience has negative effects for all ageand sex groups.Both male and female participants are more likely to beemployed after CETA, but males are less likely to be in high-payingjobs or to work long hours.Length of stay in the program has a positive impact onpostprogram earnings, with turning points for young men at 8 months andfor young women at I month.Placement on leaving the program leads fo positive earningsgains. The Urban Institute (Bassi et al., 1984) report focuses separatelyon youths.The analysts used Westat's match groups from the CurrentPopulation Survey (CPS) and estimated net effects for six race/sexgroups: male/female by white/black/Hisranic. Both random-effectsestimators and fixed-effects estimators were used to identify neteffects, bum the emphasis was on fixed-effects models to control forselection bias. Net effects were estimated for two postprogram years,1978 and 1979 (see Appendix D:Table D.2).The Urban Institute found the following: S'gnificant earnings losses for young men of all races and nosignificant effects for young women, with effects persisting into thesecond postprogram year.For Public Service Employment and on-the-job training,significant positive net effects for young women, particularlyminorities.For work experience, significant negative or insignificant neteffects for all groups.Among groups, the most negative findings were for white males,the most positive for minority females.Older youths (22-year-olds) and those who had worked less thanquarter time had stronger gains or smaller losses than the youngergroup or those who had worked quarter time or more. 205 1/8Earnings gains resulted primarily from increased time in thelabor force, time employed, and hours worked rather than from increasedaverage hourly wages. Findings From the NLS Two studies have used the NLS data base to make estimates of theaggregate effects of government-sponsored employment and trainingprograms on youths. One study (Moeller et al., 1983) was conducted bythe Policy Research Group (PRG) of Washington, D.C.; the second study(Hahn and Lerman, 1983) was conducted by the Center for Employment andIncome Studies (CEIS) of Brandeis University. Both studies evaluatedthe effects of CETA programs on youths although the PRG study expandedits scope to include such schooling programs as vocational education.The estimates made by both studies indicate relatively modesteffects of employment and training programs on the subsequent income,employment status, and educational atilinments of the youths whoparecipated in those programs. For ObTA programs, both studies findnegative overall effects of CETA on employment, although PRG reportssome positive effects at 2 years after CETA completion. Reviewing thePRG results and their own findings, Hahn and Lerman (1983:84) note:To conclude, both the PRG results and our own show negative andsignificant effects of CETA on employment variables. It isonly after going out two years in time after CETA completionthat the PRG report finds evidence of a positive, significanteffect and that on only one variable, unsubsidized earnings.We cannot confirm this positive effect, bt: it would not beinconsistent with our results. It is difficult to claim thisas an impressive success for CETA. The substantive findings from these NLS analyses are generallyconsistent with the weak and generally negative findings from the CLMSanalyses, anu we therefore do no' review them in great detail here. Limits.zo the Findings:Bias in Estimates of EffectivenessAcross 11-'e three CLMS studies, there is a pattern of preponderantlynegative net effects on youths, and the NLS studies show extremely weakeffects of program 'articipation. These results obviously invite theconclusion that feuerally funded employment and training programs havehad (in the aggregate) either little (ffect or a deleterious effect onthe future earnings and employment prospects of the youths who par-ticipated in the programs. There is, however, empirical evidence thatsuggests that these estimates may be biased.The evidence indicates that despite various intensive efforts toselect comparison groups that are similar to participants in youthprograms and to control for selection bias through the use of fixed- 206 179 effects estimators, there may still be persistent and systematic (butunmeasured) differences in the earnings profiles of comparison groupsand true controls. Such earnings differences, for example, might bedue to such unobserved factors as (perceived or actual) differencesbetween program participants and a constructed comparison group insocial attitudes, motivation, or ability.A study by Mathematica (1984) provides important evidence on thepotential for bias in the use of matching strategies such as thoseemployedthe NLS and CMS analyses reviewed above. The Mathematicastudy used data from a true experimental design that randomly assignedyouths to be either program participants or controls (the SupportedWork program). It then compared net-impact estimates derived using theexperimental design with estimates derived using the same sample ofprogram participants but substituting various \"matched samples\" con-structed from the Current Population Survey. The comparison groupswere constructed in a manner designed to simulate those used by theanalysts working with the CLMS data.Using the true control group, Mathematica found in-program earningsgains and negligible postprogram effects for youths. Using theconstructed matched samples, however, yielded either insignificant orsignificantly negative effects. Mathematica argues that biases in theestimates of program effectiveness are likely to exist in other studiesthat use similar comparison group strategies, which include the Westat,SRI, and Urban Institute studies using the CLMS and the studies basedon the NLS.A further finding of the Mathematica review is the substantialvariability in estimates made using different matching strategies onthe same data. Not only do the estimates derived from a true controlgroup differ substantially from those derived from a constructed matchsample, but the estimates of net impact derived using differentmatching strategies also differ substantially, from approximately +$122to -$1,303 (see Appendix D). Given Such a broad range of estimatedeffects and the sensitivity of estimatee program effects to alternativeassumptions, there must be cause for concern about the nature of theunderlying data.While one may argue about the generalizability of the Mathematicademonstration of bias and variability in the matched sample methodology,the finding has a precedent in the analysis of the Salk polio vaccinetrials (Meier, 1972). The Mathematics study highlights two separateproblems in net-impact estimations using a matched comparison group:(1) the extent to which employment and training programs recruit orattract participants who differ from eligible nonparticipants in waysthat affect subsequent earnings, and (2) the extent to which suchdifferences can be detected and controlled using available demographicor preprogram earnings data. Youths present a particularly difficultproblem for any such matching strategy since preprogram earnings dataeither do not exist or are not reliable indicators of the uncontrolledvariables that are of interest to program evaluators.Estimates of the magnitude and direction of the bias in matched-group evaluations are only available for the one youth program(Supported Work) whose experimental data were reanalyzed by Mathematica. 237 180From this reanalysis we have an elegant demonstration of the fact thatcommonly used matched comparison group strategies have yielded aninappropriately negative evaluation when the experimental data indicatethat the program had a null impact.There is a natural temptation on the basis of this one result toconclude that biases equal in magnitude and direction affect othetcomparison group studies. However, there is too little evidence towarrant such a generalization. All we know for certain is that thepotential for substantial bias exists in studies that use matchingtechniques rather than random assignment and that when such biases dooccur they can lead to serious errors of inference. (Of course, biasesin either direction are theoretic.'lly possible.)Until further work is done, there will be considerable uncertaintyas to the extent to which the Mathematica :*nding generalizes to otherprogram evaluations and to different populations of youths. In orderto obtain the requisite data, there will have to be a renewedcommitment to randomized experiments so that estimates of the magnitudeand direction of these biases can be made. YEDPA STANrkRDIZED ASSESSMENT SYSTEM A ,rational data base different in major respects from the CLMS andNLS was established by the Educational Testing Service under theauspices of the Office of You\"-1 Programs. A key element of YEDPA'sknowledge development strategy called for the establishment of astandardized system for the systematic collection of data on theprogress of program participants and the services provided Sy YE) Aprograms.The intent of YEDPA's data gathering as to provide astandardized data base with which to assess the performance of thevarious YEDPA demonstration projects.This data collection plan was called the Standardized AssessmentSystem (SAS).It was intended to provide preprogram, postprogram, andfollow-up (after 3 and 8 months) data for all youths enrolled in !EDPAdemonstration programs. The data collected by SAS included an intakeinterview, a reading test, and seven scales designed to measure occupa-tional knowledge, attitudes, and related skills. In addition, processdata were collected from program sites concerning the implementation ofthe programs and the services offered at those sites.In order to investigate the characteristics of the SAS data base,we obtained a copy of the data base (minus individual identifiers).Appendix A presents in detail our assessment of its sampling adequacy,measurement reliability, and measurement validity. Overall, thisanalysis suggests that sample coverage was poor and subsequent attrition,rates were extremely high. Using program operators' reports ofenrollment at 166 sites to estimate the size of the target sample forthose sites, we found that the majority of the target sample was missed 208 181 entirely.'This sample coverage problem was compounded by highattrition over time: at 3 months postprogram more than 40 percent ofthe initial sample had been lost. In addition, our examination of theattitude and knowledge measurements in the SAS data base indicated thatthose measures had low levels of stability over time and that they wereonly weakly correlated with subsequent success in the job market.The problems evident in our examination of the SAS data collectioneffort invite the question of how this might be avoided in the future.In Chapter 1 we present a number of specific recommendations in thisregard.There are, however, two more general lessons that should belearned from this experience.First, the scope of a research effort should match the resourcesavailable.In the case of SAS, it is questionable whether any researchpurpose required that data be gathered from all participants at allsites, but in any event, the available resources were inadequate forsuch a task.Well-collected data on a sample of participants orprogram sites would have been much better than the ambitious but poorlyexecuted data-gathering strategy used by SAS.The second, and related, lesson concerns the dangers of usingprogram operators to collect research data. Collection of researchdata in a longitudinal study is a demanding task. Like all survey datacollections, it requires vigorous follow-up efforts to obtain data frompersons who initially refuse to be interviewed or who are hard toreach.It also requires continued contact with respondents over timeso as to minimize attrition, together with careful efforts to tracepersonsmove.White it may seem economical to use programpersonnel for such tasks, the experience of SAS--and otherefforts--suggests that it is a false economy. 'This estimate is derived from reported enrollments for sites thatprovided process data for the SAS. Of the 458 sites that providedparticipant data, only 166 also provided such process data. Obviouslyit is not possible to tell whether sites that did not provide suchprocess data had higher or lower rates of sample coverage than sitesthat did provide process data. 209 References A.L. Nellum and Associates1980Impacts of SYEP Participation on Behavior Final Report. Washington,D.C.:A.L. Nellum obsL.vations and I.V. Sawhiil, Englewood Cliffs, N.J.: B.J., K. Flaherty, D.M. Geller, and Improvement Effort: Phase III FinalReport.Washington, D.C.: Team B.A., and N.D. Rothwell1984Measuring employment and unemployment. Pp. 129-142 in C.F.Turner and E. Martin, eds., Surveying Subjective Phenomena.Volume 2.New York:Russell Sage Foundation and Basic Books.Ball, J., and C. Wolfhagen, with D. Gerould, and L. Solnick1981The Participation of Private Businesses as Work Sponsors inthe Youth Entitlement Demonstration. New York:ManpowerDemonstration Research Corporation.Barth, the EconomicallDisadvantaged. Washington, D.C.: The Urban Institute,Becker, G.1957The Economics Chicago Press.Betsey, C.L., and B.H. Dunson1981Federal minimum wage laws and the employment of minorityyouth.American Economic Association Papers and ProceedingsMay:379-384.Borjas, G.1983The Demographic Determinants of the Demand for Black Labor.Paper presented at Conference on Inner City Black Youth 183210 184 Unemployment, sponsored by Harvard University and the NationalBureau of Economic Research, Cambridge, Mass.Bowers, N.1981Have employment patterns in recessions changed? Monthly LaborReview February:15-28.Brown, C., C. Gilroy, and A. Kohen1982The effect of the minimum wage on employment andunemployment..Journal of Economic Literature 20:487-528.Bureau of the Census1973Volume 1, Characteristics of the Population; Part 1, UnitedStates Summary-Section 2. Chapter D:DetailedCharacteristics. Washington, D.C.: U.S. Department ofCommerce.1979Iustrative Projections of World Populations to the 21stCentury.Current Population Reports, Series P-23, No. 79.Washington, D.C.: U.S. Department of Commerce.1982Projections of the Population of the United States:1982-2050.Current Population Reports, Series P-25, No. 922.Washington, D.C.: U.S. Department of Commerce.1984\"ertility of American Women. Current Population Reports,23ries P-20, No. 395. Washington, D.C.: U.S. Department ofCommerce.Bureau of Labor Statistics1982Labor Statistics Derived from the Current Population Survey.Washington, D.C.: U.S. Department of Labor.1983Handbook of Labor Statistics. Bulletin 2175. Washington,D.C.:U.S. Department of Labor.1984Employment of School Age Youth, Graduates and Dropouts.Washington, D.C.: U.S. Department of Labor.Cain, G.G.1968Benefit/Cost Estimates for Job Corps. Unpublished paper.Institute for Research on Poverty, University of Wisconsin.Cogan, J.F.1982The decline of black Controls in YouthEmployment and Demonstration Projects Act (YEDPA) Programs:information Derived from the Standard Assessment S stem DataBase.Final Data Base Report No. 1, Technical Report No. 23.Princeton, N.J.: Educational Testing Service.Congressional Budget Office1978Youth Unemployment: The Outlook and Some Policy Strategies.Washington, D.C.: Congressional Office.1982Improving Youth D.C.: Congressiona., Budget Pp. 391-425 in R.B. Freeman and D.A. Wise,eds., The Youth Labor Market Problem: Its Nature, Causes, andConsequences.National Bureau of Economic Research ConferenceReport.Chicago, Ill.: University of Chicago Press. 211 185Corporation for Public/Private Ventures1983Longer Term Impacts of Pre-Employment Services on theEmployment and Earnings of Disadvantaged Youth. Philadelphia,Pa.:Corporation for Public/Private Ventures.Crane J., and D.T. Ellwood1984The Summer Youth Employment Program: Private Job Supplementor Substitute. Prepared for the U.S. Department of Health andHuman Services, under Grant No. 92A-82. Cambridge, Mass.:Harvard University.Culp, J.M., and B.H. Dunson1983Brothers of a Different Color: A Preliminary Look at EmployerTreatment of White and Black Youth. Unpublished manuscript.Diaz, W.A., J. Ball, C. Wolfhagen, with J. Gueron, S. Sheber, ana A.Widman1982Linking School and Work for Disadvantaged Youths, The YIEPPDemonstration: Final Implementation Report. New York:Manpower Demonstration Research Corporation.Dickinson, K.P., T.R. Johnson( and R.W. West1984An of CETA Programs onEarnings.Menlo Park, Calif.: SRI International.Duncan, O.D.1984Notes on Social Measurement: Historical and Critical. NewYork:Russell Sage Foundation and Basic Books.Educational Testing Service1980Knowledge Development Framework: The Standardized AssessmentSystem.Youth Knowledge Washington,D.C.:U.S. Department of Labor.Eleey, M.F., and R.D. Leone1982An Evaluation of the Program Effects of Jobs-for DelawareGraduatesInc.Center for Labor and Human Resource Studies.Philadelphia, Pa.: unemployment: permanent in Freeman and D.A. Wise, eds., The YouthLabor Market Problem: Its Nature, Causes, and Consequences.National Bureau of Economic Research Conference Report.Chicago, Ill.: University of Chicago Press.1983The Spatial Mismatch Hypothesis: Are There Teenage JobsMissing in the Ghetto? Paper presented at Conference on InnerCity Black Youth Unemployment, sponsored by Harvard Universityand the National Bureau of Economic Research, Cambridge, Mass.Ellwood, D.T., and D.A. Wise1983Youth Employment in the Sevent%es: The Charging Patterns ofYoung Adults.NBER Working Paper No. 1055. Cambridge,Mass.:National Bureau of Economic Research.Farkas, G., D.A. Smith, and E.W. Stromsdorfer1983The youth entitlement demonstration: subsidized employmentwith a schooling requirement. Journal of Human Resources18(4):557-573. 212 186Farkas, G., R. Olsen, E.W. Stromsdorfer, L.C. Sharpe, F. Skidmore, D.A.Smith, and S. Merrill1984Post-Program Impacts of the Youth Incentive Entitlement PilotProjects.New York:Manpower Demonstration ResearchCorporation.Farkas, G., D.A. Smith, E.W. Stromsdorfer, G. Trask, and R. Jerrett, III1982Impacts from the Youth Incentive Entitlement Pilot Projects:Participation Work and Schooling Over the Full Program Period.New York:Manpower Demonstration Research Corporation.Feldstein, M., and D. the problem? Pp. 17-33 in R.B.Freeman and D.A. Wise, eds., The Youth Labor Market Problem:Its Nature, Causes, and Consequences. National Bureau ofEconomic Research Conference Report. Chicago, Ill.:University of Chicago Prerl.Fleisher, Noss.: R.B.1973Changes in the labor market for black Americans, 1948-1972.Brookings Papers on Economic Activity, No. 1. Washington,D.C.:The Brookings Institution.1980Why is there a youth labor market problem? Pp. 6-32 in B.E.Anderson and Prentice-Hall.1982Economic determinants of geographic and individuta variationin labor market position of young persons. Pp. 115-154 inR.B. Freeman and D.A. Wise, eds., The Youth Labor MarketProblem:Its Nature, Causes, and Consequences. NationalBureau of Economic Research Conference Report. Chicago,Ill.:University of Chicago Press.Freeman, R.B., and H.J. Holzer1985Young blacks and know. Public Interest78:18-31.Freeman, R.B., and J.L. Medoff,1982Why does the rate of youth labor force activity differ acrosssurveys?Pp. 75-114 in R.B. Freeman and D.A. Wise, eds., TheYouth Labor Market Problem: Its Nature, Causes, andConsequences.National Bureau of Economic Research ConferenceReport.Chicago, Ill.: University of Chicago Press.Freeman, R.B., and D.A. Wise, eds.1982The Youth Labor Market Problem: Its Nature, Causes, andConsequences.National Bureau of Economic Research ConferenceReport.Chicago, Ill.: University of Chicago Press.Fuller, W.C., and V.I. Nelson1982A Framework For Synthesis of Youth Demonstration ProjectsData.Unpublished paper. 213 187 Goldstein, J.H.1973The effectiveness of manpower training programs: a review ofresearch on the impact on the poor. Studies in PublicWelfare, Paper No. 3. Subcommittee on Fiscal Policy, JointEconomic Committee of the Congress the United States.Washington, D.C.: U.S. Government Printing Office.Gould, W., M. Ward, and F. Welch1982Measuring Displacement; An Econometric Approach. Los Angeles,Calif.:Unicon Research Corporation.Gueron, J.1984Lessons From a Job Guarantee: The. Youth Incentive EntitlementPilot Project. New York:Manpower Demonstration ResearchCorporation.Hahn, A., and R. Lerman1983The CETA Youth Employment Record. Washington, D.C.: U.S.Department of Youth Employment Policy? Washington, D.C.: NationalPlanning Association.Hall, R.E.1982The minimum wage and job turnover in markets for youngworkers.In R.B. Freeman and D.A. Wise, eds., The Youth LaborMarket Problem: Its Nature, Causes, and Consequences.Chicago, Ill.: University of Chicago Press.Hashimoto, M.1982Minimum wage effects on training on the job. AmericanEconomic Review 72:1070-1087.Heckman, J.J.1979Sample selection bias as a specification error. Econometrica47(January):153-161.Hindelang, M.J., T. Hirschi, and J.G. Weis1981Measuring Delinquency. Volume 123, Sage Library of SocialResearch.Beverly Hills, Calif.: Sage Publications.Johnson, G.E.1979The labor market displacement effect in the analysis of thenet impact of manpower training programs. Pp. 227-257 in Paper: in Benefit-Cost Analysis. Princeton, N.J.:Mathematica Policy Research.Kerachsky, S., and C. Mallar1977Evaluation of the Economic Impact of the Job Corps Program:Interim Reportt_Volume I. Princeton, N.J.: MathematicaPolicy Research.Kos ters, M., and F. Welch1972Effects of the minimum wage on the distribution of changes inaggregate employment. American Economic Review 62:323-332.Lazear, E.P., Pnd F.H. Miller1981Minimum wages versus minimum compensation. In Minimum WageStudy Commission, Report of the Minimum Wage StudyCommission.Washington, D.C.: U.S. Government PrintingOffice.214 NirIn Miaow 188 Leonard, J.S.1984The Interaction of Residential Segregation and EmploymentDiscrimination. NBER Working Paper No. 1274. Cambridge,Mass.:National Bureau of Economic Research.Lerman, R.I.1980aAn analysis of youth employment problems. In Vice President'sTask Force on Youth Employment, A Review of Youth EmploymentProblems, Programs and Policies. Volume I.Washington,D.C.:U.S. Government Printing Office.1980bThe Future of the Youth Employment Problem: A Review Paper.Technical Analysis Paper No. 69, Office of the AssistantSecretary for Policy, Evaluation and Research. Washington,D.C.:U.S. Department of Labor.Mallar, C., S. Rerachsky, C. Thornton, and D. Long1982Evaluation of the Economic Impact of the Job Corps Program,Third Follow-Up Report. Princeton, N.J.: Mathematica PolicyResearch.Mare, R.D., and Convergence Paradox of BlackYouth Joblessness: Enrollment, Enlistment, and Employment1964-1981.NORC Economics Research Center Discussion Paper.Chicago, Ill.: National Opinion Research Center.Masters, S.1981The effects of Supported Work on the earnings and transferpayments of its AFDC target group. Journal of Human Resources16(4):600-636.Mathematica Policy Research1984An Assessment of Alternative Comparison Group Methodologiesfor Evaluating Employment and Training Programs. Princeton,N.J.:Mathematica Policy Research.Maynard, R.1980The Impact of Supported Work on Young School Dropouts.Princeton, N.J.: Mathematica Policy Research.Maynard, R., E. Cavin, and J. Schore1982Post-Program Iripacts of Supported Work on Young SchoolDropouts:Results from a Follow -Up Survey. Princeton, N.J.:Mathematica Policy Research.Meier, P.1972The biggest public health experiment ever: the 1954 fieldtrial of the Salk poliomyelitis vaccine. In J. Tanur, ed.,Statistics:A Guide to the Unknown. San Francisco, Calif.:Holden-Day.Meyer, R., and D. Wise1982High school preparation and early labor force experience. Pp.277-347 in R.B. Freeman and D.A. Wise, eds., The Youth LaborMarket Problem: Its Nature, Causes, and Consequences.National Bureau of Economic Research Conference Report.Chicago, Ill.: University of Chicago Press.Mincer, J.E.1976Unemployment effects of minimum wages. Journal of PoliticalEconomy 84:S104. 215 189 Minimum Wage Study Commission1981Report of the Minimum Wage Study Commission. Washington,D.C.:U.S. Government Printing Office.Moeller, J., R. Hayes, and I. Witt1983Socioeconomic Impacts of Recent Government-SubsidizedEmployment and Training Programs on Youth. Washington, D.C.:Policy Research Group.Murphy, R.T., and L.R. Appel1981Assessment of the National Puerto Rican Forum School to WorkProgram, Year 1, October 1979-June 1980. Technical Report No.11.Princeton, N.J.: Educational Testing Service.National Commission on Employrr nt and Unemployment Statistics1979Counting the Labor Force. Washington, D.C.: U.S. GovernmentPrinting Office.National Council on Employment Policy1980a An Anatomy of School-to-Work Transition Projects. Prepared byB. Dunn and R. Taggart. Washington, D.C., National Councilon Employment Policy.1980b Getting There: A Case Study Report on the Lives, EmploymentPreparation, and Prospects of YEDPA P;:ticipants. Based onthe findings of the Youth Perspectiv.,1! Project, November1978-June 1979. Prepared by B. 3nedeker. Washington, D.C.:National Council on Employment Policy.1980cOverview to the Local Focus on Youth: A Review of PrimeSponsor Experience Implementing the Youth Employment andDemonstration Projects Act. Prepared by G. Wurzburg.Washington, D.C.: National Council on Employment Policy.1980dYouth and the Local Employment Agenda: An Analysis of PrimeSponsor Experience Implementing the Youth Employment andDemonstration Projects Act. Overview and Area Summaries,Final Report.Prepared by G. Wurzburg. Washington, D.C.:National Council J.U.1984Minority Education and Caste. New York:Academic Press.1985aCultural Boundaries and Minority Youth Orientation TowardWork.Paper delivered at Symposium on Adolescents'Orientation Toward Work, Institute for Human Development,University of California, Berkeley.1985bStockton, California, revisited: joining the labor force. InK.M. Borman, ed., Becoming a Worker. New York:Ablex.Osterman, P.1980aThe employment problems of black youth: a review of theevidence and some policy suggestions. In Vice President'sTask Force on Youth Employment, A Review of Youth EmploymentProblems, Programs and Policies. Volume II.Washington,D.C.:U.S. Government Printing Office.1980b Getting Started: The Youth Labor Market. Cambridge, Mass.:MIT Press.Perry, C., B. Anderson, R. Rowan, and H. Northrup1975The Impact of Government Manpower Programs in General, and onMinorities and Women. Industrial Research Unit, The WhartonSchool.Philadelphia:University of Pennsylvania. 216 390Polit, D., J. Kahn, and D. Stevens1985Final Impacts From Project Redirection: A Program foramant and Parenting Teens. New York:ManpowerDemonstration Research Corporation.Presser, H., and W. Baldwin1980Child care as a constraint on employment: prevalence,correlates, and bearing on the work and fertility nexus.American Journal of Sociology 85:1202-1213.Rees, A., and W. Gray1982Family effects in youth employment. Pp. 453-473 in R.B.FreJman and D.A. Wise, eds., The Youth Labor Market Problem:Its Nature, Causes, and Consequences. Chicago, Ill.:University of Chicago Press.Reimers, C.W.1983Labor market discrimination against Hispanic and black men.Review of Economics and Statistics 65:570-579.Rivera-Casale, C., B. Friedman, and R. Lerman1982Can Employer or Worker Subsidies Raise Youth Employment? AnEvaluation of Two Financial Incentive Programs forDisadvantaged Youth. Center for Employment and IncomeStudies, Heller Graduate School. Training: TheEvaluation of Various Categories of YEDPA Program Sites.Final Data Base Report No. 2, Technical Report No. 24.Princeton, N.J.: Educational Testing Service.Rossi, P.N., and M.D. Ornstein1973The impact of labor market entry factors: illustrations fromthe Hopkins Social Accounts Project. In W. Muller and K.U.Mayer, Social Stratification and Career Mobility. Paris:Mouton.Scharfman, V.S.1981The Supported Work Youth Variation: An Enriched Program forYoung High School Drop-outs. New York:ManpowerDemonstration Research Corporation.Stevenson, W.1978The relationship between early work experience and futureemployability. In A. Adams and G. Mangum, eds., The LingeringCrisis of Youth Unemployment. Kalamazoo, Mich.: UpjohnInstitute for Employment Hartmann, eds.1981Women, Work, and Jobs of Equal Value.Committee on Occupationcl C.assification and Analysis,National Press. 21? 191 Trismen, D.A.1982Assessment of the National Puerto Rican Forum Program,1980-1981.Technical Report No. 20. Princeton, N.J.:Educational Testing Service.Turner, C.F., and E. Martin, eds.1981Surveys of Subjective Phenomena: Summary Report. Panel onSurvey Measurement of Subjective Phenomena, Committee onNational Statistics, National Research Council. Washington,D.C.:National Academy Press.1984Surveying Subjective Phenomena. Panel on Survey Measurementof Subjective Phenomena, Committee on National Statistics,National Research Council. New York:Russell Sage Foundationand Abstract of United States 1980-82. Washington,D.C.:U.S. Department of Commerce.1985Statistical Abstract of the United States: Department of Commerce.U.S. Department of Labor1978Em Re rt of the Preaident. Annualtoreport.Washington, D.C.: U.S. Department of Labor.19821980aFactbook on Youth. Youth Knowledge Development Report 2.5.Washington, D.C.: U.S. Department cf Labor.1980bKnowledge Development Activities Fiscal 1978-1979. Development Report. Washington, D.C.: U.S.Department of Labor.1980cKnowledge Development Framework: The Knowledge DevelopmentAgenda.Youth Knowledge Development Report. Washington,D.C.:U.S. Department of Labor.1985aEconomic Report of the President. Washington, D.C.: of and of Labor.U.S. General Accounting Office1979More Effective Management is Needed to Improve the Quality ofthe Summer Youth Employment Program. Washington, D.C.: U.S.Government Printing Office.Venti, S.F.1984The effects of income maintenance on work, schooling, andnon-market activities of youth. Review of Economics andStatistics 66:16-25.Venti, S.F., and D.A. Youth.Unpublished manuscript.Vice President's Task Force on Youth Employment1980A Review of Youth Employment Problems, Programs and Policies.Volume 1.Washington, D.C.: U.S. Government Printing Office. 218 192wachter, M., and C. Kim1982Times series chahges in youth joblessness. Pp. 155-198 inR.b. Freeman and D.A. Wise, ees., The Youth Labor MarketProblem:Its Nature, Causes, and Consequences. NationalBureau of Economic Research Conference Report. Chicago,Ill.:University tf Chicago Press.welch, F., and J. Cunninghea1978Effects of minimum wages on the lev .1 and age composition ofyouth uncployment. Review of Economics and Statistics60:140-145.westet, Inc.1981Continuous Longitudinal Manpower Survey. Net Impact ReportNo. 1,Impact of 1977 Earnings on New 1976 through June 1977. New CSR, H.R., and War Poverty: The Feasibility ofBenefit-Cost Analysis for Manpower Programs. Unpublishedreport pr -pared for the U.S. General Accounting Office.Bethesda, Md.: Resource Management Corporation.Zimmerman, D.1930A Study of the ValrQ of Output of Participants in the SummerYouth Employment Pro,:a.m. Draft Final Report. Princeton,m.J.:Mathematica Policy Research. 219 APPENDICES APPENDIXAStandardized Data Collection for Large-Scale ProgramFvaluation: An Assessment of the YEDPA-SAS ExperienceCharles F. Turner The Youth Employment and Demonstration Projects Act (YEDPA), asnoted in Chapter 3e provided the Department of Labor (DOL) and its newOffice of Youth Programs (OYP) with a mandate to test the relati'eefficacy of different methods of dealing with the employment problemsof young Americans. The legislative concern with learning \"what worksfor whom\" was consistent with the frequently stated contention thatdecades of federal funding for similar programs had not yielded much inthe way of reliable knowledge. And so, a key element of YEDPA'sknowledge development strategy was the establishment of a standardizedsystem for the systematic collection of data on the progress of progiamparticipants and the services provided by YEDPA programs. STANDARDIZED ASSESSMENT SYSTEMIn orderto document administrative outcomes, to monitor per-formance, and to continually assess program impacts and lessons\" fromYEDPA programs, the Office of Youth Programs launched a large-scaledata gathering operation in collaboration with the Educational TestingService (ETS). The intent of the data gathering was to develop astandardized data base with which the performance of the variousprograms that YEDPA comprised could be assessed. This data gatheringplan, called the Standardized Assessment System (SAS), was ambitious inits aim.SAS was intended to provide preprogram, postprogram, andfollow-up data (3 and 8 months after program completion) for almost 50percent of the youth served by these programs (Taggart, 1980)The SAS data base is an important component of the YEDPA knowledgedevelopment enterprise not only because it was a salient feature of theYEDPA effort, but also because it provided the basic data used inevaluating a large number of the YEDPA programs. The characteristics Charles F. Turner was senior research associate with the committee. 193220 194 of this data base are thus of concern to us in evaluating what waslearned from the re.DPA experience. In the following pages we describethe SAS data collection procedures and evaluate the characteristics ofthe data obtained, e.g., the coverage of the sample and the reliabilityand validity of the measurements. Data Collection Instruments The SAS data collection instruments included an intake interview,called the Individual Participant Profile (IPP); a reading test (STEP);a battery of seven measures of occupational knowledge, attitudes, andrelated skills administered preprogram and postprogram; a programcompletion interview; interviews at 3 and 8 months postprogram; andevaluations by counselors (postprogram) and employers or work super-visors (postprogram and 3 and 8 months later). In addition, data werecollected from program sites concerning the implementation of theprogram and the services offered, and data were also collected from\"control\" groups recruited by program operators to provide comparisonsamples for program evaluation.In this section each of the data collection instruments is brieflydescribed.The descriptions of the instruments are taken from TheStandardized Assessment System for Youth Demonstration Projects(Educational Testing Service, 1980). Where suitable we have used theET3 phrasing or paraphrased the descriptions without repeated citationof the source. Individual Participant Profile The Individual Participant Profile was used to record informationon 49 r -ticipant characteristics as well as status while in theprogrb., and at termination. These data essentially duplicated thestandard information gathered on each participant in all ComprehensiveEmployment and Training Act (CETA) programs. The first 29 items werelargely demographic, covering such information as the individual's age,sex, race, and economic, educational, ani labor-force status--all attime of entry into the youth program. The remaining 20 items were\"program status\" items, which indicated the status of the participantat the time of program completion or termination. These included suchinformation as entry and termination dates, total hours spent in theprogram, whether the program provided the participant with academiccredit, and specific forms of \"positive\" and \"nonpositive\"termination.(A set of definitios accompanying the IPP form definedeach item in some detail and how Lt was to be completed by the youthprogram project personnel from their project records.) STEP Reading Scale The STEP reading scale was a short (10 to 15 minutes) measure ofreading skill that was intended to cover the wide range of reading 221 195 levels found among the YEDPA enrollees (approximately fourth to ninthgrade reading level by ETS's estimate). Twenty items were selectedfrom the STEP locator tests covering fourth to ninth grade readinglevels.Those locator tests are short reading-comprehension measuresordinarily used as screening devices for deciding which level of thefull STEP achievement tests is suitable for administration. Job Knowledge and Attitudes Battery Measures ci,Jsen for incorporation in the Job Knowledge andAttitudes battery were intended to reflect .3DPA program objectiveswhile still being compatible with the characteristics of the traineepopulation and the operational constraints of the youth projects. As astarting point, five behavioral areas thought to be affected by YEDPAprogram participation were defined by the Office of Youth Programs.These were considered to encompass the objectives of a vast majority ofthe YEDPA projects and were designated as (1) career decision making,awareness, and capability, (2) self-image, (3) work attitudes, (4) jobsearch capability, and (5) occupational sex stereotyping.Criticism of the design and administration of conventional paper-and-pencil tests used with similar youth led SAS designers to seekmeasures that were relatively short, presented orally, pictorial aswell as verbal, and appropriate in level and style of language foradolescents or young adults of low reading skill. In addition thebattery allowed the item responses to be marked directly in the testbooklet.Examples of items from each of the Job Knowledge andAttitudes battery are shown in Figure A.1.The designers of SAS chose two measures to assess what they termedcareer decision making, awareness, and capability performance. Onemeasure dealt with the \"vocational maturity\" of adolescents in makingappropriate career decisions, and the other with the youth's knowledgeof what is required for carrying out different jobs. Vocational Attitude Scale This scale contained 30 verbal items, whichwere scorable as three 10-item subscales. Those \"Involvement,' and \"Independence\" in career decisionmaking.The respondent indicated his or her agreement or disagreementwith each of 30 statements about vocational careers and employment. Job Knowledge Test This 33-item scale dealt with the qualifications,requirements, and tasks involved in various jobs. The items, inmultiple-choice format, required the respondent to indicate the correctresponse to questions about the specific occupations depicted. Self-Esteem Scale Youth programs often seek to enhance theparticipant's feelings of personal value, or self-worth, with theexpectation that improved self-perception will stimulate moresuccess-oriented social and vocational adjustment behaviors. The SAS 222 VOCATIONAL ATTITUDES WORK RELATED ATTITUDESHow would you feel if you saw this sign?CD I might try for a job inthat store, but theyprobably wouldn't want me.CD They would turn me down cold and wouldn'tthink I'm worth giving a chance.0 They would think I'm worth hiring for a jobin that store. Most bosses have it in for you and give you a hard tine.0 strongly agree0 somewhat agree0 fl hters work at putting out fires.Who do you think SHOULD be fire fighters?0 Only women0 More women than nen0 About the same number of nen and women0 More men than women0 Only nen JOB SEARCH SKILLS SALES HELP WANTEDSALESPERSONCARIOUSAPPLIANCESMOO & TVROBERTSON'SImlaySTRUMTop nore0 esperlentod Wesemen de on this job?0 Fie cameras and radios.CD Sell things im a store.0 Teach people how to drive a car.cp Sell houses to people. BEST COPYAVAILABLE224 JOB HOLDING SKILLS SELF ESTEEM JOBKNOWLEDGETFWhat would you say to a boss who said this to you? C:3It's probably just as easy to be successful in oneoccupation as it is in another. CZ) Sorry, I'll try to get here ontime fromnow on.CD It's tough for me to make h here ontime butTF I'll try. 0It doesn't matter which job you choose as long asit pays well. CD I do my workwhat's the difference if I'm late. FIGURE A.1Examples of items from Job Knowledge and Attitudes battery.SOURCE:Educational Testing Service (1980). 225Where would you work on this job most of the time(Din a factory on the assembly lineCD In the kitchen of a restaurant01n a storeCD In your own home 226 198 designers included one measure that attempted to define the level atwhich the program partScipant rated his or her personal value. Theself-esteem scale was a 15-item scale containing pictorial and verbalmaterial used to assess perceived self-worth in terms of expectationsfor acceptance or achievement in various social, vocational, andeducational settings. The respondent indicated, on a three-pointscale, the degree to which he or she would be successful or receiveacceptance in the specific situation portrayed. Work-Related Attitudes Inventory This inventory was intended tomeasure the youth's views about jobs, the importance of working,appropriate ways of behaving in job settings, and general feelingsabout his or her capabilities for succeeding in a work situation. Theinventory contained 16 items that provided both a total score andscores for three subscales defined as \"Optimism,\" \"Self-Confidence,\"and \"Unsocialized Attitudes.\" The response to each of the attitudinalstatements was based on a four-point scale of degree of agreement with,or applicability of, the statement. Job Holding Skills Scale This scale dealt with respondent awareness ofappropriate on-the-job behaviors in situations involving interactionwith supervisors and coworkers. This 11-item scale, containingpictorial and verbal material, required the respondent to indicatewhich one of three alternatives best defined what his or her responsewould be in the situation described. (Response alternatives werescaled in terms of \"most\" to \"least\" acceptable behaviors formaintaining employment.) Job Seeking Skills Test This test was intended to measure elementaryskills essential for undertaking an employment search. This test had17 items that sampled some of the skills needed to initiate anemployment search, interpret information about prospective jobs (innewspaper want ads), and understand the information requirements forfilling out a job application. The items, in a multiple-choice format,required selection of the one correct response to each question. Sex Stereotyping of Adult Occupations Scale This scale attempted tomeasure attitudinal perceptions of sex roles in occupational choice.This relatively short (21 item) verbal scale presented job titles alongwith a one-sentence description of each job and required the respondentto indicatewho should be a \" (job title as given). Afive-point response scale ranged from \"only women\" to only men.\" Project and Process DataIn addition to the range of information collected on programparticipants and controls, the SAS attempted to measure the types of 227 199 activities, the progress of program implementation, and the range ofservices being offered at each program site. This information wasexpected to be of potential use not only as contextual data for theanalysis of program outcomes, but also as data for reports to managersand policymakers about the implementation of the various YEDPA programs.The Project and Process Information questionnaire contained sixsets of questions that reported on key site-specific variables inquantitative terms. First, basic information was gathered about thesite; setting, and sponsors of the project. Second, the project wasdescribed in terms of its services, activities, and goals. Third, thelinkages involved in the project were described. Fourth, the staffinvolved in the project were profiled. Fifth, the project stabilityand the position of the project on the learning curve were assessed.Finally, the project costs were measured. Outcome Measures The outcomes of the programs were measured at program completionand 3 and 8 months after program departure. Two questionnaires wereused for this purpose: the 'Program Completion Survey\" and the'Program Follow-up Survey.\" (The same instrument was used 3 and 8months postprogram.) Program Completion Survey This questionnaire contained 48 items, mostof which were phrased as questions to be presented to the youth at thetime he or she had completed or was leaving the training program.Theycovered the participant's activities in the program, attitudes aboutthe program, job and educational aspirations, and expectations andsocial-community adjustments. The questions were intended for oralpresentation to the individual by an interviewer. (A parallelquestionnaire containing similar material was designed for use withcontrol group members and was designated the 'Control Group StatusSurvey.\") Program Follow-up Survey This 50-item questionnaire was designed to beadministered orally to the individual by an interviewer, who alsorecorded the participant's responses. The survey was intended for use3 months after the participant had left the training program and againat 8 months following program participation. Questions dealt with theformer participant's posttraining experiences in areas of employment,education, social adjustments, and future plans. (A parallel versionof the follow-up survey was used with control group members and wasdesignated the \"Control Group Follow-up Survey.\") In addition, afive-item Employer Rating Form was ;:o be completed by the present (ormost recent) employer. (Permission to interview the employer had to begranted by the youth.) 200 Concerns about Instrument Reliability and ValidityIn introducing the SAS measuring instruments, the designers at theEducational Testing Service warned that (Educational Testing service,1980) more careful testing of the instruments would have beenpreferable but it was necessary to develop these measures whileimplementing certain programs. The instruments . .. representthe best possible compromise between the many constraints atthe time the system was implemented. A particular concern expressed by the SAS designers involved thenature of the youth population from whom data were being collected.Given a population characterized as economically disadvantaged andlargely products of inner-city school systems, they anticipated thatthe validity of any available paper-and-pencil test might be suspect.For this reason thc documentation of the SAS instruments stressed the(1) use of measures that employ pictures as well as words, (2) use ofan administrator who would read items aloud so that the youth couldfollow along, and (3) the administration of the tests to small groups- -so that literacy (or other) prob: 3 might be more easily detected.Despite these precautions, it an never be assured in a datagathering operation such as SAS that measurements were made in themanner prescribed. The test administrators were not ETS employees, butrather program personnel assigned to fulfill YEDPA's data reporting\"requirement.While ETS did provide instruction to one person at eachprogram site, that person was not necessarily the one who administeredthe measurements. Moreover, staff turnover may have put some people inthe position of serving as test administrator with little or no (orwrong) instruction on how to administer the instruments. Since one ofthe canons of testing is that the manner of test administration canhave important effects on measurement, it is natural that concernsabout the reliability and validity of the SAS measurements were voicedby outsiders--as well as by ETS.Almost all of the SAS scales used previously published tests, andthere did exist a literature that documented the characteristics of thescales and estimated their reliability and predictive validity withvarious populations. These populations, however, were not identical tothe YEDPA youth who would be tested with the SAS. Thus, it did notnecessarily follow that the readings of test reliability and validityobtained from these groups could be generalized to the youth populationtargeted by YEDPA.In its 1980 report on the Standardized Assessment System, ETSpresented evidence for the reliability and validity of the SASscales.'Some of this evidence predates YEDPA and may have been used ETS (1980) presents estimates of reliability and validity in caseswhere there are \"significant\" results (p less than .01 or p less than 229 201 in the decision making about which instruments to use in SAS.Theevidence is derived from studies of small samples of youthsparticipating in Neighborhood Youth Corps (NYC) and OpportunitiesIndustrialization Center (OIC) training programs. For four of the SASscales, Table A.1 presents the correlations found between scale scoresand various criteria of \"success\" in these programs.Reportedcorrelations range from .18 to .36. Two measures show significantcorrelations with success in finding employment after programcompletion--the Job Knowledge scale (r = .22 in NYC sample) and the JobSearch Skills scale (r = .36 in NYC sample, and .21 in OIC sample).The other two scales, Job Holding and Self-Esteem, do not showsignificant associations with postprogram employment, but do showpositive associations with evaluations given by guidance counselors andwork training supervisors.The 1980 report on SAS also provides early SAS data from samples ofhigh school seniors participating in the Youth Career Developmentproject (n = 1,666) and their control group (n = 1,590).Estimates ofpredictive validity using selected criterion measures (and Cronbach'salpha for the scales) are shown in Table A.2. The range of correlationsfor this sample are generally lower than those found in the earlierstudies.In particular, only two scales (Vocational Attitudes andWork-related Attitudes) show significant correlations with postprogramactivity (coded 2 for full-time school or work, 1 for part-time schoolor work, and 0 otherwise). These correlations were very modest in size(ral .12 and .10). The scales did show somewhat higher correlationswith level of present job and a negative correlation with amount oftime required to find the present job.Overall, however, the preliminary evidence presented by ETSsuggests that (1) the seven scales are not powerful predictors ofpostprogram employment and (2) the measurement characteristics of thesescales when administered in SAS may be different from those foundelsewhere.(Whether the latter might be a function of the populationtested, lack of standardization in administration, or some other :.ause,is difficult to say.) .05).Thus it is not possible in Table A.1 and A.2 to report theirestimates for all variables and for each criterion measure.In selecting ETS \"validity\" measures to reproduce in Table A.2 andin designing our own analyses (reported in Table A.10 and A.12) we havefocused on the prediction of future rather than concurrent outcomeswhere the outcome variables involved assessments by observers otherthan the subject (e.g., an employer's evaluation of the subject at 3months postprogram) or involved reports of relatively objectivestatuses (e.g., Are you employed gull time?). We believe that thisprocedure provides more appropriate information about the usefulness(for program evaluation) of the SAS assessment battery than proceduresthat depend exclusively on more subjective reports from the respondent(e.g., assessments of job satisfaction or adjustment). 230 202TABLE A.1ETS Estimates of Predictive Validity of SAS Attitude andKnowledge Measurements SASMeasurement Criterion Predicted Sample (n) r Job knowledge Work supervisor rating NYC(109).32Counselor rating NYC(109).25Counselor rating OIC(220).19Vocational skills instructor rating nIC(261).20Posttraining employment NYC(104).22 Job holding Counselor rating NYC(111).31skills Work supervisor rating NYC(111).34Vocational skills instructor rating OIC(260).15Remedial skills instructor rating OIC(134).18 Job seeking Counselor rating NYC(111).22skills Work supervisor rating NYC(111).31.Posttraining employment NYC(104).36Posttraining employment OIC(157).21 Self-esteem Counselor rating NYC(111).34Work supervisor rating NYC(111).24Remedial skills instructor rating OIC(134).18 SOURCE:Educational Testing Service (1980). CHARACTERISTICS OF THE DATA BASECompleteness of Initial CoverageAccording to ETS, the Standardized Assessment System was designedto provide a complete enumeration of all participants (together withappropriate controls) in all YEDPA demonstration projects. In theirwords (Educational Testing Service, 1980):In a literal sense there is no \"sampling\" with respect toenrollees at a demonstration site since evaluation data are tobe collected on the performance of all enrollees at aparticular site. The control group at a particular site,however, does represent a sample from a hypothetical populationthat is, hopefully, similar to the enrollees with respect toimportant background and ability variables.The difficult task of ensuring that data were collected in astandardized manner from all program participants was not, however,under the control of ETS. The Department of Labor had arranged fordata to be collected by individual program operators; administration 231 203TABLE A.2ETS Estimates of Reliability and Predictive Validity of SASInstruments SAS MeasurementInternalConsistency(Alpha)Predictive Validity Time to FindFirst JobActivityStatus(a)Level ofPresent Job Vocational attitudes .74 b.12 .21 Job knowledge .66 bb.23 Job holding skills .56 -.16 b.28 Work-related attitudes .78 -.17 .10 .18 are for 3 months postprogram for YCDparticipants.Sample sizes range from 120 to 790 for validity estimates.Reliability estimates are average of values reported for participants and controls (combined n = 3,256).aActivity status coded 0 for not working or in school, 1 for part-time work orschool, and 2 for full-time work or school. It is not clear from the text howboth part-time work and part-time school would be coded.mot significant.SOURCE:Educational Testing Service (1980). and execution of the data collection were not ETS *s responsibility.ETS contracted to process the data supplied by the program operators(and, in a number of cases, to analyze that data).2 Indeed, most ETS discussions of the SAS data base contain forceful disclaimers that\"collection of all data with the Standardized Assessment Systeminstruments remained the sole responsibility of the service deliveryagents who were required to assign suitable staff at each project sitefor carrying out the data gathering tasks\" (ETS, 1982:15, emphasis in original).As a result of this delegation of data gathering responsibility tothe program operators, there was known to be quite incomplete reporting of data.Although the precise magnitude of the incompleteness of the initial coverage was not known, ETS has informally speculated that up to 50 percent of the program participants may have been missed. 1ETS involvement in the data collection grew out of evaluationstudies begun by N. Freeberg and D. Rock of Youth Career Developmentand Service-Mix Alternatives projects. 232 204 To investigate the characteristics of the SAS data base, wec.btained a copy of the data base (minus individual identifiers).'Because data were collected from program sites on the number of newpersons enrolled each month, it is possible to gain some insights intothe nature and magnitude of the incompleteness of coverage. using the\"process dataprovided by each site, we tabulated the total number ofpersons reported to be enrolled in YEDPA demonstration programs. Wethen tabulated data on individual participants by site to obtain anindication of the proportion of enrollees who were missing from theparticipant file.As with all attempts at complete enumeration, the estimation ofundercoverage is not straightforward unless there exists a valid countfor the true size of the po'vlsUon being enumerated. In the pre intcase, it is likely that the month-by-month founts of new progcarentrants were figures that program operators Lad readily at hang(This results from the fact that payments to programs are tied thenumber of entrants -- which, of course, introduces its cAn potential fordistortions in reporting.) If we tike the reports of total enrollmentsat site i(Ei) as an indicator of the total number of persors whoshould have been interviewed and tested, then, for any single site, theincompleteness of coverage can be represented by the ratio (NJ/Ei)where Ni is the sample count in the participant data file for sitei.For example, if a site said it enrolled 2,000 youth but only 1,200respondents from that site wale be located in the participant file,then the coverage rate could 1,1, said to be 1,200/2,C00 or 60 percent.(Note, however, how inflating of enrollment ficres by progrerioperators or mechanical errors in data entry or matching might biasthis estimate.)ill program sites accurately reported enrollment data, we mightthe',Ake a confident estimate of the completeness of coverage bysumming across sites (ENifEEi). The data do not, however,comply so readily with our wishes. Incompleteness affects not onlyparticipant data, but also the process 4ata.Analysis of the process data collected from individual programsites (shown in Table A.3) reveals that the majority of program sitesdid not provide data on their program operations. This can be detectedwithin the ETS data 'Jest: because site codes appear on both respondentrecords and site records. We thus know (assuming the site codes have 'Three observations should be made about technical aspects of thedata sets.First, the docul(entation provided with the data sets wasnot always adequate. Second, although the data have a hierarchicalstructure (there are respondents within sites within programs), thedata sets are not designed to encourage analyses that make use of thathierarchical struc*ure. Third, no procedural history exists for thedm..e gathering. Thus it is unclear how many sites were contacted fordata, how many sites provided data that was judged \"suspicious,\" howETS \"winnowed\" the data set to eliminate \" suspicious\" data, and soforth. 233 205TABLE A.3Cross-tabulation of Availability of Site \"Process\" Des in YEDPA/SAS Data Base by Availability of Participant Data Participant DataSite \"Procest.\" DataMissing Reported No data Data on one or moreparticipants from site Total reported enrollmentUnknown(n number of participant (part.) andcontrol (cont.) cases in respondent data base for those sites.aSites provided no participant or control data. becn accurately recorded) that 458 program sites provided some par-ticipant data to ETS. Of those 458 sites only 166 provided \"process\"data on site operations. Not only do these \"missing\" sites constitutethe majority of identifiable sites, but they also account for themajority of the respondents whose data were supplied to ETS (30,613 of50,182 respondents in the data base came from sites that did not report\"process\" data).Some partial information on coverage can still be gleaned from Table A.3.Note, for example, that the sites providing process data reported a total enrollment of 29,272 participants. For these samesites we find only 12,733 cases in the participant file (plus 6,836 control cases). For these sites, the coverage estimate would be12,733/29,272 ,r 43 percent. (It is, of course, a leap of faith toassume that this same percentage would apply to the sites that did notprovide process data, but it is not inconsistent with the informal\"guesstimates\" made by ETS personnel who were familiar with the SASdata collection.) Sample AttritionSubsequent to the initial data gathering, a series of date collec-tion steps were planned for each participant (and c-atrol) in the SAS data base.Interviews were to be conducted at program completion, the Job Knowledge and Attitudes battery was to be re-administered, subse-quent survey interviews were to be conducted 3 months and 8 monthsafter program completion, and data were to be gathered from employers,counselors, and on. 234 206 In all longitudinal surveys, one expects some reduction in thenumbers of respondents from whom data can be collected in eachsucceeding wave of data gathering. Such sample loss may compromise therepresentativeness of the remaining sample (save in the rare case whensample loss is effectively random). Such attrition, however, is a factof life that social researchers have to live with. Respondents moveand are untraceable, they lose their patience with the researchers'persistent inquiries, and so forth. Nonetheless, it is not unknown forwell-conducted surveys to obtain responses from 80 percent (or more) ofthe original interviewees after a period of months (and even years).Systematic follow-up and dogged determination to find the \"movers\" andpersuade the \"refusers\" have resulted in some remarkably low attritionrates in long-term follow-up studies, even with very youthful popula-tions (see Sewell and Hauser, 1975, and descriptions of the ContinuousLongitudinal Manpower Survey and National Longitudinal Survey inAppendix D).Table A.4 showc ,\u00b0.d various stages of the SAS d.ta collection andthe attrition that occurred over time. It will be seen from Table A.4that the attrition in the SAS data collection base is sufficiently highto engender skepticism about claims that the follow-up data providereasonable estimates of the postprogram experiences of the youth fromwhom data were initially collected (not to mention the entirepopulation of participants).Looking at the data base in its entirety (i.e., including allrespondents from whom any data were collected) reveals that at 8 monthsafter program completion, there is no interview data on the majority ofprogram participants and controls (see Table A.4). Even at 3 monthspostprogram, the attrition losses amount to almost half of the originalsample (45 percent of program participants and 49 percent of controlswho provided initial data did not provide interview data at 3 monthspostprogram).Sample attrition is clearly at a level at which serious doubts mustarise about whether the results obtained from the follow-up samples canbe generalized. Even for postprogram measurements, attrition rates arerather high:32 percent of participants lack postprogram surveydata.s In fact, sample attrition in the data base is higher than thatreported in the ETS analyses. This difference in numbers arisesbecause ETS eliminated approximately 11,000 cases from their publishedfigures as a result of their \"winnowing\" of the sample to exclude\"suspicious\" data.'It is possible that some portion of this \"loss\" may be attributableto youths who dropped out of the program (rather than \"completers\" forwhom data are missing). If this is so, the situation may not be quiteso bleak as it seems, since one cot1d attempt to cast an analysis interms of the effects of program completion (rather than mere enrollmentin a YEDPA program). 235 TABLE A.4SAS Data Collection Program: Instruments, Schedule, and Samples Obtained InstrumentAdministration Population fromSchedule Whom Data Collected Participants Controls Individual Participant Profile Beginning of Participants and 34,572 15,610section 1 (demographic and program controlsSES characteristics)aSTEP (reading test) Beginning of Participants and 30,191 12,998program controlsPretest (7 knowledge and 111'!g'.ning of Participants and 31,732 13,610attitudinal measures)a program controls--(program termination data) not available IPP section 2 End of program Participants --Posttest End of program Participants and 24,580 9,314 (same as pretest)a controlsProgram completion survey End of program Participants 23,354 (interview)Counselor's rating End of program Program counselors 22,232of participantsWork supervisor's rating End of program Work supervisors 11,068h --of participantsControl-Group Status Survey End of program Controls --6,471(interview)Three-month follow-up survey Three months Participants and 18,870 7,948(interview)a after end of controlsprogramThree-month employer rating Three months Employers of 2,341b 523bafter end of participantsprogram and controlsEight-month follow-up survey Eight Participants and of during Program personnel 12,733c 6,836cQuestionnaire (da:.-s on program programenvironment and processes) operation aInstruments for which N's are included in Figure A-1.bInstrument not applicable to all respondents.cN's shown are number of youths in sites who returned Process Information Questionnaire. 236 208 The magnitude of the attrition in the ETS data base makes one wonderwhy it was not anticipated either by the agency, the contractor, or thereviewers at the Office of Management and Budget (OMB) who were respon-sible for approving government data-gathering activities. We wouldnote, in this regard, that in 1977 OMB announced an explicit standardfor response rates, which (temporarily) replaced its non-numericalstandard of adequacy (Office of Management and Budget, 1977):It is expected that Gate collections for statistical purposeswill have a response rate of 75 percent. Proposed datacollections having an expected response rate of less than 75percent require a special justification. Statistical datacollection activities having a response rate below 50 percentshould be terminated. Proposed statistical data collectionshaving an expected response rate of less than 50 percent willbe disapproved.Clearly, under such a standard, this data collection would not havebeen approved (or re-approved) if the attrition rates for its follow-upmeasurements had been accurately anticipated.To illustrate the cumulative impact of the incompleteness ofcoverage discussed previously and the sample attrition that occurredover time in the SAS data base, Figure A.2 graphs an estimate of thesize of the target sample of participants for the SAS data collection(using the 43 percent coverage rate computed for sites reportingprocess data) together with the sample sizes obtained for both par-ticipants and controls over the course of the data gathering. Theeffects of undercoverage and sample attrition are quite dramatic.Because this sample attrition was so great we undertook someexploratory analyses to assess its effect on the composition of the SASsamples over time. Table A.5 presents tabulations of a variety ofeconomic and social characteristics for respondents who providedinterview data at entry and at 3 and 8 months postprogram. A fewmodest trends are evident from Table A.S. The proportion of high'chool dropouts declines from 25 to 20 percent, while the proportion ofpersons receiving public assistance shows a modest rise (42 to 47percent for participants and 38 to 42 percent for controls). Whilethere are notable changes and a very large number of \"significant\"differences (given the large sample sizes) between those who continuedto provide data and those who were lost to attrition, it was surprisinghow modest the changes were. When a parallel analysis wits performed onthe Job Knowledge and Attitude measurements (see Table A.6), theresults were equally unprovocative. Reliability and Validity of Instruments Job knowledge and attitude measures figure prominently in many ofthe evaluation studies conducted under YEDPA. The rationale behind theuse of such instruments is that they measure traits that (1) theprograms change and that (2) are important in helping youths find 237 80,000 70,000 60,000 50,000 wN40,000a2to 30,000 20,000 10,000209 riParticipants rMControls AssessmentSystem). employment.Since these are relatively inexpensive data to collect,there is some reason to favor such a strategy--particularly if onesuspects that the effects of training on employment may be unusuallysubtle or delayed in arriving. This strategy, of course, depends onthe measures being adequate in the sense of being replicable so thatrepeated measurements are relatively stable and in their being 238 210TABLE A.5Social and Demographic Characteristics of SAS 7.6Control 8.9Has children Participant 11.310.6 11.7Control 8.5 1 percent of data records were inconsistent, e.g., therespondent was a \"control\" but the 3-month follow-up flag indicated therespondent had completed a \"participant\" follow-up survey. These recordswere excluded from this analysis.SOURCE:Derived by tabulating data for every fifth record in ETS database, i.e., 20 percent subsample of data base. reasonable proxies for the more difficult to observe outcomes. Theformer condition is generally referred to under the rubric ofreliability, the latter as validity (of one sort or another).Since the Standardized Assessment System was launched with someexpressed trepidations about the suitability of such measures to theYEDPA population, it is important to seek evidence within the data baseas to whether these conditions are met by the SAS measurements. SASprovides the opportunity for making (test-retest) reliability estimates 239 211TABLE A.6Job Knowledge and Attitudes and Other Pretest Scores(at entry) of Respondents Giving Interviews at Entry and 3 a.,c1 8 MonthsPostprogram SAS Measurement SampleStageStandardDeviationofScale Entry3-MonthFollow-up8-MonthFollow-up Vocational attitudes Participant skills Participant 14.514.614.94.6 NOTE:Standard deviation of scale is computed from data for all controls andparticipants. SOURCE:Derived by tabulating data for every fifth record in ETS data base, i.e.,20 percent subsample. for these scales, since the same battery was administered preprogramand postprogram to the untreated controls. Although one can expecttrue temporal change to affect the cross-temporal correlations betweentwo measures of a trait such as self - esteem or work-related attitudes,one would expect a certain amount of stability in these traits. Afterall, if people varied widely from day to day on these traits it is not(easily) conceivable that the measure would be helpful in predictingrelatively stable social behaviors, such as employment or othervocational behaviors.A series of analyses reported in Tables A.7 through A.10 examinesome of the properties of these scales. In Table A.7, the zero-ordercorrelation of each scale measured preprogram and postprogram is 2 10 212TABLE A.7Test-Retest Reliability for SAS Measurements (computed from20 percent sample of ETS data base) Zero-Order Correlation Over TimeaSAS Measurement Controls Participants Vocational attitudes .604 .602Job knowledge .527 .505Job holding skills .460 .386Work-related affected by \"true change\" inrespondents.Since participants are enrolled in programs designed toThane their attitudes and knowledge, reliability estimates for thisgrow, should be treated with caution.aMeasurements made using identical instruments preprogram andpostprogram.\u00b0Minimum sizes of samples from which estimate was made. TABLE A.8Correlations Between Reading Scores and SAS Measurements ofJob Attitudes and Knowledge (computed from 20 percent sample of ETS database) SAS MeasurementaCorrelation with STEP Reading Scol'eParticipant Control Vocational attitudes .445 .509Job knowledge .447 .467Job holding skill .288 .354Work-related attitudes .578Sex (5,603) (2,258) aAll measurements made during pretest.b Maximum sizes of samples upon which any reported correlation is based. 241 TABLE A.9Zero-Order and Partial Correlations (with reading)from 20 percent sample of SAS data base)between SAS Pretest Measurements (calculated SAS MeasurementType ofCorrelationSAS 26 percent sample of ETS pretest data. Partial correlations control for STEPreading scale score. Step-wise case deletion was done (N = 2,196 controls and 5,464 participants). Correlationsfor program participants are shown above diagonal; those for controls are below. 243 242 214 TABLE A.10Estimates of Predictive Validity of SAS Attitude andKnowledge Measurementsbase)(computed from 20 percent sample of ETS data SAS Measurement atProgram Completion SexCorrelation with Activity differentfrom 0(at p < .05).Correlations are derived from 20 percent subsampleof YEDPA participants in ETS data base. Respondents were included only ifthey were coded as a participant in IPP profile and if the data flag forthe 3-month follow-up indicated they had completed a participant follow-upsurvey (not a control survey). In a small number of cases (281 of50,182), those two indicators are inconsistent; those cases were excludedfrom this analysis. aActivity status is coded 1 if respondent is in full-time job or is afull-time student; status is coded 0 otherwise. reported for program participants and controls.' All of thetest-retest correlations are within the range of approximately 0.4 to0.6.While these correlations are not insubstantial, neither would 'Obviously, the reliability estimates for the control groups are mostrelevant since the controls did not participate in YEDPA's programsthat were designed to change participant's attitudes, knowledge,behavior, and so forth. However, as Table A.7 shows, reliabilityestimates for program participants are quite similar to those forcontrols. 244 215 they be thought to indicate an extremely robust measurement. Indeed,if one were to assume that measurement errors (both random andsystematic) did not contaminate these data, these estimates wouldsuggest a great deal of variation over time in young people's knowledgeof and attitudes toward jobs, their self-esteem, and the extent towhich they sex stereotype the occupational world. This could, ofcourse, be the case. But it is also plausible that a relatively largecomponent of measurement error may be distorting the measurements.Overall, the self-esteem scale and the job-holding skill scale showrelatively low cross-temporal correlations, while the sex stereotypingand vocational attitudes scales show correlations of 0.6 or better.(In the case of the sex stereotyping scale, one suspects that thisrelatively high estimate of reliability may derive, in part, from thefact that all items were presented in the same format and scored in thesame direction.) These scales also show a high correlation withreading ability. Table A.8 presents the correlations between each ofthese scales (measured at pretest) and the STEP reading scale scores.These correlations range from a low of .241 for sex stereotyping to ahigh of .578 for the job search skill scale.While one might be tempted to dismiss some of these high correla-tions with reading ability as \"artifacts,\" for some purposes thecorrelation is as one would want. The ability to read a job adver-tisement is an essential component of \"job search skills.\" It is not,however, the case that such a simple argument can be made to defendthese correlations in every instance. There is no prima facie case tobe made for a correlation between the attitude measures and reading- -although there are more than enough plausible paths for indirectcausation to account for this correlation. It is important to keep inmind that reading (and a myriad of other unmeasured traits) may play arole in accounting for the zero-order test-retest reliabilities.Potential correlated measurement errors also bedevil all attempts tounderstand test-retest reliabilities.Some evidence of the construct validit of the various SASmeasurements may be gleaned from Table A.9. As intended by the SASdesigners, all of the measures are positively intercorrelated. This istrue even when a simplistic attempt is made to account for confoundingeffects of reading ability on all of the scales. The strongestcorrelations found for the SAS measures are between scales that measure It should be realized that test-retest correlations such as thoseshown in Table A.7 are affected by both true change in the respondentsand by measurement errors. If one wishes to use measures like the SASassessment battery as proxies for (unmeasurable) long-term outcomes(e.g., lifetime earning potential and employability), however,instability, per se, may be an important consideration. If acharacteristic like work-related attitudes, for example, naturallyvaries to such a degree that test-retest correlations approach zeroover a short period of time (in the absence of measurement error), theneven a perfectly reliable measurement of this characteristic would beof doubtful utility in most program evaluations. 245 216 similar or related traits, e.g., vocational attitudes and work-relatedattitudes, or job search skills and job knowledge. Conversely, correla-tions between the sex role stereotyping measures and job knowledgefactors are low. Predictive Validity Given the aim of the YEDPA programs, a key validity test for anyscale would be its ability to predict which YEDPA youth would stay inschool or find full-time employment and which would not. Severalskirmishes have been made with this analysis and Table A.10 reports thesimplest of them. (Its outcome, however, is little different from themore complicated analyses.)For all program participants (in 20 percent sample) who providedthe requisite data at 3 months (n = 2,406) and at 8 months (n = 1,649)postprogram, a score of 1 was assigned if (at follow-up) the respondentreported being either in school full time or working full time. Ascore of 0 was assigred otherwise. In the crudest analysis (reportedin Table A.10) the 0-order correlation between this dichotomous\"activity variable\" and each of the scales from the SAS battery wascalculated.'This was done separately for males and females to allowthe effects of potential differences in child-care responsibilities toappear.It will be seen from Table A.10, that there were some \"significant\"correlations between job knowledge and attitude scores and whether ayouth was \"occupied\" or \"unoccupied,\" however, the magnitude of thesecorrelations was not substantial. The correlations for the SAS database are considerably below those found for the NYC and OIC samplesreported by ETS in their 1980 report on SAS (Educational TestingService, 1980). They are even lower than the correlations (.10)reported by ETS from the Youth Career Development sample.The extremely low predictive validity of the SAS measures raisesquestions about the meaningfulness of program evaluations that resttheir verdicts of program effectiveness on such measurements. AsChapters 4 through 8 have shown, such studies are are not uncommon inthe YEDPA literature. Inter-site VariationsThe shortcomings of the aggregate SAS data base invite thequestion:Is the data base uniformly riddled with such problems? It 'This analysis is somewhat crude, but it illustrates the point in astraightforward manner (and it is analogous to analyses reported inETS, 1980).It should be noted, however, that because the criterionvariable is dichotomous, the obtained correlations will understatesomewhat the extent of the relationship. 246 217TABLE A 11Follow-up Rates for 10 Randomly Selected cites in SAS DataBase Postprogram Follow-up Rates sites were elected using a random number table from an g all sites inthe 2Th Jata base ,Iaving an \"n\" of at least 25 (controls + partic., ats) at Wave1.N's.amples whose rates are shown above range from 24 to 167. arollow-up rate is a percentage r\" all respondents at site for whom there is any3-month (or 8-month) interview data 'as indicated by \"flags\" set in the data baseto indicate presence or absence of these data).hphree sites had no control group . is possible .theory, of course, for an aggregate outcome such as theone reported here to be composed of some very fine data gatheringoperations ant sc.1 very poor ones. While the aggreyate result woaldnot be impressive, it still might be possible to isolate a sizablesubset of the data base upon wnich a convincing analysis could beperformed.To assay this possibility, we selected 10 sites at random from theSAS data base and ascertained the distribution of attrition ratesacross sites.We restricted the universe of potential sites for thisanalysis to sites that had a minimum of 25 respondents (controls andparticipants) at the initial data collection. For each of these sites,we then computed the follow-up rates at 3 and 8 months postprogram.The distribution of follow-up rates across the 10 sites is shown inTabl,.. A.11.It will be seen that at 3 months postprogra'n four siteshad foil, w-up rates for participants of 75 percent or higher. For thecontrol samples, only two sites had such high follow-up rates.While the attrition analysis at 3 months is somewhat encouraging,the results at 8 months are quite disappointing. Only one sitemaintained a 75 percent follow-up rate for participants at 8 months,and no site attained this rate for its control samples.In addition to the analysis of attrition rates, we also attemptedto assay the distribution across sites of the predictive validity ofthe SAS attitude and knowlrage measurements. Here again, we selectedlu sites at random from the SAS data base. This time, however, werestricted our analysis to sites that had a minimum of 100 programparticipants from whom data had been obtained at 3 months postprogram.This was done to provide an adequate sane L, size for calculating thecorrelation coefficients between the (imms...iate) postprogram SASmeasurements and at 3 months 247 TABLE A.12Distr_bution of Predictive Validities of SAS Attitude and Knowledge Measurements For 10Randomly Selected Sites Magnitude of Correlation withActivity Status at 3 Months Postprograma -.20 to-.10to0.00 to.10to.20 to Not SAS Measurement -.11-.010.09.19.24.30+Computableb Vocational 01 52101Job knowledg.. 10 62001Job holding skills 00 54001Job seeking skills 11 24101Work- related stereotyping 02 42101Summary 26282070 NOTES:Ten sites were selected using a random number table from among thy. 66 sites in the ETS database that had some 3-month interview data on at least 100 participants. N's for correlations withineach site range from 70 to 186.Respondents were included in this analysis only if they were coded as a program participant in IPPpiafile and if the data flag for the 3-month follow-up indicated they had completed a participantfollow-up survey (not a control survey). In a small number of cases in the overall data base (281 of50,182), these tw., indicators are inconsistent; these cases wereexcluded from this analysis.Attitude and knowledge scores are from postprogram measurement wave (i.e., \"zero\" months postprogram).aAs in -able A.10 the criterion being predicted is \"activity status,\" which is coded 1 if respondentis in a full -tike job or is a full-time atudent (it is coded 0 otherwise). Students enrolled inschool at or below the tenth grade were excluded from the analysis since such students frequently havelittle discretic 'spout their status as a result of compulsory education laws.One of the 10 randomly selected aites die not administer the SAS postprogram battery, and hence,correlations could not be computed for this site. 248 219 postprogram.Table A.12 presents the results of this analysis. (Seethe notes to Table A.12 for definitions of sample selection criteriaand the activity status variable.)It will be seen from Table A.12 that no predictive validity for anymeasurement at any site exceeded 0.30. The vast majority ofcorrelations (48 of the 60 that could be calculated) were in the range0.0 to 0.20.Indeed, over half of the coefficients we calculated (36of 60) were less than 0.10.While it would be a mistake to overgeneralize based on data fromsuch a small number of sites, these data on attrition and measurementvalidity do not encourage the belief that there exist a sizable numberof sites in the SAS data base that gathered high-quality data (wherequality is indicated by the attrition of the sample and the predictivevalidity of the measurements). REFERENCES Educational Testing Service1980The Standardized Assessment System for Youth DemonstrationProjects.Youth Knowledge Development Report No. 1.6.Washington, D.C.: U.S. Deptirtrient of Labor.1582Demonstration Programs for Youth Bmployment TheEvaluation of Various Categories cf YEDPA Program sites.Princeton, N.J.: Educational Testing Service.Office of Management and Budget1977Memorandum to heads of executive departments, February 17,1977.Sewell, W., and R. Hauser1975Education, Occupation and Earnings. New York:Academic Press.Taggart, R.1980Youth Knowledge Development: The Process and the Product.Unpublished manuscript. 249 APPENDIXBReport List This appendix lists the reports considered by the committee in itsassessment of program effectiveness and program implementation underthe Youth Employment and Demonstration Projects Act (YEDPA). (SeeChapter 4 for a description of the procedures and criteri-_ used inselection of reports included in review of YEDPA programs.) The firstsection lists research reports on the effectiveness of individual YEDPAprojects.The second section lists reports on the implementation ofYEDPA programs in general.For the review of program effectiveness only those project reportslisted in the first section were considered. All of these reports metthe committee's initial criteria for the effectiveness review. Uponmore thorough examination many of these project reports were excludedfrom the effectiveness review because they did not meet the second-stage criteria of scientific evidence set by the committee. Projectreports that did meet committee standards and were included in thereview of program effectiveness (Chapters 5-8, are indicated by an \"E\" in the left margin.For the review of program im?lementation the committee consideredtwo types of reports: project reports (listed in the first section)that also contained information pertinent to program implementation,and reports on program implementation and operation that were notcandidates for the effectiveness review because they were not specificto individual projects and because they lacked effectiveness data.Project reports of the first type included in the implementation review(Chapter 3) are indicated by an \"I\" in the left margin. Reports of thesecond type are listed in the second section, Implementation Reports.All of these reports are included in the implementation review.Reports are listed alphabetically by authoring or:-nization.Reports were prepared for the funding agency, the Employment andTraining Administration of the U.S. Department of Labor, unless otherwise indicated. Many of the projects included here, for instance,were designed and managed by the Manpower Demonstration ResearchCorporation (MDRC) with the evaluation subcontracted to Abt Associatesor Mathematica Policy Research. These project reports are listedrespectively under Abt Associates or Mathematica Policy Research, withan indication that they were prepared for MDRC. 220250 221PROJECT REPORTSAbt Associates, Inc., Youth from Low-Income Households: ABaseline Report from the Entitlement Demonstration. Preparedby S. Barclay, C. Bottom, G. Farkas, and E.W. Stromsdorfer,Abt Associates, Inc., and Randall J. Olsen, Yale University,for MDRC.E 1980Early Impacts from the Youth Entitlement Demonstration:Participation, Work, and Schooling. Prepared by G. Farkas,D.A. Smith, E.W. Stromsdorfer, and C. Bottom, Abt Associates,Inc., and Randall J. Olsen, Yale University, for MDRC.E 198-Impacts from the Youth Incentive Entitlement Pilot Projects:Participation, Work, and Schooling over the Full ProgramPeriod.Prepared by G. Farkas, D.A. Smith, E.W.Stromsdorfer, Associates,Inc., for MDRC.E 1983Final Program Impacts of the Youth Incentive EntitlementPilot Projects. Prepared by G. Farkas, R. Olsen, E.W.Stromsdorfer, L.C. Sharp, F. Skidmore, D.A. Smith, S.Merrill for MDRC.ACTION/Office of Voluntary Citizen Participation, Washfngton, D.C.1981Executive Summary to Final Report: Youth Employment SupportProgram.1981Final Report:Youth Support Program (YES).A.L. acts Work-Related Behavior Better Education, Chicago1982Athletes :or Better Education: Academic-Athletic-CounselingProject.American Association of Community and D.C.n.d.The Council ect.Second Report.American Camping Association, Port Deposit, Md.1981Project STAFF. Final Report.American Institutes for Research in the Behavioral Sciences,Washington, D.C.E 1982Needs and Characteristics of Pregnant and Parenting Teens:The Report for Project Redirection. Tc.anen, anA J.R.Kahn for MDRC.CE for Emplo-ment and Income Studies, The Florence Heller GraduateSchool for Advanced Studies in Social Welfare, Brandeis UniversityE 19rnThe Effectiveness of Two Job Search Assistance Programs forDisadvantaged Youth. Final Report.Prepared by A. Hahn andb. Friedman, with C. Rivera and R. Evans.251 222 E1982Can Employer or Worker Subsidies Raise Youth Employment? AnEvaluation of Two Financial Incentive Programs forDisadvantaged Youth. Final Report.Prepared by C.Rivera-Casale, B. Friedman, and R. Lerman.Center for Labor and Human Resource Studies, Temple UniversityE 1981Program Impacts of Jobs for Delaware's Graduates, Inc.Technical Report. Post-Program Experiences of 1980 DelawareHigh School Seniors Participatiq in the First Year of aSchool-to-Work Transition Program. Prepared by M.F. Eleeyand R.D. Leone, with V. Singh.E 1982An Evaluation of the Program Effects of Jobs for DelawareGraduates, Inc. Post High School Labor Market Experiences of1980 and 1981 Delaware High School Graduates Participating ina Special School -to -Work Transition Progi.w. Prepared byM.F. V. Evaluation of the Program Effects of Project BEST.Educational Attainment and Post High School Labor MarketExperiences of 1980 and 1981 High School Seniors afterI.,trticipation in a Labor Market Information Pilot Program.Prepared by R.D. Leone and M.F. Eleey.Center for Studies in Social Policy, McLean, Va.E1981Evaluation of the CLC/A Career Exploration Project--1980.Final Report.Prepared by J.M. B. Holmes, A.M. and F.J. Farman, for OpportunitiesIndustrialization Centers of America, Inc.Center for Urban Programs, St. Louis University19791978 Vocational Exploration Program. The Final Report.1979Vocational Exploration Demonstration Project: OperationsGuidelines.E1980Public Versus Private Sector Jobs Demonstration Project: AnAnalysib of In-Program Effects and Outcomes.1980The Vocational Exploration Demonstration Project: APreliminary Analysis of the 1979 Fall Component. Prepared byB.P. Nedwek, J. Terence Manna, and E.A. Tomey.1981The Vocational Exploration Demonstration Project: AnAnalysis of the 1980 Summer Component. Prepared by B.P.Nedwek, J. Terence Manna, and E.?, Torrey.1981The Vocational the 1979-80 Components.E Impactof VEDP II.1982The Vocational Exploration Demonstration Project: AnNnalysis of of Demonstration Project: APreliminary Analysis of VEDP II and Its Policy Implications.City University of New YorkE 1981The Youth Incentive Entitlement Pilot ProjectsDemonstration: How Youths View the Program, An AttitudinalStudy.Prepared by B. Joans, John Jay College of CriminalJustice, for MDRC.I 1981Final Evaluation Report on Oswego Youth Community Service.Prepared by M. Gittell, with M. Beardsley and M. Weissman.I 1981Final Evaluation Report on Syracuse Youth Community Service.Prpared by M. Gittell, with M. Beardsley and M. Weissman.Clark, Phipps, Clark & Harris, Inc., New York1979Career Advancement Voucher Demonstration Project. FinalGuidelines.1980Career Advancement Voucher Demonstration Project. The FirstAcademic Year.1981Career Advancement Voucher Demonstration Project. SecondYear Final Report.CSR, Inc., Washington, D.C.E 1981Report on Impacts: Study of New Initiatives E.P. Jr.E Study of New Youth Initiatives inApprenticeship.E 1981Study of New Youth Initiatives in Apprenticeship.Dynamic Programs, Inc., Trenton, N.J.I 1982 CeerF.33Dtnj20m--ComrativeAnalsesPrramParticipants and Matched Controls. Prepared by L. Mehl.Educational Testing Service, Princeton, N.J.E 1980Assessment of the Youth Career Development Program forSchool-to-Work Transition: A Phase I Evaluation-Demonstration Study. Technical Report no. 2. Prepared byD.A. Rock and N.E. Freeberg.E 1981Eight Month Follow-up Evaluation of the Youth CareerDevelopment Program for School-to-Work Transition. AnAddendum to ETS Technical Report no. 2. Prepared by D.A.Rock and N.E. Freeberg.E 1981Assessment of the U.S. Employment Service Project STEADY.Technical Report no. 9. Prepared by J. Grandy.1981Assessment of the National Football League PlayersAssociation Vocational Exploration Program (Unions forYouth`, Summer 1979. Technical Report no. 4. Prepared byD.A. Trismen.1981Assessment of the National Football Lea ue PlayersAssociation Vocational Exploration Program (Unions forYouth), Summer 1980- Technical Report no. 17. Prepared byE.C. Driscoll.E 1981Assessment of the SER Career Exploration Program, Summer1979.Technical Report no. 5. Prepared by D.A. Trismen. 253 224 E 1981Evaluation of A Service Mix Alternatives DemonstrationProgram For Out-of-School Youth. Technical Report no. 7.Prepared by N.E. Freeberg and D.A. Rock.E 1981Assessment of the Bureau of Apprenticeship and Training (BAT)School/Work Linkage Projects. Technical Report no. 8.Prepared by J. Grandy.1981Assessment of the Gra hic Communications Trainin Pr ramGiant Stet.Technical Report no. 10. Prepared by R.T.Murphy and L.R. Appel.E 1981Assessment of the National Puerto Rican Forum School to WorkProgram NPRDSTWP. Year 1.Technical Report no. 11.Prepared by Appel.1981Assessment of the Health EntuProgram--Project HOPE. Phase no. 12.Prepared by R.T. Murphy and L.R. Appel.1981Assessment of the National Urban League Summer OccupationalAwareness Program 1979. Technical Report no. 6. Prepared byT.L. Hilton.E 1981Assessment of the SER Career Exploration Program, Summer1980.Technical Report no. 13. Prepared by D.A. Trismen andE.C. Driscoll.I 1982 Almlessat)ftperheCororate Career Demonstration Program.Technical Report no. 14. Prepared by D.A. Trismen.1982Assessment of the Junior Achievement Adaptation DelvmstrationProgram.Technical Report no. 15. Prepared by D.A. Trismen.1982Assessment of the PUSH For Excellence, Inc. CareerExploration Demonstration Project. Technical Report no. 16.Prepared by T.L. Hilton.E 1982Assessment of the National Puerto Rican 2orum Program1980-1981.Technical Report no. 20. Prepared by D.A.Trismen.1982Assessment of the National Urban League Summer OccupationalAwareness Program 1980. Technical Report no. 18. Preparedby T.L. Hilton.E 1982Evaluation of the Youth Career Development Program forSchool-to-Work Transition, Phase II: Replication with Juniorand Senior g':11:111W2511j2:Aarts. Technical Report no. 19.Prepared by N.E. Freeberg and D.A. Rock.1982 Assessment of the Green Thumb Youtt. Demonstration Program.Technical Report no. 21. Prepared by D.A. Trismen.19112Assessment of Six Youth Employment Programs: Rural Youth andHousing Partnership, Youth Agricultural Entrepreneurship,Economic Development through Community Improvement, Jobs forYouth, Second Chance, Assembly Youth Employi.ent (NationalAssociation for Southern Poor). Technical Report no. 22.Prepared by D.A. Trismen.1982The Social Demography of Participants and Controls in YouthEmployment and Demonstration Proje'ts Act (YEDPA) Programs:Information Derived from the Standard Assessment System DataBase.Final Data Base Report no. 1. Technical Report no.23.Prepared by L.F. Cole, J.M. Goodison, and D.A. Rock. 254 225 1982Demonstration Programs for Youth Employment Training: TheEvaluation of Various Categories of YEDPA Program Sites.Final Data Base Report no. 2. Technical Report no. 24.Prepared by D.A. Rock, N.E. Freeberg, D.A. Trismen, between Program Processes and EmploymentOutcomes for YEDPA Youth. Final Data Base Report no. 3.Technical Report no. 25. Prepared by D.A. Rock, N.E.Freeberg, J.M. Goodison, and J. Pollack.Graduate School for Community Development, San Diego1981Second Year and Final Report: Junior Achievement AdaptationDemonstration Project.Greenleigh Associates1981Evaluation of HRDI-:.YEP Pr ram:1980 Final Re..r .Institute for Economic Development, Washington, D.C.n.d.Electronic Industries Foundation JET Program. Final Report.Prepared by V.C. Knorr and S.L. Patton.James H. Lowry and Associates, Chicago, I11., and Washington, D.C.1980Research and Evaluation of the A. Philip Randolph EducationalFund Youth Employment Programs An Analysis of FactorsRelated to Participants Leaving School.1980Research and Evaluation of the A. Philip Randolph EducationalFund Youth Employment Programs An Analysis of factorsRelated to Employment of YEP Participants.Jobs for America's Graduates, Washington, D.C.E 1983Initial Employment and Earnings Impacts of JAG ProgramsOperating During the 1981-2 School Year. Prepared by A. Sum.Manpower Demonstration Research Corporation (MDRC), New YorkE 1979The Youth Entitlement Demonstration Program: A SummaryReport on the Start-Up Period of The Youth IncentiveEntitlement Pilot Projects January-June, 1978.E 1979The Youth Entitlement Demonstration: An Interim Report onProgram Implementation. Prepared by J. Ball, W. Diaz, J.Leiman, S. Mandel, and K. McNutt.E 1979 A Preliminary Estimate of the Impact of Youth Entitlement onSchool Behavior. Prepared by S. Mandel and L. Solnick.E 1980The Youth Entitlement Demonstration: Second Interim Reporton Program Implementation. Prepared by W. Diaz, J. Ball, N.Jacobs, L. Solnick, and A. Widmar.F 1981The Participation of Private Businesses as Work Sponsors inthe Youth Entitlement Demonstration. Prepared by J. Ball andC. Wolfhagen, with D. Gerould and L. Solnick.E 19P1Project Redirection: Interim Report on ProgramImplementation. Prepared by A. Branch and J. Quint, with S.Mandel and S. Shuping Russell.E 1981The Supported Work Youth Variation: An Enriched Program forYoung High School Drop -outs. Prepared by V. Semo Scharfman.E 1982L!rking School and Work for Disadvantaged Youths: The YIEPPDemonstration: Final Implementation Report. Prepared byW.A. Diaz, J. Ball, and C. Wolfhagen, with J. Gueron, S.Sheber, and A. Widman. 255 226 E 1982The Enrichment Program: Strengthening the School-WorkLinkage in the Youth Incentive Entitlement Pilot Projects.Prepared by R. Ivry and C. Wolfhagen, MDRC, Eagleton Institute of Politics, Rutgerl University.I 1982Impacts From The Youth Incentive Entitlement Pilot ProlttlaParticipation Work, And Schoolirl Over The Full ProgramPeriod.Prepared by G. D.A. Smith, E.W.Stromsdorfer, G. Trask, and R. Jerrett and Life Circumstances: An Ethnographic Study ofProject Redirection Teens. Prepared by S. Brooks Levy, withW.J. Grinker.E 1984Post-Program Impacts of the Youth Incentive Entitlement PilotProjects.Prepared by G. Farkas, R. Olsen, E.W.Stromsdorfer, L.C. Sharpe, F. Skidmore, D.A. Smith, and S.Merrill.I 1984Post-Program Impacts of The Youth Incentive Entitlement PilotProjects.Prepared by G. Farkas, R. Olsen, E.W.Stromsdorfer, L.C. Sharpe, F. D.A. Smith, and S.Merrill.I 1985Final Impacts From Project Redirection: A Program For pregnant And Parentimaans. Prepared by D. Polit, J. Kahn,and D. Stevens.Mark Battle Associates, Inc., Washington, D.C.n.d.The Mixed Income Experiment: Statistical Analysis Report.Prepared for Educational Testing Service.1979Data Collection and Analysis klan. Assessment of the Statusand Results of Mixed Income Experiments.1979Guidelines and Operational Procedures for The Mixed IncomeExperiment.1980The Mixed Income Experiment. Report I:A Description ofProgram Participants.I 1980 Appendix 1: Preliminary Case Studies, from Report I:Description of Program Participants, Mixed Income Experiment.1980The Mixed Income Experiment. Report II:Midprogram Progress Report.I 1980Revised Final Report Phase I. Assessment and Status of MixedIncome Testing.1980Technical Work Plan. Follow -up Survey of Particil nts in theMixed Income Study.1981Executive Summary: The Mixed Income Experiment.1981 Mixed Income Experiment Phase III Report I: ParticipantStatus Three Months after Program Completion.1981Mixed Income Experiment Phase III Report II: ParticipantStatus Eight Months after Program Completion.1981The Mixed Income ExmrimentlReErIALL:ntill2m911211Site.1981 The Mixed Income Experiment. Report IV:Aggregate Analysis.1981The Mixed Income Experiment. Report V:Procedural Concernsin the Operation of the Multi-Site Study. 25 227Marquette University, Educational Opportunity Programn.d.Upward Bound/CETA Demonstration Project: A Summary Report onFirst Year Findings. Prepared by D. Franklin, M.K. Kinnick,and D.E. Mackenzie.Mathematica Policy Research, Inc., Princeton, N.J.I 1977Evaluation of the Economic I pact of the Job Corps Program:Interim Report Volume I. Prepared by S. Kerachsky and C.Mallar.E 1978Evaluation of the Economic Impact of the Job Cores PrramFirst Follow-Up Report. Project Report 78-14. Prepared byC. Mallar, S. C. Thornton, D. Long, T. Good, andP. Lapczynski.E 1980The Impact of Supported Work on Young School Dropouts.Prepared by R. Maynard for MDRC.I 1980A Study of Youth Employment Programs and Demonstrations inSyracuse, New York. Preliminary Report. Prepared by D.Zimmerman, J.R. Egan, and R. Ross.E 1980A Studof the Value of Out ut of Partici nts in the SummerYouth Employment Program. Final Report Preliminary Draft.Prepared by D. Zimmerman.E 1980Evaluation of the Economic Impact of the Job Corps Program.Second Follow-Up Report. Prepared by C. Mailer, S.Kerachsky, C. Thornton, M. Donihue, C. Jones, D. Long, E.Noggoh, and J. Schore.I 1982Post-Program Impacts of Supported Work on Young SchoolDropouts:Results from a Follow-Up Survey. Prepared by R.Maynard, E. Cavin, and J. Schore.E 1982Post-Program Impacts of Supported Work on Young SchoolDropouts:Results from a Follow up Survey. Prepared by R.Maynard, E. Cavin, and J. Schore.E 1982Evaluation of the Economic Im ct of the Job Cores Pr ram.. _Third Follow-Up Report. Prepared by C. Mallar, S. Kerachsky,C. Thornton, and D. Long.National Puerto Rican Forum, Inc., New YorkE n.d.School -To -Work TrPnsition Program Annual Report, 1980-1981.National Urban League, Inc., New YorkE 1980Public vs. Private Sector Jobs for Youth DemonstrationProject.Final Report.Prepared by J. Parsons.Olympus Research Centers, Salt Lake CityE 1982Evaluation of Job Track: A Youth Job Search Demonstration.Prepared by D.C. Roberts.E 1982Getting Youth on the Job Track: A Description and Evaluationof a Job Seetroh Training Program. Prepared by M. Johnson,with D. Roberts.Proaction Institute, East Lansing, Mich.1982Appendix A:The French Landing Hydro Project YouthEmployment Hydropower Redevelopment Project. Final Report.Prepared by D. Freddolino, E. Perri, and B. Re\" an. 257 228 Public / Private Ventures, Corporation for, PhiladelphiaE 1979The Development of the Ventures in Community ImprovementDemonstration: A Review and Analysis of the Process ThroughWhich a Demonstration Project Was Mounted under the YouthEmployment Demonstration Projects Act of 1977. Prepared byH.D. Shapiro and H. Blakely.1980New Career Pathways: Initial Research Report. Prepared byH.R. Arnold and G. Rubinow.E 1980The Ventures in Community Improvement Program (VICE: ADemonstration of Program Replication through the CETA System.Third Interim Research Report.E 1982Ventures in Community Improvement. Final Report of theDemonstration. Executive Summary.E 1982Ventures in Community Improvement. Final Public/Private Ventures' YouthEntrepreneurship Initiative.E 1982The Impact of Pre-Employment Services Employment andEarnings of Disadvantaged Youth. Final Report.E 1983Longer Term Impacts of Pre-Employment Services on theEmployment and Earnings of Disadvantaged Youth.Resource Consultants, Inc. (RCI), McLean, Va.E 1981Special Project for Indochirese Youth. Final Results.Prepared by D. Gosselin and M. Papageorgiou.RMC Research Corporation, Mountain View, Calif.I 1979Study of the Career Intern Program: Interim Education.I 1981Study of the Career Career Intern Program: Report-Task B:Assessment of Intern Outcomes. Prepared by G. KastenTallmadge and S.D. Yuen.Recruitment and Training Program (R-T-P), Inc., New York E 1982Career Exploration Program. Final Report.70001 Ltd., Washington, D.C.E 198070001 Ltd. Replication Process Internal Evaluation. Final Report.Prepared by M.J. Moorhouse.E 198370001 Ltd. Final Report to the U.S. Department of Labor.Team Associates, Inc., Washington, D.C.E 1982Job Corps' K. Flaherty, R. Thurman.Texas Association of Developing Colleges, DallasI 1980Evaluation of the Opportunities to Learn and Earn Project.Prepared by D.L. Ford and Associates. 258 229University of HoustonI 1981Corporate Career Demonstration Project. Executive Summary.Prepared by D.A. Sanders.I 1981Corporate Career Demonstration Project. Final Report. University of Tennessee1981An Evaluation of the Summer Science Student Program: Cycle IResults for the San Juan, Mayaguez and Goodyear AtomicSites.Prepared by K. Rasmussen Lounsbury, M.S. Weaver, andJ.W. Lounsbury for Oak Ridge Associated Universities, Inc.,and U.S. Department of Energy.1991An Evaluation of the Summer Science Student Pr ram:C cleII Results for the San Juan, Mayaguez and Goodyear AtomicSites.Prepared by K. Rasmussen Lounsbury, M.S. Weaver, andJ.W. Lounsbury for Oak Ridge Associated Universities, Inc.,and U.S. Department of Energy.Vera Institute of Justice, New YorkE 1983Alternative Youth Employment Strategies Project: AnEvaluation.Special Summary. Prepared by S. Sadd, M. Kotkin, and S.R. Friedman.E 1983Alternative Youth Employment Strategies FinalReport.Prepared by S. Sadd, M. Kotkin, and S.R. Friedman.Washington State Building & Construction Trades Council, OlympiaI 1982Capacity Building Demonstration Project. Final Report.Prepared by R. Oilger. IMPLEMENTATION REPORTSCenter for Labor Market Studies, Northeastern University1980Youth Knowledge Development Report (3.20), CETA Prime SponsorSelf-Reviews.Prepared by A. Sum, P. Harrington, and G.Schneider.Center for Public Cervice, Brandeis University1980Youth Knowledge Development Report (8.6), Improving theImplementation of YEDPA Programs.Office of Youth Programs, Employment and Training Administration, U.S. Department of Labor1980Youth Knowledge Development Report (12.2), Linkages BetweenEducation and Employment and Training Systems--Volume I.1980Youth Knowledge Development Report (12.3), Linkages BetweenEducation and Employment and Training Systems--Volume II. 1980Youth Knowledge Development Report (12.5), Work-educationCoulicils--Collaborative Approach.National Collaboration for Youth National Assembly, Washington, D.C. 1980Youth Knowledge Development Report (12.1), Linking withVoluntary Youth-Serving Agencies.National Council on Employment Policy, Washington, D.C.1980An Anatomy of School-to-Work Transition Projects. Preparedby B. Dunn and R. Taggart. 25i 230 1980Youth and the Local Employment Agenda: An Analysis of PrimeSnsor Exrience Im lementing the Youth Em loyment andDemonstration Projects Act. Overview and Area SummariesFinal Report.Prepared by G. Wurzburg.1980 Getting Tuere: A Case Study Report on the Lives, EmploymentPreparation, and Prospects of YEDPA Participants. Based onthe Findings of the Youth Perspectives Project Conducted fromNovember 1978-June :.479. Prepared by B. Snedeker.1980Overview to the Local Focus on Youth: A Review of PrimeSponsor Experience Implementing the Youth Employment andDemonstration Projects Act. Prepared by G. Wurzburg.National League of Cities, Washington, D.C.1980Youth Knowledge Development Report (3.18), CETA YouthPrograms in Small the Product.Unpublished papeL. 260 APPENDIX Implications of the Youth Employment Experience forImproving Applied Research and Evaluation PolicyRol,--\" Boruch Try all things; hold fast that which is good.I Thessalonians 51:21 INTRODITCTION Determining what is good is no easy matter. The pu dose of thisappendix is to capitalize on hard experience in making that judgment inone arena--employment and training programs supported by the federalgovernment.The program evaluations reviewed by the Cormittee on YouthEmployment Programs have a variety of implications for evaluationpulley.The aim of this appendix is to educe some of thoseimplications.The committee also relied on earlier reviews of sociaand educutional program evaluation generally (Riecken et al., 1974;Rivlin, 1971; General AccountingOffice, 197' others).The diLcv sion is concerned with obtaining better evidence withwhich to answer fundamental questions abot.:. youth employment andtraining programs: Who needs the services?How well a:e services delivered?What are the relative effects of the service\"'What are the relative benefits and costs of alternativeservic.,s? The implications are grouped into two simpler categories:Improving the design of outcome evaluationsImproving reporting Each implication is Followed by a brief description of evidence andrationale. Roert F. Boruch is professor of psych logy, Center for Probability andStatistics, and director, Division of Methodology and EvaluationResearch, Northwestern University. 231261 232IMPROVING THE DESIGN OF OUTCOME EVALUATIONSOnce said, it is obvious that quality in the design of an outcomeevaluation affects he quality of the data and of conclusions. Poordesigns can make programs look worse than thty are, or better than theyare, or yiele uninterpretable evidence. Quality and Evaluation Polio\" in General Quality in evaluation design ought to be recognized and ought to beexplicit in an a encvls evaluation licy and in con ressional oversi htpolicy.Special efforts need to be made to improve the quality ofresearch and evaluation designs for estimating the impact of youthemployment projects. Existing professional guidelines can be used toinfluence the quality of design and the quality of reporting.The theme of quality has been explicit in the Department of Labor'sKnowledge Development Plan, insofar as the plan yoked the introduction of new programs to good evaluation design. That is,plan recog-nized the legitimacy of the idea that good impact evaluations can onlybe done if conditions are controlled and evaluation is planned andbegun at the start of a program. This theme appears also in the U.S.General Accounting Office's (19,8) attention to competing explanationsthat characterize the results of poor research designs, to the elementsof reasonable design, and to the need for designing the evaluationbefore a new program is put into the field.The theme has been recognized by the courts in cases that recognizethe shortcomings in some evaluation designs and the benefits of others,e.g., copaymentE in health insurance. Injunctions have been issuedagainst poor designs, for example, and challenges to good designs havebeen defeated (Breger, 1983, for specific cases).Despite this, the quality of evaluations of youth employment andtraining programs is still not sufficiently high. Less than 30 percentof the reports examined by this committee, for example, were of highenough quality to be reviewed seriously. Projects rejected for seriousconsideration by this committee were flawed by t _e lack of sensiblecomparison groups, unreliable measvres of program outcome, vague objec-tives, and other shortcomings. Our acceptance rate is low, but itsill represents progress. Rossi's (1969) review of 200 evaluationsissued by the Office of Economic Opportunity before 1968, for example,uncovered no randomized field experiments and only about 25 reportswith credible evidence.Professional and institutional guidelines for improving the qualityof evaluation designs are readily available. Section A of the bib-liography lists guidelines that pertain to evaluation design andreporting in health and health services, education and training,welfare, and other areas. The references include applications ofstandards and ase.:ssments of their common features and usefulness. Itcould not be unreasonable to adopt variations on these in evaluationpolicy. 262, 233Randomized Field ExperimentsRandomized field experiments should be explicitly authorized in law and encoura ed in evaluation licy as a device for estimating theeffects of new projects, program variations 4 and program components.Randomized field tests of new programs, program components, orprogram variations are a scientifioally credible device for obtaininginterpretable evidence about a program's effects. But they aredemanding with respect to the requirement that individuals or schoolsor ether organizational units must be assigned randomly to programvariations or to program versus control conditions.The usefulness of randomized tests, in principle, is generally notat issue in professional discussWns about estimating the impact ofprograms.That is, there is substantial agreement that when experimentsare conducted properly, estimates of effects will be unbiased. Theconditions under which experimental design can be or should be employedare more debatable, however (e.g., Cronbach and others, 1980; Boruch, 1975).How precedent, pilot tests, ethics, and law constrain orenhance feasibility is considered briefly below. PrecedentSome optnts of controlled randomized tests maintain thatrandomized experiments are rarely feasible in field settings. Thereferences in Section B of the bibliography constitute evidence against the claim:the reports listed cover some recent, high-qualityexperiments.Randomized field tests have been undertaken, for example, to get atthe effects of new law enforcement procedures (Sherman and Berk, 1984,1S 5) and innovative methods for improving court efficiency (Partridge and Lind, 1983). They have been used to assess the relative benefitsand costs of special health services delivery methods and practices,e.g., day care for the chronically ill and medical information systems.They have produced good evidence on the effects of diversion projectsfor delinquent youths in California, telephone conferencing in adminis-trative law hearings in New Mexico, post-prison subsidy programs inTexas and Georgia, and nutrition education projects in Nebraska.Not all attempts to use randomized field tests succeed, of course.The procedure may and indeed has been corrupted in medical experiments,e.g., early tests of the effects of enriched oxygen environments onretrolental fibroplasia (Silverman, 1977). And they have failed attimes in formal efforts to evaluate court procedures, educationalinnevation,, and other social programs (e.g., Conner, 1977).Judging from precedent, however, it is not impossible to assignindividuals or other units randomly to programs for the sake of fLirestimates of program effects. Good randomized experiments have indeedbeen mounted.The reasons for successes and failures need to bestudied. 263 234Pilot Tests of Randomized Experiments Precedent is persuasive in the crudest sense: It implies that whathas been done might be done again. Still, experience with a randomizedtrial in one setting may be irrelevant in others.For this reason, pilot tests of large-scale field experiments areworth considering. That is, small experiments prior to the main fieldexperiment can provide evidence on feasibility that is more direct thanwhat precedent can offir, can identify problems that otherwise couldnot be anticipated, and can help to resolve predictable problems beforethe main effort.That there can be major problems in mounting randomized tests isclear from the Youth Employment Program experience (see Section C ofthe Bibliography). 'For instance, difficulties were encountered in theTallmadge and Yuen evaluations of the Career Intern Program and theevaluation of the Career Advancement Voucher Demonstration (CAVD)program for low-income college students (Clark, Phipps, Clark & HarriP,Inc., 1981; hereafter CPC&H). Some 30 randomized tests of Head Startprograms were initiated in the late 1970s, despite counsel for pilotwork:fewer than 10 succeeded. Randomized tests have also beenunsuccessfully implemented in meliclne, law enforcement, and otherareas, because the randomization was corrupted.That attempts to run good randomized trials in the youtil employmentsector were imperfect, or that other attempts have failed miserably,should not be unexpected. Imperfection and failure are our lot, justas improvement is.The pilot test strategy has helped to ensure the quality of fieldexperiments on telephoLe conferencing in the administrative courtsystem.For instance, city tests served as a pilot for a statewideexperiment in administrative appeals in New Mexico (Corsi and Hurley,1979).The strategy has also been uses' to enhance quality in the youthemployment program research. The Supported Work Experiments in fivecities were preceded by a pilot effort in one city by the VeraInstitute, and it did have a bearing on the quality of those experi-ments.The approach seems sensible in view of these efforts, thefailed efforts, and experience from other areas. Hahn's (1980 advicein the industrial commercial sector is similar, for similar reasons. Ethics Where there is an oversupply of eligible recipients for scarceprogram services, randomized assignment of candidates for the resourceseems fair.Vancouver's Crisis Intervention Program for youthfuloffenders, for instance, offered equal opportunity to eligible recipi-ents.Since all participants could rot be accommodated well withailable program resources, but were all equally eligible, they wererandomly assigned to program or control conditions.More generally, randomized experiments are most likely to beregarded as ethical when the services are in short supply, theireffectiveness is not clear, and someone is interested in effectiveness. 264 23R This rationale dovetails neatly with some managerial constraints. Thatis, despite the aspirations of program advocates, new programs cannotbe emplaced all at once, but must be introduced in stages, e.g., ser-vices are delayed for some. The argument for the ethicality of randomassignment to scarce resources is not especially pertinent when themanager can simply spread resources more thinly, e.g., by expanding thesize of classes dedicated to special instruction in tests of trainingvojecte. Randomized field tests have received attention only recently fromthe courts and from constitutional scholars. The attencion, however,has been thorough and productive.Pertinent court decisions, for example, include Aguayo v. Richardsonand California Welfare Rights Organizations v. Richardson. These casescLallenged the use of randomized experiments in assessing welfare pro-grams, but the challenges were dismissed by the court. Legal analysesof such cases are given by Breger (1983) and Teitelbaum (1983); Bermantet al. (1978), Federal Judicial Center (1983), and Rivlin and Timpane(1975) give mc,re general treatments. Statutes that recognize thelegitimacy of randomized experiments are scarce, however, and that isone reason for recommending explicit reference to randomizedexperiments in law. The People Targeted for Services: Characteristics, Access, and Number Su-leys prior to mc:nting a field test are essential to ensure thatco le tar eted for service or action are aidentifiable btrainable in the ex rimental regimen and (c) sufficient in number towarrant the investment in a controlled randomized experiment.Program managers sometimes promise to randomize because they presumethe target population is large enough tc permit random assignment ofindividuals to \"program\" versus \"control\" conditions or to programvariations.The presumption has been wrong at times in medicalresearch, e.g., experiments in day care for the chronically ill duringthe late 1970s. It has also been wrong in educational research, notablyin attempts to do randomized field experiments on Read Start preschoolprograms and in planned variations. And it has been wrong in manpowertraining programs prior to 1966, to judge from Rossi's (1969) descrip-tion of the National Opinion Research Center's (NORC's) failure torecruit enough clients for experimental tests of an employment trainingprogram.If there are too few individuals in need of the service andwho are accessible and willing to participate, one will be unable toexecute an experimes' sell.The reasons fog lrror in the presumption include ignorance: It isoften very hard to estimate the number of those in need of specialservices, harder to identify them, and at times harder still to under-stand how to train them in a program. They include greed, of course. 265 236 The funds made available fe- a special program and for an experimentproduce inflated counts of tnose in need.Regardless of the reasons for the error, the matter is important ifwe expect to have decent tests implemented. What do the youth employ-ment experiments tell us about this?For the Manpower Demonstration Research Corporation (MDRC), thereseems to have been no remarkable problems in identifying and enrollingmembers of various target groups for the Supported Work Program. Still,MDRC says it may not have focused sufficiently well on the right targetgroup in its explanation of why effects on youths fail to he substan-tial.Nor is there any reference to shortfall in the reports by theVera Institute on the Alternative. Youth Employment Strategies Project.The report on the Opportunities Industrialization Center (Inc) project(O'Malley et al., 1981) is ambiguous on this account.In the CAVD program, on the other hand, \"All CETA prime sponsorswere to recruit a pool of at least 200 youths between the ages ofsixteen and twenty-one who met YETP eligibility requirements and whodesired and were available for full time work\" (CPC&H, 1980:15). Some150 to 170 were eventually assigned to alternative treatments. Thetarget sample size was partly a function of local screening criteria.Recruitment and assignment difficulty is discussed in the report(CPC&H, 1980).Difficulty in recruitment was encountered in four offive sites.In three sites, the difficulty seems serious, said to becaused by internal organizational problems (e.g., a move to a differentbuilding) or interinstitutional problems (e.g., one agency doing thescreening, another the program implementation).Similarly, the Project STEADY evaluation reported that \"sufficientnumbers of youth were difficult to --cruit\" and that start-up time forthe program was brief according to e directors (Grandy, 1981). TheSPICY project for Indochinese youths was targeted for 120 youths persite, but obtained only 70 to 80 individuals. The Tallmadge and Yuenreport on Career Education programs gggests that only three ratherthan four cohorts (with a projected 75 per cohort) were enrolled ateach of the four sites. Further, the first two of the three cohortscontained fewer than the 75 members that were forecast (an extension ofthe period led to complete cohorts). Hahn and Friedman's evaluation ofthe Cambridge Job Factory for out-of-school youths encountered problemsin recruitment because there were related summer programs in the samearea.Their work in Wilkes-Barre suggests the enrollment problem wassevere in that area (53 percent of target reached) and that it affectedboth the Youth Employment Service Program and the Employer-VoucherProgram.The problem was attributed to competing CETA programs.A few of the experiments at hand also tell us something about thetractability of problems in the target population. The Supported WorkProgram run by MDRC, for instance, suggests that women receiving Aid toFamilies with Dependent Children profit more than young people do fromthe services provided. It is not clear that \"tractability\" can beassessed well in prior surveys of a targeted group. The experiencedoes suggest that it is important to separate ostensibly differentsubgroups in the experiment and to establish that their members can beidentified well in prior surveys. 266 237Sensitivity of Field ExperimentsStatistical power analyses and reporting on the analyses areimportant and ought to be undertaken routinely. This is elementalquality assurance for any evaluation policy.By power analysis here is meant formal calculation of the probabil-ity of finding an effect, if there indeed is an effect, despite a noisycontext.Critical reviews of field experiments in health services,education, and other areas stress that (a) the effects of projects willusually be small and (b) sample sizes are often too small to detectthose effects.That is, differences between program and control groupsare likely to go undetected.Three of the experiments reviewed by this committee had sampleslarge enough to justify the expectation that an effect would be detectedif indeed youths were influenced by the regimen. The Vera Institute'sstudy, for example, involved 600 to 800 individuals per site, withabout 300 in a control group and 100 in each of three program variationgroups.OIC had about 1,500 participants and 700 controls distributedacross seven sites. MDRC's sample size exceeded 1,200, over five sites.Other experiments listed in Section C of the Bibliography involvefar smaller samples, however. And so it is difficult to understand howa small project effect could be detected. The CAVD project, forexample, involved assignment of fewer than 30 individuals per group ineach site.At'rition led to even fewer, e.g., 4 individuals in a sitein one analysis of dropouts. And so it is no surprise that differencesamong groups are often insignificant. The Indochinese SPICY projecthad 70 to 80 individuals per site in three sites and analyzed the sitesseparately.(They did detect effects.) Tallmadge-Yuen's Career Internreport suggests that there were, at most, 75 subjects per cohort persite; there is no reference to a power analysis in th final report,and results are mixed. Measures of Program Implementation More or,..Jrly, verifiable information on the degree of programimplementation needs to be collected. Better, less-expensive methodsfor obtaining and reporting such infoldation also need to be developed.And basic research needs to be conducted to link implementation datawith impact data.No outcome evaluation should exclude measurmant of the level ofprogram implementation. Such data art.: as :asential in social programevaluation as measurements of dosage level and compliance are in evalu-at.ng new drugs and therapy.At its crudest, measuring implementation may focus on structuralfeatures of the program's construction. This includes establishing thetime trame required for actualizing major parts of program plans.Information about the time it takes for a new program to become stabil-ized, for instance, is often sketchy even for large-scale nrograms.Measurement should include crude observation on staff, material, andresources, and on the recipients of services ant their eligibility. 267 238See Rezmovic (1982), for instance, on tests of programs for former drugaddicts.It is also reasonable to expect such measurement efforts to documentthe way implementation is degraded. The Tallmadge and Yuen (1981:4)report, for example, stre \"ses staffing problems at all four experimentalsites, problems that are said to be attributable to 'extremely com-pressed time schedules and bad timing associated with start up opera-tions.\"Related reports cover actual program composition and thequalitative features of client and program interaction.It seems sensible also to establish what kinds of services areoffered to control group members. For they, too, may participate inother programs that are implemented to some degree.This measurementseems especially important insofar as 20 to 40 percent of control groupyouths in a given site may in fact avail themselves of services from other sources.The problems of assuring that treatments are delivered as adver-tised, of measuring the degree of implementation, and of understandinghow to couple implementation data and experimental data are not confinedto the youth employment arena, of course. Poorly planned and executedprograms occur in the commercial sector, though information about thisis sparse for obvious reasons (pee Hahn, 1984). Despite good planning,meteorological experiments have been imperfect and admirably welldocumented (Braham, 1979). Drug trials and other randomized clinicaltrials in medicine must often accommodate departures from protocol andnoncompliance (e.g., Silverman, 1977). And so on. \"Evaluability\"The extent to which projects and programs are \"evaluable\" should beroutinely established before large-scale evaluation is undertaken.Not all programs can be evaluated with the same level of certainty.New projects, for instance, often present better opportunities forobtaining interpretable estimates of project effects than ongoingones.It is also clear that limitations on resources and experienceprevent even new programs from being evaluated well.The need to anticipate how well one might be able to evaluete hasgenerated interest in the \"evaluability\" of programs.The idea offormal assessment, proposed by Joseph Wholey and extendedby Leonard Rutman and others, involves addressing specific questionsabout whether an evaluation can be designed to provide useful. infor-mation in a particular setting, especially whether decisions or changes can be made on the basis of the information. It has beer suggestedthat the approach be employed before demanding evaluation in everyinstance.Evaluability assessment has received some support and pilot testingin Canala and the United States ( Wholey, 1977; Rutman, 1980). Thestrategy is imperfect in that it asks one to predict .success based onexperience that may not exist. But it is useful in identlfy!..ng thesenses in which evaluation is possible and potentially helpful. It isa promising device for avoiding unnecessary effort. 268 239More to the point, the idea is to learn how to aid putting moneyinto evaluations that cannot be done well or are likely to be useless.More generally, the approach can provide a frameworL for understandinghow to achieve compromises between the desirability of special designs,such as a randomized experiment, and operational constraints of theprogram, and for understanding the kinds of evaluation that will beuseful. Testing Components and Variations Testing the components of programs is warranted, especially whentests of full programs are not feasible or appropriate.No theory of evaluation demands that the effects of an entireprogram be estimated. Few practitioners wc'!ld regard the requirementas reasonable.Yet rhetoric and legislative mandates foster this view,distracting attention from the possibility of testing importantcomponents of programs or variations on them. For example, one mayfind that running high-quality tests of an entire training program isnot possible.But estimating the effect of alternative sources ofinformation, ways of presenting information, ways of enhancing use ofinformation, and so on, may be possible in small, high-qualityexperiments.The strategy has been exploited in a few youth employment programevaluations, in research which preceded development of Sesame Street,and in experiments on surgical and health innovation. Incorporatedinto evaluation policy, the idea broadens cptions. And in the event ofa major evaluation's failure, it is a device for assuring that at leastparts of the program can be assayed well. AttritionFar better methods need to be invented and tested to controlattrition and to understand its effects on analysis. Resources need tobe dedicated to the activity.Individuals who voluntarily participate in any social program arealso free to abandon the nrogram. Individuals who participate in arandomized control group or some alternative to which they have beenrandomly assigned--by answering questions about their work activity forinstance--are also free to withdraw.The loss of contact with individuals in either group is importantinsofar as it affects how easily and confidently one can interpret theresults of an experiment. To put the matter simply, if contact is lostwith individuals in both ;coups, there is no way to determine theproject's impact on participants.If the program maintains good contact with the participants, forinstance, but fails to track nonparticipants well, it may generateevidence that makes the program look dernaging when in fact it isineffectual, or that makes the program appear effective when in factits impact is negligible or even negative. 269 240When the attrition rate in the program group differs appreciablyfrom the rate in the control group, making inferences is morecomplicated.Suppose, for instance, that all individuals who \"att'it\"in the control group found jobs. Analysis that fails to recognize thiswould probably produce inflated estimates of the program's effect.Problems in attrition in field experiments were sufficientlycritical to warrant the committee's rejecting over half of them forserious review. This does not always imply that the work was unsal-vageable, merely that resources do not permit determining tf theanalytic problems engendered by attrition could be resolved. CAVD'sdifferential in rate of interviewing, for instance, is substantial,e.g., 80 percent for the participants and 50 percent for controls.There is no discussion of the potential problems. There is no attemptto accommodate them in the report at hand. The Vera Institute (Sadd etal., 1983:18), on the other hand, reported about equal rates ofattrition, e.g., \"premature dropout was substantial and depended on(program) model,\" but there are no details. Interview completion ratesare given in the 60 to 84 percent ranee for the program group and inthe 60 to 84 percent range for the control group.The Tallradge and Yuen study of the Career Intern Project isunusual in having tried to accommodate the possible biases due todifferential attrition by matching individuals first and then keepingonly full pairs for analysis. For all four sites, they got rates inthe 50 to 70 percent range.OIC does no formal analysis of the effect of attrition. Theirreport does, however, give completion rates and rates at which com-parison groups have access to programs. They ignore these differencesin their analysis or discard controls who did become involved inprograms.Nothing is said about cooperation 3 and 8 months afterprogram completion though they give data on each point.The Project STEADY report is conscientious in providing a tablethat illustrates the flow and attrition rate at various stages in theexperiment (Educational Testing Service, 1981:Table 1, p. 26). It is ashame, however, that no serious statistical/analytic attention wa3brought to bear on this. Coupling Experiments to Longitudinal and Panel StudiesRandomized experiments ought to be coupled routinely to longi-tudinal surveys and par.0 studies. Ths_purposes of this \"satellite\"policy include calibration of ion randomized experiments, more general-izable randomized experiments, and better methods for estimatingprogram effects.Longitudinal surveys based on well-designed probability samples areclearly useful, for science and policy, in understanding how individuals(or institutions) change over time. For example, they avoid the logicaltraps that cross-sectional studies invite, such as overlooking cohorteffects, in economic, psychological, and other research.Such studies are, however, often pressed to produce evidence thatthey cannot support. Of special concern here is evidence on the impact 27'0 241 of social programs on groups that the longitudinal study happens toinclude.So, for example, the Continuous Longitudinal Manpower Survey(CLMS) has been justified and supported primarily on grounds that oneought to understand what happens to the hunan resources pool. Itssecondary or tertiary justification is that is can help one understandthe effect of special programs--in youth employment, training, and soon.Such justification may be useful for rhetorical and scientificpurposes.nut it is dysfunctional insofar as the claim is exaggerated.That is, longitudinal surveys are often not sufficient to permitconfident estimation of the effect of programs designed to, say, affectearnings of individuals who happen to be members of the sample, crimerates of those people, and so on.That the claims made for longitudinal surveys with respect toevaluation of programs can be misleading is clear empirically andanalytically.The most dramatic recent empirical Pvidence stems fromFraker and Maynard's (1985) comparisons of program effects based onrandomized experiments and effects based on nonrandomized data, notablythe CLMS and the Current Population Survey. Earlier evidence in differ-ent arenas stems from the Salk polio vaccine trials, health servicesresearch, and others (see Boruch, 1975, for listing).Randomized experiments, on the other hand, permit one to estimatethe effects of projects with considerably more confidence. Indeed thecommittee report is emphatic on this account. A major shortcoming ofexperiments, one not shared by the large-scale longitudinal studies, istheir limited generalizability. That is, a set of experiments might befeasible in only a half-dozen sites, sites that do not necessarilyreflect national characteristics.The implication is that one ought to invent and try out researchpolicy that helps to couple the benefits of longitudinal studies, i.e.,generalizability, with those of experiments, i.e., unbiased estimatesof program effect.This policy element is akin to science policy on satellite use.That is, the satellite, like the longitudinal study, requires enormousresources to emplace and maintain. It pays to capitalize on them.Further, the scientist who designs special-purpose studies can obtainaccess to part of ':he satellite to sustain his or her investigation.Just as the physicist then may use the satellite as a vehicle forlimited, temporary investigation, the policy recommended here allowsthe researcher the optiot, of using longitudinal infrastructure as aresource and as a vehicle for conducting prospective studies.The policy element gets well beyond simple scientific traditions of\"dat.,, sharing\" (Committee on National Statistics, 1985). It is con-siderably more debatable and more important in principle. Access islikely to be feasible, for example, only for a few projects, perhapsonly one every year or two, because of the sheer difficulty of couplingstudies to an already complex longitudinal enterprise. 271 242 Theory:Amateur and OtherwiseThe theories underlying programs are often puny at best andfragmented and poorly articulated at worst. They need to bestrengthened and coupled to evaluation design. Resources have to bededicated to the effort.Even in the engineering sciences, elements of theory are at timesweak and ambiguous. And applications of well-explored theory, e.g.,classical mechanics and the conflation of several complex theories orlaws operating in a complex environment, may lead to analytic problemsthat are intractable. And so, it is not uncommon to design randomizedexperiments to assess changes in chemical production processes,acoustics, and other areas (e.g., Hahn, 1984).The same problems occur in the social sector of course, in spades.Moreover, the science is young so good theories are not in abundantsupply.Indeed, the absence of formai, well-explicated theory is ajustification for randomized trials in the social sector, just asexperiments are sometimes a last ditch effort to achieve understandingin the engineering arena.To be sure, commonsense notions of how a program is supposed toproduce an effect is theory of sorts. Most aphorisms are prescriptivetheories.But such theory is not accurate simply by virtue of experi-ence, its amateur status, or the desirability of results that thetheory-based program is supposed to produce. Which means the theoryand the program based on it may also be in,ocurate.Examples of inadequate commonsense theory and of well-articulatedtheory are easy to find, There is room for improving both varieties indifferent ways. One of the ways, for Chen and Rossi (1980) is to letthe theorist, rather than only the program administrator, chooseoutcome variables that are likely to be influenced by what the programis supposed to do. The administrator may telieve that program willaffect salaries, for example. But the theorist may recognize that, inthe time available, salary changes may be undetectable and instead oneought to measure more immediate, plausibly expected effects on, say,skill or knowledge level. The benefit is enhancing the likelihood ofdetecting some effect, in the short run, and theory enhancement, in thelong run.The need for enlarging the supply of good theory seems obvious. Totake a simple variable such as time, for instance, few formal social orbehavioral theories have been laid out (partly because experience issparse) to explain the time required for a new project's stabilization,time required on tasks to produce effects on skills, time required tobenefit through skills in the market price, or time involved in thedecay of benefits. Yet theory that incorporates time variables seemsessential to designi, -, executing, and evaluating programs well.More complicated examples are not hard to develop. For example,so-called selection models have been developed by Heckman and Robb(1985), among others, to describe analytically how program applicantswind up in one program regimen versus another. The approach seemssensible insofar as it leads to a substitute for experiments and betteranalyses of nonrandomized trials. 272 243 Such models are in fact small theories and they have the merit. ofbeing explicit and often ingenious. Their shortcomings lie in theirparochialism:each is a notion developed by a mathematically orientedanalyst, who is unlikely to have (a) come within sniffing distance of areal program, i.e., not done empirical studies of the enrollment processand (b) taken the trouble to exploit theory from disciplines outsideeconomics.For example, it takes no wit to recognize that enrollment processesinvolve information, supplied to and available to administrator andapplicant, and decisions by each. The information is processed underconstraints; the decisions are made under constraints. Why then do wenot exploit, say, the theories and rules of cognitive processing thathave been developed over the past 10 years by Herbert Simon, Kahnemanand Tversky, and others to develop something more realistic and morecoherent than the simplistic selection models that the ill-informedanalyst might choose? The reason seems to lie more in disciplinaryprovincialism than in any inherent weaknesses in either kind of model.The point is that far more integration of theory and practicalprogram development and evaluation is warranted. Absent the integra-tion, it is doubtful that one will learn much that is durable. IMPROVING THE QUALITY ANDINTERPRETABILITY OF EVALUATION REPORTSThe quality of evaluation reporting can be improved substantiallyby adhering to professional guidelines issued over the past five years.Documentation on large-scale evaluations is generally much betterthan the information usually available on smaller, locally managedones.Nonetheless, there are notable gaps in what is known about eventhe large ones. Information is not always presented in accord withreasonable reporting standards issued, for example, by the EvaluationResearch Society (1982), the U.S. General Accounting Office (1970), andother organizations, and by individual experts, such as Mosteller etal. (1980)(in clinical trials section of the bibliography).The weaknesses in reporting maze it difficult to screen andsummarize results for policy, as this committee has tried to do. Andthe weaknesses complicate efforts to develop quantitative syntheses ofmultiple experiments so we may judge how sizes of program effect vary.(See Light and Piilemer (1984) and Cordray and Orwin (1985) onsynthesis and the problems that poor reporting engenders.]Doubtless some good projects have bean ignored because reporting igpoor.Good projects are not exploited as much as they should bebecause information prov.ded in reroorts is initficienz.So, for example, the be reports tell us what the attrition rateis from programs or from program versus control groups. But manyreports do not. Tie best of the best educe the implications ofattrition and he they have been taken into account to produce fairestimates of program effect. Most do not.The gaps make it verydifficult to review th' panty of evaluations and to adjust forquality of evaluation in gauging the success of multiple programs. 273 244 The topics that should be routinely considered in such reports areeasy to list.The following are based on fuller treatments in thereferences cited. Attrition RatesThe difference between the ultimate target samples of program par-ticipants and control-group members is crucial. Estimates of programeffect may be inflated, deflated, or remain unchanged, relative totheir true value, depending on the magnitude of attrition in the groups.Yet attrition rates are sometimes not reported. Nor are differencesreported.Even less frequently reported are analyses of how sensitivethe conclusions are to the rates and to differences in the rates. Character of FragrantUnderstanding what happens in a program is, of course, important;developing orderly, inexpensive descriptions of what happens is diffi-cult.This does not excuse one from trying to document programactivity well.Little reporting has been undertaken, partly perhapsbecause of a lack of understanding of how to measure the level ofprogram implementation well. Access to the Data Base Assuring that raw research data are accessible for reanalysis, inthe interest of facilitating criticism and secondary analysis, is notcommon.Still, it seems sensible to advance understanding of how toexploit costly information better and how to encourage thoughtfulcriticism (see Fienberg et al., 1985). The implication for researchpolicy in this arena is that reports should routinely inform the readerabout what raw e.ata are available and from whom.The vehicles for assuring the data that are available include thenormal contract system and agencies re for overseeingevaluations. Target Population/Recruitment The general characteristics of youths targeted for programs areusually a matter of law or regulation and are usually reported.Demographic characteristics of the sample are also reported.But how youths are recruited, what fraction of the availablepopulation is involved, and what kinds of problems were encour*ered intargeting are often not reported or given only superficial treatment.As a consequence, it would be difficult to replicate the program evenif it were found to be successful. And it is difficult for thethoughtful observer to reconcile conflicts among the results ofcifferent studies. 274 245Perhaps most important, shortfalls between target and actualsamples occirred Understanding the magnitude of the shortfall and thereasons for it are crucial to designing better evaluation-- Site Selection Many of the field 'est of youth employment programs involvemultiple sites, The trandomized trials reviewed seriously by thecommittee, for example, involve a randomized experiment in each G2 40sites.Very little information is provided on site selection in finalreports, however. Th. information is important for understanding thegeneral context of the test, perhaps for understanding why the prfsgramsucceeded or failed and why the evaluation was executed poo.\"- or 1,--111,and for learning whether and how the evaluation might h -eplicstoL.Final results need not pro..de great detail on site _election.Nonetheless, a reference, fo.....note, or 1.aragraph ought to provide leadsto accessible sources of writs-en :a:formation on the topic. Random Assignment The sptriiir method for randomly assigning individuals to alter-native regimens is rarely reported. The methods may be mundane. Orthey may be creative i the sense of being robust against ini_ifference,incompet,:s.ce, and corruption. In any case, reporting on method iswarranted in a footnote or appendix to assure the reader that indeedthe study was carried out as an exptviment and to permit pr..ise andcriticism of the random assignment process [see Dobson and Cook (1979);.For example, the specific mechanics of randomization are notdescribed in any final report on youth employment projects listed inSection C of the Bibliography. There are no citations to reports thatmay contai... the information.But broa. informati-P is given by some. The Tallmaog4 and vuenreport on the Career Intern Program, for instance, gives no detailexcept to say that assigrment was by \"lottery.\" -s repert on the OICproject al., ',1-034, _uals were randomlyassigned to program ver=us cont!ol groups but that \"there's no firmasst-ance that in all cases the participants were randomly assigned.\"The \"most\" detail on the topic is given in the final report forProject STEADY. Grandy (1981:17) reports that \"Project STEADYparticir-mts consisted of ran om samples of program applicants. Sitedirectors reported that all applicants drew a card fiom a hat, and onthat card was the designation of parttApant or control.\" Therandomization followed -Aministration of tests and screening thatdetermined eligibility and individualW willingness to participate inthe program.Failure to report such crucial information is not confined to theyouth employment reports. In their review of medical research journalarticles, such as the New Englafld Journal of N licine, for example, Der 275 11111111111111111=111111111101111010 246 Simmons et al. sound that only one-fifth reported anything on method ofrandomization. Statistical Power AnalysesIt is rare for final reports to specify the probability of findingprorram effects, if indeed they exist, given the sample size and otherdesign parameters. It seems especially desirable that evaluationsshowing \"no effects\" report the statistical power of the analysis.E'en when effects are found, the power calculations should be availablefor postevaluation analyses, e.g., was the size of effect obtainedclose to the effect guessed in the power analysis. Costs Information on the costs of an evaluation, apart from the cost ofthe program under examination, is almost never published in profes-sional journals or in final reports of evaluations. In consequence, itIs difficult to estimate wnat has been spent on evaluation aneimpossible to do good benefit/cost analyses of evaluations based onevidence.There is no readily accessible evidence.It sems desirable, then, to have information on costs in thereport.No uniform system for reporting costs of elements of evaluationhas been adopted. And so creation of alternative accounting systemsFor t,'dgets and expenditures is warr3ated. Graphs and Tables Tables in some evaluation reports are often dreadful, difficult tounderstand, and impossible to read quickly. And they are often sus-ceptible to misreading. Only a few reports on youth employmentexperiments are exceptional on this account. for example, computerprintouts of tables are merely reprinted, rather than being reorganizedand restructured to permit the reader to understan patterns quickly.The state of the art in conetructing tables any graphs has improvedremarkably over the past 10 years. It is a shame that it is ignored.See Fienberg (1979) and Kruskal (1980), among others, on improvingthese presentations. REFERENCES AND BIBLIOGRAPHY Bermant, G., 4.C. Kelmdn, toexperimtz. in Sociological Methodsand Research 4(1):31-53. 1976On common contentions about randomized experiment. Pp. 158-194in G.V. Glass, ed., Evaluation Calif.: Sige Publications.Boruch, R.F., and P.M. Wortman1979Some :mplications of educational evaluation for evaluationpolicy and program development. Review of Research inEducation 7:109-361.Boruc, R.F., D.S. Cordray, and G. Pion1982How well are local evaluations carried out? In L.E. Datta,ed., Local, State, and and localprograms:a summary on approp.lateness and feasioility.PabUc Administration Review 39(1):36-40.BraharR.E.1979Fiold experimentation in weather modification. Journal of theAmerican Statistical Association 74(365):57-104.Breger, M.J.1983Randomized sccial experiments 97-144 in and J.S. Cecil, eds., Solutions York:Academic Press.Chen, driven approach to evaluation: a modellinking basic and applied social science. Social Forces59(1):106-122.Clark, Phipps, Clark & Harris, Inc.1980Advanced Education and Trainin --Interim Re rt on the CareerAdvancement Voucher Demonstration. Youth Knowledge DevelopmentReport No. 5.3. Washington, D.C.: U.S. Department of Labor,Employment and Training Administration.1981Second Year Final Report: Career Advancement VoucherDemonstration Project. New York:Clark, Phipps, Clark &Harris, Inc.Conner, R.F.1977Selecting a control group: an analysis of the randomizationprocels in twelve social reform prcograms. Evaluation Quarterly1:195-244.1982Random assignment of clients in social experimentation. InJ.E. Sielr, ed., The Ethics of Social Research: Surveys andEatrimerNew Verlag.Cordray, D.S. Psychological Bulle and consent Mexico considerations. Pp. 159-170 inA.F. Boruch and eds., York:Academic Press.277 248Corsi, J.R., and T.L. Hurley1979Pilot study report on the use of the telephone inadministrative fair hearings. Administrative Law Review31(4):484-524.Cronbach, L.J., S.R. Ambron, S.M. D.F. Walker, Weineri980Toward Reform of Program Evaluation. San Francisco, Calif.:Jossey-Bass.Dobson, L.D., and T.D. Cook1979Implemen.ing random assignment in a field setting: a computerbased approach. Evaluation Quarterly 3:472-478.Educational Testing Service1981Assessment of the U.S.Explment Service Project STEADY.Technical Report no. 9. Prepared by J. Grandy.Evaluation Research Society1982Standards for evaluation practice. New Directions for ProgramEvaluation.No. 15.Federal Judicial Center2983Social Experimentation and the Law. Washington, D.C.: FederalJudicial Center.Fienberg, S.E.1979Graphical methods in statistics. American Statistician33/0:165-178.Fienberg, Stephen E., Margaret E. Mtrtin, and Miron L. Staf, eds.1985Sharing Research Data. Committee on National Statistics.Washington. D.C.: National Academy Press.Fisher, R.A.1966Design of Experiments. (first edition, London: Oliver andBoyd, 1935.)Eighth edition. New York:Hefner.Fraker, T., and R. Maynard1985The Use of Compar. son Group Designs in Evaluations ofEmployment Programs. MathematicaPolio: -374.Grandy, J.1981Assessment of the U.S. Employment Service Project STEADY.Tecthnical Report No. 9, prepared under contract to the U.S.Department of Labor, Office of Youth Programs. Princeton,N.J.:Educational Testing Service.Hahn, G.J.1984Experimental design in the complex world. Technometrics26(1):19-31.Heckman, J. and R. Robb1985Alternative methods for evaluating the impact ofinterventions: an overview.Presented at the Social ScienceResearch Council Workshops on Backtranslation, Committee onComparative Evaluation of Longitudinal Surveys, New York.Kruskal, W.H.1980criteria for Judging Statistical Graphics. UnpuLlishedmanuscript.University of Chicago, Department of Statistics. 278 249Light, R.., and D.B. Pillemcr1984Summing Up:The Science of Cordray, and D.E. Beroer1981Evaluation of a juvenile Evaluation Review 5(3):283-306.O'Malley, A.M. OICJA Career Exploration Project- -1980.McLean, Va.:Center Studies in Social Policy.Patridge, A., and A. Lind1983A Reevaluation of the Civil Appeals Management Plan.Washington, D.C.: Federal Judicial Center.Raizen, S.A., and P.M. Rossi1981Program Evaluation in Education: When?How?To What Ends?Report of the Committee on Program Evaluation in Education.Washingtm, D.C.: National Academy of Sciences.Rezmovic, E.L.1982Program implementation and evaluation results: a reexaminationof Type III error in a field experiment. Evaluation andProgram Planning 5:111-118.Riecken, H.W., and others1974Social Experimentation. A.M., and P.M. T;:wane, eds.1975Ethical of Social Experimentation.Washington, D.C.: The Brookings Institu:ion.Rossi, P.M.1969Practice, method, and theory in evaluating social actionprograms.Pp. S.R. Friedman1983Alternative Youth Em lo 'ent Strate ies Pro ect. New York:Vera Institute of Justice.Sherman, L.W., and R.A. Berk1984The specific deterrent effects of arrest for domestic assault.American Sociological Review 49:261-272.Silverman, W.A.1977The G.K., of Intern Program. Final Report--Task B:Assessment of Intern Outcomea. Prepared for the NationalInstitute of View, Calif.: RMC ResearchCorporation. L.E.1983Spurious tractable and intractable legal problems: apositivist approach to law and social science research. InR.F. Boruch and J. Cecil, eds., Solutions to Ethical andLegal Problems in Social Research. New York:Academic Press.U.S. General Accounting Office1978Assessing Social Program Impact Evaluations: A ChecklistApproach.Washington, D.C.: U.S. General Accounting Office.Wholey, J.1977Evaluability assessment. In L. Rutman, ed., EvaluationResearch.Beverly Hills, Calif.: Sage Publications. BIBLIOGRAPHY Guidelines, Standards, and Related Papers on Appraisingthe Quality of Social Program and Project EvaluationsThe guidelines issued by the Evaluation Research Society, the U.S.General Accounting Office, and other institutions tre marked with anasterisk(*).Papers by individual scholars (and one journalist)provide commentary, applications, comparisons among standards, or ideasfor new standards. Bernstein, I.N., and arandowized con`rol trial. Controlled Clinical Trials 2:31-49.Cordray, D.S. 1982.An assessment of the utility of the ERBstandards.New Directions for Program Evaluation No. 15:67-82.Davis, H.k., C. Windle, and S.S. Sharfstein. 1977.Developingguidelines for program evaluation capability in Community MentalHealth Centers. Evaluation 4:25-34.DerLimmons, R., L.J. Charette, B. McPeek, and F. Hosteller. 1982.Reporting on methods for clinical trials. New England Journal ofMedicine 306(22):1332-1337.Gordon, G., and E.V. Morse. 1975.Evaluation research. In A.Inkeles, Annual Review of Sociology 1.*Joint Zommittee on Standards. 1981.Standards for Evaluations oforofessional assessmentE of methodology. Methods andResearch 6(1):3-44.F.M., S.P. Gilbert, and B. McPeek. 1980.Reportingstandards and research strategiese agenda for an editor.Controlled Clinical Trials 1(1):37-58.*National Institute of Education, Department of Education. 1977.TheJoint Dissemination Review Panel Ideabook. Washington, D.C.:National Institute of Education. 280 251 Pear, R.1984.Taking the measure, or mismeasure, of it all. TheNew cork Times, August 28.*Rossi, F, ed.1982.Standards for evaluation practice. NewDirections for Program Evaluation No. 15.*U.S. General Accounting Office. 1975.Evaluation an.; Analysis toSupport Decisionmaking. Washington, ProgramImpact A Recent Randomized Fieldin Law Enforcement and Corrections,Court Procedures, Health Services, andFor a list of over 300 field experiments runBoruch, McSwe Soderstrom (1978). Law Enforcement and R.A., and L.W. Sherman. 1985.Randomized 1984.The deterrent effects ofarrest for domestic assault. American Sociological Revie,49:261-272. Civil, Criminal, and Administrative Law Corsi, J.R., L.B. Rosenfe' Fowler, Telephone Conferencing inAdministrative Law Hearings: Major Findings of the New MexicoExperiment with Unemployment Insurance Appeals. Final report tothe National Science Foundation.Goldman, G.1980.Ineffective Justice: Evaluating the A. Lind. 1983.A Reevaluation of the Civil AppealsManagement Plan. Washington, D.C.: Federal Judicial Center. Juvenile and Criminal JusticeLipsey, M.W., D.S. Cordray, and D.E. Berger. 1981.Evaluation using multiple lines of evidence.Evaluation Review 5(3):283-306. 281 252 Schneider, P., and A. Schneider. 1979.The National Juvenile JusticeRestitution Evaluation: Experimental Designs ana ResearchObjectives.Paper presented at the Third Syalposium onRestitution, Duluth, Minn., September 28-29. Health B. Littenberg, and D. Neuhauser. 1982.Doedcost information availability reduce physician test usace? Arandomized clinical unexpected firdings. Medical O.M. Haring. 1979,The impact of a computerizedmedical record summary system on incidence and length ofhospitalization. Medical Care 17(6):618-630.Weissert, W.G., T.H Wan, B.S. Livieratos, and S. Katz. 1980.Cost - effectiveness of day care services for the chronically ill: arandomized experiment. Medical Care 28(6):567-584.Zimmer, J.G., A. Groth-Junker, and J. McCus!ter. 1985.A randomizedcontrolled study of a home health care team. American Journal ofPublic Health 75(2):134-141. Nutrition RelatedRush, D., Z. Stein, and M. Susser. 1980.A nutrition education and training program: findings fromNebraska.Evaluation and Program Planning 4:335-344.U.S. Department of Agriculture, Office of Analysis and Evaluation, Foodand Nutrition Service. 1984.Food Stamp Work Registration and JobSearch Demonstration: Report on Initial Demonstration Sites.Contract No. 53-3198-0-85. Washington, D.C.: U.S. Department ofAgriculture. Randomized Experiments, Planned and Executedin Varying Degrees, on foiith Employment ProgramsClark, Phipps, Clark fi Harris, Inc. 1980.Advanced Education andTraining--Interim Report on the Career Advancement VoucherDemonstration. Youth Knowledge Development Report No. 5.3.Washington, D.C.: U.E. Department of Labor, Employment andTraining Administration.Clark, Phipps, Clark & Harris, Inc. 1981.Second Year Final Report:Career Advancement Voucher Demonstration Project. New York:Clark, Ph.-ps, Clark fi Harris, In:, (60 East 86th Street). 282 253 Grandy,1981.Assessment of the U.S. Employment Service ProjectSTEADY.Technical Report No. 9, prepared under contract to theU.S. Department of Labor, Office of Youth Programs. Princeton,N.J.:Educational Tscting Service.Hahn, A., and B. Friedman (with C. Rivera and R. Evans). 1981.TheEffectiveness of Two Job Search Assistance Programs forDisadvantaged Youth: Final Report.Center for Employment andIncome University.Manpower Demonstration Research Corporation. 1980.Summary Demonstra' on. Hampson, OIC/A Career Exploration Project- -1980.McLean, Va.:Center for Studies in Social Policy.Resource Consultants, Inc. 1981.Special Project for IndochineseYouth:Final Results. Report to U.S. Department of Labor,Employment and Training Administration, Office of Youth Programs.McLean, Va.:Resource Consultants.Rivera-Sasale, C., B. Friedman, and R. Lerman. 1982.Can Employer orWork Subsidies Raise Youth Employment? An Evaluation of TwoFinancial Incentive Programs for Disadvantaged Youth. Center forEmployment and Income. Waltham, Mass.: Brandeis University.Sadd, S., M. Kotkin, and S.R. B: Assessment of Intern Outco m3.Prepared for the National Institute of Education. Mountain View,Calif.:AMC Research Corporation. 283 APPENDIXDEstimates of Effects of Employment and TrainingPrograms Derived from National LongitudinalSurveys and Continuous Longitudinal Manpower SurveyValerie NelsonandCharles F. Turner In adds,to the program-specific evaluations -f YEDPA effec-tiveness reviewed in Chapters 4 through 8, several evaluations haveused large representative samples of the American population to deriveestimates of the overall impact of all federally funded employment andtraining programs. The most prominently used data bases in thoseceudies are the Continuous Longitudinal Manpower Survey (CLMS,administered by westat with data collection by the U.S. Bureac .f theCensu:), and a special youth sample of the National Longitudinal Survey(NLS, administered by the Center for Human Resouzce Research of OhioState University with data collection by the National Opinion ResearchCenter--NORC). Both of these surveys involve relatives~ largt samples(over 60,000 in the CLMS and over 12,000 in the NLS) drawn in a mannerdesigned to permit general4zations to the universe of American youths(NLS) or participants in MIA programs (CLMS). (It should be notedthat only a Traction of the youths in the NLS sample participated infederally funded employment and training programs, and similarly, only1 fraction of the program participants sampled in the CLMS survey wereyouths.)While the major charge of our committee was to focus on the YouthEmplciment and Demonstration Projects Act (YEDPA) knowledg^ developmentactivities, it seemed prudent to review the findings from studies usingthese other data bases. Since these studies use data gathered in adifferent manner and have a somewhat different (and wider; focus, theyprovide an important supplementary perspective on the substanle andproblems of the individual YEDPA evaluations we reviewed. Moreover,because these studies use data derived from samples with high sample-coverage rates and low sample attrition, they can provide a moreadequate evidentiary basis (at least in respect to sampling methods)than many of the other studies we reviewed.There are, nonetheless, important limitations to these data bases,as well.First, they are not targeted on specific programs--and so therelevant estimates of aggreTatt program effects may lump together both Valerie Nelson, an economist, was a consultant to the committee.Charles F. Turner was senior research associate with the committee. 251284 255effective a:d ineffective programs. Second, the data bases (particu-larly CLMS) limit the extent to which one can take into account theeffects of local labor market conditions. Third, these data are notderived from experiments in which subjects were randomly assigned tc.take part in a program, and hence the resultant estimates of programeffectiveness tequire strong assumptions about the adequacy of themodel specification and the matching procedures used to constructsynthetic \"control\" groups. Finally, we should point out that the CLMSreports were provided to the committee in \"draft\" form late in thecourse of our work, and thus our evaluation of them has not been asintensive as that of the individual 1EDPA reports.In the following pages we briefly review the characteristics of theNLS and CLMS data bases. We then describe the findings of empiricalstudies which have used these data bases to estimate program effective-ness.We conclude by discussing the most serious problem with all ofthe studies (and many of the previously reviewed YEDPA studies):potential biases in the selection of a \"control\" group of nonprogramparticipants. CHARACTERISTICS OF CLMS AND NLS DATA BASESBoth the CLMS and the NLS are full probability samples whosesampling designs appear to have been weil executed. That is to say,sample coverage appears high and the available documentation shows thatconsiderable attention was given to important methodological details,such as adequacy of sampling frame, careful screening of respondents toensure that they fell within the universe being sampled from, extensivefollow-up to ensure a high response rote, and so on.The CLMS was designed to sample all persons receiving training oremployment under the Comprehensive Employment and Training Act (CETA),and of course, a portion of that sample would have been young people.(The CLMS sample of program participants is complemented by data fornonparticipants derived from the Current Population Survey (CPS).) TheNLS youth sample, on the other hand, is a longitudinal survey ofAmerican youths begun in 1979. Because it sampled the entirepopulation of young persons (and indeed oversamplee groups who werelikely to participate in employment and training programs), it doesinclude a sample of young persons who happened to have participated inYEDPA or CETA programs. Sample Execution Rcuc' lower bounds on the number of program participants aged 18-21in each a.-11e are 21,000 for the CMS and 1,800 for the NLS. Accordingto information provided by the NLS Data Center at Ohio State University,the NORC sampling report for NLS surveys (Frankel, McWilliams, andSpencer, 1983), and the published CMS estimates (for initial waves ofdata collection), it appears that sample attrition rates were on theorder of .05 to .10 per wave in both surveys. Because the NLS retained 285 in the sample persons who did not respond in the previous wave of datacollection, it is said that each of the 1980-1983 waves interviewedalmost .95 of the wave-1 sample. T \"e CLMS, in contrast, lost Pbout .10of its sample per wave and did not retain nonrespondents from previouswaves.Thus by wave 4, it obtained interviews with only .729 thewave-1 sample. MeasurementsTo tL extent one focuses on labor force outcomes and income asdependent variables and eses standard human capital-type variables(e.g., education, training, age), either data base might be of value,although the lengthy NLS questionnaire contains a much wider range ofsocial and economic measures than does the CLMS. (One must wonder,however, about the extent to which fatigue may contaminate the repliesof the respondents to the NLS.) Error Structure The reliability and validity of these data do not appear (from theavailable documentation) to be buttressed by explicit estimates of theerror and bias introduced by respondents, interviewers; coders, proces-sors, and so on. Since the Census Bureau has a routine re-interviewprocedure, some test-retest measurements are likely available for theCLMS data set. Information on other aspects of the error and bias thataffect these data do not appear to be available. It may be reasonable,however, to assume that an error profile for many of these measurementsmight be similar to those for similar measurements made in other surveys(see, for example, Brooks and Bailer's (1978) error profile for the CPSlabor force measurements). Nonetheless, thft fnct that the populationof interest is quite unlike a cross-section of the adult populationwould argue for caution in making such an assumption. Time Period for Evaluation If we assume that recall and other errors in the interview data(and processing and reporting errors in Social Security earningsrecords) are not too troubling, the CLMS data provide interview datafor three years after a young person entered a prograw. The SocialSecurity earnings records extend this time frame even further (e.g.,for the 1975 program entrants we may have earnings in 1983).For the NLS data we have waves of data covering five years ofactual interviewing. Since the NLS obtained retrospective data in its'-itial interview, for some respondents we will nave outcomes that were,!asured more than five years after participation in a program. 986 257 General Issues of Method' Despite the distinct advantages of the large and well-executed CLMSand NLS samples, there are several serious deficiencies in the data.First and foremost, neither data set is a true experimental samplewhich randomly sorts youths into participant and control groups. As aresult, comparison groups must be constructed by a \"matching\" procedureusing demographic variables and preprogram earnings. For the CLMS, acomparison group was drawn from Current Population Survey data and forNLS, a comparison group was drawn from nonparticipants within thesample itself.However, for reasons discussed in greater detail in the finalsection of this appendix, these synthetic \"control\" groups are notentirely adequate. For the one empirical study for which there isexplicit evidence, it was found that participants appeared to be moredisadvantaged than nonparticipants in ways that could not be \"matched\"with the available data. As a result estimates of net program impactwere downwardly biased.Information on several key variables is missing in one or anotherof the samples. In particular, lack of location data in the CLMS makesit impossible to take account of variations across local labor marketsor to assess the site-specific component of the variance in outcomes.Furthermore, the matching CPS file fails to record either participationin CETA or subsequent schooling. These deficiencies can lead to under-estimates of the overall impact of CETA participation (note 1).Finally, the analyses of these data frequently ignore the fact thatboth the NLS and the CLMS have complex sample designs. The variancesfor estimates derived from such designs can differ considerably from 'For the CLMS analyses, further problems are posed by deficiencies inthe information available from the CPS files used in matching. First,many CPS youths will have been enrolled in CETA programs themselves,but neither the CPS nor the accompanying SSA files records such par-ticipation.SRI estimates these cumulative probabilities over theperiod of 1975 to 1978 to be: 12.2 percent for adult men, 14.9 percentfor adult women, 31.1 percent for young men, and 30.7 percent for youngwomen.Second, time spent in school is not recorded for the CPS sampleduring the postprogram period. As a result, net impacts can only beestimated for earnings. However, if CETA graduates are more likelythan others to seek further education, this will also tend to result inlower earnings for them in the first and second postprogram years, atleast.Not only will a negative earnings impact be accentuated, butthere will be no record of what is considered an additional, positi7eimpact of CETA, that is a return to school on the part of dropouts orother highly disadvantaged groups. The Urban Institute has found, forexample, that negative findings for youths in classroom training may beassociated with their increased time spent in school in postprogramyears.Such data limitations th convey an overly negative impressionof the impact of the program. 287 258those estimated using simple random sample (SRS)produced by the statistical routines of the mostpackages, e.g., SPSSX, SAS).These issues are discussed in greater detailformulas (i.e., thosewidely used computer below. FINDINGS OF STUDIES USING CLMS DATA BASE Three studies compare CETA participants from the fiscal 1976 andfiscal 1977 Continuous Longitudinal Manpower Surveys with comparisongroups selected from the March 1976 or March 1977 Current PopulationSurveys.These studies were conducted by Westat (1984), SRI Inter-national (1984), and the Urban Institute (Bassi et al., 1984). Afourth study conducted by Mathematica Policy Research (Dickinson etal., 1984) compares net-impact estimates derived from such :PScomparison groups with those from a true experimental comparison ofparticipants and controls (using data from the Supported Workdemonstration program).The first three CLMS reports differ in their selection of CPScomparison groups and in the analytic models used for net-impactestimation.However, their findings show similar patterns: negativeand statistically significant (or negligible) net impacts on post-CETAearnings for young men and positive, but generally insignificant netimpacts for young women. Only on-the-job training seems to producepositive gains for most groups, and work experience is universallynegative in its impact on earnings. Among the studies, the UrbanInstitute reported the greatest negative impacts and Westat the mostpositive; the SRI results were in-between. Again, however, it isimportant to note: that these findings may be biased estimates of thetrue impacts of CETA on youths and, as such, may offer an inappropriateassessment of the overall program. Analysis Strategies Each of the three CLMS-CETA evaluations used three data sets: (1)CETA participants selected from the Continuous Longitudinal ManpowerSurvey of program entrants from July 1, 1975, to June 30, 1976, and/orfrom July 1, 1976, to June 30, 1977 (Westat also conducted some pre-liminary analysis on an earlier cohort); (2) nationally representativesamples of individuals from the Current Population Survey of March 1976and/or March 1977; and (3) earnings (up to the Social Security taxlimit) for both CETA participants from the CLMS and individuals selectedfrom the CPS.Net-impact estimates Li.e based on differences in prepro-gram and postprogram earnings between the CLMS-CETA participants andearnings changes for similar individuals from the CPS file.This combination of data appears to offer many distinct advantagesover the YEDPA studies discussed in Chapters 4 through 8. The samplesare large and national]y representative and cover several years of CETAprograms.Annual edrninys data are available from Social SecurityAdministration (,SA) files from 1951 to 1979. Comparable data are 288 259available on all major programs (classroom training, on-the-jobtraining. Public Service Employment, and work experience) for the sameyears and for similar economic conditions. Finally, the CLMS filecontains detailed data on participants from prime sponsor records,individual interviews at entrance into CETA, and subsequent interviewsup to 36 months later. For these reasons ana others, Westat has char-acterized these data as superior to any data set that has previouslybeen available for evaluating large scale federally funded employmentand training programs.The problems of net-impact estimation, however, are substantial andarguments for one method or another have been a central focus of eachof the three major studies of CETA using the CLMS data base. Becausethe disagreements are often sharply drawn and bec.use they result inwide variations in net-impact estimates, these analytic issues arediscussed briefly here. No attempt is made to resolve disputes in onedirection or another, except insofar as the Supported Work evaluationprovides evidence suggesting bias in all of the estimates (see finalsection of appendix).Analytic and statistical problems fall basically into three maincategories: 1.preliminary screening of individuals from CLMS and CPSfiles on the basis of missing or nonmatching data, termination ofprogram participation before 8 days, and similar factors. Suchprematch deletions exclude as much as 30 percent of the originalsample;2.selection of a comparison sample from the CPS to match CETAparticipants along earnings related Dimensions; and3.specification of a linear regression (or other) model ofearnino (and accounting for \"selection bias\").Basically, the three studies may be distinguished in the followingways:Westat devoted substantial resources over several years tocreating a comparison file with a \"cell matching\" and weighting tech-nique, but ultimately used a fairly straightforward regression analysisto estimatelet impacts.Using these methods, ret impacts for youthswere gene'.ly found to be negligible for men an, positive for women(few precise figures for youths were provided in their study). SRI, ina subsequent study, focused on an alternative method of selecting acomparison file using a Mahalonobis or \"nearest-neighbor\" matchingtechnique, but also adopted straightforward regression analysis formost of its estimates, particularly of youths,For all the attention paid by both Westat and SRI to the selectionof the comparison group, SRI found that the two methods producedsimilar results, all else held equal. The more negative resultspresented as findings of the SRI study stem primarily from differencesin the preliminary screening process and from updating of earnings withnew information from SSA. (SRI's net-impact estimates are $591 foryoung men and $185, but statistically insignificant, for young women.)Finally, the Urban Institute adopted the Westat comparison file onyouths fort used a \"fixed-effects\" estimator to control for bias in 289 260selecting participants into CETA and reported substantially morenegative net impacts (a range of -$515 to -$1,303 for young men and-$23 to -$391, but statistically insignificant, for young women).It appears, therefore, that the primary differences in thenet-impact estimates are based not in the time-consuming creation ofcomparison files, but in the preliminary screening of the CPS and CLMSfiles and in the specification of an earnings model. The SupportedWork study by mathematica provides similar evidence that the particularprocedure used to select a comparison sample is less important than thenet-impact estimation model (a fixed-effects estimator led to a morenegative result than a linear model of postprogram earnings).The basic goal in selectiag a comparison file from the CPS is tofind a group of individuals who closely resemble the CETA participantsfrom the CLMS.Lacking a true (experimental) control group, A com-parison group procedure is a next-best approach for comparii-ri theearnings and employment outcomes of those who participate with thosewho do not.Net-impact estimates in these analyses are simply thecoefficient on program participation in an earnings regression thatcontrols for background characteristics and other earnings-relateddifferencem in a composite sample of youths from CLMS and CPS.2Three basic techniques of selecting a corparison file have beenused in these studies: 1.random sampling of CPS cases screened only for programeligibility;2.stratified cell matching whereby a list of earnings-relatedvariables is generated, CLMS participants are arrayed across cells bythese variables, and CPS canes are matched and weighted to produce asimilar distribution of participants and nonparticipants. Substantial\"collapsing\" of cells is required since the number of cells is largeeven for a small list of variables; and3.statistical matching based on predicted values of earnings orthe \"nearest neighbor\" technique of minimizing a distance function of aweighted sum of differences in earnings-related characteristics of theindividual.Several tests of the \"success\" of the CPS match are available.These are similarity in demographic or background characteristics 2If earnings functions could be correctly specified, a close matchingof the CLMS and CPS de:a files would not be so important. But knownnonlinearities, interactions of variables, and other complexities oflabor market behavior across the population at large make impactestimates from a simple, linear and additive model highly suspect.Breaking down the files into subgroups (as by sex an race for theUrban Institute and by sex and program activity for Westat and SRI)would handle some matching of youths on other earnings- relatedcharacteristics and would also make net-impact estimation more precisefor the range of people who are likely to enroll in CETA. 290 261(especial.Ly those variables that are important determinants ofearnings), similarity in preprogram earnings, and similarity inpreprogram earnings functions. In particular, a test may be made ofwhether a CETA participation dummy variable is predictive of (orcorrelated with) a preprogram dip in earnings, as an indicator thatprogram administrators may be \"creaming\" those individuals with atemporary drop in a relatively high \"permanent\" income stream.A fixed-effects estimator signed to control for such creamingand other sample selection bias Jifferencing\" a base-year and apostprogram year earnings equati .Any unobserved characteristicsthat lead to participation in CETA, but also affect earnings, areassumed to be constant over time and can be accounted for in such aprocedure.If there is creaming based on a transitory preprogram dropin income, then the base-year must be chosen a year or two earlier toreflect a more permanent income trend.In the majority of cases in the three reports, the CPS comparisongroups pass the tests of similarity to CLMS/CETA participants. Forexample, as a result of cell matching or ne-irest-neighbor matching, theCPS pool is winnowed from a largely white sample of in-school youths orhigh school graduates from families above the poverty level to a mixedblack/white sample that includes large numbers of high school dropoutsfrom families below the poverty line. The comparison groups alsoresemble CETA participants in preprogram earnings. Matching on suchbackground characteristics and preprogram earnings, of course, does notnecessarily equalize unmeasured characteristics (e.g., actual orperceived moCvation, ability)--a point to which we shall return. Westat Findings In 1980- Westat began to release a series of net-impact studiesbased on CLMS and CPS data. Comparison groups were created usingstratified cell-matching techniques for CETA entrants in the first hay'of 1975, and for fiscal 1976 and 1977. Cells were defined by suchvariables as age, race, sex, family income, and education. Two basicmatching subdivisions were made: one divided the CLMS sample into low,intermediate, and high earners and constructed separate CPS comparisonfile for etch, and a second divided the program activities into:classroom training, on-the-job training, public service employment,work experience, and multiple activities. Because the latter match wasmore \"successful\" in terms of passing statistical tests of similaritybetween groups, it was used in most of the later Westat studies. Netimpacts were estimated for three post-CETA years for the fiscal 1976group and for two years for the fiscal 1977 group.Westat's (1984) report summarizes their findings over the lastseleral years.Although the report presents very few specific resultsfor young men and women, its overall conclusions for adults are ofinterest.Key findings are the following: Statistically significant positive impacts for both cohortsand all postprogram years; estimates ranged from a low of $129 per yearto a high of $677;29i 262Among programs, classroom training and on-the-job trainingshow the highest net impacts and work experience the lowest; these rankorders are relatively stable across cohorts ard postprogram years;For the first cohort, there was a marked difference in netimpacts by sex--males experienced statistically insignificant gains andfemales experienced significant gains;For the second cohort, however, net impacts converged for menand women at statistically significant levels;Higher net impacts for low earners (less than $2,000 in 1972and 1973) than for high earners;Positive gains from \"placement\" in a job at termination andincreasing gains with length of stay in the program;Substantially higher net impacts for the second cohort thanfor the first; these are attributed to a dramatic increase in netimpacts for men, a decline in the proportion of youths with workexperience, and across-the-board increaso:s in all programs.Specifically for youths, Westat found, Youth work experience programs are statistAcatly insignificantfor all cohorts and postprogram years. Other specific youth-related findings are not reported in Westat(1984), but the Urban Institute has characterized Westat's results fromearlier reports, as follows: In looking at youth, Westat (1982) has found that for thoseyoungsters 14 to 15 years old, CETA has had little overallimpact.For other young workers net gains are found, beinghighest once again for OJT, followed by PSE and classroomtraining, and being negligible for work experience. Theresults found for young workers also tend to persist in thesecond postprogram year. Westat also produced a technicalpaper focusing on youth in CETA (1981) in which net gains werebroken down by sex. As with adults, net gains were greatestfor young females, being negligible or insignificant ''ormales.After classifying youth according to their attachmentto the labor force, net earnings gains were found to begreatest among structuraAly unemployed or discouragedworkers. SRI Findings SRI's analysis differs from Westat's in two key respects: in theselection of the comparison group and in its \"sampling frame.\" SRI'scomparison groups were drawn by use of a \"nearest-neighbor\" matchingprocedure based on minimizing the \"distance\" of matches along earnings-related variables. samplingframe differed from Westat's in the following specific ways:develop-ment of calendar year cohorts rather than fiscal year cohort3; SRI 292 263TABLE D.1SRI Estimates of Net Impact of CETAon SSA Earnings (Standard Errors inParentheses) SSA EarningsSubgroup (dollar impacts) men standard for estimatesappear in parentheses but are likely to beinaccurate; see note 5. SOURCE:SRI International (1984). inclusion (versus Westat exclusion) of individuals who received only\"direct referrals\" among those who received fewer than eight days oftreatment; SRI exclusion (versus; Westat inclusion) of individuals whoworked in 1975 but were out of thr. labor force in March 1976; and use of a different set of rules for excluding individuals if key CPS orCLMS codes did not match their SSA codes.SRI's model differed from Westat's only in the addition of severalvariables, such as veteran status and earlier earnings and the squareof 1975 SSA earnings. (Table D.1 presents SRI estimates of net impactsof CETA on earnings for all participants in 1978.) SRI also experi-mented with fixed-effects estimators for adult men and women, butargued that they were not appropriate for youths just beginning work.SRI's estimates of program effects were substantially below Westat'sfor both adults and youths, and the authors spent considerable time inidentifying the sources of those differences. From their analyses, theSRI authors concluded that most of the differences could be attributedto choices made in the sampling frame and to an updating of 1979 SSAearnings.' 3Net impacts were minimally sensitive to the estimation model or tothe matching technique used. 293 264 SRI (1984) reported the following findings for 1976 CETA enrollees: Participation in CETA results in significantly lower postpro-gram earnings for adult men (-$690) and young men (-$591) andstatistically insignificant gains for adult women (+$13) and youngwomen (+$185).All program activities have negative impacts for men, butadult women benefit from PSE and young women fLom OJT. Work experienceshave negative impacts for all age and sex subgroups.Both male and female participants are more likely to beemployed after CETA, but males are less likely to be in high-payingjobs or to work long hours.Length of stay in the program has a positive impact onpostprogram earnings; turning points for young men are at 8 months andfor young women at 1 month.Placement on leaving the program leads to positive earningsgains. Urban Institute Find:.agsThe Urban Institute used Westat's match groups from the CPS andestimated net impacts for six race/sex groups (male/female by white/black/Hispanic). Both random-effects estimators and fixed-effectsestimators were used to identify net impacts, but the emphasis was onfixed-effects models which controlled for selection bias. Net impactswere estimated for two postprogram years, 1978 and 1979. (Table D.2presents net impacts estimated in the Urban Institute analysis.)The Urban Institute (Bassi, et al., 1984) found, for youths: Significant earnings losses for young men of all races and nosignificant impacts for young women; these impacts persist into thesecond postprogram year;Significant positive net impacts for young women, particularlyminorities in Public Service Employment and on-the-job training andsignificant negative or insignificant net impacts for all groups inwork experience;Among subgroups, the moat negative findings were for whit,males, the most positive for minority females;Older youths (22-year-olds) and those who had worked less thanquarter time had stronger gains or smaller losses than the youngergroup or those who had worked quarter time or more;Earnings gains resulted primarily from increased time in thelabor force, time employed, and hours worked, rather than fromincreased average hourly wages. FINDINGS OF STUDIES USING NLS DATA BASETwo major studies have used the National Longitudinal Survey datacase to estimate the aggregate effects of government-sponsored employ- 294 265TABLE D.2Urban Institute Estimates of Net Impact of CETA Participationon Earnings of Youths Under Age 23, for Three Models Race/Sex Group1978 1979REaFE-75aFE-74aREaFE-75aFE-74a White females on social security earnings.Published t statistics are in parentheses, but are likely to be inaccurate;see note 5. FE- 75- -fixed 1975; andFE-74--fixed effects, base period 1974. SOURCE:Bassi et al. (1984). ment and training programs on youths. One study (Moeller et al., 1983)was conducted by the Policy Research Group (PRG) of Washington, D.C.,and the other (Hahn and Lerman, 1983) by the Center for Employment andIncome Studies (CEIS) of Brandeis University. Both studies evaluatedthe effects of CETA programs on youths, although the PRG study expandedits scope to include schooling programs, such as vocational education.The estimates made by both studies indicate relatively modesteffects of employment and training programs on the subsequent income,employment status, and educational attainment of the youths whoparticipated in those programs. For CETA programs both studies findnegative overall effects of CETA on employment, although PRG reportssome positive effects at two years after CETA completion. ReviewingPRG results and their own findings, the CEIS authors (Hahn and Lerman,198:484) dourly conclude an appendix to their chapter entitled \"Did theCETA System Work for Disadvantaged Youth?\" by noting:To conclude, both the PRG results and our own show negative andsignificant effects of CETA on employment variables. It isonly after going out two years in time after CETA completionthat the PRG report finds evidence of a positive, significanteffect and that on only one variable, unsubsidized earnings.We cannot confirm this positive affect, but it would not be 295 266 inconsistent with our results. It is difficult to claim thisas an impressive success for CETA. [emphasis added]Since the substantive findings from the NLS analyses are generallyconsistent with the weak and generally negative findings from the CLMSanalyses we do not review them in great detail. Instead, we brieflydescribe the analysis strategies and findings of each of the studiesthen turn to a consideration of the potential for bias introduced byuse of statistical matching procedures rather than random assignment toconstruct \"control\" groups in the CLMS and NLS analyses. CEIS Procedures and FindingsThe analysis reported by Hahn and Lerman (1983) employs a nearestneighbor matching procedures to construct a \"matched\" control groupto be compared with the 1,114 respondents in the NLS youth sample whoreported participating in CETA programs- (The matched sample wasconstructed by selectirerespondents from among the 4,608 NLSrespondents who reported that they had not participated in a CETAprogram and who were neither in the military nor had family incomesabove $25,000 in 1978, and who did respond to the questions used toconstruct the eight matching variables.)The variables used for matching were: sex, race, age, family size,family income (in 1978), weeks employed (in 1978), whether the youthwas living at home, and whether the youth was a high school dropout.All the matching variables were derived from the 1979 survey. Theresulting \"matched\" sample was then used to estimate the impact of(prior) participation in CETA programs on earnings and employment in1979 and later years. As with the CLMS matchings, the CEIS analysis ofthe NLS data base takes a pool of largely white, middle-class youthsand produces a \"matched\" sample which is 65 percent black and has amean family income of $8,790 (in 1978).The CEIS analysis concentrates initially on employment in unsub-sidized jobs as its major outcome measure.The authors argue that thisis the appropriate outcome measurement for initial study since\"politically the motivating concern in establishing a CETA program\" wasto increase the likelihood that disadvantaged youths could findemployment in the regular (i.e., nol-CETA) labor market. Their keyanalysis derives an estimate of program effects for a regression modelthat incorporates 20 other independent variables.The coefficients estimated in this analysis are reproduced in TableD.3 together with the published t-ratios. (The latter statisticsappear to ignore the complex sampling design used in the NLS and thus 4Hahn and Lerman (1983:75) used a \"nearest available Mahalonobismetric matching\" method suggested by Rubin (1979). 236 267 are likely to be inaccurate.5) It will be seen from Table D.3 thatthe net-impact estimates derived from this analysis are quite negative,(text is continued on p. 269)5A complete assessment of the variance and bias components ofestimates derived from surveys of complex design requires an assessmentof effects arising from sample design, interviewer contributions to thevariance, and the effects of sampling frame bias and nonresponse, amongother factors. These variance components in survey estimates aretypically referred to as \"design effects.\"It is often the case that the secondary analyst lacks sufficientinformation (coded into the sample data) to make adequate assessmentsof such components of the variation in his or her estimates. In theNLS (and many other surveys conducted by quality-conscious researchorganizations), information is available concerning the sample designused in the suivey (see Frankel et 'al., 1982).Like many large-scale household surveys, the NLS used a multistagearea probability sample with sample clustering at the block level. Forreasons of cost and efficiency, self-weighting simple random samples(SRS) are seldom used in such large-scale surveys. Rather, sampledesigns incorporate a multi-stage selection process and some type ofsample clustering. Instead of a random draw of individuals, smallgeographical areas (e.g., blocks in cities) are sampled, and then anumber of individuals in that area are selected for interview. Thisgroup of individuals is referred to as a sample cluster. Cluster sizes of 5 to lu individuals per \"block\" are common in national surveys. Inpersonal interview surveys, such sample clustering is a prast.icalnecessity, since any random draw of subjects in a national survey mightrequire some interviewers to travel hundreds of miles betweensuccessive interviews.Because a sample of, say 5,000, may thus consist of 500 randomlyselected \"blocks,\" from which 10 individuals were selected, thevariances of both univariate and multivariate statistics are notaccurately portrayed by the well-known formulas that apply to simplerandom samples. This is so because the sampling of individuals was notindependent of their location. To the extent that individuals within aselected location are homogeneous with respect to a given measurement,the effect of the use of a clustered sample is to increase the varianceof the estimates (above those that obtain for SRS designs)--or, toexpress it another way, to decrease the effective sample size from thenumber of individuals (Ni) toward the number of locations that were chosen (Ha).In ex.reme cases, e.g., the use of such samples toestimate the distribution of the population across (self-perceived)rural versus nonrural areas, the effective sample Eize may approachNcsince almost all of the extant variation occurs between ratherthan within sample clusters--and hence we have a sample of Ncclusters, where almost all of the Ni respondents in any one clustergive the same response when asked whether they live in a rural area.Another way of expressing this result is to say that the intra-clustercorrelation of response approaches 1.0 for this variable. For morerigorous theoretical treatments of this matter, see Hansen et al.(Footnote 5 is continued on pp. 268-269) 297 268 (1953) or Kish (1965); for an elementary introduction, see Blalock(1972:520-530).Of course, residence in a rural area is an extreme case, but highintracluster correlations arise for many other variables of interest.The type of dwelling unit (apartment versus house) has similarcharacterimtics, and even such crucial variables as race and incomesnow relatively high intra-cluster correlations in sample surveys as aresult of the residential segregation of neighborhoods. (Persons ofthe same race, income, and so on tend to live together.)This has important practical implications for the survey analystsince the widely used algorithms for computing variances for simplerandom samples (e.g., those of the SPSSX, SAS, and BMD computerpackages) are not appropriate. Use of SRS formulas to calculate thesampling variances from commonly used cluster designs may considerablyunderstate standard errors for means, regression coefficients, and soon.Since variances and their roots figure crucially iai allinferential statistics, serious errors of inference can be made.Design effects (deff) that arise from the use of complex sampledesigns are commonly expressed (see Kish, 1965:258ff) as the ratio ofthe actual variance of a sample estimate to the variance of an SRSsample of equal size. The square root of the deff ratio (which isreferred to as deft) can be used to \"deflate\" statistics derived underSRS assL.aptions. For example, in the case of the t-statistic: deft = (deff)0.5ttrue m tars/deftA careful study (Frankel, 1971) of design effects for eight variablesin the Current Population Survey found values of deft that ranged from1.1 to 1.5.(The variables studied were number of persons inhousehold, number aged 0-17, number in labor force, household income,ald, for the \"head of household,\" income, age, sex, and educational,!.ttainzient.)In discussing the practical importance of such studies,Frankel (1971:1-2) observed:As social scientists become more mathematically sophisticatedand attempt to use sample survey data to uncover multivariaterelationships, the gap between the assumptions of existingstatistical theories and the actuality of sample designs usedto collect data, make the valid use of standard inferentialtechniques tenuous. Naive researchers may be unaware of thisgap and may use inference which assumes that their sample is asimple random selection of elements. However, more sophis-ticated social scientists are faced with the task of makingstatements like that of Blau and Duncan in their study, TheAmerican Occupational Structure: We do not know, however, howother statistics, such as regression coefficients . .. andF-ratios, are affected by the departure of the sampling designfrom simple random sampling. Only very rough guesses aboutstandard errors can be made. ...\" 296 269e.g., -$1,640 in 1980 earnings (from unsubsidized employment). TheCEIS study further examines some of these outcomes for particularpopulation subgroups and youth participating exclusively in \"skillstraining\" programs. With a few modest exceptions, however, theseanalyses lead the authors to similar conclusions, i.e., no (positive)net impact of CETA participation.While these analyses Share many characteristics with the CLMSanalyses (and share the potential for \"matching bias\" that is discussedin the final section of this appendix), they do have unique aspectsthat should be noted,. A critical one is their reliance on respondents'self-reports of whether they participated in CETA.' Although noestimates of the error and bias components of these measurements areproffered, it is unlikely that these crucial variables will be reportedwithout error. Also, in contrast to the SSA records used in the CLMSanalyses, the CEIS study must rely on the self-reports of earnings inthe NLS--and indeed must then use other self-reports to characterizethose earnings as \"subsidized\" or \"unsubsidized.\" Here, again, thepotential for inaTt-uracies in such reports (involving both random andsystematic errors) could potentially affect the outcomes obtained inthe CEIS analysis. Frankel's (1971) findings suggest that standard errors for his eightvariables would be understated by about 10 to 50 percent if SRSformulas were used (with the larger numbers applying to multiplecorrelation statistics, the smaller to multiple regressioncoefficients, and means and simple correlations resting in themiddle).He has, however, no available data for race, which is quitehighly clustered geographically (racial discrimination and otherfactors produced a very nonrandom distribution of blacks and whitesacross \"blocks\" and neighborhoods in the United States). Statisticalresearch or health surveys (Landis et al., 1982) indicates that deftsin excess of 2.0 occur for such things as the partial regressioncoefficient representing the \"effect\" of race on health conditions(e.g., standard errors for the \"effects\" of race on number of decayedteeth, net of age, sex, and consumption of sugar, may be underestimatedby a factor of 2 or more if SRS formulas are used). It is difficult toassess what analogous values might be in earnings equations, butcaution is clearly advisable in interpreting the estimates provided bythe CEIS and PRG analyses.'CLMS, in contrast, sampled participants from lists usingadministrative records (from prime sponsors). The CPS match samplesused in the CLMS studies are, however, subject to similar but even moresevere concerns. It is not possible to identify \"progtam participants\"in the CPS match sample, and thus the CLMS analyses must contrast asample of individuals who all participated in CETA with a cross-sectional sample containing both participants ant: nonparticipants. 299 2O TABLE D.3CEIS Estimates of Net Impact ofParticipation in CETA tin Unsubsidized NetEarnings (in dollars per year) Independent VariablesUnsubsidized Participation in -675.9-1640.2(-3.92)(-7.54)Reservation (0.90)(-0.70)Family 1978 .0470.060(3.56)(3.48)Area 1979 interview 287.8407.9(4.44)(4.81)Mechanical comprehension -79.8(-0.56)(-0.78;Does not live at home -23.1-537.4(-0.08)(-1.44)Paragraph comprehension 137.1-95.7standard (0.95)(-.50)Math appear parenthesesbeneath coefficients, but for reasons discussed in note 5,these values are likely co oe inaccurate. SOURCE:Hahn and Lerman (1983) 271 PRG Procedures and FindingsWhile the PRG analyses differ in their details from those of CEIS,the basic strategy was the same.PRG used the NLS youth sample to (1) identify all participants in government employment and training pro-grams, (2) construct a comparison group of nonparticipants, and (3)estimate a model for the outcome variables of interest.The PRG analysis of the NLS data base differs from CEIS's in its use of a wider range of outcome measures (including earnings, employment, educational,and marital outcomes) and a somewhat different strategy Lir constructing a comparison group of nonparticipanPRG used what it described as a \"stratified random samplingprocedure\" to select the comparison group, but the description of this procedure is unclear in some respects. The authors' (Moeller et al., 1983:E-1) \"overview\" of the procedure is stated as follows:'Both the CEIS (1982) and Westat (1980) studies ... adopted a\"match\" procedure for selecting a control group (hereafterreferred to as the CGRP). We instead chose to use a stratifiedrandom sampling procedure for its computational advantages andsound statistical approach to selecting the CGRP sample. Incombination with a reasonably complete control variablespecification in the outcome regressions, weights for the twosamples to equate the number of participant and comparisongroup members within each stratification cell, and aselectivity bias correction for \"on'easured\" differences between the p?irticipant and CGRP members, we did not judge theadditional computational burden of a match procedure to be warranted. appears that this procedure involved the construction of a syntheticvariable representing the socioeconomic status (SES) of the respondentand then cross-classifying participants and nonparticipants by SES,sex, race, local unemployment rate, region. Prior to the cross-classification, each of these variables was dicnotomized (e.g., localunemployment: 0-5 percent versus 6 percent or more), except for region,which had four categories. Nonparticipants were then selected atrandom from within the resulting 128 cells with the probability of 'This text is an accurate reproduction of the PRG statement ;he original is also garbled). It should be noted, too, that Cie\"selectivity bias correction\" analysis was not included in the PRGreport, and according to statements elsewhere in the report theseanalyses were not performed. 301 272 selection for each cell being equal to the proportion of theparticipant sample that fell into the same cell.\u00b0Two aspects of the PRG analysis are troubling. First, the authorsused an ordinary least squares procedure to estimate their morelequations where some of their dependent variables take only two values(e.g., 0: out of school, is in school). This, in addition to use ofprocedures that assume simple random sampling, raises doubts about theaccuracy of the reported significance levels. On a more substantivelevel, we note that the authors never combine their separate analysesof employment status and education, and so we cannot tell to whatextent the decreased earnings of CETA participants might be due to theincreased enrollments in school. If this were to account for animportant share of the observed income drop, one might characterize theearnings decline as an investment of foregone earnings in educationrather than a negative outcome of CETA.Additional PRG analyses estimate that CETA had few impacts on otheroutcomes ie.g., receipt of welfare or unemployment income, criminalbehavior, graduation from higt school, disciplinary problems in school,or health status) that were re_iably different from zero, based on the \u00b0Because the published description of these procedures is garbled inplaces, it is not entirely clear how this selection strategy woulddiffer from a cell-matching procedure--except for the arbitrary mannerin which the size of the \"control\" sample is set (i.e., by specifying asampling fraction). In other details, there are also several puzzlingaspects.For example, great efforts are put into constructing acomposite family income and social sta*.us indicator (from a regressionusing 97 variables reflecting aspects of youths' income and socialstatus), but the resultant continuous variable (scaled in a metric of\"expected\" family income) is merely dichotomized (less than $15,000versus more than $15,000 per year).The resulting samples were then used to estimate program impacts byembedling a dichotomous program participation variable in equationspredicting each of the lames shown in Table 0.4. (Other independentariables in these eq t,were intended to control for region, age,race, pre-snrollmeni ,went status, family income, marital status,educational level, anu nealth status.) It will be seen from Table D.4that across all time periods studied, PRG estimates that the net impactof CPTA was -$28 per month on earnings rrom unsubsidised employment.Estuateet net impacts fcr other outcome variables are also negative or\"insignific\"..t.\" (Note, however, that the t-ratios are likely to beinaccurate ;ince the PRG analysis treated the NLS data as if they hadbeen derived from a simple random sample of the population; see note5.)The sole positive result shown in this analysis is for education,for which it is estimated that the net impact of CETA was to increasethe probability that the youth would remain in (or return to) school by5.6 percent. 30u4, 273TABLE D.4PRG Estimates of Net Impact ofParticipation CETA on Employment, Earnings,Education, and Marital Behavior OutcomeImpact ofCETA Months of unsubsidized earnings -27.698(2.34)Hours -8.844employment per montha (3.89)Hours of unsubsidized employment -.008with wages set by collectivebargaining(.92) Probability of being employed .028in unsubsidized job (1.59)Months of regular school .014(.98)Probability of being in .056regular school (3.45)Probability of being married -.088(.54) NOTE:Averages calculated over the youth'spostprogram quarters, up to 12. The t statisticsappear in parentheses, but are likely to beinaccurate; see note 5.aThis entry is lister in source as \"months ofunsubsidized employment,\" not hours, but this appearsto be a typographical error, since it duplicates firstentry in table.SOURCE:Moeller et al. (1983). PRG computations. The two exceptions were increased use of drugs amongCETA participants (net impact +7.3 percent) and increased likelihood ofbeing married (10.2 percent).\" However, teenage matrimony would beunlikely to qualify as a positive outcome of a CETA program, aid of 'Note that these two dependent variables are also dichotomies whichwere analyzed using OLS procedures. 303 274course, the increased \"use or sale of marijuana, hashish, or harddrugs\" would be thought by most observers to be a negative socialoutcome.The sole optimistic findings cf the PRG analysis occur twoyears after program completion. For selected quarters, the authorsfind evidence of positive net impacts of CETA on unsubsidized earningsand employment status. These impacts were not, however, reliab]vdifferent from zero (using the authors' statistics) at the time of thelast NLS measurements (33-36 months after program completion). BIASES IN ESTIMATES OF PROGRAM EFFECTIVENESS ARISING FROMUSE OF MATCHOJ i,AMPLES RATHER THAN RANDOM ASSIGNMENTAcross the three CLMS studies there is a pattern of preponderantlynegative net impacts on \"youths, and the NLS studies show extremely weakeffects of program participation. These results invite the conclusionthat federally funded employment and training programs have had (in theaggregate) either little effect or a deleterious effect on the futureearnings and employment prospects of the youth who participated in theprograms.There is, however, reas -1 to suspect (and empirical evidenceto support the suspicion) that the foregoing estimates may be biaseddownward.The reason\" for this suspicion is that (despite intensive andvarying efforts to select comparison groups similar to participants inyouth programs and to control for selection bias through use offixed-effects estimators) therr. may still be persistent and systematic,but unobserved, differences in the earnings profiles of comparisongroups and true controls. Lower earnings, for example, *;ht be due tosuch unobserved factors as (perceived or actual) differe.,:es in socialattitudes, motivation, or ability between program participants versus amore \"mainstream\" comparison group.A study by Mathematica (1984) provides important evidence on thepotential for bias in the use of matching strategies such as thoseemployed in the NLS and CLMS analyses reviewed above. The Mathematicastudy used data from a true experimental design that randomly assigned \"In addition to the potential bias in the matched control groups,there are two other reasons to question negative conclusions from theCLMS studies.The CPS lacks data on enrollment in CETA on the part ofthe comparison group and, as a result, positive net impacts may beunderestimated since some of the \"controls\" were actually programparticipants.In addition, postprogram earnings are taken from SSAfiles, which contain no information on subsequent education ortraining.However, to the extent that CETA encourages furtherschooling, it reduces imme..iate postprogram earnings (and thereforelowers the net-impact estimate), but it probably should be viewed as apositive impact in its own right. Nevertheless, this interaction hasnot been and cannot be examined with the available data. 304 275youths to be either program participants or controls. It then comparednet impact estimates derived using the experimental design withestimates derived using the same sample of program participants butsubstituting various \"matched samples\" constructed from the CPS.\"Mathematica examined net impacts based on simple differences inearnings gains, on a straightforward earnings regression model, and on a fixed-effects estimation model. Separate comparisons were performedfor youths and women receiving Aid to Families with Dependent Children (AFDC).Based on a true control group, Mathematica found in-program earningsgains and negligible postprogram effects for youths. Comparison ofSupported Work participants and the CPS matched sample, however,yieldedeither insignificant or significantly negative effects.Moreover, the bias apparent in the match sample estimates was evengreater using a fixed-effects estimator rather than (from Mathematica, 1984:Figure 111.3) illustrates howthis bias in the matched samples occurs. The age-earnings profiles ofparticipants and true controls are dramatically different in the yearsfollowing the program from the profiles of matched controls derivedfrom the CPS (regardless of which of the three matching strategies isused).While cell matching or statistical matching reduces mean differ-ences in preprogram earnings and in background characteristics,subsequent earnings still diverge, for reasons that are left unobserved7Ad unexplained, but which may have to do with actual or perceiveduifferences in motivation, ability, or social attitudes (among otherpossible factors). (Alternatively, it may be the case that the scaleof subsidized youth programs in 1978-1981 was sufficiently large thatthe programs indirectly improved the comparison groups' employmentprospects.By temporarily withdrawing many participants from thecompetitive labor market for low-income youths, the programs may haveenabled some nonparticipants to obtain more readily whateverunsubsidized joos were available, and to this extent they boostedemployment outcomes above what they would have been in the absence ofsuch federally funded programs.)Results for AFDC women provide an interesting contrast. In someinstances, the Mathematica analysis finds an upward bias in estimatesof program effects. But, in general, both the true control groupanalyses and the matched control group analyses show large and signifi-cant impacts both during and after the program. No clear pattern of \"Three techniques of matching were used:general eligibilityscreens, such as high school dropout; cell matching and weighting(similar to the technique used by Westat); and statistical matchingbased on predicted earnings (rather than on earnings-related variables,as done by SRI). 305 4,5004,0001-3,500 3,000 Eno2,500zm2,000 1,500 5000Exper 'menialsRandomized Controls. 'r I I I1972 FIGURE D.11973197419751976197719781979YEARComparison of average SSA earnings for program participantsand randomly assigned controls in Supported Work experiment to SSAearnings for \"match groups\" constructed from Policy Research (1984:Figure 111.3). differece is found between the results obtained using a basic earningsmodel and a fixed-effects model. Mathematica argues that a similarnegative alas probably eLists for other CETA evaluations using con-scructeu zomparison groups rather than true controls, at least foryouJ1s, and it specifically cites the Westat, SRI, and Urban Institutefindings in this regard.Table D.5 1984:Table IV.7) Mathematica's analyses of Supported Work,together w:.th estimates of overall program impact from the studies byWestat, SRI, and the Urban Institute. Mathematica acknowledges thatits Supported Work sample is more severely disadvantaged and thereforemore likely to have lower earnings profiles than the typical CETA youthparticipant.Nevertheless, there is some overlap of the two groups,and the Supported Work program did primarily provide supervised employ-ment, which is an element of youth programs common to on-the-job-training projects, work experience ?rojects, and public sectoremployment projects. 306 277TABLE D.5Alternative Estimates of Net Impact or EarniagF (in dollarsper year) of Participation in Supported Work and CETA Using AlternativeComparison Group Methodologies and Estimation Techniques Study and MethodologyParticipant GroupYouths AFDC Women Supporter Work participantsControl for 1978 for Supported Work and 1979 for CETA. Supported Workparticipants tended to enroll in the program slightly later than did the CETAparticipants included in the CETA net-impact studies. For this reason, 1979outcome measures for the Supported Work samples are most nearly comparable to the1978 outcomes for the CETA participant group studied. Published significancelevels are denoted by asterisks, as follows:* p less than .10** p less than .05*** p less than .01However, for reasons discussed in note ,these levels may be inaccurate. '1.7xcludes results based on the random (..)S samples meeting the Stage 1 screens.bee Westat, Inc. (1980:Tables during the first half of 1976.dThese figures pertain to male youths only.Data in the report did not permitthe calculation of an overall impact for all youths. However, only 12 percent ofthe Supported Work youth were female.eSee Bassi et al. (1984:Tables 3 and 22).(These figures pertain to female welfare recipients. Similarly large positiveimpacts were also estimated for all economically disadvantc.ged women. Because of such similarities, Mathematica analysts argue thatsimilar biases in estimates of program effectiveness may exist in thenet impacts estimated by Westat, SRI, and the Urban Institute, and theyconclude that \"It is not possible to generate reliable net programimpact estimates using ex-post comparison group procedures.\" 307 278 CONCLUSIONWhile argument may be had (at great length given the dearth ofreliable evidence) concerning the extent to which the Mathematicademonstration of bias in the matched sample methodolon, can begeneralized, the study does highlight two separate problems innet-impact estimations using a matched comparison group: 1.the extent to which employment programs recruit or attractparticipants who differ from eligible nonparticipants in ways that mayaffect subsequent earnings; and2.the extent to which such differences can be detected andcontrolled using available demographic or preprogram earnings data.For the latter problem youths presents a particularly difficult casefor any match strategy because preprogram earnings data are either notextant or not reliable indicators of the uncontrolled variables thatare of interest to program evaluators.12Estimates of the magnitude and direction of the bias inmatched-group evaluations are only available for the one youth program(Supported Work) whose experimental data were reanalyzed byMathematica.From this reanalysis we have an elegant demonstrationthat commonly used \"match\" strategies would have yielded aninappropriately negative evaluation (where the experimental dataindicate that the program `lad a null impact). Tnere is an obvioustemptation to leap from this one result to the assumption that biasesequal in magnitude and direction affect all other \"match group\"studies.The available evidence, however, is not sufficient to warrantsuch a sweeping generalization. Until the methodological point isclarified by expanding on the provocative paradigm provided by theMathematica analysts, there is considerable uncertainty as to theextent to which this finding will generalize to other programevaluations involving different populations of youths. Providing therequisite data will take a renewed commitment to conducting therandomized experiments needed to make estimates of the magnitude anddirection of the biases involved in common matching strategies. \"In contrast, for adult women receiving Aid to Families withDependent Children, it is apparently possible to control for suchdifferences.Welfare payments are known, and preprogram earnings are amuch better indicator for adults than they are for youths, and they canbe used both in selecting a watched comparison sample and as a controlvariable in the net-Lmpact estimation. Finally, the trend inpreprogram earnings can be used to test for \"creaming\" or other sampleselection biases that can be removed from the estimates. 308 279 REFERENCESBassi, L.J., N.C. Simms, L.C. Burbridge, and C.L. Be::sey1984Measuring the of CETA and the EconomicallyDisadvantaged. Washington, D.C.: The Urban H.1972Social Statistics. New P., and O.D. Duncan1967American Structure. New York:Wiley.Brooks, C., and B.A. Bailer1978An Error Profile: Employment as Measured by the CurrentPopulation Survey. Statistical Policy Working Paper No. 3.Washington, D.C.: Office of Federal Statistical Policy andStandards.Center for Human Resource Researr'1982National Longitudinal Si' R.W. West1984An Analysis the CETA programs on Participants'Earnings.Menlo Park, Calif.: SRI International.Frankel, M.R.1971Inference from McWilliams, Spencer1971National Longitudinal Survey Behavior, YouthSurvey:Technical Sampling Report. Chicago, Ill.: NationalOpinion Research Center.Hahn, A., and Lerman1983The lo ent RecordsRe tesentative Findin s onthe Effectiveness of Federal Strategies for Assisting Disad-vantaged Youth. Final Report to U.S. Department of Labor.Center for Employment and Income Studies. Waltham, Mass.:Brandeis University.Hansen, M.d., W.N. Hurwitz, and W.G. Madow1953Sample Survey Methods and Theory. 2 Vols.New York:Wiley. Kish, L.1965Survey Sampling. New York:Wiley.Landis, J.R., and others1982A statistical methodology for analyzing data from a complexsurvey.Vital and Health Statistics 2(92).Mathematica Policy Research1984An Assessment of Alternative Comparison Group Methodologies forEvaluating Employment and Tr'4ning Programs.Princeton, N.J.:Mathematica Policy Research.Moeller, J., R. Hayes, and I. Witt1983Socioeconomic Impacts of Recent Government-Subsidized EmployFentand Training Programs on south. Washington, D.C.: PolicyResearch Group.Rubin, D.B.1979Using multivariate match sampling and regression adjustment tocontrol bias in observational studies. Journal of the AmericanStatistical Association 74:318-328. 309 280SRI International1984Analysis of Impact Earnings.Stanford, SRI International.Westat,1980Ccntinuous Lqnlitudinal Man Serve1.Impact of CETA on 1978 Earnings: Westat, Inc. 310 COMMISSIONED PAPERS Knowledge Development Under the Youth Employmentand Demonstration Projects Act, 1977-1981Richard F. Elmore INTRODUCTIONIn July and August of 1977, Consress passed and President Cartersigned the Youth Employment and Demonstration Projects Act (YEDPA).The law substantially increased authorizations for two existing youthemployment programs, the Job Corps and the Summer Youth EmploymentProgram (SYEP). It added three new programs, Yoqth Community Conser-vation and Improvement Projects (YCCIP), the Youth Employment andTraining Programs (YETP), and the Young Adult Conservation Corps(YACC).It also authorized a large-scale demonstration of strategiesdesigned to encourage high-risk youths to stay in school, usingguaranteed work as an incentive--the Youth Incentive Entitlement PilotProjects (YIEPP). (Table 1 summarizes the target groups and activitiesincluded within these programs.)In the fiscal year immediately prior to the passage of YEDPA,federal outlays for youth employment programs were about $955 million(Hahn, 1979).Over the next four fiscal years, 1978-1981, about $8billion was spent on programs and about $500 million on research anddevelopment addressed to youth employment, serving about 1.5 millionyouths annually (see Tables 2 and 3). YEDPA was administered by anewly created Office of Youth Programs (OYP), which was located in theEmployment and Training Administration (ETA) of the U.S. Department ofLabor (DOLL and which relied on a large number of independent contrac-tors, PS well as state, local, and other federal agencies.Included in the legislation authorizing YEDPA was a broad charge\"to explore methods of dealing with the structural unemploymentproblems of the Nation's youth\" and \"to test the relative efficacy ofdifferent ways of dealing with these problems in different localcontexts.\"This charge was backed by substantial discretionary Richard F. Elmore is at the Graduate School of Public Affairs,University of Washington. 281 311 282TABLE 1Federal Youth Employment Programs, 1977-1981 Program Target Group c. satisfac-tory performance inschool and workWork for up Employment Programs,Fiscal 1978-1981 (in millions of dollars) FiscalProgram 1978 1979 19801981 Job Corps 280 380 470465SYEP 670 660 721769YCCIP 61 103 122 0YIEPP March 218YACC 139 273 234174YETP 294 SOURCE:Data from U.S. Department of Labor (1980a, 1981,1982).authority and money, granted to the secretary of labor and delegated tothe Office of Youth Programs, to conduct research, demonstration, andevaluation activities around the structural unemployment problems ofyouths.This effort was described with the arresting phrase \"knowledgedevelopment.\"The youth employment knowledge development effort was remarkable inmany respects: It was one of the largest short-term investments insocial research and development ever undertaken by the federal govern-ment.Its scale and complexity dwarfed any research and developmenteffort undertaken by the Department of Labor before or since.Itgenerated a large body of research, evaluation, and practical knowledge,which is only now being sorted, assessed, and assimilated into policyand practice.It coincided with a sharp surge in political attentionto youth employment problems, creating many opportunities for connect-ing research with policy. And it galvanized a broad-based nationalconstituency of policy makers, ressdrchers, and local practitioners, atleast for a short time, around the problems of youth employment. Thesefeatures argue for a retrospective look at the process.This paper analyzes the conduct of the knowledge developmenteffort, from its origins in congressional decision making, to itsdesign, implementation, and results. The paper addresses five mainquestions: (1)What congressional and executive expectations shaped theknowledge development process?(2)How was the knowledge development process designed?(3)How was the process organized and managed?(4)How has the process influenced policy and practice in youthemployment?(5)What lessons can be learned from the process that might shapefuture large-scale research and development efforts in social policy?Because the knowledge development effort was vast and the scope of thisanalysis is modest, the answers to these questions are necessarily 313 284TABLE 3Participation in Federal Youth EmploymentPrograms, Fiscal 1978-1981 (headcounts) Department of Labor (1980a, 1981, 1982). tentative and incomplete. But, even with these limitations. the paperprovides an occasion to examine the broader consequences of large-scaleinvestments in social research and development. It also provides apolitical and organizational complement to more methodologicallyoriented reviews of the evidence.The YEDPA knowledge development effort raises questions that haverun through federal investments in social research and developmentsince at least the mid-196C3. Prior to that time--during the New Deal,for example--the unspoken assumption was that public money spent onremediation of social problems was effective simply by having beenspent.In the 1930s, the National Youth Administration's employmentprograms and the Civilian Conservation Corps were assumed to haveaccomplished their purposes when federal money was transferred throughpublic employment to unemployed young people.In the 1960s, this view began to shift markedly. It was no longeradequate justification for public expenditures simply to pass moneyfrom the government to individuals who needed it; public expenditures had, in some way, to contribute to the long-term solution of basicstructural problems in society--poverty, unemployment, crime,delinquency, and the like. Some argued that even this was notsufficient justification, proposing instead that expenditures be basedon comparisons of their net returns to society, rather than just ontheir relationship to social problems.This shift in perspective coincided with a marked increase infederal social expendi#Jres and at least a five-fold increase infederal expenditures on social research and development (Rein andWhite, 1977).The dominant theme of social research and development inthe 19cOs and 1970s was the seemingly straightforward matter of\"finding out what works\" (Rivlin, 1971). The dominant analytic modelwas a combination of experimental method and economic analysis.Experimental method, which in its most rigorous form prescribes pre- and post-measurement coupled with random assignment of subjects totreatment and control groups, would provide the means of disentangling 314 285the effects of social programs from the effects of various otherfactors.Economic analysis would provide the means of attributidgvalue to program effects and of assessing their net social benefit.As the custodian of expertise and money in this effort, \"thefederal government should take the leadership in organizing, fundingrand evallating systematic experiments with various ways of deliveringeducation, health, and other socl41 services ... trying o!..t newmethods in various places under various conditions\" (Rivlin,1971:86-87).The evidence emerging from these systematic experimentswould inform public policy decisions. The underlying assumptions werethat (1) knowledge of effects and net benefits was a key determinant ofpublic policy decisions; (2) systematic knowledge, when marshaled insupport of decisions, would be used by policy makers; and (3) betterknowledge meant better decisions and more value to society from socialexpendi+ res.This analytic model produced some notable successes--well-conceivedand well-implemented experiments in income maintenance, health insur-ance, and housing subsidies--and some notable embarr ssments--vaguelyconceived and erratically implemented experiments in educationalvouchers, compensatory education, and educational performance contract-ing, for example. The analytic model also began to find its way intofederal evaluation requirements that accompanied categorical grants andfederally sponsored researc. and demonstration activities under theumbrella of operating programs. I.. education, for example, a nationalDissemination Review Panel was established to review evaluations ofexemplary programs for methodological rigor and results and to\"validate\" those programs for broad-scale dissemination. Parallelpatterns developed in delinquency prevention, employment, and mentalhealth.This analytic model had no , oner become a fixture of federalpolicy than experience began to surface a number of problems:Timing.Social experiments and evaluations, especially thewell-conceived ones, took so long to produce results that they usuallyanswered questions no longer being asked by policy makers. The demandsof the political process were out of synch with what the experimentalmethod could produce.The Nature of the Treatment. Most of the notable successeswith social experimentation were with policies involving relativelysimple cash-transfers (income maintenance, health insurance, andhousing subsidies). Most of the notable failures were with policiesinvolving complex chai.yes in existing organizations, the creation ofnew organizations, or the delivery of highly individualized services.Organizational Complexity. The large-scale accumulation ofknowledge about social problems turned out to require orchestratingcompeting political demands, marshaling mcney and expertise behindpolicy questions, and constructing organizations to deliver servicesand do research. The skills necessary for thcue activities were moreakin to the skills of management than the skills of scientific inquiry.People who have the required management skills So not necessarily havethe skills, interest, or commitment to scientific inquiry, and viceversa. 315 286Implementation. Complex interventions have to be implementedbefore they can be tested. Implementation requires skill and commitmcatfrom people whose main interest is in delivering services, not in \"finding out what works.\" Implementation also requires organizationaland administrative capacity--people and institutions who are ready toapply their practical knowledge to the problems raised by policymakers.These practical concerns often came as a shock to social scientistswhose main concerns were methodological and theoretical.Variability and Waustness. The cash-transfer experimentsseemed to produce findings that were robust from one setting to another, if not from one experiment to the next.Evaluations and experimentsrequiring complex organizational solutions and individualized servicesproduced findings that were highly sensitive to setting--differencesamong sites were consistently greater than differences among treatments across sites.Small, Ambiguous Effects. The social interventions of themid-1960s were justified politically in rhetoric that suggestedbroad-scale reform of society. The actual results of experiments andprogram evaluations showed small, often inconclusive effects.Theinterventions worked with some groups and not others; the effects weresometimes so small as to be of 7.uestionable practical significance;important sources of variation (site-to-site differences, for example)were often not included in the design of evaluations; and effects often did not persist over time.Methodological Uncertainty. Better-designed, more rigorous, more analytically sophisticated experiments and evaluations did not reduce the uncertainty and conflict surrounding policy decisions. Indeed, they often aggravated it. Serious discussions of important policy questions often got sidetracked into arcane debates overmethodological decisions, analytic assumptions, and statistical techniques, leaving the intended consumers of the results confused. The most frequent conclusions of policy research were recommendations for more research. The research community seemed reluctant to apply the same benefit-cost calculus to its own work that it applied to social policy.Conflict Between Science and Practice. As the application ofsocial science to social policy making proceeded, the breach widenedbetween people who delivered services, on the one hand, and the peoplewho conducted experiments and evaluations, on the other.Practitioners argued that the quantitative findings of rigorous research and evalua- tion were too abstract to be of any practical use, too insensitive topractical problems, and that experimentation and evaluation were expensive ornaments hung on social programs for the benefit of social scientists.Social scientists argued that, without a scientific basis, practice could not be justified to the public and that resistance tosystematic analysis stemmed from the professional's usual hostility to external scrutiny. It was impossible to engage in large-scale policy research, experimenta-tion, or evaluation in the 1970s--or the 1980s, for that matter--without 316 287 confronting these problems in one form or another. They were part ofthe baggage of systematic inquiry in the service of policymaking.Out of these misgivings there began to emerge a different, moretempered view of the connection among systematic inquiry, policy, andpractice.The utility of experimental method and economic analysiscame to be defined in narrower terms. Rigorous social experimentationrequired relatively strong theory, analytic skill, time, money, andorganizational capacity--conditions that could not be met in allinstances.Social scientists began to acknowledge an explicit tradeoffbetween internal validity (the ability to distinguish treatment effects)and external validity (the ability to generalize effects beyond anexperiment).The degree of experimental control required for a preciseestimate of effects was to some degree inconsistent with the ability totransfer the treatment from an experimental setting to a practicaloperating environment. Policy analysts began to speak with more respectabout the \"ordinary knowledge\" (Lindblom and Cohen, 1979), or practicalunderstanding, necessary to make complex decisions and to get from ananalytic result to a prescription for action. Views about the relation-ship among systematic inquiry, policy, and operating decisions becamemore elaborate and less hard edged.Systematic inquiry, even when it met rigorous methodological stan-dards, was rarely brought to bear on clearly specified decisions- -Legislative, budgetary, or administrative. But systematic inquiry didhave longer-term, more diffuse effects on the conventional wisdom thatpolicy makers used to define problems, on the way organizations werestructured, on the directions administrators pushed their organizations,and on the way practitioners handled day-to-day problems in providingservices.The shifts, in other words, were less a repudiation of theexperimental/analytic model and more a domestication of it to political,organizational, and operating realities.The Department of Labor had, by the mid-1970s, accumulated con-siderabl-, capacity and experience in economic analysis and evaluation,althou. its experience with large-scale experimentation was morelimited.The department's analytic functions in the employment andtraining area were the responsibility of the Office of the AssistantSecretary for Policy Evaluation and Research (ASPER) and, within theEmployment and Training Administration, ele Office of Policy Evaluationand Research (OPER). The Policy Evaluation and Research budget of DOLwas consistently around $35 million a year between 1976 and 1980; over$20 million was in earmarked appropriations and about $15 million indiscretionary funds (apart from YEDPA). The varied collection of stateand local government agencies and community-based organizations thatdelivered employment and training services under the ComprehensiveEmployment and Training 2'4:t (CETA! had become acclimated to a relativelyhigh level of federally required (valuation, but no less resistant toits costs and inconveniences. An array of external research andevaluation organizations had developed around DOL-sponsored evaluations,as well as a large array of university-based research organizations.Not much of this capacity for research and analysis, however, wasfocused specifically on youth employment--a matter that would becomeimportant with the passage of YEDPA. 317 288The youth employment knowledge development effort commenced at atime, then, when federal investment in analysis, research, and evalua-tion related to employment had been relatively high for a number ofyears, when methodological and analytic sophistication were on therise, when major uncertainties were surfacing about the role ofsystematic inquiry in the service of policy making, and when theadministrative structure for employment programs had become acclimatedto, if not totally accepting of, evaluation. The uncertainties thatcharacterized policy analysis, research, and evaluation generally atthat time were necessarily part of any effort to apply systematicinquiry to the youth employment problem.Among the questions gr-wing out of this larger context are thefollowing: What constitutes \"useful\" knowledge? Is the utility ofknowledge, and hence the value gained from investment in systematicinquiry, to be judged in strictly methodological and quantitativeterms--that is, are \"useful\" results measures of specific impacts towhich no alternative causal explanation can be offered under themethodological conventions of social science? Or is the utility ofresults more a matter of practical use--that is, \"useful\" results arethose that are perceived to be helpful in solving political,administrative, and practical problems?What should be the relationship between the delivery ofservices and the discovery of effects? Is it the primary responsi-bility of government agencies to deliver services to people, consistentwith the political decisions of elected officials? Or is their primaryresponsibility to \"find out what works,\" consistent with the economiccriterion of positive net benefit? Is it possible to accommodate thedelivery of services and the measurement of effects within a singleorganizational structure? Should the delivery of services be con-strained by the methodological conditions necessary to identify effects,or should methodological conditions be constrained by the practicalnecessities of delivering services?What are the political and organizational correlates ofsuccessful accumulation of knowledge? If the accumulation of knowledgeabout social problems requires orchestrating competing politicaldemands, marshaling money and expertise behind policy questions, andconstructing organizations to deliver services and do research, thenhow do we distinguish between better and worse ways of doing thesethings?What pAyoffs should we expect from large-scale research,demonstration, and evaluation activities? Should the payoffs be on theorder of \"solutions to the problem of youth unemployment\"? Or is itsufficient to offer solutions, on the order of \"ways to reduce the highschool dropout rate\" cc \"ways to impart employment skills,\" that offerconstructive suluLions to practical problems, but little hope ofsolving the overall problem? The analysis that follows is divided into five main sections: (1)expectations about knowledge development on the part of Congress and 318 289 the executive branch; (2) design of the knowledge development effort;(3) organization and management of the effort; (4) influence of theeffort on policy and program; and (5) guidance for the future thatmight be gained from the knowledge development ef_ort. POLITICAL EXPECTATIONSShortly after the inauguration of President Carter in January 1977,sev3ral representatives of the new administration were summoned to ameeting on the Senate side of the Capitol Building. The Carterappointees were Bill Spring, from the White House Domestic PolicyStaff; Ray Marshall, secretary of labor; Ernest Green, assistantsecretary for employment and training; and Nik Edes, deputy under-secretary for legislative and intergovernmental affairs at tne LaborDepartment.From the Senate was assembled a rare array of seniormembers.Among the Democrats were Henry Jackson, Washington; HubertHumphrey, Minnesota; Edward Kennedy, Massachusetts; Alan Cranston,California; Harrison Williams, New Jersey; Gaylord Nelson, Wisconsin;and Jennings Randolph, West Virginia. Among the Republicans were JacobJavits, New York, and Robert Stafford, Vermont.According to Nik Edes and Richard Johnson, then staff director ofNelson's Senate Employment Subcommittee, the Senators delivered asimple message to ti-e Carter appointees: A youth employment bill wouldbe introduced in the. Senate immediately, with or without administrationsupport.The administration could collaborate or be left behind.The reasons for the pressure were political. According to Johnson,\"There were youth proposals coming from all over the Senate; they couldhave gone to [the] public works, interior, or labor [committees].Javits sensed that the 'thole thing was about to come apart. Whichevercommittee got to the floor first with a proposal would get credit. Hedecided it was time to call a meeting. He told the administration,'We're about to produce a piece of legislation. If you want in, now isthe time'.\"Spring, recently transplanted from the Senate Labor and PublicWelfare Committee Staff to the White House, recalls, \"It was a rescueeffort by the Labor and Public Welfare Committee to maintain itsjurisidiction.Javits [ranking member of the Labor and Public WelfareCommittee] saw that Jackson [chair of the Interior Committee] al.,Randolph [chair of the Public Works Committee] were about to move, andunderstood that if something didn't happen quickly they were going tolose it.\"Within weeks, Edes, Johnson, and Spring had drafted a proposalincorporating the special programs of the key Senators. This particularselection of staff was not accidental. Edes and Spring, representingthe Carter administration, had only weeks before been members of theSenate staff--Edes working for Senator Williams, chair of Labor andPublic Welfare, and Spring working for Senator Nelson, chair of theEmployment Subcommittee. According to Spring, \"It was the old Senatestaff pulling together around an issue. There really wasn't anadministration position, because the Carter White House hadn't gottenorganized.\"319 290 Congressional PerspectiveAccording to Johnson, \"As far as the Senators were concerned, theideas were simple. You needed to have better cooperation between theschools and the employment and training system. You needed to dosomething about dropouts. You needed to provide opportunities for kidsin trouble with the schools to do useful, productive work and preparethemselves for employment.\" Jackson, Humphrey, and Randolph came ofase politically in the New Deal. Their ideas about what young peopleneeded were consistent with the New Deal view of employment in theservice of conservation and public works. YACC and YCCIP were manifes-tations of this view. Nelson and Williams had a large political stakein maintaining their committee's jurisdiction over employment policyand assuring that the federal employment and training structure providedadequate access for youths. YETP was the solution to that problem.Javits's special interest was in the connection between the schools andthe employment and training system. On the strength of Javits'sinterest, a provision was drafted requiring that a proportion of YETPfunds (originally 15 percent, later 22 percent) be allocated to projectsjointly involving local education agencies (LEAs) and CETA primesponsors.For the Carter administration the top domestic priority was dealingwith persistent inflat,on and rising unemployment. Youth employment,pec se, was not part of their early agenda. As one congressional staffmember said, \"They didn't have any hip-pocket proposals on youthemployment coming out of the transition, so it was relatively easy forthem to buy into whatever the Senate had to offer.\" On January 31,1977, Carter proposed a $20 billion emergency economic stimulus package,composed of supplemental budget requests for fiscal 1977, to cover the18-month period from April 1977 to September 1978. The package con-tained an $8 million addition to public service employment (PSE), $4billion for public works jobs, over $5.5 billion in aid for localgovernments, and $1.5 billion for unspecified youth employment programs.The administration's original intent was to implement its youthprogram administratively, without new legislative authority. Senateaide Richard Johnson said, We told them, 'You can't do that on CapitolHill, legislators want to pass legislation and get some visibility'.\"So on March 9, the administration followed with a youth employmentmessage, containing a proposal that had been worked out jointly withthe Senate.It requested authority for three new youth programs--YACC,YCCIP, YETP; it provided a set-aside of joint school-prime sponsorprojects; and it provided that half the YETP funds would be distributedby formula to prime sponsors and the other half used to fund \"innovativeand experimental\" programs at the discretion of the secretary of laboror his designee.Explaining the purpose of the discretionary funding, Richard Johnsonargued,We [the Senate) had always been inclined to put rather generousdiscretionary funding into the employment programs because we recognizedthat the formulas for distributing money sometimes resulted in problemsgetting the money to the right constituencies.\" For the Senate, inother words, discretionary funding was a way of adjusting formula-funded 320 291 programs to special geographical, political, or organizationalinterests.In retrospect, according to DOL's Nik Edes, *leaving the House outof the early negotiations was a major tactical error.\" The administra-tion's affinity for working with the Senate was understandable. Twokey actors for the administration, Edes and Spring, were former Senatestaff.Also, according to Spring, The House got left out because theinternal politics of the Senate were so delicate we were afraid we'dlose the whole thing if we tried to accommodate the interests of Housemembers too.\"When the House got wind of a Senate-administration proposal, theydecided to move on their own youth employment bill. The late CarlPerkins, chair of the House Education and Labor Committee, and AugustusHawkins, newly designated chair of the Employment Subcommittee, intro-duced the administration's youth employment bill on April 6 and thendeveloped an alternative proposa]. According to a member of the Housestaff, \"The White House didn't have a lot of experience in these things;they said, 'Wait a minute, you can't develop your own bill; we alreadyhave a bill in.' We went ahead with our own proposal.\"The Senate and House approaches differed in several respects.First, whereas the Senate proposal created new programs focused onyouths, the House proposal amended Title III of CETA, a general grantof discretionary authority to the seccetary of labor for research anddemonstration projects. The Senate saw itself as initiating new, moreor less permanent, youth employment programs. The House, by contrast,saw itself as initiating demonstration projects that would form thebasis for later, more permanent programs. In a House staff member'swords,our philosophy was 'let a thousand flowers bloom,' and thencome back after we'd had some experience and decide what was promising.\"Another key Senate-House difference was the House's Youth IncentiveEntitlement Pilot Projects (YIEPP). YIEPP was important politically tothe House proposal because it originated from the Republican side.According to Nat Semple, minority staff to the House EmploymentSubcommittee, the idea had its origiYis long before 1977. \"Marvin Esch[former Republican member from Michigan] liked to think in big terms.He had kids of his own and he was concerned about how to get kids tostay in school and how to get schools to respond to kids who might notbe the greatest academically. We had a long discussion one eveningafter work over hamburgers and beer at the Hawk and Dove [a CapitolHill eatery] and I started sketching out the ideas for entitlement onthe tablecloth. The problem was how to get the Republicans to buy offon some kind of a job guarantee. We struck on the idea of a contract.The kids would have to agree to stay in school in return for a job.There would be r.des and structure. We weren't offering something fornothing.The whole idea was basically very conservative: keep kids inschool, promote the work ethic, make kids contract for benefits, etc.It had a lot of appeal to the Republicans.\" Esch ran for the Senatefrom Michigan in 1976 and lost. Semple took the entitlement proposalto Ronald Sarasin, moderate Republican from Connecticut, and Sarasinagreed to sponsor it. 321 292A common element of all proposals was an initial 1-yearauthorization. The entire CETA package was due to expire in 1978.Everyone anticipated that youth employment would be integrated into CETA when the 1978 reauthorization occurred.Rather than putting youth programs on a different authorization schedule than the rest of CETA, there was substantial agreement :hat the new youth programs should be authorized for 1 year and then taken up again in 1978 with the reauthorization of CETA. In explaining why the proposal was couched in the language of demonstration projects, rather than new programs, theHc'iCommittee Report said, \"The Committee approach allows for learning as much as we can in order that when CETA is reauthorized nextyear, the Committee will have a better idea as to what type (or types)of program(s) actually work\" (U.S. Congress, House Committee on Education and Labor, 1977:4, also 9; hereafter House Report).While the Senate version stressed bold, New-Deal-like solutions to the problems of youth employment, the hallmark of the House version was \"learning what works.\" At several points in its report on the youthbill, the House Committee referred to the uncertainty of expert opinion about youth employment (House Report, 1977).Of all the witnesses that appeared before the Committee, not one had a definitive answer as to what would solve the problem of chronic youth unemployment. All agreed that a variety ofmethods should be tested and the educational system should be linked wish whatever approach is finally agreed upon.But if the committee was emphatic about \"finding out what works,\" it was for the most part strategically vague about what that meant. YIEPP was the most clearly specified of the House proposals, and it left considerable ambiguity. The committee's advice about what it meant by \"finding c what works\" was couched in the following terms (House Report, 1977): In placing a major emphasis .. on innovative anddemonstration programs, the Committee intends that a broad range of activities be tested ... to learn what works to remedy the structural nature of the youth employment problemand to meet the employment and training needs of specifictarget groups in the youth population. These activities include outreach, counseling, activities promoting education to work transition, labor market information, attainment of highschool equivalency, job sampling, on-the-job training, supportive services, programs to overcome sex-stereotyping injob development and placement, outreach programs for minoritiesand women ant other activities designed to improve theemployability of youth.This laundry list was indicative of the uncertainty that charac- terized both expert opinion and political judgment about the youth employment problem and its solutions in 1977 (see Hahn, 1979). There seemd to be consensus that the youth unemployment rate was too high, 322 293 but little agreement on what an acceptable rate would be. There wasconsensus that unemployment was borne disproportionately by minority,especially black, youths, but little understanding of the relativeimportance of skills, basic education, family background, and dis-crimination in predicting minority youth unemployment. There wasconsensus that the time was ripe for political action, but littleconfidence in past solutions to youth unemployment and little specificagreement on what would constitute success.Asked whether a more detailed analysis of the youth employmentproblem and its solutions might usefully have preceded a multi-billiondollar demonstration effort, one congressional staff member replied,\"Are you kidding? When you get the kind of political weight behind aproposal that this one had--Jackson, Humphrey, Randolph, Javits,Hawkins--you don't say, 'Give us a coLple of years and we'll come upwith a proposal.' You move.Right nowYou go with what you andtry to make sense of it as you go along.\"Bill Spring, a veteran of employment legislation as a Senate staffmember, observed, \"We were coming out of a period extending from theold S-1 [a federal manpower bill] in 1960, through the EconomicOpportunity Act of 1965, up to CETA, in which we had spent huge sums ofmoney on work experience for the unemployed and disadvantaged.\" Theevidence was now pretty clear that work experience had the smallestimpact of anything that had been tried. But it wasn't clear what wouldwork better.The House's uncertainty was well founded.Nat Semple had a further explanation of how the youth proposalstook shape.\"When you ask most adults what to do about any problemwith young people, they generalize from their own experience and fromwhat they think is good for kids. Congressmen and Senators are 70different.Some of them thought kids ought to be out working up ahealthy sweat in the country, some thought they ought to be doinguseful public deeds around town, some thought they ought to be stayingin school, some thought they ought to be getting useful training toprepare them for jobs. The bill was an amalgamation of all the adultideas about what's good for kids.\"In the end, the Senate conceded reluctantly to the House'sdemonstration approach. In the Conference Report, which stated theterms of compromise between the House and Senate versions, the Senateaccepted the House's language stating that the purpose of the law wasthe \"establishment of pilot, demonstration and experimental programs totest the efficacy of different ways of dealing with the problem ofyouth unemployment,\" but stipulated that the statement of purpose alsocontain language \"specifying that a variety of employment and trainingprograms, as well as demonstration programs, are authorized\" (U.S.Congress, 1977:35; hereafter Conference Report). As is usually thecase, the Congress skirted conflict between two alternative purposes byopting for both.While the Congress was strategically vague on the issue of \"learningwhat works,\" it was more specific on a number of other issues. Boththe House and Senate strongly emphasized the need to pay attention toin-school youths and the lack of coordination between the CETA systemand the educational system at the local level. The Senate took the 323 294view that good in-school programs and strong CETA-education cooperationwere \"preventive medicine\" against the more difficult problem of whatto do about school dropouts (U.S. Congress, Senate Committee on HumanResources, 1977:10; hereafter Senate Report). The Senate saw theset-aside for CETA-education cooperation as the solution to thisproblem.The House observed that \"perhaps the greatest weakness ofmost of the youth employment proposals that have been introduced in thecurrent session is their failure to place any emphasis on in-schoolyouth or on encouraging out -of- school youth to ...[return to]school\" (House Report, 1977:10). The House saw YIEPP as a way ofspeaking to this problem.Another issue that acutely concerned both the Senate and the Housewas the wage and job displacement problem for adult workers that was associated with youth employment measures. Both versions includedlanguage requiring the payment of prevailing wages, rather than theminimum wage, to youths filling an existing position. The finalversion contained language encouraging prime sponsors to take theinitiative in developing lew and restructured job classifications, incooperation with labor organizations, to accommodate youths. TheConference Report stressed that the wage standards in the law \"seek topromote the interests of both youths and currently employed workers andto engage prime sponsors, employers, and labor organizations in a cooperative effort to expand e,portunities\" (Conference Report, 1977:40).A related issue that did not arise explicitly in the youth employ-ment bill, but lay behind it, was the youth subminimum wage.The ideaof offering employers exemptions from the minimum wage for hiringyouths had long been a popular conservative rroposal for addressing youth unemployment. It was, however, anathema to labor organizationsand liberal legislators, who saw it as a mechanism for eroding theminimum wage and promoting youth displacement of adult workers. TheSenate and House versions dealt with the issue by diverting attention away from it.In the words of a House staff member, \"A major advantageof the House bill was that it temporarily defused the youth subminimum wage.Earlier in 1977 a youth subminimum amendment to the Fair LaborStandards Act had failed by one vote in the House.The big advantageor the House bill was that it gave Republicans something constructive to vote for without raising the youth subminimum again.\"Two final congressional concerns were maintenance of constituenciesand intragovernmental coordination. The Department of Labor, in theadministration of employment and training programs, had, partly bycongressional request and partly by its own initiative, developed abroad network of working relations with a very diverse array of organi- zations.The CETA system was, of course, based on prime sponsors--unitsof state and local government charged with responsibility for adminis-tering federal employment and training funds.Prime sponsors, and thestate and local government interest groups representing them (e.g.,National Governors Conference, National Conference of Mayors, NationalAssociation of Counties), were expected to play a key role in any new program. 324 295 Prime sponsors, however, delivered only a fraction of CETA-fundedservices; the remainder were delivered by contractors, scme locallybased community groups, some affiliated with national organizations(e.g., Urban League, Opportunities Industrialization Centers), many ofwhich had been in existence since the emergence of federally fundedemployment programs in the late 1950s. These community-based organiza-tions (CB0s) were, and still are, an important part of the politicalconstituency for federal employment and training. Their interests wereexpected to be represented in any new programs. In addition to thesestate and local constituencies, DOL also maintained working relationswith a number of other federal agencies through a variety of congres-sionally mandated, cooperatively administered programs. Congressexpected all these working relations, plus the newly mandatedcooperative arrangements with local educational systems, to be carriedover into the administration of youth employment programs.These expectations were stated in explicit statutory language. Thegovernors were given their own set-aside of 5 percent of total YEDPAfunding for exemp_ary projects and coordinating activities at the statelevel.The secretary of labor waa charged with implementing \"coopera-tive arrangements with educational agencies,\" including \"secondaryschools, postsecondary educational institutions, and technical andtrade schools.\" was a di tive to \"give special consideration\"to community-based organizations such as \"Opportunities Industrializa-tion Centers, the National Urban League, SER-Jobs for Progress,Community Action Agencies, union-related organizations, employer-related non-profit organizations, and other similar organizations.\"There were instructions to \"consult, as appropriate, with theSecretary of Commerce, the Secretary of Health, Education, and Welfare[later Health and Human Services], the Secretary of Housing and UrbanDevelopment, the Secretary of Agriculture, the Director of the ACTIONAgency, and the Director of the Community Services Administration.\"The rationale for these instructions was partly political--assuringthat key constituencies would be included--and partly administrative- -assuring that DOL would orchestrate the efforts of diverse federalagencies.In the words of Senate aide Richard Johnson, \"The idea wasthat someone needed to pull together the pieces around a common themeof youth employment.\"YEDPA, then, embodied a special convergence of congressionalinterests.It authorized bold new programs, but only for one year andonly as part of the general CETA authority for demonstration projects.It gave DOL a broad charge to \"find out what works\" and substantialdiscretionary resources to do it, but tempered that grant with a 1-yearauthorization, limited guidance about what to focus on, and a reminderthat it was deliverin_ services at the same time it was running researchand demonstration projects. It reminded DOL of its responsibilitiesfor maintaining good relations with federal, state, and local constitu-encies in the process of mounting new programs. It clearly signaledthat the Congress expected increased attention to in-school youths andto the connection between employment and training programs and localeducational systems. 325 296By singling out youth employment for special attention, though,Congress was significantly shifting its expectations for the employmentand training delivery system. In 1973, with the passage of CETA, theCongress had altered the mode of delivery for employment and trainingprograms by shifting from categorical to block grants. This shift infederal policy meant changing from a system in which the federalgovernment gave grants directly to local service deliverers(community-based organizations, for example) to a system in whichfederal funds went to state and local officials, who exercisedsubstantial administrative control over the allocation of federal furlsto local deliverers. In simple terms this meant a dramatic expansionin the administrative complexity of the employment and trainingsystem.It put a premium on the indirect management of local deliverythrough state and local government organizations with their ownpolitical constituencies.Under the previous system, youths were singled out for attention bycategorical programs, notably the Neighborhood Youth Corps and the Job Corps.After CETA, the Job Corps and the Summer Youth EmploymentProgram remained separately authorized, but the expectation was thatstate and local governments would make their own decisions about theappropriate mix of youth and adult programs within broad guidelines setby the federal government. An important part of the rationale for thechange was that state and local governments knew more about the specialneeds of their areas than did the federal government, and therefore,they should exercise wide discretion in the use of federal funds.With the passage of YEDPA, CETA prime sponsors saw a significantshift in federal policy, which many interpreted correctly as a\"recatearnization\" of federal employment and training programs.While the youth programs brought new money, they also brought increasedfederal program requirements, reduced flexibility, political stressesentailed in focusing on one target group when others were perceived as equally needy, and with time, a more active management role from thefederal Office of Youth Programs.As indicated in Table 4, youths continued to participate at arelatively high rate in \"regular\" CETA programs at the same time theywere receiving greater attention through YEDPA. This led many stateand local administrators to believe that young people were receiving adiuproportionate share of federal funds. Coupled with this recategori-zaton, prime sponsors were also confronted with the demands of mountinglarge public service employment programs (see Table 4),- participatingin other DOL-initiated research and demonstration activities, andresponding to increased DOL demands for better information on localdecisions and their effects. Under the structure of indirect manage-ment, cooperation of state and local governments was a key element inthe success of any federal venture, but singling youths out for specialattention did not inspire unqualified state and local support. 326 297TABLE 4Participants Under Age 22 in CETA Programs Otherthan percentages) Program of Labor (1978-1982). Executive Branch PerspectiveWithin the executive branch at the federal level, expectations forthe new youth employment effort were quite modest. YEDPA was seen as acongressional initiative. The Carter administration was happy toaccommodate it, especially insofar as it dove-tailed with thePresident's economic stimulus package. But, between January 1977 andthe early spring of 1979, the administration had bigger fish to fry.The administration's top domestic priorities were, first, reducingunemployment and inflation, and second, reforming the welfare system.An important feature of the economic stimulus program was publiclysubsidized employment. The economic stimulus package provided for anincrease in CETA-funded public service employment (PSE) from about300,000 to 725,000 people. At its peak, in spring 1978, over 750,000people were in PSE positions. In 1979, public service jobs werereduced to under 600,000, but the rapid buildup and the high turnoverof PSE participants administered a severe shock to the CETA system(U.S. Department of Labor, 1978 and 1979; hereafter DOL). The shockhad two important effects. First, it focused a large amount ofattention at the local level on finding public sector jobs to createemployment.Second, and perhaps more importantly, it created apermanent and indelible notion among the public and politicians thatCETA was a public employment program, not an employment and trainingprogram.After 1977, the fate of CETA would hang on the uses andabuses of PSE, not on its less-visible training programs. 327 298 The hallmark of the Carter welfare reform package was the use ofemployment to reduce welfare dependency. Called the Program for BetterJobs and Income, the proposal promised \"to provide a work or trainingopportunity for an employable adult in every needy family that includesa child under age 18\" (DOL, 1978:123; see also Lynn, 1981a). Thisobjective was to be achieved by coupling welfare benefits with workrequirements and by relying on the employment and training system toabsorb large numbers of welfare beneficiaries- Quite apart from thepolitical difficulties of selling such a proposal and the practicaldifficulties of administering it, the welfare reform proposal posed agargantuan job of interdepartmental coordination at the federal level.The Department of Health, Education, and Welfare (HEW), with itsprickly and combative Secretary Joseph Califano, considered itself tobe the custodian of federal welfare policy. The Department of Labor(DOL) saw in the Carter proposal an opportunity to become a centralactor in a large new policy area. The White House Domestic PolicyStaff was saddled with the role of orchestrating this complicatedbureaucratic minuet. The Carter welfare reform proposal eventuallyfailed to get congressional approval, but not before it had consumedmore than two years of the time of top policy staff and politicalleadership within the administration.The net effect of these two domestic priorities on the youthemployment effort was, first, to push YEDPA into the background withinDOL and the executive branch generally, and second, to create an intensecompetition between YEDPA-funded activities and other CETA activitiesat the local level. This condition persisted until early 1979, whenthe tide began to turn. During the 1978 CETA reauthorization debate inCongress, there was an ugly and protracted discussion of local misusesof public service employment funds, which had serious repercussions forCETA and its political supporters. In the words of Bill Spring, WhiteHouse Domestic Policy Staff member, \"We came within an inch losing the whole thing.\"In an effort to refocus attention on the positive side, the Depart-ment of Labor began increasingly to emphasize its youth employmentefforts.By late 1978, the Carter welfare reform proposal had gottenbogged down in a tangle of interdepartmental, congressional, andinterest group fights that eventually led to its demise. At thatpoint, in search of a domestic initiative that would serve to focuspositive attention on the administration in the 1980 election, theWhite House staff turned to youth employment. A staff member withinthe executive branch, who was a persistent critic of DOL's youthemployment activities, recalls a meeting in the fall of 1978. \"Therewas a proposal floating for still more money for youth employment, andI was making the usual arguments against it with Bill Spring when, as aI recall, Bert Carp [a Domestic Policy Staff member] walked into theroom and said, 'Youth employment is going to be the administration'snumber one domestic priority in the 1980 election.' At that point, Iknew the discussion was over.\"In late 1978, the President appointed the Vice President's TaskForce on Youth Employment, chaired by then-Vice President WalterMondaie, and charged it with developing a new youth initiative. In 328 299 roughly 18 months, then, youth employment moved from being a back-burner, congressionally initiated enterprise to bei-,g a top domesticpriority in tne President's bid for reelection, and the administra-tion's only new domestic initiative. These shifting expectations wereto have significant effects on the administration of YEDPA. DESIGN OF KNOWLEDGE DEVELOPMENT EFFORT The administration lost little time in responding 1.:o the congres-sional youth initiative. In July 1977, before 1ADPA had been signed bythe President, Secrltary Marshall created the Office of Youth Programs(OYP) within the Employment and Training Administratici (ETA) andappointed Robert Taggart to be its administrator. The new OYP wet::allocated 49 positions to carry out its charge; of these, 16 wereexisting Job Corps positions, and 27 of the remaining 33 positic- sere\"mandatory hires,\" or transfers from other parts of DOL, over whit.: thenew administrator had no control. This left Taggart with 6 positionsto fill.Of the total OYP positions, 14 were allocated to research,demonstration, and evaluation, and the remainder were allocated toprogram administration.The magnitude of the task confronting Taggart was extraordinary.The final terms of the congressional charge involved roughly doublingthe size of the Job Corps, as wc.11 as enriching the program's educationand training components; increasing the Summer Youth '3mployment Program;launching the Youth Incentive Entitlement Pilot Projects, a multi-site demonstration; launching three new and, most importantly, deciding how touse tt,iscretionary funding allocated to the secretary under thetermsYEDPA.,- was from the last of these--discretionary funding - -that the\"knowledge development agenda\" grew. The YEDPA funding formula was ofbyzantine complexity: it bec.;an by taking the total appropriation forYIEPP, YCCIP, and YETP and dividing it into three parts: 15 percentwent to VIEPP, 15 percent to YCCIP; and the remaining 70 percent toYETP.YACC was funded separately. Of the 70 percent allocated toYETP, three- quarter: 1ent by formula to prime sponsors; the remainingcane- quarter, After wine small deductions for special allocations tostates, and set-asides for migrant workers and native Americans, wentto the secretary for discretionary allocations. Depending on appro-priation levels and how one defined \"discretionary,\" this formula woulddeliver between $300 and $500 million in discretionary money to OYP infiscal 1978, 1979, and 1980 The low end of this range included onlythose funds authorized for discretionary allocation under the formula;the high end included YIEPP, which had to be used for a specificprogrammatic purpose, but which could be allocated at the discretion ofthe secretary.The term \"discretionary\" was deliberately ambiguous. As notedearlier, Congress viewed discretionary funds as a way of adjustingformula allocations to constituency interests and congressionalexpecLations.With the implementation of YEDPA, however, the term 329 300\"discretionary\" became synonymous with the knowledge development agenda.This change in emphasis was the result of Taggart's initiative, not theexplicit direction of Congress.While Congress's intent was to \"find out what works,\" and dis-cretionary funds were cleat ly to play a major role in meeting thatintent, it was by no means a foregone conclusion that the use ofdiscretionary funds would be organized around a centrally administered research and development agenda. The House's expectations were thatYIEPP would be run as a multi-site demonstration and that the remainderof YEPPA would, in a House staff member's words, be allocated on theprinciple of \"let a thousand flowers bloom.\" According to Senate aide Richard Johnson, \"Knowledge development was Bob Taggart's method forbringing some sort of order out of the collection of programs he had to administer.In fact, we had an embarrassing interlude with Bob rightafter the bill passed when word got back to the Hill that he wascalling YEDPA a 'disorganized hodge-podge' of programs--a littleinsensitive to the Members' interests. To his credit, though, heseized the initiative. He saw the discretionary money as anopportunity to be innovative and systematic, and pull things togetherunder a larger strategy. That was all right by us.\" Centralizing Control of YEDPA in OYPWithin DOL, it was far from a foregone conclusion that OYP wouldcontrol all program operations, research, development, and evaluationactivities associated with YEDPA. There were at least three alter-natives to this model. The usual approach would have been for thesecretary to delegate operating authority to OYP and responsibility forresearch, development, and evaluation to the Office of Policy Evaluationand Research in the Employment and Training Administration or jointlyto OPER and to the Office of the Assistant Secretary for PolicyEvaluation and Research in the Office of the Secretary.Another alternative would have been to allocate the bulk of thediscretionary money to prime sponsors under a series of large-scalegrant competitions, and then to require the recipients of thosegrants--state and lc;a1 agencies--to develop research and evaluationplans and relations with research and evaluation organizations as partof their projects. A third option might have been for OYP and OPERjointly to develop plans for a limited number of large-scale demonsLra- tions or social experiments, along be lines suggested by YIEPP, tomanage those projects jointly, and to contract with external organiza-tions to evaluate the projects.The decision to locate all responsibility for program operations,research, development, and evaluation in OYP was taken at Taggart'sinitiative.No money is ever really 'discretionary,'\" Taggart said.\"It's all got to be used to serve a variety of missions--political,administrative, and research. The question was how much control wouldwe exercise over the discretionary money and whether we would divide itup within the Department. There were a number of people who wanted to 33u 301put it all out by administrative formula to prime sponsors; evenEntitlement could have been sent out on a modified formula basis. Igot a quick sign-off [from the secretary] immediately tying it all up[in OYP].\"Taggart's aggressiveness in seizing control of the discretionaryfunds did not endear him to others in DOL, but neither did it createserious bureaucratic problems. The scale of this thing [YEDPA] wasunlike anything the department had ever done,\" Taggart argues. \"ORD[the Office of Research and Development, the unit within OPER withresponsibility for demonstrations] had a budget of around [$20] milliona year.We were talking about putting something like $200 million outin the first year. The existing structure just wasn't designed to dothat.\"While others within DOL perceived Taggart as aggressive, brash,and abrasive, they did not actively oppose his design to controldiscretionary funding after the secretary's approval and, in fact,assisted him in certain ways. Howard Rosen, then head of ORD, andSeymour Pcandwein, th-,a head of OPE (Office of Poli Evaluation, of OPER:, worked for outside services; Brandwein offered advice on researchquestions and negotiating the DOL bureaucracy. One ORD staff member,speculating about why Rosen did not fight for more control of YEDPAdiscretionary funds, said, \"I think Rosen ... saw YEDPA as more of aninstitutional capacity, delivery, building effort and thus didn't seeit as a proper ORD effort.\" The same relationship held with ASPER, inthe Office of the Secretary. Robert Lerman, then an ASPER staffmember, recalls, \"ASPER was much more preoccupied with [the] Humphrey-Hawkins [full employment proposal] than withyouth employment; the youth programs were less than highest priority,and because of that Taggart was given much freer rein.\"Taggart used another device to solidify his position within DOL.He contracted with OPER and ASPER to carry out pieces of the knowledgedevelopment agenda. ASPER was given money to conduct basic research onthe nature of the youth employment problem, which it used to contractfor a number of studies. OPER, in addition to helping with contracting,was given funds to extend two major longitudinal surveys to providemore detailed coverage of youth problems and to fund other youth-related activities. OPER, on its own, also conducted an extensiveevaluation of the Job Corps and an assessment of YEDPA implementationby local prime sponsors.By establishing this relationship Taggart deflected any oversightthey may have conducted on his research and development activities.According to ASPER's Lerman, Our relationship with OYP tied us up alittle bit.It's kind of hard to fully oversee another operation whenyou can't even spend your own money. We were all understaffed and thatworked to Bob's advantage. Besides, Bob is a doer; he doesn't wait, heacts.He just took control and pushed ahead, and no one was there totell him otherwise.\" These sentiments were endorsed by an OPERadministrator, who said, We were reluctant to ta%e on new responsi-bilities beyond our capacity or to e7.at into wrangling with Taggart,with whom [many of us] agreed a4way.\" 331 302Taggart's tactics for dealing with ASPER and OPER also avoided achronic organizational problem that DOL had been grappling with asearly as 1973. ASPER was staffed mainly by economists, who usuallytook short-term appointments of two-to-four years, often on leave fromacademic appointments, and whose main interest was the application ofeconomic analysis to policy decisions at the departmental andpresidential level. OPER, on the other hand, was staffed mair.ly bycareer civl servants whose background was in employment programs andwhose main interest was the program monitoring and evaluations aimed atimproving operations. These institutional loyalties tended to reinforcemutual stereotypes within the department, not always accurate, thatASPER 1s populated by \"academic economists\" and OPER by \"programpeople.\"Another characterization of the difference, offered by an OPERadministrator, was that the \"academics believed that conceptualizing anevaluation was the key issue ... with little regard for feasibilityor...implementation.\" The split resulted in delay and disagreementaround the planning for the national evaluation of CETA in 1974(Hargrove and Dean, 1980). A major effect of Taggart's move tocentralize program operations, research, development, and evaluation inOYP, then, was to avoid a major source of past institutional conflictwithin DOL.Another possible source of external scrutiny over OYP might havebeen the Office of Management and Budget (OMB) in the Executive Officeof the President, which monitors the research and evaluation activitiesof federal agencies. '!he OMB examiner for YEDPA, a critic of Ow'sknowledge development etforts, explains why OMB exercised littleinfluence -- oversight: \"I came on board just after YEDPA passed. Itwas clearat Taggart was unwilling to take any outside advice hedidn't agree with. No oae within DOL was willing to try to corralhim.It was a clear case institutional default. From OMB's pointof view, AZ the money comes to the agency from Congress on a set-asidebasis, we have no dire77:t way to reach it. We stay out of the sec-retary's internal business and focus on the budget and the President'sprogram.We are not in a position to tell people in the departmentswhat hind of research to do; we can try to cajole and persusde, but wedon't have much influence. One thing is for sure, though. AllowingTaggart to grab control of the discretionary money was a verysignificant decision; onc,) that happened, we all lost our ability toinfluence what was going on.\"Taggart, not surprisingly, saw the stakes differently. We hadenormous resources, basically no staff, multiple objectives, and verylittle time.People in tne department di'r't pay much attention to us;they were consumed by PSE. We ended up b 6ng the only program in thedepartment combining policy, research, ana operations. The law said,_'first, get the money to people in the right places, second, achievesome kind of coordination between federal agencies--take a leadingrole, and third, do something about the relationship between schoolsand employment programs. The research focus was my way of exercisingadministrative control. My view of the purpose was to establish an 332 303institutional base for youth employment programs and make it work toserve youths.You had to achieve large-scale institutional change, andthe way to do that was to put the money out there ana then usemonitoring, evaluation, demonstration, and research to pull the systemalong.\"In other words, centralized control was Taggart's way of puttingresearch into the service of management. \"Finding out what works\" wasuseful only insofar as it was instrumental in building a structure ofinstitutions focused of youth employment.Taggart was young--in his thirties--relatively inexperienced as anadministrator, very ambitious, and possessed of strong ideas about therole of research in policy making and administration. His major experi-ence before coming to OYP had been as a researcher, having worked withSar Levitan on a number of studies of federal employment and povertyprograms.From his prior work and his early experience in DOL, heevolved some working principles. One of these was that all programeffects are marginal. \"Whatever we deliver as a program is one of manyfactors operating on kids, and not the most important one at that.Thebest you can expect is a 10 percent effect. You can never separateparticipant, site, an3 program effects.\"Another principle was deep skepticism about employment research andthe researchers who produce it. The problem with the research com-munity is that they don't know substance, institutions, and procedures- -most employment research is useless if you need to figure out what todo [with it).\" This skepticism about research was matched by an equalskepticism about the competence and knowledge of the people who operateemployment programs. \"You can't rely on practitioners to find thesolutions. Their perspective is too narrow.\" A final principle,which evolved with experience, was that the content of the program wasless important in determining outcomes than the skill with which theprogram was implemented. \"Everything's good that's done good.\"Together, these principles comprised an instrumental view of therelationship among research, evaluation, management, and policy. Thepurpose of research and evaluation was not simply, or even primarily,to inform policy decisions. It was to create a management structure, astructure for judging and rewarding performance, for developing pro-grams, for dispensing money and assistance, and for weeding outineffective practices and replacing them with effective ones.Youcouldn't evaluate until the institutional structure was there todevelop and implement a program. Whatever was implemented was highlydependent on the limited skills of the people who worked in thedelivery system. The function of research and evaluation was, first,to create a management structure and, second, to nulge local adminis-trators by stages into better performance. From this perspective,separating the research, development, and evaluation purposes of YEDPAfrom its programmatic purposes would have been unthinkable. ForTaggart, research, development, and evaluation were, primarily, toolsof management and, secondarily, mechanisms for systematic inquiry orpolicy making. 333 304The Knowledge Development PlansThe first attempt to design the research, development, andevaluation component of YEDPA was embodied in the 1978 KnowledgeDevelopment Plan, written soon after Taggart became administrator of OYP.The term \"know1P%-- development\" is credited to Joe Seiler, a veteran of OPER an sistant to Taggart (DOL, 1980e:9). This first knowledge developmeL an was, in Taggart's words, a \"seat-of-the-pants\" document, crafted from two sources. \"First, we took the law andbroke it into pieces that were consistent with congressional intent. Next, I gave my best reading of the issues in youth policy that had ..veloped since the 60s.\"The body of the 1978 plan closely followed the structure of YEDPA and its funding formula. It included descriptions of research,development, and evaluation activities to be undertaken in each of themandated programs--YACC, YIEPP, YCCIP, and YETP--and a careful statementof how those activities would correspond to congressional expectations.The plan also contained the first list of eight cross-cutting researchissues (Table 5). This list later evolved into 15 questions (Table 6)and, in the 1979 plan, into 16 issues.The first plan was mute on the practical question of how thosebroad, cross-cutting questions would be answered by the specificstudies taking place under each congressionally mandated program. The 1979 plan made the conceptual connections between broad i dues andspecific studies clearer by organizing specific studies around broaderissues, keyed to time lines (DOL, 1980c). But throughout the plansthere was no explicit discussion of who would draw disparate studiestogether and how that would be done.The fact that these issues were left unspecified, however, did notmean that Taggart had no solutions to them. One solution was tocontract with an outside research organization, the Center forEmployment and Income Studies (CEIS; later consolidated into the Centerfor Human Resources) at Brandeis University, to help OYP exerciselateral influence over the design of evaluations in separate projects and to help synthesize results. But the primary solution, for Taggart,was that he understood connections among pieces of the design. On thismatter, Taggart is unapologetic. \"I'm the only one who knows how thepieces of the process fit together because I'm the one who designed it.\"The practical problems of mounting a large-scale research anddevelopment enterprise were another major theme in the knowledgedevelopment plans--problems of management, organization, time, and methodology.The main management problem was how to mount gooddemonstration programs without \"locking resources into aa operationalmode such that it would be difficult to transfer them in the future toapproaches which prove more effective.\" Another management problem wasthat YEDPA was intended to provide jobs as well as research on whatworks, which created \"a tradeoff between careful research design andrapid implementation to maximize economic impacts.\" The mainorganizational problem was limited staff at the federal, regional, andlocal levels and \"resources scattered over myriad projects.\" 305TABLE 5Research Questions, 1978 Knowledge Development Plan 1.Does school retention and completion increase the futureempl,:yability of potential dropouts and the disadvantaged, and issubsided employment a mechanism for increasing school retention andcompletion? 2.Can the school-to-work transition process be improved? Thisinvolves several related questions. Are new institutional arrangementsfeasible and warranted? Will increased labor market information andassistance expedite the transition? Can employer sti: tidies and otherprivate sector approaches create new transition routes? 3.Work experience has become the primary emphas2s of youthprograms.Jobs are to be \"useful\" and \"meaningful,\" i. e., having botha worthwhile output and an impact on future careers. Are the jobsproductive? Which ones are most \"meaningful\" and how can they beidentified? 4.Does structured, disciplined work experience have as mush or moreimpact on future employability than other human resource developmentservices or a combination of services and employment? 5.Are there better approaches or delivery mechanisms for the typesof career development, employment, and training services which arecurrently being offered? 6.To what extent are short-run interventions and outcomes related tolonger-term impacts during adulthood? Put in another way, how dopublic interventions affect the maturation and development process? 7.What works best and for whom? This is a perpetual and criticallyimportant question of matching services with needs. To answer this, itis first necessary to develop a set of performance or outcome standardswhich determine what does and does not work. The second step is to tryto determine who realizes these benefits under which programs andapproaches. 8.What are the costs of fully employing youths? Unemployment ratesfor youths are of questionable meaning because of the substantialnumber of \"discouraged\" individuals who are outside the labor force butwould be attracted to minimum-wage jobs. Others are working less thanthe desired number of hours. It is important to determine the extentof the job deficit and the costs of eliminating it. SOURCE:U.S. Department of Labor (1980b). 335 306TABLE 6Knowledge Development and completic increase tne future employabilityof potential dropouts and the disadvantaged, and are employment and trainingservices linked to education an effective mechanism for increasing schoolrentention and completion? 2.Can the school-to-work transition process be Improved? This involvesseveral related questions. Are new institutional arrangements feasible andwarranted? Will increased labor market information and assistance expedite the transition? Can new transition routes be created? 3.Given the fact that work experience has become tne primary emphasis ofyouth programs, are the jobs productive, which ones are most \"meaningful\" andhow can they be improved? 4.Does structured, disciplined work exprience have as much or more impacton future employability than other human resource development services or acombination of services and ..xploya.ent, i. e., should public policy emphasizestraight work experience, combinations of work and training and otherservices, or should training, education, and supportive services oe emphasized? 5.Are there better approaches and delivery mechanisms for the types ofcareer development, employment, and training services which are currently being offered? 6.To what extent are short-run interventions and outcomes related tolonger-term impacts on employability during adulthood? Put in another way,how much can public interventions redirect the developmental process?7.What works best for whom? What performance or outcome standards arebest to determine what does and does not work for youths? Which youths withwhat characteristics benefit from which programs and approaches?8.What is the universe of need for youth programs? What is the cost offully employing youths? How many would take jobs if they were available andhow many nours of employment do they require? 9.What approaches and procedures can be used to involve the private sectorin employment and training efforts ana to increase the placement of theparticipants in private sector jobs? How effective are those approaches inaccessing new jobs and providing better career tracks for youths? Are theypreferable to public sector approaches? 10.What is the best mix of enrollees in terms of age ana income status?Will poor youths benefit from interaction with nondisadvantaged youths or with older persons? Is targeting achieved and is it a wortnwhile notion?11.What arrangements can be made to increase the duration of employment andtraining interventions and to assure that participants realize lifetimebenefits?Will youths demonstrate the commitment and consistency to makethese long-term investments pay off? 336 307TABLE 6(Continued) 12.What strategies are most important at different points in the lives ofyouths?Must training be delayed until greater maturity is achieved? Art.employment and training programs a way of inducing maturity? 13.How can separate youth programs be better integrated to improveadministration and to provide more comprehensive services to youths? To whatextent are the programs already integrated at the local level? 14.How do the problems of significant youth segments differ, includingthose of migrants, rural youths, the handicapped, offenders, young women withchildren, runaway, and the like? Are special needs groups and specialproblems better handled by mainstreaming or by separate programs for thosegroups? 15.How can the lessons from knowledge development activities best betransferred to improve existing youth programs? How can the institutionalchange process be promoted? What are the learning curves on new programs andhow much can they be expected to improve with time? SOURCE:U.S. Department of Labor (1980a). The main problem with time initially was that, with the exceptionof YACC, YEDPA programs were authorized only through October of 1978.This meant that, while many research questions required long-termstudies, commitments could only be made for one year. After October1978, when YEDPA was reauthorized through 1980, there were additionaldemands to provide timely results, through the summer and fall of 1579,for the policy development effort operating under the Vice President'sTask Force for Youth Employment, which culminated with a proposal tothe Congress in January of 1980. The main methodological problem washow to devise studies that could provide verifiable results within theconstraints of program, organization, and time (DOL, 1980c).A sense of how time constraints drove design decisions can begleaned from the 1979 Knowledge Development Plan (DOL, 1980b:111):Three of the four major YEDPA programs--YETP, YCCIP, and YIEPP--are authorized only through fiscal 1980. It is anticipatedthat by that time many of the critical issues underlying youthpolicy will be re:A:dyed to a greater degree so that majordecisions can be made. For recommendations to be formulatedand legislation passed by the end of fiscal 1980, these must bebased on results which will be available at the latest by fallof 1979. The ... schedule for the implementation of 1979 discretionaryactivities makes it quite apparent that there will only be 337 308limited information from these projects by this time. Even ona rapid implementation schedule, most will not complete adesign and contracting until the end of the first quarter offiscal 1979.The results of the first half year's operationscan hardly be tabulated and analyzed by the end of 1979 andonly interim process findings will be available reflectingmainly start-up difficulties. Most of the information yieldfor the end-of-1979 decisions will have to come from projectsimplemented in fiscal 1978. Here too, the findings are limitedto early results and developments rather than long-term impacts. A less ambitious and committed person than Taggart would have concludedfrom this analysis that congressional and executive expectations forresults from YEDPA were simply incompatible with time and resourceconstraints.Taggart did not draw this conclusion: Whatever could beproduced, would be produced. Key Design FeaturesAs the knowledge development strategy evolved, certain designfeatures emerged. Among these were (1) complexity in the range ofissues, program activities, research projects, and products; (2)relatively heavy emphasis, in early phases, on process information,rather than outcome data; (3) wide variability in research design,method, and type of results from one knowledge development activity toanother; and (4) major changes over time.The knowledge development plans were complex largely because thecongressional and executive expectations that accompanied YEDPA werecomplex.Granting the complexity of expectations, though, a commontheme among both Taggart's harshest critics and strongest allies wasthat he did little to control the complexity of the enterprise. RobertLerman, ASPL1 staff member, recalls that in late 1978, when Taggartconvened a conference at Reston, Virginia to discuss knowledge develop-ment efforts, \"It struck me that the plan just had too many questions.He [Taggart] listened carefully to people's reservations and he thoughtabout the problems they raised, but early on he bought into a bigmulti-demonstration view of what he was doing, which didn't accommodatemuch to clarity in design. Things didn't seem to have a clear logicalstructure to them.\"Andrew Hahn, who worked with Leonard Hausman in the Brandeis Centerfor Employment and Income Studies as part of the technical assistancefunction of OYP, recalls, \"Len Hausman argued that the first plan wastoo complex.He said it could be organized around three aspects of theyouth labor market--labor supply, or how to affect the skills andattributes that kids bring to employers; labor demand, or how toinfluence employers' demand for kids through various kinds ofincentives; and intermediary linkages, or how to smooth out thetransition to the work.\"Taggart resisted this advice. \"There were probably two reasons whyhe resisted,\" Hahn continues. \"First, he had a hard time prioritizing. 338 309Bob always thought in long, complicated lists, rather than in simplerframeworks.Also, it may have been that he deliberately wan=ed aninelegant design; by keeping the agenda complex, he maintained controland kept [Arnold] Packer tassistant secretary for policy, evaluation,and OPER], and the White House offhis back.\"The net result of this complexity, says Hahn, who is astrong advocate of the knowledge development process, wasto encumberthe design with a huge number of second-and third-order questions thatwere often brilliant and insightful but totally confusing to anybodybut Bob.\"The second reason why Taggart resisted Hausman's advice was thatthe early results of knowledge development were hclavily weighted towarddescriptions of the process by which projects were developed andimplemented in various sites. This characteristic caused considerablefriction between Taggart and, among others, the Office of Managementand Budget.The OMB examiner for YEDPA, reflecting a characteristicinstitutional bias of OMB, said, \"I expressed very strong reservationsfrom the beginning about how it was developing, particularly about thelarge amount of money being spent on studies that didn't produceoutcome data.OMB likes to see good, strong impact evaluations.Taggart didn't see it that way. He had his political constituency toprotect.So most of the stuff he produced was very uninteresting to US.The reasons for the emphasis on process data were fourfold. First, OYP was under pressure to produce results, but lacked the time to mountprograms, let them mature, and then measure their effects. The nextbest thing, from OYP's perspective, was to build into the knowledgedevelopment process extensive information about the process by whichprograms were implemented. Or in Taggart's words, \"In the first yearand a half, our problem was how to do research when what was actuallygoing on was start-up and implementation.\"Second, the relatively heavy emphasis on process information in theearly stages was consistent with Taggart's view of research andevaluation as an instrument of management control. Process informationmay not have been useful to OMB in making government-wide allocationdecisions, but it was valuable intelligence to Taggart in his attemptto create and manage a youth employment delivery system. Moreover, byasking for process information, Taggart was communicating that heplaced a high priority on creating an infrastructure to mount,administer, and evaluate youth programs.Third, the wide variability in design, method, and type of resultsfrom one knowledge development project to another meant that there wasno straightforward way to bring specific results to bear on cross-cutting questions. Separate projects were contracted through a varietyof organizational arrangements, discussed below, and decisions aboutthe research and evaluation design for each project were worked out,case by case, by Taggart and the OYP staff. While there was an overall\"design,\" in the sense that individual projects were related to abroader set of policy questions, there was no mechanism for assuringthat the design decisions of one project were consistent with those ofother projects or with some overall set of methodological criteria.In 339 310some instances--YIEPP, for example--design decisions were arguedthrough with the responsible organization in a detailed way and with anexplicit analysis of their methodological consequences.In other instances--typically, joint projects with other federalagencies--design decisions were allowed to evolve according to thepreferences of the responsible organizations, or were not addressedexplicitly at all. In still other instances--the creation of large-scale data bases or the adaptation of existing data bases to youthquestions, for example--there was a high level of delegation to theresponsible organization, with review and comment by OYP. Variability,then, was partly a function of the complexity of the issues, programs,projects, and products that the knowledge development plans focused onand the organizations that were used to translate those plans intoaction.But variability was also a function of Taggart's own lack ofenthusiasm for consistency and rigor in methodology. He did notbelieve that focusing on methodological rigor and consistency, at theexpense of other objectives, would pay off, either in new knowledge orin better programs. \"People complain, after the fact, on a study-by-study basis, about things like the lack of adequate comparison groups,\"Taggart argues. \"S---:At least we had comparison groups in a lot ofstudies.That was more than anyone else had done on that scalebefore.We introduced as much methodological rigor as we could, eventhough I believed, and still do, that it wouldn't work. What you'redoing, when you apply fancy research methods to projects like the oneswe had early in the program, is researching ineffectuality, notintervention.The fact of the matter is that people don't know what todo.All you're discovering is that they don't.\"For Taggart, the primary questions were developmental, notmethodological. \"None of this research will yield anything if peopledon't know what they're doing. What you need to do is to give eachpart of the delivery system a piece of the action, use monitoring andevaluation to generate competence, pick up the threads running throughthe system to get a broad understanding of what makes effectiveprograms, and then get states and locals to make decisions about whogets what and get them to monitot lnd enforce.\" Questions of capacity,orrjanization, and management were prior to questions of design; researchmethods were instrumental to the development of a delivery system.Finally, the overall design of the knowledge development effort andthe design of specific studies changed markedly over time. For example,the YIEPP demonstration started by testing the effect of a fullysubsidized work guarantee on school attendance, school completion, andshort-term employment. About halfway into the demonstration, thedesign was changed to accommodate variable subsidies, on the expectationthat Congress would want to know whether a less expensive program wouldhave positive effects. Also, it became clear after YIEPP commencedthat assuring school attendance through employment guarantees was notnecessarily a clear benefit to young people if the the school programwas not adapted to their needs.Well into the demonstration, then, attention shifted to providingbetter educational programming for YIEPP participants. Another example 34o 311of a significant design shift was the introduction in 1979 of theConsolidated Youth Employment Program V(YEP) demonstration in nineprime sponsor areas. The purpose of CYEP was to test the consolidationof YETP, YCCIP, and SYEP grants into a single grant directed atmultiple purposes. The project was based on congressional andexecutive expectations that the separate youth programs authorizedunder YEDPA would be consolidated in the 1980 reauthorization (DOL,1980c:162-163).The YIEPP example indicates how shifts in design can be stimulatedby external expectations and by discoveries of weaknesses in programdesign.The CYEP example shows how design is a function of thepolitical agenda. In both instances, though, changes in design raisethe issue of whether it is better to stick to a single, well-specifiedset of projects for as long as it takes to get results, or whetherdesigns should be adjusted to external changes and internal discoveries.A strictly methodological view would argue for holding projects constantuntil results are clear, since \"finding out what works\" depends ondelivering a uniform treatment and controlling for alternative explana-tions of program effects. A developmental view, however, argues formaking adaptations whenever they are required to improve program designand adapt to changing expectations. The knowledge development plansclearly embodied the developmental view.Design, then, meant two distinctly different things in theknowledge development plans. First, it meant accommodating congres-sional, executive, and institutional interests involved in the youthemployment problem in some sort of overall scheme and using that schemeto develop an institutional base fog youth programs. Second, it meant,in the more conventional methodological sense, designing specificprojects to deliver specific results on specific issues. Methodologicalquestions were clearly instrumental to institutional development. Thereis a third meaning of design, which was not explicitly represented inthe knowledge development plans. That is the integration of specificfindings into some overall set of cross-cutting questions. The lack ofthis kind of design was the result of Taggart's strongly centralizedview of this role and of the complexity of the issues incorporated intoYEDPA. ORGANIZATION AND MANAGEMENTThe magnitude of the organization and management problemsconfronting Taggart and his OYP staff in the fall of 1977 have alreadybeen sketched: Launch three new national programs (YCCIP, YETP, YACC),launch one national demonstration program (YIEPP), expand and enrichtwo existing youth programs (Job Corps and SYEP), and allocate over$200 million in discretionary research and development funds. At aminimum, launching new programs would entail writing the 'oasic rulesthat would govern state and local administration, or in the case ofYACC, negotiating the necessary interagency agreements that wouldresult in other agencies writing the basic rules. Taggart estimatesthat he wrote, or supervised the writing of, about 40,000 pages ofp.ogram guidelines in the first year. 341 312 Launching a nationwide demonstration, like YIEPP, is an exercise inpolitics, administration, and research: The political element comesfrom the fact that, unlike the formula grant programs, only a limitednumber of localities--17 eventually in the case of YIEPP--can par-ticipate.Which localities apply and which are eventually selected arematters of considerable political sensitivity. Administratively, theproblem is how to get state card locml organizations, mainly in thebusiness of delivering employment and training services, to agree toparticipate in fixed-term research and development efforts. Theresearch problem is devising and implementing a design that will answerpolicy questions within the operating constraints imposed by theexisting delivery system. Allocating discretionary money, as we haveseen, would entail defining questions responsive to congressional andexecutive interests, elaborating those questions into plans for discreteprojects, and turning those plans into operating programs and designs.Another way of illustrating the magnitde of the organization andmanagement problems posed by YEDPA is to focus on the organization andmanagement problems involved in the allocation of discretionary funds.If the average discretionary project, defined as one attempt to mount,operate, and evaluate an idea in one site, were to cost $500,000 overthe course of two-and-a-half years, there would be roughly 1,000projects.If one were to assume that OYP would have 20 full-time staffavailable to focus exclusively on discretionary activities--an extremelygenerous assumption, given the office's other responsibilities--eachstaff member would have responsibility for roughly 50 projects. More-over, this example takes account only of the oversight necessary tomount, operate, and evaluate projects. It does not include the effortnecessary to mount broad-scale data collection across projects, tooversee the reporting of data, and to synthesize the results ofdisparate projects into general conclusions.The administrative feasibility of the knowledge development effortwas dubious, then, under even the most generous interpretation of OYP'sstaff capacity. But, according to a number of observers, includingTaggart, the quality of OYP staff fell short of the best. With theexception of a limited number of staff, perhaps three or four, whomTaggart had recruited from the outside or from positions elsewhere inDOL, OYP staff were neither trained for nor particularly interested inresearch and evaluation. \"They were basically program people,\" saidone individual who worked closely with OYP staff, \"and not the bestprogram people at that.\" Sensitivity to research design questions, theability to work with contractors on complex research issues, and anawareness of the broader consequences of specific research decisionswere attributes that, according to most observers, were in short supplyamong OYP staff.One of the central puzzles of the knowledge development effort waswhy, given the enormous federal investment and the risks involved inpoor execution, OYP did not hire more highly qualified staff. At leasttwo explanations have been advanced. One explanation is that federalpersonnel requirements do not allow agencies to respond flexibly tolarge new projects with high short-term requirements for people withspecific skills. The personnel system is designed to supply and 342 313maintain a stable career work force, not to meet peak-load demands oflarge-scale research and development proje \"ts. Hence, OYP was initiallystaffed by career employees transferred from other DOL programs, andTaggart'c requests for additional staff were met with the reply that0YP'v needs had been met.Another explanation is that the DOL budget office and OMBdeliberately used staffing as a way of showing their disapproval ofTaggart's abrasive, autonomous, highly political style of managementand the lack of methodological clarity in the knowledge developmentdesign.One executive brar...is budget analyst said, \"That's how a numberof actors within DOL and OMB got at Taggart. None of us could effec-tively control tta financial resources, but we could [control] nisemploymcrt resources. Both the depari-ment and OMB gave his requestseach year for more staff very short shrift--even t igh it wasmanifestly clear he was way understaffed.\" Furthermore, the analystargued, \"Taggart never submitted a clear, workload-based researchdesign that we could use to evpWate his requests.\"OMB's formal position on Taggart's requests was that knowledgedevelopment should be staffed by OPER, and that 0Yr staff should focuson program operation.-, Behind this formal position, though, was astrong distaste for Taggart's unabashed empire building, which wasshared by DOL budget staff. A budget analyst observed, \"Note that whenBarnicle [Taggart's successor as head of OYP] took over heimmediately an OYP [personnel] increase--that's because he knew nowto p.ay ...There are many weapons in bureaucra,:ic warfare.\"Whatever the explanation, OYP's staff was a serious, some would sayfatal, constrai.t on its ability to mount the knowledge developmessteffort.These constraints, coupled with the congressional charge to forgefederal interagency connections and to rely on community-basedorganizations, quickly led Taggart to \"management by remote ointrol\" or\"indirect management\" of the knowledge development effort (see Salamon,1981).In Taggart's words, \"It takes as much time to procesa a $5million contract as it does a $100,000 contract.\" Given a choicebetween managing thousands of contracts in the hundreds of thousands ofdollars or dozens of multi-million dollar contracts, there was nocontest in Taggart's mind. The basic plan was .to get 1..he money out ofOYP as quickly as possible in a series of large chunks; to use existingorganizations, or to create new ones, outside OYP/DOL to manage discretepieces of the knowledge develop effort; and to create capacity, alsooutside OYP, to reinitor, assist, end manage relationships among thepieces.In its basic form, this organizational scheme was not unlike themodern corporate conglomerate. It was a collection of free-standingenterprises, each with one or more \"product lines,\" each with its ownset of projects, clients, and ouputs, held together by contractualrelations with the cesster. The function of the center was not tomanage projects, o:ients, and outputs, but to see that the constituententerprises were knowing through on their contractual obligation tomanage those things themselves. 343 314As with all forms of organization, this ore has its characteristicstrengths and weaknesses. Its main strength is that it reduced thespan of control at ,he center by roughly a factor of 10--from poten-tially thousands of separate projects to, as it turned out, somethingover 100.The mail weaknesses of this organizational scheme are that,first, its success depends almost totally on strong management capacityin its constituent enterprises, and second, that the structure itselfcontains no obvious solution to management failures in constituententerprises.When problems develop in the pieces of a corporate conglomerate,central management either replaces the management of those enterprisesor sells them outright. These solutions are less feasible in thepublic sector. More importantly, though, the constituent pieces of aconglomerate--public or private--are relatively immune to centralcontrol of their internal operations, even when they are poorlymanaged.The slightest increase in management control from the centercan create an enormous overload of central management. For thisreason, among others, corporate management has tended more recently tomove away from conglomerates and toward organizational schemes thatpermit \"tight\" central management of finance and output targets,coupled with \"loose\" central management of internal organization andoperations (Peters and Waterman, 1982).Taggart's strategy of indirect management depended on pulling atleast five distinctly different types of organizational arrangementsinto a single conglomerate structure. Table 7, drawn from OYP'sknowledge development projects for fiscal 197d and 1979, illustratesthese organizational arrangements. Organizational ArrangementsIntermediaries The use of intermediaries was an outgrowth of DOL's priorexperience with the Manpower Demonstration Research Corporation(MDRC).The brainchild of a federal interagency task force, aided byFord Foundation support, MDRC had designed, implemented, and evaluateda national demonstration of supported work as a solution to w-lfaredependency (Lowry, 1979). Because of the extremely snort time linesinvolved in launching YIEPP, MDRC emerged as the most likely candidateto manage that demonstration. If the MDRC model could work with theentitlement project, why not try it with others, Taggart reasoned.Hence, in November 1977, the Corporation for Public/Private Ventures(CPPV) was established to handle demonstrations of private sector youthemployment; in January 1978, Youthwork was established to handleexemp-ary in-school employment programs; and in May 1978, the Corpora-tion for Youth Enterprises (CYE) was established, through an inter-agency agreement with the Community Services Administration (CSA), tomanage demonstrations of youth-run enterprises.The role of intermediaries in knowledge development has to beunderstood in connection with Taggart's instrumental view of research 344 TABLE 7Selected Knowledge Development Activities OrganizationAmount(fiscal 1978-1979) document forprivate sector community repairprogram; its enterprises; projects Test national youthservice--community internships;1 projectTest feasibility of transferring urbancommunity service project to ruralsetting; 1 projectTest feasibility of one-on-one volunteersin assisting youths to find employment;14 projectsTest feasibility of youth employmentin rural housing programs; incollaboration with Department ofAgriculture; 13 sitesTest feasibility and effectiveness ofyear-round program for out-of-schoolyouths in community development projects;3 projects TABLE 7(Continue) OrganizationAmount(fiscal 1978-1979) Tasks Health, Education, andWelfare Department projects(within DOL)Oftice Research youthemployment and training HEW-runRunaway Youth Centers; 11 projectsEstablish, support and test effectivenessprojects to link post-secondaryeducational institutions to C -Aagencies; 20 projects; administered byFund for the Improvement oflost- Secondary Education (FIPSE)Test feasibility of replicating andevaluate effectiveness of Career InternProgram in OpportunitiesIndustrialization Center sites; 4 sites;administered by National Institute ofEducation (NIE)Test feasibility and effectiveness ofvocational education linked to summerwork; 6 projects; administered by Bureauof Occupational and Adult EducationPart-time work for 1,000 Upward Boundparticipants; 9 projects; administered byBureau of Higher and Continuing EducationTest feasibility and effectiveness ofsummerprogram of education and work experiencein energy field 3,999,967 (1978) Expand National Longitudinal Survey2,900,000 (1979) (NLS)800,000 (1978)3 1PjExpand Continuous Longitudinal to asess impact of YCCIPand YETP on youths Assistant Secretary for PolicyEvaluation and Research(ASPER)362,000 $265,265 (1978)59,322 (1979) National 3rt 76,294(1978)Employment Policy Constituency Conference of Mayors 168,100(1978) National Association of 130,170(1978)Counties 35,000(1979)National Governors 102,763(1978)AssociationNational Urban League 8,262,633(1978)Women's Bureau 1,315,945(1979)SER-JOBS for Rican ForumNational Council of Council of LaRaza SOURCE:U.S. Department of Labor (1980b). 347Process evaluation of local implementationofYEDPA; contracted to National Council onEmployment Policy Basic research on youth employment;contracted to UCLA, National Bureau of.Economic Research, and various otherorganizations Technical assistance in research designto exemplary projects; processes forretrieval, dissemination, and utilization offindingsReview and analysis of selected programactivities, including state-of-the-art reviewof programs of disadvantaged youths andassessment provide technicalassistance providetechnical assistance to prime on participationof community-based organzations inschool-work linkages 348 318and his developmental view of how to approach the youth employmentproblem.The task was not just to demonstrate that certainprograms operating in certain settings could work, but moreimportantly, to create a large-scale constituency of organizationscommitted to making certain programs work in certain settings.Later, Taggart (1980:15) would describe his purposes as follows:The aim of the involvement strategy was to build up theexpertise for the involved groups and institutions to provideassistance in the replication of specific proven models underan incentive grant structure, as well as intensive tachni- alassistance on specific substantive components of youthprogramming. ... Without this institutional infrastructure, there would be nocapacity to deliver whatever \"solutions\" emerged from the knowledgedevelopment process. The investments in intermediaries, then, werepartly investments in research and development and partly investmentsin institutional capacity. Andrew Hahn, from Brandeis, puts theproblem this way: \"When you go to do research and demonstration in theAucational system, you've got a lot of established organizations whocan create curriculum, train, test, and evaluate. Before YEDPA, therewas no capacity like that in the youth employment area, just acollection of small entrepreneurs anti a big employment and trainingdelivery system focused mainly on adult programs.\"Intermediaries were a short-term capital investment in a longer-term problem of institutional capacity. They were also a high-riskinvestment.With the exception of MDRC, none of the intermediariesexisted prior to YEDPA, nor were they managed or staffed by people whohad experience in similar settings. Consequently, as one might expect,CPPV, Youthwork, and CYE made their early decisions on an opportunistic,trial-and-error basis that produced a predictable mix of successes anderrors (Lowry, 1979).Youthwork, for example, recruited its staff disproportionately fromthe education community, giving it little credibility with CETA primesponsors.When this became clear, the organization adjusted, but lostprecious time in the process. All the intermediary organizations, withthe exception of MDRC, had difficulty attracting and holding qualifiedresearch specialists, and this fact showed up in the quality of theirinitial plans. CPPV managed to recruit qualified staff, but its rela-tive inexperience in management created start-up problems. Youthwork'lad a high level of internal turnover in its first two years, whichundermined its ability to develop research expertise. CYE was slow indeveloping and r.ever managed to attract and hold strong research staff. Interagency Agreements Interagency agreements were an outgrowth of congressionalexpectations that DOL would \"pull together the pieces\" of the federalgovernment around the youth employment problem. The portfolio of 349 319interagency projects was substantial and reflected a number ofagendas.The ACTION projects focused on youth community service,consistent with the objectives of YCCIP. The CSA projects also focusedon youth community service, but with a strong emphasis on operationsthrough local community organizations spawned under the federalantipoverty program of the 1960s. The HEW projects focused on con-nections between local employment and training programs and secondaryor postsecondary institutions--a key congressional concern. TheDepartment of Energy project focused on drawing disadvantaged youthsinto new careers in the energy field.The interagency projects returned little in the way of structuredresearch and evaluation, for reasons that are relatively clear. WhileOyp often referred to its federal collaborators as playing the role ofprime sponsors, the facts were that GYP could exercise virtually nocontrol over the projects they administered after the interagencyagreements were signed. The agencies were neither creatures of DOL--asprime sponsors were--nor full-fledged contractors--as intermediarieswere.They were free-standing federal agencies with independentauthority.Hence, if they lacked the capacity to do systematicresearch, or if they disagreed with the demands that research andevaluation imposed on their discretion, there was little OYP could doto force their cooperation. Moreover, since the purpose of interagencyagreements, from the congressional point of view, was to cement internalrelations within the federal government, it was not necessarily in theinterests of OYP to provoke embarrassing interagency conflicts thatwould be difficult to explain to Congress. Intraagency Projects Intraagency projects, as noted above, served an important internalobjective by stabilizing OYP's relationship with ASPER and OPER. Buttwo equally important additional purposes of these projects were,first, to develop a basic research constituency for youth employmentamong academics, and second, to assure that youth employment issueswere adequately addressed in established longitudinal data bases, likethe National Longitudinal Survey and the Continuous LongitudinalManpowe Survey.In their own way, the intraagency projects were among the mostsuccessful in the knowledge development process. They involvedrelatively low-cost, finite, well-defined tasks; they could build onestablisinstitutional capacity (e.g., the National Bureau ofEconomic Research, the National Council on Employment Policy); and theyhad relatively self-explanatory payoffs. But for all their appeal inspecificity and feasibility, these projects were not very valuable inpolitical terms. Better research and more complete data about youthemployment were useful in dealing with Congress only if it could alsohe demonstrated that DOL was \"doing something* about the problems itwas documenting. 350 320External Staff Support External staff support was a direct outgrowth of limited staffcapacity within OYP. The key organization was the Brandeis Center forEmployment and Income Studies. CEIS had an intentionally broad andambiguous charge: \"(1) To provide technical research design guidanceto the na.ional array of experimental and demonstration projectsimplemented under YEDPA, and (2) to develop administration processesfor the retrieval, dissemination and policy utilization of researchfindings and other knowledge development products of these discretion-ary projects\" (DOL, 1980b:278). These responsibilities overlappedthose of a number of other organizations, including the EducationalTesting Service's (ETS) development of a Standard Assessment System(SAS), the design and evaluation functions of the intermediaries, and anumber of other individual projects with their own evaluations.But if CEIS's role was ambiguous in a formal sense, its practicalfunction was much less so. CEIS staff were the only source of \"lateralintelligence\" in the complex array of organizations spawned by OYP.All the other organizations were producing \"vertical intelligence,\" inthe sense that they were assigned projects with specialized targetgroups and particular programs. As noted above, this meant that thedesign of the knowledge development effort, if it wag to exist at all,depended on the ability to make cross-cutting conclusions fromdisparate projects.In its evaluation consulting and technical assistance role, CEISwas not just trying to improve the quality of project evaluations (adifficult task by itself), it was also gathering intelligence aboutwhat the developing delivery system looked like across a variety oflocalities and projects. CEIS also performed the function of conveningperiodic conferences to review design decisions, interim results, and practical lessons. In the absence of these activities, there was noformal mechanism for getting people involved in the knowledge develop-ment process to talk to each other about their results. While aelateral intelligence function is hard to specify in formal terms, andwhile one could argue that under the best of circumstances it wouldhave been performed inside OYP, it was a practical necessity, gijenOYP's staff capacity and the organizational complexity of the knowledge development effort.Another important external support function was provided by theEducational Testing Services Standard Assessment System.The initialidea behind SAS was plausible. ETS would develop a single battery ofinstruments, composed of measures of client background characteristics,educational measures, and employment measures, which would be adminis-tered to a large sample of YEDPA demonstration project participants, b:fore and after their participation, and would generate a data basethat could be used f.o analyze effects across sites and programs. Thisbattery of instruments would then be administered by prime sporsors as part of the routine requirements that accompany YEDPA-funded demonstra- tion projects.The results would be collected, compiled, and analyzedby ETS, but also made available to others for special studiel. 351 321By most estimates, the SAS was less than a complete success. Oneproblem had to do with conflicting expectations about its use. \"Peoplegot very confused about the purpose of the SAS,\" said CEIS's AndrewHahn.\"ETS was never intended to be the evaluator. The idea was tocreate a large data base and make ETS the repository.\" But because ETSwas cast in the role of developing the SAS, explaining it to programadministrators, and collecting data, it became identified as anevaluator, whether that was its role or not.This led to a second problem, which was conflict between ETS andprogram operators over the use of the SAS. \"Program people hated it,\"Hahn recalls, \"and it was very difficult to get their cooperation inadministering it.\" A third problem was ETS's lack of experience vriththe employment and training system, a problem it shared with a numberof other educational organizations that got involved in YEDPA projects.Schools are relatively acclimated to periodic testing, even thoughprincipals and teachers resist it. They are also accustomed to ETS asa prominent institution in the testing field. Most delivery-levelorganizations in the employment and training system had had little orno experience with testing and saw no particular reason to cooperate.ETS's experience did little to prepare it for these practical problems.A final problem was disagreement over the design and content of thesurvey.In retrospect, a number of people saw gaps in the data and inETS's analysis of it, but those gaps were not clear when initialdesigns were presented and approved. Taggart explains, \"I delegatedthe design of the SAS internally and never reviewed the actual contentof the instruments before they went out. That was about the only thingI didn't review in detail. When the first results came back, I wentthrough the ceiling--they were not what we needed at all--and read theriot act to the staff and ETS. From that point on, we had a constantbattle to try and turn it around.\" Constituency Support Constituency support projects were designed to make good onCongress's expectation that client grou.s, community-based organiza-tions, and intergovernmental constituencies would be involved andconsulted in the implementation of YEDPA programs. The mayorcounties', and governors' associations were important in maintainingany political support for any future youth employment activities, sincethey were the host governments for CETA prime sponsors. In addition,they had a strong incentive to resist separation of youth programs forother employment and training activities, because they constituted a\"recategorization\" of CETA and a retreat on the initial broad grant ofdiscretion that accompanied CETA. Putting these organizations to workidentifying exemplary youth programs in their jurisdictions, even if itdid not produce much in the way of research, was a useful way of givingthem some ownership in YEDPA.Constituency and client groups, like the Urban League and SER, werekey to development of a youth employment system in two respects. Theywere the national interest groups for their local community organize- 352 322 tions and therefore wielded some political influence in Washington. Inaddition, though, their local organizations were often the onlylegitimate route of entry into the minority community. Where primesponsors an- local school systems were identified with the dominantlocal political system, community-based organizations were an importantalternative way of tiaching communities that might not be well connectedto that system. None of the constituency support projects wasdistinguished for its research and davelopment value, but theirpolitical value was apparent.For Taggart (1980:10), the payoff for investing in constituencysupport lay more in the creation and management of a delivery systemthan in the research it generated: Rather than passively reacting to the pressure of interestgroups, an active and conscious involvement strategy wasadopted from the outset which sought to identify the completerange of institutions that could and should be involved, theirareas of possible comparative advantage and interest, and thento utilize these institutions in structured demonstrationprojects where their effectiveness could be tested. Theknowledge development plan was, in a sense, a protectivesystem; to get funding, institutions had to adapt to the designand structure of demonstration approaches. The overlay ofresearch requirements and outside evaluation agents was adisciplining force, serving a monitoring and managementfunction which would not otherwise have been possible givenlimited staffing in the Office of Youth Programs.The range of project3 described in Table 7, as wide as it is,constitutes only a very small sample of the total universe of activitiesfunded under YEDPA discretionary authority. Hence, it does not, byitself, give a complete picture of either the variety of projects orthe complexity of the organization and management problems confrontedby Taggart and the OYP staff. The selection of 27 projects in Table 7is a small fraction of the 127 projects listed as knowledge developmentactivities for fiscal 1978 and 1979. Roughly 30 OYP staff are listedas pinject monitors, but 15 of those oversaw 10; projects, which oftenamounted to an individual responsibility for $20-$30 million. Even ifthe staff had been well prepared for their research and developmentroles, their ability to attend to detailed project decisions would havebeen severely limited.It is also important to note that while discretionary funds wereused to finance knowledge development activities, they were notexclusively, or even primarily, used for research and evaluation. Infact, by DOL's estimate, 88 percent of total discretionary funds wasspent on employment and training services, 3.3 percent on basicresearch, .6 percent on evaluation of regular programs, 5.3 percent onevaluation of demonstration projects, A 2.8 percent on technicalassistance to program operators. About 30 percent of discretionaryfunds, outside YIEPP, was directed through other agencies of thefederal government to interagency projects. Close to 78 percent of 353 323discretionary funds was allocated to prime sponsors, 18 percent directlyto community-based organizations, and 6 percent to an assortment ofother organizations, including schools and private employers (DOL,)980b; also DOL, 1981).The message these figures drive home is that, regardless of howimportant research and evaluation were to the mission of knowledgedevelopment, service delivery was the main activity performed withdiscretionary money and the organizations performing that servicedelivery were not, by their nature, sympathetic to research andevaluation.Organization and management problems were not limited just to theorganizational alliances spawned by discretionary funding. There wereat least two other spheres that demanded active and continuous atten-tion.One of these spheres was the CETA delivery system, representedby prime sponsors and their local contractors. The other was whatmight be called the \"policy system,\" composed of actors outside OYP whowere consumers of knowledge development products, some of whom wereinvolved in developing the administration's youth employment proposal. The CETA Delivery SystemThe CETA delivery system was both the operating base for most YEDPAactivities and the major source of practical implementation problemsfaced in the knowledge development process. It would have been pos-sible, at least in theory, to run demonstration projects outside theCETA system, by creating \"hot-house\" projects designed, run, andevaluated by researchers. This approach was antithetical to both thelegislative charge that accompanied YEDPA and to maggart's strategy forusing knowledge development as a management tool. By insisting thatthe knowledge development process be run through the existing deliverysystem, Congress and OYP achieved a degree of involvement and practicalexperience that would otherwise have been impossible, but they alsobought all the political and administrative problems that accompanythat system.Prime sponsors represented units of local government; the adminis-trators of local prime sponsors, as well as their local constituentorganizations, were a political force in their communities and inCongress.When knowledge development imposed demands on local primesponsors that they considered to be unreasonable, and when OYP refusedto concede, prime sponsors had alternative routes of political accessthrough which to get the results they wanted. Erik Butler, a formeradministrator of youth programs in Boston and later executive directorof the Vice Prestdent's Task Force on Youth Employment said, \"When MDRCcame to talk tc us about the Entitlement project, they were talkingresearch, while we were talking program. The issue was how to accom-modate their interests and ours.\" Marion Pines, a nationally visibleemployment and training administrator from Baltimore, took her com-plaints about the reporting and administrative demands of the entitle-ment project directly to Congress, making a plea for more local controlover design decisions. This tension between national objectives and 354 324local political and administrative realities was played out in a numberof settings on a number of issues.Taggart cites OYP's attempt to improve the Summer Youth EmploymentProgram (SYEP) as one of his most illuminating confrontations with theCETA delivery system. \"Summer Enrichment,\" as it came to be known, wasan important component of Taggart's strategy for using knowledgedevelopment to influence the quality of youth programs. As is clearfrom Tables 2 and 3, SYEP accounted (and still does) for a largeproportion of both outlays and participants in federal youth employmentprograms.Since the mid-1960s, it had come to be regarded cynically bypoliticians and administrators largely as an income support program or,in the language of the street, \"fire insurance.\"Taggart's approach was to focus on developing better jobs for thesummer program and adding an educational component. \"In the firstround, we tried to rewrite the program requirements to include bettermonitoring of jobs and an education component, assuming that if weasked for them and made it explicit in evaluation requirements we wouldget it.We completely misjudged the capacity of prime sponsors. Whatwe discovered was that there was rot at the bottom of the pyramid. Theproblem was bad management; they wouldn't have known how to do it evenif they had wanted to. So we put some discretionary money behind it,got some intermediaries involved in creating and implementing programs,and focused on the problem of poor managem at the local level. Overtime, we began to see results. But the problem was that we wasted ayear finding out that the delivery system couldn't respond to thedemands we were putting on it.\"The problem of local management capacity also surfaced in a YIEPP,where MDRC was required to make heavy demands on local prime sponsorsto implement a specialized information system to track entitlementparticipants, and in the implementation of the Standard AssessmentSystem, where prime sponsors and other administrators of discretionaryprojects often balked at the additional eff.:t required to administerthe complex battery of instruments. Taggart's approach to both thepolitical entrepreneurship and management capacity problems was to relyheavily on external support staff and intermediaries both to buffer OYPfrom political pressure and to deliver much-needed advice. The Policy SystemThe policy system posed another set of problems. Taggart'sstrategy of creating an extensive network of external organizationalalliances also meant that it had to be consulted, reinforced, andaccommodated.The major problem with asking for advice from yourconstituents, of course, is that you often get it. And, more oftenthan not, it comes in the form of contradictory messages.Tne most prominent example of consultation was the conference heldin October 1978, convened by the Brandeis center, at Reston, Virginia.The conference occurred early in the development of the knowledgedevelopment process, a year after the passage of YEDPA. Its nominalpurpose was to bring the research and development organizations 355 325involved in the process together to discuss common methodologicalproblems and to develop a familiarity with the overall objectives ofthe process.As one might expect, the conference turned out to be arallection of distinct presentations on specific projects, followed bydiscussions in which participants argued positions based as much ontheir institutional and methodological biases as on their interest inknowledge development.Arnold Packer, DOL assi Cant secretary for policy evaluation andresearch, commenting on a presentation of the entitlement researchdesign, argued, \"We must be sure when we're spending the public's moneythat we have a scientifically solid approach and the ability to acceptor reject specific hypotheses which are recogrOzed as the ones that areimplicit in what policy makers are doing and thinking about in suchprograms.\"Policy relevance and methodological rigor, it seems, wereequally important. But so was timeliness. \"Will the results beavailable by the time legislation must be drafted next year?\" Packerasked.\"January 1980 is the scheduled date for submitting administra-tive recommendations. When the ouck.4c goes up a year from this January,if we are going to ask for any money to continue youth programs, t'legislation has got to accompany the budget\" (DOL, 1980e:25). HowMDRC, local entitlement projects, and OYP were to accommodate to thisschedule was their problem, not the problem of the administration'spolicy planners.John Palmer, an employment specialist from the BrookingsInstitution, took advantage of the occasion to counsel moderation onmethodological questions. Commenting on YETP discretionary projects,he said, \"Some of the discussion seems to suggest that we're going tobe able to vary components or individual elements of these programstructures and see what difference it makes. I'm dubious 'chat that'sgoing to be possible in most cases. I just don't think that themethodology or the resources that are being brought to bear are goingto permit that to happen. You're just not going to get effectiveanswers to those questions in the strict research sense.You're goingto get important answers out of the more qualitative analyses that arebeing done and from the hunches that have been made.\"Palmer continued by counseling attention to what he called \"firstorder questions,\" such as, \"Was it feasible simply to mount and executethe program under the design conditions we are trying to accomplish?Who is being served? Are we reaching the target population? Is itworking, in some sense, at that level?\" (DOL, 1980e:56). These ques-tions were several notches below those considered important by otherparticipants.Donald Nichols, an ASPER staff member, took strong exception to thelack of methodological rigor he observed in many knowledge developmentprojects.\"I want to emphasize the need for consistency across thesevarious programs,\" h2 argued. \"We want to strive to bring about somekind of consistency, so that we can not only make comparisons withineach oA, these projects, but so we'll also be able to make pretty good comparisons of one approach against another.\" He continued, \"A featurecommon to most of the demonstrations being discussed ... is that theyare not experiments with random assignment (to) groups and the like. 356 326They lack the pure classical experimental approach in that all theresults are hedged ahead of tine. Some of the researchers sound agreat deal more like advocates rather than scientists. It may well bethat advocates run better prrgrams ... but it's probably not a goodmodel for getting research results on something you might think youcould replicate on a large scale\" (DOL, 1980e:53).Vernon Briggs, from the Cornell Labor and Industrial Relationsfaculty, issued a rebuttal. \"I feel we're missing what is perhaps thegreatest contribu- of these programs in the discussion overclassical research ,ign.It seems to me that the major overridingfocus behind ali this is changing imstitutions in desired directions.\"He continued, \"I think, when you consider the whole range of employmenttraining programeA, the results of the research and the demonstrationsare used by a number of different actors and, depending on where thoseactors sit, they have different agendas. I would go as far as to saythat I think that a laical legislator would probably think more interms of whether eurvices are actually delivered than in terms :As..otle assessment of impacts\" (DOL, 1980e:60-61).Othello Foulard, director of the Cen,ar for Community Chance, bas.in Washington, D.C., delivered an even more fundamental critique ofrigorous rese7-oh. \"As a practitioner, I car say there isn't that muchmystery, as might be suggested, with further discoveries in uncoveredtLith.I wish that were the problem. It would be eas: if theaccumulation of a few more facts would provide the remedy. But theresidual of so many basic societal patterns and attitrdes, politicalstance. and the like, seem to be so obviously at the ,_tart of thematter. ...I wish there could be 'advocate' research. I don'tthink that bastardizes research at all. It teiners it. It is toorisky, too hazardous to just assume that it is appropriate let alonejudicious, to take the pure researchers' approach. If the attitudebehind the process is one tnat is devoid of passion and commitment,that is not a virtue\" (DOL, 1980e:61-62).One of the more impassioned versions of this argument is made byRobert Schrank of the Ford Foundation. \"Large sums of money have beenallocated for massive quantitative eveuation effort,\" he argued, \"butno one is asking what the pitfalls of auch research might be, orwhether it is even appropriate to what we are trying to study.\" Heoontinued,The object of the research is a network of youth programs,\"not the production of research results. If research focuses attentionon measurable results, at the expense of producing long-term effects oninstitutions, he argued, the objective social science research modelmay turn out to be more of a burden than a beacon for policymakers.\"He went on to note \"a terrible tension between doing objective evalua-tion rnd trying to make a program succeed\" that worked against long-term solutions and in favor of short-term results. He also observedthat one effect of doing evaluations of War on Poverty programs thatwere not effectively institutionalized was to reinforce the notionsthatthe social problems we were attempting to solve were intractable,\"rathar than the right solutions hadr't been tried (DOL, 1980e:36-40).In essence, then, w'len Taggart consulted his policy researchconstituency for advice about how to do knowledge development, he got 3 5 7 327back a faithful representation of the prevailing disagreements withinthat cons'-ituency over the resthoC3, content, uses, and practicalconsequences of policy research, which were outlined at the beginningof this paper. The-e was pressure for timely results that would informpolicy, but little understanding of what policy makers actually wantedto know and 7ess appreciation for how long it would take to find out.There was pressure for methodological rigor, but no agreement onwhether there were treatments that were compatible with the experimentalmodel or whether experimentation was compatible with the commitmentnecessary to make programs work. There was advice to stick to thebusiness of research and avoid the pitfalls of advocacy, but no adviceabout how to mount programs in a complex political and administrativesetting without advocacy. There was counsel to respect the tension,between dispassionate research and commitment to particular programs,but no concrete organizational solutions for how that tension could beresolved.There was advice about the dangers that accompany prematuretests of program effects, but no clear understanding of when newprograms should be evaluated.No doubt, the participants in the Reston conferenoo believed theyhad delivered a clear message to Taggart about the direction knowledgedevelopment should take. The overall effect, though, was to reproducethe general lack of agreement and to strengthen Taggart's resolve inpursuing the strategy he had chosen. For all its defects, Taggart'sstrategy at least had tentative solutions to the problems of large- scale policy research.A far more serious set of policy system problems was posed by theVice President's Task Force on Youth Employment. As noted above,sometime in the fall of 1978, the administration seized on youthemployment as its major social policy issue for the 1980 campaign,having run into difficulty with welfare reform. The Task Force was asambitious a policy development exercise as ever takes place in thefederal government. It involved a significant central staff, led firstby Torn Glynn, former director of planning and budget for ACTION, andlater by Erik Butler, a director of youth programs from Boston and aresearcher/practitioner at Brandeis.The Task Ford drew on the policy staff of t-e Domestic Council,including Bill Spring and Kitty Hirgins, a DOL staff member on detailto the White House, and on outside consultants, including PeterWelman, former director of youth services for New York State.Itinvolved extensive interagency consultations between the Departments of Education and Labor. It served as the locus for wide consultationsaround the country with business, labor, education, and employmentleaders and practitioners. And it resulted in the presentation of amajor piece of legislation to the Congress in January 1980.The TaskForce's budget, amounting to $1,027,485 over fiscal 1978 and 1979, wasfinanced from YEDPA diseretioaary funds (DOL, 1980b).Aside from the fret that the Task Force was funded from his budget,Taggart and OYP had larger interest in its work. If the President'sproposal nr.sed Congress, it would set the structure of youth programs for the foreseeable future. Taggart saw the longer-run etakes of theTask force's work and focuLA a large amount of his energy, between 358 328early 1979 and January 1980, on drafting the DOL side of the proposal.In doing so, he attempted to draw whatever lessons were available fromthe first year's experience with YEDPA and from the conventional wisdomemerging from sustained attention to the problem of youth employment.From Taggart's review he deduced a few relatively straightforwardprinciples that were to shape both the administration's youthinitiative and sutzequent changes in federal employment and trainingpolicy.In part, these principles were as follows (DOL, 1980a:86-93): Standards.Everyone involved in the employment trainingenterprise should be held to mutually agreed, self-imposed standards,or benchmarks, of performance. Trainees who do not meet performanceexpectatiws should be moved out of programs to make room for those whoare willing to try. Employers should be willing to provide structuredand demanding activities in the workplace. Training organizationsshould be willing to set performance standards for themselves and theirclients.Sequenced Activities. Programs should begin at the level ofcompetence of entering trainees and should follow a sequence ofstructured steps designed to move trainees into unsubsidized employment.Targeted Resources. Funding formulas and administrativedecisions should reflect the difference between high-cost, intensiveservices for high-risk youths and low-cost, less-intensive\"transitional\" services for more mainstream youths. The highestpriority sh \"*ld be highly targeted, concentrated programs for theneediest.Consolidated Programs. The array of categorical youthprograms initiated by YEDPA should be consolidated into a singleprogram structure.Employment-Education Collaboration. The early efforts atbetter coordination between prime sponsors and local educationalsystems did not produce widespread changes, but the objective is animportant one for federal policy.Institutional Comparative Advantage. Some organizations,notably community-based organizations, have a comparatve advanimge inreaching high-risk youths, although they vary widely in capacity todeliver services. Their role snould be strengthened.Local Accountability. The federal program structure shouldencourage attention to measurable, quantitative outcomes, rather thanto implementing complex regulations on program content. Other, more specific, lessons emerged from reviews of the preliminaryYEDPA evidence performed by Erik Butler and Jim Darr (Butler and Darr,1979).These lessons focused on a review of program-by-programresults, but generally followed the same themes.In short, the Task Force and the administration's youth initiativeforced a telescoping of the larger knowledge development process into ashort period.Many of the longer-term institutional development andresearch objectives, while they continued to be important within OYP,were pushed aside in the policy-making arera in the interest ofdeveloping an administration proposal. 359 329If the the Carter youth initiative had passed Congress, and ifCarter had won reelection in 1980, the knowledge development processmight have continued to pursue the longer-term institutional develop-ment, and the research objectives it contained might have receivedattention.But these things didn't happen. The Carter youthinitiative passed the House in August 1980, but failed to reach the floor in the Senate. Carter lost his reelection bid. In the early months of the Reagan administration, federal employment and trainingpolicy underwent a major change, including the elimination of mostYEDPA programs, with the passage of the Job Training Partnership Act. The Demise of Knowledge DevelopmentLong before the introduction of the Carter youth initiative, though,there was evidence that the knowledge development process was beginningto come apart in certain critical ways.First, the organizationalnetwork created at the beginning of the program began to requiremanagement from the center that OYP was hard-pressed to provide.Inthe words of a IDOL observer, \"It was one thing to get all thosecontracts negotiated, written, and signed in the first place, and quiteanother to deal with the problems that surfaced when the organizationsstarted to have problems, not to mention turning the whole system overwhen the contracts needed to be renewed or terminated.\"Second, the politics around the Vice President's Task Force beganto take its toll on Taggart, politically and physically. By early 1980, it had become clear that youth employment was the only game intown for those interested in affecting domestic policy. With theelection approaching, activity around the administration's proposal became feverish. There were predictable tensions between the TaskForce and Taggart over details of the administration's proposal and themechanics of assembling it. Taggart worked around the clock for monthsdrafting a proposal and selling it within the administration. At one point before the administration's proposal had been sent to Congress,one participant remembered, \"When Taggart's recommendations weren'tincorporated fully into the administration bill, he circulated his own version around town and on the Hill. This, needless to say, did notendear him to the Task Force people.\" In the end, the employmentprovisions of the administration's proposal werr largely determined by Taggart.But the costs of this political manuenering were reckoned inthe loss of sustained attention to the management of the knowledge development process.The unraveling of the knowledge development process began in March1980, when Taggart resigned his position as OYP administrator. After leaving OYP, Taggart worked independently, with foundation funding,assembling research results on employment and training programs. Hethen established the Remediation and Training Institute, a privatenonprofit organization, again with foundation funding to provideassistance to local employment and training operators.Taggart wasreplaced by Tim Barnicle, a regional DOL administrator from Boston,from March 1980 to January 1981. After that, OYP was run in the early 360 330months of 1981 by Richard Gililand, a former DOL regional adminis-trator, who was transferred to the job by the then Assistant Secretaryfor Employment and Training, Albert Angrisani. After the passage ofthe JTPA, OYP was disbanded. Some of its staff were reassigned tovarious other parts of the agency, some left the department in a seriesof reductions in force, and \"knowledge development\" ceased to exist.Though the activity called knowledge development ceased to exist,many of the contracts negotiated as part of the knowledge developmentstrategy were still outstanding. Some contracts extended into 1982.In an effort to bring some order and closure to these contracts, theBrandeis Center, in late 1981, compiled a list of unfinished projects,along with recommendations for their disposition. They identifiedabout 120 incomplete discretionary projects, of which all but a fewrequired additional DOL action to close them out. They also examineddata collection activities under ETS's Standard Assessment System, andfound 20 of 48 sites in which data were incomplete.The posture of Reagan appointees in the Department of Labor towardthese unfinished projects, by most accounts, ranged from indifferenceto outright hostility. when the new administration arrived,\" oneinsider recalled, \"an immediate freeze was put on all time extensionsand refundings of the ongoing research efforts. They wouldn't even letthe entitlement research be completed until an editorial appeared inthe Washington Post that created a Congressional uproar. It is in thenature of research that repeated time extensions and some cost overrunsoccur.By systematically refusing extensions and (by) disbanding theyouth office, most research was halted in its tracks. Without aprogram officer to follow up for final reports and without timeextensions, even where new funds were not required, and without anyhope of new research money cominc, from the department lots of thesecommi.ted academics just went off in search of other grants. Othersdidn't have the funds to analyze the data they had collected. ...\"No one ever bothered to follow up. In fact, the atmosphere wasvery hostile to research and other discretionary projects. We wereinstructed to call grantees and tell them they couldn't publish papersunless the department cleared them. Such an instruc \"ion contradictedthe actual language encouraging publication in the grants themselves.\"A career DOL employee with extensive experience in evaluationobserved that after the change in administrations the contracts were\"technically\" administered, \"but no longer with knowledgeable staff or..ny sense of high-level attention.\" Andrew Hahn, from Brandeis, ismore pointed:\"Our posture was that the taxpayers had already paid forthe research and they should have the benefit of the results. We triedto lay out what was necessary to close it (knowledge development) offwith the best results possible. It became clear, though, that finishingwas not a high priority.\" The Reagan administration's interest indissociating itself from the program of an earlier administration wasstandable.Its means (4 dissociating itself so was less under-s .ndable to people with a strong interest in research and evaluation.The demise of knowledge development, then, was a compound ni manage-ment and politics. The management problems stemmed directly Lcomstrategic decisions about the purposes of knowledge development and the 36i 331organizational form necessa,v to carry out those purposes. Knowledgedevelopment began to come apart organizationally when the problems ofconglomerate organization became clear and no solutions were forthcomingfrom 'Laggart and his staff. The complex system of intermediaries,external staff, intraagency and interagency agreements was predicatedon the accurate assumption that OYP, by itself, could not manage anenterprise of the scale required.The system was a way of dispersing responsibilities among a varietyof organizations, while at the same time maintaining a central agenda.Taggart could, in the early stages, by sheer force of personality andintellectual energy, give this system some coherence through his use ofresearch as a management tool. l'ae chief vulnerability of CUE: kind ofsystem, though, is that when the constituent parts begin to haveproblems, the center is ill equipped to solve them. And when thecenter becomes overloaded, as it did, with the problems of theconstituent parts and with external pressures of the policy agenda, thesystem begins to shake itself apart into individual projects. Thecenter depends on the constituent pieces to make the system work. ButOYP was not able to generate enough capacity in itr constituent piecesfast enough, or uniformly enough, to relieve pressure on the center.The political causes of the demise of knowledge development lie,ironically, in the closa connection between research and policy.Congress, or at least the House, expected useful answers to thequestion \"What works for whom?\" in time for the CETA reauthorization in1978.The Carter administration, when it finally turned its attentionto youth employment, expected support for a new domestic initiative.Taggart's research, program, and policy constituencies expectedmethodolocvi.cal rigor, sensitivity t- administrative constraints, andfirm answers to policy questions.How the contradictions among the..e demands were to be reconciledwas a problem his constituents happily left to Taggart. From thebeginning, knowledge development was expected to inform policy--earlyand often.It was not to be a long-distance run with a single finishon some remote horizon; it was to be a series of sprints with thefinish lines dictated by political landmarks. Taggart did little todiscourage, and much to encourage, this view; it reflected his ownbelief in the active relationship among policy, program management, andresearch.The consequences of this close connection between policy andresearch, however, were twofold. First, as the 1980 electionapproached, the demands of managing the conglomerate were overwhelmedby the demands of policy making. It wasn't enough for Taggart to focuson making an unwieldy organization work; he had also to focus oninfluencing administration policy. Second, when the political agendashifted, with the election of Ronald Reagan, the ground was cut fromunder the program. INFLUENCE ON POLICY AND PRACTICEDespite the unfinished work, and the ignominious end, the knowledgedevelopment process generated a larfle volume of research on the subject 362 332. of youth employment. One tangible proof of this output is the pub-lished collection of knowledge development reports, begun beforeTaggart left and continued through 1980, which contain the planningdocuments, evaluations, and basic research reports completed before1981.The complete collection comprises more than 70 reports, from 100to 400 pages, color coded by topic, in the form they were received asfinal products from research contractors, with short introductionsexplaining how their content relates to the overall set of questionsaround which the knowledge development process was designed. The ideabehind this method of dissemination was to make as much of theknowledge development research quickly available to Policy makers,policy analysts, researchers, and practitioners as possible and tosynthesize it later. CEIS, at Brandeis, was to play the role ofpulling the pieces together around common themes. Because of theabrupt way the process was terminated, the product of the federalinvestment became those undigested reports, and the Brandeis synthesiscontinued later under private funding.OYP began mailing the reports to potential consumers in mid-1980.In some quarters, notably Capitol Hill, this approach had the oppositeof its intended effect. Some people, it appears, preferred theirresearch in smaller bites. Nat Semple, former House minority staffmember, said facetiously, \"We came to one morning and they backed adumptruck up to the building and unloaded a ton of reports. The stuffjust wasn't useful.\"The same people who ridicule the way the knowledge developmentreports were disseminated, however, are generally complimentary of thebackground materials and \"lessons from experience\" papers that accom-panied the Carter administration's youth initiative. These summariesof the first two years of knowledge development were, in the view ofHill staff, written in language understandable to legislators,addressed to issues considered impc tent on the Hill, and generallyresponsive to questions that arose in consideration of the youthinitiative.Reinforcing this perception from the Hill is the perception ofthose who workee on the Carter youth initiative. Domestic Policy Staffmember Bill Spring argues, \"I think there is broad agreement amongthose of us who worked in the White House that the Youth Initiative wasprobably the best-rLa policy-making exercise in the Carter years. Itgot the right inforr'ation to the right people, it 7ed the educationfolks to talk to the employment and training folks t forged a broadconsensus on 114w to get at an :aportant problem. 1,,u have to say thatnone of that would have ,een done in the same way without the knowledgedevelopment process to back it up.\"Most of the supporting documents for the youth initiative would notbe considered \"research,\" in the strictest sense of that term, althoughthey were often couched in the language of \"what works.\" They moreoften took the form of recommended standards, criteria, fundingmechanisms, and institutional arrangements emerging from practicalexperience.Around these operational issues, a consensu:J began toemerge in about 1980 that spans partisan loyalties and institutionalaffiliations.This consensus has had a significant influence on -1.363 333federal policy. It forms the basis for much of the statutory languageand administrative structure surrounding the Joint Training PartnershipAct (JTPA).Robert Gutman, the Senate majority staff member who tookthe leading role in drafting JTPA, was also involved in the drafting ofYEDPA and in discussions rf the Carter youth initiative, in which thesame issues surfaced. A wide range of people, from Taggart to theBrandeis staff to the Vice President's Task Force staff to congressionalstaff, claim credit for influencing the content of JTPA. This consensusis an important indication that YEDPA and its attendant policyactivities created an occasion for rethinking the legislative andadministrative structure surrounding federal youth employment programs.This consensus has been described in a number of ways in a varietyof documents (Taggart, 1981; Hahn and Lerman, 1983; National Council onEmployment Policy, 1983, n.d.), but it includes at least the followingbasic elements:Focus on High-Risk Youths. Limited federal resources, theindeterminacy of aggregate unemployment statistics for youths, and theseriousness of the problems faced by economically disadvantaged highschool dropouts all argue for a strategy more highly focused on whatTaggart callsthe leftovers\"--young people excluded from conventionalroutes to education and employment.Deemphasize Income Maintenance, Emphasize Employment. Employ-ment programs should have employment objectives, income maintenanceprograms, and income maintenance objectives. Training stipends andwage subsidies s,ould be set to encourage unsubsidized employment andreward performance, rather than to provide income.Deemphasize Work Experience, Emphasize Basic Skills and JobTraining.Work experience should no longer be used as the catch-allsolution for the unemp:oyed. It seldom leads to longer-term employmentunless it is linked in some systematic way to education and training.Use Individualized and Sequenced Programs. Many of thefailures of employment and training programs stem from mismatchesbetween the competencies of the trainees and the content of theprograms.Programs should be designed to provide basic education,training, and job entry in a sequence and combination that matches theindividual's requirements, with intermediate benchmarks to gaue:;eperformance along the way.Require Performance Standards for both Individuals andPrograms.Employment is the expected outcome of employment programs,therefore people in the employment and training system should beevaluated and rewarded on the basis of their performance in securinglong-term, unsubsidized employment. Intermediate benchmarks areimportant, but employment outcomes are essential.Reward Performers. The absence of positive rewards for bothindividuals and program operators leads to a focus on the lowest commondenominator of participants. Programs should select from the mostdisadavantaged and reward those who succeed in meeting enpectations.Use Mainstream Institutions. The isolation of education andtraining for the disadvantaged from mainstream institutions, especiallyemployers, compounds problems of access. Heavier reliance onapprenticeships and employer-based training decreases barriers to entry. 364 334Invest in Capacity. The tnployment and training system hasbeen among the most unstable of domestic service systems. It needs astable base of federal support and a professional constituency to doits job.Incremental Expansion. The employment and training system hasbeen buffeted by a series of dramatic shifts in policy since it wasestablished.New policies should be allowed to mature and developbefore they are dramatically altered.None of these principles seems particularly revolutionary, norparticularly \"scientific\" or counter-intuitive for that matter. Butmeasured by the distr-ce between the conventional wisdom of 1976 andthat of 1985, rather taan the tenets of social science method, theyconstitute a profound shift. This shift is attributable largely to thefact that YEDPA focused the attention of researchers, practitioners,and policy makers for a time on connecting practice with policy.Another indication of the influence of knowledge development is thegeneral perception among policy staff and their bosses that the YIEPPdemonstration, the largest and most visible of the knowledge developmentactivities, was successful. Most staff cite the findings of the MDRCreports on entitlement as evidence that well-designed and well-managedprograms can have an impact on high-risk youths, that despite start-updifficulties in some settings it is possible to mount a program basedon the entitlement principle, that requiring youths to manifest certaincommitments and competencies as a condition of support is workable, andthat educational institutions must modify their programs to make theentitlement principle pork.The fact that the entitlement demonstration did not lead to afull-scale national program, is not troubling to most insiders. NatSemple, the staff person who had probably a larger s in theentitlement demonstration than most, says, The poli' teal realities of1981 were that you weren't going to get anything through Congress withthe word \"entitlement\" in it. Also, there was one serious design flawin the entitlement program that required attention: the fact that whenthe subsidy ran out, a lot of employers just gave kids pink slips. Thedemonstration, thoush, had effects well beyond the evaluation. Itlegitimized the idea that standards were fair and effective.\"Another view o. the influence of knowledge development comes fromthe Brandeis staff, who remain the single repository of knowledgedevelopment products, the main synthesizers of that evidence, and oneof the few organizations created by that process that still exist.Andrew Hahn describes the influence this way. \"Before YEDPA andknowledge development people who worked in the youth employment :ieldbasically had no common professional identity. One effect of knowledgedevelopment was to put a large infusion of resources behind thecreation of a professional constituency for youth programs. That isthe first step in raising the standards in the field to the pointwhere, as in education, you can start to expect people to performeffectively.\"Branuais's current, privately funded work is trainingand technical assistance for youth practitioners; the network they useto deliver these services is constructed from people and organizationsinvolved in YEDPA and the knowledge development effort. 365 335Taggart takes yet another view of the influence of knowledgedevelopment.By 1979-1980, he had evolved a longer-run strategy forusing research and technical assistance to raise the quality of youthemployment programs, consistent with his pessimism about the ability ofpractitioners to discover more effective techniques by themselves.Theidea was that the evaluations of discretionary knowledge developmentprojects and the activities of intermediaries would produce a list ofdiscrete program options. Taggart uses the term \"cookie cutterprograms\" to describe these options. Different settings kould requiredifferent combinations of options, given their youth populations, mixof organizations, and employment problems. The intermediaries wouldfunction as technical assistance agents, under contract with localities,to deliver pieces of a program.With the demise of the network of organizations created by theknowledge development process, this mechanism failed to materialize.But Taggart's own activities now focus on the use of computer technologyto construct education and training programs for high-risk youths from the available body of packaged curricula. Among his clients are local councils created under JTPA.Against this relatively sanguine view of the influence of knowledgedevelopment is arrayed a more pessimistic view, which takes its pointof departure from assessments of the methodological quality of knowledgedevelopment activities and their payoff in terms of scientificallyverifiable results. Michael Borus, a researcher from Rutgers hasreviewed research on employment programs for high-risk youths, includingthe Neighborhood Youth Corps, the Job Corps, and a number of discretion-ary knowledge development projects under YEDPA. He found seriousmethodological flaws in most iupact evaluations of these programs- -including low response rates, lack of adequate comparison groups, andrudimentary development of treatments--and little evidence, outside of Job Corps, of positive effects.He concludes that no progress has been made in creating effectiveprograms, and that, because of a lack of methodological and substantivesophistication, policy makers and program administrators continue tomake the same mistakes with each new initiative. His recommendedsolutions include evaluating only fully implemented programs and using\"true experimental designs,\" carefully designed and implemented datacollection instruments, benefit-cost analyses of program effects, andplanned variations in program design (Bo us, 1984).Between the sanguine view of policy- and program-orientedresearchers, on the nma hand, and the unrelenting skepticism of theacademic research community, c41 the other, lies a vast gulf ofmisunderstanding, disagreement, and conflict over what constitutes'useful\" knowledge. For policy staff and program-oriented researchers,knowledge is useful when it helps to solve immediate problems thatlegislators, administrators, and practitioners think need solving.Knowledge comes in many forms--logic, insight, operating skill,political intelligence, and empathy, to name a few--only one of which i' social science research. Creating new knowledge depends on a priorinvestment in programs and institutions to deliver them. Research methods are only useful insofar as they are instrumental in solving 366 336problems; when they get in the way of institution building and problemsolving, they should be modified. For the social scientists, knowledgeis useful only when it can be verified and replicated with known levelsof certainty.Methodological rigor is a prior condition for any usefulknowledge.Problem solvin', whether in policy or in practice, ismeaningless unless it involves the systematic accumulation of replicableresearch over time.As notes at the outset of this paper, these disagreements have beenrehearsed with monotonous regularity in virtually every large-scalepolicy research effort since the 1960s, with only a modest recognitionof the common ground between the two views. The arguments are compli-cated by ominous attributions, on both sides, of political agendas andpersonal ambitions. Policy and program enthusiasts are accused bysocial science researchers of \"advocacy\" (as if it were possibly to bean effective practitioner without being an advocate) an6 of usingpublic funds to further private ,.lendas (as if social scientists didnot benefit from doing research on program ineffectiveness). Socialscientists are accused by policy and program advocates of beingchronically in opposition to whatever the prevailing conventionalwisdom is and of putting their own peculiar tools of the trade ahead ofthe interests of regular folks (as if advocates never did the samething).These debates are inevitable, in some cases useful, and almostalways amusing. But they often do not shed much light on the largerquestions of how ;:o make judgments about the investment of the public'smoney in large-scale research and development enterprises, such as theyouth employment knowledge development effort. These larger questionsoften broach the diffuse and difficult subjects of political, organi-zational, and management strategy--subjects in which neither socialscientists nor policy advocates believe they have a comparativeadvantage.Yet, as this analysis makes clear, large-scale research anddevelopment enterprises succeed or fail based not on people's fervor,commitment, nor methodological orthodoxy, but on how skillfully theymake strategic decisions. GUIDANCE FOR THE FUTURE At the outset, I posed four broad questions raised by the youthemploy:Alt knowledge development effort: What constitutes \"useful\"knowledge? What should be the relationship between the delivery ofservices and the discovery of effects? What are the political andorganizational correlates of successful accumulation of knowledge? Andwhat payoffs should we expect from large-scale research, demonstration,and evaluation efforts? In the tentative answers to these questionslie whatever guidance the knowledge development effort has to offerfuture policy makers, administrators, and researchers. 3 6 337 Useful KnowledgeRunning through the knowledge development process is a tensionbetween knowledge acquired through social science and knowledge basedon practical insight--a tension between science and ordinary knowledge.When House members asked the Department of Labor to \"find out whatworks,\" they stated their concerns as a potpourri of questions andproblems.Some of those questions, such as how to solve structuralunemployment among young people, implied sophisticated, long-termresearch.Others--the effects of specific training and job-searchactivities, for example--implied shorter-term project evaluations.Thecongressional mandate did not take account of the vast differences inthose questions, nor the time and resources required to answer them.The questions specified by the House were, from a research perspective,exceedingly vague. They provided little guidance for what the Congress meant by \"finding out what works.\" Assuming that Congress meant rigor-ous research when it said \"find out what works\" probably overstates thesophistication of Congress's concern. Congress was more interested ingenerating a variety of Practical activities addressed to youth employ-ment than in setting the conditions for rigorous social research.On this score the House and Senate agreed. The objective was to launch awide variety of activities and see if they could survive administra-tively and politically.' In the words of a House staff member, \"findingout what works\" meant \"let a thousand flowers bloom,\" not the conduct of rigorous research.When members of Congress said \"find out what works,\" they had inmind nothing more complicated than demonstrating whether new programscould be instituted administratively and whether young people couldfind useful work in the process of participating in them. Larger, moresophisticated research questions were embedded in this basic concern,but were not central to Congress's thinking. With certain routinequalifications, the answer to the questions posed by Congress, afterthree years of research and demonstration, was \"yes.\"Knowledge of this kind is far from trivial, even though it does not meet many socialscientists' theoretical or methodological standards.Congress had other important Items on its agenda beyond finding out what works.Distributive politics--by age, by region, by constituencygroup, by federal agency, and by level of government--was Congress'smajor concern. The legislative language and history of YEDPA manifested far more attention to the distribution of money among competinginterests than it did to discovering solutions to youth unemployment.Making the CETA system more responsive to the problems of youths wasanother agenda item. By targeting youOls for special concern, Congresswas, in effect, telling the Department of Labor and the CETA systemthat they had not pa.:4 adequate attention to the problems of youths.Still another agenda item was using federal funds to make the schoolsand the employment and training system work more closely together.From the point of view of certain members, the gap between schools andCETA-funded organizations was inexcusable and should be closed.Each of these items brought with it a collection of problems thatTaggart and his staff had to solve in the implementation of YEDPA. 368 338Failing to address these items would have meant failing to respond tothe manifest concerns of Congress.One can argue that Congress was irresponsibly vague, that it failedto provide the necessary guidance in structuring a research agenda, andthat it undermined the possibility or finding out what works by loadingtoo many other items on the agenda. But these arguments all miss anessential point: Congressional action requires coalitions; coalitionpolitics requires vagueness and multiple agenda items. In someinstances, as YIEPP illustrates, the demands of coalition politics andthe demands of rigorous research are not incompatible. One cannotexpect them to be compatible in all, or even most, instances. Ordinaryknowledge of politics, in other words, should shape our sense of whatwe can feasibly expect of Congress in setting the initial conditions oflarge-scale research on social problems.Ordinary knowledge of administration also played an important rolein the knowledge development process. Federal employment and trainingprograms are administered through units of state and local goverment,which are in some senses autonomous, but which also assume the delegatedauthority of the federal government to make contracts for the deliveryof services.When a shift in policy creates new demands on that system, these.units are entitled to ask a host of practical questions about theconsequences of those demands. How should new programs be meshed withexisting delivery structures? How should the competing demand3 ofservices for youths and adults be sorted out administratively,organizationally, and politically at the local level? If localemployment training programs are supposed to be coordinated with localeducational systems, what is acceptable evidence of coordination andhow nave other jurisdictions responded to the requirement? If youngpeople are to be given clear expectations of performance as a conditionfor participation in employment programs, what constitutes satisfactoryperformance and what happens to those young people who do not meetexpectations?Again, these questions are relatively far removed from the con-ventional social science questions about Treatment A and Treatment B,but they describe knowledge that plays an important role in aldressingCongress's concerns about whether new programs can be made co workadministratively. Moreover, since the administrative structure iscomposed not just of functionaries working under contract to thefederal goverrialent, but also of governors, mayors, legislators, councilmembers, and the like- who are elected officials in their own right,these people are entitled to answers.7f we probe far enough into the administrative structure, weeventually reach the people who call employers to ask if they would bewilling) hire a young person, who teach reading, multiplication, andlong division to 18-year-old dropouts, who try to find housing for ayoung man who is sleeping in his car, and *oho try to find child carefor a young woman who is about to leave the welfare roles and startworking as an orderly in a nursing home.these people ask a different order of question. If we add anothersection to our remedial General Equivalency Diploma course, who will we 369 339get to teach it? If we are expected to get rid of kids whose attendanceand academic performance are poor, how do we keep our enrollment at ahigh enough level to meet our placement objectives? Is there a way tocombine the teaching of elementary math with training in the use ofcommon measurement tools? Is it okay to send a bright, but poor andneglected, kid to the academic program at the local community collegerather than to a job placement--will it count against our placement results?These questions are also somewhat removed from the TreatmentA versus Treatment B questions of social scientists. But if someonecannot answer these questions, it is highly unlikely that the designsset in motion by Congress will be translated into employment fordisadvantaged young people, or that the application of research methodsto employment programs will yield information useful to policy makers.What constitutes \"useful knowledge,\" then, depends on where youstand in the complex system of relationships that operates on the youth employment problem. From this premise, three conclusions follow:First, orly a small part of what the system as a whole regards asuseful knowledge meets the social scientist's definition of usefulknowledge.Second, ordinary knowledge, in the form of answers topractical questions about whether things can be done, is a preconditionfor more sophisticated forms of knowledge, like that resulting from social experiments. And third, if political and administrative systemsfail to accumulate ordinary knowledge, they will, with absolutecertainty, fail to accumulate scientific knowledge.The notion that social problem-solving r'quires the faithfulapplication of social science methods to policy decisions, then, is not so much wrong as it is incomplete. Social science deals in a kind ofknowledge that is derivative of, and dependent on, other, kinds ofknowledge.Failing to distinguish between ordinary knowledge andscientific knowledge, and failing to understand the role that ordinaryknowledge plays in the creation of scientific knowledge, is the singlelargest problem with social science in the service of policy making.As an exercise in the creation and codification of ordinary knowledge,the knowledge development process was a qualicied success--at least inthe eyes of people who regard ordinary knowledge as important.As anexercise in the application of social r-ience methods to the problem ofyouth employment, it was less suemess'...1., but by no means a complete failure.Whatever its other defects, the knowledge development process did reflect, in its design and execution, the distinction between o:dinary knowledge and scientific knowledge. Taggart observed that the applica-tion of social science methods to early YEDPA projects was \"researching ineffectuality, not intervention.\" He observed later that, for all itsdefects, the knowledge development effort produced more social scienceon employment questions than any previous federal intervention. Hisunderstandins of the limits of the existing delivery system led him totake a skeptical view of the possibilities for experimentation And tofocus on creating the prior conditions for scientific knowledge. Onthe one hand, this focus resulted in what seemed, from the point ofview of social science, a disproportionate investment in activitiesthat did not produce \"results\" in the form of clear treatment-control 3'70 340comparisons.On the other hand, the focus seems far more troubling tosocial scientists than it does to other actors in the process, includingthe Congress, which authorized the pr' to start with.At a minimum, then, it seems tht 4d-_, large-scale employmentresearch and demonstration projects. h- 1:gin with a frankacknowledgment that experimentation is 'AV final stage of some :argereffort to codify ordinary knowledge, not the first step in finding outwhat wogs.Doing research and demonstration projects involves alai,e-scale investment over a long period of time in creating aconventional wisdom, translating it into structures and beliefs andbehavior, and then (after a fashion) subjecting It to some sort ofrigorous empirical test.Beyond this minimum condition, it seems reasonable to promoteactively the notion that different levels of knowledge are required tomount large-scale research and demoustraC-71 pre-!ect', and thatresearch is only one way of gatherirr knowledge. Simpleexpedientsoften the most efiectiv..1, like practitioners' workshops,regularly ocheduled congressional visits to pilot projects, andhead-to-head discussions among administrators, practitioners, andresearchers.All of these, and more, occurred in the knowledge develop-ment process.Whether they are understood as legitimate parts ofknowledge development in retrospect is problematical. When the resultsof the knowledge development process are culle(:4 ior \"hard\" conclusionsaoout what works, these parts of the process are often lost. Delivering Services and Discovering Effects Another Impor'-nt tension running th.ough the knowledge developmentprocess is that between delivering .2ervices to constituents and tracingthe long-term benefits of those services for disadvaataged youths andfor scoiety at large. Most descriptions of YEDPA begin with thestatement that its purpose was to find out what works in gettinghigh-risk, disadvantaged youths into the labor market. As we haveseen, this is not so much an inaccurate read'ng of the intent ofCongress as it is an incomplete one. Certain members of the House hada genuine interest in finding -4 what works, but that 4nte.est wasalso rooted in d politically aL rated desire to restrain the Senate'senthusiasm for spinning out new programs. Most key Senators thoughtthey knew what to do and saw YEDPA as the vehicle for doing it. Thecompromise between the House and Senate incorporated both the ouse'stentetivity and the Senate's commitment to specific f)lutions. Moreimportant11, though, Congre.,'s charge to DOL made clear that the newresources were to be deployed to support the network of constituenciesthat had grown up around employment training programs. If DOL failedin tt' mission, tie issue of \"what works?\" would be moot, since therewould be no political constituency to support youth programs it thenext round of congressional debate. While finding out what works wasan important purpose of YEDPA, delivering services to political con-stituencies, state and local jurisdictions, employment trainingorganizations, and disad'iant -ed youths was instrumental to that 371 MIL i/M/HOM110 1341purpose.Research and development without a political constituency isof little practical use to elected policy makers.Most of the money spent on knowledge development was not spent orresearch.It was spent on providing jobs, training, and education todisadvantaged youths. Most of the decisions about ihich organizationswould rec(a YEDPA discretionary funds were not based or the provenresearch capacity of those organizations, or even the expected payoffof the fundr in research results. In fact, most organizational recipi-ents were cliosen on the basis of the constituencies they represented.Within the vast collection of projects that knowledge developmentcomprised were a limited number of projects chosen explicitly for theirresearch value--some on the basis of congressional intent, some on the basis of OYP's policy research agenda. It was in this limited array ofprojects that the research payoff of knowledge development was to occur.One can argue about whether the research agenda was well formulated,whether the rig:It projects were chosen and developed in the r!-_-ht ways,whether the proportion of constituency-based projects was too large, orwhether the right organizations were represented in the constituency-basi.ad projects. But it is difficult to argue with the fact that mostof what goes on in research and development activities of the scalertoresented b; YEDPA consists of delivering services to constituents,not doing research. It is also difficult to argue with the fact thatcreating political constituencies is an important part of t!,e processof getting from research to a change in policy.This in,:imate connection between delivering constituent servicesand disnovcring effects did not elude Congr'ss, nor did it eludeTaggart when he deployed YEDPA discret.onary money.It die, however, se mIlude many of the social scientists and policy analysts whocriticized the knowledge development effort. The confusion bet:Teen\"advocacy\" and \"research\" troubled some, as did theaggle-tagglequalivuy of the research in many of the demonstration projects.Anxious to show that social science could deliver clear, policy-relevantguidance, they failed to see that the delivery of services was drivingresearch, not vice versa.There is vicious paradox in the use of socia. science rhetoric tojustify social intervention. YEDPA AS described as an attempt to findout what works, when in fact it was an attempt to de-ever services toconstituents while at the same titre finding out what works. Becausemany people, even the politically r.sphisticated who presumably knowbetter, accept that the primary purpose was to find out what works, the\"r\"ere\" delivery of services becomes tainted. It is not enough to getthe money out to the right people and to get the right organizationsinvolved in searching for solutions to the problems of disadvantagedyouths.If the delivery of services does not add significant w'knowledge to social science, or pride solutions to the problem ofstructural unemployment, it is a failure. Anything short of significantnew social science knowledge is just pork barrel. There is nothingwrong with aspiring to signiiicant new social science knowledge, or to long-term solution to structural unemployment. The problem occurswhen, aspiring to ..3e things, we conclude that merely providing jobs,training, and education to disadvantaged youths, and merely building a 372 342professional constituency with an interest in providing those services,means that policies have failed. When this happens, the gulf betweenscience and politics widens irreparably.The fact chat we find it easy to discredit interventions thatmerely deliver services, but difficult to find scientifically validsolutions to chronic social problems, may mean that we have gotten toosophisticated in using the rhetoric of social science tL justify socialintervention.Until the \"solutions\" come along, we may simply need todo a better job of delivering services. Rather than arguing thatlarge-scale social interventions will result in solutions to chronicproblems, we may want to say that, while we are working on the chronicproblems, we intend to see that some number of disadvantaged youngpeople get access to jobs, training, and education. If we fail at themore ambitious task of finding scientifically valid solutions, we haveat least succeeded in delivering services and at creating a constituencycomn. ted to search for the solutions.In practical terms, researchers and policy makers alike shouldmoderate their use social science rhetoric to justify social inter-vention.Finding out what works, in the scientific sent , requires along-term investment in practical knowledge as well as research. Ifthat investment is not porsible, then we should not expect to findsolutions to chronic social problems. In the meantime, dierelydelivering services may the besv.. we can do. Political and Organizational CorrelatesLaurence Lynn (1981b), in his book Managing the Public's Business,argues that the alleged failures of public management are as much aresult of poorly framed policies as they are of incompetent administra-tors.The initial conditions set for public servants often make theirsuccess unlikely. There is probably no better illustration of thisargument than YEDPA. DOL was given four new youth programs to imple-ment.It was directed to expand two existing programs dramatically,and it was given a large amount of discretionary mone to find out whatworks for disadvantaged youths--all with a 1-year authorization. Theprograms were reauthorized in 1978, but by that time the Carteradministration had launched the Vice President's Task Force on YouthEmployment, with instructions to produce a new youth employment policyby the following year. The pressure mounted within the administrationto produce results that simply were not there. By 1980, as the YEDPAresearch and demonstration agenda was beginning to produce results, thepresidential election brought a reversal of the mandate under whichYEDPA was launched. Each of these events can be explained by the logicelectoral politics. Electoral politics is what makes policy researchpossible.But, against this background, it should surprise no ore thatthe results of YEDPA knowledge development fell shot of expectations.In a practical sense, there was ' ttle anyone in DOL could do tocontrol the volume or the pace of the political demands they wereoperating under. No Sectretary of Labor in his right mind would tellthe leading members of the U.S. Senate on both sides of the aisle tnat 3 73 343they should scale back their ambitions. DOL faced the oho`_ a ofparticipating in the authorization of YEDPA and sharing in the credit,or not participating and getting the program anyway. Nor would asensible secretary discourage the President from making his department'sprogram a central domestic initiative in ,Ae next campaign. There were,strictly speaking, no solutions to the problem of external derrmds onYEDPA, only adaptations. These adaptations carried a high cost, bothto the delivery system and the production of useful knowled(The political lesson from YEDPA is relatively clear, althoughprobably not very ''elpful. The scale of the enterprise was incompatiblewith the pace of external demands. A research and demonstrationeffort, without the complex structure of operating programs, could haveproduced modest, short-term results within the amount of time available.A number of new operating programs coulo have been launched, withlimited payoff in terms of new research and development. But bothdemands together were incompatible with the time and institutionalcapacity available. It is instructive that the entitlement demcnstra-tion, the one piece of the knowledge development effort that had arelatively clear mandate, a finite research agenda, and a considerableamount of institutional research capacity behind it, came the closestto meeting congressional and executive expectations. It is alsoinstructive that the Job Corps, the federal youth program with thegreatest institutional maturity, the longest history of trial and error(in both the political and experimental sense), and the most sustainedevaluation, is the example that most policy makers reach for when theytry to define successful employment policy. The more aiffuse themandate, the more complex the research agenda, and the less well-definedand mature the institutional capacf.:17 of the delivery system, the moredifficult it is to deliver services and do research on them.TLe factthat the kn-wledge development effort produced as much as it did istestimony to the ability of many people to operate under heavy expect.a-tions and unreasonable time constraints.On the organizational side, two main facts stand out: the lack ofcapacity within DOL to manage an effort of the scale required by theYEDPA mandate, and the lack of explicit consideration of organizationalalternatives to the one finally chosen. '\"he lack of capacity is asmuch a commentary on the nature of federally managed programs as it .son the qualifications of DOL/OYP staff. There were limits to how muchresearch expertioe one could expect people with essentially program-matic backgrouAls to bring to their jobs. But even with the best-qualified feder-1 staff, running a large-scale federal research anddevelopment program is an exercise in indirect management. Theprograms are administered by people whose main interest is in deliver-ing services, the research and evaluation are done by people whose maininterest is in devising and executir4 designs. The job of the federa_administrator, in this set of reiationships, is to mediate conflictinginterests and to use financial and regulatory incentives to get otherpeople to do their jobs. As Taggart can testify, this is devilishlydifficult work for which few people are equipped by experience ortraining.The more complex the system of administrative relationships,the more skill required to manage it, and the less uniform me canexpect the results to be. 374 344In otter words, \"lack of capacity\" can mean both lack of qualifiedstaff and lack of direct control. Taggart's administrative strategyfor dealing with limited capacity was to create capacity in otherorganizations and manage them from the center. It was well suited toOYP's capacity, in both senses of the term. But it had the weakness ofall such strategies--it was vulnerable t.:.) variability at the periphery.Some external alliances worked well, because they were well organizedand well staffed; others did not. If there are too many cases of thelatter, the system becomes difficult to manage from the center. Thesolutions to this problem lie either in working on a much smallerscale--an alternative not really available under YEDPA--or in gen-erating more capacity on the periphery--something that takes time to do.The lack of an explicit consideration of organizational alternativesto the one that evolved is not unusual in federal agencies. No one inthe executive branch specializes in thinking about alternative ways toorganize complicated undertakings. DOL and other executive actors withan interest in YEDPA were preoccupied with larger issues at the begin-ning of tne effort. Taggart was not the sort either to pose alter-natives or to stand back and wait while others did. He did what heconsidered necessary: he consolidated program operations, research,and evaluation in OYP. From Taggart's point of view this was the bestsolution.It is not clear, however, that it was the best solution fromthe point of view of DOL, Congress, or the executive branch. Neitheris it clear, however, that any of he alternatives for Oaspersing YEDPAauthority =long other DOL units would have worked any better. Thelesson is not that there was a better way to organize knowledge develop-ment.The lesson is, rather, that the decision of how to organize suchan effort is probably the most important high-level executive decisionthat cabinet-rank officials face. It merits careful analysis. It didnot get that analysis in this instance. Payoffs A few conclusions about the expected payoffs of large-scale researchand development efforts like YEDPA follow from this analysis. The firstis that, especially when solutions to chronic social problems involve changes in existing institutions the creation of new ones, ordina:yknowledge is a prior condition to the :reation of scientific knowledge.Administrators and practitioners need to know what to do, or what to dodifferently, in the most practical sense, before they can begin to actin systematically different gays. Legislators need to know whetherprograms can be administered and whether benefits can be delivered,before they can make j,Idgments about whether broader social problems can be solved. Social science methods, by themselves, do not deliverthis knowledge. Investing in useful knowledge, then, entails investingas much in simple information, practical intelligence, and networks ofcommunication as in research and evaluation. Second, there is aserious danger in notifying new policies on the basis that they willincrease our knowledge of how to solve chronic problems, rather thanmerely delivering services to constituencies and individuals.If the 375 345problems turn out to be resistant to social science inquiry, as theyusually do, the failure of research discredits the delivery of sery ..ces.Third, there is little anyone can do to limit the effect of shifts inthe political environment on large-scale research and demonstrationefforts, but if the complexi-i of the enterprise is inconsistent withthe time constraints imposed by shifting political priorities, theblame for failures should be shared o..,ually by elected officials andadministrators. Fourth, one element of large-scale research anddevelopment efforts that is subject to executive control is theirorganization.Initial decisions about how to organize large-scaleefforts should be subjected to explicit analysis and high -levelexecutive scrutiny: What capacity is required? What ozganizatiorshave the required capacity? What capacity needs to to develcred? Whatincentives are available for mobilizing that canacity? ACKNOWLEDGMENTSI would like to acknaledge the assistance of Charles Betsey, studydirector for the Committee on Youth Employment Procp.ams, and RobinsonHollister, chair of the committee, in preparing this paper. Membees ofthe committee provided useful comments and criticism at an early stageof the research. Special thanks also to Bernard Anderson, GordonBerlin, Michael Borus, Seymour Brandwein, Erik Butler, David Cohen,Fred Fischer, Tom Glynn, Andrew Hahn, George Iden, Arnold Packer, DanSaks, Nat Semple, and Bill Spring for comments on earlier drafts,though they bear no responsibility for the final product.This piper is based in part on a series of interviews withparticipants in YEDP., program development and policy-making processes.Their willingness to discuss events and share insights contributedgreatly to t4'.e paper. REFERENCESBorus, M.1984Why De We Keep Inventing Square Wheels? What We Know andDon't,ow About Remedial Employment and Training Programs forHigh School Dropouts. Unpublished paper. ManpowerDemonstration Research Corporation, New York City.Butler, F,, and J. Darr1979Lessons from Experienc.J: An Interim Review of the YouthEmployment and Demonstration Projects Act of 1977. Center forPublic Service. Waltham, Mass.: Brandeis University.Hahn, A.19/9Taking stock of YEDPA: the federal youth employmentinitiae-ives, Part I. Youth and Society 2(2):237-261.Hann, A., and R. Lerman1983The CETA Youth Employment Record. Washington, D.C.: U.S.Department of Lab lr. 376 346Hargrove, E., and G. Dean1980The bureaucratic politics of evaluation: a case study of theDepartment of Labor. Publi:7 Administration Review40(March/April):150-159.Lindblom, C., and D. Cohen1979Usable Knowledge: Social Science and Social Problem Solving.New Haven, Ccnn.: Yale University Press.Lowry, J.H., and Associates1979Determining the Viability of Intermediary Non-Profit1980Corporations for Youth Programming. 4 Vols.Chicago, Ill.:.Tames H. Lowry and Associates.Lynn, L.19e1aThe President as Policymakei: Jimmy Carter and WelfareReform.Philadelphia, Pa.: University press.1981b Managing the Public's Business. New York:Basic Books.National Council on Employment Policy1983Back to Basics Under JTPA. Washington, D.C.: NationalCouncil on Institute.Peters, Waterman1982In Search of York:Harper and Row.Rein, M., and S. White1977Policy research: belief and doubt. Policy A.1971Systema'Thinking management: third-party government action. Public Knowledge Development: The Process Institutefor Employment Research.U.SCongress1977Conference Report 95-456. June 22, 1977.U.S. Congress, House of Representatives, Committee on Education andLabor1977Youth Employment Innovative Demonstration Projects Act of1977.Report 95-314. June 22, 1977.U.S. Congress, Senate, Committee on Human Resources1977Youth Employment Act. Report 95-173. May 16, 1977.U.S. Department of Labor1978Employment and Training Report of the Presidenc. Washink:ton,D.C.:U.S. Department of Labor.1979Employment and Training Report of the PrcOdent. Washington,D.C.:U.S. Department of Labor. 377 347 1980aEmployment and Training Report of the President. Washington,D.C.:U.S. Department of Labor.1980bKnowledge Development Activities/ Fiscal Years 2978-1979.Office of Youth Programs, Youth Knowledge Development Report1.2.Washington, D.C.: U.S. Department of Labor.1980cKnowledge Development Agenda. Office of Youth Programs, YouthKnowledge Development Report 1.1. Washington, D.C.: U.S.Department of Labor.1980eProceedings of an Overview Conference. Office of YouthPrograms, Youth Knowledge Development Report 1.3. Washington,D.C.:U.S. Department of Labor.1981Employment and Training Report of the President. Washington,D.C.:U.S. Department of Labor.1982Employment and Training Repo._ of the President. Washington,D.C.:U.S. Department of Labor. 378 The Social Context of Youth Employment ProgramsElijah Anderson This paper is based on field work in urban black communities andin-depth ethnographic interviews with individuals familiar with youthemployment programs, including current and former trainees, supervisors, and community people with a wealth of experience with employment andunemployment.Its primary purpose is to provide insights into the social context in which youth employment programs operate. In part, this is a conceptual discussion_ What follows, then, is not a highlysystematic accounting of factors related to specific programs, but amore general set of considerations of cultural and community factorsthat have likely conditioned the effectiveness of youth employmenttra:ninq programs.The paper begins with a brief sketch of the early days ofon-the-job training, in which ethnic whites negotiated the labor market.The social context of toiay's job-training programs is then described, based largely on the interviews. The third sectiondiscusses the values held by, and required of, participants in youth employment programs. A summary and conclusions section ends the paper. THE EARLY DAYS OF ON-THE-JOB TRAININGIn the 1930s the New Deal instituted what could be called job-training programs. The Works Progress Administration (WPA), theFamily Assistance Program (FAP), and other \"ABC\" programs wereinitiated to alleviate the pain and Suffering caused by the Great Depression.In post-Depression America, youth employment programs as we know them today did not exist. Rather, employers often emphasized on-the-job training.During that era, many employers in labor-intensive industries relied on the personal references of family and trusted employees for their recruitment pool. In that time, the apprentice system, or an Elijah Anderson is associate professor, Department of Sociology, andassociate director, Center for Ethnographic Studies, at the University of Pennsylvania. 340373 349approximation of it, was also of prime importance for industrialemployment.Various white ethnic group members, the primary source oflabor in large urban areas, tended to seek out their own kind forinvaluable on-the-job work experience. Both the instructor/mentor andethnic peers were genuinely interested in seeing the man \"work out.\"And the man usually did work out, for the extent to which he \"fit\"socially with a supportive work group usually had much to do with hissuccess.The following interview with an 82-year-old Irish American, astill-practicing machinist and automobile mechanic, gives a glimpse ofthe culture of on-the-job training in those years:In the 30s and 40s the guys didn't go to any training program.No, they didn't. They studied, themselves. They had a certainnatural ability. And they used that natural ability. In otherwords, I know a lot of fellows in the automobile business.They diu. t go to any school. They didn't go nothin'.Butthey learned as they worked. They didn't know if this carneeded a carburetor, they didn't know if it needed points.They didn't know nothin'. But they found out. They'd sly,\"Yeah, I can fix your car. Bring it over here.\" Then they'dget busy and try this and try that, and finally they'd know howto do these things, see. They'd learn on the job, and the jobwasn't supplied by the government. Guys [employers] gave 'em a b2ak.They didn't know what else to do with 'em. What're you gonna do with 'em? You go out in the country, the countsblacksmith, he was the guy that fixed the automobilLs. He was a general mechanic. As a rule, a good blacksmith is just aveLy, very clever pert n, because he knows an awful lot aboutthe materials, the iron, steel, and so forth, tempering the iron, welding and al? that. He knows all these things. But he learned it the hard way. He went in with his father when hewas a little ... so high. And he grew up in it. His father taught it to him. Now my father taught me a lot. Much of the skills in that day were passed on father to son or mother to daughter. Uncles and fathers would help the youngsters. If they didn'thave that, somebody took them in to help out in a store. A boywou]d start by going with a store, and they'd start out bysweeping the floor, cleaning the place up, and they'd say in ayear, \"You can wait on customers,\" and after a while they'd be in merchandising. They'd ease up the system. They were taught things.Everybody seemed to be interested in something. They were interested in this thing. They'd come in and they took a hold.The job training described above was common to various occupations,including carpe-try, plumbing, and other skilled trades.Such job training occurred most often among white ethnics. Blacks and otherminorities were occasionally employed and trained this way as well, but they were often required to accept the hardest, dirtiest, least skill- 380 350 requiring, and least well-paid occupations, which were essentially leftover by whites who had preceded them (see Spear, 1967; Davis andHaller, 1973; Hershberg et al., 1981). Many blacks who were able toacquire an apprenticeship in occupations such as plumbing, masonry, orcarpentry were not allowed to join unions or to practice their tradesthe way white ethnics were (see Marshall, 1965). Often, blacksfortunate enough to possess such skills were required to workindependently, and at times sporadically, at less than union scale.he following comments of a 70-year-old black wallpaper stripper aregermane: I learned masonry in North Carolina. Down there I could findwork.Colored people nften did this type of work. When I cometo Philadelphia (at approximately 30 years of age], they[whites] wouldn't let me work. I couldn't find work eventhough I was qualified. So I went in business for myself, andstarted hanging wallpaper, made a living that way. I don't dothat no more.I just strip paper, now.Some of the earliest organized job-training situations weredeveloped in grade schools, YMCAs, and vocational high schools servingworking-class youths. In shop classes boys were trained to runmachines, such as lathes, and girls were often taught sewing and homeeconomics.At graduation a friend of the family, a relative, or ateacher would serve as a reference for the prospective worker. In thisway schools, friends, and families provided important links to theworkplace, informally shaping the work settings of the ea y along ethnicand cultural lines that reflected their neighborhoods, schools, andfamilies (Hareve- and Langenbach, 1978).Sometimes vocational instructors moonlighted at a local shop, whet.:they were \"regular guys,\" but also where they could channel their axlestudents into jobs. A person trusted in one place was usually trustedin the other.Through these placements, the students often gained atrade for life and affirmation of themselves through work. Trainee andinstructor alike obtained some affirmation of self-worth and perhapseven closer identification with friendship, neighborhood, or ethniccircles.Such channeling helped to create and support the peculiarracial and ethnic character of certain occupations. For the ethnicgroup members, these effective, informal job-training efforts wereimportant steps between youth and adulthood. They were effective inpart becauLthey were heavily sanctioned by those involved, but alsobecause they were part of a social system; the workplace was receptiveto them.Such social connections and placements were crucial for theeffectiveness of early employment-training effo:ts. People enteringsuch relationships often did so on the promise that they would gain ajob in return for their involvement. It was in just this way thatyoung men and women placed in comparatively rewarding employmentpositions could bevin to develop what would become lifelong positiveassociations with work. Furthermore, in these circumstances the workethic could be affirmed and reinforced, not only for the individual 381 351 placed in a meaningful job, but also for his cultural peers, who couldlock forward to the day when they too might have jobs.On the negative side, feelings of alienation and injustice could begenerated and kept alive within these group structures when people werenot pleased with their jobs or the way in which they were treaf. J. Inthis way hope and expectations were formed and neighborhood solidaritygained.Unfortunately, as these processes occurred, work settingsbecame resistant to incursions by rival ethnic groups and almostimpenetrable for members of other racial groupings, particularly blacks(see DuBois, 1899; Spear, 1967; Clark, 1973; Hershberg et al., 1981).Such outlooks and the employment practices consistent with them led toracial and ethnic competition, conflict, dominance, and subordinationin a variety of jobs. This in turn gave rise to such evaluations,,conceptions, and labels as the \"black job,\" the and, of course, \"women's work.\" MODERN JOB-TRAINING PROGRAMS In the 1960s, during the days of the Kennedy administration, jobtraining became more formal, and government-sponsored programs weremore firmly established. Bureaucratic rules were developed andelaborated, and a variety of spin-offs were later instituted (seeGinzburg, 1980; Stromsdorfer, 1980). Initially, many participants inthese programs were ethnic whites. cver time, the racial and ethni-identities of both instructors and trainees in employment programsbegan to change. Colored minorities began to make up an increasinglysignificant portion of program participants.Under these circumstances, the general effectiveness of work-training programs was severely tested and often found wanting. Thesolutions fcc the employment problems of white ethnics often did notwork well for blacks and other nonwhites. In the earlier period theethnic and cultural organization of the ethnic neighborhoods wascompatible with that of the work settings into which the traineesmoved; in the Later period contrasting, if not conflicting, ethnicpopulations were expected to work together. Although the work settingshad formerly been receptive to white trainees, they were not now so forblacks.Discrimination was a problem, to be sum, fart also important,the nature of the world cf work was undergoing crucial and far-reachingchanges.With widespread and increasing automation and technologicaldevelopment, a certain social fit between training a:.d employmentcontexts had been lost. Moreover, the structure of employmentopportunities that had awaited the ethnic whites was declining as largenumbers of blacks and Puerto Ricans attempted to negotiate the labormarket (see Doeringer and Fiore, 1971; Wilson, 1980; Hershberg et al.,'981).Furthermore, the various social connections to the workplacenat had been critical to the successful employment efforts of whiteswere largely lacking for blacks. It is this lack of social connectionsand linkages to training and employment contexts that continues to bean important consideration in the effectiveness of current job-trainingprograms.382 352 Instructors and TraineesIn many instances, the instructors in programs of the 1960s wereethnic whites who were fond of remembering how they \"came up the hardway,\" at times invoking the American \"bootstrap theory\" of socialmobility (see Hershberg, 1981). Increasingly, however, many of the newtrainees were young black men from urban ghettoes, people their instruc-tors could readily compare negatively with advantaged whites and labelas \"out to get something for nothing.\" To many white ethnics, theseyoung black men represented a threat (see Blumer, 1958; Pettigrew,1980).In earlier times when mentors taught their prot\u00e9g\u00e9s a trade or workskill, the process was often slow and guided by the cautious develop-ment of trust among participants. The \"tricks of the trade\" and otheroccupational secrets usually were only slowly divulged to \"worthy,\"\"likable,\" and \"able\" trainees, evaluations that were made subjectivelyand at times arbitrarily.When young black men were introduced into this type of job training,to be instructed largely by white wcrking-class instructors, thescenario became extremely complicated. A certain amount of tensionbetween divergent cultural groups may be anticipated and perhapsdismissed as normal happenstance. But with the introduction of raceand the resulting competition for \"power resources,\" many suchinstructors were no longer able to view themselves as simply passing onskills and trades to deserving youths (see Bonney, 1972; Wilson, 1973;Kornblum, 1974). Rather, the instructor, who may have viewed himselfas a master craftsman, might have sensed that his own group interestswere threatened by the prospect of training young black men for occupa-tions once held by membErs of the instructor's own ethnic group. Theinstructor was likely to experience some difficulty, if not profoundpsychological dissonance, in teaching something so dear to him as histrade to people generally defined as outcasts making spirited assaultson areas of influence and privilege traditionally (and legally)reserved for others he might more readily identify as his own kind (seeBlumer, 1958; Goffman, 1963; Higginbotham, 1978).Instructors at times resolved this dissonance by approachingminority trainees with a dubious attitude. Doubtful of the basicpotential of ghetto youths, they often relied on racial stereotypes intheir dealings with them. But equally important, black trainees wereoften suspicious of their instructors, at times believing them toharbor racist attitudes and approaching them only with a certain amountof hesitancy and caution. What was ostensibly begun as an instructor-trainee relationship sometimes became a full-blown racial, ethnic, andclass contest.The problem of social friction between instructor and trainee isjust one problematic area among many that must be addressed to gaininsight into the more general issue of the effectiveness of job pro-grams.First, in addition to the attitudes of teachers towardstudents, the attitudes of the trainees must be examined. What is the manner in which use attitudes are expressed in both the job-trainingcontext and on t-e actual job? Second, it is necessary to examine the 383 353circumstances in which the problematic attitudes of instructors andtrainees are expressed and to gain an ethnographic picture of themanner in which often conflicting definitions of the situation meet andbecome resolved or are left unresolved. Sources of ConflictIn addition to what might be viewed as a problem of culturalbackground--the issue of ethnic or class friction or competition--thereexists a more manifestly troublesome aspect of the social \"fit\" betweeninstructors and trainees. The culture of the job-training program, andperhaps the culture of any school situation, clashes with the cultureof the ghetto street. The hard-core unemployed are often the embodi-ment of this street culture. Even to the casual observer, their valuesappear to be very much at odds with the dominant, middle-class valuesystem represented and often invoked by the staff of a job-trainingprogram (see culture of the hard-core unemployedcarry over into the job-training setting and thus contribute totensions between trainee and instructor. For instance, numeroustrainees seem to have difficulty with riddle-class concepts ctime.From the perspective of the staff, many seem to lack interest in being,or are unable to be, punctual; they seem to accept tardiness as normalhappenstance.They may also be absent from class much of the time.Many display what is interpreted by instructors to be a \"tough\"demeanor; they appear to carry a chip on their shoulder. Some traineesappear to have trouble dealing with authority figures, particularlywhite male instructors. Instead of an attitude of seriousness, manyyouths appear to take a cavalier attitude toward the program, appearingsimply to be putting in time.These (what staff members often call irritating) aspects of thetrainee's manner of self-presentation aggravate the perhaps alreadynegatively inclined instructor, who may be so inclined for his owngroup-identification reasons: it is very difficult to comprehend theinfluence of long-standing and real ethnic, racial, and class hostilityin the current job-training setting, But it is an \"outsider\" class ofyouths--black ghetto street boys and young men--who by their life-styleand demeanor, threaten white and even black instructors from the oldworking class, causing them to maintain a certain social distance in self-defense.The teacher-student relationship, particularly in anemployment-training program, requires a profound degree of trust if itis to si!cceed, but this needed trust is often sorely lacking, which isanother important reason that many of the programs lack effectiveness.At the same time, program trainees t ye numerous complaints ofinsensitivity on the part of instructors. For instance, some instruc-tors are said to close and lock the door at the beginning of class,refusing to open it for someone who is five minutes late. Aftertraveling the 10 subway miles from the north Philadelphia ghetto, someyouths are prepared to call the instructor's actions racist, if the 384 354 instructor is white, or antiblack, if he is black. As one youthexplains, \"Five minutes ain't a whole lot of time.\" But the instructoris not inclined to see things this way. The instructor's attitude maybe that this black youth fits into the category of a person trying toget something for nothing, without putting in the hard work. Indeed,some youths think 15 minutes one way or the other is simply not thatimportant, or even that missing four or five days of school is ofnegligible import. But interrelated with the issues of attendance andpunctuality are often the trainees' basic problems of a chronic lack ofmoney and, thus, of reliable transportation to the job-training site.Unfortunately, these issues are likely to become confused and inter-preted as indicative of behavioral laxity. Many of the hard-coreunemployed a.:e likely to receive their \"caLLare\" to the training siteone day and spend it all in the next day or so. This population, notunlike those of the middle class or even the working class, has anunlimited list of \"necessities\" on which to spend money, from liquor tofood.When their money is spent, they often lack a means of transporta-tion.Then, after repeated tardiness or absence from training sessions,they fall irretrievably behind, or their aggravated instructors mayunsympathetically judge and treat them so; many then become unwillingor unable to participate further.Feeling discouraged and frustrated, many youths become convincedthat the instructor, in being a tough disciplinarian, is not all thatsupportive or interested in seeing them succeed. The instr_ctor mayrespond, \"Well, if this was a job and you were getting paid, then theseare the real expectations. You must be on time, and you must comeevery day.If you don't come every day, or if you come late, thenyou're not going to keep that job for very long.\" Such a lecture makesgood sense to instructors. But to many young people in a trainingcontext, such invocations, at times sharp tongued, of discipline,attendance, and punctuality may easily be taken as clear evidence ofprejudice.Insensitive to these perceptions, and often with a strongsense of commitment to discipline, the instructor may believe it moreimportant to get the trainee back in line.But getting the youths back in line is nc a simple task, againbeca'a of what is often a basic lack of c tltural compatibility betweentra .ees and instructors, particularly as .nstructors are prepared tointerpret the situation. The trainees often come from an urban environ-ment that has not prepared them to adapt easily to the rules and socialetiquette of the workplace. Many of the hard-core unemployed aresocialized and conditicred to be \"tough\" in their encounters with othermen, particularly challenging authority figures who are white. Theytend to have little faith in whites generally. Their demeanorfrequently evolves into a kind of arrogance that is often a defensivedisplay, particularly when confronted by potential threats or challengesto their independence and \"manhood.\" Such a demeanor is thought bymany to be absolutely necessary to survive the mean ghetto streets.After years of such conditioning, a youth meets the job-traininginstructor.In this situation, the youth must suddenly change many ofthe behavioral patterns gained through socialization, patterns that hehas come to take for granted and to value. It may appear to him that 385 355he must now, in effect, humble himself in the face of authcrity that,whether assumed by a black or white person, is perhaps of dubiouslegitimacy.The value of changing his behavior is not completely clearto him; he :gas remarkably little faith, though perhaps much hope, thatdeference and time spent in the training program will result inmeaningful employment.If employment-training programs are to be effective, they mustdeliver what trainees want most: meaningful employment. Many traineesmust indeed be taught the importance of discipline, punctuality, andgood attendance in the workplace, but at the same time, instructorsmust become sensitized to the special problems, cultural or otherwise,of the hard-core unemployed. The instructor should be able to recognizethe cultural problems noted here and then display a certain sensitivityand patience in searching for zmeative and effective ways to teach andremind youths of their particular shortcomings with regard to theculture of the workplace. Moreover, there should also be clear andidentifiable rewards for the trainees and their supervisors foreffective behavior and attitudes displayed in the training context.Instead of sensitivity toward and appreciation of the culturalmilieu from which they come, however, trainees often meet withshortsighted behavior, derision, strictness, and control on the part ofthe instructor. Instructors may feel justified in a tough anddefensive reaction, as they believe there is often a need to competefor authority in this context. In their invocations of discipline,they often promote themselves as guardians of the values of work,defending those from their students, whom they must, however, simul-taneously teach and ultimately render employable. What begins as aninstructor-trainee situation may quickly deteriorate into a contest ofethnic, racial, or class authority.Significantly, it is not only white instructors who may carryproblematic attitudes into job-training situations. Increasingly, manyof today's instructors are black and have often emerged from traditionalworking-class backgrounds. The job-training program is likely to bemade up of black trainees and black instuctors. The black instructorsmay think of themselves as having worked hard to get where they are.Having themselves made it through hard work and much personalsacrifice, they may be inclined to be prejudiced against unemployedblack youths.Their feelings may be manifested in an overzealousdesire to turn out highly successful black youths, resulting in strong,and at times arbitrary, invocations of discipline in the trainingpro;ess.There is sometimes a fine line between the appropriateinvocation of discipline for effective management of training and themanifestation of class prejudice in the form of harassment. Casualties of the ProgramOver time, some young people who participate in youth employmentprograms become frustrated and demoralized by their expezitances. Theysimply become worn down by the routine of the program and, often becauseof their inability to make visible \"progress,\" become disgusted with 386 356the program and its staff. Progress for them is to feel equipped withmarketable skills that will give them a chance to compete effectivelyfor a permanent, well - paying job. LacKing clear signs of progress,many become frustrated and resign from the program, at times in anattempt to retain a sense of manhood and independence. In so doing,many proclaim they would rather \"give it up\" (trying to obtain a job)than \"slave for the mar\" /to engage in hard labor); a popular ghettoexpression for job is \"sOn leaving, they are .ffect \"shaken out\" of the program. Later,in discussing the program with any interested party, they often recalltheir worst experiences and characterize the whole program as \"a wasteof time.\"In bad-mouthing the program to other members of the com-munity, they seek affirmation and support in having been wise enough toquit the program. As they travel through the community, they seldomhave anything positive to say about the program. In effect, they oftenonly draw the cultural boundary between the streets and the programsmore strongly and clearly. Insofar as they have prestige on thestreet, they then influence others to be loyal to the streets byrejecting the programs.Significantly, many individuals tend not to specify which programthey have had a bad experience with, and their listeners often do notrequire specifics. In such instances, \"the program\" sometimes refersto almost any and all programs in existence. There is a tendency amongcommunity people with no firsthand experience to lump all programstogether, not distinguishing between programs, be they federal, state,or local.Reports on a program, good or bad, seem to be readilygeneralized.As the casualties of the \"program\" move on, they fall into othersituations that attract them. Some develop time-consuming new projectsaimed at financial self-survival, for example a job with a fast-foodrest.urant, an exterminating company, or a factory. Chance plays animportant role here. If employment fails to materialize, some youthshave been known to involve themselves in drug dealing and othercriminal activity for financial gain; people cf the community .:c.dilymake an association between idle unemployment and crime. Often, as alast choice, those with clear law-abiding intentions may attempt toenlist in military service, but often they are rejected.Through their travels about the city and the local community, theyfind it necessary to maintain that their decision ti leave the programwas a good one. A working conception of oneself and the programdevelops, complete with excuses and justifications for why things didnot work out with the program. In this instance, many co,Iclude evenmore firmly that a well-paying job for them was simply not possiblethrough any association with the program.As frustration and disappointment grow, the program also losesrelatively mature participants who have a measure of discipline andoften the motivation to succeed at using the program for obtaining apermanent job. In fact, this is the initial goal of many of thoseentering the program. But when they fail to achieve this goal, theserious, and perhaps more intelligent, youths--those with a clear senseof options--move on, wanting no longer to tolerate the \"abuse\" and 387 357 tensions with the staff. For many, the main problem here is theprominent failure of the program to deliver on its ostensible promise:a permanent job.As they move on, the casualties leave behind in the program manyyouths who possess relatively little in the way of personal or socialskills that will enable them to participate effectively in a job-training program. They leave behind those who are not su highlymotivated, those with limited options, and the new recruits. Manyparticipants are so poor they have hardly enough food to eat or even areliable residence; alcohol and drugs are also persistent problems forsome.Program directors might then complain that the pool they now haveconsists of too many \"mental defectives, drug addicts, ex-cons, retardedpeople, illiterates.\" Such views, not only among staff but also amongcommunity people and prospective trainees, contribute to the stigmatiza-tion of the program and ultimately to its ineffectiveness. ValuesThe generalized American belief in \"pulling yourself up by your ownbootstraps\" appears at times to work against the credibility ofgovernment-sponsored job-training programs. Strikingly, \"working for aliving,\" the \"bootstrap\" ideal, and the avoidance of \"governmenthandouts\" represent values that many black and other minority Americanashare with others (see Hershberg, 1981). Many youths would likenothing better than to realize this ideal, and they work very hard atachieving it.When such highly motivated youths become involved with a job-training program, they often attain a measure of success.In theirclasses, they achieve outstanding records. Highly motivated tosucceed, such individuals are imbued with self-confidence and apositive outlook, despite the distrust and discrimination theyencounter.They appear to emerge from a family and social backgroundthat, while financially poor, places much emphasis on self-discipline,self-esteem, and a strong belief in the \"work ethic.\" As theynegotiate the training program, they very favorably impress theirteachers.When the teachers learn of openings, they do not hesitate torecommend such youths for jobs. It is for these individuals that theprogram seems most effective. They tend to obtain jobs and move on tonegotiate certain areas of the occupational structure. But suchindividuals, emerging as they do from backgrounds of poverty anddiscrimination, tend to be rare.An important policy issue for those interested in increasing theeffectiveness of youth employment programs is that of how to instillthe attitudes and behavior patterns of successful individuals intoother trainees. This would require serious and effective trainingsessions devoted to discipline and motivation. But there must also besome change in the attitudes of staff people who seem to expect toolittle from minority youth. Youth employment programs need effectiveteachers who possess the sophisticated knack for discerning the 388 358unexhibited potential of trainees and who are able and willing to helpthe trainees \"find themselves.\" But at the same time, program staffmust be willing and able to help place the youth in meaningfulemployment after they complete their training.Given the realities of the employment arena, including ethnic andracial competition and the prospective employer's often profounddistrust of black youths, placement appears to be one of the mosttroublesome aspects of the training process (see E. Anderson, 1980).Yet it is this aspect that ultimately determines the effectiveness ofthe program.Unfortunately, too many trainees pursue the programs,graduate, and are then left in the same shape they were in before theybecame involved in the program. It is this result that repeats itselffar too often, lending credence to negative commentary on the programswithin the minority communities. The comments of one former programparticipant are relevant:As far as I know, no one [of his job-training cohort] got apermanent job. Like, I got a job for a year, right? Whatcould I have done? That was money I made and spent on clothes,a little carfare. You couldn't make no moves [to get married,for instance, to buy an automobile, or to rent an apartment]with it.Now with my program, the people made it forthemselves.Now the director of my program went on to amultimillion dollar insulation program. He contracted his workout of Jersey, New York, and cities in this area here.Pittsburgh.He went to Reading, little cities and towns inPennsylvania, Ohio, Delaware. But he did not take none ofthose people that was involved in his program. And he likedme:But he never invited me to do insulation work. Because hemost likely wasn't confident in what they were teaching us.And you knew it wasn't enough, because the extent of theweatherization program we went to was plastering holes, puttingon the heat blanket, Mortite, caulking a window. That was theextent of the matter. But he took it farther than that. Heinsulated all the pipes of people's homes. He contracted allthe work in all these new buildings. So before anybody moveinto these houses he was insulating them.What I'm saying is that the whole program was about somebodytaking an interest in hiring these young people, to give thempermanent jobs. That was the whole thing. That's what theywere asking these companies to do. Yet and still this man tookon a multimillion dollar program of his own. He started itwit out a dime. His name and a couple of his references gothim maybe a million dollar loan from a bank [the accuracy ofthis figure is uncertain]. But he did not take no one withhim.He took one of the instructors. He gave anotherinstructor money to start his own glass block company. Andthese are now reputable companies. You look in the white pagesor the yellow pages, and you'll see these companies. 389 359 Because of such experiences, many youths approach job-training programswith a certain generalized suspicion of \"programs.\"On many occasions, the program \"advertises\" itself on ahettostreets, where instructors and trainees, perhaps unwittingly, are attimes under the watchful eyes of prospective trainees. Following aresome comments by a black male, 21 years old, who only brieflyconsidered becoming involved as a job-training participant:I was on the street once end one of the CETA supervisors sentone of the guys across the street to pick up some material.And because the store, the clerks, did not wait on himpromptly, the supervisor came across the street and hollers atthe guy like, \"What the hell are you still waiting over herefor?:Get yo' ass across the street:\" Now, I'm talking aboutseeing him do this in a store full of people, you know. Imean, the guy must've felt bad. I know I would've felt bad.And then the supervisor, after that, he turned around, helaughed about it. That just shows you how they treat theworkers.In the foregoing incident both the supervisor and the trainee wereblack men, an indication that conflict and tension between supervisorand trainee are not simply or always a function of interracialrelations but sometimes a function of hierarchy and the promotion ofdiscipline itself. Yet, importantly, such incidents do little for thecommunity's image of the job-training program.On the basis of such treatment by instructors, the alreadysuspicious trainee nay question the instructor's ability to make acommitment to teaching him anything. But trust in the instructor'nability is essential to any worthwhile mentor-trainee relationship.Hence, the relationship between the ghetto Louth and the instructor isa difficult one and can contribute to the ineffectiveness of thegeneral program. But equally important, in such scenarios, told andrepeated in the ghetto community, \"the program\" is made to seemincreasingly unattractive, again contributing to its disvalued status.Thus, in many communities, the program has a \"bad name,\" and areputation for being of time,\" 'eading many tobelieve that participation is not a very worthwhile way to spend one's time, even if the person is unemployed. This is indicated in thefollowing interview with a 21-year-old youth, who had been involvedwith \"the program\" and had worked in a related job for a year, but whofelt he had really not advanced from where started:Bov, these programs were very misleading, 'cause they were veryunsuccessful.Led the people to believe they would getpermanent jobs. And they had the right people there. They hadthe motivators. They had the people there who talk good[convincing], the cons, and all that. But I told 'em when theytalked to me like that. See, I don't take things at facevalue.When somebody tell me \"I can get you permanent work,\" Iwant them to take it into parts. Tell me why you think that.Do you know somebody who's gm' give me permanent work?390 360The program was a waste of money, a waste of time, verymisleading, and it got a very bad rep in the community. Theygot the community all involved. Now, this happened in '81 and'83.A number of the people wouldn't believe in it from thebeginning.And the ones who do get involved will be involvedonly for the money, only if there's a salary involved. It'sjust a band-aid. Everybody lacks confidence in it. It was apolitical act. They hired all these young guys just to getthem off the street. It would be to your advantage not to beinvolved.Because it takes up time, and time is money. Youstart off with confidence, but down the line you gon' be letdown.I don't know anyone that took that [was involved in theprogram] that's now independent. If they were on welfarebefore they started the program, they got back on. The programis just a sham. It was just a political move. People playin'chess with other peoples' lives.That general population toward which government-sponsored employ-ment programs are usually geared, the hard-core unemployed, cangenerally be described as youths whose employment prospects are quitelimited even as they enter high school. There, decisions are made thataffect the scheme of their entire lives. The tendency is for the youngblack man from the inner city to either quit or socially \"graduatefrom a segregated urban school unable to read, write, or compute.Given the large amount of distrust for black males in the urbanenvironment, he 'las little chance for permanent, gainful employment.Some youths may become involved in \"dealing\" drugs, which caninvolve anything from marijuana o heroin. Today, one does not have tobe a full-time \"professional\" dealer to be employed in the drugbusiness; one can often engage in this criminal activity only parttime, and sometimes for as little as a $10 initial investment. Simpleparticipation is often contingent upon and a result of a need formoney.A person may get involved in the illegal selling of drugs theway 4 gambler would bet on a horse or play a slot machine: he hasmoney for the moment to gamble in the hope of a quick return; he mayhave as much as $10 or $20 and want to double it. He buys the drugswholesale, carries them around, and attempts to sell them. Suchbehavior is in reality a large gamble. If he \"wins,\" he earns aprofit; if he loses, he could wind up as a victim of violence forselling \"bad\" drugs or for being part of a misunderstood deal, or as aninmate in jail if he tries to sell to the wrong person and is foundguilty of possession. Although he may venture into drug dealing on alark, he is very serious about his need for money. He may win thistime, and if he does, he is back into circulation for a while. Whilepursuing this life-style, he continues sporadically to look out for ajob.When he sees a sign in a window for \"help wanted,\" he's uncertainthat the sign applies to him; he believes he will be turned down. Hehas been turned down so often he expects \"no,\" even though he may havewitnessed the sign being placed. Prospective employers often stereo-type, distrust, and fear him. On an existential and experiential 391 361level, he knows this well. With a series of such experiences, hebecomes frustrated and increasingly discouraged.At this point he may see signs on bulletin boards at the communitycenter about \"job training.\" As he looks into this, he does so withsome suspicion, for he personally knows few people, if any, who haveobtained a permanent job through a job-training program. Yet with fewemployment options, he looks into the job-training program. He becomesinvolved, hoping to gain a permanent, well-paying job. But heapproaches the program with cautious hope. In time, he comes to seethat marketable skills that would make him truly competitive in theworkplace are not being offered. The \"skills\" that are being offered,he thinks, one should not have to spend time in school for. Forexample, after being promised that he will be taught carpentry, he istaught to caulk windows instead. He begins to believe the program is asham, a waste of his time. He begins to lose interest, yet he has fewemployment options and desperately needs money. He will do almostanything at this point, though he badly wants a \"good job,\" preferringto have a law-abiding occupation. Becoming socially involved with hisfellow trainees, he remains with the program for two or three months.Later, he \"lucks up\" on a job caulking windows for $3.50 an hour andremains employed for a year. At the end of a year, he realizes thathe's getting nowhere; thinking about his future he decides to join thearmy.He attempts to enlist, but he is rejected because he lacks ahigh school diploma; if he wants to enlist, he must attend night schoolor somehow gain a General Equivalency Diploma.Among some youths enlistment in the military is a matter of lastresort.The following comments by a black, 22-year-old Philadelphiataxicab driver are relevant:I was involved in a summer jobs program. It didn't work out.They had me working at a hospital. But the people didn'treally want me there. I was tnere for a couple of months, andthe first thing I know, I was fired. I never could get areason for it. They wasn't writing me up or nothing, but theydid complain about me, little petty stuff. I got on [becameemployed] with the cab company and started driving a cab.Whatthey really need to do is just get people permanent jobs. ...The military has helped a couple homies [close friends] ofmine.But I wouldn't go in. I would have to be doin' boss[very] bad to do somethin' like that.Unfortunately, many young men who are without jobs anJ prospectsstrongly feel that they have only their manhood and their toughness,and until they gain something better they will try to retain that. Inattempting to do so, they often find a certain local acclaim and self-esteem among peers in fathering children out of wedlock, engaging inpetty and even serious street crime, selling drugs, or burglarizinghomes.They are often left to approach \"trouble\" for nersonal affirma-tion and gloat or brag about running and shooting encounters with otheryoung men or the police. Their resolution of a dire need for employmentand money is sometimes to involve themselves in some form of antisocial 392 362behavior, perhaps winding up in jail or in the military; judges havebeen known to give the young man a choice.In addition to the poor reputation youth employment programs haveacquired in minority communities, it is important to consider thereputation of work as it is so often defined and emphasized by suchprograms.So often the jobs for which youths are being trained arethought of as dead end and menial; it is difficult fo the youth toperceive the possibility of real advancement throughWch work. Thetraining is often perceived as conferring low status on a person, whofrequently possesses an expanded sense of racial and personal pride(see E. Anderson, 1980). This again raises the issue of \"strain\" orlack of social \"fit\" between the older instructors and the youngertrainees.The instructors in the program share certain beliefs andvalues concerning work, work settings, propriety, and the work ethic.Many profess to believe in \"hard work\" for just rewards. This isperhaps an outmoded notion in our contemporary society, especiallyamong many ghetto youths who are mobile about town and are readily ableto view others of their color-caste riding trolleys, trains, and busesand dressed in pinstriped suits and carrying briefcases. They havecome to see this model, to wonder about him, and perhaps to desire toemulate him.Yet these youths have little real chance of moving toward beingthat sort of man, the young professional, if they are being trained tobe a carpenter, and poorly at that. Common sense tells them that suchjobs are closed to them and their kind; from their elders, they'veheard the tales of discrimination, and many have experienced it first-hand.Hence, many youths approach the program with a limited amount ofmotivation.Many are ambivalent about the value of such a program,even if they were to be successful in completing it. For ultimately,the program prepares the young people for jobs many have come to see as\"beneath\" them, and hence, the more they invest in terms of time andenergy, the more they believe they condone what is in their estimationan essentially inferior social and economic position, not to mentionthe boredom and toil that come with it. Yet they want jobs badly.Many older black workers, including laborers, masons, andplasterers, say that today's youth won't work. Perhaps, youths aregrowing up in a society in which physical work, in its strictworking-class definition, is simply declining as a value. Having a jobis surely important, but valued activities are often those that can bedone in a suit and tie, not a pair of coveralls. The very place of theterm \"working class\" in our lexicon, a place below all other classessave the very poor, is a clue to and passes along society's valuationof the place of \"workers.\"Many of today's youths who do not want tc work may be seen less asdisconnected from society's values than as sharing the valuation agreat many people place on physical labor; these youths are very muchup-to-date and very much connected. With their high aspirations andintermittent, often unrealistic, expectations, they are simply under-educated, untrained, and lacking in the nonphysical skills necessaryfor entry into labor markets with jobs for professionals. In a sense,minority youths are held accountable to values of physical work that 393 363seem in decline in the face of increasing automatioh and technologychange (see Wilson, 1980; Hershberg, 1981; and B. Anderson, 1981). SUMMARY AND CONCLUSIONS The foregoing account illustrates how the earlier ethnic experiencewas very different from that of blacks and other colored minoritiestoday.The job market was much more receptive to the ethnic whites,who had common skin color and a certain compatibility with the systemof work.This general receptivity inspired many to be highlymotivated.Discrimination did not exist to the degree that it now doesfor blacks and other colored people. Family and friends were oftensupportive, on and off the job. These primary reference groups helpedthem to \"work out,\" in part because they were representing people whohad helped them find work through word of mouth, but also because theycould often identify with those they were joining in the workplace (seeShibutani, 1955). Given the need for labor, there was on-the-jobtraining for those who had no skills.StriKingly, this supportive environment does not exist for minorityyouths.Individuals--black or white--do not go out of their way tohelp such youths. Equally important, minority youths, beaten down bythe specter of distrust and discrimination, are often resigned to theirposition.And because of this, many are unwilling or unable torecognize and seize opportunity. From both sides -- instructors andtrainees--there seems to be a profound lack of confidence in theability of the trainees to make progress in the job market. Many whowould employ black youths share this lack of confidence and often aprejudice that the hard-core unemployed and their culture are truly notcompatible with the work setting. Such attitudes represent majorobstacles to the employment of youths after they have completed jobtraining and, thus, are important considerations for the effectivenessof training programs.The trickling out of talented instructors is another criticalfactor affecting the effectiveness of employment programs. Sincenational and local politics often play such an important role in theemployment programs, funding is variable and at times unpredictable.As the programs receive decreasing or fluctuating funding, they becomeincreasingly unable to attract and retain effective teachers who arelikely to place their students in permanent and well-paying jobs. Asthe teacher's salary becomes uncertain or declines, he or she may losea sense of commitment to the program. The better instructors may seekbetter-paying jobs, often in the private sector, or they may retire.Such people are important resources for the programs, in part becauseof their work skills and their teaching abilities, but also because oftheir connections with the private sector and their interests in placingtheir more able students. In the early days, it was just such types ofindividuals who served ethnic whites as effective links between voca-tional schools and the work setting. But these people are rare today,given the low salaries of instructors and job insecurity. Their absencebodes ill for the effectiveness of employment training programs. 394 364 Increasingly, attempts are made to replace such people with theiraides, who now begin to teach, but who are not as highly qualified astheir former teachers. Zqually important, they sorely lack theirteachers' credibility and connections with the workplace. If formeraides possessed such connections, it may be argued, they might takeadvantage of them for themselves.Participants in the programs at all levels often feel a high degreeof uncertainty about the program's immediate future. Social andcultural tensions between many trainees and their instructors haveperhaps increased. Yet the primary issue concerning the programs stemsfrom the inability of the programs to place participants in gainfuloccupations.The largest complaint among black youths seems to be thatthe programs fail to deliver permanent jobs. More attention must begiven to this critical issue. It is chiefly because of thisfailure--and perceptions of it--that relatively few trainees havepositive evaluations of the programs. When the trainees cJtain jobs,they often feel they could have obtained the job without having gonethrough the program.Some mechanism must be instituted for accountability in thetraining program. To be effective, programs must be result oriented.After training, participants must be placed in gainful, rewardingoccupations.A novel but perhaps very effective solution to theproblem of placement may be a guarantee of a job to each trainee whosuccessfully completes the program. Such jobs would be preferablythose in which the person could clearly expect a degree of financialsecurity or mobility for his honest and diligent efforts. In thiseffort to solve what is too easily viewed by many as an intractablesocial problem, the private sector must become much more deeplyinvolved.Along with the federal government, corporate America mustplay a more direct and important role in the training and placement ofyoung people.Training programs must be made to work. When traineesare well trained and systematically and effectively placed in gainfulemployment situations, they will declare the program effective andsuccessful.Then young unemployed people will be standing in line toenroll in job-training programs instead of having to be recruited asthey are now. REFERENCESAnderson, Bernard1981How much did the programs help minorities and youth? In EliGinzberg, ed., Employing the Unemployed. New York:BasicBooks.Anderson, Elijah1978A Place on the Corner. Chicago, Ill.: University of ChicagoPress.1980Some observations on black youth employment. Pp. 64-87 inBernard Anderson and Isabel Sawhill, eds., Youth Policy. Englewood Cliffs, 365Auletta, Ken1982The Underclass. New York:Random Ht.,use.Blumer, Herbert1958Race a sense of group position. 1(1).Bonney, Norman1972Unwelcome Strangers. Unpublished Ph.D. dissertation.University of In Allen Davis Haller, eds.,The Peoples of Philadelphia. Philadelphia, Pa.: TempleUniversity Haller1973The Peoples of Philadelphia. Pa.: TempleUniversity Press.Dceringer, Peter B., and Michael J. Piore1971Internal Labor Markets and Manpower Analysis.. Lexington,Mass.:D.C. Heath.DuBois, W.E.B.1899The in an American Factory-City. NewYork:Pantheon Books.Hershberg, Theodore, ed.1981Philadelphia:Work, Space, Family, and Group Experience inthe 19th Century. New York:Oxford University Press.Hershberg, Theodore, Alan N. Burstein, Eugene P. Ericksen, Stephanie W.Greenberg, and William L. Yancey1981A tale of three cities: blacks, immigrants, and opportunityin Philadelphia, 1850-1880, 1930, 1970. In TheodoreHershberg, ed., Philadelphia: Work, Space, Family, and GroupExperience in the 19th Century. New York:Oxford sniversityPress.Higginbotham, Leon1978In the Matter of Color. New York:Oxford University Collar Community. Chicago, Iii.: University of ChicagoPress.Liebow, Elliot1967Tally's A Study of Negro Streetcorner Men. Boston,Mass.:Little, Brown.Marshall, Ray15.,5The Negro and Organized Labor. flew Groups. Cambridge:Harvard Tomatsu1955Reference groups as perspectives. American Journal ofSociology 60(May):562-569.Spear, Allan1967Black Chicago. Chicago, Ill.: University of Chicago Press.Stromsdorfer, W.1980Tile effectiveness of youth programs. Pp. 88-111 in BernardAnderson and Isabel Sawhill, eds., Youth Employment and PublicPolicy.Englewood Cliffs, N.J.: Prentice-Hall.Wel:s.man, David1977Putting on the poverty program. In David M. Gordon, ed.,Problems in Political Economy. Lexington, Mass.: D.C. Heath.Wilson, William J.1573Power, Racism, and Privilege. New York:Macmillan.1980The Declining Significance of Race. 2d edition.Chicago,Ill.:University of Chicago Press. 397 Youth Joblessness and Race:Evidence from the 1980 CensusGeorge Cave In 1983 the Census Bureau released microdata based on the \"long-form\" questionnaire completed by about one-fifth of the respondents inthe 1980 Census. \"Public-Use Microdata Sample C\" identifies the \"typeof area\"--central city, urban fringe, r cal, and so on--for a full 1percent of the U.S. population (Bureau of the Census, 1983). The largesize of this data set enables researchers to sts'dy the impact of areatype and many other factors on a multitude of individual variablesmeasured by the questionnaire. In addition to the 1 percent populationsample, a 9.1 percent subsample provides data on 226,947 individualssurveyed in the 1980 Census.This paper compares the data on unemployment and other labor forcebehavior reported for black youths with that reported for white youths.The key question addressed is, Do black youths face special problems inthe labor market due to their race? A related question is whethercorrecting black and white youth labor force sti.cistics for location,education, family income, and other factors tends to eliminate theracial differences. This paper, like most others in the empiricalliterature on youth unemployment, uses simple single-equation methodsto correct for these factors. However, the results must be interpretedvery carefully for several reasons. First; most coefficients estimatedon data for individuals are data may not estimate behavior. Third, single-equation methods introducesimultaneity bies if, for example, the probability of unemploymentinfluences th, probability of labor force participation. Finally, evensystem methods may ignore some simultaneity and overcorrect for factorsother than race. Tc some extent, residential location within the locallabor market, quantity and quality of education, family income, and soon are, like unemployment, partly the consequences of race in the labormarket.To ignore the effect of race on these determinants of labor George Cave is on the staff of the Manpower Demonstration ResearchCorporation. 367398 368 force status is to ignore the indirect labor market effects of race onunemployment.This paper is organized as follows. First, the data sets and thestatistical methods used most extensively in this study are described.Next, a brief overview is given of the seasonal, cyclical, frictional,and structural components that complicate empirical analysis of theyouth unemployment problem. This section also includes a survey ofseveral earlier empirical analyses. The empirical analysis of thelabor force status of out-of-school black and white teenagers includedin the Census microdata follows. Then the very different behavior ofthose teenagers who were enrolled in school at any time during the twomonths before Census day is explored. The paper ends with a summary ofthe major findings. THE DATAThe 0.1 percent subsample of \"Public-Use Microdata Sample C\" has226,947 self-weighting observations on individuals. Of these, 8,653are young men aged 16-19. Because only 1,190 of these young men areblack, stratifying the sample by region, education, and other factorsproduces some data cells with no nonwhites. The problem becomes evenmore severe when students are excluded from this group; there remain2,061 white males, but only 372 black males. Fortunately, it is easyto increase the number of nonwhites by a factor of 10 by using the full1 percent sample of nonwhites. However, calculations based onstratified samples containing nonwhites from the full C sample but onlythose whites in the 0.1 percent subsample require special techriques.Heteroscedasticity could arise from the 10-fold greater chance anonwhite respondent had to get into such stratified samples. Still,the huge Census microdata samples enable appropriately cautiousresearchers to home in on interesting subgroups in ways that smallersamples do not permit.The main dependent variables used here reflect labor force statusduring the week of the Census survey.' Unfortunately, questions thatwould have identified \"discouraged\" workers during the survey week werenot asked.However, analyzing nonstudents separately picks up somepart of the often-neglected behavior of those who are not in school yetare neither employed nor unemployed. 1This measure of labor force behavior is the most common. Alter-natives are available: the number of weeks spent in unemployment and inemployment in 1979 are recorded for everyone 16 years and older in\" Public Use Microdata Sample C.\" Survey-week labor force behavior isrelated systematically to weeks and spells of unemployment over thecourse of a year; see Betsey (1978) and Hanoch (1976). Using survey-week behavior does not distinguish between the short-term and long-termunemployed.399 369Other variables available for all respondents include census region,type of area, householder status, age, race, marital status, disabil-ities, years of school completed, whether the respondent has everworked, and income status. For those with at least some employment in1979, earnings, usual weekly hours, and industry in which employed arealso available. Unfortunately, crucial variables that are not availableinclude actual hourly wages, the number of spells of unemployment in1979, the number of job offers refused during job search, and eligibil-ity for unemployment compensation. METWYOLOGYTwo basic methods are used in ttis analy's to compare black andwhite labor force behavior. Both aytempt to explain dummy variablesfor employment, unemployment, and nonparticipation. When black andwhite samples are combined, and when race is one of the independentvariables, the coefficient of race shows the increase in theprobability of the behavior, conditional on the other independentvariables, that can be attributed to being black. As in Freeman(1982), linear probability models (LPMs) are estimated because theyexplain quite simply some important relationships among the threedependent variables. Howeve., because of well-known econometricdifficulties with linear probabilities, logistic methods are used aswell .2Using both methods, linear and logistic, equations are estimatedfor two types of dependent variables, unconditional and conditional.Unemployment and employment equations are estimated both for the e,population and for labor force participants only. in these models, thecoefficients for conditional employment and unemployment have the samemagnitude, but different signs. The next section points out structuralinterpretations for the conditional equations; these reflect employerbehavior and make the unconditional equations reduced forms confoundingemployer and individual structural coefficients. OVERVIEW OF THE YOUTH UNEMPLOYMENT PROBLEMThe Many Faces of Unemployment Even though economists have produced a large literature onunemployment and take many separate approaches to the subject,' not 2See Nerlove and Press (1973:Ch. 2). The LPM predicts probabilitiesoutside the unit interval, is subject to heteroscedasticity, and ingeneral does not fit the statistical assumptions underlying leastsquares regression. 'Two important strands of this, literature are largely theoretical:macroeconomic general equilibrium and wage-search distributions. Hey400 370 much fundamental progress has been made in explaining unemployment. Anadequate economic explanation of ure 'nployment would separate relevantfactors reflecting the preferences of individuals for consumption ofgoods and uses of time from factors constraining individuals' choicesabout consumption and work. Moreover, such an explanation wouldsystematize many of the stylized facts about unemployment. Further,such an explanation would yield empirically testable hypotheses forexisting data about unemployment.One problem is that the same word, unemployment, is used to denotemany very different phenomena. For a long time, empirical work onunemployment among individuals has tried to classify such unemploymentas \"seasonal,\" \"cyclical,\" \"frictional,\" or \"structural,\" although ithas been recognized that a given spell of unemployment for a givenindividual might be very difficult to categorize. Seasonal and Cyclical UnemploymentOne sort of seasonal unemployment is a characteristic of certainoccupations, such as construction work. Workers committed to suchoccupations generally do not take other kinds of jobs during theoff-season, perhaps because their wages reflect compensating differ-entials for the known risk of unemployment at certain times of theyear.This sort of demand-side unemployment is unlikely to af)..ectyoung people, who generally have not yet committed themselves tooccupations.The failure of schools and colleges to stagger their vacationperiods produces another kind of seasonal unemployment,4 which can beattributed to the supply side of the youth labor market. A deluge ofbung people compete for relatively few jobs each summer. If the kindsof jobs young people take during their summer vacations paid lowerwages, some have argued,5 the problem would be smaller.Cyclical unemployment occurs less predictably and is tied to thebusiness cycle and to cycles of product demand within industries.There has been a great deal of recent work on the nature of long-termcontracts between firms and workers who are periodically laid offtemporarily and then rehired. Feldstein (1976) estimated that 75 (1981) provides a survey. Some important articles in the empiricalliterature are cited in the next section. 4However, Clark and Summers (1962:209) cite gross flow evidence thatdemand for young workers, on the whole, adjusted remarkably well toincreased supply during the summer over the years 1968-1976. Theysurmise from preliminary statistical work that federal NeighborhoodYouth Corps and CETA programs may explain their surprising findings onthis point.5See Brown (1981) for a survey of many of the issues surroundingminimum wage differentials for youth. 401 371percent of laid-off workers in manufacturing subsequently are rehiredby the same employer. He cited 1975 evidence that 41 percent ofunemployed men aged 25-64 who had been laid off had made no attempt tofind jobs during the previous month. However, since young people tendnot to have made s. commitments to particular firms or even toparticular industries, temporary-layoff theories are less-convincingexplanations for their unemployment than for the unemployment of olderworkers.The next subsection provides rough evidence that even cyclicalunemployment tied to the business cycle is less important for youngerpeople than for more-established workers. This lack of cyclicalsensitivity is reassuring, since elsewhere in the paper I focus oncross-sectional data pertaining only to March 1980 and calendar 1979. Cyclical Sensitivity of Youth UnemploymentBecause I talk about a single cross-section of individuals in theremainder of the paper, I do not have much to say about cyclicalinfluenc'-c on youth unemployment. How important are they?Persistent unemployment of at least 3.5 percent (measured as annualaverages of monthly Current Population Survey estimates) has afflictedthe U.S. civilian labor force since the mid-1950s. The aggregate ratefell from 5.5 percent in 1954 to 4.1 percent in 1956. Then it jumpedto 6.8 percent with the 1958 recession. It fell again to 5.5 percentin 1959 and 1960 and then rose abruptly to 6.7 percent for 1961. Withthe exception of a slight faltering in 1963, it fell steadily from its1961 level until it reached the post-1953 trough of 3.5 percent in1969, a war year. Since then, as Table 1 shows, it rose in 1970 and1971, fell in 1972 and 1973, rose through 1975 to a three-decade peak,and fell to the 1979 low preceding the most recent recession.Although the aggregate time series is sensitive enough to revealfamed trends, it masks a great deal of the labor market behavior thatdisaggregation reveals. Its addition to aggregate unemployment rates,Table 1 shows unemployment rates for certain sex, age, and race groups,including groups o. teenagers 16-19 years old. With the exception thatteenage unemployment was below 12 percent for the three years preceding1958, 1969 was the post-1953 trough for each of the disaggregatedseries as well as for the aggregate unemployment rate. But many of thedisaggregated series have kept the same rank relative to each otherever since 1950. Moreover, some of the series are much more stableover time than others.Table 1 shows coefficients of variation (ratios of standarddeviations to means) for the aggregate series and for 20 disaggregatedgroups for the period between 1972 and 1982. It also shows the rank ofeach coefficient of variation (c.v.) among the 21 coefficientsreported.The aggregate series ranks 14th at 21.09 percent. All 7groups of teenagers rank abo-e the aggregate series; in fact, theteenage groups account for 4 of the top 4 groups and 7 of the top 11groups.The coefficient for the top group, black women aged 16-19, isbarely a third of the aggregate coefficient. Atother end of the 402 TABLE 1Annual Averages of Monthly Unemployment Rates, Civilian Labor Force 16 and Older Ag-gre-gate20andOlder16-19Men20andOlderMen16-19Women20andOlderWomen16-19WhiteMen20andOlderWhiteMen16-19BlackMen20andOlderBlackMen16-19WhiteWomen26aodOlderWhiteWomen16-19BlackWomen20andOlderBlackWomen16-19Men16andOlderWhiteMen16andOlderBlackWhite BlackMenWomen Women from U S Department of Labor, Bureau of Labor Statistics, Handbook of Labor Statistics, Bulletin 2175 (Washington, DC US Department of Labor,1983) 68-72 41)3 BES1 COPYAVAILABLE4 4 373 scale, groups containing older men account for all of the bottom sixranks.Older women tend to rank just below the groups of teenagers.Thus, from a disaggregation of time series using coefficients ofvariation to index instability, it can be seen that older men'sunemployment is most susceptible to macroeconomic forces exerted on alldemographic groups over time, while teenage unemployment is influencedleast by such forces. Frictional Wage-Search Unemployment Frictional wage-search unemployment results from the dynamics oflabor markets. People move in and out of the labor market as they age,as their skills change, as wage levels rise and fall, and as familyneeds and financial fortunes vary.\u00b0 ,bs are created ; firms areestablished, as plants are opened it areas, am as older workersare forced to retire.' But it may t.e a few weeks for would-beworkers and firms with vacancies to search out and find each other. Ajob applicant might not take the first offer of wages and workingconditions, and a firm might not be willing to meet the first appli-cant's wage bid. Such \"search\" unemployment mil.ut affect young peopLedisproportionately more than adults,\u00b0 because they are making gradualtransitions from full-time schooling to full-time labor force partici-pation.Young people experiment with industries and occupations beforemaking lifet;me commitments. Sometimes they have parents to supportextended periods away from both school and the labor force, and some-times they might misreport such nonparticipation as unemployment.According to \"search theories\" of frictional unemployment,'heterogeneity among individuals and among firms leads firms -o searchfor workers and individuals to search for vacancies. The latter typeof search has virtually been identified with unemployment by many laboreconomists, usually under the restrictive assumption that the utilityfunction governing individual behavior is defined over discountedfuture wages, net of search costs but ignoring foregone leisure. \u00b0When movement into the labor force exceeds steady state levels,structural unemployment may arise in addition to frictionalunemployment.It may take some time for employers to adjust theirhiring and wage policies to ale increased supply of potentialemployees. 'Destruction of jobs by the same kinds of processes may lead tostructural unemployment for established workers at the same time thatit creates frictional unemployment for new entrants into the same oranother Job market.But see note 15 below.'See Hey (1981:Ch. 5) for an accessible survey of this literature. 405 374 According to these theories, every worker is unemployed because heturns down all proffered vacancies until he has been offered hisacceptance wage, The acceptance wage is the wage such that there is nomarginal gain in expected ulity from continuing to search. Thoughfirms search for workers, if only in the sense that they do notnecessarily hire the first applicant: for a given vacancy, most searchtheories tend to ignore this phenomenon snd attribute unemploymentsolely to workers' searching for firms. The testable assertion here- -that the unemployed have refused actual job offers--has not been pittedagainst empirical evidence very oftp\". But when it has been tested,the idea that most of the unemployed have refused wage offers has notfared well.\" Structural UnemploymentIn contrast to voluntary, frictional unemployment is the notion ofinvoluntary, structural unemployment, which is defined by Killingsworth(1978:22) as \"joblessness--usually long- term - -which results from basicchanges in the economic structure: new technology, the decline of someindustries and the growth of new ones, geographic relocation ofindustries, permanent changes in consumer tastes, changes in laborforce characteristics, and so on.\"\"For unskilled workers, among whom are most young people, legalminimum wages or high union wage scales may be an important barrier to \"For example, Rosenfeld (1977) has reported empirical work on the3,238 out of 4,668 unemployed in the May 1976 CPS who answeredsupplementary questions on their job-search behavior. The highnonresponse rate and low potential for disaggregation indicate a needfor more special surveys of this kind. Yet the implications of therespondents' answers for the validity of search unemployment theoriesseem clear.Since only 32 percent were on layoff, and wore than 81percent of laid-off workers reported some effort to find an interimjob, only 6 percent of the unemployment could have been seasonal orcyclical in the sense used in this paper. Search unemployment due tohigh acceptance wages seemed less than universal: 22 percent statedwillingness to accept jobs paying less than the federal minimum wage,then $2.30 per hour; another 33 percent were willing to take a wagebetween the minimum and $2.99; and only 22 percent reported anacceptance wage of $4.00 or more. Finally, only 10 percent of thosewho were unemployed four weeks or more and who had contacted at leastone employer reported having refused any job offers. \"Killingsworth (1978) recently retold the postwar history of thisold idea. 40c 375 employment.12In an important theoretical paper, Weiss (1980) showsthat even in the absence of legal minimum wages or union pay scales,firms may find it optimal to set wages fairly high and to refuse toemploy members of certain demographic groups, even though they arewilling to work for lower wages.At the risk of excluding some dislocated workers from thedefinition,\" the structurally unemployed may be thought of as thosewho have searched for jobs but fourd no employers willing to hirethem.This simple definition maximizes the contrast between frictionalunemployment and structural unemployment, while remaining consistentwith neoclassical labor economics. The frictionally unemployed willjoin the ranks of the employed as soon as they lower their acceptancewages.But lowering their acceptance wages will not help the struc-turally unemployed find work:14 they have not refused any wage offers.There is some empirical evidence that the notion that theunemployed are refusing wage offers is especially inappropriate foryoung men.\"If this is true, then empirical models of search See Demsetz (1961). But a legal minimum wage or union wage scaleneed not be binding constraints on employer behavior if there areother, higher, wage rigidities.\"Lucas (1978) seems to. We might conceivably argue that thelaid-off skilled steelworker in Pittsburgh who won't sell his house andtake a minimum-wage job is voluntarily unemployed, but we cannot argueas easily that an unskilled teenager who cannot get that same job isunemployed voluntarily.1Indeed, in Weiss's (1980) model it is precisely the positiverelationship between the acceptance wage and expected productivity thatcauses the unemployment of workers with low acceptance wages. CompareLucas (1978:354): \"The unemployed worker at any time can always findsome job at once. ...However miserable one's current work options,one can always choose to accept them.\"\"Stephenson (1976) analyzed 281 respondents of the 300 unemployedmales aged 18-21 with 8-12 years of education who sought full-time jobsin November 1971 at the Indianapolis state employment service office.He states (on p. 110): \"Nearly 90 percent of both white and blackyouths, when describing the search before their last job, said theytook their first offer. In contrast to the search literature whichusually implies a choice among several offers, the central searchproblem of young men may be to find a single offer.\" Cave (1983)exploits this insight in modeling unemployment among unskilledworkers.Of course, because of its self-selection, Stephenson's samplemay not be representative of all unemployed youth in Indianapolis atthe time. 407 376unemployment\" may not be appropriate for individual data on youthunemployment.Alternative models directly analogous to those used onaggregate data17 are proposed at the end of the next subsection. Implications for Empirical Work on Youth UnemploymentYoung people's behavior in labor markets is even more complex thanthe behavior of their elders. Unlike prime-age males, young peoplehave nonparticipation as a real option, and they exercise it often.Whether they are in or out of the labor market, they must make anotherconstrained '.voice their elders rarely face--whether to stay enrolledin school.Moreover, they work part-time rather than full-time moreoften than older people do. Empirical studies of youth labor marketsmust deal in some fashion with the ioint determination of schoolenrollment, military status, labor force participation, hours workedper week, and wages. There is important simultaneity between par-ticipation and the chance of unemployment if participation is chosen.There is also simultaneity between the number of years of education aperson has and the chance he or she will find a place in the laborforce.In addition to the simultaneity problems, there are problems ofdefini:ion for the labor force variables. Several very different kindsof behavior are reported as the same empirical phenomenon, \"youthunemployment.\" For someone who has quit school permanently and whocannot rely on family financial support, reported unemployment mayreflect a chronic inability to find any hours of employment at any wagelevel.This kind of involuntary, structural unemployment mayconstitute what Corant (1961) called \"social dynamite,\" anu it hasgrave implications for adult poverty and crime.\" At the other endof the spectrum of interpretations of these statistics, reportedunemployment in a particular week may reflect brief job search ornormal experimentation with possible careers. For someone who has \"Since the search literature is mainly theoretical, there are fewempirical search models to criticize. Kiefer and Neumann (1979, 1981)are careful to use data on permanently laid-off men for whom theirsophisticated search model seems especially appropriate.17For example, Fleisher and Rhodes (1976).\"Recent empirical work, though not conclusive because of poor data,tends to make Conant's fears seem ill-founded. Freeman and Wise (1982)briefly survey work that, based on longitudinal data, finds nosignificant effect of employment history or se on later labor forcebehavior, once persistent individual skill and motivation differenceshave been controlled for. But Cave (1981) and Levy (1982) criticizethese results as possibly reflecting unavoidable selection bias againstthe relatively small demographic group Conant worried about. 4C& 377 completed his or her education fairly recently, reported unemploymentmay reflect a single episode of leisurely job search or unrealisticwage expectations. Summer unemployment by those who have never leftschool ought to be treated as possibly the common experience of manyyoung people.Someone who has worked long enough in the past to beeligible for state unemployment compensation may misreport actualnonparticipation as unemployment.A further problem of definition arises because many chronicallyjobless youths may not show up in unemployment statistics at all.Discouraged workers are counted among those who are not even part ofthe labor force in a particular week. They may have been unemployedfor a long period in the recent past, they may be permanent school-leavers, and they may have low reservation wages, but unless theyengage in specific search activities they are not counted as part ofthe unemployed labor force. In addition to being too inclusive anindicator of chronic joblessness, youth unemployment may be tooexclusive.Another important statistical problem plaguing empirical work onyouth labor force behavior has sometimes been called \"ecologicalcorrelation bias\" (see Freeman, 1982:115).\" Much of the empiricalwork on unemployment has used the Standard Metropolitan StatisticalArea (SMSA), not the individual, as the unit of observation.20 Theproportion of variation in labor force behavior across areas that isgenerally explained by SMSA regressions is much higher than the pro-portion of variation across individuals that is explained by regressionsusing individuals. Individual regressions may attribute to individualcharacteristics (such as education, race, and family income) explanatorypower that really belongs to area variables (such as the density ofemployment opportunities) that are correlated with the individualcharacteristics. It is surprising that few studies of individual laborforce behavior have made use of area information that may be available(albeit at great cost) even in microdata.21 \"Rosen (1984), reporting on data from a BLS cooperativefederal-state statistical program, indicates that there is a great dealof variation in unemployment among local areas. In 1979, localunemployment rates ranged from 40 percent in Menominee County,Wisconsin, to less than 1 percent in Sioux County, Vebraska.20Examples are Gilman (1965), Kalachek (1969), Fleisher Freeman (1982). These SMSA regressions generallyexplain a much higher proportion of variation in SMSA unemployment thanis explained (typically well under 10 percent) in individualregressions. 21Abowd and Killingsworth (1984) are an exception, although one mightquibble with their choice of geographic area variables to match withindividual data. 409 378 Increasing the level of aggregation by using area characteristicsto eliminate a troublesome bias suggests making other analogies tolabor force models for more aggregated data. By direct analogy to arecent analysis by Fleisher and Rhodes (1976) using SMSA data, a modelto be estimated using microdata ought to have at least two simultaneousequations, one for a\" individual's probability of labor force partici-pation and one for his probability of unemployment conditional on laborforce participation. In the participation equation, a coefficient onthe unemployment probability would give the discouraged worker effect,while a coefficient on an unemployment dummy variable for other membersof the household would give the added-worker effect. If a separateconditional unemployment probability equation was estimated for eachlabor market, using only the young labor force participants in thatlabor market, the ecological correlation problem might be reduced. A Structural Model for the Youth Labor MarketAn alternative and even more direct approach to these problems ofmodeling the youth labor market is available. An appropriate, thoughlikely quite expensive, empirical framework might generalize recentwork by Heckman (1979) in the following way.Suppose that a microdata sample has i young people, and that eachindividual is revealed to live in one of i geographic areas, which maybe considered separate labor markets. Let Mi, Ui, Ni, and Sibe dummy variables for individual i for unconditional employment,unemployment, nonparticipation, and school enrollment, respectively.Let j(i) be the geographic area in which individuate i lives. LetZi(i) be a vector of characteristics (such as the proportion ofworking-age people who are young and the fraction of jobs that do notrequire much skill) associated with area j(i). Let Xi be a vector ofcharacteristics (such as number of years of schooling and area typewithin the geographic area) specific to individuals. Let w(i) be thewage for individual i.Then consider the simultaneous equations uses some of the findings inthe literature on the youth labor market to impose an empiricallytestable structure on microdata.22 For example, the hypothesis of 22Most likely, the best data set for this purpose is the 1976 Surveyof Income and Education. It is three times as large as the monthly CPSand has more wage and geographic data revealed for individuals thandoes the census microdata. Abowd and Killingsworth (1984) and Freeman(1982) chose it. 410 379Fearn (1968) that unemployment may be strongly associated with schoolenrollment ana that wages have a week effect could be tested directlywith the third equation; the second equi-tion would pick up anydiscouraged-worker effect as a negative coefficient on unemployment;and so on.Musa; of the difficulty in empirical work on the youth labor marketstems from fairly complex sample- selection problems, which the modelpresented here could capture. Wages ire observed only for those whoare employed; for everyone else, they must be imputed. Most important,conditional unemployment is observed only for those who participate inthe labor force; a conditional probability of unemployment must beimputed to tnose who are out of the labor force. By straightforwardextension of Herkman's work, a multivariate, normal-error structure forthe four equations could accommodate this sample selection and thuscapturi informA_cion that might be otherwise lost. To reduce thecomputational complexity and cost, the last two equations could bedropped and wages ignored, which would produce a microeconometric modelmore like the Fleisher-Rhodes model for SMSA data. NONSTUDENT TEENAGERS, AGED 16-19Sample Selection ano Descriptive StatisticsTable 2 shows h-w two groups of black male teenagers were selectedfrom the 1980 Census 1 percent Sample C, and how two groups of whitemale teenagers were chosen from the 0.1 peznent C subsample. Table 3shows how four similar groupr of black and white female teenagers werechosen for analysis. Of 12,09u black males aged 16-19, 340 were inmatesof institutions; 54 of 6,950 whites were inmates. Of the remaining11,750 black and 6,896 white male teens, 3.7 percent and 2.4 percent,respectively, were in the armed forces. (The 8,239 black male studentsand 4,856 white male students will be discussed below.) There remain3,082 black male civilian noninmate, nonstudents, 1,805 of whom arelabor force participants. In addition, 1,875 white civilian noninmate,nonstudent male teens have been selected, 1,577 of whom are labor forceparticipants.Almost 56 percent of the black male noninmate, non-students are located in the Census Bureau's \"South\" region; little morethan 6 percent live in the \"West.\" In contrast, the white nonstudentsare distributed more evenly. As in the ci:le of the blacks, the Southhas the largest share of the sample population and the West has thesmallest, but the shares range only between 18 and 33 percent.Tables 4(a)-4(h) present descriptive statistics for the four blacksamples and the four white samples. The tables reveal some verystriking gross racial differences in labor force behavior. First, 41.4percent of the black males, but only 15.9 percent of the white males,are out of the labor force as well as out of -chool. Employment-populatior. ratios are 68.6 percent for white males and 40.7 percent forblack males.Among labor force participants, the white maleunemployment rate is 18.5 percent, but the black male unemployment rate 411 TABLE 2 Sample Selection: Civilian, nstudent, Teenage Labor Force Participants, Males SAMPLE SELECTION BLACK SAMPLE:Nonwhite Male Teensless Other RacesB irk Male TeensIcss Microdata Sample C' (Washington, D C . U.S. Department of Commerce, 1983) blacks, noninmate 1 percent sample;whites, noninmate 01 percent subsample.412 BEST COPY AVAILABLE TABLE 3 Sample Selection: Civilian, Nonstudent, Teenage Labor Force Participants, Females SAMPLE BLACK SAMPLE:SELECTION NENCSOWU.S.Black Civilian Noninmate Female Teens the Census, \"Public -Use Microdata Sample C\" (Washington, D.C. U S Department of Commerce, 1983) blacks, noninmate 1 percent sample,whites, noninmate 0 1 percent \"Public-Use Microdata Sample C\" (Washington, DC US Department of Commerce, 1983) blacks, noninmate 1 percent sample, whites, noninmate 0 1 percent subsample TABLE 4(b)Civilian, Nonstudent \"Public-Use Microdata Sample C\" (Washington, D.0U S Department of Commerce, 1983) blacks, noninmate 1 percent sample, whites, noninmate 0 1 percent subsample414 415 TABLE 4(c)Civilian, Nonstudent Teenage Labor Force Participants, Male Census, \"Public-Use Microdata Sample C\" (Washington, DC US Department of Commerce, 1983) blacks, noninmate 1 percent :qmple, whites,noninmate 0 1 percent subsample TABLE 4(d)Civilian, Nonstudent Teenage Microdata Sample C\" (Washingtor., DC US Department of Commerce, 1983) blacks, noninmate 1 percent sample, whites,noninmate 0 1 percent subsample 416 417 TABLE 4(e)Civilian, Female Census, \"Public-Use Microdata Sample C\" (Washington, DC US Department of Commerce, 19831blacks, noninmate 1 percent sample, whites,noninmate0 1 the Census, \"Public-Use M1cr3data Sample e (Washington, DC US Department of Commerce, 1983? blacks, noninmate 1percent sample, whites,noninmate0 1 percentsubsample.41b 419 TABLE Microdata Sample C\" (Washington, D.0 U.S Department of Commerce, 1983) blacks, nonmmate 1 percent sample, whites,noninmate0 1 percentsubsample. TABLE 4(h)Civilian, Nonstudent Teenage Labor Microdata Sample C\" (Washington,13 C U 55.4 percent of the blacksand 32.3 percent of the whites were out of the labor force as well asout of school. Among the rest of the young women, the unemploymentrate was 32.2 percent for blacks and 13.5 percent for whites.As one might expect, considering the transition from school to workthat they are making, nonstudent teenagers who participate in the laborforce are a bit older and have completed a bit more education than thegroup as a whole, regardless of race or sex. But it is surprising that1979 household income, excluding the teenager's 1979 earnings, isgreater for the labor force participants than for the group as a whole.Among the young men, the effect is much larger among black teenagersthan among the white group. Among the young women, the differencebetween means is slightly larger for whites.The fraction of black male nonstudents who are out of the laborforce is 2.6 times the fraction of white males; this ratio is 1.7 forfemales.So one important question is, What accounts for the tremendousdifferences in labor force participation rates? In particular, whatproportion of each racial group is made up of probable discouragedworkers? Labor Force Status Without placing too restrictive a structure on the data, participa-tion, employment, and unemployment can be expected to be related toage, region, area type, years of education completed, a marital statusdummy variable (FAM), disability, and household income net of theteenager's earnings. Region may to some extent reflect the structureof wages and job availability in local economies. Area type wouldcapture some of these same forces but, unlike region, would be highlycorrelated with individual and family characteristics. Since youngpeople generally make gradual transitions from school to work, years ofeducation completed, especially those in excess of 7.2, ought toincrease labor force participation and employment. The greater \"When these labor force and unemployment statistics for nonstudentsare added to those reported in Table 8 for students, nationalunemployment rates comparable to those reported by the BLS emerge.Theimplied rates are 14.6 percent for white male teens and 26.9 percentfor black male teens. The period census respondents were asked aboutoverlaps with two BLS survey periods, those for March and April 1980.Unemployment rates, not seasonally adjusted, from Employment andEarnings, bracket neatly the white teenage rate in this paper. Whitemale teenage unemployment as a percentage of the civiliannoninstitutional labor force aged 16-19 was 14.1 percent for April and14.7 percent for March. However, the analog here to the volatile\"black and other\" teenage unemployment rate reported by the BLS is notas close; those BLS rates were 27.7 percent for April and 32.3 percentfor March. 4 '22 387 financial responsibilities of mairied teenagers ought to increase theirparticipation and make voluntary unemployment, but not involuntaryunemployment, less likely for them. A disabled teenager ought to beless likely to participate in the work force and less likely to findemployment when he does. Low household income ought to impel a teenagerinto the work force, but it might also reflect poor job opportunitiesfor every member of the family, or serve as a proxy variable for poorer-quality schools.Exploratory regressions were run using these and other variables toexplain unconditional and conditional labor force status in subsamplesof young men of the same race. Repeated attempts to use three regionaldummies (for North Central, West, and South) and three area type dummies(for rural, urban outside urban area, and central city) generally wereunsuccessful for participation, employment, and unemployment equationsin all subsamples. Only the dummy variables for central city area andfor the South region consistently were significant; often, the Southcoefficient was large and extraordinarily significant. Thus, in thelinear and logistic regressions reported here, central city and Southare the only geographic dummy variables used. Intercepts pick up,along with other unidentified effects, the unidentified contributionsof living outside the South and outside the central city. Gross Effect of Race on Unemployment In Tables 5(a)-5(d), linear probability models of multiple choiceare used to show quite clearly the gross racial differentials in thelabor force behavior of young people. The table has four parts. Inparts (a) and (b), all young men aged 16-19 who were not enrolled inschool are included. In parts (b) and (d), only nonenrolled laborforce participants are included. In each model, the intercept issimply the value for whites, while the coefficient on color gives theracial difference. For example, in \"MODEL03\" of part (a), just as inTable 4(b), precisely 15.8933 percent of male white teenagers are seento be out of the labor force. The figure for blacks is 25.6908 percenthigher, for a total black male percentage of 41.584. This figure isslightly different from the 41.4341 percent given in Table 4(a) because there are only one-tenth as many blacks as before. Because unemploy-ment, employment, and nonparticipation partition the sample in (a), theintercepts in the first three equations must sum to unity and thecoefficients must sum to zero.\" \"Pindyck and Rubinf3ld (1981:301-303) provide the trivial andtedious details. In essence, even when X and Y are dummy variables,LPM coefficient estimates are computed using the usual OLS formula, b =(X'X)-1X'Y.The first factor, the inverted cross-product matrix,contains totals of individuals of each race to be used as thedenominators of the coefficient estimates. The second factor has thecounts of labor force status by race to be used as numerators. 423 388 TABLE 6(a)Linear Probability Microdata Sample C\" (Washington, D C : U S.Department of Commerce, 19831' blacks, noninmate 1 (Washington, D.C. U.S.Department of (Washington, U.S.Department U.S.Department whites, noninmate 0.1percent subsample. t425 390 What should we use as our measure of youth ursmployment? Should weuse the unconditional ratio of the number of unemployed to the size ofthe cohort displayed in parts (a) and (c) of Table 5, or should we usefrom parts (b) and (d) the rate of unemployment conditional on partici-pation in the labor force? If we choose the first option, we need gono further in our analysis of youth unemployment. For both young menand young women, \"MODEL01\" shows that the race differential is smalland insignificantly different from zero.\" In that case, our emphasismust be on the lower labor force participation rates and loweremployment-to-population ratios of blacks.\"Clearly, we must focus attention on conditional measures ofunemployment if we are to say anything sensible about racial differ-ences in youth unemployment. The much lower labor force participationof blacks and their krIgher unemployment rates tend to cancel out eachother completely in unconditional measures of unemployment. But\"MODEL21\" in Table 5(b) shows thr.t the gross male racial differentialis 12.6 percent and significant27 when we use a conditional measureof unemployment. Since 12.6 percent is less than the 18.5 percentunemployment rate for whites, however, among nonstudent male teenagersthe widely believed, roughly two-to-one ratio of black unemployment towhite unemployment was too pessimistic by one-third on census day in1980; it was only 1.68.What happens to the gross differential when we correct for region?\"MODEL31,\" Table 5(b), tells us that the ratio of black to white maleyouth unemployment rates was 2.25 outside the South but only 1.52 inthe South.\"The corresponding ratios for women are 2.5 and 2.0, 25The asymptotic t-statistic for a logit version of \"MODEL\u00b01\" is only1.16; the LPM does not lead us astray here. \"Freeman (1982:116) gives as one of four \"basic findings\" thefollowing:\"Because determinants of youth unemployment often have tisame directional impact on labor force participation rates as onemployment, [they] have little effect, or occasionally a contradictoryeffect, on unemployment rates. This suggests that anall4es focusing onunemployment can give misleading impressions about the determinants ofthe youth labor market position.\" Indeed, the advance title of theconference at which Freeman presentEl his important paper was not \"TheYouth Labor Market Problem,\" but rather \"Youth Unemployment.\" Theapproach here permits a more direct attack. 27The from the logistic regression, 3.94,confirms the LPM LPM framework gives unemployment rates for white Southerners,black non-Southerners, and black Southerners as sums of thecoefficients.For example, the rate for black Southerners is the sumof all four coefficients. 426 391.Table 5(d).These differences reflect larger regional differentials inunemployment rates for blacks than for whites, especially among youngmen.The unemployment rate for southern black males was only 42percent of the rate for nonsouthern black males, while the geographicratio of unemployment rates for white males was much higher, at almost63 percent.From Table 4(a), we know that an astounding 56.8 percentof the black male, nonstudent labor force participants live in theSouth.Were this not so, the national ratio of male unemployment ratesby race would be much higher than 1.68. Gross Effect of Race on Other Labor Force Status VariablesTable 5 shows that what was said before about the linear probabilitymodel was correct; in any set of LPM regressions of dependent variablesthat partition the sample, the intercept coefficients must sum to unityand the slopes to zero When, as in part (b), just two labor marketstates partition the sample, one of the two LPM regressions is redun-dant.In \"MODEL22,\" the intercept is the difference between unity andthe intercept in \"MODEL21.\" This simply means that the rate of whiteemployment, conditional on labor force participation, is one minus thewhite unemployment rate. The slope restriction simply ensures that theracial difference in conditional employment rates has the same absolutevalue as the racial difference in unemployment rates.In parts (a) and (c) of the table, the race coefficients forunconditional employment and nonparticipation show how the uncon-ditional unemployment ratios came to be nil. Among males, a 28.3percent gross racial differential in employment-to-population ratios isoffset almost exactly by a 25.7 percent racial differential in laborforce participation. Among females, a 31.2 percent gross racialdifferential in employment-population ratios is offset by a 28.5percent racial differential in labor force participation. Structural Interpretation There are two strikingly different structural interpretations forthe racial differential in labor force participation. Freeman (1982)and others have found little difference between the wages of employedblack and white young people.\" Heckman (1974), implementing neo-classical labor force participation theory empirically, shows how awoman observed outside the labor force can be modeled as having animputed market wage below her personal reservation wage.If Heckman'smodel is applied to the youth labor market, ignoring unemployment, then 2'Freeman (1982:142) reports S1E log hourly earni.,gs regressionsshowing only a disadvanta4e for blacks aged 18-19 and blacksaged 20-24.For 16-17 year olds, he reports an actual wage advantageof 17 percent for blacks. 427 392an explanation for lower black participation is higher black reservationwages.On the other hand, if the analogy to macroeconomic modelsposited above is maintained, the lower black participation is adiscouraged-worker effect consistent with the higher black unemploymentrate. he Effect of Additional Explanatory Variables For the reasons stated above, it might be unwise to place muchfaith in structural estimates of the effect of race on unemploymentbased on single-equation techniques, or even on system techniques,ignoring the complex sample selection used to generate data on youthunemployment, wages, and school enrollment. Thus far, the focus hasbeen on merely measuring gross effects of race on unemployment. Theestimates presented in this section should be considered much moretentative, because of the many sources of bias that have not beencorrected here.Tables 6(a)-6(d) present estimates of conditional unemploymentprobabilities for nonstudents. In parts (a) and (c) of the table, theuse of age as a regressor reduces the strong impact of years ofeducation that is present in parts (b) and (d); in fact, age replaceseducation as the greatest reducer of chi-square. Southern locationkeeps the strong negative effect on the chance of male unemploymentthat it had in the LPN. The failure of household income to explainmuch variation in male -,-employment is wirprising if unemployment isvoluntary search; perhaps replacing household income with a dummyvariable foinemployment of the head of the household would produce astronger ei. _t. Race has the largest effect of all the dummyvariables and still seems to have a strong impact on unemployment.In par*s (a) and (c) of Table 7, there is still no significantracial difference in unemployment ratios even after adjustment forother individual charactsristics. Parts (b) and (d) of the table showhow race affects ronparticipation when no discouraged-worker effectshave been permitted to occur in the equati.on. Comparison of parts (b)and (d) of Table 7 shows how remarkably the effect of marital status(FAM) differs by sex. There is no independent effect of southernlocation on young women's participation, even though the effect isstrong for young men. STUDENT TEENAGERS, AGED 16-19Sample Selection and Dencript ye StatisticsParts (a) through (d) of Table 8 contain descriptive statistics for4,856 white male students from the 0.1 percent C subsample and for8,239 black male students from the full 1 percent sample. Parts (e)through (h) give the same statistics for 4,811 white and 8,505 blackfemale students. These statistics contrast sharply with those in Table4(a) 4(h) for nonstudents. A very high proportion of all groups was 423 393 TABLE 6(a)Conditional Unemployment Probabilities Using Age as a Regressor,Dv: lian, Nonstudent Labor Force Participants, Male Teenagers 1754 OBSERVATIONS346 POSITIVES1408 NEGATIVFS0 OBSERVA IONS DELETED TO MISSING VALUES -2 LOG LIKELIHOOD FOR MODEL CONTAININGCONVERGENCE OBTAINED IN 5 ITERATIONS. MAX U.S.Department POSITIVES1408 NEGATIVES0 OBSERVATIONS DELETED DUE TO MISSING VALUES -2 LOG LIKELIHOOD FOR MODEL CONTAINING INTERCEPT ONLY= 1742.02CONVERGENCE OBTAINED IN U.S.Department COPY AVAILABLE429'1f 394TABLE 6(c)Conditional Probabilities Using Age and Education asa Regressor, Civilian, Nonstudent Labor Force Participants, OFIONS1227= 0218 =10 Our_RVATIONS DELETED DUE TO MISSING VALUES -2 LOG LIKELIHOOD FOR MODEL CONTAINING INTERCEPT ONLY 1225.96MODEL CHI-SQUARE= 82.93 WITH10 C\" (Washington, D.C. U.S.Department of Commerce, 1 percent sample; whites, 0.1percent subsample VARIABLE: U 1445 OBSERVATIONS1227U= 0218U=10 OBSERVATIONS DELETED DUE TO MISSING VALUES -2 LOG LIKELIHOOD FOR MODEL CONTAINING INTERCEPT ONLY 1225.96MODEL CHI-SQUARE= 70.27 WITH9 U.S.Department COPY AVAILABLE iikv74430 Unemployment Probabilities Using Age as a Regressor,Civilian, LOGISTIC REGRESSION PROCEDUREOEPENDENT VARIABLE: U 2178 OBSERVATIONS346 POSITIVES1832 NE.ATIVES0 OBSERVATIONS DELETED DUE TO MISSING VALUES -2 LOG LIKELIHOOD FOR MODEL CONTAINING INTERCEPT ONLY 1906.96CONVERGENCE OBTAINED IN 6 ITERATIONS. 0=0.019. MAX U.S.Department N 2178 OBSERVATIONS424 POSITIVES1754 NEGATIVES0 OBSERVATIONS DELETED DUE TO MISSING VALUES -2 LOG LIKELIHOOD FOR MODEL CONTAINING INTERCEPT ONLY 2147.20CONVERGENCE OBTAINED IN 6 ITERATIONS. D=0.122. MAX Sample C\" (Washington, D C .U.S.Department of Commerce, blacks, noiinmate 1 percent sample; whites, noninmate 0.1percent subsample. BEST COPY AVAILABLE-431 396 TABLE 7(c)Unconditional Unemployment Probabilities Using Age as a Regressor,Civilian, Nonstudent Female Teenagers LOGISTIC REGRESSION PROCEDUREDEPENDENT VARIABLE: U 2280 OBSERVATIONS2062U= 0218U=10 OBSERVATIONS DELETED DUE TO MISSING VALUES -2 LOG LIKELIHOOD FOR MODEL CONTAINING INTERCEPT ONLY= 1437.94MODEL CHI-SQUARE= U.S.Department sample; whites, noninmate 0.1percent subsample. VARIABLE: N 2280 OBSERVATIONS1445N= 0835N=10 OBSERVATIONS DELETED DUE TO MISSING VALUES -2 LOG LIKELIHOOD FOR MODEL CONTAINING INTERCEPT ONLY= 2995.54MODEL CHI-SQUARE= 461.55 WITH10 (Washington, D.C. U.S.Department of 1 percent sample; whites, 0.1percent subsample. BEST COPY AVAILABLE 432 TABLE Statistics: Teenagers, Male Blacks Census, \"Public-Use Microdata Sample C\" (Washington, D C.. U.S. Department of Commerce, 1983) blacks, noninmate 1 percent sample; whites, noninmate 0 1 percent subsample TABLE 8(b)Descriptive Statistics: Male Sample C\" (Washington, D.C.: U.S Department of Commerce, 1983): blacks, noninmate 1 percent sample,whites, noninmate 0 1 percent subsample. BEST COPY AVAILABLE 433 TABLE 8(c)Descriptive Statistics: Civilian, Student Teenage Labor Force Participants, Male Blacks Census. \"Public-Use Microdata Sample C\" (Washington, D C. U S. Department of Commerce, 1983) blacks, noninmate 1 percent sample; whites,noninmate 0 1 percent subsample TABLE 8(d)Descriptive Statistics: Civilian, Student Teenage Labor Force Participants, Male Whites \"Public-Use Microdata Sample C\" (Washington, D.C. U S. Department of Commerce, 1983) blacks, noninmate 1 percent sample, whites,noninmate 0 1 AVAILABLE434 Ivi.vii:',., \"Public-Use Microdata Sample C\" (Washington, 0 C U.S Department of Commerce, 1983) blacks, noninmate 1 percent sample; whites, nonrimate 0 1 percent subsample TABLE 8(f)Descriptive Statistics: Microdata C\" (Washington, DC.US Department of Commerce, 1983) blacks, noninmate 1 percent sample; whites, ncommate 0 1 percent subsample BEST COPY AVAILABLE 435 TABLE 8(gDescriptive Statistics: Civilian, Student Teenage Labor Force Participants, Female Blacks Sample C\" (Washington, D.0 U S. Department of Commerce, 1983). blacks, noninmate 1 percent sample; whites, noninmate 0 1 percent subsample TABLE 8(hDescriptive Statistics: Civilian, Student Teenage Labor Force Participants, Female Whites Sample C\" (Washington, D.C. U.S. Department of Commerce, 1983): blacks, nonmmate 1 percent sample; whites, nonmmat, 0 1 percent subsample. BEST COPY AVAILABLE436 401 out of the labor force, as one might expect for students at the middleof the spring term in 1980--56.2 percent of 411 white male students and74.2 percent of the black male students did not participate in thelabor force.The black-white ratio is only 1.32, just half the ratioof participation rates for black and white nonstudents reported in the last section.Employment-to-population ratios, however, are worse forblack students relative to white students than they were for blacknonstudents relative to white nonstudents. The fraction of all whitemale students who had jobs was 38.6 percent; this was 1.97 times thefraction of all black male students who had jobs. The ratio for malenonstudents wa. only 1.67. The employment-population ratio for whitefemale students was 38.2 percent, 2.06 times the ratio for black femalestudents.However, 2.06 is almost as high as 1.94, the analogous ratiofor female nonstudents. Labor Force ParticipantsOf the 4,856 white male students, 2,125 were labor force partici-pants; 2,123 of the 8,239 black students were participants. Even thoughthe original sample contained 2.2 million people, only 505 unemployedblack male teen students made it into this final group.Of the 2,125white student participants, 205 were unemployed. This means that theblack unemployment rate among teenage students was 23.8 percent, whilethe white unemployment rate was 11.8 percent. Note that the ratio ofthe black rate to the white rate is worse for male students than it wasfor male nonstudents: 2.02, compared with 1.65 as computed from Table4, or compared with 1.68, as computed from the LPM regressions on the0.1 percent sample reported in Table 5(a).Table 8(h) shows that 2,013 of the 4,811 white female students werelabor force participants; part (g) of the same table shows that 2,065of the 8,505 black female students participated in the labor force.Some 176 of the whites and 489 of the blacks were unemployed, whichyields female student rates of 8.7 percent and 23.7 percent, respec-tively.The black-white ratio of female student unemployment ratescomputed from this table 4s 2.71. Since parts (g) and (h) of Table 4imply a nonstudent ratio of 2.38, the racial ratio of unemploymentrates is worse for female students as well as for male students. Gross Effect of Race on Unemployment In Tables 9(a)-9(d) are linear probability models exactly likethose in Table 5, but this time they are estimated for students.\"MODEL01\" of Table 9(a) shows that the gross racial differential inmale unemployment-population ratios was 1.55 percent and of marginalstatistical significance.\" Part (c) of the table shows a slightly \u00b0I.T-7.1cethe LPM coefficient, the logistic coefficient is small andbarely significant at the 7 percent level. In the sample restricted tolabor farce participants, the logistic coefficient on race is large and has an asymptotic t-statistic of 5.8.437InI. 402 TABLE 9(a)Linear \"Public-Use Microdata Sample C\" (Washington, DC USDepartment of Commerce, 1983) blacks, noninmate 1 percent sample, whites, noninmate0 1 percent subsample. TABLE 9(b)Linear Probability Models: (Washington, D.C. U SDepartment of Commerce, 19831. blacks, noninmate 1 percent sample, whites, noninmate0.1 percent subsample.438BESTCOPYAVkl_iiiia 403TABLE 9(c)Linear Probability Models Civilian, C\" D C. U SDepartment of Commerce, 19P3) blacks, noninmate 1 percent sample, whites noninmate0 1 percent subsample TABLE 9(d)Linear Probability Models: eon, D.0 U SDepartment of Commerce, 1983' blacks, noninmate 1 percent sample, whites, noninmate0 1 percent subsample 439BEST COPY AVAILAFBLE 404 more significant racial differential of 1.38 percent for females.However, as was the case for nonstudents, a regression for a samplerestricted to labof force participants tells a very different story.Table 9(b) gies as the gross differential between black and whitmale student unemployment rates a highly significant 14.6 percent.This difference is greater than the white unemployment rate, 11.8percent.When computed from this regression, the ratio of black towhite student unemployment rates is 2.26. When computed from Table 8the ratio is 2.02. Once again, the difference between the two computa-tions stems from the reduced sampling error in the tenfold largersample summarized in the earlier table. NMODEL31\" shows that, onceagain, the racial differential is larger outside the South than in theSouth.Part (d) of Table 9 shows a gross female student racial unemploymentdifferential that is very close to the male differential; 't is 14.5percent ard highly significant. \"MODEL31\" shows something differentfor women, however. The implied ratios of black to white studentunemployment rates are 2.89 in the South and 2.56 outside the South.For men, the ratio was larger outside the South. Effect of Additional Explanatory Variables Tables 10(a)-10(d) show the same equations for students that wereestimated for nonstudents in Table 6. There are two dramatic changes.First, for male students but not for female students, race loses itssignificant effect entirely, regardless of whether age is included.Second, for male students but not for female students, householdincome, net of the teenager's earnings, energes from insignificance asa strong explainer of variation in unemployment. When age is includedin the equation, household income is the greatest reducer of chi-squarefor young mn, stronger even than education. SUMMARY This paper presented a very brief review of the economic literatureon unemployment, in particular thr i- plications for empiricai. work onyouth unemployment and labor force participation. New structural modelsfor use with microdata were developed. These models may reduce 4-woimportant sources of bias in estimates of the impact of race onunemploimfmt:simultaneity and ecological correlation.Original empirical work based on 1980 Census microdata shows, usingsimple, single-equation methods, that the labor force participationdecision cannot be ignored in estimating the impact of race onunemployment.For students and nonstudents, male and female, there isno gross racial differential to be explained if unemployment is measuredas the ratio of the number of unemployed to the size of the population.However, when samples are restricted to labor force participants, largeand significant racial differentials emerge. These racial differentialsvary by sex, region, and school enrollment status. A racial difference 440 405TABLE 10(a)Conditional Employment Probabilities Using Age as a Regressor,Civilian, Student Labor Force Participants, Male TeenagersLOGISTIC REGRESSION PROCEDUREDEPENDENT VARIABLE: U 2328 OBSERVATIONS304 POSITIVES2024 NECATIVES0 OBSERVATIONS DELETED DUE TO MISSING VALUES -2 LOG LIKELIHOOD FOR MODEL CONTAINING INTERCEPT ONLY= 1804.18CONVERGENCE OBTAINED IN 6 D.C. U 2328 NEGATIVES0 OBSERVATIONS DELETED DUE (0 MISSING VALUES -? LOG LIKELIHOOD FOR MODEL CONTAINING INTERCEPT ONLY= 1804 18CONVERGENCE (Washington, D.0 U SDepartment of Commerce, 1983) blacks, noninmate 1 percent sample. whites, noninmate 0 1percent subsample. BEST COPY AVAILABLE441 406TABLE 10(c)Conditional Employment Probabilities Using Age as a Regressor,Civilian, Student Labor Force Participants, Female Teenagers LOGISTIC REGRESSION PROCEDUREDEPENDENT VARIABLE: U 2202 OBSERVATIONS1987U=0220U 10 OBSERVATIONS DELETED DUE TO MISSING VALUES -7 Sample C\" (Washington, D C. U.SDepartment of Commerce, 1983) blacks, noninmate 1 percent sample, whites, noninmate 0 1percent subsample. TABLE 10(d)Conditional Employment Probabilities, Civilian, Student LaborForce Participants, Teenagers LOGISTIC REGRESSION PROCEDUPEDEPENOrN1 VARIABLE: U 2202 OBSERVATIONS1982U= 0220U=10 OBSERVATIONS DELETED DUE TO MISSING VALUES -7 LOG LIKELIHOOD FOR MODEL CONTAINING Microdata Sample C\" (Washington, DC USDepartment of Commerce, 1983) blacks, noninmate 1 percent sample, whites, noninmate 0 1percent subsample BEST COPY AVAILABLE 4414-.x'. in labor force participation tends in each case to offset almost com-pletely the racial difference in the unemployment rate, so that thereare no significant differences in unemployment-population ratios tyrace.Two very different structural interpretations of these findingsare higher reservation wages for blacks and discouraged-worker effects. REFERENCES Abowd, John M., and Mark R. Killingsworth1984 Do minority/white unemployment differences really exist?Journal of Business and Economic Statistics 2(1):64-72.Betsey, Charles L.1978 Differences in unemployment experience between blacks andwhites.American Economic Review 68(2):192-197.Brown, Charles1981 Estimating the effects of a youth differential on teenagersand adults.Pp. 389-427 in Report of the Minimum Wage StudyCommission.Vol. 5.Washinr:on, D.C.: Minimum Wage StudyCommission.Bureau of the Census1983 Census of Population and Housing, 19d0: Public-Use MicrodataSamples Technical Documentation. Data User ServicesDivision.Washington, D.C.: Bureau of the Census.Cave, George1981 The Incidence and Duration of Unemployment. Final Report tothe U.S. Department of Labor under Grant No. 91-17-78-17.Springfield, Va.: National Technical Information Service.1983 Job rationing, unemployment, and discouraged workers. Journalof Labor Economics 1(3):286-307.Clark, Kim B., and Lawrence H. Summers1982 The dynamics of youth unemployment. In Richard Freeman andDavid Wise, eds., The Youth Labor Market Problem: Its Nature,Causes, and Consequences. Chicago, Ill.: University ofChicago Press.Conant, James B.1961 Social dynamite in our large cities. Pp. 26-42 in SocialDynamite:The Report of the Conference on Unemployed,Out-of-School Youth in Urban Areas. Washington, D.C.:National Committee for Children and Youth.Demsetz, Harold1961 Structural unemployment: a reconsideratic of the evidenceand the theory. Journa.. of Law and Economics4(October):80-92.Fearn, Robert M.1968 Labor Force and L,chool Participation, of Teen2ejers. :.ion.Department of Zconomics, University of Chic o.Feldstein, Martin S.19/6 Temporary layoffs in the theory of unemployment. Journal of2olitical Economy 84(5):937-957. 443 408 Fleisher, Belton, and George Rhodes1976 Unemployment and the labor force participation of married menand women:a simultaneous model. Review of Economics andStatistics 58(4):398-406.Freeman, Richard B.1982 Economic determinants of geographic and individual variationin the labor market position of young persons. Pp. 115-154 inRichard Freeman and David Wise, eds., The Youth Labor MarketProblem: Its Nature, Causeg and Consequences. Chicago,Ill.:University of Chicago Press.Freeman, Richard B., and David A. Wise1982 The youth labor market problem: its nature, causes, andconsequences.Pp. 1-16 in Richard Freeman and David Wise,eds., The Youth Labor Market probl--1: Its Nature, Causes LandConsequences.Chicago, Ill.: University of Chicago Press.Gilman, Harry J.1965 Economic discrimination and unemployment. American EconomicReview 55(5, Part 1):1077-1096.Haw,ch, Giora1976 Hours and week in the theory of labor supply. R-1787-HEW.Santa Monica, Calif.: Rand Corporation.Heckman, James J.1974 Shadow prices, market wages and labor supply. Econometrica42(4):679-694.1979 Sample selection bias as a specification error. Econometrica47(1):153-161.Hey, John D.1981 Economics in Disequilibrium. Oxford: Martin of employment. Journal 4(1):3-21.Kiefer, Nicholas, and George Neumann1979 An empirical job-search model, with a test of the constantreservation-wage hypothesis. Journal of Political Economy87(1):99-107.1981 Estimation of wage offer distributions and reservation wages.In S. Lippmann and J. McCall, eds., Studies in the Economicsof Search.Amsterdim:North-Holland.Killingsworth, Charles C.1978 The fall and rise of the idea of structural unemployment.Industrial Relations ReseLrch Association Proceedings31(August) :1-13.Levy, Frank1982 Comment.P. 340 in Richard Freeman and David Wise, eds., TheYouth Labor Market Problem: Its Nature, Causes, andConsequences.Chicago, Ill.: University of Chicago Press.Lucas, Robert E., Jr.1978 Unemployment policy. American Economic Review 68(2):353-357. 444 409 Nerlove, Marc, and S. James '?ress1973 Univariate Logistic Models.Report R-1306-EDA/NIH. Calif.: RandCorporation.Pindyck, Robert S., and Daniel L. Rubinfeld1981 Econometric Models and Economic Forecasts. 2d edition.NewYork:McGraw-Hill.Rosen, Richard J.1984 Regional variations in employment and unemployment during1970-82.Monthly Labor Review 107(2):38-4u.RoserZeld, Carl1977 Job search of the unemployed, May 1976. Bureau of LaborStatistics, Special Labor Force Report No. 210. Monthly LaborReview 100(11):39-43.Stephenson, Stanley P., Jr.1976 The economics of youth job search behavior. Review ofEconomics and Statistics 58(1):104-111.Weiss, Andrew1980 Job queues and layoffs in markets with flexible wages.Journal of Political Economy 88(3):526-538. 445 Hispanic Youth in the Labor Market:An Analysis of High School and BeyondRoberto Fernandez INTRODUCTIONThe number of people of Spanish origin in the United States rosefrom 9.1 million in 1970 to 14.6 million in 1980 (Bureau of the Census,1982:Table 3.2). In addition to this growth in absolute numbers, therelative share of the population accounted for by Hispanics grew from4.5 percent in 1970 to 6.4 percent in 1980. Although part of theseincreases probably reflect changes in Census Bureau enumerationprocedures (see Jaffe et al., 1980:311-313 and Appendix A) and anundercount of Hispanics in 1970 (Bureau of the Census, 1f79a; U.S.Commission on Civil Rights, 1974), it is clear that Hispanics are asubstantial and growing part of the population of the United States.Hispanics tend to be younger than non-Hispanic whites. Accordingto the March 1977 Current Population Survey, the median age of theSpanish-origin population was 22.1 years versus 30.0 for non-Hispanicwhites (Bureau of the Census, 1979b:Table C). Since Hispanics aredisproportionately young, they are more likely than non-Hispanic whitesto suffer the employment problems that youth in general face in thelabor market, e.g., low employment and low labor force participationrates.In fact, the data show that regardless of age, rates ofemployment and labor force participation are lower for Hispanics thanfor non-Hispanic whites, but not as low as for native Americans ornon-Hispanic blanks (U.S. Commission on Civil Rights, 1978:Table 3.1).'owever, differences in population-age profiles cannot explain whyHispanic youths are less successful than white majority youths in thelabor market.For example, among those aged 16-19 in 1981, Hispanicshr' an unemployment rate of 24.1 percent and a civilian labor forcepar,acipation rate of 46.3 percent compared with 17.3 and 59.0 percent,respectively, for whites and 41.5 and 37.4 percent, respectively, forblacks (National Commission for Employment Policy, 1982:Table 1). Datafrom the March 1980 Current Population Survey show that Hispanic youthsencounter other barriers in the labor market, as well. Among those Roberto M. Fernandez is assistant professor in the Department ofSociology, University of Arizona. 410 446 411 aged 14-19, Hispanics performed worse than non-Hispanic whites andblacks on three out of four indicators of \"underemployment,\" i.e.,Hispanic youths are more likely to experience involuntary part-timeemployment, live in households whose incomes fall below the povertyline, and receive inequitable pay than are non-Hispanic whites andblacks, although blacks are more likely than Hispanics to be inter-mittently employed 'U.S. Commission on Civil Rights, 1982:Table 5.4;also see Clogg, 1979; Sullivan, 1979).While it is clear that Hispanic youths are less successful thannon-Hispanic whites in the labor market, the reasons underlying thesedisadvantages are less obvious. Determining the causes of Hispanicunderachievement has important practical implications; the choice ofrelevant policies to ameliorate those conditions depends on under-standing the factors that lead Hispanics to fare less well thannon-Hispanic whites in the labor market.In this paper, I undertake two tasks. First, I document the extentof the employment difficulties of Hispanics compared with non-Hispanicwhites and blacks using data from High School and Beyond, a nationallongitudinal study of high school sophomores and seniors in 1980.Because respondents in this survey were enrolled in school in 1980,labor force statistics derived from the survey will not be directlycomparable with statistics based on household surveys of the laborforce, e.g., the Current Population Surveys. However, becauserespondents in High School and Beyond all started in high school, thesurvey is ideal for studying the transition of youths from school towork.Although past research has found that Hispanic youths fare lesswell than non-Hispanic white youths on many indicators of labor marketsuccess (e.g., wages, family income; see Mayers, 1980), I will focus ontwo important measures, i.e., labor force participation and unemploymentrates.Also, because of the interdependency between youths' leavingschool and their employment decisions during the school-to-work transi-tion (see National Commission for Manpower Policy, 1976; Stevenson,1978h), I discuss the indicators of labor force status by school status,i.e., by high school dropout versus in-school youths for the sophomorecohort, and by out-of-school versus attending postsecondary institutionfor the senior cohort.My second task is to examine some of the presumed causes of thedifficulties of Hispanic youths in the labor market. As with thedescriptive analyses, labor force status will be studied in conjunctionwith school enrollment. Therefore, -a a dependent variable, laborforce participation has four categories: participating in the laborforce and enrolled in school, participating in the labor force and ontof school, out of the labor force and enrolled in school, and out of.he labor force and out of school. Employment status is treated simi-larly andiso has four categories: employed and enrolled in school,unemployed and enrolled, employed and out of school, and unemployed andout of school. Using logistic regression analysis, I predict theselabor force and enrollment status indicators with measures of familybackground, school performance, language, immigration history, andother demographic variables. 447 412The remainder of this paper addresses six topics: (1) the extantknowledge on the labor market status of Hispanic youth, (2) the char-acteristics of the High School and Beyond data set and the advantagesof using this survey for studying Hispanic youths' achievement, (3) thefindings of descriptive analyses of the various subpopulations understudy,(4) the findings of causal analyses of labor force and enroll-ment status indicators, (5) the results of empirical analyses of laborforce participation and employment, and (6) recommendations for policiesto improve the status of Hispanic youths in the labor market. LABOR MARKET STATUS OF HISPANIC YOUTHSAs the Hispanic share of the population has increased, the socio-economic achievement of Hispanics has increasingly become the object ofpolicy discussion (see e.g., National Center for Education Statistics,1980; National Commission for Employment Policy, 1982). Unfortunately,research on Hispanics in general, and Hispanic youths in particular,has been hampered by a lack of suitable data (see Estrada, 1980). Forthis reason, information on the labor market status of Hispanic youthsis poor relative to that available on non-Hispanic white and blackyouths (see, e.g., Freeman and Wise, 1982).Because much research suggests that the decisions young people makeon participating in the labor force and continuing in school areinterdependent (see B. Duncan, 1965; Edwards, 1976; Ornstein, 1976), itis important to examine the causes of Hispanics' educational difficul-ties when considering the determinants of their underachievement in thelabor market.These causes can be divided into two types: general andspecific.General factors, such as sex and family socioeconomic status,are potentially important for explaining the school and labor marketachievements of everyone in the United States, regardless of their aceor ethnicity.Specific factors are characteristics that are particu-larly salient for some minority groups and are expected to affect thosegroups disproportionately. For Hispanics, specific factors arelanguage skills and immigration history.Distinguishing between the ffects of general and specific factorson the labor market achievements of Hispanics is important for policypurposes. For example, if Hispanics' labor market daFdvantages are dueprimarily to their lower levels of family socioeconomic status, thengeneral policies designed to help all poor people would help improveHispanics' labor market status. However, if specific factors, such aslanguage background, account for a large portion of Hispanics' schoolor labor market difficulties, then general policies are apt to dolittle to improve Hispanics' performance in school or in the labormarket.In this case, policy instruments, such as bilingual education,may have to be targeted specifically on the Hispanic population toimprove Hispanics' labor market achievements. 448 413 General FactorsRecent studies identify Hispanics' low levels of education as oneof the most important _meral factors that explain Hispanic youths'underachievement in the labor market (National Commission for EmploymentPolicy, 1982).Indeed, there i; much evidence that Hispanics experienceconsiderable educational difficulties. At each age level, schoolenrollment rates for Hispanics lag those for whites (National Centerfor Education Statistics, 1980:Table 1.08). Hispanics also havesignificantly lower rates of high school completion than non-Hispanicwhites (National Center for Education Statistics, 1980:Table 1.09).Among those who remain in school, Hispanics are much more likely tohave to repeat a grade as they progress through school than non-Hispanic whites (National Center for Education Statistics, 1980:Table2.21).Hispanic educational difficulties extend to the postsecondarylevel, as well. Hispanics are underrepresented in undergraduate,graduate, and professional programs ,-lative to their share of thepopulation (National Center for Education Statistics, 1980:Table 3.01)and underrepresented among the nation's degree recipients (NationalCenter for Education Statistics, 1980:Table 3.21).There is much research, however, that suggests that these educa-tional difficulties are, in turn, caused by other general factors. Inother words, Hispanics' low levels of education are an endogenous causeof their labor market difficulties. Other factors that influenceHispanics' educational attainments may also influence their labormarket achievements directly, or indirectly through educational attain-ment.The most important of these factors is family socioeconomicbackground (Blau and Duncan, 1967; 0. Duncan et al., 1972; Jencks etal., 1972).This is generally inte:preted to mean that higher incomefamilies, in which parents have high educational and occupationalstatuses, are more likely to support their children in educationalendeavors.Less affluent families may not emphasize education fortheir children as much because the relative cost of college and highereducation relative to the prospective returns on this investment do notjustify the expenditure.In addition to the indirect effects of family background on labormarket outcomes through education, most studies have also :hown directeffects of family background on offsprings' labor market success (e.g.,Blau and Duncan, 1967). Unfortunately, the mechanisms by which thesedirect effects operate are not well understood in the case of occupa-tional status and earnings. A number of complicated and sometimescrosscutting processes appear to be operating to convert familybackground into occupational status and earnings (see Jencks et al.,1979:Ch. 3).However, in the case of youths' labor force participationand employment, it has been shown that children of poorer families arelikely to enter the labor force at earlier ages than offspring ofwealthier families (Neugarten and Hagestad, 1976), even after theeffects of educational attainment are controlled ,agan, 1981:Ch. 5).The direct effects of family background on labor force participationand employment have also been documented for high school students(Lewin-Epstein, 1981). 449 414A number of recent studies of various Hispanic subgroups have cometo the same conclusion as the studies of the general copulation: familysocioeconomic background is an important determinant of Hispanics'educational achievements (Aspire, 1976; Fligstein and Fernandez, 1982,1985; Nielsen and Fernandez, 1982) and occupational achievements (seeTienda, 1981; McLaughlin, 1982; Stolzenberg, 1982). Although there hasbeen very little empirical research on the topic, family backgroundfactors lave also been cited as important determinants of Hispanicyouths' labor market difficulties (National Commission for EmploymentPolicy, 1982). The most important of these background factors isthought to be family income (see, e.g., Aspire, 1976; Briggs et al.,1977).Hispanics are much poorer than non-Hispanics. In 1977, themediz..- family income of Hispanics was $11,421 compared with $16,284 fornon-Hispanics (Bureau of the Census, 1979b). Hispanic families alsotend to be larger than non-Hispanic families (3.88 persons versus 3.31;see Bureau of the Census, 1979b). Researchers argue that to help casethe family's financial burdens, Hispanic youths are more likely toenter the labor force than non-Hispanics. However, as Hispanic youthsbecome increasingly involved in the world of work, they are correspon-dingly drawn out of school. Hence, they are presented with a self-reinforcing situation wherein they leave school to work, and then theirlack of schooling becomes a major obstacle to their success in thelabor market. Specific Factors Language problems often head the list of specific factors that maydisproportionately affect Hispanics' educational and labor marketachievement (U.S. Department of Health, Education and Welfare, 1974;Barrera, 1979; National Commission for Employment Policy, 1982).For youths entering school from non-English language backgrounds,limited English proficiency can certainly constitute a barrier toeffective learning in English-only school systems. Students who carnotunderstand what is being taught through the medium of the English langu-age are likely to have both psychological and aubstantive difficultiesin their interactions with teachers and in their studies. As a conse-quence, it is often argued, these students tend to have lower scholasticperformance and are more likely to drop out of school (see, e.g.,Hirano-Nakanishi and Diaz, 1982; Steinberg et al., 1982a). Surveyresearch in this area tends to support these notions. For example,Lopez (1976) found that U.S.-born Mexican-Americans raised in Spanish-language environments had lower educational attainments than theirU.S.-born Mexican-American counterparts raised in English-languageenvironments.To the extent that Hispanics speak only or predominantly Spanishwhen they complete their schooling, studies suggest negative effects onwork-related variables (Lopez, 1976; Chiswick, 1978; Veltman, 1981;Garcia, 1983). Because effective communication is an importantcomponent of any production activity, Spanish monolinguals' inabilityto communicate in English may make them less attractive to employers. 45o 415 In addition, Spanish monolinguals are likely to receive lower wages(see Stolzenberg, 1982; McManus et al., 1983; Tienda, 1983) and to beunderemployed and unemployed (Carliner, 1981). For Spanish-dcminantbilinguals, there is some evidence to suggest that accented or non-standard English may result in employers consciously or unconsciouslyshowing bias against Spanish users (Garcia, 1983; Lopez, 1976).The use of Spanish, or any non-English language, however, may notbe intrinsically harmful to bilinguals' educational and work-relatedachievement.In fact, the effects of using Spanish, controlling forEnglish proficiency, have been subject to debate. One argument ampha-p'zes the cost of bilingualism. In this view, the coexistence of twolexicons and two syntaxes in the mind of the bilingual represents adrain on a finite amount of mental energy, and less mental energy willbe available, for example, for intellectual tasks in school. Anotherharmful consequence of bilingualism may be that the languages interferewith one another. This process is known as \"code switching\" (Albertand Obler, 1978). In this view, Spanish proficiency and use shouldretard achievement in English-language schools.on the other hand, other studies have found thpt bilingualproficiency is an Lsset or does not hinder bilinguals either in school(Peal and Lambert, 1962; Lambert and Tucker, 1972; Cummins, 1976, 1977;Veltman, 1980; Fernandez and Nielsen, the labor 1976; Tienda, 1981:Ch. 8; Garcia, 1983). The fe-* thatbilinguals have two codes for every concept may help them to realizethat codes are arbitrary. Therefore, bilingualism may serve tostimulate intellectual development for abstract reasonici tasks, whichshould be expressed in higher scholastic achievement. Regarding thelabor market, some studies have suggested that bilingualism is a formof human capital that may yield returns in the labor market (Carliner,1976; Tienda, 1982). Therefore, in areas where there is a demand forworkers who can communicate in more than one language, bilinguals willbe in an advantageous position in the labor market. Alsc Lopez (1976)suggests that the knowledge of Spanish may aid bilinguals to find jobsin blue-collar job markets.Results from research on the effects of immigration patterns onachievement have been inconsistent. A substantial body of work docu-ments the fact that despite an initial lack of familiarity withlanguage and customs, immigrants sometimes achieve higher educationaland occupational levels than nonimmigrants (Blau and Duncan, 1967).Chiswick's research (1977, 1978, 1979, 1980a, 1980b, 1982) tends tosupport these findings, although he shows that an initial adjustmentperiod is needed before immigrants' attainments overtake those ofnonimmigrants. Carliner's (1980) analyses support period: recent immigrants receive lower wagesthan second-generation workers, but second-generation workers receivehigher wages than do third-generation workers. These findings havebeen taken to be indicative of a selection process whereby immigrants'high level of motivation manifests itself in higher socioeconomicattainment.Nielsen and Fernandez (1982) speculate that this highlevel of motivation may be passed on to the immigrants' children, thusexplaining why progeny of more recent immigrants perform better in highschool.451 416However, when considering Hispanic immigrants specifically, 1978; Borjas, 1982; Tienda, 1983) immigrants are at a socioeconomic disadvantage (relativeto long-time residents), which these researchers attribute to dif-ficulties of language, cultural adjustment, and transferability ofskills.In addition, using census data, Jaffe et al. (1980) have shownthat Hispanic immigrants have lower levels of education than otherimmigrants, which can result, through the general mechanisms describedabove, in lower educational and occupational achievements forthemselves and their children.In addition to the above research, which focuses on the characteris-tics of immigrants that lead them to achieve well or poorly in theUnited States, a number of researchers have emphasized that thepolitical and economic climate of the United States at the time ofimmigration may be an important determinant of how well and how quicklyimmigrants are assimilated. The Cubans are an example here. it hasbeen argued that the par'ieular historical circumstances under whichthe initial wave of Cuban immigration took place--the climate ofgeneral acceptance by the host population, the legal status Cubansas political rather than economic migrants (Pedraza-Bailey, 1980;Wilson and Portes, 1980), and supportive governmental policies at thetime of Cuban settlement (see, Rogg, 1974; Pedraza-Bailey 1982; Nielsen and Fernandez, 1982; Portes, 1982). Anumber of researchers have also argued that the fact that Cubanimmigrants have largely settled in an ethnic enclave (Miami) made up ofprevious immigrants (see Wilson and Portes, 1980; Wilson and Martin,1982) who own about 10 percent of the businesses and employ 50 percentof Cuban males in the area (see Clark, 1977; Fortes et al., 1977, 1981)has had beneficial effects on Cubans' socioeconomic achievements (seePortes and Bach, 1980; Portes, 1982).Finally, there is a substantial literature that suggests thatethnicity, viewed as analytically separable from language and immigra-tion factors, is related to lower achievement among Hispanics. Akin toarguments regarding the disadvantages that blacks face, it is oftenargued that racial-ethnic prejudice or cultural and socializationdifferences between majority-minority groups help to explain achievementdifferentials (see, e.g., Carter and Segura, 1979; Noboa, 1980; for areview, see Duran, 1983). Although measuring the effects of racial orcultural discrimination in school or in the workplace is extremelydifficult, discrimination is often cited as a major reason for Hispanicyouths' school and labor market difficulties (see Carter and Segura,1979; National Commission for Employment Policy, 1982). In the case oflabor market discrimination, inferences have been made on the basis ofthe different earnings returns to education for whites and Hispanics(National Commission for Employment Policy, 1982). Such Hispanic-whitee.fferentials in returns to education have also been offered as areason for Hispanic youths' lower levels of schooling: Hispanic youthsare less likely to judge each additional year of schooling to be worththe investment, and hence, they are more likely to drop out. 417 DATA AND VARIABLES The High .9...:hool and Beyond Data Base The data analyzed in this paper are from the first two waves (1980and 1982) of the National Center for Education Statistics (NCES) study,High School and Beyond, a longitudinal study of U.S. high schoolsophomores and seniors in 1960. The data were collected for NCES bythe National Opinion Rest- Center at the University of Chicago. Thebase-year (1980) sample co.. ,sts of 30,030 sophomores and 28,240 seniorsto 1,015 high schools; the of 84 percent. Of therespondents, 2`,875 sophomores and 10,815 seniors were surveyed againin 1982.Hispanic schools were oversampled in the base year, andrespondents in those schools had very high probabilities of beingincluded in the follow-up sample (see Frankel et al., 1981).Three features of High \".nool and Beyond make it ideal for studyingHispanic youths' labor market achievements. First, because it is alongitudinal study of the sophomore and senior high school classes in1980, respondents can be tracked through their transition from schoolto work.In addition to providing information on resnondents' laborforce status, the stuay provides detailed data on respondents'educational backgrounds and on how respondents combine their school and labor force activities.Second, because Hispanics were oversampled, the study containssufficient numbers of Cubans, PueLto Ricans, and Mexican-Amer cans for::Rparate analyses. This is important because past research has shownthat Hispanic subgroups differ in their school and labor marketachi, ment profiles (Newman, 197C; Jaffe et al., 1980; National L.: cation Statistics, National Commission for EmploymentPolicy, 1982; Nielsen and Fernando 1982).Third, High School and Beyond is rare in that 't includes manydetailed questions about the linguistic practices a. the respondent andhis or her family (se.l. Nielser, 1980:App. B and C, for descriptio.ls anddiscussions of the language data available from the survey). The studyalso provides information especially relevant co Hispanics, such asnativity and length of U.S. residence. Definition of Comparison GroupsOne of the main goals of this paper is to provide statisticsshowing how Hispanic youths compare with non-Hispanic youths ondifferent measures of employment status. To this end, I have dividedboth the sophi.more and senior samples into groups of Hispanics,non-Hispanic whites, and non-Hispanic blacks.Self-identification was used in the survey to classify respondents'ethnic identity.' This was done for both theoretical and practical 'Detailed coding information on the definition of the comparisongroups and both the dependent and independent variables can be found inthe appendix. 453 418 reasons.First, the use of self-identification to define ethnicLmtificaiion is in agretment with the emerging theoretical consensuson what conktitutes 'ethnic\" identity (Barth, 1969). Second, self-identification of ethnicity is particularly well suited for use insurveys.Smith (1980) has shown that of the various metLods ofclas:ification (i.e., natal definitions, such as those based on therespondent's country of birth; behavioral definitions based on someobjectivt cultural criterion, such as the use of a language other thanEnglish, and subjective criteria invl.ving self-identification by therespondent), self-identification is the most efficient technique foreliciting a positive national-origin identification from respondents inthe general population. (Also see Smith, 1983; for research regardingthe identification of Mexican-Americans, see Hernandez et al., 1973.) Dependent VariablesTwo dependent variables are analyzed: labor force participationand unemployment. Foi both variables, the statistics reported are forthose in the civilian labor force; those enlisted in the military arecounted as out of the labor force. Because schoo. -leaving and employ-ment decisions are interdependent, I treat labor force and schoolstatus as simultaneous events. Therefore, for both sophomores andseniors, the two dependent variables each have four categories. Forlabor force participation, the four categories for sophomores areparticipating in the labor force and enrolled in high school; partici-pating in the labor force and not enrolled in high school; out of thelabor force and enrolled in school; out of the labor force and notenrolled in school. The variable is defined similarly for seniors withthe exception that the relevant school-continuation decision is used,i.e., enrollment in postsecondary education rather than enrolled versusnot enrolled in high school. The unemployment variable is defined inanalogous fashion for both cohorts, i.e., among those participating inthe labor force, respondents were distinnuished as employed versusunemployea and enrolled in school versus not enrolled. Independent VariablesCorresponding to the discussion in the literature review section,the independent variables are divided into two groups: general andspecific.Among the general predictors of labor force and schoolenrollment status are family socioeconomic background, scholasticperformance, demographic variables, and a measure of past labor forceinvolvement, 4 5 I 419For both sophomores and seniors, I measured family socioeconomicbackground with a composite variable derived from a number of measuresof parental background and family resources.2To assess the effects of scholastic performance on school retentionand employment propensity, I also included among the general predictorsof labor force and school enrollment status two measures of scholasticachievement:self-reported grades and a standardized-test composite.As measures of scholastic achievement, grades and test scores differ inthat grades do not vary across schools, while test scores vary bothwithin and between schools.Three demographic variables are also included as general predictors:sex, age, and marital sta;:us. Respondents' sex is measured by a dummyvariable coded 1 2. male and 0 as female. Because younger respondentsare expected to be less likely to participate in the labor force andmore likely to be enrolled in school, I also included a measure of therespondent's age, coded in years, in the models discussed below.Marital status was included as a demographic variable to test thehypothesis that the increased financial responsibilities that accompanymarriage are likely to force respondents into the labor force.Finally, to assess the effects of past labor force experience onyouths' labor force and enrollment status (see Stevenson, 1978a), Iincluded a dummy variable measured in the base-year survey of past workexp\"once.Consistent with the discussion above, I also included six variablesthat are likely to affect Hispanics disproportionately as predictors:respondent's, father's, and mother's length of U.S. residence (measuredin years); a dummy variable for whether the respondent is bilingual;proficiency in the non-English language; and proficiency in English.(See appendix for coding details.;Regarding the language measures, I considered respondents bilingualif a language other than English was given in response to at least oneof three questions: mother tongue of respondent (first languagespoken), second mother tongue (other language spoken before schooling),respondent's usual language. These criteria clearly distinguish thosestudents who have never usel a language other than English from thosewho have had at least some natural exposure to another language. Notethat this is unlike the criteria used in the Bilingual Education Act(as amended in 1974) to define children of limited English proficiencyin that it does not hinge on students' level of English proficiency ornativity (see O'Malley, 1981:Ch. 2). My definition also excludesrespondents with only indirect contact with languages other thanEnglish, such as those who studied a language in school as an academicsrbject. Rem placing t he socioeconomc status composite with measures offather's and mother's education and family income does not change thesubstantive ,results reported here. The summary measure was usedbecause of the large numbers of missing values on parental education(15 to 20 percent) and family income (12 to 18 percent). 455 420 The non-English language proficiency scale used in the survey isbased on the student's self-assessed ability to understand, speak,read, and write in the non-English language.' These questions arecontained in a separate language questionnaire and are only asked ofstudents who indicated some exposure to a non-English language.Finally, English proficiency is measured by performance on astandardized vocabulary test. Note that using vocabulary-test per-formance as an indicator of English proficiency builds in a correlationwith the standardized-test composite that is used as a measure of thestudent's scholastic achievement. Altaough it would have beenpreferable to have independent measures of a student's Englishproficiency and scholastic ability, I chose this specification becausethe alternative self-reported measure of English proficiency (based ona set of it:lms parallel to the proficiency in other language items)showed very little variance.The fact that the measure of English proficiency is correlated withthe composite test measuring scholastic achievement is not of itselfdisturbing.Indeed, it is difficult to imFgine any measure of Englishproficiency that is uncorrelated with these tests of scholasticachievement since the tests are written in the English language andpurport to measure knowledge and skills that are largely taught in theschools through the English language. In addition, my experience inpast research (Nielsen and Fernandez, 1982; Fernandez and Nielsen,1984) and in the preliminary stages of these analyses has shown thatthe pattern of results is the same if one uses the vocabulary test as ameasure of English proficiency and tha mathematics test as a measure ofscholastic achievement, or the vocabulary test with the composite test(i.e., reading, vocabulary, and mathematics) as a measure of scholasticachievement, as I have done here. DESCRIPTIVE ANALYSES SophomoresFor High School and Beyond, sophomores were interviewed in 1980 andtwo years later, regardless of whether they were still in high school.Table 1 presents high school dropout rates, by sex and populationsubgroup, for the sophomores.' 'Self-reported measures of language practices hale been found to behighly reliable and valid (see Fishman, 1969; Fishman and Cooper,1969;Fishman and Terry, 1969). Fishman and Terry (1969) attributethese qualities to the fact that respondents are forced to perform aglobal assessment of their linguistic behavior. Many objectivemeasures capture more fragmentary aspects of language usage and havecorrespondingly lower validity. The standard errors reported in the descriptive analyses have beencorrected for the effects of sample design. 456 421 TABLE 1Dropout Rates, by Sex and whites 13.40.69,22611.60.69,340SOURCE:Data from High School and Beyond. The high school dropout rate for Hispanic males overall (18.5percent) is lower than the rate for blacks (20.3 percent) and higherthan the rate for whites (13.4 percent). Consistent with past researchon high school noncompletion (National Center for Education Statistics,1980:Tal\",le 2.31) among males, Puerto Ricans have the highest dropoutrate (24.0 percent), followed by Mexican-Americans (21.4 percent).'tiler Latin Americans\" have the lowest dropout rate among males, lowerthan whites (12.0 versus 13.4 percent), and the rate for Cuban males(14.6 percent) is slighAay higher than the rate for whites.Among females, Hispanics overall have the highest dropout rate(18.1 percent, compared with 14.2 Percent for blacks and 11.6 percentfor whites).Cuban females have tue highest dropout rate of anysubgroup of either sex, 26.5 percent. The pattern for the remainingHispanic subgroups is the same as that for males: the rate for PuertoRicans is highest (21.5 percent), followed by Mexican-Americans (20.8percent) and other Latin Americans (10.8 percent).The mechanisms underlying these differences in dropout rates areunclear.In part because of problems of data availability, very littleempirical research exists on the causes of these different dropoutrates.However, the limited research available suggests that Hispanicsare likely to drop out in order to work and help support the family(National Council of La Raza, 1980). At )east for males, the Dropoutstatistics in Table 1 are consistent with this hypothesis: the dropout rates for th- ious subgroups increast as the median family income ofthe subgroup L.creases (National Center for Education Statistics, 1980).The same pattern holds for females, with the exception of blacks, whodrop out less than one would expect, and Cubans, who drop out more thar one would expect. 457 422 Table 2 also len-- support to the idea that Hispanic males '-end todrop out for financial reasons. Table 2 shows labor force status byschool enrollment status for the sophomores. Among out-of-schoolmales, Hispanics overall show a higher degree of labor force attachmentthan do whites or blacks: 85 percent of Hispanic males were in thelabor force compered with 82.5 and 73.1 percent, respectively, forwhites and blacks. The relatively poor Mexican-Americans show thehighest, and the relatively rich Cubans the lowest, degree of laborforce involvement among the out-of-school males. In agreement withpast research (Ryscavage and Mellor, 1973; Newman, 1978), the poorestsubgroup of all, the Puerto Ricans, show a very low rate of labor forceparticipation.However, tais is probably due to the': very high rateof military enlistment (see Table 2). A number of researchers havenoted that because Puerto Ricans are heavily concentrated in New YorkCity, which has had a declining economy in recent years, job oppor-tunities for Puerto Ricans nave worsened (Newman, 1978; NationalCouncil of La Raza, 1980). Enlistment in the military is common amongthose faced with bleak job prospects.Considering females' labor force participation rates among thosewho are out of school, Hispanics overall again have a lower rate ofparticipation than either whites or blacks. However, unlike pastresearch on the adult population that has shown that the labor forceparticipation rate of Puerto Rican females is especially low (Ryscavageand Mellor, 1973; Newman, 1978) and declining (Santana-Cooney, 1979;Santana-Cooney and Warren, 1979; National Commission for EmploymentPolicy, 1982), Table 2 shows that among youths, Puerto Rican femaleshave the highest rate of labor force participation, even higher thanwh--e females (67.8 versus F 1 percent).Also contrary to the pastresearch on the adult populc In that shows that Cuban females have ahigh rate of labor force participation relative to other Hispanicsubgroups (see Ryscavage and Mellor, 1973; Newman, 1978:Table 1;National Commission for Employment Policy, 1982), the data in Table 2show Cubans have the lowest labor force participation rate among femaleyouths.sWhile out-of-school Hispanics are more likely than out -of- schoolwhites to participate in the labor force, Hispanics are less successfulthat whites in finding employment. For both sexes, unemployment ratesamong out-of-school Hispanics are considerably higher than those ofout-of-school whites (males: 30 versus 21.8 percent; females: 34.9versus 26.6 percent), albeit not as high as among out -of- school blacks(36.8 percent for black males and 47.4 percent for black females).This is consistent with past research on the general population (seeMcKay, 1974; Newman, 1978). Also, consistent with past research on theadult population (Newman, 1978; National commission for Employment sAside from differences in the age groups studied, the discrepanciesbetween the results in past research and the analyses here are probablydue to differences in the target population. Note that none of thesesources reports data on out-1,f-school youths. 458 423 Policy, 1982), Puerto Rican males have the highest unemployment rateamong Hispanic subgroups. However, the employment situation of otherLatin Americans who are out of school is significantly better: theirumemployment rates for both sexes are relatively low, for males evenlower than the unemployment rate for whites. Somewhat of a surprise,out-of-school Cuban females show the highest jobless rate in Table 2,52.5 percent.The employment situation of out-of-school Puerto Ricanfemales is also relatively poor, albeit not as bad as for Cuban andblack females who are out of school. Finally, out-of-school Mexican-American males and females show very similar unempluyment rates (32.6versus 32.3).Turning now to students, labor force participation rates amongmales enrolled in school do not vary much among ethnic subgroups (75.5to 79.5 percent). For female students, the variation in labor forceparticipation rates across ethnic subgroups is considerably more thanfor males (67.3 to 77.7 percent) but is much less than the ranges forhigh school dropouts of either sex (males: 70.2 to 90.1 percent;females:47.4 to 67.8 percent).But while rates of labor force participation do not vary much,chances of employment do. Among male students, Puerto Ricans have thehighest unemployment rate of any subgroup (27.5 percent). Only blackfemale students have a higher unemployment rate, 32.6 percent. Amongmale Hispanics, Mexican-Americans have the lowest unemployment rate(14.8 percent), and among female Hispanics, other Latin Americans havethe lowest unemployment rate (16.3 percent).Comparing students to dropouts, no simple pattern emerges for laborforce participation rates among males. In some cases, e.g., Mexican-Americans, dropouts have a higher degree of labor force attachment thanstudents (90.1 versus 77.2 percent), but in other cases, such as Cubanmales, students have a higher level of labor force involvement thandropouts (75.5 versus 70.2 percent). Howeve, , the unemployment statis-tics for males show a clear-cut pattern: once in the labor force, highschool dropouts have a more difficult time finding work than youths whoremain in school. This pattern could reflect employers' responses todropouts' relative lack of education. An alternative explanation forthis pattern is that high school students and dropouts seek differentkinds of jobs. For example, high school students largely seek part-time employment (Lewin-Epstehi, 1981), while dropouts are more likelyto look for full-time work (Porus, 1983). Differences in u loymentrates may simply reflect differences in the job markets in % 2hstudents and dropouts starch for work. louths who are looking forfull-time work may be more disadvc.ntaged than youths searching forpart-t'me jobs because those who seek full-time employment are likelyto be competing with adult workers who have considerable laboi forceexperience.In contrast, the job market for part-time work is likelyto be less competitive.Considering the statistics for females, the pattern is clear acrossall subgroups: dropouts are less involved in the work force thanstudents.Part of this pattern may be due to a d1scouraged workereffect.Because female dropouts have relatively poor employmentprospects, as evidenced by their very high unemployment rates, females 459 TABLE 2Labor Force Status, by School Enrollment Status, Sex, and Population Subgroup, forSophomore Cohort Not Enrolled in SchoolPopulation Labor Force MilitarySubgroup Participation Unemployment EnlistmentPercentStandardErrorSampleSizePercent All Hispanics COPY AVAILABLEStandardSample StandardSampleErrorSize:PercentErrorSize Male 5.8 7.423.0 17.1 13.4 7.8 blacks 67.82.01,45132.62.41,009Non-\"Ispanic whites 77.70.87,98714.80.86,17 BEST COPY AVAILABLE 461 426 choose to stay out of the labor force. A second explanation for thispattern is related to the reasons they left school in the first place.Since many females dropped out because they were pregnant or t'ettingmarried (see Borus, 1983), it is reasonable to expect that many of themchose the role of homemaker; therefore, they are not counted intraditional definitions of labor force participation. Seniors High School and Beyond also followed up, two years later, onrespondents who were seniors in 1980. Table 3 describes the seniors'postsecondary school activities by sex and population subgroup.Hispanics are underrepresented in postsecondary education relativeto their share of the population (National Center for EducationStatistics, 1980:Table 3.01). However, Hispanics who have graduatedfrom high school have been found to go on to college at a rate equal tr(Peng, 1977; Duran, 1983) or higher (Fligstein and Fernandez, 1982,1984) than non-Hispanic whites. Peng ;1977) speculates that thispattern is due to the success of affirmative action programs. Nielsen(1980), however, offers the intriguing interpretation that this patternis actually a cons2quence of the significant barriers to Hispanicachievement in high school. Because high school is a difficult processfor Hispanics (evidenced by their very high dropout rates; see Table2), the \"survivors\" of the process, he argues, are a r'oi elect andhighly motivated group than wriites who do not encounter the sameobstacles in high school.Regardless of which of these interpretations is correct, pastresearch shows that Hispanics compare favorably with other groups intheir ability to gain access to higher education once they make itthrolgh high school. Olivas (1979), however, thinks that theequivalence of college-going rates is due to the tendency for Hispanicsdisproportionately to attend junior and two-year community colleges.Olivas (1981) and others (e.g., Duran, 19E3) argue that this is becauseHispanic high school graduates are relatively poorer than theirnon-Hispanic counterparts and, thus, are less able to afford four-yearcolleges.The data reported in Table 3 do not support these past results.Both male and female Hispanic high school graduates are less likely togo on to college than whites. Thes.: Hispanic-white differences inrates of postsecondary attendance are mainly due to Hispanicunderrepresentation in four-year institutions.Because of the small sample sizes, the standard errors for theHispanic subgroups are very large, which makes inferences for theHispanic subgroups difficult. However, the following patterns emergeamong the subgroups. The percentage not attending postsecondary schoolis particularly high for Puerto Rican males (57.8 percent), but is alsolarge for Mexican-Americans and other Latin Americans. Only Cubanmales have a higher rate of postsecondary attendance than whites (82.7versus 62.2 percent). 462 TABLE 3Postset..ondary Attendance, by Sex and Population Subgroup, for Senior Cohort PopulationSubgroapFour-year College Two-year College 'locational 463 428Although I cannot resolve the issue here, it is my speculation thatthe results reported differ from those of past research because ofdifferences in sample design. Unlike the data reported in most otherstudies, High School and Beyond is a longitudinal study of a grade-baaed cohort of students, i.e., seniors in 1986.6 Other studiesreport percentages of high school graduates in household surveys (e.g.,the Current Population Surveys; see Duran, 1983:Table 1) who go on tocollege.Sometimes an age restriction is used to define the surveypopulation, but it is typically a broad range; for example, Duran(1983) uses the population aged 18-34. If, by being poorer than whites,Hispanics are more likely to have discontinuities in their educationalcareers and therefore to take longer to make the transition tocollege,' college-going rates based on studies of grade cohorts, suchas in High School and Beyond, will show Hispanics lagging in theirrates of college-going. If it is the case that Hispanics go on tocollege at rates equal to or higher than whites but that it takeslonger for them to do so, studies of broad age cohorts, such as Duran's(1983), that do not examine the question of whether Hispanics areoverage compared with whites will show that Hispanics have reachedparity with whites. If the discrepancy between these results based onHigh School and Beyond and those based on other studies is due toHispanics' taking longer to get to college, then the discrepancy shoulddiminish as the High School and Beyond cohort ages.Table 4 shows seniors' labor force status by postsecondary schoolattendance, sex, and population subgrour. Here, too, the small samplesizes make inferences concerning the Hispanic subgroups difficult, andcaution should be exercised in interpreting differences among theHispanic subgroups. Similar to the results for the sophomores, PuertoRican males have a high rate of military enlistment two years afterhigh school graduation (23.6 percent). Black males also have a highmilitary enlistment rate (19.1 percent). Although much lower inabsolute size than the rate for Puerto Rican males, the correspondingrate for Puerto Rican females is also high relative to white females(5.2 versus 2.3 percent). The military enlistment rate among blackfemales is similar to that of white females (2.2 versus 2.3 percent).Considering the labor force participation of males who are notenrolled in school, rates of participation in the labor force are veryhigh (greater than 90 percent) and do not vary much across ethnicsubgroup.Overall. Hispanic males participate in the labor force morethan either whites or blacks (95.7 compared with 92.9 and 92 percent,respectively). Almost all civilian out-of-school Puerto Rican males are 6Peng (1977) is an exception here. His results are based on theClass of 1972 National Longitudinal Study. 7Fcr evidence that family socioeconomic status is inversely relatedto school discontinuities in the general population, see Featherman andCarter (1976). For evidence on socioeconomic status and the timing ofeducational transitions, see Hogan (1981). 464 429 either working or seeking employment (98.8 percent). Mexican-Americanmales also have a very high labor force participation rate, 96.6percent.Although not as high as the rates for males, the labor force par-ticipation rates of out-of-school females are fairlj high. However,unlike the males, there is considerable variation across ethnicsubgroup in the rates for females. Female Hispanics participate in thelabor force at a rate that is almost equal to that of white females(83.3 versus 84.4 percent), but is somewhat higher than the rate forblack females (78.2 percent). Cuban females are substantially morelikely to participate in the labor force than white females: almost 95percent of out-of-school civilian Cuban females were employed orlooking for work, compared with 84.4 percent for white females. PuertoRican females, who showed the highest labor force participation rateamong out-of-school sophomores, had a relatively low rate ofparticipation, i.e., 79.7 percent when followed up two years lacer.Turning to the unemployment rates for out -of- school males,Hispanics overal:, have an unemployment rate that is slightly higherthan that of whites (18 compared with 14.8 percent), but substantiallylower than that of blacks (29.3 percent). Among male Hispanicsubgroups, Puerto Ricans have the highest and Cubans the lowestunemployment rates (19.5 and 14.1 percent, respectively).Among out-of-school females, Hispanics' employment prospects aremuch poorer than those of whites, but not as poor as those of blacks.More than 40 percent of black females are unemployed, compared with17.8 and 27.7 percent of white and Hispanic females, respectively.Among Hispanic subgroups, Cuban females have the highest rate ofunemployment (40.5 percent)--the highest unemployment rate in Table 4.Because of their small sample size, statistics for the Cubans should beinterpreted with caution.Looking at those who are enrolled in postsecondary education, laborforce participation rates are very low. Among males, only 44.5 percentof whites, 38.8 percent of blacks, and 52.2 percent of Hispanics areemployed or seeking work while attendilig postsecondary education. Forboth sexes, Mexican-Americans have 59,9 percent; females: 58.6 percent). PuertoRicans of both the lowest labor force participation ratesamong Hispanic subgroups: 39.9 percent for males and 54.2 percent forfemales.Unemployment rates for ycath enrolled in postsecondary educationfollow the same pattern found for the other populaLms: the unemploy-mert rate for Hispanics is higher than that for whites and lower olanthat for blacks. Consistent with the re241ts for other populations,Puerto Ricans show the highest unemployntnt rate among male Hispanics(27.6 percent). Amcng : pale Hispanics, Mexican-Americans show thehighest race of uIemploym.int (15.7) percent.Finallycomparison of the labor force status of seninrs (Table 4)with that r: sophomores (Table 2) reveals a number of interestingpatterns.For one, a comparison of high school dropouts with seniorswho have not gone n to college shows that the seniors have uniformlyhigher labor force participation rates and uniformly lower unemployment 465 TABLE 4Labor Force Status, by Postsecondary School Attendance, Sex, and PopulationSubgroup, for Senior Cohort Not Enrolled in Postsecondary SchoolPopulation Labor Force Military Subgroup Participation 44.53.266473.84.1243Non-hispanic whites 44.11.81,37212.11.6719 467 432 rates.This is not surprising given that youths in the senior cohortare older than youths in the sophomore cohort (on average, 19 versus17) and are high school graduates rather than high school dropouts.But if we consider youths who are in school from both cohorts, thepatter- for labor force participation reverses, Students in highschow(sophomores) have much higher rates of labor force participationthan students in postsecondary schools. However, among those in schooland participating in the labor force, the chances of employment are notsystematically different for members of the sophomore and seniorcohorts.These patterns imply that high school students are much moreattached to the labor force than students enrolled in postsecondaryschools.There are two possible explanations for these patterns: (1)postsecondary study allows fewer opportunities for labor forceinvolvement, and (2) self-selection is operating so that students whoattend postsecondary education are the ones who wish to c-ncentrate ontheir ,,:hooling. These results may be due to the need of Hispanics toparticipate in the labor force more than whites because Hispanics arepoorer and are less able tl afford the costs of postsecondary education.But, perhaps because of self-selection, Hispanic high school studentsparticipate in the labcar force at higher rates than postse \"ondaryztvdents.Comparisons of youth who are out of school from both cohortssuggest that caution should be exercised when interpreting the causalanalyses of seniors' labor force status (presented in the next section).Unlike the sophomore cohort, the senior cohort does not include highs.\"'.00l dropouts. Thus, the caus..1 analyses that follow are subject tose_actior. bias (Heckman, 1979). This problem is compounded by the factthat the various population subgroups have markedly different selectionrates due to dropping out (see Table 2). The clta for the sophomor-cohort are not subject to this problem, because pre-sophomore yearattrition rates are small an do not vary for Hispanics andnon-Hispanics (Rumberger, 1983:Table 1). MULTIVARIATE ANAaYSESAlalysis Strategy In this section, I develop models of labor force participation andemployment for whites and Hispanics.\u00b0 The purpose is to test a \u00b0Note tbt I do not estimate models for blacks. This is for tworeasons.First, the logistic regression analyses presented in thissection eae estimated by maximum likelihood techniques and aretherefore very expensive. Eliminating blacks from consideration hasthe advantage of simplifying the number of comparisons that must bemade in the,.'Isis and cuts computation fime by a thirl. Second, amajor focus of this analysis is the assessment of the effects of 433 number of hypotheses derived from the literature concerning the causesof Hispani-s' underachievement in the labor market. Specifically, thepurpose is to test whether ELspanic-white differences in generalbackground factors, such as family income or scholastic achievement,account or Hispanics' difficulties, or wnether specific factors thatdifferentiate Hispanics from the white majority, such as language orrecency of migration, explain these difficulties.My strategy is to first specify separate models of labor forceparticipation' for white and Hispanic sophomores and seniors.Because of the small numbers of Cubans and Puerto Ricans in the sample,the various Hispanic subgroups have been aggregated and dummy variableshave been included to distinguish subgroup membership. Although itwould have been preferable to explore subgroup interactions withrespect to the models developed here, my preliminary analysis has shownthat the numbers of Cubans and Puerto Ricans are very small andtherefore likely a yield unreliable estimates.Because there is evidence tha` 3ecisions about school continuationand labor force participation are interrelated (Dumlan, 1965; Edward.1976;'rnstein, 1976), I treat labor force participation and school:nrollment status as joint dependant variables.\") Therefore, thedependent variable has four categories: in the labor force and inschool, in the labor force and out of school, out of the labor forceand in school, and out of the labor force and out of school. r,hreedummy varibles are created for membership in these four categories.They are labels' LPP1, LFP2, and LFP3 and correspond to the first threecategories above. The excluded (base) category is out of the laborforce and out of school. Each of these three dummy variables is linguistic patterns on labor force and school enrollment status.Although there is evidence that linguistic factors are importantdetermining black students' school achievement (see Dillard, 1973;%.11.7; Harber and Bryen, 1975; Labov, 1976), the literature of nonstandard English dialects, i.e., \"Black English.\" Since thelanguage data in High School and Beyond does not contain anyinformation about dialects, but is geared toward the identification offoreign-language users, the language issue for blacks cannot beproperly addressed. As with the descriptive analyses, those who are enlisted in themilitary are defined as being out of he labor force. Therefore, theequations p.., rated predict participation in the civilian labor force.l'An alternative here would be to use school enrol'-sent status as apredictor of labor force status. However, if it s true that decisionsabout ev:hool continuation and labor force participation are madejointly, the results of such a specification would suffer fromsimvitaneity bias (Theil, 1971:429-432). 469 434predicted by means of logistic regression analysis.' Thecoefficients estimated from these models represent the effectE ofindependent variables on the probability (log-odds) of being in aparticular labor force-school enrc.\"Ilent status (i.e., LPP1, LFP2,LFP3) as opposed to being in the base category (i.e., out of the laborforce and out of school).The next step is to specify models for employment versus unemploy-ment for whites and Hispanics in both cohorts. Paral_a to labor forceparticipation, employment and school enrollment are treated as jointlydetermined variables. The dependent variable has four categories:employed and in school (labeled EMP1), employed and out of school(EMP2), unemployed and in school (EMP3), and unemployed and out ofschool (the base category). A se' of logistic regressions is then runto predict membership in the first three employment-school enrollmentstatuses (i.e., F.MP1, EMP2, and EMP3). Because employment is definedonly for those who participate in the labor force, the estimatesderived from the logistic regressions for employment are conditional onparticipation in the labor force. ResultsTe les 5 and 6 show the number of cases used in the analysis andthe means and standard deviations of the independent variables forlabor force participation and employment models for white am' Hispanicsophomores aTIO seniors.The data in Table 5 confirm a number of findings of past research(see above).Hispanic youths tend to come from poorer families thanwhite youths.Hispanics show a shorter length of U.S. residence on allthree length-of-residence variables. Hispanics are also much morelikely to be bilingual and, among bilinguals, to report a greaterfacility with the non-English language (i.e., Spanish) than whites.Hispanics *also do poorly in school relative to whites: they have lowergrades and score less well on standardized tests. These patterns arethe same for both the sophomore and senior cohorts. These results arealso similar for those respondents uho are in the labor force (Mole6). Labor Force Participation of Sophomores Table 7 presents the results of the logistic regression analysesfor white and Hispanic sophomores' labor force participation-schoolenrollment.For both Hispanics and whites, only one sex effect \"Be4.ause the dependent variables are dichotomous, ordinary leastsquares regressions would produce estimate that are not minimumvariance unbiased estimates because of heteroskedasticity. A logitspecification solves (see Theil, 1971:631-633). 47o 5Means and StanJard Deviations for variables in Labor ForceParticipation-School Enrollment Analysis Sophomores Seniors White Hispanic surfaces Table 7: males are significantly more likely than femalesto be in the labor force and enrolled in school.,onsidering the other demographic variables, th, results for ageare as expected: older ouths are rime involved in the labor force andless involved in school. Among Hispanics, older youths are more likelyto be in the labor force and out of school (see equation for LFP2) andare less likely to be in school and out of the labor force (equationLFP3) than out of the labor force and out of school.The results foe whites follow a similar patter's, although oneeffect is statistically significant, i.e., the effect of age in the BEST COPY AVAILABLE 4 4 , 436TABLE 6Means and Standard Deviations for Variables in EmploymentStatus-School Enrollment Analysis Sophomores Seniors White LFP1: white youths are more likely to be in thelabor force and in :ch -ad than in any of the other categories.The independent effects of marital status on labor force participa-tion and school enrollment are similar for whites and Hispanics, evenfor this very young group. For both whites and Hispanics, having beenmarried decreases the chances of being in the labor force and in schooland increasea the odds of being in the labor force and out of school asopposed to being in either of the out-of-the-labor force categories(i.e., the base cate,:ory and LF103). For both whites and Hisoanics,married people fine it particularly difficult to participate in bothschool and the labor fc.rce. BEST COPY AVAILABLE47, TABLE 7Effects of Independent Variables on Labcr Force Participation-School Enrollment Status for White COPY AVAILABLE 438 The scnolastic achievement variables show significant effects forboth whites arJ Hispanics. For Hispanics, the higher the base-yeargrade-point average, the greater the probability of being in school andout of the labor force and the lower the chances of being in the laborforce and out of school (see equations for LFP2 and LFP3). This samepattern surfaces for whites as well, but the t-test for the coefficientin the equation for LFP1 fails significance. Performance on the batteryof standardized tests is not related to labor force participation orschool enrollment once the otner predictors in the model are controllei.The equation for Hispanics predicting LFP2 is an exception: betterperformance on the test battery lowers the chances of being out ofschool and in the labor force.The lack of significant effect: for the composite test scoresuggests that between-school variation in scholastic achievement islargely irrelevant to dropout and labor force decisions.\" Thesignificant effects of grade-point average, which only vary withinschools, strongly suggest that the effects of scholastis' achievement ondropout and labor force participation decisions are highly contextual.It is only students' scholastic achievement relative to others in theirschool context that affects their decisions to leave school and/orparticipate in the labor force.7: The last of tiva general variabl- i.e., previous work experience,has similar effects on labor force participation and school enrollmentfor Hispanics and whites. Those respondents who worked at the time ofthe base-year survey are less likely to be exclusively in school (seethe equations for LFP2), although the effect for Hispanics fails to besigni-icant.Previous work experience also increases the chances thatboth whites and Hispanics combine school and labor force activities(UPI.) and decreases their chances of being out of school and in thelabor force (LFP3). Therefore, unlike previous studies that find thathigh school students who work suffer significant costs in terms oftheir schooling (Steinberg et al., 1982b), these data show no tendencyfor either Hispanics or whites to be pulled out of school and into thelabor force by virtue of having worked during their sophomore year.Considering the effects of specific factors on youths' labor forceparticipation and school enrollment, none of the -U.S.-residence variables (i.e., mother's, father's, respondent's) sigr fi-cantly distinguishes among four categories of the dependentvariable.The only exception is the coefficient for father's length ofresidence in the equation for LFP1 for Hispanics: respondents whosefather have been in the United States longer are more likely to be inthe labor force and in school. \"Recall that test performance varies both Letween and withinschools, while grade-point average only varies within school. Becausegrade-poi-Average is controlled in these models, test scoreperformerlarci,ely taps the effects of betwlen-school variation inscholastic, achievement. 4'7 4 439in terms of the effects of the language variables, exposure ofHispanics to Spanish during their upbringing does not significantlypredict school continuation or labor force participation. Althoughcompared with Hispardus relatively few whites had been exposed toanother language (see Table 7), exposure of whites to a non-Englishlanguage raises the probability of their being in the labor force andout of school.Contrary to expectations, none of the language variables signifi-cantly distinguishes among the four categories of the dependentvariable for Hispanics. Why the effect of non -Er Ash-languagebackground appears for whites but not for Hispanics is unclear.Last among the language variables, the effects of the measure ofEnglish-language proficiency (vocabulary test score) cu. labor forceparticipation and school continuation are nil for both Hispanics an3whites.This is most likely because the main effects of English-language proficiency for these youth are probably through scholasticachievement (see Nielsen and Fernandez, 1982), which has beencontrolled in these models.Finally, the dummy variables for Hispanic subgroup show only oneeffect.After the other variables in the model are controll \"d, Cubansare more likely to combine school and labor force activities and areless likely to be in the labor force and out of school than any of theother Hispanic subgroups.The lack of significant effects for the dummy variables forHispanic subgroup implies that the other variables in the model haveexplained the subgroup variation in school continuation and labor forceparticipation. Most important among the variables that hay been foundto account for differences in achievement among Hispanic subgroups isfamily socioeconomic background. For example, the relative affluenceof the Cubans (see Jorge and Moncanz, 1980) is often cited as a majorreason for Cubans' greater success in school and the labor market (seeNielsen and FernaAez, 1982).13 However, other variables alsoexplain the dependent variables, and consequently, differences amongHispanic subgroups in labor force participation and school enrollmentare the same ones that are important for whites, i.e., scholasticachievement, previous work experience, and marital status. Accordingto these results, the processes by which Hispanics and whites decide tostay in or leave school and participate or not participate in the laborforce are very similar. The \"specific\" variables that I hypothesizedwould be necessary to explain Hispanics' underachievement have provento be insignificant. ,,-------\"Noto that the latest wave of Cuban immigrants, the Mariel refugees,arec as affluent as early waves (see Bach, 1980). However, thesedata Lnot contain any of these refugees b..ause the High School andBeyond sample was drawn prior to the Mariel boat lift. 475 440Employment of SophomoresTable 8 shows the coefficients of models predicting employment andschool enrollment as joint dependent variables for sophomores. Similarto the results for labor force participation, sex does not significantlydistinguish among the categories of the dependent variable. Consideringthe other demographic variables, age is a significant predictor in twoequations, i.e., EMP1 and EMP2 for Hispanics. Older Hispanics are lesslikely to be employed and in school and more likely to be employed andout of school than younger Hispanics.Similar to the pattern for labor force participation, marital statusis a sf.rong predictor of employment and school continuation for bothwhites and Hispanics, independent of the other variables in the model.Being married increases the chances that the zespondent is employed andout of --hr,o1 and lowers the probability of being employed and inschool for both whites and Hispanics. These results imply that bothwhites and Hispanics are more likely to be unemployed and out of schoolor unemployed and in school than being in school and employed.Apparently, employment and schooling are an either-or preposition forthose whites and Hispanics who are married.Looking at ramily socioeconomic background, socioeconomic status isrot a significant predictor for either whites or Hispanics. The factthe effects of family socioeconomic background are weaker foremployment than for labor force participation for whites is not sur-prising.Family socioeconomic background may make it mos cr-lessdesirable to seek employment, but actually securing a job involvesconvincing an employer that one is worth hiring. Especially in theyouth labor market, fa. ily background is unlikely to be an importantmarket signal to employers (see Spence, 1974).1 Although thelow-wage, low-skill, structure of the youth job 1983) is likely ?ass dependent on productivity-related criteria, employersare probably more likely to pay attention to the effects of past workexperience and the characteristics measured by the second set ofgeneral predictors, i.e., scholastic achievement.Similar to the pattern of results for labor force participation,past work experience increases the chances of being it the two employedcategories (i.e., EMP1 and EMP2) anC lowers the probability of beingunemployed and in school (EMP3). This pattern is similar for both '\"Osterman .1980) shows data to support the argument that parents arecrucial in helping many youths get started in the job market byproviding youths with networks of personal contacts that help them findjobs.The effects of such job contacts or youths' probability ofemployment is certain to be positive, but this process is probably onlymarginally :elated to these family background factors. Such networkvariables may account for the significance of mother's and father'spresence in the home in increasing youths' labor force participationand employment. 476 TABLE 8Effects of Independent Variables on Employment Status-School Enrollment Status 477 442 whites and Hispanics, although the coefficient in the EMP2 equation isnot significant for Hispanics. Here, too, there is no evidence of workexperience drawing students out of school.General scholastic achievement, as measured by performance on thetest battery, is unrelated to the dependent variables for w1 tes.ForHispanics, better performance on the tests raises the probability ofbeing employed and in school. The pattern for the test-score coeffici-ent in the other two equations implies that better students are morelikely to be in school, but neither of these effects is significant.However, two of the three coefficients for grades are significant forboth .,:cites and Hispanics. Higher grades increase the probability ofbeing employed and in school and decrease the chances of being employedand out of school.The fact that grade-point average is a significant predictor ofemployment suggests that employment choices are also made within thecontext of school. But unlike the case with labor force participation,wherein students choose whether to look for work, employment choicesalso reflect employers' choices among competitors looking for work.Because of the highly local nature of the youth job market (see Borub,1983), especially for younger youths (see Osterman, 1980), it ispossible that employers' hiring decisions are also made with referenceto the same school context that students refer to when making theirlabor force participation decisions. Therefore, while better school-performance increases students' school attachment and lowers theirprobability of labor force participation (see Table 7), employers tryto choose the best students from among those who do choose to par-ticipate in the labor force--if nct for their skills, then simply fortheir i.,etter discipline (for a similar argument regarding education anddiscipline, see Bowles and Gintis, 1977).In terms of specific variables, none of those measuring languagepatterns or immigration history significantly distinguishes the fourcells of the dependent variable. The only exception to this pattern isthe effect of non-English-language background in the equation for EMP2for whites.Contrary to my predictions, Hispanics' special circum-stances play no role in explaining their school continuation oremployment.If these results are to be trusted, thin would imply thatemployers do not find these specific characteristics relevant criteriaon which to base their hiring decisions.Finally, unlike the results for labor force participation, none ofthe subgroups is significantly different in its employment behavior.Apparently, the advantages that Cubans have in the transition into thelabor force do not appear in employment, once the other variables inthe model have been controlled. Labor Force Participation of SeniorsTable 9 shows the results of the logistic regressions predictinglabor force participation for members of the senior cohort. Asmentioned above, the main differences between the senior and sophomorecohorts are that the seniors a:e, on average, two years older than the 473 TABLE 9Effects of Independent Variables on Labor Force Participation-School Enrollment Status forWhite and 479 444 sophomores (compare Tables 7 and 8) and the seniors are all high schoolgraduates; this means that for seniors, school enrollment refers toparticipation in postsecondary education at any time in the two yearsafter the base-year survey.Sex differences in labor force-school enrollment status are stroryerfor the seniors than the sophomores. Among Hispanics, one effectsex appears:males are less likely to be in the labor force and inschool (LFP1) than females. Two sex differences surface as significantpredictors for whites. White males are more likely than white femalesto be out of the labor force and in school (LFP3) and less likely to bein school and in the labor force.Considering the effects of the other demographic variables, maritalstatus is a strong predictor of labor force participation and post-secondary school enrollment for both whites and Hispanics. Whites whoare married are (in order) most likely to be: (1) inlabor force and out of school (LFP2); (2) out of the labor force and out of school(the base category); (3) in school and in the labor force (LFP1); or(4) out of the labor force and in school (LFP3). For Hispanics, beingmarried clearly affects postsecondary school attendance: Hispanics aremost likely to be in the two out-of-school categories (LFP2 and thebase category) and least likely to be in the two in-school categoriestr,FP1 and LFP3).-CCSimilar to the patterns for sophomores' labor force participation,#mily socioeconomic background is a significant predictor of bothtrite and Hispanic seniors' labor force participation. For both whitesilltd Hispanics, respondents from more affluent families are most likelyto be attending postsecondary school and not be in the labor force-(1FP3) andare least likely to be in the labor force and out of schoolPFP2).Finally, whites from more affluent family backgrounds havehigher chances of combining school and labor force participation(UPI.), although this is not as likely an outcome as LFP3.-4--The results of the scholastic-achievement variables for seniors, inebntrast to the results for sophomores, reveal significant effects ofboth test scores and grades. Test scores are significant here probablybecause colleges routinely use performance on standardized tests (suchas the Scholastic Aptitude Test), which are likely to be correlatedwith the test battery use. in High School and Beyond,ls as screeningdevices.It is not surprising, then, that better performance on thestandardized tests increases the probability of being exclusivelyenrolled in postsecondary education for whites, although the cor-responding effect for Hispanics fails to be significant (see equationsfor LFP3).Better test performance also serves to lowur the probabilityof respondents' being out of school and in the labor force for bothwhites and Hispanics (see the equations for LFP2). But, whereasHispanics who score well on the standardized tests are more likely tocombine school and labor force activ ty, whites are not (see equationsfor LFP1). \"The test battery fur High School and Beyond was developed byEducational !Lesting Service, Princeton, N.J. 430 445 Independent of performance on the tests, grades are a strongpredictor of school and labor force activities for both whites andHispanics.Here, too, the effect is probably due to colleges' usinggrades as an admittance criterion. For both whites and Hispanics,higher grades increase the chances of being in either of the in-schoolcategories (LFP1 and LFP3) and decrease the chances of being in eitherof the in-labor-force categories.Last among the general predictors of achievement, previous workexperience has strong effects in the expected directions for bothHispanics and whites. Fcr both groups, previous work experienceincreases the likelihood of being in the labor force regardless ofwhether respondents are in school.Considering the effects of the specific variables, among thelanguage variables, proficiency in English (as measured by thevocabulary test) is unrelated to either postsecondary attendance orlabor force participation for whites. However, English proficiencydoes distinguish among some of the categories of the dependent variablefor Hispanics.Greater English proficiency lowers the chances of beingin the labor force and in school (LFP1) but increases the probabilityof being in school and out of the labor force (LFP3) for Hispanics.On the other hand, proficiency in a non-English language showb someeffects for whites, but not for Hispanics. Among hites, better non-English language proficiency increases the chances of combiningpostsecondary education and labor force participation (LFP1) andTdecreases the probability of being out of school and in the labor force(LFP2).The length-of-residence variables indicate only two significanteffects.Hispanics whose mothers are' long-time residents of the UnitedStates are less likely to be in school and in the labor force (LFP1).Among whites, respondents who are long-time residents of the United.:States are more likely to combine labor force participation and -postsecondary education (LFP1).Finally, unlike the pattern in the analyses for the sophomores, thedummy variable for the Puerto Rican subgroup indicates that they aresignificantly more likely than other Hispanics to ;- out of the laborforce and 'school. Seniors' Employment Table 10 presents the resIllts of the models of employment andpostsecondary enrollment for seniors. As noted above, these estimatesare for respondents who are in the labor force and who are high schoolgraduates.Examining the effects of the demographic variables indicates thatthere is only one effect of sex (on EMP3 for Hispanics). AmongHispanics, males are significantly more likely to be unemployed and inschool than females.There are two significant effects of age, i.e., predicting FMP1 forwhite and predicting ERP3 for Hispanics. For whites, older respondentsare less likely to be employed while in school. Among Hispanics, older BEST COPY AVAILABLE481 TABLE 10Effects of Independent Variables on Employment Status-Schoo2 Enrollment to be unemployed while attendingpostsecondary education.As has been the case in all the analyses, maatel status emerges asan important predictor of seniors' employment and school enrollment.For both whites and Hispanics, married respondents are less likely tobe employed and in school (EMP1) or anemployed and in school (EMP3).However, this latter effect is insignificant for Hispanics. For bothHispanics and whites, married rk. -'tints are more likely to beemployed and out of school (EMP2)Turning to the effects of fami socioeconomic background, theeffects are similar to those found for labor force participation.Among whites, respondents from more affluent family backgrounds aremare likely to be in the two in-school categories of the dependentvariable (EMP1 and EMP3) and less likely to be in the two out-of-schoolcategories (EMP2 and the base category). The pattern is the same .orHispanics, but the effect of family background in the equation for EMP3is not statistically significant.Considering the effects of the scholastic achievement measures, thepattern for both whites and Hispanics is familiar. Higher grade-pointaverages increase the probability of being employed and in school(EMP1) and lower the chances of being employed and out of school(EMP2).Better performance on the test battery has similar effects.As discussed above, these patterns are probably due to collegeselection criteria.The effects of the final general variable considered--previous workexperienceart also the same as those found in the other analyses.For both whites and Hispanics, respondents who worked during the baseyear are more likely to be employed and in school (EMP1) and lesslikely to be unemployed and in school (EMP3).Examining the specific variables, there is some evidence of langu-age effects among whites, but not among Hispanics. Among whites,greater facility in a non-English language significantly increases thechances of being employed and in school (DIM and lowers the chancesof being employed and out of school (EMP2). Finally, English pro-ficiency, as measured by performance on the vocabulary test, increasesthe probability of postsecondary school enrollment and employment(EMP1).Among the variables measuring the length of U.S. residence, onlyone effect appears for Hispanics: respondents whose mothers arelong-time residents in the United States are less likely to be employedand enrolled in school (MP1). Among whites, two effects surface,i.e., respondents who are long-time U.S. residents are more likely thanrecent immigrants to be employed and in school (EMP1) and less likelyto be employed and out of school (EMP2).Finally, none of the dummy variables for the Hispanic subgroups issignificantly related to the dependent variable. This implies that thesubgroup differentials in unemployment rates found in Table 4 have beenexplained by the model. P-3 448SUMMARY, CONCLUSION, AND POLICY RECOMMENDATIONS The descriptive analyses in this paper have shown that Hispanicsfare worse, overall, than whites, but not as poorly as blacks, in theschools and in the labor market. Hispanic youths drop out of highschool at a higher rate than white youths and a lower rate than blackyouths.Similarly, the unemployment rate for Hispanic youths is higherthan the rate for white youths and lower than the rate for black youths.These statistics for the overall Hispanic population mask considerableheterogeneity among the various Hispanic subgroups. Specifically,Cubans and other Latin Americans fare relatively well when comparedwith whites, but Puerto Ricans and Mexican-Americans fare relativelypoorly.Puertc Rican youths have particularly severe employmentproblems and often have unemployment rates that are as high as orhigher than the rates for black youths.The descriptive analyses also show that Hispanic-white disparitiesin labor force participation and unemployment are more severe amonghigh rzhool dropouts than among students in school. These differ-entials are even smaller for the population of high school graduates.The multivariate analyses that attempt to explain labor forceparticipation, unemployment, and school enrollment for whites andHispanics show a number of patterns. For both whites and Hispanics inthe sophomore and senior cohorts, family socioeconomic background isconsistently related to labor force participation and school enrollment;it is related to employment for seniors, but not for sophomores. Witha few exceptions, the specific factors of language and family-immigration history are not consistently related to school and labormarket achievements for either Hispanics or whites.The two most important determinants of labor force participation,employment, and school continuation for both white and Hispanic youthsare scholastic achievement and previous employment experience. Forboth white and Hispanic sophomores, grade-point average is a consistentpredictor of these school and labor market variables. For seniors,both grades and performance on standardized tests are related to theoutcome variables for both whites and Hispanics. Previous work experi-ence is also strongly related to the dependent variables fir both whiteand Hispanic youths.In conclusion, it appears that the root of Hispanic youths' labormarket problems lies in their education. These results would suggestthat policy efforts should be directed toward solving the problem ofHispanic underachievement in the schools. However, the positiveindependent effects of previous work experience also suggest that youthemployment programs are likely to have beneficial results for Hispanicyouths.Therefore, a two-pronged approach--through the schools and inthe labor market--is likely to be most fruitful in tackling Hispanicyouth employment problems. 4 84 449APPENDIXCODING INFORMATIONRespondents are classified as Hispanic in this paper on the basisof their answer to the following question from the High School andBeyond follow-up questionnaire: \"What is your origin or descent? (Ifmore than one, please mark below the one you consider the most impor-tant part of your background).\" Under the general heading of \"Hispanicor Spanish\" were grouped four possible answers: (1) Mexican, Mexican-American, Chicano; (2) Cuban, Cubano; (3) Puerto Rican, Puertoriqueno,or Boricua; and (4) Other Latin American, Latino, Hispanic, or Spanishdescent.For simplicity, these have been labeled Mexican-American,Cuban, Puerto Rican, and other Latin American. Respondents areconsidered white if their response is something other than Hispanic 4.1sthe national-origin question and \"white\" to the question \"What is yourrace?\"RespondentL are defined as black in a similar fashion. Theterms \"white\" and \"black\" as used in this paper, then, refer to whitesand blacks not of Hispanic origin. Hispanics were not differentiatedfurther on the basis of race, because the distinction between conceptsof race and ethnicity is blurred in the case of Hispanics. Many of therespondents answered \"Other\" to the race question, implying that theyview their group as a distinct \"race\" (Nielsen and Fernandez,1982:Table 1.3).Regarding the measurement of the dependent variables (labor forceparticipation. employment, and school enrollment status), respondents'labor force status is classified on the basis of their responses to thefollowing questions. Sophomores were asked two items in the follow-upsurvey:(1) \"Did you do any work for pay last week, not counting workaround the house?\" and (2) \"Whether or not you already have a job, wereyou looking for a job last week?\" Response categories of \"Yes\" and\"No\" were offered for both questions. Respondents' military enlistment(see Table 3) was determined from this question on the dropout survey:\"What were you doing the first week of February 1982?\" Among theanswers offered was \"On active duty in the Armed Forces (or serviceacademy).\"Youths who chose this option, regardless of their responseson the labor force status questions, are counted as being enlisted inthe military.For the civilian population (i.e., those who did notchoose the \"On active duty in the military\" option), respondents aredefined as employed if they answered \"Yes\" to question (1) above.Civilian respondents are classified as unemployed if they answered \"No\"to question (1) and \"Yes\" to question (2). Civilians who answered \"No\"to both questions are defined as being out of the labor force.Finally, schoo' enrollment status for sophomores is based on whetherthe respondent was part of the dropout or the in-school follow-upsample.Parallel to the sophomores, senior cohort respondents who chose the\"On active duty in the Armed FOrces (or service acalewy)\" option of thequestion \"What were you doing the first week of 1982?\" are treated asbeing enlisted in the military (see Table 5), regardless of theirchoosing other employment- or school-related options. The employment- 485 450related options are (1) \"Working for pay at a full-time or part-timejob,\" (2) \"With a job but on temporary layoff from work or waiting toreport to work,\" and (3) \"Looking for work.\" Civilians are classifiedas employed if they chose the first option, Laemployed if they chosethe second or third option, and out of the labor force if they did notchoose any of these options. The school-related options were (1)\"Taking academic courses at a two- or four-year college\" and (2)\"Taking vocational or technical courses at any kind of school orcollege (for example, vocational, trade, business, or other careertraining school).\" Civilian respondents are classified as enrolled inpostsecondary education if they chose either of the school-relatedoptions, regardless of whether they chose any of the employment-relatedoptions.The type of postsecondary school that respondents were enrolled in(see Table 4) was not determined by the above school-related item.Rather, respondents were asked to provide the names and addresses ofthe postsecondary schools that they had attended since leaving highschool.Those names and addresses were then matched with data on thecharacteristics of postsecondary educational institutions (the 1982-1983Institutional Characteristics Survey of HEC.S, Higher Education GeneralInformation Survey, collected by the National Center for EducationStatistics).These data were used to group respondents into the fourtypes of postsecondary school enrollment. Note that the data on typeof postsecondary enrollment refer to the school that respondents wereenrolled in at the time ,f the follow-up survey (February 1982) or, ifno. enrolled at that time, the last postsecondary school they wereenrolled in.Regarding the measurement of family socioeconomic status, thevariable is a linear composite derived from measures of father'soccupation, father's and mother's education, family income, and a setof questions that ask whether the respondent's family receives a dailynewspaper; whether the family possesses an encyclopedia or otherreference books, typewriter, automatic dishwasher, two or more cars ortrucks, more than 50 books, or a pocket calculator; and whether therespondent has his or her own room. Coding on this variable is basedon a linearly weighted combination of the above family backgroundmeasures, where the weights are derived from the non-missing data. Ifa case has missing data on any of these background variables, t.composite is computed from the non-missing data for that case (seeJones et al., 1983:62).Grades are measured by the question, \"Which of the following bestdescribes your grades so far in high school?\" Eight response categorieswere offered from \"Mostly A\" (a numerical average of 90 to 100) to\"Mostly below D\" (below 60). The variable was recoded on a four-pointscale so that \"Mostly A\" is \"About half A and half B\" iscoded \"3.5,\" and so on, down to \"Mostly below D,\" which is coded \".5.\"The standardized test scores used in these analyses are a compositeof reading, vocabulary, and mathematics tests administered during thebase-year survey [see Heyns and Hilton (198%) for a detailed discussionof the High School and Beyond cognitive teats). For both the sophomoreand senior cohorts, each individual test 4as standardized within cohort 486 451 to have a mean of 50 and a standard deviation of 10. For sophomores,the composite was computed by taking the mean of the non-missing testscores.This procedure was slightly modified for seniors because theywere administered two vocabulary tests. Items from the two vocabularytests were combined before the vocabulary test was standardidized (seeJones et al., 1983:Section 6.9). The test composite was then computedby taking the mean of the standardized non-missing reading, vocabulary,and mathematics test scores.Regarding the demographic variables (i.e., age, sex, and maritalstatus), age and sex were measured by base-year items. However, becausemarital status was not measured directly in the base-year survey forseniors, a question from the follow-up survey was used: \"What was yourmarital status the first week of February 1982?\" Responses were recodedso that 1 = ever married (i.e., married, divorced, separated, widowed)and 0 = never married. Because sophomores were not asked their maritalstatus directly in either the base -year or follow-up surveys, thefollowing question from the follow-up survey was used to distinguishrespondents who had been married from those who had not been married.Respondents were presented a question worded \"At what age do you expectto ... ,\" which was completed with a number of items, including \"GetMarried?\"Among the response categories for this question is \"Havealready done this.\" Respondents who chose this response to the \"GetMarried\" item were coded in parallel fashion to the seniors, i.e., 1 =ever married, versus 0 = never married for those who did not choosethis response.Both sophomores ari seniors were asked, \"Did you do any work forpay last week, not counting work around the house?\" Responses of \"yes\"and \"no\" were offered and are coded here as one and zero, respectively.Regarding parent's length of U.S. residence, students were asked inthe base-year survey how much of their mother's and father's live; havebeen spent in the United States. Each variable had five response cate-gories:(1) about 1-5 years; (2) about 6-10 years; (3) about 11-20years; (4) more than 20 years, but not all; and (5) all or almost all.Categories (1) through (3) were recoded to the midpoint (3, 8, and 15.5years, respectively). Categories (4) and (5) presented more of a prob-lem because they implicitly refer to the parent's age, for which HighSchool and Beyond does not have a measure. The values for these twocategories were imputed by using the modal age of mother's childbearing(25) and adding the student's modal age (15 for sophomores and 17 fcirseniors) and assigning that to the fifth (\"All or almost all\") cate-gory.Therefore, the value imputed for sophomores is 40 and forseniors, 42.The midpoint of the fourth category then became defineda' 29 years for sophomores and 31 years for seniors. This procedurewas repeated for father's length of residence, but three years wereadded to account for a typical (three-year difference in age betweenhusbands and wives. Thus, the fourth and fifth categories for father'slength of residence were receded to 43 and 30.5, respectively, forsophomores, and 45 and 32.5 for seniors.Students were also asked to report how much of their lives had beenspent in the United States. The response categories were (1) about 1-5years; (2) about 6-10 years; (3, nitre than 10 years, but not all; and 452 (4) all or almost all. Since available data included the student'sage, all the categories were well defined and student's age was not available, it was imputed for use inthe student length-of-residence variable as the modal age--forsophomores 15 and for seniors 17. This was done for only a few cases.Language questions were administe,:ed through a separate question-naire to all respondents (i.e., not just Hispanics) who passed a filterof five questions that asked about the respondent's mother tongue andlanguages presently spoken at home. Those students who reported alanguage other than English in response to one of the five questionsregarding language background were asked to choose on a four-poiltscale how well they understood, spoke, read, and wrote the non-Englishlanguage.The response categories are Not at All,\"Not Very Well,\"\"Pretty Well,\" and \"Very Well and were coded from zero to four.Exploratory factor analysis of the survey's pretest data showed thatthe four items clearly load on one factor, with each of the indicatorscontributing equally (see Fernandez, 1910). The composite indez wasformed by taking the mean of the four items. Note that the coding ispositive, ranging from a low of zero (indicating no proficiency in theother language) to a high of three (indicating high proficiency).Those students who did not pass the language background filter (i.e.,were monolinguals) were assigned a zero on the scale for proficienly innon-English language. When combined with the dummy variable forlanguage background, this coding has the effect of creat-ng a splinefor the proficiency-in-other-language scale.English proficiency is measured by the student's performance on th-:base-year standardized vocabulary test. To simplify across-cohortcomparisons, the scores used are based on the subset of test items thatwere identical in the sophomore and senior test batteries. The test isstandardized to a mean of 50 and a standard deviation of 10. 488 453 REFERENCES AND BIBLIOGRAPHYAlbert, Martin L., and Loraine K. Obler1978The 26:535-546.Aspira1976Social Factors in Educational Attainment among Puerto Ricansin U.S. Metropolitan Areas 1970.Puerto Ricans and EducationReport No. 1.New York:Aspira of America.Bach, Robert L.1980The new their background and prospects.Monthly Labor Review 103(October):39-46.Barrera, Mario1979Race and Class in the Southwest. South Bend, Ind.:University of Notre Dame Press.Barth, Fredrick, ed.1969Ethnic Groups and Boundaries. Boston, Mass.: Little, Brown.Blau, Peter M., and Otis Dudley Duncan1967The American Occupational Structure. New York:John Wiley &Sons.Borjas, George L.1982The earnings of male Hispanic immigrants in the UnitedStates.Industrial and Labor Relations Review 35, no. 3(Apkil):343-353.Borus, Michael E., ed.1983Tomorrow's Workers. Lexington, Mass.: D.C. Heath.Borus, Michael E., J.E. Crowley, R.W. Rumberger, R. Santos, and DavidShapiro1980Pathways to the Future: A Longitudinal Study of YoungAmericans.Youth Knowledge Development Report 2.7.Washington, D.C.: U.S. Department of Labor.Bowles, Samuel, and Herbert Gintis1977Schooling in Capitalist America. New York:Basic Books.Briggs, Vernon M., Walter Fogel, and Fred Schmidt1977The Chicano Worker. Austin:University of Texas Press.Bureau of the Census1979aCoverage of the Hispanic population of the United States inthe 1970 census: a methodological analysis. CurrentPopulatio^ Reports. Series P. 23, no. 82. Washington, D.C.:Bureau of the Census.1979bPersons of Spanish origin in the United States: March 1978.Current Population Reports. Series p. 2U, no. 339.Washington, D.C.: Bureau of the Census.1982Population profile of the United States: 1981.CurrentPopulation Reports. Series P. 20, no. 374. Washington,D.C.:Bureau of the Census.Carliner, Geoffrey1976Returns to education for blacks, anglos and five Spanishgroups.Journal of Human Resources 11:172-184. 489 4541980Wages, earnings, and hours of first, second, and thirdgeneration American mJes. Economic Inquiry 18:87-102.1981Wage differences by language group and the market for languageskills in Canada. Journal of Human Resources 16:384-399.Carter, Thomas P., and Robert D. Segura1979Mexican-Americans in School: A Decade of Change. New York:College Entrance Examination Board.Chiswick, Barry1977Sons of immigrants: are they at an earnings disadvantage?American Economic Review 67(February):376-80.1978The effects of Americanization on the earnings of foreign-bornmen.Journal of Political Economy 86:897-922.1979The economic progress in immigrants: some apparentlyuniversal patterns. Pp. William Fenner, ed.,Contemporary Problems. Washington, D.C.: AmericanEnterprise Institute for Public Policy Research.1980aAn analysis of the economic progress and impact ofimmigrants.Washington, D.C.: U.S. Department of Labor.1980bImmigrants' earnings patterns by sex, race, and ethnicgroupings.Monthly Labor Review 103(October):22-25.1982The Employment of Immigrants in the United States.Washington, D.C.: American Enterprise Institute for PublicPolicy Research.Clark, Juan M.1977The Cuban Exodus. Why?Report 1.1 the Fla.Photocopy.Clogg, C.1979bjeastirpIUnderemloernrahicThdicatorsfortheUnited States. Bilingualism on Cognitive Growth: ASynthesis of Research Findings and Explanatory Hypotheses.Working Papers on Bilingualism No. 9. April:1-43.1977Psycholinguistic evidence. Pp. 78-89 in Center for AppliedLinguistics, ed., Bilingual Education: Current 4, Education. Arlington, Va.: Center for AppliedLinguistics.Dillard, J.L.1973Black English: Its History and Usage in the United States.New York:Vintage Books.Duncan, Beverly1965Dropouts and the unemployed. Journal of Political Economy73:121-134.Duncan, 0.D., D.L. Featherman, and B. Duncan1972Socioeconomic Background and Achievement. Richard P.1983Hispanics' Education Predictors of CollegeAchievement.New York:College Entrance Examination Board.Edwards, Linda1976School retention of teenagers over the business cycle.Journal of Human Resources 11, no. 2 (Spring):1-13. 455 Estrada, Leobardo1980Review and analysis of Hispanic you':h employment datacollection systems and reporting methods. Pp. 21-50 inNational Council of La Raza, ed., Hispanic Youth Employment:Establishing a Knowledge Base. Knowledge Development Report10.1.Washington, D.C.: U.S. Department cf Labor.Featherman, David L., and T. Michael Carter1976Discontinuities in schooling and the socioeconomic lifecycle.Pp. 133-161 in W.H. Sewell, R.M. Hauser AmericanSociety.New York:Academic Press.Featherman, D.L., R.M. Hauser1978Opportunity and Roberto M.1980Selected analyses of the pretest data. Appendix D in FrancoisNielsen, Hispanic Youth in U.S. Schools: A Design forAnalysis.Washington, D.C.: National Center for EducationStatistics.Fernandez, Roberto M., and Francois Nielsen1984Bilingualism and Hispanic Scholastic Achievement: SomeBaseline Results. Unpublished manuscript. Department ofSociology. University of Arizona.Fishman, Joshua A.1969A sociolinguistic census of a bilingual neighborhood.American Journal of Sociology 75, no. 3:323-339.Fishman, Joshua A., and Robert C. Cooper1969Alternative measures of bilingualism. Journal of VerbalLearning and Verbal Behavior 8:276-282.Fishman, Joshua A., and Charles Terry1969The validity of census data on bilingualism in a Puerto Ricanneighborhood.American Sociological Review 34:636-650.Fligstein, Neil, and Roberto M. Fernandez1982The Causes of Hispanic Educational Attainment: History,Patterns, and Analyses. A report to the National Commissionfor Employment Policy, Washington, D.C.1985Educational transitions of whites and Mexican-AmericanS. ih Kohnke, David Buonanno, and Roger Tourangeau1981High School and Beyond Sample Design Report. Chicago, Ill.:National Opinion Research Center.Freeman, Richard, and David Wise, eds.1982The Youth Labor Market. Chicago, Ill.: University of ChicagoPress.Garcia, Phillip1983Dual Language Characteristics and Earnings: Male MexicanWorkers in the United States. Los Angeles Population ResearchLaboratory, University of Southern California. Photocopy.Harber, Jean R., and D.N. Bryen1976Black English and the task of reading. Review of EducationalResearch 46(3):387-405. 491 456Hauser, Robert M.1971Socioeconomic Back D.C.: American Sociological Association.Heckman, James J.1979Sample selection bias as a specification error.Econometrica47:153-162.Hernandez, J., L. F-trada, and r. Alvirez1973Census data and the problem of conceptually defining theMexican-American population. Social Science Quarterly53(4):671-687.Heyns, Barbara, and Thomas L. Hilton198?The cognitive tests for High Sc...,o1 and Beyond: anassessment.Sociology amon\"At-Risk\" Youth: Study of Language Minority Youth of Mexican Descent andLow Socioeconomic Status. Los Alamitos, Calif.: NationalCenter for Bilingual Research.Hogan, Dennis P.1981;transitions Lives of AmericanMen.New York:Academic Press.Jaffe, A.J., Ruth M. Cullen, and Thomas D. Changing Demography of Spanish Americans. New York:Academic Press.Jencks, C.S., M. Smith, H. Acland, M.J. Bane, D. Cohen, H. Gintis, B. Heyns, and S. Michelson1972Inequality:A Reassessment of the Effect of 2wily andSchooling in America. New YorksHarper and Row.Jencks, C.S., S. J. Crouse, D. Eaglesfield, 0, Jackson, K.McClelland, P. Mueser, M. Olneck, J. Schwartz, S. Waia, and J. Will4.ams1979Who Determinants of Clarke, Mooney, H. Crawford, B.Stephenson, and R. Tourangeau1983High School and Beyond: 1980 Senior Cohort First Follow-up(1982) Data File User's Manual. Washington, D.C.: National Center for Education Statistics.Jorge, Antonio, and Raul Moncanz1980Cubans in South Florida: a social science approach. Metas 1,no. 3 (Fall) :37-87.Labov, William1976Language in the Inner City: Studies in the Black EnglishVernacular.Philadelphia:University of Pennsylvania Press.Lambert, Wallace, and Richard Tucker1972Bilingual Education The St. Lambert Experiment.Rowley, Mass.: Newbury House.Lewin-Epstein, Noah1981Youth Employment During High School. AL knalysis of HighSchool and Beyond: A National Lon itudinal Study for the1980's.Washington, D.C.: National Center for Pp. La Raze, e.]., Hispanic Youth Employment:Establishing a Knowledge Base. Knowledge Development Report10.1.Washington, D.C.: U.S. Department of Labor.McKay, Roberta V.1974Employment and unemploymer* among Americans of .panishOrigin.Monthly Labor Review 97(April):12-16.McLaughlin, Steven D.1982English Language Proficiency, Occupational Characteristics andthe Employment Outcomes of Mexican-American Men. Seattle,Wash.:Battelle Human Affairs Research Centers.McManus, Walter, William Gould, and Finis Welch1983Earnings of Hispanic men: the role of English languageproficiency.Journal of Labor Economics 1(4'101-30.National Center for Education Statistics1980The Condition of Education for Hispanic Americans.Washington, D.C.: National Center for Education Statistics.National Commission for Employment Policy1982Hispanics and Jobs: Barriers to Progress. Washington, D.C.:National Commission for Employment Policy.National Commission for Manpower Policy, ed.1976From School to Work: Improviag the Transition. Washington,D.C.:National Commission for Manpower Policy.National Council of La Raza1980Hispanic Youth Employment: Establishing a Knowledge Base.Knowledge Development Report 10.1. Washington, D.C.: U.S.Department of Labor.Neugarten, Bernice, and G.O. Hagestad1976Age and the course. Pp. 35-55 in R. H. Binstock and E.Shanas, eds., Handbook of Aging and t', Social Sciences. NewYork:Van Uostrand Reinhold.Newman, Morris J.1978A profile of Hispanics in the U.S. work force. Monthly LaborReview (Decembcr):3-14.dielsen, Francois1980Hispanic Youth in the U.S. Schools: A DesignAnalysis.Washington, D.C.: National Center for Education Statistics.Nielsen, Francois, and Roberto M. Fernandez1982Achievement of Hispanic Students in American High Schools:Background Characteristics and Achievement. Washington,D.C.:National Center for Education Statistics.Noboa, Abdin1980Hispanics and desegregation: summary of Aspira's study ofHispanic segregation trends in U.S. achool districts. Metas1, no. 3 (Fall):1-24. 493 458 Olivas, Michael1979The Dilemma of Access: Minorities in Two Year Colleges.Washington, D.C.: Howard University Press.1981Financial Aid: Access and Packaging Policies. Institute forResearch on Educational Finance and Governance. Palo Alto,Calif.:Stanford University.O'Malley, J.M.1981Children's English and Services Study: Language MinorityChildren with Limited English Proficiency in the UnitedStates.Rosslyn, Va.:InterAmerica Research Associates.Ornstein, Michael D.1976Entry into the American Labor Force. New York:AcademicPress.Osterman, Paul1980Getting Started: The Youth Labor Market. Cambridge, Mass.:MIT Press.Peal, Elizabeth, and Wallace Lambert1962The relation of bii'ngualism to intelligence. PsychologicalMonographs:General and Applied 76(546):1-23.Pedraza-Bailey, Silvia1980Political and Economic Migrants in America: Cubans andMexicans.Ph.D. dissertation. Department of Sociology,University of Chicago.Pedraza-Bailey, Silvia, and Terry Sullivan1979Bilingual education in the reception of political immigrants:the case of Cubans in Miami, Florida. In Raymond V. Padilla,ed., Ethnoperspectives in Bilingual Education Research:Bilingual Education and Public Policy in the United States.Department of Foreign Langua:es and Bilingual Studies.Ypsilanti, Mich.: Eastern Michigan University.Peng, Samuel S.1977Trends higher education: 1961-1972.Educational Researcher 6(1):15-9.Portes, alinment: an analysis of 'han in the United States. Pp. York:Academic Press.Port's, Alejandro, Bach80Immigrants earnings: Cuban and Mexican in theUnited States. Migration Review 14(3):315-342.Portes,' Rjandro, J.M. Clark, and R.L. Bach1977The new wave:a statistical profile of recent Cuban exiles tothe United States. Cuban Studies7(January):1-32.Portes, Alejandro, J.M. Clark, and M. Lopez1981Six years later: the process of incorporation of Cuban exilesin the United 1973-1979.Cuban Studies 11, no. 2(July):1-24. 494 Cordelia W.1984Sources the family income white non-Hispanics. American Journal ofSociology 89(4):889-903.Rogg, Eleanor of W.1980High dropouts. Pp. 267-277 in M. Borus, J. Crowley, R.Rumberger, R. Santos, and D. Shapiro, Pathways to the Future:A Longitudinal Study' of Young Americans. Center for HumanResource Research. Columbus:Ohio State University.1983Dropping out of high school: the influence of race, sex, andfamily background. American Educational Research Journal 20,no. 2 (Summer):199-220.Ryscavage, Paul M., and Earl F. Mellor1973The economic situation of Spanish Americans. Monthly LaborReview 96(April):3-16.Sa-ana-Cooney, Rosemary1979Intercity variations in Puerto Rican female participation.Journal of Human Resources 14:222- 35.Santana-Cooney, Rosemary, and A.E. Warren1979Declining female participation among Puerto Rican NewYorkers:a comparison with native white nonSpanish NewYorkers.Ethnicity 6:281-297.Sewell, William H.1971Inequality of opportunity 36:793-809.Sewell, W.H., and R.M. Brent1976Schooling and its antecedents: substantive and status attainment process. Review ofEducational Research 46:463-625.Smith, Tom W.1980Ethnic measurement Ethnicity andmisidentification. American Statistical Michael1974Market UniversityPress.Steinberg, L.D., Garduque, and S. McAuliffe1982b High school students in the labor force: some costs andbenefits to schooling and learning. Educational Evaluationand Policy Analysis 4(3):363-372. 495 460Stevenson, Wayne1978aTht relationship between early work experience and futureemployability. Pp. 93-124 in Avril V. Adams and Garth L.Mangum, ed., The Lingering Crisis of Youth Unemployment.Kalamazoo, Mich.: W.E. Upjohn Institute for EmploymentResearch.1978bThe transition from school to work. Pp. 65-92 in Avril V.Adams and Garth L. Mangum, eds., Crisis Mich.: W.E. Upjohn forEmployment Research.Stolzenberg, and Non-Hispanics.Report Employment Policy.Santa Monica, Success Among Cuban-American and Mexican-American Immigrants: The Role of Policy and Community.Washington, r.C.: U.S. Department of Labor, Employment andTraining New York:John Wiley & Origin Workers in the U.S. Labor Market: ComparativeAnalyses of Employment and Earnings. Washington, D.C.: U.S.Department ethnicity and Chicano status attainment. 16(2):435-473.1983Market characteristics and Hispanic earnings: a comparison ofnatives and immigrants. Social Problems 31, no. 1(Octoter):59-72.Trieman, D.J., arcs K. Terrell1975Sex and the procsss of status attainment: a comparison ofworking women and men. American Sociological Reviee40(April):171-200.U.S. Commission on Civil Rights1971The Unfinished Education: Outcomes for Minorities in the FiveSouthwestern States. Washington, D.C.: U.S. Commission onCivil Rights.1974Counting the Forgotten: The 1970 Census Count of Persons ofSpanish Speaking Background. Washington, D.C.: U.S.Commission on Civil Rights.1978Social Indicators of Equality for Minorities and Women.Washington, D.C.: U.S. Commission on Civil Rights.19822UnemloentanideremloentAmong Blacks, Hispanics, andWomen.Washington, D.C.: U.S. Commission on Civil Rights. 4 JG 461U.S. Department of Health, Education and Welfare1974A Study of Selected Socioeconomic Characteristics of EthnicMinorities Based on the 1970 Census. Volume I:Americans ofSpanish Origin. Publication No. (OS) 75-120. Washington,D.C.:U.S. Department of Health, Education and Welfare.Veltman, Calvin1980Relative Educational Attainments of Minority LanguageChildren.Washington, D.C.: National Center for EducationStatistics.1981The Role of Language Characteristics in the SocioeconomicAttainment Process of Hispanic Origin Men and Women.Washington, D.C.: National Center for Education Statistics.Wilson, K.L., and W.A. Martin1982Ethnic enclaves: a comparison of the Cuban and Blackeconomies in Miami. American Journal of Sociology88(1):135-60.Wilson, Kenneth L., and Alejandro Porter1980Immigrant enclaves: an analysis of the labor marketexperiences of Cubans in Miami. American Journal of Sociology86:295-3l9. 497 The Participation of Young Women inEmployment and Training ProgramsMargaret Simms When the federal government initiated employment and trainingprograms in the 1960s, the focus was on assisting adult males who hadbeen displaced from their jobs by technological change or who werestructurally unemployed. Even in youth programs, where displacementand long-term unemployment were less important, the emphasis was onmales.It was thought that their employment needs were greater andthat unemployment was likely to lead to criminal beLavior among youngmen, but not among young women.Over time, the economic needs of women, especially young women,became an issue. Increased labor force participation by women and the\"feminization of poverty\" made policymakers and others aware of theimportance of providing meaningful employment and training opportunitiesto young women. This interest has been reinforced by studies thatindicate that unemployment among young women can have a deleteriouseffect on their future employment and earnings (Taggart and Linder,1980).In the absence of intervention, however, many young women willnot have favorable labor market experiences. This is especially truefor black women; the data indicate that labor force and employmentconditions fol. black teenage women have been deteriorating over thepastyears (Stormsdorfer, 1980; Swinton and Morse, 1983).Th,s paper reviews the participation of young women in employmenta.d training programs. The first section describes the variety ofprograms that youths have participated in, the level of participationby young women, and the characteristics of young female participantscompared with their male counterparts. The second section reviews thetype of service received by participants ard examines programoutcores.The final section summarizes the findings and suggestssubjects for additional research. Margaret C. Simms is director of the Minorities and Social PolicyProgram at The Urban Institute. The opinions expressed in this paperare the sole responsibility of the author and do not necessarilyrepresent the views of The Urban Institute and its sponsors. 46249& 463YOUTH PARTICIPATION IN EMPLOYMENT ND TRAINING ?ROGRAMS The federal government's post-Wo.ld War II involvement in employ-ment and training programs began -with the Manpower Development andTraining Act (MDTA) of 1962. Government training programs designedespecially for youths started with the creation of the NeighborhoodYouth Corps ;NYC) and the Job Corps through the Economic OpportunityAct of 1964.When the Comprehensive Employment and Training Act (CETA)was passed in 1973, most of the existing youth programs were includedin the consolidation of employment and training activities althoughthey Lemained separate activities. In 1977 the Youth Employment andDemonstration Projects Act (YEDPA) added additional programs targetedon youths.This legislation expired in 1981 and all youth trainingprograms were subsumed under the Job Training Partnership Act (JTPA) in1982.(Job Corps and the Summer Youth Employment Program (SYEP) areseparate programs under JTPA.)Young people have not only enrolled in youth programs but have alsoparticipated in the full range of employment and training programssince the mid-1960s. Between 1965 and 1972 youths were between 20 andnearly 50 percent of enrollees in such prcgrams as the PublicEmployment Program, the Work Incentive Program (WIN), MDTA, JobOpportunities in the Busi\".ess Sector (JOBS), and the ConcentratedEmployment Progrim (CEP). Youths (under age 22) constituted between 48and 62 percent of enrollees in CETA Title I in the years 1975 to 1981and more than 20 percent of enrollees in Titles II and VI during thesame years.' Female Participation Studies of participation in employment and training programs bywomen indicate that women have not been treated equally over thehistory of these programs. Between fiscal 1955 and fiscal 1978, womenwere less than one-half of program participants (Harlan, 1980). Infiscal 1978 women were 45 percent of enrollees in locally operatedprograms.By the last quarter of fiscal 1979, women were more than 50percent of enrollees in all local programs except on-the-job training.Very few studies have focused exclusively on participation by youngwomen, but estimates of their participation can be constructed fromdata on youth programs and from female and youth participation in adultprograms.Table 1 shows female participation in youth programs prior to the1973 passage of CETA and for selected programs under CETA and YEDPA.Before 1973, the largest youth program was the Neighborhood Youth 'After 1979, Titles I, II, and VI should be interpreted as TitlesII-B and C, II-D, and VI, respectively. No data are yet available onJTPA enrollment. See Burbridge (1983) for a history of youthparticipation in employment and training programs. 499 464TABLE 1Female Participation in Selected Youth Programs, 1965-1980 Percentage Female1965-197219781980 1965-1972Neighborhood Youth CorpsIn-school youths 45.2Out-of-school youths 47.7 Job Corps 27.01978-1980Job Corps 29.0NAYouth Employment and Training Programs 51.352.5Youth Community (1981). Corps.Over 4.5 million youths enrolled in NYC between 1965 and 1972, and between 45 and 48 percent of them were young women. In the muchsmaller, residential Job Corps program, young women were oily 27percent of enrollees. By 1978, women were 51 percent of enrollees inthe summer youth program (SYEP) and in Youth Employment and TrainingPrograms (YETP), but still lagged in Job Corps enrollment. Even so,they may still have been underrepresented in SYEP and YETP, since it isestimated that they were 54 percent of the eligible population (Berryman et al., 1981). Female enrollment in Youth Community Conservation andImprovement Projects (YCCIP) was only 24.8 percent in both 1978 ano 1980, although it is estimated that young women were about 46 percentof the eligible population for YCCIP. This discrepancy is thought tobe due to sexual stereotyping, since YCCIP involved intensive manuallabor, more so than did other programs (Burbridge, 1983).Overall, young women have done slightly better than adult women interms of participation in employment and training programs.However, this is primarily the result of their greater representation in youth programs.In adult CETA programs, women have been a smaller proportionof enrollees under age 22 than they have been of enrollees aged 22 and over (Table 2).An examination of the enrollment of youths in CETA and other employ-ment and training programs by race and sex reveals some minor differ-ences by sex, but far less than might be expected. Data from the 1977Continuous Longitudinal Manpower Survey (CLMS1 and Current Population Survey (CPS) reveal that women were just under 47 percent of the 465TABLE 2Female Participation in Adult CETA Programs, 1978 Women as a Percentage of ParticipantsAged 22 and Over Under Age 22 Title I 52.5 48.1Title II 41.6 34.7Title VI 37.4Total 45.5 48.6a Youth Employment Youth E-ployment andTraining Projects.SOURCE:S.E. Cht.w, and Bell (1981). enrollees in CETA programs and 50.3 percen* of the youth population(aged 22 and under) (Table 3). Most of the discrepancy was among whitewomen, whose participation in CETA was well below that of white men.Black and Hispanic women, whose CETA participation exceeded theirrepresentation in the population, participated at rates comparable tothose of their male counterparts. The National Longitudinal Survey(NLS) of Young Americans (see Borus, 1983:120) produced roughlycomparable estimates of participation in all government employment anetraining programs by youths between the ages of 14 and 21 during 1978and early 1979. Characteristics of Program Participants In addition to concern over their lower participation in government-sponsored employment and trai ing programs, it has been said that theyoung women are better qualified than the young men who enter theprograms.This may occur because there is more \"creaming\" among womenthan among men. In creaming, the program sponsor selects thoseapplicants who, in the sponsor's view, are the best qualified of thoseeligible to participate in the program. The young women who areselected into the program may have to meet higher standards in terms ofeducC:ion or prior experience. However, there could also be differencesbetween young men and young women in terms of who chooses to apply forthe employment and training programs. For example, if young women havedifferent perceptions about their likely '2articipation in the laborforce as adults, they might also differ in their interest in enrollingin employment and training programs. In a study done for The Rocke-feller Foundation, The Urban Institute examined the characteristics ofyoung women who participated in employment and training programs andcompared them with the characteristics of young men who participated 501 466 TABLE 3Percentage Distribution in the CLMS and CPS Populations by Raceand Sex for Individuals Under Age 23, Fiscal 1977 Percentage of CLMS Percentage and C.L. Betsey(1984). and nonparticipant youths. The objective of the study was to identifypossible differences and to determine which differences, if any,affected the probability of -articipation in government-sponsoredemployment and training programs (Simms and Leitch, 1983).The Urban Institute study was based or data from the NationalLongitudinal Survey of Young Americans. The NLS is a good data set foranalyzing youth participation in employment and training programsbecause it allows one to compare participants with nonparticipants.The data set includes more than 12,000 individuals aged 14 to 21 in1979.The survey oversampled minorities and low-income whites, thegroups most likely to participate in employment and training programs.Just over 2,000 respondents had participated in at least one government-sponsored employment and training program prior to the 1980 surveyinterviews.Although participation rates were higher among minoritygroups--one-third of the blacks interviewed had participated in aprogram, compared with 11 percent of whites and 24 percent ofHispanics--there were no suhstant:al differences by sex (Table 4).In general, young women in the sample had higher levels ofeducational attainment than young men. Overall, young men in thesample were more likely to have less than a high school education (49.2percent of the men versus 44.5 percent of the females in the sample)and were less likely to have completed any formal education beyond highschool (19.2 percent for males versus 23.8 percent for females) !seeTable 5).This differential was similar for all ethnic groups, exceptHispanics.For those who had participated in government paograms, theeducational gap was much wider. Among participants between January1978 and spring 1980, there were large differences between men andwomen; a larger percentage of the female than the male participants had 502 467 TABLE 4Percentage of the Population Participating in Employmentand Training Programs Prior to 1980 Men Women SingleMultiple SingleMultipleProgramProgramsTotalProgramProgramsTotal White7.63.310.97.53.811.3Black21.311.833.119.612.331.9Hispanic13.410.724.115.18.323.4Other12.05.117.17.65,212.8 NOTE:Based on National Longitudinal Survey sample of youths aged 14to 21 who answered this question. SOURCE:M.C. Simms and M.L. Leitch (1983). completed high school and acquired some college education. With theexception of Hispanics, the gender differences :In educational attainmentwere greater for government- program participants than for nolvartici-pants.Educational gaps are also apparent when another data set is used.For example, a comparison of 1977 youth enrollees in CETA with youthsin the Current Population Survey reveals that while young men ingeneral were more likely to be high school dropouts, the differencesbetween men and women in CETA programs were somewhat greater, at leastamong whites:white male enrollees had dropout rates that were atleast twice as high as those of white women who were enrolled in CETAprograms (Bassi et al., 1984).To investigate the possibility that young women who enteredgovernment programs had different qualifications because of differencesin willingness to participate in the program, Simms and Leitch (1983)analyzed the attitudes of young women toward work as part of theRockefeller study. Since young women have two options not available toyoung men--childbearing and, generally, work in the home--young womenas a group might be less interested in employment and trainingprograms.Researchers had hypothesized that women who participate inemployment and training programs have less traditional attitudes thannonparticipants and are also more likely to expect to be in the labormarket for most of their adult years. This was the case for women whoparticipated in programs prior to 1978. However, since it is possiblethat program participation and maturation affected their attitudes, itis more useful to concentrate on those who participated after January1978, since the information available on respondents' attitudes is mostlikely to precede participation. Here we find that women who wereparticipants in government programs after 1977 were no less likely to 503 468TABLE 5Highest Grade Completed, by Sex, 1979 MalesFemales Total Sample 100.0a1000a Less than high school 49.244.5 High school 31.531.8 More than high school 19.223.8Enrollees _n Government Programs after 1977100.0100.0Less than high school 80.469.4 High school d.927.8 More than high school :10.72.8 NOTE:Based on National Longitudinal Survey sample of youths aged 14to 21 who answered this question.aTotals do not add to 100.0 due to rounding.SOURCE:M.C. Simms and M.L. Leitch (1983). think that a woman's place is in the home than were women who did notparticipate in training programs. And they were more likely to thinkthat a woman's place is in the home than those who participated in private or military training programs (Table 6). However, when asked what they expect to be doing at age 35, government-program participantswere more likely to say \"working,\" indicating that they expect economicreality to he a factor in their actions.Another factor that might affect participation by young women isfamily responsibilLies. Young women with children or other familyresponsibilities may not be able to participate in programs, eitherbecause they lack child care or because they cannot take time away from nonmarket work. In 1979 the vast majority of the respondents in theNLS sample lived with their parents. Young women, however, were lesslikely to live with their parents than young men and were more likelyto be married or living on their own. There were large racialdifferences in living arrangements beginning at age 18; blacks of bothsexes were much less likely to live on their own than members of other racial or ethnic groups.The women in the sample, both married and unmarried, were much more likely to have children than the men in the sample; 17 percent of thewomen in the sample had at least one child, compared with 6.S percent of the men.There were 496 women in the sample who were heads ofhouseholds (7.8 percent of all women in the sample).Participants in government training programs were no more likely s.o be married than participants in the sample as a whole. They were,however, more likely to have children. A significant proportion of 534 469 TABLE 6Women's Responses to Statement \"A Woman's Place Is in theHome,\" by Participant Status (in andParticipant 39.345.510.74.5 NOTES:Based or. National Longitudinal Survey sample of youths aged 14to 21 who answered this question.aTotals do not add to 100.0 aue to rounding. SOURCE:M.C. Simms and M.L. Leitch (1983). women who were heads of households had participated in some type ofemployment or training program.The last phase of the study, of the determinants of participation inemployment and training programs was a multivariate analysis. The mainobjective of this analysis was to determine which factors are likely toaffect participation in employment and training programsc whether thosefactors differ for men and women, and whether after adjusting for allthe relevant factors there is still a sex differential. Included inthe regression analysis were independent variables in six broadcategories:(1) background and demographic characteristics, (2)education, (3) family responsibilities and attitudes, (4) financialneed,(5) work experience (including prior participation in trainingprograms), and (6) local employment conditions.Based on past studies of women's participation in adult programs,we expected to find that young women were less likely to participate inemployment and training programs and that young women who did partici-pate in programs were likely to be better qualified than their malecounterparts.In our regression analysis, we found some evidence toindicate that young women were less likely to be enrolled ingovernment-sponsored employment and training programs, other things 505 470being equal (Table 7). This is clearly the case for enrollment in thepre-1978 period. After January 1978, the significance of sex is not asclear.In equations that did not include participation prior to 1978as an independent variable, the coefficient for sex was negative andsignificant.Once prior participation was entered into the equation,the coefficient for sex- while still negative, became insignificant.The interpretation of this finding is not obvious. On the one hand, itmay mean that previous participants in programs were more adept atobtaining a slot in another program, and since women were less likelyto have had that prior experience, they fared worse than their malecounterparts.On the other hand, it may mean that sex differences inparticipation continue to exist and are similar in nature to those inexistence prior to 1978 and the lagged variable is picking up thisconnection.To the extent that it exists, differential participation by womendoes not seem to be related to perceptions about future participationin the labor market. None of the variables that were used to measurework expectations proved to be significant. In contrast tc women whoentered private or military training, women in government programs wereno less likely than nonparticipants to think that a woman's place is inthe home.Therefore, there is no evidence to indicate that women whoenter government programs have expectations of greater labor forceattachment than those who do not or that different attitudes about workmight explain why there are differences in participation between youngmen and young women. The presence of dependents is negativelycorrelated with participation for both men and women.In general, the variables that are important in explainingparticipation are the same for men and for wooen. For the most part,the relationships are consistent with a \"scraping\" hypothesis ratherthan a \"creaming\" hypothesis. The probability of participation isnegatively correlated with total family income and socioeconomic status(measured by father's education). It is positively correlated withprior enrollment in remedial education, with the number of periods ofno work, with the number of months on welfare (for women), and withbeing black or Hispanic. We found no evidence to indicate that thewomen who entered government programs were better qualified than theirmale counterparts. PROGRAM TREATMENT AND PROGRAM OUTCOMESAn analysis of female participation in employment and trainingprograms would be incomplete without an assessment of the treatmentyoung women receive, how it differs from that of young men, and theeffects of those treatments on some set of outcomes. This sectionfocuses on analyses that have been done in this area. Although avariety of data sources were used, most analyses relied on informationavailable from the CLMS and from the 1979 NLS because those data setsinclude enrollees in different types of employment and trainingprograms and also provide information on groups who have notparticipated in programs. 471 TABLE 7Summary of Ordinary Least-squares Runs on Participation in GovernmentTraining, Post-J.978, With Lagged Participation .i0 level.***F significant at .05 level. SOURCE:M.C. Simms (1983). 507 respondent's age in 1979BLACKHISPANICOTHERACErespondent's race; white is the income of respondent'shousehold in 1978SEX respondent's sexEMPLOYRATL1 EMPLOYRATE2MARRIEDDIVORCED1979 unemployment rate for labor marketof current residence; rates under 6percent is omitted variable marital status, single is omittedvariableDEPENDENTS number of dependents in 1978HIGHGRADE1 highest grade completed by respondent inHIGHGRADE2 1978; less than high school is omittedvariableWORKEXPECT work expectations in 5 yearsNOWORK periods of no work in 1978LIVEWITH1LIVEWITH2LIVEWITH3who individual lived with at age 14 FATHERGRAD1 highest grade completed by respondent'sFATHERGRAD2 father; less than high school isomitted variableMOTHERWORK1MOTHERWORK2number of hours respondent's motherworkedin 1979; zero hours omittedFEMALEWK14 adult female in household worked forpay when respondent was 14 473 TABLE 7 (continued) FAMILYATT REMEDIAL MOSWELFAREGOVTPRE78respoi.dent's attitude toward thestatement thehome\"whether respondent took remedial mathor English or English as a secondlanguagemonths on welfareparticipated in a government-sponsoredemployment and training program before1978 PRIVPRE78 participated in a private employmentand training program before 1978 It should be noted that analyses using these data sets examinedtreatment of and outcomes for individuals who were enrolled ingovernment-sponsored employment and training programs in the late1970s.'mere are two reasons for this. First, there is generally alag between the time data are collected and the time data sets are madeavailable for use. This lag may be up to two years in some cases.Second,if one wants to examine postprogram outcomes, additional timemust elapse so the enrollee can leave the program and follow-up datacan be collected on the status of the participant at various pointsafter leaving the program. Consequently, postprogram data on employ-ment,_:nings, and other outcomes for a person leaving a trainingprogram in 1978 might be collected in 1979 and 1980 and be availablefor analysis in 1981. These lags make it difficult to measure theeffectiveness of current programs if the -ire different from thoseoffered in the recent past. However, evaluation of past programs canbe helpful in identifying patterns of treatment and in determiningwhether some types of programs are more effective than others. Program TreatmentThree aspects of program treatment are of interest: programassignment, services received, aLa type of training received. The typeof activity an individual is assigned to and the training received canaffect postprogram outcomes. Support services, such as medical care,transportation, and child care, can affect the ability of an individualto enter or continue a program. 5O9 474Program Assignment Employment and training programs consist of four basic activities:classroom training; on-the-job training (OJT); public service employment(PSE), which was discontinued in 1981; and work-experience programs.There are differences in the assignment of men and women to theseactivities.Although the differences are greater among adults, they doexist among youths. Young women are more likely than young men to beassigned to work-experience and classroom-training activities and areless likely to be assigned to OJT and (prior to 1981) PSE (Table 8).These differences are more apparent among youths o er age 18, sincethose under age 18 are most likely to be in work-experience programs,regardless of gender. Sex uifferences are slightly greater amongwhites than among blacks or Hispanics because minorities of both sexestend to be more likely to be placed in work-experience programs orclassroom training after the age of 18.Differences in program assignment do not necessarily representdiscriminatory treatment. They maybebased on differences in the typeof treatment deemed appropriate, given the individual's background, orthey may be the result of differences in preferences between men andwomen.In their analysis of the type of skills training received,researchers at Ohio State University noted that young women in the NLSsample were more likely to receive classroom training--be it collegepreparatory, skills training, or basic education--and men were morelikely to receive on-the-job training (Borus, 1983:126). They thoughtthat these differences could stem from preferences on the part of youngpeople; young women do better in school and are therefore more likelyto accept such an assignment. However, this would certainly be at oddswith a strategy of assigning enrollees on the basis of need, since maleenrollees tend to have more educational deficiencies than femaleenrollees.An Elternate explanation may be found in the fact that thetype of jobs traditionally held by women are more likely to requireskills that are learned in the classroom and those held by young menare more likely to be learned on the job.A Rand Corporation study of sexual equity in CETA (based on theCLMS)used a different approach to evaluating the gender differencesin program assignment (Berryman et al., 1981). This study compared theproportion of males who received the CETA services tney requested tothe proportion of females who received the services they requested.Although the differences between young men and young women were smallerthan the differences between adult men and adult women, some patternswere found.In the categories of job training and jobs, men whorequested OJT and PSE were more likely to get those assignments thanwomen who requested them. On the other hand, young women who requestedclassroom training in basic skills were more likely to get it thanyoung men who requested it (Table 9). 51() TABLE 8CETA Program Activity by Race, Age, Ethnicity, and Sex, Fiscal 1977 (in percentages) Males FemalesOn-the-Public Simms, L.C. Burbriage, and C.L. 512 BEST COPY AVAILABLE 476 TABLE 9Youth Distribution of Obtained CETA Services withinDesired Service (in their desired CETA services.aTotals do not add to 100.0 due fiscal 1978.eIncludes PSE nonsustainment, and PSE unknown in fiscal Berryman, W.K. Chow, and R.M. Bell (1981:67). Occupational SegregationBoth the Rand study and the Ohio State analysis found considerablesegregation in occupational training under CETA and other governmentprograms.Among youths enrolled in employment and training programs in1978, Crowley et al. (Bonus, 1983:20, 162-163) found that 80 to 85percent of all enrollees in professional, clerical, and sales trainingprograms were women, while 78 percent of the enrollees in skilled laborand craft training were men. The low percentage of women in the latterprograms is not unexpected given that only 25 percent of women in the1979 NLS survey aspired to atypical jobs. And among those young womenwho were interested in nontraditional jobs, most were interested inmanagerial and professional careers; few indicated an interest inblue-collar jobs. Young women from more disadvantaged families, whoare the target group for government programs, are less likely to aspireto nontraditional occupations and, without encouragement, may beunlikely to pick employment or training slots in traditionally malefields.Berryman et al. (1981:4-45) also found CETA enrollees to be verytraditional in their job preferences, although that seemed to decrease 513 477 somewhat with time. In 1976, 82 percent of the young women wantedtraditionally female jobs and only 4 percent wanted traditionally malejobs.The remaining 14 percent wanted jobs that were categorized asmixed (neither predominately male nor predominately female). By 1978,the proportion wanting traditionally female jobs dropped to 60 percent,those desiring traditionally male jobs rose to 15 percent, and thoseseeking mixed jobs rose to 24 percent. Over the same period, CETAbegan to place more young women in traditionally male jobs and fewer intraditionally female jobs, and the shifts were greatest for minorityfemales. Supportive Services The service received most often by youths is job counseling. Aboutone-half of both men and women received counseling. Medical services,transportation, and child-care services were not received by largeproportions of the youth population, but the need for such servicesamong the youth population is not known. Female heads of householdwere more likely to receive health and child-care services than others,but less than cne-half of that group received any services in 1978(Bolus, 1983; Simms and Leitch, 1983). Pr3gram Outcomes The expected outcomes of program participation have been andcontinue to be diverse. In addition to increased postprogram earnings(the primary goal for adults), other objectives include increasededucational attainment (lower school dropout rates), a reduction inearly childbearing, reduced 41fare dependency, and reduced criminalactivity.Success in achieving these multiple goals, however, is oftendifficult to measure.To assess the net impact of program participation, information isneeded on the outcomes and variables, other than program participation,that are likely to affect outcomes for both the preprogram and post-program periods. Moreover, comparable information is needed for agroup of individuals who have similar preprogram characteristics butwho were not enrolled in the program. Such comprehensive information1: seldom available. Therefore, the outcomes examined most often arepostprogram earnings and employment because more data are available onthose outcomes, both for program participants and for individuals whomay be part of a comparison group. Earnings and Employment GainsOne fairly consistent conclusion, at least in evaluations ofoutcomes for adults, is that women and the economically disadvantagedreceive the greatest gains from participation in employment and training 514 478programs.2This was true for the early programs established underMDTA and has continued to be true under Cr:1TA (Perry et al., 1975;Bassi, 1982; Congressional Budget Office and National Commission fcrEmployment Policy, 1982). There is no consistency, however, in theassessment of which program activities have the greatest effect or themechanism by which those gains are made. For example, some studiesconclude that OJT and skills training have the highest payoffs (Harlan,1980), but other studies point out that the employment gains of thosetwo programs decay over time (U.S. Department of Labor, 1977). Arecent study using the Continuous Longitudinal Manpower Survey,however, found that the net earnings gains for women do not vary byprogram activity but are in the range of $800 to $1,300 for allprograms.Moreover, the gains do not appear to decrease over time(Congressional Budget Office and National Commission for EmploymentPolicy, 1982).Findings from a recently completed study by The Urban Institute(Bassi et al., 1984), which used the 1977 CLMS, indicate that many ofthe programs that work for adults also work for youths. Participationin PSE programs increased earnings for white women by $882 to $990 inthe first postprogram year and by $1,035 to $1,144 in the secondpostprogram year.' For black women in PSE the gains were $1,126 to$1,196 in the first year and $608 to $678 in the second postprogramyear, and for Hispanic women in PSE the significant gain was $1,705 to$1,862 in the first postprogram year. Black women also benefited fromparticipation in OJT; they showed gains of $861 to $877 in the firstyear and of $1,389 to $1,406 in the second year after leaving theprogram.The only significant gain for men was for white men in OJT,who experienced an increase in earnings of $452 to $463 in the firstpostprogram year. Most of the gains for women were the result ofincreases in time in the labor force, time employed, and hours worked;only 3 to 10 percent of the gains were attributable to increasedaverage hourly wages. A larger proportion of the gains for white men(16 percent) was attributable to increases in hourly wages and less toadditional time employed. Even though women benefited more from CETAparticipation in terms of gains in earnings, mean postprogram SocialSecurity earnings for young women were lower than those for young men.Youths in other programs either showed no gain or a loss inearnings compared with a matched sample drawn from the CPS. However,even individuals in those programs increased their labor force activitybetween preprogram and postprogram years and showed gains in reported 2Note that some of the studies cited measured gross earnings and/oremployment impact, and others measured net earnings and/or employmentgains (using a control group). This changes the magnitude but not thesign of the results for women. sHowever, these findings are not definitive since the Chow testsindicated a significant difference between young white women whoparticipated in CETA and their comparison group. 015 479 hourly wages.It would appear that the participants' failure to makegains relative to the comparison group is due to the fact that theincreases in labor force activity of CETA participants are not as largeas the gains made by nonparticipants. This may or may not be theresult of non-labor-market activity, such as time spent in school. Itis impossible to confirm these assumptions, since no postprogram infor-mation on the labor force activity or school status of members of thecomparison group was available.Using the 1976 CLMS to meas'ire the effect of program activity onemployment immediately after leaving the program, Harlan and Hackett(1984) found that programs that enrolled more men than women (such asOJT) provided the greatest possibility for immediate postprogramemployment and that those with the largest proportion of women had thelowest possibilities. If population groups were shifted among programsso that minorities and women were distributed like white men, post-program employment for those groups would increase, although it wouldstill lag that for white men. (No separate analysis was done foryouths.)Hahn and Lerman (1983) used the NLS to analyze the effect of CETAprograms on school enrollment and unsubsidized job experience. Theyfound that while CETA did seem to increase school entailment amongwomen and nonwhite men, it had very little positive effect on unsub-sidized employment. Youths who had not teen enrolled in CETA hadhigher rates of unsubsidized employment and had higher earnings fromunsubsidized employment. This was especially true for women, althoughyoung female CETA participants who mixed school and work had higherunsubsidized earnings per week in the first year. By 1980 young femaleCETA participants who were both in school and working were more likelyto have unsubsidized jobs than their non-CETA counterparts. Other Outcome MeasuresVery little information on outcome measures other than employmentand earnings is available on CETA actiy*.ties as a group. Bassi et al.(1984) did examine the effect of CETA on welfare dependency for CETAenrollees in 1977 who were between the ages of 18 and 65. The resultsof the analysis show that CETA does decrease the level of welfaredependency, but it does not lead to removal from the welfare rolls (atleast not under the regulations in force in 1978 and 1979). In 1978the estimated annual welfare savings for women who headed householdswas $250.This finding is consistent with the fact that women receivedthe highest gains in earnings from CETA participation. No significantwelfare savings were found for men. This is consistent with the findingthat there was not, in general, a substantial gain in earnings for men.A recently completed analysis of the long-term effects on youths ofgovernment - subsidizes employment and training programs used the NLS toexamine the impact of participation in five program activities (sub-sidized employment, classroom skills training, basic education, jobcounseling, and other) on employment, earnings, educational attainment,and welfare dependency (Crowley, 1984). The effect of participation in 516 480 1978, 1979, or 1980 on 1981 status or outcomes was found to be insig-nificant for earnings and hourly wages for both men and women, althoughit seemed to lead to subsidized employment at a later date. Participa-tion in a basic educational program was positively related to obtaininga General Equivalency Diploma (GED) for both men and women and to schoolenrollment for women. Participation in a skills training program had anegative effect on subsequent school enrollment for young women. Youngwomen who received job counseling (in 1979) or participated in sub-sidized employment programs (in 1980) actually were more likely to beon welfare and to receive larger amounts of welfare than nonpartici-pants.This could be related to greater knowledge of the benefitprograms to which they might be entitled. Women who were in programsin 1978 had lower levels of dependency on welfare in 1981, whichindicates a possible lag between program participation and movement offwelfare among younger women.There have been some evaluations of the effect of in vidualemployment and training programs on a variety of outcome measures. Onesuch sti42,1, is the evaluation of the Job Corps conducted by MathematicaPolicy Research CorporaLion (Mallar et al., 1980). This study foundthat in addition to increasing employment and earnings, Job Corps alsoincreased the probability of high school completion and collegeenrollment and decree: criminal behavior and welfare dependency. Foryoung women, participaon in Job Corps also appeared to delay familyformation and to reduce the incidence of extramarital childbearing.The impact on employment, earnings, education, and welfare payments wasgreater for women without children than for those with children. Thismay be due to the fact that the burden of family responsibilities onthose with children limited their labor force participation afterleaving the program.Another program for which a variety of outcome measures has beenevaluated is the Youth Incentive Entitlement Pilot Projects (YIEPP).This program, initiated under YEDPA, guaranteed jobs to eligible 16- to19-year-olds (part-time jobs during the school year and full-time jobsduring the summer) if they stayed in or returned to school and metspecified attendance and performance standards. A comparison of menand women eligible to participate found that the participation ratesfor young men and young women were quite similar and so were theaverage number of months in the program (Farkas et al., 1984). Therewere substantive gains in earnings for both men and women duringprogram participation, mainly due to increased employment. However,the difference in earning gains between young women and young men inthe postprogram period was significant--gains in weekly earnings formen ($13.66) were twice those for women. Since nearly one-half of theyoung women in YIEPP had had at least one child by the time theyreached the age of 19, it was thought that home responsibilities mayhave had a negative effect on labor force participation among women.However, the rate of childbearing, while quite high, varied sub-stantially from site to site within YIEPP, and on average, the 45percent rate for YIEPP participants was comparable to the 47 percentrate for the comparison group. The study concluded, therefore, thatthe program had no effect on the rate of childbearing among this group 514 481 of young, low-income women and that the high rate of childbearingprobably explained at least part of the difference in earnings gainsbetween male and female participants in YIEPP. The latter conclusionseems to be consistent with the fact that the gap between the weeklyearnings of men and women in the program increases as they grow older.Even though the gains to young women are smaller than those to youngmen, however, female program participants still do better than women inthe comparison group.While YIEPP did increase labor force participation and lowerunemployment, it did not seem to increase school enrollment. This mayhave been due, in part, to the failure to attract or retain high schooldropouts.However, the program did not appear to increase dropoutrates either (which had been true of some other programs), since therewas a school enrollment requirement.A program that puts less emphasis on job training, per se, and moreemphasis on a system of supportive services is Project Redirection,jointly sponsored by the Ford Foundation and the U. S. Department ofLabor.This program sponsors or brokers services for pregnant teen-agers and teenage mothers (under age 18) who are without high schooldiplomas and who are in welfare families. The final report on theimpact of Project Redirection has not been released yet but findingsfrom the 12-month follow-up study indicate positive results fromprogram participation in terms of employment and education, with slightdecreases in the incidence of pregnancy (Polit et al., 1983). Since 12months is a short follow-up period for evaluating program outcomes,especially since many individuals were still enrolled in the program,the findings must be regarded as tentative. What may be of greaterinterest is that the program provides an effective set of supportservices, such as child care and housing assistance, that frequentlyare not available in other programs and are obviously felt to be neededby teenage mothers. SUMMARY AND CONCLUSIONS Government employment and training programs have been utilized byboth young men and young women over the past 20 years. While differ-ences in participation based on sex were quite clear during the earlyyears, the_' are less clear now. A review of young women's participa-tion in government-sponsored employment and training programs revealsthat the level of participation has increased in recent years to alevel approaching parity in most programs, although a few programs,like Job Corps, still lag the others. Although young women who enrollin government programs have somewhat higher educational levels thanyoung men,this appears not to be a significant factor in programenrollment.The factors that affect young women's enrollment appear tobe quite similar to those that affect young men. However, there stillappear to be differences in the treatment received by young women andyoung men.Women are more likely to be involved in classroom trainingor work-experience programs that are less likely to integrate them intothe job market, and they continue to be trained in traditionally female 482 occupations.Few young women receive supportive services other thancounseling, and even women with children receive low levels of supportin terms of child care.Young women, like their adult counterparts, benefit more fromparticipation in employment and training programs than do young men.They receive higher employment and earnings gains from the activitiesin which they are least likely to be assigned, such as on-the-jobtraining and public service employment. Most of these gains come fromincreased time employed, however, and not from higher wage rates.Evaluations of selected programs, like Job Corps, also reveal :tains insuch areas as educational attainment, reduced welfare dependency andcriminality, and delayed family formation. Women with children seem tobenefit less from the programs than those without children, perhapsbecause family responsibilities prevent them from increasing theirpostprogram labor force participation.This review of studies of young women's participation in employmentand training programs has identified several shortcomings in both ourknowledge and in the operation of employment and training programs.These shortcomings promLlt the following research recammendations:1.Relatively little is known about the effects of employment andtraining programs on nonemployment outcomes, such as educational attain-ment, welfare dependency, and childbearing patterns. For youths,especially young women, these outcomes may have greater long-termeconomic consequences than the impact programs may have on short-termemployment and earnings. Therefore, more research should be done onnonemployment outcomes and their link to long-term employment andearnings gains. While the 1979 NLS has advantages as a data set becauseit includes nonparticipants in the sample, precise information on theprograms in which the enrollees participated is scanty. Program-baseddata sets, such as the CLMS or the new JTLS, will provide betterinformation on programs and services received. However, the CLMScomparison group (drawn from the Current Population Survey) lackslongitudinal information on outcomes other than participants' earnings.It is to be hoped that the Job Training Longitudinal Survey (JTLS) database, to be developed under TPA, will not have the same shortcomings.In the interim period before the JTLS is available, it would bepossible to conduct research on nonemployment outcomes by drawing acomparison group from the NLS for use with the late CLMS cohorts (1979and later), since information is available for roughly comparableperiods.2.Another area in which we lack knowledge concerns the low levelof support services provided to youths. For example, is child care notprovided because it is not requested or because it is not available?To what extent does nonavailability of child-care services ortransportation reduce program participation, especially among youngwomen?(An on-going Urban Institute study (Sonenstein and Wolf, 1985)will provide insight into the relationship between the availability ofchild care and employment or participation in education or trainingprograms.] 519 483 In terms of program operation, the_e are also suggestions forchange. 1.The fact that young women are assigned to different programsthan young men (and disproportionately to those with lower expectedearnings gains) suggests that program operators need to be moresensitive to possible gender differences in program assignment and thatmore emphasis on preprogram counseling might be needed.2.Related to the above, while today's young women are more likelyto expect to be working during their adult lives than earlier genera-tions of young women, they are not as open to nontraditional careers asthey need to be if they are to increase their earning power signifi-cantly.Employment and training programs (particularly job counselingprograms) should include information about job opportunities in non-traditional careers and the skills and education needed to enter thosecareers.Support and encouragement may also be needed to get moreyoung women into the training \"pipeline\" for those occupations.3.Low-income young women have relatively high birth rates duringtheir teenage years. While little is known about th? effect ofparticipation in employment and training programs on subsequentchildbearing, we do know that young women with children are less likelyto participate in programs and may receive lower benefits fromparticipation. More emphasis needs to be placed on outreach and onfacilitating the participation of young mothers in programs.Moreover,support services (like child care) need to be available tothese women after they leave programs in oraer to increase theirpostprogram labor force participation. REFERENCESBassi, L.J.1982CETA -Is It a Cost-Effective the EconomicallyDisadvantaged. Washington, D.C.: The Urban Institute.Berryman, S.E., W.K. Chow, Programs for Youth: Synthesis for Measured Outcomes. Washington, D.C.: TheUrban Institute.Congressional Budget Office and National Commission for EmploymentPolicy1982CETA Training Programs: Do They Work for Adults? Washington,D.C.:U.S. Government Printing Office. 520 484Crowley, J.E.1984Long-term outcomes of government-subsidized employment andtraining programs. Pp. 179-212 in P. Baker, S. Carpenter,J.E. Crowley, R. D'Amico, C. Kim, W. Morgan, and J. Melgosz,eds., Pathway to the Future. Vol. IV.Center for HumanResources Research. Coiumbu3:Ohio State University.Farkas, G., R. Olsen, Stromsdorfer, L.C. Sharpe, F. Skidmore, D.A.Smith, and S. Merrill1984Post-Program Impacts of the Youth Incentive onthe Effectiveness or Federal Strategies for Aa .tingDisadvantaged Youth. Final report to the US Apartment ofLabor.Center for Employment and Income Stud)... s. Waltham,Mass.:Brandeis University.Harlan, S.L.1980Sex Differences in Access to Federal Employment and TrainingResources under CETA: An Overview.Working Paper no. 58.Wellesley, Mass.: Research S.L., and Hackett1984Job Trainir4 Programs and Employment Outcomes: Effects by Sexand Race of Participants. Working Paper no. 129. Wellesley,Mass.:Wellesley College Ceizer for Research on Women.Mailer, C., S. Kerachsky, C. Thornton, M. Donihue, C. Jones, D. Long,E. Noggoh, and J. Schore1980Evaluation of the Economic Impact of the Job Corps Program.Second Follow-up Report. Pennsylvania.Polit, D.F., M.B. rannen, and M.C., M.L. Leitch1983Determinants of Youtn Participation in Employment and TrainingPrograms with a Special Focus on Young Wom2n. Washington,D.C.:The Urban Institute.Sonenstein, F.L., and L.A. Wolf1985Child Cara Policies Employment Behavior of WelfareMothers.Washington, D.C.: The Urban Institute.Stromsdorfer, E.W.1980The effectiveness of youth programs: an analysis of ther,1storical antecedents of current youth initiatives. Pp.88-111 in B.E. Anderson and I.V. Sawhill, eds., 485Swinton, D.H., and L.C. Morse1983The Source of Minority Employment Problems. Washington,D.C.:The Urban Institute.Taggart, R., and B. Linder1980Youth employment policy uackground material. In VicePresident's Task Force on Youth Employment, A Review of YouthEmployment Problems, Programs, and Policies. Vol. 2.Washington, D.C.: U.S. Government Printing Office.U.S. Department of Labor1977The Work Incentive (WIN) Program and Related Experiences.Washington, D.C.: U.S. Government Printing Office. Index A ACTION, 79, 80, 96, 315, 319Adkins Employability SkillsSeries Program, of, 81, 97, 287,301, 302, 317 BBarnicle, Tim, 329Benefit-cost 16, 31See 97,99, 178, 265-270, 320, 330, 332, 334 487Brandwein, Seymour, 301, Vernon, 326Budgets and appropriations,see Funding and expendi-tures; specific programsButler, Erik, 323, 327, 328 C Califano, Joseph, 298Career Exploration Program,OIC/A, 12, 127-131, 135Career forEmployment and IncomeStudiesCenter for 130Civil 57Community-based organizations(CB0s), 81, 318Cranston, 294reservation wage, 14, 62subminimum wage, 294youth/adult earnings and also Service, U.S., 82, 86Energy Department, 79, 80, 97,316, 319Entitlement program, see YouthIncentive Entitlement PilotProjectsEqual Pay Act of Richard, 327Green, 289Gutman, Augustus, and 79, 298, 319Health of programparticipants, DevelopmentDepartment (HUD), 79, 8C, 96Humphrey, 290 I 314, 315, 318Intraagency projects, 6, J Jackson, Henry, 289, 290Javits, Jacob, 289, 290490 Job Corps, 69, 73, 102, 281,296, 299, 335benefit-cost analyses, 110,114criminal activity, effect on,10, 110, 112, 114expenditures, 77, 283, 284participation figures, 78research design results,9-10, 16, 19, 110-116, 118target group, programapproach, and administra-tion, 109, Corps EducationalImprovement Effort (EIE),120-122, 126-127University of Florida, 126University of 16, 165Job Training Graduates, 16,131, 168-172, 174Johnson, Richard, 289, 290, 300 K Kennedy, development, seeYouth knowledge developmentplan 526 and Budget, Officeof, andservices, 317491 317National Council 131Jersey City/Hoboken, N.J., 131New York City P.R., 131National Urban League, 82, 295,317, 321Needs assessment, forHuman Resource Research, 254Olympus Research Centers, IndustrializationCenters of 130, 492 for,9-13, 15-16employment rates, 2, 40-43program needs of, 23-26See also specific programs PPacker, Arnold, 309, 325Palmer, John, 325Perkins, Carl, 291Pines, Marion, 323Policy Evaluation and Research,Office Group, 294Private employers, 95, 86Private industry councils, 28,29Program for Versus Private SectorJobs Project,12, 85, 102, A7-139,145-146, 159 Race differentials, and programsRandolph, 2, 40-43 528 493 294Summer ExplorationProjects, 102Summer Youth Employment Program(SYEP), 69, 73, 137, 281,296, 299, 324expenditures, 77, 79, 283participation figures, 78, 284reports disposition, 101, 102research design and results,14, 148-151, 158, recommendation, 27target group, programapproach, and 74, 147, 282Supported Work, 16, 137,179benefit-cost 144research and 142-144, Robert, 335, groups, 105-106. specific recruiting, 7-8,86-89Temporary seeEmployment programs Unemployment, 327-328 see Earnings 82, 317 YYoung Adult Conservation Corps(YACC), 69, 71, 73, 281, 299expenditures, 77, 79, 283participation figures, 78, 284target group, Projects(YCCIP), 69, 71, 73, 77, 78, 283494 participation figures, 78, 284reports disposition, 101target group, programapproach, and administra-tion, 74, 282Youth Employment Demonstra-tion 282Youth 137, 281,299Baltimore, 152-155, 157Cincinnati, 152, 153, 155, 157Cleveland, 152, 153, 152, 153, 155design, 310, 311Detroit, 154evaluation of, 334expenditures, 77, 78, 283Louisville, 152, 153, 155Mississippi, 152, 153, 157participation figures, 78, 234 5 30 Phoenix, 152, 153, 155political background, 71, 291,292, 294, 300reports disposition, 101, 102research design and results,14-15, "}