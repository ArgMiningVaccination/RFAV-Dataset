{"title": "PDF", "author": "PDF", "url": "https://www.cms.gov/Regulations-and-Guidance/Guidance/FACA/downloads/id49d.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "3 4 5 6 7 8 9 10 11 CENTERS FOR MEDICARE AND MEDICAID SERVICES 12 Medicare Evidence Development & Coverage 13 Advisory Committee 14 15 16 17 18 19 20 June 17, 2009 21 22 Centers for Medicare and Medicaid Services 23 7500 Security Boulevard 24 Baltimore, Maryland 25 file:///F|/pg061709%20(2).txt (1 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00002 1 Panelists 2 3 Chair 4 Clifford Goodman, Ph.D. 5 6 Voting Members 7 Saty Satya-Murti, M.D., FANN 8 David A. Axelrod, M.D., M.B.A. 9 John Cox, D.O., F.A.C.P. 10 Mercedes K.C. Dullum, M.D. 11 Mark D. Grant, M.D., M.P.H. 12 Mark A. Hlatky, M.D. 13 William H. Maisel, M.D., M.P.H. 14 Curtis A. Mock, M.D., M.B.A. 15 Joshua P. Prager, M.D., M.S. 16 17 CMS Liaison 18 Marcel Salive, M.D. 19 20 Industry Representative 21 Jose Alvir, Dr.P.H. 22 23 Executive Secretary 24 Maria A. Ellis 25 file:///F|/pg061709%20(2).txt (2 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00003 1 TABLE OF CONTENTS 2 Page 3 Opening Remarks 4 Barry Straube, M.D./Maria Ellis/ 5 Marcel Salive/Clifford Goodman 5 6 7 Presentation of Voting Questions 8 Rosemarie Hakim, M.D. 13 9 10 Introduction of Panel 15 11 12 Scheduled Presentations 13 Steven Goodman, Ph.D. 17 14 Donald Berry, Ph.D. 73 15 Roger Lewis, M.D., Ph.D. 107 16 Sharon-Lise Normand, Ph.D. 149 17 Gillian Sanders, Ph.D. 186 18 Donald Berry, Ph.D. 212 19 20 Scheduled Public Comments 21 Bryan R. Luce, Ph.D., M.B.A. 232 22 23 Open Public Comments N/A 24 25 Panel Questions to Presenters 237 file:///F|/pg061709%20(2).txt (3 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00004 1 Open Panel Discussion, Formal Remarks 2 and Voting 311 3 4 Closing Remarks and Adjournment 323 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 file:///F|/pg061709%20(2).txt (4 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00005 1 PANEL PROCEEDINGS 2 (The meeting was called to order at 3 8:10 a.m., Wednesday, June 17, 2009.) 4 MS. ELLIS: Good morning and welcome, 5 committee chairperson, vice chairperson, 6 members and guests. I am Maria Ellis, the 7 executive secretary for the Medicare Evidence 8 Development and Coverage Advisory Committee. 9 The committee is here today to discuss the 10 evidence, hear presentations and public 11 comment, and make recommendations concerning 12 the use of Bayesian statistics to interpret 13 evidence in making coverage decisions. The 14 meeting will introduce Bayesian concepts, 15 contrast Bayesian approaches with frequentist 16 approaches, and provide some examples of using 17 Bayesian techniques for meta-analysis. 18 The following announcement addresses 19 conflict of interest issues associated with 20 this meeting and is made part of the record. 21 The conflict of interest statutes prohibit 22 special government employees from participating 23 in matters that could affect their or their 24 employer's financial interests. Each member 25 will be asked to disclose any financial file:///F|/pg061709%20(2).txt (5 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00006 1 conflicts of interest during their 2 introduction. 3 We ask in the interest of fairness 4 that all persons making statements or 5 presentations also disclose any current or 6 previous financial involvement in a company 7 that performs Bayesian analysis or develops 8 guidance for the use of Bayesian analysis for 9 public policy-making. This includes direct 10 financial investments, consulting fees and 11 significant institutional support. If you 12 haven't already received a disclosure 13 statement, they are available on the table 14 outside of the auditorium. 15 We ask that all presenters please 16 adhere to their time limit. We have numerous 17 presenters to hear from today and a very tight 18 agenda and, therefore, cannot allow extra time. 19 There is a timer at the podium that you should 20 follow. The light will begin flashing when 21 there are two minutes remaining and then turn 22 red when your time is up. Please note that 23 there is a chair for the next speaker, and 24 please proceed to that chair when it is your 25 turn. We ask that all speakers addressing the file:///F|/pg061709%20(2).txt (6 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00007 1 panel please speak directly into the mic and 2 state your names. 3 For the record, voting members present 4 for today's meeting are: Dr. Saty Satya-Murti, 5 Dr. David Axelrod, Dr. John Cox, Dr. Mercedes 6 Dullum, Dr. Mark Grant, Dr. Mark Hlatky, Dr. 7 William Maisel, Dr. Curtis Mock, and Dr. Joshua 8 Prager. A quorum is present and no one has 9 been recused because of conflicts of interest. 10 The entire panel, including nonvoting 11 members, will participate in the voting. The 12 voting scores will be available on our web site 13 following the meeting. Two averages will be 14 calculated, one for voting members and one for 15 the entire panel. 16 I ask that all panel members please 17 speak directly into the mic, and you may have 18 to move the mic since we have to share. If you 19 require a taxicab, there is a signup sheet at 20 the desk outside of the auditorium. Please 21 submit your request during the lunch break. 22 Please remember to discard your trash in the 23 trash cans located outside of the auditorium. 24 And lastly, and most importantly, all 25 CMS guests attending today's meeting are only file:///F|/pg061709%20(2).txt (7 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00008 1 permitted in the following areas of the CMS 2 building site: The main lobby, the auditorium, 3 the lower level lobby and the cafeteria. Any 4 persons found in any area other than those 5 mentioned will be asked to leave the conference 6 and will not be allowed back on CMS property 7 again. 8 And now I would like to turn the 9 meeting over to Dr. Barry Straube. 10 DR. STRAUBE: Thank you and good 11 morning to everybody, the MedCAC panel members 12 and also our guests from the public in the 13 audience. 14 I just want to take a couple of 15 minutes. First of all, this particular MedCAC 16 is one of several that are a bit different than 17 we historically have been approaching MedCAC 18 issues, and I think it emanated when we changed 19 the name of this committee from MCAC and added 20 evidence development, and I think this is very 21 very important to the evolution of what we're 22 trying to do with the MedCAC. 23 Along that line, I wanted to recognize 24 and embarrass, in the back of the room, 25 Dr. Steve Phurrough, who I did mention at the file:///F|/pg061709%20(2).txt (8 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00009 1 last MedCAC, but Steve is with us today and 2 this topic Steve came up with while he was our 3 director of the Coverage and Analysis Group 4 before going over to AHRQ recently. It was one 5 of many topics that Steve and the staff thought 6 up and have really advanced in terms of how we 7 use the MedCAC here at CMS. I think it's only 8 the beginning of a much larger role as time 9 goes on as we do more comparative evidence 10 review, cost effective analysis, et cetera. 11 So Steve, I want to thank you and 12 publicly acknowledge your work while you were 13 here for seven years, if I remember correctly, 14 or at least five. So thank you, Steve, for 15 this, and maybe we will dedicate this 16 particular MedCAC to you. 17 Just quickly, Marcel may, this may be 18 cutting into his remarks, but we had a little 19 pre-brief meeting before we came up here, and I 20 think, again, there was a lot of enthusiasm I 21 sensed from the panel members and I appreciate 22 that. I think the panel understands and I 23 suspect by, actually there's more people in the 24 audience than I anticipated, so this is a good 25 sign too, and I think there's a number of very file:///F|/pg061709%20(2).txt (9 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00010 1 very important issues that we would like to see 2 achieved from this particular MedCAC panel. 3 One is a basic one, and it's how do we 4 use various types of analysis, but today 5 Bayesian analysis, in terms of interpreting 6 evidence that we have before us, particularly 7 in the area of coverage decision-making. But 8 as we discussed earlier this morning, the FDA 9 has used Bayesian analysis in their analysis, 10 NIH uses it for a variety of things that they 11 do. We have perhaps not used Bayesian analysis 12 or integrated it as much into our 13 decision-making process, at least in a formal 14 sense. So I think how we not only use it, but 15 how we could possibly align with FDA and NIH 16 and other federal agencies at least, but also 17 in some cases, are there indications where we 18 shouldn't be aligned with them, are there good 19 reasons why we should not be using this type or 20 other types of analysis. 21 I think we've been trying to revise 22 our coverage standards through guidance 23 documents, et cetera, and I think this MedCAC 24 helps us try to refine those guidance 25 documents, making it predictable to people who file:///F|/pg061709%20(2).txt (10 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00011 1 want us to make national coverage decisions as 2 to how we'll go about that process. 3 And then last, I think this type of 4 analysis, not only for coverage 5 decision-making, but again for the future, 6 comparative effectiveness research, cost 7 effective analysis if Congress charges us with 8 using that in the future, when we get data from 9 many complex sources and we're using it for 10 other purposes that CMS tends to use it, 11 including collecting claims and administrative 12 data, collecting data from registries, 13 collecting data from RCTs or observational 14 studies, collecting data from EHRs and using it 15 for coverage payment, quality improvement, 16 public reporting, incentive programs and so 17 forth, this will carry over into all those 18 areas. 19 I wanted to end with acknowledging, 20 again, that this is the first time we've had 21 our new chair, Dr. Cliff Goodman, and our 22 cochair, Dr. Saty Satya-Murti, here as a team, 23 and I wanted to acknowledge both of these 24 gentlemen for taking on these roles. It's very 25 important to us and we think we have fantastic file:///F|/pg061709%20(2).txt (11 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00012 1 talent in the chair and the co-chair, as well 2 as our panel of participants here today too. 3 So thank you all very much. And Marcel, I turn 4 it over to you. 5 DR. SALIVE: Thank you. Good morning. 6 I'm Marcel Salive, division director in the 7 Coverage and Analysis Group, and the designated 8 government official for this panel. I wanted 9 to thank the panel members, all of them 10 individually for their willingness to serve and 11 engaging this topic today, and I want to thank 12 the audience for coming out, and echo the 13 comments to Dr. Phurrough as he's bolting from 14 the room. 15 Today's topic is Bayesian statistics 16 which is, as you all know, a statistical theory 17 and approach to data analysis that uses a 18 method that allows us to learn from evidence as 19 it accumulates and uses the mathematic format 20 of Bayes theorem to combine prior information 21 with current information on a quantity of 22 interest. And so I think we have thought here 23 at CMS about this, and Barry Straube outlined 24 some of the rationale and I want to just echo 25 that but say that really, a lot of this derives file:///F|/pg061709%20(2).txt (12 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00013 1 from I think the interest of people who are 2 developing evidence using the Bayes method, 3 Bayesian statistics, to come here and present 4 their evidence to us and have us use it in 5 decision-making. 6 And we have been hearing this desire 7 for a number of years. I think it came much 8 more to the forefront when FDA held their 9 symposium and issued their guidance documents 10 in 2006 on, the guidance that FDA issued on the 11 use of Bayesian statistics in medical device 12 clinical trials, and so we've heard a lot about 13 that here at CMS. But I agree with Dr. 14 Straube; I just would point out that there are 15 a number of potential uses of this evidence, 16 certainly coverage decision-making is our main 17 focus in the coverage group, and for developing 18 evidence and for comparative effectiveness, 19 types of evidence. But there are probably also 20 broader applications that we can consider as we 21 learn today. 22 So with that, I want to thank you 23 again, and we can start the proceedings. 24 Dr. Rosemarie Hakim is going to present the 25 questions. file:///F|/pg061709%20(2).txt (13 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00014 1 DR. HAKIM: Hi, and welcome to the 2 MedCAC. As everyone has said, this is a little 3 bit unusual for us, and we have a number of 4 questions that are more theoretical than 5 concrete and so we kind of designed them to be 6 discussed, but we also have our traditional 7 voting criteria. 8 The first voting question is: In 9 assessing the strength of evidence for 10 effectiveness of a medical intervention that 11 incorporates Bayesian design or analysis, 12 compared to a frequentist approach, discuss the 13 following. The first thing to discuss is the 14 greatest potential strengths in a Bayesian 15 analysis approach, and the second is, what is 16 the greatest potential weaknesses of a Bayesian 17 approach. 18 The next question is one that we'll 19 vote on. It's just asking for your level of 20 confidence, asking you how confident you are 21 that potential strengths of Bayesian approaches 22 outweigh the potential liabilities in the 23 design and interpretation of published studies. 24 The next one is another one that we're 25 going to vote on and it's asking you, how file:///F|/pg061709%20(2).txt (14 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00015 1 confident are you that CMS should incorporate 2 evidence that uses Bayesian approaches in 3 trials or technology assessments submitted for 4 coverage decisions, and it's asking you to 5 think about clinical trials and technology 6 assessment. 7 DR. SALIVE: Thank you. Dr. Goodman. 8 DR. C. GOODMAN: Yes. Just a question 9 for Maria Ellis. Would you like us to 10 introduce ourselves now or later? 11 MS. ELLIS: If the panel could 12 introduce themselves and disclose if they have 13 any financial disclosure before we get started. 14 DR. C. GOODMAN: Okay. Cliff Goodman, 15 vice president of the Lewin Group. I have no 16 financial interests in companies performing 17 Bayesian analyses. With regard to potential 18 other conflicts, just to disclose, about a 19 month ago I moderated a technical working 20 section that discussed Bayesian statistics and 21 adaptive methods in clinical trials. This was 22 sponsored by a group called PACE with the TMVP, 23 but was entirely a technical session. 24 DR. SATYA-MURTI: Saty Satya-Murti. I 25 am a neurologist and have been a Medicare file:///F|/pg061709%20(2).txt (15 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00016 1 medical director for many years in the past, 2 and I consult for some industry as well and for 3 my own academic society, but I have no 4 conflicts of interest for this topic. 5 DR. AXELROD: I'm David Axelrod, I'm a 6 surgeon from Dartmouth. I have no financial 7 interests to disclose and no conflicts. 8 DR. COX: John Cox, medical oncologist 9 in Dallas, Texas, and I have no conflicts 10 associated with Bayesian analysis. 11 DR. DULLUM: Mercedes Dullum, cardiac 12 surgeon. I have no conflicts for Bayesian 13 analysis. 14 DR. GRANT: Mark Grant, associate 15 director at the Technology Evaluation Center, 16 Blue Cross and Blue Shield Association, a 17 geriatrician and epidemiologist, and have no 18 conflicts of interest. 19 DR. HLATKY: Mark Hlatky, a 20 cardiologist from Stanford, and I don't think I 21 have a conflict, but I will say that I do 22 consult with GE Healthcare from time to time 23 and maybe they use this, but I don't know. 24 DR. MAISEL: Bill Maisel, a 25 cardiologist at Beth Israel file:///F|/pg061709%20(2).txt (16 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00017 1 Center in Boston. 2 DR. MOCK: I am Curtis Mock, I'm a 3 family physician and geriatrician, regional 4 medical director with United Healthcare. I 5 have no financial conflicts and my personal 6 interest is improvement in patient care and 7 outcomes. 8 DR. ALVIR: I'm Jose Alvir, a 9 statistician from Pfizer. I have no conflicts 10 with regard to Bayesian analysis. 11 DR. C. GOODMAN: With that, it's a 12 delight to see Steve Goodman here to give our 13 initial presentation. Steve, I see we're a 14 little bit behind time, but I'm hopeful you 15 will remain prompt, and we will give you a 16 little warning close to when your time's up, 17 but it's great to have you here to kick this 18 off. 19 DR. S. GOODMAN: So, I'm going to talk 20 about, very specifically it's an introduction 21 but it's a little different introduction on 22 Bayesian approaches in measuring the strength 23 of evidence. And I have many, a number of 24 colleagues here who have seen me talk on this 25 topic in other forums. To those I apologize, file:///F|/pg061709%20(2).txt (17 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00018 1 but you incur an extra special responsibility 2 of leading the audience in appropriate 3 responses at appropriate times. So don't fall 4 asleep. 5 So here we go. I'm going to start 6 off, I heard there were voting questions, so 7 we're going to start of with a voting question, 8 and those who have heard this before, you are 9 now allowed to raise your hands. So we have a 10 well done study that's reported on a new 11 electrical stimulator for pain control, 12 something that MedCAC might consider. 13 The author states that it's turned out 14 somewhat surprisingly, in that they thought 15 they only had a 25 percent chance of being 16 proved before the experiment, to actually be 17 effective in migraines, with a difference of 15 18 percent in the incidence of migraines in the 19 treated and controlled group with a P of .05. 20 So the probability that this association is 21 real is, I'm giving you three choices, less 22 than 75 percent, 75 to just under 95 percent, 23 or 95 percent or above. I ask this to every 24 audience I speak to about Bayes, so you get 25 another two seconds. Normally I give six file:///F|/pg061709%20(2).txt (18 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00019 1 seconds, but we're behind time. 2 So with a P of .05, difference of 15 3 percent, how many think it's less than 75 4 percent? By the way, Maria is counting up the 5 number of votes, and it has to add up to the 6 number in the room minus the number who've seen 7 this before. So less than 75 percent, three 8 brave persons. 75 to just under 95 percent? 9 Okay. 95 percent or above. So, this could 10 really affect the validity outcome of this, it 11 didn't quite add up to the number of people in 12 the room. 13 (Laughter.) 14 So, the answer is less than 75 15 percent, which some of you probably suspected 16 or were afraid of. And I ask this to medical 17 audiences, I ask it to all sorts of audiences, 18 and I will tell you that these audiences who 19 very quickly learn not to answer any of my 20 questions, but this one they're actually very 21 confident on, they're not afraid of answering 22 this question, and usually about 70 to 80 23 percent will answer very confidently that it's 24 95 percent or above. 25 So what's going on here? Well, I gave file:///F|/pg061709%20(2).txt (19 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00020 1 you a piece of information that normally we 2 don't know how to incorporate into a question 3 like this, which is that it had a less than 25 4 percent chance of being true. There is no way 5 to incorporate that information. In fact, the 6 very question I asked you, what's the 7 probability that this association is real, is 8 also not answerable using traditional 9 techniques. So I asked you an unanswerable 10 question using standard methods and I gave you 11 information that was not processable using 12 standard methods, so it's not surprising that 13 most people would get it wrong and that they 14 would answer that the only thing that would 15 seem to make sense that might lead to a number 16 like .05. So, that's why we have more to talk 17 about. 18 So what were the implications of that 19 particular sample? Well, first, that P of .05 20 wasn't very strong evidence, it didn't leave us 21 very certain at the end of the day. And also, 22 they said we don't know how to formally make 23 use of that prior information about 24 plausibility. 25 Let me say a few things I won't be file:///F|/pg061709%20(2).txt (20 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00021 1 saying today. I won't be saying that if we 2 turn to Bayesian methods all our problems go 3 away. I won't say that the only right thing 4 for the statistics world are Bayesian and that 5 the Bayesian approach doesn't have its own 6 issues. I will say, however, that if we turn 7 to Bayesian methods, that difficult issues will 8 be discussed in the right way by the right 9 people. I will say some of the dilemmas that 10 CMS decision-makers face are artifacts of the 11 statistical methods that we use in assessing 12 the evidence that we look at and not due to the 13 math or the scientific method, although 14 sometimes it's shrouded in such language, and 15 that the Bayesian perspective is the best way 16 to think about evidence, and I'm focusing on 17 evidence. 18 So here is a list of things, by the 19 way, that have been identified as cancer risks, 20 and I want to emphasize that these were not 21 discovered with Bayesian methods, these were 22 discovered with standard frequentist methods. 23 So before we throw any rocks, if we are 24 inclined to later, we have to remember this 25 list. And here we go, electric razors, broken file:///F|/pg061709%20(2).txt (21 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00022 1 arms but only in women, fluorescent lights, 2 allergies, breeding reindeer, being a waiter, 3 owning a pet, fur, being short, being tall, 4 eating hot dogs, and if you escape any of those 5 risk categories, having a refrigerator. So 6 we're all at risk and that is what standard 7 methods have delivered unto us. 8 Here is my favorite medical journal, 9 the New York Times. This is a very typical 10 article, I'm sure there's something today of 11 this sort, magnets lessen foot pain of 12 diabetics, the study finds. As you see 13 highlighted in the corner, a finding that runs 14 counter to many previous studies, which if you 15 had any sense, would have buried this to a 16 footnote somewhere. But apparently they think 17 this is what makes it newsworthy. 18 Now these are direct quotes from the 19 article: We have no idea how or why the 20 magnets work, but it's a real breakthrough. 21 And while the study must be regarded as 22 preliminary, the early results are clear and 23 the treatment ought to be put to use 24 immediately. So this is, again, an example of 25 non-Bayesian thinking elevated to headlines in file:///F|/pg061709%20(2).txt (22 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00023 1 the New York Times. 2 So let's start with a little technical 3 stuff here, and I will tell you I only have, I 4 think, one equation in the whole thing. I try 5 to tell the story in pictures as much as I can, 6 because equations take an hour to explain. 7 So let's talk about inferences. There 8 are many physicians and people involved in the 9 medical field here and you understand the 10 difference in medical inference between knowing 11 what an illness is, a particular illness, and 12 then knowing its symptoms. So that is what's 13 called the deductive direction, and this is 14 what I learned in my first two years of medical 15 school. I was a walking encyclopedia, you give 16 me a disease, I could give you a list of 17 symptoms. Then I walked into the wards the 18 third year and I wasn't told that there was a 19 woman with Chagas disease in room four, I was 20 told that there was a woman with a cough, rash 21 and splenomegaly in room four and I had to go 22 in the opposite direction, which isn't 23 appearing here in the inductive direction, I 24 had to go from the symptoms to the illness, and 25 everybody here knows that that's a lot harder. file:///F|/pg061709%20(2).txt (23 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00024 1 So I was a walking encyclopedia, and 2 yet I knew very very little. And that's 3 because the inductive part, going from the 4 symptoms to the illness is actually very very 5 difficult to capture and is, the information 6 that you have going in the deductive direction 7 is not enough, and the exact same issue occurs 8 in statistical inference, okay? So if you give 9 me a mathematical hypothesis that is the null 10 hypothesis, the difference as seen between two 11 treatments is zero, I can tell you exactly what 12 the probability is that I will observe, so this 13 is the truth up here, and this is what we 14 actually see, this is the results of studies. 15 We don't actually get to see this, this is 16 hidden in the clouds, so this is what we get to 17 see. 18 And so I can tell you, if there is no 19 difference between the treatments, exactly how 20 probable is it that I will see a five percent 21 difference in one direction, I'll see exactly 22 zero difference, five percent in the other, 10 23 percent in the other, 15 percent, et cetera, 24 et cetera. Those are just mathematical 25 formulas and that's just called the deductive file:///F|/pg061709%20(2).txt (24 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00025 1 direction of inference. So I can tell you that 2 if I know, how often I will see that. 3 The problem is that that's not the 4 business that we're in. We're shown the study, 5 and we need to somehow divine what the 6 underlying truth is, that's called the 7 inductive direction, and that's what's the 8 Bayes theorem and Bayesian inference is 9 concerned with. I will tell you there is only 10 one formal coherent calculus for the inductive 11 inference and that is the Bayes theorem. There 12 is really no controversy about that, it's a 13 mathematical fact. This is not subject to 14 voting by panels or whatever. 15 What its strengths and liabilities are 16 compared to traditional methods is another 17 issue. Traditional rules of inference are a 18 collection of principles and conventions to 19 avoid errors over the long run if you know what 20 the truth is. They don't tell us how likely 21 our claims are to be true, so you wonder how we 22 make any progress using traditional methods. 23 And there's lots of good reasons and we've made 24 plenty of good progress, and they often can be, 25 they often make a lot of sense, but we often file:///F|/pg061709%20(2).txt (25 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00026 1 confront situations where they don't, and 2 that's what this conference is about. 3 The Bayesian theorem in words is this. 4 We have odds that a hypothesis is true before 5 obtaining the data, which is called the prior 6 odds. And then we have this thing called the 7 Bayes factor, which is what captures the 8 evidential strength of the data, which is 9 really going to be my focus today. Don Berry, 10 who follows me, will not focus on that as much. 11 And then you get this final post-study odds 12 that the hypothesis is true, and so we will be 13 talking more about how to use that information. 14 So this is the one equation, and I do 15 have to write this on the board, or in the 16 slide. So here we have the post-study odds, 17 that is the probability of the null hypothesis 18 given the data, divided by the probability of 19 the alternative hypothesis given the data. So 20 the post-study means given the data, you have 21 the data in hand, and what does that equal. 22 And this is just what I showed you, it is the 23 probability of the null over the alternative 24 before you pull the data, so it doesn't have 25 data here, and this is what I'm going to really file:///F|/pg061709%20(2).txt (26 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00027 1 focus on today. I'm not going to focus nearly 2 as much on this, because that's where a lot of 3 the attention to Bayes goes and there's a lot 4 to be learned from how Bayes treats evidence, 5 not just belief. 6 So over here we have this thing called 7 the Bayes factor and it's marvelously simple. 8 It's the probability of the data under the null 9 hypothesis, divided by the probability of that 10 same data under the alternative hypothesis, 11 that is, how well the data is explained by two 12 competing explanations. It couldn't actually 13 be more simple, that's all it is, and we're 14 going to explore it in much more depth. 15 This is what you're going to see a 16 little bit later, I'm not going to focus on it 17 so much, but this is the way we represent the 18 prior over multiple hypotheses, so this might 19 be all different degrees of treatment 20 difference and this is the prior, either the 21 prior belief or the prior evidence. This is 22 the curve that represents the information from 23 the data, which is called the likelihood 24 function which we will talk a little bit about, 25 and this is the probability of various file:///F|/pg061709%20(2).txt (27 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00028 1 treatment differences based on the combination 2 of these two. And this curve will always sit 3 between these two, and the way this is 4 configured with a bell-shaped curve, it will 5 always be a bit more certain. 6 And I will say right off the bat, 7 there are many things we do with traditional 8 methods that pretty much mimic what is done 9 naturally under the Bayesian paradigm. In many 10 ways they've stolen, or pretty much taken the 11 wind out of the sails, in that you can mimic 12 this exactly with traditional techniques of 13 meta-analysis. So we can obviously accumulate 14 evidence if represented in these simple ways 15 using traditional meta-analytic techniques and 16 come up with somewhat similar answers. It 17 doesn't address the somewhat more complex 18 situations and issues of design that Don will 19 talk about. But there are many things that we 20 do in using traditional methods. We sort of 21 have patched them up to get some of the 22 strengths and abilities of Bayesian methods. 23 So, this is another graphic that shows 24 what Bayes is all about. We have a certain 25 starting prior knowledge, we get data and that file:///F|/pg061709%20(2).txt (28 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00029 1 brings us to a new state of knowledge, final or 2 posterior knowledge. And what this shows is 3 that you can look at Bayes theorem from two 4 perspectives; you can focus on this and this, 5 you can talk about it as a calculus of belief, 6 that is, the evidence just operates on your 7 belief going from prior to posterior, or you 8 can look at is as a calculus of evidence, 9 because it tells you how to summarize the 10 strength of the evidence, and that's going to 11 be what I'm going to be talking about mainly, 12 because I think that's a lot of what MedCAC 13 does, and other bodies, they try to look at the 14 strength of the evidence. 15 So, how do we know the strength of the 16 evidence now? Well, P values are obviously at 17 the center of that. And the man responsible 18 for them, but also for many wonderful ideas in 19 statistics, in fact almost everything that we 20 use today that's non-Bayesian, is R.A. Fisher, 21 who was a statistician, a geneticist and a 22 polymath at the beginning of this century. 23 What's really interesting about the history of 24 statistics is that with the structure that he 25 developed in the '20s, along with hypothesis file:///F|/pg061709%20(2).txt (29 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00030 1 testing which was proposed in the '30s, we have 2 sort of the backbones of statistical analyses 3 that are used in every article in the medical 4 literature and yet this technology is, what, 5 almost 80 years old. How many other medical 6 technologies do we use virtually unchanged that 7 are 80 years old? It's hard to name even one. 8 So we should be a little bit 9 embarrassed. It's obviously a very important 10 foundation to build on and there are a lot of 11 important foundational ideas, but the idea that 12 we still use and still teach as the basic 13 technology of physical analysis and reasoning a 14 method that was developed at that time with 15 actually remarkably little change should be 16 subject to concern. 17 And Fisher himself was concerned. 18 This is a graduation speech that he gave at the 19 University of Michigan in 1958, so, you know, 20 30 years after he first brought forth these 21 ideas. So, I'm quite sure it's only personal 22 contact with the natural sciences that's 23 capable to teach straight methodic 24 mathematically minded people. I think it's 25 worse in this country, the USA, than most, file:///F|/pg061709%20(2).txt (30 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00031 1 though I may be wrong, but certainly there is 2 grave confusion of thought. We're quite in 3 danger of sending highly trained intelligent 4 young men and women out into the world with 5 tables of erroneous numbers under their arms 6 and a dense fog in the place where their brains 7 ought to be. In this century, of course, they 8 will be working on guided missiles and advising 9 the medical profession on the control of 10 disease, and there's no limit to which they 11 could impede every sort of national effort. 12 So what he saw was his methods being 13 twisted in ways and used in very mechanical 14 ways that was really an anathema to him, he was 15 really a creative scientist, as all the 16 statisticians were who developed these methods. 17 And the way they've been employed and the way 18 they were thought of when they were proposed is 19 actually quite different. 20 So what's the meaning of a P value? 21 Does anybody here know, probability, 22 plausibility, possibility? Actually, 23 unfortunately, this is what most people think, 24 and that's part of the problem, publish. So 25 what is the formal definition? It's the file:///F|/pg061709%20(2).txt (31 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00032 1 probability of getting a result as or more 2 extreme than the observed result if the null 3 hypothesis, usually chance being operational, 4 were true. Now I defy anybody to make sense 5 out of that, okay? 6 And I will also note since the P value 7 is calculated assuming the null hypothesis is 8 true, it can't represent the probability that 9 the null hypothesis is false. It's already 10 assuming the truth. The question is, what does 11 it mean about the truth, and that of course is 12 our dilemma. 13 Here is the picture that corresponds 14 to that, here's the distribution or results 15 under the null hypothesis, here is the null 16 hypothesis, and you see something out here that 17 might correspond to a 10, 20, 30 percent 18 treatment difference, and we calculate the area 19 under that curve. And if we want to make 20 things even more obscure, confusing, 21 incoherent, we'll calculate it on this side and 22 call it a two-sided P value and explain to our 23 poor students why that makes sense. 24 So that's what a P value is. 25 Now, many, many, many people have file:///F|/pg061709%20(2).txt (32 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00033 1 written about the problems, I continued to be 2 asked to write about it, I have no idea why, 3 because there are literally hundreds of 4 articles. One just appeared last year where it 5 talked about 12 P value misconceptions, here is 6 the list of 12, I'm not going to read them all 7 to you. I tried to capture the most prevalent 8 ones and here are the most prominent ones. 9 The P value is not the probability of 10 the null hypothesis, it's not the probability 11 that you will make a type one error if you 12 reject the null hypothesis, it's not the 13 probability that the observed data occurred by 14 chance, it's not the probability of the 15 observed data under the null hypothesis. It's 16 in fact not almost anything sensible you can 17 think of. That's not to say it can't be 18 interpreted with great care in reasonable ways, 19 but it's not directly any of these things, and 20 although I could spend hours, days explaining 21 why, you can read that particular article or 22 the hundreds of others that have preceded it if 23 you want to learn why. 24 So here is just a little baby toy 25 example that tells us why this P value poses file:///F|/pg061709%20(2).txt (33 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00034 1 such problems, and can pose problems for panels 2 like yours, which I am sometimes a member of. 3 So here we go, this is sort of a baby toy 4 example that statisticians are very very fond 5 of, but those who haven't seen these examples 6 are always sort of flummoxed or surprised by 7 this. 8 Two scientists perform an experiment 9 in which one of them applies two treatments, A 10 and B, to the same individual, and they record 11 which one is superior. You'll see why it takes 12 two scientists in a minute. The precise data 13 comes out like this, A is better, A is better, 14 A is better, A is better, A is better, five As, 15 and then B is better, okay? So that's our 16 data. 17 So the question is, what's the 18 evidence for A being better than B? So you 19 couldn't get a more simple example, A is, you 20 know, each person is their own control, A is 21 better in the first five and then B is better. 22 So it sure looks like A is comparatively 23 better. So you might ask, what was the design? 24 Well, actually the reason I said there were two 25 investigators here was because each file:///F|/pg061709%20(2).txt (34 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00035 1 investigator actually had a slightly different 2 idea about what the design was. Investigator 3 one had a controlled budget and planned to stop 4 after six patients no matter what. They didn't 5 clue in investigator two, who planned to stop 6 the experiment as soon as B was preferred. 7 So the question is, why does this 8 matter, should it matter? Nature didn't know. 9 The treatment didn't know. The bodies to whom 10 it was applied didn't know. So should the 11 evidence under these two scenarios be any 12 different? Let's calculate the P values. So 13 here's our design that only takes six samples, 14 which you would call a fixed sample size 15 design, you always look to the sample size 16 fraction when you look for the P value for the 17 sample size justification, and you might come 18 up with six under a variety of samples, but 19 here is the P value. 20 So the P value would be the 21 probability of what we saw plus the probability 22 of a more extreme result, right, under the null 23 hypothesis. The null hypothesis is that A 24 would be preferred to B one half of the time. 25 So what's the probability of five A preferences file:///F|/pg061709%20(2).txt (35 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00036 1 out of six? Well, it's one half to the fifth, 2 because the null hypothesis says that A should 3 be preferred one half of the time and then 4 being preferred, and there's six possible 5 combinations of those; it could be at the 6 beginning, second, third, fourth, fifth, okay? 7 And then we add the probability of more extreme 8 data, which is that all six were A. So this 9 comes out to .11 and we'd look at it and say 10 it's not greater than .05, it's not significant 11 and we need another experiment. 12 Let's look at the first B design. 13 This is what might be called an adaptive 14 design, that is, it adapts to the data in hand, 15 and you will hear a lot more about this from 16 Don Berry. So here we have the probability of 17 the data that we have in hand, but here we 18 couldn't get B coming first or B coming second, 19 we could only get B coming at the end by 20 definition, so the probability of that is 21 exactly the sequence that we saw, plus the 22 probability of getting six As and a B, seven As 23 and a B, eight As and a B, and it turns out 24 that that P value is .03, significant, less 25 published. file:///F|/pg061709%20(2).txt (36 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00037 1 Same data. The only thing that's 2 different is what was in the heads of the 3 experimenters but they didn't write it down. 4 So you might say oh, they didn't write it down. 5 But it is a rather funny thing, that depending 6 on what was on a piece of paper, the evidence 7 in front of you is going to be different, the 8 exact same evidence, that is a bit of a 9 conundrum. 10 So, the conundrum is summarized too, 11 the strength of the evidence depends on data we 12 didn't see, that is results we didn't get, 13 which in turn depends on what the experimenter 14 intended to do if other data had been observed, 15 that is, the stopping point. So the evidence 16 exists only in the experimenter's mind. So 17 again, if we start hearing anything about Bayes 18 having to do with things in people's minds, 19 let's remember this example. 20 So what do we do in traditional 21 statistics? Well, we try to control this with 22 very strict design and conduct rules, and so we 23 know exactly what we would have done if we saw 24 different things, that's what we try to do. So 25 we define very carefully the set of outcomes file:///F|/pg061709%20(2).txt (37 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00038 1 that would have occurred under the null 2 hypotheses because we constrain the outcome, 3 but it's completely artificial. This is 4 completely a demand of the method, it's not 5 really a demand of science. 6 We're often at a loss, however, if 7 those rules aren't followed exactly or if 8 they're in any way ambiguous, and this is the 9 problem that you confront all the time, and 10 here is an example of such a problem being 11 confronted in a conversation at the FDA. So 12 this was a very well-known incident that 13 occurred for the RIS drug Carvedilol, which 14 Mark Hlatky probably knows quite well. It was 15 a study design that was powered for heart 16 failure and it was powered to look at the 17 reduction in the symptoms of heart failure 18 because they didn't think they would have the 19 power to look at mortality endpoints. So they 20 chose heart failure as the primary endpoint, 21 not because mortality wasn't but because they 22 didn't think they would be able to get that 23 evidence. 24 Well, what happened? What happened 25 was that there wasn't a whole lot of effect on file:///F|/pg061709%20(2).txt (38 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00039 1 the heart failure endpoint but there was a very 2 big endpoint on a mortality endpoint, and this 3 was the discussion that ensued. This is the 4 chair of the committee: What we have to 5 wrestle with is how to interpret P values for 6 secondary endpoints in a trial which frankly 7 was negative for the primary. In a trial with 8 a positive endpoint you haven't spent all the 9 alpha on that positive endpoint and you have 10 some alpha to spend on the secondary endpoint. 11 In a trial with a negative finding for the 12 primary endpoint you have no more alpha to 13 spend for the secondary endpoints. And then 14 his committee members complete this spiral 15 downward. 16 What are the P values needed for a 17 secondary endpoint? Certainly we're not 18 talking .05 anymore, you're out of this .05 19 stuff, and I would like to have seen what you 20 thought was significant and at what level. 21 What P value tells you that it's there study 22 after study? 23 And Dr. Konstam says, what kind of 24 statistical correction do you have to do to 25 that survival data given the fact that there is file:///F|/pg061709%20(2).txt (39 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00040 1 no specified endpoint? I have no idea how to 2 do that from a mathematical standpoint. 3 Now these guys are cardiologists. 4 What you want to hear from them is cardiology, 5 you don't want to hear about how to spend the 6 alpha in their pockets and how to make the 7 adjustments, and this is where conventional 8 methods can lead you, into this really spiral 9 of gibberish about statistics, whereas what you 10 should be talking about is did this make sense, 11 what were the results of other studies, what 12 were ancillary endpoints that support the 13 mechanism we might propose. Those are the 14 sorts of things that we might want to be 15 talking about. 16 What happened here is they had a 17 result that sort of read against their 18 prespecified design focus, which typically 19 includes what is the primary endpoint and what 20 was the secondary endpoint, and this gets into 21 other issues as well. But you can see that 22 it's very very difficult to constrain one's 23 thinking when you're presented with a result 24 that seems nonsensical. 25 Eventually, I believe it was in file:///F|/pg061709%20(2).txt (40 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00041 1 another panel convened and this ended up being 2 approved, but there are many many examples like 3 this, where sort of a religious adherence to 4 prespecified rules gets us into territory which 5 we don't know how to navigate in, and then you 6 can only default, so the Bayes factor talks a 7 little bit about it. So, I've already defined 8 it, it's simply the probability of data under 9 your two competing explanations that you are 10 considering. 11 So let's do the Bayes factor 12 calculation for that little example I showed 13 you, the five As and the B, okay? So we have 14 here a null hypothesis, which was the 15 probability that A preferred is a half, right? 16 But right away we have to put something as part 17 of the calculation which we didn't have to put 18 with the P value, which is an alternative, we 19 have to specify the alternative hypothesis. 20 This doesn't come into the P value, it only 21 comes into sample size calculations and all 22 that, but you never hear boo about that later. 23 So we're going to take an alternative 24 hypothesis, the probability that A preferred is 25 five-sixths, exactly what you saw. So I'm file:///F|/pg061709%20(2).txt (41 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00042 1 going to do the best case scenario for the 2 alternative. That is, we're going to say the 3 truth, the underlying truth is exactly what we 4 saw, the probability that A preferred is 5 five-sixths, okay? So let's do the 6 calculations. 7 The probability of this data, 8 five-eighths of six patients given under the 9 null hypothesis compared to five-eighths of six 10 patients under the alternative hypothesis, 11 under the fixed sample size design turns out be 12 .23. What does that mean? It means that it's 13 about one quarter as likely under the null than 14 under the alternative, that is, it's about four 15 times more likely under this hypothesis than it 16 was under this hypothesis, and that is the best 17 case scenario we can make, in a sense the 18 strongest case we can make against the null. 19 But this, there's something 20 interesting about that. It's not nearly as low 21 as the P value. Remember, the P value under 22 this design was .11, so it's more than double 23 that. So let's do the same calculation for the 24 first B design. It turns out to be exactly the 25 same. So the evidence is the evidence, and file:///F|/pg061709%20(2).txt (42 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00043 1 here, remember, the P value was .03. 2 So there are two things we learn from 3 this. First, this aspect of the design doesn't 4 make a difference, the evidence speaks for 5 itself. Second, the strength of the evidence 6 against the null hypothesis, at least, is 7 weaker than it was when we looked at only the P 8 value. And the third thing is that this is 9 very specific to the specific question we 10 asked, which is relative to this alternative 11 hypothesis, which is by the way the strongest 12 supported hypothesis. And you will note that 13 the language I used is very much the language 14 we tend to use when we talk about evidence, it 15 supports one thing, it supports another. We 16 don't talk about evidence only in the negative 17 sense which is, again, where the P value gets 18 you. 19 So I've done this calculation again 20 and changed it to an alternative hypothesis 21 that there's only a two-thirds chance that A 22 would be preferred out of, you know, .66 or 23 point-eight-something, and here the evidence, 24 again, is the same in the two situations. But 25 now it's not quite as strong against the null file:///F|/pg061709%20(2).txt (43 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00044 1 hypothesis, it's weaker, and why? Because the 2 observation is that A was preferred five-sixths 3 of the time, so it doesn't support this 4 alternative that it was a two-thirds chance of 5 being preferred as strongly as it did that the 6 truth was actually what was seen. So this 7 hypothesis is supported a bit less strongly 8 over the null, but still what we learned here 9 is that the evidence is the evidence. 10 So, the Bayes factor doesn't depend on 11 something that exists only in the minds of the 12 investigators, that in some sense it's more 13 objective than the P value, although I'd have 14 to say the story is a little more complicated 15 than that when we get to non-toy examples. The 16 Bayes factor depends on what hypothesis you're 17 comparing to the null hypothesis, so you have 18 to be careful what question you're asking. 19 And I'm going to use an example of 20 something that's closer to the kind of things 21 that you will see, and the strength of the 22 evidence against the null is not as strong as 23 the P value indicates. So here's a slide that 24 compares the properties of the two measures of 25 evidence. The P value is noncomparative in the file:///F|/pg061709%20(2).txt (44 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00045 1 sense that it only is calculated relative to 2 the null, and the Bayes factor is comparative 3 in the sense that it compares an alternative to 4 the evidence, or gives an alternative to the 5 null. The P value uses observed data plus 6 hypothetical data, that is the data you would 7 have seen if other data and something else had 8 happened. The Bayes factor only uses the 9 observed data, which is why in those two 10 scenarios the Bayes factor came out the same, 11 it was the same observed data. 12 The P value doesn't use an alternative 13 hypothesis and the Bayes method uses an 14 alternative hypothesis that's explicit and has 15 to be predesigned. And also, just to telegraph 16 something I will highlight later, it's 17 predefined and made explicit in the form of the 18 prior. The prior is in essence a prior 19 declaration of exactly how you're going to 20 weight the evidence across the alternative 21 hypothesis. 22 With a P value we can only talk in 23 terms of negative evidence. With the Bayes 24 factor we can talk about evidence being 25 negative or positive, it supports the null, it file:///F|/pg061709%20(2).txt (45 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00046 1 supports the alternative, and the language and 2 context is much more comfortable. The P value 3 is sensitive to stopping rules, the Bayes 4 factor is insensitive to stopping rules. The P 5 value actually has no formal justification or 6 interpretation, the Bayes factor has a formal 7 justification or interpretation in the context 8 of Bayes theorem. And it's also easy to 9 explain, that is, it's how well what we see is 10 explained by, you know, by our competing 11 explanations, compare that, or it's how much 12 our belief changes. So you can look at it 13 through either prism. I defy any of you to try 14 to explain what a P value is. 15 So understanding likelihood, I'm 16 actually not going to spend too much time on 17 this since in view of my pledge to avoid too 18 much statistics they would empirically get 19 lost, but I'm going to show them to you anyway 20 and hope that they have some intuitive sense 21 and you already know what they mean. This is 22 just showing you a likelihood curve which is 23 defined by the data or, if you observe five out 24 of 15 events, so what the likelihood curve 25 shows you is how much the data supports all the file:///F|/pg061709%20(2).txt (46 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00047 1 possible underlying hypotheses. It shows you 2 how much the evidence supports various degrees 3 of truth. 4 So what this shows you is if you 5 observe five out of 15 events, so you have an 6 observed cure rate of one-third, that the 7 evidence most strongly supports, what do you 8 know -- this is the truth down here, the true 9 theory, so the way to read the likelihood curve 10 is the truth along this axis, and in a sense it 11 is the degree or the strength of the evidence 12 for that particular underlying truth on this 13 axis. So the strength of the evidence is 14 strongest for the cure rate being, what do you 15 know, one third, and then it goes down from 16 there. 17 And you might be pleased to know that 18 if you cut this at some point, you're going to 19 get something very close to a confidence 20 interval, the 95 percent confidence interval, 21 and that represents cutting the curve at 22 roughly right there. So if you cut the curve 23 at about .15, that is evidence that's 15 24 percent as strong as it is for the peak value, 25 you will get the limits of something that are file:///F|/pg061709%20(2).txt (47 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00048 1 very very close to the confidence interval. So 2 this, the foundational concepts underlying 3 Bayes evidence and some of the other 4 traditional tools we use are very very closely 5 connected. I will say it is not always a 95 6 percent confidence interval, but in simple 7 situations it is. 8 Now I talked about alternative 9 hypotheses, and I do have to use different, 10 sort of flesh that out a bit. There's 11 different ways you can state a hypothesis. I 12 can state it like this, the alternative 13 hypothesis or in any hypothesis, the cure rate 14 is 15 percent. That's what's called a simple 15 hypothesis, I exactly specified what the cure 16 rate is. But I could say the cure rate is 17 greater than 15 percent. That's what we call a 18 composite hypothesis. Even though you see this 19 written all the time, these sort of things, it 20 actually represents an infinite number of 21 hypotheses, that is, the cure rate could be 16 22 percent, 17 percent, 18 percent, 19 percent. 23 So this is what's called a composite 24 hypothesis. 25 A treatment difference of zero, the file:///F|/pg061709%20(2).txt (48 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00049 1 null hypothesis, is a simple hypothesis. 2 If treatment is beneficial, that's a 3 composite hypothesis, right, because it doesn't 4 specify how much benefit. If the treatment is 5 harmful, composite. And you will see why this 6 is important later. 7 So I'm going to show you some examples 8 from two trials, and this gets very very close 9 to the kind of evidence we normally look at, a 10 big RCT and a small RCT, and I'm going to ask 11 you which provides stronger evidence against 12 the null hypothesis. So we have our big RCT 13 that shows a five percent mortality difference 14 with a confidence interval from zero to 10 15 percent with a P of .05. The small RCT shows a 16 20 percent mortality difference but is very 17 imprecise because it's a small RCT, a P of .05. 18 The question is, what's the evidence against a 19 null hypothesis? 20 What you learn when you look at this 21 in terms of Bayesian evidence is you have to 22 add to that question, you have to say compared 23 to what. You can't just ask what's the 24 evidence against the null hypothesis, because 25 we have already been told that by this strange file:///F|/pg061709%20(2).txt (49 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00050 1 measure of the P value the evidence is the 2 same, and yet, these results are dramatically 3 different, so it doesn't make sense that these 4 represent the same evidence against the null 5 hypothesis. 6 And here are the two likely preferreds 7 that correspond to those results. This is the 8 big study where it peaks at the five percent 9 level and comes down, with the confidence 10 interval being zero to 10 percent, and here is 11 the small study with the 20 percent peak, with 12 the confidence interval from zero to about 40 13 percent. So just looking at these curves, do 14 these represent the same evidence? They're 15 clearly not, but how do we quantify that using 16 Bayesian evidence? So we have to be specific 17 about the alternative hypothesis, so let's 18 start doing that. 19 So there's the degree of evidence that 20 both curves provide for the null hypothesis, 21 it's just that we look at the zero difference 22 and we look at the height of the curves right 23 there. So now let's ask a specific question. 24 Let's ask with a Bayes factor of the null 25 hypothesis, the difference is zero, versus the file:///F|/pg061709%20(2).txt (50 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00051 1 difference being five percent, the true 2 difference under the, in the small RCT, that is 3 this one. So what we do is we look at five, 4 here's the five percent number, we look at the 5 height of the curve there, and this height over 6 that height is 40 percent. So this says that 7 the study that showed a 20 percent difference 8 with a confidence level of zero to 40 percent 9 supports the null hypothesis over the 10 hypothesis that the difference is five percent, 11 it supports the null hypothesis 40 percent as 12 much as this hypothesis, that's 40 percent the 13 height of that, which we sort of know. That 14 is, if the possible estimates are spread out 15 all over the place, this study can't 16 distinguish very well between a null effect and 17 a five percent effect, that's what this is 18 telling me. It provides very little evidence 19 for the null versus the five percent effect. 20 Let's ask the same question of the big 21 RCT, what's the Bayes factor for no effect 22 versus a five percent effect? So what we do is 23 we extend that line up to there and we divide 24 this by this, and that's 14 percent. That is, 25 the five percent difference is supported one file:///F|/pg061709%20(2).txt (51 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00052 1 over that, about seven times more than that. 2 And that is because this study is much better 3 at discriminating between a five percent 4 difference and a zero percent difference. 5 So when we ask the question the right 6 way, when we say compared to what and we 7 compare it to the same thing, the evidence 8 provided for the five percent mortality versus 9 the null is quite different in the big RCT 10 versus the small RCT in spite of the fact that 11 they have the same P values. 12 Let's flip it around. Let's say 13 what's the evidence for a 20 percent 14 difference? Well, for the small RCT it's this 15 peak over this peak, which not surprisingly is 16 the same number we had before, .14, so the big 17 study supports a 20 percent difference over a 18 zero percent difference about seven times more 19 strongly. 20 But let's look at the other one, and 21 this is really interesting. The small study -- 22 I'm sorry -- the large study which had a five 23 percent difference, it says the Bayes factor of 24 the null hypothesis versus the difference being 25 as big as 20 percent in the big RCT is greater file:///F|/pg061709%20(2).txt (52 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00053 1 than a million, so here we have the null 2 hypothesis is not supported very well compared 3 to the 20 percent. Here it says that the null 4 hypothesis is supported a million times more 5 than the hypothesis if the true cure rate is 20 6 percent, and how could that be? 7 Well actually, this tells us just what 8 the confidence interval tells us. The 9 confidence interval on that big study goes from 10 about zero to 10 percent, so it pretty much 11 completely rules out a 20 percent change, 12 right? That's what the large study probability 13 tells us, that, you know, the null hypothesis 14 is barely in the mix, 20 percent is totally out 15 of the mix, so the null hypothesis is actually 16 supported by this study if we're comparing it 17 to a 20 percent difference by over a million 18 fold. So this shows you the importance of 19 asking the question carefully and precisely and 20 accurately. 21 The only place where we get seeming 22 equivalence of the Bayes factor is if we 23 compare these two heights over these two 24 heights, but these represent Bayes factors for 25 different alternative hypotheses. This one is file:///F|/pg061709%20(2).txt (53 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00054 1 the delta equals five percent hypothesis, this 2 one is the delta equals 20 percent hypothesis, 3 and then we have Bayes factors that are equal 4 of .14 to .14, but they're evidence for 5 different hypotheses, and that's the problem. 6 And the P value is the surrogate for this and 7 this is why the P value is so confusing, it 8 doesn't include information about the 9 magnitudes of the effects. So when I tell you 10 the P value is .05, which in this case is the 11 correlate of the Bayes factor in these two, 12 it's, while it is evidence against the null in 13 some sense, even though the number is wrong, 14 it's evidence against the null with respect to 15 different alternatives and that is the problem, 16 and that's what Bayes is very very rigorous 17 about and that's why it makes more sense. 18 So here we have a table that combines 19 the data, the alternative hypotheses and the 20 Bayes factor, and you see that we have these 21 equivalent Bayes factors only when we have 22 different alternative hypotheses, so it's just 23 restating what I just said. 24 So, I know we're technically five 25 minutes from when I was supposed to end even file:///F|/pg061709%20(2).txt (54 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00055 1 though I started 20 minutes late, or ten I'm 2 getting, okay. 3 DR. C. GOODMAN: Eight. 4 DR. S. GOODMAN: Eight, okay. I will 5 do my best, but that was the toughest part. 6 Suffice it to say that the P value 7 confuses us about evidence because it doesn't 8 take into account how large the effect is, a 9 tiny effect in a large trial will appear to be 10 the same evidence as a large effect in a small 11 trial. 12 Now of course we do ask questions like 13 what's the Bayes factor of the null hypothesis 14 versus the treatment is beneficial, that is 15 that the treatment difference is greater than 16 zero, in which case we're talking about the 17 evidence for the whole curve and what might we 18 want to do then. Well, this is what Bayes 19 does. It averages the height of that whole 20 curve according to the pis. It compares this 21 height compared to the average height of the 22 rest of the curve, and that average is using 23 the prior as a weight function. So it sort of 24 says, what's the average evidence for benefit 25 over the rest of the, some reasonable range. file:///F|/pg061709%20(2).txt (55 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00056 1 So that's what the prior is doing, that's what 2 the Bayesian evidence measure, how it's 3 operating. 4 So this is the last slide on which I'm 5 going to spend a little bit of time with, it's 6 sort of a Rosetta stone of translation, very 7 very complicated, but in fact it's not quite as 8 complicated as it looks. Here's the P value, 9 here's the smallest Bayes factor we can muster 10 for the null hypothesis, and you get the 11 smallest Bayes factor when you always specify 12 the alternative that is most supported by the 13 data. I'll be happy to leave that there. 14 This is a sort of more moderate 15 Bayesian evidence measure, but I would just 16 focus here, and here we have words that 17 describe the strength of the evidence. And 18 this shows the effects of this degree of 19 evidence, the maximum effect, the maximum 20 effect of a P of .05 translated into the 21 maximum -- the most powerful Bayes factor it 22 can be translated into. It shows it's effect 23 on various prior probabilities in the null 24 hypothesis. 25 We'll focus on the P of .05. This file:///F|/pg061709%20(2).txt (56 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00057 1 translates into a minimum Bayes factor of .15, 2 which is enough to bring you from a prior 3 probability of the null hypothesis of 75 4 percent to a probability of 31 percent, a flip 5 of the coin null hypothesis probability of 50 6 percent, down to a probability of 13 percent. 7 That is, if you concluded that the association 8 was real on the basis of that, you would be 9 wrong 13 percent of the time. 10 And finally, if you said you were 95 11 percent confident that the association was 12 real, that is that the null hypothesis only had 13 a five percent chance, you would essentially be 14 saying using this translation that you were 15 only 26 percent confident that the null 16 hypothesis were true before you started. So 17 any statement based on the P of .05 that you're 18 95 percent sure that your conclusions are true 19 means that you were 75 percent sure before you 20 even started, at least 75 percent if not more. 21 And you can go down here, you see that 22 a P of .01 corresponds to a most powerful Bayes 23 factor, and again, a true Bayes factor under 24 realistic conditions is going to be larger than 25 this, gets you down from a probability on the file:///F|/pg061709%20(2).txt (57 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00058 1 null hypothesis of 60 percent to five percent, 2 so you find that you have to demand somewhat 3 more evidence looking through a Bayesian lens 4 than you do, again, if you're looking at just 5 the null hypothesis, that you do if you're 6 looking at Bayesian measures of evidence, and 7 all these numbers are higher than these 8 numbers, but these are a lot higher. So, I 9 can't -- I will just leave that there. 10 So I only start to call things, start 11 using the word strong when I get well below 12 .01. John Ioannidis looked at the Bayes factor 13 in about 300 epidemiologic studies and compared 14 them to the P values and this, the fact that 15 there's a threshold here reflects that there's 16 a minimum Bayes factor. But what you see here, 17 here's the P value, here's the Bayes factor, so 18 the P value of one percent, two percent, three 19 percent, four percent, five percent, he did 20 this only for significant P values. And you 21 see here just what I've shown you, that the 22 Bayes factors as he defined them ranged from 23 .2, .4, .6, .8, much higher numbers. And you 24 see that although there's this cluster around 25 the minimum, there's a whole spread of studies file:///F|/pg061709%20(2).txt (58 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00059 1 that have significant P values but really very 2 noncompelling Bayes factors, and all of these 3 correspond to basically small studies with 4 large effects, that's what they are. 5 I'll just say this, or jump to this as 6 a famous example. A scientist gathers ten 7 observations and discovers to her horror that 8 they're nonsignificant, and she's quite sure 9 there's a difference, and she comes to MedCAC 10 and says listen, I want to show that this 11 device or treatment works, how much more 12 evidence can I work to provide to convince you 13 that this actually works. And the actual 14 answer is, using conventional approaches, start 15 a new area of research, no amount of additional 16 evidence can lower the overall type one error 17 below 9.75 percent, because she's already spent 18 her five percent alpha, and you know, in her 19 second crack at this she's going to spend 20 another fraction of that alpha. So there's no 21 getting below the magic alpha of five percent 22 if she used that threshold. 23 The Bayesian answer would be 24 different. If a scientist gathers ten 25 observations and discovers that the Bayes file:///F|/pg061709%20(2).txt (59 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00060 1 factor is greater than .05, what's the advice 2 that we give about how to conduct the 3 experiment, and the answer is keep collecting 4 data until the Bayes factor is less than five 5 percent, until you run out of money, time, or 6 CMS approves. 7 Because in fact, even though we know 8 that if you look multiple times at P values, 9 you're bound to get a significant result, it's 10 not true for Bayes factors. You can look as 11 many times as you want, your probability of 12 \"significant\" Bayes factor, and seriously we'll 13 define it as five percent, when it by 14 definition is less than five percent. There's 15 a limit on how often you can get misleading 16 evidence if you define the alternative 17 hypothesis before you start and that's the key, 18 defining the alternative hypothesis before you 19 start and not wavering. So in other words, if 20 would stop a trial -- this is just restating. 21 This is Bayesian learning, which you 22 will hear from Don, you'll get some more 23 Bayesian learning from him, and that's one of 24 the favorites. 25 So, a few final words on priors. file:///F|/pg061709%20(2).txt (60 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00061 1 Priors if informative should be evidence-based, 2 that is, if they have a lot of information in 3 them. Informative priors can often be 4 represented as data equivalents, that is a 5 prior with a 95 percent confidence interval of 6 plus or minus 10 percent cure rate is the 7 approximate equivalent of an RCT with 400 8 subjects. So you have to think if you're going 9 to use very informative priors that you're 10 willing to say that the evidence or belief is 11 worth that much information. So there's not 12 magic in Bayesian formulation, the prior does 13 in a sense represent evidence of some sort, and 14 if we're going to use it for public policy 15 purposes, we should look very closely at what 16 that evidence is. 17 As I've already said on many 18 occasions, Bayes theorem is mathematically 19 similar to a meta-analysis of the evidence in 20 the prior to the evidence from the data. 21 And this is one example of, a real 22 example of a study that we designed for kids 23 where here was the evidence from adults, there 24 was a lot of evidence from adults on the 25 efficacy of a certain treatment for file:///F|/pg061709%20(2).txt (61 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00062 1 Guillain-Barre' disease. And in our planning 2 we said okay, we're going to say that this 3 represents this much evidence in kids. That 4 is, there was evidence from about three to 400 5 adults that actually showed a benefit of the 6 therapy. We said we're going to center it 7 around one, we're not going to presume benefit, 8 but we're going to say that the 300 adults were 9 worth 70 kids. 10 Now you could take issue with that, 11 but the discussion around how similar the 12 disease and treatment is between adults and 13 kids, that's a real discussion that you can 14 have, that's a discussion I want neurologists 15 and pathologists and doctors to have, and can 16 inform us. It's not a discussion about 17 spending alpha and stopping rules and things 18 like that, and that's what I mean by saying 19 that Bayes has the right issues discussed by 20 the right people. 21 So prior specification of how we'll 22 measure evidence with the alternative 23 hypothesis can be seen as a prior restraint on 24 how we measure that evidence. I really want to 25 emphasize this. We often talk about the prior, file:///F|/pg061709%20(2).txt (62 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00063 1 you know, as this magic subjective 2 nonscientific component, but it's a constraint, 3 it's a straitjacket in the same way that the 4 design is a prior constraint, but this is a 5 constraint we can talk about. And the design 6 is a prior constraint on the set of possible 7 outcomes under the null hypothesis, and it is 8 this constraint of the priors that sets the 9 design free, and Don is going to speak to that. 10 So it's critical. 11 Both forms of inference have 12 constraints, but the Bayesian one has one that 13 is more explicit and makes more sense and is 14 subject to discussion. So what CMS needs to 15 know, the Bayes theorem has a separable data 16 and belief component that can be viewed as a 17 calculus of evidence and not just belief. The 18 likelihood-based evidence measures can have 19 very attractive frequentist, that is error 20 control properties, I haven't shown you that, 21 Don will, but you don't give up using these 22 measures of evidence. In fact you can do it 23 just as well, you just do it along more 24 sensible measures of evidence. 25 Standard inferential methods represent file:///F|/pg061709%20(2).txt (63 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00064 1 evidence inappropriately, use unnecessary 2 rigidity in design and interpretation, and that 3 the use of Bayesian evidential measures can 4 have an impact far beyond the sometimes 5 different numbers they produce. They affect 6 how we talk about the evidence and who 7 participates meaningfully in that dialogue. 8 So, this is the entre to Don. This 9 prior evidence defined in a broad sense should 10 be formally incorporated in the interpretation 11 of clinical research. It is certainly relevant 12 to the design of clinical research. So I have 13 a quote here from Don, we're all Bayesians in 14 the design phase, and I couldn't find it 15 specifically in his writings but he's repeated 16 it I think every seven minutes between 1970 and 17 2009, and you're going to hear it again today, 18 so I hope I haven't stolen his thunder. 19 I'm going to give the final word to 20 A.W.F. Edwards, who was a disciple of R.A. 21 Fisher, who said this. What used to be called 22 judgment is now called prejudice. What used to 23 be called prejudice is now called a null 24 hypothesis. It is dangerous nonsense dressed 25 up as a scientific method and will cause much file:///F|/pg061709%20(2).txt (64 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00065 1 trouble before it's widely appreciated as such. 2 I think that presages our meeting today. 3 Thank you. 4 DR. C. GOODMAN: Thank you very much, 5 Steve. Steve, before you leave the podium, can 6 you distill for us in really a sentence or 7 two -- 8 DR. S. GOODMAN: I might say no to 9 that. 10 DR. C. GOODMAN: Can you distill for 11 us in a sentence or two from a practical 12 standpoint, were CMS to use Bayesian 13 interpretation in making coverage 14 determinations based on available evidence, 15 using those methods, that would increase the 16 credibility of their coverage determination in 17 exactly what way, and speak to the 18 non-statisticians among us. 19 DR. S. GOODMAN: That's a very big 20 question. I think I'm going to sound like a 21 Supreme Court justice here or something. It 22 really depends on the specifics and the kinds 23 of conversation that went into the coverage 24 decision. I will say that very often good 25 people, sensible people looking at evidence in file:///F|/pg061709%20(2).txt (65 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00066 1 sophisticated ways can articulate judgments 2 that at the end of the day are the same 3 judgments you would make with Bayesian methods. 4 However, it sometimes looks like you bent the 5 rules, like issues without plausibility, and I 6 haven't even gone into the comparative 7 effectiveness and issues of safety, have either 8 been broken or bent or implicit, and this 9 sometimes makes the rationale for those 10 decisions much more explicit. 11 And it takes the conversations that 12 you might have around the table around the real 13 issues that went behind the coverage decision 14 rather than leaving issues around studies that 15 either deviated from their planned design, or 16 interventions that don't have a good biologic 17 foundation for which you might want to demand 18 more evidence, but it's very difficult to do 19 that under the current paradigm where you have 20 these P .05 thresholds. So I would say that 21 the way one articulates and incorporates 22 formally the judgments that are made about the 23 requirement for evidence thresholds, more of 24 that will be on the table, a little less will 25 be mysterious. file:///F|/pg061709%20(2).txt (66 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00067 1 With that said, you know, I can't say 2 in every situation that it's going, that it 3 will make a revolutionary difference, and if it 4 was, then I would be impugning every decision 5 that the MedCAC has done. That said, it 6 allows -- I don't want to focus just on the 7 interpretation of evidence. There's a whole 8 domain which Don is going to talk about with 9 Bayesian design and the kinds of studies that 10 we set up and the kinds of studies that might 11 be used to produce evidence to the panel that 12 could be changed by incorporating a more 13 liberal Bayesian approach. 14 So I don't want to take the question, 15 just if we were fed a certain amount of 16 evidence, will our decisions be better. I 17 think this has the potential for affecting the 18 kind of evidence that you're presented with in 19 the first place, so it's sort of a twofold 20 answer. 21 DR. C. GOODMAN: So if I were to 22 distill what you just said, it sounds as though 23 it could lend greater transparency to 24 deliberation, number one. Number two, it could 25 inform the design prospectively, CMS might be file:///F|/pg061709%20(2).txt (67 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00068 1 better able to inform those who would generate 2 evidence on how to design studies that would 3 yield more useful evidence. 4 DR. S. GOODMAN: Yes, and it does 5 prevent the sometimes silly mistakes due to the 6 adherence to sort of mechanical rules which 7 sometimes happens, but in the hands of sensible 8 people hopefully it doesn't; it doesn't happen 9 too often. 10 DR. C. GOODMAN: Thank you. Again, 11 before you leave, I know we may come back to 12 further questions, but we're going to have two 13 concise questions and even more concise answers 14 from you, if that's possible. David first, 15 quickly. 16 DR. AXELROD: I wanted to come back to 17 your Carvedilol example that you brought up 18 earlier, and the question of sort of secondary 19 endpoints and subgroup analysis and that sort 20 of stuff. And I think you made a fairly 21 convincing argument that at least from a 22 primary effects design phase, if you design it 23 right, Bayesian statistics add a lot to it. 24 Would that use of Bayesian ideas and analysis 25 really have informed that Carvedilol file:///F|/pg061709%20(2).txt (68 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00069 1 discussion, because again, they didn't specify 2 up front what that alternative hypothesis would 3 have been so, again, how does that use of 4 Bayesian statistics help us understand some of 5 these sort of subgroup or secondary endpoint 6 things that come before the group here? 7 DR. S. GOODMAN: That's a very 8 complicated question actually, it's a concise 9 question, and I will actually leave that 10 partially to Don to answer. But the Bayesian 11 approach to subgroup analysis and multiplicity 12 is fundamentally different than the frequentist 13 approach, and you can either model the 14 relationship between surrogate endpoints and 15 definitive endpoints, which could have been 16 done here, where they pick one as a primary, 17 pick one as the secondary, they're clearly 18 related, and you could look at the 19 relationship. 20 You can also look at the family of 21 subgroup analysts and say that they will model 22 their relationships, they will inform each 23 other, so you can either model them as 24 explicitly related in terms of mechanism 25 related, or you can say that they, that you file:///F|/pg061709%20(2).txt (69 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00070 1 will model them as an ensemble together, and if 2 there are outliers, you sort of pull them back, 3 you don't believe outliers in the subgroup. 4 But Bayesian doesn't have a magic 5 solution to these subgroup analysis problems, 6 but they have more coherent approaches to 7 dealing with the problem, and Don will talk a 8 little bit more about that in design where the 9 issues of multiplicity are built directly in a 10 sense a priori. 11 But here the problem was already cast 12 in stone by the design and by the sort of 13 artifactual separation between secondary and 14 primary, and it didn't capture everything that 15 they knew about these endpoints, that was the 16 problem. But there was a lot going on in that 17 discussion that had nothing to do with what 18 they knew about the relationship of these 19 endpoints. It's actually a difficult issue. 20 DR. C. GOODMAN: Saty, one more and 21 then we'll move on. 22 DR. SATYA-MURTI: On the adult versus 23 child IDIG example, if I understand you 24 correctly, that would be an example where the 25 priors were set by clinicians who made a prior file:///F|/pg061709%20(2).txt (70 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00071 1 belief using their experiential data to show 2 that so many children would be helped, correct, 3 and that was devoid of any statistical origins, 4 they just got together and set a prior; is that 5 right? 6 DR. S. GOODMAN: That actually was set 7 together with me and a pediatric neurologist, 8 but the judgment call there, and it wasn't 9 necessarily the only prior that we could have 10 come up with, came out of judgments about how 11 similar the treatment and the disease was in 12 adults and children, and other evidence I 13 didn't show you empirically showed how similar 14 those were. So it wasn't just looking at one 15 curve and saying okay, there's this other 16 curve. It was using multiple sources of 17 evidence to indicate, to relate to both the 18 disease and the treatment in adults and 19 children, and we had a continued conversation 20 about that. 21 DR. SATYA-MURTI: And that was your 22 alternative? 23 DR. S. GOODMAN: Based on evidence. I 24 mean, there was actual empirical evidence there 25 as a starting point. The evidence that brought file:///F|/pg061709%20(2).txt (71 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00072 1 us from adults to kids, though, was softer, and 2 that's the crux of that issue. 3 DR. C. GOODMAN: Great. Thank you 4 very much, Steve, we appreciate your coming and 5 it was a splendid presentation. 6 Before we proceed, I know that 7 Dr. Prager came in a few minutes later, and Dr. 8 Prager, we need for you to introduce yourself 9 and declare whether you have any interests. 10 DR. PRAGER: My name is Joshua Prager. 11 I'm a full-time pain physician at UCLA. And I 12 guess the closest thing I have to a conflict, 13 which is kind of a coincidence here, is that 35 14 years ago I spent a full year studying Bayesian 15 statistics at Harvard, and I think it's just a 16 coincidence that I'm here in that regard, but I 17 haven't done anything with it in the last 35 18 years, so I guess I don't have a conflict. 19 DR. C. GOODMAN: Thank you, Dr. 20 Prager. I'm sure the Office of the Inspector 21 General will have a word with you on that. 22 Next, we're very pleased to have 23 Donald Berry from the Department of 24 Biostatistics at the University of Texas. Dr. 25 Berry, your name has been invoked at least a file:///F|/pg061709%20(2).txt (72 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00073 1 half a dozen times in the last hour. We would 2 be delighted if you could condense your 3 presentation from 60 minutes to 50, if that's 4 possible. 5 DR. BERRY: Yes, sir, I'm nothing if 6 not adaptive. 7 So, I do have conflicts. I jointly 8 own with my son a company that does consulting, 9 essentially exclusively on Bayesian statistics. 10 And as Steve indicated, perhaps a more 11 important conflict, for 40 years I have been 12 talking about this question, so I have a 13 professional conflict, especially since for the 14 first 30 years nobody listened. They would say 15 things like, every time I listen to you talk, 16 Don, I become a Bayesian for ten minutes. 17 So my outline is, I will tell you a 18 little bit more about the Bayesian approach, 19 the current use of the Bayesian approach, 20 expanding somewhat on what Steve has so 21 eloquently said, what is Bayesian adaptive 22 design, predictive probabilities in design, 23 adaptive randomization including pairing drugs 24 and biomarkers, the way we have to go in 25 medical research and drug development for file:///F|/pg061709%20(2).txt (73 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00074 1 example. And I'll tell you about I-SPY2, which 2 is a joint venture of the NCI, the FDA, a 3 consortium called the Foundation for the NIH, 4 which is funded by drug companies. Adaptive 5 dose finding, clinical utility. And CISNET. 6 CISNET is Cancer Intervention 7 Surveillance and Network and this is something 8 that was funded by the NIH, it was seven models 9 addressing the question of breast cancer 10 mortality reduction in the United States, what 11 was the cause, was it treatment, was it 12 screening, what combination, one of those 13 models was Bayesian, and I will tell you about 14 the use and the role. 15 Practical advantages of Bayes, online 16 learning, Steve talked a little bit about that, 17 I'll tell you a bit more. 18 Predictive probabilities. If there's 19 anything -- I mean, Steve indicated that 20 there's some things that frequentists can't do; 21 counter-frequentists can do essentially 22 anything. The problem is that you have to be, 23 you have to go outside of your philosophy in 24 order to do the clever things. Probably the 25 hardest thing that frequentists have to do is file:///F|/pg061709%20(2).txt (74 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00075 1 predicting where they're going. They can say 2 if you know the parameter, if I can do a 3 prediction on the null hypothesis, I can do 4 predictions, I can say what the probability 5 distribution is of the future results, but the 6 parameters take it to be known. 7 It's only the Bayesian who can say on 8 the basis of what I know today, the parameter 9 has itself a distribution. I can put those two 10 pieces of information, the future uncertainty 11 and the current uncertainty together to talk 12 about what is the probability distribution of 13 the future results given where I am today. And 14 that helps in monitoring trials, that helps in 15 building trials that are efficient, and I will 16 give you some examples of that. 17 Modeling, of course, all statisticians 18 can do modeling, just an empirical observation, 19 and I guess all of them are empirical. 20 Bayesians do more modeling. You will hear 21 about some today, hierarchical modeling, for 22 example, longitudinal modeling in cancer, but 23 generally in medicine we err in looking at 24 endpoints that are different from one study to 25 another. So some are early endpoints in file:///F|/pg061709%20(2).txt (75 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00076 1 cancer, in Phase II we look at tumor response 2 or progression-free survival, in Phase III we 3 look at overall survival, and never the twain 4 shall meet. 5 We've got to be modeling what happens 6 to an individual patient over time and looking 7 at things like tumor response and progression 8 and survival, but also biomarkers that come 9 into the equation, biomarkers could be thinking 10 more of a standard, like MRI, for example, but 11 also the various 'omics part of that revolution 12 and decision analysis, another practical 13 advantage of Bayes. 14 All right. This is Bayesian adaptive 15 science. At M.D. Anderson, my home institution 16 since I got there ten years ago, we have run 17 over 300 trials from this perspective, I think 18 that's probably more than the rest of the world 19 combined. Most of them were Phase I and Phase 20 II trials. As Dr. Salive indicated, the Center 21 of Devices at the FDA about 12 years ago 22 initiated a Bayesian approach following a 23 mandate from Congress to do things which are 24 so-called least burdensome, and they said oh, 25 Bayes. And recently in 2006, as he indicated, file:///F|/pg061709%20(2).txt (76 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00077 1 with Bayesian guidance in the past 12 years 2 there have been over 20 PMAs that have been 3 approved and maybe five 10-Ks. 4 All of our drug companies are dabbling 5 at least in the area, doing Bayesian adaptive 6 designs and sometimes niche drugs. Other 7 companies such as Eli Lily, Wyeth, Novartis, 8 it's a substantial part of their portfolio that 9 they use in the early phases, adaptive Bayesian 10 design, and sometimes in Phase III trials and 11 hopefully more in Phase IV trials, which is 12 more the interest of CMS. 13 Some Bayesian device applications, and 14 I just have this for you to look through, some 15 areas in which the Bayesian approach has been 16 used in drugs. And just to contrast oncology 17 and migraine, in migraine the registration 18 endpoint is two hours pain-free, and so the 19 information that's available is essentially 20 instantaneous. 21 There's a small matter of the 22 logistics and the information flow, but -- I'm 23 joking about a small matter, it's not a small 24 matter -- but these things have been conquered 25 by many CROs, and you can get the data almost file:///F|/pg061709%20(2).txt (77 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00078 1 instantaneously as to what the results are. 2 It's not clean results, it's not audited 3 results, it's not results that contain all of 4 the lab values, but it's the information that 5 we use, then, to say well, okay, what dose do 6 we want to use for the next patient that comes 7 in, for example, or are we done yet. 8 In oncology and many of these other 9 diseases, Alzheimer's, lupus, obesity, the 10 information is not immediate. And if it's 11 overall survival, for example, in cancer, even 12 if it's something as horrible as pancreatic 13 cancer, it's many months and maybe years before 14 the information accrues, and so that raises the 15 issue and need for doing longitudinal modeling. 16 These are in order, my understanding 17 of the way in which adaptive designs are used 18 in the world of drug development, medical 19 device development. The most common is the 20 early stopping, historically stopping for 21 efficacy, more recently and I think very 22 importantly, stopping for futility. Dose 23 finding is the second most common use of 24 Bayesian adaptive methods. Seamless phases, 25 where, you know, this notion that after a phase file:///F|/pg061709%20(2).txt (78 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00079 1 of drug development we know the answer to some 2 question, we know the dose, you never know the 3 dose. You have to recognize that and to move 4 seamlessly looking at toxicity. 5 Looking at efficacy throughout the 6 entire course in a seamless one-two, and a 7 seamless two-three, for example, is becoming 8 not exactly de rigueur but is very common. 9 Population finding, whom does my drug 10 help, which subset of the patient population 11 does my device work best in so that it has 12 clinical utility? Essentially everybody is 13 interested in this. It's an extremely 14 difficult thing to do inferentially, 15 scientifically, but people are doing it. 16 Adaptive randomization, this is 17 something that may be special for a clinical 18 hospital. At M.D. Anderson we've done many of 19 these trials where we base the next treatment 20 on how well that treatment and its competitor 21 treatments have been doing, not only 22 historically as you heard Steve talk about in 23 the prior presentation, but also in the trial. 24 So if a treatment is doing better, we assign it 25 with higher probability, and I will give you a file:///F|/pg061709%20(2).txt (79 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00080 1 couple examples of that. 2 Ramping up accrual, and I thought this 3 would be a biggie in the pharmaceutical world 4 where you start out slowly, get information, 5 get some potentially promising results, and if 6 they're sufficiently promising, you open up to 7 other centers. And if not, well, you don't 8 continue in the smaller center or maybe 9 eventually stop for futility. You know, 10 putting in something -- I sometimes ask 11 investigators, okay, so what is going to be the 12 consequence of this trial? And they say -- I 13 say suppose such and such of data and they say 14 X. Or I say well, suppose thus and so are the 15 data, and they say X. They don't really know 16 why they're doing these trials. It's of course 17 a lot better in industry, but even there 18 putting together a coherent development within 19 a process, not necessarily a trial but a 20 process. 21 Anyway, the reason it's on the bottom 22 of the list is I was wrong, this has not been 23 adopted very widely. I know one trial where 24 they're doing that in industry. The reason is 25 that the rewards in industry are associated file:///F|/pg061709%20(2).txt (80 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00081 1 with accruing as fast as you possibly can, 2 sometimes to the detriment of patients in the 3 trial, and there are plenty of examples of 4 that. And so it's difficult to persuade people 5 to go, you know, at a moderate rate for a time. 6 So just a little bit about updating 7 because I think it's so important. Steve 8 passed over something I wanted to show you. 9 Consider an example, simple example, paired 10 observations. Either the treatment does better 11 in the pair or the control does better in the 12 pair. So they're very simple in the sense that 13 the null hypothesis is like tossing a coin, a 14 fair coin, the probability of success that the 15 treatment wins the pair is a half, and you get 16 some data. And here are the, you know, 17 17 observations. The first two were successes, 18 then failure, then a couple successes and a 19 failure, et cetera. 20 The way the Bayesian approach works, 21 as Steve indicated, is you start with a prior 22 distribution, this is a non-informative flat 23 prior, it's a prior that for registration 24 purposes the FDA usually asks you to assume. 25 It pretends that you don't know anything. file:///F|/pg061709%20(2).txt (81 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00082 1 After the first observation of empiric results 2 of the success and what the mechanics are, to 3 go from prior to posterior, you multiply the 4 probability of the data, which depends on the 5 parameter, which in this case is P, so you 6 multiply by P. 7 Then the next observation was another 8 success, you multiply by P again, P-squared 9 total, and then one minus P. I'm not 10 interested so much in the mechanics, you know, 11 how do you go from one point to the next. What 12 does interest me is that you can do it. You 13 can say this is what I know today, I just made 14 another observation and I've updated 15 accordingly. So with every observation, you 16 can describe what you know. 17 And as you know, in the frequentist 18 approach, the evidence is based on the 19 experiment, so you say what the experiment is 20 going to be and you follow the experiment and 21 then draw a conclusion, you know, do you get 22 statistical significance or not. The Bayesian 23 approach is much more flexible than that. So 24 just finishing, multiply by P, another P, one 25 minus P, et cetera. These are after ten file:///F|/pg061709%20(2).txt (82 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00083 1 observations; what about the 11th? The 11th 2 observation I can tell you is going to be of 3 two types, either the pinkish color if you get 4 a success on the 11th pair, or the purplish 5 color if you get a failure on the 11th pair. 6 You know that's going to happen, either one or 7 the other. The beauty of the Bayesian approach 8 is you can say what the probabilities are of 9 those happening given what we know today, and 10 this is what we know today. So based on this, 11 what is the probability of a failure or a 12 success, and the answer is for those on 13 descending, the Laplace rule of succession, 14 there's a one-third chance of failure and a 15 two-thirds chance of success. 16 Predictive probabilities are 17 essentially monitoring trials for building good 18 experimental designs, efficient experimental 19 designs, and in my favorite clinical trial, as 20 he said, we must ask where we are and whither 21 we are tending. It applies in ordinary life 22 and it applies in clinical trials. He didn't 23 say, you know, it would be nice to ask where 24 we're going, he said you must ask whither you 25 are tending. file:///F|/pg061709%20(2).txt (83 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00084 1 So this is the current distribution 2 after 17 observations and you can calculate 3 things like the probability of the treatment 4 being effective, the P is bigger than a half. 5 You can calculate the predictive probability 6 distribution in the same way that I indicated 7 before. Or doubling the sample size, suppose 8 if you've got 17 observations, you've got bare 9 significance in the 17 observations. If you 10 double the sample size, you get 34 11 observations, the predictive observations for 12 the next 17 is shown here in the upper 13 histogram. 14 The frequentist version of that, the 15 frequentists will say well, assume P is equal 16 to the maximum likely estimate, then I get this 17 distribution. You can also assume P is equal 18 to a half and get another distribution. All of 19 those distributions have less variability than 20 the right one, and it's because they 21 incorporate the variability in the future but 22 they don't incorporate the variability in the 23 current understanding of what is P. 24 So you can calculate, for example, the 25 probability of statistical significance after file:///F|/pg061709%20(2).txt (84 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00085 1 you double the sample size is 88 percent, in 2 the case where you assume that P was equal to 3 the maximum likely estimate, it's 96 percent, 4 and 96 percent is woefully optimistic. Why do 5 people do Bayesian things? Smaller trials 6 usually, more accurate conclusions, and the 7 objective, of course there are different 8 objectives, but when we design a trial we say 9 what is the theme, what are we trying to do, 10 now let's build a trial using Bayes as a tool 11 that does that as efficiently as possible, and 12 one of the objectives can be treating patients 13 in the trial as efficiently and as good as 14 possible. 15 Predicting trial results, I will just 16 let you use this, let you check this out. An 17 important thing is that we model relationships 18 among the various endpoints and we do 19 simulation. Here is an example of a trial that 20 our monitoring committee met concerning, it 21 meets every year, or considers each trial every 22 year. This was the neoadjuvant Herceptin. 23 Herceptin is an antibody that targets for two 24 positive breast cancer and the Her2 oncogene 25 generally. file:///F|/pg061709%20(2).txt (85 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00086 1 And for those of you who don't know, 2 it reverses the usual way you treat breast 3 cancer. Usually you take out the tumor and 4 then deliver a systemic hormone or chemo. 5 Neoadjuvant means you leave the tumor in, 6 deliver the systemic therapy first, and observe 7 the tumor and the effect of the treatment on 8 the tumor and then six months later, say, 9 remove the tumor or where the tumor once lived 10 and send it to pathologists, and if they can't 11 find any tumor, that's call a pathologic 12 complete response, and that was the endpoint of 13 the trial. 14 The design of the trial was 82 15 patients in each group, 164 total. We met, the 16 data monitoring committee met after 20 percent 17 of the patients had been treated. Treatment 18 accrual was very slow for a number of reasons. 19 In the Herceptin arm the rate was 67 percent of 20 18 patients and the control arm was consistent 21 with what we had seen previously in our 22 institution of patients responding to this 23 therapy. And we said, you know, in view of 24 accrual, the rate of accrual and in view of the 25 importance of this question -- this predated file:///F|/pg061709%20(2).txt (86 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00087 1 the, for those of you that know the story, this 2 predated the four adjuvant trials totaling 3 12,000 patients that would be announced at some 4 point, all being completely consistent with 5 these results, by the way. 6 And we did a Bayesian probability 7 calculation, predictive probability calculation 8 that said that after 164 patients, if we could 9 ever get there, which was going to be well into 10 the future, the probability of success was 95 11 percent and so let's stop the trial. We did. 12 It was submitted to ASCO and published in the 13 Journal of Clinical Oncology. 14 A purely statistical reason for the 15 sorry performance with drugs in Phase II, and 16 this is the usual power calculation, this is 17 traditional powering, you know, here's the null 18 hypothesis and this is the alternative 19 hypothesis, this is the power that we have for 20 detecting the alternative hypothesis. Where we 21 get the alternative hypothesis, nobody knows. 22 The statistician says talk to the clinician, 23 the clinician says talk to the statistician. 24 But this, it might be, for example, an 25 excellent likely estimate based on frequentist file:///F|/pg061709%20(2).txt (87 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00088 1 data. If one were to say, what do we know 2 about the hypothesis, it may be that that's the 3 maximum likelihood value, but there's 4 uncertainty associated with it. Take this 5 uncertainty and consider the fact that maybe, 6 you know, the truth is down here. It has some 7 probability of being down here. And if it is 8 down there, the power is a lot less. Maybe 9 it's up here and if it is up here, the power is 10 a little bit more. The concavity of this curve 11 means that the true predictive power averaging 12 against the uncertainty is less. My rule of 13 thumb is for something that is 80 percent 14 power, I automatically give them credit for 60 15 percent, and then they have to deserve that. 16 So here is an example where they 17 didn't deserve it and I will just let you look 18 through the example. It was a stroke trial, 19 SAINT I had been conducted, had shown an odds 20 ratio of 1.2, so their actual likely estimate 21 in SAINT II was 1.2, and they built an 80 22 percent power to detect a 1.2 as opposed to 1, 23 and they increased the sample size in SAINT II 24 up to 3200 in order to achieve that. 25 In reading this paper in the New file:///F|/pg061709%20(2).txt (88 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00089 1 England Journal, this is, as Steve said, this 2 is not the probability of the null hypothesis. 3 And people were saying at the time, well, if 4 the P value is .038, that's the probability 5 that SAINT II is going to fail, so this is 6 carrying it a step beyond the absurd. 7 And if you look at, this was for 8 modified ranking, if you look at the Barthel, 9 if you look at the stroke impact scale and all 10 the other things they did, they were not even 11 close to being significant. So they advertised 12 80 percent, naive reduction 60 percent, but 13 based on the other characteristics that I read 14 in the SAINT I paper, my probability that SAINT 15 II was going to be positive was 10 percent. 16 The Astra Zeneca statisticians when I presented 17 this, you know, was you're wrong, it's 80 18 percent. Well, I was right. I suppose I 19 wouldn't be telling you if I weren't right, but 20 the results from SAINT II did not meet its 21 primary outcome, and no further development is 22 planned. 23 So, the morals are to do predictive 24 power instead of power, but more importantly, 25 build in adaptive things. I mean, this trial file:///F|/pg061709%20(2).txt (89 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00090 1 should have stopped for futility. When I first 2 presented this at an NCI conference, the 3 chairman of the data monitoring committee, 4 Stuart Polokoff was in the audience, and he 5 came up afterwards and said that you're exactly 6 right, we could see that the trial was going 7 south but we had no way that we could go about 8 getting out of this adaptive aspect and bail 9 out. 10 This is a trial just recently 11 published last month. It was a cancer group 12 that I design trials for breast cancer for. 13 This was a trial looking at capecitabine versus 14 standard therapy. The NCI said we had to do an 15 1800-patient trial and I said we can't, we 16 don't have that many patients, we could do 600 17 and that's probably going to be enough. And 18 they said no, you have to do an 1800-patient 19 trial. 20 So I built a Bayesian predictive 21 analysis, really a very liberal interim 22 analysis that would stop based on a prediction 23 that after some period of time we will know the 24 answer, so we would stop accrual at that point. 25 We wouldn't announce but we would stop accrual, file:///F|/pg061709%20(2).txt (90 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00091 1 and we advertised the trial as not being a 2 600-patient trial, not being an 1800-patient 3 trial, but a trial with a sample size ranging 4 from 600 to 1800. But lo and behold, after 600 5 patients we did the predictive calculation. 6 Accrual was, you know, we frankly lied to the 7 NCI about what the accrual would be and, you 8 know, we were right in what we knew to be our 9 ability to accrue these patients. And after 10 600 patients had accrued we did this predictive 11 calculation, and you see that it says a 12 Bayesian statistical design was used with the 13 range in sample size here. 14 Interim analyses were not of the 15 standard type in which you cross a boundary and 16 declare victory or not. Rather, the decision 17 to discontinue enrollment was based on the 18 prediction that future follow-up was likely to 19 give a meaningful answer, and it did. And for 20 those of you interested in seeing the results, 21 here they are. 22 Adaptive randomization, I mentioned 23 that at M.D. Anderson we do a lot of trials 24 that have this characteristic, so here's a 25 simple three-armed trial. The PI, Francis file:///F|/pg061709%20(2).txt (91 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00092 1 Giles, approached me about designing a trial in 2 AML. He said Ara-C, cytarabine is the standard 3 therapy in this disease, I would like to take 4 each of those arms and compare it to the 5 experimental therapy, troxacitabine, and so it 6 would be a three-armed trial, Phase II, and I 7 would like to have 25 patients per arm, 75 8 total. And I said okay, but why don't we look 9 at the data and if it's turning out that one of 10 the arms is doing better than another, we'll 11 give it higher probability, and if the 12 probability that it's better than the others is 13 sufficiently low, we will drop it. So he said 14 okay. 15 So we built in adaptive randomization 16 and this is the result of the trial. After the 17 24th patient had accrued, TI was doing 18 sufficiently poorly that we dropped it. And 19 after the 34th patient we stopped the trial 20 because TA dropped. And these are the data. 21 This is CR by date. Complete remission is 22 important, in fact, it's a registration 23 endpoint, and roughly speaking you don't live 24 if you don't get complete remission. And so 25 the standard therapy had what was quite similar file:///F|/pg061709%20(2).txt (92 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00093 1 to the historical rate. TI dropped after five 2 patients with no CRs, and TA dropped after 11 3 patients with three CRs. 4 You know, we could calculate, as Steve 5 indicated, the completely perspective design. 6 We have calculated the false positive rate and 7 power. Maybe we made a mistake, but if we did, 8 it wasn't a very big one. I mean, if TI is 9 better than IA, it's not very much better. So 10 Giles sent this to the Journal of Blood, and 11 the editors said you can't do anything with 12 five patients, and I wanted him to write back 13 and say, you tell him if he gets this disease, 14 we have a treatment for him. But he's nicer 15 than I am, so he sent it to General Clinical 16 Oncology, and they said it was clear that the 17 design was a dud, but the design is wonderful 18 so we will publish your study. 19 I think I'll skip this factorial 20 design, I'll just tell you a little bit about 21 it. You've got it in your handout, you can 22 read. In cancer we do Phase I trials looking 23 at toxicity, we establish an MTD, a maximum 24 tolerated dose, and then go into Phase II. 25 This trial design combines the two, so we start file:///F|/pg061709%20(2).txt (93 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00094 1 out, we walked up the dose ladder, it was a 2 very complicated dose ladder, you'll see two 3 dose ladders because there were two drugs and 4 there was a schedule of dosing concurrent 5 versus sequential so it was very complicated, 6 like a factorial design. Only within the 7 factorial design it's not a complete factorial, 8 we did it adaptively, walking up such that the 9 toxicity would allow us to walk up, but then 10 doing this adaptive randomization stuff in the 11 back. And so, we have a number of trials that 12 take this tack at Anderson and this is just to 13 show you how we do it. 14 I want to tell you I-SPY2, I-SPY2 is 15 this incredibly radical idea that we can look 16 at characteristics of patients that may be 17 responding to a therapy, that we in fact used 18 many therapies, there's a control therapy -- 19 let me move forward. 20 This is a neoadjuvant breast cancer 21 again, high risk, stage two or three, and the 22 standard therapy is taxane-based. We used 23 that, but then on top of that add either 24 placebo or experimental agents. And the 25 experimental agent could be one of, somewhat file:///F|/pg061709%20(2).txt (94 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00095 1 arbitrarily, five possibilities depending on 2 the accrual rate. One of the issues is we were 3 working with the Foundation for the NIH and the 4 drug companies, and the drug companies wanted 5 to get an answer reasonably quickly, so if the 6 accrual is slow we're not going to be able to 7 do five experimental arms. 8 Drugs come along, they get inserted 9 into the mix, so it's like a screening trial. 10 It's like a process rather than a trial. And 11 how big is it, it could go on forever, plugging 12 in additional drugs. As drugs show they're 13 either good or bad, they graduate or flunk out, 14 and if they graduate they graduate with a 15 diploma that says where they're good, you know, 16 what patients are benefitting from this 17 therapy. The primary endpoint is path CR, 18 although we of course relate to longer-term 19 endpoints such as survival. The surgery -- the 20 ultimate outcome for the primary endpoint is 21 six months, and that's reasonably rapid in 22 cancer but it's not fast enough for us. 23 We build in MRIs over time and look at 24 the tumor volume, and relate the tumor volume 25 to the ultimate endpoint, the path CR or not. file:///F|/pg061709%20(2).txt (95 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00096 1 And so this is something that Bayesians do just 2 kind of naturally. They say what information 3 do I have about the patient, what does it tell 4 me about the ultimate outcome, and what do I 5 have from the patients that have been treated, 6 that are all through surgery based on what 7 their MRI results were, and did they experience 8 a path CR. So using all of that information, I 9 have a current patient who has an MRI volume 10 measured that concurs with the baseline, so 11 what do I predict for her path CR, is it going 12 to be a path CR or not, and what uncertainty is 13 associated with that, and the next MRI that she 14 gets will update that as well. 15 So the goal is to predict which 16 biomarker signatures predict response to which 17 drugs and combinations, model relationships 18 between baseline and longitudinal markers to 19 predict path CR. You will see that there are 20 many biomarkers, many kinds of possibilities. 21 False positives are rearing their heads all 22 over the place and we have to beat them down at 23 least to some extent. So there has to be at 24 least some level of confirmation. 25 Bayesians worry about multiplicities. file:///F|/pg061709%20(2).txt (96 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00097 1 We graduate drugs and biomarkers to smaller 2 more focused Phase III. Instead of having a 3 3000-patient Phase III trial, we have a 4 300-patient Phase III going. The adaptive 5 design allows for learning, changing, adding 6 agents over time, uses a standard biomarker. 7 There are two kinds of biomarkers, 8 standard and qualifying, and we're working with 9 the FDA Center For Devices with respect to the 10 latter. With respect to the former, the 11 standard biomarkers have been approved and 12 these are the ones that are used to drive 13 treatment. We can't drive treatment off of the 14 qualifying biomarkers. It's conceivable that 15 the qualifying biomarkers would graduate into 16 the standard realm where we're using it for 17 treatment assignment, but if that happens it's 18 an amendment to the protocol, it's not in the 19 current protocol. 20 So, the FNIH was formed a long time 21 ago, I wanted to see if I could find it and I 22 couldn't, but the FNIH is a consortium of the 23 NCI, this is the cancer steering committee and 24 the FDA, and I think they said CMS, but I've 25 been dealing with this group a lot and I file:///F|/pg061709%20(2).txt (97 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00098 1 haven't seen CMS there yet. But this is a 2 consortium that includes industry as well; in 3 fact the funding comes from industry as well as 4 foundations. 5 So the control is taxane-based. We 6 start off balancing, when a drug comes in we 7 randomize patients to that drug based on what 8 little information we have at the start and so 9 it gets balanced in a randomized balance 10 fashion. But as we get information we learn 11 which drugs are benefitting which patients and 12 if the probability is high enough for a 13 particular patient, she gets that drug with a 14 higher probability. We include combinations, 15 possibilities for combinations. 16 So these are the patient strata. 17 There are three biomarkers. One is HER2, 18 another is hormone receptor status, either 19 estrogen or progesterone receptor positive, and 20 the third is the MammaPrint, this is a 70-gene 21 profile that has been approved by the FDA for 22 prognosis and also prediction of response to 23 therapy. 24 And so there are eight slots. This is 25 just to give you a feeling from the previous file:///F|/pg061709%20(2).txt (98 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00099 1 study, I-SPY1, where the patients fell in these 2 slides. 3 DR. C. GOODMAN: Don, about nine 4 minutes. 5 DR. BERRY: Nine minutes, okay. These 6 are path CR by bin, and the thing to notice 7 from this is that there's a good deal of 8 variability. I mean, a 17 percent probability 9 of path CR versus 67 percent probability of CR 10 in this portion of patients. So these are, the 11 experimental agents are going to have to do 12 better than these numbers or whatever the 13 control numbers are in the context of I-SPY2. 14 The interesting thing here for those 15 of you who know these numbers in breast cancer 16 is that the low numbers are the best diseases, 17 so there is kind of a paradox here. The 18 patients who do well, the ER positive patients, 19 HER2 negative patients, don't benefit much from 20 chemotherapy therapy, and that's true not only 21 in the neoadjuvant but also in the adjuvant 22 section. 23 And yet, they have a very low path CR 24 response to therapy -- I'm sorry. And yet, 25 they do very well -- let me start over. They file:///F|/pg061709%20(2).txt (99 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00100 1 do very well in the long term, they live a long 2 time, but they don't respond very much to 3 chemotherapy. On the other hand, HER2 4 positive/ER negative, the worse disease to 5 have, except for treatments coming along to 6 help, but the most chemosensitive, so there's a 7 bit of a paradox. 8 I think I'll -- I have to get through 9 this rapidly. It's conceivable, I mean, if I 10 were to say -- let me back up. If I were to 11 say dear drug company, you have a good drug for 12 HER2 positive/HR positive, MammaPrint too, but 13 nothing else. They say go fly a kite, there's 14 only four percent of patients in that group. 15 So we have to have biomarker profiles that have 16 marketing appeal and we've reduced to like ten 17 of them, and we calculate for those profiles, 18 and you graduate within the profiles. 19 I'm going to skip to CISNET, because 20 CISNET is something CMS may be interested in, 21 this kind of concept. This is population 22 modeling. This is breast cancer mortality in 23 the United States and although we did the 24 analysis up through 2002, it continues to drop. 25 There was a 24 percent reduction between 1990 file:///F|/pg061709%20(2).txt (100 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00101 1 and 2000 and the question is why, and we 2 published a conclusion of our seven models, 3 Effect of Screening and Adjuvant Therapy on 4 Mortality From Breast Cancer in the United 5 States. There were seven population models. 6 We used common endpoints. The CDC, the NCI 7 opened their files and let us have all of the 8 data that they had about things like the use of 9 mammography, who used it when, the use of 10 things like hormonal therapy, the benefits of 11 chemotherapy, et cetera, stage of disease over 12 time. 13 And one of these models was Bayesian, 14 guess which one. This is mammography screening 15 over time, women ages 40 to 79, and you see 16 that in fact it was essentially unused in the 17 early '80s, started to come in in the mid '80s, 18 and up until 2000 when most women had at least 19 some screening mammograms. Adjuvant therapy 20 over time, again increasing at about the same 21 time. So this is a conundrum. We've got 22 screening increasing at about the same time 23 that therapy is increasing, are you going to be 24 able to separate out the two. 25 These were simulations from our model file:///F|/pg061709%20(2).txt (101 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00102 1 and our model was based on fitting, so this was 2 much more complicated than Steve was 3 explaining. The likelihood is based on fitting 4 the actual data. We generate a million women, 5 give them the screening characteristics of the 6 day depending on their age, et cetera, 7 depending on when they had their last 8 mammogram. When they get cancer, we give them 9 the treatment of the day, et cetera. 10 And we of course don't know, from a 11 Bayesian perspective, we don't know any of 12 those things for sure. We don't know what the 13 benefit is of treatment, we don't know even 14 which treatment was given to which patient, but 15 we incorporate that uncertainty based on 16 parameters. We select a parameter value for 17 all of our eight or so parameters and then 18 generate a sample and if it agrees with the 19 mortality that was actually observed, we accept 20 it into our posterior distribution. And so -- 21 and we do this again and again and again, 22 millions of times, and of course we don't get 23 many acceptances, we had in this case 66 24 simulations that were accepted, and that gave 25 us the ability to calculate posterior file:///F|/pg061709%20(2).txt (102 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00103 1 distributions. 2 So here's one. This is tamoxifen, 3 this is efficacy versus effectiveness. So this 4 is from the clinical trials and it's like what 5 Steve said about the child versus the adult. 6 We said maybe going from a clinical trial 7 efficacy to actual clinical use effectiveness, 8 maybe it's not the same, so we'll discount. 9 And the way we discounted it was quite similar 10 to the way he did. We took the posterior 11 distribution from the Oxford overview and 12 inflated it by a factor of three. So this 13 distribution is much more spread, has much more 14 spread than does the actual data. The mean 15 reduction in hazard of mortality or death was 16 28 percent, and this represents the 17 distribution of those 66 observations just 18 looking at tamoxifen. 19 And the interesting thing here, I 20 mean, I expected that the effectiveness would 21 not be as great as efficacy. The interesting 22 thing is that the distribution actually shifted 23 to the right, which, if anything, suggests that 24 tamoxifen in actual use is more effective than 25 in the clinical trials. Of course you will file:///F|/pg061709%20(2).txt (103 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00104 1 notice that the distribution is still very 2 spread out and that reflects the fact that we 3 don't have a great deal of information to draw 4 this conclusion. 5 For example, we don't have individual 6 women followed over time, it's all pieced 7 together. So I'm sure a lot of times -- these 8 are factorial runs to address what would happen 9 if we had all, you know, everybody would get 10 mammograms. This is apportioning the effects 11 of the interventions. Very interestingly, we 12 found no interaction, none of the models found 13 an interaction between screening and therapy. 14 This is our 66 models. Forget those 15 letters for a minute. And what we found was, 16 you know, for some of the models, some of those 17 66, there was very little benefit from 18 screening. This represents the uncertainty 19 associated with the effect of screening in this 20 direction, treatment in this direction, and 21 these other letters are the point estimates for 22 the other six models consistent with our model. 23 Our model was the only one that did this 24 variability. All the other models, because 25 they didn't have the Bayesian approach backing file:///F|/pg061709%20(2).txt (104 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00105 1 them up, couldn't assess uncertainty the way 2 that we did, but their models fit perfectly, 3 and I suppose most anything would fit perfectly 4 with our conclusion, but fit perfectly with the 5 results. 6 So, those are the conclusions, and 7 this was my favorite quote from CNN, 8 statistical blitz helps pin down mammography 9 benefits, and then the New York Times 10 editorial, and I will stop there. Thank you. 11 DR. C. GOODMAN: Thank you very much, 12 Don. Before Don is allowed to depart the 13 podium, are there, is there a question or two 14 that is really important right now? We will 15 have another shot at Don later on today. 16 Anything at this point? 17 Don, I will just ask you one question. 18 You referred earlier to FDAMA and the least 19 burdensome approach invited in that 20 legislation, and I wonder, since 1997, I think 21 it was, has it been borne out that indeed 22 Bayesian approaches have contributed to least 23 burdensome or maybe even lesser burdensome 24 approaches, has that held up, and that might be 25 good for us to know with regard to how it might file:///F|/pg061709%20(2).txt (105 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00106 1 help CMS. 2 DR. BERRY: So, it has. I wouldn't 3 say least burdensome, but certainly lesser 4 burdensome. So, we build designs for many of 5 these companies. There was for example, and it 6 relates to a catheter, a Biosense Webster panel 7 meeting, a cardiology panel meeting in November 8 where they had approached us. We built a 9 design for them based on their slow accrual 10 that would use this prediction, and the 11 original study was hardwired at 250. They went 12 to the FDA and got approval for their catheter 13 to prevent a-fib, and with 150 patients and 14 many of them having reached the nine-month 15 point based on prediction and based on the 16 early results. 17 In 2007, the number two medical 18 breakthrough according to Time magazine, not 19 that that's your -- you know -- was a sentinel 20 node biopsy, genetic assessment of lymph nodes 21 that we had built that, the Bayesian design 22 stopped as soon as it was allowed to stop, and 23 all of the hype is about the genetics, but the 24 hype wouldn't have been in 2007, it would have 25 been at a later time without the Bayesian file:///F|/pg061709%20(2).txt (106 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00107 1 design. So I think it definitely has shown 2 lesser burdensome. 3 DR. C. GOODMAN: Good, thank you. 4 With that, thank you very much, Dr. Berry, very 5 helpful. 6 We are scheduled to take a 15-minute 7 break, we're a little bit behind, and I would 8 ask that we take, let's call it a ten-minute 9 break, which is about as much time as it takes 10 to get down the hall and come back. And 11 Dr. Lewis is up next, speaking in ten minutes, 12 and that would put us close to putting us back 13 on time. Thank you very much. 14 (Recess.) 15 DR. C. GOODMAN: Let's reconvene, 16 thank you for being prompt, and Dr. Lewis, the 17 podium is yours, sir. 18 DR. LEWIS: Great, thank you very 19 much. It's a pleasure to be here today. I'm 20 speaking on behalf of the Department of 21 Emergency Medicine at Harbor UCLA Medical 22 Center, the David Geffen School of Medicine at 23 UCLA, and the Los Angeles Biomedical Research 24 Institute. In addition to my formal employers, 25 I have a number of financial disclosures. I file:///F|/pg061709%20(2).txt (107 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00108 1 work as a paid consultant to Berry Consultants 2 and as Don already mentioned, the focus of 3 Berry Consultants is Bayesian clinical trial 4 design and analysis, and I'm also involved as a 5 consultant for adaptive clinical trials for a 6 number of sponsors. 7 I'm going to talk a little bit about 8 Bayesian thinking in clinical care since that 9 was the title of the topic that was given to 10 me. I'm going to try to clarify some questions 11 regarding the components of the decision 12 process since one of the key challenges facing 13 CMS is making explicit decisions regarding 14 coverage. I'll talk about utility functions 15 and how they affect decisions or at least ought 16 to affect decisions. And then I'm going to 17 spend some time in a description of 18 hierarchical models and how those can be used 19 to integrate potentially heterogeneous 20 information from multiple sources in a way that 21 better informs the decisions that might be 22 made. And then finally, a few closing 23 thoughts. 24 In terms of examples of Bayesian 25 thinking in clinical care, the examples are file:///F|/pg061709%20(2).txt (108 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00109 1 relatively sparse and most of them are quite 2 non-quantitative. For example, in making the 3 diagnosis of deep venous thrombosis, there are 4 a number of clinical studies. I just grabbed 5 one that was published back in 1997, this is 6 not the one that's most commonly in current 7 use, but under this system a number of risk 8 factors for this disease and physical findings 9 that are associated with the disease are given 10 a point value. The points are added up and 11 then based on the final score the patient is 12 assigned a probability of having this disease 13 that is qualitatively described as low 14 probability, moderate probability or high 15 probability. 16 Now in principle, this probability 17 assessment could be used as a posterior 18 probability if one was going to stop anyone's 19 medical evaluation of the patient at that 20 point, but in fact more commonly this 21 probability assessment system is used to create 22 a pretest probability or a prior that guides 23 both the selection of future diagnostic tests 24 or subsequent diagnostic tests and the 25 interpretation of those tests. file:///F|/pg061709%20(2).txt (109 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00110 1 Similarly, for the diagnosis of 2 pulmonary embolism, which is closely related to 3 venous thrombotic disease, there are standard 4 clinical scoring systems that are used to 5 estimate the pretest or prior probability, and 6 that pretest probability is used to guide the 7 selection of tests. For example, a patient 8 with a lower pretest probability of a serum 9 D-dimer test may be felt to be adequate to 10 exclude the diagnosis if the test is negative. 11 But with a moderate or higher pretest 12 probability, one needs to test with a higher 13 negative predictive value or negative 14 likelihood ratio. 15 For example, a CT of the chest if 16 appropriately interpreted, in order to reduce 17 the upper limit of the probability interval for 18 the true probability of disease below some 19 level that is deemed clinically acceptable, 20 meaning there is some ill defined and often 21 unspoken upper limit to the final post-test 22 probability of disease that we believe is low 23 enough, so that we feel comfortable in stating 24 that we have clinically excluded the disease. 25 The selection of that upper limit of the file:///F|/pg061709%20(2).txt (110 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00111 1 probability of disease is really based on 2 qualitative considerations that are usually 3 never defined and certainly aren't based on an 4 explicit cost benefit or other decision 5 analysis. 6 In terms of moving from these 7 qualitative assessments of probability in 8 clinical practice, which as I said are actually 9 quite limited, there has been a desire to at 10 least pretend that we use qualitative 11 assessments of probability in clinical 12 decision-making. Back in 1975, Fagan published 13 a nomogram which essentially is a graphical 14 method for doing a Bayesian calculation, in 15 which the pretest odds of the disease are 16 expressed on one axis, the likelihood ratio 17 which is related to the Bayes factor is 18 represented on another vertical axis, and you 19 can use this to graphically determine the 20 post-test probability. 21 So for example if one started with a 22 pretest probability of 30 percent and the 23 likelihood ratio for a negative test result was 24 .2, then your post-test probability would be 25 something around seven percent. You could have file:///F|/pg061709%20(2).txt (111 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00112 1 a situation in which the pretest probability 2 was lower, say five percent, and with the same 3 test results your post-test probability would 4 be about one percent. 5 Every time I hear a lecture on 6 evidence-based medicine, someone will bring up 7 this slide, I stole this from someone, and I in 8 fact have never seen this ever used in clinical 9 practice, and I still practice about 15 hours a 10 week clinically in the emergency department. 11 There are a number of reasons for this. One is 12 the fact that defining pretest odds for an 13 individual patient is phenomenally difficult 14 and in fact, physicians have widely varying 15 opinions for a single patient. But moreover, 16 and I believe this is a key point that is 17 poorly appreciated, and I've actually seen 18 written, is the fact that most clinical 19 diagnostic strategies involve the sequential 20 application of tests whose results are likely 21 to be correlated. 22 And so even though you may hear that 23 the Bayesian approach allows sequential 24 application of Bayes factors to update 25 posterior probabilities, doing so requires an file:///F|/pg061709%20(2).txt (112 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00113 1 understanding of the correlation between those 2 test results which virtually never exist in 3 clinical practice. 4 Moving now from the question of 5 estimating probability of diseases or 6 probabilities of a treatment effect to the 7 question of making decisions, how do you make a 8 decision if you have a posterior probability 9 distribution for the treatment effect? Well, 10 the components of a decision problem are 11 fourfold. The first is some sort of prior 12 belief or prior information regarding the 13 patient's disease state in the case of a 14 diagnostic test or a treatment effect, and 15 usually one also has some data or a test result 16 to use to update that prior information to 17 yield the posterior information, as has been 18 well described. 19 But in addition, a decision problem is 20 characterized by a set of possible actions that 21 one might take based on that information and 22 the goal is to make the best decision, for 23 example in selecting and initiating the 24 treatment for an individual patient, observing 25 a patient without treatment, or ordering an file:///F|/pg061709%20(2).txt (113 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00114 1 additional diagnostic test. All three of those 2 possible actions commonly exist in clinical 3 practice. 4 The utility function, which is a key 5 and necessary component to the decision 6 problem, represents the value of taking a 7 particular action when the parameter of 8 interest, such as the presence or absence of 9 the disease state, has a specific value. As 10 mentioned initially in Dr. Goodman's 11 presentation, we often don't know whether the 12 patient has a specific disease, we know there's 13 signs and symptoms, and hope to be able to have 14 some probability estimates that they have a 15 particular disease. I'm going to try to make 16 this more concrete in a second. 17 The key concept in decision-making is 18 that we select the action or the treatment that 19 maximizes the expected utility, given our 20 current probability or current information for 21 the parameter of interest, for example, the 22 true treatment effect. In this case, expected 23 means averaged over our uncertainty in the true 24 treatment effect or our uncertainty in the 25 presence of a disease. And it is this use of file:///F|/pg061709%20(2).txt (114 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00115 1 the expected utility that characterizes the 2 decision theoretic approach. 3 So as I mentioned, utility function is 4 the value or utility of selecting a particular 5 action, for example, a treatment or a 6 diagnostic strategy, given a particular 7 parameter value where one doesn't know that 8 parameter value -- I'm sorry -- where that 9 parameter value is assumed to be known although 10 in fact that is rarely the case. The utility 11 effect function should contain or should 12 capture multiple dimensions of the benefit or 13 harm to the patient associated with the 14 diagnostic or therapeutic strategy given their 15 true disease state. 16 There may be positive contributions, 17 such as improvements in patient outcome both 18 short and long term. There may be indirect 19 benefits to the community or society through 20 treatment of that patient, for example, through 21 vaccination. There may be negative 22 contributions, for example, financial costs, 23 side effects, complications or other associated 24 morbidity. Patient opportunity costs, the 25 patient may require time off work in order to file:///F|/pg061709%20(2).txt (115 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00116 1 undergo a specific diagnostic approach or 2 treatment. And there are provider opportunity 3 costs, some treatments are very time consuming 4 and labor intensive on the part of the 5 provider, for example surgical approaches 6 versus medical approaches. 7 For a utility function to make sense, 8 all of these different contributions must be 9 able to be expressed on a common scale. Now 10 that is a key challenge to the use of utility 11 functions, but it forces the different 12 stakeholders to communicate in a common 13 language regarding the values of their positive 14 and negative contributions, and that's the kind 15 of discussion that clarifies the values that 16 are being brought to the table in making a 17 decision and adds to the transparency of any 18 decision that might be made, and that is a key 19 point. 20 So for example, here I've illustrated 21 a simple utility function and I just want to go 22 through this. For example, the patient either 23 does or does not have an epidural hematoma. An 24 epidural hematoma is a virtual universally 25 fatal bleeding of the arterial blood supply file:///F|/pg061709%20(2).txt (116 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00117 1 around the brain. For example, this is the 2 disease that caused the death of Natasha 3 Richardson, and it may be present or absent 4 with the true disease state for the patient. 5 We have a decision to make. The 6 decision is either to obtain emergency computed 7 tomography of the head, a diagnostic approach 8 that was not available for Ms. Richardson, or 9 we may not obtain that test and therefore fail 10 to make the diagnosis and institute appropriate 11 and rapid surgical intervention. So for 12 example, if the disease state is that the 13 epidural hematoma is absent, then the utility 14 associated with obtaining a CT is a negative 15 number because there's some cost, in this case 16 it's largely financial cost, opportunity cost 17 and cost associated with the radiation exposure 18 to the patient and the incremental increase in 19 long-term cancer associated with that test. If 20 the epidural hematoma is absent and we do not 21 obtain the CT scan, the utility is zero because 22 we have incurred none of those costs. If, 23 however, the epidural hematoma -- I'm sorry -- 24 so if it's absent, clearly the best action to 25 select is to not obtain the CT scan, because file:///F|/pg061709%20(2).txt (117 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00118 1 that maximizes the utility under the assumption 2 that the epidural hematoma is absent. 3 In the alternative case where the 4 hematoma is present, getting the CT scan is 5 associated with a utility of minus 2500, and 6 I'm just making up these numbers, because in 7 addition to the cost of getting the CT scan and 8 those other costs associated with just the 9 test, in fact the patient is going to suffer 10 some additional morbidity and potential 11 mortality associated with the treatment of the 12 disease. So under this setting there is lots 13 and lots of costs associated with the 14 treatment. 15 However, if one does not obtain the CT 16 scan and misses the diagnosis, the patient will 17 virtually uniformly die or suffer permanent 18 neurologic sequelae and that's associated with 19 a very large negative utility. Under that 20 setting the optimal action is to obtain the CT 21 scan and to minimize the preventable morbidity 22 and mortality to the patient. That's pretty 23 straightforward. 24 But in real life we don't know until 25 the diagnostic test is performed whether the file:///F|/pg061709%20(2).txt (118 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00119 1 epidural hematoma is present or absent, so we 2 must consider the expected utilities averaged 3 over our uncertainty in the diagnosis. So 4 let's pretend based on the patient's mechanism 5 of injury and additional presentation that our 6 probability of disease is 10 percent. So in 7 this setting before the scan is obtained, the 8 prior probability of epidural hematoma is 10 9 percent, there's a 90 percent probability that 10 the patient does not have this particular 11 injury. In that setting to calculate the 12 expected utility, one averages the actual 13 utilities associated with the action and the 14 disease over the actual probabilities that 15 you're in either of these columns based on the 16 presence or absence of disease. 17 So for example, if you have a 10 18 percent chance of incurring this utility if you 19 get a CT scan, that's a negative 2500, 90 20 percent of that is minus 450, you add them 21 together and your expected utility is this 22 number. If you do not obtain the CT scan you 23 have a 10 percent chance of incurring this 24 utility which would give you minus 25,000, 90 25 percent chance of zero, and this is your file:///F|/pg061709%20(2).txt (119 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00120 1 expected utility. 2 In selecting the optimal action in 3 this setting, clearly one would select the 4 action that has the highest expected utility or 5 at least negative expected utility, and so you 6 would obtain a CT scan in the case in which 7 there is a 10 percent pretest probability, 8 prediagnostic probability of the epidural 9 hematoma. The point here is that the utility 10 function clarifies exactly what it is that 11 we're weighing in terms of the opportunity 12 costs, the financial costs, and one can explore 13 the ranges of pretest probability over which 14 the best expected utility is obtained by 15 ordering the CT scan. 16 So again, the key concept is that we 17 select the action that maximizes the expected 18 utility given the current probability 19 distribution for the parameter of interest. In 20 the case I just gave where the uncertainty was 21 simply a 10 percent versus a 90 percent 22 probability of an epidural hematoma, but in the 23 cases of considering treatment effect estimates 24 for real clinical trials, what we usually have 25 is a point estimate for that treatment effect. file:///F|/pg061709%20(2).txt (120 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00121 1 So as Don has pointed out, we should really be 2 thinking about these point estimates in terms 3 of the total uncertainty in the true treatment 4 effect, uncertainty of those data, and that was 5 the principle that led to the routine 6 overestimation of power in a subsequent 7 clinical trial. 8 This is a slide that I will not cut 9 out because I always like it. In this case it 10 makes certain assumptions about the expected 11 utility associated with being assigned to the 12 placebo group. It reflects patients' continued 13 belief that it's always better to be in the 14 experimental arm, but that is not borne out by 15 the published literature. 16 Now I would like to move from the 17 theoretical issue of decision-making into the 18 consideration of heterogeneity of evidence, and 19 this is going to touch on the challenges of 20 integrating evidence from multiple clinical 21 trials that may be, for example, performed in 22 slightly different patient groups, from 23 different patients in terms of subclasses or 24 severity of disease, or even combining evidence 25 regarding similar but related treatments in the file:///F|/pg061709%20(2).txt (121 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00122 1 same patient population. In all of these 2 cases, patients with the same disease may be 3 heterogeneous. There may be different 4 comorbidities, for example, presence or absence 5 of diabetes, hypertension, previous surgery, in 6 terms of severity of disease or the disease 7 subtypes. Sometimes those differences in 8 disease subtypes are known at the time of 9 clinical decision-making, sometimes they can 10 only be determined later in genetic analysis. 11 In addition, different treatments for 12 a single disease may have characteristics in 13 common. For example, there are classes of 14 pharmaceutical agents that based on mechanism 15 of action should be likely to work to similar 16 extents in similar patients. For medical 17 devices, for example, Fleming has a new medical 18 device that is in terms of mechanism of action 19 largely equivalent to current devices. 20 In each of those cases it is naive to 21 believe that we know nothing about the 22 effectiveness of the treatment in one patient 23 population or in one subclass of patients when 24 we know quite a lot about the effectiveness in 25 those others, and yet traditional statistical file:///F|/pg061709%20(2).txt (122 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00123 1 methods are extremely poor in combining that 2 information in a way that is rigorous, 3 verifiable and transparent. 4 Some other clinicians borrow 5 information; we do this informally, secretly 6 and we never tell you about that, so we borrow 7 information all the time. For example, if we 8 see a patient who's different than the patients 9 that were enrolled in a clinical trial but have 10 some of the same characteristics, we routinely 11 extend the apparent indications based on that 12 clinical trial over to this new patient for a 13 new patient population. 14 We do that with treatment types. For 15 example, if we have one antihypertensive that 16 has been demonstrated to have benefit, we 17 assume that the new hypertensive will have a 18 similar benefit in the absence of any separate 19 evidence. We also do this in a way that is not 20 documented and is not quantitative. 21 Off label use is another example of 22 this. Some off label use is bad, some of it 23 makes perfect sense, and the challenge is being 24 able to tell the difference between the two. 25 However, traditional statistical methods, file:///F|/pg061709%20(2).txt (123 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00124 1 frequentist statistical methods often but not 2 always take an all or none approach to 3 borrowing information across heterogeneous 4 patient populations, disease categories or 5 treatments. 6 In the case in which one takes an all 7 approach in which information is just grouped 8 from all patient populations together, think of 9 a fixed, like a meta-analysis. This approach 10 will fail to recognize subgroups that 11 experience different treatment effects or 12 complications. If one takes the no approach in 13 which you don't allow any pooling of 14 information from heterogeneous subgroups, you 15 will fail to recognize situations in which 16 there is compelling circumstantial evidence of 17 treatment efficacy in one group, for example a 18 group in which there is virtually no 19 independent data and yet there's lots of data 20 from those related groups that suggests 21 efficacy. 22 We also may lead to overestimation in 23 heterogeneity of treatment effect when we take 24 the none approach, so the common approach in 25 clinical trials in which we separate out the file:///F|/pg061709%20(2).txt (124 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00125 1 treatment effect in each of the clinically 2 important and a priori defined subgroups may 3 overestimate the spread of the treatment effect 4 in those subgroups, and I'll give an example of 5 that in a second. 6 So the point that I want to make about 7 this before I get down to a picture of the 8 specifics is that the use of hierarchical 9 modeling and where this can be done in a 10 frequentist way, it is much better done using 11 the Bayesian approach and is much more 12 transparent and understandable with the 13 Bayesian approach. This provides a flexible 14 method for sharing information from potentially 15 heterogeneous groups to a degree that is 16 justified by the consistency of information 17 across the groups and by the limitations and 18 the amount of information available from each 19 group. So this allows you to share information 20 when it's appropriate without sharing 21 information when it is not appropriate. And 22 this can allow us to integrate information 23 across clinical trials, patient groups, disease 24 categories and treatments, and this is a key 25 technique that can be used for CMS to improve file:///F|/pg061709%20(2).txt (125 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00126 1 the transparency and rigor of their coverage 2 decisions. 3 So let's look at the structure of our 4 hierarchical model. In this case I'm starting 5 the first level of my hierarchy with results 6 from three trials labeled trial A, B and C, and 7 in each case the trials have resulted in a 8 single point estimate for the clinical 9 treatment effect. Trial A appears to show some 10 harm, trial B shows an exactly null result, and 11 trial C, the point estimate falls to the right, 12 demonstrating some efficacy of the treatment. 13 So clearly looking at these trial results 14 they're qualitatively different, and the 15 question is how can we integrate this 16 information to determine whether this really 17 suggests there's a heterogeneity of treatment 18 effect or does this demonstrate that each of 19 the trials was too small to be convincing. In 20 each case we need to think of the actual 21 distribution of efficacies that are consistent 22 with the trial results. 23 In the second hierarchical model we 24 consider a hyperdistribution, which is the 25 distribution of the treatment effects within file:///F|/pg061709%20(2).txt (126 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00127 1 models. Strictly speaking we are not assuming 2 that the patients within the trials are 3 exchangeable, we don't assume that a patient 4 enrolled in trial A would have met the strict 5 inclusion criteria for the patients in trial B, 6 but we are assuming that the trial results are 7 roughly measuring the same type of treatment 8 effect. 9 This hyperdistribution, there has to 10 be some prior information about that. We have 11 two priors at the third level of the hierarchy, 12 one measures the overall average treatment 13 effect or the center of this distribution and 14 one measures the variability, the width of 15 this. So we have some prior information about 16 how different we expect the average, I'm sorry, 17 the treatment effects of the different trials 18 to be, and it is going to be information about 19 this hyperdistribution that tells us things 20 both about the average effect of the treatment 21 and about the heterogeneity of the effect 22 across trials. 23 So the information from each of the 24 three trials informs the information about the 25 hyper distribution and what we end up with is, file:///F|/pg061709%20(2).txt (127 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00128 1 for each of the three trials, a new estimate of 2 the treatment effect that takes into account 3 not only the information from each of the 4 trials and the strength of the evidence from 5 each of these three trials, but also our 6 beliefs regarding how similar the treatment 7 effect ought to have been among the three 8 trials. 9 And there's two key results here, and 10 it's important to understand their difference. 11 One is you get an estimate for the overall 12 average treatment effect of this treatment in 13 these three trials. Perhaps more importantly, 14 you obtain three separate estimates which are 15 better estimates of the true treatment effect 16 within each of the trials than you would have 17 obtained had you considered each of these three 18 trials separately, and that is a very deep and 19 important truth. It means that if these were 20 different patient populations, this estimate is 21 a better estimate for the true treatment effect 22 in this population than the estimate that you 23 got from that trial in isolation, and I would 24 love to take questions about that at the end. 25 This is an example of the James Stein file:///F|/pg061709%20(2).txt (128 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00129 1 effect, and the James Stein effect works well 2 in different trials, a lot of different trials, 3 a lot of subgroups in trials, and it says that 4 if the treatment works equally well in all 5 subgroups, just naturally with statistical 6 variation, there will be some variability in 7 the treatment effect we observe in a clinical 8 trial. So even if the treatment works exactly 9 the same, there's going to be some spread in 10 the data. And yet ironically when we look at 11 clinical trial data and we look at the 12 treatment effect observed in different 13 subgroups, we take those numbers at face value 14 without ever accounting for that excess spread 15 which we know to occur. The James Stein 16 estimator, which is not a Bayesian concept but 17 can be addressed using Bayesian approaches, 18 uses that effect to get better estimates of the 19 treatment effect within subgroups. 20 So the James Stein principle says that 21 the best estimate of the true treatment effect 22 in a subgroup of patients within a clinical 23 trial is not the treatment effect observed in 24 that subgroup if there are three or more 25 subgroups. And this is a statement that unless file:///F|/pg061709%20(2).txt (129 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00130 1 you thought about it for a long time, it ought 2 to bother you. If this does not bother you, 3 then I'm not explaining it well. 4 So here's an example of this. This is 5 a clinical trial performed at my institution 6 and it is a comparison of bag valve mask 7 ventilation or using a mask and resuscitation 8 bag versus endotracheal tube into the trachea. 9 In the out of hospital, so this is a paramedic 10 setting for critically ill or injured children, 11 this was conducted in Los Angeles and Orange 12 County, it was sponsored by what was then AHCPR 13 and a number of other federal agencies. It was 14 a relatively large study, especially for 15 treating critically ill and injured children in 16 the prehospital study, there were 830 children. 17 It was published in JAMA in about 2000. 18 So we compared endotracheal intubation 19 to bag valve mask ventilation and the primary 20 outcome was survival to hospital discharge 21 among these critically ill and injured 22 children. The overall results if you just 23 pooled all of the different subgroups of 24 patients in terms of their indication for 25 supplying airway intervention was that there file:///F|/pg061709%20(2).txt (130 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00131 1 was no improvement in survival to hospital 2 discharge. 3 However, a number of clinicians felt 4 very strongly that different subgroups of 5 patients, for example children suffering from 6 poor respiratory arrest or from near drowning, 7 would be more likely to benefit from an airway 8 intervention since the cause of their severe 9 illness was primarily respiratory in nature. 10 So for example, this would distinguish them 11 from patients who suffered multiple trauma in 12 which the initial insult was not primarily 13 respiratory in nature. 14 And this is what we actually got from 15 the trial. So on this axis I have the 16 estimated odds ratio, so these are just point 17 estimates, and I have not included the 18 uncertainty which is quite broad for a number 19 of subgroups of patients which were defined 20 a priori in the protocol, so patients with 21 multiple trauma, traumatic brain injury, near 22 drowning, cardiopulmonary arrest, SIDS, 23 physical abuse, respiratory arrest. And so 24 these numbers are based on the typical 25 calculation of the odds ratio based on patients file:///F|/pg061709%20(2).txt (131 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00132 1 only within each of the individual subgroups. 2 These data are slightly different from 3 the published data because the published data 4 allowed the patients to be members of multiple 5 subgroups and I couldn't do this, otherwise I'd 6 be double counting patients. If I instead use 7 a hierarchical Bayesian model, and for the 8 purists here I just used an empirical Bayes 9 approach just to make the point, I obtain new 10 estimates for the true treatment effect in each 11 of the subgroups that are much more tightly 12 clustered around the average treatment effect, 13 because this corrects for the James Stein 14 effect and gives me new improved estimates. 15 The irony here, and this should be 16 disturbing to anybody who looks at subgroups in 17 clinical trials, is that these are the numbers 18 that we report for the estimated treatment 19 effect, this is what's in the JAMA publication, 20 and these are in fact the best estimates. So 21 patients in whom it appeared there was evidence 22 of harm or benefit, in fact if you revise the 23 estimates to take into account this effect, 24 will show that there's essentially no estimates 25 of any benefit of this therapy in the file:///F|/pg061709%20(2).txt (132 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00133 1 prehospital setting and there's some residual 2 benefit of harm with weak evidence in one 3 group. 4 So that just shows how for a published 5 clinical trial, how the use of a hierarchical 6 model can qualitatively change the conclusions 7 you would draw regarding the likely treatment 8 effect in clinically important subgroups. But 9 this use of hierarchical models can be used not 10 just in the setting of subgroups, it can be 11 used to integrate information either across 12 clinical trials, that was the first set of 13 graphs I showed, patient groups, that was the 14 subgroups, or even these categories or 15 treatments, which should be a key interest in 16 informing coverage decisions for CMS. 17 So you can take my original graph in 18 which I had three trials, and you can simply 19 relabel this as subgroup A, subgroup B and 20 subgroup C, that would be similar to the 21 results I showed for the pediatric airway 22 trial, or you can relabel it as diseases. 23 So for example, if you want the best 24 estimate of the effect of a single treatment in 25 several different disease types that are file:///F|/pg061709%20(2).txt (133 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00134 1 thought to share some common mechanisms of 2 disease and therefore the mode of action for 3 the treatment, these estimates are actually 4 better estimates of the treatment effect in the 5 separate disease states than the separate 6 trials that you had access to. So these should 7 inform the coverage decisions rather than just 8 these in isolation. 9 Once more, you can picture a situation 10 where you initially had access to these two 11 trials, you made a coverage decision or you 12 made an assessment of the analysis, a new trial 13 comes along. This allows you a seamless and 14 transparent way to integrate that heterogeneous 15 information, again, only to the extent that it 16 is justified by the consistency of the data to 17 make an updated and a more informed decision. 18 So, my point here is that one can use 19 Bayesian models and hierarchical modeling 20 specifically to integrate information from a 21 number of sources in a way that is explicit and 22 transparent, and continuously updatable, to aid 23 decision-makers. But even that, the 24 decision-making, the availability of well 25 informed and transparent posterior probability file:///F|/pg061709%20(2).txt (134 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00135 1 distributions doesn't make the decision for 2 you, it is the use of those probability 3 distributions to calculate the expected 4 utilities that allows you to make an informed 5 and defensible decision. 6 So the use of explicit expected 7 utilities where expected means averaged over 8 our true uncertainty using all available 9 information will allow the evaluation of 10 implications of different utility functions. 11 So for example, if you make a decision 12 regarding the use of a particular therapy and a 13 new treatment becomes available so that the 14 patients that don't receive the first therapy 15 now have a secondary treatment that changes 16 their expected outcome. 17 Think of the epidural hematoma case 18 for a second. The don't CT approach made the 19 assumption that without a CT the patient would 20 have the diagnosis remain undetected, 21 untreated, and the natural course of the 22 disease would ensue. If there was a secondary 23 diagnostic approach that became available, then 24 one could have that influence the expected 25 outcome for the patient who forgoes the CT file:///F|/pg061709%20(2).txt (135 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00136 1 initially. So even with no new data on the 2 diagnostic accuracy of the first test, an 3 updating to the utility function could yield a 4 new and appropriate decision in light of new 5 information about alternative diagnostic 6 approaches and therapies. 7 The use of this approach to 8 decision-making allows the straightforward and 9 transparent incorporation of new data, so that 10 allows one to have a model of continuous 11 learning, which is something that is very 12 appealing if you don't want to redo all of your 13 analyses every time new evidence emerges 14 regarding each treatment. And it also allows 15 the appropriate incorporation of all available 16 information, for example via the hierarchical 17 modeling. 18 And in the last few minutes, what I 19 would like to do is draw a parallel between the 20 approach of adaptive clinical trials and an 21 adaptive and continuously learning approach to 22 clinical decision-making or the adoption of 23 clinical practice. So in adaptive clinical 24 trials we use the accumulating data to help us 25 guide the actual conduct of the clinical trial. file:///F|/pg061709%20(2).txt (136 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00137 1 In a sense we're using the data as a compass on 2 how the trial ought to be conducted. 3 So almost everybody who talks about 4 adaptive clinical trials has a slide like this. 5 We begin with our data collection, we analyze 6 the data. If we don't need a predetermined 7 stopping rule we may revise our allocation 8 sampling rule, enroll more patients and then 9 analyze the data. And we keep growing in this 10 process until we meet our stopping rule, when 11 we are sufficiently sure that we have reached a 12 conclusion or if the trial is futile to 13 continue. And then once we meet the stopping 14 rule, we take our next step in the development 15 of the drug or device. 16 In the clinical adoption process the 17 way I would like to see it, we would consider 18 the outcomes supporting a diagnostic or 19 therapeutic approach, we analyze the available 20 data. We ask ourselves, is there sufficient 21 evidence to establish a standard of care. If 22 there is evidence, we can consider that a 23 standard of care is possible to perform this 24 measure. If there is not sufficient evidence, 25 we gather additional evidence or wait for file:///F|/pg061709%20(2).txt (137 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00138 1 additional evidence to become available. That 2 evidence is subjected to the appropriate peer 3 review and publication processes and when the 4 new information is available, we can analyze 5 that. So this is a completely analogous 6 circular process of continual learning that 7 helps us guide our coverage decisions in a way 8 that is verifiable externally and transparent. 9 In terms of the things that I've 10 talked about up to this point, for example the 11 hierarchical model in the use of decision 12 functions, decision utility function, excuse 13 me, the process of analyzing available data in 14 my opinion should very frequently make use of 15 updatable hierarchical models, so we use all 16 the available information but only make pooling 17 decisions or sharing decisions from information 18 to the degree that is justified by the 19 consistency and quality of the data. 20 And then the process of deciding 21 whether the evidence is sufficient to establish 22 a standard of care really ought to be based on 23 a formal decision analysis in which the 24 utilities are there out in the open for 25 everybody to see and so that they can be file:///F|/pg061709%20(2).txt (138 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00139 1 updated when additional treatment or diagnostic 2 options become available for the patients. 3 So just a couple of closing thoughts, 4 and I promised I would end a few minutes early. 5 The first is that although I was given the 6 topic of Bayesian thinking in clinical 7 decision-making, that's in fact a very rare 8 thing and except in a few settings, the use of 9 Bayesian reasoning in clinical practice is 10 qualitative and inexact at best. The utilities 11 that drive clinical decision-making are usually 12 ill defined, qualitative, and if one actually 13 looks at it, physician behavior doesn't even 14 reflect their own stated utilities. So there's 15 a lack of coherence in clinical decision-making 16 that is a fact of life in our current system. 17 In terms of coverage decisions, 18 however, poor decisions may be made when 19 knowledge and uncertainty in that knowledge is 20 not appropriately quantified. And the most 21 common of this that I think we should talk 22 about is failure to integrate information from 23 multiple sources in a way that is flexible and 24 justified according to the consistency of that 25 information, and also making decisions based on file:///F|/pg061709%20(2).txt (139 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00140 1 utilities that have never been discussed 2 openly, in which the multiple components of the 3 utility function are never placed on a common 4 scale and that are not public and therefore 5 open to public scrutiny. 6 And the last point, which I didn't put 7 on the slide, has to do with keeping track of 8 the quality of the information that we're using 9 to update our posterior probabilities. Since I 10 have a minute here, I am struck by the use as a 11 quality measure, although no longer, of blood 12 cultures as a quality measure for treatment of 13 patients with community-acquired pneumonia 14 based on the use of observational data long 15 after it was apparent to everybody that the 16 results of the blood culture never influenced 17 the actual care provided to those patients. 18 The association between blood culture, the 19 obtaining of the blood culture and outcome of 20 those patients was an artifact of an 21 observational study design. The data never 22 justified drawing the conclusion, and this begs 23 the question, can we get back to the point 24 where the right people are discussing the right 25 questions. file:///F|/pg061709%20(2).txt (140 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00141 1 And I'll stop there. Thank you very 2 much. 3 DR. C. GOODMAN: Thank you very much, 4 Dr. Lewis. Dr. Lewis, if you would just remain 5 at the podium for a moment or two. Yes, Mark, 6 a question for Dr. Lewis? 7 DR. HLATKY: I just want to clarify 8 this term hierarchical model, because it meant 9 something different to me coming into this 10 meeting than I'm hearing today, and I don't 11 know if I'm confused or if maybe other people 12 are confused too. My sense of it was that, you 13 know, this was a way of analyzing data when you 14 had like patients who were nested within 15 doctors who were nested within hospitals or 16 other kind of care institutions, and you needed 17 to take account of this hierarchy of where 18 people were. And the sense that I got from 19 your description is totally different. Is this 20 the same term applied to two different things 21 or is this actually the same thing or what? 22 DR. LEWIS: Well, first, I'm happy to 23 be asked a question that I can answer with, 24 we're both right. So hierarchical models are a 25 way of dealing with clustering of multiple file:///F|/pg061709%20(2).txt (141 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00142 1 different types. As you correctly stated, the 2 clustering may be of patients within 3 physicians, physicians within health care 4 organizations, health care organizations within 5 funding types. 6 What I was focusing on here was a 7 situation in which the clustering was 8 clustering of patients within clinical trials 9 and then clinical trials were clustered within 10 another hierarchy. So the general approach 11 hierarchical modeling is a way of dealing with 12 data that has a hierarchical structure in terms 13 of the correlations and as I said, there can be 14 multiple correlations. 15 So the answer is no, this is not 16 completely different, it is exactly the same. 17 It just has to do with what the different 18 levels of the hierarchy represent. 19 DR. C. GOODMAN: Thank you. 20 Dr. Prager, and then we'll come back. 21 DR. PRAGER: I think it's well 22 documented that physicians are highly risk 23 averse, so that if you plug this into your 24 utility function you're either going to come 25 out with heavy values on the outcome or you file:///F|/pg061709%20(2).txt (142 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00143 1 will be altering the prior probabilities in the 2 physician's head when making decisions. And 3 I'm wondering, which of the two do you think 4 that is, and a probably more important question 5 related to what we're doing here today is how 6 would any of this, including physician's risk 7 aversions plugged into this model, have any 8 applicability to the question we're asking 9 today about the use of Bayesian thinking in 10 CMS's whole structure? 11 DR. LEWIS: I have several different 12 thoughts on that and I will try to keep it 13 brief. The first has to do with the statement 14 that physicians are highly risk averse. The 15 degree to which many physicians are risk averse 16 is based on a nonquantitative understanding of 17 the different components of their utility 18 function. So I tried to make the point that 19 the utility function includes not just the cost 20 of the treatment of the illness, or for example 21 the likely negative utility associated with 22 missing a diagnosis and losing a subsequent 23 malpractice case. I happened to use a dollar 24 amount if we missed epidural at the current cap 25 on pain and suffering in California to try to file:///F|/pg061709%20(2).txt (143 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00144 1 capture that, but we don't keep track of many 2 of these other costs, the utility costs when a 3 patient has to miss work and those sorts of 4 things. 5 So I think the first point is that for 6 diseases that are well characterized in terms 7 of the likely outcomes of making or missing a 8 diagnosis, just the explicit conclusion of all 9 of these different factors in the utility 10 function helps clarify the factors that we 11 ought to be balancing. I think that to the 12 extent that coverage decisions are made based 13 on utility functions, one can explore the range 14 of pretest probabilities, or I'm sorry, of 15 current probabilities of disease over which the 16 optimal action remains unchanged. 17 So in my simple example I pointed out 18 that with a pretest probability of .1, 10 19 percent, the optimal action was to do the 20 computed CT scan of the head. One can look at 21 how low the pretest probability of that disease 22 has to be before that's no longer the optimal 23 action, and that gives us a defensible way of 24 defining the upper limit for the posterior 25 probability of the disease, below which we file:///F|/pg061709%20(2).txt (144 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00145 1 don't have to undergo that particular 2 diagnostic approach. So that allows a 3 transparency and a defensibility to those 4 limits that we currently lack. 5 When I asked my residents in training, 6 how low does the probability of a pulmonary 7 embolism have to be to not work it up, I get a 8 number of answers that aren't based on anything 9 other than what sounds like a small number to 10 them. And I think that the utility functions 11 that are developed in a publicly verifiable 12 setting will give some credence to setting 13 thresholds that are rational and that will 14 yield a better allocation of our scarce 15 resources to the diagnosis and treatment of 16 patients. 17 DR. C. GOODMAN: Thank you. Dr. 18 Dullum. 19 DR. DULLUM: I think you kind of 20 answered. I was going to ask, how do you 21 quantitate the utility function, and I think 22 you kind of just answered that, thank you. 23 DR. C. GOODMAN: I think Dr. Mock was 24 next. 25 DR. MOCK: I had a question along the file:///F|/pg061709%20(2).txt (145 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00146 1 lines of applicability of your interface 2 between clinical and statistics. Specifically, 3 from your discussion and your experience, do 4 you palpably see a change in the practice 5 leading to improved outcomes and decreased 6 complications, and unnecessary expense in 7 medical care? What I mean by that, I wish that 8 you had used your DVT-PE example through the 9 presentation, I would have loved to have seen 10 you quantify those risks. But more 11 specifically, if you believe that decreased 12 variability increases efficiency, and if you 13 use your PE-DVT, do you see it applicable to 14 guidelines such as Milliman and Interqual where 15 we would decrease 50 physicians treating a 16 PE-DVT differently and have one way to treat 17 that patient to an improved outcome and 18 decreased complications? 19 DR. LEWIS: I think the answer is yes, 20 I see the role there, but physician behavior is 21 an explicit delineation of what the drivers of 22 that behavior is, and those are the components 23 of the utility function in conjunction with the 24 willingness of either regulatory agencies, 25 funders or specialty organizations to agree file:///F|/pg061709%20(2).txt (146 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00147 1 upon those utility functions so they directly 2 lead to a threshold below which the appearing 3 treatment or diagnostic workup is not justified 4 by the risk of disease, and it requires both of 5 those. 6 So basically somebody has to say based 7 on our understanding of the likely outcomes of 8 this disease, both treated and untreated, 9 pulmonary embolism is a good example, treated 10 it has a very low morbidity and mortality, 11 untreated it has an extraordinarily high 12 mortality rate. So someone has to be willing 13 to say we believe that below a post-test 14 probability of one percent, and that's not 15 probably a good number, we don't think that the 16 workup is justified, and then we have to be 17 willing to update that as new information 18 regarding the burdens of treatment and the 19 alternative therapies become available. 20 So for example, and this is a very 21 simple example, when we moved from having to 22 use unfractionated Heparin by continuous drip 23 infusion in the inpatient setting to using low 24 molecular weight Heparin in an outpatient 25 setting, the cost associated with the treatment file:///F|/pg061709%20(2).txt (147 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00148 1 went markedly down, both in terms of morbidity 2 and the actual hospitalization costs. That 3 should have changed our threshold of the 4 post-test probability for initiating empiric 5 therapy. 6 DR. COX: So then, we either regulate 7 or we align incentives financially to change 8 the behavior and the outcomes? 9 DR. LEWIS: Well, I would hope the 10 first step is identifying what is a rational 11 threshold and then aligning the incentive 12 activities along that rational threshold. 13 DR. C. GOODMAN: One last question 14 from Dr. Axelrod. 15 DR. AXELROD: Isn't -- throughout your 16 presentation you talk about when you combine 17 studies to the degree in which the data is 18 homogenous enough you can combine those 19 studies, and sort of inherent in that was those 20 priors that you put up there which you sort of 21 said, this is based on our best guesstimate of 22 it. And I think that one of the things for 23 those of us who don't do a lot of Bayes is that 24 concern about, you know, there are these two 25 big black boxes. And you know, I don't think file:///F|/pg061709%20(2).txt (148 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00149 1 you can address all of it but perhaps you can 2 comment quickly on, you know, is there enough 3 that you can kind of reassure the panel that 4 that is not as much of a black box as it seems 5 to be based on your presentation. 6 DR. LEWIS: What I was trying to show 7 the panel is that it's possible to shine a 8 light in that black box, and the way to shine 9 the light in that black box is to make 10 different assumptions regarding a third level 11 of the hierarchy and to determine whether that 12 affects qualitatively the decisions one would 13 make based on the estimates of the second level 14 of hierarchy. 15 So for example, when colleagues that I 16 work with design an analysis or a clinical 17 trial that involves a hierarchical model, it is 18 absolutely routine to try markedly different 19 assumptions regarding the priors at the very 20 top level to demonstrate that with reasonable 21 sets of data that we might expect, that would 22 not lead to differences in the qualitative 23 decisions regarding, for example, presence or 24 absence of the treatment effect or the ordering 25 of the treatment effects in terms of their file:///F|/pg061709%20(2).txt (149 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00150 1 relative efficacy. So you essentially do a 2 sensitivity analysis to demonstrate that that 3 choice is not what's driving your decision. 4 DR. C. GOODMAN: Thank you very much, 5 Dr. Lewis, very helpful. 6 Next is Dr. Sharon-Lise Normand, who's 7 going to address the application of Bayesian 8 concepts in public decision-making, and I think 9 we've already broached that topic a little bit, 10 Doctor. 11 DR. NORMAND: Thank you very much for 12 giving me the opportunity to speak today. In 13 terms of, I have no financial interests but in 14 terms of conflicts, I did serve on the FDA 15 circulatory system devices advisory panel which 16 did review some Bayesian applications. I am 17 working with the ADHA and the ACC on updating 18 their methodology for creating guidelines and 19 part of that is looking at Bayesian methods to 20 create the guidelines for evidence base. And 21 finally, I am currently working with the FDA in 22 the post-market surveillance setting in the 23 Centers for Devices and Radiologic Health, and 24 we utilize Bayesian methods. 25 So with that said, I'm going to talk a file:///F|/pg061709%20(2).txt (150 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00151 1 little bit, present you today with two 2 problems, one is going to be a safety problem, 3 and the other one is going to be with the idea 4 of using a Bayesian inference to determine 5 whether medical devices should be adopted or 6 rejected. And in particular from a statistical 7 standpoint, I'm going to be focusing on the use 8 of Bayesian methods when you have sparse data, 9 which I hope will be apparent in a second, 10 uncertainty and heterogeneity, which Professor 11 Lewis just spoke about, and finally function of 12 parameters, and hopefully I will make that 13 clear for you in a moment. 14 So, I'm assuming some people in this 15 room are familiar with the following 16 meta-analysis, and I'm grateful for the first, 17 the previous speakers talking about 18 meta-analyses, looking at the effect of 19 Rosiglitazone on the risk of MI and death from 20 cardiovascular causes, and I'm going to pick 21 this particular meta-analysis as a starting 22 point to demonstrate some of the issues with 23 using a frequentist approach to meta-analysis, 24 and I've highlighted something you can't see, 25 but basically it's stating that there is indeed file:///F|/pg061709%20(2).txt (151 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00152 1 a problem, there is a safety problem with using 2 Rosiglitazone. 3 So with the meta-analysis, I want to 4 emphasize two things, one is an observational 5 study, we didn't randomize which study could be 6 done, so the meta-analysis is actually an 7 observational study and we need to emphasize 8 that, and we found that some people might not 9 be familiar with that. And I have to thank Don 10 and Scott Berry, because I thought they were 11 competing with me in their earlier talks when 12 they talked a lot about meta-analysis, but 13 thank you anyhow. 14 In terms of meta-analysis to assess 15 safety, I want to highlight the difference in 16 the use of meta-analysis to assess safety as 17 opposed to using a meta-analysis to assess 18 effectiveness. And so one of the problems is, 19 unlike effectiveness, or less so than 20 effectiveness, the definition of safety across 21 studies varies much more, and I think that's 22 pretty well known. There have been some 23 studies that actually looked at that and said 24 indeed, you know, survival is survival, but if 25 we're looking at a safety endpoint that's not file:///F|/pg061709%20(2).txt (152 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00153 1 survival, different studies have defined that 2 in different ways, so that's a particular 3 problem. 4 Therapies that increase safety risk 5 are systematically excluded from publication, 6 and again, that's a little bit different than 7 the Bayesians excluding studies where there is 8 no treatment effect finding. They are saying 9 that even if there's a safety problem and there 10 is a quality treatment effect, those studies 11 are excluded anyhow. And what I want to focus 12 on today in particular are low event rates, and 13 I'm going to talk about the event of an MI, a 14 heart attack. 15 So in some clinical trials or 16 meta-analyses, there will be zero MIs in both 17 treatment arms because there were two treatment 18 arms, and sometimes there's going to be zero 19 observed in only one of the treatment arms. 20 And how you handle this is critically important 21 and typically not something that people have 22 dealt with when you're looking at combining 23 information for effectiveness. 24 So here is a picture of the data for 25 the Rosiglitazone study and what I have on the file:///F|/pg061709%20(2).txt (153 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00154 1 Y axis is the event rate of heart attack by 2 treatment arm, so on the Y axis it's the 3 control arm, or pardon me, the Y axis is the 4 Rosiglitazone arm, on the X axis it's the 5 control arm. Each number represents the 6 empiric event rate, a heart attack, in each of 7 those studies. And the first little circle, I 8 don't know if you can see that in red, but the 9 reds are studies in which there is at least 10 some -- there's some trials where there's no 11 events in either the whole study, or one arm, 12 and then blue is where we actually have 13 observed events. 14 Now you're going to notice, there's 15 fairly a lot of red diamonds, and what I 16 circled are the four studies in which there 17 were no events in both arms of the studies, 18 because each study had a control arm and a 19 Rosiglitazone arm. Now if I look at this, if I 20 look in this, there were only six studies in 21 the Rosiglitazone arm that had no events, no 22 heart attacks, and you can see the rate of 23 heart attacks in the control arm, in the 24 comparator control arm, so we have six of those 25 studies. You'll notice that we have 20 studies file:///F|/pg061709%20(2).txt (154 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00155 1 where there is no event in the comparator arm 2 but there are events, that is adverse events, 3 heart attacks in the Rosiglitazone study. So 4 first of all you think, gee, there seem to be 5 more studies with more events in the 6 Rosiglitazone arm, which could be a function of 7 a lot of things. 8 So first of all, you're going to see 9 that it's difficult because you have zeroes and 10 how do you deal with those, you can't divide by 11 zero, how are we going to handle it. Well, 12 typically for example, I just wanted to 13 highlight the answer or the estimate that was 14 reported in this particular study, and that was 15 a NEJM article with 38 studies. Now I 16 neglected to say that there were 42 studies 17 overall, and so there were four studies that 18 had no events in either arm, to get to 38, so 19 that's apparently what the editors did, they 20 threw away the studies where there was no event 21 in either arm, so now we're down to 38 studies. 22 And so they actually did find if 23 you're going to do the P value thing that there 24 seems to be a safety signal with the use of 25 Rosiglitazone compared to the comparator arm, file:///F|/pg061709%20(2).txt (155 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00156 1 with an odds ratio of about 1.4. So how do 2 people, and when I say people I'm going to talk 3 about lay people, and what I mean by that is 4 non-statisticians, typically in the past dealt 5 with this? Well, they do a number of things. 6 Either they drop their studies with zeroes or 7 they add a small correction, and so what they 8 will do is they'll add a small number less than 9 half, and so on a two-by-two table where we've 10 got the treatment arm, MI, no MI, the control 11 arm, MI, no MI, and we've got some zeroes in 12 that table, how do I fix that to actually 13 compute an odds ratio? Sometimes what they 14 will do is add a half to each level of that 15 table and that way I don't have to divide by 16 zero, I'm happy. 17 So that's one type of thing. You can 18 drop the studies with zero event and then just 19 add a half to those trials where there were 20 only events in one arm, and that would be 38 21 studies. And you can see if you do that, you 22 can see you get an odds ratio of 1.28, it's no 23 longer statistically significant, there is no 24 longer a meaningful P value, a signal that says 25 there is a real problem here in terms of file:///F|/pg061709%20(2).txt (156 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00157 1 adverse events, meaning heart attacks. 2 Now what other people do is, let's 3 keep the zero events on it and add a small 4 correction. So if I keep all 42 studies you 5 can see I get an odds ratio of 1.26 and again, 6 by conventional P value criteria you would say 7 that there is no evidence of a safety problem 8 here. 9 Now here is the correct approach to 10 use and it's the Bayesian approach. Now that's 11 pretty bold of me to say, correct statistical 12 approach, but it's the approach, it happens to 13 be a Bayesian approach, and I'll talk a little 14 bit about it in a second. But it's one that 15 says okay, let's actually look at the 16 likelihood. You've heard about the likelihood 17 function from previous speakers, but what that 18 does is they're able to keep all the data. I'm 19 going to admit that in some studies I don't 20 believe the underlying risk is zero, but I'm 21 going to admit that indeed I can have a study 22 where actually I will observe no heart attacks, 23 and that's the sensible thing to do. 24 And if you do that, you average the 42 25 studies, and again if you look at the P value, file:///F|/pg061709%20(2).txt (157 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00158 1 there's no difference, but if I could ask you 2 to focus your attention on the odds ratio, we 3 went from a statistically significant increased 4 risk of an adverse event with the use of 5 Rosiglitazone relative to comparators or 6 controlled groups, though all the other studies 7 showed no statistically significant P value 8 exceeding .05. But moreover, look at the point 9 estimates and how they change. 10 So what went wrong? Hopefully I can 11 give you some clues as to what went wrong. The 12 first thing in the paper, they said that they 13 excluded zero total heart attacks. Well, we 14 know that in reality, theoretically again, this 15 is not a quote, that if you've got a binomial 16 sample distribution which was the distribution 17 they assumed, you can't throw away zero 18 studies, it produces a bias. So, I don't mean 19 to pick on this and I will tell you this is 20 done over and over again, but in this 21 particular study they actually did this. 22 Now also if you think about it, 23 Professor Lewis talked about between study 24 variation, and so we have, let's say 42 trials, 25 and you could think of the 42 trials on the X file:///F|/pg061709%20(2).txt (158 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00159 1 axis and where we'd have the risk of the 2 events, we have some with zeroes and some with 3 higher values, and artificially reduced the 4 true amount of between study variation by 5 locking up those studies with zeroes, so again, 6 you're artificially reducing the amount of 7 between study variation there is. Now this 8 actually leads to a cycle of errors when you 9 get to that stage. 10 In the particular study I'm reporting 11 on, they actually did something called a Peto 12 odds ratio, and I suspect they adopted this 13 type of odds ratio because it can accommodate 14 zeroes in one arm. It can't accommodate zeroes 15 within both arms but it can accommodate zeroes 16 within the one arm, but in fact this is known 17 to create bias when there's substantial 18 differences in the control sample sizes, and in 19 fact in these 42 studies there were huge 20 disparities in the number of participants in 21 the trial and control arm. 22 So again, they used something that was 23 known to be biased in this setting trying to 24 circumvent something, I think, that they felt 25 would be a difficult to get over. And in fact, file:///F|/pg061709%20(2).txt (159 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00160 1 of the 42 studies, 25 percent had more in the 2 treated than the control group. And this is 3 why you are seeing fewer zeroes in the treated 4 arm, because there are definitely more patients 5 and the sample size is big enough to 6 accommodate an observation of an adverse event. 7 And then finally, by adding a small 8 number to the numerator or denominator, and by 9 that I mean adding a half to the two-by-two 10 table, that also can cause bias and in fact it 11 can even change the direction of the odds ratio 12 depending on certain distributions within the 13 tables. So you can actually go from, between 14 the treatment and control group, going from 15 something that is bigger than one to something 16 that is less than one. 17 So, lots of different problems in 18 reporting a very common treatment used in 19 practice that I certainly would say caused a 20 lot of concern from the FDA, and by the way, 21 the FDA did their own analysis and basically 22 agreed with these findings, again, not using 23 sort of Bayesian approaches to deal with the 24 fact that you can actually observe some zero 25 events, which is very common, and for some file:///F|/pg061709%20(2).txt (160 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00161 1 reason they didn't take account of that. 2 And as I was just saying, it's not 3 just with Rosiglitazone that this happens, so I 4 have named a number of studies here that will 5 be affected, such as the hemoglobin-based blood 6 substitute that was reported in JAMA, again, 7 adding small corrections after certain zero 8 events. The FDA has done their own analyses of 9 antidepressant therapies and anti-epileptic 10 drugs, and again, they also reanalyzed the 11 Rosiglitazone. 12 So I just caution here that if one, 13 especially in the post-market studies, if we're 14 going to look at safety in the post-market 15 setting, that the reason people do 16 meta-analysis is because it's too small to find 17 a safety signal in many of these clinical 18 trials and so it makes sense, therefore, to do 19 a meta-analysis that can combine information 20 across clinical trials. But when we get down 21 to very rare events, using sort of ad hoc 22 methods to deal with sticky problems such as 23 zeroes, I believe that there have been some 24 very misplaced conclusions at least based on 25 the data in terms of looking at safety risks. file:///F|/pg061709%20(2).txt (161 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00162 1 Now I'm going to talk about 2 arthroplasty, hip replacement systems. So, I 3 talked about meta-analysis, the fact that you 4 can do a Bayesian analysis that's going to 5 accommodate the zeroes, it's going to reflect 6 the uncertainty, it's going to admit to the 7 fact that you've got between study variation. 8 You're not going to reduce it because your 9 frequentist method doesn't know how to handle 10 the zeroes. And so then, that's the first 11 part. 12 The second part is aligned with, I 13 think a lot with the last piece of Professor 14 Lewis's discussion, and that is the idea of, 15 and I think we're going to see more and more of 16 this, combining data from multiple and diverse 17 data sources in order to invoke safety or 18 comparative effectiveness. 19 So I'm going to talk about 20 specifically hip replacement systems. In 2003 21 there were a lot of them in the U.S., about 22 200,000, and they were about $25,000 a pop, 23 let's say, so it's an expensive procedure, 24 there are a lot of them, and we have every 25 reason to believe there will be a lot more. file:///F|/pg061709%20(2).txt (162 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00163 1 And why do we believe that? Because people are 2 living longer, because there's more diabetes, 3 there's more obesity, so we have every reason 4 to believe that the use of these types of 5 devices will increase. 6 Now what type of devices are out 7 there? So we've got metal with polyethylene, 8 these are all ball and socket, we've got metal 9 on metal, and then we've got the newer ones 10 that actually require premarket applications, 11 sanding. So the metal on plastic, it was 12 about, let's say a thousand that were cleared 13 by the 510(k) path. Metal on metal, again, 14 let's also say 150 were cleared by the 510(k) 15 path. Now we're talking about ceramic on 16 ceramic that were first released in the U.S. in 17 2003, and ten premarket applications have been 18 approved. 19 Now if you think about hip replacement 20 devices, there's a lot of information that we 21 have short term, but what is really important 22 is long-term consequences and effectiveness of 23 these devices, because patients are living 24 longer, and now you've got real estate inside 25 your body and one really wants to get some file:///F|/pg061709%20(2).txt (163 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00164 1 sense of how safe, how effective are they, and 2 we really don't have much data in the U.S. to 3 get these devices approved, as well as other 4 types of, let's say data that are selected in 5 the observational phase. 6 So let's call this the effectiveness 7 endpoint. That usually has been measured in 8 most clinical trials using a short, usually 9 one-page summary that you look at. Often one 10 looks at survivorship and that is what is the 11 time to hip revision that one looks at in 12 clinical trials. And then there is a whole 13 slew of adverse events that relate to sort of 14 the device in and of itself that may 15 subsequently lead to patient problems in terms 16 of what's actually happening to them. So there 17 could be a component where there is a breakage 18 that causes problems for the patient, and a lot 19 of these are going to have radiographic 20 evidence, some of them you don't. 21 So again, we've got three different 22 types of outcomes that we measure that we're 23 interested in, and I lumped these together as 24 adverse events, but you might want to look at 25 those separately. What type of data do we file:///F|/pg061709%20(2).txt (164 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00165 1 have? Well, we have experimental data, which 2 is the preclinical data and the typical 3 clinical trial data, and there might be other 4 experimental data out there in terms of non, 5 let's say sponsored data that are out there. 6 Now when I say preclinical data, 7 currently the way, at least I know more about 8 the device side, but the way the device side 9 gets approved is that all of these paths are 10 followed. So you've got the laboratory tests 11 of how long the battery lasts and if it lasts 12 for ten years, it passes; is it rusting out 13 soon, it passes. And once it passes that 14 hurdle then you go to another hurdle and 15 there's information, and then you go to another 16 hurdle. And you might have animal information 17 and animal studies. 18 And once the device is passed or 19 failed, any further evidence is completely 20 ignored, and that is completely wrong. From a 21 Bayesian point of view, all of that information 22 needs to be continually integrated and updated. 23 If we didn't think any information, if we 24 thought information from animals were useless, 25 we wouldn't be subjecting those poor pigs to file:///F|/pg061709%20(2).txt (165 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00166 1 whatever, you know, so obviously the 2 information contained in the animal studies is 3 helpful and so we need to integrate it. 4 So I'm going to step further and say 5 that we need to integrate all of the data, 6 human data and animal data. I'm not the first 7 person to suggest this; Bill Dumanchel 8 suggested this in terms of looking at toxin 9 exposures on lung disease and looked at the 10 various mice exposure studies as well as 11 information in people. And obviously there's a 12 limit there, but right now it's completely 13 forgotten about. So those are the experimental 14 data, data in a highly controlled setting which 15 we can use. 16 Then we come to observational data 17 once it's released, but outside of -- well, it 18 has to be once it's released because you 19 shouldn't have access to it otherwise. So 20 you've got FDA mandatory post-approval studies, 21 so you've got those data which in theory will 22 capture more complete information that would be 23 contained in other data sources such as the 24 Harris Hip Score, and those types of elements 25 are important. file:///F|/pg061709%20(2).txt (166 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00167 1 There are some registries in the U.S. 2 that contain information, and although we're 3 now talking about hip replacement, the same 4 could be true with stents, with ICDs; I just 5 happened to take hip replacement as an example. 6 So there are a lot of registries that one could 7 capitalize on. Then there are registries with 8 administrative data. So of course CMS has data 9 in terms of the Medicare billing data, we have 10 in-hospital billing data. So there's a lot of 11 different data sources covering different 12 subpopulations, and the degree of precision or 13 completeness or breadth of those data vary by 14 their data sources, but nevertheless, they're 15 all informative. 16 And finally, there are data outside 17 these U.S. registries and in particular for the 18 example I'm talking about, which are hip 19 replacements, there is actually a registry in 20 Australia that has some pretty long follow-up 21 in terms of these particular devices. 22 So, lots of different data. 23 So, what's the practical consideration 24 as relates to multiple outcomes? I in the 25 first slide talked about effectiveness, file:///F|/pg061709%20(2).txt (167 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00168 1 survivorship and adverse events. For some 2 reason people treat these as well, that's one 3 bucket, another bucket, another bucket, but 4 that's all information about evidence for the 5 adoption of a particular medical technology, 6 and more importantly, a single treatment may 7 have different effects or different outcomes, 8 so that's the reason why there may be multiple 9 outcomes. 10 Even though there's one clinical 11 outcome, Harris Hip Score, we know that primary 12 and secondary outcomes are always included with 13 the outcomes, but of course the point is the 14 different outcomes are correlated to the 15 subject and there may be different predictors 16 of the outcome depending on what the outcome 17 is. 18 And then an important point in terms 19 of using these very large and different data 20 sets is the possibility of missing data, 21 because not all outcomes are measured in every 22 study. So if we use CMS data, we know that the 23 Harris Hip Scores aren't there, so you could 24 think of it as a missing data problem. 25 There are multiple treatments, and file:///F|/pg061709%20(2).txt (168 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00169 1 what I mean by that of course, we've got 2 devices, we've got classes of devices, and you 3 see these literally, we've got metal on metal, 4 we've got ceramic on ceramic, we've got metal 5 on plastic. We can think of companies, one 6 ceramic on ceramic, or two ceramic on ceramic, 7 so again, lots of heterogeneity. And the 8 question is do we as a group, are you going to 9 say okay, we are going to approve ceramic on 10 ceramic as a device or are we going to approve 11 company one, company two, I don't know the 12 policy. 13 But in any event, you can think of 14 these types of things, and there's also the 15 possibility of alternative treatments and that 16 is drugs. And so clearly in any clinical trial 17 there would not be a suitable comparison group, 18 and that also applies to multiple treatments. 19 The fact that we have product 20 synthesis, and what I mean by that is 21 observational data. Obviously these patients 22 aren't randomized and we've got to deal with 23 the selection issues. 24 And then of course we've got multiple 25 designs, and then we'd have to deal with file:///F|/pg061709%20(2).txt (169 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00170 1 cross-design synthesis. We've got randomized 2 trials, we've got observational data. The 3 randomized trials are studies where the 4 individuals have been randomized but the number 5 of studies haven't been randomized, so we've 6 got all these problems. 7 We've got site effects, meaning there 8 might be some reason to think that the outcome 9 may vary by site, and again, it may be the 10 hospitalization, the threshold to hospitalize 11 somebody in Australia may be different than 12 here. Again, I'm making that up, but there may 13 be some reason to believe that some outcomes 14 may vary and maybe the association of the 15 technology might vary. 16 And also, of course there is the time 17 period, over what time period are we suspecting 18 the treatment might evolve over time. 19 So lots of practical considerations. 20 And in terms of trying to put all of these 21 together to borrow information, to learn about 22 outcomes that may not have been measured, or to 23 get more precise information for the subgroups 24 where perhaps in one data set you had much more 25 information than in others, I really can't file:///F|/pg061709%20(2).txt (170 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00171 1 think of any other reasoning than to specify a 2 full probability model, and what I mean by that 3 is a Bayesian model. 4 So how do we use all of the evidence 5 to obtain more precise evidence of safety and 6 effectiveness of particular devices in 7 particular patients? And again, this is 8 related to Professor Lewis making the data 9 sources, rather than his diagram where in one 10 diagram it said clinical trials and another 11 diagram said subsequent. And I'm throwing 12 everything in together and basically saying 13 that's all the information, how do we combine 14 it in order to learn something. 15 So clearly we have to posit some 16 mechanism that generates the observed data. 17 And we're doing that, I'm saying we, the royal 18 we, each investigator is doing that separately 19 by saying this is the clinical data set we're 20 going to posit, this is the observational data 21 set that we're going to posit, and the animal 22 study, I'm going to posit that it's going to 23 give me information in order to infer 24 something. So people are positing something, 25 but then we have to posit some mechanism to file:///F|/pg061709%20(2).txt (171 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00172 1 form a whole data set. And I'm going to say 2 that while some outcomes may be missing, we're 3 going to assume that these outcomes are 4 connected, and I'll show you what I mean. 5 Now I think I have one slide with a 6 Greek formula, and it's not meant to frighten 7 anybody or to say that it's too complicated. I 8 want to show you that there is lots of indices 9 here, and the reason why the indices here are 10 very important is because I want to enumerate 11 the number of different sources of information. 12 So we've got an outcome, so we've got 13 an outcome m, which may be effectiveness, 14 survivorship. I've got treatment k, which may 15 be ceramic on ceramic or it may be another one. 16 I've got a study, which could be very simple, 17 it could have been a particular study for 18 Medicare or a particular trial. And then we 19 have cohort, which may be dealing with a 20 subgroup within a trial or a Medicare cohort. 21 And then we've got study-specific outcomes and 22 then we've got the sampling error. 23 The point is that the study i, cohort 24 j, treatment k, and I've written something up 25 there in a very loose generic sense, because file:///F|/pg061709%20(2).txt (172 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00173 1 I'm saying that the assumption is that the 2 outcome, suppose it's the Harris Hip Score is 3 greater than 70, I can model that with all this 4 together and say that somehow it might be 5 related, add it together to see if there is a 6 basis for changing the treatment, et cetera. 7 So there is a way of positing the underlying 8 model, and the point being that even though in 9 some studies I may not have empiric data like 10 the Harris Hip Score and the m equals one 11 outcome, I can use the information on those 12 other studies to infer about, you can think 13 about the missing outcome in the particular 14 study I'm interested in. 15 So we permit heterogeneity, and again, 16 this is something that we talked about, by 17 assuming distributions for the various 18 components of the model, and so we can see 19 effects due to outcome and treatment, we can 20 see effects due to patients, blah, blah, blah. 21 So there's lots of different effects curves 22 that we permit; we know all of these effect 23 curves, there's going to be some differences 24 and heterogeneity across the various studies. 25 So let me tell you why we should file:///F|/pg061709%20(2).txt (173 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00174 1 define, and again, this was motivated in the 2 setting earlier, but let me tell you why we 3 should be thinking about this today in 2009. 4 Well, first of all, we now have the capability 5 and the statistical tools, both 6 methodologically as well as the capability, the 7 computational capability to analyze multiple 8 outcome measures on different scales, so lots 9 of different people are able to simultaneously 10 model a binary outcome, Harris Hip Score 11 greater than 70, what's my time to hip 12 revision, we can model those all at the same 13 time now, which is very different than 14 analyzing one outcome at a time, and there's 15 lots of reasons not to model one outcome at a 16 time, and it's mostly related to missing data. 17 But nevertheless, we can accommodate 18 the heterogeneity across studies and data 19 sources, and this is a key point, that 20 different data sources, different -- should I 21 ignore that red light? 22 DR. C. GOODMAN: You've got a few more 23 minutes. 24 DR. NORMAND: We can accommodate the 25 heterogeneity across studies, we can actually file:///F|/pg061709%20(2).txt (174 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00175 1 combine information across studies within 2 multiple treatment options, and we can combine 3 now different types of studies, whether they're 4 randomized or observational. And so the idea 5 here is for more information from either some 6 studies, some databases, to more precisely 7 estimate treatment effects, and again, as I 8 said, that led to that table in there. 9 So let me conclude with, what are the 10 advantages of the Bayesian approach for 11 quantifying the evidence? And so the first 12 thing, it provides a coherent method for 13 synthesizing evidence. Now that sounds like a 14 highbrow comment, but it's very important 15 because it makes things very transparent. 16 Right now the model designs I don't believe in, 17 so let's modify it. I write down the model, I 18 know what the probability means in this 19 setting, it's pretty straightforward. 20 So it's this construction of natural 21 quantities of interest, although I didn't talk 22 about function of parameters, I can, or we 23 would estimate the specific class of device as 24 particularly unsafe or we can estimate the 25 probability that the safety risk is less than file:///F|/pg061709%20(2).txt (175 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00176 1 two percent, so we can actually estimate those 2 things in a coherent framework. It does not 3 require the modeler to do assumptions, and now 4 you may say what, but it does not require 5 making strong statistical assumptions, because 6 right now if you don't combine the information, 7 either you're doing it qualitatively in which 8 you're not combining it, or if you are going to 9 combine it you do need a variation that would 10 be heroic and extremely solid method. 11 And also, if the studies with no 12 events provide no information, so again, that 13 was one assumption in the meta-analysis that I 14 showed you, and that's actually false. So in 15 this setting you can actually utilize studies 16 with some zero event arms. 17 And it eliminates the need for 18 approximations. Now a panel may not be so 19 interested in technicalities, but these are 20 quite important. And so if you have sort of a 21 complex model and you want to combine the 22 evidence in a coherent manner, I would have 23 thought that an estimate at the end of the 24 evidence analysis phase of how effective 25 something is, I'd have to provide you some file:///F|/pg061709%20(2).txt (176 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00177 1 uncertainty attached to that, and if you don't 2 use a Bayesian approach you're doing some 3 approximations which are slippery to say the 4 least. 5 So the disadvantage I have listed here 6 is it requires more statistical knowledge and 7 expertise to implement than standard 8 approaches. And what I mean by that, I should 9 be very clear what I mean by that, I know that 10 right now almost anybody can fit a regression 11 model by, you know, using any software package. 12 It doesn't mean it's right, it doesn't mean you 13 actually have interpreted the P values 14 correctly. Again, because of the complexity, 15 you'd actually better know what you're doing, 16 so that's somewhat of a disadvantage that, you 17 know, I think it's somewhat of an advantage 18 having statisticians doing this, but in any 19 event that's one thing you really, you know -- 20 you need expertise in Bayesian analysis, so let 21 me finish with that. 22 And finally, I would like to thank 23 some people that I've been working with. The 24 meta-analysis working group, we came together 25 independently simply to formulate zero event file:///F|/pg061709%20(2).txt (177 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00178 1 trials and to do something virtually ad hoc 2 with the zero event arms of the various areas 3 that we worked in. I've looked at this from 4 the stent side and the thrombosis, and so we 5 looked at that. The hip replacement again, I 6 worked with the people at the FDA in the 7 surveillance branch, and again, I have some 8 funding from NIH to look at combined 9 multi-group conditions, and with that, I'll 10 stop. 11 DR. C. GOODMAN: Good. Thank you very 12 much, Dr. Normand. Can you go back to slide 13 20? You may need some AV help for that. 14 Questions from the panel at this point for Dr. 15 Normand? We have a few minutes before going to 16 break. Yes, Dr. Prager? 17 DR. PRAGER: I want to thank you for 18 really a good presentation, and I think the 19 choice of the hip is particularly pertinent 20 here. And give what you've been talking about, 21 I see a whole cadre of double-edged swords that 22 come up. And one of them is that we often, the 23 FDA often approves a therapy, let's say in this 24 case a hip, a specific hip replacement, without 25 long-term data, because often they're not file:///F|/pg061709%20(2).txt (178 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00179 1 available. And so we don't know that if they 2 followed it for five years and at year seven 3 the hip completely degrades, we're left having 4 something approved that really doesn't have a 5 good outcome. 6 And so the question really comes for 7 CMS. If we're to use a model like this and 8 something becomes approved, how do we integrate 9 this model into looking at outcomes after we've 10 already been approving to go forward. 11 DR. NORMAND: It's a very important 12 question, and I am not an MBA person, but I 13 will say working with the FDA, they are 14 revamping, at least from the devices side, 15 post-market surveys, and so they are quite 16 aware. So the first part of the question, you 17 know, they are really thinking about doing the 18 full cycle now, always updating the information 19 now, so that's one. 20 The second piece of your question is, 21 we can only approve or make decisions on the 22 data you have available, and if you have no 23 long-term data available, again, you want to 24 look at as much information as you can, and you 25 could make predictions about what could happen. file:///F|/pg061709%20(2).txt (179 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00180 1 But you have to have some long-term data 2 available, and that's why we study this 3 constant, you know, let's see what is happening 4 in the real world. So I think this is a 5 decision that's done at one time, so these are 6 things that need to be looked at, and again, 7 you can't look at everything, but there has to 8 be some prioritization that makes sense to make 9 sure one revisits and updates that. 10 DR. C. GOODMAN: Thank you. 11 Dr. Hlatky is next. 12 DR. HLATKY: Very interesting, thank 13 you. The thing I was struck by listening to 14 you talk about hip replacements is that there 15 are 900, or almost a thousand different models, 16 I guess, that have been approved under this 17 process. And so if one is looking at, I'm 18 assuming that, not knowing much about hip 19 replacements being a cardiologist, that some of 20 these devices may have device-specific problems 21 and other ones may have stuff that's within 22 your class. You talked specifically about the 23 class, but I'm wondering what happens if you 24 start seeing, I mean, how do you tease apart 25 how much of it is, you know, this specific file:///F|/pg061709%20(2).txt (180 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00181 1 model is no good, versus this class is no good 2 or this manufacturer is no good? 3 DR. NORMAND: Again, that relates to, 4 although I said class in what I was saying, 5 because I don't think we have the data for the 6 nine studies, but pretend for the ten that have 7 just been actually approved, there are 8 device-specific information in those, and so 9 you could, if that law and all that stuff 10 permitted it, within the FDA they could look at 11 device-specific information. So again, that's 12 part of -- you know, right now we don't have 13 the ability because we don't have the 14 device-specific information, we only know that 15 a certain type, we know it's ceramic on ceramic 16 but we don't know if a device is made by 17 Company K. 18 So the answer to the question is we'll 19 have some information that's device-specific to 20 look at, other data we don't. And so we're 21 trying to borrow some information about the 22 similarity of the devices because there is some 23 similarity issues, and that's how we define it. 24 Something brand new and nothing related to the 25 past, that just doesn't happen. And so it's file:///F|/pg061709%20(2).txt (181 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00182 1 like a demand of, thinking would be helpful 2 such as with, I don't know if you're familiar 3 with the STS and the target registries where 4 you have the device-specific names, and so it 5 could be addressed by having more information 6 that is device-specific. 7 DR. C. GOODMAN: Thank you. Yes, Dr. 8 Dullum. 9 DR. DULLUM: I was thinking that this 10 might be a benefit that CMS might look at 11 Bayesian techniques to, once you approve a 12 device such as the ICD, then there's always 13 ongoing interim analysis with the possibility 14 of disapproving it, I don't know if you ever 15 disapprove, but which would actually be 16 beneficial long term. 17 DR. NORMAND: In fact, part of the 18 Bayes factors that were talked about earlier by 19 Professor Goodman, where that information from 20 those enrolled in the clinical trials could be 21 combined with the observational registry data 22 that CMS has mandated for collection, and you 23 could look at it to get some Bayes factors and 24 say here are the numbers. Somebody has to bite 25 the bullet and say at that level it's a file:///F|/pg061709%20(2).txt (182 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00183 1 problem, we're going to stop, but that 2 mechanism is definitely, we have the ability to 3 do that, and we clearly should be doing that. 4 We shouldn't stop, you know, again, it's always 5 updating, updating. 6 DR. C. GOODMAN: Dr. Normand, with 7 regard to the challenge that CMS might face 8 about how to account for or embrace some messy 9 body of evidence, you suggested in slide, I 10 think it was slide 16, you talked about an 11 approach to use all the evidence to obtain more 12 precise estimates of safety and effectiveness 13 for a particular technology, there it is. And 14 then you go to slide 20 and you talk about 15 having a coherent framework within which to 16 combine this super-sized evidence. 17 So, do the Bayesian approaches offer a 18 way for CMS to account for and accommodate 19 these messy bodies of evidence where it did not 20 have before? What's the kind of added value 21 for Bayesian for real world mixing bodies of 22 evidence? 23 DR. NORMAND: I'm going to say that 24 the advantages are, A, there is a way to 25 combine them using bonafide theoretically file:///F|/pg061709%20(2).txt (183 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00184 1 proven formulas, it is not an approximation but 2 it's a theoretical and technical way to do it. 3 Number two, it makes it completely 4 transparent, and I think this is very key, this 5 is what we're assuming, whereas in looking at 6 analysis the way it's currently done, I think 7 those assumptions are not transparent. 8 I also think that it provides 9 evidence, I think that's the key thing. Okay, 10 you're doing things and you can only look at 11 the data that you have, good data. But when 12 you're doing that, you need to recognize in 13 your statistical approach the uncertainties 14 that are inherent in that. And I don't know 15 of, I think the Bayesian approach is a 16 framework that permits you to represent all of 17 that, where it's not clear you can do that in a 18 frequentist. Well, I could probably think of 19 one, but that would be a special case. 20 DR. C. GOODMAN: But you did just say 21 you need to know that you got good data. 22 DR. NORMAND: Yes. 23 DR. C. GOODMAN: So, does the Bayesian 24 approach allow us to interpret the available 25 evidence? I'm thinking in our more file:///F|/pg061709%20(2).txt (184 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00185 1 conventional approaches we have ways to 2 interpret various levels of evidence, we have 3 evidence hierarchies, we've got various things 4 that show greater or lesser bias and so forth. 5 Does the Bayesian toolkit allow us to make a 6 similar or a better assessment of the quality 7 of this evidence, since you're vouching for 8 using almost all of it? 9 DR. NORMAND: While I'm vouching to 10 use all of it, you know, if you give me data 11 that's no good, I'm not going to use it. So 12 there's certainly a standard level of, you 13 know, the data elements are collected and 14 defined appropriately. No matter what the 15 method, you can't overcome bad data, so that's 16 the first statement. 17 What it would provide you with is the 18 type of things you want to be able to 19 interpret, that I would claim how you're 20 currently interpreting them is wrong. So 21 you're placing an emphasis on P values, which 22 you've had, you in general, in terms of 23 concluding what evidence you have available. I 24 think the type of the Bayesian approach in what 25 we've talked about today is prudent. I think file:///F|/pg061709%20(2).txt (185 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00186 1 that everybody who speaks from a Bayesian point 2 of view is that it provides a precise summary 3 of the type of quantity you want, and that is, 4 what is the evidence. And so you could 5 combine, you do that with one data set or with 6 20 data sets, that's what I'm talking about. 7 So the general Bayesian thinking is 8 here's the evidence, these are exactly what you 9 want and need, and that's regardless of how you 10 combine everything. If you want to be better 11 than all the data that you have available and 12 it's relative good data, clean data, there is 13 no way to combine it in a format other than the 14 Bayesian way, because you need to adhere to, 15 there's lots of variation rules so that you 16 summarize it right. 17 DR. GOODMAN: Thank you very much. 18 We're going to break for lunch now, but 19 Dr. Normand, if you could keep in mind a 20 question that might arise later in the day, 21 which might be kind of a follow-on question, 22 which is: Okay, let's say you want to do this. 23 What would it take to operationalize this added 24 facility for the Agency to undertake Bayesian 25 approaches to evaluating evidence for coverage file:///F|/pg061709%20(2).txt (186 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00187 1 decisions? 2 Thank you. This has been a great 3 morning. I wish I could get a few college 4 credits for it. I know it's a little bit after 5 noon, but if we could try to reconvene at 6 one o'clock, I know we're shaving a few minutes 7 off for lunch, and if Dr. Sanders would be 8 ready to ascend the stage to the podium at 9 one o'clock, that would be wonderful. So we 10 will see you all back at about one. Thank you 11 very much. An enlightening morning it was, 12 thank you very much. 13 (Luncheon recess.) 14 DR. C. GOODMAN: After our 15 enlightening morning and a fulfilling lunch, we 16 are going to move to a two-part presentation, 17 starting with Gillian Sanders from Duke, and 18 she will tag team with Don Berry once again, 19 looking at the meta-analyses of ICDs. Dr. 20 Sanders, if you would. 21 DR. SANDERS: Sure. As you heard this 22 morning, a few years back CMS expressed an 23 interest in exploring the advantages and 24 disadvantages of Bayesian methods in RCTs, and 25 particularly those in the CMS policy and file:///F|/pg061709%20(2).txt (187 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00188 1 decision-making arena. So in collaboration 2 with AHRQ as partner with the Duke 3 Evidence-Based Practice Center, we performed a 4 systematic review of the literature and then 5 also used a case study to explore the use of 6 Bayesian methods in the CMS decision-making. 7 And together with CMS and AHRQ, we 8 chose the clinical debate of ICD therapy in the 9 prevention of sudden cardiac death, and it's 10 specifically the design of this case study that 11 I'm going to be talking about today. So just a 12 little bit of background. I'm not a Bayesian 13 statistician. My training is a Ph.D. in 14 medical schematics and I describe myself as a 15 medical decision analyst, and I really focus on 16 chronic disease modeling and then the 17 translation of these evidence-based models into 18 clinical practice and policy. I do, however, 19 in those policies use Bayesian methods 20 certainly to inform those decision models. 21 The collaborators on this project were 22 Lurdes Inoue, who's a matrix statistician based 23 at the University of Washington, who actually 24 trained with Don Berry. And then my colleagues 25 from Duke, Dave Matchar, Greg Samsa, Shalini 00189 1 Kulasingam. Greg is here today and available 2 to help with questions as well. 3 So, as any evidence-based practices 4 center review, it's guided by the feedback and 5 expertise from a technical expert panel. And 6 so here you will see the ones that were 7 associated with this project. On the left side 8 are eight investigators from the clinical 9 trials that we actually included in our 10 analysis, and then the other side are some, 11 four other members that represented some 12 statistical expertise in addition. 13 So as many of you know, sudden cardiac 14 death is the most common cause of death in the 15 U.S. and it accounts for up to 350,000 deaths 16 per year. Each year sudden cardiac death 17 claims the lives of more people than stroke, 18 lung cancer, breast cancer and AIDS combined. 19 And although the overall number of cardiac 20 deaths has decreased over the past decade, the 21 proportion of these cardiac deaths that are 22 sudden has increased. Of note here today, over 23 80 percent of sudden cardiac deaths occur in 24 patients that are 65 years and older, 25 highlighting particular interest to the CMS. file:///F|/pg061709%20(2).txt (189 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00190 1 Fortunately there's ways to prevent 2 sudden cardiac death. The implantable cardiac 3 defibrillator, or the ICD, is a device that 4 monitors the heart rhythms and delivers shocks 5 if these rhythms are detected. There's been 6 several clinical trials on ICD therapy, and 7 it's been demonstrated that their use can 8 significantly reduce mortality, and it's 9 currently the most effective therapy for 10 preventing sudden cardiac death. The 11 magnitude, however, of the effectiveness of the 12 ICD in clinically identified subgroups is 13 currently unclear. 14 In addition, ICD therapy is quite 15 expensive. Current CMS reimbursement is about 16 $30,000 per device implantation. And so 17 although evaluations of ICD cost effectiveness 18 by our group and by others have in general 19 demonstrated that the ICD is a valuable use of 20 our health care dollars, there are several 21 researchers and policy makers that certainly 22 looked at whether there could be ways of risk 23 stratifying the patients further to increase 24 the benefit and value of ICD placement. 25 In addition, the ICD represents a file:///F|/pg061709%20(2).txt (190 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00191 1 clinical domain and intervention which CMS has 2 evaluated several times over the last two 3 decades. Currently CMS only covers evidence 4 development concerning these devices in the 5 primary prevention of sudden cardiac death, 6 which reflects really the uncertainty of 7 several clinical policy questions. 8 So, this table shows some of the major 9 ICD RCTs and their timing, each column 10 represents a trial and -- I'm sorry, each trial 11 is a row, and then the columns are the years in 12 which the trial was ongoing. Those in green 13 are considered secondary prevention trials; 14 these are trials where the patient actually has 15 physically experienced sudden cardiac arrest 16 and therefore were at high risk for recurrent 17 events. 18 Unfortunately, most people don't 19 actually survive that original event, and so 20 the latter analyses and clinical trials were 21 really looking at what's considered primary 22 prevention of sudden cardiac death, and these 23 are patients that are at increased risk 24 compared to the general population but who 25 haven't had a previous ventricular event. file:///F|/pg061709%20(2).txt (191 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00192 1 In yellow here, I see there when the 2 findings in these trials were actually made 3 available and published, so that these could 4 then potentially be available for subsequent 5 trial design. For the analysis which I will 6 discuss here today, we received access to the 7 patient level data from eight of these trials, 8 namely all of them except for the CIDS and the 9 DINAMIT trial. 10 This table shows the clinical 11 characteristics for the eight trials considered 12 in our case study. There's a lot of 13 information here so I'm just going to highlight 14 a few things. First, note that the trials 15 considered in the case study differed in sample 16 size, with the smallest trial being MADIT-I, 17 having 196 patients, and the largest being 18 SCD-HEFT with 1,676 randomized to either ICD or 19 control. 20 Moreover, there are different 21 propositions across the trials. So for 22 example, some trials such as CABG, MADIT-I and 23 II, and MUSTT only have ischemic patients in 24 their populations, while the DEFINITE trial 25 only included nonischemic patients. The median file:///F|/pg061709%20(2).txt (192 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00193 1 age range was from 57 up to 65 years of age, 2 and the ejection fraction ranged from 20 3 percent in the DEFINITE trial up to 45 percent 4 in CASH. 5 And as you can see, the distribution 6 in the heart failure classes, it varies quite 7 widely but overall Class IV patients are very 8 poorly represented in the available trials. 9 In our analysis, CMS and AHRQ were 10 also interested in whether Bayesian methods 11 could be used in evaluating their registry 12 data. So we then borrowed data from the 13 ACC-NCDR ICD registry which was formed in 2005 14 following CMS's coverage development for ICD 15 therapy. The registry data collection process 16 covered over 130 different data elements, the 17 type of initial ICD implant, device upgrades, 18 and then also device replacements, and the data 19 we had access to was about 120,000 implants 20 between January of 2005 and June of 2007, and 21 the characteristics of the patients are 22 represented here. 23 Now compared to the patients that were 24 recruited to the actual ICD trials, the 25 registry patients are older and they actually file:///F|/pg061709%20(2).txt (193 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00194 1 have worse prognosis. Also, note that the 2 registry data are only for ICD patients, that 3 is, we don't have a control arm. And also, 4 currently the ICD registry does not have 5 follow-up information regarding the patient's 6 overall survival after discharge. 7 And so for the purpose of illustration 8 in our analysis here, we actually used registry 9 data from the MUSTT study which had survival 10 data associated with it to look at the survival 11 comparators in the clinical trials and registry 12 data, and I'll describe the method and issues 13 later when I get to those results. 14 So as I mentioned, even with existing 15 RCT evidence there are several clinical and 16 policy questions that have been remaining 17 unanswered. So this shows some of the 18 questions that we looked at in our analysis. 19 We looked at these both from a frequentist 20 approach and then also using Bayesian methods. 21 The major questions are: Are the patients 22 within the trials similar? Is there evidence 23 that the devices used in the different trials 24 differ in terms of their efficacies? Is there 25 evidence that the ICD is effective in file:///F|/pg061709%20(2).txt (194 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00195 1 particular patient subgroups? And can Bayesian 2 methods be used to say anything about prognosis 3 of patients within the ICD registry? 4 I will describe briefly some of the 5 methods we used in our case study. As I 6 mentioned, we considered patient level data 7 from eight trials, namely MADIT-I and II, 8 MUSTT, DEFINITE, SCD-HEFT, AVID, CASH and CABG. 9 We used overall survival as the primary 10 outcome, and the treatments considered were ICD 11 with controls. The studies now seem to focus 12 on four prognostic variables; these were age, 13 ejection fraction, the New York Heart 14 Association class, and the presence of ischemic 15 disease. Now there are certainly other 16 prognostic variables that may be as closely 17 important, for example, the cure interval or 18 time from MI, and we had a reviewer actually 19 explore these additional factors, but we really 20 wanted in this situation to explore the use of 21 the methods. 22 So we performed four sets of analyses, 23 so we used the data from individual trials, 24 combining data from all trials, the use of 25 registry data, and then to validate the impact file:///F|/pg061709%20(2).txt (195 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00196 1 we had access to aggregate versus patient level 2 data. Given our time constraints today, I'm 3 just going to skip over our analysis of the 4 individual trials and instead focus on the 5 remaining three sets of analyses. 6 In our analysis of data combining all 7 trials we used both frequentist and Bayesian 8 techniques to find data, we made adjustments 9 for potential trial effects, adjusted for trial 10 effects using fixed or random effects, and 11 assuming trial-specific baseline hazard 12 functions. Throughout our combined trials 13 analyses we used the frequentist data as the 14 priors we used in the Bayesian analyses. In 15 the analysis of the registry data, we used the 16 Bayesian methods to simulate the survival 17 experience of hypothetical patients in a 18 hypothetical new trial utilizing ICD and 19 control groups in patient subgroups, and then 20 compared the predicted and empirical survival 21 data. And finally, a unique feature of our 22 analysis was the availability of patient level 23 data as this data was published and becomes 24 available, and it becomes available as 25 subsequent trials get published. So we file:///F|/pg061709%20(2).txt (196 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00197 1 performed analyses that looked at two 2 additional points, what are the implications of 3 using aggregate data as opposed to patient 4 level data since that seems to provide the 5 efficacy, and by considering sequential 6 evidence in the trials, using the patient level 7 data, would we be able to reach a conclusion as 8 to overall ICD efficacy sooner. So there were 9 a lot of these analyses that are exploring 10 potential efficacy that Don Berry is going to 11 present next. 12 So this figure demonstrates the 13 results of combining data from all the trials 14 using either frequentist models which are the 15 diamonds labeled Weibull, or the Bayesian 16 models with the little squares labeled 17 Weibull-Bayes. The vertical extensions give a 18 look at the 95 percent confidence intervals, 19 and the box with different colors corresponds 20 to different modeling approaches used to 21 combine those trials. Within each block I put 22 without covariate adjustments and then the next 23 line we used covariate adjustment. 24 All the results showed evidence of 25 treatment effect on overall survival and as you file:///F|/pg061709%20(2).txt (197 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00198 1 can see from the results, they are very similar 2 across all the models. And although we're not 3 showing the results here today, the estimates 4 from combining data in small trials has a lower 5 uncertainty as compared to those from 6 individual trials. 7 Now these initial models relied on 8 drawing assumptions as to how we accommodate 9 trial differences, and in one extreme end we 10 defined data assuming that the trial is 11 similar; next we relaxed the assumption and 12 assumed that the trial differences were 13 accommodated with either fixed or random 14 effects and allows that inference across 15 specific hazard function. However, we have 16 allowed the effect of the prognostic variables 17 and their interaction to be similar across all 18 trials. 19 So, we actually wanted to have a more 20 flexible model to fill out across specific 21 effects of prognostic variables, and for this 22 we used a Bayesian hierarchical model which you 23 heard about this morning from Dr. Lewis. And 24 that allows, because not all subgroups are 25 represented in all trials, for example ischemic file:///F|/pg061709%20(2).txt (198 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00199 1 changes in heart failure Class IV patients, we 2 know that equivalent models cannot be estimated 3 using traditional frequentist methods. 4 So this figure demonstrates several 5 things. The different trials are shown going 6 up the Y axis with the overall data, combining 7 data here at the top in the black. The X axis 8 indicates the treatment effects, with a 9 vertical dashed line at zero meaning there was 10 no effect with standard treatment or ICD 11 therapy. Pretrial there is two lines showing 12 how different priors affect the findings. 13 Prior two is dashed, it's more informative in 14 predicting the uncertainty, so you know, the 15 interval is narrower. 16 Looking at this figure, you could 17 actually pose two important questions. Number 18 one, is there evidence that the devices used in 19 the different trials differed in terms of their 20 efficacies? And number two, controlling for 21 ejection fraction and ischemia in the NYHA 22 heart failure classes, are the patients within 23 the available trials similar? 24 Now notice that the results may be 25 confounded with the trial, but considering the file:///F|/pg061709%20(2).txt (199 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00200 1 Bayesian hierarchical model that may affect 2 some of the differential effects across trials, 3 we see that the ICD efficacy varies across the 4 different trials. 5 Why does this, however, instill 6 uncertainty? This could be due to differences 7 in the devices, certainly in supplemental 8 trials we found other trials that had more 9 variability, but it also could be due to the 10 patient population being different with the 11 trial, even after controlling for the ejection 12 fraction, ischemia and heart failure class. 13 To show this in another format, we 14 show here the median hazard ratio at a 95 15 percent confidence interval for the effective 16 ICD treatment on the individual trials, and 17 then for the entire population of trials at the 18 bottom in black. We also provide the posterior 19 probability that the hazard ratios of mortality 20 reduction be .8 or less, and this was 21 considered by a panel to be a clinically 22 important reduction in mortality. 23 So for example, a lower than 95 24 percent confidence here for the overall hazard 25 ratio includes the value of no treatment, or file:///F|/pg061709%20(2).txt (200 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00201 1 includes one, with an 82 percent probability 2 the hazard ratio is .8 or less, indicating a 3 clinically important reduction. 4 So we then wanted to explore whether 5 there was evidence of the ICD with respect to 6 the patients with different clinical 7 characteristics. You can see the differences 8 on this figure, and then we actually have a few 9 of them in a row. Again on the Y axis are the 10 different clinical trials with the combined 11 effect at the top. The two lines again 12 represent findings under two different priors, 13 with a red line reflecting a more informative 14 prior. The dot represents the median and this 15 is the line for a 95 percent confidence 16 interval. Things to the left of the dashed 17 line, or the vertical dashed line, indicates 18 that there is evidence of treatment effect, and 19 things on the right favor control therapy. 20 These analyses were performed using 21 the Bayesian hierarchical model to allow 22 further actions with differentials across 23 models. This slide looks at the efficacy of 24 the ICD in patients between the ages of 65 and 25 75. We next show the evidence of patients over file:///F|/pg061709%20(2).txt (201 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00202 1 75. We looked at, again, patients with 2 ejection fraction greater than 30 percent. One 3 thing to note is that in most of the clinical 4 trials in their inclusion criteria, they had an 5 ejection fraction of 35 or 40 percent as an 6 upper bound. 7 We also explored the effectiveness of 8 ICD therapy across different heart failure 9 classes. This shows Class II, we have Class 10 III, and then finally with Class IV. Here we 11 actually see an example of how with a more 12 informative prior, we're much less likely to 13 see high absolute values for the hazard ratio. 14 And because of the lack of patients in Class IV 15 in the different trials, they are also a less 16 informative prior. So the upper bounds of the 17 intervals is valueless and they are probably 18 too large clinically to be believable. So in 19 order to find a more informative prior we 20 actually narrowed down these examples, so you 21 can see that still across these trials, there 22 is not enough information to actually cite to 23 the evidence of the ICD. 24 So this slide, again, shows a kind of 25 ratio in the clinical trials reviewed for the file:///F|/pg061709%20(2).txt (202 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00203 1 Class IV patients, and note that not only is 2 there no evidence of a significant interaction, 3 but now there's only a 49 percent probability 4 that the hazard ratio is .8 or less. 5 And finally, we evaluated the evidence 6 for ICD effectiveness in patients with ischemic 7 disease, and here for example you can see that 8 the DEFINITE trial, which as I indicated before 9 was all nonischemic patients, so I didn't 10 actually have any ischemic patients in their 11 trial, we're able to borrow from the other 12 trials to substitute and actually provide an 13 estimate, but obviously the credible interval 14 is increased as well. 15 So, another feature of a Bayesian 16 hierarchical model is that it allows for the 17 baseline survival functions to vary from trial 18 to trial, so this figure shows the estimated 19 posterior baseline survival functions under 20 each trial, and then overall trials in black. 21 So even controlling for ejection fraction, 22 ischemia, age and heart failure class, the 23 figures indicate that a patient's baseline 24 survival differs across the different trials. 25 So for example, patients in the file:///F|/pg061709%20(2).txt (203 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00204 1 SCD-HEFT trial, shown in purple, seemed to have 2 the best survival prognosis, while patients in 3 the CABGPATCH and MUSTT have a poorer survival, 4 and we found several possible explanations for 5 this difference. The variation of the 6 cross-trial inferences, in the type of devices, 7 in the underlying medical care, in the patient 8 populations, or in patients whose 9 characteristics are currently not included in 10 our analysis, for example, gender, hazard 11 interval, time from MI, or a prior ventricular 12 event. 13 In this slide we wanted to see if 14 there were specific patient subgroups in which 15 the ICD was particularly ineffective or 16 effective. From my analysis, the evidence 17 showed there was no evidence for differential 18 treatment effect in the individual subgroups we 19 looked at. So here we actually showed that 20 there were five subgroups where the posterior 21 possibility that the hazard ratio for mortality 22 was less than .8 was greater than 75 percent, 23 so it will have an effect on what your decision 24 rule is going to be for determining 25 effectiveness. file:///F|/pg061709%20(2).txt (204 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00205 1 Also note that we don't show here, but 2 we also looked at studies that included Class 3 IV patients, and the hazard ratio being less 4 than .8 was actually 50 percent or less. 5 So some of the key findings we 6 demonstrated through these analyses is that 7 first under all model formulations, both 8 frequentist and Bayesian, there seemed to be 9 evidence for the efficacy of overall survival. 10 Second, in this particular clinical domain and 11 intervention, evidence from Bayesian models are 12 generally similar to those obtained under those 13 frequentist models. 14 Evidence obtained through combining 15 data from all trials has lowered uncertainties 16 compared to those from individual trials. And 17 analyses of the combined data prove our 18 inferences by increasing the precision of our 19 estimates as well as the power to detect main 20 effects and interactions. Finally, the 21 Bayesian techniques allow us to examine 22 questions that may not be possible under 23 traditional frequentist methods. For example, 24 by borrowing data across trials, we're able to 25 examine differential effects between given file:///F|/pg061709%20(2).txt (205 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00206 1 patient level subgroups even if an individual 2 trial does not include these subgroups. 3 We next wanted to explore the Bayesian 4 method looking at registry data. As I noted, 5 the current ICD registry doesn't have 6 longitudinal follow-up, so for those three 7 methods we actually used data from the MUSTT 8 registry, the one trial that had a registry 9 alongside the trial, and we noted that patients 10 in the MUSTT registry are actually both 11 different from those in the clinical trials, as 12 well as different characteristics from those in 13 the ICD. 14 So here we'll be showing some 15 prediction survival for patients and we're 16 looking at different subgroups. This is for 17 patients aged between 55 and 75, ejection 18 fraction less than 30, New York Heart 19 Association Class II, and with ischemic 20 disease. And we find here both in the 21 posterior predicted survival for the control 22 shown in blue, and then the ICD patient shown 23 in red, and then what we observed from these 24 same patients in the MUSTT registry in black. 25 And if you just focus on the control, you can file:///F|/pg061709%20(2).txt (206 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00207 1 see how they're reflected in the MUSTT 2 registry. 3 So as you can see here, control 4 patients in the MUSTT registry actually have 5 better survival earlier on in the predictive 6 prior model, but are more comparable to the 7 predicted survival in later years. So although 8 the Bayesian model is based on the clinical 9 trial data, for a lot of the predicted survival 10 experience in each of the subgroups of interest 11 longitudinal data is so important because the 12 clinical trial patients are often different 13 from those in the registries. The MUSTT 14 registry actually illustrated this point, that 15 empirical survivor rate was quite different 16 from what we predicted from the model. 17 DR. C. GOODMAN: Dr. Sanders, you had 18 asked me for one warning. 19 DR. SANDERS: Okay, great. 20 As you attempt to borrow information 21 across trials, the Bayesian model allows you to 22 predict survival even if the individual trial 23 does not include some of the subgroups, and 24 again, this model cannot be estimated using 25 simply frequentist methods. We just show here file:///F|/pg061709%20(2).txt (207 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00208 1 other subgroups with both the predicted 2 survival and that observed in the MUSTT 3 registry. 4 So finally, we turn to the analysis of 5 the aggregate versus patient level data, and 6 there is a lot of information in this 7 particular figure so again, I'm going to try to 8 orient you. On the X axis we looked at the 9 number of trials that we said were available to 10 combine and we assumed that the trials are 11 combined in the order of their publication 12 dates. We then provide estimates of the ICD 13 effectiveness under the separate modeling 14 assumptions. A frequentist takes the aggregate 15 effects shown in black, and then the dashed red 16 and blue lines refer to the Bayesian model with 17 fixed effects, and the solid lines are Bayesian 18 models with random effects, and the Bayesian 19 models we did it under two different priors to 20 allow that sensitivity offset as well. 21 And as you can see, with the 22 accumulated data from trials, there is a 95 23 percent credible, or under both priors the 24 posterior credibles get narrower, but the gain 25 of information from additional data is greater file:///F|/pg061709%20(2).txt (208 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00209 1 than those less informative priors. And also 2 these figures show how with two priors when 3 combining RCT data from the trials, we can only 4 find one line of overall ICD efficacy under one 5 prior, but we do not rule out no efficacy under 6 the alternative prior. 7 And this contrasts, this figure shows 8 the results of analysis when taking patient 9 level data sequentially. And as we combine 10 data from more trials, it actually becomes more 11 similar and precise. Using the more 12 informative prior, we were able to see the ICD 13 with efficacy sooner with six trials. 14 So something to note, while the 15 results from aggregate Bayesian analysis are 16 not necessarily consistent with those obtained 17 using patient level data, their accuracy could 18 be based on additional sources of variation, 19 for example those that explain patient 20 variation specifically in the study. And 21 second, combining the data from trials 22 sequentially, either through aggregate or 23 patient level data, may allow us to conclude 24 overall efficacy sooner. As already pointed 25 out, though, and we saw it earlier today, such file:///F|/pg061709%20(2).txt (209 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00210 1 analyses must clarify the role of priors for 2 reaching such a conclusion. 3 So, some final comments about our 4 analyses. As we've shown, one of the main 5 advantages of Bayesian methods is that they 6 allow the borrowing of information across 7 trials and subgroups, and they enable us to 8 estimate effects within specific subgroups even 9 if those subgroups are not represented within a 10 given trial. Note, however, the finding is 11 dependent on the chosen prior, and also that 12 such analysis would not be feasible under a 13 frequentist approach if the data in any given 14 subgroup is not available. Also note that the 15 availability of patient level data such as we 16 had in our analysis allows us to directly 17 adjust for covariates within a population, 18 potentially explaining the differences in trial 19 outcomes. 20 So, here are some of the lessons that 21 we've learned through our analysis, and these 22 are supported by our case study that I talked 23 about today, but also through our literature 24 review and the simulation studies which were 25 performed as part of the work. file:///F|/pg061709%20(2).txt (210 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00211 1 First, we only want to consider claims 2 about differential effect, subgroup effects if 3 they're accompanied by a formal statistical 4 test for interaction. 5 Second, consider all sources of data 6 in order to stipulate within the statistical 7 model which types of interaction are likely. 8 Third, base study design and 9 decision-making on those subgroup effects that 10 are likely to be strong. 11 Fourth, if the trial-based data are 12 sufficient, do not directly combine trial-based 13 data with information from other sources such 14 as observational data and/or expert opinion in 15 a setting when you're looking for validation. 16 When little or no trial-based 17 information about a subgroup is available, 18 really consider the use of other data in order 19 to specify a prior distribution, and you will 20 use this information to plan future studies. 21 And finally, claims based on Bayesian 22 methods should always include sensitivity 23 analyses to the assumed priors. 24 So just in summary, Bayesian 25 approaches provide a formal method of learning file:///F|/pg061709%20(2).txt (211 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00212 1 from the evidence and accumulating, and we 2 believe that incorporating these findings in 3 the CMS decision-making processes will enable 4 the policy makers to harness really the power 5 of the available evidence, explore subgroup 6 effects within a trial or across trials in a 7 methodologically rigorous manner, assess the 8 uncertainty of clinical trial findings, and 9 ideally improve the health outcomes of the 10 Medicare beneficiaries. 11 I will now turn it over to Don to 12 present his findings and related analysis. 13 DR. BERRY: Thank you, Gillian. 14 DR. C. GOODMAN: Dr. Sanders, while 15 we're waiting, Dr. Satya-Murti has a question 16 for you, if you don't mind. 17 DR. SATYA-MURTI: Trying to double up 18 here. On the interaction, can you give us a 19 promised interaction and then if it fails, is 20 there a way to quantify interaction, an example 21 of what interaction you were dealing with in 22 the strongest or the most disturbing 23 interaction? 24 DR. C. GOODMAN: Can you please go to 25 the microphone, Dr. Sanders? file:///F|/pg061709%20(2).txt (212 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00213 1 (Inaudible colloquy.) 2 DR. SATYA-MURTI: Yeah, give a 3 clinical example so I can relate it. 4 DR. SANDERS: Right. So I think, I'm 5 trying to remember a table, but the one where 6 we showed the ones where the subgroups were 7 greater than 75 percent probability, so I think 8 those were ones which were actually, I think 9 they were younger patients with low ejection 10 fractions. 11 DR. SATYA-MURTI: So what was the 12 interaction occurring? 13 DR. SANDERS: Oh, you mean what was 14 the actual endpoint? 15 DR. SATYA-MURTI: No. Was it because 16 they were younger and there was a third 17 independent variable that spoiled the results? 18 DR. SANDERS: I'm not sure. 19 DR. C. GOODMAN: I'll tell you what. 20 Why don't we hold off on answering that 21 question. Don, are you up? 22 DR. BERRY: Sorry about that, take it 23 off my time or my hide or something. 24 These are coauthors, or this is joint 25 with Bryan Luce, Jack Ishak and Craig Hunter of file:///F|/pg061709%20(2).txt (213 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00214 1 United BioSource. We were actually funded by 2 Boston Scientific, who when they got the 3 request from Duke for the data, said gee, 4 what's going to happen and can you, you know, 5 BioSource, can you use the data that's 6 available to predict what the Duke study is 7 going to show? And so we did that as best we 8 could. 9 We used only published studies, so 10 even though Boston Scientific has their own 11 data, we didn't ask for that and in fact we 12 specifically said we didn't want it, we'll do a 13 purely literature-based analysis based on our 14 criteria for including studies, which was 15 randomization of ICD versus not, and all of the 16 information that we have is publicly available. 17 In getting our estimates of what the 18 survival was, we actually took out rulers and 19 put them down on the survival curves to 20 estimate what the values were of the various 21 things for the individual studies. So as Scott 22 indicates, Bayesian analysis is meta-analysis, 23 it's inherently synthetic as you've heard, 24 through all of the information that's 25 available, and you do modeling. It's file:///F|/pg061709%20(2).txt (214 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00215 1 inherently, as Gillian said, the Bayesian fixed 2 effects, but recognizing the uncertainty 3 associated with the study effects and the 4 hazards associated with periods of time is a 5 natural thing for Bayesians. 6 As you see, we did a synthesis across 7 all of the studies, we estimated the individual 8 study effect. As Roger Lewis indicated today, 9 this shrinkage being a, or giving rise to 10 better estimates, and we saw some of that in 11 Gillian's presentation, the greater precision 12 associated with modeling that looks at results 13 over time, and we did predictions. So here we 14 are today at some point over the course of when 15 these trials were approved with some 16 information, should we do another study? And 17 if we did with particular characteristics, 18 what's it going to show? 19 So we imitated that process for each 20 study along the way and predicted its results 21 based on this hierarchical model. So we model 22 the sources of variation, we look at mortality 23 rates over time in terms of annual risks, we 24 explore the potential time intended effect of 25 ICD. So you'll see, it turns out that the file:///F|/pg061709%20(2).txt (215 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00216 1 effect is not that dependent on time. But in 2 many cases, cancer, for example, cancer is 3 really a heterogeneous disease, the more 4 aggressive disease kills early, and the at risk 5 population is therefore a more indolent form of 6 disease and so the hazards tend to drop. So 7 you see high hazards early on, then it drops. 8 And in cardiovascular settings, for 9 example I mentioned the placement of catheter 10 in a-fib, and there's this huge recurrence of 11 a-fib in the first month, but then the at risk 12 population changes and it drops considerably, 13 so we wanted to model that process. You will 14 see that it didn't matter too much, but we 15 incorporated it in our models. 16 We've accumulated data and illustrated 17 the accrual of evidence with each study, and we 18 answered the question, when did the evidence 19 become conclusive, and how will we predict the 20 next study. 21 So, I will come back to which studies 22 we used. We did not know what studies Duke was 23 going to use, we used all of the available 24 randomized trials. The one that's not on here 25 is MUSTT, but there are some that Gillian did file:///F|/pg061709%20(2).txt (216 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00217 1 not incorporate, presumably because she didn't 2 have the data. 3 And I have to say that I have done 4 meta-analysis where I have the data, for 5 example I have the data for all the randomized 6 trials of bone marrow transplant, both adjuvant 7 and metastatic, and it's enormously valuable to 8 be able to address such subgroups. So for 9 example, young patients or some of the 10 individual studies had shown that young 11 patients would benefit from bone marrow 12 transplant. If you want to know what the other 13 study showed, it's not verified. Some had 14 shown that HER2 negative patients might fail 15 but other studies showed that that wasn't the 16 case. So it's very important to have the 17 individual patient data, and we did not have 18 it. 19 Endpoint is mortality. Decomposed is 20 not a good word for Scott to use in that case. 21 (Laughter.) 22 We dissected the Kaplan-Meier curves, 23 did a Bayesian hierarchical model for the time 24 of death, and we did -- this is going to be 25 confusing to you because Gillian did several file:///F|/pg061709%20(2).txt (217 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00218 1 models and we too did several models. 2 The first model -- and I'm not going 3 to go through the formulas that you've got 4 there. The first model is one that assumes 5 constant hazard over the five-year period 6 within each treatment and across the studies, 7 except that there is a study effect that's 8 incorporated as a covariate. It assumes the 9 same treatment effect in all of the studies but 10 it allows for the differential hazards over 11 time. 12 The model two allows for different 13 hazard ratios over time, so it's possible that 14 the effect of the device, the ICD is different 15 in the first year than in the second year, than 16 in the third year, et cetera, and so model two 17 allows for the possibility that the ICD effect 18 is different in the different time periods. 19 Model three allows for a different 20 effect of the treatment across the various 21 studies. So this, you see, is the study effect 22 and treatment effect, and this lambda stuff 23 merely represents the different hazards, and 24 you will see those in the pictures that I'm 25 showing you. These are the hierarchical study file:///F|/pg061709%20(2).txt (218 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00219 1 effects; the one that's critical here for those 2 of you that are into this, is this thing that 3 Roger Lewis talked about, the hyperdistribution 4 of the study effects, the heterogeneity of it, 5 and the variance associated with that. That's, 6 the conclusions are in meta-analysis very 7 sensitive to that variable. 8 So model two, as I indicated, is 9 allowing for different treatment effects over 10 time and model three is this different study 11 effects. 12 So this is model one for all of the 13 studies, this is a relative risk of .77, so a 14 22 percent reduction in the risk of mortality 15 is contemplated. The probability that ICD is 16 effective in lowering that, there is a 17 probability that this hazard ratio is one, is 18 essentially one. 19 Model two, the time variable allowing 20 for -- I was going to come back to this, but 21 let me show you a picture. So this is the 22 picture of model one versus model two. So 23 focus on the solid lines here, so that's model 24 one control, this is model one ICD, is solid to 25 solid, forget about the dashes for just a file:///F|/pg061709%20(2).txt (219 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00220 1 moment. That's in the first year, so there was 2 about a 17 percent mortality in the first year 3 in the control group and about a 13 percent in 4 the ICD group in the first year. Now these are 5 removed from the at risk population. 6 The second year hazard, the proportion 7 of those who went into the second year who 8 experienced an event in the control group, who 9 died, was about 14 percent versus 11 percent in 10 the device, in the ICD group in the second 11 year. And you see that the solid line seems 12 separated by about the same amount, and in the 13 large odds scale it is exactly the same amount. 14 That's model one. Model one says the benefit 15 of the device is the same for each one of these 16 periods. The underlying risk can differ over 17 time, but the benefits are the same. 18 Model two allows for, it's a 19 completely different and independent modeling 20 in this year than in this year and in this 21 year, et cetera. And so it happens if you see 22 something very similar in the first year for 23 comparing the control versus the ICD, it's a 24 little bit wider in the second year, you know, 25 it's, you know, it's very similar to model one file:///F|/pg061709%20(2).txt (220 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00221 1 actually, except in the fourth year. In the 2 fourth year, you know, it's a tiny bit, a tad 3 better than the control group, and then back 4 to, you know, the same sort of thing in year 5 five. 6 So the previous slide -- oh, and this 7 is simply the survival version, this is cut at 8 like 50 percent of it. 9 So to go back, this then is the 10 estimated relative risk and it's, again, like 11 five different studies, combining the data from 12 all of the trials in the five different 13 studies. This is the relative risk in the 14 first year, in the second year, et cetera, and 15 that reflects the fact that there wasn't too 16 much difference in that fourth year. 17 This is merely to show the study 18 effect of model one, so we're modeling 19 heterogeneity in the results and this, MADIT-1 20 had something that we tagged as being one, so 21 this is a reference study, there is no 22 treatment in here, this is only what is the 23 population looking over time in these 30 24 studies, and what you can see is they tend to 25 get better over time, it's not unusual. file:///F|/pg061709%20(2).txt (221 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00222 1 I keep fighting, I keep predicting 2 results in breast cancer, breast cancer's 3 getting incredibly better over time, and I'm 4 always undershooting. This suggests the same 5 thing. 6 DR. C. GOODMAN: Don, about four 7 minutes. 8 DR. BERRY: Four minutes, okay. So 9 this is a comparison allowing for the study to 10 be different and this is just MADIT-I by 11 itself, this is AVID by itself and what it 12 would be, allowing for the heterogeneity in the 13 populations, you see that the reds tend to be a 14 little better. 15 This is the same page that Roger was 16 showing you. 17 This is chronological risks in the 18 model one, so it starts out, MADIT-I is the 19 only thing that's known at that time, so this 20 red is equal to black. The red is the Bayesian 21 meta-analysis of the first three studies and 22 interestingly, the effect here is about here, 23 it's about here, you know, it's going down a 24 little bit with time, but it's pretty 25 predictive, so after three studies we knew more file:///F|/pg061709%20(2).txt (222 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00223 1 or less what the answer was going to be, and 2 that is what that is intended to show. 3 This is predictive analysis, so here 4 we are with MADIT, let's predict AVID based on 5 either model one or model three, and so model 6 one predicts AVID to be like this thing, and 7 this is the actual AVID. It predicts CABG to 8 be this thing and this is the actual CABG. 9 Coming further along you see that MADIT-II had 10 this predicted value in model one, this 11 predicted value in model three, and that was 12 the answer. So the ability to do this 13 prediction shouldn't -- and of course the 14 widths of these things depend on the size of 15 the trial, and so it's useful for designing 16 trials, for instance. 17 This is the Duke studies that were 18 included, so they did not include CIDS or CASH 19 or any of these, and they included this but we 20 did not. And just to show you the comparison, 21 this is what you saw before for model one and 22 model two, so these numbers are exactly the 23 same as the previous slide. This is what you 24 get if you use the eight studies that were 25 included in the Duke analysis but using our file:///F|/pg061709%20(2).txt (223 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00224 1 methodology, and the interesting thing is that 2 the overall benefit in the Duke studies is 3 greater, and that's partly because of MUSTT, 4 but it's also partly because COMPANION was not 5 included and COMPANION was not that positive, 6 and we did include it. It still is the case 7 that the probability of the benefit is one, and 8 in each one of these relative risks, that 9 advantages by ICD is improved. 10 So, high points, 22 percent reduction 11 of the risk. In fact it's persistent, 12 consistent, we saw it was known pretty early, 13 accounted for changes in patient population. 14 Only analyses of published data. We did no 15 individual covariate modeling. 16 So I will stop, thanks. 17 DR. C. GOODMAN: Thank you very much, 18 Don. Before we change our focused attention to 19 the center mic, does our panel, do any of our 20 panelists have a question on the presentations 21 we just heard from Drs. Sanders and Berry 22 before we proceed? Yes, Mark. 23 DR. HLATKY: I was intrigued by the 24 fact that you did a completely independent 25 analysis knowing that somebody was going to do file:///F|/pg061709%20(2).txt (224 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00225 1 an analysis, and I wonder if you would draw any 2 conclusion about, in doing these models, 3 whether it's a good idea to have independent 4 replication from a separate team, given all the 5 stuff that goes into modeling. Is that an 6 important thing in public decisions like these? 7 DR. BERRY: I think it's a great idea. 8 I talked earlier on about CISNET where we had 9 seven modelers, they were using the same data 10 but with different modelers, so we got to 11 assess with the seven modelers, what is the 12 variable in the modeling process, and it's 13 substantial, there were differences in the 14 various conclusions as to the relative benefits 15 of screening and adjuvant therapy. 16 Here there's a different dimension 17 because Gillian had more data than I did, we 18 used different studies, so it's apples and 19 oranges in a way. But I think it's an 20 absolutely important thing to assess the 21 modeling ability and, you know, models, all 22 models are wrong, and to assess, you know, the 23 heterogeneity in that process by including at 24 least a couple of models. 25 DR. SANDERS: I certainly agree. I file:///F|/pg061709%20(2).txt (225 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00226 1 think that one of the ways to validate a model 2 is a situation like this where you can actually 3 look at the assumptions you made, you know, Don 4 was able to look at which of the trials we used 5 and then see whether those particular models 6 were going to yield similar results. And, you 7 know, the finish to that thing that I said, 8 that all models are wrong, but some are useful, 9 so I think it's certainly a good exercise here. 10 DR. C. GOODMAN: Dr. Prager. 11 DR. PRAGER: Gillian, I was intrigued 12 by the way you broke these things down and I 13 assume that none of the studies that were done 14 utilized any of your methodology when they went 15 for approval of their device; is that right? 16 DR. SANDERS: No, they were all done 17 using frequentist methods. 18 DR. PRAGER: Because if we looked 19 closely at the CABG study the way you 20 stratified it, it has negligible treatment 21 effect in everything except patients with 22 ejection fraction of greater than 30 percent 23 and -- 24 DR. SANDERS: Well, CABG actually is, 25 the CABG trial was not a very positive trial. file:///F|/pg061709%20(2).txt (226 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00227 1 I mean, the individual trials of CABG, DINAMIT, 2 I'm trying to think of which two, is it CASH, 3 they all varied in terms of their individual 4 trials in terms of effectiveness. But I think 5 what the difference is is that in our analysis 6 we're able to borrow information from all the 7 other trials. And so with the CABG, although 8 it gives you the estimate for the individual 9 trial, there's actually more information on 10 those types of patients from all the other 11 trials, so it is not going to give you the same 12 result as when you look at the CABG data from 13 their publication. 14 DR. PRAGER: Okay. But nevertheless, 15 now when you look at it this way it looks like 16 there's very little efficacy there, and I mean 17 to me, if I were a decision-maker making a 18 decision on whether to approve this specific 19 device, whatever was in this study, I would 20 have to say it has negligible effect in 21 everybody except those with an ejection 22 fraction greater than 30 percent. And just, 23 how can you see this feeding into the process? 24 DR. SANDERS: Right. I think this 25 adds to verifying what your decision rule is file:///F|/pg061709%20(2).txt (227 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00228 1 and how you're actually going to use this 2 Bayesian information. So that's where I tried 3 to present that information about where the 4 hazards ratio is going to be less than .8, so 5 that would be seen, at least by the 6 cardiologists on our project, as being a 7 clinically significant reduction. So there 8 were certainly subgroups where that happened. 9 But for the individual subgroups there wasn't a 10 subgroup that we could point to saying, you 11 know, for that to be for this one group, and 12 that's where you're getting this really great 13 background. 14 DR. C. GOODMAN: Dr. Maisel. 15 DR. MAISEL: First of all, Gillian, as 16 the others have mentioned, I found your 17 presentation extremely interesting. I think 18 that looking at the slides you had maybe about 19 four or five from the end, those nice graphs 20 where you did the different models and the 21 frequentist and the Bayesian analysis, I'm 22 struck by a couple of things. 23 The most striking theme to me is that 24 it really matters what model and what prior 25 probability you choose to use for your model, file:///F|/pg061709%20(2).txt (228 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00229 1 so the graded variability on that graph is 2 between the various Bayesian models that you 3 did, and so how do we know which model is the 4 right model? And I know there's no answer to 5 that, but my point simply is, it doesn't seem 6 any different on some level from, you know, you 7 can play statistical games and create a model 8 that looks good or you can create a model that 9 looks bad, so how do we know which one to 10 believe? 11 DR. SANDERS: I think, actually, Don 12 would be better to answer that. 13 DR. BERRY: So the good news with 14 respect to that is, as you heard from Roger and 15 Steve this morning, also Gillian, it's 16 transparent. I mean, you know if you assume 17 this, then you get that. And then you can go 18 back and say do I want to assume this, is that, 19 my prior, is that a reasonable prior for 20 policy-making, and to compare the various 21 priors. If it turns out that the answers still 22 vary over the range of what you think are the 23 reasonable trials, then you're not ready to 24 make the decision. I mean, very qualitatively, 25 you're not going to make a decision, and you file:///F|/pg061709%20(2).txt (229 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00230 1 may say we've got to fund a study to go out and 2 address this question because we don't yet know 3 the answer. 4 DR. C. GOODMAN: Thank you. Let us 5 revisit, briefly, Dr. Satya-Murti's question. 6 DR. SANDERS: Right. So the things 7 that we were actually exposed to, in our 8 overall we were seeing about .65 hazard ratios. 9 In those particular subgroups where it looked 10 like there was at least some higher 11 probabilities of the benefit, it ranged from 12 about maybe .52 to .58, and in the groups with 13 the Class IV patients it's about .8 up to .99. 14 So, you know, it's not, it's not huge 15 differences in the hazard ratios but there 16 certainly are differences. 17 DR. SATYA-MURTI: Yeah, that helps. 18 You have cautioned us to look for interaction, 19 so as I understand interaction, it's a surprise 20 third variable; is that a fair way of labeling 21 that? 22 DR. BERRY: I think so. Interactions, 23 there's a close relationship between subset 24 analysis and interactions. So subset analysis 25 you may ask, in this subset of patients, you file:///F|/pg061709%20(2).txt (230 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00231 1 know, the less than 30 percent, is there a 2 different treatment effect than in the greater 3 than 30 percent complementary subset? And a 4 statistician usually tests that by way of 5 interaction, in cancer we call it predictive 6 markers. And it's very difficult -- I don't 7 know the answer to this particular question, 8 but it's very difficult to show interactions, 9 and so statisticians become, as kind of a 10 breed, very conservative with respect to this 11 question. 12 The usual basis is that there is no 13 interaction and to show it is very difficult, 14 so it takes a lot of evidence to show an 15 interaction and roughly speaking, you want to 16 look for an extremely large or small posterior 17 probability or extremely low P value, something 18 that would be, in your word surprising, or 19 there'd better be a biology associated with it. 20 Now, recognize that the human mind is 21 wonderfully capable of making up biological 22 explanations for any observation. 23 The third possibility is that you have 24 to go through a confirmation study. 25 DR. SATYA-MURTI: The reason I was file:///F|/pg061709%20(2).txt (231 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00232 1 asking what that interaction, the third 2 variable is, I'm just hoping, could we put to 3 use, would that have a basis for further 4 studies from here on, we need to watch out for 5 that? 6 DR. SANDERS: It certainly might 7 affect the design and what kind of patient 8 population you might want to do the next study 9 on. I mean, if this is, the coverage decision 10 for ICD therapy is focusing really on patients 11 in different New York Heart Association 12 classes, various time from MI, which were 13 identified kind of a priori from the existing 14 clinical trials with subgroups where there 15 wasn't as much evidence, and this is certainly 16 supportive of the need for more efforts in this 17 group. 18 DR. SATYA-MURTI: Thank you. 19 DR. GOODMAN: Okay. We're going to 20 change -- 21 DR. BERRY: Can I just add one more 22 anecdote, because some people laughed when I 23 said something this morning about subsets. 24 DR. C. GOODMAN: Yes, Dr. Berry. 25 DR. BERRY: So, ER positive/HER2 file:///F|/pg061709%20(2).txt (232 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00233 1 negative breast cancer, that's more than 50 2 percent of the breast cancer. If you do a 3 subset analysis breaking it into various 4 pieces, you find that Taxol, any taxane does 5 not benefit that group. We've seen it in 6 thousands and thousands of patients. If you 7 ask now somebody from Peoria how they treat 8 those patients, they give them Taxol. 9 DR. C. GOODMAN: Thank you. We're now 10 going to change our focus to scheduled public 11 comments and so we will pause now while we turn 12 toward the center mic. And our first and 13 perhaps last scheduled public commenter is 14 Dr. Bryan Luce. Dr. Luce is going to give his 15 public comment, and I am reminded to say that 16 speakers are asked to state whether or not they 17 have financial involvement with manufacturers 18 or other interests. 19 DR. LUCE: Thank you. Yes, my name is 20 Bryan Luce. I have some financial involvement 21 in the sense that I was a co-author of the 22 paper you saw through Don Berry. I'm very 23 involved with Bayesian methods development and 24 have both industry and some public sponsorship 25 to develop those methods. file:///F|/pg061709%20(2).txt (233 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00234 1 So let me begin my remarks by first 2 thanking CMS and the committee for this 3 opportunity to comment. More importantly, I 4 wish to note that I'm impressed with CMS's 5 interest in exploring novel analytical methods 6 in a quest to improve efficiency and 7 effectiveness in coverage decision-making, and 8 I am particularly pleased that CMS is exploring 9 Bayesian methods for its coverage decision 10 process. 11 For purposes of disclosure, I do wish 12 to note my long and firmly held belief that all 13 decision processes including Medicare coverage 14 decisions as well as the decision process 15 itself are conceptually Bayesian processes, 16 whether formalized or not. I also wish to 17 disclose that I have founded the Bayesian 18 Initiative for Health Economics and Outcomes 19 Research, and more recently have founded and 20 direct the PACE Initiative, which stands for 21 pragmatic approaches to comparative 22 effectiveness, and initially it's focusing 23 specifically on the application of Bayesian 24 methods in looking at comparative trials. 25 My statement today changes a little file:///F|/pg061709%20(2).txt (234 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00235 1 bit, not too much, but it specifically 2 addresses the issue relative to conditional 3 coverage expressed specifically by CMS's 4 coverage and evidence development. 5 As I was listening this morning, I 6 would argue that the concepts of adaptive and 7 predictive probabilities scream coverage 8 (inaudible). As I see it, the CED process is 9 conceptually and almost literally a Bayesian 10 process. It is a learning and updating 11 evidence for the decision-making process. For 12 instance, typically if not always, CMS has 13 chosen to consider a new clinical procedure or 14 technology for a national coverage decision. 15 It reviews the evidence often formally, for 16 instance by our systematic review of 17 literature, other existing reports, even expert 18 opinion, and often a technology assessment from 19 AHRQ. From the Bayesian perspective, CMS would 20 now have an informative prior. 21 After full review and consideration, 22 should existing evidence be judged by CMS as 23 promising but not sufficient, for example there 24 may be inadequate evidence with respect to 25 Medicare beneficiaries, which is something I file:///F|/pg061709%20(2).txt (235 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00236 1 think we see commonly here, additional evidence 2 is requested before an NCD would be 3 reconsidered. 4 As I understand it, the recent CED 5 recommendation of pharmacogenomic-based 6 warfarin followed this process, and so from a 7 Bayesian perspective CMS now wishes to update 8 its prior, or the existing evidence base. So 9 this is a classic Bayesian problem or scenario; 10 it absolutely is best treated analytically with 11 Bayesian methods. In point of fact, I can't 12 imagine the rationale of initiating a new trial 13 de novo. 14 The CED-inspired Bayesian clinical 15 trial should be designed in the following ways 16 as far as I can see: First, a cap should be 17 conceived in terms of marginality, which is 18 adding evidence to the existing evidence base 19 until it no longer, and I think this was talked 20 about, and an informed decision can be made. 21 Second, optimally and to the extent 22 technically feasible, the trial should allow 23 the realtime evidence review and subsequent 24 adapting to what is learned as the evidence 25 accumulates, of course following their decision file:///F|/pg061709%20(2).txt (236 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00237 1 rules and termed a priori. An adaptive 2 learning process literally rerandomizes 3 treatment groups in search of optimizing 4 therapy, which should assist CMS target 5 coverage in an appropriate setting, patient 6 population, providing characteristics and so 7 forth. 8 Third, the trials should continue 9 until CMS is just, and I would argue no more 10 satisfied, that it can make an informed 11 decision. By making the full use of existing 12 evidence, employing realtime learning, adapting 13 in order to optimize evidence development, and 14 terminating as soon as CMS is satisfied, the 15 CED process itself should be optimally 16 efficient. 17 Finally, I note that this research 18 process that I'm talking about or that we have 19 been talking about, I think is highly 20 consistent with a learning health care system 21 concept that is being promoted by many, but 22 certainly by those interested in a roundtable 23 and evidence-based medicine. 24 Also, I would like to offer this point 25 in respect to the questions you're going to be file:///F|/pg061709%20(2).txt (237 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00238 1 asked to answer. I think you need more 2 questions, one of which is, and I would love to 3 have gotten it in, except you would probably 4 need OMB clearance. But the question I would 5 put on the table that I would like to have you 6 consider is to what extent do you think that 7 Bayesian adaptive methods are applicable 8 specifically to the CED-inspired trials? 9 So I think that is everything, and I 10 am very pleased to have this opportunity. 11 DR. C. GOODMAN: Thank you very much, 12 Bryan Luce. 13 We did provide an opportunity for open 14 public comments and I don't think anyone else 15 has signed up. Thank you, Ms. Ellis. 16 So we can proceed to the next section, 17 which is our questions to presenters. And 18 again, let's pause for 30 seconds while all of 19 our presenters from this morning would 20 congregate basically in the front and center, 21 the front row and close to the center aisle, if 22 you would please. 23 We were only scheduled to have a 24 30-minute time slot here for questions to 25 presenters and we may use more or less than file:///F|/pg061709%20(2).txt (238 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00239 1 that, and we would encourage the panel to do a 2 couple of things. One is questions that will 3 help us answer our remaining questions will be 4 most welcome, because these are not trivial 5 questions and we hope we can use our 6 presenters' time and expertise toward that 7 purpose. And second, concise questions are 8 desirable, as are answers. So, I know that we 9 sometimes have a tendency to throw in a lot of 10 extra examples and other ideas, but we are 11 looking for not just sensitivity but 12 specificity here in our discussions. 13 With that said, Dr. Mock is first with 14 a question, and when you throw out a question, 15 if you have a particular speaker to whom you 16 would like it to be addressed, please say so. 17 DR. MOCK: Thanks, Cliff. I want to 18 address this to Dr. Normand, Dr. Berry, as well 19 as Dr. Sanders, and the question is 20 straightforward, coming from a nonstatistician. 21 What is the decision point and what is the 22 baseline rule on inclusion versus exclusion of 23 studies when you roll them together, be it a 24 meta-analysis or a Bayesian calculation? 25 DR. SANDERS: I know this was directed file:///F|/pg061709%20(2).txt (239 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00240 1 to Dr. Normand in general, but I just wanted to 2 clear up a little bit about why we included 3 some trials and did not with other trials. 4 The COMPANION trial is a trial 5 actually of ICD-CRC devices versus plain CRC 6 versus optimal medical care, so we actually 7 thought it was a different trial with a very 8 different device so that we didn't think it 9 made sense to include it in the group. 10 The AMBIEN CAT trials are pretty small 11 trials which, one of them looks at people with 12 perhaps not transient heart failure, and so it 13 was again seen as kind of a different question. 14 But those two, certainly we could have included 15 those and I think that the differences would 16 have come out in the analyses, but I didn't 17 actually feel that they were recognized as kind 18 of the major RCT trials for us to go out for 19 the patient level data. 20 The CIDS and the DINAMIT trial, it 21 certainly would have been great for us to 22 include those, and we actually have an RO-1 23 being reviewed, I think today, and that 24 includes the DINAMIT trial, and that was purely 25 a case of us not getting access to the patient file:///F|/pg061709%20(2).txt (240 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00241 1 level data on time. And as Don showed, the 2 DINAMIT trial was a trial that showed a 3 negative, it didn't show a treatment effect, so 4 certainly it would have increased our hazard 5 ratio had we included those patients. So, 6 those are just the specific trials and in 7 general why we did them. 8 DR. NORMAND: I will try to be brief. 9 I think the first cut is clinical, it's not 10 statistical, so the clinicians need to look at 11 the various trials and studies and determine 12 whether or not it's a similar enough treatment 13 to include. So, you can think of like all 14 stents or certain stents, I'm going to throw 15 them into one study. You can think of a drug 16 where the dose is similar enough that I'm going 17 to include it. So at the first cut, it really 18 is a clinical decision that determines which 19 studies are included. 20 Now short of that, then some 21 statistical considerations would really relate 22 to some extent the quality of the data, so I'll 23 give you an extreme example that doesn't happen 24 that much, but pretend there was completely 25 missing, everybody was missing data, those file:///F|/pg061709%20(2).txt (241 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00242 1 types of things we would consider, but short of 2 that it's mostly a clinical decision that would 3 dictate what types of studies are included, and 4 the statistician would then model those 5 studies, assuming the data are measured 6 similarly. 7 DR. BERRY: So, you heard me say 8 earlier this morning that you use all of the 9 information. It's a huge task and in this 10 setting, you've got, or presumably you have to 11 set something like what is the question you're 12 addressing and does it include studies that 13 address the same question. But there are low 14 quality studies, there are high quality 15 studies, you could include them all with a 16 discounting for their quality. 17 The actual analysis, and this is one 18 of the things that Roger Lewis indicated, the 19 actual analysis is helpful in this regard 20 because if you've got a study that's out to 21 lunch, you know, it's bloated or they made up 22 the study, and you do the hierarchical model, 23 you will pinpoint that this thing is off the 24 scale and that the focus isn't here, and they 25 would borrow very little strength from that file:///F|/pg061709%20(2).txt (242 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00243 1 extreme. 2 That said, it's awfully difficult to 3 do the quality assessment, so usually we do 4 what the usual meta-analysis folks do, we set 5 bounds, only randomized controlled trials, and 6 go from there. 7 DR. GOODMAN: Thank you, Dr. Perry. 8 Dr. Goodman, Dr. Steve Goodman. 9 DR. S. GOODMAN: You didn't address it 10 to me but I just wanted to add, I was involved 11 a little bit in the MedCAC decision on MADIT-II 12 and just to add a blog to the question that 13 we're asking, in real time it's sometimes much 14 more difficult to make these judgments than 15 looking ex post facto, and in MADIT-II a 16 critical issue was the expansion of the 17 eligibility criteria to subjects who had not 18 demonstrated inducible arrhythmia. So there 19 was a large group there who did not have it 20 through physiologic testing, and it was a 21 biologic question as to whether these were 22 biologically the same as those who had 23 demonstrated inducibility, and at that time the 24 study did not have enough inducibility testing 25 in the control to assess that question. file:///F|/pg061709%20(2).txt (243 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00244 1 And there was a lot of questions that 2 CMS was, and I think this was one of the 3 reasons I was involved, was addressing, is was 4 this combinable with the others. So somewhat 5 done was a projection of what would have 6 happened. That projection works if you don't 7 include, if that inducibility factor in fact 8 didn't make a difference. And we've learned a 9 lot about inducibility and the predictability 10 of the efficacy effects since then, and I 11 gather, and Dr. Maisel could probably correct 12 me, that it doesn't have anywhere close to the, 13 if any, effect that it was thought to have at 14 the time. 15 So I think the issue in real time of 16 whether a given study, which is always defined 17 to be somewhat different than previous studies, 18 can be combined or predicted can be quite 19 difficult, and it's very difficult to try to, 20 as Dr. Normand said, it's fundamentally a 21 biological and a clinical judgment, and 22 estimates we learn more with that study and in 23 some studies that allow us to see more clearly 24 in retrospect, than what we could have seen at 25 the time, because these are fundamental file:///F|/pg061709%20(2).txt (244 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00245 1 biological questions that are simultaneously 2 being answered by those trials, and we may or 3 may not have them settled by that time. 4 DR. C. GOODMAN: Thank you, Steve. 5 Dr. Hlatky is next. 6 DR. HLATKY: I'm trying to wrestle 7 with the issue that might be, how do we use 8 observational data and combine it with the 9 trial data, and maybe an example would be 10 helpfully concrete. I guess we may have this 11 position often where trials are done in very 12 specialized selected populations, and the 13 question is whether they will work as well in 14 less selective populations, and we might say 15 let's start a registry and coverage for 16 evidence development. I'm trying to see how 17 the Bayesian process would work in that, 18 especially saying, oh, by the way, you know, it 19 doesn't work based on observations in these 20 groups. Now that we have more of them or, you 21 know, whether we had trials, we only had more 22 people where it looked like it would work, and 23 out in the real world people are willing to 24 stretch that further. 25 So it's not to any specific speaker, file:///F|/pg061709%20(2).txt (245 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00246 1 but I'm wondering how we would use these 2 methods to help us in this situation where we 3 do coverage for evidence development. 4 DR. NORMAND: Well, I guess the way I 5 would look at it is as follows: It's 6 essentially a question of causal difference, 7 Dr. Hlatky. We've got observational data, 8 we've got selection issues, and so the question 9 would be how can we use observational data in 10 order to form how effective a particular 11 treatment is. And so if we have multiple 12 sources of data, so if we have some diverse 13 populations where we think there's treatment 14 heterogeneity, then using or adopting a 15 Bayesian approach that tries to participate or 16 separate those components of variance, it seems 17 the most sensible way to proceed. 18 So it seems to me that there are two 19 types of questions you have asked when I think 20 about it, one is sort of the causal mechanism, 21 the lack of randomization in an observational 22 world combined with the focus in the real 23 world, and then on top of that how the Bayesian 24 methods could be used. And so the answer is 25 that for a usual causal question, Bayesian or file:///F|/pg061709%20(2).txt (246 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00247 1 non-Bayesian, but I would submit that even in 2 answering the causal question you could use it, 3 because you will have a lot of heterogeneity 4 and that using a Bayesian method would exploit 5 that in a good way. 6 DR. C. GOODMAN: Thank you. 7 Dr. Lewis, do you have an answer to this 8 question? 9 DR. LEWIS: Just to be very specific, 10 the observational data may be comparative or 11 noncomparative, and I think using the 12 hierarchical modeling approach you can handle 13 both of these, but the way the second level of 14 the model is structured depends on what's 15 available to you. So hypothetically if the 16 observational data are comparative, using 17 patients both with and without the treatment of 18 interest, then the heterogeneity would be in 19 the magnitude of the treatment effect, because 20 you don't believe the patients in the 21 observational study are fundamentally 22 exchangeable or the same as the patients in the 23 original RCT. So in the second level of the 24 model, those treatment effects you wouldn't 25 expect to fall right on top of each other. file:///F|/pg061709%20(2).txt (247 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00248 1 In an alternative case, which may be 2 more common, the observational data are 3 noncomparative, and in that setting the 4 information from the observational data may 5 give you information just on the rate of 6 outcome in the control arm, or the comparative 7 arm, or in the arm that includes the new device 8 or drug, and then the second model looks 9 different, but conceptually it's very similar. 10 DR. C. GOODMAN: Thank you. Dr. Grant 11 is next. 12 DR. GRANT: A general comment, 13 question to anyone. It seems to me that in 14 general there are, from the simplest respect in 15 design, there are three levels. One is, the 16 individuals design the trial CED, all those 17 kinds of things which you represent, some of 18 you. The second level are those of us who 19 spend quite a bit of our time, if not most of 20 it, evaluating evidence from those kinds of 21 trials. And then the third level are the 22 decision-makers who ultimately decide to adopt, 23 reject or to gather new evidence. You've also 24 spent a fair amount of time telling us the 25 perils and all the ills of P values and we file:///F|/pg061709%20(2).txt (248 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00249 1 haven't been involved there, and so how is it 2 going to be different? 3 How is it going to be different now at 4 all those levels? I mean, I can sort of see it 5 in some respects generally, but how is 6 everybody going to attain the skills necessary 7 to be able to utilize a different way of 8 thinking than they're used to, which they've 9 already misused? 10 DR. C. GOODMAN: Dr. Berry. 11 DR. BERRY: So, I thought you were 12 going to say as designers as opposed to 13 decision-makers as to how the process would go, 14 just a word about that, and why it is 15 different. It's the transparency, it's the 16 formal aspect, it's the decision analysis of 17 why we do this, do we calculate the utilities, 18 build this trial, make a decision, or ask for 19 more data. The question of how you're going to 20 actually do it, it's like in adaptive designs. 21 I face a world out there of, speaking as kindly 22 as I can, ignorance about this whole process, 23 higher fees, state monitoring committees, and 24 you can't do it overnight, you can't suddenly 25 say we're going to change and everything is file:///F|/pg061709%20(2).txt (249 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00250 1 going to be this way. 2 You have to get into it slowly, have 3 some pilot projects, the Duke project being 4 one, but then build up and incorporate the 5 decision aspect and the things more formally. 6 I mean, I loved what Brian had to say, but you 7 can't do that right away. It's going to take 8 time, it's going to take effort, it's going to 9 take, you know, two modeling groups to see how 10 it's going. You might even have a parallel 11 process. If you don't trust it at all, you can 12 do the usual uninformed stuff and have a 13 parallel process where some Bayesian group 14 educating you over time is doing this and 15 saying boy, you shouldn't do that, but you do 16 it anyway, and then you pay the price. It's a 17 tough question. 18 DR. C. GOODMAN: Dr. Satya-Murti and 19 then Dr. Prager. Sati? 20 DR. SATYA-MURTI: These are important 21 questions for CMS. What it is in the current 22 level of reimbursement and coverage, which is 23 also something I come from, a Bayesian decision 24 to cover or not cover may have been made on the 25 basis of expert recommendations from you all, file:///F|/pg061709%20(2).txt (250 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00251 1 but sometime later, as Bayesian inherently 2 does, you might decide, and we may not have a 3 coverage decision actually, we have denied 4 coverage. Or there's some evidence denying 5 that. If we deny and you come back and we 6 cover, everybody's happy. But the converse, 7 you cover it for some time and then you decide 8 oh, no, this is quite harmful, this has got 9 fairly grave consequences in the media and 10 industry. 11 And so that is where we're wondering 12 if we could help CMS by building, putting in 13 language where, just like most decisions would 14 be conditional, pro tem, but we may reverse it 15 and then say well, you haven't quite convinced 16 us, like with a curfew, you have violated it, 17 so you can't do it. 18 DR. C. GOODMAN: Dr. Normand. 19 DR. NORMAND: I had to get up on this 20 one. This is how we assess evidence with the 21 Bayesian approach, it has nothing to do with 22 the philosophy. 23 DR. SATYA-MURTI: I agree. 24 DR. NORMAND: And I think one would 25 argue, therefore, that my role is a policy file:///F|/pg061709%20(2).txt (251 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00252 1 world, policy-making, I'm in the department of 2 healthcare policy and we make these types of 3 decisions, and a lot of them are informed at 4 your level. And so the real issue is wanting 5 to see these issues based on the best evidence, 6 and so I would lead that into what we do with 7 the evidence. And some of the things that we 8 talked about today, I think are better ways to 9 quantify evidence, such as Bayes factors. So I 10 think if it's going to happen anyhow, it's best 11 therefore to try and adopt, this is a paradigm 12 shift, is try to adopt a type of evidence 13 building that is one that is actually going to 14 provide the answer to the questions you seek, 15 as opposed to having these other types of 16 pieces of P values and whatnot, so I just 17 wanted to say that. 18 DR. SATYA-MURTI: Actually, you're 19 correct. I grant you, the language says 20 something is reasonable and necessary, and it 21 becomes all and none, it is not so anymore for 22 where we are going now, all decisions to take 23 one or other positive or negative action is 24 likely to evolve into something that may become 25 conditional. So if as a panel we agree on file:///F|/pg061709%20(2).txt (252 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00253 1 that, we could, we're in a position to 2 recommend that more such decisions would be, I 3 don't want to use the word conditional, but 4 would be appropriate at that time subject to 5 later thinking. 6 DR. C. GOODMAN: Dr. Lewis. 7 DR. LEWIS: The right thing is not 8 always the easiest, and one of the advantages 9 of the Bayesian approach is that it is 10 inherently sequential in the sense that new 11 information allows you to update yesterday's 12 posterior and consider it as today's prior, to 13 be further updated to a current posterior. So 14 one of the opportunities for CMS in my opinion 15 is that at the time that a Bayesian methodology 16 or philosophy or approach is considered, one 17 can take the advantage of that to explicitly 18 state the intent to adopt a continual 19 reassessment approach in which it is not the 20 responsibility of CMS just to make a coverage 21 decision initially, but to continually ensure 22 that coverage decision remains the best 23 decision to insure optimal outcomes and best 24 use of the resources. 25 DR. C. GOODMAN: Thank you, Dr. Lewis. file:///F|/pg061709%20(2).txt (253 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00254 1 Dr. Prager is next. 2 DR. PRAGER: Most of all we have been 3 talking about today related to devices rather 4 than medications, and I think that may be 5 relevant because part D is a different animal 6 than the rest of coverage, although I think as 7 we move forward that may actually change. 8 As clinicians we're often faced with 9 the dilemma regarding off label use and I'll 10 give you two for instances. One is drugs that 11 are used for pain often are covered based on 12 the etiology -- it may appear that the FDA 13 requires you to study them for what caused the 14 pain rather than what is the pain. So for 15 instance, a posthepatic neuralgia is covered 16 with three different drugs right now. That 17 exact same pain, if it's caused by something 18 else, is not covered at all, and as clinicians 19 that's a problem. 20 One other example going to the device 21 world is that neuropathic pain is covered with 22 spinal cord stimulation, and yet in Europe the 23 number one use of spinal cord stimulation is to 24 treat the pain from the heart that is in 25 angina, and yet in this country it's not file:///F|/pg061709%20(2).txt (254 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00255 1 covered there. There is a multitude of studies 2 indicating in Europe, demonstrating efficacy of 3 spinal cord stimulation for angina. 4 So what my question is, given the 5 methodology that has been presented today, how 6 would the group or any one of you see it 7 applying to this off label use dilemma that 8 many of the clinicians face? 9 DR. C. GOODMAN: Dr. Lewis is going to 10 take a try at that. 11 DR. LEWIS: I will take a quick stab 12 at it. When I think of off label use, I think 13 of situations where clinicians are informally 14 borrowing information. The on label use to a 15 large extent consists of those specific 16 diseases that can be defined and for which 17 there are two phased trials leading to the 18 labeling or the unlabeled use. 19 In a hierarchical approach where you 20 borrow information, you can think of all those 21 different disease entities that cause similar 22 pain, for example neuropathic, like pain, as 23 being likely to be similar in terms of their 24 response because similarities are the 25 underlying mechanism of the pain transmission, file:///F|/pg061709%20(2).txt (255 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00256 1 for example. Thus, a medication or a device 2 that is known to have applications along, 3 across the population of those diseases, is 4 highly likely to be effective in a similar 5 disease drawn from that population of diseases. 6 In other words, the diseases are exchangeable 7 at some level in the hierarchy, and this is 8 what I referred to in my talk as circumstantial 9 evidence of efficacy. 10 So if for example you had a disease 11 that was relatively uncommon, that had a high 12 morbidity associated with it, for which similar 13 diseases, for which the device or drug had been 14 shown to be effective in similar diseases, I 15 would believe that you could determine with a 16 high probability that the treatment would be 17 effective in that disease without the need for 18 independent evidence in that patient 19 population. And I would urge CMS to consider 20 those situations, especially if those diseases 21 are relatively rare, because it allows well 22 informed coverage decisions without the burden 23 of separate high level evidence for each one 24 independently. 25 DR. PRAGER: I completely agree with file:///F|/pg061709%20(2).txt (256 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00257 1 what you just said. The question is, how would 2 you see the analysis actually getting 3 integrated into the system for that. 4 DR. C. GOODMAN: Dr. Lewis. 5 DR. S. GOODMAN: Isn't that a question 6 for CMS? 7 DR. C. GOODMAN: I would be interested 8 in hearing his response. 9 DR. LEWIS: I believe that it would 10 require the input of data to include the 11 knowledge of the underlying disease mechanisms 12 to define the population of diseases or the 13 group of diseases for which treatments are 14 likely to have similar but not identical 15 effectiveness, and I think that's a clinical 16 question. The goal is to create agreement on 17 what that group of diseases is, then examine 18 the evidence available within them so they can 19 be integrated, so I think that's the way I see 20 it being shown. But the first step, as many of 21 the questions have been answered, is that 22 clinical science has to define the domain of 23 diseases that are thought to be similarly 24 responsive. 25 DR. C. GOODMAN: Steve, but briefly. file:///F|/pg061709%20(2).txt (257 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00258 1 DR. S. GOODMAN: Yes. This was 2 addressed partially taking the slide that I 3 showed with the extrapolation from adults to 4 children. So there's something between asking 5 for a full-fledged clinical trial and doing 6 what Roger suggested, which is just extending 7 it into these other conditions, which is to say 8 that we want some evidence, the prior evidence 9 counts partially, we will decide collectively 10 how much it counts, and you might be able to do 11 a trial with 60 patients instead of 250. 12 So there are all grades of 13 transferability of the prior evidence and that 14 can be decided both scientifically and on a 15 regulatory basis, to what extent you're going 16 to allow that extrapolation. It has a lot of 17 application here because of, you know, often 18 we're involved in situations of extrapolating 19 to older patients in the Medicare studies for 20 which there haven't been a lot of studies, but 21 there's been some. So there are all shades of 22 gray between doing everything and doing 23 nothing, and this is a place where I think it's 24 a very rich area for application. 25 DR. GOODMAN: Thanks, Steve. Curtis, file:///F|/pg061709%20(2).txt (258 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00259 1 and then we're going to go to something else. 2 DR. MOCK: I want to go directly to 3 one of the questions that the panel is going to 4 be asked to vote on today and it specifically 5 addresses an answer that I'm still looking for, 6 and it's very clear. It has to do with you 7 explaining to us the strength of the Bayesian 8 methods and how those override the deficiencies 9 that there may be in studies that we read and 10 interpret, or you do, and studies that are 11 formed in the future. And I guess a subset of 12 the question is, this is where we are today, 13 where are we going? 14 I've never met any of you before today 15 but I have the impression that you all know 16 each other, it's a very small supraspecific 17 group, and it sounds like you all are believing 18 this concept. And I think that's tremendous, 19 but what happens five years from now or ten 20 years from now when there's not six of you, but 21 there's 6,000 of you trying to keep up with 22 interpreting and correlating the recent data 23 that we need to direct us where we need to go 24 with patient outcomes? 25 So please tell us, the panel, what file:///F|/pg061709%20(2).txt (259 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00260 1 answer is going to be best when we're asked 2 what our confidence is on that question, and 3 how is that answer going to work for CMS and us 4 as a population moving forward using the 5 Bayesian method of statistics? 6 DR. C. GOODMAN: Allow me to be a 7 little more specific. Imagine you've got a 8 white board in front of you and we need, for 9 starters, the three greatest potential 10 strengths of a Bayesian approach for 11 interpreting evidence. So we're looking for 12 your top three here, and we're looking for an 13 answer that does not require a statistician to 14 comprehend, we're looking for an answer that 15 can work within the Agency and is 16 comprehensible to a congressional staffer who 17 might ask. 18 DR. SANDERS: And you don't want the 19 design of a trial, you want -- 20 DR. C. GOODMAN: We want to start with 21 interpretation of evidence, what are your top 22 three? Dr. Lewis, do you want to take the 23 first crack at that? 24 DR. LEWIS: A first crack, number one, 25 transparency and yielding probability file:///F|/pg061709%20(2).txt (260 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00261 1 statements that are understandable and 2 correctly understandable by physicians, 3 policy-makers, regulators and the congressional 4 staffer. 5 DR. C. GOODMAN: So transparency is 6 your first? 7 DR. LEWIS: Transparency of 8 probability statements, statements about the 9 strength of evidence. 10 Number two is the ability to make 11 explicit the methods by which we consider 12 information from various sources of variable 13 strength and quality so that that evidence can 14 be updated as new information becomes 15 available. 16 DR. AXELROD: That seems to run 17 counter to some of the discussions we've heard 18 about the fact that this has to be done by 19 skilled people, and you need very experienced 20 statisticians and people who understand how to 21 do these things with a great deal of 22 specificity, which suggests to me that the 23 levels of transparency aren't quite so great as 24 you make it out to be. 25 DR. C. GOODMAN: Thanks for offering file:///F|/pg061709%20(2).txt (261 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00262 1 that, Dr. Axelrod. We may concur with that 2 point, but let's get these three on the table. 3 So continue, Dr. Lewis, your explicit opinion 4 regarding strength and qualities. 5 DR. LEWIS: And the third comment I 6 would make is the explicit definition of the 7 utility function that links the quantification 8 of uncertainty with the ultimate decision that 9 maximizes the benefit to the patient 10 populations. 11 DR. C. GOODMAN: And if you could 12 repeat that, I got the first part of it. 13 Explicit definition -- 14 DR. LEWIS: Explicit definition of the 15 utility function which links the quantification 16 of uncertainty with the selection of the 17 optimal decision to maximize benefit to 18 effective patient populations. 19 And then with your permission, I would 20 like to comment on the question from 21 Dr. Axelrod. 22 DR. C. GOODMAN: Just not yet, please. 23 DR. LEWIS: Yes, sir. 24 DR. C. GOODMAN: So Dr. Lewis posited 25 three such assertions, and Dr. Berry, do you file:///F|/pg061709%20(2).txt (262 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00263 1 have a fourth? 2 DR. BERRY: I just wanted to add that 3 number two should include synthesis of the 4 various information. 5 DR. NORMAND: Here's a number one. I 6 think that one of the main benefits is that you 7 will actually get a quantitative summary, you 8 will get the probability that a particular 9 treatment is better than a comparison 10 treatment, a probability, that's number one. 11 DR. C. GOODMAN: Say it again. 12 DR. NORMAND: The probability of 13 benefit, explicit benefit of treatment A versus 14 treatment B, you do not get that from 15 frequentists. 16 DR. C. GOODMAN: Probability of 17 benefit. 18 DR. NORMAND: Yes, any size. Any size 19 you want. 20 DR. C. GOODMAN: And all you get from 21 a frequentist, at least as I understand it is 22 kind of a thumbs up, thumbs down, not a how 23 much. 24 DR. BERRY: Lewis's number -- that's 25 Lewis's number (263 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00264 1 DR. C. GOODMAN: So we have about 2 three of your top reasons, correct, as I 3 understand it. Yes, Dr. Normand? 4 DR. NORMAND: Just because -- so, this 5 is a reason that's looking forward to the 6 future, because in the future we will have much 7 more data and different types of data to 8 combine any clinical trial for any decision, so 9 we will have genetic data, we'll have clinical 10 data, we may have patient survey data. So in 11 the future, because of the proliferation of 12 databases and electronic health records, we 13 will have much more diverse data sources to be 14 combined, and it is not -- the Bayesian method 15 gives you a way to do that. 16 DR. C. GOODMAN: So if I might 17 rephrase that, the Bayesian method provides 18 methodological opportunities which will be 19 enhanced by the greater availability of data, 20 and to use the technical term, our ability to 21 crunch such data in the future. 22 DR. NORMAND: I would say that it 23 provides, it's a method that will provide a 24 mechanism to summarize the continuum and 25 diverse and multiple data sources typically. file:///F|/pg061709%20(2).txt (264 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00265 1 DR. C. GOODMAN: That's very helpful, 2 the continuum being everything that we will use 3 in regard to the observational stuff to top 4 shelf RCTs, for example. Thank you. 5 Now, just allow me to pursue this. 6 Thanks for the four or so swell reasons why 7 this is the greatest thing in the world. Now 8 we would like to hear three potential 9 weaknesses of the Bayesian approach in the same 10 context. I know that the several of you who've 11 spoken that way don't typically go that way, 12 but certainly you must have been exposed to 13 this or even accused of it from time to time. 14 Where are the greatest pitfalls? 15 DR. BERRY: So, I think Dr. Axelrod's 16 comment about having to have trained 17 statisticians, it's not the standard 18 statistical approach, and if you take a 19 Bayesian approach you have to first explain the 20 Bayesian approach to everybody you're talking 21 to. 22 In addition, and I forget who said it, 23 maybe it's related, when you get 6,000 people, 24 there will be some good Bayesians and some not 25 so good Bayesians. One of the things I'm file:///F|/pg061709%20(2).txt (265 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00266 1 constantly doing is telling people that that's 2 a lousy Bayesian approach. So how do you, you 3 know, you can't call Berry every time, so how 4 are we going to do this? It takes training. 5 So I think those are the two, and 6 maybe it's only one weakness, but it's 7 substantial, and this gets back to my point 8 that we can't do this overnight because it 9 takes training, it takes getting physicians and 10 consumers so that they can understand what 11 you're doing and to build credibility. 12 DR. C. GOODMAN: I want to make sure I 13 understand your second point. Is another way 14 of saying that that you've got a roomful of 15 Bayesians and you're getting a roomful of model 16 approaches? 17 DR. BERRY: I don't know if that's 18 just another way of saying it, so it is a 19 choice of model, but it is, the Bayesian 20 approach and using a prior distribution and not 21 understanding the biology, not understanding 22 what the data shows, you can get lousy Bayesian 23 approaches, and who is going to judge what is a 24 lousy Bayesian approach? 25 DR. C. GOODMAN: So we'll (266 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00267 1 forward with better Bayesian approaches, and 2 perhaps you're not in a good position now to 3 make some sort of a judgment about their 4 quality? 5 DR. BERRY: Correct. 6 DR. C. GOODMAN: Dr. Normand. 7 DR. NORMAND: So I would characterize 8 the introduction of Bayesian approaches as a 9 paradigm shift, and any paradigm shift is a 10 problem, so I would say that. I'm up here to 11 give you an anti-disadvantage, and I'm 12 surprised that you weren't saying it's the 13 prior. You're going to be attacked on the 14 priors, I don't think it's a disadvantage, I 15 actually think it's an advantage. And the 16 reason why it's an advantage is you're making 17 it precisely transparent. A frequentist using 18 a prior, it's a point prior, but they don't say 19 it. 20 DR. C. GOODMAN: Thank you, Dr. 21 Normand. Dr. Goodman, is this one of the 22 potential weaknesses? 23 DR. S. GOODMAN: Sort of. 24 (Laughter.) 25 The problem with the question is it file:///F|/pg061709%20(2).txt (267 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00268 1 doesn't say compared to what, and I can 2 certainly list certain pitfalls. 3 DR. C. GOODMAN: It actually does. We 4 will get to weigh them. So what we are looking 5 for now is what is the downside, and then we 6 will weigh them. 7 DR. S. GOODMAN: So the compared to 8 what is the critical thing. There is almost 9 nothing I can think of as a technical problem 10 in the Bayesian realm that doesn't have an 11 exact correlate in the frequentist realm. 12 I would say, just to amplify what 13 Sharon said, that we're not used to talking 14 about many of the things that we need to talk 15 about. I'll just state some things that 16 always, everybody knows. Minimum important, 17 clinically important difference. I make the 18 point that every study has 80 percent power, 19 literally every study has 80 percent power for 20 something. For what? And then the question 21 is, so we routinely question 80 percent, you 22 know, if it falls below 80 percent power. But 23 if they say oh, it's to detect a 15 percent 24 difference as opposed to a 13 percent, that's 25 really uncommented on in virtually any review file:///F|/pg061709%20(2).txt (268 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00269 1 capacity. We're forced to talk about that and 2 we're not used to talking about it, so is that 3 a weakness of the Bayesian paradigm, that we 4 must talk about things that we're uncomfortable 5 talking about, we don't know how to do it yet? 6 I will leave that up to you, but we don't quite 7 know how to discuss in public or private forums 8 some of the things that you must discuss when 9 we talk about comprehensive Bayesian 10 approaches. 11 DR. C. GOODMAN: And that hesitation 12 to discuss that issue is not confined to 13 Bayesians. 14 DR. S. GOODMAN: No, it's just rarely 15 gone over in the other contexts. 16 DR. C. GOODMAN: Thank you, Dr. 17 Goodman. Dr. Cox. 18 DR. COX: Following up just on this, I 19 feel like we're in sort of medieval times and 20 I'm sort of like a flat earth guy, and I'm 21 looking at the new world brought to me that 22 says it's really round, but I am challenged 23 with reading literature. So here I pick up a 24 paper and it describes a Bayesian analysis with 25 all this trim that you've talked about. How do file:///F|/pg061709%20(2).txt (269 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00270 1 I tell -- I mean, I realize I'm ignorant, I'm 2 on the flat planet now, but how do I tell it's 3 a good Bayesian analysis? Is there a 4 codification of terms in the Bayesian world 5 that describes all of the ability to understand 6 all the factors that go into this analysis? 7 DR. C. GOODMAN: Dr. Lewis. And this 8 returns to number two on weaknesses. 9 DR. LEWIS: So, in many areas I join 10 you in the flat earth society. The question is 11 not whether or not the population of physicians 12 who must assimilate information from the 13 medical literature and apply that to their 14 clinical practice are going to be able to judge 15 the quality of Bayesian analyses. It's whether 16 they will be better or worse at that than they 17 are now in interpreting frequentist analyses. 18 And I firmly believe that someone who 19 teaches clinical medicine several times a week 20 for many hours in an academic environment, that 21 it is not realistic, given the complexity of 22 current medical research, to expect 23 practitioners planning primarily nonacademic 24 clinical practice careers, to have them 25 understand how to judge the quality of studies. file:///F|/pg061709%20(2).txt (270 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00271 1 I think that we have to have other safeguards 2 for insuring the quality. 3 The advantage of the Bayesian approach 4 is that for those who are expert, it will allow 5 better gatekeeping for the quality of the 6 analyses, helping protect the integrity of the 7 information presented, but I don't believee 8 it's a method that will result in the average 9 clinician having better insight into the 10 strengths and the weaknesses than they now do. 11 DR. SANDERS: I agree with Dr. Lewis's 12 comment, but I certainly think that there would 13 be a place in this situation for like a user's 14 guide for the clinical literature based on 15 Bayesian methods. I mean, certainly there are 16 lots of techniques out there that we need to be 17 able to convey to the end user. You know, I 18 work off decision analysis and having to convey 19 what that black box means is another topic, but 20 certainly I think the education of the end 21 users would be something that should be looked 22 at as we push forward. 23 DR. C. GOODMAN: Thank you. 24 Dr. Satya-Murti. 25 DR. SATYA-MURTI: Thanks for bringing file:///F|/pg061709%20(2).txt (271 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00272 1 MCID, minimum clinically important difference. 2 What you're saying, Dr. Goodman, is that 3 regardless of the type of analysis that you 4 subjected the study to, is it ultimately 5 important or not is the MCID criteria, as I 6 dealt with it in other areas. So that being 7 the case, even though the major advantage of 8 Bayesian analysis is probability, it will tell 9 you that it's 40 percent better than existing 10 treatment, or 80 percent and so on. So if 11 that's the major benefit of Bayesian technique, 12 then it still falls on the clinician. 13 DR. C. GOODMAN: Dr. Normand. 14 DR. NORMAND: So, what you can do is 15 the probability that the difference between the 16 treatment and comparison group is bigger than 17 X. So if X is bigger than the minimal clinical 18 difference, you can actually put that in there, 19 so I wanted to correct that. 20 DR. SATYA-MURTI: All right. If that 21 were the case, it still behooves the 22 decision-maker to then say, am I happy with a 23 20 percent improvement, am I happy with a 24 reduction of seizures from 12 to six, or am I 25 happy with the ability to read two more letters file:///F|/pg061709%20(2).txt (272 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00273 1 on a chart. So, it still falls finally on 2 society's values and the decision-maker; is 3 that correct? 4 DR. NORMAND: It always is. 5 DR. SANDERS: Yes. 6 DR. C. GOODMAN: Did you finish your 7 point? 8 Dr. SATYA-MURTI: Yes. I wanted to 9 make that for the record, that the 10 decision-making hasn't changed regardless of 11 these shifts in paradigms. 12 DR. C. GOODMAN: Thanks. Steve? 13 DR. S. GOODMAN: And this is just the 14 second half of that sentence, which is yes, it 15 is up to the decision-making side on that, but 16 it is, the minimum clinically important 17 difference is inherently a decision analytic 18 construct, that is, it is a difference that 19 offsets the safety issues and the tolerability 20 and all of those. So if we have a complete 21 full-blown analysis, you can be assisted by 22 adding into the discussion of what's a 23 minimally clinically important difference 24 decision the analytical approaches such as 25 Dr. Sanders and Lewis talked about. file:///F|/pg061709%20(2).txt (273 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00274 1 DR. SATYA-MURTI: And there's a lot of 2 subjectivity in that. 3 DR. S. GOODMAN: Absolutely, which 4 again, is the right people talking about the 5 right things, so you're not talking about 6 power, you're talking about how many seizures 7 should be traded off against how much 8 impairment driving is done by administering a 9 particular therapy. 10 DR. C. GOODMAN: Thank you. In order, 11 Dr. Dullum, Dr. Alvir and Dr. Hlatky. Dr. 12 Dullum? 13 DR. DULLUM: One of the advantages, 14 just so I can understand, is the probability 15 that the treatment will be better. Could that 16 also be a weakness with the ongoing analysis? 17 I mean, would it be like the weatherman saying 18 there's going to be a 60 percent chance that 19 there's going to be no rain today but, oh, by 20 the way, it did rain. So is this something 21 that when we see the probability, that we can 22 really rely on that as opposed to the 23 frequentist approach? Because it's kind of an 24 ongoing analysis, how much can you believe that 25 probability and go down that road? file:///F|/pg061709%20(2).txt (274 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00275 1 DR. C. GOODMAN: Dr. Lewis. 2 DR. LEWIS: I will take a crack at it. 3 I think there are a couple of things that can 4 happen. One is that new information becomes 5 available and when incorporated into the prior 6 analysis changes the probability statement, 7 perhaps that the treatment is better controlled 8 by a certain amount. Lacking new information, 9 I think the probability statement is very 10 believable because it incorporates the prior 11 information and the available evidence. 12 The other strength of it and the other 13 place that differences can come into play is if 14 the prior information needs to be changed 15 because, for example, we have a new 16 understanding of the mechanism of disease, we 17 now know that there's a common pathway that 18 leads to this autoimmune disease and another 19 disease that we failed to recognize as 20 autoimmune. Now that we know there's a common 21 mechanism, we have a different prior for 22 believing the treatments would share in 23 efficacies. 24 We can picture this kind of paradigm 25 shift that would change the whole structure of file:///F|/pg061709%20(2).txt (275 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00276 1 the analysis. Short of that, I would see the 2 probability of Bayesian being inherently more 3 stable than the kinds of statements we make on 4 points and null hypotheses. 5 DR. C. GOODMAN: Thank you. Dr. 6 Alvir. 7 DR. ALVIR: Thank you. One of the 8 things that struck me in an earlier 9 presentation, and I forget which one it was, 10 was that anybody can do a regression now, and 11 I'm old enough to have been in the business 12 when not everybody could do a regression. So 13 given what I believe is this Bayesian creep, 14 with more and more software out there, the fact 15 that we have this Bayesian software, in five or 16 ten years we could be up there doing a 17 presentation and saying, you know, anybody can 18 do Bayesian analyses now. 19 And again, you know, we have similar 20 problems, and again, I think the classical or 21 frequentist versus Bayesian is, for me it's an 22 overblown argument. But you know, I think it's 23 coming that there is going to be, you know, 24 abuse of Bayesian methods in the future, and 25 what can we do to prevent that? I know there file:///F|/pg061709%20(2).txt (276 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00277 1 is all that variability of projecting into the 2 future, but could you at least give us some 3 ideas? 4 DR. C. GOODMAN: Thank you. Just a 5 few. 6 DR. SANDERS: Quickly, I think this 7 returns to the peer review process, panels like 8 this, peer review for journals. I mean, 9 certainly like the Annals have some statistical 10 reviewers for all of their articles, and 11 certainly if this is the case they might bring 12 on more of a Bayesian statistician as part of 13 the review process. I think that, you know, 14 regardless of the method, there's always going 15 to be a point where we need to turn to those 16 types of mechanisms. 17 DR. C. GOODMAN: Dr. Hlatky. 18 DR. HLATKY: I guess I'm going to 19 follow up in a sense because I heard something 20 about one of the advantages is transparency, 21 and I think you're using the word transparency 22 in a different way than I would use it. 23 Transparency means that anybody can see it and 24 understand it, and I think when you guys are 25 saying transparency, you mean that you have file:///F|/pg061709%20(2).txt (277 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00278 1 these complicated mathematical functions that 2 are laid out in some way that a highly trained 3 expert can understand and is communicated 4 explicitly, rather than implicitly. 5 So my question to you is, what about 6 getting to the average doc understanding what 7 this is and not saying, well, you know, you 8 guys can cook up anything with this method? 9 DR. C. GOODMAN: Dr. Lewis. 10 DR. LEWIS: First, I agree with the 11 way you're using transparency, and it is 12 actually the way that I was hoping that I was 13 using it as well. What I mean by transparency 14 would be in terms of the user of the 15 information derived from the analysis is that 16 they understand what the analysis looked at. 17 So for example, if there's a probability 18 statement that says there's a 78 percent 19 probability of survival six months greater with 20 treatment A versus treatment B, that is a 21 statement that most clinicians can understand. 22 It's the kind of statement that they all hope 23 the treatment analysis leads to, but it 24 doesn't. 25 So the irony here in the current file:///F|/pg061709%20(2).txt (278 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00279 1 popular approach, we fool ourselves into 2 thinking that what we are comfortable with is 3 what we understand, but in fact our comfort is 4 based on a comfort with a complete lack of 5 understanding. So that's what I mean by 6 transparency. 7 There is a second level of 8 transparency that affects not the clinician 9 reading the study but at the peer review 10 process in reviewing the study, or for example 11 another statistician attempting to replicate 12 the analysis. And that is, the process of 13 Bayesian analysis in many ways forces one to 14 write down an assumption in a more explicit way 15 because they are overt as opposed to covert, 16 and that first of all makes it more 17 reproducible, but most importantly invites an 18 appropriate discussion of the merits of the 19 assumption. 20 With a frequentist analysis, many of 21 the assumptions are hidden, which completely 22 avoids or obscures the scrutiny that they ought 23 to undergo. Let me give you a concrete 24 example. Every time you see longitudinal 25 modeling with generalized estimation file:///F|/pg061709%20(2).txt (279 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00280 1 statements, how often do they tell you the 2 covariate? Not very often. How many of the 3 readers or the peer reviewers understand what 4 effect that means on the stability of the 5 estimates? It's a very small fraction, and yet 6 it can change a qualitative positive result to 7 a qualitative negative result. 8 DR. C. GOODMAN: Thank you, Dr. Lewis. 9 I want to move on to what is the 10 equivalent to our second question. You were 11 very helpful in elucidating three to four 12 strengths and three to four weaknesses. Now, 13 for the purposes of designing studies, and what 14 I'm imagining now is an enterprising and well 15 informed sponsor for a new procedure, 16 technology, some type of intervention, wanting 17 to maybe approach CMS to try to figure out what 18 sorts of evidence might CMS want to weigh in 19 what might be a national coverage 20 determination. 21 So what we're wondering, then, is what 22 might be, how might, for the design study 23 purpose, would this potentially strengthen, the 24 Bayesian approach outweigh the potential 25 liabilities in the design of a study? We're file:///F|/pg061709%20(2).txt (280 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00281 1 thinking about helping someone design a study, 2 it doesn't have to be in consultation with CMS 3 maybe, you could do it on your own, but with 4 the Bayesian ups and downs, how do we come out 5 on that, how confident are we that the 6 strengths of the Bayesian approach would 7 prevail specifically? Dr. Berry. 8 DR. BERRY: So, to give you the three 9 top reasons, be adaptive, online learning, we 10 talked about that. Using predictive 11 probabilities, asking where is the study going, 12 and doing it through the course of the trial. 13 And the third one is using prior information, 14 using parallel information that's coming from 15 other sources during the course of the trial. 16 So I would focus on those three. 17 And Dr. Goodman, the benefits, I mean, 18 I can't give you weaknesses for design because 19 it's so natural, it's so -- I mean, it is true 20 that there are things that can happen along the 21 way for the same reason of experts and 22 non-experts designing these studies, but it 23 makes so much sense to be looking at the data. 24 You said what information would CMS 25 need. You put that in the trial. You say what file:///F|/pg061709%20(2).txt (281 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00282 1 information does CMS need, let's build the 2 study to give that, and if that means we can do 3 it with 300 patients depending on the data, or 4 if it means 3,000, maybe that's beyond the pale 5 and we have to cut it at 1500 or something, but 6 we will try. 7 DR. C. GOODMAN: Dr. Salive, do you 8 have a question or inquiry specific to this? 9 DR. SALIVE: I guess this relates back 10 to the comments earlier, so we do get companies 11 that come in and say they're designing their 12 trial and they are considering FDA's input and 13 they want our input at the same time for doing 14 a trial for a new innovative product. And the 15 question revolves, my question revolves around 16 prior information and sometimes we ask what 17 that is and, you know, hand waving ensues. And 18 the question is really, how crucial is that in 19 this scenario, because sometimes we're told it 20 will be a noninformative prior, other times we 21 get some kind of rationale. 22 So, you know, we saw many of the 23 analyses earlier that I thought suggested that 24 the prior does affect somewhat the final 25 results, and so what if they're wrong, how file:///F|/pg061709%20(2).txt (282 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00283 1 useful is a noninformative prior, or is this 2 just too specific of a question? 3 DR. C. GOODMAN: Dr. Berry. 4 DR. BERRY: No, I don't think it is 5 too specific. I can tell you this, I've been 6 involved in many of the CRH considerations. 7 The standard is that we use one or more priors. 8 The issue of bringing in prior information is 9 difficult. It's, what we've taken to do is 10 that we have two priors, one prior for the 11 design aspect using the information, 12 recognizing that the FDA has its own prior, and 13 their own prior may be noninformative. So we 14 build the trial so that it's sufficient from 15 the perspective of the prior distribution of 16 the company, the experts that the company has 17 employed or hired, but the goal is to show 18 based on a noninformative prior that the device 19 is effective to the extent that it's necessary. 20 So it's a problem, it's not an easy 21 thing to do, and there is a great deal of 22 discussion with regulators, and there's room 23 for bias. You know, somebody can bring a study 24 that says I want to use this prior. You say, 25 didn't you do some other studies that weren't file:///F|/pg061709%20(2).txt (283 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00284 1 quite so positive. So it's not an easy 2 question. 3 DR. C. GOODMAN: Thank you. Steve 4 Goodman, will you answer the question on the 5 part of potential strengths outweighing 6 potential liabilities? 7 DR. S. GOODMAN: Well, I was going to 8 give the same answer to Marcel's. 9 DR. C. GOODMAN: Is it still relevant? 10 DR. S. GOODMAN: Yes. 11 DR. C. GOODMAN: Thank you. 12 Dr. Goodman. 13 DR. S. GOODMAN: In the earliest 14 phases of development I think that 15 noninformative priors are usually the way to 16 go, and if they're not convincing to you, if an 17 informative prior is not convincing to you, 18 then you shouldn't allow it to be used. As 19 Dr. Berry mentioned before, there is also 20 learning that goes on during trials, and just 21 the statement analytically, the two endpoints 22 are related to each other, is in itself a prior 23 even if you say you don't know before you start 24 it how related. 25 Just that statement, this informs me file:///F|/pg061709%20(2).txt (284 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00285 1 about that. If this is high, if the response 2 rate is high, I expect the mortality probably 3 will be lower. Just that statement, without 4 anything else you learn during the trial, that 5 in itself in a sense is an implicit prior that 6 allows you to learn during the trial. So it is 7 not critical that the priors with regard to the 8 main effect be informative; in the earliest 9 stages of development we probably shouldn't 10 make them informative unless they're entirely 11 convincing. 12 But on the other hand, to not allow 13 evidence-based priors when there is true prior 14 evidence, for example, evidence that is 15 relevant to children, children relevant to 16 adults, or 50-year-olds relevant to 17 70-year-olds is an advantage to you, because 18 you might not want more evidence than is, than 19 common sense would require. 20 DR. C. GOODMAN: Thank you, Steve. 21 Dr. Salive, is that satisfactory? Good. 22 Further points? Dr. Dullum. 23 DR. DULLUM: But isn't that one of the 24 advantages of a Bayesian, that if the prior is 25 noninformative, as you go along further in the file:///F|/pg061709%20(2).txt (285 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00286 1 analysis, that that becomes less important as 2 you get concrete information? 3 DR. S. GOODMAN: Yes, that was the 4 point, but you have to have the initial 5 linkage, you have to model something that 6 allows the information to be borrowed as you go 7 along. It has to be built into the design that 8 allows you to say if this is high, you know, it 9 tells me something about this or I will shift 10 to a surrogate. You don't have to give your 11 prior opinion about exactly what the nature of 12 that relationship is going to be. You just 13 have to say as I learn, I will allow myself to 14 adapt to the trial. Without that statement, 15 there is no basis for the application. 16 DR. C. GOODMAN: Thank you. Dr. 17 Goodman, your voice carries pretty well, but do 18 come to the mic whenever you have something 19 that you want us to remember. Other points to 20 be made with regard to this? 21 I'm still interested in nailing down 22 more in our portion too whether the potential 23 strengths outweigh the weaknesses for designing 24 studies, and then interpreting them. Curtis 25 Mock. file:///F|/pg061709%20(2).txt (286 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00287 1 DR. MOCK: I just wanted to clarify, 2 I'm sorry I'm going back to this, I just can't 3 get it. I think I heard you say, Dr. Berry, 4 that one of the weaknesses of the Bayesian 5 method is that there is no uniformity or 6 reproducibility in how a particular 7 meta-analysis is going to be performed by 8 different statisticians; is that correct? 9 DR. BERRY: No. I didn't mean to say 10 that. It is true, just as it's true for the 11 frequentist methods, that if you have two 12 statisticians that are doing the meta-analysis, 13 they may use slightly different models, they 14 may use different trials as part of the thing, 15 so there is that aspect. But if two 16 statisticians have the same prior distribution, 17 the same kind of hierarchical setup, they're 18 going to get the same answer. 19 DR. MOCK: I too work with residents 20 on a regular basis and what I'm looking for is 21 that power to say to the residents, don't use 22 taxon with the HER positive/ER negative 23 patients, and know that it's correct, and not 24 have somebody say the opposite thing two hours 25 ago and have the press pick it up and broadcast file:///F|/pg061709%20(2).txt (287 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00288 1 it. So I'm saying, is there a manner in which 2 you can see that there would be rules for the 3 Bayesian process that would give us uniformity 4 of conclusions? 5 DR. BERRY: So, we design lots of 6 studies, we send them to the FDA. They say, 7 you send us a code, they may even rewrite the 8 code, they want validation, and they want to 9 ensure, if this is a registration trial, they 10 want to ensure that the model is doing exactly 11 what it says it's going to do, that they 12 understand it, and we've had this kind of thing 13 where everybody is happy and the thing runs 14 great. 15 So it's not for the design 16 perspective, it's not really an issue. It is 17 reproducible. There is a certain amount of 18 variability in the prior distribution that we 19 use and exactly what the modeling is, are we 20 going to do separate modeling as I did in the 21 ICD example across the five years, or am I just 22 going to combine all five years? Those are 23 choices, but if two people make the same choice 24 they're going to get the same answer. 25 DR. C. GOODMAN: Dr. Lewis, on this file:///F|/pg061709%20(2).txt (288 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00289 1 question? 2 DR. LEWIS: Yes. I think in terms of 3 trying to protect yourself against the 4 conclusions of the study being diversions, or 5 stated and understood, the kinds of probability 6 statements that a Bayesian analysis allows you 7 to make are actually less prone to those 8 changes in meaning that occur when you play the 9 telephone game with clinical teaching. 10 There is a second issue that was 11 partially addressed and I just want to clarify 12 it, which is the need to have standards for the 13 quality of the Bayesian analysis just like we 14 have standards for the quality of clinical 15 trial design, and standards for the 16 communication of that quality, for example a 17 consort diagram is a requirement for 18 publication of an RCT. I believe that there is 19 a need for some definitions regarding what is a 20 quality reporting and conduct of a Bayesian 21 analysis, and that will have to be developed 22 over time and will help protect us against poor 23 quality Bayesian analyses as the number of 24 Bayesians increases. 25 DR. C. GOODMAN: Thank you, Dr. Lewis. file:///F|/pg061709%20(2).txt (289 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00290 1 Dr. Steve Goodman, on this point? 2 DR. S. GOODMAN: Yeah. I just want to 3 address, which has come up from a number of 4 you, the perceived problem of interpreting 5 complicated models. The reasons these models 6 are complicated is because the questions were 7 complicated. It wasn't the models. Any answer 8 that would be presented to a complicated 9 question that put, any method that looked 10 incredibly simple is probably wrong, or it 11 doesn't capture the uncertainty properly. 12 So what you saw was an attempt to 13 grapple with the true dimensions of uncertainty 14 in what were inherently complicated questions. 15 You're asking how do we combine observational, 16 RCQ studies and RCT studies that might have 17 five different sets of eligibility criteria and 18 all these covariate measures? These are 19 complicated questions, so we can choose to 20 ignore the complexity and have a method that 21 will give the same answer every time, you 22 mentioned the uniform answer, or acknowledge 23 that, you know, in reading the tea leaves 24 there's some complexities here, and in fact 25 there's a range of answers. file:///F|/pg061709%20(2).txt (290 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00291 1 So I think the assumption of your 2 question that getting a single uniform answer 3 is necessarily the ideal outcome to a 4 complicated question may in itself be not the 5 optimal model for trying to figure out what the 6 right answer is. For a power like you, you 7 have to deal with uncertainty, you have to make 8 sure the uncertainties are represented 9 properly, and that's what these models are 10 doing, and they're complicated because the 11 questions you're asking are complicated. You 12 don't ask simple questions; you don't need us, 13 and you don't need whole panels to answer 14 simple questions. 15 DR. C. GOODMAN: Thank you, Steve 16 Goodman. Dr. Normand, on this point? 17 DR. NORMAND: Yes. So, I just wanted 18 to add on that last point is, I also want to 19 emphasize that when someone summarizes the 20 information used in a complicated analysis, the 21 summary is not complicated, the summary can be 22 in English and in three sentences, and you're 23 not going to see those subscripts and 24 subscripts, that's behind. But the point is 25 that in actually reading the paper, you're file:///F|/pg061709%20(2).txt (291 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00292 1 going to see the probability. So it can be, 2 the answer that you need to know is not going 3 to be an equation with 3,000 subscripts. 4 DR. C. GOODMAN: Dr. Hlatky. 5 DR. HLATKY: I'm going to have to 6 leave before too long so I'm going to say 7 something that I think is important, and I 8 basically think there is a place for this, but 9 it's conditional on something very important, 10 which, I'm convinced the more I read the 11 material where the FDA in its guidance says the 12 companies need to come to them when they're 13 designing a trial, go over the information, get 14 it locked in beforehand, and in that sense they 15 will say okay, we're willing to deal with this 16 analysis when you come to us for coverage. I 17 would say that that's a good lesson for CMS, 18 you know, if you want to use these methods in 19 designing trials, encourage people to come in 20 early in the design stages. 21 But the second thing, and I think a 22 corollary to that is I think that it seems to 23 me that if you want to use these methods, you 24 have to have people on staff here in the Agency 25 who are technical experts in these methods who file:///F|/pg061709%20(2).txt (292 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00293 1 can look at what's being presented and say 2 well, this is good, this is not so good, push 3 back, maybe get information that they analyze 4 separately. I think based on the FDA guidance, 5 that they sometimes want to do the analysis 6 independently. I think that that would give an 7 enormous amount of credibility to these things, 8 which quite frankly are being driven by a lot 9 of commercial, there's a lot of interests out 10 there, there's a lot of money on the table with 11 every one of these CMS decisions, and we 12 shouldn't fool ourselves into thinking that 13 there isn't. 14 So I mean, I think that it has to be 15 bulletproof is really what it has to be. So I 16 would say that I think these are encouraging 17 techniques, but I do think that we need experts 18 here in CMS to deal with them, and there has to 19 be an interchange. 20 DR. C. GOODMAN: Thank you, Mark. 21 Dr. Grant. 22 DR. GRANT: I have to go too, so I 23 will echo what Mark just said, and it is true. 24 The same kind of misuse, misinterpretation and 25 difficulties with traditional modes of file:///F|/pg061709%20(2).txt (293 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00294 1 synthesis and analysis, are just, you know, are 2 just everywhere. I see it all the time and I 3 don't think it's really any different there 4 versus here. At the same time, I think that, 5 if there's one point that wasn't made, and if 6 it was maybe I missed it, was the issue of 7 equipoise that in designing trials there is one 8 reason, or one compelling reason, that you're 9 exposing true patients to treatments that don't 10 work, which I would think has a lot to say for 11 using the design approach from that 12 perspective. 13 I am entirely convinced that having 14 direct positive statements associated with 15 certainty will improve the system. Is there 16 evidence to support that, I don't know. But, 17 that's all. 18 DR. C. GOODMAN: Thank you, Dr. Grant. 19 I want to pursue now, I think we've heard 20 about, most of what we need to know for 21 question two from our experts with their 22 opinions. Now our question three has to do 23 specifically with looking at whether CMS itself 24 as an agency should incorporate evidence that 25 uses Bayesian approaches in trials, as well as file:///F|/pg061709%20(2).txt (294 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00295 1 in technology assessments, and I think that 2 technology assessments here means secondary 3 syntheses, often depending upon systematic 4 reviews and other secondary analyses. 5 And so having discussed with you first 6 the question about the relative strengths and 7 weaknesses vis-a-vis a frequentist approach, 8 having talked about the net effect of the 9 strengths and liabilities of Bayesian for 10 designing studies and interpreting them, now 11 let's turn to, if it's okay with the panel, 12 turn to, well, what would be the advice to this 13 Agency, to CMS which has to make practical 14 decisions that will affect millions of 15 Americans and needs to hold up to public 16 scrutiny. 17 This is sort of a different world now. 18 We're out of the classroom and graduate school 19 and into the public fray here. So let's 20 explore, if you will, the clinical trials piece 21 first. CMS may be involved in, as was just 22 said, may be talking with sponsors of 23 interventions about how they might design 24 clinical trials or other kinds of data 25 gathering to ultimately inform a coverage file:///F|/pg061709%20(2).txt (295 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00296 1 decision, and how confident are you that the 2 Agency might encourage that or look well upon 3 that, using Bayesian approaches for clinical 4 trials? Comments by our experts? Dr. Normand. 5 DR. NORMAND: So the answer is yes, 6 you should do this, understanding that you have 7 to have the expertise to do this. 8 DR. C. GOODMAN: Is it always yes, Dr. 9 Normand? 10 DR. NORMAND: Yes. 11 DR. C. GOODMAN: Dr. Berry? 12 DR. BERRY: Yes. People talked about 13 over time when you publish these results, I can 14 understand them. And, you know, it's with some 15 reluctance that I refer to something that is my 16 own paper, but the thing that I showed the New 17 England Journal of Medicine, a paper on breast 18 cancer in women over 65, published May 14th, 19 last month, that is wholly, completely 20 Bayesian, and you can read it, you can 21 understand it, we've gotten some comments, two 22 reviewers said this is a wonderful study. You 23 know, you didn't have to have a full study 24 because you build in this Bayesian thing and 25 you get the answer in the shortest time file:///F|/pg061709%20(2).txt (296 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00297 1 possible, and it's like a love fest. And it's 2 understandable, and you should read it to see 3 if you can understand it. 4 DR. C. GOODMAN: Dr. Lewis, and then 5 Dr. Goodman. 6 DR. LEWIS: I agree the answer is yes 7 and it's always yes. There are situations in 8 which the net benefit of the Bayesian approach 9 over a more traditional approach will be 10 relatively less. Although there may be a 11 leviathan situation in which the sponsor is so 12 convinced of the effects of a therapy that 13 they're willing to invest, almost squander 14 extraordinary resources in the testing, and if 15 the sponsor is willing to do that, they will 16 end up with an easily interpretable answer. 17 They could have obtained that answer sooner, at 18 less cost and putting fewer patients at risk 19 had they adopted the Bayesian approach. I 20 don't know whether that's a concern of CMS. 21 DR. C. GOODMAN: Thank you. Steve 22 Goodman. 23 DR. S. GOODMAN: I'll just flip the 24 question around and say, imagine if the world 25 was entirely Bayesian, we all understood the file:///F|/pg061709%20(2).txt (297 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00298 1 mechanics and the vocabulary, what reasons 2 would we have to go to the current system? I 3 can't imagine one. 4 DR. C. GOODMAN: Thank you. Dr. Mock. 5 DR. MOCK: Thank you for those answers 6 regarding this question. Is there a difference 7 in your answers regarding technology assessment 8 versus study design? So the statistics are the 9 same regardless. 10 DR. C. GOODMAN: Let the record 11 reflect that the four experts were shaking 12 their heads that there was no difference. 13 Let me pose a little bit of kind of 14 like a second loaded question that is relevant 15 to question three. Certainly coverage and 16 evidence development is an important part of 17 the set of tools or processes that the Agency 18 has been using more or less over the years to 19 learn as we go. And actually part of the name 20 of this group, the ED in MedCAC is evidence 21 development. As I believe Dr. Luce suggested, 22 is a Bayesian approach inherent in coverage and 23 evidence development or an important tool for 24 it, or something that should be explicitly 25 stated when innovators and other sponsors come file:///F|/pg061709%20(2).txt (298 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00299 1 to seek a national coverage determination? 2 In other words, if it is an occasion 3 on which the Agency might want to suggest 4 coverage with evidence development, would the 5 Agency might want to discuss the use of 6 Bayesian approaches in that arrangement? Steve 7 Goodman. 8 DR. S. GOODMAN: I think others have 9 spoken to this and very well, and I just want 10 to say two things about that. One is, 11 certainly it is one of the only ways to 12 coherently think about how to add up and 13 accumulate the sometimes different information 14 that you're going to get from the evidence 15 development model after provisional, we'll say 16 a provisional coverage decision, than the data 17 that went before it. The data that went before 18 it may have been an RCT. The data that comes 19 after it, as was pointed out, may be an 20 observational study, it may be noncomparative, 21 and how to put those together is very very 22 tricky, and I can't imagine doing it in other 23 than this manner. 24 That said, and this addresses 25 something that Dr. Satya-Murti said before, file:///F|/pg061709%20(2).txt (299 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00300 1 this is something you're acutely aware of, the 2 incentives to do a proper study after even a 3 provisional coverage assessment sometimes slip 4 away, and this is something the FDA has come 5 across as well. Once it's covered, there's 6 often very very little incentive to get more 7 evidence because you're in a holding pattern, 8 and unless you have some sort of enforcement 9 pattern, that is a time-limited approval under 10 which it is required that more evidence be 11 gathered of a certain type that actually will 12 change your, will be sufficient to change your 13 decision depending on how it comes out, it 14 won't work. 15 So that's something for you to decide, 16 that's not a statistical issue, but it's a very 17 very complicated issue since your decisions 18 themselves affect both the quantity and quality 19 of the information that comes after, and you 20 have to think very carefully of whether the 21 registries or models that you set up actually 22 generate the information that you need. 23 Sometimes they don't. They're very well 24 intentioned, but at the end of the day they 25 don't give you the information that allows you file:///F|/pg061709%20(2).txt (300 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00301 1 to actually modify the decision when the 2 information comes in. 3 DR. C. GOODMAN: Thank you, point well 4 taken. Dr. Satya-Murti. 5 DR. SATYA-MURTI: Yeah, thanks. I'm 6 glad you iterated that and asked us to consider 7 that earlier this morning. I really think 8 saying no is infinitely harder, so if at all 9 possible, and our premise is, if in the 10 recommendation dossier like FDA does, CMS would 11 come out with that, or even build it into the 12 executive level language, I don't mean a CFR, 13 but within the Agency's language they define 14 what is reasonable and necessary and so on. If 15 we can carefully put in verbiage that says that 16 any coverage is really time and evidence 17 dependent, it could be annulled, and maybe 18 that's too harsh a word, but this is a pro tem 19 decision, and that's apparently what you are in 20 de facto doing under the guidance or documented 21 language. 22 DR. C. GOODMAN: Thank you. Other 23 comments on this point across the panel? 24 Dr. Dullum. 25 DR. DULLUM: Yes. I think if you can file:///F|/pg061709%20(2).txt (301 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00302 1 roll in the observational data with the written 2 approval, you could actually use streamlined 3 better therapy, maybe even find subgroups, I 4 don't know that this is possible, subgroups 5 that would also benefit from the treatment 6 process and it would really help to direct care 7 in that aspect. 8 DR. C. GOODMAN: Thank you, Dr. 9 Dullum. Dr. Grant. 10 DR. GRANT: Yes, just along these 11 lines, I think this is a point well taken for 12 the CED. There needs to be significant 13 attention to which parameters, which evidence 14 needs to be informed, very careful specific 15 attention, and I think otherwise, you're not 16 going to be in the circumstances to be able to 17 see an active interest and consideration being 18 formed, and that really is avoidable. So the 19 probability should be relatively low, we should 20 know whether or not to proceed with adoption or 21 reject it at that particular time. 22 DR. C. GOODMAN: Allow me to, with the 23 permission of the panel, ask sort of a 24 follow-up question for number three with regard 25 to the advisability of employing Bayesian file:///F|/pg061709%20(2).txt (302 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00303 1 methods compliant with the Agency, and it has 2 to do with innovation, and I think you touched 3 on it earlier today, so here's the issue. 4 The MedCAC in the past, at least some 5 of the ones in which I participated, and 6 coverage when we look at coverage 7 decision-making by other major payers in the 8 U.S. and frankly in the world, one of the 9 issues that arises is that technologies evolve 10 over time. So the gizmo changes over time and 11 the extra pieces, people who apply the gizmo 12 changes over time. Certainly in the device 13 realm, companies invent themselves around each 14 other all the time. 15 So innovation is occurring in real 16 time as we speak here, and some of the things 17 we've heard about in discussions between 18 innovators, regulators and payers is that if 19 you think there's something to think about in 20 innovation, then innovators need signals about 21 what's going to be expected of them over time 22 as far as evidence requirements and other 23 hurdles, and at the same time we need to be 24 able to recognize that the innovation isn't the 25 ones that we think. file:///F|/pg061709%20(2).txt (303 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00304 1 That said, can you address the matter 2 of the ability of Bayesian methods, if there 3 are any, to account for or reflect innovation 4 as it unfolds over time, and be able to drag 5 that into more informed coverage 6 decision-making? Dr. Normand. 7 DR. NORMAND: I don't know if this is 8 going to answer your question directly or get 9 to all of the pieces you want, but certainly 10 there are sources of variation that will be 11 accounted for in the Bayesian method, and these 12 relate to both over time it would relate to, 13 let's say with a surgical device, 14 surgery-specific variation. It would always 15 relate to device-specific variation. And so 16 there are pieces of the innovation as you model 17 the device longitudinally, and you would try to 18 separate out those components that you realized 19 were changing over time. 20 And so again, it amounts to a complex 21 model because you're trying to separate out 22 lots of pieces of information that would impact 23 on the variation of the outcomes which relate 24 to more centers using it, perhaps different 25 skilled surgeons using it, a different patient file:///F|/pg061709%20(2).txt (304 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00305 1 population using it, or the device changing 2 over time. So again, those are all components 3 that make the model more complex, but again, 4 it's a natural fit to a type of Bayesian model 5 that says okay, we can try to separate those 6 out a little bit over time. 7 DR. C. GOODMAN: So, that's partially 8 helpful. What you've answered, then, is at any 9 given time there may be variations on a 10 technological theme, and Bayesians can kind of 11 identify those and follow them individually? 12 DR. NORMAND: I'm saying that you 13 would have at a given point in time, in theory 14 you would have all the longitudinal information 15 prior to that time, so all of the changes made 16 in that device, et cetera, those things happen, 17 and then if you wanted to look at those things 18 right now, if we look at what happened, it's a 19 very complex model but in theory it could be 20 handled within a Bayesian framework. 21 And then the second thing you're maybe 22 asking is about future predictions of things, 23 with this type of change made in this 24 mechanism, if you change the device, if you do 25 this, if you do that, what kind of impact would file:///F|/pg061709%20(2).txt (305 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00306 1 that have on future types of patients, and 2 that's more of a predictive probability going 3 into the future. 4 DR. C. GOODMAN: Still drawn from your 5 progress. 6 DR. NORMAND: Well, it's today 7 posterior, because you've got to believe as a 8 Bayesian, right now I can tell you, and I'm 9 being a little dramatic here, but you can get 10 the best information, have the best evidence 11 you have available right now and based on that, 12 you write and choose what you're thinking, that 13 becomes your prior for future events, but 14 that's basically what Bayesians do. 15 DR. C. GOODMAN: Thank you. 16 Dr. Berry. 17 DR. BERRY: This is, the Bayesian 18 person is absolutely ideal for doing that, and 19 in fact it was one of the main reasons that CRH 20 had this Bayesian initiative, because they 21 would say well, devices are so different from 22 drugs, at least back then they were in that 23 they would change them all the time, and we 24 want to be borrowing information from the 25 pervious version of the device, and one can do file:///F|/pg061709%20(2).txt (306 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00307 1 that in a number of ways, not the least of 2 which is the hierarchical approach. 3 Gillian mentioned that the person that 4 did her Bayesian analysis on hierarchical 5 modeling was Lurdes Inoue, and she did her 6 dissertation at Duke and her dissertation was 7 precisely on this question. You have a device 8 that you've changed somewhat. You'd like to 9 have evidence in a clinical trial or some 10 evidence, high level evidence base that it's 11 not changed very much and that the outcome is 12 very similar. But you don't want to run a 13 thousand-patient trial, so you go back to the 14 lab and you say there are measures in the lab 15 that may be predictive, that may be related to 16 the performance of the device, and we concede 17 that that's true. 18 But we built a model as Steve Goodman 19 suggested here, not -- what he was talking 20 about was longitudinally, but here it's the 21 preclinical to the clinical. So imagine four 22 pieces where you've got preclinical on the 23 current device, clinical on the current device, 24 preclinical on the modification of the device, 25 some small amount of clinical on the file:///F|/pg061709%20(2).txt (307 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00308 1 modification of the device, but the totality of 2 the evidence pulls together the question of is 3 the modification of the device doing the same 4 thing as the previous version. So that's just 5 one example of the kind of thing that you can 6 do to borrow across the various levels of the 7 technology changing. 8 DR. C. GOODMAN: Okay. Could you just 9 finish this sentence for me? So, a Bayesian 10 approach is a credible method for assessing 11 evidence of effectiveness of an intervention 12 even as it is evolving over time because what. 13 DR. BERRY: Even as the device is 14 evolving over time because of the possibility 15 of modeling the relationship between the 16 previous versions of the device along the lines 17 of what Sharon-Lise was saying, and the current 18 version. And you may require a high level of 19 evidence through a clinical trial; that 20 clinical trial could be very much smaller based 21 on the Bayesian model. 22 DR. GOODMAN: Thank you, that helps. 23 Yes, Dr. Luce? 24 DR. LUCE: Just to build on that, and 25 I will try to do it in a very concrete way, I file:///F|/pg061709%20(2).txt (308 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00309 1 can picture a setting in which there's temporal 2 changes in evidence regarding the device could 3 be influenced by three things. One could be 4 secular trends of changes in the patient 5 population underlying risks. One could be 6 changes in the providers that are using the 7 device, greater personal or institutional 8 experience with the device if there's some 9 technical expertise required for its use. And 10 the third would be internal changes in the 11 device, so they actually change a design 12 feature, or a new version of it comes out. 13 The advantage of the Bayesian approach 14 in quantifying the estimates of the 15 effectiveness of the device through all of 16 those changes is that the model can 17 appropriately and explicitly include that 18 structure, you can estimate the effect of each 19 of those effects on it, that's one point. 20 The second point is you can picture a 21 situation in which CMS, for example, may have 22 approved coverage for a class of device and a 23 new device comes out that in a small trial 24 appears to be much more effective, and a 25 decision might be to either approve the new file:///F|/pg061709%20(2).txt (309 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00310 1 device and disapprove the previous ones, or 2 just approve the new device. The borrowing of 3 information across the population of devices 4 will help you come up with a better estimate 5 for the true effectiveness of the new device 6 using the information that you already have on 7 how that class of devices performs, and that 8 can yield a more accurate reliable decision 9 regarding the coverage of the new device. 10 DR. C. GOODMAN: Thank you. And so 11 the borrowing phenomenon is something, too, 12 which several of you have referred to today, 13 the borrowing of information. Thank you. 14 Dr. Normand. 15 DR. NORMAND: Yes. I just want to 16 follow up on something that the FDA permitted, 17 and Dr. Maisel I think is familiar with this, 18 and this was with an OPD, operating performance 19 criterion, so that was done without having to 20 implement a new clinical trial, but actually 21 compared to a lesser number, and what the FDA 22 approved was for an independent entity to 23 analyze all of the clinical trials, and so that 24 was used to borrow some information from some 25 patient populations, maybe older diabetics in file:///F|/pg061709%20(2).txt (310 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00311 1 some groups, but they actually used that 2 information, permitted that information to be 3 used when a new company came in and said I want 4 to have a new stent, I don't want to have a 5 clinical trial because this is similar to 6 another one already approved on the market, 7 what number do I need to get. And having all 8 that information together from the other 9 clinical trials, that helped the FDA to find a 10 very fine difference be made, basically a line 11 in the sand to say this is what you need to 12 move forward. So again, there is a method when 13 you're using Bayesian methods in this manner. 14 DR. C. GOODMAN: Thank you very much. 15 I don't see any questions now from our panel. 16 Do we have any further questions, any 17 panelist's questions that might plumb the depth 18 of our expertise from the front row at this 19 point? Okay. 20 Dr. Salive, any further questions for 21 the experts? 22 DR. SALIVE: No. 23 DR. C. GOODMAN: I notice that about 24 four members of the panel have left to catch 25 planes and so only the brave remain, so we will file:///F|/pg061709%20(2).txt (311 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00312 1 have a discussion among ourselves in public 2 obviously, but let's talk about each of our 3 three main questions, and if we do need in this 4 discussion to refer back to our experts or even 5 our public commenter, that would be fine. 6 Let's return, let's go back to each of the 7 questions starting with one, let's discuss it 8 as needed, try to answer it, and then move on 9 to two, and then move on to three, unless there 10 are any objections. Dr. Salive, is that okay 11 with you? 12 DR. SALIVE: That's great. 13 DR. C. GOODMAN: Let's take question 14 one, and I'll just sort of rephrase it, excuse 15 me, restate it. And it's a two-part question, 16 and this is not a voting question, it's sort of 17 what your answers are kind of question. And 18 so, in assessing the strength of evidence for 19 the effectiveness of a medical intervention 20 that incorporates Bayesian design or analysis 21 compared to a frequentist approach, please 22 discuss the following, and (a) is, what are the 23 potential greatest strengths of a Bayesian 24 approach? 25 And so, which of us might want to put file:///F|/pg061709%20(2).txt (312 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00313 1 something on the table that we might have heard 2 or not heard so far that stands out about a 3 Bayesian versus a frequentist approach? Dr. 4 Satya-Murti. 5 DR. SATYA-MURTI: Well, foremost is, 6 I'm not as scared of the Bayesian approach as I 7 was until this meeting, that's an advantage for 8 you. But anyway, adaptability strikes me as a 9 very useful piece of information and that we 10 can quantify the probability with that. 11 What does concern me is that the 12 intensity of training and the quality of 13 Bayesian varies, and how do I know, that's been 14 brought up. It's not something that cannot be 15 overcome, but that is a concern. And what is 16 reassuring is that such ancient questions as 17 what are clinically important to the MCID, or 18 how much of the benefit is important to make a 19 decision, that decision remains, so that 20 doesn't disenfranchise the decision-maker. 21 DR. C. GOODMAN: So you kind of gave a 22 thumbs up on the adaptability and a thumbs down 23 on sort of the variability? 24 DR. SATYA-MURTI: Well, yeah, the 25 complexity of the training requirement and file:///F|/pg061709%20(2).txt (313 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00314 1 quality, so you have to watch out. You need 2 built-in expertise or -- 3 DR. C. GOODMAN: Okay, complexity in 4 training is a potential disbenefit. Other 5 comments on this? Dr. Dullum perhaps? 6 DR. DULLUM: Well, I think the 7 strength to me is the adaptability is ongoing 8 as we do get more information, and I think 9 that's a huge benefit that will improve the 10 quality of care and the use of this in guiding 11 our management of patients, so I think that's a 12 huge benefit. 13 I guess I'm now not so concerned about 14 the prior because it does, it's kind of an 15 ongoing, it does change and if you're wrong 16 about your prior, it seems to be of less 17 significance once you get conflicting data, and 18 that's all good with the strengths of it. 19 And in the weakness, I guess, is the 20 complexity and still needing to have in-depth 21 statisticians, paperers anyway, but if this 22 makes it easier for us to understand, I think 23 that would also be a benefit, but that seems to 24 me to be a downside, is that the knowledge has 25 to be so in depth. file:///F|/pg061709%20(2).txt (314 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00315 1 DR. C. GOODMAN: Thank you. Dr. Cox, 2 anything about strengths or weaknesses? 3 DR. COX: I really don't have anything 4 unique to say other than it does seem to me in 5 the world that we come into, I know there's 6 been a growth of registries, clinical 7 registries. One of the strengths that I have 8 learned over the past two weeks of being 9 introduced into this in depth, and talked about 10 today, is the ability to blend different 11 sources of data, and this whole source of 12 borrowing sources more intelligently and 13 treating patients better in that regard. 14 And the weaknesses, I think we're 15 beating it to death, and others have said it 16 quite well, but it's apparent that this is 17 complex, and so we have a lot of education and 18 I think training coming, to be able to 19 understand this better. 20 DR. C. GOODMAN: Great, thanks. 21 Dr. Maisel. 22 DR. MAISEL: I mean, I agree with 23 what's been said. I think the transparency as 24 we have been using the term with the results 25 and the probability is a definite advantage. I file:///F|/pg061709%20(2).txt (315 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00316 1 think the prior knowledge that we have of the 2 prior data is also an advantage. 3 I do have some concerns, unlike some 4 of the speakers, of the need for practicing 5 physicians to understand the data. I think 6 it's critically important that people who take 7 care of patients and read journal articles can 8 understand the data that they're looking at and 9 understand the statistical analysis that 10 underlies it. I don't think that's a problem 11 that can't be overcome, and I think CMS or 12 others could work hard at putting these types 13 of data analyses into context with a coverage 14 decision, perhaps have a section that explains 15 what the analysis is if a Bayesian approach was 16 used, why this analysis was used, and whatever 17 else may be of interest to the practicing 18 clinician. And I think it could be worked on 19 in journals to better explain, and not just in 20 statistics journals but journals that 21 practicing clinicians use to better inform them 22 about how a Bayesian analysis might have been 23 applied. 24 DR. C. GOODMAN: Great point. So 25 you're saying as the message is disseminated, file:///F|/pg061709%20(2).txt (316 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00317 1 accompany it with some translation and 2 explanation and so forth. 3 DR. MAISEL: Exactly. I don't think 4 it's enough to have so-and-so wrote something 5 down and followed up with a statistical 6 analysis, and we are entitled to understand 7 what that means to some degree. 8 DR. C. GOODMAN: Dr. Alvir. 9 DR. ALVIR: Just the point that if 10 you're doing the Bayesian approach correctly, 11 then there is all this initial investment that 12 you have to do with just laying out all your 13 assumptions, which doesn't preclude that from 14 happening nor doing that correctly too, you 15 actually should be doing all of that also, but 16 again, just that requirement, to actually think 17 all of these through from the beginning and 18 putting all of those assumptions in at the 19 front end, at the beginning, is a great 20 advantage. 21 DR. C. GOODMAN: Thanks. Just to kind 22 of recap some of the other points that we've 23 heard, strengths anyway, again, the 24 transparency that's come up several times, the 25 explicitness regarding methods and synthesis file:///F|/pg061709%20(2).txt (317 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00318 1 with regard to strength and quality of design 2 and findings, specific definition of utility 3 was brought up, and then this other point with 4 regard to as our ability to generate data, 5 analyze it, come up with tools for mining and 6 analyzing data, that will just play to the 7 strengths of Bayesian from what we heard. 8 The weaknesses, again, we heard about 9 having to train people to do this, we talked 10 about the multiplicity of model approaches and 11 how there's really a spectrum of bad to good, 12 and what we're not really good at yet is having 13 some sort of approach to assess bad to good, 14 and that's something that would help with 15 regard to sifting through the methods. The 16 paradigm shift is something that's not the 17 fault of any particular method, but a paradigm 18 would have to shift, and that discontinuity 19 brings disquiet to the stakeholders. 20 I think that the set we just recited 21 back to you is probably not a bad summary of 22 the strengths and weaknesses compared to the 23 frequentist approach. Did we miss anything 24 else that we need to state here? 25 Dr. Satya-Murti. file:///F|/pg061709%20(2).txt (318 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00319 1 DR. SATYA-MURTI: Like Bill said, a 2 small addition at the end of an article of what 3 they see as strengths. Most of the journals 4 only pick one or two articles, but this one has 5 made it a point to look at strengths and 6 weaknesses, so I think some kind of a 7 translation of the strengths and weaknesses to 8 a major decision would be very good. I think 9 that's a good idea. 10 DR. C. GOODMAN: Okay. Good. If I'm 11 not mistaken, I think we just answered 12 Question 1 as part of the record, based on what 13 we just summarized. 14 Question 2 is a voting question on a 15 one to five scale, and Question 2 asks, how 16 confident are we that the potential strengths 17 of Bayesian approaches outweigh the potential 18 liabilities in the design and interpretation of 19 a published study, and let's look at the 20 designing studies part first. How confident 21 are we that the potential strengths of Bayesian 22 approaches outweigh the potential liabilities 23 basically in designing studies? 24 So on that set of one to five where 25 liabilities outweigh the strengths is a one and file:///F|/pg061709%20(2).txt (319 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00320 1 a five is strengths outweigh the liabilities, 2 can you hold up your cards, please. 3 (Members voted and the votes were 4 recorded by staff.) 5 DR. C. GOODMAN: Thank you. Okay. 6 Part two is the same question but instead of 7 about designing studies, it's interpreting 8 study results. So how confident are we that 9 the potential strength of Bayesian approaches 10 outweigh the potential liabilities of 11 interpreting study results? 12 (Members voted and the votes were 13 recorded by staff.) 14 DR. C. GOODMAN: And before I forget, 15 just for the record, the panelists who had to 16 leave earlier have supplied their scores. 17 MS. ELLIS: Correct. 18 DR. C. GOODMAN: Those are in the 19 hopper, then. 20 Question 3 now has to do with, and we 21 just finished discussing that a little while 22 ago, and this is a two-part once again. And 23 the question goes, how confident are we that 24 CMS should incorporate evidence that uses 25 Bayesian approaches in technology assessments file:///F|/pg061709%20(2).txt (320 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00321 1 in, A, clinical trials, and B, technology 2 assessments, submitted for coverage decisions? 3 Okay. CMS is going to get the stuff, 4 evidence, submitted for things that may need 5 national coverage determinations. And in the 6 role of, in the instance of clinical trials, 7 how confident are we that CMS ought to utilize 8 Bayesian methods for clinical trials? Dr. 9 Satya-Murti. 10 DR. SATYA-MURTI: Very briefly. So 11 there is an assumption there that CMS has been 12 involved in the clinical trial when the study 13 was already designed? 14 DR. C. GOODMAN: I would say not 15 necessarily so. Dr. Salive, comment? I 16 wouldn't assume that. 17 DR. SALIVE: I would not assume that. 18 DR. SATYA-MURTI: That changes the 19 tenor. 20 DR. C. GOODMAN: At least for you, 21 Dr. Satya-Murti. Yes, Dr. Dullum? 22 DR. DULLUM: Can I clarify it too? 23 They have to use Bayesian statistics or 24 analysis to even look at it, or are you talking 25 about applying this to a study that's already file:///F|/pg061709%20(2).txt (321 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00322 1 been done by a frequentist? 2 DR. C. GOODMAN: My reading of it 3 would be that a sponsor or other advocate might 4 seek a coverage decision at this level, CMS, 5 and would supply some body of evidence, and 6 said body of evidence would include that of 7 clinical trials, and those clinical trials 8 might have used Bayesian approaches. So having 9 been presented that evidence, how confident are 10 you that CMS ought to incorporate it in making 11 their decision. 12 DR. SATYA-MURTI: We don't necessarily 13 know how those trials were designed yet? 14 DR. C. GOODMAN: We don't, but 15 presumably what we know at CMS, and sometimes 16 with help from an evidence-based practice 17 center, will appraise the evidence presented to 18 it. 19 DR. SALIVE: I don't think we need to 20 make this more complicated than the question 21 is. It seems like a fairly straightforward and 22 simple question to me, should we have CMS 23 incorporate Bayesian analyses using their 24 judgment in asking the proper questions about 25 whether it's used in the right way and file:///F|/pg061709%20(2).txt (322 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00323 1 incorporated the proper way. I think we can 2 rely on their judgment to do it properly. 3 DR. C. GOODMAN: They could appraise 4 it. Okay. Where one is CMS ought to 5 discourage this sort of thing, and five is they 6 ought to encourage, on a one to five scale. 7 (Members voted and the votes were 8 recorded by staff.) 9 DR. C. GOODMAN: So we're not quite -- 10 excuse me. Yes, the technology assessment 11 part, and remember, there is a distinction 12 between clinical trials and technology 13 assessments, and we've got our cards up. 14 (Members voted and the votes were 15 recorded by staff.) 16 DR. C. GOODMAN: Before some final 17 comments, Dr. Salive, is there anything that 18 you would have wished we had covered that we 19 still might address before we have final 20 comments and then adjourn? 21 DR. SALIVE: No. 22 DR. C. GOODMAN: Good. Before we do 23 adjourn, and I just want to give credit in due 24 time to the brave ones who survived today and 25 are still on the panel. file:///F|/pg061709%20(2).txt (323 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00324 1 We have gone over quite a bit in 2 detail as far as methodologies for Bayesian 3 versus frequentist in terms of primary data 4 gathering, secondary data gathering, what are 5 some indications for the Agency. Since we 6 still have the floor insofar as it applies to 7 advice to the Agency, do you have any 8 additional insights or advice to the Agency 9 about incorporating Bayesian methods in its 10 deliberations regarding evidence requirements 11 for coverage or how the Agency might work with 12 intervention sponsors that might approach it 13 with regard to coverage? Dr. Maisel? 14 DR. MAISEL: I'm not sure what the 15 normal practice is for CMS, but I do think it 16 would be valuable to put in writing your 17 approach to Bayesian analyses, and so if you're 18 going to permit people to come in with analyses 19 such as this, you might outline the things 20 you're going to judge the analysis on, such as 21 a prespecified amount of decisions before the 22 trial is started, that the results should be 23 well documented in a timely fashion before the 24 trial is completed, those are some things that 25 I think are critical in getting quality file:///F|/pg061709%20(2).txt (324 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00325 1 analyses. 2 DR. C. GOODMAN: Great comment. 3 Dr. Cox. 4 DR. COX: Just following up on that, 5 these documents also help those of us in the 6 community or in research who understand, it 7 gives us the kind of over the bow explanation 8 that you need to understand the analysis, so it 9 helps press the paradigm. 10 DR. C. GOODMAN: Great, thank you. 11 Dr. Satya-Murti. 12 DR. SATYA-MURTI: There are 13 commonalities between the Bayesian and the 14 frequentist approach, and that is that the 15 final outcome of the study still doesn't 16 change, so in that guidance it will be good 17 also to stress what is common, so we don't 18 necessarily think of this as too adversarial. 19 DR. C. GOODMAN: Thank you. My final 20 comment for you is this. This is a great time 21 to be looking at Bayesian methods, whether you 22 look them or not, looking at Bayesian methods 23 and their sister approach, adaptive trial 24 designs and others, this is an important time 25 to look at these. There are several things file:///F|/pg061709%20(2).txt (325 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00326 1 going on in our current environment that are 2 affecting current decision-making here in the 3 U.S., whether public payers or private, 4 internationally, others around the world, and 5 the various things going on with a heightened 6 interest in a bunch of abbreviations and 7 acronyms, health technology assessment, HTA, 8 EBM, evidence-based medicine, as we've heard 9 here today, CED, coverage with evidence 10 development, comparative effectiveness 11 research, heterogeneity of treatment effects in 12 other subpopulations, the role of personalized 13 medicine, and the importance of tracking 14 innovation and accounting for how it's changing 15 effects on patient health. 16 So those half dozen things that I just 17 listed all have the potential to benefit from 18 the insights gained by things like Bayesian 19 methods, so I applaud the Agency for looking at 20 this very important issue. It's timely, it is 21 very important that you are looking at it and 22 considering it. 23 I think that there is an extraordinary 24 wealth of expertise, not only represented by 25 the experts from whom we've heard today, but in file:///F|/pg061709%20(2).txt (326 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00327 1 the United States and around the world, so I 2 think it's a very good step that CMS is looking 3 at seriously in this current environment, as 4 we're looking more carefully at how we assess 5 interventions for patients' health in the 6 United States. 7 So hats off to the Agency. I want to 8 thank, including those who aren't here, 9 Dr. Satya-Murti, Dr. Axelrod, Dr. Cox, 10 Dr. Dullum, Dr. Grant, Dr. Hlatky, Dr. Maisel, 11 Dr. Prager, Dr. Alvir. I want to thank our 12 guess speakers who have been very helpful, 13 patient and informative; that would include Don 14 Berry, Steve Goodman, Roger Lewis, Sharon-Lise 15 Normand and Gillian Sanders. We are very 16 grateful for the expert guidance and good 17 logistical planning from Dr. Marcel Salive, 18 Maria Ellis, and the rest of the staff here at 19 CMS. With that, Dr. Salive? 20 DR. SALIVE: I want to thank all 21 those same people plus Rosemarie Hakim, plus 22 Steve Phurrough for thinking about this idea 23 and then leaving, not necessarily in that 24 order, but thanks to everyone, and safe travels 25 home. file:///F|/pg061709%20(2).txt (327 of 328) [8/14/2009 7:14:08 AM]file:///F|/pg061709%20(2).txt 00328 1 DR. C. GOODMAN: We're adjourned, 2 thank you. 3 (Whereupon, the meeting adjourned at 4 3:58 p.m.) 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 file:///F|/pg061709%20(2).txt (328 "}