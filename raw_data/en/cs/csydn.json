{"title": "PDF", "author": "PDF", "url": "https://biostat.app.vumc.org/wiki/pub/Main/Ocu20202021/OCU2021.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "SELECTED TOPICS IN PHASE IIAND III CLINICAL TRIALS Tatsuki Koyama, PhD Department of Biostatistics, Vanderbilt University Medical Center tatsuki.koyama@vumc.org Osaka City University, analysis following a two-stage design in phase II crossover design for the comparison of two active treatments and placebo 77 7.6 Latin Study: CEASAR Prostate cancer is the second leading cause of cancer death among American men behind lung cancer. The common treatment choices for localized disease are surgery, radiation, and observation (active surveillance). For localized prostate cancer, 5-year survival is nearly 100% , and in compar- ative effectiveness studies, patient-reported disease-specic functional outcomes are often used as the primary endpoint. The Comparative Effectiveness Analysis of Surgery and Radiation (CEASAR) study1assessed patient-reported functional outcomes and health-related quality of life at 3 years after treatment. Suppose we are interested in comparing the Sexual Functional Score (QOL) after 3 years from treatment. groupSum(d$Epic36, d$Treatment, Combined=FALSE) N Min Q1 Med Q3 Max Mean SD SE Surgery 1222 0 10.00 33.3 70 100 41.0 33.4 0.96 Radiation 38.3 70 100 40.4 33.5 1.27 with(d, t.test(Epic36 ~ Treatment)) Welch Two Sample t-test data: Epic36 by Treatment 1Barocas et al., \"Association between radiation therapy, surgery, or observation for localized prostate cancer and patient-reported outcomes after 3 years\" = 1432, p-value = 0.7 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: -2.51 3.74 sample estimates: mean in group Surgery mean in group Radiation 41.0 40.4 This shows there is no statistically signicant difference in QOL. However, it is well-known that the patient populations for Surgery and Radiation are very different. The baseline QOL is quite different between the groups as shown below. groupSum(d$Epic00, d$Treatment, Combined=FALSE) N Min Q1 Med Q3 Max Mean SD SE Surgery 1388 0 41.7 80 95 100 65.9 32.8 0.88 Radiation 853 0 23.3 60 85 100 54.5 33.1 1.13 with(d, t.test(Epic00 ~ Treatment)) Welch Two Sample t-test data: Epic00 by Treatment t = 8, df = 1793, p-value = 3e-15 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: 8.61 14.24 sample estimates: mean in group Surgery mean in group Radiation 65.9 54.4 As Table below shows, some of other baseline characteristics that are probably associated with the post-treatment QOL are highly different between groups. Clinical Trials 3 Tatsuki Koyama, PhDTable 1.1: CEASAR baseline characteristics N Surgery Statistic N=1455 N=908 Age at diagnosis 2363 5762 66 63 (597) (307) c2 2=17, 44% (395) High Risk 17% (243) 22% (202) PSA at diagnosis, corrected 2363 4.25.1 6.9 4.5 5.9 8.5 F1;2361=49, P<0.0011 Marital 9% (120) 13% (111) c2 4=15, P=0.0052 22% (306) 24% (336) 21% (185) Graduate/professional school 24% (340) 21% (161) SF36 Score 2287 85100 median b, and the upper quartile cfor continuous variables. Nis the number of non-missing values. Numbers after percents are frequencies. Tests 1Wilcoxon test;2Pearson test Clinical Trials 4 Tatsuki Koyama, PhDIn general, establishing a cause-and-effect association from an study is difcult due toconfounders . Confounder A prognostic factor that is associated with both response (e.g., Quality of Life) and explanatory variable (e.g., treatment choice). We can analyze the data with a method that accounts for the baseline difference in the treatment groups. QOL\u0018Treatment\u0002(Baseline QOL + Age + Race + TIBI + Risk + PSA) How about comorbidities? sex? smoking? Many statistical methods exist to establish causal relationships from an observation study such as propensity scores and instrumental variables. Can observational studies establish a cause-and-effect association? Philip Morris International https://www.pmi.com/our-business/about-us/our-views/health-effects-of-smoking-tobacco \"Cigarette smoking causes serious disease and is addictive.\" \"All cigarettes are harmful and addictive.\" \"Public health authorities have concluded that secondhand smoke causes diseases, including lung cancer and heart disease, ...\" JT https://www.jti.co.jp/tobacco/responsibilities/guidelines/responsibility/index.html https://www.jti.com/about-us/our-business/our-six-core-principles \"Smoking is a cause of serious diseases including lung cancer, coronary heart disease, em- physema and chronic bronchitis.\" \"All relevant risk factors need to be taken into consideration when investigating the cause or causes of a disease in any smoker.\" 1.2 Experiment Observational study A study design in which the investigator does not control the assignment of treatment of individual study subjects (Piantadosi2) 2Clinical Trials: A Methodologic Perspective Clinical Trials 5 Tatsuki Koyama, PhDExperiment A study in which the investigator makes a series of observations under controlled/arranged conditions. In particular, the investigator controls the treatment applied to the subjects by de- sign. (Piantadosi) Clinical trial A prospective study comparing the effect and value of an intervention against a control in human subjects (Friedman3) Advantages of observational studies include: Lower cost. Greater timeliness. A broad range of patients. Greater application where experiments would be impossible or unethical. Theadvantage of clinical trials is that they can establish a cause-and-effect association. 1.2.1 Example: PIVOT In Prostate Cancer Intervention Versus Observation Trial4(PIVOT), prostate cancer patients who were good candidates for radical prostatectomy were enrolled from 1994 to 2002. The last obser- vation was made in 2010. The results were presented at American Urological Association Annual Meeting in May, 2011. The inclusion criteria for the study were: 75 years or younger. Localized disease. PSA\u001450mg=mg. Diagnosed with 12 months. Radical prostatectomy candidate. With the all-cause mortality as the primary endpoint, the primary objective was to answer the follow- ing question: Among men with clinically localized prostate cancer detected during the early PSA era, does the intent to treat with radical prostatectomy reduce all-cause & prostate cancer mortality compared to observation? 3Fundamentals of Clinical Trials 4Wilt et al. (PIVOT Study Group). \"Radical prostatectomy versus observation for localized prostate cancer\". N Engl J Med. 2012. 367(3):203-213. Clinical Trials 6 Tatsuki Koyama, PhD13;022men entered into of the prostatectomy group and 35(10%) of the observation group. The following table summarized the assigned and received treatments. Actual Treatment Assigned Treatment Surgery Observation Other Surgery 281 (77%) 53 (15%) 30 ( 8%) 364 analysis compares 364surgery patients and 367observation patients based on their assigned treatments. As-treated analysis compares 317surgery patients and 345observation patients based on their received treatments. Per-protocol analysis compares 281surgery patients and 292observation patients who adhered to the protocol. Conclusions: \"Among men with localized prostate cancer detected during the early era of PSA test- ing, radical prostatectomy did not signicantly reduce all-cause or prostate-cancer mortality, as com- pared with observation, through at least 12 years of follow-up. Absolute differences were less than 3 percentage points.\" Clinical Trials 7 Tatsuki Koyama, PhDChapter 2 Multiplicity in Clinical Trials -FDA's Guidance- 2.1 Background The problem When Khypothesis tests are conducted with type I error rate of a, the overall type I error rate becomes higher than a. The overall type I error rate =P[At least one type I error] =Family-wise error. Suppose there are 8hypothesis tests, and each is conducted at 5%level. Then P[At least one type I error] =1\u0000P[no type I error] =1\u0000(1\u00000:05)8 =0:337 And to control the family-wise type I error rate at 5%, each test must be conducted at a=0:00639 because 1\u0000(1\u00000:00639 )8=0:05 Recent development 2016.12 EMA: Guideline on multiplicity issues in clinical trials 2017.1 FDA: Draft guidance. Multiple endpoints in clinical trials 2017.8 in Med: A Dmitrienko RB D'Agostino. Journal of Biopharm Stat: Special issue on multiplicity issues in clinical trials Clinical Trials 8 Tatsuki Koyama, PhD2018.5 NEJM: A Dmitrienko clinical trials\" Guidelines EMA: Guideline on multiplicity issues in clinical trials (Draft) -15 pages -Draft published on 12/15/2016 -Replaces \"Points to consider on multiplicity issues in clinical trials\" (Adopted 2002) FDA: Multiple endpoints in clinical trials: Guidance for industry -50 pages -Draft published in January 2017 -Details on statistical methods in addition to general principles Prespecication is necessary. \"An important principle for controlling multiplicity is to prospectively specify all planned endpoints, time points, analysis populations, and analyses.\" Multiplicity topics / of (FDA)) Multiple analyses -Subgroup analyses -Multiple analyses methods Clinical Trials 9 Tatsuki Koyama, PhD Superiority/Non-inferiority (FDA) Safety variables (EMA) Multiple treatment arms (EMA) Dose-response studies (EMA) Estimation (EMA) Endpoints Primary endpoints \"Success on any one alone could be considered sufcient to demonstrate the drug's effective- ness\" Secondary endpoints evidence \"All other endpoints\" (Is adjustment necessary?) \"endpoints that are thought to be less likely to show an effect but are included to explore new hypotheses\" Endpoints are frequently ordered by -clinical importance (Mortality as primary) -the likelihood of demonstrating an effect (PFS as primary, OS as secondary) Composite endpoint Combine clinical outcomes into a single variable. Cardiovascular death OR heart attack OR stroke. (coronary artery disease) MAKE 30 (Major Adverse Kidney Events: impaired renal function OR hemodialysis OR death (AKI) \"Analyses of the components of the composite endpoint are important and can influence interpreta- tion of the overall study results.\" Co-primary endpoints Demonstration of treatment effects on more than one endpoint is necessary to conclude efcacy. FDA requires each test be done at 5%level. Relaxation of alpha ... would undermine the assurance of an effect on each disease aspect considered essential to showing that the drug is effective. Clinical Trials 10 Tatsuki Koyama, PhDa=0:22(0:222\u00190:05) if independent. Type II error rate inflation may be severe. ( 0:052=0:0025) Co-endpoints are likely to be correlated, but the correlation is unknown. Contrast this to a group sequential design where the correlation of accumulated data can be computed. Cov(Zj;Zk) =p Nj=Nk. a1=0:030anda2=0:030for the Pocock boundary. 2.2 Statistical methods Statistical methods to control family-wise type I error rate (FWER) \"Two-arm trials that examine treatment versus control on multiple endpoints\" \"Similar considerations: different time points, different doses. Two Multistep procedures (step-down, step-up, sequential procedures) -Generally more (power) -Condence interval not readily available 1. The Bonferroni Method 2. The Holm Method 3. The Hochberg Method 4. Prospective Alpha Allocation Scheme 5. The Fixed-Sequence Method 6. The Fallback Method 7. Gatekeeping Testing Strategies 8. The Truncated Holm and Hochberg Procedures for Parallel Gatekeeping 11 Tatsuki Procedures Common Statistical Method 1. Bonferroni (Single step; assumption free) Each hypothesis test is conducted at a=Klevel. a=K\u0019the solution, a, toa=1\u0000(1\u0000a)K. 2. Holm (Multi-step step down; free) H1;\u0001\u0001\u0001;Hmis a family of mnull hypotheses, and P1;\u0001\u0001\u0001;Pmare the corresponding P-values. The ordered P-values, P[i]are compared to a=(m+1\u0000k), and let kbe the smallest index such thatP[i]>a=(m+1\u0000i). Reject null hypotheses H(1);\u0001\u0001\u0001;H(k\u00001). Example: a=0:05.p1=0:015,p2=0:03,p3=0:04,p4=0:01. Holm method: p[1]=0:01,p[2]=0:015,p[3]=0:03,p[4]=0:04. The and 0:05. 3. Hochberg (Multi-step step up; Positive correlation) Similar to Holm but backwards. Start comparing the largest p-value to aand work the way down to the smallest p-value. Reject all H0once p[k]<a=(m+1\u0000k). 4. Prospective Alpha Allocation Scheme (Single step; Positive correlation) Similar to Bonferroni, but the aforementioned cases where the Hochberg procedure is known to be valid, its use is generally not recommended for the primary comparisons of conrmatory clinical trials unless it can be shown that adequate control of Type I error rate is provided. Sequential method 5. Fixed-Sequence Method Tests endpoints in a predened order, all at a=0:05, moving to the next endpoint only after a success on the previous endpoint. Clinical Trials 12 Tatsuki Koyama, PhD6. Fallback Method Fixed-sequence method with some a\"saved\" for later use. (e.g., 0:03on the rst test, 0:02on the second.) Suppose pA=0:045,pB=0:015,pC=0:065, and the sequence is C, B, A. A (0:045) B ( 0:015) C ( 0:065) Bonferroni not Reject Reject not Reject Holm not Reject Reject not Reject FSM (C,B,A) not Reject not Reject not Reject FSM (A,B,C) Reject Reject not Reject Fallback (C,B,A) not Reject Reject not Reject Gatekeeping testing strategy The gatekeeping testing strategy tests the primary and secondary families sequentially with a=0:05 for the primary family and with some apassed on to the secondary family. Serial gatekeeping strategy The primary family are tested as co-primary endpoints ( a=0:05). The secondary family is tested only if all primary null hypotheses are rejected (at a=0:05). Parallel gatekeeping strategy The primary family uses a strategy that allows passing of an individ- uala, and the secondary family allocates the passed-on (accumulated) amount. Parallel gatekeeping strategy Primary endpoints (A, B) a=0:05 Bonferroni with 0:04for A and 0:01for Secondary 0:019) Reject not Reject 0:04is passed to (C, D, E) Critical values: 0:0133,0:02,0:04 Reject not Reject Reject Clinical Trials 13 Tatsuki Koyama, PhD2.3 Graphical approach Using gMCP package in R. K Rohmeyer, F Klinglmueller (2018). gMCP: Graph Based Multiple Test Procedures. R pack- age version 0.8-14. F Bretz, M Posch, EGlimm, FKlinglmueller, W Maurer, K Rohmeyer (2011), Graphical ap- proaches for multiple comparison procedures using weighted Bonferroni, Simes Koyama, PhDH1 a=3H2 a=3H3 a=31 21 2 21 2 Holm using gMCP Package: Step 1 Holm using PhDFixed sequence method H1 method H1 Improved fall back method H1 1 21 2 Clinical Koyama, PhDImproved fall back with gMCP package: Step 1 Improved fall back with gMCP package: Step 2 Improved fall back with gMCP package: Step 3 Clinical Trials 21 21 2 1 1 1Primary Secondary Clinical Trials 18 Tatsuki Koyama, PhDChapter 3 Randomization 3.1 Example: Polio vaccine trial (1954) In 1954, 1:8million children participated in the largest clinical trial to date to assess the effectiveness of the vaccine developed by Jonas Salk in preventing paralysis or death from poliomyelitis. 1:8million children in selected school districts throughout the US were involved in this placebo- controlled trial. -Why was placebo necessary? -60;000cases in 1952; about half of that in 1953. Randomized trial. -750;000children participated. -They required parents' consent. -Half of the children with consent were randomized into the vaccine group. NFIP design. -The National Foundation for Infantile Paralysis (NFIP) conducted a study in which all 2nd graders with consent received the vaccine with 1st and 3rd graders acting as control. -1;125;000children participated. -The control children did not require consent. Systematic difference between groups. -No blinding. -Polio is a contagious disease! Clinical Trials 19 Tatsuki Koyama, PhDThe results double-blind design Size Treatment Control 200;000 71 No consent 350;000 46 (\u0003Rate of polio cases per 100;000) The NFIP design Size Rate\u0003 Treatment 225;000 25 Control 725;000 54 No consent 125;000 44 (\u0003Rate of polio cases per 100;000) 3.2 Introduction Randomization Assignment of patients or experimental subjects to two or more treatments by chance alone. Main advantages of randomization It removes the potential of bias in the allocation of participants to the intervention group or to the control group (allocation bias). It tends to produce similar (compatible) groups in terms of measured as well as unmeasured confounders confounding by indication in observational studies. Randomization is considered so important that the intention-to-treat principle considered sacrosanct: \"Analyze by assigned treatments irrespective of actual treatment received.\" Perceived disadvantages of randomization are often about emotional and ethical issues. !randomization before consent Predecessors to randomization: Alternating assignments (TCTCTCTC...). 1Freedman et al. Statistics, second edition Clinical Trials 20 Tatsuki Koyama, PhD Treatment assignment based on birthday / day of the week. The primary problems with these non-random assignment are the lack of assurance of comparability (baseline balance). An additional issue with the \"alternating assignments\" is that if one is unblinded, all the rest are unblinded, too. 3.3 Simple randomization For each subject, flip a coin to determine treatment assignment. P[treatment 1] =\u0001\u0001\u0001=P[treatment k]=1=k. Problems with simple randomization and how to deal with them. Imbalance in treatment allocation. -Replacement randomization. -Block randomization. -Adaptive randomization. (Biased coin / Urn Imbalance in baseline patient characteristics. -Stratied randomization. (Stratied permuted block randomization) -Covariate adaptive randomization. 3.4 Imbalance in treatment allocation If the number of patients, Nis20,P[10and 10] =0:18. The probability of 7to13split or worse is 26%. The treatment effect variance as 10-10 split. Even if treatment allocation is balanced at the end of trial, there may be a (severe) imbalance at some point. Because we may monitor trials over time, we prefer to have balance over time. 3.4.1 Block randomization To ensure a better balance (in terms of number of patients) across groups over time, consider a block randomization (random permuted blocks). Clinical Trials 21 Tatsuki Koyama, PhDBlock randomization ensures approximate balance between treatments by forcing balance after a small number of patients (say 4 or 6). For example, the rst 4 patients are allocated to treatment A or B sequentially based on AABB . There are 6 sequences of A,A,B,B, and let each sequence have 1/6 chance of being selected. AABB ABAB ABBA replace=FALSE), '\\n') } 1 B A B A 2 B A A B 3 A B A B 4 A A B B 5 B A A B What's wrong with block size of 2? Block size of 200? Easily applicable to more than 2 groups in 1:5){ cat(i, sample(rep(LETTERS[1:3],each=2), 6, replace=FALSE), '\\n') } 1 A B C C B A 2 A B C B C A 3 A A B C B C 4 C C B A A B 5 B C A B A C Easily applicable to unequal group sizes ( Na=40andNb=20). for(i in 1:5){ cat(i, sample(rep(LETTERS[1:2],c(4,2)), 6, replace=FALSE), '\\n') } 1 B A A A B A 2 A B A A A B 3 A A A B B A 4 A A B A B A 5 A B B A A A Clinical Trials 22 Tatsuki Koyama, PhDWhy might we want unequal group sizes? We may want to have a better estimate of the effect for the new treatment. Treatment costs may be very different. Given the total sample size and the relative cost of treatment 2 to treatment 1, we can nd the optimal allocation ratio to minimize the total cost. Variances may be different. Suppose the means, m1andm2, of treatment groups are being compared using Z=(\u00afX1\u0000\u00afX2)\u0000(m1\u0000m2)q s2 1=n1+s2 2=n2: For a given N=n1+n2, the test statistic is maximized when the denominator is minimized. Solving \u00b6 \u00b6n1\u0012s2 2 Therefore, the optimal allocation ratio is r=n1=n2=s1=s2. Analysis should account for the randomization scheme but often does not. Matts and McHugh (1978 J Chronic Dis ) point out that because blocking guarantees balance between groups and increases the power of a study, blocked randomization with the appropriate analysis is more powerful than not blocking at all or blocking and ignoring it in the analysis. not accounting for blocking in analysis is conservative. 3.4.2 Biased coin and urn model These techniques are sometimes classied as \"adaptive randomization\". Allocation of i-th patient depends on how many have been randomized to group A ( na) and group B (nb). Clinical Trials 23 Tatsuki Koyama, PhDAny given time, the probability of allocation to group A may be P[A] =nb na+nb: Or the rule may =2=3when nb\u0000na>5, and P[B] =2=3when na\u0000nb>5. Characteristics of such a randomization scheme are usually studied by simulations. An urn model is one type of biased coin randomization. Prepare an urn with one Amber ball and one Blue ball. Pick one ball and make the corresponding treatment assignment (A/B). Put a ball of the opposite color in the urn. urn1 <- function(n){ # randomize n patients into A or B. # At any time P[A] = (#B so far + 1) / (#A so far + 1 + #B so far + 1). out ','Next ') out[1:n,] } urn1(n=10) A so far B so far P[A next] Next 1 0 0 0.500 A 2 1 0 0.333 A 3 2 0 0.250 B 4 2 1 0.400 B 5 2 2 0.500 A 6 3 2 0.429 A 7 4 2 0.375 B Clinical Trials 24 Tatsuki Koyama, PhD8 4 3 0.444 B 9 4 4 0.500 B 10 4 5 0.545 A 3.5 Imbalance in baseline patient characteristics Block randomization and biased coin model ensure that the group sizes are reasonably balanced. In order to facilitate the comparison of treatment effects, balance on important baseline variables is sometimes desired. Randomization does not guarantee all the measured variables will be balanced. And imbalance does not mean randomization did not work. Senn (1994) It is argued that this practice [testing baseline homogeneity] is philosophically unsound, of no practical value and potentially misleading. Instead it is recommended that prognostic variables be identied in the trial plan and tted in an analysis of covariance regardless of their baseline distribution (statistical signicance). Piantadosi These methods, while theoretically unnecessary, encourage covariate balance in the treatment groups, which tends to enhance the credibility of trial results. An annonymous reviewer Since this is a randomized controlled trial, comparison of baseline char- acteristics (Table 1) is not necessary. The problem with this approach is that when comparing baseline characteristics we already know that the null hypothesis is true if the randomization was done correctly. Thus, we would expect 1 test in 20 to give a 'signicant' result with p<0:05 by chance alone. The best approach is to specify key prognostic factors to include in multivari- able models irrespective of their signicance between treatment groups. 3.5.1 Stratied randomization Stratied randomization is applied to ensure that the groups are balanced on baseline variables that are thought to be signicant. Create strata based on the variables for which balance is sought. e.g., (Male, 65 or younger), (Male, older), (Female, younger), (Female older) Randomize to treatments within each stratum. Use block randomization! What's wrong with -using simple randomization within a stratum? Trials 25 Tatsuki Koyama, PhD-using too many strata? Stratication should in analysis. -Pre-randomization stratication and post-randomization stratication (at time of analysis) has no clear winner. If trial is large, stratication may not be necessary Stratication by center is a good idea from practical viewpoints. -Allows randomization to be hosted at each site -Allows sites to be removed and still maintains balance Block randomization is a special type of stratied randomization where strata are dened by ... . If each stratum has a target size, plans need to be in place to close down recruitment based on the baseline characteristics. e.g., \"We do not need any more (Male, older)\". 3.5.2 Adaptive and minimization randomization Adaptive randomization can be used to reduce baseline imbalance: Dene an imbalance function based on factors thought to be important Then use a rule to dene P[treatment A] so that the next assignment is more likely to reduce imbalance. For example, the factors to balance are sex (male/female) and hypertension (yes/no), and let the imbalance function be I=2\u0002(sex imbalance )+3\u0002(hypertension imbalance ): The patients randomized so far are Sex Hypertension Male Female Y es No Group 1 10 3 8 5 Group 2 8 3 6 5 Clinical Trials 26 Tatsuki Koyama, PhDThe next patient is male-non hypertensive. be I=2\u0002(11\u00008)+3\u0002(6\u00005) =9if Group Group 2. Thus let P[Group 2] =2=3. Minimization randomization uses the same idea but use P[Group 2] = 1, to eliminate randomness when there is some imbalance. Randomize only when to assign the next patient to either group gives the same value of I. 3.6 Response adaptive randomization As the name suggests, response adaptive randomization methods use the information about the response so far to allocate the next patient. Play the winner : The idea is to allocate more patients in the treatment that seems to be working better. To apply these methods, it is necessary to have a response quickly. Urn model can be used to make treatment assignment imbalance based on the results (success/failure) of each treatment so far. (e.g., put one blue ball if the treatment B yields success.) Instead of updating the probabilities of treatment assignment after each patient, we can update them after a group of patients' results are available to reduce administrative burden. In a phase II clinical trial, play the winner design may be used to reduce the number of treatments in consideration. (e.g., Only retain the treatment arms that have P[positive response] >0:4.) 3.6.1 Example: ECMO Bartlett the use of extracorporeal membrane oxygenation (ECMO) to treat newborns with respiratory failure. A play-the-winner design3was used because the outcome is known soon after randomization. most ECMO patients were expected to survive and most control patients were expected to die. -Ethically, the investigators felt obligated not to withhold the lifesaving treatment. -Scientically, they felt obligated to perform a randomized study. The randomization plan: The rst patient will be randomized to ECMO or the conventional treatment (CT) with equal probability. 2\"Extracorporeal circulation in neonatal respiratory failure: a prospective randomized study\". (1985) Pediatrics 3Zelen (1969) JASA ; Wei and Durham (1978) JASA Clinical Trials 27 Tatsuki Koyama, PhD For each patient who survives on ECMO or dies on CT, one ECMO ball is added to the urn. For each patient who survives on CT or dies on ECMO, one CT ball is added to the urn. The trial will be terminated when 10 balls of one kind have been added, and that treatment will be chosen as the winner. What actually happened: P(ECMO)=1/2 Patient 1 was randomized to ECMO and survived. P(ECMO)=2/3 Patient 2 was randomized to CT and died. P(ECMO)=3/4 Patient 3 was randomized to ECMO and survived P(ECMO)=4/5 Patient 4 was randomized to ECMO and survived P(ECMO)=5/6 Patient 5 was randomized to ECMO and survived P(ECMO)=6/7 Patient 6 was randomized to ECMO and survived P(ECMO)=7/8 Patient 7 was randomized to ECMO and survived P(ECMO)=8/9 Patient 8 was randomized to ECMO and survived P(ECMO)=9/10 Patient 9 was randomized to ECMO and survived P(ECMO)=10/11 Patient 10 was randomized to ECMO and survived Randomization was stopped when there were 11ECMO patients who survived and 1CT patient who died. Controversies followed because ... fisher.test( cbind(c(11,0),c(0,1)) ) Fisher 's Exact Test for cbind(c(11, 0), c(0, 1)) p-value = 0.08 alternative hypothesis: true odds ratio is not equal to 1 95 percent confidence interval: 0.282 Inf sample estimates: odds ratio Inf Clinical Trials 28 Tatsuki Koyama, PhD\"In retrospect it would have been better to begin with two or three pairs of balls, which probably would have resulted in more than one control patient.\" 3.7 Nonbipartite matching in clinical trials Reference: Lu B, Greevy R, Xu X, Beck C. \"Optimal nonbipartite matching and its statistical applications\". 2011. 65(1):21-30. R package \"nbpMatching\" http://biostat.mc.vanderbilt.edu/wiki/Main/MatchedRandomization When baseline data on all the subjects are available, the subjects can be matched, and treatments are randomly assigned within each pair. Matching is done to minimize some form of multidimensional (multivariate) distance, e.g., Mahalanobis distance. 3.7.1 Example The human papillomavirus (HPV) vaccine will prevent a high proportion of vaginal, oropharyngeal, vulvar, and penile cancers. Y et the proportion of 11- and 12-year old girls who receive this vaccine is not very high. The investigators would like to test effectiveness of the tailored coaching intervention to educate the health-care providers. For this study, 18community-based, private pediatric practices have been recruited. Clinical Trials 1 ProvidersGroup ProvidersProviders 01020304050600102030405060 Group 1 % BlackGroup 2 % Black% Black By Baseline HPV % and Number of Providers Clinical Trials 31 1 ProvidersGroup 01020304050600102030405060 Group 1 % 2 % Black% BlackBy Baseline HPV % and Number of Providers and % Black Group1 Group2 1 17.2 2 41.0 33.0 1 ProvidersGroup ProvidersProviders 01020304050600102030405060 Group 1 % BlackGroup 2 % Black% Black Clinical Trials 34 Tatsuki Koyama, PhDChapter 4 Superiority, Non-inferiority, and equivalence 4.1 Superiority and non-inferiority In a phase 3 clinical trial, the objective is often to show the new treatment is better than the con- ventional treatment. This is called a superiority clinical trial, in which the following hypotheses are tested: HS0:d=0 HS1:d>0 where dis the difference of the treatment effects. Here we assume larger values of dindicate a favorable result. We generally do not conduct a two-sided hypothesis test in a clinical trial. Type I error rate is usually set at 2:5%, and power is usually set at 80% or90% at some clinically meaningful value, dS. When there is a conventional treatment that is known to be effective, it may be of interest to show non-inferiority of the new treatment to the control. HN0:d=\u0000dI HN1:d>\u0000dI Here, dIis a pre-specied positive number, which is referred to as the non-inferiority margin. It is customary to set the power of non-inferiority test at 0. Mathematically, superiority testing and non- inferiority testing are very similar; one is a location shift of the other. After observing the data, d, it is always possible to compute dIsuch that H0for the non-inferiority test is rejected. Therefore, it is necessary to dene the non-inferiority margin a priori. A non-inferiority trial usually requires a bigger sample size than a superiority trial does. That is, dI<dS.dIneeds to be small enough to be clinically indifferent, and dSneeds to be large enough to be clinically meaningful. Clinical Trials 35 Tatsuki Koyama, PhDBecause when the data from the control and treatment groups are similar, it biases towards no difference, the intention-to-treat analysis biases towards positive results in a non-inferiority trial. This can be seen in the following small simulation study. sig <- 4 del <- 1 pSwitch is the proportion of patients switching the group # (T -> C and C -> T are is the true difference (>0). # Under null, del=-niMargin; under alternative, del=0. # pSwitch is the proportion of patients switching the group # (T -> C and C -> T are a superiority trial, subjects' switching treatment groups does not cause type I error inflation even though power reduces. In a non-inferiority trial, when 20% of the subjects switch groups, type I error rate was inflated to about 25%; however, the power is remained at 90% because, the centers of distributions coincide under the alternative. There is no multiplicity penalty for testing superiority and non-inferiority in the same clinical trial. It is because these hypotheses are nested in the sense that if HS0is rejected, HN0is always rejected, and ifHN0is not rejected, HS0is not rejected. We can test for both sets of hypotheses with one condence interval. 4.2 Equivalence In the statistical hypothesis testing paradigm, no conclusion can be reached by failing to reject H0, and equivalence can not be concluded by failing to reject a superiority null hypothesis. In an equiva- lence trial, the following hypotheses are tested: HE0:jdj\u0014de HE1:jdj>de In the clinical trial literature, non-inferiority trials are often referred to as equivalence trials. There are seldom any therapeutic equivalence trial; most of the equivalence trials are early phase bioe- quivalence trials in the pharmacokinetics/pharmacodinamics arena. In bioequivalence trials, several pharmacokinetic (PK) parameters, such as, Cmax,Cmin, and AUC for a generic drug are compared to those for the marketed drug. Clinical Trials 38 Tatsuki Koyama, PhDAn example of clinical equivalence trial Pri et. al \"Leukotriene antagonists as rst-line or add-on asthma-controller therapy\". New Eng- land Journal of Medicine (2011). In this pragmatic clinical trial, the investigators aimed to show leukotrine-receptor antagonist (LTRA) is equivalent to either an inhaled glucocorticoid rst-line asthma-controller therapy or a long-acting beta agonist (LABA) as add-on therapy in patients already receiving inhaled glucocorticoid therapy. This is a pragmatic trial, as well. As with non-inferiority trials, the intention-to-treat analysis biases towards equivalence, making it challenging to handle dropouts and non-compliances (switching treatment arms). Clinical Trials 39 Tatsuki Koyama, PhDChapter 5 Phase II Oncology Clinical Trials 5.1 Introduction Phase II clinical trial A clinical trial designed to test the feasibility of, and level of activity of, a new agent or procedure. (safety and activity) Some typical characteristics of a typical phase II clinical trial include: It includes a placebo and two to four doses of the test drug. When the response is observed quickly, adaptive designs may be benecial and used because they may -improve quality of estimation of the MED (minimum effective dose (lowest dose of a drug that produces the desired clinical effect). -increase number of patients allocated to MED. -allow for early stopping for futility. The primary objectives of phase II trials are: To determine whether the drug is worthy of further study in phase III trial. Signicant treatment effect? / dose-response relationship? To gather information to help design phase III trial. -Determine dose(s) to carry forward -Determine the primary and secondary endpoints -Estimate treatment effects for power/sample size analysis -Estimate recruitment rate Clinical Trials 40 Tatsuki Koyama, PhD-Examine feasibility of treatment (logistics of administration and cost) -Learn about side effects and toxicity In phase II clinical trials, parallel group designs, crossover designs, and factorial designs are often used. 5.2 Phase II trials in oncology A phase II clinical trial in oncology generally uses a xed dose chosen in a phase I trial. The primary objective is to assess therapeutic response to treatment. In the simplest case, a single treatment arm is compared to a historical control. In other cases, a control group and/or multiple doses are included. The treatment efcacy is often evaluated on surrogate markers for a timely (quick) evaluation of efcacy. Surrogate outcome An outcome measurement in a clinical trial that substitutes for a denitive clin- ical outcome or disease status. CD4 counts in AIDS study. PSA (prostatic specic antigen) in prostate cancer study. Blood pressure in cardiovascular disease. 3 months survival (binary) for survival. Tumor shrinkage for survival. Tumor response to treatment is evaluated according to Response Evaluation Criteria in Solid Tumors (RECIST) Complete response (CR) Disappearance of all target lesions. Partial response (PR) At least a 30% decrease in the sum of the longest diameter (LD) of target lesions, taking as reference the baseline sum LD. Stable disease (SD) Neither sufcient shrinkage to qualify for PR nor sufcient increase to qualify for PD, taking as reference the smallest sum LD since the treatment started. Progressive disease (PD) At least a 20% increase in the sum of the LD of target lesions, taking as reference the smallest sum LD recorded since the treatment started or the appearance of one or more new lesions. Generally, objective tumor response is dened as CR or PR in RECIST so that the response variable has a binary endpoint. In the rest of chapter, we will consider a single arm trial with a binary response. The hypothesis of interest is one-sided H1:p>p0, and the type I error rate is usually 5to10%. The power is usually 80to90%. Clinical Trials 41 Tatsuki Koyama, PhD5.3 Classical (old) two-stage designs It is crucial that these phase II studies have an opportunity to stop early for toxicity, and that is ac- complished by Data Monitoring Committee (DMC), aka, Data and Safety Monitoring Board (DSMB). It is also desired to discard ineffective treatment early, and two-stage designs with a futility stop has been popular. We will discuss the designs proposed by Gehan (1961), Fleming (1982), and Simon (1989), using the following unied notation: stage I sample size \u0001\u0001\u0001n1. stage I data\u0001\u0001\u0001X1\u0018Binomial (n1;p). stage I critical value \u0001\u0001\u0001r1so that if X1\u0014r1then terminate the study for futility. stage II sample size \u0001\u0001\u0001n2. stage II data\u0001\u0001\u0001X2\u0018Binomial (n2;p). total sample size \u0001\u0001\u0001nt=n1+n2. total data\u0001\u0001\u0001Xt\u0011X1+X2. stage II critical value \u0001\u0001\u0001rtso that if Xt\u0014rtthen terminate the study for futility, otherwise conclude efcacy. 5.3.1 Gehan's design It is old (1961) and outdated but may be ok to use in limited situations. The design calls for the rst stage with n1=14andr1=0, i.e., if no positive response is observed in 14, then stop for futility. The rational is that if true response rate is at least 20%, then X1=0is unlikely. In fact, it is 0:044. The second stage sample size depends on the desired precision for estimating p, and it ranges between 1and 86. A typical n2is14so that nt=28. 5.3.2 Fleming's design Fleming (1982) proposed a multistage design for phase II clinical trials. One of its key characteristics is stopping early for efcacy. Example H0:p=0:15,H1:p=0:30. (powered at 0:30) a=:05,b=:2 (Reject H0in Tatsuki Koyama, PhDn1r1s1ntrt a 1\u0000b 0 :8013 36:6 36 :9 5.4 Simon's design In his 1989 paper, Simon introduced two criteria to choose a 2 stage design for single arm and one sided test. The optimal design has the smallest expected sample size under H0(n1+Ep0[n2]), and the minimax design has the smallest total p0=0:15and 0 :68 50:2 0 11 0:046 0 :804 34:5 0 :54 46:7 0 11 0:048 0 :819 48:0 0 :00 48:0 0 :00 5.4.1 Conditional power To nd a good design (sample sizes and critical values), we need to understand the conditional power of a design. The conditional power is the probability of rejecting H0(in stage 2) given the stage 1 result, i.e., conditioned on X1=x1. Clearly, when X1>rt, conditional power is 1, and when X1\u0014r1(futility stop), conditional power is 0. a function of p,x1andn2as well as rt To obtain the unconditional power, we need to integrate (sum) the conditional power over all Clinical Trials 43 Tatsuki Koyama, PhDUnlike in a single-stage situation, there may be more than one good design. Simon used the optimal andminimax to choose two reasonable designs among many satisfying the type I error rate and power constraints. Expected sample size under the null can be written as Ep0[nt] =n1+n2P[continue ] > rt <- 10 150.00.20.40.60.81.0 x1conditional powerGiven a design, computing operational characteristics such as type I error rate, power, expected sample size is not difcult; however, solving for the optimal, minimax, and other preferable designs is not trivial. Simon's original papers show how to do this. A very good webpage by Anastasia Ivanova at UNC is at http://cancer.unc.edu/biostatistics/ program/ivanova/SimonsTwoStageDesign.aspx . Clinical Trials 46 Tatsuki Koyama, PhD5.4.3 Something in between The two criteria, optimal and minimax, give two designs that are extreme, and neither may t the investigators' needs. For example, for testing H0:p=0:3witha=0:05andb=0:10atp1=0:45, the minimax designs 60:8 0 :70 balanced 53 0:043 0 :903 64:4 0 :78 minimax :901 78:5 0 :86 The optimal design tends to have a small n1and the minimax design tends to have a large n1. Therefore, a simple approach to nd a good alternative design is to force n1=n2. (balanced design of Y e and Shyr, simple=TRUE) [[1]] n1 r1 A more systematic approach is to express the criteria for optimization as q(w) =w\u0002(nt)+(1\u0000w)\u0002E0[N]; where 0\u0014w\u00141.q(0)and q(1)correspond to the optimal and minimax designs, respectively. Com- putation shows that the minimax design is the best design with respect to q(w)forw2(0:827;1]. In between the optimal and minimax designs, the following \"admissible\" designs exist that optimize q(w) for certain ranges of w. (Jung, Lee, Kim, George, 2004) Clinical Trials 47 Tatsuki Koyama, PhDn1 r1 ntrt a 0 :901 60:8 0 :70 (0;0:006) admissible 1 104 38 0:050 0 :903 60:8 0 :70(0:006;0:136) admissible 2 48 16 101 37 0:050 0 :901 61:3 0 :75(0:136;0:182) admissible 3 40 12 94 35 0:048 0 :902 62:8 0 :58(0:182;0:303) admissible 4 46 34 0:049 0 :902 64:1 0 :60(0:304;0:827) minimax 0:045 0 :900 90:0 0 :00 5.5 Data analysis following a two-stage design in phase II clini- cal trials The primary objective of a (cancer) phase II clinical trial is to make a correct \"go/no-go\" decision; however, making a good inference for pis advantageous for planning the following phase III trial. We have seen before that when we terminate a study based on an interim summary of the data, a usual statistic that we often compute may be biased. In this section, we will look at the issue of bias in two-stage design in phase II clinical trial in detail. Simon's design will be our focus, but many general discussions can be applied to other designs as well. 5.5.1 p-value If we ignore the fact that the data were gathered in a two-stage design and compute a p-value as if X\u0018Binomial (nt;p), it is bigger than the true p-value with the following denition/interpretation. p-value the probability under the null hypothesis that we would observe the data as or more extreme than what we have observed The term \"as or more extreme\" can be interpreted as \"as big or bigger evidence against H0\". In a simple single-stage design, the meaning of this is usually straightforward. We can all agree that Z=2:0is more extreme (more evidence against H0) than Z=1:9. However, in two-stage designs, understanding the denition of p-value sometimes gets tricky. Example: H0:p=0:3,H1:p>0:3;a=0:05and the suppose we observe X1=7in stage 1 so that we move on to the second stage. And in stage 2, we observe additional 12positive responses in n2=31patients ( 19in46total) so that H0is rejected because Xt=19>rt. If we compute a p-value without taking into account the study design, we might use X\u0018Binomial (46;0:3) aas shown below: 1-pbinom(18,46,0.3) [1] 0.0681 To see this inconsistency clearly, we will rewrite above as pc=P0[X\u001519] =15 \u00e5 x1=0P0[X2\u001519\u0000x1jX1=x1]P0[X1=x1]: From this expression we see that in computing pc, we include sample paths that can not be realized with this Simon's design, namely, X1=0,X2\u001519;X1=1,X2\u001518;\u0001\u0001\u0001;X2=5,X2\u001514. Aproper p-value that takes into account the actual sampling scheme used may be pp=15 \u00e5 x1=6P0[X2\u001519\u0000x1jX1=x1]P0[X1=x1]: In general, for Trials 49 Tatsuki Koyama, PhDifx1>r1(i.e., if there is a second stage). The following simple R script that the trial is terminated in stage 1, we can dene pp=P0[X1\u0015x1]: Thus we think that \"moving on to the second stage\" has more evidence against H0than \"terminating in the rst stage for futility\", which makes sense. Theproper p-value ( pp) has the following characteristics: It is always smaller than or equal to pc. It is consistent with the hypothesis testing, i.e., pp\u0014aif and only if H0is rejected. IfXt=rt+1, then ppis equal to the level of the test (so-called the actual type I error rate). It does not distinguish different sample paths that lead to the same Xt. That is, evidence against H0is identical if xtis the same regardless of x1. For example, X1=8,X2=12andX1=10,X2=10yield the same p-values. When does this ( pp) break down? It breaks down when we allow n2to be different for various values of X1. In some modications of Simon's design (e.g., Banerjee A, Tsiatis AA. Stat Med 2006), the stage 2 sample size varies with x1. Then, ppcan not be computed because we cannot order the sample paths simply based on Xt. A bigger concern is that this ppcannot be used when n2is changed from that planned. An even bigger concern is if the actual n2is different from that planned, how can we re-compute the critical value, rt, to control type I error rate? The answer is not simple! Clinical Trials 50 Tatsuki Koyama, PhD5.5.2 Point estimate Because the results from a phase II clinical trial are often used in planning a phase III clinical trial, a good estimate of pis often of interest. MLE In a single stage design, the MLE of pisp=x=n. For a Simon's design, we can write the likelihood, letting Yidenote the individual datum from pis p(x) =( x1=n1ifx1\u0014r1 xt=ntifx1>r1 We have seen before that this p(x)has a downward bias, i.e., Ep[p(x)]\u0014p. A simple explanation is that when pis small at the end of stage 1, we tend to terminate the study, and this downward bias tends to remain; however when pis large at the end of stage 1, more data are gathered and the upward bias of stage 1 tends to be corrected. Example :p0=0:3,p1=0:5,a=0:05,b=0:2. Then the minimax design is X1=8andX2=12so that Xt=20. p=20 39=0:513: Whitehead We can write the bias of the MLE estimator as: B(p) =Ep[p(x)]\u0000p: So a good Trials 51 Tatsuki Koyama, PhDHowever, B(p)is unknown, so we need to estimate it. Let's use the current estimate of pinB(p). That is pw=p\u0000B(pw): This is Whitehead's estimator (1986 Biometrika). We can write pw; which leads to Epw[p(x)] = p: To nd pw, we need pw=0:520. Koyama We can write the bias of the MLE estimator as: B(p) =Ep[p(x)]\u0000p: So a good estimator would be p=p\u0000B(p): However, B(p)is unknown, so let's use B(p), that is pk=p\u0000B(p): This is simpler and more straightforward than Whitehead's estimator. We can write pk=p\u0000Ep[p(x)]+ p 52 Tatsuki 2 p. In the current example, pk=0:521. Unbiased estimator For a general multistage design with early stopping for futility and efcacy, Jung and Kim (2004 Stat Med) found the unbiased estimator of p. They showed that the pair ( M,S), where Mis the number of stage (when terminated) and Sthe number of successes, is complete and sufcient for p. And clearly x1=n1is unbiased for p, the uniformly minimum variance unbiased estimator (UMVUE) is found through Rao-Blackwell theorem. The for pubis complex, but for Simon's two-stage design (two-stage with only futility stop), it 0such that the p-value for testing H0:p=p\u0003 0is0:5by the realized sample path. Many adaptive designs for phase II clinical trials were originally motivated as a hypothesis testing procedure, and computing this estimator should be fairly simple in many designs. If the test statistic is continuous, this estimator is known as the median unbiased estimator (Cox and Hinkley 1974). It is unbiased for the true median. The proof uses the fact that the p-value is distributed Uni f(0;1)under H0. Clinical these methods, we compute the bias of each estimator for various true values of p. Use bias and mean squared error = var + bias2to compare them. For each estimator, compute p(X)for every sample (dened by Xin[0;nt]) and compute Ep[p(X)] =nt \u00e5 x=0p(x)Pp[X=x]: p[p(X)] =Ep[(p(X)\u0000p)2] =nt \u00e5 x=0(p(x)\u0000p)2Pp[X=x]: The following two plots show bias and MSE for the current example. Clinical Trials 54 Tatsuki Koyama, PhD0.2 0.3 0.4 0.5 0.60.030.020.010.000.01 true pbias MLE Whitehead Unbiased Koyama Median 0.2 0.3 0.4 0.5 0.60.0060.0070.0080.0090.0100.011 true pMSE MLE Whitehead Unbiased Koyama MedianClinical Trials Koyama, 6 Factorial design 6.1 Introduction Factorial clinical trials (Piantadosi) Experiments that test the effect of more than one treatment using a design that permits an assessment of interactions among the treatments The simplest example of a factorial design is 2 treatment, 2 treatment groups (2 by 2) designs. With this design, one group receives both treatment, a second group receives neither, and the other two groups receive one of A or B. Treatment B Treatment A No Y es Total No n n 2n Y es n n 2n Total 2n 2n 4n Four treatment groups and sample sizes in a 2\u00022balanced factorial design. Alternatives to a 2\u00022factorial design Two separate trials (for A and for B) Three arm trial (A, B, neither) Two major advantages of factorial design (but not simultaneously): Allows investigation of interactions (drug synergy). Drug synergy occurs when drugs interact in ways that enhance effects or side-effects of those drugs. Reduces the cost (sample size) if the drugs do not interact. Clinical Trials 56 Tatsuki Koyama, PhDSome requirements for conducting a clinical trial with factorial design: The side effects of two drugs are not cumulative to make the combination unsafe to administer. The treatments need to be administered in combination without changing dosage of the indi- vidual drugs. It is ethical not to administer the individual drugs. A and B may be given in addition to a standard drug so all groups receive some treatment. We need to be genuinely interested in studying drug combination , otherwise some treatment combinations are unnecessary. Some terminology Factors (how many different treatments are in consideration) Levels (2 if yes/no) 2kfactorial studies have kfactors, each with two levels (presence/absence) Full factorial design has no empty cells. Unreplicated study has one sample per cell (obviously not very common in clinical studies) Fractional factorial designs (some cells are left empty by design) Complete block designs / Incomplete block designs Latin squares 6.2 Notation and assumptions Treatment B Treatment A No Y es No m m +b Y es m+a m +a+b+g With this formulation, ais the effect of treatment A, bis the effect of treatment B, and gis the interaction effect. (If the effects of A and B are additive with no interaction, then g=0.) Clinical Trials 57 Tatsuki Koyama, PhDFor a continuous outcome and large sample sizes (may be different for each group), we have the following for the observed sample cell means. Y0\u0018Normal Test for the interaction effect In a factorial design, we usually test the presence of interaction effect rst. H0:g=0 H1:g6=0 The observed mean responses are: Treatment B Treatment A No Y es No Y0YB Y es YAYAB The interaction effect may be estimated by g= (\u00afYAB\u0000\u00afYB)\u0000(\u00afYA\u0000\u00afY0); and Var(g) =4s2 n: (Why is this known, then Z=g have to estimate s2and assume within-group variances are equal, we f=4(n\u00001)under H0. 6.4 Treatemnt effect 6.4.1 g6=0 The treatment A effect can be estimated as a=\u00afYA\u0000\u00afY0; and its variance is Var(a) d f=2(n\u00001)under H0. Constructing the test for bis exactly the same. Clinical Trials 59 Tatsuki Koyama, PhD6.4.2 g=0 If no interaction is present then g=0, and a=\u00afYAB\u0000\u00afYBcan also be used to estimate a. If we use the average of aand ato estimate a, this estimator has the test for bis exactly the same. In order to have the same efciency in a two-arm trial (A vs placebo), we would need 2npatients in each treatment arm. var(a1) =2s2 2n=s2 n: So if we were to test A and B in two separate experiments we would need 2nper arm\u00024 arms (A and placebo, B and placebo), totaling 8nsubjects. Noticing we are repeating the placebo in these hypothetical experiments, we decide to use a 3-arm experiment with A, B, and placebo arms. Then we would require a total of 6nsubjects for the same precision. 6.5 Examples The group means are: Clinical Trials 60 Tatsuki Koyama, PhDTreatment B Treatment A No Y es No 10 40 Y es 30 60 If there is a synergistic effect, then h11>60. Treatment B Treatment A No Y es No 10 40 Y es 30 80 Treatment B Treatment A No Y es No 10 40 Y es 30 120 In the last situation, the treatment effects may be multiplicative. Treatment B Treatment A No Y es No log(10) =1 log (40) =1:60 Y es log(30) =1:48 log (120) =2:08 Suppose the samples of size 20yield the following estimates of the cell means. Treatment B Treatment A No Y es No 9:83 40 :05 Y es 28:94 59 :76 Assuming no interaction, to estimate the drug A effect we compute either a1=\u00afYA\u0000\u00afY0=28:94\u00009:83=19:11 or a1=\u00afYAB\u0000\u00afYB=59:76\u000040:05=19:71 or their average (19:11+19:71)=2=19:41. Clinical Trials 61 Tatsuki Koyama, PhDHow bad is it to estimate a1this way I (1989) Read all about it on http://phs.bwh.harvard.edu/ . The Physician's Health Study was a randomized clinical trial designed to test the following two theo- ries: Daily low-dose aspirin use reduces the risk of cardiovascular disease. Beta carotene reduces the risk of cancer. Population hierarchy: 261,248 US male MDs aged 40 to 84. 112,528 responded to questionnaires. 59,285 willing to participate. 33,332 willing and eligible MDs enrolled in run-in (18 weeks of active aspirin and beta-carotene placebo). Run-in period Eligible patients are monitored for treatment compliance. 22;071randomized Beta-carotene Aspirin Active Placebo Total Active 5;517 The trial's DSMB stopped the aspirin arm several years ahead of schedule on 1988/1/25 be- cause it was clear that aspirin had a signicant effect on the risk of a rst myocardial infarction. (It reduced the risk by 44%.) Clinical Trials 62 Tatsuki Koyama, PhD-Did it change the sample sizes for the Beta-carotene components? (Next homework?) There were too few strokes or deaths to base sound clinical judgement regarding aspirin and stroke or mortality. The beta-carotene arm terminated as scheduled on 1995/12/12 with the conclusion that 13 years of supplementation with beta-carotene produced neither benet nor harm. Beta-carotene alone was not responsible for the health benet seen among people who ate plenty of fruits and vegetables. Over 300 other ndings have emerged from the trial so far. 6.6 Treatment interactions Factorial designs are the only way to study treatment interactions. Recall the interaction term is estimated by g= (\u00afYAB\u0000\u00afYB)\u0000(\u00afYA\u0000\u00afY0), and its variance is Var(g) =4s2=n. This variance is 2times as large as that of AandBmain effects, and to have the same precision for an estimate of an interaction effect, the sample size has to be 4 times as large. This means, the two main advantages of the factorial designs (efciency and interaction objectives) cannot be satised simultaneously. When there is an ABinteraction, we cannot use the estimators, aand b, which are only valid with no interaction effect. In fact, we cannot talk about an overall main effect in the presence of an interaction. Instead, we can talk about the effect of Ain the absence of B, a=\u00afYA\u0000\u00afY0; or the effect of Ain the presence of B a0=a+g=\u00afYAB\u0000\u00afYB: Some additional notes In the 2\u00022\u00022design ( 23design), there are 3 main effects and 4 interactions possible. The number of high order interactions will grow quickly with k, but oftentimes, they are (assumed to be)0. A \"quantitative\" interaction does not affect the direction of the treatment effect. For example when treatment B is effective either with or without treatment A, but the magnitude of its effec- tiveness changes. With a \"qualitative\" interaction, the effects of A are reversed with the presence of B. In this case, an overall treatment A effect does not make sense. Clinical Trials 63 Tatsuki Koyama, PhD The factorial design can be analyzed with linear models (analysis of variance models). Limitations of factorial designs A higher level design can get complex quickly. Test for interaction requires a large sample size (or have a very low power if the study is pow- ered for the main effects). Combination therapy may be considered as a treatment in its own right. Of further interest... Partial (fractional) factorial designs have missing cells by design (especially when higher order interactions are assumed to be zero) Clinical Trials 64 Tatsuki Koyama, PhDChapter 7 Crossover design Crossover trials are those in which each patient is given more than one treatment, each at different times in the study, with the intent of estimating differences between them. In a simple 2\u00022design (or AB/BA design), patients are randomized to either \"A then B\" group or \"B then A\" group. Period Group I II AB Treatment A Treatment B BA Treatment B Treatment A2 Treatments / 2 Periods / 2 Sequences P1P2 S1A B n1 S2B A n2 4 2 Sequences P1P2P3P4 S1A B A B n1 S2B n2 Clinical Trials 65 Tatsuki Koyama, PhD7.1 Some characteristics of crossover design All subjects receive more than one treatment (not simultaneously). Each subject acts as own control. Therefore, the treatment groups are comparable without relying on randomization. -Treatment periods (order of AandB) are often randomly assigned. -Baseline characteristics are identical with regard to many patient characteristics, but not with regard to their recent history of exposure to other potentially effective treatments. carryover effects -The comparability of the treatment groups is not guaranteed by the structure of the trial alone. The investigators need to estimate the carryover effects. Crossover designs are not used ... -with any condition that treatment could effect considerable change. -for acute illness. Crossover designs are most suitable for treatments intended for rapid relief of symptoms in chronic diseases, where the long-term condition of the patient remains fairly stable. Precision The primary strength of crossover trials is increased efciency. Suppose the treatment effects are Yt\u0018Normal (mt;s2); Yc\u0018Normal (mc;s2); and we are interested in mt\u0000mc. In a parallel design (with per group sample size of n), we have D=Yt\u0000Yc\u0018Normal\u0012 mt\u0000mc;2s2 n\u0013 : With a TC=CTcrossover design var(D) =2s2 n\u00002cov(Yt;Yc) =2s2 n(1\u0000rtc); where rtcis the responses on treatments TandC. Therefore, a crossover design is more efcient than a parallel design given rtc>0. Clinical Trials 66 Tatsuki Koyama, PhDRecruitment Some patients may hesitate to participate in a clinical trial if there is a 50%probability of not receiving any effective treatment. With a crossover design, everyone is guaranteed to receive the test drug. On the other hand, the patients may hesitate to participate in a crossover trial because they will go through more than one treatment, especially when outcomes are assessed with diagnostic proce- dures such as X-ray, blood drawing, lengthy questionnaires. Carryover effects The biggest concern is the possibility that the treatment effect from one period might continue to be present during the following period. A sufciently long \"washout\" period between the treatments may prevent signicant carryover effects (but how long is sufciently long?). If there are baseline measurements that represent patient's disease status, this can be checked against their baseline levels. If the treatment effects a permanent change or cure in the underlying condition, the treatment given after could look articially superior. Dropouts In a crossover design, the trial duration tends to be longer than a comparable study using inde- pendent groups, which may cause more dropouts. Also because every patient take more than one treatment, dropouts due to severe side effects may also increase. The consequences of dropouts are more severe in crossover trial; a simple analysis cannot use only the data from the rst period. 7.2 Analysis of 2\u00022crossover B. b2\u0001\u0001\u0001Carryover effect of treatment A b3\u0001\u0001\u0001Increment carryover effect of treatment B Treatment Beffect is b0+b1, and the carryover effect due to treatment Bisb2+b3. The primary hypotheses to test are: H0:b1=0 H1:b16=0 And how to conduct this test (how to estimate b1) depends on whether b3=0. (We'll see why later.) Step 0 : Assumptions Clinical Trials 67 Tatsuki Koyama, Note that under H0:b3=0, we have mA1+mB2=mB1+mA2. Thus, we can use Z1=(YB1+YA2)\u0000(YA1+YB2)p Var(YB1+YA2)+Var(YA1+YB2) to test these hypotheses (assuming s2is known). Why is this good (convenient)? Because we don't have to worry about the correlations when com- puting Z1. Instead, we can compute the within-subject difference sum. Let's say wi1=yA1i+yB2iand wj2=yB1j+yA2j. Then we have Z1=w2\u0000w1p Var(w2)+Var(w1) If we don't assume s2is known, we can Clinical Trials 68 Tatsuki Koyama, PhDStep 2a (If b3=0) can if H0:b1=0. Let's say di1=yB2i\u0000yA1ianddj2=yA2j\u0000yB1j. Let's conrm that the following test statistic can be used to test this hypothesis. t2=d1\u0000d2p 2sd=pn; where s2 d= (s2 d1+s2 d2)=2. What's the degree of freedom? We are interested in estimating b1. Note that b1= (d1\u0000d2)=2. So that s2 d=(2n) But we are not that interested in estimating b2. Step 2c (If b3=0) Maybe we want to estimate b0. We have two estimates of b0, and we can take the average of them b0=1 2\u0000 can test to see if b0=0by testing H0:mB1+mA2=mB2\u0000mA1 H1:mB1+mA26=mB2\u0000mA1 Constructing the relevant ttest statistic is not as straightforward as the previous steps because we cannot assume the true variances of w2andd1are equal. We can use t=w2\u0000d1r s2w2 n+s2 d1 n; which follows a tdistribution approximately with estimated degrees of freedom given by the Satterth- waite formula. To estimate b0with a condence interval, compute a condence interval (w2\u0000d1)\u0006t1\u0000a=2;d n+s2 d1 n rst (applying the unequal-varince t-test), and divide it by 2. Step 2d (If b3=0) Maybe we want to estimate b0+b1. Again we can use the average process as in step 2c. Step 3 (If b36=0) Because the carryover affects S1andS2differently, we cannot eliminate b2as we did before. YB1\u0000YA2=b1\u0000b2\u0000b3 Clinical Trials 70 Tatsuki Koyama, PhDTaking the within-individual difference is not going to help, so we cannot take an advantage of the correlated endpoint. In this case, we ignore the data from the second period. b1=YB1\u0000YA1 Var(b1) =2s2 n Treat the study as a two sample test with sample size =nper group. Moreover, we can estimate the treatment effects with b0=YA1 b0+b1=YB1 7.2.1 3, variances of b0and b0+b1are the same. Varfb3gis at least twice as large as Varfb2gforr\u00150. Therefore, any crossover trial designed to detect the differential treatment effects will have lower power for difference of the carryover effects, which is critical to detect the subsequent analysis and interpretation of the trial will be different. With the presence of a clinically important carryover effect difference, a crossover design is no more efcient than an independent-groups trial. A two-stage procedure may be used: the difference of carryover effects is tested rst with a type I Clinical Trials 72 Tatsuki Koyama, PhDerror rate of 10\u001820% before moving on to the primary hypothesis testing of the treatment effects. Estimates will be different depending on the conclusion from the rst stage. 7.3 Examples 7.3.1 From clinicalTrials.gov Capecitabine/Erlotinib Followed of Gemcitabine Versus Gemcitabine/Erlotinib Followed of Capecitabine http://clinicaltrials.gov/ct2/show/NCT00440167 This crossover trial is performed in advanced and metastatic pancreatic cancer not previously ex- posed to chemotherapy. The study compares a standard arm with gemcitabine plus erlotinib to an experimental arm with capecitabine plus erlotinib. It is the rst trial of its kind to incorporate second-line treatment into the study design. Patient who fail on rst-line therapy are switched to the comparator chemotherapy without erlotinib. The trial therefore not only compares two different regimens of rst-line treatment, it also compares two sequential treatment strategies. Colchicine Double-Blind Controlled Disease http://clinicaltrials.gov/ct2/show/study/NCT00700297 Method: patients were randomized at the study entry to take either colchicine or placebo. At 4 months, they were crossed over. Those who were taking colchicine went on placebo and those on placebo went on colchicine. Each patient tried therefore, both colchicine and placebo. The primary outcome was the effect of colchicine on the disease activity index, the IBDDAM (16-17). To calcu- late the overall IBDDAM of the baseline, the IBDDAM of the last 12 months (prior to the study) of each manifestation was calculated and added together. The overall disease activity index was then divided to the number of months (12 months) to have the mean activity index per month. IBDDAM was then measured every 2 months (in the middle and at the end, in each arm of the study). The total IBDDAM of the 4 months was then divided by 4 to have the mean activity index per month. The secondary outcome was to see how the individual symptoms responded to colchicine (IBDDAM of each manifestation). Statistical analysis: The analysis was done by the intention to treat method. As the difference be- tween IBDDAM before and after treatment had normal distribution Student T test for paired samples were used to evaluate the outcome in the colchicine and the placebo group. As the Levene's test showed the homogeneity of variance, ANOVA (one way) was used to test the effect of treatment (colchicine and placebo) and gender on patients' outcome. The dependent variable was the dif- ference between IBDDAM (before and after the treatment). The independent variables were the treatment, and the gender. SPSS 15 was used for all statistical calculations. Clinical Trials 73 Tatsuki Koyama, PhDA Placebo-Controlled, Cross-Over Trial of Aripiprazole http://clinicaltrials.gov/ct2/show/record/NCT00351936 Primary endpoint: Evaluate the effects of aripiprazole on weight, Body Mass Index (BMI), and waist/hip circumference. This study is a ten-week, placebo-controlled, cross-over, randomized trial of the added to 20 obese stable olanzapine-treated patients with schizophre- nia or schizoaffective disorder. The advantage of the crossover design is that each subject will act as their own control and fewer subjects will be required. The double-blind, placebo-controlled, crossover study will consist of two random order 4-week treat- ment arms (aripiprazole 15 mg or placebo) separated by a 2-week adjuvant treatment washout. Following baseline, subjects will be randomized, double-blind, to either aripiprazole or placebo for 4 weeks. After the initial 4 weeks of medication patients will be reassessed, have a 2-week washout period and then crossover to the other treatment for another 4 weeks. Data management and statistical analysis will be provided by Dr. David Schoenfeld from the Mas- sachusetts General Hospital, Biostatistics Center. 7.4 Examples 7.4.1 Hills and Armitage Hills M, Armitage P (1979) Pharmacol .8: 7-20. Children with enuresis were treated with a new drug or placebo for 14 days The primary data are number of dry nights out of 14. An estimate of within-subject differences (treatment effects) is d=YA\u0000YB. The carryover effects may be estimated by Z1=d1\u0000d2q var(d1)+var(d2); and Zis approximately normally distributed under H0. Similarly the overall treatment effect can be estimated by Z2=d1+d2q var(d1)+var(d2); Clinical Trials 74 Tatsuki Koyama, period trt dry 1 1 1 1 1 8 2 1 1 2 0 5 3 2 2 1 0 12 4 2 2 2 1 11 5 3 1 1 1 14 6 3 1 2 0 10 7 4 1 1 1 8 8 4 1 2 0 0 9 5 2 1 0 6 10 5 2 2 1 8 11 6 1 1 1 9 12 6 1 2 0 7 13 7 1 1 1 11 14 7 1 2 0 6 15 8 2 1 0 13 16 8 2 2 1 9 17 9 1 1 1 3 18 9 1 2 0 5 19 10 2 1 0 8 20 10 2 2 1 8 21 11 1 1 1 6 22 11 1 2 0 0 Clinical Trials 75 Tatsuki Koyama, PhD23 12 2 1 0 8 24 12 2 2 1 9 25 13 1 1 1 0 26 13 1 2 0 0 27 14 2 1 0 4 28 14 2 2 1 8 29 15 2 1 0 8 30 15 2 2 1 14 31 16 1 1 1 13 32 16 1 2 0 12 33 17 2 1 0 2 34 17 2 2 1 4 35 18 1 1 1 10 36 18 1 2 0 2 37 19 1 1 1 7 38 19 1 2 0 5 39 20 2 1 0 8 40 20 2 2 1 13 41 21 1 1 1 13 42 21 1 2 0 13 43 22 1 1 1 8 44 22 1 2 0 10 45 23 2 1 0 9 46 23 2 2 1 7 47 24 1 1 1 7 48 24 1 2 0 7 49 25 1 1 1 9 50 25 1 2 0 0 51 26 2 1 0 7 52 26 2 2 1 10 53 27 1 1 1 10 54 27 1 2 0 6 55 28 1 1 1 2 56 28 1 2 0 2 57 29 2 1 0 7 58 29 2 2 1 6 # Group 1: design for the comparison of two active treatments and placebo By GG Koch, IA Amara, BW Brown, T Colton, and DB Gillings (1989). Consider sequences of treatments TT, TC, and CT. 1. The rst period is parallel group design to address direct use in all patients 2. The second period for TT versus TC is a parallel group comparison design to address T versus C for patients who received T during the rst period. 3. The second period for TT versus CT enables \"delayed start\" assessment of T relative to C if dropout during the rst period is minimal and non-informative. 4. The second period for CT versus TC is for assessment of T relative C if carryover effects are small. 5. If T\u0000C from 1, 2, 4 are similar (carryover effects of T to T, T to C, C to T are small), then an overall analysis of treatment effect differences have a very high power. 6. More patients are allocated to receive T within each period. Clinical Trials T. b2\u0001\u0001\u0001Carryover effect for C b3\u0001\u0001\u0001Increment of carryover effect for T tcould represent additional treatment effects for longer duration. Period 1 comparison between T and C is for primary treatment effects, and period 2 comparisons address effects of delayed start (CT vs. TT) and of long-duration effects. Now consider TT, TC, CT, and CC. 1. This design can estimate all the parameters in the TT, TC, CT case. 2. CC vs. CT enables estimation of treatment effects with run-in period. 3. Relatively unethical to have many patients assigned to receive C. to T. b2\u0001\u0001\u0001Carryover effect for C b3\u0001\u0001\u0001Carryover effect for T tcould represent additional treatment effects for longer duration. Example: Pincus T et al. (2004) \"Patient preference for placebo, acetaminophen (paracetamol) or celecoxib efcacy studies (PACES): two randomised, double blind, placebo controlled, crossover clinical trials in patients with knee or hip osteoarthritis\". Ann Rheum Dis .63: 931-939. Clinical Trials 78 Tatsuki Koyama, PhD7.6 Latin squares When there are ktreatments and each patient is to receive all ktreatments. Then there are k! possible sequences. Three treatments yield 6sequences, four treatments yield 24, and ve yield 120. k=3: ABC, ACB, BAC, BCA, CAB, CBA The idea is to use a reduced number of sequences (reduced sample size) but maintain a good \"representation\", i.e., every treatment is represented in every period with the same frequency. P1P2P3 S1A B C S2B C A S3C A BP1P2P3 S1A C B S2B A C S3C B A There are 6!=(3!)(3!) =20ways to choose 3 sequences from 6, but only 2 of those are Latin squares. 7.7 Optimal designs There is an extensive literature on optimal choice of sequences for measuring treatment effects in the presence of carryover. More advanced theory \u0001\u0001\u0001 Optimality depends on assumptions about carryover effects Concerns about carryover can be reduced by using designs with more than two periods. (Laska E, Meisner M, Kushner HB. (1983) This design is not uniquely optimal, but it can be used to estimate treatment effects with more efciency than using data from period 1. P1 P2 P3 P4 AABB m11=m+p1+tam12=m+p2+ta+lam13=m+p3+tb+lam14=m+p4+tb+lb BBAA m21=m+p1+tbm22=m+p2+tb+lbm23=m+p3+ta+lbm24=m+p4+ta+la Note mis the overall mean, pis the period effect, tis the treatment effect, and lis the carryover effect. To obtain an unadjusted (for carryover effect) treatment effect ( B\u0000A), use the following sum to 1for B and\u00001for A to form a contrast B\u0000A. Clinical Trials 79 Tatsuki Koyama, PhD Weights sum are present, we can construct weights so that carryover effects will number patients per sequence. from the 2\b 12+02+02+02 s2 n=2s2 n: The adjusted estimator has slightly higher variance, but it is unbiased with presence of carryover. William's square When an even number of treatments are considered in the same number of periods, William's square gives an optimal design. (Williams EJ (1949). \"Experimental designs balanced for the estimation of residual effects of treatments\". Australian Journal of Scientic Research. Series A2 . 149-168.) It is a Latin square design in which every treatment precedes every other treatments exactly once. P1P2P3P4 sequence 1 A B C D sequence 2 B D A C sequence 3 C A D B sequence 4 D C B A Latin square designs are a special type of incomplete block design. Example : An experiment was conducted to study the effects of different types of background music on the productivity ( Y) of bank tellers. The treatments were dened as ve combinations of temp and style of music: A: slow, instrumental and vocal B: medium, instrumental and vocal C: fast, instrumental and vocal D: medium, instrumental only E: fast, instrumental only There are 120 possible sequences of these treatments. Clinical Trials 81 Tatsuki Koyama, PhDChapter 8 Group sequential design 8.1 Introduction Fully sequential method A test of signicance is repeated after each observation. Group sequential method A test of signicance is repeated after a group of observations. Some basic characteristics of a group sequential method The response variable needs to be observed immediately. Number of stages (or looks) can be 2 to 20. Looks are equally spaced. (This is not a critical requirement.) At each interim (and nal) analysis, compute summary statistic based on the cumulative data. A group sequential method is a strategy to stop early as opposed to an \"adaptive design\", which is often viewed as a strategy to extend the study if necessary. A set of critical values are computed so that the overall ais as specied. -Haybittle-Peto (1971) This is an ad hoc method in which a very conservative critical value (e.g., Z>3) is used at every interim test. At the nal analysis, no adjustment is used (i.e., Z>\u00001:960) It is highly unlikely to stop early. -Pocock (1977) A \"repeated test of signicance\" at a constant signicance level to analyze accumulating data. -O'Brien-Fleming (1979) The signicance levels increase as the study progress. Clinical Trials 82 Tatsuki Koyama, PhD8.2 Example For 5, = 2, alpha = 0.025, beta = 0.1, delta0 = 0, delta1 = 0.25, n.fix = \"OF\") x.po <- gsDesign(k = 5, test.type = 2, alpha = 0.025, beta = 0.1, delta0 = 0, delta1 = 0.25, n.fix = 1, sfu = \"Pocock\") Clinical Trials 83 Tatsuki Koyama, PhD0.0 0.6 0.8 1.0 1.242024 Information FractionBoundary Pocock O'BrienFlemingSample size is expressed in terms of ratios to the sample size of the conventional single-stage design. ## Pocock x.po Symmetric two-sided group sequential design with 90 % power and 2.5 % Type I Error. Clinical Trials 84 Tatsuki Koyama, PhDSpending computations assume trial stops if a bound is crossed. Sample Size Analysis Ratio* Z Nominal p Spend 1 0.241 2.41 0.0079 spending: Pocock boundary. * Sample size ratio compared to fixed design with no interim Boundary crossing probabilities and expected sample size assume any cross stops the trial Upper boundary (power or Type I Error) Analysis Theta 1 2 3 4 5 Total (futility or Type II Error) Analysis Theta 1 2 3 4 5 Total sequential design with 90 % power and 2.5 % Type I Error. Spending computations assume trial stops if a bound is crossed. Sample Clinical Trials 85 Tatsuki Koyama, PhDSize Analysis Ratio* Z Nominal p O'Brien-Fleming boundary. * Sample size ratio compared to fixed design with no interim Boundary crossing probabilities and expected sample size assume any cross stops the trial Upper boundary (power or Type I Error) Analysis Theta 1 2 3 4 5 Total E{N} 0.75 Lower boundary (futility or Type II Error) Analysis Theta 1 2 3 4 5 Total 0.00 0 In the tables of the critical values, Nominal p is simply P[Z>z], where Z\u0018Normal (0;1). Spend is the type I error probability that has been spent by the end of each stage, and it is based on conditional probability. For example, for the second stage of the Pocock design, it is 0:006. It can be computed as follows: P[Z2>2:413j\u00002:413\u0014Z1\u00142:413]: Tatsuki Koyama, PhD8.3 General applications the cumulative sample sizes for the treatment and control groups. Note that this is not a conditional distribution but a marginal distribution. Dene \"information\" as Ik= (s2=ntk+s2=nck)\u00001. Roughly speaking, information is square of what appears in the denominator of the test statistic, Z. When nk=ntk=nck,Ik= (2s2=nk)\u00001. The test statistic multivariate normal distribution because each Zkis a linear combination of the independent normal variates XtiandXci. The marginal distribution of Zkis General decision rule a group sequential design is After group k=1;\u0001\u0001\u0001;K\u00001 ifjZkj\u0015ckstop and reject H0. otherwise continue to group k+1. After group K ifjZkj\u0015cKstop and reject H0. otherwise stop for futility. The test's type I error rate can be expressed as PfjZkj\u0015ckfor some k=1;\u0001\u0001\u0001;Kg: The critical values, ck, are chosen so that the above probability is equal to a. And the power of the study at d1is P(K[ k=1\u0000 jZjj<cj;forj=1;\u0001\u0001\u0001;k\u00001andjZkj\u0015ck\u0001) : Clinical Trials 88 Tatsuki Koyama, PhDEvaluation of this probability requires knowing the distribution of (Z1;\u0001\u0001\u0001;ZK). Refer to tables of cK values or a computer software. For a Pocock method, the critical values are constant, so ck=CP(K;a). That is, specifying a andKuniquely determines the critical values. For the previous example, CP(5;0:025) =2:413. For an O'Brien-Fleming method, the critical values have the form, ck=CB(K;a)p K=k For the same example, CB(5;0:025) =2:040. critical values [1] 2.04 2.28 2.63 3.23 4.56 More generally, if stage sample sizes are different, use Ik, that is, ck=CB(K;a)p IK=Ik. 8.3.1 Beta blocker heart attack trial Seven analyses (including the nal one) were planned (corresponding to the timing of the Data Monitoring Committee meetings) using O'Brien-Fleming bounds with two-sided type I error rate of 5%. The primary outcome was survival, and log-rank test was used. Clinical Trials 89 Tatsuki Koyama, PhDIf Pocock boundary had been used, N=7anda=0:05give Z=2:485. Therefore, the trial would have been stopped at the same point. 8.3.2 non-Hodgkin's lymphoma Pocock 1983 Clinical Trials: A Practical Approach . A trial was conducted in patients with non- Hodgkin's lymphoma for two drug -CVP-). The primary endpoint was tumor shrinkage (Y es/No). Statistical analyses were planned after approximately 25 patients. With 5 looks and one-sided a= 0:05. The Pocock procedure requires a signicance level of 0.017 at each analysis. c2tests without the continuity correction were performed at each of the 5 scheduled analyses. gsDesign(k=5, test.type=1, alpha=0.05, n.fix=1, sfu= 'Pocock ') One-sided group sequential design with 90 % power and 5 % Type I Error. Sample Size Analysis Ratio* Z Nominal p Spend 1 0.246 2.12 0.0169 spending: Pocock boundary. * Sample size ratio compared to fixed design with no interim Boundary crossing probabilities and expected sample size assume any cross stops the trial Upper boundary (power or Type I Error) Analysis Theta 1 2 3 4 5 Total =24 =36 5 23=67 31 CVP appeared better than the CP , but difference was not statistically signicant. Further analy- ses of secondary endpoints convinced the researchers that the CVP was better than the CP . 8.4 Alpha-spending \"Classical\" group sequential designs have equal information (sample size) at every stage, but we may want to be a little more flexible. And when Ikis not a constant we might want to change aspent accordingly. Clinical Trials 91 Tatsuki Koyama, The biggest alpha-spending approach is its flexibility; neither the number nor timing of the interim analyses need to be specied in advance. The monitoring plan can be changed during the trial and still type I error rate is preserved. The power depends relatively little on the number and timing of the CD, DeMets DL Clinical Trials 92 Tatsuki 0.4 0.6 0.8 1.00.0000.0050.0100.0150.0200.025 Information fractionalpha spendingOF Pocock Power (1) Power (4)alpha spending functions8.5 One-sided test If \"stop for futility\" is not an option, the same boundary can be used. If a futility stop is an option, then Clinical Trials 93 Tatsuki Koyama, PhDAfter group k=1;\u0001\u0001\u0001;K\u00001 ifZk\u0015bkstop and reject H0). After group K ifZk\u0015bKstop and reject H0. ifZk<aKstop for futility. Note that aK=bKensures that the test terminates at analysis K. 8.6 Repeated condence intervals If we compute unadjusted condence intervals \u00afXso far\u00061:96s=pnso far at the end of each stage, we get low coverage probabilities. Armitage, McPherson, Rowe (\"Repeated signicance tests on accumulating data\". JRSS-A 1969) computed the actual coverage probabilities (Table 2). Number of looks Overall probability that all intervals contain q 1 0 :95 2 0 :92 3 0 :89 4 0 :87 5 0 :86 10 0 :81 20 0 :75 50 0 :68 \u00a5 0 The idea of repeated condence intervals (RCIs) is to use an adjusted value, ck(a;K), instead of 1:96so that the overall coverage probability is 1\u0000a=2. The value of ck(a;K)is the critical value (border) for each stage and depends on aand Kif Pocock boundary is used, and additionally kif O'Brien-Fleming boundary is used. Example: Suppose we use a 6-stage group sequential design of O'Brien-Fleming type with a two- two-sided group sequential design with 90 % power and 2.5 % Type I Error. Spending computations assume trial stops if a bound is crossed. Sample Size Clinical Trials 94 Tatsuki Koyama, PhDAnalysis Ratio* Z spending: O'Brien-Fleming boundary. * Sample size ratio compared to fixed design with no interim Boundary crossing probabilities and expected sample size assume any cross stops the trial Upper boundary (power or Type I Error) Analysis Theta 1 2 3 4 5 6 Total E{N} (futility or Type II Error) Analysis Theta 1 2 3 4 5 6 Total 0.00 0 0.0002 2.90 2.51 2.25 2.05 First, let's conrm that the critical values have the form ck=COB(K;a)p IK=Ik. The nal critical value COB(6;a) =2:053, and assuming the looks are equi-distant (same after stage 1, we would use 2:053in place of the regular 1:96when computing a 95%condence interval. In general after stage k(k=1;\u0001\u0001\u0001;6), (\u00afxkt\u0000\u00afxkc)\u0006ckp 2s2 p mk; where mis per-group sample size for each stage. This method (RCI) is consistent with the corresponding hypothesis testing. Only when is H0rejected in stage k, the condence interval for that stage will exclude the null value. Thus, we can use the idea of \"inverting hypothesis test\" to get the same condence interval. (more later) 8.7 p-values Recall how we construct a proper p-value for a Simon's two-stage design in phase II methodology. We needed to dene \"more or as extreme as the observed data\". To be able to do this, we need to have an ordering of all the sample paths. In a simple single-stage design, the ordering is usually based on z-values (or absolute value of z-values if two-sided test), i.e., the bigger the observed z, the stronger the evidence against H0. Then a one-sided p-value is computed by p=P0[Z\u0015z]: With a group sequential design, or more generally, with a multi-stage design with pre-specied group- wise sample sizes, the is true: 1.k0=kandz0\u0015z. 2.k0<kandz0\u0015bk0(upper critical value). 3.k0>kandz\u0014ak(lower critical value). MLE ordering. (k0;z0) (k;z)ifz0=pIk0>z=pIk. Originally proposed in connection with a test for a binomial proportion The bigger value of the MLE gets a higher order. Sometimes called \"sample mean ordering\" because this is equivalent to ordering based on the sample mean (one-sample) or the difference of sample means (two-samples). Likelihood ratio ordering. (k0;z0) (k;z)ifz0>z. (Stages do not matter.) Clinical Trials 96 Tatsuki Koyama, PhD Score test ordering. (k0;z0) (k;z)ifzpIk0>zpIk. Whichever ordering is used, we can compute a one-sided p-value is P0[(T;ZT) (k\u0003;z\u0003)] For example, if we use a stage-wise ordering and test terminates in the K\u00001stage with ZK\u00001>bK\u00001 H0). p=Z\u00a5 b1g1(z;0)dz+\u0001\u0001\u0001+Z\u00a5 z\u0003gK\u00001(z;0)dz: In the above expression, gk(z;q)is a density function of zin stage k. Conceptually, the density function of zinkstage depends on all the data in the previous stages, 1\u0001\u0001\u0001k\u00001, requiring multivariate integration. Armitage, McPherson, Rowe (1969) derived a recursive formula so that the computation is much simplied, requiring only a =Z Ck1gk\u00001(m;q)pIkpDKf\u0012zpIk\u0000mpIk\u00001\u0000DkqpDk\u0013 region the stage k1, and Dkis the increment information, Ik\u0000Ik\u00001. If stage-wise ordering is used, it automatically ensures that item the p-value is less than the signi- cance level aif and only if H0is rejected. Once we dene the ordering to use with the group sequential test then we can compute a p-value for testing H0:q=0by \"inverting hypothesis test\". A (1\u0000a=2)condence interval is a collection of q0 0 such that H0 0:q=q0 0would be accepted with the observed sample path. (More details with general adaptive designs.) Clinical Trials 97 Tatsuki Koyama, PhDChapter 9 General Adaptive Designs Adaptive clinical trials are prospectively planned. -All possible adaptations are dened in protocol. require much more forethought than a single stage design. require same level of evidence as usual. are accepted by regulators (e.g., FDA) -FDA guidance available Guidance for Industry: Adaptive Design Clinical Trials for Drugs and Biologics are nicer with the Bayesian method. 9.1 Introduction Much of discussion in the literature for flexible designs in phase III clinical trial methodologies revolves around 2 stage designs. Practically speaking, implementing flexible Frequentist clinical trials beyond two stages is difcult, and perhaps these multi-stage flexible designs add only little to the designs with just two stages. Moreover, phase III clinical trials are for conrmatory purposes, and adaptively changing the design more than once in the middle of a conrmatory trial is not seen favorable by the regulatory gure. So we will only consider two-stage adaptive designs. Two-stage group sequential designs are exam- ples of such designs. Clinical Trials 98 Tatsuki Koyama, PhD9.2 Background We will look at unblinded two stage designs in which all the information from stage 1 is available. Design of the second stage (sample size and critical value) may be specied as functions of stage 1 data. If both sample size and critical value are constants in stage 1 data, then it reduces to a two-stage group sequential design. Adaptive designs can be categorized into the following two types: prespecied designs Design of the second stage (e.g., sample size and critical value) is specied before the rst stage. There is nothing to decide at the end of stage 1. The design of the second stage is dened flexibility as functions of stage 1 data. Group sequential designs fall into this category. unspecied designs Design of the second stage is not specied in advance and determined after stage 1 data are observed. These designs are generally not accepted by the regulatory body. Characteristics of these types of designs: prespecied designs Type I error can be controlled. Type II error can be controlled; the power can be specied. Design characteristics (e.g., expected and maximum sample sizes) can be computed prior to the initiation of the study. unspecied designs Type I error can be controlled. These designs give much flexibility to handle unexpected situations (e.g., variance much bigger than anticipated). Probably not accepted. What they say about adaptive designs... PhRMA (2006) \"A clinical study design that uses accumulating data to decide how to modify aspects of the study as it continues, without undermining the validity and integrity of the trial.\" \"... changes are made by design, and not on an ad hoc basis; therefore, adaptation is a design feature aimed to enhance the trial, not a remedy for inadequate planning.\" Clinical Trials 99 Tatsuki Koyama, PhDEMA (2006) \"A study design is called 'adaptive' if statistical methodology allows the modication of a design element (e.g. sample-size, randomisation ratio, number of treatment arms) at an interim analysis with full control of type I error rate.\" \"adaptive designs should not be seen as a means to alleviate the burden of rigorous planning of clinical trials.\" FDA (2010) \"... adaptive design clinical study is dened as a study that includes a prospectively planned opportunity for modication of one or more aspects of the study design and hypotheses based on analysis of data (usually interim data) from subjects in the study.\" 9.3 Conditional power Power is the probability of rejecting H0. Type I error rate is the power computed under H0. Conditional power is the probability of rejecting H0at the end of the second stage conditioned on the rst stage data. Example: Suppose in stage 1, we will reject H0ifZ1>2:3otherwise continue to stage 2. At the end of stage 2, we will reject H0ifZ2>2:1, where Z1is from the stage 1 data, and Z2is from the combined data from both stages. Then Stage 1 power is P[Reject H0at the end of stage 1] =P[Z1>2:3]. Stage 2 conditional power is P[Reject H0at the end of stage 2 | Stage 1 data] =P[Z2>2:1jZ1= z1]. -If there is no stage 2, conditional power does not exist, but... -we can let conditional power =1ifH0is rejected in stage 1 and =0if the trial stops for futility in stage 1. Conditional type I error rate is the probability of rejecting H0in stage 2 under H0conditioned on the stage 1 data. Suppose Z2=Z1+Z2\u00001p 2 Clinical Trials 100 Tatsuki Koyama, PhDwhere Z2are from the cumulative data, and Z2\u00001are from the stage 2 data only. Under H0Z2\u0018 Normal (0;1). Conditioned on Z1=z1, we have Z2=z1+Z2\u00001p 2: Therefore, Z2>cis equivalent to Z2\u00001>p 2c\u0000z1: # Stage 1 type I error rate 1-pnorm(2.3) [1] 0.0107 # Conditional type I Reject 1-pnorm(2.1 * sqrt(2) - z1) } # Conditional type I error rate if Z_1 = 0. condTypeI(0) [1] 0.00149 # Conditional type I error rate if Z_1 = 1. condTypeI(1) [1] 0.0244 # Conditional type I error rate if Z_1 = 2. condTypeI(2) [1] 0.166 When planning a two-stage adaptive design, we need to make sure that the (unconditional) type I error rate is a, which is usually 2:5%To compute the unconditional type I error rate, or more generally, the unconditional power, we need to integrate the unconditional type I error rate (power) with respect to the distribution of Z1. Clinical Trials 101 error rate. lower=-Inf, upper=2.3)$value [1] 0.0138 Sometimes, the term, \"predictive power\" is confused with the conditional power. The predictive power is a Bayesian concept, which is a weighted average of the power computed for different values of q with the weight is dened by the distribution of q. In the above example, we used a simple test statistic Z2=Z1+Z2\u00001p 2 to combine the data from both stages; however, this is rarely used in practice (despite its simplicity) because it puts the same weight on the stage 1 and 2 z-values regardless of the sample sizes. 9.4 Two-stage design -without all the math- We will consider a simple situation, where we aim to test H0:d=0, where d=mt\u0000mc. Random samples are taken from the treatment and control populations Xt\u0018Normal (mt;s2 t) Xc\u0018Normal (mc;s2 c): and known: s2 t=s2 c=s2. Also assume the stage 1 sample sizes are equal in the control and treatment groups: n1t=n1c=n1. Then \u00afX1t\u0018Normal the null is Norlam (0;1). In stage 1, we observe Z1and use the following decision rule: Clinical Trials 102 Tatsuki Koyama, PhD IfZ1<k1, stop for futility. IfZ1>k2, stop and reject H0. Ifk1<Z1<k2then continue to stage 2. In stage 2, we take a sample of size n2from each arm, and dene Z2\u00001=pn2(\u00afX2t\u0000\u00afX2c)p 2s: (0;1)under H0. Note that n2may be a function of the stage 1 data. Instead of combining the stage 1 and 2 data with (Z1+Z2\u00001)=p 2, we will use the following test statistic so that each Xis weighted equally. Z2=pn1pn1+n2Z1+pn2pn1+n2Z2\u00001: We can write down the conditional distribution of this test statistic given Z1=z1(omitted). The important ideas here are: n2is not a constant, but it is a random variable. n2(z1). When conditioned on Z1=z1,Z1is no longer a random variable but a constant. There are many decent ways to combine the stage 1 and 2 data. The critical value to use at the end of stage 2 can be for Z2\u00001, and it may be a function of Z1. In the second stage, a sample of size n2(z1)is taken, and the decision rule at the end of stage 2 is: IfZ2\u00001\u0014c(z1), stop and conclude futility. IfZ2\u00001>c(z1), stop and conclude efcacy. 9.5 Conditional power functions Like with the group sequential designs, we need to have the conditional type I error rate that satises a=a1+Zk2 k1P0[Reject H0jZ1=z1]g(z1)dz1: Clinical Trials 103 Tatsuki Koyama, PhDP0[Reject H0jZ1=z1]is the conditional power, and we can use any form of conditional power as long as the above criterion is satised. Here let CP(Z1;d)to denote the conditional power function, so that CP(Z1;d=d0)is the conditional type I error rate. CP(Z1;d=d1)is the conditional power at the original alternative. CP(Z1;d=d)is the conditional power at the stage 1 trend. 9.6 Example Design a two-stage procedure to test H0:mt\u0000mc=0and H1:mt\u0000mc>0. Assume sis known to be 4. We want one sided ato be 0:025and power to be 0:90atmt\u0000mc=1. For a single stage design, the sample size is N=42(2)(z0:025+z0:10)2 Stage 1 design Let's decide to look at the data when n1=135observations are available from each group. (approxi- mately 40% ofN) We also need to decide how much of aandbwe want to \"spend\" in stage 1. Let's 2 0 2 4Stage 1 probabilitiesAlso let's set the maximum sample size to be 500 (approximately 50% increase from N). Clinical Trials 105 Tatsuki Koyama, PhD0.0 0.5 1.0 z1n1+n2(z1) 0 k1 1 k2n1NFirst, let's look at some stage 1 design characteristics: Some stage 1 characteristics Stage 1 m x z Accept Continue Reject 0 0 0 0:538 0 :453 0 :010 0 :582 0 :393 Stage 2 design: For stage 2, we will choose a conditional type I error function so that the type I error rate is controlled at2:5%. Also, we will choose a conditional power function so that the overall (unconditional) power is90%. Clinical Trials 107 Tatsuki Koyama, PhD-Some math - We choose to use the following conditional type I error function: CP(Z1;d=d0) =0:002+5:255(z1\u0000k1): And the conditional power function: CP(Z1;d=d1) =0:75+1:004(z1\u0000k1): These two functions will satisfy the type I error rate condition ( 2:5%) and power condition ( 90%). the form A(z1;x0) =a0+a1(z1\u0000k1)2and A(z1;x1) =b0+b1(z1\u0000k1). We can use any Afunctions as long as they satisfy aand power conditions. First we pick a0(the value of A(z1;x0)atz1=k1to be 0:002and solve for that A(z1;x1) =0:75+1:004(z1\u0000k1): Using these two Afunctions, we can compute n2(z1), and it turns out maxfn1+n2(z1)g>500, and we need to modify the design a little. It is relatively simple to make small modications to the design be- cause we understand how the design elements A(z1;x0),A(z1;x1),n2(z1), and c(z1), are interrelated. First while xing A(z1;x0), we \"tap\" n2(z1)so that maxfn1+n2(z1)g=500. This action changes A(z1;x1) slightly resulting a smaller power than 0:90. To make the power 0:90again, we add a constant to the new A(z1;x1)but capping the resulting n1+n2(z1)at500. The nal design is shown below graphically. Clinical Trials 108 Tatsuki Koyama, PhD0.0 0k1 1k2n1NDesign with flat A0and flat A1 Stage 1 Stage 2 This design Single stage m x n1Accept Continue Reject Reject Power E[N]Max NPower N 0 0 0:538 0:507 0:900 337 In the literature, many specic Afunctions have been proposed. A few examples include: Proschan (1995) APH(z1;x) Lan (2004) ACDL(z1;x) A(z1;z1)\"Conditional power under the current trend\" 9.7 Unspecied designs The minimum requirement to control type I error rate is to pre-specify A(z1;x0)function that satises acondition. Then after the rst stage, when the actual z1from the data are available, pick n2(z1)so that conditional powers at any a value of x(other than x0) can be set. If we allow even A(z1;x0)to be specied after the st stage, type I error rate cannot be controlled. There exist many (in fact innite number of) A(z1;x0)functions that give the desired value of a1(0:01 in our example). Depending on z1the required sample size to guarantee a certain conditional power differs. We cannot choose an A(z1;x0)function that gives the minimum sample size for the observed z1. Roughly speaking, when the conditional type I error rate at the observed z1is large, the required sample size is small for the same conditional power. All three conditional type I error rates in the following plot give a=0:025. Clinical Trials 111 Tatsuki Koyama, PhD0.0 0.5 1.0 Trials 112 Tatsuki Koyama, Ordering of sample space To compute p-values and condence interval (through inverting hypothesis tests), we need to dene an ordering of sample space; however, this task is difcult because of sample size difference for potential values of z1. One useful fact (not too difcult to show) is that the decision rule, \"reject if Z2>c(z1)\" is equivalent to the rule \"reject if stage 2 (conditional) p-value is less than A(z1;x0)evaluated at the observed z1.\" So we can compute a (conditional) p-value just using the stage 2 data, P0[Z2>z2], and compare it to the conditional type I error rate computed at the observed z1. Suppose the red line in the previous plot is used as A(z1;x0), then ifz1=2:0and stage 2 conditional p-value is 0:10then H0will be rejected because this p-value is less than A(z1;x0)i.e., below the red line. ifz1=1:0and stage 2 conditional p-value is 0:10then H0will not be rejected. Therefore, we need an ordering of the sample space that takes into account not only the sample size of stage 2, n2(z1), but also the conditional type I error rate for the stage 2, A(z1;x0). Suppose we choose to use A(z1;x0)andA(z1;x1)shown in the plot below. 0.0 0.5 1.0 1.5 2.0 2.50.00.20.40.60.81.0 Z1Conditional PowersA(z1,1) A(z1,0)=.005+.1118(z 1k1)2 Clinical Trials 113 Tatsuki Koyama, PhDAnd let's consider the following 5 sample paths indicated by the conditional pvalues. Can we order the strength of evidence against H0for these data? 0.0 0.5 1.0 1.5 2.0 2.50.00.20.40.60.81.0 Z1Conditional PowersA(z1,0)=.005+.1118(z 1k1)2 When z1is the same, the second stage sample size is the same, so it should be simple to order the sampling paths. The smaller pvalue, the stronger evidence against H0. Blue Red Y ellow. When the conditional pvalues are the same, then we can order them by the strength of evi- dence in the rst stage. Blue Black Green. The black and red dots should indicate equal strength of evidence because they both result in \"just\" rejecting H0. So in the above picture, the only unclear ordering is between Green and Y ellow. The third rule gives a hint as to how to proceed; the data leading to the black and red dots indicate that those data have just enough evidence to reject H0. The blue dot is for a sampling path that gives stronger evidence against H0; we could reject H0 0that is more extreme. We can nd a value of x\u0003 0(equivalently, m\u0003 0) so that A(z1;x\u0003 0)goes through the blue dot, and say we could have rejected H\u0003 0:m=m\u0003 0. Clinical Trials 114 Tatsuki Koyama, that p=P0[Z2>z2], and once a value of z1is observed, we can evaluate c(z1)andn2(z1), so the only unknown quantity in the above expression is x\u0003 0. From the above picture, we know the ordering is: Blue Red=Black Green Y ellow. And \"some as or more extreme\" than the observed is anything on and below the line, and we can compute the p-value by computing Z\u00a5 k2g1(z1;x0)dz1+Zk2 k1A(z1;x\u0003 A(z1,0) A(z1,.22) This method (ordering) guarantees that the p-value and the corresponding hypothesis testing are consistent ( p-value <aiffH0is rejected). And it can be shown that when n2(z1)and cu(z1){critical value for the combined statistic} are con- stants, this ordering reduces to the stage-wise ordering. Clinical Trials 115 Tatsuki Koyama, PhD9.9 Predictive power With an unspecied design, some people are reluctant to use the conditional power to determine the design of the second stage. One issue is that where to compute the conditional power is not always clear. The original alternative is usually a reasonable choice ( A(z1;x1)). However, when the observed z1is much different (smaller) from x1we may not be interested in the conditional power at x1but at some smaller value that is still clinically meaningful. (Minimum clinically relevant alternative =x 1) Another popular choice isx\u0011z1=pn1(\"alternative under the current trend\"). Or maybe we should compute the conditional power at somewhere in between x1andx 1. Average? Now we are talking like a Bayesian because we are talking about an average of xs which are, for a frequentist, parameters. Maybe we have a prior distribution of x(or equivalently m). And a posterior distribution of xafter the rst stage, p(xjz1), and we can compute a weighted average of the conditional power with respect to the posterior distribution. Something like Z\u00a5 \u0000\u00a5A(z1;x)p(xjz1)dx; and this is often called a predictive power given the stage one data. The conditional power is a frequentist concept, and it is computed at one value of x. The predictive power is a Bayesian concept, and it is a weighted average of the conditional power with respect to a posterior distribution of x. Clinical Trials 116 Tatsuki Koyama, PhD "}