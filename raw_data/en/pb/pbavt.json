{"title": "PDF", "author": "PDF", "url": "https://nces.ed.gov/nationsreportcard/pdf/main1996/1999455.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "STUDENT WORK ANDTEACHER PRACTICES IN SCIENCESTUDENT WORK ANDTEACHER PRACTICES IN SCIENCE U.S. Department of Education Office of Educational Research and Improvement NCES 1999-455 NATIONAL CENTER FOR EDUCATION STATISTICSWhat is The Nation's Report Card? THE NATION'S REPORT CARD, the National Assessment of Educational Progress (NAEP), is the only nationally representative and continuing assessment of what America's students know and can do in various subject areas. Since 1969,assessments have been conducted periodically in reading, mathematics, science, writing, history, geography, and otherfields. By making objective information on student performance available to policymakers at the national, state, and locallevels, NAEP is an integral part of our nation's evaluation of the condition and progress of education. Only informationrelated to academic achievement is collected under this program. NAEP guarantees the privacy of individual students andtheir families. NAEP is a congressionally mandated project of the National Center for Education Statistics, the U.S. Department of Education. The Commissioner of Education Statistics is responsible, by law, for carrying out the NAEP project throughcompetitive awards to qualified organizations. NAEP reports directly to the Commissioner, who is also responsiblefor providing continuing reviews, including validation studies and solicitation of public comment, on NAEP's conductand usefulness. In 1988, Congress established the National Assessment Governing Board (NAGB) to formulate policy guidelines for NAEP. The Board is responsible for selecting the subject areas to be assessed from among those included in the NationalEducation Goals; for setting appropriate student performance levels; for developing assessment objectives and testspecifications through a national consensus approach; for designing the assessment methodology; for developing guidelinesfor reporting and disseminating NAEP results; for developing standards and procedures for interstate, regional, and nationalcomparisons; for determining the appropriateness of test items and ensuring they are free from bias; and for taking actionsto improve the form and use of the National Assessment. The National Assessment Governing Board Mark D. Musick, ChairPresidentSouthern Regional Education BoardAtlanta, Georgia Michael T. Nettles, Vice Chair Professor of Education & Public PolicyUniversity of MichiganAnn Arbor, Michiganand DirectorFrederick D. Patterson Research InstituteUnited Negro College Fund Moses Barnes Secondary School PrincipalFort Lauderdale, Florida Melanie A. Campbell Fourth-Grade TeacherTopeka, Kansas Honorable Wilmer S. Cody Commissioner of EducationState of KentuckyFrankfort, Kentucky Edward Donley Former ChairmanAir Products & Chemicals, Inc.Allentown, Pennsylvania Honorable John M. Engler Governor of MichiganLansing, Michigan Thomas H. Fisher Director, Student Assessment ServicesFlorida Department of EducationTallahassee, Florida Michael J. Guerra Executive DirectorNational Catholic Education AssociationSecondary DepartmentWashington, California Juanita Haugen Local School Board PresidentPleasanton, California Carole Kennedy Elementary School PrincipalColumbia, Missouri Honorable Nancy Kopp Maryland House of DelegatesBethesda, Maryland Honorable William J. Moloney Commissioner of EducationState of ColoradoDenver, Colorado Mitsugi Nakashima First Vice-ChairpersonHawaii State Board of EducationHonolulu, Hawaii Debra Paulson Eighth-Grade Mathematics TeacherEl Paso, Texas Honorable Norma Paulus Former Superintendent of Public Instruction Oregon State Department of EducationSalem, Oregon Honorable Jo Ann Pottorff Kansas House of RepresentativesWichita, Kansas Diane Ravitch Senior Research ScholarNew York UniversityNew York, New YorkHonorable Roy Romer (Member Designate)Former Governor of ColoradoDenver, Colorado John H. Stevens Executive DirectorTexas Business and Education CoalitionAustin, Texas Adam Urbanski PresidentRochester Teachers AssociationRochester, New York Deborah Voltz Assistant ProfessorDepartment Special EducationUniversity of LouisvilleLouisville, Kentucky Marilyn A. Whirry Twelfth-Grade English TeacherManhattan Beach, California Dennie Palmer Wolf Senior Research AssociateHarvard Graduate School of EducationCambridge, Massachusetts C. Kent McGuire (Ex-Officio) Assistant Secretary of EducationOffice of Educational Research and Improvement U.S. Department of EducationWashington, DC Roy TrubyExecutive Director, NAGBWashington, DCStudent Work and Teacher Practices in Science 1.2 Distribution of Estimated Assessment Time by Ways of Knowing and Doing of Students Within Each Science Achievement Level for the Map of Selected Questions on the NAEP Science Scale for Selected Questions on the NAEP Science Scale for Selected Questions on the NAEP Science Scale for 2.1 Distribution of Questions by Fields of Science and by W ays of Knowing and Doing Science, Grade 4:Public and Nonpublic 2.2 Teachers' Reports on How Much Time They Spent Teaching Life Science, Earth Science, and Physical Science, Grade 4: Public andNonpublic 2.3 Average Question Score for Earth Science, Physical Science, and Life Science, Grade 4:Public and Nonpublic 2.4 Average Question Score for Conceptual Understanding, Scientific Investigation, and Practical Reasoning, Grade 4:Public and Nonpublic 2.5 Sample Questions Categorized by Fields of Science and by Ways of Knowing and Doing Science, Grade 4:Public and Nonpublic Percentages Choosing Each Response: Grade 4 Major Source Percentages Correct within Each Achievement Level Interval: Grade 4 Major Source Correct within Each Achievement Level Interval: Grade Choosing Each Response: Grade 4 Visibility of Correct within Each Achievement Level Interval: Grade 4 Visibility of Moon Correct within Each Achievement Level Interval: Grade 4 Percentages Complete or Essential within Each Achievement Level Interval: Correct within Each Achievement Level Interval: Grade within Each Achievement Level Interval: Grade at Different Score Levels: Grade 4 Plants: or Essential within Each Achievement Level Interval: Grade 4Plants: Percentages Correct within Each Achievement Level Interval: Grade Percentages Correct within Each Achievement Level Interval: Grade 4 Percentages Complete within Each Achievement Level Interval: Grade 4 Percentages Correct within Each Achievement Level Interval: Grade 4 Percentages at Different Score Levels: Grade 4 Properties Complete within Each Achievement Level Interval: Grade 4 Percentages Complete within Each Achievement Level Interval: Grade Percentages Complete or Essential within Each Achievement Level Interval: Grade Complete within Each Achievement Level Interval: Grade Complete within Each Achievement Level Interval: Grade Percentages Complete within Each Achievement Level Interval: Grade 4 Ease D istribution of Questions by Fields of Science and by Ways of Knowing and Doing Science, Grade 8:Public and Nonpublic 3.2 Teachers' Reports on How Much Time They Spent Teaching Life Science, Earth Science, and Physical Science, Grade 8:Public and Nonpublic 3.3 Average Question Score for Earth Science, Physical Science, and Life Science, Grade 8:Public and Nonpublic 3.4 Average Question Score for Conceptual Understanding, Scientific Investigation, and Practical Reasoning, Grade 8:Public and Nonpublic 3.5 Sample Questions Categorized by Fields of Science and by Ways of Knowing and Doing Science, Grade 8:Public and Nonpublic Percentages Correct within Each Achievement Level Interval: Grade 8 Location Correct within Each Achievement Level Interval: Grade Correct within Each Achievement Level Interval: Grade Complete within Each Achievement Level Interval: Grade 8 Percentages Correct within Each Achievement Level Interval: Grade Percentages Complete or Essential within Each Achievement Level Essential within Each Achievement Level Interval: Grade Complete within Each Achievement Level Interval: Grade Percentages Correct within Each Achievement Level Interval: Grade 8 Percentages Complete or Essential within Each Achievement Level Interval: within Each Achievement Level Interval: Grade Percentages Complete within Each Achievement Level Interval: Grade 4.1 Distribution of Questions by Fields of Science and by Ways of Knowing and Doing Science, Grade 12:Public and Nonpublic 4.2 Average Question Score for Earth Science, Physical Science, and Life Science, Grade 12:Public and Nonpublic 4.3 Average Question Score for Conceptual Understanding, Scientific Investigation, and Practical Reasoning, Grade 12:Public and Nonpublic 4.4 Sample Questions Categorized by Fields of Science and by Ways of Knowing and Doing Science, Grade 12:Public and Nonpublic Percentages Correct within Each Achievement Level Interval: Grade 12 Percentages at Different Score Levels: Grade 12 Pacific Ring Percentages Complete or Essential within Each Achievement Level Interval: Grade 12Pacific Correct within Each Achievement Level Interval: Grade 12 Percentages Correct within Each Achievement Level Interval: Grade 12 Interpretation Correct within Each Achievement Level Interval: Grade 12 at Different Score Levels: Grade 12 Keeping Correct within Each Achievement Level Interval: Grade 12 Keeping Ice Complete within Each Achievement Level Interval: Grade Percentages Correct within Each Achievement Level Interval: Grade 12 Temperature at Different Score Levels: Grade 12 Identification of Ocean and Essential within Each Achievement Level Interval: Grade 12Identification of Ocean or Essential within Each Achievement Level or Essential within Each Achievement Level Interval: or Essential within Each Achievement Level Interval: Teachers' Reports on How Much Emphasis They Give to Student Objectives, Grades 4 and 8:Public and Nonpublic Reports on How Often Students Do a V ariety of Classroom Activities, Grades 4 and 8:Public and 5.3 Reports from Students Currently Taking a Science Course on How Often They Do a Variety of Classroom Activities, Grade 12:Public and Nonpublic Teachers' Reports on Using Different Teaching Activities, Grades 4 and 8: Public and Nonpublic Students' Reports on How Often Their Teachers Use Different Teaching Activities, Grade 12:Public and Nonpublic on Doing Hands-on Tasks, Grades 4, 8, and 12: Public and 5.7 St udents' Reports on Whether or Not They Conduct Science Projects or Investigations that Take a Week or More,Grades 4, 8, and 12: Public and Teachers' Reports on How They Use Computers for Science Instruction, Grades 4 and 8: Public and Nonpublic Teachers' Reports on How Much Science Homework They Assign, Grades 4 and 8: Public and Nonpublic Students' Reports on Attitudes and Beliefs about Science, by Gender, Grade 4: Public and Nonpublic Schools Reports on Attitudes and Beliefs about Science, by Race/Ethnicity, Grade 4: Public and Nonpublic Relationship Between Students' Average Scale Scores and Positive Attitudes and Beliefs about Science,Grades 4, 8, and 12: Public and Reports About their Motivation and Performance on the NAEP Science Assessment, Grades 4 and 8:Public and Reports About their Motivation and Performance on the NAEP Science Assessment, Grade 12:Public and Reports on Parental Involvement, Grades 4, 8 and 12: Public and Nonpublic Schools' Reports on the Severity of Three Problems in the School, Grades 4 and 8: Public and Nonpublic for the NAEP 1996 Science Assessment . Teacher Practices in Science iIn 1996 the National Assessment of Educational Progress (NAEP) assessed the knowledge and skills of students in the areas of earth science, life science, and physical science. It alsocollected information relating to the background of students (grades 4, 8, and 12), their teachers(grades 4 and 8), and the schools they attended (grades 4, 8, and 12). This report is intendedprimarily for teachers; hence, the results presented relate directly to students ' performance, classroom practices, and school climate. The report also discusses students ' attitudes and beliefs about science. Performance, Knowledge, and Skills At grades 4 and 8, the amount of exposure to the different fields of science was notassociated with differences in the composite, life science, earth science, or physicalscience average scale scores of students or the percentage of students at or aboveProficient . At grades 4 and 8, male students had a higher average question score than female students for questions that measured conceptual understanding. At grade 12, malestudents outperformed female students on questions that measured conceptualunderstanding and practical reasoning. At grades 4, 8, and 12, White students had a higher average question score than Black and Hispanic students for questions that measured earth, physical, and lifescience and also for questions that measured conceptual understanding, scientificinvestigation, and practical reasoning. Classroom Practices Seventy-eight percent of fourth graders and 88 percent of eighth graders had teacherswho reported placing heavy emphasis on understanding key science concepts. Thesestudents had higher average scale scores and were more likely to be at or above theProficient level than students whose teachers placed less emphasis on this objective. Forty-one percent of students in grade 8 had teachers who reported placing a heavy emphasis on developing laboratory skills; 15 percent of fourth graders had teacherswho reported the same emphasis. The eighth-grade students had higher average scalescores and were more likely to perform at or above the Proficient level than eighth graders whose teachers reported placing less emphasis on laboratory skills. Thereii Student Work & Teacher Practices in Sciencewas no difference in performance among fourth graders that was associated with how much emphasis their teachers gave to developing laboratory skills. Teachers of 56 percent of fourth graders and 80 percent of eighth graders reported students doing hands-on activities at least once or twice a week. At the eighth-gradelevel, students who did hands-on activities almost every day or once or twice a weekhad higher scale scores and were more likely to be at or above the Proficient level than students who did hands-on activities once or twice a month or never or hardlyever. A similar pattern was seen at grade 12, based on self-reporting by students. Nodifferences were seen at the fourth-grade level. Approximately half of the student population at grades 4 and 8 had teachers who reported not using computers for instruction in science. Teachers of 42 percent and 87 percent of students in grades 4 and 8, respectively, reported that they expected their students to spend one hour or more on theirhomework each week. Attitudes, Motivation, and School Climate At the fourth-grade level, 67 percent of students said they liked science. Thepercentages were somewhat lower for eighth and twelfth graders: 50 and 52 percent,respectively. Those who said they liked science outperformed those who said they didnot like science. In general, the greater the number of positive attitudes towards science, the higher the performance of students at grades 4, 8, and 12. The percentage of students who thought it was important to do well on the NAEP science assessment was highest at the fourth-grade level, 59 percent, and lowest atthe twelfth-grade level, 9 percent. Students who thought it most important to do welldid not necessarily perform better than students who thought it less important to dowell. Where the school problems of student absenteeism, teacher absenteeism, and lack of parental involvement were more severe, as reported by school administrators, studentperformance was lower.Chapter 1 Student Work & Teacher Practices in Science 1This is a report written primarily for science teachers. It has as its focus samples of questions and student responses taken from the National Assessment of Educational Progress (NAEP) scienceassessment that was administered in 1996 to students in grades 4, 8, and 12. The assessment wasunique on two counts: first, each student who participated in the assessment was required to do ahands-on task; and second, slightly more than 60 percent of the questions were open-ended andthus required students to construct their own responses. For ease of reading, the report is dividedinto four parts. In the first part (chapter 1), an overview of the assessment is provided. Thisincludes information about the framework used in the development of the assessment, adescription of how the assessment was administered to students, and an explanation of how tointerpret NAEP results. In the second part (chapters 2, 3, and 4), examples of questions andstudents' responses are presented. These chapters are divided by grade; that is, chapters 2, 3, and4 discuss the performance, knowledge, and skills of students in grades 4, 8, and 12, respectively.The third part (chapters 5 and 6) contains information collected from students, teachers, andschool administrators about classroom practices, student motivation, and parental involvement inlearning. These chapters give teachers a snapshot of what is taking place in fourth-, eighth-, andtwelfth-grade classrooms across the United States. Finally, the fourth part contains appendicesoffering a fuller description of the procedures used for the NAEP 1996 science assessment(appendix A), scoring guides for questions discussed in chapters 2, 3, and 4 (appendix B), andstandard errors for the statistics presented in the report (appendix C).2 Student Work & Teacher Practices in ScienceIntroduction The teaching and learning of science in the nation 's schools has been a primary educational concern for the last half of this century. Although a variety of approaches and methods havebeen explored and implemented during this time, recent reform efforts demonstrate a generalconsensus on basic principles for enhancing students ' learning of science. Government agencies and professional organizations such as the National Science Board, the AmericanAssociation for the Advancement of Science, the National Science Teachers Association, andthe National Research Council have expressed agreement on several key goals for the teachingof science: \u007f\u007fStudents should acquire a core of scientific understanding, including organized factual information. \u007f\u007fStudents should acquire the ability to relate scientific concepts to each other and to problems they encounter in and out of school. \u007f\u007fStudents should be able to apply science knowledge in practical ways. \u007f\u007fStudents should be familiar with experimental design and have the ability to carry out scientific experiments that are developmentally appropriate. \u007f\u007fStudents should acquire the science knowledge and understanding that will allow them the opportunity to pursue further study in scientific fields or enter science- ortechnology-related careers. 1 As the science curriculum evolves to account for these and other important educational goals, assessing students ' achievement in science learning is essential for informing the curriculum development and policy planning that is ongoing. In 1996, NAEP conducted anational assessment of science achievement at grades 4, 8, and 12. The assessment was basedon a framework that placed particular emphasis on conceptual understanding and theapplication of knowledge and skills, as well as the factual knowledge that is fundamental forscience literacy. NAEP's Mission The National Assessment of Educational Progress (NAEP) is the only nationally representativeand continuing assessment of what students in the United States know and can do in variousacademic subjects. NAEP is authorized by Congress and directed by the National Center forEducation Statistics (NCES) of the U. S. Department of Education. The National AssessmentGoverning Board (NAGB), an independent body, provides policy guidance for NAEP . Since its inception in 1969, NAEP 's mission has been to collect, analyze, and produce valid and reliable information about the academic performance of students in the United Statesin various subject areas. In 1990, the mission of NAEP was expanded to include state-by-state 1National Assessment Governing Board. (1995). Science framework for the 1996 National Assessment of Educational Progress . W ashington, DC: Author.Student Work & Teacher Practices in Science 3results. State participation in NAEP is voluntary and grew from 40 states and territories in 1990 to 47 in the 1996 science assessment. NAEP has also become a valuable tool in trackingprogress toward the National Education Goals. The subjects assessed by NAEP are thosehighlighted at the 1989 Education Summit and in later legislation. /G50 The NAEP 1996 Science Framework The science assessment was crafted to measure the content and skills specifications described inthe science framework for the 1996 National Assessment of Educational Progress. 3 The framework was developed in 1991 through a consensus process involving educators, policymakers, representatives of the business community, assessment and curriculum experts, andmembers of the public. The project was managed by the Council of Chief State School Officers(CCSSO) under the auspices of NAGB. The NAEP science framework is based on the view that \"scientific knowledge should be organized to provide a structure that connects and creates meaning for factual information, andthis organization is influenced by the context in which the knowledge is presented. \" /G52 Moreover, \"science proficiency depends upon the ability to know and integrate facts into larger constructs and to use the tools, procedures, and reasoning processes of science for an increasedunderstanding of the natural world. \" /G53 Thus, the framework called for the NAEP 1996 science assessment to include the following: \u007f\u007fMultiple-choice questions that assess students ' knowledge of important facts and concepts and that probe their analytical reasoning skills; \u007f\u007fConstructed-response questions (questions that require students to create short or extended answers) that explore students ' abilities to explain, integrate, apply, reason about, plan, design, evaluate, and communicate science information; and \u007f\u007fHands-on tasks that probe students ' abilities to use materials to make observations, perform investigations, evaluate experimental results, and apply problem-solvingskills. The core of the science framework is organized along two dimensions. The first dimension divides science into three major fields: earth, physical, and life. The seconddimension defines characteristic ways of knowing and doing science: conceptual understanding,scientific investigation, and practical reasoning. Each question in the assessment is categorizedas measuring one of the ways of knowing and doing science within one of the fields of science(e.g., scientific investigation in the context of earth science). Brief descriptions of the threemajor fields of science and the three ways of knowing and doing science are contained infigures 1.1 and 1.2. 2Executive Office of the President. (1990). National goals for education. W ashington, DC: Government Printing Office. Goals 2000: 1804, 103rd Cong., 2nd Sess. (1994). 3National Assessment Governing Board. (1995). Science framework for the 1996 National Assessment of Educational Progress , p.31. W ashington, DC: Author. 4Ibid. 5Ibid.4 Student Work & Teacher Practices in ScienceDescriptions of the Three Fields of Science Earth Science The earth science content assessment centers on objects and events that are relatively accessible or visible. The concepts and topics covered are solid Earth (lithosphere), water (hydrosphere), air (atmosphere), and Earth in space. The topics under \"solidEarth\" consist of: composition; forces that alter its surface; the formation, characteristics, and uses of rocks; the changes and uses of soil; natural resources used by humankind; and natural forces within Earth (not at grade 4). Concepts andtopics related to water include the water cycle; the nature of oceans and their effects; and the location of water, its distribution and characteristics. The topic \"air\" is broken down into composition and structure of the atmosphere (including energytransfer); the nature of weather; climate (not at grade 4) and interactions of human society with atmosphere. \"Earth in space\" consists of: the setting of Earth in the solar system; the setting and evolution of the solar system in the universe (not at grade 4);tools and technology that are used to gather information about space; apparent daily motions of the Sun, the Moon, the planets, and the stars; rotation of Earth about its axis, and Earth's revolution around the Sun; the tilt of Earth's axis that producesseasonal variations in the climate; and Earth history. Physical Science The physical science component addresses basic knowledge and understanding of the structure of the universe as well as of the physical principles that operate within it. The major sub-topics probed are: matter and its transformations, energy and its transformations, and motion. \"Matter and its transformations\" are described bydiversity of materials (classification and types and the particulate nature of matter); temperature and states of matter; properties and uses of material (modifying properties, synthesis of materials with new properties); and resource management(not at grades 4 and 8). \"Energy and its transformations\" involve different forms of energy; energy transformations in living systems, natural physical systems, and artificial systems constructed by humans; and energy sources and use, includingdistribution, energy conversion, and energy costs and depletion. \"Motion\" is broken down into an understanding of frames of reference; force and changes in position and motion; action and reaction (not at grade 4); vibrations and waves as motion;general wave behavior (not at grades 4 and 8); electromagnetic radiation; and the interactions of electromagnetic radiation with matter. Life Science The fundamental goal of life science is to attempt to understand and explain the nature and function of living things. The major concepts assessed in life science are change and evolution, cells and their functions (not at grade 4), organisms, andecology. \"Change and evolution\" includes: diversity of life on Earth; genetic variation within a species; theories of adaptation and natural selection; and changes in diversity over time (not at grades 4 and 8). \"Cells and their functions\" consists ofinformation transfer; energy transfer for the construction of proteins; and communication among cells. \"Organisms\" are described by reproduction, growth and development; life cycles; and functions and interactions of systems withinorganisms.The topic of \"ecology\" centers on the interdependence of life\u2014 populations, communities, and ecosystems. FIGURE 1.1 SOURCE: National Assessment Governing Board, Science Framework for the 1996 National Assessment of Educational Progress, 1995.Student Work & Teacher Practices in Science 5The framework also presents two overarching domains that describe science: the nature of science and the organizing themes of science (see figure 1.3). The nature of science encompasses the historical development of science and technology, the habits of mind thatcharacterize science, and the methods of scientific inquiry and problem solving. It also includesthe nature of technology \u2014 specifically, design issues involving the application of science to real-world problems and associated trade-offs or compromises. The themes of science include the notion of systems and their application in the scientific disciplines, models and theirfunctioning in the development of scientific understanding, and patterns of change as they areexemplified in natural phenomena.Descriptions of Knowing and Doing Science FIGURE 1.2 Conceptual Understanding Conceptual understanding includes the body of scientific knowledge that students draw upon when conducting a scientific investigation or engaging in practical reasoning. Essential scientific concepts involve a variety of information, including:facts and events the student learns from both science instruction and experiences with the natural environment; and scientific concepts, principles, laws, and theories that scientists use to explain and predict observations of the natural world. Scientific Investigation Scientific investigation probes students ' abilities to use the tools of science, including both cognitive and laboratory tools. Students should be able to acquire newinformation, plan appropriate investigations, use a variety of scientific tools, and communicate the results of their investigations. Practical Reasoning Practical reasoning probes students ' abilities to use and apply science understanding in new, real-world applications. SOURCE: National Assessment Governing Board. Science Framework for the 1996 National Assessment of Educational Progress. 1995.6 Student Work & Teacher Practices in ScienceDescription of Overarching Domains The Nature of Science The nature of science incorporates the historical development of science and technology, the habits of mind that characterize these fields, and methods of inquiry and problem-solving. It also encompasses the nature of technology, including issuesof design, application of science to real-world problems, and trade-offs or compromises that need to be made. Themes Themes are the \"big ideas \" of science that transcend the various scientific disciplines and enable students to consider problems with gl obal implications. The NAEP science assessment focuses on three themes: systems, models, and patterns of change. \u007fSystems are complete, predictable cycles, structures, or processes occurring in natural phenomena. Students should understand that a system is an artificial construction created to represent or explain a natural occurrence. Students should be able to identify and define the system boundaries, identify the components and their interrelationships, and note the inputs and outputs of the system. \u007fModels of objects and events in nature are ways to understand complex or abstract phenomena. As such, they have limits and involve simplifying assumptions, but also possess generalizability and often predictive power. Students need to be able to distinguish the idealized model from the phenomenonitself and to understand the limitations and simplified assumptions that underlie scientific models. \u007fPatterns of change involve students ' recognition of patterns of similarity and differences, and their ability to recognize how these patterns change over time. In addition, students should have a store of common types of patterns and be able to transfer their understanding of a familiar pattern of change to a new andunfamiliar one. FIGURE 1.3 The percentage of assessment time devoted to each field of science and each way of knowing and doing science was clearly specified by the framework.6 Table 1.1 shows the distribution of estimated assessment time by field of science . At grades 4 and 12, the distribution of content across the three fields of science is approximately equal. For grade 8, theframework placed a somewhat heavier emphasis on life science (40 percent), with the remainingassessment time evenly divided between earth science and physical science. The distribution atgrade 8 \"reflects the importance for this age group of human biology, which is increasingly recognized both in curriculum and instruction. \" 7 6National Assessment Governing Board. (1995). Science framework for the 1996 National Assessment of Educational Progress .W ashington, DC: Author. 7Ibid.SOURCE: National Assessment Governing Board. Science Framework for the 1996 National Assessment of Educational Progress . 1995.Student Work & Teacher Practices in Science 7 Distribution of Estimated Assessment Time by Field of ScienceTABLE 1.1 SOURCE: National Assessment Governing Board. Science Framework for the 1996 National Assessment of Educational Progress. 1995.Earth 4 Grade 8 Grade 12 Table 1.2 shows the distribution of estimated assessment time by ways of knowing and doing science. At each grade level, approximately 45 percent of assessment time is devoted tothe measurement of conceptual understanding. Scientific investigation is more heavilyemphasized at grade 4 than at grades 8 and 12. This was thought desirable by the authors of theframework \"because learning by doing plays a crucial role for younger students, and ways of knowing in science need to be introduced early. \" 8 The proportion of assessment time spent on the measurement of practical reasoning is lowest at grade 4 \"because of developmental considerations and lack of opportunities at early ages. \"9 8National Assessment Governing Board. (1995). Science framework for the 1996 National Assessment of Educational Progress . Washington, DC: Author. 9Ibid. Distribution of Estimated Assessment Time by Ways of Knowing and Doing ScienceTABLE 1.2 SOURCE: National Assessment Governing Board. Science Framework for the 1996 National Assessment of Educational Progress. 1995.Conceptual Understanding 45% 45% 26% 28%Grade 4 Grade 8 Grade 128 Student Work & Teacher Practices in ScienceThe NAEP 1996 science assessment was made up of three types of questions: multiple choice, short constructed response, and extended constructed response. For the purposes of testconstruction, it was assumed that each multiple-choice question would take approximately oneminute to complete, each short constructed-response question would take approximately twominutes to complete, and each extended constructed-response question would takeapproximately five minutes to complete. Short constructed-response questions required a fewwords or a sentence or two for an answer (e.g., briefly stating how nutrients move from thedigestive system to the tissues). Extended constructed-response questions generally required aparagraph or more (e.g., outlining an experiment to test the effect of increasing the amount ofavailable food on the rate of increase of a Hydra population). Some extended constructed-response questions also required diagrams, graphs, or calculations. Table 1.3 shows how manyquestions of each type were administered at grades 4, 8, and 12. For example, at grade 4, 51 ofthe questions administered were multiple-choice, 73 were short constructed-response, and 17were extended constructed-response. Thus, 36 percent of the total number of questionsadministered at grade 4 were multiple choice. In addition, the table shows how many overlapquestions were administered. An overlap question is one administered to students at twogrades, either grades 4 and 8 or grades 8 and 12. For example, 9 multiple-choice, 16 shortconstructed-response, and 4 extended constructed-response questions were administered tostudents at grades 4 and 8. This \"double \" utilization of questions was done to ensure that there were enough questions to measure the higher-ability students at the lower grade levels and thelower-ability students at the higher grade levels. Table 1.3 also shows the percentages of timedevoted to each question type for the assessment as a whole. Approximately 20 percent ofstudents ' time was spent answering multiple-choice questions and approximately 80 percent answering short and extended constructed-response questions.Student Work & Teacher Practices in Science 9Number of Questions, Percent of Questions, and Percent of Questions by Time, by Grade Level and Type TABLE 1.3 Grade 4 Grade 8 Grade 12 MC1SCR2ECR3MC SCR ECR MC SCR ECR Grade 4 Only 42 57 13 Grades 4 and 8 Overlap 9 16 4 9 16 4 Grade 8 Only 44 58 12 Grades 8 and 12 Overlap 21 26 3 21 26 3 Grade 12 Only 49 63 28 TOTAL Number of Questions by Grade 51 73 17 74 100 20 70 89 31 TOTAL Percent of Questions by questions 3 Extended constructed-response questions NOTE: Numbers may not add to 100 due to rounding.SOURCE: National Assessment Governing Board, National Assessment of Educational Progress, 1996 Science Assessment,1996.TOTAL Percent Teacher Practices in ScienceThe Assessment Design At each of grades 4, 8, and 12, there were 15 different sections or \"blocks \" of science questions, usually consisting of both multiple-choice and constructed-response questions.These questions assessed ways of knowing and doing science in the context of earth, physical,and life science. Hands-on tasks comprised 4 of the 15 blocks at each grade level. In thesetasks, students were given sets of equipment and asked to conduct an investigation and answerquestions related to the investigation. For example, students in grade 12 were given a mixtureof five substances and asked to separate them. Three of the 15 blocks assessed themes. One of these blocks addressed systems, a second addressed models, and a third addressed patterns of change. For example, students atgrade 8 were shown a simplified model of part of the solar system, with a brief description, andwere then asked a number of questions based on this information. Each student in the assessment received a booklet that contained 3 of the 15 blocks of science questions. One of these blocks was always a hands-on task. At the fourth-grade level,students were allowed 20 minutes to complete each block of questions. At the eighth- andtwelfth-grade levels, students were allowed 30 minutes to complete each block. Theme blockswere placed randomly in the student booklets. Not every booklet contained a theme block, butno booklet contained more than one theme block. In addition to answering science questions, students also answered questions about their general backgrounds, their science experiences, and their motivation. Further informationregarding the assessment design and background questionnaires can be found in theforthcoming NAEP 1996 Technical Report . 10 It should be noted that not every student in grades 4, 8, and 12 took the assessment. However, since the assessment was administered to nationally representative samples, theresults can be extrapolated to all fourth-, eighth- and twelfth-grade students in the UnitedStates. Appendix A gives an overview of the sampling process. 10Allen, N. L., Carlson, J., & Zelenak, C.A. (in press) The NAEP 1996 technical report . W ashington, DC: National Center for Education Statistics.Student Work & Teacher Practices in Science 11Reporting NAEP Results The NAEP Science Scale The NAEP 1996 science assessment spanned the broad field of science in each of the grades assessed. Because of the survey nature of the assessment and the breadth of the domain, eachstudent participating could not be expected to answer all the questions in the assessmentwithout imposing an unreasonable burden on students and their schools. Instead, each studentwas administered a portion of the assessment, and data were combined across students to reporton the achievement of fourth, eighth, and twelfth graders and on the achievement of subgroupsof students (e.g., subgroups defined by demographics such as gender or race/ethnicity). Student responses to the assessment questions were analyzed to determine the percentages of students responding correctly to each multiple-choice question and thepercentages of students achieving each of the score categories for constructed-responsequestions. A series of scales was then created to summarize student performance. The samemethodology was used at each grade level. First, scales were created to correspond to earthscience, physical science, and life science. Then, a composite scale was created, using aweighted average of the three fields of science scales. These weighted averages wereproportional to the relative importance assigned to each field of science as specified by theframework. For example, at the eighth-grade level, a greater proportion of time was spent onquestions measuring life science (40 percent) than on questions measuring earth science orphysical science (30 percent each), and thus life science received a heavier weighting in thecomposite scale. Unless otherwise indicated, scale score results presented in this report arebased on this overall composite scale. The composite scale at each grade ranges from 0 to 300, with a mean of 150 and a standard deviation of 35. While the scale-score ranges are identical, the scale was derivedindependently at each grade. Also, scales were weighted differently at different grades indetermining the overall scale. Therefore, average scale scores across grades cannot becompared. For example, equal scale scores on the grade 4 and grade 8 scales do not implyequal levels of science achievement. (Additional details of the scaling procedures can be foundin appendix A of this report and in the forthcoming NAEP 1996 Technical Report . 11) 11Allen, N. L., Carlson, J., & Zelenak, C.A. (in press) The NAEP 1996 technical report . W ashington, DC: National Center for Education Statistics.12 Student Work & Teacher Practices in ScienceAverage Question Score Average question score represents a different way to look at student performance than the scale scores customarily used in NAEP. For multiple-choice questions and constructed-responsequestions that are scored on a two-part scale (right or wrong), the question score is thepercentage of students answering each question of this type correctly. For questions that arescored on either a three-level or a four-level scale, the question score represents the average ofall student scores on that question, expressed as a percentage of the maximum possible score.For example, on a question using a three-level scoring guide, scores of Complete , Partial , and Unsatisfactory are converted to 1, 0.5, and 0, respectively. These converted scores are then multiplied by the percentage of students receiving each score and the sum found. In otherwords, if 10 percent of students received a score of Unsatisfactory (i.e., 0), 30 percent received a score of Partial (i.e., 0.5), and 60 percent received a score of Complete (i.e., 1), the question score would be ([0 x 0.1] + [0.5 x 0.3] + [1 x 0.6]) = 0.75. The average question score is foundby combining the question scores over the full set of questions within an area of interest (suchas life science or conceptual understanding) and dividing by the number of questions in thatarea. For example, the average question score for the 47 life science questions administered atgrade 4 is 0.44 out of a possible 1. Average question scores are used in chapters 2, 3, and 4 todiscuss student performance in each of the fields of science and ways of knowing and doingscience. 12 Achievement Levels for Student Performance Since 1988, NAGB has been required by law to set performance standards, called \"achievement levels, \" for NAEP. The achievement levels are developmental, and as such are continually under review. Table 1.4 presents the policy definitions of the three NAEPachievement levels \u2014 Basic , Proficient , and Advanced \u2014 that apply across grades and subject areas . The levels are cumulative; that is, students performing at the Proficient level should have all the knowledge and skills of students at the Basic level, and students performing at the Advanced level should have all the knowledge and skills of students performing at the Proficient level. Additional information about achievement levels can be found in the report, 1996 Science Performance Standards: Achievement Results for the Nation and the States . /G49/G51 12To make valid inferences from the student samples to the respective populations from which they were drawn, sampling weights were used in the analysis. 13Bourque, M. L., Champagne, A. B., & Crissman, S. (1997). 1996 science performance standards: Achievement results for the nation and the states. W ashington, DC: National Assessment Governing Board.Student Work & Teacher Practices in Science 13Policy Definitions of NAEP Achievement Levels TABLE 1.4 Advanced Superior performance. Proficient Solid academic performance for each grade assessed. Students reaching this level have demonstrated competency over challenging subject matter, including subject- matter knowledge, application of such knowledge to realworld situations, andanalytical skills appropriate to the subject matter. Basic Partial mastery of prerequisite knowledge and skills that are fundamental for proficient work at each grade. The science achievement levels consist of specific content descriptions of what students know and can do at the three levels. Cut scores on the 0-to-300 NAEP science scale define thethree achievement levels. The content descriptions were developed by a broadly representativegroup of scientists and science educators and were based on student achievement on theassessment questions. A summary of the science achievement level descriptions and thecorresponding cut scores is found in figure 1.4.14 Student Work & Teacher Practices in ScienceBASIC Students performing at the Basic level demonstrate some of the knowledge and reasoning required for under- 138 standing of the earth, physical, and life sciences at a level appropriate to Grade 4. For example, they can carry out simple investigations and read uncomplicated graphs and diagrams. Students at this level also show abeginning understanding of classification, simple relationships, and energy. PROFICIENT Students performing at the Proficient level demonstrate the knowledge and reasoning required for under- 170 standing of the earth, physical, and life sciences at a level appropriate to Grade 4. For example, they understand concepts relating to the Earth 's features, physical pr operties, and structure and function. In addition, students can formulate solutions to familiar problems as well as show a beginning awareness of issues associated withtechnology. ADVANCED Students performing at the Advanced level demonstrate a solid understanding of the earth, physical, and life 204 sciences as well as the ability to apply their understanding to practical situations at a level appropriate to Grade 4. For example, they can perform and critique simple investigations, make connections from one or more of thesciences to predict or conclude, and apply fundamental concepts to practical applications. BASIC Students performing at the Basic level demonstrate some of the knowledge and reasoning required for under- 143 standing of the earth, physical, and life sciences at a level appropriate to Grade 8. For example, they can carry out investigations and obtain information from graphs, diagrams, and tables. In addition, they demonstratesome understanding of concepts relating to the solar system and relative motion. Students at this level also havea beginning understanding of cause-and-effect relationships. PROFICIENT Students performing at the Proficient level demonstrate much of the knowledge and many of the reasoning 170 abilities essential for understanding of the earth, physical, and life sciences at a level appropriate to Grade 8. For example, students can interpret graphic information, design simple investigations, and explain such scientificconcepts as energy transfer. Students at this level also show an awareness of environmental issues, especiallythose addressing energy and pollution. ADVANCED Students performing at the Advanced level demonstrate a solid understanding of the earth, physical, and life 207 sciences as well as the abilities required to apply their understanding in practical situations at a level appropriate to Grade 8. For example, students perform and critique the design of investigations, relate scientific concepts toeach other, explain their reasoning, and discuss the impact of human activities on the environment. BASIC Students performing at the Basic level demonstrate some knowledge and certain reasoning abilities required 145 for understanding of the earth, physical, and life sciences at a level appropriate to Grade 12. In addition, they demonstrate knowledge of the themes of science (models, systems, patterns of change) required for understandingthe most basic relationships among the earth, physical, and life sciences. They are able to conduct investigations,critique the design of investigations, and demonstrate a rudimentary understanding of scientific principles. PROFICIENT Students performing at the Proficient level demonstrate the knowledge and reasoning abilities required for 178 understanding of the earth, physical, and life sciences at a level appropriate to Grade 12. In addition, they demonstrate knowledge of the themes of science (models, systems, patterns of change) required for understandinghow these themes illustrate essential relationships among the earth, physical, and life sciences. They are able toanalyze data and apply scientific principles to everyday situations. ADVANCED Students performing at the Advanced level demonstrate the knowledge and reasoning abilities required for 210 a solid understanding of the earth, physical, and life sciences at a level appropriate to Grade 12. In addition, they demonstrate knowledge of the themes of science (models, systems, pattern of change) required for integratingknowledge and understanding of scientific principles from the earth, physical, and life sciences. Students candesign investigations that answer questions about real-world situations and use their reasoning abilities to makepredictions.Grade 4Cut Score Content Descriptions Summary of the 1996 NAEP Science Achievement Level DescriptionsFIGURE 1.4 SOURCE: National Assessment Governing Board, National Assessment of Educational Progress, 1996 Science Assessment. 1996.Grade 12Grade 8Student Work & Teacher Practices in Science 15Table 1.5 shows the percentages of students within each science achievement level at grades 4, 8, and 12, as well as the percentages of students below the Basic achievement level. At grades 4, 8, and 12, three percent of students performed at the Advanced level for that specific grade. Twenty-six percent of students at grades 4 and 8 were at the Proficient level, whereas 18 percent of grade 12 students were at the Proficient level. At least one-third of students at each grade performed below the Basic level. A complete description of the achievement levels can be found in appendix A. In this report, information pertaining to achievement levels is included with the sample studentresponses in chapters 2, 3, and 4. The percentages of students performing at or above theProficient level are also presented in the tables in chapters 4 and 5, together with scale scores. Percentages of Students Within Each Science Achievement Level for the NationTABLE 1.5 Below Basic Basic Proficient Advanced SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. Grade 4 33 38 26 3 Grade 12 43 36 18 3 Grade 8 39 32 26 316 Student Work & Teacher Practices in ScienceItem Maps Another way to illustrate the range of performance on the NAEP science scale is to map questions from the assessment onto the 0-to-300 scale at each grade level. The resulting item maps are visual representationsthat compare questions with ability. More specifically, they indicate which questions a student at a givenperformance level on the NAEP scale is likely to answer correctly. 14 Figures 1.5 through 1.7 show item maps for grades 4, 8, and 12, respectively. The illustrative questions shown in these maps are the same asthose discussed in chapters 2, 3, and 4 of this report. Multiple-choice questions are denoted by (mc), andeach constructed-response question by its score value in parentheses after the short description of thequestion. 15 All multiple-choice questions in this assessment had four options. The following examples will help in interpreting these maps. In figure 1.5, which shows the mapping of assessment questions for grade 4, a four-option, multiple-choice question about reading thelevel of a liquid in a graduated cylinder maps at the 129 point on the scale. This means that fourth-gradestudents with science scale scores at or above 129 have at least a 74-percent chance of answering thisquestion correctly. 16 Put slightly differently, this question is answered correctly by at least 74 of every 100 students scoring at or above the 129 scale-score level. This does not mean that students at or above the129 scale score always answer the question correctly or that students below the 129 scale score alwaysanswer it incorrectly. Rather, the percentage of students who can successfully answer the questiondepends on their overall ability as measured on the NAEP science scale. As another example, consider theconstructed-response question that maps at a scale score of 252 on the grade 4 composite science scale.This question asks what forces impact Earth 's surface and how they impact it. Scoring of responses to this question allows for partial credit by using a four-level scoring guide. Mapping the question at the 252scale score indicates that at least 65 percent of the students performing at or above this point achieved ascore of 4 ( Complete ) on the question. 14Details on the procedures used to develop the item maps will be provided in the forthcoming NAEP 1996 Technical Report . The procedures are similar to those used in past NAEP assessments. 15The placement of constructed-response questions is based on the mapping of 2 ( Complete ) on a 2-point scoring guide for short constructed-response questions scored as right or wrong, 3 ( Complete ) on a 3-point scoring guide for short constructed-response questions, and 4 ( Complete ) on a 4-point scoring guide for extended constructed-response questions. 16For constructed-response questions, a criterion of 65 percent was used. For multiple-choice questions, the criterion was 74 per cent. The use of a higher criterion for multiple-choice questions reflected students ' ability to \"guess \" the correct answer from among the alternatives.Student Work & Teacher Practices in Science 170 \u2014 0 \u2014\u2014300\u2014NAEP Scale NOTE: Each grade 4 science question was mapped onto the NAEP 0-to-300 science scale. The position of the question on the scale represents the scale score attained by students who had a 65-percent probability of reaching a given score level on a constructed-response question or a 74-percent probability of corr ectly answering a 4-option multiple-choice question. Only selected questions are presented. Achievement level cut points are referenced on the map. NOTE: \"mc\" indicates a multiple-choice question.NOTE: The number in parentheses indicates the score level.297/H17076Know plant parts and explain their function (4) 239/H17076Infer why it is easier to float in salt water than fresh water (3) 226/H17076Compare life cycles (2) 209/H17076Identify mystery water (3) 185/H17076Identify pattern of ripples (mc) 171/H17076Draw and label pupa (3) 158/H17076Understand what makes the moon visible from Earth (mc) 129/H17076 Read liquid level in graduated cylinder (mc) 114/H17076 Recognize cause of radio malfunction (mc)\u2014204\u2014 (Advanced) \u2014170\u2014 (Proficient) \u2014138\u2014 (Basic)Know forces that impact Earth's surface and explain impact (4) /H17075 252 Infer properties of metals (3) /H17075 235 Evaluate appropriateness of experiment involving beetles (2) /H17075 222 Recognize causes of smog in U.S. (mc) /H17075 196 Understand impact on life cycle if larva eaten (mc) /H17075 177 Recognize major source of gasoline (mc) /H17075 170 Know that water covers most of Earth's surface (mc) /H17075 137 Recognize graph that corresponds to data (mc) /H17075 117 FIGURE 1.5Map of Selected Questions on the NAEP Science Scale for Grade 418 Student Work & Teacher Practices in Science 0 \u2014 0 \u2014\u2014300\u2014NAEP Scale NOTE: Each grade 8 science question was mapped onto the NAEP 0-to-300 science scale. The position of the question on the scale represents the scale score attained by students who had a 65-percent probability of reaching a given score level on a constructed-response question or a 74-percent probability of correctly answering a 4-option multiple-choice question. Only selected questions are presented. Achievement level cut points are referenced on the map. NOTE: \"mc\" indicates a multiple-choice question. NOTE: * The characteristics of this item do not meet the mapping criteria at this value. However, in order for it to meet the c riteria, the item would have to be assigned a value beyond the valid range of scores. NOTE: The number in parentheses indicates the score level.FIGURE 1.6Map of Selected Questions on the NAEP Science Scale for Grade 8 * Know function of mitochondrion (mc) /H17075 300 Explain cause and prevention of food poisoning (3) /H17075 265 Devise an experiment using hydra given a hypothesis (3) /H17075 242 Explain how to account for seasons in model (3) /H17075 238 Infer coldest day from graph (mc) /H17075 206 Explain which bulb uses least electricity (3) /H17075 202 Measure height of pencil above solution (2) /H17075 182 Understand where earthquakes occur (mc) /H17075 172 Classify organism from characteristics (mc) /H17075 153288/H17076Explain inheritance of hair color (3) 257/H17076Predict heating rates from data (4) 239/H17076Recognize how insulated bottle works 230/H17076Complete life cycles of grasshopper and butterfly (4) 226/H17076Explain difference between window and mirror (2) 204/H17076Interpolate concentration of salt solution from graph (4) 191/H17076Draw graph (4) 174/H17076Recognize nonrenewable resource (mc) \u2014170\u2014 (Proficient) \u2014143\u2014 (Basic)Student Work & Teacher Practices in Science 19 0 \u2014 0 \u2014\u2014300\u2014NAEP Scale NOTE: Each grade 12 science question was mapped onto the NAEP 0-to-300 science scale. The position of the question on the scale represents the scale score attained by students who had a 65-percent probability of reaching a given score level on a constructed-response question or a 74-percent probability of correctly answering a 4-option multiple-choice question. Only selected questions are presented. Achievement level cut points are referenced on the map. NOTE: \"mc\" indicates a multiple-choice question.FIGURE 1.7Map of Selected Questions on the NAEP Science Scale for Grade 12 Explain how to keep ice cream below 0\u00b0C (3) /H17075 294 Predict genotype (4) /H17075 283 Explain cause of malaria (3) /H17075 279 Explain cloud formation (3) /H17075 227 Devise test to identify salt water (4) /H17075 190 Determine greatest mass from graph (mc) /H17075 174 Recognize relationship between evaporation and temperature (mc) /H17075 157 Recognize eclipse progression (mc) /H17075 125285/H17076Explain activity at ring of fire (4) 282/H17076Know properties of materials given separation equipment (4) 230/H17076Recognize accuracy of conclusion based on table (mc) 207/H17076Explain why soil should be tested after a flood (3) 189/H17076Recognize path of car on ice (mc) 172/H17076Explain how to reduce risk of heart disease (3) 160/H17076Describe separation of materials (4) 142/H17076Separation of materials (3)\u2014210\u2014 (Advanced) \u2014178\u2014 (Proficient) \u2014145\u2014 (Basic) NOTE: The number in parentheses indicates the score level.20 Student Work & Teacher Practices in ScienceThe results presented in this report are estimates because they are based on samples rather than on the entire population. As such, the results are subject to a measure of uncertainty thatis reflected in the standard errors of the estimates. Standard errors provide a measure of howmuch survey results could vary if a different but equally valid sample of students were chosen.The standard errors are presented in appendix C. 17 In this report, comparisons among question types or between subgroups of students are based on statistical tests that consider both the magnitude of the differences between theaverage percentages and their standard errors. Throughout the report, differences are discussedonly when they are significant from a statistical perspective. This means that observeddifferences are unlikely to be due to chance factors associated with sampling variability. Alldifferences are significant to the 0.05 level with appropriate adjustments made for multiplecomparisons. The term \"significant, \" therefore, is not necessarily intended to imply judgment about the absolute magnitude or educational relevance of the differences. Cautions in Interpretations There are several cautions that readers of this report should bear in mind as they look at thedata presented. The first caution relates to the information collected from responses to theNAEP background questions. This information was self-reported and, while the questions werewritten as unambiguously as possible, respondents ' interpretations of them may nonetheless have differed. The second caution relates to interpreting as causal the statistical relationshipsbetween student, teacher, or school variables and students ' performance. This report presents student performance data for individual background variables, and some readersunderstandably might be tempted to see the background variable as causing the level ofperformance. Readers must understand, however, that differences in science performance rarelyhave a single cause, but rather stem from multiple, interrelated educational and socioeconomicfactors. Therefore, neither the existence nor absence of statistical correlations between studentperformance and any single variable should be taken as conclusive evidence regarding a causalrelationship between the two. Conclusions about the relative effectiveness of different teachingapproaches or the impact of various technologies on student performance, for example, arelikely to be misleading if based solely on single-variable data. The final caution concerns thefact that although the data reported here are cross-sectional (based on student performance atone time), learning is cumulative. The classroom-based variables examined in this report reflectstudents ' experiences during half of the school year (because the assessment is given in January-March) and do not reflect either their experiences in three, seven, or eleven years ofprevious schooling or their experiences outside of school. 17The standard errors in this report should be interpreted in the following fashion: There is a 95-percent probability that a statistic for a population of interest is within two standard errors of the mean reported. For example, if we report that 50percent of female students answered a question correctly and the standard error is 0.5, then there is a 95-percent chancethat the actual value of the statistic for the whole population of female students falls between 49 and 51 percent.Interpreting NAEP ResultsStudent Work & Teacher Practices in Science 2118O'Sullivan, C. Y., Reese, C. M., & Mazzeo, J. (1997). NAEP 1996 science report card for the nation and the states: Findings from the National Assessment of Educational Progress (NCES Publication No. 97-499). W ashington, DC: National Center for Education Statistics. Bourque, M. L., Champagne, A. B., & Crissman, S. (1997). 1996 science performance standards: Achievement results for the nation and the states. W ashington, DC: National Assessment Governing Board. National Assessment Governing Board. (1997). What do students know? W ashington, DC: Author. O'Sullivan, C.Y., W eiss, A. R., & Askew, J. M. (1998). Students learning science: A report on policies and practices in U.S. schools. (NCES Publication No. 98-493). W ashington, DC: National Center for Education Statistics.The above considerations notwithstanding, the data presented are quite useful. They are collected from a national sample and so can be generalized to the population of students in aspecific grade. The percentage data indicate how commonly a variety of classroom practices areemployed, the extent of parental involvement in school, and the range of student attitudes andbeliefs about science. And despite the caution with which they must be approached, theperformance data linked to background variables are suggestive of what students know and cando in science in an assortment of contexts. The data also are a place from which to beginadditional investigations, in-depth research, and constructive conversations about educationalpractices and student work. It is unlikely that any other large-scale assessment design couldyield data of greater breadth or depth without a far greater investment of time and money. Additional NAEP Science Publications This report is one of a series of reports designed to provide a comprehensive account of theresults from the NAEP 1996 science assessment. Four reports are already completed: theNAEP 1996 Science Report Card for the Nation and the States , which examines and compares the science performance of groups of students defined by demographic characteristics or byresponses to background questions (e.g., males compared to females); a companion report, 1996 Science Performance Standards: Achievement Results for the Nation and the States , which presents the NAGB 's achievement levels within the context of demographic variables; What do Students Know ?, a summary of the NAEP 1996 science results; and Students Learning Science: A Report on Policies and Practices in U.S. Schools , which provides a \"snapshot \" of current teacher practices, school policies, and student achievement. 18 This report \u2014 Student Work & Teacher Practices in Science \u2014 is directed at teachers and contains examples of questions, student responses, and data relating to classroom activities. A final report will present results from a special study conducted in conjunction with the main NAEP 1996 science assessment that assessed students with advanced training inscience. In addition, that final report will present a second study that identifies and describesthe cognitive processes required to answer each question administered in the NAEP 1996science assessment. It should be noted that the NAEP 1996 science assessment provided a wealth of information, not all of which appears in reports. However, data from the assessment (referred toas Summary Data Tables) are available on the World Wide Web and can be accessed throughhttp://nces.ed.gov/naep. NAGB reports and assessment frameworks can be found through http://www.nagb.org.22 Student Work & Teacher Practices in Science19Allen, N. L., Swinton, S. .S., Isham, S. P ., & Zelenak, C. A. (1997). Technical report of the NAEP 1996 state assessment program in science (NCES Publication No. 98-480). W ashington, DC: National Center for Education Statistics. Allen, N. L., Carlson, J., & Zelenak, C. A. (in press) The NAEP 1996 technical report . W ashington, DC: National Center for Education Statistics.Overview of Remaining Chapters Chapters 2, 3, and 4 of this report present analyses of student performance in three fields of science and three ways of knowing and doing science. In addition, chapters 2, 3, and 4 containexamples of questions and students ' responses for grades 4, 8, and 12, respectively. Although students generally took sets of questions that covered all three fields of science, the questionsdiscussed in these chapters are grouped into the three ways of knowing and doing science \u2014 conceptual understanding, scientific investigation, and practical reasoning. The two exceptionsto this grouping relate to questions taken from the theme blocks and hands-on tasks. Thesequestions are discussed separately. Two tables appear with each sample question in chapters 2,3, and 4. These tables differ depending on whether the question is multiple-choice orconstructed-response. For multiple-choice questions, the first table shows the percentage ofstudents choosing each response option and the second table shows the percentage of studentswithin each achievement level interval choosing the correct option. For constructed-responsequestions, the first table presents the percentage of students in each score category. The secondtable displays the percentage of students within each achievement-level interval that received ascore of Complete in the case of short constructed-response questions and Complete or Essential in the case of extended constructed-response questions. Chapters 5 and 6 contain information collected from students, teachers, and school administrators about classroom practices, student motivation, and parental involvement inlearning. The averages and percentages presented in these chapters are estimates because theyare based on samples rather than on all members of each population. Finally, this report contains appendices that support or augment the results presented. Appendix A contains a detailed description of the science achievement levels, information onnational samples, and information pertaining to the background questionnaires. Appendix Bpresents scoring guides for questions discussed in chapters 2, 3, and 4. Appendix C containsthe standard errors for the statistics presented in this report. Detailed information about themeasurement methodology and data analysis techniques used in this report is available in thetwo NAEP technical reports. 19Chapter 2 Student Work & Teacher Practices in Science 23Grade 4: Performance, Knowledge, and Skills Introduction There are many questions about science learning that are of interest to educators. For example, how much class time is spent on earth science, physical science, and life science? Do male andfemale students perform differently on different types of science questions? How do studentsperform on multiple-choice and constructed-response questions? Data collected during theNAEP 1996 science assessment have been analyzed and provide some answers to these kindsof questions. This chapter discusses the results. The grade 4 assessment was constructed according to specifications outlined in the Science Framework for the 1996 National Assessment of Educational Progress . 1 The specifications stated that, at the fourth-grade level, the distribution of assessment time acrossthe three science fields should be approximately equal. In addition, 45 percent of assessmenttime should be directed toward conceptual understanding, 45 percent toward scientific investigation, and 10 percent toward practical reasoning. (A description of the fields of science and the ways of knowing and doing science is presented in chapter 1, and figures 1.1 and 1.2).Each question in the science assessment was classified as measuring one of the ways ofknowing and doing science within one of the fields of science (for example, scientificinvestigation in the context of life science). Table 2.1 shows the number of multiple-choice, short constructed-response, and extended constructed-response questions in each of the major fields of science and ways ofknowing and doing science. The total number of each question type is also shown. There were51 multiple-choice questions and 94 constructed-response questions in the grade 4 assessment.Each constructed-response question had its own unique scoring guide that defined the criteriaused to evaluate students ' responses. 2 Short constructed-response questions were usually scored 1National Assessment Governing Board. (1995). Science framework for the 1996 National Assessment of Educational Progress. W ashington, DC: Author. 2Appendix B contains scoring guides for the sample questions that appear in this report.24 Student Work & Teacher Practices in Scienceaccording to three levels of performance: Complete , Partial , or Unsatisfactory ; however, some of them were scored as either right or wrong ( Complete or Unsatisfactory ). Extended constructed- response questions were usually scored according to four levels: Complete , Essential , Partial , or Unsatisfactory . In a few instances, however, five- and six-level scoring guides were used. In total, 275,339 student responses were scored; this number included the 25 percent of studentresponses that were scored twice to monitor the reliability of the scoring process. 3 (See appendix A for a more complete description of the scoring process.) Distribution of Questions by Fields of Science and by Ways of Knowing and Doing Science, Grade 4: Public and Nonpublic Schools CombinedTABLE 2.1 Short Constructed- Extended Constructed- Multiple-Choice Response Response Total Fields of Science Earth Science 22 27 4 53 Life Science 16 25 6 47 Physical Science 13 26 6 45 Total 51 78 16 145 Knowing and Doing Conceptual Understanding 36 36 9 81 Scientific Investigation 9 23 5 37 Practical Reasoning 6 19 2 27 Total 51 78 16 145 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. 3For grade 4, the percentage agreement for the 1996 reliability sample was 94. This means that the scores given by first and second scorers agreed 94 percent of the time.Student Work & Teacher Practices in Science 25Teachers ' Reports on How Much Time They Spent Teaching Life Science, Earth Science, and Physical Science, Grade 4: Public and Nonpublic Schools CombinedTABLE 2.2 Average Scale Score Percentages Percentages Composite Life Earth Physical At or Above of Students (all fields) Science Science Science ProficientIn this class, about how much time do you spend on each of the following areas in science? Life Science A Lot 28 150 151 150 150 29 Some 65 151 151 151 152 31 Little 6 150 151 151 150 26 None 1 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 Earth Science A Lot 19 151 152 151 151 31 Some 76 151 151 150 151 29 Little 5 153 148 153 153 29 None 0 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 Physical Science A Lot 16 154 155 154 154 34 Some 73 151 151 151 151 30 Little 9 145 145 146 146 25 None 2 134 136 139 134 16 \u2014\u2014Sample size is insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Grade 4 Science Teaching Content As part of the NAEP science assessment, teachers of grade 4 students were asked to specify how much time they spent teaching life science, earth science, and physical science. Teacherswere presented with the response options \"A Lot, \" \"Some, \" \"Little, \" and \"None. \" The results are shown in table 2.2. Teachers of approximately 28, 19, and 16 percent of grade 4 students reported spending a lot of time covering life science, earth science, and physical science, respectively. It shouldbe noted that although teachers were covering each of the major fields of science, noinformation was collected on the nature of that coverage. Thus, it is not known whether studentshad the opportunity to learn the material that was assessed on the NAEP survey. The amount ofexposure to the three fields of science did not have an impact on the average scale scores ofstudents or on the percentage of students that attained the Proficient level. No statistical differences were found. In addition, the amount of exposure to the different fields of sciencewas not associated with differences in scale scores of students in the different fields. Forexample, students whose teachers reported that they spent little time on life science performedas well on life science questions as did students whose teachers reported that they spent a lot oftime on life science.26 Student Work & Teacher Practices in Science4See chapter 1 for a more complete description of the analysis.Average Question Score Table 2.3 shows the average question score of earth science, physical science, and life science questions for all students, male and female students, and White, Black, and Hispanic students.For all students the average question score for questions measuring earth science was 0.40. Forquestions measuring physical science and life science, the average question scores were thesame, 0.44. 4 Readers are cautioned not to make comparisons among the fields of science for any group of students. V ariations may have been due, for example, to the particular make-up of theset of questions administered and could have differed if students were administered a differentset of questions covering the same fields of science. Comparisons can be made, however, amongthe different reporting groups within each field of science. It was found that White students hada higher average question score than Black and Hispanic students for the earth science,physical science, and life science questions. In addition, male students had a higher averagequestion score than female students for the earth science questions. Average Question Score for Earth Science, Physical Science, and Life Science, Grade 4: Public and Nonpublic Schools CombinedTABLE 2.3 Earth Science Physical Science Life Science All Students NOTE: There were insufficient sample sizes for the American Indian and Asian/Pacific Islander racial/ethnic subgroups to produce reliable results. Consequently, racial/ethnic subgroup information is provided only for White (not Hispanic), Black (no t Hispanic), and Hispanic subgroups. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 27Average Question Score for Conceptual Understanding, Scientific Investigation, and Practical Reasoning, Grade 4: Public and Nonpublic Schools CombinedTABLE 2.4 Conceptual Scientific Practical Understanding Investigation Reasoning All Students 0.44 0.43 0.38 Male 0.45 0.43 0.38 Female 0.43 White 0.35 0.34 0.29 NOTE: There were insufficient sample sizes for the American Indian and Asian/ Pacific Islander racial/ethnic subgroups to produce reliable results. Consequently, racial/ethnic subgroup information is provided only for White (not Hispanic), Black(not Hispanic), and Hispanic subgroups. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Table 2.4 shows the average question score for questions classified as conceptual understanding, scientific investigation, or practical reasoning.5 For all students, the average question score was 0.44 for questions measuring conceptual understanding, 0.43 for questionsmeasuring scientific investigation, and 0.38 for questions measuring practical reasoning. Again, readers are cautioned not to compare performance among the ways of knowing and doing science, since student performance may have varied if different sets of questions hadcomprised these categories. When the data for the different reporting groups within each way ofknowing and doing science are examined, however, several differences emerge. White studentshad a higher average question score than Black and Hispanic students for questions thatmeasured conceptual understanding, scientific investigation, and practical reasoning. Inaddition, male students had a higher average question score than female students for thequestions that measured conceptual understanding. 5See chapter 1 for a more complete description of the analysis.28 Student Work & Teacher Practices in ScienceSample Questions and Student Responses A more in-depth understanding of students ' performance on the NAEP 1996 science assessment can be gained by examining individual test questions and how students responded.Table 2.5 summarizes the science questions that are discussed in this section of chapter 2.They are organized by ways of knowing and doing science and by fields of science. Since thediscussion of sample questions must be limited to those questions that have been released tothe public, no examples of scientific investigation in the context of earth science are availablefor discussion. The items that were not released to the public (approximately 73 percent of theassessment) will be reused next time NAEP administers the science assessment. This isplanned for the year 2000. Some of the questions described could be classified in more thanone field of science and more than one way of knowing and doing science. For the purposes oftest construction and analysis, however, the classification had to be limited to one field ofscience and one way of knowing and doing science. In this chapter, the questions are organized for discussion by the three ways of knowing and doing science \u2014 conceptual understanding, scientific investigation, and practical reasoning. The sample questions from the theme block and the hands-on task are discussed asa unit because this is how they were administered to the students. For example, one studentmay have been asked ten questions covering the three fields of science and the three ways ofknowing and doing science, followed by a set of questions based on a theme, followed by a setof questions based on a hands-on task. The questions relating to a theme or hands-on task areindicated in table 2.5 by \"Theme \" and \"Task. \" Two tables displaying data are included with each question. For multiple-choice questions, the first table shows the percentage of students choosing each response and thesecond table shows the percentages correct within each achievement-level interval. Forconstructed-response questions, the first table shows the percentages of students at differentscore levels and the second shows the percentages of students that received a score of Complete (or Essential or higher in the case of extended constructed-response questions) within each achievement -level interval. In this chapter, the tables showing percentages of students within each achievement-level interval do not contain data in the column labeled \"Advanced \" because the number of students classified as Advanced was too small to permit a reliable estimate. 6 6Allen, N. L., Carlson, J., & Zelenak, C. A. (in press) The NAEP 1996 Technical Report. W ashington, DC: National Center for Education Statistics.Student Work & Teacher Practices in Science 29TABLE 2.5 Earth Science Physical Science Life Science Conceptual Understanding Scientific Investigation Practical ReasoningMajor source of gasoline (mc)Earth's surface (mc) Visibility of Moon fromEarth (mc)Sources of smog Task: Mystery water (scr) Properties of life Theme: Life cycles (scr)Sample Questions Categorized by Fields of Science and by Ways of Knowing and Doing Science, Grade 4: Public and Nonpublic Schools Combined NOTE: \"mc\" indicates a multiple choice question; \"scr\" indicates a constructed-response question; and \"ecr\" indicates an extended constructed-response question.30 Student Work & Teacher Practices in ScienceConceptual Understanding7 Eighty-one questions administered to fourth graders in the NAEP 1996 science assessment measured knowledge and understanding of basic facts and concepts across the three fields ofscience: earth, physical, and life. A selection of these questions follows. Major Source of Gasoline The multiple-choice question shown below measures students ' knowledge of a \"resource from Earth used by humankind. \" and is classified under the earth science topic \"Solid Earth. \" In the question, students were told that cars and other machines use gasoline as an energy source andwere then asked to recognize what substance gasoline is made from and where it is found. 2. Cars and many other machines use gasoline as an energy source. What is the major source of gasoline? AWater from the Earth's oceans BWood from large trees CGases in the atmosphere DOil from beneath the Earth's surface The correct option is D. 7See figure 1.2 for a description of conceptual understanding.Student Work & Teacher Practices in Science 31 TABLE 2.7Percentages Correct within Each Achievement Level Interval: Grade 4 Major Source of Gasoline Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 45 66 82 - - - - Sample size insufficient to permit a reliable estimate.The percentages of students within each of the achievement level intervals who successfully answered the question are shown in table 2.7. Sixty-six percent of students at theBasic level and 82 percent at the Proficient level answered the question correctly. Nearly half the students classified as below Basic knew the source of gasoline and where it was found.Response Options A B C D Omit 5 2 28 64 1 TABLE 2.6Percentages Choosing Each Response: Grade 4 Major Source of GasolineThe percentage of fourth graders choosing each response is reported in table 2.6. Approximately two-thirds of students answered the question correctly. Twenty-eight percentthought that gasoline came from gases in the atmosphere. This choice may have been due to thepresence of the word \"gases \" in the option and \"gasoline \" in the question. The remainder chose water or wood.32 Student Work & Teacher Practices in ScienceEarth 's Surface The following multiple-choice question measures recall of factual information. It is classified under the earth science topic \"Water \" and asks specifically whether or not students know that most of the Earth 's surface is covered by water. 7. Most of the Earth's surface is covered by Aoceans Blakes Cland Dice caps The correct option is A.Student Work & Teacher Practices in Science 33Response Options A B C D Omit 78 3 18 1 1 NOTE: Numbers do not add to 100 due to rounding. TABLE 2.8Percentages Choosing Each Response: Grade 4 Earth 's SurfaceThe question proved to be somewhat easy (table 2.8). Seventy-eight percent of fourth graders knew that most of Earth 's surface is covered by oceans (water). The only other attractive option, perhaps not surprisingly, was land. A few students (four percent) thought that the correctresponse was lakes or ice caps. TABLE 2.9Percentages Correct within Each Achievement Level Interval: Grade 4 Earth 's Surface Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 56 83 94 - - - - Sample size insufficient to permit a reliable estimate.The percentages of students within each of the achievement levels that answered the question correctly is shown in table 2.9. The question proved easy for students classified asBasic and Proficient . Eighty-three percent and 94 percent of students, respectively, knew that most of Earth 's surface is covered by oceans.34 Student Work & Teacher Practices in Science7. We can see the Moon from Earth because the Moon Ais so hot that it glows like the Sun Breflects light from the Sun Chas many volcanoes that give off a glowing gas Dis made of rocks that give off their own light The correct option is B.Visibility of Moon from Earth The next sample multiple-choice question is classified under the earth science topic \"Earth in Space. \" This question required students to understand that the Moon is visible because it reflects light from the Sun.Student Work & Teacher Practices in Science 35 TABLE 2.11Percentages Correct within Each Achievement Level Interval: Grade 4 Visibility of Moon from Earth Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 53 70 87 - - - - Sample size insufficient to permit a reliable estimate.Response Options A B C D Omit 77 032 01 NOTE: Numbers do not add to 100 due to rounding. TABLE 2.10Percentages Choosing Each Response: Grade 4 Visibility of Moon from EarthSeventy percent of fourth graders answered the question correctly; however, 20 percent thought that the Moon was made of rocks that gave off their own light (table 2.10). Student performance data show that just over half of students classified as below Basic, 70 percent classified as Basic , and 87 percent classified as Proficient knew that the Moon is visible because it reflects light from the sun.36 Student Work & Teacher Practices in Science8. In some parts of the United States, smog sometimes makes the air seem hazy, even on a sunny day. Smogalso makes it hard for some people to breathe. Wheredoes most of the smog in the air come from? AFactories and automobiles BVolcanoes and earthquakes CForests and farm fields DNuclear power plants The correct option is A.Sources of Smog In the next multiple-choice question, students were asked to indicate the major sources of smog. The question was designed to measure knowledge relating to \"interactions of human society with atmosphere \" under the major earth science topic \"Air.\" Since smog may have been a term that was not familiar to fourth-grade students, several of its properties were mentioned. This question could have been answered by straight recall; however, it could also have been answered by deduction. Students may have known that there are few active volcanoes inthe United States and that forests and farm fields are unlikely to give off noxious fumes. Manystudents would not know about the existence of nuclear power plants unless they lived near one.Some students, however, probably recognized that there are many cars and factories in theUnited States and deduced that these may be a source of smog.Student Work & Teacher Practices in Science 37 TABLE 2.13Percentages Correct within Each Achievement Level Interval: Grade 4 Sources of Smog Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 39 57 70 - - - - Sample size insufficient to permit a reliable estimate.Response Options A B C D Omit 55 10 11 22 2 TABLE 2.12Percentages Choosing Each Response: Grade 4 Sources of SmogInformation on the percentages of students choosing each response is shown in table 2.12. Fifty-five percent of students knew that most of the smog in air comes from factories andautomobiles. Option D proved very attractive to fourth graders, with 22 percent believing thatnuclear power plants were the major source of smog. Table 2.13 shows the achievement-level data. Thirty-nine percent of students classified as below Basic and 57 percent of students classified as Basic knew that the sources of smog were factories and automobiles.38 Student Work & Teacher Practices in Science4-6q/c78/c97/c116/c117/c114/c97/c108/c32/c70/c111/c114/c99 /c101 /c115 The following example is an extended constructed-response question that measured concepts relating to \"Solid Earth. \" It asked students to think about natural forces that change features of Earth 's surface, either quickly or slowly. \"Quickly \" was defined as a period of days and \"slowly \" was defined as hundreds of years. To make the question more accessible to students and to allow them to think and respond to each part, the question was formatted to allow eachpart to be answered in turn. The question was scored using a four-level scoring guide. 8 To receive a score of Complete , a student had to name two natural forces and explain how each changed the Earth 's surface. A score of Essential was obtained if a student named two forces and explained how one of them changed Earth 's surface. A score of Partial could be obtained in several ways. A student could have named one or two forces or named a force and stated how itchanged Earth 's surface. A score of Unsatisfactory was given to those student responses that attempted to answer the question but failed to name a correct natural force. 8Appendix B contains scoring guides for the sample questions that appear in this report.Student Work & Teacher Practices in Science 394-6x Sample 1: Natural ForcesSample 1: Complete Response A variety of answers were included in the credited responses for this question. For example, students could have identified volcanoes, earthquakes, storms, or fires for short-term forces anderosion, weathering, or glaciers for long-term forces. In the sample response shown below, thestudent correctly chose volcanoes as a natural force that can change Earth 's surface over a period of days, and rivers as a natural force that can change a part of Earth 's surface over hundreds of years. The student also explained how Earth 's surface is changed by these forces, specifying ash and lava for volcanoes and the carving of a canyon by a river.40 Student Work & Teacher Practices in Science4-11x Sample 2: Natural ForcesSample 2: Essential Response The next sample response received a score of Essential . To receive this score, students had to correctly name a short-term and a long-term force and explain how one of these forces changedEarth 's surface. This student identified \"earthqake \" and \"water freezes in cracks. \" There was, however, no explanation given for the earthquake. The student merely repeated that the \"Earth 's surface changes. \" The information given for part (b) was accepted since the student knew that water expands as it freezes and causes cracks to widen.Student Work & Teacher Practices in Science 414-12x Sample 3: Natural ForcesSample 3: Partial Response The student response shown below indicates one correct force with a satisfactory explanation. The student was given credit for \"Earth shack \" and \"Because it would crack the soil of the Earth. \" No credit was given to the second part of the response since the natural force indicated was toovague \u2014 \"a moutan can. \"42 Student Work & Teacher Practices in Science4-13x Sample 4: Natural ForcesSample 4: Unsatisfactory Response The following response received a score of Unsatisfactory . Clearly the student did not understand what natural forces were and chose instead to write about trees.Student Work & Teacher Practices in Science 43Complete Essential Partial Unsatisfactory Omit 4 2 34 49 10 NOTE: Numbers do not add to 100 due to rounding. TABLE 2.14Percentages at Different Score Levels: Grade 4 Natural Forces TABLE 2.15Percentages Complete or Essential within Each Achievement Level Interval: Gr ade 4 Natural Forces Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 04 1 4 - - - - Sample size insufficient to permit a reliable estimate.Information on student performance is presented in table 2.14. The question proved to be very challenging. Four percent of students were able to name two forces, one long-term andone short-term, and describe how the Earth 's surface was changed by these forces. Two percent of students were able to identify two forces and explain how one of them could change Earth 's surface. A third of the fourth-grade population were in the Partial category, either stating two correct forces or one force and a description. Nearly half the student population was unable tocorrectly answer any part of the question. The percentage of students at each achievement level attaining a score of Essential or better is shown in table 2.15. Zero percent of students who were classified as below Basic , 4 percent who were classified as Basic , and 14 percent who were classified as Proficient were able to name two forces and explain at least one of these forces.44 Student Work & Teacher Practices in Science3. You stand on the end of a boat dock and toss a small stone out into a pond of still water. Ripples form on the surface of the water.Which drawing shows what you will see when you look down at thewater? ( X marks where the stone enters the water.) ART - 3aTops of Ripples X X X XTops of Ripples Tops of Ripples Tops of RipplesA The correct option is C.B C DPattern of Ripples The following multiple-choice question addressed vibrations and waves as motion and was classified under the physical science topic \"Motion. \" The question asked students to recognize the pattern of ripples that formed after a small stone was dropped into water. This questionproved to be somewhat difficult, as it required students either to remember this phenomenonfrom past experiences of playing with water or to visualize what would happen when a stonedisturbs water.Student Work & Teacher Practices in Science 45Response Options A B C D Omit 4 6 57 33 1 NOTE: Numbers do not add to 100 due to rounding. TABLE 2.16Percentages Choosing Each Response: Grade 4 Pattern of Ripples TABLE 2.17Percentages Correct within Each Achievement Level Interval: Grade 4 Pattern of Ripples Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 37 58 78 - - - - Sample size insufficient to permit a reliable estimate.Information on student performance is presented in tables 2.16 and 2.17. Fifty-seven percent of fourth graders answered the question correctly. A third of the students knew that theripples radiated out, but failed to realize that they did so in concentric circles. The 4 percent ofstudents who chose option A understood that the ripples moved out from the stone, but thoughtthat the pattern was in the form of a square. The item proved somewhat easy for studentsclassified as Proficient. Seventy-eight percent of these students knew the correct pattern of ripples emanating from a disturbance of pond water.46 Student Work & Teacher Practices in ScienceMealworm Lifecycle The following multiple-choice question presented students with a diagram of an insect life cycle and asked them to choose from a set of predictions of what would happen if the larva were eatenby a bird. It was classified under the life science topic \"Organisms. \" PupaAdult LarvaEgg ART - 7-a4. The life cycle of a mealworm is pictured above. What would happen if this larva were eaten by a bird? AThe larva would die before it could reproduce. BThe bird would become sick. CThe mealworm species would be wiped out. DThe mealworm eggs would be spread by the bird. The correct option is A.Student Work & Teacher Practices in Science 47 TABLE 2.19Percentages Correct within Each Achievement Level Interval: Grade 4 Mealworm Life Cycle Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 39 57 81 - - - - Sample size insufficient to permit a reliable estimate.Information on student performance is presented in table 2.18. The question was fairly challenging for students; 57 percent answered it correctly. Students found options B and Dattractive. Eighteen percent thought that the bird would get sick and 16 percent thought that themealworm eggs would be spread by the bird. A further eight percent may have thought that thediagram applied to all mealworms, since they believed that the mealworm species would bewiped out. Response Options A B C D Omit 57 18 8 16 1 TABLE 2.18Percentages Choosing Each Response: Grade 4 Mealworm Life Cycle As shown in table 2.19, 57 percent of students classified as Basic and 81 percent classified as Proficient answered the question correctly.48 Student Work & Teacher Practices in SciencePlants: Parts and Functions The extended constructed-response question shown below was designed to measure whether students could identify the major parts of a plant, and give a function for each identified part.The diagram showed a flowering plant, with numbers pointing to a flower, a leaf, and a root. Inorder to answer this question completely, students had to know the meaning of the word\"function \" in the context of this question. The question was scored using a four-level scoring guide. 9 In order to receive a score of Complete , students had to name the three plant parts and state a function for each. There were several ways for a student to receive a score of Essential. The student could name two or three plant parts and give a function for two of them. A score ofPartial was given to those responses that named as a minimum one part. A response that was scored as Unsatisfactory contained no correct information. 5. Name the parts of the plant below that are labeled 1, 2, and 3. Explain the function of each part. ART - 9-a1 2 3 9Appendix B contains scoring guides for the sample questions that appear in this report.Student Work & Teacher Practices in Science 494-32x Sample 2: Plants: Parts and Functions4-26x Sample 1: Plants: Parts and FunctionsSample 1: Complete Response A number of different functions were acceptable for each plant part. For example, students could say that the roots take in water or minerals or that they hold the plant in the soil. Creditedresponses for the flower ranged from the specific \"it has the pollen \" to the more general \"it makes more life. \" In addition, students were given credit for writing \"bud\" for flower. This student was able to identify the parts of the plant and give a correct function for each. Sample 2: Essential Response The next sample response received a score of Essential . This student identified the three parts correctly but was only able to give a correct function for the roots, that is, \"to hold the plant in place. \"50 Student Work & Teacher Practices in Science4-29x Sample 4: Plants: Parts and Functions4-28x Sample 3: Plants: Parts and FunctionsSample 3: Partial Response The sample response shown below received a score of Partial . It has two parts labeled correctly, \"flower \" and \"ruts.\" \"Stim\" was not credited since the arrow on the diagram is pointing to a leaf. The student did not attempt to state a function for the labeled parts. Sample 4: Unsatisfactory Response The next response received a score of Unsatisfactory . The student did not name any part and appeared to answer the question, \"What does it (the flower) do? \" with \"It grows on it. \"Student Work & Teacher Practices in Science 51Table 2.20 shows the percentages of students at each score level. Two percent of students received a score of Complete . They were able to name the three plant parts and state a function for each. Twenty-seven percent of students received a score of Essential . This meant that they could name at least three parts and state one function or name two parts and state twofunctions. Sixty-five percent of fourth-grade students received a score of Partial . They could name at least one plant part or state one function. Three percent of students were unable toname any of the three major parts of a plant or give their function. TABLE 2.21Percentages Complete or Essential within Each Achievement Level Interval: Gr ade 4 Plants: Parts and Functions Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 10 26 56 - - - - Sample size insufficient to permit a reliable estimate.Complete Essential Partial Unsatisfactory Omit 22 7 6 53 4 NOTE: Numbers do not add to 100 due to rounding. TABLE 2.20Percentages at Different Score Levels: Grade 4 Plants: Parts and Functions Table 2.21 shows the percentages of students within each of the achievement-level intervals who received a score of Essential or better. Twenty-six percent of students classified as Basic and 10 percent of students classified as below Basic were able to name at least two parts of a plant and state their functions correctly.52 Student Work & Teacher Practices in ScienceScientific Investigation10 Thirty-seven questions administered to fourth graders in the NAEP 1996 science assessment measured the knowledge and skills related to scientific investigation. These exercises rangedfrom testing for discrete skills such as indicating the volume of water in a graduated cylinder toasking students to plan an appropriate investigation. The following examples indicate some ofthe breadth of this skill area. Volume The first multiple-choice question asks students to read a graduated cylinder, a skill that isimportant when conducting investigations. While the question could have been classified in allthree domains, it was classified under the physical science topic \"Matter and its Transformations, \" since the NAEP science framework specifically states, \"Students can use metric devices to measure linear dimensions of objects, weight, volume, and temperature. \" 11 To answer this question correctly, students had to understand the scale of the cylinder andwhat each graduation measured. 10See figure 1.2 for a description of scientific investigation. 11National Assessment Governing Board. (1995). Science framework for the 1996 National Assessment of Educational Progress. W ashington, DC: Author.1. The pictures below show containers with water in them. Which container has 35 milliliters (mL) of water in it? ART - 1a1020304050mL 1020304050mLA B C D 1020304050mL 1020304050mL The correct option is D.Student Work & Teacher Practices in Science 53Just over three-quarters of the student population was able to measure the volume correctly (table 2.22). Five percent of students chose option A, and 3 percent chose option C.These students failed to read the graduations correctly. The two percent who chose option B \u2014 25 ml \u2014 may have counted down from the 30 ml mark instead of up. Response Options A B C D Omit 5 2 3 76 15 NOTE: Numbers do not add to 100 due to rounding. TABLE 2.22Percentages Choosing Each Response: Grade 4 Volume The percentage of students within each of the achievement levels that provided a correct response is shown in table 2.23. The question proved to be easy; 82 percent of studentsclassified as Basic knew how to read a graduated cylinder. However, the omit rate for this question was high. Fifteen percent of grade 4 students did not attempt to answer the questioneven though it was the first question in the block. 12 TABLE 2.23Percentages Correct within Each Achievement Level Interval: Grade 4 Volume Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 55 82 91 - - - - Sample size insufficient to permit a reliable estimate. 12A block of questions took 20 minutes to complete. Each student was presented with three blocks.54 Student Work & Teacher Practices in ScienceBar Graphs Displaying data in a variety of ways is an important skill in scientific investigation. The sample question below shows a multiple-choice question set in a life science context that askedstudents to recognize which bar graph represented data shown in a table. To answer thisquestion correctly, students had to ascertain the height of the bar graphs in each option andchoose the bar graph that represented the data in the table. The correct option is C.2. Data about the hair color of fifteen students are shown in the table below. Which of the following bar graphs represents the data shown in the table?Hair Color Red Black Brown Blond 156 3 ART - 6aDB Brown Black Blond Red123456 0Students Hair ColorBrown Black Blond Red123456 0Students Hair Color Blond 0Students Black Blond Red123456 0Students Hair ColorA CB DStudent Work & Teacher Practices in Science 55Response Options A B C D Omit 46 8 4 33 TABLE 2.24Percentages Choosing Each Response: Grade 4 Bar Graph Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 69 89 98 - - TABLE 2.25Percentages Correct within Each Achievement Level Interval: Grade 4 Bar Graph - - Sample size insufficient to permit a reliable estimate.Information on student performance is presented in table 2.24, and the percentage of students at each achievement level that chose the correct response is shown in table 2.25.Fourth graders found this question very easy, with 84 percent choosing option C, the correctanswer. Four percent chose option A. These students may have failed to look at the scale on theabscissa (the y-axis) and therefore chose the order strictly on the size of the bars, incorrectlyviewing one as the highest and six as the lowest. Six percent and three percent of studentschose options B and D, respectively. As indicated by the achievement-level data, 89 percent ofstudents that were classified as Basic answered the question correctly .56 Student Work & Teacher Practices in ScienceExperimental Setup The purpose of this short constructed-response question was to find out whether fourth-grade students could recognize an experimental setup that would answer the question \"Do beetles choose to live in bright light or in the shade? \" To answer this question correctly, students had to understand that the variable was light versus dark, that the beetles had to be able to move freelyfrom a light to a dark area or vice versa, and that certain other factors had to be controlled. Three experimental setups were presented to the students, one of which is included here. The two that are not included showed a correct setup with a dish of water on the light anddark sides, and an incorrect setup where there were two separate boxes, one open to the lightand the other covered with a lid. Each box in the incorrect setup contained a dish with water;however, there was no way for the beetles to transfer from box to box. Therefore, they could notchoose where to live. The question shown below was scored using a three-level scoring guide. 13 A response received a score of Complete if it stated that the experimental design was inappropriate and explained why. To receive a score of Partial , the response merely had to state that the experimental setup was inappropriate with an incorrect or no explanation. A score ofUnsatisfactory was given to responses that contained no correct information. 13 Appendix B contains scoring guides for the sample questions that appear in this report. Student Work & Teacher Practices in Science 57Samples 1 and 2: Complete Response Samples 1 and 2 both received full credit. The response indicated in the first sample clearly demonstrates that the student understood that water had to be present in both the light and thedark areas. The second sample response is somewhat different. The student starts by saying,\"Y es cause of the wall that blocks the light, \" which is incorrect. However, the student then states, \"But I would put a water dich in the shad to so the water can be on wich ever side he chocesz. \" The student has, therefore, understood that the conditions have to be identical on each side of the wall. This response was also given a score of Complete . 4-18xSample 1: Experiment Setup 4-19xSample 2: Experiment Setup 58 Student Work & Teacher Practices in ScienceSample 3: Partial Response Students in this category answered \"no\" but were unable to articulate a correct reason for their dissatisfaction with the setup. The student in the sample response thought that the experimentalsetup was not good because \"it just not good for this experiment. \" Sample 4: Unsatisfactory Response A student response that received a score of Unsatisfactory is shown below. This response, while enthusiastic, simply states what is present in the diagram and makes a judgment about theexperiment and not the experimental setup \u2014 \"So yes I do think it is a good experiment. \"4-20xSample 3: Experiment Setup 4-21xSample 4: Experiment Setup Student Work & Teacher Practices in Science 59 TABLE 2.27Percentages Complete within Each Achievement Level Interval: Gr ade 4 Experimental Setup Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 16 2 9 - - - - Sample size insufficient to permit a reliable estimate.Complete Partial Unsatisfactory Omit 12 27 59 3 NOTE: Numbers do not add to 100 due to rounding. TABLE 2.26Percentages at Different Score Levels: Grade 4 Experimental SetupInformation on student performance is presented in table 2.26. Twelve percent of students were able to recognize that the setup was incomplete and give a valid explanation. Twenty-sevenpercent of the student population recognized that the experimental setup was flawed but wereunable to justify their decision adequately. Fifty-nine percent of fourth-grade students wereunable to recognize that the experimental setup was flawed because it was not adequatelycontrolled. The percentages of students within each of the achievement levels who successfully answered the question are presented in table 2.27. The item was very difficult; six percent ofstudents classified as Basic and one percent classified as below Basic were able to judge and explain adequately the correctness of an experimental setup.60 Student Work & Teacher Practices in Science1. Kristen was listening to a portable radio one afternoon and forgot to turn it off. The next morning the radiowould not work. What is the best explanation for whythe radio would not work? AAll the radio stations stopped broadcasting. BThe energy stored in the batteries was all used up. CIt was too cold the next morning for the radio to play. DThe radio speaker broke because it was left on for so long. The correct option is B.Practical Reasoning14 In order to do well on questions that measured practical reasoning, students need to remember scientific facts and concepts and apply them. Of the 145 questions that constituted the grade 4NAEP science assessment, 27 were classified as measuring practical reasoning. A selection ofthese is shown below. Radio Malfunction The following multiple-choice question required students to recognize why a portable radio didnot work after being left on all night. It was classified under the physical science topic \"Energy and its Transformations. \" 14See figure 1.2 for a description of practical reasoning.Student Work & Teacher Practices in Science 61Many students are familiar with batteries from everyday life, as evidenced by the fact that 85 percent of the grade 4 population answered this question correctly (table 2.28). V ery few wereattracted to options A and C. Option D, which referred to the radio breaking because it was left ontoo long, did prove to be attractive to 10 percent of the population. However, given the limited lifeof batteries, option B was clearly the best explanation. The achievement level data shown in table2.29 indicate that 90 percent of students classified as Basic answered the question correctly. TABLE 2.29Percentages Correct within Each Achievement Level Interval: Grade 4 Radio Malfunction Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 70 90 96 - - - - Sample size insufficient to permit a reliable estimate.Response Options A B C D Omit 28 521 02 NOTE: Numbers do not add to 100 due to rounding. TABLE 2.28Percentages Choosing Each Response: Grade 4 Radio Malfunction62 Student Work & Teacher Practices in ScienceProperties of Metals The following short constructed-response question was designed to find out whether fourth-grade students knew any properties of metals. It was classified under the physical science topic \"Matterand its Transformations.\" The question's introductory sentence was included to help studentsfocus on familiar metallic objects. They could then use the examples as a springboard for thinkingabout why metals are used to make different things. A three-level scoring guide was used to scorethe responses. 15 Students had to record two properties of metals in order to receive a score of Complete , one property to receive a score of Partial , and no properties to receive a score of Unsatisfactory . 4-2q 15 Appendix B contains scoring quides for the sample questions that appear in this report.Student Work & Teacher Practices in Science 634-1x Sample 2: Properties of MetalSample 1: Complete Response The first sample response received a score of Complete . This student focused on the objects given in the question and indicated a number of properties. Thus the student indicated that \"a pot getswarm...it heats the food,\" implying conductivity. The student also noted that the tools were bothhard and not easy to break and that the wire \"easy lets electricity travel through it.\" 4-2x Sample 1: Properties of Metal Sample 2: Partial Response Students who achieved the score of Partial recorded one correct property. In the example, the student stated that \"Metal is a good conductor.\"64 Student Work & Teacher Practices in ScienceSample 3: Unsatisfactory Response The following response clearly demonstrates that the student did not understand what the question was asking. The reason the student gave is that if \"they don do pots, pans, tools, wire,din we we'll not have nothing.\" In other words, if they don't make them out of metal then wewon't have any. 4-4x Sample 3: Properties of MetalStudent Work & Teacher Practices in Science 65 TABLE 2.31Percentages Complete within Each Achievement Level Interval: Gr ade 4 Properties of Metals Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 61 8 3 5 - - - - Sample size insufficient to permit a reliable estimate. TABLE 2.30Percentages at Different Score Levels: Grade 4 Properties of Metals Complete Partial Unsatisfactory Omit 19 34 40 6 NOTE: Numbers do not add to 100 due to rounding.Data for student performance are shown in tables 2.30 and 2.31. Nineteen percent of fourth graders were able to think of at least two properties. Thirty-four percent of students wereable to think of one property. Forty percent of fourth graders were unable to think of any reasonwhy metals are used to make many different things. A further six percent of students omittedthe question. Approximately one-third of students classified as Proficient received a score of Complete . However, students classified as Basic and below Basic found the item challenging; 18 percent and 6 percent, respectively, answered the question fully.66 Student Work & Teacher Practices in ScienceTheme Block Three of the fifteen 20-minute blocks of questions at the fourth-grade level address each of the three themes \u2014 systems, models, and patterns of change \u2014 outlined in the Science Framework for the 1996 National Assessment of Educational Progress .16 Not every student in the assessment was administered one of these theme blocks and no student was administered more than one.These blocks of questions differed from others in the assessment in that they probed deeply intostudents ' understanding of a given area of science \u2014 such as life cycles \u2014 whereas most blocks usually did not devote more than one or two questions to any given topic. The eight questions based on the theme \"patterns of change \" have been released to the public and can be found on the Internet. 17 Students were presented with information relating to Ms. Brown 's fourth-grade class (see below). Ms. Brown told her class that she would put the pond water and frogs ' eggs she had collected into a fish tank and then they could all watch as the eggs developed into tadpoles and frogs. The students were then asked two questions thatrelated to the life cycles of frogs and a third that asked how tadpoles and frogs got oxygen intotheir bodies. The remaining five questions, of which three are presented here, addressed the lifecycles of a number of other animals such as salamanders and butterflies. Questions 1-8 refer to the life cycles of different animals. One day Ms. Brown brought a bucket of pond water to her fourth-grade class. In the bucket were several clumps of frogs ' eggs \u2014and there were many eggs in each clump, as you can see in Picture 1. \"We'll put these eggs and the pond water into the fish tank on the table in the back of theroom,\" said Ms. Brown, \"and soon these eggs will hatch into tadpoles. Then we can watch as the tadpoles grow and change into Board. (1995). Science framework for the 1996 National Assessment of Educational Progress. W ashington, DC: Author. See figure 1.3 for a description of themes. 17National Center for Education Statistics: National Assessment of Educational Progress. (1997). 1996 science assessment public release, grade 4 [On-line]. Available: http://nces.ed.gov/naep.Picture 1Student Work & Teacher Practices in Science 67Theme Block: Metamorphosis The question depicted below asks students to recognize the missing stage of the life cycle of a butterfly. Since the pupal stage varies in appearance depending on the species, the diagram wasscored somewhat leniently. In addition, three labels were accepted \u2014 pupa, chrysalis, and cocoon. The question was scored according to a three-level scoring guide. 18 To receive a score of Complete , students had to both draw and label the missing part of the life cycle. A drawing or a diagram gave the student a score of Partial . Students who received a score of Unsatisfactory attempted the question but were unable to draw or label the missing part. 4-22q5. Insects also change as they grow. Look at the picture below. One part of the picture is missing. Draw and label themissing part of the picture. 18Appendix B contains scoring guides for the sample questions that appear in this report.68 Student Work & Teacher Practices in Science Egg Caterpillar Butterfly Draw and label the missing part of the picture. 4-23x5. Insects also change as they grow. Look at the picture below. One part of the picture is missing. Draw and label themissing part of the picture.Sample 2: MetamorphosisSample 1: Complete Response The following sample response received a score of Complete. This student was able to draw and label the missing part as \"the cocoon. \" Sample 1: Metamorphosis 4-22x5. Insects also change as they grow. Look at the picture below. One part of the picture is missing. Draw and label themissing part of the picture. Egg Caterpillar Butterfly Draw and label the missing part of the picture. Sample 2: Partial Response The next sample response received a score of Partial . This student was able to draw the missing part but did not label it. While the diagram does look somewhat like the caterpillar, the fact thatit is hanging from what looks like a twig indicates that it is probably the pupal stage. Studentscould also receive a Partial score for a correct label with a missing or incorrect diagram. Most students, however, did attempt a diagram.Student Work & Teacher Practices in Science 69Sample 3: U nsatisfactory Response The following sample response received a score of Unsatisfactory . This student drew an \"egg\" and labeled it. The question was of average difficulty; 51 percent of students received a score of Complete (table 2.32). Thirty-seven percent of students received a score of Partial . Nine percent of students were unable to draw or label the missing pupa. Achievement level data shown in table 2.33 indicate that 74 percent of students classified as Proficient answered the question correctly. Twenty-four percent of students classified as below Basic were also able to draw and label the missing stage of the butterfly life cycle. TABLE 2.32Percentages at Different Score Levels: Grade 4 Metamorphosis Complete Partial Unsatisfactory Omit 51 37 9 4 NOTE: Numbers do not add to 100 due to rounding. Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 24 56 74 - - - - Sample size insufficient to permit a reliable estimate. TABLE 2.33Percentages Complete within Each Achievement Level Interval: Gr ade 4 Metamorphosis4-25xEgg Caterpillar Butterfly Draw and label the missing part of the picture. 5. Insects also change as they grow. Look at the picture below. One part of the picture is missing. Draw and label themissing part of the picture.Sample 3: Metamorphosis70 Student Work & Teacher Practices in ScienceTheme Block: Grasshoppers and Butterflies The next question in the theme block showed students the life cycle of a grasshopper. They were asked to compare the life cycle of this organism to that of a butterfly. This question wasscored using a four-level scoring guide. 19 In order to receive a score of Complete, students had to indicate at least two differences and one similarity or one difference and two similaritiesbetween the life cycle of a grasshopper and the life cycle of a butterfly. A score of Essential was given to responses that included two differences or similarities or one difference and onesimilarity. A score of Partial was given to responses that contained just one correct difference or similarity. Responses receiving a score of Unsatisfactory provided no appropriate information. The question was somewhat difficult to score since students tended to be repetitious and scorers had to decide when something new was being stated. Also, many students wrote aboutthings that the organisms do such as flying and hopping. Such answers were not credited. 19Appendix B contains scoring guides for the sample questions that appear in this report.Student Work & Teacher Practices in Science 71 72 Student Work & Teacher Practices in ScienceSample 1: Complete Response The following student response indicated a number of differences and similarities. This student recognized that the grasshopper got bigger, whereas the butterfly changed in appearance. Thestudent stated that \"both of them are eggs first. \" This was the most popular student response for describing a way that the grasshopper 's life cycle is the same as the butterfly 's life cycle. The student added that both go through \"many stages \" and that the grasshopper \"has more stages to go through. \" Sample 1: Grasshoppers and Butterflies gs-smp1Student Work & Teacher Practices in Science 73Sample 2: Grasshoppers and Butterflies gs-smp2 Sample 2: Essential Response The student in the response shown below indicates that grasshoppers \"do not wrap up there body, \" presumably referring to the presence of a cocoon. In addition, the student stated that they \"both hatched out of a egg. \" The additional differences and similarities were discounted since these referred to actions of the organisms.74 Student Work & Teacher Practices in ScienceSample 3: Grasshoppers and Butterflies gs-smp3 Sample 3: Partial Response The next response indicated one difference that was accepted. This student recognized that the grasshopper came from an egg, whereas the butterfly developed from something that lookeddifferent, that is \"a warm. \"Student Work & Teacher Practices in Science 75Sample 4: Grasshoppers and Butterflies gs-smp4 Sample 4: Unsatisfactory Response The student response shown below received a score of Unsatisfactory . Clearly the student did not understand what the question was asking.76 Student Work & Teacher Practices in ScienceInformation relating to the percentages of students at different score levels is shown in table 2.34. Eighty percent of students were able to state at least one difference or one similaritybetween the life cycle of a grasshopper and the life cycle of a butterfly. Sixteen percent ofstudents were able to describe at least two differences and one similarity or one difference andtwo similarities. Complete Essential Partial Unsatisfactory Omit 16 34 30 19 0 TABLE 2.34Percentages at Different Score Levels: Grade 4 Grasshoppers and Butterflies NOTE: Numbers do not add to 100 due to rounding. TABLE 2.35Percentages Complete or Essential within Each Achievement Level Interval: Gr ade 4 Grasshoppers and Butterflies Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 41 7 3 0 - - - - Sample size insufficient to permit a reliable estimate.The percentages of students at each achievement level who received a score of Complete or Essential are shown in table 2.35. Students who were classified as below Basic found the question challenging, as evidenced by the four percent who were able to name at least twodifferences or two similarities or one difference and one similarity.Student Work & Teacher Practices in Science 778. Think about how humans grow and develop from newborn babies to adults. Is a human 's life cycle more like a frog 's life cycle or more like a grasshopper 's life cycle? Explain your answer.Theme Block: Life Cycles The question shown below was the last question in the theme block. It asked students to decide whether the human life cycle is more like a frog 's life cycle or a grasshopper 's life cycle. To answer the question successfully, students had to synthesize information that had beenpresented to them earlier in the block in the form of a diagram of the life cycle of a grasshopperand a number of questions relating to the frog 's life cycle. Students were also given additional information to help clarify what constituted a human life cycle. Their responses were scoredaccording to a two-level scoring guide as either Complete or Unsatisfactory . 20 Students who received a score of Complete were able to justify their choice of organisms satisfactorily. Sample 1: Complete Response The student writing this sample response clearly understood the purpose of the question. The student stated \"grasshoppers because they keep growing. \" Although the explanation was somewhat general, the student did add that the \"frog changes into different things. \" 20Appendix B contains scoring guides for the sample questions that appear in this report.Sample 1: Life Cycles 4-29x8. Think about how humans grow and develop from newborn babies to adults. Is a human 's life cycle more like a frog 's life cycle or more like a grasshopper 's life cycle? Explain your answer.78 Student Work & Teacher Practices in ScienceSamples 2 and 3: Unsatisfactory Response In the first Unsatisfactory response sample, the student chose \"frog\" and explained this choice on the basis of the statement \"when we are in are mothers stomak, \" thus discounting the information concerning \"newborn babies to adults. \" In the second Unsatisfactory response sample, the student chose to describe the human life cycle, thus responding to the firstsentence in the question. Since there was no Partial score for this question, a response that indicated the correct organism but gave an incorrect explanation was scored as Unsatisfactory . 4-30x.tif8. Think about how humans grow and develop from newborn babies to adults. Is a human 's life cycle more like a frog 's life cycle or more like a grasshopper 's life cycle? Explain your answer.Sample 2: Life Cycles 4-31x.tif 8. Think about how humans grow and develop from newborn babies to adults. Is a human 's life cycle more like a frog 's life cycle or more like a grasshopper 's life cycle? Explain your answer.Sample 3: Life CyclesStudent Work & Teacher Practices in Science 79 TABLE 2.37Percentages Complete within Each Achievement Level Interval: Gr ade 4 Life Cycles Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 41 3 3 8 - - - - Sample size insufficient to permit a reliable estimate.Information relating to performance data is shown in tables 2.36 and 2.37. The question was challenging. Nineteen percent of fourth graders received a score of Complete . Achievement level data indicate that 38 percent of students classified as Proficient were able to explain how the human life cycle was more like a grasshopper life cycle than a frog life cycle. Complete Unsatisfactory Omit 19 80 1 TABLE 2.36Percentages at Different Score Levels: Grade 4 Life Cycles80 Student Work & Teacher Practices in ScienceFLOATING PENCIL Using a Pencil to Test Fresh and Salt Water You have been given a bag with some things in it that you will work with during the next 20 minutes. Take all of the things out of the bag and put them on your desk. Now look at the picture below. Do you have everything that is shown in the picture? If you are missinganything, raise your hand and you will be given the things you need. Hands-on Task Four hands-on tasks were administered in the NAEP fourth-grade science assessment. Each task asked students to use materials to perform an investigation, make observations, record andevaluate experimental results, and apply problem-solving skills. The first page of one of the four tasks presented to students is shown below. An instrument constructed from a pencil and thumbtack served as a hydrometer in this task.Students were asked to observe, measure, and compare the lengths of a portion of pencil,marked with calibrations for ease of measurement, that floated above the water surface in freshwater and in salt water. The students then determined if the unknown sample was fresh water orsalt water and predicted how the addition of more salt to the salt solution would affect thefloating pencil. The task assessed students ' abilities to make simple observations, measure volume using a graduated cylinder, measure length using a ruler, apply observations and measurementto test an unknown, make generalized inferences from observations, and apply understanding toan everyday situation. The task, scoring guides for each question, and sample student responsescan be found on the Internet. 21 21National Center for Education Statistics. National Assessment of Educational Progress. (1997). 1996 science assessment public release, grade 4 [On-line]. Available: http://nces.ed.gov/naep.Student Work & Teacher Practices in Science 81Hands-on Task: Mystery Water The short-constructed-response question shown below appeared toward the end of the task, after students had measured the height of the pencil above the surface of the fresh water, saltwater, and mystery water. Students were then asked to identify the \"mystery water \" and justify their answers. The question was scored using a three-level scoring guide. 22 Students received a score of Complete if they correctly identified the water and justified their choice. To receive a score of Partial , students had only to state the identity of the mystery water. A score of Unsatisfactory was given to responses that misidentified the mystery water. 22Appendix B contains scoring guides for the sample question that appear in this report.82 Student Work & Teacher Practices in ScienceSamples 1 and 2: Complete Response The sample responses below both received a score of Complete . Both responses state that the mystery water was fresh water and correctly relate the answer to the height of the pencil abovethe solutions. 4-7xSample 2: Mystery Water Sample 1: Mystery Water 4-5x Student Work & Teacher Practices in Science 83Sample 3: Partial Response In the example shown below, the student indicates fresh water and justifies this answer by stating \"because it do not have salt and it. \" This answer did not relate to the task and therefore received no credit. Sample 4: Unsatisfactory Response The following response received a score of Unsatisfactory . The student chose salt water, which was incorrect, and justified the answer without referring to the task. 4-10xSample 4: Mystery Water Sample 3: Mystery Water 4-8x84 Student Work & Teacher Practices in ScienceThe percentages of students receiving various scores are shown in table 2.38. Twenty- eight percent of fourth graders were able to identify the mystery water as fresh water andcorrectly explain their choice. Forty-five percent of grade 4 students were able to identify themystery water as fresh water but were not able to justify their selection adequately. Twenty-seven percent of students were unable to identify the water correctly. TABLE 2.38Percentages at Different Score Levels: Grade 4 Mystery Water Complete Partial Unsatisfactory Omit 28 45 27 1 NOTE: Numbers do not add to 100 due to rounding. TABLE 2.39Percentages Complete within Each Achievement Level Interval: Gr ade 4 Mystery Water Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 52 1 4 9 - - - - Sample size insufficient to permit a reliable estimate.When results are presented by achievement level (table 2.39), 21 percent of students classified at the Basic level and 49 percent classified at the Proficient level answered the question correctly.Student Work & Teacher Practices in Science 85 4-14qHands-on Task: Ease of Floating The question shown below was the last one in the task. Students were expected to relate the experiences encountered when doing the task to a practical situation. Thus, students wereasked to consider whether it was easier to stay afloat in the ocean or in fresh water. They hadalready been told at the beginning of the task that \"fresh water has very little salt in it and is quite different from salt water, which is found in oceans. \" They did not have to bring into the assessment the knowledge that oceans are salty. The question was scored using a three-levelscoring guide. 23 In order to receive a score of Complete on this question, students had to state \"ocean \" and present an explanation that referred back to the hands-on task. A response that merely stated \"ocean water \" received a score of Partial . Students who did not relate the concept of density to floating in salt water versus fresh water received a score of Unsatisfactory .86 Student Work & Teacher Practices in ScienceSample 2: Ease of Floating 4-15x Sample 1: Complete Response The following response received a score of Complete . The student correctly indicates \"ocean, \" states that the ocean contains salt, and explains the choice in terms of the pencil floating higherin salt water than in fresh water. 4-14x Sample 1: Ease of Floating Sample 2: Partial Response In the following sample response, the student stated \"the ocen, \" which is correct; however, the explanation was too general. Thus the response received a score of Partial.Student Work & Teacher Practices in Science 87Sample 3: Unsatisfactory Response Responses in the Unsatisfactory category identified the mystery water as fresh water and very often gave a justification that was related to experience. This student chose fresh water because\"the water won 't burn the eyes as much, \" thus answering the question, \"which water do you prefer to swim in and why? \" 4-17x Sample 3: Ease of Floating88 Student Work & Teacher Practices in Science TABLE 2.40Percentages at Different Score Levels: Grade 4 Ease of Floating Complete Partial Unsatisfactory Omit 14 29 56 1 TABLE 2.41Percentages Complete within Each Achievement Level Interval: Gr ade 4 Ease of Floating Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 21 0 2 2 - - - - Sample size insufficient to permit a reliable estimate.Data relating to student performance are shown in tables 2.40 and 2.41. Fourteen percent of fourth graders were able to use the results from the experiment in a real-world situation.Twenty-nine percent of grade 4 students chose the correct answer but failed to explain itadequately. Thus they received a score of Partial . Fifty-six percent of grade 4 students were unable to answer the question. Students found this item very difficult, as evidenced by the achievement level data (table 2.41). Ten percent of students classified as Basic and two percent classified as below Basic received a score of Complete for the question.Student Work & Teacher Practices in Science 89Summary of Grade 4 Data The data presented in this chapter give an indication of how students in grade 4 perform on science questions that cover a range of topics and make use of a variety of question types. Thequestions presented had to be limited to those that were released to the public. 24 However, these are fairly representative and do give an indication of the understandings and skills surveyed inthe assessment. Similarly, the data for the small group of questions discussed in this chapterrepresent the data seen for the questions as a whole. In general, students found questions thatasked them to construct their own responses more difficult than questions that allowed them tochoose the answer from a set of options. \u007fThe amount of exposure to earth science, physical science, and life science was not associated with differences in the scale scores of students in these fields. Forexample, students whose teachers reported that they spent little time on life scienceperformed as well on life science questions as did students whose teachers reportedthat they spent a lot of time on life science. \u007fMale students had a higher average question score than female students for the earth science questions. \u007fWhite students had a higher average question score than Black and Hispanic students for the earth, physical, and life science questions. \u007fMale students had a higher average question score than female students for questions that measured conceptual understanding. \u007fWhite students had a higher average question score than Black and Hispanic students for questions that measured conceptual understanding, scientificinvestigation, and practical reasoning. \u007fFor the questions presented in this chapter, the percentage of students who gave correct responses to the multiple-choice questions ranged from 55 percent to 85percent. \u007fFor the questions presented in this chapter, the percentage of students who received a score of Complete on the constructed-response questions ranged from 2 percent to 51 percent. 24National Center for Education Statistics. National Assessment of Educational Progress. (1997). 1996 science assessment public release, grade. [On-line]. Available; http://nces.ed.gov/naep.Chapter 3 Student Work & Teacher Practices in Science 91Grade 8: Performance, Knowledge, and Skills Introduction Science instruction in the early years in school tends to be general. However, as students enter middle school there is a tendency for science to be taught in the fields of earth, physical, or life.Evidence for this tendency can be found from data collected from students during the NAEP1996 science assessment. These data indicated that approximately 63 percent of grade 8students were taking a science course that was field specific. The remainder reported takingeither general science or integrated science. 1 Since the types of science courses and the order in which students take them vary from district to district, the NAEP science assessment surveys grade-appropriate content from earth,physical, and life science. The data collected can then be analyzed to ascertain, for example,how students would perform if given only physical science questions or only life sciencequestions. This chapter discusses the results of such analyses and also presents questions andstudent responses from the three fields of science \u2014 earth, physical, and life. The NAEP science survey that was administered in 1996 to students in grade 8 was constructed according to specifications outlined in the Science Framework for the 1996 National Assessment of Educational Progress . 2 The specifications state that 40 percent of assessment time should cover life science, 30 percent earth science, and 30 percent physicalscience. The framework also specifies that 45 percent of assessment time should be spent onquestions that measure conceptual understanding, 30 percent on scientific investigationquestions, and 25 percent on practical reasoning questions. (A description of the variouscategories is presented in chapter 1.) Like questions in the fourth-grade assessment, everygrade 8 question was classified as measuring one of the ways of knowing and doing sciencewithin one of the fields of science (for example, conceptual understanding in the context ofearth science). 1O'Sullivan, C. Y., Weiss, A. R., & Askew, J. M. (1998). Students learning science: A report on policies and practices in U.S. schools. (NCES Publication No. 98-496). W ashington, DC: National Center for Education Statistics. 2National Assessment Governing Board. (1995). Science framework for the 1996 National Assessment of Educational Progress. W ashington, DC: Author.92 Student Work & Teacher Practices in ScienceThe number of multiple-choice, short constructed-response, and extended constructed- response questions in each of the major areas is presented in table 3.1, as is the total number ofquestions. There were 74 multiple-choice questions and 120 constructed-response questions inthe grade 8 assessment. Each constructed-response question had its own unique scoring guidethat defined the criteria used to evaluate students ' responses. Short constructed-response questions were usually scored according to three levels of performance: Complete , Partial , or Unsatisfactory ; however, some of them were scored as either right or wrong ( Complete or Unsatisfactory ). Extended constructed-response questions were usually scored according to four levels of performance: Complete , Essential , Partial , or Unsatisfactory . In a few instances, however, five- and six-level scoring guides were used. In total, 322,261 student responses toconstructed-response questions were scored. This included the responses that were scoredtwice to monitor the reliability of the scoring process \u2014 25 percent of responses for national NAEP . 3 Appendix A describes the scoring process in more detail. Distribution of Questions by Fields of Science and by Ways of Knowing and Doing Science, Grade 8: Public and Nonpublic Schools CombinedTABLE 3.1 Short Constructed- Extended Constructed- Multiple-Choice Response Response Total SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Fields of Science Earth Science 26 35 4 65 Life Science 24 36 6 66 Physical Science 24 29 10 63 Total 74 100 20 194 Knowing and Doing Conceptual Understanding 59 48 3 110 Scientific Investigation 8 19 11 38 Practical Reasoning 7 33 6 46 Total 74 100 20 194 3For grade 8, the percentage agreement for the 1996 reliability sample was 94. This means that scores given by the first and second scorers agreed 94 percent of the time.Student Work & Teacher Practices in Science 93Teachers ' Reports on How Much Time They Spent Teaching Life Science, Earth Science, and Physical Science, Grade 8: Public and Nonpublic Schools CombinedTABLE 3.2 Average Scale Score Percentage Percentage Composite Life Earth Physical At or Above of Students (all fields) Science Science Science ProficientIn this class, about how much time do you spend on each of the following areas in science? Life Science A Lot 19 149 148 149 150 28 Some 40 150 151 150 150 29 Little 23 156 155 157 155 34 None 18 157 159 156 155 35 Earth Science A Lot 41 151 151 152 150 30 Some 39 151 151 152 152 30 Little 11 155 157 152 155 36 None 9 157 161 155 155 34 Physical Science A Lot 49 153 153 152 153 32 Some 35 153 153 153 152 32 Little 12 154 153 156 152 32 None 4 144 149 143 139 21 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Grade 8 Science Teaching Content As part of the NAEP 1996 science assessment, teachers of eighth-grade students were asked to specify how much time they spent teaching earth, physical, and life science. Teachers werepresented with the response options \"A Lot, \" \"Some, \" \"Little, \" and \"None. \" The results are shown in table 3.2. Forty-one percent of eighth-grade students were taught by teachers who reported spending a lot of time teaching earth science and 49 percent were taught by teachers whoreported spending a lot of time teaching physical science. Nine percent had teachers whoindicated that they had not taught earth science and four percent had teachers whoindicated they had not taught physical science. About the same percentage of students had teachers who said that they spent a lot of time teaching life science (19 percent) as who saidthey spent no time teaching it (18 percent). The amount of exposure to the different fields of science showed no relationship with the composite (all fields of science combined), life science, earth science, or physical science average scale scores of students or the percentage of students at or above Proficient .94 Student Work & Teacher Practices in ScienceAverage Question Score The average question score for questions measuring earth science, physical science, and life science was 0.38, 0.42, and 0.35, respectively (Table 3.3). Readers are cautioned not to makecomparisons among the fields of science for any group of students. Variations may, for example,be due to the particular make-up of the set of questions administered and could well not hold ifstudents were administered a different set of questions covering the same fields of science.Comparisons can be made, however, among the different reporting groups within each field ofscience. Several significant differences were found. Male students outperformed femalestudents on both the physical science questions and the earth science questions. On questionsthat measured physical science or earth science, White students and Asian/Pacific Islanderstudents outperformed Black and Hispanic students, and Hispanic students outperformedBlack students. In addition, on questions that measured physical science, White studentsoutperformed Asian/Pacific Islander students. On the questions that measured life science,White and Asian/Pacific Islander students outperformed both Black and Hispanic students. Average Question Score for Earth Science, Physical Science, and Life Science, Grade 8: Public and Nonpublic Schools CombinedTABLE 3.3 Earth Science Physical Science Life Science All Students 0.38 0.42 0.35 Male 0.39 0.44 0.35 Female 0.39 0.42 0.36 NOTE: There were insufficient sample sizes for the American Indian racial/ethnic subgroup to produce reliable results. NOTE: White refers to White (not Hispanic), Black refers to Black (not Hispanic). SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 95Table 3.4 shows the average question score for questions that measured conceptual understanding, scientific investigation, and practical reasoning. For all students, the averagequestion score was 0.39 for questions that measured conceptual understanding, 0.46 forquestions that measured scientific investigations, and 0.30 for questions that measuredpractical reasoning. Again, readers are cautioned not to compare performance among the waysof knowing and doing science, since student performance may have varied if different sets ofquestions had comprised these categories. When the data for the different groups of studentswithin each way of knowing and doing science are examined, however, several differencesemerge. Male students outperformed female students for questions that measured conceptualunderstanding. For questions that measured conceptual understanding and scientificinvestigation, White students and Asian/Pacific Islander students outperformed Black andHispanic students, and Hispanic students outperformed Black students. For questions thatmeasured practical reasoning, White students outperformed Black and Hispanic students andHispanic students outperformed Black students. Average Question Score for Conceptual Understanding, Scientific Investigation, and Practical Reasoning, Grade 8: Public and Nonpublic Schools CombinedTABLE 3.4 Conceptual Scientific Practical Understanding Investigation Reasoning All Students 0.50 Black 0.28 0.32 0.20 Hispanic 0.32 0.36 0.22 Asian/ Pacific Islander 0.40 0.48 \u2014\u2014 \u2014\u2014 Sample size is insufficient to permit a reliable estimate. NOTE: White refers to White (not Hispanic), Black refers to Black (not Hispanic). SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.96 Student Work & Teacher Practices in ScienceSample Questions and Student Responses The following section contains sample questions for each of the major fields of science. Table 3.5 summarizes the classification of questions that are discussed. Since the discussion must belimited to test questions that have been released to the public, no examples of questionsmeasuring scientific investigation in the area of physical science or of questions measuringpractical reasoning in the area of earth science are available for discussion. Some of thequestions described could be classified in more than one field of science or way of knowingand doing science. For the purposes of test construction and analysis, however, theclassification had to be limited to one field of science and one way of knowing and doing science. Sample Questions Categorized by Fields of Science and by Ways of Knowing and Doing Science, Grade 8: Public and Nonpublic Schools CombinedTABLE 3.5 Earth Science Physical Science Life Science Conceptual Understanding Scientific Investigation Practical ReasoningLocation of earthquakes(mc)Windchill (mc)Theme: Seasons \"mc\" indicates short constructed-response question; and \"ecr\" indicates an extended constructed-response question. 4See figure 1.2 for a description of conceptual understanding.Conceptual Understanding4 One hundred and ten questions administered to eighth graders during the NAEP 1996 science assessment measured conceptual understanding. These included both multiple-choice andconstructed-response questions in each of the three major content fields \u2014 earth science, physical science, and life science. A selection of these questions follows.Student Work & Teacher Practices in Science 97Location of Earthquakes The following multiple-choice question is classified under the earth science topic \"Solid Earth. \" In order to answer it correctly, students had to know the relationship between tectonic plate boundaries and occurrence of earthquakes. The percentages of students choosing each response are shown in table 3.6. Sixty percent knew that earthquakes were associated with tectonic plates. Twenty-four percentthought that they did not seem to occur with any consistent pattern. These students may havebeen thinking about the frequency of earthquakes rather than the location of earthquakes. TABLE 3.7Percentages Correct within Each Achievement Level Interval: Grade 8 Location of Earthquake Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 41 61 83 - - - - Sample size insufficient to permit a reliable estimate.The percentages of students within each of the achievement level intervals that successfully answered the question are shown in table 3.7. A fairly high percentage of studentswho were classified as below Basic , Basic , or Proficient were able to answer the question correctly.2. If the locations of earthquakes over the past ten years were plotted on a world map, which of the following would be observed? A Earthquakes occur with the same frequency everywhere on Earth. B Earthquakes generally occur along the edges of tectonic plates. C Earthquakes most frequently occur near the middle of continents. D Earthquakes do not seem to occur in any consistent pattern. The correct option is B. Response Options A B C D Omit 6 6 01 02 4 1 TABLE 3.6Percentages Choosing Each Response: Grade 8 Location of Earthquake98 Student Work & Teacher Practices in ScienceWindchill The following multiple-choice question is classified under the earth science topic \"Air.\" To answer this question correctly, students had to consider several pieces of information that werepresented in the table, namely the high and low temperatures on any given day and the averagewind speed. In addition, they had to understand the meaning of \"average windchill temperature. \" 2. On which day was the average windchill temperature likely to be the lowest? A Monday BTuesday C Wednesday D Friday The correct option is A.The following question refers to the table below. Monday Tuesday Wednesday Thursday Friday High Temperature ( \u00b0F) 43 50 42 53 60 Low Temperature ( \u00b0F) 28 38 28 39 45 Precipitation (inches) 0.0 1.0 1.5 0.0 1.6 Average Wind Speed 15 10 7 10 10 (mph)Student Work & Teacher Practices in Science 99Information relating to student performance is presented in Table 3.8. The question was somewhat difficult. There were two days on which the lowest temperature was 28 degrees F \u2014 Monday and W ednesday. The high temperature on these two days \u2014 43 and 42, respectively \u2014 differed by 1 degree F. In addition, the average wind speed on these two days was 15 mph and 7mph, respectively. Since the question asks about the average windchill temperature, studentshad to realize that the one degree difference in high temperature, is likely less important thanthe 8 mph difference in average wind speed. Thus, the correct response is Monday (option A).Although many students probably knew that they had to evaluate wind speed and temperature,48 percent of the student population chose the day on which the lowest average wind speedoccurred (7 mph), instead of the day with the highest average wind speed (15 mph). Thus, lessthan half the student population (41 percent) was able to evaluate the three pieces ofinformation correctly \u2014 that is, high and low daily temperatures and average wind speed. Response Options A B C D Omit 41 3 48 8 0 TABLE 3.8Percentages Choosing Each Response: Grade 8 Windchill The percentages of students within each achievement level interval who chose the correct answer are presented in table 3.9. The question proved to be somewhat difficult; 57percent of students at the Proficient level answered the question correctly. TABLE 3.9Percentages Correct within Each Achievement Level Interval: Grade 8 Windchill Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 27 39 57 - - - - Sample size insufficient to permit a reliable estimate.100 Student Work & Teacher Practices in ScienceInsulated Bottle The following multiple-choice question was classified under the physical science topic \"Energy and its Transformations. \" It required students to understand how cold liquids are kept cold in an insulated bottle. Information relating to students ' performance is presented in tables 3.10 and 3.11. As can be seen from the results, energy tends to be a very difficult concept for students tounderstand. Just over half of eighth graders (54 percent) thought that cold energy was keptwithin the bottle. Fifteen percent thought the bottle destroyed the heat entering it or that liquidwas kept cold by trapping dissolved air. Thirty-one percent of students thought that theinsulated bottle slowed the transfer of heat into the bottle. The question proved difficult forstudents at all achievement levels. Forty-five percent of students classified as Proficient chose the correct response. Response Options A B C D Omit 5 5 41 03 1 1 NOTE: Numbers do not add to 100 due to rounding. TABLE 3.10Percentages Choosing Each Response: Grade 8 Insulated Bottle TABLE 3.11Percentages Correct within Each Achievement Level Interval: Grade 8 Insulated Bottle Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 20 32 45 - - - - Sample size insufficient to permit a reliable estimate.11. An insulated bottle keeps a cold liquid in a bottle cold by A destroying any heat that enters the bottle B keeping cold energy within the bottle C trapping dissolved air in the liquid D slowing the transfer of heat into the bottle The correct option is D.Student Work & Teacher Practices in Science 101 TABLE 3.13Percentages Correct within Each Achievement Level Interval: Grade 8 Nonrenewable Resource Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 44 63 82 - - - - Sample size insufficient to permit a reliable estimate.Response Options A B C D Omit 61 14 8 17 0 TABLE 3.12Percentages Choosing Each Response: Grade 8 Nonrenewable Resource3. Which of the following energy sources is the best example of a nonrenewable resource? A Coal B Wind C Water D Sunlight The correct option is A.Nonrenewable Resource The next multiple-choice question, also classified under \"Energy and its Transformations, \" asked students to choose the energy source that was nonrenewable from a list of four options. Information on the percentages of students choosing each response is shown in table 3.12. Students had to know the meaning of the word \"nonrenewable \" to answer the question correctly. Sixty-one percent of students chose coal. Thirty-nine percent did not know themeaning of a \"nonrenewable resource \" and chose wind, water, or sunlight, all of them renewable resources. Information on the percentages of students classified within each achievement level interval is presented in table 3.13. Forty-four percent of students who were classified as belowBasic were able to recognize a nonrenewable resource.102 Student Work & Teacher Practices in ScienceMirrors and Windows The following constructed-response question was classified under the physical science topic \"Motion, \" since it required students to know something about the behavior of light. It was designed to find out whether students could explain the difference between mirrors andwindows. /c32Instead of simply asking for differences between mirrors and windows, the question was placed in context \u2014 that is, Sarah asked her brother to explain why she could see herself in a mirror but could see through a window. The question was scored according to a three-levelscoring guide. 5 In order to achieve a score of Complete, students had to address both mirrors and windows. In order to receive a score of Partial , students could address either a mirror or a window. A response that received a score of Unsatisfactory showed no evidence of knowing the difference between a mirror and a window. 6. Raul 's little sister, Sarah, wants to know why she can see herself in a mirror, but she can see through a window. What should Raul tell hissister to explain the differences between mirrors and windows? 5 Appendix B contains scoring guides for the sample questions that appear in this report. 8-30x6. Raul 's little sister, Sarah, wants to know why she can see herself in a mirror, but she can see through a window. What should Raul tell hissister to explain the differences between mirrors and windows?Sample 1: Mirrors and WindowsSample 1: Complete Response In the first sample response, the student addresses the subject of the mirror backing and states that, \"This reflects light and any other object that can be seen. \" The student also states that, \"Glass doesn 't have anything on the back or front that reflects. \" One can assume, therefore, that the student knows that light passes through the window. While a certain amount of light willreflect off the glass, the student was not penalized for omitting this information.Student Work & Teacher Practices in Science 103Sample 2: Partial Response The student in the next sample response states that there was something on the back of the mirror (and not on windows). No mention was made of the reflective properties of mirrors andwindows. Students also received a score of Partial if they stated that light bounces off a mirror but goes through glass. Sample 3: Unsatisfactory Response The next sample response received a score of Unsatisfactory . The student does not appear to understand what the question was asking, merely stating how mirrors and windows were used. 8-32x6. Raul 's little sister, Sarah, wants to know why she can see herself in a mirror, but she can see through a window. What should Raul tell hissister to explain the differences between mirrors and windows?Sample 3: Mirrors and Windows Complete Partial Unsatisfactory Omit 22 86 6 4 TABLE 3.14Percentages at Different Score Levels: Grade 8 Mirrors and WindowsInformation on student performance is presented in table 3.14. The question proved to be very difficult, with just two percent of the eighth-grade population receiving a score ofComplete . Twenty-eight percent received a score of Partial . Sixty-six percent of students were not able to tell any difference between a mirror and a window.8-31x6. Raul 's little sister, Sarah, wants to know why she can see herself in a mirror, but she can see through a window. What should Raul tell hissister to explain the differences between mirrors and windows?Sample 2: Mirrors and Windows 104 Student Work & Teacher Practices in ScienceTable 3.15 shows the percentages of students within each achievement level interval. The question was very challenging. Zero percent of students classified as below Basic,one percent classified as Basic, and four percent classified as Proficient received a scoreof Complete. TABLE 3.15Percentages Complete within Each Achievement Level Interval: Grade 8 Mirrors and Windows Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 014 - - - - Sample size insufficient to permit a reliable estimate. Mitochondrion At the middle school level, the structure and function of cells is an integral part of life science textbooks. The following question asks about the function of a mitochondrion and was classifiedunder the life science topic \"Cells, \" as specified by the framework. 6 10. What does a mitochondrion do in a cell? AIt controls the transport of substances leaving and entering the cell. BIt contains the information to control the cell. CIt produces a form of energy that the cell can use. DIt breaks down waste products in the cell. The correct option is C. 6National Assessment Governing Board. (1995). Science framework for the 1996 National Assessment of Educational Progress. W ashington, DC: Author.Student Work & Teacher Practices in Science 105 TABLE 3.17Percentages Correct within Each Achievement Level Interval: Grade 8 Mitochondria Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 26 29 28 - - - - Sample size insufficient to permit a reliable estimate.Response Options A B C D Omit 27 15 28 30 1 NOTE: Numbers do not add to 100 due to rounding. TABLE 3.16Percentages Choosing Each Response: Grade 8 MitochondriaStudent performance data are presented in table 3.16. This question proved to be very difficult for students and did not discriminate well among students of different ability levels, which might suggest that students were guessing. To answer this question correctly, students could either recognize that mitochondria produce cellular energy or choose the correct option through elimination. For example, they may have recognized that option A refers to the cell membranes, that option B refers to the cell nucleus, and that option D refers to lysosomes.Twenty-eight percent of students answered this question correctly by choosing C. However, choices A and D were also attractive. Choice B attracted only 15 percent of students, presumably because the description referred to the nucleus, the organelle that students are most likely to remember because of its link to genes. As shown in table 3.17, approximately equal percentages of students who were classified as below Basic , Basic , and Proficient answered the question correctly (26, 29, and 28 percent, respectively). Given that students had a 25 percent chance of getting this questioncorrect by guessing and that the percentages of students within each achievement level interval were similar, few students knew the function of a mitochondrion.106 Student Work & Teacher Practices in Science1. A certain organism has many cells, each containing a nucleus. If the organism makes its own food, it would beclassified as Aa bacterium Ba fungus Ca plant Dan animal The correct option is C.Classification The multiple-choice question shown below is classified in the life science topic \"Change and Evolution. \" It measures students ' ability to recognize an organism from its characteristics. Each choice represents one of the major classification groups, namely, bacteria, fungi, plants, and animals. To answer the question correctly, students had to know some of thecharacteristics of each of these groups. For example, they had to know that bacteria are usuallyunicellular and contain no nucleus and that fungi and animals do not make their own food. Thisleaves plants as the only possible answer. As shown in table 3.18, 72 percent of eighth graderswere able to answer this question correctly. Response Options A B C D Omit 14 12 72 2 0 TABLE 3.18Percentages Choosing Each Response: Grade 8 ClassificationStudent Work & Teacher Practices in Science 107The percentages of students in each of the achievement levels that answered the question correctly are shown in table 3.19. The question proved to be fairly easy; 74 percent ofstudents classified as Basic knew the characteristics of a plant. TABLE 3.19Percentages Correct within Each Achievement Level Interval: Grade 8 Classification Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 61 74 84 - - - - Sample size insufficient to permit a reliable estimate.108 Student Work & Teacher Practices in Science7 See figure 1.2 for a description of scientific investigation. 8 Appendix B contains scoring guides for the sample questions that appear in this report.Scientific Investigation7 Thirty-eight of the 194 questions administered to eighth graders in the NAEP 1996 science assessment were classified as scientific investigation. The types of questions asked ranged fromthose requiring students to demonstrate skills such as measurement and graph drawing to thoserequiring students to devise experiments based on given hypotheses. A sample question isshown below. A selection of questions from a hands-on task that also measures scientificinvestigation is presented at the end of this chapter. Hydra The following extended constructed-response question was part of a set of three concerning aclass project using an organism called Hydra . Students were told that the organism was an animal and given a diagram of its appearance as shown below. Data were presented to the students and they were asked a series of three questions based on this data. The first question asked students to explain the changes in appearance andnumber of hydras and tested students ' ability to relate reproduction \u2014 budding \u2014 to increase in population. The second question, shown below, asked students to design an experiment, withappropriate controls, to test the effect of increasing the amount of food on the rate of increase ofthe hydra population. The third question asked students if they thought that the hydrapopulation could double in one day given unlimited food. Only student responses to the secondquestion are shown here. The question was scored according to a four-level scoring guide. 8 Students at the highest level, Complete , had to devise a valid experiment that included more than one hydra and an appropriate control. To achieve a score of Essential , the student response had to include an appropriate control but use only one hydra instead of a number of them. Theresponses that received a score of Partial had some fundamental problems, such as absence of a control and inappropriate amounts of food. A score of Unsatisfactory was given to responses that gave no indication of the ability to set up a controlled experiment.Student Work & Teacher Practices in Science 109Questions 14-16. Hydras are tiny (1-centimeter long ) animals that live in streams and ponds. The picture below shows an adult hydra drawn larger than actual size. Evita and Michael used 20 hydras for a class science project. They kept the hydras in a glass dish about 5 centimeters high, fed them regularly, and bubbled air into thewater to make sure the hydras had enough oxygen. Evita and Michael observed the hydras every day for 10 days. Each day they drew in their lab notebook the appearance of a typical hydra and recorded the total number ofhydras. Their records for day 1, day 4, day 7, and day 10 are shown below. Tentacle BudBodyMouth Opening BudBudDay 1 Day 4 Day 10 Day 7 Population: 20 Population: 20 Population: 20 Population: 40 ART -18a 15. Evita and Michael predicted that if they fed the hydras twice as much food, the population of hydras would double their number in 5 days.Describe an experiment with appropriate controls that Evita and Michaelcould do to test this hypothesis.110 Student Work & Teacher Practices in ScienceSample 1: Complete Response The following sample response received a score of Complete . The student clearly identifies two sets of hydras, one of which is the control group. The food amounts are also correctly stated:\"the normal amount \" and \"twice as much food. \" The response then states \"compare at the end of five days, \" implying that the two sets of hydras should be examined to see whether the population can double in five days when twice the amount of food is fed to them. Sample 2: Essential Response The second sample response received a score of Essential . Students who received this score described a correct experiment except they included only one organism in each group. Thestudent who wrote sample response 2 recognizes that a control is needed but chooses to put onlyone hydra in each group: \"Have two different hydras feed on of the hydras twice as much. And feed the other on the regular amount... \" 15. Evita and Michael predicted that if they fed the hydras twice as much food, the population of hydras would double their number in 5 days.Describe an experiment with appropriate controls that Evita and Michaelcould do to test this hypothesis.Sample 2: Hydra 8-27x 8-26x15. Evita and Michael predicted that if they fed the hydras twice as much food, the population of hydras would double their number in 5 days.Describe an experiment with appropriate controls that Evita and Michaelcould do to test this hypothesis. Sample 1: HydraStudent Work & Teacher Practices in Science 111Sample 3: Partial Response The next sample response received a score of Partial . This student fails to mention a control group, but does understand that the hydras have to be fed twice as much for only five days.Students also received a score of Partial for mentioning two groups of hydras without specifically stating a food amount. 15. Evita and Michael predicted that if they fed the hydras twice as much food, the population of hydras would double their number in 5 days.Describe an experiment with appropriate controls that Evita and Michaelcould do to test this hypothesis.Sample 3: Hydra 8-28x112 Student Work & Teacher Practices in ScienceSample 4: Unsatisfactory Response The following student response received a score of Unsatisfactory . This student states \"feed the hydras only a little bit each day and see how big they are after five days... \" and then suggests increasing the amount a little bit more. This response clearly demonstrates that the studentlacked the knowledge and skills necessary to construct a valid experiment since no attempt wasmade to feed the hydras twice the amount of food. Sample 4: Hydra 8-29x 15. Evita and Michael predicted that if they fed the hydras twice as much food, the population of hydras would double their number in 5 days.Describe an experiment with appropriate controls that Evita and Michaelcould do to test this hypothesis.Student Work & Teacher Practices in Science 113Table 3.20 shows the percentage of students at different score levels. Twelve percent of students were able to answer this completely, suggesting those students understood the purposeof a control and also that more than one hydra was needed in each group. Six percent ofstudents understood the need for a control but failed to realize that a number of hydras wasneeded in each group to make a valid comparison. Thirty percent of students received a score ofPartial. Their answers contained some fundamental errors, such as the lack of a valid control. The 44 percent of eighth graders who were in the category Unsatisfactory were unable to set up a fairly simple experiment based on a hypothesis presented to them. TABLE 3.21Percentages Complete or Essential within Each Achievement Level Interval: Grade 8 Hydra Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 61 5 3 0 - - - - Sample size insufficient to permit a reliable estimate.Table 3.21 shows the percentages of students within each achievement level interval that received a score of Complete or Essential. Overall, students found the question somewhat difficult. Six percent of students classified as below Basic , 15 percent classified as Basic , and 30 percent classified as Proficient were able to construct a valid experiment from a given hypothesis.Complete Essential Partial Unsatisfactory Omit 1 2 6 3 04 41 0 NOTE: Numbers do not add to 100 due to rounding. TABLE 3.20Percentages at Different Score Levels: Grade 8 Hydra114 Student Work & Teacher Practices in SciencePractical Reasoning9 The following sample questions give an indication of the types of questions that were thought to measure practical reasoning. They address subject matter from physical and life science only,since no practical reasoning questions addressing earth science topics were released to the public. Lightbulbs The following short constructed-response question measures whether students knew that heatrequires energy for production. They were asked which of two types of lightbulbs \u2014 incandescent or fluorescent \u2014 would use the least amount of electricity and why. Students did not have to remember the properties of one type of lightbulb versus another; they were told thatfluorescent lightbulbs produced much less heat when operating. The question was scored on athree-level scale. 10 A response that received a score of Complete needed to indicate \"fluorescent lightbulb \" and link heat to energy consumption. To receive a score of Partial , students had merely to state the correct lightbulb with no explanation or an explanation that was faulty. Astudent response that received a score of Unsatisfactory indicated the incorrect lightbulb. 7. When operating, ordinary incandescent lightbulbs produce a lot of heat in addition to light. Fluorescent lightbulbs produce much less heat whenoperating. If you wanted to conserve electricity, which type of bulb shouldyou use? Explain your answer. 9See figure 1.2 for a description of practical reasoning. 10Appendix B contains scoring guides for the sample questions that appear in this report.Student Work & Teacher Practices in Science 1158-19x 7. When operating, ordinary incandescent lightbulbs produce a lot of heat in addition to light. Fluorescent lightbulbs produce much less heat whenoperating. If you wanted to conserve electricity, which type of bulb shouldyou use? Explain your answer.Sample 2: Lightbulbs 8-17x7. When operating, ordinary incandescent lightbulbs produce a lot of heat in addition to light. Fluorescent lightbulbs produce much less heat whenoperating. If you wanted to conserve electricity, which type of bulb shouldyou use? Explain your answer.Sample 1: LightbulbsSample 1: Complete Response The following response received a score of Complete . The student knows that electricity is needed to produce heat and that the incandescent lightbulb uses more electricity because itproduces more heat. Sample 2: Partial Response The next response received a score of Partial . This student chose fluorescent lightbulbs. However, the explanation has to do with safety and does not address conservation of electricity.116 Student Work & Teacher Practices in ScienceSample 3: Unsatisfactory Response The following student response received a score of Unsatisfactory . The student 's answer is based on previous experience. While it relates to saving money, it does not address the issue of energyconservation. 8-20x 7. When operating, ordinary incandescent lightbulbs produce a lot of heat in addition to light. Fluorescent lightbulbs produce much less heat whenoperating. If you wanted to conserve electricity, which type of bulb shouldyou use? Explain your answer.Sample 3: LightbulbsStudent Work & Teacher Practices in Science 117Information relating to student performance is shown in tables 3.22 and 3.23. One third of the eighth-grade population answered the question correctly; that is, they chose fluorescentlightbulbs and correctly linked heat to energy consumption. Thirty-nine percent of studentschose the correct lightbulb but were unable to justify their answers satisfactorily. Twenty-fourpercent of eighth graders chose the incandescent lightbulb. As shown in table 3.23, 15 percent of students classified as below Basic , 34 percent classified as Basic , and 53 percent classified as Proficient were able to choose the correct lightbulb and link heat and energy consumption. TABLE 3.23Percentages Complete within Each Achievement Level Interval: Grade 8 Lightbulbs Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 15 34 53 - - - - Sample size insufficient to permit a reliable estimate.Complete Partial Unsatisfactory Omit 33 39 24 4 TABLE 3.22Percentages at Different Score Levels: Grade 8 Lightbulbs118 Student Work & Teacher Practices in Science11Appendix B contains scoring guides for the sample questions that appear in this report.Heating Rate Prediction An experiment concerning the heating of soil and water was described to students. Students were then presented with two questions. In the first question, students were asked whatvariables needed to be controlled in the experiment. They were then presented with some dataand asked to relate that data to another situation, namely a beach. The second question askedstudents to predict, explain their predictions, and then give reasons why their predictions mightbe faulty. The responses were scored according to a four-level scoring guide. 11 To receive a score of Complete, s tudents had to predict correctly, explain their predictions, and then state why their predictions might be incorrect. For a student response to receive a score of Essential , it had to contain a correct prediction and either explain the prediction or explain why theprediction could be wrong. A response that contained a correct prediction only was given ascore of Partial . Students who were unable to predict or explain were given a score of Unsatisfactory .Student Work & Teacher Practices in Science 119 120 Student Work & Teacher Practices in ScienceSample 1: Complete Response The following sample received a score of Complete . The student predicts that the sand will be hotter, and refers clearly to the experimental data in the explanation. The student then gives anumber of plausible explanations for why the prediction might be wrong, including a constantlymoving ocean and the presence of salt in the ocean. 8-22x Sample 1: Heating Rate PredictionStudent Work & Teacher Practices in Science 1218-25xSample 2: Heating Rate Prediction Sample 2: Essential Response The next sample response received a score of Essential . This student is able to predict and explain the prediction. However, he or she is unable to come up with reasons why the predictionmight be incorrect.122 Student Work & Teacher Practices in ScienceSample 3: Partial Response The following sample response received a score of Partial . The student predicts that the sand would be warmer but does not use the data to explain the prediction. Since the prediction isbased on experimental data, reasons why the prediction might be wrong should have referred tothe experimental conditions that produced the data. 8-24xSample 3: Heating Rate Prediction Student Work & Teacher Practices in Science 123 Sample 4: Heating Rate Prediction 8_23x.tifSample 4: Unsatisfactory Response The next response received a score of Unsatisfactory . The student clearly does not relate any part of the response to the data and thinks that the water will be warmer. Judging from theexplanation, the student has some knowledge of reflective properties but fails to link the answerto the data. The explanation for the prediction was not credited since the prediction is incorrect.124 Student Work & Teacher Practices in ScienceTable 3.24 presents the percentages of students at different score levels. The question proved to be very challenging. The percentage of eighth-grade students that received a score ofComplete was six percent. Thirty-one percent of students were able to look at the data and transfer the information to a different scenario, but were unable to give a satisfactoryexplanation. Thus, they received a score of Partial . Fifty-four percent of students were unable to answer the question. Complete Essential Partial Unsatisfactory Omit 6 6 31 54 4 NOTE: Numbers do not add to 100 due to rounding. TABLE 3.24Percentages at Different Score Levels: Grade 8 Heating Rate Prediction TABLE 3.25Percentages Complete or Essential within Each Achievement Level Interval: Grade 8 Heating Rate Prediction Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 18 2 5 - - - - Sample size insufficient to permit a reliable estimate.The percentages of students within each of the achievement levels that provided a Complete or Essential response are shown in table 3.25. The question was very challenging for students within each of the achievement level intervals. One percent of students classified asbelow Basic , eight percent classified as Basic , and 25 percent classified as Proficient were able to predict and present valid explanations.Student Work & Teacher Practices in Science 125Food Poisoning The purpose of this short constructed-response question was to find out whether eighth graders knew that organisms that cause food poisoning could grow in a potato salad on a hot day, andthat a way of preventing this growth was to keep the salad cold. The question was classifiedunder the life science topic \"Organisms. \" The students were given some information to help them. They were told that the picnic was held on a hot day. They were also told that the saladwas made using mayonnaise. Some may have known that mayonnaise contains eggs as one of its ingredients \u2014 a fairly common source of bacteria. The question was scored using a three-level guide. 12 A response that received a score of Complete had to answer both parts of the question satisfactorily, whereas a response that received a score of Partial gave a correct explanation for only one of the parts. Responses that received a score of Unsatisfactory addressed neither part of the question correctly. 12Appendix B contains scoring guides for the sample questions that appear in this report.13. A group of students took potato salad made with mayonnaise to a picnic on a very hot day. Explain how eating the potato salad couldcause food poisoning. Describe something that could be done to the potato salad to prevent the people who eat it from getting food poisoning.126 Student Work & Teacher Practices in ScienceSample 1: Complete Response The following student response received a score of Complete . The student recognizes that bacteria can grow in the mayonnaise when it gets hot. The student also knows that the saladshould be kept in a cooler at all times. Sample 1: Food Poisoning 8_10x Student Work & Teacher Practices in Science 127Sample 2: Food Poisoning 8_11x Sample 2: Partial Response The next student response received a score of Partial . This student recognizes that the mayonnaise can spoil but fails to state what causes the spoiling. The student does, however,recognize that the salad needs to be kept cold to prevent spoiling. Students also received ascore of Partial if they satisfactorily explained how eating the potato salad could cause food poisoning with no explanation of how to prevent the food poisoning.128 Student Work & Teacher Practices in ScienceSample 3: Unsatisfactory Response The student response shown below received a score of Unsatisfactory . The student states that the mayonnaise in the potato salad will get \"old and shriveld up \" \u2014 maybe meaning dried up \u2014 and \"could cause food poisning. \" This is clearly incorrect. The student made a general statement for the second part of the question and said that the salad should not be exposed\"to the sun. \" Sample 3: Food Poisoning 8_12xStudent Work & Teacher Practices in Science 129 TABLE 3.26Percentages at Different Score Levels: Grade 8 Food Poisoning Complete Partial Unsatisfactory Omit 10 61 26 3 TABLE 3.27Percentages Complete within Each Achievement Level Interval: Grade 8 Food Poisoning Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 28 1 8 - - - - Sample size insufficient to permit a reliable estimate.Student performance data are presented in table 3.26. Ten percent of students knew that the growth of pathogenic organisms caused food poisoning and that keeping the salad coldcould prevent this. Sixty-one percent of students received a score of Partial . The majority of these received credit for the second part of the question; that is, they knew that the potato saladshould be kept cold but did not know why. Twenty-six percent of the eighth-grade studentpopulation received a score of Unsatisfactory . The percentages of students within each of the achievement levels that provided a response of Complete are shown in table 3.27. The question proved to be difficult, with just 2 percent of students classified as below Basic, 8 percent classified as Basic, and 18 percent classified as Proficient receiving a score of Complete .130 Student Work & Teacher Practices in Science7. Hair color in humans is an inherited trait. How is it possible for two people who had brown hair from birth toproduce a child with blond hair?Inheritance The next question asks students to demonstrate an introductory knowledge of genetics in a practical setting. They were told that hair color in humans is an inherited trait, and wereexpected to know the difference between a dominant and recessive trait. They were alsoexpected to know that in order for a recessive trait to be expressed, both parents must pass onthe gene for that trait to their offspring. The question was scored using a three-level guide. 13 To receive a score of Complete , students had to explain that the child inherited recessive genes from its parents. A student response that received a score of Partial had to mention that the trait for blond hair was passed from grandparents to parents to the child. A response thatreceived a score of Unsatisfactory did not demonstrate any understanding of the concept of recessive genes. 13Appendix B contains scoring guides for the sample questions that appear in this report.Student Work & Teacher Practices in Science 1318-14x Sample 1: Inheritance 7. Hair color in humans is an inherited trait. How is it possible for two people who had brown hair from birth toproduce a child with blond hair?Sample 1: Complete Response The first sample response received a score of Complete . This student provides a diagram to aid in the explanation. The parents are shown with genotypes Bb and Bb and a key indicates that Bis brown and b is blond. The explanation states that the blond gene is recessive. The studentalso gives the possible genotypes resulting from this cross, one of which is bb, indicating thepossibility that the parents could have a child with blond hair. This student obviously has a verygood grasp of basic genetics.132 Student Work & Teacher Practices in ScienceSample 2: Partial Response The following sample response received a score of Partial . This student answered the question in general terms, stating, \"Mabee the mother or fathers, mother and fathers had blond hair. \" Sample 3: Unsatisfactory Response The next sample response is an example of a student 's response that shows no understanding of inherited traits.8-15x Sample 2: Inheritance 7. Hair color in humans is an inherited trait. How is it possible for two people who had brown hair from birth toproduce a child with blond hair? 8-16x Sample 3: Inheritance 7. Hair color in humans is an inherited trait. How is it possible for two people who had brown hair from birth toproduce a child with blond hair?Student Work & Teacher Practices in Science 133Table 3.28 presents the percentages of students at each of the different score levels. Four percent of the grade 8 student population received a score of Complete, whereas 60 percent were unable to think of a valid reason why a child could have blond hair when each of its parents hadbrown hair. TABLE 3.28Percentages at Different Score Levels: Grade 8 Inheritance Complete Partial Unsatisfactory Omit 43 06 0 6 TABLE 3.29Percentages Complete within Each Achievement Level Interval: Grade 8 Inheritance Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 028 - - - - Sample size insufficient to permit a reliable estimate.Table 3.29 shows the percentages of students within each achievement level interval. The difficulty of the question is reflected in the data. Zero percent of students classified asbelow Basic , two percent classified as Basic , and eight percent classified as Proficient received a score of Complete on the question.134 Student Work & Teacher Practices in ScienceTheme Block Three of the fifteen 30-minute blocks of questions at the eighth-grade level addressed each of the three themes \u2014 systems, models, and patterns of change \u2014 outlined in the Science Framework for the 1996 National Assessment of Educational Progress.14 Not every student in the assessment was administered one of these theme blocks and no student was administered more than one.These blocks of questions differed from other questions in the assessment in that they probedstudents ' understanding of a given area of science such as the Solar System and afforded students the opportunity to display both breadth and depth of understanding. Other 30-minute blocks ofquestions covered material in earth, physical, and life science and usually not more than one ortwo questions were devoted to any topic. The 12 questions based on the theme \"models \" have been released to the public and can be found on the Internet. 15 Students were presented with a picture illustrating a simplified model of part of the Solar System (shown below). The four planets closest to the Sun wereincluded and the orbit of Earth shown. Students were then asked a series of questions relatingto this model. For example, they were asked to draw in the orbits of the other planets, explainthe differences and similarities between the simplified model of the Solar System and the realSolar System, and explain the difficulties that they would encounter if they attempted to add theother planets to the diagram. In addition, several questions were asked that related to the graphshown on the next page, one of which is presented here. The final question asked students toexplain why seasons occur. That question is also presented in this chapter. The picture below illustrates a simplified model of part of the Solar System. The Sun and the four planets closest to the Sun are represented by the shadedfigures. The Earth 's orbit (the path that it takes as it moves around the Sun) is represented by the large circle and the arrow on this circle shows the directionin which the Earth moves. I II III IV I Mercury II VenusIII EarthIV MarsPlanetsSun 14National Assessment Governing Board. (1995). Science framework for the 1996 National Assessment of Educational Progress. W ashington, DC: Author See figure 1.3 for a description of themes 15National Center for Education Statistics: National Assessment of Educational Progress (1997). Science assessment public release, grade 4 [On-line]. Available: http://nces.ed.gov/naep.Student Work & Teacher Practices in Science 135The planets move at different speeds and require different amounts of time to circle the Sun. The following graph shows the number of Earthdays it takes for each of the four planets to move around the Sun once. 0100200300400500600700800 50 100 150 200 250Time to Move Around the Sun (Earth days) Average Distance from Sun (million kilometers)IIIIIIIV I IIMercury VenusIII IVEarth MarsTheme: Graph Reading The following question was presented to students halfway through the theme block and measured students ' ability to read a graph. The graph showed the time it took planets to move around the Sun (in Earth days) versus the average distance of planets from the Sun. Studentswere asked to indicate which of the four options was a true statement based on the graph.136 Student Work & Teacher Practices in Science8. Based on the graph, which of the following is true? AThe farther a planet is from the Sun, the longer it takes for the planet to move around the Sun. BThe closer a planet is to the Sun, the longer it takes for the planet to move around the Sun. CThe smaller a planet is, the longer it takes for the planet to move around the Sun. DThe larger a planet is, the longer it takes for the planet to move around the Sun. The correct option is A. Performance data are shown in table 3.30. Students found this multiple-choice question relatively easy, as indicated by the 85 percent who chose the correct option \u2014 A. Response Options A B C D Omit 8 5 5542 NOTE: Numbers do not add to 100 due to rounding. TABLE 3.30Percentages Choosing Each Response: Grade 8 Graph Reading TABLE 3.31Percentages Correct within Each Achievement Level Interval: Grade 8 Graph Reading Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 66 95 99 - - - - Sample size insufficient to permit a reliable estimate.The percentages of students in each of the achievement levels that chose the correct option are shown in table 3.31. The question proved to be easy; 95 percent of students at theBasic level were able to interpret the graph correctly.Student Work & Teacher Practices in Science 13712. What additions or changes could be made to this model of the Solar System to best explain why the NorthernHemisphere of the Earth is colder in January than in July?You may draw a picture as part of your answer.Theme /c58/c32Seasons The next question appeared in the last position in the theme block. It asked students to specify what changes had to be made to the model that was initially given to them, and to explain whyJanuary is colder than July in the Northern Hemisphere. Students could draw a picture as partof their answer. However, this was not mandatory. The question was scored according to a three-level scoring guide. 16 A student response that received a score of Complete could draw and/or describe changes to the model. A response that received a score of Partial mentioned the Earth 's tilt but did not elaborate further. A response that received a score of Unsatisfactory showed no understanding of the causes of seasons. 16Appendix B contains scoring guides for the sample questions that appear in this report.138 Student Work & Teacher Practices in ScienceSample 1: Complete Response The first sample response received a score of Complete . This student correctly shows the Earth 's tilt and labels the Earth in summer and winter. The student also includes a description thataddresses direct rays. The response clearly demonstrates understanding of why the Earth iscolder in January than in July. 8-34x Sample 1: Seasons 12. What additions or changes could be made to this model of the Solar System to best explain why the Northern Hemisphere of the Earth is colder in Januarythan in July? You may draw a picture as part of your answer. Sample 2: Partial Response The following response received a score of Partial . This student knows that the tilt of the Earth had something to do with the temperature differential between winter and summer, but fails toexplain it adequately. Sample 2: Seasons 8-35x 12. What additions or changes could be made to this model of the Solar System to best explain why the Northern Hemisphere of the Earth is colder in Januarythan in July? You may draw a picture as part of your answer.Student Work & Teacher Practices in Science 139Sample 3: Unsatisfactory Response Sample response 3 received a score of Unsatisfactory . This particular response fails to show the angle of tilt. In addition, the student thinks that the Earth is closer to the Sun in July than inJanuary, which is incorrect \u2014 the reverse is true. Sample 3: Seasons 8-36x12. What additions or changes could be made to this model of the Solar System to best explain why the Northern Hemisphere of the Earth is colder in Januarythan in July? You may draw a picture as part of your answer.140 Student Work & Teacher Practices in Science TABLE 3.32Percentages at Different Score Levels: Grade 8 Seasons Complete Partial Unsatisfactory Omit 81 27 6 3 NOTE: Numbers do not add to 100 due to rounding. TABLE 3.33Percentages Complete within Each Achievement Level Interval: Grade 8 Seasons Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 16 1 6 - - - - Sample size insufficient to permit a reliable estimate.Performance data are shown in tables 3.32 and 3.33. Eighth graders found the question very challenging. Eight percent of students received a score of Complete , 12 percent a score of Partial, and 76 percent a score of Unsatisfactory . When results are presented by achievement level, 1 percent of students classified as below Basic , 6 percent classified as Basic , and 16 percent classified as Proficient were able to suggest additions or changes to the model to best explain why the Northern Hemisphere of the Earth is colder in January than in July. Hands-on Task Each student who participated in the NAEP 1996 science assessment took one of four hands-ontasks. Each task was designed to use materials to perform an investigation, make observations,record and evaluate experimental results, and apply problem-solving skills. The first page of one of the four tasks presented to students is shown below. It is similar to the one administered tofourth graders, which is discussed in chapter 2; however, the questions asked were moredifficult. For example, students were expected to be able to construct a graph and interpolatefrom that graph. An instrument constructed from a pencil and thumbtack served as a hydrometer in this task. Students were asked to observe, measure, and compare the lengths of a portion of pencil,marked with calibrations for ease of measurement, that floated above the surface in distilledwater and in a 25% salt solution. Based on these observations, the students were asked toStudent Work & Teacher Practices in Science 14117National Center for Education Statistics. National Assessment of Educational Progress. (1997). 1996 science assessment science public release, grade 8 [On-line]. Available: http://nces.ed.gov/naep.predict how the addition of more salt to the salt solution would affect the floating pencil. Students then measured the length of the pencil that floated above the surface of a solution of unknown saltconcentration and used the results of their previous observations to estimate the salt concentrationof the unknown solution. The task assessed students ' abilities to make simple observations, measure length using a ruler, apply observations to an unknown, draw a graph, interpolate from graphical data, andmake a generalized inference from observations. The task also assessed students ' understanding of the value of performing multiple trials of the same procedure. The completetask, scoring guides for each question, and sample student responses can be found on theInternet. 17 SALT SOLUTIONS Estimating the Salt Concentration of an Unknown Salt Solution Using the \"Floating Pencil Test \" For this task, you have been given a kit that contains materials that you will use to perform an investigation during the next 30 minutes. Please open your kit now anduse the following diagram to check that all of the materials in the diagram areincluded in your kit. If any materials are missing, raise your hand and theadministrator will provide you with the materials that you need. Paper Towels Plastic BowlBottle of Distilled WaterGraduated CylinderBottle of 25% Salt SolutionBottle of Unknown Salt SolutionShort Pencil with Thumbtack in Eraser 0123456789101112131415 Metric Ruler142 Student Work & Teacher Practices in Science18Appendix B contains scoring guides for the sample questions that appears in this report.The next diagram shows several questions taken from the task. The first three questions relate to measurement and averages. The last two (12 and 14) relate to graph drawing andinterpolation. These are followed by student responses. Each set of student responses shownbelow belongs to one student. Thus, readers can judge the accuracy of each student 's graphing and interpolation skills. The questions relating to measurement and interpolation were scoredusing four-level scoring guides and the questions relating to average and graphing were scoredusing three-level guides. 18 To receive a score of Complete on the question that assessed measuring skills, students had to show three sets of measurements that agreed within +/- 0.2 cm and the correct relativeorder of pencil heights above each solution had to be correct. (Since the pencils were notuniform in length, the height of different pencils above the same solution varied. Thus,students ' responses were credited for the closeness exhibited between the two measurements taken for each solution and the relative order of pencil heights above each of the threesolutions.) A score of Essential was given to responses that had each pair of measurements within +/- 0.2 cm, but whose relative order was unexpected. A score of Partial was given to those responses that showed two sets of measurements that agreed within tolerance, and a scoreof Unsatisfactory was given to those responses that had one or no sets of measurements that agreed within tolerance. The question that related to calculating averages was scored using a three-level guide. A score of Complete was given to responses that correctly calculated three averages; a response that correctly calculated one or two averages was given a score or Partial . A response that received a score of Unsatisfactory contained no correct averages. The ability to graph was also measured using a three-level guide. A score of Complete meant that students could plot their own data correctly and draw a line between each point.A score of Partial was given for plotting one data point correctly or two data points correctly without connecting them. A score of Unsatisfactory was given to a graph that was incorrectly plotted. The skill of interpolation was measured using a four-level guide. To receive a score of Complete , the student had to indicate a salt concentration that was consistent with the data and correctly explain how the answer was obtained. If the response showed a correct concentrationbut lacked a clear explanation, it received a score of Essential . A score of Partial was given to responses that calculated the salt concentration using proportional reasoning and not a graph.A response received a score of Unsatisfactory if the value for the salt concentration was not consistent with the graph.Student Work & Teacher Practices in Science 143 ss-3144 Student Work & Teacher Practices in ScienceHands-on Task: Salt Solution, Sample Set 1 Sample set 1 shows responses that each received a score of Complete . This student is able to measure and calculate averages accurately. This latter task was somewhat easy because the twomeasurements for each solution were identical. The concentration of salt in the unknown isaccurate (16 percent) and the student gives a good explanation of how to interpolate.Student Work & Teacher Practices in Science 145 14. Based on the graph that you plotted, what is the salt concentration of unknown solution? Explain how you determined your answer. Average Length of Pencil Above Water Surface (cm) % Salt in Water0 5 10 15 20 253.0 2.5 2.0 1.5 0.51.0 8-4x12. On the graph below, plot the average values you obtained for the distilled water and the 25% salt solution. Draw a straight line between the twodata points. Assume that this line represents the relationship between thelength of pencil that is above the water surface and the concentration ofsalt in the water.8-2x Sample Set 1: Salt Solution: Measurement and Average146 Student Work & Teacher Practices in ScienceHands-on Task: Salt Solution, Sample Set 2 Sample set 2 shows responses that demonstrate the skill of graphing only. Only one of the three sets of measurements (the one for distilled water) is within the range of tolerance (agreementbetween the two measurements within +/- 0.2 cm). Therefore, the student received a score ofUnsatisfactory for measuring. The same student is able to calculate one average but is not able to calculate averages that involve fractions. This response received a score of Partial . The student is then able to plot the data correctly, thus receiving a score of Complete for the graph, but is unable to interpolate and admits to guessing.Student Work & Teacher Practices in Science 1478-3x 14. Based on the graph that you plotted, what is the salt concentration of unknown solution? Explain how you determined your answer.12. On the graph below, plot the average values you obtained for the distilled water and the 25% salt solution. Draw a straight line between the twodata points. Assume that this line represents the relationship between thelength of pencil that is above the water surface and the concentration ofsalt in the water.Sample Set 2: Salt Solution: Measurement and Average Average Length of Pencil Above Water Surface (cm) % Salt in Water0 5 10 15 20 253.0 2.5 2.0 1.5 0.51.0 8-5x148 Student Work & Teacher Practices in ScienceHands-on Task: Salt Solution, Sample Set 3 Sample response 3 received a score of Complete on measurement and averaging. This student is unable to graph the data correctly and cannot interpolate, thus receiving a score ofUnsatisfactory for both questions.Student Work & Teacher Practices in Science 149 Average Length of Pencil Above Water Surface (cm) % Salt in Water0 5 10 15 20 253.0 2.5 2.0 1.5 0.51.0 8-7x 14. Based on the graph that you plotted, what is the salt concentration of unknown solution? Explain how you determined your answer.12. On the graph below, plot the average values you obtained for the distilled water and the 25% salt solution. Draw a straight line between the twodata points. Assume that this line represents the relationship between thelength of pencil that is above the water surface and the concentration ofsalt in the water.Sample Set 3: Salt Solution: Measurement and Average150 Student Work & Teacher Practices in ScienceTables 3.34 and 3.35 present student data for the question relating to measurement. Forty-two percent of eighth-grade students were able to measure the height of the pencil abovethe surface of three solutions and thus received a score of Complete . Thirty-nine percent of students classified as below Basic , 61 percent of students classified as Basic , and 77 percent classified as Proficient were able to take duplicate measures that agreed within +/- 0.2 cm. Complete Essential Partial Unsatisfactory Omit 42 16 21 20 1 TABLE 3.35Percentages Complete or Essential within Each Achievement Level Interval: Grade 8 Salt Solution: Measurement Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 39 61 77 \u2014\u2014 - - Sample size insufficient to permit a reliable estimate. TABLE 3.34Percentages at Different Score Levels: Grade 8 Salt Solution: MeasurementStudent Work & Teacher Practices in Science 151 TABLE 3.36Percentages at Different Score Levels: Grade 8 Salt Solution: Average Complete Partial Unsatisfactory Omit 57 22 18 3 TABLE 3.37Percentages Complete within Each Achievement Level Interval: Grade 8 Salt Solution: Average Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 23 65 91 \u2014\u2014 - - Sample size insufficient to permit a reliable estimate.Tables 3.36 and 3.37 show the percentages of students at different score levels and the percentages of students within each achievement level interval for the question that askedstudents to calculate averages. Fifty-seven percent of eighth graders were able to averagecorrectly. In addition, 65 percent of students classified as Basic and 91 percent classified as Proficient were able to calculate averages accurately .152 Student Work & Teacher Practices in ScienceData relating to student performance on graphing are presented in tables 3.38 and 3.39. Twenty-eight percent of students were able to transfer their data to graphs. Forty-two percent ofstudents were not able to perform this skill successfully. Students who were classified as belowBasic found graphing extremely challenging; two percent were able to graph correctly. By contrast, 61 percent of students classified as Proficient were able to graph correctly. TABLE 3.38Percentages at Different Score Levels: Grade 8 Salt Solution: Graphing Complete Partial Unsatisfactory Omit 28 19 42 11 TABLE 3.39Percentages Complete within Each Achievement Level Interval: Grade 8 Salt Solution: Graphing Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 22 1 6 1 \u2014\u2014 - - Sample size insufficient to permit a reliable estimate.Student Work & Teacher Practices in Science 153Tables 3.40 and 3.41 present performance data for the skill of interpolating. Twenty-eight percent of eighth graders were able to interpolate and received a score of Complete or Essential. The question proved very difficult for those students who were below the Basic level or at the Basic level. Three percent of students classified as below Basic and 19 percent classified as Basic were able to find the concentration of salt in the unknown solution using their own data. Complete Essential Partial Unsatisfactory Omit 20 8 16 53 3 TABLE 3.40Percentages at Different Score Levels: Grade 8 Salt Solution: Interpolating TABLE 3.41Percentages Complete or Essential within Each Achievement Level Interval: Grade 8 Salt Solution: Interpolating Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 31 9 5 4 \u2014\u2014 - - Sample size insufficient to permit a reliable estimate.154 Student Work & Teacher Practices in ScienceSummary of Grade 8 Data The data presented in this chapter give an indication of how students in grade 8 perform on science questions that cover a range of topics and make use of a variety of question types. Thequestions presented had to be limited to those that were released to the public. 19 These are fairly representative and do give an indication of the understandings and skills surveyed in theassessment. Similarly, the data for the small group of questions discussed in this chapterrepresent the data seen for the questions as a whole. In general, the multiple-choice questionsthat required students to know facts, such as the function of a mitochondrion or the meaning ofwindchill, or concepts such as energy were more difficult than those that asked for skills suchas simple graph reading. Constructed-response questions that required students to demonstratetheir understanding of concepts such as seasons and behavior of light also proved very difficult,whereas skills such as measuring and simple averaging were somewhat less difficult. \u007fThe amount of exposure to the different fields of science was not associated with differences in the composite, life science, earth science, or physical science averagescale scores of students or the percentage of students at or above Proficient . For example, students whose teachers reported that they spent little time on physicalscience performed as well on physical science questions as did students whoseteachers reported that they spent a lot of time on physical science. \u007fMale students had a higher average question score than female students for questions that measured physical science and earth science. \u007fWhite students and Asian/Pacific Islander students had a higher average question score than Black and Hispanic students for questions that measured earth science,physical science, and life science. \u007fMale students had a higher average question score than female students for questions that measured conceptual understanding. \u007fWhite students and Asian/Pacific Islander students had a higher average question score than Black and Hispanic students for questions that measured conceptualunderstanding and scientific investigation. \u007fThe percentage of students who gave correct responses to the multiple-choice questions discussed in this chapter ranged from 28 percent to 85 percent. \u007fThe percentage of students who received a score of Complete on the constructed- response questions discussed in this chapter ranged from 2 percent to 57 percent. 19National Center for Education Statistics, National Assessment of Educational Progress. (1997). 1996 science assessment public release, grade 8. [On-line]. Available; http://nces.ed.gov/naep.Chapter 4 Student Work & Teacher Practices in Science 155Grade 12: Performance, Knowledge, and Skills Introduction The NAEP 1996 science assessment was administered nationally to grade 12 students. The assessment was constructed according to specifications in the Science Framework for the 1996 National Assessment of Educational Progress .1 Each question in the assessment was classified as either earth, physical, or life science. (A description of the fields of science can be found inChapter 1) The amount of time specified for each field of science was approximately equal. Forthe ways of knowing and doing science, the specifications state that 45 percent of assessmenttime should be spent on conceptual understanding, 30 percent on scientific investigation, and25 percent on practical reasoning. As with questions in the fourth- and eighth-gradeassessments, each grade 12 question was classified as measuring one of the elements ofknowing and doing science within one of the fields of science (for example, scientificinvestigation in the context of life science). The number of multiple-choice, short-constructedresponse, and extended constructed-response questions in each of the content and cognitivedomains is presented in table 4.1. There were 70 multiple-choice questions and 120constructed-response questions in the grade 12 NAEP science assessment. Each constructed-response question had its own unique scoring guide that defined the criteria used to evaluate students ' responses. 2 Short constructed-response questions were usually scored according to three levels of performance: Complete , Partial , and Unsatisfactory ; however, some of them were scored as either right or wrong ( Complete or Unsatisfactory ). Extended constructed-response questions were usually scored according to four levels ofperformance: Complete , Essential , Partial , and Unsatisfactory . In a few instances, however, five- and six-level scoring guides were used. In total, 242,104 student responses were scored. Thisincluded the 25 percent of responses that were scored twice to monitor the reliability of thescoring process. 3 The scoring process is described in more detail in appendix A. 1National Assessment Governing Board. (1995). Science framework for the 1996 National Assessment of Educational Progress . W ashington, DC: Author. 2Appendix B contains scoring guides for the sample questions that appear in this report. 3For grade 12, the percentage agreement for the 1996 reliability sample was 94 percent. This means that the scores of the first and second scorers agreed 94 percent of the time.156 Student Work & Teacher Practices in ScienceDistribution of Questions by Fields of Science and by Ways of Knowing and Doing Science, Grade 12: Public and Nonpublic Schools CombinedTABLE 4.1 Short Constructed- Extended Constructed- Multiple-Choice Response Response Total SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Fields of Science Earth Science 22 33 9 64 Life Science 22 34 10 66 Physical Science 26 23 11 60 Total 70 90 30 190 Knowing and Doing Conceptual Understanding 62 43 9 114 Scientific Investigation 3 22 12 37 Practical Reasoning 5 25 9 39 Total 70 90 30 190 As part of the NAEP 1996 science assessment, students and school administrators answered questions relating to science course work and graduation requirements. The resultsgive an indication of the current status of science education in the United States and provide acontext for understanding students ' performance vis- \u00e0-vis the number and types of science courses taken. For example, analyses of data from the NAEP 1996 science assessment showthat students who took courses in biology, chemistry, and physics outperformed students whodid not take these three courses. In particular, physics appeared to be a critical course; studentswho took any combination of subjects that included physics outperformed their peers who didnot take physics as one of their courses. 4 However, data also show that 96 percent of students completed course work in biology, 74 percent in chemistry, and 41 percent in physics.5 The relatively low percentage of students taking physics can be explained in a number of ways. Although students may either choose or be advised not to take physics, graduationrequirements and prerequisites also play a role. Sixty-three percent of students attendedschools or districts having a two-year science requirement for graduation, and while manystudents took more science courses, 41 percent reported having taken two years or less ofscience. Since physics is generally not offered as a first- or second-year course, these studentswere unlikely to take physics as one of their two requirements for graduation. 6 Furthermore, many students are not able to take physics because they have not fulfilled the mathematics 4O'Sullivan, C. Y., Weiss, A. R., & Askew, J. M. (1998). Students learning science: A report on policies and practices in U.S. schools . (NCES Publication No. 98-493). W ashington, DC: National Center for Education Statistics. 5Ibid. 6Ibid. National Center for Education Statistics, National Assessment of Educational Progress. (1997). 1996 Science assessment summary data tables [On-line]. Available: http://nces.ed.gov/naep/tables96/index.html.Student Work & Teacher Practices in Science 1577O'Sullivan, C. Y., Weiss, A. R., & Askew, J. M. (1998). Students learning science: A report on policies and practices in U.S. schools . (NCES Publication No. 98-493). W ashington, DC: National Center for Education Statistics.requirements imposed by many schools for entry into the course. Students may, therefore, take more than two years of science, but will often take courses other than physics, such as advancedbiology or science and technology. Additional data collected during the 1996 assessment indicated that 32 percent of students in grade 12 had completed course work in biology, chemistry, and physics. 7 The data also showed that 46 percent of students were no longer enrolled in a science course when theywere administered the NAEP 1996 science assessment. Average Question Score The average question scores for earth science, physical science, and life science questions arepresented in table 4.2. For all students 0.42 was the average question score for both earthscience and physical science questions. The average question score for life science questionswas 0.40. Readers are cautioned not to make comparisons among the fields of science for anygroup of student. V ariations may, for example, be due to the particular make-up of the set ofquestions administered and could well not hold if students were administered a different set ofquestions covering the same fields of science. Comparisons can be made, however, among thedifferent groups of students and several differences were found. Male students had a higheraverage question score than female students on earth science and physical science questions.The performance of White students on earth, physical, or life science questions was higher thanthe performance of Black and Hispanic students in these same fields of science. In addition,White students outperformed Asian/Pacific Islander students for the questions that measuredphysical science. Asian/Pacific Islander students had higher average question scores thanBlack and Hispanic students on questions that measured earth, physical, and life science andHispanic students had a higher average question score than Black students on questions thatmeasured earth science. Average Question Score for Earth Science, Physical Science, and Life Science, Grade 12: Public and Nonpublic Schools CombinedTABLE 4.2 Earth Science Physical Science Life Science NOTE: White refers to White (not Hispanic), and Black refers to Black (not Hispanic). SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.All Islander Student Work & Teacher Practices in ScienceAverage Question Score for Conceptual Understanding, Scientific Investigation, and Practical Reasoning, Grade 12: Public and Nonpublic Schools CombinedTABLE 4.3 Conceptual Scientific Practical Understanding Investigation Reasoning NOTE: White refers to White (not Hispanic) and Black refers to Black (not Hispanic). SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.All Students 0.42 0.45 0.35 Pacific Islander 0.41 0.46 0.34Table 4.3 shows the average question score for questions that measured conceptual understanding, scientific investigation, and practical reasoning. For all students, the averagequestion scores for questions measuring conceptual understanding, scientific investigation, andpractical reasoning were 0.42, 0.45, and 0.35, respectively. Again readers are cautioned not tocompare the performance among the ways of knowing and doing science since studentperformance may have varied if different sets of questions had comprised these categories.When the data for the different groups of students within each way of knowing and doingscience are examined, however, several differences emerge. Male students had a higher averagequestion score than female students for questions that measured conceptual understanding andpractical reasoning. For questions that measured conceptual understanding and scientificinvestigations, White students outperformed Black, Hispanic, and Asian /Pacific Islanderstudents, Hispanic and Asian/Pacific Islander students outperformed Black students, andAsian/Pacific Islander students outperformed Hispanic students. For questions that measuredpractical reasoning, White students outperformed Black, Hispanic, and Asian/Pacific Islanderstudents, and Asian/Pacific Islander students outperformed Black and Hispanic students.Student Work & Teacher Practices in Science 159TABLE 4.4 Earth Science Physical Science Life Science Conceptual Understanding Scientific Investigation Practical ReasoningSample Questions Categorized by Fields of Science and by Ways of Knowing and Doing Science, Grade 12: Public and Nonpublic Schools Combined NOTE: \"mc\" indicates a multiple choice question; \"scr\" indicates a constructed-response question; and \"ecr\" indicates extended constructed-response ring of fire (ecr)Theme: Cloud formation(scr) Theme: Identification of ocean and lake water (ecr) Flooding (scr)Path on ice (mc) Object with greatest mass(mc)Theme: andevaporation materials (ecr)Task: (ecr) Keeping ice cream cold (scr)Genotype (ecr) from results (mc) Malaria (scr) Heart disease (scr) 8Allen, N. L., Carlson, J., & Zelenak, C. A. (in press) The NAEP 1996 Technical Report. W ashington, DC: National Center for Education Statistics.Sample Questions and Student Responses The following section contains sample questions for each of the major fields of science (earth, physical, and life science). Table 4.4 summarizes the classification of these questions. Somequestions can be classified in more than one field of science or way of knowing and doingscience. For the purposes of test construction and analysis, however, the classification had to belimited to one field of science and one way of knowing and doing science. As in chapters 2 and3, the questions are organized by ways of knowing and doing science. The theme block andhands-on task are discussed separately since each was administered to students as a unit. Two tables displaying data are included with each question. For multiple-choice questions, the first table shows the percentage of students choosing each response and thesecond table shows the percentages correct within each achievement-level interval. Forconstructed-response questions, the first table shows the percentages of students at differentscore levels and the second shows the percentages of students that received a score of Complete (or Essential or higher in the case of extended constructed-response questions) within each achievement -level interval. In this chapter, the tables showing percentages of students within each achievement-level interval do not contain data in the column labeled \"Advanced \" because the number of students classified as Advanced was too small to permit a reliable estimate. 8160 Student Work & Teacher Practices in ScienceConceptual Understanding9 The NAEP 1996 science assessment administered at grade 12 contained 190 questions. One hundred and fourteen of these addressed conceptual understanding. A selection of questionsfollows. These questions measure understanding of basic facts and concepts taken from thefields of earth science, physical science, and life science. Solar Eclipse The first multiple-choice question is classified under the earth science topic \"Earth in Space. \" To answer this question correctly, students had to recognize the next stage in the progression ofa solar eclipse. In addition, students had to recognize the direction the Moon takes as it passesdirectly between the Earth and the Sun. The correct option is C.ART - 20-A 9See figure 1.2 for a description of conceptual understanding.Student Work & Teacher Practices in Science 161 TABLE 4.6Percentages Correct within Each Achievement Level Interval: Grade 12 Solar Eclipse Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 69 86 92 - - - - Sample size insufficient to permit a reliable estimate.Response Options A B C D Omit 5 3 80 11 1 TABLE 4.5Percentages Choosing Each Response: Grade 12 Solar EclipseStudent performance data for this question are shown in table 4.5. The question was fairly easy for twelfth-grade students. Eighty percent chose the correct option, C. A smallpercentage of students chose one of the three incorrect options, A, B, or D. The most attractiveof these was D. The percentage of students within each of the achievement level intervals that successfully answered the question is shown in table 4.6. Sixty-nine percent of studentsclassified as below Basic and 86 per cent classified as Proficient answered the question correctly.162 Student Work & Teacher Practices in SciencePacific Ring of Fire The purpose of this extended constructed-response question was to find out whether students knew that volcanic activity and earthquakes usually occurred at the boundaries of tectonicplates. It was classified under the earth science topic \"Solid Earth. \" The question explained where the Ring of Fire is located and then asked students to link this area with volcanic activityand earthquakes. To answer this question satisfactorily, students had to have some knowledge ofthe tectonic plate theory. The responses were scored according to a four-level scoring guide. 10 Students at the highest level, Complete , had to include in their responses the notion of volcanic activity and earthquakes being caused by the relative movement of tectonic plates diverging,converging, or sliding past each other. To achieve a score of Essential, a student had to mention the relative movement of plates or link the movement of plates to activity. A score of Partial was given to responses that merely stated \"plates \" or \"movement \" without adequate explanation. A response that received a score of Unsatisfactory demonstrated no knowledge of plate movement as a cause of volcanic activity or earthquakes. 6. The Pacific Ring of Fire is a belt-shaped region that roughly coincides with the seacoasts bordering the Pacific Ocean. Explain why volcanicactivity and earthquakes occur frequently in this region. 10Appendix B contains scoring guides for the sample questions that appear in this report.Student Work & Teacher Practices in Science 16312-23x Sample 1: Pacific Ring of Fire 6. The Pacific Ring of Fire is a belt-shaped region that roughly coincides with the seacoasts bordering the Pacific Ocean. Explain why volcanicactivity and earthquakes occur frequently in this region.Sample 1: Complete Response The first sample response received a score of Complete . The student links the relative movement of plates to volcanic activity and earthquakes. Although the response does not use the technicallanguage associated with movement, the response does imply that \"divergent \" movement is taking place and that this movement leaves an open area where lava builds up, \"causing a volcano. \" 12-24xSample 2: Pacific Ring of Fire 6. The Pacific Ring of Fire is a belt-shaped region that roughly coincides with the seacoasts bordering the Pacific Ocean. Explain why volcanicactivity and earthquakes occur frequently in this region.Sample 2: Essential Response The second sample response received a score of Essential . This student clearly links movement of plates to volcanic activity and earthquakes \u2014 \"Two large plates are running into each other \" \u2014 but does not describe the movement in any detail.164 Student Work & Teacher Practices in Science12-25xSample 3: Pacific Ring of Fire 6. The Pacific Ring of Fire is a belt-shaped region that roughly coincides with the seacoasts bordering the Pacific Ocean. Explain why volcanicactivity and earthquakes occur frequently in this region. 12-26x Sample 4: Pacific Ring of Fire 6. The Pacific Ring of Fire is a belt-shaped region that roughly coincides with the seacoasts bordering the Pacific Ocean. Explain why volcanicactivity and earthquakes occur frequently in this region.Sample 3: Partial Response The student in the next sample merely states that, \"this is where two plates of the earth come together. \" This explanation was considered to be too general because the student did not indicate that the plates were indeed moving in some way. Thus, it received a score of Partial . Sample 4: Unsatisfactory Response The next sample shows a typical response that received a score of Unsatisfactory . This student thinks that water movement from the Pacific Ocean causes the level of the underground surfaceto shift, producing volcanic activity and earthquakes.Student Work & Teacher Practices in Science 165Table 4.7 presents the percentages of students at each of the score levels. The item proved to be difficult. Four percent of twelfth graders were able to give a fairly full explanation as to why volcanic activity and earthquakes frequently occur in a given region. Forty-eight percentof students knew that the activity had something to do with \"plates. \" The remaining 34 percent gave an incorrect answer to the question. In addition, the omit rate for this question was veryhigh, 15 percent, suggesting that many students thought the question was too hard to attempt toanswer. TABLE 4.8Percentages Complete or Essential within Each Achievement Level Interval: Grade 12 Pacific Ring of Fire Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 10 32 63 - - - - Sample size insufficient to permit a reliable estimate.Complete Essential Partial Unsatisfactory Omit 4 2 62 23 41 5 TABLE 4.7Percentages at Different Score Levels: Grade 12 Pacific Ring of Fire Table 4.8 presents the percentages of students within each achievement level interval that received a score of Complete or Essential . Ten percent of students classified as below Basic , 32 percent classified as Basic , and 63 percent classified as Proficient were at least able to explain the relative movement of plates or link the movement of plates to activity.Insert Table 4.8Note: Numbers do not add to100 due to rounding.166 Student Work & Teacher Practices in SciencePath on Ice The next multiple-choice question was classified under the physical science topic \"Motion. \" The diagram depicts a car that is traveling around a curve onto ice. The question asks studentsto choose from four options which path the car is most likely to take on the ice. Students weretold that the frictional force on the tires was reduced to zero. To answer this question correctly,students had to understand the meaning of the word \"friction \" and realize that the car 's tires would no longer grip and the car would, therefore, continue on the path it was taking when itencountered the ice. 2. A car initially travels with constant speed around a tight, unbanked curve in a circular arc with center X, as shown in the diagram above. At position P, the car encounters a patch of ice, which reduces the frictional force on the tires to zero. Which of the following best shows the path that the car takes while it is on the ice? A A B B C C D D The correct option is C.ART - 25aXIce No IceAIceC BD PStudent Work & Teacher Practices in Science 167Response Options A B C D Omit 5 2 65 41 5 0 TABLE 4.9Percentages Choosing Each Response: Grade 12 Path on Ice TABLE 4.10Percentages Correct within Each Achievement Level Interval: Grade 12 Path on Ice Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 38 59 76 - - - - Sample size insufficient to permit a reliable estimate.The percentages of students choosing each response are shown in table 4.9. Fifty-four percent of grade 12 students answered the question correctly. Options B and D were alsoattractive to students. Students who chose option B thought that the car would veer to the left;those who chose option D thought the car would continue in its circular path. The percentages of students within each of the achievement level intervals are presented in table 4.10. Thirty-eight percent of students classified as below Basic and 59 percent classified as Basic recognized the correct path a car took on ice.168 Student Work & Teacher Practices in ScienceInterpretation of Velocity/Time Graph The question shown below required students to infer from a graph of velocity as a function of time which object had the greatest mass. It was classified under the physical science topic\"Motion. \" To answer this question correctly, students had to realize that the object with the greatest mass would have the least velocity because the same net force was applied to eachobject. They also had to understand the meaning of the word \"velocity \" and be able to recognize that as time increased so too did velocity. ART - 22a10. A graph of velocity as a function of time when the same net force is applied to three different objects is shown below. Which object has the greatest mass? A A B B C C D They all have the same mass. The correct option is C.Velocity Time0A B CStudent Work & Teacher Practices in Science 169 TABLE 4.12Percentages Correct within Each Achievement Level Interval: Grade 12 Interpretation of Velocity/Time Graph Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 27 63 87 - - - - Sample size insufficient to permit a reliable estimate.Information relating to student performance is presented in tables 4.11 and 4.12. Fifty- three percent of students answered the question correctly. Twenty-two percent thought that allthe objects had the same mass, despite the evidence that each object was accelerating at adifferent rate. The achievement level data show that 87 percent of students classified asProficient answered the question correctly. Twenty-seven percent of students classified as below Basic were also able to answer the question correctly. Response Options A B C D Omit 15 9 53 22 1 TABLE 4.11Percentages Choosing Each Response: Grade 12 Interpretation of Velocity/Time Graph170 Student Work & Teacher Practices in ScienceGenotype In the example shown below, students were told the phenotype for earlobes of a mother, father, and their children. They were then asked to predict the genotype of the father and to supplyadditional information to support their prediction if they thought it was needed. This questionrequired knowledge of a number of principles key to the understanding of genetics. Studentshad to understand the meaning of the terms \"dominant, \" \"recessive, \" and \"genotype, \" and also had to be able to perform a simple genetic cross based on information that was given to them.While the convention for representing genetic crosses is usually the Punnett square, studentsdid not have to conform to this. The question deliberately did not ask for the Punnett square,but merely for a diagram to support students ' predictions. The question was scored using a four- level scoring guide. 11 To receive a score of Complete a student had to address the three parts of the question by providing a correct prediction, a supporting diagram, and some additionalinformation that would help support the prediction. Students could have made one of severalpredictions. For example, they could have chosen the most likely situation (given thephenotypes of the 5 children) in which the trait for free earlobes is dominant. Thus, thegenotype of the father could be FF or Ff. If the genotype were FF, then all the offspring wouldhave free earlobes; if the genotype were Ff, the offspring would have a 50/50 chance ofacquiring free earlobes. However, given the phenotypes of the children (all free earlobes), thegenotype FF may be more likely. Students could also have decided that attached earlobes weredominant. In this situation, the father 's genotype would have to be ff and mother 's genotype Ff. In this case the children would also have a 50/50 chance of receiving the trait for free earlobes. The question also asked what further information might be needed to support the prediction. Several student responses were accepted. For example, students could have statedthat it would be helpful to know the genotype or phenotype of the father 's parents, or they could have talked about the need for a sixth child. If this child had attached earlobes, then thefather 's genotype would have to be Ff. Also, they could have explained that the genes for types of earlobes could be mapped and the DNA sequence determined \u2014 thus giving a definitive answer to the prediction. A score of Essential addressed two of the three parts of the question, and a score of Partial addressed one of the three parts. Students receiving a score of Unsatisfactory did not correctly answer any part of the question. 11Appendix B contains scoring guides for the sample questions that appear in this report.Student Work & Teacher Practices in Science 171 12-23xSample 1: Genotype 16. A mother with attached earlobes and a father with free earlobes have 5 children \u2014 4 boys and 1 girl. All of the children have the father 's type of earlobes. What can be predicted about the genotype of the father? Construct a genetic diagramto support your prediction. What additional information, if any, would you needto determine the genotype of the father? Explain.16. A mother with attached earlobes and a father with free earlobes have 5 children \u2014 4 boys and 1 girl. All of the children have the father 's type of earlobes. What can be predicted about the genotype of the father? Construct a genetic diagramto support your prediction. What additional information, if any, would you needto determine the genotype of the father? Explain. Sample 1: Complete Response The first sample response received a score of Complete . Although the student uses an incorrect term \u2014 \"homogeneous \" instead of \"homozygous \" \u2014 it is clear from the diagram that free earlobes are dominant, since the student has used the typical convention of genetic crosses: acapped letter for dominant and an uncapped letter for recessive genes. The student also clearlystates that the genotype of the father 's parents would be needed to prove the genotype of the father.172 Student Work & Teacher Practices in ScienceSample 2: Essential Response Sample response 2 received a score of Essential . This student states \"E\" for the genotype but then makes it clear in the diagram that it is in fact \"EE.\" Thus, the father 's genotype is predicted and evidence for the prediction is given in a Punnett square. The student fails,however, to mention what further information might be needed to support the prediction. 12-12xSample 3: Genotype 16. A mother with attached earlobes and a father with free earlobes have 5 children \u2014 4 boys and 1 girl. All of the children have the father 's type of earlobes. What can be predicted about the genotype of the father? Construct a genetic diagramto support your prediction. What additional information, if any, would you needto determine the genotype of the father? Explain.Sample 3: Partial Response Sample response 3 received a score of Partial . Here the student predicts that the \"father 's gene's are more dominate over the mothers, \" but gives no further details.12-9xSample 2: Genotype 16. A mother with attached earlobes and a father with free earlobes have 5 children \u2014 4 boys and 1 girl. All of the children have the father 's type of earlobes. What can be predicted about the genotype of the father? Construct a genetic diagramto support your prediction. What additional information, if any, would you needto determine the genotype of the father? Explain.Student Work & Teacher Practices in Science 173Sample 4: Unsatisfactory Response The last example received a score of Unsatisfactory . The student clearly does not understand the concepts needed to answer the question and writes instead in general terms aboutbloodlines. Complete Essential Partial Unsatisfactory Omit 3 1 64 33 6 2 TABLE 4.13Percentages at Different Score Levels: Grade 12 GenotypeTable 4.13 presents the percentages of twelfth graders at the different score levels. The question was very difficult. Nineteen percent of students had a solid understanding of basicgenetics. Forty-three percent had a minimal understanding and received a score of Partial . Thirty-six percent of students received a score of Unsatisfactory . 12-11xSample 4: Genotype 16. A mother with attached earlobes and a father with free earlobes have 5 children \u2014 4 boys and 1 girl. All of the children have the father 's type of earlobes. What can be predicted about the genotype of the father? Construct a genetic diagramto support your prediction. What additional information, if any, would you needto determine the genotype of the father? Explain.174 Student Work & Teacher Practices in Science TABLE 4.14Percentages Complete or Essential within Each Achievement Level Interval: Grade 12 Genotype Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 51 8 3 7 - - - - Sample size insufficient to permit a reliable estimate.The percentages of students within each achievement level that received a score of Complete or Essential are shown in table 4.14. The data show that despite the difficulty of the question, five percent of students classified as below Basic were able to answer the question fully. This can probably be explained by the fact that simple genetic crosses are usually a corecomponent of any high school biology course and, according to data collected during the NAEP1996 science assessment, 96 percent of all twelfth-grade students had taken a course inbiology. 12 12O'Sullivan, C.Y., W eiss, A .R. and Askew, J.M. (1998). Students learning science: A report on policies and practices in U.S. schools . (NCES Publication No. 98-493) W ashington, DC: National Center for Education Statistics.Student Work & Teacher Practices in Science 175ART - 19a4. A laboratory technician places red blood cells into three different solutions.Observations are recorded each minute for five minutes. Solution Solution 1 Solution 2 Solution 31 min. 2 min. 3 min. 4 min. 5 min. No change Cells are slightlylarger.Cells are muchlarger.Cells are huge.Cells are gone. No change No change No change No change No change No change Cells are slightlysmaller.Cells are muchsmaller.Cells lookwilted.Nothing that lookslike acell can befound.Time The laboratory technician concludes that red blood cells cannot function in any fluid except serum. Which of the following best characterizes thisconclusion? AIt is accurate on the basis of the information given. B It is accurate because the cells changed in all the solutions but one. C It is inaccurate because the cells were outside the body. D It cannot be substantiated with the data provided. The correct option is D.Scientific Investigation13 Thirty-seven questions of the 190 that make up the NAEP 1996 science assessment for grade 12 measure the knowledge and skills that comprise scientific investigation. One of thequestions classified as scientific investigation is shown below. Questions that measurescientific investigation can also be found in the section describing the hands-on task\"Separation. \" Concluding from Results One of the skills necessary for scientific investigation is the ability to draw valid conclusions from results. The sample below displays a table that shows what happens to red blood cellswhen they are placed in three different solutions. Based on the results, the technicianconcluded that the red blood cells could not function in any fluid except serum. Students wereasked to choose from among four statements that related to the accuracy of this conclusion. 13 See figure 1.2 for a description of scientific investigation.176 Student Work & Teacher Practices in ScienceInformation on student performance is presented in table 4.15. This question proved to be somewhat difficult. To answer this question correctly, students had to examine eachstatement vis- \u00e0-vis the table. The only conclusion that could be drawn from the table was that the cells in solution 2 did not change, whereas those in solutions 1 and 3 did change, one set ofred blood cells becoming larger and the other becoming smaller. The technician, however,extrapolated from the behavior of the cells in three solutions to the universe of solutions. Thus,options A and B are incorrect. However, they drew 13 percent and 32 percent of twelfth graders,respectively. Eleven percent of students chose option C. This statement questioned theconclusion on the grounds that the experiment was conducted outside the body. Forty-threepercent chose the correct answer; the technician had made a conclusion that could not besubstantiated with the data provided. Response Options A B C D Omit 13 32 11 43 1 TABLE 4.15Percentages Choosing Each Response: Grade 12 Concluding from Results TABLE 4.16Percentages Correct within Each Achievement Level Interval: Grade 12 Concluding from Results Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 30 49 57 - - - - Sample size insufficient to permit a reliable estimate.The percentages of students within each of the achievement levels that answered the question correctly are shown in table 4.16. Thirty percent of students classified as below Basic , 49 percent classified as Basic , and 57 percent classified as Proficient were able to evaluate a conclusion based on a set of results.Student Work & Teacher Practices in Science 177Practical Reasoning14 The 1996 NAEP science assessment at grade 12 contained 39 questions that measured the ability of students to apply scientific understanding to everyday situations. A selection of thesequestions appears below. They are set in the context of earth science, physical science, or lifescience. Flooding The first short constructed-response question is set in the context of earth science. Studentswere asked to think of reasons why soil on a farm should be tested after a major flood. While thequestion did not require students to know fundamental scientific facts, they did have torecognize that factories and farms were sources of pollution. They also had to recognize thatwater washes away topsoil and leaches out nutrients necessary for plant growth. This questionwas scored according to a three-level scoring guide. 15 A score of Complete was given for two flood-related reasons for testing the soil, and a score of Partial was given for one flood-related reason. Incorrect reasons were given a score of Unsatisfactory . 14See figure 1.2 for a description of practical reasoning. 15Appendix B contains scoring guides for the sample questions that appear in this report.5. You live along a major river, and your farm was flooded this spring. There are many larger farms and a few factories upriver that were also flooded.Provide two flood-related reasons for testing your soil before planting thisyear.178 Student Work & Teacher Practices in ScienceSample 2: Flooding 12-18x5. You live along a major river, and your farm was flooded this spring. There are many larger farms and a few factories upriver that were also flooded.Provide two flood-related reasons for testing your soil before planting thisyear.Sample 1: Complete Response The first sample received a score of Complete . This student clearly states, \"to make sure there are no toxins in the soil from the factories \" and also understands that it would be important to know \"if the nutrients are still in the soil. \" Thus the student has provided two flood-related reasons for testing the soil. Sample 2: Partial Response Sample response 2 is a more general answer. However, the student does realize that because\"the factories could have contaminated the water in the river, \" the soil might also have become contaminated. The student, therefore, was credited with one valid reason and received a scoreof Partial .12-16xSample 1: Flooding 5. You live along a major river, and your farm was flooded this spring. There are many larger farms and a few factories upriver that were also flooded.Provide two flood-related reasons for testing your soil before planting thisyear.Student Work & Teacher Practices in Science 179 12-17xSample 3: Flooding 5. You live along a major river, and your farm was flooded this spring. There are many larger farms and a few factories upriver that were also flooded.Provide two flood-related reasons for testing your soil before planting thisyear.Sample 3: Unsatisfactory Response The following response received a score of Unsatisfactory . Although this student mentions \"river\" and \"factories, \" he or she failed to indicate why these might cause problems for crop growth. The percentages of students who attained the different score levels are presented in table 4.17. Seventy-two percent of students were able to think of a least one flood-relatedreason why soil should be tested before planting. TABLE 4.18Percentages Complete within Each Achievement Level Interval: Grade 12 Flooding Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 13 37 55 - - - - Sample size insufficient to permit a reliable estimate.Achievement level data (table 4.18) show that 55 percent of students classified as Proficient provided a complete response to the question. The question also proved accessible to students who were classified as below Basic : 13 percent of these students received a score of Complete .Complete Partial Unsatisfactory Omit 32 40 20 8 TABLE 4.17Percentages at Different Score Levels: Grade 12 Flooding180 Student Work & Teacher Practices in ScienceKeeping Ice Cream Cold The next question asks students how they could keep ice cream below 0 degrees C for several hours. The question was classified under the physical science category \"Matter and its Transformations. \" To answer this question correctly, students had to realize that placing the ice cream in ice would not keep the ice cream colder than 0 degrees C for several hours.Substances that have temperatures lower than 0 degrees C, such as dry ice, would have to beutilized, or substances such as rock salt would have to be added to ice to lower the meltingpoint of ice, thus increasing the cooling effect on the ice cream. Responses were scored using athree-level scoring guide. 16 A student had to choose a correct method and explain how it worked to receive a score of Complete . A response that received a score of Partial mentioned a method that would work but had no adequate explanation. A score of Unsatisfactory was given to student responses that attempted the question but failed to answer any part of it correctly. 6. You are taking ice cream in a cooler to a picnic and want to keep the ice cream colder than 0 \u00b0C for several hours. How could you do this? 12-27xSample 1: Keeping Ice Cream Cold 6. You are taking ice cream in a cooler to a picnic and want to keep the ice cream colder than 0 \u00b0C for several hours. How could you do this?Sample 1: Complete Response Sample response 1 received a score of C omplete . The student chooses to pack the ice cream in ice and then add rock salt. The student knows that this will keep the temperature lower than 0degrees Celsius \u2014 \"It makes the freezing point much lower. \" 16Appendix B contains the scoring guides for the sample questions that appear in this report.Student Work & Teacher Practices in Science 181 12-28xSample 3: Keeping Ice Cream Cold 6. You are taking ice cream in a cooler to a picnic and want to keep the ice cream colder than 0 \u00b0C for several hours. How could you do this?Sample 2: Keeping Ice Cream Cold 12-29x6. You are taking ice cream in a cooler to a picnic and want to keep the ice cream colder than 0 \u00b0C for several hours. How could you do this?Sample 2: Partial Response The next example received a score of Partial . This student knows that salt can be added to ice but does not state clearly that salt lowers the melting point of ice. Sample 3: Unsatisfactory response The following sample response received a score of Unsatisfactory. The student adds ice only \u2014 a method that will fail to keep the ice cream colder than zero degrees for several hours. Theaddition of ice on its own was a common student response.182 Student Work & Teacher Practices in Science TABLE 4.19Percentages at Different Score Levels: Grade 12 Keeping Ice Cream Cold Complete Partial Unsatisfactory Omit 10 25 62 4 NOTE: Numbers do not add to 100 due to rounding. TABLE 4.20Percentages Correct within Each Achievement Level Interval: Grade 12 Keeping Ice Cream Cold Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 49 2 0 - - - - Sample size insufficient to permit a reliable estimate.Performance data are presented in table 4.19. One quarter of the students were able to state a viable method for keeping ice cream colder than O degrees C, but were unable toexplain why their methods worked. Sixty-two percent of the twelfth-grade students were unableto come up with a valid method. The percentages of students who received a score of Complete within each of the achievement level intervals are shown in table 4.20. The item was very difficult. Four percent ofstudents classified as below Basic , 9 percent classified as Basic , and 20 percent classified as Proficient were able to provide a correct methodology for keeping ice cream colder than 0 degrees C together with a correct explanation of how their methodologies worked.Student Work & Teacher Practices in Science 1837. Heart disease is a major cause of death in the United States. Describe two ways a person can reduce the risk of heart disease.Heart Disease The next sample shows a question that asks students to describe two ways a person can reduce his or her risk of heart disease. Since this is a topic commonly in the news, it might be expectedthat twelfth graders would find the question easy to answer. This was borne out by the results.Ninety-four percent of students could describe one or more ways to reduce the risk of heartdisease. The question was scored using a three-level guide. 17 A description of two ways a person can reduce the risk of heart disease received a score of Complete . A description of one way received a score of Partial . Sample 1: Complete Response The first response received a score of Complete . The student talks about eating \"healthful foods \" and specifically mentions what these are. The response also indicates that exercise is important for reducing the risk of heart disease. Sample 1: Heart Disease 12-2x7. Heart disease is a major cause of death in the United States. Describe two ways a person can reduce the risk of heart disease. 17Appendix B contains the scoring guides for the sample questions that appear in this report.184 Student Work & Teacher Practices in ScienceSample 2: Partial Response The next response received a score of Partial . In this response, the student mentions exercising every day (for which the student received credit) and then states that \"A second way is to eat properly. \" This was not credited since the statement is very broad and gives no indication that the student understands what \"properly \" entails. Many students received a score of Partial because one of their descriptions was too general. Sample 2: Heart Disease 12-4x 7. Heart disease is a major cause of death in the United States. Describe two ways a person can reduce the risk of heart disease. Sample 3: Unsatisfactory Response The following response received a score of Unsatisfactory . This answer was typical of responses in this category. Students tended to know that they had to \"eat right, \" but did not describe what that meant. Four percent of students were in this category. Sample 3: Heart Disease 12-3xx7. Heart disease is a major cause of death in the United States. Describe two ways a person can reduce the risk of heart disease.Student Work & Teacher Practices in Science 185 TABLE 4.21Percentages at Different Score Levels: Grade 12 Heart Disease Complete Partial Unsatisfactory Omit 57 37 4 2 TABLE 4.22Percentages Complete within Each Achievement Level Interval: Grade 12 Heart Disease Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 45 61 72 - - - - Sample size insufficient to permit a reliable estimate.Table 4.21 presents the percentages of students at each of the score levels. Fifty-seven percent of students received a score of Complete for this question. The percentages of students within each achievement level interval who provided a correct response indicates that the question was accessible on all levels (table 4.22). Forty-fivepercent of students who were classified as below Basic were able to describe two ways a person can reduce the risk of heart disease.186 Student Work & Teacher Practices in ScienceMalaria The purpose of the following constructed-response question was to find out whether twelfth graders knew what causes malaria and how it is transmitted. This question proved to be verydifficult. To answer the question satisfactorily, students had to know that malaria is spread bymosquitoes. However, students were not expected to know that the organism ( Plasmodium ) is carried by a special type of mosquito that is prevalent mostly in the tropics. Thus, only theexplanations were scored, using a three-level guide. 18 To receive a score of Complete , a student had to specifically address cause and transmission. A score of Partial was given to a response that mentioned the cause and/or transmission of malaria in very general terms. A responsereceived a score of Unsatisfactory when it displayed no understanding of the cause of malaria and its transmission. Sample 1: Complete Response The first sample response received a score of Complete . This student states that the risk is high if mosquitoes are plentiful. The student knows that the parasite is picked up by a mosquito froman infected person and can be transmitted to others \u2014 the implication being other people. 12-5xSample 1: Malaria 8. A person has just returned to the United States from the tropics and is found to have malaria. What is the risk of other people catching thedisease from this person? 18 Appendix B contains scoring guides for the sample questions that appear in this report.8. A person has just returned to the United States from the tropics and is found to have malaria. What is the risk of other people catching thedisease from this person? Explain your answer.Student Work & Teacher Practices in Science 18712-8xSample 3: Malaria 8. A person has just returned to the United States from the tropics and is found to have malaria. What is the risk of other people catching thedisease from this person? Sample 2: Partial Response In the next response, the student knew that \"insects and flies \" were linked to malaria. However, the explanation dealt more with prevention \u2014 \"If the person is kept away from other people then no insects or fly could infect another person \" \u2014 than with why the risk was nonexistent. Thus the response received a score of Partial . 12-8newSample 2: Malaria 8. A person has just returned to the United States from the tropics and is found to have malaria. What is the risk of other people catching thedisease from this person? Sample 3: Unsatisfactory Response The next response received a score of Unsatisfactory . Many answers were based on a general knowledge of diseases and did not reflect malaria in particular. For example, some studentsthought the risk was low because of vaccines, whereas others thought that people with goodimmune systems would not catch it. Still others, as in sample 3, thought that the risk was highbecause \"malaria is contagious. \"188 Student Work & Teacher Practices in ScienceTable 4.23 presents information on the percentages of students at each score level. The question proved to be very challenging; 3 percent of twelfth graders received a score ofComplete . Seventy-one percent of students who attempted the question received a score of Unsatisfactory . Ten percent of students omitted it. Table 4.24 presents the percentages of students within each achievement level interval that received a score of Complete . Students at all levels found the question very difficult. Five percent of those classified as Proficient knew what causes malaria and how it is transmitted. TABLE 4.23Percentages at Different Score Levels: Grade 12 Malaria Complete Partial Unsatisfactory Omit 31 6 7 11 0 TABLE 4.24Percentages Complete within Each Achievement Level Interval: Grade 12 Malaria Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 145 - - - - Sample size insufficient to permit a reliable estimate.Student Work & Teacher Practices in Science 189Theme Block Three of the fifteen 30-minute blocks of questions at the twelfth-grade level addressed each of the three themes \u2014 systems, models, and patterns of change \u2014 outlined in the Science Framework for the 1996 National Assessment of Educational Progress.19 Not every student in the assessment was administered one of these theme blocks and no student was administered morethan one. These sets of questions differed from others in the assessment in that they probeddeeply into students ' understanding of a given area in science \u2014 such as the Water Cycle \u2014 whereas most blocks usually did not devote more than one or two questions to any given topic. The 15 questions based on the theme \"systems \" have been released to the public and can be found on the Internet. 20 Students were presented with a diagram (see below) showing aspects of the water cycle in a region near the coast of a large continent. They were then askeda series of questions relating to this system. For example, they were asked where in the systemwater existed as a gas or a solid, during which part of the cycle solid impurities separated fromwater, and what role trees played in the cycle. They were also asked several questions aboutclimate in the region and the effects of acid rain on the system. Three questions are shown here,one relating to rate of evaporation, one asking students to come up with a methodology fordistinguishing ocean water from land water, and one asking students to explain how cloudsform. 19National Assessment Governing Board. (1995). Science framework for the 1996 National Assessment of Educational Progress . W ashington, DC: Author. 20National Center for Education Statistics. National Assessment of Educational Progress. (1997). NAEP 1996 science assessment public release, grade 12 [On-line]. Available: http://nces.ed.gov/naepThe diagram above shows a region near the coast of a large continent. A range of high, snowcapped mountains lies near the ocean. There is a farm between themountains and a forest. The following questions ask you to think about water and the water cycle in the system shown in the diagram. In the system, water exists as a gas, a liquid, anda solid. 190 Student Work & Teacher Practices in ScienceTheme Block: Temperature and Evaporation The multiple-choice question shown below asks students to select a graph that shows how the rate of evaporation changes with changes in water temperature. To answer this questioncorrectly, students had to be able to read the graphs and understand that the x-axis showed temperature increasing and that the y-axis showed rate of evaporation increasing. They then had to understand that evaporation is the transformation of liquid into a gas, and that thisrequires the input of energy \u2014 in this case, increasing temperature. 6. Which of the following graphs shows how the rate of evaporation changes with changes in water temperature? The correct option is C.ART - 26aRate of Evaporation Water TemperatureRate of Evaporation Water Temperature Rate of EvaporationRate of EvaporationWater Temperature Water TemperatureDA C BStudent Work & Teacher Practices in Science 191 TABLE 4.26Percentages Correct within Each Achievement Level Interval: Grade 12 Temperature & Evaporation Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 46 78 92 - - - - Sample size insufficient to permit a reliable estimate.Response Options A B C D Omit 12 3 68 17 0 TABLE 4.25Percentages Choosing Each Response: Grade 12 Temperature & EvaporationInformation on the percentages of students choosing each response is shown in table 4.25. Students found this question fairly easy. Sixty-eight percent of twelfth graders couldrecognize which graph depicted how the rate of evaporation changes with changes in watertemperature. Twelve percent of students chose option A. These students may have equated rateof evaporation with amount of water remaining; that is, they may have thought the graphdepicted a large amount of water whose volume decreased as temperature increased. V ery fewstudents chose option B and 17 percent chose option D. Students who chose option D may havethought that the rate of evaporation is high initially and then steadily decreases as the water inthe container diminishes. Table 4.26 presents achievement level data. The question proved to be fairly easy; 46 percent of students classified as below Basic answered it correctly.192 Student Work & Teacher Practices in ScienceTheme Block: Identification of Ocean Water A second question taken from the theme block asked students to determine which of two unlabeled jars contained ocean water and which contained lake water. To answer this questioncorrectly, students had to understand that ocean water contains salt and then come up with amethod to test this. A number of methodologies such as distillation, testing differences indensity, and testing differences in freezing points were accepted. However, to achieve a score ofComplete the student 's methodology had to be clear and indicate how the test would differentiate the ocean water from the salt water. The question was scored using a four-levelscoring guide. 21 A score of Complete was given to a student response that clearly demonstrated a valid test and also stated how the test would work. Responses that received a score of Essential described a method and its results but provided minimal detail or the method was flawed insome way. A score of Partial was given to a response that described a valid method but omitted details on how the method would work. Students who received a score of Unsatisfactory demonstrated no knowledge of a correct methodology for determining which water was oceanwater and which was lake water. 7. Some students were studying water in the environment. They filled one sample jar with ocean water and another sample jar with fresh water fromthe lake. The labels on the jars fell off, and the water in both jars lookedthe same. Describe a test, other than tasting or smelling the water, thatthe students could do to determine which jar held the ocean water andwhich jar held the lake water. Explain how the test could work. 21Appendix B contains scoring guides for the sample questions that appear in this report.Student Work & Teacher Practices in Science 193 Sample 1: Identification of Ocean and Lake Water 12-19x7. Some students were studying water in the environment. They filled one sample jar with ocean water and another sample jar with fresh water fromthe lake. The labels on the jars fell off, and the water in both jars lookedthe same. Describe a test, other than tasting or smelling the water, thatthe students could do to determine which jar held the ocean water andwhich jar held the lake water. Explain how the test could work.Sample 1: Complete Response The first sample received a score of Complete . The student describes a very thorough method and clearly states that the \"salt water will leave a white residue of the bottom of the pot (which is salt particals). \"194 Student Work & Teacher Practices in ScienceSample 2: Identification of Ocean and Lake Water 12-20x 7. Some students were studying water in the environment. They filled one sample jar with ocean water and another sample jar with fresh water fromthe lake. The labels on the jars fell off, and the water in both jars lookedthe same. Describe a test, other than tasting or smelling the water, thatthe students could do to determine which jar held the ocean water andwhich jar held the lake water. Explain how the test could work.Sample 2: Essential Response In the next response, which received a score of Essential , the student mentions distillation and expands on it a little: \"in which you heat up the water. \" However, the student fails to mention that the ocean water is the water that contains salt and does not make it clear that the waterevaporates and leaves the salt behind. Sample 3: Partial Response Sample response 3, which received a score of Partial , is similar to the response that received a score of Essential . However, the student gives no description of a test, other than \"letting the water dry up. \" Sample 3: Identification of Ocean and Lake Water 12-21x 7. Some students were studying water in the environment. They filled one sample jar with ocean water and another sample jar with fresh water fromthe lake. The labels on the jars fell off, and the water in both jars lookedthe same. Describe a test, other than tasting or smelling the water, thatthe students could do to determine which jar held the ocean water andwhich jar held the lake water. Explain how the test could work.Student Work & Teacher Practices in Science 195Sample 4: Identification of Ocean and Lake Water 12-22xx 7. Some students were studying water in the environment. They filled one sample jar with ocean water and another sample jar with fresh water fromthe lake. The labels on the jars fell off, and the water in both jars lookedthe same. Describe a test, other than tasting or smelling the water, thatthe students could do to determine which jar held the ocean water andwhich jar held the lake water. Explain how the test could work.Sample 4: Unsatisfactory Response Sample 4 received a score of Unsatisfactory . Many students knew that the presence of salt should be investigated, but could not come up with a methodology. A number of students talkedabout tasting and smelling, which were specifically mentioned in the question. Others talkedabout viewing the samples directly under a microscope. In these instances, students werelooking for differences such as sediment on the bottom of the jars or salt crystals and parasitesvisible under a microscope.196 Student Work & Teacher Practices in SciencePerformance data are presented in tables 4.27 and 4.28. Thirty-nine percent of twelfth graders were able to explain a test in some detail and explain the results of the test. Fortypercent of twelfth graders could not answer the question and thus received a score ofUnsatisfactory . An examination of the achievement level results indicates that the question was accessible to students classified as below Basic , Basic , and Proficient . Complete Essential Partial Unsatisfactory Omit 39 7 6 40 8 NOTE: Numbers do not add to 100 due to rounding. TABLE 4.27Percentages at Different Score Levels: Grade 12 Identification of Ocean and Lake Water TABLE 4.28Percentages Complete or Essential within Each Achievement Level Interval: Grade 12 Identification of Ocean and Lake Water Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 23 56 74 - - - - Sample size insufficient to permit a reliable estimate.Student Work & Teacher Practices in Science 1979. Explain how clouds can form as air rises. You may draw a diagram as part of your explanation.Theme Block: Cloud Formation The next sample question asks students to explain how clouds form as air rises. To answer this question correctly, students had to explain both that water vapor condensed to form clouds andthat condensation took place because the air cooled as it rose, causing the water vapor to turnfrom a gas to a liquid in the form of clouds. Many students chose to draw a diagramsupplemented with explanatory material. The question was scored using a three-level scoringguide. 22 A score of Complete was given to a response that mentioned cooling and condensation. A score of Partial was given to responses that mentioned that droplets of water in the air form clouds. A score of Unsatisfactory was given to those responses that demonstrated no understanding of cloud formation. 22Appendix B contains scoring guides for the sample questions that appear in this report.198 Student Work & Teacher Practices in Science 12-13xSample 1: Cloud Formation 9. Explain how clouds can form as air rises. You may draw a diagram as part of your explanation.Sample 1: Complete Response The first sample received a score of Complete . This student clearly indicates an understanding of the process by stating that, \"When the air cannot hold all of the evaporated water because it is too cold, the water vapor condenses on dust particles to form clouds. \"Student Work & Teacher Practices in Science 199 4-15xSample 2: Cloud Formation 9. Explain how clouds can form as air rises. You may draw a diagram as part of your explanation.Sample 2: Partial Response The following student response received a score of Partial . This student states that condensation took place but fails to mention cooling.200 Student Work & Teacher Practices in Science 12-14xSample 3: Cloud Formation 9. Explain how clouds can form as air rises. You may draw a diagram as part of your explanation.Sample 3: Unsatisfactory Response Sample response 3 received a score of Unsatisfactory . While the student talks about condensation, he or she relates it to air and not to water vapor. The \"more dense air becomes condensed and clouds form. \"Student Work & Teacher Practices in Science 201 TABLE 4.30Percentages Complete within Each Achievement Level Interval: Grade 12 Cloud Formation Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 06 2 1 - - - - Sample size insufficient to permit a reliable estimate. TABLE 4.29Percentages at Different Score Levels: Grade 12 Cloud Formation Complete Partial Unsatisfactory Omit 81 9 5 71 6Table 4.29 contains information relating to the percentages of students receiving various scores. This question proved to be very challenging. Eight percent of students were able to givean adequate explanation of how clouds form. Nineteen percent of students gave an explanationthat did not fully explain the process. Fifty-seven percent of students were unable to answer thequestion satisfactorily. Information on the percentages of students classified within each achievement level interval is presented in table 4.30. Zero percent of students classified as below Basic were able to explain how clouds form as air rises.202 Student Work & Teacher Practices in ScienceHands-on Task Each student who participated in the NAEP 1996 science assessment at grade 12 performed one of four hands-on tasks. Each task required students to use materials to perform aninvestigation, make observations, record and evaluate experimental results, and apply problem-solving skills. The diagram below shows the first page of one of the hands-on tasks as presentedto students. SEPARATION Separating a Mixture of Solid Materials For this task, you have been given a kit that contains materials that you will use to perform an investigation during the next 30 minutes. Please open your kit now and usethe following diagram to check that all of the materials in the diagram are included inyour kit. If any materials are missing, raise your hand and the administrator willprovide you with the materials that you need. Plastic Spoon2 Plastic Cups Bottle of Water4 Unlabeled Plastic Bags Magnet Plastic Funnel 2 Pieces of Filter PaperPlastic Tray Water Sieve Plastic Bag Containing Solid MaterialsPaper Towels A ART-21A In the separation task, students were asked to apply their understanding of basic physical principles and the use of simple laboratory equipment to separate a mixture of fivesolid materials that have different properties (copper pellets, steel pellets, iron filings, sand,and salt). Students designed the procedures and used them to accomplish the task. This taskassessed students ' abilities to apply their conceptual knowledge of physical principles, to draw inferences from investigative results, and to evaluate and effectively communicate theirinvestigative procedures. It also assessed students ' understanding of one aspect of the nature of technology by asking students to apply their knowledge to the design of a practical separationprocedure.Student Work & Teacher Practices in Science 203Three questions from this task are shown on the following page. Since students had to devise their own methodologies for this task, the first question was included to help them thinkabout how the equipment could be used. The second question in the hands-on task directedstudents to use the equipment supplied to them to separate the components of the mixture.They were told to place each separated component into one of the plastic bags. Immediatelyafter the students were assessed, the assessment administrator recorded how pure thecomponents were on a grid. The third question in the hands-on task asked students to writestep-by-step instructions that would allow someone else to separate the components from themixture. The complete task, scoring guides for each question, and sample student responsescan be found on the Internet. 23 23National Center for Education Statistics. National Assessment of Educational Progress. (1997). 1996 science assessment public release, grade 12 [On-line] Available: http://nces.ed.gov.naep.204 Student Work & Teacher Practices in Science Student Work & Teacher Practices in Science 20512-30xSample 1: Physical Properties 1. Look at the contents of plastic bag (A) without opening it. What properties do the substances in the mixture have that would allow the followingequipment to be used to separate the mixture? Hands-on Task: Physical Properties The first question was scored using a four-level scoring guide.24 Since three properties were sought, a student response that stated all three received a score of Complet e. Two properties elicited a score of Essential, and one property received a score of Partial . A response that indicated no correct properties received a score of Unsatisfactory . Sample 1: Complete Response Sample response 1 received a score of Complete . The student clearly describes three properties \u2014 namely, magnetism, solubility, and size \u2014 that can be used to separate the components of the mixture. 24Appendix B contains scoring guides for the sample questions that appear in this report.206 Student Work & Teacher Practices in ScienceSample 2: Essential Response Sample response 2 received a score of E ssential . Here the student implies that all metals are magnetic, thus receiving no credit for this part of the question. 12-31xSample 2: Physical Properties 1. Look at the contents of plastic bag (A) without opening it. What properties do the substances in the mixture have that would allow the followingequipment to be used to separate the mixture? 12-33xSample 3: Physical Properties 1. Look at the contents of plastic bag (A) without opening it. What properties do the substances in the mixture have that would allow the followingequipment to be used to separate the mixture?Sample 3: Partial Response Sample response 3 received a score of Partial . Only the third part of the question was given credit.Student Work & Teacher Practices in Science 207Table 4.31 presents the percentages of students at different score levels. Grade 12 students found it difficult to articulate any properties of the materials as evidenced by the 52percent who received a score of Unsatisfactory .12-32xSample 4: Physical Properties 1. Look at the contents of plastic bag (A) without opening it. What properties do the substances in the mixture have that would allow the followingequipment to be used to separate the mixture? Table 4.32 shows the percentages of students within each achievement level interval that received a score of Complete or Essential . Two percent of students classified as below Basic , 12 percent classified as Basic , and 26 percent classified as Proficient knew at least two properties of materials that would allow for their separation using specific equipment. TABLE 4.31Percentages at Different Score Levels: Grade 12 Physical Properties Complete Essential Partial Unsatisfactory Omit 2 1 02 95 2 8 TABLE 4.32Percentages Complete or Essential within Each Achievement Level Interval: Grade 12 Physical Properties Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 21 2 2 6 - - - - Sample size insufficient to permit a reliable estimate.Sample 4: Unsatisfactory Response Sample response 4 received a score of Unsatisfactory . The question specifically asked for \"properties \"; however, many students did not identify properties but rather identified which of the substances in the mixture could be separated by the particular piece of equipment. Thus,sample 4 shows components of the mixtures \u2014 metal, dirt, and rocks \u2014 but not their properties.208 Student Work & Teacher Practices in ScienceCP SP IF SD ST 1 2 3 4Sample 1: Separation of MaterialsHands-on Task: Separation The second question required students to separate the components of the mixture and place them in bags. Administrators then recorded the results on a grid (see below). The grid had twosets of labels. The labels at the top were for each component and the labels down the side werefor each bag. Thus if one bag contained copper pellets (CP), the oval beside CP and 1 was filledin. The grids were subsequently scored according to a five-level guide. 25 If a student successfully separated all five components, a score of Complete was given. Separation of three components gave students a score of Essential . A score of Adequate was given for two separated components, and a score of Partial was given for one separated component. Students who were unable to separate any of the five components from the mixture received a score ofUnsatisfactory . Sample 1: Complete Response 25 Appendix B contains scoring guides for the sample questions that appear in this report.The grid shown in the first sample received a score of Complete . This student had pure samples of copper pellets (CP) in bag 1, steel pellets (SP) in bag 2, iron filings (IF) in bag 3, sand (SD)in bag 4, and therefore, by default, salt (ST) in water.Student Work & Teacher Practices in Science 209Sample 2: Separation of Materials CP SP IF SD ST 1 2 3 4 CP SP IF SD ST 1 2 3 4Sample 3: Separation of MaterialsSample 2: Essential Response The next grid received a score of Essential . This student had pure samples of iron filings (IF), sand (SD), and therefore, by default, salt (ST) in water. Bag 1, however, contained twosubstances, copper pellets (CP) and steel pellets (SP). The student failed to realize that thesecould be separated based on the property of magnetism. Sample 3: Adequate Response The next grid received a score of Adequate . This student had pure samples of copper pellets (CP) in bag 2 and steel pellets (SP) in bag 4. Bag 1 contained iron filings, sand, and salt; thus, thestudent only separated two of the components.210 Student Work & Teacher Practices in ScienceCP SP IF SD ST 1 2 3 4Sample 5: Separation of MaterialsSample 4: Partial Response The fourth grid received a score of Partial . This student had a pure sample of iron filings (IF) in bag 2 only. Bag 1 contained copper and steel pellets, bag 3 contained iron filings and sand, andbag 4 contained iron filings, sand, and salt. Iron filings were found in three of the five bags;however, since they appeared to be pure in one of the bags, the student was given a score ofPartial for one separated component. Sample 5: Unsatisfactory Response The final grid received a score of Unsatisfactory . This student did not succeed in separating any of the components of the mixture. Bag 1 contained copper and steel pellets and bag 2 containedthe remaining three components.CP SP IF SD ST 1 2 3 4Sample 4: Separation of MaterialsStudent Work & Teacher Practices in Science 211 TABLE 4.34Percentages Complete or Essential within Each Achievement Level Interval: Grade 12 Separation of Materials Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 58 72 75 - - - - Sample size insufficient to permit a reliable estimate.Complete Essential Adequate Partial Unsatisfactory Omit 34 33 8 10 9 6 TABLE 4.33Percentages at Different Score Levels: Grade 12 Separation of MaterialsTable 4.33 presents the percentages of students at different score levels. Eighty-five percent of students received a score of Complete , Essential , Adequate , or Partial, indicating that they were able to separate out at least one component of the mixture. Thirty-four percentof students received a score of Complete , indicating they were able to separate out all five components. This task proved accessible to all students. As shown in table 4.34, 58 percent of those students classified as below Basic received a score of Complete or Essential .212 Student Work & Teacher Practices in ScienceHands-on Task: Description of Method The question that asked students to write step-by-step instructions on how to separate the mixture was scored using a five-level guide.26 If a student described how to separate all five components, a score of Complete was given. A description that led to the separation of three components was given a score of Essential . A score of Adequate was given to a description that allowed for separation of two components, and a score of Partial was given to a description that allowed for the separation of one component. A score of Unsatisfactory was given to student responses that were too general, inaccurate, or hard to follow. Sample 1: Complete Response The first student response was given a score of Complete . This student has written a description that would enable someone else to separate the components of the mixture. Sample 1: Description of Method SEPSAMP1 26 Appendix B contains scoring guides for the sample questions that appear in this report.Student Work & Teacher Practices in Science 213Sample 2: Essential Response The next response received a score of Essential . This student sifted out the metal balls, but did not realize that there were two types of balls present, one of which was magnetic. Sample 2: Description of Method SEPSAMP2 214 Student Work & Teacher Practices in ScienceSample 3: Adequate Response The following sample response received a score of Adequate . This student separated out the two sets of balls (copper and steel pellets). The description then became very general: \"With the remaining sediment, Filter it out using the Funnel Filter paper and water in some way oranother. \" Thus, no credit was given for this part of the response. Sample 3: Description of Method SEPSAMP3 Student Work & Teacher Practices in Science 215Sample 4: Partial Response The fourth response received a score of Partial . This student talked in general about the separation process. The only specific direction that would lead to the separation of onecomponent was \"I used the magnet to get the shaved metal out, \" meaning the iron filings. This was credited. The statement \"I got the little balls out w/the sieve \" was not credited since there were two types of \"balls, \" copper and steel. Sample 4: Description of Method SEPSAMP4 216 Student Work & Teacher Practices in ScienceSample 5: Unsatisfactory Response The final sample response received a score of Unsatisfactory . This student did not furnish any step-by-step instructions but merely stated that the materials should be put in a sieve and thenput into the plastic bags. Sample 5: Description of Method SEPSAMP5 Student Work & Teacher Practices in Science 217Student performance data are presented in tables 4.35 and 4.36. Twenty-six percent of students at grade 12 were able to give step-by-step instructions on how to separate out thecomponents of the mixture. Achievement level data show that 33 percent of students classifiedas below Basic , 69 percent classified as Basic, and 82 percent classified as Proficient received a score of Complete or Essential . Complete Essential Adequate Partial Unsatisfactory Omit 26 32 4 21 16 1 TABLE 4.35Percentages at Different Score Levels: Grade 12 Description of Method TABLE 4.36Percentages Complete or Essential within Each Achievement Level Interval: Grade 12 Description of Method Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 33 69 82 - - - - Sample size insufficient to permit a reliable estimate.218 Student Work & Teacher Practices in ScienceSummary of Grade 12 Data The data presented in this chapter give an indication of how students in grade 12 perform on science questions that cover a range of topics and make use of a variety of question types. Thequestions presented had to be limited to those that were released to the public. 27 These are fairly representative and do give an indication of the understandings and skills surveyed in theassessment. Similarly, the data for the small group of questions discussed in this chapterrepresent the data seen for the questions as a whole. In general, students found the constructed-response questions more challenging than the multiple-choice questions. Questions thatrequired application of knowledge and understanding proved to be the most difficult. \u007fMale students had a higher average question score than female students for questions that measured earth science and physical science. \u007fWhite students had a higher average question score than Black and Hispanic students for questions that measured earth, physical, and life science. \u007fMale students had a higher average question score than female students for questions that measured conceptual understanding and practical reasoning. \u007fWhite students had a higher average question score than Black, Hispanic, and Asian/ Pacific Islander students for questions that measured conceptual understanding,scientific investigation, and practical reasoning. \u007fThe percentage of students who gave correct responses to the multiple-choice q uestions discussed in this chapter ranged from 43 percent to 80 percent. \u007fThe percentage of students who received a score of Complete on the constructed- response questions described in this chapter ranged from 2 percent to 57 percent. 27National Center for Education Statistics, National Assessment of Educational Progress. (1997). NAEP 1996 science assessment public release , grade 12 [On-line]. Available: http://nces.ed.gov/naep.Chapter 5 Student Work & Teacher Practices in Science 219Classroom Practices Introduction Over the past decade, leading science organizations have spearheaded efforts to reform science education in the United States. The National Research Council of the National Academy ofSciences, the American Association for the Advancement of Science, and the National ScienceTeachers Association have all proposed curriculum reforms designed to emphasize themesrather than traditional content divisions, concepts rather than facts, and active rather thanpassive learning. 1 Moreover, many states and districts have been revising their science curriculum, often using the national proposals as guidelines.2 As part of the NAEP 1996 science assessment, students and their teachers were asked a number of questions related toinstructional objectives and classroom activities. This chapter discusses the results of thesequestionnaires and thus sheds light on recent instructional practices as well as the extent towhich schools and teachers have adopted these reforms. The tables in this chapter present three sets of data: percentages of students who responded to or whose teachers responded to questions in the student and teacherquestionnaires; the average scale scores of students; and the percentages of students at or aboveProficient . 3 The following example demonstrates how these data can be read. In the top left- hand box in table 5.1, there are three numbers with superscripts: 44a, 151b, and score, and superscript 'c' denotes percentage at or above Proficient . Thus 44 percent of students had teachers who reported heavily emphasizing knowing science facts, these students had anaverage scale score of 151, and 30 percent of them were at or above the Proficient level. The order of the data is the same in each box of every table in this chapter. 1American Association for the Advancement of Science. (1993). Benchmarks for science literacy . W ashington, DC: Author. National Research Council of the National Academy of Sciences. (1995). National science education standards . W ashington, DC: Author. National Science Teachers Association. (1992). Scope, sequence, and coordination of secondary school science . W ashington, DC: Author. 2Blank, R.K. & Pechman, E.M. (1995). State curriculum frameworks in mathematics and science: How are they changing across the states? W ashington, DC: Council of Chief State School Officers. O'Sullivan, C.Y., W eiss, A.R., & Askew, J.M. (1998). Students learning science: A report on policies and practices in U.S. schools . W ashington, DC: National Center for Education Statistics. 3Chapter 1 and appendix A both contain descriptions of scale scores and achievement levels.220 Student Work & Teacher Practices in Science4Tobin, K., Kahle, J. & Fraser, B. (1990). Windows into science classrooms: Problems associated with higher-level cognitive learning . London: Falmer Press. Appleton, K. & Asoko, H. (1996). A case study of a teacher 's progress toward using a constructivist view of learning to inform teaching in elementary science . Science Education , 80(2), 165-80. Kadel, S. (1992). Problem-centered learning in mathematics science. Hot topics: Usable research . W ashington, DC: Office of Educational Research and Improvement. Haury, D. L. (1993). Teaching science through inquiry . W ashington, DC: Office of Educational Research and Improvement.The reader is cautioned against overinterpreting the results. If no statistically significant correlations exist, there may still be cause-and-effect relationships; however, thesemay be masked by other factors. Similarly, when statistically significant correlations do exist, itis also impossible to assign cause and effect to a single variable since many factors may impactstudent performance. Instructional Objectives The way teachers teach science and the knowledge and skills students take away from theirscience courses depend, in part, on the district and state requirements that determine thecurriculum and, in part, on teachers ' own understanding of how children learn and which teaching approach is most effective. 4 As part of the NAEP 1996 science assessment, teachers of fourth- and eighth-grade students were asked how much emphasis they gave to nine differentinstructional objectives. Two of the objectives were related to content knowledge ( \"knowing science facts and terminology \" and \"understanding key science concepts \"); five addressed the development of different skills (problem-solving, communicating ideas, laboratory, dataanalysis, and using technology); and two were about getting students to appreciate science(\"developing students ' interest in science \" and \"learning about the relevance of science to society and technology \"). The results are shown in table 5.1. At the fourth-grade level, 44 percent of students had teachers who gave heavy emphasis to knowing science facts and terminology, whereas 78 percent had teachers who heavilyemphasized understanding key science concepts. Clearly, some teachers were giving heavyemphasis to both facts and concepts. The percentages of students whose teachers gave heavyemphasis to the five objectives that addressed the development of different skills ranged from49 percent for science problem-solving skills to 12 percent for data analysis skills and usingtechnology as a scientific tool. Teachers of nearly half of fourth graders (48 percent) gave littleor no emphasis to using technology as a scientific tool. A relatively large number of students(70 percent) had teachers who reported placing a heavy emphasis on developing students ' interest in science, whereas one percent of students had teachers who gave it little or noemphasis. At the eighth-grade level, teachers of 88 percent of students placed a heavy emphasis on understanding key science concepts, with the remaining 12 percent of students ' teachers giving conceptual understanding moderate emphasis. Fifty-five percent of students hadteachers who placed moderate emphasis on knowing science facts and terminology, while 40percent had teachers who gave knowing science facts and terminology heavy emphasis.Student Work & Teacher Practices in Science 22144a53 3 40 55 4 151b150 158 148 154 154 30c29 45 28 32 30 78 22 0 88 12 0 152 146 \u2014\u2014 153 145 \u2014\u2014 31 23 \u2014\u2014 31 23 \u2014\u2014 32 55 12 46 49 5 149 151 156 152 150 164 27 30 34 31 29 45 70 29 1 69 28 3 152 149 162 152 150 148 31 26 43 31 30 25 49 45 6 67 30 3 152 149 157 153 150 140 31 27 35 31 30 20 35 51 14 41 44 15 152 149 156 152 151 151 31 28 34 31 31 27 15 55 30 41 44 15 157 150 150 154 154 138 36 29 29 32 33 18 12 53 35 24 64 12 150 152 150 155 152 141 31 30 28 35 30 22 12 41 48 15 52 33 153 150 152 149 153 150 32 29 30 27 32 30TABLE 5.1 Grade 4 Grade 8 Heavy Moderate Little or None Heavy Moderate Little or None Knowing science facts and terminology Understanding key science concepts Learning about relevance of science to society and technology Developing students ' interest in science Developing science problem-solving skills Learning how to communicate ideas in science effectively Developing lab skills and techniques Developing data analysis skills Using technology as a scientific toolTeachers ' Reports on How Much Emphasis They Give to Student Objectives, Grades 4 and 8: Public and Nonpublic Schools Combined About how much emphasis will you give to each of the following objectives for your students? aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient \u2014\u2014Sample size was insufficient to permit reliable estimates. NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics. National Assessment of Educational Progress (NAEP),1996 Science Assessment.222 Student Work & Teacher Practices in ScienceTeachers of eighth-grade students also placed emphasis on some areas of skill development. Sixty-seven percent of students had teachers who reported placing a heavyemphasis on developing problem-solving skills, 41 percent had teachers who put heavyemphasis on knowing how to communicate ideas in science effectively, and 41 percent hadteachers who put heavy emphasis on developing laboratory skills and techniques. By contrast,fewer than one in four students (24 percent) were taught by teachers who placed a heavyemphasis on developing data analysis skills, and the teachers of 33 percent of students placedlittle or no emphasis on using technology as a scientific tool. As was the case in fourth grade, alarge majority of eighth graders (69 percent) had teachers who placed heavy emphasis ondeveloping students ' interest in science. There were a few instances in which varying degrees of emphasis on instructional objectives were statistically related to differences in performance. Among fourth graders,students had higher scale scores and were more likely to be at or above the Proficient level if their teachers placed a heavy, rather than a moderate, emphasis on understanding scienceconcepts. Also, fourth graders whose teachers reported placing a heavy emphasis on learningabout the relevance of science to society and technology had lower scale scores than thosewhose teachers gave little or no emphasis to this objective. As with fourth graders, eighth graders had higher average scale scores and were more likely to be at or above the Proficient level if their teachers placed a heavy emphasis, rather than a moderate emphasis, on understanding science concepts. Further, grade 8 students hadhigher scale scores and a greater percentage of them reached the Proficient level if their teachers placed either a heavy or moderate emphasis on developing laboratory skills andtechniques than if their teachers gave little or no emphasis to these skills. Finally, eighth-gradestudents whose teachers reported placing a heavy or moderate emphasis on developing dataanalysis skills had higher scale scores than those whose teachers gave these skills little or noemphasis. The percentage of students at or above the Proficient level was higher for those whose teachers placed a heavy emphasis on data analysis skills than those whose teachers placedlittle or no emphasis on data analysis skills.Student Work & Teacher Practices in Science 223Classroom Activities From reading a textbook or writing a report to doing hands-on activities or working collaboratively on projects, teachers have available a wide variety of classroom activities toassign their students. The trend in science education for over a decade has been toward \"doing science \" and collaborative learning. Hands-on activities, active participation, the exchange of ideas through group projects and discussions, the use of innovative resources and technologiesto engage students and enrich understanding \u2014 these activities are increasingly considered to be better suited to the way students actually learn than traditional ones such as textbookreading, teacher lectures, and individual deskwork. 5 Data collected as part of the NAEP 1996 science assessment shed light on the frequency of various classroom activities. Teachers of fourth- and eighth-grade students were asked how often their students did each of 10 different activities. Twelfth-grade students were asked how often they did each of 13different activities (the 10 activities asked of the fourth- and eighth-grade teachers plus threeadditional age-appropriate activities). The results of the fourth- and eighth-grade teacherquestionnaires are shown in table 5.2 and the results of the twelfth-grade student questionnaireare shown in table 5.3. 5Siversten, M.L. (1993). State of the art: Transforming ideas for teaching and learning science . W ashington, DC: U.S. Office of Educational Research and Improvement. Suter, L.E. (Ed.). (1996). The learning curve: What we are discovering about U.S. science and mathematics education. W ashington, DC: National Science Foundation.224 Student Work & Teacher Practices in ScienceAs indicated in table 5.2, few students did any given activity almost every day. Reading a textbook was the most frequently assigned classroom activity at both grades 4 and 8, with 28percent of fourth graders and 34 percent of eighth graders having teachers who reported thattheir students did this almost every day. These findings are consistent with those of otherstudies that have shown the persistence of textbook-centered instruction. Alternative teachingmethods are most commonly used as supplements to, rather than as replacements for textbooks,even among teachers who believe in structuring learning around activities other thantextbooks. 6 On the other hand, no more than five percent of students at either grade read a book or magazine about science, did oral or written science reports, used computers, or took ascience test or quiz almost every day. Of the activities assigned once or twice a week, hands-onactivities appeared to be the most frequent; 47 percent of fourth graders and 62 percent ofeighth graders had teachers who reported their students did hands-on activities once or twice aweek. Further, teachers of 40 percent of fourth graders and 53 percent of eighth gradersindicated that their students talked about measurements and results of those hands-on activities once or twice a week. Among infrequently assigned activities, 69 percent of fourth graders never or hardly ever used computers, 56 percent never or hardly ever gave oral science reports, and 53 percentnever or hardly ever prepared a written science report, according to their teachers. Fifty-twopercent of eighth-grade students never or hardly ever gave oral science reports, and 62 percentnever or hardly ever used computers for science, according to their teachers. At grade 8, performance data show a few differences associated with the frequency with which classroom activities were performed. These differences suggest a positive relationshipbetween frequency of certain activities and science performance. Students who did hands-onactivities almost every day or once or twice a week outperformed those who did hands-onactivities once or twice a month or never or hardly ever. Students who did hands-on activities orinvestigations in science monthly also outperformed those who never or hardly ever did them.Students who talked about the results of hands-on activities had higher scale scores and weremore likely to be at or above the Proficient level than students who never or hardly ever talked about them, and students who talked about the results weekly had higher scale scores andpercentages at or above Proficient than those who talked about them monthly. 6Hynd, C.R., et. al. (1994). Learning counterintuitive physics concepts: the effects of text and educational environment . Athens, GA: National Reading Research Center. Powell, R. (1991). Teaching alike: A cross-case analysis of first-career and second-career beginning teachers ' instructional convergence. Teaching and Teacher Education, 13(3), 341-356. Belcher, C. D. & Williams, W . (1995). Middle school science teachers ' perception of textbook congruency with classroom needs . Paper presented at the Annual Meeting of the Missouri Unit of the Association of T eacher Educators, Osage Beach, MO. Lee, O. (1995). Subject matter knowledge, classroom management, and instructional practices in middle school classrooms. Journal of Research in Science Teaching , 32(4), 23-40. Mastropieri, M. N. & Scruggs, T.E. (1994). Text versus hands-on science curriculum: Implications for students with disabilities. Remedial and Special Education, 15(2), 72-85.Student Work & Teacher Practices in Science 22528a36 14 21 34 42 14 10 151b149 151 154 152 153 153 149 29c28 28 34 32 30 31 28 5 26 48 22 1 15 58 26 155 152 152 147 144 150 152 153 33 30 31 26 18 28 31 33 42 94 81 91 5 3 34 4 8 144 150 152 150 154 151 151 155 27 28 31 29 32 30 30 35 63 54 71 22 4 4 42 5 6 152 152 150 147 155 154 147 151 33 31 29 25 32 32 28 31 0 5 39 56 0 3 45 52 \u2014\u2014 144 151 151 \u2014\u2014 149 150 154 \u2014\u2014 27 30 30 \u2014\u2014 21 29 33 0 4 43 53 1 9 58 32 \u2014\u2014 153 151 150 \u2014\u2014 151 151 155 \u2014\u2014 36 29 29 \u2014\u2014 29 29 35 9 47 42 3 18 62 18 2 148 152 150 144 154 155 143 122 29 31 28 21 32 33 24 9 64 04 41 01 2 5 33 1 4 148 153 149 148 154 155 149 127 29 33 27 27 30 34 27 11 2 9 20 69 0 7 30 62 150 150 154 150 \u2014\u2014 159 152 151 29 29 33 28 \u2014\u2014 36 30 30 01 37 61 0 2 4 35 1 3 \u2014\u2014 144 152 148 148 152 152 148 26 24 31 27 24 32 30 27Teachers ' Reports on How Often Students Do a Variety of Classroom Activities, Grades 4 and 8: Public and Nonpublic Schools CombinedTABLE 5.2 About how often do your science students do each of the following?Grade 4 Grade 8 Almost Once or Once or Never or Almost Once or Once or Never or Every Twice a Twice a Hardly Every Twice a Twice a Hardly Day Week Month Ever Day Week Month Ever Read a science textbook Read a book or magazine about science Discuss science in the news Work with other students on a science activity orproject Give an oral science report Prepare a written science report Do hands-on activities or investigations in science Talk about measurements and results from students ' hands-on activities Use computers for science Take a science test or quiz aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient \u2014\u2014Sample size was insufficient to permit reliable estimates. NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics. National Assessment of Educational Progress (NAEP),1996 Science Assessment.226 Student Work & Teacher Practices in ScienceThe data on grade 12 classroom activities are presented in table 5.3. Readers should note that the data are derived not from all students but rather from the 54 percent of studentswho indicated that they were taking a science course in twelfth grade. 7 The percentages therefore tend to reflect the classroom experiences of a select subset of the student population\u2014 those taking more years of science, including more advanced classes. For most of the activities, the grade 12 percentages are not unlike those seen at grades 4 and 8. Reading a science textbook was the most frequently used classroom activity. Twenty-eight percent of twelfth-grade students reported that they read a science textbook almost everyday, and an additional 36 percent read a science textbook once or twice a week. Moreover, 42percent of students reported doing hands-on activities or investigations in science once or twicea week, and 37 percent reported talking about the measurements and results from their hands-on activities or investigations once or twice a week. In results comparable to those for studentsat fourth and eighth grade, the majority of students at twelfth grade never or hardly ever gaveoral science reports or used computers for science. Sixty-nine percent of twelfth gradersreported never or hardly ever designing and carrying out their own experiments, and 62 percentreported never or hardly ever going outside to observe or measure things. An analysis of scale score and proficiency data reveals many performance differences related to the frequency with which the classroom activities were done. None of the 13 variablesexamined at grade 12 was without at least some relationship to overall scale scores. Rather thanmention each relationship found, it might be more useful to point to two patterns, one in whichdoing an activity less often corresponded to lower performance and one in which doing anactivity more often corresponded to lower performance. Students who reported never or hardly ever doing the following activities had lower scale scores and a lower percentage at or above Proficient than students who did those activities more often: reading a science textbook, discussing science in the news, working with other students on a science activity or project,doing hands-on activities or investigations in science, talking about the measurements andresults from their hands-on activities or investigations in science, or analyzing data and formingconclusions from their investigations. Students who reported that they prepared a writtenscience report or went outside to observe or measure things almost every day had lower scalescores than those who reported doing them less often. In addition, students who reported goingoutside to observe or measure things almost every day were less likely to be at or above theProficient level than students who reported doing this once or twice a month or never or hardly ever. 7O'Sullivan, C. Y., Weiss, A. R., & Askew, J. M. (1998). Students learning science: A report on policies and practices in U.S. schools . (NCES Publication No. 98-496) W ashington, DC: National Center for Education Statistics.Student Work & Teacher Practices in Science 22728a36 14 22 163b165 160 149 34c37 32 20 41 6 3 0 4 9 159 162 167 156 34 35 39 26 82 3 2 9 4 0 162 169 167 151 33 41 39 22 17 36 28 19 166 167 160 144 38 40 29 16 1 3 23 73 \u2014\u2014 136 158 163 \u2014\u2014 14 29 34 21 4 3 8 4 6 138 163 163 159 17 36 34 30 16 42 30 12 164 168 160 133 35 40 29 9 15 37 28 20 164 169 163 141 35 40 33 14 41 3 2 3 6 1 162 164 167 158 36 39 38 28 3 6 22 69 159 152 165 160 33 29 36 31 93 2 3 0 2 9 163 170 163 148 35 43 33 18 75 8 3 0 5 150 161 167 133 23 31 39 10 2 7 28 62 134 149 166 161 11 23 37 32Reports from Students Currently Taking a Science Course on How Often They Do a Variety of Classroom Activities, Grade 12: Public and Nonpublic Schools CombinedTABLE 5.3 When you study science in school, how often do you do each of the following?Grade 12 Almost Once or Twice Once or Twice Never or Every Day a Week a Month Hardly Ever Read a science textbook Read a book or magazine about science Discuss science in the news Work with other students on a science activity or project Give an oral science report Prepare a written science report Do hands-on activities or investigations in science Talk about measurements and results from students ' hands-on activities Use computers for science Design and carry out your own science investigation Analyze data and form conclusion from your investigations Take a science test or quiz Go outside and observe or measure things aPercentage of Students b Average Scale Score cPercentage At or Above Proficient \u2014\u2014 Sample size was insufficient to permit reliable estimates. NOTE: Percentages may not add up to 100 due to rounding.SOURCE: National Center for Education Statistics. National Assessment of Educational Progress (NAEP),1996 Science Assessment.228 Student Work & Teacher Practices in Science8Perkins, D. N. et al. (1995). Software goes to school: Teaching for understanding with new technologies . New Y ork: Oxford University Press. Hawkes, M. (1995). Educational technology dissemination: Its impact on learning, instruction, and educational policy . Paper presented at the Annual Meeting of the National Rural Education Association, Salt Lake City, Utah. 9Rieber, L.P . (1993) A pragmatic view of instructional technology. In K. Tobin, (Ed.), The practice of constructivism in science education (pp. 193-212). W ashington, DC: AAAS Press.Teacher Activities New technologies are providing science teachers with an expanding range of instructional activities for their classrooms. In addition to traditional activities such as lecturing andperforming demonstrations, teachers can now make use of computers and a variety of othertechnologies. 8 But do teachers actually employ these various resources in their classrooms? Fourth- and eighth-grade teachers and twelfth-grade students were asked to report on howfrequently five different activities for science instruction were used: talking to the class aboutscience, doing a science demonstration, showing a science video or science television program,using computers for science, and using CD 's or laser disks on science. The results are shown in tables 5.4 and 5.5. The data provide a useful starting point for understanding the extent to which each of the activities is employed in science classrooms, butreaders would do well to bear in mind some related issues which the data do not address. Forexample, how frequently teachers make use of the activities and technologies may depend notonly on their preferences but on whether they have access to the necessary equipment and aretrained in how to use it. Moreover, the degree to which activities contribute to higher studentachievement depends on the effectiveness with which teachers match them to students ' needs and integrate them into the learning process. 9 Talking to the class about science, i.e., lecturing, was the primary instructional activity at all grades. The remaining activities were generally employed much less frequently, especiallyat the middle school and high school levels. At grade 4, teachers of 59 percent of students reported that they talked to their classes about science almost every day. On the other hand, teachers of fewer than five percent ofstudents said they did science demonstrations, showed videotapes or television programs, usedcomputers, or used CD 's or laser disks almost every day. After talking to the class, the most frequent activity was doing a science demonstration. Forty-six percent of fourth graders hadteachers who indicated doing such demonstrations weekly. At the eighth-grade level, 87 percent of students had teachers who reported talking about science almost every day. Teachers of 49 percent of students said they did a sciencedemonstration once or twice a week. Data from teachers ' reports also show that 21 percent of eighth graders had teachers who reported showing a science videotape or science televisionprogram one or more times a week. Few students had teachers who made frequent use ofcomputers, CD 's or laser disks for science.Student Work & Teacher Practices in Science 229Teachers ' Reports on Using Different Teaching Activities, Grades 4 and 8: Public and Nonpublic Schools CombinedTABLE 5.4 When you teach science, about how often do you do each of the following?Grade 4 Grade 8 Almost Once or Once or Never or Almost Once or Once or Never or Every Twice a Twice a Hardly Every Twice a Twice a Hardly Day Week Month Ever Day Week Month Ever 59a35 6 0 87 11 1 0 152b149 148 \u2014\u2014 153 146 \u2014\u2014 \u2014\u2014 31c28 25 \u2014\u2014 32 24 \u2014\u2014 \u2014\u2014 4 46 43 7 10 49 39 3 156 151 149 154 146 154 151 148 39 30 28 30 21 34 29 32 0 12 61 26 1 20 64 15 \u2014\u2014 150 152 148 \u2014\u2014 152 154 144 \u2014\u2014 30 30 27 \u2014\u2014 31 32 25 2 6 20 72 1 7 28 65 151 147 155 150 \u2014\u2014 153 153 151 28 25 34 29 \u2014\u2014 30 31 30 1 4 17 78 2 11 28 59 \u2014\u2014 156 153 150 148 157 150 152 \u2014\u2014 31 33 29 27 36 28 31Talk to the class about science Do a science demonstration Show a science videotape or TV science program Use computers for science Use CDs or laser disks on science aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient \u2014\u2014Sample size was insufficient to permit reliable estimates. NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics. National Assessment of Educational Progress (NAEP),1996 Science Assessment.Scale scores and percentages of students at or above Proficient associated with the teachers ' reports about the frequency of science activities show no significant differences at grade 4. At grade 8, students whose teachers reported talking to their class about sciencealmost every day had higher scale scores than students at grade 8 whose teachers reportedtalking to their class once or twice a week. Students at grade 8 whose teachers said they diddemonstrations weekly performed at a higher level than those students whose teachers said theydid demonstrations almost every day. Finally, students at grade 8 whose teachers said theyshowed videotapes or television science programs monthly had higher scale scores than thosewhose teachers never or hardly ever showed those programs.230 Student Work & Teacher Practices in ScienceAt the twelfth-grade level, data were collected from students about how frequently their teachers did certain activities. The data are from all twelfth graders, not only those takingscience in twelfth grade, and therefore reflect some students ' experiences in earlier grades. The results are shown in table 5.5. Sixty-eight percent of students said their teachers talked tothe class about science almost every day, and over half of students (55 percent) had a sciencedemonstration at least once a week. Fewer than five percent of students said their teachersshowed science videotapes or science television programs, used computers, or used CDs orlaser disks almost every day, although 22 percent of students said their teachers showedscience videotapes or science television programs once or twice a week. Two thirds of twelfthgraders reported that their teachers never or hardly ever used a computer when teaching science. Among twelfth graders, the greater the frequency with which teachers talked to their students about science, the higher the students ' performance. Students whose teachers did demonstrations almost every day or weekly had higher scale scores than students whoseteachers did demonstrations monthly or never or hardly ever. In addition, students whoseteachers did monthly demonstrations had higher scale scores than those whose teachers neveror hardly ever did them. The percentage of students at or above Proficient was lower for students whose teachers never or hardly ever did science demonstrations than for studentswhose teachers did demonstrations more frequently. Students whose teachers showedvideotapes or television science programs weekly or monthly had higher scale scores thanstudents who either saw these programs almost every day or never or hardly ever saw them; thepattern was identical for achievement level data. Higher student performance was associated with moderate computer use. Students whose teachers used computers for science almost every day had lower scale scores than thosewhose teachers used them once or twice a month, and students whose teachers never or hardlyever used computers had lower scale scores than those whose teachers used them weekly ormonthly. Achievement level data show that the percentage of twelfth graders performing at orabove Proficient was greater for students whose teachers used computers for science weekly or monthly than for students whose teachers never or hardly ever used computers for science. Students whose teachers used CDs or laser disks on science weekly or monthly had higher scale scores than students whose teachers used CDs or laser disks almost every day ornever or hardly ever. The percentage of students at or above Proficient whose teachers never or hardly ever used CDs or laser disks on science or who used them almost every day was lowercompared to those whose teachers used them once or twice a month.Student Work & Teacher Practices in Science 23168a75 2 0 160b143 136 129 28c17 9 6 18 37 21 25 158 159 153 133 29 28 22 8 42 2 4 4 3 0 139 154 157 142 13 24 26 16 4 9 20 67 150 157 159 148 23 29 29 19 3 8 16 73 144 157 162 149 17 30 32 19Students ' Reports on How Often Their Teachers Use Different Teaching Activities, Grade 12: Public and Nonpublic Schools CombinedTABLE 5.5 When you study science, how often does your teacher do each of the following?Grade 12 Almost Once or Twice Once or Twice Never or Every Day a Week a Month Hardly Ever Talk to the class about science Do a science demonstrationShow a science videotape or TV science program Use computers for science Use CDs or laser disks on science aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics. National Assessment of Educational Progress (NAEP),1996 Science Assessment. Hands-on Tasks The importance of using hands-on activities in science instruction is widely accepted in both theory and practice. According to the American Association for the Advancement of Science,\"construing habits of mind to include manipulation and observation skills raises no eyebrows in science. Scientists know that finding answers to questions about nature means using one 's hands and senses as well as one 's head. \" 10 As seen in tables 5.2 and 5.3, almost all fourth- and eighth-grade teachers reported that their students did hands-on tasks at least once or twice amonth, and 88 percent of twelfth-grade students who were studying science said that they, too,did hands-on activities at least once or twice a month. Some teachers do shy away from hands-on tasks, claiming that they lack the necessary content knowledge, do not have enoughmaterials, or that the tasks require too much time and effort. 11 Nevertheless, hands-on activities appear to be widely used in regular science instruction. 10American Association for the Advancement of Science. (1993). Benchmarks for science literacy. W ashington, DC: Author. 11Sumrall, W . J. Science 32(4), 16-19. Haury, D. L. & P . of hands-on science teaching . W ashington, DC: Office of Educational Research and Improvement.232 Student Work & Teacher Practices in ScienceStudents in grades 4 and 8 were asked if they had ever done any hands-on activities or projects in school with living things, electricity, chemicals, rocks/minerals, a magnifying glass/microscope, a thermometer/barometer, or with simple machines. Grade 12 students were askedif they had ever done science investigations or projects in school using the same list ofmaterials. 12 In addition, grade 12 students were asked if they had ever done science investigations or projects in school with instruments for measuring speed and velocity. Studentsat all three grade levels were also asked to indicate if they had done \"none of the above \" activities. To all of the questions, students could either respond in the affirmative or notrespond at all; students not responding are assumed to have not done the activity. The resultsfor grades 4, 8, and 12 are shown in table 5.6. Several patterns emerge from the data. First, inall three grades more students reported having done each activity than reported not having donethat activity, with one exception: at grade 4, over half (57 percent) of students said they had notdone a hands-on activity with simple machines. The percentages of students at grade 4 who haddone hands-on activities ranged from 52 percent for activities involving thermometers orbarometers to 63 percent for activities with living things. For eighth graders, the range was from55 percent for activities with simple machines to 81 percent for activities with chemicals, andfor twelfth graders from 64 percent for activities measuring speed or velocity to 88 percent forinvestigations or projects using either chemicals or magnifying glasses or microscopes.Eighteen percent of fourth graders, 6 percent of eighth graders, and 3 percent of twelfth gradersindicated that they had used \"none of the above \" to do hands-on tasks. For each variable, scale scores and achievement levels were tested for differences between those who indicated that they had used living things, electricity, chemicals, rocks/minerals, magnifying glass/microscope, thermometer/barometer, simple machines, orinstruments for measuring speed and velocity (grade 12 only) and those who did not respond. Atgrade 4, students who said they had done hands-on activities or projects with a magnifying glassor microscope had higher scale scores than those not responding, and students who said theyhad done hands-on activities or projects with living things had lower scale scores than those notresponding. In addition, the percentage of students at or above Proficient was higher for those who had done hands-on activities using a magnifying glass or microscope than for those who didnot respond. Fourth graders who responded that they had done \"None of the Above \" hands-on tasks had lower scale scores and were less likely to be at or above the Proficient level than students not responding. At grades 8 and 12, for each activity or project, students whoresponded affirmatively had higher scale scores and were more likely to be at or above theProficient level than students who did not respond. Students who indicated that they had done \"None of the Above \" had lower scale scores and were less likely to be at or above the Proficient level than those who did not respond. There was one exception to this pattern: at grade 12, thepercentage of students at or above Proficient was the same for those who had done hands-on activities with rocks/minerals as for those who did not respond. 12Includes data from all grade 12 students, not only those taking science.Student Work & Teacher Practices in Science 23363a37 71 29 87 13 149b152 154 140 153 128 28c30 33 20 23 7 54 46 69 31 74 26 149 151 153 143 155 136 27 31 32 22 25 11 56 44 81 19 88 12 151 149 154 134 154 121 30 28 32 15 23 5 53 47 64 36 69 31 151 149 153 145 152 145 29 28 31 25 21 21 57 43 80 20 88 12 152 148 154 134 153 124 30 27 32 15 23 7 52 48 69 31 80 20 150 150 155 139 155 128 29 29 33 19 25 7 43 57 55 45 69 31 150 150 155 144 157 135 30 28 33 24 26 10 64 36 154 142 24 15 18 82 6 94 3 97 130 154 117 152 114 151 12 32 6 30 6 22TABLE 5.6 Grade 4 Grade 8 Grade 12 Yes No Yes No Yes NoStudents ' Reports on Doing Hands-on Tasks, Grades 4, 8, and 12: Public and Nonpublic Schools Combined Have you ever done hands-on activities or projects in school with any of the following? Living things (plants, animals, bacteria) Electricity (batteries, flashlight) Chemicals (mixing or dissolving)Rocks/Minerals (identifying type)Magnifying glass/microscopeThermometer/barometerSimple machines (pulleys and levers) Instruments for measuring speed and velocity* None of the Above * Question not asked at grades 4 and 8 aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient NOTE: Questions only offered a \"yes\" option. Students not responding were assumed to have not done the activity and are included in the \"no\" category. NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics. National Assessment of Educational Progress (NAEP),1996 Science Assessment.234 Student Work & Teacher Practices in ScienceTABLE 5.7 Grade 4 Grade 8 Grade 12 Yes No Yes No Yes No Percentage of Students 60 40 64 37 68 32 Average Scale Score 150 151 152 147 155 142 Percentage At or Above Proficient 29 29 31 26 25 15Do you ever do science projects in school that take a week or more?Students ' Reports on Whether or Not They Conduct Science Projects or Investigations that Take a Week or More, Grades 4, 8, and 12: Public and Nonpublic Schools Combined NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics. National Assessment of Educational Progress (NAEP),1996 Science Assessment.Investigations Taking a Week or More Real-world questions in science are usually not answered quickly. Formulating hypotheses, developing and carrying out experiments, analyzing data, and drawing conclusions require timeand persistence. As teachers attempt to expose their classes to the methods and thinking ofscience, it is useful for students to participate in investigations that progress over a period oftime. Students at grades 4, 8, and 12 were asked if they had ever done science projects inschool that took a week or more to complete. The results are presented in table 5.7. Sixty percent of students at grade four, 64 percent at grade eight, and 68 percent at grade 12 reported having done a science project that took a week or more. At grades 8 and 12,this activity was positively associated with performance; students who indicated that they hadengaged in long-term projects had higher scale scores and were more likely to be at or abovethe Proficient level than students who indicated that they had not.Student Work & Teacher Practices in Science 23513 Executive Office of the President. (1996). National technology literacy goals. Washington, DC: US Government Printing Office. 14 Heaviside, S., Riggins, T., & Farris, E. (1997 ). Advanced telecommunications in U.S. public elementary and secondary schools, fall 1996 . W ashington, DC: National Center for Education Statistics. 15American Association for the Advancement of Science. (1993). Benchmarks for science literacy. W ashington, DC: Author. National Research Council of the American Academy of Sciences. (1995). National science education standards. W ashington, DC: Author. 16Cordes, C. (1998, January 16). As educators rush to embrace technology, a coterie of skeptics seeks to be heard. The Chronicle of Higher Education , 44 (19), A25-26. 17 O'Sullivan, C. Y., W eiss, A. R., & Askew, J. M. (1998). Students learning science: A report on policies and practices in U.S. schools . (NCES Publication No. 98-496) W ashington, DC: National Center for Education Statistics. 18Ibid.Computers and Science Instruction A good deal of support exists nationally for the use of computers in schools. America 's Technology Literacy Challenge , a 1996 White House initiative, called for all classrooms to be equipped with modern computers and connected to the Internet, and for teachers to be trained \"to help students learn through computers. \"13 As of fall 1996, 65 percent of U.S. public schools had internet access, and most that did not planned to be connected by the end of the decade.14 Many educators, including science educators in the American Association for the Advancement ofScience (AAAS) and the National Research Council of the American Academy of Sciences, alsosupport the goal of integrating computers into the classroom. According to the AAAS, \"students should start using calculators and computers early and use them in as many different contexts aspossible. Properly used over time, calculators and computers can actually help students learnmathematics and acquire quantitative thinking skills \" necessary for science achievement. 15 The rush to technology has not gone unchallenged. Critics express concern that computers might beused in age-inappropriate ways, undermine the critical relationship between teacher and student,become a substitute for more important activities, and draw resources away from more criticalareas. 16 Reflecting the growing interest in computers in classrooms, students participating in the 1996 NAEP science assessment and their teachers were asked a number of questions regardingcomputer use. Teachers of 15 percent of fourth-grade students and 16 percent of eighth-gradestudents reported having no computers available for their science classes, whereas teachers of53 percent of fourth graders and 38 percent of eighth graders said they had at least onecomputer in their classrooms. 17 Teachers of the remaining 32 percent of fourth graders and 46 percent of eighth graders reported having computers available in computer laboratories,although the computers were not necessarily easy to access. 18 Most teachers made infrequent use of computers in their science classes. Tables 5.2 and 5.3 of this chapter show that at grades4, 8, and 12 approximately two thirds of students never or hardly ever used a computer forscience, and tables 5.4 and 5.5 reveal that at all three grades about two thirds of students hadteachers who never or hardly ever used a computer for teaching science.236 Student Work & Teacher Practices in ScienceWhen teachers did use computers for science instruction, how did they use them? Teachers of students in grades 4 and 8 were asked if they used computers for any of five tasksor if they did not use computers for instruction. The results are shown in table 5.8. At thefourth-grade level, computers were used most frequently for playing science/learning games (30percent of students) and least frequently for \"drill and practice \" and \"data analysis and other applications \" (5 percent and 6 percent of students, respectively). Teachers of 53 percent of grade 4 students reported they did not use computers for science instruction. An analysis ofperformance data shows that grade 4 students whose teachers did not use computers forinstruction had lower scale scores and were less likely to reach the Proficient level than those students whose teachers did use computers. Students whose teachers used computers forplaying science/learning games and for word processing had higher scale scores and were moreoften at or above Proficient than students whose teachers did not use computers for these purposes. Also, students whose teachers used computers for simulations and modeling hadhigher scale scores than those students whose teachers did not. Teachers of grade 8 students who used computers tended to place a somewhat different emphasis on their use than teachers of grade 4 students, generally reflecting the more highlydeveloped cognitive skills of the older children. Twenty-five percent, 19 percent, and 22percent of students had teachers who used computers for simulations and modeling, dataanalysis, and word processing, respectively. Twenty-one percent of students had teachers whoused computers for playing science/learning games. Forty-six percent of students had teacherswho reported not using computers for science instruction. Among eighth graders, there were nodifferences in scale scores or percentages at or above Proficient that were associated with how computers were used.Student Work & Teacher Practices in Science 237Teachers ' Reports on How They Use Computers for Science Instruction, Grades 4 and 8: Public and Nonpublic Schools CombinedTABLE 5.8 How do you use computers for instruction in science?Grade 4 Grade 8 Yes No Yes No 5a95 8 92 149b151 156 151 28c30 36 30 30 70 21 79 154 149 152 152 33 28 29 31 18 82 25 75 155 150 155 151 34 29 32 30 69 4 1 9 8 1 149 151 152 152 29 30 30 31 10 90 22 78 159 150 154 151 37 29 34 30 53 47 46 54 148 154 150 153 27 32 29 32Drill and practice Playing science/learning gamesSimulations and modelingData analysis and other applicationsWord processingI do not use computers for science instruction. aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics. National Assessment of Educational Progress (NAEP),1996 Science Assessment. Homework The effectiveness of homework \u2014 its contribution to student learning \u2014 depends on many factors, including the quality and appropriateness of the assignments, the amount of homeworkassigned, and the attention given to completed assignments by teachers. Studies indicate that,in general, homework is correlated with higher achievement among high school students, withsomewhat higher achievement among middle school students, and with no difference inachievement among grade school students. Moreover, assignments of more than about one hourper night tend to raise achievement for high school students but not for elementary or juniorhigh school students. 19 Teachers of fourth- and eighth-grade students who participated in the 19Black, S. (1996). The truth about homework. American School Board Journal, 183 (10), 48-51.238 Student Work & Teacher Practices in Science1996 NAEP science assessment were asked how much time they expected students in their classes to spend doing science homework each week. The results are shown in table 5.9. One infive grade 4 students was not expected to do any science homework, 38 percent were expected to do one-half hour of science homework each week, and 33 percent were expected to do one hourof science homework each week. There was no relationship between scale scores or thepercentage of students at or above Proficient and teachers ' reports of the amount of homework expected. More science homework was assigned in the eighth grade. Thirteen percent ofstudents had teachers who expected them to spend one-half hour or less on science homework each week and 47 percent had teachers who expected them to spend two hours or more onscience homework each week. Eighth-grade students whose teachers expected them not to doany science homework had lower scale scores than those whose teachers expected them to do anhour or more a week. Students whose teachers expected them to spend one-half hour a week on science homework had lower scale scores than those whose teachers expected them to spend two hours or more a week on science homework. The same differences were seen in the percentageof students at or above Proficient . Teachers ' Reports on How Much Science Homework They Assign, Grades 4 and 8: Public and Nonpublic Schools CombinedTABLE 5.9 About how much time do you expect a student in this class to spend doing science homework each week?Grade 4 Grade 8 Two Two One Half One Hours or One Half One Hours or None Hour Hour More None Hour Hour More Percentage of Students 20 38 33 9 2 11 40 47 Average Scale Score 152 149 152 147 134 144 152 155 Percentage At or Above Proficient 30 29 31 28 15 21 31 35 NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics. National Assessment of Educational Progress (NAEP),1996 Science Assessment.Student Work & Teacher Practices in Science 239Summary As part of the NAEP 1996 science assessment, teachers of students in grades 4 and 8 and students in grades 4, 8, and 12 were afforded the opportunity to respond to questions directlyrelated to classroom activities. Grade 4 Seventy-eight and 15 percent of students, respectively, were taught by teachers who reported placing heavy emphasis on understanding key science concepts and ondeveloping laboratory skills and techniques. Students had higher average scale scores and were more likely to be at or above the Proficient level if their teachers placed a heavy emphasis on understanding key science concepts than if their teachers did not. Forty-seven percent of students were taught by teachers who reported assigning hands on activities or investigations to students once or twice a week. Sixty percent of students indicated that they had done science projects that took a week or more. Approximately half the student population had teachers who reported not using computers for instruction in science, whereas 30 percent of students had teachers whoreported using the computer to play science/learning games during science instruction. One fifth of the student population had teachers who reported expecting no time to be spent on science homework each week. Grade 8 Eighty-eight and 41 percent of students, respectively, were taught by teachers who reported placing heavy emphasis on understanding key science concepts and on developinglaboratory skills and techniques. Students had higher average scale scores and were more likely to be at or above the Proficient level if their teachers placed a heavy emphasis on understanding key science concepts or on developing laboratory skills and techniques than if their teachers did not. Sixty-two percent of students were taught by teachers who reported assigning hands-on activities or investigations to students once or twice a week. Students who did hands-onactivities almost every day or once or twice a week had higher scale scores than studentswho did hands-on activities once or twice a month or never or hardly ever. Sixty-four percent of students indicated that they had done science projects that took a week or more. Forty-six percent of students had teachers who reported not using computers for instruction in science, whereas 25 percent of students had teachers who reported using computers forsimulations and modeling during science instruction. Eighty-seven percent of students had teachers who reported expecting one or more hours to be spent on science homework each week.240 Student Work & Teacher Practices in ScienceGrade 12 Forty-two percent of students currently taking science reported doing hands-on activities or investigations once or twice a week. Students who did hands-on activities almost every dayor once or twice a week demonstrated higher performance than students who did hands-onactivities once or twice a month or never or hardly ever. The greater the frequency with which teachers talked to their students about science, the higher the students ' scale scores. Sixty-eight percent of students indicated that they had conducted science investigations that took a week or more.Chapter 6 Student Work & Teacher Practices in Science 241Attitudes, Motivation, and School Climate Introduction What students learn in school is influenced by many things beyond what teachers plan for their classes. Students ' attitudes, the interest and involvement of parents, and school climate all can affect teaching and learning both positively and negatively, although it would be inadvisable toassume a causal connection between any single variable and a student 's performance. As part of the NAEP 1996 science assessment, all students were asked questions concerning theirattitudes and beliefs about science and their motivation and performance on the assessment.School administrators were asked questions about parental involvement in their schools andabout school climate. Taken together, this information creates further context for understandingstudent performance in the science assessment. The tables in this chapter present three sets of data: percentages of students who responded to or whose teachers responded to questions in the student and teacherquestionnaires; the average scale scores of students; and the percentages of students at or aboveProficient . The following example demonstrates how these data can be read. In the top left-hand box in table 6.1 there are three numbers with superscripts: 67 a, 153b, and 32c. score, and superscript 'c' denotes percentage at or above Proficient . Sixty-seven percent of students reported liking science. These students had an average scale score of 153, and 32 percent of them were at orabove the Proficient level.242 Student Work & Teacher Practices in Science1Nolen, S. B. & Haladyna, T. M. (1990). Motivation and studying in high school science. Journal of Research in Science Teaching, 27(2), 115-26. Swanson, C. B. (1995). How technology in the chemistry classroom affects students ' attitudes and motivation. Teaching and Change 3(1), 63-75. Nemerow, L.G. (1996). Do classroom games improve motivation and learning? Teaching and Change 3(4), 356-66.Student Attitudes and Beliefs about Science It is well understood among educators that students learn best when they are motivated. As seen in the previous chapter, in addition to teaching content, teachers of nearly all fourth- andeighth-grade students placed a moderate or heavy emphasis on developing their students ' interest in science (see Table 5.1). Science teachers try many ways to motivate their students,from simply exhibiting enthusiasm for the subject to stimulating interest by using hands-ontasks, technology, games, and other techniques. 1 Are teachers ' efforts successful? What do students think about science? Students at grades 4, 8, and 12 were asked how much they agreed with eight statements regarding theirattitudes and beliefs about science. The results are presented in Table 6.1 for all students andby gender, in Table 6.2 for all students and by race/ethnicity, and in Table 6.3 as a compositebased on how many positive attitudes toward science students had. Throughout the discussionthat follows, the terms \"positive attitudes \" and \"negative attitudes \" refer specifically to the way students responded to six of the eight statements. The positive attitudes consisted of the \"agree \" responses to three statements \u2014 \"I like science, \" \"I am good at science, \" and \"Science is useful for solving everyday problems \" \u2014 and the \"disagree \" responses to three statements \u2014 \"Learning science is mostly memorizing, \" \"If I had a choice I would not study any more science in school, \" and \"Science is boring. \" Conversely, \"disagree \" responses to the first three questions and \"agree \" responses to the latter three questions were interpreted as negative attitudes. \"Not sure \" responses and all responses to the statements \"Everyone can do well in science if they try \" and \"Science is a hard subject \" were considered to be neither positive nor negative. Students ' responses show that their attitudes toward science were, on average, neither very positive nor very negative. Fourth graders seemed to be the most favorably disposed toscience, with eighth and twelfth graders being somewhat less so.Student Work & Teacher Practices in Science 243The picture becomes more complex when women and minorities are considered separately. Women and minorities have historically been underrepresented in the fields ofscience and engineering. Two causes that have been identified as contributing to thisunderrepresentation are negative attitudes and perceptions of science and poor academicperformance in science on the part of women and minorities. According to Clewell, Anderson,and Thorpe, \"factors affecting females ' and minorities ' attitudes include a poor self-concept as a 'doer' of math or science; their negative perception of the utility of these subjects in 'real life '; the stereotyping of math and science as White male activities; and the influence of significantothers, such as parents, teachers, and peers, in discouraging participation in these subjects. \" Moreover, research has suggested that the relatively poorer academic performanceof females and minorities stems, in part, from their more negative attitudes and beliefsabout science. 2 All Students Among fourth-grade students, 67 percent said they liked science and 64 percent said theywould continue to study it even though less than half (45 percent) believed they were good at it.Eighty-four percent thought everyone can do well in science if they try. Forty percent thoughtscience was mostly memorizing. A majority of students, 70 percent, did not agree that scienceis boring (see Table 6.1). Half of eighth graders (50 percent) said they liked science and would continue to study it if it were their choice. Forty percent thought science is useful for solving everyday problemsand 37 percent thought it is a hard subject. Forty-seven percent of eighth-grade studentsbelieved themselves to be good at science, although 67 percent believed everyone could do wellif they tried. As with eighth graders, about half of twelfth graders (52 percent) said they liked science. However, 43 percent thought they would continue to study it if given the choice(compared to 50 percent of eighth graders and 64 percent of fourth graders). Twelfth graderswere more likely to recognize the relevance of science than were younger students; half agreedit was useful for solving everyday problems. Twelfth graders were also more likely than fourthand eighth graders to think that science was hard (50 percent), less likely to think that theywere good at it (39 percent), and less likely to think that everyone can do well at it (49 percent). 2Clewell, B. C., Anderson, B. T., & Thorpe, M. E. (1992). Breaking the barriers: Helping female and minority students succeed in mathematics and science . San Francisco, CA: Jossey-Bass Publishers. Skolnick, J., Langbort, C., & Day, L. (1982). How to encourage girls in math & science . Englewood Cliffs, NJ: Prentice- Hall, Inc.244 Student Work & Teacher Practices in ScienceIn many cases, what could be considered positive attitudes toward science correlated with higher performance. For example, students who liked science outperformed those who didnot. However, readers are again cautioned against drawing conclusions regarding causality; it isimpossible to tell from the data presented whether students did better because they likedscience, whether they liked science because they did well at it, or because of a combination ofthese and other variables. At the fourth-grade level, students who said they liked science or were good at science had higher scale scores and were more likely to perform at or above the Proficient level than those who said they were not sure or did not like science. Students who indicated that they werenot sure if they were good at science outperformed those who did not think they were good at it.Students who disagreed that learning science is mostly memorizing and students who were notsure of this outperformed students who agreed that it is mostly memorizing. Students who wouldstudy more science if given the choice and who did not think science was boring had higherscale scores and were more likely to reach the Proficient level than those who would not study any more or thought science was boring. Eighth- and twelfth-grade students who agreed that they liked science, that they were good at science, or that science was useful for solving everyday problems had higher scalescores and were more likely to be at or above the Proficient level than their counterparts who were not sure or disagreed with these three statements. Students who answered that they werenot sure outperformed those who disagreed with the three statements. Students who agreed thatscience was boring or that they would not study it if they had the choice had lower scale scoresand were less likely to reach the Proficient level than students who were not sure or who disagreed, while students who were not sure were outperformed by those who disagreed. Eighthgraders who thought science was a hard subject had lower scale scores and were less likely toreach the Proficient level than students who did not think science was hard. Finally, twelfth graders who disagreed that science was mostly memorizing outperformed those who were notsure or who agreed, while those who thought that everyone can do well in science if they trywere outperformed by those who were not sure or disagreed with that statement.Student Work & Teacher Practices in Science 245Students ' Reports on Attitudes and Beliefs about Science, by Gender, Grade 4: Public and Nonpublic Schools CombinedTABLE 6.1 How much do you agree with the following statements?All Students Males Females Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree 67a23 10 68 22 11 66 25 10 153b146 144 154 146 143 151 145 145 32c24 20 35 26 20 29 22 21 45 45 10 49 41 10 41 49 10 156 148 135 157 149 134 154 148 136 36 26 13 38 27 14 33 24 12 40 36 24 42 35 23 38 38 25 146 153 155 149 153 155 143 153 154 24 31 34 28 33 36 21 30 32 35 34 32 36 33 31 33 35 32 152 151 149 152 153 149 151 148 149 32 30 26 34 34 26 29 26 25 17 19 64 19 18 62 14 19 66 140 144 155 143 144 156 137 144 154 19 24 33 22 26 36 16 23 30 84 10 5 83 11 6 86 10 4 151 152 139 153 151 138 150 153 142 29 34 22 32 34 22 26 35 23 15 15 70 17 15 69 13 16 72 141 143 154 142 141 156 138 144 153 19 24 33 21 24 36 17 23 30 27 31 42 28 29 43 26 32 42 146 152 152 148 153 153 145 151 152 25 31 31 28 33 32 22 28 29 aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everyday problems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.246 Student Work & Teacher Practices in ScienceStudents ' Reports on Attitudes and Beliefs about Science, by Gender, Grade 8: Public and Nonpublic Schools CombinedTABLE 6.1 (continued) How much do you agree with the following statements?All Students Males Females Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.50a28 21 54 26 20 47 30 23 157b146 141 158 145 140 155 147 141 37c24 18 39 24 19 34 24 17 . 4 7 3 7 1 65 2 3 31 4 4 2 4 01 8 162 143 133 163 142 132 161 145 134 43 21 10 44 21 10 41 21 10 33 36 31 34 37 29 32 36 32 150 149 152 150 150 155 150 149 149 28 28 32 29 30 37 27 27 28 40 34 25 42 33 25 39 36 25 156 151 141 157 152 141 155 150 140 37 29 18 38 31 19 35 26 18 23 27 50 22 27 52 24 28 48 141 148 156 141 149 157 141 147 155 18 27 36 18 29 38 17 25 34 67 22 11 67 21 12 67 22 11 148 157 151 149 158 151 147 157 151 26 37 31 29 39 32 24 36 30 28 26 46 27 25 48 28 27 44 144 149 156 144 148 158 144 149 154 21 27 36 22 28 39 20 26 33 37 30 32 37 30 33 38 31 32 148 150 154 147 151 156 148 149 151 26 29 33 27 31 36 25 28 30I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everyday problems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.Student Work & Teacher Practices in Science 247Students ' Reports on Attitudes and Beliefs about Science, by Gender, Grade 12: Public and Nonpublic Schools CombinedTABLE 6.1 (continued) How much do you agree with the following statements?All Students Males Females Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.52a22 26 56 22 22 48 23 29 161b142 136 164 141 137 158 142 136 32c1 2 9 3 7 1 3 1 12 71 1 7 39 37 24 45 36 19 33 38 29 166 146 132 169 145 130 164 146 134 39 14 5 43 15 6 34 13 5 34 27 39 34 30 37 34 25 41 147 146 157 149 148 161 145 144 153 17 17 29 20 19 36 14 14 23 50 30 20 51 29 20 50 31 20 159 144 139 162 146 140 155 143 138 30 15 10 35 19 11 25 12 8 33 24 43 30 26 44 36 22 43 141 145 161 141 147 165 140 144 157 11 15 33 13 17 40 9 13 27 49 29 22 51 29 20 48 29 23 147 154 155 151 155 156 143 152 154 19 25 24 23 29 29 14 22 19 25 25 50 23 26 50 26 23 51 137 146 159 139 148 163 136 144 156 9 1 7 3 01 2 1 93 6 7 1 42 4 50 26 23 44 29 27 56 24 20 150 150 154 151 151 159 149 148 147 19 21 28 23 23 34 16 19 20I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everyday problems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.248 Student Work & Teacher Practices in ScienceGender Results from the NAEP 1996 science assessment show that male and female performance was the same at both grades 4 and 8 but that males outperformed females at grade 12.3 Did the attitudes of male and female students toward science also start out the same and then diverge? As shown in Table 6.1, among fourth graders, male and female attitudes toward science were generally similar; equal numbers of students indicated they liked science and did notthink it was boring or mostly memorizing. Although males were as likely as females to thinkthat science is a hard subject (28 percent vs. 26 percent), they were more likely to think thatthey were good at it (49 percent vs. 41 percent). At eighth grade, more males than females likedscience (54 percent vs. 47 percent), and 10 percent more males than females thought they weregood at it (52 percent vs. 42 percent). Answers to the other questions did not differ betweenmales and females at grade 8. Attitudes diverged somewhat more at grade 12. As with eighthgraders, more males than females liked science (56 percent vs. 48 percent) and thought theywere good at it (45 percent vs. 33 percent). In addition, more females than males at grade 12said they would not study more science if they had a choice (36 percent vs. 30 percent) andmore females than males agreed that science was a hard subject (56 percent vs. 44 percent). There were differences in performance between males and females at fourth and twelfth grade associated with some of the attitudes and beliefs presented in Table 6.1. There were nodifferences at eighth grade. In each instance where differences were found, males outperformedfemales. This took place regardless of whether the attitudes were positive, negative, or unclear.For example, at the fourth-grade level, males who liked science \u2014 a positive attitude \u2014 were more likely to be at or above Proficient than were females who liked science. Males who agreed that learning science was mostly memorizing \u2014 a negative attitude \u2014 had higher scale scores and were more likely to be at or above Proficient than females who felt the same way. Males who were not sure if science is useful for solving everyday problems \u2014 an unclear attitude \u2014 were more likely to have reached the Proficient level than females who were not sure if science is useful. Among twelfth graders, males who liked science outperformed females who likedscience, males who believed they were good at science outperformed females who believed theywere good at science, males who would study more science if given the choice outperformedfemales who would study more science, and males who did not think science is boringoutperformed females who did not think science is boring. Males who thought learning scienceis mostly memorizing were more likely to be at or above the Proficient level than were females with the same attitude, but males who did not think learning science is mostly memorizing alsooutperformed females who did not think learning science is mostly memorizing. It should benoted that the comparisons above are between male and female students giving the sameresponses to the questions (i.e., males who agree compared to females who agree, males whodisagree compared to females who disagree). 3O'Sullivan, C. Y., Reese, C. M., & Mazzeo, J. (1997). NAEP 1996 science report card for the nation and the states . W ashington, DC: National Center for Education Statistics.Student Work & Teacher Practices in Science 249Race/Ethnicity Do members of different racial and ethnic groups have different attitudes toward science? Table 6.2 provides data on the attitudes and performance of White (not Hispanic), Black (notHispanic), Hispanic, Asian/Pacific Islander, and American Indian students. NAEP createsthese subgroups based on students ' reports of their race/ethnicity. The discussion below highlights those areas in which student attitudes differed the most, usually by eight to tenpercent or more. There were additional instances in which the differences in attitudes werefound to be statistically significant but were not large enough to be considered noteworthy. Among fourth graders, attitudes toward science differed somewhat, but not a great deal, among members of different racial/ethnic groups. Forty-seven percent of White students and 47percent of Black students thought they were good at science, compared to 37 percent ofHispanic students and 35 percent of Asian/Pacific Islander students. Thirty-seven percent ofWhite students believed learning science was mostly memorizing, compared to 48 percent ofBlack students and 45 percent of Hispanic students. More White students (32 percent) andBlack students (35 percent) disagreed that science is useful for solving everyday problems thandid Asian/Pacific Islander students (24 percent). Sixty-six percent of White students said theywould not stop studying science if they had a choice, compared to 59 percent of their Blackpeers. Seventy-two percent of White students disagreed that science is boring, compared to 64percent of Black students. At the eighth-grade level, a greater percentage of White students (50 percent) thought they were good at science than did either Hispanic students (35 percent) or Asian/PacificIslander students (39 percent). More Black students (46 percent) than Hispanic students alsobelieved they were good at science. Fifteen percent of American Indian students disagreed withthe statement \"science is useful for solving everyday problems, \" a smaller percentage than for White (25 percent), Black (27 percent), or Hispanic (29 percent) students. White students wereless likely to agree that everyone can do well in science if they try (63 percent) and more likelyto disagree (13 percent) than were Black (77 percent and 8 percent), Hispanic (74 percent and9 percent), or Asian/Pacific Islander (80 percent and 5 percent) students. Asian/PacificIslander students were less likely to agree that science is boring (20 percent) than were White(29 percent) and American Indian (39 percent) students. Black students were more likely todisagree that science is a hard subject (41 percent) than White (31 percent), Hispanic (30percent), Asian/Pacific Islander (26 percent), or American Indian (28 percent) students.250 Student Work & Teacher Practices in Science67a23 10 67 23 10 64 23 13 153b146 144 162 156 153 126 121 126 32c24 20 41 31 27 8 5 6 45 45 10 47 44 9 47 41 13 156 148 135 165 157 145 127 124 117 36 26 13 45 33 18 9 6 4 40 36 24 37 38 25 48 30 22 146 153 155 157 161 163 123 126 127 24 31 34 33 39 42 6 8 7 35 34 32 35 33 32 35 30 35 152 151 149 161 160 158 125 123 125 32 30 26 41 38 33 8 6 7 17 19 64 16 18 66 21 20 59 140 144 155 152 156 163 116 117 130 19 24 33 27 33 41 3 6 9 84 10 5 84 11 5 86 8 6 151 152 139 160 162 152 126 120 116 29 34 22 37 43 31 7 8 3 15 15 70 14 14 72 18 19 64 141 143 154 151 157 162 118 116 129 19 24 33 26 33 41 5 5 8 27 31 42 26 32 42 29 25 46 146 152 152 156 161 161 124 119 128 25 31 31 33 39 39 7 5 8Students ' Reports on Attitudes and Beliefs about Science, by Race/Ethnicity, Grade 4: Public and Nonpublic Schools CombinedTABLE 6.2 How much do you agree with the following statements?All Students White Black Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everyday problems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.Student Work & Teacher Practices in Science 25164a27 9 71 23 6 70 20 11 131b124 124 154 143 \u2014 149 \u2014\u2014 11c7 6 34 16 \u2014 30 \u2014\u2014 37 52 11 35 57 8 42 48 10 133 129 114 158 149 \u2014 156 139 \u2014 12 9 3 41 23 \u2014 35 22 \u2014 45 34 21 42 38 21 49 31 20 126 130 134 149 150 159 144 144 \u2014\u2014 8 9 14 25 27 38 27 26 \u2014\u2014 33 37 30 36 40 24 31 34 35 129 128 130 153 152 147 143 146 144 10 9 8 31 29 24 20 31 27 18 21 61 10 24 66 20 16 64 119 119 135 \u2014\u2014 138 159 \u2014\u2014 \u2014\u2014 152 57 1 1 \u2014\u2014 15 37 \u2014\u2014 \u2014\u2014 31 83 12 5 90 8 2 83 10 6 130 129 107 151 \u2014\u2014 \u2014\u2014 146 \u2014\u2014 \u2014\u2014 91 2 1 2 8 \u2014\u2014 \u2014\u2014 27 \u2014\u2014 \u2014\u2014 16 17 67 9 16 75 17 18 65 122 115 134 \u2014\u2014 \u2014\u2014 156 \u2014\u2014 \u2014\u2014 151 76 1 1 \u2014\u2014 \u2014\u2014 33 \u2014\u2014 \u2014\u2014 31 30 31 40 23 40 36 30 20 51 124 130 131 142 153 155 132 \u2014\u2014 153 7 1 1 1 01 6 2 83 7 1 4 \u2014\u2014 35Students ' Reports on Attitudes and Beliefs about Science, by Race/Ethnicity, Grade 4: Public and Nonpublic Schools CombinedTABLE 6.2 (continued) How much do you agree with the following statements?Hispanic Asian/Pacific Islander American Indian Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students b Average Scale Score cPercentage At or Above Proficient \u2014\u2014Sample size was insufficient to permit reliable estimates. NOTE: Percentages may not add up to 100 due to rounding. SOURCE: National Center for Education Statistics. National Assessment of Educational Progress (NAEP), 1996 Science Assessment.I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everyday problems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.252 Student Work & Teacher Practices in Science50a28 21 51 27 22 50 28 21 157b146 141 166 157 148 126 118 115 37c24 18 46 31 22 8 3 1 47 37 16 50 35 15 46 36 18 162 143 133 170 153 141 128 117 111 43 21 10 52 27 13 8 3 0 33 36 31 32 36 33 39 36 25 150 149 152 160 159 160 124 120 118 28 28 32 36 36 39 5 5 6 40 34 25 41 35 25 41 32 27 156 151 141 166 159 150 125 124 112 37 29 18 47 36 24 6 6 3 23 27 50 22 27 51 24 27 49 141 148 156 150 158 165 114 119 126 18 27 36 23 34 45 2 3 7 67 22 11 63 24 13 77 15 8 148 157 151 158 164 158 120 126 119 26 37 31 35 44 36 4 9 4 28 26 46 29 24 47 26 29 45 144 149 156 151 159 166 114 123 125 21 27 36 26 36 45 1 6 7 37 30 32 38 30 31 33 26 41 148 150 154 156 160 165 119 121 123 26 29 33 32 37 43 4 5 6Students ' Reports on Attitudes and Beliefs about Science, by Race/Ethnicity, Grade 8: Public and Nonpublic Schools Combined How much do you agree with the following statements?All Students White Black Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everyday problems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.TABLE 6.2 (continued)Student Work & Teacher Practices in Science 25346a34 20 49 36 15 39 33 27 135b123 125 161 148 135 148 \u2014\u2014 \u2014\u2014 14c8 8 41 25 12 26 \u2014\u2014 \u2014\u2014 35 46 19 39 48 14 39 39 22 142 125 118 166 146 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 20 7 5 49 22 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 34 39 26 32 41 27 31 33 36 132 128 128 157 147 155 \u2014\u2014 \u2014\u2014 \u2014\u2014 13 11 8 34 23 39 \u2014\u2014 \u2014\u2014 \u2014\u2014 37 34 29 46 33 21 36 49 15 132 130 123 157 152 144 \u2014\u2014 \u2014\u2014 \u2014\u2014 13 11 8 34 31 25 \u2014\u2014 \u2014\u2014 \u2014\u2014 23 29 48 16 31 53 37 27 36 123 127 134 141 144 161 \u2014\u2014 \u2014\u2014 151 8 1 0 1 32 1 2 34 0 \u2014\u2014 \u2014\u2014 33 74 17 9 80 15 5 72 16 12 129 134 126 150 \u2014\u2014 \u2014\u2014 151 \u2014\u2014 \u2014\u2014 10 13 13 28 \u2014\u2014 \u2014\u2014 29 \u2014\u2014 \u2014\u2014 24 32 43 20 36 44 39 26 35 126 128 132 142 151 159 \u2014\u2014 \u2014\u2014 \u2014\u2014 10 11 12 19 29 38 \u2014\u2014 \u2014\u2014 \u2014\u2014 36 33 30 39 35 26 38 34 28 127 127 134 145 154 161 \u2014\u2014 \u2014\u2014 \u2014\u2014 9 8 16 23 31 42 \u2014\u2014 \u2014\u2014 \u2014\u2014Students ' Reports on Attitudes and Beliefs about Science, by Race/Ethnicity, Grade 8: Public and Nonpublic Schools CombinedTABLE 6.2 (continued) How much do you agree with the following statements?Hispanic Asian/Pacific Islander American Indian Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient \u2014\u2014Sample size was insufficient to permit reliable estimates. NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics. National Assessment of Educational Progress (NAEP), 1996 Science Assessment.I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everydayproblems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.254 Student Work & Teacher Practices in Science52a22 26 54 21 25 47 22 32 161b142 136 169 151 144 134 116 116 32c12 9 39 16 12 7 1 2 39 37 24 42 36 23 38 36 25 166 146 132 174 155 140 135 121 113 39 14 5 47 18 7 7 3 0 34 27 39 32 27 41 42 25 32 147 146 157 155 155 165 126 119 126 17 17 29 22 21 36 3 3 5 50 30 20 52 30 19 48 30 22 159 144 139 167 153 147 129 119 121 30 15 10 37 20 13 5 3 2 33 24 43 33 24 43 35 24 42 141 145 161 147 154 171 119 121 130 11 15 33 14 20 42 2 2 6 49 29 22 44 31 25 61 25 14 147 154 155 158 161 159 123 124 130 19 25 24 26 31 27 3 5 6 25 25 50 24 24 51 29 24 46 137 146 159 145 155 168 114 122 132 9 1 7 3 31 3 2 13 7 0 3 6 50 26 23 53 26 21 38 25 37 150 150 154 156 159 168 125 121 126 19 21 28 23 27 40 5 3 4Students ' Reports on Attitudes and Beliefs about Science, by Race/Ethnicity, Grade 12: Public and Nonpublic Schools Combined How much do you agree with the following statements?All Students White Black Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everyday problems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.TABLE 6.2 (continued)Student Work & Teacher Practices in Science 25547a28 26 56 29 15 44 24 32 140b121 123 162 139 128 \u2014\u2014 \u2014\u2014 \u2014\u2014 12c3 3 32 14 5 \u2014\u2014 \u2014\u2014 \u2014\u2014 27 45 28 31 45 25 29 41 29 150 126 119 173 143 132 \u2014\u2014 \u2014\u2014 \u2014\u2014 20 3 3 46 14 8 \u2014\u2014 \u2014\u2014 \u2014\u2014 34 29 37 38 26 36 32 21 47 132 126 133 148 143 157 \u2014\u2014 \u2014\u2014 \u2014\u2014 85 9 1 8 1 7 3 1 \u2014\u2014 \u2014\u2014 \u2014\u2014 40 35 25 57 31 12 50 22 28 139 124 125 157 143 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 14 2 4 28 18 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 32 27 41 21 26 53 28 21 51 126 123 139 137 146 157 \u2014\u2014 \u2014\u2014 \u2014\u2014 44 1 2 8 1 9 3 0 \u2014\u2014 \u2014\u2014 \u2014\u2014 61 25 14 66 24 10 44 25 \u2014\u2014 128 133 137 146 154 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 79 9 2 0 2 5 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 24 27 49 16 29 55 23 19 58 124 122 139 137 148 154 \u2014\u2014 \u2014\u2014 \u2014\u2014 25 1 1 9 2 4 2 6 \u2014\u2014 \u2014\u2014 \u2014\u2014 48 28 24 56 27 17 52 26 22 132 128 131 149 149 153 \u2014\u2014 \u2014\u2014 \u2014\u2014 87 7 2 0 2 3 2 9 \u2014\u2014 \u2014\u2014 \u2014\u2014Students ' Reports on Attitudes and Beliefs about Science, by Race/Ethnicity, Grade 12: Public and Nonpublic Schools CombinedTABLE 6.2 (continued) How much do you agree with the following statements?Hispanic Asian/Pacific Islander American Indian Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students b Average Scale Score cPercentage At or Above Proficient \u2014\u2014Sample size was insufficient to permit reliable estimates. NOTE: Percentages may not add up to 100 due to rounding. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everyday problems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.256 Student Work & Teacher Practices in ScienceAttitudes at grade 12 followed a pattern closer to that at grade 8 than at grade 4. Among twelfth graders, a greater percentage of White (25 percent) and Black (32 percent) studentsdisagreed with the statement \"I like science \" than did Asian/Pacific Islander students (15 percent). Moreover, fewer Black students (47 percent) agreed with the statement than did Whitestudents (54 percent). Forty-two percent of White students said they were good at science,compared to 27 percent of Hispanic students and 31 percent of Asian/Pacific Islander students.A greater percentage of Black students than Hispanic students said they were good at science(38 percent compared to 27 percent). Asian/Pacific Islander students were relatively likely toagree and unlikely to disagree that science is useful for solving everyday problems. Fifty-sevenpercent agreed, compared to 40 percent of Hispanic students, and 12 percent disagreed,compared to 19 percent of White, 22 percent of Black, 25 percent of Hispanic, and 28 percentof American Indian students. A higher percentage of White (33 percent), Black (35 percent),and Hispanic (32 percent) students agreed that if given the choice they would not study anymore science in school than did Asian/Pacific Island students (21 percent). As at eighth grade,White students were less likely to agree (44 percent) and more likely to disagree (25 percent)that everyone can do well in science if they try than were Black (61 percent and 14 percent),Hispanic (61 percent and 14 percent), or Asian/Pacific Islander (66 percent and 10 percent)students. Fewer Asian/Pacific Islander students (16 percent) agreed that science is boring thandid White (24 percent), Black (29 percent), or Hispanic (24 percent) students. Black studentswere less likely to agree (38 percent) and more likely to disagree (37 percent) that science is ahard subject than were White (53 percent and 21 percent), Hispanic (48 percent and 24percent), or Asian/Pacific Islander (56 percent and 17 percent) students. Positive Attitudes To develop a more complete picture of student attitudes, data from the questions about beliefsand attitudes were combined and compared to provide a sense of how favorably students feltabout science. A positive attitude index was developed based on student responses to six of thebackground questions \u2014 the \"agree \" responses to three statements \u2014 \"I like science \"; \"I am good at science \"; and \"Science is useful for solving everyday problems \" \u2014 and the \"disagree \" responses to three statements \u2014 \"Learning science is mostly memorizing \"; \"If I had a choice I would not study any more science in school \"; and \"Science is boring. \" Table 6.3 presents the percentages of students, average scale score, and percentages at or above Proficient for the range of positive attitudes \u2014 from zero positive attitudes to six positive attitudes for each of grades 4, 8, and 12. The index gives composite values for attitudes; therefore, there is no way toknow which of the positive attitudes students displayed, except when the number of positiveattitudes is either zero or six. At all three grades, students were dispersed across the range of positive attitudes, although the lowest percentage at each grade had all six positive attitudes. Among fourthStudent Work & Teacher Practices in Science 257TABLE 6.3 Number of Positive Attitudes 0123 4 56Relationship Between Students ' Average Scale Scores and Positive Attitudes and Beliefs about Science, Grades 4, 8, and 12: Public and Nonpublic Schools Combined Grade 4 Percent of Students 8 12 15 23 27 13 2 Average Scale Score 141 141 141 148 155 163 180 Percentage At or Above Proficient 19 21 20 25 33 43 71 Grade 8 Percent of Students 14 19 17 16 16 13 5 Average Scale Score 143 141 142 148 157 165 180 Percentage At or Above Proficient 19 19 19 27 35 47 68 Grade 12 Percent of Students 16 19 15 14 14 13 9 Average Scale Score 137 136 139 149 157 168 185 Percentage At or Above Proficient 7 8 12 19 25 39 62 NOTE: The Positive Attitude Index is a composite score based on student responses to six questions in the Student Background Questionnaire. The Agree responses to three questions: ( \"I like science \"; \"I am good at science \"; and \"Science is useful for solving everyday problems \") and the Disagree responses to three questions: ( \"learning science is mostly memorizing \"; \"if I had a choice I would not study any more science in school \"; and \"science is boring \") were combined to form the index. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.graders, 2 percent had six positive attitudes and 8 percent had zero positive attitudes, whereas 23 percent had three positive attitudes and 27 percent had four positive attitudes. At grades 8 and12, fifty percent of students had 2 or fewer positive attitudes. Five percent of eighth graders and 9percent of twelfth graders had six positive attitudes. An examination of performance data at each grade shows a fairly consistent pattern in which the greater the number of positive attitudes over two or three, the higher the studentperformance (students with zero, one, or two positive attitudes performed similarly to eachother). At grade 4, scale scores rose with each positive attitude over two, and the percentage ofstudents at or above Proficient rose with each positive attitude over three. At grade 8, scale scores and the percentage of students at or above Proficient rose with each positive attitude over two, with one exception: The percentage of students at or above Proficient did not differ significantly between those with three positive attitudes and those with four positive attitudes.Among twelfth graders, scale scores increased with each positive attitude over two, and thepercentage of students at or above Proficient also increased with each positive attitude over two, with one exception: There was no difference in the percentage at or above Proficient for students with three positive attitudes and students with four positive attitudes.258 Student Work & Teacher Practices in Science4Kiplinger, V . L. & Linn, R. L. (1993 ). Raising the stakes of test administration: The impact on student performance on NAEP . W ashington, DC: National Center for Education Statistics. Burke, P . (1991). You can lead adolescents to a test but you can 't make them try . Final Report. W ashington, DC: U.S. Office of Technology Assessment.Students ' Motivation on the NAEP Science Assessment Because students do not receive individual scores on NAEP assessments, there is some question as to how strongly they are motivated to try to do well.4 Students participating in the NAEP 1996 science assessment were asked four questions related to their experiences takingthe assessment. Two of the questions were about how well students thought they performed andtwo questions were about how motivated students were to do well. A fifth question asked ifstudents had been required to write long answers to questions on tests during the school year. Itwas designed to explore how well students might have been prepared for the type ofconstructed-response questions found on the assessment. The results are presented in Tables6.4 and 6.5. Among fourth graders, 40 percent thought they answered almost all of the questions on the assessment correctly and 6 percent thought they answered less than half correctly. At theeighth-grade level, 18 percent thought they answered almost all questions correctly and 11percent thought they got less than half correct. At the twelfth-grade level, 13 percent said theygot almost all the questions right, whereas 23 percent said they got less than half right. According to their responses, older students were less motivated to do well on the assessment than were younger students. Forty-two percent of fourth graders said they triedmuch harder on the NAEP science assessment than on other science tests and 9 percent saidthey did not try as hard. Among eighth graders, 18 percent said they tried much harder and 16percent said they did not try as hard. At twelfth grade, 6 percent said they tried much harderwhile 39 percent said they did not try as hard. Similarly, doing well appears not to have been asimportant to older students. Doing well was very important to 59 percent of fourth graders, 25percent of eighth graders, and 9 percent of twelfth graders, whereas doing well was not veryimportant to 5 percent of fourth graders, 15 percent of eighth graders, and 29 percent of twelfthgraders. An examination of student performance data reveals numerous differences among students based on their motivation and performance on the NAEP science assessment. Forexample, at the fourth-grade level, the more questions students thought they got right, the bettertheir performance, although there was no difference between students who thought they gotalmost all the questions right and those who thought they got more than half right. Fourthgraders who thought the assessment was harder than most science tests and those who thoughtit was about as hard as most science tests outperformed students who thought it was eithereasier or much harder than other science tests. Trying hard on the test did not necessarily correlate with better performance at grade 4. Students who said they tried about as hard on the NAEP assessment as they did on otherscience tests outperformed students who said they tried much harder, harder, and not as hard.However, students who did not try as hard as on other science tests were outperformed bystudents in the other three categories.Student Work & Teacher Practices in Science 259Similarly, there was not a consistent positive relationship between how important it was for fourth-grade students to do well and how well they did. Students for whom it was not as importantto do well on NAEP as on other science tests had lower scale scores and were less likely to be ator above the Proficient level than were students for whom it was somewhat important, important, or very important. However, students for whom it was very important to do well had lower scalescores and were less likely to be at or above the Proficient level than were students for whom it was important to do well, and they were also less likely to be at or above the Proficient level than were students for whom it was somewhat important to do well. Finally, students who indicated that they had been asked to write long answers on science tests and assignments once or twice a month outperformed students who had writtenlong answers at least once a week, once or twice a year, or never. Students who said they werenever asked to write long answers were outperformed by all other students. 5 At the eighth-grade level, the more questions students thought they had answered correctly, the better they performed. Students who thought the NAEP assessment was muchharder than other science tests were outperformed by students who thought it was harder, aboutas hard, or easier. As at the fourth-grade level, trying hard or thinking it important to do welldid not necessarily relate to higher performance. Students who tried about as hard on the NAEPassessment as they did on other science tests outperformed students who tried much harder,harder, or not as hard as they did on other tests, and students who tried much harder on NAEPactually performed less well than all other students. Students who thought it was very importantto do well had lower average scale scores than those who thought it was important or somewhatimportant to do well; there were no differences in the percentages at or above Proficient . As at fourth grade, eighth-grade students who indicated that they never were asked to write longanswers to science questions did not perform as well as students who were asked to write them. Twelfth graders, like eighth graders, had a good sense of how well they performed; the more questions they thought they got right, the better their scale scores and the more likely thatthey would be at or above the Proficient level. Twelfth graders also were good judges of how difficult the assessment was for them. The easier they thought it was, the better they performed.However, higher student motivation did not relate to better performance. In fact, students whoseresponses indicated that they were the most motivated to do well on the assessment did not dothe best and those whose responses showed them to be the least motivated did not do the worst.Students who said they tried about as hard on NAEP as on other tests or not as hard as on othertests outperformed students who said either that they tried harder or much harder, and studentswho said it was very important for them to do well had lower scale scores than those who said itwas important, somewhat important, or not very important. Finally, the more often twelfth graders had been asked to write long answers to science questions, the better they performed, except there was no difference between those who saidthey were asked to write long answers at least once a week and those who said they were askedto write long answers once or twice a month. 5Eighty percent of the assessment time in the NAEP 1996 science assessment was devoted to constructed-response questions.260 Student Work & Teacher Practices in ScienceStudents ' Reports About their Motivation and Performance on the NAEP Science Assessment, Grades 4 and 8: Public and Nonpublic Schools CombinedTABLE 6.4 Education Grade 4 Grade 8 Percentage Percentage Percentage Average At or Above Percentage Average At or Above of Students Scale Score Proficient of Students Scale Score Proficient About how many questions do you think you got right. . .? Almost All 40 153 34 18 165 50 More Than Half 37 154 32 42 157 36 About Half 17 144 18 29 141 16 Less Than Half 6 129 9 11 127 6 How hard was this test compared to most other tests. . .? Much Harder 23 142 20 14 136 15 Harder 20 155 36 26 152 31 About as Hard 30 156 36 34 154 34 Easier 27 147 23 26 152 29 How hard did you try on this test compared to how hard you tried on most other science tests. . .? Much Harder 42 148 24 18 135 14 Harder 19 151 31 21 147 25 About as Hard 30 159 39 45 159 38 Not as Hard 9 134 14 16 150 28 How important was it to do well. . .? Very Important 59 149 27 25 146 26 Important 26 154 33 33 151 30 Somewhat Important 9 153 35 27 154 32 Not as Important 5 137 15 15 151 30 This year in school, how often have you been asked to write long answers to questions on tests. . .? At Least Once a Week 40 150 28 39 152 31 Once or Twice a Month 29 156 37 35 155 34 Once or Twice a Year 15 150 30 15 148 26 Never 16 141 18 11 135 14 NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 261Students ' Reports About their Motivation and Performance on the NAEP Science Assessment, Grade12: Public and Nonpublic Schools CombinedTABLE 6.5 Education Grade 12 Percentage Percentage Average At or Above of Students Scale Score Proficient About how many questions do you think you got right. . .? Almost All 13 175 53 More Than Half 33 164 33 About Half 31 145 11 Less Than Half 23 126 2 How hard was this test compared to most other tests. . .? Much Harder 12 128 5 Harder 21 143 13 About as Hard 34 150 18 Easier 33 166 38 How hard did you try on this test compared to how hard you tried on most other science tests. . .? Much Harder 6 127 4 Harder 11 134 9 About as Hard 44 156 25 Not as Hard 39 154 24 How important was it to do well. . .? Very Important 9 139 14 Important 25 152 23 Somewhat Important 36 153 22 Not as Important 29 152 23 This year in school, how often have you been asked to write long answers to questions on tests. . .? At Least Once a Week 28 156 27 Once or Twice a Month 26 156 28 Once or Twice a Year 13 149 21 Never 33 143 13 NOTE: Percentages may not add to 100 due to rounding. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.262 Student Work & Teacher Practices in ScienceParental Involvement in School When school personnel and parents develop an effective means of communication, they strengthen the learning environment for the students both at school and at home.6 One of the reasons cited most frequently by school personnel for contacting parents is to request parentvolunteer time in school. 7 As part of the NAEP 1996 science assessment, school administrators in grades 4, 8, and 12 were asked a number of questions about how frequently they tried toinvolve parents in the teaching and learning process. The administrators were asked tocategorize this frequency as \"Yes, routinely, \" \"Y es, occasionally, \" or \"No.\" For the purposes of this report the second two categories \u2014 \"Y es, occasionally \" and \"No\" \u2014 were combined. The results are presented in Table 6.6. As the data show, the higher the grade level, the less likely schools were to involve parents in the four activities described. For example, 39 percent of grade 4 students attendedschools that reported regularly using parents as aides in classrooms. This number decreased to13 percent in grade 8 and 4 percent in grade 12. The only parental activity that was sustainedin any appreciable measure across all three grades was having a parent volunteer program.According to school administrators, 78 percent of grade 4 students, 55 percent of grade 8students, and 41 percent of grade 12 students attended schools that routinely had parentvolunteer programs. Performance data show no differences in average scale scores or thepercentage of students at or above Proficient associated with parental involvement at any of the three grades. 6Griffith, J. (1996). Relation of parental involvement, empowerment, and school traits to student academic performance. Journal of Educational Research, 90(1), 33-41. Rutherford, B. et al. (1995). Parent and community involvement in education. Vol.I: Findings and conclusions. Studies of education reform. W ashington, DC: Office of Educational Research and Improvement. Illinois State Board of Education. (1993 ). The relationship between parent involvement and student achievement: a review of the literature . Springfield, IL: Author. 7U.S. Department of Education. (1995). The Condition of Education, 1995. Washington, DC: National Center for Education Statistics.Student Work & Teacher Practices in Science 263Schools ' Reports on Parental Involvement, Grades 4, 8 and 12: Public and Nonpublic Schools CombinedTABLE 6.6 Education Grade 4 Grade 8 Grade 12 Yes No Yes No Yes NoDoes your school do any of the following to involve parents? SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Use parents as aides in the classroom Percentage of Students 39 61 13 87 4 96 Average Scale Score 151 150 155 150 144 151 Percentage At or Above Proficient 30 29 37 29 15 22 Have parents review or sign students ' homework Percentage of Students 70 30 53 47 8 92 Average Scale Score 149 152 153 148 145 151 Percentage At or Above Proficient 28 30 31 28 17 22 Assign homework for students to do with parents Percentage of Students 33 67 24 76 3 97 Average Scale Score 149 151 151 151 151 151 Percentage At or Above Proficient 27 30 29 29 21 21 Have a parent volunteer program Percentage of Students 78 22 55 45 41 59 Average Scale Score 150 148 152 149 150 151 Percentage At or Above Proficient 30 26 31 27 21 21264 Student Work & Teacher Practices in Science8Pitkiff, E. (1993). Teacher absenteeism: What administrators can do. NASSP Bulletin, 77(551), 39-45. See also Ehrenberg, R. G., et al. (1991). School district leave policies, teacher absenteeism, and student achievement. Journal of Human Resource, 26(1), 72-105.Perceived School Problems Studies have shown that \"teacher absenteeism appears highest in elementary schools, schools with lower student achievement, schools composed of economically disadvantaged and minoritystudents, and urban school districts. Teachers holding temporary teaching certificates wereabsent more often and poorly achieving students had more temporary and absent teachers. \" 8 A number of questions included in the NAEP 1996 science assessment school questionnaire weredesigned to gather data about the types of challenges schools face as they strive to provideoptimal learning environments for their students. Specifically, school administrators were askedto evaluate the seriousness of certain problems in their schools along a continuum that included\"not a problem, \" \"minor problem, \" \"moderate problem, \" and \"serious problem. \" Responses to three of the questions \u2014 covering student absenteeism, teacher absenteeism, and parental involvement \u2014 are found in Table 6.7. The data indicate that although most students attended schools where these three problems were generally not thought to be serious, many students, and in some cases a majority,were exposed to them to some degree. Moreover, more students were exposed to worse degreesof the problems as grade level increased. For example, in all three grades a majority of studentsattended schools in which student absenteeism was considered to be at least a minor problem:57 percent at the fourth-grade level, 67 percent at the eighth-grade level, and 85 percent at thetwelfth-grade level. Fifteen percent of fourth graders, 20 percent of eighth graders, and 51percent of twelfth graders attended schools where the problem was moderate or serious. Nofourth- or eighth-grade students and one percent of twelfth-grade students attended schoolswhere teacher absenteeism was considered to be a serious problem, but 41 percent of fourthgraders, 45 percent of eighth graders, and 56 percent of twelfth graders attended schools whereit was a minor or moderate problem. Lack of parental involvement was not a problem where 29percent of fourth graders, 14 percent of eighth graders, and 15 percent of twelfth gradersattended school, but it was a moderate or serious problem where 36 percent of fourth graders,40 percent of eighth graders, and 46 percent of twelfth graders attended school. An examination of scale score and achievement level data at the three grades reveals many differences in performance associated with different responses to the questions. Althoughthere was not a difference in performance for each comparison, every difference that wasmeasured fit the same pattern: the more severe the problem, as reported by schooladministrators, the lower the scale score and/or percentage of students at or above Proficient . For example, at the eighth-grade level, students attending schools where lack of parentalinvolvement was a serious problem had lower scale scores than students attending schoolswhere it was not a problem. Students in schools where lack of parental involvement was amoderate problem had lower scale scores and were less likely to be at or above the Proficient level than students in schools where lack of parental involvement was a minor problem or wasnot a problem.Student Work & Teacher Practices in Science 265Schools ' Reports on the Severity of Three Problems in the School, Grades 4 and 8: Public and Nonpublic Schools CombinedTABLE 6.7 To what degree is each of the following a problem in your school?Moderate Serious Not a Problem Minor Problem Problem Problem Grade 4 Student Absenteeism Percentage of Students 44 42 11 4 Average Scale Score 156 148 141 124 Percentage At or Above Proficient 35 27 20 7 Teacher Absenteeism Percentage of Students 58 34 7 0 Average Scale Score 155 146 134 \u2014\u2014 Percentage At or Above Proficient 33 24 15 \u2014\u2014 Lack of Parental Involvement Percentage of Students 29 35 29 7 Average Scale Score 157 153 143 135 Percentage At or Above Proficient 36 32 21 15 Grade 8 Student Absenteeism Percentage of Students 33 47 18 2 Average Scale Score 158 150 142 \u2014\u2014 Percentage At or Above Proficient 38 28 20 \u2014\u2014 Teacher Absenteeism Percentage of Students 55 39 6 0 Average Scale Score 155 147 139 \u2014\u2014 Percentage At or Above Proficient 34 26 18 \u2014\u2014 Lack of Parental Involvement Percentage of Students 14 46 32 8 Average Scale Score 159 154 145 140 Percentage At or Above Proficient 40 32 22 22 \u2014\u2014Sample size was insufficient to permit reliable estimates. NOTE: Percentages may not add to100 due to rounding. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.266 Student Work & Teacher Practices in ScienceSchools ' Reports on the Severity of Three Problems in the School, Grade 12: Public and Nonpublic Schools CombinedTABLE 6.7 (continued) To what degree is each of the following a problem in your school?Moderate Serious Not a Problem Minor Problem Problem Problem Grade 12 Student Absenteeism Percentage of Students 15 34 40 11 Average Scale Score 161 152 149 136 Percentage At or Above Proficient 28 22 20 12 Teacher Absenteeism Percentage of Students 43 46 10 1 Average Scale Score 153 150 140 \u2014\u2014 Percentage At or Above Proficient 23 21 14 \u2014\u2014 Lack of Parental Involvement Percentage of Students 15 39 38 8 Average Scale Score 161 156 145 132 Percentage At or Above Proficient 32 24 17 9 \u2014\u2014Sample size was insufficient to permit reliable estimates. SOURCE: National Center for Education Statistics,National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 267Summary As part of the NAEP 1996 science assessment, students were asked about their beliefs and attitudes vis- \u00e0-vis science, and school administrators were asked questions about parental involvement in their schools and also about school problems such as student and teacherabsenteeism. The data show the following: \u007fAmong fourth-grade students, 67 percent said they liked science. The percentages of students at grades 8 and 12 who said they liked science were somewhat lower \u2014 50 and 52 percent, respectively. \u007fAt all three grades, students who agreed with the statement \"I like science \" outperformed their counterparts who disagreed with the statement \"I like science. \" \u007fAt the fourth-grade level, 47 percent of White students and 47 percent of Black students thought they were good at science compared to 37 percent of Hispanic students and 35percent of Asian/Pacific Islander students. \u007fAt the eighth-grade level, a greater percentage of White students (50 percent) thought they were good at science than did either Hispanic students (35 percent) or Asian/PacificIsland students (39 percent). More Black students (46 percent) than Hispanic students(35 percent) thought that they were good at science. \u007fAt the twelfth-grade level, 42 percent of White students said they were good at science compared to 27 percent of Hispanic students and 31 percent of Asian/Pacific Islanderstudents. A greater percentage of Black students (38 percent) than Hispanic students(27 percent) indicated the same thing. \u007fIn general, the greater the number of positive attitudes towards science, the higher the performance of students at grades 4, 8, and 12. \u007fForty percent, 18 percent, and 13 percent of students in grades 4, 8, and 12, respectively, thought they had answered almost all the questions on the assessment correctly. \u007fFifty-nine percent, 25 percent, and 9 percent of students in grades 4, 8, and 12, respectively, thought it was very important to do well on the NAEP science assessment. \u007fAccording to school reports, 78 percent of grade 4 students, 55 percent of grade 8 students, and 41 percent of grade 12 students attended schools that had parent volunteer programs. \u007fThe more severe a school problem (such as student absenteeism), as reported by school administrators, the lower the student performance.Appendix A Student Work & Teacher Practices in Science 269Overview of Procedures Used for the NAEP 1996 Science Assessment Conducting a large-scale assessment such as the National Assessment of Educational Progress (NAEP) entails the successful coordination of numerous projects, committees, procedures, andtasks. This appendix provides an overview of the NAEP 1996 science assessment 's primary components: the framework, instrument development, administration, scoring, and analysis.A more extensive review of the procedures and methods used in the science assessment isincluded in two technical reports: the Technical Report of the NAEP 1996 State Assessment Program in Science and the NAEP 1996 Technical Report . 1 The Science Framework The science framework for the 1996 National Assessment of Educational Progress was produced under the auspices of the National Assessment Governing Board (NAGB) through aconsensus process managed by the Council of Chief State School Officers, which worked withthe National Center for Improving Science Education and the American Institutes forResearch. 2 The framework was developed over a 10-month period between October 1990 and August 1991. The following factors guided the process for developing consensus on the scienceframework: \u007fThe active participation of individuals such as curriculum specialists, science teachers, science supervisors, state assessment developers, administrators,individuals from business and industry, government officials, and parents; 1Allen, N. L., Swinton, S. .S., Isham, S. P. & Zelenak, C.A. (1997). Technical report of the NAEP 1996 state assessment program in science (Publication No. NCES 98-480). W ashington, DC: National Center for Education Statistics. Allen, N. L., Carlson, J., & Zelenak, C.A. (in press) The NAEP 1996 technical report (NCES Publication No. 98-479). Washington, DC: National Center for Education Statistics. 2National Assessment Governing Board. (1995). Science framework for the 1996 National Assessment of Educational Progress . W ashington, DC: Author.270 Student Work & Teacher Practices in Science\u007fThe representation of what is considered essential learning in science, and the recommendation of innovative assessment techniques to probe the critical abilitiesand content areas; and \u007fThe recognition of the lack of agreement on a common scope of instruction and sequence, components of scientific literacy, important outcomes of learning, and thenature of overarching themes in science. While maintaining some conceptual continuity with the NAEP 1990 science assessment framework, the 1996 framework acknowledges some of the reforms currently taking place inscience education as well as documents such as the science framework used for the 1991International Assessment of Educational Progress. In addition, the Framework SteeringCommittee recommended that a variety of strategies be used for assessing students ' performance. These included: \u007fMultiple-choice questions that assess students ' knowledge of important facts and concepts and that probe their analytical reasoning skills; \u007fConstructed-response questions that explore students ' abilities to explain, integrate, apply, reason about, plan, design, evaluate, and communicate science information;and \u007fHands-on tasks that probe students ' abilities to use materials to make observations, perform investigations, evaluate experimental results, and apply problem-solvingskills. The Assessment Design Each student in the assessment received a booklet comprising six sections, or blocks. Three ofthese blocks consisted of cognitive questions that assessed the knowledge and skills outlined inthe framework. 3 The other three blocks were sets of background questions. Students at grades 8 and 12 were allowed 30 minutes to complete each cognitive block, while students at grade 4were given cognitive blocks that required 20 minutes to complete. The background questionstook students in each grade about ten minutes to answer. Thus students in grade 4 tookapproximately 70 minutes to answer the cognitive and background questions whereas studentsin grades 8 and 12 took approximately 100 minutes. 3National Assessment Governing Board. (1995). Science framework for the 1996 National Assessment of Educational Progress. Washington, DC: Author.Science Work & Teacher Practices in Science 271At each grade level there were 15 different sections, or blocks, of cognitive questions, usually consisting of both multiple-choice and constructed-response questions. Four of thefifteen blocks at each grade level presented hands-on tasks. In these tasks, students were givensets of equipment and asked to conduct an investigation and answer questions related to theinvestigation. Every student conducted a hands-on task. Three of the 15 blocks assessed themes. One of the three addressed systems, a second addressed models, and a third addressed patterns of change. For example, students were showna simplified model of part of the solar system, with a brief description, and then were asked anumber of questions based on that information. Theme blocks were placed randomly in thestudent booklets. Not every booklet contained a theme block, but no booklet contained morethan one theme block. The Background Questionnaires As part of the national NAEP 1996 science assessment, approximately 2,500 teachersresponsible for teaching science to students who participated in the fourth- and eighth-gradeassessments responded to a questionnaire. The questionnaires were composed of two sections.One section contained questions about teachers ' backgrounds, education, and resources. The other asked about teachers ' science preparation and instructional practices. Teacher sampling for the teacher questionnaires was based on participating students, hence the responses do notnecessarily represent all fourth- and eighth-grade teachers in the nation. Rather, they representteachers of a representative sample of students in the assessment. Consequently, the findingsportray the nature of students ' instructional experiences and the backgrounds of their teachers. There was no background teacher questionnaire at grade 12 because approximately half thestudents that participated in the NAEP science assessment were not enrolled in a sciencecourse and thus could not be linked to any teacher. Approximately 700 principals or other administrators of sampled schools at grades 4, 8, and 12 completed a school questionnaire for the main NAEP study. Each of the grade-specificquestionnaires focused on five areas: instructional content, instructional practices andexperiences, teacher characteristics, school conditions and contexts, and conditions outside theschool (i.e., home support, out-of-school activities, and attitudes). Approximately 23,000 students in grades 4, 8, and 12 in main NAEP responded to three sets of background questions in addition to science cognitive exercises. The backgroundquestions probed students ' general backgrounds, their science experiences, and their motivations.272 Student Work & Teacher Practices in ScienceIt is important to note that in this report, as in all NAEP reports, the student is the unit of analysis, even when information from teacher or school questionnaires is reported. This isbecause the sampling for the teacher and school questionnaires was based on participatingstudents and does not represent all teachers or schools in the nation or in a state. For example,when discussing how much science homework teachers reported assigning to students, NAEPcan report that 38 percent of fourth-grade students were expected to spend one-half hour onscience homework each week. National Samples Results presented in this report are based on nationally representative probability samples offourth-, eighth-, and twelfth-grade students. The samples were selected using a complexmultistage sampling design that involved sampling students from selected schools withinselected geographic areas across the country. The sample design had the following stages: 1. Selection of primary sampling units (geographic areas such as: a county, group of counties, or metropolitan statistical area) 2. Selection of schools (public and nonpublic) within the selected areas3. Selection of students within the selected schoolsEach selected school that participated in the assessment and each student assessed represents a portion of the population of interest. Sampling weights are needed to make validinferences between the student samples and the respective populations from which they weredrawn. In addition, NAEP oversamples nonpublic schools and schools in which more than 15percent of the student population is non-White. Sampling weights adjust for disproportionaterepresentation due to such oversampling. Table A.1 provides a summary of the weighted and unweighted student sample sizes for the national NAEP 1996 science assessment. The numbers reported include public andnonpublic school students. Unweighted Student Weighted Student Number of Schools Sample Size Sample SizeNational School and Student Sample SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. Table A.1 Grade 4 237 7,305 3,621,677 Grade 8 202 7,774 3,568,034 Grade 12 232 7,537 2,907,065Science Work & Teacher Practices in Science 273Data Collection and Scoring Data collection for the main NAEP assessment was conducted by trained field staff from W estat, the NAEP grantee for data collection. For the state component of the assessment, datawere collected by local school personnel trained by W estat representatives. Materials from theassessment were shipped to National Computer Systems (NCS), where trained scorers evaluatedthe responses to the constructed-response questions using scoring rubrics or guides prepared byEducational Testing Service (ETS). Each constructed-response question had a unique scoringguide that defined the criteria used to evaluate students ' responses. The extended constructed- response questions were evaluated with four- or five-level guides, while the short constructed-response questions were rated according to two- or three-level guides. The constructed-response questions were scored using NCS 's image technology. Scorers working at computer terminals (image stations) scored students ' responses on-line. This tool allowed for several advantages. First, training could be conducted on one item at a time ratherthan a block of items. Second, responses that were to be scored twice as an indicator ofreliability could be routed automatically to a second scorer. Information on adjacent and perfectagreement, score distribution, and quantity of responses scored was available on demand.Third, backreading of student responses could be accomplished in a timely manner, allowingfor ongoing evaluation of the accuracy of scores assigned by the scorers. The training for scoring constructed-response questions was conducted on an item-by- item basis. Each scoring team consisted of approximately 10 scorers, one table leader, and onetrainer. A set procedure was employed for each training session that utilized anchor papers,practice papers, calibration papers, and, in addition, for the extended constructed-responsequestions, qualification sets. First, scorers were introduced to the question and scoring guide.Second, the trainer explained each anchor paper vis- \u00e0-vis the scoring guide. Third, each member of the team scored a set of practice papers, and then discussed the responses as agroup. If the question required an extended response, scorers were given a set of qualificationpapers to score. Eighty percent exact agreement was required to qualify for scoring. When thetrainer and table leader were confident that the scorers were ready, scoring commenced. Duringthe beginning stages of scoring, responses that had previously not been encountered werediscussed by the team to ensure that scoring decisions not addressed in training were handledin the same manner by all team members. For the national science assessments, just over 1 million constructed responses were scored. This number includes rescoring to monitor interrater reliability. The overall percentagesof agreement for the 1996 national reliability samples were 94 percent at grade 4, 94 percent atgrade 8, and 93 percent at grade 12.274 Student Work & Teacher Practices in ScienceData Analysis and IRT Scaling of Student Responses Subsequent to the professional scoring, all information was transcribed to the NAEP database at ETS. Each processing activity was conducted with rigorous quality control. After theassessment information had been compiled in the database, the data were weighted according tothe population structure. The weighting for the national and state samples reflected theprobability of selection for each student as a result of the sampling design, adjusted fornonresponse. Through stratification, the weighting ensured that the representation of certainsubpopulations corresponded to figures from the U.S. Census and the Current PopulationSurvey. 4 Analyses were then conducted to determine the percentages of students that gave various responses to each cognitive and background question. Item Response Theory (IRT) was used to estimate average science scale scores for the nation, for various subgroups of interest within the nation, and for the jurisdictions. IRT modelsthe probability of answering a question in a certain way as a mathematical function ofproficiency or skill. The main purpose of IRT analysis is to provide a common scale on whichperformance can be compared across groups (for example, those defined by characteristics suchas gender and race/ethnicity). The item mapping is also based on IRT. Because of the complex way the blocks of items are placed in booklets, students do not receive enough questions about a specific topic to provide reliable information about individualperformance. Traditional test scores for individual students, even those based on IRT, wouldlead to misleading estimates of population characteristics, such as subgroup means andpercentages of students at or above a certain scale score level. Consequently, NAEP constructssets of plausible values designed to represent the distribution of performance in the population.Plausible values for an individual are not scale scores for that individual but may be regardedas representative values from the distribution of potential scale scores for all students in thepopulation with similar characteristics and identical patterns of item response. Statisticsdescribing performance on the NAEP science scale are based on the plausible values. Theyestimate values that would have been obtained had individual scale scores been observed, thatis, had each student responded to a sufficient number of cognitive questions so that his or herindividual scores could be estimated precisely. 5 4For additional information about the use of weighting procedures in NAEP , see Johnson, E. G. (1989). Considerations and techniques for the analysis of NAEP data. Journal of Educational Statistics, 14, 303-334. 5For theoretical and empirical justification of the procedures employed, see Mislevy, R. J. (1991). Randomization-based inferences about the latent variables from complex samples. Psychometrika, 56 (2), 177-196. For computational details, see E. G. Johnson & R. Zwick (Eds.), Focusing the new design: The NAEP 1988 technical report (pp. 267-296). W ashington, DC: National Center for Education Statistics and Johnson, E. G., & Allen, N. L. (1992). The NAEP 1990 technical report (No.21-TR-20). Princeton, NJ: Educational Testing Service, National Assessment of Educational Progress.Science Work & Teacher Practices in Science 2756Allen, N. L., Carlson, J., & Zelenak, C.A. (in press) The NAEP 1996 technical report (Publication No. NCES 98-479). W ashington, DC: National Center for Education Statistics. 7For the national assessment, a primary sampling unit is a selected geographic region (a county, a group of counties, or metropolitan statistical areas).At each grade, three distinct 0-to-300 scales were created to summarize students ' abilities in the three defined fields of science: earth, physical, and life. The scales summarizestudent performance across all three question types in the assessment (multiple-choice, shortconstructed-response, and extended constructed-response). For each grade, the mean for eachfield of science was set at 150 and the standard deviation at 35. Constraining the mean andstandard deviation of the scales to 150 and 35 also constrained, to some degree, the locations ofthe percentiles for the total group of students at each grade. However, within-grade comparisonsof percentiles across subgroups still provide valuable comparative information. This reportingmetric was developed using data from the national assessment program, and the results for thestate assessment program were linked to these scales. Because the assessment was developedusing a new framework, it was not appropriate to compare or link the results from the 1996assessments to previous NAEP science assessments. In addition to the plausible values for each scale, a composite of the three fields of science scales was created as a measure of overall science performance. This composite was aweighted average of the plausible values for the three science scales, in which the weights wereproportional to the relative importance assigned to each field of science in the assessmentframework. More detailed information about data analysis and items are presented in the 1996 NAEP Technical Report . 6 NAEP Reporting Groups Findings from the NAEP 1996 science assessment are presented for groups of students defined by shared characteristics. Data are reported for subgroups only when sufficient numbers ofstudents and adequate school representation are present. There must be at least 62 students ina particular subgroup from at least six different primary sampling units. 7 Data for all students, regardless of whether their subgroups were reported separately, were included in computingoverall national results. The reporting subgroups presented in this report are gender andrace/ethnicity.276 Student Work & Teacher Practices in Science8Bourque, M.L., Champagne, A.B., & Crissman, S. (1997). 1996 science performance standards: Achievement results for the nation and the states . W ashington, DC: National Assessment Governing Board.Achievement Level Results NAEP results are reported for student performance according to the newly defined achievement levels set by the NAGB. The results are expressed as percentages of students or percentages ofselected subgroups who have reached Basic , Proficient , and Advanced levels. The three levels are at each grade and are cumulative in nature. That is, it is assumed that students at theProficient level are likely to be successful at the Basic and Proficient levels, and that students at the Advanced level are likely to be successful at the Basic , Proficient , and Advanced levels. Results in this report are presented as percentages of students at or above the Proficient level. The achievement levels that NAGB develops usually specify what students should know and beable to do. The science achievement levels were developed somewhat differently becauseNAGB believed that some of the levels derived from the traditional achievement level settingprocess did not meet its criterion of reasonableness. Some levels were believed to be too highwhile others were too low based on comparisons to achievement levels for other NAEP subjects,Advanced Placement (AP) results, and Third International Mathematics and Science Study(TIMSS) data for eighth-grade students. The Board therefore chose to set new levels thatsatisfied their criterion of reasonableness. Science educators and scientists were then asked todevelop descriptions of what students know and can do at each achievement level based on theactual performance of students on the assessment questions. 8 Full descriptions of the achievement levels for each grade follow in table A.2.Science Work & Teacher Practices in Science 277Cut Score Content Descriptions* * Shaded areas indicate summary of content descriptions. 1996 NAEP Science Achievement Level Descriptions: Grade 4Table A.2 Students performing at the Basic level demonstrate some of the knowledge and reasoning required for understanding of the earth, physical, and life sciences at a level appropriate to Grade 4. For example, theycan carry out simple investigations and read uncomplicated graphs and diagrams. Students at this level alsoshow a beginning understanding of classification, simple relationships, and energy. Fourth-grade students performing at the Basic level are able to follow simple procedures, manipulate simple materials, make observations, and record data. They are able to read simple graphs and diagrams and drawreasonable but limited conclusions based on data provided to them. These students can recognize appropriateexperimental designs, although they are unable to justify their decisions. When presented with diagrams, students at this level can identify seasons; distinguish between day and night; and place the position of the Earth, sun, and planets. They are able to recognize major energy sources andsimple energy changes. In addition, they show an understanding of the relationship between sound andvibrations. These students are able to identify organisms by physical characteristics and group organisms withsimilar physical features. They can also describe simple relationships among structure, function, habitat, lifecycles, and different organisms. Students performing at the Proficient level demonstrate the knowledge and reasoning required for understanding of the earth, physical, and life sciences at a level appropriate to Grade 4. For example, theyunderstand concepts relating to the Earth 's features, physical properties, and structure and function. In addition, students can formulate solutions to familiar problems as well as show a beginning awareness ofissues associated with technology. Fourth-grade students performing at the Proficient level are able to provide an explanation of day and night when given a diagram. They can recognize major features of the Earth 's surface and the impact of natural forces. They are also able to recognize water in its various forms in the water cycle and can suggest ways toconserve it. These students recognize that various materials possess different properties that make themuseful. Students at this level are able to explain how structure and function help living things survive. Theyhave a beginning awareness of the benefits and challenges associated with technology and recognize somehuman effects on the environment. They can also make straightforward predictions and justify their position. Students performing at the Advanced level demonstrate a solid understanding of the earth, physical, and life sciences as well as the ability to apply their understanding to practical situations at a level appropriate toGrade 4. For example, they can perform and critique simple investigations, make connections from one ormore of the sciences to predict or conclude, and apply fundamental concepts to practical applications. Fourth-grade students performing at the Advanced level are able to combine information, data, and knowledge from one or more of the sciences to reach a conclusion or to make a valid prediction. They can alsorecognize, design, and explain simple experimental procedures. Students at this level recognize nonrenewable sources of energy. They also recognize that light and sound travel at different speeds. These students understand some principles of ecology and are able to compare andcontrast life cycles of various common organisms. In addition, they have a developmental awareness of thebenefits and challenges associated with technology.BASIC 138 PROFICIENT 170 ADVANCED 204278 Student Work & Teacher Practices in ScienceCut Score Content Descriptions* * Shaded areas indicate summary of content descriptions. 1996 NAEP Science Achievement Level Descriptions: Grade 8 Students performing at the Basic level demonstrate some of the knowledge and reasoning required for understanding of the earth, physical, and life sciences at a level appropriate to Grade 8. For example, theycan carry out investigations and obtain information from graphs, diagrams, and tables. In addition, theydemonstrate some understanding of concepts relating to the solar system and relative motion. Students at thislevel also have a beginning understanding of cause-and-effect relationships. Eighth-grade students performing at the Basic level are able to observe, measure, collect, record, and compute data from investigations. They can read simple graphs and tables and are able to make simple datacomparisons. These students are able to follow directions and use basic science equipment to perform simpleexperiments. In addition, they have an emerging ability to design experiments. Students at this level have some awareness of causal relationships. They recognize the position of planets and their movement around the sun and know basic weather-related phenomena. These students can explainchanges in position and motion such as the movement of a truck in relation to that of a car. They also have anemerging understanding of the interrelationships among plants, animals, and the environment. Students performing at the Proficient level demonstrate much of the knowledge and many of the reasoning abilities essential for understanding of the earth, physical, and life sciences at a level appropriate to Grade 8.For example, students can interpret graphic information, design simple investigations, and explain suchscientific concepts as energy transfer. Students at this level also show an awareness of environmental issues,especially those addressing energy and pollution. Eighth-grade students performing at the Proficient level are able to create, interpret, and make predictions from charts, diagrams, and graphs based on information provided to them or from their own investigations.They have the ability to design an experiment and have an emerging understanding of variables and controls.These students are able to read and interpret geographic and topographic maps. In addition, they have anemerging ability to use and understand models, can partially formulate explanations of their understanding ofscientific phenomena, and can design plans to solve problems. Students at this level can begin to identify forms of energy and describe the role of energy transformations in living and nonliving systems. They have knowledge of organization, gravity, and motions within the solarsystem and can identify some factors that shape the surface of the Earth. These students have someunderstanding of properties of materials and have an emerging understanding of the particulate nature ofmatter, especially the effect of temperature on states of matter. They also know that light and sound travel atdifferent speeds and can apply their knowledge of force, speed, and motion. These students demonstrate adevelopmental understanding of the flow of energy from the sun through living systems, especially plants.They know that organisms reproduce and that characteristics are inherited from previous generations. Thesestudents also understand that organisms are made up of cells and that cells have subcomponents with differentfunctions. In addition, they are able to develop their own classification system based on physicalcharacteristics. These students can list some effects of air and water pollution as well as demonstrateknowledge of the advantages and disadvantages of different energy sources in terms of how they affect theenvironment and the economy.Table A.2 continued BASIC 143 PROFICIENT 170Science Work & Teacher Practices in Science 279Cut Score Content Descriptions* * Shaded areas indicate summary of content descriptions.1996 NAEP Science Achievement Level Descriptions: Grade 8Table A.2 continued Students performing at the Advanced level demonstrate a solid understanding of the earth, physical, and life sciences as well as the abilities required to apply their understanding in practical situations at a levelappropriate to Grade 8. For example, students perform and critique the design of investigations, relatescientific concepts to each other, explain their reasoning, and discuss the impact of human activities on theenvironment. Eighth-grade students performing at the Advanced level are able to provide an explanation for scientific results. They have a modest understanding of scale and are able to design a controlled experiment. Thesestudents have an understanding of models as representations of natural systems and can describe energytransfer in living and nonliving systems. Students at this level are able to understand that present physical clues, including fossils and geological formations, are indications that the Earth has not always been the same and that the present is a key tounderstanding the past. They have a solid knowledge of forces and motions within the solar system and anemerging understanding of atmospheric pressure. These students can recognize a wide range of physical andchemical properties of matter and some of their interactions and understand some of the properties of lightand sound. Also, they can infer relationship between structure and function. These students know thedifferences between plant and animal cells and can apply their knowledge of food as a source of energy to apractical situation. In addition, they are able to explain the impact of human activities on the environment andthe economy.ADVANCED 207 280 Student Work & Teacher Practices in ScienceCut Score Content Descriptions* * Shaded areas indicate summary of content descriptions. 1996 NAEP Science Achievement Level Descriptions: Grade 12Table A.2 continued Students performing at the Basic level demonstrate some knowledge and certain reasoning abilities required for understanding of the earth, physical, and life sciences at a level appropriate to Grade 12. In addition, theydemonstrate knowledge of the themes of science (models, systems, patterns of change) required forunderstanding the most basic relationships among the earth, physical, and life sciences. They are able toconduct investigations, critique the design of investigations, and demonstrate a rudimentary understanding ofscientific principles. Twelfth-grade students performing at the Basic level are able to select and use appropriate simple laboratory equipment and write down simple procedures that others can follow. They also have a developmental ability todesign complex experiments. These students are able to make classifications based on definitions such asphysical properties and characteristics. Students at this level demonstrate a rudimentary understanding of basic models and can identify some parts of physical and biological systems. They are also able to identify some patterns in nature and rates of changeover time. These students have the ability to identify basic scientific facts and terminology and have arudimentary understanding of the scientific principles underlying such phenomena as volcanic activity, diseasetransmission, and energy transformation. In addition, they have familiarity with the application of technology. Students performing at the Proficient level demonstrate the knowledge and reasoning abilities required for understanding of the earth, physical, and life sciences at a level appropriate to Grade 12. In addition, theydemonstrate knowledge of the themes of science (models, systems, patterns of change) required forunderstanding how these themes illustrate essential relationships among the earth, physical, and life sciences. They are able to analyze data and apply scientific principles to everyday situations. Twelfth-grade students performing at the Proficient level are able to demonstrate a working ability to design and conduct scientific investigations. They are able to analyze data in various forms and utilize information to provide explanations and to draw reasonable conclusions. Students at this level have a developmental understanding of both physical and conceptual models and are able to compare various models. They recognize some inputs and outputs, causes and effects, andinteractions of a system. In addition, they can correlate structure to function for the parts of a system that theycan identify. These students also recognize that rate of change depends on initial conditions and other factors. They are able to apply scientific concepts and principles to practical applications and solutions forproblems in the real world and show a developmental understanding of technology, its uses, and itsapplications.PROFICIENT 178BASIC 145Science Work & Teacher Practices in Science 281Cut Score Content Descriptions* * Shaded areas indicate summary of content descriptions. Students performing at the Advanced level demonstrate the knowledge and reasoning abilities required for a solid understanding of the earth, physical, and life sciences at a level appropriate to Grade 12. In addition,they demonstrate knowledge of the themes of science (models, systems, patterns of change) required forintegrating knowledge and understanding of scientific principles from the earth, physical, and life sciences.Students can design investigations that answer questions about real-world situations and use their reasoningabilities to make predictions. Twelfth-grade students performing at the Advanced level are able to design scientific investigations to solve complex, real-world situations. They can integrate, interpolate, and extrapolate information embedded indata to draw well-formulated explanations and conclusions. They are also able to use complex reasoningskills to apply scientific knowledge to make predictions based on conditions, variables, and interactions. Students at this level recognize the inherent strengths and limitations of models and can revise models based on additional information. They are able to recognize cause-and-effect relationships within systems and canutilize this knowledge to make reasonable predictions of future events. These students are able to recognizethat patterns can be constant, exponential, or irregular and can apply this recognition to make predictions.They can also design a technological solution for a given problem.1996 NAEP Science Achievement Level Descriptions: Grade 12Table A.2 continued ADVANCED 210282 Student Work & Teacher Practices in ScienceEstimating Variability Because the statistics presented in this report are estimates of group and subgroup performance based on samples of students rather than the values that could be calculated if every student inthe nation had answered every question, the degree of uncertainty associated with the estimatesshould be taken into account. Two components of uncertainty are accounted for in thevariability of statistics based on student ability: (1) the uncertainty due to sampling only arelatively small number of students; and (2) the uncertainty due to sampling only a relativelysmall number of cognitive questions. The first component accounts for the variability associatedwith the estimated percentages of students who had certain background characteristics or whoanswered a certain cognitive question correctly. Because NAEP uses complex sampling procedures to select students for participation, conventional formulas for estimating sampling variability that assume simple random samplingare inappropriate. NAEP uses a jackknife replication procedure to estimate standard errors.The jackknife standard error provides a reasonable measure of uncertainty for any studentinformation that can be observed without error. However, because each student typicallyresponds to only a few questions within any content area, the scale score for any single studentwould be imprecise. In this case, plausible values technology can be used to describe theperformance of groups and subgroups of students, but the underlying imprecision involved inthis step adds another component of variability to statistics based on NAEP scale scores. 9 Appendix C provides the standard errors accounting for both components of uncertainty for theresults presented in this report. When the standard error is based on a small number of students or when the group of students is enrolled in a small number of schools, the amount of uncertainty associated with thestandard error may be quite large. This situation is identified in this report when it occurs. The reader is reminded that, like findings from all surveys, NAEP results are subject to other kinds of error, including the effects of imperfect adjustment for student and schoolnonresponse and unknowable effects associated with the particular instrumentation and datacollection methods. Nonsampling errors can be attributed to a number of sources: inability toobtain complete information about all selected schools in the sample (some students or schoolsrefused to participate, or students participated but answered only certain questions); ambiguousdefinitions; differences in interpreting questions; inability or unwillingness to give correctinformation; mistakes in recording, coding, or scoring data; and other errors in data collecting,data processing, and sampling and in estimating missing data. The extent of nonsampling erroris difficult to estimate and, because of their nature, the impact of such errors cannot bereflected in the data-based estimates of uncertainty provided in NAEP reports. 9For further details, see Johnson, E. G. & Rust, K. F. (1992). Population inferences and variance estimation for NAEP data. Journal of Educational Statistics, 17 , 175-190.Science Work & Teacher Practices in Science 28310Allen, N. L., Carlson, J., & Zelenak, C.A. (1999). The NAEP 1996 technical report (Publication No. NCES 98-479). W ashington, DC: National Center for Education Statistics. Report in preparation.Drawing Inferences from the Results The results from the sample, taking into account the uncertainty associated with them, are used to make inferences about the population. Using confidence intervals based on the standarderrors provides a way to make inferences about the population averages and percentages in amanner that reflects the uncertainty associated with the sample estimates. An estimated sampleaverage scale score \u00b1 2 standard errors approximates a 95-percent confidence interval for the corresponding population quantity. This statement means that one can conclude at the 95-percent confidence level that the average performance of the entire population of interest (e.g.,all fourth-grade students in public schools in a jurisdiction) is within \u00b1 2 standard errors of the sample average. As an example, suppose that the average science scale score of the students in a particular group was 156 with a standard error of 1.2. A 95-percent confidence interval for thepopulation quantity would be as follows: Average \u00b1 \u00b1 2 x 1.2156 \u00b1 2.4153.6, 158.4 Thus one can conclude at the 95 percent level of confidence that the average scale score for the entire population of students in that group is between 153.6 and 158.4. Similar confidence intervals can be constructed for percentages, if the percentages are not extremely large or extremely small. For extreme percentages, confidence intervalsconstructed in the manner above may not be appropriate, and accurate confidence intervals canbe constructed only by using procedures that are quite complicated. Extreme percentages, defined by both the magnitude of the percentage and the size of the sample from which it was derived, should be interpreted with caution. (The forthcomingNAEP 1996 Technical Report contains a more complete discussion of extreme percentages.) 10284 Student Work & Teacher Practices in ScienceStatistical Tests for Determining Group Differences in Performance Statistical tests are used to determine whether the evidence, based on the data from the groups in the sample, is strong enough to indicate that the averages or percentages are actuallydifferent for those groups in the population. If the evidence is strong (i.e., the difference isstatistically significant), the report describes the group averages or percentages as beingdifferent (e.g., one group performed higher or lower than another group), regardless of whetherthe sample averages or percentages appear to be approximately the same. If the evidence is notsufficiently strong (i.e., the difference is not statistically significant), the averages orpercentages are described as being not significantly different, regardless of whether the sampleaverages or percentages appear to be approximately the same or widely discrepant. The reader is cautioned to rely on the results of the statistical tests rather than on the apparent magnitude of the difference between sample averages or percentages whendetermining whether the sample differences are likely to represent actual differences among thegroups in the population. To determine whether a real difference exists between the average scale scores (or percentages of a certain attribute) for two independently sampled groups in the population, oneneeds to obtain an estimate of the degree of uncertainty associated with the difference betweenthe averages (or percentages) of these groups for the sample. This estimate of the degree ofuncertainty, called the standard error of the difference between the groups, is obtained bytaking the square of each group 's standard error, summing the squared standard errors, and taking the square root of that sum. Standard Error of the Difference for Independent Groups = SE A-B = +2 B2 ASE SE In a manner similar to that in which the standard error for an individual group average or percentage is used, the standard error of the difference can be used to help determinewhether differences among groups in the population are real. The difference between theaverages or percentages of the two groups plus or minus two standard errors of the differencerepresents an approximate 95-percent confidence interval. If the resulting interval includeszero, there is insufficient evidence to claim a real difference between the groups in thepopulation. If the interval does not contain zero, the difference between the groups isstatistically significant (different) at the .05 level. In this report, differences among groups thatinvolve poorly defined variability estimates and extreme percentages are not discussed. As an example, to determine whether the average science scale score of Group A is higher that that of Group B, suppose that the sample estimates of the average scale scores andstandard errors were as follows: Group Average Scale Score Standard Error A 118 0.9 B 116 1.1Science Work & Teacher Practices in Science 285The difference between the estimates of the average scale scores of Groups A and B is two points (118 - 116). The standard error of this difference is 1.4 1.1 0.92 2=+ Thus, an approximate 95 percent confidence interval for this difference is Difference \u00b1 2 standard errors of the difference 2 \u00b1 2x1.42 \u00b1 2.8-0.8, 4.8 The value zero is within the confidence interval; therefore, there is insufficient evidence toclaim that Group A outperformed Group B. The procedures described in this section and the certainty ascribed to intervals (e.g., a 95-percent confidence interval) are based on statistical theory that assumes that only oneconfidence interval or test of statistical significance is being performed. However, in chapters2 to 6 of this report, many different groups are being compared (i.e., multiple sets of confidenceintervals are being analyzed). In sets of confidence intervals, statistical theory indicates that thecertainty associated with the entire set of intervals is less than that attributable to eachindividual comparison from the set. To hold the significance level for the set of comparisons at aparticular level (e.g., 0.05), adjustments called multiple comparison procedures must be madeto the methods described in the previous section. One such procedure, the Bonferroni method,was used in the analyses described in this report to adjust the confidence intervals for thedifferences among groups when sets of comparisons were considered. 11 Many of the confidence intervals discussed in the main body of this report were components of a set of multiplecomparisons, and so included Bonferroni adjustments. Thus the confidence intervals for thesecomparisons are more conservative than the confidence interval (described above) for what asingle comparison would be. Derived Variables A derived variable is a variable that is created by combining responses from two or morevariables into one set of responses. Table 6.3 and the corresponding standard error table in appendix C contain data involving students ' positive attitudes toward science. The positive attitude index was a composite score based on student responses to six questions in the student backgroundquestionnaire. The \"agree \" responses to three questions \u2014\"I like science, \" \"I am good at science, \" and \"Science is useful in solving everyday problems \"\u2014 and the disagree responses to three questions \u2014\"Learning science is mostly memorization, \" \"If I had a choice I would not study any more science in school, \" and \"Science is boring \"\u2014 were combined to form the index. 11Miller, R. G. (1966). Simultaneous statistical inference. New Y ork, NY: McGraw-Hill.Appendix B Student Work & Teacher Practices in Science 287Scoring Guides288 Student Work & Teacher Practices in ScienceGrade 4 Scoring Guides Natural Forces 4-6qStudent Work & Teacher Practices in Science 289TABLE B2.14 Grade 4 Scoring Guide Natural Forces (4) Complete Student identifies two forces and describes how each force changed Earth's surface. (3) Essential Student identifies two forces and describes how one of the forces changed Earth's surface. (2) Partial Student identifies one force and describes how it changed Earth 's surface or identifies one or two forces only. (1) Unsatisfactory Student does not identify forces that change Earth 's surface. Examples of Credited Responses Short Term: Volcanic eruption - can blow up part of a mountain top, cover earth with lava, create new rock Earthquakes - can uplift land, cover up land, create cracks in surface Storms - can change coastline, cause flooding or mudslides Long Term: Erosion and weathering - water causing rocks to crack because of freezing and thawing, wind shaping rocks over time, gradual wearing of rocks. Glaciers - movement of rocks, shaping of land forms.290 Student Work & Teacher Practices in Science5. Name the parts of the plant below that are labeled 1, 2, and 3. Explain the function of each part. ART - 9-a1 2 3 Plants: Parts and FunctionsStudent Work & Teacher Practices in Science 291TABLE B2.20 Grade 4 Scoring Guide Parts and Functions (4) Complete Student identifies the three plant structures and gives a correct function for each structure (six response parts). (3) Essential Student names two or three structures and gives a function for two of them (four or five response parts). (2) Partial Student responds correctly to one to three parts of the question. (1) Unsatisfactory Student is unable to name any plant structure or state any function correctly. Examples of Credited Responses Flower (blossom, petals, bud) - reproductive structure; produces pollen Leaves - part of plant where food is produced; carries out photosynthesis Roots \u2014 take in water; anchor plant292 Student Work & Teacher Practices in Science TABLE B2.26 Grade 4 Scoring Guide Experimental Setup (3) Complete Student states that the experimental design is not appropriate and clearly explains that a dish of water should be provided on both the lighted side of the container and the shaded side. (2) Partial Student states that the experimental design is not appropriate and offers no explanation or an incorrect explanation. (1) Unsatisfactory Student states that the experimental design is appropriate and may or may not include an incorrect explanation.Experiment Setup ART 4-18xStudent Work & Teacher Practices in Science 293TABLE B2.30 Grade 4 Scoring Guide Properties of Metals (3) Complete Student identifies two properties of metals. (2) Partial Student identifies one property of metals. (1) Unsatisfactory Student does not correctly identify any properties of metals. Examples of Credited Responses Generally hard and strong, some are magnetic, conduct heat and electricity, can be made into different shapes (malleable and ductile)Properties of Metal 4-2q294 Student Work & Teacher Practices in ScienceTABLE B2.32 Grade 4 Scoring Guide Metamorphosis (3) Complete Student draws and correctly labels the pupal stage of the butterfly life cycle. Acceptable labels include pupal, cocoon, or chrysalis. (2) Partial Student is able either to draw the pupal stage or write the correct label. (1) Unsatisfactory Student is unable to draw the pupal stage of a butterfly 's life cycle or give a correct label.4-22q5. Insects also change as they grow. Look at the picture below. One part of the picture is missing. Draw and label themissing part of the picture. MetamorphosisStudent Work & Teacher Practices in Science 295Grasshoppers and Butterflies 296 Student Work & Teacher Practices in ScienceTABLE B2.34 Grade 4 Scoring Guide Grasshoppers and Butterflies (4) Complete Student tells two ways the grasshopper 's life cycle differs from the butterfly 's life cycle and one way the life cycles are similar Or, one way the grasshopper 's life cycle differs from the butterfly 's life cycle and two ways the life cycles are similar. (3) Essential Student tells one way the grasshopper 's life cycle differs from the butterfly 's life cycle and one way the life cycles are similar Or, two ways the life cycles are different Or, two ways the life cycles are similar. (2) Partial Student tells one way the grasshopper 's life cycle differs from the butterfly 's life cycle Or, one way the life cycles are similar. (1) Unsatisfactory Student does not tell any differences or similarities. Examples of Credited Responses Differences The grasshopper does not change much in form after it hatches from the egg but mainly increases in size, while the butterfly changes from acaterpillar to a pupa to a butterfly. The grasshopper eats the same food as it develops, the butterfly does not. The butterfly goes into a cocoon, the grasshopper does not. Similarities Both hatch from eggs Both undergo a great increase in size Both moltNeither born with wingsStudent Work & Teacher Practices in Science 297Life Cycles TABLE B2.36 Grade 4 Scoring Guide Life Cycles (3) Complete Student is able to state a reasonable justification that includes a brief description of one correct similarity between the human life cycle and thegrasshopper or frog life cycle. (1) Unsatisfactory Student is unable to describe a similarity between the human life cycle and the grasshopper or frog life cycle. Examples of Credited Responses Grasshopper \u2014 humans and grasshoppers do not undergo complete metamorphosis Grasshopper \u2014 both have the same form all along8. Think about how humans grow and develop from newborn babies to adults. Is a human 's life cycle more like a frog 's life cycle or more like a grasshopper 's life cycle? Explain your answer.298 Student Work & Teacher Practices in ScienceTABLE B2.38 Grade 4 Scoring Guide Mystery Water (3) Complete Student states that the mystery water is fresh water and adequately justifies this conclusion by using a comparison. (2) Partial Student states that the mystery water is fresh water but does not give adequate justification. (1) Unsatisfactory Student does not correctly identify the mystery water. Examples of Credited Response Explanations The pencil floated to the same level as it did in the fresh water. The water went up to the same place as in fresh water. Because in the fresh water it went to A and it went to A again. Examples of Partial Response Explanations It looked like fresh water.It works like fresh water. It was the same as fresh water.Mystery Water 10. Is the mystery water fresh water or is it salt water? How can you tell what the mystery water is?Student Work & Teacher Practices in Science 299TABLE B2.40 Grade 4 Scoring Guide Ease of Floating (3) Complete Student demonstrates a beginning understanding of the concept of density by stating \"ocean \" and presenting an explanation that refers back to the hands-on task. (2) Partial Student demonstrates some understanding of floating and density by explaining that the ocean is salt water or relates answer to pencil but does not give a complete explanation. (1) Unsatisfactory Student does not relate swimming in salt water and fresh water to density. Examples of Credited Responses Ocean - the pencil floated the highest in the salt water. Ocean - because the salt water pencil floated higher than the fresh water pencil.4-14qEase of Floating 300 Student Work & Teacher Practices in ScienceGrade 8 Scoring Guides Mirrors and Windows TABLE B3.14 Grade 8 Scoring Guide Mirrors and Windows (3) Complete Student includes statements about the physical properties of mirrors and windows and the reflective properties of mirrors and windows (light must be mentioned). Student refers to both the backing of the mirror and thereflective properties. (2) Partial Student states that mirrors have a backing on them but windows do not, or student states that light bounces (reflects) off a mirror but travels througha window. (1) Unsatisfactory Student states that mirrors and windows differ but gives no reason for the differences, or student restates the question.6. Raul 's little sister, Sarah, wants to know why she can see herself in a mirror, but she can see through a window. What should Raul tell hissister to explain the differences between mirrors and windows?Student Work & Teacher Practices in Science 301TABLE B3.20 Grade 8 Scoring Guide Hydra (4) Complete Student describes an experiment that would test the hypothesis. This includes a control and more than one hydra in each group. (3) Essential Student describes an experiment that would test the hypothesis. This includes a control, but only one hydra in each group. (2) Partial Student describes an experiment that includes feeding hydras twice as much food but has no control group. (A statement about comparing it to the previous setup was not considered to be a control.) Or, studentresponse incorporated two groups of hydras but did not specifically mention food amounts. (1) Unsatisfactory Student experiment does not test the hypothesis.15. Evita and Michael predicted that if they fed the hydras twice as much food, the population of hydras would double their number in 5 days.Describe an experiment with appropriate controls that Evita and Michaelcould do to test this hypothesis.Hydra302 Student Work & Teacher Practices in ScienceTABLE B3.22 Grade 8 Scoring Guide Lightbulbs (3) Complete Student chooses fluorescent lightbulbs and explains that heat comes from electrical energy and that the less heat produced the more light is ob-tained for a given amount of electrical energy or, the less heat is pro- duced, the less electricity is used for a given amount of light. Some link between heat and energy consumption must be made. (2) Partial Student chooses fluorescent lightbulbs but an incorrect or no explanation is given. (1) Unsatisfactory Student chooses incandescent lightbulb or no lightbulb with no explana- tion or an incorrect explanation.7. When operating, ordinary incandescent lightbulbs produce a lot of heat in addition to light. Fluorescent lightbulbs produce much less heat whenoperating. If you wanted to conserve electricity, which type of bulb shouldyou use? Explain your answer.LightbulbsStudent Work & Teacher Practices in Science 303TABLE B3.24 Grade 8 Scoring Guide Heating Rate Prediction (4) Complete Student provides a reasonable prediction such as the sand will be hotter at noon than the water. The response also provides a reasonable explanation that relates to the data in the table. For example, the soil temperature washotter than the water temperature after 8 minutes. Finally, the response must provide a reasonable explanation of why the prediction may be wrong. Credited responses include difference in length of time, samplesize, color of samples, soil versus sand, and fresh water versus salt water. (3) Essential Student provides a reasonable prediction and either an explanation of the prediction or an explanation of why the prediction may be incorrect. (2) Partial Student provides a reasonable prediction. (1) Unsatisfactory Student provides no reasonable prediction or explanations.Heating Rate Prediction At a beach that has white sand, you measure the temperature of the sand and the temperature of the seawater at 9:00 a.m. You find thatboth have a temperature of 16 \u00b0C. If it is clear and sunny all morning, what do the data from the experiment predict about the temperatureof the white sand compared to the temperature of the seawater atnoon? Explain your answer.Explain why the prediction based on the data might be wrong.304 Student Work & Teacher Practices in ScienceTABLE B3.26 Grade 8 Scoring Guide Food Poisoning (3) Complete Student explains that bacteria cause food poisoning and describes a method of prevention, such as putting the salad in a cooler. (2) Partial Student explains the cause of food poisoning or recognizes that the salad has to be kept cold. (1) Unsatisfactory Student does not understand that bacteria cause food poisoning and does not recognize that keeping the salad cold will help prevent this.Food Poisoning 13. A group of students took potato salad made with mayonnaise to a picnic on a very hot day. Explain how eating the potato salad couldcause food poisoning. Describe something that could be done to the potato salad to prevent the people who eat it from getting food poisoning.Student Work & Teacher Practices in Science 305Inheritance 7. Hair color in humans is an inherited trait. How is it possible for two people who had brown hair from birth toproduce a child with blond hair? TABLE B3.28 Grade 8 Scoring Guide Inheritance (3) Complete Student explains the inheritance of recessive genes by a child from the child's parents. Grandparents did not have to be mentioned. (2) Partial Student knows that the trait (gene) is passed from grandparents or ances- tors to parents to child but does not explain recessive genes. (1) Unsatisfactory Student is unable to demonstrate any understanding of the concept of recessive genes.306 Student Work & Teacher Practices in ScienceTABLE B3.32 Grade 8 Scoring Guide Seasons (3) Complete Student describes or draws changes to the model such as adding the tilt of Earth. The responses may also refer to rotation or traveling in the orbit ora brief description of why it is colder in January than in July. (2) Partial Student does not make any additions to the model but mentions Earth 's tilt or direct/indirect sunlight, or more/less sunlight. Student provides an incomplete diagram (no month and/or hemisphere labels) but makes anattempt at explaining why Earth is colder in January. (1) Unsatisfactory St udent shows no understanding of the causes of the seasons. This includes responses that conflict with reality such as \"the Earth is farther from the Sun in January. \"Seasons 12. What additions or changes could be made to this model of the Solar System to best explain why the NorthernHemisphere of the Earth is colder in January than in July?You may draw a picture as part of your answer.Student Work & Teacher Practices in Science 307 ss-3Measurement, Average, Graphing, Interpolating308 Student Work & Teacher Practices in ScienceTABLE B3.34 Grade 8 Scoring Guide Measurement (4) Complete Student shows three sets of measurements that agree within \u00b1 0.2 cm, and the relative order of pencil heights above each solution is correct. (3) Essential Student shows three sets of measurements that agree within tolerance, but the relative order of pencil heights above each solution is incorrect. (2) Partial Student shows two sets of measurements that agree within tolerance. (1) Unsatisfactory Student shows one or no sets of measurements that agree within tolerance. TABLE B3.36 Grade 8 Scoring Guide Average (3) Complete Student shows correct calculations of the average of the three sets of measurements to within \u00b1/G320.1 cm. (2) Partial Student shows correct calculation(s) of the average of one or two sets of averages within \u00b1/G320.1 cm. (1) Unsatisfactory Student shows no correct calculations.Student Work & Teacher Practices in Science 309TABLE B3.40 Grade 8 Scoring Guide Interpolating (4) Complete Student indicates a salt concentration that is consistent with the data and correctly explains how the answer was obtained. (3) Essential Student indicates a salt concentration that is consistent with the data but fails to explain adequately how the value is obtained, or a correct expla- nation of how to interpolate is given but an error is made with the value. (2) Partial Student shows how to use proportional reasoning in the explanation or gives an unclear explanation of how to use the graph but does not have agraph that can be used to interpolate. (1) Unsatisfactory Student does not show a value consistent with the graph or give an explanation.TABLE B3.38 Grade 8 Scoring Guide Graphing (3) Complete Student draws a plot of two data points based on student 's own data and draws a line between the two points. (2) Partial Student draws a graph of one data point based on student 's own data or correctly plots two data points but fails to connect them. (1) Unsatisfactory Student fails to show any correct plotting of data.310 Student Work & Teacher Practices in ScienceGrade 12 Scoring Guides Pacific Ring of Fire TABLE B4.7 Grade 12 Scoring Guide Pacific Ring of Fire (4) Complete Student demonstrates a thorough understanding of why volcanic activity and earthquakes occur in the region of the Pacific Rim. The response has to include volcanic activity and earthquakes being caused by the relativemovement of two (tectonic) plates diverging, converging, or sliding past each other. (3) Essential Student mentions plates and the relative movement of them but does not link this to the activity that causes volcanic activity or earthquakes, orstudent 's response links plates to activity but does not adequately describe the relative movement. (2) Partial Student mentions plates but does not link these to volcanic activity or earthquakes. (1) Unsatisfactory Student does not mention the movement of plates as the cause of volcanic activity or earthquakes.6. The Pacific Ring of Fire is a belt-shaped region that roughly coincides with the seacoasts bordering the Pacific Ocean. Explain why volcanicactivity and earthquakes occur frequently in this region.Student Work & Teacher Practices in Science 311TABLE B4.13 Grade 12 Scoring Guide Genotype (4) Complete Student predicts the father 's genotype, supports the prediction in diagram- matic form, and gives some additional information that will help determine the genotype. (3) Essential Student addresses two of the three elements described under Complete. (2) Partial Student addresses one of the three elements described under Complete, often in general terms. (1) Unsatisfactory Student addresses none of the elements described under Complete.16. A mother with attached earlobes and a father with free earlobes have 5 children \u2014 4 boys and 1 girl. All of the children have the father 's type of earlobes. What can be predicted about the genotype of the father?Construct a genetic diagram to support your prediction. What additionalinformation, if any, would you need to determine the genotype of thefather? Explain.Genotype312 Student Work & Teacher Practices in ScienceTABLE B4.17 Grade 12 Scoring Guide Flooding (3) Complete Student states two distinct reasons for testing the soil such as presence of toxins from factories or farms, erosion of topsoil, and leaching of essential minerals from the soil. (2) Partial Student states one reason for testing the soil. (1) Unsatisfactory Student states no correct reasons for testing the soil.Flooding 5. You live along a major river, and your farm was flooded this spring. There are many larger farms and a few factories upriver that were alsoflooded. Provide two flood-related reasons for testing your soil beforeplanting this year.Student Work & Teacher Practices in Science 313Keeping Ice Cream Cold TABLE B4.19 Grade 12 Scoring Guide Keeping Ice Cream Cold (3) Complete Student indicates a correct method and satisfactorily explains how the method works. The student could give methods such as adding salt or packing in dry ice and explain that the salt lowers the freezing point of water or the melting point of ice, or that the temperature of the dry ice iswell below zero. (2) Partial Student indicates a correct method but fails to explain it adequately. (1) Unsatisfactory Student fails to indicate a correct method.6. You are taking ice cream in a cooler to a picnic and want to keep the ice cream colder than 0 \u00b0C for several hours. How could you do this?314 Student Work & Teacher Practices in ScienceTABLE B4.21 Grade 12 Scoring Guide Heart Disease (3) Complete Student describes two ways to reduce the risk of heart disease such as eating less saturated fat and exercising more. (2) Partial Student describes one way to reduce the risk of heart disease. (1) Unsatisfactory Student is unable to describe correctly any way to reduce the risk of heart disease.Heart Disease 7. Heart disease is a major cause of death in the United States. Describe two ways a person can reduce the risk of heart disease.Student Work & Teacher Practices in Science 315TABLE B4.23 Grade 12 Scoring Guide Malaria (3) Complete Student states that malaria is spread by mosquitoes and states that a mosquito must bite the infected person and then bite an uninfected personfor the disease to be transmitted. (2) Partial Student states that malaria is spread by mosquitoes (insects) but does not connect it to the person in the question or student has a general sense of what causes malaria. (1) Unsatisfactory Student demonstrates no understanding of the cause and transmission of malaria.8. A person has just returned to the United States from the tropics and is found to have malaria. What is the risk of other people catching thedisease from this person? Explain your answer.Malaria316 Student Work & Teacher Practices in ScienceTABLE B4.27 Grade 12 Scoring Guide Ocean and Lake Water (4) Complete Student describes both a method and its results. For example, the student could say that the salt water would leave a residue of salt if boiled or allowed to evaporate. (3) Essential Student describes a method and its results but provides minimal detail, or provides a partial or flawed method. (2) Partial Student describes a method but does not indicate how it would work. For example, student advises measuring the density of water in each jar. (1) Unsatisfactory Student describes an inconclusive method.7. Some students were studying water in the environment. They filled one sample jar with ocean water and another sample jar with fresh water fromthe lake. The labels on the jars fell off, and the water in both jars lookedthe same. Describe a test, other than tasting or smelling the water, thatthe students could do to determine which jar held the ocean water andwhich jar held the lake water. Explain how the test could work.Ocean and Lake WaterStudent Work & Teacher Practices in Science 317TABLE B4.29 Grade 12 Scoring Guide Cloud FormationCloud Formation 9. Explain how clouds can form as air rises. You may draw a diagram as part of your explanation. (3) Complete Student states that a change in temperature causes water to condense, thus forming clouds. (2) Partial Student states that as moist air rises, droplets of water form clouds. (1) Unsatisfactory Student may know that clouds are made up of water droplets and/or ice crystals, but no explanation is given for how a cloud forms.318 Student Work & Teacher Practices in ScienceTABLE B4.31 Grade 12 Scoring Guide Physical Properties (4) Complete Student states the properties that may be useful for separating a mixture of substances using magnetism, solubility, and size. (3) Essential Student states two of the properties that would allow for separation. (2) Partial Student states one of the properties the would allow for separation. (1) Unsatisfactory Student is unable to give any properties that would allow for separation.1. Look at the contents of plastic bag (A) without opening it. What properties do the substances in the mixture have that would allow the followingequipment to be used to separate the mixture? Magnet:Filter paper:Sieve:Physical PropertiesStudent Work & Teacher Practices in Science 319TABLE B4.33 Grade 12 Scoring Guide Separation of Materials (5) Complete Student separates all of the solids in the mixture, except for the salt, which remains dissolved in water. (4) Essential Student separates three or four of the solids in the mixture. (3) Adequate Student separates two of the solids in the mixture. (2) Partial Student separates one of the solids in the mixture. (1) Unsatisfactory Student is unable to separate any of the solids in the mixture.Separation of Materials 2. Now use this equipment to separate the five materials in the mixture. Each time you successfully separate a material from the mixture,place this separated material in one of the small unlabeled plasticbags. The materials that you separate do not have to be 100 percentpure, but they should be as pure as possible. Each separated materialshould be placed in its own plastic bag. The bags with the separatedmaterials will be collected after you have completed the task. [Notes: 1) If you have collected a material in the filter paper, you do not need to separate the material from the filter paper. Just put thefilter paper in the plastic bag. 2) If you end up with one of the fivematerials dissolved in water, you can leave this material in the cup.]320 Student Work & Teacher Practices in ScienceTABLE B4.35 Grade 12 Scoring Guide Description of Method (5) Complete Student describes steps that lead to five separated components. (4) Essential Student describes steps that lead to three separated components. (3) Adequate Student describes steps that lead to two separated components. (2) Partial Student describes steps that lead to one separated component. (1) Unsatisfactory Student is unable to describe any of the separations. Note: There are a number of different steps that can be followed. All are valid provided that the components can be separated by following the student 's directions.Description of Method 3. Based on what you discovered as you worked to separate the materials in the mixture, write in the space below step-by-step instructions thatwould allow someone else to separate all five solids using the same setof equipment.Appendix C Student Work & Teacher Practices in Science 321Standard Errors Standard Errors for Teachers ' Reports on How Much Time They Spent Teaching Life Science, Earth Science, and Physical Science, Grade 4: Public and Nonpublic Schools CombinedTABLE C2.2 Average Scale Score Percentage Percentage Composite Life Earth Physical At or Above of Students (all domains) Science Science Science ProficientIn this class, about how much time do you spend on each of the following areas in science? Life Science A Lot 2.7 1.5 1.8 1.8 2.0 1.7 Some 2.8 1.2 1.5 1.2 1.6 1.3 Little 1.4 3.8 4.0 3.5 5.2 5.1 None 0.4 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 Earth Science A Lot 2.1 2.3 2.6 2.9 2.5 2.6 Some 2.4 1.0 1.3 1.2 1.4 1.2 Little 1.0 4.1 4.1 4.5 5.3 4.4 None 0.3 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 Physical Science A Lot 2.3 2.3 2.8 2.6 2.8 2.3 Some 2.5 1.1 1.5 1.1 1.6 1.4 Little 1.5 3.5 4.0 3.8 4.0 3.5 None 0.5 7.4 7.5 8.6 7.4 5.9 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.322 Student Work & Teacher Practices in ScienceStandard Errors for Average Question Score for Earth Science, Physical Science, and Life Science, Grade 4: Public and Nonpublic Schools CombinedTABLE C2.3 Earth Science Physical Science Life Science All There were insufficient sample sizes for the American Indian and Asian/ Pacific Islander racial/ethnic subgroups to produ ce reliable results. Consequently, racial/ethnic subgroup information is provided only for White, Black, and Hispanic subgroups.SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. Standard Errors for Average Question Score for Conceptual Understanding, Scientific Investigation, and Practical Reasoning, Grade 4: Public and Nonpublic Schools CombinedTABLE C2.4 Conceptual Scientific Practical Understanding Investigation Reasoning All There were insufficient sample sizes for the American Indian and Asian/ Pacific Islander racial/ethnic subgroups to produce reliable results. Consequently, racial/ethnic subgroup information is provided only for White, Black, and Hispanic subg roups. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 323 TABLE C2.7Standard Errors for Per centages Correct within Each Achievement Level Interval: Grade 4 Major Source of Gasoline Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 3.4 4.1 3.2 \u2014\u2014 \u2014\u2014 Sample size insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Response Options A B C D Omit 0.6 0.5 1.8 1.9 0.4 TABLE C2.6Standard Errors for Percentages Choosing Each Response: Grade 4 Major Source of Gasoline SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. Response Options A B C D Omit 1.4 0.6 1.2 0.3 0.2 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.8Standard Errors for Percentages Choosing Each Response: Grade 4 Earth 's Surface324 Student Work & Teacher Practices in Science TABLE C2.9Standard Errors for Percent ages Correct within Each Achievement Level Interval: Grade 4 Earth 's Surface Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 3.8 2.3 1.8 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.11Standard Errors for Percent ages Correct within Each Achievement Level Interval: Grade 4 Visibility of Moon from Earth Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 3.7 3.6 2.3 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Response Options A B C D Omit 1.0 2.0 0.5 1.7 0.3 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.10Standard Errors for Percentages Choosing Each Response: Grade 4 Visibility of Moon from EarthStudent Work & Teacher Practices in Science 325Response Options A B C D Omit 1.9 1.0 1.0 1.4 0.5 TABLE C2.12Standard Errors for Percentages Choosing Each Response: Grade 4 Sources of Smog SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.13Standard Errors for Per centages Correct within Each Achievement Level Interval: Grade 4 Sources of Smog Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 3.6 4.2 3.8 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. Complete Essential Partial Unsatisfactory Omit 0.9 0.5 1.6 1.9 0.8 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.14Standard Errors for Percentages at Different Score Levels: Grade 4 Natural Forces326 Student Work & Teacher Practices in ScienceResponse Options A B C D Omit 0.7 0.6 2.4 2.2 0.7 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.16Standard Errors for Percentages Choosing Each Response: Grade 4 Pattern of Ripples TABLE C2.17Standard Errors for Percentages Correct within Each Achievement Level Interval: Grade 4 Pattern of Ripples Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 3.0 4.0 3.6 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.15Standard Errors for Percentages Complete or Essential within Each Achievement Level Interval: Grade 4 Natural Forces Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) \u2014\u2014 1.9 3.0 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 327Response Options A B C D Omit 1.7 1.3 0.9 1.2 0.2 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.18Standard Errors for Percentages Choosing Each Response: Grade 4 Mealworm Life Cycle TABLE C2.19Standard Errors for Per centages Correct within Each Achievement Level Interval: Grade 4 Mealworm Life Cycle Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 3.0 3.0 3.2 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. Complete Essential Partial Unsatisfactory Omit 0.5 2.0 2.1 0.4 0.7 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.20Standard Errors for Percentages at Different Score Levels: Grade 4 Plants: Parts and Functions328 Student Work & Teacher Practices in Science TABLE C2.21Standard Errors for Percentages Complete or Essential within Each Achievement Level Interval: Grade 4 Plants: Parts and Functions Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 3.6 4.2 3.8 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. Response Options A B C D Omit 0.7 0.5 0.6 1.4 1.0 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.22Standard Errors for Percentages Choosing Each Response: Grade 4 Volume TABLE C2.23Standard Errors for Percent ages Correct within Each Achievement Level Interval: Grade 4 Volume Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 3.2 2.4 2.5 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 329Response Options A B C D Omit 0.5 2.0 2.1 0.4 0.7 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.24Standard Errors for Percentages Choosing Each Response: Grade 4 Bar Graph Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 3.6 4.2 3.8 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.25Standard Errors for Per centages Correct within Each Achievement Level Interval: Grade 4 Bar Graph Complete Partial Unsatisfactory Omit 1.4 1.6 1.6 0.3 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.26Standard Errors for Percentages at Different Score Levels: Grade 4 Experimental Setup330 Student Work & Teacher Practices in Science TABLE C2.29Standard Errors for Percent ages Correct within Each Achievement Level Interval: Grade 4 Radio Malfunction Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 2.9 2.8 1.8 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Response Options A B C D Omit 0.5 1.4 0.4 1.0 0.4 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.28Standard Errors for Percentages Choosing Each Response: Grade 4 Radio Malfunction TABLE C2.27Standard Errors for Percentages Complete within Each Achievement Level Interval: Grade 4 Experimental Setup Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 0.8 2.6 4.4 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 331 TABLE C2.31Standard Errors for Percentages Complete within Each Achievement Level Interval: Grade 4 Properties of Metals Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 1.8 2.7 3.4 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.30Standard Errors for Percentages at Different Score Levels: Grade 4 Properties of Metals Complete Partial Unsatisfactory Omit 1.4 1.8 1.7 0.7 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.32Standard Errors for Percentages at Different Score Levels: Grade 4 Metamorphosis Complete Partial Unsatisfactory Omit 1.7 1.3 0.8 0.5 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.332 Student Work & Teacher Practices in Science TABLE C2.35Standard Errors for Percentages Complete or Essential within Each Achievement Level Interval: Grade 4 Grasshoppers and Butterflies Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 1.3 2.1 3.7 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Complete Essential Partial Unsatisfactory Omit 1.2 1.8 1.8 1.6 0.2 TABLE C2.34Standard Errors for Percentages at Different Score Levels: Grade 4 Grasshoppers and Butterflies SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.33Standard Errors for Percentages Complete within Each Achievement Level Interval: Grade 4 Metamorphosis Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 2.5 3.0 2.8 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 333 TABLE C2.36Standard Errors for Percentages at Different Score Levels: Grade 4 Life Cycles Complete Unsatisfactory Omit 1.4 1.4 0.3 TABLE C2.37Standard Errors for Percentages Complete within Each Achievement Level Interval: Grade 4 Life Cycles Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 1.4 2.3 3.3 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.38Standard Errors for Percentages at Different Score Levels: Grade 4 Mystery Water Complete Partial Unsatisfactory Omit 1.9 1.7 1.8 0.2 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.334 Student Work & Teacher Practices in Science TABLE C2.40Standard Errors for Percentages at Different Score Levels: Grade 4 Ease of Floating Complete Partial Unsatisfactory Omit 1.2 1.4 1.5 0 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.41Standard Errors for Percentages Complete within Each Achievement Level Interval: Grade 4 Ease of Floating Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) \u2014\u2014 1.9 2.8 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C2.39Standard Errors for Percentages Complete within Each Achievement Level Interval: Grade 4 Mystery Water Below Basic Basic Proficient Advanced (0-137) (138-169) (170-203) (204-300) 1.8 2.9 3.4 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 335Standard Errors for Teachers ' Reports on How Much Time They Spent Teaching Life Science, Earth Science, and Physical Science, Grade 8: Public and Nonpublic Schools CombinedTABLE C3.2 Average Scale Score Percentage Percentage Composite Life Earth Physical At or Above of Students (all domains) Science Science Science ProficientIn this class, about how much time do you spend on each of the following areas in science? Life Science A Lot 4.1 2.5 2.8 2.9 2.8 3.4 Some 5.3 2.4 2.5 2.5 2.5 2.5 Little 3.6 2.7 2.5 3.1 2.8 3.5 None 4.5 4.0 4.7 4.4 3.2 5.9 Earth Science A Lot 5.0 2.5 2.6 2.8 2.5 3.0 Some 4.5 2.1 2.2 2.1 2.1 2.3 Little 2.7 4.7 4.7 5.5 4.2 6.7 None 1.9 3.5 4.4 3.8 3.2 5.2 Physical Science A Lot 4.3 1.7 2.1 1.8 1.6 2.4 Some 4.4 2.7 2.7 2.9 2.9 3.2 Little 3.2 3.3 3.4 4.4 2.9 3.5 None 1.2 6.4 6.9 7.0 6.2 5.3 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.336 Student Work & Teacher Practices in ScienceStandard Errors for Average Question Score for Conceptual Understanding, Scientific Investigation, and Practical Reason- ing, Grade 8: Public and Nonpublic Schools CombinedTABLE C3.4 Education Conceptual Scientific Practical Understanding Investigation Reasoning All 0.017 \u2014\u2014 \u2014\u2014 Sample size is insufficient to permit a reliable estimate. NOTE: There were insufficient sample sizes for the American Indian racial/ethnic subgroup to produce reliable results. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Standard Errors for Average Question Score for Earth Science, Physical Science, and Life Science, Grade 8: Public and Nonpublic Schools CombinedTABLE C3.3 Earth Science Physical Science Life Science All insufficient sample sizes for the American Indian racial/ethnic subgroup to produce reliable results. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 337 TABLE C3.7Standard Errors for Percentages Correct within Each Achievement Level Interval: Grade 8 Location of Earthquake Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 2.9 4.0 3.1 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Response Options A B C D Omit 0.6 1.8 0.8 1.7 0.2 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C3.6Standard Errors for Percentages Choosing Each Response: Grade 8 Location of Earthquake Response Options A B C D Omit 2.2 0.5 2.1 0.9 0.1 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C3.8Standard Errors for Percentages Choosing Each Response: Grade 8 Windchill338 Student Work & Teacher Practices in Science TABLE C3.11Standard Errors for Percentages Correct within Each Achievement Level Interval: Grade 8 Insulated Bottle Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 2.3 3.4 6.6 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessmen t.Response Options A B C D Omit 0.7 1.9 1.1 1.4 0.2 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C3.10Standard Errors for Percentages Choosing Each Response: Grade 8 Insulated Bottle TABLE C3.9Standard Errors for Percentages Correct within Each Achievement Level Interval: Grade 8 Windchill Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 3.8 3.6 4.4 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 339 TABLE C3.13Standard Errors for Percentages Correct within Each Achievement Level Interval: Grade 8 Nonrenewable Resource Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 3.2 3.5 5.4 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Response Options A B C D Omit 2.4 1.6 1.0 1.4 0.2 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C3.12Standard Errors for Percentages Choosing Each Response: Grade 8 Nonrenewable Resource Complete Partial Unsatisfactory Omit 0.4 1.7 1.9 0.6 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C3.14Standard Errors for Percentages at Different Score Levels: Grade 8 Mirrors and Windows340 Student Work & Teacher Practices in Science TABLE C3.17Standard Errors for Percentages Correct within Each Achievement Level Interval: Grade 8 Mitochondria Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 2.2 2.7 4.5 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Response Options A B C D Omit 1.5 0.9 1.7 1.4 0.3 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C3.16Standard Errors for Percentages Choosing Each Response: Grade 8 Mitochondria TABLE C3.15Standard Errors for Percentages Complete within Each Achievement Level Interval: Grade 8 Mirrors and Windows Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) \u2014\u2014 0.8 1.3 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 341 TABLE C3.19Standard Errors for Percentages Correct within Each Achievement Level Interval: Grade 8 Classification Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 3.2 2.7 3.1 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Response Options A B C D Omit 1.1 1.4 1.9 0.5 0.1 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C3.18Standard Errors for Percentages Choosing Each Response: Grade 8 Classification Complete Essential Partial Unsatisfactory Omit 2.4 0.8 1.7 2.6 0.8 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment . TABLE C3.20Standard Errors for Percentages at Different Score Levels: Grade 8 Hydra342 Student Work & Teacher Practices in Science TABLE C3.22Standard Errors for Percentages at Different Score Levels: Grade 8 Lightbulbs Complete Partial Unsatisfactory Omit 2.0 1.5 1.3 0.7 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C3.23Standard Errors for Percentages Complete within Each Achievement Level Interval: Grade 8 Lightbulbs Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 2.8 4.6 4.4 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP),1996 Science Assessment. TABLE C3.21Standard Errors for Percentages Complete or Essential within Each Achievement Level Interval: Grade 8 Hydra Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 2.0 3.5 6.6 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 343 TABLE C3.25Standard Errors for Percentages Complete or Essential within Each Achievement Level Interval: Grade 8 Heating Rate Prediction Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) \u2014\u2014 2.5 4.7 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Complete Essential Partial Unsatisfactory Omit 0.8 1.0 1.9 1.8 0.7 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C3.24Standard Errors for Percentages at Different Score Levels: Grade 8 Heating Rate Prediction TABLE C3.26Standard Errors for Percentages at Different Score Levels: Grade 8 Food Poisoning Complete Partial Unsatisfactory Omit 1.5 1.8 1.5 0.6 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.344 Student Work & Teacher Practices in Science TABLE C3.28Standard Errors for Percentages at Different Score Levels:Grade 8 Inheritance Complete Partial Unsatisfactory Omit 1.2 1.3 1.7 0.6 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C3.29Standard Errors for Percentages Complete within Each Achievement Level Interval: Grade 8 Inheritance Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) \u2014\u2014 1.0 1.9 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C3.27Standard Errors for Percentages Complete within Each Achievement Level Interval: Grade 8 Food Poisoning Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 1.1 2.3 4.0 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 345 TABLE C3.31Standard Errors for Percentages Correct within Each Achievement Level Interval: Grade 8 Graph Reading Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 2.8 1.8 \u2014\u2014 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Response Options A B C D Omit 1.4 0.7 0.7 0.4 0.5 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C3.30Standard Errors for Percentages Choosing Each Response: Grade 8 Graph Reading TABLE C3.32Standard Errors for Percentages at Different Score Levels: Grade 8 Seasons Complete Partial Unsatisfactory Omit 1.2 1.5 2.1 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.346 Student Work & Teacher Practices in Science TABLE C3.35Standard Errors for Percentages Complete or Essential within Each Achievement Level Interval: Grade 8 Salt Solution: Measurement Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 2.7 2.4 2.9 \u2014\u2014Complete Essential Partial Unsatisfactory Omit 1.7 1.3 1.4 1.3 0.2 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C3.34Standard Errors for Percentages at Different Score Levels: Grade 8 Salt Solution: Measurement \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment . TABLE C3.33Standard Errors for Percentages Complete within Each Achievement Level Interval: Grade 8 Seasons Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) \u2014\u2014 1.4 3.0 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 347 TABLE C3.36Standard Errors for Percentages at Different Score Levels: Grade 8 Salt Solution: Average Complete Partial Unsatisfactory Omit 1.3 1.0 1.0 0.4 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment . TABLE C3.37Standard Errors for Percentages Complete within Each Achievement Level Interval: Grade 8 Salt Solution: Average Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 2.0 2.1 1.7 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment . TABLE C3.38Standard Errors for Percentages at Different Score Levels:Grade 8 Salt Solution: Graphing Complete Partial Unsatisfactory Omit 1.6 1.2 1.4 0.8 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment .348 Student Work & Teacher Practices in Science TABLE C3.41Standard Errors for Percentages Complete or Essential within Each Achievement Level Interval: Grade 8 Salt Solution: Interpolating Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 1.3 2.8 3.5 \u2014\u2014Complete Essential Partial Unsatisfactory Omit 1.2 1.0 1.3 1.6 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C3.40Standard Errors for Percentages at Different Score Levels: Grade 8 Salt Solution: Interpolating \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C3.39Standard Errors for Percentages Complete within Each Achievement Level Interval: Grade 8 Salt Solution: Graphing Below Basic Basic Proficient Advanced (0-142) (143-169) (170-206) (207-300) 0.7 2.2 4.6 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 349Standard Errors for Average Question Score for Conceptual Understanding, Scientific Investigation, and Practical Reasoning, Grade 12: Public and Nonpublic Schools CombinedTABLE C4.3 Conceptual Scientific Practical Understanding Investigation Reasoning SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.All 0.015Standard Errors for Average Question Score for Earth Science, Physical Science, and Life Science, Grade 12: Public and Nonpublic Schools CombinedTABLE C4.2 Earth Science Physical Science Life Science SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP),1996 Science Assessment.All Teacher Practices in ScienceComplete Essential Partial Unsatisfactory Omit 0.7 2.1 1.3 1.7 1.1 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C4.7Standard Errors for Percentages at Different Score Levels: Grade 12 Pacific Ring of Fire TABLE C4.6Standard Errors for Percentages Correct within Each Achievement Level Interval: Grade 12 Solar Eclipse Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 2.6 2.2 2.2 \u2014\u2014 \u2014\u2014 Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Response Options A B C D Omit 0.7 0.6 1.3 0.8 0.4 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C4.5Standard Errors for Percentages Choosing Each Response: Grade 12 Solar EclipseStudent Work & Teacher Practices in Science 351 TABLE C4.8Standard Errors for Percentages Complete or Essential within Each Achievement Level Interval: Grade 12 Pacific Ring of Fire Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 1.9 3.0 3.9 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. Response Options A B C D Omit 0.8 2.1 2.3 1.2 0.2 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C4.9Standard Errors for Percentages Choosing Each Response: Grade 12 Path on Ice TABLE C4.10Standard Errors for Percentages Correct within Each Achievement Level Interval: Grade 12 Path on Ice Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 2.8 3.0 6.1 \u2014\u2014 \u2014\u2014 Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.352 Student Work & Teacher Practices in ScienceResponse Options A B C D Omit 1.2 1.0 1.7 1.2 0.2 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C4.11Standard Errors for Percentages Choosing Each Response: Grade 12 Interpretation of Velocity/Time Graph TABLE C4.12Standard Errors for Percentages Correct within Each Achievement Level Interval: Grade 12 Interpretation of Velocity/Time Graph Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 2.6 3.6 4.5 \u2014\u2014 \u2014\u2014 Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. Complete Essential Partial Unsatisfactory Omit 0.8 1.5 1.8 1.8 \u2014\u2014 \u2014\u2014 Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C4.13Standard Errors for Percentages at Different Score Levels: Grade 12 GenotypeStudent Work & Teacher Practices in Science 353 TABLE C4.14Standard Errors for Percentages Complete or Essential within Each Achievement Level Interval: Grade 12 Genotype Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 1.3 2.5 4.4 \u2014\u2014 \u2014\u2014 Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. Response Options A B C D Omit 1.1 1.4 1.1 1.9 0.3 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C4.15Standard Errors for Percentages Choosing Each Response: Grade 12 Concluding from Results TABLE C4.16Standard Errors for Percentages Correct within Each Achievement Level Interval: Grade 12 Concluding from Results Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 2.4 3.1 4.1 \u2014\u2014 \u2014\u2014 Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.354 Student Work & Teacher Practices in Science TABLE C4.19Standard Errors for Percentages at Different Score Levels: Grade 12 Keeping Ice Cream Cold Complete Partial Unsatisfactory Omit 1.3 1.5 1.8 0.7 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C4.18Standard Errors for Percentages Complete within Each Achievement Level Interval: Grade 12 Flooding Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 1.9 4.2 5.6 \u2014\u2014 \u2014\u2014 Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Complete Partial Unsatisfactory Omit 1.7 1.6 1.2 0.7 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C4.17Standard Errors for Percentages at Different Score Levels: Grade 12 FloodingStudent Work & Teacher Practices in Science 355 TABLE C4.20Standard Errors for Percentages Correct within Each Achievement Level Interval: Grade 12 Keeping Ice Cream Cold Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 1.4 2.0 3.4 \u2014\u2014 \u2014\u2014 Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C4.21Standard Errors for Percentages at Different Score Levels: Grade 12 Heart Disease Complete Partial Unsatisfactory Omit 2.1 2.1 0.7 0.5 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C4.22Standard Errors for Percentages Complete within Each Achievement Level Interval: Grade 12 Heart Disease Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 2.9 4.3 5.5 \u2014\u2014 \u2014\u2014 Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.356 Student Work & Teacher Practices in ScienceResponse Options A B C D Omit 1.0 0.5 1.8 1.2 0.2 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C4.25Standard Errors for Percentages Choosing Each Response: Grade 12 Temperature & Evaporation TABLE C4.23Standard Errors for Percentages at Different Score Levels: Grade 12 Malaria TABLE C4.24Standard Errors for Percentages Complete within Each Achievement-Level Interval: Grade 12 Malaria Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 0.6 1.2 1.1 \u2014\u2014 \u2014\u2014 Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Complete Partial Unsatisfactory Omit 0.6 1.5 1.8 1.0 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 357 TABLE C4.26Standard Errors for Percentages Correct within Each Achievement Level Interval: Grade 12 Temperature & Evaporation Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 2.4 2.7 2.1 \u2014\u2014 \u2014\u2014 Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. Complete Essential Partial Unsatisfactory Omit 1.3 1.0 0.6 1.6 0.7 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C4.27Standard Errors for Percentages at Different Score Levels: Grade 12 Identification of Ocean and Lake Water TABLE C4.28Standard Errors for Percentages Complete or Essential within Each Achievement Level Interval: Grade 12 Identification of Ocean and Lake Water Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 2.0 2.5 4.2 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.358 Student Work & Teacher Practices in ScienceComplete Essential Partial Unsatisfactory Omit 0.8 0.9 1.4 1.6 0.7 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C4.31Standard Errors for Percentages at Different Score Levels: Grade 12 Physical Properties TABLE C4.30Standard Errors for Percentages Complete within Each Achievement Level Interval: Grade 12 Cloud Formation Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) \u2014\u2014 2.9 2.5 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C4.29Standard Errors for Percentages at Different Score Levels: Grade 12 Cloud Formation Complete Partial Unsatisfactory Omit 1.6 1.2 2.3 1.4 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 359 TABLE C4.32Standard Errors for Percentages Complete or Essential within Each Achievement Level Interval: Grade 12 Physical Properties Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 0.7 1.7 3.9 \u2014\u2014 \u2014\u2014 Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. Complete Essential Adequate Partial Unsatisfactory Omit 2.0 1.9 0.9 1.2 1.6 1.8 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C4.33Standard Errors for Percentages at Different Score Levels: Grade 12 Separation of Materials TABLE C4.34Standard Errors for Percentages Complete or Essential within Each Achievement Level Interval: Grade 12 Separation of Materials Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 3.0 3.9 5.5 \u2014\u2014 \u2014\u2014Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.360 Student Work & Teacher Practices in ScienceComplete Essential Adequate Partial Unsatisfactory Omit 1.2 1.6 0.6 1.5 1.3 0.2 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment. TABLE C4.35Standard Errors for Percentages at Different Score Levels: Grade 12 Description of Method TABLE C4.36Standard Errors for Percentages Complete or Essential within Each Achievement Level Interval: Grade 12 Description of Method Below Basic Basic Proficient Advanced (0-144) (145-177) (178-209) (210-300) 2.5 3.2 3.1 \u2014\u2014 \u2014\u2014 Sample size was insufficient to permit a reliable estimate. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 361TABLE C5.1 Grade 4 Grade 8 Heavy Moderate Little or None Heavy Moderate Little or None Knowing science facts and terminology Understanding key science concepts Learning about relevance of science to society and technology Developing students ' interest in science Developing science problem-solving skills Learning how to communicate ideas in science effectively Developing lab skills and techniques Developing data analysis skills Using technology as a scientific toolStandard Errors for Teachers ' Reports on How Much Emphasis They Give to Student Objectives, Grades 4 and 8: Public and Nonpublic Schools Combined About how much emphasis will you give to each of the following objectives for your students? aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient \u2014\u2014Sample size was insufficient to permit reliable estimates. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.2.8a3.0 0.9 3.4 3.1 2.0 1.5b1.3 6.7 2.1 1.3 4.0 0.9c1.7 8.7 2.2 1.9 6.9 2.1 2.1 \u2014\u2014 2.3 2.2 \u2014\u2014 0.9 1.9 \u2014\u2014 1.1 2.2 \u2014\u2014 1.0 2.8 \u2014\u2014 1.4 2.9 \u2014\u2014 2.6 2.7 1.9 4.5 3.7 2.3 1.5 1.3 2.2 1.7 1.5 5.22.1 1.7 3.0 2.0 2.0 8.8 2.8 2.9 0.4 4.3 4.3 1.60.9 2.1 4.9 1.3 3.0 9.11.2 2.6 7.8 1.6 3.8 8.6 3.0 2.8 1.5 3.9 3.4 1.41.2 1.5 3.6 1.3 2.8 15.51.5 1.6 5.8 2.0 3.5 11.5 2.6 2.7 1.9 4.5 3.7 2.31.5 1.3 2.2 1.7 1.5 5.22.1 1.7 3.0 2.0 2.0 8.8 1.8 2.5 2.5 4.0 4.4 2.32.5 1.2 1.6 1.9 1.9 2.83.0 1.4 2.2 2.6 2.6 2.6 1.7 2.9 2.7 3.9 4.7 2.73.6 1.3 1.2 2.4 1.5 1.24.0 1.6 2.2 3.1 2.1 2.2 1.9 2.8 3.1 2.8 3.9 4.12.6 1.3 1.6 2.3 1.5 2.52.9 1.7 2.0 2.8 1.8 3.3362 Student Work & Teacher Practices in ScienceStandard Errors for Teachers ' Reports on How Often Students Do a Variety of Classroom Activities, Grades 4 and 8: Public and Nonpublic Schools CombinedTABLE C5.2 About how often do your science students do each of the following?Grade 4 Grade 8 Almost Once or Once or Never or Almost Once or Once or Never or Every Twice a Twice a Hardly Every Twice a Twice a Hardly Day Week Month Ever Day Week Month Ever Read a science textbook Read a book or magazine about science Discuss science in the news Work with other students on a science activity orproject Give an oral science report Prepare a written science report Do hands-on activities or investigations in science Talk about measurements and results from students ' hands-on activities Use computers for science Take a science test or quiz aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient \u2014\u2014 Sample size was insufficient to permit reliable estimates. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.2.9a2.6 2.3 3.0 3.5 3.4 2.7 2.5 1.1b1.5 1.7 2.8 2.1 2.0 2.2 2.6 2.2c1.7 3.1 3.8 2.5 2.8 2.8 3.6 1.5 2.6 3.1 2.6 0.6 2.4 4.0 3.8 4.1 1.9 1.3 1.9 4.5 2.6 1.4 2.5 5.4 2.2 1.5 2.5 4.5 3.2 1.9 2.8 1.4 2.6 3.2 2.5 4.3 2.7 4.5 2.3 7.7 1.7 1.5 2.4 3.3 1.8 1.8 6.9 6.1 2.2 1.7 2.8 5.0 2.3 2.1 10.0 1.1 2.2 2.7 1.7 2.8 3.8 3.1 3.5 4.8 1.7 1.1 2.4 1.6 1.8 3.0 13.9 5.8 2.0 1.6 2.8 3.2 2.3 3.9 14.1 0.2 1.4 2.7 2.8 \u2014\u2014 1.1 4.4 4.4 \u2014\u2014 6.3 1.5 1.5 \u2014\u2014 3.4 1.8 1.9 \u2014\u2014 6.8 1.6 1.8 \u2014\u2014 5.0 2.3 2.4 \u2014\u2014 1.0 2.8 3.1 0.4 2.0 4.0 3.6 \u2014\u2014 6.3 1.2 1.6 \u2014\u2014 3.2 1.4 2.0 \u2014\u2014 8.2 1.2 2.2 \u2014\u2014 3.2 1.8 2.5 1.6 2.9 3.5 1.1 2.9 3.2 2.3 0.6 3.2 1.3 1.6 4.5 2.1 1.5 2.5 3.8 3.6 1.8 1.9 4.2 3.2 2.0 2.3 3.5 1.4 2.4 2.8 1.7 2.6 3.9 3.7 1.0 3.6 1.5 1.2 2.9 2.0 1.6 1.8 3.8 4.2 1.9 1.6 3.3 4.0 2.1 2.0 3.1 0.6 2.2 2.6 3.5 0.3 2.2 3.6 3.9 8.6 2.7 1.7 1.4 \u2014\u2014 4.0 2.1 1.6 12.2 2.8 2.4 1.7 \u2014\u2014 4.9 3.0 1.7 2.0 1.5 2.3 1.8 1.1 4.9 5.0 1.6 \u2014\u2014 3.0 1.2 3.9 3.5 1.8 2.0 6.6 \u2014\u2014 2.6 1.4 4.8 3.5 2.4 2.9 7.5Student Work & Teacher Practices in Science 363Standard Errors for Reports from Students Currently Taking a Science Course on How Often They Do a Variety of Classroom Activities, Grade 12: Public and Nonpublic Schools CombinedTABLE C5.3 When you study science in school, how often do you do each of the following?Grade 12 Almost Once or Twice Once or Twice Never or Every Day a Week a Month Hardly Ever Read a science textbook Read a book or magazine about science Discuss science in the news Work with other students on a science activity or project Give an oral science report Prepare a written science report Do hands-on activities or investigations in science Talk about measurements and results from students ' hands-on activities Use computers for science Design and carry out your own science investigation Analyze data and form conclusion from your investigations Take a science test or quiz Go outside and observe or measure things aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient \u2014\u2014 Sample size was insufficient to permit reliable estimates. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.1.3a1.0 0.9 1.0 1.4b1.4 2.3 1.9 2.4c2.4 2.9 2.0 0.4 0.8 0.9 0.93.8 2.0 1.5 1.45.0 2.7 2.3 2.4 0.5 1.1 0.9 1.23.7 1.5 1.6 1.31.1 2.3 2.8 1.8 1.1 1.5 1.1 1.22.0 1.5 1.4 1.8 4.3 2.0 2.2 2.1 0.2 0.4 1.3 1.57.6 4.6 1.7 1.2 \u2014\u2014 6.6 2.9 1.8 0.3 1.2 1.1 1.7 6.6 2.4 1.3 1.19.6 3.9 2.4 2.0 1.3 1.2 1.3 1.02.4 1.3 1.6 2.34.6 2.2 2.7 2.0 1.1 1.2 1.1 1.11.8 1.3 1.8 1.73.6 2.2 3.0 1.9 0.5 0.9 1.0 1.64.5 1.7 1.6 1.46.2 3.4 2.2 2.1 0.3 0.6 1.1 1.44.6 3.6 1.8 1.06.5 4.6 3.4 1.4 0.8 1.2 0.9 1.42.8 1.5 1.5 1.45.0 2.5 2.6 1.8 0.7 1.3 1.4 0.52.4 1.2 1.9 4.63.3 1.8 3.5 3.4 0.3 0.6 1.2 1.55.3 3.6 1.8 1.14.3 4.1 3.2 1.7364 Student Work & Teacher Practices in ScienceStandard Errors for Teachers ' Reports on Using Different Teaching Activities, Grades 4 and 8: Public and Nonpublic Schools CombinedTABLE C5.4 When you teach science, about how often do you do each of the following?Grade 4 Grade 8 Almost Once or Once or Never or Almost Once or Once or Never or Every Twice a Twice a Hardly Every Twice a Twice a Hardly Day Week Month Ever Day Week Month Ever Talk to the class about science Do a science demonstration Show a science videotape or TV science program Use computers for science Use CDs or laser disks on science aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient \u2014\u2014 Sample size was insufficient to permit reliable estimates. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.3.3a3.1 1.3 0.3 2.4 2.2 0.7 0.2 1.2b2.6 5.0 \u2014\u2014 1.1 2.8 \u2014\u2014 \u2014\u2014 1.7c3.0 7.4 \u2014\u2014 1.5 3.7 \u2014\u2014 \u2014\u2014 1.0 3.7 3.7 1.4 2.1 3.1 3.7 0.8 7.1 1.7 1.4 2.5 2.1 1.7 1.7 0.7 7.0 1.9 1.4 3.6 2.4 2.4 2.4 8.7 \u2014\u2014 1.7 2.6 2.6 0.6 3.8 4.2 2.5 \u2014\u2014 2.9 1.2 2.3 \u2014\u2014 3.7 1.1 3.2 \u2014\u2014 3.2 1.4 2.5 \u2014\u2014 5.3 1.5 3.6 1.2 1.2 2.8 3.4 0.3 2.2 4.2 4.7 10.0 3.2 1.8 1.4 \u2014\u2014 3.2 2.0 1.6 11.3 3.7 2.4 1.7 \u2014\u2014 4.9 2.9 1.8 0.3 1.4 2.5 2.7 0.9 2.6 3.3 4.0 \u2014\u2014 3.6 2.3 1.2 4.6 3.7 1.9 1.5 \u2014\u2014 5.4 2.9 1.3 4.3 4.8 1.7 2.0Student Work & Teacher Practices in Science 365Standard Errors for Students ' Reports on How Often Their Teachers Use Different Teaching Activities, Grade 12: Public and Nonpublic Schools CombinedTABLE C5.5 When you study science, how often does your teacher do each of the following?Grade 12 Almost Once or Twice Once or Twice Never or Every Day a Week a Month Hardly Ever Talk to the class about science Do a science demonstrationShow a science videotape or TV science program Use computers for science Use CDs or laser disks on science aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.0.9a0.4 0.3 0.7 0.9b2.5 2.6 1.3 1.7c2.8 2.0 1.0 0.9 0.8 0.7 0.81.5 1.1 1.3 1.12.5 1.5 2.0 1.0 0.4 1.0 1.4 1.12.8 1.4 1.1 1.53.0 2.7 1.4 1.2 0.4 0.5 0.7 1.22.5 1.9 1.5 1.03.7 3.0 2.1 1.3 0.3 0.7 1.0 1.62.8 2.6 1.6 1.03.2 4.1 2.6 1.2366 Student Work & Teacher Practices in ScienceTABLE C5.6 Grade 4 Grade 8 Grade 12 Y e sN o Y e sN oY e sN oStandard Errors for Students ' Reports on Doing Hands-on Tasks, Grades 4, 8, and 12: Public and Nonpublic Schools Combined Have you ever done hands-on activities or projects in school with any of the following? Living things (plants, animals, bacteria) Electricity (batteries, flashlight) Chemicals (mixing or dissolving)Rocks/Minerals (identifying type)Magnifying glass/microscopeThermometer/barometerSimple machines (pulleys and levers) Instruments for measuring speed and velocity* None of the Above *Question not asked at grades 4 and 8 aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.1.2a1.2 1.2 1.2 0.7 0.7 0.8b1.1 1.0 1.2 0.9 0.9 1.1c1.7 1.3 1.5 1.3 1.2 1.6 1.6 1.3 1.3 0.8 0.81.1 1.0 1.1 1.5 0.9 1.51.2 1.4 1.4 1.9 1.3 1.4 1.2 1.2 1.3 1.3 0.6 0.61.1 0.9 0.9 1.9 0.8 2.11.3 1.3 1.3 1.9 1.2 1.2 1.8 1.8 1.6 1.6 1.1 1.11.2 0.9 1.1 1.5 0.9 1.51.3 1.3 1.4 1.8 1.2 1.8 1.3 1.3 1.3 1.3 0.7 0.71.0 1.0 0.9 1.3 0.8 2.01.3 1.3 1.3 1.5 1.3 1.3 1.0 1.0 1.3 1.3 0.9 0.91.0 1.9 1.0 1.3 0.9 1.91.2 1.3 1.5 1.4 1.3 1.2 1.3 1.3 2.0 2.0 1.1 1.11.1 0.8 1.2 1.4 1.0 1.11.2 1.2 2.0 1.9 1.4 1.1 1.0 1.01.0 1.11.3 1.4 0.7 0.7 0.5 0.5 0.3 0.31.6 0.7 1.9 1.8 3.3 0.81.4 1.0 1.5 1.2 1.7 1.2Student Work & Teacher Practices in Science 367TABLE C5.7 Grade 4 Grade 8 Grade 12 Yes No Yes No Yes No Percentage of Students 1.4 1.4 2.5 2.5 0.9 0.9 Average Scale Score 0.9 1.1 1.2 1.6 0.9 1.1 Percentage At or Above Proficient 1.2 1.6 1.7 2.0 1.4 1.1Do you ever do science projects in school that take a week or more?Standard Errors for Students ' Reports on Whether or Not They Conduct Science Projects or Investigations that Take a Week or More, Grades 4, 8, and 12: Public and Nonpublic Schools Combined SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.368 Student Work & Teacher Practices in ScienceStandard Errors for Teachers ' Reports on How They Use Computers for Science Instruction, Grades 4 and 8: Public and Nonpublic Schools CombinedTABLE C5.8 How do you use computers for instruction in science?Grade 4 Grade 8 Yes No Yes No Drill and practice Playing science/learning gamesSimulations and modelingData analysis and other applicationsWord processingI do not use computers for science instruction. aPercentage of Students b Average Scale Score cPercentage At or Above Proficient SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.1.5a1.5 3.9 3.9 5.3b1.0 5.8 1.2 4.1c1.2 6.8 1.7 2.6 2.6 3.5 3.51.7 1.1 3.2 1.32.0 1.2 4.5 1.6 2.8 2.8 5.0 5.01.8 1.1 2.2 1.52.0 1.4 3.9 1.9 1.2 1.2 3.1 3.14.9 1.0 1.6 1.35.9 1.2 2.2 1.6 1.7 1.7 3.1 3.12.9 1.0 1.2 1.23.8 1.3 2.4 1.4 3.0 3.0 3.9 3.91.3 1.1 1.9 1.31.5 1.5 2.1 1.9Student Work & Teacher Practices in Science 369Standard Errors for Teachers ' Reports on How Much Science Homework They Assign, Grades 4 and 8: Public and Nonpublic Schools CombinedTABLE C5.9 About how much time do you expect a student in this class to spend doing science homework each week?Grade 4 Grade 8 Two Two One Half One Hours or One Half One Hours or None Hour Hour More None Hour Hour More Percentage of Students 2.3 3.2 3.1 1.4 0.7 2.1 3.7 3.9 Average Scale Score 2.6 1.8 1.8 4.7 4.5 3.0 2.0 1.5 Percentage At or Above Proficient 3.7 2.0 2.1 6.5 3.4 3.2 2.4 1.9 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.370 Student Work & Teacher Practices in ScienceStandard Errors for Students ' Reports on Attitudes and Beliefs about Science, by Gender, Grade 4: Public and Nonpublic Schools CombinedTABLE C6.1 How much do you agree with the following statements?All Students Males Females Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everyday problems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.1.1a0.7 0.6 1.3 0.9 0.7 1.4 1.0 0.6 0.9b1.1 1.7 1.1 1.7 1.8 1.0 1.5 2.5 1.1c1.5 2.1 1.4 2.7 2.6 1.4 2.4 3.2 1.0 0.9 0.5 1.3 1.3 0.7 1.2 1.1 0.61.0 1.0 1.8 1.0 1.3 2.2 1.5 1.2 2.11.3 1.1 2.0 1.4 1.5 3.2 2.2 1.6 2.3 0.7 0.8 0.6 1.0 1.0 0.7 0.9 1.2 1.01.0 1.1 1.0 1.1 1.3 1.2 1.2 1.2 1.31.6 2.0 1.5 2.1 2.0 2.1 1.6 2.9 1.9 0.7 0.6 0.7 1.0 0.9 0.9 0.9 0.9 1.11.1 1.0 1.1 1.4 1.4 1.4 1.2 1.4 1.21.3 1.6 1.5 1.7 2.0 2.0 1.9 2.2 2.1 0.6 0.7 0.8 0.9 0.8 1.0 0.8 1.0 1.21.3 1.6 0.8 1.5 2.1 0.9 1.8 1.8 1.01.5 2.1 1.1 1.9 2.4 1.3 2.3 2.6 1.5 0.6 0.6 0.3 0.8 0.7 0.4 0.9 0.8 0.40.7 2.0 2.6 0.9 2.1 2.8 0.8 2.9 3.80.9 2.9 3.1 1.1 3.5 3.1 1.3 3.1 4.8 0.8 0.5 0.9 0.9 0.7 1.1 1.0 0.6 1.21.8 1.7 0.8 1.8 2.3 1.0 2.4 1.8 0.92.0 2.0 1.0 2.5 2.7 1.3 2.4 2.6 1.3 0.8 0.7 0.8 0.9 1.0 1.1 0.9 0.9 1.11.1 1.2 1.0 1.4 1.6 1.2 1.4 1.4 1.31.6 2.0 1.2 2.0 2.3 1.7 2.0 2.6 1.8Student Work & Teacher Practices in Science 371Standard Errors for Students ' Reports on Attitudes and Beliefs about Science, by Gender, Grade 8: Public and Nonpublic Schools CombinedTABLE C6.1 (continued) How much do you agree with the following statements?All Students Males Females Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students b Average Scale Score cPercentage At or Above Proficient SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everyday problems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.1.3a0.7 1.0 1.4 0.9 1.0 1.6 0.9 1.3 1.0b1.3 1.5 1.1 1.6 1.8 1.4 1.9 1.8 1.7c1.8 1.7 1.6 1.6 2.6 2.4 2.6 1.8 1.1 0.8 0.8 1.4 1.2 1.0 1.3 1.0 0.90.9 1.2 1.6 0.9 1.3 2.1 1.3 1.4 1.61.6 1.4 1.5 1.6 1.4 2.1 2.4 1.9 1.9 0.8 0.5 0.8 1.3 0.7 1.4 1.0 0.9 1.11.0 1.0 1.2 1.4 1.3 1.4 1.0 1.4 1.81.3 1.5 2.0 1.7 1.8 2.2 1.6 2.1 3.1 1.0 0.7 1.0 1.1 0.9 1.1 1.4 0.8 1.21.0 0.9 1.4 1.2 1.3 1.6 1.4 1.4 1.71.7 1.6 1.5 1.7 2.2 2.1 2.5 2.4 1.9 0.8 0.7 0.9 0.9 0.9 1.2 1.1 1.0 1.31.4 1.1 1.0 1.7 1.4 1.2 1.6 1.3 1.51.5 1.9 1.6 2.5 2.3 1.6 1.8 2.5 2.4 0.8 0.6 0.5 1.0 1.1 1.4 1.2 0.9 0.60.8 1.6 2.1 1.1 1.5 2.4 0.7 2.1 2.81.1 2.2 3.3 1.5 2.5 3.8 1.5 3.0 4.6 1.0 0.6 1.2 1.0 1.1 1.5 1.4 0.9 1.51.6 1.2 1.0 1.6 1.4 1.2 2.2 1.4 1.31.8 2.0 1.6 2.6 2.1 1.7 2.1 2.4 2.5 1.2 0.7 1.2 1.4 0.9 1.2 1.3 1.0 1.61.1 1.1 1.2 1.4 1.4 1.2 1.5 1.6 1.81.4 1.4 2.0 1.8 1.6 2.1 1.8 2.4 2.9372 Student Work & Teacher Practices in ScienceStandard Errors for Students ' Reports on Attitudes and Beliefs about Science, by Gender, Grade 12: Public and Nonpublic Schools CombinedTABLE C6.1 (continued) How much do you agree with the following statements?All Students Males Females Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everyday problems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.0.8a0.6 0.8 1.2 0.9 0.9 1.0 1.0 1.1 1.0b1.2 1.1 1.4 1.6 1.6 1.0 1.5 1.4 1.6c1.5 1.1 2.2 1.5 2.0 1.8 2.1 1.1 0.7 0.9 0.9 0.9 1.1 0.9 1.0 1.1 1.21.1 1.2 0.8 1.5 1.5 1.3 1.3 1.2 1.11.9 1.3 0.8 2.6 1.8 1.2 2.4 1.4 1.1 0.8 0.5 0.7 1.2 1.1 1.1 1.0 0.8 0.91.0 1.3 1.3 1.5 1.6 2.0 1.2 1.7 1.31.1 1.9 1.7 1.6 2.8 2.6 1.4 2.4 1.8 0.8 0.9 0.8 1.2 1.0 1.0 0.9 1.2 1.11.1 1.2 1.1 1.3 1.9 1.6 1.2 1.3 1.51.4 1.5 1.0 2.1 1.7 2.0 1.6 2.0 1.1 0.8 0.6 0.9 1.0 0.9 1.2 1.1 0.8 1.21.0 1.3 1.0 1.6 1.7 1.5 1.0 1.5 1.21.1 1.4 1.7 1.7 2.1 2.8 1.2 2.0 1.9 1.0 0.7 0.8 1.2 0.9 1.1 1.3 1.0 1.01.0 1.2 1.3 1.3 1.8 2.3 1.2 1.3 1.31.3 1.5 1.7 1.9 2.3 3.1 1.3 2.0 2.0 0.8 0.6 0.9 0.8 0.8 1.0 1.1 0.9 1.11.1 1.0 1.0 1.6 1.6 1.6 1.3 1.6 1.11.0 1.5 1.7 1.6 2.0 2.6 1.4 2.0 1.9 0.9 0.6 0.6 1.1 0.9 1.0 1.0 0.7 0.70.9 1.3 1.6 1.5 1.8 1.9 0.9 1.7 1.51.3 1.7 1.9 1.9 2.3 2.2 1.4 1.9 2.4Student Work & Teacher Practices in Science 373Standard Errors for Students ' Reports on Attitudes and Beliefs about Science, by Race/Ethnicity, Grade 4: Public and Nonpublic Schools CombinedTABLE C6.2 How much do you agree with the following statements?All Students White Black Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everyday problems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.1.1a0.7 0.6 1.3 0.9 0.7 1.5 1.3 1.1 0.9b1.1 1.7 1.0 1.4 1.8 2.0 3.6 3.7 1.1c1.5 2.1 1.5 2.2 2.7 1.6 2.5 2.9 1.0 0.9 0.5 1.1 1.0 0.6 2.0 2.1 1.21.0 1.0 1.8 1.1 1.1 1.9 2.2 2.2 4.01.3 1.1 2.0 1.6 1.6 2.6 1.9 1.6 2.6 0.7 0.8 0.6 0.8 1.1 0.9 1.4 1.7 1.41.0 1.1 1.0 1.1 1.4 1.2 1.8 2.5 3.51.6 2.0 1.5 2.1 2.7 2.0 1.5 2.6 2.1 0.7 0.6 0.7 0.9 0.9 0.9 1.3 1.3 1.51.1 1.0 1.1 1.1 1.2 1.2 2.3 1.9 2.61.3 1.6 1.5 1.8 2.2 1.8 1.6 1.8 2.0 0.6 0.7 0.8 0.9 0.9 1.0 1.4 1.1 1.61.3 1.6 0.8 1.5 1.6 1.0 2.7 4.1 1.91.5 2.1 1.1 2.2 2.8 1.5 1.7 3.1 2.0 0.6 0.6 0.3 0.8 0.8 0.4 1.3 0.8 0.90.7 2.0 2.6 0.8 2.2 2.7 1.9 4.6 6.20.9 2.9 3.1 1.3 3.9 4.1 1.5 4.2 3.2 0.8 0.6 0.9 1.0 0.7 1.2 1.3 1.2 1.31.8 1.7 0.8 1.8 1.9 0.9 3.6 4.6 1.72.0 2.0 1.0 2.9 3.0 1.4 2.2 3.5 1.5 0.8 0.7 0.8 1.0 0.9 1.1 1.3 1.4 1.51.1 1.2 1.0 1.4 1.3 1.2 1.8 3.0 2.41.6 2.0 1.2 2.7 2.6 1.7 1.9 2.3 2.0374 Student Work & Teacher Practices in ScienceStandard Errors for Students ' Reports on Attitudes and Beliefs about Science, by Race/Ethnicity, Grade 4: Public and Nonpublic Schools CombinedTABLE C6.2 (continued) How much do you agree with the following statements?Hispanic Asian/Pacific Islander American Indian Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient \u2014\u2014 Sample size was insufficient to permit reliable estimates. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everyday problems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.1.7a1.5 1.0 3.0 2.3 1.3 3.5 3.2 2.4 1.9b2.6 4.1 4.1 4.6 \u2014\u2014 4.4 \u2014\u2014 \u2014\u2014 1.8c1.7 3.5 5.7 5.0 \u2014\u2014 5.8 \u2014\u2014 \u2014\u2014 1.5 1.5 1.0 2.9 2.9 1.9 4.6 4.6 2.2 2.2 2.1 3.2 5.0 3.5 \u2014\u2014 5.6 4.3 \u2014\u2014 2.5 1.4 2.7 8.6 4.1 \u2014\u2014 7.0 6.0 \u2014\u2014 2.1 1.4 1.3 3.1 3.7 2.3 4.2 4.1 3.0 1.8 2.2 2.7 4.3 4.0 6.1 6.2 5.0 \u2014\u2014 1.7 1.4 2.9 7.0 5.2 9.0 7.7 6.3 \u2014\u2014 1.6 1.5 1.6 2.1 2.7 2.2 3.6 3.7 4.2 2.3 2.4 2.2 4.2 4.8 4.6 5.6 4.9 6.12.1 1.9 2.0 6.5 5.8 6.2 6.7 8.6 6.8 1.2 1.2 1.7 2.4 3.3 4.9 2.9 2.5 3.42.6 2.9 1.7 \u2014\u2014 3.6 3.5 \u2014\u2014 \u2014\u2014 4.2 1.7 1.9 1.5 \u2014\u2014 4.8 5.5 \u2014\u2014 \u2014\u2014 5.9 1.2 1.1 0.6 1.8 1.7 0.7 2.9 2.5 1.8 1.8 3.0 5.7 3.6 \u2014\u2014 \u2014\u2014 3.9 \u2014\u2014 \u2014\u2014 1.3 3.0 1.4 5.0 \u2014\u2014 \u2014\u2014 4.7 \u2014\u2014 \u2014\u2014 1.3 1.1 1.5 2.1 2.0 2.8 2.9 3.3 3.5 3.4 3.4 1.6 \u2014\u2014 \u2014\u2014 4.0 \u2014\u2014 \u2014\u2014 3.9 2.6 2.0 1.7 \u2014\u2014 \u2014\u2014 5.9 \u2014\u2014 \u2014\u2014 5.8 1.4 1.3 1.4 3.0 3.8 3.6 3.9 2.7 4.6 2.7 2.0 2.2 4.6 4.7 4.8 6.4 \u2014\u2014 5.3 2.0 2.1 2.1 6.1 7.2 7.7 4.3 \u2014\u2014 7.2Student Work & Teacher Practices in Science 375Standard Errors for Students ' Reports on Attitudes and Beliefs about Science, by Race/Ethnicity, Grade 8: Public and Nonpublic Schools Combined How much do you agree with the following statements?All Students White Black Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everyday problems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.TABLE C6.2 (continued) 1.1a0.7 0.6 1.6 1.0 1.3 2.1 1.4 1.6 0.9b1.1 1.7 1.2 1.5 1.7 1.7 1.4 2.3 1.1c1.5 2.1 2.3 2.5 2.2 1.5 1.0 0.8 1.0 0.9 0.5 1.3 0.9 1.0 1.7 1.3 1.51.0 1.0 1.8 0.9 1.3 1.9 1.7 1.8 2.31.3 1.1 2.0 1.9 2.0 2.3 1.6 1.1 0.4 0.7 0.8 0.6 1.0 0.7 1.1 1.3 1.3 1.01.0 1.1 1.0 1.3 1.1 1.5 1.7 1.7 1.71.6 2.0 1.5 2.0 2.0 2.5 1.3 1.5 1.4 0.7 0.6 0.7 1.2 0.9 1.3 1.4 1.4 1.41.1 1.0 1.1 1.3 1.1 1.5 1.6 1.6 2.01.3 1.6 1.5 2.4 2.3 2.2 1.5 1.5 1.0 0.6 0.6 0.3 1.1 0.8 1.1 1.4 1.4 1.71.3 1.6 0.8 1.5 1.3 1.2 2.0 1.9 1.51.5 2.9 1.1 2.0 2.7 2.2 0.7 1.6 1.5 0.6 0.6 0.3 1.0 0.8 0.7 1.0 1.0 0.90.7 2.0 2.6 1.0 1.8 1.9 1.2 2.1 4.00.9 2.9 3.1 1.7 2.7 4.2 1.1 2.4 1.7 0.8 0.5 0.9 1.3 0.8 1.5 1.4 1.0 2.01.8 1.7 1.8 1.9 1.3 1.2 1.9 2.7 2.12.0 2.0 1.0 2.5 3.0 2.3 0.6 1.6 1.4 0.8 0.7 0.8 1.6 0.8 1.5 1.7 0.9 1.91.1 1.1 1.0 1.3 1.3 1.3 1.6 2.0 1.61.6 2.0 1.2 2.0 1.8 2.8 1.4 1.6 1.1376 Student Work & Teacher Practices in ScienceStandard Errors for Students ' Reports on Attitudes and Beliefs about Science, by Race/Ethnicity, Grade 8: Public and Nonpublic Schools CombinedTABLE C6.2 (continued) How much do you agree with the following statements?Hispanic Asian/Pacific Islander American Indian Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient \u2014\u2014Sample size was insufficient to permit reliable estimates. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everydayproblems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.1.9a1.5 1.2 3.7 3.0 2.3 6.0 5.1 6.9 1.8b2.3 2.5 3.1 4.4 4.3 5.0 \u2014\u2014 \u2014\u2014 1.5c1.8 2.7 5.5 5.6 6.6 7.0 \u2014\u2014 \u2014\u2014 2.8 2.5 1.2 3.0 2.8 2.1 4.0 5.2 5.1 1.9 1.5 3.0 3.2 3.1 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 2.8 1.9 1.6 6.3 4.6 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 1.3 1.5 1.3 2.5 3.1 3.1 5.1 4.0 3.6 2.1 2.3 2.7 3.4 3.6 6.9 \u2014\u2014 \u2014\u2014 \u2014\u2014 2.4 1.8 1.9 4.9 6.4 8.9 \u2014\u2014 \u2014\u2014 \u2014\u2014 2.1 1.3 1.7 3.8 3.1 2.0 4.2 3.8 2.7 2.5 2.0 3.1 4.7 4.5 4.1 \u2014\u2014 \u2014\u2014 \u2014\u2014 2.2 2.2 1.7 7.0 6.8 6.6 \u2014\u2014 \u2014\u2014 \u2014\u2014 1.3 1.7 2.0 2.7 2.2 3.8 5.9 3.8 5.2 3.0 2.4 1.5 5.3 3.9 3.3 \u2014\u2014 \u2014\u2014 6.2 2.3 2.3 1.4 8.0 5.4 5.0 \u2014\u2014 \u2014\u2014 8.1 1.3 1.2 0.9 2.9 2.3 1.5 3.2 3.0 2.8 1.4 3.3 5.9 3.2 \u2014\u2014 \u2014\u2014 5.3 \u2014\u2014 \u2014\u2014 1.1 2.9 4.1 3.7 \u2014\u2014 \u2014\u2014 8.4 \u2014\u2014 \u2014\u2014 1.4 1.8 1.8 2.4 2.5 2.8 5.0 4.2 3.8 2.7 2.3 1.9 4.4 4.4 3.7 \u2014\u2014 \u2014\u2014 \u2014\u2014 2.4 2.2 1.5 6.2 6.0 6.2 \u2014\u2014 \u2014\u2014 \u2014\u2014 1.3 1.8 1.8 3.0 2.4 2.0 4.2 4.5 3.8 2.5 2.6 1.9 3.7 3.3 5.0 \u2014\u2014 \u2014\u2014 \u2014\u2014 1.6 2.1 2.1 5.7 4.4 8.1 \u2014\u2014 \u2014\u2014 \u2014\u2014Student Work & Teacher Practices in Science 377Standard Errors for Students ' Reports on Attitudes and Beliefs about Science, by Race/Ethnicity, Grade 12: Public and Nonpublic Schools Combined How much do you agree with the following statements?All Students White Black Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everyday problems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.TABLE C6.2 (continued) 1.1a0.7 0.6 1.0 0.7 0.9 2.0 1.4 1.8 0.9b1.1 1.7 1.0 1.1 1.3 1.8 2.2 1.7 1.1c1.5 2.1 2.0 2.1 1.7 1.5 0.8 0.8 1.0 0.9 0.5 0.9 1.1 1.1 2.3 1.6 1.81.0 1.0 1.8 1.2 1.1 0.9 2.2 2.4 2.21.3 1.1 2.0 2.4 1.7 1.1 1.6 1.2 0.6 0.7 0.8 0.6 1.0 0.8 0.9 2.3 1.4 1.91.0 1.1 1.0 1.0 1.3 1.5 1.7 3.0 2.11.6 2.0 1.5 1.6 2.3 2.2 1.1 1.8 1.7 0.7 0.6 0.7 0.9 1.1 0.9 2.1 1.6 1.61.1 1.0 1.1 1.1 1.4 1.2 2.2 2.1 2.31.3 1.6 1.5 1.7 2.2 1.7 1.4 1.5 0.8 0.6 0.7 0.8 1.0 0.7 1.1 1.8 1.6 1.61.3 1.6 0.8 1.3 1.3 1.0 1.5 2.5 2.31.5 2.1 1.1 1.6 1.7 2.1 0.9 1.6 1.6 0.6 0.6 0.3 1.2 0.9 1.0 2.0 1.5 1.40.7 2.0 2.6 1.2 1.4 1.4 1.4 2.4 3.70.9 2.9 3.1 2.0 1.9 2.1 0.9 1.9 2.8 0.8 0.5 0.9 1.0 0.6 1.0 1.9 1.6 1.61.8 1.7 0.8 1.3 1.1 1.1 1.9 2.3 2.02.0 2.0 1.0 1.5 2.1 2.2 0.6 1.7 1.4 0.8 0.7 0.8 1.1 0.7 0.7 1.7 1.1 1.91.1 1.2 1.0 1.0 1.6 1.6 2.3 2.4 1.91.6 2.0 1.2 1.7 2.3 2.8 1.6 1.3 1.3378 Student Work & Teacher Practices in ScienceStandard Errors for Students ' Reports on Attitudes and Beliefs about Science, by Race/Ethnicity, Grade 12: Public and Nonpublic Schools CombinedTABLE C6.2 (continued) How much do you agree with the following statements?Hispanic Asian/Pacific Islander American Indian Agree Not Sure Disagree Agree Not Sure Disagree Agree Not Sure Disagree aPercentage of Students bAverage Scale Score cPercentage At or Above Proficient \u2014\u2014 Sample size was insufficient to permit reliable estimates. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.I like science. I'm good at science. Learning science is mostly memorizing. Science is useful for solving everyday problems. If I had a choice, I would not study any more sciencein school. Everyone can do well in science if they try. Science is boring. Science is a hard subject.2.4a2.0 2.6 2.7 2.3 2.2 5.8 3.9 6.2 3.2b3.4 2.8 3.2 4.0 3.7 \u2014\u2014 \u2014\u2014 \u2014\u2014 2.3c1.1 1.6 4.7 4.4 2.4 \u2014\u2014 \u2014\u2014 \u2014\u2014 1.4 2.1 1.8 3.2 3.0 1.9 6.2 5.7 6.0 3.4 2.7 2.7 3.2 3.1 3.9 \u2014\u2014 \u2014\u2014 \u2014\u2014 3.8 1.0 1.2 5.8 3.7 2.9 \u2014\u2014 \u2014\u2014 \u2014\u2014 2.1 1.9 1.7 2.9 1.8 2.7 12.0 8.5 7.8 3.2 3.3 2.6 3.8 4.3 3.5 \u2014\u2014 \u2014\u2014 \u2014\u2014 2.7 2.6 1.8 4.1 5.0 5.6 \u2014\u2014 \u2014\u2014 \u2014\u2014 2.1 1.9 1.7 2.9 1.8 2.7 12.0 8.5 7.8 3.2 3.3 2.6 3.8 4.3 3.5 \u2014\u2014 \u2014\u2014 \u2014\u2014 2.7 2.9 1.8 4.1 5.0 5.6 \u2014\u2014 \u2014\u2014 \u2014\u2014 2.1 1.6 2.0 3.0 2.5 1.6 5.0 4.9 4.9 2.9 2.5 2.8 3.0 5.1 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 2.7 0.9 1.5 4.5 4.9 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 2.5 1.6 1.7 2.5 2.4 1.5 6.5 6.6 4.9 2.1 4.1 4.5 3.2 5.3 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 1.7 1.9 3.1 3.6 6.5 \u2014\u2014 \u2014\u2014 \u2014\u2014 \u2014\u2014 1.9 1.8 2.3 1.4 3.2 3.2 5.1 7.0 8.2 2.4 3.2 3.2 4.7 4.0 3.0 \u2014\u2014 \u2014\u2014 \u2014\u2014 1.8 1.5 2.6 4.8 4.3 4.7 \u2014\u2014 \u2014\u2014 \u2014\u2014 2.0 1.5 2.1 2.4 2.1 1.9 9.3 10.6 5.2 2.8 2.6 3.1 3.0 4.7 7.4 \u2014\u2014 \u2014\u2014 \u2014\u2014 1.8 1.8 2.9 3.8 5.9 9.6 \u2014\u2014 \u2014\u2014 \u2014\u2014Student Work & Teacher Practices in Science 379TABLE C6.3 Number of Positive Attitudes 0123 4 56Standard Errors for Relationship Between Students ' Average Scale Scores and Positive Attitudes and Beliefs about Science, Grades 4, 8, and 12: Public and Nonpublic Schools Combined Grade 4 Percent of Students 0.7 0.5 0.5 0.7 0.7 0.6 0.2 Average Scale Score 1.9 1.7 1.5 1.2 1.2 1.0 2.3 Percentage At or Above Proficient 2.2 2.1 1.7 1.6 1.6 1.9 4.5 Grade 8 Percent of Students 0.7 0.6 0.6 0.4 0.5 0.7 0.3 Average Scale Score 2.0 1.1 1.3 1.4 1.4 1.2 2.4 Percentage At or Above Proficient 2.1 1..2 1.4 2.5 2.3 2.4 4.4 Grade 12 Percent of Students 0.5 0.6 0.5 0.6 0.4 0.4 0.4 Average Scale Score 1.4 1.0 1.3 1.5 1.3 1.2 1.2 Percentage At or Above Proficient 1.3 1.0 1.7 2.3 2.1 2.4 2.8 NOTE: The Positive Attitude Index is a composite score based on student responses to six questions in the Student Background Questionnaire. The Agree responses to three questions: ( \"I like science \"; \"I am good at science \"; and \"Science is useful for solving everyday problems \") and the Disagree responses to three questions: ( \"learning science is mostly memorizing \"; \"if I had a choice I would not study any more science in school \"; and \"science is boring \") were combined to form the index. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.380 Student Work & Teacher Practices in ScienceStandard Errors for Students ' Reports About their Motivation and Performance on the NAEP Science Assessment, Grades 4 and 8: Public and Nonpublic Schools CombinedTABLE C6.4 Education Grade 4 Grade 8 Percentage Percentage Percentage Average At or Above Percentage Average At or Above of Students Scale Score Proficient of Students Scale Score Proficient About how many questions do you think you got right. . .? Almost All 0.8 1.0 1.3 0.6 1.2 2.4 More Than Half 0.6 0.8 1.4 0.8 1.1 1.6 About Half 0.6 1.2 2.0 0.5 1.2 1.6 Less Than Half 0.4 2.4 2.4 0.5 1.6 1.4 How hard was this test compared to most other tests. . .? Much Harder 0.7 1.2 1.3 0.5 1.9 2.4 Harder 0.7 1.4 2.2 1.1 1.4 2.4 About as Hard 0.7 1.4 2.1 0.7 1.2 1.7 Easier 0.9 1.1 1.3 1.1 1.2 1.6 How hard did you try on this test compared to how hard you tried on most other science tests. . .? Much Harder 0.7 1.0 1.1 0.7 1.6 2.0 Harder 0.6 1.3 1.7 0.7 1.2 1.4 About as Hard 0.8 1.1 1.6 0.9 1.0 1.8 Not as Hard 0.6 1.8 2.2 0.6 1.8 2.2 How important was it to do well. . .? Very Important 0.8 0.8 1.0 1.0 1.4 1.9 Important 0.6 1.1 1.6 0.7 1.2 1.6 Somewhat Important 0.4 2.0 2.3 0.6 1.1 2.0 Not as Important 0.3 2.3 3.4 1.0 2.2 2.8 This year in school, how often have you been asked to write long answers to questions on tests. . .? At Least Once a Week 1.2 0.8 1.1 1.0 1.1 1.4 Once or Twice a Month 0.6 1.2 1.7 0.8 1.1 1.6 Once or Twice a Year 0.5 1.5 2.1 0.5 1.3 2.3 Never 1.0 1.3 1.7 0.6 1.7 1.6 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Student Work & Teacher Practices in Science 381Standard Errors for Students ' Reports About their Motivation and Performance on the NAEP Science Assessment, Grade12: Public and Nonpublic Schools CombinedTABLE C6.5 Education Grade 12 Percentage Percentage Average At or Above of Students Scale Score Proficient About how many questions do you think you got right. . .? Almost All 0.5 1.7 3.6 More Than Half 0.6 0.9 1.7 About Half 0.6 1.0 1.3 Less Than Half 0.7 1.0 0.8 How hard was this test compared to most other tests. . .? Much Harder 0.7 1.5 1.1 Harder 0.6 1.1 1.6 About as Hard 0.7 1.1 1.5 Easier 1.0 1.1 2.0 How hard did you try on this test compared to how hard you tried on most other science tests. . .? Much Harder 0.4 2.2 1.0 Harder 0.5 2.0 2.1 About as Hard 0.9 1.2 1.8 Not as Hard 1.0 1.2 1.4 How important was it to do well. . .? Very Important 0.5 2.4 2.1 Important 0.9 1.9 2.7 Somewhat Important 0.6 1.2 1.6 Not as Important 0.9 1.0 1.4 This year in school, how often have you been asked to write long answers to questions on tests. . .? At Least Once a Week 1.0 1.4 1.9 Once or Twice a Month 0.6 1.3 1.9 Once or Twice a Year 0.6 1.4 1.5 Never 0.9 1.2 1.0 SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.382 Student Work & Teacher Practices in ScienceStandard Errors for Schools ' Reports on Parental Involvement, Grades 4, 8 and 12: Public and Nonpublic Schools CombinedTABLE C6.6 Education Grade 4 Grade 8 Grade 12 Yes No Yes No Yes NoDoes your school do any of the following to involve parents? SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Use parents as aides in the classroom Percentage of Students 3.6 3.6 3.2 3.2 1.5 1.5 Average Scale Score 1.8 1.4 5.4 1.2 6.5 1.0 Percentage At or Above Proficient 2.0 1.3 5.3 1.5 5.6 1.4 Have parents review or sign students ' homework Percentage of Students 4.0 4.0 5.8 5.8 2.2 2.2 Average Scale Score 1.3 2.1 1.6 2.4 3.3 1.1 Percentage At or Above Proficient 1.6 2.5 2.3 2.8 2.9 1.4 Assign homework for students to do with parents Percentage of Students 4.1 4.1 5.2 5.2 1.6 1.6 Average Scale Score 1.9 1.2 3.3 1.3 5.1 1.0 Percentage At or Above Proficient 2.3 1.3 4.2 1.6 4.4 1.3 Have a parent volunteer program Percentage of Students 2.8 2.8 5.7 5.7 4.6 4.6 Average Scale Score 1.0 3.1 1.7 1.9 1.8 1.8 Percentage At or Above Proficient 1.2 3.2 2.0 2.4 1.9 2.0Student Work & Teacher Practices in Science 383Standard Errors for Schools ' Reports on the Severity of Three Problems in the School, Grades 4 and 8: Public and Nonpublic Schools CombinedTABLE C6.7 To what degree is each of the following a problem in your school?Moderate Serious Not a Problem Minor Problem Problem Problem \u2014\u2014 Sample size was insufficient to permit reliable estimates. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.Grade 4 Student Absenteeism Percentage of Students 3.7 3.9 2.1 1.0 Average Scale Score 1.9 1.9 3.6 4.9 Percentage At or Above Proficient 2.1 1.8 3.8 2.8 Teacher Absenteeism Percentage of Students 4.0 4.3 2.1 \u2014\u2014 Average Scale Score 1.4 2.2 5.7 \u2014\u2014 Percentage At or Above Proficient 1.8 2.2 5.2 \u2014\u2014 Lack of Parental Involvement Percentage of Students 4.0 3.3 4.2 1.8 Average Scale Score 2.4 1.9 2.2 6.0 Percentage At or Above Proficient 3.0 2.0 2.3 5.1 Grade 8 Student Absenteeism Percentage of Students 4.3 4.4 3.4 3.4 Average Scale Score 2.4 1.5 3.2 3.2 Percentage At or Above Proficient 3.2 1.8 3.0 3.0 Teacher Absenteeism Percentage of Students 4.9 4.9 2.0 2.0 Average Scale Score 1.9 2.2 5.3 5.3 Percentage At or Above Proficient 2.4 2.1 5.3 5.3 Lack of Parental Involvement Percentage of Students 2.5 4.1 4.5 4.5 Average Scale Score 2.8 1.8 1.9 1.9 Percentage At or Above Proficient 3.8 2.1 2.4 2.4384 Student Work & Teacher Practices in ScienceStandard Errors for Schools ' Reports on the Severity of Three Problems in the School, Grade 12: Public and Nonpublic Schools CombinedTABLE C6.7 (continued) To what degree is each of the following a problem in your school?Moderate Serious Not a Problem Minor Problem Problem Problem Grade 12 Student Absenteeism Percentage of Students 3.0 4.0 4.3 1.8 Average Scale Score 2.6 1.5 1.9 3.0 Percentage At or Above Proficient 3.7 1.9 2.1 2.3 Teacher Absenteeism Percentage of Students 3.9 4.1 2.6 0.7 Average Scale Score 1.6 2.0 3.5 \u2014\u2014 Percentage At or Above Proficient 1.7 2.2 2.2 \u2014\u2014 Lack of Parental Involvement Percentage of Students 3.0 4.1 4.3 1.8 Average Scale Score 2.4 2.0 1.8 2.8 Percentage At or Above Proficient 2.9 2.4 1.6 2.1 \u2014\u2014 Sample size was insufficient to permit reliable estimates. SOURCE: National Center for Education Statistics, National Assessment of Educational Progress (NAEP), 1996 Science Assessment.This report is the culmination of the efforts of many individuals who contributed their considerable knowledge, experience, and creativity to the NAEP 1996 science assessment. The NAEP 1996 science assessment was a collaborative effort among staff from the National Center for Education Statistics (NCES), the National Assessment Governing Board (NAGB), Educational Testing Service (ETS), Westat,and National Computer Systems (NCS). In addition, the program benefited from the contributions of hundreds of individuals at the state and local levels \u2014 governors, chief state school officers, state and district test directors, state coordinators, and district administrators \u2014 who tirelessly provided their wisdom, experience, and hard work. Most importantly, NAEP is grateful to the thousands of students and hundreds of teachers and administrators who made the assessment possible. The NAEP 1996 science assessment was funded through NCES, in the Office of Educational Research and Improvement of the U.S. Department of Education. The Commissioner of Education Statistics, Pascal D. Forgione Jr., and the NCES staff \u2014 Peggy Carr, Arnold Goldstein, Steven Gorman, Gary W . Phillips, and Larry Ogle \u2014 worked closely and collegially with the authors to produce this report. The authors were also provided invaluable advice and guidance by the members of the National Assessment Governing Board, NAGB staff, and the Science Standing Committee. In particular, the authors are indebted to Arnold Goldstein of NCES for his daily efforts to coordinate the activities of themany people who contributed to this report. The NAEP project at ETS is directed by Steven Lazer and John Mazzeo. The NAEP 1996 assessments were directed by Stephen Lazer and John Mazzeo. Tom Corley, Lee Jones, Tim Ligget, Christine O 'Sullivan, Amy Pearlmutter, Will Pfeiffenberger, Mario Yepes-Baraya, and Ann Marie Zolandz worked with the Science Instrument Development Committee to develop the assessment instrument. Sampling and data collection activities were conducted by Westat under the direction ofRene Slobasky, Nancy Caldwell, Keith Rust, and Dianne Walsh. Printing, distribution, scoring, and processing activities were conducted by NCS under the direction of Brad Thayer, Patrick Bourgeacq, Charles Brungardt, Mathilde Kennel, Linda Reynolds, and Brent Studer. The statistical and psychometric activities for NAEP at ETS are directed by Nancy Allen, John Barone, James Carlson, John Donoghue, and David Freund. The analyses presented in this report were led by John Donoghue and Steven Isham. The considerable production efforts were done by Loretta Casalaina, Sharon Davis-Johnson, Katonya Davis and Kelly Gibson. The production of the World Wide Web version of this report was led by Patricia O 'Reilly with assistance from Kelly Gibson, Phillip Leung, Jim Rura, and Terry Schoeps. Many thanks are due to the numerous reviewers, both internal and external to NCES and ETS. The comments and critical feedback of the following reviewers are reflected in this report: Mary Lyn Bourque, Audrey Champagne, Michael Cohen, Angelo Collins, Lawrence Feinberg, Andrew Kolstad,Michelle Leon, Laura Lippman, Marilyn McMillen, W ayne Martin, Thomas Sachse, Sylvia Ware, Arthur Williams, David Williams, and Shi-Chang Wu.AcknowledgmentsUnited States Department of Education Washington, DC 20208-5653 Official Business Penalty for Private Use, $300Postage and Fees Paid U.S. Department of Education Permit No. G-17 Standard Mail (B) "}