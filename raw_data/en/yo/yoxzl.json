{"title": "PDF", "author": "PDF", "url": "https://control.asu.edu/Publications/theses/colbert/colbert_thesis.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "From Data to Predictive Models: Robust Identi cation and Analysis of the Immune System by Brendon K. Colbert A Dissertation Presented in Partial Ful llment of the Requirements for the Degree Doctor of Philosophy Approved September 2021 by the Graduate Supervisory Committee: Matthew Peet, Chair Abhinav Acharya Spring Berman Luis Crespo Sze Zheng Yong ARIZONA STATE UNIVERSITY December 2021ABSTRACT In this dissertation, we develop new data-driven techniques to solve three problems related to generating predictive models of the immune system. These problems and their solutions are summarized as follows. The rst problem is that, while cellular characteristics can be measured using ow cytometry, immune system cells are often analyzed only after they are sorted into groups by those characteristics. Instead of grouping cells we propose analyzing the cellular characteristics by generating Probability Density Functions (PDFs) to model the ow cytometry data. To generate a PDF to model the distribution of immune cell characteristics we develop a new class of random variable called Sliced-Distributions (SDs) in Chapter 3 and show that SDs outperform other state-of-the-art methods and can di erentiate between immune cells from healthy mice and those with Rheumatoid Arthritis. The second problem is that while immune system cells can be broken into dif- ferent subpopulations, it is unclear which subpopulations are most signi cant. We, therefore, formulate a new machine learning algorithm in Chapter 4 to identify sub- populations that can best predict disease severity or the populations of other immune cells. The proposed machine learning algorithm performs well when compared to other state-of-the-art methods and is applied to an immunological dataset to identify disease-relevant subpopulations of immune cells denoted immune states. Finally, while immunotherapies have been e ectively used to treat cancer, select- ing an optimal drug dose and period of treatment administration is still an open problem. In Chapter 5 we propose a method to estimate Lyapunov functions of a system with unknown dynamics. We apply this method to generate a semialgebraic set containing immunotherapy doses and period of treatment that leads to tumor elimination. The problem of selecting an optimal pulsed immunotherapy treatment ifrom this semialgebraic set is formulated as a Global Polynomial Optimization (GPO) problem. In Chapter 6 a new method to solve GPO problems is proposed and optimal pulsed immunotherapy treatments are identi ed for this system. iiDEDICATION Dedicated to my anc\u0013 ee, my family, and my friends. iiiTABLE OF CONTENTS Page LIST Optimal Machine Learning Algorithms 21 1.4.3 Problem 3: Generating Constrained Predictive Models and Random Variables . . . . 43 3 UNCERTAINTY QUANTIFICATION Problem for Sliced-Exponentials 51 3.2.3 A Convex Optimization Problem to Solve the . . 65 Feature Space . . . 66 3.4.2 Problem in Feature Space . . 69 3.5 Numerical Results of the New TK Kernel Learning Algorithm for Regression 126 4.8 Application of the TK Kernel Learning Algorithm to an Region of Attraction . . 163 5.3.2 Computational Complexity of the Optimization Problem. . . . 167 5.3.3 Modeling the Region of Attraction 6.3 Solving the GPO Problem using the ideal Branch and Bound . . . . . . 214 viiiLIST OF TABLES Table Page 3.1 The Log Likelihood (LL) of the Uncertainty Models on the Test Par- tition Data Points and the Computation Time (T) for the MLE MN, EM GMM, MLE SE, and WCE SE Implementations. The Data Sets Have Dimension (n) and Number of Training Data . . . 73 3.2 The Volume (V) of the Level Sets of the Uncertainty Models Containing All of the Test Partition Data Points and the Computation Time (T) for the MLE MN, EM GMM, MLE SE, MLE SN, WCE SN and WCE SE Implementations. The Data Sets Have Dimension (n) and Number of Training Data Accuracy AL(H;R) of Predicting Whether a Patient Has RA or Does Not Have RA Using Varying Degree SE Models of Immune System Cells From Healthy Patients and RA Mean Computation Time (in Seconds), along with Stan- dard Deviation, for 30 Trials Comparing the SDP Algorithm In [29] and Algorithm 2. All Tests Are Run on an Intel I7-5960x Cpu at 3.00 Ghz with 128 Tests Are Run on a Desktop with Intel i7-4960X CPU at 3.60 GHz and with 64 Gb of RAM. N/A Indicates That the Algorithm Was Stopped after 24 Hours All Regression Tests Are Run on a Desktop with Intel i7-5960X CPU at 3.00 GHz and with 128 Test Set Accuracy of the SOS Optimal Function on the Van Der Pol Oscillator and the Predator-Prey Model Data. Accuracy of the Lya- punov Function Is De ned as the Sum of the Absolute Error of the Function for Each Test Point Divided by the Total Number of The Percentage of Initial Conditions That Were Correctly Determined to Be Within the Region of Attraction, Falsely Reported to Be Within the Region of Attraction and Falsely Reported to Be Outside of the Region of Attraction by the Optimal Lyapunov Function Obtained from The Percentage of Initial Conditions That Were Correctly Determined to Be Within the Region of Attraction, Falsely Reported to Be Within the Region of Attraction and Falsely Reported to Be Outside of the Region of Attraction by the Optimal Lyapunov Function Obtained from Optimization Problem (5.8). All Examples Are for the Degree 6 Model of the ROA Except for the Immune-Dynamics Which Is a A Comparison of Starting Conditions of Interior Point Method and the Resulting Number of Suboptimal (OBV < f( ^x2)) or FIGURES Figure Page 1.1 A Diagram of the Immune System Dynamics From [126] for Determin- ing Self Versus Non-self. In This Model the Derivative Response with Respect to the Antigen Is Physically Approximated in the Immune System by the Relative Delay in Maturation of Regulatory Immune System Cells When Compared to Helper T Diagram of the Immune System Dynamics Described in Eq. (1.7) . . . 17 1.3 Recommended Reading Order of the Material in This Dissertation - All Chapters but Chapters 5 And 6 Are Independent of Each Other. . . . 20 2.1 A Plot of a Function with Two Inputs (X,Z) and One Output (Y). When Both Inputs Are Known the Output Is Always Known (a), When Only One Input Is Known the Output Is Uncertain Element Show a Histogram of Mea- sured\u000ejData, While Subplots Corresponding to the jth and ith Posi- tion Show a Scatterplot of Measured Data of \u000ejVersus\u000eifor a Rescaled Version Optimization Problem (3.10), Sub- plots along the jth Diagonal Element Show a Sliced-Exponential PDF of Degree 8 Fit to Measured \u000ejData, While Subplots Corresponding to the jth and ith Position Show a Sliced-Exponential PDF of Measured Data of\u000ejVersus\u000eiof of a Rescaled Version of the Iris Dataset [55] (Blue) and Data Sampled from the SE PDF (Green) Optimized Using the Solution of the MLE Optimization Problem. Subplots along the jth Diagonal Ele- ment Show a Histogram of the Sampled \u000ejData, While Subplots Cor- responding to the jth and ith Position Show Sets of SE PDFs Fit Using Optimization Problem (3.19) That Contain Bi-variate Subsets of the Iris Data Set (Red) Compared to Level Sets of the SE PDFs Fit Using Optimization Problem (3.10) to the Same a Rescaled Version of the Iris Dataset [55] (Blue) and Data Uniformly Sampled from the Level Set HWf\u000e(D)of an SE PDF (Green) Optimized by Solving the WCE Optimization Problem. Subplots along the jth Diagonal Element Show a Histogram of the Sampled \u000ejData, While Subplots Corresponding to the jth and ith Position Show a Scat- terplot a Rescaled Version of the Iris Dataset [55] (Blue) and Data Sampled from the SN PDF (Green) Optimized Using the Rescaled Precision Matrix. Subplots along the jth Diagonal Element Show a Histogram of the Sampled \u000ejData, While Subplots Corresponding to the jth and ith Position Show a Scatterplot of of a Rescaled Version of the Iris Dataset [55] (Blue) and Data Uni- formly Sampled from the Level Set HWf\u000e(D)of an SN PDF (Green) Op- timized by Solving the WCE Optimization Problem in Feature Space. Subplots along the jth Diagonal Element Show a Histogram of the Sampled\u000ejData, While Subplots Corresponding to the jth and ith Position Show a Scatterplot of and CD11b Receptors Measured Using Mass Cy- tometry for Healthy Patients (a) and Patients PDF of Healthy Immune System Cells (a) and RA Immune System Cells (b) With CD66b and CD11b the Optimal Classi er for Labeling a 1-dimensional Data Set Compared to Gaussian Classi ers as Well as the Normalized Kernel Function, k(5;z), Using Di erent P1;1Matrices andX= [0;10]. 100 4.2 The Objective of Optimization Problem 4.19 And 4.20 for the TK and GPK Classes of Degree dand for a Positive Combination of mGaus- sian Kernels with Bandwidths Ranging from :01 to 10. The Number of Bandwidths Is Selected so That the Number of Decision Variables (Displayed above the Figure) Match in the Gaussian and in the Time vs Number of Training and Spiral Separator using Method [TK 124 xiiiFigure Page 4.5 In (a) and (b) We Find Log Scale Plots of the Time Taken to Execute FW TKL for P2Rq\u0002q. The Line of Best Linear Fit Is Included for Reference. In (c) and (d) We Find Log Scale Plots of the Time Taken to Optimize TKL as a Function of qfor Four Di erent Values of m. . . 125 4.7 A Graphical Description of the Experimental Procedure of Inducing and Treating RA in Mice. The First Two Steps Induce Ra, the next Two Steps Is the Application of the Treatment and the Final Step Is the Data Generation Using Flow Cytometry. CFA = Complete Freund's Adjuvant, IFA gure (a) Shows a 3d Representation of the Section of the Grand Canyon to Be Fitted. In (b) We Plot Elevation Data of This Section of the Grand Canyon. In (c) We Plot the Predictor for a Hand-tuned Gaussian Kernel. In (d) We Plot the Predictor from The Green Squares Indicate That the Feature Selection Method (Left) Selected the Feature (Top). The Methods Are Ordered from Lowest Objective Function, J(b), at the Top to Greatest Objective at the Bottom. The SFS Methods and the Features Most Commonly Selected by Those The Green Squares Indicate That the Feature Selection Method (Left) Selected the Feature (Top). The Methods Are Ordered from Lowest Objective Function, J(b), at the Top to Greatest Objective at the Bottom. The SFS Methods and the Features Most Commonly Selected by Those The Green Squares Indicate That the Feature Selection Method (Left) Selected the Feature (Top). The Methods Are Ordered from Lowest Objective Function, J(b), at the Top to Greatest Objective at the Bottom. The SFS Methods and the Features Most Commonly Selected by Those gures (a) and (b) Show the Initial Conditions Used to Generate the Data for Optimization Problem (a) and (b) Plot the Computation Time of Optimization Problem (5.8) with Respect to the Number of Data Points (a) and the Size of the Semi-De nite gures (a) and (b) Show the Estimated Region of Attraction E \u0003 Versus the True Region of Attraction Identi ed by Observing the Tra- jectories of Branch and Bound Algorithm Applied to the Two-variate Optimization Problem (6.9). Note That Every Iteration Discards Half gures (a) and (b) Plot Simulations of Tumor Dynamics Using the Optimal Pulsed Immunotherapy Treatments likelihood and computation time to compute SE and WCSE distributions after using one million points to calculate the of both the MLE and WCE op- timization problems as the degree or number of INTRODUCTION The human immune system consists of over 25 billion individual white blood cells alone [117, 150] that, in coordination, act to protect the body against threats such as viruses and cancer. The adaptive immune system has been optimized over 500 million years [56] of evolutionary pressure from pathogens to eliminate and recall threats, all without any centralized control. Despite recorded interest in the immune system as early as the 5th century BC [45, 146], we still do not completely understand the complex relationships between the millions of cells that control such a vital system to human life. Without understanding how the immune system functions, one can not fully understand why it fails nor how it can be xed. We are thus motivated by one crucial question: How do we generate better models of the immune system? Immune system cells interact through surface receptors with other immune sys- tem cells and molecular signals to collectively respond to threats such as viruses or cancer cells. Unfortunately, determining all the characteristics (such as cell surface receptors or intracellular proteins) of the immune cells in the body is, as of yet, im- possible. Fortunately, using techniques such as ow cytometry [94, 142], a sample of an individuals immune system cells can be analyzed, and a limited number of cellular characteristics (e.g. size, surface molecules, etc.) of the immune system cells can be determined. An important question then, is what immune cell characteristics need to be measured with ow cytometry to predict whether the immune systems will, for example, eliminate a virus or cancer cells. This dissertation therefore answers the question of how to generate better pre- dictive models of the immune system by rst developing techniques to determine 1what immune cell characteristics (using techniques such as ow cytometry) need to be measured so that we can accurately predict labels such as whether an individual is healthy or has a given disease. Next we focus on generating better data-driven models that use these cell characteristics to predict more complicated labels such as disease severity. Finally we generate a model to predict whether a given dosage and treatment period of an immunotherapy will eliminate tumor cells in a patient. Potential Impact of Improved Predictive Models of the Immune System 1 Immune Health Metrics: The normal range of the populations of simple immune cells categories, such as the population of all white blood cells have been rigorously studied (see for instance [117]). However, being inside a normal range does not indicate that a persons immune system is operating normally, especially since even among healthy individuals there is a large diversity in the populations of immune system cells [18]. Thus better metrics to analyze diverse populations of immune system cells are necessary to determine immune health with greater precision. 2 Disease Metrics: Determining the immune system cells that best explain the severity of a disease is important for determining optimal treatment strategies since treatments could, for instance, be designed to target the immune system cells causing the disease. In addition, tracking a disease metric throughout treatment can be used to determine if the current treatment is modifying the immune system as expected or if a new approach may be necessary. 3 Personalized Immunotherapy Treatments: Successful immunotherapy treat- ments depends on the immune cells and, for cancer speci cally, the local tumor microenviroment [79]. Therefore, for optimal performance, the immunotherapy drugs, dosage, and dosing schedule should be selected based on the populations 2and characteristics of the patients own immune cells. To motivate the methods developed in this dissertation we will rst describe what is known about the immune system and highlight challenges which make it di\u000ecult to model. 1.1 The Immune System While the immune system has, clearly, existed for the entirety of human history the rst known record of the concept of immunity is attributed to Thucydides in the 5th century BC [45, 146]. Thucydides noted that survivors of the plague of Athens in 430 BC were unable to contract the illness again and were thus \\immune\". The rst attempt by humans to intentionally modulate this theorized process of immunity occurred at least as early as 1000 AD in China where powdered smallpox lesions were inhaled to induce immunity to smallpox. Immunity to threats is perhaps one of the most important bene ts of the im- mune system since, as witnessed by Thucydides, it is often the best defense against pathogens. With the advent of immunotherapies and vaccines immune system mech- anisms can be exploited to, for instance, confer protection to pathogens without rst contracting the illness as is required for \\natural\" immunity. Unfortunately, the im- mune response is not infallible nor are its mechanisms completely understood. For instance, autoimmunity such as arthritis or type 1 diabetes are examples of when the system mistakenly targets the body itself. While the symptoms of these diseases can be treated, they can rarely be resolved [21, 49]. Thus, to understand why the immune system fails, and how these failures can be treated, much interest in the immune system is rmly rooted in the process of self versus non-self determination, wherein a potential threat is targeted for elimination if it is identi ed as non-self or protected if it is identi ed as self. In the following 3sections we describe key immune system components that are related to self versus non-self determination and propose models which describe the interactions between the immune system cells as they collectively identify and eliminate threats. 1.2 Self Versus Non-Self Determination Models of self versus nonself determination can describe, for example, how the immune system fails to recognize a threat such as cancer, or incorrectly recognizes healthy cells as a threat in autoimmunity. To describe how self versus nonself de- termination works, we rst describe how common threats to the immune system are identi ed by the innate immune system. Next we illustrate, through observations, that the innate immune system alone cannot properly eliminate pathogenic threats and that the more complex adaptive immune system is necessary for self versus non- self determination. Finally we end by illustrating how the immune system cells are proposed to interact to between immune system cells using models proposed in the literature. 1.2.1 The Innate Immune System Many pathogenic threats share common molecular patterns of infection that are not found in healthy human cells. These common patterns are exploited by the innate immune system, whose role is to eliminate these \\obvious\" threats. The innate system therefore has a simplistic method for self versus non-self determination that is limited to a pre-determined set of common patterns. Characteristics of pathogenic threats are called Pathogen-Associated Molecular Patterns (PAMPs). Innate immune cells can recognize PAMPs that are associated with bacteria, fungi and viruses but not human cells [112]. Upon recognizing a PAMP innate immune system cells release signals to alert other immune system cells of a 4potential threat and can engulf and process nearby molecules to present to other immune system cells. We de ne these signals and PAMPs as follows. Signals and Molecules: Cytokines: Cytokines are signaling molecules released and recognized by immune system cells. These signals are used to modulate the immune response by, for example, attracting immune system cells or promoting in ammation to increase the magnitude of the immune response. PAMPs: PAMPs are pathogen-associated molecular patterns that are commonly found on a wide variety of pathogens. When innate immune system cells recognize PAMPs they, for instance, release cytokine signals or eliminate pathogens. Antigens: Antigens are molecules such as proteins, peptides and polysaccharides. For example antigens can be part of a pathogen, and are thus speci c to that pathogen, as opposed to PAMPs which are related to a wide variety of pathogens. While the innate immune system does not recognize antigens, they can present antigens to other immune system cells (such as adaptive immune system cells presented in the next subsection). The role of the innate immune system then is primarily to recognize PAMPs, release cytokines to alert other immune system cells of potential threats and present antigens to other immune system cells. Some examples of innate immune system cells include: Innate Immune System Cells Macrophages: Macrophages are a type of immune system cell which can engulf and digest foreign substances. They are known to recognize PAMPs associated with gram-negative and gram-positive [112]. 5Natural Killer (NK) Cells: Natural killer cells are a type of immune system cell which also engulf and digest foreign substances. They are known to recognize PAMPs associated with viruses, speci cally single stranded and double stranded RNA [112]. Dendritic Cells: Dendritic cells can also engulf and digest foreign substances, but are primarily known as Antigen-Presenting Cells (APCs) because they will process and display antigen to other immune system cells via MHC I or MHC II molecules. They are known to recognize PAMPs associated with viruses and bacteria [112]. The response to PAMPs is nearly immediate because of the large numbers of cir- culating innate immune cells that can respond. Unfortunately, innate immune system cells are dependent on a limited number of receptors and do not recognize speci c pathogens that have been encountered previously. Therefore the innate immune sys- tem does not have a so called \\memory\" that could grant immunity to reinfection that was observed by, for instance, Thucydides. In addition, when adaptive immune system cells are defective as in DiGeorge's, Wiskott-Aldrich or Job's syndrome, the individual is dependent on the innate immune system and is highly susceptible to pathogens such as viruses and bacteria [112]. The adaptive response we describe in the next subsection is thus crucial to eliminating pathogens that would otherwise threaten the entire system. 1.2.2 The Adaptive Immune System: The adaptive immune system itself consists of hundreds of millions of cells all speci c for di erent antigens - and thus pathogens associated to those antigens. When an adaptive immune cell recognizes an antigen it can mount a targeted response directly against the pathogen associated to the antigen and the cumulative response of all of the adaptive immune cells composes the complete immune response. In addition, adaptive immune system cells can di erentiate into memory cells that live 6longer to confer longer lasting immunity to the individual. These adaptive immune system cells that are antigen speci c are further de ned as follows. Adaptive Immune System Cells B Cells: B cells are a type of immune system cell which produce antibodies that are speci c for a particular antigen. Antibodies are molecules that attach to antigen on pathogens marking the pathogen for elimination via phagocytosis by the innate immune system. B cells can also secrete cytokines to modulate the immune response. Cytotoxic T Cells: Cytotoxic T cells eliminate infected cells. These cells are partic- ularly important for eliminating viruses since viruses are not susceptible to antibodies while inside infected cells. Helper T Cells: Helper T cells secrete cytokines to assist the immune response. The cytokines these helper T cells release include those which aid B cells and antibody production. Regulatory T Cells: Regulatory T cells release cytokines to shut down the immune response once the threat has been eliminated. Regulatory T cells can also suppress T cells which are speci c for self antigens to avoid autoimmunity. Some innate immune system cells, such as macrophages and dendritic cells can present antigen to T and B cells and are thus involved in the adaptive immune response, though are not speci cally adaptive cells. Likewise antibodies released by the adaptive response enhance the phagocytosis of pathogens by macrophages, illustrating how the two systems are interconnected. An important question remains, however, as to how a T or B cell could be designed to speci cally target an antigen that the immune system has never encountered before. The answer to this question lies in a process called somatic recombination. 7Somatic Recombination in T Cells The adaptive immune system generates adaptive cells speci c for an unseen antigen by generating cells with random antigen receptors. If enough random receptors are generated then the chances that at least one adaptive cell is speci c for any given antigen can be relatively high. Of course randomly generating antigen receptors could lead to dangerous autoimmunity, for instance, if a receptor speci c for a self antigen is generated. The maturation process of adaptive cells is designed to lter out ine ective or self-reactive cells. For brevity we will focus on the process of somatic recombination in T cells, but note that somatic recombination also occurs in B cells. T cell precursors travel from the bone marrow to the thymus where they proliferate to generate nearly 5 \u0001107total cells every day. However only 2 \u00004% of these cells become mature T cells by passing two ltering processes and rearranging segments of their DNA to generate new antigen receptors, called T Cell Receptors (TCRs). We focus on so called \\conventional\" T cells whose TCRs have an and gene and which additionally have either the TCR co-receptor CD4 or CD8. However, immature T cells can have neither co-receptor or even both co-receptors depending on their stage of development. For instance T cells rst enter a double-negative stage and have neither CD4 or CD8 co-receptors. In the double-negative stage the gene of the TCR is rearranged rst to begin the random TCR generation process. If a gene is rearranged and if the coding sequence is without errors then the cells are said to have passed selection and can develop into double-positive cells. In the double-positive stage developing T cells have both CD4 and CD8 co- receptors and the gene is rearranged to complete the somatic recombination of the TCR. Once both the and genes have undergone somatic recombination the 8TCR has been randomly combined and is speci c for an antigen that the immune system may have never encountered before. To ensure that the TCR functions prop- erly and is not self-reactive there are two selection stages to lter out T cells with poor TCRs. The rst lter for developing T cells is called positive selection. In positive selec- tion thymic cells present self antigen on Major Histocompatibility Complex (MHC) molecules to developing T cells. In this stage if the TCR is functioning properly the developing T cells should have a small response to the MHC molecule. Developing T cells that either have no response, or too large of a response to the MHC and self antigen presented by the thymic cells will not pass positive selection. After positive selection the number of TCR will increase on the T cells as they nish developing. The second lter for developing T cells is called negative selection. Since the developing T cells have more TCR on the cell surface after passing positive selection, T cells that are speci c for self antigens will have larger responses in this stage. If the developing T cells have a large response to the thymic self antigen presenting cells, then the developing cell is either killed or becomes a regulatory T cell if it expresses the CD4 co-receptor [112]. After passing both positive and negative selection the T cells are fully developed and roam the body searching for antigen speci c to their TCR. 1.2.3 A Circuit Model of Self Non-self Determination While it is not completely clear exactly how self versus nonself determination works, it seems clear that helper and regulatory T cells modulate the immune response through the release of cytokines and cell-cell interactions. We consider the regulatory and helper T cell populations to be most important for the decision of self versus nonself, as they can control the cytotoxic T and B cell populations through the 9release of cytokines and cellular interactions. Furthermore, there is evidence that the dynamics of the antigen in the system also has a large e ect on the adaptive immune response. Most notably, in [80, 158], it was shown that the adaptive immune response is stronger when antigen is introduced at an exponentially increasing rate. Since pathogens such as bacteria and viruses grow exponentially the ability to mount stronger responses against rapidly growing threats is clearly advantageous. In [126] it was shown how the widely recognized delay in regulatory T cell activa- tion (see [75, 139]), could approximate a derivative response to antigen signaling. The cells that compose the immune system are thus proposed to act as a large decentral- ized control system that mimic a Proportional-Integral-Derivative (PID) controller. To describe the proposed model we will next analyze the proportional, derivative, and integral response of the PID type response. The Proportional Response: To adequately eliminate threats the immune sys- tem must respond to the antigen signal in the system. Suppose that for any time tthe functiona(t) describes the amount of antigen in the system, E(t) is the population of helper T cells and Tc(t) is the population of cytotoxic T cell. In [126] the popu- lation of helper T cells grows when unactivated T helper cells recognize an antigen, producing a proportional response to the antigen and the population decays as the cells die. Likewise the helper T cells recruit unactivated cytotoxic T cells that are speci c for the antigen so that the threat posed by the antigen can be eliminated. The proportional response of these populations can be described as follows. _E(t) =rEaa(t)Neq\u0000dEE(t); _Tc(t) =rEcE(t)Nc\u0000dTcTc(t); (1.1) wheredE; dTc>0 unactivated helper and cytotoxic T cells, and rEa; rEc>0 are recruitment rates. In Fig. 1.1 we illustrate 10the positive proportional response of the helper T cells to antigen stimulation. The proportional response does grow in response to an antigenic threat to protect the individual. Unfortunately the proportional response alone does not explain the observed decision making process of the immune system. For instance self antigen, which is always present in the system, should cause a consistent level of in ammation and a proportional response alone would cause the immune system to be auto-reactive. Ea P _aR ProportionalResponse Derivative ResponsePositiveFeedbackIntegral Response Figure 1.1: A diagram of the immune system dynamics from [126] for de- termining self versus non-self. In this model the derivative response with respect to the antigen is physically approximated in the immune system by the relative delay in maturation of regulatory immune system cells when compared to helper T cells.The Derivative Response: The derivative response of the circuit model explains how the immune system can di erentiate between a self antigen and a non-self antigen. The proposed mechanism of self versus non-self di erentia- tion is based upon populations of regulatory T cellsR(t) which reduce immune responses through direct contact with helper T cells, or the release of cytokines. The antigen signal released by healthy cells will be roughly con- stant and the derivative of this signal will be relatively small. The antigen signal released by a threat, however, will begin small and in- crease as the threat multiplies. In the case of a threat the derivative of the antigen signal will be large. The proposed mechanism of self versus non-self determination is based on a deriva- tive response to the antigen signal. In [126], regulatory cells are modeled as being a delayed response due to slower maturation rates of regulatory T cells, but that also have a proportional response to antigen so that the population of regulatory T cells 11is de ned as follows. R(t) =rR dRa(t\u0000 ); (1.2) whererRis the recruitment rate of the regulatory T cells and dRis the death rate. It is assumed that the population of regulatory T cells acts on the population of helper T cells ar a rate of rRE, and the combined proportional and derivative response of the helper T cells can thus be de ned as, _E(t) =rEaa(t)E(t)\u0000rRErR dRa(t\u0000 dRanda(t)\u0000a(t\u0000 ) approximates the derivative of the antigen signal. In Fig. 1.1 we illustrate the positive derivative response of the helper T cells to antigen stimulation. If rEauKREthen the response is primarily dependent on the derivative of the antigen signal, thus implying that regulatory T cells can suppress immune responses to self antigens (which should be relatively constant), but can still recognize threats which produce an increasing antigen signal. In that case, the proportional response illustrated in Fig. 1.1 is nonexistent. Unfortunately a derivative response alone is not always capable of eliminating threats completely and may lead to persistent infection. To ensure infections are eliminated, a cytokine based switching mechanism is proposed. IL-2 is a cytokine known to be important for the proliferation of immune system cells and is released by helper T cells and the number of IL-2 molecules, p, can be modeled as =rpE(t)\u0000dpp(t) wherep(t) =rpE(t) dpis the quasi-steady state of IL-2 in the system. 12Since IL-2 promotes proliferation of helper T cells, and is released by helper T cells, these dynamics generate a positive feedback loop. This positive feedback loop can be modeled as follows when using the quasi-steady state approximation of the amount of the rate of positive feedback of released IL-2 on the helper T cell population and u(t) represents the dynamics of the derivative response. In Fig. 1.1 we illustrate the positive feedback between the IL-2 population, pand the helper T cell population. If the derivative response of the system is relatively small, then the system is stable as the positive feedback can't overcome the natural decay rate of the helper T cells. However, for a large enough derivative response the system becomes unstable and the helper T cell population experiences uncontrolled exponential growth. Thus, the positive feedback loop is only \\switched\" on when a threat with a large enough derivative response is recognized. Large enough derivative responses triggers exponential growth so that threats can be eliminated by the immune system. Unfortunately uncontrolled exponential growth is unrealistic. To control this growth an integral response was proposed in [126] to stabilize the system. The Integral Response: An integral response is proposed to describe how the immune system can stop the uncontrolled exponential growth of the helper T cell population once a threat has been eliminated. A subpopulation of regulatory T cells called iTregcells are believed to be generated by the helper T cell population. Thus the population of iTregcells,Ri(t), is modeled 13as, _Ri(t) rate and \u0017Rrp dpE(t)2models the e ect of the helper T cell positive feedback loop on the population of iTregcells. TheiTregcells have a relatively low death rate when compared to the other cell populations. Thus the population of iTreg cells is approximately, Ri(t)uRt 0\u0017Rrp dpE(s)2ds. Combining the proposed derivative and integral responses (and assuming rEa= KRE) generates the helper T at which the iTregcells inhibits the helper T cell population. In Fig. 1.1 we illustrate the negative integral feedback from the iTregcell popula- tion on the helper T cell population. Considering all of the dynamics, the proposed model has an approximate derivative response to antigen that, if large enough, acts as a trigger for uncontrolled growth of the helper T cells via a cytokine feedback loop. This feedback loop is controlled by an integral like response from the population of iTregcells to contract the population of helper T cells once the antigen threat has been eliminated. The PID like dynamics describes how millions of immune system cells can unknowingly collaborate to determine if a threat is self or non-self and mount a controlled response to protect the individual from threats. The problem of self versus non-self recognition is important for understanding how the immune system identi es threats and for identifying the mechanisms that cause immune driven diseases such as rheumatoid arthritis. However, we are also interested in treating diseases after the self versus nonself determination has already 14been decided, but, after the immune system has been unable to eliminate the threat. To illustrate how immunotherapies can be used to help the immune system eliminate a threat, we next consider a model of the dynamics between cancer cells, the immune system, and an immunotherapy. 1.3 Antigen Recognition and Elimination In some cases, even if a threat has been identi ed as nonself, poor immune re- sponses can fail to eliminate the threat. For instance, cancers can release cytokines which inhibit the immune response allowing uncontrolled tumor growth. In these cases modeling the relationship between the threat, the immune system, and poten- tial immunotherapies can aid in the selection of an immunotherapy, dosage, or period of treatment to ensure the immune system eliminates the threat. Antigen in the body is captured by antigen-presenting cells such as macrophages and dendritic cells and presented on MHC I and MHC II molecules to activate adap- tive immune system cells, which then proliferate extensively to eliminate the threat. Activated cytotoxic T cells can directly eliminate infected cells that present their TCR speci c antigen, while B cells generate antibodies that mark the antigen for destruction by, for instance, increasing the e ectiveness of macrophage phagocytosis. Helper T cells and regulatory T cells release cytokines which can increase (helper) or decrease (regulatory) the number and e ectiveness of cytotoxic T cells and B cells. Thus, in many models the helper and regulatory T cells are the most important for modeling the magnitude of the immune response. To illustrate how these dynamics can be modeled we consider the model proposed in [170] to describe the dynamics between tumor cells, a cytokine, and cytotoxic, helper and regulatory T cells. 151.3.1 An Immunological Cancer Model The immune system usually generates immune responses to eliminate cancer cells. However, in this subsection we will de ne a proposed model which describes how tumor cells can release a cytokine to inhibit the immune response enabling the tumor cells to grow uncontrollably. First denote the tumor size as T, the cytokine TGF- asB, cytotoxic T cells as E, regulatory T cells as Rand activated tumor-speci c cytotoxic T-cells administered with a vaccine as V. The dynamics of each of these states is de ned as follows. _T=a0T(1\u0000c0T)\u0000\u000e0ET 1 +c1B\u0000\u000eoTV; _B=a1T2 c2+T2\u0000dB; _E=fET constants a0,c0,\u000e0,c1,a1,d,c3,f, andrde ne di erent rates at which the cancer cells and immune system cells decay or proliferate. The values of these constants were identi ed from other papers or were selected such that the model trajectories best captured experimental data. In Fig. 1.2 we illustrate graphically the relationship between the tumor, immune system cells and the cytokine signal, where solid lines imply a positive relationship and dashed lines imply a negative relationship between the state variables in the direction of the arrow. We will discuss the dynamics of each of these states in more detail as follows. Tumor Dynamics: This model assumes that the tumor follows a logistic popu- lation growth, as de ned by the term a0T(1\u0000c0T). In this case the tumor cells initially increase exponentially at a rate close to a0but the rate decreases as the cell population approaches the carrying capacity,1 c0, of the tumor. Elimination of the tumor cells occurs at a rate proportional to the population of cytotoxic T and 16tumor cells and inversely proportional to the levels of TGF- , and is given by\u000e0ET 1+c1B. The motivation behind this term comes from papers such as [160], which have shown that TGF- decreases the rate at which cytotoxic T cells can eliminate tumor cells. However, since cytotoxic T cells injected via vaccination are activated outside of the patient, it is assumed that they are fully di erentiated and not a ected by the levels of TGF- . Thus the injected cytotoxic T cells, V, eliminate tumor cells at a rate of \u000eoTVand are independent of the levels of TGF- . TB V E R Figure 1.2: A diagram of the im- mune system dynamics Eq. (1.7).Cytokine Dynamics: Experimental evi- dence in [121], suggests that the rate at which TGF- is produced is low for small popula- tions of tumor cells, but rapidly increases as the tumor population increases. The dynamics of the level of TGF- is described in [5] where it increases at a rate of a1T2 c2+T2and naturally decays at a rate of d. Cytotoxic T Cell Dynamics: For the cy- totoxic T cell dynamics it is assumed that the amount of antigen in the system is proportional to the volume of tumor cells. In this model the rate of cytotoxic T cell activation is directly proportional to the number of interactions between the T cells and tumor cells and is proportional to ET. To account for the negative e ect of TGF- on the activation and recruitment of cytotoxic T cells, the rate of increase of Eis given byfET 1+c3TB. Regulatory T cells act to shut down the immune response and, in this model, the e ect on the population of cytotoxic T cells is given by the term \u0000\u000e0RE. Furthermore, 17this model assumes that a proportion, rof cytotoxic T cells will be converted into regulatory T cells as also seen in models in [91]. Finally the cytotoxic T cells will naturally decay at a rate of \u0000\u000e1. Regulatory T Cell Dynamics: In this model the regulatory T cells are assumed to be converted from cytotoxic T cells. Although regulatory T cells can originate from helper T cells as well, this simpli cation is used to generate a model of minimal complexity. Therefore the regulatory T cells increase at a rate proportional to the cytotoxic T cell population, rE, and decay at a rate of \u000e1R. Administered Cytotoxic T Cells: The administered cytotoxic T cells are as- sumed to be fully di erentiated and thus no longer dividing, so the population in- creases only when an injection of cells is given according to the function g(t). An injection of activated T cells is a type of immunotherapy called adoptive T cell trans- fer. The injected T cells are usually taken from a patients own blood, and then grown in large numbers outside of the patient before reinjection. This treatment has been used to treat metastatic melanoma as described in [136]. These dynamics illustrate a simpli ed model of the complex interaction between immune system cells and a threat (in this case tumor cells). While this dissertation proposes data-driven techniques that do not require re- searchers to generate dynamical models ()such as those described in this section) the models help illustrate how the immune system cells in the previous section are proposed to interact. Furthermore, in Chapter 5 and 6, we use the immunotherapy model to simulate trajectory data that could be measured in a real experiment, and use this simulated data with a proposed data-driven technique. 181.4 Summary of Contributions and Organization Predictive models can be broken into two categories - physics based or data- driven. We have just illustrated examples of the former category, where fundamental physical laws or observed relationships are used to generate models between proposed explanatory variables and outputs of interest. However, when fundamental physical laws are unknown or too complex to derive, for instance as often occurs when modeling biological systems, data-driven models represent a tractable alternative. Data driven decision making has already had a positive impact on quality of life, for instance its application within the healthcare industry has decreased re-admission and mortality rates and can provide patient speci c treatments that are more e ec- tive [76, 103]. However the data-driven approach, when applied to the identi cation and analysis of the immune system, comes with its own set of problems. To generate predictive models of the immune system we have identi ed three problems whose solutions will enable better modeling of complex systems. The rst two problems are identi ed in Subsection 1.4.1 and Subsection 1.4.2 and are solved using methods developed in Chapters 3 and 4 respectively. The nal problem, de ned in Subsection 1.4.3 is solved using methods developed in Chapters 5 and 6, and thus it is recommended that these two chapters are read in order. In addition, we provide relevant background information in Chapter 2 which may be helpful if readers are unfamiliar with the topic at hand. A graphical illustration of the recommended reading order is included in Fig. 1.3. 1.4.1 Problem 1: Generating Models of the Distribution of Measured Data By performing ow cytometry on a sample of immune system cells it is possible to measure characteristics (e.g. size, cell surface receptors) that determine how a cell 19Background Information Chapter 4Chapter 5 Chapter 3 Chapter 6 Conclusion (Chapter 7) Figure 1.3: Recommended reading order of the material in this dissertation - All chapters but Chapters 5 and 6 are independent of each other. will interact with antigen, other immune system cells or cytokine signals. To analyze the populations of immune cells they are usually sorted into di erent populations in a process called gating. Unfortunately, a large variation in gating has been recorded between researchers [102] implying that analyzing ow cytometry data is a subjective process. We propose treating immune cell populations as random variables and modeling the distribution of the cellular characteristics as opposed to gating the ow cytometry data. The distribution of the cellular characteristics can then be compared between ow cytometry data sets without the need for gating. Unfortunately, the distribution of the cellular characteristics of immune system cells do not fall into any known distribution and are therefore di\u000ecult to model. The rst identi ed problem then is, given multivariate data from some unknown Data Generating Mechanism (DGM), to identify methods to model the complex distribu- tion of that data. To model complex distributions of data, in Chapter 3 we propose a new class of Probability Density Functions (PDFs) and formulate convex optimization problems to 20 t the parameters of the PDF to model the distribution of the cellular characteristics. We show that the class of PDFs is dense in the set of all continuous PDFs. This means that a PDF from this class exists that can perfectly model a random variable if its corresponding PDF is continuous. This implies that we do not need to make strict, and often invalid, assumptions that the data is normally distributed [6, 12]. To demonstrate the e ectiveness of this approach we compare the proposed method to other state of the art approaches to generate a model of the PDF of four publicly available data sets. By withholding a testing partition of data, we use a standard set of metrics to show that the proposed method outperforms the other state of the art methods. We also illustrate, using a mass cytometry dataset, how to generate models of the PDF of the cellular characteristics of immune cells taken from populations of healthy patients, and those taken from populations of patients with Rheumatoid Arthritis. Despite di erences in the PDFs among patients within the same groups, these models are able to identify \\immune features\" that are consistently shared among the patients in each group. These immune features therefore capture components of the immune system that are assumed to be relevant to the disease. Finally we note that this portion of the research is based on the work in [32, 33]. 1.4.2 Problem 2: Generating Optimal Machine Learning Algorithms Next, there exists hundreds of di erent immune cells and signals which could potentially be classi ed as either helper [165, 105] or regulatory [138, 90]. Generating a model which uses every potential subset of immune system cells would require a large amount of di\u000ecult to acquire data to determine how these di erent immune cells interact. Given populations of immune system cells (as opposed to cytometry data as in the previous subsection), the second problem is to identify a subset of those 21populations which capture the essential features of the immune system. Given inputsfxigm i=1(e.g. populations of immune cells) and outputs fyigm i=1(e.g. disease severity), predictive models such as neural networks and kernel learning algo- rithms generate a data-driven model, f, to predict the relationship between the inputs and outputs. While neural networks and kernel learning algorithms have advanced sig- ni cantly in recent years, these machine learning algorithms have fundamental aws. For instance, while the activation functions used in neural networks have shown an ability to represent complex patterns in data, there is no convex formulation of the problem of training such a network - implying that trained neural networks may be locally optimal but not globally optimal. In fact it was shown in [137] that even the simplest two-layer ReLU neural networks have many local minimum and thus neural network algorithms may return sub-optimal solutions. Whereas when a minimum is found for a convex optimization problem it is guaranteed that that solution is globally optimal. Kernel methods also have state of the art performance on a number of bench- marks. However, kernel methods require the selection of a kernel function, a problem that is highly dependent on the data itself. To minimize the \\human element\" of selecting a kernel function, kernel learning algorithms use a data-driven approach to select an optimal kernel function. While these kernel learning algorithms generally have convex formulations, they unfortunately learn only simple combinations of ker- nel functions that must be selected a priori, therefore not completely removing the \\human element\" of the algorithms performance. To judge the quality of a set of kernel functions three nonempirical criteria were de ned that simple combinations of kernel functions are, unfortunately, unable to meet. In Chapter 4 we develop the rst machine learning algorithm which, to our knowl- edge, meets all three of the proposed criteria for sets of kernel functions. Our proposed 22method (see [29, 30]) improves the accuracy of kernel based machine learning algo- rithms such as the support vector machine by automatically selecting an optimal kernel function (with respect to the data) from the class of Tessellated Kernel (TK) functions we have developed. We show that support vector machines with optimal TK kernels on average have improved accuracy when compared to other state of the art methods of machine learning on a set of 12 datasets. Finally we use the machine learning algorithm proposed in this chapter to identify populations of immune sys- tem cells that capture key components of the immune system (populations we denote \\immune states\") - including populations that are related to the disease severity of Rheumatoid Arthritis. Finally we note that this portion of the research is based on the work in [28, 29, 30]. 1.4.3 Problem 3: Generating Constrained Predictive Models and Identifying Optimal Treatments When the immune system is malfunctioning by, for instance, targeting the body itself as in autoimmunity or failing to eliminate cancer cells, a number of immunother- apies have been designed to modify the populations of immune system cells by block- ing cell surface receptors or releasing cytokines. Examples include Ipilumumab and Nivolumab which can deactivate e cells [74, 163]. While these and other im- munotherapies have shown promising results as cancer treatments, an important ques- tion is how to determine an optimal immunotherapy drug, dosage, the timing of drug administration. This is made di\u000ecult because an optimal immunotherapy treatment must depend on the number of immune system cells and their cellular characteristics, especially in the case of cancer immunotherapy [79]. The nal problem posed in this dissertation therefore is how to identify optimal immunotherapy treatments based upon the population and characteristics of immune system cells, such as the number 23of e ector and regulatory type cells. We assume that the dynamics that govern the immune system response vary slightly between di erent patients, and that the initial populations of immune system cells are most important for predicting if an immunotherapy treatment will lead to complete elimination of a tumor. We then generate a model of the Lyapunov function of the system (that is dependent upon the selected treatment strategy) using trajectory measurements of tumor growth starting from di erent initial populations of immune system cells, treatment strategies, and di erent patients with slight variations in the immune system dynamics. For a selected treatment strategy, if the initial conditions of the patient are within the Region Of Attraction (ROA) of the system (based on the Lyapunov function model) then the treatment strategy is predicted to lead to complete tumor elimination for that patient. The Lyapunov function model makes no assumptions on the form of the underlying system dynamics. While Lyapunov functions are often used to prove stability or to nd regions of attraction of a system with known dynamics there exist few methods wherein Lyapunov function estimates can be generated by trajectory measurements alone. We develop a new method to model Lyapunov functions from trajectory data in Chapter 5. However, since Lyapunov functions are globally positive, we rst develop a convex optimization problem to select a positive function that best models given input and output data according to either the least absolute deviations or least squares metrics. We then develop a method of generating values of a converse Lyapunov function using measurements of trajectories from di erent initial conditions, thus generating a model of the Lyapunov function using only measured trajectory data. We demonstrate the proposed approach by modeling the Lyapunov function of simulated data from the cancer dynamics model described in Eq. (1.7). Fortunately, 24we may represent the treatment strategies which (for the given initial conditions) are predicted to stabilize the system as a semi-algebraic set. We then show that selecting an optimal pulsed immunotherapy treatment can be formulated as a global polynomial optimization problem using the Lyapunov function model. This approach assumes that the dynamical models of each patient will be identical. To address this assump- tion we show that if the patient models are not identical (by varying the dynamical models to simulate di erent patients) we are able to nd robust immunotherapy treat- ments that can e ectively treat patients with varying immune dynamics, but are no longer optimal for any given patient. In Chapter 6 we formulate a new algorithm to solve global polynomial optimization problems. To demonstrate that the algorithm, in conjunction with the model of the Lyapunov function, can nd optimal treatment strategies, we simulate 1000 random patients and use the GPO algorithm to select optimal treatments. The simulations of the immunotherapy model show that over 30% of the selected treatments are within 10% of the optimal treatment strategy, and that all of the treatments lead to complete cancer elimination within 120 days - all based solely on measured trajectories of the system dynamics. Finally we note that this portion of the research is based on the work in [27, 31]. 25Chapter 2 BACKGROUND MATERIAL In this chapter we lay the foundation for the methods proposed in this dissertation. In Section 2.1 and 2.2 we provide background material on convex optimization - speci cally delving into the topics of semide nite programming and polynomial opti- mization that are important for developments within all chapters of this dissertation. Furthermore, in Section 2.3 we review Lyapunov theory which is most relevant to Chapter 5 and in Section 2.4 we review methods of classi cation and regression using support vector machines that are most relevant to Chapter 4. Finally in Section 2.5 we brie y review some uncertainty quanti cation methods which lays the foundation for Chapter 3. 2.1 Convex Optimization Problems All of the methods proposed in this dissertation generate predictive models by solving optimization problems. An optimization problem has the form, min z2Rnf0(z) (2.1) subject to: fi(z)\u001408i= 1;:::;m; where each fi:Rn!Ris a function of the vector z2Rncalled the decision variables. The function f0(z) is called the objective function, and the functions fi(z) fori= 1;:::;m are constraint functions. If we de ne the set of all feasible points as Z:=fz2Rnjfi(z)\u001408i= 1;:::;mg, thenz\u00032Zis optimal if f0(z\u0003)\u0014f0(y) for ally2Z. 26Optimization problems are divided into di erent classes depending on the types of functions that compose the objective function and constraints. The rst types of optimization problem we will de ne are the class of convex and nonconvex optimiza- tion problems. If the functions fi(z) for alli= 0;:::;m that compose the objective and constraint functions are convex then we say the optimization problem is con- vex, otherwise the optimization problem is nonconvex. We de ne convex functions as follows. De nition 1. A function if g(tz+ (1\u00001)y)\u0014tg(z) for allz;y2Xand allt2[0;1]. An important property of convex optimization problems are that any locally op- timal decision variables are globally optimal. This implies that if a locally optimal decision variable is found, it must be the globally optimal solution. Nonconvex opti- mization problems do not have this property and there are seldom any ways to verify if a locally optimal decision variable is globally optimal. The classes of convex optimization can be further divided into the class of Linear Programs (LPs), Quadratic Programs (QPs), and semide nite programs (SDPs). Of most signi cance to this dissertation is the class of semide nite programs (which contains the classes of LPs and QPs), which we cover in greater detail in the following subsection. 272.1.1 Semide nite Programming A semide nite programming problem in its standard form can be represented as follows. min Z2Rn\u0002ntrace(CZ) (2.2) subject form of Eqn. (2.2) are convex optimization problems that can be solved in polynomial time (see [3]) using solvers such as Sedumi and Mosek [4, 153]. The constraint, Z\u00170, restricts the decision variable Zto be within the cone of symmetric positive semide nite n\u0002nmatrices. Semide nite programming has found numerous implementations in optimal con- trol with linear matrix inequalities. Linear Matrix Inequalities (LMIs) have been applied to determine stability of linear systems and design optimal H2andH1con- trollers and observers for nominal and uncertain plant models. More examples of the use of LMIs to solve problems related to control systems can be found in [47]. In this dissertation however we focus on the application of semide nite programming to the optimization of polynomial functions. 2.1.2 Polynomial Optimization We de ne polynomial optimization as an optimization problem where the vector of decision variables zparameterize at least one degree bounded, possibly multivariate, polynomial function. We denote this ring of polynomial functions in x2RnasR[x] and the degree dbounded ring of polynomial functions as Rd[x]. 28To show that any polynomial in Rd[x] can be linearly parameterized by a vector of decision variables we must rst denote the monomials of the variables x2Rn. The monomials be ordered using various orderings on Nn. In this dissertation the graded lexicographical ordering is used. This ordering is de ned inductively as follows. Fora;b2Nn,a\u0014bifPn i=1ai<Pn i=1bi;ora1=b1and [a2;\u0001\u0001\u0001;an]\u0014[b2;\u0001\u0001\u0001;bn]. Denote byZ(x) the nite ordered of all monomials, where x <x if < . Because we have used the graded lexicographical ordering, if we restrict ourselves to the rst\u0000d+n d\u0001 elements of Z, then this is the vector of all monomials of degree dor less. We denote this truncated vector as Zd(x) and the length of Zdasq:=\u0000d+n d\u0001 . Using this de nition, it is clear that any polynomial has a vector representation as pd(x;z) =zTZd(x) for some vector z2Rq, wheredis the degree of polynomial p. In addition for any given y2Rnwe have that p(y;z) is a linear function with respect to the decision variables zand can be represented as, p(y;z) =qX j=1zjnY i=1y i i: Therefore evaluating pat any point yis a linear function of the decision variables and is a convex function of the decision variable z. Furthermore, consider constraints of a polynomial function evaluated not over a single given point y, but over an in nite amount of points y2Y. For instance consider the constraint, p(y;z)\u00150;for ally2Y; where there exist an in nite number of constraints on the decision variables z. We will discuss methods of enforcing this constraint in the following section. 292.2 Optimization of Positive Polynomials In this section a parametrization of a set of nonnegative polynomials is de ned using the Sum-Of-Squares (SOS) polynomial approach. Next a parametrization of a set of polynomials nonnegative over a semialgebraic set is given based upon the Positivstellensatz result. Finally we de ne the greatest lower bound problem and the closely related Global Polynomial Optimization problem. 2.2.1 Sum-of-Squares Polynomials In this subsection we de ne the set of SOS polynomials, and show that the set of SOS polynomials is a convex set de ned by positive semide nite matrices. Formally, we denote the degree dbounded sum-of-squares polynomials is Sd[x]. Clearly any element of S[x] is a nonnegative polynomial. Furthermore, using the vector representation of polynomials we can show that any SOS polynomial has a matrix representation as i\u00170. Moreover, any polynomial, h(x) =Zd(x)TMZd(x): is the matrix Mmultiplied by the square root of the corresponding eigenvalue. Therefore we have shown that any SOS polynomial has a representation of this form, h2d(x;M) =ZT d(x)MZd(x); for someM\u00170. A positive cate of positivity on Rnfor the polynomial h2d. However, it is important to note that even if a polynomial cannot be parameterized with a positive semide nite Mit still may be nonnegative on Rn. For instance the motzkin polynomial is an example of a degree 2 dbounded polynomial that is not an SOS polynomial but is nonnegative on the domain Rn[111]. Next we use the we review Putinar's positivstellensatz which gives necessary condi- tions for a polynomial to be positive on the semiaglebraic set S:=fx2Rn:gi(x)\u0015 0; i= githat de ne Sto deduce a cone of polynomials which are non-negative on S. This cone is the quadratic module which we de ne as follows. De nition 2. Given a nite collection of polynomials gi2R[x], we de ne the Clearly, any polynomial in Ais nonnegative on S. Furthermore, since for any f;g2R[x] we have that fg2R[x], the constraint p2A(k)can be represented as a polynomial in matrix form and the constraint can be represented as an LMI. Furthermore, if the module satis es the Archimedean property, then Putinar's Posi- tivstellensatz states that any polynomial which is positive on Sis an element of A. That is,Aparameterizes the cone of polynomials positive on S. A quadratic module Ais said to be Archimedean if there exists some p2A andR6= 0 such that p(x) =R2\u0000Pn i=1x2 i. We thatfgigis an Archimedean representation of Sif the associated quadratic module is Archimedean. Note that the Archimedean property is a property of the functions giwhich then de ne the quadratic module and not a property of S. Speci cally, if Sis compact, andfgigl i=1 is not Archimedean, consequence of Putinars Postivstellensatz is that the problem of computing the greatest lower bound of a polynomial function over a semi-algebraic set can be formulated as a convex optimization problem. 2.2.3 The Greatest Lower Bound Problem The Greatest Lower Bound (GLB) problem is de ned as, \u0015\u0003:= max \u00152R\u0015 (2.4) such that: f(x)\u0000\u0015>0;8x2S; 32where we de ne the feasible set Sas S:=fx2Rn:gi(x)\u00150; hj(x) = 0g: (2.5) Unfortunately, there is no algorithm which solves the GLB exactly in polynomial time. However asymptotically exact approaches to solving the GLB problem such as SOS programming in [123], and its dual Moment-relaxation problem in [98] can be used to approximate the GLB problem when the functions f,giandhjare polyno- mials. Both these approaches are well-studied toolboxes, including SOSTOOLS [130] and [73]. Both a hierarchy of primal/dual semide under mild conditions, the algorithms are asymptotically accurate in the sense that lim k!1p\u0003 k= lim k!1d\u0003 k=f\u0003[141]. Moreover, if the feasible set, S, as de ned in (2.5), is nonempty and compact, then there exist constants f,hj, andgisuch thatjp\u0003 problem closely related to the GLB is the Global Polynomial Optimization Problem. 2.2.4 Global Polynomial Optimization Global Polynomial Optimization (GPO) is de ned as optimization of the form f\u0003:= min x2Rnf(x) (2.6) such in decision variables x. Clearly the GLB and GPO problems are closely related in that \u0015\u0003=f\u0003=f(x\u0003), but are not 33equivalent in that the GLB problem does not nd x\u0003. As de ned in Eq. 2.6, the GPO problem encompasses many well-studied sub- classes including Linear Programming (LP) [88, 85], Quadratic (QP) [106], and Mixed-Integer Non- linear Programming (MINLP) [99]. Because of its generalized form, almost any op- timization problem can be cast or approximately cast as a GPO, including certain NP-hard problems from economic dispatch [122], optimal power ow [64] and optimal decentralized control [101]. As applied to control theory, GPO can be used for stabil- ity analysis of polynomial dynamical systems by, e.g., verifying invariants as in [110]. convex and hiare a\u000ene, the GPO problem is convex and may be solved using barrier functions and gradient descent. When the GPO problem is not convex, there also exist special cases in which the global optimum is guaranteed to be found. For example, in [154] the unconstrained problem was solved using Groebner bases. In the special case of x2R1, the problem was solved in [144, 145]. In addition, there exist several widely used heuristics which often yield reasonably suboptimal and approximately or exactly feasible solutions to the GPO problem (e.g. [35, 151]), but which we will not discuss here in depth. The moment approach can be used to obtain an algorithm with nite termination time, unfortunately, however, it has been shown that the class of problems for which these methods terminate is a strict subset of the general class of GPO problems [115] and furthermore, there are no tractable conditions verifying if the algorithm will terminate or bounds on computational complexity in the case of nite termination. Therefore, in Chapter 6 we propose a new method for solving GPO problems. 342.3 Lyapunov Theory Lyapunov Theory refers to the work of A. M. Lyapunov in which the de nitions of stability were standardized and methods for determining stability of systems were proposed. Lyapunov considered systems of ordinary di erential equations of _x(t) =f(x(t)); x(0) =x0; (2.7) wheref:Rn!Rnandx02Rnare respectively denoted the vector eld and initial conditions. If we de ne g(x0;t) to be the solution map of Eq. (2.7), where g(x;0) =x(0) andd dtg(x;t) =f(g(x;t)) for allx2Rnandt\u00150 then we may de ne asymptotic stability of a system on a set Xas follows. De nition 3. Given a nonlinear ODE, _x=f(x), the point x= 0 is asymptotically stable on the = 0;8x2X (2.8) where@tg(x;t) =f(g(x;t))andg(x;0) =x. Lyapunov based methods estimate the region of attraction on a compact set X2 Rnby searching for a Lyapunov function V:Rn!R, and a scalar csuch that the time derivative of the Lyapunov function is negative for all values of xon the set D:=fxjV(x)\u0014c; x6= 0g. The Lyapunov function, V, must be positive on the setDbut can be any type of function - for instance we see logarithmic Lyapunov functions in [1]. If we consider polynomial Lyapunov functions then the search for Lyapunov proofs of stability can be cast as a semi-de nite programming problem using the Sum-of- Squares (SOS) optimization discussed in the previous section. The toolbox SOS- Tools [129], provides a general purpose sum-of-squares programming solver that can 35be used to solve multiple control systems problems using Semi-De nite Programming (SDP) solvers such as SeDuMi [153]. Note, however, that even when the ODE of a system is known, _ x=f(x), and the function f:Rn!Rnis polynomial, methods for nding the region of attraction involve a bilinear SOS optimization problem that can be, at least approximately, solved using bisection [82] or genetic algorithms [70]. SDP techniques have also been used to nd Lyapunov functions as a certi cate of stability for switched [15] and hybrid systems [81]. Most relevant to this dissertation are data based methods (of which there are very few). However when an ODE and Lyapunov function are given, but the ODE does not capture all the system dynamics, a data-based approach to estimate these unmodeled dynamics and return an estimate of the region of attraction for the system can be found in [9]. If an ODE does have an equilibrium point, then the set of converse Lyapunov theorems guarantee the existence of Lyapunov functions that prove stability on the region of attraction [69]. For example, such a converse Lyapunov function, V(x) =Z1 0kg(x;t)k2dt; (2.9) is guaranteed to exist. Non-Lyapunov based methods for calculating stability and the region of attraction generally involve numerically integrating the vector eld of the ODE. One such nu- merical method (see [26]) involves identifying the equilibrium points whose unstable manifolds contains initial conditions that approach the equilibrium point of interest, which is usually performed by integrating the vector eld. The union of these man- ifolds are then within the region of attraction. Other methods involve numerically integrating the vector eld in the forward and reverse direction and observing the trajectories of a set of initial conditions as in [62]. 36In Chapter 5 we develop a data based method for modeling a converse Lyapunov function for an unknown system and use this model to estimate the region of attrac- tion. 2.4 Support Vector Machines One of the fundamental problems in machine learning is that of using labeled data to predict the values of unlabeled data. For instance, assume a data generat- ing mechanism has generated data points fxigm i=1\u001aRnwith corresponding labels fyigm i=1\u001aR, then a common problem is to predict the labels of future points drawn from the DGM. Support Vector Machines (SVMs) are a machine learning method for binary clas- si cation (yi2f\u0000 1;1g) and regression problems ( Vladmir Vapnik in the 1990s [14, 36]. The support vector machine was designed to minimize the error of predicting unlabeled data based on minimizing a bound on the prediction error provided by Vapnik-Chervonenkis (VC) theory. In this section we will pose both the 1-norm soft margin support vector machine as well as the epsilon Support Vector Regression ( \u000f-SVR) problem. We will propose improvements to these machine learning algorithms in Chapter 4. 2.4.1 The 1-norm Soft Margin SVM: Suppose we are given a set of mtraining data pointsfxigm i=1\u001aRn, each with associated labelyi2f\u0000 1;1gfori= 1;\u0001\u0001\u0001;m. We want to nd a classi er, f, that correctly classi es the training points (i.e. f(xi) =yi) as well as points that are not included in the training data. A point is misclassi ed if f(xi) =\u0000yiand we impose a penaltyC2R+on points in the training data that have been misclassi ed. We de ne the primal version of the linear 1-norm soft margin from inputs to outputs is then f:Rn!f\u0000 1;1g wheref(z) = sign(wTz+b). This map maximizes the margin (distance) between training data with a negative label, and those with a positive label. If the relationship between the inputs and outputs is not linear, then we may introduce a positive kernel function, kto generate nonlinear classi ers. De nition 4. We say a function k:Y\u0002Y!Ris apositive kernel function if Z YZ Yf(x)k(x;y)f(y)dxdy\u00150 for any function f2L2[Y]. For any given positive kernel kwe may associate a function \b such that k(x;y) = h\b(x);\b(y)iwhereh\u0001;\u0001iis the dot product. In this case Optimization Problem (2.10) might be posed er would be f(x) = sign (hw\u0003;\b(x)i+b\u0003) which maximizes the margin between points of negative and positive label in the ker- nel space \b( x). Although the primal form of SVM has certain advantages - see [133], it is ill-suited to kernel learning. For this reason, we consider the dual formulation, max 2RmmX \b from the optimization problem using h\b(xi);\b(xj)i= k(xi;xj) where the elements k(xi;xj) de ne the kernel matrix. In this case, the resulting classi er is only a function of kand becomes f(z) = sign mX i=1 \u0003 iyik(xi;z) +b! : Note thatbcan be the average of yj\u0000Pm i=1 iyik(xj;xi) for all jsuch that 0 < j< C - See [140]. This implies that the primal variable wis not explicitly required for the calculation of b, and that the resulting learned classi er, f, may be expressed solely in terms of and the kernel function. Commonly used positive kernel functions include the gaussian kernel k1(x;y) = e(\u0000 jjx\u0000yjj2), where is the bandwidth (and must be chosen a priori) and the polyno- mial kernel k2(x;y) = (1 +xTy)dwheredis the degree of the polynomial. We next formulate the Kernel Learning problem for the \u000f-SVR problem. 2.4.2 The \u000f-SVR Problem: Suppose we are given a set of mtraining data pointsfxigm i=1\u001aRn, each with associated outputyi2Rfori= 1;\u0001\u0001\u0001;m. given \\penalty\" parameter C2R+ and allowable loss \u000f2R+, we de ne the primal version of the linear epsilon Support Vector Regression ( learned from inputs to outputs is then f:Rn!Rwheref(x) = wTx+b. As in the case of the binary support vector machine, the use of a positive kernel 39function,k, can be used to modify the learned predictor. Using the transformation \b, such that k(x;y) =h\b(x);\b(y)i, Optimization Problem (2.13) would be f(z) =hw;\b(z)i+b. As in the 1-norm soft margin problem we will consider the dual formulation, eliminate \b from the optimization problem using h\b(xi);\b(xj)i= k(xi;xj) where the elements k(xi;xj) de ne the kernel matrix. The resulting predictor is only a function of kand exploiting the Karush-Kuhn-Tucker (KKT) conditions - See [147]. This implies that the primal variable wis not explicitly required for the calculation of b, and that the resulting predictor, f, may be expressed solely in terms of , \u0003and the kernel function. In Chapter 4 we will propose a new class of kernel function and a new algorithm to optimize this kernel function with respect to the given data. 402.5 Uncertainty Quanti cation Consider the problem of using numerical algorithms to model the probability density function of a continuous random variable based on data sampled from that variable. Speci cally, suppose we are given a parameterized set of probability dis- tributions and would like to select the distribution which best models a set of data, using some metric for t (e.g. Maximum Likelihood Estimation (MLE)). This prob- lem is often referred to as uncertainty quanti cation and is a critical part of analysis in such elds such as climate change [124, 168], control a well-studied eld of research [43, 156], and as a result, there are many candidates for the parameterized class of models and associated tting algorithms. As an illustration of how uncertainty can a ect measured data consider Fig- ures 2.1(a) and (b). In Fig. 2.1(a) we show a function with two inputs ( XandZ) and one output ( Y). However, assume that the input Zrepresents varying operating conditions, noise, or some unmeasured characteristic. Then in Fig. 2.1(b) we show the value of the output, Y, for di erent values of the input, X, over all possible values of the unmeasured value Z. Clearly, the function no longer returns a single value for a given input, but will vary depending upon the value of the unknown Z. When mea- suring data from a DGM, the unmeasured a ects imply that the exact relationship between the inputs and outputs will be inexact, as illustrated in Fig. 2.1(b). By quantifying the variability in the measured data, robust predictive models can be generated to account for the unknown factors causing the variation in the measured data. In this dissertation we use Probability Density Functions to model the variability of data drawn from a DGM. 41(a) A function with two inputs (X,Z) and one output (Y). All inputs are measured and the output has no uncertainty. (b) A function with one input (X), one unmea- sured input (Z) and one output (Y). Since Z is unmeasured the output is uncertain. Figure 2.1: A plot of a function with two inputs (X,Z) and one output (Y). When both inputs are known the output is always known (a), when only one input is known the output is uncertain (b). 2.5.1 Important De nitions We de neL1(\u0001) as the set of all Lebesgue functions fon \u0001\u001aRn that satisfyR \u0001f(\u000e)d\u000e <1andL1+(\u0001) as allL1functions that are positive for all values in \u0001. A Probability Density Function (PDF) on a bounded compact domain \u0001 is a convex subset of L1functions [48] and is de ned as follows. De nition 5. We say a function f2L1+(\u0001) is aProbability Density Function on a bounded compact domain \u0001if, Z \u0001f(\u000e)d\u000e= 1 and,f(\u000e)\u00150for all\u000e2\u0001: From this de nition we may de ne F\u0001as the set of all \u000e2\u0001f(\u000e)<1\u001b : for comparing the distance between two PDFs, fandgare The squared Hellinger In this paper we de ne density between two sets of PDFs using the Hellinger metric. De nition 6. Given two sets of PDFs FandGwe say that Fis dense in Gif for anyg2Gandepsilon> 0there exists an f2Fsuch thatd2 H(f;g)\u0014\u000f. Note, however, that the relationship between the Hellinger distance and the L1 distance is d2 H(f;g)\u0014dT(f;g) [93], implying that this de nition of density holds if we replace the squared Hellinger distance with the L1distance. 2.5.2 Metrics for Selecting PDFs to Model Random Variables To select a predictive model which best models the variability of measured data we will use two di erent metrics - the likelihood and worst case likelihood metrics. Likelihood Metrics Suppose we are given a set of data, D:=f\u000eigm i=1, drawn from some unknown DGM where\u000e2Rnis a continuous random variable. Here we will propose two metrics for selecting a PDF from a given class to model the DGM. The rst metric is the likelihood of the data. For a PDF f, with given parameters \u0012, the likelihood of the data is given by, Lf(D) =Y \u000e2Df(\u000e;\u0012): (2.16) 43Finding the parameters, \u0012, which result in the maximum likelihood of the data is called the Maximum Likelihood Estimation (MLE) optimization problem. This approach is covered extensively in work such as [113]. A second metric used to evaluate a PDF with respect to given data is the worst case likelihood of the data, Wf(D) = min \u000e2Df(\u000e;\u0012): (2.17) Finding the parameters, \u0012, which result in the maximum worst case likelihood is called the maximum Worst Case likelihood Estimation (WCE) optimization problem. The level sets of the WCE optimized PDF functions are often used to characterize sets of minimal volume that are likely to contain future data points. Uncertainty Quanti cation with Gaussian Distributions For example, consider the class of Gaussian PDFs. For any \u00162Rnand positive matrixP\u001702Rn\u0002n, we may obtain a Gaussian Probability Density Function of the form fG(\u000e;\u0016;P) :=e\u0000(\u000e\u0000\u0016)TP(\u000e\u0000\u0016) 2 (2\u0019)n=2p det(P\u00001): (2.18) For a given set of data the MLE optimization problem (for a Gaussian PDF) is the following optimization problem. max \u00162Rn;P2Rn\u0002nLfG(D) =Y \u000e2DfG(\u000e;\u0016;P) The solution to the maximum likelihood problem for a Gaussian PDF has an ana- lytical solution that can be computed e\u000eciently where, \u0016\u0003is the mean of the data, andP\u0003is the inverse of the empirical covariance matrix, and is called the precision matrix. 44For the same set of data the WCE problem (again for a Gaussian PDF) is the following optimization problem, max \u00162Rn;P2Rn\u0002nWfG(D) = max \u00162Rn;P2Rn\u0002nmin \u000e2DfG(\u000e;\u0016;P): Generally the worst case likelihood approach does a poor job of modeling the PDF of the resulting DGM. However, it can be used to characterize volumes where future data is likely to fall based on the level sets of the model PDF. The level sets of the Gaussian distribution are semi-algebraic and are de ned as follows. H =f\u000e: (Zd(\u000e)\u0000\u0016)TP(Zd(\u000e)\u0000\u0016)\u0014 g; (2.19) The worst case likelihood approach tends to generate sets that contain all of the data with signi cantly smaller volume than the maximum likelihood approach. In fact if the worst case likelihood approach is used to nd \u0016andP, and = max\u000e2D(Zd(\u000e)\u0000 \u0016)TP(Zd(\u000e)\u0000\u0016), then we show in Chapter 3 that the set Sis exactly the ellipsoid of minimal volume containing all of the points in D. 45Chapter 3 UNCERTAINTY QUANTIFICATION USING POLYNOMIAL AND SUM-OF-SQUARES OPTIMIZATION To generate models that capture the diversity of immune system cells found in, for instance ow cytometry or mass cytometry datasets, we will model the Probability Density Function (PDF) of characteristics of the immune system cells. Analyzing the PDF of the cellular characteristics of a patients immune system cells returns a holistic model of the immune system when compared to sorting the cells into a nite set of groups. PDF models can then be compared using metrics such as the Hellinger distance [72] to determine immune system similarity between two individuals. How- ever, the PDF of cytometry datasets often do not fall under any known distribution like, for instance a Gaussian. Modeling the cellular characteristics with a PDF thus requires state of the art techniques. One approach to modeling the PDF of multivariate data is to use Gaussian Mix- ture cantly richer class of distributions than multivariate normals and examples of the use of GMMs to model random variables include adjacent vehicle motion in [169], and modeling wind power generation in [87]. Unfortunately the use of numerical algorithms for tting GMMs to data su ers from the problem of non- convexity of the optimization problem. Speci cally, the MLE optimization problem introduced in Chapter 2 for GMMs is a non-convex optimization problem. Thus any distribution obtained from an expectation-maximization algorithm as applied to the MLE problem for GMMs is likely to be sub-optimal, with no provable bounds on performance [11]. 46In this chapter we propose new sets of PDFs to model the distribution of mul- tivariate data which are dense in the set of all bounded PDFs ( F\u0001) on a compact domain (Recall De nition 6 from Subsection 2.5.1 for the de nition of density for sets of PDFs). However, unlike the GMMs, the parameters of these sets are convex with respect to the MLE optimization problem and the globally optimal parameters can be found. In Section 3.1 we propose a new set of distributions called Sliced Distributions (SDs). We then de ne in Sections 3.2 and 3.3 two subsets of Sliced Distributions, the Sliced-Exponential (SE) and Sliced-Normal (SN) distributions and prove that, for any\u000f >0 and PDF in f2F\u0001, their exists a SE PDF gsuch that the squared Hellinger distance between fandgis less than \u000f. Furthermore we introduce convex optimization problems that can be used to t a SD to a given set of data drawn from a DGM. Then in Section 3.5 we compare SDs to classes of PDFs such as the Gaussian and GMMs on standard metrics, and show that SDs generate superior models of the distribution of publicly available datasets. We then apply the SDs to model the di erence in the PDF of immune cell characteristics between healthy patients and those with rheumatoid arthritis using a mass cytometry dataset. Furthermore we show that the PDF models can be used to predict whether a patient has RA or does not have RA with an estimated accuracy of 92 :86%. 3.1 Sliced-Distributions In this section we de ne the set of Sliced Distributions which we will use to represent the joint probability distribution of random variables. The general form of the Probability Density Function (PDF) of a SD is as follows. De nition 7. Let\u000e2Rnbe a random variable with support \u0001\u001aRn,Z:Rn!Rq withq > n , andpf:Rq\u0002Rk!Rwith support \u0001Zbe a given probability density 47function. Then the sliced PDF is given by, pSD(\u000e) >>:1 cpf(Z(\u000e);\u0012) for all\u000e2\u0001 density func- tion. IfZis injective non-surjective function then any\u000e2\u0001g is non-empty and the Sliced-Distribution, pSD(\u000e), is a slice of the PDF pf(z) on \u0001Z=SZwhereSZis \"sliced\" out of the distribution. We classify Sliced Distributions by the function Zwhich lifts the data to a higher dimensional space, and by the distribution in the higher dimensional space, pf. To further illustrate the connection between the functions pfandZ, we de ne the physical and feature spaces as follows. De nition 8. For a given random vector \u000e2Rq, a function Z:Rn!Rqand corresponding PDF pfwith support \u0001Z\u001aRq, we say the physical space isRn and contains samples \u000e(i)of the random vector \u000eand the feature space isRqand contains transformed samples of the random vector z(i):=Z(\u000e(i)). Thereforepfis a joint density function in the feature space, while pSDis a joint density function in the physical space. 3.2 The Set of Sliced-Exponential Random Variables In this section we propose the set of Sliced-Exponential (SE) random variables and de ne two convex optimization problems that can be used to select the parameters 48of the SE that best model the distribution of given data, D:=f\u000ei2Rngm i=1. We make no assumptions on the data Dexcept that it is drawn from some unknown Data Generating Mechanism (DGM). We de ne the set of SE random variables as follows. De nition 9. Given bounded \u00012Rn,\u0015, than dof\u000eandc=R \u0001e\u0000\u0015TZd(\u000e)d\u000e. In Theorem 11 we will show that E\u0001is dense inF\u0001, the set of all bounded PDFs. In addition we prove that the likelihood of the data is convex with respect to the \u0015 parameter of the SE PDF. We use this fact in Subsections 3.2.2 and 3.2.3 to show that the MLE and WCE optimization problems are convex. 3.2.1 Properties of SE Random Variables We will show in this subsection that the set of SE random variables is dense in the set of all random variables de ned by bounded PDFs on a compact domain. Lemma 10. On compact \u0001, for anyf2F\u0001and\u000f >0, \u0001eh(x)dx\u0000f(\u000e) d\u000e<\u000f: Proof. that exists an M <1such that sup\u000e2\u0001f(\u000e)\u0014M and since \u0001 is compact V\u0001=R \u00011\u0001(\u000e)d\u000eexists. Next for any > 0, de ne the 49function log( )(x) =8 >>< >>:log(x)x> log( max nV\u0001, sinceMis the maximum proof. We next apply Lemma 10 to show that the set of Sliced-Exponential PDFs is dense in the set of Theorem 11. d2 H(f;h)<\u000f. 50Proof. Lemma 10 we have that for any \u000f >0 there a d\u000e < \u000f . Polynomial functions are dense in the set of continuous functions on compact sets, which are dense in L1(\u0001) [57], therefore there exists H(h;f)\u0014Z \u0001jh(\u000e)\u0000f(\u000e)jd\u000e<\u000f: We will show in the numerical results that even SEs of nite degree can model the distribution of unknown DGMs better than other state of the art methods. Next we will develop an optimization problem for optimizing the \u0015parameter of the SE. 3.2.2 Solving the MLE Optimization Problem for Sliced-Exponentials This subsection describes how to select an optimal parameter \u0015to model the distribution of a given set of data D:=f\u000e(i)gm i=1by solving the MLE optimization problem for xed values of \u0001 and d. Maximizing the Likelihood of the Data We rst de ne the MLE problem with respect to the set of Sliced-Exponentials. We then de ne a convex optimization problem and show that it solves the MLE problem. The likelihood of a given set of data D, for a model fis, Lf(D) =mY i=1f\u000e(\u000e(i)); (3.4) and the solution of the MLE problem is the model fwithin a given set of PDFs that maximizesLf(D). 51Recall that for a support set \u0001, our Sliced-Exponential PDF can be de ned as, fd(\u000e;\u0015;\u0001) =8 >>< >>:e\u0000\u0015TZd(\u000e)\u0000log(c)if\u000e2\u0001 0 otherwise.(3.5) The MLE problem with respect to the SE set of random variables and data from a DGMD:=f\u000e(i)gm i=1, is to \u00152RqOd;\u000e;s(\u0015) =mY i=1e\u0000\u0015TZd(\u000e(i))\u0000log(c); (3.6) however since there is no known analytical solution for cwe will calculate its value using Monte Carlo sampling. First letS:=fs(i)gb i=1containbpoints uniformly sampled from the set \u0001. Then we may estimate the normalization constant cusing Monte Carlo sampling as, c=Z \u0001e\u0000\u0015TZd(\u000e)d\u000e\u0019v\u0001 bbX i=1e\u0000\u0015TZd(s(i)); (3.7) wherecbecomes exact as bapproaches in nity. We therefore estimate log( c) as, log( ~cb(\u0015;d;S)) = log(v\u0001)\u0000log(b) + log bX i=1e\u0000\u0015TZd(s(i))! : (3.8) We will discuss how many samples, bto select for accurate estimation of the normal- ization constant in Appendix A.1 and further analysis can be found in [40]. Now we may simplify the objective the following expression, min \u00152Rq(mX i=1log bX i=1e\u0000\u0015TZd(s(i))! +\u0015TZd(\u000e(i))) ; (3.10) is equivalent to maximizing equation (3.9) and thus returns the solution to the MLE problem. Next we will prove that this optimization problem is convex. The MLE Optimization Problem is Convex Here we will nd the gradient and Hessian of the objective function of Optimization Problem (3.6). For a given degree d, data set\u000e, and sampled set, S, the objective function of Optimization Problem (3.9) is Od;\u000e;s(\u0015) :=mX j=1log bX i=1e\u0000\u0015TZd(s(i))! +\u0015TZd(\u000e(j)): (3.11) The gradient of this objective function with respect to \u0015is therefore a sum of the gradient and Hessian of functions of the following form, f(\u0015;s;\u000e ) = log bX i=1e\u0000\u0015TZd(s(i))! +\u0015TZd(\u000e): (3.12) The partial derivative of f(\u0015;s;\u000e ) to each element of the monomial basis of the ith datum in s. The element corresponding to the k'th row and j'th column of of the Hessian that the Hessian matrix is positive semi-de nite and, thus, the functionf(\u0015;s;\u000e ) in Eq. (3.12) is convex with respect to \u0015. Lemma 12. ForV2Rb\u0002qwhereV(j)2Rbis the jth column vector in the matrix V, andE2Rq+whereEiis the ith element in Eands=Pb i=1Ei, then prove that His positive semi-de nite and since\u0010Pb i=1Ei\u00112 is a positive constant we will nd a decomposition H\u0010Pb i=1Ei\u00112 =RRTwhich proves His posi- tive 2)\u00022be every unique H=RRT (Pb i=1Ei)2, imply- thatHis itself positive RRTis nite and \u0010Pb i=1Ei\u00112 is a positive scalar. 54We have now proven that the Hessian matrix is positive semi-de nite. Theorem 13. Optimization Problem (3.6) is convex. Proof. The objective function of Optimization Problem (3.6) is a positive summation of functions f(\u0015;s;\u000e ) = log\u0010Pb i=1e\u0000\u0015TZd(s(i))\u0011 +\u0015TZd(\u000e) which have a positive semi- de nite Hessian matrix with respect to \u0015as proven in Lemma 12. Since positive sums of convex functions are convex Optimization Problem (3.6) is convex. To demonstrate the SEs with parameters optimized by solving the MLE problem, we will next model the distribution of a publicly available data set using Optimization Problem (3.9). Example 1 For this example we use the publicly available Iris [55] data set, D:= f\u000e(i)2R4g150 i=1. For reference, Fig. 3.1 shows a scatterplot of the Iris dataset after it has been scaled to t within a hyper-cube centered at 0 with side lengths of 1. We have selected the Iris dataset to use as an example since it is clearly multi-modal, and does not fall into any known distribution. In Fig. 3.2 we plot SE PDFs t to lower-dimensional subsets of the Iris dataset. Along the diagonal we plot the marginal PDFs of each variate \u000e1through\u000e4using degree 8 SEs. In each of the non-diagonal subplots we plot the SE PDFs describing two of the variates using degree 6 SEs. These plots show that low degree Sliced- Exponentials may model a wide variety of random variables. To show that SEs can characterize the multi-modal dependencies in higher dimen- sional data sets we train a fourth degree SE on the Iris data set. Using slice sampling we generate and plot 150 simulated data points from the trained SE in Fig. 3.3. For comparison the log likelihood value of a normal distribution t to this data is 596.4, compared to a log likelihood value of 725.8 for the SE. This is a signi cant increase 55Figure 3.1: Subplots along the jth diagonal element show a histogram of measured \u000ej data, while subplots corresponding to the jth and ith position show a scatterplot of measured data of \u000ejversus\u000eifor a rescaled version of the Iris dataset [55]. in the log likelihood of 19 :57%. Next we consider the WCE problem for generating optimal parameters \u0015. 3.2.3 A Convex Optimization Problem to Solve the Worst Case Estimation (WCE) Problem Optimizing the SE with respect to the worst case likelihood estimation yields SE PDFs whose sets enclose the data more tightly than SEs optimized by solving the maximum likelihood estimation problem. We rst formally de ne the WCE problem 56Figure 3.2: Sliced-Exponential PDFs t using Optimization Problem (3.10), subplots along the jth diagonal element show a Sliced-Exponential PDF of degree 8 t to measured\u000ejdata, while subplots corresponding to the jth and ith position show a Sliced-Exponential PDF of measured data of \u000ejversus\u000eiof the Iris dataset [55]. and show that we may nd the value of \u0015, for a given degree d, which maximizes the worst case likelihood on a set of data points, D, by solving a convex optimization problem. The selection of an optimal degree dcan be identi ed using cross-validation techniques such as those proposed later in Section 3.5.1. 57Figure 3.3: Plot of a rescaled version of the Iris dataset [55] (blue) and data sampled from the SE PDF (green) optimized using the solution of the MLE optimization problem. Subplots along the jth diagonal element show a histogram of the sampled \u000ejdata, while subplots corresponding to the jth and ith position show a scatterplot of sampled data of \u000ejversus\u000ei. Solving the WCE Optimization Problem for Sliced-Exponentials We rst derive the WCE problem with respect to the set of Sliced-Exponentials. We then de ne a convex optimization problem and show that it solves the MLE problem. The worst case likelihood of a model fon a given set of data D:=f\u000e(i)gm i=1is de ned 58as, Wf(D) = min i2f1;\u0001\u0001\u0001;mgf\u000e\u0000 \u000e(i)\u0001 ; and nding the model ffrom a set of models that maximizes Wf(D) is called the Worst Case Estimation (WCE) problem. For a support set \u0001, recall that the Sliced-Exponential PDF is de ned as, f\u000e(\u000e;\u0015) =8 >>< >>:e\u0000\u0015TZd(\u000e)\u0000log(c)if\u000e2\u0001 0 if \u000e =2\u0001:(3.15) Since there are no analytical solutions for the normalization constant of the PDF, we will use the Monte Carlo based numerical integration constant de ned in Eq. (3.8). The solution of the WCE problem for the SE set is the given by, \u0015WC:= argmax \u0015min i2f1;\u0001\u0001\u0001;mge\u0000\u0015TZd(\u000e(i))\u0000log( ~cb(\u0015;d;s )): (3.16) We may this constraint maximizes the worst case likelihood on the data inDas de ned in Eq. (3.16) for the degree dSE. 59-0.5 0 0.5 2-0.500.51 WCE MLE Data(a) Level sets of SE PDFs that contain all of the rst and second variates of the Iris data set where \u0015was optimized by solving the WCE (red) or the MLE (blue) optimization problem. -0.5 0 0.5 4-0.500.53 WCE MLE Data(b) Level sets of SE PDFs that contain all of the third and fourth variates of the Iris data set where \u0015was optimized by solving the WCE (red) or the MLE (blue) optimization problem. Figure 3.4: Level sets of SE PDFs t using Optimization Problem (3.19) that contain bi-variate subsets of the Iris data set (red) compared to level sets of the SE PDFs t using Optimization Problem (3.10) to the same data (blue). Therefore, solving the optimization problem, min t2R;\u00152Rq( \u0000tjt+ log bX i=1e\u0000\u0015TZd(s(i))! +\u0015TZd(\u000e(i))\u001408i2f1;\u0001\u0001\u0001;mg) ; (3.19) is equivalent to maximizing equation (3.17) minus the constant term log(v\u0001 b). Theorem 14. Optimization Problem (3.19) is convex. Proof. The objective function of Optimization Problem (3.6) is a\u000ene and thus convex. The function f(\u0015;s;\u000e ) +\u0015TZd(\u000e) has positive semi-de Hessian matrix with respect to \u0015as proven in Lemma 12 and is thus convex. Since pos- itive sums of convex functions constraint, t+log\u0010Pb i=1e\u0000\u0015TZd(s(i))\u0011 + \u0015TZd(\u000e(i))\u00140 is convex and Optimization Problem (3.6) is therefore a convex opti- mization problem. 60For any SE with PDF f\u000e, we de ne the level set of smallest volume that contains all of the points in Das, H :=f\u000ejf\u000e(\u000e;\u0015)\u0015 g; (3.20) for =Wf\u000e(D). For any value of 2R+,H :=f\u000ejf\u000e(\u000e;\u0015)\u0015 gis de ned by a polynomial inequality and is thus a semi-algebraic set. This can be seen with the following 0\u0014log(f\u000e(\u000e;\u0015))\u0000log( )\u0014\u0000\u0015TZd(\u000e)\u0000log(c)\u0000log( )\u0014\u0000\u0015TZd(\u000e)\u0000\u0014; semi-algebraic set f\u000ej\u0000\u0015TZd(\u000e)\u0000\u0014\u0015 0g. To demonstrate the advantages of the SEs optimized by solving the WCE using Optimization Problem (3.19) we will analyze the data-enclosing level sets of the SE t to a publicly available data set. Example 2 For this example we also use the publicly available Iris [55] data set, D:=f\u000e(i)2R4g150 i=1. For reference, Fig. 3.1 shows a scatterplot of the Iris dataset after it has been scaled to t within a hyper-cube centered at 0 with side lengths of 1. In Fig. 3.4 we plot the level set HWf\u000e(D), which is the set of minimal volume that contains all of the Iris dataset, for SEs optimized by solving the MLE and WCE optimization problem. Fig. 3.4 shows the bi-variate PDFs of the ML SEs corresponding to the ith and jth parameters. Recall that as in Fig. 3.2 these sets correspond to lower-dimensional subsets of the iris data set. Notice that the data- enclosing set for a four dimensional SE can't be shown in the same format. However, uniformly distributed samples over such a set are shown in gure 3.5. 61Figure 3.5: Plot of a rescaled version of the Iris dataset [55] (blue) and data uni- formly sampled from the level set HWf\u000e(D)of an SE PDF (green) optimized by solv- ing the WCE optimization problem. Subplots along the jth diagonal element show a histogram of the sampled \u000ejdata, while subplots corresponding to the jth and ith position show a scatterplot of sampled data of \u000ejversus\u000ei. We calculated the volume of the minimum volume ellipsoid that contains the Iris data to be 0.0164, whereas the volume of the sliced-exponential level set is 0.0036. This implies that the volume of the sliced-exponential level set was 128% less than volume of the minimum volume ellipsoid. The level sets of SE PDFs can be used with polynomial optimization methods such as sum-of-squares optimization [131, 123] to carry out formal robustness analysis and 62optimization, such as the polynomial level sets used in [50, 25]. In addition, the reliability of such sets, which bound the probability of future samples drawn from the same DGM falling within the set, can be assessed using scenario theory as in [41]. We perform a numerical analysis of the e ect of the number of samples used to calculate the numerical integration constant, and the e ect of increasing the number of samples or dimension of Don the solution to the MLE and WCE problems in Appendix A.1. Next we consider a closely related set of sliced distributions called sliced-normals. 3.3 Sliced-Normal Distributions Here we de ne a subset of Sliced Distributions called the Sliced-Normal (SN) distribution. As in the previous section we rst prove that the set of Sliced-Normal distributions is dense in the set of all bounded PDFs F\u0001. Unfortunately for an equivalent degree, SNs have more parameters than SEs and are thus more expensive to t to data. Therefore we propose solving optimiza- tion problems closely related to the MLE and WCE optimization problems that have a signi cantly reduced computational complexity when compared to the Sliced- Exponential MLE and WCE optimization problems. In the feature space Sliced-Normal Distributions are multivariate normal distri- butions where the returns the monomial basis of \u000e. Speci cally is the positive de nite precision matrix, 63and the set of SN distributions is, FN:=fp(d) SN(\u000e)jd2Ng: (3.22) The SN distributions di er from the SE distributions in that the polynomial ar- gument is a sum-of-squares polynomial and is thus globally positive. Sum-of-squares polynomials have more parameters than the polynomial parameterization used with SEs. 3.3.1 Properties of Sliced-Normals In this subsection we show that the SN set is dense in the set of all bounded PDFs F\u0001. We begin by showing that for any SE distribution we may nd an equivalent SN distribution on \u0001. Therefore the set of SN distributions must, like the set of SE distributions, be dense in F\u0001. Lemma 15. For any polynomial function, p(\u000e)and\u000f > 0there exists a sum-of- squares polynomial since polynomials are bounded on compact sets. Then we \u0001, and the set of SOS polynomials is dense in the set of nonnegative polynomials on any compact 64set [97]. Therefore there exists an SOS polynomial q(\u000e) such that q(\u000e) =f(\u000e) =p(\u000e) for all\u000e2\u0001 that Z 1 cpep(\u000e)\u00001 cqeq(\u000e) d\u000e<\u000f Therefore on any compact \u0001 the SN distributions is dense in the set of SE distri- butions. Lemma 16. The set of SN the set of bounded PDFs F\u0001. Proof. From Lemma 15 we have that the set of sliced-normal PDFs N\u0001are dense in the set of sliced-exponential PDFs E\u0001and from Theorem 11 we have that the set of sliced-exponentials is dense in F\u0001. While both the SE and SN sets are dense in F\u0001, the set of degree bounded SEs has fewer decision variables for a given degree dpolynomial. Therefore when solving the MLE and WLE optimization problems exactly it is more computationally e\u000ecient to solve these problems using the SE set. However, there exist a number of computationally e\u000ecient solutions for nding SNs using metrics related to the MLE and WLE problems that cannot be applied to the set of SEs. These solutions often result in comparable models but at signi cantly less computational expense. 3.4 E\u000ecient Modeling Approaches using Approximate Solutions The MLE and WLE optimization problems in the physical space for the SN and SE distributions can be computationally expensive to solve. This is primarily due to the Monte Carlo sampling method which might require millions of samples to accurately compute the normalization constant for each computation of the gradient, 65hessian or objective value. We next develop computationally inexpensive methods by solving the MLE optimization problem in feature space. 3.4.1 Solving the MLE Optimization Problem in Feature Space In feature space an SN PDF is equivalent to a normal PDF where there are analytical solutions for the mean, \u0016and precision matrix Pand thus Monte Carlo sampling is not required to optimize these parameters. Speci cally, the MLE optimization problem in feature space is formulated as max P2Rq\u0002q;\u00162Rq8 < :logY \u000e2De\u0000(Zd(\u000e)\u0000\u0016)TP(Zd(\u000e)\u0000\u0016) 2 (2\u0019)q=2p det(P\u00001):P\u001709 = ;; (3.23) because a SN distribution is a multivariate normal distribution in the feature space and the normalization constant for a multivariate Gaussian is c= (2\u0019)q=2p det(P\u00001). This optimization problem is a special case of optimization problems of the form max P2Rq\u0002q;\u00162Rq8 < :logmY i=1e\u0000(hi\u0000\u0016)TP(hi\u0000\u0016) 2 cp det(P\u00001):P\u001709 = ;: (3.24) Such optimization problems admit an analytic solution, as can be found in, e.g. [67]. Speci cally, for given fhig, we have mean and Pis the empirical preci- sion matrix of the data in feature space. Unfortunately the optimal P\u0003and\u0016\u0003selected by optimizing a multivariate Gaus- sian distribution in the feature space may have a poor likelihood value in the physical space. Thus we next consider a second method to improve the SN parameters to increase the likelihood of the data. 663.4.2 Rescaling the Feature Space Precision Matrix In this section, we propose a convex optimization problem that maximizes the likelihood of the SN for a given data sequence by scaling the suboptimal precision matrixPobtained in the prior subsection. In this case, we assume that a degree d has been selected and we are given previously selected values of the hyperparameters P\u00032Rq\u0002qand\u0016\u00032Rq, presumably found using Optimization Problem (3.23). We now consider SN `candidates' of support set of the SN, and is the rescaling factor. This distribution can be cast as a SE distribution where the monomial basis has been replaced with a polynomial function B(\u000e) =1 2(Zd(\u000e)\u0000\u0016\u0003)TP\u0003(Zd(\u000e)\u0000\u0016\u0003) thus implying \u00152Rand this problem can be solved using the SE optimization methods de ned in Section 3.2. Since there is only one scalar decision variable, this problem is computationally inexpensive compared to using a larger monomial basis such as in the full set of SN or SE distributions. If \u0003>0, we have that P\u0003is still positive de nite, thus making the polynomial a sum of squares polynomial and the distribution a SN distribution. To demonstrate the SNs with parameters optimized by rescaling the MLE optimal feature space solution, we will next model the distribution of a publicly available data set using Optimization Problem (3.25). Example 3 For this example we use the publicly available Iris [55] data set, D:= f\u000e(i)2R4g150 i=1. For reference, Fig. 3.1 shows a scatterplot of the Iris dataset after it 67Figure 3.6: Plot of a rescaled version of the Iris dataset [55] (blue) and data sampled from the SN PDF (green) optimized using the rescaled precision matrix. Subplots along the jth diagonal element show a histogram of the sampled \u000ejdata, while subplots corresponding to the jth and ith position show a scatterplot of sampled data of \u000ej versus\u000ei. has been scaled to t within a hyper-cube centered at 0 with side lengths of 1. We have selected the Iris dataset to use as an example since it is clearly multi-modal, and does not fall into any known distribution. To show that SNs can characterize the multi-modal dependencies in higher dimen- sional data sets we train a fourth degree SN on the Iris data set. Using slice sampling we generate and plot 150 simulated data points from the trained SN in Fig. 3.6. For 68comparison the log likelihood value of a normal distribution t to this data is 596.4, compared to a log likelihood value of 875.7 for the SN. This is a signi cant increase in the log likelihood of 37 :94%. We next consider approximate solutions to the WLE optimization problem. 3.4.3 Solving the WCE Optimization Problem in Feature Space We may also compute approximate solutions to the WLE optimization problem for the set of SN distributions. First we will show that the WLE optimization problem for the set of degree 1 SN distributions is identical to the minimum volume ellipsoid problem as de ned in [162, 161]. Then we use the solution of the minimum volume ellipsoid problem in the feature space to e\u000eciently render SNs that are optimal in the feature space as an alternative to solving the computationally expensive WCE problem for SEs. The minimum volume ellipsoid problem can be formulated as the following opti- mization [162], > 0: Optimization Problem (3.26) can be solved e\u000eciently even for cases where the number of pointsm > 100;000 andn > 50 using methods from [161]. Note that, since the volume of the ellipse is not related to the rst column and row of Man equivalent optimization problem is given by, min M2Rq\u0002q\u0000log(detM2:q;2:q) (3.27) such Mwithout the rst row and column. 69The solution to the WLE optimization problem in feature space on the other hand is given by, P\u0003;Q\u0003= arg max P2Rq\u0002q;Q2Rq+1\u0002q+1\b logjPj\u0000 :zT iQzi\u0014 By a change of variable R=q Q, we have that the objective function of the WLE optimization problem in feature space can be formulated as, \u0000logjQ2:q;2:qj+ =\u0000log qq jRj+ =\u0000log qq jR2:q;2:qj+ =\u0000(q) log( ) + (q) log(q)\u0000log(jR2:q;2:qj) + ; and the constraint can be formulated as, zT iRzi\u0014q: Since is unconstrained we nd that \u0003=1 R\u00170 ; (3.29) which is identical to the minimum volume ellipsoid problem. Thus, if we solve the minimum volume ellipsoid problem with the data, zi, we may recover the solution to the WLE optimization problem for a SN. Let R\u0003be the solution to the minimum volume ellipsoid problem and we may recover the solution to Optimization Prob- lem (3.28) as Q\u0003:=R\u0003 q2. E\u000ecient for the minimum volume ellipsoid prob- lem such as those de ned in [161], can therefore be used to nd suboptimal solutions to the WLE optimization problem for SNs. 70Figure 3.7: Plot of a rescaled version of the Iris dataset [55] (blue) and data uniformly sampled from the level set HWf\u000e(D)of an SN PDF (green) optimized by solving the WCE optimization problem in feature space. Subplots along the jth diagonal element show a histogram of the sampled \u000ejdata, while subplots corresponding to the jth and ith position show a scatterplot of sampled data of \u000ejversus\u000ei. Example 4 For this example we also use the publicly available Iris [55] data set, D:=f\u000e(i)2R4g150 i=1. For reference, Fig. 3.1 shows a scatterplot of the Iris dataset after it has been scaled to t within a hyper-cube centered at 0 with side lengths of 1. To demonstrate the WLE method for SNs, we generate an optimal SN model by solving the WLE optimization problem in feature space. We then plot uniformly dis- tributed samples over the level set of minimal volume, HWf\u000e(D), using sliced sampling 71in Fig. 3.7. The volume of the minimum volume ellipsoid that contains the Iris data is 0.0164, whereas the volume of the level set of the sliced-normal is 0.0013. This implies that the volume of the sliced-normal level set was 170% less than the volume of the minimum volume ellipsoid. Next we compare SDs to other distributions by modeling the distribution of a set of publicly available data sets and examining their performance on a test partition of the data. 3.5 Numerical Results of SD Optimization First we compare the SDs to the sets of Gaussians and Gaussian mixture models. Then we apply the SDs to the problem of identifying cell populations that most di er between patients with, and without Rheumatoid Arthritis. By identifying the populations that di er the most between the two types of patients we will identify cell populations that are potentially correlated to the disease. 3.5.1 Numerical Accuracy of SD Optimization In this subsection we will use the MLE and WCE optimization problems to nd optimal SE and SN random variables that model the uncertainty in publicly available data sets. We use a separate set of testing points to compare the accuracy of the SD random variables to the set of Gaussian random variables and the set of Gaussian mixture models. Methodology: Speci cally we partition the data into a training, validation, and testing data partition. Some methods have regularization parameters that can be used to increase the generalization of the algorithm and avoid over tting. For these 72Table 3.1: The log likelihood (LL) of the uncertainty models on the test partition data points and the computation time (T) for the MLE MN, EM GMM, MLE SE, and WCE SE implementations. The data sets have dimension (n) and number of training data points (m). Dataset Model LL Time (s) VOS MLE MN is used to select the regularization parameter, and then the method is retrained (with the selected regularization parameter) using the training and validation partition. Model performance is then analyzed on the testing partition of the data. We use the following data sets. 73Data: In this section we use the data sets, VOS ,TV1,BP, andIRas can be found in [128, 119, 83, 55] in the UCI machine learning or OpenML databases. To compare the proposed SEs and SNs to other methods we use the following implementations. We repeat all tests 5 times with di erent partitions of the training, validation, and test partitions and report the average and standard deviations of all values. [MLE SE] The MLE optimization problem (Optimization Problem (3.6)) is used to select the optimal \u0015parameter of the SE. We use cross-validation to select the degree of the SE random variable which generated the largest likelihood on the validation partition of the data; [FS MLE SN] The Feature Space (FS) based MLE optimization problem (Optimiza- tion Problem (3.25)) is used to select the suboptimal rescaled Pand\u0016parameters of the SN. Optimal SNs can also be found using the techniques in [41], but will have a larger computation time than an MLE SE of the same degree and is thus omitted. We use cross-validation to select the degree of the SN random variable which generated the largest likelihood on the validation partition of the data; [WCE SE] The WCE optimization problem (Optimization Problem (3.6)) is used to select the optimal \u0015parameter of the SE. We use cross-validation to select the degree of the SE random variable which generated the largest worst case likelihood on the validation partition of the data; [FS WCE SN] The Feature Space (FS) WCE optimization problem (Optimization Problem (3.28)) is used to select the optimal \u0016andPparameters of the SN. We use cross-validation to select the degree of the SN random variable which generated the 1The data set TVoriginally contains data points with more than two dimensions, however, we extract the time of day and tra\u000ec volume from the original data (the real valued variables) to create our two dimensional data set. 74largest worst case likelihood on the validation partition of the data; [MLE MN] The MLE optimization problem is solved to optimize the mean and covariance matrix of a multivariate normal random variable as in [51]. In this case no regularization parameters were used, however to ensure a fair comparison between methods the normalization constant is computed using the same Monte Carlo samples as are used in the SE and SN cases; [EM GMM] The expectation-maximization problem is solved to optimize the mean and covariance matrix of a mixture of kmultivariate normal random variables. We use,k, the number of multivariate normal distributions as a regularization parameter and selectk2f1;\u0001\u0001\u0001;30gwhich had the largest likelihood on the validation partition of the data. As in the MLE MN case we ensure a fair comparison between methods by computing the normalization constant using the same Monte Carlo samples as are used in the SE and SN cases. Maximum Likelihood Comparison First we analyze the di erence in likelihood of the models with respect to the test data partition. A larger likelihood value on the test partition implies that the model is a better t for the data. In Table 3.1 we compare the performance of the MLE SE, MLE SN, MLE MN, and EM GMM imple- mentations on the test partition set. We report the likelihood on the test partition and the computation time in Table 3.1. In all cases the MLE SE model has a higher likelihood on the test partition than all other implementations. This implies that in all cases the MLE SE model was more likely to have generated the data in the test partition than the other models. The FS-MLE SN implementation was second best in all cases but the Iris data set and was faster than the MLE SE implementation. In cases with greater numbers of data points and higher dimensional problems the FS-MLE SN is more computationally 75Table 3.2: The volume (V) of the level sets of the uncertainty models containing all of the test partition data points and the computation time (T) for the MLE MN, EM GMM, MLE SE, MLE SN, WCE SN and WCE SE implementations. The data sets have dimension (n) and number of training data points (m). Dataset Model V Time (s) TV MLE MN the MLE SE implementation. Worst Case Set Comparison We next train each algorithm on the training par- tition of the TV,BPandIRdata sets and analyze the volume of the level sets that contain all of the test data partition. If we let Dtbe the testing partition, then in Table 3.2 we report the volume of the sets HWf\u000e(Dt)and the computation time for each algorithm. The level set of minimal volume which contained the testing partition of data had the smallest volume when modeled using the WCE SE algorithm in all cases but 76the Iris data set where the SN FS-WCE implementation was slightly better. This implies that the WCE SE algorithm most tightly enclosed the data in almost every case, and generalized well to new data points. The time taken to generate the set of minimal volume was longest for the WCE optimization problem. The FS-WCE SN implementation performed well on all but the BP data set, where it was outperformed by all but the MLE MN implementation. However, when compared to the SE WCE implementation, the SN FS-WCE was signi cantly faster while o ering comparable performance in some cases. This makes the SN FS-WCE a good rst choice for generating tightly enclosing sets, while the SE WCE implementation can be used for generating tighter enclosing sets but at a greater computational cost. 3.5.2 Applications of SDs to a Mass Cytometry Dataset In this subsection we use a Sequential Forward Selection (SFS) algorithm to iden- tify immune cell characteristics that di er the most between the average patient with rheumatoid arthritis and an average healthy patients using a publicly available mass cytometry dataset. The Immune Dataset The mass cytometry dataset consists of 5 samples of immune system cells taken from healthy patients and 9 samples of immune system cells taken from RA patients. This data was taken from the owrepository [] and the methods of data collection are described in []. We analyze a group of 5 healthy patients Hk=fhk i2[0;1]41gmk h i=1which contains P5 k=1mk h= 1;251;491 total cell measurements and a second group of 9 RA patients Rk=frk i2[0;1]41gmk 77A Metric of Similarity We treat all of the measured samples in HandRas random variables generated by healthy patients and those with RA. To analyze the mass cytometry data from both populations we will model the random variables as sliced-exponentials to generate SE models for the healthy and RA patients respectively. As in the de nition of density between two sets of PDFs we use the squared Hellinger distance as a metric of distance between PDFs. If d2 H(f;g) = 0, then the PDFsfandgare identical on \u0001, whereas larger values indicate a larger distance between the PDFs. Given a possible set of feature indices F:=f1;\u0001\u0001\u0001;ng, we de ne the set of partitions of FasP(F), and the set of all possible partitions of Fof lengthw\u0014n as follows. Bw:=fv2Nwjv2P(F)g For a given selection of features, b2Bw, we denote the associated projection Pb: Rn!Rwso that (Pb(\u000e))i=\u000ebifor\u000e2Rnandi= 1;\u0001\u0001\u0001;w. Suppose we let f(H) Pb(\u000e)be a model of the distribution of the bfeatures in\u000efor the healthy population of patients andf(R) Pb(\u000e)be a model of the distribution of the bfeatures in \u000efor the population of patients with RA. Then, if we restrict the search to wfeatures, the solution to the following combinatoric optimization problem returns the features, b, which vary the most between the healthy and RA patient populations. max b2Bwd2 H(f(H) Pb(\u000e);f(R) Pb(\u000e)) (3.30) As in Chapter 4 we will use a Sequential Feature Selection (SFS) algorithm as described in [20] to perform feature selection to solve Optimization Problem (3.30). SFS algorithms begin with an empty (or full) set of features and sequentially add (or 78(a) Dot plot of CD66b and CD11b recep- tors measured using mass cytometry for healthy patients. (b) Dot plot of CD66b and CD11b recep- tors measured using mass cytometry for patients with RA. Figure 3.8: Dot plot of CD66b and CD11b receptors measured using mass cytometry for healthy patients (a) and patients with RA (b). remove) the highest value (or cost) feature until the set of features is a certain size or meets a performance metric. The SFS algorithm used in this paper is as described in [42]. This SFS algorithm begins with b:=;, and iteratively selects a locally optimal feature (with respect to the objective function of Optimization Problem (3.30)) at each step. Results: We solve Optimization Problem (3.30) using the SFS algorithm as described in [20] using sliced-exponential models of degree one through ve to model the PDFs of the healthy and diseased cells. We select w= 3 to limit the search to the top three most important cellular characteristics. To determine which degree of sliced-exponential best captures the di erence be- tween cells from healthy patients and those with RA, we will analyze how well the two models can be used to di erentiate between RA and healthy patients. Letf(H)andf(R)be sliced-exponential models of the healthy patient data in H 79Table 3.3: The leave-one-out classi cation accuracy AL(H;R) of predicting whether a patient has RA or does not have RA using varying degree SE models of immune system cells from healthy patients and RA patients. SE Degree 1 2 3 4 5 AL(H;R)85:71% 78:57% 78:57% 92:86% 92:86% and RA patient data in Rrespectively. Given a set of data, Dfrom a new patient we will use the likelihood of both models on the data to determine if the patient is healthy or has RA. Speci cally, if Lf(H)(D)>Lf(R)(D) then the patient is predicted to be healthy, otherwise they are predicted to have RA. To estimate the predictive accuracy of the sliced-exponential models on new data we will use the leave-one-out classi cation accuracy. Let, f(H;k)andf(R;k)be the models of the healthy patient data and RA patient data - excluding for the k'th patient in that set. Let I(x) be an indicator function that is equal to one if x > 0 and zero otherwise and the leave-one-out classi cation error can then be is the accuracy of predicting whether a patient in the training data set is healthy or has RA using the healthy and RA models when they are trained without that patients data. This is a better estimate of the predictive accuracy for future patients whose data was not used to train the models. We show the leave-one-out classi cation accuracy for varying degrees of sliced- exponential models in Table 3.3. The best leave-one-out classi cation accuracy was generated by the degree four and ve sliced-exponentials which both achieved an accuracy of 92 :86% after misidentifying one healthy patient as having RA. This anal- ysis shows that more complex models than exponential or normal distributions are required to e ectively model the di erences in the densities of the average healthy 80(a) Sliced-Exponential PDF of healthy immune system cells with CD66b and CD11b measured using mass cytometry. (b) Sliced-Exponential PDF of RA im- mune system cells with CD66b and CD11b measured using mass cytometry. Figure 3.9: Sliced-Exponential PDF of healthy immune system cells (a) and RA immune system cells (b) with CD66b and CD11b measured using mass cytometry. patient and the average RA patient. Given equal performance between two models, it is good practice to select the least complex model. Therefore we will further analyze the degree four sliced-exponential model. The three cell characteristics that most di er between the healthy and diseased populations (based on the degree 4 sliced-exponential models) consist of the CD66b, CD11b and CD23 receptors. We show a dot plot of the cellular measurements taken from healthy and RA patients for the rst two receptors in Fig. 3.8(a) and 3.8(b). To demonstrate that the populations of cells have complex densities (necessitat- ing the use of SEs or other complex distributions) we show the joint PDFs of the sliced-exponential model for the rst two receptors of the healthy and RA patients in Fig. 3.9. The complex bimodal density of the cellular characteristics captured by the degree 4 sliced-exponential is what makes the leave-one-out classi cation accuracy higher than the lower degree sliced-exponential models. Further testing is necessary to determine a more accurate estimate of the predictive 81accuracy of this model. Furthermore, collecting mass cytometry data from patients with other autoimmune diseases is necessary to determine if the models can di er- entiate between patients with RA and other autoimmune diseases, or if the models are capturing densities of cell populations that may be similar in other autoimmune diseases. 3.6 Conclusion This chapter proposes convex optimization problems to select optimal parameters of sliced distributions that solve the MLE and WCE optimization problems to model the distribution of given data. We showed that two sets of SD PDFs are dense in the set of all bounded PDFs with respect to the Hellinger distance. The developments herein allow for the e\u000ecient characterization of the distribution of data. We use two metrics to demonstrate that the proposed methods, based on Sliced Distributions, have superior performance with respect to modeling the distribution of data when compared to Gaussian mixture models and multivariate normal models. The rst metric is based on the likelihood of the models to generate a test partition of the data, while the second is based on the volume of the level sets of the model PDFs that most tightly contain the test partition of the data. The models optimized with respect to the maximum likelihood metric are superior with respect to the rst metric, while those optimized with respect to the worst case likelihood metric are superior in the second metric. Furthermore we show that SDs may be used to model mass cytometry data of the average healthy patient and the average RA patient. By comparing the models generated for each group, we identi ed a set of immune system characteristics whose PDF models di ered most between healthy patients and those with RA. These models can di erentiate between mass cytometry datasets taken from healthy and RA pa- 82tients with high accuracy, illustrating that the models captured important di erences in the immune system cells between the two groups. However, further testing with larger datasets is necessary to more accurately determine the predictive accuracy of the proposed models. 83Chapter 4 MACHINE LEARNING WITH POSITIVE KERNELS PARAMETERIZED BY POSITIVE MATRICES There exists hundreds of di erent subpopulations of immune cells and cytokine signals which could potentially be classi ed as either helper [165, 105] or regula- tory [138, 90]. Analyzing data to determine which of these potential cells and signals is most relevant to the immunogenic or tolerogenic responses to antigen requires so- phisticated machine learning methods. One such state of the art class of machine learning algorithms is the class of kernel methods. Kernel methods are a class of machine learning algorithm (the most relevant to this chapter being the support vector machine) that return a function, f2F, designed to map a set of inputs to corresponding outputs. Speci cally kernel methods can be used on problems such as classi cation, regression and the clustering of data. The set of functions,F, from which the kernel method may select a function is dependent on the selection of some a priori selected kernel function. Therefore, the selection of a kernel function determines the class of functions that can be searched over, directly a ecting the accuracy of the learned map from the inputs to outputs. Kernel Learning (KL) algorithms such as those found in [171, 149, 172] automate this task by nding the kernel, k2K which optimizes an achievable metric such as the soft margin (for classi cation). The set of kernels, k2K, over which the algorithm can optimize, however, strongly in uences the performance of the resulting classi er or predictor. To understand how the choice of Kin uences performance and robustness, we pro- pose three properties to characterize the set K- tractability, density, and universality. 84Speci cally,Kis tractable ifKis convex (or, preferably, a linear variety) - implying the KL problem is solvable using, e.g. the algorithms in [134, 78, 96, 132, 66]. The set Khas the density property if, for any \u000f>0 and any positive kernel, k\u0003there exists a k2K wherekk\u0000k\u0003k\u0014\u000f. The density property implies the kernel generalizes well implying good performance on untrained data. The set Khas the universal property if anyk2K is universal (see De nition 17) - ensuring a classi er/predictor exists that maps each unique training input to its corresponding output using any kernel function inK. Previously, there was no class of kernel that meets all three criteria - e.g. Gaus- sians are not tractable or accurate; polynomials are not scalable. Therefore we have proposed a new class that meet all three criteria - the Tessellated Kernel (TK) class. Speci cally, the TK class: admits a linear parameterization using positive matrices; is dense in all kernels; and every element in the class is universal. This implies that the use of TK kernels for learning the kernel can obviate the need for selecting can- didate kernels in other Kernel Learning (KL) algorithms or parameters such as the bandwidth of the Gaussian kernel. Numerical testing on soft margin Support Vector Machine (SVM) problems show that algorithms using TK kernels outperform other kernel learning algorithms, neural networks, and random forest algorithms. Finally we apply KL with TKLs to the problem of identifying immune system cells in an animal model that are correlated to the immune state of mice with Rheumatoid Arthritis. Given a set of immune system populations, this analysis identi es the key populations that are correlated to the disease severity and progression of the disease. 4.1 Introduction to Kernel Learning This chapter addresses the problem of the automated selection of an optimal kernel function for a given kernel-based machine learning problem (e.g. soft margin SVM). 85Kernel functions implicitly de ne a linear parametrization candidate mapsy=f(x) from vectors xto for a given kernel, the `kernel trick' allows optimization over a set of candidate functions in the kernel-associated hy- pothesis space without explicit representation of the space itself. The kernel selection process, then, is critical for determining the class of hypothesis functions and, as a result, is a well-studied topic with common kernels including polynomials, Gaussians, and many variations of the Radial Basis Function. In addition, specialized kernels include string kernel selection process heavily in uences the accuracy of the resulting t and hence signi cant research has gone into the optimization of these kernel functions in order to select the hypothesis space which most accurately represents the underlying physical process. Recently, there have been a number of proposed kernel learning algorithms. For support vector machines, the methods proposed in this chapter are heavily in uenced by the SDP approach proposed in [96] which directly imposed kernel matrix positiv- ity on a subspace de ned by the linear combination of candidate kernel functions. There have been several extensions of the SDP approach, including the hyperker- nel method in [120]. However, because of the complexity of semide nite program- ming, more recent work has focused on alignment methods for MKL as in, e.g. [39] or gradient methods for convex and non-convex parameterizations of positive linear combinations of candidate kernels, such as SimpleMKL [134] or the several varia- tions in SHOGUN [149]. MKL methods rely on kernel operations (addition, multiplication, convolution) to generate large numbers of parameterized kernel func- in and regularization includes the group sparsity metric [155] and the enclosing ball approach [58]. See, e.g. [66] for a comprehensive review of 86MKL algorithms. In this chapter, we focus on the class of \\Universal Kernels\" formalized in [109]. For a given compact metric space (input space), X, it is said that a function k: X\u0002X! Ris a Positive Kernel (PK) if for any N2Nand anyfxigN i=1\u001aX, the matrix de ned elementwise by Kij=k(xi;xj) is symmetric and Positive SemiDe nite (PSD). De nition 17. A kernelk:X\u0002X ! Ris said to be universal on the compact metric spaceXif it is continuous and there exists an inner-product space Wand feature map, \b :X !W such thatk(x;y) =h\b(x);\b(y)iWand where any given PD kernel, the RKHS Hexists, is unique, and can be char- acterized (as described in [157]) using the Riesz representation theorem as the closure of spanfk(y;\u0001) :y2Xg with inner product ned are preferred when large amounts of data are available, due to the fact that the dimension of the hypothesis space increases for every additional data point - resulting in the ability to construct highly specialized and accurate classi ers. The most well-known example of a universal kernel is the Gaussian (generalized in [174]). However, many other common kernels are not universal, including, sig- ni cantly, the polynomial class of kernels. This is signi cant because the class of 87generalized polynomial kernels (Eq. (4.9)) have the density and tractability prop- erty, while the set of Gaussian kernels have the universality property but not the tractability property. The Class of Tessellated Kernels (TK) We proposed the class of kernel func- tions (called Tessellated Kernels) which are not polynomials, yet which are de ned by polynomials and admit a linear parametrization in [29]. These kernels de ne classi- ers on a tessellated domain, each sub-domain (or tile) of which is a hyper-rectangle with vertices de ned by the input data -fxigm i=1. In this way, each data point further divides any tiles within which any of its features lie, resulting in increasing numbers of disjoint tiles. The classi er itself, then, is piecewise polynomial - being polynomial when restricted to any particular tile. TK kernels have three important properties which make them uniquely well-suited for kernel learning problems. First, these kernels admit a linear parameterization us- ing positive semide nite matrices - meaning we can use convex optimization to search over the entire class of such kernels (tractability), which is proven in Corollary 28 and implemented in Optimization Problem (4.23). This is like the class of generalized polynomial kernels (See Eq. (4.9)) yet unlike other universal kernel classes such as the Gaussian/RBF, wherein the bandwidth parameter appears in the exponential. Second, the TK class is dense in all kernels (accuracy), meaning there exists a TK kernel that can approximate any given kernel arbitrarily well. This is like the gen- eralized polynomial class yet unlike the Gaussian/RBF class, wherein the resulting kernel matrix is restricted to having all positive elements. Third, any kernel of the TK class has the universal property (scalability). This is like the Gaussian/RBF class and unlike the generalized polynomial kernels, none of which are universal. The TK class is thus unique in that no other currently known class of kernel functions has all 88three properties of tractability, accuracy, and scalability. 4.1.1 Kernel Learning for Classi cation and Regression We rst present two standard algorithms for solving the kernel learning problem for both classi cation and regression. These algorithms are general in the sense that they apply to any given linear parameterization of kernel functions. The Kernel Function: To nd nonlinear models using SVMs we must introduce a positive kernel function, k. De nition 18. We say a function k:Y\u0002Y!Ris apositive kernel function if Z YZ Yf(x)k(x;y)f(y)dxdy\u00150 for any function f2L2[Y]. Recall from Chapter 2 that applying a kernel function to the 1-norm soft margin SVM problem yields the optimization problem a to the \u000f-SVR Problem yields the dual formu- lation in and 2.15 require that the kernel function, k(x;y), be chosen a priori, a choice which signi cantly in uences the accuracy of the resulting classi er f. Next we alter the optimization problem by considering the kernel itself to be an optimization variable, constrained to lie in a given convex set of candidate positive kernel functions, K. The Kernel-learning Problem (1-norm SVM): Since Optimization Problems 2.12 and 2.15 are the dual of the SVM/SVR opti- mization problems, we want to select the kernel function k2K that minimizes the objective function of the dual. For the 1-norm soft margin SVM, when the kernel itself is parameterized as an optimization variable we therefore have the following convex optimization problem. case of the \u000f-SVR optimization problem the KL problem is given as the following convex the kernel learning problems, we now present two standard approaches to parameterizing the set of candidate kernels, K, and solving the resulting convex optimization problem. 904.1.2 SDP-based kernel learning using positive kernel matrices We rst consider the method in [96], for the 1-norm soft margin SVM wherein positive matrices were used to parameterize Kfor training points of the SVM problem and the kiwere chosen a priori to be, for instance, Gaussian and polynomial kernels. It is signi cant to note that the PSD constraint on the kernel matrix K, enforces that the kernel matrix is PSD for the set of training data, but does not necessarily enforce that the kernel function itself is PD - meaning that kernels in Kare not necessarily positive kernels. Using this parameterized K, the kernel optimization problem for the 1-norm soft margin support vector machine was formulated in [96] as the following semi-de nite program, where eis the vector of all ones. \u00162Rl; original constraint K\u00150 inKhas been replaced by an equivalent constraint on G. This problem can now be solved using well-developed interior-point methods as in [3] with implementations such as MOSEK in [4]. We next consider the method of [114], for the \u000f-SVR problem wherein, like the 91method in [96], a linear combination of positive matrices were used to parameterize K. Using this parameterization of K, the kernel optimization problem for the \u000f-SVR problem, as formulated in [114], is as follows, where again eis the vector of (4.4) and (4.5), the size of the SDP constraint is ( m+ 1)\u0002(m+ 1) which is problematic in that the complexity of the resulting SDP grows as a polynomial in the number of training data. Methods that do not require this large semi-de nite matrix constraint are explored next. 4.1.3 Minimax Kernel Learning In this subsection, we again take a set of basis kernels fkigl i=1and consider the set of positive linear combinations, K:=( k:k(x;y) =lX i=1\u0016iki(x;y); \u0016i\u00150) : (4.6) Any element of this set is a positive kernel, replacing the matrix positivity constraint by a LP constraint. For classi cation the Kernel Learning problem in minimax form Kernel Learning problem in minimax form is as these formulations is generally referred to as Multiple Kernel Learning (MKL) and is solved directly in the minimax formulation rather than as an SDP in [96, 114]. These formulations are an LP minimization problem in \u0016for xed and a QP maximization problem in for xed\u0016. Recently, a number of highly e\u000ecient two-step methods have been proposed which exploit this formulation, includ- ing SimpleMK [134]. These methods alternate between xing \u0016and optimizing , then xing and optimizing \u0016, adding the constraint thatP i\u0016i= 1 using a pro- jected gradient descent. Other two-step solvers include [66]. Two-step MKL solvers typically have a signi cantly reduced computational complexity compared with SDP- based approaches and can typically handle thousands of data points and thousands of basis kernels. In Section 4.4 and 4.5 we apply the SDP and the minimax approach respectively to the problem of Kernel Learning with Tessellated Kernels. 4.2 Positive matrices parameterize positive kernels The methods proposed in the prior section generally require the kernel function to be a positive summation, or sometimes a positive product, of a priori selected kernel functions. In this section we review a new framework for using positive matrices to parameterize positive kernels that we rst proposed in [29]. This is a generalization of a result initially proposed in [135]. In Subsection 4.2.1 we apply this framework to obtain generalized polynomial kernels. In Subsection 4.2.2, we use the framework to obtain the TK class. 93Proposition 19. LetNbe any bounded measurable function matrix P\u00150. Then k(x;y) =Z XN(z;x)TPN(z;y)dz (4.7) is a positive kernel function. Proof. SinceNis bounded and measurable, k(x;y) is bounded and measurable. Since P\u00150, there exists P1 2such thatP= (P1 2)TP1 2. any be the vector of monomials of degree d. If we now de ne NP(z;y) =Qd(y), thenkas de ned in Proposition 19 is a polynomial of degree 2d. The following result is from [127]. Lemma 20. A polynomial kof degree 2dis a positive polynomial kernel if and only if there exists some P\u00150such that k(x;y) =Qd(x)TPQd(y): (4.8) 94This lemma implies that a representation of the form of Equation (4.7) is necessary and su\u000ecient for a generalized polynomial kernel to be positive. For convenience, we denote the set of generalized polynomial kernels of degree das follows. Kd P:=fk:k(x;y) =Qd(x)TPQd(y) :P\u00150g (4.9) Unfortunately, however, polynomial kernels are never universal and hence we propose the following universal class of TK kernels, each of which is de ned by polynomials, but which are not polynomial. 4.2.2 Tessellated Kernels To begin, we de ne the indicator function for the positive orthant as I+(z) =8 >>< >>:1z\u00150 de ne Zd:Rn\u0002Rn!Rqto be the vector of monomials of degree dinR2n. We now propose the with this de nition, we de ne the class of shows that any k2KTis piecewise polynomial. Speci cally, if we de ne the partition of Rninto 2northants - parameterized by 21. Suppose that g 2f0;1gnis de we (4.12) Note that the number of domains X used to de ne the piecewise polynomial k is 2n, which does not depend on q(the dimension of Pij). Thus, even if Zd= 1, the resulting kernel is partitioned into 2ndomains. The size of Zd(x;y)2Rqonly in uences the degree of the polynomial de ned on each domain. The signi cance of the partition does not lie in the number of domains of the kernel, however. Rather, the signi cance of the partition lies in the resulting classi er, which, for a given set of training data fxigm i=1, has a where 2f0;\u0001\u0001\u0001;mgn. Although the training an ordering using \u0000( i;j) :f0;\u0001\u0001\u0001;mg\u0002f 1;ng!f 1;\u0001\u0001\u0001;mgwhere \u0000(i;j) indicates that of the training data, x\u0000(i;j)has theith largest value. 97That is, [x\u0000(i\u00001;j)]j\u0014[x\u0000(i;j)]j\u0014[x\u0000(i+1;j)]j8i= 1;\u0001\u0001\u0001;m\u00001; j = 1;\u0001\u0001\u0001;n: Now, for any 2f0;\u0001\u0001\u0001;mgn, we may de ne an tile X [x\u0000( j;j)]j\u0014zj\u0014[x\u0000( j+1;j)]j; j= 1;\u0001\u0001\u0001;n =mX i=1 iyik(xi;z) +b =f (z)8z2X : To de ne the f , we associate with every tile and datum ian orthant (i; ) which denotes the position of tile T datum xi- i.e.T is in the f (z) =mX i=1 iyik (i; )(xi;z) which is a polynomial for every . In this way, each data point further divides the domains which it intersects, resulting in ( m+ 1)ndisjoint sub-domains, each with associated polynomial classi er. Thus we see that the number of domains of de nition of the classi er grows quickly inm, the number of training data points. For instance, with n = 2 there are 100 tiles for just 9 data points. This growth is what makes TK kernels universal - as will be seen in Section IV. 98In Figure 4.1(a) we see the function, f(z) =Pm i=1 iyik(xi;z) +b, for a degree 1 TK kernel trained for a 1-dimensional labeling problem as compared with a Gaussian kernel. We see that the TK classi er is continuous, and captures the shape of the generator better than the Gaussian. Note that the TK classi er is not continuously di erentiable and the derivative can change precipitously at the edges of the tiles. However, if we decrease the inverse regularity weight Cin the objective function of Optimization Problem (2.11), then this has the e ect of smoothing the resulting classi er. In Figure 4.1(a), as Cdecreases we see that the changes in slope at edges of the tiles decrease. To illustrate that the function k(xi;z) is a piecewise polynomial tessellated by the training datum, we plot the value of an assortment of TK kernels in one dimension in Figure 4.1(b). We use training datum xi= 5, and a selection of di erent positive where P1;2=P2;1=P2;2= 0 0 13 75;A4=2 666640 0 0 0 1 0 0 0 13 77775: (4.13) In the rst three cases the monomial basis is of degree 1, while in the fourth case the monomial basis is of degree 2 - for simplicity we exclude monomials with z. These di erent matrices all illustrate changes in slope which occur at the training datum. 4.3 Properties of the tessellated class of kernel functions In this section, we prove that all TK kernels are continuous and universal and that the TK class is pointwise dense in all kernels. 990 1 2 3 4 5 6 7 8 9 10 Data Value -2 -1.5-1 -0.500.511.5Classi/f_ier Value Data T: C = 0.05 G: C = 1 T: C = 0.15 G: C = 10 T: C = 5 G: C = 50(a) Optimal classi er, f(z) using a degree one TK (solid lines), and a positive combination of Gaussian kernels (dotted lines) with three di erent penalty weights C. 0 1 2 3 4 5 6 7 8 9 10 x00.20.40.60.811.2 Kernel Function Value k(x,5) P11 = A 1 P11 = A 2 P11 = A 3 P11 = A 4(b) Normalized kernel function k(5;z) using P1;1=Aifrom (4.13) and P1;2=P2;1= 0. Figure 4.1: This gure depicts the optimal classi er for labeling a 1-dimensional data set compared to Gaussian classi ers as well as the normalized kernel di erent P1;1matrices andX= [0;10]. 4.3.1 TK kernels are continuous that for any P\u00150 andN(z;x), k(x;y) =Z XN(z;x)TPN(z;y)dz is a positive kernel and TK kernels, we theorem this implies that the classi ers consist of functions of the form f(y) =mX i=1 iZ XN(xi;z)TPN(y;z)dz: The following theorem establishes that such functions are necessarily continuous. 100Theorem 22. Suppose that for a<b2Rn,Y=X= [a;b],P\u00150,Nis as de ned in Eqn. (4.10) for somed\u00150andkis as de ned in 75>0: To prove that f(z) is continuous we need only prove that k(x;y) is continuous. Applying Lemma 3 we may de ne k(x;y) as k(x;y) (x;y) ifx\u0000y2X : To expand k (x;y), use multinomial notation for the monomials inZd. to max( xj;yj), and can be written as the continuous function, \u0012 ;j(x;y) =1 2(xj+yj+jxj\u0000yjj); we conclude that k(x;y) is the product and summation of continuous functions and thereforekand the resulting classi ers are both continuous. 4.3.2 TK kernels are Universal In addition to continuity, we show that any TK kernel with P 0 has the universal property. The following theorem shows that any TK kernel with P 0 is necessarily universal. Theorem 23. Supposekis as de ned in Eqn. (4.7) for 0,d2NandN as de . for Y=X= generality, we assume > 0, then there exist\u000fisuch thatP=P0+P 0 0\u0015 102wherefe1gis the rst |{z} k1(x;y); ^kis a Since the hypothesis space satis es the additive property (See [166, 13]), if k1is a universal kernel, then kis a universal kernel. Recall that for a given kernel, the hypothesis space, H, can be characterized as the closure of span fk(y;\u0001) :y2Xg . Now, consider spanfk1(y;\u0001) :y2Xg; which consists we may construct a triangle function of height 1 centered at 3=\u0000\u000e: By taking the product of triangle functions in each dimension, we obtain the pyramid functions which are known to be dense in the space of continuous functions on a 103compact domain (See [143]). We conclude that k1is a universal kernel and hence k is universal. This theorem implies that even if the degree of the polynomials is small, the kernel is still universal. Speci cally, in the case when n= 1 andd= 0, the setK0 Tis universal yet contains only three parameters (the elements of the symmetric P2R2\u00022). 4.3.3 TK kernels are pointwise dense in all kernels In the previous two subsections, we have shown that TK kernels are continuous and universal. Furthermore, as shown in Section 4.2, the TK class admits a linear parameterization. The remaining question, then, is whether TK kernels are superior in some performance metric to other classes of universal kernels such as Gaussian kernels. First, note that the universal property is of the kernel itself and which is extended to a class of kernels by requiring all kernels in that class to satisfy the property. However, although a kernel may be universal, it may not be well-suited to SVM. Expanding on this point, although it is known that any universal kernel may be used to separate a given set of data, it can be shown that for any given set of normalized data, fxi;yig, there exists a universal kernel, k, for which the objective function of the solution to 1-norm soft margin problem is arbitrarily suboptimal - e.g. by increasing the bandwidth of the Gaussian kernel. To address the question of performance, we propose the pointwise density property. This property is de ned on a set of kernels and guarantees that there is some kernel in the set of kernels for which the solution to the 1-norm soft margin problem is optimal. Speci cally, we have the following. De nition 24. The set of kernels Kis said to be pointwise dense if for any positive kernel, k\u0003, any set of data fxigm i=1, and any\u000f >0, there exists k2K such 104thatkk(xi;xj)\u0000k\u0003(xi;xj)k\u0014\u000f. This de nition implies that a set of kernels can approximate any given positive kernel arbitrarily well. To illustrate the importance of the pointwise density property we show that for a large class of kernel learning problems, the value of the optimal kernel is not pointwise positive - i.e. k(x;y)6\u00150 for allx;y2X. This is signi cant because almost all commonly used kernels are pointwise non-negative. Indeed we nd that the elements of the optimal kernel matrix are negative as frequently as they are positive. Optimal kernels are not pointwise positive To demonstrate the necessity of negative values in optimal kernel matrices, we will analytically solve an SDP to the optimal kernel matrix for the 1-norm KL problem. The Optimal Kernel Matrix for 1-norm SVM To demonstrate the necessity of negative values in optimal kernel matrices, we analytically solve the following SDP derived from Optimization Problem (4.4) which determines the optimal kernel matrix ( K\u0003) given the labels yof a problem and a \\penalty\" parameter C, but with no constraint on the form of the kernel function (other than it be PD). min t2R;K2Rm\u0002m; of this optimization problem. Theorem 25. Letyi2f1;\u00001gfori= 1;\u0001\u0001\u0001;mandC\u00152 m, then the solution 2R;\u00172Rm;\u000e2Rm \u0017\u00150;\u000e\u00150min K2Rm\u0002m; K\u00150;trace(K)=m(e+\u0017\u0000\u000e+ y)T(YKY)\u00001(e+\u0017\u0000\u000e+ y) + 2C\u000eTe: Now, for any feasible K, we have that K\u00150 this Ksolves the rst sub-problem and hence Optimization Prob- lem conditions are satis ed and since the optimization problem is convex, (\u0017\u0003;\u000e\u0003; \u0003) is optimal. This result shows that for binary labels, the optimal kernel matrix has an analytic solution. Furthermore, if we consider the case wherePm i=1yi= 0, then\u0015\u0003= 0 and 107henceK\u0003=yyTandK\u0003 i;j=yiyj. This implies that the optimal kernel matrix consists of an equal number of positive and negative entries - meaning that kernels functions with globally positive values will not be able to approximate the optimal kernel ma- trix well. Furthermore, for values of Cless than2 m, we numerically nd that the same kernel matrix is still optimal - only the values of \u000e\u0003and \u0003are di erent. The GPK and TK classes are dense in all kernels Having demonstrated the signi cance of pointwise density, we now establish that both the GPK and TK kernel sets satisfy this property. For this analysis, we relax the strict positivity constraint P > 0 in the de nition of the TK class. In this case, the GPK class becomes a subset of the TK class. We then prove pointwise density of the GPK class - a property which is then inherited by the TK class. The following lemma shows that the GPK class is a subset of the TK class. Lemma 26.Kd P\u001aKd T Proof. P, a P1\u00150 such that kp(x;y) =Zd(x)TP1Zd(y). Now letJbe the matrix now use polynomial interpolation to prove that GPK kernels are pointwise dense. Theorem 27. For any kernel matrix K\u0003and any nite set fxigm i=1, there exists interpolation (as [60]), for d, we may Zd(x1)\u0001\u0001\u0001Zd(xm)\u0015 to the optimal kernel We next show that in practice, a degree of only 4 or 5 can be su\u000ecient to approximate the optimal kernel matrix with minimal error using either GPK and TK kernels. Speci cally, we consider the problem of approximating the optimal kernel matrix for a given set of data fxigand given set of kernels, K, using both sets of kernel functions we consider are: K G- the sum of KGaussians with bandwiths i;Kd P- the GPKs of degree d; andKd T- the TK kernels of degree d. That is, we chooseK2fK G;Kd;Kd Tgwhere for convenience, we de ne the class of sums of Gaussian kernels of (4.19) and (4.20) for K G,Kd P, andKd Tas a function of the degree of the polynomials, dand the number of bandwidths selected (K). For this test, we use the spiral data set with 20 samples and corresponding labels such thatPm i=1yi= 0. Since half of the entries in K\u0003are\u00001, and since the 110Polynomial Degree (d) 1 2 3 4 5 6 7||KK* ||1 n2 00.20.40.60.81 Tessellated Kernel Polynomial Kernel Gaussian Kernel 6 21 55 120 231 406 666 (a)kK\u0000K\u0003k1 n2 for the TK and GPK classes of degreedand for a positive combination of m Gaussian kernels. Polynomial Degree (d) 1 2 3 4 5 6 7 00.20.40.60.811.2 Tessellated Kernel Polynomial Kernel Gaussian Kernel 6 21 55 120 231 406 666 ||KK* ||(b)kK\u0000K\u0003k1for the TK and GPK classes of degreedand for a positive combination of mGaussian kernels. Figure 4.2: The objective of Optimization Problem 4.19 and 4.20 for the TK and GPK classes of degree dand for a positive combination of mGaussian kernels with bandwidths ranging from :01 to 10. The number of bandwidths is selected so that the number of decision variables (displayed above the gure) match in the Gaussian and in the TK kernel case. Gaussian kernel is globally positive, it is easy to see that for K=K Gthe minimum objective values of Optimization Problems (4.19) and (4.20) are lower bounded by 0 :5 and 1 respectively, irrespective of the choice of bandwidths, iand number of data points. In Figs. 4.2(a) and 4.2(b) we numerically show the change in the objective value of Optimization Problems (4.19) and (4.20) for the optimal Gaussian, GPK, and TK kernels as we increase the complexity of the kernel function. For the TK and GPK kernel functions, we increase the complexity of the kernel function by increas- ing the degree of the monomial basis while scaling the x-axis to ensure equivalent computational complexity. The results demonstrate that, as expected, the Gaussian kernel saturates with an objective value signi cantly larger than the lower bound of 0 :5 for the 1-norm and exactly at 1 for the 1-norm (the projected lower bound). Meanwhile, as the degree 111increases, both the GPK and TK kernels are able to approximate the kernel matrix arbitrarily well, with almost no error at degree d= 7. Furthermore, the TK kernels converge somewhat faster. 4.4 SDP formulation of the TK kernel learning algorithm Subsection 4.1.2 gave a convex formulation of the kernel learning problem using the convex constraint k2K. Having now de ned the TK class of kernels, we now address speci c implementations of the TK kernel learning problem using both an SDP method based on Optimization Problem (4.4) and a method that directly solves the minimax formulation. In both cases, our goal for this section is to de ne an explicit linear map from the elements of the positive matrix variable, P, to the values of the kernel function k(xi;xj). To construct our mapping, we rst create an index of the elements in the basis Zd(z;x) which is used in Nd T(z;x) as de ned in Eqn. (4.10). Recall Zd(z;x) is a vector of all monomials of degree dor less of length q:=\u0000d+2n d\u0001 . We now specify that the elements of Zdare ordered, and by default we use lexicographical ordering on the exponents of the variables of the monomials. Speci dg. Using this notation, we have the following representation of the TK kernel k. Corollary 28. Suppose that for a<b2Rn,Y=X= [a;b], Now letkbe as de ned in Eqn. (4.7) for some P > 0and whereNis as de ned in Eqn. j \u0010j! : Proof. The proof follows from Theorem 22. Using a linear map from the elements of Pto the value of k(x;y), we may now write the SDP version of the TK kernel learning problem as SDP and can, therefore, be solved e\u000e- ciently using standard SDP solvers such as MOSEK [4]. Note that we use the trace constraint to ensure the kernel function is bounded. 113Typically SDP problems require roughly p2n2number of operations, where pis the number of decision variables and nis the dimension of the SDP constraint (See [44]). The number of decision variables in (4.23) is moderate, increasingly linearly in the number of training data points and the number of elements of P. However, this optimization problem has a semi-de nite matrix constraint whose dimension is linear inm, the number of training data. As we will see in Section 4.6, the increase in training data increases nand limits the amount of training data that can be processed using Optimization Problem (4.23). To improve the scalability of the algorithm, we consider a minimax formulation. 4.5 Minimax formulation of the TK kernel learning algorithm In this section, we formulate the KL optimization problem as a minimax saddle point problem for classi cation and regression. This formulation enables a decompo- convex primal and dual sub-problems, OPTA(P) andOPTP( no duality gap. We the Frank-Wolfe algorithm and show using Danskin's Theorem that the gradient step can be e\u000eciently computed using the primal and dual sub-problems. Finally, we propose e\u000ecient algorithms for computing OPTA(P) and OPTP( ): in the former case using an e\u000ecient SMO algorithm for convex QP and in the latter case, using an analytic solution based on the SVD. 4.5.1 Primal-Dual Decomposition For convenience, we de ne the feasible sets for the sub-problems as use the generic form Y\u0003to refer to either YcorYr depending on whether the algorithm is being applied to the classi cation or regression problem. To de ne the objective function we use \u0015( ;P) The KL optimization problem ( OPT) for TK kernels is now de ned as the following minimax saddle point optimization problem. OPTP:= min P2Xmax ); labels) for classi ca- ones) for regression. Minimax Duality To nd the dual of the KL optimization sub-problems: that OPTP= P2XOPTA(P) and its dual is there is no duality gap between OPTPandOPTD- a property we will use in our termination criterion. Lemma 29. OPTP=OPTD. Furthermore,f \u0003;P\u0003gsolveOPTPif and only if OPTP( \u0003) =OPTA(P\u0003). Proof. For any minmax optimization problem with and is convex for every 2Y and (P;\u0001) is concave for every P2X, and the function is continuous [53]. In our case, these conditions hold for both classi Finally, we note that OPTA(P) is convex with respect to P- a property we will use in Thm. 33. Lemma 30. LetOPTA(P)be as de ned in 4.26. Then, the function OPTA(P)is convex with respect to P. 116Algorithm 1: 3:Pk+1=Pk+ k(Sk\u0000Pk);k=k+ 1;return to 1. Proof. First without loss of generality let e\u00032Rmbe a vector of ones and e\u0003 = . The function OPTA(P) :Rn\u0002n!Ris convex if :=OPTA(X+tV) is convex in tfor allt2H:=fs2RjX+sV\u00170g. To g(t) we g(\u0012t1+ (1\u0000\u0012)t2)\u0014\u0012g(t1) + \u0015( linear with respect S2Xf(S);whereXis a convex subset of matrices andh\u0001;\u0001iis the Frobenius matrix inner product, the Frank-Wolfe (FW) algorithm is de ned as in Algorithm 1. In our case, we have f(Q) =OPTA(Q) so 117that OPTP= min P2XOPTA(P): Unfortunately, implementation of the FW algorithm requires us to compute rQOPTA(Q)jQ=Pkat each iteration. Fortunately, as shown in Subsections 4.5.3 and 4.5.4, we may e\u000eciently solve the sub-problems OPTAandOPTP. Further- more, in Theorem 32, we will show that these sub-problems can be used to e\u000eciently compute the gradient rQOPTA(Q)jQ=Pk- allowing for an e\u000ecient implementation of the FW algorithm. Theorem 32 uses Danskin's theorem, shown below as abridged from [10]. Proposition 31 (Danskin's Theorem-[10]) .LetY\u001aRmbe a compact set, and :X\u0002Y! Rbe such that (\u0001; ) 2Y of only one unique point, \u0016 , and (\u0001;\u0016 )is di erentiable at ) @Pi; i = 1;:::;n: Using Danskin's Theorem we may now e\u000eciently calculate the partial derivative for step 1a of the KL algorithm for TKs. Lemma (4.26) anyPk\u00150, we have arg min S2XhrQOPTA(Q)jQ=Pk;Si= argOPTP(argOPTA(Pk)): 118Proof. For simplicity, we de ne D( ) as in Eqn. (4.29) such that \u0015(e\u0003 ;P) convex in , for anyPk>0,OPTA(Pk) has a unique solution and hence we have by Danskin's Theorem that arg argOPTP(argOPTA(Pk)): now propose the e\u000ecient implementation of the FW algorithm, as de ned in Algorithm 2, based on e\u000ecient algorithms for computing OPTAandOPTPas will be de ned in Subsections 4.5.3 and 4.5.4. In the following theorem, we use convergence properties of the FW algorithm to show that Algorithm 2 has worst-case linear f=OPTA, then Theorem 32 shows that fis di erentiable and, if thePksatisfy Algorithm 2, that the Pkalso satisfy Algorithm 1. In addition, Lemma 30 shows that f(Q) =OPTA(Q) is convex in Q. It has been shown in, e.g. [77], that ifXis convex and compact and f(Q) is convex di on 119Algorithm 2: An E\u000ecient FW Algorithm for TKL. Note that the stopping criterion is de ned using the duality gap OPTP( k)\u0000OPTA(Pk)>0, which is equivalent to the stopping criterion used in the standard FW algorithm. k(Sk\u0000Pk),k=k+ FW Algorithm produces iterates Pk, such that, f(Pk)\u0000f(P\u0003)<O(1 k) where f(P\u0003) = min P2Xf(P) = min P2XOPTA(P) the proof. In the following subsections, we provide e\u000ecient algorithms for computing the sub-problems OPTAandOPTP. 4.5.3 Step 1, Part A: Solving OPTA(P) For a given P > 0,OPTA(P) is a convex Quadratic Program (QP). General purpose QP solvers have a worst-case complexity which scales as O(m3) [173] where, 120when applied to OPTA,mbecomes the number of samples. This computational complexity may be improved, however, by noting that OPTAis compatible with the representation de ned in [22] for QPs derived from SVM. In this case, the algorithm in LibSVM [22], can reduce the computational burden somewhat. This improved per- formance is illustrated in Figure 4.5 where we observe the achieved complexity scales asO(m2:1). Note that for the 2-step algorithm proposed in this manuscript, solving the QP inOPTA(P) is signi cantly slower that solving the Singular Value Decom- position (SVD) required for OPTP( ), which is de ned in the following subsection. However, the achieved complexity of O(m2:1) is also signi cantly faster than solv- ing the SDPs described in [96, 114, 29]. This complexity comparison will be further discussed in Section 4.6. 4.5.4 Step 1, Part B: Solving OPTP( ) For a given ,OPTP( ) is an SDP. Fortunately, however, this SDP is structured so as to admit an analytic solution using the SVD. To solveOPTP( ) we minimize \u0015(e\u0003 ;P) from Eq. (4.24) which, as per Corollary 28, is linear in Pand can be formulated in Corollary 28. The following theorem gives an analytic solution for OPTPusing the SVD. Theorem 34. For a given , denote symmetric D )2Rq\u0002qas de ned and letD =V\u0006VTbe SVD. Let vbe the right singular vector corre- sponding to the minimum singular value of D . ThenP\u0003=qvvTsolvesOPTP( ). Proof. Denote the minimum singular value of D as\u001bmin(D ). Then for any feasible P2X, by [54] hD ;Pi\u0015\u001bmin(D )trace(P) =\u001bmin(D )q: consider P=qvvT2Rq\u0002q.Pis feasible =q. Furthermore, hD ;Pi=qtrace(V\u0006VTvvT) =qtrace(vTV\u0006VTv) =q\u001bmin(D ) as desired. Note that the size, q, ofD inOPTP( ) scales with the number of features, but not the number of samples ( m). As a result, we observe that the OPTPstep of Algorithm 2 is signi cantly faster than the OPTAstep. 4.6 Implementation and complexity analysis In this section we rst analyze the complexity of Optimization Problem (4.23) with respect to the number of training points as well as the selected degree of the TK -Kd T. We then perform the same analysis on Optimization Problem (4.25) with respect to the number of training points and the number of random matrices selected. 122Number of Training Inputs 10 210 3Seconds to Optimize 10 010 110 210 310 4 d = 1 d = 2 d = 3(a) Complexity scaling for identi cation of circle Number of Training Inputs 10 210 3Seconds to Optimize 10 010 110 210 310 4 d = 1 d = 2 d = 3(b) Complexity scaling for identi cation of spiral Figure 4.3: Log-Log plot of computation time vs number of training data for 2-feature kernel learning. Analysis of the SDP Approach: In Optimization Problem (4.23) the con- straint that the kernel be a positive TK kernel can be expressed as an LMI constraint with variables Pij. Using Optimization Problem (4.23), if P2Rq\u0002q, andmis the number of training data, with a Mosek implementation, we nd experimentally that the complexity of the resulting SDP scales as approximately m2:6+q1:9as can be seen in Fig. 4.3 and is similar to the complexity of other methods such as the hyperkernel approach [120]. These scaling results are for training data randomly generated by two synthetic 2-feature example problems (circle and spiral - See Fig. 4.4) for degrees d= 1, 2, 3 and where dde nes the length of Zd(and hence q) which is the vector of all monomials in 2 variables of degree dor less. Note that the length of Zdscales with the degree and number of features, n, as q=(n+d\u00001)! n!d!. For a large number of features and a high degree, the size of Zdwill become unmanageably large. Note, however, that, as indicated in Section 4.3, even whend= 0, every TK kernel is universal. Analysis of the Minimax Approach: In Figures 4.5, we plot the computation time of the FW TKL algorithm -5 ed with pleMKL] (n=150) Figure 4.4: a s Compared with [SimpleMKL] for nTraining Data.]Discriminant surface for circle and spiral separator using method [TK] as compared with [SimpleMKL] for n training data. classi cation and regression on a desktop PC with an Intel i7-5960X CPU at 3.00 GHz and 128 Gb of RAM as a function of mandq, wheremis the number of samples used to learn the TK kernel function and the size of Pasq\u0002q(so thatqis a function of the number of features and the degree of the monomial basis Zd). The data set for these plots is Combined Cycle Power Plant (CCPP) from [164, 86], containing 4 features and m= 9568 samples. In the case of classi cation, labels with value greater than or equal to the median of the output were relabeled as 1, and those less than the median were relabeled as \u00001. To enable comparison with SimpleMKL, we use an identical stopping criterion of 10\u00002. Figures 4.5(a-d) demonstrate that the complexity of Algorithm 2 scales as approximately O(m2:28q0:57) for classi cation andO(m2:34q2:40) for regression. These results are signi cantly lower with respect tomthan the value of O(m2:6q1:9) reported in [29] for binary classi cation using the SDP implementation. Aside from improved scalability, the overall time required for Algorithm 2 is signi cantly reduced when Numerical complexity analysis of TKL for regression versus m. 4 5 6 7 8 9 10 Value of q468101214Time (seconds)m=5367 m=6244 m=7122 m=8000 (c) Numerical complexity analysis of TKL for classi cation versus q. 4 5 6 7 8 9 10 Value of q101102103Time (seconds)m=5367 m=6244 m=7122 m=8000(d) Numerical complexity analysis of TKL for regression versus q. Figure 4.5: In (a) and (b) we nd log scale plots of the time taken to execute FW TKL forP2Rq\u0002q. The line of best linear t is included for reference. In (c) and (d) we nd log scale plots of the time taken to optimize TKL as a function of qfor four di erent values of m. in [29], improving by two orders of magnitude in some cases. This is illustrated for classi cation using four data sets in Table 4.1. This improved complexity is likely due to the lower overhead associated with QP and the SVD. 125Table 4.1: We report the mean computation time (in seconds), along with standard deviation, for 30 trials comparing the SDP algorithm in [29] and Algorithm 2. All tests are run on an Intel i7-5960X CPU at 3.00 GHz with 128 Gb of RAM. Method Liver Cancer the New TK Kernel Learning Algorithm for Regression In this section, we compare the accuracy of the classi cation and regression solu- tions obtained from the FW TKL algorithm to a selection of several other state of the art methods. Speci cally, we use the following implementations of these algorithms. [TKL] Algorithm 2 with d= 1,\u000f=:1 and we scale the data so that xi2[0;1]n, and then select [ a;b] in [134] with a standard selection of Gaussian and polynomial kernels with bandwidths arbitrarily chosen between .5 and 10 and polynomial degrees one through three - yielding approximately 13( n+ 1) kernels. We set\u000f=:1 as in TKL and Cis chosen by 2-fold cross-validation; [NNet] A neural network with 3 hidden layers size 50 using MATLABs ( patternnet for classi cation and feedforwardnet for regression) implementation and stopped learning after the error in a validation set decreased sequentially 50 times. [RF] The Random Forest algorithm [16] as implemented on the scikit-learn python toolbox [125] for classi cation and regression. We select between 50 and 650 trees (in 50 tree intervals) using 2-fold cross-validation. [XGBoost] The XGBoost algorithm [24] for classi cation and regression. We select between 50 and 650 trees (in 50 tree intervals) using 2-fold cross-validation; 126[AMKL] The AverageMKL implementation from the MKLpy python package [100], averages a standard selection of Gaussian and polynomial kernels; [PWMK] The PWMK implementation from the MKLpy python package [100], which uses a heuristic based on individual kernel performance from [159] to learn the weights of a standard selection of Gaussian and polynomial kernels; [CKA] The CKA implementation from the MKLpy python package [100], uses the centered kernel alignment optimization in closed form from [38] to learn the weights of a standard selection of Gaussian and polynomial kernels. Six classi cation and six regression datasets were chosen arbitrarily from [46, 22] to contain a variety of number of features and number of samples. No other datasets were tested for relative performance and datasets were not \\pre-screened\". In both classi cation and regression, our accuracy metric uses 5 random divisions of the data into test sets ( mtsamples\u0018=20% of data) and training sets ( msamples\u0018=80% of data). Individual test results and their standard deviations are reported in Tables 4.2 and 4.3 for classi cation and regression respectively. Regression analysis Out of the six di erent regression data sets the proposed al- gorithm (TKL) scored above average on ve of the data sets, an improvement over all other algorithms but XGBoost which also scored above average on ve of the data sets. The average percent di erence between the average MSE and the MSE for PMKL was -23.16% which was better than all other tested algorithms including XG- Boost. Unfortunately, the cost of this increased accuracy is an increased computation time. The average percent di erence between the average computation time and the time for PMKL was 19.49%. However, TKL is also the top performing algorithm for three of the six data sets. 127Classi cation analysis Out of the six di erent classi cation data sets the proposed algorithm (TKL) scored above average on all of the data sets, an improvement over all other algorithms. The average percent di erence between the average TSA and the TSA for TKL was 6.77% which was close to the top score of 6.84% by the AMKL algorithm. The PWMK algorithm had an average percent di erence of 8.52%, but failed to converge on one of the data sets. Like in the regression case, the cost of this increased accuracy is an increased computation time. The average percent di erence between the average computation time and the time for PMKL was 68.41%. However, TKL is also the top performing algorithm for two of these data sets. To further illustrate the importance of density property and the TKL framework for practical regression problems, we used elevation data from [8] to learn a degree 2 TK kernel and associated SVM predictor representing the surface of the Grand Canyon in Arizona. This data set is particularly challenging due to the variety of geographical features. The result from the TKL algorithm can be seen in Figure 4.6(d) where we see that the regression surface visually resembles a photograph of this terrain, avoiding the artifacts present in the Gaussian-based method. Next we use the TKL algorithm and a selection of other machine learning algo- rithms to analyze an immune dataset. 4.8 Application of the TK Kernel Learning Algorithm to an Immune State Identi cation Problem The immune response is a dynamic process by which the body determines whether an antigen is self or nonself. The state of this dynamic process is de ned by the relative balance and population of in ammatory and regulatory actors which comprise this decision making process. The goal of immunotherapy as applied to, e.g. Rheumatoid Arthritis (RA), then, is to bias the immune state in favor of the regulatory actors - 128thereby shutting down autoimmune pathways in the response. While there are several known approaches to immunotherapy, the e ectiveness of the therapy will depend on how this intervention alters the evolution of this state. Unfortunately, this process is determined not only by the dynamics of the process, but the state of the system at the time of intervention - a state which is di\u000ecult if not impossible to determine prior to application of the therapy. In this section we use feature selection algorithms, in combination with the TK kernel learning algorithm and other machine learning algorithms, to identify an im- mune state using a data-driven approach. We initially de ne our immunological dataset obtained from ongoing trials of RA immunotherapy. Then we de ne a set of machine learning algorithms which use a given subset of data observables to identify outputs of interest such as other observables or the RA outcome - as measured by severity of in ammation. To identify important features from the immunological dataset we propose a met- ric for suitability of a given set of observables based partially on predictive power of the associated model. The rst part of this metric is based on minimality (not prediction), wherein we impose a penalty based on the number of observables in the set (cardinality) in order to reduce experimental and clinical complexity. Second, in order to ensure that relevant immunological data is not lost, we also add a penalty based on the error of the associated model to predict observables from the data not included in the given set. Third, to measure e\u000ecacy of the prediction, we impose a penalty based on the error in prediction of RA severity - a quantity we refer to as the \\disease state\". Finally we use a variety of feature selection algorithms to determine the set of observables which are optimally suited using the suitability metric described above. We then report the results of applying the resulting algorithms to our dataset after 129applying di erent weights to the three parts of the suitability metric. We de ne the optimal sets returned by each case as \\immune states\" and analyze the immune cells that were selected by the feature selection algorithms in each case. 4.8.1 The Immune Dataset Figure 4.7: A graphical description of the experimental procedure of in- ducing and treating RA in mice. The rst two steps induce RA, the next two steps is the application of the treatment and the nal step is the data generation using ow cytome- try. CFA = complete Freund's ad- juvant, IFA = incomplete Freund's adjuvant.We propose a methodology for identifying observable measures for immune system health from measured features of the immune sys- tem. To better illustrate this methodology, we consider the approach as applied to a par- ticularly rich dataset obtained from an on- going series of experiments involving the use of biomaterials-based particles [107] containing metabolites that promote self tolerance in in- termediate/late stage RA in a DBA/1j mouse model which develops severe arthritis when im- munized with bovine collagen type 2 (bc2) au- toantigen. In this experimental series, the par- ticles were synthesized either with or without autoantigen bc2 - a strategy designed to de- termine if the particles can generate antigen- speci c anti-in ammatory response. An overview of the experimental procedure is provided in Fig. 4.7. The chronology of the experiment is listed here in detail. The data collection used for model generation occurs exclusively on either day 62 or 70. Day 0 and 21: RA was induced in mice to generate an autoimmune response for the development of severe polyarthritis. On day 35, the mice were divided into 3 130groups, each receiving a distinct therapeutic regimen. Group 0 - Days 35/42: The control group consists of 5 control mice, each re- ceiving two subcutaneous injections of phosphate bu ered saline (PBS) near the hind legs on days 35 and 42. Group 1 - Days 35/42: Treatment group 1 consists of 5 mice. Each mouse receives two injections of 0.5 mg of biomaterials-based particles without embedded autoantigen bc2 near the hind legs on days 35 and 42. Group 2 - Days 35/42: Treatment group 2 consists of 8 mice. Each mouse receives two injections of 0.5 mg of biomaterials-based particles with embedded au- toantigen bc2 near the hind legs on days 35 and 42. Measurements Taken on Days 62/70: Paw thickness measurements are used to determine arthritic scores for all mice and the end of study paw measurements were obtained either on day 62 or 70, and are de ned on the interval [0 ;5]. Further- more, ow cytometry was performed on cells collected from the popliteal lymph node, cervical lymph node and spleen of each mouse on day 62 or 70. The ow cytome- try procedure measured values for CD4 (T helper (Th) cell marker), CD8 (cytotoxic T (Tc) cell marker), Ki67 (proliferation), CD25 memory marker), and a tetramer that is speci c to the autoantigen. Based on this staining, we identi ed 41 di erent combinations of markers which might be used to classify the phenotype of a T cell and determined the percentage of either CD4 or CD8 T cells 131presenting the associated combination of markers. Summary of Associated Dataset: The data consists of 84 samples, based on 18 mice, each sample is associated with a mouse and sample location. All samples are taken on day 62/70, and each sample consists of 43 features and one label. The rst two features of each sample indicate group number (0-2) and sample location (1-3). The remaining 41 features de ning the percentage (0-100) of the CD4/CD8 population exhibiting the associated combination of markers. The label for each sample is the arthritic score (0-5). Based on this data we next propose several methods of machine learning to con- struct predictive models which use subsets of the features to predict both the label (disease progression) and discarded features. For generating these models, all features are scaled to the interval [0 ;1]. 4.8.2 Selected Machine Learning Algorithms We de ne six machine learning algorithms that will be used in combination with a feature selection algorithm to determine the immune state. In each case below, we assume the data set contains msamples,fxi;yigm i=1, each with nfeatures,xi2Rn and a label yi2R. Regression (LR) The regularized linear returns a predictive model y=f(x) optimization problem. min In this case, 1\u00150 and 2\u00150 are the regularization parameters. Linear regression has the advantage of low computational complexity. However, the resulting predictor 132is linear and if the underlying physical process is nonlinear, accuracy of the predictive model will be poor. \u000f-loss Support Vector Regression (SVR) The support vector regression prob- lem (Optimization Problem (2.15)) uses a predictive model of the form f(x) = Pm i=1 ik(x;xi) where 2Rmis the decision variable and kis a user selected positive kernel function. The objective function penalizes any points where jf(xi)\u0000yij\u0015\u000f, where\u000fis a tuning parameter by a regularization parameter C. SVR can generate ac- curate nonlinear predictive models for appropriate choice of k. However, the selection of the kernel heavily in uences the resulting accuracy and this process of selection is di\u000ecult to automate. Kernel Learning (TKL) Kernel learning algorithms improve on the SVR problem by automating the search for a kernel function. We have shown that the class of Tes- sellated Kernel functions have the properties of universality, density, and tractability - meaning the resulting algorithms are rather accurate and generalize well to new data. The regularization parameters in this case are the \u000fandCas de ned above for SVR. Decision Tree Algorithms Decision trees are composed of a series of conditional statements that branch in a \\tree\" like manner. We say the \\depth\" of a decision tree is how many conditional statements appear in a branch before leading to a label denoted the \\leaf\". Both the depth of the decision trees and the maximum number of leaves are regularization parameters that can be modi ed by the user. Decision trees are often weak predictors alone and in this paper we use ensemble (random forest) or boosting (boosted trees) methods to increase predictive performance. These algorithms are de ned as follows. 133\u000fRandom Forest: The random forest algorithm is an ensemble machine learn- ing method based on a combination of decision trees. Ensemble methods use a combination of predictive models (trees) that individually have poor generaliza- tion but when used in combination can have signi cantly improved predictions. The number of decision trees combined in the random forest algorithm can be used as a regularization parameter. \u000fBoosted Trees: Gradient boosting is another machine learning method also based on a combination of decision trees. In the boosted algorithm trees are added to the predictive model sequentially, and each additional tree is t to the current residuals of the model. A \\learning rate\" is a weight applied to the addition of each decision tree, and is often used as a regularization parameter. Small learning rates tend to improve the generalization of the predictive models. Next we will focus on a metric we may use to identify the observables which are most suitable to the task of predicting self vs nonself determination in autoimmune disease. 4.8.3 Quantifying Suitability of a Given Set of Observables To identify a set of observables for predicting self vs nonself determination we rigorously de ne a metric for suitability in order to select the observables which lead to superior predictive models. First, for the sake of generality, we de ne the algorithm, OPT , which we use as a placeholder for the machine learning algorithms described previously. De nition of OPT : Given a dataset fxi;yigm i=1\u001aRn\u0002Rq,OPT 134In cases where the machine learning algorithm returns a function with a single output we train the machine learning algorithm qtimes, once for each output. Next, given a possible set of feature indices F:=f1;\u0001\u0001\u0001;ng, we de ne the set of all subsets of FasP(F), and the set of all possible subsets of Fof lengthw\u0014nas follows. Bw:=fv2Nwjv2P(F)g For a given selection of features, b2Bw, we denote the associated projection Pb: Rn!Rwso that (Pb(x))i=xbiforx2Rnandi= 1;\u0001\u0001\u0001;w. To de ne a metric we consider three cost/penalty functions, M1;M2;andL. The functionLis a function of the cardinality of the number of features selected, L(jbjC). The costsM1andM2, however, measure how well the selection of features can be used to predict the disease state and the discarded features respectively. To accurately evaluate the performance of the predictor a partition of the data must be withheld from the training algorithm, OPT , and used solely for the purpose of testing the performance. For a given set of data, these metrics will vary depending on which data points are used for training OPT and which are used to evaluate its performance. To explicitly account for the e ect of choice in partitioning of data samples, we now de ne the set of samples S:=f1;\u0001\u0001\u0001;mg, and the set of partitions of SasP(S). As for features, we denote the set of sample partitions of length ras Sr:=fv2Nrjv2P(S)g and for a given selection of samples, g2Sr, we denote the associated projected data set asPg(X) :=fxi2X; i2gg. Therefore, the costs M1andM2are a function of the feature partition, b, and the training partition, g2Sr2P(S), so thatM1(b;g) andM2(b;g) are the Root Mean Square Error (MSE) of predicting the test partition ideal case, we would average these costs over all possible partitions of the data set to give an estimate of the predictive power of b2Bw. However, such an approach would result in very large computational overhead. Therefore, we use thek-fold cross validation approach, wherein we divide the samples into ktraining partitions of sizem(k\u00001) k, which we label as g(i)2Sm(k\u00001) kfori= 1;\u0001\u0001\u0001;k. Then the average cost of given weights. First, we let 1= 1 and 2=L(w) = 0 - a case we denoted as the Minimal Disease State (MDS). In this case, we are only concerned with predicting the progression of the disease and are not concerned with predicting non-selected features or with the number of features selected. Therefore, the number of features selected for each algorithm is the number of features which generated the smallest J0(b;g). Second, we let 1= 0 1forw> 10: In this case, we ignore the disease state and are only concerned with reducing the number of features while retaining the ability to reconstruct discarded features - a 136case we denote as the Minimal Immune State (MIS). Finally, we let 1= 2= 1 and L(w) as de ned for the MIS. We denote this nal case as the Minimal Immune and Disease State (MIDS). Now that we have de ned the metric of suitability as a function of the partition, b2Bwwe will de ne the following combinatoric optimization problem. min b2Bw;w2NJ(b) (4.31) To perform feature selection to solve Optimization Problem (4.31) we will use a Sequential Feature Selection (SFS) algorithm as described in [20]. This SFS algorithm begins with b:=;, and iteratively selects a locally optimal feature (with respect to the objective function of Optimization Problem (4.31)) at each step. Clearly, the e ectiveness of Feature Selection depends on the ML algorithm ( OPT ) used to generate the predictive model. Therefore, in the Results subsection, we test all the machine learning algorithms proposed herein. Unfortunately, the accuracy of the predictive model is in uenced by user-selected parameters within the algorithm. For reproducibility, we list here the selections for these parameter values. Linear Regression: We test all 16 combinations of 12[0;0:1;1;5] and 22 [0;0:1;1;5] and select the choice yielding the highest metric ( J). TKL: We use the default TK kernel parameters and test \u000f=:005, andC2 [:01;:1;:3;:5;1] and select the choice yielding the highest metric ( J). SVR: We test all combinations of \u000f=:1,C2[1;5;10] and 3 kernel functions (linear, RBF, or 3rd degree polynomial) and select the choice yielding the highest metric ( J). For the RBF kernel the features are normalized by their variance and a bandwidth of1 nis selected. Random Forest We test 9 combinations of number of trees (n trees2[50;100;150]) and the maximum tree depth of (max depth2[5;10;20]) and select the choice yielding 137the highest metric ( J). Boosted Trees We test 15 combinations of number of trees (n trees2[50;100;150;250]) and learning rate (LR 2[0:01;0:1;0:5]) and select the choice yielding the highest met- ric (J). Alternative feature selection algorithms are used as a baseline by which we may compare the wrapper method. We use three lter methods and one embedded method in the analysis as follows. Filter Methods Given a set of data, lter methods use a rating function to rank each features relative \\importance\". After the features have been ranked, the user may select wfeatures to be kept and the remaining features will be discarded. Mutual Information (MI) The Mutual Information criteria [7] is a statistical function of two random variables that describes the amount of information contained in one random variable relative to the other. Analysis of Variance (ANOVA) The ANOVA method [92] is a commonly used method for analyzing variable dependencies. The F-test is used to estimate the features importance. Principle component analysis (PCA) This method approximates the data with linear manifolds [148]. The main methods used to perform PCA are based on the sin- gular value decomposition and diagonalization of the correlation matrix. We calculate the importance based on the rst 3 eigenvectors. In all cases, once a set of features has been selected, suitability ( J) is determined using each of the ML algorithms and we report the minimum of these values. Embedded Methods 138Embedded FS methods attempt to embed the process of feature selection directly into the model generation process - typically adding a cost for inclusion of a particular feature in the model. These methods have been used for a similar application in gene expression as in [68]. For this analysis, only a single embedded method was considered. Mean Decrease in Impurity (RF) The Gini Importance or Mean Decrease in Impurity [17] is an embedded method for the Random forest algorithm. It calculates the importance of features as the mean of the number of splits (over all trees) that include this feature, weighted by the probability of reaching this node. 4.8.4 Results Here we de ne three immune states generated by varying the weights of the metric. These three immune states are lower dimensional subsets of the data which can be used to either predict the progression of RA, reconstruct the full set of T cell markers and populations, or perform both tasks simultaneously. In all cases the SFS algorithms consistently outperformed the lter and embed- ded methods. For this reason we focus the analysis on the SFS algorithms and the frequency by which the SFS algorithms selected populations of immune system cells. Case 1: Features for Predicting Disease Progression (MDS) First we consider the problem of selecting features that are optimal for predicting the disease progression. Most Important Features Using the SFS Algorithms In Fig. 4.8 we show the observables that were selected by each of the proposed algo- rithms. Counting the number of times a feature was selected by the proposed SFS 139methods, the following features were chosen by at least three of the methods. (1)CD4+GATA3+CD44+CD62(Lo) (3 times) (2)CD4+GATA3+Ki67+ (3 times) (3)CD4+Foxp3+CD25+ (3 times) (4)CD4+Foxp3+CD25+Ki67+Autoantigen (3 times) (5)CD4+Tbet+ (3 times) Among the cytotoxic cells, the algorithms were most consistent, with all ve of the SFS algorithms selecting one feature in common. (6)CD8+Ki67+ (4 times) (7)CD8+GATA3+ (3 times) (8)CD8+Tbet+ (3 times) This group of cells consists of cytotoxic (6,7,8), Th memory (1), Th (2,5), and Treg (3,4) T cell sub-populations. The location feature (origin of the tested cells), was selected only once by an SFS based algorithm. This implies that there is signi cant uniformity in the disease state among the lymph nodes and spleen. In addition, only one selected feature (4) was autoantigen speci c - indicating that most of these T cell markers may be correlated to, not just the progression of RA, but the progression of other similar autoimmune diseases as well. Finally, the MDS consisted of biomarkers that were not data-rich but contained general classes of T cells rather than the more speci c sub-populations selected in the MIS and MIDS cases. This suggests that the disease state is caused by a large 140irregularity in general populations of T cells rather than irregularities in a few smaller speci c populations. In this case we do not include the treatment as a possible feature, since we are primarily interested in the prediction of the disease state using sub-populations of T cells as opposed to the already known correlation between treatment and disease state. In the next two cases treatment is considered a feature. Case 2: Features for Reconstructing Discarded Features (MIS) Next we consider the problem of selecting features that are optimal for recon- structing discarded features to determine a Minimal Immune State. Most Important Features In Fig. 4.9 we show the features that were selected by each of the proposed algo- rithms. Unlike in the previous subsection, there was less of an agreement among the high-performing SFS algorithms as to the most signi cant features. For MIS only 6 di erent features were selected by at least three algorithms. First, if we consider markers speci c to helper and regulatory cells, and counting the number of times a feature was selected by the SFS methods (each method selected 10 features), the following features were each chosen by at least half of the algorithms. (1)CD4+GATA3+CD44+CD62L(Lo) (4 times) (2)CD4+Tbet+Ki67+ (4 times) (3)CD4+GATA3+Ki67+Autoantigen (3 times) (4)CD4+Tbet+Autoantigen (3 times) We note that two of the selected features are autoantigen speci c as opposed to the single autoantigen speci c feature selected for cells in MDS. 141Among the cytotoxic cells, the algorithms were less consistent, with only three of the SFS algorithms selecting similar sub-populations. (5)CD8+Ki67 (3 times) (6)CD8+GATA3+CD44+CD62(Lo) (3 times) We note that the central memory T cells (CD62L) appear in both the helper populations and the cytotoxic cell populations. No regulatory cells were consistently selected by all ve of the top performing algorithms, suggesting that no speci c regulatory cell type was most important for reconstructing the immune state. In this case, data-rich biomarkers (those containing multiple markers), were se- lected slightly more often when compared to MDS. The average number of markers in the selected features is 3.33 in this case compared to 2.875 in the MDS case. This may be due to the fact that estimating the entire immune state is signi cantly more di\u000ecult then simply estimating the disease state alone, and more data-rich markers may therefore be necessary. Of particular note is the fact that the location feature (origin of the tested cells) and the treatment feature (which treatment was applied) were both selected by almost every algorithm. This implies that the immune state is not uniform across the lymph nodes and spleen, and that the speci c treatment given to the mice has a large impact on the immune state. Case 3: Features for Disease Progression and Reconstruction (MIDS) Next we consider the problem of selecting features that are optimal for predicting a combination of the MIS and MDS objectives, the Minimal Immune and Disease State. 142Most Important Features Using the SFS Algorithms In Fig. 4.10 we show the features that were selected by each of the proposed algo- rithms. If we consider markers speci c to helper and regulatory cells, the following features were each chosen by at least three of the ve SFS algorithms. (1)CD4+GATA3+CD44+CD62L(Lo) (4 times) (2)CD4+Tbet+Ki67+ (4 times) (3)CD4+Tbet+Autoantigen (4 times) (4)CD4+GATA3+Ki67+Autoantigen (3 times) As in the MIS case two of the selected features are autoantigen speci c, however no cytotoxic cells were consistently selected by at least three of the SFS algorithms. Similar to the MIS case, no regulatory cells were consistently selected by all ve of the top performing algorithms. Just as in the case of the MIS the location feature (origin of the tested cells) were selected by almost every algorithm and the treatment attribute was likewise selected by every algorithm. However, in this case the algorithms were least consistent on selecting cytotoxic cells, implying that no single cytotoxic cell type was consistently selected to both reconstruct the immune system and determine the disease progression. This would imply, therefore, that the Th cell populations are more essential to both predicting the disease progression and reconstructing the immune state. We note that the memory T cell sub-population CD4+GATA3+CD44+CD62L(Lo) was selected in all three cases. It is clear that this sub-population is signi cant to both the immune and disease states. 1434.9 Conclusion We have proposed an e\u000ecient algorithm for TK kernel learning based on a primal- dual decomposition combined with a FW type algorithm. The set of TK kernels is tractable, dense, and universal, implying that KL algorithms based on TK kernels are more robust than existing machine learning algorithms, an assertion supported by numerical testing on 6 relatively large and randomly selected datasets. We also considered the use of the KL learning problem in the identi cation of three di erent states of the immune system of increasing complexity. Speci cally, we used a set of mouse-model experiments to obtain a robust dataset of T cell markers and populations at the end stage of a proposed immunotherapy treatment. The rst state is the disease state, which is important for tracking the disease progression and predicting the e ectiveness of treatments. Next is the immune state which is the minimal number of sub-populations needed to reconstruct the remaining discarded features. Finally we nd the combined overall immune state for predicting both the disease state and reconstructing the discarded features. From these experiments we were able to determine that the CD4+GATA3+CD44+CD62L(Lo) memory T cell sub-population is signi cant to both the immune state and disease state of mice with RA - and have developed a set of T cell sub-populations important for tracking the disease progression and outcome of immunotherapy. 144(a) An image from Google Maps of a sec- tion of the Grand Canyon corresponding to (36.04, -112.05) latitude and (36.25, -112.3) longitude. (b) Elevation data ( m= 750) from [8] for a section of the Grand Canyon between (36.04, -112.05) latitude and (36.25, -112.3) longitude. (c) Predictor using a hand-tuned Gaussian kernel trained on the elevation data in (b). The Gaussian predictor poorly represents the sharp edge at the north and south rim. (d) Predictor from Algorithm 2 trained on the elevation data in (b). The TK predictor accurately represents the north and south rims of the canyon. Figure 4.6: Sub gure (a) shows a 3D representation of the section of the Grand Canyon to be tted. In (b) we plot elevation data of this section of the Grand Canyon. In (c) we plot the predictor for a hand-tuned Gaussian kernel. In (d) we plot the predictor from Algorithm 2 for d= 2. 145Table 4.2: All classi cations tests are run on a desktop with Intel i7-4960X CPU at 3.60 GHz and with 64 GB of RAM. N/A indicates that the algorithm was stopped after 24 hours without a solution. Dataset Method Accuracy (%) Time (s) Dataset Method Accuracy (%) Time (s) Abalone TKL All regression tests are run on a desktop with Intel i7-5960X CPU at 3.00 GHz and with 128 Gb of RAM. Dataset Method Error Time (s) Dataset Method Error Time (s) Gas squares indicate that the feature selection method (left) selected the feature (top). The methods are ordered from lowest objective function, J(b), at the top to greatest objective at the bottom. The SFS methods and the features most commonly selected by those methods are bolded. 148Figure 4.9: The green squares indicate that the feature selection method (left) selected the feature (top). The methods are ordered from lowest objective function, J(b), at the top to greatest objective at the bottom. The SFS methods and the features most commonly selected by those methods are bolded. 149Figure 4.10: The green squares indicate that the feature selection method (left) se- lected the feature (top). The methods are ordered from lowest objective function, J(b), at the top to greatest objective at the bottom. The SFS methods and the features most commonly selected by those methods are bolded. 150Chapter 5 PREDICTIVE MODELING WITH CONSTRAINED POLYNOMIALS USING SUM-OF-SQUARES PROGRAMMING A number of immunotherapies have been developed to modulate the immune re- sponse when the immune system fails to recognize and eliminate a threat such as cancer, or identi es self antigens as a threat as in Rheumatoid Arthritis. While im- munotherapies are promising, for example as cancer treatments, the question that arises is how to determine an optimal immunotherapy for a patient given the current population of immune system cells [79]. Unfortunately, it is not always clear how exactly an immunotherapy will a ect the immune system cells, nor how the current immune system cells can a ect the immunotherapies e ectiveness. Because the inter- actions between immunotherapies and immune system cells are unclear, generating physics based models, therefore, is not always tractable or e\u000ecient. Rather than relying on physics based models of the immune system, in this chapter we look at data-driven methods for calculating the region of attraction of a system with unknown dynamics. Finding the Region Of Attraction (ROA) of nonlinear Ordinary Di erential Equations (ODEs) is a well-studied and important problem. For instance, estimates of the region of attraction have been used in cases such as verifying and validating ight control [19] and analyzing cancer dormancy equilibria [108]. Unfortunately, in many real-world cases the vector eld de ning the ODE may not be known a priori and there exist few methods which can estimate the ROA. In this chapter we consider systems of the form _x(t) =f(x(t)); x(0) =x0; (5.1) 151wheref:Rn!Rnis the vector eld and x02Rnis the initial condition. Lyapunov functions and their predictive models, by design, must be globally pos- itive. In Section 5.1 we rst consider the problem of generating predictive models that are constrained to be globally positive or positive over a semialgebraic set using polynomial functions. Polynomial functions have been used to model system dynam- ics for system identi cation [23], and have been used to generate predictive models using, for instance, least squares regression [63]. In chapter 1 we showed that the set of Sum-of-Squares polynomials have been used in toolboxes such as SOStools [130] to solve important problems in control systems such as nding a Lyapunov func- tion for a system with known dynamics. In this chapter we show that the class of sum-of-squares polynomials can also be used to model Lyapunov functions given only measured trajectory data of an unknown system. We assume the vector eld is unknown, but trajectory data is available. Specif- ically, de ne g(x0;t) to be the solution map of Eq. (5.1), where g(x;0) =x(0) and d dtg(x;t) =f(g(x;t)) for allx2Rnandt\u00150. Then we assume trajectory data is the form of g(xi;k\u0001t) fork= 1;:::;m andi= 1;:::;m . The question is then how to use this data to estimate the region of attraction. In Section 5.2 we consider generating estimates of a converse Lyapunov function, V(x) =Z1 0kg(x;t)k2dt; (5.2) by observing trajectories g(xi;t) over possibly multiple initial condi- tionsxi. We then search for an optimal sum-of-squares polynomial by solving the least absolute deviations optimization problem, min h2HmX i=1jh(xi)\u0000yij; (5.3) whereHis the convex cone of sum-of-squares polynomials, 1;:::;m to be the given initial conditions and yi=V(xi). We brie y note that there has been 152some work on using trajectory data to t Lyapunov functions for purposes other than estimating the region of attraction [89, 118]. However, these results provide no labeling (i.e. the true or estimated value of V(xi) is unknown) and hence cannot be used to estimate stability regions. Upon obtaining the optimal Lyapunov function V\u00032H, we estimate the region of attraction as a maximal level set of the Lyapunov function. We de ne the level set asV\u0003 =fxjV\u0003(x)\u0014 gand, after selection of , useV\u0003 as the estimate of the ROA. Finally we model the Lyapunov function of the dynamics between cancer cell pop- ulations, and immune system cell populations for a range of immunotherapy treat- ments. We use simulated trajectory data of the population of tumor cells throughout time from various initial values of the immune system cells and a range of immunother- apy treatments. We assume in this case that the e ect of the variation in patient dynamics is negligible when compared to the di erences in the initial conditions of the immune system cells. Therefore the learned Lyapunov function is an average estimate among a collection of di erent patients. We show that the generated model can be used to predict whether an immunother- apy treatment (within the given range) will lead to complete tumor elimination with greater than 90% accuracy over a subset of initial conditions even when patient dy- namics di er. The prediction requires only an initial measurement of the populations of the tumor cells, some immune system cells and a cytokine. We then show that nd- ing an optimal immunotherapy treatment can be formulated as a global polynomial optimization problem using the ROA model as a constraint. 1535.1 Generating Optimal Predictive Models with Sum-of-Squares Polynomial Functions In this section we consider the problem of generating polynomial models that are constrained to be globally positive or positive over a set. Recall the semialgebraic set S:=fx2Rn:gi(x)\u00150; i= 1;:::;lg;where gi2R[x],S6=;andSis compact. We can enforce positivity of a polynomial ponS as follows, min p2Rk[x] \u001bi2Sk[x]8i=0;:::;lC(p) (5.4) such that: p=\u001b0+lX i=1\u001bigi; whereCis an objective function that is being minimized and the giare the poly- nomials in the semialgebraic set S. Letcbe the decision variables that parametrize p, then ifC(p) is linear or quadratic with respect to the vector c, the problem can be e\u000eciently solved as a semi-de nite program using interior point methods such as those in [2] and a suitable solver such to nd the function, p(x) that best maps thexito the corresponding yi. Two metrics used to select the model which best maps inputs to outputs are the least squares and least absolute deviations metric. The least squares and least absolute deviations regression objectives respectively are, C(p) =mX i=1(p(xi)\u0000yi)2and; C (p) =mX i=1jp(xi)\u0000yij: (5.5) The solution to Optimization Problem 5.4 using one of the objective functions in Eq. (5.5), is the degree kpolynomial function that is positive on the set Sand best maps the inputs to the outputs with respect to the given data and selected metric. 154Least Absolute Deviations Here we consider the general problem of how we may t a SOS function, say p: Rn!R+that is guaranteed to be positive on a semialgebraic set Sand that maps fromxitoyiwith minimal error. Perhaps the simplest method of function tting is to minimize some variation onP ikp(xi)\u0000yik. We rst select a computationally inexpensive approach of least absolute deviations, de ned as min p2Rd[x] \u001bi2Sd[x]8i=1;:::;lmX i=1jp(xi)\u0000yij: (5.6) such on S:=fx2Rn:gi(x)\u00150; i= 1;:::;lg. While the objective function is still not linear, we may de ne a dummy variable 2Rmas well as 2 mconstraints to obtain the following optimization problem, min 2Rm (5.6). If we substitute the parameterization \u001bj(x) =ZT d(xi)PjZd(xi) in optimization 155problem (5.7), of ZT d(xi)PjZd(xi) is linear with respect to the elements of P, this optimization problem then has 2 mlinear constraints, jsemide nite matrix decision variables of size q\u0002qand a linear objective function. This problem can then be e\u000eciently solved as a semi-de nite program using interior point methods such as those in [2] and a suitable solver such as mosek [4] or SeDuMi [153]. Least Squares We de ne the least squares version of the constrained polynomial optimization prob- lem as, S:=fx2Rn:gi(x)\u00150; i= 1;:::;lg. While the objective function is not linear, we may de ne a dummy variable 2Rm as well as 2 mconstraints to obtain the following optimization problem, min optimization problem (5.9) since the LMI constraint enforces i\u0015(p(xi)\u0000yi)2. This optimization problem can be cast as an LMI and solved using semi-de nite programming. If we replace \u001bi2S[x] with\u001bi(x) =Zd(x)TPiZd(x) forPi\u00150 optimization problem (5.10), Since the value of ZT d(xi)PjZd(xi) is linear with respect to the elements of P, this optimization problem then has m2x2 LMI constraints, jsemide nite matrix decision variables of size q\u0002qand a linear objective function. This problem can then, like the least absolute deviations version of the optimization problem, be e\u000eciently solved as a semi-de nite program using interior point methods. Ifp(x) is only required to be globally positive everywhere, as in the next section, thenp=\u001b0and the problem only has one semide nite matrix decision variable of sizeq\u0002q. In this case the solution to optimization problem (5.8) and (5.11) returns the optimal function, p\u0003(x) =Zd(x)TP\u0003Zd(x). In the following section we show how these constrained polynomial functions can be used to approximate the Region of Attraction from state measurements of a system with unknown dynamics. 157-2.5 -2 -1.5 -1 -0.5 0 0.5 1 1.5 2 2.5 -3 -2 -1 0123 X1X2 (a) The initial condition data (black circles) used in optimization problem 5.8 for the Van Der Pol Oscillator. The area within the black dotted line is a numerical estimate of the region of attraction of the system using the reverse time dynamics. 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 500.511.522.533.54 XY (b) The initial condition data (black cir- cles) used in optimization problem 5.8 for the Predator-Prey model. The area within the black dotted line is a numerical estimate of the region of attraction of the system us- ing the reverse time dynamics. Figure 5.1: Sub gures (a) and (b) show the initial conditions used to generate the data for optimization problem (5.8). 5.2 Data Based Estimation of the Region of Attraction Recall that we consider systems of the form _x(t) =f(x(t)); x(0) =x0; (5.12) wheref:Rn!Rnis the vector eld and x02Rnis the initial condition. We assume trajectory data is available in the form of g(xi;k\u0001t) fork= 1;:::;m and i= 1;:::;m map of Eq. (5.12). 1585.2.1 Determining the Value of a Converse Lyapunov Function We use trajectory data to de ne inputs of the form xiand associated outputs of the formyi= log(1 +V(xi)) whereVif the converse Lyapunov function de ned in Equation (5.2). If we let g(x;t) be the solution map to the nonlinear ODE, then we de ne our trajectory data to be of the form of vectors a(i;j) =g(xi;j\u0001t) for j= 1;:::;K where \u0001tis the measurement time-step and xiare the initial conditions used to generate the trajectories. Then V(xi) =ZK\u0001t 0kg(x;t)k2dt+V(a(i;K)): If we takeKsu\u000eciently large, we may assume a(i;K)\u00190. If we likewise assume \u0001 t is small, then we make the approximation V(xi) =ZK\u0001t 0kg(x;t)k2dt\u0019KX j=0ka(i;j)k2\u0001t: (5.13) In practice, of course, use a trapezoidal approximation of this integral. Ideally \u0001 tis constant, however, the trapezoidal approximation of the integral does not require that the trajectory be measured on a speci c time step. Thus we may still approximate the converse Lyapunov function in cases where measurements are taken in irregular time steps. We conclude that a given set of trajectories at Ktime instants associated with L initial conditions gives us K\u0001Lvalues ofV(x). However, we do not use V(xi) as our label. This is because V(x) grows very quickly asxapproaches the edge of the region of attraction and decreases quickly near the origin, resulting in several orders of magnitude variation. This variation causes performance issues when solving Optimization Problem (5.8) - points of a smaller magnitude have less in uence on the value of the optimal function V\u0003(x). To resolve this issue we instead use data labels yi=log(1 +V(xi)) as data for the 159optimization algorithm where the values of V(xi) are obtained from Equation (5.13). This means, however, that the actual output from the optimization solver is p\u0003(x) =ZT d(x)P\u0003Zd(x)\u0018=log(1 +V(x)) from whence we may obtain our estimate of the converse function as V\u0003(x) = 10p\u0003(x)\u00001: Note thatp\u0003(x)>0 if and only if V(x)>0 andp\u0003(x) = 0 if and only if V(x) = 0. Furthermore, _V(x(t))\u00140 implies _p\u0003(x(t))\u00140 and hence p\u0003(x) is tting to a valid Lyapunov function for the system - albeit not the original converse from Section 2. Estimating the Region of Attraction Having shown how trajectory data can be used to provide training data to model a Lyapunov function, we now discuss how to use that function to estimate the region of attraction. We denote this tted Lyapunov function as V\u0003(x) = 10ZT d(x)P\u0003Zd(x)\u00001 which is the optimal globally positive sum-of-squares function returned by either Optimization Problem 5.8 or Optimization Problem 5.11. Recall from Chapter 1 that the level set of a Lyapunov function, V :=fx2RnjV(x)\u0014 g can be used as an estimate of the region of attraction if the time derivative of the Lyapunov function is also negative on the level set. However, if Vis the converse Lypaunov function, then any state xwhereVis nite is part of the region of attraction (see [69]). Therefore if one had the exact converse Lyapunov function (5.2), then by choosing a suitably large one could estimate the region of attraction arbitrarily well. In this 160case however we have only an estimate, V\u0003(x), of the Lyapunov function that is optimal with respect to the trajectory data we are given. In areas where we do not have trajectory information V\u0003(x) is not likely to be accurate, so we must consider a metric with which to select . Consider the largest value of the converse Lyapunov function (5.2) of all the tra- jectories used to nd the optimal jfV\u0003(xj)g, 1;:::;m andxjare the initial conditions of the given trajectories. Then we will only consider the level set of our optimal function, V\u0003(x), that is less than or equal to \u0003since this is the smallest value of the actual converse Lyapunov function (5.2) that should contain all of the trajectory measurements. However, it is possible that \u0003may be too large of a value and the estimate of the region of attraction may contain points outside of the true region of attraction S. We will then consider a factor of safety, 0 <\u0011\u00141, to de ne a smaller estimate of the region of attraction. We then have that our estimate for the region of attraction is E\u0011 \u0003:=fxjV\u0003(x)\u0014\u0011 \u0003g; where values of \u0011that are closer to zero result in a smaller, more conservative estimate of the region of attraction when compared to values of \u0011that are closer to one. In cases where test data is available, one may nd the percentage of points that are falsely determined to be within the region of attraction (false positives) and use the proportion of these as a metric for selecting \u0011. For instance, if a more conservative estimate of the region of attraction is needed the value of \u0011can be selected by choosing the largest value of \u0011which has no false positive results on the test set. Next we perform a series of numerical tests to determine the e\u000ecacy of the pro- posed method. 1610 2000 4000 6000 8000 10000 0123456Time (seconds) Number of Initial Conditions (a) The computation time of Optimiza- tion Problem (5.8) versus the number of data points. The black circles indicate a 2nd order polynomial was used and the black stars are 4th order polynomi- als. The black dashed line is the line of best t through these points. 2 4 6 8 10 12 14 16 0246810 12 14 Size of SDP Constraint Time (seconds) (b) The computation time of Optimiza- tion Problem (5.8) versus the size of the semi-de nite matrix, q=\u0000n+d n\u0001 . The black circles are indicate the problem was optimized with 2000 data points and the black stars indicate the problem was op- timized with 4000 data points. Figure 5.2: Sub gures (a) and (b) plot the computation time of Optimization Problem (5.8) with respect to the number of data points (a) and the size of the semi-de nite matrix (b). 5.3 Numerical Tests In this section we provide the results from numerical tests on two nonlinear dynam- ical systems to determine the accuracy of the method and its numerical complexity. Then we perform a deeper analysis of a controlled nonlinear system which has ve state variables. In this case we generate a function which, given a control strategy, returns a model of the Lyapunov function of the system dynamics for the control strategy and can be used to estimate if the initial conditions of the patient are within the ROA. 162Table 5.1: Test set accuracy of the SOS optimal function on the Van Der Pol Oscillator and the Predator-Prey model data. Accuracy of the Lyapunov function is de ned as the sum of the absolute error of the function for each test point divided by the total number of test points. ODE d = 2 d = 4 d = 6 Van Der for Estimating the Region of Attraction Here we perform numerical testing to estimate the performance of the ROA model on new data. Given new trajectory data that was not used to generate the model we calculate the number of initial conditions correctly identi ed as being in the region of attraction, falsely labeled as being in the region of attraction (false positives) and those that are falsely labeled as not being in the region of attraction (false negatives), including how the selection of a ects those values. In addition we examine the e ect of the polynomial degree on the accuracy of the ROA estimate and the accuracy of the region of attraction prediction, V\u0003(x). Example 1: Our rst test system is the Van der Pol oscillator in reverse time, de ned as _x1=\u0000x2 _x2=x1+x2(x2 1\u00001); (5.14) which has a locally asymptotically stable equilibrium point at x1=x2= 0. To generate the data set we use L= 50 di erent initial conditions taken from within the region of attraction, between a radius of 1 and 4 from the equilibrium 163pointx= 0. We simulate the trajectory of the nonlinear ODE for 10 seconds with \u0001t=:1 andK= 100, although we only use the j= 1 through j= 4 time-steps per trajectory for data generation, resulting in 200 data points of the form xi,yi. In addition, we add normally distributed noise scaled as 10\u00002where the labels are typically in the interval yi2[3;13]. Fig. 5.1 shows the initial conditions used to generate the data for optimization problem (5.8). To evaluate the accuracy of the t we generated a second test set of trajectory data with 500 initial conditions xievenly spread in the region of attraction and calculated the value of the converse Lyapunov function at each point. In Table 5.2 we calculate the average least absolute error of the ROA model on a test set of data. Increasing the degree of the ROA model decreased the error on the test set of data indicating that the degree 6 model performed best. A graphical representation of the region of attraction is presented In Fig. 5.3(a) where the true region of attraction of the system Sand the estimated region of attraction for the 6th degree polynomial, E\u0011 \u0003for\u0011= 1 are shown. The 6th degree polynomial correctly identi ed 97 :50% of the test set as being within the region of attraction with a 2 :48% false negative rate and a 0 :02% false positive rate, outperforming the lower degree polynomials in all categories except the false positive rate. In some cases a lower false positive rate may be required; a requirement that can be ful lled by decreasing the value of \u0011which decreases the false positive rate by returning a smaller estimate of the region of attraction. In Table 5.3 we see that decreasing \u0011shrinks the region of attraction, decreasing both the percent of test data correctly categorized and the number of false positives. 164Table 5.2: The percentage of initial conditions that were correctly determined to be within the region of attraction, falsely reported to be within the region of attraction and falsely reported to be outside of the region of attraction by the optimal Lyapunov function obtained from Optimization Problem (5.8). ODE Degree True Pos. False Pos. False Neg. 2 96.16 % 0.00 % 3.84 % Van Der Pol 4 95.92 % 0.00 % 4.08 % 6 97.50 % 0.02 % 2.48 % 2 61.22 % 35.22 3.56 % % 4.22 % 6 96.11 % 2.11 % 1.78 % 2 90.83 % 1.79 % 9.17 % Immune-Dynamics 4 96.33 % 4.98 % 3.67 % 6 81.88% 6.07 % 18.12 % Example 2: The second test system is a biological model of predator-prey dynamics as described in [61], _x=x(\u0000(x\u0000 = 0:5 andc= 2:1. Here represents the minimum density for successful mating, and represents the asymptotic carrying capacity. We are interested then in the region of attraction of the point x= 2:1;andy= 1:98, which is a locally asymptotically stable equilibrium point. The region of attraction of this point is the region over which the predator-prey system will asymptotically converge to a non-zero, desirable, equilibrium point. 165To generate the data set we use L= 50 di erent initial conditions taken from within the region of attraction, between a radius of 1 and 4 from the equilibrium pointx= 2:1;andy= 1:98. We simulate the trajectory of the nonlinear ODE for 10 seconds with \u0001 t=:1 andK= 100, although we only use the j= 1 through j= 4 time-steps per trajectory for data generation, resulting in 200 data points of the form xi,yi. In addition, we add normally distributed noise scaled as 10\u00002where the labels are typically in the interval yi2[3;13]. Fig. 5.1 shows the initial conditions used to generate the data for optimization problem (5.8). In Table 5.2 we calculate the average least absolute error of the ROA model on a test set of data. As in example 1, increasing the degree of the ROA model decreased the error on the test set of data indicating that the degree 6 model performed best. A graphical representation of the region of attraction is presented In Fig. 5.3(b) where the true region of attraction of the system Sand the estimated region of attraction for the 6th degree polynomial, E\u0011 \u0003for\u0011= 1 are shown. The 2nd degree polynomial model performs nearly 30% worse with respect to the accuracy when compared to example 1. Since the predator-prey model has a more complicated region of attraction than example 1, the 2nd degree polynomial is insu\u000ecient to capture this region. In fact we see an increase in accuracy of over 30% from the 2nd degree to the 4th degree sum-of-squares polynomial and the 4th degree polynomial models of example 1 and 2 have similar performance. The 6th degree sum-of-squares polynomial model performed best, correctly iden- ti ed 96:11% of the test set as being within the region of attraction with a 2 :1% false positive rate and a 1 :78% false negative rate. In Table 5.3 we see that decreasing \u0011again decreases the percent of test data correctly categorized, but in this case it causes a signi cant decrease in the number of false positives. In fact when decreasing \u0011from 1 to 0 :8 we have that the false positive rate drops from 2 :11% to 0:00%. 1665.3.2 Computational Complexity of the Optimization Problem Using the data simulated using the nonlinear dynamics of the Examples 1 and 2 we will analyze the computational complexity of the optimization problem. In Fig. 5.2 we plot the computation time for Optimization Problem (5.8) versus: the number of data points in Sub gure (a); and versus the length of the semi-de nite matrixP2Rq(d)\u0002q(d)whereq=\u0000n+d n\u0001 in Sub gure (b). The best least absolute deviations t to the complexity data in Sub gure (a) had a slope of .004 and .005 for the degree two polynomial and the degree four polynomial respectively. Based on the numerical data the complexity of optimization problem (5.8) scales linearly with respect to m, the number of data points used in the optimization prob- lem. With respect to the length of the semi-de nite matrix, the computational com- plexity is sublinear. This implies that modeling problems with large numbers of states or higher degree polynomial models may be computationally expensive. 5.3.3 Modeling the Region of Attraction of a Biological System with Pulsed-Immunotherapy Here we perform an analysis of simulated trajectories of an immunotherapy for the treatment of cancer. We separate the analysis of this system from Examples 1 and 2 because the ROA model can account for changes in the dynamics due to di erent control strategies - unlike the previous two uncontrolled system examples. Rather than modeling a single Lyapunov function, the learned function will return a Lyapunov function for any of the supplied control strategies, of a given form. Then, for a given control strategy, the model of the Lyapunov function can be used to predict whether the initial conditions of the patient are within the ROA assuming the given control strategy is applied. 167-4 -3 -2 -1 0 1 2 3 4 -4 -3 -2 -1 01234 X1X2 (a) The area contained within the black dot- ted line is within the region of attraction of the Van Der Pol Oscillator and the area con- tained within the blue line is the estimate of the region of attraction de ned as E\u0011 \u0003 where\u0011= 1. 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 500.511.522.533.54 XY (b) The area contained within the black dot- ted line is within the region of attraction of the predator-prey model and the area con- tained within the blue line is the estimate of the region of attraction de ned as E\u0011 \u0003 where\u0011= 1. Figure 5.3: Sub gures (a) and (b) show the estimated region of attraction E \u0003versus the true region of attraction identi ed by observing the trajectories of the system in reverse. We consider a nonlinear system developed in [170] with ve state variables, that was rst de ned in Chapter 1, _T(t) values of the constants a0,c0,\u000e0,c1,a1,d,c3,f, andrare as 168de ned in Table 1 in [170], the constant c2= 7;000 represents the addition of an anti-TGF- treatment and g(t) represents a pulsed immunotherapy treatment. These dynamics de ne the relationship between tumor size T, TGF- B, e ector immune cells E, regulatory immune cells Rand activated tumor-speci c cytotoxic T-cells administered as a vaccine V. The e ector immune cells and the immune cells added into the system via vaccination act to deplete the number of tumor cells, while the regulatory cells Rand amount of TGF- ,B, act to decrease the number of e ector immune cells. As opposed to the previous two examples we are primarily interested only in the nal state of one of the variables. In this case we are interested solely in the region of attraction of the tumor dynamics, and while the other variables also reach an equilibrium we are unconcerned with their nal values. Therefore we generate measurements of a converse Lyapunov function as the inte- gral of the tumor state alone, as opposed to the integral of all states as in the previous two examples. We model the input g(t) as a pulsed immunotherapy treatment where the dose is denoted as dv, the period of treatment as pv, and the number of treat- ments asnv. We model the dynamics for 60 days and assume that the treatment will continue for the entire 60 day period to ensure tumor elimination. The inputs for the resulting model are the initial values of T,B,E,R, and the dose and number of treatments dvandnv. The training data is obtained by uniformly sampling initial conditions for T(0)2[0;10],B(0)2[0;:5],E(0)2[50;300],R(0)2 [0;50],V(0) = 0 and dv2[0;10000] and nv2[60;60 7]. The number of doses given varies between once a day to once a week. In addition we simulate variability in the dynamics of each patient by uniformly drawing the coe\u000ecients to be \u000610% of the nominal coe\u000ecient values. To generate the data set we use L= 443 di erent initial conditions taken from 169Table 5.3: The percentage of initial conditions that were correctly determined to be within the region of attraction, falsely reported to be within the region of attraction and falsely reported to be outside of the region of attraction by the optimal Lyapunov function obtained from Optimization Problem (5.8). All examples are for the degree 6 model of the ROA except for the Immune-dynamics which is a degree 4 model. ODE \u0011True Pos. False Pos. False Neg. 0.6 94.64 % 0.00 % 5.36 % Van Der Pol 0.8 96.28 % 0.00 % 3.72 % 1 97.50 % 0.02 % 2.48 % 0.8 92.89 % 0.00 7.11 % % 3.44 % 1 96.11 % 2.11 % 1.78 % 0.8 56.39 % 0.20 43.61 Immune-Dynamics 1 96.33 % 4.98 % 3.67 % within the region of attraction and 557 initial conditions taken outside the region of attraction for a total of 1000 intial conditions. We simulate the trajectory of the nonlinear ODE for 60 days with \u0001 t= 1 day and K= 60. To select an optimal model of the Lyapunov function using points outside of the re- gion of attraction, we will add one additional constraint to optimization problem (5.8) as proposed in [95]. Suppose, fxi;yigm i=1, be the initial conditions and converse Lya- punov function values of initial conditions within the region of attraction, and let fzigmo i=1be initial conditions that do not converge and are thus outside the region of attraction. Then the value of the Lyapunov function at values zimust be greater 170thanymax= arg max iyi. Thus we solve the following modi ed optimization problem to force the Lyapunov function values at zito be greater than ymax. patient variability, the LAD metric used to t pto the given data implies that pshould be a median estimate of the Lyapunov function for all patients. However, the introduction of the previous constraint enforces the Lyapunov function to overestimate the value of the Lyapunov function anywhere a treatment failed to eliminate a patients tumor - increasing the number of true positives and false nega- tives. The Lyapunov function, and thus the ROA estimate, is dependent upon the se- lected treatment strategy. Therefore given a dosage dvand number of doses nv, the resulting polynomial model of the ROA is the semi-algebraic set S=f[T;B;E;R ]2 R4jp(T;B;E;R;d v;nv)\u0014 gwherepis a polynomial returned by the proposed algorithm and is the value of the selected level set. In Table 5.2 we calculate the average least absolute error of the ROA model returned by Optimization Problem (5.17) on a test set of 10,000 data points. Unlike examples 1 and 2, increasing the degree of the ROA model only decreased the error on the test set of data for the degree 4 polynomial model. This implies that the degree 6 model over t to the data and we restrict the analysis to the degree 4 polynomial model. The 4th degree sum-of-squares polynomial correctly identi ed 96 :53% of the test 171set as being within the region of attraction with a 5 :37% false positive rate. In Table 5.3 we see that decreasing \u0011again decreases the percent of test data correctly categorized, but causes a signi cant decrease in the number of false positives. When decreasing\u0011from 1 to 0 :8 we have that the false positive rate drops from 5 :37% to just 0:20% but unfortunately decreases the accuracy of true positives to just 56 :39%. Because of the low rate of false positives, we select a value of \u0011= 1 and the semi- algebraic set of the estimated for given nvanddv, is then S1=f[T;B;E;R ]2R4jp(T;B;E;R;d v;nv)\u00147:4390g: However,pcan be used to do more than just estimate the region of attraction for a given treatment strategy. Instead, suppose we are given the initial conditions, T(0), B(0),E(0) andR(0) of a patient and want to search for a treatment strategy that minimizes the volume of administered immunotherapy but still eliminates the tumor in the patient. Given a patients initial conditions T0,B0,E0andR0(and the model p), solving the following optimization problem will return a predicted open loop treatment strategy, wherex1is the dose and x2is the number of doses, that leads to complete tumor elimination while minimizing the volume of administered immunotherapy. min x2R2x1x2 (5.18) subject to 7 :4390\u0000p(T0;B0;E0;R0;x1;x2)\u00150 Optimization Problem (5.18) is a type of Global Polynomial Optimization (GPO) problem because the objective is bi-linear and pis a polynomial function. In the next chapter we identify a new method for solving such problems. The solution to this problem uses the ROA model to generate a predicted treatment strategy that eliminate the cancer cells while minimizing the amount of treatment administered. 172Thus treatment strategies can be selected without any knowledge of the underlying system dynamics. 5.4 Conclusion We have proposed a new method for tting a polynomial function to given data using least absolute deviations or least squares while additionally constraining the function to be positive over semi-algebraic sets. We validate this approach by mod- eling a a nonnegative Lyapunov function of a system with unknown dynamics, and show that the resulting models are constrained and e ective. The model of the Lyapunov function is then used to estimate the region of at- traction of the nonlinear ODE given only data on the trajectory of the system over a nite set of initial conditions. This method is independent of any knowledge of the vector eld, and the region of attraction can therefore be predicted without requiring the system dynamics to be identi ed. We ran numerical tests on two systems with two states, and one nonlinear controlled system with four states. We show how using the ROA model can be used to identify an optimal pulsed immunotherapy treatment strategy by solving a GPO problem - but leave further analysis of the system to the next chapter. 173Chapter 6 SOLVING GLOBAL POLYNOMIAL OPTIMIZATION PROBLEMS In Chapter 5 we formulated a global polynomial optimization problem whose solution returns an optimal pulsed immunotherapy dosage and period of treatment, that is based on the populations of immune system cells in the patient. In this Chapter we develop a method for solving such global polynomial optimization problems, and analyze the optimal treatments found by solving the optimization problem from the previous chapter. Global Polynomial Optimization (GPO) is de ned as optimization of the form f\u0003:= min x2Rnf(x) (6.1) subject to in decision variables x. As de ned in Eq. 6.1, the GPO problem encompasses many well-studied sub- classes including Linear Programming (LP) [88, 85], Quadratic (QP) [106], and Mixed-Integer Non- linear Programming (MINLP) [99]. Because of its generalized form, almost any op- timization problem can be cast or approximately cast as a GPO, including certain NP-hard problems from economic dispatch [122], optimal power ow [64] and optimal decentralized control [101]. As applied to control theory, GPO can be used for stabil- ity analysis of polynomial dynamical systems by, e.g., verifying polytopic invariants as in [110]. 174More information on the GPO problem can be found in Chapter 2, including other special cases where alternative methods can be used to solve this problem. In this sec- tion however, we propose a polynomial-time algorithm for using SOS estimates of the Greatest Lower Bound (GLB) to extract arbitrarily accurate approximate solutions. Speci cally, de ne the feasible set S:=fx2Rn:gi(x)\u00150; hj(x) = 0g: (6.2) The Greatest Lower Bound (GLB) problem associated to the GPO Problem (6.1) is de ned as \u0015\u0003:=max \u00152R\u0015 (6.3) subject to f(x)\u0000\u0015>0;8x2S: The GLB and GPO problems are closely related in that \u0015\u0003=f\u0003=f(x\u0003), but are not equivalent in that the GLB problem does not nd x\u0003. Our approach is based on the observation that while the GLB problem does not return x\u0003, it can be used as a selection criteria in a bisection algorithm - See Section 6.3. This means that an algorithm which solves the GLB problem with complexity O(k) can be combined with bisection to nd a point x2Rnsuch thatjx\u0000x\u0003j\u0014\u000ffor any\u000fand the resulting complexity is of order O(knlog(r \u000f)) whereris the radius of a hyper-sphere containing all feasible points. In Section 6.4 we propose a sequence of algorithms, Ek, and show that they will return in polynomial-time a point xk2Rnthat is sub-optimal to the GPO problem in the following sense. If xkis the sequence of proposed solutions produced by the sequence of algorithms Ek, we show that if the feasible set, S, of Problem (6.1) is bounded, then there exist a sequence of feasible value of the GPO problem. 175In Section 6.5, we illustrate the e ectiveness of the proposed algorithm by applying it to an example problem wherein the existing moment based approach fails to extract a solution. We then use the algorithm to solve Optimization Problem (5.18) from Chapter (5) to demonstrate how an optimal pulsed immunotherapy treatment can be identi ed even without knowledge of the underlying system dynamics. 6.1 Problem Statement In this chapter, we consider simpli ed GPO problems of the form: such that: gi(x)\u00150 fori= 0;\u0001\u0001\u0001;l wheref;gi2R[x]. The class of problems in (6.4) is equivalent to that in (6.1), where we have simply replaced every hi(x) = 0 constraint with some g1(x) =h(x)\u00150 and g2(x) =h(x)\u00140. For every problem of Form (6.4), we de ne the associated feasible setS:=fx2Rn:gi(x)\u00150g: First we assume S6=;, otherwise there would be no feasible point and therefore no optimal point. Note that given gi, one may use SOS optimization combined with Positivstellensatz results in [152] to determine feasibility of S. Proposed Algorithm In this subsection, we propose a GLB and Branch and Bound- based algorithm which, for any given \u000f>0, will return some x2Rnfor which there exists a point x2Ssuch that: f(x)\u0000f\u0003\u0014\u000f (6.5) Before de ning this algorithm, however, in the following section, we describe some background on the dual SOS and Moment algorithms for generating approximate solutions of the GLB Problem. 1766.2 SOS approach to solving the GLB problem In this section, we brie y describe the use of SOS programming to de ne a hier- archy of GLB problems. Recall from Chapter 2 that the quadratic module is de ned as follows. De nition 35. Given a nite collection of polynomials gi2R[x], we de ne the quadratic module as the degree- kbounded quadratic module as M(k):=fpjp=\u001b0+lX Consider the GPO Problem (6.4) where fgigis an Archimedean representation of the feasible set, S, with associated quadratic module M. We now de ne the degree- unbounded version of the SOS GLB problem. f\u0003=\u0015\u0003:= max \u00152R\u0015 (6.6) such that: f(x)\u0000\u00152M: SinceMis Archimedian, it follows that \u0015\u0003=f\u0003(wheref\u0003is as de ned in (6.4)). Although Problem (6.6) is convex, for practical implementation we must restrict the degree of the SOS polynomials which parameterize M- meaning, we must restrict ourselves to optimization on M(k). This de nes a new sequence of GLB problems as p\u0003 that lim k!1p\u0003 k= p\u0003. Furthermore, it was shown in [141, 116] that bounds on the convergence rate of 177p\u0003 k!\u0015\u0003exist as a function of gi,fandk. Finally, the computational complexity ofpkis equivalent to that of a semide nite program with order ( l+ 1)\u0003(dk 2e)2scalar variables, where lis the (6.4) and \u0003( d) :=\u0000d+n d\u0001 . 6.3 Solving the GPO Problem using the ideal Branch and Bound In this section we show that, given an algorithm that returns the exact solution to the GLB problem, we can design an algorithm that returns x2Rnsuch that jx\u0000x\u0003j\u0014\u000f, using2 log 2nlog(r \u000f) computations of the GLB for any desired accuracy \u000f. The Ideal Branch and Bound Algorithm At every iteration, we have an active hyper-rectangle A(j) the Greatest Lower Bound of \u0015\u0003 i:=max \u00152R\u0015 (6.8) subject to =A1, otherwise A(j+ =A2; 5. Setj=j+ 1 and go to step 2; At termination, we may choose any x2A, which will be accurate within jx\u0000x\u0003j\u0014 r2\u0000j=n. Let us examine these steps in more detail. Initialize the algorithm Since the set Sis compact, there exists some r >0 such thatS\u001aBr(r). We may then initialize A= of all 1's. 178Bisect Bisection of the hypercube occurs along the longest edge. Thus, after n iterations, we are guaranteed a two-fold increase in accuracy. As a result, the largest edge of the hypercube diminishes as 2\u0000k=n, and we need to compute the GLB 2 nlog(r \u000f) times to attain the desired accuracy. Compute the Greatest Lower bound We assume that our solution to the GLB problem is exact. In this case, we are guaranteed that an optimizing xwill always lie inAi. Complexity To attain a desired accuracy of \u000frequiresnlog(r \u000f) log(2)number of bisections, since the largest edge of the hypercube generates a two fold decrease in the error for everynbisections. This means that the GLB must be computed2nlog(r \u000f) log(2)times and if the GLB is of complexity O(k), then the complexity of the ideal algorithm must be O(c1knlog(r \u000f)) wherec1=2 log(2). As an example, consider the simple two variate optimization problem, min x;y2Ry (6.9) subject to x+ 5\u00150; xy\u000010\u00150; 15\u0000x\u0000y\u00150; x2+ 3y2\u0000180 = 0: Conceptually, the rst eight iterations of the ideal branch and bound algorithm for this two variate optimization problem are displayed in Figure 6.1. In this case, the algorithm returns a sequence of nested rectangles A(k). LetA1(k) andA2(k) be the bisection of A(k) and\u0015\u0003(A) be the greatest lower bound over domain A. If the optimal feasible point x\u0003lies in the rectangle A(k), andi(k) = arg minf\u0015\u0003(A1(k));\u0015\u0003(A2(k))g, thenx\u0003is guaranteed to lie in Ai(k). Therefore, by induction, at every iteration k, x\u0003is guaranteed to lie in domain A(k) =Ai(k). Figure 6.1 illustrates the rectangle discarded at each iteration, the optimal point x\u0003 1(which lies in Akat each iteration) and the associated optimal objective values \u0015\u0003(Ai(k)). 179*( 2(1))= 5 *( 1(1))= 8 (Discard 1) x1* Discard 4 Discard 3 Discard 5 Discard 6 *( 1(2))= inf (Discard 2) *( 2(2))= 5Figure 6.1: The ideal and Bound Algorithm applied to the two-variate Opti- mization Problem (6.9). Note that every iteration discards half of the active hyper- rectangle. 6.4 Modi ed Branch and Bound Algorithm Here, we present a slightly modi ed branch and bound algorithm that combined with SOS/Moment relaxations, can approximate the solution to the GPO problem to any desired accuracy, in a certain sense. The Modi ed Branch and Bound Algorithm At every iteration, we have an active hyper-rectangle A= [a;b], a set of feasible rectangles Z=f[ai;bi]gieach [a;b] = 3. max \u00152R\u0015 (6.10) such 7. IfZis empty stop; otherwise set A=ZiwhereZiis the smallest element of Z and goto 2. At termination, the globally optimal point is arg min p2Pf(p), which must be accurate within\u000feven if the local solvers were unable to nd a solution. 6.4.1 The GLB and GD Subroutines Consider GPO Problem (6.4) and suppose the corresponding feasible set S:= fx2Rn:gi(x)\u00150g;is nonempty and compact with S\u001aC(a;b), for associated Archimedean quadratic (bi\u0000xi)(xi\u0000ai). These nomials are then used modi ed feasible set S\\Aas Sab:=fx2Rn:gi(x)\u00150;8i: 1\u0014i\u0014s;wj(x)\u00150;8j: ning the will de ne the kth-order SOS/Moment GLB subroutine, denoted Bk, which calculates the GLB in Step (3) of the Modi ed Branch and Bound Algorithm, and the Sequential Quadratic Program- ming subroutine which calculates a locally optimal point in Step (4) of the Modi ed Branch and Bound Algorithm. 181GLB ; (6.13) whereg0(x) = This allows us to formulate and solve the modi ed k-th order SOS ab and the corresponding dual GLB moment problem. The subroutine returns the k=G[a;b] We may solve the original GPO problem, with the additional constraint that, x2Ai, using the following optimization problem, Gab:= min x2Rnf(x) (6.15) such that: x2S\\Ai; gj(x)\u00150 forj= 0;\u0001\u0001\u0001;l: (6.16) Since the derivatives of polynomial functions are smooth we may use algorithms such as Sequential Quadratic Programming (SQP) to nd a locally optimal solution MATLABs fmincon application of SQP. When the locally optimal solution returned by the SQP is within \u000fof the GLB returned by the GLB subroutine, then x\u0003is a globally optimal solution with \u000ftolerance to the GPO problem on the hyper-rectangle Ai. The locally optimal points returned by the SQP subroutine can also be used to discard hyper-rectangles if the GLB on those hyper-rectangles are greater than f(x\u0003), 182since a globally optimal solution could not possibly exist on that hyper-rectangular set. 6.4.2 Formal De nition of the Modi ed Branch and Bound Algorithm, Ek We now de ne a sequence of Algorithms Eksuch that for any k2N,Ektakes GPO Problem (6.4) and returns an estimated feasible point x\u0003. The Sequence of Algorithms Ek: In the following, we use the notation a bto indicate that the algorithm takes valueband assigns it to a. The parameter lrepresents the number of branch and bound loops and in Theorem 38 is set by the desired accuracy as l > n log2(Lpn \u000f) wherenis the number of variables and Lis a bound on the radius of the feasible set. The inputs to the following algorithm Ekare the functionsfgigandf, the initial hyper-rectangle such that S\u001a[a;b], and the design parameters \u000fandl. The output is the estimated feasible point, x. Algorithm Ek: input:\u000f2R+,l2N,a;b2Rn,f;g1;:::;gs2R[x]. output:x2Rn(as locally optimal solution within \u000fof the GLB, theEkalgorithm can still return a point with guaranteed accuracy. In the following section we will discuss the complexity and accuracy of the sequence of Algorithms Ek. 6.4.3 Convergence and Complexity of Ek In this subsection, we rst show that for any k2N, the greatest lower bounds ob- tained by the subroutine Bkincrease at each iteration of the Branch and Bound loop. Next we show that for any desired accuracy, there exists a su\u000eciently large k, such that Algorithm Ekreturns a proposed solution with that accuracy. Since there are no guarantees on the local solution found using Sequential Quadratic Programming subroutine we assume the algorithm continues for at least literations and provide bounds on the solution returned by Ekin the worst case scenario where the SQP algorithm does not return any feasible points. 184The following lemma gives an algebraic property of the polynomials of the form w(x) = (x\u0000ai)(bi\u0000x) which are used to de ne the augmented feasible set Sab. Lemma 36. Leta\u0014c < d\u0014b2R,g:= (x\u0000a)(b\u0000x)andh:= (x\u0000c)(d\u0000x). Then, there exist ; and 2R, such that g(x) = h(x) + (x+ )2; ; \u00150 Proof. Without loss of generality, one can assume that a= 0 (consider the change of variablez:=x\u0000a). Now letp2:=c,q2:=d\u0000c, andr2:=b\u0000d. First, we consider the case where p2;r26= 0. This leads to two sub-cases: Case 1 :r26=p2. Let =p4+p2q2\u0000p p2r2(p2+q2)(q2+r2) r2\u0000p2; =p4+p2q2 2\u0000p4\u0000p2q2; = + Verifying the equality g(x) = h(x) + (x+ )2is straightforward. To show that ; \u00150, the proof for Case 1. Case 2 :r2=p2. In this case, let =\u00002p2+q2 2; =4p2(p2+q2) q4; = + 1 185Equality and positivity for this case can then be easily veri ed. Now, suppose r2=p2= 0. In this case, simply set = 0; = 1. Ifp2= 0;r26= 0, set = b d\u00001; =b d; = 0. The case p26= 0,r2= 0 is similar to p2= 0,r26= 0,through the change of variable z=b\u0000x. In the following lemma, we use Lemma 36 to show that for any a1; a2; b1; b22Rn such thata1\u0014a2< b 2\u0014b12Rn, the feasible set of the SOS problem solved in Subroutine Bk(a1;b1) is contained in that of Subroutine Bk(a2;b2). Lemma 37. anyk2Nanda\u0014b2Rn, letM(k) abbe quadratic exist \u001bi;!j;22\u0006S such thath=Ps i=0\u001bigi+Pn j=1!jwj;2, whereg0(x) = 1. Hence, we can plug expression for wj;2to have degree dor less. Then for any k\u0015d+ 2 and for any hyper-rectangles C(c;d)\u001aC(a;b), if\u0015(a;b)and\u0015(c;d)are the solutions obtained by Subroutines Bk(a;b) andBk(c;d) applied to GPO Problem (6.4), then Lemma 37 shows that \u0015(a;b)\u0014\u0015(c;d). Now, for a xed k2N, let\u000fandlbe the design parameters of Algorithm Ek applied to Problem (6.1). For m= 0;:::;l , let (\u0015\u0003)m:=\u0015(j\u0003), wherej\u0003is as we de ned iteration mof the loop in Algorithm Ek. Using Lemma 37, it is straightforward to show that ( \u0015\u0003)m\u0014(\u0015\u0003)m+1form\u0014l\u00001. In the next theorem, we will show that for any given \u000f >0, there exist k2N such that Algorithm Ekapplied to GPO Problem (6.4) will provide a point x2Rn satisfying (6.5). Theorem 38. Suppose GPO Problem (6.4) has a nonempty and compact feasible set S. Choosea;b2Rnsuch thatS\u001aC(a;b). For any desired accuracy, 0< \u000f < 1, letl > n log2(Lpn \u000f)whereL= maxibi\u0000ai. Then there exists a k2Nsuch that if x=Ek(\u000f;l;a;b;f;g i), then there exists a feasible point y2Ssuch thatf(y)\u0000f\u0003\u0014\u000f andky\u0000xk<\u000f, wheref\u0003is the objective value of the GPO Problem (6.4) . Proof. De nePto be the set of all possible hyper-rectangles generated by the branch- ing loop of Algorithm Ek(for anyk) with number of branches bounded by l. The vertices of all elements of Pclearly lie on a grid with spacingsjai;bij 2l. Therefore, the cardinalityjPjis nite and bounded as a function of l,aandb. It has been shown that for any C :=C(e;f)2P, there exists a k 2Nsuch that for any k0\u0015k , the solution of Subroutine Bk0(e;f) is accurate with the error tolerance \u000f. Now de ne k:= maxfk jC 2Pg . We will now show that Algorithm Ekreturns a point xwith the desired accuracy. First, we show that Algorithm Ekgenerates exactly lnested hyper-rectangles. The Ek. We use induction on mto show that for all m\u0014l: (C)m\u001a(C)m\u00001: The base case m= 0 is trivial. For the inductive step, rst note that ( \u0015\u0003)m\u0014f\u0003for allm\u0014land (\u0015\u0003)1\u0014\u0001\u0001\u0001\u0014 (\u0015\u0003)l. The latter is obtained from Lemma 37 and the former is because at each iteration, S\u001aSm i=0C(a(i);b(i)). The assumption that the solution of Subroutine Bk0(e;f) is accurate within \u000f, implies that Bk((a)m;(b)m)\u0014(\u0015\u0003)m+\u000f: (6.17) Now we will show that again at iteration m+1 one of the hyper-rectangles ( C(1))m and (C(2))mmust also satisfy Eqn. 6.17. Suppose this is not true. Then we can (\u0015\u0003)m+1<Bk((~a)m;(~b)m)\u0000\u000f; (6.18) 188This contradicts the fact that all Bk((~a)m;(~b)m),Bk((^a)m;(^b)m) andBk((a)m;(b)m) have accuracy higher than \u000f. Therefore, it is clear that either ( C(1))mor (C(2))mwill be bisected at iteration m+ 1. This fact, together with the induction hypothesis which certi es that ( C)mpossesses the smallest volume between all the hyper-rectangles obtained up to that iteration, guaranteeing that either ( C(1))mor (C(2))m, will be branched at the next iteration. Therefore, the algorithm will generate lnested hyper- rectangles. ( (\u0015)m2[f\u0003\u0000\u000f;f\u0003+\u000f];8m= 1;:::;l: (6.22) Finally, as a special case one can write: f\u0003\u0000\u000f\u0014Bk((a)l;(b)l)\u0014f\u0003+\u000f: Now, note that the \u000f-accuracy of Bk((a)l;(b)l) implies that ( C)lis feasible. It also be implied that ( C)l\\Scontainsysuch thatf(y)\u0015Bk((a)l;(b)l)\u0015f(y)\u0000\u000f. Therefore,jf(y)\u0000f\u0003j\u0014\u000f: Finally, ifxis the point return Ek, then based on the de nition ofl, it is implied that after the last iteration m=l\u00001, the largest diagonal of the branched hyper-rectangle is less than \u000f, henceky\u0000xk2\u0014\u000f, as desired. Theorem 38 ensures that for any accuracy \u000f >0 there exists a k2Nsuch that AlgorithmEkreturns\u000f-approximate solutions to the GPO problem with a logarithmic bound on the number of branching loops. The following corollary shows that these \u000f-approximate solutions can themselves approximately satisfy the constraints of the original GPO as follows. 189Corollary 39. Let GPO Problem (6.4) have nonempty and compact feasible set that is contained in C(a;b)for somea;b2Rn. For any given \u000e >0, there exists \u000f such that if the conditions in Theorem 38, then jf(x)\u0000f\u0003j\u0014\u000eandgi(x)\u0015\u0000\u000e;8i= 1;:::;s: Proof. LetLbe such that any polynomial h2ff;g1;:::;gsgsatis esjh(c)\u0000h(d)j\u0014 Ljc\u0000dj2;8c;d2C(a;b). (Existence of Lfollows from the Lipschitz polynomials on compact sets.) Choose \u000fsuch that\u000f\u0014\u000e=L. Let\u000fandxsatisfy the conditions in Thoerem 38. It is straightforward to show that xsatis es Eq. (6.23). Unfortunately, of course, Theorem 38 does not provide a bound on the size of k(although the proof implies an exponential bound). Fortunately, the SQP step of algorithmEkoften nds the optimal point after just a few iterations of the algorithm, implying that even if kis not large enough, an \u000f-approximate solution can still be found. Table 6.1: A comparison of starting conditions of interior point method and the resulting number of suboptimal (OBV <f( ^x2)) or failed solutions over 50 trials. Max Perturbation Suboptimal No Solution Trials \u00061 8 1 50 \u00062 16 0 50 \u00065 24 2 50 \u000610 36 2 50 1906.5 Numerical Results Here we consider two applications of the GPO algorithm proposed in this chapter. In the rst example we illustrate the importance of using the GPO method over local solvers. In the second example we analyze the region of attraction model for a pulsed immunotherapy cancer treatment that was generated in Chapter 5 to select an optimal treatment strategy. Example 1: Consider the following GPO problem. In this example we have 6 variables, an objective function of degree 4 and several equality and inequality constraints of degree 4 or less. Polynomial optimization prob- lems similar to this example are important in economic dispatch models [122] or optimal power ow [64] and since the ideal generated by equality constraints in this case are not zero dimensional, the Moment approach to extracting solutions fails. We applied Algorithm E5to this problem with parameters \u000f= 0:005 andl= 200, using Sedumi to solve the SDPs associated with the SOS and Moment problems. The result is the point ^ x= [5:1274;3:9372;0:8043;\u00004:6793;4:2704;\u00004:1748], where all inequalities are feasible and the equality constraints h1andh2have errors 1910 10 20 30 40 50 60 Time (days)01020304050Tumor Volume)(a) The simulated tumor volume of the example problem using the optimal pulsed immunotherapy treatment gen- erated by solving Optimization Prob- lem (6.24). (b) The simulated tumor volume of 1000 randomized initial conditions using the optimal pulsed immunotherapy treat- ment generated by solving Optimization Problem (6.24) for each problem set of initial conditions. Figure 6.2: Sub gures (a) and (b) plot simulations of tumor dynamics using the optimal pulsed immunotherapy treatments found using the GPO algorithm. of 1:015\u000210\u00009and 0:019\u000210\u00009respectively. Furthermore, the objective value is f(^x) =\u00003719 which closely tracks the GLB value of \u00003718:94. To illustrate the importance of using this branch and bound technique over run- ning the SQP algorithm with random initial guesses, we ran several batteries of tests, successively decreasing the accuracy of the initial guess. Using ^ xas the centroid, we proposed 50 randomly distributed initial guesses within a radius of 1 ;2;5 and 10. These results are listed in Table 6.1 and indicate the increasing number of initial guesses which resulted in either local optima or no feasible solution - ultimately at 76% for maximum radius 10. Example 2: In this example we use the GPO solver to identify optimal treatments using the ROA model of tumor-immune dynamics from Chapter 5. The system dy- 192namics are detailed in Eq. (1.7) in Chapter 1. These dynamics de ne the relationship between tumor size T, TGF- B, e ector immune cells E, regulatory immune cells Rand activated tumor-speci c cytotoxic T-cells administered as a vaccine V. In Chapter 5 we found an optimal data-driven model of the region of attraction for a given dosage dvand number of doses nvde ned as the following semi-algebraic set, S1:=f[T;B;E;R ]2R4jp(T;B;E;R;d v;nv)\u00147:4390g: To demonstrate how the combination of the ROA model and the GPO solution can identify optimal data-driven controllers for pulsed immunotherapy treatment we sim- ulate a test case. Assume we have a patient with nominal system parameters and the following initial conditions, T(0) = 5,B(0) = 0:1,E(0) = 100,R(0) = 50. Using these initial conditions we can de ne a semialgebraic set of all treatment parameters, dvandnvwhich are predicted to eliminate the tumor in 60 days. This set is de ned the model is accurate we may solve the following optimization problem to identify an optimal treatment strategy for this patient. min x2R2dvnv (6.24) subject to [ dv;nv]2R1: We pulsed immunotherapy treatment of approx- imately 2000 cells injected at a period of every 2 :25 days. After simulation it was 193con rmed that this pulsed immunotherapy treatment does successfully eliminate the tumor cells within 60 days. We show the population of tumor cells throughout time for this nominal case in Fig. 6.2(a). Since this data-driven modeling of the ROA is not exact we next test the ro- bustness of the optimal solutions. To test the robustness of the optimal treatments we randomly generate 1,000 di erent patients whose dynamic constants vary within \u000610% and whose initial conditions are within T(0)2[2;6];B(0)2[0:05;0:15];E(0)2 [90;110];R(0)2[40;60]. We found that 75 :00% of the optimal treatments found using Optimization Problem (6.24) eliminated the tumor within 60 day. In Fig. 6.2(b) we plot the volume of tumor cells throughout time after applying the optimal treatment. To determine how close to optimal the treatments are we decreased the dosage by 10% and found that only 35 :69% of the treatments led to tumor elimination within 60 days. Likewise only 34 :68% of treatments eliminated the tumor when the period of treatment was increased by 10% of the optimal value. When decreasing the dosage by 10% and increasing the period by 10% only 3 :85% of the cases eliminated the tumor within 60 days, implying that over 71% of the treatments eliminated the cancer cells and were within 10% of the optimal dose and period. 6.6 Conclusion We have proposed a sequence of Algorithms Ek; k2Nto extract solutions to the GPO problem based on a combination of Branch and Bound and SOS/Moment relax- ations. The computational-complexity of Algorithm Ekis polynomial in k, polynomial in the number of constraints and linear in the number of branches l. Additionally, for any scalar\u000f >0, there k2Nsuch that Algorithms Ek, innlog(r \u000f) number of iterations, returns a point that is within the \u000f-distance of a feasible and \u000f-suboptimal point. For a xed degree of semide nite relaxations, our numerical case study demon- 194strates convergence to an \u000f-suboptimal point returned by the Ekalgorithm. Additionally we were able to use the GPO algorithm in conjunction with a ROA model from Chapter 5 to select optimal pulsed immunotherapy treatments for the treatment of cancer. This method did not require any system models to be known, instead relying on trajectory measurements to build a semialgebraic set used to model the region of attraction, and the GPO algorithm to select an optimal point contained within the model. Applying such a model in practice would require only an initial measurement of the tumor volume, levels of TGF- , and amounts of e ector and regulatory immune cells. 195Chapter 7 CONCLUSION Motivated by three problems to generate better predictive models of the immune system, we formulated convex optimization problems to generate improved data- driven models of physical processes. These methods were applied to determine cellular characteristics that di er most between healthy patients and those with rheumatoid arthritis; identify populations of immune system cells that are most correlated to the severity of rheumatoid arthritis in mice; and select an optimal dosage and period of an immunotherapy treatment for cancer based upon the size of the tumor, initial populations of e ector and regulatory cell types, and the amount of a cytokine signal in the tumor environment. In this chapter we present concluding remarks for each problem. Problem 1: Generating Models of the Distribution of Measured Data In Chapter 3 we propose convex optimization problems to select optimal parameter of Sliced Distribution PDFs to model the density of a random variable. Unlike other sets of distributions, SD PDFs are dense in the set of all bounded PDFs in L1(\u0001). This implies that we can use SDs to model the PDF of a random variable while making only a few minor assumptions on the physical process which generated the data. Additionally, we formulated convex optimization problems to select optimal parameters for the SDs, so the globally optimal member of the degree bounded set of distributions is guaranteed to be found, unlike other sets of PDFs such as Gaussian mixture models. The performance of SDs is compared to multivariate normals and Guassian mix- ture models using two metrics to demonstrate that the proposed methods have supe- 196rior performance with respect to modeling the distribution of random variables. The rst metric is based on the likelihood of the models to generate a test partition of the data, while the second is based on the volume of the level sets of the PDFs that most tightly contain the test partition of the data. In both cases methods using the pro- posed SDs perform better than the other tested distributions, though this improved performance comes at an increase in computation time. Finally we show that SDs may be used to model the variation in immune system cell characteristics measured from mice with RA as well as healthy mice. By com- paring the models generated for both groups, we identi ed a set of immune system characteristics that di ered most between healthy and diseased mice. These \\immune features\" could be used to perfectly di erentiate between mass cytometry datasets taken from diseased and healthy mice, illustrating that the PDF models captured essential features of the immune system that di er after the onset of RA. Problem 2: Generating Optimal Machine Learning Algorithms In Chapter 4 we proposed an e\u000ecient kernel learning algorithm which met three criteria to ensure the resulting predictors are robust. Speci cally we introduced an e\u000ecient TK kernel learning algorithm based on a FW type algorithm which simulta- neously selects an optimal TK kernel function and generates a predictor using that kernel function. While the average computation time of the TK kernel learning algo- rithm is larger than the other methods, the set of TK kernels is tractable, dense, and universal, implying that KL algorithms based on TK kernels are more robust than existing machine learning algorithms. This assertion is supported by numerical test- ing on 12 moderately sized and randomly selected datasets, which yielded increases in the average accuracy of the TK kernel learning algorithm over other state-of-the-art alternatives. 197We also considered the use of the KL learning problem in the identi cation of three di erent states of the immune system of increasing complexity. Speci cally, we used a set of mouse-model experiments to obtain a robust dataset of T cell markers and populations at the end stage of a proposed immunotherapy treatment. From these experiments we were able to determine that the CD4+GATA3+CD44+CD62L(Lo) memory T cell sub-population is a signi cant population in that it is identi ed as an essential component of the immune system and an essential component for estimating the disease severity of mice with RA. Other immune system cell populations were also identi ed that are highly correlated with, for example, estimating the disease severity, or estimating the populations of other immune system cells. Problem 3: Generating Constrained Predictive Models and Identifying Optimal Treatments In Chapter 5 we solve the problem of generating predictive models that are con- strained to be, for example, globally positive. We formulate a convex method to optimize the parameters of a polynomial function to t given data with respect to the least squares or least absolute deviations metrics and constraint the function to be either globally positive, and thus a sum-of-squares polynomial, or to be positive over a semi-algebraic set. This method was used to generate predictive models of a converse Lyapunov func- tion from trajectory data taken from a dynamical system. This dynamical system models the relationship between tumor cells, immune system cells, and cytokines for a given immunotherapy treatment. We assume that variability in the dynamical sys- tems for di erent patients has a minor e ect on the ROA, and that di erent patient trajectories can be combined to model the average Lyapunov function of a group of patients. Speci cally, given trajectories from patients given pulsed immunotherapy 198treatments of di erent periods and dosages, we t a function that generates a pre- diction of the region of attraction of the system for a given period and dosage of therapy. Given the initial conditions of a patients immune system, the model can also be used to predict if a given dosage and period of treatment will lead to elimination of the tumor. Fortunately, for a set of initial conditions, the model of the dosage and period of treatment that leads to complete tumor elimination in 60 days is a semi- algebraic set. Therefore, given the initial conditions of a patients immune system, we may solve a global polynomial optimization problem to select a treatment that is predicted to eliminate the tumor within 60 days while minimizing the total dosage of treatment. Next in Chapter 6 we proposed a sequence of Algorithms Ek; k2Nto ex- tract solutions to GPO problems based on a combination of Branch and Bound and SOS/Moment relaxations. The computational-complexity of Algorithm Ekis poly- nomial ink, polynomial in the number of constraints and linear in the number of branchesl. Additionally, for any scalar \u000f > 0, there exist a k2Nsuch that Al- gorithmsEk, inO(log(1=\u000f)) number of iterations, returns a point that is within the \u000f-distance of a feasible and \u000f-suboptimal point. For a xed degree of semide nite relaxations, our numerical case study demonstrated convergence to an \u000f-suboptimal point returned by the Ekalgorithm. This GPO algorithm was applied to solve the GPO problem formulated in Chap- ter 5 to select an optimal dosage and period of a pulsed immunotherapy treatment to eliminate the tumor cells. This method thus relies only on trajectory measurements to generate a semialgebraic set that estimates the region of attraction. This region of attraction estimate is then used to generate a GPO problem which is solved with the GPO algorithm to select an optimal dosage and treatment period. The simulations 199of the immunotherapy model show that over 84% of the treatments returned by the GPO algorithm are within 10% of the optimal treatment strategy, implying that even though the dynamical systems of the patient di ered slightly, the ROA estimate was still able to nd e ective treatments for a majority of patients. 200REFERENCES [1] A. Ahmadi, M. Krstic, and P. Parrilo. A globally asymptotically stable polyno- mial vector eld with no polynomial lyapunov function. In Decision and Control and European Control Conference , pages 7579{7580, 2011. [2] ods for semide nite programming: convergence rates, stability and numerical results. SIAM Journal on Optimization , 8(3), 1998. semide nite programming: convergence rates, stability and numerical results. SIAM Journal on Optimization , 8(3):746{768, 1998. [4] M. ApS. The MOSEK optimization toolbox for MATLAB manual. Version 7.1 (Revision 28). , 2015. [5] J. Arciero, T. Jackson, and D. Kirschner. A mathematical model of tumor- immune evasion and sirna treatment. Discrete & Continuous Dynamical Systems-B , 4(1):39, 2004. [6] D. C. Bailey. Not normal: the uncertainties of scienti c measurements. Royal Society open science , 4, 2017. [7] R. Battiti. Using mutual information for selecting features in supervised neural net learning. IEEE transactions on neural networks , 5(4), 1994. [8] J. Becker, D. Sandwell, W. Smith, J. Braud, B. Binder, J. Depner, D. Fabre, J. Factor, S. Ingalls, S. Kim, et al. Global bathymetry and elevation data at 30 arc seconds resolution: Srtm30 plus. Marine Geodesy Moriconi, A. Schoellig, and A. Krause. Safe learning of regions of attraction for uncertain, nonlinear systems with gaussian processes. InProceedings on Decision and Control 2016. [10] D. Bertsekas. Nonlinear programming . Athena Scienti c, 2 edition, 1998. [11] C. M. Bishop. Pattern recognition. Machine learning , 128(9), 2006. [12] R. Bono, M. J. G\u0013 omez-Benito. Non-normal distri- butions commonly used in health, education, and social sciences: a systematic review. Frontiers in psychology , 8, 2017. [13] K. M. Borgwardt, Kriegel, B. Sch\u007f olkopf, and A. J. Smola. Integrating structured biological data by kernel maximum mean discrepancy. Bioinformatics , 2006. [14] B. Boser, I. training algorithm for optimal mar- gin classi ers. In Proceedings of the fth annual workshop on Computational learning theory , 1992. 201[15] M. Branicky. Multiple lyapunov functions and other analysis tools for switched and hybrid systems. IEEE Transactions on Automatic Control , 43(4), 1998. [16] L. Breiman. Random forests. Machine Learning 45:5{32, 2004. [17] L. Breiman, J. Friedman, R. P. Brodin and M. Davis. system variation. Nature reviews immunology , 17(1):21{29, 2017. [19] A. Chakraborty, P. Seiler, region of attraction analysis for ight control veri cation and validation. Control Engineering Practice (4):335{345, 2011. [20] G. Chandrashekar and F. Sahin. A survey on feature selection methods. Com- puters and Electrical Engineering , 40(1), 2014. [21] C. Chang, Y.-C. Chen, H.-M. Chen, N.-S. Yang, and W.-C. Yang. Natural cures for type 1 diabetes: a review of phytochemicals, biological actions, and clinical potential. Current Medicinal Chemistry , 20(7):899{907, 2013. [22] C.-C. Chang and C.-J. Lin. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology , 2:27:1{27:27, 2011. Software available at http://www.csie.ntu.edu.tw/ cjlin/libsvm . [23] S. Chen and S. Billings. Representations of non-linear systems: the narmax model. International journal of control , 49(3), 1989. [24] T. Chen and C. Guestrin. XGBoost: A scalable tree boosting system. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , 2016. [25] G. Chesi. Lmi techniques for optimization over polynomials in control: a survey. IEEE Transactions on Automatic Control , 2010. [26] H.-D. Chiang, M. Hirsch, and F. Wu. Stability regions of nonlinear autonomous dynamical systems. IEEE Transactions on Automatic Control , 1988. [27] B. Colbert and M. Peet. Using trajectory measurements to estimate the region of attraction of nonlinear systems. In 2018 IEEE Conference on Decision and Control (CDC) , pages 2341{2347, 2018. [28] B. Colbert and M. Peet. Using sdp to parameterize universal kernel functions. In 2019 IEEE 58th Conference on Decision and Control (CDC) , pages 4622{4629, 2019. [29] B. Colbert and M. Peet. A convex parametrization of a new class of universal kernel functions. Journal of Machine Learning Research , 21(45):1{29, 2020. URL http://jmlr.org/papers/v21/19-594.html . 202[30] A tessellated kernel learning, 2020. [31] B. Colbert, H. Mohammadi, and M. Peet. Combining sos with branch and bound to isolate global solutions of polynomial optimization problems. In 2018 Annual American Control Conference (ACC) , pages 2190{2197, 2018. [32] B. Colbert, L. Crespo, and M. Peet. A sum of squares optimization approach to uncertainty quanti cation. In 2019 American Control Conference (ACC) , pages 5378{5384, 2019. [33] B. Colbert, L. Crespo, and M. Peet. A convex optimization approach to im- proving suboptimal hyperparameters of sliced normal distributions. In 2020 American Control Conference (ACC) , pages 4478{4483, 2020. [34] M. Collins and N. Du y. Convolution kernels for natural language. In Advances in Neural Information Processing Systems , volume 14, 2002. [35] W. Cook, T. Koch, D. E. Ste y, and K. Wolter. A hybrid branch-and-bound approach for exact rational mixed-integer programming. Mathematical Pro- gramming Computation , 5(3), 2013. [36] networks. Machine learning , 20(3), 1995. [37] C. Cortes, M. Mohri, and A. Rostamizadeh. Learning non-linear combinations of kernels. In Advances in Neural Information Processing Systems , volume 22, 2009. [38] C. Cortes, M. Mohri, and A. Rostamizadeh. Two-stage learning kernel algo- rithms. Proceedings of the 27th International Conference on Machine Learning , 2010. [39] C. Cortes, M. Mohri, and A. Rostamizadeh. Algorithms for learning kernels based on centered alignment. Journal of Machine Learning Research , 13(28): 795{828, 2012. [40] L. Crespo, B. Colbert, T. Slagel, and S. Kenny. Robust estimation of sliced- exponential distributions. In Proceedings of the IEEE Conference on Decision and Control , 2021. [41] L. G. Crespo, B. K. Colbert, S. P. Kenny, and D. P. Giesy. On the quanti cation of aleatory and epistemic uncertainty using sliced-normal distributions. Systems & Control Letters , 2019. [42] M. Dash and H. Liu. Feature selection for classi cation. Intelligent data anal- ysis, 1, 1997. [43] B. DeVolder, J. Glimm, J. Grove, Y. Kang, Y. Lee, K. Pao, D. Sharp, and K. Ye. Uncertainty quanti cation for multiscale simulations. J. Fluids Eng. , 124(1), 2002. 203[44] A. C. Doherty, P. A. Parrilo, and F. M. Spedalieri. Complete family of separa- bility criteria. Physical Review A , 2004. [45] M. Doherty and M. Robertson. Some early trends in immunology. TRENDS in Immunology , 25(12):623{631, 2004. [46] D. Dua and C. learning 2017. and H.-H. systems: analysis, design and applications . CRC Press, 1 edition, 2013. [48] J. Egozcue, and V. Pawlowsky-Glahn. 22(4):1175{1182, 2006. [49] H. El-Gabalawy and P. Lipsky. Why do we not have a cure for rheumatoid arthritis? Arthritis Research & Therapy , 4(3):1{5, El-Samad, S. Prajna, A. Papachristodoulou, M. Khammash, and J. Doyle. Model validation and robust stability analysis of the bacterial heat shock re- sponse using sostools. IEEE Conference on Decision and Control , 2003. [51] S. R. Eliason. Maximum likelihood estimation: Logic and practice . Sage, 1993. [52] E. Eskin, J. Weston, W. Noble, and C. Leslie. Mismatch string kernels for svm protein classi cation. In Advances in Neural Information Processing Systems , volume 15, 2003. [53] K. Fan. Minimax theorems. Proceedings of the National Academy of Sciences of the United States of America , 39(1):42, 1953. [54] Y. Fang, K. Loparo, and X. Feng. Inequalities for the trace of matrix product. IEEE Transactions on Automatic Control , 39(12):2489{2490, 1994. [55] R. Fisher. Contributions to mathematical statistics. Biometrika , 1950. [56] M. F. Flajnik and M. Kasahara. Origin and evolution of the adaptive immune system: genetic events and selective pressures. Nature Reviews Genetics , 11(1): 47{59, 2010. [57] G. B. Folland. Real analysis: modern techniques and their applications , vol- ume 40. John Wiley & Sons, 1999. [58] K. Gai, G. Chen, and C.-S. Zhang. Learning kernels with radiuses of mini- mum enclosing balls. In Advances in Neural Information Processing Systems , volume 23, 2010. [59] T. G\u007f artner, P. Flach, and S. Wrobel. On graph kernels: Hardness results and e\u000ecient alternatives. In Learning Theory and Kernel Machines , pages 129{143. Springer, 2003. 204[60] M. Gasca and T. On the history of multivariate polynomial interpolation. InNumerical Analysis: Historical Developments in the 20th Century , pages 135{147. Elsevier, 2001. [61] M. Gatto and S. Rinaldi. Stability analysis of predator-prey models via the liapunov method. Bulletin of mathematical biology , 39(3), 1977. [62] R. Genesio, M. Tartaglia, and A. Vicino. On the estimation of asymptotic stability regions: State of the art and new proposals. IEEE Transactions on Automatic Control , 30(8):747{755, 1985. [63] J. Gergonne. The application of the method of least squares to the interpolation of sequences. Optimal power ow as a polynomial optimization problem. IEEE Transactions on Power Systems , 31(1), 2016. [65] M. G\u007f onen and E. Alpaydin. Localized multiple kernel learning. In Proceedings of the International Conference on Machine learning , page 352359, 2008. [66] M. G\u007f onen and E. Alpayd\u0010n. Multiple kernel learning algorithms. Journal of Machine Learning Research , 12(64):2211{2268, 2011. [67] L. Gu. Multivariate gaussian distribution. Technical CMU, 2008. [68] I. Guyon, J. Weston, S. Barnhill, and V. Vapnik. Gene selection for cancer classi cation using support vector machines. Machine Learning , 46, 2004. [69] W. Hahn. The converse of the stability theorems. In Stability of Motion . Springer, 1967. [70] F. Hamidi, H. Jerbi, W. Aggoune, M. Djemai, and M. N. Abdkrim. Enlarg- ing region of attraction via LMI-based approach and Genetic Algorithm. In Communications, Computing and Control Applications , 2011. [71] D. Haussler. Convolution kernels on discrete structures. Technical report, Uni- versity of California in Santa Cruz, 1999. Control , chapter Detect- ing Global Optimality and Extracting Solutions in GloptiPoly, pages 293{310. Springer, 2005. [74] F. S. Hodi, S. J. O'Day, D. F. McDermott, R. W. Weber, J. A. Sosman, J. B. Haanen, R. Gonzalez, C. Robert, D. Schadendorf, J. C. Hassel, et al. Improved survival with ipilimumab in patients with metastatic melanoma. New England Journal of , 363(8):711{723, T. H\u007f ofer, O. Krichevsky, and Altan-Bonnet. Competition for il-2 between regulatory and e ector t cells to chisel immune responses. Frontiers in im- munology , 3:268, 2012. [76] J. Hu, A. Perer, and F. Wang. Data driven analytics for personalized healthcare. InHealthcare Information Management Systems . Springer, 2016. Frank-Wolfe: Projection-free sparse convex optimization. InProceedings of the 30th international conference on machine learning , 2013. [78] A. Jain, S. Vishwanathan, and M. Varma. SPF-GMKL: generalized multiple kernel learning with a million kernels. In Proceedings of the ACM International Conference on Knowledge Discovery and Data Mining , pages 750{758, 2012. [79] L. Jeanbart and M. Swartz. Engineering opportunities in cancer immunother- apy. Proceedings of the National Academy of Sciences , 112(47):14467{14472, 2015. [80] P. Johansen, T. Storni, L. Rettig, Z. Qiu, A. Der-Sarkissian, K. Smith, V. Manolova, K. Lang, G. Senti, B. ullhaupt, et al. Antigen kinetics de- termines immune reactivity. Proceedings of the National Academy of Sciences , 105(13):5189{5194, 2008. [81] quadratic lyapunov functions hybrid Transactions on Automatic Control , 43(4), 1998. [82] M. Jones, H. Mohammadi, and M. Peet. Estimating the region of attraction using polynomial optimization: A converse Lyapunov result. In Proceedings of the IEEE Conference on Decision and Control , 2017. [83] M. Shabany. Cu -less high- accuracy calibration-free blood pressure estimation using pulse transit time. In 2015 IEEE international symposium on circuits and systems (ISCAS) , 2015. [84] A. Kann and J. P. Weyant. Approaches for performing uncertainty analysis in large-scale energy/economic policy models. Environmental Modeling & Assess- ment , 5, 2000. [85] N. Karmarkar. A new polynomial-time algorithm for linear programming. 4, Kaya, P. T\u007f ufekci, and F. G\u007f urgen. Local and global learning methods for predicting power of a combined gas & steam turbine. In Proceedings of the international conference on emerging trends in computer and electronics engi- neering , pages 13{18, 2012. [87] D. Ke, C. Chung, and Y. Sun. A novel probabilistic optimal power ow model with uncertain wind power generation described by customized gaussian mix- ture model. IEEE Transactions on Sustainable Energy , 2015. 206[88] L. Khachiyan. Polynomial algorithms in linear programming. USSR Computa- tional Mathematics and Mathematical Physics , 20(1), 1980. [89] S. Khansari-Zadeh and A. Billard. Learning control Lyapunov function to en- sure stability of dynamical system-based robot reaching motions. Robotics and Autonomous Systems , 62(6), 2014. [90] H.-J. Kim, B. Verbinnen, X. Tang, L. Lu, and H. Cantor. Inhibition of follicular t-helper cells by cd8+ regulatory t cells is essential for self tolerance. Nature , 467(7313):328{332, 2010. [91] P. Kim, P. Lee, and D. Levy. Emergent group dynamics governed by regulatory cells produce a robust primary t cell response. Bulletin of mathematical biology , 72(3):611{644, 2010. [92] M. Kumar, N. K. Rath, A. and S. Rath. Feature selection and classi ca- tion of microarray data using mapreduce based anova k-nearest Procedia Computer Science , 54, 2015. [93] Z. Kvatadze and T. Shervashidze. On the accuracy of kraft upper bound for the l1-distance between gaussian densities in rk. Georgian Mathematical Journal , 12, 2005. [94] O. Laerum and T. Farsund. Clinical application of ow cytometry: a review. Cytometry: The Journal of the International Society for Analytical Cytology , 2 (1):1{13, 1981. [95] B. Lai, T. Cunis, and L. Burlion. Nonlinear trajectory based region of attraction estimation for aircraft analysis. In AIAA Scitech 2021 Forum , 2021. P. Bartlett, L. El Ghaoui, and M. Jordan. Learning the kernel matrix with semide nite programming. Journal of Machine Learning Research , 2004. [97] J. B. Lasserre. A sum of squares of nonnegative polynomials. SIAM review , 49(4), 2007. [98] B. Lasserre. Moments, positive polynomials and their applications , volume 1. World Scienti c, 2009. [99] M. Laurent. Emerging Applications of Algebraic Geometry , chapter Sums of Squares, Moment Matrices and Optimization Over Polynomials. Springer, 2009. [100] I. Lauriola and F. Aiolli. Mklpy: , 2020. [101] as a rank-constrained opti- mization. In Communication, Control, and Computing (Allerton), 2013 51st Annual Allerton Conference on , pages 39{45, 2013. 207[102] E. Levin, K. Serrano, and D. Devine. Standardization of cd 62p measurement: results of an international comparative study. Vox sanguinis , 105(1):38{46, 2013. [103] Y. Liu. Big data and predictive business analytics. The Journal of Business Forecasting , 33(4), 2014. [104] H. Lodhi, C. Saunders, J. Shawe-Taylor, N. Cristianini, and C. Watkins. Text classi cation using string kernels. Journal of Machine Learning Research , 2002. [105] F. E. Lund and T. D. Randall. E ector and regulatory b cells: modulators of cd4+ t Nature Reviews Immunology , 10(4):236{247, 2010. [106] Z.-Q. Luo and S. Zhang. A semide nite relaxation scheme for multivariate quartic polynomial optimization with quadratic constraints. SIAM Journal on Optimization , 20(4), 2010. [107] J. Mangal, S. Inamdar, Y. Yang, S. Dutta, M. Wankhede, X. Shi, H. Gu, M. Green, K. Rege, M. Curtis, et al. Metabolite releasing polymers control dendritic cell function by modulating their energy metabolism. Journal of Ma- terials Chemistry B , 8(24), 2020. [108] A. Merola, C. Cosentino, and F. Amato. An insight into tumor dormancy equilibrium via the analysis of its domain of attraction. Biomedical Signal Processing and Control , 3(3):212{219, 2008. [109] C. Micchelli, Y. Xu, and H. Zhang. Universal kernels. Journal of Machine Learning Research , 2006. [110] B. Mohamed and (Proc. Sympos. Wright-Patterson Air Force Base, Ohio, 1965) , 1967. [112] K. Murphy and C. Weaver. Janeway's immunobiology . Garland science, 2016. [113] I. Myung. Tutorial on maximum likelihood estimation. Journal of mathematical Psychology , 2003. [114] K. Ni, S. Kumar, and T. Nguyen. Learning the kernel matrix for superresolu- tion. In Proceedings of the IEEE Workshop on Multimedia Signal Processing , pages 441{446, 2006. [115] J. Nie. Optimality conditions and nite convergence of lasserre's hierarchy. Mathematical Programming , 146(1), 2013. [116] J. Nie and M. Schweighofer. On the complexity of putinar's positivstellensatz. Journal of Complexity , 23(1), 2007. 208[117] H. Norma, M. Mendy, J. Janean, D. Agnes, B. Brenda, H. Honey, E. Carrie, J. Mary, H. Robin, B. Marsha, L. Peggy, and L. Terri. RN Adult Medical Surgical Nursing Review Module . ati Nursing Education, 10 edition, 2016. [118] N. Noroozi, P. Karimaghaee, F. Safaei, and H. Javadi. Generation of lyapunov functions by neural networks. In Proceedings of the World Congress on Engi- neering , 2008. [119] M. D. of Transportation. Metro interstate tra\u000ec volume data set, 2019. URL https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+ Volume . [120] C. S. Ong, A. J. Smola, and R. C. Williamson. Learning the kernel with hyperkernels. Journal of Machine Learning Research , 2005. [121] F. Paillard. Commentary: Immunosuppression mediated by tumor cells: A challenge for immunotherapeutic approaches. Human gene therapy , 11(5):657{ 658, 2000. [122] J. B. Park, Y. W. Jeong, J. R. Shin, and K. Y. Lee. An improved particle swarm optimization for nonconvex economic dispatch problems. IEEE Transactions on Power Systems , 25(1), 2010. [123] P. A. Parrilo. Structured semide nite programs and semialgebraic geometry methods in robustness and optimization . PhD thesis, California Institute of Technology, 2000. [124] A. Patt, R. J. Klein, and A. de la Vega-Leinert. Taking the uncertainty in climate-change vulnerability assessment seriously. Comptes Geoscience Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, A. and E. Duchesnay. Scikit-learn: Ma- chine learning in Python. Journal of Machine Learning Research , 12:2825{2830, 2011. [126] M. Peet, P. Kim, and P. Lee. Biological circuit models of immune regulatory response: A decentralized control system. In 2011 50th IEEE Conference on Decision and Control , pages 3020{3025, 2011. [127] M. M. Peet, A. Papachristodoulou, and S. Lall. Positive forms and stability of linear time-delay systems. SIAM Journal on Control and Optimization , 2009. [128] D. B. Percival and P. Guttorp. Long-memory processes, the allan variance and wavelets. In Wavelet analysis and its applications , volume 4. Elsevier, 1994. [129] S. Prajna, P. Antonis, and P. Pablo. Introducing sostools: A general purpose sum of squares programming solver. In Proceedings of the IEEE Conference on Decision and Control , 2002. 209[130] S. Prajna, A. Papachristodoulou, and P. A. Parrilo. Introducing sostools: A general purpose sum of squares programming solver. In Proceedings of the 41st IEEE Conference on Decision and Control , volume 1, pages 741{746, 2002. [131] S. Prajna, A. Papachristodoulou, P. Seiler, and P. A. Parrilo. SOSTOOLS and its control applications. In Positive polynomials in control . Springer, 2005. [132] S. Qiu and T. Lane. Multiple kernel learning for support vector regression. Computer Science Department, The University of New Mexico, Albuquerque, NM, USA, Tech. Rep , 2005. [133] A. Rahimi and B. Recht. Random features for large-scale kernel machines. In Advances in neural information processing systems , pages 1177{1184, 2008. [134] A. Rakotomamonjy, F. R. Bach, S. Canu, and Y. Grandvalet. SimpleMKL. Journal of Machine Learning Research 2008. [135] B. Recht. Convex Modeling with Priors . PhD thesis, Massachusetts Institute of Technology, 2006. [136] S. Rosenberg, N. Restifo, J. Yang, R. Morgan, and M. Dudley. Adoptive cell transfer: a clinical path to e ective cancer immunotherapy. Nature Reviews Cancer , 8(4):299{308, 2008. [137] I. Safran and O. Shamir. Spurious local minima are common in two-layer ReLU neural networks. In International Conference on Machine Learning , 2018. [138] S. Sakaguchi, M. Miyara, C. M. Costantino, and D. A. Ha er. Foxp3+ regula- tory t cells in the human immune system. Nature Reviews Immunology , 10(7): 490{500, 2010. Regulation of cd4+ cd25+ regulatory t cell activity: it takes (il-) two to tango. European journal of immunology , 35 (5):1336{1341, 2005. [140] B. Sch\u007f olkopf, A. J. Smola, and F. Bach. Learning with kernels: support vector machines, regularization, optimization, and beyond . MIT press, 2002. [141] M. Schweighofer. Optimization of polynomials on compact semialgebraic sets. SIAM Journal on Optimization 2005. [142] H. Shapiro. Multistation multiparameter ow cytometry: a critical review and rationale. Cytometry: The Journal of the International Society for Analytical Cytology , 3(4):227{243, 1983. [143] B. Shekhtman. Why piecewise linear are dense in C [0, 1]. Journal of Approximation Theory , 1982. [144] Letters , 21(1), 1997. 210[145] N. Z. Shor. Quadratic optimization problems. Soviet Journal of Computer and Systems Sciences , 25(6), 1987. [146] A. M. Silverstein. A history of immunology . Academic Press, 2009. [147] A. Smola and B. Sch\u007f olkopf. A tutorial on support vector regression. Statistics and computing , 2004. [148] F. Song, Z. Guo, and D. Mei. Feature selection using principal component analysis. 2010 International Conference on System Science, Engineering Design and Manufacturing Informatization , 1, 2010. [149] S. Widmer, J. Behr, A. Zien, F. d. Bona, A. Binder, C. Gehl, V. Franc, et al. The SHOGUN machine learning toolbox. Journal of Machine Learning Research , 2010. [150] C. Starr, R. Taggart, C. Evers, and L. Starr. Biology: The unity and diversity of life . Cengage Learning, 2015. [151] D. E. Ste y and K. Wolter. Valid linear programming bounds for exact mixed- integer programming. INFORMS Journal on Computing , 25(2), 2013. [152] G. Stengle. sedumi 1.02, a matlab toolbox for optimization over symmetric cones. Optimization methods and software , 11, 1999. [154] B. Sturmfels. Solving systems of polynomial equations . American Mathematical Society, 2002. [155] N. Subrahmanya and Y. Shin. Sparse multiple kernel learning for signal pro- cessing applications. IEEE Transactions on Pattern Analysis and Machine In- telligence , 2010. [156] T. Sullivan. Introduction to uncertainty quanti cation . Springer, 2015. [157] H. Sun. Mercer theorem for RKHS on noncompact sets. Journal of Complexity , 2005. [158] H. Tam, M. Melo, M. Kang, J. Pelet, V. Ruda, M. Foley, J. Hu, S. Kumari, J. Crampton, A. Baldeon, et al. Sustained antigen availability during germinal center initiation enhances antibody responses to vaccination. Proceedings of the National Academy of Sciences , 113(43):E6639{E6648, 2016. [159] H. Tanabe, B. Ho, C. Nguyen, and S. Kawasaki. Simple but e ective methods for combining kernels in computational biology. In 2008 IEEE International Conference on Research, Innovation and Vision for the Future in Computing and Communication Technologies , 2008. 211[160] M. Terabe, E. Ambrosino, Berzofsky. enhancement of cd8+ t cell{ by an anti{transforming factor- oclonal antibody. M. Todd. Minimum-volume ellipsoids: Theory and algorithms . SIAM, 2016. [162] M. J. Todd and E. A. Y\u0010ld\u0010r\u0010m. On khachiyan's algorithm for the computation of minimum-volume enclosing ellipsoids. Discrete Applied Mathematics , 155 (13), 2007. [163] S. L. Topalian, M. Sznol, D. F. McDermott, H. M. Kluger, R. D. Carvajal, W. H. Sharfman, J. R. Brahmer, D. P. Lawrence, M. B. Atkins, J. D. Powderly, et al. Survival, durable tumor remission, and long-term safety in patients with advanced melanoma receiving nivolumab. Journal of [164] P. T\u007f ufekci. Prediction of full load electrical power output of a base load operated combined cycle power plant using machine learning methods. International Journal of Electrical Power & Energy Systems , 60:126{140, 2014. [165] Y. Y. Wan and R. A. Flavell. How diverse{CD4 e ector t cells and their functions. Journal of molecular cell biology , 1(1):20{36, 2009. [166] H. Wang, Q. Xiao, and D. Zhou. An approximation theory approach to learning with`1regularization. Journal of Approximation Theory , 2013. [167] M. Webster and C.-H. Cho. Analysis of variability and correlation in long-term economic growth rates. Energy economics , 28, 2006. [168] M. D. Webster, M. Babiker, M. Mayer, J. M. Reilly, J. Harnisch, R. Hyman, M. C. Saro m, and C. Wang. Uncertainty in emissions projections for climate models. Atmospheric environment , 36, 2002. [169] J. Wiest, M. H\u007f o ken, Kre\u0019el, and K. Dietmayer. Probabilistic trajectory prediction with gaussian mixture models. In 2012 IEEE Intelligent Vehicles Symposium , 2012. [170] S. Wilson and D. Levy. A mathematical model of the enhancement of tumor vaccine e\u000ecacy by immunotherapy. Bulletin of mathematical biology , 74(7): 1485{1500, 2012. [171] Z. Xu, R. Jin, H. Yang, I. King, and M. Lyu. Simple and e\u000ecient multiple kernel learning by group lasso. In Proceedings of the 27th international conference on machine learning , pages 1175{1182, 2010. [172] H. Yang, Z. Xu, J. Ye, I. King, and M. Lyu. E\u000ecient sparse generalized multiple kernel learning. IEEE Transactions on neural networks , 22(3):433{446, 2011. [173] Y. Ye and E. An extension of Karmarkar's projective algorithm for convex 212[174] E. Zanaty and A. A . vector machines (SVMs) with universal kernels. NUMERICAL SCALABILITY OF SLICED EXPONENTIALS In this section we consider the computational complexity of the MLE and WCE optimization problems for SE. We rst consider the e ect of the number of samples inSthat are used to calculate the numerical integration constant. Then we consider the e ect of the number and dimension of the training data points and the degree of the SE. Evaluating the E ect of the Sample Number The number of samples used to calculate the numerical integration constant in Op- timization Problems 3.6 (MLE) and 3.16 (WCE) will have an e ect on the optimal \u0015\u0003and the computation time of the algorithm. We perform numerical experiments using the Iris data set and the MLE and WCE optimization methods to observe the e ect of the number of selected samples, S, on the computation time and objective value of the resulting \u0015\u0003. The dimension of the data e ects the accuracy of the Monte Carlo integral esti- mation. To compare the di erence between data sets of di erent dimension we will perform the tests rst using only the rst dimension of the Iris data set, then compare those results to using the full Iris data set. The MLE Optimization Problem To study the properties of Optimization Prob- lem (3.6) with respect to the number of samples in Swe plot the normalized log likelihood and the normalized computation time of the MLE problem in Fig. A.1(a) averaged over 15 trials. The log likelihood is calculated after the optimal parameter \u0015\u0003has been returned by Optimization Problem 3.6 using one million samples and then normalized so that the one dimensional data set can be compared to the four dimensional data set. The computation time is likewise normalized for comparison between the one dimensional and four dimensional cases. Note that in each case the computation time increases approximately linearly as a function of the number of samples in S. The computation time does not increase lin- early with respect to the dimension of the problem, which we explore in the following subsection. In the one dimensional case the log likelihood does not signi cantly change after approximately 105samples. On the other hand the log likelihood in the four dimen- sional case was too small to be accurately computed in the case of 104samples, and required 8\u0001105samples before the log likelihood was accurate. In the one dimensional case as few as 105samples can be used where in the four dimensional case at least eight times as many points are required. The WCE Optimization Problem To study the properties of Optimization Problem 3.16 with respect to the number of samples in Swe plot the normalized 2140 2 4 6 8 10 Number of Samples 10500.20.40.60.81Normalized Log Likelihood 00.20.40.60.81 Normalized CPU Time (seconds)n=1 n=4(a) The normalized log likelihood and computation time of a degree 10 SE trained with the rst dimension of the Iris dataset (n=1) and a degree 4 SE trained on the full data set (n=4). 0 2 4 6 8 10 Number of Samples 10500.20.40.60.81Normalized Log Likelihood 00.20.40.60.81 Normalized CPU Time (seconds)n=1 n=4(b) The normalized worst likelihood and computation time of a degree 10 WCSE trained with the rst dimension of the Iris dataset (n=1) and a degree 4 WCSE trained on the full data set (n=4). Figure A.1: The normalized log likelihood and computation time to compute SE and WCSE distributions after using one million points to calculate the normalization constant. worst case likelihood and the normalized computation time of the WCE problem in Fig. A.1(b) averaged over 15 trials. The worst case likelihood is calculated after \u0015\u0003 has been returned by Optimization Problem 3.16 using one million samples and then normalized so that the one dimensional data set can be compared to the four dimen- sional data set. The computation time is likewise normalized for comparison between the one dimensional and four dimensional data sets. Note that like in the MLE case, the computation time increases approximately linearly as a function of the number of samples in S. However, unlike the MLE case, in both the one dimensional and four dimensional cases the worst case likelihood does not signi cantly change after approximately 105samples. The \u0015\u0003of the WCE problem thus is signi cantly less a ected by the dimension of the problem than the MLE problem. Computational Complexity of Optimizing SE PDFs Here we provide a numerical estimation of the complexity of the MLE and WCE opti- mization problems with respect to the number of training data points, the dimension and the degree of the SE. We rst will specify two techniques employed to decrease the computational complexity of solving the MLE and WCE problems. Implementation To solve the MLE and WCE optimization problems we develop two techniques to decrease the computation time. The rst technique automatically selects the number of samples used to numerically compute the integration constant. The second solves the MLE and WCE problems by iteratively solving the problem for smaller degree SEs rst. The Sampling Sub-Routine: To compute \u0015\u0003we use a small initial sample of mcpoints to calculate the numerical integration constant and a much larger sample of m0points to verify that the number of samples was adequate. Using the computed \u0015\u0003, if the objective function using mcsamples is within a threshold value of the objective 2151 2 3 4 5 6 7 8 Degree of SE10-210-1100101102103Time to Optimize (seconds)n = 1 n = 2 n = 3 n = 4(a) Computational complexity analysis of the MLE problem, the di erent colored lines represent data sets of di erent di- mension. 102103 Number of Samples10-1100101102Time to Optimize (seconds)d = 1 d = 2 d = 3 d = 4(b) Computational complexity analysis of the WCE problem, the di erent colored lines represent di erent degree SEs. Figure A.2: Computational complexity analysis of both the MLE and WCE opti- mization problems as the degree or number of training samples is varied. function using m0then\u0015\u0003is accepted, otherwise the number of samples is increased by a factor of \u0014. In this dissertation we select mcto be 103samples,m0to be 106samples and the threshold for accepting \u0015\u0003is if the objective functions are within 5% of each other. Finally we set \u0014= 10 so that we increase the number of samples by a whole magnitude if the number of samples was not enough. Iterative Solutions: To nd an optimal degree kSE we apply an iterative procedure, wherein we rst nd \u0015\u0003for a degree d= 1 SE. We then use this \u0015\u0003to initialize the search for the optimal degree d+ 1 SE and repeat this process until we have the optimal \u0015\u0003of the degree kSE. Data: In this section we use the data sets, VOS ,TV1,BP, andIRas can be found in [128, 119, 83, 55] in the UCI machine learning or OpenML databases. The MLE Optimization Problem For the MLE formulation we plot the com- putational time in Figure A.2(a) as a function of the degree for each of the four data sets in a log-log plot. Empirically the computational complexity is of order O(d1:2), O(d2:3),O(d3:2), andO(d3:7) for dimension of 1 through 4 respectively. The number of data points does not have a consistent e ect on the computation time of the MLE optimization problem. For instance, increasing the number of sam- ples can decrease the computation time as the number of data points changes the optimal\u0015. The WCE Optimization Problem For the WCE optimization problem the num- ber of data points has a more consistent e ect on the computational time than the MLE optimization problem. Therefore, we plot the computational time of the three dimensional data set BP, in Figure A.2(b) where the number of points mare varied 1The data set TVoriginally contains data points with more than two dimensions, however, we extract the time of day and tra\u000ec volume from the original data (the real valued variables) to create our two dimensional data set. 216along the x axis and we plot separate colors for degrees dbetween 1 and 4. From this data we have empirically determined the computational complexity is approximately O(m0:54d2:7) wheremis the number of data points in Danddis the degree of the SE random variable. For large numbers of data points the MLE optimization problem will have a sig- ni cantly faster computation time. 217 "}