{"title": "PDF", "author": "PDF", "url": "https://files.eric.ed.gov/fulltext/ED135801.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "ED 135 801AUTHORTITLEINSTITUTIONSPONS AGENCYPUB DATENOTEAVAILABLE FROMDOCUMENT RESUMETM Formulation ofQuestions, Design and Analysis.Stanford Univ., Calif. Stanford Foundation, Hew York, N.Y.; SpencerFoundation, Chicago, Ill.Jul 76243p.Stanford Evaluation Consortium, School of Education,Stanford Stanford, California 94305($1.00)EDRS PRICE MF-$0.83 BC-$12.71 ways of analyzing data from Aptitude Treatment Interactions were examined over a two-year period. In light of past arguments the author maintains that the questions surrounding aggregation have been badly posed and that the customary methods of analysis were either incorrect or subject to misinterpretation.Therefore, the majority of studies of educational effects--whether classroom experiments, or evaluations of programs or surveys--have collected and analyzed data in ways that conceal more than they reveal. The established methods have generated false conclusions in many studies. Further, the traditional research strategy which pits tsubstantive hypotheses against a null hypothesis and requiresstatistical significance of effects can rarely be used in educational -research. Samples large enough to detect strong, but probabilisticeffects are likely to be prohibitively costly. (Author/MV) ***********************************************************************Documents acquired by ERIC include many informal unpublished* materials not available from other sources. ERIC makes every effort * * to obtain the best copy available. Nevertheless, items of marginal* * reproducibility are often encountered and this affects the quality * * of the microfiche and hardcopy reproductions ERIC makes available * * via the ERIC Document Reproduction Service (EDRS). EDRS is not * responsible for the quality of the original document. Reproductions * * supplied by EDRS are the best that can be made from the original. ************************************************************************ laOCCASIONAL PAPERS OF THE STANFORD POSITIONOR POLICYEvaluationConsortium Stanford University, Stanford, PORTED OWNEP12 RESEARCH ON CLASSROOMS AND SCHOOLS:FORMULATION OF QUESTIONS, DESIGN, AND ANALYSIS Lee J. Cronbach-- with the assistance ofJoseph E. Deken and Noreen Webb July, 1976The Stanford Evaluation Consortium is a group of faculty members andstudents concerned with the improvement of evaluation of educational and social-service programs. The Occasional Papers represent the views of the authors as individuals. Comments and suggestions for revision are invited.The papers should not be quoted or cited without thespecific permission of the author; they are automatically superseded upon formal publication of the material.Additional copies of this paper are available for $1.00 each from the Stanford Evaluation Consortium, School of Education, Stanford University, Stanford, California 94305.3 Table ot Contents Preface 1.Introduction to the problemFrom a statistical issue to a substantive issue11.1 1.1The Abt Follow Through report 1.3a *The need to disentangle effects 1.9Psychological bias and sociological bias 1.14A debate in educational psychology 1.15Debates within sociology in various research contexts 2.1The problem as seen in research on ATI 2.1A tiSample size for regression analysis 2.2The Maier-Jacobs study 2.3Harvard Project Physics 2.5Three kinds of process effects 2.11Ecological psychology 2.16Evaluative studies and school-effect studies 2.17Extrapolation in interpretation 2.23 3.A mothematical model 3.1 a a*Definition of components Interpretation of componentsPartitioning variance3 .1 3 .4 3 .8 Table of Contents 2 Choices made in forming the model 3.9Direction of decomposition 3.9Nonlinearity 3.10Effects of aggregating data of \u00a2 3,15Comparing Bb and Sw 3.16Implication 3.21Aggregation effects with multiple discriminants 3.22 4.The reference population and its carameters Alternative models for statistical inference4.14.1 Collectives distinct, persons fixed 4 .2Collectives nested within local populations 4 .3The independence assumption 4 .4Choice among models 4.5Weights that define parameters 4.7Illustrative statistics for populations of collectives 4.11Head Start 4.11School districts in California 4.12A problem of estimation 4.13 5.Illustrative ATI studiesThe Anderson study A weighting decisionRegressions of ZACH on PRECOM Regressions of ZACH on ABU,Cooperative Reading dataPlan of the studies p.-55.1 5.1 5.2 5.3 5.8 5.11 5.11 Table of Contents 3 The original analysis across projects 5.12Half-class as unit of analysis? 5.13The original analysis within projects 5.14Procedures in our reanalysis 5.16Results of our analysis 5.18Conclusions regarding units of analysis 5.22Head Start Planned Variation 5.23 regression 8.8Follow Through data 8.9Design 2.Treatments crossed with blocks; collectives nested 8.10The plan of the Head Start study 8.11Alternative analyses, assuming homogeneity of regression 8.13Alternative analyses, recognizing heterogeneity ofregressions 8.17 Table of Contents 4 9.Multivariate considerations 9.1Simple correlations 9.1Correlations of reading outcomes analyses 9.20A school-effects model 9.20Partialling 9.22 10.The Road Ahead 10.1 7 1 Preface If any fraction of the argument herein is correct, educational research -- and a great deal of social science -- is in serious trouble. The implications of my analysis can be put bluntly: 1.The majority of studies of educational effects -- whether classroom experiments, or evaluations of programs,or surveys -- have collected and analyzed data in ways that conceal more than they reveal. The established methods havegenerated false conclusions in many studies. 2.The traditional research strategy -- pitting sub- stantive hypotheses against a null hypothesis and requiringstatistical significance of effects -- can rarely be used in educational research. Samples latge enough to detect strong but probabilistic effects are likely to be prohibitively costly.This work began with a perplexity regarding an aspect of an isolated kind of research on instruction. Funds from the Spencer Foundation enabled me to examine with two assistants, over a two-year period, some alternative ways of analyzing data from studies of Aptitude x Ti-eatment interactions.When the time came to write a final report, I discovered that the problem was larger, more important, and less tractable than we had assumed when we were concentrating on ATI studies and techniques (Cronbach & Snow, 1976). Sociologists have discussed and debated for many years about the legitimacy of explaining data in terms of \"context effects\" or \"compo- sitional effects\". Similar but less extensive discussion is to be found in the literature of political science, and comparable questions arise in trying to reconcile microeconomics with macroeconomics. That literature has been virtually ignored by educational research workers and by psychologists, except in the \"school-effect\" studies of the past ten years.If this monograph does no more than alert my colleagues to the perils of ignoring issues of aggregation, that would be sufficient justification. As I studied the past arguments, I came to think that the questions surrounding aggregation have been badly posed, and that the customary methods of analysis were either incorrect or subject to misinterpretation. Hence I am addressing a broad audience of social scientists rather than merely those in educational research.As I began to set down my ideas and puzzlements, the plotthickened with each passing week. Many recent publications and unpublished reports came to my attention; I particularly credit a paper by Walt Haney (1974b) for its seminal influence. I tried parts of the argument on knowledge- able colleagues, and those interchanges moved my thinking further. 2 It will be evident from the physical form of the paper that itis a draft still undergoing revision. I have decided to distribute it in this form because of myconviction that these issues are of vital importance and that it would becounterproductive to delay the discussion until my argument is polished.Millions of dollars are 'going into evaluation studies each year; it wouldbe a sufficient short-run contribution to persuade sponsors and investi-gators to think hard about the questions raised here. I have not resolvedthe problems presented by aggregate phenomena; it is my intention here tostir up debate and to encourage proposals from others. I invite -- nay,beseech -- comments and counterarguments from those who receive this paper.This project originated out of a concern with Aptitude x Treatmentinteractions.The procedure in ATI research is to calculate an outcome-on-aptitude regression for some teaching method, with the intent ofdiscovering and explaining differences in regression slopes for alternativemethods.During the same period I became involved in theoretical aspects of analysis of covariance. In that analysis, regression slopes have beenregarded as instrumental rather than as of primary interest. As the Abtexample in Section 1 shows, the issue of units of analysis arises therealso.Thirdly, Leigh Burstein has completed a doctoral dissertation onthe aggregation problem, as seen particularly in studying regressionscalculated in educational sociology. I have served as chairman of hisdissertation committee and find that experience influencing my thinking here.My two aSsistants, Joseph Deken and Noreen Webb, played an importantrole in developing materials for this monograph. Miss Webb took primaryresponsibility for the illustrative data analyses and the data-processingmethods, and Mr. Deken led the way in the statistical theorizing. Neitherof them is to be held responsible for the present content of the paper.Analyses of California Assessment data were made by David Rogosa, undersupport from the State, and Lynne Gray assisted in analyzing the Featherstonedata.David E. Wiley was good enough to work through the entire manuscriptand did much to correct and extend my thoughts. Conversations withLeigh Burstein, Merrill Carlsmith, Dan Davis, Mike Hannan, and David Rogosawere helpful;'likewise, I thank Dudley Duncan, Robert Hauser, and HerbertWalberg for suggestions in correspondence. The revision of the report prepared for the Spencer Foundation and its reproduction and distribution was supported by the Stanford EvaluationConsortium under a grant from the Russell Sage Foundation. 9 1.1 1.Introduction to the Problem From a statistical issue to a substantive issueIf A contour map of the region from Maine to Maryland wereprepared with a six-inch contour interval, a person inspecting themap would not perceive the Atlantic Ocean. Some such remarkwas the lead sentevIce of an article in Science some years back.I have been unable to locate the article, and thecontour mentionedmay have been six feet, not six inches.However the writer phrasedit, the point is that a fine-grain analysis can overlook largeconfigurations in the data.. It is equally true that too gross ananalysis can conceal important relationships. Nor are all sinsthose of omission; investigation on the wrong scale can positivelydistort relations.It is conventional in psychology and biology to regard thesingle organism as the object of investigation, and educationalresearch workers took over that point of view.They frame hypothesesin terms of individuals and base their analysis on individual scores,though they do not always make ehe person the sampling unit. Only subsequent tothe Coleman report of 1966 did the rise in sociological and economicresearch make hypotheses at the level of collectives common in education.The habits of the psychologist and biologist do not fit researchon classroom instruction. Rats receiving a 10 1.2 drug or placebo are properly considered to be independent subjects; what onerat does has no effect on the score of the next (unless the experimentersomehow introduces correlated errors). Students in a class, however, do notprovide independent evidence. Typically, persons within a class are more alike at the outset ofinstruction than persons randomly sampled from the relevant population, Certain adventitious common experiences during instruction depress or raisethe scores of many of them -- a flu epidemic, or perhaps a wave of enthusiasm.What the c.ass experiences goes beyond the treatment specified by the experi-menter.There are unintended treatment 1variations in the experiment on ratsalso, but the design tries to ensure that no two rats experience the samevariation.In the classroom where variation is common to members of theclass, the entire class provides a single observation on the effect of thewritings (e.g., Peckham, et al., 1969)treatment.SomeAon educational statistics warn against taking the Anu\"oer of students in the experiment as the basis for evaluiting degrees offreedom, on the grounds that this gives an unjustifiably small estimate ofthe sampling error. The warning they do not give is that analysis on indi-viduals often looks at the wrong question. There is a literature in sociology that warns of the importance ofchoosing the right unit, and most of that literature too has perceived thequestion as one of analytic procedure.E Sociologists (and political scientists, economists, etc.)work with censuses and other public records compiled for some aggregate unitsuch as a county or an industry. If one wants to know how reliance on publiclevel of libraries relates to education, he may find circulation figures available forkeach local library system, and educational statistics available for census tracts.Then by combining census tracts that more or less niatch the service 1For notes see end of section.11 1.3 area of the library system, he is enabled to correlate book circulation witheducation.A famous paper by Robinson (1950) -- echoing E. L. Thorndike(1939) -- warned against interpreting such correlations as ifthey described relations at the individual level; over the years, a rathersizable literature has reiterated or modified Robinson's warning. I shalllater review some of the current ideas,.but I do not concern myself withthe problem of unavailability of data, which motivated much of the originalwork. The great majority of sociologists who deal with data at two levels havecarried out essentially the same analysis at two levels, orhave mingledmeasures on units and subunits in the same calculation. Thus, a sociologistwho had full data might enter into the same regression equation an indivi-dual's use of the library, his education, and a measure of the size of thecommunity library, assigning that same value to all residents of the community.The statistical analysis then pools all the individuals, without regard t.community boundaries. I shall propose that in a large class of educational studies,and probably in -rtany other studies of social services, the more reasonableanalysis is to relate variables within groups (schools, communities), andthen to analyze group-level variables across groups. Whereas most sociologistshave related Y to X and to the group mean X, I propose to relate Y to Y, and Y -to X - A.This reformulation changes the Gestalt of substantive findings. Only recently have sociological writers pointedly recommended separateexamination of between-group and within-group statistics, though casualreferences to or illustrations of such analyses appear here and there inthe literature. Alwin (1975) has now recommended this decomposition as asuperior way to examine composition or context effects, and Firebaugh's(1975) theoretical paper on aggregatlon bias appears to be in close12 1.3a harmony with this report, insofar as it overlaps. As far back as 1969,Slatin analyzed relations of delinquency to other variables within arealunits of a community, and between areal units.In one of the most recentstudies of \"school effects\", Hauser, Sewell, and Alwin (1974) make use ofan overall regression analysis, a within-schools analysis, and a between-schools analysis; but they use the analyses to examine somewhat differentaspects of the data. Minkowich, Davies, & Bashi (1976) have analyzed the\"little Coleman report\" on Israeli schools by means of a systematic separationof between-school and units-of-analysis problem\", the investigator is presumed to be interested in how one variable depends on another (which ,may or may not have been manipulated). Writers prior to Firebaugh havediscussed whether analyzing means of classes or other groups of subjects isan acceptable substitute for analyzing scores indIvidually, and vice versa. In these discussions, the variables at the group level are \"aggregates\"of measures on individuals. The choice of unit of analysishas a considerable effect on correlations, regression slopes, andwithin-treatment variances. Thoughit has little or no effect onunadjusted within-treatment means,the unit of analysis can make a difference in the estimate ofa covariate-adjusted treatment mean, when persons or classes have notbeen assigned to treatments at random or when the number of independentassignments to treatment is small. The Abt Follow Through report.The confusedstate of the artand the importance of the pi.-oblemaredisplayed in the analysis ofFotlow Throu0 Planned Variations data by Abt Associates (Cline, 1974).13 1.4 The difficulties recognized there and the difficulties not recognized thereforeshadow most of my concerns in this report. In this multimillion-dollarstudy, over a dozen sponsors set up FT groups, each group using whatevermodel of compensatory education the sponsor advocated alongside an NFTcontrol.Control schools were only roughly comparable to the experimentalschools the sponsor used. Comparability of samples across and within spon-sors was so poor that Abt analyzed data of each sponsor as a separate quasi-:an experiment.(I consider this sound; I have doubts about overall analysis inan appendix that considers sponsors simultaneously.) The fact that the Abtconsultants included methodologists prominent in educational evaluation leads me to think that the analysis does reflect the state of the art.Three analyses wereonsidered: individual, class, and school (each within sponsor). The individual analysis started, in effect, by punching one card with the data for each child. The sponsor's whole batchof FT and NFT children was then run through an ancova program, to reach anumber described as the adjusted treatment effect. The school analysis was the same, except that therewas one card per school, with pupil averages on variables replacing individual scores. The class analysiswas similar, with one card per class, all classes within a treatment being pooled in the analysis.Abt used different variable sets for the three analyses. Abt chose 18 covariates,but only 11 of these entered the individual analysis and 12 entered the school analysis. The global variable Southern/Western/Other Region, for example,could have been punched in the cards for pupil and class,if it was worth considering at the school level. The school-levelaggregate Percent Minority could have been reprosented at the individuallevel by a Minority/Nonminority code. (But very likely Abt was14 1.5 not supplied that datum.) Conversely, the individual variable Preschool Exp./No Preschool Exp. could (and I think should) have reappeared as an aggregate,(Some part of the differences in findings from the three analyses arosebecause data were missing. E.g., children counted in the classaggregate on certain varie% es were omitted from the individual analysisbecause their scores were incomplete. Loss of data is acompli-cation, but probably not the main source of confusion.)In my opinion Abt was correct to emphasize the school level in its summaries.Treatments were assigned to schools, and no doubt program deliveryvaried from school to school. Abt, however, feeling that the rationale for choosing a level was weak, offered the three analyses as a \"cross-validation\".It is not, of course, anything of the kind; the three analyses arein no way independent, and they ask different questions. Abt did indeed statethat the analyses asked different questions, and that an aggregate variable isa different variable from the disaggregated variable that generated it. Andyet, said Abt, if the three analyses give similar estimates of the treatmenteffect, the result can be accepted with \"enhanced confidence\", To be sure, if acritic is disappointed by the finding that the school-level analysis reports, hemay claim that analysis at some other level would give the result he would like;presenting all three analyses disarms such a critic.But it is a mistake to re-gard the three analyses as equally relevant and equally legitimate.The results of the three analyses did not agree.Sponsor 3, Arizona(pp. V1-66ff.) provides a striking example. Let us confine attention toeffects on the Wide Range Achievement Test (WRAT). The first glaring discrep-anxy appears in the unadjusted treatment effect. With the posttest meanexpressed in raw units, the differences (FT minus NFT) are PupilMean diff. = +1.37 N = 317 FT, 265 NFT Pooled s.d = 12.8 t = not is to be expected that s.d.'s will be larger at the individual level.It might be expected that means and mean differences will be the sameexcept for such perturbations as missing cases introduce) but they are not.(Discrepancies seem much larger when the Abt charts display each mean difference divided by the corresponding s.d.!) My onlyguess as to the reason for the discrepant means is that the one-card-per-class and one-card-per-school techniques of calculation weightedcases differently. I agree with the decision to calculate tat the school level only.I do not agree with the decision to test the unadjusted difference, however. Adjustment changes the picture. The mean differences become PupilMean cliff. The adjustment, then, reduced the effect in two analyses, as it should ifthe FT sample was superior to the NFT sample at the outset. But itincreased the effect at the school level, which could only happen if theNFT sample was better at the outset or the regression slope -- positiveat the class level -- changed to negative at the school level! At least one of the adjusted analyses must be seriously wrong. In fact, it can beargued that none of them is of much value. The pupil-level analysis andprobably the class-level analysis are theoretically inappropriate; and thenumber of classes or of schools is too small to determine adequately theregression coefficient on which the adjustment is based.Apt wisely did not test significance at the two lower levels.Many if not most investigators would have done so, if only because thelarger N promises a higher significance level. 2The most serious question to be raised about Abt's significance test is whether it is meaningful.16 1.7In a generalized regression analysis loosely comparable to analysis ofcovariance, 12 regression coefficients plus two constants were fitted to the41 school means on the covariates. Multiple-regression coefficients arenotoriously unstable in small samples; if the coefficients change, the adjustment is likely to change dramaticallywhen the groups are dissimilar to begin with. It is advisable in generalto distrust any one regression coefficient when predictors are correlated,even when samples are large. The treatment effect in this study is literallycalculated as a thirteenth regression coefficient. I suspect that in aquasiexperiment like this uncertainty regarding the adjusted treatmenteffect in the population is much larger than the conventional significancetest indicates.The Abt group went one step beyond ancova.Theirs is one of the rare analysesthat tal'es seriously the many warnings in the statistical and psychological lit-erature about fallible covariates. The fallible covariate most likely underadjusts,hence disattenuation is vital in a nonrandom experiment. Abt does disattenuatethe adjusted treatment effect in the pupil-level analysis and so arrives at onefinal \"true score adjusted treatment effect\". A value of the pupil-level \"adjusted effect\" of 0.36 for WRAT with Sponsor 3. (In other instances, thechange is sometimes an increase and is sometimes a change of sign.) How Abt disattenuated is a mystery. Abt correctly states that the onlysound correction method available in 1974 was limited to the study with asingle covariate. Yet the analysis they disattenuated was a multipleregression with several fallible covariates. It seems likely that they usedone of the unacceptable techniques in circulation in early 1974.Cronb'ach, Rogosa, Floden, and Price (1976), building on an unpublished paperof Keesling and Wiley, have recently put forth a correction for the multivariate case.Abt might, of course, have hit upon this method. In any event, the point to be Fade here is that aggregate data again17 no 1.81.9 spawn confus jn. Abt corrected only the individual analysis, arguingthat class and school data are much more \"stable\" and in need of nocorrection.Later we shall see, however, that group regressions may be justas fallible as individual ones. The standard error of measurement ofa group mean (dith pupils fixed) is small, butthe coefficient of generalizability for the group means(which enters thedisattenuation formula/may be lower than that for individual data. Classand school analyses of covariance ought to be disattenuated when assignment isnot random.2a The need to disentangle effects. Onlychaotic debate can result from program evaluations in education until thepresent confusion about units of analysis is dispelled. The issue is notreally one of ircen from sample to population, as the infrequenttreatment of the ue in statistics texts suggegts. And it is notusually one of \"substituting\" analyses of aggregates for analyses ofindividuals.Conflicting if not wholly incorrect descriptive resultsin the Abt sample are the root source of confusion. Analyses at the group level and the individual level give conflictingdescriptive results because they bear on different substantiverquestions.The investigator who \"wants to know the relation between two variables\" isnot asking a clear question until he tells whether the group or individualrelation is the one of interest. The investigator who proposes to partialout certain influences has to specify which relations he I 8 1.10 intends to remove -- and he had better know why!Some social scientistshave recognized that the problem is less one of choosing the right analysisand more one of asking the right question (Dogan & Rokkan, 1969).Scheuch's (1966) exposition -- of how the choice of unit depends upon thetheoretical question in hand, and of how the evolving theory takes shapeand power from the choice of units once it is made -- is outstandinglycomplete and eloquent. But even Scheuch is concerned with thechoice of units, instead of with the problem of separating berween-groups 41$ from within-groups effects. Duncan, Featherman, and Duncan (1972) dohave a clear discussion of what is to be gained from such separation, anargument faintly foreshadowed in the marvelously lucid pioneering workof Duncan, Cuzzort, and Duncan (1961). Insofar asrelevant experiences are associated with groupsthere are two matters to consider: between-groups relations and within-grouprelations.The overall individual analysis combines these, to everyone's confusion.A distinction between aggregate and global data is sometimesmade (but not in a consistent way). I shall define an aggregate datum as a simple composite (count, average) of individualcharacteristics such as per capita income, sex ratio within a school,mean reading level, or percentage of dropouts. Global characteristics are thoseassociated with the collective that are not operationally divisibleover individuals, e.g., the per-pupil school budget, the age of aschool principal, the size of the school library, the fraction ofmeetings of a class that are devoted to discussion. A count of acharacteristic on which individuals do not vary within groups (e.g.,population in an areal unit; sex in sex-homogeneous intact groups) isclassed as a global property. The distinction is unimportant, sinct thetwo kinds of variables are to be analyzed in exactly the same way.The 19 only real difference is that aggregate variables confuse interpreters,whoare inclined to regard the aggregated and disaggregateddata as alternative representations \"of the same variable\". Except inpretest measures on newlyassembled groups, they are not (see below).The interplay between aggregate and individual phenomena can beillustrated by considering the proportion of college-educatedin a community. An industry needing an educated labor force isattracted to the area. Then the probability that a person will work inthis industry is not merely a function of his individual level of education;it is a function of the educational level in the area where he resides.Causality i= equivocal: since the industry, once established,attracts pe.- with suitable education into the area.Thi3 example draws attention to a point insufficiently emphasized inthe literature on aggregation effects. The aggregate variable often represents a different construct from theindividual-level variable. A particular relationship might happen tohave the same form and parameters at both levels, but even if bothrelations were described by (say) Y = 2X + 3, the relations are rarely\"the same\".The aggregate 17 and the individual X are different variables;ditto for Y.3That the individual is college educated indicates a good dealabout what he would be inclined to purchase or what jobs he would becapable of holding. The aggregate college education in the communitynot only describes an aggregate market and an aggregate employee pool;it says a good deal about what goods and services probably are wellsupplied in the Community (pediatricians? art movies?books?brokerageoffices?etc.), and a good deal about the kinds of jobs offered. The 2 0 1.12 ._.4gr,gate construct enters into a network of relations describing propertiesof groups (global as well as aggregate properties). It is true that acollege graduate is more likely to live in a community where the nroportionof college graduates is high. But inference from his individual educationto the probability that a choice of pediatricians is available to him is aweak inference, mediated first of all by the characteristics of the gro up.His individual probability of knowing of multiple pediatricians -- when theyare in the community -- does depend on his own education. Instead of consid-ering group and individual relations as alternativeversions of the same information, I propose to regard them as statementsebout different variables, even when the variables originate in the same 3aoperation. In educational research, practical considerations sometimes suggestthat one level is more relevant than the others.The State of California,for e,:ample, conducts a testing program whose main function is to informlocal district boards how adequate the achievement of pupils in theirschool system is. The district mean in readingis presentedalongside a regression estimate of the expected reading mean.In;.971-73 (for example), the variables givengreatest weight in predicting Grade-6 reading in unified school districtsre an index of family poverty, per cent college educated, and per cent'Spanish surnamed. These variables were all aggregated to the districtlevel, and districts were taken as the unit of analysis. This is logical.The State also reports scores school by school, and compares the schoolscore to a regression estimate of each expected school mean. 21 1.13 There is no a priori reason for the raw-score regression weights for dis-tricts to give lust predictions at the school level. TheState mightforma school-level regression equation, enteringall the individual schools into the calculation. But this isless logical than a two-step operation that predicts the district meanand the school's deviation from the district mean.The procedure permits assigningone weight to per-cent-college-educated at the district level, and anotherweight to the school percentage expressed as a deviation from the districtpercentage (and perhaps a third to the product of the two). 3b \"Choose the one unit that fits the decision\" is an inadequate rule.In a seminar discussion of this report one person suggested that when policymakers want information at (say) the school level, this immediately settlesthe question of units of analysis. Ido not think so; analysis with \"school as unit\" is not the same as analysisof districts and schools within district. But,in a hierarchical analysis,the results at two or more levels can be packaged into a statement thataddresses the question in the decision-maker's mind.Another example comes from evaluation research.Suppose that aneducational innovation will beinstalled -- if at all -- on a school-wide basis. To decidefor or against it one may need to know how student ability influencesoutcomes. The question can be posed interms of individual or school characteristics (e.g., the mean ability scoreof the student body, the range of ability scores). The administrator'squestion appears to be, In the presence of what school characteristicsdoes this innovation provide cost-effective results?Only if there isa live possibility of reassigning students among schools, or of assigning thestudents within the school to different treatments, does the decision aboutadoption rest on individual differences.42 2 1.14to analyze so as to disentangle This paper examines howeffects at two (or more) levels and how to interpret bothsets (or all sets) of findings. Psychological bias and sociological biasAs Matilda Riley (1963, pp. 707ff.:Lid, it is natural forpsychologists to think in terms of individuals and for sociologiststochink in terms of collectives .Not only is the psychologist'stheory in that form, but the experimental tradition hasalways looked on the single animal or the single human subject as aatExperimemtalbiological organism responding to an objective, manipulable world.a research,even in social psychology, has consistently formulated propositions about a condition that can be imposed \"uniformly\" on all subjects, as if theywere being run one by one in an experimental cubicle. This language hasbeen carried over into evaluation studies and research on classroom learning.In psychology, units of analysis have received appreciable attentiononly in connection with laboratory studies of learning. A number of papers(e.g., Estes, 1956) have discussed the fact that \"group learning curves\" -- i.e., curves fitted to group averages on successive trials -- have littlein common with individual learning cur,,es. In particular, a group curveshowing gradual learning may actually be a composite of individual each ofcurves9in which \"sudden\" learning occurs. Insofar as this discussion A.has been influential, it has reinforced the psychologist's wish to avoidaggregation.Scheuch (1966) discussed similar individualist and collectivistbiases as they have appeared in economicS (and, incidentally, inpolitical science). The attempt to develop theory by combiningindividual preference or demand functions appears to be the exactcounterpart of the psychologist's attempt to combine individuallearning curves, save that combiningworks out badly for thepsychologist and analysis at the individual level works ouEbadly for macroeconomics.23 1.15A debate in educational psychology. The conflict between thisorientation to the individual and an orientation to the groupseems first to have been aired .in an educational context in 1967 (Wittrock & Wiley, 1970, pp. 271 ff.).In that symposium on evaluation David Wiley stated that the appropriate unit ,of study in educational evaluation is the collective-- class or school -- rather than the individual. (Today, he TJould not emphasize one unit to theexclusion of the other.) Wiley was challenged by Benjamin Bloom, whoinsisted that it is pupils the school teaches. Pupils react as individuals,and the effects on them should be the focus.The instructor and psychologist,Bloom protested, are too often pressed to investigate the wrong question justbecause it fits into a rationale the methodologists find comfortable.Wiley properly retorted that he had been speaking as a substantive specialiston education, not as a statistician. Upon saying that, he was attackedby Robert Glaser for \"ignoring the existence of a discipline called the .experimental psychology of learning\". Glaser judged it inappropriate toseek conclusions about classrooms.Effects in the classroom are anaggregation of effects of environmental arrangements on individuals.With a sufficient understanding of the laws of individual learningas compiled in experimental psychology, one would be ready to design environments.A bit later Glaser said, in echo of Bloom:\"It is stilltrue that noone has ever taught a class.You teach anindividual in the context of a class, but no one hasever taught a class.It is impossible to teach a class. You teach individuals whose behaviorchanges....The class isa convenient artifact so that the teacher can.reach onestudent.\" Against thiswe can place one of Wiley's final remarks,2 4 1.16 pregnant for this report:\"When we talk about the effects ofa treatmenton the classroom, we are talking about something fundamentally differentfrom the effects of the treatmenton the individuals in the classroom.\"Glaser's position does not appear to be tenable. Inprinciple, an adequate account of the laws of learning at the individuallevel would indeed predict response to any environment, just as inprinciple an adequate understanding of physical forces at the molecularlevel would account for the durability of a bridge. The laws thatdescribe learning, however, have to be interactive laws thattake intoaccount both the characteristics of the individual and of the setting(Cronbach, 1975). Many of thoseinteractions (e.g., effects on thestudent of the abilities of theother group members) can only be studied in the group context. That isto say, parameters describing the group haveto be written into the\"laws of learning.\" Such relations can only be detected throughresearch on groups of particular kinds (Putnam, 1973).Debates within sociology. Just as the psychologist prefers to seeindividual causation wherever he looks, many a sociologist envisions group-level causal processes wherever he can.Aggregate variables have been ofparticular interest to those sociologists investigating social-psychologicalprocesses.The investigators at the Bureau of Applied Social Research atColumbia, and their disciples, have pursued studies of \"context effects\"with considerable enthusiasm. The central idea is that one's actions anddecisions depend not only on his individual characteristics but also onthose in his reference group.EAmong reports of context effects or alleged context effects, the onebest known to educators is that of Coleman et al. (1966). It was arguedthere, on the basis of a regression analysis, that a student's achievementand aspirations increase if he is in a student body that is strongly motivated.2 5 1.17 Allan Barton (1968) attacked those sociologists who processed data atthe individual level, as a prelude to a description of some of the causalmodels that could be used at the group level: For the last thirty years, empirical social research has been dominated by the sample survey. But as usually practiced,using random sampling of individuals, the surveyisasociological rneatgrinder, tearing the individual from his socialcontext and guaranteeing that nobody in the study interactswith anyone else in it. It is a little like a biologist putting his experimental animals through a hamburger machine and_ looking atevery hundredth cellthrougha microscope; anatomy and physiology get lost, structure and functiondisappear, and one is left with cell biology. Barton went on to point out that to reduce sampling ehror the pollsterscatters his interviews widely and thereby loses the opportunity to look40 at behavior in, for example, neighborhood clusters. Representative ofreports of context effects is a study by Bowers (1968) in 99 colleges.Students were asked, for example, if they disapproved of drunkenness and if(or cheating, etc.) they had been drunk. The percentage of drunkenness was crosstabulated (seeBarton, 1970) against individual approval/disapproval, within colleges where(for example) the disapproval rate c,hs high. The persons who as individualsapproved were less likely to have gotten drunk if the majorityin their college strongly disapproved. hauser (1970b) pointed out thatBowers was in effect entering the group mean X and the individual attitudemultiplescore X into a regression equation to predict behavior, and dhen claiming thepositive weight for X as evidencefor a context effect. Robert Hauser has spearheaded an opposition group within sociology.Hic 1971 monograph reviewed the literature to that date and challenged thosewho had tried to show context effects: Contextual analysis is based on a misunderstanding ofstatistical aggregation and of social process which is 2 6 1.17a rooted in the identification of differences among groupswith the social, and differences among individuals withthe psychological. [p. 133Bowers' two-variable analysis is of just that character (Hauser, 1970b).Hauserwenton (1971, p. 46) to argue that the usual interpretation giventhe Coleman report is indefensible. Those who are conservative regardingcausal interpretations typically refer to \"compositional effects\", a termapparently introduced by Davis, Spaeth, and Huson (1961). In an oft-cited paper (1970a), Ha6ser challenged his fellow sociologistsjust as Wiley challenged the psychologists. Hauser contrived a demonstrationof a context effect: thAt educational aspiration of students (within eithersex) rises as the proportion of males in the high-school studeut body rises. For the sake of heightening the drama, Hauser went on to propose socialpolicies that would hold down the proportion of females receiving a high-school education. Then he demolished the claim for a context effect byreinterpreting the global sex-ratio variable as a proxy for such aggregatevariables as IQ and social status. The groups with high ratios also werehigher in the proportion of high IQs and students of high status.Hauser's argument is essentially about specification error. If onerelates the dependent variable to only a fraction of the initial variables atthe individual level that contributed directly to the effect (or that contributedto the allocation of persons into groups), this is equivalent to using an inadequatecovariate to adjust scores in a quasiexperiment. Only if an ideal adjustment ismade (Cronbach et al., 1976) will one properly evaluate the effect of groups as such. 27 1.17 b Barton (1970) challenged Hauser's argument and Hauser (1970b) replied.The debate continued in a paper by Farkas (1974) and a rejoinder by Hauser(1974).The several papers cite earlier arguments for and against contextualinterpretations. It is unnecessary to restate the several positions, parti-cularly since I am advocating a kind of analysis not discussed directly bythe others.It may be useful to restate the essence of Hauser's position asI understand it. The heart of the matter is a rule of parsimony; if most ofthe variance can be explained by individual-level relationships, there is noneed to invoke a contextual explanation.Thus, where Bowers gave X and Teequal status in his regression, Hauser considers it appropriate to calculateregression weights for X and X.X. Since X and X are correlated, this proce-dure allocates most of the predictable variance to the first predictor. (Myproposed scheme is similar to Hauser's save that it fits weights to T.( andX-X-- which equals X X .)Hauser does not deny the possibility of causaleffects at the group level, but he places on them the burden of proof. More-over, and his point is one that no writer of the 1970's would deny, anyserious claim to a group-Ievel causal effect ought to be supported by tracing itto observable intermediate processes.Simple pre-post correlations orregressions do not carry much weight in a discussion of causes today. The terminology of the sociological debate has been an unnecessary sourceof confusion.I suggest that three kinds of relations are worth distinguishing; 1.Demographic effects. The groups examined have, as groups,no causal influence. But the groups differ on certain precursorsof the outcome variable of interest.Processes at the individualoutcomelevel would generate differences between the groups. This is AHauser's preferred explanation for observed effects at the grouplevel.One might speak of \"composition\" effects, but there areambiguities in the term. If desegregated schools create outcomes28 1.17c unlike those the same students would have had in segregatedschools, this is a consequence of studentbody \"composition\". While \"demographic\" is open to thP sameconstruction, I think it can serve as I have defined it. 2.Group-caused effects. Outcomes for a given individualdepend on the group he associates with or the setting in whichhis group works. This includes \"context\" effects that arisefrom peer influence, and also \"school\" effects that arise from particular curricular offerings or other nonpsychological causes.Insofaras the events in the desegregated school modify outcomes, theeffect is \"group-caused\". To be sure, a new curriculum is notcaused by the group, but it is a cause that affected the personbecause he is a member of the particular group. 3.Arbitrary aggregation effects. The relations listed above applyto the study where groupsare observed over a period' of time andchanges are to be explained. Grouping is sometimes imposed on abody of data after the effects have been produced.This happens whensurvey data on, for example, race and unemployment are aggregated tothe level of, say, the county. Insofar as the basis for aggregationcorrelates with either or both the variables of interest, statisticsat the aggregate level may differ from the corresponding disaggregatedstatistics. As we proceed it will become increasingly evident that, from data on Xand Y alone, it is impossible to establish which of these classifications aphenomenon falls into. 2 9 Units of analysis? oftreatment?of theor ?Abt, handed data to process, saw the question as oneof units \"of analysis\". At an earlier stage in the Follow-Through evalu-ation, however, the question had been faced as a choice of units of design, i.e.,of sampling and of treatment. The sponsor was instructed to identify schools inwhich he would install his FT treatment and similar schools to be NFTcontrols.This only crudely approximated a process of formal samplingand random assignment, but it did identify the school as the unit to whichthe treatment would be adninistered. (The plan actually called for treating justa few classes per experimental school,ignoring the others.)A structurally different decision was made in designing the Performance(Ray, 1972). Contracting experimentA Districts were chosen as before, somewhat arbitrarily,and two schools with disadvantaged pupils were selected within the distrif_t.One of these went into each treatment.The district was a sampling unit --given an intent to generalize the results into national policy.The school,however, was the unit of assignment, hence of treatment.Someone might challenge this terminology by describing a study with thesame design where the treatment was a vaccine administered to eachexperimental student individually, with a placebo administered in thecontrol school. Individual injections or no,I stillsee the treatment unit as the school. The design equalized districtfactors over treatments, but it confounded school factors with the treatment.If this design was consciously preferred to a split-school design, thejustification must have been interest in some social effect (e.g., spreadof the disease in an inoculated community). It is possible for the unit of sampling and the unit of treatment to differin other ways. One mignt sample individuals and assign them to classes individ-ually, and then assign classes to treatment.Then the unit of treatment is clearlythe class.;onversely, one might sample classes and then assign individuals fromthe classes to one or another independent treatment.30 1.19This brings us to the unit \"of theory\". Thechoice of design is often constrained by practical matters, buttherationale for the design ought to come from theory. Theoryneed not be grand and abstract, but it does state a question ingeneral terms. The wrong design may examine too broad or too narrowa phenomenon.Federal support for Performance Contracts was entertained asa national policy, but it was surely anticipated that each districtwould decide whether to enter such contracts.Hence a contrast ofexperimental and control districts would have been sensible. 5Ifthe thought was that PC, once adopted, would become mandatory forall districts in the nation, the logical experiment would, on itsface, be a period of nationwide trial. The contrast group could beanother nation or the same nation in the pre-experimentperiod.The notion of taking the nation asthe unit of treatment may bedismissedif theory says that every effect is mediated locally.Insome contexts no such cla. would be made. America's \"noble experiment\",the Eighteenth (Prohibition) Amendment, could not have been evaluatedby studies of prohibition ac local option. To define a unit of theory is to argue that there.are boundaries in thesocial space which mark off entities that have properties of their own.Justhow to identify \"entities\" or \"systems\" for scientific study, where objectboundaries are not apparent to the eye, is a question of long standing in manyfields including sociology (D.T. Campbell, 1958). Some social entities appearto be good subjects around which to build theory; they cohere, and their membersundergo common experiences. Other groupings (e.g., by first letter of one'sname) have nc more than momentary power to produce a common effect on the groupmembers.Groups that are real for some purposes (e.g., college majors) areunlikely to be the groups around which some other aspecL of behavior (e.g.,social life) is.organized. Groups that are interconnected in some respects,hence part ofa larger system, may function as independent systems with31 1.19a respect to certain phenomena. Analysis at the level of the collective is likely to have no justifi-cation in science or in policy studies unless the collective is in somereal sense a carrier of an effect. Shively (1969, p. 1184; his italics)warned against calculating ecological correlations, and presumably wouldwarn against regressions also, \"unless the theory with which we are workingconceives of the aggregations we are using as real entities, for which noother type of aggregation can readily be substituted.\" In educationalresearch it does seem reasonable to think of classrooms and schools anddistricts as having real enough effects. To analyze at the group levelseems to invite no greater penalty than the disappointment of looking fora group-level effect and finding it absent.In other kinds of research,the social fabric may be so seamless that no unit of theory can be readilydefended.Then some model other than that of members-nested-in-unitsmay be required. Hannan (1971) considers that the so-called aggregation problem insociology (and economics ') arises as much from the units of theory asfrom the units of aggregation for analysis.(Where, as is usual, sociologicaland economic data are collected naturalistically, no question of unit ofassignment arises, and hannan does not concern himself directly withsampling units.) 39 1.20 Macrosociology and macroeconomics seek generalizations applicable tolarge collectives, whergasmicrotheory seeks to generalize about processes occurring among small units (e.g., social participation or purchasing behavior of the single family).Propositions at the two levels may be cast in terms of the sameconstruct (e.g., per capita income). Some sociologists -- Hannan pointsto Parsons as arch-example -- expect \"homology\", with the same relationsemerging at all levels once the right set of variables is identified. Others, including Hannan, expect the micro path coefficients linking homologous variables to differ from the coefficients generated by macrodata on the same sample. He sees the ultimate problem not as picking a unitof theory but as of developing a \"between levels\" theory of aggregattonprocesses, to permit reductive interpretation of macro data and aggregative interpretation ofmicro data.Micro, macro, and aggregation relations together constitutean idealtheoufor Hannan. What social scientists have generally seen as a problem of data analysishas a striking correspondence to a major issue in the philosophy of natural science, reductionism. Daniel Bell (1975) discusses the attitudes thatphysicists, in particular, have taken to the proposition that relations needto be developed in an integrated manner so that one can read upward fro!\"subnuclear processes and downward from phenomena on the hunan scale andlarger.How close Bell is to our concerns is indicated by the fact thatat the outset he quotes J. S. Mill to illustrate\"the 'naive'formulation of the issue\": Human beings in society have no properties other thanthose which are derived from and may be resolved into thelaws of the nature of individual man. 1.21 The need to move back and forth between levels of aggregation is minimal for the physicist, Bell suggests,because the energy thatgoes into processes within atoms -- for example -- is some orders of magnitude below the energies that go into the kineticmotion of gas molecules at normal temperatures. The proposal to lookat each level in turn in social research cannot use that rationale; the energy in individual transactions must be of the same order ofmagnitude as most contextual effects arisingfrom the class. Apart from that, my proposal to examine class-levelrelations and then to examine individuals-within-class isin strikingparallel to what the physicist does. Having studied molar gas lawsto his heart's content, he turns to the study of forces binding atomswithin the molecule. But he seeks conclusions about atoms within apure gas, not a conclusion about atoms without regard to molecularcontext. I can see the benefit to be gained -- in principle -- fromHannan's integrated theory. Suppose our question is, What will it doto students' life chances if we require passage of an achievement testbefore allowing them a high-school diploma? A local ruling, a stateruling, or a national ruling would have different effects, and a theoryof the type Hannan has in mind could hypothetically forecast them,without experimenting at all three levels in turn.I have no faiththat social scientists can attain such powerful theory (Cronbach, 1975).If I am right, it is necessary direct one's inquiry to whatever level ismost pertinent to the question of theory or practice of most immediateconcern. 1.22 Units within hierarchies. Almost all previous writers havespoken of thecontrast between analysis of elements and analyses ofcollectives, Abt and Hannan being recent examples. My plan of attackis instead to pick one level of collective and examine (a) relations between collectives at that level and (b) relations of elements withincollectives (rather than relations of elements without regard to theboundaries of their collectives). 6 Almost allmy argument will be confined to two stages -- e.g., pupilswithin classes. I shall consistently treat a measure on the smaller unitas a composite of a mean for the larger unit and a deviation from that mean.(E.g., mean age of class, and pupil age minus class mean.) 7 There is nologicaldifficulty in extending sucn a series of componentsover pupils-within-classes-within-schools-within-districts. lath a dependentvariable at one level, all components of independent variables associatedwith that level and higher levels may enter the analysis. (Also, a statistical index derived from a component at a lower level may become an independentvariable.E.g., the s.d. on a predictor of pupils within a class may be used toaccount for class mean differences on the dependent variable.)The same principle could be applied in the reverse manner, the class mean being acomnosite or pupil score end class-mean-minus-oupil-score. Then taedeoeninnt variable at one level is ex,)laine0 1J.co-,puneats a.. Cant 12ve1and lower levels. For sore studies this may be more appropriate than downward decomposition. The chief difficulty is that the deviationscore is correlated with the lower-level score, which complicatesanalysis and interpretation. (The scoreX.X(= X - 112X) has a zero correlation with X.) 1.23 This upward decomposition was central to Blau's (1957) definition of struc-tural (context) effects. When Hauser restated Bowers' question in terms ofregression weights for X and X-X,he was proposing a similar upward decompo-sition.This formulation seems to be the one that springs to the mind ofthose sociologists who choose not to express relations directly in terms ofX and X.Perhaps this follows from the obvious causal principle that Xarises from X and from the sense that a context effect is something added.A reference-group perception, however, might easily operate causally interms of XX,as is seen in Meyer's hypothesis (1970, p. 63) that astudent's judgment of his own ability -- which affects his aspirations --arises from his standing relative to his group. I do not argue that X isprior to X; rather (p.3.3 ), I make X prior to X and X X .I also parti-often tion Y, which has not been done in the sociological literature.Insofar as 4I have a causal preconception, it is that X often determines what educationalactivities are offered to a class or student body. But no one causal positionfits all studies. Units in areal analysis. The procedure probably does not apply wellto all the kinds of nesting considered in writings on aggregation. Whereexposure to treatments takes place in South Sea islands, and the islands are assembled into collectives each of which unites the islands under its own policy,hierarchical analysis applies. This is equally the case withclassrooms nested within schools. In the old problem of slicing up a timeseries, however, months nested within years or biennia are not islands. Aprice movement is not contained within a month or a year. Areal unitssimilarly flow into one another and, at least in agricultural research, 3 ti 1.24 the reporting area corresponds badly to the causal variables such asweather and marketing facilities. A model of units nested within larger units may be unrealistically simple even in schools. In simpler days, pupils were nested within classes, firmswithin industries, families within communities.Today, even the 9-year-old maywork in a dozen groups and individual settings with several teachers andaides, all in the course of a school daY.Similarly, the firm is often aconglomerate, and family members commute and so come under the influence ofseveral communities. Streuning (in Streuning & Guttentag, 1975) points to theimportance,for evaluation of health services,of an ecological analysis.He proposes to divide a catchment area with a population of perhaps400,000 into 100 units, and to correlate characteristics of the unitwith indicators of use of services. His plan calls for reducing alarge set of predictor variables and a large set of dependent variablesby cluster or factor analyses, followed by calculation of multiple-P..'regression equations relating dimensions from the two sets.Thecoefficients in these equations would generate hypotheses aboutways to increase use of services. Streuning's planprobably represents,at its best,the state of the art in using existingrecords to understand and improve a social program. The question to consider here is whether the choice of unit matters.Streuning chose not to use a unit smaller than the census tract, presumablybecause many data available at that level are unavailable at lower levels.He chose not to use a larger unit because a sample size of 100 or more isrecommended for inference from sample correlations. Streuning does not arguethat the tract boundaries relate to any gradient of action. Some actions --say, reducing the income level at which a certain service is given withoutcharge -- are conditional on individual characteristics. Some -- establishing37 i.z5 a hot-line phone for pregnancy counseling -- are citywide. Streuning couldwell have thought more about the choice of unit.The N of 100 units shouldnot be a ruling consideration for Streuning. Insofar as he is seekingpolicies for this single catchinent area he is dealing with a population, nota sample.Insofar as he is seeking theoretical insight he is dealing with asample of size one (of many catchment areas in the nation). Although it may bedistressing not to have some data for units smaller than the census tract,this is not an insuperable barrier to using smaller units; one can assignthe value for the tract, or a prorated value, to each of its subunits (say,an apartment building). Geographical areas can be divided coarsely or finely. The Yule-Kendall computations on wheat and potatoes (p. 2.12) show that correlationschange with the unit of analysis. Some corre-lations will change more than others. If so, both at the factor-''analytic stage where he reduces the predictor set and at the multiple-\"regression stage, Streuning could expect to get different results ashe alters the unit of analysis. As no areal unit can be seen as the unit of theory inStreuning's case, it is uncertain what procedure to recommend.Anext step appears to be to collect data that are disaggregated to thegreatest degree possible, and to apply the proposed methods of analysis across and within various alternative levels of aggregation. A seriousproblem for studies of human ecologies -- once we leave the neat hierarch- icalpartitioning of schools -- is how to bound \"an ecology\". Arbitraryslicing of areas along the lines of large aggregate reporting unitsdefined without reference to the problem in hand seems certain tomisdirectthinking. 3 8 Page1.21.26Notes for Section 1 1In this report, treatment is a general term. It includes controlled andadministered instructional or therapeutic interventions, but it alsoincludes variations in services that sprang up without control (e.g.,talkative teachers vs. listening teachers). Any service or activity orpolicy that could in principle be installed deliberately is a treatment.Although many examples in the first parts of this paper refer to treat-ment contrasts, the theory to be developed considers relations within asingle treatment. It therefore applies not only to experiments but tonaturalistic studies (e.g., of utilization of educational TV). Much of the discussion of units in sociology has been concerned withcorrelations between variables that are present simultaneously (e.g.,ethnic and religious identifications). Some of my thoughts about asym-metric relations of treatment to outcome may not fit these studies wherethere is no manipulable variable. 1.62In an appendix, Abt claimingas many as 3800 d.f. 1.99aLumsden (1976) takes vehement exception to my advice regarding disattenuation. I should apologize for recommendingdisattenuation and yet reporting attenuated results throughout this work.The examples are all secondary analyses, and at best I could show the effect 01a guessed reliability coefficient on any results. 3 9 Page1.11Notes 1 cont.1.273This is not true, of course, when groups are formed at random andtreated individually. Then any relation of X to any variable is nothingmore than a \"compositiod' of the relations of X. When aggregationisafter the fact, and individuals within an aggregatehave been treatedindependently, the statement may or may not hold. Consider race as the basis forgrouping.Income within the race group may be an indicator of successfulperformance; income as a between-group variable is heavily colored withmarket inequity. The variable in the total pool is a mixture of the twoconstructs. 1.123aBlalock (1964, p. 98) says that when relations of Y to X and X differ therelation must have been altered by the entry of certain causal variables atone level and not the other. I prefer to say that X and X are distinctvariables,The properties of what the physicists call a critical massarise from the aggregate itself, not some \"additional variable\". The wholein this case is more than the sum of the parts. 1.133bIn the one trial of such a scheme that we have made, the three analysesgenerated much the same standard deviation of residuals in a cross-validation, though the regression equations did not weight the variablesin the same way. 4 0 Page1.13 1.19Notes 1 cont.1.28 4Even then, research conducted in schools as now constituted is a poorbasis for forecasting what will happen when new assignment rules areadopted, 5From schools contrasted within districts one can generate a difference score between treatments for each district. What appears to be a school-'level design is thus capable of being given a district-level analysis. A policy decision that PC should or should not be adopted district-widehereafter, on the basis of a difference in this study, does require the assumption that the effect in a PC school is the same whether ok not comparable schools in the district have PC. The choice of unit for assignment of treat- ment thus rests on a theoretical proposition. Even the district-may not be a large enough unit for adequate evaluation of a policy. The Federal governmententertained the idea of encouraging district use of such contracts; but if the designer of the evaluation could offer grounds for believing that payoff would be greater when all the districts in a county went on the contractingbasis, then sampling scattered districts would not disclose important data on the working of the policy. 1.19a5aThere is a substantial literature in economics and econometrics that I have made no attempt to review. 1.226Analysis of elements within collectives is of course the basic method in comparative studies that take one nation or one school at a time,and then repeat the study in another collective. I know of noinstance in which such a comparative study has formally analyzedacross collectives as well as within collectives. 1.227The dichotomous variable such as Black/White becomes 7r = per centblack for the class, and 1 -7ror-71)for black or whiteindividual, respectively. Although the two components are linearlyindependent, the variance of the deviation component is nonlinearlyrelated tor.41 2.1 2.Units in various research contexts The problem as seen in research on Aptitude x Treatment interactionI was brought to face the aggregation problem while R. E. Snow and Iwere completing a review of the numerous studies on Aptitude x Treatmentinteraction (ATI; Cronbach and Snow, 1976). The issue in such research iswhether outcome-on-aptitude regressions (hereafter, I refer to Y-on-Xregressions) have the same slopes within the treatments -- say, withincompeting teaching methods. Findings on interaction might give the school a basis for assigning a particular student to whatever mode or style ofinstruction is to produce best results for him. The investigatornaturally approaches the problem with tlie p3ychologist's bias, asking how 4 2 individual characteristics relate to individual outcomes and henceto choice of treatment for the individual. Conventional thinkingabout aptitude effects on individuals is not fully applicable, Snow and Inow realize.A practically relevant conclusion ought to describethe result to be expected under the usual school conditions. The_ school teaches students in groups -- even in much \"individualizedinstruction\".Sample size for regression analysis. Investigators conducting ATIstudies in classrooms have, with rare exceptions, pooled the data for subjects within a treatment before analysis, ignoring the class grouping. They have taken the individual student as the unit of analysis.Even in a simple t-test on the outcome in a true experiment, acalculation at the group level is less likely to reach significance than a calculation at the individual level. Assuming uniform group size n 2 the twotvalues have approximately the ratio nnyThus if T4 has a reasonable value of 0.30 and n10,the individual tis 3 times the group t.In regression analysis the lack of power is even more serious. (See Section 7.) Something like 100 degrees of freedom is required to reject the hypothesis that a regression slope is zero when the actual slope is large enough to be of considerable importance -- say, a standardized slope of 0.4.(See Cronbach & Snow, Chap. 3,4.) Consequently, 100 classes (!) must be observed to get a good fix on a between-classes regression.Pooling classes and analyzing individual scores, theinvestigator claims a large number of degrees of freedom; he Is then 4 32.2 2.3 more likely to be able to report a significant difference betweenregression slopes. Unfortunately,his significance levels are spuriousunless he makes strong assumptions. If classes are the unit of sampling,the number of classes is the natural basis for statistical inference. The strategy of ATI research (andof much other social andeducational research) will have to be modified, once it is recognizedthat the costs of the usual strategy are nearly prohibitive. Experiments examin-ing the difference between group-level regressions will be uninformative, in thesense that the prior and posterior probabilities of accepting the nullhypothesis are nearly equal in a study of reasonable size. Only with thesample sizes attainable in survey research will one find it profitable toassessthe \"significance\" of group-level regressions. unitsThe Maier-Jacobs study. One team investigating ATI did take classes as theof analysis.Maier and Jacobs (1966) carried out a year-longexperiment in many classrooms. Spanish was taught by programmedinstruction in 39 elementary-grade classes; 17 by an \"orderly\" and 22 bya \"scrambled\" program. Maier and Jacobs analyzed the classroom meanson various pretests and outcome measures and reported, among otherconclusions,that the outcome means were similar in the two treatments.The between-classes regression slope of attitude toward programmedinstruction (posttest) onto IQ was positive when the orderly programwas used.(The slope was small because the s.d. of attitudes was verysmall in the metric used, but the correlation was 0.75.) The implica-tion is that duller classes liked the orderly program less than ablerclasses.In the scrambled treatment there was an effect in the oppositedirection; programmed instruction received higher ratings in duller classes. 4 4 2.4 Another set of between-classes regressions used IQ as the predictor am.an achievement posttest as the outcome. Maier and Jacobs provided Snowand me with statistics on those variables for all cases pooled, from which we could calculdte three sets of achievement-on-IQ slopes: OrderlyScrambled Overall (individuals pooled) 0.530.62Between classes 0.500.77Within classes (pooled) 0.550.52 The differences are not enormous, and no sensible comment about significance can be made with a limited number of classes pertreatment. Evidently,ablerclasses pulled ahead ofduller classes, most strongly in the scrambled treatment. Second, IQ differences within the class related to outcome similarly in eachtreatment.This (like many other studies) denied the working assumptionof the programmed-instruction movement of the 1960's, that orderlystep-by-step progression of instruction would largely erase the effectof IQ on learning. 45 2.5 Harvard Project Physics. The evaluators of Harvard Project Physics,an innovative high-school curriculum, likewise collected data in classrooms scatteredover the nation. In addition to individual scores on beginning-of-year and end-of-year tests, the investigators had information on theclimate of each classroom, obtained by aggregating questionnaireresponse!: of students. The papers of this project sometimes reportedanalyses at the individual level (cases from all classroom beingpooled) and sometimes reported analyses of class means. The chiefreport published to date (Welch & Walberg, 1972) analyzed at theclass level.The several analyses in this and earlier publicationscannot be directly compared because they used somewhat different variablesand statistical techniques. Interactive effects were reported.The studies suffered from a number of faults common in research oninteractions at that time. Snow and I, after a critical look at themethodology of the studies (Cronbach & Snow, 1976, Chap. 10), wereuncertain as to the dependability of the interactions reported. Thecomparison of main effects, using classes as the unit of analysis,was open to much less question. Walberg (paper in preparation) has recently reflected on theHPP experience. He comments that the research group received conflictingadvice from methodological experts as to the best way to handle themixture of individual and class data they had amassed.His paper (in itscurrent draft) goes on to list something like a dozen competing modes ofanalysis, several of which were tried by himself and his colleagueson one or another set of variables. His final paper will be of 4 6 2.6 obvious use topersons interested in this report; but it would beinappropriate to discuss the draft here. Only late in our work did Snow and I 1)come aware that the interactionphenomenon has to be defined substantively as a between-groupsor within-groupseffect.We came at last to see the importance of Wiley's view that responseto treatment is not simply an individual-level process.Group characteristics -- aggregate or global -- may interact with treatments,and they may interact in a different manner than individual characteristics.Some pages on this theme were added to Chapter 4 of the Cronbach-Snowbook in the final stages of writing.Three kinds of process. To recapture the argument of those pages,it will suffice to consider the regressions of outcome Y onto aptitude X(the score for the individual p) and onto the aggregate Xc, the 47 2.7 mean of this same aptitude over individuals in class c.At least threekinds of causal phenomena may enterinto an observed interaction or an observed regression slope calcu-lated from individual-level data.There is a sample of classes.These need not have been assembledat random, but the classes are divided at random between two treatments.C:Acommon outcome measure is obtained on all persons, with thefollowing hypothetical results: a.The overall mean is the same in treatments A and B.b.The regression of outcome on a measure of initialability or achievement is nearly flat -- say, a slope of 0.2--when calculated on all the persons in the A group.c.In the same metric, the individual-levelregression slope is 0.6 in the B group (Figure 2.1).I.e., students with superior aptitude do considerablybetter in B than students of low aptitude, and consid-erably better than their high-aptitude counterparts inTreatment A. r:Three alternative explanations may be offered:1.Interaction at the individual level.2.Interaction at the class level.3.Interactive effects within the class.A concrete example will help in what follows. In Treatment A (didactic),history students study immigration problems of the U.S. through textbooksand teacher exposition. Treatment B is inductive; the students examineoriginal documents, newspapers, etc and work out conclusions throughdiscussion. 4 8 at 2.7 (i)Result observed in pooled data (ii)Regression generated by individual effects,with and zero.Yx x x Figure 2.1.Alternative ways of generating an overall regression slope of 0.64 9 2.8The three kinds of effects can be examined without reference to differencesin slope(interaction4 The prior problem is to explain the within-treatment regressions. How might the steep regression (all casespooled) in theinductive treatment have arisen?Let us assume that the groupsdiffer at theoutset of the study only with respectto X and irrelevantvariables; i.e., there are no specification errors.Also, to hold questionsof attenuation effects in abeyance, let us assume that X is perfectly measured.(1) Individual level. Psychologists have regarded regressionsof outcome on aptitudeas manifestations of individual aptitude,working on lessons delivered tothe individual. If a Y-on-X regression is steep, the interpretation hasbeen that the person with a high score on the aptitude test somehowprocesses material more efficiently or diligently than the low-aptitude student. E.g., the fast reader has a considerable advantagewhen numerous documents must be scanned and evaluated forrelevance.Interpreting the observed interaction as of type (1) impliesthat the result would be found if students were exposed to the teachingmethod individually. Panel(ii) is consistent with this interpretation.The within-class regressions depart only by chance from the pooled regression.Any particular configuration ofregressions could arise from combinations of two or three kinds ofeffects, however. The modern interest in ATI st,met. or a concern with individualassignment in education. Cronbach andGleser (1957) establisheda rationale for validating such assignment rules. To justifyassigning students to alternativetreatments (e.g., to regular and slowsections), it was logicallynecessaryexisted inone treatment than in that asteeper neverass%med that data would be collected50 2,9 by assigning students from the whole aptitude range to each treatment, just as a selection test is validated on a sample from the whole range of applicants.In suggesting that regressions observed in wide-range groups would guide the formation of groups more homogeneous in aptitude, Cronbach and Gleser implicitly assumed that theregression slope reflectsthe response of the individual to the treatment. Hisexpectedoutcome in a given treatment was taken to be the same regardlessof the choice of persons to be treated alongside him. (2)Group level.An alternative causal hypothesis is that the level of aptitude in the class as a whole determines the effect of a treatment.Would not a steep slope be found in Treatment B if the sourcematerial selected for interpretation in abler classes (as identified by meanaptitude) were much superior to that selected for use by the dull groups? Such a mechanism, triggered by the class average, perhaps serves both the abler and less able trembers of the able class.Under this hypothesis the richness of the experience dependson the environment, not on the abilities of the students working singly.(See Panel iii.) A similar group effect might be found if the teacher regulates tile pace,forcing the discussion to a penetrating level in the able class andleavingit superficial in a dull class. (3)Comparative effects within the class. The third possibility 5 1 2.10 is that the regression slope is determined by effects within the class. Suppose that,in classes using the inductivemethod B,the ablest students within the class steal the show. They dominatethe discussion; they are rewarded for locating materials more rapidly thanothers, awl so are encouraged to redouble their efforts.The duller members of the class, systematically outshone,come to rely on their abler classmates to keep things going (Panel iv).Another possibility is that the typical teacher will habitually interactmore with the superior members of the inductive class.Effect (1) presumes that the outcome is a function of the student andthe choice of treatment, not depending in any systematic way on the makeupof the class.Effects (2) and (3) presume that class makeup matters, thattwo students whose aptitude is at the population mean will achieve differentlywhen one is superior to the classmates he draws and the other is assigned toa group abler than he is. In Panel (iii) a student gains by entering a classwhere he is below average; in Panel (iv) it is the other way around.The shallow slope in the didactic treatment A might be explainedby the gear-absence of all the three types of regression effect. Buteffects can balance each other. A shallow pooled slope in the didactictreatment may result if one effect is positive whereas the other twoare close to zero or one is negative. It is possible for a slope tobe negative (e.g., when a teacher concentrates effort on the leastable members of the class). The difference of 0.4 in slopes in the pooled analysis (---- 0.6 - 0.2)can arise in principle from an interaction effect of0.8 at the individual level, an effect of -0.4 (say, 0.2 - 0.6) at thegroup level, and an effect of 0.0 at the within-group level.Figure 2.2 5 2 2.11 sketches two out of many possible configurations that yield pooled slopes of 0.2 in A and 0.6 in B. An interaction observed in pooled data from manyclasses obviously cannot be directly interpreted.The problem I began with, then, was this: What analysiscomes closest to describing separately the interaction effects of the three kinds?And what problems of interpreting the findings arise?It has perhaps already become apparent to the reader that the problem is not adequately formulated in the paragraphs above. Once a distinctionbetween effects at the individual and class levels is made, it is naturalto separate within-classes and between-classes regression analyses. At best, this resolves into two components an effectthat has three possible sources. I see no way to disentdngle the effects in analyzing data from the usual designs. Aggregation effectsThe sociological and econometric literature contain many paperson what is usually referred to as aggregation bias. Robinson (1950) set in motion the discussion of aggregation bias in sociology by demonstrating the disparity. Later papers havejudged that Robinson was shortsightedto emphasize correlations rather than regression coefficients, butthe same issues arise when regression coefficients are compared. Although the literature triggered by Robinson's work is voluminous (see cita-tions in Dogan & Rokkan, 1969, and Hannan, 1971), thinking has notmoved steadily forward. Arguments have become more complex, but consensus is lacking. As late as 1971 Hauser could say that \"sociolo-gists have not yet fully exploited the insight it [Robinson's article] 5 3 'TREATMENT ACoefficient = 0.2TREATMENT (ii)Difference in slopes at the within-group 2.2.Distinctive configurations generating the same overall ATI(The intraclass correlation is assumed to be 0.75.) 5 t 2.12 provides into the interpretation of relationships at different levelsof aggregation.\" (His p. 11-12.) He went on, in echo of Riley (see p.1.14) to speak of a \"misunderstanding\" arising from the view thateffects at the group level are sociological in nature, and individual effects psychological (\"internal to the individual\"). Firebaugh (1975) ..rejects even today the complacent view of Scheuch (1966) that most of theproblems are \"intellectually settled\".The original concern for aggregation bias had to do with theeffect of arbitrary contiguous grouping. Yule and Kendall (1950, p.310-11) chose the example of a correlation between potato and wheatper acreyieldsKIt is necessary to use data at some aggregation larger thanthe potato patch; in the records, counties were the smallest availableunit.It seems reasonable a priori to group neighboringcounties.In a series of correlations for 48 counties, 24 pairs, then12 sets, and finally 6 regionE, the correlation moved up from 0.22 to0.76.Yule and Kendall properly concluded that a correlation is specific.to the unit chosen, but failed to consider deeper interpretations..Some of their within-region covariance was part of the overall between-c'county covariance.-Aggregation redefines the questioninvestigated by moving certain information out one variance (covariance)and into another. Ilrnetvist (1975, pp. 101-102) offers some educational examples withnon-arbitrary grouping. He correlated measures collected in the International Study of Educational Achievement at the individual, school, and country levels.The respective correlations of reading comprehension with a measure lf schoolsatisfaction among 10-year olds were 0.19, 0.18, and -0.77 -- a change ofdirection as well as size. He also shows that it is possible for aggregatecorrelations to be smaller in absolute value than lower-level correlations. rhe successive correlations for reading with science knowledge at age 14were 0.60, 0.76, and 0.54. no 2.13 2.14 Discussion in recent years has centered increasingly on causalinterpretation. A number of writers rejected Robinson's emphasis on onecorrelation as an estimator of another, making the valid point that the twocorrelations reflect different phenomena or processes.It is the failureto arrive at a clear logic for interpreting the two that continues to plaguethe field.Thus Patricia Kendall and Lazarsfeld (1955, p. 295) discussed data fromThe American Soldier where a within-groups regression coefficient was posi-tive and a between-groups coefficient negative.Soldiers who had beenpromoted gave more positive answers on a question about promotion chancesin the Army than men who had not been promoted. Ratings related positivelyto individuals' actual promotion. This was true for military police andalso true within the Air Corps. But promotion rates were higher in the AirCorps whereas the rating on promotion policy was higher in the MP's. Thatis, the between-group regression of rating on mean actual promotions wasnegative.Kendall and Lazarsfeld concluded that the group phenom-enon reflectS shared experience and perceptions and is not just an aggregateof individual data. Oddly, they abandoned this caution in another instance. Soldiers whochose their own assignments liked their jobs better than others did. Unitswhere choice was commonly allowed were most likely to be rated by theirmembers as good units. So the between-groups and within-groups slopes aresimilar.Kendall and Lazarsfeld said that the relationship,orroborates the result\" from group cit'a.This appears suspiciously circular.If the results had disagreed (as they could have), would the writers not thenhave insisted that the group and within-group data bore on different phenomena? or the sociologists in the Columbia group,most processes (e.g., gener-ating a certain income level) occur to the person in a group context, and no 56 2.15 process truly operates on the individual in isolation.Coleman (1954) urgescontextual interpretations because otherwise sociology becomes no more thanan \"aggregate psychology\". It appears that onecan interpret an aggregate regression coefficient as causally similar to anindividual coefficient only by assuming that groupmembers developed their scores on the variablesindependently, two members of a group sharing an experience no more oftenthan members of different groups.Moreover, even if Y scores of individualswere generated independently, if groups were formed on the basis of anyvariable that correlates with YX this will produce a difference betweenthe within- and between-groups slopes. (See Section 3.) There can be nogeneral warrant for substituting group data when individual relations areof interest.Conversely, an analysis at the individual level describes acomposite of within-groups and between-groups effects that is easy to misin-terpret. 57 2.16 Ecological psychologyThe context of human behavior is receiving increasing substantiveattention in psychology. Roger Barker devoted a career to the study of behavioral settings, adoptingthe Lewinian position that the situation intowhich the individual moves..toes as much to shape behavior as the personality of the individual.Barker's interest was in the microecology. Bronfenbrenner (1974, 1975, 1976)is less concerned with immediate situations and more concerned with thetotality of the individual's environment. Though each individual'scultural setting may be unique, from Bronfenbrenner's point of viewthere are statistical similarities.in the experiences of individualsliving in the same neighborhood or participating in the same communityculture.Neighborhood data are to be considered in the same light asclassroom data, and subjected to separate between-neighborhood andwithin-neighborhood analyses. Bronfenbrenner suggests that the effect of an experi-mental intervention (e.g., a program for disadvantaged children) is likelyto be small unless it radically changes the ecology of its subjects.Moreover, he questions the appropriateness of a strictly individualpsychologyi insofar as the subjects are part of the sameinteractive community, the community and its members may constitute asingle \"subject\". That is to say, a treatmentmay have a substantial effect in one community and a negligible effect or the opposite effect in another.PorhapS the contrast depends upon characteristics that could have beenidentified at the outset of the intervention, or perhaps on fortuitous 2.17 occurrences.Bronfenbrenner and C. R. Henderson (personal communication)have embarked on a program of disentangling between-gromosand within-groupscomponents of variance that apparently is probing more into technical,statistical issues than I have.Evaluative studies and school-effect studies The importance of group effects is slowly becoming recognized in theliterature on educational evaluation. As long ago as 1967,the Wiley-Bloom-Glaser debate took place at a conference on evaluation.In the same year Bock and Wiley (1967) argued that the bestdesign for a comparative educational experiment is often to assignclassrooms -- not pupils -- to treatments, at random within schools. Indata they studied, the component for differences among pupils usuallyaccounted for 20-30 per cent of the sampling variance of the outcome meanwithin a treatment, with pupils regarded as random.The remaining 70-80per cent of the sampling variance arose from schools and from classroomswithin schools. In their data, classroomsaccounted for far more variance in arithmetic fundamentals than schools, whereas schools (neighborhoods?) accounted for more variance in reading. 2.18 The Bock-Wiley paper is one of a series of \"school-effect\" studies thatask how much variance in achievement, aspiration, or career level is \"attri-butable\" to school differences. Another kind of school-effect study relatesspecific characteristics of the school (verbal ability of teachers, say, ormean sense of efficacy in the student body) to outcomes, as in the Colemanreport. Werts (1968), among many others, reacted critically to the Colemanreport.Coleman's analytic device was to partial the school means on familybackground and similar student characteristics out of the final achievementtest scores of individuals. The residual school effect (percentage ofvariance in individual achievement accounted for) was then interpreted asan index of the impact of the school. The Coleman report left the impressionthat excellence of facilities and other supposedly valuable features of theschool program had little or no correlation with competence of graduates.Good students tend to be found in schools that have good facilities, hencethe variance due to treatment overlaps the contribution of student ability.Partialling out student differences at the first step arbitrarily assignsthe overlapping variance to student characteristics and not to treatment.Werts advocated a partitioning due to McNemar which evaluates the uniquecontributions of student characteristics and school characteristics andleaves their overlap as a third fraction of the predictable variance inoutcome.The distinction between the individual and group levels ofanalysis was touched on in several of the papers, but became a focus of atten-tion only recently. Coleman himself (1975) has now acknowledged the validity 6 0 2.19 of the objection to partialling out family variables in estimating school effects, butsaysthatcritics misperceived the purpose of his 1966 analysis.Luecke and McGinn (1975) contrasted Coleman's method of analysis with another adopted by Project Talent.Among other conclusions, they report that Coleman's method systematically overestimates the effect onachievement of family background (vis-\u00e0-vis effects of teacher and school quality).Their procedure is to simulate the generation of student achieve-ment over five stages (years of schooling) by setting up a causal model and specifying parameters of the causal variables including the correlations that represent causal links. Far more is at issue in their paper than the level of aggregation. They are concerned with \"dynamic\" effects in a long- continued process, and with the fact that students change classes and schools. Scoring the quality of the student's own teacherinstead of using the aggregate quality of teachers in his school also modifies conclusions. I find myself discontented with the Luecke-McGinn presentation, particularly in their use of certain zero-order correlations (e.g., family with first-year achievement) as the standard index of infl.ience against which other analyses are judged. The study does illustrate the potential of simulations for forcing social scientists to recognize the consequ(nces of their analytic decisions. Simulations may have important uses in later work on aggregation per se. (iii) (iv) Figure 2.3.Alternative causal models for the relation of schoolquality to achievement6 1 2.20 Duncan (e.g., 1970) has been especiallyinsistent that any plan ofanalysis rests on a particular causal model.Pedhazur (1975) has recentlyapplied similar thinking to the effect of school-level variables on achievement.Figure 2.3 is a modified version of a figure on his page 247. I use circlesfor global school-level variables and squares for individual-level variables(which may be aggregated). Otherwise, the diagrams follow the conventionsof structural models. B represents background factorssuch as parentalincome; S represents a school-quality variable such as per-pupilexpenditure or quality of teachers; and A represents student achievement. unspecifiedU and V are causes or sources of error. The B-to-S relation in(i) implies that neither variable causes the other; the relation mustarise from some prior cause.In each other diagram, B contributes to S,perhaps via parents' willingness to vote more money for the schools.Achievement is said to depend directly on S in (ii), and directly on B in(iv); in (i) and (iii) the effect of B and S is joint. Pedhazur has muchto say about alternative ways of partitioning variance and of testing theadequacy of the several models, but he does not emphasize units as such.(Later in his article, he does identify the main sources in the units-of-rnanalysis literature but adds little of his own.)If (iv) is the model, analysis is wholly at the individual level withB as tne sole predictor. Adding S to the regression equation (with thesame value for every student in the school) would falsely reduce theapparent contribution of B to A, and would imply that A depends on S.Ifthis model does apply, the partial covariance sAs.B will depart from zeroonly by chance. 6 2 2.21 If (ii) is the accepted model, analysis can appropriately becarried out at the group (school) level, with S as the sole predictorof the aggregate A. There would be no reason to supplement this withan analysis of the B-to-A relation within groups if one believes themodel's assertion that the partial covariance a BAfSis zero. If (i) is the accepted model, partitioning of the variance is opento the ambiguities discussed by Werts. The analysis can be done atthe group level, with the aggregates B and A entered along with S. A supplementary individual-within-groups analysis of the B-to-A relation can be made.Model (iii) is analyzed much as (i) is, but the interpretationcan be less equivocal. The predictable variance of the aggregate Ais allocated to two sources: B-independent-of-S, and S. The S portionincludes some indirect or joint influence of B, but this is not seenas an influence \"of Bon A\"; it is an influence mediated by school quality.Here again, the model makes it reasonable to consider aB-to-A-within-S effect at the individual level. Most educational evaluations have been analyzed with individualsas the unit of analysis, even when using aggregate variables as in theLuecke-McGinn simulation. An example among studies of real data isthe report on Head Start Planned Variation (Featherstone, 1973) inwhich the number of individual children receiving each treatment 6 3 2.22 variation was taktm as the sample size for it.The PerformanceContracting experiment, on theother hand, used the average for a single school as a data point.Analysis at the classroom level is a third possibility -- as in theMaier-Jacobs and HPP studies. In principle, the evaluator could recognize hierarchical nestingbut apparently no evaluation report has done this.Pupils are nested within classrooms, classrooms are nested withinschools, and schools are nested within districts. It is reasonable to expectthat an innovation mandated from the top of the hierarchy -- let us say,by the State Department of Education -- will not trickle down uniformlyto the pupils.Possibly districts or communities will have a strong mediatinginfluence, in causing the innovation to work or in sabotaging it; desegregationagain comes to mind as an example. Innovations also succeed or fail at thelevel of the school, in the sense thatstrong school leadership can produceresults whereas passive compliance wipes out the effect. Within the school,individual teachers conform or fail to conform to the treatment specifica-tions, and add variation by the manner in which they carry out the treatment.And finally, of course, one expects individual differences within a elassroom. If one confines attention to the mean outcome in a treatment,nothing can be learned from a hierarchical breakdown; properly weighted,a mean is a mean is a mean. It is in the variances and regressioncoefficients at the several levels that differences could appear. 6 ,1 2.23 Extrapolation in interpretationTo conceive of an interaction \"at the individual level\" when treatmentshave been _pplied to individuals within groups is to engage in treacherous extrapolation. Data collected on groups are being explained in terms of processes within the individual. Such an interpretation is conventional in educational research and notunheard-of in general psychology, but it is highly questionable.A treatment may be significantly altered by the very fact that it isadministered to the suL,ect when he is in company with other subjects. Inthe example above, the inductive procedurefor teaching history would be radically altered by applying it to studentsindividually, as that would allow no way to retain the important feature ofgroup discussion. The ''operational definition\" of the treatment consists essentially of aset of instructions directing the acts of the experimenter or teacher.Whenthis identical operation is shifted from a group context to an individualcontext, the treatment is likely to be significantly altered.The teacher's reprimand, or instruction to \"Pay attention to ..is a different stimulus when addressed to the group in general than whenaddressed to the student in isolation. Thanks to social facilitation, doinga page of arithmetic drill alongside one's classmates is not the same taskas doing it alone. Thus the operational definition has to specify individual administration or group administration -- more than that, it has to specify the basis for constituting groups. As is well Known, evidence collected from applying one operationallydefined treatment may indicate little or nothing about what will happenwhen a treatment with another operational definition is administered.Sometimes the change in the6 5 -2.24 operation (here, the change made by altering the context) makes a largedifference, and sometimes it makes none.This has to be tested directly;experiments with one operation do not give direct evidence on another.Onemay reason indire'.7.t1y if he has established a strong presumption that thechange in operntion never matters. Berg,mann (in Prank, 13131 n.3) use,2t\".leexample of the location of the apparatus in an experimental room. -The presumption that a shift in location makes no difference is so strong,Bergmann says, that we are willing to ignore a shift in that aspect of thespecification. Bergmann is right in the abstract, but his example istelling in a way he did not intend.Gerald Holton tells me of the experience ofFermi and his group when they first attempted to bombard the nucleuswith neutrons, in an attempt to create artificial radioactivity. Theygot negative results when the apparatus was set up on one bench in thelaboratory, and aot success on another bench. The critical difference wasa marble surface on the first bench. Neutrons rebounding from thesurface had no more effect than those directly fired at the targetnucleus.The second table, with a wooden surface, slowed the neutronswhile scattering them, and it was these rebounding slow neutrons thatproduced the effect Fermi was seeking.Holton tells a similar storyof Rutherford, discovering thorium.Rutherford's electroscope dis-charged when far from the open door of his laboratory because ofradioactive gases in the air. When he had collected data with theapparatus near the door there was no discharge; the gases were sweptaway by currents near the open door. A presumption that a certainshift in operation has no effect, then, is a presumption madeat considerable risk. e'd 2.25 Group contexts surely affect human behavior at times. Hence evidencecollected by observing individuals behaving in groups is not a dependaoleindication of what will happen in an individual experiment. Nor can evi-dence obtained in groups composed in one manner indicate what will happenwhen the groups are formed by a different procedure, unless a strong theory about the character of the context effects has already been worked out. lhe group-level and within-group effects are observed in a sampleof classes.These classes can be regarded as drawn from a population ofclasses formed by a certain process. The results can be generalized tothat population of classes, i.e., to classes formed by the same processfrom a similar pool of persons.The inference is of a type commonplacein statistics.To make an inference to classes formed by some otherprocess or rule is just as much a leap in the dark as it would be toextrapolate from the treatment observed to some variant of it: The experimenter may or may not know what process formed theclasses he observes. If he formed them by randomly grouping membersof a student body or by another formal assignment rule, he can gener-ate similar groups by that same process so long as the population ofstudents is unchanged from year to year. If the groups were formedby the existing community and within-school processes, his findingswill apply so long as the school population is stable and thoseprocesses continue to control class membership. He cannot assumethat the findings will apply if a new grouping procedure is installedfollowing the experiment. Altering nothing but the size of thein,;tructional groups might be enough to change the relation of interest. 2.26 This line of argument can lead in two directions. (1)To beconservative, the person conducting an experimentinintact classeswill limit his conclusion to classes formed in the same manner.Heshould specify the process that formed the classes or the characteristicsof the classes, in such a way that others making use of his researchcan judge whether their classes resemble his in composition. Thisextends the usual recommendation regarding description of a subjectpopulation.In classroom experiments, the class is the subject andthe characteristics of the subject classes should be brought into theopen.(2) A liberalizing step is to regard the assembly rules astreatment dimensions. In the course of a long program of work,particularly work oriented toward theory, an investigator varies the specifications for an experimental treatment. The successivevariants form a collection that can be described by parameters, andthe varying effects can be described as a function of the parameters.When this process is well advanced, the investigator can make reasonable predictions about treatments that have not been roadtested.Just as a collection of manipulated treatments has parameters, apopulation of classes has parameters.Applying different sortingprocesses in successive experiments would build up some theory.One might be able then to make limited extrapolations to classesformed in ways other than those directly observed. 11 6 8 3.1 3.A mathematical model The regression equation neded for distinguishing the effects ofinterest can be built up in steps.Confine attention to a single treatment,and identify persons pas members of groups c.The person hasscoresXand'Ywhich may for emphasis be written XpandY P Pc The model could be set up in terms of xup andYu,the \"true\" or \"universe scores\" that would hypothetically be obtained by exhaustive measurement. Inthis section the model is in observed-score form. Universe scores will betaken up in Section 6. The class mean is the mean over the fixed class ofY(pc);likewise forX.I should note also that, so long as questions of statistical inference are held in abeyance, the model appliesto dichotomous veriables as well as to continuous ones. This section can be read as if all collectives have the same numberof members.When the number is variable, the definition of any parameterinvolves a weighting decision. See Section 4.Definition of couonents The Y score may be divided into general-Ievel, between-group, andwithin-group components in the usual mannerN/ (3.1)Y(oye)(Ypc- pyc) P A The between-groupscomponent divides into a part predicted by the group meanon (3.Xand a residual. Ititohe noted that the same regression coef f icient serves to predict that hest accounts for the 6 9 sum of squares within groups. Then (3,3)(YPy ) =(XPx )6 wp But within a particular group the regression slope Bcneed not equal aww;ich leads to the further (8a)(xxc) + (Xpcpxc) + cPcBetween, predicted Group residual Common within, predicted Specific within, predicted Person residual3. 2 The overall slope Bt considered by those who analyze at the individual level is a composite of fib and aw. As shown by Duncan, Cuzzort, and Duncan (1961, p. 66): t-st = 614 + rcabo aw)ornyb + (1-n2)awwhere q the intraclass correlation of X [equal to 02(Px )/o2(Xpc-)1, la Coupled with the argument on pp.4 .3-4, this formula has an importantimplication for those who try to interpret q in typical educationalstudies.is a weighted average. In studies with a modest number ofgroups, .-!1)is badly estimated, though Emay be well estimated. Thelarger the value of ,the more the error in bmakes for errors in .(The investigator usually has the illusion that numerous cases entered intothe latter calculation.) Puttingon the left side of 7 0(3.5)4 Ileave it unanalyzed. 3.3In a two-treatment study, uyincludes effect as well as thegeneral mean.In the two-treatment study of the usual type, groups are nestedwithin treatments and the treatment constitutes a third level in the hierarchy.The model (3.5) could be defined with Uc replacing aw. In general, thischange decreases the \"common within, predicted\" variance and increasesthe specific-within variance. The definition in terms of k is more conven-tional, often being associated with an assumption that group membership israndom and the Y, X distributions within classes homogeneous. The distinction has little importance for descriptive statistics. Forsome sets of data we have calculated b wand bcand found that the twodiffered negligibly. The expected value c= E [ \u00a3(XpP)(YpY)/(Xp11x)2] cpccppec pecdoes not generally equal= IE (XpuX)(YpY)1/E (XpX)2 cpc If more than one Xis available, forevery subject, weighted compositeswill account for more variance, between and within groups, than the single XThe model can be extended by introducing, for example, a Bbi13132, etc.It is comparatively difficult to think about the multivariate case, however;the best composite predictor between groups may differ from the best within-groups composite, and each preeictor group may have its own best composite.Theusual intuitive understanding of multivariate relationships isconfonndeu by the fact that predictors whose between-groups correlation equals zero may have a nonzero within-groupscorrelation, or vice versa. Consequently,anv geometric analo4y (e.g., reference to \"dimensions\") is likely to go 1shall return to the two-predictor problem.A simple structural model will perhaps be helpful (Figure 3.1).lne grouping rule determines the division of X between the class mean and73 rule ParentSES8cf3w11,at 3.3 Figure 3.1.Structural model for hierarchical analysis. .63tI\\.84141-A1(.94) (.33)Collegeplans Figure 3.2.Structural regression based on data of AlexanderNumerals showunstandardized regression coefficients; numerals in parenthesesshow standarddeviations for selected components. 3 .4 the deviation score. These C40 are uncorrelated. Analysis may then proceedseparately in the upper and lower tracks.The conventional \"individual-level\"analysis can be thought of as proceeding in the same manner, save that fib and fiware constrained to have the same value.The concrete example in Figure 3 .2 is derived from a figure of Duncanet al., 1972, p. 193; c here symbolizes a school, not a class.The originaldata were supplied by E. Q. Campbell and C. N. Alexander, Jr. (N = 1137.)Duncan et al. give correlations; I assume sx = sy = 1 to get regressioncoefficients.Also, I assumelinearity (i.e., that nx = r).px ).The intraclass correlations for X and Y pcare 0.20 and 0.11, respectively, indicating that more of the variance liesbetween schools in the independent variable than in the dependent variable.This on its face suggests that schools do not cause divergence. Such aninference would be stronger if it were believed that SES is a sufficientspecification of the precursors of educational aspirations established atthe time students entered school (including any preliminary statement ofaspirations).The regression coefficient, however, is higher betweenschools than within, which on its face argues for a tendency of high SESs,!1100Is to cause aspirations to rise.(For more on this kind of reasoning,Sec p. 3.l8.)The regression coefficients here are consistent with thedifference in correlations noted by Duncan et al. (0.86 between and 0.4;within); this would not always oe the case.Interpretation of components. To give a further sense of the implicationsfive basic components, Figure 3.3 displays regression lines like thoseof Figure 1.1. Regression lines for two groups are represented in Panels (i)-(iii).(The length, of the lines have no significance.) With two groups.tne group means fall on the between-groursregression line and ,re is 7 3 Y1, ..!iepiscli...,7\"N.c2 ( regressionLine through pooled-within-groupsslopeSpecific within-group regression Possible relations among Ob,7 4and Bc. necessarily O. In Panel (iv), four groups are shown.One of the ycomponents is labelled. In Panel (i), the e component for a singlemember of Group 2 is identified. Regarding the residuals: The residual eincludes any effectsPcof individual characteristics p brought to theexperiment that were not fully represented in X, anderrorsthatcaused his observed Y to differ from his universe score on Y. (As I havestated the model, the average error over members of his class is addedintouland removed from .) Fur- thermore, it includes any effect, unpredictable from his X score andnot common to other group members, that influenced his final level ofaccomplishment -- an illness, for example.The residual ccan be thought of as an adjusted \"group effect.\"3 .5 Where the group is a class, yc includes the \"main effect\" of the teacher,plus the effects of variations in the delivery of the treatment to this class, plus unrredicted effects that have a net influence on the mean (uncommon,nthusiasm, an epidemic, etc.), and the average error of measurement in theYThe individual-level errors need not have an average close to zero.Ihe between-grouFseffect described by. reflects any\"bousistent-tendency of higher-X groups to do better than others (or-.,-orse) on the outcome measure.An example already mentioned is the possibilitytt-it tea-ners cover more ground in abler classes.Ihe Jommon-within effect reflects the tendency for students abovegroup average to outperform (or underperform) the rest of the group.r,-rc,-;,ion coefficient is derived from data on One,,roup.The educator 't.t;t-.tat in otthe ette.,t on outcome is that students above4t Ind Hean 3.6 do better, regardless of their classmates. That amounts to a predic-tion that aw will be positive. Ifstudents are assembled into groups on the. basis of X information alone, and working in the groups makes no difference,ab will equal aw ,as suggested in Panel (1). Butthe inference cannot be reversed. The fact that ab 7Bw does not identifythe causal situation (see p.3.17 ). The specific within-group regressions are likely to vary, but it is hardto know whether to take this variation seriously. The regression coefficientswill differ by chance even when the processes operating in the classes arebasically the same. 'lecond, insofar as the selection factors operating to formthe several groups differ,the slopes will be affected. Third, and most interesting, are the possibLedifferences in causal processes. Slope differences might come about, for example,if one teacher distributes attention to high-X and low-X students in a differentpropGrtion than the next does, or if some teachers set up a strong competitionthat encourages the able and discourages the others.The configuration in Panel (ii) suggests that instruction inhigh-X groups differs little in average effect from that in low-Xgroups.Within groups, however, the student's X level makes a substantialdifference.Apparently, the treatment has set upa scarcity economy within the classroom, so that the comparatively ablestudents snatch up the educationally useful experience at the expense ofthe comparatively weak students. If these are the results, a student nearthe average of the overall X distribution is much better oftin a classthat, as a class, is below average on X. The student with high X wouldiccomplish far more in a wide-range class, but such a class can be constitutedonly by bringing in low-ability students, who are sacrificed in his inturest.iheIdent-; with low X scores accomplish more ii pla,ed in A haM(Tcnollus low-X group.7 6 3 .7A grouping policy is derived only by extrapolation, however. Would a strictly homogeneous group of studentswith uniform low scores on X fall on the between-gruups regression linefound in this experiment on heterogeneous groups?Panel (iii) shows $14less thanBb.Here, the student's final outcome depends a great deal on thelevel of the class, and little on his comparative standing within theaptitude distribution of the class. Perhaps such a config-uration describes what would be found if the graduates of a prestigiousmedical or business school and a run-of-the-nation school were assessed.The highly selective school probably offers a more intensive program of training.Once the program is adapted to the level of the group, it may be thatfactors other than aptitude X account for differences in success withineither group.Thus X might have been a valid predictor of success beforethe school programs diverged, and not after, The slopes representingi,have various configurations.In Panel (i), 6c2614is negatil:..Something happeningin negated the advarmage abler students have withintypical classes, represented by the slope Bw.Tedious instruction might have this effect.It will be useful to recapitulate much that has been said by reproducingFigure 3 .1 in the form of Figure 3.4, with labels attached.to the causalconnectiont-The labels are illustrative and not exhaustive; chance effectsalso enter the residuals. I have not separated the specific and common-within effects here.77 Groupingrule.at 3.7 rean Figure 3.4.Interpretation of causal arrows in Figure 3.1 7 8 3.8 What is easily overlooked is that Grouping Rule is a causal factor.Change the rule, and all the regression coefficients would change. Thisperhaps says no more than that any coefficient applies only to a certainpopulation of groups (Section 4); but the present formulation, along withwhat is to come at page 3.11, emphasizes that the rule for assembling groupsis often a manipulable, causal variable,. The intra=class coefficient for X is the regression coefficient that goes with thecausal arrow leading to ux, and 1 - q is the coefficient leading to thedeviation score. Partitioning variance The model leads directly co a partitioning of variance. The overallvariance of Y divides into between-groupsand within-groupsportions, andeach of these subdivides. If one assigns to each individual threepredictor scores --Xp,11X, andc, where the last is a string of codeddummy variables -- a stepwise regression analysis will decompose thevariance of Y. Predictors enter in the ordershown at left, and the change inthe mean square for regression at each step estipates a variAnce:Variance attributable to the between- B22b(uXcgroups five coMponents tA) in Y. The variances fo1cXcandover all groups pooled.9are defined-cc 3.9 Choices made in forming the model In setting up any model one t.hooses between alternatives.Direction of decomposition. I have chosen to partition group effectsout of the y scores before evaluating within-group relationships. The step-wise order shown above is just one of the possible orders(discussed e.g.byWerts, Duncan, or Pedhazur). The variance that might be attributed to theoverlap of group and individual charac-teristics is assigned here to the between-groups component.Insofar as thisis an arbitrary choice, not just-ified-by-a-causa\u00b1-mod-eli-it-genernesambiguity in interpreting SI) Ow.It would have been possible to set up the model in just the oppositeway, fitting a regression line to individual scores without regard to groupsand dhen asking if group membership accounts for additional variance andcovariance (see p. 1.17b, 1.22). This is a substantive decision. A considerableamount of variance in instructional practice occurs at the grouplevel.It seems to me that individual differences are beststudied by comparing persons treated under the same circum-stances.Members of the group are, in a sense, in the same circum-stances.In multilevel hierarchies, effects could be removed inmany orders, only a theory about particular variables justifies one modelrather than another. Thus it might be argued, :.th respect to change ininterracial attitudes after desegregation, that the school is a more criticalunit thanthe class or the district. It might equallybe argued that in improving the self-concept of individual children4the class is more potent source of variance than the school. Some 8 0 3 .10 other variable (truancy?) is perhaps more associated with the indi-vidual and his home, and less with the unit of instruction.Then,it would make sense to frame the model with the individual as primary.Such a model might start with an analysis of the pooled data from allclasses, and then look at groups with unexpectedly high and low rates of truancy.Nonlinearity.Nonlinear terms could be added to the model.After extracting the common within-groups regression, one can reasonably fit acoefficient to terms of the form 6 (X-X)(0X);the contribution cp of the specific-within-group regression is reduced accordingly.This addedmemberallows for the possibility that within-group slopes arelinearly related to the class mean on X (as in panel iv of Figure 1.3).Whether it will be profitable to make this separation is to be judged inthe light of one's prior beliefs about the phenomenon under investigation. It leaps ahead of the story to consider predictors other than X.Anyeffect of global properties ofgroups on within-groupsrelationships must come via a product term.A group propertyGcis necessarilyuncorrelated with Y p40.x.Gx (XPXc) cPc introducedvia quadraticterms [in qc(XPc- px )2,etc.],In fact, one of the of distinctive within-classregressions is that ofMajasan (see Cronbach, 1975).Majasan predicted that measuredachievementin a college psychology class would have a parabolic regression on thestudents' BQscores.The BQ hada BQ score for eachinstructor and he predicted that (with aptitude held constant) the parabolic 8 1 3.11 regressical would have its peak where the student BQ matched the instructor's.He was able to confirm this prediction in 10 out of 11 classes, the exceptionbeing a class where no measured-achievement criterion was available. (Majasanthecould not investigate between-class regression because the course examina- tion varied with the class.) There is a lively danger that regression techniques will dramatizerelationships that arose by chance; and making hypotheses complex adds to the risk.Nonlinearities may reasonably be explored, but unless there is arationale for predicting nonlinearity, little credence can be given anonlinear relationship the first time it turns up. Lffects of aggregating data It will be necessary next to examine the relation among'andb' .fhe three are linked by the intraclass correlation n 2 (p. 3.2).My ideas on this subject have been formed over yea-s of discussionwith Leigh Burstein, whose dissertation (1975) on the bias problem has inturn been influenced by his work with Hannan (Hannan & Burstein, 1974). Nyfomulation is struLtured differently from Burstein's in important particulars,but the formulas to be presented for abin Figures 3.5 and 3.7 are consis-tent with his. The traditional problem of \"assessing the bias\" due to analyzing at the grotip level when is wanted aeserves little of our attention -- we rarely want .do want tc, compare band . 20 3.12 The development that follows (and the highly general development that endsthe section) lays out some algebraic tautologie. It does not depend in anyway on substantive considerations, and would hold true for data generated byany causal model whatsoever. The analysis nonetheless fulfills an importantfunction, in showins how numbers that are sometimes given a substantive inter-pretation can be generated by the aggregation rule.The argument is most directly understandable when two individual char-acteristics that exist simultaneously are to be related to each other, forexamplethe potato and wheat yields of Yule and Kendall, or the ethnic andreligious identifications discussed by Duncan et al. This is post hoc grouping;the effects have already been developed, perhaps in group settings that haveno relation to the groups now being composed for purposes of analysis. Thosedata might 1-,e grouped in a number of -rbitrary ways; the joint distributionoverall has been established. For the Y-on-X regression, how does thewithin-groups or the between-groups regression depart from the overallThe counterpart question can be asked about the X-on-Y regntssion. Theanswers will depend on how the bases on which groups are differentiated relateto X and Y, or, what is equivalent, to X and Ole partial variateY-X = Y- :t .Snecial case withlirlimp_Lion.. To develop a comparatively simple4rgument,I introduce a discriminant function W ,and assume .that X, Y,and W have a multivariate normal distribution. We may consider that groupsare formed by dividing Winto regions and assigning persons in the sameregion to the same group fcr purposes of analysis (not necessarily fortrtament).It follows that the means of X, Y, and W are perfectly correlated. (Itts this coplition on which the immediately following argument depends. It,oubl he satisfied when theumption of trivariate normality is not.3ut -;uch 4 stronr. 3.13 assumption will serve for the moment.) In the rest of the argument I shall use Z andnot W; Z is simply the group mean on W, and every member of the group hasthe same Z score. Instead of working with correlated variables I substitute orthogonalvariables I, II, and III; these are perfectly correlated, respectively, withX, Y.X, and Z.Y, X. Each of these components has a zero mean and a unit s.d. overindividuals in the population. The relations to be developed in this populationwould be found for samples, if sample statistics were used to define I, II, andIII.Variables I, II, and III can be thought as coordinates in a three-space;I and II are orthogonal coordinates for the X, Y plane.Figu:e 3.5 shows how the standard scores on X, Y, and Z may be describedin terms of component loadings.(To use standard scoies simplifies the argu-ment without loss of generality.) The symbol A is used for the correlation ofX and Y, overall, and CB for the correlation of X and Z.This notation isused because B proves to be a key parameter; all Z that project into thesame line of the X, Y plane have the same B.Since dimensions I and II carrythe information in XandY,andCis the proportion of variance in Zthat I and II account for, C=RZ.Y.As a convention, Ctakes a X,positivv! sign. tiI 3.14= 1,Z lies in the X, Y plane and therefore must be a continuousvariable.'this can occur only if the grouping procedure sliced the W scaleinto infinitely thin slices, hence it is a hypothetical limiting case.2 As Figure 3.5 shows, the covariances within any group (i.e., amongpersons with Z constant) can be described by a partial-covariance formula. Then simple subtraction produces the between-group covariances in the popu-lation.No matter what the value of C the between-groups regressioncoefficient is the same. The relation of Bt to ab, then, depends on B andnot on A or C.*This formulation applies to the population. As withC = 0 , C =Iis a hypothettcal limiting case. A finite collection of individuals can be regarded as apopulation, hence the formulas can apply to them. If the groupingproce-iure is strictly random, however, the correlation of X withWand that of Ywith Wwill not be precisely zero.Consequently, Cwill not reach 1 .With purely random posthoassignment, any one group is a random sample of the totalcollection of individuals and its within-group regression coefficient isan unbiased estimate of .Consequently, with purely random groupingYXsubsequent to treatment of individuals, ter., -IA, ,and:,the formulas for ,7I)and ;remain the same, when /1-B21 CB C2[AB+/1-Avi-B217=CAB +CA-Az /1-B2 1 First part of Figure 3.587 Values of regression slopes when C = 1at 3.14 of parametersof a single grouping variable under a linear assumption 0 8 the values of BwandBbboth approach Btbecomes larger. How does the discriminant functirn affect aband$w?Figure 3.5 gives formulas in A, B, and C, and, more simply, in terms of 1) LetX*be the projection into the X, Y plane of the line along whichthe meansX, Ylie, and define 4) as the angle between X* andX;cos= B. Figure 3.6 is for the case B.= 0.40; a horizontal broken line repre-sents atOne curve displays tbe value of al,at each q,from -90\u00b0 to900, this curve would be repeated in the range 900 < 270\u00b0.A secondfunction represents values of awwith C = 1; this is the unrealistic case into infinitesimal regions.whereW isdivided-The third function gives awwhen C = 0.8.As C Adeclines toward zero the line for awcomes closer to that foras the number of groups3.15 Obviously, the relation of ab and aw depends on the relation of thegrouping variable Z to X and Y. This is similar to the effect of \"restrictionof range\" ,)r \"truncation\" on test validity a problem well known in psycho-metri,:s. Iinterpret these results before offering a more general development. Me_aninl_of .Traditional writings on aggregation bias have thought of theprinciple as one that could be nrbitrarilv established. Thus Feigearid '.,:av; (1972) were looking for a way to group banks into small sets so thatthe Feder.11 reserve System could report data for the sets without violatingionlidentialitv, and vet the data would represent the mieroe.onomicadequatelv.The formulas of this section to hutiriint,r,.-ted in applying them to ,roup-, that were termed bv natural pr,,esses. 8 9 X Z = Y ZyX -60 -3'; Figure 3.6.Between- and within-groups of andC3.0 1.0 -1.0 -3 . 0 3.16 at, which defines Y.X, is determined from the overall distribution.In an experimental treatment, the values of Yreflect any predictable andunpredictable effects including context effects. The grouping variable maybe related toY.Xfor many reasons. The most startling paradoxis that if groups are formed strictly on the basis of Xthere may nonethelessbe a relation of ZtoY.X, hence a non-zero Suppose that groupingis based onX, and no other initial characteristic adds to the predictionofY.But suppose there is a concext effect, such that high-X groups havehighYmeans.If one partials Xout ofY, using the overallregression coefficient, the high-X groups will have a positive residualY.Xand the lpw-X groups will have a negative residual. Thenipwill bepositi.(An inverse context effect, with high-X groups doing comparativelybadly, will make negative.)A positive 15could also arise in theabsence of any context effect if grouping takes into account someWthatis correlated with individual values of Y.X .An unlikely third possibilityis that grouping is actually based in part on the outcomes of the treatment. Lompiring ;-.1) and .:,,In the sociological literature there is a line of red-,ning trdt runs like this: If Db equalst,there-are no context effects. or, ecuivdientiv, if there are no context effects. Thus one can 'Lw '-is co11ege as in Figure 3.2, on ES within schools. reg 9 2 3.17 Duncan et al. (1972, p. 197) would dismiss the hypothesis that the schoolclimate had an effect (direct or indirect) on aspirations. In such a casethey suggest that the between-groups slope merely aggregates evidence ofeffects at the individual level. Duncan ec al. (p. 195) expand on their version of Figure 3.2 (in amanner that loses something in my compression and in translation to theregression form). Essentially, they substitute for the ax-to-,,ly path adiamond-shaped configuration that makes room for intermediate variablesand Y* ,whose sumis .Yc= b 11and hence is a predicted school Ycw Xcmean under the hypothesis P, w=.In the population 6wux would surelybe the between-groups predictor if classes had been formed at random andif no causal effects at the school level entered into p Ycor Y .The partofthat is left over, Y\" ,is analogous to the adjusted mean in analysis Py of covariance. For the Campbell-Alexander data the coefficient linking Xtocisc set equal to b,, i.e., 0.47; and the coefficient leading to Y: is 0.630.47 = standard deviations of 'Ycand Y* are 0.21 and 0.07,respectively.M.1 this suggested to Duncan et al. that \"composition effects\"(demographic) are much stronger than \"school effects\" (grout caused). Thiskind of inference does not appear to be justified.3 In Campbell-Alexander data = 0.20.Suppose that 0.50 1; theAreression coefticient ot college plans on that would if each-;tusient ',ere so his planserned.lnder tut, no-sch,ci-eff ctshypothesis, if tudent6ero 3.18 grouped nonrandomly with n 2= 0.20, the values of k band kwcould be those Xof the Campbell-Alexander data: 0.63 and 0.47. What is required under thelinear assumption of the model above is that tan= 0.15, which implies that grouping depends much more on SES than onothercorrelates of educational aspirations. When grouping has no causaleffect, a difference between kb and k wwill occur unless 4, = 0. That is,a nonzeroBb - awcertainly implies a causal effect at the group level only ifthe discriminant function combines the predictor X (in this case SES) with in-formation unrelated to the dependent variable. This allows random grouping as a limiting case. So much, then,for the attempt to infer a causal groupingeffect from a difference between the two coefficients.It is a little less obvious that a zero difference in coefficients canarise in the presence of a group-caused effect. For the sake of argument I specifythe grouping variable: students are assigned to schools strictly on the basisof SES.If we continue to suppose that group context has no effect, -bw= ,since := 0.Now suppose that a causal effect of the Coleman type isadded.In high-SES schools aspirations of the student body as a whole aregiven a boost; in low-SES schools aspirations are lowered. This context t'frect raises o bbut does not imply a change in a w.In consequence, -bexceeds the original This seems to fit with the common reasoning of sociologists. But Meyer among others has suggestedanother type of context effect. A student's aspiration tends to be raisedwhen he finds himself superior to his schoolmates, and lowered when he is below the mean. This has the effect of raising above the original Hence effects of the Coleman Ind Meyer types may 0 fsetand leave =ohBw.each oerAAlso, a group-caused effect may offset a demographic effect.This reminder of the 9 1 3 .19argument developed at p. 2.6ff. indicates that the absence of a causal group-ing effect does not follow from ob = ow .It should be noted that nothing in the model itself implies the presenceor absence of a causal effect from grouping.Consider the possibility that2 groups are formed prior to the events that determine Y ; sonx is prede-termined.Let one collection of groups be treated as groups. Let membersof equivalentgroups be treated as individuals. If grouping has a causal7etfect,ry and c,xy will almost certainly not be the same in the two data sets,hence the ,values will not be the same.But the formulas of Figure3.5 fit both studies. This in itself implies that there is no way to reasonpost hoc about the effects of grouping, on Lhe basis solely of Y-on-X regressionsor similar data. This discussion takes on added importance in the light of Alwin's paper.Alwin shows that the analyses preferred by the Columbia group of sociologistsand cue analyses preferred by Duncan, Hauser, and others of their persuasionlead to identical conclusions, in the multivariate as well as the univariateIhe fact that cannot be directly inte6reted implies the needwtor more elaborate models and for the collection of more evidence on thepreumed mediator of the context effect. In the never case, for example,eviaen,e on self-perceived ability would not be hard to collect. 9 no p. 3.203.21 Implication for ATI research. I st-rted this investigation witha concern for contrasting regression slopes across treatments.If, Isaid, the within-group-within-treatment slopes were the same acrosstreatments, and the between-group slopes were different across treatments,this suggested an ATI at the group level (i.e., a causally interpretablegroup effect). Such a commonsense view must be modified to recognizewhat has just been said about aggregation effects.To glimpse some of the problems, let us assume that the relationofYtoXis strictly individual within each treatment (i.e., thatgrouping has no behavioral consequences). Assume also that the twoY-on-X regressions have an identical positive slope Etfor all individualspooled.But suppose that the grouping principle used in one treatment differsfrom that used to form groups in the other. Then, of course, anyanalysis of between- and within-groups information refers todifferent populations of groups, even if the individuals came from thesame population of individuals. And any difference found in comparingstatistics may be attributable to the grouping rule. NO qiSuppose that in one treatment groups are formed by randomsampling.Then, within the limits of sampling error,bb = bt = bw . Suppose that, in the second treatment, group formation isinfluenced by some variable (other than X) that predictsYwell.Thenbbbtbw ,and strong ATI effects will be reported atthe between-groups and within-groups levels!It would be possiblekon.oct an example in which there was no interaction between orwithin group-:, but an overall interaction did appear . 3.22 If an ATI study sets out to compare two treatments that arealready in place, how groups were formed is crucial to the interpretation.Crogps.served by one program may differ in their demographic makeup fromthose served by the alternative program, even though both sets of groupscover about the same range of individual differences. Perhaps this section can be summed up simply by sayingthat interpretation of regression coefficients must be exceedinglycircumspect when grouping rule is confounded with treatment, so thateach treatment is observed in a different population of groups. Aggregation effects with multi le discriminants. Ageneral formulation can be offered to replace the simple one used to this point.Consider twodiscriminantfunctions W and W .Personsare grouped by imposing assignment rules on the joint distribution ofcorrespondingWand W' .The group means will be denoted by Z.and Z' .All personswithin a segment are assigned the same Z and Z' .It is easiest toconceive of slicing first on W and then on WI (If W and W' fell in the X, Y plane,this would divide the original distribution into lozenges.) It is notnecessary to make the division by sharp cuts, however. As before, themodel applies to data where the investigator did not control assignmentto groups; the role of W and W'is to provide a sufficient simulationof the grouping process that might have occurred. 9 7 3.23 I requirethat the group means Xand V be22 linear functions of Z and Z ,i.e. that ID = 1.This is X.ZZIPY.zz'only slightly restrictive. Given any distribution of X,Yone can easily form a Z and Z' that will reproduce the first andsecond moments (but not necessarily higher moments) of the distribution.(E.g., let Z = X andZ' = Y - a-W. Many alternative pairs of contin-uous W and W' will generate this Z and Z' respectively.) This model is sufficient to reproduce first and second moments whengrouping was regulated by complex contingency rules, since any such rulestill leaves uswith an R-,7pair for each group, hence a Z,Z' pair.Themodel would need to be extended to deal with.multiple-regression problems. The development could be stated for any Z and Z% but no information islost if Z and Z' are rotated within the plane. I therefore work withvariables ZIand Z2which are orthogonal; I require that Z2 with Y.X . Instead of using partial covariances as in Figure 3.5, Figure 3.7proceeds more directly to the results. Figure 3.7 starts with a factorialmodel in four dimensions, with each variable assigned unit s.d. The multiple-regression equations for predicting X andYfrom Zi and Z2 are formed.Since all members of a group have the same values of 11 and Z 2,theseregression equations predict the XandY. Despite the more complex model, the formulas match the results inFigure3,5, when those are stated in terms of A(= ),tanandXYThe only functional difference is that nX =C2B2+ D-,norC-B-as 2 7 betore.Figure 3. 6 applies to but not to since holding Cconstant does not simplify adequately, A figure can be developed holding riXandCconstant, allowing Bto vary. (B implies 1 theI, II plane, and * 2/9 defineas the between XandX,tan= C B Yl-B-( C-B + D )Hence= A +-Atan 4 / A - a6T,Y)A -AC2B2-C2BY1-A- Y1-132 D 1(C2 B2 + D2)n2=A/1-A7tan21-nX Figure3 .7.Regression coefficients as a function of parameters derivedfrom 9 As before, =11/1-A2 tan $](---1-)1-n23.24 Ifn2= 0,bis indeter-minate.Ifn2 = 1 ,is indeterminate. Disregarding those -has the same sign as tan positive;this only Il-B2is negative, thatis to say, variable Zlis negatively correlated with Y.X .This canarise from a causal effect that places high-X groups at a disadvantage (including a Meyer-type context effect). If there is no group-caused effect, the negative value can arise from an assemblyrule such that groups containing more high-X persons tend to contain personswho are low on some other predictor of Y .For example, if pupils wereassigned to classes on the basis of IQ (which can be interpreted as a functionof MA - Age), the highest group will be high on MA and low in Age, on theaverage.Then if MA is used to estimate or forecast achievement, these c-v.4itions would make b< ewGrouping on degree of \"underachievement\"produce a similar anomaly. It appears unlikely that demographiceffects alone will often make bThe relation =occurswith grouping on some combination of 'bwX with an irrelevant variable (perhaps a random assignment process). This requires that there be no demographic variable or other precursor X'such that :# 0.4 relevant grouping variables. 1That is,X completely specifies the Notes for Section 3 3.25 p. 3.11Walberg (personal communication) suggests that the mean should not be usedas an aggregate statistic because of its sensitivity to skew and especiallyto outliers.Decker Walker suggests that the model should provide for non-linear regression from the outsets (and this does appear to be importantwith a categorical variable such as that of Bowers). I prefer to leave thesepossible elaborations in the background. Investigators should inspect plotsof bemween-groups and pooled-within-groups relations. At different places in this report I have shifted notation, more becausethe sections were drafted at different times than for any good reason. Whatappears here as Xcwas si7ply 17in Section 1 and Xcin Section 2. p. 3.2laothers have used E2the correlation ratio, in place of fi;.Whenclass membership is fixed. as I assume, the two are identical.p. 3.14When Z coincides with X and each differential element of Z definesa new group (B = =1, C = 1, = 0), the variance of X within groups is zeroand the slope is undefined. With B = \u00b11 and C even slightly different fromzero, the within-groups slope becomes A .When Z coincides with Y.X or projects into YX = 900), thebetween-groups variance is zero and the between-groups slope is undefined.increases toward 90 the slope becomes indefinitely great; asdecreases from 00 toward -90\u00b0, the slope becomes indefinitely great butnegative.Statements about r.andnin Figure 3.5 are true when bothare given positive signs. 101 Notes 33.26 p. 3.11s nal communication indicates that Duncan does not wish to f'efend the p. 3.24ument discussed here; it was formulated nearly ten years ago. Today hewould emphasize that coefficients are highly equivocal unless there is com-mitment to a causal model of the process of group formation and of thegeneration of the dependent variable. The Alwin paper indicates that thereasoning of the 1972 publication haF not been superseded in the sociologicalliterature. 4With a finite number of groups a strictly random process may generate avalue ofthat is far from zero in either direction. 102 4 .1 4.The reference population and its parameters Alternative models for statistical inference Data on students observed in a group of classes could be interpretedwith no attempt to generalize. That is, the classes, and the studentswithin the classes, could be regarded as fixed.(One could consider thedata themselves as a sample of observations that might have been made onthese same subjects, in which case one would generalize over the universeof observations.) The most obvious way to frame a generalization is to assert that personsand classes are randomly sampled from a population of students. This re-quires drawing students randrnly and independently to fill each class intarn, which would make approximately zero the intraclass correlation forevery initial characteristic of the persons.This is not reasonable formost groups that exist in society, and it is likely to be contradicted bythe data in hand. In trying to identify more plausible alternatives, I confine attentionto two levels, collectives and members. The ideas apply tosubcollectives as much as to individual members, and are readily extendedto additional levels. I assume that it is intended to generalize overcollectives, and that the collectives are a random sample of the populationof collectives. Collectives, then, may be considered \"random\" as thatterm is used in the statistical literature.Tn deciding whether to treat members as fixed or in some sense random,the key lies in the structure of the population. Are all the collectivesseparate and distinct? Or do different sets of members constituterealizations of \"the same collective\"? The second alternative applies mostobviously when the population of collectives extends over localities and103 4.2 over time.High-school student bo'ies have different members each year.An investigator interested in persistent differences among schools mightthink of the population as comprising a number of \"local\" populations,each made up of a succession of student bodies in different years. (Thepopulation may be finite.) Classes within a population of classes mightlikewise be identified with teachers, so that the potential members ofclasses of one teacher constitute a local population. I next discuss themodel for inference that follows from each of the alternatives. At theend, it will be possible to discuss the bases for choice between the twoconceptions. Collectives distinct, persons fixed. In the first formulation,collectives are regarded as without connecting identities, just as personsare in the usual models for inference. Collectives are sampled independ-ently, from a population of collectives that might have been formed byapplying a particular grouping rule to a population of individuals. Thegrouping rule may be under deliberate control or may be a social processthat can be only inferred from the data. It seems to me that under these circumstances members have to beregarded as fixed. A certain group of persons was assembled and togetherwent through certain events. Those events constitute a unique history.There is no basis for speculating as to what would have happened if, atthe outset, Billy had been replaced on the class rolls by Milly. What wenton in the class may have been influenced by the synergism between Billy and certain others; to have enrolled Milly instead would have made the classa different experimental \"subject\". The class containing Hilly might havebeen drawn under the grouping rule, but it is a distinct class and only oneof numerous alternatives to the class observed. The model does not allow fora close family tie of the class with Billy to particular other classes in the populati,n, except as classes may be blocked a posteriori on selected-aggregate and global variables. 10 1 4 .3 With students fixed, effects within the classroom have to be lookedupon as historical accounts of the consequences of bringing together thisset of students, this teacher, and whatever unpredictable events affectedthe group.The unforeseeable variability in delivery of the treatment, inclassroom morale, in epidemic illness, etcis a part of the causal history.As a thought experiment one can ask what would have happened if this samecollective had gone through the specified treatment several times independ-ently.That is, one can be conscious that fortuitous events played a rolein determining the history and the scores.But there is no satisfactoryway to assess such variability. The one empirical approach is to treatsuccessive units of instruction in the class as independent events, buteven if the topics are unrelated, the first experience is likely to influencethe second.It is practicable to generalize over the universe of observa-tions of the outcome -- but that is a side issue here.Collectives nested within local populations. The alternativerecognizes the division of the population of members into what can conven-iently be called local populations. The grouping rule determines the member-ship of each local population. Random definition of local populations isunlikely.Each local population is a subpopulation of the population ofcollectives defined by the grouping rule. It consists of all the collectivesbelonging to a certain locality -- i.e., all the \"remedial\" sophomore Englishclasses that might be formed in this school during a 10-year period. Herecollectives are simply nested within localities.Onemight think ofcrossing localities with time periods and identifying a place-time combinationwith a subpopulation. Student bodies, neighborhoods, and classes are not formed randomly, as isevidenced by the usual intraclass correlations on initial characteristics. Butit sveMs not too unrealistic to assume that any one collective within a localpopulation is a random sample from a set of collectives that might have takenits place.Thus, if local populations of classes are identified with teachers,105 for4 .4 where each teacher.has many potential classes, I allow the intrateacher correla- tion on an initial variable to depart from zero, and assume that the intraclass correlation within a teacher fluctuates around chance expectancy. Even with this model, sometimes it is appropriate to regard thecollective observed as having a fixed membership and generating a uniquehistory.Then one could evaluate the relevance of collective-levelEtatisticsto the subpopulation only by observing two or morecollectives from thatsubj -pulation.The independence assumpt- n,WhenAthe investigator chooses instead to regard the members as random,he is making two assumptions. He is assuming that one member of the localpopulation has as good a chance to fall into the sampled collective asanother, which seems plausible. Second, he is assuming that as the eventsof the treatment period unfolded, each member's history and performancedeveloped independently of the experiences and acts of his classmates.This seems more likely to fit the facts of individual instruction than ofgroup instruction. But let me be more precise.I elaborate on the model of Section 3. Assume a population of sub-populations for which there is a singleSbandaw.There iscorresponding population of values of px,ye,andcw,one value of eacheach subpopulation. Here,pxis the expected value of XoverPc members of subpopulation c Second, there is a grand population of deviationscores for members, X -XcandY -Ye.(uYc=b+ Ic.)The variances of themeansare a function of the intraclass correlations.With this model of the population, the logical design is to samplelocal populations and then, to represent those chosen, to sample one ormore collectives. The calculated yeandwfor a particularsampledcollective estimate corresponding parameters for the subpopulation.1 0 4 .5 V To evaluate the sampling error when only one collective per subpopulationhas been observed, one uses the member as unit of sampling and estimatesthe variability of the mean or regression coefficient from the within-collective variance.This amounts to viewing the members as independent instruments for observing aneffect,an effect that is associated with the subpopulation no matter which membersconstitute the collective. The obvious example is a teacher effect. Theteacher may be supposed to generate an effect of size yein every class,b. virtue of excellent (or poor) technique. Individuals affect the meanonYthrough their aptitudes, but if the model is properly specifiedthat contribution is separated from yc .Likewise, the teacher teaches. classA The independence assumption fits well withsome conceptions of teacher effects, school effects, and context effectsgenerally. It is not hard to generate counterexamples, starting with contagioneffects.Most teachers have the impression that classes develop theirown \"personalities\" -- responsive, recalcitrant, mutually supportive,divergent, etc. This implies a variability across classes within thesubpopulation much greater than one would estimate from the within-classvariation.On the other hand, consider the teacher who \"grades on acurve\", so that every class has almost the same final rating. Then thevariation of mean ratings across classes will be much less than one wouldestimate from variation within the class.Choice among models. The first summary comment to make is that, formany research purposes, inference regarding members of collectives is ofsecondary importannP at most.In compensatory educ...tion, the chief 107 question is whether, on the average over (presumably) districts, onepolicy is more profitable than a competing policy. An experiment oninstructional method usually seeks a conclusion that can be generalizedover classes or possibly teachers. For such purposes, the collective isthe unit of decision making or of theory, and it seemingly should be theprimary unit of sampling, assignment, and analysis. In such a context,however, an invest4,ator might appropriately make supplementary studiesof classes, asking why some have large means or4 .6 large regression coefficients. At this point, he does face a choice betweenregarding the class statistics as representing a fixed history or as representing-the independent histories of its members. To think of members as random and independent appears to require,first, an iden*ification of local populations. To simply say \"pupils areregarded as random\" (for example) is to make a deniable aisumption of zerointraclass correlation. In the kinds of studies this report discusses,local populations are readily conceived, so that is no barrier. The pointis primarily important in stressing that the variance over members inpooled collectives is not a proper basis for inference; the model directsattention to variance of members within collectives. Inference based onthis variance has to do with parameters within local populations, not withinference over the undifferentiated grand population. Second, a substantive decision is required as to the legitimacy ofthe independence assumption. Bowers might want to set confidence limitson the mean proportion cheating in College A, over its subpopulation ofsuccessive student bodies. He surely would not regard students asindependent; his very hypothesis regarding the context effect seems toimply a positive feedback loop among the members. Some years, then, are los 4 .7 likely to see more cheating than others, and within-year variance ofstudents would tend to give a conservative confidence interval. An investi-gator evaluating programmed instructional materials might be convincedthat students react to the materials independently, so that each one earnsabout the same score as he would have if taught alongside other classmates.Then he can contentedly regard students as random while estimating the(Students are extent to which certain teachers get superior results. random within the subpopula-tion for the teacher, however.) Third, think of research like Barker's, where the localthe population is the community and the variable of interest isAnumber ofover persons responsible tasks undertaken in the community. The variability within theAcohort will give too wide a confidence interval for the community mean.The number of roles to be filled is finite, hence the mean over cohortsmust be quite stable; yet there is a large variance within the cohort.An investigator who has only one sample from a subpopulation andwants to infer to the subpopulation must develop a substantive argumentabout the direction and amount of bias the independence assumption entails.He may go on to base an inference on this shaky assumption,withappropriate caution.In this report I have chosen to regard members as fixed withincollectives.This is a conservative position that limits the number ofissues I have to deal with in each particular example.Weights that define parametersPopulation parameters have to be defined with due regard to the numberof members per collective, when this is not constant. Parameters mayweight by the number of members or may weight collectives equally. Thisrequires a conscious choice of the parameters to be estimated. To be sure,a person who is interested in the weighted mean for school districts may109 4 .8 use the unweighted mean as an estimator, assuming that the correlation of the variable with district size is negligible. But the fundamental questionis what mean (or variance, regression coefficient, etc.) he would like to evaluate.Sometimes the decision can be reduced to a theoretical questionand sometimes it is a question of utility. The same weighting should, Ithink, be used in defining all the parameters of the study, to avoidnumerical inconsistencies.I am inclined to think that in most instructional research weightingpupils equally is the preferred way to define parameters. It is doctrinein our society that individuals are equally important, and in any ultimate policy decision the burden of proof is on whoever proposes to weigh pupil interests unequally. That is, if it should happen that the mean effect ofa treatment is positive when calculations are weighted by class size, andnegative when unweighted, \"the good of the greatest number\" would favoruse of the treatment. Weighting classes by ncweights individuals equally.Theory may give a reason for weighting on a principle other than \"one man, one vote\". In research on factors influencing national returns forSenate seats, the fact that each State has two Senatorial votes mightargue for using unweighted State means. This, it should be noted, arises not from a statistical principle but from a substantive context in which Statesare equivalent in weight. Weighting groups equally can be appropriate in education also. One example is an evaluation study with wear-and-tear-on-the-teacher as dependent variable. Teachers, in that instance, are theones with equal rights. When the State of California wants to examine the mean of studentachievement, it might count districts, or schools, or pupils equally. Itseems obvious that pupils are the correct unit. If a change in distribution 11 0 4 .9 of tax revenues depresses the school program in 20 large cities whileimproving the program in the 500 smallest districts, the effect on thewelfare of pupils qua pupils probably is negative on balance.Surely thelegislature is just as concerned with the welfare of the typical city childas with that of the typical child in a small community. With regard to the regression of district mean outcome on backgroundcharacteristics, if district size makes much difference there probablyashould be separate regression in each size category. But if only oneregression is to be used, the pupil-weighted regression for district meansseems to give the best statement as to the \"normal\" district-level outcomecorresponding to given background characteristics.Consistently weighted calculations produceharmoniousnumbers at several levels. For example, the pupil-weighted sum of squaresbetween districts and the sum of pupil-weighted within-district sums ofsquares for schools add up to the pupil-weighted sum of squares forschools pooled. Inverse weighting is equally possible. If one wanted toweight districts equally in district-level calculations, it would bein possible in school-level calculations to weight each school inverse proportion tothe number of schools in its district.The weighting that defines a parameter may not be the weighting usedin making estimates, particularly if the sampling fraction varies with the 111 4 .10 collective.One might, in California, sample schools in large districts while collecting data in every school in the small district. This wouldlead one to weight schools unequally in calculations over districts.In Bowers' study, data on attitudes and conduct were collected in 93 Lolleges.The same number of students were sent questionnaires in each college, though returns were not uniform. The sample sizes were not atall proportional to the college enrollments.The population of interest could be defined by a.counting respondents equally, or b.counting colleges equally (which would call for weightingeach sample mean equally and in individual-level calculations weighting thedata inversely by the size of the sample for the person's college), or c.counting individuals in the national student populationequally (which would call for weighting each datum by the ratio of collegeenrollment to sample size for that college).Bowers, it will be recalled, was concerned with the relation of behavior to the dominant opinion in thestudent body.This is described in the between-colleges regression and inthe mean of the within-college regressions. Option (a) -- which Bowersand others used in their calculations -- seems not to be the soundestchoice.The resulting statistics refer to no population save that consti-tuted by the sampling procedure. Options (11) and (c) could give disparatedistributed around results if means for large and small colleges are not Athe sameregression line, or if their within-college regressions differ systemat-ically.If the large colleges e-hihit a positive trend and, lauglicio, thesmall ones exhibit a negative trend, these can balance out in the unweightedcalculation whereas the large-group trend will dominate the weightedcalculation.I believe that Bowers would be interested in a trend whether112 4. 11 it appears in the weighted or the unweighted calculation. In investigationslike this, as in the California data, it appears important to learn howregressions vary with group 1 If Bowers were to decide that size was not systematically related tothe effects of interest, he might want to take the precision of his informa-tion into account in estimating the relationships. If student bodies aremuch larger than his samples, the standard error of each college mean isnearly inversely proportional to the square root of the sample size for it,and the means could be weighted by that factor in the between-groupsanalysis.The same weighting could be used in averaging the within-collegeregression coefficients. Illustrative statistics for populations of collectivesThe population of collectives, I have said, is characterized by anumber of parameters at the level of the collective. Two examples willgive concreteness to the idea.Head Start,. Smith and Bissell (1970) give correlations, means, ands:d.'s for a set of demographic variables and a posttest (MetropolitanReading Readiness) on 202 Head Start children in 26 centers. The entriesin Table 4 .1 are calculated from their report.As the data come from asample of centers they describe the reference population only approximately.The covariances of the initial variables are as much a part of the populationdefinition as are the variances. In fact, Smith and Bissell described thedata in such detail in order to point out that the Head Start group matcheithe control group poorly. Even though the means and standard deviationsmatched fairly well, the correlations were consistently stronger in thecontrol group. POPED and NKIDS, for example, have a covariance of -0.39 inthe Head Start sample, and -0.77 in the control sample (between centers).113 Table 4 .1.Statistics describing a sample of Head Start VariableBetween-centersvariances (MR) 52.21.252.961.68- .7275.69.29 1 I 115 4 .12 School districts in California. Another example comes from theCalifornia Assessment Program. Every student in certain grades is testedeach year.Rogosa and I have analyzed data for 882 districts (4514 schools);this is not the entire population, since we confined the analysis to schoolsfor which information was available on each of the variables under consid-eration.These were: ELT 3.A readiness test given to first-graders entering in 1973.ELT 4.A similar test given to first-graders entering in 1974.Rdg.A reading test at end of, third grade, given in 1975 tostudents most of whom entered in 1972.SES.An estimate based on teacher's report of father'soccupation for each third-grader.Mob.Principal's estimate of per cent mobility for the school.Bil.Teacher's estimatethat the pupil was or was not bilingual.Calculations can be made directly from school means and from districtmeans, but in the district-level calculations we weighted by number ofschools.(In retrospect,we had better grounds for weighting by number ofpupils.) Table 4 .2 gives results for all districts except those having just oneschool.The correlations are large for all variables except mobility.Theintraclass correlations are larger than in the Head Start data and, exceptfor mobility, remarkably uniform.Even in this weighted calculation the elimination of the one-schooldistricts had a large effect. The LLT-3 vs. ELT-4 correlation dropped from0.95 to 0.84.No interclass correlation increased.The standard deviationsfor schools did not change but those for districts increased.Consequently,the intraclass correlations rose to about 0.50 (0.40 for mobility). To at 4 .12 Table4.2. Population parameters for California districtswith more than one school. All calculations weighted bynumber of schools per district. one-school district separate flom the remainder makes sense;and in the population of larger districts it is advisable to check thatrelations of interest do not vary with district size.Los Angeles (441 schools) is four times as large as the next largestdistrict, which led us to wonder whether Los Angeles alone had an appreciableinfluence.The correlations with Los Angeles omitted departed little fromthose in Table 4 .2. The s.d.'s for schools decreased by about 10 per cent2 (except for SES and mobility) andnincreased.Removing Los Angeles hadlittle effect on most of the statistics because its mean was close to theState mean.Had it been an outlier on any variable the changes would havebeen great. A problem of estimation If one wishes only to describe relations in the sample of groups andindividuals before him, it is unnecessary to speak of \"estimation\".Calcu-lation simply requires attention to the definition of the various componentsand parameters, with respect to such matters as weighting.I postponemost problems of inference to Section 7.One point needs to be made here,however, to prepare the reader for the erratic behavior of the between-groupscoefficients to be encountered in Section 5.A regression coefficient is determined largely by the cases toward theextremes on the predictor variable. Those cases \"have leverage\" on theslope of the regression line, just as do persons perched on the end of theseesaw.Cases near the mean -- the fulcrum -- have little influenceon the slope.This means that the \"effective\" sample size determininga regression coefficient is much lees than the number of sampling units.4.11Note 1.We made some limited comparisons in some of the Bowers data and foundthat regressions were similar whether colleges or individuals in thesample were weighted equally. We did not apply weighting of type (c).118 5.Illustrative ATI-studiesThe Anderson study Before considering theory further, I turn to a number of illus-trative studies, beginning with G. L. Anderson's 1939 data.Webb andI reanalyzed that study because the ATI effect it reported5.1 has been of considerable interest. A full account of the design of thestudy and of our reanalysis appears in the Cronbach-Webb (1975) paper, so I canbe brief here. Data on 9 classes in Treatment A andSin Treatment B are available. The classes were taught the same year-long arithmetic curriculum -- the A's by a method that emphasized themeanings of the processes, and the B's by a drill method, with little meaning'being developed. Teachers were assigned to the method most like theirusual style, not randomly. The students in each class were those assignedto that teacher by the school's routine procedure. The study is a quasi-experiment.One can reasonably generalize from the A data to the populationof teachers likely to opt for a meaningful method (in the schools of thelate 1930's).I prefer not to regard the A and B teachers assamples from the same population. The classes may well,be randomsamples from a single population of classes, but classes withintreatments differed in ability level.Among Anderson's many pretest scores, we found it sufficientto use just two, which we label ABILITY and PRECOM. The former is a conventional group mental test rescaled to have mean zero and s.d. 100over all cases pooled. The latter is the total score on the Compassachievement test in arithmetic computation, at the time of pretest.It tco 119 5.2 was put on the 0,100 standard-score scale. The dependent variable (ZACH)was a similarly scaled composite of subtests from the Compass posttest andfrom the Analytic Skills of Attainment. Rescaling makes it easier tocompare regression coefficients for variables with different metrics.These will not be standardized regression coefficients. The s. d. of eachvariable varies with the group. Webb and I did not use the single stepwise regression analysis suggestedat p. 3.9, because it is a comparatively awkward way to arrive atdescriptive statistics for separate classes. Instead, we carried outseparate regression analyses within treatments and within each class.This costs more in computer time than a single generalized analysis, but the ease of interpretation saves investigator time. The procedure does not, however, generate inferential statistics on the treatment contrast.A weighting decision. To evaluate 6band other between-group statistics within a treatment one has theseoptions: 1.Calculateuxandpfor each group. Enter these Yc'ck pairs in the computations. Or 2.Carry out the computations but weight each pair L'Xc 1by the corresponding nc. 120 5.3 In the model Webb and I used nc as a weight in defining parameters. Weighted calculations from the sample give unbiased estimates of theweighted parameters and the unweighted calculations in general do not. Regressions of ZACH on PRECOM. Within each treatment,regression analyses were made with the group mean on PRECOM aspredictor and with the individual's deviation score as a predictor.ignore the constant terms, which are of no immediate interest inthis report; the treatment means did not vary greatly.The unstand-ardized regression coefficients were between-classes coefficient is large enough tobe of potential theoretical and practical interest if taken at facevalue.Apparently, differences in X means produce comparativelylarge differences in outcome means of drill classes. One can ration-alize this by hypothesizing that when an able class shows good resultson drills the teacher steps up the pace and covers more topics or morevariants within a topic. Increasing (or reducing) the amount of workcovered is comparatively easy in a drill class. Practically, thisdifference in coefficients coupled with a near-zero difference inoverall means suggests the hypothesis that the drill method is bestfor classes formed of high-PRECOM students, and the meaning methodbest for low-PRECOM classes; but this would require verificationon classes formed in that way. 121 5.4 A between-classes coefficient in a small study cannot be trusted.Eventhough Anderson's study was large by conventionalstandards -- over 400 students -- only 8 or 9 classes contributed toeach regression equation. A difference in coefficients much greaterthan 0.27 (in this metric) would fall short of significance with sucha sample.When we plotted the means (see figure) the two sets ofpoints seemed to lie within the same distribution. Coefficients aremost strongly influenced by data points at the extremes of the X scale,At the right end the extreme points in the two treatments are closetogether.At the left end, the extreme point for drill pullsits slope down, whereas the extremepoint for meaning is very little below zero on the Y scale. Thisalone seems to produce the difference in final slopes.For a more formal consideration of statistical inference, see Section 7. The within-class coefficients are almost exactly equal. Takingthe coefficients at face value, the two coefficients for drill arethe same, which is consistent with the view that individual aptitudedetermines performance and context effects are lacking. These data,however, give no basis for ruling out the hypothesis that if studentswere taught individually the overall slope would become much flatter(no systematic adjustment of the pace to ability) or much steeper(students truly moving at their own rate). The fact that the between-class slope is smaller than the within-classes slope for meaning wouldinvite other speculative interpretations -- for example, that thecomparatively able members of a class drive the level of discussionup to the point where the less able become confused. All suchinterpretations become moot when the uncertainty attached to the between- groups coefficients and the possibility of demographic effects are borne in mind122 ,ZACH100 100 the study(From Cronbach r- Webb, 1975)000 0 DRILL0 MEANING 50100 124 5.5 Along with the coefficients within single classes, the followingarray gives the class means on PRECOM in parentheses.Drill:1.07.93.90.90.84.63.56.55.51(34)(-45)(38)(17)(-7)(6)(-13)(81)(-118)Meaning:1.121.08.87.76.73.67.50.43(-1)(-7)(38)(23)(-75)(-8)(108)(36)These distributions of b's do not differ. The weighted averages are0.75 and 0.78 respectively. An investigator gathering data such as these today would be wise toask why some coefficients are twice as large as others. A coefficientis an historical fact about a certain group of identified students, going through a unique series of local eventsthat realized in a specific way an intended treatment plan. It isas legitimate to contrast high- and low-slope classes as it is forthe historian to contrast, say, utopian settlements that succeededwith utopias that failed. In the drill classes, the Bc's are positively related to the classmeans (r = 0.28). The low-slope outlier whose mean is -118 contributesso much to the correlation that it probably should not be taken seriously.In the sample of meaning classes, the correlation is -0.34; theoutlier whose mean is -75 weakens an otherwise-strong negative trend. Whenthe sample of classes is of the normal size, trends such as these willnever be convincingly established as characteristic of the populationof classes.Nonetheless, the analysis is a reasonable step in learning from the data. 12 ;) no pg. 5.6 The variance of ZACH scores within treatments was broken down asfollows (all figures are percentages): Between classesDrill Meaning Individuals (overall) 100.0 100.0 AThese values are pretty much what one would expect: within-classdifferences account for more variance than between-class differences,and variance is larger unpredictablevariance.The specific-within-class regressions do not formuch variance. Comparatively little of the between-class variance inoutcome under the meaning treatment was predicted; this is consistentwith the slope reported earlier. It is wellto keep absolutemagnitudes of effects in mind. (In the Anderson data, the ZACH 1265.7 variances within Drill and within Meaning were 9880 and 10011respectively.) A between-classes effect, for example, shouldnot be dismissed as unimportant merely because it is small relativeto the scale of individual differences; at some point, one mustconsider the meaning in absolute terms. When a test is the dependentvariable, what is \"important\" is judged on the basis of the alisolute proficiency required to earn various scores.Regressions of ZACH on ABIL.Anderson's original analyses werebivariate, and at the individual level. Hisregression5.8 planes relating achievement to ABILITY and PRECOM had different slopes.Drill appeared to generate better achievement for students with high PRECOM and comparatively lowABILITY whereas meaning gave better results for those with the reversepattern (\"underachievers\"). Before making this calculation, Andersonremoved a subset of superior classes from the sample.Webb and Iretained all classes in ourcalculations.Instead of analyzing ABILITY we formed a variate ABIL defined asthe value of ABIL and PRECOMhave little redundancy at the individual level. To have used ABILITYas a predictor in a univariate analysis would echo so much of theinformation in PRECOM as to obscure the interpretation. 127 5.9 The unstandardized regression coefficients onto ABIL were as follows: ADrill treatmentMeaning treatment-0.20 0.390.31 0.52 When PRECOM was the predictor, the Anderson finding had led us toanticipate larger coefficients in the drill treatment.This was true onlyof the between-classes coefficient, and we have dismissed that finding as untrustworthy. Anderson led us to anticipate smaller coefficients inthe drill treatment with ABIL as predictor, and again the principaldifference appeared between classes. The difference is impressivelylarge -- but is it worthy of serious consideration? The plot of group means again suggests that the two sets ofmeans have the same distribution, in that range of ABILwhere both treatments appear. The negative slope in drill would turnslightly positive if one class at the upper right were discarded. Thesalient feature of the plot, however, is the narrow range of ABILmeans in drill classes. Tracing this back, we found that across .drill classes ABILITYand PRECOM were highly correlated (0.74), but the correlation wasnear across the meaning classes. The drill-class meansin ABILITY werelargely redundant with PRECOM.Consequently, there was little variance in the second dimension of thebetween-class predictor distribution. The small variance in ABIL acrossdrill classes meant that the between-class slope onto ABIL is almost worthlessas an estimate of the population regression.128 Sao Anderson's study foundered on an accident of sampling. Theclasses in the two treatments appeared comparable to him, since theunivariate between-class distributions on ABILITY and PRECOM weresimilar.Also, the bivariate distributions for individuals pooledlooked much the same. Anderson failed to inspect the bivariatedistributions of class means. The points in the drill distributionlie nearly in a straight line, whereas the meaning distribution iselliptical.A chance failure to assign \"off-line\" classes to thedrill treatment spoiled Anderson's chance to get information on thebivariate regression. Smith and Bissell, it will be recalled (p. 3.6),found a similar anomaly in the between-groups covariances of predictors in the Westinghouse study, even though Head Start and control cases hadsupposedly been matched. The Westinghouse investigatorsevidently inspected univariate between-center statistics and,like Anderson, failed to observe the mismatch of the multivariate distribution of center means for predictors.In Anderson's data, the slope difference onto ABIL within groupsis too small to be worth interpreting. I shall not pursuefurther details of the study. 129 5.11 Cooperative Reading data* Plan of the studies. The Cooperative Reading study of the mid-1960swas a forerunner of other \"planned variation\" studies.To compare a dozenmethods for teaching primary reading, 27 research contracts were let.Eachinvestigator was to adopt certain features of a standard design, but hewas free to add procedures and to introduce treatments that interested himalongside the standard treatments.We concentrateon the comparison ofBasal (B) andLanguage Experience (LE) methods.Each preparedhis own reporta, and a composite analysia of all-the data was made byBond and Dykstra (1967). The reports attracted our attention becausemany ATI were reported; a sumnary of those, prepared mainly by Snow,appears in Cronbach and Snow, 1976, Chap. 8.The director of each of the 27 studies selected intact classroomswhose teachersagreed to participate in the study and assigned classes totreatments.Directors didsome matching of teachers across treatments onthe basis ofamount of experience, and on achievement of their students inthe previousyear.In most of theprojects teachers ranged widely inrated competence. Most teacherswere experienced in teaching first-gragereading using basal readers; few had taught by LE.Some project directors matched classes across treatments on thebasis of student aggregate performance in kindergarten, and on aggregateSES.Most projects used students of varying ability.In some projects,ethnic backgrounds of classes happened to differ fromtreatment totreatment.In few of theprojects comparing B and LE were classesrandomly assigned to treatments. *Noreen Webb is coauthor of this section. 5.11a In the Bond-Dykstra analyses comparing Basal to other methods,the non-Basal approaches seemed in general to be superior to Basal programs.Students superior in certain abilities seemed toachieve better in LE than in B. Less able pupils profited more from B.This relation was not clearly interpreted, however, since Bond and Dykstrawere unable to carry out a multivariate ATI study using all readinessand aptitude scores ,together. A reanalysis of a subset of the data with sophisticated multivariate'techniques was made by Lo (1973). He reported asignificant advantage for students with high perceptual speed (i.e.,-high on Identical Forms) in LE, whereas those low on the scale did betterin B.Lots analysis pooled classes and projects within treatments. 5.12 The original analysis across projects. Four projects compared Bwith LE.The B classes usually followed traditional Ginn or Scott-Foresmanreaders.In LE classes pupils told stories; these stories formed readingmaterial which incorporated the children's language patterns.The methodsvaried slightly across projects.Treatment groups within projects ranged from 219 pupils to 652pupils; the number of classes per treatment ranged from 10 to 27.Class size varied from 8 to 32.Students in all projects were tested in Septemberof Grade 1 on the Pintner-Cunningham Intelligence Test and on severalmore specific variables (e.g., Phonemes, Pattern Copying, Word Meaning).Five subtests of the Stanford Achievement Test Primary Battery I wereadministered after 140 days of instruction.Bond and Dykstra first analyzed in a Sex x Treatmentx Project design, working from the means for boys and girls in each class.The unit of analysis was thus the half-class mean.Analysis of variance was performed on each pretestorposttest.Two analyses of covariance were performed on eachposttest, one with Phonemes and Identical Forms as covariates,the other with all seven pretest measures as covariates.Girls scored significantly higher than boys on all pretests.On 6 out of 7 pretests projects differ6ignificant1y. Treatment groupSdiffered significantly on 4 pretests, On one pretest, a significant 1 \"9. 5.13 Project x Treatment interaction appeared. These last results strongly imply that the treatment groups are not random samples from the same population, though the significance tests are questionable (see below).Most sex differences at posttest tended todisappear in the covariance analysis. The few treatment differencesfound could be attributed to chance.Significant differences among projects and Project x Treatmentinteraction effects turned pp. Because the traatments behaveddifferently from one project to another, Bond and Dykstra decided toanalyze within each project. Half-class as unit of analysis? The Bond-Dykstra anova is excep-tional in its design, and a discussion of it will extend thinking onunits of analysis. The example is so exotic, however, that I give itlittle space.Their design and analysis are shown schematically in Figure 5.2.Three factors are crossed. Male and female halves of a class were taken as theunit of analysis, with no attention paid to the nesting of halves within classes. -To ignore classes is in effectto assume a priori that the component of variance associated with classes is zero. This would be self-evident only if half-classes had beenformed and treated separately, and then arbitrarily paired for the analysis. 133 EffectsProjectsiTreatments jSexkijjkijkHalf-classes within ijk Figure 5.2.Scheme within ijk Error term Figure 5.3.Analysis 134 5.14 An analysis that more adequately recognizes the pairing of half- classes looks upon the half-classes as repeated measures on the class. (This formulation was suggested to me by Dan Davis.) The analysis proceedsas suggested in Figure 5.3. Since sex is a fixed factor, the error termfor thei, j,andijeffects is(a),the mean square for classes.The error term (b)applies to the remaining effects.The error mean square of Bond and Dykstra is closely related to(b)but it includes variance attributable to class and it claims twice as manyd.f.for error. The original analysis within projects. In the within-projectanalysis Bond and Dykstra made the student the unit of analysis in orderto look at ATI effects. The treatment main effect usually favored LE,though this was reversed in some projects. To study interactions, subjectswere blocked in turn on Pintner (4 levels), Phonemes (3 levels), andLetter Names (4 levels). In only one project (Stauffer) were many inter-actions reported as significant; the child with poorer readiness tended toachieve more in B, whereas the able child profited more from LE. Bondand Dykstra dismissed this result, judging 133that the apparent 5.15interaction effect with one variable might be accounted for by initialdifferences on other variables. They lacked a procedure for handlingthe pretests simultaneously. Bond and Dykstra were too hasty in dismissing ATI in the otherprojects simply on the basis of nonsignificance. According to Cronbach and Snow, blocking on aptitude produces extremely weaksignificance tests even when students are properly the unit of analysisand N is large. Bond and Dykstra attributed to chance several borderline significant inter-actions that involved the same outcome variable. But when significancetests lack power, it is a mistake to let descriptions of nonsignificant but interesting effects drop from sight. Bond and Dykstra recognized the virtues of taking the class asunit of analysis, saying flatly that the class mean is the correct unitfor their analyses of treatment effects (not distinguishing this from thehalf-class).Like other investigators of the period, they overlooked theconcept of class-level ATI. Because they saw analysis at the class level as acontroversial procedure, they compared estimates of treatment effectsfrom their half-class-level analysis within projects and their pupil-levelanalysis. They pointedoutthat differences in procedure (especiallycovarying out Pintner in the individual analysis and blocking on it inthe half-class analysis) obscure the comparison.The mean differencesas well as the significance levels were greater in the individualanalysis, by factors as large as 8 to 1.Higher significance levelsare to be expected, because of the increase in claimed d.f.; the increase inmeans, however, Was not explained (see our Section 8). 136 5.16 Procedures in our reanalysis. Professor Dykstra supplied us aset of data for reanalysis, including only the pupils for whomsecond- as well as first-grade data were available. Moreover, wediscarded classes where many data were missing or punched as zero.A zero punch sometimes implies a missing score; even if that is notthe case, numerous zeros imply questionable test administration. Ouranalyses111 the first grade therefore cannot match the original report. We used data from three projects.that compared B and LE. Thenumbers of students for whom we received data were 211, 189, and 181for B, and 171, 183, and 199 for LE. We dropped two LE classes withmany zero scores from one project, reducing N for that project from199 to 169 students in 8 classes.Two B classes in that projectexhibited many zero scores on pretests other than Pintner. Weretained these classes in the analyses using the Pintner pretest,but dropped them in analyses of other pretests, lowering N from 181to 146 students in 8 classes.Likewise, in analyzing PatternCopying and Identical Forms we set aside an LE class where zeroeswere frequent. After cleaning we had from 8 to 11 classes withina treatment available for analysis. 137 5.17 We formed a composite outcome score (POST) from the Reading andParagraph Meaning subtests of the Stanford Achievement Test, weightingeach inversely with respect to its s.d. within treatments pooled. Herewe shall not discuss the remaining Stanford Achievement Test subtests.Our conclusions about the contrasts between levels of analy-sis of the composite are supported, however, by analyses on Spellingand on Study Skills. We used the following pretests in the reanalysis: Pintner,Murphy-Durrell Letter Names and Learning Rate, Thurstone PatternCopying, Thurstone-Jeffrey Identical Forms, and Metropolitan Listen-ing Tests.We did not consider thePhmetics or Word Meaning subtestsbecause of the prevalence of missing data in our sample.For demon-stration purposes we take up one predictor at a time here, though amultivariate analysis would be more adequate.Pretest intercorrelationswere low.Therefore we calculated only univariate regres-sions.The composite cutcome all pretest variables were standardizedto mean zero and s.d. 100 over all cases pooled. POST thus becomesZPOST, Pintner becomes ZPINT, etc. 138 5.18 Results of our analysis. We obtained a conventional regressioncoefficient (cases pooled) within each treatment within each project,across all projects within a treatment, and across all treatments withina project.These are more or less conventional analyses. Second, wehave a between-classes regression coefficient within each treatmentfrom the analysis of class means within a project.Third, we havea set of pooled within-classes regression coefficients, each calculated as themean of specific within-class slopes, for the combinations of treatmentand project listed above. Fourth, we have the regression within each class.In order to simplify, the tables to follow report data for only three pretests, but conclusions are generally drawn from six such tests. (1)Conventional regressions. The conventional regressioncoefficients of the standardized composite outcome variable (ZPOST) ontothe standardized readiness measures appear in Table 5.1.The slopes of ZPOST onto the standardized scoresfor ZPINT, ZIDEN (Identical Forms), and ZLIST (Listening) were higher inLE than in B for all cases pooled within a treatment. These differencesgenerally reappeared within projects. Differences of around 0.25 are neitherdramatic nor trivial. Taking that figure at face value,a student 2 s.d. below the mean on ZPINT will rise 1/2 s.d. in postteStperformance if he moves from LE to B.In the regressions of ZPOST onto ZIDEN, the only large effectappeared in the Stauffer project, where the slope in B wasclose to zero. In the Stauffer project there were ratherlarge slope differences of the same kind on ZLIST, ZLET, ZLRN, 7COPY,and ZIDEN.In the other two projects slope differences were usuallynegligible. We move on now to decompose the effects.139 at 5.18 Table .17 .27 .09.20(101.0) (89.4)(118.0LE .29 .30.17 0 5.19 (2) Between-classes regressions. Between-classes statistics weightedby class size for three variables appear in Table 5.2. The slope differences(LE - B) for all six pretests may be summarized as follows: -0.30 to -0.01 0.00 0.290.30 21Table Cleland 2 13Hahn 2 2 1 1Stauffer 1 5Manydifferences that seem practically important appear,all the large differences indicating a steeper slope in LE. That is, intheLEftabler classes do conspicuously better than classes of low average readiness.Between-classes analysis -- which to us as to Bond-Dykstra seems to be theaappropriate emphasis in this research -- paints far more emphatic pictureof ATI than the conventional analysis. The variation from project toproject is noteworthy. The Stauffer classes were, as a set, far below theothers on most of the pretests,1;hich may or may not be a causal factorin generating slope differences. Each of the slopes is determined by 11 or fewer classes, and conse-quently we can have no confidence that similar results.would appear innew samples of classes. As in the Anderson reanalysis, plotting datapoints is instructive. In the Cleland project, the slope onto ZPINT wasnegative,suggesting that B was detrimental to high-ability classes. Theplot of B class means for that project (Figure 5.4), however, showed thatthe negative slope resulted from the deviation of just one class (near-1(i0, +100).If that one class were deleted, the slope in B would be positive, notnegative.141 at 5.19 Table posT AA0NgA.a013illat 5.19 AAweaA4W0rat00a'\u00b0A1119i0004ailIIIACo0A0A00 ..8LE0iiiCLELAND0HAHN6 ASTAUPFER Figure 5.4.Plot of class means in Reading study 143 5.20 The slope differences onto ZPINT in the Hahn project may alsobea chance result. The B and LE classes could fit into the samejoint distribution. The range on ZPINT is small and the slopes notwell determined. The LE classes in the project directed by Stauffer formed anunusual distribution on ZPINT, split in ehe middle; some classes werevery much lower at pretest and posttest than the majority of classesin that project. In therange where ZPINT > -50, the 8Stauffer Bclasses have conspicuously poorer outcomes than his 6 LE classes inthat range.This is aneffect worth noting, whether significantor not.There is no warrant for a statement about the regressionslopes, in view of the narrow range of these 6 LE classes. The result for ZIDEN agrees with Lo's finding of an interaction oftreatment with \"perceptual speed\". On each subtest -- even ZIDEN --however, LE and B plots fit into the same joint distribution. Thus, withinprojects, every negative slope of ZPOST onto ZIDEN or ZLIST resulted froma single class with high posttest and low pretest or from a class withhigh pretest and low posttest (or from one class of each kind). Again,we must dismiss the differences between slopes among B and LE classesas chance results. At the between-classes level no Aptitude x Treatment interaction hasbeen established. It is entirely likely that differences in regressionslopes are chance results. Studies with many classes per treatment areneeded to estimate between-class effects. 141 5.21 (3) Within-class regressions. The within-class regression coefficients, averaged within each project, appear in Table 5.3. These varied much less than the between-classes slopes, and the differences were small. Just one of the 18 differences exceeded 0.30 (Hahn on ZLIST). It is evident that the interaction effects found in the overall analysis arose from the between- groupsdifferences (which we recognize as likely to be chance effects) and not from within-group differences. If the between-groups effects are untrustworthy, it follows that the differences observed in the overall analysis are untrustworthy.Taking all projects together, the difference for ZPINT is in thedirection of a finding reported by Bond-Dykstra and Lo from their conven-tional analyses -- but the effect is very weak (0.46 vs. 0.34). On the other pretests the differences for projects pooled are even weaker. Within projects separately, there is not even a consistency in sign between the slope differences in Table 5.2 and those in Table 5.3.The two comparatively large differences (both in the Hahn project) cannot be taken seriously. filRegression slopes for ZPOST onto ZPINT within Hahn's 11 classes rangedfrom 0.23 to 0.80 in B and from 0.46 to 1.00 in LE.The slopes of ZPOST onto ZLIST ranged from -0.70 to 0.81 in B and from0.08 to 0.47 in LE. This undermines the conclusion that slopestendto be higher in LE than in B.We looked further into instances where a specific within-classcoefficient on a pretest was negative. All these negative values weretraceable co one or more anomalous students who scored high at pretestmnd very low at posttest or vice versa. 1 4 5 at 5.21 Table 5.3.Unstandardized regression coefficients .70 .43.46(71.7)(76.8) (102.8) Pooled .23 .56 .39 .40Difference-.01 .28 .07 .12 ZIDEN B .16 .43 .36 .31(72.5)(74.1) (110.0)LE .20 .11 .51 .19 .28Difference-0.02 .41-0.09 .11 146 5.22 Conclusions regarding units of analysis. The reanalyses we have madeof the Bond-Dykstra data -- of which only a fraction appear in this report --demonstrate the central themes of our theoretical section. 1.Analyses of the conventional kind, pooling individuals acrossclasses, combine between-class and within-class effects in the sample.They therefore give an equivocal descriptive picture of the relation ofoutcomes to predictors. We shall later see (Section 8) that they give apoor description of adjusted treatment effects. Significance tests basedon individual-level analysis are unacceptable when classes are the unit ofsampling.Because between-class data weigh heavily in the overall regressionslopes, any undependability in the between-class results casts doubt on theoverall results. 2.Between-class analyses appear appropriate in this study.Between-class regression slopes often differ greatly between treatments. These differences, however impressive they may be when coefficients arecompared, are evidently dependent on the inclusion of particular \"outlier\"classes in the sample. With samples of 11 or fewer classes per treatment,observed differences in between-class coefficients are untrustworthy.The alternative of pooling projects for a between-classesconsistentanalysis leaves us with modest but differences in coefficients, basedon the unusually large sample of about 30 classes per treatment. Whetherit is legitimate to combine projects, however, is questionable. 3.Pooled-within-class within-project coefficients do not differgreatly.Even though these coefficients are based on large numbers ofobservations, their statistical stability is low, because the specificwithin-class coefficients differ considerably.an important subject for investiotion. 147Such variability may be 5.23 Head Start Planned Variation* Our third set of reanalyses exploits a fraction of the datacollected in the Head Start Planned Variation study. This study wascarried out in 1969-71, in the wake of the Westinghouse study of HeadStart.Like the Follow-Through study that Abt analyzed, this was a prospective study in which a number ofsponsors set up experimental classrooms using their own \"models\" ofinstruction; the control groups (chosen by the sponsor) were enrolledin \"regular Head Start classrooms\". Emphasis, however,was to beplaced on the contrast among experimental groups. The samples given thevarious treatments were not chosen to be similar at the outset.My interest in these data was aroused by an ATI study made by theHuron Institute (Featherstone, 1973) under the direction of MarshallSmith. A number of interactions of treatment differenceswith such variables as the Pre-School Inventory of Caldwell (PSI) andprior preschool experience (PPE) were reported. Featherstone analyzeddata from two cohorts. The 1969-1970 data were used to iden-tifyhypotheses for more formal testing on the sample of the nextyear.The first analyses are said to have been made by \"the Data-Textpackaged program for unweighted-means analysis of covariance.\" Huronargued that the variation in sample size from model to model wasfortuitous, leaving no reason for giving greater weight to models whichhad more children. Although this reasoning appeals to me (models beingconsidered fixed), classes are random within models and should be weightedby size within models. It appears that the child was taken as the unit of *Lynne Gray assisted in this analysis.148 5.23a analysis in both the first and second set of data, and I do not know how the computer package resolved the weighting problem. For analysis of the 1970-71 data, Smith s'et out a most unusual setof procedures (summarized in Featherstone's appendix). The description istoo limited tJ remove ambiguity; just what the Huron group did is notgreatly important here, however, as I am not retracing their footsteps.Some comment does seem to be called for. Let me consider their \"PSIregression 4b\" (Featherstone, p. 188). The dependent variable was thePSI posttest (PSI2) and the independent variable was \"directiveness of model\".For this purpose, all Engelmann-Becker cases and all Bushellcases were coded as more directive; and EDC, Bank Street, and Far Westcases were coded as less directive. Only 183 cases were employed.Featherstone speaks of 12 first-order predictors (one being model-group and the others being descriptive of the child and his background).Class identification was ignored. The full model also contained32 first-order interaction terms (11 of them being relations of the formModel xChild characteristic), and at least four second-orderinteractions but possibly a much larger number. We are told that\"regressions were done stepwise with main effects forced in and inter-actions allowed to enter one by one to explain the maximum additional variance.Results given in the text are for the step on which thestandard deviation of the residuals was minimum.\"CR The \"results\" take the form, first, of the standardized regressioncoefficient and its significance for each of three variables: Modelgroup, PSI (pretest) and their product. The latter two were significant. 149 5.24 Second, there is a table of \"Effects on adjusted PSI [2] score (givenin s.d. 's)\" at p. 111 -- a fourfold table, crossing directiveness with High/Low P5I-1. The High/Low contrast gives means 0.5/-0.8 in theless directive treatment and 0.4/-0.1 in the directive treatment; the student of ATI effects could easily believe that the choice of treatmentfor Lows makes a large difference. Attempts by various persons at Huron to provide me with a morecomplete description of the analytic procedure broke down, and I canonly try to invent a plausible way to get such figures. Perhaps Hurontested significance of the three contributions independently, by thestep-down method of removing each one from the full model. Possiblythe adjusted scores were deviations from estimates obtained forindividuals using the full-model regression equation less the criticalterms for PSI-1, Directiveness, and PSI x Directiveness. A procedureeven approximately like this would be enormously daring, since it seemsto abandon entirely the customary assumption of homogeneous regressions across treatments, and fits dozens of regression coefficients to obtain anadjustment.The final variable is not PSI-1; it is PSI-1 withdozens of things partialled out. Such steps could be givena strong justification, provided that (1) the variables on which treat-ment groups differed at pretest are highly reliable; (2) the product cerms were formed by multiplying deviations from the grand mean -- anything elseallows correlations among predictors to totally obscure what is happening--and (3) children ha been sampled and treated independently. I suspectthat allthese requirements were violated, but it is thethird thatbrings me bnck to the point of this report.150 5.25 When there are 183 cases and dozens of correlated predictors,any one of the partial regression coefficients is likely to be highlyunstable.This is true even when no one intercorrelation of predictorsis large.What is worse, in this study the students were treated ingroups.It seems that data come from some 15 classes. (Children for whomIQs were missing were left out of Featherstone's Regression 4 ).Thenumber of classes is much less than the number of variables enteringthe regression equation. If classes are the sampling unit,are leftnodegrees of freedom for making estimates of effects.The datahave been seriously \"overfitted\"; it is not unlikely that the finalregression weights in the full model were fitted to rounding error.AnalysiS at the individual level can be defended, I think, only byasserting that each child received independent treat-ment, and that differences in pretest characteristics and treatmentdelivery, among children sampled one from each classy no largerthan would be found for a random sample of childrer within a class. We madesimple regression analyses, one the conventional overallanalysis such as Featherstone employed, and two with partitioned effects.(The analysis we made and the ancova to appear in Section 8 are more nearlylike Featherstone's \"regression 3\" than the analysis just reviewed. The reason for reviewing analysis 4b is that Featherstone's descriptionof it is less equivocal than that for 3; moreover, the only summary data reportel on her PSI studies came from 4b.)In a file of data supplied by Tony Bryk of Huron, we selecteda set of 244 chil.dren in 13 classes of the more directive programs (Bushell, Engelmann-Becker) and 315 in 30 classes of the less directive 151 5.26 programs (EDC, Bank Street, Far West), to investigate the regressionof the PSI posttest (PSI-2) on PSI pretest (PSI-1). Featherstone used422 children in her regression. As in the Anderson and Bond reanalyses, we have regression slopeswithin treatments for three analyses. The raw-score means of PSI-1were 38:6 and 35.1 for the directive and nondirective groups (hereafterD and ND, respectively). The means of PSI-2 were 49.89 and 44.78.The s.d.'s were in the range 9-13.We converted all variables to ametric with 100 as the s.d. for all cases together.The three analyses all indicate a steeper slope in the NDtreatment (Table 5.4). In the Featherstone report also, the D treatmentappeared to be advantageous for children low on the PSI pretest andnot for Highs. The slope difference in the conventionalanalysis(our counterpart of Featherstone's) is considerably smaller than thedifference in the between-groups coefficients, however. Taking thecoefficients at face value, the between-groups value seems to implythat what happened in the ND treatment depended strongly on the abilitylevel of the class; this was much less true in D. Within classesthe interaction is considerably smaller than in the between-treatmentsanalysis or the conventional analysis.A reader of Featherstone'sreport would be led to think that the ND treatment is more profitablefor individuals with higher initial PSI, but the within-classes effectis evi,ently slight. The effect she reported operates mostly betweenclasses.If this phenomenon were established as stable, it would argue __.that ND is an advantageous treatment for the childplaced in a group with high average PSI-1; this would be true whetherhe himself is high or not. 152 at5.26 Table 5.4. Regression coefficients (PSI-2 on PSI-1) within Head Start treatments calculated by various procedures 2rixRegression coefficients Treatment DirectiveChildren pooledConventional Between classes Regression 153. 5.27 The truth of the matter once again is found in a plot of classmeans.The statistics and the plot are given in raw-score units.The statistics did not suggest a dramatic disparity. OnPS1-1, there was a mean and s.d. of 38.6 and 7.0 for D, compared with35.1 and 7.9 for ND. On PSI-2 the values were 49.9, 4.7; 44.8, 7.8.Any drama has to be found in the s.d.'s for PSI-2. It turns out thata small army of ND classes had means below 30 on PSI-1, whereas onlythree D classes were so low. The unimpressive one-point difference in pretests.d.'srepresents variation impressive to the eye in the chart.Figure 5.5 repeats the story of earlier plots in this chapter: the twosets of points are close to indistinguishable, so far as trend isconcerned [save for one lone outlier]. It would be imprudent to assertthat there is nothing to the view that the D treatment is comparativelylikely to produce changes in class rankings.But the evidence for aninteraction is much less impressive than a total of 559 cases and anoverall slope difference of 0.25 led us to expect.Analyses of other variables give further examples of contrastamong regression coefficients of the three types.In Table 5.5 areexhibited relations of PSI-2 to various predictors, again with100 as the overall s.d. for all variables. With regard to age,Featherstone (p. 136) reported that the directive models favored youngerchildren in these data. She gave no numerical results to support thestatement.Table 5.5 shows a weak tendency toward a flatter slope in D,which is consistent with her statement, but not impressively so. Again,the difference arises mostly from the sketchily determined between-classes slopes.Preschool experience did not have a statistically significant effecton PSI-2, Featherstone said, but there was a strong means on the Preschool Inventory155 5.28 The estimated regression slope of IQ on preschool experience (afterher complex adjustment) was flat in the less directive treatments, andquite steep in D. Since PSI and IQ were strongly correlated, therelations for the two ought to be similar. When we regressed PSI-2onto preschool experience (with no adjustment) the regression slopewith was flat with ND in the overall analysis; the slopeD was onlymodestly positive. The correlation of Age with PSI-1 between classes(0.70) was about as strong as that with PSI-2 (0.66). Very likelyFeatherstone's complex analysis did not succeed in \"correcting\" forinitial differences in ability. Perhaps her finding arose chieflyfrom the between-groups slope of ability on age at pretest. Adjustingby means of the shallow conventional slope would by no means removethe large between-classes trend. (See Section 8 on adjustments.)Featherstone's report on interactions of race ison awithin-projects basis. \"Three of the less-directive models ... showeffects favoring white children, while...(one of) the more directivemodells] shows a highly significant PSI effect favoring Black children\"(p. 149). A project-by-project analysis has advantagesoveraclasses-within-treatment analysis. The N'swithin projects are often too small to zdlow solid analyses, however. For whatit is worth, the breakdown in Table 5.5 shows that if there is adifference between D and ND it is found in the between-classes regressionslopes, with the exceptional (but weak and not-to-be-trusted) findingthat D classes with more black members earn higher scores on the averagethan D classes with fewer black members. Again here, the paradoxicalreversal of sign was present at pretest. MOMED was one of three SES indicators in the Huron analysis,and no clear results emerged. The regression slopes in the table show156 5.29 no strong effect and, as usual, the largest difference is found inthe weakly measured between-class coefficients. It is hard to credita finding that classes where the children have, on average, more educatedmothers should do less well, as they do in ND. It will come as no surprisees that almost the same difference in between-class coefficients was presentat pretest. Like the Bond-Dykstra study, this is a comparatively large experiment,planned with substantial national resources and subjected to thoughtfulattention by both substantive specialists and methodologists over aperiod of years. Despite the ambitious plan, the study is manifestlytoo small to permit convincing comparison of the \"planned variations\",with 500-600 children distributed over eight models and each modelrepresented by fewer than a dozen classes, ill-matched across studies.The Huron analysts had some justification for collapsing so as tocontrast the D and ND types of model. They mistakenly thought thatwith 200-300 cases per treatment they could perform an elaborate searchfor interactions. In fact, they had 18 cases for most analyses in the D treatment, since a class constitutes a case -- or so this report argues.As has been seen it other studies, the interaction effects reported ariseprimarily at the between-classes level. Between-classes effects with alimited number of classes are to be ..liewed with suspicion. Moreover, theeffects reported by Featherstone seem with suspicious frequency to be anecho of between-class trends present before training began. The idiosyn-cracy of the Huron analysis should not obscure the fact that adjustment of posttest scores for initial differences, on the basis of the overallregression coefficient, cannot adjust adequately for between-class differences. Ishall return to this topic.157 6.1 6.Disattenuating regression slopes In theoretically-oriented work, relations of true or universe scores are the chief concern. In practically-oriented work also, the observed rrelations ought almost always to be corrected for error of measurement. In thecLassical formulation of the problem, Eis the true score of Person pon the test whose observed score is X, and is the true score underlying Y.ThenB=/p2,the denominatorYX EX being the reliability coefficient for X.The error inYdoes not enter into the correction. Sincep21, the corrected slope is steeperEXthan the uncorrected slope.There is no reason to expect the pooled-within-groupsand between-groupsreliabilities for Xto be the same.The two reliabilities for Xwill be the same (in the population)if groups are formed at random. Some writers appear to expect between-groupsreliabilities to be higher just because means are determined more accuratelythan individual scores. An example appears in the Abt report (p. V-6); itexpresses concern for the biases arising from measurement error inindividual-level ancova and then adds: \"Measurement error, on the otherhand, need not concern us at the school level: the stability of schoolmeans is much better than that of the individual child measurements.\"I shall argue that the standdrd error of measurement for means is lot, putthat the reliability coefficient need not be higher between than within groups. Itis to be noted that if tne within-groups and between-groupsregression coefficients are the same, they will not be the same after correc-ti,n tor attenuation if the reliability coefficients differ. ConversLly. .1 5 8 6.2 regression coefficients that differ may become equal or may differ in theopposite direction, if the reliabilities differ. This is one more barrierto inferring context effects from a difference in observed regression slopes.Within- and between-groups reliabilities Three cases ought to be distinguished: I.Classes are formed without reference to the scores X.Individuals are tested on Xbefore classes are formed, or persons within a class are tested independently. Class membership is determined in whole or in part on the basis of X .Individuals are tested onXbeforeclasses are formed. III.Classes are formed without reference to the scores X.Xmeasures are taken within the classes, by a grouptesting procedure.Inany of these cases a variable correlated with X but observed independently 2 of it may influence assignment to classes; i.e., nXneed nct be zero inany case.The cases have not been considered separately by previous writers.They require different psychometric analyses. Let us assume that groups are of uniform size nc.Also let us assumethat all members of a group are tested under the same ni conditions offaceti(e.g.,testitems)andthesamen.conditions of j(e.g., occasions).The terminology of this section and the basic concepts come from Cronbach ettheory al.11972 (hereafter referred to as CGNR). Generalizabllitv departs fromclassical theory in recognizing several sources of ;error and in not requiringhomogeneity of means, variance.1 and correlotions of scores obtained undtrdiiierent conditions. Each person has a universe score ;that is the xpe( tvalue of his scores' whon on all ijcombinations in the pti 159 6.3universe.I assume that the same universe is pertinent to every group. Iwritefor th.cin of the universe scores for the group members. Here \"cI writeXandXcfor the observed scores of individual and group.We wish to consider at various points parameters of the overall, between-groups, and within-groups distributions. The respective variances )j.2tpwptpcCase I.When group membership andvice versa, the generalizability (reliability) of individual-level scores isevaluated without regard to groups, in the manner set forth in CGNR. We can, inthe crossed design assumed above, express the observed score as the sum of theuniverse score, an error component, and a constant: X=+ constant.1Estimates of a2(p)andEa2(6)are available tp tfor whatever design was used to collect the Xscores, and these together2 provide the coefficient of generalizability Ept.expected values of certain variances and coefficientg because the CGNR model does notassume uniformity of error variances; the conditions iandjdrawn for a part-icular realization of the measuring operation produce a certain population variancefororX ,and it is the expectation over i and jthat is of interest..For purposes of disattenuating a between-groups regression one wants a group-level coefficient of generalizability. This is2 2 the ratio of 0 bc)toEab(Xc).The basis for forming groups determinesanintraclass correlation n2(uc,w),or siidplyn2(p).That is theratio of between-groups variance in the variance.Since, when pisa member of c up=(1.1(,)(upPc),c2(nc)n2(p)02t(i.,p)and(12(u-u )= [1.-n2(p))126, )pc tpIt is necessary to speak of Also,=- 6), where6cis the average of 6over membersof the arc and Lo2(6- ((,) = !. nctpwP,It(61)).Even tilough persons are fixed, the errors of measurement are random. I; refersLo tne expectation over repeated applications of the estimated from a G studyon individuals which estimates(12(u )andc2(6) ,and from the observed tp The formulas for such a G study are given by CGNR.a) Analternative is simply to carry out a G study on class means. The within-groups coefficient rwisn -1Xc) = fl-r12(P)P2t(iidg,l-n2(p)]0.2t(pp)--cir-Ea2t(6)]. Ep2(II- u coefficient for classes pooled. Sincen (p) > is likely that6.4 lne between-groups coefficient derived here is the same as that suggestedby Shaycoft(1962), for which Haney (1974a) presents a derivation. Studentsare treated as fixed within classes. Haney goes on to discuss an alternativeotfered by Wile!, (in Wittrock Z, Wiley, 1970) which treatsstudents as random within classes. 1 6 1 6.5 Wiley seems to contemplate that a group (the student body in one school, orthe class assigned to one teacher) could have many \"parallel forms\" drawn inthe same manner but not randomly representative of the total pool. His ques-tion is how strongly class means would correlate from one such set of classesto their set of Dorpelgangers. Case II.When assignment is based in part on the observed X ,it isnecessary to consider not only n2kp,but also an intraclass correlation2,(;)orn2(6).If assignment takes into accountXand at least oneother variable with p,n2(p)>n2(5).If as n 2(6)decreases, this degenerates 2to1;i.e., to Case I.) With persons fixed within groups, n 2 2 has not been described in the earlierliterature -- is smaller than that for Case I. This within-groups coefficient is largerCase III.2 collected in groups, but izability (reliability) ofAnalyses in Chapter VII of CGNR treat datado not consider simultaneously the general-individual and group data. In Case III itnek.essarv to analyze somewhat differently than in Cases I and II.here again, assume persons fixed within groups (p .c). 3uliverse consists of test forms icrossed with occasions j.Ihe investigator intends to generalize from D-study data generated hyaopleitty, the same form to all groups, each group being observed on one1;ien.Such a studv has the design E(p x j) :c J Xi,n=I, n162 6.6In the G-study, however, each of the kgroups is to take more than oneform.LetussuPPosethateachgrouptakesthesamen.form$, each formon a different occasion. The design, then, is (p:c) x i ;(j,ci) .Theobserved score for group con any onei,jpair resolves into componentsin this way: Xcij = P + (Pc P) + (PiP) (pcijpcPi/I)ecij Analysis of variance produces Table 6.1. Variance components areestimated by entering the actual mean squares in place of the EMS. I 72 write e(c) for c c), etc., as in CGNR. The between-groups rell'ability coefficient definedby the D-study debign. With the design specified (one form, one occasion),2.2 Ec2(X ..) = c2(c) + a (ci) +a (res) ctjIn view of the specification that persons are fixed within groups, andin view of the intent to adjust a pooled-within-groups regression slope, it isappropriate to decompose X- Xca..]Th..e components can be written X- x= (0-) ci(1)eljPc The last tWO(p confounded in the G-study design.The analysis of the deviation scores gives the quantities in Table 6.2.(The analysis of variance could be carried out in one step for both 163 at 6.6 Table 6.1 Mean squares in the analysis of group means and equationsforexpected mean squares Source ofvariance d.f.Mean sqExpected mean = a2(res) Table 6.2 Mean squares in the analysis of individual deviation scoresand equations for expected mean squaresSource of Expected mean square a function ij,e) = a2(res:c) 1 ccc 1 (3 6.7 individuals and groups. It -itild also be possible to make the analysisshown in Table6.2for one class at a time.)These stratified random assignment, the minimum of n2(p) isthat for groups a kpc0a2(p i) 02 (pcij,e) c'Two terms in the upper row have no lower-row counterparts. Within pairedterms, the upper term and lower terms are in the ratio n2/(1-n2), where then2is the vllue for that component. Whether rbandrware near equal depends on the intraclass correlations.Large occasion effects and large intraclass correlations for the pi,pj,or (less 1,tely) pijcomponea:s will tend make the group-level coefficientsmaller (!) than the Trithin-groups coefficient. Any effectassociated with the occasion (noise outside the test room, faultyinstructions. otc.) is common to all members of the group.Since these 165 6.8 components of error are not independent over persons, averaging withinthe group does not necessarily reduce them. If2(p)is large and the n2for the other three components in thewi'hin-groups denoMinator are small, the ratio of between-groups numerator to wi_lin-groups numerator will perhaps be larger than the ratio of denominators. Then the between-groups coefficient is the larger one. Case III analyses can of course be made for many other experimental T49,f9rT1,11,a,rprItAin,to,be worked,out,according, to the,principles_exhibited in CGNR. An overall \"individual-level\" coefficient canbe calculated by adding the two numerators, adding the two denominators, andthen dividing. This is not the value that would be estimated for the overallcoefficient by an analysis that ignored groups.General remarks I have replaced the \"individual\" (overall) and \"group\"reliabilities of other writers with \"group\" and \"individualAthin-group'reliabilities. Also, I have separated Cases I, II, and III, whereas othek.writers confined themselves to Case I without realizing it. The sixcoefficients will vary in size, but whether the differences are large-nlv future experience can tell us.Surely nc one will question theadvisability of choosing the logically correct coefficient in anydisattenuation procedure. It should be noted, however, thatI have discussed formulas forthe 40efficient of generalizability only because disattenuation requiresa coefficient. In the commonplace investigation of measurement error,t1(6)the standard errorkis of far more interest than the coefficient. Formost purposes, it is more important to know how well a rroup is measured 1G 6.9 than to know whether the measure discriminates between groups. Thestandard error of generalization of the group mean [a (Xc- uc)1.1islikely to be considerably smaller than the within-group standard error[a (Xpclj.-u)]so long as persons are fixed within groups.Pc 167 p.(). 36.10 Notes for Section 6 1The error1!is defined according to the experirental design. The eataproviding a coefficient of generalizability may not be the saue as thoseused to calculate the Y-on-X regression. Indeed, the G study may be carriedout under one case and the D study (the regression study) under another.That may still permit one to determine an appropriate coefficientof generalizability, provided that the groups used in the G study are a samplefrom the population of groups in the D study. In this report I shall assumethat the G-study and D-study data are collected by the same experimentaldesign, on samples formed under the same case. p. 6.52The Bowers data (p. 2. ) appear to me to be an example of Case III Hauser P. 6.has pointed out the importance of correcting regression coefficients forattenuation in reaching a decision about the apparent context effect in theBowers data, but Hauser assumed that the within-colleges coefficient wouldbe small compared to that between-colleges. In Bowers' study, a mail ques-tionnaire on attitude and behavior went to students at many colleges. Theonly facet along which it seems reasonable to classify individual data isoccasions.No doubt variability would appear if the questionnaire had beenfilled out on two independent occasions. I suspect that there are systematicCollege z Occasion effects, even if all mailings took place in the samemonth.A cheating scandal erupting on one campus would cause, studentresponses to a question on cheating to shift, the shift being fairly uniformwithin that college and not appearing in other colleges. If the questionfbout having been drunk is asked before the main event of the social yearon one campus and, by the vagaries of the local calendar, is Asked ,ubsequentto that event on another, we can again expect appreciable variahilit, overthAt ic to he (onsidered a (roup-related error. iRead: nected within c' for designs follows CGNR.168 7 .1 7.Statistical inferenceThe investigator will wish to generalize formally or informallybeyond his sample. In the problems considered here, it seems to me thatstatistical inference should center on setting confidence intervals onparameters within one treatment. I prefer confidenceintervals (or posterior distributions) to tests of the null hypothesisone beingfor many reasons, the most compelling that in research such as we areAdiscussing the null hypothesis has a high probability of survival. Confidence intervals enable one to report what he found with due caution, yetwithout suggesting that his study added nothing to knowledge. Posteriordistributions have the added advantage that, in principle, they enable ex-..perience to accumulate whereas other procedures treat each study as a newventure. I proposeto discuss only limited aspects of statistical inference.Within one treatment, we have to think about the between-groups and within-groups regressions (common and specific) of Y onX.I assume that groupsare randomly sampled from a population of groups, and that the distributionOfis bivariate normal. I assume members fixed within collectives. I make no attempt to set limits on the regression of y onto cc, .InLbw, procedures for setting limits on disattenuated regressions will be wanted. 1(j9 7.2 A iull examination would next move on to estimates of the treatmenteffect.A distinction is required between one-population and two-populationwere(or larger) studies, the former being those where groups assigned randomlyAto treatment.The case (4 homogeneous regressions (traditionally assumed)must be considered separate from the case where within-treatment coefficients&lifer.Again, error of measurement is to be considered; use of theattenuated regressions in covariance adjustment gives a false conclusion.The difficulties of inference about single treatments or treatment comparisons have not been resolved evenfor the study where individuals are assigned and treated, with none of thecomplications introduced 1-,y grouping (Cronbach et al., 1976).I omit inference about multiple regressions from this report entirely.Sampling error of a mean The simplest statistical inference evaluates the population mean on thebasis of sample information. If individuals are the unit of sampling andanalysis, the sampling error of the mean is estimated by s(Y)M.T.If groupsare the unit of sampling and analysis, the corresponding Lormula is sC.Ye)/vrIC\"wherekis the number of groups. 22 Suppose all groups are of size n; = kn ;ThenYe) =(Y)In random sampling tne intraclass correlation is 1/n,and the two modes ofcalculution will lead to very similar conclusions. The conclusions will nothe Idtpti,d1, 14 thetdistribution depends on the number of degrees ef 170 7. 3 freedom claimed. 2 With larger values of ny ,the sampling error calculated at the grouplevel -- as it should be -- becomes quite a bit larger than the one calcu-lated at the individual level. Consequently, analysis with groups as unitsgenerates comparatively wide confidence intervals.When the nullhypothesis is valid, the analysis with individuals as units will reporta significant effect unduly often.The between-grou s regression Where groups are randomly sampled from a population andall receive \"the same treatment\", the well-known procedures for establishing confidence intervals for a regression line apply to the between-groups regression. The parameters of the regression equation in the populationare;41,, and eb; the value of 00,1y)lux is also pertinent.cc Each sample is characterized by a pair of means, a coefficient bb'andan S-17.7A; .Under the assumption of normality, the bb are distributed normallyabout ,I7b,independently of the sy.-x-.The expected joint distribution of bb, spairs permits one to define an elliptical confidence region in the b, s spaceoutside which the pair 8b, a is unlikely to fall. From this comes the usualequation which, for a between-groups regression, can be describes the lower confidence limit for che regression line. The upperlinitis described by the same expression ith t,replacing t, .There 1-21ir,-2 d.t. for t, where I: is the number ot groups.The two equations 1 7 1 7.4 describe an hyperbola in the X, Y space; the asymptotes of the hyperbola(which pass through the sample mean p ,p) identify theouter limits of XYthe regression coefficient. Confidence intervals for group data are likely to be wide, because inmust studies the number of groups is small. Ifs-- is small, however, asY.X happens in some group data, the confidence interval can be satisfactorilynarrow in the neighborhood of the X mean.Samples on the order of 100 classes are required to make bba goodestimate of6bThis statement comes as an unpleasant surprise to mostresearch workers, and some find it hard to believe. A simple example mayovercome such doubts. Suppose that1Gly ) = C(4x 1/4-(1-T .Ifk = 100 2z= 0.10and the 957 limits on sample values of zare 0.22 and 0.62, implyinglimits of 0.22 and 0.55 on r.Swings over that range, and over the(orre,Tonding range of b,could be consequential. Just how large asamplf- to demand is a matter of judgment, of course. lhe within-groups regression _TLe usual procedure cannot be adapted to establish a confidence interval:or tile poolekl-within-groups regression if individuals are fixed within grc,ups. ; 2 7.5 The several ecare independent estimators of Eec.If theecare assumed to have a normal distribution, it is a simple matter to set confidence limits: as<Et3<c c ts(=tBcc1--lacThe number of degrees of freedom is k - 1.These limits can be thoughtof as describing two within-groups regression lines both of which pass throughthe point 0,0. (lle hyperbola of the between-groups inference degenerates whenthe mean is given a priori.) Whether these confidence limits will be wide ornarrow depends on the spread of the ec. With regard to the specific Oc, it is difficult to ask a useful inferen-tial question in the usual circumstances (see pp. 4 .1-8). 8.1 8.Analysis of covarianceAnalysis of covariance is used to evaluate the difference amongoutcomes in two or more treatments. An adjustment for initial differencesis the crux of the procedure. Even when assignment of individuals orclasses to treatments is random, the choice of unit of analysis has someeffect on the result. When assignment is not controlled, the initialdifference may be large; then the choice of units may greatly affect theadjustment.The standard procedure is to calculate (directly or indirectly)an adjusted outcome score for each person or group. Should thb adjustmentbe derived from the within-groups, the between-groups, or the overallindividual level regression coefficient? Many investigators seem routinelyto assume that the regression coefficient calculated at the individuallevel (within treatments) should be used.Among those who recognize morethan one possibility, some carry out and report alternative analyseswithout a clear basis for interpreting them.In analysis of covariance, a number of difficulties arise even apartfrom questions regarding units of aggregation.In the best case, one hasan experiment with random assignment; then the analysis with any regressionequation gives an unbiased estimate of the treatment effect. The statis-tical model assumes that the covariate and its values are fixed, and thisis not generally appropriate in social and educational research.Problems multiply when selection or self-selection determines who entersand completes each treatment. Poor data on initial characteristics --failure to measure some characteristic for which adjustment should bemade, or inaccurate measurement -- bias the estimate of the treatmenteffect. Ishall say no more about these difficulties, though they are I i I 8.2 pertinent to research on groups. Recommendations for analysis of covariance have to take into accountthe design for collecting data. Any of the elaborate designs to whichanalysis of variance is applied can be extended by adding covariates, sinceancova is anova of adjusted scores. It will be sufficient here to considertwo designs, and to limit attention to investigations with only two treat-ments, A and B. Design 1 is an extension of the two-group experiment (or quasi-experiment).Collectives are nested within treatments, and members arenested within collectives. Collectives are considered to be a randomsample of a population of collectives; if assignment to treatment wasnonrandom, there is a population for each treatment, defined by the selec-tion rules, explicit or implicit. I have suggested that members be con-sidered fixed within collectives, but some analyses treat members as random.Design 2 crosses treatments with a blocking factor. This factor maybe a higher-order collective. In the Performance Contracting experiment,schools -- the unit to which treatments were assigned -- were nestedwithin school districts, each district in the study having a school ineach treatment. The factor may be a potential cause whose main effect isto be removed from the error variance, as when every teacher handles a classin each treatment. The factor may be a characteristic ofpersons, as when class membership is determined by selecting studentswithin certain IQ ranges. Once collectives are identified within blocks,they may be assigned to treatments randomly or not.Collectives withina treatment are a-;sumed to be experimentally independent.Desko I.Collectives nested in treatments Itis usual in educational research to choose one set of schools orclas,:os for Treatment A and to choose independently another -,et for B. 173 8.3 This was the design in the Follow Through study where Abt (Cline et al.,1974) offerea analyses of covariance at the pupil, class, and school levels.\"Where results are consistent for parallel questions across the threelevels of aggregation\", they said, \"we have enhanced confidence that theyrepresent the true effects.\" This was a study with nonrandom assignmentand the treatment populations differed in initial characteristics.Theanalyses would be most unlikely to agree with each other even if Abt had used the same variables in each analysis. Each covariatewas formed by multiple regression, hence different composites were used tomake the three adjustments. It would require an enormous coincidence foradjustments made with different composites and different regressioncoefficients to be the same. Alternative adjustments. It will be instructive to consider adetailed list of alternatives, though some of them seem unreasonablea priori.To keep matters simple, suppose that there is one perfectlyreliable covariate X,that there are just two levels, and thatcorresponding regressions have the same coefficient from treatment totr, itment.But do not assume that 6b= 6w.Set the mean value ofXfor ail cases at zero. Each analysis determines the intercept of a within-treatment regressionlinc atX = 0 .The heart of ti process is to fix a coefficientfiln one slibtracts EXfrom theYscore for each unit of analysis andaverages within the treatment. The coefficient may be determined in these wav-.: 8.4 1.Overall. Calculate a within-treatments regression coefficientwithout regard to boundaries of collectives. 2.Between collectives. Calculate a regression for collectivemeans, within treatments. 3.Within collectives. 3a.Convert scores to deviations from the mean of the collective.Pool collectives, and calculate the regression coefficient. One can obtain an intercept for each collective, or forall collectives. 3b.Calculate a regression equation within each collective,and use it to adjust scores of members. This gives an intercept for the collective. 3c.After calculating within-collective coefficients as in 3b,determine the trend of coefficients as a function of themean of the collectives on X.For collectives withanyXmean, obtain a coefficient on the basis of thisregular trend.In analysis 1, the number of degrees of freedom comes from the number ofindividuals. In 2,3b, and 3c, the number of classes is the basis fordetermining degrees of freedom. In 3a, investigators might adopt either basis for calculating degrees of freedom. The several analyses are illustrated in Figure 8.1, which showsschematically the data for three collectives in just one treatment. In thi:, illustratiun thebetween-groups slope is steeper than any of the within-group slopes, andwithin-group slopes have a regular trend. Panels (i),(ii), and (iii)represent adjustments 1, 2, and 3,/,---Pc,tiv,'!v. 1 7 7 (i) OverallY 0 (ii) getweengroupsxat 8.4 (3(iii) withingroupsconsidering trenu Figure 8.1. Estimates of adjusted treatment mean consider-ing three alternative regression lines 178 8.5 The adjusted mean in Panel (ii) is the smallest of the three.Although it is not necessary that the between-groups coefficient belarger than that within groups, experience shows that this usually is the case.Adjustment by means of the between-groups coefficient, then, is amore drastic adjustment than the others, and leads to a less favorableconclusion about the treatment for which the sample stands higher onX.The pooled-within-classes adjustment (3a) is shown by the dottedline in Panel (iii); it gives the largest of the adjusted means.Theoverall adjustment in Panel (i) is close to that in Panel (ii) because of 2the largenx.It will alwayslie between the adjusted means from the between- and pooled-within 2 at:justments.It will be close to the latter if nXis small.Thc adjustment 3cthat takes into account the steeper slope in classes withhigherXgives the intercept indicated by the arrow in Panel (iii).This is the average of the separately adjusted means for the classes. If it is believed that group-caused effects are nonnegligible, thebetw,!en-collectives analysis appears to be appropriate. Each collectiveis an independent realization of the effects, group-caused and other,sampled from a population of realizations. The intent is to generalize to a population of realizations for which the overall mean Xis near zero. if there are no group-caused effects, then one could still analyzeappropriately at the between-collectives level. Collectives are the unit of sampling, and unless collectives differ only by chance on initialyariahle,, relvant to Y,the statisticA ,,0e1H4 hnt r;I v no p. 8.6 8.7 calculated within collectives. Note that the uppermost regression linein Panel (iii) projects the unadjusted mean forYin the rightmostcollective into a considerably lower adjusted mean. If this has anymeaning, it is a prediction as to what would happen if individuals withX = 0were treated as members of a collective with a high mean on X.The extrapolation is rash on its face.To use it in evaluating thetreatment, however, embodies the even more absurd extrapolation that thisis the mean to be expected \"if this class were made up of students whosemean score is zero\". The presumed reason for a steep slope in the high-Xclasses is that the level of Xmakes a difference in the slope, so thatthe extrapolation is self-contradictory. If within-groups slopes are irrelevant, why mention them? My reasonis that they crop up in practice! Most obviously, every time an educa-rional investigator performs an experiment with one collective per treat-meat, his analysis of covariance uses adjustment 3.(Since there is only one class per treatment, cases 3a, 3b, and 3c areindistinguishable, and indistinguishable from the overall adjustment 1.) The analysis is just, if the class is a random collection of individualswho respond independently to the treatment. If not, the investigator hasadiusted without information onr,b.IfBbBw,he has overadjustedor underadiusted. In1multigroup to assumeFb = ,theavera!1 analysis is justifid and the others are less suitable. Theoverall analysis also makes sense when individuals are sampled individually,Ind the individual's experience is not systematically asso(iated with that of)thers in his group. In this lattercase, demographic effects may (ause a i tte bet ween t reatment(.11t.(LandOw has no bearing on the estimate of the180 8.8Cooperative Reading data. To illustrate the contrasts amonganalyses 1,2, and 3a, Webb and I processed data from the study of Hahnwithin the Cooperative Reading Program. We used 183 students in 11 classesthat had followed a Language Experience (LE) program and 189 in 11 classesin a Basal (B) program. The raw score on Stanford Word Reading at the endof Grade I(a component of POST) was our dependent variable, and thePintner test of mental ability our covariate. The B group had a Pintnermean higher than the LE group (1.24 points higher; about 0.2 s.d.). I.The first analysis used the overall regression. Scores within atreatment were pooled without regard to class membership. The overallregression slope for the combined treatments was 0.45. The covarianceanalysis gave this information:Mean for LE before adjustment, 24.5 ; after adjustment, 24.2Mean Basal each treatment ieparately. The regression coefficients were 0.ii in IE and 0.37 in B, and the corresponding adjusted means were .2 and .I hIlseofthe,4pec if f1)e: tiien1-;hadli t t le cite( ten thedi:seran,e in Id,,,,,t.1 means, as is to he ev.ptAtid; titting within A tratmentht, the ellrt primal-11v ot reducing the re,4idual varian(o. 1 8.9 2.When class means were used to calculate the within-treatmentsregression coefficient, it rose to 0.63. The covariance analysis wascarried out as before but with the adjusted class mean as the dependentvariable.This score was entered for each class member, in keeping withour policy of weighting. The sums of squares from this analysis were used,but the number of degrees of freedom for the denominator given by thecomputer, based on individuals, was replaced with 20, based on classes. SSd.f.MSFTreatments 222.25 1222.252.34Within treatments 1894.012094.70 The F ratio does not reach significance.An adjusted treatment effect of1.5 replaces the 1.8 of the individual-level analysis. The adjustedtreatment means are 24.1 and 22.6. (Bond and Dykstra reported an adjustedindividual-level treatment effect of 1.8, matching ours.After class-level adjustment, they reported an effect of 5.6, however; I have beenunable to determine why.) 1.The within-classes coefficient for treatments pooled was 0.42.The summary in Table 8.1 indicates that the shift in methods ofidiuscment did not produce a great difference in the adjusted treatmenteftekt. The shift from a claim of sig,ificance to non-ginifiance stems from the larger error variance that accompanies the correctnumberof degrees of freedom. Follow Through data. One more brief example can be derived fromthe Follow Through data mentioned in Section 5.Featherstone reportedthat ehildren with prior preschool experience were better off in ale,;s-dlrective treatment. The study had classes nesttd within treatments. 132 at 8.9 Table 8.1.Coefficients and adjusted means from three analyses Analysis Coefficient(s) Means after adjustmentLEBDifference .42 24.222.5 1.8 Table 8.2.Alternative adjustments of hypothetical data for three a and dinstment 2 isto center mean of A's. 133 8.10 Featherstone found it appropriate to use separate regression lines forthe two treatments. As in Section 5, all variables are rescaled so thatthe s.d. for all cases together is 100. Here I take the posttest on the Preschool Inventory as dependentvariable and preschool experience as predictor.When the same set of datais processed in modes 1, 2, and 32, the adjusted treatment effects shiftas follows: adjustment -0.0950.1480.243 The between-groups adjustment, which I consider the appropriate one,reduced the treatment effect to about 85 per cent of that reported bythe conventional overall analysis, and reduced thenumerator of theF ratio by 28 per cent. Change occurred primarily in the value for D,sincebbandbwwere nearly the same in D.Design 2.Treatments crossed with blocks; collectives nestedThe design in which collectives are blocked gives up some number ofdegrees of freedom, but brings irrelevant variance under tighter control. Once 1.1t)are ,ollected under such a design it seems to make no sense toignore the blocking. The blocks may be regarded as fixed (e.g., when the50 State,, serve as blocks) but it is probably more common to regard themAti r,ndomly representative of some larger population of blocks. Then thedequacy of the information depends on the number of blocks in the sample.';tippw-w that, within hlock,;, there are just two colletives, one 8.11 assigned to each treatment. Then, if no covariate is to be considered,one might reasonably form the means for the collectives, take the differencebetween treatments in each block, and test whether the mean of the differ-ences differs from zero. An equivalentprocedure is a two-way.analysis of variance, with the Blocks x Treatmentinteraction supplying the error variance for the F ratio.Blocking servesthe same function as analysis of covariance, insofar as there ate relevantinitial differences between blocks. Whatever variables contribute tovariance in outcome at the block level are extracted; this does not modifythe estimate of the treatment effect, but it reduces the estimatedsampling error. A covariate may now be introduced to allow for initial differencesbetveen collectives within the block. The question is, how does the meanoutcome in the collective relate to the initial mean? And how would thedifference in outcome means be altered if the initial difference were zero?The_plan of the Head Start study. My thinking about Design 2 wasstimullted primarily by the famous Head Start evaluation made by theWestinghow-fe Learning Corporation (hereafter WLC; 1969) and the reanalysisby SmitT) 4nd Bissell (SB; 1970). Both sets of analysts wrestled with theproblem of units. Although I shall raise questions regarding the,olution,- put torth in those reports, WIC and Sg were ahead of their timein their thinking about levels of analysis. The entire body of datainclude5 tindings for full-year Head Start program-, Ind summer programs,for white children and black children, and for follow-up result Q. on attention 8.12 further to the full-year data on children of all races together, withSES as covariate and Total score on the Metropolitan Readiness Test earlyin Grade 1 (MRT) as outcome. I shall not trace the influence of a subtleshift in covariates that occurred; in one analysis WLC used a singlepredetermined SES composite and in another formed a three-variablecomposite post hoc by multiple regression (overall); SB formed threecomposites, one from the between-group correlations, one within-groups,and one overall (p. 9.18). For my purposes, I shall simply speak of SESas covariate. Head Start was administered through local offices or centers, eachwith its orritory; centers were the primary unit of sampling for thestudy.Within a center there was occasionally more than a single class,but this was too infrequent to be considered in the design. Classeswithin a center, then, were combined. The pool of Head Start (A) childrenconsisted of those who could be tested in first-grade and who had attendedthe centers under consideration. A pool of control (B) children consistedof children located in first-grade who came from the center territory,who had been eligible for Head Start, and who had not received this orother prekindergarten training. Now from the A pool a sample of 8 childrenwas drawn for each center; and 8 B children were individually pairedwith them -- matched on sex, race, and attendance/nonattendance atkindergarten.Thus the design is Treatments crossed with Pairs ofchildren, Pairs nested within Centers, one child per cell. Both WLC andhowever, ignored the matching at the individual level, and I shallignore itiRo.I do not 'iee how the information ,ould be usedcon-;tructivelv in assessing the main effect of treatments.,-haracter of the discriminant may be noted in passing. In thisthe collectiveq differed on several known variables. In addition 8.13 to the variables in Table 4.1, center pools differed in racial makeupand in the prevalence of kindergarten attendance. This is one of,thecomparatively uncommon instances of a quasiexperiment in which membershipin a collective is correlated with a posttreatment variable, for reasonsnot arising wholly from initial demographics or from the group as cause.(The child's attendance at kindergar.ten may have been to some degree aconsequence of his Head Start experience, or of his parents' desire tocompensate for the absence of Head Start experience.) Whatever the causalchain, if children with krindergarten experience are more numerous incertain centers, and kindergarten raises MRT scores, the discriminant iscorrelated with YX on a basis that can neither be considered a contexteffect nor a demographic effect. Alternative analyses, assuming homogeneity of regression. WIX reportedtwo analyses, and SB reported six. These eight by no means cover all thepossibilities, and I shall argue that none of the eight -- as I understandeach of them -- is logically appropriate. It is not precisely clear howsome analyses were conducted, and in both reports there are mysteriousdifferences in the unadjusted mean of MRT from one table to another. ItIs not so important to discuss those particular analyses as it is tocomprehend the range of alternatives and to develop a rationale for choiceamong thorn.I mav as well say at the outset that my preference among theanalvses has ch.Inged more than once as I have studied the problem, and tli,ttIAm not ,onvinced that I now know what should have been done withthese data. The u-otal andlvsis of covariance adjw,ts reuession coefficient that corresponding AInd 1:87 8.14 regression coefficients are the same in the population. SB found thisnot to be the case at any level of analysis for MRT-on-SES regressions,and so in some analyses they abandoned the Lomogeneity assumption. Istart with analyses that assume homogeneity. It will be helpful to denotethe between-collectives regression coefficient as bb,that withincollectives as fegression which ignores collective TATboundaries as boI am assuming here that the twobbagree, thatthebwagree, and that theboagree.The obvious possibilities follow, grouped in three categories. Icode them to identify the procedures I think WLC and SB adopted.(E.g., WLC1resembles one of the two WLC analyses.) A.Number of individuals as base for d.f.A-b.Use ofbb.(No one has proposed to use this.I list itfor the sake of symmetry.) A-w.Use ofbw.The productbw(SES)is subtracted fromindividual MRT scores. Then to compare treatments an unmatchedt-test is carried out on individual adjusted scores. (Where Irefer to a t-test, the algorithm of anova beused, collectives (WLC2). Smithand Bissell made a generalized regression analysis which issimilar (SB1). (The significance test is often made incorrectly,by assessing the significance of the increment in mean-square-explained-by-regression when the dummy variable for treatment (r)i, added Ati a 1.1,,tpredictor.The treatment effect 108 8.15 band the variance in Yaccounted for by treatment T T2 2isbTIT, which may be larger or smailer than the incrementin mean square. TheFratio is raised or lowered in thesame way that overadjustment would distort it.I see no warrant for taking individuals as the base for degrees of freedomwhen centers were the primary unit of sampling. Both WLC and SB offerA-o analyses with the idea that they may be \"more sensitive\" to smalldifferences, but inflating the number of d.f. simply produces spuriouslylow levels of the arisk. B.Number of collectives as the base for d.f. B-b.Use ofbb.Either individual scores or collective meansarresidualized by subtracting bb(SES).An unmatched t-teston adjusted means for collectives is run. There is an analogousgeneralized regrcssion analysis (SB2). g-w.Use salient difficulty here is with the unmatched t-test.Collect:vesare nested within centers, and no method of adjusting for SES can removeall the relevant differences among centers. Such differences do nottilsify the estimate of the treatment effect, but they unnecesarilvlower the power of the stati:,tical infereoce. The obvious wav to esclp('the problem is to use a matched t-test. Whether this i profitdbledcimmd- on'h, hetw,n-center,; vAriance in ar lusted Mrl. 180 the base for d.f. C-b.Use for collectives. WLC this with analysisof covariance by removing the variance for centers, and thenusing the Centers X Treatments interaction as an error termto evaluate the Treatment mean square, after covarying out SESon ofbbseems to address thequestion:If we were to search through a large number of collectives,disregarding center membership, and were to pair up selected A and Bcollectives so that each pair had the same SES mean, what difference inthe MRTcwould be expected? I say this, because using bbestimatesthe expected MRT for a collective regarding which one knows the SES meanand nothing else. So this method does not take pairing into account.It does not allow for variables relevant to Y, and orthogonal to Xon which centers differ, so it loses the value of the matching t-test.As forbo,it suffers as usual from being a composite of bbandbwthe b-regression and the w-regression. Ifbbis off the mark, so ish.Us;agbwseems to ask almost the right question. If we search 0through the pool of A and B children within a center, and select out two,:ets that have the same SES meaa, what mean difference in MRT would beexpected?That is, the analysis attempts to simulate the result in anexperiment where equivalent children within a center are assigned totrcAtment.The analyis, however, ignores the fact that A children1 9 0 8.17 were created in a group. If many collectives were formed from thechildren in the same center and given the Head Start treatment, the between-collectives-within-center-within-A regression need not be thesame as the regression within-collectives-within-center-within-A. Onemight waive the question of demographic differences (other than SES)between such hypothetical classes, but it seems that one must also assumeabsence of context effects to justify analysis C-o. If this argument iscorrect, then, one would need more than one A collective within a centerto arrive at the logically appropriate adjustment.The problem does notarise with B's, who were treated individually and could not have beensubject to a context effect. This meticulous dissection is required to work toward an understand-ing of analysis of covariance, but it does not cast serious doubt on theresults from WLC1, since the amount ofadjustment was small. Insofar asthat analysis is in question -- aside from the challenges any quasiexperi-ment is open to -- the question arises from the inhomogeneity ofregressions, which I deal with next. AlternaLive analyses, recognizing heterogeneity of regressions.In the analysis with homogeneous regressions, one finds out how far theA cases are ibove the reference regression line and how far the B casesare below it(or vice versa), combines those differences, and reaches anestimate of the treatment effect. One would have the same result if heformed the two within-treatment regressions (which ate parallel) and4letermined the distance between them. The u-\"al way of speakin aboutthe Analysis i; to speak of the \"intercept',\" v:here two regressionfine-; te(erence 1 9 1 8.18 think ofXas at the mean of the grand population. When the regressionlines are not parallel, the treatment effect is different at each valueofX.One can compare their intercepts at the grand mean, and manyinvestigators would do just that, to determine the effect of the ABdifference for the population of eligible children. SB chose instead todetermine the A - B difference where Xis at the mean of the A population,of children who were eligible and who entered. I accept this decisionat least for present purposes. The SB technique was to adjust scores of B chilnren only. The B'swere of higher SES than the A's, on average, so their MRT scores wereadjusted down, to get an estimate of what the B mean would have been ifthe B's had had an SES mean comparable to that of A children. If theB regression coefficient is s,and a B child is uSES units abovethe reference group of B's in SES, then his MRT score is lovered by suunits. An important choice is to be made regarding the reference group.The child is, let us say, in a center where the A mean on SES is 7(on no matter what scale), whereas the SES mean of all A's is 5.ihe child, Jet us say, has an SES of 7; do we take A's in his center asthe reference uoup and make a zero adjustment, or do we take all theas the reference group and reduce his MRT score by2s?It makesno ditterence in the final report of the treatment effect, but it doesiutlueme the variance. to ,how this,let us consider artificial data and assume an analysis h,.let us adiust the MRTe ind notindividual scores; the argu--,FTlf would have the -;,tme flavor if we Idinsted individuals or used another r, t.0t,)t`ft1 92 8.19 The simple data in Table 8.2 show bb = 1.0for B collectives. InCenter 1 the B mean on SES is 8, 3 units above the mean of all A cases;hence adjustment 1 is -3.0. The SES mean of 8 is just one unit abovethe A mean for that center, and adjustment 2 is -1.0. When the full setof computations is carried out, we see that the mean over centers for B'sis the same with either adjustment. The treatment effect changes from0 to 1 with either adjustment. But the variance of differences, whichprovides the error term in a matched t-test, is lower when adjustment 2is used.It seems to me that adjustment 2 is more appropriate thanadjustment 1, when matching within centers is intended. (Whether using bbis appropriate is another question.) It would be possible to set up categories D, E, F of regressionscorresponding to adjustment 1. This would be a pointless digression.Let me say only that as nearly as I can tell SB4,.which used 1)0,would be coded D-o,as counterpart of A-o,and SB6, which used bw ,would beD-w .With regard to adjustment 2, there is no point indetailing categories G and H, counterparts of A and B; let us considerjust the category that has the proper d.f. (counterpart of C). I.Number of centers as the base for d.f. I-b.Use ofbb.Regression of MRT for B collectives on SES cis determined, and MRT cfor B's in a particular center is adjusted according to the discrepancy of their SESc from thatof A's in the center. Matched t-eest is entered with themean MRTcof A's and the adjusted MRT cof B's (SB5). 1-w.Use ofbw.Similar to I-b I-o.Use ofb.Similar to 1-b, using bo 193 8.20 Once more we face the question, which regression? It seems to methat usingbwis wholly appropriate. B's were treated individually,and they were identified individually within centers.Hence one wishesto estimate the probable MRT score for individual children within acenter who have a particular SES mean. I can see no way in whichbetween-center differences among children (which enter the other tworegression coefficients) become relevant to a within-center adjustment.Although analysis I-w, which I favor, came to light becauseregressions were heterogeneous, I believe it also would be justifiedif corresponding regressions had happened to be homogeneous. It willbe recalled that the regression coefficient required to recognize the grouping ofA cases could not be evaluated. The Head Start design, with one treat-ment given individually and the other treatment given to groups, treatmentsbeing crossed with primary sampling units, is highly exceptional. Thegeneral conclusion is not that some analysis is generally to berecommended but that any investigator proposing to use ancova onDesign 2 must reason carefully to settle upon the proper analysis. VJ I Notes 88.21 Notes for Section 8p. 8.81Sincewe calculated from the adjusted scores, the computer printout p. 8.14showed 370 d.f. ,and a higher F.Taking the number of degrees offreedom as 1, 369, the F ratio is significant at the .01 level. 2This could be called bt'comparable to the tof Section 3. 195 9.1 9.Multivariate considerations In the course of this project we made several multivariate analyses.andgained some experience in thinking about the decomposition ofmultivariate relations. I shall discuss those materials only selectivelyand briefly, since consensus regarding univariate analysis needs to develop beforewe try to resolVe multivariate issues. Simple correlations Since Robinson and Yule and Kendall, it has been recognized thatcorrelations change in going from the aggregate to the individual. I aminterested in a comparison across and within groups, whereas previouswriterscontrasted correlations across groups with correlationsacross individuals regardless of group.The kind of issue that arises for the psychologist can be seen if weconsider convergent and divergent thinking. A good many investigatorshave argued about the degree to which these are correlated, and correlationsranging from zero to fairly large positive values have been reported. Thosecorrelations have typically been calculated by measuring schoolchildren in anumber of classes and pooling all cases.It is reasonable to suppose thatthe classroom can have an effect on the level of divergent thinking (D) forchildren who stand at the same point on convergent thinking (C); Torranceand others expect certain tactics of teachers to inhibit divergent thinking.If the teacher's effect on D is uniform over the range of D,and unrelated to the class mean onbC(w)D,willPexceed aDC(b).The overall regression coefficient will fall between them.The three correlations will similarly be discrepant. It would appear, then,196 9.2 that an attempt to sort out within- and between-groups relations is necessaryto pursue any argument about the structure of abilities. However, thewithin and between relations differ because of demographic effects when groupmembership has no causal consequences. Computing separate correlations orregressions adds information but leaves interpretation equivocal.Correlations of reading outcomes. In exploring the CooperativeReading data our eyes were caught by the correlations between subtests ofthe Stanford Achievement Test within the LE and B treatments. In theconventional correlation matrix (over all individuals) the correlations of Spelling with other subtests were conspicuously lower in the B treatment.This 'could be of subbtantive interest. The LE program is, on its face, amore integrated approach to language and as such would perhaps generate higher correlations among outcomes than the Basal method.do The obvious next step was to decompose the correlations. A typical set ofvalues is that relating Spelling to Word Reading; Within LEWithin BConventional 0.760.54Between-classes 0.900.83Within-classes 0.610.39 This result, and seemed to indicate that the treatment chieflyaffected within-classes correlations. The fact that between-classes correlations were consistently large is also of interest. Althoughcorrelations of aggregates often are large, it would be possible forteachers to sTary the proportionate emphasis they give to different outcomes,and it so the between-groups correlations would fall off. 197 9.3 Correlations are affected by variances, and if the groups wereselected differently in the two treatments, or moved farther apart inone treatmenc than another, this could account for differences incorrelations. In fact, the within-classes variames proved to be muchthe same across treatments in all subtests except Spelling. In Spelling,the within-classes variance for B was more than double that for LE. Thismay be an important substantive finding, and one that is less strikingin the conventional analysis. Here is the full set of variances: Reading SpellingWith:. LEWithin BWithin LEWithin n 20.460.340.550.32 The higher intraclass correlations for LE are consistent with the somewhathigher intraclass for LE on the Pintner pretest (0.37 ys. 0.23).We regressed Reading on Spelling and Spelling on Reading, obtainingthese coefficients: Reading on Spelling Spelling on ReadingWithin LEWithin BWithin LEWithin B Between classes 1.060.840.810.82Within classes 0.840.380.470.40 The one clear finding is that between-classes regression slopes areconsiderably larger than within-clasFRs slopes.Similar discrepancies were.found for other pairs of variables. This finding is not, I think, to be 198 9.4 dismissed as a consequence of greater measurement error in the individualscores.Rather, it is a statement that between-class differences in measured achievement are highly stable across outcomes in these elementaryschools.Perhaps a part of the higher relation arises from conditions oftest administration; correlated errors due to high or low group moralewould make the regression steeper. More likely, the crucial fact is thatindividual patterns of difficulty -- the good reader who is weak inspelling and his opposite -- lower the within-class correlation butbalance out over the class. Between-class differences in one subject would not be predictable from differences in another if there were a strong tendency for one teacher to put more emphasis on Reading(relative to Spelling) than the next teacher, or to have greatersuccess in teaching one subject than another.One might, as he prefers, emphasize the similarity of the Spelling-'on-Reading regressions across treatments or the dissimilarity of theReading-on-Spelling regressions. The proper conclusionappears to be that (at least in the samples) the within-groups jointdistribution in B is d4stinctly different from that in LE, the formerhaving a much greater dispersion. Another way of summarizing the sameinformation is to emphasize the difference in n 2(greater in LE for both variables).Since(perhaps fortuitously) n2 on the Pintner pretest wasgreater for LE, interpretation must be left open.The methodological moral of this exercise is that correlations amongvariables may be calculated within and between groups, but should not beinterpreted by themselves. The information of importance is contained inthe joint distribution of X,Y means and of X,Y deviations expressed in aunitorm K metric and a uniform Y metric. Assuming that all distributions 19 9 9.5are normal, three parameters describe each distribution shape (and twoparameters describe location). Correlations are derived from standardizedmeasures, and the standardization of a variable is different for eachdistribution; contrasts are invariably distorted.For similar reasons, use of unstandardized path coefficientsgenerally is recommended. Because a direction of relationships has beenpostulated, interpretation is simpler than in the Reading-versus-Spellingexample.Path coefficients have often been calculated from disaggregateddata.It appears advisable to partition the structural regressions, making between-groups and within-groups analyses, despite the probableequivocality of the findings. (See also p. 9.23.) The comments made here apply to Harnqvist's analysis of relationsoutcomes in the Tnternational siudy, mentioned on p. 2.12. He not onlyshows some striking differences among correlations at the individual andaggregate levels but makes the suggestion that the disaggregated correlationsbe recomputed for individuals within schools and schools within countries.He sees the lines he has opened up as dealing with some highly significantsubstantive questions. If my reasoning above is correct, the correlationsought to be supplemented by the pertinent variances, to give a sense ofthe joint distributions. Only this can give the reader a basis for interprelation. 200 9.6 Component analysis and factor analysis Variables are reorganized into components or factors for three purposes: (1) Orthogonalization. Even if all the information from the original variablesis retained in the orthogonal variables, it is often easier to carry outcalculations and to make plots and summary statements in terms of orthogonal components.The simplest case of this kind of simplification is the changeof variables X and Y to the set X and YX, the latter being a partial variate. (2) Rank reduction. There is redundancy in almost any set of variables, andthe set can perhaps be compressed to fewer variables without much loss of information.Use of a limited number of components or factors simplifies,and relationships involving fewer variables will often crossvalidate in new samples better than relations fitted to a large number of variables.This is why minor factors or components are ordinarily discarded. (3) Identification of constructs. The purpose of rank reduction is toarrive at simple, stable empirical statements. The purpose of rotation ofthe factor set is to arrive at simple, stable descriptive or theoretical propositions.Those who rotate a set of such variables are searching forwhet are often called \"underlying dimensions\". Perhaps it is better tothink of these as constructs, as working hypotheses regarding variablesthat can be used to formulate a satisfying theoretical network. If agood set of variables is found, relationships can be summarized in sentencesthat are comparatively simple, in the sense that each proposition employsonly a few constructs in the set -- even though all the constructs areimportant enough to enter some sentences. (The reader may recognize Thurstone's concept of simple structure as an illustration of this desideratum.)2 \" 1 9.7 The partial variate Y-X is defined asYOyxX.Since we have seenthat the regression coefficients from between, within, and overall analysesdiffer, three distinct partial variates will be formed by them.The YXformed in an overall analysis will not ordinarily be uncorrelated with Xeither within groups or between groups.More generally, a variable setthat is mutually orthogonal in one of the three analyses will almost certainlynot be oithogonal in the other two. 1Insofar as an investigator is primarilyinterested in orthogonaliz tion, then, he may need separate orthogonaliza-tions for the betweer- and within-groups segments of the data. As aminimum, he must decide which set of intercorrelations he wishes to reduceto zero. A similar comment is to be made regarding rank reduction. When thefirst nfdimensions from a larger set of nvvariables are retained and theremaining information discarded, this process will discard a fraction of thebetween-group infonnation and a fraction of the within-group information.Those two fractions may differ in amount and in character. Suppose thatthe analysis is made within groups, and the first three factors retained.Those factors may account for 80 per cent of the total variance within groupson all variables; they may account for 92 percent of the total variancebetween groups, or 70 per cent.When an overall analysis is carried out,the first component may arise largely from between-groups variance, orlargely from within-groups variance, or from a mixture of the two in anyproportion.The same is true of each later component.It is unlikely thatseveral successive factors would arise from the same single source, unlessthe groups were formed at random and the between-groups information isnothing but uoise. The practical implication is that a person who reduceshis data on the basis of a single factor analysis at any one of the threelevels retains the major fraction of the information at that level, while202 9.8 perhaps discarding a signiticant fraction of the information at one ofthe other levels. Where rank reduction is the aim, it is important toexamine separately the within-group and between-group residual covariancesor correlations, to make certain that they are negligible.The most intriguing problems arise in the attempt to establishconstructs on the basis of factor analysis. As was said earlier, variablesthat have the same operational definition may have different substantiveinterpretations at the individual and the aggregate levels. A factor is aweighted composite of observables (or variables that are in principleobservable), hence the preceding statement applies to any factor. A compositethat enters into simple between-groups relationships may have quite differentrelationships with corresponding individual-Jevel variables (within groupsor overall).The person using factor analysis as a tool in theory construc-tion, then, will need one set of factors for his between-groups theory andanother set of factors for his within-groups theory.To be sure, he mayfind that the two sets of constructS coincide, but that is a possibility tobe evaluated, not assumed. Discriminant analysis is the one context where separate multivariatedecompositions have often been made within groups and between groups.Discriminant analysis is an attempt to describe differences between groupsin terms of one or a few variables. In Fisher's famous example of twospecies of iris, a number of physical measurements were made on many specimenscf each species. (More than two species could have been investigated.) Theanalysis reduced the measures to two composites which were sufficient toclassify plants into the two populations with few errors. The firstdiscriminant function is whatever composite has the largest intraclasscorrelation.Thc second is whatever composite of the remaining informationhas the largest intraclass correlation. And so on.As a first step in the 203 9.9 analytic procedure, the within-groups variance-covariance matrix isfactored into orthogonal components and these are standardized (within groups).A consequence of this standardization is that when any dimension is partialledout (as in going from the first discrtminant function to calculation of thesecond), the multivariate distribution of residuals can again be describedby orthogonal variables with unit variance. The means of the groups on thecomponents are formed, and the first principal component of the between-groupscovariances becomes the first discriminant function. Successive principalcomponents become successive discriminant functions. The first two or morediscriminant functions can be rotated if that is thought to give a more\"meaningful\" description of group differences. In the study of irises orother similar pools, the rotated discriminants might suggest somethingabout the character of the genotypic differences between species.A rather large number of factor analyses of aggregate data have beenmade.R. B. Cattell (1949, 1952) suggested that a group has a \"syntali-r_y\"analogous to the personality of an individual, and he paralleled his studiesof dimensions of individual differences with some factor analyses of groupdifferences.For other summaries or discussions of aggregate-level factoranalyses, see Janson, 1969; Cartwright, 1969; and Tryon and Bailey, 1970.So far as I know, only Slatin (1974) has carried out factorizations of thesame data at two levels. I discuss his study below.Whether an investigator should want factors for between-groups andwithin-groups variance is a subtle decision; in some contexts, factorsfrom an overall analysis are no doubt appropriate. When groups were formedby aggregation rules that are irrelevant to the matter at issue, thebetween-groups factors that reflect those rules will be of no importance.In Fisher's study, on the other hand, the aggregation represented a judgment 204 9.10 that two pools of plants were distinct biologically. Therefore the pooled set of individuals represented an arbitrary mingling of between- anti within-gloups information. The causes of variation between groups were probablynot the causes within groups, and the structure might well have differedfrom one group to another. The psychologist has most often regardedeffects as strictly individual. Even Cattell, in his studies of individualtraits, has analyzed overall correlation matrices, ignoring groups. Thismay be appropriate in some circumstances but probably not in all. If it istrue that teachers affect scores on divergent thinking or spelling, to mixclass-level differences into a study of individual differences gives usindirect and clouded information about individual growth in ability patterns.On the other hand, to use within-groups information as the basis for similarconclusions is a dubious practice, insofar as arbitrary or irrelevantassignment rules restricted the range on some variables and modified theintercorrelations. We move now to an illustrative factorization of ability tests whichwill give some concreteness to what has been said. This set of data wasexamined some time ago, as an exploration. It was a poor choice from asubstantije point of view. The tests were given to first-graders early intheir school careers, and the between-group differences reflect neighborhood differences or rules for assigning children to classes rather than psycho-logical causes. The betwecn-group information is essentially a summaryof demogcaphic effects. Despite the likelihood that the overall analysisprobably answers the questions most likely to be asked about these data,much can be learned from the contrasts among the analyses. 0 52 9.11 Analysis of correlations. Miss Webb analyzed three correlation matrices (overall, between classes, within classes) for eight preteststhein Bond-Dykstra data, using a total of 1049 cases from the B and LEtreatments combined. (We had no reason to considertreatments separately.)Analyses were made with unity in the diagonal and also with estimatedcommunalities; no insight will be lost by discussing just the latter at this point.Thefirst fact of interest is the high degree of multicollinearity in the between-groups correlation matrix, so high that the communality for the 206 9,12 Pintner score was 0.99. (As a consequence, the computer's aitempt at varimax rotation produced a nonsensical result.) I rotated factors II and III in the within-grrtps analysis through 45\u00b0, to bring them morenearly into line with the corresponding factors of the other two analyses.Table 9.1 presents the factor loadings, communalities, and percentages of variance accounted for by the first three factors in each analysis. It will be noted thatthe communalities were considerably higher between groups thanEwithin groups, except for bCopying and bIdentical Formswhich had large unique factors. Correspondingly, the common factorsaccounted for a larger fraction of the between-groups variance than ofthe within-groups variance.The reader may plot the loadings for himself. He will see that thestructure in the conventional analysis corresponds far more closely to the between-dasses analysis than to the within-classes analysis. This istrue even though the intraclass correlations were only about 0.30 (see below).Factors I and II in the conventional and between-groups analysesplot out as a quasi-simplex. The order in which the tests string out isidentical except for the position of Listening. The within-classesanalysis produces a vdo-cluster configuration: wCopying, wIdentical Forms,and wPintner fall along one vector and the other five tests cluster on another. The table codes the tests differently in the three factor analyses toremind us that the between-classes and within-class R analyses look at 0 7 Table 9.1.Three factor-analyses of readiness measures Conventional Between classes 9.13 different vari les.bPintner is the class mean (standardized after averaging),and wPintner is the individual deviation from that mean (likewise standardized).Because of standardization, the Pintner variable of the conventional analysis equals n2bPintner2 (1 - n2)wP i intner, where n s the intraclass correlation for Pintner. Factorins covariances. The standardizing operation will distort. information.If a variable has a small intraclass correlation, it has a small between-classes variance yet it has as much \"weight\" in a between-classesfactor analysis of correlations as a variable with large variance. Conversely,a variable with little within-classes variance is given heavier weight inthe within-classes analysis when correlations are used. Our next step, then, was to partition the olrerall correlation matrix of the scores intobetween-groups an i-groups covariance matrices, and then to factorthose matrices.2 We started with correlations because there seemed to be no reason for weighting one variable differentlyfrom another in the overall analysis; one could, however, start withthe covariance of raw scores or of scores resealed in some preferred manner.Any such scaling decision affects which variables dominate the firstprincipal components of the overall analysis. Having begun with onesin the diagonal of the overall matrix, we had intraclass correlations 2 in the diagonal of the between-groups matrix and values of 1 -.nthe within-groups diagonal. In the between-classesanalysis, three factors accounted for79 per cent of the variance, and little variance remained to beaccounted for in subsequent factors. Therefore, Table 9.2 presentsonly the first three factors. 210 Table 9.2.Analysis of covariance matrices for readiness measures variance was extracted more slowly, and fivethefactors are retained. Neither the b nor w analysis was particularly closeto the overall analysis of covariances (not shown here); it couldbe described roughly as \"halfway between\" the two. The n2-,was particularly low for Listening, and particularly high forCopying.Possibly an explanation could be constructed from a search forceiling and floor effects or other anomalies; alternatively, the patterningcould reflect something about neighborhood characteristics. Since thechildren were tested near the start of the first grade, causal \"class\"effects are highly unlikely, except as irregular administration of testsaffected class standings.between-groupsThe three chief components of the covariance matrix are not much likethe first three components of the correlation matrix. (Some of this shiftcomes about because we decomposed the entire covariance,rather than just thecommon-factor portion as before.) The general factor runs over all testsabout equally, except for Listening and Identical Forms.Components bIIand bill are essentially sgecific to bCopying and bIdentical Forms.The within-groups analysis shows fairly strong common factors.Listening loads more heavily than in the between-groups analysis, becauseof its small intraclass correlation. The first factor within groups ispresent about equally in all measures. Rotation could bring out theconn2ction of wPintner with wCopying and the connection of wPhonemes with wLetter Naming, but the structure is not strongly patterned. 213 9.15 Slatir's analyses. Slatin (1974) factored 10 variables at the group andindividual levels. His data were measures of ability and family backgroundfor boys, plus two indices of property value for their neighborhoods. Hisaggregates were areal units, such that the 516 boys were successively clusteredinto 47, 21, and 10 areas. Slatin factored each of four correlation matrices,extracting and rotating three factors. He was impressed by the differencesbetween the factor structures, and suggests tentatively that a more sociological(more \"social\") explanation of phenomena will be reached when aggregate dataare factored than when individual data are factored.Our work perhaps sheds some light on Slatin's findings. The most strikingchange in going from the individual analysis to the aggregate analysis was ashift in loadings for Age. Pairing up the varimax-rotated factors of the fouranalyses, the loadings for Age are516 tndividuals -.22-.1047 smallest areas .03-.7421 medium areas -.19-.9210 largest areas -.24-.95Factor I is an ability factor and the chief markers for II, other than age,represent neighborhood wealth or father's status. Age had a much lowerintraclass correlation than several other variables (Slatin, 1969), and hence,when variableswere restandardized, tiny and fortuitous covariances acrossgroups were inflated to the point of making Agea powerful influence in theaggregate-level analyses. (One covariance of about 0.03, I estimate, wasinflated into a correlation of 0.72.)If covariances had been analyzedinstead, the analyses at successive levels would have changed onlygradually.At the individual level, there is a near-simplex running throughthe ability measures, then around to lot size and value of dwelling unit (DU).(Age and Delinquency have such low correlations that they (10 not enter thesimplex.)Much the same simplex appeared in the aggregate covariance matrices.214 9.16 If covariances had been factored, I believe that the only change would havebeen a reduction of the spread of the vectors; at the highest level ofaggregation IQ and DU correlated 0.67. It might have been wise for Slatin to have examined factors within aggregates.The relation of individual characteristics after neighborhood is held constantmight be the best way to briag more purely psychological relations to thesurface.But it might be equally interesting to decompose \"upward\", factoringvalues of Tir.-Xto see what \"social\" factors might appear after the individualinformation was removed. Suggestions.hInsofar as investigators seek only to replace original variables with asmaller number of composites that carry most of the differential information,no serious problems arise. There is no reason to try to establish homologybetween factors at various levels, and one will of course factor at whicheverlevel he is interested in. His only major decision will be whether tostandardize variables at that level or to use some other metric.It is when factors are to be regarded as constructs that interpretationbecomes awkward. It is unreasonable tc expect homology. If only for statisticalreasons, different results are likely to appear at the between-groups and 215 9.17 within-groups levels. The grouping variables that modify the regressioncoefficients (as shown in Section 4) also modify the covariances, even whenno causal effects are associated with the groups.Beyond this, however,original variables take on different meanings when aggregated. They can beexpected to cluster differently, with the consequence that different constructswill be appropriate between and within groups. Let us consider total yieldsof wheat and potatoes (rather than per-acre yields). More agriculturalcounties will have larger yields of both potatoes and wheat. But withincounties the farmer decides whether to plant potatoes or wheat, so the twoyields may be negatively correlated at the level of the farm. In some problemsit may make sense to track down just this patterning; in other problemswhere group boundaries seem to have little causal significance an overallanalysis will suffice. Brunswik's \"ecological\" ideas will help in interpretation. Any resultobtained from a sample of persons is also representative of the sample ofsubecologies in which their behavior developed.If one samples groups andmeasures everyone in those groups, the correlational information is a state-ment about the distribution of behavior within and between groups, hencewithin and between subecologies. The results generalize over the populationof groups sampled. When sampling is at the individual level, perhaps from acensus roster, the result holds for persons who have grown up in a culture,distributed over its subecologies. The only difference from the study wheregroups were sampled is that with individual sampling there are too few personsfrom any one subecology to warrant examining its specific characteristics.From this point of view, then, the overall correlation describes an ecologyin the large, the between-groups correlationcontrasts subecologies withinthat ecology, and within-groups correlation describes typical relations 2I0 9.18 within subecologies. The factor analyst who intends to study a purely psychological question about the distribution and covariation of abilitiesis inevitably reporting on a phenomenon that is cultural, demographic, and sociological in part. The overall covariance being a composite of between-groups and within-groups covariances, the adequacy of the overall data depends on the adequacy of the data at the two levels. Our Bond-Dykstra analysis used 1049 cases, and thatis ordinarily enough to satisfy any factor analyst. But the information forthe important between-groups portion of the covariance comes from a sample of 57 classes.Few would consider 57 cases a sufficient sample for a factor analysis.If we assume substantial homogeneity of relations within the severalclasses -- which is probably necessary if a within-classes factor analysis isto be taken seriously -- then the within-groups covariances are well establishedwhen 50-odd classes are pooled. Yet insofar as Table 9.1 is representative,the overall analysis that has conventionally been made rests far more on thefallible between-groups covariances. Now if within-class relations are nothomogeneous, the whole analysis is suspect. The pooled-within-class analysishas uncertain meaning, and its stability is a function of the number ofclasses, not the number of individuals. The case for considering separately the between and within factoranalyses is especially impressive when we move out of the ability domain. An example is the Learning Environment Inventory (LEI) developed b Y G. J. Andersonand Walberg(1974) within Harvard Project Physics. This is a collection of items describing instructional procedure and student attitudes; the student responds so as to report how he perceives his class. Items have been 2 1 7 9.19 assembled into scales on the basis of their intercorrelations, and the scaleshave been factor-analyzed. Insofar as correlations arise simply from semanticoverlap of items, one would expect similar joint-distribution shapes withinand between classes. But the correlational structure, insofar as it reflectspsychological differences, may be quite different. Within the class, thecorrelation reflects the correspondence of perceptions. Are the studentsmost prone to describe the class as \"apathetic\" also the ones prone todescribe it as \"difficult\"? Across classes the correlation speaks of adifferent phenomenon: When the students collectively describe the class as\"difficult\", do they also describe it as \"apathetic\"? The former refers tothe phenomenology of the student, compared to other students rating the sameevents.The latter refers to behavioral differences between classes (thoughsome of those differences are perceptual rather than objective). The purpose of the LEI is to identify differences among classrooms. Forit, then, studies of scale homogeneity or scale intercorrelation should becarried out with the classroom group as unit of analysis. Studying individualsas perceivers within classrooms could be interesting, but is a problem quiteseparate from the measurement of environments. of unitsEmpirical test construction. Once thequestionrs raised, all empiricaltest construction and item-analysis proceduas need to be reconsidered. Is itbetter to retain items that correlate across classes? or items that correlatewithin classes? A correlation based on deviation scores within classes indicatesstudentswhether students who comprehended one point better than mostpalso comprehendedthe second point better than most -- instruction being held constant. Acorrelation between classes indicates whether a class that learned one thing learned another, but this depends first and foremost on what teachers assignedand emphasized. It is the items that teachers give different weight to218 9.20 that have the greatest variance across classes. If some teachers work hard toteachuse of the semicolon and others consider it unimportant, the semicolonitems will correlate comparatively high over classes.If teachers who careabout semicolons may or may not care about colons, a low across-classescorrelation between s,emicolon and colon items is to be expected. This leadsus to regard the between-group and within-group correlations of items asconveying different information, and makes the overall correlation forclasses pooled an uninterpretable blend. Multiple regression and ielated techniquesA school-effects model. It makes sense to consider two or more measureson the individual or the collective for many purposes. A simple school-effectsstudy might include Xi = family background, X2 = ability of teachers, and Y =student achievement. Suppose that data in just one community will be examined.It appears best to identify the X2 of the student's own teacher.A conven-tional analysis might evaluate (9.1) y=1.2Xlp+ a2.1 A more sophisticated individual-level analysis fact that the predictors -- especially Xlsand X2s-- tend to becorrelated creates difficulties of interpretatior. The difficulties areexacerbated by the fact that the number of schools is small.Consequently, Is, 2sis likely to vary considerably from community to community.Thisis a fact about iota: affairs, acceptable enough in considering fixed schoolsin a fixed community. If communities are compared or an attPmpt is made togeneralize over communities, it is highly likely that the a that one wishes219 9.21to interpret will be much affected by the value of p.Particularly if p ls, 2s is large, the 1331244-123and Bcan be compared only at considerable risk. It -is not at all unlikely that their balance would shift in another year in thesame community even if pls, 2sdoes not change. A decomposition seems to require aggregation at the class level () aswell as the school level (s). In place of (9.2) we have three equations: (9.3)Ys=s1-2Xls+ 0Xs2-1 2s (9.4)yyS=ac1.2(Xlc-Xls) + 0c2-1(X2c-X2s) c (9.5)pCY8p1-2(X1p-X1c) 8p2-1(X2p-X2c) Assume that all definitions of parameters take number of students into account.What is here written as 0s1-2could be writtenYls.2s;in the notation of (9.2)it would be 03-4-- with no partialling of 1 and 2. The last termin (9.5) isentered pro forma. Teacher quality X2c cannot be disaggregated, henceX2p= X2cand the term vanishes. A global school quality would vanish fromc and p equations. 3The sums of squares from (9.4) and (9.5) can be combinedinto components of the within-schools SS.The correlation 0 1s2sis now relevant only to (9.3).The problemof allocating variance between two correlated predictors(p.2.17) arises atthe school levels, but 0applies to and 0 '1s2s '1c2c to the other.In general, ofcourse, interpretation of an equation at thewithin-class level takes p1p2pinto account.The important point to remember here is that Band13p1-2 's1-2' ac1-2'are coefficients for different predictors, predicting different outcomes.Tho overall analysis of (9.1) evaluates only two out of five parameters; eventhe analysis with added contextual variables leaves the components entangled.From an explanatory point of viewa single equation fitted to theecologyprovides lessinformation than the set of equations.220 9.22 Partialling.A multiple-regression equation gives regression weightsfor one variable with others held constant. A partial correlation relatestwo residualized variables. What usually goes unrecognized is that thevariable carrying the same label becomes an operationally different variableat each level of aggregation. If we formYc.Xc at the aggregate level forsome group c, that value will rarely equal the average for c of theY.Xformed by partialling at the individual level.Hgrnqvist (1975, p. 102) reports partial correlations (at the end ofsecondary school) for achievement in literature with achievewent in sciencewith reading comprehension held constant: IranEnglandIndividual level 0.25-0.13School level 0.36-0.60This is certainly of interest, as a kind of documentation for the \"two cultures\"stereotype of British education. Where vie must be cautious is in believingthat the same pair of variables has been correlated in each instance. Thevariables may be denoted (with some notation that should be transparent) asL - b1RdandSz- b2Rd.But bothb1orb2take on a new definition anda new numerical value in each cell, as follows: btIbtE bbIbbE It seems to me highly dangerous to compare variables across levels andacross collectives when the operational definitions shift. To argue thatthe several operations represent the same construct seems to entail an enormous 221 9.23 burden of proof; in one contoxt reading may be a proxy for individual SESand in the next context it may be more a proxy for global school quality.This argument applies obviously to path analyses, since most of theirpredictors are partial variates.I can make only one recommendation and it is no more than a palliative.Recall that in the Anderson reanalysis (p. 5.8) Webb and I defined avariable ABIL = ABILITY 0.47 PRECOM; where 0.47 was the overall regressioncoefficient of ABILITY on PRECOM (within treatments pooled). We entered thisvariable in the within-collectives and between-collectives analyses.Thecorrelation of ABIL with PRECOM in each of these analyses was close enoughto zero that we were able to reach interpretations; we did not have a mind-boggling shift in definition. I speak of this procedure as a palliativebecause one is not guaranteed that in each subset of the data the variableso formed will have a low correlation with the variable whose contributionwas adjusted downward. inble 9.3.Zero-order and multiple regression coefficients for Head Start classes at two levels of aggregation,with Metropolitan Readiness Test as dependent variable POPEDPOPINCPOPOCCNKIDSBetween centersZero-order 3.476.066.720.72Multiple equations given by Smith and Bissell, two ofwhich appear in Table 9.3, are further evidence on the same point. Thebetween-centemequation tells a quite different story, on its surface, thanthe within-centers equation does. All variables contribute to the formerequation; within centers, only POPED has a la-.-ge weight. (All variables hadbeen rescaled to similar metrics.) Some of the disparities are explainablein terms of the zero-order coefficients, but the shift in NKIDS is not. Thedifficulty lies in the fact that the weight is for \"NKIDS with the otherthree variables partialled out\". Since the correlations among predictorschanged from one level to another, the partial variates are radicallydifferent in their definitions from one analysis to the other.Disparities such as these (including disparities across treatments)cqused no difficulty for Smith and Bissell, since they were not attemptinga causal interpretation of regression weights. Sociologistoften do attemptsuch interpretations, huwever. Some set of operationally definedquasiorthogonal composites would appear to be necessary for any comparisonof regression coeffici.ents across levels or across treatments. One mightbe wiser to examine zero-order regression coefficients for such compositesthan to use multiple regression, but path analysis calls for multiple regression. 223 9.9i Notes for Section 9p. 9.7 1Duncan et al. (1969, p. 54) establish the following relationship: p. 9.13 p. 9.212 2 1/2rt= (nxny)rb+ [(1nx)(1ny)1rw 2A note on procedures may be helpful some readers. TheSPSS programs \"do not accept\" covariance matrices, but for correlation matrices apply to covarianCe matrices,we fooled the computer into thinking it was analyzing correlations.We entered the between-groups matrix with ones in the diagonal,used an option in the program to instruct the computer that the\"estimated communalities\" were the vector of n2, and called for aprincipal-factor analysis with those communalities. The result was aprincipal-components solution for the between-groups covariance matrix.The same method was used for the within-groups matrix, with the vectorof1 - n2. 3I noted earlier that product terms can be added, particularly toenter global variables in lower-level equations. Thus (9.5) could become^(9.5a)YYal(xlp-Xlc) aplc2(Xlp-Xlc)x2c predictors are uncorrelated. A positiveplc2implies that theabler teacher is associated with a steeper Y-on-X regression within theclass.Even though analysis is based on individuals it is the number ofteachers that regulates the sampling error of this coefficient. 224 10.1 10.The Road AheadThis report has been chiefly concerned with educational research inwhich data are collected on students with classrooms or on classes withindistricts.The difficulties noted in a great variety of commonplace studies(Table 10.1) imply a need for new strategies of design and interpretation.It is not clear to me just which of those difficulties will troubleinvestigators in other fields -- for example, students of votingbehavior or of reference-group theory; my impression is that their difficultiesinclude those treated here plus additional ones.I started with a concern for a somewhat specialized kind of research,the study of Aptitude X Treatment interaction. That kind of inquiry has inthe past examined overall regressions of outcOme on aptitude for pools ofstudents assembled from many classes.According to the analysis here, nomeaningful question is being asked about interactions in group instructionunless between-group and within-group regressions are considered separately.The implications of my explorations extend far beyond the studies of inter-actions, however. Every educational or sociological study that attends directly to regressioncoefficients and correlations, including studies using structural-equationmodels, must be thought through in the light of the argument I have presented.Sometimes a traditional analysis looking only at overall relationships orbetween-group relationships will prove to be adequate for the purposes of theinvestigation. More often, I suspect, the.investigator will find that a morecomplex decomposition will add to his store of information. But it will alsomake him painfully sensitive to the vagaries of results -- no matter howanalyzed -- when only a limited number of groups are sampled.And it beginsto appear that even the best of analyses will leave the causal interpretation 225 at iu.i Table 10.1.Kinds of investigation within education, psychologyand sociology where difficulties have been identified Page reference in this report Analysis of covariance Aptitude x Treatment interaction Attenuation, correction 8.11 ff.Factor analysis and component analysis 9.6 ff.Item analysis in test construction 9.19Multiple regression 1.7, 9.20Partial correlation 9.22Path analysis 2.19, 3.17, 9.24Placement rules, development of 2.8Predicting scores aggregates 1.12, 4.9Regression, comparing across levels 1.3a, 2.17 ff., 9.20Social-area analysis 1.23 10.2 of results equivocal, unless assignment to groups was under the control ofthe investigator. For the most part, I have made the following assumptions: 1.Every member participates in just one collective at the nexthigher level. 2. .At successive levels of aggregation collectives.are completelynested. 3.Aggregates at the highest level are random and membership atlower levels is fixed. 4.A member has no direct effect on scores of a collective towhich he does not belong. 5.Data are complete at the lowest level of disaggregation. 6.There is a known causal order, X preceding Y.The chief difficulties identified in educational studies that fitthese assumptions are as follows: 1.There is no warrant for direct generalization from groupsformed in one way to groups assembled in some other manner.This requires revision of previous thinking about the classifica-tion of students on the basis of aptitude (Cronbach & Gleser, 1957; Cronbach &Snow, 1976).An investigator who applies a treatment to a number of individualsseparately will identify a certain regression of outcome on aptitude, and maydevise a selection rule so that only promising individuals will receive thetreatment in the future. If there are two treatments, he may devise a classi-fication rule for deciding which treatment an individual is to receive. Theserules are a suitable basis for future decisions if individuals from the samepopulation are to be treated individually. If they are to be assembled intoinstructional groups, however, the overall regression of outcome on aptitude227 10.3 need not be the same as before; moreover, the possibility of distinct within- and between-group relations should be taken into account in the decision rule.The policy based on the individual-level investigation provides only atentative hypothesis about group-level instruction. The same argument appliesif the original study uses group instruction. If the initial groups 4reassembled by a certain rule, the findings apply to future groups formed inthe same manner. If future groups are formed in a different way, the oldconclusions do not apply directly. In the short run, it appears necessaryto insist on fresh validation research when persons are taught (or carry outtasks) in groups and the basis for forming groups is modified. In the longrun, studies of groups formed in different ways might develop a theory thatwould permit reasonable predictions about kinds of groups that have not beendirectly investigated. 2.Most experimental studies carried out in classrooms have beenanalyzed by means of \"individual level\" (overall) statistics, with classes ignored.The between-groups regression of outcome on aptitude is likely todiffer from that within groups; the overall analysis combines the two kindsof relationship into a composite that is rarely of substantive interest.Individual-level analysis may be undertaken as adeliberate choice. Analysis of pooled individual data is warranted when: a)The investigator (as in much survey research) is interestedwho are in a composite description of individuals mixed into groups in the populationas they are in the sample, and not in a causal interpretation of group-related effects; or b)The investigator is prepared to assume that any causal effectsassociated with group membership are trivial in magnitude; or, c)Known conditions of group formation make the overall statistic a comparatively efficient estimator of a between-groups parameter. 10.4 3.A conscious decision, rooted in the theoretical background orthe practicalcontext of the investigation, is requir'ed'to identify theappropriate units for sampling, assignment to treatment, and analysis. Thisis true in factor analysis, item analysis and empirical keying of tests,prediction of scores for lower-level units, etc.An between-groups analysis, and a within-groups analysis address substantivelydifferent questions and usually give different results.4.When analysis of covariance is used to compare instructionaltreatments, and data have been collected by using an intact collective (e.g., the school) as the primary sampling unit and the unit of assignment,the theoretically appropriate adjustment appears to be that given by theregression coefficient across such collectives (perhaps within blocks).In non-randomexperiments, analysis at some other level may give a consider-ably different estimate of the adjusted treatment effect. To determine a between-classes or a between-schools regressioncoefficient with reasonable precision one must have a much larger sample ofsuch units than is normally available to the experimenter. Consequently,his adjustment may be heavily influenced by sampling errors. 5.In the study of aptitude-treatment interactions, particularinterest attached to the between-classes regression coefficient, becauseinstructional treatments will most often be assigned to whole classes.Ashas been said, it is rarely practical to determine such a regressioncoefficient with precision. This fact, together with the hazard in generalizing to groups formed by newassembly rules, seems to discourage altogether a sheer empirical search forATI in classroom instruction.229 10.5 6., For the within-groups coefficient, the sampling error dependson the number of classes and the variability of the specific within-groupscoefficients.The customary manner of examining such sampling errors ignoresthat variability. Sometimes the estimate of the pooled within-groupscoefficient will be undependable even though hundreds of individuals provide data. 7.No secure causal interpretation can be given to the between-groupsregression coefficient, the within-groups coefficient, or \"context effects\" and \"school effects\"that have been made in the past are not defensible. At least three causal processes may affect regression slopes: directeffects of the individual's characteristics on his performance, competitive effects or other differentiation of experience arising from the heterogeneity of individuals within groups, and processes that raise or lower the outcomesfor groups with high (low) standing on the predictor variable. The firsttwo of these are confounded in the between-groups coefficient, and the lattertwo affect the within-groups coefficient. There is no direct way, then, toevaluate the magnitudes of the three effects from the two observed coefficients(especially as the two components affecting a regression coefficient may workin opposite directions). 8.Even when only strictly individual causes operate, the between-groups and within-groups regression coefficients will generally differ from thatcalculated for individuals pooled, because of demographic differencesamong the groups. These differences may reflect social processes,or aggre-gation rules of the data collector. This creates great ambiguities ininterpreting differences between parameters at two levels of aggregation, ordifferences between parameters for Odo treatment populations that wereaggregated into groups by different rules. 230 10.6 9.Studies of regression coefficients, and analyses of covariancein which regression coefficients play a part, cannot be soundly interpretedwithout due consideration of errors of observation of the predictor variable.Direct comparison of an observed between-groups regression coefficient withan observed within-groups coefficient is surely unsound. Observed regressioncoefficients will not be patterned like the coefficients for universe scores;yet the latter are of more fundamental interest.Contrary to the usualbelief, group-level information will not necessarily have a smaller standarderror and a smaller coefficient of generalizability than information onindividuals within groups. The information that would be required to evaluate thereliability (generalizability) of group-level data has not been collectedin studies to date. Indeed, the theory for such studies has barely begunto evolve.Yet -- let me repeat -- without proper disattenuation onearrives at incorrect answers to the kinds of questions educational researchworkers and sociologists have been trying to study. Sweeping recommendations cannot be made because of our present ignoranceand because tactics must be suited to each substantive problem.The followingsuggestions are derived in part from what others have written. 1.There should be a deliberate attempt to conceptualize the processesoperating when persons are treated in groups or hierarchical structures formedon a certain basis. Once a process is postulated one can hope to suggestindicators of intermediate events that will give information on the strengthof the process. Such more complete specification of the modeluill berequired to get data that warrant causal interpretation.231 10.7 2.The process by which individuals are assigned to (or voluntarily enter)groups should be specified as fully as possible. In general, when groupmembership is under full control of an investigator -- whether he uses arandom process or groups persons having specified characteristics --interpretation of findings will be freed of many of the uncertainties thatarise with self-selected groups. Where the collectives already exist, there should be a careful descriptionof the way collectives differ. These discriminating, variables-are-a-part-of -the causal process by which group effects are generated, and they may createnoncausal relationships at the group level. 3.Some amount of direct experimentation on coatext effects should becarried out, to supplement and lend supporting insight to the correlationalstudies under field conditions. It should be instructive, for example, toinvestigate how learning differs, cognitively and affectively, when personswork alone and when similar persons work in a group composed in one oranother manner. To experimentally disentangle effects of group composition,of group differences in the treatment delivered, of within-group differencesin experiences, and of individual differences properly speaking would informboth methodologists and theorists. Such studies will necessarily be limitedin time and size, and cannot answer questions about cumulative effects ofgroup experience. 4.In an experiment or survey, it would often be advisable at the firststage of sampling to select units it the highest level at which 'causal processes of interest operate.tn an experiment,it is those units that should be assigned to treatment.Thus, in a study of school desegregation, it seems reasonable to take thecommunity as the sampling unit.This is true not only because desegregation 232 iu.8 plans are typically district-wide but also because the attitudes of patronsin one school are likely to influence their fellow townspeople. An exceptionto this largest-unit principle is noted for static descriptive studies suchas public-opinion polls; if the interest is only in the population averageor some similar statistic, conventional sampling of small units is efficient.Another qualification: In contrasting treatment effects at one level it maybe efficient to select random collectives at the next higher level, and then todivide the members of each one among treatments. Once the large unit is chosen, it may be sensible to sample smaller unitswithin it:schools within a district, classrooms within a school, or studentswithin a classroom. Such multistage sampling has to be designed to fit thepurposes of the particular investigation (Jaeger, 1970).For the kinds ofstudies discussed in the report, it will almost always be more important toincrease the number of schools or classrooms. Itmay be appropriate totest only a fraction of the individual students, if that economy permits anincrease in the number of groups.In obtaining a between-collectives regression coefficient, there areadvantages in an extreme-groups design, most or all of the data being takenfrom groups whose means are far out on the predictor scale. This design hassuperior cost-effectiveness for evaluating a univariate regression equation.I do not suggest, however, that groups be formed by assembling individualswith extreme scores; such groups are not appropriate representatives of thereference population of collectives formed in a more normal manner. 5.In most studies, it will be impractical to collect extensive data on alarge sample of higb-level units.Not many investigators will be in aposition to investigate 100 school systems, or even 100 classes. Researchon higher-level units, then, will have to be more in the character of case233 10.9 studies, and less in the character of statistical studies. This point wasmade by Merton and Kitt (1950) in one of the first modern papers on groupeffects, but it seems to have dropped from sight during subsequent attemptsto draw conclusions about context effects from survey-like data.6.The mode of analysis of effects is to be determined by the substantivemodel suggested for the processes at the several levels. It will often beappropriate to form separate structural models for between-groups relationsand for within-groups relations, taking into account the rules by whichcollectives are formed. 7.Plots of the data should be made, to the greatest degree possible. Repeatedly, bivariate plots of group means have improved my interpretation ofbetween-group statistics (often by inducing caution). Studies of groupswill usually be limited in size, and outliers can make a large diff-erence in the statistics. 8.In predicting scores of members of collectives, it will generally be sound to estimate the dependent variable for the collective and then add thepredicted deviation of the member's score from that group value, instead ofmaking a one-stage prediction. Even if the two-stage prediction accounts for rather little additionalvariance, it may make statements about atypical individuals that differappreciably from the simple prediction. 231 10.10 I have adopted the working hypothesis that treating personsin groupsdoes make a difference. The makeup of a group may determine the events thatimpinge on the group as a whole, and may condition the events that impingeon the individual group member or on his perception of them. Some investi-gators will prefer a simpler working hypothesis that tries to explain theworld without reference to group effects. No doubt group effects arenegligible in some instruction and in some social processes, but even theinvestigator who prefers to deny their existence will be wise to allow hisdata to speak on the point, to the extent that a design of modest size cangive information. It is intellectually legitimate to adopt a strong modelthat assumes absence of group effects, but this is likely to be a poorstrategy in any substantive field where one has insufficient experience tomake the assumption persuasive.The issues that have come to light in this paper lead me to think thateducational studies conducted in classrooms or with data from schools andschool districts have almost never been analyzed correctly. Those fewinvestigators who have taken the collective as the unit of analysis haverarely brought to the surface the potentially interesting within-groupinformation.Moreover, survival of the null hypothesis with groups as theunit of analysis must often have been given a substantive interpretationwithout realization that the sample was insufficient to make the studyinformative.Per contra, use of the individual as unit of analysis when dataare collective is likely to reject null hypotheses falsely. Descriptive aswell as inferential statistics obtained by analyzing data on collectives at235 10.11 the individual level are open to misinterpretation, except where theinterpreter realizes that he is looking at a composite figure for anassemblage of groups. Oddly, the history of the aggregation problem in sociology, politics,and psychology has been one of regarding individual-level relationships asthe information of primary interest, and group-level relationships as adistorted shadow of the former. Once the conventional individual-levelinformation is seen as a composite of within-groups and between-groups effects(at least for certain variables and certain collectives), the situation isnearly reversed. The conventional mixture of the two effects is not usuallythe most meaningful variable to enter into hypotheses. Not all studies in collectives will move in the direction emphasized inthis report.There probably are kinds of inves,igation (factor analysis ofreading-readiness tests being one) where the question can best be posed atthe individual level even though data come from collectives. Even in suchstudies, however, the investigator would do well to ponder the propositionthat if he randomly samples one student from each school in a large area hewill get a different result than if he includes all the students in all theschools, or confines his analysis to students in a single school.Methodology should be matched to the substantive context; forexample, factor analysis of the Learning Environment Inventory would seemparticularly to call for distinguishing relations between and within groups.The methodological maxim appears to be that an investigator who collectsdata on collectives ought to take an explicit position on the role ofbetween-group, within-group, and individual-without-regard-to-group effectsin the variables he studies. He may opt deliberately for any one of severalanalyses. but he should not back into one of the analyses merely because it 236 10.12 is commonplace or convenient. Perhaps an investigator will wish to leavethe question open, and analyze the data at several levels. This is to beencouraged so long as each analysis is logical, and the interpretation isecological.To regard analyses at two levels as alternative ways to answerthe same question is rarely if ever justified. I have suggested elsewhere (Cronbach, 1975) that the ideal of establish-ing lawlike, lasting relationships in the social sciences may be unapproach-able.In that paper I was focussing on the study of the psychology ofindividuals.This report makes the difficulties seem even more forbidding.A social science must deal with collectives, and the cost of obtaining data on collectives is great. It appears that the only recourse is tomake more use of the data we can afford to collect, appreciating hintsin the data with due regard for their uncertainty, and enriching ourquantitative summaries with awareness of the qualitative context of theevents. 237 References and Author IndexAlwin, D. F.Assessing school effects: Some identities. Paper presented to Pacific Sociological Association, 1975.(Revised draft used here.) Anderson, G. J., & Walberg, H. J. Learning environments. In H. J. Walberg (Ed.) Evaluating educational performance.Berkeley, Ca.: McCutchan, 1974. Pp. 81-98.1.3, 3.19 9.18Anderson, G. L. A comparison of the outcomes of instruction under two theories of learning. Unpublished doctoral dissertation,University of Minnesota, 1941. 5.1 ff.Barton, A. H.Bringing society back in: Survey research and macro- methodology.American Behavioral 1968, 1.17Barton, A. H.Comments on Hauser's \"context and consex\". of Sociology, 1970, 76, 514-517. 1.17, 1.17bBell, D.The basic structure of knowledge: What we may no longer take for granted. Unpublished memorandum for a conference on philosophy of science at Aspen-Berlin, September, 1975.Blalock, H. M., Jr. Causal inferences in nonexperimental research. Chapel Hill: University of North Carolina Press. 1964.Blau. P. M.Formal organization: Dimensions of analysis. American Journal of Sociology, 1957, 63, 58-69.Bock, R. D., & Wiley, D. E. Quasi-experimentation in educational settings:Comment.School Review, 1967, 75, 353-366.1.20 1.27 1.23 2.17Bond, G. L., & Dykstra, R. The Cooperative Research Program in first- grade reading instruction. Reading Research Quarterly, 1967, 2, 5-142. 5.11 ff., 8.8, 9.2, 9.11 ff.Bowers, W.Normative constraints on deviant behavior in the college context.Sociometry, 1968, 63, 58-69. 1.17 ff., 4.10, 6.10Bronfenbrenner, U. Experiment in human ecology: A reorientation to theory and research on socialization. Unpublished address, American Psychological Association, 1974. 2.16Bronfenbrenner, U. The ecology of human development in retrospect and . prospect.Paper presented to a Conference of the International Society for the Study of Behavioral Development, Guildford, England,July, 1975. 2.16Bronfenbrenner, U. The experimental ecology of education.Unpublished address, American Educational Research Association, 1976. 2.16Burstein, L.The use of data from groups for inferences aboutindividuals in educational research. Unpublished doctoraldissertation, Stanford University, 1975. 2383.11 Campbell, D. T. Common fate, similarity, and other indices ofthe status of aggregates of persons as social entities.Behavioral Science, 1958, 3, 14-25.Cartwright, D. S. Ecological variables. In San Francisco: Jos-s'ey-Bass, 1969.Pp. 155-218. Cattell, R. B. An attempt at more refined definition of thecultural dimensions of syntality in modern nations. AmericanSociological Review, 1952, 17, 408-421.1.19 9.9 9.9Cattell, R. B. The dimensions of culture patterns by factorizationof national characters. Psychometrika, 1949, 14, 279-298. 9.9Cline, M. G. et al. Education'ai'experimentation: Evaluation ofthe Planned Variation Model. 6.1, 8.3Coleman, J. S. Methods and results in the IEA studies of effectsof school on learning. Review of Educational Research, 45, 1975,355-386. 2.18Coleman, J. S., et al. Equality of educational opportunity.Washington: Government Printing Office, 1966. 1.1, 1.16, 2.18, 3.18Cronbach, L. J. Beyond the two disciplines of scientific psychology.American Pszchologist, 1975, 30, 116-127. 1.16, 1.21, 3.10, 10.12Cronbach, L. J. & Gleser, G. C. Psychological tests and personneldecisions.Urbana: University of Illinois Press. 1957.(2nd ed., 1965) Cronbach, L. J., Gleser, G. C., Rajaratnam, N.The dependability of behavioral New York: Wiley, 1972.2.8,10.2 6.2 ff.Cronbach, L. J., Rogosa, D., Floden, R. E., & Price, G. Analysisof covariance -- Angel of salvation, or temptress and deluder?Occasional Paper, Stanford Evaluation Consortium, StanfordUniversity, Stanford, Calif., 1976. 1.7, 1.17a, 7.2Cronbach, L. J. & Snow, R. E. A titudes and instructional methods.New York: Irvington Publishers, 1976. Preface, 2.1 ff., 5.11, 10.2Cronbach, L. J. & Webb, N. Between-ciass and within-class effectsin a reported Aptitude , Treatment interaction: Reanalysis of astudy by G. L. Anderson. Journal of Educational Psychology, 1975,67, 717-727. Davis, J. A., Spaeth, J. L., & Huson, C. A technique for analysingthe effects of group composition. American Sociological Review,1961, 26, 215-225. ' 35.1 ff. 1,.17a Dogan, M. & Rokkan, S., Quantitative analysis1.10,2.11 in the social sciences. Cambridge: M.I.T. Press, 1969.Duncan, 0. D.Partials, partitions, and paths. Francisco: Jossey-Bass, 1970. Pp. 38-47. 2.20Duncan, 0. D., Cuzzort, R. P., & Duncan, B. D. Statistical geography. Glencoe: Free Press, 1961. 1.10,3.2,9.7Duncan, 0. D., Featherman, D. L., & Duncan, B. Socioeconomic3.4,3.17 background and achievement. New York: Seminar Press, 1972. 1.10,Estes, W. K.The problem of inference from curves based on group data.Psychological Bulletin, 1956, 53, 134-140. 1.14Farkas, G.Specification, residuals, and contextual effects. Sociological Methods and Research, 1974, 2, 333-364. 1.17bFeatherstonc,H. J. Cognitive effects of preschool programs on different types of children. Cambridge, Mass.: Huron Institute, 1973. 2.21, 5.23 ff., 8.9 ff.Feige, E. L., & Watts, H. W.An investigation of the consequences of partial aggregation of micro-economic data. Econometrica, 1972, 40, 343-360. Firebaugh, G.The ecological fallacy: A reconsideration and reformulation.Unpublished manuscript, University of Indiana, 1975. Frank, P.(Ed.)Validation of scientific theories.New York: Collier Books, 1961.Haney, W.The dependability of group mean scores. Unpublished paper, Harvard University Graduate School of Education, Cambridge, Mass., 1974a.Haney, W.Units of analysis issues in the evaluation of Projc.ct Follow Through. Unpublished report, Huron Institute, Cambridge, Mass., 1974b.3.15 1.3, 2.12 2.24 6.4 PrefaceHannan, M. T.Aggregation and disaggregation in sociology. Lexington, Mass.: Lexington, 1971. 1.19a, 2.11Hannan, N., & Burstein, L. Estimation from grouped observations. American Sociological Review, 1974, 39, 374-392. 3.11lirnqvist, K.The international study of educational achievement. In F. N. Kerlinger (Ed.) Review of Research in Education, 1975, 3, 85-109. 2.12, 9.5,9.22 240 Hauser, R. M.Context and consex: A cautionary tale.American Journal of Sociology, 1970a, 75, 645-664. 1.17a Hauser, R. M.Hauser replies. American Journal of Sociology, 1970b,76, 517-520. Hauser, R. M.Socioeconomic background and educational performance.Washington, D. C.: American Sociological Association, 1971. 1.17 ff:, 2.11Hauser, R. M.Contextual analysis revisited. SociologicalMethods and Research, 365-375. 1.17b, 6.101.17 ff. Hauser, R. M., Sewell, W. H., and Alwin, D. F. High school effects onachievement.W. H. Sewell, R. M. Hauser, and D. L. Featherman (Eds.)Schooling and achievement in American society. New York: AcademicPress, 309-341. Jaeger, R. M.Designing school testing programs for institutionalappraisal:An application of sampling theory. Unpublisheddoctoral dissertation, Stanford University, 1970.Janson, C. G.Some problems of ecological factor analysis.In M. Dogan and S. Rokkan (Eds.) Quantitative ecological analysis in the social sciences. Cambridge, Mass.: MIT Press, 1969.Pp. 301-342. Kendall, P. L.,& Lazarsfeld, P. F. The relation between individualand group characteristics in \"The American Soldier\". InP. F. Lazarsfeld & M. Rosenberg (Eds.) The language of social research.Glencoe, Ill.: Free Press, 1955. Pp. 290-296.Lo, M.- Y.Statistical analysis of interaction and its applicationto data from the Cooperative Research Program in primary readinginstruction.Unpublished doctoral dissertation, State Universityof New York at Buffalo. UM 73-29,111. 1973.Luecke, D. F.,& McGinn, N. F. Regression analyses and educationproduction functions: Can they be trusted? Harvard EducationalReview, 10.8 9.9 2.14 J.Test theory.Annual Review of Psychology, 1976, 27,251-280. 1.26Maier, M. H., & Jacobs, P. I. The effects of variations in aself-instructional program on instructional outcomes.Psychological Reports, 1966, 18, 539-546.Merton, R. K., & Kitt, A. Contributions to the theory of referencegroups.In R. K. Merton & P. F. Lazarsfeld (Eds.) Continuitiesin social structure. Glencoe, Ill.: Free Press, 1950.Meyer, J. W.High school effects on college intentions.American Journal of Sociolm, 1970, 75, 59-70. 2412.3 10.9 1.23, 3.18 Minkowich, A., Davis, D., & Bashi, J. An evaluation study ofIsraeli elementary schools. Jerusalem: Hebrew University,School of Education. To appear, 1976. 1.3aPeckham, P. D., Glass, G. V., & Hopkins, K. D.The experimentalunit in statistical analysis. Journal of Special Education,1969, 3, 337-349. 1.2Pedhazur, E. J. Analytic methods in studies of educational effects. Review of Research in Education, 1975, 3, 243-305. 2.20Putnam, H.Reductionism and the nature of psychology. Cognition, 1973, 2, 131-146. 1.16Ray, H. W.Final report on the Office of Economic Opportunity experiment in educational performance contracting.Unpublished report, Battelle Laboratories, Columbus, O., 1972. 1.18Riley, M. W.Sociological research, a case approach.New York: Harcourt, Brace & World, 1963. 1.14, 2.12Robinson, W. S. Ecological correlations and the behavior of indiv- iduals.American Sociological Review, 1950, 15, 351-357. 1.3, 2.11Scheuch, E. K. Cross-national.comparisons using aggregate data:Some substantive and methodological problems.In R. L. Merritt and S. Rokkan (Eds.) Comparing nations: The use of quantitative data in cross-national research. New Haven: Yale University Press, 1966.Pp. 131-167. 1.10, 1.14, 2.12Shaycoft, M.The statistical characteristics of school means. In Flanagan, J. C., et al. Studies of the American High School.Pittsburgh: University of Pittsburgh, 1962.Shively, W. P. \"Ecological\" inference: The use of aggregate data to study individuals. American Political Science Review, 1969, 63, 1183-1196.6.4 1.19aSlatin, G. T.Ecological analysis of delinquency: 1969, 34, 894-907. 1.3Slatin, G. T.A factor analytic comparison of ecological and individual correlations: Some methodological implications.Sociological Quarterly, 1974, 15, 507-520. 9.9, 9.15Smith, M. S. & Bissell, J. E. Report analysis: The impact of Head Start.Harvard Educational Review, 1970, 40, 5.10, 8.11 ff., 9.23Streuning, & Guttentag, Beverly Hills: Sage, 1975. Pp. 519-536. 1.24 242 Thorndike, E. L. On the fallacy Of imputing the correlationsfound for groups to the individuals or smaller groups composing them.American Journal of Psychology, 1939, 52, 122-124. 1.3Tryon, R. C., & Bailey, D. E. Cluster analysis. New York:McGraw-Hill, 1970. 9.9Welch, W., & Walberg, H. J. A national experiment in curriculumevaluation.American Educational Research Journal, 1972, 9, 373-383. 2.5Werts, C. E.The partitioning of variance in school effects studies.American Educational Research Journal, 1968, 5, 311-318. 2.18Westinghouse Learning Corporation. The impact of Head Start. 2 vols.Washington, D.C.: U.S. Department of Commerce, 1969. 8.11 ff.Wittrock, M.D., & Wiley, D. E. (Eds.) The evaluation ofinstruction:Issues and problems. New York: Holt, Rinehart, & Winston, 1970. 1.15, 6.4Yule, G. U., & Kendall, M. G. An introduction to the theory ofstatistics.London: Charles Griffin, 1950. 1.25, 2.12 243 "}