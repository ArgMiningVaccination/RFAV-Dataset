{"title": "PDF", "author": "PDF", "url": "https://authors.library.caltech.edu/64539/1/p480-panageas.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "Evolutionary Dynamics in Finite Populations Mix Rapidly Ioannis PanageasPiyush SrivastavaNisheeth K. Vishnoi Abstract In this paper we prove that the mixing time of a broad class of evolutionary dynamics in nite, unstructured populations is roughly logarithmic in the size of the state space. An important special case of such a stochastic process is the Wright-Fisher model from evolutionary biology (with selection and mutation) on a population of size Nover mgenotypes. Our main result implies that the mixing time of this process is O(logN) for all mutation rates and tness landscapes, and solves the main open problem from [ 4]. In particular, it signicantly extends the main result in [ 18] who proved this for m=2. Biologically, such models have been used to study the evolution of viral populations with applications to drug design strategies countering them. Here the time it takes for the population to reach a steady state is important both for the estimation of the steady-state structure of the population as well in the modeling of the treatment strength and duration. Our result, that such populations exhibit rapid mixing, makes both of these approaches sound. Technically, we make a novel connection between Markov chains arising in evolutionary dynamics anddynamical systems on the probability simplex. This allows us to use the local and global stability properties of the xed points of such dynamical systems toconstruct a contractive coupling in a fairly general setting. We expect that our mixing time result would be useful beyond the evolutionary biology setting, and the techniques used here would nd applications in boundingthe mixing times of Markov chains which have a natural underlying dynamical system. 1 Introduction Evolutionary dynamical systems are central to the sci- ences due to their versatility in modeling a wide variety of biological, social and cultural phenomena, see [ 11]. Ioannis Panageas, Georgia Institute of often used to capture the determin- istic, innite population setting, and are typically the rst step in our understanding of seemingly complex processes. However, real populations are nite and often lend themselves to substantial stochastic eects (such as random drift) and it is often important to under- stand these eects as the population size varies. Hence, stochastic or nite population versions of evolutionary dynamical systems are appealed to in order to study such phenomena. While there are many ways to translate a deterministic dynamical system into a stochastic one, one thing remains common: the mathematical analysis becomes much harder as dierential equations are easier to analyze and understand than stochastic processes. Consider the example of the error-prone evolution of an unstructured, asexual haploid population in evolutionary biology; this is also the main motivation for this work. Each individual in the population could be one of mtypes. An individual of type ihas a tness (that translates to the ability to reproduce) which is specied by a positive integer ai,and captured as a whole by a diagonal m\u00d7mmatrix Awhose ( i, i)th entry is ai. The reproduction is error-prone and this is captured by an m\u00d7mstochastic matrix Qwhose ( i, j)th entry captures the probability that the jth type will mutate to the ith type during reproduction.1The population is assumed to be innite and its evolution deterministic. The population is assumed to be unstructured , meaning that only the type of each member of the population matters and, thus, it is sucient to track the fraction of each type. One can then track the fraction of each type at step tof the evolution by a vector x(t)m(the probability simplex of dimension m) whose evolution is then governed by the dierence equation x(t+1)= QA x(t) /bardblQA x(t)/bardbl1.Of interest is the steady state2or the limiting distribution of this process and how it changes as onechanges the evolutionary parameters Qand A.This model was proposed in the pioneering work of Eigen and co-authors [6, 7]. Importantly, this particular dynamical system has found use in modeling rapidly evolving viral 1We follow the convention that a matrix if stochastic if its columns sum up to 1. 2Note that there is a unique steady state, called the quasispecies , when QA > 0. 480 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited.populations (such as HIV), which in turn has guided drug and vaccine design strategies. As a result, thesedynamics are well-studied; see [ 4,17] for an in depth discussion. However, viral populations are generally not innite and show stochastic eects: e.g., the eective population size of HIV-1 in infected individuals is approximately 103106[2,8], which is believed to be responsible for the strongly stochastic nature of its evolution. Several researchers have studied stochastic versions of Eigen'sdeterministic evolution equations [ 1,3,10,12 -16,19]. One such stochastic version, motivated by the Wright-Fisher model in population genetics, was studied byDixit et al. [ 4]. Here, the population is again assumed to be unstructured and xed to a size N.Thus, after normalization, the composition of the population iscaptured by a random point in m;s a y X(t)at time t.How does one generate X(t+1)in this model when the parameters are still described by the matrices Qand Aas in the innite population case? To do this, in the replication (R) stage, one rst replaces an individualof type iin the current population by aiindividuals of type i: the total number of individuals of type iin the intermediate population is therefore aiNX(t) i.I n the selection (S) stage, the population is culled back to sizeNby sampling Nindividuals from this intermediate population. In analogy with the Wright-Fisher model, weassume in this paper that the Nindividuals are sampled with replacement.3Finally, since the evolution is error prone, in the mutation (M) stage, one then mutates eachindividual in this intermediate population independentlyand stochastically according to the matrix Q.The vector X(t+1)then is the normalized frequency vector of the resulting population. While this stochastic (RSM) model captures the eect of population size, it is useful only if the mixingtime, or the time it takes for the population to reach (close to) its steady state, is much smaller than the size of the state space. For example, in simulations, samples from close to steady state are needed and this is only computationally feasible when the mixing time is small. Moreover, the ecacy of drug design strategies depends on the time it takes the population to evolve to steady state - the mixing time therefore models the minimum required duration of treatment. However, the numberof states in the RSM process is roughly Nm(when m is small compared to N), and a mixing time that grows too fast as a function of the size of the state space can therefore be prohibitively large. For example, even for a 3Culling via sampling without replacement was considered in [4], but the Wright-Fisher inspired sampling with replacement is the natural model for culling in the more general setting that we consider in this paper.small constant m= 40 and a population of size 10 ,000, the number of states can grow to more than 2300! The importance of obtaining rigorous bounds for mixing time of RSM model was rst pointed out in [ 4]. Rigorous mixing time results are far and few; they have either ignored mutation, assumed that the model is neutral (i.e., types have the same tness), or moved to the diusion limit which requires both mutation and selection pressure to be weak. Recently, the mixing time was shown to be roughly logNfor the m= 2 case (for allQandA) when all other parameters of the model are constants when compared to N, see [ 18]. As discussed in the technical overview, there are signicant hurdlesto extend this result to m> 2 and this problem has remained open since it was raised in [ 4]. 1.1 Our contribution. In this paper we prove that the mixing time of the RSM model on an unstructured population of size N, parametrized by m\u00d7mmatrices QandAisO(logN)when all other parameters of the model are constants when compared to N. Interestingly this result turns out to be a corollary of a rapid mixing result for a more general class of evolutionary dynamics in nite populations which should have applicability beyond evolutionary biology. Before we describe the result we present the setup: consider an innite population whose evolution is described by a function f:m/mapstomwhere the population at time t, captured by the vector x(t)m,evolves according to the rule x(t+1)=f(x(t)).Inspired by the Wright-Fisher model, we convert an innite population dynamics to a nite one, say of size N,as follows: the fraction of each type in the population at time tis captured by a random vector X(t)mand the population at time t+1 is obtained by sampling Ntimes independently from the distribution f(X(t)).Our main result is that, under mild assumptions on f,the mixing time is bounded by O(logN) when all parameters involving fare assumed to be constants when compared to N. Theorem 1.1 (Informal statement - see Theorem 3.6).Letf: m/mapstombe an evolution function which satises certain mild conditions explained below, and consider the stochastic evolution guided by fon a population of size N. Then, the stochastic evolution converges to its stationary distribution in time O(logN). We rst explain the conditions on frequired by the theorem; see Denition 3.3for a formal description. The key conditions are 1) that fhas a \"unique xed point\" which lies in the interior of m,2) that the unique xed point of fshows \"contraction near the xed point\" and 3) that fshows \"convergence to xed point\" . While it is clear what (1) and (3) mean, the second condition 481 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited.roughly means that there is a k>0 such that if J(x) denotes the Jacobian of fatx,then for all xwhich are near ,/bardblJk(x)/bardbl1<1.For technical reasons, we also need that fis twice dierentiable in the interior of m. While we would have liked the contractive condition to hold for k=1,unfortunately, there are simple examples w h e r et h i si sf a l s e . A sw es h a l ls e el a t e r ,t h ef a c tt h a tw e cannot take k= 1 is the main source of all the technical diculties that arise in our work. While we do not prove that these assumptions on f are necessary for the theorem to hold, there is some intuitive justication for them as we discuss below. Although the case of fhaving multiple xed points is interesting in its own right, one might expect thestochastic population in this setting to exhibit slowmixing, since it can get stuck close to one of the xedpoints. We therefore concentrate on the case wherethere is a unique xed point and leave it as an openproblem to study our theorem in the case of multiplexed points formally. The assumption that this xed point be located in the interior is motivated by the fact that this is the case in most applications, e.g. Eigen's model has this property when Q> 0a n d A>0, entry- wise. The \"contraction near the xed point\" condition ensures that the xed point is indeed a steady stateof the deterministic evolution in the sense of being asymptotically stable: once the evolution reaches close enough to the xed point, it converges to the latter. Together with the \"convergence to xed point\" condition (which, again, is satised by models such as Eigen's model), this condition also ensures that the behavior of the deterministic system is free of exotic features, e.g. the presence of cycles, which may present a barrier to the fast mixing of the stochastic evolution. The smoothness condition is of a more technical nature, but models our expectation that any evolutionary dynamics should not be too susceptible to small changes in the population prole. Several other remarks are in order. 1) We treat m,a bound on the derivatives of f,and the rate of contraction as constants and, hence, we do not optimize the dependence on these parameters in this paper. We l e a v ei ta sa no p e np r o b l e mt od e t e r m i n et ow h a textent our results can be generalized when mis a growing function of N.It would be quite interesting to get a bound on the mixing time which depends polynomially on m.In this paper, our emphasis instead is on circumventing the obstacles that arose in previous attempts to prove a mixing time of close to O(logN)f o r general models: earlier works in this direction either putstringent conditions on the parameters of the model (e.g., Dixit et al. had to place very strong conditions on the matrices QandAfor their mixing time result to hold), orwere valid only when the number of genotypes was very small (e.g. Vishnoi [18] required the condition m=2 ) . 2) It is not obvious that the desired mixing time result for the RSM model is a corollary of the main theorema n dw eg i v eap r o o fi nS e c t i o n 3.2. This result should be of independent interest in population genetics. 3) A natural next step is to study the evolution of structured populations. Roughly, this setting extends the RSM model by introducing an additional input parameter, a graph on Nvertices. The graph provides structure to the population by locating each individual at a vertex, and the main dierence from the RSM model is that at time t+1,an individual determines its new vertex by sampling with replacement from among its neighbors in the graph at time t; see [ 9] for more details. Here, it is no longer sucient to just keep track of the fraction of each type. The RSM model can be seen as a special case when the underlying graph is the complete graph onNvertices, so that the locations of the individuals in the population are of no consequence. Our results do not seem to apply directly to this setting and it is a challenging open problem to prove bounds in the general graph setting. Finally, we give a quick comparison of our techniques with that of [ 18] who proved a similar result for m=2.(See the technical overview below for a more detailed discussion.) While [ 18] also used the underlying deterministic process, it was only to bring two copies of the Markov chain close enough (about a distance/radicalbig 1/N). Subsequently, his argument involved the constructionof an ad-hoc coupling which contracts when m=2. However, there appear to be serious hurdles when onetries to generalize this coupling for m> 2.We bypass these obstacles by again resorting to the properties of f listed above, however, in novel ways. We now move on to illustrating our key techniques. 2 Technical overview We analyze the mixing time of our stochastic process by studying the time required for evolutions started at two arbitrary starting states X(0)andY(0)to collide. More precisely, let Cbe any Markovian coupling of two stochastic evolutions XandY, both guided by a smooth contractive evolution f, which are started at X(0)and Y(0).L e t Tbe the rst (random) time such that X(T)=Y(T). It is well known that if it can be shown that P[T>t ]1/4 for every pair of starting states X(0)andY(0)then tmix(1/4)t. We show that such a bound on P[T>t ]h o l d si fw ec o u p l et h ec h a i n su s i n g the optimal coupling of two multinomial distributions (see Section 3for a denition of this coupling). Our starting point is the observation that the optimal coupling and the denition of the evolutions 482 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited.implies that for any time t, (2.1) E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleX(t+1)Y(t+1)/vextenddouble/vextenddouble/vextenddouble 1|X(t),Y(t)/bracketrightBig =/vextenddouble/vextenddouble/vextenddoublef(X (t))f(Y(t))/vextenddouble/vextenddouble/vextenddouble 1. Now, if fwere globally contractive, so that the right hand side of eq. ( 2.1) was always bounded above by /prime/vextenddouble/vextenddoubleX(t)Y(t)/vextenddouble/vextenddouble 1for some constant /prime<1, then we would get that the expected distance between the two copies of the chains contracts at a constant rate. Since the minimum possible positive /lscript1distance between two copies of the chain is 1 /N, this would have implied anO(logN) mixing time using standard arguments. However, such a global assumption on f,w h i c hi s equivalent to requiring that the Jacobian Joffsatises /bardblJ(x)/bardbl1<1 for all xm, is far too strong. In particular, it is not satised by standard systems such as Eigen's dynamics discussed above. Nevertheless, these dynamics do satisfy a more local version of the above condition. That is, they have a unique xed point to which they converge quickly, and in the vicinity of this xed point, some form of contrac- tion holds. These conditions motivate the \"unique xed point\", \"contraction near the xed point\", and the \"con- vergence to xed point\" conditions in our denition of a smooth contractive evolution (Denition 3.3). However, crucially, the \"contraction near the xed point\" con- dition, inspired from the denition of \"asymptoticallystable\" xed points in dynamical systems, is weaker than the stepwise contraction condition described in the last paragraph, even in the vicinity of the xed point. As we shall see shortly, this weakening is essential for generalizing the earlier results of [ 18]t ot h e m> 2 case, but comes at the cost of making the analysis more challenging. However, we rst describe how the \"convergence to xed point\" condition is used to argue that thechains come close to the xed point in O(logN)t i m e . This step of our argument is the only one technically quite similar to the development in [18]; our laterarguments need to diverge widely from that paper. Although this step is essentially an iterated application of appropriate concentration results along with the fact that the \"convergence to xed point\" condition implies that the deterministic evolution fcomes close to the xed point at an exponential rate, complications arise because fcan amplify the eect of the random perturbations that arise at each step. In particular, if L>1 is the maximum of /bardblJ(x)/bardbl1over m, then after /lscriptsteps, a random perturbation can become amplied by a factor of L/lscript. As such, if /lscriptis taken to be too large, these accumulated errors can swamp the progressmade due to the fast convergence of the deterministic evolution to the xed point. These considerations imply that the argument can only be used for /lscript=/lscript0logN steps for some small constant /lscript0, and hence we are only able to get the chains within ( N)d i s t a n c eo ft h e xed point, where < 1/3 is a small constant. In particular, the argument cannot be carried out all the way down to distance O(1/N), which, if possible, would have been sucient to show that the coupling time is small with high probability. Nevertheless, it does allow us to argue that both copies of the chain enter an O(N) neighborhood of the xed point in O(logN)s t e p s . At this point, [ 18] showed that in the m= 2 case, one could take advantage of the contractive behavior near the xed point to construct a coupling obeying eq. ( 2.1) in which the right hand side was indeed contractive:in essence, this amounted to a proof that /bardblJ/bardbl1<1 was indeed satised in the small O(N) neighborhood reached at the end of the last step. This allowed [18]t o complete the proof using standard arguments, after some technicalities about ensuring that the chains remained for a suciently long time in the neighborhood of the xed point had been taken care of. The situation however changes completely in the m> 2 case. It is no longer possible to argue in general that /bardblJ(x)/bardbl1<1w h e n xis in the vicinity of the xed point, even when there is fast convergence to the xed point. Instead, we have to work with a weaker condition (the \"contraction to the xed point\" condition alluded to earlier) which only implies that there is a positiveinteger k, possibly larger than 1, such that in some vicinity of the xed point,/vextenddouble/vextenddoubleJk/vextenddouble/vextenddouble 1<1. In the setting used by [ 18],kcould be taken to be 1, and hence it could be argued via eq. ( 2.1) that the distance between the two coupled copies of the chains contracts in each step. This argument however does not go through when only a kth power of Jis guaranteed to be contractive while Jitself could have 1 1 norm larger than 1. This inability to argue stepwise contraction is the major technical obstacle in our work when compared to the work of [ 18], and the source of all the new diculties that arise in this more general setting. As a rst step toward getting around the diculty of not having stepwise contraction, we prove Theorem 4.1, which shows that the eventual contraction after ksteps can be used to ensure that the distance between two evolutions x(t)andy(t)close to the xed point contracts by a factor k<1o v e ra n epoch ofksteps (where k is as described in the last paragraph), even when the evolutions undergo arbitrary perturbations u(t)andv(t) at each step, provided that the dierence u(t)v(t) between the two perturbations is small compared to the dierence x(t1)y(t1)between the evolutions at the 483 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited.previous step. The last condition actually asks for a relative notion of smallness, i.e., it requires that (2.2)/vextenddouble/vextenddouble/vextenddouble(t)/vextenddouble/vextenddouble/vextenddouble 1\u00b7\u00b7=/vextenddouble/vextenddouble/vextenddoubleu(t)v(t)/vextenddouble/vextenddouble/vextenddouble 1/vextenddouble/vextenddouble/vextenddoublex (t1)y(t1)/vextenddouble/vextenddouble/vextenddouble 1, where is a constant specied in the theorem. Note that the theorem is a statement about deterministic evolutions against possibly adversarial perturbations,and does notrequire u(t)and v(t)to be stochastic, but only that they follow the required conditions onthe dierence of the norm (in addition to the implied condition that the evolution x(t)andy(t)remain close to the xed point during the epoch). Thus, in order to use Theorem 4.1for showing that the distance/vextenddouble/vextenddoubleX(t)Y(t)/vextenddouble/vextenddouble 1between the two coupled chains contracts after every kiterations of eq. ( 2.1), we need to argue that the required condition on the perturbations in eq. ( 2.2) holds with high probability over a given epoch during the coupled stochastic evolution ofX(t)andY(t). (In fact, we also need to argue that the two chains individually remain close to the xedpoint, but this is easier to handle and we ignore this technicality in this proof overview; the details appear in the formal proofs in Section 5.) However, at this point, a complication arises from t h ef a c tt h a tT h e o r e m4.1 requires the dierence (t) between the perturbations at time tto be bounded relative to the dierence/vextenddouble/vextenddoubleX(t1)Y(t1)/vextenddouble/vextenddouble 1at time t1. In other words, the upper bounds required on the (t)become more stringent as the two chains come closer to each other. This fact creates a trade-o between the probability with which the condition in eq. ( 2.2) can be enforced in an epoch, and the required lower bound on the distance between the chains required during the epoch so as to ensure that probability (this trade-o is technically based on Lemma 3.5). To take a couple of concrete examples, when/vextenddouble/vextenddoubleX(t)Y(t)/vextenddouble/vextenddouble 1is (logN/N )in an epoch, we can ensure that eq. ( 2.2) remains valid with probability at least 1 N(1)(see the discussion following Theorem 4.4), so that with high probability ( logN) consecutive epochs admit a contraction allowing the distance between the chains to come down from ( N) at the end of the rst step to (log N/N ) at the end of this set of epochs. Ideally, we would have liked to continue this argu- ment till the distance between the chains is (1 /N) and (due to the properties of the optimal coupling) they have a constant probability of colliding in a single step. However, due to the trade-o referred to ear- lier, when we know only that/vextenddouble/vextenddoubleX(t)Y(t)/vextenddouble/vextenddouble 1is (1 /N) during the epoch, we can only guarantee the condi- tion of eq. ( 2.2) with probability (1) (see the discus- sion following the proof of Theorem 4.4). Thus, wecannot claim directly that once the distance between the chains is O(logN/N ), the next ( log log N)e p o c h s will exhibit contraction in distance leading the chain to come as close as O(1/N) with a high enough positive probability. To get around this diculty, we consider O(log log N) epochs with successively weaker guaranteed upper bounds on/vextenddouble/vextenddoubleX(t)Y(t)/vextenddouble/vextenddouble 1. Although the weaker lower bounds on the distances lead in turn to weaker con- centration results when Theorem 4.4is applied, we show that this trade-o is such that we can choose these pro- gressively decreasing guarantees so that after this set of epochs, the distance between the chains is O(1/N)w i t h probability that it is small but at least a constant .S i n c e the previous steps, i.e., those involving making both chains come within distance O(N) of the xed point (for some small constant <1), and then making sure that the distance between them drops to O(logN/N ), take time O(logN) with probability 1 o(1), we can conclude that under the optimal coupling, the collision or coupling time Tsatises (2.3) P[T>O (logN)]1q, for some small enough constant q, irrespective of the starting states X(0)andY(0)( n o t et h a th e r ew ea r ea l s o using the fact that once the chains are within distance O(1/N), the optimal coupling has a constant probability of causing a collision in a single step). The lack ofdependence on the starting states allows us to iterate eq. (2.3) for (1)consecutive \"blocks\" of time O(logN) each to get P[T>O (logN)]1 4, which gives us the claimed mixing time. 3 Preliminaries and formal statement of results In preparation for formally stating our main result, we now discuss some preliminary notation, denitions and technical tools that will be used later on. We then formally state our main theorem in Sections 3.1and3.2. Notation. We denote the probability simplex on a set of size mas m. Vectors in Rm, and probability distributions in mare both denoted in boldface, and xjdenotes the jth co-ordinate of a given vector x.T i m e indices are denoted by superscripts. Thus, a time indexedscalar sat time tis denoted as s(t), while a time indexed vector xat time tis denotes as x(t). The letters Xand Y(with time superscripts and co-ordinate subscripts, as appropriate) will be used to denote random vectors. Scalar random vectors and matrices are denoted by other capital letters. Boldface 1denotes a vector all whose entries are 1. Operators and norms. For any square matrix M,w ed e n o t eb y /bardblM/bardbl1its 1 1 norm dened as 484 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is y/bardblM/bardbl2itsoperator norm (M )itsspectral radius dened as the maximum of the absolute values of its eigenvalues. The following theorem, stated here only in the special case of the 1 1 norm, relates the spectral radius with other matrix norms. Theorem 3.1 (Gelfand's formula, specialized to the11norm ).For any square matrix M, we have sp (M ) = lim l/vextenddouble/vextenddoubleMl/vextenddouble/vextenddouble1/l 1. Derivatives. Letg:RmRmbe any dier- entiable is the m\u00d7mmatrix i, j)e n t r yi sgi(x) xj.T h e Hessian of a twice dierentiable function h:RmRat a given point xis the m\u00d7msymmetric matrix whose (i, j)e n t r yi s2h(x) xixj. We use the following special case 3.2 (Taylor's theorem, J(z)denote the Jacobian of gatz.L e t x,yRmbe two points, and suppose there exists a positive constant Bsuch that at every point on the line segment joining xtoy, the Hessians of each of the mco-ordinates giof ghave operator norm at most 2B. two probability distributions on mobjects. A coupling Cofpand qis a distribution on ordered pairs in [m]\u00d7[m], such that its marginal distribution on the rst co-ordinate is equal to pand that on the second co-ordinate is equal to q. A simple, if trivial, example of a coupling is the joint distribution obtained by sampling the two co-ordinates independently, one from pand the other from q. Couplings allow a very useful dual characterization of the total variation distance, as stated in the following well known lemma. Lemma 3.3 (Coupling lemma ).Letp,qmbe two probability Then, /bardblpq/bardblTV=1 2/bardblpq/bardbl1=m i n CP(A,B )C[A/negationslash=B], where the minimum is taken over all valid couplings C ofpandq.Moreover, the coupling in the lemma can be ex- plicitly described. We use this coupling extensively in our arguments, and hence we record some of its useful properties here. Denition 3.1 (Optimal coupling ).Letp,qm be two probability distributions on mobjects. For each i[m], let si\u00b7\u00b7=min(pi,qi), and s\u00b7\u00b7=/summationtextm i=1si. Sample U, V, W independently at random as follows: P[U=i]=si s,P[V=i]=pisi 1s, andP[W=i]=qisi 1s, for all i[m]. We then sample (independent of U, V, W ) a Bernoulli random variable Hwith mean s.T h e s a m p l e ( A, B) given by the coupling is ( U, U)i fH=1a n d( V,W ) otherwise. It is easy to verify that Ap,Bqand P[A=B]=s=1/bardblpq/bardblTV. Another easily veried but important property is that i[m] P[A=i, B/negationslash=i]=/braceleftBigg 0i f ).LetMbe an ergodic Markov chain on a nite state space with stationary distribution . Then, the mixing time tmix() is dened as the smallest time such that for any starting state S(0), the distribution of the state S(t)at time tis within total variation distance of. The term mixing time is also used for tmix() for a xed values of <1/2. For concreteness, in the rest of this paper, we use tmixto refer to tmix(1/e) (though any other constant smaller than 1 /2 could be chosen as well in place of 1 /ewithout changing any of the claims). A standard technique for obtaining upper bounds on mixing times is to use the Coupling Lemma above. Suppose S(t) 1andS(t) 2are two evolutions of an ergodic chain Msuch that their evolutions are coupled according to some coupling C.L e t Tbe the stopping time such that S(T) 1=S(T) 2. Then, if it can be shown that P[T>t ]1/efor every pair of starting states (S(0) 1,S(0) 2), then it follows that tmix\u00b7\u00b7=tmix(1/e) t. Concentration. We now discuss some concentra- tion results that are used extensively in our later argu- ments. We begin with some standard Cherno-Hoeding type (Cherno-Hoeding bounds [ i.i.d Bernoulli random variables with mean . We then have 485 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is exp (N/ 3). An important tool in our later development is the following lemma, which bounds additional \"discrepancies\" that can arise when one samples from two distribution pand qusing an optimal coupling. The important feature for us is the fact that the additional discrepancy (denoted as ein the lemma) is bounded as a fraction of the \"initial discrepancy\" /bardblpq/bardbl1. However, such relative bounds on the discrepancy are less likely to hold when the initial discrepancy itself is very small, and hence, there is a trade-o between the lower bound that needs to be imposed on the initial discrepancy /bardblpq/bardbl1, and the desired probability with which the claimed relative bound on the additional discrepancy eis to hold. The lemma makes this delicate trade-o precise. Lemma 3.5. Letpandqbe probability distributions on a universe of size m, so that p,qm. Consider an optimal coupling of the two distributions, and let xand ybe random frequency vectors with mco- ordinates (normalized to sum to 1) obtained by taking N independent samples from the coupled distributions, so that E[x]=pandE[y]=q. Dene the random error vector eas e\u00b7\u00b7=(xy)(pq). Suppose c>1andt(possibly dependent upon N)a r e such that /bardblpq/bardbl1ctm N. We then have /bardble/bardbl1/parenleftbigg2c/parenrightbigg /bardblpq/bardbl1 with probability at least 12mexp (t/3). Proof. The properties of the optimal coupling of the distributions pandqimply that since the Ncoupled samples are taken independently, 1.|xiyi|=1 N/summationtextN j=1Rj,w h e r e Rjare i.i.d. Bernoulli random variables with mean |piqi|,a n d 2.xiyihas the same sign as piqi.The second fact implies that |ei| = ||xiyi||(piqi)||. By applying the concen- tration bounds from Theorem 3.4to the rst fact, we then get (for any arbitrary i[m]) P/bracketleftBigg |ei|>/radicalBigg t of two bounds applies to every i[m] (except those ifor which |piqi|= 0, but in those cases, we have |ei|= 0, so the bounds below will apply nonetheless). Thus, taking a union bound over all the indices, we see that with probability at least 1 2mexp (t/3) ,w eh a v e (3.4) uses the Cauchy-Schwarz inequality to bound the rst term while eq. ( 3.5) uses the hypothesis in the lemma thatctm N/bardblpq/bardbl1. The claim of the lemma follows since c>1. 3.1 Main theorem. We are now ready to state our main theorem. We begin by formally dening the conditions on the evolution function required by the theorem. Denition 3.3 (Smooth contractive evolution ).A function f:mmis said to be a ( L, B, )smooth contractive evolution if it has the following properties: Smoothness fis twice dierentiable in the interior of m. Further, the Jacobian Joffsatises /bardblJ(x)/bardbl1Lfor every xin the interior of m, and the operator norms of the Hessians of its co- ordinates are uniformly bounded above by 2 Bat all points in the interior of m. Unique xed point fhas a unique xed point in mwhich lies in the interior of m. Contraction near the xed point At the xed point ,t h eJ a c o b i a n J()o ffsatises sp (J ())<< 1. 486 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited.Convergence to xed point For every /epsilon1>0, there exists an /lscriptsuch that for any xm, /vextenddouble/vextenddoublef/lscript(x)/vextenddouble/vextenddouble 1</epsilon1 . Remark 3.1. Note that the last condition implies that /bardblft(x)/bardbl1=O(t) in the light of the previous con- dition and the smoothness condition (see Lemma A.1). Also, it is easy to see that the last two conditions im- ply the uniqueness of the xed point, i.e., the second condition. However, the last condition on global con- vergence does not by itself imply the third condition on contraction near the xed point. Consider, e.g., g:[1,1][1,1] dened as g(x)= xx3.T h e unique xed point of gin its domain is 0, and we have g/prime(0) = 1, so that the third condition is not satised. On the other hand, the last condition is satised, since for x[1,1] satisfying |x|/epsilon1,w eh a v e |g(x)|| x|(1/epsilon12). In order to construct a function f:[ 0,1][0,1] with the same properties, we note that the range of gis [x0,x0] where x0=2/(3 3), and consider f:[ 0,1][0,1] dened as f(x)=x0+g(xx0). Then, the unique xed point of fin [0,1] is x0,f/prime(x0)=g/prime(0) = 1, the range offis contained in [0 ,2x0][0,1], and fsatises the fourth condition in the denition but does not satisfy the third condition. Given an fwhich is a smooth contractive evolution, and a population parameter N, we can dene a stochastic evolution guided by fas follows. The state at time t is a probability vector x(t)m. The state x(t+1) is then obtained in the following manner. Dene y(t)=f(x(t)). Obtain Nindependent samples from the probability distribution y(t), and denote by z(t)the resulting frequency vector over evolution, and consider the stochastic evolution guided by fon a population of size N.T h e n , there exists c0andN0depending upon L, B andand fsuch that for any N>N 0, the mixing time tmix(1/e) of the stochastic evolution is at most c0((log N)). 3.2 The RSM model as a special case. We now show that the Eigen or RSM model discussed in the introduction is a special case of the abstract model dened in the last section, and hence satises the mixingtime bound in Theorem 3.6. Our rst step is to show that the RSM model can be seen as a stochastic evolutionguided by QandAare entries, with Q stochastic (i.e., columns summing up to 1), as describedin the introduction. We will then show that this f is a smooth contractive evolution, which implies that Theorem 3.6applies to the RSM process. We begin by recalling the denition of the RSM process. Given a starting population of size Nonm types represented by a 1 /N-integral probability vector p=(p1,p2,...,p m), the RSM process produces the population at the next step by independently samplingNtimes from the following process: 1. Sample a type Tfrom the probability distribution Ap /bardblAp/bardbl1. 2.Mutate Tto the result type Swith probability QST. We now show that sampling from this process is exactly the same as sampling from the multinomial distribution f(p)=QA p /bardblQA p/bardbl1. To do this, we only need to establish the following claim: Claim 3.7. For any type t[m],P[S=t]=/summationtext jQtjAjjpj/summationtext jAjjpj=(QA jAjjpj)=/summationtext jAjjpj=/bardblAp/bardbl1,w h e r ei n the last equality we used the fact that the columns of Q sum up to 1. Now, we have P[S=t]: =m/summationdisplay iQti\u00b7(Ap) i /bardblAp/bardbl1=/summationtext i=1QtiAiipi/summationtext jAjjpj 3.7, we see that producing Nindepen- dent samples from the process described above (which corresponds exactly to the RSM model) produces the same distribution as producing Nindependent samples from the distribution(QA p) /bardblQA p/bardbl1. Thus, the RSM process is evolution guided by f(x): =QA x /bardblQA x/bardbl1.W e now proceed to verify that this fis a smooth contractive evolution. We rst note that the \"smoothness\" condi- tion is directly implied by the denition of f. For the \"uniqueness of xed point\" condition, we observe that every xed point ofQA x /bardblQA x/bardbl1in the simplex mmust be an eigenvector of QA.S i n c e QAis a matrix with positive entries, the Perron-Frobenius theorem implies that it has a unique positive eigenvector v(for which we can assume without loss of generality that /bardblv/bardbl1=1 ) with a positive eigenvalue 1. Therefore f(x) has a unique xed point =vin the simplex mwhich is in its interior. The Perron-Frobenius theorem also implies that for every xm,limt(QA)tx/t 1v.I n fact, this convergence can be made uniform over m 487 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited.(meaning that given an /epsilon1>0w ec a nc h o o s e t0such that for all t>t 0,/bardbl(QA )tx/t 1v/bardbl1</epsilon1for all xm) since each point xmis a convex combination of the extreme points of mand the left hand side is a linear function of x. From this uniform convergence, it then follows easily that limt ft(x)=v, and that the convergence in this limit is also uniform. The \"conver- gence to xed point\" condition follows directly from this observation. Finally, we need to establish that the spectral radius of the Jacobian J\u00b7\u00b7=J(v)o f fat its xed point is less than 1. A simple computation shows that the Jacobian at visJ=1 1(IV)QAwhere Vis the matrix each of whose columns is the vector v.S i n c e QA has positive entries, we know from the Perron-Frobenius theorem that 1as dened above is real, positive, and strictly larger in magnitude than any other eigenvalue of QA.L e t 2,3,..., mbe the other, possibly complex, eigenvalues arranged in decreasing order of magnitude (so that 1>|2|). We now establish the following claim from which it immediately follows that sp (J )=| 2| 1<1 as required. Claim 3.8. The eigenvalues of M\u00b7\u00b7=(IV)QAare m,0. Proof. LetDbe the Jordan of QA,s o that D=U1QAU for some invertible matrix U. Note thatDis an upper triangular matrix with 1,2,..., m on the diagonal. Further, the Perron-Frobenius theorem applied to QA implies that 1is an eigenvalue of both algebraic and geometric multiplicity 1, so that we can assume that the topmost Jordan block in Dis of size 1 and is equal to 1. Further, we can assume the corresponding rst column of Uis equal to the corresponding positive eigenvector vsatisfying /bardblv/bardbl1=1 . It therefore follows that U1V=U1v1Tis the matrix e11T,w h e r ee 1is the rst standard basis vector. Now, since Uis invertible, Mhas the same eigenval- ues as U1MU =(U1U1V)QAU =(Ie11TU)D, w h e r ei nt h el a s tl i n ew eu s e UD=QAU . Now, note that all rows except the rst of the matrix e11TUare zero, and its (1 ,1) entry is 1 since the rst column of Uisv, which in turn is chosen so that 1Tv=1 . T h u s , we get that ( Ie11TU)Dis an upper triangular matrix with the same diagonal entries as Dexcept that its (1 ,1) entry is 0. Since the (1 ,1) entry of Dwas1while its other diagonal entries were 2,3,..., m, it follows that the eigenvalues of ( Ie11TU)D(and hence those of M)a r e 2,3,..., m,0, as claimed. We thus see that the RSM process satises the condition of being guided by a smooth contractive evolution and hence has the mixing time implied by Theorem 3.6.4 Perturbed evolution near the xed point As discussed in Section 2, the crux of the proof of our main theorem is analyzing how the distance between two copies of a stochastic evolution guided by a smooth contractive evolution evolves in the presence of small perturbations at every step. In this section, we present our main tool, Theorem 4.1, to study this phenomenon. We then describe how the theorem, which itself is presented in a completely deterministic setting, applies to stochastic evolutions. Fix any ( L, B, )-smooth contractive evolution fon m, with xed point . As we noted in Section 2,s i n c e the Jacobian of fdoes not necessarily have operator (or 1 1) norm less than 1, we cannot argue that the eect of perturbations shrinks in every step. Instead, we need to argue that the condition on the spectral radius of the Jacobian of fat its xed point implies that there is eventual contraction of distance between the two evolutions, even though this distance might increase in any given step. Indeed, the fact that the spectral radius sp (J )of the Jacobian at the xed point offis less than < 1 implies that a suitable iterate of fhas a Jacobian with operator (and 1 1) norm less than 1 at. This is because Gelfand's formula (Theorem 3.1) implies that for all large enough positive integers k/prime, /vextenddouble/vextenddoubleJk()/vextenddouble/vextenddouble 1<k. We now use the above condition to argue that after k steps in the vicinity of the xed point, there is indeed a contraction of the distance between two evolutions guided by f, even in the presence of adversarial pertur- bations, as long as those perturbations are small. The precise statement is given below; the vectors (i)in the theorem model the small perturbations. Theorem 4.1 (Perturbed evolution ).Letfbe a (L, B, )-smooth contractive evolution, and let be its xed point. For all positive integers k>k 0(where k0is a constant that depends upon f) there exist /epsilon1, (0,1] depending upon fandkfor which the d/parenleftbig (i)/parenrightbigki=1be sequences of 1, which satisfy the following conditions: 1. (Denition). For1ik,t h e r ee x i s tv e c t o r s u(i)andv(i)such that x(i)=f(x(i1))+u(i),y(i)=f(y(i1))+v(i), and(i)=u(i)v(i). 2. (Closeness to xed point). For0ik,/vextenddouble/vextenddoublex(i)/vextenddouble/vextenddouble 1/epsilon1and/vextenddouble/vextenddoubley(i)/vextenddouble/vextenddouble 1/epsilon1. 488 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited.3. (Smal l perturbations). For1ik,/vextenddouble/vextenddouble(i)/vextenddouble/vextenddouble (0)y(0)/vextenddouble/vextenddouble/vextenddouble 1. In the theorem, the vectors x(i)andy(i)model the two chains, while the vectors u(i)andv(i)model the individual perturbations from the evolution dictated by f. The theorem says that if the perturbations (i)to the distance are not too large, then the distance between the two chains indeed contracts after every ksteps. Proof. As observed above, we can use Gelfand's formula to conclude that there exists a positive integer k0 (depending upon f) such that we have/vextenddouble/vextenddoubleJ()k/vextenddouble/vextenddouble 1<k for all k>k 0.T h i s k0will be the sought k0in the theorem, and we x some appropriate k>k 0for the rest of the paper. Since fis twice dierentiable, Jis continuous on m. This implies that the function on k mdened by z1,z2,..., zk/mapsto/producttextk i=1J(zi) is also continuous. Hence, there exist /epsilon11,/epsilon12>0 smaller than 1 such that if /bardblzi/bardbl/epsilon11for 1 ikthen (4.6)/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublek/productdisplay i=1J(zi)/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble 1k/epsilon12. fis continuously dierentiable, /bardblJ/bardbl1is bounded above on mby some positive constant L, which we assume without loss of generality to be greater than 1. Similarly, since f has bounded second derivatives, it follows from the multivariate Taylor's theorem that there exists a positive constant B(which we can again assume to be greater than 1) such that for any x,ym, we can nd a vector such that /bardbl/bardbl1Bm/bardblxy/bardbl2 2Bm/bardblxy/bardbl21such that (4.7) f(x)= (L+1 )k1/bracerightbigg 1, and =2Bm/epsilon1 1. With this setup, we are now ready to proceed with the proof. Our starting point is the use of a rst order Taylor expansion to control the error x(i)y(i)in terms ofx(i1)y(i1). Indeed, eq. (4.7) when applied to this situation (along with the hypotheses of the theorem)yields for any 1 ikthat x(i)y(i)=f(x(i1))f(y(i1))+(i) =J(y(i1))(x(i1)y(i1))+((i)+(i)), (4.8) where (i)satises/vextenddouble/vextenddouble(i)/vextenddouble/vextenddouble 1Bm/vextenddouble/vextenddoublex(i1)y(i1)/vextenddouble/vextenddouble2 1. Before proceeding, we rst take note of a simple consequence of eq. ( 4.8). Taking the /lscript1norm of both sides, and using the conditions on the norms of (i)and (i),w eh a distance /epsilon1of by the hypothesis of the theorem, the above calculation and the denition (i1)y(i1)/vextenddouble/vextenddouble/vextenddouble the last inequality we use 4 Bm/epsilon1 /epsilon121. This, in turn, implies via induction 1 ik, (4.9)/vextenddouble/vextenddouble/vextenddoublex (i)y(i)/vextenddouble/vextenddouble/vextenddouble 1(L+1 )i/vextenddouble/vextenddouble/vextenddoublex (0)y(0)/vextenddouble/vextenddouble/vextenddouble 1. the proof. By iterating eq. ( 4.8), we can control x(k)y(k)in terms of get from eq. (4.6 ) that the leftmost term in the above sum has /lscript1norm less than (k/epsilon12)/vextenddouble/vextenddoublex(0)y(0)/vextenddouble/vextenddouble 1. We now proceed to estimate the terms in the summation. Our rst step to use the conditions on the norms of (i)and(i)and the fact that /bardblJ/bardbl1L uniformly to obtain the upper bound k/summationdisplay i=1Lki/parenleftBig/vextenddouble/vextenddouble/vextenddoublex(i1)y(i1)/vextenddouble/vextenddouble/vextenddouble 1 \u00b7(Bm/vextenddouble/vextenddouble/vextenddoublex (i1)y(i1)/vextenddouble/vextenddouble/vextenddouble 1+)/parenrightBig . 489 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited.Now, recalling that x(i)andy(i)are both within an /epsilon1 /lscript1-neighborhood of so that/vextenddouble/vextenddoublex(i)y(i)/vextenddouble/vextenddouble 12/epsilon1,w e can estimate the rst inequality is an application of eq. ( 4.9), and the last uses the denitions of /epsilon1and. Combining with the upper bound of ( k/epsilon12)/vextenddouble/vextenddoublex(0)y(0)/vextenddouble/vextenddouble 1obtained above for the rst term, this yields the result. Remark 4.1. Note that kin the theorem can be chosen as large as we want. However, for simplicity, we x some k>k 0in the rest of the discussion, and revisit the freedom of choice of konly toward the end of the proof of the main theorem (Theorem 3.6) on page 14. 4.1 Evolution under random perturbations. We now explore some consequences of the above theorem for stochastic evolutions. Our main goal in this subsection isto highlight the subtleties that arise in ensuring that the third \"small perturbations\" condition during a random evolution, and strategies that can be used to avoid them.However, we rst begin by showing the second condition, that of \"closeness to the xed point\" is actually quitesimple to maintain. It will be convenient to dene for this purpose the notion of an epoch ,w h i c hi ss i m p l yt h e set of ( k+ 1) initial and nal states of kconsecutive steps of a stochastic evolution. Denition 4.1 (Epoch ).Letfbe a smooth contractive evolution and let kbe as in the statement of Theorem 4.1 when applied to f.A n epoch is a set of k+ 1 consecutive states in a stochastic evolution guided by f. By a slight abuse of terminology we also use the same term to refer to a set of k+ 1 consecutive states in a pairof stochastic evolutions guided by fthat have been coupled using the optimal coupling. Suppose we want to apply Theorem 4.1to a pair of stochastic evolutions guided by f. Recall the parameter /epsilon1in the statement of Theorem 4.1. Ideally, we would likely to show that if both the states in the pair at thebeginning of an epoch are within some distance /epsilon1/prime</epsilon1of the xed point , then (1) all the consequent steps in the epoch are within distance /epsilon1of the xed point (so that the closeness condition in the theorem is satised), and more importantly (2) that the states at the last step of the epoch are again within the same distance /epsilon1/primeof the xed point, so that we have the ability to apply the theorem to the next epoch. Of course, we also need to ensure that the condition on the perturbations being true also holds during the epoch, but as stated above, this is somewhat more tricky to maintain than the closeness condition, so we defer its discussion to later in the section. Here, we state the following lemma which shows that the closeness condition can indeed be maintained at the end of the epoch. Lemma 4.2 (Remaining close to the xed point ). Letw<w/prime<1/3be xed constants. Consider a stochastic evolution X(0),X(1),... on a population of sizeNguided by a (L, B, )-smooth contractive evolution f: mmwith xed point .S u p p o s e > 1is such that/vextenddouble/vextenddoubleX(0)/vextenddouble/vextenddouble 1 Nw.I f Nis chosen large enough (as a function of L, , m, k, w, w/primeand), then with probability at least 12mkexp/parenleftBig Nw/prime/2/parenrightBig we have /vextenddouble/vextenddoubleX(i)/vextenddouble/vextenddouble 1(+m)( L+1)i Nw ,f o r 1ik1. /vextenddouble/vextenddoubleX(k)/vextenddouble/vextenddouble 1 Nw. To prove the lemma, we need the following simple concentration result the proof of which is deferred to Appendix B. Lemma 4.3. LetX(0),X(1),... be a stochastic evo- lution on a population of size Nwhich is guided by a (L, B, )-smooth contractive evolution f: mm with xed point . For any t>0and1/3, it holds with probability at (N/2)that that with prob- have (4.10)/vextenddouble/vextenddouble/vextenddoubleX (i)fi(X(0))/vextenddouble/vextenddouble/vextenddouble 1(L+1 )im Nw/prime, for 1 ik. On the other hand, the fact that max/bardblJ(x)/bardbl1L implies that /vextenddouble/vextenddouble/vextenddoublef i+1(X(0))/vextenddouble/vextenddouble/vextenddouble 1=/vextenddouble/vextenddouble/vextenddoublef i+1(X(0))f()/vextenddouble/vextenddouble/vextenddouble 1 L/vextenddouble/vextenddouble/vextenddoublef i(X(0))/vextenddouble/vextenddouble/vextenddouble 1, 490 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited.so that /vextenddouble/vextenddouble/vextenddoublefi(X(0))/vextenddouble/vextenddouble/vextenddouble 1Li/vextenddouble/vextenddouble/vextenddoubleX (0)/vextenddouble/vextenddouble/vextenddouble 1 Li Nw, Combining eqs. ( 4.10)a n d( 4.11), we already get the rst item in the lemma. However, for i=k,w ec a n do much better than the above estimate (and indeed, this is the most important part of the lemma). Recallthe parameter /epsilon1in Theorem 4.1. If we choose Nlarge enough so that (4.12)(+m)(L+1 )k Nw/epsilon1, then the above argument shows that with probability at least 1 2mkexp/parenleftBig Nw/prime/parenrightBig , the sequences of Theorem 4.1: the perturbations in this case are simply 0. Hence, we get that (4.13)/vextenddouble/vextenddouble/vextenddoublefk(X(0))/vextenddouble/vextenddouble/vextenddouble 1k/vextenddouble/vextenddouble/vextenddoubleX (0)/vextenddouble/vextenddouble/vextenddouble 1k Nw. Using )km Nw/prime+k Nw. Thus, (since <1) we only need to choose Nso that (4.14) Nw/primew(L+1 )km (1k) in order to get the second item in the lemma. Since w> 0a n d w/prime>w, it follows that all large enough N will satisfy the conditions in both eqs. ( 4.12)a n d( 4.14), and this completes the proof. 4.2 Controlling the size of random perturba- tions. We now address the \"small perturbations\" con- dition of Theorem 4.1. For a given smooth contractive evolution f,l e t, w, w/primebe any constants satisfying the hypotheses of Lemma 4.2(the precise values of these constants will specied in the next section). For some Nas large as required by the lemma, consider a pair X(t),Y(t)of stochastic evolutions guided by fon a population of size N, which are coupled according to the optimal coupling. Now, let us call an epoch decent if the rst states X(0)andY(0)in the epoch satisfy/vextenddouble/vextenddoubleX(0)/vextenddouble/vextenddouble 1,/vextenddouble/vextenddoubleY(0)/vextenddouble/vextenddouble 1Nw. The lemma (be- cause of the choice of Nmade in eq. (4.12)) shows that if an epoch is decent, then except with probability that is sub-exponentially small in N,1.the current epoch satises the \"closeness to xed point\" condition in Theorem 4.1,a n d 2. the next epoch is decent as well. Thus, the lemma implies that if a certain epoch is decent, then with all but sub-exponential (in N) probability, a polynomial (in N) number of subsequent epochs are also decent, and hence satisfy the \"closeness to xed point\" condition of Theorem 4.1. Hypothetically, if these epochs also satised the \"small perturbation\" condition, then we would be done, since in such a situation, the distance between the two chains will drop to less than 1 /Nwithin O(logN) time, implying that they would collide. This would in turn imply a O(logN) mixing time. However, as alluded to above, ensuring the \"small perturbations\" condition turns out to be more subtle. In particular, the fact that the perturbations (i)need to be multiplicatively smaller than the actual dierences/vextenddouble/vextenddoublex(i)y(i)/vextenddouble/vextenddouble 1pose a problem in achieving adequate concentration, and we cannot hope to prove that the \"small perturbations\" condition holds with very high probability over an epoch when the staring dierence/vextenddouble/vextenddoubleX(0)Y(0)/vextenddouble/vextenddouble 1is very small. As such, we need to break the arguments into two stages based on the starting dierences at the start of the epochs lying in the two stages. To make this more precise (and to state a result which provides examples of the above phenomenon and will also be a building block in the coupling proof), we dene the notion of an epoch being good with a goal g. As before let X(t)andY(t)be two stochastic evolutions guided by fwhich are coupled according to the optimal coupling, and let (i)be the perturbations as dened in Theorem 4.1. Then, we say that a decent epoch (which we can assume, without loss of generality, to start att=0 )i s good with goal gif one of following two conditions holds. Either (1) there is a j,0jk1 such that/vextenddouble/vextenddoublef(X(j))f(Y(j))/vextenddouble/vextenddouble 1g, or otherwise, (2) it holds that the next epoch is also decent, and, further /vextenddouble/vextenddouble/vextenddouble (i)/vextenddouble/vextenddouble/vextenddouble 1/vextenddouble/vextenddouble/vextenddoubleX (i)Y(i)/vextenddouble/vextenddouble/vextenddouble 1for 0 ik, where again is as dened in Theorem 4.1. Note that if an epoch is good with goal g, then either the expected dierence between the two chains drops below gsometime during the epoch, or else, all conditions of Theorem 4.1are satised during the epoch, and the distance between the chains drops by a factor of k. Further, in terms of this notion, the preceding discussion can be summarized as \"the probability of an epoch being good depends upon the goal g, and can be small if gis too small\" . To make this concrete, we prove the following t h e o r e mw h i c hq u a n t i e st h i st r a d e - o b e t w e e nt h es i z e 491 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited.of the goal gand the probability with which an epoch is good with that goal. Theorem 4.4 (Goodness with a given goal ). Let the chains X(t),Y(t), and the quantities N, m, w, w/prime,k,L ,/epsilon1 andbe as dened above, and let <(logN)2.I fNis large enough, then a decent epoch is good with goal g\u00b7\u00b7=4L2m 2Nwith probability at least 12mk/parenleftBig exp(/3) + exp(Nw/prime/2)/parenrightBig . Proof. LetX(0)and Y(0)denote the rst states in the epoch. Since the current epoch is assumed to be decent, Lemma 4.2implies that with probability at least 12mkexp(Nw/prime/2), the \"closeness to xed point\" condition of Theorem 4.1holds throughout the epoch, and the next epoch is also decent. If there is a jk1 such that/vextenddouble/vextenddoublef(X(j))f(Y(j))/vextenddouble/vextenddouble 1g, then the current epoch is already good with goal g. So let us assume that /vextenddouble/vextenddouble/vextenddoublef(X (i1))f(Y(i1))/vextenddouble/vextenddouble/vextenddouble 1g =4L 2\u00b7m Nfor 1 ik. However, in this case, we can apply the concentration result in Lemma 3.5with c=4L2/2andt=to get that with probability at L/vextenddouble/vextenddouble/vextenddoublef(X (i1))f(Y(i1))/vextenddouble/vextenddouble/vextenddouble to xed point\" and \"small perturbations\") for being good with goal ghold with the claimed probability. N o t et h a tw en e e dt ot a k e to a large constant, at least ( log(mk)), even to make the result non-trivial. In particular, if we take =3log(4mk), then if Nis large enough, the probability of success is at least 1 /e. However, with a slightly larger goal g,i ti sp o s s i b l et o reduce the probability of an epoch not being good to oN(1): if we choose =logN, then a decent epoch is good with the corresponding goal with probability at least 1 N1/4,f o rNlarge enough. In the next section, we use both these settings of parameters in the above theorem to complete the proof of the mixing time result. As described in Section 2, the two settings above will be used in dierent stages of the evolution of two coupled chains in order to argue that the time to collision of the chains is indeed small. 5 Proof of the main theorem: Analyzing the coupling time Our goal is now to show that if we couple two stochastic evolutions guided by the same smooth contractiveevolution fusing the optimal coupling, then irrespective of their starting positions, they reach the same state in a small number of steps, with reasonably high probability. More precisely, our proof would be structured as follows. Fix any starting states X(0)andY(0)of the two chains, and couple their evolutions according to the optimal coupling. Let Tb et h e r s tt i m es u c ht h a t X(T)=Y(T). Suppose that we establish that P[T<t ]q,w h e r e tand pdo not depend upon the starting states ( X(0),Y(0)). Then, we can dovetail this argument for /lscript\"windows\" of time teach to see that P[T>/lscript \u00b7t](1q)/lscript:t h i s is possible because the probability bounds for Tdid not depend upon the starting positions ( X(0),Y(0))a n d hence can be applied again to the starting positions (X(t),Y(t))i fX(t)/negationslash=Y(t). By choosing /lscriptlarge enough so that (1 q)/lscriptis at most 1 /e(or any other constant less than 1 /2), we obtain a mixing time of /lscriptt. We therefore proceed to obtain an upper bound on P[T<t ]for some t= ( l o g N). As discussed earlier, we need to split the evolution of the chains into several stages in order to completethe argument outlined above. We now describe thesefour dierent stages. Recall that fis assumed to be a(L, B, )-smooth contractive evolution. Without loss of generality we assume that L>1. The parameter r appearing below is a function of these parameters and k a n di sd e n e di nL e m m a A.1. Further, as we noted after the proof of Theorem 4.1,kcan be chosen to be as large as desired. We now exercise this choice by choosing kto be large enough so that (5.15) ke1. The other parameters below are chosen to ease the application of the framework developed in the previous section. 1.Approaching the xed point .W e d e n e Tstart to be the rst time such that /vextenddouble/vextenddouble/vextenddoubleX(T start +i)/vextenddouble/vextenddouble/vextenddouble 1,/vextenddouble/vextenddouble/vextenddoubleY (T start +i)/vextenddouble/vextenddouble/vextenddouble 1 Nw for 0 ik1, where \u00b7\u00b7=m+randw=min/parenleftBig 1 6,log(1 /) 6 log( L+1)/parenrightBig .W show that (5.16) P[Tstart>tstartlogN] 4mkt ologNexp/parenleftBig N1/3/parenrightBig , where tstart\u00b7\u00b7=1 6 bounded by exp/parenleftbig N1/4/parenrightbig forNlarge enough. 492 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited.2.Coming within distance /parenleftBig logN N/parenrightBig .L e t n d 2. Then, we dene T0to be the smallest number of steps needed after either /vextenddouble/vextenddouble/vextenddoubleX(T 0)Y(T 1h0logN N(1 + ). enough (5.17) P[T0>k t 0logN]1 N0/7, (1/N). Let 0and hbe as dened in the last item. We now dene a sequence of /lscript1\u00b7\u00b7=/ceilingleftBig log log N klog(1 /)/ceilingrightBig random variables T1,T2,...T /lscript. We begin by dening the stopping time S0\u00b7\u00b7=Tstart+T0.F o r i1,Tiis dened to be the smallest number of steps after Si1such that the corresponding stopping time be 0 if setting Si=Si1 already satises the above conditions. Dene i= ik0. We prove below when Nis P[Ti>k+1 ]4mkexp (( ilogN)/8), t 0andhbe as dened in the last two items. Note that after time S/lscript1,w eh a v 0k/lscript 1logN Then, from the properties of the optimal coupling we have that X(S/lscript1+1)=Y(S/lscript1+1)with probability at least/parenleftBig 1Lh 0 2N/parenrightBigN which is at least exp (L 0h) when Nis so large that N>h L 0.Assuming eqs. ( 5.16)t o( 5.18), we can complete the p r o o fo fT h e o r e m 3.6as follows. Proof of Theorem 3.6. LetX(0),Y(0)be the arbitrary starting states of two stochastic evolutions guided by f, whose evolution is coupled using the optimal coupling. LetTbe the minimum time tsatisfying X(t)=Y(t). By the Markovian property and the probability bounds in items 1 to 4 above, we have (for large enough N) where the last inequality is true for large enough N. Applying Lemma C.1 to the above sum (with the parameters xand in the lemma dened as assumption in eq. ( 5.15)), we can put a upper follows: /lscript1/summationdisplay i=1exp((ik0logN)/8)1 exp(k0/8)1 =1 17mk 11 16mk, where the inequality follows from the lemma and the fact thatlog log N klog(1 /)/lscript11+log log N klog(1 /), and the last inequality uses the denition of 0andm, k 1. Thus, for large enough N,w eh a v e P[TclogN]q, where c\u00b7\u00b7=2 (tstart+kt0)a n d q\u00b7\u00b7=( 3/4)exp (L 0h1). Since this estimate does not depend upon the starting states, we can bootstrap the estimate after every clogN steps to get P[T>c /lscript logN]<(1q)/lscripteq/lscript, which shows thatc q\u00b7logN is the mixing time of the chain for total variation distance 1/e,w h e nN is large enough. 493 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited.We now proceed to prove the claimed equations, starting with eq. ( 5.16). Let t\u00b7\u00b7=tstartlogNfor convenience of notation. From Lemma A.1we have /vextenddouble/vextenddouble/vextenddoubleft(X(0))/vextenddouble/vextenddouble/vextenddouble 1rt. On the other hand, applying with =1/3, we have /vextenddouble/vextenddouble/vextenddoublef 1(L+1 )tm N1/3 with probability at least 1 2mtexp(N1/3). From the triangle inequality and the denition of t, we then see that with probability at least 1 2mtexp/parenleftbig N1/3/parenrightbig ,w w are as dened in item 1 above. Now, if we instead looked at the chain starting at some i<k ,t h e same result would hold for X(t+i). Further, the same analysis applies also to Y(t+i). Taking an union bound over these 2 kevents, we get the required result. Before proceeding with the proof of the other two equations, we record an important consequences of eq. (5.16). Let w, be as dened above, and let w/prime>w be such that w/prime<1/3. Recall that an epoch starting at time 0 is decent if both X(t)andY(t)are within distance /Nwof. Observation 5.1. For large enough N, it holds with probability at least 1exp(Nw/prime/4)that for 1ikN, X(T start +i),Y(T start +i)are within /lscript1distance /Nwof . Proof. We know from item 1 that the epochs starting at times Tstart+ifor 0 i<k are all decent. For large enough N, Lemma 4.2followed by a union bound implies that the Nconsecutive epochs starting at T+j+k/lscriptwhere /lscriptNand 0 jNare also all decent with probability at least 1 2mk2Nexp(Nw/prime/2), which upper bounds the claimed probability for large enough N. We denote by Ethe event that the epochs starting atTstart+ifor 1 ikNare all decent. The above observation says that P(E)1exp(Nw/prime/4)f o r N large enough. We now consider T0.L e t g0\u00b7\u00b7=h 0logN N(1+),w h e r e his as dened in items 2 and 3 above. From Theorem 4.4followed by an union bound, we see that the rst t1logNconsecutive epochs starting at Tstart,Tstart+k,T start+2k,... are good with goal g0(they are already known to be decent with probability at least P(E) from the above observation) with probability at least 12mkt N 0/(3(1+ ))+e x p ( which is larger than 1 N 0/7forNlarge enough (since < 1). Now, if we have/vextenddouble/vextenddoublef(X(i))f(Y(i))/vextenddouble/vextenddouble 1g for some time iduring these t1logNgood epochs then T0kt1logNfollows immediately. Otherwise, the goodness condition implies that the hypotheses of Theorem 4.1are satised across all these epochs, and +kt kt 1logN Nwg0h0logN N, where the second last inequality is true for large enough N. Finally, we analyze Tifori1. For this, we need to consider cases according to the state of the chain at time Si1. However, we rst observe that plugging our choice ofhinto Theorem 4.4shows that any decent epoch is good with goal gi\u00b7\u00b7=hilogN N(1+)with probability at least 1 2mkexp((ilogN)/7) for Nlarge enough (since <1). Further, since we can assume via the above observation that all the epochs we consider are decent with probability at least P(E), it follows that the epoch starting at Si1(and also the one starting at Si1+ 1) is good with goal giwith probability at least p\u00b7\u00b7=12mkexp((ilogN)/7)P(\u00acE) 12mkexp(( ilogN)/8), where the last inequality holds whenever ilogN and Nis large enough (we will use at most one of these two epochs in each of the exhaustive cases we consider below). Note that if at any time Si1+j (where jk+1 )d u r i n go n eo ft h e s et w og o o de p o c h s it happens that/vextenddouble/vextenddoublef(X(Si1+j))f(Y(Si1+j))/vextenddouble/vextenddouble 1gi, then we immediately get Tik+ 1 as required. We can therefore assume that this does not happen, so that the hypotheses of Theorem 4.1are satised across these epochs. Now, the rst case to consider is/vextenddouble/vextenddoubleX(Si1)Y(Si1)/vextenddouble/vextenddouble 1hi1logN N. Since we are 494 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited.assuming that Theorem 4.1is satised across the epoch k)Y(Si1+k)/vextenddouble/vextenddouble/vextenddouble 1 k/vextenddouble/vextenddouble/vextenddoubleX (Si1)Y(Si1)/vextenddouble/vextenddouble/vextenddouble 1 N=hilogN N. Thus, in this case, we have Tikwith probability at least pas dened in the last paragraph. Even simpler is the case/vextenddouble/vextenddoublef(X(Si1))f(Y(Si1))/vextenddouble/vextenddouble 1hilogN Nin which case Tiis zero by denition. Thus the only remaining case left to consider is hilogN N</vextenddouble/vextenddouble/vextenddoublef(X (Si1))f(Y(Si1))/vextenddouble/vextenddouble/vextenddouble 1 hi1logN N(1 + ). Since h=4L2m the rst inequality allows us to use Lemma 3.5with the parameters candtin that lemma set to c=4/2andt=iL2logN,a dw eo b t a i n /vextenddouble/vextenddouble/vextenddoubleX (Si1+1)Y(Si1+1)/vextenddouble/vextenddouble/vextenddouble 1 (1 + )/vextenddouble/vextenddouble/vextenddoublef(X (Si1))f(Y(Si1))/vextenddouble/vextenddouble/vextenddouble 1 hi1logN probability at least 1 2mexp/parenleftbig ( iL2logN)/3/parenrightbig . Using the same analysis as the rst case from this point onward (the only dierence being that we need to use the epoch starting at Si1+ 1 instead of the epoch starting atSi1used in that case), we get that P[Ti1+k ]p2mexp/parenleftbig ( iL2logN)/3/parenrightbig 14mkexp (( ilogN)/8). since L, k > 1. Together with eq. (5.19), this completes the proof of eq. ( 5.18). References [1]Alves, D., and Fontanari, J. F. Error threshold in nite populations. Phys. Rev. E 57, 6 (June 1998), 7008 - 7013. [2]Balagam, R., Singh, V., Sagi, A. R., and Dixit, N. M. Taking multiple infections of cells and recombi- nation into account leads to small within-host eective- population-size estimates of HIV-1. PLoS ONE 6,1( 0 1 2011), e14531.[3]Campos, P. R. A., and Fontanari, J. F. Finite-size scaling of the quasispecies model. Phys. Rev. E 58 (1998), 2664-2667. [4]Dixit, N., Srivastava, P., and Vishnoi, N. K. A nite population model of molecular evolution: Theory and computation. J. Comput. Biol. 19 1176- 1202. [5]Dubhashi, D. P., and Panconesi, A. Concentration of Measure for the Analysis of Randomized Algorithms . Cambridge University Press, 2009. [6]Eigen, M. Selforganization of matter and the evolution of biological macromolecules. Die Naturwissenschaften 58(1971), 456-523. [7]Eigen, M., and prin- ciple of natural self-organization. Part A: the Die Naturwissenschaften 64 (1977), 541-565. [8]Kouyos, R. D., Althaus, C. L., and Bonhoeffer, S.Stochastic or deterministic: What is the eective population size of HIV-1? Trends Microbiol. 14,1 2 (2006), 507 - 511. [9]Lieberman, E., Hauert, C., and Nowak, M. A.Evolutionary dynamics on graphs. Nature 433 , 7023 (Jan. 2005), 312-316. [10] Musso, F. A stochastic version of Eigen's model. Bull. Math. Biol. 73 (2011), 151 - 180. [11] Nowak, M. Evolutionary Dynamics. Harvard Univer- sity Press, 2006. [12] Nowak, M., and Schuster, P. Error thresholds of replication in nite populations-mutation frequencies and the onset of muller's ratchet. J. Theor. Biol. 137 (1989), 375-395. [13] Ray, T. S., Payne, K. A., and Moseley, L. L. Role of nite populations in determining evolutionary dynamics. Phys. Rev. E 77, 2 (Feb 2008), 021909. [14] Saakian, D. B., Rozanova, O., and Akmetzhanov, A.Dynamics of the Eigen and the Crow-Kimura models for molecular evolution. Phys. Rev. E 78, 4 (Oct 2008), 041908. [15] Tripathi, K., Balagam, R., Vishnoi, N. K., and Dixit, N. M. Stochastic simulations suggest that HIV- 1 survives close to its error threshold. PLoS Comput. Biol. 8 , 9 (2012), e1002684. [16] van Nimwegen, E., Crutchfield, J. P., and Mitchell, M. Statistical dynamics of the Royal Road Genetic Algorithm. Theor. Comput. Sci. 229 (1999), 41 - 102. [17] Vishnoi, N. K. Evolution without sex, drugs and Boolean functions. http://theory.epfl.ch/vishnoi/ (2013). [18] Vishnoi, N. K. The speed of evolution. In Proc. 26th Annual ACM-SIAM Symp. Discret. Algorithms (SODA) (2015), pp. 1590-1601. [19] Wilke, C. Quasispecies theory in the context of population genetics. BMC Evol. Biol. 5 , 1 (2005), 44. 495 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited.A Proofs omitted from Section 3.1 Lemma A.1 (Exponential convergence ).Letfbe a smooth contractive evolution, and let andbe as in the conditions described in Section 3.1. Then, there exist a positive rsuch that for every zm, and every positive integer t, /vextenddouble/vextenddoubleft(z)/vextenddouble/vextenddouble 1rt. Proof. Let/epsilon1andkbe as dened in Theorem 4.1.F r o m the \"convergence to the xed point\" condition, we know that there exists an /lscriptsuch that for all zm, (A.1)/vextenddouble/vextenddoublef/lscript(z)/vextenddouble/vextenddouble 1/epsilon1 Lk. N o t et h a tt h i si m p l i e st h a t f/lscript+i(z) is within distance /epsilon1of fori=0,1,...,k , so that Theorem 4.1can be applied to the sequence of vectors f/lscript(z),f/lscript+1(z),...,f/lscript+k(z) and,f()=,...,fk()=(the perturbations are simply 0). Thus, we get /vextenddouble/vextenddoublef/lscript+k(z)/vextenddouble/vextenddouble 1k/vextenddouble/vextenddoublef/lscript(z)/vextenddouble/vextenddouble 1k/epsilon1 Lk. Since <1, we at /lscript+kalso satises eq. ( A.1) and hence we can iterate this process. Using also the fact that the 1 1 norm of the Jacobian offis at most L(which we can assume without loss of generality to be at least 1), we therefore get for every zm, and every r ei nt h el a s tl i n ew eu s et h ef a c t st h a t L>1,<1 andj<k . Noting that any t/lscriptis of the form /lscript+ki+j for some iandjas above, we have shown that for every t/lscriptand every zm (A.2)/vextenddouble/vextenddoubleft(z)/vextenddouble/vextenddouble 1/parenleftbiggL /parenrightbiggk+/lscript t/bardblz/bardbl1. Similarly, for t</lscript ,w eh a v e ,f o ra line we have again used L>1, < 1 andt</lscript .F r o m e q s . ( A.2)a n d( A.4), we get the claimed result with r\u00b7\u00b7=/parenleftBig L /parenrightBigk+/lscript .B Proofs omitted from Section 4 Proof of Lemma 4.3. Fix a co-ordinate j[m]. Since X(i)is the normalized frequency vector obtained by taking Nindependent samples from the distribution f(X(i1)), Hoeding's N12/parenrightbig 2e x p( N), where the last inequality holds because 1/3. Taking a union bound over all j[m], we therefore have that for any xed it, (B.5) P/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleX (i)f(X(i1))/vextenddouble/vextenddouble/vextenddouble 1>m N/bracketrightBig 2mexp (N). For let us dene the quantities s(i)\u00b7\u00b7=/vextenddouble/vextenddoubleX(i)fi(X(0))/vextenddouble/vextenddouble 1for 0 it. Our goal then is to show that it holds with high probability that s(i)(L+1)im Nfor all isuch that 0 it. Now, by taking an union bound over all values of iin eq. ( B.5), we see that the following holds for all i with probability at least 1 2mtexp (N): s(i)=/vextenddouble/vextenddouble/vextenddoubleX m N+Ls(i1),(B.6) where the rst term is estimated using the probabilistic guarantee from eq. (B.5) and the second using the upper bound on the 1 1 norm of the Jacobian of f. However, eq. (B.6) implies that s(i)m(L+1)i Nfor all 0 it, which is what we wanted to prove. To see the former claim, we proceed by induction. Since s0= 0, the claim is trivially true in the base case. Assuming the claim is true for s(i), we then apply eq. exponentially decreasing exponents The following technical lemma is used in the proof of Theorem 3.6. Lemma C.1. Letx, be positive real numbers less than 1such that <1 e.L e t /lscriptbe a positive integer, and dene 496 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited.y\u00b7\u00b7=x/lscript.T h e n /lscript/summationdisplay i=0xiy 1y. Proof. Note that since both xandare positive and less than 1, so is y.W en o wh a v e i=0yi,s <1/e, y 1y. 497 Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. "}