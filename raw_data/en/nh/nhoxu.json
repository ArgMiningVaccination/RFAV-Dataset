{"title": "PDF", "author": "PDF", "url": "https://mospace.umsystem.edu/xmlui/bitstream/handle/10355/62795/ProjectReport.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "EVERYONE HATES THE REFEREE: HOW FACT-CHECKERS MITIGATE A PUBLIC PERCEPTION OF BIAS A project presented to the faculty of the graduate school at the University of Missouri-Columbia School of Journalism by ALLISON COLBURN Committee: Katherine Reed (chair) Jennifer Rowe Barbara Cochran December 2017 ii\"ACKNOWLEDGEMENTS I want to thank Katherine Reed for helping me take my abstract ideas into something concrete and researchable. She was an essential guide when I was struggling to come up with my project proposal. I also want to thank Jennifer Rowe for her encouragement and for turning my \"judgements\" into \"judgments.\" And Barbara Cochran has given me a great deal of support during my project's professional component. I have gained so much from having three intelligent, successful and strong-willed women on my committee. Last, I would be remiss to forget to acknowledge the Missouri School of Journalism. The disillusioned student who started with the school in fall 2015 is a better, more confident version of herself today. iii\"TABLE OF CONTENTS Acknowledgments.................................................................................................. ii Chapter 1. Introduction..............................................................................................3 2. Activity Log.............................................................................................7 3. Evaluation .............................................................................................17 4. Physical Evidence .................................................................................20 5. Analysis.................................................................................................64 Appendix...............................................................................................................85 1. Note to Reader..................................................................85 2. Literature Review..............................................................86 3. Interview Transcripts.........................................................104 4. Fact-Checking Policies......................................................142 3 Introduction When I was about 7 years old, an adult in my life who I looked up to and admired in many ways, told me that dinosaurs never existed. According to her faith, God would never place such ghastly creatures on Earth. And the Earth was 6,000 years old. And macroevolution was a sham. She wasn't the only person in my life who rejected certain fields of science. A good portion of my community believed the same. I grew up in Colorado Springs near Focus on the Family, a Christian organization that rejects Darwin's theory of evolution. The organization has, since its founding in 1977, attracted like-minded individuals and churches to the surrounding area. The problem for second-grade me was that I loved dinosaurs. I also loved reading about the big bang, the life cycle of stars and Earth's history. When people who I considered to be much wiser than me told me that what I was learning in school was wrong, I had to make a decision: Are dinosaurs fake? Or are adults lying to me? Overwhelming scientific evidence won my vote. But what I learned then about faith, fact and delusion continues to puzzle me. I've had countless conversations with people, many of whom I consider to be friends, about why they believe what they do, despite there being no evidence to support it and ample evidence to dispel it. They tell me that aliens visit Earth all of the time, the U.S. government was behind the September 11 attacks and big pharmaceutical companies are withholding the cure for cancer. Their strong-held beliefs always hinge on some core ideology that, if shaken or disturbed, might demolish the person they think they are. Some pundits and scholars argue that we live in a post-truth political era, where appeals to emotion and personal belief are more persuasive than objective facts. Conspiracy theories 4 have made their way from the fringe to the mainstream. This poses a problem for journalists, who must now figure out how to present facts to an increasingly skeptical audience. My project aims to offer a critical look at the fact-checking process along with its framing devices in the hopes of finding best practices for reporting fact-checks. In a way, I've always wanted to do this kind of research. The social components of spreading fiction have fascinated me for years. In undergrad, my plan was to complete my bachelor's degree in English literature and then spend my life conducting research in folklore and oral narratives and teach at a university. This plan came to an end about half-way through my senior year. As I spent more time getting to know university researchers, I realized I was jealous of my friends who were going to work in business, health care and other, more sociable fields. The thought of confining myself to studies in literature sounded peaceful, but lonely. After about eight months of deliberation, I settled on journalism as my next career move. I felt it would be a good way for me to contribute something meaningful. I had relatively little experience in the field before I applied to the Missouri School of Journalism. I was working in retail and wrote for a volunteer-run, small community newspaper outside of Colorado Springs. My first story went on the front page: \"Stormwater drainage fee set for ballot,\" the headline read. It wasn't the coolest story, but I felt like I was doing something helpful for my community. Since then, I have gained almost two years of experience working at the Columbia Missourian. During my first and second semester of graduate school, I worked as an education reporter in addition to working general assignment shifts. I became an expert on my beat as I reported on K-12 and higher education, learning the complexities of charter schools, university funding and closing the academic achievement gap. My current position, which I have held for 5 the past year, is an assistant city editor. I spend about 20 hours per week keeping tabs on breaking news and editing general assignment stories. Through these positions I have grown comfortable with pitching stories, working on long-term pieces and handling any daily news that comes in. I've also taken important skills classes, including Computer-assisted Reporting, Advanced Data Journalism, Investigative Reporting and Magazine Editing. When I first started my graduate program in the Missouri School of Journalism, I created a few goals: Learn to write feature stories, cover breaking news, develop data skills, work in news editing and report on politics. I've spent most of my time focusing on the first four goals, but I've only just touched on the last. Even though political reporting intersects with all topics, I haven't quite had the opportunity to really dig into that essential genre of journalism. By spending the upcoming fall semester reporting in Washington, D.C. and completing my professional project, I hope to finally finish what I set out to do in fall 2015. Lately, my interest in political reporting has centered on fact-checking. As fake news continues to pervade online and the new White House administration writes off fact-checks by claiming the existence of \"alternative facts,\" sorting out what is true and what is purely made up has become perhaps the most essential public service in journalism. While writing for PolitiFact Missouri in my fact-checking class this spring, I realized I was interested in taking a scholarly approach to the topic. For my project, I chose to work with framing theory because I wanted to understand the different approaches fact-checkers take in trying to correct the record and dispel misleading information. Some organizations use rating systems, some call false claims lies, and some just lay out whatever information they found and allow the reader to make a judgment. After surveying various theories, it became apparent that these organizations' methods of presenting 6 fact-checks were framing devices. Analyzing fact-checks through the lens of framing theory sets me up to understand how journalists grapple with the era of alternative facts. In my PolitiFact class, I have already learned how to identify verifiable claims, track down the source of information behind a claim and report on its various facets. With the help of editors, I've also taken part in deciding how to rate the fact-checks of mine and my peers. I recently accepted a news reporting internship on the metro desk of the St. Louis Post-Dispatch, which will take place from May to August this year. The experience I've gained since beginning my graduate program along with the experience I'll have come August sets me up for success in completing my project and fulfilling my graduate school goals. 7 Activity Log The week of 8/21-8/28 Hello everyone. I don't have a whole lot to report this week. My first few days in Washington were spent starting my internship at PolitiFact and getting familiar with the city. It was a weird start because I so far haven't had an in-person editor. The newsroom is kind of split in half. There are a few of us in the D.C. Office, and a few more people work in Florida. Most of our communication so far has been over Slack. On the one hand, it's nice for reporters and editors to be able to work from home if they want to. But the main challenge I dealt with last week was figuring out what I was doing without the help of a supervisor. I did manage to get a couple of clips published last week, and tomorrow we should be publishing another story. This internship so far has been much different in terms of pace than my breaking news internship this summer at the Post-Dispatch, where I was getting at least one thing published a day. It goes to show how much more time goes into reporting fact-checks and political analysis than into breaking news. Not that breaking news and general assignment reporting is easy, it's just a quicker process. The added work of having to spell out all of your sources in a citation also slows down the PolitiFact process. This is a good thing, though. It forces reporters to review their information again before publishing. As for the research project, I didn't get to it last week, but I will start setting up interviews this week. I'll start with the people who I think will be tougher to get in touch with. Katherine, I know you mentioned you have a contact at Le Monde. When you get a chance, do you mind shooting me their email address? Have a lovely week! Allison The week of 8/29-9/4 Happy Labor Day. This weekend I reached out to FactCheck.org, Glenn Kessler at The Washington Post and Snopes for my project interviews. I'm optimistic I'll hear back in the next couple of days. (I have not yet emailed Katherine's Le Monde contact. I need to have my French-speaking friend read over the email.) I realized need to get a couple of contacts from PolitiFact, especially this one New York Times fact-checker who used to write for PolitiFact. I'm honestly not sure who to contact with the Associated Press, but I'm wondering if someone from PolitiFact might know of a good person. I know it's been a slow start with the project. No need to worry, I'm picking up the pace. 8 Last week I wrote another couple of stories - one on Trump's efforts to reinvigorate the coal industry and the other on his flailing school choice initiative. The reporting for these took a while because we hadn't done any updates on those campaign promises yet. This meant I needed to talk to many people and do a lot of reading to figure out exactly what Trump has done so far, without missing anything. I also met my in-person supervisor on Tuesday, and I helped with some of the research on fact-checking Trump's speech in Phoenix. On Friday the Washington program folks went to the Newseum. It was by far one of the coolest museums I've seen in D.C. Before taking a tour of the place, we met Gene Policinski, the Newseum's chief operating officer. I assumed he was going to tell us he was concerned about attacks on the press from political leaders and other public figures, but he said he was more worried about everyday Americans justifying suppressing 1st Amendment freedoms out of fear of things like terrorism and neo-nazis. He has seen many politicians attack the press over the past several decades, but those politicians come and go. More important is that the general public doesn't see this polarizing time as a reason to chip away at our own Constitutional rights. I'm not 100 percent convinced we won't. I'll end on that bleak note. Have a great week! The week of 9/5-9/11 Hello, I made some progress with my project last week when I interviewed Glenn Kessler at the Washington Post. He was generally really nice and had interesting things to say. The best part of the interview was when we got to the subject of media bias. He said that when people contact him to tell him he's biased toward one political party or another, he usually tells them to read his fact-checking column for one month, then decide if he is biased. Generally, people contact him again a month later and say that they realized he is pretty good about holding both political parties accountable. The problem is that many people just read one fact-check online and judge the reporter based on that snippet. This week I'm hoping to get a couple of other interviews done and work on transcribing. Labor Day weekend shortened my work week, so I didn't get the usual amount of work done. On Tuesday, I published a short article on the difficulty of balancing the federal budget. Then on Thursday I pitched an idea to create a list of fake Hurricane Irma photos and videos making the rounds on social media. The editors liked the idea. However, once I gathered all the photos/videos I could find, the list didn't really seem to fit with our Irma coverage. It just kind of skimmed the surface of different fake things on social media, when we generally try to do deep dives into fake news stories. The list sounded good in theory, though. In seminar last week, we visited Sen. Claire McCaskill's office to chat with her communications staff. It was really neat to get a glimpse into how they perform their jobs. One of my biggest takeaways was that it's super important to meet up with communications people when you start 9 working on a beat so you can develop relationships with them quickly and also get an understanding of who to contact on any given topic. It also helps to explain to them what kind of stories you are interested in because many of them never worked in journalism and might not understand why the stories they pitch aren't getting any traction. On Friday I attended the graduation ceremony/dinner for this year's Alfred Friendly Fellows. (And I ran into Katherine there!) I had become friends with a couple of the fellows back in the spring and over the summer, so it was great to see them again before they went back to their home countries. The week of 9/12-9/18 Hello, I feel kind of stuck on my project this week. I have reached out to Snopes and FactCheck.org. I also got in touch with a reporter from Le Monde who initially responded to my query on Thursday but has not scheduled an interview with me yet. Snopes and FactCheck.org have not responded. I'm getting kind of worried because I'd really like to get these interviews done as soon as possible. They obviously have stuff going on, but how long should I wait before bugging them again? Over the weekend, I transcribed the Washington Post interview, so at least that is done. On the internship side of things, we've only had one editor for the past few days. Things are going a little bit slower than usual. Last week I wrote about probable cuts to Medicare as well as the new GOP health care/repeal plan. Seminar was really interesting on Friday. We visited Politico and talked with Angela Greiling Keane, who is the deputy technology editor. She's also a Mizzou graduate. My first thought walking into Politico was, 'Oh, so that's why everyone thinks Millennials are taking over.' The newsroom was overwhelmingly young, and I can only assume that other media startups have similar demographics. My other first impression was that the newsroom was not very diverse, which is a problem that Angela talked about in our meeting. She also lamented the fact that they hire too many people from the East and West Coast. It's definitely difficult for a national news organization to keep up with things happening in the Midwest and states outside the mainland when those states are underrepresented among reporters and editors. Angela had great advice regarding job and internship searching. Just a few highlights, in case you were curious: !Editors and hiring managers don't necessarily care if you have your own fancy website. It's great to have, but won't make or break whether you get the job. !If you are from a part of the country that isn't East or West Coast, you might consider playing that up in the interview. !A good way to get into the major newsrooms is to work at trade publications and develop a specialty. After a few years of experience, you will be in a good position to make the switch to a larger organization. 10 !Your social media presence is SO important. Job and internship seekers will want to not only get rid of the obvious things, such as foul language or political activism, but they will also look for more subtle things like only retweeting one political candidate. Generally, they don't care what tweets a job candidate \"likes,\" unless that candidate \"likes\" something super inappropriate. (ex. Ted Cruz Twittergate) Any advice on getting those interviews set up would be greatly appreciated. Thank you, Allison The week of 9/19-9/25 On the project front: !I interviewed Eugene Kiely, director of FactCheck.org. He had a lot of interesting things to say, and the interview really got at the question of whether ratings trivialize fact-checks. He said it's a lot more meaningful to summarize the story with a few words rather than to try and fit the fact-check in a rating system. In other words, labeling a fact-check as \"lacks context\" is, in his opinion, more accurate than a \"half true\" or a \"mostly true\" because the reporting doesn't usually fit into a degree of truth. FactCheck.org does have labels on their checks, but they try to pull phrases from the story that encompass the check. An interesting side note: last week PolitiFact did a similar thing on a check of Jimmy Kimmel's health care claims. Kimmel made four points about the Graham-Cassidy bill; instead of giving each a rating, PolitiFact gave each a summarizing label (e.g. \"Not able to verify,\" \"It could happen\"). CNN loved this and went through each point with our labels. In our Slack channel, the editors said we should do more of this. I will be sure to talk about this with Angie when I interview her. !I also found out why I was having trouble getting in contact with people over the past couple of weeks. Apparently my Mizzou email address is being blocked by certain spam filters. I did some research, and this happens often with university email accounts. Anyway, I got in touch with a couple of reporters over Twitter, so I'm trying to set up those interviews this week. Internship: !I wrote an update on Trump's promise to close parts of the internet to ISIS. I also wrote about the campaign promise to change the vaccination schedule for children, but we'll be publishing that later this week. These two checks gave me trouble because people were not interested in talking about topics that they thought were ridiculous and improbable. One internet/free speech rights organization told me they don't like having to respond every time Trump tweets. My general response was that Trump is in a position of power 11 to accomplish the things he promises (or at least sway public opinion in his favor), so it's still important to tackle the issues. It took a bit longer to report on these two. We had a break from seminar this week, so I'll have an update on that next week. The week of 9/26-10/2 I had a really interesting week. On the project side: !This morning I interviewed Alexandre Pouchard with Les Decodeurs (part of Le Monde). The organization stopped using a rating system several years ago and now just uses summarizing labels such as \"misleading\" or \"taken out of context.\" Pouchard said the reason for this change was because the true-false rating system stopped feeling accurate after a while. Politicians are now more careful with how they present information, which Pouchard thinks is in response to the rise of fact-checking. He said politicians are more likely today to cherry pick statistics. So presenting the fact-checks on a graded truth scale ignores the complicatedness of the claim. !We also talked about the public perception of bias, which he says is a problem for Les Decodeurs on both sides of the political spectrum. The more strongly a reader feels about a political party, the more likely they are to believe Les Decodeurs are biased. He sees just as many reader complaints from the right-wing as from the left. He generally responds by showing the readers links to fact-checks they have done on politicians from other political parties, but if a person is more of an \"activist\" type, they will write him off. Those readers are just a small minority though. During my internship last week, I published promise updates on changing the vaccination schedule for children, banning foreign lobbyists from raising money in U.S. politics and the latest in the GOP effort to repeal Obamacare. This week I'm working on Trump's tax reform promises. On Friday in seminar we got to talk with Marina Walker Guevara, the deputy director of the International Consortium of Investigative Journalists. She had some fascinating stories about the Panama Papers. It was great to learn how journalists from all over the world managed to pull off a year-long project. And on Sunday we watched a filming of Meet the Press. Chuck Todd stayed and talked with us afterwards for a good 15 minutes or so. He had a lot to say about the perception of bias in the media. He feels that journalists need to stop taking the bait every time Trump insults the news media. By getting defensive and defiant, journalists are merely playing into Trump's hand by presenting themselves as Trump's opposition. Chuck said the best thing to do is to not take the criticism personally. 12 That's all for now. Have a great rest of your week! The week of 10/3-10/9 I have to be honest - I didn't really get anywhere on the project front this week aside from transcribing an interview. Next week I have an interview with Alexios Mantzarlis (from Poynter), but I'm struggling a bit to set up interviews with New York Times fact-checker Linda Qiu and Snopes fact-checker Bethania Palma. We have been in touch, however, I haven't confirmed interview times with either one. I will keep bugging them. I've also contacted the Associated Press' media spokesperson, so that should help with getting a fact-checker from there. Last week was pretty busy at my internship. I wrote four tax promise updates: Cut taxes for everyone, eliminate the carried interest loophole, eliminate the marriage penalty and create targeted child care tax credits. I have another tax promise that we're trying to edit and publish today. I also wrote an update on Trump's promise to move the U.S. embassy in Tel Aviv to Jerusalem. The tax promises were difficult because I knew very little about taxes. Now I know a lot about taxes, which is cool. During seminar on Friday we visited NPR and talked with Keith Woods, the vice president of NPR's Diversity in News and Operations. He helped us think about diversity in a much deeper sense than the common characteristics we often think of (race, ethnicity, gender, religion and sexual orientation). Having geographic diversity in a newsroom is also certainly important, and it's a characteristic that our seminar has talked about before. But the one I hadn't thought about was experiential diversity. He said he values having a someone on the team, for instance, who grew up in a household where someone was addicted to opioids. When journalists have personal experience in the issue they're covering, the reporting ends up being more accurate than when the newsroom lacks that diversity. Obviously, Keith can't just ask someone during the hiring process if they have had any personal experience with opioids, but he can recruit from areas that have been greatly affected by opioid use. I thought that was interesting. Have good rest of your week! The week of 10/10-10/16 With the help of Barbara, I made a good deal of progress this week on my project. Yesterday I interviewed The New York Times' Linda Qiu over coffee. She had such a great perspective because she previously worked at PolitiFact and has worked as the only fact-checker for the Times since it started its fact-checking bureau. She made some really interesting points, including: 13 !She gets just as much pushback from readers who believe her fact-checks are biased at the Times as she did at PolitiFact, even though the Times does not use a rating system. !Much of the pushback she receives is from Democrats who don't understand why the \"liberal\" NYT isn't on their side. !Sometimes her readers get so upset with her for being \"biased\" that they say horribly racist and sexist things. The best thing to do is to not respond. !She scrutinizes every word of her stories to make sure there is no language that strikes a certain tone and could be perceived as biased. She said, \"The more boring the story is, the better.\" !She thinks the beauty of rating systems is that the reader can scroll past the reporting if they want, but they always have the option to go back and read how the conclusion was drawn. This morning I have an interview with the former head of the Associated Press fact-checking bureau (thanks to Barbara for helping me get in touch with him). On Friday I'm talking with Alexios Mantzarlis (from Poynter), and on Monday I get to interview Mike Jenner. Last week I wrote promise updates on calling for an international conference to defeat ISIS, moving the Israeli embassy in Tel Aviv to Jerusalem, lowering the corporate tax rate and repealing Obamacare(this one was updated again the next day by Lou Jacobson because Trump announced another health care change late Thursday night, and I was off on Friday). This week I asked for a break on promise updates, so I'm doing a couple of fact-checks instead. In seminar on Friday, we visited The Weekly Standard, a conservative publication. I liked hearing a new perspective from Fred Barnes, the executive editor, though he didn't say much that I hadn't seen before from publications like National Review. However, one thing he said that stuck out to me: Barnes referenced a political theory that the power of the presidency lies in the ability of president to persuade. Presidents accomplish things, not by bullying or intimidation, but by persuading Congress and the American public to get on board with his or her agenda. This ability, Barnes argued, is the thing Trump lacks. But every other president in the past knew how to persuade. The week of 10/17-10/23 Project: I only have one interview left. One of my editors, Angie Holan, was out of town for the first half of the week, but we're aiming to interview today, tomorrow or, at the latest, on Monday. In the past week I interviewed Jim Drinkard, a Mizzou grad and a former editor at the Associated Press's Washington, D.C., bureau. I also talked with Alexios Mantzarlis from Poynter and Mike Jenner from Missouri's best newspaper. All were great interviews. I won't go into depth on them right now, but I look forward to sharing them with you. 14 One note: Alexios disagreed with research on the backfire effect and pointed me to some more recent research showing that people actually do change their minds when presented with factual information that counters their beliefs. I wouldn't go so far to say previous research on the backfire effect is wrong, but I think newer research shows it is more complicated than we assumed. So my question is, if I wanted to add a paragraph or two to my literature review, should I just add that to my final project? Or should I resubmit my project proposal? Internship: I took a break from promise tracking last week and instead wrote a fact-check on U.N. ambassador Nikki Haley's claim that Congress had no say in the Iran deal in 2015. I also helped out with social media and searched for and compiled a list of fact-checkable claims. I'll be publishing another fact-check this week, and then I'm getting back to promises. Seminar: We had the day off on Friday. This week we're going to visit USA Today. That's all for right now. I hope you have a good rest of your week. The week of 10/24-10/30 I'm finished with my interviews, so now I'm thinking about how to write my analysis. My project sought to understand if or how rating systems trivialize fact-checks. The theory is that rating systems push fact-checks into a strategic game frame, as opposed to a factual analysis frame. After my interviews, I don't think the problem is with the rating systems. Though some organizations do not believe in using rating systems, the most compelling evidence to me was that about every journalist I spoke with said they receive complaints of bias, regardless of their use of ratings. Most of these complaints come from readers with strong political leanings. Even when journalists pay extra careful attention to eliminate their voice from fact-checks, they are still accused of bias. What really interests me is that these journalists don't know exactly how to respond to those accusations. This is in part because they receive so many reader complaints via social media and email that they can't keep up. It's also because they don't know how to engage with readers who might not be interested in the journalist's perspective. This isn't to say there isn't an argument for not using rating systems. I just think, if the goal is to focus reader attention on the reporting as opposed to the rating, it doesn't really matter if a rating is used. Is this answer a cop-out? I'd love any suggestions you might have for writing the analysis. Internship: 15 This week I published a fact-check on the opioid epidemic's effect on West Virginia's labor force and a promise update on Trump's plan to change the name of Denali back to Mount McKinley. Seminar: On Friday we visted USA Today in McClean, Virginia. Donna Leinwand Leger, the paper's managing editor told us a bit about the organization and shared stories from her experiences reporting on the War in Iraq, the 2010 Haiti earthquake and the 2004 Indonesian tsunami. Her best advice: Shed your fears, volunteer to report on anything and everything and make sure you talk with experienced reporters about how to prepare before reporting in a war zone or on a natural disaster. The week of 10/31-11/6 I still haven't finished transcribing; I have a couple of more interviews left to get through. This weekend I'll write my analysis, and I'm aiming to get a completed version of my project out early next week. I've been mulling over how to tweak my research questions, and I think I've settled on these: How do fact-checkers try to mitigate the public perception of bias in their reporting and writing? How do fact-checkers respond to accusations of bias from readers? Do rating systems make it more difficult for fact-checkers to avoid those accusations? Those three questions are, I think, broad enough that I can cover the main points of my interviews. Internship: We've been really low on editors over the past week. I published one promise update last week (included in my weekly report 10), and wrote another that we just kind of forgot about and will be publishing today, I think. I've been working on a fact-check over the past couple of days that has been difficult to report. The claim is that the Las Vegas gunman's use of a bump stock actually prevented more casualties in the shooting than would have otherwise happened had he not been able able to fire rapidly. I thought I would find consensus on this among experts, but that's not the case. The other problem is the police are not commenting because they're still working on the investigation, so I'm having trouble coming up with a rating without an authoritative voice on this. Seminar: On Friday we talked with three lawyers who specialize in media law. Most of the conversation centered on the sexual harassment issues that have been in the news. One of the lawyers said she saw this as a sort of revolution in law where public opinion is changing the way these cases get handled, which is a good thing. 16 We also talked about using anonymous sources. Obviously, anonymous sources can cause many legal issues, and the public often distrusts the reporting because it is not transparent. So lawyers urge reporters to only use anonymous sources as a last resort. One thing they said that I thought was really important: Be very careful about what you put in emails, slack messages, texts, etc. Those can be FOIA'd, and if you use any language in describing a story that makes it seem like you or your organization have any biases, that could be used against you in court. I'll be in touch in a few days regarding the project. The week of 11/14-11/21 I wanted to send you an update before we go into my project defense next week. Katherine is going through my analysis, so I will send out the full project once I clean that portion up. Along with that, I'll also send out the location of the room I reserved for the defense. We've had an interesting couple of weeks in seminar. On Nov. 10, we visited the Washington Post and met a few people from the investigative unit. Steven Rich, a Mizzou grad, was there. My biggest takeaway: 99 percent of the time, the things that investigative reports uncover aren't caused my malice, but instead by incompetence. Rich, along with Jeff Leen, the investigations editor, and David Fallis, a deputy editor for investigations, walked us through their reporting process. They explained a concept that I had actually learned from Jacqui Banaszynski - the minimum and the maximum story. They usually do some pre-reporting for a couple of weeks before they get started on a project, and then they figure out what the ideal story (maximum) would look like. They ask themselves what data, documents and sources they could get and whether the story would be worth pursuing if they don't get everything they want (the minimum). I thought it was pretty cool to hear them talk about something I learned at the J-school. On Monday last week, we went to a showing of Fight for the First. Andrea Michell, who was there to interview a couple of the Meet the Press Film Festival documentary makers, said she was impressed with how the students in the film handled themselves. Hooray for Mizzou! I have couple of clips from last week to share: One is a fact-check of the claim that bump stocks prevented casualties in the Vegas shooting (false). The other is on Trump's promise to eliminate wasteful spending in every department. (I might have already shared that link with you guys. I don't remember.) Today we are publishing another couple of promise updates I wrote. We've been trying to get as many promises done as we can before we write our look-back on Trump's first year in office. 17 Evaluation I spent the fall 2017 semester interning for PolitiFact at its Washington, D.C. bureau. I was the first University of Missouri intern PolitiFact had in D.C. Most of time was spent writing stories on President Donald Trump's efforts to meet his campaign promises. I also wrote three fact-checks, helped with social media and found fact-checkable claims for PolitiFact to report on. My supervisors have been pleased with my work, and as a result, they have decided to continue the Washington program internship. In particular, my supervisors said my copy was easy to read and edit, I paid close attention to accuracy and I was easy to work with. In an evaluation written by one of my supervisors, Angie Holan, she called my reporting thorough, my writing \"clear and calm\" and added that I take coaching well. She and others on the PolitiFact team look forward to working with more Mizzou journalism students. Aside from learning the basics of reporting in Washington, the internship taught me to be more aware of my own assumptions. Countless times, I went into a story thinking I knew what I was going to find and ended up finding that I didn't know what was happening nationally as well as I thought. For instance, because Trump had not signed off on any major legislation in his first year, I assumed there would not be much to write about regarding his campaign promises. However, I quickly learned that many things are accomplished without the need for Congressional approval. Trump has halted many regulations, such as regulations spelled out in the Clean Power Plan, through the use of executive action. Political and governmental processes are complicated, which makes accuracy so important when reporting on those topics. When it came to verifying the accuracy of information included in my report, I learned to become extra critical of the information I cite. I got in the habit of double checking every piece of information included in my articles with several different 18 sources, which included people, news reports and documents. I think I learned to become more critical because I had the time to do so at PolitiFact. I didn't have daily deadlines that I absolutely needed to meet. Instead, stories took as long to report and write as they needed to. The reason why I am glad I further developed my critical thinking skills is because I'm still frustrated about the times when I received corrections on stories I wrote at the Columbia Missourian. This semester has helped me improve my accuracy so much. I also learned how to challenge my assumptions when I interviewed several different fact-checkers for my project. Having them talk me through their reporting and verification processes helped me understand what steps reporters, and people in general, should take when they're trying to find the closest version of the truth. It is beyond important to consult an ideological spectrum. (This doesn't necessarily mean placing fringe beliefs on the same level of accuracy as mainstream ideas.) About everyone is going to put spin on something, and only by evaluating the information coming from those many different perspectives can reporters arrive at the facts. The weekly Washington program seminars helped me better understand journalism's role in a democracy. Every news organization we went to serves a different function. Some organizations exist to help us understand the world through a certain ideology. Other organizations have reporters who dive deep into a certain topic, industry or political issue. Sometimes journalism just serves to entertain and help people see why their world is such an interesting place. Between Aug. 21 and Nov. 20, I wrote 24 stories for PolitiFact. The majority of my stories took much longer to report and write than I had assumed they would. When I was interning at The St. Louis Post-Dispatch over the summer, I wrote at least one story per day, on 19 average. This semester, I averaged around one story every other day. In hindsight it makes sense that analytical pieces would take longer to report. Reporting at PolitiFact requires a depth of knowledge about a wide variety of issues. In contrast, beat reporting builds on a journalist's previous reporting. When you don't already have expertise in an issue that you need to provide analysis on, it can mean you have to spend more time learning, which is exactly what I had to do. My experiences this semester have made me wiser and, I hope, a better person. 20 Physical Evidence Trump ties wall funding to government shutdown By Allison Colburn on Friday, August 25th, 2017 at 11:46 a.m. Is President Donald Trump ready to compromise on his plan to make Mexico pay for a border wall? During an Aug. 22 rally in Phoenix, Trump brought up the wall many times but did not say that Mexico will pay for it, as he had repeatedly done on the campaign trail. He did say one thing new to our ears: He threatened a government shutdown if \"obstructionist Democrats\" try to prevent the wall from being built. \"And we are building a wall on the southern border, which is absolutely necessary,\" Trump said. \"Now the obstructionist Democrats would like us not to do it. But believe me, if we have to close down our government, we're building that wall.\" One possible source of funding is making its way through Congress. The House of Representatives on July 27 passed a $790 billion funding bill (H.R. 3219) that includes $1.6 billion for 28 miles of new levee wall and 46 miles of fencing along the U.S.-Mexico border. Congress and the White House must agree on a funding plan before Sept. 30, the start of the next fiscal year. Trump's threat to shut down the government comes a few weeks after a leaked transcript of a phone call between Trump and Mexican President Pena Nieto showed the two leaders butting heads over which country would foot the bill. During the Jan. 27 conversation, Trump asked Nieto to stop saying publicly that Mexico will not pay for the wall because it put Trump in a political bind. Another detail of his promise, the type of wall, has changed over the past several months. Trump said during the campaign that the wall 21 would be \"impenetrable.\" In July he said it would be a \"steel wall with openings.\" He has also brought up the idea of creating a wall with solar panels. At the Phoenix rally, Trump said he's aiming to build \"walls that you can see through in a sense. You want to see what's on the other side.\" H.R. 3219 specifies funding for 32 miles of \"bollard fencing,\" 28 miles of \"bollard levee wall,\" and 14 miles of \"secondary fencing.\" A bollard is an upright steel post. But before any type of border walls or fences are built, the funding bill still needs Senate approval. We continue to rate this promise In the Works. Launch of veterans complaint hotline delayed two months By Allison Colburn on Wednesday, August 23rd, 2017 at 10:42 a.m. Just a few days before President Donald Trump's initiative to create a 24-hour White House complaint hotline for veterans was set to launch, the Department of Veterans Affairs announced it would push back the opening by two months. The reason? The VA said it wants to stop using a third-party vendor to operate the the hotline service and instead staff the service with veterans and VA personnel, according to an Aug. 11 news release. \"The message we've heard loud and clear is veterans want to talk to other veterans to help them solve problems and get VA services,\" VA Secretary David Shulkin said in the release. In the meantime, a pilot hotline that launched June 1 is still available from 8 a.m. to 5 p.m. Eastern Time on Mondays through Fridays. It can be reached at (855) 948-2311. 22 But since its rollout, the hotline has been criticized for not meeting the initiative's original goal \u2014 to ensure complaints about the VA don't go unresponded to by creating a \"private White House hotline.\" The goal is among Trump's 10 steps to address the VA's history of problems. Trump has said he would answer phone callsif no one else was available to address complaints. One veteran, Thomas Fant, told the Military Times that his experience with the hotline led him to feel that the hotline was just another VA hotline rather than a way to reach out to the White House. His complaint was passed on to VA staff and later marked \"resolved,\" even though the complaint was not addressed. \"My impression is it turned out to be another layer of bureaucracy instead of simplifying things,\" Fant said. Haley Scott, deputy director of communications for Iraq and Afghanistan Veterans of America, said she hasn't heard any feedback about the hotline from the organization's members. The hotline cost $190,000 to launch. The department estimated it would take $5,700 per month to operate. The latest estimate to staff the hotline is $150,000 a month. Given this hiccup, it appears we may have jumped the gun on our previous rating of Promise Kept. As we wait to see how things develop, we're moving this promise to In the Works. Coal industry improves slightly as Trump rolls back regs By Allison Colburn on Tuesday, August 29th, 2017 at 3:47 p.m. On the campaign trail, President Donald Trump responded to years of declining jobs in the coal industry with a vow to \"put miners back to work\" by repealing Obama-era regulations. These regulations, Trump argued, were harming coal companies' ability to stay in business. 23 \"They want to be miners, but their jobs have been taken away,\" Trump said at an Aug. 10, 2016, rally in Abingdon, Va. \"And we're going to bring them back, folks.\" Exactly how many coal mining jobs were lost? During Barack Obama's presidency, the number of coal miners employed in the United States hit a high of just under 90,000 in 2012 then descended to a record low of 48,000 in July 2016, according to Bureau of Labor Statistics data. The number began slowly increasing starting in October. When Trump took office, an estimated 50,000 coal miners had jobs. Several months into Trump's first term, we figured it was time to check in on the White House's progress toward restoring the coal industry. A glance at more recent data indicates small improvement since Trump took office: 600 coal mining jobs have been created. (This is down from 800 jobs in May, and it's not nearly as many as the 45,000 new coal mining jobs that Trump falsely claimed in July.) Coal production is also up slightly from where it was at this time last year, and freight rail traffic data show more coal is being shipped by rail in 2017 than in 2016. \"At this point it's probably too soon to say that it's based on any sort of action by the current administration,\" said Matthew Preston, a research director for Wood Mackenzie, which provides consulting and research services on energy industries. He has, however, seen a modest uptick in coal investments in response to regulation rollbacks. Those rollbacks include: Trump, along with congressional Republicans, in February revoked the Stream Protection Rule, which was put into effect just weeks prior on Jan. 19. On March 28, Trump signed an executive order to begin the process of dismantling the Clean Power Plan, an Obama administration policy that sought to limit carbon emissions and placed strict regulations on coal-fired power plants. However, the Supreme Court halted enforcement of the policy a few months after it was announced, and states had until 2022 to comply. 24 Also part of the March 28 executive order, Trump lifted a temporary ban on new coal leasing on federal land. An estimated 40 percent of coal mined in the United States comes from federal land. In another blow to Obama-era environmental initiatives, Trump pulled out of the Paris Climate Agreement on June 1. He argued that the agreement allowed other countries to use coal-fired power plants but banned the United States from doing so. This was not true. Among these actions, Trump has also pointed to the opening of a coal mine in Pennsylvania as proof that his efforts to help the coal industry have produced tangible results. But the mine had been in the making since at least September 2016. Trump has clearly at least taken steps to fulfill his campaign promise. What isn't clear is if rolling back recent regulations can actually bring back the thousands of jobs lost. An April 2017 Columbia University study found that Obama-era environmental regulations were to blame for a 3.5 percent decline of coal production from 2011 to 2016. Coal production overall had declined 33 percent during that time period. This was mostly due to competition from natural gas, lower than expected electricity demand and the collapse of the Asian coal market. The finding was corroborated in a recent study requested by Energy Secretary Rick Perry and released by the Energy Department. \"The repeal of environmental regulations may slow coal's further decline, but it won't bring coal back,\" said Jason Bordoff, a professor at Columbia University and founding director of the school's Center on Global Energy Policy. Bordoff said the recent increase in U.S. coal production has largely to do with a temporary increase in Chinese demand for coal imports. For what it's worth, American Coal Council representative Terry Headley said he thinks Trump's presidency has helped reinvigorate the coal industry. \"I live in West Virginia, and I'm seeing it every day,\" Headley said. \"Coal mines are once again hiring, and some are even contemplating red hats (inexperienced miners) for the first time in years.\" 25 Headley was unable to point to any particular legislative changes or presidential actions that could explain the job increases. Rather, he attributed the boost to Trump's slashing of regulations in general. Whether Trump's regulation rollbacks will bring back the roughly 40,000 coal mining jobs lost since 2012 still remains to be seen, but experts and researchers say that is highly unlikely. Regardless, Trump has at least taken steps toward his goal. We rate this promise In the Works. School choice advocates won't see $20 billion any time soon By Allison Colburn on Thursday, August 31st, 2017 at 5:12 p.m. Among President Donald Trump's education goals was a promise to \"immediately\" allocate $20 billion in federal money toward school choice initiatives. He proposed that the money could be distributed to states with school choice laws and programs, thereby encouraging the other states to get on board. \"School choice\" is an umbrella term for a variety of programs and laws with one essential goal \u2014 to allow public funding to follow K-12 students to a public or private school other than neighborhood school assigned to them based on residential boundary lines. These include voucher programs, charter schools, magnet schools, and tax-credit programs. After his inauguration, Trump has asked Congress to create a national school voucher program and to allot $1.4 billion toward school choice in the FY 2018 budget. Congress has yet to do either, and doesn't seem interested in doing so in the future. The House Appropriations Committee rolled out a spending plan in July that largely ignored the Trump administration's requests to increase 26 charter school spending by $167 million, create a new $250 million private school voucher program and add $1 billion in Title I funding earmarked for school choice initiatives. The House spending plan did include one small win for Trump \u2014 a $28 million increase in charter school spending. (This is not unprecedented. Charter school funding increased by more than $125 million during the Obama administration.) On the surface it might look like charter schools will receive more money should the proposed budget pass; however, a broader look at the agency's budget shows potential deep cuts to other areas of the education spending plan. For instance, both Trump and the House proposed eliminating a more than $2 billion teacher training and class-size reduction program that serves publicly funded schools, including charter schools. Another notable example is the 21st Century Community Learning Centers program, a $1.2 billion after-school program for low-income students. The funding is allotted to schools, both public and private, nonprofits and community organizations that meet eligibility requirements. Trump asked Congress to eliminate this program; the House wants its funding to be reduced by $200 million. In all, the House proposed $2.4 billion in cuts to education. Trump requested a $9.2 billion reduction, which is 13.5 percent of the department's budget. Our ruling Trump had promised to \"immediately\" award $20 billion in federal funding toward school choice. His 2018 budget proposal asked for significantly less, and so far, Congress hasn't taken him up on the offer. Furthermore, Trump's proposed cuts to other education programs would take away funding that would have otherwise gone to schools included in school choice, not just traditional public schools. 27 He could eventually increase funding for school choice in future legislation, but for now we rate this promise Stalled. Trump budget proposal claims balanced budget, CBO disagrees By Allison Colburn on Wednesday, September 6th, 2017 at 4:06 p.m. Prior to taking office, President Donald Trump promised to balance the federal budget by making small reductions in spending each year. \"If we save just one penny of each federal dollar spent on non-defense, and non-entitlement programs, we can save almost $1 trillion over the next decade,\" Trump said in a September 2016 campaign speech at the New York Economic Club in Manhattan. \"If our plan exceeds the 3.5 percent 10-year growth average, then our jobs proposal will actually reduce the deficit.\" Exactly when could Americans expect to see a balanced budget? Trump didn't give a timeframe to Fox News anchor Sean Hannity when Hannity asked earlier that year. Instead, he said it would be done \"fairly quickly,\" but it would take longer than one or two years. The White House took its first steps to balance the budget with its release of the president's FY 2018 spending proposal, in which Trump asked Congress to reduce non-defense discretionary spending by 2 percent every year for the next 10 years as well as reform various entitlement programs. This, combined with proposed regulation rollbacks and tax cuts, would result in a surplus budget by 2027, according to the proposal. The U.S. House of Representatives spending plan, which was released in July, largely mirrored Trump's proposal. Both plans, however, have been criticized by nonpartisan groups for relying on an economic growth model that might be overly optimistic. 28 Trump's proposal assumes an annual gross domestic product growth of 3 percent. In July, the Congressional Budget Office released a report that placed growth at 1.9 percent under Trump's proposal, 0.1 percent higher than the office's baseline. That lower growth number means that by 2027, deficit spending would be closer to $720 billion instead of the $16 billion surplus calculated under the White House proposal. (The House assumed an average 2.6 percent economic growth over the next decade and projected a $9 billion surplus by 2027 in its plan.) The White House budget proposal also neglected to factor in Trump's promise to lower individual and corporate taxes, the nonpartisan Committee for a Responsible Federal Budget pointed out in a statement. \"The budget balances on paper - and having a specific fiscal goal is an important first step,\" said the committee's president, Maya MacGuineas. \"But it only achieves that goal by relying on incredibly rosy economic growth assumptions along with very aggressive and unrealistic future cuts while omitting a potentially extremely costly tax reform plan.\" A final budget must be agreed on by Congress and the White House before Oct. 1. Whether or not the budget will ultimately balance depends on several factors including tax legislation, actual economic growth and how much Congress is willing to cut in spending over the next few years. But independent analysis of the proposed budgets finds fault with the budgets' overly optimistic assumptions about future tax revenue. For now, we rate this promise Stalled. Future of Medicare funding uncertain under Trump presidency By Allison Colburn on Wednesday, September 13th, 2017 at 11:09 a.m. 29 President Donald Trump's vow to save Medicare from budget cuts is facing a snag as the 2018 budget makes its way through Congress. The promise, along with maintaining current funding levels for other entitlement programs, was one of Trump's earliest campaign pledges. \"Save Medicare, Medicaid and Social Security without cuts. Have to do it,\" he said in his presidential announcement speech. The 2018 White House budget proposal released in May left Medicare benefits largely untouched compared with Medicaid, which would see a more than $600 billion decrease over 10 years compared to current spending levels. Still, Medicare spending would decrease by more than $50 billion in the next decade compared with current levels. Though the proposed budget doesn't spell out large direct cuts to Medicare, cuts to other programs would indirectly affect the senior health insurance program. For instance, the budget included eliminating the State Health Insurance Assistance Program, which provides Medicare beneficiaries with counseling and assistance to navigate the health care system. However, those cuts won't necessarily happen because the White House budget proposal is more of a wish list that the president gives to Congress, where both the House of Representatives and the Senate must create and agree on a final budget to be signed by the president. The House's current budget resolution, which was released in July, asked to cut Medicare by $487 billion between 2018 and 2027. Much of this would be done by turning Medicare into a voucher-like program, increasing income-related premiums and limiting medical malpractice litigation by capping attorney fees and awards, according to the plan. Again, that $487 billion cut won't necessarily make it into the final budget, especially since the House resolution currently doesn't contain legal language that would help ensure the full cut through a special legislative process called reconciliation. Even though the budget resolution has a line that calls for reduced Medicare spending, it doesn't actually include a way to make that happen, said Marc Goldwein, the senior vice president of the Committee for a Responsible 30 Federal Budget. He said Congress could end up making some moderate cuts to Medicare this year, but \"they're clearly not prioritizing it.\" Congress and the White House must agree on a budget before Oct. 1 or pass a continuing resolution to avoid a government shutdown during budget negotiations. But even if Medicare doesn't undergo cuts in the next budget, it's still possible that the program could be affected by an Obamacare repeal or replacement. \"It's unclear given the uncertainty surrounding dealings in Washington right now,\" said David Lipschutz, an attorney with the Center for Medicare Advocacy. \"But we are certainly not out of the woods.\" An effort to repeal portions of the health care law died on the Senate floor on July 28 when Republican Sen. John McCain voted against it, but that hasn't stopped the GOP from trying again. Another Obamacare partial repeal proposal by Sens. Bill Cassidy, R-La,, Lindsey Graham, R-S.C., and Dean Heller, R-Nev., has the support of McCain and Trump, according to press reports. A process that temporarily allowed health care legislation to advance in the Senate with 50 votes rather than the usual 60 votes -- Republicans' best chance at passing a health care bill -- will end on Sept.30. Lipschutz said the upcoming deadline could pressure Republicans to hastily pass legislation on health care. If a new partial repeal looks anything like past efforts to change health care, Medicare would likely be affected by cuts to Medicaid spending, one-third of which goes to low-income seniors who are enrolled in both Medicare and Medicaid. (The Congressional Budget Office projected over $800 billion in cuts to Medicaid by 2026 in its analysis of the Obamacare Repeal Reconciliation Act of 2017.) The Commonwealth Fund calculated that, under the previous repeal bill, around 11 million Medicare beneficiaries would lose coverage for long-term services under Medicaid, such as nursing home care. Our ruling 31 The overall change to Medicare spending will depend on what makes it into the final 2018 budget and what happens with Obamacare. But current legislative proposals, some of which have garnered Trump's support, plan for funding cuts that affect Medicare in some way, whether directly or indirectly. Trump has not signed either into law yet, so for now we rate this promise Stalled. GOP senators announce 'final' chance for Obamacare repeal By Allison Colburn on Thursday, September 14th, 2017 at 12:01 p.m. On the same day that Sen. Bernie Sanders introduced a single-payer health care bill, four senators on the Republican side of the aisle unveiled what they called their last attempt to roll back portions of the Affordable Care Act. The bill, spearheaded by Sens. Bill Cassidy, R-La., Lindsey Graham, R-S.C., Dean Heller, R-Nev., and Ron Johnson, R-Wis., would replace federal funding currently being spent on Medicaid expansion, tax credits and subsidies with block grants, which state leaders could decide how to allocate. It would also end the medical device tax as well as Obamacare's individual and employer mandates. Graham, in reference to Obamacare repeal efforts, told congressional Republicans during a Sept. 13 press conference, \"This is your best and only chance to make it happen.\" To pass the bill, the senators face a fleeting window of time. A temporary process that Republicans have been relying on to advance health care legislation in the Senate with 50 votes rather than the usual 60 votes will end on Sept. 30. That process didn't quite work on July 28, when a bill to repeal portions of Obamacare died on the Senate floor after Republican Sens. John McCain, Susan Collins and Lisa Murkowski voted against it. (McCain was the final deciding vote.) President Donald Trump applauded the new bill in a statement released after the press conference. 32 \"I applaud the Senate for continuing to work toward a solution to relieve the disastrous Obamacare burden on the American people,\" Trump said. \"My administration has consistently worked to enact legislation that repeals and replaces Obamacare, and that can pass the Senate and make it to my desk.\" The bill is not a full repeal of Obamacare. It is not yet clear if the bill has enough votes to pass the Senate, so for now we continue to rate this promise Stalled. Latest partial repeal effort dies before deadline By Allison Colburn on Thursday, September 28th, 2017 at 5:27 p.m. Another Senate attempt to repeal portions of the Affordable Care Act has ended, this time before going to a vote. Senate Majority Leader Mitch McConnell announced a GOP-led health care bill would not go to a vote after three Republican senators said the bill did not have their support. In July, a similar partial-repeal effort died when Sens. John McCain, Susan Collins and Lisa Murkowski voted against it. The latest bill, spearheaded primarily by Sens. Bill Cassidy, R-La. and Lindsey Graham, R-S.C., would have taken funding that is used under current law for Medicaid expansion and insurance subsidies and used it to fund block grants to states. A preliminary analysis by the Congressional Budget Office said the bill would have reduced the deficit by $133 billion by 2026 as well as resulted in millions more uninsured people compared to the current health care law. McCain and Collins, along with Sen. Rand Paul, R-Ky., publicly voiced their opposition to the Graham-Cassidy bill. Proponents of the bill only had a few weeks to gain enough support before a temporary process that allows health care legislation to pass in the Senate with 50 votes rather than the usual 60 ends on Sept. 30. Graham called it the GOP's \"best and only chance\" to meet its goal of repealing Obamacare. 33 However, that might not be true. After it became clear that the Graham-Cassidy bill was going to fail, President Donald Trump told reporters to expect new health care legislation to repeal portions of the Affordable Care Act in early 2018. Until we see new movement on his promise to repeal Obamacare, we'll continue to rate this Stalled. Trump's executive action could erode marketplace built under Obamacare By Allison Colburn on Thursday, October 12th, 2017 at 3:58 p.m. Attempts to repeal portions of the Affordable Care Act have failed in the past several months, leading President Donald Trump to issue an executive order expanding access to cheaper, less comprehensive health care plans. The order, signed on Oct. 12, instructs federal agencies to remove certain limitations on \"association health plans\" and expand the availability of short-term health plans, both of which can skirt certain minimum coverage requirements included in the Affordable Care Act and state laws. These changes will not immediately take effect; federal agencies will have to figure out how to act on Trump's directions. The executive action orders agencies to explore ways in which the government can expand access to short-term health plans, which are available to individuals on a three-month basis and meant for people who are in-between health care coverage plans. Under the instructions, association health plans would be allowed to sell plans across state lines; those plans allow small businesses to band together to create cheaper health care plans that offer fewer benefits. The order was intended to create more options for individuals seeking health insurance and help stimulate competition among insurers. Some health policy advocates worry that it could disrupt the insurance marketplace in a way that 34 would drive up health care costs for elderly individuals and people with medical conditions. Chris Hansen, the president of the American Cancer Society Cancer Action Network, criticized the action in a statement, saying the changes would create a rift in insurance coverage. \"If younger and healthier people leave the market, people with serious illnesses like cancer will be left facing higher and higher premiums with few, if any, insurance choices,\" Hansen said. \"Moreover, those who purchase cheap plans are likely to discover their coverage is inadequate when an unexpected health crisis happens, leaving them financially devastated and costing the health care system more overall.\" The National Association of Insurance Commissioners also raised concerns about the action, saying it could hurt \"already fragile markets.\" It will be months before changes are seen in the marketplace. Trump has faced several hurdles in his plan to repeal Obamacare since taking office. Congress was unable to pass a repeal bill before a temporary rule allowing the Senate to move health care legislation through the chamber with only 50 votes ended on Sept. 30. In an Oct. 10 tweet, Trump signaled he would use executive powers to move forward on his goal, saying: \"Since Congress can't get its act together on HealthCare, I will be using the power of the pen to give great HealthCare to many people - FAST\" He dealt another blow to Obamacare regulations on Oct. 6, when his administration expanded employers' ability to exclude coverage for contraceptivesin their health insurance plans. \"Today is only the beginning,\" Trump said during the most recent executive order signing. \"In the coming months, we plan to take new measures to provide our people with even more relief and more freedom.\" However, Trump can only accomplish so much with executive orders. He might be able to chip away at certain Obamacare provisions, but to fulfill his campaign promise, he will have to get Congress to pass legislation. We continue to rate this Stalled. 35 In wake of London train attack, Trump doubles down on campaign promise By Allison Colburn on Thursday, September 21st, 2017 at 10:49 a.m. Shortly after news broke of the Sept. 15 Parsons Green bombing in London, President Donald Trump reiterated his campaign promise to close down portions of the internet to curb the spread of terrorism. \"Loser terrorists must be dealt with in a much tougher manner,\" Trump said in a tweet. \"The internet is their main recruitment tool which we must cut off & use better!\" Prior to the election, he suggested U.S. antiterrorism officials would work with leaders in the technology industry to shut down parts of the internet that terrorist groups such as ISIS, or ISIL, use to recruit and share information. U.K. Prime Minister Theresa May shared similar views in June after a different terrorist attack occurred on the London Bridge. Google, Twitter, Facebook and Microsoft responded to criticisms by vowing to improve detection of extremist content. But cracking down on unwelcome or violent speech has proven to be difficult for those companies. A ProPublica investigation released in June found that Facebook's algorithm for identifying hate speech wound up removing some posts for nonsensical reasons and allowing other posts that should have been removed. Likewise, Twitter says it has shut down nearly 1 million suspected terrorist accounts since August 2015, but the company has struggled to find the \"magic algorithm\" to identifying terrorist content. However, crackdowns on terrorist-related content appear to merely shift the problem elsewhere. Recent research shows that suspected terrorists have moved their online presence from Twitter to Telegram, a messaging app that was created in 2013. The extent of the U.S. government's power to shut down online terrorist propaganda is unclear. When former Federal Communications Commission Chairman Tom Wheeler was questioned on the topic in November 2015, days after a mass shooting took place at a concert in Paris, Wheeler responded 36 that the commission doesn't have the legal authority to shut down individual websites. Even if legislation were passed to ban or block terrorist propaganda online, First Amendment rights could stand in the way. In addition, United States law generally protects internet service providers from legal responsibility for what the companies' users say or do on the internet, a marked difference from European countries such as France, which holds internet service providers responsible for removing terrorist propaganda. Even though internet providers and websites have certain rights, there are still legal methods of taking down online content, according to Daphne Keller, director of intermediary liability at the Stanford Center for Internet and Society. U.S. Immigrations and Customs Enforcement has taken some of those legal avenues in the past to remove sites with child sex abuse material or with large-scale piracy. \"These kinds of blocks have been condemned by human rights bodies because they are poorly targeted and often take down legal speech with the illegal,\" she said. \"I have not heard of this being done for terrorism, though it might be.\" There might also be legal ground to compel third-party platforms, such as Twitter and YouTube, to remove content uploaded by known terrorists and terrorist organizations, but Keller said this has not yet been court-tested. Meanwhile, Secretary of State Rex Tillerson recently accepted $60 million from Congress to continue the United States' counter-Russian and terrorist propaganda efforts (after sitting on the funding as lawmakers pressured him to take it). For Trump's part, the president signed a joint statement among G7 leaders in May to put pressure on technology companies to eliminate online extremism. Trump has reiterated this promise as president with subsequent terror attacks, but the chances of shutting down the internet don't look great in the United States based on stumbling efforts so far by tech companies and the First Amendment's speech protections. We rate this promise Stalled. 37 Trump's HHS secretary, in charge of vaccination schedule, has no clear stance By Allison Colburn on Tuesday, September 26th, 2017 at 4:05 p.m. Before and during his campaign, President Donald Trump repeatedly linked vaccines to autism, despite the fact that the claim has been debunked. At a 2015 Republican presidential candidate debate, CNN anchor Jake Tapper asked Trump how, if elected, he would handle overseeing the Centers for Disease Control and Prevention and the National Institute of Health, which both disagree with his stance on vaccinations. Trump responded: \"Autism has become an epidemic... I am totally in favor of vaccines. But I want smaller doses over a longer period of time.\" When it comes to the vaccination schedule, the White House has limited control. Federal recommendations on the schedule are chosen through the CDC's Advisory Committee on Immunization Practices. Members on the committee must go through a rigorous application process and are ultimately appointed to four-year terms by the U.S. Health and Human Services Department secretary, a position currently held by former U.S. Rep. Tom Price. Even though the CDC's immunization schedule could possibly have some influence on state laws, the schedule and other CDC recommendations are not federal requirements. As of February 2017, all states require immunizations as a condition of enrollment in public school and, in many cases, private school. However, depending on the state, parents can exempt their children from immunizations for medical or philosophical reasons. In response to a question about implementing federal immunization requirements during his tenure, Price acknowledged in March that state governments tend to make those decisions, but evaded a question about whether vaccines should be required. 38 \"I believe it's a perfectly appropriate role for the government -- this happens, by and large, at the state government level, because they're the ones that have the public health responsibility -- to determine whether or not immunizations are required for a community population,\" Price said during a CNN town hall event. It is unclear where Price stands on vaccines. He agreed during his confirmation hearing that science has debunked the autism link, but he has also been a member of the Association of American Physicians and Surgeons, a group that believes in a link between vaccines and autism. Because the federal government doesn't decide state immunization laws, changes to the CDC vaccination schedule won't necessarily result in any changes to vaccination requirements. Price could end up having some influence on the vaccination schedule through his Advisory Committee on Immunization Practices member appointments. But terms on the 15-member committee are staggered, meaning Price could only select a few members per presidential term. It will be difficult for Trump to implement this promise, and we've seen no indication that Trump or Price intends to aggressively push for it. Since we've found no action on this promise, for now we rate it Stalled. No action yet on Donald Trump's promise to regulate foreign lobbying in elections By Allison Colburn on Thursday, September 28th, 2017 at 5:25 p.m. Among President Donald Trump's six-point plan to change the way politicians raise money was a pledge to prevent foreign lobbyists from raising money in United States elections, which he said he would accomplish in his first 100 days in office. The promise came after a chain of Clinton campaign emails were hacked and released online in October 2016. Some emails showed campaign aides debating whether to accept donations from U.S. citizens who are registered 39 foreign lobbyists. Ultimately, they agreed that the campaign would take the money and deal with possible public criticism. Days later, Trump vowed at a campaign rally in Green Bay, Wisc.: \"I'm going to ask Congress to pass a campaign finance reform that prevents registered foreign lobbyists from raising money in American elections and politics.\" It is already illegal for foreign nationals to donate in American elections, but U.S. citizens can lobby on behalf of a foreign entity. Under the Foreign Agents Registration Act (FARA), lobbyists representing foreign interests must disclose their relationship to the foreign governments as well as disclose any financial activity. Whether FARA is actually enforced is an entirely different matter. A 2016 Department of Justice audit found that prosecutions and enforcement of the act are rare. From 1966 to 2015, the department only brought seven criminal cases relating to FARA. In a notable recent case, Trump's former campaign manager, Paul Manafort, retroactively registered as a foreign agent after news reports linked himto lobbying done on behalf of a Ukrainian governing party. Because FARA enforcement is sparse, it's tough to get a true sense of how many lobbyists raising funds for campaigns or political causes are lobbying on behalf of foreign interests, according to Lydia Dennett, an investigator with the Project on Government Oversight. A simple ban on foreign lobbyist fundraising would likely make the campaign funding process less transparent. \"This kind of lifetime ban sounds good on its surface, but it could deter people from registering\" as a foreign agent, Dennett said. If Trump really wants to limit foreign money going toward elections, it would also mean closing up certain legal loopholes that allow people to donate in elections through shell companies and political nonprofits, said John Wonderlich, the executive director of the Sunlight Foundation, an organization that advocates for open government. Portions of the Citizens United Supreme Court case would have to be overturned and enforcement of lobbying laws would need to increase. In a Jan. 28 executive order, Trump partially met other government ethics promises. The order prohibited White House Administration officials from 40 lobbying for five years after their service, which was another goal in his six-point plan. No action on the promise to ban foreign lobbyist fundraising has been taken so far. Until we see some movement on this, we'll continue to leave it unrated. Trump's child care promise takes new approach in tax framework By Allison Colburn on Thursday, October 5th, 2017 at 2:57 p.m. As part of a plan to help families afford child care expenses, President Donald Trump campaigned on expanding assistance for parents paying for the care of others in their household. \"For many families in our country, child care is now the single largest expense \u2014 even more than housing,\" Trump said at a September 2016 campaign speech in Aston, Pa. \"Yet, very little meaningful policy work has been done in this area ...There is no financial security.\" One portion of Trump's Child Care Plan proposed allowing working parents to deduct from their taxes child care expenses for up to four children and elderly dependents. The deduction would not extend beyond the \"average cost of care\" for the parent's state of residence and would not apply to a person making more than $250,000 per year. The plan also suggested offering child care spending rebates through the Earned Income Tax Credit, which is a benefit for low- to moderate-income earners. The framework for the Trump administration's proposed tax legislation, released on Sept. 27, takes a different approach. Instead of basing deductions and tax credits on child care costs, the framework proposes increasing the Child Tax Credit from the current amount of $1,000 and raising the current income threshold for which the credit phases out. The plan does not specify how much the credit would increase or which incomes level would qualify. The framework also creates a new $500 credit for non-child dependents such as the elderly or disabled. 41 Those expanded credits could certainly help taxpayers afford their child care costs, but no part of the framework bases deductions or credits on child care expenses, as Trump had initially proposed. Furthermore, the framework does not include any changes to the Earned Income Tax Credit. Trump's initial plan to help parents offset the cost of child care based on expenses incurred hasn't made its way into the current tax policy plan. But the framework at least expands the Child Tax Credit and includes a new credit aimed at helping people afford caring for dependents. Since at least some action has been taken on this promise, for now we'll rate it In the Works. Tax plan appears to favor wealthiest, no guarantee of cuts for all By Allison Colburn on Thursday, October 5th, 2017 at 3:12 p.m. President Donald Trump campaigned on a tax reform plan that made one thing clear: If elected, Americans would see smaller portions of their paychecks going to the federal government. The day before the 2016 West Virginia Republican primary, Trump told CNN's Chris Cuomo, \"Everybody is getting a tax cut, especially the middle class.\" One caveat, Trump said, was that he might have to raise taxes on the wealthy. \"I'm not going to allow it to be increased on the middle class,\" he added. The Trump administration's 2017 tax legislation framework, released on Sept. 27, proposes deep rate cuts, fewer taxable income brackets, increases to the standard deduction and eliminating several tax breaks. Some details -- necessary to get an exact picture of how proposed legislation would affect each individual and household -- were not included in the plan, such as the thresholds for the income brackets. 42 However, by filling in the gaps with details from previous proposals by Trump and other Republican leaders, the Tax Policy Center was able to publish a preliminary analysis that projected initial across-the-board income tax decreases followed by increases on certain income levels within the next decade. By 2027, nearly 30 percent of individuals making between $50,000 and $150,000 and 60 percent of people making between $150,000 and $305,000 would see tax increases, the analysis found. The center noted that the top 1 percent of earners would receive about 80 percent of the tax benefit. This income group would see its after-tax income increase 8.5 percent, whereas the bottom 95 percent of earners would see an average 1.2 percent increase. Taxpayers with certain types of family and income characteristics could also see their taxes increase, partly due to the proposed elimination of state and local tax deductions. Treasury Secretary Steven Mnuchin said in an interview on ABC's This Week that committees working on the legislation are trying to figure out a way to prevent states such as California and New York from drastic federal tax hikes. When asked whether he could guarantee that all middle class individuals will receive a tax cut, Mnuchin acknowledged that he could not. Final details of the plan have yet to be determined, but early analysis shows that the current framework struggles to ensure tax cuts for everyone. It also appears to favor cuts for wealthier individuals and could increase taxes on some middle class groups. We'll see if the actual tax legislation falls in line with Trump's promise, but for now we rate this Stalled. Proposed corporate, small business tax rates don't fall to 15 percent 43 By Allison Colburn on Wednesday, October 11th, 2017 at 11:36 a.m. President Donald Trump promised during his campaign to cap the corporate tax rate at 15 percent from its current maximum rate of 35 percent. Now in office, he might settle for something in between. The White House's 2017 tax code framework \u2014 which was put together by the Trump administration, the House Committee on Ways and Means and the Senate Committee on Finance \u2014 proposes cutting the corporate tax rate to 20 percent. Also included in the plan is a new provision that would limit the maximum tax rate on income earned by \"small businesses\" (defined in the framework as sole proprietorships, partnerships and corporations with no more than 100 shareholders). These businesses, often referred to as \"pass-through entities,\" currently do not pay corporate taxes. Rather, the profits \"pass through\" the business and are taxed at individual rates, which do not exceed 39.6 percent. The framework calls for capping the tax rate of income earned by pass-through businesses at 25 percent. Trump's original plan was to also tax these types of businesses at a 15 percent rate. (His campaign's tax plan is archived here.) In May, the Tax Policy Center estimated a 10-year federal revenue loss of between $390 billion and $660 billion if the United States cut the rate for pass-through income taxes to 25 percent. Between 85 and 88 percent of the net tax benefit would go to the upper 1 percent of pass-through income earners, depending on whether the legislation uses a broad or narrow definition of pass-through income. It's worth noting that Trump conducts business through more than 500 pass-through entities, according to a document obtained and published by the New York Times. Even though his initial plan to tax all businesses, large and small, at no more than a 15 percent rate didn't quite pan out, Trump is still pushing for significant business tax cuts. It looks like he is headed for 44 a compromise, but until we see legislation on this, we'll continue to rate this In the Works. Tax plan calls for end to marriage penalty, but lacks specifics By Allison Colburn on Thursday, October 5th, 2017 at 3:02 p.m. Donald Trump promised during his presidential campaign to help the working class by eliminating a feature of the tax code that charges some married couples at a higher rate than if they were to file taxes individually. Because married couples are taxed differently than single individuals, payments can result in either a penalty or a bonus. When both people in a marriage make similar incomes, the combined incomes can push the couple into a higher tax bracket in which they pay more. Couples earning higher incomes tend to be more likely to receive penalties than bonuses. The majority of Americans receive marriage bonuses. To eliminate the penalty, Trump \u2014 in his campaign's tax plan \u2014 proposed making the taxable income of an individual filer exactly half of that of a married couple. In other words, a single person making between $50,001 and $150,000 would be taxed at the same rate as a couple filing jointly with a combined income of between $100,001 and $300,000. The Trump administration's 2017 tax framework, which was released on Sept. 27, calls for eliminating instances in which married couples receive fewer benefits than if they were to file separately. If included in the final tax legislation and passed into law, the standard deduction for married and single taxpayers would amount to $24,000 and $12,000, respectively. It also proposed eliminating the marriage penalty in the Child Tax Credit. 45 However, the framework does not spell out how it would eliminate the marriage penalty from taxable income rates, as Trump's campaign tax plan had done. We'll wait to see if Trump's initial tax promise makes it into the final legislation. For now, we'll rate this In the Works. No international conference on ISIS in sight By Allison Colburn on Friday, October 13th, 2017 at 11:44 a.m. As part of his counterterrorism plan, President Donald Trump promised he would convene a conference between world leaders to help develop a coordinated plan to defeat ISIS. \"As president, I will call for an international conference focused on this goal,\" Trump said during a campaign speech in Youngstown, Ohio. \"We will work side-by-side with our friends in the Middle East, including our greatest ally, Israel. We will partner with King Abdullah of Jordan, and President Sisi of Egypt, and all others who recognize this ideology of death that must be extinguished.\" No such conference has taken place, and the White House didn't respond to our request for a status update. So we took a look at what Trump has done so far to help bring international counterterrorism efforts to the same table. In the past year, Trump has met with world leaders on dozens of occasions to discuss terrorism and other global issues, including meetings with King Abdullah II and Egyptian President Abdel Fatah al-Sisi. He also reaffirmed the United States' commitment to counterterrorism at the G20 summit in July and has pushed NATO to increase its counterterrorism spending and efforts. 46 In May, Trump toured Europe and the Middle East, where he called for international cooperation to fight terrorism. During his stop in Riyadh, Trump signed a $110 billion arms deal with the Saudi Arabian government and, along with Sisi and Saudi King Salman bin Abdulaziz, inaugurated the Global Center for Combating Extremist Ideology, which monitors terrorist propaganda. These regular conferences and meetings with foreign leaders are typical for a U.S. president. But we haven't yet seen any initiative to bring world leaders together for a conference to discuss terrorism. We'll look for any updates on this promise, but for now we it Stalled. Trump signals step back from Israeli embassy plan By Allison Colburn on Monday, October 9th, 2017 at 12:46 p.m. President Donald Trump further distanced himself from his campaign promise to move the U.S. embassy in Israel from Tel Aviv to Jerusalem. During an interview on the Trinity Broadcasting Network, Trump told former Arkansas Gov. Mike Huckabee that he wants to first try to make peace between Israel and Palestine. \"I want to give that a shot before I even think about moving the embassy to Jerusalem,\" Trump said on the Christian network interview. \"If we can make peace between the Palestinians and Israel, I think it'll lead to ultimately peace in the Middle East, which has to happen.\" In June, Trump signed a waiver on the Jerusalem Embassy Act of 1995, which mandates that the embassy be moved to Jerusalem by 1999. Past presidents have also waived the act out of concern that it would derail peace talks. A White House statement on the waiver said Trump still intends to follow through on his promise. It was not a matter of \"if that move happens, but only when,\" the statement said. 47 David Friedman, the U.S. ambassador to Israel, echoed the White House's long-term strategy during an interview on TBN a few days before Trump's sit-down with Huckabee. \"The embassy will move. It's not if, but when,\" Friedman said. \"And I am convinced that during his term, the United States will recognize Jerusalem as the undivided and eternal capital of the state of Israel.\" When Huckabee asked Trump, in light of Friedman's comments, for a timeframe on the move, Trump said the decision would happen in the \"not too distant future.\" Trump has not backed off of his promise, but his recent remarks on the subject show he is facing substantial roadblocks and cannot say when the embassy will move. We'll continue to rate this Stalled. Haley wrongly says Congress had no input on Iran nuclear deal By Allison Colburn on Thursday, October 19th, 2017 at 12:13 p.m. Defending President Donald Trump's decision to decertify the Iran nuclear deal, United Nations ambassador Nikki Haley said Congress now has a voice on the issue that it didn't have in the past. Trump's decision allows Congress to potentially kill the agreement or tack on new conditions. \"He's saying to Congress, can we make it better?\" Haley told ABC's George Stephanopoulos on an Oct. 15 broadcast of This Week. \"And I think that his engagement with Congress is something that never happened under President Obama. They were never allowed to debate it. They were never allowed to discuss it. So, now Congress is going to be fully engaged on the threats of Iran.\" This was an early criticism of the agreement. After the United States, Iran and other foreign governments came to an agreement on the framework for the Iran deal, both Republicans and Democrats in 48 Congress appealed to Obama to let them have a say in it before the final deal was reached. Here, we are fact-checking Haley's claim that Congress was \"never allowed\" to debate or discuss the agreement. Congressional responsibility in the Iran deal Much of the responsibility for U.S. foreign policy falls under the authority of the executive branch. Congress does play a significant role, however, in foreign trade and commerce, immigration, foreign aid, the defense budget and any declarations of war. The Senate authorizes treaties and confirms the president's cabinet nominees. To avoid needing Senate approval for an agreement with a foreign power, the president can simply avoid calling the agreement a treaty. The Obama administration said the Iran deal was neither a treaty nor an executive agreement. Instead, the State Department said in a letter that the deal \"reflects political commitments\" between the seven nations involved. When the president negotiates a deal that is not deemed a treaty, Congress -- if it wants a say on the deal -- must convince the president to give the legislative branch the power to approve or block the final deal. That's exactly what Congress did when it passed the Iran Nuclear Agreement Review Act of 2015, a bill that had bipartisan support and allowed Congress the right to review any agreement reached in the negotiations. Obama initially threatened to veto the bill but did not. Senators considered a separate, and ultimately unsuccessful, measure that would have given them the the power to block the agreement through a resolution of disapproval. A procedural vote on the resolution fell short of the 60 votes needed to override a Democratic filibuster. Despite the resolution's failure, by passing the Iran Nuclear Agreement Review Act, Congress was able to have some authority and say in the final agreement. Sen. Bob Corker, R-Tenn., who spearheaded the bill, has touted the legislation for taking \"power back from the president\" and forcing the executive office to be transparent. 49 \"There's no question the prior administration made every effort to bypass Congress and implement the agreement without congressional review or approval,\" Corker said in an emailed statement. \"That is why we overwhelmingly passed INARA, which required the administration to submit the full details of the agreement to Congress and established a process for a debate and vote on the deal.\" It should also be noted that Obama administration officials went on the record about the Iran deal during congressional hearings and briefings, allowing members of Congress to bring up questions and concerns with the White House in a public debate setting. Further, the review act imposed a requirement that the president recertify the deal every 90 days. In other words, every three months the president must ensure the following: !Iran is abiding by the rules of the agreement, !Iran hasn't taken action to advance its nuclear weapons program, !the waiver of sanctions on Iran are still appropriate. \"This kind of ongoing management I think is unusual and represented quite a compromise by President Obama,\" said John Glaser, the director of foreign studies at the libertarian-leaning Cato Institute. Glaser pointed out that the Obama administration would not have been able to handle \"all of the subtlety, secrecy, and nuance that was required\" to negotiate the Iran deal if it had involved Congress from the beginning. Haley, we should note, backtracked a bit in an interview on Meet The Press, when moderator Chuck Todd pointed out that the reason the Iran deal has a certification process is because Congress added constraints. Haley responded: \"And Congress did that because President Obama didn't give them the authority to be a part of that decision. So they did 50 it to try and control the situation and not let it get to a bad problem.\" She didn't add similar caveats during the ABC interview. Our ruling Haley said Congress was never allowed to debate or discuss the Iran nuclear agreement while Obama was in office. Though Congress had to fight for the right to disapprove of the deal, the passage of the Iran Nuclear Agreement Review Act of 2015 allowed Congress to not only vote on the deal but to also hold public hearings and debate. The Senate ultimately did not have the votes to block the deal, but the act included a requirement for the president to frequently monitor Iran's progress in meeting the agreement's conditions. So Congress did have input, even if Obama initially tried to avoid it. We rate this claim Mostly False. Opioid epidemic likely hurting West Virginia's workforce By Allison Colburn on Friday, October 27th, 2017 at 10:37 a.m. The Democratic senator from West Virginia \u2014 where the opioid overdose death rate ranked highest in the nation in 2015 \u2014 connected the state's opioid use with its battered workforce. Sen. Joe Manchin told MSNBC's Kasie Hunt that the opioid crisis is destroying families and wrecking the state's economic future. \"I've got the greatest workers in the world,\" Manchin said on Oct. 22. \"But I'm down to around 50 percent of the adult workers who are actually working now because of addiction or conviction.\" We wondered to what extent opioids are to blame for low employment in West Virginia. Manchin's office told us he learned about the effect opioid abuse has on the state's employment through \"hundreds of meetings with business executives, state workforce and labor experts, at his job fairs 51 and with community leaders across the state.\" The office also clarified Manchin's comment, saying people who struggle with addiction or have been convicted in crimes related to opioid use in the past often have trouble getting jobs. Experts agreed that the opioid crisis affects employment rates in West Virginia, but they don't know how much. Measuring the workforce Manchin is about on the mark when he says about half of West Virginia's adults are employed. What's less certain is the role opioid abuse plays. To measure this, the Bureau of Labor Statistics looks at two key figures: the employment-population ratio (the percentage of people over the age of 16 who are employed) and the labor force participation rate (the percentage of people over the age of 16 who are either employed or actively looking for a job). The latest estimates place West Virginia at a 50.4 percent employment-population ratio and a 53.1 percent labor force participation rate in September. By comparison, the United States' employment-participation ratio in September was at 60.4 percent and the labor force participation rate was 63.1 percent. (Because the labor force doesn't typically include students and retirees, college towns or populations with more elderly individuals might sometimes appear to have lower workforce participation.) West Virginia has historically had one of the lowest labor participation rates in the United States. Since the late 1970s, as far back as the Bureau of Labor Statistics' data on labor participation rates goes, the state's rate has remained below 58 percent. Similarly, the employment-population ratio has not exceeded 55 percent. A 2015 study of West Virginia's labor participation rate conducted by the West Virginia Center on Budget & Policy found that the state's higher-than-average elderly population, percentage of people on work disability and poor overall health were major factors in the 52 participation rate. In addition, lower rates of educational attainment beyond a high school degree had prevented young workers from obtaining jobs that require more education. Where does that leave opioid addiction? Experts say that's an unanswered question. \"While I'm sure addiction and the opioid crisis have played a role in hurting West Virginia's workforce, I'm not sure you can attribute much of the state's decline to it,\" said Sean O'Leary, a senior policy analyst with the center. He also noted that the state's recent decline coincides with the national recession. The opioid epidemic's effect on labor At the national level, a September 2017 paper out of Princeton University suggested opioid use could account for 20 percent of the drop in men's labor force participation from 1999 to 2015 and 25 percent of the decline in women's participation. And the problem has drawn the attention of Federal Reserve Chair Janet Yellen, who testified to the epidemic's effects on national labor during a July 13 Senate Banking Committee meeting. \"I do think it is related to declining labor force participation among prime-age workers,\" Yellen said. \"I don't know if it's causal or if it's a symptom of long-running economic maladies that have affected these communities and particularly affected workers who have seen their job opportunities decline.\" But there is no specific research related to West Virginia. Anecdotal evidence suggests employers nationwide have struggled in the past several years to find potential workers who are drug-free and healthy enough to perform required job tasks. The Federal Reserve Bank of Cleveland also cited the problem in a September 2016 report on West Virginia, which said local employers contacted by the reserve bank indicated \"educational attainment and 53 social factors such as frequent opioid and heroin use\" limited the employers from finding the workers they need. Still, the exact statistical impact for the state remains unclear. Jessica Ice, an assistant professor at West Virginia University's Institute for Labor Studies and Research, said she would be hesitant to attribute the entire decline in employment to opioids. \"I think we are still learning about the extent of the problem here as the epidemic continues to wreak havoc on the state of West Virginia,\" Ice said. \"While surely there is an impact I cannot even say what came first, disability and then prescription drug abuse? Hopelessness over the state of the economy and resorting to drugs to cope?\" Our ruling Manchin said the reason for the decline of working adults in West Virginia to \"around 50 percent\" of adults is due to the state's opioid epidemic. His estimate of workforce participation is correct, and recent research at the national level suggests opioids have hurt workers and employers looking for healthy employees. Experts on West Virginia's economy think the health crisis has affected participation in the workforce; they just don't yet know to what extent. In any event, a number of other factors are likely driving the decline. Manchin's claim is partially accurate, but lacks context that might give a different understanding of the data. We rate this statement Half True. Did bump stocks prevent more casualties in Las Vegas? By Allison Colburn on Monday, November 13th, 2017 at 9:00 a.m. Some legislators see the legal manufacture and use of bump stocks \u2014 found on 12 of the 23 guns in the Las Vegas gunman's Mandalay Bay hotel room \u2014 as a loophole in firearms regulation. 54 State Sen. Michael Williams, a Republican candidate running in Georgia's gubernatorial primary, recently came out against any legislation banning the devices, which can be attached to a semiautomatic weapon to simulate the rate of fire of a fully automatic weapon. To stress his point, he announced he would give away a free bump stock to a random person who enters the giveaway event. \"The tragedy in Las Vegas broke my heart, but any talk of banning or regulating bump stocks is merely cheap political lip service from career politicians,\" Williams said in a news release. \"In reality, the bump stock is the new, shiny object politicians are using to deceive voters into believing they are taking action against gun violence.\" Williams continued: \"Many firearms experts determined the Las Vegas shooter's use of a bump stock actually prevented more casualties and injures (sic) due to its inconsistency, inaccuracy, and lack of control.\" That didn't sound right to us, because the basic point of a bump stock is to help someone shoot really fast. The device allows the recoil from firing a semiautomatic weapon to slide the firearm back and forth. The movement \"bumps\" the trigger against the shooter's finger without having to manually squeeze the trigger for each shot. We should note that police have not yet said precisely which weapons were used in the shooting. But we wanted to look into the claim that the gunman would have hurt fewer people had he not had the ability to fire rapidly. Is this a popular expert opinion? What the experts say So who are these experts? We reached out to Williams and his campaign but received no response. The campaign has previously pointed to a post from Legally Armed America \u2014 written by Paul Glasco, who reviews guns and gun products 55 \u2014 that argued that a ban on bump fire stocks would be useless to prevent these kind of attacks. As part of our own research, we talked to five experts who said Williams is factually correct on one point about the nature of this attachment: Because because bump stocks use a weapon's recoil to allow the user to fire rapidly and repeatedly, the use of a bump stock makes the weapon more difficult to control when firing. This decreases the weapon's accuracy, which depends on a weapon's steadiness. Two experts supportive of gun rights \u2014 United States Concealed Carry Association president Tim Schmidt and lawyer John Pierce \u2014 were not convinced bump stocks would have made the crime more deadly. They agreed that a more accurate weapon could have hurt more people, but they needed more information about the crime to come to a conclusion. But three of the five experts said the rapid gunfire is likely what made the recent shooting so devastating. Precise aim was not a requirement; hundreds were injured. Adam Winkler, a law professor at the University of California, Los Angeles, who specializes in firearms, said the use of a semiautomatic weapon without a bump stock would have made a difference if the Las Vegas gunman was trying to hurt a specific person. \"When you don't care who you hit, being a little more inaccurate doesn't matter,\" Winkler said. To be fair, Arthur Alphin, a retired Army lieutenant colonel and West Point graduate, made the case to the Los Angeles Times that accuracy did matter, but so did the rapid fire. The weapon could have been held steady with a bipod, which was found in the gunman's room. If the gunman had been trained by military or law enforcement, an unaltered semiautomatic weapon could have been more harmful than one outfitted with a bump stock, said Rick Vasquez, a former assistant chief and acting chief of the Bureau of Alcohol, Tobacco, Firearms and Explosives' firearms technology branch. 56 But given the gunman's lack of formal training and the fact that the crowd at the Route 91 Harvest music festival was somewhat blocked in, \"any device that is going to spray a lot of ammunition is going to be more deadly,\" Vasquez said. \"He was shooting into a densely packed crowd of thousands of people,\" said Gary Kleck, a criminologist from Florida State University who studies the effects of guns on injuries and death in crimes. \"The main effect of using bump stocks in this particular situation was to increase the number of rounds the shooter could fire in a short period of time before police crashed into his hotel room, which increased the numbers of victims hit somewhat randomly.\" The Las Vegas Metropolitan Police Department declined to comment, citing the ongoing nature of the investigation. Our ruling Williams said many firearms experts have determined that the use of a bump stock in the Las Vegas shooting prevented more injuries and deaths than would have otherwise occurred had he not used a bump stock. Outside of a blog from a pro-gun rights group, we did not find \"many firearms experts\" making that argument. We did learn that bump stock devices tend to affect a weapon's accuracy. But we found several firearms experts who attributed the high number of people injured and killed to the shooter's ability to fire rapidly, which a bump stock would have amplified. We rate this statement False. Trump administration asks agencies to 'reorganize' By Allison Colburn on Thursday, November 9th, 2017 at 10:33 a.m. 57 Among President Donald Trump's campaign promises was a pledge to eliminate \"wasteful\" spending in every sector of the federal government. Specifically, he said he would \"ask every department head and government to provide a list of wasteful spending projects that we can eliminate\" in his first 100 days. \"The politicians have talked about this for years, but I'm going to do it,\" Trump said during his acceptance speech at the Republican National Convention. Trump has taken action here. But it appears what he proposed is just a normal part of the job. Three federal agencies contacted by PolitiFact interpreted the president's words as a reference to the list of budget priorities each agency compiles every year. The White House did not respond to a request for clarification. The annual federal budget process begins around 17 months prior to the fiscal year when the president and the Office of Management and Budget solicit requests to agencies for each department's budget priorities, including what should be cut or what funding should increase. The office then gives each agency feedback on the proposals. Agencies are barred from submitting their budget requests directly to Congress, per the 1921 Budget and Accounting Act. Usually in February, the president submits his budget request to Congress, which may consider the president's request when creating the budget. The White House publicly released its fiscal year 2018 request in May. Details of the final budget were still being ironed out in Congress at the end of October, behind the budget's Oct. 1 deadline. In its 2019 budget guidance, which was sent to agencies on July 7, the Office of Management and Budget asked the agencies to submit plans to \"reform\" their departments in accordance with an executive order signed on March 13. 58 That order requested agencies to come up with a way to \"reorganize the agency, if appropriate, in order to improve the efficiency, effectiveness, and accountability of that agency.\" The Office of Management and Budget's director will then decide whether to \"eliminate unnecessary agencies, components of agencies, and agency programs, and to merge functions.\" The agency budget proposals along with their plans for restructuring or possibly cutting portions of the agencies were due to the Office of Budget and Management on Sept. 11. Even though compiling a list of budget priorities and possible areas in which cuts can be made is an annual task for federal agencies, Trump did emphasize his goal to cut down on spending that he deems wasteful in an executive order. Whether cuts are made will be largely left up to Congress. For now we rate this In the Works. Trump backed off promise to change Denali's name, says Alaska senator By Allison Colburn on Monday, October 30th, 2017 at 12:27 p.m. President Donald Trump said on the campaign trail that he would reverse an order from President Barack Obama renaming North America's tallest mountain from Mount McKinley to Denali. But Alaska's Republican senators aren't interested. And they've told Trump as much. During a speech at the 2017 Alaska Federation of Natives' annual conference in Anchorage, Sen. Dan Sullivan relayed a conversation in which he and Sen. Lisa Murkowski told Trump they did not want to change the name. \"He looked at me and said, 'I heard that the big mountain in Alaska also had - also its name was changed by executive action. Do you want us to reverse 59 that?' \" Sullivan said, according to the Alaska Dispatch News. The two senators responded no. Murkowski's office confirmed some of the details of the meeting, which took place in March. \"It was part of a larger conversation where they were discussing harmful impacts to Alaska from the Obama administration, and while on the topic, Trump asked if reversing the name was something our state and the senators would like to see happen,\" said Hannah Ray, press secretary for Murkowski. \"They told him no, and explained why \u2014 that the name Denali was given by the Athabascan people more than 10,000 years ago.\" Trump agreed to not change the name, according to Sullivan. \"So he's like, 'all right, we won't do that,' \" Sullivan said in the speech. The White House did not respond to a request for comment. Before Obama's move, Murkowski had tried to change the mountain's name to Denali. She introduced legislation in January 2015 that Ohio lawmakers opposed, because President William McKinley was from Ohio. Months later, then-Secretary of the Interior Sally Jewell ordered the name change, which Obama announced on Aug. 30, 2015. The next day, Trump tweeted: \"President Obama wants to change the name of Mt. McKinley to Denali after more than 100 years. Great insult to Ohio. I will change back!\" Without the support of Alaskan leadership, Trump appears to have backed off this pledge. We rate this promise Stalled. Justice Dept. sues to block AT&T merger with Time Warner By Allison Colburn on Monday, November 20th, 2017 at 5:22 p.m. 60 The U.S. Justice Department is suing to block AT&T's $85 billion merger with Time Warner. David McAtee, senior executive vice president and general counsel for AT&T Inc., confirmed the suit in a Nov. 20 statement. \"Today's DOJ lawsuit is a radical and inexplicable departure from decades of antitrust precedent,\" McAtee said. \"Vertical mergers like this one are routinely approved because they benefit consumers without removing any competitor from the market. We see no legitimate reason for our merger to be treated differently.\" The suit comes weeks after news reports said the deal was stumbling. The Wall Street Journal, citing unnamed sources familiar with the matter, first reported on Nov. 2 that the Justice Department might sue to block the merger if the department can't come to an agreement with the two companies. Multiple news outlets, including Bloomberg, the New York Times, CNBC and theLos Angeles Times, also reported that the Justice Department is asking AT&T to sell certain assets to alleviate some of the department's antitrust concerns. In particular, negotiations focused on selling either DirectTV or Turner Broadcasting, which owns several network television stations, including CNN. PolitiFact does not use reporting from anonymous sources. But news on the deal has prompted criticism from people who believe President Donald Trump is influencing the department's dealings on the matter, given his rhetoric on the campaign. \"As an example of the power structure I'm fighting, AT&T is buying Time Warner and thus CNN, a deal we will not approve in my administration because it's too much concentration of power in the hands of too few,\" Trump said in an Oct. 22, 2016 speech. Presidents cannot deny or approve mergers, but they can appoint people to departments that oversee them. Trump's nominee for assistant attorney general for the Justice Department's antitrust division, Makan Delrahim, was approved by the Senate in 61 September. When the New York Times recently asked Delrahim about comments he had made a year ago in which he said the merger is not a major antitrust problem, Delrahim said those comments were taken out of context. When asked about the merger during his November trip to Asia, Trump said the deal might end up in litigation. Before the lawsuit was announced, AT&T was planning to look into whether the White House had any influence or involvement by seeking communications records between the White House and the department, according to Bloomberg. Sen. Amy Klobuchar, D-Minn., along with other Senate Democrats, wrote letters to both Trump and Delrahim in which they asked if there have been communications between them on the matter. When we asked about any communications, the Justice Department and the White House pointed to recent statements from Delrahim and White House spokesman Raj Shah, who both denied discussions on the merger took place. AT&T has hired a lawyer, Daniel Petrocelli, to serve as lead trial counsel in the case that the Justice Department sues. Petrocelli has represented Time Warner and Walt Disney in the past, and last year he represented Trump in lawsuits related to Trump University. \"Fortunately, the Department of Justice doesn't have the final say in this matter,\" McAtee said. \"Rather, it bears the burden of proving to the U.S. District Court that the transaction violates the law. We are confident that the court will reject the Government's claims and permit this merger under longstanding legal precedent.\" Until we see some resolution on the deal, we'll rate this In the Works. Trump has mixed record on expanding mental health services By Allison Colburn on Monday, November 20th, 2017 at 5:17 p.m. President Donald Trump's health care plan promised to help national mental health efforts. 62 His campaign's list of health care goals (archived here) said: \"Finally, we need to reform our mental health programs and institutions in this country. Families, without the ability to get the information needed to help those who are ailing, are too often not given the tools to help their loved ones.\" Much of the reform that has taken place during his first year in office can be attributed to the former Congress. The 21st Century Cures Act, passed a month before Trump took office. The bill drew criticism for removing some regulations on the pharmaceutical industry (proponents argued it would help speed up drug development). But the legislation also appropriated funding for mental health research, treatment and early intervention as well as established a new assistant secretary for mental health and substance use disorders. Trump's nominee for the new position, Elinore McCance-Katz, was approved by the Senate on Aug. 3. She leads the U.S. Department of Health and Human Services' Substance Abuse and Mental Health Services Administration and is tasked with streamlining more than 100 federal agencies concerned with mental health. In the past year, the Trump administration has also: !Announced an Oct. 26 executive action that, in light of the ongoing opioid crisis, would allow the quick hiring of personnel to deal with the epidemic, the expansion of telemedicine services and more flexibility in using grant money to help address the public health issue. !Expanded veterans' access to urgent mental health care services to former service members with other-than-honorable discharges. However, not every action has been helpful to the cause. Trump has proposed and supported plans that cut Medicaid funding, including Republican-led plans to repeal and replace Obamacare. Medicaid is the largest payer for mental health services in the United States. Andrew Sperling, the director of legislative affairs for the National Alliance on Mental Illness, said the failure of Obamacare repeal-and-replace has been a good thing for mental health care, but he also said the administration should be applauded for appointing McCance-Katz, who he believes to be a great choice for the position. 63 Going forward, Sperling said, the Trump administration could do more to increase information sharing and physician and family access to patients' medical records, within the bounds protected by privacy laws. Trump has made some effort to make good on this promise, though he has also tried to get legislation passed that would cut down on mental health care services. Until we see more action, we rate it In the Works. 64 EVERYONE HATES THE REFEREE: HOW FACT-CHECKERS MITIGATE A PUBLIC PERCEPTION OF BIAS Allison Colburn Katherine Reed, project supervisor ANALYSIS Introduction A year has passed since the 2016 presidential election. Social media companies are still grappling with how to stop fake news. The president is calling real news fake. And fact-checkers are being accused of bias by the public, politicians and conservative media. How are fact-checkers grappling with this chaotic landscape? In interviews, eight journalists from different fact-checking organizations discuss the dynamics between politics, media cynicism and fact-checking. The journalists interviewed are: !Alexandre Pouchard, a reporter at Le Monde, one of France's leading newspapers. He has worked on the paper's fact-checking team, called Les D\u00e9codeurs, since 2014. !Alexios Mantzarlis, the director of Poynter's International Fact-Checking Network. He has previously worked as the managing editor at Pagella Politica and was the co-founder of FactCheckEU. !Angie Holan, the editor of PolitiFact. She helped launch the fact-checking website in 2007. Prior to this, she worked at newspapers in several different states. !Eugene Kiely, a director at FactCheck.org. He previously worked for USA Today, The Philadelphia Inquirer and The Record. !Glenn Kessler, writes \"The Fact Checker\" column for The Washington Post. He joined the newspaper in 1998. 65 !Jim Drinkard, former editor at the Associated Press' Washington, D.C., bureau. He previously worked as a reporter for USA Today and the Associated Press and retired from his role as editor in June 2017. !Linda Qiu, the New York Times' fact-checker. Prior to joining the Times in early 2017, she worked as a reporter for PolitiFact. !Mike Jenner, professor at the University of Missouri School of Journalism and interim executive editor at the Columbia Missourian. From August 2015 to May 2017, he led PolitiFact's Missouri bureau. It should be noted that \"fact-checking\" in this project refers to a form of reporting in which the journalist analyzes a claim, breaks down the merits of that claim and, in some cases, assigns a rating. This kind of journalism has its roots in fact-checks in the 1980s and early 1990s by broadcast organizations such as CBS and CNN and by the Washington Post (Dobbs, 2012; Graves, 2016). These early fact-checks took a closer look at claims made in political campaign ads and campaign speeches. In 2008, PolitiFact and the Washington Post began full-time fact-checking operations, and dozens of organizations across the United States and around the world have followed suit. In the context of this project, \"fact-checking\" does not refer to the process of verifying each piece of information that goes into a news report, which all news organizations employ, though the process is more rigorous at magazines and with investigative pieces (McPhee, 2009; \"Investigations - Guidance in Full,\" 2015). The bind Just more than a decade ago, politicians and other public figures could speak without the worry of having their names published next to a Pinocchio face or an image engulfed in flames with the words, \"Pants On Fire!\" 66 Fact-checking operations, some inspired in part by The Washington Post's fact-checker and PolitiFact, have expanded nationally and internationally. Their purpose is two-fold: Fact-checkers provide context for complicated current events and issues, and they serve as political referees, adjudicating the extent to which a claim is true or false. The latter purpose tends to displease politicians and, most importantly, the readers/citizens whom fact-checkers aim to enlighten. A Google search of \"fact-checking bias\" produces about 1.7 million results. Myriad opinion articles, academic studies and online blogs have been predicated on the idea that fact-checkers conceal their political beliefs behind a false presentation of journalistic detachment. These accusations are, arguably, unsurprising; referees are never the popular people on the field. But the difference between a political and a sports referee is that a fact-checker's job security depends on public support of the practice. A referee is as essential to a football game as the athletes and coaches are, but most fact-checking operations rely on funding from citizens who think fact-checking is essential to politics. Fact-checkers are in a bind. How can they hold public officials accountable without alienating their audiences? In interviews with eight journalists from leading fact-checking organizations, it became clear that fact-checkers take accusations of bias very seriously, but they haven't quite figured out the best way to respond. The approaches they each take to fact-checking vary only slightly; the most significant difference is in whether they use rating systems. Furthermore, their communications with frustrated readers tend to be more reflective of the political climate than of the news organization. Attempts by journalists to change the minds of readers who believe fact-checking is biased only has a limited effect, if any effect at all. 67 The critics Criticism of fact-checking in the United States has been particularly harsh on the conservative end of the political spectrum, at least in the past few years. A June 2017 analysis of responses to fact-checks from political websites during the 2016 presidential election found that 77 percent of the criticism of fact-checks came from conservative-leaning sites (Iannucci & Adair, 2017). Survey research by Graves, Nyhan and Reifler (2015) found that Democrats favor fact-checking more than Republicans do. \"This particular issue doesn't replicate well around the world,\" said Alexios Mantzarlis, the director of Poynter's International Fact-Checking Network. \"In a lot of countries, the systems aren't bipolar, but multipolar. So it's hard to attack a fact-checker for being sold to one side when there are maybe four or five sides.\" At one of France's largest newspapers, Le Monde, the criticisms come from both ends of the spectrum in a political system with several different major political parties. Alexandre Pouchard, a journalist with Le Monde's fact-checking team, Les D\u00e9codeurs, said claims of bias tend to come from readers who strongly identify with left-leaning political parties as well as right-leaning political parties. This, he said, is a sign that they're doing a good job. The cause of the perception in the United States that fact-checkers favor Democrats might also be explained by the influence of conservative media outlets on their readers and viewers. Mantzarlis said these outlets' efforts to discredit mainstream media has possibly primed people to distrust fact-checkers. \"Now I will say, PolitiFact and the Washington Post fact-checker, two of the major political fact-checking operations, both excellent, both committed to nonpartisanship, are both hosted in liberal-leaning papers,\" Mantzarlis said. \"I think that's where part of the perception 68 may come from. But when I see FactCheck.org being attacked as well, then I kind of think that there's something more malicious in operation.\" In a move to assuage conservative criticism of fact-checker bias, Facebook, which has launched partnerships with PolitiFact, Snopes and the Associated Press to help the social media company identify and debunk fake news, has reportedly brought on a conservative fact-checker at The Weekly Standard (Timmons, 2017). Mantzarlis said any fact-checker working with Facebook has to be a signatory of the International Fact-Checking Network's code of principles, meaning they must abide by certain standards of nonpartisanship and transparency. He also said he believes there is no such thing as a partisan fact-checker. The idea that a \"conservative\" fact-checker would add balance to a supposedly liberal-leaning genre of journalism relies heavily on an idea disputed by fact-checkers \u2014 that their personal politics impedes their ability to challenge Democrats and to be fair to Republicans. In fact, when asked if they were aware of the public perception, several fact-checkers said they had heard of it or read about it in surveys. Their own experience with readers, they said, was somewhat more bipartisan in terms of criticism. When they fact-check Democrats, they get criticism from Democrats. The same goes for Republicans. Sometimes the criticism draws on assumptions about the way fact-checkers and the news media in general treat conservatives. Linda Qiu, the fact-checker for The New York Times, said she's noticed that when she fact-checks Democrats, liberal readers think she's being too harsh. They assume that the so-called \"liberal media\" doesn't hold the same fairness standards for both major political parties, she said. 69 \"There's a sense that you're supposed to be on their side,\" Qiu said. \"And I'm like no, no, no, I'm not on anyone's side. I'm not the opposition to anyone. I'm just trying to lay out a clear picture.\" PolitiFact Editor Angie Holan said reader criticism depends largely on whether the reader agrees with a fact-check's rating. \"We get more complaints from conservatives about being part of the liberal media,\" Holan said. \"I don't think that's particularly because we're fact-checkers or what we choose to fact-check. I just think that is the rap that a lot of conservative readers make on media that are not overtly conservative.\" A blog, PolitiFactBias.com, devotes itself to finding specific instances of PolitiFact being unfair to conservatives. The blog does not provide analysis or opinion about fact-checks that give Republicans positive ratings. Rather, it mostly focuses on instances of PolitiFact being too hard on conservatives. \"What I find is it's hard for me to take critics seriously when they never say we do anything right,\" Holan said. \"Sometimes we can do things right, and you'll never see it on that site.\" Politics' effect on the public perception of fact-checkers Each fact-checker interviewed attributed much of the public perception of bias to the current state of politics, which largely determines which claims they choose to fact-check. The people who are in the news the most are the ones making the most on-the-record claims and sharing the most information, or misinformation, with the public. In recent years, Republican-control of Congress has meant that Republicans are more often the ones speaking publicly and 70 making factual claims to help bolster their proposed legislation or political agenda. Now, the problem is exacerbated by Republican-control of the White House. In the presidential primaries, 17 Republicans ran for office. Only two Democrats faced off in the primaries. This meant that, on any given day during the primaries, the total number of claims from all presidential hopefuls tended to skew Republican. And then there's President Donald Trump, who has a history of making outlandish claims in speeches and interviews that even members of his own party struggle to defend. As of Dec. 5, 69 percent of the almost 500 Trump claims that PolitiFact has fact-checked were rated either Mostly False, False or Pants on Fire. His frequent tweets, which he claims are not reviewed by White House communications staff, add even more fact-checkable claims to the mix. \"Until Trump came along, Obama was the most fact-checked president in history,\" said Jim Drinkard, who worked as an editor at the Associated Press' Washington, D.C., bureau until he retired in June. He oversaw the expansion of the organization's fact-checking initiative over the past decade. \"And it's because whoever is the president is important,\" Drinkard said. \"We pay the most attention to what's important. Right now we have a president who is factually challenged to a remarkable and perhaps unprecedented degree. And he happens to be the president, so he's getting fact-checked.\" In his last few months working at the Associated Press, Drinkard ended up spending most of his time fact-checking Trump due to the volume of inaccurate or misleading statements made by the president. 71 Glenn Kessler, Washington Post fact-checker, said the current state of politics in Washington presents a huge hurdle for him in trying to even the scorecard between the two parties. \"The best possible situation for the fact-checker is when you have a divided government,\" Kessler said. \"When you had a Democratic president and a Republican Congress, it was equal. There were days, weeks, we'd go like 14-straight fact-checks of Democrats. And then 14-straight fact-checks of Republicans.\" Now his coverage is dominated by Trump and other Republican leaders. \"I don't know what to do,\" Kessler said. \"We really just like to focus on what's in the news and who's saying things that are interesting and worthy of fact-checking. But this year is really bad.\" Responding to accusations of bias Every fact-checker expressed appreciation for reader interaction. Readers often point fact-checkers to useful information that might have been omitted. The journalists then update their fact-checks with the new information, which makes the reporting richer and more accurate. Readers also contact fact-checkers with questions about whether something someone said was true. Kessler said about half his fact-checks are prompted by ideas and questions from readers. When readers accuse fact-checkers of bias, fact-checkers take it seriously. Eugene Kiely, a director at FactCheck.org, has a team of students who respond to readers. But whenever the organization receives complaints of bias, Kiely responds personally. He wants to know exactly what the reader thinks is biased and whether a correction, update or clarification is in order. Other fact-checking organizations find it difficult to keep up with the volume of reader emails. Due to limited resources, many fact-checking organizations do not have people purely 72 devoted to responding to readers. However, they do try to respond to all questions and complaints. There are a few similarities among how fact-checkers respond to bias complaints. One, they explain their reporting process. This means explaining why they chose a particular claim to check, which sources they used and what the logic was in their framing of the fact-check. Two, the fact-checkers always ask for specifics: What, exactly, about the fact-check leads the reader to the conclusion of bias? What information included in the fact-check is incorrect? Was any information omitted? Sometimes readers are persuaded and placated. Other times readers continue asserting the organization is biased. Kessler said he always tells readers to read The Washington Post fact-checker for a month and then decide if he is still biased. He's had some success with this. Readers sometimes get back to him and say they realize he's equal opportunity when it comes to fact-checking politicians. Pouchard has used a similar strategy. Les D\u00e9codeurs will often respond to readers who claim they favor one party or another by sending them fact-checks of politicians from other parties. Again, this doesn't always work. A possible reason some people cling to their ideological beliefs in the face of factual information that contradicts those beliefs is a phenomenon called the backfire effect, in which misperceptions are increased upon seeing counter-factual information. But recent research has debunked the theory. Porter and Wood (2016) tested more than 8,000 research participants on 36 different topics and found a backfire effect for only one issue: the misperception that weapons of mass destruction were found in Iraq. Another study found that Trump supporters corrected their 73 misperceptions of claims Trump has made after being presented with factual evidence that counters those claims (Swire et. al., 2017). This, however, did not make participants less likely to vote for Trump. \"In most cases people will, on average, change their mind towards the more accurate information,\" Mantzarlis said. \"Now, people are fact-resistant but not fact-immune. We do have confirmation bias. We do have motivated reasoning. We do have all kinds of things that make it less likely to accept things that go against our opinions.\" But just because the human mind finds ways to protect its beliefs, doesn't mean it is impossible for people to change their minds in the face of evidence that challenges their beliefs, he said. Several fact-checkers perceived many of the complaints of bias they receive to be coming from a small percentage of the population that has particularly strong ideological views. Activists were much more likely to complain. In some cases, the complaints devolve into abuse. Readers sometimes attack fact-checkers on a personal level. \"I've gotten a lot of gender-based attacks,\" Holan said. \"I mean for some reason some of the readers who dislike us like to go to the insult of 'whore.' That seems to be super popular.\" Qiu said she receives sexist comments along with racist attacks because her last name is Asian. The online abuse tends to increase when a partisan website writes about or criticizes something she wrote. In one instance, when Qiu was still working at PolitiFact, Breitbart published a piece criticizing a fact-check she wrote on a claim made in the novel, Clinton Cash. She was subjected to a barrage of hate on social media and in email. 74 \"A lot of those were very rude memes, like pictures and my face superimposed in very compromising positions,\" Qiu said. \"That was not fun.\" Qiu and Holan said they don't bother responding to abusive comments and complaints from readers. Especially when they receive hundreds of emails in a given day, they don't find it productive. Do ratings make it more difficult to defend against bias complaints? Critics of rating systems believe ratings introduce opinion into articles that are meant to be objective. PolitiFact created its rating system because it wanted to be able to sort statements by relative accuracy, Holan said. This allowed the organization to look at particular subjects and see how accurate politicians and pundits have been on the issues, for example. \"Now I think some people take the ratings too far in what they think we're trying to say, because we don't fact-check a random sample of what any one person says or a random sample on any one topic,\" Holan said. \"So some of our audience sees this as an opportunity for us to have biases and bring our biases in, but that's not what we're intending.\" The ratings tend to occasionally stump fact-checkers. Holan sometimes has trouble deciding between a Half True and a Mostly True because Half True is often perceived by readers to mean the speaker is being shady. Half True is actually intended to convey that the statement is partially accurate but leaves out important information. Another benefit of rating systems is that they help fact-checkers apply their judgment consistently. \"The Major League umpires, they work really hard to be consistent so that you know depending on the umpire you have, you know the strike zone doesn't change in size by 25 75 percent based on who stands behind the plate,\" said Mike Jenner, a professor at the University of Missouri School of Journalism. He taught the school's fact-checking class, which publishes through PolitiFact's Missouri bureau, from 2015-2017. Jenner said he struggles in deciding on a rating for a claim that is literally true but has a lot of nuances. At The Washington Post, Kessler has trouble deciding between two Pinocchios, which is similar to PolitiFact's Half True rating, and three Pinocchios, which is like a Mostly False. \"These ratings, frankly, are subjective,\" Kessler said. \"So my three might be someone else's two.\" But the ratings do help him with consistency, he said. One time he had trouble deciding on whether to give a claim that Hillary Clinton had made a two or a three, and he settled on a three. After he published, a reader sent him a link and pointed out that he had already fact-checked that same talking point a couple a few years prior. \"With great trepidation, I clicked on the link to see what was my rating, and it was three Pinocchios,\" Kessler said. \"And I had exactly the same analysis as to why it was three Pinocchios. So that was a relief.\" In response to reader demand to have input on the ratings, The Washington Post created a rating tool for people to vote on how many Pinocchios they think the fact-check should have. Regardless of how true or nuanced a claim is, readers most often either choose a Geppetto Checkmark, denoting the claim is true, or four Pinocchios. In other words, reader ratings fall along the same extremes as partisan lines in a deeply divided country. 76 \"People take it very seriously,\" Kessler said. \"You wouldn't believe how many emails I get from people who apologize profusely for having accidently hit the wrong rating, and could we fix it so it didn't mess up the score. It happens at least once a day.\" Readers do care a lot about ratings. Holan said the majority of complaints she receives take issue with the ratings, not so much with the reporting. But ratings also force reporters to analyze their logic. All fact-checking organizations adjudicate in some way or another. The Associated Press explains why a claim is wrong in the first few paragraphs of its fact-checks. FactCheck.org uses phrases such as \"misleading\" or \"lacks context\" to summarize claims. With a rating system, reporters and editors take a look at the reporting, analyze it and discuss why they think a claim should have one rating or another. \"I think the risk (of not using rating systems), and sometimes we do see it, is that if you don't have to come to an actual conclusion, you sort of throw all that facts that you know on the page, and you're not really adjudicating.\" Mantzarlis said. \"Then you're not delivering the service that fact-checking was launched and born to deliver.\" And, Jenner argued, if those ratings do end up driving readers to criticize, that might not be such a bad thing. \"We have to invite scrutiny,\" Jenner said. \"We're scrutinizing what others say and what they do. We need to be able to provide the same accountability that we're asking of public officials.\" Some solutions That said, there are many things journalists can do to help combat the perception of bias. The first step is to follow organizational policies. The seven different organizations represented in this paper express a commitment to transparency in their policies. In general, 77 readers should know where and when information was found or sources were contacted. Whenever possible, sources should include hyperlinks. Each organization lists their corrections policy online along with a commitment to correcting misinformation in a swift manner. Fact-checkers who work for a newspaper follow the paper's corrections policy. PolitiFact's corrections policy states that, whenever a correction or clarification is made, the organization evaluates whether the change affects the fact-check's rating. If the correction or clarification affects the final ruling, the rating will be changed as well. The aim for transparency in fact-checking even extends beyond the reporting and editing processes. The International Fact-Checking Network specifically asks fact-checking organizations to be transparent in how their operations are funded (\"Code of Principles,\" 2016). \"If we accept funding from other organizations, we ensure that funders have no influence over the conclusions we reach in our reports,\" the network's code of principles says. \"We detail the professional background of all key figures in our organization and explain our organizational structure and legal status.\" In addition, the network says fact-checkers should create an accessible communication channel between the organization and the readers. Fact-checkers must apply to be signatories of the network's code and pass a vetting process. As of December 2017, at least 40 organizations in the United States and abroad had passed the process and signed on to the code. The list includes the Associated Press, FactCheck.org, PolitiFact, Le Monde and The Washington Post. Facebook requires the fact-checking organizations it works with to be signatories of the code. These policies are meant to help ensure journalistic integrity and build or keep public trust, but fact-checkers have come up with more ways to address their public perception problem. 78 Qiu, for instance, said she tries to consult experts who fall along an ideological spectrum. She described it as doing a \"mini survey,\" where she reaches out to several different experts who represent different viewpoints, and she tries to find some consensus among them. If every expert can agree on one point, that point can be considered factual. If she talks to six experts and only five of them agree, Qiu can say \"most of the experts believe such and such\" and then present the other side. Whenever possible, Qiu tries to rely on data rather than experts. \"You can't slant numbers,\" Qiu said. Mantzarlis said one way to help bring ideological diversity into a fact-check is to find the surprising source, someone who would arguably counter his or her own interests by weighing in on the fact-check. For instance, when reporting on a claim made about the military, the journalist could reach out to a pro-military group in addition to finding expert sources who don't have a stake in the outcome of the fact-check. Another way journalists can cut down on the possibility of slant in their fact-checks is by paying close attention to the report's language. Holan said she edits out certain snarky phrases that occasionally creep into reporters' work. She sometimes sees reporters write things that imply some sort of expectation of how a politician or other public figure speaks. She has seen this happen especially when reporters write about claims made by Trump, since he has a history of making inaccurate statements. \"Every now and then, one of our reporters files a piece that has something like, 'Well here he goes again,'\" Holan said. \"And I always delete out that because it's like Trump, he... yes, he has a lot of negative ratings on our site. But I live in hope that one day he will gradually learn to speak more accurately, and our fact checks should give him the benefit of the doubt... and 79 maybe one day soon he'll reduce the number of things that he says that are not accurate.\" She added that not everything Trump says is false. Drinkard and Qiu both stressed the importance of being dispassionate in the writing of fact-checks. The tone should remain neutral, they said. This can be difficult when the purpose of fact-checking is to point out inaccuracies. The format lends itself to condescension, Qiu said, which is why she thinks it's important for the writing to be dry. On the other hand, Drinkard said there are occasional opportunities when fact-checkers can have some fun with the writing. One of his favorite leads on a fact-check was about the claim that Obama was the least popular president in modern American history. The first sentence of the story restated the claim. \"And the second sentence was, 'That's true, if you leave out Lyndon Johnson, John Kennedy, George W. Bush...' And we listed 17 presidents,\" Drinkard said. However, he said the livelier writing should be reserved for particularly outlandish claims. One subject on which fact-checkers vehemently agreed was the debate over whether to use the word \"lie.\" Out of six fact-checkers who were asked about the use of the word, each said it should be avoided. Their main gripe was that it implied the speaker intended to deceive. \"Did they believe what they said when they were passing this information along?\" Kiely said. \"Were they given some bad information from someone when they passed it along? That wouldn't be intentional either. You just don't know.\" Qiu, Kiely and Pouchard tried to imagine a situation in which the word would be used but found it difficult to come up with exact circumstances. There would have to be definitive proof, they said. If, for example, some emails existed that showed the speaker knew what he or she was saying was wrong, and those emails were made public, could a case then be made for using the word. 80 \"It also has an emotional freight with it,\" Drinkard said. \"It's a word that is very emotionally tinged. And we see ourselves more in the role of a referee or a judge. We're not blaming them for (an inaccurate statement). We're just pointing out that it's wrong.\" Conclusion Fact-checking, when done well, can help people find the truth in the garbage heap of fake news and political spin online and in media. It can also hold public officials accountable. But it can't do any of that without reader trust. Journalists interviewed said they didn't really have a surefire solution to winning over readers who accuse them of bias. Sometimes responding to them produces productive and helpful conversations. Other times it does not. I see one common thread with each experience these journalists shared with me, and I'm surprised not one person interviewed brought it up. What's clear is this public perception problem stems from an overall lack of media literacy among readers. Here's my long-winded reasoning: Fact-checking is perhaps the most transparent form of journalism. Information is corroborated with multiple sources, given scrutiny and proper context and, when possible, hyperlinked. In some cases, as is common practice at PolitiFact, fact-checkers spell out the dates on which they communicated with their sources and say whether interviews were conducted over email or over the phone. Fact-checkers walk readers through their reporting process; they explicitly say how they arrived at their conclusions, including why certain pieces of information carry more weight than others. I went into my research assuming I would find practices and processes vary widely among fact-checkers, but instead found consensus in the ways fact-checkers report, write and edit. Furthermore, they are held up to their standards by 81 These journalists do not care about the political affiliations of the people they fact-check, and they actively challenge their own political assumptions. They know every word they write will be pored over by readers looking for holes in the reporting and evidence of bias, so they pay close attention to where their reporting and writing are potentially failing readers. My own experience gives me no reason to doubt that a system of checks and balances within each fact-checking organization pushes reporters back in line when they stumble outside a mindset of impartiality. The first fact-check I wrote for PolitiFact's Missouri bureau required me to take a deep dive into some frequently cited crime statistics. The state's governor, Eric Greitens, made his case for increased police funding in part by saying Missouri's three largest cities were among the top 11 most violent cities in the United States. When I analyzed the FBI data, it became clear how easy it was to cherry pick by simply choosing to only look at cities within a certain population range, but that wasn't enough for me to rate the claim anything but true. Then experts told me I should take the statistic with a grain of salt. Some cities, St. Louis especially, are deeply segregated by race and income, they said. When a metropolitan area has a pronounced history of white and middle-class flight from urban centers to the suburbs, that city's crime rates, which are measured by the number of crimes per 100,000 residents, tend to be worse than those of more integrated cities. The statistic might give someone the impression that Missouri's cities are incredibly unsafe, but it most likely means that the crime is just concentrated to the areas that are represented in the FBI's yearly report, which separates city centers from their surrounding metropolitan areas. It was clear to me that the statistic needed some context. When it came time to edit and discuss my fact-check, I had it in my mind that the claim was mostly false. It's not that I wanted Greitens to be wrong \u2014 I didn't have much of an opinion 82 of him at the time, nor was I a registered voter in the state \u2014 but a part of me did not want Missouri's cities to suffer from a poor and arguably unfair reputation. My editors were surprised I had said the claim was mostly false, given that the statistic itself was, at least on the surface, accurate. One editor thought the claim should be rated mostly true. Another thought half true. Other reporters weighed in and said they didn't see how it could possibly be mostly false. I had a moment of clarity and realized I was letting my feelings shape my analysis. Since PolitiFact defines what each rating means, we compared my reporting to the definitions and settled on half true, which means the statement is partially accurate but leaves out important details or takes things out of context. I call this a system of checks and balances because each fact-check is discussed and deliberated by multiple people who are hired in part to poke holes in the reporting and writing. Every fact-check I have written has gone through multiple layers of editing. Sometimes I write a fact-check and my editor thinks I am missing a crucial piece of information that I need to include. Other times my editor takes out nonessential information. When the first layer of editing is finally finished, at least two other editors read through the fact-check. Then all three editors debate what the final rating should be and whether they agree with the rating I gave it, and I ultimately have no say in what they decide. So where does the bias come from? It can't possibly come from the reporter, as the reporter's final work is rarely the same as it was when it was first shown to an editor. It also can't come from the sources, since the reader can see those sources for his or herself. Perhaps it comes from everyone at fact-checking organizations everywhere working together toward the common goal of crushing one particular ideology. Some might find this idea 83 laughable. But to someone who lacks the understanding of how news organizations operate, this explanation might make sense. I see evidence of readers' weak media literacy in the fact that they continue to assert the fact-checkers are biased. As was described to me by the journalists I interviewed, the readers can't often pinpoint exactly what screams bias to them. Even though responding to reader complaints sometimes ends up in a productive conversation, fact-checkers haven't figured out how to help that one strong-headed sect of readers understand how journalism is done. Until we see a cultural shift toward media literacy, the fact-checkers aren't likely to have any luck. But I'm an optimist. The public perception of bias could resolve itself over time. Every fact-checker I spoke to who covers politics in the United States attributed the perception of bias among conservative readers to the fact that Republicans have been the ones making headlines and gaining seats in Congress over the past few years. With more Republicans speaking publicly, more Republicans are getting fact-checked. That problem is compounded by Trump, who tends to stray from facts, holding the highest office in the nation. \"Facts are facts. That fairness element is all we have,\" Drinkard told me. \"Hopefully over the long-haul, when presidents come and presidents go, they'll be treated the same. And so, people will understand that.\" Engaging with readers does sometimes work. And if it works sometimes, then journalists should continue trying to get readers to understand their logic and should devote more resources to reader engagement. In the end, though, the practice of fact-checking will just have to speak for itself. 84 When I asked Qiu whether it worries her knowing that sometimes a person's natural reaction is to write off a source of information that contradicts his or her beliefs, she said it's something she asks herself about a lot. \"How does fact-checking sway public opinion one way or another?\" Qiu said. \"Maybe it doesn't. But I think the purpose of it isn't necessarily to change hearts and minds, but it's to say these are the facts.\" Sources Graves, L., Nyhan, B., & Reifler, J. (2015). The diffusion of fact-checking: Understanding the growth of a journalistic innovation. American Press Institute. Iannucci, R. & Adair, B. (2017) Heroes or hacks: The partisan divide over fact-checking. Duke Reporters' Lab. International Fact-Checking Network fact-checkers' code of principles. (2016, September 15). Retrieved from https://www.poynter.org Dobbs, M. (2012). The rise of political fact-checking: How Reagan inspired a journalistic movement: A reporter's eye view. New America Foundation. Graves, L. (2016). Deciding what's true: The rise of political fact-checking in American journalism. New York: Columbia University Press. McPhee, J. (2009, February 9). Checkpoints. The New Yorker. Investigations-Guidance in Full. (2015, July). BBC. Retrieved from http://www.bbc.co.uk/editorialguidelines/guidance/investigations/guidance-full Timmons, H. (2017, Oct. 7). Facebook's latest solution to its fake news problem\u2014sign on a right-wing fact-checker. Quartz. Retrieved from https://qz.com/1095509/facebooks-latest-solution-to-its-fake-news-problem-sign-on-a-right-wing-fact-checker/ Wood, T. & Porter, E. (2016) The elusive backfire effect: mass attitudes' steadfast factual adherence. Briony, S., Berinsky, A., S. & Ecker, U. (2017). Processing political misinformation: comprehending the Trump phenomenon. Royal Society Open Science. 85 Note to reader: Discrepancies between the project proposal and the analysis My initial goal for this project was to determine whether rating systems trivialize the in-depth reporting that goes into fact-checks. I hypothesized that rating systems change the framing of fact-checks from that of factual analysis to a game or strategy frame. As I conducted my interviews, I found myself asking more questions about bias and reader interaction. This was in part because I got the sense that the fact-checkers had discussed ratings so many times that they were just repeating answers they had given before. When I started talking about bias, however, the conversation livened up. I felt I had stumbled onto a more pressing problem. It came time to begin writing my analysis, and I had a wealth of information that just wasn't suited for the original question I wanted to answer. With the approval of my committee, I changed my focus from how ratings affect factual analyses to how fact-checkers mitigate a public perception of bias. This enabled me to write a more thorough and, in my opinion, more useful analysis that I hope will shed some light on a problem journalists grapple with every day. 86 ORIGINAL PROJECT PROPOSAL Theoretical Framework Framing theory is often used to analyze the reporting, visual elements and word choice of news stories. In a general definition, a frame is a \"central organizing principle that holds together and gives coherence and meaning to a diverse array of symbols\" (Gamson, Croteau, Hoynes, & Sasson, 1992, p. 384). In other words, a frame offers newsreaders an understanding of a news piece's content through a specific lens. Frames organize information into a form or narrative that encourages readers to understand the information in a specific way. They provide an interpretation of a situation or person, \"often along with a moral judgment that provides an emotional charge\" (Entman, Matthes, & Pellicano, 2009, p. 177). The journalist's sources, information, anecdotes and choice of words guide the reader through the complexities of broader societal issues and arrive at a conclusion meant to produce a specific understanding of an event, person or topic, whether the frame is presented consciously or not. To an extent, the news media can shape a political or social reality through framing (Nelson, Oxley, & Clawson, 1997). One criticism of framing theory is that it seems to embrace subjectivity or suggest subjectivity is inevitable in news reports. However, the relationship between facts and frames is too complicated and intertwined to expect separation between the two. The idea that moral judgments, values and opinions can and should be presented distinctly from facts has propagated throughout much of U.S. history as a central principle in American journalism (Schudson, 2001). This adherence to what is believed to be objectivity has often resulted in \"he said, she said\" reporting, which presents two sides to every issue, gives equal weight to both perspectives and leaves the reader to decide on the truth (Lawrence & Schafer, 2012). But a false equivalence between disputed political realities is still a frame, presenting only a sliver of societal reality. 87 Journalism's relationship to truth, objectivity and subjectivity is better understood through Bill Kovach's and Tom Rosenstiel's (2014), \"discipline of verification,\" the scientific approach to factual accuracy and truth-telling. The discipline separates journalism from art, entertainment, propaganda and fiction. A piece of journalism is just as concerned with verifying a story's larger meaning as it is with verifying the small, seemingly insignificant details. The process is guided by principles of transparency, humility, originality, fairness, thoroughness and accuracy (Kovach & Rosentiel, 2014). Inherent biases and subjectivity are part of what makes journalists human, but adherence to discipline of verification prevents them from producing spin. News stories can take many different forms; however, the rugged reporting process behind each story underlies every news frame. Fact-check journalism's dominant frame is always factual analysis, but can dip into the realm of strategic game framing through the language used to describe the fact-checkers verdict or judgment of a claim. (Graves, 2016). Many fact-checkers describe the practice as a combination of accountability and explanatory journalism, two growing sectors in the field. The genre was created in part as a remedy to \"he said, she said\" reporting, where reporters regurgitate what was said and allow viewers or readers make up their mind, and \"horse race\" reporting, which focuses more on how each candidate is doing in the polls and public perception than the political issues (Graves, 2016). Rather than merely reporting what candidates and politicians say, fact-checkers analyze political facts and draw conclusions about their degree of truthfulness. This has drawn criticism from scholars, people in the media and readers, who believe it is not journalism's place to arbitrate political truth. Although fact-checking was created to provide an alternative to the political 'horse race,' the focus on political actors places fact-checking in at least the same realm as the skeptical strategic-game-frame reporting (Graves, 2016). Strategic 88 game framing of political coverage is defined by a focus on the motives, wins and losses and campaign strategies of political actors (Aalberg, Stromback, & de Vreese, 2011). It also focuses on a candidate's leadership choices and integrity, among other personality traits (Cappella & Jamieson, 1996). Research suggests that strategic game framing can induce audiences to see a false political claim as unjustified, but at the expense of activating audience cynicism in politics and the media (Cappella & Jamieson, 1996). Although fact-checks always employ the 'factual analysis' frame, they differ across platforms in the degree to which they issue a verdict or judgment on a claim. As Fairhurst and Sarr (1996) define framing, to judge a subject's character and significance is to frame it. Adjudication is accomplished through the language, jargon, code words and metaphors used in a piece of journalism, which influence the frame (Fairhurst & Sarr, 1996; Hertog & McLeod, 2001). This judgment is found in the language of fact-checks - true, falsely claims, lies, and so on, as well as the visual elements included in a fact-check rating. Literature Review Fact-checkers as political referees Fact-checking can refer to two different aspects of journalism. One, the topic at hand, is a form of reporting in which the journalist analyzes a claim, breaks down the merits of that claim and, in some cases, assigns a rating. The other use of the term refers to the essential journalistic process of verifying each piece of information that goes into a news report. This process goes beyond making sure names, numbers, quotes and dates are correct, a common practice in daily newsrooms that occurs at multiple editorial levels prior to publication (Nelson, 2012). The rigor and depth of fact-checking can vary depending on the type of reporting. For instance, 89 investigative stories receive deeper editorial scrutiny (\"Investigations - Guidance in Full,\" 2015). Fact-checking practices also vary by publication. Magazines, which do not have the pressure of the daily deadline, exercise a fact-checking process that involves breaking down a story's reporting source by source, essentially re-reporting the story (McPhee, 2009). Designated fact-checkers at magazines will go over interview transcripts, the reporter's notes and research and will call each cited source back to verify what the source told the reporter (Hepworth, 2017). However, the magazine fact-checking process mirrors newspaper fact-checking when it comes to online stories (Bloyd-Peshkin & Sivek, 2017). For the purpose of this research, fact-checking refers to a type of service journalism in which factual claims are tested when it is not clear whether those claims are true. After conducting the relevant research and reporting, the fact-checkers usually come to a conclusion about the extent to which the claim is true. Exactly how the reporter flags fact from fiction in the fact-check might differ based on which news organization the reporter works for. Untrue information might be indicated with a headline that includes words such as, mostly false or falsely claims. For other news organizations, categories of truthfulness, or ratings, might be employed. Some have more categories than others - PolitiFact's ratings meter extends from \"True\" to \"Pants on Fire,\" while The Washington Post uses a system of \"Pinocchios\" where one Pinocchio indicates a degree of falsity and four indicates a flat-out lie. What the two ratings systems have in common is a nod to childhood lessons on lying \u2014 the rhyme \"Liar, liar, pants on fire\" and Pinocchios' tale invoke a sense of shaming. Symbols that accompany a fact-check contribute to the fact-check's framing effects the same way text provides meaning to a story (Messaris and Abraham, 2001). Visual components to a news story can even produce stronger framing effects than the text alone (Powell et. al, 2015). 90 One exception to the ratings systems is FactCheck.org, which does not rate any of its fact-checks. The reason, the website's former director said in a 2012 letter to readers, is that the organization considers ratings to be \"by their nature subjective \u2014 the difference between one or two 'Pinocchios' is a matter of personal judgment, and debatable\" (Jackson, 2012). The website also believes that the evaluative process of understanding political claims is important in helping voters gain political literacy (Amazeen, 2013). On the other hand, as journalists pointed out to Graves (2016) and Amazeen (2013) in various interviews, rating meters capture reader attention and simplify dense analysis. They also provide readers with a summary, which can help make fact-checking more accessible. A similar debate is found in the use of the word, \"lie.\" The New York Times received flak in January 2017 for running a headline that read, \"Trump Won't Back Down From His Voting Fraud Lie\" after the president repeated a claim that between three and five million illegal immigrants voted in the election (Fandos, 2017). Critics of the Times' use of the word said it is inherently subjective to say \"lie\" an intent to deceive must accompany the falsehood (Gonzales, 2017). Because journalists can never know if a politician intended to deceive unless they admitted it, to use the word \"lie\" is to editorialize. New York Times op-ed columnist David Leonhardt (2017) defended the word, saying that sometimes there is clear evidence that a claim is not only false, but the politician is also aware of the truth. The difference of opinion among journalists on framing fact-checks reveals the tricky chasm between schools of thought on what constitutes bias. While one journalist might decry placing overt judgment in the form of a rating into an article, the other might argue it is a more effective method of communicating the degree to which a person tells the truth. However, what truly separates a fact-check from an opinion piece is the journalistic process. Kovach and 91 Rosentiel (2014) outlined three key concepts in journalism's discipline of verification: transparency, originality and humility. !To be transparent, journalists must tell their audience what they know, what they don't know and how they know what they know. They cannot add things into a story if those things did not happen. This includes conflating or rearranging characters, dialog and events in time or place. !Originality means journalists should do their own independent reporting rather than use other reports to verify. This helps prevent false information from being spread. !The last factor, humility, is a journalist's ability to question his or her own assumptions. This requires an open mind and a deep familiarity with the limits of one's knowledge. Regardless of how journalists choose to present their reporting, the journalistic discipline of verification remains the same. A brief history of fact-checking By no means is the practice of fact-checking a recent development in journalism. For as long as the field has existed, journalists have integrated the process of verification into newsrooms. However, the fact-check as its own, separate publishable piece of \"service journalism\" is relatively new to the craft. The first official fact-checker at The Washington Post, Michael Dobbs (2012), contends that the modern fact-check began in the early 1980s with coverage of the Reagan administration. During this time, journalists grew more comfortable communicating doubt about political claims 92 in their reporting. This was in part due to increasing criticism of journalists' failures to hold officials accountable in the past in addition to Reagan's tendency to make outlandish claims. For instance while running for election, Reagan \"was ridiculed for his claim that trees caused four times more pollution as automobiles and factory chimneys put together\" (Dobbs, 2012, p. 4). Despite the ridicule, Reagan continued repeating the erroneous claim throughout his run. Soon after Inauguration Day, reporters began fact-checking the new president's press conferences and public statements. The Post ran sidebars along with its coverage on press conferences fact-checking statements made by Reagan. Most of this aggressive fact-checking occurred in the first two years of Reagan's presidency but had faded by the late '80s. Fact-checking picked up steam again in the late 1980s and early 1990s during presidential campaign seasons (Graves, 2016). A couple of weeks before the 1988 election, ABC aired a segment dissecting a George H. W. Bush campaign ad that hurled a baseless claim at his opponent. More broadcast and print news publications started publishing factual analyses of campaign ads during the 1990 midterm elections. In 1991, CNN reporter Brooks Jackson, who years later launched FactCheck.org, started reporting on political campaign ads for a fact-checking segment. In an interview with Graves, Jackson said he felt a little uncomfortable with the fact-checks because of the necessity to editorialize. He had not been trained to analyze claims and provide judgments on their veracity. But for many journalists covering the elections, fact-checking proved to be a useful tool for combating political spin (Dobbs, 2012). In 2003, Jackson helped start FactCheck.org, the first publication devoted to fact-checking political statements full-time (Graves 2016). Since then, fact-checking operations have flourished. PolitiFact and the Washington Post started their fact-checkers in 2007. Operating out of the St. Petersberg Times, now the Tampa Bay Times, PolitiFact's coverage of the 2008 election earned the website the 93 Pulitzer Prize in National Reporting. Many regional news organizations created fact-checking operations after the 2008 election, either operating on their own or in conjunction with larger organizations. Dobbs (2012) started the Washington Post's fact-checking service out of a sense that \"Washington reporting had strayed away from the truth-seeking tradition [...] By focusing on the 'he said, she said' aspect of reporting, we were permitting presidential candidates and others to get away with sometimes outrageous falsehoods\" (p. 3). His editors wholly approved his idea with only one objection: One editor did not like the idea of using a Pinocchio nose that would grow depending on how false a claim was for the rating scale because he thought it would offend some readers. Instead, they decided to keep Pinocchio's nose the same length but give between one and four Pinocchios to fact-checks, with one being somewhat true and four being a flat-out lie. In his experience with the Pinocchio system, Dobbs has found it to be frustrating at times. Many political claims don't fall neatly into categories of truthfulness: \"Exaggeration, spin, and artful insinuation are much more common political sins than outright falsehoods\" (Dobbs, 2012, p. 9). Even on a rating scale that he designed himself, Dobbs struggled to adjudicate facts. Fact-checking bias Political fact-checkers have been heavily criticized over the past decade for masking what critics call biased reporting under the veil of a fact-check. Several times, MSNBC anchor Rachel Maddow has criticized PolitiFact's ratings system, pointing to perceived inconsistencies in ratings or taking issue with the reasoning for a particular rating. In one PolitiFact take-down she said fact-checking has become \"pointless at a time in our country when we really need it to mean something, because PolitiFact exists and has branded themselves the generic arbitrator of fact 94 and the paragon of fact-checking, and they are terrible at it\" (Wemple, 2013, para. 5). Maddow is not alone. An entire website, PolitiFactbias.com, devotes itself to analyzing PolitiFact reporting. As often as they can, the site's bloggers point out where they perceive flaws in reporting and connect it to their idea that PolitiFact has a liberal bias. The fact-checking process does not purport to be scientific, but it does borrow three things from the scientific method: claims, evidence, and judgments (Graves, 2016). Fact checkers select only verifiable claims, not opinions or predictions. Claims are either chosen by fact checkers or selected from reader suggestions (Adair & Holan, 2013). Journalists try to choose fact-checkable statements that only include one verifiable claim, as opposed to multiple claims lumped into one statement. Fact-checkers then seek out data, documents, experts and nonpartisan sources and investigate the claim. After compiling the information into a report, a judgment is made by reporters and editors (Graves, 2016). Sometimes this judgment occurs in the form of a rating. Other times it is framed through word choice in the story's body or headline. This process is not perfect. Uscinski and Butler (2013) have found instances in which fact-checkers gave ratings to statements that included more than one claim as well as instances in which fact-checkers checked predictions, which can be problematic because there is no sure-fire way to know what's going to happen in the future. Among the university researchers who have studied fact-checking in the past several years, Uscinski and Butler are some of the more outspoken researchers against the journalistic format. One of their main criticisms is with the ability of journalists to only attain a surface-level analysis of a claim, due to the time constraints and limited available resources of the profession. They suggest fact-checking would be better left to social scientists, who can conduct experiments and research to determine a political reality. The fact-checking process, they argue, is inherently biased because journalists rely on their gut in 95 deciding which claims to check. Rating systems are criticized by researchers and news readers as another area where fact-checkers display overt bias. As journalists who have worked as fact-checkers have done, Uscinski and Butler point out that there is a lot of gray area in political speech, and a statement cannot necessarily fit neatly into a category of truth. Another issue is that ratings tend to act as a reflection of a politician's character. PolitiFact compiles ratings for each person who has been fact-checked into a graph that shows what percent of his or her fact checks have been given each type of rating. A politician with more false ratings is then portrayed as more dishonest than a politician with a greater amount of true ratings. More than anything, the researchers take issue with the idea of the fact-checker as arbitrator. In a scathing criticism of ratings systems, Uscinski and Butler (2013) say: With rating systems enumerated by \"Pinocchios\" and capped by \"pants-on-fire\" ratings, fact-checking appears in many respects little different than other sensationalized \"infotainment\"-style news coverage that attempts to shoehorn reality into commercially marketable segments. But arguably it is worse, because it both reflects and encourages a simplistic understanding of a complex world. (p. 163). To them, the fact-checkers are not holding politicians accountable but are instead providing analysis of political situations and framing it as scientific. A number of different researchers have analyzed PolitiFact's data to look for indications of bias. An analysis of 500 PolitiFact stories found that 75 percent of the statements rated false or pants on fire were from Republicans (Ostermeier, 2011). In a similar study from George Mason University (2013), out of 100 fact checks, Republican claims were rated false three times more often than claims from Democrats. However, without the context of the individual claims, it is 96 difficult to prove bias by merely aggregating ratings. The question still stands: Is PolitiFact biased or do Republicans lie more? In defense of fact-checking What critics of fact-checking often fail to note is the practice's potential benefits. In 2011, Democrats in Congress reacted to a Republican-led change in Medicare coverage funding by repeatedly claiming in interviews and public appearances that Republicans voted to end Medicare (Adair & Holan, 2011). PolitiFact rated the claim false or pants on fire in nine different fact-checks. After PolitiFact named the claim the 2011 Lie of the Year, the number of articles in the Congressional Record that included references to ending Medicare was cut in half (Amazeen, 2013, p. 15). NyHan and Reifler's (2014) experiment on fact-checking's effectiveness in influencing political behavior contains possibly the most substantive evidence that fact-checking discourages lying by politicians. The researchers sent letters to a randomly assigned group of politicians notifying them that they would be fact-checked and reminding them that the respect and support of constituents would be at stake if they were caught lying. A control group did not receive letters. The researchers then observed media reports and fact-checks of the politicians included in the study and found that the group that was warned about fact-checking was substantially less likely to receive a negative fact check rating or have their statements questioned by reporters. Though the findings are correlative and do not prove the effect, the chance of changing political behavior for the better is a possible upside to fact checking. More important is the effect on the reader. A survey from the Annenberg Public Policy Center (2012) found that people who used fact-checking websites to learn whether a political claim was accurate were significantly more 97 likely to correctly answer questions about current events and civics than those who did not use fact-checking websites, even after controlling for several factors, such as party identification, education and age. The study, though encouraging for fact-checkers, comes with a caveat: There is no way to tell if people who read fact checks are more knowledgeable about current events or if people who are knowledgeable about current events are more likely to read fact-checking websites (NyHan & Reifler, 2015). At the minimum, fact-checks can help people better understand political issues (Nyhan & Reifler, 2015). Studies on reader response to corrections of misinformation conclude with mixed results. Some studies show that correcting falsehoods decreases misperception (Thorson, 2015). Other experiments produce results that complicate this. Nyhan and Reifler (2010) observed little to no difference in misperception when a person had been given information that corrected the record. In some cases, the corrections actually produced a backfire effect in which misperceptions were increased. The theory states that ideological convictions can override a person's willingness to accept corrected information (Nyhan & Reifler, 2010). Neurological evidence of the effect points to chemical activity in the brain's insular cortex and amygdala to explain why a person might hold tight to his or her beliefs despite abundant evidence disproving them. Kaplan, Gimbel and Harris' (2016) study on the brain's response to counterevidence that contradicts one's ideological beliefs interpreted increased brain activity in the amygdala and insular cortex to be the brain's way of protecting itself from information that could attack deeply held beliefs. Our biological reaction, then, might be to distrust the information source, selectively avoid some information and form counterarguments. While Democrats and Republicans are both equally susceptible to believing misinformation (Thorson, 2015), people are much more likely to believe falsehoods that suit their own ideological beliefs (Nyhan & Reifler, 2010). 98 Despite this, people generally want to see more fact-checking journalism though interest varies by demographics. Survey research by Graves, Nyhan and Reifler (2015) indicates that interest is greater among people with higher levels of education. In addition, Democrats favor the practice more than Republicans, which might represent an opportunity for journalists to learn how to expand the appeal of fact checking to conservative-leaning voters. And there is ample room to grow: About half the surveyed population was unfamiliar with fact-checking. However, 94 percent of respondents who were aware of the practice had a favorable view of fact-checking, compared to 73 percent favorability among respondents who were unfamiliar. For newsrooms looking to offer new reporting formats, research and survey results provide insight into an area of journalism that readers, listeners or viewers might be interested in. The challenge would then be to figure out how to present fact-checks. Should reporters and editors use ratings systems? If so, what would that ratings system look like? Which words would journalists use to summarize the veracity of a claim? This project seeks to identify best practices for reporting and presenting fact-checks. My research question is: To what degree do rating systems move a fact check from a factual analysis frame to a strategic game frame? In other words, do rating systems trivialize fact checks? Methodology My research will focus on nine organizations: !The Associated Press !FactCheck.org Post !PolitiFact Missouri !Poynter I will conduct semi-structured interviews with journalists on fact-checking teams. My goal is to get interviewees to discuss the merits of their fact-checking process and the way they format fact-checks along with the instances in which they have struggled with them. I plan to interview one journalist per organization. I already have contacts for journalists at PolitiFact, PolitiFact Missouri and Poynter. Because the way fact-checks are framed differs between organizations, the questions will vary some with each interview. I intend the conversations to be mostly free-flowing, but I will go into every interview with a list of prepared questions. In addition to interviews, I will collect the fact-checking policies of each organization and include them in an addendum to my final project. Many fact-checking policies are posted online. In cases when I cannot retrieve the policies, I will contact the organization. Interviews will cover three topics: The reporting process, rating systems and media cynicism. Here are examples of questions I might ask: 1.!How do you decide what to fact-check? 2.!How do you usually go about your reporting process? What typical steps do you take to investigate factual claims? 3.!Can you give an example of a time when you had trouble choosing a rating for a fact-check? 100 4.!What kind of public reactions do you get to your ratings? How do you respond? 5.!Has anyone ever admitted they lied after you published a fact-check? 6.!Do your analytics show that your readers actually read your fact-checks? Or do readers scroll past the reporting to see the rating? 7.!Why use a rating system? Why did your organization decide to use the rating system it uses? 8.!Are there ever times in which you do not give a rating to a fact check? 9.!What is your stance on using the word lie? What is your organization's stance on using it? 10.!Are you aware of the public perception that fact-checking is unfair to Republicans and biased toward liberals? 11.!Does it worry you that there is research showing that a person's biological reaction to seeing information that contradicts their ideological beliefs is to write off the source of that information? 12.!How do you try to combat the perception that the media is liberal/biased in your fact checks? 13.!Do you think rating systems take the nuance out of the reporting in fact checks? Why or why not? Possibilities for Publication Columbia Journalism Review, Poynter, MediaShift 101 References Aalberg, T., Str\u00f6mb\u00e4ck, J., & de Vreese, C. H. (2011). The framing of politics as strategy and game: A review of concepts, operationalizations and key findings. Journalism, 13(2), 162 -178. Adair, B., Holan, A. D. (2011). Lie of the year 2011: 'Republicans voted to end Medicare'. PolitiFact. Adair, B., Holan, A. D. (2013) PolitiFact, PunditFact and the Truth-O-Meter. Politifact. Amazeen, M. A. (2013). Making a difference? A critical assessment of fact-checking in 2012. New America Foundation Media Policy Initiative Research Paper. Annenberg Public Policy Center. (2012). The public still has a lot to learn about the 2012 presidential race, but those who seek who seek out fact checking on the internet know more. The University of Pennsylvania. Bloyd-Peshkin, S., & Sivek, S. C. (2017, March 23). Magazines find there's little time to fact check online. Columbia Journalism Review. Cappella, J. N., & Jamieson, K. H. (1996). News Frames, Political Cynicism, and Media Cynicism. The Annals of the American Academy of Political and Social Science, 546, 71-84. Dobbs, M. (2012). The rise of political fact-checking: How Reagan inspired a journalistic movement: A reporter's eye view. New America Foundation. Entman, R.M. (1993). Framing: Toward clarification of a fractured paradigm. Journal of Communication. 43(4), 51-58. Entman, R. M., Matthes, J., & Pellicano, L. (2009). Nature, sources, and effects of news framing. In K. Wahl-Jorgensen & T. Hanitzsch (Eds.), The handbook of journalism studies (pp.175-190). New York, NY: Routledge. Fairhurst, G. & Sarr, R. (1996). The art of Framing. San Francisco: Jossey-Bass. Fandos, N. (2017, January 24). Trump Won't Back Down From His Voting Fraud Lie. Here Are the Facts. The New York Times. Gamson, W. A., Croteau, D., Hoynes, W., & Sasson, T. (1992). Media images and the social construction of reality. Annual Review of Sociology, 18(1), 373-393. Gonzales, R. (2017, January 25). NPR And The Word 'Liar': Intent Is Key. National Public Radio. Graves, L., Nyhan, B., & Reifler, J. (2015). The diffusion of fact-checking: Understanding the 102 growth of a journalistic innovation. American Press Institute. Graves, L. (2016). Deciding what's true: The rise of political fact-checking in American journalism. New York: Columbia University Press. Hepworth, S. (2017, March 8). The New Yorker's chief fact-checker on how to get things right in the era of 'post-truth.' Columbia Journalism Review. Hertog, J., & McLeod, D. (2001). A multiperspectival approach to framing analysis: A field guide. In S. Reese, O. Gandy, & A. Grant (Eds.), Framing public life: Perspectives on media and our understanding of the social world (pp. 139-161). Mahwah, NJ: Lawrence Erlbaum Associates. Investigations-Guidance in Full. (2015, July). BBC. Retrieved from http://www.bbc.co.uk/editorialguidelines/guidance/investigations/guidance-full Jackson, B. (2012, December 21). Firefighters, Fact-Checking and American Journalism. FactCheck.org. Kaplan, J. T., Gimbel, S. I., & Harris, S. (2016). Neural correlates of maintaining one's political beliefs in the face of counterevidence. Scientific Reports, 6. Kovach, B., & Rosenstiel, T. (2014). The elements of journalism: What newspeople should know and the public should expect. New York: Three Rivers Press. Leonhardt, D. (2017, March 20). All the President's Lies. The New York Times. McPhee, J. (2009, February 9). Checkpoints. The New Yorker. Messaris, P., & Abraham, L. (2001). The role of images in framing news stories. In S. D. Reese, O. H. Gandy, & A. E. Grant (Eds.), Framing public life: Perspectives on media and our understanding of the social world (pp. 215 - 226 ). Mahwah , NJ: Lawrence Erlbaum Associates. Nelson, P. (2012, January 2). Check the facts: 10 tips for copy editors. American Copy Editors Society. Nelson, T. E., & Oxley, Z. M., & Clawson, R. A. (1997). Toward a psychology of framing effects. Political Behavior, 19 (3), 221-246. Nyhan, B., & Reifler, J. (2010). When corrections fail: The persistence of political misperceptions. Political Behavior, 32(2): 303-330. Nyhan, B., & Reifler, J. (2014). The effect of fact-checking elites: A field experiment on U.S. state legislatures. American Journal of Political Science, 59(3), 628-640. 103 Nyhan, B., & Reifler, J. (2015). Estimating fact-checking's effects: Evidence from a long-term experiment during campaign 2014. American Press Institute. Ostermeier, E. (2011). Selection Bias? PolitiFact rates Republican statements as false at 3 times the rate of Democrats. Smart Politics. Powell, T. E., Boomgaarden, H. G., De Swert, K., & de Vreese, C. H. (2015). A clearer picture: The contribution of visuals and text to framing effects. Journal Of Communication, 65(6), 997-1017. Schudson, M. (2001). Journalism: Theory, Practice & Criticism, 2(2), 149-170. Lawrence, R. G., & Schafer, M. L. (2012). Debunking Sarah Palin: Mainstream news coverage of 'death panels.' Journalism, 13(6), 766-782. The Center for Media and Public Affairs. (2013). Study: Media fact-checker says Republicans lie more. George Mason University. Thorson, E. (2015). Identifying and correcting policy misperceptions. American Press Institute. Uscinski, J. E., & Butler, R. W. (2013). The epistemology of fact checking: Critical review. Journal of Politics and Society, 25(2), 162-180. Wemple, E. (2013, May 08). Rachel Maddow pans PolitiFact, again. The Washington Post. 104 Interview Transcripts Alexios Mantzarlis There's a debate about whether rating systems cause fact-checkers to be subjective in their reporting, and I'm wondering what your thoughts are on this. Full disclosure, I come from, the fact-checking organization that I launched, Pagella Politica, had ratings, still has ratings. I think ratings are very helpful. And I think at the outset they sort of help reporters be particularly careful as to how they evaluate judgments, careful about how they evaluate claims, because they need to come to a final judgment. They need to justify to the reader to the person being fact-checked. So I think in prinicple and very often also in practice, it is a way push us toward greater objectivity. I am wary and conscious of the fact that these rating systems do give the sort of sense that they are some kind of scientific scale... (inaudible) that you put it into the liquid and you get the response. And in that sense, I am concerned, especially of how our readers perceive it. Because yeah, as you know well having interned for PolitiFact, the difference between a half-true and an almost true or the difference between an almost false or whatever, it's a very close call. So over thousands of fact-checks, are we always making those close calls the same way? Probably not. So I do think that's where, if not subjectivity, at least some inconsistency can creep in. I think that's a long-winded way to say yes and no. I know that the organizations that don't use rating systems, I think a good example is the Associated Press. They just have the claim and they just report what they know. You mentioned that rating systems help fact-checkers think about their fact-checking. It helps them make a judgment. Would you say that even in the places where they're not using rating systems that they are making a judgment? Yeah. I mean, most of the fact-checkers around the world, whether it's FactCheck.org, don't use rating systems. So there's excellent fact-checking with meticulous sort of judgment making without the need for a rating system. But I think the risk is, and sometimes we do see it, is that if you don't have to come to an actual conclusion, you sort of throw all that facts that you know on the page, and you're not really adjudicating. You're kind of giving context, which is helpful and useful and important. But if you're not giving the reader a sense of 'ok, am I believing this thing or ..?' Then you're not delivering the service that fact-checking was launched and born to deliver. I know a lot of people who scroll past the reporting and just go straight to the rating. Is there a risk that rating systems could detract from the nuance of the fact-check? For sure. A good chunk of readers come to see the scale and leave, right? And so, yeah, it is a risk. We need to also be mindful of the fact that in 2017 most people anyway just stick to the headline. So can the headline say everything rather than sort of repeat the claim? That's sort of the flip side of it. 105 Actually I think Poynter, Daniel, the reporter on the fact-checking network, is writing a piece today or next week on a Turkish fact-checking site that just moved its rating scale from the home page to I think the bottom of each fact-check. And they found a lot more engagement. So I think perhaps there can be some innoculating format and website changes that we could be making as fact-checkers to at least reduce the likelihood that people just read the rating and get the fuck out. So then it comes back to the formatting. We can think about ways to engage readers. That's a good point. So I want to move to the perception of bias. I know that in the United States the common perception of fact-checkers is that they're biased against conservatives and they favor liberals. So I'm wondering, internationally, is this a common perception? How do public attitudes for fact-checkers differ in other countries? I get asked this a lot. This particular issue doesn't quite replicate well around the world. In a lot of countries the systems aren't bipolar, but mulitpolar. So it's hard to attack a fact-checker for being sold to one side when there are maybe four or five sides. Obviously we've seen it's not unfrequent for people to be annoyed at fact-checkers and therefore to explain away the findings by suggesting they're biased. I think it's unique to the United States that these accusations come particularly from one side of the political spectrum. So you would say it's our two-party system? In general I'd say that there's something particularly about the way Fox and its accolates in the media and how their system started. That there was not so much a political, but a mediatic effort to discredit mainstream news operations that came and was most successful from right-wing media outlets like Fox. And so that has sort of primed people who follow those news outlets to accept those criticisms. Now I will say the PolitiFact and the Washington Post fact-checker, two of the major political fact-checking operations, both excellent, both committed to nonpartisanship, are both hosted in liberal-leaning papers. I think that's where part of the perception may come from. But when I see FactCheck.org being attacked as well, then I kind of think that there's something more malicious in operation. I saw that one of Facebook's solutions to the perception of bias for fact-checkers is that they hired a conservative fact-checker. I'm wondering, do you feel like that's a good solution? Is it creating balance? I don't think there is such a thing as a fact-checker for one side or the other side. I think at most there are some fact-checking organizations being held within outlets that have had on their editorial pages consistent opinions towards one side or the other. That said on Facebook, if there are ...and we're kind of involved in that because in order to be a part of Facebook, of the fact-checking work, you need to be a signatory of the IFCN code of principles. So any new partner will have to sign up to the same principles of transparency and nonpartisanship that existing ones have promised to abide by. So they're welcome. If the Weekly Standard comes up with a continuous and high-quality fact-checking operation, that may be perceived by conservative readers as a more credible source than maybe PolitiFact. And so that could be an option. I would caution against the false balance that we've seen in the media throughout to suggest that as long as its a conservative and as long as they're putting fact-checks on their page, then that's fine. 106 What we need is more media outlets doing consistently good, high-standard fact-checking. If we can get it from media outlets whose editorial pages have a varying set of opinions, even better. What are the best ways to respond to accusations of bias? How should reporters handle that? One thing is a choice of the sources, experts and data sets. I think there has been a little bit of study on this. Sort of finding the surprising source. So finding maybe a pro-military think tank or something that would seem to counter their own interests in giving an expert opinion can help. So really digging into what the sources may communicate to the readers I think is probably the most effective way. But also I think just interacting with your audience, right? Back when I was at Pagella, a lot of the times when reporters would get accused of bias or preferences, once you actually scratched the surface and asked them what specifically in the fact-check was not okay. What do you think was missing, what source is not fine? Most of the time you can start healthy conversations that get you out of this name calling. Granted, there's going to be 10-20 percent of the audience that won't accept something. And that's fine. You're not going to convince everyone at the same time of everything. I was talking to Linda Qiu the other day about some of the feedback she gets from readers. She said sometimes readers send her hateful messages, and readers sometimes attack her for her race and gender. In your experience with fact-checkers, is this a problem across the board? Do women and people of color receive more hate from readers than white men? I don't think, especially in the U.S., that there is a sufficiently diverse set of fact-checkers to answer that question with data. Linda echoes what Michelle Lee, formerly of the Washington Post fact-checker, experienced. Is it worse, some of the horrible stuff that minorities and women have to live through on other beats? I don't know. Unfortunately, it's a particularly vitriolic and vile moment. So the type of hate that fact-checkers receive, you would say its kind on par with what reporters on other beats receive? Yeah, at least on beats that deal with things that get people riled up like politics. One last thing before we go, does it worry you that there is research showing that a person's biological or psychological reaction to seeing information that contradicts their ideological beliefs is to just write off that source of information? No because much of that research has been disproved. The backfire effect is sort of the origin for much of this conversation, failed to get replicated in a much larger study. And the original authors also walked it back and worked with the new authors to find that it's a very very limited case. In most cases people will, on average, change their mind towards the more accurate information. And there have been now five or six studies over the past year to confirm this. 107 Now, people are fact resistant but not fact immune. We do have confirmation bias. We do have motivated reasoning. We do have all kinds of things that make it less likely to accept things that go against our opinions. But it's neither impossible nor does it not happen. Unfortunately the field has been slow to update. That paper from 2006 was extremely well-cited. So if you look for stuff, that comes up a lot. This is a personal pet peeve honestly because I've seen it. A lot of these post-truths and post-fact headlines that we've seen on other media outlets have been sort of predicated on that one 2006 study. And so it's a little ironic that we're sort of stuck in a place that we're discussing the fact that people don't adapt to, don't change their mind in front of facts. And of course the people that are saying that are doing exactly the same thing by ignoring new evidence. Angie Holan I just want to start by asking: Why use a ratings system? What's the case for it? Well when we conceived of PolitiFact, we started off thinking about ratings, and because the site is so highly structured, it made sense for us to have ratings because we wanted to be able to sort statements by relative accuracy. You can't really sort and analyze findings without having some sort of ratings system, even if it's not even if it's not set as a literal rating. You have to give it, if you want to sort it you have to give it some sort of like a standardized description. So we felt like ratings were just the most straightforward way to do this. Why did you want to be able to sort the fact checks? Well any kind of journalism, when you apply structured data, it gives you more dimensions for reporting and analysis. So it's like if you just have a database of news stories, it's really hard to spot trends or summarize. And we wanted to be able to like pull up all the statements on a given topic or on or that a given person said. And being able to look at the ratings gives you a quick snapshot of relative accuracy. Now I think some people take the ratings too far in what they think we're trying to say, because we don't fact-check a random sample of what any one person says or a random sample on any one topic. So some of our audience sees this as an opportunity for us to have biases and bring our biases in, but that's not what we're intending. OK. Can you give an example when you had trouble choosing a rating? A lot of times when deciding whether to rate something mostly true or half true. Those are some of the most difficult choices because half true is a fairly positive rating. I mean, mostly true is a fairly positive rating and half true sounds shady. So there's a big gulf there. I always found that gap to be particularly tricky. What types of types of fact-checks do you tend to give more half trues than mostly true? Well mostly true is pretty accurate. A half true tends to be like, Yeah there's something here but there's also stuff that tends in the opposite direction. I mean the half true rating really is a 50-50 108 rating. I think some people see the Half True rating as suggesting bad intent on the part of the speaker. And we don't really intend that to be the case. But the Half True rating, I find is... I wish we could make it a half true, half false because I think that would maybe convey better that we're trying to...that's supposed to be our 50-50 rating. In the past decade, have there been any other ideas for changing the rating system? We did make one change early on that we used to call barely true, (but we changed it) to mostly false because people thought the barely true sounded too positive. I've often wondered if we should add a rating called inconclusive, but at the end of the day, I don't think that would help. I think that would add confusion. Some of the academics who study our ratings say that our readers really struggle with what to make of the half true rating. And I think they might also struggle with an inconclusive label. Yeah. So are you guys thinking of changing that in the future? No, we're not thinking of changing it. And what I would say is, because of the academics who say that readers are confused by the Half-True rating, I try, as someone who helps determine the ratings and votes on the ratings, to really push myself off of half true, unless I really feel like no other rating rating is appropriate. Half True is my, just speaking for myself, half true is my rating of last resort when it really is like kind of throw your hands up. What about times when you decide not to give something a rating? Sometimes it's when the evidence is inconclusive, and it's very unclear which way it's pointing. Sometimes we don't rate something because the person spoke in a confusing manner and it's not exactly clear what they're saying. There's a lot of reasons to not read something. Sometimes we don't rate something just because we're not sure if we have all the evidence yet, and we want to give time for more evidence to come in. OK. And do your analytics, do they show that the readers actually read the fact-checks or do readers tend to scroll to the bottom and read the summary? Yeah, I couldn't give you a good analytically based answer that. I would say some of the fact-checks seem very readable because people will spend a lot of time on the page. And what kind of public reaction to you get to your ratings? Oh it runs the whole range of what you'd expect. And usually I find people say it was a good check or not based on whether they agreed with the rating. And people complain about fact checks when they don't like the ratings, and they will admit that everything else about the fact check was sound that they just like the rating. Do you tend to notice that the complaints are coming more from like a certain political background or ideology? Or is it pretty much equal with both liberals and conservatives? 109 We get more complaints from conservatives about being part of the liberal media. I don't think that's particularly because we're fact-checkers or what we choose to fact-check. I just think that is the rap that a lot of conservative readers make on media that are not overtly conservative. I'm just kind of curious, there's the site, PolitiFactBias.com. What are what are your thoughts on that site? That seems to be one guy who's been around for a long time, and his complaints just seem to be that we don't have good, that we don't give enough good ratings, positive ratings to conservatives. And then he just kind of looks for whatever evidence he can find to support that point. Do you guys ever read his stuff? Does it ever worry you? He's been making the same complaint for so long that it has tended to become background noise, to be honest. I find him just very singularly focused in his complaints, and he very seldom brings up anything that I learn from. But he's very, you know, I give him credit for sticking in there. I mean he used to give us, like when he first started he would give us grades for our reporting and our editing. So it would be like grades for this report: Reporter Angie Holan, editor Bill Adair. And like we could never do better than like a D-minus. So it's just like whatever. What I find is it's hard for me to take critics seriously when they never say we do anything right. Sometimes we can do things right, and you'll never see it on that site. So the reaction that you get from readers to your fact-checks, do they vary from reporter to reporter based on that like that reporter's gender or race? The complaints we get about the reporters? A little bit of background. I interviewed Linda. She was talking about how she tends to receive a lot of like racist and sexist complaints from readers. Yeah, I think that is more, like I don't get racist... Well let's see... That's the kind of feedback that people tend to get directly. I get sexist comments directed at myself. I don't get sexist comments directed at other reporters. I think that that's the kind of like attack that that they tend to send directly to the person that they're attacking. Although I did get one email from a reader that said once that I looked at your staff and it seems like it's run by women, and it seems like your project is run by women and Jews. Which is like...ok? It's like yeah, I mean, you know we do have women on staff and we have some people of Jewish descent on staff and like, I don't know what to make of that. But I do think what my take on it is that when people are looking to attack us, they will grab anything at hand that they see as a means of attacking. 110 I've gotten a lot of gender-based attacks. I mean for some reason some of the readers who dislike us like to go to the insult of \"whore.\" That seems to be super popular. That's the insult that's generally thrown at women and not men just because of the cultural context. But among the male reporters do they feel like they receive just as much, like I guess you'd call it like maybe hate-tweeting or hate emails as female reporters? Yeah, I don't know. It would be interesting if you could quantify that. Changing subjects, has anyone ever admitted that they were wrong or lying after you published a fact-check? Yeah. No one's ever admitted that they were purposefully lying and now they're caught, but they have said stuff like, \"Oh I got that wrong I'm sorry.\" And sometimes even in the checks, like sometimes we call somebody and, before we can publish, they have recanted or.... but we usually often check them anyway because it's like if someone goes on a TV show and says something that's wrong. Well if we email them and then email us back and say, \"Sorry I guess I goofed. Sorry about that.\" Well it's like we're the only ones who saw that. Not the people who saw that TV show. Yeah, so it's important to set the record straight. Exactly. So most news organizations don't use the word lie. You know, obviously it implies intent. I'm assuming PolitiFact's stance is also to not use it... We usually don't use it, but we do use it for Lie of the Year. I just think if we're saying something is false, inaccurate, misleading and exaggerated, I don't think we need to say they lied as well. The only reason we have to live that year is is frankly because it's so catchy, not because like we're trying to make you the kind of broader point about the word lying. I do think that discussions of intention are often just not useful because you can never prove someone's intention. You can't get into their heads. So I discourage speculation about people's intentions, as a general rule. Now sometimes like what they're saying is phrased so puzzlingly or confusingly like if you didn't speculate it would be weird. But like we don't need to like extra speculation, and every now and then I see that copy and I just take it out. We don't know what they're thinking or whether they know that they're being deceptive. And especially, especially President Trump. I think he, it is very unclear, just generally speaking, because he says so many things that are inaccurate, if he knows what he's saying is inaccurate or not. There are many instances where I suspect he really doesn't realize or know or care that he's speaking inaccurately. So like I don't want to impute a bad intention if it's not provable on Trump or anybody else. So I find it's better to steer away from the the topic of intention. And I think lie is the word now, that 111 people assume has some intention behind it, but like I think even the word lie is actually kind of problematic and in dispute because I don't think it always has that intention element. And the example that I use is like we all we all talk about you know lying to ourselves. You know I the cheeseburger couldn't hurt me but I was just lying to myself. Well is there intention there? That gets into some deep psychological issues of motivating reasoning. And like if you have a motive for saying something I mean you might really believe it even if it's wrong. So anyway, there was my long rambling answer. To play devil's advocate, the Truth-O-Meter has that, you know, Pants on Fire, which is kind of a riff off of \"liar liar pants on fire.\" Is there an argument there that, in a way, PolitiFact is calling the speaker a liar? We just see that as a way of saying this is this is ridiculous. This is absurd. Sometimes we've rated things pants on fire just that are extremely, extremely wrong. Or if they have elements of being offensive. I think I see the pants on fire rating as denoting extreme wrongness. Now other people might see intention, but I don't know. I will tell you, you were also asking about ratings earlier and analytics. We can tell from the analytics that the pants on fire rating is just extremely popular in its own right. People go to the Pants on Fire page. That's one of the most popular pages in site, more so than any of the others standalone rating agencies. Why do you think that is? I just think people think it's funny. Yeah. They just want to see people caught in a lie or something? Yeah, I think they want to see people caught in a lie. I think there's also like an inherent love of the tall tale or the outrageous statement. I mean that's what drives fake news. So, you're obviously aware of the public perception that fact-checking is unfair towards conservatives. So how do you try and combat that perception in your fact-checks? You know that's a good question. Right now at this particular moment because Republicans hold the presidency and both houses of Congress, I just, it's a struggle. In times when there's been more partisan balance in political power, we have consciously tried like hey let's try to fact check a roughly equal number of Republicans to Democrats. And we can't really do that right now because it wouldn't make sense. I mean the Democrats are in minorities in the Congress. We're not going to check them 50 percent of the time, and especially when we have a president like Trump who says a lot of inaccurate things that need fact checking because our first mission before any sort of partisan proportionality is to fact check things that are wrong. And with Trump in the presidency, it's our first duty to fact check him when he says things are wrong. So our old method of showing our independence where we would fact check a roughly equal number of claims, we haven't been doing that lately. But I just think that right now we have to correct the 112 wrong information that's circulating in politics. And if people want to charge bias, my my answer now is tell me which particular fact check do you think we got wrong and let's discuss that. Then when somebody does, you know, reach out to you or your fact-checkers and says, \"look this is totally biased,\" or something like that, what do you say to them? Well I look at what they're saying and I ask myself is it bias? And I try to look for ways we can improve in the future. We tend not to pull a lot of stuff back because... like OK, if something is inaccurate or wrong, yes we will pull it back. Then if it's not inaccurate or wrong and people are like I just think you have the wrong emphasis or you picked the wrong rating because of your liberal bias. We don't tend to look at that stuff again because it's just like we'd be looking at stuff all the time. So what I tell readers usually is I say I'm sorry you disagreed with us on this one. I hope you still respect our methods and we'll come back and read our other items. But lately I don't get like kind of thoughtful like hey I think this was biased. I get stuff like. I hope you're happy you're destroying the country. Which is like, I mean that's a charge of bias. But it's not one that there can really be any dialogue about. Have you found success in chatting with people and chatting with readers and helping them see where you guys are coming from? You know, I have to say, when I get critiques from readers, I try to incorporate them into broader work that we can publish on the site. I find one on one interactions with readers to be challenging and time consuming. We're hoping in 2018 to hire an engagement editor who can spend more time on reader interaction. But when we got to a certain size it PolitiFact, and like when I was a reporter, I had a lot of one on one interactions with readers. But as we've gotten to be a bigger and bigger organization, my responsibilities increased exponentially. It's hard to justify one on one interaction And I read on my email, I look at all the tweets I see and sometimes I do reply, especially to some of someone looking for more information or I can give them a simple answer. Yeah, but people who are like, pretty critical, I'm not going to send them a long lengthy email defending us just because I can't. And that's not talked about that much in journalism because I think we all like the idea of engagement, and certainly online. We try to engage with people in the public online space of responding to tweets or comments on Facebook. But there's a real element of if we're going to continue to produce reports, we need to focus on producing the reports. And there's not a whole bunch of extra time to do reader interaction just for the sake of responding to claims of bias. And maybe that's all a big cop out. I don't know. Well the other thing, you don't know what the intentions of the readers are because there's a percentage of reader interaction, and I don't know what percentage is, but that I would just consider partisan hack. They're not trying to really learn anything from you. They're not trying to give you constructive feedback. They're trying to work the referee. Or frankly just abuse people, you know like, \"you're a whore and you're destroying the country.\" What am I supposed to get out of that kind of comment? 113 I feel a little guilty about not responding to every reader email I get, but it's just it's not feasible. And so my last thing I want to touch on is fact-check editing. Are there any particular words or phrases that you try to eliminate or that you worry might lead a reader to think you're biased? What kinds of things do you edit out? I edit out stuff that expresses some kind of expectation about how someone might speak. Like especially with Trump because he has such a documented track record of inaccurate statements. Every now and then, one of our reporters files a piece that has something like, \"Well here he goes again.\" And I always delete out that because it's like Trump, he, yes he has a lot of negative ratings on our site. But I live in hope that one day he will gradually learn to speak more accurately, and our fact checks should give him the benefit of the doubt that this might happen one... that you know, not everything he says is false, and maybe one day soon he'll reduce the number of things that he says that are not accurate. Stuff like that I edit out. We try to follow AP style, and I think AP works very hard to keep out biased claims. We try not to use the phrases pro-choice or pro-life in our checks. AP style is a little bit awkward, but the AP style is actually \"favors abortion rights\" and \"opposes abortion rights.\" We use that. Sometimes I cut out like, I don't know, just stuff that isn't particularly well attributed or documented. Just out of my own curiosity, you guys are going into rural states, Trump country. Is that in response to you know feeling like maybe you're accessing only liberal readers? Yeah it's been it's in response to what our analytics tell us - that we don't have a lot of conservative readers or fewer than there are in the general population. So we're personally concerned about that. And then we're also just responding to general distrust in the media from conservative readers. I mean what we're dealing with is not just the facts problem it's it's the independent media's problem. Jim Drinkard When did the AP fact-checking bureau start? Well we don't have a fact-checking bureau per say. We basically, we use all the people within the AP within bureaus everywhere to do fact-checking where it's most logical to do it from. A lot of it, by far the bulk of it has been done out of the Washington bureau. But we don't have dedicated staff really to do this like some places do like PolitiFact does and that's really their sole thing. We use the reporters that we have assigned a beat to do fact-checking within the areas of their beat expertise. And I think Washington is still remains the sort of intensively beat-driven bureau 114 in the AP globally. So we have a lot of people who are subject matter experts in the fields that they cover. So when something comes up that falls into their (inaudible), we assign them to do the fact-checking that gets done. So it's a slightly different model. The Washington Post, Glenn Kessler and another colleague of his, do all of their fact-checking pretty much. We don't do it that way. We use people who are already pretty schooled in the areas that they're looking into. And so how long have you guys been doing that? It's not clear to me exactly when the format evolved. I can sort of trace it to probably the late 1980s when we first started looking at politics through this lens. And it has kind of morphed and changed over time. Back then there was a lot of consulting with experts. Like finding an outside academic expert or someone else who we would interview and ask them to give their opinion about factuality. What we do now is we basically try to speak with the voice of authority and do that ourselves, so it's not a he said, they said kind of back and forth. It's much more sort of a judicial rendering, sort of a judicial conclusion about what's right and wrong. And I can't exactly pin down a date when that happened. But it's been over time. And it's kind of been fine-tuned most in the last, I would say, 10 years or so. By fine-tuned, do you mean you guys were doing it more often? Yes, more often. I can speak personally about this most recent time period because that's where I've been most intensely involved in it. Several years ago, we had a bureau chief in Washington who basically assigned me to try to promote accountability journalism in the bureau. It's not that it wasn't existing. It certainly has for as far as I know, but it was to be a more intentional effort to get all reporters involved in accountability journalism. And fact-checking was a big part of that. Probably the biggest part of that. So that's been in that last 10-year window. And that was really centered in the Washington bureau. And other bureaus have also... the AP just has its own ethos has been about accountability. But this was an intent to try to ramp it up in this bureau. And then what I did when I got that assignment was to try do some training. We had people come in and talk about fact-checking. I would edit them and critique them and try to sharpen them along with one of my colleagues, Calvin Woodward, who is a really great writer and just has an incredible gut instinct for this kind of journalism. So he and I worked with people to try to improve the product. And the numbers crept up to the point where in the first half of this year when I retired in June, I think we were turning out five or six fact-check stories a week just out of our bureau. And most of them were about the Trump administration. So how do you usually decide what to fact-check? We occasionally will fact-check something that is said by a politician that is true and surprisingly so. It's all about what's interesting and usually that means it's about when somebody goes out of bounds factually, so most of the instances are when someone, usually a public figure, public official, trus-passes on the bounds of reality. And that's the bulk of them. So you guys don't use the sort of rating systems like Pinocchios or the Truth-O-Meter. Why did the AP decide to format its fact-checks in the way it does? 115 You I think that too was kind of a gradual, evolving thing. If you think back to the late '80s when we began doing this, there was no internet, there were no savy graphics that you could put with it. All we had were words, and I think over time, and this is just me talking, I'm not speaking for the AP. When I was practicing this and when we were promoting it to our reporters, I said \"if what you're about here is trying to get to the ground facts of some matter and you're trying to eliminate opinion or minimize subjectivity in your judgments, why would you introduce a rating scale that requires subjectivity?\" It's (ratings) attractive I guess to readers. But we have the entire breadth of the English language to go with. So there are incredible nuances available within our language if we just use it. And so I've always argued that you don't really need a scale, and sometimes it causes problems. PolitiFact does not encourage this, but you have people looking at their judgments and then try to do math problems out of it so to determine which politician is the least truthful. And that's a fool's errand. You can't do that with those ratings, and they will tell you that you can't do it. But people will persist in doing it anyway. So why even go there? So to me that's the reason. We have a wealth of language to describe why people have strayed from the truth in their public statements, and we don't really need a rating scale to make that judgment. So when something is flat out wrong, what sort of language do you use to signify and let people know this is very wrong? We try to make a judgment right at the beginning of the story to let people know what our ruling is, which is kind of the opposite of what Glenn does at the Post. He gets through all the explanation and then makes his conclusion. We try to give it in the first paragraph and then go on to explain why that's the case. It's just a preference I guess. Maybe it's the AP's old inverted pyramid. Give it a lede at the top. We kind of pick whatever is the right word. Sometimes we'll say, \"so and so falsely claimed that.\" Or we might say, \"A particular public figure said this, but that's a stretch\" or \"but that ignores these other countervailing factors.\" It's just whatever the occasion warrants. I remember ....and there are times when you can have some fun with... I can't remember which politician it was. It was probably during the campaign. Somebody claimed that... I think it was probably Obama... that Barack Obama was the least popular president in modern American history. And the second sentence was, \"That's true, if you leave out Lyndon Johnson, John Kennedy, George W. Bush...\" And we listed 17 presidents. All of these presidents had periods in their presidencies when they had lower ratings than whatever Obama had at that time. So if it's really outlandish, you can have some fun with it and be entertaining. And when you can do that, that's almost better than a rating scale. It's more lively and just a little more interesting. Yeah, you can get some creativity in there. 116 Right. How does the reporting process for a fact-check differ at the AP from PolitiFact or the Washington Post? It kind of depends. Often the reporter just happens to know what the reality is and can do it almost based on their own knowledge. But we do cite things. We look at data. We'll give the countervailing information in whatever detail and whatever citations are appropriate. Sometimes these things can turn into an investigative piece of their own. But it just sort of depends on the circumstance and what the material is. I'm remembering, this would have been a couple of years ago, a piece that came in probably an election context. And it had to do with gas prices in the U.S. petroleum market and domestic oil production. And it was part of that perennial argument about are we energy independent? Or are we not? Are we dependent on foreign oil? The thing we did was we had one of our investigative reporters and a science writer look into it and run a regression analysis on U.S. oil production over time and how that correlated or didn't with gas prices at the pump. And there was absolutely no correlation. It was a really smart way to approach it, and it basically debunked the whole idea that somehow if we just drill more ...petroleum is an international market. It;s not confined to the borders of the United States. And it explained all of that, and it was like a 1200 or 1500-word piece. But it was a real slam-dunk of a fact-check because it just debunked the whole idea. So we do those as well. One of things we try to do is write them (fact-checks) as tightly and concisely as we can. And I think readers like to have their time valued. And some of this also grows out of, a big part of what we have done is to fact-check speeches and debates that are very high profile in politics. When you're doing like a campaign debate, we'll have six or seven or eight reporters all listening. We'll have somebody who knows health care policy, somebody who knows law enforcement, somebody who knows foreign policy or defense. And they're all listening for things that are wrong. And we do them quickly and almost in real time so that by the time the debate is over we already have a story on the wire and by an hour after the debate is over we have a pretty full story on the wire. So those are quick hits and those are things that they're listening for and they can quickly look up or just write based on their own knowledge. What kind of reactions from readers do you get to your fact-checks? Well because we don't have the kind of website metrics, at least we didn't when I retired six or so months ago. We have some metrics, but we don't have what I would think are complete ones. Now when we get complaints from people we respond to them, and we do occasionally get complaints, especially from the principals involved, the politicians. But that's actually diminished over time. I think when we first started doing this many years ago, politicians took great umbrage that we would dare to question their factuality. And they've gotten used to it now. They know it's going to happen, and they're not surprised. And often I think they know what they're saying is wrong, and they just say it because they think it's going to help them somehow. 117 But it's not like a constant drum beat of things. One of the things that we do see is sort of whether the Twitter-sphere lights up after a fact-check. And often that lines up following fairly familiar patterns that people love what agrees with them and hate what doesn't agree with them. Have you ever received something from a reader who takes issue with a fact-check you've done? Any sort of reaction where you might get an email or phone call? Yeah, yeah, from time to time. We engage with them on whatever it is. If they find something that they think should have changed what we wrote, we'll evaluate it and examine it and talk to the reporter who is the expert on it and then respond accordingly. Often it's just a disagreement about what weight to give some fact or whether our analysis is correct. But I frankly can't think of a whole ton of those that happened. I don't have a file of them or anything. It doesn't seem like they happen all that often. I mean it's not like an everyday occurrence that we get complaints. Do you receive more feedback on fact-checks than you would on any other article you publish? Just judging from my limited portfolio as an editor, I would say it's roughly comparable. I don't think it differs largely from the kind of response we get on any news story. Has anyone ever admitted they were wrong after you published a fact-check? Yeah. Some politicians... it's not so much an admission, but political statements usually get repeated a lot. So somebody is campaigning or out talking about an issue, and they'll say something in many different forums. But sometimes after you fact-check something, the next time they talk about it, they'll rephrase it a little bit so that it is closer to accurate. And it is interesting who does that and who doesn't do it. You can kind of see patterns in it. I do know what, for example, in the last administration, actually during campaign time, Obama would tweak things he said publically to correct or minimize things that we had found factually questionable. But you don't see that with all of them? No, as a matter of fact, I would say it's probably slightly less common for politicians to change their message based on a fact-check than it is for them to just keep repeating the same thing. When they do persist in saying the same incorrect things over and over, we'll write that again and again. And it doesn't seem to change their mind, which sort of leads you to conclude that they must think that what they're saying is getting out there and to say it is more important than to be correct, for their purposes. We'll write a fact-check that says, \"So and so said this, and it's not any truer than the last three times he said it.\" Along those lines, what is your stance on using the word lie? 118 We don't use it. It seems really straightforward to me. A factual inaccuracy can be done by mistake. It can be done by design. It can be done because somebody doesn't know better. We don't know how that... maybe they believe it. And a lie is something that you tell knowing that it is incorrect. And we can't judge that. It also has an emotional freight with it. It's a word that is very emotionally tinged. And we see ourselves more in the role of a referee or a judge. We're not blaming them for it. We're just pointing out that it's wrong. We're trying to be, not in the fray, but above it so that we can say that's not correct. But we don't say you're a dirty rotten liar. Are you aware of the public perception that fact-checking is biased against Republicans and favors Democrats? I guess I've seen some of that. I'm aware that that gets said. Until Trump came along, Obama was the most fact-checked president in history, as far as we can tell. Certainly we did a lot of fact-checking of Obama. And it's because whoever is the president is important. So we pay the most attention to what's important. So right now we have a president who is factually challenged to a remarkable and perhaps unprecedented degree. And he happens to be the president, so he's getting fact-checked. So starting in January and going through my retirement in June, I was pretty much full-time on fact-checking President Trump. So then when you're writing or editing the fact-check, what steps do you take to try to combat the perception of bias? You briefly touched on this earlier, but how do you try to eliminate bias or subjectivity in the reporting and the wording? Just by being as straight down the middle as we can and being dispassionate in the way we write about it... facts are facts. That fairness element is all we have. It is very easy to make the complaint when there is a conservative in the White House, and that person has sort of set a new standard for fact-free speech, that it's bias. But that's not bias, that's reality. So hopefully over the long-haul, when presidents come and presidents go, they'll be treated the same. And so, people will understand that. Right. So your advice would be, we're going to continue our fact-checking and history will write itself. Yeah. That's just me. I'm not speaking out of any knowledge of the bosses at AP these days or what they might say to that. But to me, that's it. You just try to keep a judicial temperament about what you're doing. My last question: Do you think that ratings take the nuance out of the reporting? Why or why not? I don't think they necessarily do. I think they may be a useful way to engage readers because it's a handy scorecard kind of way to do things. And as long as people look at them and then look 119 beyond them to the actual text and the explanation, then I don't know that it does any particular harm. It's only when that's all that people look at that you miss something. Then you're not getting fully as educated as we'd like people to be about the subject matter. So it's handy, but that's only a problem if people use it as a complete shortcut. Eugene Kiely How do you decide what to fact-check? The idea is that we try to capture both Democrats and Republicans. So we look at what's available on C-Span. We look at what's available on CQ transcripts. We look at the transcripts of the Sunday talk shows. We do that every Monday. That's how we start our week. We look at major speeches by the president. Well, any public remarks at all by the president. Briefings that are done by the leadership in both houses. We have a service called CMAD. It's a media analysis group. So that provides us with TV ads on all federal policy issues, on all house and senate races, on all presidential races and on all gubernatorial races. So we'll use that to identify what races based on the competitiveness of the races. So the idea is that we go to these sources expecting that we're going to be able to find material from both Democrats and Republicans. Given that Congress is majority Republican right now, are you guys trying to balance that out by seeking more (claims from) Democrats? By going through the process that we have, we're going through transcripts that include both Democrats and Republicans. So if the Democrats are holding a press conference about the Cassidy-Graham bill, we're reviewing that. And if the Republicans hold a press briefing on it, we're reviewing that. So what we wind up writing about is different than what we're looking at because then it depends on the claims that are made. So just yesterday we posted a story on the issue of pre existing conditions. And both parties were misrepresenting the Graham-Cassidy bill. And we got that from the transcripts that we review. The difference with majority control is you have the president of the United States and Congress that is controlled by one party. So they're very active in ways that you normally don't see, except for that time when Obama and the Democrats were in control back in 2009 and 2010. So right noiw there's a lot of activity. On top of that you have a president who is holding campaign rallies, who makes comments at (inaudible), who tweets regularly. Three of those things that we didn't have in a previous president. So he's also very active. So there's a lot more opportunities to do fact-checking, period, and in this case to be fact-checking the president of the United States because he's out there more. Right. And so what kind of public reactions does FactCheck.org get to its fact-checks? 120 We get emails sent to us all the time. We get maybe 100 or so emails a day. And during the campaign season, it was hundreds. More than over 200 a day. It was crazy. But there's always going to be criticism from readers who feel that we're being biased in one way or the other. We're hearing a lot from people who support Donald Trump. During the presidential campaign, we got criticism from Bernie Sanders (supporters), from supporters of Hillary Clinton, from supporters of Donald Trump. It depends on the circumstances. Right now we're getting people who criticize us because they feel we're being biased because we're writing a story about Trump's UN speech. And then I'll respond to them like I did this week after we did this story on the UN speech saying, \"Look, this is what we did. Here's a story that we did on Obama's final state of the union address, where we wrote about the same kinds of things.\" The one criticism we get when we do major speech stories like that is \"you're picking on small things.\" It's like well, \"what he said was true, but you say it's misleading. You know, you're nitpicking.\" We get them from both Democrats and Republicans. And we'll say \"well, we're saying it's true but it's misleading because it lacks context, and what we're doing is providing context.\" So that's one of the common criticisms that I get from both sides depending on who's in power and what we're writing about. And we also get a lot of support. We have a very active and engaged audience. We have 50,000 subscribers. These are people who get our weekly newsletter. And we get more than 100 emails a day. I think the majority of them are just questions. People just want to know is this true. \"I read this online, I heard somebody say this on MSNBC, and is this true?\" When you respond to them, they'll inevitably thank us. \"You're providing a good service. Keep up the good work.\" So I would say the majority of public response that we get is supportive. Why did your organization decide not to use a rating system? Because it's subjective to decide on what it's going to be rated, whether it's going to be half true or mostly false. Whether it's going to be one Pinocchio or two Pinocchios injects an element of subjectivity into it. So what we're trying to do is be as objective as possible and lay out the facts of the case. Drawing conclusions, sure. If something is true, we'll say it's true. If something is true but misleading, we'll say that. If something is false, we'll say that. If they're distorting information, if they're taking things out of context. We'll put these labels on them. If you go to share the facts, I'm sure you're familiar with this, if you go to the bottom of our stories, we'll put those widgets in and it'll render a conclusion. It's not a rating system. So we're not saying that this claim is more or worse than some other claim. Because that's really subjective. For example, during the times we used to write about Obama's claim that you could keep your plan if you like your plan, we first wrote about that in 2009 when he out...he went out somewhere, I don't know, Colorado or one of those states, and held a town hall meeting. And he said you can keep your plan if you want to. So we wrote a story that said you can't keep your plan, and we wrote that over and over and over again. And during the time we got a lot of criticism, not a lot, but some criticism from some of his supporters who were arguing that it's obvious that you can't keep your plan. That's not what he means. You know, thinking that it was not a big deal. And maybe you would only give it one Pinocchio, I don't know what other fact- 121 checking organizations did. So rather than us saying that this is one Pinocchio or four Pinocchios, we let readers decide because there were people who felt that this was egregious, and it really came back and hurt the Democrats in the mid-term elections. So the severity of the violation, we leave that up to readers. We just lay out the facts so they can make up their own mind to how serious it is. Same thing with Hillary Clinton's emails. We would get emails from her supporters that this isn't a big deal. But obviously, Republicans thought it was a huge deal. And it was a disagreement between both of the supporters, partisans. So rather than say any one of her claims that were wrong or misleading, we didn't say that they were a one Pinocchio or whatever. We would just lay it out and say \"she's spinning the facts\" or \"she's omitting information\" or \"she's wrong.\" If it's something that people find serious, that's entirely up to them. Do readers typically disagree on how true a fact-check is? No. Usually it's, like with the UN speech, for example, the criticism there was basically you're picking on him. You're writing about statements that he said that were true, and then you're criticising him. And it's like well, we're not against Donald Trump, just like we weren't against Barack Obama. And I shared that example with Obama. We'll also say it's true what Trump said. More people are working now than ever before. Well that's true. But you want to put some context around it. That's been true since like 1939. So there's been population growth, so there's more people. There's more people than ever. So we'll put that in context, and that's what we do. Just like when Barack Obama said we've created 500,000 manufacturing jobs, which is a popular statement that he used to make. And it's like, well, yeah that's true too. But the country during his time in office lost even more manufacturing jobs than that. We're just providing the context. Most of the back and forth we have with readers are very vague and general, for number one. It'll be \"you're biased.\" And then our response for all criticisms of bias is.... We have students plus scholarships, year-round fellowship programs... and they go through emails, we go through emails. And then criticism that deals with bias, I will directly respond to because I want to know from them why do you think we're biased? Can you point to any examples? Anything that shows that we got it wrong. I certainly take that seriously and look at it in response with a correction if it is wrong, with an update if we omitted information that was important. Or if we go it right, (but) we're just disagreeing, I'll explain it to them in an email. What is your typical response to claims of bias? The typical response is to explain our process and how we go about selecting things to write about, and how we go to the person who made the claim, and seek out information that supports the statement that whoever is making the claim and do our own research on it. And we just kind of lay out this is how we do it. The process that we have in place is designed to take out any bias that any one of us might have. We're not randomly writing about things. We're trying to have some sort of controlled process when we're reviewing these claims. When did FactCheck.org start doing the Share The Facts box? 122 When we started. Bill Adair created that, and we started using it immediately. It's not a rating system, but it's a label. How do you decide what label goes on it? It's a descriptive label, and the words come from the story itself. So if we say in the story that Bill Cassidy is wrong when he says that preexisting conditions are absolutely the same, then we'll say that's false. If it's someone who is one of those true but misleading kind of things like I described with the employment numbers, then that might be something like lacks context or spins the information. The words themselves usually come from the article. What is the organization's stance on using the word lie? We don't use it. Unless we can prove that it was intentional, which pretty much doesn't happen. We don't know what's inside someone's head when they made that claim. It's possible that you could find out through some internal document or emails that emerge later that show that someone was telling a lie, but you rarely know that at the time, so we don't use the word lie. That injects some subjectivity into it too because you really don't know whether someone is purposefully lying. That goes to intent and what the intent was when they said it. Did they believe what they said when they were passing this information along? Were they given some bad information from someone when they passed it along? That wouldn't be intentional either. You just don't know. Like there's a lot of Democrats who say George Bush lied about weapons of mass destruction in Iraq. There's really no evidence of that. It's very complicated, but there's no clear-cut evidence that would show that. It was a mix of information that was being provided to the administration from the intelligence community about it. So it's just a slippery slope because you've got to be careful once you're going to decide to use it. And you really need to have a clear existence of evidence that the person lied. And that rarely happens. Definitely. So are you aware of the public perception that fact-checking is biased against Republicans and biased towards liberals? Yeah, there are surveys that show that Democrats have higher favorability towards fact-checking than Republicans do. Definitely. Do you think because FactCheck.org doesn't use a rating system, do you think that helps combatting that perception of bias? I would suggest you talk to Charlie Sykes. He's the author of that book How The Right Lost Its Mind. And he on several occasions has been very complimentary towards FactCheck.org in feeling that we play it straight. And (he's) highly critical of PolitiFact. He doesn't think too highly of the Washington Post fact-checker as well. So I do think there is a difference of opinion out there about the different fact-checking organizations. I don't know why that is and whether the rating system has any impact. It's certainly a popular thing to have a meter or a sort of rating system. 123 Do you think that rating systems maybe take the nuance out of the reporting that goes into the fact-check? Yeah. I do. If you look at the same articles, we're writing about the same topic. And that happens frequently in fact-checking. So you look at us, you look at the Washington Post, you look at PolitiFact. They're written virtually the same. We have the same primary sources, whether it's the Bureau of Labor Statistics or it's the GAO or whatever. We're going to the same primary sources, and we're coming to pretty much identical conclusions. Then it becomes for the other organizations, they have to decide what they're going to rate it. I think the stories themselves are the same for the most part, especially when we're talking about the same exact statements that are being made. When the statements are slightly different, you might get a different outcome depending on how it was worded. But yeah, I think it does remove some of the nuance from it because people look at the bottom line, and they'll start arguing whether it's two or three. I don't think it's worth it. It's a little unnecessary. Glenn Kessler How do you decide what to fact-check? I'd say about 50 percent of our fact-checks were the result of questions from readers, which comes through either Twitter or email or things like that. And we look for things that are substantive about meaty policy issues. My feeling is that if you're a regular reader of the fact-checker, you would be able to get an understanding of some of the complexities of different policy issues. And we look for things that are in the news. So if there's a gun shooting, we might do a bunch of gun fact-checks. But again it's also is the response from readers who are hearing rhetoric about a particular issue and are asking questions about it. But we don't try to play gotcha. We don't try to check minor little things. It really should be on a substantive policy issue if all things go according to plan. Contrast to PolitiFact, we don't necessarily look for a lot of things that are quote-on-quote true. We do have a Geppetto checkmark. We will write those if it's a fact that is kind of unexpectedly true. It's something that's surprising, and it turns out to be true. The three fact-checkers have slightly different ways in how they handle true statements. FactCheck.org, if they find out the thing is true they stop working on it. We're kind of the middle ground between PolitiFact and FactCheck.org. What are some of the typical steps that you take in your reporting? We generally will first do some research. It's very easy with google to get a sense of where this particular factoid might have come from. So that way we get a feel for is this total B.S.? Or is 124 this based on a reputable source? That sort of thing. Did it come out of an article on Breitbart or did it come out of something from the Census Bureau? And again, we want to make sure it's about a substantive policy issue. So once we have a general sense of where it came from, or if we can't figure it out at all, we will then approach the staff or the person who said this. We'll say something along the lines of, \"We saw such and such said this. It looks like this is based on this and that. Here are some issues we have with it.\" Or, \"Gee, we saw this. We can't figure out where it came from. What's the source?\" Can you give an example of a time when you had trouble choosing a rating for a fact-check? Generally it's not that difficult. I mean we have one Pinocchio, which is kind of like mostly true, two Pinocchios, which is kind of like half-true, three, which is mostly false. The hardest point is trying to weigh between a two and a three. It's kind of a fuzzy line there. We don't do half Pinocchios. For instance, just yesterday, there were two statements having to do with whether or not DACA led to the influx of unaccompanied kids trying to cross the southern border. And I looked at two statements there. One was by the president. One was by Jeff Sessions. And both were kind of on the cusp between two or three. Sessions was more of a two because he included some caveats. The way he framed it was, \"among other things, this led to this.\" Trump was a little more aggressive. He leaned towards a three. So I discussed that. We have a policy where we try to explain what led us between a two and a three. Because it is such a fuzzy line. These ratings, frankly, are subjective. So my three might be someone else's two. Ultimately I made it a three just because the president's statement trumped Session's statement. Has anyone ever admitted they lied after you published a fact-check on something they said? I don't use the word lie. In fact that word is forbidden to be used at the Washington Post. But I once had a very senior member of Congress call me up and say, \"What do I have to do to avoid getting Pinocchios?\" I had written something like, \"The fact he uttered looked like it had been written out on a cocktail napkin without much forethought.\" And he said, \"You know you wrote that line about the cocktail napkin. Actually it just occurred to me when I was standing there waiting my turn to speak.\" So he said, \"I learned my lesson. I'm never going to say something like this without checking with my staff.\" And then I've had senators call me up and say, \"Thank you for pointing this out. I'm never going to use this fact again. I didn't realize how sketchy it was.\" That sort of thing. In most cases, the reason we don't use the word lie is because we can't get in someone's head. We don't really know what they're thinking when they're saying this. With Trump, you know, 125 he definitely pushes the envelope because he repeatedly says these things even after they've been fact-checked. But at the same time, I think Trump is very situational, and he firmly believes in what he's saying at that moment even though it may be completely contradictory to something he said the day before or five minutes before. So in his mind, it may not be a lie. I don't know. What are some typical public reactions you get from your ratings? Not from politicians, but from readers. Most readers vehemently disagree with the rating. We have a tool that allows readers to offer their own opinion on what the rating should be, which we implemented about a year and a half ago just because readers were demanding it. They wanted to have a say. If you look at it, it tends to be extremely partisan, where no matter who it is, particularly if it's someone like Trump, a huge percentage of the people will say, \"It's four Pinocchios!\" Or, \"It's Geppetto checkmark!\" Particularly when we sit there and stare at our navel and say, \"Oh, I think this is a two.\" We give very reasoned answers as to why it's a two. Virtually no one ever agrees with a two. It's either four Pinocchios or Geppetto checkmark. So would you say that having that sort of reader input isn't totally useful? Maybe. I don't know. People take it very seriously. You wouldn't believe how many emails I get from people who apologize profusely for having accidently hit the wrong rating and could we fix it so it didn't mess up the score. It happens at least once a day. I'm sure you get emails from readers who disagree with your rating. How do you respond to that? It depends on the tenor of the email. I mean we get some emails that are (inaudible) and we kind of ignore those. The female colleague that I work with gets particularly sexist or racist, you know, so those we ignore. But we have a policy that we will revisit the Pinocchio rating if someone comes forward with evidence that makes us think that we had leaned too much in one direction. And we have changed Pinocchio ratings in response to evidence that readers have provided. My feeling is this: Fact-checks are never finished and can always be updated if new information comes. A famous case is we had once given Hillary Clinton two Pinocchios for something she had said about her emails. And then, six or seven months later when the FBI report had come out, we realized that we now had enough evidence to give her four Pinocchios. So we changed the rating. Are you aware of the public perception that fact-checking is unfair to Republicans and biased towards liberals? Yes, I've participated in public debates and radio interviews with people that make that case. And how do you try to combat that perception? 126 I've always told people, \"Read the fact-checker for a month and then come back.\" And after I've said that to readers, I've gotten emails back and they said, \"You know, you're so right. I realize you're equal opportunity to politicians and parties. So I've taken back what I had originally said to you.\" Frankly, the era of Trump and Republican control in Congress has really put us in a bind. And I struggle with it because, like I said we listen to a lot of what readers want to have fact-checked. And Trump is so dominating the news, and the Republicans control Congress, that we're just not fact-checking democrats enough. And in part it's because the Democrats aren't saying anything. We write about people who are important and who are in the news, and that happens to be Republicans. The Republicans are doing this, they're saying they're going to do this about health care, or they're going to do that. Occasionally, there's an actual debate, I would say about, say the health care bill. And when the Democrats said tens of thousands of people would die if the Republican planned is passed \u2014 hooray! We can do a fact-check. We can say no, that's wrong, that's four Pinocchios, blah blah blah. But on a day-to-day basis, it's just the Trump show. And that is a serious, serious problem. And I've not been able to figure out a way aropund it. One thing we've done so that we don't just fact-check constantly Trump, is we have a database of Trump's claims, all in one place. So that way, rather than do a fact-check, we just put it in the database. But that still leaves us with lots of Trump claims. Or lots of Paul Ryan claims or Mitch McConnell claims. We've been able to ding Schumer. We've been able to ding Pelosi. Bernie Sanders. But not on the kind of basis... You know, we had a primary race going on. It was bad enough that there were two Democrats, but it was somewhat more balanced. The best possible situation for the fact-checker is when you have a divided government. When you had a Democratic president and a Republican Congress, it was equal. There were days, weeks, we'd go like 14-straight fact-checks of Democrats. And then 14-straight fact-checks of Republicans. So I don't know what to do. We really just like to focus on what's in the news and who's saying things that are interesting and worthy of fact-checking. But this year is really bad. In trying to make things a little bit more equal for the time being are you trying to pay closer attention to what Democrats are saying? Well we look for it. I mean we get virtually no reader questions saying, \"I heard Nancy Pelosi say this. This is wrong.\" Since we're just not paying attention to them. But we do look at the transcripts. But like I said, it has to be something compelling. It has to be an issue in news. I'm hoping now that Congress is back, we might have more health care, we might have debt ceiling, things like that. That we'll get some material. It's a big problem. 127 Before we go, I'd just like to talk a little more about rating systems. What's the argument for using a rating system? Because it's a great marketing gimick. (laughs) I mean, it's a psuedo-scientific, subjective thing. It's an easy, simple way for readers to get a sense of the bottom line of the fact-check. I do know there are people who all they do is just go straight to the Pinocchio, and they don't read the fact-check. That's a problem. We spend a lot of time on the fact-check. I don't claim that there's anything particularly magical about it, except that it's any easy way for people to talk about it. This month is the 10th anniversary of the fact-checker. We've been collecting video tape of all the politicians that would, at the end of the day, say something like, \"The Washington Post gave that four Pinocchios.\" It's a way for people to talk about the fact-check. It's nothing more. I'm a big fan of the rating system. I think it's a good way to keep track. I have to say, I've done this for almost seven years. It allows me to keep in mind how I rated things before, and to be consistent. I think that's a very helpful tool. I like to think I am conssistent, but you never know. I had this strange experience where I fact-checked something that Hillary Clinton said. It had to do with, I don't remember, something about the debt or the deficit. And I settled on three Pinocchios for it. And a reader wrote me a note and said, \"Do you realize you fact-checked this very same talking point four years ago?\" Which I had completely forgotten about. They sent me the link. I'm amazed the reader remembered it and I didn't. With great trepidation, I clicked on the link to see what was my rating, and it was three Pinocchios. And I had exactly the same analysis as to why it was three Pinocchios. So that was a relief. But more times I'll think this thing that this Democrat is saying is very similar to this thing that this Republican said, so I'll look and see what did I give the Republican. Oh, I gave the Republican two Pinocchios. Well then we'll give the Democrat two Pinocchios too. So at least on a personal level, that's the useful thing about the rating scale. If you could change anything about the rating scale, what would you change? I don't know. I'm pretty happy with it. It seems to work. People are always saying there should be a fifth Pinocchio, you know, like a five-star general. I see no need to do that. It's like it becomes grade inflation. The Pinocchios are very powerful. I tend to think it's more powerful than the Truth-O-Meter just because of the image. Politicians on Capitol Hill live in fear of those Pinocchios. There was a Senate leader giving a speech or something, and he had his staff methodically look through every fact-check of that particular issue to make sure he didn't say anything incorrect. That's great. So it sounds like it's had some sort of concrete effect in that way. Yeah, I mean, we don't write the fact-checks to change politicians' behavior. It's to inform readers. But I do get feedback. 128 You said something about the image of the Pinocchio versus the Truth-O-Meter. What do you mean? The Truth-O-Meter's great. Don't get me wrong. But it's more like a..it doesn't quite have the same image as a Pinocchio. And, frankly, I also think it's because it's the Washington Post. It's the Washington Post, which is the hometown paper in Washington, D.C. 'The Washington Post awarded you Pinocchios' \u2014 that sounds bad, as opposed to 'you got a mostly false on the Truth-O-Meter.' Mike Jenner So I just wanted to start out by talking about the reporting process that you guys go through for fact checking. It's going to feel weird having me ask this because like I went through the class, but just for the sake of getting it on the record, I would just like to ask you: How do you teach your students to go about the reporting process for fact checking? Well so the I think the most fundamental thing is choosing the right statement to fact-check because it has to be a verifiable statement. And it's funny how so many politicians these days don't speak in sentences that involve facts. They kind of live in a fact-free world. We can't check an opinion. Opinions are opinions, and that's not really our province. The other thing is we can't check predictions, and that's even if you go back later and you can go back and I guess report on whether somebody's prediction was smart or accurate or whatever. But that's really not the same as checking the facts. So they have to be verifiable and they have to be...there has to be something there that's tangible and checkable. So I say that's the number one thing we do. And then after we've identified which statement we're going to check is, we go back to the speaker and the person who made the statement and ask them for the data or the evidence that supports their statements. And that's really I think different from a lot of other ways that other people might do that kind of reporting, in that they look for evidence that kind of supports her refutes the claim before going back to the source. That's just the first thing we do. And it generally speeds the process and kind of gets you to knowing quickly whether or not the data or the evidence is objective or from a credible source or whether it's from somebody who's got a point of view or a partisan bent. You know exactly where the individual is coming from. And in some cases we found that while they don't have any evidence they either just made it up or they are speaking extemporaneously, as the governor's press secretary said this one time. (former) Governor Nixon. Going back to the source, I think that's really important from a kind of a transparency standpoint too. So I just think that that all fits together with the idea that the PolitiFact method is all about transparency, and that's why we publish all our sources and link to them. 129 So I guess the the next step...I mean it should be over right? If you checked the information that the source gives you, check that out and find out that it's true or false, then you know you ought to be able to make a ruling. But I mean that be kind of that wouldn't be it would be very interesting. There's a lot more to it than that. And usually things are a lot more nuanced. And so we need to put things in context and kind of look at the statement and kind of see how it lines up with all the other factors that surround the issue. And so that means talking to experts in the field, maybe they're economists, maybe they're political scientists, maybe they're sociologists. And looking at other data sets, too, that might kind of line up with or kind of even color or change or oppose the data set that the politician used as the basis for their claim. Right. OK. Great. Thank you. I want to move a little bit now to the ratings. Can you can you give an example of a time when you and your students had trouble choosing a rating for a fact check? Yeah, I'm trying to think of a specific...One of the things that I learned pretty quickly is you really need to... the cleaner the statement, and I guess the more limited the statement is, the better because if you're trying to check kind of a double barrel claim you can end up with a claim that's kind of half true or maybe half of it's true, half of it's false. And that really poses problems for how to rate it. So you really need to choose a claim that isn't kind of double barreled, so to speak. And so I mean I can remember times when we've had claims that covered so much territory that, I mean it wasn't a double barrel, but it covered so much ground that it was hard to know if some of it was true and some of it was maybe not so clear. It was hard to figure out how to cut a way that all, and how to how to rank it. Here's the other thing that...PolitiFact's rating scale goes from totally true, and the parts are, let's see, mostly true half true mostly false false and then pants on fire. So I mean there are gradations that you can weigh them on. I find it really hard when somebody is literally true but there are some other nuances that come into play. I think some of the PolitiFact editors have been doing this long enough that they've seen enough of these that it's easier for them to make a call than most. And you want to be consistent. I mean, you want to be kind of like, you know, strike zone for a pitcher. You know, the Major League umpires, they work really hard to be consistent so that you know depending on the umpire you have, you know the strike zone doesn't change in size by 25 percent based on who stands behind the plate. And so it's important to be consistent in how we assign these ratings. So I think the folks who do this you know day in day out. I've done enough of them, and they do it frequently enough that they're really really good at that. Right. So like can you think of an example when you didn't assign a rating to a fact-check? Yeah absolutely. Now I'm trying to remember exactly which one that is that we did that. There are times when... I'm trying to remember. 130 There are times where it's really hard to find the rating for a fact-check. It's where there's a lot more nuance. And these are where somebody is literally true, but there's a lot of factors that are going into it and maybe the context of what they're saying is not true. There are times when we really can't reconcile the claim with the rating because it may be that their statement is is true in a sense but there's so much other nuance or contradictory factors that it's just really hard to try and call it. Oftentimes those stories are really interesting and have a lot of background, and they're good stories. It would be wrong to not share what we've discovered because sometimes it's pretty interesting and pretty telling. So on a few occasions, or maybe less. One or two times in my experience. We've done the reporting and come up with a story and we just couldn't agree on a rating that we thought was fair or accurate or consistent with other situations, and so we just said we're not going to give it a rating. But here's the the context and the background. I think that has value for the reader because they can kind of get a lot of understanding from the reporting. Right. Right. What kind of public reactions do you get to your ratings? Well people who are hardcore partisans are going to kind of.... it sort of falls under the under the same kind of... you know, in today's political environment and the journalistic environment, we see a lot of people holding close to their political views and their partisan views really color their feelings about the content they read. So sometimes we'll see people who have pretty strong partisan beliefs kind of reject a ruling that we've made or some of the reporting we've done because it contradicts with what they want to believe. People who I think are the strongest partisans have a harder time with the fact-checking process and with being willing to be open to the idea that their candidate or their representative didn't say something that was 100 percent truthful. Right. OK. So how do you respond to that sort of partisan reader? I think that if you look at the large picture of what fact-checks we've done and the fact-checks that PolitiFact nationally he has done. I think if you look at the overall, you see that things tend to spread themselves out in a bell curve just like any large population does. And there's sort of a standard distribution of of who we checked and the truth or falsity of it. And I think that the numbers would show that we are not out to get Republicans or Democrats who are not favoring one liberal or conservative viewpoint or one issue or another. And one thing we do that I think makes us more credible is we publish our sources and link to them and people can do their own homework and look and see for themselves how something was presented. And so you know the other thing I would say is that I have seen PolitiFact actually reconsider rulings even years after the after the stories were published, not because the circumstances changed, but because new evidence was brought to light that indicated ...maybe if we'd known this at the time that this evidence existed. Now we think that the rating is different than when we first published the story, and I've seen PolitiFact be open to that. I think that there's an even spread of heroes and villains here. We're not going after one side or another. Everybody's getting treated with the same kind of fair hand. And then the fact that we're 131 open to criticism, when we listen to the readers who say hey you got this wrong or what about this. I think that willingness to listen is important too. Does it worry you, the idea that people write off information that contradicts their beliefs? Oh yeah. It worries me on a kind of... a more than like at the micro level. I mean it worries me about the future of journalism but also the future of democracy. I've lived through the last you know 30 years of politics and media and how it changed how people want to consume news that sort of fits their bubble, and I think it's terribly worrying. But I think that is not just a fact-check issue that's a world issue. So PolitiFact isn't getting hate for a special reason, it's all reporters and all beats. Yes that's totally. That's something that we're seeing across the board and at the highest levels of government and most local levels too. I think there's a feeling among a lot of voters and a lot of politicians that they're going to band together with their birds of a feather and there's a willingness to ignore some things or some facts if they're inconvenient. And so I think that's very troubling. It's just that we need to be open to the fact that things aren't always going to go our way. And we have to be willing to accept that. And take an objective look at what's true and what's not true and then make a good judgment. And I just I worry about how that plays out for democracy and for the future. Right. Definitely. So I just have a few more questions left before we go. Has anyone ever admitted that they were wrong after you published a fact-check? You mean a source? Somebody you've checked. Has somebody you've ever checked said \"Oh I was I was wrong,\" or \"oh I made a mistake or something like that?\" Yeah. I'm trying to remember. There's a one fact check that...Peter Kinder on on the swastika on the bathroom wall. I remember that one. I mean he kind of admitted he was wrong. See here's the story. We wrote a story, we wrote, the headline said, \"Missouri politician wrongly claims zero evidence a swastika on Missouri campus\" and we gave him a pants on fire rating for that. And he later backed off a little. He stopped saying there was no evidence after everybody finally set the evidence right. Right. So it did have some sort of effect. Do you consider yourself to be more in favor of using a rating system or more not in favor of using a rating system? 132 I am in favor of a rating system, and I like PolitiFact's better than say The Washington Post. In the Post's rating system they assign Pinocchio's to false. And then if they're true they give them Geppettos, which are kind of weird. I don't think people get that. I mean people may remember who Pinocchio is, but I don't think they understand Geppetto. And I don't know why they would let Geppetto be a proxy for truth. I don't know what.... But I think that there are other sites like the one Annenburg does. FactCheck.org Yeah, FactCheck.org. I don't believe they...I think they have kind of a narrative ruling. They don't really have a rating system. But I kind of like the rating system. I know it opens you up for criticism. And I think PolitiFact has been criticized for some of its features and some of the ratings. I mean you do have to have to make a call. You can't give it 5.6; you've got to say it's either half true or mostly true. But I think it's good to call a spade a spade. And it's a good thing to be open for criticism. Could you could you elaborate a little bit more? Why is that a good thing? Well I just think that we ought to be open about our methods and open about what we report. And I think it's not bad for people to challenge us. I would hope that they would come away and say, \"OK we challenged them. They had a good answer.\" We have to invite scrutiny. We're scrutinizing what others say and what they do. We need to be able to provide the same accountability that we're asking of public officials. So I don't think it's a bad thing. I think it's a good thing. Alexandre Pouchard Thank you so much for taking the time to talk with me today. And I just kind of wanted to start by getting a sense of how you guys decide what to what claims to fact check. We look a lot for interviews in radio, TV. It's very instinctive, I can say, because we don't only do political fact-checking. Fact checking is one of the ways cover different stories. We particularly focus on numbers, statistics that we can we can actually check. Some things you read, and it rings a bell and just makes you wonder. Is it true? So questioning, always questioning here when we listen or read the news. Sometimes it's true and we don't cover it. Sometimes when it's false, we cover it. We may write an article if it's true and it's really surprising. It's really about instinct first. So in the U.S., because it's a two party system we we definitely try to get you know we try to have a balance of like fact checks from Republicans and also fact checks from 133 Democrats. And I was wondering do you guys try to balance it out with the political parties in France. Yes we try. We try every two or three articles about right wing politicians. We'll try to find a fact-check with a left-wing one. We try, but if it's something we can fact-check. Sometimes they don't really care if it's true or not. They just say numbers, figures, even if it's not true. Usually the left parties, they take precautions. But when they when they were in power, when Hollande was in power, they paid a lot to defend their policy. So at that time, we fact-checked a lot - the left party. So it really depends on who is in power. But I think at the end it's kind of balanced because... I think it was the second or third anniversary of Les Decodeurs, we made data of fact-checking , and just to see did we fact-check more left or right parties, and at the end, it was almost a perfect equality. It was 50-50. And it was almost the same articles saying it's false with left parties and false with right parties. And in France is there. is there a public perception that fact-checkers are biased towards one political party or another. Maybe not (just) fact-checkers. More journalists, for left-parties. A lot of readers think this, but, in our fact-checks and our articles, we go to the statistics. It doesn't matter if it's said from left parties or right parties. When we fact-check left-wing politicians, we have many readers say \"Oh, you're right-wing, or you're liberal,\" economically, I mean. \"You're conservative. And when we fact-check right-wing politicians, many readers tell us that we're left. We're too progressive. I think that's a sign of, we are doing a good job. So when readers contact you and say you know you're being biased or you know they bring up their criticisms, how do you respond to that? If it's criticism about a fact, we mention the sources. We always mention the sources in our articles. So we respond on the topics we are writing about. If it's just an accusation of you are right-wing, you are left-wing journalists. Sometimes we respond by sending articles where we are criticizing politicians of other parties to show that we are fact-checking everyone. But sometimes the readers, the readers they say, \"Oh ok, I didn't see this one.\" Sometimes they just say well you just wrote one or two articles about the other side, but I do know that you are politically biased. They don't want to see that we are actually trying to fact-check everyone and to be balanced in our coverage. So why do you why do you think that is? Why do you think it is that people still are reluctant to see you as independent of political parties? It's a difficult question. Probably I think it's about the most militant, the most activist readers, the ones who are really reading because...they are not the maturity of the reader. So clearly it's a 134 minority, and about this minority, I think they can be convinced. They just see or read what they want to see or read. You are really in your activist ways, so you think you see the world as your activism. So if the media writes articles against your own ideas.. I think they just focus on the criticism against their own ideas. They don't want to see it any other way. So they classify the media in their own categories. Like I said, for many readers Le Monde is more right-wing newspaper or is center-right newspaper, and for many others, especially for right-wing activists, Le Monde is a left-wing newspaper. OK so I'm going to switch the conversation just a little bit to talking about how you, your presentation of your fact checks. So I understand that Le Monde used to use rating systems. And you guys stopped using those, like mostly false or false or whatever. And so it used to be kind of similar to PolitFact in the ratings. And then you guys switched, and I'm curious to know why. Why did you guys decide to stop using the ratings? Yes, at first in the beginning of Les Decodeurs, it was a fact-checking blog at first in 2009. There were few labels. There was true, false, rather true or rather false. And it was kind of harsh, and sometimes difficult to cover. We still mention sometimes true, false, but now more and more, we are using other labels like it's more complicated. Or we use a lot, it's misleading. We use it a lot because more and more... I think politicians have adapted their speeches. More and more they use statistics because sometimes statistics are true, but they are misleading the reader because they don't show the broader picture. Like with criminality, politicians will say robberies have increased per month. And if we look at the statistics and we see that robberies is the only one, the only statistic that is increasing and all the other ones are decreasing, we'll show the broad picture and say, \"yeah, robberies are increasing, this is true. But all of the other data, statistics about criminality are decreasing.\" So it's not false, but it's misleading. It's used in a way to ...it's kind of dishonest. We use different labels more and more because I think that politicians, except some of them, a minority, but politicians have adapted their public speeches and interviews because they do know that journalists are reading and listening. We'll fact-check them, so they're more careful. Sometimes we'll publish an article with it's false, but it's kind of rare now. Often it's more complicated or misleading. So that's interesting. You think that maybe because of the rise of fact-checking, there has been a change in political speech, in the way that politicians present facts. Am I correct in saying that? Yeah, yeah I'd say definitely. In the U.S.. We we are having a debate about using the word lie, which I don't know what the French translation for that would be. Right. 135 And I'm curious to know if there is a similar conversation happening in France about using that word. Yeah, sometimes. We do hesitate to use it because a lie, it shows an intention. It implies that the politician is voluntarily lying. So we have to be sure that the politician is actually lying. Sometimes. In most of the cases, we try to use different words like false. It's not a big debate. We've not been discussing it in seminaries. In our daily work, we have among the fact-checking team, we discuss it, we say, can we use the lie word? because we have to be precautious. What are what are instances in which you would use that word? It could be that case if we've written a lot if it's wrong, it's not true. But we can't be sure that the politician has read our article. It depends on whether it was a big debate. It would be like, he knows it's not true because he's an expert of the topic. Or he knows it's not true in private circles. Or he's mentioned something else in a seminar or a conference. In that case we can use lie, but based on past articles... I don't think we would use it because we can be sure he's actually read the article. Until we do know he's lying, we will not use it. Right. Definitely. In my last question, at some places in the U.S., we use ratings like the Truth-O-Meter for PolitiFact or Pinocchios for the Washington Post. People use the ratings to kind of engage readers to get them interested in the articles. And so I'm kind of wondering what tools do you guys use to engage readers? It would be like on the social networks to publish a picture with a quote and the label like it's false or it's more complicated to encourage the readers to read the articles. We use color, the red, green, orange and blue. Four colors. At Le Monde, Les Decodeurs is the only edition of Le Monde using color, so it's something attractive to encourage readers. But we don't grade the politicians. Yes, it would be very attractive, but since we don't fact-check everyone everyday, we can't be complete. We can't fact-check every sentence. So we are to be very serious about the statistics. If we start to make data of fact-checks without checking everything, we can't assume we are complete. It would be attractive to have a grading of politicians, but it's something we would have to fact-check everything. Linda Qiu I'd like to start by getting a little bit of background on you. How did you get started on fact-checking with the New York Times? Right after the election. They didn't have a fact-checker at the time. So I was approached by the senior editor. So why after the election? What spurred that? 136 I honestly have no idea. When they contacted me I just thought well, if anything I get a free coffee out of the New York Times. But I think they realized that they had dropped the ball for such a long time. So they wanted to remedy that. So how do you manage being the only fact-checker for The Times? For me it's just like there's so many opportunities, like I'm not fighting for stories with anyone else. And I have a dedicated editor, so it's just sort of like, OK what does the editing desk feel like is appropriate to fact-check? And what I think is interesting. So I'll pitch longer term things that will take me a couple of days or sometimes a couple of weeks to research. And I'll do the daily stuff. Could you talk a little bit more about how you decide what to fact-check? Yeah. Part of it is how do you supplement the coverage from the bureau. So I work out of the Washington bureau. So like for example, last week for the Iran deal, Trump speech focused on the Iran deal. So that was like a big foreign policy moment. And I was asked to fact-check that in order to supplement the coverage. So the story was like, this is what he said. This is what it means for U.S.- Iran relationship. And this is what's going to happen going forward. Going. And our diplomatic correspondent, who knows more about the Iran deal than anyone I've ever talked to. He said Trump also said a couple things in there that are just not accurate. I'd like to include this in my story, but it just doesn't flow with it, so a side bar to that would be awesome. So a lot of times it's complementing what the main stories are going to be about. Are you mostly fact-checking the president? It turns out to be mostly the president because he is the president so he's just the most important target. But I have done fact-checks of other Republican leaders and Democratic leaders as well. But yeah I mean for now the focus has been on President Trump. So I guess you've been with the New York Times for about 8 months now. What are some of the main differences that you've seen so far between the New York Times fact-checking and PolitiFact? So PolitiFact, I mean, they've been around for such a long time. So they sort of have like a really established method. And there is a lot more top down at PolitiFact. I don't know what your experience has been but like. You know for me it was a lot of, maybe like 70 percent assignment, 30 percent stories. And because there were so many other fact checkers, we each had carved out our own beats. So I don't know if you ever worked with Lauren before. She left to go to law school, but she did all of the Clinton emails and national security. And I did all of the climate change stuff and moved on to all the economic stuff. So it sort of like keeps you focused on what claims you could be fact-checking we back. And at the Times, as the only person, it's sort of like, OK, today I'm going to be doing this and tomorrow I'll be doing that. It's all over the place. 137 So you're having to learn a lot of different subjects very fast. How do you manage that? I mean the blessing of being at one of the best newspapers in the world is that I can go downstairs and talk to the best reporters in the country. They'll give me context and guide the coverage. At PolitiFact there wasn't that much internal expertise. Like you would have to call on outside experts. I rely heavily on my colleagues to at least give me a push to think. This is what we think is missing. Just because we've been covering it for such a long time, so they can point me in the right direction. That helps me a lot, like last week when I was doing the Iran deal thing, I was talking with David Sanger the entire time. He's been writing about the Iran deal for years. Right. So you get to benefit off the New York Times' knowledge. And I think that's what it's like for the fact-checker at the Washington Post, too. So I understand the New York Times doesn't really use a rating system. Why is that? In the beginning when I started we did try to do a rating system and it just got kind of cumbersome to lay out. It was really like a lay out decision more than anything, I would say. We would do like, you know, somebody has a claim and the claim is, sort of like a quote format. And then we would say like false or misleading. And we would have a set amount of words that we were using to try to standardize it. And it was just really difficult to keep to that format all the time. And after some discussions with editors, we felt like it was more important just to give context of the claim and to explain it more than to like slap a rating on it. And that's not set in stone. We might revert back to what it was before. The format we have right now is like when we're doing like one of those listees where there's three or four claims in an article. We do subheads, and that seems to get to the point of what we're rating. It's like X said, and it was falsely stated. Or that requires more context. So that's like the equivalent of false and mostly false. That sort of gets the point across but it's also a more scannable way. So you don't have to read the entire quote and then see the rating. It's a different presentation. I wouldn't say it's better or worse in any way. It fits better for the print product, which the New York Times cares a lot more about than PolitiFact. So I think one of the benefits of the rating systems is kind of marketing. How does the New York Times then market the fact-checks in a way that will get people to click on it? Yeah I mean, so this is it's kind of interesting to see the analytics of PolitiFact, 70 percent of traffic came in through social media. For the New York Times, a lot of it is driven by readers who are already subscribing. So that's just sort of like, the ratings don't matter as much because there's already a built in audience. And for me. Sometimes what drives it is just having really good SEO. A good fact-check for me, 50 percent of that is coming through search. 138 When you were working for PolitiFact, can you give an example of a time when you had trouble choosing a rating? There have been a couple of times where I think like we started out thinking that a story was going to be rated, and it ended up just being a story. I would say that most of the time, what I pitched as a rating didn't venture far from what the editors say. But the one divergence I can think of is, during the election when Trump was in this feud with Megan Kelly. And he said something like I never called for Megan Kelly to be removed from the debate moderators. I had never found an instance of him literally saying Megan Kelly can't moderate this debate. So I pitched I think I pitched that as a half true and then the editors were like, OK, but you're taking that too literally. Like if you look at the other statements that you've laid out he's clearly calling for it in other terms. So they bumped it to a false. Are you usually convinced by your editors' arguments? 95 percent of the time. Sometimes I feel overruled, and I get a little upset about it. What kind of public reactions do you get to your fact-checks at the New York Times? A lot of it...I guess it depends from fact-check to fact-check. Sometimes people are really upset because you know, like during the election. During the whole birther thing, the New York Times said lie in a headline. So a lot of the feedback I get is like why are you calling it a falsehood instead of a lie? And then I have to explain, I don't know the intent of the speaker, so I can't call it a lie. That's one reaction. And then some of it, I would say whenever I fact-check Democrats, I get a lot of response from subscribers who think that I'm too harsh on Democrats. So that's been sort of interesting and I got that at PolitiFact as well. There's a sense that, you know, you're supposed to be on their side. And I'm like no, no, no, I'm not on anyone's side. I'm not the opposition to anyone. I'm just trying to lay out a clear picture. Have you noticed any difference between the reactions that you got at PolitiFact versus the reactions you get at the New York Times? Not particularly. I think part of it was also, when I was at PolitiFact, I was in the heat of the 2016 election. So things were just a lot more geared up to a different level. And PolitiFact has like, people have certain beliefs who read PolitiFact who I think thought like molded into my coverage as well. At the Times it's been, people seem, almost more receptive to it because, especially in the beginning when it was in a new form, people were like oh, wow, the New York Times is fact-checking now. But as time has gone on, there's definitely been the same amount of criticisms when i'll say like Trump is misleadingly said, and I'll get a reader who says, why don't you call it a lie? 139 The New York Times did use the word lie that one time. Is that a word that the Times would use again? I wasn't at the Times when that happened, but my understanding is that was in reference to the birther theory that Trump had been promoting for years when it was clearly debunked. He'd been asked about. He said I'll give five million dollars to charity of President Obama's choice if he gives me his birth certificate. And he kept going with it. The editors at that time decided there was a lot more intentionally smearing of truth that was evidenced by how long it had been going for instead of what we think of as typical political spin. I think that decision made sense. It's not one that I would have personally made just because I don't think... if you don't know the intent of the person, you can't judge whether is was a lie or not. Do you think it would be impossible to learn if something was a lie? At what point would you say, OK we can call this a lie? Honestly like if there was hard, hypothetically, right? If Wikileaks released a trove of internal emails from the White House and people were saying like, we know this is false, but we're going to promote this theory anyway, and let's keep saying this over and over again. They've acknowledged that it's false, and they keep saying it. That's when you can call it a lie. But I think, absent that really high burden of proof, people shouldn't call anything a lie. Has anyone ever admitted they were wrong after you published a fact-check? A couple of times when I was giving Hillary Clinton false of Pants on Fire. ratings, the reaction I got from the spokesman was she misspoke. Which was not like an admission of blatantly lying, but she went a little over the board and we acknowledge that. But in recent memory that hasn't happened while I've worked at the Times. I want to take one step back to public reactions. How do you respond when people say you're biased? I mean I pick and choose my battles for sure, like sometimes when I get an email in all caps calling me all sorts of names, I'm not going to engage with that. But sometimes I'll get a really thoughtful, respectful response that's like, \"I disagree with this, this and this.\" For example last week I wrote about Trump saying that Bob Corker gave us the Iran deal. So I sort of like laid out why that wasn't true, and I got a response saying....I don't know if you read that National Review article... Yeah I read that yesterday. So he was laying out like, it was a very long email. He was not very respectful. More respectful than some of the stuff that I usually get. And I responded saying, thank you so much for your input. I read the National Review article you sent me, but I'm still failing to see how it addresses this, this and this. And he was like OK, well thanks for listening. I still disagree, but thanks. 140 You tried. After you've responded to emails from readers, have you ever gotten a good response back? Once or twice. There's a guy who I think maybe lives in Florida. But he still reads my work. He writes me weekly. A couple of times I'll disagree with him, and he'll write back and be like OK I see your point. A very polite exchange. So that's happened like once or twice, but it's very rare. Do you ever get attacks from readers that are gender-based or racist? Totally. Especially during the campaign. A lot of people with nasty, racially geared stuff. Especially if I'm writing about China, people assume things about your background. I have an Asian last name and so I get a lot of people like, you're from communist China. How could you say that Bernie is right? Communism is bad. Or they're like, you're an Asian woman and you're supporting all these white men. You must be sexually attracted to them. Stuff like that. There was this one dude who... It usually ratchets up once a different website like Breitbart writes about the fact-check. So I wrote something about Clinton cash, and I got a lot of feedback. A lot of those were very rude memes, like pictures and my face superimposed in very compromising positions. That was not fun. Wow. I'm sorry. You're just doing your job. Changing course a bit here, are you aware of the public perception that fact-checking is unfair to Republicans and biased towards liberals? Yeah I've heard that for sure. How would you respond to that if somebody said, look at all this evidence, you're biased? That's one of the blessings of not having ratings. They can't compare two ratings that you know like, on paper it might look the same, but laid out in different forms. So then I can say that if you read the fact-check, don't...like an accusation like that doesn't get you anywhere. But if you can point out somewhere in my coverage, we can talk about the facts. And then I would also say that this perception that the New York Times is liberal comes from the fact that we have a liberal opinions page. That doesn't mean that the coverage is slanted in that way. I think a lot of people misunderstand that. The New York Times opinion page is liberal; the Wall Street Journal's is conservative. That doesn't mean that the coverage is slanted in any way. People don't understand that. I know there's an idea out there that a person's natural, biological reaction is to write off the source of information that contradicts their beliefs. Does that worry you? Certainly. I often wonder who are these fact-checks for? Because if people want to read something just to bolster their political perceptions. Or does it actually play some sort of service? No one has figured out what the best solution for that sort of.... you know...how does fact-checking sway public opinion one way or another? Maybe it doesn't. But I think the purpose of it 141 isn't necessarily to change hearts and minds, but it's say these are the facts. And you can make up your own mind about whether this sways your vote in anyway or not, but as long as we have this clear lay out of the facts, I think that's the most important thing. And I think something that we all need to be more aware of is tone. In fact-checking it's really easy to be snarky. It's really easy to be condescending and sort of liven up your prose, but fact-checking is supposed to be dry. You can't have your fact-checks colored by any sort of tone that might give people the wrong impression. I try to be very neutral in the way that I write. So when you're self editing, you're being careful to say, am I coming off as biased? Yeah. Sometimes after I read a fact-check, I'm like wow, that was really boring. And that's good. What about in terms of sources? How do you factor in the public perception of bias? Yeah. This is something that I learned at PolitiFact. You consult a variety of experts, and I very heavily rely on data. So if I'm writing something about jobs, I'm not going to consult a liberal economist to tell me, or a conservative economist. I'll just look at the BLS data and say, well, these are the numbers. You can't slant numbers. When I do have to rely on exerts, I try to consult and ideological spectrum. So if I'm writing about health care. I'll talk to someone at the American Enterprise Institute, then I'l talk to someone at Urban, and if they same thing, then I know that fact's, you know. If they can all agree on something, you know sort of like doing a mini survey. If I talked to six economists, and five of them say one thing and one says another thing, then they I can say most people believe...and then present the other side. And in that situation, does it make it harder to have a rating? I think the benefits of having a rating system is that it's much more digestible. It is also a really good way of marketing the fact-checks. But I do think that without the ratings, you can lay out an argument maybe more persuasive because it doesn't reduce it to one word. Would you say that ratings kind of take the nuance out of the reporting? That's the beauty of PolitiFact. If a reader doesn't want anything but the rating, they get that. But if you want the nuance, you can get that too. But at the end of the day, this is a service, and it's about what the readers want out of a fact-check. If you can have it both ways, why not? 142 Fact-Checking Policies Le Monde 1. We give context and facts Our articles are built around the most objective facts possible: statistics, figures, laws, dates, facts, are our primary material. We provide facts, we do not do speculative journalism, we do not give our opinion. 2. We verify information and public statements Decoders are focused on factual verification . Assertions - whether from politicians or other public actors - are verified and contextualised. 3. Nothing is too complex to be explained simply All phenomena, all current issues, are explainable to the greatest number. We make sure that the items in the Decoders are always understandable, even by people who do not know the subject. 4. The text is only an option to tell the information If a graph explains a subject better than a text, we will choose the graph.Information can often be told in graphs, data or video. 5. Data is information, information is data Datajournalism - the processing, formatting and staging of data - is one of our main focuses for processing information. 6. Our sources are accessible in one click Our articles explicitly mention the source of a fact or a number. As soon as a fact, a number, a source, is available on the Internet, we indicate it by a link. 143 7. The unit is not the article, it is the information We do not wait to publish relevant information to have finished writing a long article. What matters is this information, if it helps to inform a debate. Also, give it as soon as it is reliable and verified, on the most suitable support. We will then assemble these \"bricks\" of information. 8. The information is only valid if it is shared Decoder productions are not limited to articles on the .fr World site, they can also be broadcast on social networks , where they can reach their audience. 9. Information is an element of the conversation on social networks Each publication can be exchanged with readers. Their remarks are taken into account and may lead to changes in the content. 10. We are at the service of our readers We seek to answer questions, polemics, as they form on social networks. We are listening to our readers and their needs for explanations about the news. The Washington Post Our Goal This column first started on Sept. 19, 2007, as a feature during the 2008 presidential campaign. The Washington Post revived it as a permanent feature on Jan. 11, 2011. The purpose of this website, and an accompanying column in the Sunday print edition of The Washington Post, is to \"truth squad\" the statements of political figures regarding issues of great importance, be they national, international or local. It's a big world out there, and so we rely on readers to ask questions and point out statements that need to be checked. 144 But we are not limited to political charges or countercharges. We also seek to explain difficult issues, provide missing context and provide analysis and explanation of various \"code words\" used by politicians, diplomats and others to obscure or shade the truth. The success of this project depends, to a great extent, on the involvement of you-the reader. About 50 percent of our fact checks start with an inquiry from a reader. Readers send us suggestions on topics to fact check and tips on erroneous claims by political candidates, interest groups, and the media. Once we have posted an item on a subject, we invite your comments and contributions. You can follow us on Twitter at GlennKesslerWP or friend us on Facebook. We welcome comments and suggestions via tweets (Include #FactCheckThis in your tweet) or on our Facebook page. You can also email us at factchecker@washpost.com. If you have facts or documents that shed more light on the subject under discussion, or if you think we have made a mistake, please let us know. We also want to make sure that the authors of questionable claims have ample opportunity to argue their case. We issue our own ruling on factual disputes (see our rules on the \"Pinocchio Test\" below) but it can be revised and updated if fresh evidence emerges. Our view is that a fact check is never really finished, so the rating can be revised after we obtain new information that changes the factual basis for our original ruling. A Few Basic Principles This is a fact-checking operation, not an opinion-checking operation. We are interested only in verifiable facts, though on occasion we may examine the roots of political rhetoric. 145 We will focus our attention and resources on the issues that are most important to voters. We cannot nitpick every detail of every speech. We especially try to examine statements that are newsworthy or concern issues of importance. We understand that everyone makes mistakes, especially when speaking extemporaneously, so we do not play \"gotcha.\" We will strive to be dispassionate and non-partisan, drawing attention to inaccurate statements on both left and right. But we also fact check what matters \u2014 and what matters are people in power. When one political party controls the White House and both houses of Congress, it is only natural that the fact checks might appear to heavily focused on one side of the political spectrum. (Divided government is much better for The Fact Checker.) We urge readers to bring to our attention possible false claims we might have missed. We will stick to the facts of the issue under examination and are unmoved by ad hominem attacks. The identity or political ties of the person or organization making a charge is irrelevant: all that matters is whether their facts are accurate or inaccurate. We will adopt a \"reasonable person\" standard for reaching conclusions. We do not demand 100 percent proof. The burden for proving the accuracy of a claim rests with the speaker, however. Consistent with Washington Post policy, no one working on The Fact Checker may engage in partisan political activity or make contributions to candidates or advocacy organizations. Since 2013, The Washington Post has been owned by Jeff Bezos, the chief executive of Amazon, as a personal investment via Nash Holdings LLC. The Fact Checker is part of the national-news section of The Post, which is managed separately from the editorial and opinion section of The Post. 146 We are committed to being transparent about our sources. Whenever possible, we provide links to sources so readers have access to the information we used to reach the conclusions in our fact checks and can verify the information themselves. Everyone makes mistakes and we strive to correct any errors in accordance with The Washington Post's corrections policy. We welcome feedback from readers who may dispute our conclusions and who want to offer additional information that might result in a change in ruling. The Pinocchio Test Where possible, we will adopt the following standard in fact-checking the claims of a politician, political candidate, diplomat or interest group. We do make some allowance for statements made in live interviews, as opposed to a prepared text. We will judge more harshly statements from a prepared text, on the grounds that the politician and staff had time to discuss the statistic. We also make allowances if the politician or interest group acknowledges an error was made. Finally, we also have a feature called \"Recidivism Watch,\" which highlights claims repeated by politicians even though the claim has been previously debunked. 147 One Pinocchio Some shading of the facts. Selective telling of the truth. Some omissions and exaggerations, but no outright falsehoods. (You could view this as \"mostly true.\") Two Pinocchios Significant omissions and/or exaggerations. Some factual error may be involved but not necessarily. A politician can create a false, misleading impression by playing with words and using legalistic language that means little to ordinary people. (Similar to \"half true.\") Three Pinocchios !Significant factual error and/or obvious contradictions. This gets into the realm of \"mostly false.\" But it could include statements which are technically correct (such as based on official government data) but are so taken out of context as to be very misleading. The line between Two and Three can be bit fuzzy and we do not award half-Pinocchios. So we strive to explain the factors that tipped us toward a Three. 148 Four Pinocchios Whoppers. The Geppetto Checkmark Statements and claims that contain \"the truth, the whole truth, and nothing but the truth\" will be recognized with our prized Geppetto checkmark. We tend to reserve this for claims that are unexpectedly true, so it is not awarded very often. An Upside-Down Pinocchio A statement that represents a clear but unacknowledged \"flip-flop\" from a previously-held position. 149 Verdict Pending There are occasions when it is impossible to render a snap judgment because the issue is very complex or there are good arguments on both sides. In this case, we will withhold our judgment until we can gather more facts. We will use this website to shed as much light as possible on factual controversies that are not easily resolved. (The iconic Pinocchio image used by The Fact Checker was created in 2007 by illustrator Steve McCracken.) *** All judgments are subject to debate and criticism from our readers and interested parties, and can be revised if fresh evidence emerges. We invite you to join the discussion on these pages and contact the Fact Checker directly with tips, suggestions, and complaints. If you feel that we are being too harsh on one candidate and too soft on another, there is a simple remedy: let us know about misstatements and factual errors we may have overlooked. PolitiFact PolitiFact is a fact-checking website that rates the accuracy of claims by elected officials and others who speak up in American politics. PolitiFact is run by editors and reporters from the Tampa Bay Times, an independent newspaper in Florida, as is PunditFact, a site devoted to fact-checking pundits. The Tampa Bay Times is owned by the not-for-profit Poynter Institute. The PolitiFact state sites are run by news organizations that have partnered with the Times. The state sites and PunditFact follow the same principles as the national site. 150 PolitiFact staffers research statements and rate their accuracy on the Truth-O-Meter, from True to False. The most ridiculous falsehoods get the lowest rating, Pants on Fire. PolitiFact checks claims by elected officials, candidates, leaders of political parties and political activists. We examine officials at all levels of government, from county commissioners to U.S. senators, from city council members to the president. We also check claims by groups involved in the discourse -- political parties, advocacy groups and political action committees -- and examine claims in widely circulated chain emails. PunditFact checks claims from pundits, columnists, bloggers, political analysts, the hosts and guests of talk shows, and other members of the media. Choosing claims to check Every day, PolitiFact and PunditFact staffers look for statements that can be checked. We comb through speeches, news stories, press releases, campaign brochures, TV ads, Facebook postings and transcripts of TV and radio interviews. Because we can't possibly check all claims, we select the most newsworthy and significant ones. In deciding which statements to check, we ask ourselves these questions: !Is the statement rooted in a fact that is verifiable? We don't check opinions, and we recognize that in the world of speechmaking and political rhetoric, there is license for hyperbole. !Is the statement leaving a particular impression that may be misleading? !Is the statement significant? We avoid minor \"gotchas\" on claims that obviously represent a slip of the tongue. !Is the statement likely to be passed on and repeated by others? 151 !Would a typical person hear or read the statement and wonder: Is that true? Transparency and on-the-record sources PolitiFact and PunditFact rely on on-the-record interviews and publish a list of sources with every Truth-O-Meter item. When possible, the list includes links to sources that are freely available, although some sources rely on paid subscriptions. The goal is to help readers judge for themselves whether they agree with the ruling. Truth-O-Meter rulings The goal of the Truth-O-Meter is to reflect the relative accuracy of a statement. The meter has six ratings, in decreasing level of truthfulness: TRUE - The statement is accurate and there's nothing significant missing. MOSTLY TRUE - The statement is accurate but needs clarification or additional information. HALF TRUE - The statement is partially accurate but leaves out important details or takes things out of context. MOSTLY FALSE - The statement contains an element of truth but ignores critical facts that would give a different impression. FALSE - The statement is not accurate. PANTS ON FIRE - The statement is not accurate and makes a ridiculous claim. Principles in Truth-O-Meter rulings Words matter - We pay close attention to the specific wording of a claim. Is it a precise statement? Does it contain mitigating words or phrases? 152 Context matters - We examine the claim in the full context, the comments made before and after it, the question that prompted it, and the point the person was trying to make. Burden of proof - People who make factual claims are accountable for their words and should be able to provide evidence to back them up. We will try to verify their statements, but we believe the burden of proof is on the person making the statement. Statements can be right and wrong - We sometimes rate compound statements that contain two or more factual assertions. In these cases, we rate the overall accuracy after looking at the individual pieces. Timing - Our rulings are based on when a statement was made and on the information available at that time. Process for Truth-O-Meter rulings A writer researches the claim and writes the Truth-O-Meter article with a recommended ruling. After the article is edited, it is reviewed by a panel of at least three editors that determines the Truth-O-Meter ruling. Corrections and review We strive to make our work completely accurate. When we make a mistake, we correct it and note it on the original item. If the mistake is so significant that it requires us to change the ruling, we will do so. Readers who see an error should contact the writer or editor. Their names are listed on the right side of every Truth-O-Meter item. Clicking on their names will take you to their bio pages, where you can find their email addresses. When we find we've made a mistake, we correct the mistake. !In the case of a factual error, an editor's note will be added and labeled \"CORRECTION\" explaining how the article has been changed. 153 !In the case of clarifications or updates, an editor's note will be added and labeled \"UPDATE\" explaining how the article has been changed. !If the mistake is significant, we will reconvene the three-editor panel. If there is a new ruling, we will rewrite the item and put the correction at the top indicating how it's been changed. We respect that reasonable people can reach different conclusions about a claim. If you disagree with a ruling, we encourage you to email the writer or editor with your comments about our ruling. You can also post comments to our Facebook page or write a letter to the editor. We periodically publish these comments in our Mailbag feature. PolitiFact has two other features: !The Flip-O-Meter, which rates whether an elected official has been consistent on an issue. !Promise meters, such as the Obameter and the GOP Pledge-O-Meter, that rate the status of elected officials' campaign promises. The Flip-O-Meter The Flip-O-Meter rates an official's consistency on an issue. The rating is not making a value judgment about a politician who changes positions on an issue. Indeed, voters often like politicians who are flexible and have the ability to compromise or adapt their positions to the wishes of constituents. Still, accusations of shifting positions are so common in politics that it is valuable to have us provide an analysis of a shift and rate the amount of change. The Flip-O-Meter has three ratings: !No Flip - No significant change in position. !Half Flip - A partial change in position. !Full Flop - A complete change in position. The writing, editing and rating process for Flip-O-Meter items is the same as the process for Truth-O-Meter items. 154 The Promise meters To create our promise meters, staffers pore through speech transcripts, TV appearances, position papers and campaign websites looking for promises. However, a promise is not a position statement. We define a promise as a prospective statement of an action or outcome that is verifiable. All of our promises list the source. The promise meters have six levels. The first three provide a broad picture of whether the official is making progress; the final three indicate whether he or she kept the promise. Not Yet Rated \u2014 Every promise begins at this level and retains this rating until we see evidence of progress \u2014 or evidence that the promise has stalled. In the Works \u2014 This indicates the promise has been proposed or is being considered. Stalled \u2014 There is no movement on the promise, perhaps because of limitations on money, opposition from lawmakers or a shift in priorities. Compromise \u2014 Promises earn this rating when they accomplish substantially less than the official's original statement but when there is still a significant accomplishment that is consistent with the goal of his original promise. Promise Kept \u2014 Promises earn this rating when the original promise is mostly or completely fulfilled. Promise Broken - The promise has not been fulfilled. This could occur because of inaction by the executive or lack of support from the legislative branch or other group that was critical for the promise to be fulfilled. A Promise Broken rating does not necessarily mean that the executive failed to advocate for the policy. Promise ratings change whenever the circumstances change. For some promises, it's possible that the status could initially go to In the Works, but then move back to Stalled if we decide the proposal has hit a lull, and then go back to the In the Works. 155 FactCheck.org At FactCheck.org, we follow a process when we select, research, write, edit and, if necessary, correct our articles. Topics Our topics vary slightly depending on the election cycle. In all years, we closely monitor the factual accuracy of what is said by the president and top administration officials, as well as congressional and party leaders. However, we primarily focus on presidential candidates in presidential election years, and on the top Senate races in midterm elections. In off-election years, our primary focus is on the action in Congress. Selection When selecting material to write about, we seek to devote an equal amount of time reviewing claims by Republicans and Democrats. We do that by reviewing statements they make in the same venues. Our sources include: Sunday talk shows. We review transcripts of the Sunday talk shows on the major networks and cable stations. (ABC, NBC, CBS, Fox News and CNN.) TV ads. A paid service provides us with TV ads for all federal elections (president, Senate and House). We review most if not all of the TV ads in the presidential campaigns, but limit our review for other federal races to those that are identified by nonpartisan sources as \"competitive\" - which, for example, were eight Senate races in 2014. C-SPAN. During presidential election years, we review C-SPAN videos of campaign rallies and events on its campaign page, if transcripts of the events are not available. We also monitor C-SPAN during floor debates on major legislation. Presidential remarks. We review virtually all remarks given by the president, including every speech and press conference. The president's remarks are available on the White House website, and they are emailed to us from the White House press office. CQ Transcripts. This service provides us with transcripts of network and cable news shows, as well as other events, such as speeches and press conferences. We review transcripts that include the remarks of federal politicians, party leaders, candidates and top administration officials on a daily basis. We also monitor comments made by major political figures to the news media, which will lead us to search for transcripts or videos of the remarks. Campaign and official websites, press releases and similar materials. We monitor what politicians and candidates say on their websites or in social media posts, such as on Facebook and Twitter. Readers. We answer questions from readers in a feature we call Ask FactCheck. Research We systematically go through transcripts and videos looking for statements based on facts. Once we find a statement that we suspect may be inaccurate or misleading, we will engage - or attempt to engage - with the person or organization that is being fact-checked. The burden is on the person or organization making the claim to provide the evidence to support it. If the supporting material shows that statement is accurate, we will drop it and move on to something else. Our mission is to reduce the level of deception and confusion in U.S. politics, so we focus on claims that are false or misleading. If the supporting material does not support the claim or if no evidence is provided, then we will conduct research of our own. We rely on primary sources of information. Our sources include: the Library of Congress for congressional testimony; the House Clerk and Senate Secretary's office for roll call votes; the Bureau of Labor Statistics for employment data; the Securities and Exchange Commission for corporate records; the IRS for tax data; the 156 Bureau of Economic Analysis for economic data; and the Energy Information Administration for energy data - to name a few. We rely on nonpartisan government agencies for expertise, analyses and reports, including the Congressional Budget Office, the Joint Committee on Taxation, the Government Accountability Office, the Congressional Research Service, the Centers for Medicare & Medicaid Services, and the federal inspectors general. We also rely on a few respected and trustworthy outside experts, such as the Kaiser Family Foundation on health care data, the Tax Policy Center for tax data and the National Conference of State Legislatures. We also interview experts on other topics as needed - for instance, in researching issues on foreign countries, we would contact experts on those areas. Our goal is to use the best evidence. Editing After a story is written, it goes through several layers of editing and review: Line editing. A line editor reviews the story for content. Is context missing? Is the writing clear? Is the word choice accurate? Copy editing. A copy editor reviews the story for proper style and grammar. Fact-checking. A fact-checker goes through the story line by line, word by word, to make sure that every fact is correct and every statement we make and conclusion we draw is accurate and based on the evidence. All of our stories contain hyperlinks to source material, so that readers can check our facts. By the time we publish, the story will have been reviewed in most cases by four people who were not involved in the writing and the reporting of that story: a line editor, copy editor, fact-checker and by the director of the Annenberg Public Policy Center, Dr. Kathleen Hall Jamieson, a former dean of the Annenberg School for Communication at the University of Pennsylvania. Correction Policy If any new information comes to light after we publish a story that materially changes that story, we will clarify, correct or update our story and provide a note to readers that explains the change, why it was made and the date it was made. Readers can contact us at editor@factcheck.org to request a correction or clarification. Our goal, as stated in our mission, is to apply the best practices of both journalism and scholarship, and to serve as a nonpartisan, nonprofit \"consumer advocate\" for voters, regardless of their party affiliation. We treat conservatives and liberals alike and apply exactly the same standards of accuracy to claims made by both sides. International Fact-Checking Network code of principles 1.!A COMMITMENT TO NONPARTISANSHIP AND FAIRNESS We fact-check claims using the same standard for every fact check. We do not concentrate our fact-checking on any one side. We follow the same process for every fact check and let the evidence dictate our conclusions. We do not advocate or take policy positions on the issues we fact-check. 2.!A COMMITMENT TO TRANSPARENCY OF SOURCES We want our readers to be able to verify our findings themselves. We provide all sources in enough detail that readers can replicate our 157 work, except in cases where a source's personal security could be compromised. In such cases, we provide as much detail as possible. 3.!A COMMITMENT TO TRANSPARENCY OF FUNDING & ORGANIZATION We are transparent about our funding sources. If we accept funding from other organizations, we ensure that funders have no influence over the conclusions we reach in our reports. We detail the professional background of all key figures in our organization and explain our organizational structure and legal status. We clearly indicate a way for readers to communicate with us. 4.!A COMMITMENT TO TRANSPARENCY OF METHODOLOGY We explain the methodology we use to select, research, write, edit, publish and correct our fact checks. We encourage readers to send us claims to fact-check and are transparent on why and how we fact-check. 5.!A COMMITMENT TO OPEN AND HONEST CORRECTIONS We publish our corrections policy and follow it scrupulously. We correct clearly and transparently in line with our corrections policy, seeking so far as possible to ensure that readers see the corrected version. The Associated Press Here!is!a!rundown!of!what!we!fact1check!and!why.!There!are!two!general!categories:!We#push#back#on#political#spin,#exaggeration#and#falsehoods.!This!is!how!the!traditional!AP!Fact!Check!began,!principally!in!Washington,!looking!at!speeches!by!the!president,!political!candidates!and!other!politicians!and!officials.!State!and!international!bureaus!have!done!fact!checks!too!on!speeches!by!other!leaders,!including!at!the!United!Nations.!We#debunk#false#reporting#and#the#growing#phenomenon#of#deliberately#\"fake#news.\"!We!want!to!identify!and!debunk!trending!stories!of!all!kinds,!whether!in!text,!photos!or!videos,!that!are!fictional,!contrived,!twisted!or!otherwise!patently!false!yet!likely!to!be!mistaken!for!truth!by!unwary!news!consumers.!An!example!would!be!the!widely!circulated!story!last!year!that!Pope!Francis!had!endorsed!Donald!Trump's!candidacy!for!president.!No!such!endorsement!had!occurred,!yet!many!people!believed!it.!Note:!The!two!genres!of!fact1check!stories!are!distinguished!by!the!editor's!notes!that!go!with!them:!!!!!!!The!traditional!fact!checks!carry!this!note!in!the!Publishable!Eds.!Note!field:!EDITOR'S!NOTE:!A!look!at!the!veracity!of!claims!by!political!figures.!!!!!!!The!\"fake!news\"!stories!carry!this!note!at!the!bottom!of!the!story!below!a!dash!line:!This!story!is!part!of!an!ongoing!Associated!Press!effort!to!fact1check!claims!in!suspected!false!news!stories.!Some!other!key!rules!and!guidelines:!Be#sure#we#are#right.!Never!state!in!a!fact!check!anything!of!which!we're!not!certain.! 158 Prioritize#items#with#relevance#and#importance.!We!can't!check!every!falsehood.!Focus!on!things!that!matter.!Keep#items#short.#The!lead!should!present!the!assertion!that's!being!checked,!and!quickly!state!what's!wrong!with!it.!Because!it!is!words!being!examined,!we!need!exact!quotes.!That!should!be!followed!by!our!presentation!of!the!facts,!backed!by!appropriate!citations!and!attribution.!Stick#to#checking#facts,#rather#than#opinion.!A!person's!personal!tastes!and!preferences!might!lie!outside!the!mainstream,!but!as!opinions!they!are!not!a!topic!for!a!fact!check.!Our#ruling#doesn't#have#to#be#black#and#white.!Statements!can!fall!along!a!wide!range!of!accuracy,!and!we!don't!use!a!rigid!rating!scale!to!make!our!judgments.!A!statement!can!be!false,!exaggerated,!a!stretch,!a!selective!use!of!data,!partly!or!mostly!true.!We!use!the!most!apt!description!that's!supported!by!what!we!know.!Make#use#of#the#AP's#inGhouse#expertise.!Fact!checks!are!reported!stories.!AP's!own!beat!reporters,!from!politics!and!government!to!science,!sports!and!medicine,!are!among!our!best!resources!to!make!sure!our!fact!checks!are!solid.! AP Stylebook entry: fact%checks,%fake%news!Holding(politicians(and(public(figures(accountable(for(their(words(often(requires(reporting(or(research(to(verify(facts(that(affirm(or(disprove(a(statement,(or(that(show(a(gray(area.!Fact<checking(also(is(essential(in(debunking(fabricated(stories(or(parts(of(stories(done(as(hoaxes,(propaganda,(jokes(or(for(other(reasons,(often(spread(widely(on(the(internet(and(mistaken(as(truth(by(some(news(consumers.!The(term(fake(news(may(be(used(in(quotes(or(as(shorthand(for(the(modern(phenomenon(of(deliberate(falsehoods(or(fiction(masked(as(news(circulating(on(the(internet.!However,(do(not(label(as(fake(news(specific(or(individual(news(items(that(are(disputed.(If(fake(news(is(used(in(a(quote,(push(for(specifics(about(what(is(meant.(Alternative(wording(includes(false(reports,(erroneous(reports,(unverified(reports,(questionable(reports,(disputed(reports(or(false(reporting,(depending(on(the(context.!In(all(cases,(the(goal(of(fact<checking(is(to(push(back(on(falsehoods,(exaggeration(and(political(spin.(Be(specific(in(describing(what(is(false(and(back(up(those(descriptions(with(facts.!Basic(fact<checking(should(always(be(part(of(the(main(story,(including(wording(noting(when(an(assertion(differs(with(known(facts.(Often,(however,(additional(reporting(is(required(to(explore(disputed(points(or(questions(more(fully.(In(those(cases,(a(separate(fact(check(piece(should(be(done.(Some(points:!Present(the(assertion(that's(being(checked,(and(quickly(state(what's(wrong(with(it(or(what(is(correct.(Use(the(exact(quote(or(quotes(that(are(being(examined.(Follow(with(the(facts,(backed(by(appropriate(citations(and(attribution.!Stick(to(checking(facts,(rather(than(opinion.(A(person's(personal(tastes(and(preferences(might(lie(outside(the(mainstream,(but(as(opinions(they(are(not(a(topic(for(a(fact(check.!Fact(checks(need(not(show(statements(to(be(clearly(correct(or(clearly(incorrect.(Words(can(be(true,(false,(exaggerated,(a(stretch,(a(selective(use(of(data,(partly(or(mostly(true,(etc.(Use(the(most(apt(description(that's(supported(by(what(the(facts(show.!If(a(statement(can't(be(confirmed,(or(can't(be(immediately(confirmed,(say(so.!Usage(notes:(fact(check(and(fact<checking((n.),(to(fact<check((v.)! The New York Times (Excerpts from the Times' guidelines on integrity) 159 Other People's Reporting. When we use facts gathered by any other organization, we attribute them. This policy applies to material from newspapers, magazines, books and broadcasts, as well as news agencies like The Associated Press (for example, \"the Senator told The Associated Press\"). In other words, even though The AP is a co-op and we are members, we do not treat its reporting as our own. When writing from a pool report, if we have not witnessed the events, we attribute them to the pool reporter. In a roundup, we may use a phrase like \"reports from news agencies and New York Times bureaus.\" Our preference, when time and distance permit, is to do our own reporting and verify another organization's story; in that case, we need not attribute the facts. But even then, as a matter of courtesy and candor, we credit an exclusive to the organization that first broke the news. Attribution to another publication, though, cannot serve as license to print rumors that would not meet the test of The Times's own reporting standards. Rumors must satisfy The Time s's standard of newsworthiness, taste and plausibility before publication, even when attributed. And when the need arises to attribute, that is a good cue to consult with the department head about whether publication is warranted at all. In those cases when it makes a difference whether we directly witnessed a scene, we should distinguish in print between personal interviews and telephone or E-mail interviews, as well as written statements. Fact Checking. Writers at The Times are their own principal fact checkers and often their only ones. (Magazine articles, especially those by nonmembers of our staff, are fact-checked, but even magazine writers are accountable in the first instance for their own accuracy.) Concrete facts - 160 distances, addresses, phone numbers, people's titles -must be verified by the writer with standard references like telephone books, city or legislative directories and official Web sites. More obscure checks may be referred to the research desk. If deadline pressure requires skipping a check, the editors should be alerted with a flag like \"desk, please verify,\" but ideally the writer should double back for the check after filing; usually the desk can accommodate a last-minute repair. It is especially important that writers verify the spelling of names, by asking. A person who sees his or her own name misspelled in The Times is likely to mistrust whatever else we print. And too often, our correction column makes it clear that someone has guessed a spelling by the sound. Corrections. Because our voice is loud and far-reaching, The Times recognizes an ethical responsibility to correct all its factual errors, large and small. The paper regrets every error, but it applauds the integrity of a writer who volunteers a correction of his or her own published story. Whatever the origin, though, any complaint should be relayed to a responsible supervising editor and investigated quickly. If a correction is warranted, fairness demands that it be published immediately. In case of reasonable doubt or disagreement about the facts, we can acknowledge that a statement was \"imprecise\" or \"incomplete\" even if we are not sure it was wrong. Policies retrieved from: La charte des D\u00e9codeurs. (2014, October 3). Retrieved from http://www.lemonde.fr Kessler, G. (2013, September 11). About The Fact Checker. Retrieved from https://www.washingtonpost.com Adair, B., Holan, A. (2013, November 1). The Principles of PolitiFact, PunditFact and the Truth-O-Meter. Retrieved from http://www.politifact.com 161 Our Process. (n.d.) Retrieved from http://www.factcheck.org International Fact-Checking Network fact-checkers' code of principles. (2016, September 15). Retrieved from https://www.poynter.org Easton, L. (2017, February 1). What we fact-check and why. Retrieved from https://blog.ap.org Guidelines on Integrity. (2008, September 25). "}