{"title": "PDF", "author": "PDF", "url": "https://www3.weforum.org/docs/WEF_Chatbots_RESET_Framework_Pilot_Projects_Using_Chatbots_in_Healthcare_2021.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "in Healthcare INSIGHT REPORT NOVEMBER 2021Contents Forewords Executive summary 1 Background Purpose Framework Piloting process 2 Summary Healthcare applications Opportunities Challenges Need for governance Why use the Chatbots RESET framework? Summary of feedback Some best practices Overall observations 3 Next steps 4 Details of the four pilots Ada Health OmniBot AI Apollo Hospitals Tech Mahindra Contributors3 4 5 5 5 6 7 7 7 7 7 8 8 8 8 9 10 10 13 16 18 21 Cover and Inside: Getty Images, Unsplash \u00a9 2021 World Economic Forum. All rights reserved. No part of this publication may be reproduced or transmitted in any form or by any means, including photocopying and recording, or by any information storage and retrieval system.Disclaimer This document is published by the World Economic Forum as a contribution to a project, insight area or interaction. The findings, interpretations and conclusions expressed herein are a result of a collaborative process facilitated and endorsed by the World Economic Forum but whose results do not necessarily represent the views of the World Economic Forum, nor the entirety of its Members, Partners or other stakeholders. Chatbots RESET Framework Pilot Projects: Using Chatbots in Healthcare 2Forewords Artificial intelligence (AI) is a valuable tool that has been deployed in applications in wide-ranging areas. Nowhere is governance of the use of AI more important than in healthcare - a socially critical service that touches everyone. The use of AI in healthcare is a double-edged sword: there can be tremendous benefits, but if AI is not implemented in a responsible manner, severe negative consequences could result. The Chatbots RESET framework was developed by the World Economic Forum precisely to address this challenge. It covers both AI and healthcare ethics principles, but perhaps most importantly, it defines actions that can be taken by stakeholders to operationalize the principles. Operationalization is a big challenge in responsible AI implementation, and the framework addresses it directly. Frameworks need to be exercised in real-world applications in order to have impact. We have been fortunate to have two start-ups and two large organizations pilot this framework over the past few months. They have shared their journey in this report. Piloting and scaling of frameworks such as Chatbots RESET are critical to ensure that soft governance mechanisms are rapidly adopted and fully deployed. Without this, the gap between the rapid adoption of AI and governance of its use will continue to widen.Kay Firth-Butterfield Head of Artificial and Machine Intelligence, World Economic Forum In January 2020 we launched an effort to determine whether the use of chatbots in healthcare needs to be governed. At that time we did not anticipate the explosion in the use of chatbots that would occur as a result of the COVID-19 pandemic. Since then, chatbots have been used to communicate information about, for example, the virus, the symptoms, preventive measures, self-care and vaccination by national and global agencies, including the Centers for Disease Control (CDC) and the World Health Organization (WHO). Chatbots based on the Microsoft Health Bot platform alone have numbered in the thousands globally. The timing was impeccable. The members of our exceptionally high-quality, multistakeholder community contributed to the thought leadership behind the co-creation of the Chatbots RESET framework. Since the framework was published in December 2020, four partner organizations have conducted projects to pilot it, implementing the principles and actions from the framework in deploying chatbots for healthcare applications. This insight report contains details of these pilots and the lessons learned. The report serves as a reference and motivator for other organizations to implement the principles from the framework in their use of chatbots in healthcare. Readers might also be inspired by the framework to extend it to the broader use of AI in healthcare or the use of chatbots in varied applications. Collaborative efforts in these directions are welcome.Venkataraman (Sundar) Sundareswaran Mitsubishi Chemical Holdings Fellow, Artificial and Machine Intelligence, World Economic Forum Chatbots RESET Framework Pilot Projects: Using Chatbots in Healthcare 3Executive summary As artificial intelligence (AI) applications proliferate, they are starting to affect everyday life in real ways. An example of this is the use of conversational AI systems, also known as chatbots, in healthcare applications. Over the course of the COVID-19 pandemic, chatbots have been used extensively to communicate information about the virus and vaccination, and to assist in symptom checking. Such uses of AI in healthcare can be extremely beneficial, but we must pay attention to the potential negative consequences as well. Last year, the World Economic Forum assembled a multistakeholder community that co-created Chatbots RESET, a framework for governing the responsible use of chatbots in healthcare. The framework consists of two parts: (1) a set of 10 principles selected from AI ethics and healthcare ethics principles and interpreted within the context of the use of chatbots in healthcare; and (2) operationalization actions for each principle in the form of recommendations to implement in various stages of deployment of chatbots in healthcare. The Chatbots RESET framework is actionable, and can be readily used by developers, providers and regulators. The framework was published in December 2020.Since the publication of the Chatbots RESET framework, four organizations have piloted the framework: Ada Health, OmniBot AI, Apollo Hospitals and Tech Mahindra. These organizations applied principles from the framework in their healthcare chatbot projects, leveraging operationalization actions recommended in the framework. During these pilots, they selected suitable principles for their projects, implemented actions to realize the principles, and provided feedback on their experience. A caveat, which is true for any piloting activity, is that the principles and actions were chosen to exercise the framework rather than to fully validate it. This insight report provides details of each of the pilots along with a summary of their overall feedback. It is hoped that the report serves as a reference for others, enabling them to follow in the footsteps of these four pioneering organizations, encouraging them to take the lead in using AI technologies responsibly in healthcare applications by implementing the principles and actions from the Chatbots RESET framework. DECEMBER 2020Chatbots RESET A Framework for Governing Responsible Use of Conversational AI in HealthcareIn collaboration with Mitsubishi Chemical Holdings Corporation Chatbots RESET Framework Pilot Projects: Using Chatbots in Healthcare 4Background1 The primary purpose of this document is to arm readers with an understanding and access to a framework that will help them succeed in their chatbot efforts in healthcare. Many healthcare organizations, including small and medium enterprises (SMEs), large companies, healthcare providers, insurers, civil society organizations and government regulatory agencies, are interested in understanding the positive and negative impacts of using AI technology such as chatbots in the field. This interest has been further sharpened by the acceleration of AI deployments during the COVID-19 pandemic. Chatbot technology has been deployed in thousands of cases during the pandemic and presents a unique and narrow use case of AI in healthcare. The Artificial Intelligence and Machine Learning team at the World Economic Forum brought together stakeholders from organizations in healthcare and beyond to co-create a framework for the use of chatbots in healthcare. Purpose Chatbots RESET, the framework co-created by the multistakeholder project community, was published by the Forum in December 2020. Since then, four partner organizations have piloted the framework in their projects. The framework consists of a set of principles selected by project community experts from AI and healthcare. These principles have been elaborated in the framework in the context of the use of chatbots in healthcare. Furthermore, a set of actions per principle has been developed by the project community to assist users of the framework in \"operationalizing\" the principles. The benefits of including the operationalization actions have become abundantly clear during the piloting process.Framework Chatbots RESET principlesSafety/ non- malecence Efcacy Data Transparency Fairness Explainability Integrity Inclusiveness Accountability Chatbots RESET principles Developer Provider Regulator DEVELOP DEPLOY SCALEAI ethics Healthcare ethicsPrinciples Actions to implement principles Chatbots RESET Framework Pilot Projects: Using Chatbots in Healthcare 5Piloting the framework is intended to be a quick way to validate its contents in terms of their relevance and practicality. To enable partner organizations to rapidly complete the piloting process, they were offered two approaches, both of which included only a small amount of oversight from the Forum: (1) use of the framework in a real project, either new or ongoing, to implement a chatbot for a healthcare scenario; (2) use of the framework in a simulated scenario, for example, a future use of chatbots in a healthcare application.The four partner organizations that participated in the pilot completed their implementation and assessment in a period of three months (January- March 2021) and shared their feedback at a community session during the Global Technology Governance Summit held on 6 April 2021. This report provides a comprehensive documentation of their piloting experience. It starts with a summary of the experience of the piloting partners, and then provides further details on each of their implementations and processes.Piloting process Chatbots RESET Framework Pilot Projects: Using Chatbots in Healthcare 6Summary2 While each pilot had its own implementation approach, experience and lessons learned, there were some common elements across the pilots. These are shared below. All of the pilots were concerned with guiding patients in the early part of their healthcare journey. This included educating them on healthcare conditions and care options. One of the pilots, which was specifically focused on education about a public health situation, namely COVID-19, was a voice-based chatbot, while the others were text-based.Healthcare applications Piloting partners noted that several opportunities arise from the use of chatbots in healthcare: -Availability of data on patients' healthcare/medical records (EHR/EMR) -Better clinical decision-making -Contributions to improving the quality, reducing the cost and increasing the accessibility of healthcare -Reduction in the number of unanswered calls to hotlines -Lowering of processing time for public health incidents (e.g. vaccinations)Opportunities Partners identified the following challenges in implementing chatbots for healthcare: -Selecting the appropriate problem -Handling bias issues successful machine-human collaboration -Balancing vs. a high level of accessibility -Finding a \"one-solution-fits-all\" to serve diverse populations and comply with country-specific lawsChallenges The following items were identified as the reasons why chatbots in healthcare should be governed: -Ethics concerns when serving a socially critical need such as healthcare -Adoption requirements (often requiring clinician-AI collaborative solutions) -The fact of being a new field (often not classified as medical devices) -Regulation not having caught up with fast-moving technology -Promoting acceptance by governmentsNeed for governance The following feedback was provided by piloting partners -Some operationalization actions should be assigned to both developers and providers, because often they need to work together and agree on outcomes and pathways -Providers and developers should assess mutual digital maturity at the beginning of a project to ensure smooth engagements -Any background/preparatory work performed should be shared with collaborators from other parts of the ecosystem -Expert consultants with first-hand experience should be engaged -Practical guidance based on real-world insights gleaned during piloting could be added to the frameworkSummary of feedback Effective lessons shared by piloting partners include: -Prior experience in the context of disabilities legislation, e.g. the Americans with Disabilities Act (ADA), was helpful -Crowd testing is a good way to assess bot functions -A realistic subject pool and real-life conditions are importantSome best practices The following observations were made based on the feedback from piloting partners -Healthcare applications for the different pilots were very similar, focused on providing guidance in the early stages of the healthcare journey, including symptom checking and educating the patient -Not all principles were applicable in every scenario. Piloting partners implemented between four and eight principles in each case -Piloting partners reported that the principles in the framework are complete and coherent -They were extremely positive about the utility of the framework -All of the implementations took place within a short time span of two to three months -The pilots provided useful feedback on how to maintain and improve the framework Section 4 provides more details on each pilot in the form of responses to a series of questions posed to the piloting partners.Overall observationsPartners articulated the following features as reasons why they chose the Chatbots RESET framework for their pilots: -Ease of use -Well-articulated -Comprehensive -Helps address data sensitivity -Multistakeholder product -Opportunity to retroactively check prior products and projects -Continuous improvement possible, by starting with few principles in the framework and expanding to cover the other principles -Acts as a checklist for factors that may be missed or neglected (e.g. transparency)Why use the Chatbots RESET framework? Chatbots RESET Framework Pilot Projects: Using Chatbots in Healthcare 8Next steps We are currently working on a pilot that aims to increase healthcare access for the population of Rwanda. A separate report will be prepared on this pilot when it is completed. We invite you to participate in the Chatbots RESET project in one of the following ways: -Pilot the framework in your application of chatbots in healthcare, or -Extend the framework to adjacent applications of chatbots or other areas in healthcare by working with us3 Chatbots RESET Framework Pilot Projects: Using Chatbots in Healthcare 9Details of the four pilots Three of the four pilots implemented the Chatbots RESET framework in real applications, while the fourth (Tech Mahindra) used a simulated application. In the following sections, the piloting partners share their approach and observations.4 What is your organization's background? Ada is a global health company founded by doctors, scientists and industry pioneers to create new possibilities for personal health, and transform knowledge into better outcomes. Its core system connects medical knowledge with intelligent technology to help every individual actively manage their health and health organizations deliver effective care. The company works with leading health providers, organizations and governments to realize this vision. The Ada platform has 11 million users worldwide and has completed 25 million assessments since its global launch in 2016. Why did you decide to pilot? Ada was keen to help pilot this framework as we want to contribute to the process by which this document is iterated and optimized based on real-world insights of chatbot development in healthcare. We value guidance that moves beyond abstract principles and provides practical guidance on what actions are needed to meaningfully incorporate those principles in all phases of the product development life cycle. Having this pilot planned from the very beginning of the Chatbots RESET project was the right approach, and ensures that this document remains relevant, rather than becoming another policy document that has little to no impact on promoting best practices. What is your take on why governance is needed for this application? This is required because the field is still relatively new and, while many chatbot applications may fall under the auspices of medical device regulation in the relevant territory, many do not (or alternatively, the medical device regulation may be too high level and not sufficiently focused on the specific circumstances of the application of these novel technologies to established healthcare systems). Therefore, governance frameworks like this one serve a useful purpose in filling gaps where regulation has not yet caught up with the realities of developing and deploying products in this fast-moving field.Which healthcare application did you pilot? The use case in this project is the introduction of Ada's AI-driven symptom assessment and care navigation platform across a US-based health system for broad use by any current patients over the age of 16 years. The chatbot has been integrated into the health system's web-based patient portal. Users of the symptom assessment platform interact with a conversational chatbot-style interface and enter their basic demographics, past medical history and current symptoms, and receive suggestions regarding which conditions may be causing their symptoms, and what type of healthcare they may want to seek next (e.g. self-care, primary care, emergency care). Where available, basic user information can be pulled from the patients' health records, so they do not have to enter their information twice. Based on the level of urgency recommended by the Ada platform, the user is guided to appropriate care options provided by the health system. What was your piloting approach? The Ada platform has a conversational element at the front end; this is how the user interacts with it. This pilot focused on the deployment of the Ada platform with a new client, which required new features to be developed. This project kicked off in November 2020 and the pilot ran between February and March 2021. As a result, the pilot was run retrospectively, in order to collect insights on the use of the framework. Six senior project team members representing a broad range of functions (a project manager, a director of AI, a data scientist, a UX product designer, a medical director and a solutions architect) were interviewed in semi- structured interviews. For each of the actions chosen that were relevant to them, the interviewees were asked to comment on: a. Whether they had implemented the action in their work on this project b. If they did, what was their experience of implementing it: was it difficult to achieve? Easy? c. If they did not, why not? What could have enabled them to implement it?Ada Health Chatbots RESET Framework Pilot Projects: Using Chatbots in Healthcare 10The participants were also asked to read and comment on the whole framework in the context of their work on this project. What are the challenges and opportunities? The COVID-19 pandemic has undoubtedly accelerated digital transformation of healthcare worldwide. In particular, there is a greater recognition of the value of digital health solutions that allow patients and members of the public to receive trusted and safe medical guidance in their own homes, reducing the need for unnecessary hospital visits, which put them and their family at increased risk and also cause additional strain on already busy healthcare systems. Therefore, the Ada platform (the chatbot in this pilot) provides an ideal opportunity to ensure that those patients who most need in- person care can receive it, while those who are well enough to guide their own care can be reassured by understandable and relevant medical information. Nevertheless, such a major change to the way patients and the public access healthcare brings with it undeniable challenges. First, providers and their patients rightly expect the chatbot solution developed to be safe, and to necessarily err on the side of caution. This means that there is a balance to be struck between an acceptable level of safety and overcautiousness, an approach that could lead to too many people being unnecessarily referred to in-person appointments (negating the reason for the chatbot being deployed in the first place). Moreover, given the chatbot's hugely important role as a \"digital front door\" to health services, it is essential to ensure the highest standards of accessibility to the chatbot and to the information/guidance that it provides. A chatbot solution that is inaccessible to those with the highest healthcare needs (who are usually in the most deprived/vulnerable socioeconomic groups) is unacceptable and may cause more harm than good. Similarly, the outputs of the chatbot need to account for the different needs of the various cultural, socioeconomic and other subgroups within the target population. Developing a solution that is at once generalizable to a whole healthcare system's patient population but also able to take into account individual nuances and needs is a major challenge, one that Ada focuses on in all aspects of its product development and deployment. What principles and actions did you choose? The principles and actions selected were: Efficacy: identify intended users and understand their needs at the beginning of the development process Data protection: require security review before launch Human agency: provide tooling/adaptations for patients with visual impairments Accountability: ensure that chatbot workflows are audited by humans at least every year internally to maintain current status and accuracy Transparency: be explicit in distinguishing between recommendation and information Fairness: ensure that data used in development includes under-represented groups Explainability: perform stakeholder analysis to determine the level of explainability expected by users and providers These were selected in consultation with other clinical experts at Ada, as they were felt to reflect the actions most relevant to the development and deployment process experienced so far with the project in question. Efcacy Data protection Human agency Accountability Transparency Fairness Explainability What is your feedback and can you share some best practices? -Some actions should be clearly assigned to both developers and providers, to reflect their joint roles in the co-development of these products. Examples of such actions include those related to stakeholder analysis, such as \"identify intended users and understand their needs at the beginning of the development process\" and \"perform stakeholder analysis to determine the level of explainability expected by users and providers\" -An action should be added to ensure collaborators assess each other's digital maturity at the start of a project -An action should be added to ensure developers/providers are ready to share their background/preparatory work with collaborators, and if necessary be prepared to repeat it -Expert consultants should be engaged who have experience of living with disabilities that may be relevant to the use of chatbots, such as visual impairment One thing that immediately became clear across all of the interviews we performed is that the \"boundary\" between the role of developers and providers is not clear-cut, especially in the application of novel technology to existing healthcare systems, which may require significant co-development. Therefore, some actions that are currently assigned to developers are more appropriately assigned to both developers and providers. Examples of such actions include those related to stakeholder analysis, such as \"identify intended users and understand their needs at the beginning of the development process\" and \"perform stakeholder analysis to determine the level of explainability expected by users and providers\". Assigning these actions to both of these stakeholders in the development process reflects the fact that, across different projects, different groups may know their target user base best and therefore be best placed to undertake and correctly interpret user research and wider stakeholder analysis. In this project, we collaborated with partners from a healthcare system we were largely unfamiliar with, so we remained open to the provider's insights on the needs and wants of their target population, because we understood that they knew them best.The framework as a whole does not take into account potential differences in digital maturity between developers and providers, which may exist even when they are collaborating on the same project. Lower digital maturity may cause issues with realistic expectations in terms of development/deployment parameters, such as scope and timelines, largely due to inexperience with the implementation of digital solutions such as chatbots. Ensuring that developers and providers mutually assess each other's digital maturity before embarking on a project together will allow better expectation management and will frame ongoing co-development conversations in the context of what is genuinely achievable given the resources allocated to the project, and the existing institutional experience of the collaborators. In the interplay between developers and providers, previous work carried out by one or the other party is frequently quoted in early conversations as the partnership is being developed. However, this important work may be presented without context and may have been carried out without the benefit of the specific insights the other party may bring. It is important that developers and providers remain open to sharing these results completely and transparently, and also to potentially repeating the research if the insights from their partners could be brought to bear on a new round of research. With respect to the action on \"provide tooling/ adaptations for patients with visual impairments\", our previous experience with this action in the context of the Americans with Disabilities Act (ADA) was very helpful in the development process for this project. Nevertheless, this area is far from clear, and significant ambiguity remains in the way the legislation can be interpreted. In this respect, we would like to recommend our approach as a best practice; this was to engage a consulting team specifically focused on advising on the development of accessible digital health tools, which they were able to do given their experience of living with disabilities such as visual impairments. Such expert consultants provided a degree of insight that had previously been inaccessible to us, and we are confident that our tool does a much better job in terms of accessibility as a result of their input. Chatbots RESET Framework Pilot Projects: Using Chatbots in Healthcare 12What is your organization's background? OmniBot's Conversational AI platform enables organizations to develop fully scalable chatbots and voice assistants for use in many areas, including customer service, e-commerce and healthcare, in a very short time. The German start-up - co-founded by Jeff Adam, who led the team that developed the Amazon Alexa/Echo voice assistant platform - serves market-leading companies in various industries. OmniBot emphasizes data security and the protection of end customers' privacy. Today, employees in Europe, the US, Asia and the Middle East are working on implementing a wide range of customer projects. OmniBot partnered with Majorel, a leading customer experience (CX) and business process outsourcing (BPO) provider, to offer a hybrid service model that combines OmniBot's platform and technical expertise in implementing chatbots and voice assistants with Majorel's global workforce of 64,000 employees and its customer service centre expertise. The target is to improve the customer experience and the efficiency of contact centres by integrating voice assistants in various customer contact channels - such as via telephone. Why did you decide to pilot? OmniBot's chief executive officer and co-founder Jascha Stein actively contributed to the preparation and writing of the Chatbots RESET framework. Subsequently, he decided to apply the theory from the framework to a practical example. OmniBot views the Chatbots RESET framework as an opportunity to improve the quality of its work using the Chatbots RESET defined principles. Such principles are especially valuable in the healthcare sector, due to the highly sensitive nature of the information involved and the accuracy needed. The framework also acts as a checklist for factors that may be missed by developers. What is your take on why governance is needed for this application? We believe that governance actions are necessary for our healthcare application (which is deployed to address COVID-19 challenges) because information is constantly being updated due to ongoing research and fluctuations in the numbers of infected people. The dissemination of, and access to, objective information from validated sources is therefore of high importance. The handling of data in particular, but also applications in the health sector as a whole, requires guidelines and directives to be made available to developers so that governments and health authorities can take responsibility for the use of these applications and also increase acceptance of their use among the population.Which healthcare application did you pilot? The COVID-19 pandemic is a unique global challenge. Constantly changing information, including instructions related to health and security regulations and measures, present ongoing communication challenges for government organizations. Disseminating current information to the public, and making sure they can access it, plays a decisive role in the fight against the virus. Together with Majorel, OmniBot has developed the Corona Information and Service Hotline for use in public services. Majorel manages these hotlines in several counties in Germany as an essential contribution to global health security. As a voice- conversational AI telephone bot with real-time supervision by live agents, the OmniBot Corona VoiceBot provides the following features: -Answering FAQs about COVID-19, including current topics such as vaccination -Answering questions about the current situation in your country using real-time statistics -Self-diagnostic surveys -Automated processes for making a vaccination appointment -Automated processes for registration on a waiting list for vaccination A voicebot-powered contact centre for the management of healthcare (such as the Corona Hotline) helps ease the pressure on government and health department phone lines, which are overburdened due to the public's increasing need for information. With low service centre capacity in terms of live agents, a limited number of calls can be answered. To optimize information access as well as individual consultation, efficient automation is needed. Using voicebots means hotlines are available for inbound calls at any time. However, outbound calls can also be initiated; people can be contacted who are eligible to participate in the vaccination campaign or when a vaccination appointment becomes available. A combined service with human live agents and voicebots can serve many areas beyond healthcare. What was your piloting approach? We developed the Corona Hotline as a real-life use case at the beginning of the COVID-19 pandemic. In this first phase, we tested it both internally and with a diverse group of users. Using the Chatbots RESET framework, we subsequently reviewed the Corona Hotline and adapted it to the needs OmniBot AI Chatbots RESET Framework Pilot Projects: Using Chatbots in Healthcare 13of the current situation by updating the content (FAQs) and optimizing and expanding automated processes (making appointments for vaccinations; joining a waiting list). Not all principles were 100% applicable to our use case, as not all topics are covered by the Corona Hotline. For example, there is no specific medical consultation, but rather it concerns the provision of information and the automation of processes. We have successfully implemented aspects from the areas of efficacy, data protection, human agency, accountability, transparency, explainability, integrity and inclusiveness, whereby a focus was placed on efficacy and inclusiveness by choosing a telephone bot. However, human agency, transparency and explainability are also important principles that we have successfully implemented (for details on the implementation, see below). What are the challenges and opportunities? We saw the following opportunities: -The rate of unanswered calls decreases due to automation of the Corona Hotline -Questions can be answered quickly at any time and independently of human resources due to 24/7 availability -There are no waiting times or need to redial -The concerns of hotline users are handled quickly -Processes such as making a vaccination appointment and registering on a waiting list are automated, reducing processing times -By automating processes, efficiency is increased and there is less of a burden on service centre employees -Users of the Corona Hotline receive objective information from validated sources and can find out about current COVID-19 concerns (e.g. number of people infected, deceased and recovered) in real time -Constantly updating information can be quickly adapted in the Corona Hotline -The information and service hotline has a broad range of topics and can be expanded -Pre-classification by the bot optimizes efficient processing in the service centre -In the case of detailed concerns, it is possible to transfer the conversation to a service centre employee to provide live personal interaction, which increases individual information access and user satisfaction -Costs for service centre staff can be decreasedWe saw the following challenges: -FAQs can be limited, if they do not consider the local context; it is possible to extend FAQs, but local healthcare regulations can make this task challenging. However, if they are extended, the hotline must accommodate these. -Currently, the Corona Hotline is available only in English and Japanese, but it could potentially be extended multilingually, with a focus on translating technical or COVID-19-specific terms -When processing personal data, data protection compliance must be ensured -More planning and technical implementation are required to integrate the option to have an agent to take over in real time -Within the scope of inclusiveness, not all potential users (100%) can be reached, but the vast majority can be -For application in the health sector, there is low tolerance for error What principles and actions did you choose? Efficacy: We have developed the Corona Hotline as a voicebot for the masses. About 50% of the world's population has no internet access; older people may have limited or no experience of using the internet but have phone access; and there are about 750 million illiterate people worldwide who are unable to communicate with a text-based chatbot. To address this problem, the Corona Hotline provides information over the phone. We have prepared the information in an understandable form, and designed the dialogue flow logically and intuitively to ensure ease of use. As a matter of principle, we have included information and content that comes only from official, verified and regularly checked, up-to-date sources. Our self-diagnostic survey follows the Risk Level 2: Moderate template from the template by asking for general conditions and symptoms, but does not provide a concrete diagnosis, recommending instead consultation with a doctor. Data protection: The Corona Hotline begins by asking whether the user agrees to the recording. Only after agreement is given can the user interact with the bot. The Corona Hotline is GDPR compliant and also includes a rights and roles concept and identity management for access controls. Unauthorized access is prevented by security measures. Sensitive data is adequately protected during transmission and storage, with the level of protection depending on the corresponding classification of the data based on relevant data protection standards. Chatbots RESET Framework Pilot Projects: Using Chatbots in Healthcare 14Human agency: We have developed the Corona Hotline as a voicebot hotline with real-time supervision, enabling seamless real-time communication with trained live agents. A handover to a live agent is not only possible in case of escalation, but at any time (within service hours). The agents can also view, check and evaluate the conversation history at any point in order to improve the degree of automation. Accountability: The Corona Hotline is regularly reviewed internally to ensure that the FAQs in particular are up to date. If the geographic area of the Corona Hotline is known, regular, country-specific adjustments can be made to meet current needs. All conversation histories are transparent (depending on their access level, users can check their histories and access relevant information at any time). Transparency: Right at the beginning, an explicit prompt explains that the user is communicating with an AI-based bot. The ability to divert to a live agent during the call is communicated transparently to the user. From the outset, the user is also clearly informed about what they can do (get information, take a self-diagnostic survey, check current statistics from their own country, make an appointment for vaccination and put themselves on the waiting list). In addition, the user is informed about the performance limits of the hotline with respect to FAQs (\"trained on a few select topics so far\"). In the case of the self-diagnostic survey, users are cautioned that a doctor needs to be consulted, and that the service is only a reference based on a self-assessment flow designed by health authorities. Users are also informed immediately if the bot has not understood them (escalation). This was tested under real-world conditions.Explainability: At the start, it is explained to users why the conversation is being recorded. In the FAQs section, layperson's terms have been used - and any difficult terms that arise are explained by the bot. In addition, the source from which the bot is drawing its information is given. In the self-diagnostic survey, users are also informed that they will be asked some questions in order to evaluate their risk of infection. The questions are all formulated in an understandable way, and the answers are kept clear and comprehensible. For vaccination appointments, when an appointment is declined, a clear explanation is offered or the call is handed over to a live agent, so that automated processes are also made comprehensible and transparent or are, at a minimum, escalated to a live agent. Integrity: The sources used for the FAQs are communicated openly and transparently. Only information from valid sources is given out by the bot (e.g. CDC, WHO). Inclusiveness: The bot is not only usable in English, but also in Japanese - and can potentially be expanded to other languages, such as Hindi. The Corona Hotline is designed as a voicebot to take into account the fact that up to 50% of the world's population does not have access to reliable internet services. Information can thus be made available to anyone with access to a telephone. Potentially, the voicebot is also expandable as a chatbot based on text. Among the slightly less relevant principles for us were safety/non-maleficence and fairness, because, due to our use case, we do not collect data on, for example, ethnicity and religion, which could lead to users being treated unequally. Efcacy Data protection Human agency Accountability Transparency Explainability Integrity Inclusiveness What is your feedback and can you share some best practices? Overall, the principles were comprehensible and understandable, and a review and adaptation of our Corona Hotline was possible. The principles also gave us an impression of completeness and appear coherent, so that we do not currently see a need for any modifications or additional measures. We suggest reviewing the principles at regular intervals and adapting them as necessary to meet the constantly updating requirements. We see crowd testing as a useful measure for assessing the bot functions, because a diverse group of potentially real users and different user types ensures heterogeneity and representativeness. In addition, tests with native speakers under real conditions (background noise, dialects) can be carried out in this way. Another measure of our quality assurance is the setting up of processes for quick error correction. The basis for this is continuous screening and consistent evaluation of conversation histories and any errors that occur. Permanent optimization also includes the inclusion of questions that are frequently asked by users but are not yet available in the FAQs of the Corona Hotline. We are aware that no voicebot or chatbot works 100% of the time, which is why we have decided to integrate live agents. In doing so, we are pursuing the goal of improving the user experience by combining technology (OmniBot) with personal human interaction (Majorel). What is your organization's background? Apollo Hospitals has a robust presence across the healthcare ecosystem, including hospitals, pharmacies, primary care and diagnostic clinics. Apollo 247 is the Apollo group's digital platform, offering online teleconsultations and pharmacy and lab services. The online platform was launched in early 2020 with a vision of providing easy access to world-class healthcare solutions to consumers across India. In little more than a year since its launch, Apollo 247 has managed to attract more than 7 million registered users with more than 1 million active weekly users. Why did you decide to pilot? Being a relatively new tool, guiding principles for chatbots are not well defined. Our decision to pilot the Chatbots RESET framework came from the comprehensive RESET principles underpinning it. The RESET documentation provides implementable action steps that help operationalize each principle at various stages of the project, including development, deployment and scaling. The framework is easy to use, lucidly articulated and comprehensive. What is your take on why governance is needed for this application? While most geographies have now developed regulatory guidelines and governing principles for telemedicine and medical devices, governance for chatbots has mostly remained elusive. As chatbots come to the forefront, with great potential to affect patients' healthcare journey, a governing framework becomes critical. Additionally, there are multiple issues to be addressed through such a framework, including: -Interoperability and universalization: algorithms prepared on one organization's electronic medical record (EMR) system need to be translatable to others' and thus require extensive validation in diverse populations -Calibration and benchmarking: Apollo Hospitals strongly advocates the use of clinicians plus AI - they are mutually complementary to decision- making -Clinically relevant outcomes: as measured through sensitivity, specificity, likelihood ratios and predictive values -Patient safety: meeting accepted standards of clinical benefits Which healthcare application did you pilot? The Apollo 247 team is developing an AI/machine learning-based symptom assessment platform, SympAI, with the aim of providing users with their probable diagnosis and diagnostic/lab investigations, in addition to the next steps that they can consider based on their symptoms. We carried out the Chatbots RESET framework pilot on the current version of the platform, which is a Level 2 chatbot (as defined in the framework), live on the Apollo 247 portal, where its primary use is to advise users on which medical specialty to consult after assessing their symptoms. The platform is undergoing constant upgrades and a Level 3 chatbot, currently in beta development mode, will soon be available on the Apollo 247 portal.Apollo Hospitals Chatbots RESET Framework Pilot Projects: Using Chatbots in Healthcare 16What was your piloting approach? We are using a real use case scenario in the piloting approach. As we develop the chatbot's capability to advance its functionality to a Level 4 chatbot, we applied the selected principles and action steps. The developer and clinical team worked together in conjunction with the project management team to incorporate these. What are the challenges and opportunities? Apollo 247 was launched in India around the beginning of the pandemic. We witnessed a great demand from consumers for tele/digital healthcare services as the physical healthcare infrastructure was already under great stress from rising COVID-19 cases. While the pandemic has accelerated the growth of telehealth, it is likely that the trend is here to stay, with users becoming accustomed to increased ease of access to healthcare. Opportunities: -Using SympAI to triage patients from minor cases to more serious conditions, thereby saving them unnecessary visits to hospitals -Integrating with Apollo 247's digital platform to maintain the continuum of care for patients via telehealth as well as Apollo clinics -Integrating with Apollo Health Check - these algorithms streamline better clinical decision- making and appropriate and timely conversions to higher levels of care -Most importantly, using simplistic APIs (application programming interfaces) to integrate with other organizations' EMRs, easing access to clinicians and their patients for point-of-care decision-making Challenges: -Ensuring the safety of any recommendations or decisions made by a chatbot - especially in relation to whether or not to seek emergency care -Addressing bias - that is, bias generated by geographical factors, different clinical settings, investigators or machines (tests/imaging/graphs (ECG)) and their impact on the development and validation of an AI model -Addressing sensitivity and privacy issues with users, especially in a country such as India with diverse beliefs and values -Practical accuracy, which requires a solution that reflects knowledge representation, causal structure, missing observation, flow of information etc. -Machine and human handovers - algorithms learn to hand over/defer to a clinical expert in decision-making What principles and actions did you choose? The following principles and actions were selected by the developer and clinical team for integration into the SympAI platform. Safety: We built on existing guidelines to allow for the determination of critical/serious/ non-serious cases and integrated the Canadian Triage and Acuity Scale (CTAS) into our chatbot to identify patients in need of immediate emergency care. Efficacy: We included efficacy metrics as a central aspect of procurement, including requests for evidence of efficacy from developers. Validation frameworks were put in place with the help of a clinical team to review recommendation outputs from the chatbot. Accountability: We sought clinical inputs in the decision to implement a chatbot; a clinical team was involved in each step of the process of development. We had the team in place to review the knowledge as well as the clinical governance aspects of the chatbot. Transparency: We provided an explanation of decision or inference, in plain language, by infographic or by video, and informed users of whether the matter is non-serious, serious or critical. Our triage advised patients whether they required urgent or outpatient care. Additionally, the interface allowed users to see the options they selected and the aspects that went into deciding on a particular diagnosis. Explainability: We used layperson's terms in patient-facing chatbot interactions (and provided links to clinical concepts). We are now working on a medical content library that would make it easy for patients to understand their condition, with likely next steps. Chatbots RESET Framework Pilot Projects: Using Chatbots in Healthcare 17Efcacy Data protection Human Agency Accountability Transparency Explainability Integrity Inclusiveness Safety/ non-malecence Efcacy Accountability Transparency Explainability What is your feedback and can you share some best practices? The framework principles and actions are clear and easy to follow. We can conform to these principles and, as evidence builds up, re-evaluate at regular intervals - annually or biannually. An overarching methodology would be to have regular touch points for knowledge transfers between the developer and the clinical team. When we started on the project, it became clear that there was a need to have the clinical and development team collaborate and have regular interactions on various aspects of the chatbot. Our clinical team had regular sessions with the developer team, providing insights on how a physician approaches a patient in the clinic. This included the patient interview process, identifying diagnostics used for screening, mapping different symptoms and so on. At the same time, it was important for the clinical team to be involved in defining the logic around the recommendation engine. The two teams collaborated extensively, learning from each other's core expertise. Another area of improvement would be establishing boundaries in terms of machine to human handover. While the AI helps the system improve its efficacy, there must be human supervision before the system is deployed. Therefore, in this case, while the chatbot performs the task independently, humans should act as supervisors. What is your organization's background? Tech Mahindra offers innovative and customer- centric digital experiences, enabling enterprises, associates and society to \"Rise\" (a Tech Mahindra policy). We are a $5.1 billion organization with more than 126,200 professionals in 90 countries helping 1,058 global customers, including Fortune 500 companies. We focus on using next-generation technologies including 5G, blockchain, cybersecurity, artificial intelligence and more to enable end-to-end digital transformation for global customers. Why did you decide to pilot? We intend to provide a seamless customer experience using chatbots in healthcare. This includes answering questions about symptoms and test centres, booking appointments, making bill payments through gateways, providing information on pandemic research, and offering the ability to connect to a live agent. We simulated healthcare scenarios to answer questions that belong to low- and moderate-risk levels. We had previously developed a chatbot that catered to these scenarios in real time. Piloting the Chatbots RESET framework in a simulated environment provided suitable guidelines that are in line with our objective of ensuring that chatbots we design and develop are ethical.Tech Mahindra Chatbots RESET Framework Pilot Projects: Using Chatbots in Healthcare 18What is your take on why governance is needed for this application? Governance provides a guidance framework to ensure and enable responsible development and deployment of chatbots. Lack of governance makes chatbots susceptible to privacy and fairness issues. Which healthcare application did you pilot? We created two chatbots - low-risk level and moderate-risk level - on Entellio, our chatbot development platform. These chatbots provide AI conversational experiences that respond to scenarios centred around the patient journey in a hospital at the low- and moderate-risk levels. The low-risk level chatbot can provide information to users about hospital opening and visiting hours and general information about the current pandemic, and allow them to book appointments online. The moderate-risk level chatbot provides information about users' specific conditions, such as when they will be discharged, or symptoms of specific diseases, including COVID-19. What was your piloting approach? We developed the COVID chatbot on Entellio to provide general and location-specific information about the pandemic. Entellio is an internal conversational platform built using open-source technologies. The chatbots for healthcare were implemented in this platform. Pilot process: We first chose the principles of non-maleficence, efficacy, data protection, fairness, explainability and integrity to include in our simulated chatbots for low- and moderate-risk levels. The Chatbots RESET framework provides guidelines to operationalize the principles, with corresponding actions to ensure that the chatbot developed is responsible. We identified relevant questions that would be asked by users in relation to their hospital experience and the pandemic. We then trained the chatbots to respond to these questions by incorporating actions in the response. Entellio has the capacity to incorporate users' feedback, which was used to determine the success of the pilot and whether any additional requirements were needed. What are the challenges and opportunities? Plenty of opportunities exist to help both the public and hospitals in terms of customer service. Challenges lie in the adoption of chatbots due to poor prior experience or lack of openness. Challenges also exist because there are insufficient governance policies to convince users about fairness, privacy, transparency and data protection. What principles and actions did you choose? -Principles we used in the framework: non- maleficence, efficacy, data protection, fairness, explainability and integrity -Actions we implemented: we implemented separate chatbots based on the type of questions users asked. For the low-risk level chatbot, questions were centred around general healthcare information, so responses were factual. At the moderate-risk level, users could be redirected to different channels such as a payment gateway or asked to consult with their doctor. -Rationale in selecting these principles and actions: principles such as efficacy and integrity are essential to ensure chatbot users receive fair responses and thus drive adoption. A chatbot should be trained only on the use case it was created for, which is Entellio's central policy. For user-specific questions, authentication is vital if the user is to be redirected to the correct channel as appropriate. Efcacy Data protection Human Agency Accountability Transparency Explainability Data protection Explainability Fairness Integrity What is your feedback and can you share some best practices? The principles and actions are clearly stated for low- and moderate-risk level use cases. High- and very high-risk levels need additional guidance from experts to determine acceptance criteria. Sample scenarios at these risk levels are listed below: High-risk scenarios: -User mentions mental health condition and then asks about next steps -User checks symptoms and gets diagnosis onlineVery high-risk scenario: -User specifies that he/she is experiencing serious mental health issues and wants to know next-step recommendations We suggest using icons that represent the principles next to the chatbot responses, as appropriate (and only when appropriate). This could act as a quick, visual indicator so the end user can see that the responses comply with the principles of the framework. Also, chatbots are now evolving into voicebots. We foresee the application of the Chatbots RESET framework principles in the development of voicebots as well. Chatbots RESET Framework Pilot Projects: Using Chatbots in Healthcare 20Contributors Lead authors Arunima Sarkar Project Lead, Artificial Intelligence and Machine Learning, World Economic Forum Venkataraman Sundareswaran Mitsubishi Chemical Holdings Project Fellow, Artificial Intelligence and Machine Learning, World Economic Forum Acknowledgements The piloting approaches and results in this white paper were contributed by the following individuals from the partnering organizations: Matthew Fenech, previously Medical Safety Lead, Ada Health Sujoy Kar, Chief Medical Information Officer, Apollo Hospitals Group Nikhil Malhotra, Global Head of Innovation, Tech Mahindra Jonathan Muck, Senior Communications and Public Affairs Manager, Ada Health Jascha Stein, Co-Founder and Chief Executive Officer, OmniBot.ai Chatbots RESET Framework Pilot Projects: Using Chatbots in Healthcare Economic Forum la 2744 contact@weforum.org www.weforum.orgThe World Economic Forum, committed to improving the state of the world, is the International Organization for Public-Private Cooperation. The Forum engages the foremost political, business and other leaders of society to shape global, regional and industry agendas. "}