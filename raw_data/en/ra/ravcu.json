{"title": "Biostatistics Publications", "author": null, "url": "https://divisionofresearch.kaiserpermanente.org/research/biostatistics/biostatistics-publications/", "hostname": "kaiserpermanente.org", "description": null, "sitename": "Kaiser Permanente Division of Research", "date": "2022-12-07", "cleaned_text": "A demonstration of Modified Treatment Policies to evaluate shifts in mobility and COVID-19 case rates in U.S. counties Mixed evidence exists of associations between mobility data and coronavirus disease 2019 (COVID-19) case rates. We aimed to evaluate the county-level impact of reducing mobility on new COVID-19 cases in summer/fall of 2020 in the United States and to demonstrate modified treatment policies to define causal effects with continuous exposures. Specifically, we investigated the impact of shifting the distribution of 10 mobility indexes on the number of newly reported cases per 100,000 residents 2 weeks ahead. Primary analyses used targeted minimum loss-based estimation with Super Learner to avoid parametric modeling assumptions during statistical estimation and flexibly adjust for a wide range of confounders, including recent case rates. We also implemented unadjusted analyses. For most weeks, unadjusted analyses suggested strong associations between mobility indexes and subsequent new case rates. However, after confounder adjustment, none of the indexes showed consistent associations under mobility reduction. Our analysis demonstrates the utility of this novel distribution-shift approach to defining and estimating causal effects with continuous exposures in epidemiology and public health. Authors: Nugent, Joshua R; Balzer, Laura B Am J Epidemiol. 2023 May 05;192(5):762-771. Effectiveness of BNT162b2 COVID-19 Vaccination in Children and Adolescents We assessed BNT162b2 vaccine effectiveness (VE) against mild to moderate and severe coronavirus disease 2019 (COVID-19) in children and adolescents through the Omicron BA.4/BA.5 period. Using VISION Network records from April 2021 to September 2022, we conducted a test-negative, case-control study assessing VE against COVID-19-associated emergency department/urgent care (ED/UC) encounters and hospitalizations using logistic regression, conditioned on month and site, adjusted for covariates. We compared 9800 ED/UC cases with 70 232 controls, and 305 hospitalized cases with 2612 controls. During Delta, 2-dose VE against ED/UC encounters at 12 to 15 years was initially 93% (95% confidence interval 89 to 95), waning to 77% (69% to 84%) after 150 days. At ages 16 to 17, VE was initially 93% (86% to 97%), waning to 72% (63% to 79%) after 150 days. During Omicron, VE at ages 12 to 15 was initially 64% (44% to 77%), waning to 13% (3% to 23%) after 150 days; at ages 16 to 17 VE was 31% (10% to 47%) during days 60 to 149, waning to 7% (-8 to 20%) after 150 days. A monovalent booster increased VE to 54% (40% to 65%) at ages 12 to 15 and 46% (30% to 58%) at ages 16 to 17. At ages 5 to 11, 2-dose VE was 49% (33% to 61%) initially and 41% (29% to 51%) after 150 days. During Delta, VE against hospitalizations at ages 12 to 17 was high (>97%), and at ages 16 to 17 remained 98% (73% to 100%) beyond 150 days; during Omicron, hospitalizations were too infrequent to precisely estimate VE. BNT162b2 protected children and adolescents against mild to moderate and severe COVID-19. VE was lower during Omicron predominance including BA.4/BA.5, waned after dose 2 but increased after a monovalent booster. Children and adolescents should receive all recommended COVID-19 2023 May 01;151(5). Blood donor, component, and recipient-specific factors associated with venous thromboembolism in transfused hospitalized adult patients: Data from the recipient epidemiology and donor evaluation Study-III (REDS-III) Growing evidence suggests multiple pathophysiological mechanisms linking red blood cells (RBC) transfusions to thrombosis. This study examined blood donor, component, and recipient factors which may be associated with thromboembolic outcomes following RBC transfusion. We utilized the Recipient Epidemiology Donor Evaluation Study-III (REDS-III) database on patients transfused in 12 hospitals between 2013-2016. Stratified Cox proportional hazards regression models with time-dependent exposures were used to examine associations of donor and component modification characteristics on venous thromboembolism (VTE) in patients transfused RBC units. 59,603 patients 229,500 RBC units 79,298 hospitalizations with post-transfusion VTE occurring in 1869 (2.4%) of patients. In adjusted regression analyses, a per RBC-unit risk of VTE was present for gamma irradiation (HR = 1.03; 95% CI: 1.02-1.03), female donor sex (HR = 1.01; 95% CI: 1.00-1.01), storage duration greater = 1.01; 95% CI: index strata (HR = 1.11; 95% CI: 1.08-1.14), and principal diagnoses including malignancy (HR CI: 1.10-1.16), cardiac arrest (HR = hip fracture (HR = 1.59; 95% CI:1.53-1.66) were associated with VTE in adjusted analyses. We identified several donor, component, and recipient-specific factors associated with VTE in transfused hospitalized adult patients. In adjusted models, the dose-dependent associations of donor and component-specific factors with VTE were modest and unlikely to be clinically significant in the majority of transfused patients. Additional mechanistic and clinical studies linking blood donor and component factors with thrombotic outcomes are needed. Authors: 2023-02-25. tobacco smoking and risk of SARS-CoV-2 infection and hospitalization: Evaluating the role of socio-demographic factors and comorbidities Our recently published study of >2.4 million adults in Northern California indicated that current versus never-tobacco smoking was associated with lower risk of SARS-CoV-2 infection and less severe coronavirus disease 2019 (COVID-19). We extended this research by evaluating whether these associations were moderated by socio-demographic factors and medical comorbidities. This retrospective cohort study of 1,885,826 adults with current or never-smoking status in Kaiser Permanente Northern California from 3/5/2020 (baseline) to 12/31/2020 (pre-vaccine) included electronic health record-based socio-demographics (sex, age, race/ethnicity, neighborhood deprivation index (NDI)) and medical comorbidities (obesity, cardiovascular conditions, diabetes, renal disease, respiratory conditions). We estimated the adjusted risk of SARS-CoV-2 infection and hospitalization (30 days of infection) associated with smoking status using Cox proportional hazard regression models. We estimated associations within subgroups of socio-demographics and comorbidities, and tested for effect modification using interaction terms. During the study, 35,627 patients had SARS-CoV-2 infection. Current versus never-smoking status was associated with lower adjusted rates of SARS-CoV-2 infection (aHR ranging from 0.51 to 0.89) and hospitalization (aHR ranging from 0.32 to 0.70) within nearly every socio-demographic and comorbidity subgroup. Statistically significant interactions showed that the magnitude of protection for SARS-CoV-2 infection varied by sex, age, race/ethnicity, NDI, cardiovascular conditions and diabetes, and for SARS-CoV-2 hospitalization by age and renal disease. Taken together, results indicated that while some socio-demographics and comorbidities moderated the associations, the lower risk of SARS-CoV-2 infection and hospitalization associated with current versus never-smoking status persisted among patients regardless of Apr 26;172:107523. Epub 2023-04-26. Impact of a scalable training program on the quality of colonoscopy performance and risk of post-colonoscopy colorectal cancer Endoscopist adenoma detection rates (ADR) vary widely and are associated with patients' risk of post-colonoscopy colorectal cancers (PCCRC). However, few scalable physician-directed interventions demonstrably both improve ADR and reduce PCCRC risk. Among patients undergoing colonoscopy, we evaluated a scalable online training's influence on individual-level ADRs and PCCRC risk. The intervention was a 30-minute, interactive, online training, developed using behavior-change theory to address factors that potentially impede adenoma detection. Analyses included interrupted time series analyses for pre- vs. post-training individual-physician ADR changes (adjusted for temporal trends) and Cox regression for associations between ADR changes and patients' PCCRC risk. Across 21 endoscopy centers and all 86 eligible endoscopists, ADRs increased immediately by an absolute 3.13% (95% confidence interval [CI]; 1.31-4.94) in the 3-month 0.40-0.77) (95%CI: and post-training periods, respectively. Post-training ADR increases were higher among endoscopists with pre-training ADRs below the median. Among 146,786 post-training colonoscopies (all indications), each 1% absolute increase in screening ADR post-training was associated with a 4% decrease in their patients' PCCRC risk (hazard ratio [HR]: 95%CI: 0.93-0.99). An ADR increase of 10% vs. <1% was associated with a 55% reduced risk of PCCRC (HR: 0.45, 95%CI: 0.24-0.82). A scalable online behavior-change training focused on modifiable factors was associated with significant and sustained improvements in ADR, particularly among endoscopists with lower ADRs. These ADR changes were associated with substantial reductions in their patients' risk of PCCRC. Authors: Corley, Douglas A; H; Quesenberry, Charles P; et al. Gastrointest Endosc. 2023 Apr 22. Protection of 2 and 3 mRNA Vaccine Doses Against Severe Outcomes Among Adults Hospitalized with COVID-19 - VISION Network, August 2021 - March 2022 We assessed coronavirus disease 2019 (COVID-19) vaccination impact on illness severity among adults hospitalized with COVID-19, August 2021-March 2022. We evaluated differences in intensive care unit (ICU) admission, in-hospital death, and length of stay among vaccinated (2 or 3 mRNA vaccine doses) versus unvaccinated patients aged 18 years hospitalized for 24 hours with COVID-19-like illness and positive severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) molecular testing. We calculated odds ratios (ORs) for ICU admission and death and subdistribution hazard ratios (SHR) for time to hospital discharge adjusted for age, geographic region, calendar time, and local virus circulation. We included 27 149 SARS-CoV-2-positive hospitalizations. During both Delta- and Omicron-predominant periods, protection against ICU admission was strongest among 3-dose vaccinees compared with unvaccinated patients (Delta OR, .28-.96]; Omicron OR, 0.69 [95% CI, .54-.87]). During both periods, risk of in-hospital death was lower among vaccinated compared with unvaccinated patients but ORs overlapped across vaccination strata. We observed SHR >1 across all vaccination strata in both periods indicating faster discharge for vaccinated patients. COVID-19 vaccination was associated with lower rates of ICU admission and in-hospital death in both Delta and Omicron periods compared with Infect Dis. 2023 Apr 18;227(8):961-969. Glycemic Control Over Multiple Decades and Dementia Risk in People With Type 2 Diabetes The levels of glycemic control associated with the lowest risk of dementia in people with type 2 diabetes are unknown. This knowledge is critical to inform patient-centered glycemic target setting. To examine the associations between cumulative exposure to various ranges of glycated hemoglobin (HbA1c) concentrations with dementia risk across sex and racial and ethnic groups and the association of current therapeutic glycemic targets with dementia risk. This cohort study included members of the Kaiser Permanente Northern California integrated health care system with type 2 diabetes who were aged 50 years or older during the study period from January 1, 1996, to September 30, 2015. Individuals with fewer than 2 HbA1c measurements during the study period, prevalent dementia at baseline, or less than 3 years of follow-up were excluded. Data were analyzed from February 2020 to January 2023. Time-updated cumulative exposure to HbA1c thresholds. At each HbA1c measurement, participants were categorized based on the percentage of their HbA1c measurements that fell into the following categories: less than 6%, 6% to less than 7%, 7% less than 8%, 8% to less than 9%, 9% to less than 10%, and 10% or more of total hemoglobin (to convert percentage of total hemoglobin to proportion of total hemoglobin, multiply by 0.01). Dementia diagnosis was identified using International Classification of Diseases, Ninth Revision codes from inpatient and outpatient encounters. Cox proportional hazards regression models estimated the association of time-varying cumulative glycemic exposure with dementia, adjusting for age, race and ethnicity, baseline health conditions, and number of HbA1c measurements. A total of 253 211 participants were included. The mean (SD) age of participants was 61.5 (9.4) years, and 53.1% were men. The mean (SD) duration of follow-up was 5.9 (4.5) years. Participants with more than 50% of HbA1c measurements at 9% to less than 10% or 10% or more had greater risk of dementia compared with those who had 50% or less of measurements in those categories (HbA1c 9% to <10%: adjusted hazard ratio [aHR], 1.15-1.51]; HbA1c10%: aHR, 1.74 [95% CI, 1.62-1.86]). By contrast, participants with more than 50% of HbA1c concentrations less than 6%, 6% to less than 7%, or 7% to less than 8% had lower risk dementia aHR, CI, 0.89-0.97]). In this study dementia risk was greatest among adults with cumulative HbA1c concentrations of 9% or more. These results support currently recommended relaxed glycemic targets for older people with type 2 diabetes. Authors: Moran, Chris; Lacy, Mary JAMA Neurol. 2023 Apr 17. Association of primary lifetime occupational cognitive complexity and cognitive decline in a diverse cohort: Results from the KHANDLE study Higher occupational complexity has been linked to favorable cognitive outcomes, but rarely examined in racially and ethnically diverse populations. In a diverse cohort (n = 1536), linear mixed-effects models estimated associations between main lifetime occupational complexity and domain-specific cognitive decline (z-standardized). Occupational complexity with data, people, and things were classified using the Dictionary of Occupational Titles. For occupational complexity with data, highest tertile (vs. lowest) was associated with higher baseline executive function ( = 0.11; 95% confidence interval [CI] 0.00-0.22) and slower rate of decline ( = 0.03; 95% CI 0.01-0.06), and 0.14; 95% CI 0.04-0.25). Highest tertile of occupational complexity with people was associated with higher baseline executive function ( = 0.29; 95% CI 0.18-0.40), verbal 0.23; 95% CI 0.12-0.34). In a diverse cohort, higher occupational complexity is associated with better cognition. Findings should be verified in larger cohorts. Few studies have examined associations of occupational complexity with cognition in diverse populations. Racial and ethnic minorities are disproportionately exposed to lower occupational complexity. Occupational complexity with data and people are associated with better cognition. Authors: Soh, Associations of dietary isothiocyanate exposure from cruciferous vegetable consumption with recurrence and progression of non-muscle-invasive bladder cancer: findings from the Be-Well Study High recurrence and progression rates are major clinical challenges for non-muscle-invasive bladder cancer (NMIBC). Dietary isothiocyanates (ITCs), phytochemicals primarily from cruciferous vegetables (CV), show strong anticancer activities in preclinical BC models, yet their effect on NMIBC prognosis remains unknown. This study aimed to investigate the associations of dietary ITC exposure at diagnosis with NMIBC recurrence and progression. The study analyzed 1143 participants from the Be-Well study, a prospective cohort of newly diagnosed NMIBC cases in 2015-2019 with no prior history of BC. Dietary ITC exposure was indicated by self-reported CV intake, estimated ITC intake, urinary metabolites, and plasma ITC-albumin adducts. Cox proportional hazards regression models were used to calculate hazard ratios (HRs) and 95% confidence intervals (CIs) for recurrence and progression, and unconditional logistic regression models were used to calculate odds ratios (ORs) and 95% CIs for delayed and multiple recurrence. Over a mean follow-up of 25 mo, 347 (30%) developed recurrence and 77 (6.7%) had disease progression. Despite no significant associations with the overall risk of recurrence, urinary ITC metabolites (OR: 1.96; 2.13; 95% CI: 1.03, 4.50) were associated with late recurrence after 12-mo postdiagnosis compared with before 12-mo postdiagnosis. Raw CV intake was associated with reduced odds of having 2 recurrences compared with having one (OR: 0.34; 95% CI: 0.16, 0.68). Higher plasma concentrations of ITC-albumin adducts were associated with a reduced risk of progression, including progression to muscle-invasive disease (for benzyl ITC, 0.19, 0.86). Our findings indicate the possible beneficial role of dietary ITCs in NMIBC prognosis. Given the compelling preclinical evidence, increasing dietary ITC exposure with CV intake could be a promising strategy to attenuate recurrence and progression risks in patients with NMIBC. Authors: Wang, Zinian; et al. Am J Clin Nutr. 2023 Apr 11. The prospective association of hyperandrogenism, oligomenorrhea and polycystic ovary syndrome with incident gestational diabetes: The coronary artery risk development in young adults women's study In this 28-year prospective study of 455 women (mean age: 26 years), polycystic ovary syndrome (PCOS) was associated with a 2.6-fold elevated risk of gestational diabetes (GDM). However, hyperandrogenism or oligomenorrhea in the absence of Apr;198:110593. Epub 2023-03-02. State-Level Indicators of Childhood Educational Quality and Incident Dementia in Older Black and White Adults Higher educational attainment is associated with reduced dementia risk, but the role of educational quality is understudied, presenting a major evidence gap, especially as it may contribute to racial inequities. To evaluate the association between state-level educational quality during childhood and dementia risk. This cohort study analyzed longitudinal data collected from January 1, 1997, through December 31, 2019 (23-year follow-up period). The sample comprised members of Kaiser Permanente Northern California (KPNC), a large integrated health care delivery system, who completed an optional survey during 1964-1972. Eligible individuals were US born; non-Hispanic Black or non-Hispanic White; aged 65 years or older as of January 1, 1996; were still alive; and did not have a dementia diagnosis or lapse in KPNC membership greater than 90 days between January 1 and December 31, 1996. Historical state-level administrative indicators of school quality (school term length, student-teacher ratio, and attendance rates) linked to participants using birth state and birth year (with a 6-year lag) and divided into tertiles using the pooled sample. Dementia diagnoses from electronic health records between 1997 and 2019 were analyzed between March 1 and August 31, 2022. The associations of educational quality with incident dementia were estimated using Cox proportional hazards regression models. Among 21 450 KPNC members who participated in the optional survey, individuals born before availability of educational quality records (n = 87) and missing educational attainment (n = 585) were excluded. The final analytic sample was 20 778 individuals (56.5% women, education). Among Black individuals, 76.2% to 86.1% (vs 20.8%-23.3% of White individuals) attended schools in states in the lowest educational quality tertiles. Highest (vs lowest) educational quality tertiles were associated with lower dementia risk (student-teacher ratio: hazard 0.79 [95% CI, 0.73-0.86]). Effect estimates did not differ by race and were not attenuated by adjustment for educational attainment. In this cohort study, lower state-average educational quality was more common among Black individuals and associated with higher dementia risk. Differential investment in high-quality education due to structural racism may contribute to dementia disparities. Authors: Soh, Apr 01;80(4):352-359. Racial-Ethnic Differences in Treatment Initiation for New Diagnoses of Perinatal Depression The adverse consequences of untreated perinatal depression highlight the need to identify populations to target in order to increase treatment rates. The authors sought to evaluate treatment initiation for a new diagnosis of depression during pregnancy or postpartum and to describe racial-ethnic differences in initiation and type (psychotherapy, antidepressants) of treatment in a large health care system with universal perinatal depression screening. This retrospective cohort study included women who delivered a live birth in the Kaiser Permanente Northern California system between October 2012 and May 2017. Black, Latina, Asian, and White women ages 15 years were eligible. New depression diagnoses were defined by using ICD-9 and ICD-10 codes from electronic health records. Treatment initiation was defined as receiving at least one antidepressant medication dispensation or psychotherapy visit up to 90 days after the diagnosis. Modified Poisson regression was used to estimate the risk for initiating treatment and the type of treatment initiated. In total, 13,637 women with a new depression diagnosis (prenatal: N=7,041, 51.6%; postpartum: N=6,596, 48.4%) were identified. Of the pregnant women, 31.4% initiated treatment, and of the postpartum women, 73.1% initiated treatment. Latina and Asian women were less likely than White women to initiate treatment postpartum. During pregnancy and postpartum, non-White women were more likely to initiate psychotherapy. White women were more likely to initiate antidepressant medication during pregnancy and postpartum or a combination of antidepressant medication and psychotherapy during the postpartum period. Research is warranted to identify patient-, provider-, and system-level barriers that contribute to racial-ethnic of cardiometabolic risk factors following endocrine therapy in women with breast cancer Studies comparing the effect of aromatase inhibitor (AI) and tamoxifen use on cardiovascular disease (CVD) risk factors in hormone-receptor positive breast cancer (BC) survivors report conflicting results. We examined associations of endocrine therapy use with incident diabetes, dyslipidemia, and hypertension. The Pathways Heart Study examines cancer treatment exposures with CVD-related outcomes in Kaiser Permanente Northern California members with BC. Electronic health records provided sociodemographic and health characteristics, BC treatment, and CVD risk factor data. Hazard ratios (HR) and 95% confidence intervals (CI) of incident diabetes, dyslipidemia, and hypertension in hormone-receptor positive BC survivors using AIs or tamoxifen compared with survivors not using endocrine therapy were estimated using Cox proportional hazards regression models adjusted for known confounders. In 8,985 BC survivors, mean baseline age and follow-up time was 63.3 and 7.8 years, respectively; 83.6% were postmenopausal. By treatment, 77.0% used AIs, 19.6% used tamoxifen, and 16.0% used neither. Postmenopausal women who used tamoxifen had an increased rate (HR: 1.43, 95% CI: 1.06-1.92) of developing hypertension relative to those who did not use endocrine therapy. Tamoxifen use was not associated with incident diabetes, dyslipidemia, or hypertension in premenopausal BC survivors. Postmenopausal AI users had higher hazard rates of developing diabetes with non-endocrine therapy users. Hormone-receptor positive BC survivors treated with AIs may have higher rates of developing diabetes, dyslipidemia, and hypertension over an average 7.8 years Sq. 2023 Mar 22. Early Estimates of Bivalent mRNA Vaccine Effectiveness in Preventing COVID-19-Associated Emergency Department or Urgent Care Encounters and Hospitalizations Among Immunocompetent Adults - VISION Network, Nine States, 2022, the most of the sequenced viral genomes in the United States, with further Omicron sublineage diversification through November 2022.* Bivalent mRNA vaccines contain an ancestral SARS-CoV-2 strain component plus an updated component of the Omicron BA.4/BA.5 sublineages. On September 1, 2022, a single bivalent booster dose was recommended for adults who had completed a primary vaccination series (with or without subsequent booster doses), with the last dose administered 2 months earlier (1). During September 13-November 18, the VISION Network evaluated vaccine effectiveness (VE) of a bivalent mRNA booster dose (after 2, 3, or 4 monovalent doses) compared with 1) no previous vaccination and 2) previous receipt of 2, 3, or 4 monovalent-only mRNA vaccine doses, among immunocompetent adults aged 18 years with an emergency department/urgent care (ED/UC) encounter or hospitalization for a COVID-19-like illness. VE of a bivalent booster dose (after 2, 3, or 4 monovalent doses) against COVID-19-associated ED/UC encounters was 56% compared with no vaccination, 32% compared with monovalent vaccination only with last dose 2-4 months earlier, and 50% compared with monovalent vaccination only with last dose 11 months earlier. VE of a bivalent booster dose (after 2, 3, or 4 monovalent doses) against COVID-19-associated hospitalizations was 59% compared with no vaccination, 42% compared with monovalent vaccination only with last dose 5-7 months earlier, and 48% compared with monovalent vaccination only with last dose 11 months earlier. Bivalent vaccines administered after 2, 3, or 4 monovalent doses were effective in preventing medically attended COVID-19 compared with no vaccination and provided additional protection compared with past monovalent vaccination only, with relative protection increasing with time since receipt of the last monovalent dose. All eligible persons should stay up to date with recommended COVID-19 vaccinations, including receiving a bivalent booster dose. Persons should also consider taking additional precautions to avoid respiratory illness this winter season, such as masking in public indoor spaces, especially in areas where COVID-19 community levels are high. Authors: 17;71(53):1637-1646. Epub 2023-03-17. TRENDS IN SMOKING-SPECIFIC LUNG CANCER INCIDENCE RATES WITHIN A U.S. INTEGRATED HEALTH SYSTEM, 2007-2018 At least 10% of lung cancers arise in adults who have never smoked. Data remain inconclusive on whether lung cancer incidence has been increasing among never-smoking adults. How have age-adjusted incidence rates of lung cancer changed temporally, especially among never-smoking adults? Trends in lung cancer incidence were examined using linked electronic health record and cancer registry data on a dynamic cohort of adults aged 30 years at risk for incident lung cancer between 1/1/2007 and 12/31/2018 from an integrated healthcare system in northern California. Truncated age-adjusted lung cancer incidence rates and average annual percentage change (AAPC) in rates were estimated, overall and separately for ever- and never-smoking adults by age, sex, and race/ethnicity. Our (52.5% 15.4% never-smoking) were diagnosed with lung cancer. The overall lung cancer incidence rate declined from 91.1 to 63.7 per 100,000 100,000 person-years (AAPC, -4.2%; 95% CI, -4.4%, -3.9%) and, to varying degrees, within all age, sex, and racial/ethnic groups. Among never-smoking adults, incidence rates were relatively constant, with three-year period estimates ranging from 19.9 to 22.6 per 100,000 person-years (AAPC, 0.9%; 95% CI, -0.3%, 2.1%). Incidence rates for never-smoking adults appeared stable over time within age, sex, and racial/ethnic groups, except for those of Asian and Pacific Islander (API) origin (AAPC, 2.0%; 95% CI, 0.1%, 3.9%), whose rates were about twice as high compared to their counterparts. These observed trends underscore the need to further elucidate the etiology of lung cancer in never-smoking adults, including why incidence is higher and rising in never-smoking API adults. Authors: Sakoda, Lori C; Alabaster, P; Quesenberry, Charles P; Velotta, Jeffrey B Chest. 2023 Mar 17. Rates of malignancies among patients with moderate to severe atopic dermatitis: a retrospective cohort study Patients with atopic dermatitis (AD), also known as eczema, may be at an increased risk for malignancies compared with patients without AD; however, incidence rates (IRs) of malignancies in patients with moderate to severe AD are largely unknown. The objective of this study was to evaluate and compare IRs of malignancies in adults with moderate to severe AD (aged 18 years). Retrospective cohort study using data from a Kaiser Permanente Northern California (KPNC) cohort. AD severity classification was adjudicated with medical chart review. Covariates and stratification variables included age, sex and smoking status. Data were obtained from the KPNC healthcare delivery system in northern California, USA. Cases of AD were defined by outpatient dermatologist-rendered codes and prescriptions of topical therapy or phototherapy (moderate) or systemic treatment (severe). KPNC health plan members with moderate or severe AD (2007-2018). Malignancy IRs and 95% CIs per 1000 person-years were calculated. 7050 KPNC health plan members with moderate and severe AD met eligibility criteria for inclusion. IRs (95% CI) were highest for non-melanoma skin cancer (NMSC) in patients with moderate and severe AD (4.6 (95% CI 3.9 to 5.5) and 5.9 (95% CI 3.8 to 9.2), respectively) and breast cancer (2.2 (95% CI 1.6 to 3.0) and 0.5 (95% CI 0.1 to 3.9), respectively). Except for breast cancer, which was only evaluated in women, malignancies were higher (with non-overlapping CIs) in patients with moderate and moderate to severe AD in men versus women for basal cell carcinoma and NMSC and in former versus never smokers for NMSC and squamous cell carcinoma. This study estimated IRs of malignancies in patients with moderate and severe AD and provides valuable information for dermatology clinicians and ongoing clinical trials in these 10;13(3):e071172. Epub 2023-03-10. Associations between antidepressant use patterns during pregnancy and birth outcomes among periconception antidepressant users Little is known about antidepressant medication use patterns during pregnancy among periconception (before and immediately following conception) users. Additionally, the associations between these patterns and birth outcomes is unclear, after taking into account underlying depression severity. This study describes patterns of antidepressant use among periconception users and examines associations between usage patterns and birth outcomes. This retrospective cohort study included pregnant Kaiser Permanente Northern California (KPNC) members with a live birth between 2014 and 2017 and an antidepressant medication fill that overlapped the 8th week of pregnancy. Outcomes were preterm birth and neonatal intensive care unit (NICU) admission. Data were extracted from KPNC's electronic health records. Modified Poisson regression was conducted. Of the 3637 pregnancies meeting inclusion criteria, 33% (n = 1204) continued antidepressant use throughout the pregnancy (refilled throughout pregnancy), 47% (n = 1721) discontinued use (no refills), and 20% (n = 712) stopped and reinitiated use (refill after 30+ day gap in supply). Women who continued use had 1.86 (95% confidence interval (CI) 1.53, 2.27) times the risk of preterm birth and 1.76 (95% CI: 1.42, 2.19) times the risk of NICU admission, compared to women who discontinued use during pregnancy. Similarly, women with continued use had 1.66 (95% CI: 1.27, 2.18) times the risk of preterm birth and 1.85 (95% CI: 1.39, 2.46) times the risk of NICU admission, compared to women who stopped and reinitiated use. This relationship held when examining continuous exposure; the relationship between continuous exposure and preterm delivery was stronger in later trimesters. Periconception antidepressant users who continue use during pregnancy, particularly into the second and third trimesters, may be at higher risk of adverse birth outcomes. This evidence should be considered alongside the risks associated with depression relapse. Immunodeficiency Virus Status, Tenofovir Exposure, and the Risk of Poor Coronavirus Disease 19 (COVID-19) Outcomes: Real-World Analysis From 6 United States Cohorts Before Vaccine Rollout People with human immunodeficiency virus (HIV) (PWH) may be at increased risk for severe coronavirus disease 2019 (COVID-19) outcomes. We examined HIV status and COVID-19 severity, and whether tenofovir, used by PWH for HIV treatment and people without HIV (PWoH) for HIV prevention, was associated with protection. Within 6 cohorts of PWH and PWoH in the United States, we compared the 90-day risk of any hospitalization, COVID-19 hospitalization, and mechanical ventilation or death by HIV status and by prior exposure to tenofovir, among those with severe acute respiratory syndrome coronavirus 2 infection between 1 March and 30 November 2020. Adjusted risk ratios (aRRs) were estimated by targeted maximum likelihood estimation, with adjustment for demographics, cohort, smoking, body mass index, Charlson comorbidity index, calendar period of first infection, and CD4 cell counts and HIV RNA levels (in PWH only). Among PWH (n = 1785), 15% were hospitalized for COVID-19 and 5% received mechanical ventilation or died, compared with 6% and 2%, respectively, for PWoH (n = 189 351). Outcome prevalence was lower for PWH and PWoH with prior tenofovir use. In adjusted analyses, PWH were at increased risk compared with PWoH for any hospitalization (aRR, 1.31 [95% confidence interval, 1.20-1.44]), COVID-19 hospitalizations (1.29 [1.15-1.45]), and mechanical ventilation or death (1.51 [1.19-1.92]). Prior tenofovir use was associated with reduced hospitalizations among PWH (aRR, 0.85 [95% confidence interval, .73-.99]) and PWoH (0.71 [.62-.81]). Before COVID-19 vaccine availability, PWH were at greater risk for severe outcomes than PWoH. Tenofovir was associated with a significant reduction in clinical events for both PWH and PWoH. J; et al. Clin Infect Dis. 2023 Mar 02. Estimation of COVID-19 mRNA Vaccine Effectiveness and COVID-19 Illness and Severity by Vaccination Status During Omicron BA.4 and BA.5 Sublineage including BA.4 and BA.5, may be associated with greater immune evasion and less protection against COVID-19 after vaccination. To evaluate the estimated vaccine effectiveness (VE) of 2, 3, or 4 doses of COVID-19 mRNA vaccination among immunocompetent adults during a period of BA.4 or BA.5 predominant circulation; and to evaluate the relative severity of COVID-19 in hospitalized patients across Omicron BA.1, BA.2 or This test-negative case-control study was conducted in 10 states with data from emergency department (ED) and urgent care (UC) encounters and hospitalizations from December 16, 2021, to August 20, 2022. Participants included adults with COVID-19-like illness and molecular testing for SARS-CoV-2. Data were analyzed from August 2 to September 21, 2022. mRNA COVID-19 vaccination. The outcomes of interest were COVID-19 ED or UC encounters, hospitalizations, and admission to the intensive care unit (ICU) or in-hospital death. VE associated with protection against medically attended COVID-19 was estimated, stratified by care setting and vaccine doses (2, 3, or 4 doses vs 0 doses as the reference group). Among hospitalized patients with COVID-19, demographic and clinical characteristics and in-hospital outcomes were compared across sublineage periods. During the BA.4 and BA.5 predominant period, there were 82 229 eligible ED and UC encounters among patients with COVID-19-like illness (median [IQR] age, 51 [33-70] years; 49 682 [60.4%] female patients), and 19 114 patients (23.2%) had test results positive for SARS-CoV-2; among 21 007 hospitalized patients (median [IQR] age, 71 [58-81] years; 11 209 [53.4%] female patients), 3583 (17.1 %) had test results positive for SARS-CoV-2. Estimated VE against hospitalization was 25% (95% CI, 17%-32%) for receipt of 2 vaccine doses at 150 days or more after receipt, 68% (95% CI, 50%-80%) for a third dose 7 to 119 days after receipt, and 36% (95% CI, 29%-42%) for a third dose 120 days or more (median [IQR], 235 [204-262] days) after receipt. Among patients aged 65 years or older who had received a fourth vaccine dose, VE was 66% (95% CI, 53%-75%) at 7 to 59 days after vaccination and 57% (95% CI, 44%-66%) at 60 days or more (median [IQR], 88 [75-105] days) after vaccination. Among hospitalized patients with COVID-19, ICU admission or in-hospital death occurred in 21.4% of patients during the BA.1 period vs 14.7% during the BA.4 and BA.5 period (standardized mean difference: 0.17). In this case-control study of COVID-19 vaccines and illness, VE associated with protection against medically attended COVID-19 illness was lower with increasing time since last dose; estimated VE was higher after receipt of 1 or 2 booster doses compared with a primary series alone. Authors: Epub 2023-03-01. Practice Patterns and Outcomes Associated With Anticoagulation Use Following Sepsis Hospitalizations With New-Onset Atrial Fibrillation Practice patterns and outcomes associated with the use of oral anticoagulation for arterial thromboembolism prevention following a hospitalization with new-onset atrial fibrillation (AF) during sepsis are unclear. Retrospective, observational cohort study of patients 40 years of age discharged alive following hospitalization with new-onset AF during sepsis across 21 hospitals in the Kaiser Permanente Northern California health care delivery system, years 2011 to 2018. Primary outcomes were ischemic stroke/transient ischemic attack (TIA), with a safety outcome of major bleeding events, both within 1 year of discharge alive from sepsis hospitalization. Adjusted risk differences for outcomes between patients who did and did not receive oral anticoagulation within 30 days of discharge were estimated using marginal structural models fitted by inverse probability weighting using Super Learning within a target trial emulation framework. Among 82 748 patients hospitalized with sepsis, 3992 (4.8%) had new-onset AF and survived to hospital discharge; mean age was 78\u00b111 years, 53% were men, and 70% were White. Patients with new-onset AF during sepsis averaged 45\u00b133% of telemetry monitoring entries with AF, and 27% had AF present on the day of hospital discharge. Within 1 year of hospital discharge, 89 (2.2%) patients experienced stroke/TIA, 225 (5.6%) had major bleeding, and 1011 (25%) died. Within 30 days of discharge, 807 (20%) patients filled oral anticoagulation prescriptions, which were associated with higher 1-year adjusted risks of ischemic stroke/TIA (5.69% versus 2.32%; risk difference, 3.37% [95% CI, 0.36-6.38]) and no significant difference in 1-year adjusted risks of major bleeding (6.51% versus 7.10%; risk difference, -0.59% [95% CI, -3.09 to 1.91]). Sensitivity analysis of ischemic stroke-only outcomes showed a risk difference of 0.15% (95% CI, -1.72 to 2.03). After hospitalization with new-onset AF during sepsis, oral anticoagulation use was uncommon and associated with potentially higher stroke/TIA risk. Further research to inform mechanisms of stroke and TIA and management of new-onset AF after sepsis is needed. Authors: 2023-02-28. Perinatal Outcomes After Bariatric Surgery Compared With a Matched Control Group To evaluate perinatal outcomes associated with pregnancy after bariatric surgery within a large integrated health care system using propensity score matching. We conducted a retrospective cohort study that evaluated perinatal outcomes in pregnant patients after bariatric surgery from January 2012 through December 2018. History of bariatric surgery was identified by using International Classification of Diseases codes and a clinical database. Primary outcomes were preterm birth (PTB), gestational hypertension, preeclampsia, impaired glucose tolerance or gestational diabetes, a large-for-gestational-age (LGA) or small-for-gestational-age (SGA) neonates, and cesarean birth. Propensity scores were estimated by using logistic regression that accounted for age at delivery, prepregnancy body mass index, year of delivery, parity, neighborhood deprivation index, race and ethnicity, insurance status, initiation of prenatal visit in the first trimester, smoking during pregnancy, chronic hypertension, and preexisting diabetes. Five patients in the control group were matched to each patient in the case group on linear propensity score, and modified Poisson regression was used to adjust for covariates. Sensitivity analyses by timing and type of surgery were performed. We identified a case cohort of 1,591 pregnancies in patients after bariatric surgery and a matched cohort of 7,955 pregnancies in patients who had not undergone bariatric surgery. Demographic characteristics were similar in both groups. In multivariate models, pregnancy after bariatric surgery was associated with a decreased risk of preeclampsia (7.5% vs 10.2%, adjusted relative risk [aRR] 0.72, 95% CI 0.60-0.86), gestational diabetes or impaired (23.5% vs 35.0%, aRR 0.73, 95% CI 0.66-0.80), vs 19.9%, aRR 0.56, 95% CI 0.48-0.65) and an risk SGA (10.9% vs 6.6%, aRR 1.51, 95% CI 1.28-1.78). No significant differences were observed in PTB, gestational hypertension and cesarean delivery. Pregnancy after bariatric surgery in a racially and ethnically diverse cohort of patients is associated with decreased risk of preeclampsia, gestational diabetes or impaired fasting glucose, and LGA neonates; it is also associated with an increased risk of SGA neonates compared with pregnant patients in a matched control group. Authors: Boller, Marie J; Long-term Trajectories of Physical Function Decline in Women With and Without Cancer Patients with cancer experience acute declines in physical function, hypothesized to reflect accelerated aging driven by cancer-related symptoms and effects of cancer therapies. No study has examined long-term trajectories of physical function by cancer site, stage, or treatment compared with cancer-free controls. Examine trajectories of physical function a decade before and after cancer diagnosis among older survivors and cancer-free controls. This prospective cohort study enrolled patients from 1993 to 1998 and followed up until December 2020. The Women's Health Initiative, a diverse cohort of postmenopausal women, included 9203 incident cancers (5989 breast, 1352 colorectal, 960 endometrial, and 902 lung) matched to up to 5 controls (n = 45 358) on age/year of enrollment and study arm. Cancer diagnosis (site, stage, and treatment) via Medicare and medical records. Trajectories of self-reported physical function (RAND Short Form 36 [RAND-36] scale; range: 0-100, higher scores indicate superior physical function) estimated from linear mixed effects models with slope changes at diagnosis and 1-year after diagnosis. This study included 9203 women with cancer and 45 358 matched controls. For the women with cancer, the mean (SD) age at diagnosis was 73.0 (7.6) years. Prediagnosis, physical function declines of survivors with local cancers were similar to controls; after diagnosis, survivors experienced accelerated declines relative to controls, whose scores declined 1 to 2 points per year. Short-term declines in the year following diagnosis were most severe in women with regional disease (eg, -5.3 [95% CI, -6.4 to -4.3] points per regional vs -2.8 [95% CI, -3.4 to -2.3] for local breast cancer) or who received systemic therapy (eg, for local endometrial cancer, -7.9 [95% CI, -12.2 chemotherapy; -3.1 [95% CI, to -2.6 [95% CI, -4.2 to -1.0] with neither, respectively). While rates of physical function decline slowed in the later postdiagnosis period (eg, women with regional colorectal cancer declined -4.3 [95% CI, -5.9 to -2.6] points per year in the year following diagnosis vs -1.4 [95% CI, -1.7 to -1.0] points per year in the decade thereafter), survivors had estimated physical function significantly below that of age-matched controls 5 years after diagnosis. In this prospective cohort study, survivors of cancer experienced accelerated declines in physical function after diagnosis, and physical function remained below that of age-matched controls even years later. Patients with cancer may benefit from supportive interventions to preserve physical functioning. Authors: Cespedes Natural of multiple recurrences in intermediate-risk non-muscle invasive bladder cancer: lessons from a prospective cohort To describe the risk of multiple recurrences in intermediate-risk non-muscle invasive bladder cancer (IR-NMIBC) and their impact on progression. Prognostic studies of IR-NMIBC have focused on initial recurrences, yet little is known about subsequent recurrences and their impact on progression. IR-NMIBC patients from the Be-Well Study, a prospective cohort study of NMIBC patients diagnosed from 2015 to 2019 at Kaiser Permanente Northern California, were identified. The frequency of first, second, and third intravesical recurrences of urothelial carcinoma were characterized using conditional Kaplan-Meier analyses and random-effects shared-frailty models. The association of multiple recurrences with progression was examined. In 291 patients with IR-NMIBC (median follow-up 38 months), the 5-year risk of initial recurrence was 54.4%. After initial recurrence (n = 137), 60.1% of patients had a second recurrence by 2 years. After second recurrence (n = 70), 51.5% of patients had a third recurrence by 3 years. In multivariable analysis, female sex (Hazard Ratio 1.51, P< .01), increasing tumor size (HR 1.14, P< .01) and number of prior recurrences (HR 1.24, P< .01) were associated with multiple recurrences; whereas maintenance BCG (HR 0.66, P = .03) was associated with reduced recurrences. The 5-year risk of progression varied significantly (P< .01) by number of recurrences: 9.5%, 21.9%, and 37.9% for patients with 1, 2, and 3+ recurrences, respectively. Multiple recurrences are common in IR-NMIBC and are associated with progression. Female sex, larger tumors, number of prior recurrences, and lack of maintenance BCG were associated with multiple recurrences. Multiple recurrences may prove useful as a clinical Mar;173:134-141. Epub 2022-12-24. Maternal SARS-CoV-2 vaccination and infant protection against SARS-CoV-2 during the first six months of life We examined the effectiveness of maternal vaccination against SARS-CoV-2 infection in 30,311 infants born at Kaiser Permanente Northern California from December 15, 2020, to May 31, 2022. Using Cox regression, the effectiveness of 2 doses of COVID-19 vaccine received during pregnancy was 84% (95% confidence interval [CI]: 66, 93), 62% 0-4 and 0- 6 of a child's life, respectively, in the Delta variant period. In the Omicron variant period, the effectiveness of maternal vaccination in these three age intervals was Over the entire study period, the incidence of hospitalization for COVID-19 was lower during the first 6 months of life among infants of vaccinated mothers compared with infants of unvaccinated mothers (21/100,000 person-years vs. 100/100,000 person-years). Maternal vaccination was protective, but protection was lower during Omicron than during Delta. Protection during both periods decreased as infants aged. Authors: Zerbo, 28;14(1):894. Epub 2023-02-28. Protection from COVID-19 mRNA vaccination and prior SARS-CoV-2 infection against COVID-19-associated encounters in adults during Delta and Omicron predominance Data assessing protection conferred from COVID-19 mRNA vaccination and/or prior SARS-CoV-2 infection during Delta and Omicron predominance periods in the U.S. are limited. This cohort study included persons 18 years who had 1 healthcare encounter across four health systems and had been tested for SARS-CoV-2 before August 26, 2021. COVID-19 mRNA vaccination and prior SARS-CoV-2 infection defined the exposure. Cox regression estimated hazard ratios (HRs) for the Delta and Omicron periods; protection was calculated as (1-HR)x100%. Compared to unvaccinated and previously uninfected persons, during Delta predominance, protection against COVID-19-associated hospitalizations was high for those 2- or 3-dose vaccinated and previously infected, 3-dose vaccinated alone, and prior infection alone (range:91%-97%, with overlapping 95% confidence intervals (95%CIs)); during Omicron predominance, estimates were lower (range:77%-90%). Protection against COVID-19-associated emergency department/urgent care (ED/UC) encounters during Delta predominance was high for those exposure groups (range:86%-93%); during Omicron predominance, protection remained high for those 3-dose vaccinated with or without a prior infection (76% (95%CI=67%-83%) and 71% (95%CI=67%-73%), respectively). COVID-19 mRNA vaccination and/or prior SARS-CoV-2 infection provided protection against COVID-19-associated hospitalizations and ED/UC encounters regardless of variant. Staying up-to-date with COVID-19 vaccination still provides protection against severe COVID-19 disease, regardless of prior infection. Authors: Bozio, Catherine H; Fireman, Bruce; Stenehjem, Edward; et al. J Infect Dis. 2023 Feb 18. Sex- and ethnic-specific patterns in the incidence of hip fracture among older US Asian and non-Hispanic White adults Asian and Pacific Islander (Asian/PI) adults have lower hip fracture incidence than non-Hispanic White (NHW) adults, but data regarding Asian/PI subgroups are limited. We compared hip fracture incidence among older US Asian/PI and NHW populations, including ethnic subgroup differences. Using observational data from a California healthcare system, we identified Asian/PI and NHW adults aged 50 years (2000-2019) and followed subjects to 2021 for hip fracture determined by principal/primary hospital diagnosis or by secondary hospital diagnosis with hip/femur procedure codes. Age-adjusted hip fracture incidence was calculated with 95% confidence intervals (CIs). Log-Poisson regression was used to determine fracture incidence rate ratios (IRRs, [CI]; NHW or Chinese as reference) adjusting for age and year. Among 215,359 Asian/PI and 776,839 NHW women, hip fracture incidence was 1.34 (1.28-1.40) and 2.97 (2.94-3.01) per 1000 person-years, 188,328 Asian/PI NHW fracture was 0.62 (0.58-0.67) and (1.78-1.84) per 1000 person-years, respectively, with 0.34 (0.32-0.37). subgroups, 0.85 [0.75-0.96]) had lower, and (IRR 1.36 [1.20-1.54]) and South Asian (IRR 1.36 [1.07-1.72]) women had higher hip fracture incidence compared to Chinese women. Hip fracture incidence was only higher among South Asian (IRR 1.61 [1.21-2.14]) compared to Chinese men. Hip fracture incidence among US Asian/PI adults was 55% (women) and 66% (men) lower than NHW adults, but incidence varied by Asian/PI subgroup. The heterogeneity among Asian/PI adults highlights the importance of examining fracture risk by ethnic subgroup. Authors: Lo, Joan C; Chandra, Malini; Christopher D; Lee, Catherine J Am Geriatr Soc. 2023 Feb 15. Maternal and neonatal outcomes associated with treating hypertension in pregnancy at different thresholds In the United States, there has been controversy over whether treatment of mild-to-moderate hypertension during pregnancy conveys more benefit than risk. The objective of the study was to compare risks and benefits of treatment of mild-to-moderate hypertension during pregnancy. This retrospective cohort study included 11,871 pregnant women with mild-to-moderate hypertension as defined by blood pressure (BP) values from three Kaiser Permanente regions between 2005 and 2014. Data were extracted from electronic health records. Dynamic marginal structural models with inverse probability weighting and informative censoring were used to compare risks of adverse outcomes when beginning antihypertensive medication treatment at four BP thresholds (155/105, 150/100, 145/95, 140/90 mm Hg) compared with the recommended threshold in the United States at that time, 160/110 mm Hg. Outcomes included preeclampsia, preterm birth, small-for-gestational-age (SGA), Neonatal Intensive Care Unit (NICU) care, and stillbirth. Primary analyses allowed 2 weeks for medication initiation after an elevated BP. Several sensitivity and subgroup (i.e., race/ethnicity and pre-pregnancy body mass index) analyses were also conducted. In primary analyses, medication initiation at lower BP thresholds was associated with greater risk of most outcomes. Comparing the lowest (140/90 mm Hg) to the highest BP threshold (160/110 mm Hg), we found an excess risk of preeclampsia (adjusted Risk Difference (aRD) 38.6 per 100 births, 95% Confidence Interval (CI): 30.6, 46.6), SGA (aRD: 10.2 per 100 births, 95% CI: 2.6, 17.8), NICU admission (aRD: 20.2 per 100 births, 95% CI: 12.6, 27.9), and stillbirth (1.18 per 100 births, 95% CI: 0.27, 2.09). The findings did not reach statistical significance for preterm birth (aRD: 2.5 per 100 births, 95% CI: -0.4, 5.3). These relationships were attenuated and did not always reach statistically significance when comparing higher BP treatment thresholds to the highest threshold (i.e., 160/110 mm Hg). Sensitivity and subgroup analyses produced similar results. Initiation of antihypertensive medication at mild-to-moderate BP thresholds (140-155/90-105 mm Hg; with the largest risk consistently associated with treatment at 140/90 mm Hg) may be associated with adverse maternal and neonatal outcomes. Limitations include inability to measure 13. Risk of venous thromboembolism in non-respiratory and respiratory presentations of COVID-19 in critically ill patients Authors: Roubinian, Nareg H; Vinson, Mark, Dustin G; Liu, Vincent X Chest. 2023 Feb 12. Association of the COVID-19 Pandemic With Unstable and/or Unsafe Living Situations and Intimate Partner Violence Among Pregnant Individuals The social, behavioral, and economic consequences of the COVID-19 pandemic may be associated with unstable and/or unsafe living situations and intimate partner violence (IPV) among pregnant individuals. To investigate trends in unstable and/or unsafe living situations and IPV among pregnant individuals prior to and during the COVID-19 pandemic. A cross-sectional population-based interrupted time-series analysis was conducted among Kaiser Permanente Northern California members who were pregnant and screened for unstable and/or unsafe living situation and IPV as part of standard prenatal care between January 1, 2019, and December 31, 2020. COVID-19 pandemic (prepandemic period: January 1, 2019, to March 31, 2020; during pandemic period: April 1 to December 31, 2020). The 2 outcomes were unstable and/or unsafe living situations and IPV. Data were extracted from electronic health records. Interrupted time-series models were fit and adjusted for age and race and ethnicity. The study sample included 77 310 pregnancies (74 663 individuals); 27.4% of the individuals were Asian or Pacific Islander, 6.5% were Black, 29.0% were Hispanic, 32.3% were non-Hispanic White, and 4.8% were other/unknown/multiracial, with a mean (SD) age of 30.9 (5.3) years. Across the 24-month study period there was an increasing trend in the standardized rate of unsafe and/or unstable living situations (2.2%; rate ratio [RR], 1.022; 95% 1.049; 95% CI, 1.021-1.078 per month). The ITS model indicated a 38% increase (RR, 1.38; 95% CI, 1.13-1.69) in the first month of the pandemic for unsafe and/or unstable living situation, with a return to the overall trend afterward for the study period. For IPV, the interrupted time-series model suggested an increase of 101% (RR, 2.01; 95% CI, 1.20-3.37) in the first 2 months of the pandemic. This cross-sectional study noted an overall increase in unstable and/or unsafe living situations and IPV over the 24-month period, with a temporary increase associated with the COVID-19 pandemic. It may be useful for emergency response plans to include IPV safeguards for future pandemics. These findings suggest the need for prenatal screening for unsafe and/or unstable living situations and IPV coupled with referral to appropriate support services and preventive interventions. Authors: Avalos, Lyndsay A; Ray, Feb 01;6(2):e230172. Epub 2023-02-01. Association of Long-term Exposure to Particulate Air Pollution With Cardiovascular Events in California Long-term exposure to fine particulate air pollution (PM2.5) is a known risk factor for cardiovascular events, but controversy remains as to whether the current National Ambient Air Quality Standard (12 g/m3 for 1-year mean PM2.5) is sufficiently protective. To evaluate the associations between long-term fine particulate air pollution and cardiovascular events using electronic health record and geocoded address data. This retrospective cohort study included adults in the Kaiser Permanente Northern California integrated health care system during 2007 to 2016 and followed for up to 10 years. Study participants had no prior stroke or acute myocardial infarction (AMI), and lived in Northern California for at least 1 year. Analyses were conducted January 2020 to December 2022. Long-term exposure to PM2.5. Individual-level time-varying 1-year mean PM2.5 exposures for every study participant were updated monthly from baseline through the end of follow-up, accounting for address changes. Incident AMI, ischemic heart disease (IHD) mortality, and cardiovascular disease (CVD) mortality. Cox proportional hazards models were fit with age as time scale, adjusted for sex, race and ethnicity, socioeconomic status, smoking, body mass index, baseline comorbidities, and baseline medication use. Associations below the current regulation limit were also examined. The study cohort included 3.7 million adults (mean [SD] age: 41.1 [17.2] years; 1 992 058 [52.5%] [0.5%] American Indian or Alaskan Native, 714 043 [18.8%] Asian, 287 980 [7.6%] Black, 696 796 [18.4%] Hispanic, 174 261 [4.6%] multiracial, 1 904 793 [50.2%] White). There was a 12% (95% CI, 7%-18%) increased risk of incident AMI, a 21% (95% CI, 13%-30%) increased risk of IHD mortality, and an 8% (95% CI, 3%-13%) increased risk of CVD mortality associated with a 10 g/m3 increase in 1-year mean PM2.5. PM2.5 exposure at moderate concentrations (10.0 to 11.9 g/m3) was associated with increased risks of incident AMI (6% [95% CI, 3%-10%]) and IHD mortality (7% [95% CI, 2%-12%]) compared with low concentrations (less than 8 g/m3). In this study, long-term PM2.5 exposure at moderate concentrations was associated with increased risks of incident AMI, IHD mortality, and CVD mortality. This study's findings add to the evidence that the current regulatory standard is not sufficiently protective. Authors: Alexeeff, Stacey E; 2023-02-01. High-dimensional propensity scores for empirical covariate selection in secondary database studies: Planning, implementation, and reporting Real-world evidence used for regulatory, payer, and clinical decision-making requires principled epidemiology in design and analysis, applying methods to minimize confounding given the lack of randomization. One technique to deal with potential confounding is propensity score (PS) analysis, which allows for the adjustment for measured preexposure covariates. Since its first publication in 2009, the high-dimensional propensity score (hdPS) method has emerged as an approach that extends traditional PS covariate selection to include large numbers of covariates that may reduce confounding bias in the analysis of healthcare databases. hdPS is an automated, data-driven analytic approach for covariate selection that empirically identifies preexposure variables and proxies to include in the PS model. This article provides an overview of the hdPS approach and recommendations on the planning, implementation, and reporting of hdPS used for causal treatment-effect estimations in longitudinal healthcare databases. We supply a checklist with key considerations as a supportive decision tool to aid investigators in the implementation and transparent reporting of hdPS techniques, and to aid decision-makers unfamiliar with hdPS in the understanding and interpretation of studies employing this approach. This article is endorsed by the International Society for 2022-11-22. Association of cannabis use during pregnancy with severe acute respiratory syndrome coronavirus 2 infection: a retrospective cohort study Cannabis use is increasingly common among pregnant individuals and might be a risk factor for severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection. We aimed to test whether prenatal cannabis use is associated with increased risk of SARS-CoV-2 infection during pregnancy. This is a retrospective cohort study. The study was conducted in California, USA. A total of 58?114 pregnancies (with outcomes from 5 March 2020 to 30 September 2021) among 57?287 unique pregnant women aged 14-54?years who were screened for prenatal substance use, enrolled in Kaiser Permanente Northern California (KPNC) (a health-care system) and had not tested positive for COVID-19 prior to pregnancy onset. We utilized data from the KPNC electronic health record. Cannabis use status (current, recently quit and non-user) was based on universal screenings during prenatal care (including urine toxicology testing and self-reported use on a self-administered questionnaire). SARS-CoV-2 infection [based on polymerase chain reaction (PCR) tests] was estimated in time-to-event analyses using Cox proportional hazard regression models adjusting for covariates. Secondary analyses examined differences in (a) SARS-CoV-2 testing rates and (b) SARS-CoV-2 infection rates among those tested. We observed 348?810 person-months of follow-up time in our cohort with 41?064 SARS-CoV-2 PCR tests and 6% (n?=?2414) of tests being positive. At the start of follow-up, 7% of pregnant individuals had current use, 12% had recently quit and 81% did not use cannabis. Adjusting for covariates, current use was associated with lower rates of SARS-CoV-2 infection [adjusted hazard ratio (aHR)?=?0.60, 95% confidence interval (CI)?=?0.49-0.74 than non-use. Those who had recently quit did not differ from non-cannabis users in infection rates (aHR?=?0.96, 95% CI?=?0.86-1.08). Sensitivity analyses among patients who received a SARS-CoV-2 test also found lower odds of infection associated with current versus no cannabis use (aOR?=?0.76, CI?=?0.61-0.93). Current cannabis use appears to be associated with a reduced risk of SARS-CoV-2 infection among pregnant individuals. Authors: Young-Wolff, Epub 2022-10-12. A prospective study of lifestyle factors and bone health in breast cancer patients who received aromatase inhibitors in an integrated healthcare setting Fracture and osteoporosis are known side effects of aromatase inhibitors (AIs) for postmenopausal hormone receptor positive (HR+) breast cancer (BC) patients. How modifiable lifestyle factors impact fracture risk in these patients is relatively unknown. We conducted a prospective cohort study to examine the association of lifestyle factors, focusing on physical activity, with risk of incident major osteoporotic fracture and osteoporosis in 2152 HR+ BC patients diagnosed from 2006 to 2013 at Kaiser Permanente Northern California and who received AIs. Patients self-reported lifestyle factors at study entry and at 6-month follow-up. Fracture and osteoporosis outcomes were prospectively ascertained by physician-adjudication and bone mineral density (BMD) values, respectively. Hazard ratios (HRs) and 95% confidence intervals (CIs) were calculated from multivariable proportional hazards regression. Models were adjusted for age, menopausal status, race/ethnicity, body mass index (BMI), AJCC stage, breast cancer treatment, prior osteoporosis, and prior major fracture. Over a median 6.1 years of follow-up after AI initiation, 165 women experienced an incident osteoporotic fracture and 243 women had osteoporosis. No associations were found between overall moderate-vigorous physical activity and fracture risk, although < 150 min/week of aerobic exercise in the 6 months after BC diagnosis was associated with increased fracture risk (HR=2.42; 95% CI: 1.34, 4.37) compared with 150 min/week (meeting physical activity guidelines). Risk was also higher for never or infrequently engaging in aerobic exercise (HR=1.90; 95% CI: 1.05, 3.44). None or infrequent overall moderate-vigorous physical activity in the 6 months before BC diagnosis was associated with increased risk of osteoporosis (HR=1.94; 95% CI: 1.11; 3.37). Moderate-vigorous physical activity during the immediate period after BC diagnosis, particularly aerobic exercise, was associated with lower risk of major osteoporotic fractures in women on AI therapy. Findings may inform fracture prevention in women on AI therapy through non-pharmacologic lifestyle-based strategies. Authors: Kwan, Marilyn 2023 Feb;17(1):139-149. Epub 2021-02-09. Vaccine effectiveness against influenza-associated urgent care, emergency department, and hospital encounters during the 2021-2022 season, VISION Network Following historically low influenza activity during the 2020-2021 season, the United States saw an increase in influenza circulating during the 2021-2022 season. Most viruses belonged to the influenza A(H3N2) 3C.2a1b 2a.2 subclade. We conducted a test-negative case-control analysis among adults 18 years of age at three sites within the VISION Network. Encounters included emergency department/urgent care (ED/UC) visits or hospitalizations with 1 acute respiratory illness (ARI) discharge diagnosis codes and molecular testing for influenza. Vaccine effectiveness (VE) was calculated by comparing the odds of influenza vaccination 14 days before the encounter date between influenza-positive cases (type A) and influenza-negative and SARS-CoV-2-negative controls, applying inverse probability-to-be-vaccinated weights, [4%] included. VE influenza-associated hospitalizations. VE against ED/UC encounters was lower in adults 65 years of age (7%; CI: -5-17%) or with immunocompromising conditions (4%, CI:-45-36%). During an influenza A(H3N2)-predominant influenza season, modest VE was observed. These findings highlight the need for improved vaccines, particularly for A(H3N2) viruses that are historically associated with lower VE. al. J Infect Dis. 2023 Jan 23. MiXcan: a framework for cell-type-aware transcriptome-wide association studies with an application to breast cancer Human bulk tissue samples comprise multiple cell types with diverse roles in disease etiology. Conventional transcriptome-wide association study approaches predict genetically regulated gene expression at the tissue level, without considering cell-type heterogeneity, and test associations of predicted tissue-level expression with disease. Here we develop MiXcan, a cell-type-aware transcriptome-wide association study approach that predicts cell-type-level expression, identifies disease-associated genes via combination of cell-type-level association signals for multiple cell types, and provides insight into the disease-critical cell type. As a proof of concept, we conducted cell-type-aware analyses of breast cancer in 58,648 women and identified 12 transcriptome-wide significant genes using MiXcan compared with only eight genes using conventional approaches. Importantly, MiXcan identified genes with distinct associations in mammary epithelial versus stromal cells, including three new breast cancer susceptibility genes. These findings demonstrate that cell-type-aware transcriptome-wide analyses can reveal new insights into the genetic and cellular etiology of breast cancer and other diseases. Authors: Song, Jan 23;14(1):377. Epub 2023-01-23. A broad assessment of covid-19 vaccine safety using tree-based data-mining in the vaccine safety datalink Except for spontaneous reporting systems, vaccine safety monitoring generally involves pre-specifying health outcomes and post-vaccination risk windows of concern. Instead, we used tree-based data-mining to look more broadly for possible adverse events after Pfizer-BioNTech, Moderna, and Janssen COVID-19 vaccination. Vaccine Safety Datalink enrollees receiving 1 dose of COVID-19 vaccine in 2020-2021 were followed for 70 days after Pfizer-BioNTech or Moderna and 56 days after Janssen vaccination. Incident diagnoses in inpatient or emergency department settings were analyzed for clustering within both the hierarchical ICD-10-CM code structure and the post-vaccination follow-up period. We used the self-controlled tree-temporal scan statistic and TreeScan software. Monte Carlo simulation was used to estimate p-values; p = 0.01 was the pre-specified cut-off for statistical significance of a cluster. There were 4.1, 2.6, and 0.4 million Pfizer-BioNTech, Moderna, and Janssen vaccinees, respectively. Clusters after Pfizer-BioNTech vaccination included: (1) unspecified adverse effects, (2) common vaccine reactions, such as fever, myalgia, and headache, (3) myocarditis/pericarditis, and (4) less specific cardiac or respiratory symptoms, all with the strongest clusters generally after Dose 2; and (5) COVID-19/viral pneumonia/sepsis/respiratory failure in the first 3 weeks after Dose 1. Moderna results were similar but without a significant myocarditis/pericarditis cluster. Further investigation suggested the fifth signal group was a manifestation of mRNA vaccine effectiveness after the first 3 weeks. Janssen vaccinees had clusters of unspecified or common vaccine reactions, gait/mobility abnormalities, and muscle weakness. The latter two were deemed to have arisen from confounding related to practices at one site. We detected post-vaccination clusters of unspecified adverse effects, common vaccine reactions, and, for the mRNA vaccines, chest pain and palpitations, as well as myocarditis/pericarditis after Pfizer-BioNTech Dose 2. Unique advantages of this data mining are its untargeted nature and its inherent adjustment for the multiplicity of diagnoses and risk intervals scanned. Authors: Yih, W Katherine; Fireman, Bruce; Maro, Vaccine. 2023 Jan 16;41(3):826-835. Epub 2022-12-16. A safety study evaluating non-COVID-19 mortality risk following COVID-19 vaccination The safety of COVID-19 vaccines plays an important role in addressing vaccine hesitancy. We conducted a large cohort study to evaluate the risk of non-COVID-19 mortality after COVID-19 vaccination while adjusting for confounders including individual-level demographics, clinical risk factors, health care utilization, and community-level socioeconomic risk factors. The retrospective cohort study consisted of members from seven Vaccine Safety Datalink sites from December 14, 2020 through August 31, 2021. We conducted three separate analyses for each of the three COVID-19 vaccines used in the US. Crude non-COVID-19 mortality rates were reported by vaccine type, age, sex, and race/ethnicity. The counting process model for survival analyses was used to analyze non-COVID-19 mortality where a new observation period began when the vaccination status changed upon receipt of the first dose and the second dose. We used calendar time as the basic time scale in survival analyses to implicitly adjust for season and other temporal trend factors. A propensity score approach was used to adjust for the potential imbalance in confounders between the vaccinated and comparison groups. For each vaccine type and across age, sex, and race/ethnicity groups, crude non-COVID-19 mortality rates among COVID-19 vaccinees were lower than those among comparators. After adjusting for confounders with the propensity score approach, the adjusted hazard ratios (aHRs) were 0.46 (95% confidence interval [CI], 0.44-0.49) after dose 1 and 0.48 (95% CI, 0.46-0.50) after dose 2 of the BNT162b2 vaccine, 0.41 (95% CI, 0.39-0.44) after dose 1 and 0.38 (95% CI, 0.37-0.40) after dose 2 of the mRNA-1273 vaccine, and 0.55 (95% CI, 0.51-0.59) after receipt of Ad26.COV2.S. While residual confounding bias remained after adjusting for several individual-level and community-level risk factors, no increased risk was found for non-COVID-19 mortality among recipients of three COVID-19 vaccines used in the US. Authors: Xu, Stanley; Klein, Nicola P; Fireman, Bruce; al. Vaccine. 2023 Jan 16;41(3):844-854. Epub 2022-12-20. A mid-level health manager intervention to promote uptake of isoniazid preventive therapy among people with HIV in Uganda: a cluster randomised trial. BACKGROUND: Despite longstanding guidelines endorsing isoniazid preventive therapy (IPT) for people with HIV, uptake is low across sub-Saharan Africa. Mid-level health managers oversee IPT programmes nationally; interventions aimed at this group have not been tested. We aimed to establish whether providing structured leadership and management training and facilitating subregional collaboration and routine data feedback to mid-level managers could increase IPT initiation among people with HIV compared with standard practice. METHODS: We conducted a cluster randomised trial in Uganda among district-level health managers. We randomly assigned clusters of between four and seven managers in a 1:1 ratio to intervention or control groups. Our intervention convened managers into mini-collaboratives facilitated by Ugandan experts in tuberculosis and HIV, and provided business leadership and management training, SMS platform access, and data feedback. The control was standard practice. Participants were not masked to trial group, but study statisticians were masked until trial completion. The primary outcome was IPT initiation rates among adults with HIV in facilities overseen by participants over a period of 2 years (2019-21). We conducted prespecified analyses that excluded the third quarter of 2019 (Q3-2019) to understand intervention effects independent of a national 100-day IPT push tied to a financial contingency during Q3-2019. This trial is registered with ClinicalTrials.gov (NCT03315962), and is ongoing. FINDINGS: Between Nov 15, 2017, and March 14, 2018, managers from 82 of 82 eligible districts (61% of Uganda's 135 districts) were enrolled and randomised: 43 districts to intervention, 39 to control. Intervention delivery took place between Dec 6, 2017, and Feb 2, 2022. Over 2 years, IPT initiation rates were 0.74 versus 0.65 starts per person-year in intervention versus control groups (incidence rate ratio [IRR] 1.14, 95% CI 0.88-1.46; p=0.16). Excluding Q3-2019, IPT initiation was higher in the intervention group versus the control group: 0.32 versus 0.25 starts per person-year (IRR 1.27, 95% CI 1.00-1.61; p=0.026). INTERPRETATION: Following an intervention targeting managers in more than 60% of Uganda's districts, IPT initiation rates were not significantly higher in intervention than control groups. After accounting for large increases in IPT from a 100-day push in both groups, the intervention led to significantly increased IPT rates, sustained after the push and during the COVID-19 pandemic. Our findings suggest that interventions centred on mid-level health managers can improve IPT implementation on a large, subnational scale, and merit further exploration to address key public health challenges for which strong evidence exists but implementation remains suboptimal. FUNDING: National Institute of Allergy and Infectious 28. HIV incidence after pre-exposure prophylaxis initiation among women and men at elevated HIV risk: A population-based study in rural Kenya and Uganda. BACKGROUND: Oral pre-exposure prophylaxis (PrEP) is highly effective for HIV prevention, but data are limited on HIV incidence among PrEP users in generalized epidemic settings, particularly outside of selected risk groups. We performed a population-based PrEP study in rural Kenya and Uganda and sought to evaluate both changes in HIV incidence and clinical and virologic outcomes following seroconversion on PrEP. METHODS AND FINDINGS: During population-level HIV testing of individuals >/=15 years in 16 communities in the Sustainable East Africa Research in Community Health (SEARCH) study (NCT01864603), we offered universal access to PrEP with enhanced counseling for persons at elevated HIV risk (based on serodifferent partnership, machine learning-based risk score, or self-identified HIV risk). We offered rapid or same-day PrEP initiation and flexible service delivery with follow-up visits at facilities or community-based sites at 4, 12, and every 12 weeks up to week 144. Among participants with incident HIV infection after PrEP initiation, we offered same-day antiretroviral therapy (ART) initiation and analyzed HIV RNA, tenofovir hair concentrations, drug resistance, and viral suppression (<1,000 c/ml based on available assays) after ART start. Using Poisson regression with cluster-robust standard errors, we compared HIV incidence among PrEP initiators to incidence among propensity score-matched recent historical controls (from the year before PrEP availability) in 8 of the 16 communities, adjusted for risk group. Among 74,541 individuals who tested negative for HIV, 15,632/74,541 (21%) were assessed to be at visit Over 7,150 person-years follow-up, HIV incidence was 0.35 per (95% confidence interval [CI] 0.22-0.49) among PrEP initiators. Among controls, HIV incidence was 0.92 per 100 person-years (95% CI 0.49-1.41), corresponding to 74% lower incidence among PrEP initiators compared to matched controls (adjusted incidence rate ratio [aIRR] 0.26, 95% CI 0.09-0.75; p = 0.013). Among women, HIV incidence was 76% lower among PrEP initiators versus matched controls (aIRR 0.24, 95% CI 0.07-0.79; p = 0.019); among men, HIV incidence was 40% lower, but not significantly so (aIRR 0.60, 95% CI 0.12-3.05; p = 0.54). Of 25 participants with incident HIV infection (68% women), 7/25 (28%) reported taking PrEP =30 days before HIV diagnosis, and 24/25 (96%) started ART. Of those with repeat HIV RNA after ART start, 18/19 (95%) had <1,000 c/ml. One participant with viral non-suppression was found to have transmitted viral resistance, as well as emtricitabine resistance possibly related to PrEP use. Limitations include the lack of contemporaneous controls to assess HIV incidence without PrEP and that plasma samples were not archived to assess for baseline acute infection. CONCLUSIONS: Population-level offer of PrEP with rapid start and flexible service delivery was associated with 74% lower HIV incidence among PrEP initiators compared to matched recent controls prior to PrEP availability. HIV infections were significantly lower among women who started PrEP. Universal HIV testing with linkage to treatment and prevention, including PrEP, is a promising approach to accelerate reductions in new infections in generalized epidemic settings. TRIAL REGISTRATION: 2021 Feb. Type I error control for cluster randomized trials under varying small sample structures. BACKGROUND: Linear mixed models (LMM) are a common approach to analyzing data from cluster randomized trials (CRTs). Inference on parameters can be performed via Wald tests or likelihood ratio tests (LRT), but both approaches may give incorrect Type I error rates in common finite sample settings. The impact of different combinations of cluster size, number of clusters, intraclass correlation coefficient (ICC), and analysis approach on Type I error rates has not been well studied. Reviews of published CRTs find that small sample sizes are not uncommon, so the performance of different inferential approaches in these settings can guide data analysts to the best choices. METHODS: Using a random-intercept LMM stucture, we use simulations to study Type I error rates with the LRT and Wald test with different degrees of freedom (DF) choices across different combinations of cluster size, number of clusters, and ICC. RESULTS: Our simulations show that the LRT can be anti-conservative when the ICC is large and the number of clusters is small, with the effect most pronouced when the cluster size is relatively large. Wald tests with the between-within DF method or the Satterthwaite DF approximation maintain Type I error control at the stated level, though they are conservative when the number of clusters, the cluster size, and the ICC are small. CONCLUSIONS: Depending on the structure of the CRT, analysts should choose a hypothesis testing approach that will maintain the appropriate Type I error rate for their data. Wald tests with the Satterthwaite DF approximation work well in many circumstances, but in other cases the LRT may have Type I error rates closer to the nominal level. Authors: Nugent, Joshua R; Kleinman, Ken P BMC Med in patients with COVID-19 varies by SARS-CoV-2 period and vaccination status P Blood Adv. 2023 Jan 10;7(1):141-144. Tree-based data mining for safety assessment of first COVID-19 booster doses in the Vaccine Safety Datalink The Centers for Disease Control and Prevention's Vaccine Safety Datalink (VSD) has been performing safety surveillance for COVID-19 vaccines since their earliest authorization in the United States. Complementing its real-time surveillance for pre-specified health outcomes using pre-specified risk intervals, the VSD conducts tree-based data-mining to look for clustering of a broad range of health outcomes after COVID-19 vaccination. This study's objective was to use this untargeted, hypothesis-generating approach to assess the safety of first booster doses of Pfizer-BioNTech (BNT162b2), Moderna (mRNA-1273), and Janssen (Ad26.COV2.S) COVID-19 vaccines. VSD enrollees receiving a first booster of COVID-19 vaccine through April 2, 2022 were followed for 56 days. Incident diagnoses in inpatient or emergency department settings were analyzed for clustering within both the hierarchical ICD-10-CM code structure and the follow-up period. The self-controlled tree-temporal scan statistic was used, conditioning on the total number of cases for each diagnosis. P-values were estimated by Monte Carlo simulation; p = 0.01 was pre-specified as the cut-off for statistical significance of clusters. More than 2.4 and 1.8 million subjects received Pfizer-BioNTech and Moderna boosters after an mRNA primary series, respectively. Clusters of urticaria/allergy/rash were found during Days 10-15 after the Moderna booster (p = 0.0001). Other outcomes that clustered after mRNA boosters, mostly with p = 0.0001, included unspecified adverse effects, common vaccine-associated reactions like fever and myalgia, and COVID-19. COVID-19 clusters were in Days 1-10 after booster receipt, before boosters would have become effective. There were no noteworthy clusters after boosters following primary Janssen vaccination. In this untargeted data-mining study of COVID-19 booster vaccination, a cluster of delayed-onset urticaria/allergy/rash was detected after the Moderna booster, as has been reported after Moderna vaccination previously. Other clusters after mRNA boosters were of unspecified or common adverse effects and COVID-19, the latter evidently reflecting immunity to COVID-19 after 10 days. Authors: Katherine Yih, W; Fireman, Bruce; Maro, Vaccine. 2023 Jan 09;41(2):460-466. Epub 2022-11-24. Cigarette Smoking and Risk of SARS-CoV-2 infection and Disease Severity Among Adults in an Integrated Health Care System in California The relationship between tobacco smoking status and SARS-CoV-2 infection and coronavirus disease 2019 (COVID-19) severity is highly debated. We conducted a retrospective cohort study of?>2.4 million adults in a large healthcare system to evaluate whether smoking is associated with SARS-CoV-2 infection and disease severity. This retrospective cohort study of 2,427,293 adults in KPNC from March 5, 2020 (baseline) to December 31, 2020 (pre-vaccine) included smoking status (current, former, never), socio-demographics, and comorbidities from the electronic health record. SARS-CoV-2 infection (identified by a positive PCR test) and COVID-19 severity (hospitalization, ICU admission or death???30 days of COVID-19 diagnosis) were estimated in time-to-event analyses using Cox proportional hazard regression models adjusting for covariates. Secondary analyses examined COVID-19 severity among patients with COVID-19 using logistic regression. During the study, 44,270 patients had SARS-CoV-2 infection. Current smoking was associated with lower adjusted rates of SARS-CoV-2 never-smoking. Former smoking was associated with a lower adjusted rate of SARS-CoV-2 infection (aHR?=?0.96 95% CI: 0.94-0.99) never-smoking. Logistic regression analyses among patients with COVID-19 found lower odds of hospitalization for current versus never-smoking and higher odds of hospitalization and death for former versus never-smoking. In the largest US study to date on smoking and COVID-19, current and former smoking showed lower risk of SARS-CoV-2 infection than never-smoking, while a history of smoking was associated with higher risk of severe COVID-19. In this cohort study of 2.4 million adults, adjusting for socio-demographics and medical comorbidities, current tobacco smoking was associated with a lower risk of both SARS-CoV-2 infection and severe COVID-19 illness compared to never-smoking. A history of smoking was associated with a slightly lower risk of SARS-CoV-2 infection and a modestly higher risk of severe COVID-19 illness compared to never-smoking. The lower observed COVID-19 risk for current versus never-smoking deserves further investigation. Results support prioritizing individuals with smoking-related comorbidities for vaccine outreach and treatments as they become Young-Wolff, Adams, Alyce S; Prochaska, Judith J Nicotine Tob Res. 2023 Jan 05;25(2):211-220. Pregnancy post-bariatric surgery: Improved outcomes with telephonic nutritional management program Pregnancies post-bariatric surgery are increasingly common. It is important to understand how to manage prenatal care in this high-risk population to optimize perinatal outcomes. To determine among pregnancies post-bariatric surgery whether participation in a telephonic nutritional management program was associated with improved perinatal outcomes and nutritional adequacy. Retrospective cohort study of pregnancies post-bariatric surgery from 2012 to 2018. Participation in a telephonic management program with nutritional counseling, monitoring and nutritional supplement adjustment. Modified Poisson Regression estimated the relative risk using propensity score methods to account for baseline differences between the patients who participated in the program and patients who did not. 1575 pregnancies occurred post-bariatric surgery, of which 1142 (72.5 % of pregnancies) participated in the telephonic nutritional management program. Participants in the program were less likely than non-participants to have a preterm birth (aRR 0.48, 95 % CI 0.35-0.67), preeclampsia (aRR 0.43, 95 % CI (0.27-0.69)), gestational hypertension (aRR 0.62, 95 % CI 0.41-0.93), and to have neonates admitted to a Level 2 or 3 (aRR 0.61, 95 % CI0.39-0.94; aRR 0.66, 95 % CI 0.45-0.97, respectively), after adjusting for the propensity score to account for baseline differences. Risk of cesarean delivery, gestational weight gain, glucose intolerance and birthweight did not differ by participation. Among 593 pregnancies with nutritional labs available, participants in the telephonic program were less likely to have nutritional inadequacy in late pregnancy (aRR 0.91, 95 % CI 0.88-0.94). Participation in a telephonic nutritional management program post-bariatric surgery was associated with improved perinatal outcomes and Association between anaemia and hospital readmissions in patients undergoing major surgery requiring postoperative intensive care Anaemia is a common sequela of surgery, although its relationship with patient recovery is unclear. The goal of this investigation was to assess the associations between haemoglobin concentrations at the time of hospital discharge following major surgery and early post-hospitalisation outcomes, with a primary outcome of 30 day unanticipated hospital readmissions. This investigation includes data from two independent population-based observational cohorts of adult surgical patients (aged 18 years) requiring postoperative intensive care unit admission between 1 January 2010 and 31 December 2019 in hospitals in Olmsted County, Minnesota, and between 1 July 2010 and 30 June 2017 in the Kaiser Permanente Northern California integrated healthcare system, California. Cox proportional hazards models assessed the associations between discharge haemoglobin concentrations (per 10 g.l-1 ) and outcomes, with prespecified multivariable adjustment. A total of 3260 patients were included from Olmsted County hospitals and 29,452 from Kaiser Permanente Northern California. In adjusted analyses, each 10 g.l-1 decrease in haemoglobin at hospital discharge was associated with a 9% (hazard ratio 1.09, 95%CI 1.02-1.18; p = 0.014) and 8% increase (hazard ratio 1.08, 95%CI 1.06-1.11; p < 0.001) in the hazard for readmission within 30 days in Olmsted County and Kaiser Permanente Northern California, respectively. In a sensitivity analysis exploring relationships across varying levels of pre-operative anaemia severity, these associations remained consistent, with lower discharge haemoglobin concentrations associated with higher readmissions irrespective of pre-operative anaemia severity. Anaemia at hospital discharge in surgical patients requiring postoperative intensive care is associated with increased rates of hospital readmission in two large independent cohorts. Future studies are necessary to evaluate strategies to prevent and/or treat anaemia in these patients for the improvement of post-hospitalisation outcomes. Authors: Warner, M A; Hanson, A 2022-09-08. Predicting Post-Sepsis Cardiovascular Events with Death as a Competing Risk Authors: Myers, Laura C; Lee, Catherine; Go, Alan S; Liu, Vincent X; Walkey, Allan J; et al. Ann Am Thorac Soc. 2023 Jan;20(1):145-148. Survival Associated With Consolidated Multidisciplinary Care in Head and Neck Cancer: A Retrospective Cohort Study To compare survival among patients with head and neck cancer before and after implementing a weekly multidisciplinary clinic and case conference. A retrospective cohort study with chart review was conducted of 3081 patients (1431 preimplementation, 1650 postimplementation) diagnosed with cavity, oropharynx, hypopharynx, nasopharynx, or larynx. Pre- and postimplementation differences in overall and disease-specific survival 1, 2, and 3 years after diagnosis were assessed with unadjusted Kaplan-Meier curves and multivariable Cox proportional hazard regression models adjusted for demographic characteristics, comorbidity burden, smoking status, tumor site and stage, p16 status for oropharyngeal squamous cell cancer, and initial treatment modality. Patients less commonly presented with oropharyngeal squamous cell cancer and advanced tumors (III-IVB) and received primary treatment with surgery alone or with adjuvant therapy preimplementation than postimplementation. Overall survival at 3 years was 77.1% and 79.9% (P = .07) and disease-specific survival was 84.9% and 87.5% (P = .05) among pre- and postimplementation patients, respectively. At 3 years, preimplementation patients had slightly poorer overall (hazard ratio, 1.20; 95% CI, 1.02-1.40) and disease-specific (hazard ratio, 1.26; 95% CI, 1.03-1.54) adjusted survival than postimplementation patients. In unadjusted and adjusted analyses, survival improvements were more pronounced among patients with advanced disease. A multidisciplinary clinic and case conference were associated with improved outcomes among patients with head and neck cancer, especially those with advanced tumors. All patients with head and neck cancer should receive multidisciplinary team management, especially those with advanced tumors. Authors: Surg. 2023 Jan;168(1):82-90. Early Estimates of Bivalent mRNA Vaccine Effectiveness in Preventing COVID-19-Associated Emergency Department or Urgent Care Encounters and Hospitalizations Among Immunocompetent Adults - VISION Network, Nine States, 2022, the most of the sequenced viral genomes in the United States, with further Omicron sublineage diversification through November 2022.* Bivalent mRNA vaccines contain an ancestral SARS-CoV-2 strain component plus an updated component of the Omicron BA.4/BA.5 sublineages. On September 1, 2022, a single bivalent booster dose was recommended for adults who had completed a primary vaccination series (with or without subsequent booster doses), with the last dose administered 2 months earlier (1). During September 13-November 18, the VISION Network evaluated vaccine effectiveness (VE) of a bivalent mRNA booster dose (after 2, 3, or 4 monovalent doses) compared with 1) no previous vaccination and 2) previous receipt of 2, 3, or 4 monovalent-only mRNA vaccine doses, among immunocompetent adults aged 18 years with an emergency department/urgent care (ED/UC) encounter or hospitalization for a COVID-19-like illness. VE of a bivalent booster dose (after 2, 3, or 4 monovalent doses) against COVID-19-associated ED/UC encounters was 56% compared with no vaccination, 31% compared with monovalent vaccination only with last dose 2-4 months earlier, and 50% compared with monovalent vaccination only with last dose 11 months earlier. VE of a bivalent booster dose (after 2, 3, or 4 monovalent doses) against COVID-19-associated hospitalizations was 57% compared with no vaccination, 38% compared with monovalent vaccination only with last dose 5-7 months earlier, and 45% compared with monovalent vaccination only with last dose 11 months earlier. Bivalent vaccines administered after 2, 3, or 4 monovalent doses were effective in preventing medically attended COVID-19 compared with no vaccination and provided additional protection compared with past monovalent vaccination only, with relative protection increasing with time since receipt of the last monovalent dose. All eligible persons should stay up to date with recommended COVID-19 vaccinations, including receiving a bivalent booster dose. Persons should also consider taking additional precautions to avoid respiratory illness this winter season, such as masking in public indoor spaces, especially in areas where COVID-19 community levels are high. Authors: abnormalities and survival among patients with non-metastatic breast cancer Research on the impact of metabolic abnormalities on breast cancer prognosis is limited by small samples and assessment of laboratory values at a single time point, often prior to cancer diagnosis and treatment. In this population-based cohort, time-updated laboratory values were adjusted for cancer treatment to assess the association between metabolic risk factors (glucose, high-density lipoprotein cholesterol (HDL-C), low-density lipoprotein cholesterol (LDL-C), triglycerides) and breast cancer survival. 13,434 women diagnosed with stage I-III breast cancer from 2005-15 at Kaiser Permanente were included. All outpatient fasting glucose, HDL-C, LDL-C, and triglyceride values from diagnosis through 2019 or death were extracted from electronic medical records. Risk of breast cancer-specific mortality was evaluated with Cox proportional hazards models adjusted for metabolic labs, demographics, body mass index, diabetes, dyslipidemia and anti-hypertensive medications, tumor characteristics (stage, ER and HER2 receptor status) and cancer treatment (use of chemotherapy, tamoxifen, and aromatase inhibitors). Mean (SD) age at diagnosis was 62.3 (11.8) years. Over a median follow-up of 8.6 years, 2,876 patients died; 1,080 of breast cancer. Patients with low HDL-C ( 45 vs. > 45 mg/dL) had higher breast cancer-specific mortality (HR, 1.77; 95% CI, 1.53-2.05), as did those with elevated fasting glucose (> 99 vs. 60-99 mg/dL) (HR, 1.19; 95% CI, 1.03-1.37). Elevated levels of triglycerides and LDL-C were not associated with breast cancer-specific mortality. High fasting glucose and low HDL-C evaluated over time after cancer diagnosis were associated with higher breast cancer mortality independent of cancer treatments and changes in other metabolic risk factors. Future studies should address whether pharmacologic or lifestyle treatment of glucose and lipids after breast cancer diagnosis can optimize survival outcomes. Authors: Zimbalist, Alexa S; Caan, Bette J; in Self-reported and Biochemically Verified Cocaine and Methamphetamine Use Among Pregnant Individuals in Northern California, 2011-2019 This cross-sectional study uses data from the Kaiser Permanente Northern California health care system with universal screening via self-report and urine toxicology at prenatal care entrance to examine trends in cocaine and methamphetamine use among pregnant individuals from 2011 to 2019. High-sensitivity troponin I is associated with cardiovascular outcomes but not with breast arterial calcification among postmenopausal women Prior studies support the utility of high sensitivity troponin I (hsTnI) for cardiovascular disease (CVD) risk stratification among asymptomatic populations; however, only two prior studies examined women separately. The association between hsTnI and breast arterial calcification is unknown. Cohort study of 2896 women aged 60-79 years recruited after attending mammography screening between 10/2012 and 2/2015. BAC status (presence versus absence) and quantity (calcium mass mg) was determined using digital mammograms. Pre-specified endpoints were incident coronary heart disease (CHD), ischemic stroke, heart failure and its subtypes and all CVD. After 7.4 (SD = 1.7) years of follow-up, 51 CHD, 30 ischemic stroke and 46 heart failure events were ascertained. At a limit of detection of 1.6 ng/L, 98.3 of the cohort had measurable hsTnI concentration. HsTnI in the 4-10 ng/L range were independently associated of CHD (adjusted hazard ratio[aHR] = 2.78; 95% CI, 1.48-5.22; p = 2.06; 95% CI, 1.37-3.09; p = 0.0005) and hsTnI over 10 ng/L was independently associated with CHD (aHR = 4.75; 95% CI, 1.83-12.3; p = 0.001), ischemic stroke (aHR = 3.81; 95% CI, 1.22-11.9; p = 0.02), heart failure (aHR = 3.29; 95% CI, 1.33-8.13; p = 0.01) and all CVD (aHR = 4.78; 95% CI, 2.66-8.59; p < 0.0001). No significant association was found between hsTnI and BAC. Adding hsTnI to a model containing the Pooled Cohorts Equation resulted in significant and clinical important improved calibration, discrimination ( Cindex = 6.5; p = 0.02) (bias-corrected NRI = 0.18; 95% CI, -0.13-0.49 after adding hsTnI categories). Our results support the consideration of hsTnI as a risk enhancing factor for CVD in asymptomatic women that could drive preventive or therapeutic Authors: Iribarren, Carlos; The effect the COVID-19 pandemic on prenatal cannabis use by pre-conception depression and anxiety status 2022-11-11. Incidence of Myocarditis/Pericarditis Following mRNA COVID-19 Vaccination Among Children and Younger Adults in the United States Authors: Goddard, Urinary in Early to Mid-Pregnancy and Risk of Gestational Diabetes: A Longitudinal Study in a Multiracial Cohort Environmental phenols are ubiquitous endocrine disruptors and putatively diabetogenic. However, data during pregnancy are scant. We investigated the prospective associations between pregnancy phenol concentrations and gestational diabetes mellitus (GDM) risk. In a nested matched case-control study of 111 individuals with GDM and 222 individuals without GDM within the prospective PETALS cohort, urinary bisphenol A [BPS]), benzophenone-3, and triclosan were quantified during the first and second trimesters. Cumulative concentrations across the two times were calculated using the area under the curve (AUC). Multivariable conditional logistic regression examined the association of individual phenols with GDM risk. We conducted mixture analysis using Bayesian kernel machine regression. We a priori examined effect modification by Asian/Pacific Islander (A/PI) race/ethnicity resulting from the case-control matching and highest GDM prevalence among A/PIs. Overall, first-trimester urinary BPS was positively associated with increased risk of GDM (adjusted odds ratio comparing highest vs. lowest tertile [aORT3 vs. T1] 2.12 [95% CI 1.00-4.50]). We identified associations among non-A/Ps, who had higher phenol concentrations than A/PIs. Among non-A/PIs, first-trimester BPA, BPS, and Triclosan in the second trimester and AUC were positively associated with GDM risk among non-A/PIs (P < 0.05). In mixture analysis, triclosan was significantly associated with GDM risk. Urinary BPS among all and BPA, BPS, and triclosan among non-A/PIs were associated with GDM risk. Pregnant individuals should be aware of these phenols' potential adverse health effects. large genome-wide association study of QT interval length utilizing electronic health records QT interval length is an important risk factor for adverse cardiovascular outcomes; however, the genetic architecture of QT interval remains incompletely understood. We conducted a genome-wide association study of 76,995 ancestrally diverse Kaiser Permanente Northern California members enrolled in the Genetic Epidemiology Research on Adult Health and Aging cohort using 448,517 longitudinal QT interval measurements, uncovering 9 novel variants, most replicating in 40,537 individuals in the UK Biobank and Population Architecture using Genomics and Epidemiology studies. A meta-analysis of all 3 cohorts (n = 117,532) uncovered an additional 19 novel variants. Conditional analysis identified 15 additional variants, 3 of which were novel. Little, if any, difference was seen when adjusting for putative QT interval lengthening medications genome-wide. Using multiple measurements in Genetic Epidemiology Research on Adult Health and Aging increased variance explained by 163%, and we show that the 6 measurements in Genetic Epidemiology Research on Adult Health and Aging was equivalent to a 2.4\u00d7 increase in sample size of a design with a single measurement. The array heritability was estimated at 17%, approximately half of our estimate of 36% from family correlations. Heritability enrichment was estimated highest and most significant in cardiovascular tissue (enrichment 7.2, 95% CI = 5.7-8.7, P = 2.1e-10), and many of the novel variants included expression quantitative trait loci in heart and other relevant tissues. Comparing our results to other cardiac function traits, it appears that QT interval has a multifactorial genetic etiology. 30;222(4). Associations between childhood obesity and pubertal timing stratified by sex and race/ethnicity Earlier puberty has been associated with numerous adverse mental, emotional, and physical health outcomes. Obesity is a known risk factor for earlier puberty in girls, but research with boys has yielded inconsistent findings. We examined sex- and race/ethnicity-specific associations between childhood obesity and puberty in a multiethnic cohort of 129,824 adolescents born at a Kaiser Permanente Northern California medical facility between 2003 and 2011. We used Weibull regression models to explore associations between childhood obesity and breast development onset (thelarche) in girls, testicular enlargement onset (gonadarche) in boys, and pubic hair development onset (pubarche) in both sexes, adjusting for important confounders. Clear dose-response relationships were observed. Boys with severe obesity had the greatest risk for earlier gonadarche (hazard ratio = 1.23, 95% confidence limit: 1.15, 1.32) and pubarche (hazard ratio = 1.44, 95% confidence limit: 1.34, 1.55), while underweight boys had delayed puberty compared with peers with normal body mass index. A similar dose-response relationship was observed in girls. There were significant interactions between childhood body mass index and race/ethnicity. Childhood obesity is associated with earlier puberty in both boys and girls, and the magnitude of the associations may vary by race/ethnicity. Prevention of childhood obesity may delay pubertal timing and mitigate health risks associated with both conditions. Authors: Aghaee, 19;191(12):2026-2036. Association of serum folate levels during pregnancy and prenatal depression To evaluate the association between serum folate levels during pregnancy and prenatal depression and the extent to which obesity may modify this relationship. This secondary data analysis leveraged data from a previous study of pregnant Kaiser Permanente Northern California participants who completed a survey and provided a serum sample between 2011 and 2013. Serum folate was assessed using the Center for Disease Control's Total Folate Serum/Whole Blood Microbiological Assay Method. A score of 15 or greater on the Center for Epidemiologic Studies Depression Scale was defined as prenatal depression. We used Poisson regression to estimate risk of prenatal depression given prenatal serum folate status (low/medium tertiles vs. high tertile) in the full sample and in subsamples of women with pre-pregnancy body mass index in the (a) normal range and (b) overweight/obese range. Of the sample, 13% had prenatal depression. Combined low/medium folate tertiles was associated with prenatal depression (adjusted relative risk [aRR]?=?1.97, 95% confidence interval [CI]: 0.93-4.18), although results did not reach statistical significance. This relationship was stronger among women with overweight/obesity than women with normal weight (aRR: and aRR: 1.50, 95% CI: respectively). Results suggest an association between lower pregnancy folate levels and prenatal depression that may be stronger among women with overweight or obesity. Future studies need to clarify the temporal sequence of these 2023 Dec;36(1):1-4. Epub 2022-11-17. Smoking Behaviors and Prognosis in Patients With Non-Muscle-Invasive Bladder Cancer in the Be-Well Study Tobacco smoking is an established risk factor associated with bladder cancer, yet its impact on bladder cancer prognosis is unclear. To examine associations of use of tobacco (cigarettes, pipes, and cigars), e-cigarettes, and marijuana with risk of recurrence and progression of non-muscle-invasive bladder cancer (NMIBC) and to explore use of smoking cessation interventions. The Be-Well Study is a prospective cohort study of patients with NMIBC diagnosed from 2015 to 2019 and followed-up for 26.4 months in the Kaiser Permanente Northern and Southern California integrated health care system. Eligibility criteria were age at least 21 years, first NMIBC diagnosis (stages Ta, Tis, or T1), alive, and not in hospice care. Exclusion criteria were previous diagnosis of bladder cancer or other cancer diagnoses within 1 year prior to or concurrent with NMIBC diagnosis. Data were analyzed from April 1 to October 4, 2022. Use of cigarettes, pipes, cigars, e-cigarettes, and marijuana was reported in the baseline interview. Use of smoking cessation interventions (counseling and medications) was derived from electronic health records. Hazard ratios (HRs) and 95% CIs of recurrence and progression of bladder cancer were estimated by multivariable Cox proportional hazards regression. A total of 1472 patients (mean [SD] age at diagnosis, 70.2 [10.8%] years; 1129 [76.7%] male patients) with NMIBC were enrolled at a mean (SD) of 2.3 (1.3) months after diagnosis, including 874 patients (59.4%) who were former smokers and 111 patients (7.5%) who were current cigarette smokers; 67 patients (13.7%) smoked pipes and/or cigars only, 65 patients (4.4%) used e-cigarettes, 363 patients (24.7%) used marijuana. Longer cigarette smoking duration and more pack-years were associated with higher risk of recurrence in a dose-dependent manner, with the highest risks for patients who had smoked for 40 or more years (HR, 2.36; 95% CI, 1.43-3.91) or 40 or more pack-years (HR, 1.97; 95% CI, 1.32-2.95). There was no association of having ever smoked, being a former or current cigarette smoker, and years since quit smoking with recurrence risk. No associations with pipes, cigars, e-cigarettes, or marijuana were found. Of 102 patients offered a smoking cessation intervention, 57 (53.8%) received an interventions after diagnosis, with female patients more likely than male patients to engage in such interventions (23 of 30 female patients [76.7%] vs 34 of 76 male patients [44.7%]; P = .003). These findings suggest that longer duration and more pack-years of cigarette smoking were associated with higher risk of NMIBC recurrence. Cigarette smoking remains a critical exposure before and after diagnosis in survivors of NMIBC. Authors: Kwan, Marilyn Geographic Retail Cannabis in Northern California and Prenatal Cannabis Use During the COVID-19 Pandemic Prenatal cannabis use is associated with health risks for mothers and their children. Prior research suggests that rates of prenatal cannabis use in Northern California increased during the COVID-19 pandemic, but it is unknown whether increases varied with the local cannabis retail and policy environment. To test whether pandemic-related increases in prenatal cannabis use were greater among pregnant individuals with greater retail availability of cannabis around their homes or among those living in jurisdictions that allowed storefront retailers. A cross-sectional, population-based time series study used data from pregnancies in the Kaiser Permanente Northern California health care system screened for cannabis use before (January 1, 2019, to March 31, 2020) and during (April 1 to December 31, 2020) the early COVID-19 pandemic. Proximity to the nearest retailer and number of retailers within a 15-minute drive from one's home and local cannabis storefront retailer policy (banned vs permitted) were calculated. Interrupted time series models were fit using multiplicative and additive Poisson regression, adjusting for age and race and ethnicity. The COVID-19 pandemic. Prenatal cannabis use based on universal urine toxicology tests conducted during early pregnancy at entrance to prenatal care. The sample (n = 99 127 pregnancies) included 26.2% Asian or Pacific Islander, 6.8% Black, 27.6% Hispanic, 34.4% non-Hispanic White, and 4.9% other, unknown, or multiracial individuals, with a mean (SD) age of 30.8 (5.3) years. Prenatal cannabis use before (6.8%) and during (8.2%) the pandemic was associated with closer proximity to a retailer, greater retailer density, and residing in a jurisdiction that permitted vs banned retailers. There was a greater absolute increase in cannabis use from before to during the pandemic among those within a 10-minute drive (<10 minutes: patients; interaction P = .02). Otherwise, relative and absolute rates increased similarly across categories of cannabis retailer proximity/density and local policy (interaction P > .05). Prenatal cannabis use was more common among individuals living in areas with greater retail availability of cannabis. Although relative rates increased similarly during the pandemic regardless of local cannabis retail and policy environment, there was a larger absolute increase associated with living closer to a storefront cannabis retailer. Continued monitoring of local cannabis policy, the retail environment, and prenatal cannabis use is needed. Authors: Young-Wolff, With Long-term Patient Outcomes: The KP-TAA Study The risk of adverse events from ascending thoracic aorta aneurysm (TAA) is poorly understood but drives clinical decision-making. To evaluate the association of TAA size with outcomes in nonsyndromic patients in a large non-referral-based health care delivery system. The Kaiser Permanente Thoracic Aortic Aneurysm (KP-TAA) cohort study was a retrospective cohort study at Kaiser Permanente Northern California, a fully integrated health care delivery system insuring and providing care for more than 4.5 million persons. Nonsyndromic patients from a regional TAA safety net tracking system were included. Imaging data including maximum TAA size were merged with electronic health record (EHR) and comprehensive death data to obtain demographic characteristics, comorbidities, medications, laboratory values, vital signs, and subsequent outcomes. Unadjusted rates were calculated and the association of TAA size with outcomes was evaluated in multivariable competing risk models that categorized TAA size as a baseline and time-updated variable and accounted for potential confounders. Data were analyzed from January 2018 to August 2021. TAA size. Aortic dissection (AD), all-cause death, and elective aortic surgery. Of 6372 patients with TAA identified between 2000 and 2016 (mean [SD] age, 68.6 [13.0] years; 2050 female individuals [32.2%] and 4322 male individuals [67.8%]), mean (SD) initial TAA size was 4.4 (0.5) cm (828 individuals [13.0% of cohort] had initial TAA size 5.0 cm or larger and 280 [4.4%] 5.5 cm or larger). Rates of AD were low across a mean (SD) 3.7 (2.5) years of follow-up (44 individuals [0.7% of cohort]; incidence 0.22 events per 100 person-years). Larger initial aortic size was associated with higher risk of AD and all-cause death in multivariable models, with an inflection point in risk at 6.0 cm. Estimated adjusted risks of AD within 5 years were 0.3% (95% 2.7-44.3) in patients with TAA size of 4.0 to 4.4 cm, 4.5 to 4.9 cm, 5.0 to 5.4 cm, 5.5 to 5.9 cm, and 6.0 cm or larger, respectively, in time-updated models. Rates of the composite outcome of AD and all-cause death were higher than for AD alone, but a similar inflection point for increased risk was observed at 6.0 cm. In a large sociodemographically diverse cohort of patients with TAA, absolute risk of aortic dissection was low but increased with larger aortic sizes after adjustment for potential confounders and competing risks. Our data support current consensus guidelines recommending prophylactic surgery in nonsyndromic individuals with TAA at a 5.5-cm threshold. Authors: Solomon, Matthew D; Lee, Catherine; Chang, Robert; Go, Alan S; Kaiser Permanente Northern California Center for Thoracic Aortic Disease ,; et al. JAMA Cardiol. 2022 Nov 01;7(11):1160-1169. Retrospective cohort study to assess the association between treatment with tocilizumab and mortality among mechanically ventilated patients with COVID-19 Assess the association between tocilizumab administration and clinical outcomes among mechanically ventilated patients with COVID-19 pneumonia. Retrospective cohort study. Large integrated health system with 9 million members in California, USA. 4185 Kaiser Permanente members hospitalised with COVID-19 pneumonia requiring invasive mechanical ventilation (IMV). Receipt of tocilizumab within 10 days of initiation of IMV. Using a retrospective cohort of consecutive patients hospitalised with COVID-19 pneumonia who required IMV in a large integrated health system in California, USA, we assessed the association between tocilizumab administration and 28-day mortality, time to extubation from IMV and time to hospital discharge. Among 4185 patients, 184 received tocilizumab and 4001 patients did not receive tocilizumab within 10 days of initiation of IMV. After inverse probability weighting, baseline characteristics were well balanced between groups. Patients treated with tocilizumab had a similar risk of death in the 28 days after intubation compared with patients not treated with tocilizumab (adjusted HR (aHR), 1.21, 95% CI 0.98 to 1.50), but did have a significantly longer time-to-extubation (aHR 0.71; 95% CI 0.57 to 0.66; CI 0.50 to 0.88). However, patients treated with tocilizumab 2 days after initiation of IMV had a similar risk of mortality (aHR 1.47; 95% CI 0.96 to 2.26), but significantly shorter time-to-extubation (aHR 0.37; 95% CI 0.23 to 0.58) and time-to-hospital-discharge (aHR 0.31; 95% CI CI 0.17 to 0.56) compared with patients treated with tocilizumab 3-10 days after initiation of IMV. Among mechanically ventilated patients with COVID-19, the risk of death in the 28-day follow-up period was similar, but time-to-extubation and time-to-hospital-discharge were longer in patients who received tocilizumab within 10 days of initiation of IMV compared with patients who did not receive tocilizumab. Authors: Skarbinski, Jacek; Fireman, Epub 2022-10-31. Prescribing for different antibiotic classes across age groups in the Kaiser Permanente Northern California population in association with influenza incidence, 2010-2018 There is limited information on the volume of antibiotic prescribing that is influenza-associated, resulting from influenza infections and their complications (such as streptococcal pharyngitis). We estimated that for the Kaiser Permanente Northern California population during 2010-2018, 3.4% (2.8%-4%) of all macrolide aminopenicillin prescriptions, of all generation cephalosporins prescriptions, (1.8%-2.6%) of all protected aminopenicillin prescriptions and 1.3% (1%-1.6%) of all quinolone prescriptions were influenza-associated. The corresponding proportions were higher for select age groups, e.g. 4.3% of macrolide prescribing in ages over 50 years, 5.1% prescribing in ages 5-17 (1.9%-4.6%) in ages <5 years was influenza-associated. The relative contribution of influenza to antibiotic prescribing for respiratory diagnoses without a bacterial indication in ages over 5 years was higher than the corresponding relative contribution to prescribing for all diagnoses. Our results suggest a modest benefit of increasing influenza vaccination coverage for reducing prescribing for the five studied antibiotic classes, particularly for macrolides in ages over 50 years and aminopenicillins in ages <18 years, and the potential benefit of other measures to reduce unnecessary antibiotic prescribing for respiratory diagnoses with no bacterial indication, both of which may contribute to the mitigation of antimicrobial resistance. Authors: Goldstein, Edward; Fireman, Bruce 2022-10-26. Effectiveness of COVID-19 Among Immunocompromised Adults During SARS-CoV-2 Omicron Predominance - VISION Network, 10 States, December 2021-August 2022 Persons with moderate-to-severe immunocompromising conditions might have reduced protection after COVID-19 vaccination, compared with persons without immunocompromising conditions (1-3). On August 13, 2021, the Advisory Committee on Immunization Practices (ACIP) recommended that adults with immunocompromising conditions receive an expanded primary series of 3 doses of an mRNA COVID-19 vaccine. ACIP followed with recommendations on September 23, 2021, for a fourth (booster) dose and on September 1, 2022, for a new bivalent mRNA COVID-19 vaccine booster dose, containing components of the BA.4 and BA.5 sublineages of the Omicron (B.1.1.529) variant (4). Data on vaccine effectiveness (VE) of monovalent COVID-19 vaccines among persons with immunocompromising conditions since the emergence of the Omicron variant in December 2021 are limited. In the multistate VISION Network,\u00a7 monovalent 2-, 3-, and 4-dose mRNA VE against COVID-19-related hospitalization were estimated among adults with immunocompromising conditions\u00b6 hospitalized with COVID-19-like illness,** using a test-negative design comparing odds of previous vaccination among persons with a positive or negative molecular test result (case-patients and control-patients) for SARS-CoV-2 (the virus that causes COVID-19). During December 0, 2, 3, and 4 mRNA COVID-19 vaccine doses, respectively. Among test-negative respective doses. Overall, VE against COVID-19-related hospitalization among adults with immunocompromising conditions hospitalized for COVID-like illness during Omicron predominance was 36% 14 days after dose 2, 69% 7-89 days after dose 3, and 44% 90 days after dose 3. Restricting the analysis to later periods when Omicron sublineages BA.2/BA.2.12.1 and BA.4/BA.5 were predominant and 3-dose recipients were eligible to receive a fourth dose, VE was 32% 90 days after dose 3 and 43% 7 days after dose 4. Protection offered by vaccination among persons with immunocompromising conditions during Omicron predominance was moderate even after a 3-dose monovalent primary series or booster dose. Given the incomplete protection against hospitalization afforded by monovalent COVID-19 vaccines, persons with immunocompromising conditions might benefit from updated bivalent vaccine booster doses that target recently circulating Omicron sublineages, in line with ACIP recommendations. Further, additional protective recommendations for persons with immunocompromising conditions, including the use of prophylactic antibody therapy, early access to and use of antivirals, and enhanced nonpharmaceutical interventions such as well-fitting masks or respirators, should SARS-CoV-2 Vaccination and Infant Protection Against SARS-CoV-2 During the First 6 Months of Life We examined the effectiveness of maternal vaccination against SARS-CoV-2 infection in 30,288 infants born at Kaiser Permanente Northern California from December 15, 2020, to May 31, 2022. Using Cox regression, the effectiveness of maternal vaccination was 85% (95% confidence interval [CI]: 67, 93), 64% (CI: 43, 78) and 57% (CI: 36,71) during the first 2, 4 and 6 months of life, respectively, in the Delta variant period. In the Omicron variant period, the effectiveness of maternal vaccination in these three age intervals was Over the entire study period, the incidence of hospitalization for COVID-19 was lower during the first 6 months of life among infants of vaccinated mothers compared with infants of unvaccinated mothers (21/100,000 person-years vs. 100/100,000 person-years). Maternal vaccination was protective, but protection was lower during Omicron than during Delta. Protection during both periods decreased as infants aged. Authors: Zerbo, Nicola Res Sq. 2022 Oct 18. Patterns of Substance Use During Early Pregnancy and Associations With Behavioral Health Characteristics The aims of the study are to identify patterns of early pregnancy substance use and to examine how these patterns relate to behavioral health conditions measured in early pregnancy. We conducted a retrospective observational study (N= 265,274 pregnancies) screened for alcohol, cannabis, nicotine, pharmaceutical opioids, and stimulants during the first trimester via self-report and urine toxicology tests in Kaiser Permanente Northern California from January 1, 2012, to December 31, 2019. To identify patterns of prenatal substance use, we conducted latent class analysis. We then calculated the prevalence of depression, anxiety, intimate partner violence, and family drug use history for each prenatal substance use group and compared the prevalences by estimating prevalence ratios using modified Poisson regression, adjusting for sociodemographic characteristics. We identified the following 4 latent groups with different patterns of substance use: (a) predominantly alcohol and no other substances (9.30%), (b) predominantly cannabis and no other substances (4.88%), (c) predominantly nicotine and some pharmaceutical opioids high-polysubstance (alcohol, cannabis, nicotine, and stimulants; 0.36%); these pregnancies were compared with (e) no prenatal substance use (84.37%). The prevalence of all behavioral health conditions was elevated in all prenatal substance use groups compared with the no substance use group. Furthermore, the prevalence of depressive and anxiety disorders, intimate partner violence and family drug use history were greater in the high-polysubstance cluster than the alcohol and cannabis clusters. Results highlight the importance of screening and interventions for all types of substance use during early pregnancy and suggest a particularly high need to prioritize targeting early interventions to pregnant and reproductive age individuals with polysubstance Kelly C J Addict Med. 2022 Oct 18. Assessment of genetic susceptibility to multiple primary cancers through whole-exome sequencing in two large multi-ancestry studies Up to one of every six individuals diagnosed with one cancer will be diagnosed with a second primary cancer in their lifetime. Genetic factors contributing to the development of multiple primary cancers, beyond known cancer syndromes, have been underexplored. To characterize genetic susceptibility to multiple cancers, we conducted a pan-cancer, whole-exome sequencing study of individuals drawn from two large multi-ancestry populations (6429 cases, 165,853 controls). We created two groupings of individuals diagnosed with multiple primary cancers: (1) an overall combined set with at least two cancers across any of 36 organ sites and (2) cancer-specific sets defined by an index cancer at one of 16 organ sites with at least 50 cases from each study population. We then investigated whether variants identified from exome sequencing were associated with these sets of multiple cancer cases in comparison to individuals with one and, separately, no cancers. We identified 22 variant-phenotype associations, 10 of which have not been previously discovered and were significantly overrepresented among individuals with multiple cancers, compared to those with a single cancer. Overall, we describe variants and genes that may play a fundamental role in the development of multiple primary cancers and improve our understanding of shared mechanisms underlying carcinogenesis. Authors: 10 06;20(1):332. Epub 2022-10-06. Waning of vaccine effectiveness against moderate and severe covid-19 among adults in the US from the VISION network: test negative, case-control study To estimate the effectiveness of mRNA vaccines against moderate and severe covid-19 in adults by time since second, third, or fourth doses, and by age and immunocompromised status. Test negative case-control study. Hospitals, emergency departments, and urgent care clinics in 10 US states, 17 January 2021 to 12 July 2022. 893 461 adults (18 years) admitted to one of 261 hospitals or to one of 272 emergency department or 119 urgent care centers for covid-like illness tested for SARS-CoV-2. The main outcome was waning of vaccine effectiveness with BNT162b2 (Pfizer-BioNTech) or mRNA-1273 (Moderna) vaccine during the omicron and delta periods, and the period before delta was dominant using logistic regression conditioned on calendar week and geographic area while adjusting for age, race, ethnicity, local virus circulation, immunocompromised status, and likelihood of being vaccinated. 45 903 people admitted to hospital with covid-19 (cases) were compared with 213 103 people with covid-like illness who tested negative for SARS-CoV-2 (controls), and 103 287 people admitted to emergency department or urgent care with covid-19 (cases) were compared with 531 168 people with covid-like illness who tested negative for SARS-CoV-2. In the omicron period, vaccine effectiveness against covid-19 requiring admission to hospital was 89% (95% confidence interval 88% to 90%) within two months after dose 3 but waned to 66% (63% to 68%) by four to five months. Vaccine effectiveness of three doses against emergency department or urgent care visits was 83% (82% to 84%) initially but waned to 46% (44% to 49%) by four to five months. Waning was evident in all subgroups, including young adults and individuals who were not immunocompromised; although waning was morein people who were immunocompromised. Vaccine effectiveness increased among most groups after a fourth dose in whom this booster was recommended. Effectiveness of mRNA vaccines against moderate and severe covid-19 waned with time after vaccination. The findings support recommendations for a booster dose after a primary series and consideration of additional booster doses. Authors: Ferdinands, Jill M; Sociodemographic and clinical characteristics associated with never-smoking status in patients with lung cancer: findings from a large integrated health system Evidence is limited characterizing sociodemographically diverse patient populations with lung cancer in relation to smoking status. In a cross-sectional analysis of adults diagnosed with lung cancer at ages 30 years from 2007-2018 within an integrated healthcare system, overall and sex-specific prevalence of never smoking were estimated according to sociodemographic and clinical characteristics. Adjusted prevalence ratio (aPR) and 95% confidence interval (CI) were also estimated using modified Poisson regression to identify patient characteristics associated with never smoking, overall and by sex. Similar analyses were conducted to explore whether prevalence and association patterns differed between non-Hispanic White and Asian/Pacific Islander patients. Among 17,939 patients with lung cancer, 2,780 (15.5%) never smoked and 8,698 (48.5%) had adenocarcinoma. Overall prevalence of never smoking was higher among females than males (21.2% vs. 9.2%, aPR 1.72, 95% CI: 1.51-1.95) than non-Hispanic White patients; patients who primarily spoke Spanish (aPR 1.60, 95% CI: 1.32-1.94), any Asian language (aPR 1.20, languages (aPR 1.84, 95% CI: 1.27-2.65) than English; patients living in the least vs. most deprived neighborhoods (aPR 1.36, 95% CI: 1.24-1.50); and patients with adenocarcinoma (aPR than squamous cell carcinoma tumors. Patterns of never smoking associated with sociodemographic, but not clinical factors, differed by sex. The higher prevalence of never smoking associated with Asian/Pacific Islander race/ethnicity was more evident among females (aPR 3.30, CI: 2.95-3.47) than males (aPR 2.25, 95% CI: 1.92-2.63), whereas the higher prevalence of never smoking associated with living in the least deprived neighborhoods was more evident among males (aPR 1.93, 95% CI: 1.56-2.38) than females (aPR 1.18, 95% CI: 1.06-1.31). Associations between primary language and never-smoking status were found only among females. Overall and sex-specific prevalence and association patterns differed between Asian/Pacific Islander and non-Hispanic white patients. Our findings suggest that patterns of never-smoking status associated with sociodemographic and clinical characteristics are different across sex and race/ethnicity among patients with lung cancer. Such data are critical to increasing awareness and expediting diagnosis of this disease. Authors: Banks, Kian C; Sumner, Eric Res. 2022 Oct;11(10):3522-3534. Disparities in the Incidence of Ectopic Pregnancy in a Large Health Care System in California, 2010-2019 IntroductionEctopic pregnancy leads to reproductive health morbidity, including greater risk of another ectopic pregnancy, infertility, and, in rare cases, mortality. Information on trends in the incidence of ectopic pregnancy in the last decade is limited. MethodsA population-based cross-sectional study of women aged 15-44 years enrolled at Kaiser Permanente Northern and Southern California 2010-2019 was conducted. Electronic health records were used to identify ectopic pregnancies. The crude ectopic pregnancy incidence per 1000 pregnancies (live births, induced abortions, and ectopic pregnancies) and 95% confidence interval (CI) was estimated per study year, overall, and stratified by age group. The age-adjusted incidence and 95% CI was estimated per study year, overall, and stratified by race/ethnicity. Temporal trend was assessed using Poisson regression. ResultsThere were 15,537 ectopic pregnancies among 979,027 pregnancies. The overall age-adjusted ectopic pregnancy incidence was 15.8 per 1000 pregnancies, 95% CI: 15.6, 16.1. The annual incidence increased from 15.2, 95% CI: 14.4, 16.1, in 2010 to 16.4, 95% CI: 15.6, 17.2, in 2019 (p < 0.001). The overall incidence was highest among women aged 40-44 years (24.2, 95% CI: 22.7, 25.6) and non-Hispanic 22.8); compared to 30-34-year-old (16.2, and non-Hispanic White (14.6, 95% CI: 14.1, 15.0) women, respectively. DiscussionThe increase in ectopic pregnancy incidence during the studied period was largely driven by increasing incidence in younger women. However, disparities in the incidence by age and race/ethnicity persisted. ConclusionEctopic pregnancy remains a significant source of reproductive health morbidity, especially for older ( >40 years) and non-Hispanic of COVID-19 mRNA Vaccine Effectiveness Against Medically Attended COVID-19 in Pregnancy During Periods of Delta and Omicron Variant Predominance in the United States Pregnant people are at high risk for severe COVID-19 but were excluded from mRNA vaccine trials; data on COVID-19 vaccine effectiveness (VE) are needed. To evaluate the estimated effectiveness of mRNA vaccination against medically attended COVID-19 among pregnant people during Delta and Omicron predominance. This test-negative, case-control study was conducted from June 2021 to June 2022 in a network of 306 hospitals and 164 emergency department and urgent care (ED/UC) facilities across 10 US states, including 4517 ED/UC encounters and 975 hospitalizations among pregnant people with COVID-19-like illness (CLI) who underwent SARS-CoV-2 molecular testing. Two doses (14-149 and 150 days prior) and 3 doses (7-119 and 120 days prior) of COVID-19 mRNA vaccine (1 dose received during pregnancy) vs unvaccinated. Estimated VE against laboratory-confirmed COVID-19-associated ED/UC encounter or hospitalization, based on the adjusted odds ratio (aOR) for prior vaccination; VE was calculated as (1 - aOR) \u00d7 100%. Among 4517 eligible CLI-associated ED/UC encounters 885 (19.6%) and 334 (34.3%) were SARS-CoV-2 positive, respectively; the median (IQR) patient age was 28 (24-32) years and 31 (26-35) years, 537 (12.0%) and 118 (12.0%) were non-Hispanic Black and 1189 (26.0%) and 240 (25.0%) were Hispanic. During Delta predominance, the estimated VE against COVID-19-associated ED/UC encounters was 84% (95% CI, 69% to 92%) for 2 doses within 14 to 149 days, 75% (95% CI, 5% to 93%) for 2 doses 150 or more days prior, and 81% (95% CI, 30% to 95%) for 3 doses 7 to 119 days prior; estimated VE against COVID-19-associated hospitalization was During Omicron predominance, for ED/UC encounters, the estimated VE of 2 doses within 14 to 149 days, 2 doses 150 or more days, 3 doses within 7 to 119 days, and 3 doses 120 or more days prior was 3% (95% CI, to 83%), respectively. In this study, maternal mRNA COVID-19 vaccination, including booster dose, was associated with protection against medically attended COVID-19. VE estimates were higher against COVID-19-associated hospitalization than ED/UC visits and lower against the Omicron variant than the Delta variant. Protection waned over time, particularly during Omicron Epub 2022-09-01. Electronic cigarette use and risk of COVID-19 among young adults without a history of cigarette smoking It is unknown whether use of e-cigarettes increases susceptibility to COVID-19. In a large clinical sample of young adults, we evaluated whether current or ever e-cigarette use was associated with polymerase chain reaction (PCR)-confirmed COVID-19. To address the confounding of combustible smoking, the sample was restricted to never smokers. This retrospective cohort study analyzed data from the electronic health records of 74,853 young adults (aged 18-35 years), without a history of cigarette smoking, who were screened for e-cigarette use (current, former, never) in the Kaiser Permanente Northern California (KPNC) healthcare system from 3/5/2020 (baseline) to 11/30/2020 (pre-vaccine). COVID-19 risk was estimated in time-to-event analyses using multivariable Cox proportional hazard regression models, adjusted for socio-demographics and medical comorbidities. E-cigarette status in the cohort was: 1.6% current, 1.2% former, and 97.2% never. During follow-up, 1965 (2.6%) patients acquired COVID-19. We did not find evidence that current (vs never) e-cigarette use was associated with risk of COVID-19 (aHR = 1.12 95%CI:0.77-1.62). However, we did find suggestive evidence that former (versus never) e-cigarette use may be associated with greater risk of COVID-19 (aHR = 1.39 95%CI:0.98-1.96). While e-cigarette use is associated with health risks for young adults, results from this study suggest that current use of e-cigarettes may not increase susceptibility for COVID-19 among young adults who have never smoked cigarettes. Authors: Young-Wolff, Kelly profiles as biomarkers for ASD and ASD with co-occurring intellectual disability Maternal autoantibody-related ASD (MAR ASD) is a subtype of autism in which pathogenic maternal autoantibodies (IgG) cross the placenta, access the developing brain, and cause neurodevelopmental alterations and behaviors associated with autism in the exposed offspring. We previously reported maternal IgG response to eight proteins (CRMP1, CRMP2, GDA LDHA, LDHB, NSE, STIP1, and YBOX) and that reactivity to nine specific combinations of these proteins (MAR ASD patterns) was predictive of ASD risk. The aim of the current study was to validate the previously identified MAR ASD patterns (CRMP1 + GDA, CRMP1 + CRMP2, YBOX, and CRMP1 + STIP1) and their accuracy in predicting ASD risk in a prospective cohort employing maternal samples collected prior to parturition. We used prenatal plasma from mothers of autistic children with or without co-occurring intellectual disability (ASD = 540), intellectual disability without autism (ID = 184) and general population controls (GP = 420) collected by the Early Markers for Autism (EMA) study. We found reactivity to one or more of the nine previously identified MAR ASD patterns in 10% of the ASD group compared with 4% of the ID group and 1% of the GP controls (ASD vs GP: Odds Ratio (OR) = 7.81, 95% Confidence Interval (CI) 3.32 to 22.43; ASD vs ID: OR = 2.77, 95% CI (1.19-7.47)) demonstrating that the MAR ASD patterns are strongly associated with the ASD group and could be used to assess ASD risk prior to symptom onset. The pattern most strongly associated with ASD was CRMP1 + CRMP2 and increased the odds for an ASD diagnosis 16-fold (3.32 to >999.99). In addition, we found that several of these specific MAR ASD patterns were strongly associated with ASD with intellectual disability (ASD + ID) and others associated with ASD without ID (ASD-no ID). Prenatal screening for these MAR patterns may lead to earlier identification of ASD and facilitate access to the appropriate early intervention services based on each child's needs. and mRNA-1273 COVID-19 vaccination Evidence indicates that mRNA COVID-19 vaccination is associated with risk of myocarditis and possibly pericarditis, especially in young males. It is not clear if risk differs between mRNA-1273 versus BNT162b2. We assessed if risk differs using comprehensive health records on a diverse population. Members 18-39 years of age at eight integrated healthcare-delivery systems were monitored using data updated weekly and supplemented with medical record review of myocarditis and pericarditis cases. Incidence of myocarditis and pericarditis events that occurred among vaccine recipients 0 to 7 days after either dose 1 or 2 of a messenger RNA (mRNA) vaccine was compared with that of vaccinated concurrent comparators who, on the same calendar day, had received their most recent dose 22 to 42 days earlier. Rate ratios (RRs) were estimated by conditional Poisson regression, adjusted for age, sex, race and ethnicity, health plan, and calendar day. Head-to-head comparison directly assessed risk following mRNA-1273 versus BNT162b2 during 0-7 days post-vaccination. From December 14, 2020 - January 15, 2022 there were 41 cases after 2,891,498 doses of BNT162b2 and 38 cases after 1,803,267 doses of mRNA-1273. Cases had similar demographic and clinical characteristics. Most were hospitalized for 1 day; none required intensive care. During days 0-7 after dose 2 of BNT162b2, the incidence was 14.3 (CI: 6.5-34.9) times higher than the comparison interval, amounting to 22.4 excess cases per million doses; after mRNA-1273 the incidence was 18.8 (CI: 6.7-64.9) times higher than the comparison interval, amounting to 31.2 excess cases per million doses. In head-to-head comparisons 0-7 days after either dose, risk was moderately higher after mRNA-1273 than after BNT162b2 (RR: 1.61, CI 1.02-2.54). Both vaccines were associated with increased risk of myocarditis and pericarditis in 18-39-year-olds. Risk estimates were modestly higher Epub 2022-07-12. Prolactin and maternal metabolism in women with a recent GDM pregnancy and links to future T2D: the SWIFT study Prolactin is a multifaceted hormone known to regulate lactation. In women with gestational diabetes mellitus (GDM) history, intensive lactation has been associated with lower relative risk of future type 2 diabetes (T2D). However, the role of prolactin in T2D development and maternal metabolism in women with a recent GDM pregnancy has not been ascertained. We examined the relationships among prolactin, future T2D risk, and key clinical and metabolic parameters. We utilized a prospective GDM research cohort (the SWIFT study) and followed T2D onset by performing 2-hour 75-g research oral glucose tolerance test (OGTT) at study baseline (6-9 weeks postpartum) and again annually for 2 years, and also by retrieving clinical diagnoses of T2D from 2 years through 10 years of follow up from electronic medical records. Targeted metabolomics and lipidomics were applied on fasting plasma samples collected at study baseline from 2-hour 75-g research OGTTs in a nested case-control study (100 future incident T2D cases vs 100 no T2D controls). Decreasing prolactin quartiles were associated with increased future T2D risk (adjusted odds ratio 2.48; 95% CI, 0.81-7.58; P = 0.05). In women who maintained normoglycemia during the 10-year follow-up period, higher prolactin at baseline was associated with higher insulin sensitivity (P = 0.038) and HDL-cholesterol (P = 0.01), but lower BMI (P = 0.001) and leptin (P = 0.002). Remarkably, among women who developed future T2D, prolactin was not correlated with a favorable metabolic status (all P > 0.05). Metabolomics and lipidomics showed that lower circulating prolactin strongly correlated with a T2D-high risk lipid profile, with elevated circulating neutral lipids and lower concentrations of specific phospholipids/sphingolipids. In women with recent GDM pregnancy, low circulating prolactin is associated with specific clinical and metabolic parameters and lipid metabolites linked to a high risk of developing Metab. 2022 Aug 18;107(9):2652-2665. Risk of severe COVID-19 infection among adults with prior exposure to children Susceptibility and severity of COVID-19 infection vary widely. Prior exposure to endemic coronaviruses, common in young children, may protect against SARS-CoV-2. We evaluated risk of severe COVID-19 among adults with and without exposure to young children in a large, integrated healthcare system. Adults with children 0-5 years were matched 1:1 to adults with children 6-11 years, 12-18 years, and those without children based upon a COVID-19 propensity score and risk factors for severe COVID-19. COVID-19 infections, hospitalizations, and need for intensive care unit (ICU) were assessed in 3,126,427 adults, of whom 24% (N = 743,814) had children 18 years or younger, and 8.8% (N = 274,316) had a youngest child 0-5 years. After 1:1 matching, propensity for COVID-19 infection and risk factors for severe COVID-19 were well balanced between groups. Rates of COVID-19 infection were slightly higher for adults with exposure to older children (incident risk ratio, 1.09, 95% confidence interval, [1.05-1.12] and IRR 1.09 [1.05-1.13] for adults with children 6-11 and 12-18, respectively), compared to those with children 0-5 years, although no difference in rates of COVID-19 illness requiring hospitalization or ICU admission was observed. However, adults without exposure to children had lower rates of COVID-19 infection (IRR 0.85, [0.83-0.87]) but significantly higher rates of COVID-19 hospitalization (IRR 1.49, [1.29-1.73]) and hospitalization requiring ICU admission (IRR 1.76, [1.19-2.58]) compared to those with children aged 0-5. In a large, real-world population, exposure to young children was associated with less severe COVID-19 illness. Endemic coronavirus cross-immunity may play a role in protection against severe COVID-19. Authors: Solomon, Matthew D; Escobar, S A. 2022 Aug 16;119(33):e2204141119. Epub 2022-07-27. Safety of COVID-19 Vaccination in US Children Ages 5-11 Years Limited postauthorization safety data for the Pfizer-BioNTech coronavirus disease 2019 vaccination among children ages 5 to 11 years are available, particularly for the adverse event myocarditis, which has been detected in adolescents and young adults. We describe adverse events observed during the first 4 months of the United States coronavirus disease 2019 vaccination program in this age group. We analyzed data from 3 United States safety monitoring systems: v-safe, a voluntary smartphone-based system that monitors reactions and health effects; the Vaccine Adverse Events Reporting System (VAERS), the national spontaneous reporting system comanaged by the Centers for Disease Control and Prevention and Food and Drug Administration; and the Vaccine Safety Datalink, an active surveillance system that monitors electronic health records for prespecified events, including myocarditis. Among 48 795 children ages 5 to 11 years enrolled in v-safe, most reported reactions were mild-to-moderate, most frequently reported the day after vaccination, and were more common after dose 2. VAERS received 7578 adverse event reports; 97% were nonserious. On review of 194 serious VAERS reports, 15 myocarditis cases were verified; 8 occurred in boys after dose 2 (reporting rate 2.2 per million doses). In the Vaccine Safety Datalink, no safety signals were detected in weekly sequential monitoring after administration of 726 820 doses. Safety findings for Pfizer-BioNTech vaccine from 3 United States monitoring systems in children ages 5 to 11 years show that most reported adverse events were mild and no safety signals were observed in active surveillance. VAERS reporting rates of myocarditis after dose 2 in this age group were substantially lower than those observed among adolescents ages 12 to 15 years. Authors: Hause, 01;150(2). Predictive Metabolomic Markers in Early to Mid-Pregnancy for Gestational Diabetes: A Prospective Test and Validation Study Gestational diabetes mellitus (GDM) predisposes pregnant individuals to perinatal complications and long-term diabetes and cardiovascular diseases. We developed and validated metabolomic markers for GDM in a prospective test-validation study. In a case-control sample within the PETALS cohort (GDM n = 91 and non-GDM n = 180; discovery set), a random PETALS subsample (GDM n = 42 and non-GDM n = 372; validation set 1), and a case-control sample within the GLOW trial (GDM n = 35 and non-GDM n = 70; validation set 2), fasting serum were measured by gas chromatography/time-of-flight mass spectrometry. analysis examined associations between metabolites and GDM. Ten-fold cross-validated LASSO regression identified predictive metabolomic at GW 16-19 with GDM risk (false discovery rate <0.05). A 17-metabolite panel at GW 10-13 outperformed the model using conventional risk factors, including fasting glycemia (area under the curve: discovery 0.871 vs. validation 2 0.972 vs. 0.742; P < 0.01). Similar results were observed with a 13-metabolite panel at GW 17-19. Dysmetabolism is present early in pregnancy among individuals progressing to GDM. Multimetabolite panels in early pregnancy can predict GDM risk beyond conventional risk factors. Authors: Zhu, 08 01;71(8):1807-1817. Adults hospitalized with breakthrough COVID-19 have lower mortality than matched unvaccinated adults Coronavirus disease 2019 (COVID-19) breakthrough infections are common. Evaluate in-hospital mortality of patients with COVID-19 by vaccination status using retrospective cohort study. We generated propensity scores for receipt of full vaccination in adults requiring supplemental oxygen hospitalized at Kaiser Permanente Northern California (1 April 2021 to 30 November 2021) with positive severe acute respiratory syndrome coronavirus 2 polymerase chain reaction tests. Optimal matching of fully vaccinated/unvaccinated patients was performed comparing in-hospital mortality. Of 7305 patients, 1463 (20.0%) were full, 138 (1.9%) were partial, and 5704 (78.1%) were unvaccinated. Fully vaccinated were older than partial or unvaccinated (71.0, 63.0, and 54.0 years, respectively, p < 0.001) comorbidities (Comorbidity Point Scores (2.8%, 0.7%, and 0.4%, p < 0.001). Fewer fully vaccinated patients died compared to matched unvaccinated (9.0% vs. 16.3%, p < 0.0001). Fully vaccinated patients are less likely to die compared to matched unvaccinated patients. Authors: Myers, Laura C; Kipnis, Patricia; Greene, John; Bruce H; Klein, Nicola P; Myocarditis and/or pericarditis risk after mRNA vaccination: A Canadian head to head comparison of BNT162b2 and mRNA-1273 vaccines Canadian and international data suggest the risk of myocarditis and/or pericarditis is elevated during the week after mRNA COVID-19 vaccination, particularly in younger age groups, in males, and after second doses. This article examines whether there is a product-specific difference in the risk for myocarditis and/or pericarditis between the two mRNA myocarditis and/or pericarditis were calculated from reports received by the Canadian Adverse Events Following Immunization Surveillance System from December 2020-March 2022. Excess cases and attributable incidence among individuals aged 18-39 were estimated for each vaccine in comparison with background rates from 2015 to 2019. Head-to-head comparisons used Poisson regression, conditioned on week of vaccine administration, to estimate rate ratios for the week after mRNA-1273 vaccination versus the week after BNT162b2, by age and sex as well as overall. Analyses were restricted to May 30-March 13, 2021, when heightened media awareness was unlikely to have affected reporting rates for the two products differentially. In 18-29 year-old males who received a second dose of mRNA COVID-19 vaccine, attributable risk of myocarditis and/or pericarditis was found to be 5.69 (95% CI: 4.07 - 7.95; p < 0.001) times higher among mRNA-1273 recipients (n = 106) as compared to BNT162b2 recipients (n = 33). In the same group, Poisson regression modelling estimated that the risk of myocarditis and/or pericarditis was 4.72 (p-value = <0.001) times higher after mRNA-1723 compared to BNT162b2 vaccination. The risk of myocarditis and/or pericarditis is higher after mRNA-1723 vaccination than BNT162b2 vaccination in those aged 18-39 years, especially in males aged 18-29 years, where the risk is several times higher. Authors: of 2, 3, and 4 COVID-19 mRNA Vaccine Doses Among Immunocompetent Adults During Periods when SARS-CoV-2 Omicron BA.1 and BA.2/BA.2.12.1 Predominated 2021-June 2022 The Omicron variant (B.1.1.529) of SARS-CoV-2, the virus that causes COVID-19, was first identified in the United States in November 2021, with the BA.1 sublineage (including BA.1.1) causing the largest surge in COVID-19 cases to date. Omicron sublineages BA.2 and BA.2.12.1 emerged later and by late April 2022, accounted for most cases.* Estimates of COVID-19 vaccine effectiveness (VE) can be reduced by newly emerging variants or sublineages that evade vaccine-induced immunity (1), protection from previous SARS-CoV-2 infection in unvaccinated persons (2), or increasing time since vaccination (3). Real-world data comparing VE during the periods when the BA.1 and BA.2/BA.2.12.1 predominated (BA.1 period and BA.2/BA.2.12.1 period, respectively) are limited. The VISION network examined 214,487 emergency department/urgent care (ED/UC) visits and 58,782 hospitalizations with a COVID-19-like illness\u00a7 diagnosis among 10 states during December 18, 2021-June 10, 2022, to evaluate VE of 2, 3, and 4 doses of mRNA COVID-19 vaccines (BNT162b2 [Pfizer-BioNTech] or mRNA-1273 [Moderna]) compared with no vaccination among adults without immunocompromising conditions. VE against COVID-19-associated hospitalization 7-119 days and 120 days after receipt of dose 3 was 92% (95% CI = 91%-93%) and 85% (95% CI = respectively, during the BA.1 period, with 69% (95% CI = 58%-76%) and 52% (95% CI = 44%-59%), respectively, during the BA.2/BA.2.12.1 period. Patterns were similar for ED/UC encounters. Among adults aged 50 years, VE against COVID-19-associated hospitalization 120 days after receipt of dose 3 was 55% (95% CI = 46%-62%) and 7 days (median = 27 days) after a fourth dose was 80% (95% CI = 71%-85%) during BA.2/BA.2.12.1 predominance. Immunocompetent persons should receive recommended COVID-19 booster doses to prevent moderate to severe COVID-19, including a first booster dose for all eligible persons and second booster dose for adults aged 50 years at least 4 months after an initial booster dose. Booster doses should be obtained immediately when persons become eligible.\u00b6. 22;71(29):931-939. Epub 2022-07-22. Reach, acceptability, and perceived success of a telehealth diabetes prevention program among racially and ethnically diverse patients with gestational diabetes: the GEM cluster-randomized trial Patients with gestational diabetes mellitus and from racial/ethnic minority groups face disproportionate risk for type 2 diabetes. Lifestyle interventions, if accessible and acceptable to diverse patients, could advance diabetes prevention and mitigate racial/ethnic disparities. Here we describe overall and race/ethnicity-specific reach, acceptability, and perceived success from an effective telehealth diabetes prevention lifestyle program for patients with gestational diabetes mellitus, implemented in the Gestational Diabetes Effects on Moms (GEM) cluster-randomized controlled trial. GEM tested a program of 13 telephone sessions and behavior change techniques (BCTs, e.g., goal setting) in a healthcare system. We evaluated participation (completing 1 session), acceptability of BCTs, and perceived success reaching program goals. Among 1,087 patients (75.2% from minority groups), 50.3% participated. Participation rates were 61.7% among Black, 56.4% among Hispanic, 55.6% among multiracial/other, 53.0% among White, and 43.7% among Asian/Pacific Islander patients. Evaluation survey respondents (n = 433/547; 79.2%) largely rated BCTs as very helpful (range 40.9%-58.4%) or moderately helpful (27.3%-34.9%). Respondents from minority groups largely rated goal setting for weight management as very or moderately helpful, with fewer minority respondents rating it as only a little/not at all helpful than White respondents (p = .02). Black and White respondents reported more limited success reaching a healthy weight than Asian/Pacific Islander, Hispanic, and multiracial/other women (p = .005). A telehealth diabetes prevention lifestyle program demonstrated reach and acceptability across racial/ethnic groups. While perceived success can be improved among Black and White participants, such programs could promote access to preventive care and help mitigate disparities in diabetes risk. Authors: Brown, Susan D; Hedderson, Lessons from a mature acellular pertussis vaccination program and strategies to overcome suboptimal vaccine effectiveness Despite high vaccination coverage among children and adolescents, pertussis remains a public health problem, with large outbreaks occurring periodically in the US and other developed countries. We examine lessons learned more than 20 years after implementation of programs which use only acellular pertussis vaccines and propose avenues for possible effective use of acellular pertussis vaccine to prevent large outbreaks. Acellular pertussis vaccines were introduced more than 20 years ago, yet the incidence of pertussis has been increasing over the past decade, with periodic large outbreaks marked by notable shifts in disease burden from infants and young children toward fully vaccinated adolescents and young adults. This age shift is mainly driven by the waning of vaccine immunity. To better protect adolescents against pertussis, modification of the current acellular pertussis vaccination schedule or adoption of new vaccination strategies should be considered. For infants not yet eligible to be vaccinated, maternal vaccination against pertussis during pregnancy is an effective way to protect infants from infection, severe disease and death. Implementation of maternal vaccination programs should be encouraged in countries without one or efforts to improve coverage should be supported in countries with existing program. Authors: Zerbo, Ousseny; Fireman, Bruce; Epub 2021-10-08. A Web-Based mHealth Intervention With Telephone Support to Increase Physical Activity Among Pregnant Patients With Overweight or Obesity: Feasibility Randomized Controlled Trial Pregnant patients with overweight or obesity are at high risk for perinatal complications. Excess gestational weight gain (GWG) further exacerbates this risk. Mobile health (mHealth) lifestyle interventions that leverage technology to facilitate self-monitoring and provide just-in-time feedback may motivate behavior change to reduce excess GWG, reduce intervention costs, and increase scalability by improving access. This study aimed to test the acceptability and feasibility of a pilot mHealth lifestyle intervention for pregnant patients with overweight or obesity to promote moderate intensity physical activity (PA), encourage guideline-concordant GWG, and inform the design of a larger pragmatic cluster randomized controlled trial. We conducted a mixed methods acceptability and feasibility randomized controlled trial among pregnant patients with a prepregnancy BMI of 25 to 40 kg/m2. Patients with singletons at 8 to 15 weeks of gestation who were aged 21 years and had Wi-Fi access were recruited via email from 2 clinics within Kaiser Permanente Northern California and randomized to receive usual prenatal care or an mHealth lifestyle intervention. Participants in the intervention arm received wireless scales, access to an intervention website, activity trackers to receive automated feedback on weight gain and activity goals, and monthly calls from a lifestyle coach. Surveys and focus groups with intervention participants assessed intervention satisfaction and ways to improve the intervention. PA outcomes were self-assessed using the Pregnancy Physical Activity Questionnaire, and GWG was assessed using electronic health record data for both arms. Overall, 33 patients were randomly assigned to the intervention arm, and 35 patients were randomly assigned to the usual care arm. All participants in the intervention arm weighed themselves at least once a week, compared with 20% (7/35) of the participants in the usual care arm. Participants in the intervention arm wore the activity tracker 6.4 days per week and weighed themselves 5.3 times per week, and 88% (29/33) of them rated the program \"good to excellent.\" Focus groups found that participants desired more nutrition-related support to help them manage GWG and would have preferred an app instead of a website. Participants in the intervention arm had a 23.46 metabolic equivalent of task hours greater change in total PA per week and a 247.2-minute greater change in moderate intensity PA per week in unadjusted models, but these effects were attenuated in adjusted models (change in total PA: 15.55 metabolic equivalent of task hours per week; change in moderate intensity PA: 199.6 minutes per week). We found no difference in total GWG (mean difference 1.14 kg) compared with usual care. The pilot mHealth lifestyle intervention was feasible, highly acceptable, and promoted self-monitoring. Refined interventions are needed to effectively affect PA and GWG among pregnant patients with overweight or obesity. 22;6(6):e33929. Epub Risk of severe clinical outcomes among persons with SARS-CoV-2 infection with differing levels of vaccination during widespread Omicron (B.1.1.529) and Delta (B.1.617.2) variant circulation in Northern California: A retrospective cohort study The incidence of and risk factors for severe clinical outcomes with the Omicron (B.1.1.529) SARS-CoV-2 variant have not been well-defined. We conducted a retrospective cohort study to assess risks of severe clinical outcomes within 21 days after SARS-CoV-2 diagnosis in a large, diverse, integrated health system. Among 118,078 persons with incident SARS-CoV-2 infection, 48,101 (41%) were during the Omicron period and 69,977 (59%) during the Delta (B.1.617.2) period. Cumulative incidence of any hospitalization (2.4% versus 7.8%; adjusted hazard ratio [aHR] 0.55; (0.6% versus 2.8%; aHR 0.47; CI 0.41-0.54), with invasive mechanical ventilation (0.1% versus 0.7%; aHR 0.43; CI 0.33-0.56), and death (0.2% versus 0.7%; aHR 0.54; CI 0.42-0.70) were lower in the Omicron than the Delta period. The risk of hospitalization was higher among unvaccinated persons (aHR 8.34; CI 7.25-9.60) and those who completed a primary COVID-19 vaccination series (aHR 1.72; CI 1.49-1.97) compared with those who completed a primary vaccination series and an additional dose. The strongest risk factors for all severe clinical outcomes were older age, higher body mass index and select comorbidities. Persons with SARS-CoV-2 infection were significantly less likely to develop severe clinical outcomes during the Omicron period compared with the Delta period. COVID-19 primary vaccination and additional doses were associated with reduced risk of severe clinical outcomes among those with SARS-CoV-2 infection. National Cancer Institute and The Permanente Medical Group. Skarbinski, Lancet Health Am. 2022 Jun 16:100297. Association of Physician Adenoma Detection Rates With Postcolonoscopy Colorectal Cancer Although colonoscopy is frequently performed in the United States, there is limited evidence to support threshold values for physician adenoma detection rate as a quality metric. To evaluate the association between physician adenoma detection rate values and risks of postcolonoscopy colorectal cancer and related deaths. Retrospective cohort study in 3 large integrated health care systems (Kaiser Permanente Northern California, Kaiser Permanente Southern California, and Kaiser Permanente Washington) with 43 endoscopy centers, 383 eligible physicians, and 735 396 patients aged 50 to 75 years who received a colonoscopy that did not detect cancer (negative colonoscopy) between January 2011 and June 2017, with patient follow-up through December 2017. The adenoma detection rate of each patient's physician based on screening examinations in the calendar year prior to the patient's negative colonoscopy. Adenoma detection rate was defined as a continuous variable in statistical analyses and was also dichotomized as at or above vs below the median for descriptive analyses. The primary outcome (postcolonoscopy colorectal cancer) was tumor registry-verified colorectal adenocarcinoma diagnosed at least 6 months after any negative colonoscopy (all indications). The secondary outcomes included death from postcolonoscopy colorectal cancer. Among 735 396 patients who had 852 624 negative colonoscopies, 440 352 (51.6%) were performed on female patients, median patient age was 61.4 years (IQR, 55.5-67.2 years), median follow-up per patient was 3.25 years (IQR, 1.56-5.01 years), and there were 619 postcolonoscopy colorectal cancers and 36 related deaths during more than 2.4 million person-years of follow-up. The patients of physicians with higher adenoma detection rates had significantly lower risks for postcolonoscopy colorectal cancer (hazard ratio [HR], 0.97 per 1% absolute adenoma detection rate increase [95% CI, 0.96-0.98]) and death from postcolonoscopy colorectal cancer (HR, 0.95 per 1% absolute adenoma detection rate increase [95% CI, 0.92-0.99]) across a broad range of adenoma detection rate values, with no interaction by sex (P value for interaction = .18). Compared with adenoma detection rates below the median of 28.3%, detection rates at or above the median were significantly associated with a lower risk of postcolonoscopy colorectal cancer (1.79 vs 3.10 cases per 10 000 person-years; absolute difference in 7-year risk, -12.2 per 10 000 colonoscopies to -13.4]; HR, 0.61 [95% CI, 0.52-0.73]) and related deaths (0.05 vs 0.22 cases per 10 000 person-years; absolute difference in 7-year risk, -1.2 per 10 000 negative colonoscopies [95%, CI, -0.80 to -1.69]; HR, 0.26 [95% CI, 0.11-0.65]). Within 3 large community-based settings, colonoscopies by physicians with higher adenoma detection rates were significantly associated with lower risks of postcolonoscopy colorectal cancer across a broad range of adenoma detection rate values. These findings may help inform recommended targets for colonoscopy quality measures. Authors: Schottinger, Joanne E; of guideline-recommended postpartum diabetes screening among diverse women with gestational diabetes: associations with patient factors in an integrated health system in USA Clinical guidelines urge timely postpartum screening for diabetes among women with gestational diabetes mellitus (GDM), yet patient factors associated with screening uptake remain unclear. We aimed to identify patient factors associated with completed postpartum diabetes screening (2-hour oral glucose tolerance test within 4-12 weeks postpartum), as recommended by the American Diabetes Association (ADA). Within the context of Gestational Diabetes' Effects on Moms (GEM), a pragmatic cluster randomized trial (2011-2012), we examined survey and electronic health record data to assess clinical and sociodemographic factors associated with uptake of ADA-recommended postpartum screening. Participants included 1642 women (76% racial/ethnic minorities) identified with GDM according to the Carpenter and Coustan criteria in a health system that deploys population-level strategies to promote screening. To contextualize these analyses, screening rates derived from the GEM trial were compared with those in the health system overall using registry data from a concurrent 10-year period (2007-2016, n=21 974). Overall 52% (n=857) completed recommended postpartum screening in the analytic sample, comparable to 45.7% (n=10 040) in the registry. Screening in the analytic sample was less likely among women at elevated risk for type 2 diabetes, assessed using items from an ADA risk test (vs non-elevated; adjusted rate ratio (aRR)=0.86 (95% CI 0; 0.80 to 0.93)); or less than college education (0.79 (0.72 to 0.86)). Screening was more likely among Chinese Americans (vs White; 1.31 (1.15 to 1.49)); women who attended a routine postpartum visit (5.28 (2.99 to 9.32)); or women who recalled receiving healthcare provider advice about screening (1.31 (1.03 to 1.67)). Guideline-recommended postpartum diabetes screening varied by patient clinical and sociodemographic factors. Findings have implications for developing future strategies to improve postpartum care. Authors: Brown, Susan Res Care. 2022 06;10(3). Effect of Electronic and Mail Outreach From Primary Care Physicians for COVID-19 Vaccination of Black and Latino Older Adults: A Randomized Clinical Trial COVID-19 morbidity is highest in Black and Latino older adults. These racial and ethnic groups initially had lower vaccination uptake than others, and rates in Black adults continue to lag. To evaluate the effect of outreach via electronic secure messages and mailings from primary care physicians (PCPs) on COVID-19 vaccination uptake among Black and Latino older adults and to compare the effects of culturally tailored and standard PCP messages. This randomized clinical trial was conducted from March 29 to May 20, 2021, with follow-up surveys through July 31, 2021. Latino and Black individuals aged 65 years and older from 4 Kaiser Permanente Northern California (KPNC) service areas were included. Data were analyzed from May 27, 2021, to September 28, 2021. Individuals who had not received COVID-19 vaccination after previous outreach were randomized to electronic secure message and/or mail outreach from their PCP, similar outreach with additional culturally tailored content, or usual care. Outreach groups were sent a secure message or letter in their PCP's name, followed by a postcard to those still unvaccinated after 4 weeks. The primary outcome was time to receipt of COVID-19 vaccination during the 8 weeks after initial study outreach. KPNC data were supplemented with state data from external sources. Intervention effects were evaluated via proportional hazards regression. Of 8287 included individuals (mean and preferred English-language communications, and 2071 were Latino and preferred Spanish-language communications; 2847 participants (34.4%) had a neighborhood deprivation index at the 75th percentile or higher. A total of 2767 participants were randomized to culturally tailored PCP outreach, 2747 participants were randomized to standard PCP outreach, and 2773 participants were randomized to usual care. Culturally tailored PCP outreach led to higher COVID-19 vaccination rates during follow-up compared with usual care (664 participants [24.0%] vs 603 participants [21.7%]; adjusted hazard ratio (aHR), 1.22; 95% CI, 1.09-1.37), as did standard PCP outreach (635 participants [23.1%]; aHR, 1.17; 95% CI, 1.04-1.31). Individuals who were Black (aHR, 1.19; 95% CI, 1.06-1.33), had high neighborhood deprivation (aHR, 1.17; 95% CI, 1.03-1.33), and had medium to high comorbidity scores (aHR, 1.19; 95% CI, 1.09-1.31) were more likely to be vaccinated during follow-up. This randomized clinical trial found that PCP outreach using electronic and mailed messages increased COVID-19 vaccination rates among Black and Latino older adults. ClinicalTrials.gov Identifier: NCT05096026. Trends in Cannabis Polysubstance Use During Early Pregnancy Among Patients in a Large Health Care System in Northern California Rates of prenatal cannabis use are increasing alongside perceptions that cannabis is a harmless therapeutic for pregnancy-related ailments, while rates of prenatal use of alcohol and tobacco are decreasing. It is important to examine whether cannabis use during pregnancy is increasing similarly among patients with and patients without co-occurring substance use. To examine trends in cannabis polysubstance use during pregnancy and to test differences in cannabis use over time among pregnant individuals who use only cannabis vs those who use cannabis and other substances. This cross-sectional time-series study used data from 367 138 pregnancies among 281 590 unique pregnant patients universally screened for prenatal substance use as part of standard care in Kaiser Permanente Northern California from January 1, 2009, to December 31, 2018. Statistical analysis was performed from October 5, 2021, to April 18, 2022. Time (calendar year). Use of substances during early pregnancy was assessed via universal screening with a self-administered questionnaire (for cannabis, alcohol, stimulants, and nicotine) and/or positive results of a urine toxicology test (for cannabis, alcohol, stimulants, and pharmaceutical opioids), and data were extracted from the electronic health record. The study sample of 367 138 pregnancies from 281 590 unique pregnant patients (median gestation at time of screening, 8.6 weeks [IQR, 7.3-10.6 weeks]) was 25.9% Asian or Pacific Islander, 6.6% Black, 25.8% Hispanic, 38.0% non-Hispanic White, and 3.6% other race or ethnicity; 1.1% were aged 11 to 17 years, 14.9% were aged 18 to 24 years, 61.9% were aged 25 to 34 years, and 22.1% were aged 35 years or older; and the median neighborhood household income was $70 455 (IQR, $51 563-$92 625). From 2009 to 2018, adjusted rates of use of only cannabis during pregnancy (no other substances) increased substantially from 2.39% (95% CI, 2.20%-2.58%) in 2009 to 6.30% (95% CI, 6.00%-6.60%) in 2018, increasing at an annual relative rate of 1.11 (95% CI, 1.10-1.12). The rate of use of cannabis and 1 other substance also increased (annual relative rate, 1.04 [95% CI, 1.03-1.05]), but not as rapidly (P < .001 for difference), while the rate of use of cannabis and 2 or more other substances decreased slightly (annual relative rate, 0.97 [95% CI, 0.96-0.99]). Adjusted rates of prenatal use of cannabis and alcohol (1.04 [95% CI, 1.03-1.06]) and cannabis and stimulants (1.03 [95% CI, 1.01-1.06]) increased over time, while rates of prenatal use of cannabis and nicotine (0.97 [95% CI, 0.96-0.98]) decreased. In this cross-sectional time-series study, rates of prenatal cannabis use during early pregnancy increased significantly more rapidly among patients without co-occurring substance use, which could reflect increased acceptability of cannabis and decreased perceptions of cannabis-related harms. Furthermore, increased rates of use of cannabis with alcohol and stimulants warrant continued monitoring. Authors: Epub 2022-06-01. Perspectives on Postpartum Diabetes Screening among Patients with Gestational Diabetes in an Integrated Healthcare System Authors: Glaser, Katherine; Ferrara, Assiamira; 06;226(6):857-859.e1. Epub 2022-02-12. Predicting obstructive sleep apnea severity in children referred for polysomnography: use of the Pediatric Sleep Questionnaire and Subscales This study evaluated the role of the Pediatric Sleep Questionnaire (PSQ) and associated subscales in predicting the severity of obstructive sleep apnea (OSA) in children referred for attended polysomnography (PSG). This is a retrospective study of children (0-18 years) who completed PSQs the night of their initial diagnostic PSG (2019-2020). We excluded children with previous PSG, positive airway pressure titrations, or underlying genetic or craniofacial syndromes. Area under the receiver operating characteristic curve (AUC [95%CIs]) were estimated for prediction of varying severities of obstructive apnea-hypopnea index (oAHI > 2, 5, 10, and 25/h) by the PSQ's sleep-related breathing disorders (SRBD) scale and subscales. Of 477 children, median (IQR) age at PSG was 5.7 (4.3); 60% of children were male, obese, and 4% had oAHI > 25/h. SRBD score did not improve discrimination of OSA cases at any oAHI threshold, with AUC CI that crossed 50% at all severities. Snoring subscale scores were predictive at but were not predictive at oAHI > 25/h. The addition of demographic data (age and gender) improved the classification of the SRBD scale. When utilized in children referred for attended PSG due to concerns for an underlying sleep disorder, the PSQ snoring subscale was more predictive of OSA at varying thresholds than the SRBD scale. While the original intent of the PSQ was not for the purpose of predicting severity in children referred for PSG, future directions include augmenting the questionnaire with additional clinical Authors: M Cespedes Sleep Breath. 2022 May 28. Risk of Cardiovascular Disease in Women With and Without Breast Cancer: The Pathways Heart Study To examine cardiovascular disease (CVD) and mortality risk in women with breast cancer (BC) by cancer therapy received relative to women without BC. The study population comprised Kaiser Permanente Northern California members. Cases with invasive BC diagnosed from 2005 to 2013 were matched 1:5 to controls without BC on birth year and race/ethnicity. Cancer treatment, CVD outcomes, and covariate data were from electronic health records. Multivariable Cox proportional hazards models estimated hazard ratios (HRs) and 95% CIs of CVD incidence and mortality by receipt of chemotherapy treatment combinations, radiation therapy, and endocrine therapy. A total of 13,642 women with BC were matched to 68,202 controls without BC. Over a 7-year average follow-up (range < 1-14 years), women who received anthracyclines and/or trastuzumab had high risk of heart failure/cardiomyopathy relative to controls, with the highest risk seen in women who received both anthracyclines and trastuzumab (HR, 3.68; 95% CI, 1.79 to 7.59). High risk of heart failure and/or cardiomyopathy was also observed in women with BC with a history of radiation therapy (HR, 1.38; 95% CI, 1.13 to 1.69) and aromatase inhibitor use (HR, 1.31; 95% CI, 1.07 to 1.60), relative to their controls. Elevated risks for stroke, arrhythmia, cardiac arrest, venous thromboembolic disease, CVD-related death, and death from any cause were also observed in women with BC on the basis of cancer treatment received. Women with BC had increased incidence of CVD events, CVD-related mortality, and all-cause mortality compared with women without BC, and risks varied according to the history of cancer treatment received. Studies are needed to determine how women who received BC treatment should be cared for to improve cardiovascular outcomes. Risk of Cardiometabolic Risk Factors in Women With and Without a History of Breast Cancer: The Pathways Heart Study The incidence of cardiometabolic risk factors in breast cancer (BC) survivors has not been well described. Thus, we compared risk of hypertension, diabetes, and dyslipidemia in women with and without BC. Women with invasive BC diagnosed from 2005 to 2013 at Kaiser Permanente Northern California (KPNC) were identified and matched 1:5 to noncancer controls on birth year, race, and ethnicity. Cumulative incidence rates of hypertension, diabetes, and dyslipidemia were estimated with competing risk of overall death. Subdistribution hazard ratios (sHRs) were estimated by Fine and Gray regression, adjusted for cardiovascular disease-related risk factors, and stratified by treatment and body mass index (BMI). A total of 14,942 BC cases and 74,702 matched controls were identified with mean age 61.2 years and 65% non-Hispanic White. Compared with controls, BC cases had higher cumulative incidence rates of hypertension (10.9% v 8.9%) and diabetes (2.1% v 1.7%) after 2 years, with higher diabetes incidence persisting after 10 years (9.3% v 8.8%). In multivariable models, cases had higher risk of diabetes (sHR, 1.16; 95% CI, 1.07 to 1.26) versus controls. Cases treated with chemotherapy (sHR, 1.23; 95% CI, 1.11 to 1.38), left-sided radiation (sHR, 1.13 to 1.48), or endocrine therapy (sHR, 1.23; 95% CI, 1.12 to 1.34) continued to have higher diabetes risk. Hypertension risk was higher for cases receiving left-sided radiation (sHR, 1.11; 95% CI, 1.03 to 1.16). Normal-weight (BMI < 24.9 kg/m2) cases had higher risks overall and within treatment subgroups versus controls. BC survivors at KPNC experienced elevated risks of diabetes and hypertension compared with women without BC depending on treatments received and BMI. Future studies should examine strategies for cardiometabolic risk factor prevention in BC survivors. 2022-01-13. Exploratory analysis of novel electronic health record variables for quantification of healthcare delivery strain, prediction of mortality, and prediction of imminent discharge To explore the relationship between novel, time-varying predictors for healthcare delivery strain (eg, counts of patient orders per hour) and imminent discharge and in-hospital mortality. We conducted a retrospective cohort study using data from adults hospitalized at 21 Kaiser Permanente Northern California hospitals between November 1, 2015 and October 31, 2020 and the nurses caring for them. Patient data extracted included demographics, diagnoses, severity measures, occupancy metrics, and process of care metrics (eg, counts of intravenous drip orders per hour). We linked these data to individual registered nurse records and created multiple dynamic, time-varying predictors (eg, mean acute severity of illness for all patients cared for by a nurse during a given hour). All analyses were stratified by patients' initial hospital unit (ward, stepdown unit, or intensive care unit). We used discrete-time hazard regression to assess the association between each novel time-varying predictor and the outcomes of discharge and mortality, separately. Our dataset consisted of 84 162 161 hourly records from 954 477 hospitalizations. Many novel time-varying predictors had strong associations with the 2 study outcomes. However, most of the predictors did not merely track patients' severity of illness; instead, many of them only had weak correlations with severity, often with complex relationships over time. Increasing availability of process of care data from automated electronic health records will permit better quantification of healthcare delivery strain. This could result in enhanced prediction of adverse outcomes and service delays. New conceptual models will be needed to use these new data elements. Authors: Lee, Catherine; Lawson, Brian L; Mann, Ariana J; Liu, Vincent X; Myers, Laura C; Schuler, Alejandro; Escobar, Gabriel J J Am Med Inform Assoc. 2022 05 11;29(6):1078-1090. Effect of Lifestyle Coaching or Enhanced Pharmacotherapy on Blood Pressure Control Among Black Adults With Persistent Uncontrolled Hypertension: A Cluster Randomized Clinical Trial Greater difficulty in controlling blood pressure (BP) and adverse lifestyle practices such as higher salt intake or less physical activity may account for some of the differences between BP control rates in Black vs White adults, thereby exposing Black adults to a higher risk of vascular events. To determine whether a lifestyle coaching intervention or an enhanced pharmacotherapy protocol is more effective than usual care in improving BP control rates in Black adults treated within an integrated health care delivery system. Shake, Rattle & Roll, a cluster randomized clinical trial, was conducted from June 5, 2013, to June 11, 2018, in a large integrated health care delivery system. Enrollment was completed during a 12-month period and interventions were implemented for 12 months. Follow-up lasted 48 months after enrollment. Panels of Black adult members of the health care delivery system with BP of at least 140/90 mm Hg from 98 adult primary care physicians were randomly assigned at the primary care physician level to usual care (UC group [n = 1129]), enhanced pharmacotherapy monitoring (EP group [n = 346]) of current BP management protocol, or diet and lifestyle coaching consisting of photographs, stories, and recipes, for example, that are appropriate for Black adults (LC group [n = 286]) focused on the Dietary Approaches to Stop Hypertension (DASH) diet. Data were analyzed from June 1, 2016, to March 25, 2022. The UC group received care per customary protocol. The EP group was contacted by a research nurse and/or a clinical pharmacist to discuss barriers to hypertension control, and drug therapy emphasized the use of thiazide diuretic intensification and addition of spironolactone as needed. The LC group received as many as 16 telephone sessions with a lifestyle coach and an emphasis on implementing reduction of sodium intake and the DASH diet. Intention-to-treat analysis of BP control rates at end of the 12-month intervention. Among the 1761 participants, the mean (SD) age was 61 (13) years, and 1214 (68.9%) were women. At the end of the 12-month intervention period, there was no significant difference in BP control rate among study groups (UC, 61.8% EP, P = .07). However, greater BP control was present in the LC group vs UC at 24 months (UC, P months vs UC, P = .006) after enrollment. The contribution of BP medication adherence to explain group differences was inconclusive. In this cluster randomized clinical trial including Black adults with persistent uncontrolled hypertension, a 12-month LC intervention was more effective at controlling BP than UC at 24 and 48 months after enrollment. Further research is needed to explore the potential implementation of this intervention into clinical practice. ClinicalTrials.gov Identifier: 02;5(5):e2212397. Contribution Risk Factors to Racial-Ethnicity Disparities in Preterm Birth Subtypes There are recognized racial-ethnic disparities in preterm birth and in maternal cardiometabolic risk factors likely linked to systemic racism. However, it is unclear the extent to which cardiometabolic risk factors contribute to the higher rates of preterm birth among minoritized populations. This study aimed to evaluate racial-ethnic disparities in preterm birth subtypes and the role of maternal cardiometabolic risk factors as mediators of the association between maternal race-ethnicity and preterm birth subtypes. This was a retrospective cohort study of 295,210 singleton live births from 2011 to 2018. Preterm birth subtypes were defined as medically indicated and spontaneous preterm birth. Poisson regression with robust standard errors were used to provide estimates of the relative risks and 95% confidence intervals for preterm birth subtypes. Causal mediation analysis used logistic regression models to estimate the natural direct and natural indirect (mediated) effects of maternal cardiometabolic risk factors. Compared with White individuals, Black, Asian, and Hispanic individuals were at increased risk for having both medically indicated preterm birth (1.45, 1.30-1.61; 1.21, 1.12-1.31; and 1.13, 1.05-1.22, respectively) (risk ratios, 95% confidence intervals, respectively) and spontaneous preterm birth (1.20, 1.08-1.34; 1.34, 1.26-1.43; and 1.16, (1.08-1.23), independent of established risk factors. The extent to which cardiometabolic risk factors mediated the associations between race-ethnicity (each group vs White in separate analyses) and preterm birth subtypes varied by race-ethnicity. Hypertensive disorders mediated 30.1% of the association between Black race-ethnicity and medically indicated preterm birth, but it did not mediate the association for other racial-ethnic groups or for spontaneous preterm birth. Any glucose disorder in pregnancy was a mediator of medically indicated preterm birth and spontaneous preterm birth for Asian (65.8% and 13.9%, respectively) and Hispanic (17.3% and 11.9%) race-ethnicity but not for Black race-ethnicity. Overweight or obesity mediated the association between race-ethnicity and medically indicated preterm birth (15.5% among Black individuals and 25.1% among Hispanic individuals) and spontaneous preterm birth (10.7% among Hispanic individuals) but was not a mediator among Asian individuals. Black, Asian, and Hispanic individuals are at increased risk for preterm birth. Maternal cardiometabolic risk factors partially mediate the associations between race-ethnicity and preterm birth subtypes but the extent varies by race-ethnicity. These findings suggest that strategies that improve and diminish differences in cardiometabolic health between race-ethnicity populations may diminish disparities 05;4(3):100608. Epub 2022-03-04. Association between residential green cover and direct healthcare costs in Northern California: An individual level analysis of 5 million persons Prior studies have shown higher green cover levels are associated with beneficial health outcomes. We sought to determine if residential green cover was also associated with direct healthcare costs. We linked residential Normalized Difference Vegetation Index (NDVI) satellite data for 5,189,303 members of Kaiser Permanente Northern California (KPNC) to direct individual healthcare costs for 2003-2015. Using generalized linear regression to adjust for confounding, we examined the association between direct healthcare costs and green cover within250, 500, and 1000 meters (m) of an individual's residence. Costs were determined from an internal cost accounting system that captures administrative and patient care costs for each clinical encounter. Sensitivity analyses included adjustments for comorbidity and an alternative measure of green cover, tree canopy. We observed a significant inverse association between higher levels of residential green cover and lower direct healthcare costs. The relative rate of total cost for the highest compared to the lowest decile of NDVI was 0.92 (95% CI 0.90-0.93) for the 500 m buffer. The association was robust to adjustment from a broad array of confounders, found at each buffer size, and largely driven by hospitalization, and emergency department visits. Individuals in the top decile of residential green cover had adjusted healthcare costs of $374.04 (95% CI $307.31-$439.41) per person per year less than individuals living in the bottom or least green decile. Sensitivity analyses including tree canopy cover as the green space measure yielded similar findings. Analyses that included adjustment for comorbidity were consistent with the hypothesis that green cover reduces healthcare costs by improving health status. Green cover was associated with lower direct healthcare costs, raising the possibility that residential greening can have a significant healthcare cost impact across the population. Authors: Van Den Eeden, Stephen K; H E M Becker, 2022-03-17. Perinatal Complications in Individuals in California With or Without SARS-CoV-2 Infection During Pregnancy Additional research from population-based studies is needed to inform the treatment of SARS-CoV-2 infection during pregnancy and to provide health risk information to pregnant individuals. To assess the risk of perinatal complications associated with SARS-CoV-2 infection and to describe factors associated with hospitalizations. This population-based cohort study included 43 886 pregnant individuals with longitudinal electronic health record data from preconception to delivery who delivered at Kaiser Permanente Northern California between March 1, 2020, and March 16, 2021. Individuals with diagnostic codes for COVID-19 that did not have a confirmatory polymerase chain reaction test for SARS-CoV-2 were excluded. SARS-CoV-2 infection detected by polymerase chain reaction test (from 30 days before conception to 7 days after delivery) as a time varying exposure. Severe maternal morbidity including 21 conditions (eg, acute myocardial infarction, acute renal failure, acute respiratory distress syndrome, and sepsis) that occurred at any time during pregnancy or delivery; delivery; and newborn birth weight and respiratory conditions. Standardized mean differences between individuals with and without SARS-CoV-2 were calculated. Cox proportional hazards regression was used to estimate the hazard ratios (HRs) and 95% CIs for the association between SARS-CoV-2 infection and perinatal complications and hospitalization and to consider the timing of SARS-CoV-2 infection relative to outcomes. In this study of 43 886 pregnant individuals (mean [SD] age, 30.7 [5.2] years), individuals with a SARS-CoV-2 infection (1332 [3.0%]) were more likely to be younger, Hispanic, multiparous individuals with a higher neighborhood deprivation index and obesity or chronic hypertension. After adjusting for demographic characteristics, comorbidities, and smoking status, individuals with SARS-CoV-2 infection had higher risk for severe maternal morbidity (HR, 2.45; 95% CI, than individuals without SARS-CoV-2. SARS-CoV-2 infection was also associated with increased risk of medically indicated preterm birth (HR, 2.56; 95% CI, 2.06-3.19); spontaneous preterm (HR, 95% CI, preterm birth. Among individuals with SARS-CoV-2 (5.7%) a hospitalization; pregestational diabetes (HR, 7.03; 95% CI, 2.22-22.2) and Asian or Pacific Islander (HR, 2.33; 95% CI, 1.06-5.11) and Black (HR, 3.14; 95% CI, 1.24-7.93) race and ethnicity were associated with an increased risk of hospitalization. In this cohort study, SARS-CoV-2 infection was associated with increased risk of severe maternal morbidity, preterm birth, and VTE. The study findings inform clinicians and patients about the risk of perinatal complications associated with SARS-CoV-2 infection in pregnancy and support vaccination of pregnant individuals and those planning conception. Jenna 01;182(5):503-512. Safety of measles and pertussis-containing vaccines in children with autism spectrum disorders To determine whether children aged 4-7 years with a diagnosis of autism spectrum disorders (ASD) were at increased risk of fever, febrile seizures, or emergency department (ED) visits following measles- or pertussis-containing vaccines compared with children without ASD. The study included children born between 1995-2012, aged 4-7 years at vaccination, and members of six healthcare delivery systems within Vaccine Safety Datalink. We conducted self-controlled risk interval analyses comparing rates of outcomes in risk and control intervals within each group defined by ASD status, and then compared outcome rates between children with and without ASD, in risk and control intervals, by estimating difference-in-differences using logistic regressions. The study included 14,947 children with ASD and 1,650,041 children without ASD. After measles- or pertussis-containing vaccination, there were no differences in association between children with and without ASD for fever (ratio of rate ratio for measles-containing vaccine = 1.07, 95% CI 0.58-1.96; for pertussis-containing vaccine = 1.16, 95% CI 0.63-2.15) or ED visits (ratio of rate ratio for measles-containing vaccine = 1.11, 95% CI 0.80-1.54; for pertussis-containing vaccine 0.87, 95% CI 0.59-1.28). Febrile seizures were rare. Pertussis-containing vaccines were associated with small increased risk of febrile seizures in children without ASD. Children with ASD were not at increased risk for fever or ED visits compared with children without ASD following measles- or pertussis-containing vaccines. These results may provide further reassurance that these vaccines are safe for all children, including those with ASD. Authors: Zerbo, Ousseny; Fireman, Bruce; 20;40(18):2568-2573. Epub 2022-03-18. Incidence of Guillain-Barr\u00e9 Syndrome After COVID-19 Vaccination in the Vaccine Safety Datalink Postauthorization monitoring of vaccines in a large population may detect rare adverse events not identified in clinical trials such as Guillain-Barr\u00e9 syndrome (GBS), which has a background rate of 1 to 2 per 100 000 person-years. To describe cases and incidence of GBS following COVID-19 vaccination and assess the risk of GBS after vaccination for Ad.26.COV2.S (Janssen) and mRNA vaccines. This cohort study used surveillance data from the Vaccine Safety Datalink at 8 participating integrated health care systems in the United States. There were 10 158 003 participants aged at least 12 years. Data analysis was performed from November 2021 to February 2022. Ad.26.COV2.S, BNT162b2 (Pfizer-BioNTech), or mRNA-1273 (Moderna) COVID-19 vaccine, including mRNA vaccine doses 1 and 2, December 13, 2020, to November 13, 2021. GBS with symptom onset in the 1 to 84 days after vaccination, confirmed by medical record review and adjudication. Descriptive characteristics of confirmed cases, GBS incidence rates during postvaccination risk intervals after each type of vaccine compared with the background rate, rate ratios (RRs) comparing GBS incidence in the 1 to 21 vs 22 to 42 days postvaccination, and RRs directly comparing risk of GBS after Ad.26.COV2.S vs mRNA vaccination, using Poisson regression adjusted for age, sex, race and ethnicity, site, and calendar day. From December 13, 2020, through November 13, 2021, 15 120 073 doses of COVID-19 vaccines were administered to 7 894 989 individuals (mean [SE] age, 46.5 [0.02] years; 8 138 318 doses received [53.8%] by female individuals; 3 671 199 doses received [24.3%] by Hispanic or Latino individuals, 2 215 064 doses received [14.7%] by Asian individuals, 6 266 424 doses received [41.4%] by White individuals), including 483 053 Ad.26.COV2.S doses, 8 806 595 BNT162b2 doses, and 5 830 425 mRNA-1273 doses. Eleven cases of GBS after Ad.26.COV2.S were confirmed. The unadjusted incidence rate of GBS per 100 000 person-years in the 1 to 21 days after Ad.26.COV2.S was 32.4 (95% CI, 14.8-61.5), significantly higher than the background rate, and the adjusted RR in the 1 to 21 vs 22 to 42 days following Ad.26.COV2.S was 6.03 (95% CI, 0.79-147.79). Thirty-six cases of GBS after mRNA vaccines were confirmed. The unadjusted incidence rate per 100 000 person-years in the 1 to 21 days after mRNA vaccines was 1.3 (95% CI, 0.7-2.4) and the adjusted RR in the 1 to 21 vs 22 to 42 days following mRNA vaccines was 0.56 (95% CI, 0.21-1.48). In a head-to-head comparison of Ad.26.COV2.S vs mRNA vaccines, the adjusted RR was 20.56 (95% CI, 6.94-64.66). In this cohort study of COVID-19 vaccines, the incidence of GBS was elevated after receiving the Ad.26.COV2.S vaccine. Surveillance is ongoing. Authors: Hanson, Kayla Joint associations between neighborhood walkability, greenness, and particulate air pollution on cardiovascular mortality among adults with a history of stroke or acute myocardial infarction Fine particulate matter (PM2.5) is a known risk factor for cardiovascular disease (CVD). Neighborhood walkability and greenness may also be associated with CVD, but there is limited evidence on their joint or interacting effects with PM2.5. Cox proportional hazard models were used to estimate the risk of CVD mortality among adults with a history of acute myocardial infarction and/or stroke living in Northern California. We assessed the independent and joint effects of walkability, greenness (Normalized Differentiated Vegetation Index [NDVI]), and PM2.5 at residential addresses, controlling for age, sex, race/ethnicity, comorbidities, BMI, smoking, revascularization, medications, and socioeconomic status. Greenness had a nonlinear association with CVD mortality (P = 0.038), with notably protective effects (HR = 0.87 [95% confidence interval {CI} = 0.78, 0.97]) at higher greenness levels (NDVI 0.3) and moderate attenuation after adjusting for PM2.5 (HR = 0.92 [95% CI = 0.82, 1.03]) per 0.1 increase in NDVI. Walkability had no independent effect on CVD mortality. PM2.5 had a strong independent effect in models adjusted for greenness and walkability (HR = 1.20 [95% CI = 1.08, 1.33)) per 10 g/m3 increase in PM2.5. There was an interaction between walkability and PM2.5 (P = 0.037), where PM2.5 had slightly stronger associations in more walkable than less walkable neighborhoods (HR = 1.23 [95% CI = 1.06, 1.42] vs. 1.17 [95% CI = 1.04, 1.32]) per 10 g/m3 increase in PM2.5. Greenness had no interaction with PM2.5 (P = 0.768) nor walkability (P = 0.385). High greenness may be protective of CVD mortality among adults with CVD history. PM2.5 associated CVD mortality risk varies slightly by level of neighborhood walkability, though these small differences may not be clinically meaningful. Authors: Liao NS; Van Booster Doses Following 1 Ad.26.COV2.S (Janssen [Johnson & Johnson]) Vaccine Dose Against COVID-19-Associated Emergency Department and Urgent Care Encounters and Hospitalizations Among Adults - VISION Network, 10 States, December 2021-March 2022 CDC recommends that all persons aged 18 years receive a single COVID-19 vaccine booster dose 2 months after receipt of an Ad.26.COV2.S (Janssen [Johnson & Johnson]) adenovirus vector-based primary series vaccine; a heterologous COVID-19 mRNA vaccine is preferred over a homologous (matching) Janssen vaccine for booster vaccination. This recommendation was made in light of the risks for rare but serious adverse events following receipt of a Janssen vaccine, including thrombosis with thrombocytopenia syndrome and Guillain-Barr\u00e9 syndrome (1), and clinical trial data indicating similar or higher neutralizing antibody response following heterologous boosting compared with homologous boosting (2). Data on real-world vaccine effectiveness (VE) of different booster strategies following a primary Janssen vaccine dose are limited, particularly during the period of Omicron variant predominance. The VISION Network\u00a7 determined real-world VE of 1 Janssen vaccine dose and 2 alternative booster dose strategies: 1) a homologous booster (i.e., 2 Janssen doses) and 2) a heterologous mRNA booster (i.e., 1 Janssen dose/1 mRNA dose). In addition, VE of these booster strategies was compared with VE of a homologous booster following mRNA primary series vaccination (i.e., 3 mRNA doses). The study examined 80,287 emergency department/urgent care (ED/UC) visits\u00b6 and 25,244 hospitalizations across 10 states during December 16, 2021-March 7, 2022, when Omicron was the predominant circulating variant.** VE against laboratory-confirmed COVID-19-associated ED/UC encounters was 24% after 1 Janssen dose, 54% after 2 Janssen doses, 79% after 1 Janssen/1 mRNA dose, and 83% after 3 mRNA doses. VE for the same vaccination strategies against laboratory-confirmed COVID-19-associated hospitalizations were 31%, 67%, 78%, and 90%, respectively. All booster strategies provided higher protection than a single Janssen dose against ED/UC visits and hospitalizations during Omicron variant predominance. Vaccination with 1 Janssen/1 mRNA dose provided higher protection than did 2 Janssen doses against COVID-19-associated ED/UC visits and was comparable to protection provided by 3 mRNA doses during the first 120 days after a booster dose. However, 3 mRNA doses provided higher protection against COVID-19-associated hospitalizations than did other booster strategies during the same time interval since booster dose. All adults who have received mRNA vaccines for their COVID-19 primary series vaccination should receive an mRNA booster dose when eligible. Adults who received a primary Janssen vaccine dose should preferentially receive a heterologous mRNA vaccine booster dose 2 months later, or a homologous Janssen vaccine booster dose if mRNA vaccine is contraindicated or unavailable. Further investigation of the durability of protection afforded by different booster strategies is warranted. Authors: Natarajan, Karthik; telemedicine during the COVID-19 pandemic: patient's choice of video versus telephone visit The aim of this study is to examine the association between patient characteristics and primary care telemedicine choice among integrated delivery system patients self-scheduling visits during the COVID-19 pandemic. We used multivariate logistic regression to examine the association between the choice of video versus telephone and patient sociodemographic characteristics and technology access among patient-initiated primary care telemedicine visits scheduled online from March to October 2020. Among 978 272 patient-scheduled primary care telemedicine visits, 39% were video visits. Patients of Black or Hispanic race/ethnicity, or living in low socioeconomic status or low internet access neighborhoods were less likely to schedule video visits. Patients 65 years or older, with prior video visit experience or mobile portal access, or visiting their own personal provider were more likely to schedule video visits. While video adoption was substantial in all patient groups examined, differences in telemedicine choice suggest the persistence of a digital divide, emphasizing the importance of maintaining a telephone telemedicine of rashes by primary care physicians and dermatologists For patients with a rash, the effect of teledermatology workflow on utilization has not been defined. We compared utilization across four teledermatology workflows in patients with a rash. The observational longitudinal cohort study included 28,857 Kaiser Permanente Northern California members with a new rash diagnosis seen in primary care and with dermatology advice obtained using teledermatology. The workflows differed in camera and image quality; who took the picture; how the image was forwarded; and synchronicity and convenience. On average, 23% of patients had a follow-up office visit in dermatology within 90 days of their primary care visit. In multivariable analysis, the four technologies differed substantially in the likelihood of a follow-up dermatology office visit. In contrast, the likelihood was only negligibly related to medical centre or primary care provider. Technologies and workflows that offer the mobility of a smartphone with a high level of synchronicity in communication were growth and pubertal onset timing in a multiethnic prospective cohort of girls Early puberty increases risk of adverse health conditions throughout the life course. US girls are experiencing earlier puberty without clear reasons. Studies suggest early life factors, such as infant growth, may influence pubertal timing. We assessed the associations between infant growth and onset of breast development (thelarche), pubic hair development (pubarche), and menarche in girls. A prospective cohort of girls born at a Kaiser Permanente Northern California medical facility in 2005-11 was used. Weight-for-age z-scores were calculated at birth and 24 months. Difference in z-scores greater than 0.67 represent rapid \"catch-up\" growth, less than -0.67 represent delayed \"catch-down\" growth, and between -0.67 and 0.67 represent \"normal\" growth. Pubertal onset was measured using clinician-assessed sexual maturity ratings (SMRs) and defined as the age at transition from SMR 1 to SMR 2 + for both thelarche and pubarche. SMR data was collected through June 2020. Menarche was analyzed as a secondary outcome. Weibull and modified Poisson regression models were used. Models were adjusted for potential confounders. There were 15,196 girls included in the study. Approximately 30.2% experienced catch-up growth, 25.8% experienced catch-down growth, and 44% had normal growth. Girls with catch-up growth had increased risk of earlier thelarche (hazard ratio = 1.26, 95% confidence interval (CI): 1.18, 1.35), pubarche (1.38, 95% CI: 1.28, 1.48), risk = 1.52, 95% CI: 1.36, 1.69) compared to those with normal growth, after adjusting for covariates. These associations were partially mediated by childhood body mass index. Catch-down growth was associated with later pubertal onset. Girls who experience infant catch-up growth have higher risk of earlier pubertal development compared to girls with normal growth and the associations are partially explained by childhood obesity. This information may help clinicians to monitor girls who are at high risk of developing earlier. Authors: mRNA Vaccination in Preventing COVID-19-Associated Emergency Department and Urgent Care Encounters and Hospitalizations Among Nonimmunocompromised Children and Adolescents Aged 5-17 Years - VISION Network, 10 States, April 2021-January 2022 The efficacy of the BNT162b2 (Pfizer-BioNTech) vaccine against laboratory-confirmed COVID-19 exceeded 90% in clinical trials that included children and adolescents aged 5-11, 12-15, and 16-17 years (1-3). Limited real-world data on 2-dose mRNA vaccine effectiveness (VE) in persons aged 12-17 years (referred to as adolescents in this report) have also indicated high levels of protection against SARS-CoV-2 (the virus that causes COVID-19) infection and COVID-19-associated hospitalization (4-6); however, data on VE against the SARS-CoV-2 B.1.1.529 (Omicron) variant and duration of protection are limited. Pfizer-BioNTech VE data are not available for children aged 5-11 years. In partnership with CDC, the VISION Network* examined 39,217 emergency department (ED) and urgent care (UC) encounters and 1,699 hospitalizations among persons aged 5-17 years with COVID-19-like illness across 10 states during April 9, 2021-January 29, 2022,\u00a7 to estimate VE using a case-control test-negative design. Among children aged 5-11 years, VE against laboratory-confirmed COVID-19-associated ED and UC encounters 14-67 days after dose 2 (the longest interval after dose 2 in this age group) was 46%. Among adolescents aged 12-15 and 16-17 years, VE 14-149 days after dose 2 was 83% and 76%, respectively; VE 150 days after dose 2 was 38% and 46%, respectively. Among adolescents aged 16-17 years, VE increased to 86% 7 days after dose 3 (booster dose). VE against COVID-19-associated ED and UC encounters was substantially lower during the Omicron predominant period than the B.1.617.2 (Delta) predominant period among adolescents aged 12-17 years, with no significant protection 150 days after dose 2 during Omicron predominance. However, in adolescents aged 16-17 years, VE during the Omicron predominant period increased to 81% 7 days after a third booster dose. During the full study period, including pre-Delta, Delta, and Omicron predominant periods, VE against laboratory-confirmed COVID-19-associated hospitalization among children aged 5-11 years was 74% 14-67 days after dose 2, with wide CIs that included zero. Among adolescents aged 12-15 and 16-17 years, VE 14-149 days after dose 2 was 92% and 94%, respectively; VE 150 days after dose 2 was 73% and 88%, respectively. All eligible children and adolescents should remain up to date with recommended COVID-19 vaccinations, including a booster dose for those aged 12-17 Mar 04;71(9):352-358. Epub 2022-03-04. Comparison of dementia incidence and prevalence between individuals with and without HIV infection in primary care from 2000 to 2016 To compare dementia incidence and prevalence after age 50 years by HIV status. Observational cohort, 2000-2016. People with HIV (PWH) on antiretroviral therapy (ART) and demographically similar people without HIV (PWoH), all aged 50 years and older, were identified from Kaiser Permanente healthcare systems in Northern California, Southern California, and Mid-Atlantic States (Maryland, Virginia, Washington DC). Dementia diagnoses were obtained from electronic health records. Incidence and prevalence of dementia, overall and by time period (i.e. 2000-2002, 2003-2004, ..., 2015-2016), were calculated using Poisson regression. Trends were examined using Joinpoint regression. Rate ratios were used to compare dementia by HIV status with adjustment for sociodemographics, substance use, and clinical factors. The study included 13 296 PWH and 155 354 PWoH (at baseline: for both, mean age = 54 years, 89% men; for PWH, 80% with HIV RNA <200 copies/ml). From 2000 to 2016, overall incidence of dementia was higher among PWH [adjusted incidence rate ratio (aIRR) = 1.80, 95% confidence interval (CI) = 1.60-2.04]. Dementia incidence decreased among both PWH and PWoH (-8.0 and -3.1% per period, respectively) but remained higher among PWH in the most recent time period, 2015-2016 (aIRR = 1.58, 95% CI = 1.18-2.12). The overall prevalence of dementia from 2000 to 2016 was higher among PWH [adjusted prevalence ratio (aPR) = 1.86, 95% CI = 1.70-2.04] and was also higher among PWH in 2015-2016 (aPR = 1.75, 95% CI = 1.56-1.97). Reductions in dementia incidence are encouraging and may reflect ART improvement, but PWH are still more likely to have dementia than PWoH. Monitoring the burden of dementia among PWH is important as this population ages. Authors: Lam, Jennifer O; Lee, Age-Adjusted Mortality Rates and Age and Risk-Associated Contributions to Change in Heart Disease and Stroke Mortality, 2011-2019 and 2019-2020 Authors: Postmenopausal Women Breast arterial calcification (BAC), a common incidental finding in mammography, has been shown to be associated with angiographic coronary artery disease and cardiovascular disease (CVD) outcomes. We aimed to (1) examine the association of BAC presence and quantity with hard atherosclerotic CVD (ASCVD) and global CVD; (2) ascertain model calibration, discrimination and reclassification of ASCVD risk; (3) assess the joint effect of BAC presence and 10-year pooled cohorts equations risk on ASCVD. A cohort study of 5059 women aged 60-79 years recruited after attending mammography screening between October 2012 and February 2015 was conducted in a large health plan in Northern California, United States. BAC status (presence versus absence) and quantity (calcium mass mg) was determined using digital mammograms. Prespecified end points were incident hard ASCVD and a composite of global CVD. Twenty-six percent of women had BAC >0 mg. After a mean (SD) follow-up of 6.5 (1.6) years, we ascertained 155 (3.0%) ASCVD events and 427 (8.4%) global CVD events. In Cox regression adjusted for traditional CVD risk factors, BAC presence was associated with a 1.51 (95% CI, 1.08-2.11; P=0.02) increased hazard of ASCVD and a 1.23 (95% CI, 1.002-1.52; P=0.04) increased hazard of global CVD. While there was no evidence of dose-response association with ASCVD, a threshold effect was found for global CVD at very high BAC burden (95th percentile when BAC present). BAC status provided additional risk stratification of the pooled cohorts equations risk. We noted improvements in model calibration and reclassification of ASCVD: the overall net reclassification improvement CI, 0.01-0.22; adding BAC status. Our results indicate that BAC has potential utility for primary CVD prevention and, therefore, support the notion that BAC ought to be considered a risk-enhancing factor Subcutaneous Insulin With Perinatal Complications Among Women With Gestational Diabetes Nearly 30% of individuals with gestational diabetes (GDM) do not achieve glycemic control with lifestyle modification alone and require medication treatment. Oral agents, such as glyburide, have several advantages over insulin for the treatment of GDM, including greater patient acceptance; however, the effectiveness of glyburide for the treatment of GDM remains controversial. To compare the perinatal and neonatal outcomes associated with glyburide vs insulin using causal inference methods in a clinical setting with information on glycemic control. The population-based cohort study included patients with GDM who required medication treatment from 2007 to 2017 in Kaiser Permanente Northern California. Machine learning and rigorous casual inference methods with time-varying exposures were used to evaluate associations of exposure to glyburide vs insulin with perinatal outcomes. Data analysis was conducted from March 2018 to July 2017. Time-varying exposure to glyburide vs insulin during pregnancy. Outcomes evaluated separately included neonatal hypoglycemia, jaundice, shoulder dystocia, respiratory distress syndrome (RDS), neonatal intensive care unit (NICU) admission, size-for-gestational age, and cesarean delivery. Inverse probability weighting (IPW) estimation was used to separately compare perinatal outcomes between those initiating glyburide and insulin. This approach was combined with Super Learning for propensity score estimation to account for both baseline and time-dependent confounding in both per-protocol (primary) and intention-to-treat (secondary) analyses to evaluate sustained exposure to the same therapy. From 2007 to 2017, 11 321 patients with GDM (mean [SD] age, 32.9 [4.9] years) initiated glyburide or insulin during pregnancy. In multivariate models, the risk of neonatal respiratory distress was 2.03 (95% CI, 0.13-3.92) per 100 births lower and the risk of NICU admission was 3.32 (95% CI, 0.20-6.45) per 100 births lower after continuous exposure to glyburide compared with insulin. There were no statistically significant differences in glyburide vs insulin initiation in risk for neonatal hypoglycemia (0.85 [95% CI, -1.17 to 2.86] jaundice (0.02 [95% CI, to per dystocia (-1.05 [95% CI, -2.71 to 0.62] per age categories (-2.75 [95% CI, -6.31 to 0.80] per 100 births). Using data from a clinical setting and contemporary causal inference methods, our findings do not provide evidence of a difference in the outcomes examined between patients with GDM initiating glyburide compared with those Blood Pressure Patterns Identify Risk of Hypertensive Disorders of Pregnancy Among Racial and Ethnic Groups Hypertensive disorders of pregnancy are a leading cause of severe maternal morbidity and mortality and confer 4-fold higher perinatal mortality in Black women. Early pregnancy blood pressure patterns may differentiate risk of hypertensive disorders of pregnancy. This study identified distinct blood pressure trajectories from 0 to 20 weeks' gestation to evaluate subsequent pregnancy-related hypertension in a retrospective cohort of 174 925 women with no prior hypertension or history of preeclampsia, prenatal care entry 14 weeks, and a stillborn or live singleton birth delivered at Kaiser Permanente Northern California hospitals in 2009 to 2019. We used electronic health records to obtain clinical outcomes, covariables, and longitudinal outpatient blood pressure measurements 20 weeks' gestation (mean 4.1 measurements). Latent class trajectory modeling identified 6 blood with the odds of preeclampsia/eclampsia and gestational hypertension' and effect modification by race-ethnicity and prepregnancy body size. Compared with ultra-low-declining, adjusted odds ratios (95% confidence intervals [CIs]) for low-increasing, moderate-stable, and elevated-stable groups 3.25 (2.7-3.9), (4.5-6.3), 9.2 (7.7-11.1) for preeclampsia/eclampsia' and 6.4 (4.9-8.3), 13.6 (10.5-17.7), and 30.2 (23.2-39.4) for gestational hypertension. Race/ethnicity, and prepregnancy obesity modified the trajectory-group associations with preeclampsia/eclampsia (interaction P<0.01), with highest risks for Black, then Hispanic and Asian women for all blood pressure trajectories, and with increasing obesity class. Early pregnancy blood pressure patterns revealed racial and ethnic differences in associations with preeclampsia/eclampsia risk within equivalent levels and patterns. These blood pressure patterns may improve individual risk stratification permitting targeted surveillance and early mitigation strategies. Authors: P; E Hypertension. 2022 03;79(3):599-613. Epub 2021-12-29. Impact of the Affordable Care Act on Colorectal Cancer Incidence and Mortality The Patient Protection and Affordable Care Act eliminated cost sharing for preventive services, including colorectal cancer screening for individuals aged 50-75 years with private health insurance. This study examines the impact of the Affordable Care Act's removal of cost sharing for colorectal cancer screening on colorectal cancer incidence and mortality. Trends in colorectal cancer incidence and colorectal cancerrelated mortality were modeled among 2,113,283 Kaiser Permanente Northern California members aged 50 years between 2003 and 2016 using an interrupted time-series design. As a sensitivity analysis, a controlled analysis utilized a comparison group of members covered with preAffordable Care Act zero cost sharing for colorectal cancer screening. Analyses were performed in 2019 and 2020. The colorectal cancer incidence dropped by 17% around the time the Affordable Care Act was enacted (change in level incidence rate ratio; 95% CI=0.77, 0.90, 2-sided p-value year (95% CI=0.93, 1.00, p=0.05). A similar pattern was observed for colorectal cancerrelated mortality. The controlled results indicated that the elimination of cost sharing for screening due to the Affordable Care Act was associated with greater improvements in colorectal cancer outcomes among members previously covered by health plans with out-of-pocket costs for screening than among those with health plans with zero cost sharing for screening before the Affordable Care Act. The elimination of cost sharing for colorectal cancer screening due to the Affordable Care Act was associated with a decrease in age-, race/ethnicity-, and sex-adjusted colorectal cancer incidence and colorectal cancerrelated mortality, implying that policies that remove barriers to screening, particularly financial burden from cost sharing, can result in improved colorectal cancer outcomes. Authors: Lee, Catherine; Kushi, Lawrence H; Jeffrey K; J Med. 2022 Cohort and Nested Case-Control Study of Cutaneous Squamous Cell Carcinoma in Solid Organ Transplant Recipients, by Medication Knowledge is needed about the risk of cutaneous squamous cell carcinoma (cSCC) in solid organ transplant recipients (SOTRs) using contemporary immunosuppressive regimens. Evaluate the risk of cSCC in relation to medications used by SOTRs. The cohort and nest case-control study included 3308 SOTRs and 65,883 persons without transplantation during 2009-2019. Incident cSCC was identified from pathology data, and medications were identified from pharmacy data. Adjusted hazard ratios and 95% confidence intervals (CIs) were estimated using Cox proportional hazards analysis, with voriconazole examined as a time-dependent variable. The annual incidence of cSCC was 1.69% in SOTRs and 0.30% in persons without transplantation. The adjusted hazard ratio of cSCC associated with lung transplant was 14.83 (95% CI, 9.85-22.33) for lung and 6.53-10.69 for other organs. Risk in Latinx persons was higher than in other non-White groups. Among lung recipients, the hazard ratio was 1.14 for each month of voriconazole use (95% CI, 1.04-1.26). Azathioprine use for 7 months, relating to mycophenolate mofetil intolerance, was associated with a 4.22-fold increased risk of cSCC (95% CI, 1.90-9.40). Belatacept and other immunsuppressive medications were not associated with risk. The number of events was somewhat small. The knowledge of risks and benefits in diverse patients can translate to improvements in care. Authors: Dusendang, Jennifer R; 2021-08-09. Antibiotic prescribing across age groups in the Kaiser Permanente Northern California population in association with different diagnoses, and with influenza incidence, 2010-2018 There is limited information on the volume of antibiotic prescribing that is influenza-associated, resulting from influenza infections and their complications (such as streptococcal pharyngitis and otitis media). Here, we estimated age/diagnosis-specific proportions of antibiotic prescriptions (fills) for the Kaiser Permanente Northern California population during 2010-2018 that were influenza-associated. The proportion of influenza-associated antibiotic prescribing among all antibiotic prescribing was higher in children aged 5-17 years compared to children aged under 5 years, ranging from 1.4% [95% CI (0.7-2.1)] in aged <1 year to 2.7% (1.9-3.4) in aged 15-17 years. For adults aged over 20 years, the proportion of influenza-associated antibiotic prescribing among all antibiotic prescribing was lower, ranging from 0.7% (0.5-1) for aged 25-29 years to 1.6% (1.2-1.9) for aged 60-64 years. Most of the influenza-associated antibiotic prescribing in children aged under 10 years was for ear infections, while for age groups over 25 years, 45-84% of influenza-associated antibiotic prescribing was for respiratory diagnoses without a bacterial indication. This suggests a modest benefit of increasing influenza vaccination coverage for reducing antibiotic prescribing, as well as the potential benefit of other measures to reduce unnecessary antibiotic prescribing for respiratory diagnoses with no bacterial indication in persons aged over 25 years, both of which may further contribute to the mitigation of antimicrobial resistance. Authors: Goldstein, Edward; Fireman, Bruce Effectiveness of mRNA Vaccines Against COVID-19-Associated Emergency Department and Urgent Care Encounters and Hospitalizations Among Adults During Periods of Delta and Omicron Variant Predominance - VISION Network, 10 States, August 2021-January 2022 CDC recommends that all persons aged 12 years receive a booster dose of COVID-19 mRNA vaccine 5 months after completion of a primary mRNA vaccination series and that immunocompromised persons receive a third primary dose.* Waning of vaccine protection after 2 doses of mRNA vaccine has been observed during the period of the SARS-CoV-2 B.1.617.2 (Delta) variant predominance (1-5), but little is known about durability of protection after 3 doses during periods of Delta or SARS-CoV-2 B.1.1.529 (Omicron) variant predominance. A test-negative case-control study design using data from eight VISION Network sites\u00a7 examined vaccine effectiveness (VE) against COVID-19 emergency department/urgent care (ED/UC) visits and hospitalizations among U.S. adults aged 18 years at various time points after receipt of a second or third vaccine dose during two periods: Delta variant predominance and Omicron variant predominance (i.e., periods when each variant accounted for 50% of sequenced isolates).\u00b6 Persons categorized as having received 3 doses included those who received a third dose in a primary series or a booster dose after a 2 dose primary series (including the reduced-dosage Moderna booster). The VISION Network analyzed 241,204 ED/UC encounters** and 93,408 hospitalizations across 10 states during August 26, 2021-January 22, 2022. VE after receipt of both 2 and 3 doses was lower during the Omicron-predominant than during the Delta-predominant period at all time points evaluated. During both periods, VE after receipt of a third dose was higher than that after a second dose; however, VE waned with increasing time since vaccination. During the Omicron period, VE against ED/UC visits was 87% during the first 2 months after a third dose and decreased to 66% among those vaccinated 4-5 months earlier; VE against hospitalizations was 91% during the first 2 months following a third dose and decreased to 78% 4 months after a third dose. For both Delta- and Omicron-predominant periods, VE was generally higher for protection against hospitalizations than against ED/UC visits. All eligible persons should remain up to date with recommended COVID-19 vaccinations to best protect against COVID-19-associated hospitalizations and event (TEE) risk following intravenous immune globulin (IGIV) in the U.S. (2006-2012) Since 2013, the U.S. Food and Drug administration (FDA) has required that intravenous immune globulin (IGIV) products carry a boxed warning concerning the risk of thromboembolic events (TEEs). This study assessed the incidence of TEEs attributable to IGIV in a large population-based cohort. A self-controlled risk interval design was used to quantify the transient increase in TEE risk during the risk interval (days 0-2 and 0-13 following IGIV for arterial and venous TEEs, respectively) relative to a later control interval (days 14-27 following IGIV). Potential IGIV-exposed TEE cases from 2006 to 2012 were identified from the FDA-sponsored Sentinel Distributed Database and confirmed through medical record review. Inpatient IGIV exposures were not included in the venous TEE analysis due to concerns about time-varying confounding. 19,069 new users of IGIV who received 93,555 treatment episodes were included. Charts were retrieved for 62% and 70% of potential venous and arterial cases, respectively. There was a transient increase in the risk of arterial TEEs during days 0-2 following IGIV treatment (RR = 4.69; 95% CI 1.87, 11.90; absolute increase in risk = 8.86 events per 10,000 patients, 95% CI 3.25, 14.6), but no significant increase in venous TEE risk during days 0-13 following outpatient IGIV treatments (RR = 1.07, 95% CI 0.34, 3.48). Our results suggest there is a small increase in the absolute risk of arterial TEEs following IGIV. However, lower-than-expected chart retrieval rates and the possibility of time-varying confounding mean that our results should be interpreted cautiously. Continued pharmacovigilance efforts are warranted. Authors: Ammann, Eric M; Fuller, 2021-11-24. of a Third Dose of mRNA Vaccines Against COVID-19-Associated Emergency Department and Urgent Care Encounters and Hospitalizations Among Adults During Periods of Delta and Omicron Variant Predominance - VISION Network, 10 States, August 2021-January 2022 Estimates of COVID-19 mRNA vaccine effectiveness (VE) have declined in recent months (1,2) because of waning vaccine induced immunity over time,* possible increased immune evasion by SARS-CoV-2 variants (3), or a combination of these and other factors. CDC recommends that all persons aged 12 years receive a third dose (booster) of an mRNA vaccine 5 months after receipt of the second mRNA vaccine dose and that immunocompromised individuals receive a third primary dose. A third dose of BNT162b2 (Pfizer-BioNTech) COVID-19 vaccine increases neutralizing antibody levels (4), and three recent studies from Israel have shown improved effectiveness of a third dose in preventing COVID-19 associated with infections with the SARS-CoV-2 B.1.617.2 (Delta) variant (5-7). Yet, data are limited on the real-world effectiveness of third doses of COVID-19 mRNA vaccine in the United States, especially since the SARS-CoV-2 B.1.1.529 (Omicron) variant became predominant in mid-December 2021. The VISION Network\u00a7 examined VE by analyzing 222,772 encounters from 383 emergency departments (EDs) and urgent care (UC) clinics and 87,904 hospitalizations from 259 hospitals among adults aged 18 years across 10 states from August 26, 2021\u00b6 to January 5, 2022. Analyses were stratified by the period before and after the Omicron variant became the predominant strain (>50% of sequenced viruses) at each study site. During the period of Delta predominance across study sites in the United States (August-mid-December 2021), VE against laboratory-confirmed COVID-19-associated ED and UC encounters was 86% 14-179 days after dose 2, 76% 180 days after dose 2, and 94% 14 days after dose 3. Estimates of VE for the same intervals after vaccination during Omicron variant predominance were 52%, 38%, and 82%, respectively. During the period of Delta variant predominance, VE against laboratory-confirmed COVID-19-associated hospitalizations was 90% 14-179 days after dose 2, 81% 180 days after dose 2, and 94% 14 days after dose 3. During Omicron variant predominance, VE estimates for the same intervals after vaccination were 81%, 57%, and 90%, respectively. The highest estimates of VE against COVID-19-associated ED and UC encounters or hospitalizations during both Delta- and Omicron-predominant periods were among adults who received a third dose of mRNA vaccine. All unvaccinated persons should get vaccinated as soon as possible. All adults who have received mRNA vaccines during their primary COVID-19 vaccination series should receive a third dose when eligible, and eligible persons should stay up to date with COVID-19 vaccinations. Authors: Sidedness-Dependent Prognosis in Metastatic Colorectal Cancer To the association of gain-of-function (GOF) (non-GOF) left-sided colorectal cancer (LCC). with metastatic colorectal cancer (CRC) who had next-generation sequencing performed other mutp53 as non-GOF. We used Cox regression modeling to examine the association between GOF and non-GOF mutp53 and overall survival (OS), adjusting for age, sex, ethnicity, performance status, Charlson comorbidity index and receipt of chemotherapy. Of total 1,043 patients, 735 had tumors with mutp53 and 308 had wild-type p53 (wtp53). GOF was associated with worse OS than non-GOF mutp53 only in LCC (hazard ratio [HR] = 1.66 [95% CI, 1.20 to 2.29]), but not RCC = 0.79 [95% CI, 0.49 to 1.26]). Importantly, RCC was associated with worse OS than LCC only in the subset of patients whose CRC carried non-GOF (HR = 1.76 [95% CI, 1.30 to 2.39]), but not GOF mutp53 0.92 (HR = 0.88 [95% CI, 0.60 to 1.28]). These associations were largely unchanged after also adjusting for RAS, BRAF, and PIK3CA mutations, and microsatellite instability-high. Poorer survival of patients with metastatic RCC versus LCC appeared to be restricted to with non-GOF mutp53, whereas GOF versus non-GOF mutp53 was associated with poorer survival only among patients with LCC. This approach of collectively classifying mutp53 into GOF and non-GOF provides new insight for prognostic stratification and for understanding the mechanism of sidedness-dependent prognosis. If confirmed, future CRC clinical trials may benefit from incorporating this approach. Authors: Pan, Minggui; Solorzano, Epub 2021-11-29. Identifying hypertensive disorders of pregnancy, a comparison of two epidemiologic definitions Studies of hypertension in pregnancy that use electronic health care data generally identify hypertension using hospital diagnosis codes alone. We sought to compare results from this approach to an approach that included diagnosis codes, antihypertensive medications and blood pressure (BP) values. We conducted a retrospective cohort study of 1,45,739 pregnancies from 2009 to 2014 within an integrated healthcare system. Hypertensive pregnancies were identified using the \"BP-Inclusive Definition\" if at least one of three criteria were met: (1) two elevated outpatient BPs, (2) antihypertensive medication fill plus an outpatient hypertension diagnosis, or (3) hospital discharge diagnosis for preeclampsia or eclampsia. The \"Traditional Definition\" considered only delivery hospitalization discharge diagnoses. Outcome event analyses compared rates of preterm delivery and small for gestational age (SGA) between the two definitions. The BP-Inclusive Definition identified 14,225 (9.8%) hypertensive pregnancies while the Traditional Definition identified 13,637 (9.4%); 10,809 women met both definitions. Preterm delivery occurred in 20.9% of BP-Inclusive Definition pregnancies, 21.8% of Traditional Definition pregnancies and 6.6% of non-hypertensive pregnancies; for SGA the numbers were 15.6, 16.3, and 8.6%, respectively (p < 0.001 for all events compared to non-hypertensive pregnancies). Analyses in women meeting only one hypertension definition (21-24% of positive cases) found much lower rates of both preterm delivery and SGA. Prevalence of hypertension in pregnancy was similar between the two study definitions. However, a substantial number of women met only one of the study definitions. Women who met only one of the hypertension definitions had much lower rates of adverse neonatal events than women meeting both definitions. Maternal and neonatal outcomes of antihypertensive treatment in pregnancy: A retrospective cohort study To compare maternal and infant outcomes with different antihypertensive medications in pregnancy. Retrospective cohort study. Kaiser Permanente, a large healthcare system in the United States. Women aged 15-49 years with a singleton birth from 2005-2014 treated for hypertension. We identified medication exposure from automated pharmacy data based on the earliest dispensing after the first prenatal visit. Using logistic regression, we calculated weighted outcome prevalences, adjusted odds ratios (aORs) and 95% confidence intervals, with inverse probability of treatment weighting to address confounding. Small for gestational age, preterm delivery, neonatal and maternal intensive care unit (ICU) admission, preeclampsia, and stillbirth or termination at > 20 weeks. Among 6346 deliveries, 87% with chronic hypertension, the risk of the infant being small for gestational age (birthweight < 10th percentile) was lower with Compared with for methyldopa (26.5%; aOR 1.10 [1.07 2.23]). vs. 23.3%, but not elevated with methyldopa. Risks of other outcomes did not differ by medication. Risk of most outcomes was similar comparing labetalol, methyldopa and nifedipine. Risk of the infant being small for gestational age was substantially lower for methyldopa, suggesting this medication may warrant further 2022;17(5):e0268284. Epub of cardiovascular events among patients with moderate-to-severe atopic dermatitis in an integrated health care system: A retrospective cohort study Patients with versus without atopic dermatitis may have a greater risk of cardiovascular events, and the risk increases with severity of atopic dermatitis. The incidence of cardiovascular events in the population of patients with moderate-to-severe atopic dermatitis is largely unknown. This retrospective study evaluates incidence rates of cardiovascular events in patients aged 12 years with moderate-to-severe atopic dermatitis in a cohort of Kaiser Permanente Northern California health care system members without recognized risk factors for adverse events. Patients with moderate-to-severe atopic dermatitis, as defined by dermatologist-rendered code and prescription history between 2007 and 2018, were included. Major adverse cardiovascular events, venous thrombotic events, deep vein thrombosis, and pulmonary embolisms were identified via International Classification of Diseases codes. Stratification variables included age, sex, race, smoking history, and diabetes. Incidence rates per 1000 person-years were calculated by the number of patients with an incident event divided by the total person-years of observation. Among 8197 patients with moderate-to-severe atopic dermatitis, incidence rates per 1000 person-years (95% confidence interval) for major adverse cardiovascular events, venous thrombotic events, deep vein thrombosis, and pulmonary embolism (2.1-3.2), 2.0 (1.5-2.5), 1.6 (1.2-2.1), and 0.7 (0.5-1.0), respectively. Incidence rates for all events were higher for older versus younger patients, patients with versus without diabetes, former smokers versus patients who had never smoked, and men versus women, except for pulmonary embolisms, which were higher in women. This study estimated the incidence of cardiovascular events in patients with moderate-to-severe atopic dermatitis and provides 01;22(1):306-314. Parent-focused prevention of adolescent health risk behavior: Study protocol for a multisite cluster-randomized trial implemented in pediatric primary care Evidence-based parenting interventions play a crucial role in the sustained reduction of adolescent behavioral health concerns. Guiding Good Choices (GGC) is a 5-session universal anticipatory guidance curriculum for parents of early adolescents that has been shown to reduce substance use, depression symptoms, and delinquent behavior. Although prior research has demonstrated the effectiveness of evidence-based parenting interventions at achieving sustained reductions in adolescent behavioral health concerns, public health impact has been limited by low rates of uptake in community and agency settings. Pediatric primary care is an ideal setting for implementing and scaling parent-focused prevention programs as these settings have a broad reach, and prevention programs implemented within them have the potential to achieve population-level impact. The current investigation, Guiding Good Choices for Health (GGC4H), tests the feasibility and effectiveness of implementing GGC in 3 geographically and socioeconomically diverse large integrated healthcare systems. This pragmatic, cluster randomized clinical trial will compare GGC parenting intervention to usual pediatric primary care practice, and will include approximately 3750 adolescents; n = 1875 GGC intervention and n = 1875 usual care. The study team hypothesizes that adolescents whose parents are randomized into the GGC intervention arm will show reductions in substance use initiation, the study's primary outcomes, and other secondary (e.g., depression symptoms, substance use prevalence) and exploratory outcomes (e.g., health services utilization, anxiety symptoms). The investigative team anticipates that the implementation of GGC within pediatric primary care clinics will successfully fill an unmet need for effective preventive parenting interventions. Trial registration: Pregnancy Prevention: Further Evidence of Benefits of Prescription Contraceptives To estimate the incidence of ectopic pregnancy (EP) associated with prescription contraceptive use. We performed a retrospective cohort study of women aged 15 to 44 years at Kaiser Permanente Northern and Southern California during 2010 to 2019. We identified EPs and prescription contraceptive use from diagnosis, procedural, and medication codes, and natural language processing of clinical notes from electronic health records. Contraceptive use categories included combined hormonal contraceptives, intrauterine devices, depot-medroxyprogesterone acetate (DMPA), progestin-only pills (POPs), implants, no method after recent discontinuation of a prescription contraceptive in the last 12 months, and no method after discontinuation of a prescription contraceptive more than 12 months ago or no use of prescription contraceptives during the study period. Contraceptive use was updated as women started, stopped, or changed methods. An EP was attributed to a contraceptive method if it occurred 14 days after starting and up to 42 days after stopping a method. Age-adjusted EP incidence and 95% confidence intervals (CI) were estimated per 10,000 woman-years overall and by contraceptive category. There were 11,436 EPs among 3,204,118 women with 11,909,842 woman-years of follow-up for an overall EP incidence of 9.5 per 10,000 woman-years (95%CI 9.3-9.6). The majority of EPs (9662; 84.5%) occurred during no prescription contraceptive use. EP incidence was lowest during DMPA (1.8 per 10,000 woman-years [95%CI 1.2-2.5]) or implant (2.0 per 10,000 woman-years [95%CI 1.2-3.3]) use, and higher during POP use at 15.2 (95%CI 12.2-19.6); however, incidence was highest after recent discontinuation of a prescription contraceptive (20.6 per 10,000 woman-years [95%CI 19.7-21.4]). EP incidence is lower with prescription contraceptive use than with nonuse. All prescription contraceptives, including POPs are A study in an integrated healthcare delivery system TdP is a form of polymorphic ventricular tachycardia which develops in the setting of a prolonged QT interval. There are limited data describing risk factors, treatment, and outcomes of this potentially fatal arrhythmia. Our goals were as follows: (1) to validate cases presenting with Torsade de Pointes (TdP), (2) to identify modifiable risk factors, and (3) to describe the management strategies used for TdP and its prognosis in a real-world healthcare setting. Case-control study (with 2:1 matching on age, sex, and race/ethnicity) nested within the Genetic Epidemiology Research on Aging (GERA) cohort. Follow-up of the cohort for case ascertainment was between January 01, 2005 and December 31, 2018. A total of 56 cases of TdP were confirmed (incidence rate = 3.6 per 100,000 persons/years). The average (SD) age of the TdP cases was 74 (13) years, 55 percent were female, and 16 percent were non-white. The independent predictors of TdP were potassium concentration <3.6 mEq/L (OR = 10.6), prior history of atrial fibrillation/flutter (OR = 6.2), QTc >480 ms (OR = 4.4) and prior history of coronary artery disease (OR = 2.6). Exposure to furosemide and amiodarone was significantly greater in cases than in controls. The most common treatment for TdP was IV magnesium (78.6%) and IV potassium repletion (73.2%). The in-hospital and mortality rates for TdP cases were 10.7% and 25.0% percent, respectively. These findings may inform quantitative multivariate risk indices for the prediction of TdP and could guide practitioners on which patients may qualify for continuous ECG monitoring and/or electrolyte replacement therapy. assessment of risks for severe COVID-19 disease outcomes Among approximately 4.6 million members of Kaiser Permanente Northern California, we examined associations of severe COVID-19 with demographic factors and comorbidities. As of July 23, 2021, 16 182 had been hospitalized, 2416 admitted to an ICU, and 1525 died due to COVID-19. Age was strongly associated with hospitalization, ICU admission, and death. Black persons and Hispanic ethnicity had higher risk of death compared with Whites. Among the comorbidities examined, Alzheimer's disease was associated with the highest risk for hospitalization (aHR 3.19, CI: 2.88-3.52) and death (aHR 4.04, CI: 3.32-4.91). Parkinson's disease had the second highest risk of death (aHR = 2.07, CI: 01;16(1):159-165. Epub 2021-08-25. Predicting adolescent alcohol and other drug problems using electronic health records data Alcohol and other drug (AOD) use problems may cause significant burden on affected adolescents and their families, yet treatment providers often do not identify these problems early enough. To develop, and internally and externally validate a multivariable prediction model of adolescent AOD problems using child- and maternal-level predictors before age 12, and child-level predictors between ages 12 to 18, as recorded in the electronic health records (EHR). A retrospective cohort study conducted time-to-event analyses using Cox proportional hazards models. 41,172 children born between 1997 and 2000 at four health plans (Kaiser Permanente Hawaii, KPHI; Kaiser Permanente Northern California, KPNC; Geisinger Clinic, GC; and Henry Ford Health System, HFHS) who had continuous membership since birth and linkable maternal records in the health plan. AOD use problems between ages 12 to 18, defined as either: 1) having a contact with the AOD treatment program or 2) receiving a non-tobacco AOD diagnosis in an inpatient or outpatient encounter. Candidate predictor variables include demographics, socioeconomic status, and clinical diagnoses of the children and the mothers. Overall, 1400 (3.4%) adolescents had an AOD disorder between ages 12 to 18; the median follow-up time post-age 12 was 5.3 years. The research team developed two final prediction models: a \"baseline\" model of 10 child-level and 7 maternal-level predictors before age 12, and a more comprehensive \"time-varying\" model, which incorporated child risk factors after age 12 as time-varying covariates in addition to the baseline model predictors. Model performance evaluation showed good discrimination performance of the models, with the concordance index improved for the time-varying model, especially for prediction of AOD events in late adolescence. This study identified a number of child and maternal characteristics and diagnoses routinely available in EHR data as predictive of risk for developing AOD problems in adolescence. Further, we found that risk of developing problems varies significantly by the timing and persistence of the risk factors. Findings may have potential clinical implications for prevention and identification of adolescent AOD problems, but more research is needed, especially across additional health systems. Authors: Chi, Comanagement of Rashes by Primary Care Providers and Dermatologists: A Retrospective Study There is a high demand for managing skin disease, and dermatologists are in short supply. To better understand how rashes and other specific skin conditions are co-managed by primary care providers (PCPs) and dermatologists, we estimated the frequency with which PCPs sought consultation with or referral to dermatology and the proportion of patients who had a follow-up dermatology office visit in the following 90 days. The retrospective longitudinal study included 106,459 patients with a skin condition diagnosed by 3,830 PCPs, from January 2017 to March 2017. Comprehensive electronic medical record data with generalized linear mixed modeling accounted for patient factors including diagnosis and clustering by medical center and PCP. PCPs escalated 9% of patients to dermatology through consultation or referral, while 5% required a follow-up dermatology office visit within 90 days. Patients with bullous, hair, or pigment conditions or psoriasis were most likely to be escalated. Clustering of escalation and follow-up visits was minimal in relation to medical center (intraclass correlation, 0.04 for both outcomes) or PCP (escalation, intraclass correlation, 0.16; follow-up visits, 0.09). Improving primary care education in skin disease and, for certain skin conditions, standardizing approaches to workup, treatment, and escalation may further streamline care and reduce pressure on the dermatologist workforce. PCPs managed 91% of rashes without consultation or referral to dermatology, and the frequency of patients scheduled for dermatology office visits after primary care was similar from one PCP to another. Authors: Epub 2021-12-13. Cancer in people with and without hepatitis C virus infection: comparison of risk before and after introduction of direct-acting antivirals Chronic hepatitis C virus (HCV) infection is a leading cause of liver cancer. The association of HCV infection with extrahepatic cancers, and the impact of direct-acting antiviral (DAA) treatment on these cancers, is less well known. We conducted a cohort study in a healthcare delivery system. Using electronic health record data from 2007 to 2017, we determined cancer incidence, overall and by type, in people with HCV infection and by DAA treatment status. All analyses included comparisons with a reference population of people without HCV infection. Covariate-adjusted Poisson models were used to estimate incidence rate ratios. 2,451 people with HCV and 173,548 people without HCV were diagnosed with at least one type of cancer. Compared with people without HCV, those with HCV were at higher risk for liver cancer [adjusted incidence rate ratio (aIRR) = 31.4, 95% confidence interval (CI) = 28.9-34.0], hematologic cancer (aIRR = 1.3, 95% CI = 1.1-1.5), cancer (aIRR = 1.3, 95% CI = 1.2-1.5), cancer 2.0, = (aIRR 1.4, 95% = 1.1-1.8), anal cancer (aIRR = 1.6, 95% CI = 1.1-2.4). Compared with people without HCV, the aIRR for liver cancer was 31.9 (95% CI = 27.9-36.4) among DAA-untreated and 21.2 (95% CI = 16.8-26.6) among DAA-treated, and the aIRR for hematologic cancer was 1.5 (95% CI = 1.1-2.0) among DAA-untreated and 0.6 (95% CI = 0.3-1.2) among DAA-treated. People with HCV infection were at increased risk of liver cancer, hematologic cancer, and some other extrahepatic cancers. DAA treatment was associated with reduced risk of liver cancers and hematologic cancers. DAA treatment is important for reducing cancer incidence among people with HCV infection. Authors: Lam, Jennifer O; Acellular Pertussis Vaccination Hypotonic-hyporesponsive episode (HHE) after whole cell pertussis vaccination is a known adverse event. Less is known about the risk of HHE after administration of acellular pertussis vaccines. Using parental interviews, this study actively surveyed for HHE among infants after doses 1 and 2 of acellular pertussis vaccine. We interviewed the parents of 52,531 infants. HHE was reported at a rate of 22.8 per 100,000 doses (95% CI: 11.8-39.9) of acellular pertussis vaccine, approximately 45 episodes per 100,000 children. These rates are lower than HHE rates reported after whole cell pertussis vaccines and within the range of HHE rates reported in other studies of acellular pertussis vaccines. Authors: Hansen, John; Decker, Michael D; Lewis, Edwin; Fireman, Bruce; Vitali; David David R; Black, Steven; Klein, P Pediatr Infect Dis J. 2021 12 01;40(12):1122-1126. Laboratory-Confirmed COVID-19 Among Adults Hospitalized with COVID-19-Like Illness with Infection-Induced or mRNA Vaccine-Induced SARS-CoV-2 Immunity - Nine States, January-September 2021 Previous infection with SARS-CoV-2 (the virus that causes COVID-19) or COVID-19 vaccination can provide immunity and protection from subsequent SARS-CoV-2 infection and illness. CDC used data from the VISION Network* to examine hospitalizations in adults with COVID-19-like illness and compared the odds of receiving a positive SARS-CoV-2 test result, and thus having laboratory-confirmed COVID-19, between unvaccinated patients with a previous SARS-CoV-2 infection occurring 90-179 days before COVID-19-like illness hospitalization, and patients who were fully vaccinated with an mRNA COVID-19 vaccine 90-179 days before hospitalization with no previous documented SARS-CoV-2 infection. Hospitalized adults aged 18 years with COVID-19-like illness were included if they had received testing at least twice: once associated with a COVID-19-like illness hospitalization during January-September 2021 and at least once earlier (since February 1, 2020, and 14 days before that hospitalization). Among COVID-19-like illness hospitalizations in persons whose previous infection or vaccination occurred 90-179 days earlier, the odds of laboratory-confirmed COVID-19 (adjusted for sociodemographic and health characteristics) among unvaccinated, previously infected adults were higher than the odds among fully vaccinated recipients of an mRNA COVID-19 vaccine with no previous documented infection (adjusted odds ratio [aOR] = 5.49; 95% confidence interval [CI] = 2.75-10.99). These findings suggest that among hospitalized adults with COVID-19-like illness whose previous infection or vaccination occurred 90-179 days earlier, vaccine-induced immunity was more protective than infection-induced immunity against laboratory-confirmed COVID-19. All eligible persons should be vaccinated against COVID-19 as soon as possible, including unvaccinated persons previously infected with SARS-CoV-2. Authors: 2-Dose with mRNA COVID-19 Vaccines Against COVID-19-Associated Hospitalizations Among Immunocompromised Adults - Nine States, January-September 2021 Immunocompromised persons, defined as those with suppressed humoral or cellular immunity resulting from health conditions or medications, account for approximately 3% of the U.S. adult population (1). Immunocompromised adults are at increased risk for severe COVID-19 outcomes (2) and might not acquire the same level of protection from COVID-19 mRNA vaccines as do immunocompetent adults (3,4). To evaluate vaccine effectiveness (VE) among immunocompromised adults, data from the VISION Network* on hospitalizations among persons aged 18 years with COVID-19-like illness from 187 hospitals in nine states during January 17-September 5, 2021 were analyzed. Using selected discharge diagnoses, VE against COVID-19-associated hospitalization conferred by completing a 2-dose series of an mRNA COVID-19 vaccine 14 days before the index hospitalization date\u00a7 (i.e., being fully vaccinated) was evaluated using a test-negative design comparing 20,101 immunocompromised adults (10,564 [53%] of fully vaccinated) and 69,116 immunocompetent adults (29,456 [43%] of whom were fully vaccinated). VE of 2 doses of mRNA COVID-19 vaccine against COVID-19-associated hospitalization was lower among immunocompromised patients (77%; 95% confidence [CI] = immunocompetent patients (90%; 95% CI = 89%-91%). This difference persisted irrespective of mRNA vaccine product, age group, and timing of hospitalization relative to SARS-CoV-2 (the virus that causes COVID-19) B.1.617.2 (Delta) variant predominance in the state of hospitalization. VE varied across immunocompromising condition subgroups, ranging from 59% (organ or stem cell transplant recipients) to 81% (persons with a rheumatologic or inflammatory disorder). Immunocompromised persons benefit from mRNA COVID-19 vaccination but are less protected from severe COVID-19 outcomes than are immunocompetent persons, and VE varies among immunocompromised subgroups. Immunocompromised persons receiving mRNA COVID-19 vaccines should receive 3 doses and a booster, consistent with CDC recommendations (5), practice nonpharmaceutical interventions, and, if infected, be monitored closely and considered early for proven therapies that can prevent severe outcomes. Authors: Embi, Epub 2021-11-05. Rates of Prenatal Cannabis Use Among Pregnant Women Before and During the COVID-19 Pandemic Authors: Young-Wolff, Kelly C; Ray, G Associated With Patient-Scheduled Primary Care Telemedicine and In-Person Visits in a Large Integrated Health System Telemedicine visits can offer patients convenient access to a clinician, but it is unclear whether treatment differs from that with in-person visits or how often patients require in-person follow-up. To examine whether physician prescribing and orders differ between telemedicine and office visits, whether physicians conducting telemedicine visits are more likely to require in-person follow-up, and whether telemedicine visits are associated with more health events. This cohort study included all patients who scheduled primary care appointments through the patient portal of a large integrated health care delivery system newly implementing patient-scheduled video telemedicine visits from January 2016 to May 2018. Adjusted rates of any medication prescribed or laboratory tests or imaging ordered and rates of follow-up health care utilization (in-person visits, emergency department visits, and hospitalizations) within 7 days after the index visit, stratified by index primary care visit type, were generated using multivariable adjustment for patient, access, and clinical characteristics. This study included 1 131 722 patients (611 821 [54%] female; mean [SD] age, 43 [22] years) with 2 178 440 total appointments (307 888 [14%] telemedicine), of which 13.5% were for patients younger than 18 years, 22.2% were for patients 65 years or older, and 54.9% were for female patients. After adjustment, 38.6% (95% CI, 38.0%-39.3%) of video visits, 34.7% (95% of telephone visits, and 51.9% (95% CI, 51.8%-52.0%) of office visits had any medication prescribed; laboratory tests or imaging were ordered for 29.2% (95% CI, 28.5%-29.8%) of video visits, 27.3% (95% of telephone visits, and 59.3% (95% CI, 59.3%-59.4%) of clinic visits. After adjustment, follow-up visits within 7 days occurred after 25.4% (95% CI, 24.7%-26.0%) of video visits, 26.0% (95% of telephone visits, and 24.5% (95% CI, 24.5%-24.6%) of office visits. Adjusted emergency department visits and rates of hospitalizations were not statistically significantly different by primary care index visit type. In this cohort study of patient self-scheduled primary care telemedicine visits within ongoing patient-physician relationships, prescribing and orders were significantly lower for telemedicine visits than for clinic visits, with slightly higher follow-up office visits for telemedicine but no difference in health events (emergency department visits or hospitalizations). Video or telephone visits may be a convenient and efficient way to access primary care and address patient needs. Authors: 2021-11-01. Prospective validation of the Kaiser Permanente prostate cancer risk calculator in a contemporary, racially diverse, referral population To prospectively validate a new prostate cancer risk calculator in a racially diverse population. We recently developed, internally validated and published the Kaiser Permanente Prostate Cancer Risk Calculator. This study is a prospective validation of the calculator in a separate, referral population over a 21-month period. All patients were tested with a uniform PSA assay and a standardized systematic, ultrasound-guided biopsy scheme. We report on 3 calculator models: Model 1 included age, race, PSA, prior biopsy status, body mass index, and family history of prostate cancer; Model 2 added digital rectal exam to Model 1 variables; Model 3 added prostate volume to Model 2 variables. We considered three outcomes: high-grade disease (Gleason score 7), low-grade disease (Gleason score=6), and no cancer. Predictive discrimination and calibration were calculated. How each model might alter biopsy frequency and outcomes at various thresholds of risk was assessed. We compared the performance of our calculator with two other calculators. In 4178 patients (16.2% Asian, 11.3% African American, 13.5% Hispanic), cancer was found in 53%; 62% were Gleason score 7. Using a high-grade risk threshold for biopsy of 10%, Model 2 predictions would result in 9% of men avoiding a biopsy, while only missing 2% of high-grade cancers. At the same threshold, Model 3 predictions would result in 26% of men avoiding a biopsy, while only missing 5% of high-grade cancers. The c-statistics for Models 1, 2, and 3 to predict high-grade disease vs. low-grade or no cancer were 0.76, 0.79 and 0.85, respectively. The c-statistics for Models 1, 2, and 3 to predict any prostate cancer vs. no cancer were 0.70, 0.72 and 0.80, respectively. All models were well calibrated for all outcomes. Our Model 3 calculator had superior discrimination for high grade disease (c-statistic=0.85, 0.84-0.86) and any cancer (0.80, In the high-grade cancer predicted risk range of 0-30%, our Model 2 was better calibrated than the PCPT and PBCG calculators. This validation of our calculator showed excellent performance for Adverse Events After COVID-19 mRNA Vaccination Safety surveillance of vaccines against COVID-19 is critical to ensure safety, maintain trust, and inform policy. To monitor 23 serious outcomes weekly, using comprehensive health records on a diverse population. This study represents an interim analysis of safety surveillance data from Vaccine Safety Datalink. The 10 162 227 vaccine-eligible members of 8 participating US health plans were monitored with administrative data updated weekly and supplemented with medical record review for selected outcomes from December 14, 2020, through June 26, 2021. Receipt of BNT162b2 (Pfizer-BioNTech) or mRNA-1273 (Moderna) COVID-19 vaccination, with a risk interval of 21 days for individuals after vaccine dose 1 or 2 compared with an interval of 22 to 42 days for similar individuals after vaccine dose 1 or 2. Incidence of serious outcomes, including acute myocardial infarction, Bell palsy, cerebral venous sinus thrombosis, pulmonary embolism, stroke, and thrombosis with thrombocytopenia syndrome. Incidence of events that occurred among vaccine recipients 1 to 21 days after either dose 1 or 2 of a messenger RNA (mRNA) vaccine was compared with that of vaccinated concurrent comparators who, on the same calendar day, had received their most recent dose 22 to 42 days earlier. Rate ratios (RRs) were estimated by Poisson regression, adjusted for age, sex, race and ethnicity, health plan, and calendar day. For a signal, a 1-sided P < .0048 was required to keep type I error below .05 during 2 years of weekly analyses. For 4 additional outcomes, including anaphylaxis, only descriptive analyses were conducted. A total of 11 845 128 doses of mRNA vaccines (57% BNT162b2; 6 175 813 first doses and 5 669 315 second doses) were administered to 6.2 million individuals (mean age, 49 years; 54% female individuals). The incidence of events per 1 000 000 person-years during the risk vs comparison intervals for ischemic stroke was 1612 vs 1781 (RR, 95% CI, 0.89-1.18). No vaccine-outcome association met the prespecified requirement for a signal. Incidence of confirmed anaphylaxis was 4.8 (95% CI, 3.2-6.9) per million doses of BNT162b2 and 5.1 (95% CI, 3.3-7.6) per million doses of mRNA-1273. In interim analyses of surveillance of mRNA COVID-19 vaccines, incidence of selected serious outcomes was not significantly higher 1 to 21 days postvaccination compared with 22 to 42 days postvaccination. While CIs were wide for many outcomes, surveillance is ongoing. Authors: Klein, Nicola P; 12;326(14):1390-1399. Intensive lactation among women with recent gestational diabetes significantly alters the early postpartum circulating lipid profile: the SWIFT study Women with a history of gestational diabetes mellitus (GDM) have a 7-fold higher risk of developing type 2 diabetes (T2D). It is estimated that 20-50% of women with GDM history will progress to T2D within 10 years after delivery. Intensive lactation could be negatively associated with this risk, but the mechanisms behind a protective effect remain unknown. In this study, we utilized a prospective GDM cohort of 1010 women without T2D at 6-9 weeks postpartum (study baseline) and tested for T2D onset up to 8 years post-baseline (n=980). Targeted metabolic profiling was performed on fasting plasma samples collected at both baseline and follow-up (1-2 years post-baseline) during research exams in a subset of 350 women (216 intensive breastfeeding, IBF vs. 134 intensive formula feeding or mixed feeding, IFF/Mixed). The relationship between lactation intensity and circulating metabolites at both baseline and follow-up were evaluated to discover underlying metabolic responses of lactation and to explore the link between these metabolites and T2D risk. We observed that lactation intensity was strongly associated with decreased glycerolipids (TAGs/DAGs) and increased phospholipids/sphingolipids at baseline. This lipid profile suggested decreased lipogenesis caused by a shift away from the glycerolipid metabolism pathway towards the phospholipid/sphingolipid metabolism pathway as a component of the mechanism underlying the benefits of lactation. Longitudinal analysis demonstrated that this favorable lipid profile was transient and diminished at 1-2 years postpartum, coinciding with the cessation of lactation. Importantly, when stratifying these 350 women by future T2D status during the follow-up (171 future T2D vs. 179 no T2D), we discovered that lactation induced robust lipid changes only in women who did not develop incident T2D. Subsequently, we identified a cluster of metabolites that strongly associated with future T2D risk from which we developed a predictive metabolic signature with a discriminating power (AUC) of 0.78, superior to common clinical variables (i.e., fasting glucose, AUC 0.56 or 2-h glucose, AUC 0.62). In this study, we show that intensive lactation significantly alters the circulating lipid profile at early postpartum and that women who do not respond metabolically to lactation are more likely to develop T2D. We also discovered a 10-analyte metabolic signature capable of predicting future onset of T2D in IBF women. Our findings provide novel insight into how lactation affects maternal metabolism and its link to future diabetes onset. ClinicalTrials.gov NCT01967030 10 08;19(1):241. Epub 2021-10-08. Effectiveness of Covid-19 Vaccines in Ambulatory and Inpatient Care Settings There are limited data on the effectiveness of the vaccines against symptomatic coronavirus disease 2019 (Covid-19) currently authorized in the United States with respect to hospitalization, admission to an intensive care unit (ICU), or ambulatory care in an emergency department or urgent care clinic. We conducted a study involving adults (50 years of age) with Covid-19-like illness who underwent molecular testing for severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). We assessed 41,552 admissions to 187 hospitals and 21,522 visits to 221 emergency departments or urgent care clinics during the period from January 1 through June 22, 2021, in multiple states. The patients' vaccination status was documented in electronic health records and immunization registries. We used a test-negative design to estimate vaccine effectiveness by comparing the odds of a positive test for SARS-CoV-2 infection among vaccinated patients with those among unvaccinated patients. Vaccine effectiveness was adjusted with weights based on propensity-for-vaccination scores and according to age, geographic region, calendar time (days from January 1, 2021, to the index date for each medical visit), and local virus circulation. The effectiveness of full messenger RNA (mRNA) vaccination (14 days after the second dose) was 89% (95% confidence interval [CI], 87 to 91) against laboratory-confirmed SARS-CoV-2 infection leading to hospitalization, 90% (95% CI, 86 to 93) against infection leading to an ICU admission, and 91% (95% CI, 89 to 93) against infection leading to an emergency department or urgent care clinic visit. The effectiveness of full vaccination with respect to a Covid-19-associated hospitalization or emergency department or urgent care clinic visit was similar with the BNT162b2 and mRNA-1273 vaccines and ranged from 81% to 95% among adults 85 years of age or older, persons with chronic medical conditions, and Black or Hispanic adults. The effectiveness of the Ad26.COV2.S vaccine was 68% (95% CI, 50 to 79) against laboratory-confirmed SARS-CoV-2 infection leading to hospitalization and 73% (95% CI, 59 to 82) against infection leading to an emergency department or urgent care clinic visit. Covid-19 vaccines in the United States were highly effective against SARS-CoV-2 infection requiring hospitalization, ICU admission, or an emergency department or urgent care clinic visit. This vaccine effectiveness extended to populations that are disproportionately affected by SARS-CoV-2 infection. (Funded by the Centers for Disease Control and Prevention.). Authors: Thompson, Mark G; Fireman, Epub 2021-09-08. QT Interval Dynamics and Cardiovascular Outcomes: A Cohort Study in an Integrated Health Care Delivery System Background Long QT has been associated with ventricular dysrhythmias, cardiovascular disease (CVD) mortality, and sudden cardiac death. However, no studies to date have investigated the dynamics of within-person QT change over time in relation to risk of incident CVD and all-cause mortality in a real-world setting. Methods and Results A cohort study among members of an integrated health care delivery system in Northern California including 61 455 people (mean age, 62 years; 60% women, 42% non-White) with 3 in 2005-2009; mean\u00b1SD follow-up time, 7.6\u00b12.6 years). In fully adjusted models, tertile 3 versus tertile 1 of average QT corrected (using the Fridericia correction) was associated with cardiac arrest (hazard ratio [HR], 1.66), heart failure (HR, 1.62), ventricular dysrhythmias (HR, 1.56), all CVD (HR, 1.31), ischemic heart disease (HR, 1.28), total stroke (HR, 1.18), and all-cause mortality (HR, 1.24). Tertile 3 versus tertile 2 of the QT corrected linear slope was associated with cardiac arrest (HR, 1.22), ventricular dysrhythmias (HR, 1.12), and all-cause mortality (HR, 1.09). Tertile 3 versus tertile 1 of the QT corrected root mean squared error was associated with ventricular dysrhythmias (HR, 1.34), heart failure (HR, 1.28), all-cause mortality (HR, 1.20), all CVD (HR, 1.14), total stroke (HR, 1.08), and ischemic heart disease (HR, 1.07). Conclusions Our results demonstrate improved predictive ability for CVD outcomes using longitudinal information from serial ECGs. Long-term average QT corrected was more strongly associated with CVD outcomes than the linear slope or the root mean squared error. This new evidence is clinically relevant because ECGs are frequently used, noninvasive, and common diuretic known to be photosensitizing and previously associated with non-melanoma skin cancer, was recently reported to be associated with two melanoma subtypes, nodular and lentigo, among residents of Denmark. Our goal was to examine whether Danish findings could be replicated in a US cohort, using a similar study design and analysis. Among non-Hispanic White enrollees of Kaiser Permanente Northern California, we conducted an analysis of 9176 melanoma cases and 264 781 controls, matched on age, sex and time in health plan. We examined use of HCTZ prior to cancer diagnosis (cases) or comparable date for controls, categorized as never use, ever use and high use (50 000 mg). Electronic health records provided data on prescriptions, cancer diagnoses, and covariates. Conditional logistic regression was used to calculate odds ratios (ORs) and 95% confidence intervals (CIs), adjusted for education, income and number of dermatology, internal medicine and urgent care visits. We observed a small increase in risk of melanoma, all types combined, associated with high use (50 000 mg) of HCTZ (OR = 1.11, 95% CI 1.00-1.23) and no evidence of a dose-response. Risk was more elevated for lentigo subtype (OR = 1.57, 95% CI 1.01-2.42). The somewhat elevated risk for nodular subtype was not statistically significant (OR = 1.22, 95% CI 0.78-1.90). There was very little association of high use with the superficial spreading subtype (OR = 1.05, 95% CI 0.80-1.37). Our findings support a recent report of an association between high use of HCTZ and increased risk of the Epub Association of Cardiovascular Outcomes and Mortality With Sustained Long-Acting Insulin Only vs Long-Acting Plus Short-Acting Insulin Treatment Cardiovascular events and mortality are the principal causes of excess mortality and health care costs for people with type 2 diabetes. No large studies have specifically compared long-acting insulin alone with long-acting plus short-acting insulin with regard to cardiovascular outcomes. To compare cardiovascular events and mortality in adults with type 2 diabetes receiving long-acting insulin who do or do not add short-acting insulin. This retrospective cohort study emulated a randomized experiment in which adults with type 2 diabetes who experienced a qualifying glycated hemoglobin A1c (HbA1c) level of 6.8% to 8.5% with long-acting insulin were randomized to continuing treatment with long-acting insulin (LA group) or adding short-acting insulin within 1 year of the qualifying HbA1c level (LA plus SA group). Retrospective data in 4 integrated health care delivery systems from the Health Care Systems Research Network from January 1, 2005, to December 31, 2013, were used. Analysis used inverse probability weighting estimation with Super Learner for propensity score estimation. Analyses took place from April 1, 2018, to June 30, 2019. Long-acting insulin alone or with added short-acting insulin within 1 year from the qualifying HbA1c level. Mortality, cardiovascular mortality, acute myocardial infarction, stroke, and hospitalization for heart failure. Among 57 278 individuals (39 279 with data on cardiovascular mortality) with a mean (SD) age of 60.6 (11.5) years, 53.6% men, 43.5% non-Hispanic White individuals, and 4 years of follow-up (median follow-up of 11 [interquartile range, 5-20] calendar quarters), the LA plus SA group was associated with increased all-cause mortality compared with the LA group (hazard ratio, 1.27; 95% CI, 1.05-1.49) and a decreased risk of acute myocardial infarction (hazard ratio, 0.89; 95% CI, 0.81-0.97). Treatment with long-acting plus short-acting insulin was not associated with increased risks of congestive heart failure, stroke, or cardiovascular mortality. Findings of this retrospective cohort study suggested an increased risk of all-cause mortality and a decreased risk of acute myocardial infarction for the LA plus SA group compared with the LA group. Given the lack of an increase in major cardiovascular events or cardiovascular mortality, the increased all-cause mortality with long-acting plus short-acting insulin may be explained by noncardiovascular 2021 09 01;4(9):e2126605. Epub Presti, Joseph; Alexeeff, Stacey; 09;36(9):2854-2855. Epub 2021-07-13. Lifestyle-related education and counseling resource utilization and cardiovascular biomarkers in midlife women with low physical activity Health plan-based resources are promising avenues for decreasing cardiovascular disease risk. This study examined associations of lifestyle-related resource utilization within a healthcare delivery system and cardiovascular biomarkers among midlife women with low physical activity. Midlife women (45-55 years old) with <10 min/week of reported physical activity at a primary care visit within a large integrated healthcare delivery system in Northern California in 2015 (n = 55,393) were identified. Within this cohort, subsequent lifestyle-related health education and individual coaching resource utilization, and the next recorded physical activity, weight, systolic blood pressure, plasma glucose, HDL and LDL cholesterol measures up to 2 years after the index primary care visit were identified from electronic health records. We used a multilevel linear model to estimate associations. About 3% (n = 1587) of our cohort had 1 lifestyle-related resource encounter; 0.3% (n = 178) had 4 encounters. Participation in 4 lifestyle-related resource encounters (compared to none) was associated with 51 more minutes/week of physical activity (95% CI: 33,69) at the next clinical measurement in all women, 6.2 kg lower weight (95% CI: -7.0,-5.5) at the next measurement in women with obesity, and 8-10 mg/dL lower plasma glucose (95% CI: -30,14 and -23,2, respectively) at the next measurement in women with diabetes or prediabetes. Our results support the sustained utilization of health plan-based lifestyle-related resources for improving physical activity, weight, and plasma glucose in high-risk midlife women. Given the observed low utilization, health system-wide efforts may be warranted to increase utilization of lifestyle-related resources in this lifestyle preterm birth: a prospective cohort study Preterm birth (PTB) remains a leading cause of neonatal mortality and long-term morbidity. Individual factors have been linked to PTB risk. The impact of a healthy lifestyle, with multiple modifiable prenatal factors, remains unknown. We aimed to examine the associations of preconceptional and early-pregnancy low-risk modifiable factors (individually and in combination) with PTB risk. This prospective cohort study included 2449 women with singleton pregnancies in the Pregnancy Environment and Lifestyle Study. PTB was defined as ultrasound-confirmed obstetric estimate-based gestational age at delivery <37 wk. A weight (prepregnancy BMI: 18.5-24.9 kg/m2) based on clinical measurements and high-quality diet (Alternate Healthy Eating Index-Pregnancy score 75th percentile) and low-to-moderate stress during early pregnancy (Perceived Stress Scale score <75th percentile) assessed at gestational weeks 10-13. Poisson regression estimated adjusted relative risk (aRR) of PTB in association with individual and combined low-risk modifiable prenatal factors, adjusting for sociodemographic, clinical, and other prenatal factors. One hundred and sixty women (6.5%) delivered preterm. Risk of PTB was lower among women who had healthy 2, or 3 low-risk modifiable prenatal factors compared with none had PTB risk, respectively. Associations of having 1 low-risk factor with PTB risk were more pronounced for medically indicated than for spontaneous PTB and for late than for early or moderate PTB. Associations also varied by race or ethnicity, although with overlapping 95% CIs. A healthy prenatal lifestyle with multiple low-risk modifiable factors was associated with lower risk of PTB. Our findings may inform multicomponent preconceptional or early-pregnancy prevention IN OBSTETRICS Authors: Escobar, Gabriel J; Schuler, Gynecol. 2021 08;225(2):208. Epub 2021-04-23. COVID-19 Vaccination Coverage Among Insured Persons Aged 16 Years, by Race/Ethnicity and Other Selected Characteristics - Eight Integrated Health Care Organizations, United States, December 14, 2020-May 15, 2021 COVID-19 vaccination is critical to ending the COVID-19 pandemic. Members of minority racial and ethnic groups have experienced disproportionate COVID-19-associated morbidity and mortality (1); however, COVID-19 vaccination coverage is lower in these groups (2). CDC used data from CDC's Vaccine Safety Datalink (VSD)* to assess disparities in vaccination coverage among persons aged 16 years by race and ethnicity during December 14, 2020-May 15, 2021. Measures of coverage included receipt of 1 COVID-19 vaccine dose (i.e., receipt of the first dose of the Pfizer-BioNTech or Moderna COVID-19 vaccines or 1 dose of the Janssen COVID-19 vaccine [Johnson & Johnson]) and full vaccination (receipt of 2 doses of the Pfizer-BioNTech or Moderna COVID-19 vaccines or 1 dose of Janssen COVID-19 vaccine). Among 9.6 million persons aged 16 years enrolled in VSD during December 14, 2020-May 15, 2021, 1-dose coverage was 48.3%, and 38.3% were fully vaccinated. As of May 15, 2021, coverage with 1 dose was lower among non-Hispanic Black (Black) and Hispanic persons (40.7% and 41.1%, respectively) than it was among non-Hispanic White (White) persons (54.6%). Coverage was highest among non-Hispanic Asian (Asian) persons (57.4%). Coverage with 1 dose was higher among persons with certain medical conditions that place them at higher risk for severe COVID-19 (high-risk conditions) (63.8%) than it was among persons without such conditions (41.5%) and was higher among persons who had not had COVID-19 (48.8%) than it was among those who had (42.4%). Persons aged 18-24 years had the lowest 1-dose coverage (28.7%) among all age groups. Continued monitoring of vaccination coverage and efforts to improve equity in coverage are critical, especially among populations disproportionately affected by COVID-19. Authors: Pingali, 16;70(28):985-990. Epub 2021-07-16. Particulate Matter and Cardiovascular Risk in Adults with Chronic Obstructive Pulmonary Disease Rationale: People with chronic obstructive pulmonary disease (COPD) have an increased risk of cardiovascular disease and may be more susceptible to air pollution exposure. However, no study has examined the association between long-term fine particulate matter exposure (2.5 m in aerodynamic diameter) and risk of cardiovascular events in this potentially vulnerable population. Objectives: To estimate the association between long-term fine particulate matter and risk of cardiovascular events among adults with COPD. Methods: This retrospective cohort study included 169,714 adults with COPD who were members of the Kaiser Permanente Northern California health plan during 2007-2016. Electronic health record data were linked to 1 km modeled particulate matter 2.5 m in aerodynamic diameter exposure estimates. We fit Cox proportional hazard models, adjusting for age, sex, race/ethnicity, calendar year, smoking, body mass index, comorbidities, medications, and socioeconomic status. In low exposure analyses, we examined effects below the current regulation limit (12 g/m3). Measurements and Main Results: Among adults with COPD, a 10-g/m3 increase in 1-year mean fine particulate matter exposure was associated with an elevated risk of cardiovascular mortality (hazard ratio, 1.10; 95% confidence interval [CI], 1.01-1.20). Effects were stronger in low exposure analyses (hazard ratio, 1.88; 95% CI, 1.56-2.27). Fine particulate matter exposure was not associated with acute myocardial infarction or stroke in overall analyses. Conclusions: Long-term fine particulate matter exposure was associated with an increased risk of cardiovascular mortality among adults with COPD. Current regulations may not sufficiently protect those with Alexeeff, Sidney, Am J Respir Crit Care Med. 2021 07 15;204(2):159-167. The effect of mail order pharmacy outreach on older patients with diabetes Authors: Gong, Chelsea; 2021-03-26. Mediating Effects of Cardiometabolic Risk Factors on the Association Between Maternal Race-Ethnicity and Cesarean Delivery Among Low-Risk Women Background: While racial-ethnic disparities in cesarean delivery rates among nulliparous women delivering a term singleton in the vertex position (NTSV) exist, it remains unclear the extent to which potentially modifiable maternal cardiometabolic risk factors (obesity, maternal hyperglycemia and hypertensive disorders) underlie these disparities. We examined race-ethnicity and risk of NTSV cesarean deliveries and whether the associations were mediated by maternal cardiometabolic risk factors. Materials and Methods: A cohort study of 62,048 NTSV deliveries in Kaiser Permanente Northern California. The outcome was cesarean delivery. Results: Black, Asian, and Hispanic women were at increased risk of having a NTSV cesarean delivery compared with White women (relative risks and 95% confidence intervals: 1.37 [1.28-1.45]; 1.11 [1.07-1.16]; 1.12 [1.07-1.16], respectively), independent of established risk factors and prenatal care utilization. The extent to which cardiometabolic risk factors mediated the associations between race-ethnicity (each group vs. White, in separate analyses) and NTSV cesarean delivery varied by race-ethnicity. Maternal overweight/obesity (body mass index 25.0) mediated the association between Black and Hispanic race-ethnicity and NTSV cesarean delivery (21.1% [15.8-26.4] and 24.7% [14.6-34.8, respectively), but not for Asian race. Maternal hyperglycemia (gestational diabetes mellitus or preexisting diabetes) mediated the association between Asian and Hispanic race and NTSV cesarean delivery (18.5% [9.8-27.2] and 9.8% [5.0-14.7], respectively), but not for Black race. Hypertensive disorders mediated 3.2% (0.70-5.8) of the association between Black race and cesarean delivery, but not for other race-ethnicities. Conclusion: Black, Asian, and Hispanic women are at increased risk for NTSV cesarean deliveries. Maternal cardiometabolic risk factors only partially mediate the associations between race-ethnicity and NSTV cesarean and Causal Inference with Unmeasured Exposures: An Application to Birth Cohort Studies of Early BMI Rebound Observational studies reporting on adjusted associations between childhood body mass index (BMI; weight (kg)/height (m)2) rebound and subsequent cardiometabolic outcomes have often not paid explicit attention to causal inference, including definition of a target causal effect and assumptions for unbiased estimation of that effect. Using data from 649 children in a Boston, Massachusetts-area cohort recruited in 1999-2002, we considered effects of stochastic interventions on a chosen subset of modifiable yet unmeasured exposures expected to 01;190(7):1414-1423. Visual Outcomes After Cataract Surgery: Topical NSAID Prophylaxis Compared with Prednisolone To compare visual outcomes in patients without a history of macular edema after phacoemulsification using combination topical nonsteroidal anti-inflammatory drug plus prednisolone with prednisolone alone. Kaiser Permanente Northern California, USA. Retrospective cohort study. Information was obtained from the electronic health record. The first measure of corrected distance visual acuity (CDVA) recorded during the period 3 weeks to 1 year after phacoemulsification was obtained. Confounding factors and clustering of eyes within patients were adjusted using linear mixed effects regression models for the continuous outcome of CDVA improvement and general estimating equations for the dichotomous outcome of 20/20 or better vs 20/25 or worse. The study included 62 700 health plan members of whom 26,309 (42%) used topical prednisolone alone, whereas 36,391 (58%) used combination treatment. The mean within-person change in CDVA from the preoperative measurement to the postoperative measurement was the same (-0.43 logMAR) for patients in the 2 groups. However, the group that received combination treatment was somewhat more likely to achieve CDVA of 20/20 or better (odds ratio 1.24 with 95% CI, 1.20-1.28). In this large study of cataract surgery patients, a small statistically significant association of combination treatment compared with prednisolone alone was observed. Authors: 2021 Jul 01;47(7):870-877. Participant education, spousal education and dementia risk in a diverse cohort of members of an integrated health care delivery system in Northern California The role of spousal education on dementia risk and how it may differ by gender or race/ethnicity is unknown. This study examines the association between one's own education separate from and in conjunction with spousal education and risk of dementia. Cohort. Kaiser Permanente Northern California (KPNC), an integrated health care delivery system. 8835 members of KPNC who were aged 40-55, married and reported own and spousal education in 1964-1973. Dementia cases were identified through medical records from 1 January 1996 to 30 September 2017. Own and spousal education was self-reported in 1964-1973 and each was classified as four indicator variables (high school, trade school/some college, college degree and postgraduate) and as college degree versus college degree. Age as timescale weighted Cox proportional hazard models adjusted for demographics and health indicators evaluated associations between participant education, spousal education and dementia risk overall and by gender and race/ethnicity. The cohort was 37% non-white, 46% men and 30% were diagnosed with dementia during follow-up from 1996 to 2017 (mean follow-up=12.7 years). Greater participant education was associated with lower dementia risk independent of spousal education, demographics and health indicators. Greater spousal education was associated with lower dementia adjusting for demographics but became non-significant after further adjustment for participant education. The same pattern was seen for spousal education college degree (not adjusting for participant education HRspousal educationcollege degree=0.83 (95% (95% CI: 0.83 to 1.01)). These associations did not vary by gender or race/ethnicity. In a large diverse cohort, we found that higher levels of participant's own education were associated with lower dementia risk regardless of spousal education. An inverse association between spousal education and dementia risk was also present, however, the effects became non-significant after adjusting for participant education. Authors: Gilsanz, Epub Association of Type 1 Diabetes and Hypoglycemic and Hyperglycemic Events and Risk of Dementia To determine whether severe hypoglycemic and hyperglycemic events are associated with longitudinal dementia risk in older adults with type 1 diabetes. A longitudinal cohort study followed 2,821 members of an integrated healthcare delivery system with type 1 diabetes from 1997-2015. Hypoglycemic and hyperglycemic events requiring emergency room or hospitalization were abstracted from medical records beginning 1/1/1996 through cohort entry. Participants were followed for dementia diagnosis through 9/30/2015. Dementia risk was examined using Cox proportional hazard models adjusted for age (as timescale), sex, race/ethnicity, HbA1c, depression, stroke, and nephropathy. Among 2,821 older adults (mean age 56) with type 1 diabetes, 398 (14%) had a history of severe hypoglycemia, 335 (12%) severe hyperglycemia and 87 (3%) both. Over a mean 6.9 years of follow-up, 153 individuals (5.4%) developed dementia. In fully adjusted models, individuals with hypoglycemic events had 66% greater risk of dementia than those without a hypoglycemic event (HR=1.66; 95% CI: 1.09, 2.53), while those with hyperglycemic events >2 times the risk (HR=2.11; 95% CI: 1.24, 3.59) than those without a hyperglycemic event. There was a 6-fold greater risk of dementia in individuals with both severe hypoglycemia and hyperglycemia versus those with neither (HR=6.20; 95% CI: 3.02, 12.70). For older individuals with type 1 diabetes, severe hypoglycemic and hyperglycemic events are associated with increased future risk of dementia. Whitmer, 2021 Jun 02. A prognostic information system for real-time personalized care: Lessons for embedded researchers Embedded researchers could play a central role in developing tools to personalize care using electronic medical records (EMRs). However, few studies have described the steps involved in developing such tools, or evaluated the key factors in success and failure. This case study describes how we used an EMR-derived data warehouse to develop a prototype informatics tool to help oncologists counsel patients with pancreatic cancer about their prognosis. The tool generated real-time prognostic information based on tumor type and stage, age, comorbidity status and lab tests. Our multidisciplinary team included embedded researchers, application developers, user experience experts, and an oncologist leader.This prototype succeeded in establishing proof of principle, but did not reach adoption into actual practice. In pilot testing, oncologists succeeded in generating prognostic information in real time. A few found it helpful in patient encounters, but all identified critical areas for further development before implementation. Generalizable lessons included the need to (1) include a wide range of potential use cases and stakeholders when selecting use cases for such tools; (2) develop talking points for clinicians to explain results from predictive tools to patients; (3) develop ways to reduce lag time between events and data availability; and (4) keep the options presented in the user interface very simple. This case demonstrates that embedded researchers can lead collaborations using EMR-derived data to create systems for real-time personalized patient counseling, and highlights challenges that such teams can anticipate. Authors: Lieu, Tracy A; Neugebauer, Romain; Van Den to Mail Order Pharmacy Use and Racial/Ethnic Disparities for Patients With Diabetes? Authors: 06;44(6):e113-e114. Epub 2021-04-13. Racial Disparities in COVID-19 Testing and Outcomes : Retrospective Cohort Study in an Integrated Health System Racial disparities exist in outcomes after severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection. To evaluate the contribution of race/ethnicity in SARS-CoV-2 testing, infection, and outcomes. Retrospective cohort study (1 February 2020 to 31 May 2020). Integrated health care delivery system in Northern California. Adult health plan members. Age, sex, neighborhood deprivation index, comorbid conditions, acute physiology indices, and race/ethnicity; SARS-CoV-2 testing and incidence of positive test results; and hospitalization, illness severity, and mortality. Among 3 481 716 eligible members, 42.0% were White, 6.4% African American, 19.9% Hispanic, and 18.6% Asian; 13.0% were of other or unknown race. Of eligible members, 91 212 (2.6%) were tested for SARS-CoV-2 infection and 3686 had positive results (overall incidence, 105.9 per 100 000 persons; by racial group, White, 55.1; African American, 123.1; Hispanic, 219.6; Asian, 111.7; other/unknown, 79.3). African American persons had the highest unadjusted testing and mortality rates, White persons had the lowest testing rates, and those with other or unknown race had the lowest mortality rates. Compared with White persons, adjusted testing rates among non-White persons were marginally higher, but infection rates were significantly higher; adjusted odds ratios [aORs] for African American persons, Hispanic persons, Asian persons, and persons of other/unknown race were 2.01 (95% CI, 1.75 2.19 (CI, 1.98 to 2.42), and 1.57 (CI, 1.38 to 1.78), respectively. Geographic analyses showed that infections clustered in areas with higher proportions of non-White persons. Compared with White persons, adjusted hospitalization rates for African American persons, Hispanic persons, Asian persons, and persons of other/unknown race were 1.47 (CI, 1.03 to 2.09), 1.42 (CI, 1.11 to 1.82), 1.47 (CI, 1.13 to 1.92), and 1.03 (CI, 0.72 to 1.46), respectively. Adjusted analyses showed no racial differences in inpatient mortality or total mortality during the study period. For testing, comorbid conditions made the greatest relative contribution to model explanatory power (77.9%); race only accounted for 8.1%. Likelihood of infection was largely due to race (80.3%). For other outcomes, age was most important; race only contributed 4.5% for hospitalization, 12.8% for admission illness severity, 2.3% for in-hospital death, and 0.4% for any death. The study involved an insured population in a highly integrated health system. Race was the most important predictor of SARS-CoV-2 infection. After infection, race was associated with increased hospitalization risk but not mortality. The Permanente Medical Group, Inc. Authors: Escobar, Gabriel J; Adams, Alyce Epub 2021-02-09. Design of the Association of Uterine Perforation and Expulsion of IUD (APEX-IUD) Study: A Multisite Retrospective Cohort Study Intrauterine devices are effective and safe, long-acting reversible contraceptives, but the risk of uterine perforation occurs with an estimated incidence of 1 to 2 per 1000 insertions. The European Active Surveillance Study for Intrauterine Devices, a European prospective observational study that enrolled 61,448 participants (2006-2012), found that women breastfeeding at the time of device insertion or with the device inserted at 36 weeks after delivery had a higher risk of uterine perforation. The Association of Uterine Perforation and Expulsion of Intrauterine Device (APEX-IUD) study was a Food and Drug Administration-mandated study designed to reflect current United States clinical practice. The aims of the APEX-IUD study were to evaluate the risk of intrauterine device-related uterine perforation and device expulsion among women who were breastfeeding or within 12 months after delivery at insertion. We aimed to describe the APEX-IUD study design, methodology, and analytical plan and present population characteristics, size of risk factor groups, and duration of follow-up. APEX-IUD study was a retrospective cohort study conducted in 4 organizations with access to electronic health records: Kaiser Permanente Northern California, Kaiser Permanente Southern California, Kaiser Permanente Washington, and Regenstrief Institute in Indiana. Variables were identified through structured data (eg, diagnostic, procedural, medication codes) and unstructured data (eg, clinical notes) via natural language processing. Outcomes include uterine perforation and device expulsion; potential risk factors were breastfeeding at insertion, postpartum timing of insertion, device type, and menorrhagia diagnosis in the year before insertion. Covariates include demographic characteristics, clinical characteristics, and procedure-related variables, such as difficult insertion. The first potential date of inclusion for eligible women varies by research site (from January 1, 2001 to January 1, 2010). Follow-up begins at insertion and ends at first occurrence of an outcome of interest, a censoring event (device removal or reinsertion, pregnancy, hysterectomy, sterilization, device expiration, death, disenrollment, last clinical encounter), or end of the study period (June 30, 2018). Comparisons of levels of exposure variables were made using Cox regression models with confounding adjusted by propensity score weighting using overlap weights. The study population includes 326,658 women with at least 1 device insertion during the study period (Kaiser Permanente Northern California, 161,442; Kaiser Permanente Southern California, 123,214; Kaiser Permanente Washington, 20,526; Regenstrief Institute, 21,476). The median duration of continuous enrollment was 90 (site medians 74-177) months. The mean age was 32 years, and the population was racially and ethnically diverse across the 4 sites. The mean body mass index was 28.5 kg/m2, and of the women included in the study, 10.0% had menorrhagia 12 months before insertion, 5.3% had uterine fibroids, and 10% were recent smokers; furthermore, among these women, 79.4% had levonorgestrel-releasing devices, and 19.5% had copper devices. Across sites, 97,824 women had an intrauterine device insertion at 52 weeks after delivery, of which 94,817 women (97%) had breastfeeding status at insertion determined; in addition, 228,834 women had intrauterine device insertion at >52 weeks after delivery or no evidence of a delivery in their health record. Combining retrospective data from multiple sites allowed for a large and diverse study population. Collaboration with clinicians in the study design and validation of outcomes ensured that the APEX-IUD study results reflect current United States clinical practice. Results from this study will provide valuable information based on real-world evidence about risk factors for intrauterine devices perforation and expulsion for clinicians. Authors: Anthony, Mary S; Epub 2021-01-15. Timing of Antiretroviral Therapy Initiation and Risk of Cancer among Persons Living with HIV Persons living with human immunodeficiency virus (HIV; PLWH) experience a high burden of cancer. It remains unknown which cancer types are reduced in PLWH with earlier initiation of antiretroviral therapy (ART). We evaluated AIDS-free, ART-naive PLWH during 1996-2014 from 22 cohorts participating in the North American AIDS Cohort Collaboration on Research and Design. PLWH were followed from first observed CD4 of 350-500 cells/\u00b5L (baseline) until incident cancer, death, lost-to-follow-up, or December 2014. Outcomes included 6 cancer groups and 5 individual cancers that were confirmed by chart review or cancer registry linkage. We evaluated the effect of earlier (in the first 6 months after baseline) versus deferred ART initiation on cancer risk. Marginal structural models were used with inverse probability weighting to account for time-dependent confounding and informative right-censoring, with weights informed by subject's age, sex, cohort, baseline year, race/ethnicity, HIV transmission risk, smoking, viral hepatitis, CD4, and AIDS diagnoses. Protective results for earlier ART were found for any cancer (adjusted hazard ratio [HR] 0.57; 95% confidence 95% CI, .06-.73). By 15 years, there was also an observed reduced risk with earlier ART for virus-related NADCs (0.6% vs 2.3%; adjusted risk difference -1.6; 95% CI, -2.8, -.5). Earlier ART initiation has potential to reduce the burden of virus-related cancers in PLWH but not non-AIDS-defining cancers (NADCs) without 2021 06 01;72(11):1900-1909. Particulate Air Pollution and Risk of Cardiovascular Events Among Adults With a History of Stroke or Acute Myocardial Infarction Background Previous studies have found associations between fine particulate matter <2.5 \u00b5m in diameter (PM2.5) and increased risk of cardiovascular disease (CVD) among populations with no CVD history. Less is understood about susceptibility of adults with a history of CVD and subsequent PM2.5-related CVD events and whether current regulation levels for PM2.5 are protective for this population. Methods and Results This retrospective cohort study included 96 582 Kaiser Permanente Northern California adults with a history of stroke or acute myocardial infarction. Outcome, covariate, and address data obtained from electronic health records were linked to time-varying 1-year mean PM2.5 exposure estimates based on residential locations. Cox proportional hazard models estimated risks of stroke, acute myocardial infarction, and cardiovascular mortality associated with PM2.5 exposure, adjusting for multiple covariates. Secondary analyses estimated risks below federal and state regulation levels (12 \u00b5g/m3 for 1-year mean PM2.5). A 10-\u00b5g/m3 increase in 1-year mean PM2.5 exposure was associated with an increase in risk of cardiovascular mortality (hazard ratio [HR], 1.20; 95% CI, 1.11-1.30), but no increase in risk of stroke or acute myocardial infarction. Analyses of <12 \u00b5g/m3 showed increased risk for (HR, CI, 1.96-2.71), 10-\u00b5g/m3 increase in 1-year mean PM2.5. Conclusions Adults with a history of CVD are susceptible to the effects of PM2.5 exposure, particularly on CVD mortality. Increased risks observed at exposure levels <12 \u00b5g/m3 highlight that current PM2.5 regulation levels may not be protective for this susceptible population. Authors: Liao, Noelle S; Sidney, Fat Volumes in Parous Women: the CARDIA Study Lactation is associated with lower risks for cardiovascular disease in women. Organ-related adiposity, which plays significant roles in the development of cardiometabolic diseases, could help explain this observation. We evaluated the association of lactation duration with visceral (VAT) and pericardial (PAT) fat volumes in women. Data were obtained from 910 women enrolled in the Coronary Artery Risk Development in Young Adults (CARDIA) study (1985-1986) without diabetes prior to pregnancy who had 1 birth during 25 years of follow-up and had VAT and PAT measured from computed tomographic scans in 2010-2011. Cumulative lactation duration across all births since baseline was calculated from self-reports collected at periodic exams. At baseline, the average age of women (48% black, 52% white) was 24 \u00b1 3.7 years. After controlling for baseline age, race, smoking status, body mass index, fasting glucose, family history of diabetes, fat intake, total cholesterol, physical activity, and follow-up covariates (parity, gestational diabetes), the mean fat volumes across categories of lactation [none (n = 221), 1-5 months (n = 306), 6-11 months (n = 210), and 12 months (n = 173)] were 122.0, 113.7 105.0, and 110.1 cm3 for VAT and 52.2, 46.7, 44.5, and 43.4 cm3 for PAT, respectively. Changes in body weight from the first post-baseline birth to the end of follow-up mediated 21% and 18% of the associations of lactation with VAT and PAT, respectively. In this prospective study, longer cumulative lactation duration was associated with lower VAT and PAT volumes, with weight gain partially mediating these associations. Authors: Appiah, Associated With Subsequent Development of Cutaneous Squamous Cell Carcinoma Risk of cutaneous squamous cell carcinoma (cSCC) after the diagnosis of actinic keratosis (AK) has not been studied during long follow-up periods. To estimate the risk up to 10 years and identify risk factors for cSCC development. This longitudinal cohort study, performed from January 1, 2009, to February 29, 2020, examined Kaiser Permanente Northern California patients with AK and control patients matched 1:1 on age, sex, race/ethnicity, medical center, and date of the initial diagnosis plus 30 days in the patients with AK. Patients with AK and control participants were followed up for up to 10 years for incidence of cSCC. Incident cSCC was obtained from pathologic data, and subdistribution hazard ratios (HRs) and 95% CIs were estimated using Cox proportional hazards regression analysis, accounting for competing risks, calendar year, demographic factors, and number of AKs. The study included 220 236 patients with AK and 220 236 matched control patients (mean [SD] age, 64.1 [12.2] years; 231 248 [52.5%] female). After losses to follow-up were accounted for, risk of cSCC increased with each year of follow-up by 1.92% (95% CI, 1.89%-1.95%) in patients with AK and 0.83% (95% CI, 0.81%-0.85%) in matched control patients (subdistribution HR, 1.90; 95% CI, 1.85-1.95). However, among patients 49 years or younger, those diagnosed with AK were nearly 7 times more likely to be diagnosed with cSCC than those without AK (HR, 6.77; 95% CI, 5.50-8.32). At 10 years, the cumulative incidence of cSCC reached 17.1% (95% CI, 16.9%-17.4%) in patients with AK and 5.7% (95% CI, 5.5%-5.9%) in control patients. Increased numbers of AKs were modestly associated with increased cSCC risk (15 AKs vs 1 AK: subdistribution HR, 1.89; 95% CI, 1.75-2.04). Older patients had much higher risk of cSCC than younger patients (compared with those 49 years of age at AK diagnosis; 80 years of age: subdistribution HR, 8.18; 95% CI, 7.62-8.78). Other than AK, risk factors for cSCC included older age, White race (a proxy for skin type), history of basal cell carcinoma, and male sex. Risk decreased between 2009 and 2019 (2018-2019 vs 2009-2010: subdistribution HR, 0.67; 95% CI, 0.63-0.72). The results of this longitudinal cohort study can be used to develop recommendations to increase early detection of cSCC. Additional research is needed to understand the effect of AK treatment on cSCC risk and outcomes of Reduction After Phacoemulsification: A Matched Cohort Study Phacoemulsification has been linked to lowered intraocular pressure (IOP) in patients with glaucoma, ocular hypertension, anatomic narrow angles, and in glaucoma suspects, but the magnitude of change has varied. Retrospective cohort study. Patients with glaucoma treated from June 2010 through May 2015 who underwent phacoemulsification (surgical group) were matched to patients who did not (nonsurgical group) for age, gender, type of glaucoma, baseline IOP, and number and type of glaucoma medications. Electronic medical record information was used to compare the matched surgical and nonsurgical groups. Change in IOP, change in number of glaucoma medications, and likelihood of a glaucoma procedure within 36 months after phacoemulsification. Intraocular pressure measures were obtained from Goldmann applanation tonometry when available (45%), and otherwise with (iCare USA, NY), noncontact tonometry, and pneumotonometry. Among 16 169 matched pairs, average IOP after the index date was lower in the surgical than nonsurgical group throughout follow-up to 36 months. The difference was greatest during months 1 through 18, during which IOP increased by 0.22 mmHg from 16.49 mmHg in the average nonsurgical patient and decreased by 0.99 mmHg from 16.50 mmHg in the average surgical patient (difference difference, 1.21 mmHg; 95% confidence interval [CI], 1.12-1.30 mmHg). The difference in difference was greatest for patients with ocular hypertension (2.00 mmHg) and for patients with preoperative IOP of 20 mmHg or more (2.46 mmHg). By 30 to 36 months, 5% (95% CI, 4%-6%) fewer surgical patients used an ophthalmic medication. In the surgical group, the odds of selective laser trabeculoplasty were reduced in patients with ocular hypertension (odds ratio [OR], 0.27; 95% suspects CI, 0.20-0.47), whereas the odds of glaucoma surgery were elevated in surgical patients with primary open-angle glaucoma (OR, 1.48; 95% CI, 1.08-2.01). The association of phacoemulsification for cataract with IOP reduction was lower than in past referral-based studies. Surgeons should expect to reduce IOP approximately 1 to 2 mmHg with phacoemulsification in patients with preoperative IOP of 2020-10-10. Comparison of dementia risk after age 50 between individuals with and without HIV infection To compare risk of dementia after age 50 by HIV status among individuals in a primary care setting. Observational cohort study; participants were identified from 2013 to 2017 and followed through 2019. Participants were people with HIV (PWH) on antiretroviral therapy (ART) and demographically similar people without HIV (PWOH), all at least 50 years old and with no prior diagnosis of dementia. The study setting was Kaiser Permanente Northern California, an integrated healthcare delivery system in the United States. Incident dementia diagnoses and baseline data on sociodemographics, smoking, alcohol use, other substance use, and clinical factors were gathered from the electronic health record. Cumulative proportion of incident dementia by HIV status was assessed using Kaplan-Meier curves. Unadjusted and adjusted hazard ratios for incident dementia by HIV status were generated using Cox proportional hazards models with age as the time scale. The study included 5381 PWH and 119 022 PWOH (average age at baseline: 57 and 58 years, respectively). Incident dementia was diagnosed in 117 PWH and 2427 PWOH. By age 80, 25.8% of PWH and 13.8% of PWOH had been diagnosed with dementia, corresponding with an unadjusted hazard ratio of 1.98 (95% CI 1.64-2.39). After adjustment for sociodemographic, substance use, and clinical factors, including frequency of outpatient visits, the risk of dementia among PWH remained elevated (vs. PWOH, adjusted hazard ratio = 1.58, 95% CI 1.31-1.92). Compared with PWOH, PWH were at 58% higher risk for dementia despite HIV treatment with ART. Research is needed to investigate the potential benefits of targeted risk factor management or earlier cognitive screening in this population. Authors: Lam, Jennifer O; Hou, Craig J AIDS. 2021 04 01;35(5):821-828. Patterns and Factors Associated With Adherence to Lung Cancer Screening in Diverse Practice Settings For lung cancer screening to confer mortality benefit, adherence to annual screening with low-dose computed tomography scans is essential. Although the National Lung Screening Trial had an adherence rate of 95%, current data are limited on screening adherence across diverse practice settings in the United States. To evaluate patterns and factors associated with adherence to annual screening for lung cancer after negative results of a baseline examination, particularly in centralized vs decentralized screening programs. This observational cohort study was conducted at 5 academic and community-based sites in North Carolina and California among 2283 individuals screened for lung cancer between July 1, 2014, and March 31, 2018, who met US Preventive Services Task Force eligibility criteria, had negative results of a baseline screening examination (American College of Radiology Lung Imaging Reporting and Data System category 1 or 2), and were eligible to return for a screening examination in 12 months. To identify factors associated with adherence, the association of adherence with selected baseline demographic and clinical characteristics, including type of screening program, was estimated using multivariable logistic regression. Screening program type was classified as centralized if individuals were referred through a lung cancer screening clinic or program and as decentralized if individuals had a direct clinician referral for the baseline low-dose computed tomography scan. Adherence to annual lung cancer screening, defined as a second low-dose computed tomography scan within 11 to 15 months after baseline screening. Among the 2283 eligible individuals (1294 years; 1160 [50.8%] aged 65 years) who had negative screening results at baseline, overall adherence was 40.2% (n = 917), with higher adherence among those who underwent screening through centralized (46.0% [478 of 1039]) vs decentralized (35.3% [439 of 1244]) programs. The independent factor most strongly associated with adherence was type of screening program, with a 2.8-fold increased likelihood of adherence associated with centralized screening (adjusted odds ratio [aOR], 2.78; 95% CI, 1.99-3.88). Another 1.10-1.96). After negative results of a baseline examination, adherence to annual lung cancer screening was suboptimal, although adherence was higher among individuals who were screened through a centralized program. These results support the value of centralized screening programs and the need to further implement strategies that improve adherence to annual screening for lung cancer. Authors: Sakoda, Lori C; Quesenberry, Charles 01;4(4):e218559. Epub 2021-04-01. Clustering of Social and Physical Pain Variables and Their Association With Mortality in Two Population-Based Cohorts Social pain and physical pain are related bidirectionally, but how these variables cluster in the population is unknown. This study included 2833 women from the Study of Women's Health Across the Nation (SWAN), a community-based cohort of middle-aged women, and 3972 women from the Pathways Study, a population-based cohort of women diagnosed with American Joint Committee on Cancer stages I-IV breast cancer diagnosed between 2005 and 2013. Women provided data on measures related to social pain (social network size, social support, loneliness, social well-being) and physical pain (sensitivity to pain, bodily pain) at study baseline. Analyzing each cohort separately, we used latent class analysis to evaluate social-physical pain clusters, logistic regression to evaluate predictors of categorization into clusters, and Cox proportional hazards models to evaluate associations of clusters with all-cause mortality. We also performed a meta-analysis to combine cohort mortality associations. Each cluster analysis produced a \"low social-physical pain\" cluster (SWAN, 48.6%; Pathways, 35.2%) characterized social and pain \"high social-physical pain\" cluster (SWAN, 17.9%; Pathways, 17.9%) symptoms, and a \"low social/high physical pain\" cluster of women with high pain and compromised social functioning but otherwise low social symptoms (SWAN, 33.5%; Pathways, 46.9%). In meta-analysis, categorization into the high social-physical pain cluster was associated with elevated mortality (adjusted hazard ratio = 1.34, 95% confidence interval = 1.05-1.71, Q statistic = 0.782), compared with those in the low social-physical pain cluster. In two cohorts of women, latent class analysis produced similar sets of social-physical pain clusters, with the same proportion having both high social and pain symptoms; women in this cluster had elevated Psychosom Med. 2021 04 01;83(3):228-238. Dual trajectories of physical activity and blood lipids in midlife women: The Study of Women's Health Across the Nation Physical activity (PA) has the potential to attenuate cardiovascular disease risk in midlife women through multiple pathways, including improving lipid profiles. Longitudinal patterns of PA and blood lipid levels have not been studied in midlife women. Our study identified trajectories of PA and blood lipids across midlife and characterized the associations between these trajectories. We evaluated 2,789 participants from the Study of Women's Health Across the Nation (SWAN), a longitudinal cohort study with follow-up over the menopause transition. Women reported PA using the Kaiser Physical Activity Survey at seven study visits across 17 years of follow-up. Serum high-density lipoprotein (HDL) cholesterol, low-density lipoprotein (LDL) cholesterol, and triglycerides were measured at eight study visits across the same 17-year follow-up period. We used group-based trajectory models to characterize trajectories of PA and blood lipids over midlife and dual trajectory models to determine the association between PA and blood lipid trajectories adjusted for race/ethnicity, body mass index category, smoking, and lipid-lowering medication use. Women were 46 years old, on average, at study entry. Forty-nine percent were non-Hispanic white; 32 % were Black; 10 % were Japanese; and 9 % were Chinese. We identified four PA trajectories, three HDL cholesterol trajectories, four LDL cholesterol trajectories, and two triglyceride trajectories. The most frequently occurring trajectories were the consistently low PA trajectory (69 % of women), the low HDL cholesterol trajectory (43 % of women), the consistently moderate LDL cholesterol trajectory (45 % of women), and the consistently low triglycerides trajectory (90 % of women). In dual trajectory analyses, no clear associations were observed between PA trajectories and HDL cholesterol, LDL cholesterol, or triglycerides trajectories. The most frequently observed trajectories across midlife were characterized by low physical activity, low HDL cholesterol, moderate LDL cholesterol, and low triglycerides. Despite the absence of an association between long-term trajectories of PA and blood lipids in this study, a large body of evidence has established the importance of clinical and public health messaging and interventions targeted at midlife women to promote regular and sustained PA during midlife to achieve other cardiovascular and metabolic benefits. Authors: Moderate-to-Moderately-Severe Antenatal Depressive Symptoms: a Pilot Study Within an Integrated Health Care System Traditional mindfulness-based interventions have been shown to reduce depression symptoms in pregnant women, although in-person classes may pose significant accessibility barriers, particularly during the COVID-19 pandemic. Mobile technology offers greater convenience, but little is known regarding the efficacy of self-paced, mobile-delivered (mHealth) mindfulness interventions in this population. This study tested the feasibility and acceptability of offering such an intervention for pregnant women with moderate-to-moderately-severe depression symptoms. We conducted a single-arm trial within Kaiser Permanente Northern California (KPNC). Participants were identified through KPNC's universal perinatal depression screening program. Eligible participants included English-speaking pregnant women (<28 weeks of gestation) with moderate-to-moderately-severe depressive symptoms without a regular (<3 times/week) mindfulness/meditation practice. Participants were asked to follow a self-paced, 6-week mindfulness meditation program using a mobile app, Headspace, 10-20 min/day. Outcome measures included feasibility, acceptability, and patient-reported outcomes (e.g., depression symptoms). Of the 27 women enrolled, 20 (74%) completed the study. Over half (55%) of participants used the app 50% of the days during the 6-week intervention. Responses to the semi-structured interviews indicated that women appreciated the convenience of the intervention and the ability to engage without having to attend classes or arrange childcare. We observed significant improvements in pre-postintervention scores for depression symptoms, perceived stress, sleep disturbance, and mindfulness. Our study demonstrates the feasibility and acceptability of an mHealth mindfulness intervention for women with moderate-to-moderately-severe antenatal depression symptoms. The preliminary data further suggest that an efficacy trial is warranted. Mar 11:1-11. Editorial Expression of Concern: Exposure to Magnetic Field Non-Ionizing Radiation and the Risk of Miscarriage: A Prospective Cohort of Cannabis Retailer Proximity and Density With Cannabis Use Among Pregnant Women in Northern California After Legalization of Cannabis for Recreational Use Authors: Young-Wolff, Kelly Infection Clostridioides difficile infection (CDI) is a major cause of severe diarrhea. In this retrospective study, we identified CDI risk factors by comparing demographic and clinical characteristics for Kaiser Permanente Northern California members 18 years old with and without laboratory-confirmed incident CDI. We included these risk factors in logistic regression models to develop 2 risk scores that predict future CDI after an Index Date for Risk Score Assessment (IDRSA), marking the beginning of a period for which we estimated CDI risk. During May 2011 to July 2014, we included 9986 CDI cases and 2 230 354 members without CDI. The CDI cases tended to be older, female, white race, and have more hospitalizations, emergency department and office visits, skilled nursing facility stays, antibiotic and proton pump inhibitor use, and specific comorbidities. Using hospital discharge as the IDRSA, our risk score model yielded excellent performance in predicting the likelihood of developing CDI in the subsequent 31-365 days (C-statistic of 0.848). Using a random date as the IDRSA, our model also predicted CDI risk in the subsequent 31-365 days reasonably well (C-statistic 0.722). These results can be used to identify high-risk populations for enrollment in C difficile vaccine trials and facilitate study feasibility regarding sample size and time to completion. Authors: Aukes, Laurie; Forum Infect Dis. 2021 Mar;8(3):ofab052. Epub 2021-02-04. Gestational weight gain and adverse pregnancy outcomes by pre-pregnancy BMI category in women with chronic hypertension: A cohort study It is important to understand relationships of gestational weight gain with adverse pregnancy outcomes in women with chronic hypertension, given their high baseline risk of adverse outcomes. We assessed associations of gestational weight gain with adverse pregnancy outcomes in women with chronic hypertension by pre-pregnancy body mass index categories. We identified 14,369 women with chronic hypertension using electronic health records from 3 integrated health care delivery systems (2005-2014). Gestational weight gain-for-gestational age charts were used to calculate gestational weight gain z-scores, which account for gestational age. Modified Poisson regression models using generalized estimating equations were used to calculate relative risks and 95% confidence intervals, adjusted for sociodemographic and medical characteristics. Preeclampsia, preterm delivery, cesarean delivery, neonatal intensive care unit admission, birthweight (extracted from the electronic health record). In women with normal weight or overweight, low gestational weight gain (z-score < -1) was associated with 27-28% greater risk of preterm delivery and 48-82% greater risk of small-for-gestational age birthweight, while high gestational weight gain (z-score > 1) was associated with 40-90% greater risk of preeclampsia and 59-113% greater risk of large-for-gestational age birthweight. In women with obesity, low gestational weight gain was associated with 27-54% lower risk of several adverse pregnancy outcomes, including preeclampsia and cesarean delivery. In women with chronic hypertension and normal weight or overweight, moderate gestational weight gain may confer the lowest risk of adverse outcomes. In women with chronic hypertension and obesity, low gestational weight gain may be necessary for the lowest risk of adverse pregnancy outcomes. Authors: of polygenic risk scores for 16 cancer types in two large cohorts Even distinct cancer types share biological hallmarks. Here, we investigate polygenic risk score (PRS)-specific pleiotropy across 16 cancers in European ancestry individuals from the Genetic Epidemiology Research on Adult Health and Aging cohort (16,012 cases, 50,552 controls) and UK Biobank (48,969 cases, 359,802 controls). Within cohorts, each PRS is evaluated in multivariable logistic regression models against all other cancer types. Results are then meta-analyzed across cohorts. Ten positive and one inverse cross-cancer associations are found after multiple testing correction. Two pairs show bidirectional associations; the melanoma PRS is positively associated with oral cavity/pharyngeal cancer and vice versa, whereas the lung cancer PRS is positively associated with oral cavity/pharyngeal cancer, and the oral cavity/pharyngeal cancer PRS is inversely associated with lung cancer. Overall, we validate known, and uncover previously unreported, patterns of pleiotropy that have the potential to inform investigations of risk prediction, shared etiology, and precision cancer prevention strategies. Authors: 02 12;12(1):970. Epub 2021-02-12. The relationship of smoking and unhealthy alcohol use to the HIV care continuum among people with HIV in an integrated health care system Smoking tobacco and unhealthy alcohol use may negatively influence HIV care continuum outcomes but have not been examined in combination. Participants were people with HIV (PWH) in Kaiser Permanente Northern California. Predictors included smoking status and unhealthy alcohol use (exceeding daily and/or weekly limits) reported by patients during primary care screening (index date). Outcomes were based on not achieving the following steps in the care continuum: linkage to HIV care (1 visit within 90 days of newly identified HIV diagnosis), retention (2+ in-person visits, 60+ days apart) and HIV RNA control (<75 copies/mL). Adjusted odds ratios (ORs) were obtained from separate logistic regression models for each outcome associated with smoking and unhealthy alcohol use independently and combined. The overall sample (N = 8958) had a mean age of 48.0 years; was 91.3 % male; 54.0 % white, 17.6 % Latino, 15.1 % black, and 9.6 % other race/ethnicity. Smoking was associated with higher odds of not being linked to HIV care (OR = 1.60 [95 % CI 1.03-2.48]), not retained (OR = 1.30 [95 % CI 1.13-1.50]), and HIV RNA not in control (OR = 1.91 [95 % CI 1.60-2.27]). Alcohol measures were not independently associated with outcomes. The combination of unhealthy alcohol use and smoking (versus neither) was associated with higher odds of not being linked to care (OR = 2.83 [95 % CI 1.40-5.71]), although the interaction did not reach significance (p = 0.18). In this large sample of PWH in an integrated health care system, smoking, both independently and in combination with unhealthy alcohol use, was associated with worse HIV care continuum outcomes. Authors: Satre, Derek D; 2021 02 01;219:108481. Epub 2021-01-08. Recruitment strategies and design considerations in a trial of resistance training to prevent dose-limiting toxicities in colon cancer patients undergoing chemotherapy Low muscle is associated with an increased risk of chemotherapy-related dose limiting toxicities (DLT) in cancer patients. Resistance training (RT) improves muscle mass; however, the effects of RT on preventing DLTs and dose reductions in colon cancer patients has not been investigated. FOcus on Reducing dose-limiting toxicities in Colon cancer with resistance Exercise (FORCE) is a multicenter, randomized clinical trial examining the effects of RT on relative dose intensity (RDI; primary outcome) and moderate and severe chemotoxicities (primary outcome) in non-metastatic colon cancer patients receiving adjuvant chemotherapy. Patients (N = 180) will be recruited from Kaiser Permanente Northern California, Dana-Farber Cancer Institute, and Penn State Cancer Institute. This paper describes recruitment strategies and design considerations. Patients will be randomized in equal numbers to RT intervention or control. Patients have baseline and post completion of chemotherapy visits where information on anthropometry, physical function, body composition, quality of life, physical activity and dietary behaviors, and inflammatory blood markers will be collected. Patient-reported outcomes of chemotherapy side effects will be collected around the time of chemotherapy throughout the duration of the trial. Intervention participants will be prescribed a progressive RT program consisting of 4-6 visits with a certified exercise trainer, delivered either in-person or remotely by video conference, and will be asked to engage twice weekly in-home training sessions. Control patients at the end of the study receive a consult with a FORCE exercise trainer, an online exercise RT training program and a set of resistance bands. Results of this trial will provide information on the benefit of resistance exercise as a treatment to increase RDI. Authors: Caan, Bette J; Meyerhardt, 2020-12-07. Exercise During the First Trimester of Pregnancy and the Risks of Abnormal Screening and Gestational Diabetes Mellitus To estimate the effects of exercise during the first trimester on the risks of abnormal screening and gestational diabetes mellitus (GDM). Data come from PETALS, a prospectively followed pregnancy cohort (n = 2,246, 79% minorities) receiving care at Kaiser Permanente Northern California. A Pregnancy Physical Activity Questionnaire was used to assess exercise. Glucose testing results for screening and diagnostic tests were obtained from electronic health records. Inverse probability of treatment weighting and targeted maximum likelihood with data-adaptive estimation (machine learning) of propensity scores and outcome regressions were used to obtain causal risk differences adjusted for potential confounders, including prepregnancy BMI, exercise before pregnancy, and gestational weight gain. Exercise was dichotomized at 1) the cohort's 75th percentile for moderate- to vigorous-intensity exercise (13.2 MET-h per week or 264 min per week of moderate exercise), 2) current recommendations (7.5 MET-h per week or 150 min per week of moderate exercise), and 3) any vigorous exercise. Overall, 24.3% and 6.5% had abnormal screening and GDM, respectively. Exercise meeting or exceeding the 75th percentile decreased the risks of abnormal screening and GDM by 4.8 (95% CI 1.1, 8.5) and 2.1 (0.2, 4.1) fewer cases per 100, respectively, in adjusted analyses. Exercise reduces the risks of abnormal screening and GDM, but the amount needed to achieve these risk reductions is likely higher than current recommendations. Future interventions may consider promoting 38 min per day of moderate-intensity exercise to prevent PREDICTION OF OBSTETRIC AND FETAL COMPLICATIONS USING AUTOMATED ELECTRONIC HEALTH RECORD DATA An increasing number of delivering women experience major morbidity and mortality. Limited work has been done on automated predictive models that could be used for prevention. Using only routinely collected obstetrical data, this study aimed to develop a predictive model suitable for real-time use with an electronic medical record. We used a retrospective cohort study design with split validation. The denominator consisted of women admitted to a delivery service. The numerator consisted of women who experienced a composite outcome that included both maternal (eg, uterine rupture, adverse events. We employed machine learning methods, assessing model performance using the area under the receiver operator characteristic curve and number needed to evaluate. A total of 303,678 deliveries took place at 15 study hospitals between January 1, 2010, and March 31, 2018, and 4130 (1.36%) had 1 obstetrical complication. We employed data from 209,611 randomly selected deliveries (January 1, 2010, to March 31, 2017) as a derivation dataset and validated our findings on data from 52,398 randomly selected deliveries during the same time period (validation 1 dataset). We then applied our model to data from 41,669 deliveries from the last year of the study (April 1, 2017, to March 31, 2018 [validation 2 dataset]). Our model included 35 variables (eg, demographics, vital signs, laboratory tests, progress of labor indicators). In the validation 2 dataset, a gradient boosted model (area under the receiver operating characteristic curve or c statistic, 0.786) was slightly superior to a logistic regression model (c statistic, 0.778). Using an alert threshold of 4.1%, our final model would flag 16.7% of women and detect 52% of adverse outcomes, with a number needed to evaluate of 20.9 and 0.455 first alerts per day per 1000 annual deliveries. In conclusion, electronic medical record data can be used to predict obstetrical complications. The clinical utility of these automated models has not yet been demonstrated. To conduct interventions to assess whether using these models results in patient benefit, future work will need to focus on the development of clinical protocols suitable for use in interventions. Authors: Escobar, to left-truncated semi-competing risks data to examine the impact of education level on incident dementia Semi-competing risks arise when interest lies in the time-to-event for some non-terminal event, the observation of which is subject to some terminal event. One approach to assessing the impact of covariates on semi-competing risks data is through the illness-death model with shared frailty, where hazard regression models are used to model the effect of covariates on the endpoints. The shared frailty term, which can be viewed as an individual-specific random effect, acknowledges dependence between the events that is not accounted for by covariates. Although methods exist for fitting such a model to right-censored semi-competing risks data, there is currently a gap in the literature for fitting such models when a flexible baseline hazard specification is desired and the data are left-truncated, for example when time is on the age scale. We provide a modeling framework and openly available code for implementation. We specified the model and the likelihood function that accounts for left-truncated data, and provided an approach to estimation and inference via maximum likelihood. Our model was fully parametric, specifying baseline hazards via Weibull or B-splines. Using simulated data we examined the operating characteristics of the implementation in terms of bias and coverage. We applied our methods to a dataset of 33,117 Kaiser Permanente Northern California members aged 65 or older examining the relationship between educational level (categorized as: high school or less; trade school, some college or college graduate; post-graduate) and incident dementia and death. A simulation study showed that our implementation provided regression parameter estimates with negligible bias and good coverage. In our data application, we found higher levels of education are associated with a lower risk of incident dementia, after adjusting for sex and race/ethnicity. As illustrated by our analysis of Kaiser data, our proposed modeling framework allows the analyst to assess the impact of covariates on semi-competing risks data, such as incident dementia and death, while accounting for dependence between the outcomes when data are left-truncated, as is common in studies of aging and dementia. Authors: Lee, PM2.5 Exposure and Risks of Ischemic Heart Disease and Stroke Events: Review and Meta-Analysis Background Fine particulate matter <2.5 \u00b5m in diameter (PM2.5) has known effects on cardiovascular morbidity and mortality. However, no study has quantified and compared the risks of incident myocardial infarction, incident stroke, ischemic heart disease (IHD) mortality, and cerebrovascular mortality in relation to long-term PM2.5 exposure. Methods and Results We sought to quantitatively summarize studies of long-term PM2.5 exposure and risk of IHD and stroke events by conducting a review and meta-analysis of studies published by December 31, 2019. The main outcomes were myocardial infarction, stroke, IHD mortality, and cerebrovascular mortality. Random effects meta-analyses were used to estimate the combined risk of each outcome among studies. We reviewed 69 studies and included 42 studies in the meta-analyses. In meta-analyses, we found that a 10-\u00b5g/m3 increase in long-term PM2.5 exposure was associated with an increased risk of 23% for IHD mortality (95% CI, 15%-31%), 24% for for myocardial infarction -1% to 18%). There were an insufficient number of studies of recurrent stroke and recurrent myocardial infarction to conduct meta-analyses. Conclusions Long-term PM2.5 exposure is associated with increased risks of IHD mortality, cerebrovascular mortality, and incident stroke. The relationship with incident myocardial infarction is suggestive of increased risk but not conclusive. More research is needed to understand the relationship with recurrent events. Authors: Alexeeff, Stacey E; Liao, Noelle S; Liu, Xi; Van Stephen Am Heart Assoc. 2021 01 05;10(1):e016890. Epub 2020-12-31. Building Predictive Models for Care-Where to Build and What to Predict? Authors: Selby, Joe 04;4(1):e2032539. Epub 2021-01-04. Incidence and predictors of type 1 diabetes among younger adults aged 20-45 years: The diabetes in young adults (DiYA) study To estimate incidence of type 1 diabetes (T1D) and to develop a T1D prediction model among young adults. Adults 20-45 years newly-diagnosed with diabetes in 2017 were identified within Kaiser Permanente's healthcare systems in California and invited for diabetes autoantibody (DAA) testing. Multiple imputation was conducted to assign missing DAA status. The primary outcome for incidence rates (IR) and the prediction model was T1D defined by 1 positive DAA. Among 2,347,989 persons at risk, 7862 developed diabetes, 2063 had DAA measured, and 166 (8.0%) had 1 positive DAA. T1D IR (95% CI) per 100,000 person-years was 15.2 for ages 20-29 and 38.2 (28.6-47.8) for ages 30-44 years. The age-standardized IRs were 32.5 (22.2-42.8) for men and 27.2 (21.0-34.5) for women. The age/sex-standardized IRs were 30.1 (23.5-36.8) overall; 41.4 (25.3-57.5) for Hispanics, 37.0 (11.6-62.4) for Blacks, 21.4 (14.3-28.6) for non-Hispanic Whites, and 19.4 (8.5-30.2) for Asians. Predictors of T1D among cases included female sex, younger age, lower BMI, insulin use and having T1D based on diagnostic codes. T1D may account for up to 8% of incident diabetes cases among young adults. Follow-up is needed to establish the clinical course of patients with one DAA at diagnosis. Authors: Lawrence, Jean M; 2020-12-15. A Randomized Encouragement Trial to Increase Mail Order Pharmacy Use and Medication Adherence in Patients with Diabetes Mail order pharmacy (MOP) use has been linked to improved medication adherence and health outcomes among patients with diabetes. However, no large-scale intervention studies have assessed the effect of encouraging MOP use on medication adherence. To assess an intervention to encourage MOP services to increase its use and medication adherence. Randomized encouragement trial. 63,012 diabetes patients from three health care systems: Kaiser Permanente Northern California (KPNC), Kaiser Permanente Hawaii (KPHI), and Harvard Pilgrim Health Care (HPHC) who were poorly adherent to at least one class of cardiometabolic medications and had not used MOP in the prior 12 months. Patients were randomized to receive either usual care (control arm) or outreach encouraging MOP use consisting of a mailed letter, secure email message, and automated telephone call outlining the potential benefits of MOP use (intervention arm). HPHC intervention patients received the letter only. We compared the percentages of patients that began using MOP and that became adherent to cardiometabolic medication classes during a 12-month follow-up period. We also conducted a race/ethnicity-stratified analysis. During follow-up, 10.6% of intervention patients began using MOP vs. 9.3% of controls (p < 0.01); the percent of cardiometabolic medication delivered via mail was 42.1% vs. 39.8% (p < 0.01). Metformin adherence improved in the intervention arm relative to control at the two KP sites (52% vs. 49%, p < 0.01). Stratified analyses suggested a significant positive effect of the intervention in White (RR: 1.12, 95% CI: 1.03, 1.22) and Asian (RR: 1.30, 95% CI: 1.17, 1.45) patients. This pragmatic trial showed that simple outreach to encourage MOP modestly increased its use and improved adherence measured by refills to a key class of diabetes medications in some settings. Given its minimal cost, clinicians and health systems should consider outreach interventions to actively promote MOP use among diabetes patients. Intern Med. 2021 01;36(1):154-161. Epub 2020-10-01. Maternal immune response and air pollution exposure during pregnancy: insights from the Early Markers for Autism (EMA) study Perinatal exposure to air pollution and immune system dysregulation are two factors consistently associated with autism spectrum disorders (ASD) and other neurodevelopmental outcomes. However, little is known about how air pollution may influence maternal immune function during pregnancy. To assess the relationship between mid-gestational circulating levels of maternal cytokines/chemokines and previous month air pollution exposure across neurodevelopmental groups, and to assess whether cytokines/chemokines mediate the relationship between air pollution exposures and risk of ASD and/or intellectual disability (ID) in the Early Markers for Autism (EMA) study. EMA is a population-based, nested case-control study which linked archived maternal serum samples collected during weeks 15-19 of gestation for routine prenatal screening, birth records, and Department of Developmental Services (DDS) records. Children receiving DDS services for ASD without intellectual disability (ASD without ID; n = 199), ASD with ID (ASD with ID; n = 180), ID without ASD (ID; n = 164), and children from the general population (GP; n = 414) with no DDS services were included in this analysis. Serum samples were quantified for 22 cytokines/chemokines using Luminex multiplex analysis technology. Air pollution exposure for the month prior to maternal serum collection was assigned based on the Environmental Protection Agency's Air Quality System data using the maternal residential address reported during the prenatal screening visit. Previous month air pollution exposure and mid-gestational maternal cytokine and chemokine levels were significantly correlated, though weak in magnitude (ranging from - 0.16 to 0.13). Ten pairs of mid-pregnancy immune markers and previous month air pollutants were significantly associated within one of the child neurodevelopmental groups, adjusted for covariates (p < 0.001). Mid-pregnancy air pollution was not associated with any neurodevelopmental outcome. IL-6 remained associated with ASD with ID even after adjusting for air pollution exposure. This study suggests that maternal immune activation is associated with risk for neurodevelopmental disorders. Furthermore, that prenatal air pollution exposure is associated with small, but perhaps biologically relevant, effects on maternal immune system function during pregnancy. Additional studies are needed to better evaluate how prenatal exposure to air pollution affects the trajectory of maternal immune activation during pregnancy, if windows of heightened susceptibility can be identified, and how these factors influence neurodevelopment of the offspring. Authors: Volk, Heather E; Epub Risk of complete atypical femur fracture with Oral bisphosphonate exposure beyond three years Bisphosphonate (BP) therapy has been associated with atypical femur fracture (AFF). However, the threshold of treatment duration leading to increased AFF risk is unclear. In a retrospective cohort of older women initiating BP, we compared the AFF risk associated with treatment for at least three years to the risk associated with treatment less than three years. We used observational data from a large population of female members of an integrated healthcare system who initiated oral BP during 2002-2014. Women were retrospectively followed for incident AFF confirmed by radiologic adjudication. Demographic data, pharmacologic exposures, comorbidity, bone density, and fracture history were ascertained from electronic health records. Inverse probability weighting was used to estimate risk differences comparing the cumulative incidence (risk) of AFF if women discontinued BP within three years to the cumulative incidence of AFF if women continued BP for three or more years, adjusting for potential time-dependent confounding by the aforementioned factors. Among 87,820 women age 45-84 years who initiated BP (mean age 68.6, median T-score - 2.6, 14% with prior major osteoporotic fracture), 16,180 continued BP for three or more years. Forty-six confirmed AFFs occurred during follow-up in the two groups. AFF-free survival was greater for BP treatment < 3 years compared to treatment 3 years (p = 0.004 comparing areas under survival curves). At five years, the risk of AFF was 27 per 100,000 (95% confidence interval, CI: 8-46) if women received BP treatment < 3 years and 120 per 100,000 (95% CI: 56-183) if women received BP treatment 3 years (risk difference 93 per 100,000, 95% CI: 30-160). By ten years, the risks CI: 8-46) and 363 (95% CI: 132-593) per 100,000 for BP treatment < 3 and 3 years, respectively (risk difference 336 per 100,000, 95% CI: 110-570). Bisphosphonate treatment for 3 or more years was associated with greater risk of AFF than treatment for less than 3 years. Although AFFs are uncommon among BP-treated women, this increased risk should be considered when counseling women about long-term BP use. Future studies should further characterize the dose-response relationship between BP duration and incident AFF and identify patients at highest risk. Authors: and Validation of Machine Learning Models: Electronic Health Record Data To Predict Visual Acuity After Cataract Surgery To develop predictive models of final corrected distance visual acuity (CDVA) following cataract surgery using machine learning algorithms and electronic health record data. In this predictive modeling study we used decision tree, random forest, and gradient boosting. We included the first surgical eye of 64,768 members of Kaiser Permanente Northern California who underwent cataract surgery from June 1, 2010 through May 31, 2015. We measured discrimination and calibration of machine learning models for predicting postoperative CDVA 20/50 or worse vs 20/40 or better. The training set included 51,712 patients, and the validation set included 13,056 patients. We compared 3 machine learning models and found that the gradient boosting model provided the best discrimination ability for CDVA. The most important variables for predicting final CDVA 20/50 or worse were preoperative CDVA, age, and age-related macular degeneration, which together accounted for 41% of the gain in optimization of the gradient boosting model. Other important variables in the model included dispensed glaucoma medication, epiretinal membrane, cornea disorder, cataract surgery operating time, surgeon experience, and census block neighborhood characteristics (household income, family income, family poverty, college education, and home residence by owner). For predicting CDVA after cataract surgery, gradient boosting had the best ability to discriminate patients with postoperative CDVA 20/50 or worse from patients with postoperative CDVA 20/40 or better. Machine learning has the potential to improve prognosis and can improve patient information when making decisions to undergo cataract surgery. Authors: Alexeeff, 12;25:1. Validation Study of Kaiser Permanente Bedside Dysphagia Screening Tool in Acute Stroke Patients Dysphagia occurs in up to 50% of patients with acute stroke symptoms, resulting in increased aspiration pneumonia rates and mortality. The purpose of this study was to validate a health system's dysphagia (swallow) screening tool used since 2007 on all patients with suspected stroke symptoms. Annual rates of aspiration pneumonia for ischemic stroke patients have ranged from 2% to 3% since 2007. From August 17, 2015 through September 30, 2015, a bedside dysphagia screening was prospectively performed by 2 nurses who were blinded to all patients age 18 years or older admitted through the emergency department with suspected stroke symptoms at 21 Joint Commission accredited primary stroke centers in an integrated health system. The tool consists of 3 parts: pertinent history, focused physical examination, and progressive testing from ice chips to 90 mL of water. A speech language pathologist blinded to the nurse's screening results performed a formal swallow evaluation on the same patient. The end study population was 379 patients. Interrater reliability between 2 nurses of the dysphagia screening was excellent at 93.7% agreement ( = 0.83). When the dysphagia screenings were compared with the gold standard speech language pathologist professional swallow evaluation, the tool demonstrated both high sensitivity (86.4%; 95% confidence interval = 73.3-93.6) and high negative predictive value (93.8%; 95% confidence interval = 87.2-97.1). This tool is highly reliable and valid. The dysphagia screening tool requires minimal training and is easily administered in a timely manner. Authors: Finnegan, Barbara Bisphosphonate Treatment Beyond 5 Years and Hip Fracture Risk in Older Women Clinical trials have demonstrated the antifracture efficacy of bisphosphonate drugs for the first 3 to 5 years of therapy. However, the efficacy of continuing bisphosphonate for as long as 10 years is uncertain. To examine the association of discontinuing bisphosphonate at study entry, discontinuing at 2 years, and continuing for 5 additional years with the risk of hip fracture among women who had completed 5 years of bisphosphonate treatment at study entry. This cohort study included women who were members of Kaiser Permanente Northern and Southern California, 2 integrated health care delivery systems, and who had initiated oral bisphosphonate and completed 5 years of treatment by January 1, 2002, to September 30, 2014. Data analysis was conducted from January 2018 to August 2020. Discontinuation of bisphosphonate at study entry (within a 6-month grace period), discontinuation at 2 years (within a 6-month grace period), and continuation for 5 additional years. The outcome was hip fracture determined by principal hospital discharge diagnoses. Demographic, clinical, and pharmacological data were ascertained from electronic health records. Among 29 685 women (median [interquartile range] age, 71 [64-77] years; 17 778 [60%] non-Hispanic White individuals), 507 incident hip fractures were identified. Compared with bisphosphonate discontinuation at study entry, there were no differences in the cumulative incidence (ie, risk) of hip fracture if women remained on therapy for 2 additional years (5-year risk difference [RD], -2.2 per 1000 individuals; 95% CI, -20.3 to 15.9 per 1000 individuals) or if women continued therapy for 5 additional years (5-year RD, 3.8 per 1000 individuals; 95% CI, -7.4 to 15.0 per 1000 individuals). While 5-year differences in hip fracture risk comparing continuation for 5 additional years with discontinuation at 2 additional years were not statistically significant (5-year RD, 6.0 per 1000 individuals; 95% CI, -9.9 to 22.0 per 1000 individuals), interim hip fracture risk appeared lower if women discontinued after 2 additional years (3-year RD, 2.8 per 1000 individuals; 95% CI, 1.3 to 4.3 per 1000 individuals; 4-year RD, 9.3 per 1000 individuals; 95% CI, 6.3 to 12.3 per 1000 individuals) but not without a 6-month grace period to define discontinuation. In this study of women treated with bisphosphonate for 5 years, hip fracture risk did not differ if they discontinued treatment compared with continuing treatment for 5 additional years. If women continued for 2 additional years and then discontinued, their risk appeared lower than continuing for 5 additional years. Discontinuation at other times and fracture rates during intervening years should be further studied. Authors: Izano, Monika A; Lo, Associations between spousal caregiving and health among older adults in Mexico: A targeted estimation approach To evaluate associations between spousal caregiving and mental and physical health among older adults in Mexico. Data come from the Mexican Health & Aging Study, a national population-based study of adults 50 years and their spouses (2001-2015). We compared outcomes for spousal caregivers to outcomes for those whose spouses had difficulty with at least one basic or instrumental activity of daily living (I/ADL) but were not providing care; the control group conventionally includes all married respondents regardless of spouse's need for care. We used targeted maximum likelihood estimation to evaluate the associations with past-week depressive symptoms, lower-body functional limitations, and chronic health conditions. At baseline, 846 women and 629 men had a spouse with 1 I/ADL. Of these, 60.9% of women and 52.6% of men were spousal caregivers. Spousal caregiving was associated with more past-week depressive symptoms for men (Marginal Risk Difference (RD): 0.27, 95% confidence internal [CI]: 0.03, 0.51) and women (RD: 0.15, 95% CI: 0.07, 0.23). We could not draw conclusions about associations with lower-body functional limitations and chronic health conditions. On average, all respondents whose spouses had caregiving needs had poorer health than the overall sample. We found evidence of an association between spousal caregiving and mental health among older Mexican adults with spouses who had need for care. However, our findings suggest that older adults who are both currently providing or at risk of providing spousal care may need targeted programs and policies to support health and long-term care needs. Authors: Torres JM; Int J Geriatr Psychiatry. 2020 Dec 01. Health System-Based Unhealthy Alcohol Use Screening and Treatment Comparing Demographically-Matched Participants With and Without HIV Unhealthy alcohol use among persons living with HIV (PLWH) is linked to significant morbidity, and use of alcohol services may differ by HIV status. Our objective was to compare unhealthy alcohol use screening and treatment by HIV status in primary care. Cohort study of adult (18 years) PLWH and HIV-uninfected participants frequency matched 20:1 to PLWH by age, sex, and race/ethnicity who were enrolled in a large integrated healthcare system in the United States, with information ascertained from an electronic health record. Outcomes included unhealthy alcohol screening, prevalence, provider-delivered brief interventions, and addiction specialty care visits. Other predictors included age, sex, race/ethnicity, neighborhood deprivation index, depression, smoking, substance use disorders, Charlson comorbidity index, prior outpatient visits, insurance type, and medical facility. Cox proportional hazards models were used to compute hazard ratios (HR) for the outcomes of time to unhealthy alcohol use screening and time to first addiction specialty visit. Poisson regression with robust standard errors was used to compute prevalence ratios (PR) for other outcomes. 11,235 PLWH and 227,320 HIV-uninfected participants were included. By 4.5 years after baseline, most participants were screened for unhealthy alcohol use (85% of PLWH and 93% of HIV-uninfected), but with a lower rate among PLWH (adjusted HR 0.84, 95% CI 0.82 to 0.85). PLWH were less likely, compared with HIV-uninfected participants, to report unhealthy drinking among those screened (adjusted PR 0.74, 95% CI 0.69 to 0.79), and among those who screened positive, less likely to receive brief interventions (adjusted PR 0.82, 95% CI 0.75 to 0.90), but more likely (adjusted HR 1.7, 95% CI 1.2 to 2.4) to have an addiction specialty visit within 1 year. Unhealthy alcohol use was lower in PLWH, but the treatment approach by HIV status differed. PLWH reporting unhealthy alcohol use received less brief interventions and more addiction specialty care than HIV-uninfected participants. Authors: Silverberg, Michael 12;44(12):2545-2554. Epub and Melanoma Risk Histone deacetylase inhibitors, including acid, selectively induce cellular differentiation and apoptosis in melanoma cells. No published pharmacoepidemiologic studies have explored the association between valproic acid use and melanoma risk. We conducted a retrospective cohort study of adult white Kaiser Permanente Northern California members (n = 2,213,845) from 1997 to 2012 to examine the association between valproic acid use and melanoma risk. Melanoma hazard ratios (HRs) and 95% CIs were estimated using Cox proportional hazards models, adjusted for age, sex, calendar year, and healthcare use. Melanoma incidence was lower among exposed individuals (64.0 exposed vs. 96.2 unexposed per 100,000 person-years, P < 0.001). Exposed individuals had a lower incident melanoma risk (HR = 0.64; 95% CI = 0.51-0.79) in unadjusted analysis, and the estimate was attenuated but significant in adjusted analysis (HR = 0.76, 95% CI = 0.61-0.94). Cumulative exposure based on the number of fills revealed a biologically implausible inverse dose-effect. Exposed individuals were more likely to present with local than regional or distant disease at diagnosis (80/82; 97.6% exposed vs. 12,940/13,971; 92.6% unexposed). Our findings suggest that valproic acid exposure may be associated with decreased melanoma risk and progression, but the cumulative exposure analyses suggest that the observation may be owing to residual confounding. Authors: Chavez 2020-04-28. Identifying Ectopic Pregnancy in a Large Integrated Health Care Delivery System: Algorithm Validation Surveillance of ectopic pregnancy (EP) using electronic databases is important. To our knowledge, no published study has assessed the validity of EP case ascertainment using electronic health records. We aimed to assess the validity of an enhanced version of a previously validated algorithm, which used a combination of encounters with EP-related diagnostic/procedure codes and methotrexate injections. Medical records of 500 women aged 15-44 years with membership at Kaiser Permanente Southern and Northern California between 2009 and 2018 and a potential EP were randomly selected for chart review, and true cases were identified. The enhanced algorithm included diagnostic/procedure codes from the International Classification of Diseases, Tenth Revision, used telephone appointment visits, and excluded cases with only abdominal EP diagnosis codes. The sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and overall performance (Youden index and F-score) of the algorithm were evaluated and compared to the validated algorithm. There were 334 true positive and 166 true negative EP cases with available records. True positive and true negative EP cases did not differ significantly according to maternal age, race/ethnicity, and smoking status. EP cases with only one encounter and non-tubal EPs were more likely to be misclassified. The sensitivity, specificity, PPV, and NPV of the enhanced algorithm for and were 82.5% and 95.2%, respectively. The sensitivity and NPV were lower for the previously published algorithm at 94.3% and 88.1%, respectively. The sensitivity of surgical procedure codes from electronic chart abstraction to correctly identify surgical management was 91.9%. The overall accuracy, defined as the percentage of EP cases with correct management (surgical, medical, and unclassified) identified by electronic chart abstraction, was 92.3%. The performance of the enhanced algorithm for EP case ascertainment in integrated health care databases is adequate to allow for use in future epidemiological studies. Use of this algorithm will likely result in better capture of true EP cases than the Nov 30;8(11):e18559. Epub 2020-11-30. A Mobile Health Mindfulness Intervention for Women With Moderate to Moderately Severe Postpartum Depressive Symptoms: Feasibility Study Approximately 20% of women suffer from postpartum depression (PPD). Due to barriers such as limited access to care, half of the women with PPD do not receive treatment. Therefore, it is critical to identify effective and scalable interventions. Traditional mindfulness programs have been effective in reducing depressive symptoms, however access remains a barrier. A self-paced mobile health (mHealth) mindfulness program may fit the lifestyle of busy mothers who are unable to attend in-person classes. However, little is known regarding the feasibility or efficacy of mHealth mindfulness interventions in postpartum women with depressive symptoms. This study aims to assess the feasibility, acceptability, and preliminary efficacy of an mHealth mindfulness intervention for postpartum women with moderate to moderately severe depressive symptoms. We conducted a single-arm feasibility trial of an mHealth mindfulness intervention within Kaiser Permanente Northern California (KPNC), a large integrated health care system. Participants were identified through clinician referral and electronic health records via KPNC's universal perinatal depression screening program and recruited by the study team. Inclusion criteria included the following: English-speaking, up to 6 months postpartum with a Patient Health Questionnaire (PHQ-8) score of 10 to 19, and no regular mindfulness/meditation practice. Participants were asked to use a mindfulness app, Headspace, 10 to 20 min/day for 6 weeks. Baseline and postintervention surveys captured data on patient-reported outcomes (depression and stress symptoms, sleep quality, and mindfulness). Semistructured interviews captured acceptability. Retention and adherence were used to assess feasibility. Of the 115 women who were contacted and met the eligibility criteria or declined participation before eligibility assessment, 27 (23%) were enrolled. In addition, 70% (19/27) completed the study. The mean age of participants was 31 years (SD 5.2), 30% (8/27) were non-Hispanic White, and, on average, participants were 12.3 weeks postpartum (SD 5.7). Of the women who completed the study, 100% (19/19) used the Headspace app at least once, and nearly half (9/19, 47%) used the app on 50% of the days during the 6-week intervention period. Of the 16 participants who completed the postintervention interview, 69% (11/16) reported that they were very or extremely satisfied with the app. Interviews indicated that women appreciated the variety of meditations and felt that the program led to reduced anxiety and improved sleep. Significant improvements in pre- and postintervention scores were observed for depressive symptoms (PHQ-8: -3.8, P=.004), perceived stress (10-item Perceived Stress Scale: sleep quality (Pittsburgh Sleep Quality Index: -2.1, P=.02, indicating less sleep disturbance). Improvements in mindfulness were also significant (Five Facet Mindfulness Questionnaire-Short Form: 10.9, P=.01). An mHealth mindfulness intervention for postpartum women with moderate to moderately severe depressive symptoms is feasible and acceptable. An efficacy trial is 12;7(11):e17405. Epub 2020-11-12. Individual and Neighborhood Factors Associated with Failure to Vaccinate against Influenza during Pregnancy Uptake of influenza vaccine among pregnant women remains low. We investigated whether unvaccinated pregnant women were clustered geographically and determined factors associated with failure to vaccinate using spatial and multivariate logistic regression analyses. Pregnant women who were members of Kaiser Permanente Northern California in 2015 or 2016 were included in the study. More than half (53%) of the 77,607 included pregnant women were unvaccinated. Spatial analysis identified 5 clusters with a high prevalence of unvaccinated pregnant women. The proportion of unvaccinated women ranged from 57% to 75% within clusters as compared with 51% outside clusters. In covariate-adjusted analyses, residence in a cluster was associated with a 41% increase in the odds of being unvaccinated (odds ratio (OR) = 1.41, 95% confidence interval (CI): 1.36, 1.46). The odds of being unvaccinated were greater for Black women (OR = 1.58, 95% CI: 1.49, 1.69), Hispanic women (OR = 1.15, 95% CI: 1.05, 1.25), women with subsidized health insurance (OR = 1.18, 95% CI: 1.11, 1.24), women with fewer than 5 prenatal-care visits (OR = 1.85, 95% CI: 1.60, 2.16), and neighborhoods with a high deprivation index (fourth quartile vs. first: OR = 1.14, 95% CI: 1.07, 1.21). In conclusion, unvaccinated pregnant women were clustered geographically and by key sociodemographic factors. These findings suggest that interventions to increase influenza vaccine coverage among pregnant women are needed, particularly in vulnerable populations. Authors: Zerbo, Ousseny; Ray, J 2020 11 02;189(11):1379-1388. Presentation of Rash in a Community-Based Health System Coordination of care between primary care providers and dermatologists is important to ensure high quality and cost efficiency. In our integrated care setting, we used a retrospective cohort study to assess which patients self-refer to dermatology and which returned for a follow-up visit in dermatology. We identified 107,832 patients with a new rash diagnosis who presented to primary care or dermatology between January and March 2017. We compared patients who self-referred to dermatology with those who used primary care, using multi-level generalized estimating equations with adjustment for patient-level covariables and medical center. We also characterized patients who returned for a follow-up visit in dermatology. Among patients with a new rash diagnosis, 99% were originally seen in primary care. Patients with a history of a dermatological condition were more likely to present to dermatology. Patients with a history of a dermatological condition or with psoriasis, pigment, hair, bullous, or multiple conditions were more likely to have a follow-up visit with a dermatologist. For each outcome, initial location of care and return for a follow-up visit, we found minimal clustering by medical center or provider. One percent of patients with a new rash diagnosis self-refer to dermatology in this setting. Patients with a history of a dermatological condition were more likely to self-refer to dermatology and to have a follow-up visit with a dermatologist. Individual dermatologists and primary care providers had little impact on a patient's odds of returning for a follow-up Perm J. 2020 11;24:1-4. Changing Provider PSA Screening Behavior Using Best Practice Advisories: Interventional Study in a Multispecialty Group Practice Most guidelines recommend against PSA-based screening for prostate cancer in men 70 years of age. Adherence to these guidelines is variable. To determine whether the use of a \"Best Practice Advisory\" (BPA) intervention within the electronic medical record (EMR) system can alter the rate of PSA screening in men 70 years of age. This is an interventional study spanning the years 2013 through 2017, in men 70 years of age in Kaiser Permanente Northern California with no prior history of prostate cancer. The BPA intervention was activated in the EMR system on October 15, 2015, with no prior notice or education. Integrated healthcare system including all Kaiser Permanente Northern California facilities. A population-based sample that included all male members 70 years of age without a history of prostate cancer. The main outcome was the rate of PSA testing in men 70 years of age. We compared the rates of PSA testing between the pre-BPA period (January 1, 2013-October 14, 2015) and the post-BPA period (October 15, 2015-December 31, 2017). An interrupted time series analysis of PSA ordering rates was performed. Following the 2015 BPA intervention, screening rates substantially declined from 36.0 per 100 person-years to 14.9 per 100 person-years (rate ratio = 0.415; 95% CI: 0.410-0.419). The effect of the BPA was comparable among all patient races and ordering provider specialties. The interrupted time series analysis showed a rapid, large, and sustained drop in the rate of PSA ordering, and much less temporal variation in test ordering after activation of the BPA. Following activation of a BPA within the EMR, the rates of inappropriate PSA testing significantly declined by 58.5% in men 70 years of age and temporal variation was reduced. Med. 2020 11;35(Suppl 2):796-801. Epub 2020-10-26. Bone Mineral Density in Older U.S. Filipino, Chinese, Japanese, and White Women Bone mineral density (BMD) reference data exist for U.S. White, Black, and Hispanic (Mexican American) populations but not for U.S. Asians. Few studies have compared BMD findings among different U.S. Asian ethnicities. Retrospective observational study. Large northern California healthcare system. Asian and White women aged 50 to 79 years with BMD testing from 1998 to 2017 excluding those with estrogen or osteoporosis treatment, recent fracture, or select disorders affecting skeletal health. Femoral neck (FN)-BMD and height data. Differences in FN-BMD were examined by ethnicity and age, comparing Filipino, Chinese, and Japanese women and non-Hispanic White women. Differences in BMD were also examined after adjustment for height. There were 37,224 Asian women (including 11,147 Filipino, 10,648 Chinese, and 2,519 Japanese) and 115,318 non-Hispanic White women. Mean height was similar among the Asian subgroups and about 6 to 8 cm lower than Whites. Mean FN-BMDs differed by less than 3% for Filipino, Chinese, and Japanese and all were lower than Whites, with smaller Asian-White differences among younger women (<3%; ages 50-59) and larger differences among older women (6-8%; ages 65-79). Adjusting FN-BMD for height reduced White-Asian differences by about 30% to 40%. Mean FN-BMD and height for Filipino, Chinese, and Japanese women were similar but consistently lower than White women, especially among older women. Although Asian-White BMD differences were substantially attenuated after height adjustment; some differences persisted for older women. Future studies should investigate potential age-cohort effects and the extent to which these BMD differences influence fracture risk and clinical care. Authors: Lo, Epub 2020-10-12. Consequences of depletion of susceptibles for hazard ratio estimators based on propensity scores We use simulated data to examine the consequences of depletion of susceptibles for hazard ratio (HR) estimators based on a propensity score (PS). First, we show that the depletion of susceptibles attenuates marginal HRs toward the null by amounts that increase with the incidence of the outcome, the variance of susceptibility, and the impact of susceptibility on the outcome. If susceptibility is binary then the Bross bias multiplier, originally intended to quantify bias in a risk ratio from a binary confounder, also quantifies the ratio of the instantaneous marginal HR to the conditional HR as susceptibles are depleted differentially. Second, we show how HR estimates that are conditioned on a PS tend to be between the true conditional and marginal HRs, closer to the conditional HR if treatment status is strongly associated with susceptibility and closer to the marginal HR if treatment status is weakly associated with susceptibility. We show that associations of susceptibility with the PS matter to the marginal HR in the treated (ATT) though not to the marginal HR in the entire cohort (ATE). Third, we show how the PS can be updated periodically to reduce depletion-of-susceptibles bias in conditional estimators. Although marginal estimators can hit their ATE or ATT targets consistently without updating the PS, we show how their targets themselves can be misleading as they are attenuated toward the null. Finally, we discuss implications for the interpretation of HRs and their relevance to underlying scientific and clinical questions. See video Abstract: https://links.lww.com/EDE/B727. Authors: Fireman, Bruce; Wyss, Richard; et al. Epidemiology. 2020 11;31(6):806-814. Early Screening of African Americans (45-50 Years Old) in a Fecal Immunochemical Test-based Colorectal Cancer Screening Program Some guidelines recommend starting colorectal cancer (CRC) screening before age 50 years for African Americans, but there are few data on screening uptake and yield in this population. We performed a prospective study of fecal immunochemical test (FIT) screening among African American members of the Kaiser Permanente Northern California health plan. We compared data from African American members screened when they were 45-50 years old (early screening group) in 2018 with data from previously unscreened African American, white, Hispanic, and Asian/Pacific Islander health plan members who were 51-56 years old. Screening outreach was performed with mailed FIT kits. Logistic regression models, adjusted for sex, were used to evaluate differences among groups in screening uptake, colonoscopy follow-up of abnormal test results, and test yield. Among 10,232 African Americans in the early screening group who were mailed a FIT, screening was completed by 33.1%. Among the 4% with positive test results, 85.3% completed a follow-up colonoscopy: had any with advanced histology or polyp 10 mm), and 2.6% were diagnosed with CRC. African Americans in the early screening group were modestly more likely to have completed screening than previously unscreened African Americans, whites, and Hispanics 51-56 years old. The groups did not differ significantly in positive results from the FIT (range, 3.8%-4.6%) and more than 74% received a follow-up colonoscopy after a positive test result. The test yields for any adenoma (range, 56.7%-70.7%), advanced adenoma (range, 20.0%-33.6%), and CRC (range, 0%-7.1%) were similar. Proportions of African Americans who participated in early (aged 45-50 years) FIT screening and test yield were comparable to those of previously unscreened African Americans, whites, Hispanics, and Asian/Pacific Islanders who were 51-56 years 2020-07-20. Prospective development of a prostate cancer risk calculator in a racially diverse population: The Kaiser Permanente Prostate Cancer Risk Calculator To prospectively develop a prostate cancer (CaP) risk calculator in a racially diverse population. All patients referred for prostate biopsy due to an elevated prostate-specific antigen or abnormal digital rectal exam in a 19-months period at Kaiser Permanente Northern California underwent a standardized systematic, ultrasound-guided biopsy scheme (14-cores for initial biopsy, 18-20 cores for repeat biopsy). All pertinent clinical variables were prospectively collected. The highest Gleason score for each patient was recorded for all positive biopsies. We used a split sample design to develop and validate 3 multivariable prediction models using multinomial logistic regression with the least absolute shrinkage and selection operator. All models included these core variables: age, race, prostate-specific antigen, prior biopsy status, body mass index, and family history of CaP. Model 1 included only the core variables, Model 2 added digital rectal exam, and Model 3 added digital rectal exam and prostate volume. We considered 3 outcomes: high-grade disease (Gleason score 7), low-grade disease (Gleason score = 6), and no cancer. Predictive discrimination was quantified using the c-statistic. Complete data were available for 2,967 patients. Cancer was found in 50% of patients: of these, 58% were Gleason score 7 and 42% were low grade. Compared to Caucasians, African Americans were at a higher risk while Asians and Hispanics were at a lower risk for overall and high-grade cancer detection. The number of prior negative biopsies was also protective for these outcomes. The c-statistics for Model 1, 2, and 3 to predict high-grade disease vs. low-grade or no cancer were 0.76, 0.79, and 0.85, respectively. The c-statistics for Model 1, 2, and 3 to predict any CaP vs. no cancer were 0.69, 0.70, and 0.79, respectively. All models were well calibrated for all outcomes. In men with elevated PSA levels, our calculator provides useful information that may enhance the shared decision-making process regarding the need and management of suspicious findings on chest computed tomography is associated with improved lung cancer diagnosis in an observational study Follow-up of chest CT scan findings suspicious for lung cancer may be delayed because of inadequate documentation. Standardized reporting and follow-up may reduce time to diagnosis and care for lung cancer. We implemented a reporting system that standardizes tagging of chest CT scan reports by classifying pulmonary findings. The system also automates referral of patients with findings suspicious for lung cancer to a multidisciplinary care team for rapid review and follow-up. The system was designed to reduce the time to diagnosis, particularly for early-stage lung cancer. We evaluated the effectiveness of this system, using a quasi-experimental stepped wedge cluster design, examining 99,148 patients who underwent diagnostic (nonscreening) chest CT imaging from 2015 to 2017 and who had not received a chest CT scan in the preceding 24 months. We evaluated the association of the intervention with the incidence of diagnosis and surgical treatment of early-stage (I, II) and late-stage (III, IV) lung cancer within 120 days of chest CT imaging. Forty percent of patients received the intervention. Among 2,856 patients (2.9%) who received diagnoses of lung cancer, 28% had early-stage disease. In multivariable analyses, the intervention was associated with 24% greater odds of early-stage diagnosis (OR, 1.24; 95% CI, 1.09-1.41) and no change in the odds of late-stage diagnosis (OR, 1.04; 95% CI, 0.95-1.14). The intervention was not associated with the rate of surgical treatment within 120 days. In this large quasi-experimental community-based observational study, implementation of a system that combines standardized tagging of chest CT scan reports with clinical navigation was effective for increasing the diagnosis of early-stage intactness and timing of pubertal onset in girls: a prospective cohort study Girls who experience early-life familial stress may have heightened risk of early puberty, which has adverse implications for adolescent and adult health. We assessed the association between household intactness and pubertal onset using a racially/ethnically diverse cohort of girls from Northern California. A prospective cohort study of 26,044 girls born in 2003-10. Girls living with both parents from birth up to 6 years were considered to come from \"intact\" households while others constituted \"non-intact\" households. Pubertal development was measured using pediatrician-assessed Tanner staging for breast and pubic hair. Pubertal onset was defined as the transition from Tanner Stage 1 to 2+ for breast (thelarche) and pubic hair (pubarche). Menarche data was collected from routine well-child questionnaires. Weibull regression models accommodating left, right, and interval censoring were used to determine risk of earlier thelarche and pubarche, and logistic regressions were used to assess the risk of early menarche (age < 12). Girls exposed to non-intact households before age 2 years were at increased risk for earlier thelarche and pubarche with significant effect modification by race/ethnicity, compared with girls from intact households. The associations were strongest among Black girls (adjusted hazard ratio [HR]: 1.60, 95% confidence interval for thelarche and pubarche, respectively). There were no significant associations among Asian/Pacific Islanders. Girls who lived in non-intact households before age 2 years were also at increased risk for earlier menarche, but without race/ethnic interaction. Adjustment for prepubertal obesity did not change these associations. Associations between living in non-intact households after age 2 years and early puberty were weaker but still significant. Exposure to a non-intact household early in life may increase the risk of early puberty in girls. Future psychosocial interventions focused on improving family cohesiveness and efforts to reduce childhood stress among families that are non-intact may mitigate these negative associations, thereby preventing future adverse health effects of early puberty and health disparities. Authors: Aghaee, 31 loci for mammographic density phenotypes and their associations with breast cancer risk Mammographic density (MD) phenotypes are strongly associated with breast cancer risk and highly heritable. In this GWAS meta-analysis of 24,192 women, we identify 31 MD loci at P < 5 \u00d7 10-8, tripling the number known to 46. Seventeen identified MD loci also are associated with breast cancer risk in an independent meta-analysis (P < 0.05). Mendelian randomization analyses show that genetic estimates of dense area (DA), nondense area (NDA), and percent density (PD) are all significantly associated with breast cancer risk (P < 0.05). Pathway analyses reveal distinct biological processes involving DA, NDA and PD loci. These findings provide additional insights into the genetic basis of MD phenotypes and their associations with breast cancer risk. shared electronic health records: telemedicine and laboratory follow-up after hospital discharge Continuity of patient information across settings can improve transitions after hospital discharge, but outpatient clinicians often have limited access to complete information from recent hospitalizations. We examined whether providers' timely access to clinical information through shared inpatient-outpatient electronic health records (EHRs) was associated with follow-up visits, return emergency department (ED) visits, or readmissions after hospital discharge in patients with diabetes. Stepped-wedge observational study. As an integrated delivery system staggered implementation of a shared inpatient-outpatient EHR, we studied 241,510 hospital discharges in patients with diabetes (2005-2011), examining rates of outpatient follow-up office visits, telemedicine (phone visits and asynchronous secure messages), laboratory tests, and return ED visits or readmissions (as adverse events). We used multivariate logistic regression adjusting for time trends, patient characteristics, and medical center and accounting for patient clustering to calculate adjusted follow-up rates. For patients with diabetes, provider use of a shared inpatient-outpatient EHR was associated with a statistically significant shift toward follow-up delivered through a combination of telemedicine and outpatient laboratory tests, without a traditional in-person visit (from 22.9% with an outpatient-only EHR to 27.0% with a shared inpatient-outpatient EHR; P < .05). We found no statistically significant differences in 30-day return ED visits (odds ratio, 1.02; 95% CI, 0.96-1.09) or readmissions (odds ratio, 0.98; 95% CI, 0.91-1.06) with the shared EHR compared with the outpatient-only EHR. Real-time clinical information availability during transitions between health care settings, along with robust telemedicine access, may shift the method of care delivery without adversely affecting patient health outcomes. Efforts to expand interoperability and information exchange may support follow-up care efficiency. Authors: Reed, Mary; Huang, Manag 2020 10 01;26(10):e327-e332. 2020-10-01. and early-childhood obesity: between- and within-family comparisons Associations of excessive gestational weight gain (GWG) with greater birthweight and childhood obesity may be confounded by shared familial environment or genetics. Sibling comparisons can minimize variation in these confounders because siblings grow up in similar environments and share the same genetic predisposition for weight gain. We identified 96 289 women with live births in 2008-2014 at Kaiser Permanente Northern California. Fifteen percent of women (N = 14 417) had at least two births during the study period for sibling analyses. We assessed associations of GWG according to the Institute of Medicine (IOM) recommendations with birthweight and obesity at age 3 years, using conventional analyses comparing outcomes between mothers and sibling analyses comparing outcomes within mothers, which control for stable within-family unmeasured confounders such as familial environment and genetics. We used generalized estimating-equations and fixed-effects models. In conventional analyses, GWG above the IOM recommendations was associated with 88% greater odds of large-for-gestational age birthweight [95% confidence interval (CI): 1.80, 1.97] and 30% greater odds of obesity at 3 years old (95% CI: 1.24, 1.37) compared with GWG within the IOM recommendations. In sibling analyses, GWG above the IOM recommendations was also associated with greater odds of large-for-gestational age [odds ratio (OR): 1.36; 95% CI: 1.20, 1.54], but was not associated with obesity at 3 years old (OR = 0.98; 95% CI: 0.84, 1.15). GWG likely has a direct impact on birthweight; however, shared environmental and lifestyle factors within families may play a larger role in determining early-childhood weight status and obesity risk than GWG. Epidemiol. 2020 10 01;49(5):1682-1690. Association of Low Muscle Mass and Low Muscle Radiodensity With Morbidity and Mortality for Colon Cancer Surgery Given the risks of postoperative morbidity and its consequent economic burden and impairment to patients undergoing colon resection, evaluating risk factors associated with complications will allow risk stratification and the targeting of supportive interventions. Evaluation of muscle characteristics is an emerging area for improving preoperative risk stratification. To examine the associations of muscle characteristics with postoperative complications, length of hospital stay (LOS), readmission, and mortality in patients with colon cancer. This population-based retrospective cohort study was conducted among 1630 patients who received a diagnosis of stage I to III colon cancer from January 2006 to December 2011 at Kaiser Permanente Northern California, an integrated health care system. Preliminary data analysis started in 2017. Because major complication data were collected between 2018 and 2019, the final analysis using the current cohort was conducted between 2019 and 2020. Low skeletal muscle index (SMI) and/or low skeletal muscle radiodensity (SMD) levels were assessed using preoperative computerized tomography images. Length of stay, any complication (1 predefined complications) or major complications (Clavien-Dindo classification score 3), 30-day mortality and readmission up to 30 days postdischarge, and overall mortality. The mean (SD) age at diagnosis was 64.0 (11.3) years and 906 (55.6%) were women. Patients with low SMI or low SMD were more likely to remain hospitalized 7 days or longer after surgery (odds ratio [OR], 1.33; 95% CI, 1.05-1.68; OR, 1.39; 95% CI, 1.05-1.84, respectively) and had higher risks of overall mortality (hazard ratio, 1.40; 95% CI, 1.13-1.74; hazard ratio, 1.44; 95% CI, 1.12-1.85, respectively). Additionally, patients with low SMI were more likely to have 1 or more postsurgical complications (OR, 1.31; 95% CI, 1.04-1.65) and had higher risk of 30-day mortality (OR, 4.85; 95% CI, 1.23-19.15). Low SMD was associated with higher odds of having major complications (OR, 2.41; 95% CI, 1.44-4.04). Low SMI and low SMD were associated with longer LOS, higher risk of postsurgical complications, and short-term and long-term mortality. Research should evaluate whether targeting potentially modifiable factors preoperatively, such as preserving muscle mass, could reverse the observed negative associations with postoperative outcomes. Authors: Xiao, Jingjie; JAMA Surg. 2020 10 01;155(10):942-949. Determining Which of Several Simultaneously Administered Vaccines Increase Risk of an Adverse Event Childhood immunization schedules often involve multiple vaccinations per visit. When increased risk of an adverse event is observed after simultaneous (same-day) vaccinations, it can be difficult to ascertain which triggered the adverse event. This methods paper discusses a systematic process to determine which of the simultaneously administered vaccine(s) are most likely to have caused an observed increase in risk of an adverse event. We use an example from the literature where excess risk of seizure was observed 1 day after vaccination, but same-day vaccination patterns made it difficult to discern which vaccine(s) may trigger the adverse event. We illustrate the systematic identification process using a simulation that retained the observed pattern of simultaneous vaccination in an empirical cohort of vaccinated children. We simulated \"true\" effects for diphtheria-tetanus-acellular pertussis (DTaP) and pneumococcal conjugate (PCV) on risk of seizure the day after vaccination. We varied the independent and interactive effects of vaccines (on the multiplicative scale). After applying the process to simulated data, we evaluated risk of seizure 1 day after vaccination in the empirical cohort. In all simulations, we were able to determine which vaccines contributed to excess risk. In the empirical data, we narrowed the association with seizure from all vaccines in the schedule to three likely candidates, DTaP, PCV, and/or Haemophilus influenzae type B (HiB) (p < 0.01, attributable risk when all three were administered together: five per 100,000). Disentangling their associations with seizure would require a larger sample or more variation in the combinations administered. When none of these three were administered, no excess risk was observed. The process outlined could provide valuable information on the magnitude of potential risk from individual and simultaneousvaccinations. Associations should be further investigated with independent data as well as biologically based, statistically independent hypotheses. Authors: Wang SV; 10;43(10):1057-1065. Feasibility of Measuring Preferences for Chemotherapy Among Early-Stage Breast Cancer Survivors Using a Direct Rank Ordering Multicriteria Decision Analysis Versus a Time Trade-Off Chemotherapy is increasingly a preference-based choice among women diagnosed with early-stage breast cancer. Multicriteria decision analysis (MCDA) is a promising but underutilized method to facilitate shared decision making. We explored the feasibility of conducting an MCDA using direct rank ordering versus a time trade-off (TTO) to assess chemotherapy choice in a large population-based sample. We surveyed 904 early-stage breast cancer survivors who were within 5 years of diagnosis and reported to the Western Washington State Cancer System and Kaiser Permanente Northern California registries. Direct rank ordering of 11 criteria and TTO surveys were conducted from September 2015 to July 2016; clinical data were obtained from registries or medical records. Multivariable regressions estimated post hoc associations between the MCDA, TTO, and self-reported chemotherapy receipt, considering covariates. Survivors ranged in age from 25 to 74 years and 73.9% had stage I tumors. The response rate for the rank ordering was 81.0%; TTO score was 94.2%. A one-standard deviation increase in the difference between the chemotherapy and no chemotherapy MCDA scores was associated with a 75.1% (95% confidence interval 43.9-109.7%; p < 0.001) increase in the adjusted odds of having received chemotherapy; no association was found between the TTO score and chemotherapy receipt. A rank-order-based MCDA was feasible and was associated with chemotherapy choice. Future research should consider developing and testing this MCDA for use in clinical encounters. Additional research is required to develop a TTO-based model and test its properties against a pragmatic MCDA to inform future shared decision-making Drug Saf. 2020 10;29(10):1331-1335. Epub 2020-05-25. History of Early Childhood Infections and Acute Lymphoblastic Leukemia Risk Among Children in a U.S. Integrated Health Care System Surrogate measures of infectious exposures have been consistently associated with lower childhood acute lymphoblastic leukemia (ALL) risk. However, recent reports have suggested that physician-diagnosed early-life infections increase ALL risk, thereby raising the possibility that stronger responses to infections might promote risk. We examined whether medically diagnosed infections were related to childhood ALL risk in an integrated health-care system in the United States. Cases of ALL (n = 435) diagnosed between 1994-2014 among children aged 0-14 years, along with matched controls (n = 2,170), were identified at Kaiser Permanente Northern California. Conditional logistic regression was used to estimate risk of ALL associated with history of infections during first year of life and across the lifetime (up to diagnosis). History of infection during first year of life was not associated with ALL risk (odds ratio (OR) = 0.85, 95% confidence interval (CI): 0.60, 1.21). However, infections with at least 1 medication prescribed (i.e., more \"severe\" infections) were inversely associated with risk (OR = 0.42, 95% CI: 0.20, 0.88). Similar associations were observed when the exposure window was expanded to include medication-prescribed infections throughout the subjects' lifetime pragmatic randomized trial of mHealth mindfulness-based intervention for advanced cancer patients and their informal caregivers Assess the feasibility of conducting a cluster randomized trial (RCT) comparing technology-delivered mindfulness-based intervention (MBI) programs against a waitlist control arm targeting advanced cancer patients and their informal caregivers. Two-arm cluster RCT within Kaiser Permanente Northern California (KPNC). We recruited patients with metastatic solid malignancies or hematological cancers and their informal caregivers. Intervention-group participants chose to use either a commercially available mindfulness app (10-20 minutes/day) or a webinar-based mindfulness course for 6 weeks. The waitlist control group received usual care. We assessed feasibility measures and obtained participant-reported data on quality-of-life (primary outcome) and distress outcomes (secondary) pre- and post-intervention. 103 patients (median age 67 years; 70% female; 81% White) and 39 caregivers (median age 66 years; 79% female; 69% White) were enrolled. Nearly all participants chose the mindfulness app over the webinar-based program. Among the participants in the intervention arm who chose the mobile-app program and completed the postintervention (6-week) survey, 21 (68%) patients and 7 (47%) caregivers practiced mindfulness at least 50% of the days during the 6-week study period. Seventy-four percent of intervention participants were \"very\" or \"extremely\" satisfied with the mindfulness program. We observed improvements in anxiety, quality of life, and mindfulness among patients in the intervention arm compared to those in the control group. We demonstrated the feasibility of conducting a cluster RCT of mHealth MBI for advanced cancer patients and their caregivers. Such remote interventions can be helpful particularly during the COVID-19 pandemic. This article is protected by copyright. All rights 26. Pan-cancer study detects genetic risk variants and shared genetic basis in two large cohorts Deciphering the shared genetic basis of distinct cancers has the potential to elucidate carcinogenic mechanisms and inform broadly applicable risk assessment efforts. Here, we undertake genome-wide association studies (GWAS) and comprehensive evaluations of heritability and pleiotropy across 18 cancer types in two large, population-based cohorts: the UK Biobank (408,786 European ancestry individuals; 48,961 cancer cases) and the Kaiser Permanente Genetic Epidemiology Research on Adult Health and Aging cohorts (66,526 European ancestry individuals; 16,001 cancer cases). The GWAS detect 21 genome-wide significant associations independent of previously reported results. Investigations of pleiotropy identify 12 cancer pairs exhibiting either positive or negative genetic correlations; 25 pleiotropic loci; and 100 independent pleiotropic variants, many of which are regulatory elements and/or influence cross-tissue gene expression. Our findings demonstrate widespread pleiotropy and offer further insight into the complex genetic architecture of cross-cancer susceptibility. Authors: 09 04;11(1):4423. Epub 2020-09-04. Trends and correlates of self-reported alcohol and nicotine use among women before and during pregnancy, 2009-2017 To examine trends and correlates of frequency of self-reported alcohol and nicotine use among pregnant women. Cross-sectional study of 363,240 pregnancies from 2009 to 2017 screened for self-reported substance use at their first prenatal visit in Kaiser Permanente Northern California. Poisson regression with a log link function was used to estimate the annual prevalences of self-reported daily, weekly, and monthly alcohol and nicotine use, adjusting for socio-demographics. Generalized estimating equation models were used to estimate the adjusted odds ratios (aOR) of any self-reported prenatal alcohol or nicotine use among those who self-reported use in the year prior to pregnancy, by frequency of pre-pregnancy substance use and socio-demographics. The sample was 64 % non-White [mean (SD) age = 30.1 (5.6)]. From 2009-2017, alcohol use before pregnancy increased from 63.4%-65.9% (trend p-value = .008), and prenatal alcohol use decreased from 11.6%-8.8% (trend p-value<.0001). Nicotine use before pregnancy decreased from 12.7 % to 7.7 % (trend p-value<.0001), and prenatal use decreased from 4.3 % to 2.0 % (trend p-value<.0001). Trends by use frequency were similar to overall trends. The odds of continued use of alcohol and nicotine during pregnancy were higher among those who used daily or weekly (versus monthly or less) in the year before pregnancy and varied with socio-demographics. Prenatal alcohol and nicotine use decreased from 2009 to 2017. More frequent pre-pregnancy use predicted higher odds of prenatal use. Results suggest that interventions and education about the harms of prenatal substance use for frequent users prior to conception may reduce substance use during pregnancy. Authors: Young-Wolff, Kelly C; 2020 09 01;214:108168. Epub 2020-07-15. Evaluation of a Vaccine-Communication Tool for Physicians To evaluate a Kaiser Permanente Northern California physician training tool entitled \"Effective Communication without Confrontation\" aimed at improving communication with vaccine-hesitant parents, building trust, and alleviating physician stress surrounding vaccination visits. Trainings were held May to July 2015. Pre- and post-training surveys assessed physician comfort and perceived effectiveness in communicating with vaccine-hesitant parents. We measured vaccination coverage at the 2-, 4-, and 6-month well-child visits, and days undervaccinated at 9 months of age. We compared vaccination rates before and after the training. Of 415 physicians who received training, 249 completed post-training surveys. Physicians reported that the training helped them feel \"much more or more\" comfortable talking with parents who are unsure (72.3%), want to delay (73.9%), or refuse (63.5%) vaccinations and \"much more or more\" effective at persuading parents who are unsure (67.5%) or want to delay vaccinations (61.4%). They reported feeling \"the same or less\" effective persuading parents who refuse vaccinations (66.3%). Vaccine coverage remained unchanged and high from before to after the training (95%-96%), as did parent satisfaction with his or her child's provider (4.73/5.00). The Effective Communication without Confrontation training did not increase vaccine coverage, but did improve physicians' comfort and perceived effectiveness communicating with most vaccine-hesitant parents and may help to ease potentially stressful vaccination visits. Authors: Glanternik JR; 09;224:72-78.e1. Epub 2020-06-06. The Covid-19 Pandemic and J Med. 2020 08 13;383(7):691-693. Epub 2020-05-19. Smoking and cessation treatment among persons with and without HIV in a U.S. integrated health system Persons with HIV (PWH) are more likely to smoke and are more susceptible to the harmful effects of smoking than persons without HIV. We examined smoking patterns and use of cessation treatment among PWH and persons without HIV in a U.S. integrated health system. We identified adults (18 years) with HIV and demographically-matched persons without HIV between July 2013 and December 2017. Smoking status and cessation treatment were ascertained from health records. We calculated age-standardized annual prevalence of smoking and evaluated trends using Cochran-Armitage tests and Poisson regression. Factors associated with cessation treatment during the study period, and smoking in the last year of the study, were evaluated by HIV status using multivariable Poisson models. The study included 11,235 PWH and 227,320 persons without HIV. Smoking prevalence was higher among PWH across all years but declined for both groups (from 16.6% to 14.6% in PWH and 11.6% to 10.5% in persons without HIV). Among smokers, PWH were more likely to initiate cessation treatment compared to persons without HIV (17.9% vs. 13.3%, covariate-adjusted prevalence ratio of 1.31, 95% CI = 1.15-1.50), with few differences in cessation treatment across subgroups of PWH. In 2017, smoking prevalence remained higher in PWH, especially among those who were younger or who had diagnoses of depression or substance use disorder. In a setting with access to cessation resources, smoking prevalence decreased both in PWH and persons without HIV. PWH had greater uptake of cessation treatment, which is encouraging for smoking reduction and improved health. Authors: Epub 2020-06-18. Increased Risk of Colorectal Cancer in Individuals With a History of Serrated Polyps Serrated polyp (SPs) are precursors to 20% to 30% of cases of colorectal tumors, but patients' long-term risk after removal of SPs is poorly understood. We investigated the risk of colorectal cancer (CRC) in individuals with a history of SPs. We performed a retrospective cohort study of Kaiser Permanente Northern California members who underwent colonoscopy from 2006 through 2016. Study participants were categorized based on the size and location of SPs. We used Cox proportional hazards modeling to estimate the hazard ratio (HR) and 95% confidence interval (CI) for the association of CRC diagnosed more than 1 year after colonoscopy, with polyp type vs no polyp after adjustment for year of colonoscopy, age, sex, race/ethnicity, and smoking history. The study included 233,393 individuals, of whom 445 developed incident CRC. At 10 years, the cumulative incidence rates of CRC for individuals with no polyp, proximal small SPs, proximal large SPs, and distal SPs were 4.7 (95% CI, 4.0-5.6), 14.8 (95% CI, 30.2 (95% CI, 13.2-68.4), and 5.9 (95% CI, 3.6-9.5) per 1000 persons, respectively. In patients with SPs, risk of CRC was not increased until 3 years or more after the first colonoscopy (HR for small proximal SPs 2.6; 95% CI, 1.7-3.9 HR for large proximal SPs 8.0; 95% CI, 3.6-16.1). The presence of synchronous adenomas increased the risk for CRC (HR for proximal SPs with synchronous adenomas 4.0; 95% CI, 3.0-5.5 synchronous adenomas 2.4; 95% CI, 1.7-3.4). In a retrospective analysis of a large cohort of individuals examined by colonoscopy, we found that risk of incident CRC increased in individuals with proximal SPs (large SPs in particular) 3 years or more after the colonoscopy. These findings support guidelines that recommend surveillance colonoscopy for individuals with SPs. Authors: Risk of Atopic Dermatitis in Children Caesarean delivery (C-section) may disrupt maternal-infant microbial transfer and alter immune system development and subsequent risk for atopic dermatitis. Investigate the association between C-section and atopic dermatitis by age four and examine potential sources of bias in the relationship in a large cohort study. Maternal and child information was collected through Kaiser Permanente Northern California's (KPNC) integrated healthcare system. Data sources included electronic medical records, pharmacy databases, state birth records, and prospectively collected breastfeeding surveys. Children were eligible if they were born in a KPNC or contracting hospital between 2005 and 2014 and had continuous enrolment in the KPNC system for at least four years (n = 173 105). Modified Poisson regression with robust variance estimation was used to estimate the association between C-section and atopic dermatitis overall and when stratified by demographic and labour and delivery characteristics. Although unadjusted analyses showed a positive association between C-section and atopic dermatitis [RR(95%CI): 1.06(1.03, 1.10)], this null after adjustment [aRR(95%CI): 1.02(0.99, 1.05)]. In stratified analyses, there was evidence that C-section increased atopic dermatitis risk among certain subgroups pre-pregnancy BMI), but associations were weak. C-section delivery conditions indicative of the least exposure to maternal microbiome (ie no labour, short interval between membrane rupture and delivery) showed no evidence of association with atopic dermatitis. Estimated associations were not strongly influenced by intrapartum antibiotics, breastfeeding, missing data, or familial factors. Caesarean delivery was not associated with atopic dermatitis by age four in this large US cohort. This association did not appear to be biased by intrapartum antibiotics, breastfeeding behaviour, C-section indication, 2020-06-11. Comparison of Overall and Comorbidity-Free Life Expectancy Between Insured Adults With and Without HIV Infection, 2000-2016 Antiretroviral therapy (ART) has improved life expectancy for individuals with HIV infection, but recent data comparing life span and comorbidity-free years by HIV status are lacking. To quantify the gap in life span and comorbidity-free years by HIV status among adults with access to care. This matched cohort study used data from insured adults with and without HIV infection (aged 21 years) matched 1:10 at medical centers of Kaiser Permanente in northern and southern California and the mid-Atlantic states of Washington DC, Maryland, and Virginia from January 1, 2000, through December 31, 2016. Data were analyzed from September 1, 2019, through March 31, 2020. HIV status and, for individuals with HIV infection, ART initiation at a CD4 cell count of 500/L or greater. Overall life expectancy and expected years free of major chronic comorbidities, including chronic liver disease, chronic kidney disease, chronic lung disease, diabetes, cancer, and cardiovascular disease. Of 39 000 individuals with HIV infection and 387 785 matched uninfected adults, 374 421 (87.7%) were male, with a mean (SD) age of 41.4 (10.8) years. Among 359 244 individuals with known race/ethnicity, 90 177 (25.1%) were non-Hispanic black and 87 191 (24.3%) were Hispanic. From 2000 to 2003, overall life expectancy at age 21 years of age was 37.6 years among individuals with HIV infection and 59.7 years among uninfected adults, (difference, 22.1 years; 95% CI, 20.2-24.0 years). From 2014 to 2016, overall life expectancy at 21 years of age among individuals with HIV infection increased to 56.0 years compared with 65.1 years among uninfected adults (difference, 9.1 years; 95% CI, 7.9-10.2 years). During 2011 to 2016, individuals with HIV infection who initiated ART with a CD4 cell count of 500/L or greater had a life expectancy at 21 years of age of 57.4 years compared with 64.2 years among uninfected adults (difference, 6.8 years; 95% CI, 5.0-8.5 years). From 2000 to 2003, the expected number of comorbidity-free years remaining at 21 years of age was 11.3 for individuals with HIV infection and 26.6 years for uninfected adults (difference, 15.3 years; 95% CI, 13.9-16.6 years). This difference in comorbidity-free years persisted over time but decreased to 9.5 years (95% CI, 7.7-11.2 years) for individuals with HIV infection who initiated ART at a CD4 cell count of 500/L or greater. The results suggest that life expectancy of adults with HIV infection may be near that of life expectancy of individuals without HIV infection, but greater attention is needed to prevention of comorbidities among individuals with HIV infection. Azithromycin Use With Cardiovascular Mortality Azithromycin is one of the most commonly prescribed antibiotics in the US. It has been associated with an increased risk of cardiovascular death in some observational studies. To estimate the relative and absolute risks of cardiovascular and sudden cardiac death after an outpatient azithromycin prescription compared with amoxicillin, an antibiotic not known to increase cardiovascular events. This retrospective cohort study included 2 large, diverse, community-based integrated care delivery systems with comprehensive capture of encounters and prescriptions from January 1, 1998, to December 31, 2014. The cohort included patients aged 30 to 74 years who had at least 12 months of health-plan enrollment prior to antibiotic exposure. The exclusion criteria were absence of prescription benefits, prescription for more than 1 type of study antibiotic within 10 days, hospitalization or nursing home residence, and serious medical conditions. Risk of cardiovascular death associated with azithromycin vs amoxicillin exposure was calculated after controlling for confounding factors using a propensity score. Data were analyzed from December 1, 2016, to March 30, 2020. Outpatient prescription of azithromycin or amoxicillin. The primary outcomes were cardiovascular death and sudden cardiac death. An a priori subgroup analysis quantified the effects of azithromycin exposure among patients with increased baseline cardiovascular risk. The secondary outcomes were noncardiovascular death and all-cause mortality. The study included 7 824 681 antibiotic exposures, including 1 736 976 azithromycin exposures (22.2%) and 6 087 705 amoxicillin exposures (77.8%), among 2 929 008 unique individuals (mean [SD] age, 50.7 [12.3] years; 1 810 127 [61.8%] women). Azithromycin was associated with a significantly increased hazard of cardiovascular death (hazard ratio [HR], 1.82; 95% CI, 1.23-2.67) but not sudden cardiac death (HR, 1.59; 95% CI, 0.90-2.81) within 5 days of exposure. No increases in risk were found 6 to 10 days after exposure. Similar results were observed in patients within the top decile of cardiovascular risk (HR, 1.71; 95% CI, 1.06-2.76). Azithromycin was also associated with an increased risk of noncardiovascular death (HR, 2.17; 95% CI, 1.44-3.26) and all-cause mortality (HR, 2.00; 95% CI, 1.51-2.63) within 5 days of exposure. These findings suggest that outpatient azithromycin use was associated with an increased risk of cardiovascular death and noncardiovascular death. Causality cannot be established, particularly for noncardiovascular death, owing to the likelihood of Patient Characteristics Associated With Choosing a Telemedicine Visit vs Office Visit With the Same Primary Care Clinicians Video or telephone telemedicine can offer patients access to a clinician without arranging for transportation or spending time in a waiting room, but little is known about patient characteristics associated with choosing between telemedicine or office visits. To examine patient characteristics associated with choosing a telemedicine visit vs office visit with the same primary care clinicians. This cross-sectional study included data from 1 131 722 patients who scheduled a primary care appointment through the Kaiser Permanente Northern California patient portal between January 1, 2016, and May 31, 2018. All completed primary care appointments booked via the patient portal were identified. Only index visits without any other clinical visits within 7 days were included to define a relatively distinct patient-initiated care-seeking episode. Visits for routine physical, which are not telemedicine-eligible, were excluded. Data were analyzed from July 1, 2018, to December 31, 2019. Patient choice between an office, video, or telephone visit. Relative risk ratios (RRRs) for patient sociodemographic characteristics (age, sex, race/ethnicity, neighborhood socioeconomic status, language preference), technology access (neighborhood residential internet, mobile portal use), visiting the patient's own personal primary care clinician, and in-person visit barriers (travel-time, parking, cost-sharing), associated with choice of video or telephone telemedicine (vs office visit). Of 2 178 440 patient-scheduled primary care visits scheduled by 1 131 722 patients, 86% were scheduled as office visits and 14% as telemedicine visits, with 7% of the telemedicine visits by video. Choosing telemedicine was statistically significantly associated with patient sociodemographic characteristics. For example, patients aged 65 years and over were less likely than patients aged 18 to 44 years to choose telemedicine (RRR, 0.54-0.57 for telephone visit). Choosing telemedicine was also statistically significantly associated with technology access (patients living in a neighborhood with high rates of residential internet access were more likely to choose a video visit than patients whose neighborhoods had low internet access: RRR, 1.10; 95% CI, 1.06-1.14); as well as in-person visit barriers (patients whose clinic had a paid parking structure were more likely to choose a telemedicine visit than patients whose facility had free parking: RRR, 95% CI, 1.61-1.86 for telephone visit). In this cross-sectional study, patients usually chose an in-person visit when scheduling an appointment online through the portal. Telemedicine may offer the potential to reach vulnerable patient groups and improve access for patients with transportation, parking, or cost barriers to clinic visits. Authors: Reed ME; Epub 2020-06-01. A telehealth lifestyle intervention to reduce excess gestational weight gain in pregnant women with overweight or obesity (GLOW): a randomised, parallel-group, controlled trial Excess gestational weight gain (GWG) among women with overweight or obesity synergistically increases their already elevated risk of having gestational diabetes, a caesarean delivery, a large for gestational age infant, and post-partum weight retention, and increases their child's risk of obesity. We investigated whether a primarily telehealth lifestyle intervention reduced excess GWG among women with overweight or obesity. We did a randomised controlled trial in five antenatal clinics of Kaiser Permanente; Oakland, San Leandro, Walnut Creek, Fremont, and Santa Clara, CA, USA. Women at 8-15 weeks' gestation with singletons, pre-pregnancy BMI 25\u00b70-40\u00b70 kg/m2, and aged 18 years or older were randomly assigned (1:1) to receive the telehealth lifestyle intervention or usual antenatal care. Randomisation was adaptively balanced for age, BMI, and race and ethnicity. Data collectors and investigators were masked to group assignments. The core lifestyle intervention consisted of two in-person and 11 telephone sessions on behavioural strategies to improve weight, diet, and physical activity, and stress management to help women meet a trial goal of gaining at the lower limit of the Institute of Medicine (IOM) guidelines range for total GWG: 7 kg for women with overweight and 5 kg for women with obesity. Usual antenatal care included an antenatal visit at 7-10 weeks' gestation, an additional seven antenatal visits, on average, and periodic health education newsletters, including the IOM GWG guidelines and information on healthy eating and physical activity in pregnancy. The primary outcome was weekly rate of GWG expressed as excess GWG, per Institute of Medicine guidelines and mean assessed in the intention-to-treat population. The trial is registered at ClinicalTrials.gov, NCT02130232. Between March 24, 2014, and Sept 26, 2017, 5329 women were assessed for eligibility and 200 were randomly assigned to the lifestyle intervention group and 198 to the usual care group. Analyses included 199 women in the lifestyle intervention group (one lost to follow-up) and 195 in the usual care group (three lost to follow-up). 96 (48%) women in the lifestyle intervention group and 134 (69%) women in the usual care group exceeded Institute of Medicine guidelines for rate of GWG per week (relative risk 0\u00b770, 95% CI 0\u00b759 to 0\u00b783). Compared with usual care, women in the lifestyle intervention had reduced weekly rate of GWG (mean 0\u00b726 kg per week [SD 0\u00b715] vs 0\u00b732 kg per week [0\u00b713]; mean between-group -0\u00b707 kg per week, 95% CI -0\u00b709 to -0\u00b704). No between-group differences in perinatal complications were observed. Our evidence-based programme showed that health-care delivery systems could further adapt to meet the needs of their clinical settings to prevent excess GWG and improve healthy behaviours and markers of insulin resistance among women with overweight or obesity by using telehealth lifestyle interventions. US National Institutes of Health. Authors: 06;8(6):490-500. Prenatal Depression and Diet Quality During Pregnancy Maternal nutrition during pregnancy has a significant effect on the health of the offspring and mother, highlighting the need for identifying factors that may affect diet during pregnancy. Research in nonpregnant and pregnant populations suggest depression may play a role. To investigate the relationship between prenatal depression and diet quality during pregnancy overall and by race/ethnicity and to explore the relationships between prenatal depression and the 12 Healthy Eating Index 2010 dietary components. A cross-sectional secondary analysis of a cohort study of Kaiser Permanente Northern California women entering prenatal care between October 2011 and April 2013. Participants included 1,160 adult pregnant women. Poor diet quality was defined as a Healthy Eating Index 2010 score in the lowest quartile. Logistic regression was used to assess the relationship between prenatal depression (defined as a depression diagnosis, Patient Health Questionnaire score of 10 or greater or antidepressant medication dispensing between the last menstrual period and completion of the food frequency questionnaire) and poor diet quality overall and by race/ethnicity. Relationships between prenatal depression and each of the 12 Healthy Eating Index 2010 dietary components were assessed using t-tests and linear regression analyses. One hundred fifty-nine (14%) participants had prenatal depression. Women with prenatal depression had nearly two times the odds of poor diet quality (odds ratio 1.80, 95% CI 1.23 to 2.60) compared with women without prenatal depression, after adjusting for potential confounders. Differences emerged by race/ethnicity; after adjusting for potential confounders the adjusted odds of poor diet quality were significant only among Hispanic women. Hispanic women with prenatal depression had an increased odds of poor diet quality compared with Hispanic women without prenatal depression (odds ratio 2.66, 95% CI 1.15 to 6.06). Women with prenatal depression had a higher consumption of empty calories (from solid fats, alcohol, and added sugars; threshold for counting alcohol >13 g/1,000 kcal) (P=0.01) and lower consumption of greens and beans (P<0.05), total fruit (P<0.01), and whole fruit (P<0.01), compared with women without prenatal depression. Except for empty calories, these findings remained after adjusting for potential confounders. Study findings suggest that women with prenatal depression are at a higher risk of poor diet quality compared with women without prenatal depression, and the relationship is stronger among Hispanic women. Nutrition counseling interventions for women with depression should consider the use of culturally sensitive materials and target limiting empty calories from solid fats, alcohol, and added sugars and encourage eating more greens, beans, and fruit. Authors: Epub 2020-02-13. Time-to-event analysis when the event is defined on a finite time interval Acute graft-versus-host disease (GVHD) is a frequent complication following hematopoietic cell transplantation (HCT). Research on risk factors for acute GVHD has tended to ignore two important clinical issues. First, post-transplant mortality is high. In our motivating data, 100-day post-HCT mortality was 15.4%. Second, acute GVHD in its classic form is only diagnosed within 100 days of the transplant; beyond 100 days, a patient may be diagnosed with late onset acute or chronic GVHD. Standard modeling of time-to-event outcomes, however, generally conceive of patients being able to experience the event at any point on the time scale. In this paper, we propose a novel multi-state model that simultaneously: (i) accounts for mortality through joint modeling of acute GVHD and death, and (ii) explicitly acknowledges the finite time interval during which the event of interest can take place. The observed data likelihood is derived, with estimation and inference via maximum likelihood. Additionally, we provide methods for estimating the absolute risk of acute GVHD and death simultaneously. The proposed framework is compared via comprehensive simulations to a number of alternative approaches that each acknowledge some but not all aspects of acute GVHD, and illustrated with an analysis of HCT data that motivated this work. Authors: Lee C; Lee SJ; Haneuse S Stat Methods Med Res. 2020 06;29(6):1573-1591. Epub 2019-08-22. Inverse probability weighted Cox model in multi-site studies without sharing individual-level data The inverse probability weighted Cox proportional hazards model can be used to estimate the marginal hazard ratio. In multi-site studies, it may be infeasible to pool individual-level datasets due to privacy and other considerations. We propose three methods for making inference on hazard ratios without the need for pooling individual-level datasets across sites. The first method requires a summary-level eight-column risk-set table to produce the same hazard ratio estimate and robust sandwich variance estimate as those from the corresponding pooled individual-level data analysis (reference analysis). The second and third methods, which are based on two bootstrap re-sampling strategies, require a summary-level four-column risk-set table and bootstrap-based risk-set tables from each site to produce the same hazard ratio and bootstrap variance estimates as those from their reference analyses. All three methods require only one file transfer between the data-contributing sites and the analysis center. We justify these methods theoretically, illustrate their use, and demonstrate their statistical performance using both simulated and real-world data. Authors: Shu D; Yoshida K; Fireman BH; Stat Methods Med Res. 2020 06;29(6):1668-1681. Epub 2019-08-26. Comparative Effectiveness of 2 Diabetes Prevention Lifestyle Programs in the Workplace: The City and County of San Francisco Diabetes Prevention Trial Data on the comparative effectiveness of Diabetes Prevention Programs (DPPs) in the workplace are limited. Between September 2015 and July 2016, employees of the City and County of San Francisco who were at risk for type 2 diabetes (N = 158) were randomly assigned to one of 2 DPP-derived programs recognized by the Centers for Disease Control and Prevention: an in-person YMCA-DPP (n = 78) or an online virtual lifestyle management DPP (VLM-DPP) offered through Canary Health (n = 80). The primary outcome was change in body weight assessed at 6 and 12 months. Follow-up ended in August 2017. Both the YMCA-DPP and VLM-DPP yielded a significant reduction in percentage body weight at 6 months. For the YMCA-DPP, mean percentage change at 6 months was -2.70% (95% confidence interval [CI], -3.91% to -1.48%) and months was -2.46% (95% CI, -4.24% to -0.68%). For the VLM-DPP, mean percentage change at 6 months was -2.41% (95% CI, -4.07% to -0.77%) and at 12 months -1.59% (95% CI, -3.51% to 0.33%). The mean between-condition difference 6 months was -0.25% (95% CI, -2.04% to 1.55%) and at 12 months was -0.84% (95% CI, -3.03% to 1.34%). No significant differences were observed between conditions. The YMCA-DPP had a slightly higher reduction in waist circumference than VLM-DDP at 6 months (mean between-condition difference -2.00 cm [95% CI, -4.24 to 0.25 cm]). Participant engagement, expressed as mean number of completed core program sessions, was significantly higher for the YMCA-DPP than the VLM-DPP. Participants of the YMCA-DPP completed an average of 10.2 sessions (95% CI, 9.0 to 11.4), and participants of the VLM-DPP completed an average of 5.9 sessions (95% CI, 4.7 to 7.1). The adjusted mean between-condition difference was 4.2 sessions (95% CI, 2.54 to 5.99). Both the YMCA-DPP and VLM-DPP yielded weight loss at 6 months, which was maintained at 12 months in the YMCA-DPP. The workplace may be an effective setting to offer DPPs. Authors: Pump Inhibitor Use and Risk of Gastric, Colorectal, Liver, and Pancreatic Cancers in a Community-Based Population Proton pump inhibitors (PPIs) are commonly used for gastrointestinal disorders; given they increase the systemic levels of gastrin, a trophic hormone, there is a concern about their carcinogenicity. This study evaluated the association between PPI use and gastrointestinal cancers. We performed a nested case-control study in a large, community-based integrated healthcare setting. Cases were adults with gastric (n = 1,233), colorectal (n = 18,595), liver (n = 2,329), or pancreatic cancers (n = 567). Each case was matched with up to 10 controls by age, sex, race/ethnicity, medical facility, and enrollment duration. The primary exposure was defined as 2-year cumulative PPI supply. Data were obtained from pharmacy, cancer registry, and electronic medical record databases. Associations were evaluated using conditional logistic regression and adjusted for multiple confounders. We also evaluated the cancer risks separately by PPI dose, duration of use, and dose and duration. PPI use of 2-years was not associated with the risks of gastric (odds ratio [OR]: 1.07, 95% CI: 0.89-1.67), compared to non-users. In exploratory analyses, elevated cancer risks were primarily restricted to those with 10 years of PPI use, but no consistent associations were found for increasing PPI dose and/or duration of use. PPI use of 2 years was not associated with increased risks of gastrointestinal cancers. The cancer risks associated with PPI use of 10 years requires further study. Authors: Lee JK; Merchant Gastroenterol. 2020 05;115(5):706-715. Initial Glycemic Control and Care Among Younger Adults Diagnosed With Type 2 Diabetes The prevalence of type 2 diabetes is increasing among adults under age 45. Onset of type 2 diabetes at a younger age increases an individual's risk for diabetes-related complications. Given the lasting benefits conferred by early glycemic control, we compared glycemic control and initial care between adults with younger onset (21-44 years) and mid-age onset (45-64 years) of type 2 diabetes. Using data from a large, integrated health care system, we identified 32,137 adults (aged 21-64 years) with incident diabetes (first HbA1c 6.5% [48 mmol/mol]). We excluded anyone with evidence of prior type 2 diabetes, gestational diabetes mellitus, or type 1 diabetes. We used generalized linear mixed models, adjusting for demographic and clinical variables, to examine differences in glycemic control and care at 1 year. Of identified individuals, 26.4% had younger-onset and 73.6% had mid-age-onset type 2 diabetes. Adults with younger onset had higher initial mean HbA1c values (8.9% [74 mmol/mol]) than adults (8.4% [68 mmol/mol]) (P < 0.0001) achieving an HbA1c <7% (<53 mmol/mol) 1 year after the diagnosis (adjusted odds ratio [aOR] 0.70 [95% CI 0.66-0.74]), even after accounting for HbA1c at diagnosis. Adults with younger onset had lower odds of in-person primary care contact (aOR 0.82 [95% CI 0.76-0.89]) than those with onset during mid-age, but they did not differ in telephone contact (1.05 [0.99-1.10]). Adults with younger onset had higher odds of starting metformin (aOR 1.20 [95% CI 1.12-1.29]) but lower odds of adhering to that medication (0.74 [0.69-0.80]). Adults with onset of type 2 diabetes at a younger age were less likely to achieve glycemic control at 1 year following diagnosis, suggesting the need for tailored care approaches to improve outcomes for this high-risk patient 2020 05;43(5):975-981. Epub 2020-03-04. Alcohol and tobacco use in relation to mammographic density in 23,456 women Percent density (PD) is a strong risk factor for breast cancer that is potentially modifiable by lifestyle factors. PD is a composite of the dense (DA) and nondense (NDA) areas of a mammogram, representing predominantly fibroglandular or fatty tissues, respectively. Alcohol and tobacco use have been associated with increased breast cancer risk. However, their effects on mammographic density (MD) phenotypes are poorly understood. We examined associations of alcohol and tobacco use with PD, DA, and NDA in a population-based cohort of 23,456 women screened using full-field digital mammography machines manufactured by Hologic or General Electric. MD was measured using Cumulus. Machine-specific effects were estimated using linear regression, and combined using random effects meta-analysis. Alcohol use was positively associated with PD (P trend = 0.01), unassociated with DA (P trend = 0.23), and inversely associated with NDA (P trend = 0.02) adjusting for age, body mass index, reproductive factors, physical activity, and family history of breast cancer. In contrast, tobacco use was inversely associated with PD (P trend = 0.0008), unassociated with DA (P trend = 0.93), and positively associated with NDA (P trend<0.0001). These trends were stronger in normal and overweight women than in obese women. These findings suggest that associations of alcohol and tobacco use with PD result more from their associations with NDA than DA. PD and NDA may mediate the association of alcohol drinking, but not tobacco smoking, with increased breast cancer risk. Further studies are needed to elucidate the modifiable lifestyle factors that influence breast tissue composition, and the important role of the fatty tissues on breast prior to Hysterectomy for Women with Leiomyoma or Abnormal Bleeding To develop a risk prediction model for occult uterine sarcoma using preoperative clinical characteristics in women undergoing hysterectomy for presumed uterine leiomyomata. Cases of uterine sarcoma were identified from the electronic medical records. Age/race-matched controls were selected at a 2:1 ratio (controls:cases) from a cohort of 45 188 women who underwent hysterectomy for uterine leiomyomata or abnormal bleeding during the same time interval. Unadjusted conditional logistic regression was performed to identify risk factors for occult uterine sarcomas, defined as no preoperative suspicion for malignancy. A risk prediction model was developed using a weighted logistic regression model, and the performance of the model was assessed using the receiver operator characteristic curve and corresponding area under the curve. A large integrated health care system in California PATIENTS: Women 18 years of age and older who underwent a hysterectomy and were diagnosed with a uterine sarcoma and matched controls from 2006 to 2013. None. There were 117 cases of occult uterine sarcomas that met inclusion criteria during the study period. The final risk prediction model included age, race/ethnicity, number of myomas, uterine weight, uterine size increase, degree of pelvic pain, and recent history of blood transfusion. The risk prediction model showed high accuracy based on the receiver operating characteristic curve method (area under the curve = 0.83; 95% confidence interval, 0.77-0.90); however, the positive predictive values were low (0.048 or less) at all risk thresholds. Multiple clinical features are associated with the presence of a uterine sarcoma, but when incorporated into a prediction model, they fail to provide significantly more information about women who may have an unrecognized sarcoma and only marginally improve the certainty about women who are not likely to have sarcoma. - Jun;27(4):930-937.e1. Epub 2019-07-25. Additive effects of blood donor smoking and gamma irradiation on outcome measures of red blood cell transfusion Recent publications have reported conflicting results regarding the role of blood donor tobacco use on hemoglobin (Hb) levels in patients after red blood cell (RBC) transfusion. We examined associations and interactions between donor, component, and recipient factors to better understand the impact of donor smoking on transfusion outcomes. We linked blood donor and component manufacturing data, including self-reported cigarette smoking, with a cohort of patients transfused RBCs between 2013 and 2016. Using multivariable regression, we examined Hb increments and subsequent transfusion requirements after single-unit RBC transfusion episodes, adjusting for donor, component, and recipient factors. We linked data on 4038 transfusion recipients who received one or more single-unit RBC transfusions (n = 5086 units) to donor demographic and component manufacturing characteristics. Among RBC units from smokers (n = 326), Hb increments were reduced after transfusion of gamma-irradiated units (0.76 g/dL; p = 0.033) but not unirradiated units (1.04 g/dL; p = 0.54) compared to those from nonsmokers (1.01 g/dL; n = 4760). In parallel with changes in Hb levels, donor smoking was associated with the receipt of additional RBC transfusions for irradiated (odds ratio [OR], 2.49; p = 0.01) but not unirradiated RBC units (OR, 1.10; p = 0.52). Donor smoking was associated with reduced Hb increments and the need for additional transfusions in recipients of gamma-irradiated RBC units. Additional research is needed to better understand interactions between donor, component, and recipient factors on efficacy measures of RBC transfusion. 2020 May 01. Exploiting nonsystematic covariate monitoring to broaden the scope of evidence about the causal effects of adaptive treatment strategies In studies based on electronic health records (EHR), the frequency of covariate monitoring can vary by covariate type, across patients, and over time, which can limit the generalizability of inferences about the effects of adaptive treatment strategies. In addition, monitoring is a health intervention in itself with costs and benefits, and stakeholders may be interested in the effect of monitoring when adopting adaptive treatment strategies. This paper demonstrates how to exploit nonsystematic covariate monitoring in EHR-based studies to both improve the generalizability of causal inferences and to evaluate the health impact of monitoring when evaluating adaptive treatment strategies. Using a real world, EHR-based, comparative effectiveness research (CER) study of patients with type II diabetes mellitus, we illustrate how the evaluation of joint dynamic treatment and static monitoring interventions can improve CER evidence and describe two alternate estimation approaches based on inverse probability weighting (IPW). First, we demonstrate the poor performance of the standard estimator of the effects of joint treatment-monitoring interventions, due to a large decrease in data support and concerns over finite-sample bias from near-violations of the positivity assumption (PA) for the monitoring process. Second, we detail an alternate IPW estimator using a no direct effect assumption. We demonstrate that this estimator can improve efficiency but at the potential cost of increase in bias from violations of the PA for the treatment process. Authors: MJ; Neugebauer R Biometrics. 2020 Apr 15. If Influenza Vaccines Wane Can We Delay Vaccination Without Compromising Coverage? Authors: Klein NP; Fireman B Clin Infect Dis. 2020 04 10;70(8):1560-1561. Cumulative Adherence to Secondary Prevention Guidelines and Mortality After Acute Myocardial Infarction Background The survival benefit associated with cumulative adherence to multiple clinical and lifestyle-related guideline recommendations for secondary prevention after acute myocardial infarction (AMI) is not well established. Methods and Results We examined adults with AMI (mean age 68 years; 64% men) surviving at least 30 (N=25 778) or 90 (N=24 200) days after discharge in a large integrated healthcare system in Northern California from 2008 to 2014. The association between all-cause death and adherence to 6 or 7 secondary prevention guideline recommendations including medical treatment (prescriptions for -blockers, renin-angiotensin-aldosterone system inhibitors, lipid medications, and antiplatelet medications), risk factor control (blood pressure <140/90 mm Hg and low-density lipoprotein cholesterol <100 mg/dL), and lifestyle approaches (not smoking) at 30 or 90 days after AMI was evaluated with Cox proportional hazard models. To allow patients time to achieve low-density lipoprotein cholesterol <100 mg/dL, this metric was examined only among those alive 90 days after AMI. Overall guideline adherence was high (35% and 34% met 5 or 6 guidelines at 30 days; and 31% and 23% met 6 or 7 at 90 days, respectively). Greater guideline adherence was independently associated with lower mortality (hazard ratio, 0.57 [95% CI, 0.49-0.66] for those meeting 7 and hazard ratio, 0.69 [95% CI, 0.61-0.78] for those meeting 6 guidelines versus 0 to 3 guidelines in 90-day models, with similar results in the 30-day models), with significantly lower mortality per each additional guideline recommendation achieved. Conclusions In a large community-based population, cumulative adherence to guideline-recommended medical therapy, risk factor control, and lifestyle changes after AMI was associated with improved long-term survival. Full adherence was associated with the greatest survival benefit. Authors: Solomon MD; Leong TK; 17;9(6):e014415. Epub 2020-03-05. Depletion of Susceptibles Bias in Analyses of Intra-season Waning of Influenza Vaccine Effectiveness Bias arises in studies of waning vaccine effectiveness when higher-risk individuals are depleted from the at-risk population at different rates between study groups. We examined how this bias arises and how to avoid it. A reanalysis of data from California confirmed a finding of intra-season waning of influenza vaccine effectiveness. Authors: Ray GT; Lewis Klein NP; Daley Association of immunosuppression and HIV viremia with anal cancer risk in persons living with HIV in the United States and Canada People living with human immunodeficiency virus (HIV; PLWH) have a markedly elevated anal cancer risk, largely due to loss of immunoregulatory control of oncogenic human papillomavirus infection. To better understand anal cancer development and prevention, we determined whether recent, past, cumulative, or nadir/peak CD4+ T-cell count (CD4) and/or HIV-1 RNA level (HIV RNA) best predict anal cancer risk. We studied 102 777 PLWH during 1996-2014 from 21 cohorts participating in the North American AIDS Cohort Collaboration on Research and Design. Using demographics-adjusted, cohort-stratified Cox models, we assessed associations between anal cancer risk and various time-updated CD4 and HIV RNA measures, including cumulative and nadir/peak measures during prespecified moving time windows. We compared models using the Akaike information criterion. Cumulative and nadir/peak CD4 or HIV RNA measures from approximately 8.5 to 4.5 years in the past were generally better predictors for anal cancer risk than their corresponding more recent measures. However, the best model included CD4 nadir (ie, the lowest CD4) from approximately 8.5 years to 6 months in the past (hazard ratio [HR] for <50 vs 500 cells/\u00b5L, 13.4; 95% proportion of time CD4 <200 cells/\u00b5L from approximately 8.5 to 4.5 years in the past (a cumulative measure; HR for 100% vs 0%, 3.1; 95% CI, 1.5-6.6). Our results are consistent with anal cancer promotion by severe, prolonged HIV-induced immunosuppression. Nadir and cumulative CD4 may represent useful markers for identifying PLWH at Silverberg MJ; North American AIDS Cohort Collaboration on Research and Design of the International Epidemiologic Databases to Evaluate AIDS; et al. Clin Infect Dis. 2020 03 03;70(6):1176-1185. Long-term Risk of Colorectal Cancer and Related Death After Adenoma Removal in a Large, Community-based Population The long-term risks of colorectal cancer (CRC) and CRC-related death following adenoma removal are uncertain. Data are needed to inform evidence-based surveillance guidelines, which vary in follow-up recommendations for some polyp types. Using data from a large, community-based integrated health care setting, we examined the risks of CRC and related death by baseline colonoscopy adenoma findings. Participants at 21 medical centers underwent baseline colonoscopies from 2004 through 2010; findings were categorized as no-adenoma, low-risk adenoma, or high-risk adenoma. Participants were followed until the earliest of CRC diagnosis, death, health plan disenrollment, or December 31, 2017. Risks of CRC and related deaths among the high- and low-risk adenoma groups were compared with the no-adenoma group using Cox regression adjusting for confounders. Among 186,046 patients, 64,422 met eligibility criteria age, 61.6 \u00b1 7.1 years; median follow-up time, 8.1 years from the baseline colonoscopy). Compared with the no-adenoma group (45,881 patients), the high-risk adenoma group (7563 patients) had a higher risk of CRC (hazard ratio [HR] 2.61; 95% confidence interval CI 1.90-6.56), whereas the low-risk adenoma group (10,978 patients) did not have a significant increase in risk of CRC (HR 1.29; 95% CI 0.89-1.88) or related death (HR 0.65; 95% CI 0.19-2.18). With up to 14 years of follow-up, high-risk adenomas were associated with an increased risk of CRC and related death, supporting early colonoscopy surveillance. Low-risk adenomas were not associated with a significantly increased risk of CRC or related deaths. These results can inform current surveillance guidelines for high- and low-risk adenomas. of Mortality between Untreated and Treated Papillary Thyroid Cancer: A Matched Cohort Analysis To examine the association between treatment status and mortality risk among patients with papillary thyroid cancer (PTC). We identified 3,679 adults with PTC. Thirty-one untreated patients were matched to 155 treated patients. Hazards ratios (HR) and 95% confidence intervals (CIs) were calculated to estimate all-cause and disease-specific mortality. A low-risk subgroup was analyzed for differences in all-cause mortality. The adjusted HRs (95% CIs) for all-cause mortality at 5 and 10 years were 4.2 (1.7-10.3) and 4.1 (1.9-9.4) and for disease- specific mortality were 14.1 (3.4-59.3) and 10.2 (2.9-36.4), respectively, for untreated versus treated patients. The adjusted HRs (95% CIs) for all- cause mortality was 0.7 (0.1-6.4) for low-risk untreated versus matched treated patients. Compared to treated patients, untreated PTC patients were at higher risk of death while low-risk untreated PTC patients had comparable rate of metastasis and no increased risk of all-cause mortality. Level Epub 2019-10-28. Exercise During the First Trimester and Infant Size at Birth: Targeted Maximum Likelihood Estimation of the Causal Risk Difference This cohort study sought to estimate the differences in risk of delivering infants who were small or large for gestational age (SGA or LGA, respectively) according to exercise during the first trimester of pregnancy (vs. no exercise) among 2,286 women receiving care at Kaiser Permanente Northern California in 2013-2017. Exercise was assessed by questionnaire. SGA and LGA were determined by the sex- and gestational-age-specific birthweight distributions of the 2017 US Natality file. Risk differences were estimated by targeted maximum likelihood estimation, with and without data-adaptive prediction (machine learning). Analyses were also stratified by prepregnancy weight status. Overall, exercise at the cohort-specific 75th percentile was associated with an increased risk of SGA of 4.5 (95% CI: 2.1, 6.8) per 100 births, and decreased risk of LGA of 2.8 (95% CI: 0.5, 5.1) per 100 births; similar findings were observed among the underweight and normal-weight women, but no associations were found among those with overweight or obesity. Meeting Physical Activity Guidelines was associated with increased risk of SGA and decreased risk of LGA but only among underweight and normal-weight women. Any vigorous exercise reduced the risk of LGA in underweight and normal-weight women only and was not associated with 2020 02 28;189(2):133-145. Learning to learn from data: Using deep adversarial learning to construct optimal statistical procedures Traditionally, statistical procedures have been derived via analytic calculations whose validity often relies on sample size growing to infinity. We use tools from deep learning to develop a new approach, adversarial Monte Carlo meta-learning, for constructing optimal statistical procedures. Statistical problems are framed as two-player games in which Nature adversarially selects a distribution that makes it difficult for a statistician to answer the scientific question using data drawn from this distribution. The players' strategies are parameterized via neural networks, and optimal play is learned by modifying the network weights over many repetitions of the game. Given sufficient computing time, the statistician's strategy is (nearly) optimal at the finite observed sample size, rather than in the hypothetical scenario where sample size grows to infinity. In numerical experiments and data examples, this approach performs favorably compared to standard practice in point estimation, individual-level predictions, and interval estimation. Authors: 2020-02-26. Association of Depression, Anxiety, and Epub 2020-02-05. Association of Mobile Patient Portal Access With Diabetes Medication Adherence and Glycemic Levels Among Adults With Diabetes Online patient portals support self-management, and mobile devices expand portal access, but whether this translates to improvements in diabetes outcomes is unclear. To examine the association of adding mobile patient portal access with diabetes medication adherence and glycemic levels among adults with diabetes. This retrospective cohort study included patients with diabetes treated at Kaiser Permanente Northern California, a large, integrated health care delivery system, from April 1, 2015, to December 31, 2017. Inclusion criteria were adults with diabetes with an oral diabetes prescription at baseline and no insulin use. Data were analyzed from March 2018 to March 2019. Patient portal access status for each calendar month from April 2015 to December 2017, categorized as never used, used from a computer only, used from a mobile device only, or used from both computer and mobile device. Medication adherence, measured by monthly percentage of days covered (PDC), and glycemic levels, measured by changes in glycated hemoglobin A1c (HbA1c) levels. The association of portal access with study outcomes was assessed using linear regression with patient-level fixed effects and adjusting for time-changing variables, stratified by baseline HbA1c level. Among 111 463 included patients (mean [SD] age, 63.79 [12.93] years; 59 918 [53.76%] men), the number of patients using the portal from both a computer and mobile device increased over time from 38 371 patients (34.42%) in April 2015 to 57 920 patients (61.71%) in December 2017. Among patients with no prior portal access, adding computer-only portal access was associated with an increase in PDC of 1.16 (95% CI, 0.63 to 1.70) percentage points and a change of -0.06 (95% CI, -0.08 to -0.03) percentage points in HbA1c level, and adding both mobile and computer portal access was associated with an increase in PDC of 1.67 (95% CI, 1.10 to 2.23) percentage points and a change of -0.13 (95% CI, -0.16 to -0.10) percentage points in HbA1c level. Among patients with higher baseline HbA1c level (>8.0%), changing from no portal access to both computer and mobile access was associated with an increase in PDC of 5.09 (95% CI, 3.78 to 6.40) percentage points and a change of -0.19 (95% CI, -0.27 to -0.15) percentage points in HbA1c level. These findings suggest that providing patients with computer patient portal access and combining it with mobile patient portal access are associated with significantly improved diabetes medication adherence and glycemic control, with greater benefits among patients with more clinical need. Convenient access to portal self-management tools through a mobile device could significantly improve diabetes management. Authors: Graetz I; Huang 2020 02 05;3(2):e1921429. Epub 2020-02-05. Life Expectancy of Insured People With and Without Hepatitis C Virus Infection, 2007-2017 Among 25 291 and 4 921 830 people with and without hepatitis C, life expectancy at age 20 increased 1.8 years and 0.3 years from the interferon to interferon-free era, respectively. Increases were highest for racial and/or ethnic minority groups with hepatitis C. Authors: Marcus JL; Lam JO; Quesenberry CP; Silverberg Feb;7(2):ofaa044. Epub 2020-02-05. Determinants of Oral Bisphosphonate Use Beyond 5 Years Few studies have examined factors that determine bisphosphonate (BP) continuation beyond 5 years in clinical practice. To investigate factors associated with BP continuation among women who completed 5 years of BP therapy. Women who received 5 consecutive years of oral BP treatment entered the cohort during 2002-2014 and were followed up to 5 additional years. Multivariable logistic regression was used to evaluate the association of demographic and clinical factors with adherent treatment continuation. The cohort included 19,091 women with a median age of 72 years. Baseline and time-varying factors associated with increased odds of BP continuation after 5 years were (a) most recent bone mineral density (BMD) T-score -2 to -2.4 (OR = 1.31, 95% CI 1.25-1.38), T-score -2.5 to -2.9 95% 1.39-1.57), and T-score -3.0 (OR = 1.57, 95% CI = 1.47-1.68) versus T-scores above -2.0; (b) index date before 2008 (OR =1.35, 95% CI = 1.29-1.41); and (c) diabetes mellitus (OR = 1.08, 95% CI = 1.01-1.16). In contrast, factors associated with decreased odds of BP continuation were (a) recent hip (OR = 0.61, 95% CI = 0.52-0.71) or humerus (OR = 0.79, 95% CI = 0.66-0.94) fracture or fracture other than hip, wrist, spine, or humerus (OR = 0.90, 95% CI = 0.84-0.97); (b) Charlson Comorbidity Index score > 2 (OR = 0.91, 95% CI = 0.84-0.98); (c) history of rheumatoid arthritis (OR = 0.89, 95% CI = 0.80-0.99); (d) Hispanic (OR = 0.89, 95% CI=0.85-0.94) or Asian (OR = 0.90, 95% CI = 0.85-0.94) race/ethnicity; and (e) use of proton pump inhibitors (OR = 0.65, 95% CI = 0.59-0.71). Patient age and fracture before BP initiation were not associated with treatment continuation. Clinical factors predicting continued BP treatment beyond 5 years include low BMD T-score, absence of recent fracture, and earlier era of treatment. Use of proton pump inhibitors was associated with lower likelihood of BP continuation. Other clinical and demographic factors were also noted to have variable effects on BP treatment continuation. This study was supported by a grant from the National Institute on Aging and National Institute of Arthritis, Musculoskeletal and Skin Diseases at the National Institutes of Health (NIH; R01AG047230, S1). The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH or Kaiser Permanente. Lo has received previous research funding from Amgen and Sanofi, unrelated to the current study. Adams has received previous research funding from Merck, Amgen, Otsuka, and Radius Health, unrelated to the current study. Ettinger has served as an expert witness for Teva Pharmaceuticals, unrelated to the current study. Ott previously attended a scientific advisory meeting for Amgen but declined the honorarium. The other authors have nothing to disclose. These data were presented at the 2018 Annual Meeting of the American Society of Bone and Mineral Research (ASBMR), September 28-October 1, 2018, Montreal, Quebec, Care Spec Pharm. 2020 Feb;26(2):197-202. Adjuvant endocrine therapy for breast cancer patients: impact of a health system outreach program to improve adherence Reports suggest that up to 50% of women with hormone receptor-positive (HR+) breast cancer (BC) do not complete the recommended 5 years of adjuvant endocrine therapy (AET). We examined the impact of an outreach program at Kaiser Permanente Northern California (KPNC) on adherence and discontinuation of AET among patients who initiated AET. We assembled a retrospective cohort of all KPNC patients diagnosed with HR+, stage I-III BC initiating AET before (n = 4287) and after (n = 3580) implementation of the outreach program. We compared adherence proportions and discontinuation rates before and after program implementation, both crude and adjusted for age, race/ethnicity, education, income, and stage. We conducted a pooled analysis of data from six Cancer Research Network (CRN) sites that had not implemented programs for improving AET adherence, using identical methods and time periods, to assess possible secular trends. In the pre-outreach period, estimated adherence in years 1, 2, and 3 following AET initiation was 75.2%, 71.0%, and 67.3%; following the outreach program, the estimates 79.4%, 75.6%, and 72.2% (p-values < .0001 for pairwise comparisons). Results were comparable after adjusting for clinical and demographic factors. The estimated cumulative incidence of discontinuation was 0.22 (0.21-0.24) and 0.18 (0.17-0.19) at 3 years for pre- and post-outreach groups (p-value < .0001). We found no evidence of an increase in adherence between the study periods at the CRN sites with no AET adherence program. Adherence and discontinuation after AET initiation improved modestly following implementation of the outreach program. 2020 Epub 2020-01-23. Body Composition, Adherence to Anthracycline and Taxane-Based Chemotherapy, and Survival After Nonmetastatic Breast Cancer Although most chemotherapies are dosed on body surface area or weight, body composition (ie, the amount and distribution of muscle and adipose tissues) is thought to be associated with chemotherapy tolerance and adherence. To evaluate whether body composition is associated with relative dose intensity (RDI) on anthracycline and taxane-based chemotherapy or hematologic toxic effects and whether lower RDI mediates the association of adiposity with mortality. An observational cohort study with prospectively collected electronic medical record data was conducted at Kaiser Permanente Northern California, a multicenter, community oncology setting within an integrated health care delivery system. Participants included 1395 patients with nonmetastatic breast cancer diagnosed between January 1, 2005, and December 31, 2013, and treated with anthracycline and taxane-based chemotherapy. Data analysis was performed between February 25 and September 4, 2019. Intramuscular, visceral, and subcutaneous adiposity as well as skeletal muscle were evaluated from clinically acquired computed tomographic scans at diagnosis. The primary outcome was low RDI (<0.85), which is the ratio of delivered to planned chemotherapy dose, derived from infusion records; in addition, hematologic toxic effects were defined based on laboratory test values. To evaluate associations with overall and breast cancer-specific mortality, logistic regression models adjusted for age and body surface area were fit as well as Cox proportional hazards models adjusted for age, race/ethnicity, adiposity, Charlson comorbidity index score, and tumor stage and subtype. The mediation proportion was computed using the difference method. The mean (SD) age at diagnosis of the 1395 women included in the study was 52.8 (10.2) years. Greater visceral (odds ratio [OR], 1.19; 95% CI, 1.01-1.34 per SD) adiposity were associated with increased odds of RDI less than 0.85. Greater muscle mass was associated with a decreased odds of hematologic toxic effects (OR, 0.84; 95% CI, 0.71-0.98 per SD). Relative dose intensity less than 0.85 was associated with a 30% increased risk of death (hazard ratio, 1.30; 95% CI, 1.02-1.65). Lower RDI partially explained the association of adiposity with breast cancer-specific mortality (mediation proportion, 0.20; 95% CI, Excess adiposity, presenting as larger visceral or intramuscular adiposity, was associated with lower RDI. Lower RDI partially mediated the association of adiposity with worse breast cancer-specific survival. Body composition may help to identify patients likely to experience toxic effects and subsequent dose delays or reductions, which could compromise chemotherapeutic efficacy. 01;6(2):264-270. Comparison of Mortality and Major Cardiovascular Events Among Adults With Type 2 Diabetes Using Human vs Analogue Insulins The comparative cardiovascular safety of analogue and human insulins in adults with type 2 diabetes who initiate insulin therapy in usual care settings has not been carefully evaluated using machine learning and other rigorous analytic methods. To examine the association of analogue vs human insulin use with mortality and major cardiovascular events. This retrospective cohort study included 127 600 adults aged 21 to 89 years with type 2 diabetes at 4 health care delivery systems who initiated insulin therapy from January 1, 2000, through December 31, 2013. Machine learning and rigorous inference methods with time-varying exposures were used to evaluate associations of continuous exposure to analogue vs human insulins with mortality and major cardiovascular events. Data were analyzed from September 1, 2017, through June 30, 2018. On the index date (first insulin dispensing), participants were classified as using analogue insulin with or without human insulin or human insulin only. Overall mortality, mortality due to cardiovascular disease (CVD), myocardial infarction (MI), stroke or cerebrovascular accident (CVA), and hospitalization for congestive heart failure (CHF) were evaluated. Marginal structural modeling (MSM) with inverse probability weighting was used to compare event-free survival in separate per-protocol analyses. Adjusted and unadjusted hazard ratios and cumulative risk differences were based on logistic MSM parameterizations for counterfactual hazards. Propensity scores were estimated using a data-adaptive approach (machine learning) based on 3 nested covariate adjustment sets. Sensitivity analyses were conducted to address potential residual confounding from unmeasured differences in risk factors across delivery systems. The 127 600 participants (mean [SD] age, 59.4 [12.6] years; 68 index, 32.3 [7.1]) had a median follow-up of 4 quarters (interquartile range, 3-9 quarters) and (2.4%). There were no differences in adjusted hazard ratios for continuous analogue vs human insulin exposure during 10 quarters for overall mortality (1.15; 95% CI, 0.75-1.11). Insulin-naive adults with type 2 diabetes who initiate and continue treatment with human vs analogue insulins had similar observed rates of major cardiovascular events, CVD mortality, and overall mortality. Authors: Vaccine effectiveness of cell-culture relative to egg-based inactivated influenza vaccine during the 2017-18 influenza season There is concern that influenza vaccine effectiveness (VE) may be attenuated by passage in eggs during manufacture. We compared quadrivalent cell-culture vaccine with egg-based vaccines, most of which were trivalent, against influenza A and B during 2017-2018 when A(H3N2) and B/Yamagata (present only in quadrivalent vaccines) predominated. We retrospectively examined risk of PCR-confirmed influenza A and B in members of Kaiser Permanente Northern California aged 4-64 years. We estimated the relative VE (rVE) of cell-culture vaccine versus egg-based vaccines, and the absolute VE (aVE) of each vaccine comparing vaccinated to unvaccinated individuals. Analyses used Cox regression with a calendar timeline, stratified by birth year, and adjusted for demographics, co-morbidities and utilization. One-third (1,016,965/3,053,248) of the population was egg-based and 84,420 (8.3%) The against influenza A 8.0% (95% CI: -10, 23); and 20.1% (CI: 14.5, 25.4) for egg-based vaccines. The rVE against influenza B was 39.6% (CI: 27.9, 49.3); aVE was 40.9% (CI: 30, and 9.7% (CI 3.5, 15.6) for egg-based trivalent vaccines. Inclusion of the B/Yamagata lineage in the quadrivalent cell-based vaccine provided better protection against influenza B but vaccine effectiveness against influenza A was low for both the cell-culture vaccine and the egg-based vaccines. Improving influenza vaccines requires ongoing comparative vaccine effectiveness monitoring. Authors: Klein NP; One. 2020;15(2):e0229279. Epub 2020-02-26. Identifying hypertension in pregnancy using electronic medical records: The importance of blood pressure values To incorporate blood pressure (BP), diagnoses codes, and medication fills from electronic medical records (EMR) to identify pregnant women with hypertension. A retrospective cohort study of singleton pregnancies at three US integrated health delivery systems during 2005-2014. Women were considered hypertensive if they had any of the following: (1) 2 high BPs (140/90 mmHg) within 30 days during pregnancy (High BP); (2) an antihypertensive medication fill in the 120 days before pregnancy and a hypertension diagnosis from 1 year prior to pregnancy through 20 weeks gestation (Treated Chronic Hypertension); or (3) a high BP, a hypertension diagnosis, and a prescription fill within 7 days during pregnancy (Rapid Treatment). We described characteristics of these pregnancies and conducted medical record review to understand hypertension presence and severity. Of 566,624 pregnancies, 27,049 (4.8%) met our hypertension case definition: 24,140 (89.2%) with High BP, 5,409 (20.0%) with Treated Chronic Hypertension, and 5,363 (19.8%) with Rapid Treatment (not mutually exclusive). Of hypertensive pregnancies, 19,298 (71.3%) received a diagnosis, 9,762 (36.1%) received treatment and 11,226 (41.5%) had a BP 160/110. In a random sample (n = 55) of the 7,559 pregnancies meeting the High BP criterion with no hypertension diagnosis, clinical statements about hypertension were found in medical records for 58% of them. Incorporating EMR BP identified many pregnant women with hypertension who would have been missed by using diagnosis codes alone. Future studies should seek to incorporate BP to study treatment and outcomes of hypertension in pregnancy. Authors: Epub 2020-01-03. Use of Time-Dependent Propensity Scores to Adjust Hazard Ratio Estimates in Cohort Studies with Differential Depletion of Susceptibles Estimating hazard ratios (HR) presents challenges for propensity score (PS)-based analyses of cohorts with differential depletion of susceptibles. When the treatment effect is not null, cohorts that were balanced at baseline tend to become unbalanced on baseline characteristics over time as \"susceptible\" individuals drop out of the population at risk differentially across treatment groups due to having outcome events. This imbalance in baseline covariates causes marginal (population-averaged) HRs to diverge from conditional (covariate-adjusted) HRs over time and systematically move toward the null. Methods that condition on a baseline PS yield HR estimates that fall between the marginal and conditional HRs when these diverge. Unconditional methods that match on the PS or weight by a function of the PS can estimate the marginal HR consistently but are prone to misinterpretation when the marginal HR diverges toward the null. Here, we present results from a series of simulations to help analysts gain insight on these issues. We propose a novel approach that uses time-dependent PSs to consistently estimate conditional HRs, regardless of whether susceptibles have been depleted differentially. Simulations show that adjustment for time-dependent PSs can adjust for covariate imbalances over time that are caused by depletion of susceptibles. Updating the PS is unnecessary when outcome incidence is so low that depletion of susceptibles is negligible. But if incidence is high, and covariates and treatment affect risk, then covariate imbalances arise as susceptibles are depleted, and PS-based methods can consistently estimate the conditional HR only if the PS is periodically updated. Authors: Wyss R; Fireman B; et al. Epidemiology. 2020 01;31(1):82-89. Outcomes of Robotic Hysterectomy for Treatment of Benign Conditions: Influence of Patient Complexity Robotic hysterectomy may offer advantages for complex cases over the conventional laparoscopic approach. To assess the association of surgical approach (robotic vs conventional) with blood loss, risks of readmission, reoperation, complications, and average operative time. In a retrospective cohort study, we used the electronic medical records of Kaiser Permanente Northern California, 2011 to 2015, to estimate outcomes of robotic and conventional laparoscopic hysterectomy among women with complex or noncomplex benign disease. Mixed-effects regression models accounted for patient characteristics and surgeon volume. The study included 560 robotic and 6785 conventional laparoscopic cases. Overall, 1836 patients (25%) met criteria for being complex. The average operative time was 152 minutes for robotic hysterectomy and 157 minutes for conventional laparoscopic hysterectomy (p < 0.0001). Complex surgical cases averaged 190 minutes and noncomplex cases averaged 144 minutes. The difference in operative time for high-volume surgeons treating complex patients with robotic hysterectomy vs conventional hysterectomy was 21 minutes faster (p < 0.05). After adjustment, the risk of blood loss at least 51 mL was lower for robotic surgery than for conventional surgery for complex and noncomplex patients. Other than risk of urinary tract complications, we observed no differences in the risks of complications or risk of reoperation between robotic and conventional laparoscopy for complex and noncomplex patients. For women with complex disease, the robotic approach, when used by a higher-volume surgeon, may be associated with shorter operative time and slightly less blood loss, but not with lower risk of complications. Authors: Changes in Prostate Cancer Presentation Following the 2012 USPSTF Screening Statement: Observational Study in a Multispecialty Group Practice In 2012, the US Preventive Services Task Force (USPSTF) recommended against PSA-based screening for prostate cancer in men of all ages. Following this change, screening declined yet the complete impact on clinical presentation is not well defined in the screen-eligible population. To determine if the rates of PSA screening, prostate biopsy, incident prostate cancer detection, and stage IV at presentation in screen-eligible men in Kaiser Permanente Northern California changed following the 2012 USPSTF Prostate Cancer Screening recommendations. Retrospective study spanning the years 2010 to 2015, in screen-eligible Kaiser Permanente Northern California members (African American men ages 45-69 and all other men ages 50-69) with no prior history of prostate cancer. Participants All screen-eligible, male members during 2010 (n = 403,931) to 2015 (n = 483,286) without a history of prostate cancer within all Kaiser Permanente Northern California facilities. Annual rates of PSA testing, prostate biopsy, incident prostate cancer detection, and stage IV cancer at presentation were compared between the pre-guideline period, 2010 and 2011, and the post-guideline period, 2014 and 2015, in men under the age of 70. Following the 2012 USPSTF guideline change, screening rates declined 23.4% (95% CI 23.0-23.8%), biopsy rates declined 64.3% (95% CI and incident prostate cancer detection rates declined 53.5% (95% CI 50.1-56.7%) resulting in 1871 fewer incident cancers detected, and metastatic cancer rates increased 36.9% (95% CI 9.5-71.0%) resulting in 75 more stage IV cancers detected. Less screening resulted in a large decrease in cancer detection, some of which may be beneficial as many cancers may be indolent, yet this decrease occurred at the expense of an increase in metastatic cancer rates. For every 25 fewer cancers detected, one metastatic cancer was diagnosed. This information may be valuable in the shared decision-making process around prostate cancer J Gen Intern Med. 2019 Dec 09. Effect of Sex, Age and Positivity Threshold on Fecal Immunochemical Test Accuracy: a Systematic Review and Meta-Analysis Quantitative fecal immunochemical tests (FITs) for hemoglobin are commonly used for colorectal cancer (CRC) screening. We aimed to quantify the change in CRC and advanced adenoma detection and number of positive test results at different positivity thresholds and by sex and age. We searched MEDLINE and EMBASE, selecting articles of FIT for CRC detection in asymptomatic adults undergoing screening. We calculated sensitivity and specificity, as well as detected number of cancers, advanced adenomas, and positive test results at positivity thresholds 10 g hemoglobin/g feces, 10 to 20 g/g, 20 to 30 g/g, and >30 g/g. We also analyzed results from stratified by patient sex, age, and reference standard. Our meta-analysis comprised 46 studies with 2.4 million participants and 6478 detected cancers. Sensitivity for detection of CRC increased from (95% confidence at thresholds 10 g/g. At these threshold values, sensitivity for detection of advanced adenomas increased from 21% (95% CI, 18%-25%) to 93%-96%) to 91% (95% CI, 89%-93%). In 3 studies stratified by sex, sensitivity of CRC detection was 77% in men (95% CI, 75%-79%) and 81% in women (95% CI, 60%-100%) (P = .68). In 3 studies stratified by age groups, sensitivity of CRC detection was 85% for ages 50-59 years (95% CI, and 73% for ages 60-69 years (95% CI, 71%-75%) (P = .10). All studies with colonoscopy follow-up had similar sensitivity levels for detection of CRC to studies that analyzed 2-year registry follow-up CI, 73%-77%). In a meta-analysis of studies that analyzed detection of CRC and advanced adenomas at different FIT positivity thresholds, we found the sensitivity and specificity of detection to vary with positive cutoff value. It might be possible to decrease positive threshold values for centers with sufficient follow-up colonoscopy resources. More research is needed to precisely establish FIT thresholds for each sex and age 2019-08-22. A primer on quantitative bias analysis with positive predictive values in research using electronic health data In health informatics, there have been concerns with reuse of electronic health data for research, including potential bias from incorrect or incomplete outcome ascertainment. In this tutorial, we provide a concise review of predictive value-based quantitative bias analysis (QBA), which comprises epidemiologic methods that use estimates of data quality accuracy to quantify the bias caused by outcome misclassification. Health informaticians and investigators reusing large, electronic health data sources for research. When electronic health data are reused for research, validation of outcome case definitions is recommended, and positive predictive values (PPVs) are the most commonly reported measure. Typically, case definitions with high PPVs are considered to be appropriate for use in research. However, in some studies, even small amounts of misclassification can cause bias. In this tutorial, we introduce methods for quantifying this bias that use predictive values as inputs. Using epidemiologic principles and examples, we first describe how multiple factors influence misclassification bias, including outcome misclassification levels, outcome prevalence, and whether outcome misclassification levels are the same or different by exposure. We then review 2 predictive value-based QBA methods and why outcome PPVs should be stratified by exposure for bias assessment. Using simulations, we apply and evaluate the methods in hypothetical electronic health record-based immunization schedule safety studies. By providing an overview of predictive value-based QBA, we hope to bridge the disciplines of health informatics and epidemiology to inform how the impact of data quality issues can be quantified in research using electronic health data sources. Authors: Newcomer SR; Med Inform Assoc. 2019 12 01;26(12):1664-1674. Risk Estimates for Diabetes and Hypertension with Different Physical Activity Methods To estimate risks of incident type 2 diabetes (T2D) and stage 2 and greater hypertension associated with self-reported and accelerometer-determined moderate-vigorous physical activity (MVPA) separately and adjusted for each other. The sample included 2291 black and white men and women, ages 38-50 yr, in the Coronary Artery Risk Development in Young Adults (CARDIA) fitness study, conducted during the year 20 core CARDIA examination. Accelerometer-determined (Actigraph, LLC. model 7164) MVPA (MVPA-Acc), assessed at year 20, was defined as minutes per day of counts 2020 min. Self-reported MVPA (MVPA-SR) was assessed at year 20 using the CARDIA Physical Activity History. Incident T2D was ascertained at years 25 and 30 from fasting glucose, 2 h glucose tolerance test, HbA1c, or diabetes medication; incident hypertension was ascertained at those same times from measured blood pressure or use of antihypertensive medications. Modified Poisson regression models estimated relative risk (RR) of incident (years 25 and 30) T2D or hypertension, associated with middle and high tertiles of year 20 MVPA-Acc alone, year 20 MVPA-SR alone, and both, adjusted for each other, relative to bottom tertile. In men, MVPA-Acc, but not MVPA-SR, was associated with a 37% to 67% decreased risk of incident T2D in a dose-response relation that persisted with adjustment for BMI, Similar associations were observed in women, although the risk reduction was similar in the second and third tertiles, relative to the bottom tertile. In both men and women, MVPA-Acc was marginally associated with reduced risk of incident stage 2 and greater hypertension, but only after adjustment for BMI, whereas MVPA-SR was not associated in either sex. Accelerometer-determined MVPA may provide more consistent risk estimates for incident diabetes than self-reported Sports 2019 12;51(12):2498-2505. Depletion-of-susceptibles bias in influenza vaccine waning studies: how to ensure robust results Vaccine effectiveness studies are subject to biases due to depletion-of-persons at risk of infection, or at especially high risk of infection, at different rates from different groups (depletion-of-susceptibles bias), a problem that can also lead to biased estimates of waning effectiveness, including spurious inference of waning when none exists. An alternative study design to identify waning is to study only vaccinated persons, and compare for each day the incidence in persons with earlier or later dates of vaccination to assess waning in vaccine protection as a function of vaccination time (namely whether earlier vaccination would result in lower subsequent protection compared to later vaccination). Prior studies suggested under what conditions this alternative would yield correct estimates of waning. Here we define the depletion-of-susceptibles process formally and show mathematically that for influenza vaccine waning studies, a randomised trial or corresponding observational study that compares incidence at a specific calendar time among individuals vaccinated at different times before the influenza season begins will not be vulnerable to depletion-of-susceptibles bias in its inference of waning as a function of vaccination time under the null hypothesis that none exists, and will - if waning does actually occur - underestimate the extent of waning. Such a design is thus robust in the sense that a finding of waning in that inference framework reflects actual waning of vaccine-induced immunity. We recommend such a design for future studies of waning, whether observational or randomised. Authors: Lipsitch M; Goldstein E; 2019-11-27. Haloperidol and Prostate Prevention: The antipsychotic drug haloperidol has antiproliferative and growth-inhibiting properties on prostate cancer cell lines in vitro by binding the sigma 1 protein. Evidence is needed regarding a possible preventive association in men. To examine whether our epidemiologic data support an inverse association of haloperidol use with risk of prostate cancer. These case-control analyses used conditional logistic regression to estimate relative risk by odds ratios (ORs) adjusting for race/ethnicity and aspects of medical care related to detection of prostate cancer. We tested 3 other commonly used antipsychotic drugs, risperidone, quetiapine, and olanzapine, for sigma 1 protein binding and inhibition of clonogenic growth of prostate cancer cells. Use of any of these by men was considered use of a comparator drug. 1) association of haloperidol with prostate cancer; 2) sigma 1 binding and clonogenic growth. Probably owing to small numbers of haloperidol recipients, evidence of a preventive association was inconsistent, depending on the definition of long-term use. If duration of use was greater than 1 year, the odds ratio (OR) was 0.38 (95% confidence interval (CI) = 0.14-1.01) for haloperidol and 0.80 (95% CI = 0.66-0.98) for the comparator drug; if the duration of use was greater than 2 years, the OR was 0.66 (95% CI = 0.24-1.76) for haloperidol and 0.84 (95% 0.66-1.08) comparator drug. Unlike haloperidol, risperidone, quetiapine, and olanzapine did not bind sigma 1 or inhibit clonogenic growth. Given the laboratory evidence, our ambiguous epidemiologic findings should encourage more epidemiologic evaluation of haloperidol use and risk of prostate cancer. Finding a negative association could be a scientific advance in prostate cancer prevention but would not be sufficient basis for recommending the prescription of haloperidol for that purpose. 2019-11-22. Validity of Self-reported Cannabis Use Among Pregnant Females in Northern California Most clinical and epidemiologic estimates of prenatal cannabis use are based on self-report, and the validity of self-reported cannabis use has not been examined in a large, representative population of pregnant women. We determined the validity of self-reported prenatal cannabis use and predictors of nondisclosure using data from Kaiser Permanente Northern California's (KPNC) healthcare system with universal prenatal cannabis screening during prenatal care. Validation study using data from 281,025 pregnancies in KPNC among females aged 11 years who completed a self-administered questionnaire on prenatal cannabis use and a cannabis urine toxicology test from 2009 to 2017. We calculated sensitivity, specificity, positive predictive value, and negative predictive value of self-reported prenatal cannabis use using urine toxicology testing as the criterion standard, and sensitivity of urine toxicology testing using self-reported use as the criterion standard. We compared sociodemographics of those who disclosed versus did not disclose prenatal cannabis use. Urine toxicology testing identified more instances of prenatal cannabis use than self-report (4.9% vs 2.5%). Sensitivity of self-reported use was low (33.9%). Sensitivity of the toxicology test was higher (65.8%), with greater detection of self-reported daily (83.9%) and weekly (77.4%) than monthly or less use (54.1%). Older women, those of Hispanic race/ethnicity, and those with lower median neighborhood incomes were most likely to be misclassified as not using cannabis by self-reported screening. Given that many women choose not to disclose prenatal cannabis use, clinicians should educate all prenatal patients about the potential risks and advise them to quit cannabis use during Alexeeff S J Addict Med. 2019 Nov 04. Association of donor age, body mass index, hemoglobin, and smoking status with in-hospital mortality and length of stay among red blood cell-transfused recipients Recent publications have reported conflicting findings regarding associations of blood donor demographics and mortality of transfused patients. We hypothesized that the analysis of additional donor characteristics and consideration of alternative outcomes might provide insight into these disparate results. We analyzed data from a retrospective cohort of transfused patients from the Recipient Epidemiology and Donor Evaluation Study-III (REDS-III). We used stratified Cox regression models to estimate associations between blood donor characteristics and hospital mortality and posttransfusion length of stay among patients transfused red blood cell (RBC) units. Donor characteristics evaluated included age, body mass index, hemoglobin levels, and smoking status. The statistical analyses were adjusted for recipient factors, including total number of transfusions. We studied 93,726 patients in 130,381 hospitalizations during which 428,461 RBC units were transfused. There were no associations between blood donor characteristics and hospital mortality. Receipt of RBC units from donors less than 20 years of age was associated with a shorter hospital length of stay (hazard ratio for discharge per transfused unit, 1.03; 95% confidence interval, 1.02-1.04; p < 0.001) but not for other donor characteristics. We found no evidence of associations between blood donor factors and in-hospital mortality. Our finding of shorter hospital length of stay in patients transfused RBCs from younger donors is intriguing but requires confirmation. Future collaborations are needed to develop a framework of appropriate methodologic approaches to be used in linked analyses across large cohorts. Authors: Roubinian NH; Lee C; NHLBI Recipient Epidemiology and (REDS-III); et al. Transfusion. 2019 11;59(11):3362-3370. Epub 2019-10-11. Comparative Effectiveness Study of Face-to-Face and Teledermatology Workflows for Diagnosing Skin Cancer The effectiveness and value of teledermatology and face-to-face workflows for diagnosing lesions are not adequately understood. We compared the risks of biopsy and cancer diagnosis among 2 face-to-face workflows (direct referral and roving dermatologist) and 4 teledermatology workflows. Retrospective study of 59,279 primary care patients presenting with a lesion from January through June 2017. One teledermatology workflow achieved high-resolution images with use of a dermatoscope-fitted digital camera, a picture archiving and communication system, and image retrieval to a large computer monitor (in contrast to a smartphone screen). Compared with direct referral, this workflow was associated with a 9% greater probability of cancer detection (95% confidence interval [CI], 2%-16%), a 4% lower probability 95% CI, and 0.61; 95% CI, 0.57-0.65). workflows were less effective. Differing proficiencies across teledermatology workflows and selection of patients for direct referral could have caused bias. Implementation is critical to the effectiveness of Adipose Tissue Distribution and Cardiovascular Disease Risk Among Breast Cancer Survivors Cardiovascular disease (CVD) is a major source of morbidity and mortality among breast cancer survivors. Although body mass index (BMI) is associated with CVD risk, adipose tissue distribution may better identify patients with a high risk of CVD after breast cancer. Among 2,943 patients with nonmetastatic breast cancer without prior CVD, we used International Classification of Diseases (9th and 10th revisions) codes to identify incidence of nonfatal stroke, myocardial infarction, heart failure, or CVD death. From clinically acquired computed tomography scans obtained near diagnosis, we measured visceral adiposity squared), subcutaneous adiposity (centimeters squared), and (fatty infiltration into muscle [Hounsfield Units, scored inversely]). We estimated hazard ratios (HRs) and 95% CIs per SD increase in adiposity accounting for competing risks and adjusting for demographics, smoking, cancer treatment, and pre-existing CVD risk factors. Mean (SD) age was 56 (12) years. Over a median follow-up of 6 years, 328 CVD events occurred. Each SD increase in visceral or intramuscular adiposity was associated with an increase in CVD risk (HR, 1.15 [95% CI, 1.03 to 1.29] and HR, 1.21 [95% CI, 1.06 to 1.37]), respectively). Excess visceral and intramuscular adiposity occurred across all BMI categories. Among normal-weight patients, each SD greater visceral adiposity increased CVD risk by 70% (HR, 1.10 to 2.62]). Visceral and intramuscular adiposity were associated with increased CVD incidence after breast cancer diagnosis, independent of pre-existing CVD risk factors and cancer treatments. The increased CVD incidence among normal-weight patients with greater visceral adiposity would go undetected with BMI alone. Measures of adipose tissue distribution may help identify high-risk patients and tailor CVD prevention Epub 2019-08-01. Use of electronic health record data and machine learning to identify candidates for HIV pre-exposure prophylaxis: a modelling study The limitations of existing HIV risk prediction tools are a barrier to implementation of pre-exposure prophylaxis (PrEP). We developed and validated an HIV prediction model to identify potential PrEP candidates in a large health-care system. Our study population was HIV-uninfected adult members of Kaiser Permanente Northern California, a large integrated health-care system, who were not yet using PrEP and had at least 2 years of previous health plan enrolment with at least one outpatient visit from Jan 1, 2007, to Dec 31, 2017. Using 81 electronic health record (EHR) variables, we applied least absolute shrinkage and selection operator (LASSO) regression to predict incident HIV diagnosis within 3 years on a subset of patients who entered the cohort in 2007-14 (development dataset), assessing ten-fold cross-validated area under the receiver operating characteristic curve (AUC) and 95% CIs. We compared the full model to simpler models including only men who have sex with men (MSM) status and sexually transmitted infection (STI) positivity, testing, and treatment. Models were validated prospectively with data from an independent set of patients who entered the cohort in 2015-17. We computed predicted probabilities of incident HIV diagnosis within 3 years (risk scores), categorised as low risk (<0\u00b705%), moderate risk (0\u00b705% to <0\u00b720%), high risk (0\u00b720% to <1\u00b70%), and very high risk (1\u00b70%), for all patients in the validation dataset. Of 3 750 664 patients in 2007-17 (3 143 963 in the development dataset and 606 701 in the validation dataset), there were 784 incident HIV cases within 3 years of baseline. The LASSO procedure retained 44 predictors in the full model, with an AUC of 0\u00b786 (95% CI 0\u00b785-0\u00b787) for incident HIV cases in 2007-14. Model performance remained high in the validation dataset (AUC 0\u00b784, 0\u00b780-0\u00b789). The full model outperformed simpler models including only MSM status and STI positivity. For the full model, flagging 13 463 (2\u00b72%) patients with high or very high HIV risk scores in the validation dataset identified 32 (38\u00b76%) of the 83 incident HIV cases, including 32 (46\u00b74%) of 69 male cases and none of the 14 female cases. The full model had equivalent sensitivity by race whereas simpler models identified fewer black than white HIV cases. Prediction models using EHR data can identify patients at high risk of HIV acquisition who could benefit from PrEP. Future studies should optimise EHR-based HIV risk prediction tools and evaluate their effect on prescription of PrEP. Kaiser Permanente Community Benefit Research Program and the US National Institutes of Health. Authors: 10;6(10):e688-e695. Epub 2019-07-05. Effect of donor, component and recipient characteristics on hemoglobin increments following red blood cell transfusion Significant research has focused individually on blood donors, product preparation and storage, and optimal transfusion practice. To better understand the interplay between these factors on measures of red blood cell (RBC) transfusion efficacy, we conducted a linked analysis of blood donor and component data with patients who received single-unit RBC transfusions between 2008 and 2016. Hemoglobin levels before and after RBC transfusions and at 24- and 48-hour intervals after transfusion were analyzed. Generalized estimating equation linear regression models were fit to examine hemoglobin increments after RBC transfusion adjusting for donor and recipient demographic characteristics, collection method, additive solution, gamma irradiation, and storage duration. We linked data on 23?194 transfusion recipients who received one or more single-unit RBC transfusions (n = 38?019 units) to donor demographic and component characteristics. Donor and recipient sex, Rh-D status, collection method, gamma irradiation, recipient age and body mass index, and pretransfusion hemoglobin levels were significant predictors of hemoglobin increments in univariate and multivariable analyses (P < .01). For hemoglobin increments 24 hours after transfusion, the coefficient of determination for the generalized estimating equation models was 0.25, with an estimated correlation between actual and predicted values of 0.5. Collectively, blood donor demographic characteristics, collection and processing methods, and recipient characteristics accounted for significant variation in hemoglobin increments related to RBC transfusion. Multivariable modeling allows the prediction of changes in hemoglobin using donor-, component-, and patient-level characteristics. Accounting for these factors will be critical for future analyses of donor and component factors, including genetic polymorphisms, on posttransfusion increments and other patient outcomes. Blood. 2019 09 26;134(13):1003-1013. Epub 2019-07-26. Enhanced Recovery After Surgery to Change Process Measures and Reduce Opioid Use After Cesarean Delivery: A Quality Improvement Initiative To evaluate implementation of an enhanced recovery after surgery (ERAS) program for patients undergoing elective cesarean delivery by comparing opioid exposure, multimodal analgesia use, and other process and outcome measures before and after implementation. An ERAS program was implemented among patients undergoing elective cesarean delivery in a large integrated health care delivery system. We conducted a pre-post study of ERAS implementation to compare changes in process and outcome measures during the 12 months before and 12 months after implementation. The study included 4,689 patients who underwent an elective cesarean delivery in the 12 months before (pilot sites: March 1, 2015-February 29, 2016, all other sites: October 1, 2015-September 30, 2016), and 4,624 patients in the 12 months after (pilot sites: April 1, 2016-March 31, 2017, all other sites: November 1, 2016-October 31, ERAS program implementation. After ERAS implementation mean inpatient opioid exposure (average daily morphine equivalents) decreased from 10.7 equivalents (95% CI 10.2-11.3) to 5.4 equivalents (95% CI 4.8-5.9) controlling for age, race-ethnicity, prepregnancy body mass index, patient reported pain score, and medical center. The use of multimodal analgesia (ie, acetaminophen and neuraxial anesthesia) increased from 9.7% to 88.8%, the adjusted risk ratio (RR) for meeting multimodal analgesic goals was 9.13 (RR comparing post-ERAS with pre-ERAS; 95% CI 8.35-10.0) and the proportion of time patients reported acceptable pain scores increased from 82.1% to 86.4% (P<.001). Outpatient opioids dispensed at hospital discharge decreased from 85.9% to 82.2% post-ERAS (P<.001) and the average number of dispensed pills decreased from 38 to 26 (P<.001). The hours to first postsurgical ambulation decreased by 2.7 hours (95% CI -3.1 to -2.4) and the hours to first postsurgical solid intake decreased by 11.1 hours (95% CI -11.5 to -10.7). There were no significant changes in hospital length of stay, surgical site infections, hospital readmissions, or breastfeeding rates. Implementation of an ERAS program in patients undergoing elective cesarean delivery was associated with a reduction in opioid inpatient and outpatient exposure and with changes in surgical process measures of care without worsened surgical outcomes. Authors: Hedderson M; 2019 09;134(3):511-519. Depot Medroxyprogesterone Acetate, Oral Contraceptive, Intrauterine Device Use, and Fracture Risk To assess fracture risk among women with depot medroxyprogesterone acetate (DMPA), oral contraceptive pill (OCP), and intrauterine device (IUD) use. A retrospective cohort study of 308,876 women age 12-45 years who initiated DMPA, combined or progestin-only OCPs, and copper and levonorgestrel IUDs from 2005 to 2015. Cumulative DMPA, OCP, and IUD use was assessed. Time since last DMPA injection was quantified as recent (within 2 years) and past (more than 2 years ago). Crude fracture rate was estimated using a Poisson distribution. Unadjusted and adjusted hazard ratios (HRs) were estimated using cox proportional hazards models. Thirteen percent of women used DMPA, in 1,391,251 person-years (5.5/1,000 person-years [95% CI 5.4-5.6]). The fracture rate for women with any DMPA use was 6.6 (95% CI 6.1-7.2) and 7.8 (95% CI 6.0-10.0) for women with recent use and more than 2 years of cumulative use. Women who had recent use with 2 years or less, or more than 2 years of cumulative use had higher fracture risk compared with women who had no DMPA use and used other methods (adjusted HR 1.15 [95% CI 1.01-1.31] and 1.42 [95% CI 1.10-1.83], respectively). Fracture risk was not increased in women with past DMPA use. Women who had more than 2 years cumulative use of combined OCPs and women with any progestin-only OCP use had lower fracture risk compared with women who did not use OCPs and used other methods (adjusted HR 0.85 [95% CI 0.76-0.96] and 0.88 [95% CI 0.80-0.97], respectively). Use of DMPA beyond 2 years should not be considered an absolute contraindication. Although DMPA use was associated with slightly increased fracture risk compared with other methods, the absolute risk of fracture was small and was not observed after discontinuation. Authors: Raine-Bennett 2019 09;134(3):581-589. Pre- and Early Pregnancy Onset Depression and Subsequent Rate of Gestational Weight Gain Background:Depression is associated with weight change outside of pregnancy. We assessed associations of prepregnancy or early pregnancy onset depression with gestational weight gain (GWG) rate overall and according to Institute of Medicine (IOM) recommendations. Materials and Methods:Depression from 6 months prepregnancy through 20 weeks gestation was identified in a health care system in northern California with perinatal depression screening (2011-2016; n = 87,600). GWG rate (lbs/week) was calculated using weight at delivery and at diagnosis or depression screening 20 weeks. Results:Compared to women without prepregnancy or early pregnancy depression, women with prepregnancy onset depression had 11% greater risk prevention Postherpetic (HZ) and is characterized by long-lasting pain. Zoster vaccine live (ZVL) is licensed for people 50 years and older to prevent HZ and PHN. This study evaluated vaccine effectiveness (VE) of ZVL against PHN. We conducted an open cohort study within Kaiser Permanente Northern California with continuous accrual of people as they became age-eligible for ZVL. We defined PHN using a PHN diagnosis between 90 and 365 days after an incident episode of HZ. We estimated VE against PHN using Cox regression with a calendar timeline stratified by year of birth and adjusted for sex, race, influenza vaccination, outpatient visit frequency, comorbidities, and immune compromise status. From 2007 to 2016, 1\u00b75 million people entered the study population and 33% received ZVL. During 7\u00b76 million 62,205 HZ cases, 4150 (6\u00b77%) of which went on to develop PHN. Overall VE for PHN was 64\u00b78% (95% VE was 82\u00b78% (95% CI 86\u00b77) during first year after vaccination, 58\u00b73% (95% CI 50.1, 65.2) during the third year, and then waned more gradually to 48\u00b77% (95% CI 30\u00b72, 62\u00b73) during the eighth year. VE in persons vaccinated when aged 80 years or older was similar to VE in younger vaccinees. VE in persons vaccinated when immune compromised was similar to VE in immune competent. Overall, ZVL was 65% effective against PHN. It was effective in all age groups and provided moderate protection through 8 years. Authors: Klein NP; Bartlett J; of pubertal onset in girls: a multiethnic population-based prospective cohort study Early puberty is associated with higher risk of adverse health and behavioral outcomes throughout adolescence and adulthood. US girls are experiencing earlier puberty with substantial racial/ethnic differences. We examined the association between breastfeeding and pubertal timing to identify modifiable risk factors of early puberty and potential sources of racial/ethnic differences in the timing of pubertal development. A prospective cohort study of 3331 racially/ethnically diverse girls born at Kaiser Permanente Northern California (KPNC) between 2004 and 06. All data were obtained from KPNC electronic clinical and administrative datasets. Mother-reported duration of breastfeeding was obtained from questionnaires administered at each 'well-baby' check-up exam throughout the baby's first year and categorized as 'Not breastfed', 'Breastfed < 6 months', and 'Breastfed 6 months'. Pubertal development data used Tanner stages assessed by pediatricians during routine pediatric checkups starting at age 6. Pubertal onset was defined as transition from Tanner Stage 1 to Tanner Stage 2+ for breast (thelarche) and pubic hair (pubarche). Weibull regression models accommodating for left, right, and interval censoring were used in all analyses. Models were adjusted for maternal age, education, race/ethnicity, parity and prepubertal body mass index (BMI). We also examined race/ethnicity as a potential effect modifier of these associations. Not breastfeeding was associated with earlier onset of breast and pubic hair development compared to breastfeeding 6 months (adjusted hazard Breastfeeding for < 6 months was also associated with the risk of earlier pubic hair development (HR: 1.14; 95% CI: prepubertal BMI slightly attenuated the association between breastfeeding and timing of breast onset but remained significant. The association between not breastfeeding and early breast development may be stronger among African American girls (HR: 1.92; 95% CI: 1.01-3.66, no breastfeeding vs. 6 months) than other racial/ethnic groups. Breastfeeding is an independent predictor of pubertal onset in girls, and the strength of the association may vary by race/ethnicity. Providing breastfeeding support and lactation education for high risk mothers may help prevent earlier pubertal onset and promote positive health outcomes later in J Clin Rheumatol. 2019 08;25(5):e54-e56. Targeted learning with daily EHR data Electronic health records (EHR) data provide a cost- and time-effective opportunity to conduct cohort studies of the effects of multiple time-point interventions in the diverse patient population found in real-world clinical settings. Because the computational cost of analyzing EHR data at daily (or more granular) scale can be quite high, a pragmatic approach has been to partition the follow-up into coarser intervals of pre-specified length (eg, quarterly or monthly intervals). The feasibility and practical impact of analyzing EHR data at a granular scale has not been previously evaluated. We start filling these gaps by leveraging large-scale EHR data from a diabetes study to develop a scalable targeted learning approach that allows analyses with small intervals. We then study the practical effects of selecting different coarsening intervals on inferences by reanalyzing data from the same large-scale pool of patients. Specifically, we map daily EHR data into four analytic datasets using 90-, 30-, 15-, and 5-day intervals. We apply a semiparametric and doubly robust estimation approach, the longitudinal Targeted Minimum Loss-Based Estimation (TMLE), to estimate the causal effects of four dynamic treatment rules with each dataset, and compare the resulting inferences. To overcome the computational challenges presented by the size of these data, we propose a novel TMLE implementation, the \"long-format TMLE,\" and rely on the latest advances in scalable data-adaptive machine-learning software, xgboost and h2o, for estimation 2019 20;38(16):3073-3090. Epub 2019-04-25. Self-reported Daily, Weekly, and Monthly Cannabis Use Among Women Before and During Pregnancy As the overall prevalence of prenatal cannabis use rises, it is vital to also monitor trends in the frequency of cannabis use in the period leading up to and during pregnancy because more frequent use may confer greater health risks for mothers and their children. To examine trends in the frequency of self-reported cannabis use among pregnant women in the year before and during pregnancy. Cross-sectional study using data from 367 403 pregnancies among 276 991 women 11 years or older who completed a self-administered questionnaire on cannabis use during standard prenatal care in Kaiser Permanente Northern California from January 1, 2009, to December 31, 2017. The annual prevalence of self-reported daily, weekly, and monthly cannabis use among women before and during pregnancy was estimated using Poisson regression with a log link function, adjusting for sociodemographics. Data analyses were conducted from February to May 2019. Calendar year. Self-reported frequency of cannabis use in the year before pregnancy and during pregnancy assessed as part of standard prenatal care (at approximately 8 weeks' gestation). Among the overall sample of 367 403 pregnancies among 276 991 women, 35.9% of the women In the sample, 1.2% of the women were aged 11 to 17 years; 15.3%, 18 to 24 years; 61.4%, 25 to 34 years; and 22.0%, older than 34 years. Median (interquartile range) neighborhood household income was $70 472 ($51 583-$92 643). From 2009 to 2017, the adjusted prevalence of cannabis use in the year before pregnancy increased from 6.80% (95% CI, 6.42%-7.18%) to 12.50% (95% CI, 12.01%-12.99%), and the adjusted prevalence of cannabis use during pregnancy increased from 1.95% (95% CI, 1.78%-2.13%) to 3.38% (95% CI, 3.15%-3.60%). Annual of in daily cannabis (1.115; less cannabis use (1.050; 95% CI, 1.043-1.057) in the year before pregnancy increased significantly, with daily use increasing most rapidly (from 1.17% to 3.05%). Similarly, annual relative rates of change in self-reported daily cannabis use (1.110; less cannabis use (1.044; 95% CI, 1.032-1.057) during pregnancy increased significantly from 2009 to 2017, with daily use increasing most rapidly (from 0.28% to 0.69%). Results of this study demonstrate that frequency of cannabis use in the year before pregnancy and during pregnancy has increased in recent years among pregnant women in Northern California, potentially associated with increasing acceptance of cannabis use and decreasing perceptions of cannabis-associated Epub 2019-07-03. Acellular Pertussis Vaccine Effectiveness Over Time To determine pertussis risk by diphtheria-tetanus-acellular pertussis (DTaP) vaccination status and time since last DTaP dose. Children born at Kaiser Permanente Northern California between 1999 and 2016 were followed from 3 months of age until they tested positive for pertussis; disenrolled from Kaiser Permanente Northern California; received the tetanus toxoid, reduced diphtheria toxoid, and acellular pertussis, adsorbed vaccine; turned 11 years of age, or the end of the study period. DTaP vaccination status was categorized on the basis of the number of doses received in relation to the number of doses expected according to the Advisory Committee on Immunization Practice-recommended ages. Among 469 982 children ages 3 months to 11 years, we identified 738 pertussis cases. A total of 99 cases were unvaccinated, 36 were undervaccinated, 515 were fully vaccinated, and 88 were fully vaccinated plus 1 dose. Pertussis risk was 13 times higher among unvaccinated (adjusted hazard ratio [aHR] = 13.53; 95% confidence interval [CI] 10.64-17.21) compared with fully vaccinated children and 1.9 times higher (aHR = 1.86; 95% CI 1.32-2.63) among undervaccinated children. Among vaccinated children ages 19 to <84 months, pertussis risk was 5 times higher (aHR = 5.04; 95% CI 1.84-13.80) 3 years vs <1 year after vaccination. Among children ages 84 to 132 months, risk was 2 times higher (aHR = 2.32; 95% CI 0.97-5.59) 6 years vs <3 years after vaccination. Undervaccinated and especially unvaccinated children were at greater risk of pertussis. However, most pertussis cases occurred among children age-appropriately vaccinated who were further away from their last DTaP dose, suggesting that suboptimal vaccine effectiveness played a major role in recent pertussis Authors: 07;144(1). Epub 2019-06-10. Colorectal Cancer Screening in People With and Without HIV in an Integrated Health Care Setting As people with HIV (PWH) live longer, age-appropriate colorectal cancer (CRC) screening is increasingly important. Limited data exist on CRC screening and outcomes comparing PWH and persons without HIV. Large integrated health care system. This study included PWH and demographically matched persons without HIV who were aged 50-75 years during 2005-2016 and had no previous CRC screening. We evaluated time to first CRC screening (fecal test, sigmoidoscopy, or colonoscopy). We also assessed detection of adenoma and CRC with sigmoidoscopy or colonoscopy by HIV status, accounting for CRC risk factors including sex, age, race/ethnicity, number of outpatient visits, smoking, body mass index, type-2 diabetes, and inflammatory bowel disease. Among PWH, we evaluated whether CD4 count (<200/200-499/500 cells/\u00b5L) was adenoma and 3177 PWH and 29,219 persons without HIV, PWH were more likely to be screened (85.6% vs. 79.1% within 5 years, P < 0.001). Among those with sigmoidoscopy or colonoscopy, adenoma was detected in 161 (19.6%) PWH and 1498 (22.6%) persons without HIV, and CRC was detected in 4 (0.5%) PWH and 69 (1.0%) persons without HIV. In adjusted analyses, we found no difference in prevalence of either adenoma or CRC by HIV status (adjusted prevalence ratio = 0.97, 95% confidence interval: 0.83 to 1.12). Lower CD4 count did not increase likelihood of adenoma or CRC. Within an integrated health care system with an organized CRC screening program, we found no disparities in CRC screening uptake or outcomes among people with and without HIV, and CD4 count did not influence CRC risk 01;81(3):284-291. Stressors in Midlife and Risk of Dementia: The Role of Race and Education Posttraumatic stress disorder is associated with increased dementia risk but less is known about stress because of everyday problems in diverse populations. A total of 9605 health care plan members who provided information regarding midlife stressors in 1972 to 1973 (ages, 40 to 55 y) were followed for dementia diagnosis between 1996 and 2017. Cox proportional hazard models evaluated associations between midlife stressors and dementia adjusting for demographics and lifecourse health indicators. Reporting at least 1 midlife stressor was associated with 17% greater dementia risk [hazard ratio (HR), 1.17; 95% confidence interval (CI),1.07-1.27] versus 0 midlife stressors and 26% increased risk among those with less than equal to high school education (HR, 1.26; 95% CI,1.09-1.44) adjusting for demographics. Compared with whites without stressors, whites with 1 stressor had 13% greater dementia risk (HR, 1.13; 95% CI, 1.02-1.24), blacks without stressors 19% greater risk (HR, 1.19; 95% CI,1.08-1.32), and blacks with 1 stressors 47% greater risk (HR, 1.47; 95% CI,1.27-1.69) in fully adjusted models. Resource problems were associated with 20% greater risk (HR, 1.20; 95% CI, 1.01-1.42) than interpersonal problems. Reporting 1 serious midlife stressor was associated with elevated dementia risk, especially stressors related to resources problems and for those with less than equal to high school education. Everyday stressors can impact brain health over the long term and may contribute to racial inequities in dementia rates, though education can be a mitigating Jul-Sep;33(3):200-205. A Randomized Study of Values Affirmation to Promote Interest in Diabetes Prevention Among Women With a History of Gestational Diabetes The objective of this study was to test whether 2 interventions promote interest in diabetes prevention among women with a history of gestational diabetes mellitus, who face high lifetime risk for diabetes. We designed an email outreach message promoting an existing preventive lifestyle program. The message incorporated values affirmation, a theory-based intervention that can improve openness to health information but typically relies on a writing exercise less practical in health care settings. In a 3-arm randomized study, 237 women with elevated body mass index and a history of gestational diabetes mellitus were randomized to read an outreach message containing either no affirmation (control) or 1 of 2 affirmations, streamlined to remove the typical writing exercise: either a values affirmation prompting reflection on any personal value, or a parenting affirmation prompting reflection on caregiving-related values. Outcomes included demonstrating interest in the lifestyle program (seeking information about it or intending to join) and seeking publicly-available health information about diabetes prevention. Compared with control, participants randomized to the values affirmation more frequently demonstrated interest in the lifestyle program (59.0% vs. 74.4%; adjusted relative risk: 1.31; 95% confidence interval: and sought information adjusted relative risk: 1.22; 95% confidence interval: 0.97-1.54). The parenting affirmation yielded no significant differences in either outcome. A streamlined values affirmation, designed for feasibility in a health care setting, can promote interest in diabetes prevention among women at high risk. Research is needed to evaluate its effects on diabetes prevention program enrollment and clinical outcomes. Authors: A Med Care. 2019 07;57(7):528-535. Association of Blood Donor Sex and Prior Pregnancy With Mortality Among Red Blood Cell Transfusion Recipients Evidence regarding associations of blood donor sex with mortality among red blood cell transfusion recipients is conflicting. To study associations of donor sex and prior pregnancy with mortality of transfusion recipients. Data from 3 retrospective cohorts of transfusion recipients (the Kaiser Permanente Northern California [KPNC] and Recipient Epidemiology and Donor Evaluation Study-III [REDS-III] databases of data from January 2013 to December 2016 and the Scandinavian Donations and Transfusions [SCANDAT] database with data from January 2003 to December 2012) were analyzed. Final dates of follow-up were December 31, 2016, for the KPNC and REDS-III cohorts and December 31, 2012, for the SCANDAT cohort. Stratified Cox regression models were used to estimate associations between donor exposure groups with risk of mortality, adjusting for the number of red blood cell unit transfusions. The number of transfused red blood cell units from female donors, previously pregnant donors, and sex-discordant donors (male donor and female recipient or female donor and male recipient). In-hospital mortality. The study population included 34 662 patients (mean age, 69 years; 18 652 [54%] women) from the KPNC cohort, 93 724 patients (mean age, 61 years; 48 348 [52%] women) from the REDS-III cohort, and 918 996 patients (mean age, 72 years; 522 239 [57%] women) from the SCANDAT cohort. The median number of red blood cell transfusions per patient was 3 in the KPNC cohort, 2 in the REDS-III cohort, and 3 in the SCANDAT cohort. The percentage of transfusions from previously pregnant or parous donors was 9% in the KPNC cohort, 18% in the REDS-III cohort, and 25% in the SCANDAT cohort. The percentage of transfusions in the 3 cohorts from female donors ranged from 39% to 43%, from previously pregnant or parous donors ranged from 9% to 25%, and from sex-discordant donors ranged from 44% to 50%. There were 3217 in-hospital deaths in the KPNC cohort, 8519 in the REDS-III cohort, and 198 537 in the SCANDAT cohort. There were no statistically significant associations between any of the 3 donor exposures and in-hospital mortality in the 3 cohorts. Hazard ratios for in-hospital mortality per transfused unit from female donors were 0.99 (95% CI, 0.96-1.03) for the KPNC cohort, 1.00 1.00 (95% CI, 0.99-1.00) for the SCANDAT cohort. For units from previously pregnant or parous female donors, hazard ratios were 1.00 (95% CI, 1.00-1.01) for the KPNC cohort, 1.01 for the REDS-III cohort, and 1.00 (95% CI, 1.00-1.01) for the SCANDAT cohort. For units from sex-discordant transfusions, hazard ratios were 1.02 (95% CI, 0.99-1.05) for the KPNC cohort, 0.99 (95% CI, for the REDS-III cohort, and 1.00 (95% CI, 0.99-1.00) for the SCANDAT cohort. Among red blood cell transfusion recipients, transfusions from female, previously pregnant, or sex-discordant donors were not significantly associated with increased mortality. Authors: Edgren G; Lee C; al. JAMA. 2019 06 11;321(22):2183-2192. Telomere length and socioeconomic status at neighborhood and individual levels among 80,000 adults in the Genetic Epidemiology Research on Adult Health and Aging cohort Telomere length (TL) may serve as a biologic marker of aging. We examined neighborhood and individual-level socioeconomic status (SES) in relation to TL. The study included 84,996 non-Hispanic white subjects from the Genetic Epidemiology Research on Adult Health and Aging (GERA) cohort, part of the Research Program on Genes, Environment and Health. Relative TL (T/S) was log2 transformed to improve normality and standardized to have mean 0 and variance 1. Neighborhood SES was measured using the Neighborhood Deprivation Index (NDI), and individual SES was measured by self-reported education level. We fit linear regression models of TL on age, sex, smoking, body mass index, comorbidities, NDI, and education level. We tested for differences in the associations by sex and nonlinearity in the association of NDI with TL. Each SD increase in NDI was associated with a decrease of 0.0192 in standardized TL, 95% confidence interval (CI) = -0.0306, -0.0078. There was no evidence of nonlinearity in the association of NDI with TL. We further found that less than high school education was associated with a decrease of 0.1371 in standardized TL, 95% CI = -0.1919, -0.0823 as compared to a college education. There were no differences in the associations by sex. We found evidence that both lower neighborhood SES and lower individual-level SES are associated with shorter TL among non-Hispanic whites. Our findings suggest that socioeconomic factors may influence aging by contributing to shorter TL. Authors: Alexeeff, and Mammographic Density: Associations Among Women and Comparison of Studies Using Digitized Film-Screen Mammography and Full-Field Digital Mammography Breast density is a modifiable factor that is strongly associated with breast cancer risk. We sought to understand the influence of newer technologies of full-field digital mammography (FFDM) on breast density research and to determine whether results are comparable across studies using FFDM and previous studies using traditional film-screen mammography. We studied 24,840 screening-age (40-74 years) non-Hispanic white women who were participants in the Research Program on Genes, Environment and Health of Kaiser Permanente Northern California and underwent screening mammography with either Hologic (Hologic, Inc., Marlborough, Massachusetts) or General Electric (General Electric Company, Boston, Massachusetts) FFDM machines between 2003 and 2013. We estimated the associations of parity, age at first birth, age at menarche, and menopausal status with percent density and dense area as measured by a single radiological technologist using Cumulus software (Canto Software, Inc., San Francisco, California). We found that associations between reproductive factors and mammographic density measured using processed FFDM images were generally similar in magnitude and direction to those from prior studies using film mammography. Estimated associations for both types of FFDM machines were in the same direction. There was some evidence of heterogeneity in the magnitude of the effect sizes by machine type, which we accounted for using random-effects meta-analysis when combining results. Our findings demonstrate the robustness of quantitative mammographic density measurements across FFDM and film mammography platforms. 06 01;188(6):1144-1154. SemiCompRisks: An R Package for the Analysis of Independent and Cluster-correlated Semi-competing Risks Data Semi-competing risks refer to the setting where primary scientific interest lies in estimation and inference with respect to a non-terminal event, the occurrence of which is subject to a terminal event. In this paper, we present the R package SemiCompRisks that provides functions to perform the analysis of independent/clustered semi-competing risks data under the illness-death multi-state model. The package allows the user to choose the specification for model components from a range of options giving users substantial flexibility, including: accelerated failure time or proportional hazards regression models; parametric or non-parametric specifications for baseline survival functions; parametric or non-parametric specifications for random effects distributions when the data are cluster-correlated; and, a Markov or semi-Markov specification for terminal event following non-terminal event. While estimation is mainly performed within the Bayesian paradigm, the package also provides the maximum likelihood estimation for select parametric models. The package also includes functions for univariate survival analysis as complementary analysis tools. Authors: Alvares, Danilo; Haneuse, Sebastien; Lee, J. 2019 Jun;11(1):376-400. Epub 2019-08-20. Using Pharmacy Data and Adherence to Define Long-Term Bisphosphonate Exposure in Women Assigning drug exposure is a necessary first step in examining bisphosphonate (BP) treatment in observational studies using pharmacy data. To determine whether the choice of adherence level using the proportion of days covered (PDC) affected BP exposure assignment. 10,381 female health plan members who initiated oral BP therapy between 2002 and 2010 and had received 5 consecutive years of treatment were identified and subsequently followed up to 5 additional years. In each 90-day interval of follow-up, a woman was considered \"on treatment\" if she received the drug for more than a predetermined PDC based on pharmacy days supply and \"off treatment\" if she received the drug for less than that PDC. Women who continued on therapy above the PDC threshold during follow-up were considered continuously on therapy. Women who were off treatment during the first 90-days of follow-up were classified as off therapy and were followed to determine if they remained continuously off treatment. This study evaluated the extent to which varying the PDC threshold ( 0.5, 0.6, and 0.7) affected the proportion of women classified as \"continuously on\" or \"continuously off\" BP during follow-up. 0.5, 0.6, and 0.7, 48%, 43%, and 36% of women who remained on follow-up were categorized as continuously on treatment at year 2 of follow-up, and 18%, 14%, and 12% were categorized as continuously on treatment by the end of follow-up. Using these same PDC thresholds, 9%, 12%, and 15% of women were categorized as off therapy during the first quarter of follow-up and were highly likely to remain off therapy: 4%, 5%, and 5% were classified as continuously off therapy at year 2, and 4% of women were classified as such by the end of follow-up for all 3 thresholds. A PDC of 0.6 was chosen as a practical threshold for drug adherence. Varying the PDC to 0.5 or 0.7 resulted in modest changes in the proportions of women considered continuously on BP therapy. This study was supported by a grant from the National Institute of Aging and National Institute of Arthritis, Musculoskeletal and Skin Diseases at the National Institutes of Health (R01AG047230, S1). Lo has received previous research funding from Amgen and Sanofi, outside of the current study. Chandra has received previous research funding from Amgen outside of the current study. Adams has received previous research funding from Merck, Amgen, Otsuka, and Radius Health, outside of the current study. Ott previously attended a scientific advisory meeting for Amgen but declined the honorarium. Ettinger previously served as an expert witness Manag Care Spec Pharm. 2019 Jun;25(6):719-723. Adipose Tissue Distribution and Survival Among Women with Nonmetastatic Breast Cancer Previous studies of breast cancer survival have not considered specific depots of adipose tissue such as subcutaneous adipose tissue (SAT) and visceral adipose tissue (VAT). This study assessed these relationships among 3,235 women with stage II and III breast cancer diagnosed between 2005 and 2013 at Kaiser Permanente Northern California and between 2000 and 2012 at Dana Farber Cancer Institute. SAT and VAT areas (in centimeters squared) were calculated from routine computed tomography scans within 6 (median: 1.2) months of diagnosis, covariates were collected from electronic health records, and vital status was assessed by death records. Hazard ratios (HRs) and 95% CIs were estimated using Cox regression. SAT and VAT ranged from 19.0 to 891 cm2 and from 0.484 to 454 cm2 , respectively. SAT was related to increased risk of death (127-cm2 increase; HR [95% CI]: 1.13 [1.02-1.26]), but no with VAT (78.18-cm2 increase; HR [95% CI]: 1.02 [0.91-1.14]). An association with VAT was noted among women with stage II cancer (stage II: interaction < 0.01). Joint increases in SAT and VAT were associated with mortality above either alone (simultaneous 1-SD increase: HR 1.19 [95% CI: 1.05-1.34]). SAT may be 06;27(6):997-1004. Epub 2019-04-25. Prompting Patients with Poorly Controlled Diabetes to Identify Visit Priorities Before Primary Care Visits: a Pragmatic Cluster Randomized Trial Most patients with diabetes do not meet all evidence-based goals of care, and many patients report poor communication and lack of involvement in decision-making during primary care visits. To test the hypothesis that a \"Pre-Visit Prioritization\" secure email message could improve visit communication and glycemic control among patients with type 2 diabetes. We conducted a pragmatic, provider-randomized, multi-site clinical trial from March 2015 to October 2016 across 30 primary care practices within Kaiser Permanente Northern California (KPNC), a large integrated care delivery system. Eligible patients had at least 1 year of KPNC membership, type 2 diabetes with most recently measured hemoglobin A1c (HbA1c)?>?=?8.0%, and were registered users of the KPNC online patient portal. Patients in the intervention arm, upon booking an appointment, received a secure email through the KPNC online portal with a link to the EHR allowing them to submit their top one or two priorities prior to the visit. Control patients received usual care. Glycemic control; change in HbA1c 6 and 12 months after the initial visit; patient-reported outcomes related to patient-provider communication and patient care experiences. During the study period, 1276 patients had at least one eligible visit. In post-visit surveys (n?=?457), more intervention arm patients reported preparing questions for their visit (72% vs 63%, p?=?0.048) and being given treatment choices to consider (81% vs 73%, p?=?0.041). Patients in both arms had similar reductions in HbA1c over the 12-month study period (0.56%?\u00b1?1.45%), with no significant differences between arms. A \"light touch\" email-based pre-visit intervention resulted in improved measures of visit interaction but did not significantly improve glycemic control relative to usual care. Improving diabetes clinical outcomes through more effective primary care visits may require more intensive approaches to patient visit 06;34(6):831-838. Epub 2019-02-11. Intra-season Waning of Influenza Vaccine Effectiveness In the United States, it is recommended that healthcare providers offer influenza vaccination by October, if possible. However, if the vaccine's effectiveness soon begins to wane, the optimal time for vaccination may be somewhat later. We examined whether the effectiveness of influenza vaccine wanes during the influenza season with increasing time since vaccination. We identified persons who were vaccinated with inactivated influenza vaccine from 1 September 2010 to 31 March 2017 and who were subsequently tested for influenza and respiratory syncytial virus (RSV) by a polymerase chain reaction test. Test-confirmed influenza was the primary outcome and days-since-vaccination was the predictor of interest in conditional logistic regression. Models were adjusted for age and conditioned on calendar day and geographic area. RSV was used as a negative-control outcome. Compared with persons vaccinated 14 to 41 days prior to being tested, persons vaccinated 42 to 69 days prior to being tested had 1.32 (95% confidence interval [CI], 1.11 to 1.55) times the odds of testing positive for any influenza. The odds ratio (OR) increased linearly by approximately 16% for each additional 28 days since vaccination. The OR was 2.06 (95% CI, 1.69 to 2.51) for persons vaccinated 154 or more days prior to being tested. No evidence of waning was found for RSV. Our results suggest that effectiveness of inactivated influenza vaccine wanes during the course of a single season. These results may lead to reconsideration of the optimal timing of seasonal influenza vaccination. Authors: Ray GT; Klein Clin Infect Dis. 2019 05 02;68(10):1623-1630. Association of Infant Temperament With Subsequent Obesity in Young Children of Mothers With Gestational Diabetes Mellitus Infant temperament is associated with excess weight gain or childhood obesity risk in samples of healthy individuals, although the evidence has been inconsistent. To our knowledge, no prior research has examined this topic among children exposed to gestational diabetes mellitus (GDM) in utero. To prospectively evaluate infant temperament in association with overweight and obesity status at ages 2 to 5 years among children born to mothers who experienced GDM. This prospective cohort study took place at Kaiser Permanente Northern California medical centers. We studied singleton infants delivered at 35 weeks' gestational age or later to mothers who had been diagnosed with GDM. Data were collected from 2009 to 2016, and data analysis occurred from June 2017 to October 2018. The primary exposures in the child's first year were soothability, distress to limitations, and activity aspects of temperament, as assessed by a validated questionnaire. Modifiable covariates in the child's first year included breastfeeding intensity and duration monthly ratio scores, along with the timing of the introduction of sugary beverages and complementary foods. The primary outcome was child overweight and obesity status, assessed at ages 2 to 5 years. Multinomial logistic regression models estimated adjusted odds ratios and 95% CIs for infants whose temperaments were measured at 6 to 9 weeks of age and categorized as elevated (75th percentile) or not elevated in the 3 domains. We controlled for nonmodifiable and modifiable covariates across models. A total of 382 mother-infant pairs participted, including 130 infants (34.0%) who were non-Hispanic white, 126 infants (33.0%) who were Hispanic, 96 infants (25.1%) who were Asian, 26 infants (6.8%) who were non-Hispanic black, and 4 infants (1.1%) who were of other races/ethnicities. In descriptive analyses, elevated infant soothability and activity temperaments were associated with the early introduction of 100% fruit juice and/or sugar-sweetened beverages (at ages <6 months) and shorter breastfeeding duration (from 0 to <3 months), while elevated distress to limitations was associated with early introduction of complementary foods (at ages <4 months). Elevated soothability consistently was associated with a higher odds of later childhood obesity, with adjusted odds ratios across models ranging from 2.22 (95% CI, 1.04-4.73) to 2.54 (95% CI, 1.28-5.03). Greater breastfeeding intensity and duration (12-month combined) score was associated with lower odds of obesity, independent of infant temperament and other covariates. Among this high-risk population of infants, elevated soothability was associated with early childhood obesity risk, perhaps in part because caregivers use sugary drinks to assuage infants. Soothability temperament may be a novel screening target for early obesity prevention interventions involving responsive feeding and emotion regulation. Authors: Faith 01;173(5):424-433. Gestational weight gain and optimal wellness (GLOW): rationale and methods for a randomized controlled trial of a lifestyle intervention among pregnant women with overweight or obesity Excess gestational weight gain (GWG) is common among women with overweight or obesity, increasing their risks for pregnancy complications, delivering a large infant, and postpartum weight retention. To date, only intensive interventions have had success and few interventions have been designed for implementation in healthcare settings. We describe the development, rationale, and methods of GLOW (GestationaL Weight Gain and Optimal Wellness), a randomized controlled trial evaluating the efficacy of a lifestyle intervention to prevent excess GWG among racially/ethnically diverse women with overweight or obesity in an integrated healthcare delivery system. Participants in Kaiser Permanente Northern California will be randomized, within 2 weeks of completing a study baseline clinic visit at 10 weeks' gestation, to either usual medical care or a multi-component pregnancy lifestyle intervention adapted from the Diabetes Prevention Program (target N = 400). Informed by focus groups with patients and designed to be feasible in a clinical setting, the intervention will include 13 weekly individual sessions (11 delivered by telephone) focused on behavior change for weight management, healthy eating, physical activity, and stress management. Outcomes will be assessed in women and their infants from randomization to 12 months postpartum. The primary outcome is GWG. Secondary outcomes include changes in diet and physical activity during pregnancy and infant birthweight. Exploratory outcomes include cardiometabolic profile assessed via pregnancy blood samples and cord blood samples; and postpartum weight retention and infant anthropometrics up to 12 months of age. The trial includes systematic approaches to enhance intervention fidelity, intervention adherence, and participant retention in trial assessments. GLOW is among few trials targeting excess GWG among diverse women with overweight or obesity in a healthcare setting, with long-term maternal and infant outcomes assessed up to 12 months after delivery. This evaluation of a multi-component intervention is designed to produce generalizable results to inform potential adoption of the intervention in clinical settings. ClinicalTrials.gov ( NCT02130232 ): submitted April 30, 2014; posted Epub 2019-04-30. Reproductive period and risk of dementia in a diverse cohort of health care members Women have >50% greater lifetime risk of dementia than men but the role of female-specific endocrine milieu is not well-understood. This study evaluates associations between indicators of estrogen exposure from women's reproductive period and dementia risk in a large diverse population. We evaluated 15,754 female members (29.9% nonwhite) of Kaiser Permanente with clinical examinations and health survey data from 1964 to 1973 and were members as of January 1, 1996. In midlife (mean age 51.1 years), women reported age at menarche and menopause and hysterectomy status. Reproductive span was calculated as menopause age minus menarche age. Dementia diagnoses were abstracted from January 1, 1996 to September 30, 2017 medical records (mean age at start of dementia follow-up 76.5 years). Cox proportional hazard models evaluated associations between aspects of reproductive span and dementia risk adjusting for demographics and life course health indicators. Forty-two percent of women developed dementia. Compared to menarche at age 13.0 (mean menarche age), menarche at ?16 was associated with 23% greater dementia risk (adjusted hazard ratio [HR] 1.23; 95% confidence interval [CI] 1.01-1.50) adjusting for demographics and life course health indicators. Natural menopause at age <47.4 (mean menopause age) was associated with 19% elevated dementia risk (HR 1.19; 95% CI 1.07-1.31). Reproductive spans <34.4 years (mean duration) were associated with 20% elevated dementia risk (HR 1.20; 95% CI 1.08-1.32). Hysterectomies were associated with 8% elevated dementia risk (HR 1.08; 95% CI 1.01-1.16). In this large prospective cohort study, endocrine events signaling less estradiol exposure (i.e., later age at menarche, younger age at menopause, shorter reproductive span, and hysterectomies) were associated with elevated risk of dementia. and viraemia with non-Hodgkin lymphoma risk overall and by subtype in people living with HIV in Canada and the USA: a multicentre cohort study Research is needed to better understand relations between immunosuppression and HIV viraemia and risk for non-Hodgkin lymphoma, a common cancer in people living with HIV. We aimed to identify key CD4 count and HIV RNA (viral load) predictors of risk for non-Hodgkin lymphoma, overall and by subtype. We studied people living with HIV during 1996-2014 from 21 Canadian and US cohorts participating in the North American AIDS Cohort Collaboration on Research and Design. To determine key independent predictors of risk for non-Hodgkin lymphoma, we assessed associations with time-updated recent, past, cumulative, and nadir or peak measures of CD4 count and viral load, using demographics-adjusted, cohort-stratified Cox models, and we compared models using Akaike's information criterion. Of 102 131 people living with HIV during the study period, 712 people developed non-Hodgkin lymphoma. The key independent predictors of risk for overall non-Hodgkin lymphoma were recent CD4 count (ie, lagged by 6 months; <50 cells per L vs 500 cells per L, hazard ratio [HR] 3\u00b72, 95% CI 2\u00b72-4\u00b77) and average viral load during a 3-year window lagged by 6 months (a cumulative measure; 100 000 copies per mL vs 500 copies per mL, HR 9\u00b76, 95% CI 6\u00b75-14\u00b70). These measures were also the key predictors of risk for diffuse large B-cell lymphoma (recent CD4 count <50 cells per L vs 500 cells per L, HR 2\u00b74, 95% CI 1\u00b74-4\u00b72; average viral load 100 000 copies per mL vs 500 copies per mL, HR 7\u00b75, 95% CI 4\u00b75-12\u00b77). However, recent CD4 count was the sole key predictor of risk for CNS non-Hodgkin lymphoma (<50 cells per L vs 500 cells per L, HR 426\u00b73, 95% CI 58\u00b71-3126\u00b74), and proportion of time viral load was greater than 500 copies per mL during the 3-year window (a cumulative measure) was the sole key predictor for Burkitt lymphoma (100% vs 0%, HR 41\u00b71, recent immunosuppression and prolonged HIV viraemia have important independent roles in the development of non-Hodgkin lymphoma, with likely subtype heterogeneity. Early and sustained antiretroviral therapy to decrease HIV replication, dampen B-cell activation, and restore overall immune function is crucial for preventing non-Hodgkin lymphoma. National Institutes of Health, Centers for Disease Control and Prevention, US Agency for Healthcare Research and Quality, US Health Resources and Services Administration, Canadian Institutes of Health Research, Ontario Ministry of Health and Long Term Care, and the Government of Alberta. Authors: Hern\u00e1ndez-Ram\u00edrez RU; Neugebauer RS; Silverberg MJ; North American AIDS Cohort Collaboration on Research and Design of the International Epidemiologic Databases to Evaluate AIDS; et al. Lancet HIV. 2019 04;6(4):e240-e249. Epub 2019-02-27. Incidence of dementia after age 90 in a multiracial cohort Little is known about dementia incidence in diverse populations of oldest-old, the age group with highest dementia incidence. Incident dementia diagnoses from 1/1/2010 to 9/30/2015 were abstracted from medical records for 2350 members of an integrated health care system in California (n = 1702 whites, n = 375 blacks, n = 105 Latinos, n = 168 Asians) aged 90 in 2010. We estimated race/ethnicity-specific age-adjusted dementia incidence rates and implemented Cox proportional hazards models and Fine and Gray competing risk of death models adjusted for demographics and comorbidities in midlife and late-life. Dementia incidence rates (n = 771 cases) were lowest among Asians (89.9/1000 person-years), followed blacks (121.5/1000 person-years). and competing risk models estimated 28% and 36% higher dementia risk for blacks versus whites adjusting for demographics and comorbidities. Patterns of racial/ethnic disparities in dementia seen in younger older adults continue after the age of 90 years, though smaller in 2019-02-20. Visual outcomes after cataract surgery in patients with type 2 diabetes To assess the relation between diabetic retinopathy (DR) severity, duration of diabetes, insulin dependence, and preoperative hemoglobin A1c (HbA1c) with visual outcome after phacoemulsification for cataract in patients with type 2 diabetes. Kaiser Permanente Northern California, USA. Retrospective case series. Information was obtained from the electronic medical record for patients, June 1, 2010, through May 31, 2015. Confounding factors and clustering of eyes within patients were controlled for using linear mixed-effects regression models for continuous outcomes and general estimating equations for dichotomous outcomes. The study included 65 370 patients; 28% had type 2 diabetes without DR, 5% nonproliferative DR, and 1.2% proliferative DR. Patients with diabetes and no DR were as likely as those without diabetes to achieve a corrected distance visual acuity (CDVA) of 20/20 (odds ratio, 1.01; 95% confidence The odds of a postoperative CDVA of 20/25 or worse increased with the severity of retinopathy duration of diabetes and insulin dependence, but not with the preoperative HbA1c. Although the odds of a postoperative CDVA of 20/20 was lower in patients with DR, every DR group averaged 4 lines of CDVA improvement, the same as patients without diabetes. A longer duration of diabetes, insulin dependence, and elevated HbA1c were not associated with worse postoperative outcomes. Patients with DR and cataracts were less likely to achieve a CDVA of 20/20 vision but gained as many lines of CDVA from phacoemulsification as patients without diabetes, showing no evidence that cataract surgery should be delayed in diabetic patients with elevated Analytical Methods Using Only Aggregate-Level Information to Conduct Multivariable-Adjusted Analysis in Distributed Data Networks Distributed data networks enable large-scale epidemiologic studies, but protecting privacy while adequately adjusting for a large number of covariates continues to pose methodological challenges. Using 2 empirical examples within a 3-site distributed data network, we tested combinations of 3 aggregate-level data-sharing approaches (risk-set, summary-table, and effect-estimate), 4 confounding adjustment methods (matching, stratification, inverse probability weighting, and matching weighting), and 2 summary scores (propensity score and disease risk score) for binary and time-to-event outcomes. We assessed the performance of combinations of these data-sharing and adjustment methods by comparing their results with results from the corresponding pooled individual-level data analysis (reference analysis). For both types of outcomes, the method combinations examined yielded results identical or comparable to the reference results in most scenarios. Within each data-sharing approach, comparability between aggregate- and individual-level data analysis depended on adjustment method; for example, risk-set data-sharing with matched or stratified analysis of summary scores produced identical results, while weighted analysis showed some discrepancies. Across the adjustment methods examined, risk-set data-sharing generally performed better, while summary-table and effect-estimate data-sharing more often produced discrepancies in settings with rare outcomes and small sample sizes. Valid multivariable-adjusted analysis can be performed in distributed data networks without sharing of individual-level data. Authors: Li 04 01;188(4):709-723. Comparative effectiveness of treatment of actinic keratosis with topical fluorouracil and imiquimod in the prevention of keratinocyte carcinoma: a cohort study The effectiveness of 5-fluorouracil compared with that of imiquimod for preventing keratinocyte carcinoma is unknown. To compare the effectiveness of 5-fluorouracil and that of imiquimod in preventing keratinocyte carcinoma in a real-world practice setting. We identified 5700 subjects who filled prescriptions for 5-fluorouracil or imiquimod for treatment of actinic keratosis in 2007. An intention-to-treat analysis controlling for potential confounding variables was used to calculate 2- and 5-year cumulative risk differences for subsequent keratinocyte carcinoma overall and in field-treated areas. 5-Fluorouracil was associated with a statistically significant decreased risk of any keratinocyte carcinoma compared with imiquimod (adjusted hazard ratio [aHR], 0.86; 95% confidence interval [CI], 0.76-0.97), but there were no significant differences in risk by tumor subtype (for squamous cell carcinoma: aHR, 0.96; 95% CI, 0.81-1.14). There were no significant differences in 2- or 5-year cumulative risk of keratinocyte carcinoma among those treated with 5-fluorouracil versus with imiquimod. Generalizability to other practice settings may be limited. Whereas 5-fluorouracil was more effective in reducing keratinocyte carcinoma risk overall, we found no differences in the short- or long-term risk of subsequent site-specific keratinocyte carcinoma in a real-world Epub 2018-11-17. Developing a Prognostic Information System for Personalized Care in Real Time Electronic medical records hold promise to transform clinical practice. However, technological and other barriers may preclude using them to guide care in real time. We used the Virtual Data Warehouse (VDW) to develop a tool that enables physicians to generate real-time, personalized prognostic information about survival after cancer. Patients with cancer often ask their oncologists, \"Have you ever seen a patient like me?\" To help oncologists answer this question, we developed a prototype Prognostic Information System (PRISM), a web-based tool that gathers data about the index patient from Kaiser Permanente's clinical information systems, selects a historical cohort of similar patients, and displays the survival curve of the similar patients relative to key points in their treatment course. The prototype was developed by a multidisciplinary team with expertise in oncology, research, and technology. We have completed two rounds of user testing and refinement. Successful development rested on: (1) executive support and a clinical champion; (2) collaboration among experts from multiple disciplines; (3) starting with simple cases rather than ambitious ones; (4) extensive research experience with the Virtual Data Warehouse, related databases, and an existing query tool; and (5) following agile software development principles, especially iterative user testing. Clinical data stored in health care systems' electronic medical records can be used to personalize clinical care in real time. Development of prognostic information systems can be accelerated by collaborations among researchers, technology specialists, and clinicians and by use of existing technology like the Virtual Data Warehouse. Authors: Lieu TA; Neugebauer R; Van Den Eeden SK; (Wash DC). 2019 Mar 25;7(1):2. Epub 2019-03-25. Maternal Gestational Weight Gain, Obesity, and the Timing of Pubertal Onset in Daughters Early puberty is associated with adverse health outcomes, but little is known regarding early life determinants influencing pubertal timing. We examined the associations between maternal gestational weight gain (GWG) and the timing of the onset of breast development (thelarche) and pubic hair development (pubarche) in a cohort of 2,070 girls born in a Kaiser Permanente Northern California facility between 2005-06. Using Weibull regression models accommodating interval censoring, and adjusting for important confounders, we found that excessive GWG was associated with increased risk of early thelarche (hazard ratio [HR]: 1.50; CI: 1.08-1.71). The associations between excess or inadequate GWG and risk of earlier thelarche were stronger if mothers were obese before or at the beginning of pregnancy (body mass pubarche outcome. Inclusion of girls' prepubertal body mass index slightly attenuated these associations, but they remained significant. Monitoring of maternal weight before and throughout pregnancy may help prevent early pubertal onset and subsequent negative health J Epidemiol. 2019 Mar 15. The association of medical and demographic characteristics with sarcopenia and low muscle radiodensity in patients with nonmetastatic colorectal cancer Sarcopenia and low skeletal muscle radiodensity (SMD) have been associated with adverse outcomes in patients with colorectal cancer (CRC); however, factors contributing to these 2 muscle abnormalities are unclear. The aim of this study was to investigate the association of medical and demographic characteristics with muscle abnormalities among patients with nonmetastatic CRC. Patients with stage I-III invasive CRC (2006-11) who had diagnostic computed tomography (CT) available from Kaiser Permanente Northern California electronic medical records were included. CT-assessed sarcopenia and low SMD were defined according to optimal stratification. Logistic regressions including age, stage, site, total adipose tissue (TAT), race/ethnicity, neutrophil-lymphocyte ratio, smoking history, alcohol use, and Charlson Comorbidity Score were performed to identify characteristics associated with muscle abnormalities. The study included 3262 patients (49.9% females) with a mean \u00b1 SD age of 62.6 \u00b1 11.4 y. Sarcopenia and low SMD were highly prevalent (42.4% and 29.6%, respectively). Age and sex interactions were noted for muscle mass, but not SMD. Age was associated with higher odds of muscle abnormalities in a dose-response manner. Compared with those aged 50 y, patients aged 70-80 y had considerably higher odds (OR: 27.03). High TAT of low SMD (OR: 9.62; 95% CI: 0.48, 0.71). Compared with Caucasians, Americans had lower odds of sarcopenia and low SMD. Patients with a higher neutrophil-lymphocyte ratio had higher odds of having both muscle abnormalities. Patients who were smokers or had any comorbidity had higher odds of low SMD, but not sarcopenia. Muscle abnormalities were common in patients with nonmetastatic CRC, with great variability in muscle mass and SMD across age, TAT, and race/ethnicity. Factors associated with muscle abnormalities may be used to facilitate risk stratification and the guidance of targeted strategies to counteract these 03 01;109(3):615-625. Trends in marijuana use among pregnant women with and without nausea and vomiting in pregnancy, 2009-2016 Cross-sectional studies indicate an elevated prevalence of prenatal marijuana use in women with nausea and vomiting in pregnancy (NVP). However, it is unknown whether differences in marijuana use by NVP status have persisted over time as marijuana becomes more acceptable and accessible and prenatal use increases overall. We compared trends in prenatal marijuana use by NVP status in the first trimester of pregnancy using data from Kaiser Permanente Northern California's (KPNC) large healthcare system. The sample comprised KPNC pregnant women aged 12 who completed a self-administered questionnaire on marijuana use and a urine toxicology test for cannabis during standard prenatal care from 2009 to 2016. The annual prevalence of marijuana use via self-report or toxicology by NVP status was estimated using Poisson regression with a log link function, adjusting for sociodemographics and parity. We tested for linear trends and differences in trends by NVP. Of 220,510 pregnancies, 38,831 (17.6%) had an NVP diagnosis. Prenatal marijuana use was elevated each year among women with NVP. The adjusted prevalence of use increased significantly from 2009 to 2016 at an annual rate of 1.086 (95%CI = 1.069-1.104) among women 3.2%-3.7%) to 5.8% (95%CI = 5.5%-6.1%). Trends did not vary by NVP status. The prevalence of prenatal marijuana use has remained elevated over time among women with NVP. Clinicians should ask pregnant patients about their reasons for marijuana use and treat NVP 03 01;196:66-70. Epub 2019-01-18. Use of three summary measures of pediatric vaccination for studying the safety of the childhood immunization schedule Summary measures such as number of vaccine antigens, number of vaccines, and vaccine aluminum exposure by the 2nd birth day are directly related to parents' concerns that children receive too many vaccines over a brief period. High correlation among summary measures could cause problems in regression models that examine their associations with outcomes. To evaluate the performance of multiple regression models using summary measures as risk factors to simulated binary outcomes. We calculated summary measures for a cohort of 232,627 children born between 1/1/2003 and 9/31/2013. Correlation and variance inflation factors (VIFs) were calculated. We conducted simulations (1) to examine the extent to which an association can be detected using a summary measure other than the true risk factor; (2) to evaluate the performance of multiple regression models including true and redundant risk factors; (3) to evaluate the performance of multiple regression models when all three were risk factors; (4) to examine the performance of multiple regression models with incorrect relationship between risk factors and outcome. These summary measures were highly correlated. VIFs were 7.14, 6.25 and 2.17 for number of vaccine antigens, number of vaccines, and vaccine aluminum exposure, respectively. In simulations, an association would be detected if a summary measure other than the true risk factor was used. The power to detect the association between the true risk factor and outcome significantly decreased if redundant risk factors were included. When all three were risk factors, multiple regression model was appropriate to detect the stronger risk factor. Correctly specifying the relationship between risk factors and the outcome was crucial. Multiple regression models can be used to examine the association between summary measures and outcome despite of high correlation among summary measures. It is important to correctly specify the relationship between risk factors and outcome. Authors: Xu S; The Be-Well Study: a prospective cohort study of lifestyle and genetic factors to reduce the risk of recurrence and progression of non-muscle-invasive bladder cancer Bladder cancer is one of the top five cancers diagnosed in the U.S. with a high recurrence rate, and also one of the most expensive cancers to treat over the life-course. However, there are few observational, prospective studies of bladder cancer survivors. The Bladder Cancer Epidemiology, Wellness, and Lifestyle Study (Be-Well Study) is a National Cancer Institute-funded, multi-center prospective cohort study of non-muscle-invasive bladder cancer (NMIBC) patients (Stage Ta, T1, Tis) enrolled from the Kaiser Permanente Northern California (KPNC) and Southern California (KPSC) health care systems, with genotyping and biomarker assays performed at Roswell Park Comprehensive Cancer Center. The goal is to investigate diet and lifestyle factors in recurrence and progression of NMIBC, with genetic profiles considered, and to build a resource for future NMIBC studies. Recruitment began in February 2015. As of 30 June 2018, 1,281 patients completed the baseline interview (774 KPNC, 511 KPSC) with a recruitment rate of 54%, of whom 77% were male and 23% female, and 80% White, 6% Black, 8% Hispanic, 5% Asian, and 2% other race/ethnicity. Most patients were diagnosed with Ta (69%) or T1 (27%) tumors. Urine and blood specimens were collected from 67% and 73% of consented patients at baseline, respectively. To date, 599 and 261 patients have completed the 12- and 24-month follow-up questionnaires, respectively, with additional urine and saliva collection. The Be-Well Study will be able to answer novel questions related to diet, other lifestyle, and genetic factors and their relationship to recurrence and progression among early-stage bladder cancer 2019 Feb;30(2):187-193. Epub 2019-01-17. Long-term Risk of Colorectal Cancer and Related Deaths After a Colonoscopy With Normal Findings Guidelines recommend a 10-year rescreening interval after a colonoscopy with normal findings (negative colonoscopy results), but evidence supporting this recommendation is limited. To examine the long-term risks of colorectal cancer and colorectal cancer deaths after a negative colonoscopy result, in comparison with individuals unscreened, in a large, community-based setting. A retrospective cohort study was conducted in an integrated health care delivery organization serving more than 4 million members across Northern California. A total of 1?251?318 average-risk screening-eligible patients (age 50-75 years) between January 1, 1998, and December 31, 2015, were included. The study was concluded on December 31, 2016. Screening was examined as a time-varying exposure; all participants contributed person-time unscreened until they were either screened or censored. If the screening received was a negative colonoscopy result, the participants contributed person-time in the negative colonoscopy results group until they were censored. Using Cox proportional hazards regression models, the hazard ratios (HRs) for colorectal cancer and related deaths were calculated according to time since negative colonoscopy result (or since cohort entry for those unscreened). Hazard ratios were adjusted for age, sex, race/ethnicity, Charlson comorbidity score, and body mass index. Of the 1?251?318 patients, 613?692 were men (49.0%); mean age was 55.6 (7.0) years. Compared with the unscreened participants, those with a negative colonoscopy result had a reduced risk of colorectal cancer and related deaths throughout the more than 12-year follow-up period, and although reductions in risk were attenuated with increasing years of follow-up, there was a 46% lower risk of colorectal cancer (hazard ratio, 0.54; 95% CI, 0.31-0.94) and 88% lower risk of related deaths (hazard ratio, 0.12; 95% CI, 0.02-0.82) at the current guideline-recommended 10-year rescreening interval. A negative colonoscopy result in average-risk patients was associated with a lower risk of colorectal cancer and related deaths for more than 12 years after examination, compared with unscreened patients. Our study findings may be able to inform guidelines for rescreening after a negative colonoscopy result and future studies to evaluate the costs and benefits of earlier vs later rescreening intervals. Authors: 04;2(9):e1911513. Epub 2019-09-04. Long-Term Outcomes Among Patients Discharged From the Hospital With Moderate Anemia: A Retrospective Cohort Study Randomized clinical trial findings support decreased red blood cell (RBC) transfusion and short-term tolerance of in-hospital anemia. However, long-term outcomes related to changes in transfusion practice have not been described. To describe the prevalence of anemia at and after hospital discharge and associated morbidity and mortality events. Retrospective cohort study. Integrated health care delivery system with 21 hospitals serving 4 million members. 445 371 surviving adults who had 801 261 hospitalizations between January 2010 and December 2014. Hemoglobin levels and RBC transfusion, rehospitalization, and mortality events within 6 months of hospital discharge. Generalized estimating equations were used to examine trends over time, accounting for correlated observations and patient-level covariates. From 2010 to 2014, the prevalence of moderate anemia (hemoglobin levels between 7 and 10 g/dL) at hospital discharge increased from 20% to 25% (P < 0.001) and RBC transfusion declined by 28% (39.8 to 28.5 RBC units per 1000 patients; P < 0.001). The proportion of patients whose moderate anemia had resolved within 6 months of hospital discharge decreased from 42% to 34% (P < 0.001), and RBC transfusion and rehospitalization within 6 months of hospital discharge decreased from 19% to 17% and 37% to 33%, respectively (P < 0.001 for both). During this period, the adjusted 6-month mortality rate decreased from 16.1% to 15.6% (P = 0.004) in patients with moderate anemia, in parallel with that of all others. Possible unmeasured confounding. Anemia after hospitalization increased in parallel with decreased RBC transfusion. This increase was not accompanied by a rise in subsequent RBC use, rehospitalization, or mortality within 6 months of hospital discharge. Longitudinal analyses support the safety of practice recommendations to limit RBC transfusion and tolerate anemia during and after hospitalization. National Heart, Lung, and Blood Institute. Authors: Escobar GJ Ann Intern Med. 2019 01 01;170(1):80. Patients with complex chronic conditions: Health care use and clinical events associated with access to a patient portal For patients with diabetes, many with multiple complex chronic conditions, using a patient portal can support self-management and coordination of health care services, and may impact the frequency of in-person health care visits. To examine the impact of portal access on the number of outpatient visits, emergency visits, and preventable hospitalizations. Observational study comparing patients' visit rates with and without portal access, using marginal structural modeling with inverse probability weighting estimates to account for potential bias due to confounding and attrition. Large integrated delivery system which implemented a patient portal (2006-2007). We examined 165,447 patients with diabetes defined using clinical registries. Our study included both patients with diabetes-only and patients with multiple complex chronic conditions (diabetes plus asthma, congestive artery disease, congestive heart failure, or hypertension). We examined rates of outpatient office visits, emergency room visits, and preventable hospitalizations (for ambulatory care sensitive conditions). Access to a patient portal was associated with significantly higher rates of outpatient office visits, in both patients with diabetes only and in patients with multiple complex conditions (p<0.05). In patients with multiple complex chronic conditions, portal use was also associated with significantly fewer emergency room visits (3.9 fewer per 1,000 patients per month, p<0.05) and preventable hospital stays (0.8 fewer per 1,000 patients per month, p<0.05). In patients with only diabetes, the results were directionally consistent but not statistically significantly associated with emergency room visits and preventable hospital stays. Observational study in an integrated delivery system. Access to a patient portal can increase engagement in outpatient visits, potentially addressing unmet clinical needs, and reduce downstream health events that lead to emergency and hospital care, particularly among patients with multiple complex conditions. Authors: Reed ME; 2019;14(6):e0217636. Epub 2019-06-19. Potential Effects Of Eliminating The Individual Mandate Penalty In California The tax penalty for noncompliance with the Affordable Care Act's individual mandate is to be eliminated starting in 2019. We investigated the potential impact of this change on enrollees' decisions to purchase insurance and on individual-market premiums. In a survey of enrollees in the individual market in California in 2017, 19 percent reported that they would not have purchased insurance had there been no penalty. We estimated that premiums would increase by 4-7 percent if these enrollees were not in the risk pool. The percentages of enrollees who would forgo insurance were higher among those with lower income and education, Hispanics, and those who had been uninsured in the prior year, relative to the comparison groups. Compared to older enrollees and those with two or more chronic conditions, respectively, younger enrollees and those with no chronic conditions were also more likely to say that they would not have purchased insurance. Eliminating the mandate penalty alone is unlikely to destabilize the California individual market but could erode coverage gains, especially among groups whose members have historically been less likely to be insured. Authors: Fung V; Fireman B; Hsu J; et al. Health Aff (Millwood). 2018 12;37(12):1997-2004. Kidney function, proteinuria and breast arterial calcification in women without clinical cardiovascular disease: The MINERVA study Breast arterial calcification (BAC) may be a predictor of cardiovascular events and is highly prevalent in persons with end-stage kidney disease. However, few studies to date have examined the association between mild-to-moderate kidney function and proteinuria with BAC. We prospectively enrolled women with no prior cardiovascular disease aged 60 to 79 years undergoing mammography screening at Kaiser Permanente Northern California between 10/24/2012 and 2/13/2015. Urine albumin-to-creatinine ratio (uACR), along with specific laboratory, demographic, and medical data, were measured at the baseline visit. Baseline estimated glomerular filtration rate (eGFR), medication history, and other comorbidities were identified from self-report and/or electronic medical records. BAC presence and gradation (mass) was measured by digital quantification of full-field mammograms. Among 3,507 participants, 24.5% were aged 300 mg/g. The prevalence of any measured BAC (>0 mg) was 27.9%. Neither uACR 30 mg/g nor uACR 300 were significantly associated with BAC in crude or multivariable analyses. Reduced eGFR was associated with BAC in univariate analyses (odds ratio 1.53, 95% CI: 1.18-2.00), but the association was no longer significant after adjustment for potential confounders. Results were similar in various sensitivity analyses that used different BAC thresholds or analytic approaches. Among women without cardiovascular disease undergoing mammography screening, reduced eGFR and albuminuria were 2019-01-17. Shake Rattle & Roll - Design and rationale for a pragmatic trial to improve blood pressure control among blacks with persistent hypertension In Kaiser Permanente Northern California (KPNC), members had similar access to care and a very high overall rate of hypertension control. However, blacks had poorer blood pressure (BP) control than whites. The Shake Rattle & Roll (SRR) trial aimed to improve BP control rates in blacks and to reduce disparities in hypertension control. SRR was a cluster randomized controlled trial conducted at an urban medical center. All 98 adult primary care physicians (PCP) and their panels of hypertensive black patients were randomized, stratified by panel size, to one of three arms: 1) Usual Care (n?=?33 PCPs, N?=?1129 patients); 2) Enhanced Monitoring arm with an on improving pharmacotherapy protocol adherence (n?=?34 PCPs, N?=?349 patients); or 3) Lifestyle arm with a culturally tailored diet and lifestyle coaching intervention focusing on the Dietary Approaches to Stop Hypertension eating plan (n?=?31 PCPs, N?=?286 patients). The intervention period was for 12-months post-enrollment. Follow-up was planned for one and three years post-intervention completion. Primary outcome measure was the proportion of participants with controlled BP, defined as <140/90?mmHg, at 12-months post-enrollment. Secondary outcome included adverse cardiovascular events. An intention-to-treat analysis was carried out as the primary analysis. SRR was a uniquely designed trial that included components from both pragmatic and explanatory methods. The pragmatic aspects allow for a more cost-effective way to conduct a clinical trial and easier implementation of successful interventions into clinical practice. However, there were also challenges of having mixed methodology with regards to trial conduction and analysis. Authors: Nguyen-Huynh 01;76:85-92. Epub 2018-11-28. Automated symptom and treatment side effect monitoring for improved quality of life among adults with diabetic peripheral neuropathy in primary care: a pragmatic, cluster, randomized, controlled trial To evaluate the effectiveness of automated symptom and side effect monitoring on quality of life among individuals with symptomatic diabetic peripheral neuropathy. We conducted a pragmatic, cluster randomized controlled trial (July 2014 to July 2016) within a large healthcare system. We randomized 1834 primary care physicians and prospectively recruited from their lists 1270 individuals with neuropathy who were newly prescribed medications for their symptoms. Intervention participants received automated telephone-based symptom and side effect monitoring with physician feedback over 6 months. The control group received usual care plus three non-interactive diabetes educational calls. Our primary outcomes were quality of life (EQ-5D) and select symptoms (e.g. pain) measured 4-8 weeks after starting medication and again 8 months after baseline. Process outcomes included receiving a clinically effective dose and communication between individuals with neuropathy and their primary care provider over 12 months. Interviewers collecting outcome data were blinded to intervention assignment. Some 1252 participants completed the baseline measures [mean age (sd): 67 (11.7), 53% female, 57% total, 1179 participants (93%) completed follow-up (619 control, 560 intervention). \u00b1 0.094; control: 0.653 \u00b1 0.092) and symptom severity were similar at baseline. The intervention had no effect on primary [EQ-5D: -0.002 (95% CI -0.01, 0.01), P = 0.247] or process outcomes. Automated telephone monitoring and feedback alone were not effective at improving quality of life or symptoms for people with symptomatic diabetic peripheral 01;36(1):52-61. Epub 2018-11-07. Recurrence after hospitalization for acute coronary syndrome among HIV-infected and HIV-uninfected individuals We evaluated the association of HIV infection and immunodeficiency with acute coronary syndrome (ACS) recurrence, and with all-cause mortality as a secondary outcome, after hospitalization for ACS among HIV-infected and HIV-uninfected individuals. We conducted a retrospective cohort study within Kaiser Permanente Northern California of HIV-infected and HIV-uninfected adults discharged after ACS non-STEMI, or unstable angina] during We compared the outcomes of ACS recurrence and all-cause mortality within 3 years, both overall by HIV status and stratified by recent CD4 count, with HIV-uninfected individuals as the reference group. Hazard ratios (HRs) were obtained from Cox regression models with adjustment for age, sex, race/ethnicity, year, ACS type, smoking, and cardiovascular risk factors. Among 226 HIV-infected and 86 321 HIV-uninfected individuals with ACS, HIV-infected individuals had a similar risk of ACS recurrence compared with HIV-uninfected individuals [HR 1.08; 95% confidence interval (CI) 0.76-1.54]. HIV infection was independently associated with all-cause mortality after ACS hospitalization overall (HR 2.52; 95% CI 1.81-3.52). In CD4-stratified models, post-ACS mortality was for HIV-infected with counts of 201-499 cells/?L (HR 5.41; 95% CI 3.14-9.34), but not those with counts ? 500 cells/?L (HR 0.67; 95% CI 0.22-2.08), compared with HIV-uninfected individuals (P trend < 0.001). HIV infection and immunodeficiency were not associated with recurrence of ACS after hospitalization. All-cause mortality was higher among HIV-infected compared with HIV-uninfected individuals, but there was no excess mortality risk among HIV-infected individuals with high CD4 Postcolonoscopy colorectal cancers (PCCRCs) are defined as those detected 10 years after an index colonoscopy negative for cancer, but modifiable risk factors are not well established in large, community-based populations. We evaluated risk factors from the index colonoscopy for PCCRCs diagnosed 1 to 10 years after an index colonoscopy using a case-control design. Odds ratios (OR) and 95% confidence intervals (CI) were adjusted for potential confounders. A proximal polyp 10 mm (OR, (OR, an incomplete 5.52; 95% CI, 2.98-10.21) were associated with PCCRC. Risk factors for early versus late cancers (12-36 months vs >36 months to 10 years after examination) included incomplete polyp excision in the colonic segment of the subsequent cancer (OR, 4.76; 95% CI, 2.35-9.65); failure to examine the segment (OR, 2.42; 95% CI, 1.27-4.60); and a polyp 10 mm in the segment (OR, 2.38; 95% CI, 1.53-3.70). A total of 559 of 1206 patients with PCCRC (46.4%) had 1 or more risk factors that were significant for PCCRC (incomplete examination, large polyp, or any adenoma). In a large community-based study with comprehensive capture of PCCRCs, almost half of PCCRCs had potentially modifiable factors related to polyp surveillance or removal and examination completeness. These represent potential high-yield targets to further increase the effectiveness of colorectal cancer 2018-08-23. Birth in High Infant Mortality States and Dementia Risk in a Cohort of Elderly African American and White Health Care Members Birth in areas with high infant mortality rates (IMRs) has been linked to worse long-term health outcomes, yet it is completely unknown if it impacts dementia risk. In total 6268 health care members were followed for dementia diagnosis from 1996 to 2015. Birth state IMRs from 1928 were ranked into quartile (worst IMRs quartile range, whites: 69 to 129 deaths/1000 live births, Non-whites: 129 to 277 deaths/1000 live births). Cox proportional hazard models estimated the dementia risk associated with birth state IMR quartile adjusting for demographics and lifecourse health indicators. Compared with whites born outside of states in the worst IMR quartile, African Americans born in states in the worst IMR quartile had 92% increased dementia risk (HR=1.92; 95% CI: 1.42, 2.59), and African Americans born outside those states had 36% increased risk (HR=1.36; 95% CI: 1.20, 1.53). There was no association between birth state IMR and dementia risk among whites. Birth in states with the highest rates of infant mortality was associated with elevated dementia risk among African Americans but not whites. The large absolute difference in IMRs likely reflects harsher early childhood conditions experienced by African Americans. These findings suggest that childhood conditions may play a role in racial disparities in dementia Jan-Mar;33(1):1-6. Patterns of medication adherence in a multi-ethnic cohort of prevalent statin users diagnosed with breast, prostate, or colorectal cancer To investigate the implications of a cancer diagnosis on medication adherence for pre-existing comorbid conditions, we explored statin adherence patterns prior to and following a new diagnosis of breast, colorectal, or prostate cancer among a multi-ethnic cohort. We identified adults enrolled at Kaiser Permanente Northern California who were prevalent statin medication users, newly diagnosed with breast, colorectal, or prostate cancer between 2000 and 2012. Statin adherence was measured using the proportion of days covered (PDC) during the 2-year pre-cancer diagnosis and the 2-year post-cancer diagnosis. Adherence patterns were assessed using generalized estimating equations, for all cancers combined and stratified by cancer type and race/ethnicity, adjusted for demographic, clinical, and tumor characteristics. Among 10,177 cancer patients, statin adherence decreased from pre- to post-cancer diagnosis (adjusted odds ratio (ORadj):0.91, 95% confidence interval (95% CI):0.88-0.94). Statin adherence decreased 95% CI:0.90-0.99) and colorectal (ORadj:0.79, 95% CI:0.74-0.85) cancer patients. No difference in adherence was observed among prostate cancer patients (ORadj:1.01, 95% CI:0.97-1.05). Prior to cancer diagnosis, adherence to statins was generally higher among non-Hispanic whites and multi-race patients than other groups. However, statin adherence after diagnosis decreased only among these two populations (ORadj:0.85, 95% CI:0.85-0.92 and ORadj:0.86, 95% CI:0.76-0.97), respectively. We found substantial variation in statin medication adherence following diagnosis by cancer type and race/ethnicity among a large cohort of prevalent statin users in an integrated health care setting. Improving our understanding of comorbidity management and polypharmacy across diverse cancer patient populations is warranted to develop tailored interventions that improve medication adherence and reduce disparities in health outcomes. Authors: 2018-10-18. Prevalence and predictors of delayed clinical diagnosis of Type 2 diabetes: a longitudinal cohort study To examine the prevalence and person-level predictors of undiagnosed Type 2 diabetes among adults with elevated HbA1c values. We identified adults without diabetes who had a first elevated HbA1c (index HbA1c 48 mmol/mol; 6.5%) between January 2014 and December 2015, and classified them by Type 2 diabetes diagnosis status at 1 year following this result. Multilevel modelling techniques were used to examine the association of individual demographic, clinical, and utilization characteristics with remaining undiagnosed. We quantified differences in early Type 2 diabetes care between diagnosed and undiagnosed individuals. Of the 18 356 adults with a first elevated index HbA1c , 30.2% remained undiagnosed with Type 2 diabetes 1 year later. Individuals with lower index HbA1c values [adjusted odds ratio (aOR) 5.95, 95% 95% CI 1.24-1.59; referent 50-59 years), (aOR 1.35, 95% CI 1.24-1.47; referent no prediabetes) had increased odds of remaining undiagnosed. After adjusting for age, race, and index HbA1c , remaining undiagnosed was associated with lower odds of initiating metformin (aOR 0.06, 95% CI 0.05-0.07). Almost one-third of adults with an elevated HbA1c value were not diagnosed with Type 2 diabetes within 1 year. Undiagnosed Type 2 diabetes, in turn, was associated with differences in early care. Strategies that leverage the electronic health record to facilitate earlier diagnosis may help reduce delays and allow for early intervention towards the goal of improved 12;35(12):1655-1662. Epub 2018-09-21. Central Obesity Increases the Risk of Gestational Diabetes Partially Through Increasing Insulin Resistance This study examined the associations of central obesity measures, waist to hip ratio (WHR) and waist circumference (WC), in early pregnancy with subsequent risk of gestational diabetes mellitus (GDM) and evaluated the potential mediating role of insulin resistance markers. Within the prospective Pregnancy Environment and Lifestyle Study cohort of 1,750 women, WC and hip circumference were measured at gestational weeks 10 to 13. In a nested case-control study within the cohort, 115 GDM cases and 230 controls had fasting serum insulin, homeostatic model assessment of insulin resistance (HOMA-IR), and adiponectin measurements at gestational weeks 16 to 19. Poisson and conditional logistic regression models were used, adjusting for established risk factors for GDM, including prepregnancy overweight or obesity. For A Obesity (Silver Spring). 2018 Nov 21. Examining the role of access to care: Racial/ethnic differences in receipt of resection for early-stage non-small cell lung cancer among integrated system members and non-members To examine the role of uniform access to care in reducing racial/ethnic disparities in receipt of resection for early stage non-small cell lung cancer (NSCLC) by comparing integrated health system member patients to demographically similar non-member patients. Using data from the California Cancer Registry, we conducted a retrospective cohort study of patients from four racial/ethnic groups (White, Black, Hispanic, Asian/Pacific Islander), aged 21-80, with a first primary diagnosis of stage I or II NSCLC between 2004 and 2011, in counties served by Kaiser Permanente Northern California (KPNC) at diagnosis. Our cohort included 1565 KPNC member and 4221 non-member patients. To examine the relationship between race/ethnicity and receipt of surgery stratified by KPNC membership, we used modified Poisson regression to calculate risk ratios (RR) adjusted for patient demographic and tumor characteristics. Black patients were least likely to receive surgery regardless of access to integrated care (64-65% in both groups). The magnitude of the black-white difference in the likelihood of surgery receipt was similar for members members, roughly equal proportions of Hispanic and White patients received surgery; however, among non-members, Hispanic patients were less likely to surgical treatment for NSCLC were not reduced through integrated health system membership, suggesting that factors other than access to care (e.g., patient-provider communication) may underlie disparities. Future research should focus on identifying such modifiable Effects of Organized Colorectal Cancer Screening on Cancer Incidence and Mortality in a Large, Community-based Population Little information is available on the effectiveness of organized colorectal cancer (CRC) screening on screening uptake, incidence, and mortality in community-based populations. We contrasted screening rates, age-adjusted annual CRC incidence, and incidence-based mortality rates before (baseline year 2000) and after (through 2015) implementation of organized screening outreach, from 2007 through 2008 (primarily annual fecal immunochemical testing and colonoscopy), in a large community-based population. Among screening-eligible individuals 51-75 years old, we calculated annual up-to-date status for cancer screening (by fecal test, sigmoidoscopy, or colonoscopy), CRC incidence, cancer stage distributions, and incidence-based mortality. Initiation of organized CRC screening significantly increased the up-to-date status of screening, from 38.9% in 2000 to 82.7% in 2015 (P < .01). Higher rates of screening were associated with a 25.5% reduction in annual CRC incidence between 2000 and 2015, from 95.8 to 71.4 cases/100,000 (P < .01), and a 52.4% reduction in cancer mortality, from 30.9 to 14.7 deaths/100,000 (P < .01). Increased screening was initially associated with increased CRC incidence, due largely to greater detection of early-stage cancers, followed by decreases in cancer incidence. Advanced-stage CRC incidence rates decreased 36.2%, from 45.9 to 29.3 cases/100,000 (P < .01), and early-stage CRC incidence rates decreased 14.5%, from 48.2 to 41.2 cases/100,000 (P < .04). Implementing an organized CRC screening program in a large community-based population rapidly increased screening participation to the 80% target set by national organizations. Screening rates were sustainable and associated with substantial decreases in CRC incidence and mortality within short time intervals, consistent with early detection and cancer prevention. Authors: Levin Epub 2018-07-19. Adverse Selection into and within the Individual Health Insurance Market in California in 2014 The Affordable Care Act (ACA) introduced reforms to mitigate adverse selection into and within the individual insurance market. We examined the traits and predicted medical spending of enrollees in California post-ACA. Survey of 2,103 enrollees in individual market plans, on- and off-exchange, in 2014. We compared actual versus potential participants using data from the 2014 California Health Interview Survey on respondents who were individually insured or uninsured. We predicted annual medical spending for each group using age, sex, self-rated health, body mass index, smoking status, and income. Average predicted spending was similar for actual ($3,377, 95 percent CI [$3,280-$3,474]) and potential participants ($3,257 [$3,060-$3,454]); however, some vulnerable subgroups were underrepresented. On- versus off-exchange enrollees differed in sociodemographic and health traits with modest differences in spending ($3,448 [$3,330-$3,565] vs. $3,175 [$3,012-$3,338]). We did not find evidence of selection into the overall insurance pool in 2014; however, differences by exchange status reflect the importance of including off-exchange enrollees in analyses and the pool for risk adjustment. California's post-ACA individual market has been a relative success, highlighting the importance of state policies and outreach efforts to encourage participation in the market. Authors: Fung V; 2018 10;53(5):3750-3769. Epub 2018-05-17. Early Midlife Pulmonary Function and Dementia Risk Poor pulmonary function (PPF) is associated with increased risk of dementia, yet it is unclear if PPF in early adulthood to midlife increases risk, independent of smoking and subsequent vascular disease. This study evaluated the association between multiple markers of PPF in early adulthood to midlife and long-term risk of dementia. We evaluated 27,387 members of an integrated health care system with forced expiratory volume in 1, 2 seconds, and vital capacity collected from 1964 to 1973 (mean age=41.8\u00b14.2 y). Associations of PPF with dementia diagnoses from January 1, 1996 to September 30, 2015 were evaluated with Cox proportional hazards models adjusted for demographics, height, body mass index, hypertension, smoking status, diabetes, stroke, and heart failure. In total, 7519 individuals (27%) were diagnosed with dementia. In fully adjusted Cox proportional hazards models, for all PPF measures each liter decrease was associated with a 13% to 14% higher risk of dementia. Compared with the highest quintile, the first quintile of PPF measures were associated with a 24% to 28% increased risk of dementia; second to fourth quintiles showed strong dose-dependent associations. Results were similar when stratified by smoking status. In this large, diverse cohort, multiple measures of PPF in early adulthood to midlife were associated with dementia risk independent of smoking Oct-Dec;32(4):270-275. Association of raltegravir use with long-term health outcomes in HIV-infected patients: an observational post-licensure safety study in a large integrated healthcare system Raltegravir became the first integrase inhibitor to gain FDA approval; but with limited evidence documenting long-term risks in real world care, especially for major health outcomes of interest. Assess raltegravir safety in clinical practice within an integrated health system. We conducted a cohort study of HIV-infected adults within Kaiser Permanente California from 2005 to 2013. We compared patients initiating raltegravir during the study period with two groups; a historical cohort (started new antiretroviral regimen [ART] 2005-2007) and a concurrent cohort that did not initiate raltegravir (2007-2013). We used multivariate Cox proportional hazard regression to obtain hazard ratios (HR) for pre-specified incident health outcomes, employing propensity scores to adjust for potential confounding. The population included 8,219 HIV-infected adults (raltegravir cohort N = 1,757; 4,798 patient-years), greater years known HIV-infected among raltegravir patients. The raltegravir cohort had increased HR for AIDS-defining (HR 2.69 [1.53-4.71]; HR 1.85 [1.21-2.82]) and non-AIDS-defining malignancies (HR 2.26 [1.29-3.94]; HR 1.88 [1.26-2.78]) relative to both comparison cohorts. Compared to the historical cohort we found no significant difference in all-cause mortality; the raltegravir cohort experienced increased HR for all-cause mortality compared to concurrent (HR 1.53 [1.02-2.31]). Raltegravir appeared protective of lipodystrophy when compared to the historical cohort but associated with increased incidence compared to concurrent. There were no significant differences in the incidence of hepatic, skin, or cardiovascular events. The potentially elevated risk for malignancy and mortality with raltegravir and residual confounding merits further investigation. We demonstrate the value of observational cohorts for monitoring post-licensure medication safety. Authors: Pre-Pregnancy Biomarker Risk Score Improves Prediction of Future Gestational Diabetes Previous studies have not examined the ability of multiple preconception biomarkers, considered together, to improve prediction of gestational diabetes mellitus (GDM). To develop a preconception biomarker risk score and assess its association with subsequent GDM. A nested case-control study among a cohort of women with serum collected as part of a health examination (1984 to 1996) and subsequent pregnancy (1984 to 2009). Biomarkers associated with GDM were dichotomized into high/low risk. Integrated health care system. Two controls were matched to each GDM case (n = 256 cases) on year and age at examination, age at pregnancy, and number of pregnancies between examination and index pregnancy. GDM. High-risk levels of sex hormone-binding CI: 1.07, 2.62) times the odds of GDM and included in the biomarker risk score. For each unit increase in the biomarker risk score, odds of GDM were 1.94 times greater (95% CI: 1.59, 2.36). A biomarker risk score including only SHBG and glucose was sufficient to improve prediction beyond established risk factors (age, race/ethnicity, body mass index, family history of diabetes, previous GDM; area under the curve = 0.73 vs 0.67, P = 0.002). The improved, predictive ability of the biomarker risk score beyond established risk factors suggests clinical use of the biomarker risk score in identifying women at risk for GDM before conception for targeted prevention strategies. Authors: Oct 01;2(10):1158-1169. Epub 2018-09-13. Traumatic brain injury associated with dementia risk among people with type 1 diabetes To examine the association between traumatic brain injury (TBI) and dementia risk among a cohort of middle-aged and elderly individuals with type 1 diabetes (T1D). We evaluated 4,049 members of an integrated health care system with T1D 50 years old between January 1, 1996, and September 30, 2015. Dementia and TBI diagnoses throughout the study period were abstracted from medical records. Cox proportional hazards models estimated associations between time-dependent TBI and dementia adjusting for demographics, HbA1c, nephropathy, neuropathy, stroke, peripheral artery disease, depression, and dysglycemic events. Fine and Gray regression models evaluated the association between baseline TBI and dementia risk accounting for competing risk of death. A total of 178 individuals (4.4%) experienced a TBI and 212 (5.2%) developed dementia. In fully adjusted models, TBI was associated with 3.6 times the dementia risk (hazard ratio [HR] 3.64; 95% confidence interval [CI] 2.34, 5.68). When accounting for the competing risk of death, TBI was associated with almost 3 times the risk of dementia (HR 2.91; 95% CI 1.29, 5.68). This study demonstrates a marked increase in risk of dementia associated with TBI among middle-aged and elderly people with T1D. Given the complexity of self-care for individuals with T1D, and the comorbidities that predispose them to trauma and falls, future work is needed on interventions protecting brain health in this vulnerable population, which is now living to old 26. Long-term Glycemic Control and Dementia Risk in Type 1 Diabetes Individuals with type 1 diabetes have experienced an increase in life expectancy; yet, it is unknown what level of glycemic control is ideal for maintaining late-life brain health. We investigated the association of long-term glycemic control with dementia in older individuals with type 1 diabetes. We followed 3,433 members of a health care system with type 1 diabetes, ages 50 years, from 1996 to 2015. Repeated measurements of hemoglobin A1c (HbA1c), dementia diagnoses, and comorbidities were ascertained from health records. Cox proportional hazards models were fit to evaluate the association of time-varying glycemic exposure with dementia, with adjustment for age, sex, race/ethnicity, baseline health conditions, and frequency of HbA1c measurement. Over a mean follow-up of 6.3 years, 155 individuals (4.5%) were diagnosed with dementia. Patients with 50% of HbA1c measurements at 8-8.9% (64-74 mmol/mol) and 9% (75 mmol/mol) had 65% and 79% higher risk of dementia, respectively, compared with 04. Comparison of privacy-protecting analytic and data-sharing methods: A simulation study Privacy-protecting analytic and data-sharing methods that minimize the disclosure risk of sensitive information are increasingly important due to the growing interest in utilizing data across multiple sources. We conducted a simulation study to examine how avoiding sharing individual-level data in a distributed data network can affect analytic results. The base scenario had four sites of varying sizes with 5% outcome incidence, 50% treatment prevalence, and seven confounders. We varied treatment prevalence, outcome incidence, treatment effect, site size, number of sites, and covariate distribution. Confounding adjustment was conducted using propensity score or disease risk score. We compared analyses of three types of aggregate-level data requested from sites: risk-set, summary-table, or effect-estimate data (meta-analysis) with benchmark results of analysis of pooled individual-level data. We assessed bias and precision of hazard ratio estimates as well as the accuracy of standard error estimates. All the aggregate-level data-sharing approaches, regardless of confounding adjustment methods, successfully approximated pooled individual-level data analysis in most simulation scenarios. Meta-analysis showed minor bias when using inverse probability of treatment weights (IPTW) in infrequent exposure (5%), rare outcome (0.01%), and small site (5,000 patients) settings. SE estimates became less accurate for IPTW risk-set approach with less frequent exposure and for propensity score-matching meta-analysis approach with rare outcomes. Overall, we found that we can avoid sharing individual-level data and obtain valid results in many settings, although care must be taken with meta-analysis approach in infrequent exposure and rare outcome scenarios, particularly when confounding adjustment is performed with IPTW. Authors: Yoshida K; Gruber 09;27(9):1034-1041. Epub 2018-07-18. Use of non-steroidal anti-inflammatory drugs during pregnancy and the risk of miscarriage Nonsteroidal antiinflammatory drugs are among the medications most widely used by pregnant women, and previous studies have reported an increased risk of miscarriage that is associated with nonsteroidal antiinflammatory drug use during pregnancy. Although the findings have not always been consistent, there is a well-established mechanism for the association: nonsteroidal antiinflammatory drugs inhibit the production of prostaglandin, which is essential for successful embryonic implantation. Abnormal implantation increases the risk of miscarriage. The purpose of this study was to examine the impact of nonsteroidal antiinflammatory drug use in early pregnancy on the risk of miscarriage, especially regarding the timing and duration of use. We conducted a cohort study among pregnant members of Kaiser Permanente Northern California, an integrated healthcare delivery system. Pregnant Kaiser Permanente Northern California members (N=1097) were recruited very early in pregnancy (median gestational age at enrollment, 39 days) to achieve optimal ascertainment of miscarriage, including early miscarriages, which are often missed in studies of miscarriages. Based on the use of nonsteroidal antiinflammatory drugs and acetaminophen, which has similar indication as nonsteroidal antiinflammatory drugs, 3 cohorts were formed: (1) women who used nonsteroidal antiinflammatory drugs only, (2) women who used acetaminophen only (to control for indication), and (3) women who used neither nonsteroidal antiinflammatory drugs nor acetaminophen (unexposed control subjects). Among all eligible women contacted, 63% participated in the study. Miscarriages were ascertained from both electronic medical record data and directly from interviews with participants. The Cox proportional hazards model with accommodation for left truncation was used to examine the risk of miscarriage associated with the use of nonsteroidal antiinflammatory drugs and acetaminophen during pregnancy; we controlled for potential confounders. After an adjustment for multiple confounders that included maternal age, previous miscarriage, multivitamin use, caffeine drinking, and smoking during pregnancy, we found that nonsteroidal antiinflammatory drug use during pregnancy was associated with a statistically significant increased risk of miscarriage compared with both unexposed control subjects (adjusted hazard ratio, 1.59; 95% confidence interval, 1.13-2.24) and acetaminophen users (indication control subjects; adjusted hazard ratio, 1.45; 95% confidence interval, 1.01-2.08). The risk was largely due to nonsteroidal antiinflammatory drug use around conception (adjusted hazard ratio, 1.89; 95% confidence interval, 1.31-2.71) with a statistically significant dose-response relationship: adjusted hazard ratio, 1.37 (95% confidence interval, 0.70-2.71) for nonsteroidal antiinflammatory drug use of 14 days; adjusted hazard ratio, 1.85 (95% confidence interval, 1.24-2.78) for nonsteroidal antiinflammatory drug use of 15 days. The association was stronger for early miscarriage (<8 weeks gestational age): adjusted hazard ratio, 4.08 (95% confidence interval, 2.25-7.41). Women with lower body mass index (<25 kg/m2) appeared to be more susceptible to the effect of nonsteroidal antiinflammatory drug use around conception (adjusted hazard ratio, 3.78; 95% confidence interval, 2.04-6.99) than women with high body mass index (25 kg/m2; adjusted hazard ratio, 1.03; 95% confidence interval, 0.61-1.72). After we controlled for confounding by indication, nonsteroidal antiinflammatory drug use around conception was associated with an increased risk of miscarriage with a dose-response relationship. In addition, women with lower body mass index could be especially vulnerable to the effects of nonsteroidal antiinflammatory drug use around the time of embryonic implantation, although this new observation must be confirmed in future studies. Authors: Li DK; Cutaneous Melanoma Risk among People with HIV in the United States and Canada Cutaneous melanoma incidence may be modestly elevated in people with HIV (PWH) vs. people without HIV. However, little is known about the relationship of immunosuppression, HIV replication, and antiretroviral therapy (ART) with melanoma risk. PWH of white race in the North American AIDS Cohort Collaboration on Research and Design were included. A standardized incidence ratio was calculated comparing risk with the white general population, standardizing by age, sex, and calendar period. Associations between melanoma incidence and current, lagged, and cumulative measures of CD4 count, HIV RNA level, and ART use were estimated with Cox regression, adjusting for established risk factors such as age and annual residential ultraviolet B (UVB) exposure. Eighty melanomas were diagnosed among 33,934 white PWH (incidence = 40.75 per 100,000 person-years). Incidence was not elevated compared with the general population [standardized incidence ratio = 1.15, 95% confidence interval (95% CI) = 0.91 to 1.43]. Higher melanoma incidence was associated with older age [adjusted hazard ratio (aHR) per decade increase = 1.50, 95% CI = 1.20 to 1.89] and higher UVB exposure (aHR for exposure 35 vs. <35 mW/m = 1.62, 95% CI = 0.99 to 2.65). Current, lagged, and cumulative CD4 and HIV RNA were not associated with melanoma incidence. Melanoma incidence was higher among people ART-treated for a larger proportion of time in the previous 720 days (aHR per 10% increase = 1.16, 95% CI = 1.03 to 1.30). These results suggest that HIV-induced immune dysfunction does not influence melanoma development. The association between ART and melanoma risk may be due to increased skin surveillance among PWH engaged in clinical care. Associations with age and UVB confirmed those established in the general Syndr. 2018 08 15;78(5):499-504. Relative Performance of Propensity Score Matching Strategies for Subgroup Analyses Postapproval drug safety studies often use propensity scores (PSs) to adjust for a large number of baseline confounders. These studies may involve examining whether treatment safety varies across subgroups. There are many ways a PS could be used to adjust for confounding in subgroup analyses. These methods have trade-offs that are not well understood. We conducted a plasmode simulation to compare relative performance of 5 methods involving PS matching for subgroup analysis, including methods frequently used in applied literature whose performance has not been previously directly compared. These methods varied as to whether the overall PS, subgroup-specific PS, or no rematching was used in subgroup analysis as well as whether subgroups were fully nested within the main analytical cohort. The evaluated PS subgroup matching methods performed similarly in terms of balance, bias, and precision in 12 simulated scenarios varying size of the cohort, prevalence of exposure and outcome, strength of relationships between baseline covariates and exposure, the true effect within subgroups, and the degree of confounding within subgroups. Each had strengths and limitations with respect to other performance metrics that could inform choice of method. Authors: Wang SV; Fireman B; Gagne JJ; et al. Am J Epidemiol. 2018 08 01;187(8):1799-1807. Disparities in Initiation of Direct-Acting Antiviral Agents for Hepatitis C Virus Infection in an Insured Population The cost of direct-acting antiviral agents (DAAs) for hepatitis C virus (HCV) infection may contribute to treatment disparities. However, few data exist on factors associated with DAA initiation. We conducted a retrospective cohort study of HCV-infected Kaiser Permanente Northern California members aged 18 during October 2014 to December 2016, using Poisson regression models to evaluate demographic, behavioral, and clinical factors associated with DAA initiation. Of 14 790 HCV-infected patients aged 18 6148 (42%) initiated DAAs. DAA initiation was less likely among patients who were non-Hispanic black (adjusted rate ratio [aRR] = 0.7; 95% confidence interval [CI], 0.7-0.8), Hispanic (aRR 0.8; 95% CI, 0.7-0.9), and other minority races/ethnicities (aRR = 0.9; 95% CI, 0.8-1.0) than among non-Hispanic white people and among those with lowest compared with highest neighborhood deprivation index (ie, a marker of socioeconomic status) (aRR = 0.8; 95% CI, 0.7-0.8). Having maximum annual out-of-pocket health care costs >$3000 compared with $3000 (aRR = 0.9; 95% CI, 0.8-0.9) and having Medicare (aRR = 0.8; 95% CI, 0.8-0.9) or Medicaid (aRR = 0.7; 95% CI, 0.6-0.8) compared with private health insurance were associated with a lower likelihood of DAA initiation. Behavioral factors (eg, drug abuse diagnoses, alcohol use, and smoking) were also significantly associated with a lower likelihood of DAA initiation (all P < .001). Clinical factors associated with a higher likelihood of DAA initiation were advanced liver fibrosis, HCV genotype 1, previous HCV treatment (all P < .001), and HIV infection ( P = .007). Racial/ethnic and socioeconomic disparities exist in DAA initiation. Substance use may also influence patient or provider decision making about DAA initiation. Strategies are needed to ensure equitable access to DAAs, even in insured populations. Authors: Marcus JL; Lam JO; Quesenberry CP; Rep. 2018 Jul/Aug;133(4):452-460. Epub 2018-05-11. Associations Between Maternal Obesity and Pregnancy Hyperglycemia and Timing of Pubertal Onset in Adolescent Girls: A Population-Based Study Early puberty is associated with adverse health outcomes. We investigated whether in utero exposure to maternal obesity is associated with daughters' pubertal timing using 15,267 racially/ethnically diverse Kaiser Permanente Northern California members aged 6-11 years with pediatrician-assessed Tanner staging (2003-2017). We calculated maternal body mass index (BMI; weight (kg)/height (m)2) during pregnancy from the electronic health record data. Using a proportional hazards model with interval censoring, we examined the associations between maternal obesity and girls' pubertal timing, as well as effect modification by race/ethnicity and mediation by prepubertal BMI. Maternal obesity (BMI 30) and overweight (BMI 25-29.9) were associated with earlier onset of breast development in girls (hazard ratio (HR) = 1.39 (95% confidence interval (CI): 1.30, 1.49) and HR = 1.21 (95% CI: 1.13, 1.29), respectively), after adjustment for girl's race/ethnicity, maternal age, education, parity, and smoking during pregnancy. There was interaction by race/ethnicity for associations between maternal obesity and girls' pubic hair onset: Associations were strongest among Asian and non-Hispanic white girls (HR = 1.53 (95% CI: 1.24, 1.90) and HR = 1.34 (95% CI: 1.18, 1.52), respectively) and absent for African-American girls. Adjustment for girl's prepubertal BMI only slightly attenuated associations. Our results suggest the importance of maternal metabolic factors during pregnancy in the timing of girls' puberty and potential differences in the associations Erratum: High-dimensional propensity score adjustment in studies of treatment effects using health care claims data Authors: Wyss R; Fireman B; Rassen JA; Schneeweiss S Epidemiology. 2018 Jun 27. Association of Muscle and Adiposity Measured by Computed Tomography With Survival in Patients With Nonmetastatic Breast Cancer Sarcopenia (low muscle mass), poor muscle quality (low muscle radiodensity), and excess adiposity derived from computed tomography (CT) has been related to higher mortality in patients with metastatic breast cancer, but the association with prognosis in patients with nonmetastatic breast cancer is unknown. To evaluate associations of all 3 body composition measures, derived from clinically acquired CT at diagnosis, with overall mortality in nonmetastatic breast cancer. This observational study included 3241 women from Kaiser Permanente of Northern California and Dana Farber Cancer Institute diagnosed from January 2000 to December 2013 with stages II or III breast cancer. We calculated hazard ratios (HRs) to evaluate the associations of all-cause mortality with sarcopenia, low muscle radiodensity, and total adipose tissue (TAT). Models were adjusted for sociodemographics, tumor characteristics, treatment, body mass index (BMI; calculated as weight in kilograms divided by height in meters squared), and other body composition measures. We also evaluated the cross-classification of categories of sarcopenia (yes/no) and tertiles of TAT, with outcomes. Overall survival time and all-cause mortality. Median (range) age of 3241 women included in this study was 54 (18-80) years, and median follow-up was 6.0 years; 1086 patients (34%) presented with sarcopenia, and 1199 patients (37%) had low muscle radiodensity. Among patients with nonmetastatic breast cancer, those with sarcopenia showed higher overall mortality (HR, 1.41; 95% CI, 1.18-1.69) compared with those without sarcopenia. Patients in the highest tertile of TAT also showed higher overall mortality (HR, 1.35; 95% CI, 1.08-1.69) compared with those in the lowest tertile. Low radiodensity was not associated with survival. In analyses of sarcopenia and TAT, highest mortality was seen in patients with sarcopenia and high TAT (HR, 1.89; 95% CI, 1.30-2.73); BMI alone was not significantly related to overall mortality and did not appropriately identify patients at risk of death owing to their body composition. Sarcopenia is underrecognized in nonmetastatic breast cancer and occurs in over one-third of newly diagnosed patients. Measures of both sarcopenia and adiposity from clinically acquired CT scans in nonmetastatic patients provide significant prognostic information that outperform BMI and will help to guide interventions to optimize mapping of traffic related air pollution with Google street view cars and incidence of cardiovascular events within neighborhoods in Oakland, CA Some studies have linked long-term exposure to traffic related air pollutants (TRAP) with adverse cardiovascular health outcomes; however, previous studies have not linked highly variable concentrations of TRAP measured at street-level within neighborhoods to cardiovascular health outcomes. Long-term pollutant concentrations for nitrogen dioxide [NO2], nitric oxide [NO], and black carbon [BC] were obtained by street-level mobile monitoring on 30 m road segments and linked to residential addresses of 41,869 adults living in Oakland during 2010 to 2015. We fit Cox proportional hazard models to estimate the relationship between air pollution exposures and time to first cardiovascular event. Secondary analyses examined effect modification by diabetes and age. Long-term pollutant concentrations [mean, (standard deviation; SD)] for NO2, NO and BC were 9.9 ppb (SD 3.8), 4.9 ppb (SD 3.8), and 0.36 g/m3 (0.17) respectively. A one SD increase in NO2, NO and BC, was associated with a change in risk of a cardiovascular event of 3% (95% confidence interval CI -8% to 7%), respectively. Among the elderly (65 yrs), we found an increased risk of a cardiovascular event of 12% for 17%) per one SD increase. We found no effect modification by diabetes. Street-level differences in long-term exposure to TRAP were associated with higher risk of cardiovascular events among the elderly, indicating that within-neighborhood differences in TRAP are important to cardiovascular health. Associations among the general population were consistent with results found in previous studies, though not statistically significant. Authors: Alexeeff 2018-05-15. A Cohort Study of Metformin and Colorectal Cancer Risk among Patients with Diabetes Mellitus Background: Several epidemiologic studies have reported strong inverse associations between metformin use and risk of colorectal cancer, although time-related biases, such as immortal time bias, may in part explain these findings. We reexamined this association using methods to minimize these biases.Methods: A cohort study was conducted among 47,351 members of Kaiser Permanente Northern California with diabetes and no history of cancer or metformin use. Follow-up for incident colorectal cancer occurred from January 1, 1997, until June 30, 2012. Cox regression was used to calculate HRs and 95% confidence intervals (CIs) for colorectal cancer risk associated with metformin use (ever use, total duration, recency of use, and cumulative dose).Results: No association was observed between ever use of metformin and colorectal cancer risk (HR, 0.90; 95% CI, 0.76-1.07) and there was no consistent pattern of decreasing risk with increasing total duration, dose, or recency of use. However, long-term use (5.0 years) appeared to be associated with reduced risk of colorectal cancer in the full population (HR, 0.78; 95% CI, 0.60-1.02), among current users (HR, 0.78; 95% 0.59-1.04), and in men (HR, 0.65; 95% CI, 0.45-0.94) but not in women. Higher cumulative doses of metformin were associated with reduced risk. In initial users of sulfonylureas, switching to or adding metformin was also associated with decreased colorectal cancer risk.Conclusions: Our findings showed an inverse association between long-term use of metformin and colorectal cancer risk. Findings, especially the risk reduction among men, need to be confirmed in large, well-conducted studies.Impact: If our findings are confirmed, metformin may have a role in the chemoprevention 2018 05;27(5):525-530. Vaccination Patterns in Children After Autism Spectrum Disorder Diagnosis and in Their Younger Siblings In recent years, rates of vaccination have been declining. Whether this phenomenon disproportionately affects children with autism spectrum disorder (ASD) or their younger siblings is unknown. To investigate if children after receiving an ASD diagnosis obtain their remaining scheduled vaccines according to the Advisory Committee on Immunization Practices (ACIP) recommendations and to compare the vaccination patterns of younger siblings of children with ASD with the vaccination patterns of younger siblings of children without ASD. This investigation was a retrospective matched cohort study. The setting was 6 integrated health care delivery systems across the United States within the Vaccine Safety Datalink. Participants were children born between January 1, 1995, and September 30, 2010, and their younger siblings born between January 1, 1997, and September 30, 2014. The end of follow-up was September 30, 2015. Recommended childhood vaccines between ages 1 month and 12 years. The proportion of children who received all of their vaccine doses according to ACIP recommendations. The study included 3729 children with ASD (676 [18.1%] female), 592 907 children without ASD, and their respective younger siblings. Among children without ASD, 250 193 (42.2%) were female. For vaccines recommended between ages 4 and 6 years, children with ASD were significantly less likely to be fully vaccinated compared with children without ASD (adjusted rate ratio, 0.87; 95% CI, 0.85-0.88). Within each age category, vaccination rates were significantly lower among younger siblings of children with ASD compared with younger siblings of children without ASD. The adjusted rate ratios varied from 0.86 for siblings younger than 1 year to 0.96 for those 11 to 12 years old. Parents who had a child with ASD were more likely to refuse at least 1 recommended vaccine for that child's younger sibling and to limit the number of vaccines administered during the younger sibling's first year of life. Children with ASD and their younger siblings were undervaccinated compared with the general population. The results of this study suggest that children with ASD and their younger siblings are at increased risk of vaccine-preventable diseases. Authors: Zerbo O; 05 01;172(5):469-475. Prospective surveillance pilot of rivaroxaban safety within the US Food and Drug Administration Sentinel System The US Food and Drug Administration's Sentinel system developed tools for sequential surveillance. In patients with non-valvular atrial fibrillation, we sequentially compared outcomes for new users of rivaroxaban versus warfarin, employing propensity score matching and Cox regression. A total of 36 173 rivaroxaban and 79 520 warfarin initiators were variable-ratio matched within 2 monitoring periods. Statistically significant signals were observed for ischemic stroke (IS) (first period) and intracranial hemorrhage (ICH) (second period) favoring rivaroxaban, and gastrointestinal bleeding (GIB) (second period) favoring warfarin. In follow-up analyses using primary position diagnoses from inpatient encounters for increased definition specificity, the hazard ratios (HR) for rivaroxaban vs warfarin new users were 0.61 (0.47, 0.79) for IS, 1.47 (1.29, 1.67) for GIB, and 0.71 (0.50, 1.01) for ICH. For GIB, the HR varied by age: <66 HR = 0.88 (0.60, 1.30) and 66+ HR = 1.49 (1.30, 1.71). This study demonstrates the capability of Sentinel to conduct prospective safety monitoring and raises no new concerns about rivaroxaban safety. Authors: Chrischilles EA; Fireman B; 03;27(3):263-271. Epub 2018-01-10. Methods for addressing \"innocent bystanders\" when evaluating safety of concomitant vaccines The need to develop methods for studying the safety of childhood immunization schedules has been recognized by the Institute of Medicine and Department of Health and Human Services. The recommended childhood immunization schedule includes multiple vaccines in a visit. A key concern is safety of concomitant (same day) versus separate day vaccination. This paper addresses a methodological challenge for observational studies using a self-controlled design to investigate the safety of concomitant vaccination. We propose a process for distinguishing which of several concomitantly administered vaccines is responsible for increased risk of an adverse event while adjusting for confounding due to relationships between effect modifying risk factors and concomitant vaccine combinations. We illustrate the approach by re-examining the known increase in risk of seizure 7 to 10 days after measles-mumps-rubella (MMR) vaccination and evaluating potential independent or modifying effects of other vaccines. Initial analyses suggested that DTaP had both an independent and potentiating effect on seizure. After accounting for the relationship between age at vaccination and vaccine combination, there was little evidence for increased risk of seizure with same day administration of DTaP and MMR; incidence rate ratio, 95% confidence interval 1.2 (0.9-1.6), P value = .226. We have shown that when using a self-controlled design to investigate safety of concomitant vaccination, it can be critically important to adjust for time-invariant effect modifying risk factors, such as age at time of vaccination, which are structurally related to vaccination patterns due to recommended immunization schedules. Authors: Wang SV; Feb 13. Herpes Zoster Rates in a Large Cohort of 01;154(2):218-219. Bias from outcome misclassification in immunization schedule safety research The Institute of Medicine recommended conducting observational studies of childhood immunization schedule safety. Such studies could be biased by outcome misclassification, leading to incorrect inferences. Using simulations, we evaluated (1) outcome positive predictive values (PPVs) as indicators of bias of an exposure-outcome association, and (2) quantitative bias analyses (QBA) for bias correction. Simulations were conducted based on proposed or ongoing Vaccine Safety Datalink studies. We simulated 4 studies of 2 exposure groups (children with no vaccines or on alternative schedules) and 2 baseline outcome levels (100 and 1000/100 000 person-years), with 3 relative risk (RR) levels (RR = 0.50, 1.00, and 2.00), across 1000 replications using probabilistic modeling. We quantified bias from non-differential and differential outcome misclassification, based on levels previously measured in database research (sensitivity > 95%; specificity > 99%). We calculated median outcome PPVs, median observed RRs, Type 1 error, and bias-corrected RRs following QBA. We observed PPVs from 34% to 98%. With non-differential misclassification and true RR = 2.00, median bias was toward the null, with severe bias (median observed RR = 1.33) with PPV = 34% and modest bias (median observed RR = 1.83) with PPV = 83%. With differential misclassification, PPVs did not reflect median bias, and there was Type 1 error of 100% with PPV = 90%. QBA was generally effective in correcting misclassification bias. In immunization schedule studies, outcome misclassification may be non-differential or differential to exposure. Overall outcome PPVs do not reflect the distribution of false positives by exposure and are poor indicators of bias in individual studies. Our results support QBA for immunization schedule safety research. Authors: Newcomer SR; 2018-01-02. Liver Enzymes in Early to Mid-pregnancy, Insulin Resistance, and Gestational Diabetes Risk: A Longitudinal Analysis Background: Liver enzymes may be implicated in glucose homeostasis; liver enzymes progressively change during pregnancy but longitudinal data during pregnancy in relation to insulin resistance and gestational diabetes (GDM) risk are lacking. We investigated longitudinal associations of -glutamyl transferase (GGT) and alanine aminotransferase (ALT) with insulin secretion and resistance markers across early to mid-pregnancy and subsequent GDM risk. Methods: Within the prospective Pregnancy Environment and Lifestyle Study cohort, 117 GDM cases were ascertained and matched to 232 non-GDM controls in a nested case-control study. Fasting blood samples were collected at two clinic visits (CV1, gestational weeks 10-13; CV2, gestational weeks 16-19). Linear mixed model and conditional logistic regression were used, adjusting for major risk factors for GDM. Results: In repeated measure analysis, after adjusting for confounders including body mass index and waist-to-hip ratio, GGT per standard deviation increment was associated with elevated fasting glucose and HOMA-IR (% change = 1.51%, 95% CI 0.56-2.46% and 7.43%, 95% CI CV2, GGT levels comparing the highest versus lowest quartile were associated with 3.01-fold (95% CI 1.32-6.85) and 3.51-fold (95% CI Epub 2018-10-02. An Observational Study of Cardiovascular Risks Associated with Rheumatoid Arthritis Therapies: A Comparison of Two Analytical Approaches Comparative safety studies typically use hierarchical treatment categories that lump monotherapy and combination therapy. The consequence of this approach on study results is not clear. For example, studies of tumor necrosis factor inhibitors usually lump users regardless of whether they are using the drug alone or in combination with other agents. This study explored the importance of lumping vs splitting users of monotherapy and combination therapy. We also explored whether the timing of disenrollment from Health Plan membership was informative as an outcome variable when interpreting unmeasured, time-varying confounding. This observational cohort study included Kaiser Permanente Northern California 2003 to 2013 members with rheumatoid arthritis who started methotrexate. The study end point was a major cardiovascular event. In Cox proportional hazards analysis, we compared treatment classifications using five lumped categories with treatment classification using nine split categories. We also studied disenrollment as an outcome. Among 5885 patients, 238 experienced serious cardiovascular events during an average follow-up of 4.25 years. Analysis of drug treatments using 5 lumped categories was difficult to interpret because treatment effects and drug users were mixed. In contrast, analysis of 9 drug categories that split monotherapies from combination therapy was easier to interpret, although confidence intervals were wider. Analysis of drug treatment in relation to disenrollment provided useful information with which to assess study validity, although the power of the analysis was limited. In comparative safety studies, we recommend greater transparency in classifying treatment and evaluating disenrollment. Authors: Herrinton LJ; Goldfien Perm J. 2018;22:17-101. A cohort study of maternal cardiometabolic risk factors and primary cesarean delivery in an integrated health system Maternal cardiometabolic risk factors (i.e., hyperglycemia, pre-existing hypertension and high body mass index) impact fetal growth and risk of having a cesarean delivery. However, the independent and joint contribution of maternal cardiometabolic risk factors to primary cesarean section is unclear. We aimed to elucidate the degree to which maternal cardiometabolic risk factors contribute to primary cesarean deliveries and whether associations vary by infant size at birth in an integrated health system. A cohort study of 185,045 singleton livebirths from 2001 to 2010. Poisson regression with robust standard errors provided crude and adjusted relative risks (RR) and 95% confidence intervals (CIs) for cesarean delivery risk associated with risk factors. We then estimated the proportion of cesarean sections that could be prevented if the cardiometabolic risk factor in pregnant women were eliminated (the population-attributable risk [PAR]). In a single multivariable model, maternal cardiometabolic risk factors were independently associated with cesarean delivery: RR (95% CI) abnormal glucose screening 1.04 (1.01-1.08); gestational diabetes 1.18 (1.11-1.18) and pre-existing diabetes 1.60 (1.49-1.71); pre-existing hypertension 1.16 (1.10-1.23); overweight 1.27 (1.24-1.30); obese class 1.46 (1.42-1.51); and obese class III 1.97 (1.88-2.07); adjusting for established risk factors, medical facility and year. The associations between maternal cardiometabolic risk factors and primary cesarean delivery remained among infants with appropriate weights for gestational age. The PARs were 17.4% for overweight/obesity, 7.0% for maternal hyperglycemia, 2.0% for pre-existing hypertension and 20.5% for any cardiometabolic risk factor. Maternal cardiometabolic risk factors were independently associated with risk of primary cesarean delivery, even among women delivering infants born at an appropriate size for gestational age. Effective strategies to increase the proportion of women entering pregnancy at an optimal weight with normal blood pressure and glucose before pregnancy could potentially eliminate up to 20% of cesarean deliveries. Infarction in New Users of Saxagliptin: A Population-Based Study The cardiovascular safety of saxagliptin, a dipeptidyl-peptidase 4 inhibitor, compared with other antihyperglycemic treatments is not well understood. We prospectively examined the association between saxagliptin use and acute myocardial infarction (AMI). We identified patients aged 18 years, starting from the approval date of saxagliptin in 2009 and continuing through August 2014, using data from 18 Mini-Sentinel data partners. We conducted seven sequential assessments comparing saxagliptin separately with sitagliptin, pioglitazone, second-generation sulfonylureas, and long-acting insulin, using disease risk score (DRS) stratification and propensity score (PS) matching to adjust for potential confounders. Sequential testing kept the overall chance of a false-positive signal below 0.05 (one-sided) for each pairwise comparison. We identified 82,264 saxagliptin users and more than 1.5 times as many users of each comparator. At the end of surveillance, the DRS-stratified hazard ratios (HRs) (95% CI) were 1.08 (0.90-1.28) in the comparison with sitagliptin, long-acting insulin. The corresponding PS-matched HRs were similar. Only one interim analysis of 168 analyses met criteria for a safety signal: the PS-matched saxagliptin-pioglitazone comparison from the fifth sequential analysis, which yielded an HR of 1.63 (1.12-2.37). This association diminished in subsequent analyses. We did not find a higher AMI risk in saxagliptin users compared with users of other selected antihyperglycemic agents during the first 5 years after U.S. Food and Drug Administration approval of the drug. Authors: Toh S; Fireman BH; Mini-Sentinel Saxagliptin-AMI Surveillance Epub 2017-11-09. Trends in Self-reported and Biochemically Tested Marijuana Pregnant Females cohort study comparing the effectiveness of topical fluoruracil vs. topical imiquimod for the treatment of actinic keratosis The most widely used topical agents for the field-based treatment of multiple actinic keratoses (AKs) are 5-fluorouracil and imiquimod, but their comparative effectiveness has not been assessed in a real-world setting. We compared the effectiveness of 5-fluorouracil and imiquimod in reducing risk for subsequent AKs in a large, integrated health care delivery system in northern California. In this cohort study, we identified adult health plan members who had an AK diagnosed in 2007 and who subsequently filled a prescription for 5-fluorouracil or imiquimod (N = 5700). We followed subjects for subsequent AKs identified by the International Classification of Diseases codes and estimated the 2-year (short-term) and 5-year (long-term) differences in cumulative risk while controlling for potential confounding by pretreatment variables. 5-Fluorouracil reduced the short-term incidence of subsequent AKs (cumulative risk difference -4.54% [95% confidence interval, -7.91% to -1.17%]), but there was no statistically significant evidence of a long-term decreased risk (cumulative risk difference -1.43% [95% confidence interval, -3.43% to 0.05%]) compared with that with imiquimod. This is a retrospective study with limited ascertainment of all relevant potential confounding variables. We found that 5-fluorouracil appeared to be significantly more effective than imiquimod in the short-term, but not long-term, prevention of 2017 Dec 22. Exposure to Magnetic Field Non-Ionizing Radiation and the Risk of Miscarriage: A Prospective Cohort Study Magnetic field (MF) non-ionizing radiation is widespread and everyone is exposed to some degree. This prospective cohort study of 913 pregnant women examined the association between high MF exposure and miscarriage risk. Cox (proportional hazards) regression was used to examine the association. After controlling for multiple other factors, women who were exposed to higher MF levels had 2.72 times the risk of miscarriage (hazard ratio = 2.72, 95% CI: 1.42-5.19) than those with lower MF exposure. The increased risk of miscarriage associated with high MF was consistently observed regardless of the sources of high MF. The association was much stronger if MF was measured on a typical day of participants' pregnancies. The finding also demonstrated that accurate measurement of MF exposure is vital for examining MF health effects. This study provides fresh evidence, directly from a human population, that MF non-ionizing radiation could have adverse biological impacts on human health. Li DK; Chen 2017-12-13. Disparities in Prostate, Lung, Breast, and Colorectal Cancer Survival and Comorbidity Status among Urban American Indians and Alaskan Natives Cancer is the second leading cause of death among American Indians and Alaskan Natives (AIAN), although cancer survival information in this population is limited, particularly among urban AIAN. In this retrospective cohort study, we compared all-cause and prostate, breast, lung, and colorectal cancer-specific mortality among AIAN (n = 582) and non-Hispanic white (NHW; n = 82,696) enrollees of Kaiser Permanente Northern California (KPNC) diagnosed with primary invasive breast, prostate, lung, or colorectal cancer from 1997 to 2015. Tumor registry and other electronic health records provided information on sociodemographic, comorbidity, tumor, clinical, and treatment characteristics. Cox regression models were used to estimate adjusted survival curves and hazard ratios (HR) with 95% confidence intervals (CI). AIAN had a significantly higher comorbidity burden compared with NHW (P < 0.05). When adjusting for patient, disease characteristics, and Charlson comorbidity scores, all-cause mortality and cancer-specific mortality were significantly higher for AIAN than NHW patients with breast cancer (HR, 1.47; 95% CI, 1.13-1.92) or with prostate cancer (HR, 1.87; 95% CI, 1.14-3.06) but not for AIAN patients with lung and colorectal cancer. Despite approximately equal access to preventive services and cancer care in this setting, we found higher mortality for AIAN than NHW with some cancers, and a greater proportion of AIAN cancer patients with multiple comorbid conditions. This study provides severely needed information on the cancer experience of the 71% of AIANs who live in urban areas and access cancer care outside of the Indian Health Services, from which the vast majority of AIAN cancer information comes. 01;77(23):6770-6776. Epub 2017-11-29. A review of the performance of different methods for propensity score matched subgroup analyses and a summary of their application in peer-reviewed research studies When evaluating safety signals, there is often interest in understanding safety in all patients for whom compared treatments are reasonable alternatives, as well as in specific subgroups of interest. There are numerous ways that propensity score (PS) matching can be implemented for subgroup analyses. We conducted a systematic literature review of methods papers that compared the performance of alternative methods to implement PS matched subgroup analyses and examined how frequently different PS matching methods have been used for subgroup analyses in applied studies. We identified 5 methods papers reporting small improvements in covariate balance and bias with use of a subgroup-specific PS instead of a mis-specified overall PS within subgroups. Applied research papers frequently used PS for subgroups in ways not evaluated in methods papers. Thirty three percent used PS to match in the overall cohort and broke the matched sets for subgroup analysis without further adjustment. While the performance of several alternative ways to use PS matching in subgroup analyses has been evaluated in methods literature, these evaluations do not include the most commonly used methods to implement PS matched subgroup analyses in applied studies. There is a need to better understand the relative performance of commonly used methods for PS matching in subgroup analyses, particularly within settings encountered during active surveillance, where there may be low exposure, infrequent outcomes, and multiple subgroups of interest. Authors: Wang SV; Fireman B; Dec;26(12):1507-1512. Epub 2017-10-06. Serious infections among a large cohort of subjects with systemically treated psoriasis Biologic therapy is effective for treatment of moderate-to-severe psoriasis but may be associated with an increased risk for serious infection. To estimate the serious infection rate among patients with psoriasis treated with biologic as compared with nonbiologic systemic agents within a community-based health care delivery setting. We identified 5889 adult Kaiser Permanente Northern California health plan members with psoriasis who had ever been treated with systemic therapies and calculated the incidence rates and 95% confidence intervals (CIs) for serious infections over 29,717 person-years of follow-up. Adjusted hazard ratios (aHRs) were calculated using Cox regression. Adjusting for age, sex, race or ethnicity, and comorbidities revealed a significantly increased risk for overall serious infection among patients treated with biologics as compared with those treated with nonbiologics (aHR, 1.31; 95% CI, 1.02-1.68). More specifically, there was a significantly elevated risk for skin and soft tissue infection (aHR, 1.75; 95% CI, 1.19-2.56) and meningitis (aHR, 9.22; 95% CI, 1.77-48.10) during periods of active biologic use. Risk associated with individual drugs was not examined. We found an increased rate of skin and soft tissue infections among patients with psoriasis treated with biologic agents. There also was a signal suggesting increased risk for meningitis. Clinicians should be aware of these potential adverse events when prescribing biologic Dermatol. 2017 Sep 13. Age at menarche and late adolescent adiposity associated with mammographic density on processed digital mammograms in 24,840 women Background: High mammographic density is strongly associated with increased breast cancer risk. Some, but not all, risk factors for breast cancer are also associated with higher mammographic density.Methods: The study cohort (N = 24,840) was drawn from the Research Program in Genes, Environment and Health of Kaiser Permanente Northern California and included non-Hispanic white females ages 40 to 74 years with a full-field digital mammogram (FFDM). Percent density (PD) and dense area (DA) were measured by a radiological technologist using Cumulus. The association of age at menarche and late adolescent body mass index (BMI) with PD and DA were modeled using linear regression adjusted for confounders.Results: Age at menarche and late adolescent BMI were negatively correlated. Age at menarche was positively associated with PD (P value for trend <0.0001) and DA (P value for trend <0.0001) in fully adjusted models. Compared with the reference category of ages 12 to 13 years at menarche, menarche at age >16 years was associated with an increase in PD of 1.47% (95% CI, 0.69-2.25) and an increase in DA of 1.59 cm2 (95% CI, 0.48-2.70). Late adolescent BMI was inversely associated with PD (P < 0.0001) and DA (P < 0.0001) in fully adjusted models.Conclusions: Age at menarche and late adolescent BMI are both associated with Cumulus measures of mammographic density on processed FFDM images.Impact: Age at menarche and late adolescent BMI may act through different pathways. The long-term effects of age at menarche on cancer risk may be mediated through factors besides Survival after dementia diagnosis in five racial/ethnic groups Information on anticipated survival time after dementia diagnosis among racially/ethnically diverse patients is needed to plan for care and evaluate disparities. Dementia-free health care members aged 64 years were followed (1/1/2000-12/31/2013) for dementia diagnosis and subsequent survival (n = 23,032 Asian American; n = 18,778 African American; n = 21,000 Latino; n = 4543 American Indian/Alaska Native; n = 206,490 white). Kaplan-Meier curves were estimated for survival after dementia diagnosis by race/ethnicity. We contrasted mortality patterns among people with versus without dementia using Cox proportional hazards models. After dementia diagnosis (n = 59,494), whites had shortest median survival (3.1 years), followed by American Indian/Alaska Natives (3.4 years), African Americans (3.7 years), Latinos (4.1 years), and Asian Americans (4.4 years). Longer postdiagnosis survival among racial/ethnic minorities compared with whites persisted after adjustment for comorbidities. Racial/ethnic mortality inequalities among dementia patients mostly paralleled mortality inequalities among people without dementia. Survival after dementia diagnosis differs by race/ethnicity, with shortest survival among whites and longest among Asian ofatumumab for double-refractory chronic lymphocytic and alemtuzumab [double refractory (DR-CLL)]. Ofatumumab was licensed on the basis of an uncontrolled Phase II study, Hx-CD20-406, in which patients receiving ofatumumab survived for a median of 13.9 months. However, the lack of an internal control arm presents an obstacle for the estimation of comparative effectiveness.METHODS:The objective of the study was to present a method to estimate the cost effectiveness of ofatumumab in the treatment of DR-CLL. As no suitable historical control was available for modelling, the outcomes from non-responders to ofatumumab were used to model the effect of best supportive care (BSC). This was done via a Cox regression to control for differences in baseline characteristics between groups. This analysis was included in a partitioned survival model built in Microsoft\u00ae Excel with utilities and costs taken from published sources, with costs and quality-adjusted life years (QALYs) were discounted at a rate of 3.5% per annum.RESULTS:Using the outcomes seen in non-responders, ofatumumab is expected to add approximately 0.62 life years (1.50 vs. 0.88). Using published utility values this translates to an additional 0.30 QALYs (0.77 vs. 0.47). At the list price, ofatumumab had a cost per QALY of \u00a3130,563, and a cost per life year of \u00a363,542. The model was sensitive to changes in assumptions regarding overall survival estimates and utility values.CONCLUSIONS:This study demonstrates the potential of using data for non-responders to model outcomes for BSC in cost-effectiveness evaluations based on single-arm trials. Further research is needed on the estimation of comparative effectiveness using uncontrolled clinical studies. 2017. a large cohort of patients with systemically treated psoriasis in a managed care population Moderate to severe psoriasis often requires treatment with systemic agents, many of which have immunosuppressive properties and could increase cancer risk, including nonmelanoma skin cancer (NMSC). We sought to estimate the overall malignancy rate (excluding NMSC) and NMSC rate among 5889 patients with systemically treated psoriasis. We identified a cohort of adult Kaiser Permanente Northern California health plan members with psoriasis diagnosed from 1998 to 2011 and treated with at least 1 systemic antipsoriatic agent and categorized them into ever-biologic or nonbiologic users. Malignancy rates were calculated per 1000 person-years of follow-up with 95% confidence intervals (CI). Crude and confounder-adjusted hazard ratios (aHRs) were calculated using Cox regression. Most biologic-exposed members were treated with TNF-alfa inhibitors (n = 2214, 97%). Overall incident cancer rates were comparable between ever-biologic as compared to nonbiologic users (aHR 0.86, 95% CI 0.66-1.13). NMSC rates were 42% higher among individuals ever exposed to a biologic (aHR 1.42, 95% CI 1.12-1.80), largely driven by increased cutaneous squamous cell carcinoma risk (aHR 1.81, 95% CI 1.23-2.67). No information was available on disease severity. We found increased incidence of cutaneous squamous cell carcinoma among patients with systemically treated psoriasis who were ever exposed to biologics, the majority of which were TNF-alfa inhibitors. Increased skin cancer surveillance in this population may be warranted. Authors: Asgari MM; Testosterone Replacement With Cardiovascular Outcomes Among Men With Androgen Deficiency Controversy exists regarding the safety of testosterone replacement therapy (TRT) following recent reports of an increased risk of adverse cardiovascular events. To investigate the association between TRT and cardiovascular outcomes in men with androgen deficiency. A retrospective cohort study was conducted within an integrated health care delivery system. Men at least 40 years old with evidence of androgen deficiency either by a coded diagnosis and/or a morning serum total testosterone level of less than 300 ng/dL were included. The eligibility window was January 1, 1999, to December 31, 2010, with follow-up through December 31, 2012. Any prescribed TRT given by injection, orally, or topically. The primary outcome was a composite of cardiovascular end points that included acute myocardial infarction (AMI), coronary revascularization, unstable angina, stroke, transient ischemic attack (TIA), and sudden cardiac death (SCD). Multivariable Cox proportional hazards models were used to investigate the association between TRT and cardiovascular outcomes. An inverse probability of treatment weight, propensity score methodology, was used to balance baseline characteristics. The cohorts consisted of 8808 men (19.8%) ever dispensed testosterone (ever-TRT) (mean age, 58.4 years; 1.4% with prior cardiovascular events) and 35 527 men (80.2%) never dispensed testosterone (never-TRT) (mean age, 59.8 years; 2.0% with prior cardiovascular events). Median follow was 3.2 years (interquartile range [IQR], 1.7-6.6 years) in the never-TRT group vs 4.2 (IQR, 2.1-7.8) years in the ever-TRT group. The rates of the composite cardiovascular end point were 23.9 vs 16.9 per 1000 person-years in the never-TRT and ever-TRT groups, respectively. The adjusted hazard ratio (HR) for the composite cardiovascular end point in the ever-TRT group was 0.67 (95% CI, 0.62-0.73. Similar results were seen when the outcome was restricted to combined stroke events (stroke and TIA) (HR, 0.72; 95% CI, 0.62-0.84) and combined cardiac events (AMI, angina, revascularization procedures) (HR, 0.66; 95% CI, 0.60-0.72). Among men with androgen deficiency, dispensed testosterone prescriptions were associated with a lower risk of cardiovascular outcomes over a median follow-up of 3.4 years. Authors: Cheetham TC; Med. Trends in Incidence of Hospitalized Acute Myocardial Infarction in the Cardiovascular Research Network (CVRN) Monitoring trends in cardiovascular events can provide key insights into the effectiveness of prevention efforts. Leveraging data from electronic health records provides a unique opportunity to examine contemporary, community-based trends in acute myocardial infarction hospitalizations. We examined trends in hospitalized acute myocardial infarction incidence among adults aged 25 years in 13 US health plans in the Cardiovascular Research Network. The first hospitalization per member for acute myocardial infarction overall and for ST-segment elevation myocardial infarction and non-ST-segment elevation myocardial infarction was identified by International Classification of Diseases, Ninth Revision, Clinical Modification primary discharge codes in each calendar year from 2000 through 2008. Age- and sex-adjusted incidence was calculated per 100,000 person-years using direct adjustment with 2000 US census data. Between 2000 and 2008, we identified 125,435 acute myocardial infarction hospitalizations. Age- and sex-adjusted incidence rates (per 100,000 person-years) of acute myocardial infarction decreased an average 3.8%/y from 230.5 in 2000 to 168.6 in 2008. Incidence of ST-segment elevation myocardial infarction decreased 8.7%/y from 104.3 in 2000 to 51.7 in 2008, whereas incidence of non-ST-segment elevation myocardial infarction increased from 126.1 to 129.4 between 2000 and 2004 and then decreased thereafter to 116.8 in 2008. Age- and sex-specific incidence rates generally reflected similar patterns, with relatively larger decreases in ST-segment elevation myocardial infarction rates in women compared with men. As compared with 2000, the age-adjusted incidence of ST-segment elevation myocardial infarction in 2008 was 48% lower among men and 61% lower among women. Among a large, diverse, multicenter community-based insured population, there were significant decreases in incidence of hospitalized acute myocardial infarction and the more serious ST-segment elevation myocardial infarctions between 2000 and 2008. Decreases in ST-segment elevation myocardial infarctions were most pronounced among women. While ecologic in nature, these secular decreases likely reflect, at least in part, results of improvement in primary prevention efforts. Authors: Reynolds K; Go AS; Quesenberry CP; Med. 2017 Mar;130(3):317-327. Epub 2016-10-14. Identification of the joint effect of a dynamic treatment intervention and a stochastic monitoring intervention under the no direct effect assumption The management of chronic conditions is characterized by frequent re-assessment of therapy decisions in response to the patient's changing condition over the course of the illness. Evidence most suitable to inform care thus often concerns the contrast of adaptive treatment strategies that repeatedly personalize treatment decisions over time using the latest accumulated data available from the patient's previous clinic visits such as laboratory exams (e.g., hemoglobin A1c measurements in diabetes care). The frequency at which such information is monitored implicitly defines the causal estimand that is typically evaluated in an observational or randomized study of such adaptive treatment strategies. Analytic control of monitoring with standard estimation approaches for time-varying interventions can therefore not only improve study generalizibility but also inform the optimal timing of clinical surveillance. Valid inference with these estimators requires the upholding of a positivity assumption that can hinder their applicability. To potentially weaken this requirement for monitoring control, we introduce identifiability results that will facilitate the derivation of alternate estimators of effects defined by general joint treatment and monitoring interventions in the context of time-to-event outcomes. These results are developed based on the nonparametric structural equation modeling framework using a no direct effect assumption originally introduced in a prior paper that inspired this work. The relevance and scope of the results presented here are illustrated with examples in diabetes comparative effectiveness research. Authors: Neugebauer R; Iron Deficiency Proton pump inhibitors (PPIs) and histamine-2 receptor antagonists (H2RAs) suppress gastric acid production, which can inhibit iron absorption. However, few data exist regarding whether these medications increase the risk of clinical iron deficiency. A community-based case-control study evaluated the association between acid-suppressing medication use and the subsequent risk of iron deficiency. It contrasted 77,046 patients with new iron deficiency diagnoses (January 1999-December 2013), with 389,314 controls. Medication exposures, outcomes, and potential confounders used electronic databases. We excluded patients with pre-existing risk factors for iron deficiency. Associations were estimated using conditional logistic regression. Among cases, 2343 (3.0%) received a prior 2-year supply of PPIs and 1063 (1.4%) received H2RAs (without PPI use). Among controls, 3354 (0.9%) received a prior 2-year supply of PPIs and 2247 (0.6%) H2RAs. Both 2 years of PPIs (adjusted odds ratio, 2.49; 95% confidence interval, 2.35-2.64) and 2 years of H2RAs (odds ratio, 1.58; 95% CI, 1.46-1.71) were associated with an increased subsequent risk for iron deficiency. Among PPI users, the associations were stronger for higher daily doses (>1.5 vs <0.75 PPI pills/d; P value interaction = .004) and decreased after medication discontinuation (P-trend < .001). Some of the strongest associations were among persons taking >1.5 pills per day for at least 10 years (odds ratio, 4.27; 95% CI, 2.53-7.21). No similar strong associations were found for other commonly used prescription medications. Among patients without known risk factors for iron deficiency, gastric acid inhibitor use for 2 years was associated with an increased subsequent risk of iron deficiency. The risk increased with increasing potency of acid inhibition and decreased after medication discontinuation. sports and exercise is associated with glycaemic control in women with gestational diabetes To assess the association of regular, unsupervised sports and exercise during pregnancy, by intensity level, with glycaemic control in women with gestational diabetes (GDM). Prospective cohort study of 971 women who, shortly after being diagnosed with GDM, completed a Pregnancy Physical Activity Questionnaire assessing moderate and vigorous intensity sports and exercise in the past 3 months. Self-monitored capillary glucose values were obtained for the 6-week period following the questionnaire, with optimal glycaemic control defined80% values meeting the targets<5.3mmol/L for fasting and <7.8mmol/L 1-hour after meals. Logistic regression estimated the odds of achieving optimal control; linear regression estimated activity level-specific least square mean glucose, as well as between-level mean glucose differences. For volume of moderate intensity sports and exercise ([MET\u00d7hours]/week), the highest quartile, compared to the lowest, had significantly increased odds of optimal control (OR=1.82 [95% CI: 1.06-3.14] P=0.03). There were significant trends for decreasing mean 1-hour post breakfast, lunch and dinner glycaemia with increasing quartile of moderate activity (all P<0.05). Any participation in vigorous intensity sports and exercise was associated with decreased mean 1-hour post breakfast and lunch glycaemia (both P<0.05). No associations were observed for fasting. Higher volumes of moderate intensity sports and exercise, reported shortly after GDM diagnosis, were significantly associated with increased odds of achieving glycaemic control. Clinicians should be aware that unsupervised moderate intensity sports and exercise performed in mid-pregnancy aids in subsequent glycaemic control among women Screening Mammography for Free: Impact of Eliminating Cost Sharing on Cancer Screening Rates To study the impact of eliminating cost sharing for screening mammography on mammography rates in a large Medicare Advantage (MA) health plan which in 2010 eliminated cost sharing in anticipation of the Affordable Care Act mandate. Large MA health maintenance organization offering individual-subscriber MA insurance and employer-supplemented group MA insurance. We investigated the impact on breast cancer screening of a policy that eliminated a $20 copayment for screening mammography in 2010 among 53,188 women continuously enrolled from 2007 to 2012 in an individual-subscriber MA plan, compared with 42,473 women with employer-supplemented group MA insurance in the same health maintenance organization who had full screening coverage during this period. We used differences-in-differences analysis to study the impact of cost-sharing elimination on mammography rates. Annual screening rates declined over time for both groups, with similar trends pre-2010 and a slower decline after 2010 among women whose copayments were eliminated. Among women aged 65-74 years in the individual-subscriber MA plan, 44.9 percent received screening in 2009 compared with 40.9 percent in 2012, while 49.5 percent of women in the employer-supplemented MA plan received screening in 2009 compared with 44.1 percent in 2012, that is, a difference-in-difference effect of 1.4 percentage points less decline in screening among women experiencing the cost-sharing elimination. Effects were concentrated among women without recent screening. There were no differences by neighborhood socioeconomic status or race/ethnicity. Eliminating cost sharing for screening mammography was associated with modesty lower decline in screening rates among women with previously low screening adherence. Authors: Jena AB; Huang R Package: Conducting Transparent and Reproducible Simulation Studies of Causal Effect Estimation with Complex Longitudinal Data The simcausal R package is a tool for specification and simulation of complex longitudinal data structures that are based on non-parametric structural equation models. The package aims to provide a flexible tool for simplifying the conduct of transparent and reproducible simulation studies, with a particular emphasis on the types of data and interventions frequently encountered in real-world causal inference problems, such as, observational data with time-dependent confounding, selection bias, and random monitoring processes. The package interface allows for concise expression of complex functional dependencies between a large number of nodes, where each node may represent a measurement at a specific time point. The package allows for specification and simulation of counterfactual data under various user-specified interventions (e.g., static, dynamic, deterministic, or stochastic). In particular, the interventions may represent exposures to treatment regimens, the occurrence or non-occurrence of right-censoring events, or of clinical monitoring events. Finally, the package enables the computation of a selected set of user-specified features of the distribution of the counterfactual data that represent common causal quantities of interest, such as, treatment-specific means, the average treatment effects and coefficients from working marginal structural models. The applicability of simcausal is demonstrated by replicating the results of two published simulation studies. Authors: Sofrygin O; van Epub 2017-10-16. Acute demyelinating events following vaccines - a case centered analysis Case reports have suggested that vaccines may trigger transverse myelitis (TM) or acute disseminated encephalomyelitis (ADEM), but the evidence for a causal association is inconclusive. We analyzed the association of immunization and subsequent development of TM or ADEM. We identified all cases of TM and ADEM in the Vaccine Safety Datalink population. Using a case-centered method, we compared vaccination of each case to vaccination of all matched persons in the study population, who received the same type of vaccine, with respect to whether or not their vaccination occurred during a predetermined exposure interval. We calculated a risk difference (excess risk) of TM and ADEM for each vaccine. Following nearly 64 million vaccine doses, only 7 cases of TM and 8 cases of ADEM were vaccinated during the primary exposure window 5-28 days prior to onset. For TM, there was no statistically significant increased risk of immunization. For ADEM, there was no statistically significant increased risk following any vaccine except for Tdap (adolescent and adult tetanus, reduced diphtheria, acellular pertussis) vaccine. Based on 2 exposed cases, the odds ratio for Tdap exposure 5-28 days prior to ADEM onset was 15.8 (95% confidence interval [CI], 1.2-471.6; P = .04), and the estimated excess risk was 0.385 (95% CI, -.04 to 1.16) cases per million doses. We found no association between TM and prior immunization. There was a possible association of ADEM with Tdap vaccine, but the excess risk is not likely to be more than 1.16 cases of ADEM per million vaccines administered. Authors: Baxter Epub 2016-09-01. Semi-Parametric Estimation and Inference for the Mean Outcome of the Single Time-Point Intervention in a Causally Connected Population. AbstractWe study the framework for semi-parametric estimation and statistical inference for the sample average treatment-specific mean effects in observational settings where data are collected on a single network of connected units (e.g., in the presence of interference or spillover). Despite recent advances, many of the current statistical methods rely on estimation techniques that assume a particular parametric model for the outcome, even though some of the most important statistical assumptions required by these models are most likely violated in the observational network settings, often resulting in invalid and anti-conservative statistical inference. In this manuscript, we rely on the recent methodological advances for the targeted maximum likelihood estimation (TMLE) of causal effects in a network of causally connected units, to describe an estimation approach that permits for more realistic classes of data-generative models and provides valid statistical inference in the context of network-dependent data. The approach is applied to an observational setting with a single time point stochastic intervention. We start by assuming that the true observed data-generating distribution belongs to a large class of semi-parametric statistical models. We then impose some restrictions on the possible set of the data-generative distributions that may belong to our statistical model. For example, we assume that the dependence among units can be fully described by the known network, and that the dependence on other units can be summarized via some known (but otherwise arbitrary) summary measures. We show that under our modeling assumptions, our estimand is equivalent to an estimand in a hypothetical iid data distribution, where the latter distribution is a function of the observed network data-generating distribution. With this key insight in mind, we show that the TMLE for our estimand in dependent network data can be described as a certain iid data TMLE algorithm, also resulting in a new simplified approach to conducting statistical inference. We demonstrate the validity of our approach in a network simulation study. We also extend prior work on dependent-data TMLE towards estimation of novel causal parameters, e.g., the unit-specific direct treatment effects under interference and the effects of interventions that modify the initial network structure. Authors: Sofrygin O; Disease Among HIV-Infected and HIV-Uninfected Adults in a Large Integrated Healthcare System It is unclear whether HIV-infected individuals remain at higher risk of invasive pneumococcal disease (IPD) compared with HIV-uninfected individuals. We conducted a cohort study of HIV-infected and demographically matched HIV-uninfected adults within Kaiser Permanente Northern California during the period 1996-2011. We used Poisson models to obtain rate ratios (RRs) for incident IPD associated with HIV infection and other risk factors. Among 13,079 HIV-infected and 137,643 HIV-uninfected adults, the IPD rate per 100,000 person-years was 160 (n = 109 events) for HIV-infected and 8 (n = 75 events) for HIV-uninfected subjects, with an adjusted RR of 13.0 [95% confidence interval (CI): 9.1-18.7]. For HIV-infected individuals, IPD per 100,000 person-years decreased by 71% during study follow-up, from 305 in 1996-1999 to 88 in 2010-2011 (p < 0.001), with an adjusted RR of 6.6 (95% CI: 2.7-16.1) compared with HIV-uninfected subjects in 2010-2011. Risk factors for IPD among HIV-infected individuals included black compared with white race/ethnicity, smoking, cancer, and higher HIV RNA levels. The 23-valent pneumococcal polysaccharide vaccination was not associated with a reduced risk of IPD in HIV-infected or HIV-uninfected individuals. Among HIV-infected IPD serotype was 19A (33%), of the 13-valent pneumococcal conjugate vaccine (PCV13). Despite a dramatic decline in IPD incidence for HIV-infected adults since 1996, IPD rates were nearly sevenfold higher compared with HIV-uninfected adults in recent years, even after adjustment for risk factors. Timely antiretroviral therapy initiation, risk reduction strategies, and recent guidelines recommending PCV13 use may further reduce IPD incidence among HIV 2016 Oct;30(10):463-470. Risk of cancer in Asian Americans: a Kaiser Permanente cohort study To supplement published cohort data about incident cancer in Asian Americans (Asians) including risk of specific Asian ethnic groups. A cohort study in 124,193 persons (13,344 Asians) with baseline examination data in 1978-1985 used Cox proportional hazards models with seven covariates to estimate hazard ratios (HRs) and 95 % confidence intervals (CIs). Through 2012 cancer was diagnosed in 18,687 persons including 1,522 Asians. Compared to Whites, the HR (CIs) for any cancer in Asians was 0.8 (0.7-0.9, p < 0.001). Lower Asian risk was stronger for men (HR = 0.7, p < 0.001) than for women (HR = 0.9, p = 0.003). Lower Asian vs. White risks with p < 0.05 were found for cancers of the upper airway digestive area, hematologic malignancies, melanoma, and cancers of the prostate, bladder, and brain. Melanoma contributed substantially to lower Asian risk, especially in women. HRs for specific Asian groups versus Whites follow: Chinese = 0.9 (p < 0.001), Japanese = 0.9 (p = 0.01), Filipinos = 0.8 (p < 0.001), South Asians = 0.5 (p < 0.001), and Other Asians = 0.7 (p = 0.006). Both South Asian men and women had lower risk than Whites, and South Asians had lower risk than any other racial/ethnic group. Asians had lower cancer risk than Whites, due to lower risk of several cancer types. Each Asian ethnic group had lower risk than Whites with South Asians at the lowest risk. Authors: Tran Control. 2016 Oct;27(10):1197-207. Epub 2016-08-25. Narrowing the gap in life expectancy between HIV-infected and HIV-uninfected individuals with access to care It is unknown if a survival gap remains between HIV-infected and HIV-uninfected individuals with access to care. We conducted a cohort study within Kaiser Permanente California during 1996-2011, using abridged life tables to estimate the expected years of life remaining (\"life expectancy\") at age 20. Among 24,768 HIV-infected and 257,600 HIV-uninfected individuals, there were 2229 and 4970 deaths, with mortality rates of 1827 and 326 per 100,000 person-years, respectively. In 1996-1997, life expectancies at age 20 for HIV-infected and HIV-uninfected individuals were 19.1 and 63.4 years, respectively, corresponding with a gap of 44.3 years (95% confidence interval: 38.4 to 50.2). Life expectancy at age 20 for HIV-infected individuals increased to 47.1 years in 2008 and 53.1 years by 2011, narrowing the gap to 11.8 years (8.9-14.8 years) in 2011. In 2008-2011, life expectancies at age 20 for HIV-infected individuals ranged from a low of 45.8 years for blacks and 46.0 years for those with a history of injection drug use to a high of 52.2 years for Hispanics. HIV-infected individuals who initiated antiretroviral therapy with CD4 ?500 cells per microliter had a life expectancy at age 20 of 54.5 years in 2008-2011, narrowing the gap relative to HIV-uninfected individuals to 7.9 years (5.1-10.6 years). For these HIV-infected individuals, the gap narrowed further in subgroups with no history of hepatitis B or C infection, smoking, drug/alcohol abuse, or any of these risk factors. Even with early treatment and access to care, an 8-year gap in life expectancy remains for HIV-infected compared with HIV-uninfected individuals. 01;73(1):39-46. Case centered analysis of Optic Neuritis following vaccines We evaluated the risk of optic neuritis (ON) after vaccines, using a case-centered analysis, comparing the time since vaccination for the patients with ON with that for all similar vaccinees in a large integrated health plan population. We did not detect any association between ON and receipt of any type of vaccine. Authors: Baxter R; Lewis E; Fireman B; DeStefano F; Jul 01;63(1):79-81. Epub 2016-04-10. Pre-pregnancy adverse lipid profile and subsequent risk of gestational diabetes Lower low-density lipoprotein (LDL) peak diameter and a predominance of small, dense LDL are associated with type 2 diabetes, but it is unclear whether they are a risk factor for gestational diabetes mellitus (GDM). To evaluate whether prepregnancy lipid profile predicts the development of GDM during pregnancy. A nested case-control study among women who participated in a multiphasic health exam, where blood was collected and stored between 1984 and 1996, and who then had a subsequent pregnancy between 1984 and 2009. Kaiser Permanente Northern California. Cases were 254 women who developed GDM. Two controls were selected for each case and matched for year of blood draw, age at baseline, age at pregnancy, and number of intervening pregnancies. Prepregnancy LDL peak diameter and prepregnancy lipid subfraction concentrations grouped according to size, and the odds of developing GDM. Women in the lowest quartiles of LDL peak diameter and high-density lipoprotein had increased odds of GDM compared with women in the highest quartiles (odds ratio [95% CI], 2.60 [1.37-4.94] and 1.98 [1.01-3.86], respectively), in multivariable adjusted models. Being in the highest quartile of small and very small LDL subfractions also increased the odds of GDM (2.61 [1.35-5.03] and 2.44 [1.22-4.85], respectively). Lower LDL peak diameter size and high-density lipoprotein levels and higher levels of small and very small LDL subfraction groups were present years before pregnancy in women who developed GDM. A prepregnancy atherogenic lipid profile may help identify women at risk of GDM to target for prevention. 2016-04-05. Risk for Hospitalized Heart Failure Among New Users of Saxagliptin, Sitagliptin, and Other Antihyperglycemic Drugs: A Retrospective Cohort Study Recent postmarketing trials produced conflicting results about the risk for hospitalized heart failure (hHF) associated with dipeptidyl peptidase-4 (DPP-4) inhibitors, creating uncertainty about the safety of these antihyperglycemic agents. To examine the associations of hHF with saxagliptin and sitagliptin. Population-based, retrospective, new-user cohort study. 18 health insurance and health system data partners in the U.S. Food and Drug Administration's Mini-Sentinel program. Patients aged 18 years or older with type 2 diabetes who initiated therapy with saxagliptin, sitagliptin, pioglitazone, second-generation sulfonylureas, or long-acting insulin products from 2006 to 2013. Hospitalized HF, identified by International Classification of Diseases, Ninth Revision, Clinical Modification codes 402.x1, 404.x1, 404.x3, and 428.xx recorded as the principal discharge diagnosis. 78 553 saxagliptin users and 298 124 sitagliptin users contributed an average of 7 to 9 months of follow-up data to 1 or more pairwise comparisons. The risk for hHF was not higher with DPP-4 inhibitors than with the other study drugs. The hazard ratios from the disease risk score (DRS)-stratified analyses were 0.83 (95% CI, 0.70 to 0.99) for saxagliptin versus sitagliptin, (CI, 0.47 to 0.85) for 0.87) saxagliptin sulfonylureas, and 0.61 (CI, 0.50 to 0.73) for saxagliptin versus insulin. The DRS-stratified hazard ratios were (CI, to (CI, 0.64 to 0.78) for sitagliptin versus insulin. Results from the 1:1 propensity score-matched analyses were similar. Results were also similar in subgroups of patients with and without prior cardiovascular disease and in a subgroup defined by the 2 highest DRS deciles. Residual confounding and short follow-up. In this large cohort study, a higher risk for hHF was not observed in users of saxagliptin or sitagliptin compared with other selected antihyperglycemic agents. U.S. Food and Drug Administration. Authors: Toh S; Fireman BH; et al. Ann Intern Med. 2016 Jun 07;164(11):705-14. Epub 2016-04-26. Moderate and Vigorous Intensity Exercise During Pregnancy and Gestational Weight Gain in Women with Gestational Diabetes Objectives To estimate the associations of moderate and vigorous intensity exercise during pregnancy with the rate of gestational weight gain (GWG) from gestational diabetes (GDM) diagnosis to delivery, overall and stratified by prepregnancy overweight/obesity. Methods Prospective cohort study with physical activity reported shortly after the GDM diagnosis and prepregnancy weight and post-diagnosis GWG obtained from electronic health records (n = 1055). Multinomial logistic regression models in the full cohort and stratified by prepregnancy overweight/obesity estimated associations of moderate and vigorous intensity exercise with GWG below and above the Institute of Medicine's (IOM) prepregnancy BMI-specific recommended ranges for weekly rate of GWG in the second and third trimesters. Results In the full cohort, any participation in vigorous intensity exercise was associated with decreased odds of GWG above recommended ranges as compared to no participation [odds ratio (95 % confidence interval): 0.63 (0.40, 0.99)], with a significant trend for decreasing odds of excess GWG with increasing level of vigorous intensity exercise. Upon stratification by prepregnancy overweight/obesity, significant associations were only observed for BMI 25.0 kg/m(2): any vigorous intensity exercise, as compared to none, was associated with 54 % decreased odds of excess GWG [0.46 (0.27, 0.79)] and significant trends were detected for decreasing odds of GWG both below and above the IOM's recommended ranges with increasing level of vigorous exercise (both P 0.03). No associations were observed for moderate intensity exercise. Conclusions for Practice In women with GDM, particularly overweight and obese women, vigorous intensity exercise during pregnancy may reduce the odds of excess Intravenous immune globulin and thromboembolic adverse events: A systematic review and meta-analysis of RCTs Prior case reports and observational studies indicate that intravenous immune globulin (IVIg) products may cause thromboembolic events (TEEs), leading the FDA to require a boxed warning in 2013. The effect of IVIg treatment on the risk of serious TEEs (acute myocardial infarction, ischemic stroke, or venous thromboembolism) was assessed using adverse event data reported in randomized controlled trials (RCTs) of IVIg. RCTs of IVIg in adult patients from 1995 to 2015 were identified from Pubmed, Embase, ClinicalTrials.Gov, and two large prior reviews of IVIg's therapeutic applications. Trials at high risk of detection or reporting bias for serious adverse events were excluded. 31 RCTs with a total of 4,129 participants (2,318 IVIg-treated, 1,811 control) were eligible for quantitative synthesis. No evidence was found of increased TEE risk among IVIg-treated patients compared with control patients was found when arterial and venous TEEs were analyzed as separate endpoints. Trial publications provided little specific information concerning the methods used to ascertain potential adverse events. Care should be taken in extrapolating the results to patients with higher baseline risks of TEE. Am. J. Hematol. 91:594-605, 2016. \u00a9 Jun;91(6):594-605. 2016-04-24. Case Study of the Impact of Data-Adaptive Versus Model-Based Estimation of the Propensity Scores on Causal Inferences from Three Inverse Probability Weighting Estimators Consistent estimation of causal effects with inverse probability weighting estimators is known to rely on consistent estimation of propensity scores. To alleviate the bias expected from incorrect model specification for these nuisance parameters in observational studies, data-adaptive estimation and in particular an ensemble learning approach known as Super Learning has been proposed as an alternative to the common practice of estimation based on arbitrary model specification. While the theoretical arguments against the use of the latter haphazard estimation strategy are evident, the extent to which data-adaptive estimation can improve inferences in practice is not. Some practitioners may view bias concerns over arbitrary parametric assumptions as academic considerations that are inconsequential in practice. They may also be wary of data-adaptive estimation of the propensity scores for fear of greatly increasing estimation variability due to extreme weight values. With this report, we aim to contribute to the understanding of the potential practical consequences of the choice of estimation strategy for the propensity scores in real-world comparative effectiveness research. We implement secondary analyses of Electronic Health Record data from a large cohort of type 2 diabetes patients to evaluate the effects of four adaptive treatment intensification strategies for glucose control (dynamic treatment regimens) on subsequent development or progression of urinary albumin excretion. Three Inverse Probability Weighting estimators are implemented using both model-based and data-adaptive estimation strategies for the propensity scores. Their practical performances for proper confounding and selection bias adjustment are compared and evaluated against results from previous randomized experiments. Results suggest both potential reduction in bias and increase in efficiency at the cost of an increase in computing time when using Super Learning to implement Inverse Probability Weighting estimators to draw causal inferences. Authors: Neugebauer R; Schmittdiel 2016 05 01;12(1):131-55. Evaluation of propensity scores, disease risk scores, and regression in confounder adjustment for the safety of emerging treatment with group sequential monitoring The objective of this study was to evaluate regression, matching, and stratification on propensity score (PS) or disease risk score (DRS) in a setting of sequential analyses where statistical hypotheses are tested multiple times. In a setting of sequential analyses, we simulated incident users and binary outcomes with different confounding strength, outcome incidence, and the adoption rate of treatment. We compared Type I error rate, empirical power, and time to signal using the following confounder adjustments: (i) regression; (ii) treatment matching (1:1 or 1:4) on PS or DRS; and (iii) stratification on PS or DRS. We estimated PS and DRS using lookwise and cumulative methods (all data up to the current look). We applied these confounder adjustments in examining the association between non-steroidal anti-inflammatory drugs and bleeding. Propensity score and DRS methods had similar empirical power and time to signal. However, DRS methods yielded Type I error rates up to 17% for 1:4 matching and 15.3% for stratification methods when treatment and outcome were common and confounding strength with treatment was stronger. When treatment and outcome were not common, stratification on PS and DRS and regression yielded 8-10% Type I error rates and inflated empirical power. However, when outcome and treatment were common, both regression and stratification on PS outperformed other matching methods with Type I error rates close to 5%. We suggest regression and stratification on PS when the outcomes and/or treatment is common and use of matching on PS with higher ratios when outcome or treatment is rare or moderately rare. Authors: Apr;25(4):453-61. Epub 2016-02-15. Waning Tdap Effectiveness in Adolescents Because the effectiveness of diphtheria-tetanus-acellular pertussis (DTaP) vaccine wanes substantially after the fifth dose at ages 4 to 6 years, there is a growing cohort of adolescents who rely on tetanus toxoid, reduced diphtheria toxoid, and acellular pertussis (Tdap) for protection against pertussis. Yet despite high Tdap vaccine coverage among adolescents, California experienced large pertussis outbreaks in 2010 and 2014. We investigated Tdap vaccine effectiveness (VE) and waning within Kaiser Permanente Northern California among adolescents exclusively vaccinated with DTaP vaccines. We modeled pertussis risk in relation to Tdap vaccination status among adolescents beginning on their 10th birthday. We estimated the hazard ratio (HR) for each subsequent year after Tdap compared with unvaccinated adolescents by using Cox regression, adjusting for calendar time, age, gender, race, and facility. We calculated VE as 1 - HR. We also treated time since Tdap vaccination as a continuous variable and estimated the change in the HR per 1-year increase since vaccination. On the basis of 1207 pertussis cases, Tdap VE during the first year after vaccination was 68.8% (95% confidence interval [CI] 59.7% CI -30.6% to 36.4%) by ?4 years after vaccination. Adolescents who were more remote from Tdap were significantly more likely to test positive for pertussis than were those vaccinated more recently (HR per year 1.35, 95% CI 1.22 to 1.50). Routine Tdap did not prevent pertussis outbreaks. Among adolescents who have only received DTaP vaccines in childhood, Tdap provided moderate protection against pertussis during the first year and then waned rapidly so that litle protection remained 2-3 years after vaccination.. Authors: Klein NP; Bartlett J; Fireman B; Baxter R Pediatrics. 2016 Mar;137(3):e20153326. Epub 2016-02-05. Gene by Environment Investigation of Incident Lung Cancer Risk in African-Americans Genome-wide association studies have identified polymorphisms linked to both smoking exposure and risk of lung cancer. The degree to which lung cancer risk is driven by increased smoking, genetics, or gene-environment interactions is not well understood. We analyzed associations between 28 single nucleotide polymorphisms (SNPs) previously associated with smoking quantity and lung cancer in 7156 African-American females in the Women's Health Initiative (WHI), then analyzed main effects of top nominally significant SNPs and interactions between SNPs, cigarettes per day (CPD) and pack-years for lung cancer in an independent, multi-center case-control study of African-American females and males (1078 lung cancer cases and 822 controls). Nine nominally significant SNPs for CPD in WHI were associated with incident lung (corrected p-values from 0.027 to 6.09 \u00d7 10(-5)). CPD was found to be a nominally significant effect modifier between SNP and lung cancer for six SNPs, including CHRNA5 rs2036527[A](betaSNP*CPD = - 0.017, p = 0.0061, corrected p = 0.054), which was associated with CPD in a previous genome-wide meta-analysis of African-Americans. These results suggest that chromosome 15q25.1 variants are robustly associated with CPD and lung cancer in African-Americans and that the allelic dose effect of these polymorphisms on lung cancer risk is most pronounced in lighter smokers. Authors: David SP; Authors: Adherence to Metformin, Statins, and ACE/ARBs Within the Diabetes Health Plan (DHP) Reducing patient cost-sharing and engaging patients in disease management activities have been shown to increase uptake of evidence-based care. To evaluate the effect of employer purchase of a disease-specific plan with reduced cost-sharing and disease management (the Diabetes Health Plan/DHP) on medication adherence among eligible employees and dependents. Employer-level \"intent to treat\" cohort study, including data from eligible employees and their dependents with diabetes, regardless of whether they were enrolled in the DHP. Employers that contracted with a large national health plan administrator in 2009, 2010, and/or 2011. Ten employers that purchased the DHP and 191 employers that did not (controls). Inverse probability weighting (IPW) estimation was used to adjust for inter-group differences. The DHP includes free or low-cost medications and physician visits. Enrollment strategies and specific benefit designs are determined by the employer and vary in practice. DHP participants are notified up front that they must engage in their own health care (e.g., receiving diabetes-related screening) in order to remain enrolled. Mean employee adherence to metformin, statins, and ACE/ARBs at the employer level at one year post-DHP implementation, as measured by the proportion of days covered (PDC). Baseline adherence to the three medications was similar across DHP and control employers, ranging from 64 to 69 %. In the first year after DHP implementation, predicted employer-level adherence for DHP purchase. Non-randomized, observational study. The Diabetes Health Plan, an innovative health plan that combines reduced cost-sharing and disease management with an up-front requirement of enrollee participation in his or her own health care, is associated with a modest improvement in medication adherence at 12 months. Authors: Duru OK; Neugebauer R; Mangione Med. 2015 Nov;30(11):1645-50. Epub 2015-05-06. Balancing Score Adjusted Targeted Minimum Loss-based Estimation Adjusting for a balancing score is sufficient for bias reduction when estimating causal effects including the average treatment effect and effect among the treated. Estimators that adjust for the propensity score in a nonparametric way, such as matching on an estimate of the propensity score, can be consistent when the estimated propensity score is not consistent for the true propensity score but converges to some other balancing score. We call this property the balancing score property, and discuss a class of estimators that have this property. We introduce a targeted minimum loss-based estimator (TMLE) for a treatment-specific mean with the balancing score property that is additionally locally efficient and doubly robust. We investigate the new estimator's performance relative to other estimators, including another TMLE, a propensity score matching estimator, an inverse probability of treatment weighted estimator, and a regression-based estimator in simulation Tumor Subtype, and Breast Cancer Prognosis and Survival Breastfeeding is associated with decreased breast cancer risk, yet associations with prognosis and survival by tumor subtype are largely unknown. We conducted a cohort study of 1636 women from two prospective breast cancer cohorts. Intrinsic tumor subtype (luminal A, luminal B, human epidermal growth factor receptor 2 [HER2]-enriched, basal-like) was determined by the PAM50 gene expression assay. Breastfeeding history was obtained from participant questionnaires. Questionnaires and medical record reviews documented 383 recurrences and 290 breast cancer deaths during a median follow-up of nine years. Multinomial logistic regression was used to estimate odds ratios (ORs) and 95% confidence intervals (CIs) between breastfeeding and tumor subtype. Cox regression was used to estimate hazard ratios (HRs) for breast cancer recurrence or death. Statistical significance tests were two-sided. Breast cancer patients with basal-like tumors were less likely to have previously breastfed than those with luminal A tumors (OR = 0.56, 95% CI = 0.39 to 0.80). Among all patients, ever breastfeeding was associated with decreased risk of recurrence (HR = 0.70, 95% CI = 0.53 to 0.93), especially breastfeeding for six months or more (HR = 0.63, 95% CI = 0.46 to 0.87, P trend = .01). Similar associations were observed for breast cancer death. Among women with luminal A subtype, ever breastfeeding was associated with decreased risks of recurrence (HR = 0.52, 95% CI = 0.31 to 0.89) and breast cancer death (HR = 0.52, 95% CI = 0.29 to 0.93), yet no statistically significant associations were observed among the other subtypes. Effects appeared to be limited to tumors with lower expression of proliferation genes. History of breastfeeding might affect prognosis and survival by establishing a luminal tumor environment with lower proliferative 2015-04-28. High-dimensional propensity score in comparative effectiveness with time-varying interventions The high-dimensional propensity score (hdPS) algorithm was proposed for automation of confounding adjustment in problems involving large healthcare databases. It has been evaluated in comparative effectiveness research (CER) with point treatments to handle baseline confounding through matching or covariance adjustment on the hdPS. In observational studies with time-varying interventions, such hdPS approaches are often inadequate to handle time-dependent confounding and selection bias. Inverse probability weighting (IPW) estimation to fit marginal structural models can adequately handle these biases under the fundamental assumption of no unmeasured confounders. Upholding of this assumption relies on the selection of an adequate set of covariates for bias adjustment. We describe the application and performance of the hdPS algorithm to improve covariate selection in CER with time-varying interventions based on IPW estimation and explore stabilization of the resulting estimates using Super Learning. The evaluation is based on both the analysis of electronic health records data in a real-world CER study of adults with type 2 diabetes and a simulation study. This report (i) establishes the feasibility of IPW estimation with the hdPS algorithm based on large electronic health records databases, (ii) demonstrates little impact on inferences when supplementing the set of expert-selected covariates using the hdPS algorithm in a setting with extensive background knowledge, (iii) supports the application of the hdPS algorithm in discovery settings with little background knowledge or limited data availability, and (iv) motivates the application of Super Learning to stabilize effect estimates based on the 28;34(5):753-81. Epub 2014-12-08. Risk of Cardiovascular Disease Associated With a Restless Legs Syndrome Diagnosis in a Retrospective Cohort Study from Kaiser Permanente Northern California Recent cross-sectional studies suggest that restless legs syndrome (RLS) may be associated with an increased prevalence of cardiovascular disease (CVD) comorbidity or risk factors. We evaluated whether primary or secondary RLS was associated with an increased risk of incident cardiovascular disease in a retrospective cohort study within Kaiser Permanente Northern California (KPNC). We identified members of KPNC with primary RLS and secondary RLS between 1999 and 2008 by an algorithm that incorporated longitudinal clinical records related to the diagnosis and treatment of RLS and comorbidities. We then matched each RLS case with up to 50 individuals with no clinical records of RLS by age, sex, race/ethnicity, zip code, and membership duration. For the analyses we excluded any individual with coronary artery disease (CAD: angina, acute myocardial infarction, coronary revascularization procedure, CAD death), CVD (CAD plus stroke), and hypertension at baseline. New cardiovascular events were determined from clinical records. Follow-up ended at an outcome event, disenrollment from KPNC, or death, whichever occurred earliest. There were over 473,358 person-y of follow-up in this cohort analysis with a mean follow-up time of 3.91 y and range from 6 mo to 12 y. Survival analysis techniques, including survival curves and proportional hazard regression models, were used to assess the association between RLS status and CVD. There were 7,621 primary RLS and 4,507 secondary RLS cases identified and included in the study. In general, primary RLS cases were younger and had less comorbidity than secondary RLS cases. During the follow-up period, CVD was diagnosed in 478 primary RLS cohort members, CAD was diagnosed in 310, and hypertension events were identified in 1,466. Diagnosis in secondary RLS cohort members was made during the follow-up period with 451, 338, and 598 CVD, CAD, and hypertension events, respectively. Subjects with primary RLS had a similar risk of incident CVD (hazard ratio (HR) = 0.95; 95% confidence interval (CI) = 0.86-1.04) and CAD (HR = 0.99; 95% CI = 0.89-1.13) to the comparison cohort, with a slight elevation in the risk of hypertension events (HR = 1.19; 95% CI = 1.12-1.25), after multivariable adjustment. Individuals classified as secondary RLS had a significant increased risk of CVD (HR = 1.33; 95% CI = 1.21-1.46), CAD (HR = 1.40; = 1.25-1.56), and hypertension (HR = 1.28; 95% CI = 1.18-1.40). Primary restless legs syndrome (RLS) was not associated with new-onset cardiovascular disease (CVD) or coronary artery disease (CAD) but was associated with a slight increased risk of hypertension. In contrast, secondary RLS was associated with an increased risk of CVD, CAD, and hypertension. Beverage Choice, and Cancer: A Cohort Study in a Large Kaiser Permanente Population The authors studied incident cancer risk from 1978 to 1985 and through follow-up in 2012 relative to light-to-moderate and heavy drinking and to the choice of alcoholic beverage in a cohort of 124,193 persons. With lifelong abstainers as referent, heavy drinking (? 3 drinks per day) was associated with increased risk of 5 cancer types: upper airway/digestive tract, lung, female breast, colorectal, and melanoma, with light-to-moderate drinking related to all but cancer. incorporating randomized controlled trials and non-randomized comparative cohort studies for assessing the safety and effectiveness of medical treatments: challenges and opportunities Network meta-analysis is increasingly used to allow comparison of multiple treatment alternatives simultaneously, some of which may not have been compared directly in primary research studies. The majority of network meta-analyses published to date have incorporated data from randomized controlled trials (RCTs) only; however, inclusion of non-randomized studies may sometimes be considered. Non-randomized studies can complement RCTs or address some of their limitations, such as short follow-up time, small sample size, highly selected population, high cost, and ethical restrictions. In this paper, we discuss the challenges and opportunities of incorporating both RCTs and non-randomized comparative cohort studies into network meta-analysis for assessing the safety and effectiveness of medical treatments. Non-randomized studies with inadequate control of biases such as confounding may threaten the validity of the entire network meta-analysis. Therefore, identification and inclusion of non-randomized studies must balance their strengths with their limitations. Inclusion of both RCTs and non-randomized studies in network meta-analysis will likely increase in the future due to the growing need to assess multiple treatments simultaneously, the availability of higher quality non-randomized data and more valid methods, and the increased use of progressive licensing and product listing agreements requiring collection of data over the life cycle of medical products. Inappropriate inclusion of non-randomized studies could perpetuate the biases that are unknown, unmeasured, or uncontrolled. However, thoughtful integration of randomized and non-randomized studies may offer opportunities to provide more timely, comprehensive, and generalizable evidence about the comparative safety and effectiveness of medical treatments. Authors: Cameron C; Fireman 2015-11-05. Higher Levels of Cystatin C Are Associated with Worse Cognitive Function in Older Adults with Chronic Kidney Disease: The Chronic Renal Insufficiency Cohort Cognitive Study To determine the association between cognition and levels of cystatin C in persons with chronic kidney disease (CKD). Prospective observational study. Chronic Renal Insufficiency Cohort Cognitive Study. Individuals with a baseline cognitive assessment completed at the same visit as serum cystatin C measurement (N = 821; mean age 64.9, 50.6% male, 48.6% white). Levels of serum cystatin C were categorized into tertiles; cognitive function was assessed using six neuropsychological tests. Scores on these tests were compared across tertiles of cystatin C using linear regression and logistic regression to examine the association between cystatin C level and cognitive performance (1 standard deviation difference from the mean). After multivariable adjustment for age, race, education, and medical comorbidities in linear models, higher levels of cystatin C were associated with worse cognition on the modified Mini-Mental State Examination, Buschke Delayed Recall, Trail-Making Test Part (Trails) A and Part B, and Boston Naming (P < .05 for all). This association remained statistically significant for Buschke Delayed Recall (P = .01) and Trails A (P = .03) after additional adjustment for estimated glomerular filtration rate (eGFR). The highest tertile of cystatin C was associated with greater likelihood of poor performance on Trails A (odds ratio (OR) = 2.17, 95% confidence interval (CI) = 1.16-4.06), Trails B (OR = 1.89, 95% CI = 1.09-3.27), and Boston Naming (OR = 1.85, 95% CI = 1.07-3.19) than the lowest tertile after multivariate adjustment in logistic models. In individuals with CKD, higher serum cystatin C levels were associated with worse cognition and greater likelihood of poor cognitive performance on attention, executive function, and naming. Cystatin C is a marker of cognitive impairment and may be associated with cognition independent of eGFR. Authors: Yaffe K; Soc. 2014 Sep;62(9):1623-9. Epub 2014-08-14. Targeted learning in real-world comparative effectiveness research with time-varying interventions In comparative effectiveness research (CER), often the aim is to contrast survival outcomes between exposure groups defined by time-varying interventions. With observational data, standard regression analyses (e.g., Cox modeling) cannot account for time-dependent confounders on causal pathways between exposures and outcome nor for time-dependent selection bias that may arise from informative right censoring. Inverse probability weighting (IPW) estimation to fit marginal structural models (MSMs) has commonly been applied to properly adjust for these expected sources of bias in real-world observational studies. We describe the application and performance of an alternate estimation approach in such a study. The approach is based on the recently proposed targeted learning methodology and consists in targeted minimum loss-based estimation (TMLE) with super learning (SL) within a nonparametric MSM. The evaluation is based on the analysis of electronic health record data with both IPW estimation and TMLE to contrast cumulative risks under four more or less aggressive strategies for treatment intensification in adults with type 2 diabetes already on 2+ oral agents or basal insulin. Results from randomized experiments provide a surrogate gold standard to validate confounding and selection bias adjustment. Bootstrapping is used to validate analytic estimation of standard errors. This application does the following: (1) establishes the feasibility of TMLE in real-world CER based on large healthcare databases; (2) provides evidence of proper confounding and selection bias adjustment with TMLE and SL; and (3) motivates their application for improving estimation efficiency. Claims are reinforced with a simulation study that also illustrates the double-robustness property of 2014-02-17. Intensive residential treatment for severe obsessive-compulsive disorder: characterizing treatment course and predictors of response. BACKGROUND:Intensive residential treatment (IRT) is effective for severe, treatment-resistant obsessive-compulsive disorder (OCD). We sought to characterize predictors and course of response to IRT.METHODS:Admission, monthly, and discharge data were collected on individuals receiving IRT. We examined the association between baseline characteristics and percent change in OCD symptoms as measured by the Yale-Brown Obsessive-Compulsive Scale (Y-BOCS) using linear regression. We compared baseline characteristics of IRT responders (35% reduction in Y-BOCS) versus non-responders, and of patients who did versus those who did not achieve wellness (Y-BOCS 12) using non-parametric tests. To examine the course of OCD severity over time, we used linear mixed-effects models with randomly varying intercepts and slopes.RESULTS:We evaluated 281 individuals admitted to an IRT program. Greater baseline Y-BOCS scores were associated with a significantly greater percent reduction in Y-BOCS scores ( = -1.49 ([95% confidence interval: -2.06 to -0.93]; P < .001)). IRT responders showed significantly greater baseline Y-BOCS scores than non-responders (mean (SD) 28 (5.2) vs. 25.6 (5.8); P = .003) and lower past-year alcohol use scores than non-responders (1.4 (1.9) vs. 2.1 (2.2); P = .01). Participants who achieved wellness displayed lower hoarding factor scores than those who did not (5 (4.6) vs. 9.53 (6.3); P = .03). OCD symptoms declined rapidly over the first month but more slowly over the remaining two months.CONCLUSIONS:Higher baseline OCD severity, lower past-year alcohol use, and fewer hoarding symptoms predicted better response to IRT. IRT yielded an initial rapid reduction in OCD symptoms, followed by a slower decline after the first month.Copyright \u00a9 2014 Elsevier Ltd. All rights reserved. 23. subtypes from gene expression assay in a population-based breast cancer cohort: Differences by age, race, and tumor characteristics Data are lacking to describe gene expression-based breast cancer intrinsic subtype patterns for population-based patient groups. We studied a diverse cohort of women with breast cancer from the Life After Cancer Epidemiology and Pathways studies. RNA was extracted from 1 mm punches from fixed tumor tissue. Quantitative reverse-transcriptase PCR was conducted for the 50 genes that comprise the PAM50 intrinsic subtype classifier. In a subcohort of 1,319 women, the overall subtype distribution based on PAM50 was luminal and progesterone receptor positive by immunohistochemistry, HER2 negative, and low histologic grade), only 76.5% were categorized as luminal A by PAM50. Continuous-scale luminal A, luminal B, HER2-enriched, and normal-like scores from PAM50 were mutually positively correlated. Basal-like score was inversely correlated with other subtypes. The proportion with non-luminal A subtype decreased with older age at diagnosis, P Trend < 0.0001. Compared with non-Hispanic Whites, African American women were more likely to have basal-like tumors, age-adjusted OR = 4.4 [95% confidence intervals (CI), 2.3-8.4], whereas Asian and Pacific Islander women had reduced odds of basal-like subtype, OR = 0.5 (95% CI, 0.3-0.9). Our data indicate that over 50% of breast cancers treated in the community have luminal A subtype. Gene expression-based classification shifted some tumors categorized as low risk by surrogate clinicopathologic criteria to higher-risk subtypes. Subtyping in a population-based cohort revealed distinct profiles by age and race. 2014-02-12. A pragmatic cluster randomized clinical trial of diabetes prevention strategies for women with gestational diabetes: design and rationale of the Gestational Diabetes' Effects on Moms (GEM) study Women with gestational diabetes (GDM) are at high risk of developing diabetes later in life. After a GDM diagnosis, women receive prenatal care to control their blood glucose levels via diet, physical activity and medications. Continuing such lifestyle skills into early motherhood may reduce the risk of diabetes in this high risk population. In the Gestational Diabetes' Effects on Moms (GEM) study, we are evaluating the comparative effectiveness of diabetes prevention strategies for weight management designed for pregnant/postpartum women with GDM and delivered at the health system level. The GEM study is a pragmatic cluster randomized clinical trial of 44 medical facilities at Kaiser Permanente Northern California randomly assigned to either the intervention or usual care conditions, that includes 2,320 women with a GDM diagnosis between March 27, 2011 and March 30, 2012. A Diabetes Prevention Program-derived print/telephone lifestyle intervention of 13 telephonic sessions tailored to pregnant/postpartum women was developed. The effectiveness of this intervention added to usual care is to be compared to usual care practices alone, which includes two pages of printed lifestyle recommendations sent to postpartum women via mail. Primary outcomes include the proportion of women who reach a postpartum weight goal and total weight change. Secondary outcomes include postpartum glycemia, blood pressure, depression, percent of calories from fat, total caloric intake and physical activity levels. Data were collected through electronic medical records and surveys at baseline (soon after GDM diagnosis), 6 weeks (range 2 to 11 weeks), 6 months (range 12 to 34 weeks) and 12 months postpartum (range 35 to 64 weeks). There is a need for evidence regarding the effectiveness of lifestyle modification for the prevention of diabetes in women with GDM, as well as confirmation that a diabetes prevention program delivered at the health system level is able to successfully reach this population. Given the use of a telephonic case management model, our Diabetes Prevention Program-derived print/telephone intervention has the potential to be adopted in other settings and to inform policies to promote the prevention of diabetes among women with GDM. of hemoglobin A1c imputation using fasting plasma glucose in diabetes research using electronic health records data In studies that use electronic health record data, imputation of important data elements such as Glycated hemoglobin (A1c) has become common. However, few studies have systematically examined the validity of various imputation strategies for missing A1c values. We derived a complete dataset using an incident diabetes population that has no missing values in A1c, fasting and random plasma glucose (FPG and RPG), age, and gender. We then created missing A1c values under two assumptions: missing completely at random (MCAR) and missing at random (MAR). We then imputed A1c values, compared the imputed values to the true A1c values, and used these data to assess the impact of A1c on initiation of antihyperglycemic therapy. Under MCAR, imputation of A1c based on FPG 1) estimated a continuous A1c within 1.88% of the true A1c 68.3% of the time; 2) estimated a categorical A1c within one category from the true A1c about 50% of the time. Including RPG in imputation slightly improved the precision but did not improve the accuracy. Under MAR, including gender and age in addition to FPG improved the accuracy of imputed continuous A1c but not categorical A1c. Moreover, imputation of up to 33% of missing A1c values did not change the accuracy and precision and did not alter the impact of A1c on initiation of antihyperglycemic therapy. When using A1c values as a predictor variable, a simple imputation algorithm based only on age, sex, and fasting plasma glucose gave acceptable results. Authors: Xu S; Neonatal Factors Associated with Autism Spectrum Disorders in Preterm Infants To determine the prevalence of autism spectrum disorders (ASD) across gestational age, examine the risk of ASD by gestational age controlling for other risk factors, and identify potential risk factors in the neonatal intensive care unit. A retrospective cohort of infants born at ? 24 weeks between January 1, 2000, and December 31, 2007 at 11 Kaiser Permanente Northern California hospitals (n = 195,021). ASD cases were defined by a diagnosis made at a Kaiser Permanente ASD evaluation center, by a clinical specialist, or by a pediatrician. Cox proportional hazards regression models were used to evaluate the association between gestational age and ASD as well as potential risk factors in the neonatal intensive care unit and ASD. The prevalence of ASD in infants <37 weeks was 1.78% compared with 1.22% in infants born ? 37 weeks (P < .001). Compared with term infants, infants born at 24-26 weeks had an adjusted hazard ratio (HR) for a diagnosis of ASD of 2.7 (95% CI 1.5-5.0). Infants born at 27-33 weeks (adjusted HR 1.4, 95% CI 1.1-1.8) and 34-36 weeks (adjusted HR 1.3, 95% CI 1.1-1.4) were also at increased risk. High frequency ventilation and intracranial hemorrhage were associated with ASD in infants < 34 weeks. ASD was ~ 3 times more prevalent in infants <27 weeks compared with term infants. Each week of shorter gestation was associated with an increased risk of ASD. High frequency ventilation and intracranial hemorrhage were associated with ASD among 2014 Jan;164(1):20-5. Epub 2013-10-22. Do Medicare Advantage plans select enrollees in higher margin clinical categories? The CMS-HCC risk adjustment system for Medicare Advantage (MA) plans calculates weights, which are effectively relative prices, for beneficiaries with different observable characteristics. To do so it uses the relative amounts spent per beneficiary with those characteristics in Traditional Medicare (TM). For multiple reasons one might expect relative amounts in MA to differ from TM, thereby making some beneficiaries more profitable to treat than others. Much of the difference comes from differences in how TM and MA treat different diseases or diagnoses. Using data on actual medical spending from two MA-HMO plans, we show that the weights calculated from MA costs do indeed differ from those calculated using TM spending. One of the two plans (Plan 1) is more typical of MA-HMO plans in that it contracts with independent community providers, while the other (Plan 2) is vertically integrated with care delivery. We calculate margins, or average revenue/average cost, for Medicare beneficiaries in the two plans who have one of 48 different combinations of medical conditions. The two plans' margins for these 48 conditions are correlated (r=0.39, p<0.01). Both plans have margins that are more positive for persons with conditions that are managed by primary care physicians and where medical management can be effective. Conversely they have lower margins for persons with conditions that tend to be treated by specialists with greater market power than primary care physicians and for acute conditions where little medical management is possible. The two plan's margins among beneficiaries with different observable characteristics vary over a range of 160 and 98 percentage points, respectively, and thus would appear to offer substantial incentive for selection by HCC. Nonetheless, we find no evidence of overrepresentation of beneficiaries in high margin HCC's in either plan. Nor, using the margins from Plan 1, the more typical plan, do we find evidence of overrepresentation of high margin HCC's in Medicare more generally. These results do not permit a conclusion on overall social efficiency, but we note that selection according to margin could be socially efficient. In addition, our findings suggest there are omitted interaction terms in the risk adjustment model that Medicare currently uses. Authors: Newhouse JP; McWilliams JM; Price M; Huang Hsu J Health Econ. 2013 Dec;32(6):1278-88. Impact of Specific Glucose-Control Strategies on Microvascular and Macrovascular Outcomes in 58,000 Adults With Type 2 Diabetes Comparative effectiveness research methods are used to compare the effect of four distinct glucose-control strategies on subsequent myocardial infarction and nephropathy in type 2 diabetes. A total of 58,000 adults with type 2 diabetes and A1C <7% (53 mmol/mol) while taking two or more oral agents or basal insulin had subsequent A1C ?7% (53 mmol/mol) to 8.5% mmol/mol). Follow-up started on date of first A1C ?7% and ended on date of a specific clinical event, death, disenrollment, or study end. Glucose-control strategies were defined as first intensification of glucose-lowering therapy at A1C ?7, ?7.5, ?8, or ?8.5% with subsequent control for treatment adherence. Logistic marginal structural models were fitted to assess the discrete-time hazards for each dynamic glucose-control strategy, adjusting for baseline and time-dependent confounding and selection bias through inverse probability weighting. After adjustment for age, sex, race/ethnicity, comorbidities, blood pressure, lipids, BMI, and other covariates, progressively more aggressive glucose-control strategies were associated with reduced onset or progression of albuminuria but not associated with significant reduction in occurrence of myocardial infarction or preserved renal function based on estimated glomerular filtration rate over 4 years of follow-up. In a large representative cohort of adults with type 2 diabetes, more aggressive glucose-control strategies have mixed short-term effects on microvascular complications and do not reduce the myocardial infarction rate over 4 years of follow-up. These findings are consistent with the results of recent clinical trials, but confirmation over longer periods of observation is needed. Authors: Neugebauer R; Fireman B; Roy Nov;36(11):3510-6. Epub 2013-07-22. Multivariable confounding adjustment in distributed data networks without sharing of patient-level data It is increasingly necessary to analyze data from multiple sources when conducting public health safety surveillance or comparative effectiveness research. However, security, privacy, proprietary, and legal concerns often reduce data holders' willingness to share highly granular information. We describe and compare two approaches that do not require sharing of patient-level information to adjust for confounding in multi-site studies. We estimated the risks of angioedema with enzyme inhibitors (ACEIs), comparison with beta-blockers within Mini-Sentinel, which has created a distributed data system of 18 health plans. To obtain the adjusted hazard ratios (HRs) and 95% confidence intervals (CIs), we performed (i) a propensity score-stratified case-centered logistic regression analysis, a method identical to a stratified Cox regression analysis but needing only aggregated risk set data, and (ii) an inverse variance-weighted meta-analysis, which requires only the site-specific HR and variance. We also performed simulations to further compare the two methods. Compared with beta-blockers, the adjusted HR was 3.04 (95% 2.85 (1.34, 6.04) for aliskiren in the case-centered analysis. The corresponding HRs were 2.98 (2.76, 3.21), 1.15 (1.00, 1.33), and 2.86 (1.35, 6.04) in the meta-analysis. Simulations suggested that the two methods may produce different results under certain analytic scenarios. The case-centered analysis and the meta-analysis produced similar results without the need to share patient-level data across sites in our empirical study, but may provide different results in other study settings. Authors: Toh S; Fireman BH; Hennessy Nov;22(11):1171-7. Epub 2013-07-23. Socioeconomic Status and Lung Cancer: Unraveling the Contribution of Genetic Admixture OBJECTIVES: We examined the relationship between genetic ancestry, socioeconomic status (SES), and lung cancer among African Americans and Latinos. METHODS: We evaluated SES and genetic ancestry in a Northern California lung cancer case-control study (1998-2003) of African Americans and Latinos. Lung cancer case and control participants were frequency matched on age, gender, and race/ethnicity. We assessed case-control differences in individual admixture proportions using the 2-sample t test and analysis of covariance. Logistic regression models examined associations among genetic ancestry, socioeconomic characteristics, and lung cancer. RESULTS: Decreased Amerindian ancestry was associated with higher education among Latino control participants and greater African ancestry was associated with decreased education among African lung cancer case participants. Education was associated with lung cancer among both Latinos and African Americans, independent of smoking, ancestry, age, and gender. Genetic ancestry was not associated with lung cancer among African Americans. CONCLUSIONS: Findings suggest that socioeconomic factors may have a greater impact than genetic ancestry on lung cancer among African Americans. The genetic heterogeneity and recent dynamic migration and acculturation of Latinos complicate recruitment; thus, epidemiological analyses and findings Health. 2013 Oct;103(10):e73-80. Epub 2013 Aug 15. Implementation of an outpatient electronic health record and emergency department visits, hospitalizations, and office visits among patients with diabetes IMPORTANCE: The US federal government is spending billions of dollars in physician incentives to encourage the meaningful use of electronic health records (EHRs). Although the use of EHRs has potential to improve patient health outcomes, the existing evidence has been limited and inconsistent. OBJECTIVE: To examine the association between implementing a commercially available outpatient EHR and emergency department (ED) visits, hospitalizations, and office visits for patients with diabetes mellitus. DESIGN, SETTING, AND POPULATION: Staggered EHR implementation across outpatient clinics in an integrated delivery system (Kaiser Permanente Northern California) between 2005 and 2008 created an opportunity for studying changes associated with EHR use. Among a population-based sample of 169,711 patients with diabetes between 2004 and 2009, we analyzed 4,997,585 person-months before EHR implementation and 4,648,572 person-months after an EHR was being used by patients' physicians. MAIN OUTCOMES AND MEASURES: We examined the association between EHR use and unfavorable clinical events (ED visits and hospitalizations) and office visit use among patients with diabetes, using multivariable regression with patient-level fixed-effect analyses and adjustment for trends over time. RESULTS: In multivariable analyses, use of the EHR was associated with a statistically significantly decreased number of ED visits, 28.80 fewer visits per 1000 patients annually (95% CI, 20.28 to 37.32), from a mean of 519.12 visits per 1000 patients annually without using the EHR to 490.32 per 1000 patients when using the EHR. The EHR was also associated with 13.10 fewer hospitalizations per 1000 patients annually (95% CI, 7.37 to 18.82), from a mean of 251.60 hospitalizations per 1000 patients annually with no EHR to 238.50 per 1000 patients annually when using the EHR. There were similar statistically significant reductions in nonelective hospitalizations (10.92 fewer per 1000 patients annually) and hospitalizations for ambulatory care-sensitive conditions (7.08 fewer per 1000 patients annually). There was no statistically significant association between EHR use and office visit rates. CONCLUSIONS AND RELEVANCE: Among patients with diabetes, use of an outpatient EHR in an integrated delivery system was associated with modest reductions in ED visits and hospitalizations but not office visit rates. Further studies are needed to quantify the association of EHR use with changes in costs. Authors: Reed M; J JAMA. 2013 Sep 11;310(10):1060-5. Risk of Coronary Disease in South Asian Americans Authors: A; Cardiol. 2013 Aug 13;62(7):644-5. Epub 2013 Jun 13. Super learning to hedge against incorrect inference from arbitrary parametric assumptions in marginal structural modeling OBJECTIVE: Clinical trials are unlikely to ever be launched for many comparative effectiveness research (CER) questions. Inferences from hypothetical randomized trials may however be emulated with marginal structural modeling (MSM) using observational data, but success in adjusting for time-dependent confounding and selection bias typically relies on parametric modeling assumptions. If these assumptions are violated, inferences from MSM may be inaccurate. In this article, we motivate the application of a data-adaptive estimation approach called super learning (SL) to avoid reliance on arbitrary parametric assumptions in CER. STUDY DESIGN AND SETTING: Using the electronic health records data from adults with new-onset type 2 diabetes, we implemented MSM with inverse probability weighting (IPW) estimation to evaluate the effect of three oral antidiabetic therapies on the worsening of glomerular filtration rate. RESULTS: Inferences from IPW estimation were noticeably sensitive to the parametric assumptions about the associations between both the exposure and censoring processes and the main suspected source of confounding, that is, time-dependent measurements of hemoglobin A1c. SL was successfully implemented to harness flexible confounding and selection bias adjustment from existing machine learning algorithms. CONCLUSION: Erroneous IPW inference about clinical effectiveness because of arbitrary and incorrect modeling decisions may be avoided with SL. Authors: Neugebauer R; Fireman B; Aug;66(8 Suppl):S99-109. Confounding adjustment in comparative effectiveness research conducted within distributed research networks BACKGROUND: A distributed research network (DRN) of electronic health care databases, in which data reside behind the firewall of each data partner, can support a wide range of comparative effectiveness research (CER) activities. An essential component of a fully functional DRN is the capability to perform robust statistical analyses to produce valid, actionable evidence without compromising patient privacy, data security, or proprietary interests. OBJECTIVES AND METHODS: We describe the strengths and limitations of different confounding adjustment approaches that can be considered in observational CER studies conducted within DRNs, and the theoretical and practical issues to consider when selecting among them in various study settings. RESULTS: Several methods can be used to adjust for multiple confounders simultaneously, either as individual covariates or as confounder summary scores (eg, propensity scores and disease risk scores), including: (1) centralized analysis of patient-level data, (2) case-centered logistic regression of risk set data, (3) stratified or matched analysis of aggregated data, (4) distributed regression analysis, and (5) meta-analysis of site-specific effect estimates. These methods require different granularities of information be shared across sites and afford investigators different levels of analytic flexibility. CONCLUSIONS: DRNs are growing in use and sharing of highly detailed patient-level information is not always feasible in DRNs. Methods that incorporate confounder summary scores allow investigators to adjust for a large number of confounding factors without the need to transfer potentially identifiable information in DRNs. They have the potential to let investigators perform many analyses traditionally conducted through a centralized dataset with detailed patient-level information. Aug;51(8 Suppl 3):S4-10. Targeted maximum likelihood estimation in safety analysis OBJECTIVES: To compare the performance of a targeted maximum likelihood estimator (TMLE) and a collaborative TMLE (CTMLE) to other estimators in a drug safety analysis, including a regression-based estimator, propensity score (PS)-based estimators, and an alternate doubly robust (DR) estimator in a real example and simulations. STUDY DESIGN AND SETTING: The real data set is a subset of observational data from Kaiser Permanente Northern California formatted for use in active drug safety surveillance. Both the real and simulated data sets include potential confounders, a treatment variable indicating use of one of two antidiabetic treatments and an outcome variable indicating occurrence of an acute myocardial infarction (AMI). RESULTS: In the real data example, there is no difference in AMI rates between treatments. In simulations, the double robustness property is demonstrated: DR estimators are consistent if either the initial outcome regression or PS estimator is consistent, whereas other estimators are inconsistent if the initial estimator is not consistent. In simulations with near-positivity violations, CTMLE performs well relative to other estimators by adaptively estimating the PS. CONCLUSION: Each of the DR estimators was consistent, and TMLE and CTMLE had the smallest mean squared error in simulations. Authors: Lendle SD; Fireman 2013 Aug;66(8 Adverse Clinical Events Among Medicare Beneficiaries Using Antipsychotic Drugs: Linking Health Insurance Benefits and Clinical Needs OBJECTIVE: Medicare Part D provides formulary protections for antipsychotics but does not exempt these drugs from cost-sharing. We investigated the impact of Part D coverage on antipsychotic drug spending, adherence, and clinical outcomes among beneficiaries with varying indications for use. METHODS: We conducted a historical cohort study of Medicare Advantage beneficiaries who received antipsychotic drugs, with diagnoses of schizophrenia or bipolar disorder or with no mental health diagnoses (N=10,190). Half had a coverage gap; half had no gap because of low-income subsidies. Using fixed effects regression models, we examined changes in spending and adherence as beneficiaries experienced cost-sharing increases after reaching the gap. We examined changes in hospitalizations and emergency department visits using proportional hazard models. RESULTS: Across all diagnostic groups, total monthly expenditure on antipsychotic drugs decreased with cost-sharing increases in the gap compared with those with no gap (eg, schizophrenia: -$123 95% $104 [$98, $110]). Adherence similarly decreased, with the largest declines among those with schizophrenia (-20.6 percentage points [-22.3, -18.9] in proportion of days covered). Among beneficiaries with schizophrenia and bipolar disorder, hospitalizations and emergency department visit rates increased with cost-sharing increases (eg, schizophrenia: hazard ratio=1.32 [1.06, 1.65] for all hospitalizations), but did not among subjects without mental health diagnoses. Clinical event rates did not change among beneficiaries with low-income subsidies without gaps. CONCLUSIONS: There is evidence of interruptions in antipsychotic use attributable to Part D cost-sharing. Adverse events increased among beneficiaries with approved indications for use, but not among beneficiaries without such indications. Authors: Fung V; Newhouse JP; Hsu J Med Care. 2013 Jul;51(7):614-21. Effectiveness and Reach of the FLU-FIT Program in an Integrated Health Care System: A Multisite Randomized Trial OBJECTIVES: We tested the effectiveness of offering home fecal immunochemical tests (FITs) during influenza vaccination clinics to increase colorectal cancer screening (CRCS). METHODS: In a clinical trial at Kaiser Permanente Northern California influenza clinics in Redwood City, Richmond, South San Francisco, Union City, and Fresno, we randomly assigned influenza clinic dates to intervention (FIT offered) or control (FIT not offered) and compared subsequent CRCS activity. RESULTS: Clinic staff provided FITs to 53.9% (1805/3351) of intervention patients aged 50 to 75 years. In the intent-to-treat analysis, 26.9% (900/3351) and 11.7% (336/2884) of intervention and control patients completed an FIT, respectively, within 90 days of vaccination (P = .001). The adjusted odds ratio for completing FIT in the intervention versus the control arm was 2.75 (95% confidence interval = 2.40, 3.16). In the per protocol analysis, 35.4% (648/1830) of patients given FIT and 13.3% (588/4405) of patients not given FIT completed FIT within 90 days of vaccination (P = .001). CONCLUSIONS: This intervention may increase CRCS among those not reached by other forms of CRCS outreach. Future research should include the extent to which these programs can be disseminated and implemented nationally. Authors: Potter MB; Ackerson Am J Public Health. 2013 Jun;103(6):1128-33. Epub 2013 Apr 18. Technical evaluation of methods for identifying chemotherapy-induced febrile neutropenia in healthcare claims databases. BACKGROUND:Healthcare claims databases have been used in several studies to characterize the risk and burden of chemotherapy-induced febrile neutropenia (FN) and effectiveness of colony-stimulating factors against FN. The accuracy of methods previously used to identify FN in such databases has not been formally evaluated.METHODS:Data comprised linked electronic medical records from Geisinger Health System and healthcare claims data from Geisinger Health Plan. Subjects were classified into subgroups based on whether or not they were hospitalized for FN per the presumptive \"gold standard\" (ANC <1.0\u00d710(9)/L, and body temperature 38.3\u00b0C or receipt of antibiotics) and claims-based definition (diagnosis codes for neutropenia, fever, and/or infection). Accuracy was evaluated principally based on positive predictive value (PPV) and sensitivity.RESULTS:Among 357 study subjects, 82 (23%) met the gold standard for hospitalized FN. For the claims-based definition including diagnosis codes for neutropenia plus fever in any position (n=28), PPV was 100% and sensitivity was 34% (95% CI: 24-45). For the definition including primary position (n=54), PPV was 87% (78-95) and sensitivity was 57% (46-68). the definition neutropenia in any position PPV was 77% was 67% (56-77).CONCLUSIONS:Patients hospitalized for chemotherapy-induced FN can be identified in healthcare claims databases--with an acceptable level of mis-classification--using diagnosis codes for 13;13:60. Retinopathy Cognitive Impairment in Adults With CKD BACKGROUND: Retinal microvascular abnormalities have been associated with cognitive impairment, possibly serving as a marker of cerebral small-vessel disease. This relationship has not been evaluated in persons with chronic kidney disease (CKD), a condition associated with increased risk of both retinal pathology and cognitive impairment. STUDY DESIGN: Cross-sectional study. SETTING & PARTICIPANTS: 588 participants 52 years or older with CKD in the Chronic Renal Insufficiency Cohort (CRIC) Study. PREDICTOR: Retinopathy graded using the Early Treatment Diabetic Retinopathy Study severity scale and diameters of retinal vessels. OUTCOMES: Neuropsychological battery of 6 cognitive tests. MEASUREMENTS: Logistic regression models were used to evaluate the association of retinopathy, individual retinopathy features, and retinal vessel diameters with cognitive impairment (=1 SD from the mean), and linear regression models were used to compare cognitive test scores across levels of retinopathy, adjusting for age, race, sex, education, and medical comorbid conditions. RESULTS: The mean age of the cohort was 65.3+/-5.6 (SD) years, 51.9% were nonwhite, and 52.6% were men. The prevalence of retinopathy was 30.1%, and the prevalence of cognitive impairment was 14.3%. Compared with those without retinopathy, participants with retinopathy had an increased likelihood of cognitive impairment on executive function (35.1% vs 11.5%; OR, 3.4 [95% CI, 2.0-6.0]), attention (26.7% 7.3%; 3.0 [95% 1.8-4.9]), naming vs 10.0%; OR, 2.1 [95% CI, 1.2-3.4]) after multivariable adjustment. Increased level of retinopathy also was associated with lower cognitive performance on executive function and attention. Microaneurysms were associated with cognitive impairment on some domains, but there were no significant associations with other retinal measures after multivariable adjustment. LIMITATIONS: Unknown temporal relationship between retinopathy and impairment. CONCLUSIONS: In adults with CKD, retinopathy is associated with poor performance on several cognitive domains, including executive function and attention. Evaluation of retinal microvascular abnormalities may be a promising tool for identifying patients with CKD who are at increased risk of cognitive impairment. Authors: Yaffe K; Go AS; CRIC Study Investigators; et al. Am J Kidney Dis. 2013 Feb;61(2):219-27. Epub 2012 Dec 1. Impact of type 2 diabetes on lower urinary tract symptoms in men: a cohort study BACKGROUND: Studies of the impact of type 2 diabetes on the prevalence and incidence of lower urinary tract symptoms (LUTS) among men have provided divergent results. We sought to examine this issue using two large and diverse cohorts. METHODS: This study used questionnaire and clinical data from two large multiethnic cohorts, the California Men's Health Study (CMHS) and Research Program in Genes, Environment and Health (RPGEH). Diabetes characteristics data were derived from questionnaire and Diabetes Registry data. LUTS were measured using a standardized scale. Socioeconomic and comorbidity data were obtained by self-report. Multivariable logistic regression analysis was used to examine the association between baseline DM status and prevalence and incidence of LUTS, with adjustment for potential confounding variables. RESULTS: We found type 2 diabetes to be associated with prevalent LUTS (odds ratio (OR) = 1.32, 95% confidence interval (CI) 1.26, 1.38). The association was stronger among men with type 2 diabetes who were on active pharmaceutical treatment and had it for a longer duration. No association was observed between type 2 diabetes and new onset LUTS. CONCLUSIONS: Type 2 diabetes increases the risk of Den 20;13:12. Social networks, social support, and burden in relationships, and mortality after breast cancer diagnosis in the Life After Breast Cancer Epidemiology (LACE) Study Larger social networks have been associated with lower breast cancer mortality. The authors evaluated how levels of social support and burden influenced this association. We included 2,264 women from the Life After Cancer Epidemiology study who were diagnosed with early-stage, invasive breast cancer between 1997 and 2000, and provided data on social networks (spouse or intimate partner, religious/social ties, volunteering, time socializing with friends, and number of first-degree female relatives), social support, and caregiving. 401 died during a median follow-up of 10.8 years follow-up with 215 from breast cancer. We used delayed entry Cox proportional hazards regression to evaluate associations. In multivariate-adjusted analyses, social isolation was unrelated to recurrence or breast cancer-specific mortality. However, socially isolated women had higher all-cause mortality (HR = 1.34, 95 % CI: 1.03-1.73) and mortality from other causes (HR = 1.79, 95 % CI: 1.19-2.68). Levels of social support and burden modified associations. Among those with low, but not high, levels of social support from friends and family, lack of religious/social participation (HR = 1.58, 95 % CI: 1.07-2.36, p = 0.02, p interaction = 0.01) and lack of volunteering (HR = 1.78, 95 % CI: 1.15-2.77, p = 0.01, p interaction = 0.01) predicted higher all-cause mortality. In cross-classification analyses, only women with both small networks and low levels of support (HR = 1.61, 95 % CI: 1.10-2.38) had a significantly higher risk of mortality than women with large networks and high levels of support; women with small networks and high levels of support had no higher risk of mortality (HR = 1.13, 95 % CI: 0.74-1.72). Social networks were also more important for caregivers versus noncaregivers. Larger social networks predicted better prognosis after breast cancer, but associations depended on the quality and burden of family relationships. Authors: Kroenke Cancer Res Treat. 2013 Jan;137(1):261-71. Epub 2012 Nov 10. Patient awareness and knowledge of breast cancer-related lymphedema in a large, integrated health care delivery system Breast cancer patients have voiced dissatisfaction regarding their education on breast cancer-related lymphedema risk and risk reduction strategies from their clinicians. Informing patients about lymphedema can contribute to decrease their risk of developing the condition, or among those already affected, prevent it from progressing further. In this cross-sectional study, a lymphedema awareness score was calculated based on responses to a brief telephone interview conducted among 389 women diagnosed with invasive breast cancer at Kaiser Permanente Northern California from 2000 to 2008 and had a previous record of a lymphedema-related diagnosis or procedure in their electronic medical record. During the telephone interview, women self-reported a lymphedema clinical diagnosis, lymphedema symptoms but no lymphedema diagnosis, or neither a diagnosis nor symptoms, and responded to questions on lymphedema education and support services as well as health knowledge. Multivariable logistic regression [odds ratio (OR) and 95 % confidence interval (CI)] was used to determine the associations of selected sociodemographic and clinical factors with the odds of having lymphedema awareness (adequate vs. inadequate). The median (range) of the lymphedema awareness score was 4 (0-7). Compared with patients <50 years of age, patients 70+ years of age at breast cancer diagnosis had lower odds of adequate lymphedema awareness (OR 0.25; 95 % CI 0.07, 0.89), while patients 50-59 and 60-69 years had greater odds of adequate awareness although not statistically significant (OR 2.05; 95 % CI 0.88, 4.78 and OR 1.55; 95 % CI 0.60, 4.02, respectively; p for trend = 0.09). Higher educational level and greater health literacy were suggestive of adequate awareness yet were not significant. These results can help inform educational interventions to strengthen patient knowledge of lymphedema risk and risk reduction practices, particularly in an integrated health care delivery setting. With the growing population of breast cancer survivors, increasing patient awareness and education about lymphedema risk reduction and care after cancer diagnosis is warranted. Authors: Kwan ML; Treat. 2012 Sep;135(2):591-602. Epub 2012 Aug 19. Cigarette Smoking Associated With Lung Adenocarcinoma In Situ in a Large Case-Control Study (SFBALCS) INTRODUCTION:: Adenocarcinoma in situ (AIS), formerly bronchioloalveolar carcinoma, is an uncommon subtype of lung adenocarcinoma and accounts for approximately 3% to 4% of lung cancers. Compared with other lung cancer histologies, AIS patients are less likely to be smokers, yet associations with other lung cancer risk factors and differences by sex have not been determined. METHODS:: A total of 338 AIS patients and frequency-matched controls from the parent study (cases = 6039, controls = 2073) were included in these analyses. Odds ratios and 95% confidence intervals as estimates of the relative risk were obtained from multivariable unconditional logistic regression analyses. RESULTS:: Risk of AIS was associated with ever smoking (OR = 2.7, 95% confidence intervals: 2.1, 3.6), increased 20% to 30% for each 10-year increase in pack-years of smoking and decreased with increased years since quitting (p for trend <0.0001). There was no evidence that risk differed by sex but there was some suggestion that risk may differ by exposure to asbestos and by second-hand tobacco smoke exposure in whites. CONCLUSION:: There is an association between AIS and smoking, which is smaller in magnitude than the association between other subtypes of non-small-cell lung cancer and smoking. Our findings suggesting that effects may differ by exposure to asbestos and second-hand tobacco smoke should be interpreted conservatively and warrant validation and further evaluation in larger studies of AIS. Sep;7(9):1352-60. Mortality and the self-controlled case series method. Response to Letter to Editor Authors: Maclure M; Fireman B; Nelson J; 2012 Aug;21(8):907. Influence of breastfeeding during the postpartum oral glucose tolerance test on plasma glucose and insulin OBJECTIVE: To examine the effect of breastfeeding during the postpartum oral glucose tolerance test (OGTT) on maternal blood glucose and insulin among women with recent gestational diabetes mellitus. METHODS: Participants were enrolled in the Study of Women, Infant Feeding, and Type 2 Diabetes, a prospective observational cohort study of 1,035 Kaiser Permanente Northern California members who had been diagnosed with GDM and subsequently underwent a 2-hour 75-g OGTT at 6-9 weeks postpartum for the study enrollment examinations from 2008 to 2011. For this analysis, we selected 835 study participants who reported any intensity of lactation and were observed either breastfeeding their infants (ie, putting the infant to the breast) or not breastfeeding during the OGTT. RESULTS: Of 835 lactating women, the 2-hour 75-g OGTT at 6-9 weeks postpartum. Mean (standard deviation) duration of breastfeeding during the OGTT was 15.3 (8.1) minutes. Compared with not having breastfed during the OGTT, having breastfed during the test was associated with lower adjusted mean (95% confidence interval) 2-hour glucose -0.15 (-0.25 to -0.06; P<.01), insulin sensitivity index0,120 by 0.08 (0.02-0.15; P=.02), but no differences in plasma fasting glucose or insulin concentrations. CONCLUSION: Among postpartum women with recent gestational diabetes mellitus, breastfeeding an infant during the 2-hour 75-g OGTT may modestly lower plasma 2-hour glucose (5% lower on average) as well as insulin concentrations in response to ingestion of glucose. epidemiological studies with strong confounding One of the identifiability assumptions of causal effects defined by marginal structural model (MSM) parameters is the experimental treatment assignment (ETA) assumption. Practical violations of this assumption frequently occur in data analysis when certain exposures are rarely observed within some strata of the population. The inverse probability of treatment weighted (IPTW) estimator is particularly sensitive to violations of this assumption; however, we demonstrate that this is a problem for all estimators of causal effects. This is due to the fact that the ETA assumption is about information (or lack thereof) in the data. A new class of causal models, causal models for realistic individualized exposure rules (CMRIER), is based on dynamic interventions. CMRIER generalize MSM, and their parameters remain fully identifiable from the observed data, even when the ETA assumption is violated, if the dynamic interventions are set to be realistic. Examples of such realistic interventions are provided. We argue that causal effects defined by CMRIER may be more appropriate in many situations, particularly those with policy considerations. Through simulation studies, we examine the performance of the IPTW estimator of the CMRIER parameters in contrast to that of the MSM parameters. We also apply the methodology to a real data analysis in air pollution epidemiology to illustrate the interpretation of the causal effects defined by CMRIER. Copyright (c) 2012 John Wiley & Sons, Ltd. 2012 Jun 15;31(13):1380-404. Epub 2012 Feb 23. Plasma signaling proteins in persons at genetic risk for Alzheimer disease: influence of APOE genotype. OBJECTIVE:To study the effect of familial Alzheimer disease (FAD) mutations and APOE genotype on plasma signaling protein levels.DESIGN:Cross-sectional comparison of plasma levels of 77 proteins measured using multiplex immune assays.SETTING:A tertiary referral dementia research center.PARTICIPANTS:Thirty-three persons from families harboring PSEN1 or APP mutations, aged 19 to 59 years.MAIN OUTCOME MEASURES:Protein levels were compared between FAD mutation carriers (MCs) and noncarriers (NCs) and among APOE genotype groups, using multiple linear regression models.RESULTS:Twenty-one participants were FAD MCs and 12 were NCs. Six had the APOE 2/3, 6 had the 3/4, and 21 had the 3/3 genotype. Levels of 17 proteins differed among APOE genotype groups, and there were significant interactions between age and APOE genotype for 12 proteins. Plasma levels of apolipoprotein E and superoxide dismutase 1 were highest in the 2 carriers, lowest in 4 carriers, and intermediate in the 3 carriers. Levels of multiple interleukins showed the opposite pattern and, among the 4 carriers, demonstrated significant negative correlations with age. Although there were no significant differences between FAD MCs and NCs, there were interactions between mutation status and APOE genotype for 13 proteins.CONCLUSIONS:We found different patterns of inflammatory markers in young and middle-aged persons among APOE genotype groups. The APOE 4 carriers had the lowest levels of apolipoprotein E. Young 4 carriers have increased inflammatory markers that diminish with age. We demonstrated altered inflammatory responses in young and middle adulthood in 4 carriers that may relate to AD risk later in Jun;69(6):757-64. doi: 10.1001/archneurol.2012.277. The value of additional pathology comments indicating suspicion of adenocarcinoma among women diagnosed preoperatively with complex atypical endometrial hyperplasia Over 40% of women with a preoperative diagnosis of complex atypical hyperplasia (CAH) will have endometrial cancer at hysterectomy. CAH diagnoses are often qualified by comments indicating suspicion of cancer. We examine whether these comments correlate with cancer found at hysterectomy. Pathology reports for 824 women with CAH diagnoses who underwent hysterectomy were reviewed to identify those qualified by comments indicating concern for cancer. The rate of cancer, severity of disease, and effects of endometrial sampling method and age were determined. Comments indicating suspicion of cancer qualified 219 of 824 (27%) CAH diagnoses and were associated with a significantly higher cancer rate at hysterectomy (69% versus 40%; P<0.0001), regardless of whether sampling consisted of curettage or biopsy. Cancer severity correlated independently with age. Comments indicating concern for underlying cancer frequently qualify CAH diagnoses and are associated with a high likelihood of cancer and with more extensive disease, especially for older women. Authors: Suh-Burgmann E; Hung YY; Armstrong MA Int J Gynecol Pathol. 2012 May;31(3):222-6. Dynamic marginal structural modeling to evaluate the comparative effectiveness of more or less aggressive treatment intensification strategies in adults with type 2 diabetes PURPOSE: Chronic disease care typically involves treatment decisions that are frequently adjusted to the patient's evolving clinical course (e.g., hemoglobin A1c monitoring and treatment intensification in diabetes patients). Thus, in comparative effectiveness and safety research (CER), it often is less clinically relevant to contrast the health effects of static treatment decisions than to compare the effectiveness of competing medical guidelines, that is, adaptive treatment strategies that map the patient's unfolding clinical course to subsequent treatment decisions. With longitudinal observational studies, treatment decisions at any point in time may be influenced by clinical factors that also are risk factors for the outcome of interest. Such time-dependent confounders cannot be properly handled with standard statistical approaches, because such confounders may be influenced by previous treatment decisions and may thus lie on causal pathways between the very outcomes and early treatment decisions whose effects are under study. Under explicit assumptions, we motivate the application of inverse probability weighting estimation to fit dynamic marginal structural models (MSMs) in observational studies to address pragmatic CER questions and properly adjust for time-dependent confounding and informative loss to follow-up. METHODS: We review the principles behind this modeling approach and describe its application in an observational study of type 2 diabetes patients to investigate the comparative effectiveness of four adaptive treatment intensification strategies for glucose control on subsequent development or progression of urinary albumin excretion. RESULTS: Results indicate a protective effect of more aggressive treatment intensification strategies in patients already on two or more oral agents or basal insulin. These conclusions are concordant with recent randomized trials. CONCLUSIONS: Inverse probability weighting estimation to fit dynamic MSM is a viable and appealing alternative to inadequate standard modeling approaches in many CER problems where time-dependent confounding and informative loss to follow-up are expected. Copyright (c) 2012 John Wiley & Sons, Ltd. Authors: sizes for predementia Alzheimer's trials based on the Alzheimer's Disease Neuroimaging Initiative This study modeled predementia Alzheimer's disease clinical trials. Longitudinal data from cognitively normal (CN) and mild cognitive impairment (MCI) participants in the Alzheimer's Disease Neuroimaging Initiative were used to calculate sample size requirements for trials using outcome measures, including the Clinical Dementia Rating scale sum of boxes, Mini-Mental State Examination, Alzheimer's Disease Assessment Scale-cognitive subscale with and without delayed recall, and the Rey Auditory Verbal Learning Task. We examined the impact on sample sizes of enrichment for genetic and biomarker criteria, including cerebrospinal fluid protein and neuroimaging analyses. We observed little cognitive decline in the CN population at 36 months, regardless of the enrichment strategy. Nonetheless, in CN subjects, using Rey Auditory Verbal Learning Task total as an outcome at 36 months required the fewest subjects across enrichment strategies, with apolipoprotein E genotype 4 carrier status requiring the fewest (n = 499 per arm to demonstrate a 25% reduction in disease progression). In MCI, enrichment reduced the required sample sizes for trials, relative to estimates based on all subjects. For MCI, the Clinical Dementia Rating scale sum of boxes consistently required the smallest sample sizes. We conclude that predementia clinical trial conduct in Alzheimer's disease is enhanced by the use of biomarker inclusion criteria. Authors: Grill 13. Single-institution, multidisciplinary surgical resection of primary chest wall sarcomas. INTRODUCTION:Primary chest wall sarcomas are rare mesenchymal tumors and their mainstay of therapy is wide surgical resection. We report our single-institution, multidisciplinary experience with full-thickness resection for primary chest wall sarcomas.METHODS:A retrospective review of our prospectively maintained databases revealed that 51 patients were referred for primary chest wall sarcomas from 1990 to 2009.RESULTS:All patients required resections that included rib and/or sternum. Twenty-nine patients (57%) had extended resections beyond the chest wall. Forty-two patients (82%) required prosthetic reconstruction and 17 patients (33%) had muscle flap coverage. Overall, 51% (26/51) of patients received neoadjuvant therapy. desmoid tumors were treated with induction therapy. Negative margins were obtained in 46 patients (90%). There were no perioperative mortalities. Eight patients (16%) experienced complications. Local recurrence and metastasis was detected in 14 and 23%. Five-year overall and disease-free survivals were 66% and 47%, respectively. Favorable prognostic variables for survival included age 50 years, tumor volume 200 cm, desmoid tumor, bony tumor, chondrosarcoma, and low-grade soft tissue sarcoma.CONCLUSIONS:We report our multidisciplinary experience with primary chest wall sarcomas that included induction therapy in the majority of high-risk soft tissue and bony sarcomas and desmoid tumors. Despite aggressive preoperative treatments, acceptable surgical results with low morbidity and mortality can be achieved. Neoadjuvant systemic therapy may reduce local and distant recurrence and improve overall survival. Authors: of a Cell Phone-Based Physical Activity Diary PURPOSE: Physical activity (PA) diaries reduce the recall error inherent in self-reported PA but are burdensome. The purpose of this study was to compare a cell phone-based diary with a paper diary and examine the reliability and validity of the cell phone diary. METHODS: In a pilot study, 25 women and 23 men, age 45-65 yr, completed cell phone and paper PA diaries 4 d.wk(-1) for three consecutive weeks and a user satisfaction survey. In the subsequent validation study, 623 middle-age participants (52.5% women) were asked to complete the cell phone diary and wear an accelerometer for two 7-d periods, approximately 6 months apart. They also completed two PA questionnaires. Fitness, body mass index, and percent body fat were obtained as indirect validation criteria. RESULTS: Estimates of PA from the cell phone and paper diaries were similar (mean within person difference = -43.8 MET.min.d(-1) of total PA, SD = 360, P = 0.49, 7.4 min.d(-1) of moderate-vigorous PA, SD = 66, P = 0.53). Users preferred the cell phone diary over the paper diary (59.6% vs 35.4%). In the subsequent study, intraclass correlations for the cell phone diary ranged from 0.55 for light PA to 0.63 for vigorous PA. Although PA estimates from the cell phone diary were generally significantly higher than those from the accelerometer and the questionnaires, correlations for moderate and vigorous PA were moderate (rho = 0.25-0.59 with the questionnaires and 0.27-0.35 with the accelerometer). The correlations between the cell phone diary and the indirect validation criteria were generally in the expected direction and of moderate magnitude. CONCLUSIONS: A cell phone-based PA diary is equivalent to a paper diary, acceptable to users, and a relatively reliable and valid approach to self-reported Clinician awareness and knowledge of breast cancer-related lymphedema in a large, integrated health care delivery setting Breast cancer survivors have reported dissatisfaction regarding their education on risk of breast cancer-related lymphedema (BCRL) from clinicians. We describe clinician knowledge and treatment referral of patients with BCRL among active oncologists, surgeons, and primary care physicians in the Kaiser Permanente Northern California Medical Care Program. A total of 887 oncologists, surgeons, and primary care clinicians completed a 10-minute web survey from May 2, 2010 to December 31, 2010 on BCRL knowledge, education, and referral patterns. A knowledge score of BCRL was calculated based on clinician responses. Multivariable regression models were used to determine the associations of selected covariates with BCRL knowledge score and clinician referral, respectively. Compared with primary care clinicians, oncologists had the highest mean score followed closely by surgeons (P < 0.0001). In multivariable analyses, being female, an oncologist or surgeon, and recently receiving BCRL materials were each significantly associated with higher BCRL knowledge scores. About 44% of clinicians (n = 381) indicated they had ever made a BCRL referral (100% oncologists, 79% surgeons, and 36% primary care clinicians). Clinicians with a higher knowledge score were more likely to make referrals. In stratified analyses by specialty, the significant associated factors remained for primary care but became non-significant for oncology and surgery. These results can inform educational interventions to strengthen clinician knowledge of the clinical management of BCRL, especially among primary care clinicians. With the growing number of breast cancer survivors, increasing clinician education about BCRL across all specialties is Res Treat. 2012 Feb;131(3):1029-38. Epub 2011 Oct 29. Lactation Intensity and Postpartum Maternal Glucose Tolerance and Insulin Resistance in Women With Recent GDM: The SWIFT cohort OBJECTIVE: To examine the association between breastfeeding intensity in relation to maternal blood glucose and insulin and glucose intolerance based on the postpartum 2-h 75-g oral glucose tolerance test (OGTT) results at 6-9 weeks after a pregnancy with gestational diabetes mellitus (GDM). RESEARCH DESIGN AND METHODS: We selected 522 participants enrolled into the Study of Women, Infant Feeding, and Type 2 Diabetes (SWIFT), a prospective observational cohort study of Kaiser Permanente Northern California members diagnosed with GDM using the 3-h 100-g OGTT by the Carpenter and Coustan criteria. Women were classified as normal, prediabetes, or diabetes according to American Diabetes Association criteria based on the postpartum 2-h 75-g OGTT results. RESULTS: Compared with exclusive or mostly formula feeding (>17 oz formula per 24 h), exclusive breastfeeding and mostly breastfeeding (=6 oz formula per 24 h) groups, respectively, had lower adjusted mean (95% CI) group differences in fasting plasma glucose (mg/dL) of -4.3 (-7.4 to -1.3) and -1.7) and -36.5 (-59.3 to -13.7) (all P < 0.05). Exclusive or mostly breastfeeding groups had lower prevalence of diabetes or prediabetes (P = 0.02). CONCLUSIONS: Higher intensity of lactation was associated with improved fasting glucose and lower insulin levels at 6-9 weeks' postpartum. Lactation may have favorable effects on glucose metabolism and insulin sensitivity that may reduce diabetes risk after GDM Jan;35(1):50-6. Epub 2011 Oct 19. Dermatologic care in the homeless and underserved populations: observations from the Venice Family Clinic Dermatologic care in the homeless and impoverished urban underserved populations is rarely described despite the wide prevalence of skin concerns in this population. Because the homeless population may be subject to increased sun exposure compared to the nonhomeless population, they also may be at increased risk for skin cancer. We sought to describe the spectrum of dermatologic diseases seen in a free clinic in Venice, California-the Venice Family Clinic (VFC)-as well as the differences in diagnoses between the homeless and nonhomeless patients seen at this clinic. A retrospective chart review was performed of dermatology patients (N = 82) seen at VFC throughout the 2006 calendar year. The homeless population (n = 22) was found to have more diagnoses of malignant/premalignant growths (25% [16/64] of all homeless diagnoses) compared to their nonhomeless (n = 60) counterparts (6.1% [8/132] of all nonhomeless diagnoses; P < .0001). This difference was sustained when ethnicity was controlled, with 29.6% [16/54] of diagnoses in the homeless white group consisting of malignant/ premalignant growths compared to 8.9% [4/45] of diagnoses in the nonhomeless white cohort (P < .005). Homeless patients may have a higher incidence of skin cancers and precancerous skin lesions due to increased sun exposure and/or limited access to dermatologic care. Authors: Grossberg AL; Carranza Craft N Cutis. 2012 Jan;89(1):25-32. Challenges in the design and analysis of sequentially monitored postmarket safety surveillance evaluations using electronic observational health care data PURPOSE: Many challenges arise when conducting a sequentially monitored medical product safety surveillance evaluation using observational electronic data captured during routine care. We review existing sequential approaches for potential use in this setting, including a continuous sequential testing method that has been utilized within the Vaccine Safety Datalink (VSD) and group sequential methods, which are used widely in randomized clinical trials. METHODS: Using both simulated data and preliminary data from an ongoing VSD evaluation, we discuss key sequential design considerations, including sample size and duration of surveillance, shape of the signaling threshold, and frequency of interim testing. RESULTS AND CONCLUSIONS: All designs control the overall Type 1 error rate across all tests performed, but each yields different tradeoffs between the probability and timing of true and false positive signals. Designs tailored to monitor efficacy outcomes in clinical trials have been well studied, but less consideration has been given to optimizing design choices for observational safety settings, where the hypotheses, population, prevalence and severity of the outcomes, implications of signaling, and costs of false positive and negative findings are very different. Analytic challenges include confounding, missing and partially accrued data, high misclassification rates for outcomes presumptively defined using diagnostic codes, and unpredictable changes in dynamically accessed data over time (e.g., differential product uptake). Many of these factors influence the variability of the adverse events under evaluation and, in turn, the probability of committing a Type 1 error. Thus, to ensure proper Type 1 error control, planned sequential thresholds should be adjusted over time to account for these issues. Copyright (c) 2012 John Wiley & Sons, Ltd. Authors: Nelson JC; Cook AJ; Saf. 2012 Jan;21 Suppl 1:62-71. Design considerations in an active medical product safety monitoring system Active medical product monitoring systems, such as the Sentinel System, will utilize electronic healthcare data captured during routine health care. Safety signals that arise from these data may be spurious because of chance or bias, particularly confounding bias, given the observational nature of the data. Applying appropriate monitoring designs can filter out many false-positive and false-negative associations from the outset. Designs can be classified by whether they produce estimates based on between-person or within-person comparisons. In deciding which approach is more suitable for a given monitoring scenario, stakeholders must consider the characteristics of the monitored product, characteristics of the health outcome of interest (HOI), and characteristics of the potential link between these. Specifically, three factors drive design decisions: (i) strength of within-person and between-person confounding; (ii) whether circumstances exist that may predispose to misclassification of exposure or misclassification of the timing of the HOI; and (iii) whether the exposure of interest is predominantly transient or sustained. Additional design considerations include whether to focus on new users, the availability of appropriate active comparators, the presence of an exposure time trend, and the measure of association of interest. When the key assumptions of self-controlled designs are fulfilled (i.e., lack of within-person, time-varying confounding; abrupt HOI onset; and transient exposure), within-person comparisons are preferred because they inherently avoid confounding by fixed factors. The cohort approach generally is preferred in other situations and particularly when timing of exposure or outcome is uncertain because cohort approaches are less vulnerable to biases resulting from misclassification. Copyright (c) 2012 John Wiley & Sons, Suppl 1:32-40. When should case-only designs be used for safety monitoring of medical products? PURPOSE: To assess case-only designs for surveillance with administrative databases. METHODS: We reviewed literature on two designs that are observational analogs to crossover experiments: the self-controlled case series (SCCS) case-crossover (CCO) design. RESULTS: SCCS views the 'experiment' prospectively, comparing outcome risks in windows with different exposures. CCO retrospectively compares exposure frequencies in case and control windows. The main strength of case-only designs is they entail self-controlled analyses that eliminate confounding and selection bias by time-invariant characteristics not recorded in healthcare databases. They also protect privacy and are computationally efficient, as they require fewer subjects and variables. They are better than cohort designs for investigating transient effects of accurately recorded preventive agents, for example, vaccines. They are problematic if timing of self-administration is sporadic and dissociated from dispensing times, for example, analgesics. They tend to have less exposure misclassification bias and time-varying confounding if exposures are brief. Standard SCCS designs are bidirectional (using time both before and after the first exposure event), so they are more susceptible than CCOs to reverse-causality bias, including immortal-time bias. This is true also for sequence symmetry analysis, a simplified SCCS. Unidirectional CCOs use only time before the outcome, so they are less affected by reverse causality but susceptible to exposure-trend bias. Modifications of SCCS and CCO partially deal with these biases. The head-to-head comparison of multiple products helps to control residual biases. CONCLUSION: The case-only analyses of intermittent users complement the cohort analyses of prolonged users because their different biases compensate for one another. Copyright (c) 2012 John Wiley & Sons, Ltd. Authors: 1:50-61. A case-control study of asphalt and tar exposure and lung cancer in minorities OBJECTIVES: Considerable controversy surrounds the carcinogenic potential of asphalt and tar. Since minority individuals may have had relatively high historical exposures, we investigated asphalt and tar exposure and lung cancer risk among African Americans and Latino Americans. METHODS: We conducted a case-control study of lung cancer among African Americans and Latino Americans in the San Francisco Bay area (422 cases, 894 controls). A questionnaire was used to obtain detailed work histories and exposure information. Self-reported exposure to asphalt and tar as well as other factors (e.g., smoking, automobile exhaust, and asbestos) were evaluated as predictors of lung cancer risk. Potential effect modification by cytochrome P450 (CYP) 1A1 was also explored. RESULTS: Self-reported duration of exposure to asphalt and tar was associated with a statistically significant excess risk of lung cancer in the overall population (OR: 1.11, 95% CI: 1.01-1.22), evaluating risk per year of exposure. Years of exposure to automobile exhaust (OR: 1.02, 95% CI: 1.00-1.05) and asbestos (OR: 1.04, 95% CI: 1.02-1.06) were also associated with statistically significant elevations in risk. In Latino Americans, the lung cancer risks associated with polycyclic aromatic hydrocarbon-related exposures were consistently higher in the CYP1A1 wild-type subjects as compared to the variant genotype subjects, and the interaction was statistically significant for smoking and the CYP1A1 M2 polymorphism (P-value(interaction) = 0.02). CONCLUSIONS: These data are consistent with the literature suggesting that exposure to asphalt and tar may increase risk of lung cancer. However, it was not possible to separate the effects and asphalt and tar in this study. Am. J. Ind. Med. (c) 2011 Med. 2011 Nov;54(11):811-8. Epub 2011 Aug 31. Robust extraction of covariate information to improve estimation efficiency in randomized trials In randomized trials, investigators typically rely upon an unadjusted estimate of the mean outcome within each treatment arm to draw causal inferences. Statisticians have underscored the gain in efficiency that can be achieved from covariate adjustment in randomized trials with a focus on problems involving linear models. Despite recent theoretical advances, there has been a reluctance to adjust for covariates based on two primary reasons: (i) covariate-adjusted estimates based on conditional logistic regression models have been shown to be less precise and (ii) concern over the opportunity to manipulate the model selection process for covariate adjustments to obtain favorable results. In this paper, we address these two issues and summarize recent theoretical results on which is based a proposed general methodology for covariate adjustment under the framework of targeted maximum likelihood estimation in trials with two arms where the probability of treatment is 50%. The proposed methodology provides an estimate of the true causal parameter of interest representing the population-level treatment effect. It is compared with the estimates based on conditional logistic modeling, which only provide estimates of subgroup-level treatment effects rather than marginal (unconditional) treatment effects. We provide a clear criterion for determining whether a gain in efficiency can be achieved with covariate adjustment over the unadjusted method. We illustrate our strategy using a resampled clinical trial dataset from a placebo controlled phase 4 study. Results demonstrate that gains in efficiency can be achieved even with binary outcomes through covariate adjustment leading to increased statistical 30;30(19):2389-408. Epub 2011 Jul 12. A predictive model to help identify intimate partner violence based on diagnoses and phone calls BACKGROUND: Intimate partner violence (IPV) is a significant health problem but goes largely undiagnosed, undisclosed, and clinically undocumented. PURPOSE: To use historical data on diagnoses and telephone advice calls to develop a predictive model that identifies clinical profiles of women at high risk for undisclosed IPV. METHODS: A case-control study was conducted in women aged 18-44 years enrolled at Kaiser Permanente Northern California (KPNC) in 2005-2006 using symptoms reported by telephone and clinical diagnosis from electronic medical records. Analysis was conducted in 2007-2010. Overall, 1276 cases were identified using ICD-9 codes for IPV and were matched with 5 controls each. A full multivariate model was developed to identify those with IPV, as well as a reduced model and a summed-score model whose performance characteristics were assessed. RESULTS: Predictors most highly associated with IPV were history of remote IPV (OR=7.8); calls or diagnoses for psychiatric problems (OR=2.4); calls for HIV concerns (OR=2.4); and clinical diagnoses of prenatal complications (OR=2.1). Using the summed-score model for a population with IPV prevalence of 7%, and using a threshold score of 3 for predicting IPV with a sensitivity of 75%, 9.7 women would need to be assessed to diagnose one case of IPV. CONCLUSIONS: Diagnosed IPV was associated with a clinical profile based on both telephone call data and clinical diagnoses. The simple predictive model can prompt focused clinical inquiry and improve diagnosis of IPV in any clinical setting. Authors: 2011 of lapatinib plus capecitabine in women with HER2+ metastatic breast cancer who have received prior therapy with trastuzumab. BACKGROUND:In a phase III trial of women with HER2+ metastatic breast cancer (MBC) previously treated taxanes (EGF100151), lapatinib plus progression capecitabine monotherapy (C-only). In a trial including HER2+ MBC patients who had received at least one prior course of trastuzumab and no more than one prior course of palliative chemotherapy (GBG 26/BIG 03-05), continued trastuzumab economic model using patient-level data from EGF100151 and published results of GBG 26/BIG 03-05 as well as other literature were used to evaluate the incremental cost per quality-adjusted life-year [QALY] gained with L+C versus C-only and versus in women with HER2+ MBC previously treated with trastuzumab from the UK National Health Service (NHS) perspective.RESULTS:Expected costs were \u00a328,816 with 0.737 and 0.896. In the base case, L+C was estimated to provide more QALYs at a lower cost compared with T+C; cost per QALY gained was \u00a377,993 with L+C versus C-only. In pairwise probabilistic sensitivity analyses, the probability that L+C is preferred to C-only was 0.03 given a threshold of \u00a330,000. The probability that L+C is preferred to T+C was 0.54 regardless of the threshold.CONCLUSIONS:When compared against capecitabine alone, the addition of lapatinib has a cost-effectiveness ratio exceeding the threshold normally used by NICE. Compared with T+C, L+C is dominant in the base case and approximately equally likely to be cost-effective in probabilistic sensitivity analyses over a wide range 2012 Oct;13(5):589-603. doi: 10.1007/s10198-011-0323-1. Epub 2011 Jun 24. Development of disability in chronic obstructive pulmonary disease: beyond lung function BACKGROUND: COPD is a major cause of disability, but little is known about how disability develops in this condition. METHODS: The authors analysed data from the Function, Living, Outcomes and Work (FLOW) Study which enrolled 1202 Kaiser Permanente Northern California members with COPD at baseline and re-evaluated 1051 subjects at 2-year follow-up. The authors tested the specific hypothesis that the development of specific non-respiratory impairments (abnormal body composition and muscle strength) and functional limitations (decreased lower extremity function, poor balance, mobility-related dyspnoea, reduced exercise performance and decreased cognitive function) will determine the risk of disability in COPD, after controlling for respiratory impairment (FEV(1) and oxygen saturation). The Valued Life Activities Scale was used to assess disability in terms of a broad range of daily activities. The primary disability outcome measure was defined as an increase in the proportion of activities that cannot be performed of 3.3% or greater from baseline to 2-year follow-up (the estimated minimal important difference). Multivariable logistic regression was used for analysis. RESULTS: Respiratory impairment measures were related to an increased prospective risk of disability (multivariate OR 1.75; 95% CI 1.26 to 2.44 for 1 litre decrement of FEV(1) and OR 1.57 per 5% decrement in oxygen saturation; 95% CI 1.13 to 2.18). Non-respiratory impairment (body composition and lower extremity muscle strength) and functional limitations (lower extremity function, exercise performance, and mobility-related dyspnoea) were all associated with an increased longitudinal risk of disability after controlling for respiratory impairment (p<0.05 in all cases). Non-respiratory impairment and functional limitations were predictive of prospective disability, above-and-beyond sociodemographic characteristics, smoking status and respiratory impairment (area under the receiver operating characteristic curve increased from 0.65 to 0.75; p<0.001). CONCLUSIONS: Development of non-respiratory impairment and functional limitations, which reflect the systemic nature of COPD, appear to be critical determinants of disablement. Prevention and treatment of disability require a comprehensive approach to the COPD Feb;66(2):108-14. Epub 2010 Nov 3. Coffee, caffeine, and risk of hospitalization for arrhythmias Context: Population study data about relations of coffee drinking to arrhythmia are sparse.Objective: To study relations of coffee drinking to risk of cardiac arrhythmia in 130,054 persons with previous data about coffee habits.Design and Outcome Measure: We used Cox proportional hazards models with 8 covariates to study coffee-related risk in 3137 persons hospitalized for cardiac arrhythmia. We conducted a similar analysis of total caffeine-related risk in a subgroup with data about other caffeine intake (11,679 study participants; 198 hospitalized).Results: With non-coffee-drinkers as the referent, the adjusted hazard ratio (HR) for any arrhythmia at the level of <1 cup of coffee per day was 1.0 (95% confidence interval [CI] = 0.9-1.1; p = 0.7); for 1-3 cups/day, it was 0.9 (CI, 0.8-1.0; p = 0.2), and for >/=4 cups/day, it was 0.8 (CI, 0.7-0.9; p = 0.002). With coffee intake as a continuous variable, the HR per cup per day was 0.97 (CI, 0.95-0.99; p = 0.001). Results were similar for several strata, including persons with history or symptoms of possible cardiore-spiratory disease and those without such history or symptoms. Coffee had similar relations to atrial fibrillation (48% of participants with arrhythmia) and most other specific arrhythmia diagnoses. Controlled for number of cups of coffee per day, total caffeine intake was inversely related to risk (HR highest quartile vs lowest = 0.6; p = 0.03).Conclusion: The inverse relations of coffee and caffeine intake to hospitalization for arrhythmias make it unlikely that moderate caffeine intake increases arrhythmia Authors: Klatsky 2011 Summer;15(3):19-25. The MCCB impairment profile for schizophrenia outpatients: results from the MATRICS psychometric and standardization study The MATRICS Psychometric and Standardization Study was conducted as a final stage in the development of the MATRICS Consensus Cognitive Battery (MCCB). The study included 176 persons with schizophrenia or schizoaffective disorder and 300 community residents. Data were analyzed to examine the cognitive profile of clinically stable schizophrenia patients on the MCCB. Secondarily, the data were analyzed to identify which combination of cognitive domains and corresponding cut-off scores best discriminated patients from community residents, and patients competitively employed vs. those not. Raw scores on the ten MCCB tests were entered into the MCCB scoring program which provided age- and gender-corrected T-scores on seven cognitive domains. To test for between-group differences, we conducted a 2 (group)\u00d77 (cognitive domain) MANOVA with follow-up independent t-tests on the individual domains. Classification and regression trees (CART) were used for the discrimination analyses. Examination of patient T-scores across the seven cognitive domains revealed a relatively compact profile with T-scores ranging from 33.4 for speed of processing to 39.3 for reasoning and problem-solving. Speed of processing and social cognition best distinguished individuals with schizophrenia from community residents; speed of processing along with visual learning and attention/vigilance optimally distinguished patients competitively employed from those who were not. The cognitive profile findings provide a standard to which future studies can compare results from other schizophrenia samples and related disorders; the classification results point to specific areas and levels of cognitive impairment that may advance work rehabilitation efforts. Authors: Kern 2011 Mar;126(1-3):124-31. doi: 10.1016/j.schres.2010.11.008. Epub 2010 Dec 14. Fixing flaws in Medicare drug coverage that prompt insurers to avoid low-income patients Since 2006 numerous insurers have stopped serving the low-income segment of the Medicare Part D program, forcing millions of beneficiaries to change prescription drug plans. Using data from participating plans, we found that Medicare payments do not sufficiently reimburse insurers for the relatively high medication use among this population, creating perverse incentives for plans to avoid this part of the Part D market. Plans can accomplish this by increasing their premiums for all beneficiaries to an amount above regional benchmarks. We demonstrate that improving the accuracy of Medicare's risk and subsidy adjustments could mitigate these perverse incentives. Authors: Hsu J; Fung V; Huang J; (Millwood). 2010 Dec;29(12):2335-43. Epub 2010 Oct 28. Mammographic density and risk of second breast cancer after ductal carcinoma in situ BACKGROUND: We examined whether mammographic density predicts risk of second breast cancers among patients with ductal carcinoma in situ (DCIS). METHODS: The study included DCIS patients diagnosed during 1990 to 1997 and treated with breast-conserving surgery at Kaiser Permanente Northern California. Medical records were reviewed for clinical factors and subsequent breast cancers (DCIS and invasive). Ipsilateral mammograms from the index DCIS were assessed for density without knowledge of subsequent cancer status. Cox regression modeling was used to examine the association between mammographic density and risk of breast cancer events. RESULTS: Of the 935 eligible DCIS patients, 164 (18%) had a subsequent ipsilateral breast cancer, and 59 (6%) had a new primary cancer in the contralateral breast during follow-up (median, 103 mo). Those with the greatest total area of density (upper 20% of values) were at increased risk for invasive disease in either breast [hazard ratio (HR), 2.1; 95% confidence interval (95% CI), 1.2-3.8] or any cancer (DCIS or invasive) in the ipsilateral 1.7; or contralateral (HR, 3.0; 95% CI, 1.3-6.9) breast compared with those with the smallest area of density (bottom 20%). HRs for these same end points comparing those in the highest with those in the lowest American College of Radiology Breast Imaging Reporting and Data System category were 1.6 (95% CI, 0.7-3.6), 1.3 (95% CI, 0.7-2.6), and 5.0 (95% CI, 1.4-17.9), respectively. There was a suggestion of increasing risk of contralateral, but not ipsilateral, cancer with increasing percent density. CONCLUSIONS: Women with mammographically dense breasts may be at higher risk of subsequent breast cancer, especially in the contralateral breast. IMPACT: Information about mammographic density may help mapping of chromosome 15q25.1 lung cancer susceptibility in African-Americans Several genome-wide association studies identified the chr15q25.1 region, which includes three nicotinic cholinergic receptor genes (CHRNA5-B4) and the cell proliferation gene (PSMA4), for its association with lung cancer risk in Caucasians. A haplotype and its tagging single nucleotide polymorphisms (SNPs) encompassing six genes from IREB2 to CHRNB4 were most strongly associated with lung cancer risk (OR = 1.3; P < 10(-20)). In order to narrow the region of association and identify potential causal variations, we performed a fine-mapping study using 77 SNPs in a 194 kb segment of the 15q25.1 region in a sample of 448 African-American lung cancer cases and 611 controls. Four regions, two SNPs and two distinct haplotypes from sliding window analyses, were associated with lung cancer. CHRNA5 rs17486278 G had OR = 1.28, 95% CI 1.07-1.54 and P = 0.008, whereas G had OR = 0.78, 95% CI 0.66-0.94 and P = 0.008 for lung cancer risk. Lung cancer associations remained significant after pack-year adjustment. Rs7178270 decreased lung cancer risk in women but not in men; gender interaction P = 0.009. For two SNPs (rs7168796 A/G and rs7164594 A/G) upstream PSMA4, lung cancer risks for people with haplotypes GG and AA were reduced compared with those with AG (OR = 0.56, 95% CI 0.38-0.82; P = 0.003 and OR = 0.73, CI rs16969968 G) and CHRNA3 (rs578776 G) was associated with increased lung cancer risk (P = 0.002). The identified regions contain SNPs predicted to affect gene regulation. There are multiple lung cancer risk loci in the 15q25.1 2010 Jun 29. Cost-effectiveness of zoledronic acid plus endocrine therapy in premenopausal women with hormone-responsive early breast cancer. PURPOSE:The aim of this study was to estimate the cost-effectiveness of adding zoledronic acid 4 mg intravenously every 6 months to endocrine therapy in premenopausal women with hormone receptor-positive early breast cancer from a US health care system perspective.MATERIALS AND METHODS:A Markov model was developed to predict disease progression, mortality, and costs of breast cancer care for premenopausal women with hormone receptor-positive early breast cancer receiving up to 3 years of (1) endocrine therapy (goserelin plus tamoxifen or anastrozole); or (2) endocrine therapy plus zoledronic acid. Model parameters were obtained from ABCSG-12 (Austrian Breast and Colorectal Cancer Study Group Trial-12) and the literature. The incremental cost per quality-adjusted life year (QALY) gained with zoledronic acid was calculated under 2 scenarios: (1) benefits of zoledronic acid persist to maximum (7 years) follow-up in ABCSG-12 (\"trial benefits\") or (2) benefits persist until death (\"lifetime benefits\").RESULTS:Adding zoledronic acid to endocrine therapy was projected to yield a gain of 0.41 life years (LYs) and 0.43 QALYs assuming trial benefits and 1.34 LYs and 1.41 QALYs assuming lifetime benefits. Assuming trial benefits, the incremental cost per QALY gained with zoledronic acid was $9300. Assuming lifetime benefits, zoledronic acid was estimated to increase QALYs and reduce costs. Cost per 1;10(4):267-74. doi: 10.3816/CBC.2010.n.034. Availability and accuracy of medical record information on language usage of cancer patients from a multi-ethnic population Documentation of language usage in medical settings could be effective in identifying and addressing language barriers and would improve understanding of health disparities. This study evaluated the availability and accuracy of medical records information on language for 1,664 cancer patients likely to have poor English proficiency. Accuracy was assessed by comparison to language obtained from interview-based research studies. For patients diagnosed at facilities where information on language was not abstracted electronically, 81.6% had language information in their medical records, most often in admissions documents. For all 37 hospitals, agreement between medical records and interview language was 79.3% overall and was greater for those speaking English than another language. Language information is widely available in hospital medical records of cancer patients. However, for the data to be useful for research and reducing language barriers in medical care, the information must be collected in a consistent and accurate manner. Authors: Minor Health. 2010 Aug;12(4):480-8. Proton pump inhibitors and histamine-2 receptor antagonists are associated with hip fractures among at-risk patients BACKGROUND & AIMS: Drugs that inhibit gastric acid might increase the risk of hip fracture. However, little long-term exposure data exist and no large studies have been conducted in the United States. METHODS: We conducted a case-control study using data from an integrated health services organization. We evaluated 33,752 patients with incident diagnoses of hip/femur fractures (cases), 130,471 matched members without fractures (controls), prescription data for use of proton pump inhibitors (PPIs) or histamine-2 receptor antagonists (H2RAs) (up to 10 years' cumulative duration), and confounders. RESULTS: Patients with hip fractures were more likely than controls to have previously received a > or =2-year supply of PPIs (odds ratio [OR], 95% CI, 1.08-1.29). The risk was reduced after discontinuation of medication (OR of 1.30 [95% CI, 1.21-1.41] for current PPI users vs OR of 1.09 [95% CI, 0.64-1.85] for patients who received their last prescription 2-2.9 years ago). Higher dosages (but not increasing cumulative durations) were associated with increased risk (eg, > or =1.5 pills/day: OR, 1.41 pills/day: OR, 1.12 [95% CI, 0.94-1.33]). Excess fracture risk for PPI use was only present among persons with at least one other fracture risk factor. CONCLUSIONS: Use of drugs that inhibit gastric acid is associated with an increased risk of hip fracture; however, this association was only found among persons with at least one other risk factor for hip fracture. Acid inhibition might therefore be associated with fracture risk in persons already at risk for osteoporosis, although other confounding cannot be excluded. Epub 2010 Mar 27. Ambient ozone concentrations and cardiac mortality in Southern California 1983-2000: application of a new marginal structural model approach The authors evaluated the association between ambient ozone levels and cardiac mortality in California's South Coast Air Basin during the period 1983-2000 and compared inferences from several types of marginal structural model (MSM) estimators. The authors undertook an ecologic study during the high-ozone seasons among persons over age 55 years. In contrast to conditional regression analysis and MSMs based on G-computation and simple inverse probability-of-treatment weighting (IPTW), an MSM that protected against violation of the experimental treatment assignment (ETA) assumption and considered only those areas that could have experienced both high and low ozone concentrations during 1983-2000 found no consistent evidence that reductions in quarterly 1-hour maximum ozone concentrations from levels above any of the regulatory standards to levels below those standards led to decreases in cardiac mortality; however, it did find evidence of decreases related to a decrease in 8-hour maximum concentrations. The G-computation estimator and simple IPTW estimators were biased because of serious violation of the ETA assumption. These analyses highlight the importance of nonviolation of the ETA assumption for valid inference and the failure of conditional regression to provide marginal estimates in the presence of interactions. Noncausal models also consistently inferred larger associations, which may have been due to bias violation of the ETA assumption on which these models rely. Authors: Epub 2010 May 3. Association of prediagnostic serum vitamin D levels with the development of basal cell carcinoma We investigated the association between serum 25-hydroxyvitamin D (25(OH)D) levels and basal cell carcinoma (BCC) risk in a nested case-control study at Kaiser Permanente Northern California (KPNC). A total of 220 case patients with BCC diagnosed after serum collection were matched to 220 control subjects. We estimated odds ratios (ORs) and 95% confidence intervals (CIs) using conditional logistic regression. Fully adjusted models included body mass index (BMI), smoking, education, sun-exposure variables, X-ray exposure, and personal history of cancer. For each measure of serum 25(OH)D (continuous, clinically relevant tertiles, quintiles), we found an increased risk of BCC in (OR=1.03, 95% CI 1.00-1.05, P<0.05; OR=3.98, 95% CI: 1.20-4.50, 1st vs. 5th quintile, test for trend P-value 0.03). In fully adjusted models, the values prediagnostic serum 25(OH)D levels may be associated with increased risk of subsequent BCC. Further studies to evaluate the effect of sun exposure on BCC and serum 25(OH)D levels may May;130(5):1438-43. Epub 2009 Dec 31. Clinical features in early Parkinson disease and survival OBJECTIVE: To examine the association between demographic and clinical features in early Parkinson disease (PD) and length of survival in a multiethnic population. DESIGN: Clinical features within 2 years of diagnosis were determined for an inception cohort established during 1994-1995. Vital status was determined through December 31, 2005. Predictor variables included age at diagnosis, sex, race/ethnicity, as well as clinical subtype (modified tremor dominant, postural instability gait difficulty), symmetry, cognitive impairment, depression, dysphagia, and hallucinations. Cox proportional hazards regression analysis was used to identify factors associated with shorter survival. SETTING: Kaiser Permanente Medical Care Program, northern California. PATIENTS: Five hundred seventy-three men and women with newly diagnosed PD. RESULTS: Three hundred fifty-two participants in the PD cohort (61.4%) had died in the follow-up period. Older age at diagnosis (hazard ratio [HR], 1.1; 95% confidence interval [CI], subtype (HR, 1.8; CI, 1.3-2.7), symmetry of motor CI, 1.1-3.7), mild (HR, 1.7; impairment, and hallucinations (HR, 2.1; 95% CI, 1.3-3.2) were associated with increased all-cause mortality, after adjusting for age, sex, and race/ethnicity. None of the other factors altered mortality risk. In an empirical predictive analysis, most previous significant predictors remained associated with shorter survival. CONCLUSIONS: Both motor and nonmotor features in early PD predict increased mortality risk, particularly postural instability gait difficulty, cognitive impairment, and hallucinations. These predictors may be useful in clinical practice and when designing clinical trials. Authors: Eeden SK Arch Nov;66(11):1353-8. Alcohol consumption and risk of hematologic malignancies PURPOSE: Limited data suggest that alcohol drinking may have an inverse relation to risk of non-Hodgkin's lymphoma (NHL). Prospective data about alcohol, NHL, and other hematologic malignancies (HM) are sparse. METHODS: We carried out a cohort study in a multiethnic population of 126,293 adults who supplied baseline information at health examinations. There were subsequent HM diagnoses in 1244 persons. We used Cox proportional hazards models with seven covariates. The role of beverage types was studied by comparing groups with preponderant choices and by studying the role of frequency of drinking beverage types. RESULTS: Using lifelong abstainers plus infrequent drinkers as referent, adjusted relative risks (95% confidence intervals) for HM follow: less than one drink per day=1.0 (0.9-1.2), one to two drinks per day=0.9 (0.7-1.0), greater than three drinks per day=0.7 (0.6-0.9, p=0.008). For 673 NHL these were 1.2 (1.0-1.5), 0.9 (0.7-1.2), and 0.9 (0.6-1.2). Persons reporting greater than three drinks/day had inverse relations to lymphocytic (n= 146) and myelocytic (n= 169) leukemias, with relative risk of 0.5 (0.2-1.0, p<0.05) for each. No major independent relation was seen for choice of wine, liquor, or beer. CONCLUSIONS: Alcohol drinking is associated with slightly lower risk of HM, due largely to inverse relations to lymphocytic and myelocytic leukemia. Apr 25. Cost-effectiveness of aliskiren in type 2 diabetes, hypertension, and albuminuria. The Aliskiren in the Evaluation of Proteinuria in Diabetes (AVOID) trial demonstrated that adding aliskiren, an oral direct renin inhibitor, at a dosage of 300 mg/d to the highest approved dosage of losartan and optimal antihypertensive therapy reduces albuminuria over 6 mo among patients with type 2 diabetes, hypertension, and albuminuria. The cost-effectiveness of this therapy, however, is unknown. Here, we used a Markov model to project progression to ESRD, life years, quality-adjusted life years, and lifetime costs for aliskiren plus losartan versus losartan. We used data from the AVOID study and the Irbesartan in Diabetic Nephropathy Trial (IDNT) to estimate probabilities of progression of renal disease. We estimated probabilities of mortality for ESRD and other comorbidities using data from the US Renal Data System, US Vital Statistics, and published studies. We based pharmacy costs on wholesale acquisition costs and based costs of ESRD and transplantation on data from the US Renal Data System. We found that adding aliskiren to losartan increased time free of ESRD, life expectancy, and quality-adjusted life expectancy by 0.1772, 0.1021, and 0.0967 yr, respectively. Total expected lifetime health care costs increased by $2952, reflecting the higher pharmacy costs of aliskiren and losartan ($7769), which were partially offset by savings in costs of ESRD ($4860). We estimated the cost-effectiveness of aliskiren to be $30,500 per quality-adjusted life year gained. In conclusion, adding aliskiren to losartan and optimal therapy in patients with type 2 diabetes, hypertension, and albuminuria may be cost-effective from a US health care system Epub 2009 Sep endometrial risk of unrecognized adenocarcinoma and value dilation and whether preoperative dilation and curettage (D&C) lowers the risk of unexpected at hysterectomy. METHODS: Women with complex atypical endometrial hyperplasia on sampling from January 2000 to May 2008 who underwent hysterectomy within 6 months were identified using a pathology database. Patient age, sampling procedures, and hysterectomy pathology were recorded. Women were categorized as having either an office biopsy-based evaluation or a curettage-based evaluation. The proportion of women with cancer at surgery was estimated and compared for the two groups. RESULTS: Of 824 women with complex atypical endometrial hyperplasia on initial sampling, 48% were found to have cancer. For 100 women, cancer was diagnosed preoperatively by additional sampling before hysterectomy. For the remaining 724, 298 (41%) had unexpected cancer at hysterectomy. The diagnosis of complex endometrial hyperplasia 531 (73%) and curettage-based for 193 (27%). The risk of cancer for women who had a D&C was significantly lower than for those who had biopsy, but still of concern (30% compared with 45%, P<.001), as was the risk of myometrial invasion (18% compared with 25%, P=.05). Age was strongly correlated to risk of cancer, invasive cancer, and deeply invasive or grade 3 disease. CONCLUSION: Dilation and curettage lowered the risk of unexpected cancer compared with biopsy, but 18% of women still had invasive cancer found at hysterectomy. The risk of unexpected cancer is strongly related to age. Dilation and curettage can help detect cancer preoperatively but is not reliable for excluding cancer. LEVEL OF EVIDENCE: II. Authors: Suh-Burgmann E; Hung YY; Armstrong MA Obstet Gynecol. 2009 Sep;114(3):523-9. Cost of routine immunization of young children against rotavirus infection with Rotarix versus RotaTeq. Using a probabilistic model of the clinical and economic burden of rotavirus gastroenteritis (RVGE), we estimated the expected impact of vaccinating a US birth cohort with Rotarix in lieu of RotaTeq. Assuming full vaccination of all children, use of Rotarix - rather than RotaTeq - was estimated to reduce the total number of RVGE events by 5% and associated costs by 8%. On an overall basis, Rotarix would reduce costs by $77.2 million (95% CI $71.5-$86.5). Similar reductions with Rotarix were estimated to occur under an assumption of incomplete immunization of 2009 Jun 23. Cost-effectiveness of pregabalin versus venlafaxine in the treatment of generalized anxiety disorder: findings from a Spanish perspective. The objective of the present study was to describe a new model of the cost-effectiveness of treatment of generalized anxiety disorder (GAD) and its application to a comparison of pregabalin versus venlafaxine extended-release (XR) from a Spanish healthcare perspective. Microsimulation techniques, including Hamilton Anxiety Scale (HAM-A) score, number of weeks with minimal Feb;11(1):35-44. doi: 10.1007/s10198-009-0160-7. Epub 2009 Jun 9. Improving diet and physical activity with ALIVE: a worksite randomized trial CONTEXT: Healthy diets and regular physical activity confer many health benefits, but the prevalence of these behaviors is relatively low. BACKGROUND: Cost-effective strategies are needed to increase healthy eating and physical activity in the population. DESIGN: An RCT, conducted in 2006, of a 16-week e-mail program offered individually tailored, small-step goals; a personal homepage with tips; educational materials; and tracking and simulation tools. SETTING/POPULATION: Seven hundred eighty-seven employees in the administrative offices of a large healthcare organization volunteered to participate. MAIN OUTCOME MEASURES: Changes were self-reported for total physical activity; moderate physical activity (MPA); vigorous physical activity (VPA); walking; sedentary behavior; and intake of fruits and vegetables, saturated and trans fats, and added sugars in the intervention group compared to the control group. RESULTS: In intent-to-treat analyses (conducted in 2007 and 2008) that set change in nonresponders to the follow-up questionnaire to zero, the intervention group reported increases of 28.0 minutes/week (min/wk) of walking (SE=5.5, p=0.0003) relative to the control group. Intake of both saturated and trans fats (grams/day [g/day]) declined (beta=-0.95, SE=0.36, p=0.01; beta=-0.29, SE=0.12, p=0.02, consumption of fruits and vegetables increased significantly (p=0.03), and the consumption of added sugars decreased marginally (p=0.08). The largest changes were in participants who did not meet behavioral recommendations at baseline (increase of 55.4 min/wk of MPA and decrease of 1.15 g/day of trans fats, relative to the control group). Differences between the intervention and control groups were still observed 4 months after the intervention ended. CONCLUSIONS: ALIVE is an effective program for achieving significant improvement in diet and physical activity. TRIAL G Am J Prev Med. 2009 Jun;36(6):475-83. Hypoglycemic episodes and risk of dementia in older patients with type 2 diabetes mellitus CONTEXT: Although acute hypoglycemia may be associated with cognitive impairment in children with type 1 diabetes, no studies to date have evaluated whether hypoglycemia is a risk factor for dementia in older patients with type 2 diabetes. OBJECTIVE: To determine if hypoglycemic episodes severe enough to require hospitalization are associated with an increased risk of dementia in a population of older patients with type 2 diabetes followed up for 27 years. DESIGN, SETTING, AND PATIENTS: A longitudinal cohort study from 1980-2007 of 16,667 patients with a mean age of 65 years and type 2 diabetes who are members of an integrated health care delivery system in northern California. MAIN OUTCOME MEASURE: Hypoglycemic events from 1980-2002 were collected and reviewed using hospital discharge and emergency department diagnoses. Cohort members with no prior diagnoses of dementia, mild cognitive impairment, or general memory complaints as of January 1, 2003, were followed up for a dementia diagnosis through January 15, 2007. Dementia risk was examined using Cox proportional hazard regression models, adjusted for age, sex, race/ethnicity, education, body mass index, duration of diabetes, 7-year mean glycated hemoglobin, diabetes treatment, duration of insulin use, hyperlipidemia, hypertension, cardiovascular disease, stroke, transient cerebral ischemia, and end-stage renal disease. RESULTS: At least 1 episode of hypoglycemia was diagnosed in 1465 patients (8.8%) and dementia was diagnosed in 1822 patients (11%) during follow-up; 250 patients had both dementia and at least 1 episode of hypoglycemia (16.95%). Compared with patients with no hypoglycemia, patients with single or multiple episodes had a graded increase in risk with fully adjusted hazard ratios (HRs): for 1 episode (HR, 1.26; 95% confidence interval [CI], 1.10-1.49); 2 episodes (HR, 1.80; 95% CI, 1.37-2.36); and 3 or more episodes (HR, 1.94; 95% CI, 1.42-2.64). The attributable risk of dementia between individuals with and without a history of hypoglycemia was 2.39% per year (95% CI, 1.72%-3.01%). Results were not attenuated when medical utilization rates, length of health plan membership, or time since initial diabetes diagnosis were added to the model. When examining emergency department admissions for hypoglycemia for association with risk of dementia (535 episodes), results were similar (compared with patients with 0 episodes) with fully adjusted HRs: for 1 episode (HR, 1.42; 95% CI, 1.12-1.78) and for 2 or more episodes (HR, 2.36; 95% CI, 1.57-3.55). CONCLUSIONS: Among older patients with type 2 diabetes, a history of severe hypoglycemic episodes was associated with a greater risk of dementia. Whether minor hypoglycemic episodes increase risk of dementia is the risk of Barrett's esophagus INTRODUCTION: We examined the association between smoking and the risk of Barrett's esophagus (BE), a metaplastic precursor to esophageal adenocarcinoma. METHODS: We conducted a case-control study within the Kaiser Permanente Northern California population. Patients with a new diagnosis of BE (n = 320) were matched to persons with gastroesophageal reflux disease (GERD) (n = 316) and to population controls (n = 317). Information was collected using validated questionnaires from direct in-person interviews and electronic databases. Analyses used multivariate unconditional logistic regression that controlled for age, gender, race, and education. RESULTS: Ever smoking status, smoking intensity (pack-years), and smoking cessation were not associated with the risk of BE. Stratified analyses suggested that ever smoking may be associated with an increased risk of BE among some groups (compared to population controls): persons with long-segment Barrett's esophagus (odds ratio [OR] = 1.72, 95% confidence interval [CI] 1.12-2.63); subjects without GERD symptoms (OR = 3.98, 95% CI 1.58-10.0); obese subjects (OR = 3.38, 95% CI 1.46-7.82); and persons with a large abdominal circumference (OR = 3.02, 95% CI (1.18-2.75)). CONCLUSION: Smoking was not a strong or consistent risk factor for BE in a large community-based study, although associations may be present in some population subgroups. Authors: Epub 2008 Oct 14. CYP1A1/2 haplotypes and lung cancer and assessment of confounding by population stratification Prior studies of lung cancer and CYP1A1/2 in African-American and Latino populations have shown inconsistent results and have not yet investigated the haplotype block structure of CYP1A1/2 or addressed potential population stratification. To investigate haplotypes in the CYP1A1/2 region and lung cancer in African-Americans and Latinos, we conducted a case-control study (1998-2003). African-Americans (n = 535) and Latinos (n = 412) were frequency matched on age, sex, and self-reported race/ethnicity. We used a custom genotyping panel containing 50 single nucleotide polymorphisms in the CYP1A1/2 region and 184 ancestry informative markers selected to have large allele frequency differences between Africans, Europeans, and Amerindians. Latinos exhibited significant haplotype main effects in two blocks even after adjusting for admixture [odds ratio (OR), 2.02; 95% confidence and OR, 0.55; 95% CI, 0.36-0.83], but no main effects were found among African-Americans. Adjustment for admixture revealed substantial confounding by population stratification among Latinos but not African-Americans. Among Latinos and African-Americans, interactions between smoking level and haplotypes were not statistically significant. Evidence of population stratification among Latinos underscores the importance of adjusting for admixture in lung cancer association studies, particularly in Latino populations. These results suggest that a variant occurring within the CYP1A2 region may be conferring an increased risk of lung cancer in Latinos. Epub 2009 Mar 10. Distributing $800 billion: an early assessment of Medicare Part D risk adjustment The viability and stability of the Medicare Part D prescription drug program depend on accurate risk-adjusted payments. The current approach, prescription drug hierarchical condition categories (RxHCCs), uses diagnosis and demographic information to predict future drug costs. We evaluated the performance of multiple approaches for predicting 2006 Part D drug costs and plan liability. RxHCCs explain 12 percent of the variation in actual drug costs, overpredict costs for beneficiaries with low actual costs, and underpredict costs for beneficiaries with high actual costs. Combining RxHCCs with individual-level information on prior-year drug use greatly improves performance and decreases incentives for plans to select against bad risks. Authors: Hsu J; Huang J; Fung V; Newhouse JP Health Aff (Millwood). 2009 Jan-Feb;28(1):215-25. Using drink size to talk about drinking during pregnancy: a randomized clinical trial of Early Start Plus This clinical trial compared two brief alcohol use interventions in prenatal clinics: Early Start (ES), a substance-abuse screening and treatment program integrated with prenatal care focused on abstention (n=298), and Early Start Plus (ESP), adding a computerized drink-size assessment tool and intervention focused on drinking less (n=266). Controls were untreated alcohol users (n=344). Controls had higher adverse neonatal and maternal outcome rates. Findings favored ESP for preterm labor and ES for low birth weight. No differences between ES and ESP were statistically significant. ESP provides clinicians with an innovative assessment tool that creates open dialogue about drinking during pregnancy. Authors: Work Health Care. 2009 Jan;48(1):90-103. Base excision repair genes and risk of lung cancer among San Francisco Bay Area Latinos and African-Americans Base excision repair (BER) is the primary DNA damage repair mechanism for repairing small base lesions resulting from oxidation and alkylation damage. This study examines the association between 24 single-nucleotide polymorphisms (SNPs) belonging to five BER genes (XRCC1, APEX1, PARP1, MUTYH and OGG1) and lung cancer among Latinos (113 cases and 299 controls) and African-Americans (255 cases and 280 controls). The goal was to evaluate the differences in genetic contribution to lung cancer risk by ethnic groups. Analyses of individual SNPs and haplotypes were performed using unconditional logistic regressions adjusted for age, sex and genetic ancestry. Four SNPs among Latinos and one SNP among African-Americans were significantly (P < 0.05) associated with either risk of all lung cancer or non-small cell lung cancer (NSCLC). However, only the association between XRCC1 Arg399Gln (rs25487) and NSCLC among Latinos (odds ratio associated copy of Gln = 1.52; 95% confidence interval: 1.01-2.28) had probability of <0.5. Arg399Gln is a SNP with some functional evidence and has been shown previously to be an important SNP associated with lung cancer, mostly for Asians. Since the analyses were adjusted for genetic ancestry, the observed association between Arg399Gln and NSCLC among Latinos is unlikely to be confounded by population stratification; however, this result needs to be confirmed by additional studies among the Latino population. This study suggests that there are genetic differences in the association between BER pathway and lung cancer between Latinos and 2008 Nov 24. Iron intake and body iron stores as risk factors for Barrett's esophagus: a community-based study OBJECTIVE: High iron stores are a proposed modifiable risk factor for esophageal adenocarcinoma, but minimal human data exist. We evaluated whether iron intake and iron stores were associated with Barrett's esophagus, a metaplastic change that is a strong risk factor for esophageal adenocarcinoma. METHODS: We conducted a case-control study within the Kaiser Permanente Northern California population. We identified all persons with a new diagnosis of Barrett's esophagus (cases); they were matched to persons with GERD (without Barrett's esophagus) and to population controls. Subjects completed examinations, dietary questionnaires, and testing for serum iron stores (ferritin and transferrin saturation). Analyses used unconditional logistic regression. RESULTS: We evaluated 319 cases, 312 GERD patients, and 313 population controls. Compared with population controls, Barrett's esophagus patients had lower dietary iron intakes (4th vs 1st quartiles, odds ratio [OR]= 0.37, 95% confidence interval [CI] 0.17-0.80), similar total iron intakes (including supplement use), and lower iron stores (4th vs 1st quartiles, ferritin OR = 0.24, 95% 0.66, 95% CI 0.41-1.04; P value trend <0.01 and 0.03, respectively). Similar associations were observed in comparisons with GERD controls and among subjects without clear sources of blood loss on endoscopy. CONCLUSIONS: Patients with Barrett's esophagus had lower dietary iron intakes and lower serum iron stores than controls in our population. These findings do not provide support for the current hypothesis that high iron stores or a high iron intake are risk factors for Barrett's esophagus, a potential early event in the carcinogenic sequence 2008 Dec;103(12):2997-3004. Epub 2008 Oct 1. Comparison of statistical methods for estimating genetic admixture in a lung cancer study of African Americans and Latinos A variety of methods are available for estimating genetic admixture proportions in populations; however, few investigators have conducted detailed comparisons using empirical data. The authors characterized admixture proportions among self-identified African Americans (n = 535) and Latinos (n = 412) living in the San Francisco Bay Area who participated in a lung cancer case-control study (1998-2003). Individual estimates of genetic ancestry based on 184 informative markers were obtained from a Bayesian approach and 2 maximum likelihood approaches and were compared using descriptive statistics, Pearson correlation coefficients, and Bland-Altman plots. Case-control differences in individual admixture proportions were assessed using 2-sample t tests and logistic regression analysis. Results indicated that Bayesian and frequentist approaches to estimating admixture provide similar estimates and inferences. No difference was observed in admixture proportions between African-American cases and controls, but Latino cases and controls significantly differed according to Amerindian and European genetic ancestry. Differences in admixture proportions between Latino cases and controls were not unexpected, since cases were more likely to have been born in the United States. Genetic admixture proportions provide a quantitative measure of ancestry differences among Latinos that can be used in analyses of genetic risk factors. Authors: Aldrich MC; Quesenberry CP; Wiencke Nov 1;168(9):1035-46. Epub 2008 Sep 12. Nucleotide excision repair genes and risk of lung cancer among San Francisco Bay Area Latinos and African Americans Few studies on the association between nucleotide excision repair (NER) variants and lung cancer risk have included Latinos and African Americans. We examine variants in 6 NER genes (ERCC2, ERCC4, ERCC5, LIG1, RAD23B and XPC) in association with primary lung cancer risk among 113 Latino and 255 African American subjects newly diagnosed with primary lung cancer from 1998 to 2003 in the San Francisco Bay Area and 579 healthy controls (299 Latinos and 280 African Americans). Individual single nucleotide polymorphism and haplotype analyses, multifactor dimensionality reduction (MDR) and principal components analysis (PCA) were performed to assess the association between 6 genes in the NER pathway and lung cancer risk. Among Latinos, ERCC2 haplotype CGA (rs238406, rs11878644, rs6966) was associated with reduced lung cancer risk [odds ratio (OR) of 0.65 and 95% confidence interval (CI): especially rs17655 rs20581) prediction accuracy of 67.4% (p = 0.001) for lung cancer. Among African Americans, His/His genotype of ERCC5 His1104Asp (rs17655) was associated with cancer risk (OR = 0.61; 95% CI: 0.42-0.88). Our study suggests different elements of the NER pathway may be important in the different ethnic groups resulting either from different linkage relationship, genetic backgrounds and/or exposure histories. Authors: 2008 Nov 1;123(9):2095-104. Cost-effectiveness of abatacept in patients with moderately to severely active rheumatoid arthritis and inadequate response to tumor necrosis factor-alpha antagonists. OBJECTIVE:To assess cost-effectiveness of abatacept in patients with rheumatoid arthritis (RA) with inadequate response to tumor necrosis factor-alpha antagonists (anti-TNF).METHODS:We developed a simulation model to depict progression of disability [in terms of Health Assessment Questionnaire Disability Index (HAQ-DI)] in women aged 55-64 years with moderately to severely active RA and inadequate response to anti-TNF. At model entry, patients were assumed to receive either oral disease modifying antirheumatic drugs (DMARD) only or oral DMARD plus abatacept. Patients were then tracked from model entry until death. Future health-state utilities and medical-care costs (except study therapy) were estimated based on predicted values of the HAQ-DI. The model was estimated using data from a Phase III clinical trial of abatacept plus secondary sources. Cost-effectiveness was expressed in terms of incremental cost (2006 US$) per quality-adjusted life-year (QALY) gained alternatively over 10 years and a lifetime. Future costs and health effects were discounted at 3% annually.RESULTS:Over 10 years, abatacept would yield 1.0 additional QALY (undiscounted) per patient (4.0 vs 3.0 for oral DMARD) at an incremental (discounted) cost of $45,497 (100,648 vs $55,151) respectively; over a lifetime, corresponding figures were 1.6 QALY (5.8 vs 4.2) and $45,979 ($42,678, $49,932) per QALY gained over a lifetime. Findings were robust in sensitivity analyses.CONCLUSION:Abatacept is cost-effective by current standards of medical practice in patients with moderately to severely active RA and inadequate response to an 2008 Sep;35(9):1745-53. Epub 2008 Jul 15. Medicare beneficiaries' knowledge of Part D prescription drug program benefits and responses to drug costs CONTEXT: Medicare Part D drug benefits include substantial cost sharing. OBJECTIVE: To determine beneficiaries' knowledge of benefits and cost responses. DESIGN, SETTING, AND PARTICIPANTS: Telephone interviews were conducted in 2007 in a stratified random sample of community-dwelling Kaiser Permanente-Northern California Medicare Advantage beneficiaries aged 65 years or older, with a gap in coverage if they exceeded $2250 in drug costs (N = 1040; 74.9% response rate). Half were selected to have reached the gap in 2006. In the source population of Medicare Advantage Prescription Drug plan beneficiaries, 8% entered the coverage gap in 2006. Models were adjusted for individual characteristics and weighted for sampling proportions. MAIN OUTCOME MEASURES: Knowledge of cost sharing including awareness of the coverage gap, gap start and end amounts, and drug cost sharing before, during, and after the gap. Cost-related responses including cost-coping behaviors (eg, switching to lower-cost medications), reduced adherence (eg, not refilling prescriptions), and financial burden (eg, going without necessities). RESULTS: An estimated 40% (95% confidence interval [CI], 35%-45%) of beneficiaries were aware that their drug plan in 2006 included a coverage gap; knowledge of the gap was greater among individuals who reached the gap during the year. Approximately 36% (95% CI, 32%-41%) of beneficiaries reported at least 1 of the following responses to drug costs: cost-coping behavior (26%), reduced adherence (15%), or experiencing financial burden (7%). In multivariate analyses, beneficiaries with lower household income more frequently reported cost responses (difference of 14.5 percentage points for < $40,000/y vs > or = $40,000/y [95% CI, 3.6-25.4 percentage points]). Compared with beneficiaries who were unaware of having a coverage gap, those who were aware more frequently reported any cost response (difference of 11.3 percentage points [95% CI, 0.8-21.9 percentage points]), but had fewer reports of borrowing money or going without necessities (difference of 5.5 percentage points [95% CI, 1.1-10.0 percentage points]). CONCLUSIONS: Beneficiaries in this Medicare Advantage plan have limited knowledge of Part D cost sharing and often report behavioral responses to drug costs. Limited knowledge is associated with fewer reports of cost responses overall, but more reports of financial burden. Authors: Hsu J; Fung V; Price M; Huang JAMA. 2008 Apr 23;299(16):1929-36. Cost-effectiveness of abatacept in patients with moderately to severely active rheumatoid arthritis and inadequate response to methotrexate. OBJECTIVE:To assess cost-effectiveness of abatacept in patients with moderately to severely active RA and inadequate response to MTX.METHODS:We developed a simulation model to depict progression of disability [in terms of the HAQ Disability Index (HAQ-DI)] in women aged 55-64 yrs with moderately to severely active RA and inadequate response to MTX. At model entry, patients were assumed to receive either only MTX or MTX plus abatacept. Patients were then tracked from model entry until death. Future health-state utilities and medical-care costs (except study therapy) were estimated based on predicted values of the HAQ-DI. The model was estimated using data from a Phase III clinical trial of abatacept plus various secondary sources. Cost-effectiveness was expressed in terms of incremental cost (2006 US$) per quality-adjusted life-year (QALY) gained over alternatively 10 yrs and a lifetime. Costs and health effects were both discounted at 3% annually.RESULTS:Over 10 yrs, abatacept would yield 1.2 additional QALYs (undiscounted) per patient (4.6 vs 3.4 for MTX) at an incremental (discounted) cost of $51,426 ($103,601 vs $52,175, respectively); over a lifetime, corresponding figures were 2.0 QALYS (6.8 vs 4.8) and $43,041 ($39,070, $46,725) per QALY gained over a lifetime. Findings were robust in sensitivity analyses.CONCLUSION:Abatacept is cost-effective by current standards of medical practice in patients with moderately to severely active RA and inadequate response to 2008 Apr;47(4):535-41. doi: 10.1093/rheumatology/ken007. Dietary patterns and the risk of Barrett's esophagus The objective of this study was to examine the associations between dietary patterns and the risk of Barrett's esophagus, a precursor to esophageal adenocarcinoma. The authors conducted a case-control study within the Kaiser Permanente Northern California population between 2002 and 2005. Patients with a new diagnosis of Barrett's esophagus (n = 296 cases) were matched to persons with gastroesophageal reflux disease (n = 308) without Barrett's esophagus and to population controls (n = 309). Dietary information was obtained from a validated, 110-item food frequency questionnaire. A principal component analysis was used to identify major dietary patterns. Two major dietary patterns were 'Western' (high in fast food and meat) and 'health-conscious' (high in fruits, vegetables, and nonfried fish). When cases and population controls were compared, strong adherence to the health-conscious dietary pattern was inversely associated with Barrett's esophagus (odds ratio = 0.35, 95% confidence interval: 0.20, 0.64; fourth vs. first quartile comparison). In contrast, data suggested an adverse effect of the Western dietary pattern on the risk of Barrett's esophagus, although no dose-effect relation was found. Results suggest strong associations between a diet rich in fruits and vegetables and the risk of Barrett's Apr 1;167(7):839-46. Epub 2008 Jan 23. Effects of depression and selective serotonin reuptake inhibitor use on adherence to highly active antiretroviral therapy and on clinical outcomes in HIV-infected patients OBJECTIVES: To determine the impact of depression on highly active antiretroviral therapy (HAART) adherence and clinical measures and investigate if selective serotonin reuptake inhibitors (SSRIs) improve these measures. DESIGN: Retrospective cohort study. METHODS: In 2 large health maintenance organizations, we measured the effects of depression (with and without SSRI use) on adherence and changes in viral and immunologic control among HIV-infected patients starting a new HAART regimen. HAART adherence, HIV RNA levels, and changes in CD4 T-cell counts through 12 months were measured. RESULTS: A total of 3359 patients were evaluated; 42% had a depression diagnosis, and 15% used SSRIs during HAART. Depression without SSRI use was associated with significantly decreased odds of achieving > or =90% adherence to HAART (odds ratio [OR] = 0.81, 95% confidence interval [CI]: 0.70 to 0.98; P = 0.03). Depression was associated with significantly lower odds of an HIV RNA level <500 copies/mL (OR = 0.77, 95% CI: 0.62 to 0.95; = 0.02). Depressed patients compliant with SSRI medication (>80% adherence to SSRI) had HAART adherence and viral control statistically similar to nondepressed HIV-infected patients taking HAART. Comparing depressed with nondepressed HIV-infected patients, CD4 T-cell responses were statistically similar; among depressed patients, those compliant with SSRI had statistically greater increases in CD4 cell responses. CONCLUSIONS: Depression significantly worsens HAART adherence and HIV viral control. Compliant SSRI use is associated with improved HIV adherence and 2008 Mar 1;47(3):384-90. Development of Alive! (A Lifestyle Intervention Via Email), and its effect on health-related quality of life, presenteeism, and other behavioral outcomes: randomized controlled trial BACKGROUND: Cost-effective interventions to improve diet and physical activity are a public health priority. Alive! is an email-based intervention to increase physical activity, reduce saturated and trans fats and added sugars, and increase fruit and vegetable consumption. It was shown to improve these behaviors in a large randomized controlled trial. OBJECTIVE: (1) To describe the components and behavioral principles underlying Alive!, and (2) to report effects of the intervention on the secondary outcomes: health-related quality of life, presenteeism, self-efficacy, and stage of change. METHODS: The Alive! behavior change model is designed to elicit healthy behaviors and promote their maintenance. Behavioral strategies include assessments followed by individualized feedback, weekly goal-setting, individually tailored goals and tips, reminders, and promotion of social support. Alive! was tested among non-medical employees of Kaiser Permanente of Northern California, who were randomized to either the intervention group or the wait-list control group. After randomization, intervention group participants chose one topic to undertake for the intervention period: increasing physical activity, increasing fruits and vegetables, or decreasing saturated and trans fats and added sugars. Pre-post questionnaires assessed changes in SF-8 health-related quality of life, presenteeism, self-efficacy, and stage of change. Mixed effects multiple linear regression and ordinal logistic regression models were used, with department as a random effect factor. Analyses were by intention to treat: the 30% (238/787) who did not respond to the follow-up questionnaires were assigned change scores of zero. RESULTS: Participants were 19 to 65 years (mean 44.0 +/- 10.6), and 74.3% (585/787) were female. Mean SF-8 Physical quality of life score increased significantly more in the intervention group than in the control group, 1.84 (95% CI 0.96-2.72) vs 0.72 (95% CI -0.15-1.58) respectively, P = .02. SF8 Mental score also improved significantly more in the intervention group than in the control group (P = .02). The odds ratio for improvement in self-assessed health status was 1.57 (95% CI 1.21-2.04, P < .001) for the intervention group compared to the control group. The odds ratio for having a reduction in difficulty accomplishing work tasks because of physical or emotional problems, a measure of presenteeism, was 1.47 (95% CI 1.05-2.05, P = .02) for the intervention group compared to the control group. The odds of having an improvement in self-efficacy for changing diet was 2.05 (95% CI 1.44-2.93) for the intervention vs the control group (P < .001). Greater improvement in stage of change for physical activity (P = .05), fats (P = .06), and fruits/vegetables (P = .006) was seen in the intervention group compared to the control group. Significant effects on diet and physical activity behavior change are reported elsewhere. CONCLUSIONS: Cost-effective methods that can reach large populations with science-based interventions are urgently needed. Alive! is a fully automated low-cost intervention shown to effect significant improvements in important health parameters. TRIAL REGISTRATION: Clinicaltrials.gov Med Internet Res. 2008 Nov 19;10(4):e43. Medical therapy for diabetes is associated with increased use of lower endoscopy BACKGROUND: Diabetes mellitus is associated with an increased risk of colorectal neoplasia and diabetes medications may further influence the risk. Observational studies of the effect of diabetes medications on colonic neoplasia may be biased if use of diabetes medications is associated with undergoing lower endoscopy. This study examined the association between diabetes therapies and use of lower endoscopy. METHODS: This retrospective cohort study included patients with diabetes in an integrated, prepaid health plan. The primary exposure variables were use of sulfonylureas, metformin, thiazolidinediones (TZDs), and insulin. The outcome measure was completion of a flexible sigmoidoscopy or colonoscopy. Cox proportional hazards modeling, accounting for the time-varying nature of the medication exposures, was used to generate estimates of the relative hazard (HR) of lower endoscopy with different medications. RESULTS: The study included 44 169 patients followed for a mean duration of 4.2 years (SD = 2.5 years); 34% underwent at least one lower endoscopy. Patients who filled a diabetes medication prescription were more likely to undergo lower endoscopy (HR = 1.13, 95%CI 1.06-1.21). Compared to those taking only sulfonylureas, patients receiving sulfonylureas and metformin (HR = 1.12, 95%CI 1.06-1.18) or metformin alone (HR = 1.17, 95%CI 1.07-1.26) were more likely to undergo lower endoscopy. For all medications, new use was associated with undergoing lower endoscopy (p < 0.05 for all comparisons). CONCLUSIONS: Diabetic patients receiving medications are more likely to undergo lower endoscopy than those on diet control alone, particularly in the first year after initiating a new medication class and if taking metformin. Authors: of contraception and pregnancy when prescribing potentially teratogenic medications for reproductive-age women BACKGROUND: Certain medications are identified by the U.S. Food and Drug Administration (FDA) as class D or X because they increase the risk for birth defects if used during pregnancy. OBJECTIVE: To assess pregnancy rates and the frequency of contraceptive counseling documented with prescriptions for class D or X drugs filled by women of reproductive age. DESIGN: Description of prescriptions filled in 2001. SETTING: A large health maintenance organization in northern California in 2001. PATIENTS: 488,175 women age 15 to 44 years who filled a total of 1,011,658 class A, B, D, or X prescriptions. MEASUREMENTS: Medications dispensed, contraceptive counseling, and pregnancy testing. RESULTS: A class D or X prescription was filled by 1 of every 6 women studied. Women who filled a prescription for class D or X medications were no more likely than women who filled prescriptions for safer, class A or B medications to have received contraceptive counseling, filled a contraceptive prescription, or been sterilized (48% vs. 51% of prescriptions). There was little variation by clinical indication in rates of contraceptive counseling with class D or X prescriptions, except for isotretinoin. Women who filled a class D or X prescription were only slightly less likely to have a pregnancy documented within 3 months than women filling a class A or B prescription (1.0% vs. 1.4% of prescriptions). LIMITATIONS: International Classification of Diseases, Ninth Revision, codes underestimate contraceptive counseling. Documentation of a positive pregnancy test after filling a prescription may overestimate medication use in early pregnancy. Women who filled several prescriptions are overrepresented in prescription analyses. CONCLUSION: Prescriptions for potentially teratogenic medications are frequently filled by women of childbearing age without documentation of contraceptive counseling. Authors: Schwarz EB; Postlethwaite DA; Hung YY; Armstrong 2007 Sep 18;147(6):370-6. Cost-effectiveness of letrozole versus tamoxifen as initial adjuvant therapy in postmenopausal women with hormone-receptor positive early breast cancer from a Canadian perspective. BACKGROUND:In the primary core analysis of BIG 1-98, a randomized, double-blind trial comparing 5 years of initial adjuvant therapy with letrozole versus tamoxifen in postmenopausal women with hormone receptor-positive (HR+) early breast cancer, letrozole significantly improved disease-free survival by 19% and reduced the risk of breast cancer recurrence by 28% and distant recurrence by 27%.METHODS:A Markov model was used to estimate the incremental cost per quality-adjusted life year (QALY) gained with 5 years of initial adjuvant therapy with letrozole versus tamoxifen from a Canadian healthcare system perspective. Probabilities of recurrence and side effects for tamoxifen were based on published results of BIG 1-98 and other published population-based studies. Corresponding probabilities for letrozole were calculated by multiplying probabilities for tamoxifen by estimated relative risks for letrozole versus tamoxifen from BIG 1-98. Other probabilities, costs of breast-cancer care and treatment of side effects, and health-state utilities were obtained from published studies. Costs and QALYs were estimated over the lifetime of a cohort of postmenopausal women with HR+ early breast cancer, aged 60 years at initiation of therapy, and discounted at 5% annually.RESULTS:Compared with tamoxifen, letrozole QALYs (11.582 vs. 11.239). These benefits are at cost of Can$ 8,110 (Can$ 30,819 vs. breast cancer, initial adjuvant treatment with letrozole is cost-effective from the Canadian K; Epub 2007 Jul 26. Cost-effectiveness of letrozole versus tamoxifen as initial adjuvant therapy in hormone receptor-positive postmenopausal women with early-stage breast cancer. BACKGROUND:In Breast International Group (BIG) 1-98, a randomized, double-blind trial comparing 5 years of initial adjuvant therapy with letrozole versus tamoxifen in postmenopausal women with hormone receptor-positive early breast cancer, letrozole significantly improved disease-free survival by 19% and reduced risk of breast cancer recurrence by 28% and distant recurrence by 27%.PATIENTS AND METHODS:A Markov model was used to estimate the incremental cost per quality-adjusted life year (QALY) gained with 5 years of initial adjuvant therapy with letrozole versus tamoxifen from a US health care system perspective. Probabilities and costs of breast cancer recurrence and treatment-related adverse events and health-state utilities were based on published results of BIG 1-98 and other published studies. Costs and QALYs were estimated over the lifetime of a cohort of postmenopausal women with hormone receptor-positive early breast cancer, aged 60 years at initiation of therapy. In our base case, we assumed that benefits of letrozole on risk of breast cancer recurrence are maintained for 5 years after therapy discontinuation (\"carry-over effect\") and examined the effects of this assumption on results in sensitivity analyses.RESULTS:Under base-case assumptions, letrozole yields an additional 0.409 QALYs versus tamoxifen at an additional cost of $9705, yielding a cost per QALY gained for letrozole versus tamoxifen of $23,743 (95% carry-over letrozole yields 0.264 QALYs at a cost of $10,341, for a cost per QALY gained of $39,098 (95% confidence interval, $23,968- $83,501).CONCLUSION:In postmenopausal women with hormone receptor-positive early breast cancer, initial adjuvant treatment with letrozole is cost-effective from the US health Jun;7(8):608-18. The prevalence, burden, and treatment of urinary incontinence among women in a managed care plan OBJECTIVE: Urinary incontinence (UI) symptoms are common among women, yet only a small proportion of women with incontinence receive a diagnosis and treatment. We used survey and utilization data to determine the prevalence, burden, and treatment use for incontinence among women at Kaiser Permanente in Northern California. METHODS: In 2002, we surveyed 6726 female health plan members about health issues, including incontinence. We assessed type and bothersomeness of incontinence symptoms in the previous 7 days. For survey respondents and a 10% sample of female plan members (n = 108,825), we assessed use from 1997 to 2003. RESULTS: The survey response rate was 49.7% (3344 of 6726); 44% of respondents reported incontinence symptoms in the previous 7 days, with over half of these women reporting that these symptoms bothered them. Fifteen percent of women with incontinence symptoms had a diagnosis consistent with incontinence in the previous 5 years. One third of the women reporting current bothersome incontinence and 14 or more incontinence episodes in the last 7 days had a diagnosis consistent with incontinence in the previous 5 years. Among women who had received medical or surgical treatment for incontinence in the previous 5 years, approximately half currently report being bothered by their symptoms. CONCLUSIONS: Prevalence of bothersome incontinence symptoms among females in a prepaid health plan is high. However, only a small proportion of these women received a diagnosis or treatment for incontinence symptoms in the last 5 years. Efforts to improve the detection and treatment of bothersome incontinence symptoms are needed. infusional thalassaemia patients: US healthcare system perspective. BACKGROUND:Deferasirox is a recently approved once-daily oral iron chelator that has been shown to reduce liver iron concentrations and serum ferritin levels to a similar extent as infusional deferoxamine.OBJECTIVE:To determine the cost effectiveness of deferasirox versus deferoxamine in patients with beta-thalassaemia major from a US healthcare system perspective.METHODS:A Markov model was used to estimate the total additional lifetime costs and QALYs gained with deferasirox versus deferoxamine in patients with beta-thalassaemia major and chronic iron overload from blood transfusions. Patients were assumed to be 3 years of age at initiation of chelation therapy and to receive prescribed dosages of deferasirox and deferoxamine that have been shown to be similarly effective in such patients. Compliance with chelation therapy and probabilities of iron overload-related cardiac disease and death by degree of compliance were estimated using data from published studies. Costs ($US, year 2006 values) of deferoxamine administration and iron overload-related cardiac disease were based on analyses of health insurance claims of transfusion-dependent thalassaemia patients. Utilities were based on a study of patient preferences for oral versus infusional chelation therapy, as well as published literature. Probabilistic and deterministic sensitivity analyses were employed to examine the robustness of the results to key assumptions.RESULTS:Deferasirox resulted in a gain of 4.5 QALYs per patient at an additional expected lifetime cost of $US126,018 per patient; the cost per QALY gained was $US28,255. The cost effectiveness of deferasirox versus deferoxamine was sensitive to the estimated costs of deferoxamine administration and the quality-of-life benefit associated with oral versus infusional therapy. Cost effectiveness was also relatively sensitive to the equivalent daily dose of deferasirox, and the unit costs of deferasirox and deferoxamine, and was more favourable in younger patients.CONCLUSION:Results of this analysis of the cost effectiveness of oral deferasirox versus infusional deferoxamine suggest that deferasirox is a cost effective iron chelator from a US in longitudinal studies with history-restricted marginal structural models A new class of Marginal Structural Models (MSMs), History-Restricted MSMs (HRMSMs), was recently introduced for longitudinal data for the purpose of defining causal parameters which may often be better suited for public health research or at least more practicable than MSMs (6, 2). HRMSMs allow investigators to analyze the causal effect of a treatment on an outcome based on a fixed, shorter and user-specified history of exposure compared to MSMs. By default, the latter represent the treatment causal effect of interest based on a treatment history defined by the treatments assigned between the study's start and outcome collection. We lay out in this article the formal statistical framework behind HRMSMs. Beyond allowing a more flexible causal analysis, HRMSMs improve computational tractability and mitigate statistical power concerns when designing longitudinal studies. We also develop three consistent estimators of HRMSM parameters under sufficient model assumptions: the Inverse Probability of Treatment Weighted (IPTW), G-computation and Double Robust (DR) estimators. In addition, we show that the assumptions commonly adopted for identification and consistent estimation of MSM parameters (existence of counterfactuals, consistency, time-ordering and sequential randomization assumptions) also lead to identification and consistent estimation of HRMSM parameters. J Stat. 2007 Jan 1;1:119-154. Using drink size to talk about drinking during pregnancy: Early start plus Heavy drinking during pregnancy can cause birth defects and other alcohol-related effects. Because costs associated with fetal complications are high, health care organizations are invested in finding ways to intervene with pregnant drinkers. We describe a computerized intervention tested at prenatal clinics that uses drink size as a way of creating dialogue about pregnancy drinking. The intervention helps pregnant women screened as at-risk for alcohol use recognize how much they actually drink, using calibrated glassware and beverage containers along with computer graphics designed to define true volume for specific alcoholic beverage types. The intervention promotes abstinence; however, if that is not an obtainable goal, women are taught ways to cut down as much as possible during the rest of their pregnancy. Clinician feedback has been very positive, and the few women who continued to drink did not drink frequently or engage in binge drinking. Further, their average daily volume was 1 drink per day. outcomes in human immunodeficiency virus-infected patients in the era of highly active antiretroviral therapy HYPOTHESIS: Matched patients who test positive or negative for human immunodeficiency virus (HIV) who are undergoing comparable operations have similar complication rates and outcomes. DESIGN: A retrospective study of surgical outcomes in HIV-infected and matched HIV-noninfected patients. Baseline information including HIV-related laboratory results, complications, and mortality was collected from printed and electronic records through 12 postoperative months. SETTING: Kaiser Permanente Medical Care Program-Northern California, an integrated health organization with more than 3 million members, including more than 5000 HIV-infected members. PATIENTS: From July 1,1997, through June 30, 2002, HIV-infected members undergoing surgical procedures were matched 1:1 with HIV-noninfected patients undergoing surgical procedures by type, location, and year of surgery as well as by sex and age. Surgical procedures studied included appendectomy, arthrotomy or arthroscopy, bowel resection, cholecystectomy, laparoscopy or laparotomy, and mammoplasty. MAIN OUTCOME MEASURES: Complications and mortality through 12 postoperative months, comparisons between HIV-infected and HIV-noninfected patients using matched-pair analyses, and HIV-infected cohort data were analyzed using the Fisher exact test and logistic regression. RESULTS: Of 332 HIV-infected-HIV-noninfected pairs (mean age, 46.7 years; male sex, 91%), more than 95.0% were followed up through 12 postoperative months or until their deaths. Pairs had similar comorbidities, length of hospital stay, and number of postoperative surgical visits (P>.05, all variables). Among HIV-infected patients, the median years with HIV infection was 8.4 years; median CD4 T-cell count was 379/microL; 61.5% of these patients had an HIV RNA level less than 500 copies per milliliter; and 68% were receiving highly active antiretroviral therapy. Various complications were no more frequent among HIV-infected than in HIV-noninfected patients (11.1% vs 10.2%; P = .79), except for pneumonia (P = .04). There were more deaths within the 12 postoperative months in HIV-infected patients (10/332 vs 2/332; P = .02); 2 patients died 30 days or less after being operated on. Among HIV-infected patients, viral load of 30 000 copies per milliliter or more was associated with increased complications (adjusted odds ratio, 2.95; P = .007), but a CD4 cell count less than 200/muL was not associated with poorer outcomes. CONCLUSIONS: The HIV-infected patients had more incidences of postoperative pneumonia and higher 12-month mortality, although other operative outcomes were comparable for HIV-infected and HIV-noninfected patients. Viral suppression to fewer than 30 000 copies per milliliter reduced surgical complications. Cost-sharing for emergency care and unfavorable clinical events: findings from the safety and financial ramifications of ED copayments study OBJECTIVE: To evaluate the effect of emergency department (ED) copayment levels on ED use and unfavorable clinical events. Data Source/Study Setting. Kaiser Permanente-Northern California (KPNC), a prepaid integrated delivery system. STUDY DESIGN: In a quasi-experimental longitudinal study with concurrent controls, we estimated rates of ED visits, hospitalizations, ICU admissions, and deaths associated with higher ED copayments relative to no copayment, using Poisson random effects and proportional hazard models, controlling for patient characteristics. The study period began in January 1999; more than half of the population experienced an employer-chosen increase in their ED copayment in January 2000. DATA COLLECTION/EXTRACTION METHODS: Using KPNC automated databases, the 2000 U.S. Census, and California state death certificates, we collected data on ED visits and unfavorable clinical events over a 36-month period (January 1999 through December 2001) among 2,257,445 commercially insured and 261,091 Medicare insured health system members. PRINCIPAL FINDINGS: Among commercially insured subjects, ED visits decreased 12 percent with the $20-35 copayment (95 percent confidence interval [CI]: 11-13 percent), and 23 percent with the $50-100 copayment (95 percent CI: 23-24 percent) compared with no copayment. Hospitalizations, ICU admissions, and deaths did not increase with copayments. Hospitalizations decreased 4 percent (95 percent CI: 2-6 percent) and 10 percent (95 percent CI: 7-13 percent) with ED copayments of $20-35 and $50-100, respectively, compared with no copayment. Among Medicare subjects, ED visits decreased by 4 percent (95 percent CI: 3-6 percent) with the $20-50 copayments compared with no copayment; unfavorable clinical events did not increase with copayments, e.g., hospitalizations were unchanged (95 percent CI: -3 percent to +2 percent) with $20-50 ED copayments compared with no copayment. CONCLUSIONS: Relatively modest levels of patient cost-sharing for ED care decreased ED visit rates without increasing the rate of unfavorable clinical events. Authors: Hsu J; Price M; Oct;41(5):1801-20. infants: outcomes of moderately premature infants in the neonatal intensive care unit BACKGROUND: Newborns of 30-34 weeks gestation comprise 3.9% of all live births in the United States and 32% of all premature infants. They have been studied much less than very low birthweight infants. OBJECTIVE: To measure in-hospital outcomes and readmission within three months of discharge of moderately premature infants. DESIGN: Prospective cohort study including retrospective chart review and telephone interviews after discharge. SETTING: Ten birth hospitals in California and Massachusetts. PATIENTS: Surviving moderately premature infants born between October 2001 and February 2003. MAIN OUTCOME MEASURES: (a) Occurrence of assisted ventilation during the hospital stay after birth; (b) adverse in-hospital outcomes-for example, necrotising enterocolitis; (c) readmission within three months of discharge. RESULTS: With the use of prospective cluster sampling, 850 eligible infants and their families were identified, randomly selected, and enrolled. A total of 677 families completed a telephone interview three months after hospital discharge. During the birth stay, these babies experienced substantial morbidity: 45.7% experienced assisted ventilation, and 3.2% still required supplemental oxygen at 36 weeks. Readmission within three months occurred in 11.2% of the cohort and was higher among male infants and those with chronic lung disease. CONCLUSIONS: Moderately premature infants experience significant morbidity, as evidenced by high rates of assisted ventilation, use of oxygen at 36 weeks, and readmission. Such morbidity deserves more research. Authors: Dis Child Fetal Neonatal Ed. 2006 Jul;91(4):F238-44. Epub 2006 Apr 12. Hemoglobin level, chronic kidney disease, and the risks of death and hospitalization in adults with chronic heart failure: the Anemia in Chronic Heart Failure: Outcomes and Resource Utilization (ANCHOR) Study BACKGROUND: Previous studies have associated reduced hemoglobin levels with increased adverse events in heart failure. It is unclear, however, whether this relation is explained by underlying kidney disease, treatment differences, or associated comorbidity. METHODS AND RESULTS: We examined the associations between hemoglobin level, kidney function, and risks of death and hospitalization in persons with chronic heart failure between 1996 and 2002 within a large, integrated, healthcare delivery system in northern California. Longitudinal outpatient hemoglobin and creatinine levels and clinical and treatment characteristics were obtained from health plan records. Glomerular filtration rate (GFR; mL.min(-1).1.73 m(-2)) was estimated from the Modification of Diet in Renal Disease equation. Mortality data were obtained from state death files; heart failure admissions were identified by primary discharge diagnoses. Among 59,772 adults with heart failure, the mean age was 72 years and 46% were women. Compared with that for hemoglobin levels of 13.0 to 13.9 g/dL, the multivariable-adjusted risk of death increased with lower hemoglobin levels: an adjusted hazard ratio (HR) of 1.16 and 95% confidence interval (CI) of 1.11 to 1.21 for hemoglobin levels of 12.0 to 12.9 g/dL; HR, 1.50 and 95% CI, 1.44 to 1.57 for 11.0 to 11.9 g/dL; HR, 1.89 and 95% CI, 1.80 to 1.98 for 10.0 to 10.9; HR, 2.31 and 95% CI, 2.18 to 2.45 for 9.0 to 9.9; and HR, 3.48 and 95% CI, 3.25 to 3.73 for <9.0 g/dL. Hemoglobin levels > or = 17.0 g/dL were associated with an increased risk of death (adjusted HR, 1.42; 95% CI, 1.24 to 1.63). Compared with those with a GFR > or = 60 mL . min(-1).1.73 m(-2), persons with a GFR <45 increased mortality risk: adjusted HR, 1.39 and 95% CI, 1.34 to 1.44 for 30 to 44; HR, 2.28 and 95% CI, 2.19 to 2.39 for 15 to 29; HR, 3.26 and 95% CI, 3.05 to 3.49 for <15; and HR, 2.44 and 95% CI, 2.28 to 2.61 for those on dialysis. Relations were similar for the risk of hospitalization. The findings did not differ among patients with preserved or reduced systolic function, and hemoglobin level was an independent predictor of outcomes at all levels of kidney function. CONCLUSIONS: Very high (> or = 17 g/dL) or reduced (<13 g/dL) hemoglobin levels and chronic kidney disease independently predict substantially increased risks of death and hospitalization in heart failure, regardless of the level of systolic function. Randomized trials are needed to evaluate whether raising hemoglobin levels can improve outcomes in chronic heart failure. Authors: Go Jun 13;113(23):2713-23. Epub 2006 Jun 5. Unintended consequences of caps on Medicare drug benefits BACKGROUND: Little information exists about the consequences of limits on prescription-drug benefits for Medicare beneficiaries. METHODS: We compared the clinical and economic outcomes in 2003 among 157,275 Medicare+Choice beneficiaries whose annual drug benefits were capped at 1,000 dollars and 41,904 beneficiaries whose drug benefits were unlimited because of employer supplements. RESULTS: After adjusting for individual characteristics, we found that subjects whose benefits were capped had pharmacy costs for drugs applicable to the cap that were lower by 31 percent than subjects whose benefits were not capped (95 percent confidence interval, 29 to 33 percent) but had total medical costs that were only 1 percent lower (95 percent confidence interval, -4 to 6 percent). Subjects whose benefits were capped had higher relative rates of visits to the emergency department (relative rate, 1.09 [95 percent confidence interval, 1.04 to 1.14]), nonelective hospitalizations (relative rate, 1.13 [1.05 to 1.21]), and death (relative rate, 1.22 [1.07 to 1.38]; difference, 0.68 per 100 person-years [0.30 to 1.07]). Among subjects who used drugs for hypertension, hyperlipidemia, or diabetes in 2002, those whose benefits were capped were more likely to be nonadherent to long-term drug therapy in 2003; the respective odds ratios were 1.30 (95 percent confidence interval, 1.23 to 1.38), 1.27 (1.19 to 1.34), and 1.33 (1.18 to 1.48) for subjects using drugs for hypertension, hyperlipidemia, and diabetes. In each subgroup, the physiological outcomes were worse for subjects whose drug benefits were capped than for those whose benefits were not capped; the odds ratios were 1.05 (95 percent confidence interval, 1.00 to 1.09), 1.13 (1.03 to 1.25), and 1.23 (1.03 to 1.46), respectively, for subjects with a systolic blood pressure of 140 mm Hg or more, a serum low-density-lipoprotein cholesterol level of 130 mg per deciliter or more, and a glycated hemoglobin level of 8 percent or more. CONCLUSIONS: A cap on drug benefits was associated with lower drug consumption and unfavorable clinical outcomes. In patients with chronic disease, the cap was associated with poorer adherence to drug therapy and poorer control of blood pressure, lipid levels, and glucose levels. The savings in drug costs from the cap were offset by increases in the costs of hospitalization and emergency department care. Authors: Hsu J; Price M; Huang J; N J 2006 Jun 1;354(22):2349-59. Early experiences with e-health services (1999-2002): promise, reality, and implications BACKGROUND: E-health services may improve the quality and efficiency of care; however, there is little quantitative data on e-health use. OBJECTIVE: The objective of this study was to examine trends in e-health use and user characteristics. RESEARCH DESIGN: This was a longitudinal study of e-health use (1999-2002) within an integrated delivery system (IDS). We classified 4 e-health services into transactional (drug refills and appointment scheduling) and care-related (medical and medication advice) services. SUBJECTS: Approximately 3.3 million members of a large, prepaid IDS. MEASUREMENTS: Amount and frequency of e-health use over time and characteristics of users. RESULTS: The number of members registered for access to e-health increased from 20,617 (0.7% of all members) in Q1 1999 to 270,987 in Q3 2002. Between Q1 Q3 2002, (1.3%) used the drug refill service and 55,901 (1.7%) used the appointment scheduling service compared with 10,756 members (0.3%) who used the medical advice service and 3069 (0.1%) who used the medication advice service. Over the same period, transactional service users averaged 3.5 uses/user versus 1.6 uses/user among care-related service users. Members most likely to use e-health services had a high level of clinical need, a regular primary care provider, were 30 to 64 years old, female, white, and lived in a nonlow socioeconomic status neighborhood. These findings were consistent across e-health service types. CONCLUSIONS: Although use of all e-health services grew rapidly, use of care-related services lagged significantly behind use of transactional services. Subjects with greater clinical need and better ties to the health system were more likely to use both types of e-health services. Authors: Fung V; Selby JV; Hsu J Med Care. 2006 May;44(5):491-6. An observational study examining the impact of capecitabine on warfarin antithrombotic activity and bleeding complications OBJECTIVE: The objectives of this study are to quantify the frequency of concomitant use of capecitabine and warfarin, and to quantify the rate of bleeding events and elevated international normalized ratio (INR) among concomitant users of warfarin and capecitabine. RESEARCH DESIGN AND METHODS: We conducted a retrospective population-based study within the Henry Ford Health System (Detroit, MI) and the Kaiser Permanente Medical Care Program of Northern California (Oakland, CA). The study population included patients prescribed concomitant capecitabine and warfarin from 1 April 1997 through 31 July 2002. Data from the medical records of concurrent users were extracted through 31 August 2002. MAIN OUTCOME MEASURES: Concomitant use of capecitabine and warfarin, bleeding events, and INR laboratory results, collected from computerized databases and medical record review. RESULTS: Overall, 11% of capecitabine users also received warfarin (99 / 883). Among 17 patients who received warfarin for venous access device prophylaxis, one bleeding event occurred during concomitant capecitabine/warfarin use (rate = 35.7 bleeding events per 100 person-years, 95% confidence interval [CI] 0.9-198.9), and no events occurred during use of warfarin alone (95% CI 0.0-136.2) (p = 0.50). Among patients prescribed warfarin for indications other than port prophylaxis, no bleeding events occurred during concomitant use of capecitabine and warfarin (95% CI 0.0-34.6), and one event occurred during warfarin use alone (rate = 9.2 bleeding events per 100 person-years, 95% CI 0.2-51.3) (p = 0.54). We found one INR elevation > 3.0 among concomitant capecitabine/warfarin users receiving warfarin for port prophylaxis (rate = 35.7 per 100 person-years) and no INR elevations > 3.0 during use of warfarin alone (p = 0.46). Among patients using warfarin for indications other than port prophylaxis, the rates of INR > 3.0 were 309.7 per 100 person-years (95% CI 213.2-434.9) during concomitant capecitabine/warfarin and 193.5 events per 100 person-years (95% CI 119.8-295.8) during use of warfarin alone (p = 0.09). CONCLUSIONS: The results of our study show a low prevalence of capecitabine and warfarin concomitant use. We did not find large differences in the rates of bleeding events and elevated INR in patients receiving concomitant capecitabine and warfarin when compared with use of warfarin alone. While these results do not imply a lack of biologic interaction, our findings indicate that patients appear to be appropriately managed in clinical practice. and racial/ethnic disparities in outcomes after acute myocardial infarction: a cohort study among members of a large integrated health care delivery system in northern California BACKGROUND: Previous studies have documented sex and racial/ethnic disparities in outcomes after acute myocardial infarction (AMI), but the explanation of these disparities remains limited. In a setting that controls for access to medical care, we evaluated whether sex and racial/ethnic disparities in prognosis after AMI persist after consideration of socioeconomic background, personal medical history, and medical management. METHODS: We conducted a prospective cohort study of the members (20,263 men and 10,061 women) of an integrated health care delivery system in northern California who had experienced an AMI between January 1, 1995, and December 31, 2002, and were followed up for a median of 3.5 years (maximum, 8 years). Main outcome measures included AMI recurrence and all-cause mortality. RESULTS: In age-adjusted analyses relative to white men, black men (hazard ratio [HR], 1.44; 95% confidence interval [CI], 1.26-1.65), black women 1.26-1.72), and Asian women (HR, 1.37; 95% CI, 1.13-1.65) were at increased risk of AMI recurrence. However, multivariate adjustment for sociodemographic background, comorbidities, medication use, angiography, and revascularization procedures effectively removed the excess risk of AMI recurrence in these 3 groups. Similarly, the increased age-adjusted risk of all-cause mortality seen in black men (HR, 1.55; 95% CI, 1.37-1.75) and black women (HR, 1.45; 95% CI, 1.27-1.66) was greatly attenuated in black men and reversed in black women after full multivariate adjustment. CONCLUSION: In a population with equal access to medical care, comprehensive consideration of social, personal, and medical factors could explain sex and racial/ethnic disparities in prognosis Med. 2005 Oct 10;165(18):2105-13. TPMG Northern California appointments and advice call center Kaiser Permanente (KP) has been developing its use of call centers as a way to provide an expansive set of healthcare services to KP members efficiently and cost effectively. Since 1995, when The Permanente Medical Group (TPMG) began to consolidate primary care phone services into three physical call centers, the TPMG Appointments and Advice Call Center (AACC) has become the 'front office' for primary care services across approximately 89% of Northern California. The AACC provides primary care phone service for approximately 3 million Kaiser Foundation Health Plan members in Northern California and responds to approximately 1 million calls per month across the three AACC sites. A database records each caller's identity as well as the day, time, and duration of each call; reason for calling; services provided to callers as a result of calls; and clinical outcomes of calls. We here summarize this information for the period 2000 through 2003. Authors: Conolly P; Levine L; Amaral J Med Syst. 2005 Aug;29(4):325-33. Menopause, physical activity, and body composition/fat distribution in midlife women PURPOSE: Hormonal changes associated with menopause, chronological aging, and lifestyle, specifically physical activity, may all influence the changes in body composition and fat distribution experienced by midlife women. This cross-sectional study examined those relations in a representative sample of 248 white and Chinese women, ages 47-57, participating in an ancillary study to the Study of Women's Health Across the Nation (SWAN), a multi-center, longitudinal investigation of the natural history of the menopause in a racially/ethnically diverse cohort. METHODS: Body composition (lean mass, percent body fat) was assessed with dual energy x-ray absorptiometry, and central adiposity was determined by waist circumference. Physical activity was assessed from 7 d of accelerometer recordings. Menopausal status was based on self-reported bleeding patterns. RESULTS: Higher levels of physical activity, particularly vigorous-intensity activity, were generally independently associated with decreased percent body fat and smaller waist circumference, although these findings were not statistically significant in the Chinese women. Among the white women, every half a standard deviation increase in total activity was associated with a 1.6-point decrease in percent body fat (P = 0.002). Waist circumference decreased from 96.2 cm (SE = 1.04) in those doing no vigorous-intensity activity to 81.4 cm (SE = 1.05) in those doing 10 min or more a day (P for trend = 0.05). For both the whites and the Chinese, late peri- and postmenopausal status was associated with lower lean mass, and among the Chinese, tended to be associated with higher percent body fat. CONCLUSION: These findings suggest that regular physical activity may help to mitigate the tendency for weight gain and adverse changes in body composition and fat distribution that accompany aging and the menopausal transition. Authors: Sports Exerc. 2005 Jul;37(7):1195-202. Use of e-Health services between 1999 and 2002: a growing digital divide OBJECTIVE: To evaluate the patterns of e-Health use over a four-year period and the characteristics of users. DESIGN: Longitudinal, population-based study (1999-2002) of members of a prepaid integrated delivery system. Available e-Health services included ordering prescription drug refills, scheduling appointments, and asking medical questions. MEASUREMENTS: Rates of known access to e-Health services, and of e-Health use each quarter. RESULTS: The number of members with known e-Health access increased from 51,336 (1.6%) in 1999 to 324,522 (9.3%), in 2002. The percentage of households in which at least one person in the household had access increased from 2.7% to 14.1%. Among the subjects with known access, the percentage of subjects that used e-Health at least once increased from 25.7% in 1999 to 36.2% in 2002. In the multivariate analysis, subjects who had a low expected clinical need, were nonwhite, or lived in low socioeconomic status (SES) neighborhoods were less likely to have used e-Health services in 2002. Disparities by race/ethnicity and SES persisted after controlling for access to e-Health and widened over time. CONCLUSION: Access to and use of e-Health services are growing rapidly. Use of these services appears to be greatest among persons with more medical need. The majority of subjects, however, do not use any e-Health services. More research is needed to determine potential reasons for disparities in e-Health use by race/ethnicity and SES as well as the implications of these disparities on clinical outcomes. Authors: Hsu J; Am Med Inform Assoc. 2005 Mar-Apr;12(2):164-71. Epub 2004 Nov 23. Physical activity and changes in weight and waist circumference in midlife women: findings from the Study of Women's Health Across the Nation Controversy exists regarding the extent to which age, menopausal status, and/or lifestyle behaviors account for the increased weight, fat mass, and central adiposity experienced by midlife women. To address this question, the authors longitudinally examined the relations of aging, menopausal status, and physical activity to weight and waist circumference in 3,064 racially/ethnically diverse women aged 42-52 years at baseline who were participating in the Study of Women's Health Across the Nation (SWAN), an observational study of the menopausal transition. Over 3 years of follow-up (1996-1997 to 1999-2000), mean weight increased by 2.1 kg (standard deviation (SD), 4.8) or 3.0% (SD, 6.5) and mean waist circumference increased by 2.2 cm (SD, 5.4) or 2.8% (SD, 6.3). Change in menopausal status was not associated with weight gain or significantly associated with increases in waist circumference. A one-unit increase in reported level of sports/exercise (on a scale of 1-5) was longitudinally related to decreases of 0.32 kg in weight (p < 0.0001) and 0.10 cm in waist circumference (not significant). Similar inverse relations were observed for daily routine physical activity (biking and walking for transportation and less television viewing). These findings suggest that, although midlife women tend to experience increases in weight and waist circumference over time, maintaining or increasing participation in regular physical activity contributes to prevention or attenuation of those gains. Epidemiol. 2004 Nov 1;160(9):912-22. Can disease management reduce health care costs by improving quality? Disease management (DM) promises to achieve cost savings by improving the quality of care for chronic diseases. During the past decade the Permanente Medical Group in Northern California has implemented extensive DM programs. Examining quality indicators, utilization, and costs for 1996-2002 for adults with four conditions, we find evidence of substantial quality improvement but not cost savings. The causal pathway-from improved care to reduced morbidity to cost savings-has not produced sufficient savings to offset the rising costs of improved care. We conclude that the rationale for DM programs, like the rationale for any medical treatments, should rest on their effectiveness and value. Authors: Fireman B; Bartlett J; Selby J Health Aff (Millwood). 2004 Nov-Dec;23(6):63-75. The safety of telephone management of presumed cystitis in women Authors: Vinson DR; Quesenberry CP Jr Arch Intern Med. 2004 May 10;164(9):1026-9. Wine, liquor, beer, and mortality A substantially increased risk for heavy drinkers and a slightly reduced risk for lighter drinkers results in the J-shaped alcohol-mortality curve. Limited data suggest a more favorable mortality experience for drinkers of wine than for drinkers of liquor or beer. To examine these relations, the authors performed a cohort study of participants in a large Northern California prepaid health care program. Demographic and history data were collected from 128,934 adults undergoing health evaluations in 1978-1985, with subsequent death ascertained by an automated linkage system. Cox proportional hazards models with eight covariates were used to determine relative risk estimates according to total alcohol intake and days per week of drinking wine, wine types, beer, or liquor. The J-shaped alcohol-mortality relation was stable for 20 years. Independently, frequency of wine drinking was associated with lower mortality risk (p<0.001) largely because of lower coronary disease risk. Similar risk reductions were associated with red wine, white wine, other types of wine, and combinations of wine types. Much of the lower risk associated with light drinking was related to wine drinking. The authors conclude that drinkers of any type of wine have a lower mortality risk than do beer or liquor drinkers, but it remains unclear whether this reduced risk is due to nonalcoholic wine ingredients, drinking pattern, or associated traits. Authors: Klatsky AL; Friedman GD; Armstrong MA; Kipp H Am J Epidemiol. 2003 Sep 15;158(6):585-95. The early repolarization normal variant electrocardiogram: correlates and consequences PURPOSE: We compared the characteristics and outcomes of patients with 'early repolarization' electrocardiograms (ECGs) with those who had normal ECGs. METHODS: In 1983 to 1985, we collected photocopies of 2234 selected ECGs from 73088 patients undergoing health examinations. Excluding 153 ECGs with missing data or that were judged to be abnormal, the remaining ECGs were reinterpreted in 2000 by cardiologists as showing early repolarization (n = 670), or being borderline (n = 330) or normal (n = 1081). Characteristics and outcomes of persons with early repolarization ECGs were compared with those who had normal ECGs using analysis of variance, logistic regression, or proportional hazards models. Information on exercise was available in 325 patients. RESULTS: Patients with early repolarization were more likely to be male (81% [n = active (mean [+/- SD], 10.4 +/- 1.3 hours per week of activity vs. 6.4 +/- 1.2 hours per week of activity) than those with normal ECGs. Patients with early repolarization were not more likely to be hospitalized (hazard ratio [HR] = 1.0; 95% confidence interval [CI]: 0.9 to 1.2) or to die (HR = 0.8; 95% CI: 0.6 to 1.2) during follow-up than those with normal ECGs. Outpatient diagnoses were not more common in those with early repolarization; arrhythmias were actually less common (P <0.01). CONCLUSION: Although especially prevalent in young, athletic, black men, early repolarization is not rare in other patients. The long-term prognosis of early repolarization is Am J Med. 2003 Aug 15;115(3):171-7. Traits of persons who drink decaffeinated coffee PURPOSE: Little is known about the traits of decaffeinated coffee drinkers, who are sometimes used to ascertain whether the health effects of coffee intake are due to caffeine or some other coffee ingredient. METHODS: We studied these traits in 12,467 persons who reported type of coffee consumed at health examinations; 36% drank caffeinated only, 13% drank decaffeinated only, 27% drank both types and 24% drank no coffee. RESULTS: Odds ratios estimated from logistic regression analyses revealed that compared with regular (caffeinated) coffee drinkers or abstainers, decaffeinated coffee drinkers were less likely to be heavy coffee drinkers, smokers, alcohol drinkers, users of caffeinated soft drinks and medication and to be free of illness. Increased decaffeinated coffee drinking was associated with older age, female sex, African American ethnicity, use of special diets and cardiovascular, gastrointestinal, or neuropsychiatric symptoms. Persons on special diets were more likely to drink decaffeinated coffee whether they had heart disease or were free of any illness. CONCLUSION: These data suggest that decaffeinated coffee use is related to illness in some persons but to a healthy lifestyle in others. These potential and possibly conflicting confounding factors need to be considered when studying the health effects of coffee or caffeine. Authors: Kubo Shlonsky substance abuse intervention in obstetric clinics decreases adverse neonatal outcomes OBJECTIVE: To evaluate the effect of Early Start, a managed care organization's obstetric clinic-based perinatal substance abuse treatment program, on neonatal outcomes. STUDY DESIGN: Study subjects were 6774 female Kaiser Permanente members who delivered babies between July 1, 1995 and June 30, 1998 and were screened by completing prenatal substance abuse screening questionnaires and urine toxicology screening tests. Four groups were compared: substance abusers screened, assessed, and treated by Early Start ('SAT,' n=782); substance abusers screened and assessed by Early Start who had no follow-up treatment ('SA,' n=348); substance abusers who were only screened n=262); and controls who screened negative ('C,' n=5382). RESULTS: Infants of SAT women had assisted ventilation rates (1.5%) similar to control infants (1.4%), but lower than the SA (4.0%, p=0.01) and S groups (3.1%, p=0.12). Similar patterns were found for low birth weight and preterm delivery. CONCLUSION: Improved neonatal outcomes were found among babies whose mothers received substance abuse treatment integrated with prenatal care. The babies of SAT women did as well as control infants on rates of assisted ventilation, low birth weight, and preterm delivery. They had lower rates of these three neonatal outcomes than infants of either SA or S women. Authors: Armstrong MA; Gonzales Perinatol. 2003 Jan;23(1):3-9. Physical activity and menstrual cycle characteristics in two prospective cohorts Relations between physical activity and prospectively collected menstrual cycle characteristics were examined in two large cohorts. One cohort consisted of women employed in the semiconductor industry in 1989 who participated in a prospective study of reproductive outcomes (n = 367). The other consisted of women living in Tecumseh, Michigan, who completed both the 1992-1993 and 1993-1994 examinations for the Michigan Bone Health Study (n = 328). Mean cycle length, variability of cycle length, and mean bleed length were calculated from daily diaries (Semiconductor cohort) or monthly menstrual calendars (Michigan cohort) for a median of five and 11 cycles, respectively. Physical activity was assessed by self-report at baseline and expressed as metabolic equivalent-minutes per week. In the Semiconductor study, women also reported daily minutes of vigorous exercise in their diaries. In the Michigan cohort, total physical activity, total recreational physical activity, and vigorous recreational activity were positively associated with cycle length. The magnitude of these associations declined as body mass index increased. In the Semiconductor cohort, the minutes of daily vigorous exercise were positively associated with cycle length only in a repeated-measures analysis. These findings lend modest support to the hypothesis that moderate levels of physical activity can lengthen the menstrual cycle. Authors: 1;156(5):402-9. Life after a ventricular arrhythmia BACKGROUND: There are few data from community-based evaluations of outcomes after a life-threatening ventricular arrhythmia (LTVA). We evaluated patients' quality of life (QOL) and medical costs after hospitalization and treatment for their first episode of an LTVA. METHODS: We prospectively evaluated QOL by use of the Duke Activity Status Index (DASI), Medical Outcomes Study SF-36 mental health and vitality scales, the Cardiac Arrhythmia Suppression Trial (CAST) symptom scale, and resource use in patients discharged after a first episode of an LTVA in a managed care population of 2.4 million members. RESULTS: We enrolled 264 subjects with new cases of LTVA. Although functional status initially decreased compared with self-reports of pre-event functional status, both functional status and symptom levels improved significantly during the study period. These improvements were greater in patients receiving an implantable cardioverter defibrillator (ICD) than in patients receiving amiodarone. Ratings of mental health and vitality were not significantly different between the treatment groups and did not change significantly during follow-up. The total 2-year medical costs were higher for patients receiving an ICD than for patients receiving amiodarone, despite lower costs during the follow-up period for the patients receiving an ICD. CONCLUSIONS: New onset of an LTVA has a substantial negative initial impact on QOL. With therapy, most patients have improvements in their QOL and symptom level, possibly more so after treatment with an ICD. The costs of treating these patients are very high. Authors: Hsu Am Heart J. 2002 Sep;144(3):404-12. Foot problems as risk factors of fractures This case-control study examines whether foot problems are risk factors of fractures of five sites among people aged 45 years or older at six Kaiser Permanente Medical Centers in northern California. From October 1996 to May 2001, interviewers collected information through a standardized questionnaire. Incident cases of distal forearm (n = 1,000), foot (n = 827), proximal humerus (n = 448), shaft of the tibia/fibula (n = 168), and pelvis (n = 172) fractures and 1,913 controls from the same medical centers were included. After adjustment for potential confounders and for each additional foot problem, the odds of a foot fracture increased by 8% (adjusted odds ratio = 1.08, 95% confidence interval: 1.03, 1.13). In contrast, each additional foot problem was associated with a reduction in the odds of a forearm fracture (adjusted odds ratio = 0.93, 95% confidence interval: 0.89, 0.98). In general, foot problems were not related to fractures of other sites, although diabetes, which may result in foot problems, increased the odds of a proximal humerus fracture (adjusted odds ratio = 1.65, 95% confidence interval: 1.20, 2.26). If these findings are supported by data from other studies, preventive measures to retard the development of foot problems could reduce the incidence of foot fractures. Authors: Keegan TH; 2002 May 15;155(10):926-31. Treatment decisions about lumbar herniated disk in a shared decision-making program BACKGROUND: An explicit process of collaborative (shared) decision making involving the patient and physician has been recommended for discretionary surgical procedures in which small-area analysis demonstrates high variation not attributable to differences in the patient population in the area. One such example is laminectomy for lumbar herniated disk (HD). An observational study was undertaken to evaluate the impact of an HD videodisk program on patient satisfaction, decision making, and treatment preferences. METHODS: Enrollment occurred in the outpatient offices of surgeons treating Kaiser Permanente (Colorado Region) patients with HD who had indications for surgery. Enrollment took place from May 1993 to December 1995, and follow-up surveys of patients were completed by January 1997. RESULTS: A 6.0% decrease in the undecided group and a 1.3% decrease in the group preferring nonsurgical treatment drove a shift of patients toward laminectomy, from 26.7% to 35.8% (Wilcoxon signed rank test = 349.5, p = .017). Postviewing preference (74.0%) was a better aggregate predictor of the ultimate treatment than previewing preference (70.0%) for laminectomy. DISCUSSION: Viewing the videodisk increased the preference for laminectomy. However, limitations in the data prevented us from determining whether this change in preference was actually reflected in patients' ultimate decisions. The fact that the strongest predictor of choosing surgery was the patient's valuation of his or her condition supports shared decision making, with its emphasis on patient's values. Participation in other videodisk programs has been low; perhaps physicians should ask patients to view these videodisks before their visits. Authors: Barrett PH; slopes for different folks: socioeconomic and racial/ethnic disparities in asthma and hay fever among 173,859 U.S. men and women Although allergic diseases such as asthma and hay fever are a major cause of morbidity in industrialized countries, most studies have focused on patterns of prevalence among children and adolescents, with relatively few studies on variations in prevalence by race/ethnicity and socioeconomic position among adults. Our study examined racial/ethnic and socioeconomic patterns in the prevalence of asthma overall, asthma with hay fever, asthma without hay fever, and hay fever overall, in a population of 173,859 women and men in a large prepaid health plan in northern California. Using education as a measure of socioeconomic position, we found evidence of a positive gradient for asthma with hay fever with increasing level of education but an inverse gradient for asthma without hay fever. Hay fever was also strongly associated with education. Compared with their White counterparts, Black women and men were more likely to report asthma without hay fever, and Black women were less likely to have asthma with hay fever. Asian men were also more likely to report asthma with hay fever, and Asian women and men were much more likely to have hay fever. Racial/ethnic disparities in prevalence of allergic diseases were largely independent of education. We discuss implications for understanding these social inequalities in allergic disease risk in relation to possible differences in exposure to allergens and determinants of immunologic susceptibility and suggest directions for future research. OBJECTIVES: To determine the incidence of neonatal dehydration leading to rehospitalization, whether clinical and health services data could predict its occurrence, and the outcome of dehydrated infants. METHODS: We employed a retrospective case-control design nested within a cohort of 51 383 newborns weighing 2000 g or more, with a gestational age of 36 weeks or more born at 11 Kaiser Permanente hospitals during 1995 and 1996. Cases were 110 infants who were rehospitalized within 15 days of discharge with dehydration, and who either had 12% or greater weight loss or a serum sodium level of 150 mEq/L or greater. Controls were 402 randomly selected infants. We reviewed subjects' paper medical records and telephoned their families at 24 to 36 months of age to ascertain neurological outcomes. RESULTS: Rehospitalization for dehydration occurred in 2.1 per 1000 live births (95% confidence interval [CI], 1.8-2.6). Among vaginal births, the most important risk factors were being born of a first-time mother (adjusted odds ratio 3.9-32.6); maternal age to older than 35 years (AOR, 3.0; 95% CI, 1.5-6.0); and gestational age younger than 39 weeks (AOR, 2.0, 95% CI, 1.2-3.5). Among cesarean births, having a birth hospitalization length of stay less than 48 hours was associated with dehydration (odds ratio [OR], 14.8; 95% CI, 1.4-154.1). Adherence to the American Academy of Pediatrics follow-up guideline did not decrease risk of readmission. Among surviving infants, 1 of 110 cases and 12 of 400 controls had evidence of possible neurological problems 24 to 36 months after discharge (P =.3). No cases of limb gangrene, amputation, or intracranial infarction occurred. CONCLUSIONS: In this population with good access to medical care, serious sequelae of neonatal dehydration are rare. Interventions to decrease the frequency of neonatal dehydration should focus on first-time mothers and those who breastfeed exclusively. Authors: Adolesc Med. 2002 Feb;156(2):155-61. Utilization of health services among patients referred to an alcohol treatment program This study assessed utilization of health services among 1,317 adults referred to an outpatient Psychiatry Department alcohol treatment program from July, 1988 through December, 1989. The mean number of visits/year for 1 year before and 4 years after treatment referral were compared for all outpatient clinics combined and 4 clinic subgroups; the mean number of hospitalizations and number of days hospitalized were also analyzed. Overall, utilization was higher before treatment than after, except for Psychiatry Department visits. Amount of treatment received had little effect on utilization. These results suggest that alcoholism treatment contributes to a reduction in higher cost health services utilization. Authors: Armstrong MA; Midanik Safety of neonatal hepatitis B vaccine administration OBJECTIVE: To determine whether hepatitis B vaccination of newborns increases the incidence of fever and/or suspected sepsis. METHODS: A prospective clinical study was undertaken at the Kaiser Permanente San Francisco Medical Center involving normal full term newborns born between November 1, 1991, and April 30, 1994. During this time 3302 infants were vaccinated within 21 days of birth with hepatitis B vaccine, and 2353 were not. Clinical and demographic data were collected from Kaiser Permanente's existing clinical information systems, and laboratory data for blood and cerebrospinal fluid (CSF) cultures were obtained from the comprehensive automated regional laboratory reporting system. RESULTS: There were no significant differences between vaccinated and unvaccinated newborns in the proportion of infants who received care for fever (0.8% vaccinated and 1.1% unvaccinated, P = 0.28), allergic reactions, seizures or other neurologic events in the first 21 days of life. Vaccinated newborns were significantly less likely to undergo microbiologic evaluation for possible sepsis. Among vaccinated newborns 4.0% had blood cultures and 1.6% had CSF cultures. Among infants who were not vaccinated 8.3% had blood cultures and 1.6% had CSF cultures (P <0.001 for both tests). CONCLUSION: This study found no evidence that newborn hepatitis B vaccination is associated with an increase in the number of febrile episodes, sepsis evaluations or allergic or neurologic events. In addition our data did not support any increase in medical procedures attributed to receipt of hepatitis B vaccine. Authors: Lewis E; Pediatr Infect Dis J. 2001 Nov;20(11):1049-54. The prevalence of clinically recognized obsessive-compulsive disorder in a large health maintenance organization OBJECTIVE: Little is known about the prevalence of obsessive-compulsive disorder (OCD) as recognized in clinical settings. The authors report data on the prevalence of clinically recognized OCD in a large, integrated, group practice health maintenance organization (HMO). METHOD: The authors examined the database of outpatient diagnoses for the 1.7 million people (age >or=6) in the San Francisco Bay Area and Sacramento who were continuously enrolled in Kaiser Permanente from May 1995 through April 1996. OCD diagnoses were confirmed by chart review. RESULTS: The 1-year prevalence of clinically recognized OCD was 84/100,000 (95% confidence interval: 80-89/100,000), or 0.084%. It varied among the 19 clinics within the HMO but was nowhere higher than 150/100,000. Prevalence was higher among women than among men but was higher among boys than among girls. Above age 65, OCD prevalence decreased markedly in both genders. Period prevalence rates increased by 60% as the length of the study period doubled from 1 to 2 years, more than would be expected for a chronic disease requiring regular care. About three-quarters of both children and adults with OCD had comorbid psychiatric diagnoses; major depression was common in both groups. CONCLUSIONS: Although previously reported prevalences of 1%-3% from community studies may have included many transient or misclassified cases of OCD not requiring treatment, the very low prevalence of clinically recognized OCD in this population suggests that many individuals suffering from OCD are not receiving the benefits of effective treatment. Authors: Fireman B; Koran LM; Leventhal JL; Jacobson A Am J Psychiatry. 2001 Nov;158(11):1904-10. Patterns of cigarette smoking and alcohol use among lesbians and bisexual women enrolled in a large health maintenance organization OBJECTIVES: This study compared the prevalence of cigarette smoking and alcohol use among lesbians and bisexual women with that among heterosexual women. METHODS: Logistic regression models were created with data from an extensive member health survey at a large health maintenance organization. Sexual orientation was the primary predictor, and alcohol consumption and cigarette smoking were outcomes. RESULTS: Lesbians and bisexual women younger than 50 years were more likely than heterosexual women to smoke cigarettes and drink heavily. Lesbians and bisexual women aged 20 to 34 reported higher weekly alcohol consumption and less abstinence compared with heterosexual women and older lesbians and bisexual women. CONCLUSIONS: Lesbians and bisexual women aged 20 to 34 years are at risk for alcohol use and cigarette smoking. Authors: Gruskin EP; Hart S; Gordon N; Ackerson L Am J Public Health. 2001 Jun;91(6):976-9. Impact of the change in polio vaccination schedule on immunization coverage rates: a study in two large health maintenance organizations OBJECTIVE: In January 1997, one of the most significant changes to United States vaccine policy occurred when polio immunization guidelines changed to recommend a schedule containing inactivated polio vaccine (IPV). There were concerns that parent or physician reluctance to accept IPV into the routine childhood immunization schedule would lead to lowered coverage. We determined whether adoption of an IPV schedule had a negative impact on immunization coverage. DESIGN: A cohort study of 2 large health maintenance organizations (HMOs), Group Health Cooperative and Kaiser Permanente Northern California, was conducted. For analysis at 12 months of age, children who were born between October 1, 1996, and December 31, 1997, and were commercially insured and covered by Medicaid were continuously enrolled; for analysis at 24 months of age, children who were born between October 1, 1996, and June 30, 1997, and were commercially insured and covered by Medicaid were continuously enrolled. The 3 measures of immunization status at 12 and 24 months of age were up-to-date status, cumulative time spent up-to-date, and the number of missed opportunity visits. RESULTS: At both HMOs, children who received IPV were as likely to be up to date at 12 months as were children who received oral poliovirus vaccine (OPV), whereas at Group Health, children who received IPV were slightly more likely to be up to date at 24 months (relative risk: 1.12; 95% confidence interval [CI]: 1.05, 1.19). These findings were consistent for children who were covered by Medicaid. At Kaiser Permanente, children who received IPV spent ~3 fewer days up to date in the first year of life, but this difference did not persist at 2 years of age. At Group Health, children who received IPV were no different from those who received OPV in terms of days spent up to date by 1 or 2 years of age. At Group Health, children who received IPV were less likely to have a missed opportunity by 12 months old (odds ratio [OR] 0.46; 95% CI: 0.31, 0.70), but this finding did not persist at 24 months of age. At Kaiser Permanente, children who received IPV were more likely to have a missed opportunity by 12 months (OR 2.06; 95% CI: 1.84, 2.30), and 24 1.50; 95% CI: 1.36, 1.67). CONCLUSIONS: The changeover from an all-OPV schedule to one containing IPV had little if any negative impact on vaccine coverage. Use of IPV was associated with a small increase in the likelihood of being up to date at 2 years of age at one of the HMOs and conversely was associated with a small increase in the likelihood of having a missed-opportunity visit in the other HMO.polio, poliomyelitis, vaccination, immunization coverage. 2001 Apr;107(4):671-6. Slow infusion for the prevention of akathisia induced by prochlorperazine: a randomized controlled trial The utility of intravenous prochlorperazine (PCZ) in the treatment of nausea, vomiting, and headache may be limited by the akathisia that occurs frequently with the recommended 2-min infusion rate. We tested the hypothesis that decreasing the rate of PCZ infusion to 15 min reduces the incidence of akathisia at 1 hour. This double-blinded, randomized, controlled trial was conducted in the Emergency Department of an academic tertiary-care medical center with an annual census of 95,000 emergency patient visits. We enrolled a convenience sample of adult patients who received 10 mg i.v. PCZ for the treatment of nausea, vomiting, or headache. Subjects were randomized to receive either a 2-min infusion of PCZ (10 mg) followed by a 15-min infusion of saline, or a 2-min infusion of saline followed by a 15-min infusion of prochlorperazine. The incidence of akathisia at 1 hour was measured by using explicit diagnostic criteria. One hundred sixty patients were randomly enrolled into two groups, which were comparable with respect to age, gender, weight, and complaint. Akathisia developed in 31 of 84 patients (36.9%) who received the 2-min infusion of PCZ and in 18 of 76 patients (23.7%) who received the 15-min infusion of PCZ (p = 0.07), a 36% (95% CI, -5% to 61%) relative reduction. The delta from pre-infusion to postinfusion scores between the two groups was not significant (p = 0.19). We conclude that slowing the rate of PCZ infusion does not decrease akathisia. an obstetric clinic-based, perinatal substance abuse intervention program Maternal substance abuse is a serious problem with significant adverse effects to mothers, fetuses, and children. The Early Start Program provides pregnant women in a managed care organization with screening and early identification of substance abuse problems, early intervention, ongoing counseling, and case management by a licensed clinical social worker located in the prenatal clinic, where she is an integral part of the prenatal team. We describe the development of the Early Start Program, its administrative history, and how it has interfaced with clinicians and administrators. We also highlight two important program characteristics: the partnership with a perinatal health services research unit and the degree to which the program could be 'exported' to other managed care settings. Authors: Armstrong MA; Health Care. 2001 Winter;9(2):6-15. Hormone replacement therapy and the risk of myocardial infarction in women with coronary risk factors To assess the risk of myocardial infarction in users of post-menopausal hormone replacement therapy who are at high risk of coronary disease because of hypertension, diabetes mellitus, or smoking, we used data from a previously published case-control study of women 45-74 years. After adjustment for age, ethnicity, and education, the odds ratio for myocardial infarction in current users of hormone replacement therapy was 0.9 (95% confidence interval (CI) = 0.5-1.6) in women with no major coronary risk factors, 0.8 (95% CI = 0.5-1.8) in women with one risk factor, and 1.1 (95% CI = 0.5-2.2) in women with two risk factors. Authors: Petitti DB; Sidney S; Quesenberry CP Jr Epidemiology. 2000 Sep;11(5):603-6. Efficacy of nurse telehealth care and peer support in augmenting treatment of depression in primary care BACKGROUND: Primary care treatment of depression needs improvement. OBJECTIVE: To evaluate the efficacy of 2 augmentations to antidepressant drug treatment. DESIGN: Randomized trial comparing usual care, telehealth care, and telehealth care plus peer support; assessments were conducted at baseline, 6 weeks, and 6 months. SETTING: Two managed care adult primary care clinics. PARTICIPANTS: A total of 302 patients starting antidepressant drug therapy. INTERVENTIONS: For telehealth care: emotional support and focused behavioral interventions in ten 6-minute calls during 4 months by primary care nurses; and for peer support: telephone and in-person supportive contacts by trained health plan members recovered from depression. MAIN OUTCOME MEASURES: For depression: the Hamilton Depression Rating Scale and the Beck Depression Inventory; and for mental and physical functioning: the SF-12 Mental and Physical Composite Scales and treatment satisfaction. RESULTS: Nurse-based telehealth patients with or without peer support more often experienced 50% improvement on the Hamilton Depression Rating Scale at 6 weeks (50% vs 37%; P =.01) and 6 months (57% vs 38%; P =.003) and on the Beck Depression Inventory at 6 months (48% vs 37%; P =. 05) and greater quantitative reduction in symptom scores on the Hamilton scale at 6 months (10.38 vs 8.12; P =.006). Telehealth care improved mental functioning at 6 weeks (47.07 vs 42.64; P =.004) and treatment satisfaction at 6 weeks (4.41 vs 4.17; P =.004) and 6 months (4.20 vs 3.94; P =.001). Adding peer support to telehealth care did not improve the primary outcomes. CONCLUSION: Nurse telehealth care improves clinical outcomes of antidepressant drug treatment and patient satisfaction and fits well within busy primary care settings. Authors: Hunkeler EM; Berman WH; Salzer M; et Aug;9(8):700-8. of pulmonary embolism and/or deep venous thrombosis in Asian-Americans Several reports from Asian countries suggest a low prevalence of pulmonary embolism (PE) and deep venous thrombosis (DVT) in Asians, and sparse US data show that a slightly higher prevalence of PE/DVT in 'nonwhites' than in whites is evident in all geographic regions except the Pacific region (California, Oregon, and Washington) where 'nonwhites' include a larger proportion of Asians and Hispanics than in other US locations. We prospectively studied PE/DVT hospitalizations in 128,934 persons in relation to traits determined at health examinations in 1978 to 1985. Through 1994, 337 persons were subsequently hospitalized for PE and/or DVT (for PE first, n = 206). Cox proportional-hazards models with 9 covariates were used. In multivariate models, the following RRs (95% confidence intervals) were found for PE/DVT combined: black/white = 1.1 (0.4 to 1.4); Hispanic/white = 0.7 (0.3 to 1.5); and Asian/white = 0.2 (0.1 to 0. 5; p = 0.002). The lower risk of Asians was present in each sex and for persons first hospitalized for either PE or DVT. Covariates with significant positive relations to risk were age, male sex, body mass index, and a composite coronary disease risk/symptom variable; covariates not significantly related were education, marital status, smoking, and alcohol. These data suggest that Asians have very low risk of PE/DVT, which may account for US geographic variations in white/non-white risk differences. Possible explanations include the absence of hazardous mutations or unspecified PE/DVT protective traits in Asians. Authors: Klatsky AL; Armstrong 1;85(11):1334-7. Neonatal assisted ventilation: predictors, frequency, and duration in a mature managed care organization OBJECTIVES: Reference data are lacking on the frequency and duration of assisted ventilation in neonates. This information is essential for determining resource needs and planning clinical trials. As mortality becomes uncommon, ventilator utilization is increasingly used as a measure for assessing therapeutic effect and quality of care in intensive care medicine. Valid comparisons require adjustments for differences in a patient's baseline risk for assisted ventilation and prolonged ventilator support. The aims of this study were to determine the frequency and length of ventilation (LOV) in preterm and term infants and to develop models for predicting the need for assisted ventilation and length of ventilator support. METHODS: We performed a retrospective, population-based cohort study of 77 576 inborn live births at 6 Northern California hospitals with level 3 intensive care nurseries in a group-model managed care organization. The gestational age-specific frequency and duration of assisted ventilation among surviving infants was determined. Multivariable regression was performed to determine predictors for assisted ventilation and LOV. RESULTS: Of 77 576 inborn live births in the study, 11 199 required admission to the neonatal intensive care unit and of these, 1928 survivors required ventilator support. The proportion of infants requiring assisted ventilation and the median LOV decreased markedly with increasing gestational age. In addition to gestational age, admission illness severity, 5-minute Apgar scores, presence of anomalies, male sex, and white race were important predictors for the need for assisted ventilation. The ability of the models to predict need for ventilation was high, and significantly better than birth weight alone with an area under the receiver operating characteristic curve of.90 versus.70 for preterm infants, and.88 versus.50 for term infants. For preterm infants, gestational age, admission illness severity, oxygenation index, anomalies, and small-for-gestational age status were significant predictors for LOV, accounting for 60% of the variance in the length of assisted ventilation. For term infants, oxygenation index and anomalies were significant predictors but only accounted for 29% of the variance. CONCLUSIONS: Considerable variation exists in the utilization of ventilator support among infants of closely related gestational age. In addition, a number of medical risk factors influence the need for, and length of, assisted ventilation. These models explain much of the variance in LOV among preterm infants but explain substantially less among term infants.neonatal intensive care, assisted ventilation, Score for Neonatal Acute Physiology, resource consumption, prematurity. Authors: and immunogenicity of heptavalent pneumococcal conjugate vaccine in children. Northern California Kaiser Permanente Vaccine Study Center Group OBJECTIVE: To determine the efficacy, safety and immunogenicity of the heptavalent CRM197 pneumococcal conjugate vaccine against invasive disease caused by vaccine serotypes and to determine the effectiveness of this vaccine against clinical episodes of otitis media. METHODS: The Wyeth Lederle Heptavalent CRM197 (PCV) was given to infants at 2, 4, 6 and 12 to 15 months of age in a double blind trial; 37,868 children were randomly assigned 1:1 to receive either the pneumococcal conjugate vaccine or meningococcus type C CRM197 conjugate. The primary study outcome was invasive disease caused by vaccine serotype. Other outcomes included overall impact on invasive disease regardless of serotype, effectiveness against clinical otitis media visits and episodes, impact against frequent and severe otitis media and ventilatory tube placement. In addition the serotype-specific efficacy against otitis media was estimated in an analysis of spontaneously draining ears. RESULTS: In the interim analysis in August, 1998, 17 of the 17 cases of invasive disease caused by vaccine serotype in fully vaccinated children and 5 of 5 of partially vaccinated cases occurred in the control group for a vaccine efficacy of 100%. Blinded case ascertainment was continued until April, 1999. As of that time 40 fully vaccinated cases of invasive disease caused by vaccine serotype had been identified, all but 1 in controls for an efficacy of 97.4% (95% confidence interval, 82.7 to 99.9%), and 52 cases, all but 3 in controls in the intent-to-treat analysis for an efficacy of 93.9% (95% confidence interval, 79.6 to 98.5%). There was no evidence of any increase of disease caused by nonvaccine serotypes. Efficacy for otitis media against visits, episodes, frequent otitis and ventilatory tube placement was 8.9, 7.0, 9.3 and 20.1% with P < 0.04 for all. In the analysis of spontaneously draining ears, serotype-specific effectiveness was 66.7%. CONCLUSION: This heptavalent pneumococcal conjugate appears to be highly effective in preventing invasive disease in young children and to have a significant impact on otitis media. Authors: Black S; Fireman B; Edwards K; et al. Pediatr Infect Dis J. 2000 Mar;19(3):187-95. The cost of health conditions in a health maintenance organization In this retrospective cohort analysis of all adults who were members of Kaiser Permanente, Northern California, between July 1995 and June 1996 (N = 2,076,303), the authors estimated the prevalence, average annual costs per person, and percentage of total direct medical expenditures attributable to each of 25 chronic and acute conditions. Ordinary least squares regression was used to adjust for age, gender, and comorbidities. The costs attributable to the 25 conditions accounted for 78 percent of the health maintenance organization's total direct medical expense for this age-group. Injury accounted for a higher proportion (11.5 percent) of expenditures than any other single condition. Three cardiovascular conditions-ischemic heart disease, hypertension, and congestive heart failure-together accounted for 17 percent of direct medical expense and separately accounted for 6.8 percent, 5.7 percent, and 4.0 percent, respectively. Renal failure ($22,636), colorectal cancer ($10,506), pneumonia ($9,499), and lung cancer ($8,612) were the most expensive conditions per person per year. Authors: Ray Res Rev. 2000 Mar;57(1):92-109. Parents' preferences for outcomes associated with childhood vaccinations BACKGROUND: The number of shots in the childhood immunization schedule has been increasing and is likely to continue to increase in the coming years. Consideration of the psychologic costs of multiple injections, adverse events and vaccine-preventable disease is therefore growing in importance. METHODS: We assessed parent preferences, using both the time tradeoff (i.e. amount of parent time willing to trade) and willingness-to-pay (i.e. dollars willing to pay) metrics, for possible outcomes of vaccination among 206 parents of infants receiving care at Kaiser, Northern California Region. We also explored the relationship between preferences and subject characteristics. RESULTS: In general the amount of time subjects were willing to give up and the quantity of money they were willing to spend to avoid an outcome increased with the severity of the outcome. Preferences for our six main outcomes of interest all differed from one another (P < 0.0001, Tukey's multiple comparisons procedure). Rank correlation coefficients between time tradeoff and willingness-to-pay values for the six main outcomes ranged from 0.42 to 0.52 (all P < 0.004). Subject characteristics, including education, income, race/ethnicity and the child's birth order, did not explain the variation in parent preferences. CONCLUSIONS: In general subjects were willing to give up more money or time to avoid less desired outcomes. They were willing to give up only very small amounts of their own life expectancy or money to avoid minor, temporary outcomes (e.g. moderate fussiness, fever and pain) whereas they were willing to forego substantial lengths of their life or amounts of money to avoid a major, permanent outcome (i.e. permanent disability). Nonetheless much variation surfaced in the amount of time (or money) subjects were willing to trade to avoid outcomes. If this variation represents true differences in preferences, guideline developers must consider the role of individual parent preferences in decisions concerning vaccination. Infect Dis J. 2000 Feb;19(2):129-33. Cost of care for patients in cancer clinical trials BACKGROUND: Information on the costs of medical care for patients enrolled in clinical trials is needed by policymakers evaluating ways to facilitate clinical research in a managed care environment. We examined the direct costs of medical care for patients enrolled in cancer clinical trials at a large health maintenance organization (HMO). METHODS: Costs for 135 patients who entered 22 cancer clinical trials (including 12 breast cancer trials) at Kaiser Permanente in Northern California, from 1994 through 1996 were compared with costs for 135 matched control subjects who were not enrolled in such trials. Cancer registry data and medical charts were used in matching the control subjects to the trial enrollees with respect to cancer site, stage, date of diagnosis, age, sex, and trial eligibility. The direct costs of medical care were compared between trial enrollees and the control subjects for a 1-year period, with data on costs and utilization of services obtained from Kaiser Permanente databases and medical charts. RESULTS: Mean 1-year costs for the enrollees in trials were 10% higher than those for the control subjects ($17 003 per enrollee compared with $15 516 per control subject; two-sided P =.011). The primary component of this difference was a $1376 difference in chemotherapy costs ($4815 per trial enrollee versus $3439 per control subject; two-sided P<.001). Costs for the 11 enrollees in trials that had a bone marrow transplant (BMT) arm were approximately double the costs for their matched control subjects (borderline significance: two-sided P=.054). The $15 041 mean cost for the enrollees in trials without BMT was similar to the $15 186 mean cost for their matched control subjects. CONCLUSIONS: Participation in cancer clinical trials at a large HMO did not result in substantial increases in the direct costs of medical care. Authors: Fireman BH; Jan 19;92(2):136-42. Sex-based differences in causes of hospitalization for coronary heart disease Authors: Klatsky A; Armstrong MA Perm J. 2000 for cancer incidence: A cohort study BACKGROUND: Because married couples share at least their home environment, spousal aggregation of cancer might provide clues to unsuspected etiologic factors. The authors sought to measure the concordance of cancer occurrence in married couples and explore factors that might explain greater-than-expected concordance. METHODS: The authors identified 25,670 cancer-free married couples in northern California who were followed for up to 31 years for the development of cancer. In Cox proportional hazards analysis, the development of cancer in a spouse was treated as a time-dependent, independent variable, and spouse-with/spouse-without risk ratios were determined, controlling for age and gender. For selected concordant espoused pairs, additional explanatory information was sought in their medical records. RESULTS: There was no excess concordance for all cancers combined; the spouse-with/spouse-without risk ratio was 0.97 (95% confidence interval, 0.90-1.05). Statistically significant husband-wife associations were found only for cancer of the tongue and stomach and for non-Hodgkin lymphoma. Except for cancer of the penis/endometrium and testis/vulva, based on one couple with each combination, gender specific cancers did not aggregate within married couples. Established and suspected risk factors, not necessarily related to the marriage, were found for some individuals who had concordance with their spouses. CONCLUSIONS: Little spousal concordance for cancer occurrence was found. The study of spousal aggregation does not appear useful in identifying unsuspected environmental causes of cancer in heterogeneous populations in urban areas of affluent Western countries. A cohort study would have to be much larger than this one to detect weak spousal concordance reliably. Authors: Friedman GD; Quesenberry 1;86(11):2413-9. Frequency of neonatal bilirubin testing and hyperbilirubinemia in a large health maintenance organization OBJECTIVE: To determine the frequency and interhospital variation of bilirubin testing and identified hyperbilirubinemia in a large health maintenance organization. DESIGN: Retrospective cohort study. SETTING: Eleven Northern California Kaiser Permanente hospitals. SUBJECTS: A total of 51,387 infants born in 1995-1996 at >/= 36 weeks' gestation and >/= 2000 g. MAIN OUTCOME MEASURE: Bilirubin tests and maximum bilirubin levels recorded in the first month after birth. RESULTS: The proportion of infants receiving >/= 1 bilirubin test varied across hospitals from 17% to 52%. The frequency of bilirubin levels >/= varied from .9% to 3.4% (mean: 2.0%), but was not associated with the frequency of bilirubin testing (R(2) = .02). Maximum bilirubin levels >/= 25 mg/dL (428 micromol/L) were identified in.15% of infants levels 30 mg/dL (513 micromol/L) in .01%. CONCLUSIONS: Significant interhospital differences exist in bilirubin and frequency of identified hyperbilirubinemia. Bilirubin levels >/=20 mg/dL were commonly identified, but levels 25 mg/dL were not. Authors: Newman Nov;104(5 Pt 2):1198-203. Rehospitalization for respiratory syncytial virus among premature infants OBJECTIVES: New interventions to prevent respiratory syncytial virus (RSV) have recently become available. Clinical decisions about the use of these interventions require a better understanding of the incidence of and risk factors for RSV. We sought to characterize the epidemiology of severe RSV disease among premature infants and to identify high-risk subgroups. DESIGN: Retrospective cohort. SETTING: Kaiser Permanente Northern California, July 1992 to April 1996. PARTICIPANTS: One thousand seven hundred twenty-one premature infants born at 23 to 36 weeks who were discharged from a neonatal intensive care nursery (NICU) within 12 months before the December to March RSV season. A secondary analysis included 769 infants discharged during the RSV season. OUTCOME MEASURES: Hospitalization for RSV. RESULTS: Of 1721 infants already home from the NICU at the start of the season, 3.2% were rehospitalized for RSV. In a multivariate model, risk factors for RSV hospitalization included gestation =32 weeks (odds ratio [OR], 2.6), >/=28 days of perinatal oxygen (OR, 3.7), and NICU discharge during September to November (OR, 2.7). Predicted risk of hospitalization varied by subgroup, ranging from 1.2% to 24.6%. Among 769 infants discharged from the NICU during the RSV season, 3.5% were rehospitalized for RSV during the same season; gestation and perinatal oxygen were not associated with admission. CONCLUSIONS: Most premature infants in this population were at less risk of severe RSV disease than previous studies in other populations have suggested. Preterm infants with a lower gestational age, a prolonged perinatal oxygen requirement, and NICU discharge within 3 months of the RSV season were most likely to require hospitalization for RSV disease. Cost-effectiveness analyses are needed to help define the role of available prophylactic interventions. Authors: Joffe S; Escobar GJ; Black Lieu Pediatrics. 1999 Oct;104(4 Pt 1):894-9. Resolving the gatekeeper conundrum: what patients value in primary care and referrals to specialists CONTEXT: Few data are available regarding how patients view the role of primary care physicians as 'gatekeepers' in managed care systems. OBJECTIVE: To determine the extent to which patients value the role of their primary care physicians as first-contact care providers and coordinators of referrals, whether patients perceive that their primary care physicians impede access to specialists, and whether problems in gaining access to specialists are associated with a reduction in patients' trust and confidence in their primary care physicians. DESIGN, SETTING, AND PATIENTS: Cross-sectional survey mailed in the fall of 1997 to 12707 adult patients who were members of managed care plans and received care from 10 large physician groups in California. The response rate among eligible patients was 71%. A total of 7718 patients (mean age, 66.7 years; 32 % female) were eligible for analysis. MAIN OUTCOME MEASURES: Questionnaire items addressed 3 main topics: (1) patient attitudes toward the first-contact and coordinating role of their primary care physicians, (2) patients' ratings of their primary care physicians (trust and confidence in and satisfaction with), and (3) patient perceptions of barriers to specialty referrals. Referral barriers were analyzed as predictors of patients' ratings of their physicians. RESULTS: Almost all patients valued the role of a primary care physician as a source of first-contact care (94%) and coordinator of referrals (89%). Depending on the specific medical problem, 75% to 91% of patients preferred to seek care initially from their primary care physicians rather than specialists. Twenty-three percent reported that their primary care physicians or medical groups interfered with their ability to see specialists. Patients who had difficulty obtaining referrals were more likely to report low trust (adjusted odds ratio [OR], 2.7; 95% confidence interval [CI], 2.1-3.5), low confidence 1.6-2.9), and low satisfaction (OR, 3.3; 95% CI, 2.6-4.2) with their primary care physicians. CONCLUSIONS: Patients value the first-contact and coordinating role of primary care physicians. However, managed care policies that emphasize primary care physicians as gatekeepers impeding access to specialists undermine patients' trust and confidence in their primary Jul 21;282(3):261-6. Rehospitalization in the first two weeks after discharge from the neonatal intensive care unit BACKGROUND: High-risk newborns are known to have higher than average utilization of services after discharge from the neonatal intensive care unit (NICU). Most studies on this subject report aggregate data over periods ranging from 1 to 3 years postdischarge. Little is known about events that are temporally close to NICU discharge. OBJECTIVES: To characterize rehospitalizations within the first 2 weeks after discharge from six community NICUs. METHODS: We scanned electronic databases and reviewed the charts of rehospitalized infants from six NICUs in the Kaiser Permanente Medical Care Program. We subdivided infants into five groups based on gestational age (GA) and birth hospitalization length of stay (LOS): 1) >/=37 weeks' GA with <4 days LOS 2593); 2) >/=37 weeks' GA with >/=4 days' LOS (n = 1133); 3) from 33 to 36 weeks' GA with <4 days' LOS (n = 545); 4) from 33 to 36 weeks' GA with >/=4 days' LOS (n = 1196); and 5) <33 weeks' GA (n = 587). We performed bivariate and multivariate analyses to identify predictors that might be useful for practitioners. RESULTS: There were 6054 newborns discharged alive from the six study NICUs between August 1, 1992 and December 31, 1995, and 99.5% of these infants remained in the health plan during the 2 weeks after NICU discharge. The overall rehospitalization rate was 2.72%, which is 20% higher than the rate among healthy term newborns in the Kaiser Permanente Medical Care Program (2.26%). The two most common reasons for rehospitalization were jaundice (62/165, 37.6%) and feeding difficulties (25/165, 15.2%). with 33 to 36 weeks' GA and <4 days' LOS were rehospitalized at a significantly higher rate than were all other infants (5.69%); 71% of infants in this group were rehospitalized for jaundice. The following variables predicted rehospitalization in (AOR: 2.94; 95% CI: 1.87-4.62), and birth at facility B, which had the highest rehospitalization rate of the six facilities (AOR: 1.92; CONCLUSIONS: The rate of rehospitalization among NICU graduates is higher than among healthy term infants. Most of the rehospitalizations among infants with from 33 to 36 weeks' GA and <4 days' LOS are for illnesses that are not life-threatening. Collaborative studies and new process and outcomes measures are needed to assess the effectiveness of follow-up strategies in high-risk newborns. Authors: Carpenter DM Pediatrics. 1999 Jul;104(1):e2. Quality of primary care practice in a large HMO according to physician specialty OBJECTIVE: To determine whether physician specialty was associated with differences in the quality of primary care practice and patient satisfaction in a large, group model HMO. DATA SOURCES/STUDY SETTING: 10,608 patients ages 35-85 years, selected using stratified probability sampling from the primary care panels of 60 family physicians (FPs), 245 general internists (GIMs), and 55 subspecialty internists (SIMs) at 13 facilities in the Kaiser Permanente Medical Care Program of Northern California. Patients were surveyed in 1995. STUDY DESIGN: A cross-sectional patient survey measured patient reports of physician performance on primary care measures of coordination, comprehensiveness, and accessibility of care, preventive care procedures, and health promotion. Additional items measured patient satisfaction and health values and beliefs. PRINCIPAL FINDINGS: Patients were remarkably similar across physician specialty groups in their health values and beliefs, ratings of the quality of primary care, and satisfaction. Patients rated GIMs higher than FPs on coordination (adjusted mean scores 68.0 and 58.4 respectively, p<.001) and slightly higher on accessibility and prevention; GIMs were rated more highly than SIMs on comprehensiveness (adjusted mean scores 76.4 and 73.8, p<.01). There were no significant differences between specialty groups on a variety of measures of patient satisfaction. CONCLUSIONS: Few differences in the quality of primary care were observed by physician specialty in the setting of a large, well-established group model HMO. These similarities may result from the direct influence of practice setting on physician behavior and organization of care or, indirectly, through the types of physicians attracted to a well-established group model HMO. In some settings, practice organization may have more influence than physician specialty on the delivery of primary Computer-based models to identify high-risk adults with asthma: is the glass half empty of half full? This study developed and evaluated the performance of prediction models for asthma-related adverse outcomes based on the computerized hospital, clinic, and pharmacy utilization databases of a large health maintenance organization. Prediction models identified patients at three- to four-fold increased risk of hospitalization and emergency department visits, and were valid for test samples from the same population. A model that identified 19% of patients as high risk had a sensitivity of 49%, a specificity of 84%, and a positive predictive value of 19%. We conclude that prediction models that are based on computerized utilization data can identify adults with asthma at elevated risk, but may have limited sensitivity and specificity in actual populations. Authors: Lieu TA; Capra AM; colonic neoplasia with screening sigmoidoscopy CONTEXT: Indications are not well defined for follow-up colonoscopy for all patients with distal colonic tubular adenomas (TAs) found at screening sigmoidoscopy. whether distal adenoma size, number, and villous histology, along with family age, are predictors of advanced proximal colonic neoplasia. DESIGN: Cross-sectional analysis conducted between January 1, 1994, and December 31, 1995. SETTING: Large group-model health maintenance organization in northern California. PATIENTS: A total of 2972 asymptomatic subjects aged 50 years or older undergoing colonoscopy as follow-up to a screening sigmoidoscopy. MAIN OUTCOME MEASURE: Based on sigmoidoscopy, colonoscopy, and pathology reports, occurrence of advanced proximal neoplasia, defined as adenocarcinoma or TAs 1 cm or larger or with villous features or severe dysplasia located beyond sigmoidoscopic view. RESULTS: The prevalence of advanced proximal neoplasia was similar among patients with no TAs at sigmoidoscopy, those with TAs less than 1 cm in diameter, and those with TAs 1 cm in diameter or larger (prevalence, 5.3%, 5.5%, and 5.6%, respectively). Of patients with 12.1% tubulovillous adenoma adenoma was the proximal neoplasia (odds ratio, 2.30; 95% confidence interval, 1.69-3.14). Age of 65 years or older, having more than 1 adenoma, and a positive family history of colorectal cancer were also significant predictors. Distal adenoma size was not a significant predictor in any multivariate analyses. CONCLUSIONS: Advanced proximal neoplasia is not uncommon in subjects with or without distal TAs, but subjects with advanced distal histology and those older than 65 years are at increased risk. Age-specific screening using sigmoidoscopy starting at ages 50 to 55 years and colonoscopy after age 65 years may be justified. activity patterns in a diverse population of women BACKGROUND: Demographic and psychosocial correlates of activity in domains other than recreational activity have not been well characterized and may be particularly relevant for health promotion efforts aimed at women. METHODS: Cross-sectional relationships between recreational, occupational, and household/caregiving physical activity and demographic and psychosocial factors were assessed with a mail survey in a random sample of 2,636 ethnically diverse women members of a large health maintenance organization, ages 20-65. Activity was assessed with a modified Baecke questionnaire that uses categorical responses regarding frequency of domain-specific activities to create four semicontinuous activity indices (sports/exercise, active living, occupational, household/caregiving). RESULTS: Multivariable logistic regression analysis showed that the likelihood of being in the highest quartile of the sports/exercise and active-living indices, compared with the other three quartiles, was decreased among older, nonwhite, less well educated, heavier women who had young children at home, lacked motivation to exercise, and perceived external obstacles to exercise behavior. The odds ratios (ORs) ranged from 0.38, 95% confidence interval (CI) 0.33-0.45, associated with low motivation, to 0.95, 95% CI 0.93-0.98, associated with increasing body mass index. Social support and confidence in one's ability to continue to exercise, even when faced with other pressures and demands (termed self-efficacy), were associated with increased likelihood of high levels of sports/exercise and active living (OR = 2.34, 95% CI 1. 83-2.98 and OR = 3.96, 95% CI 2.92-5.38, respectively). In contrast, the highest quartile of household/caregiving activity was positively associated with increasing age (OR = 1.28, 95% CI 1.16-1.42), Hispanic ethnicity (OR = 1.58, 95% CI 0.55-1.01), being married (OR = 1.70, 95% CI 1.33-2.18), having young children at home (OR = 6.99, 95% CI 4.33-11), and greater time constraints as a barrier to exercise (OR = 1.55, 95% CI 1.38-1.74) and was negatively associated with employment (OR = 0.38, 95% CI 0.30-0.47). Increased likelihood of the highest quartile of occupational activity was associated with high school education or less (OR = 2.26, 95% CI 1.74-2.94) and current smoking (OR = 1.66, 95% CI 1.23-2.23), while self-efficacy regarding exercise was associated with decreased likelihood (OR = 0. 77, 95% CI 0.61-0.96). CONCLUSIONS: These findings suggest that demographic and psychosocial correlates of physical activity vary by domain and that initiatives to promote physical activity in the population need to take these differences into account. Authors: and menopausal symptoms: a case-control study A case-control study design was used to examine whether habitual physical activity prior to the final menstrual period (FMP) was associated with reduced risk of vasomotor and other symptoms during the perimenopausal period. Both cases and controls were identified through a screening interview with randomly selected women members, ages 48-52, of a large health maintenance organization. Cases (n = 82) were defined as women 3-12 months past their FMP who reported regularly having hot flashes or night sweats at least once a day or night during the 3 months following their FMP. Controls (n = 89) were of the same biologic age with respect to the FMP but reported vasomotor symptoms less than once a week during the reference time period. Neither cases nor controls had a history of hormone replacement therapy (HRT), hysterectomy, or bilateral oophorectomy. Case-control status, habitual physical activity (including recreational, housework, child care, and occupational activity), and psychological and somatic symptoms were assessed by self-report. Participation in vigorous recreational activity during the year prior to the FMP was not associated with reduced risk of frequent vasomotor symptoms after the FMP (odds ratio [OR] = 1.03 for a 50-unit increase in activity score, 95% confidence interval [CI] = 0.97-1.1). This lack of relationship was observed in all domains of activity. Factors that were associated with decreased risk included higher body mass index (BMI) (weight in kg/(height in meters)2) (OR = 0.95 per 1 unit increase in BMI, 95% CI = 0.90-1.00) and higher education (having a college degree relative to less education) (OR = 0.56, 95% CI = 0.40-0.80). Physical activity was also unassociated with reduced risk of psychologic distress, depressive feelings, or somatic symptoms, but, relative to controls, having vasomotor symptoms (being a case) was strongly associated with increased risk of experiencing those symptoms (OR ranging from 1.83 for psychologic distress to 2.84 for depressive feelings). These findings suggest that regular physical activity before the FMP may not reduce the likelihood of experiencing symptoms during the perimenopause, although the small sample size may limit the inferences that can be drawn. Authors: Sternfeld B; 1999 Jan-Feb;8(1):115-23. Alcohol consumption and utilization of health services in a health maintenance organization OBJECTIVES: This study examined the relation between alcohol use and utilization of health services during a 3-year period in a sample of 4,264 adult respondents to a member health survey in a health maintenance organization. METHODS: Respondents were categorized as abstainers (no drinks in the past year, n = 1,139), lighter drinkers (less than seven drinks/week, n = 2,330), moderate drinkers (seven to 13 drinks/week, n = 498), and heavier drinkers (> or =14 drinks/week, n = 297). Each drinker group was compared with abstainers on outpatient visits, hospital days, and number of hospitalizations controlling for age, race, and health plan membership. RESULTS: The mean number of outpatient visits was inversely related to the amount of alcohol consumed. Significant differences also were found for mean number of hospitalizations and mean days hospitalized per year. Compared with the three drinker groups, abstainers were significantly higher on both inpatient measures. CONCLUSIONS: These results might be explained by the inclusion in the abstainer group of exdrinkers who quit because of illness, inattention to health problems by heavier drinkers, or lower rates of illness among drinkers. The findings underscore the importance of replicating our study in other cohorts in which problem drinkers can be identified and compared with non-problem drinkers and in which lifelong abstainers can be separated from exdrinkers in the analysis. Authors: Armstrong MA; Midanik LT; Klatsky AL Med Care. 1998 Nov;36(11):1599-605. Structured review of neonatal deaths in a managed care organisation We sought to quantify neonatal mortality (< 28 days) in a 10-hospital system, determine what proportion was associated with suboptimal neonatal care and make recommendations on how neonatal mortality rates (NMRs) could be used in quality improvement efforts. Deaths were identified using electronic linkage to the State of California Death Certificate Tapes. Individual fatalities were reviewed by a minimum of two physicians who did not care for the infant. Deaths were classified as either being associated with suboptimal care or not. For deaths where suboptimal care was an issue, emphasis was on delineating the process involved in the death. Subjects were all neonatal deaths among 64,469 babies born in 1990-91 in the 10 birth facilities of the Kaiser Permanente Medical Care Program, Northern California Region. A total of 241 neonatal deaths were identified. Adjusting for prematurity by increasing the follow-up period in preterm babies (included as neonatal deaths if they died up to 40 weeks corrected gestational age + 27.9 days) increased overall mortality rates by 5%. Birthweight-specific NMRs in Kaiser Permanente are similar to those of other published reports. Among the 198 deaths in babies weighing > or = 500 g at birth, only 14 (7%) were possibly associated with suboptimal care. In populations with access to health insurance, reporting only aggregate NMRs is of limited use. The number of deaths that could be ascribed to suboptimal neonatal care is very small and measuring variations in rates of such deaths is difficult. Future measurements of quality of care will require more sophisticated measures, database systems, review strategies and dissemination methods. Authors: Escobar streptococcal infection in a managed care population. Perinatal Group B Streptococcal Infection Study Group OBJECTIVE: In a health maintenance organization population, we determined the incidence of early-onset (at less than or equal to 7 days) neonatal group B streptococcal (GBS) disease, the sensitivity and prevalence of labor risk factors, the adherence to a protocol for intrapartum antibiotics, and the costs for care of and outcomes of affected infants. METHODS: Mothers and infants at four health maintenance organization hospitals in northern California in 1989 to 1995 were studied retrospectively using computerized databases and chart review. In 1994, two of the four hospitals had adopted protocols similar to the ACOG recommendations for intrapartum antibiotics for women with labor risk factors (preterm, temperature 100.4F or higher, or rupture of membranes (ROM) 18 hours or more). RESULTS: Among the 79,940 live births, the incidence of early-onset neonatal GBS infection was higher among preterm than among term infants (3.1 compared with 0.9 per 1000). Before protocol adoption, 68% of 65 infants with GBS had mothers with labor risk factors. Approximately 18% of all mothers had labor risk factors: 7.7% had preterm delivery, and 10.6% had term delivery with fever and/or ROM 18 hours or more. At the two hospitals that adopted GBS protocols, GBS incidence was reduced from 1.3 per 1000 in the preprotocol period to 0.8 per 1000 in the postprotocol period (P=.08). Six cases of neonatal GBS occurred after protocol adoption. Of these, four were not preventable under the protocol and two might have been preventable if protocol had been followed. Three of the 19 preterm infants with group B streptococcal disease died. CONCLUSION: Risk factor-based protocols hold some promise to reduce GBS disease, but clinical strategies to promote protocol adherence are needed. Authors: Lieu TA; Jul;92(1):21-7. Computer-based models to identify high-risk children with asthma Effective management of populations with asthma requires methods for identifying patients at high risk for adverse outcomes. The aim of this study was to develop and validate prediction models that used computerized utilization data from a large health-maintenance organization (HMO) to predict asthma-related hospitalization and emergency department (ED) visits. In this retrospective cohort design with split-sample validation, variables from the baseline year were used to predict asthma-related adverse outcomes during the follow-up year for 16,520 children with asthma-related utilization. In proportional-hazard models, having filled an oral steroid prescription (relative risk [RR]: 1.9; 95% confidence interval [CI]: 1.3 to 2.8) or having been hospitalized (RR: 1.7; 95% CI: 1.1 to 2.7) during the prior 6 mo, and not having a personal physician listed on the computer (RR: 1.6; 95% CI: 1.1 to 2.3) were associated with increased risk of future hospitalization. Classification trees identified previous hospitalization and ED visits, six or more beta-agonist inhalers (units) during the prior 6 mo, and three or more physicians prescribing asthma medications during the prior 6 mo as predictors. The classification trees performed similarly to proportional-hazards models, and identified patients who had a threefold greater risk of hospitalization and a twofold greater risk of ED visits than the average patient. We conclude that computer-based prediction models can identify children at high risk for adverse asthma outcomes, and may be useful in population-based efforts to improve asthma Care Med. 1998 Apr;157(4 Pt 1):1173-80. Obesity, health services use, and health care costs among members of a health maintenance organization BACKGROUND: Obesity is an independent risk factor for a variety of chronic diseases and is therefore a potential source of avoidable excess health care expenditures. Previous studies of obesity and health care costs have used group level data, applying estimates of population-attributable risks to estimates of US total costs of care for each obesity-related disease. OBJECTIVE: To quantify the association between body mass index (BMI) and health services use and costs stratified by age and use source at the patient level, a level of detail not previously reported. METHODS: In 17,118 respondents to a 1993 health survey of members of a large health maintenance organization, we ascertained through computerized databases all hospitalizations, laboratory services, outpatient visits, outpatient pharmacy and radiology services, and the direct costs of providing these services during 1993. RESULTS: There was an association between BMI and annual rates of inpatient days, number and costs of outpatient visits, costs of outpatient pharmacy and laboratory services, and total costs (P < or = .003). Relative to BMI of 20 to 24.9, mean annual total costs were 25% greater among those with BMI of 30 to 34.9 (rate ratio, 1.25; 95% confidence interval, 1.10-1.41), and 44% greater among those with BMI of 35 or greater (rate ratio, 1.44; 95% confidence interval, 1.22-1.71). The association between BMI and coronary heart disease, hypertension, and diabetes largely explained these elevated costs. CONCLUSION: Given the high prevalence of obesity and the associated elevated rates of health services use and costs, there is a significant potential for a reduction in health care expenditures through obesity prevention efforts. Authors: Quesenberry CP Jr; Caan B; Jacobson A Arch Intern Med. 1998 Mar 9;158(5):466-72. Cataract extraction. Risk factors in a health maintenance organization population under 60 years of age Risk factors for cataract extraction in a young (less than 60 years of age) urban health maintenance organization population were evaluated in a case-control study. The subjects (72 case-control pairs) subscribed to the Kaiser Permanente Medical Care Program in the San Francisco Bay area and had cataract extraction between 1976 and 1980. All patients had visual acuity of at least 20/40 OU, documented before development of cataracts. Thirty-six (50%) of the 72 cataract extraction patients had at least one known risk factor for cataract formation, including trauma, intraocular inflammation, diabetes mellitus, syphilis, oral or topical steroid use, or previous eye surgery. Male patients were found to be a mean of 4.3 years younger than female patients, and diabetics were found to be a mean of 3.5 years older than nondiabetics. Variables found to be related to cataract extraction in univariate analysis included diagnosis of diabetes mellitus, a family history of cataracts, pulse rate, white blood cell count, and syphilis. Authors: Schwab IR; Armstrong MA; Arch Ophthalmol. 1988 Aug;106(8):1062-5. Precursors of essential hypertension: body weight, alcohol and salt use, and parental history of hypertension Body mass index, alcohol and salt consumption, and parental history of hypertension were examined as possible predictors of the development of essential hypertension in 1,031 persons, ages 30-49 years at entry, with documented normotension followed by documented hypertension after a mean interval of 6 years. In a comparison with 1,031 matched persistently normotensive persons initial body mass index and percentage increase in body mass index were each predictive of hypertension. Consumption of three or more alcoholic drinks a day at baseline was also predictive, more so if this level of intake persisted than if it diminished. Heavy salt intake as crudely estimated at baseline by one question was also associated with the development of hypertension. Parental history of hypertension was also predictive, more so for hypertension in the mother than for hypertension in the father, and the association was apparent only in female subjects. These characteristics at baseline showed independent associations with subsequent hypertension in multivariate analysis. When follow-up data were included in the multivariate analysis, alcohol consumption at the hypertensive examination was much more strongly related than at the baseline examination, suggesting a short-term effect, and heavy salt consumption was no longer predictive, possibly because of a marked loss of subjects due to missing follow-up data. This large study confirms longitudinally the importance of obesity, weight gain during adulthood, alcohol, family history, and, to some extent, salt as predictive and possibly causal factors for essential hypertension. Authors: Cholecystectomy and large bowel cancer The records of 5898 patients with colorectal cancer and 27,687 controls were examined for previous cholecystectomy. The estimated relative risks (and 95% confidence intervals) of development of any cancer of the large bowel and cancer of the right colon after cholecystectomy were 1.0 (0.8-1.2) and 1.1 (0.8-1.5) in women and 1.1 (0.9-1.5) and 1.2 (0.8-1.9) in men, respectively. Although these data do not rule out a small increase in risk, it is proposed that the association found in some other studies is, at least in part, an artifact. Intense diagnostic effort and treatment aimed at mild abdominal symptoms, encouraged by some patients and some medical care settings, could increase the detection and removal of gallstones and the early detection of colorectal cancer. Authors: Friedman retinol and retinol-binding protein levels do not predict subsequent lung cancer Retinol and retinol-binding protein levels were measured in sera previously obtained, and stored in the frozen state, at multiphasic health checkups from 151 persons subsequently found to have lung cancer (cases) and 302 persons who remained free of cancer (controls). Two controls were matched to each case for sex, skin color, age, date of multiphasic health checkup, and aspects of the smoking habit. Mean levels in cases and controls were, respectively, retinol: 82.17 and 82.37 micrograms/dl and 6.00 mg/dl (p = 0.81). Mean differences between cases and controls were, retinol: 0.195 and 0.24 mg/dl. No significant trend in relative risk of lung cancer was observed when the retinol or retinol-binding protein distribution was divided into quintiles. No significant associations were observed in subgroups based on age, sex, histologic type of cancer, cigarette consumption, or interval between blood drawing and cancer diagnosis. In this large study, retinol and retinol-binding protein levels were not useful in predicting the subsequent development of lung cancer. Authors: Evaluation: a 16-year follow-up The Multiphasic Health Checkup Evaluation Study, a long-term clinical trial, has been completed. A study group of 5156 men and women age 35-54 at entry was urged to have annual multiphasic health checkups (MHCs) for 16 years. A control group of 5557 comparable subjects was not so urged but was followed up in a comparable fashion. The mean and median number of MHCs per person were 6.8 and 6, respectively, in the study group and 2.8 and 1, respectively, in the control group. During 16 years the study group experienced a 30% reduction (p less than 0.05) in deaths from pre-specified 'potentially postponable' causes, largely associated with lower death rates from colorectal cancer and hypertension. This reduction was most pronounced in the early years of the study. The two groups did not differ to a statistically significant degree in mortality from all other causes (84% of total mortality) or in total mortality. There was no difference in self-reported disability in the overall groups. In the setting of our prepaid health care plan where MHCs were already available on a voluntary basis, a program of urging middle-aged persons to undergo regular MHCs brought about a substantial reduction in mortality from preselected diseases. Authors: Friedman GD; Collen MF; Fireman BH J Chronic Dis. 1986;39(6):453-63. Psychological questionnaire score, cigarette smoking, and myocardial infarction: a continuing enigma The ability of a group of 94 psychological questions to discriminate between men in whom cigarette smoking was associated with increased risk of myocardial infarction and men in whom smoking was not so associated remains puzzling. Further analyses, controlling for reported alcohol consumption and for a questionnaire item that might reflect physical activity, failed to alter this finding. This interaction of the questionnaire responses with smoking was not found with two other major coronary risk factors, serum cholesterol and systolic blood pressure. Believing that these observations may provide (a) a clue to how cigarette smoking affects risk of myocardial infarction, or (b) some means of identifying greater or lesser susceptibility to the effects of smoking, we invite other investigators to join in the pursuit of this matter. A list of ten selected yes-or-no questions with strong interaction with smoking is provided to assist others in studying this phenomenon; these are similar to ten items on the Minnesota Multiphasic Personality Inventory. Authors: "}