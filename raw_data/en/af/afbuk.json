{"title": "PDF", "author": "PDF", "url": "https://imsarchives.nus.edu.sg/oldwww/Programs/011wnlinear/files/howell.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "Feature Matching in Time Series Modelling Yingcun Xia1and Howell Tong2 1Department of Statistics and Applied Probability National University of Singapore, Singapore 2Department of Statistics, London School of Economics, UK. October 27, 2010 Abstract : Using a time series model to mimic an observed time series has a long history. However, with regard to this objective, conventional estimation methods for discrete-time dynamical models are frequently found to be wanting. In fact, they are characteristically misguided in at least two respects: (i) assuming that there is a true model; (ii) evaluating the ecacy of the estimation as if the postulated model is true. There are numerous examples of models, when tted by conventional methods, that fail to capture some of the most basic global features of the data, such as cycles with good matching periods, singularities of spectral density functions (especially at the origin) and others. We argue that the shortcomings need not always be due to the model formulation but the inadequacy of the conventional tting methods. After all, all models are wrong, but some are useful if they are tted properly . The practical issue becomes one of how to best t the model to data. Thus, in the absence of a true model, we prefer an alternative approach to conventional model tting that typically involves one-step-ahead prediction errors. Our primary aim is to match the joint probability distribution of the observable time series, including long-term features of the dynamics that under- pin the data, such as cycles, long memory and others, rather than short-term prediction. For want of a better name, we call this specic aim feature matching . The challenges of model mis-specication, measurement errors and the scarcity 1of data are forever present in real time series modelling. In this paper, by syn- thesizing earlier attempts into an extended-likelihood, we develop a systematic approach to empirical time series analysis to address these challenges and to aim at achieving better feature matching. Rigorous proofs are included but relegated to the Appendix. Numerical results, based on both simulations and real data, suggest that the proposed catch-all approach has several advantages over the conventional methods, especially when the time series is short or with strong cyclical fluctuations. We conclude with listing directions that require further 1 Introduction Dynamical models, either in continuous time or in discrete time, have been widely used to describe the changing world. Interestingly, salient features of many seemingly complex observations can sometimes be captured by simple dynamical models, as demonstrated most eloquently by Sir Isaac Newton in the seventeenth century when he used his model, Newton's law of universal gravitation, to explain Kepler's observations concerning planetary motion. In statistics, dynamical models are the raison d'^ etre of time series analysis. For a time series, the dynamics transmits information about its future from observations made in the past and the present. Of particular interest are the long-term future, the periodicity and so on. To capture salient features, there are essentially two approaches: either substantive or black-box. Examples of both approaches abound. The former is often preferred if available in the context in which we nd ourselves. If not available, then a black-box approach might be the only choice. We shall include examples of both approaches. Let us rst mention two 2substantive examples as they are relevant to our later discussion. 1.1 Two substantive models and related features 1. Animal populations . There are numerous ecological models describing the time evolution of animal population. The single-species model of Oster and Ipaktchi (1978) can be written as dxt dt=b(xt)xt\u00b5xt, (1.1) where xtis the number of adults at time t,is the delayed regulation duration due to the time taken for the young to develop into adults or discrete breeding seasons; b(\u00b7) is the birth rate; and \u00b5is the death rate. There are dierent specications for b(.). Gurney et al. (1980) suggested b(u) =cexp(u/N 0), where N0is the reciprocal of the exponential decay rate and cis a parameter related to the reproducing rate of adults. Ellner et al. (2002) investigated the estimation of model ( 1.1) by replacing b(xt)xtand\u00b5xtwith unknown functions B(xt) and D(xt) respectively, which they then used a nonparametric method to estimate. Wood (2001) considered a similar approach. There are several discrete-time versions of ( 1.1) in biology. See, for example, Varley et al. (1973). If we approximate dxt/dt byxtxt1, then we obtain a nonlinear time series model in discrete time xt=b(xt)xtxt, (1.2) where =\u00b51. In ecology, population cycles are often observed and are an issue of paramount impor- tance. For example, the blowfly data shows a cycle of 39 days and the Canadian lynx shows a cycle of about 9.7 years. Some ecologists have even suggested chaotic patterns although we are skeptical about this possibility. Most ecologists consider the dynamics underlying population cycles as one of the major challenges in their discipline. 2. Transmission of infectious diseases . The conventional compartmental SIR model partitions a community with population Ninto three compartments St(for susceptible), It(for infectious) and Rt(for recovered): N=St+It+Rtat any time instant t. The SIR model is simple but very useful in investigating many infectious diseases including measles, mumps, rubella and SARS. Each member of the population typically progresses from susceptible to infectious to recovered or death. 3Infectious diseases tend to occur in cycles of outbreaks due to the variation in the number of susceptible individuals over time. During an epidemic, the number of susceptible individuals falls rapidly as more of them are infected and thus enter the infectious and recovered compartments. The disease cannot break out again until the number of susceptible has built back up as a result of babies being born into the susceptible compartment. Consider a population characterized by a death rate \u00b5and a birth rate equal to the death rate, in which an infectious disease is spreading. The dierential equations of the SIR model are dSt dt=\u00b5(NSt)It NSt,dIt dt=It NSt(+\u00b5)It,dRt dt=It\u00b5Rt, where is the contact rate, is the recovery rate of the disease. See, e.g., Anderson and May (1991) and Isham and Medley (2008) for details. This model has been extensively investigated and very successfully used in the control of infectious diseases. Discrete time versions of the model have been proposed. An example is It+1=r0StIt/N, S t+1=StIt+1+\u00b5N, where \u00b5is the birth rate and r0is the basic reproductive rate of transmission. See, e.g., Bartlett (1957, 1960), Anderson and May (1991) and the discussion in section 6. Again, an important feature for the transmission of infectious disease is the periodicity, to understand which it is essential to understand the eect of such factors as the birth rate, the seasonal force, the transmission rate and the incubation time on the dynamics, the phase dierence that is related to the transmission in dierent areas, and the interaction between dierent diseases; see for example Earn et al. (2000) and Rohani et al. (2003). The model can also be used to guide the policy maker in controlling the spread of the disease. See, for example, Bartlett (1957), Hethcote (1976), Keeling and Grenfell (1997) and Dye and Gay (2003). 1.2 The objectives Our primary concern is parametric time series modelling with the objective of achieving good matching of the joint probabilistic distribution of the observable time series, including, in particular, salient features, such as cycles and others. Short-term prediction is secondary in this paper. Accepting G. E. P. Box's dictum: All models are wrong, but some are useful 4(1976), we use parametric time series models only as means to an end. We are typically less interested in the consistency of estimators of unknown parameters in the conventional sense, which is predicated on the assumed truth of the postulated model. In fact, we are more interested in improving the matching capability of the postulated model. Suppose we postulate the following model xt=g(xt1, ..., x tp) +t, (1.3) where tis the innovation and the function g(.) is known up to parameters . To indicate the dependence of xton, we also write it as xt(). Following Tong (1990), we call ( 1.3) with Var(t) = 0 the skeleton of the model. In postulating the above model, we recognize that it is generally just an approximation of the true underlying dynamics no matter how the function g(.) is specied. Of particular note is the fact that conventional methods of estimation of in the present setup are usually not dierent from those used for a cross- sectional model: with observations {y1, y2,\u00b7\u00b7\u00b7, yT}and postulated model g, typically a loss function is based on the errors and takes the following form L() = ( Tp)1T t=p+1{ytg(yt1, ..., y tp)}2, where, here and elsewhere, Tdenotes the sample size. The errors above happen to coincide with the one-step-ahead prediction errors. Under general conditions, minimizing this loss function is known mathematically to lead to ecient estimation if the postulated model is true . However, the postulated model is, by the Box dictum, almost invariably wrong, in which case the above loss function is not necessarily t for purpose. To illustrate, let observations {y1, y2, ..., y T}be given and, of the postulated model ( 1.3), let the function gbe linear and tbe Gaussian with zero mean Let T={C(j), 0,1,2, ..., T 1}denote a set of sample autocovariances of the y-data. Then minimizing L() yields well-known estimates of that are functions of S={C(0), C(1), ..., C (p)}.If the postulated model is 'right', then Sis a minimal set of sucient statistics (ignoring boundary eects) and all is well. However, if it is wrong, then it is unlikely that Swill remain so. Since the model is typically wrong, then restricting to Sis unt for the purpose of estimating ;Tmay be preferable. To reconcile with the Box spirit, diagnostic checks, goodness of t tests and other post- modelling devices are recommended. Indeed Box and Jenkins (1970) has stressed these 5post-modelling devices. See also Tsay (1992) for some later developments. These are undoubtedly very important developments. However, the challenge remains as to whether we can adopt the Box spirit more seriously right at the modelling stage rather than at the post-modelling stage. It is worth recalling the fact that the classic autoregressive (AR) model of Yule (1927) and the moving average (MA) model of Slutsky (1927) were originally proposed to capture the sunspot cycle and the business cycle respectively, rather than for the purpose of short term prediction. 2 The matching approach We shall use the letters yandxto signify respectively the real time series under study and the time series generated by the postulated model. The adjective observable is reserved for a stochastic process. An observed time series consisting of observations constitutes (possibly part of) a realization of a stochastic process. In order for model ( 1.3) to be able to approximate an observable {yt:t= 1,2, ...}well, it is natural to require throughout this paper that the state space of {xt() :t= 1,2, ...}covers that of the observable {yt:t= 1,2, expositional simplicity, let p= 1. Starting from x0() =y0, the postulated model is said to match an observable time series under study perfectly if their conditional distributions are the same, namely P{x1(0)< u 1, ..., x n(0)< u 1, ..., n< n|y0} (2.4) almost surely for some 0and any nand any real values u1, ..., u n. We call the approach based on the above mode, including its weaker versions, collectively by the name catch-all approach . However, formulation ( 2.4) is usually quite dicult to implement in practice. In the next two sub-sections, we suggest two weaker forms, although other forms are obviously possible. In the econometric literature, the notion of calibration has been introduced (e.g., Kyd- land and Prescott, 1996). It has many alternative denitions. Broadly speaking, calibration consists of a series of steps intended to provide quantitative answers to a particular eco- nomic question. A crucial step involves some so-called 'computational experiments' with a substantive model of relevance to economic theory; it is acknowledged that the model is 6unlikely to be the true model for the observed economic data. At the philosophical level, calibration and our feature matching share almost the same aim. However, there are some fundamental dierences in methodology. Our methodology provides a statistical and co- herent framework (in a non-Bayesian sense) to estimate allthe parameters of a postulated (and usually wrong) model. As far as we know, calibration seems to be in need of such a framework. See, e.g., Canova (2007, esp. p. 239). The hope is that our methodology will be useful to substantive modellers in all elds, including ecology, economics, epidemiology and others. At the other end of the scale, it has been suggested that our methodology has potential in data mining. (K.S. Chan, private communication.) 2.1 Matching up-to- m-step-ahead point predictions If we are interested in the mean conditional on some initial observation say y0, we can weaken the matching requirement ( mof the random vector is, in practice, bounded above by the sample size under consideration. The expectation is taken with respect to the relevant joint distribution of the random vector conditional on the initial value being y0.Since a postulated model is just an approximation of the underlying dynamics, we set 0to minimize the dierence of the prediction Euclidean norm of a vector. In other words, we choose by minimizing up-to- m-step-ahead prediction errors. It is basically based on a catch-all idea. It is easy to see that the best based on minimizing ( 2.5) depends on m. Generally speaking, we setm= 1,when and only when we have complete faith in the model, which is what the conventional methods do. Denote the m-step-ahead prediction of yt+mbased on model ( 1.3) by g[m] (yt) =E(xt+m|xt=yt). If model ( 1.3) is deterministic (i.e. Var(t) = 0) or linear, g[m] (yt) is model of xt, then min Q(yt, xt()) = 0. Otherwise we generally expect min Q(yt, xt())>0. Minimizing Q(yt, xt()) is for xt() to arrive at a choice within the postulated model that gives all (suitably weighted) multiple-step-ahead predictions of ytas accurately as possible in the mean-square sense. Note that the above measure of the dierence between two time series is based on a (weighted) least squares loss function. If the distribution of the innovation is known, a likelihood type measure of the dierence can be used instead. A Bayesian may perhaps then endow {wm}with some prior distribution. This line of development may be worth further exploration as suggested by an anonymous referee. Intuitively speaking, a Jshaped {wm} tends to emphasis low-pass ltering, because E(yt+m|yt) is a slowly varying function for suciently large m. Similarly, an inverted- Jshaped ltering. between high-pass ltering and low-pass ltering. The most commonly used estimation method in time series modelling is probably that based on minimizing the sum of squares of the errors of one-step-ahead prediction. This has been extended to the sum of squares of errors of other single-step-ahead prediction. See, for example, Cox (1961), Tiao and Xu (1993), Bhansali and Kokoszka (2002) and Chen et al.(2004). Clearly, the former method is predicated on the model being true. The latter extension recognizes that this is an unrealistic assumption for multi-step-ahead prediction. Instead, a panel of models is constructed so that a dierent model is used for the prediction at each dierent horizon. The focus of the extension is prediction. 8The approach that we develop here essentially builds on the above extension. First, we shift the focus away from prediction. Second, we transform the prediction based on a panel of models into the tting of a single time series model . We eectively synthesize the panel into a catch-all methodology. Specically, we propose to minimize the sum of squares of errors of prediction over all (allowable) steps ahead , as given in equation ( 2.6). We stress again that our primary objective is feature matching rather than prediction. Of course, it is conceivable that good feature matching may sometimes lead to better prediction, especially for the medium and long term. Clearly each member of the panel can be recovered, at least formally, from the catch-all setup by setting, in turn, the weight, wj, to unity, leaving the rest to zero. 2.2 Matching ACFs Suppose that the observable {yt}and{xt()}are both second-order stationary. If we are interested in second-order moments, then a weaker form of ( 2.4) is the following dierence or distance function: DC(yt, = the suxes of yandx() are self-explanatory. We assume that the spectral density function (SDF) of the observable ytexists; it is given by fy() =1 2(0) +1 k=1y(k) cos( k). The SDF of xt(), which we also assume to exist, can be dened similarly. We can also measure the dierence between two time series by reference to the dierence between their SDFs, for example DF(yt, xt()) is called the Itakura-Saito distortion measure; see also Whittle (1962). Further discussion on measuring the dierence between two SDFs can be found in Georgiou (2007). Suppose that {xt()}and the observable {yt}have the same marginal distribution and they each have second-order moments. Then we can prove that DC(yt, if {xt()}and the observable {yt}are linear AR models then there are some positive constants C3andC4such that Q(yt, xt())C3DC(yt, xt()),Q(yt, xt())C4DF(yt, xt()). For further details, see Theorem A in the Appendix. For linear AR models under the above setup, Q(., .),DC(., .) and DF(., .) are equivalent. However, the equivalence is not generally true. A counter-example can be constructed easily by reference to the classic random telegraph signal process. (See, e.g., Parzen, 1964, p. 115). Let us close this section by describing one way of implementing the ACF criterion for an ARMA model with normal innovation. Suppose y1, ..., yTare observations from the observable {yt}. Whittle (1962) considered a 'likelihood function' for ARMA models in terms of the SDF. Let I(w) =1 2T T t=1ytexp(t) 2 be the periodogram of the sample, where is the imaginary unit. Let f() be the theoretical SDF of an ARMA model with parameters . Whittle (1962) proposed to estimate by = min T j=1{I(j) f(j)+ log( f(j))} , where j= 2j/T . matching , the celebrated Whittle's like- lihood is not a conventional likelihood but a precursor of the extended-likelihood approach. It matches the second-order moments, by using a natural sample version of DF(yt, xt()) up to a constant. For this reason, it is expected that for mis-specied models, Whittle's estimator can lead to better matching of the ACFs of the observed time series than the inno- vation driven methods (e.g. the least squares estimation (LSE) or the maximum likelihood estimation (MLE)). We shall give some numerical comparison between Whittle's estimator and the others in sections 5 and 6 below. 3 Time series with measurement errors To illustrate the advantages of the catch-all approach, that involves minimal assumptions on the observed time series, we give detailed analyses of two cases involving measurement errors, one of which is related to a linear AR(p) model and the other a nonlinear skeleton model. 10They can be considered special cases of model mis-specication in that the observable y- time series is a measured version of the x-time series subject to measurement errors. For the linear case, measurement error is an old problem in time series analysis that was studied at least as early as Walker (1960). Some new lights will be shed. 3.1 Linear AR(p) models Consider the following AR(p) model xt=1xt1+...+pxtp+t. (3.7) Stationarity is assumed. By the Yule-Walker equations, we have the recursive formula for the ACF, {(j)}, of the x-time series, namely (k) =(k1)1+(k2)2+...+(kp)p, The Yule-Walker equations can be written as m= m. Suppose that the observable y-time series is a sequence of independent and identically distributed random variables each with zero mean and nite variance. Clearly, {yt}is no longer given by an AR(p) model of the form (3.7). Let{(j)}denote the ACF of the observable ytime series. Let mandmdenote the analogously dened matrix and vector of ACFs for the observable ytime series. Suppose we are now given the observations {y1, y2, . . . , y T},and we wish to t the wrong model of the form (3.7) to them. We may estimate (j) by (j) = (j) =T1Tj t=1(yt \u00afy)(yt+j\u00afy). Let mandmdenote the obvious sample version of mand sample version ofmrespectively. 11Since any pequations can be used to determine the value of the parameters, the Yule- Walker estimators typically use the rst pequations, i.e. =1 k=1{(k)(k1)1(k2)2...(kp)p}2, involving the ACF only up to lag p. We can achieve closer matching of the ACF by incorporating lags beyond pas well. For example, we may consider estimating by minimizing m k=1{(k)(k1)1(k2)2...(kp)p}2, m p. Denoting the mYule-Walker estimator (or AYW( m)). For the error-free case, i.e. t= 0 with probability 1, it is easy to see that {p}is the most ecient amongst all {m}, m=p, p+ 1, .... Otherwise, under some regularity conditions, we have in distribution n{{m}} N(0,m), where = ( mm)1 mmand p+ 4 I).For further details, see Theorem B in the Appendix. the bias 2 ( mm+ 22 p+4 I)1(p+2 I)in the estimator will be smaller when mis larger. For suciently large sample size, the smaller bias can lead to higher eciency in the sense of mean squared errors (MSE). Let \u00afk= ((k), (k+ 1), ..., (k+p 1)). Then mm= pp+m k=p\u00afk\u00af k. Thus, the bias can be reduced more substantially if the ACF decays very slowly and a larger mis used. For example, a highly cyclical time series usually has slowly decaying ACF, in which case the AYW will provide a substantial improvement over the Yule-Walker estimators. However, even with the ACF slowly decaying, a large mmay cause larger variability of the estimator. Therefore, a good choice of mis also important in practice. We shall return to this issue later. 12In fact, Walker (1960) suggested using exactly pequations to estimate coecients giving W.= the dierence between AYW and W.. Walker (1960) showed that in the presence of observation error, then =pis the optimal choice amongst all candidates with p, by reference to MSE. However, Walker's method seems counter-intuitive because it relies on the sample ACF at higher lags to a greater extent than those at the lower lags. Further discussion on the Walker's method can be found in Sakai et al. (1979) and Staudenmayer and Buonaccorsi (2005). It is well known that an autoregressive model plus independent additive white noise results in an ARMA model. Walker's approach essentially treats the resulting ARMA model as a true model. This approach has attracted attention in the engineering literature. See, e.g., Friedlander and Sharman (1985) and Stoica et al (1991). The essential dierence between this approach and the catch-all approach is that the latter postulates an autoregressive model to match the observations. And we know that it is a wrong model, as we consistently do with all postulated models. Note that the use of sample ACFs at all possible lags has points of contact with the so-called generalized method of moments, used extensively in Econometrics. See, e.g., Hall (1994). Next, we consider estimation based on Q(., .). Given a nite sample size, we may stop at say the m-step-ahead prediction. Let e1= (1,0, ...,0)and = 12... p1p 1 0 ... 0 0 ......... 0 0 0 0 ... 1 0 . We by ..., y where wkis a weight function, typically positive denite. A reasonable choice of wkis the absolute value of the autocorrelation function of the observed time series, i.e. wk=|ry(k)|. We call {m}in (3.10) the up-to- m-step-ahead prediction estimator (APE or APE( m)). The asymptotic properties of {m}will be discussed later. 133.2 Nonlinear skeletons A deterministic nonlinear dynamic model with observation error is commonly used in many applied areas, e.g. ecology, dynamical systems and others. See, for example, May (1976), Gurney et al. (1980), Tong (1990), Anderson and May (1991), Alligood et al. (1997), Grenfell et al. (2002), Chan and Tong (2001) and the examples in section 6below. Consider using the following nonlinear skeleton xt=g(xt1, ..., x tp) (3.11) to match the observable time series {yt}. Employing the Q(., .) criterion, the estimator is t=p+1m k=1wk{yt1+kg[m] (yt1, ..., we again call the up-to- m-step-ahead prediction estimator (APE or APE( m)). Here the weight function {wk}is as dened in equation ( 2.6). For ease of explanation, we consider again yt=xt+tandp= 1. Starting from any state x0=x0, let xt=g[m] (x0). Suppose the dynamical system has Lyapunov exponent (x0) = lim nn1n1 t=0log(|g (xt)|)<0, for all We predict xt+mby yt+m=g[m] (yt). By have |g[m] (xt+t)g[m] (xt)| More generally, suppose the system xt=g0(xt1, ..., x tp) has a nite dimensional state space and admits only limit cycles, but xtis observed as yt=xt+t, where {t}are independent with mean 0. Suppose that the function g(v1, ..., v p) has bounded derivatives in both in the parameter space and v1, ..., v pin a neighbourhood of the state space. Suppose that the system zt=g(zt1, ..., z tp) has only negative Lyapunov exponents in a small neighbourhood of {xt}and in the observed Y0=X0+ (0, 1, ..., p) is taken as the initial values of{xt}, then for any n, f(ym+1, ..., y m+n|X0)f(ym+1|X0=Y0)...f(ym+n|X0=Y0)0 (3.13) 14asm . Suppose the equation Xt\u00001{g(Xt1)xt}2= 0 has a unique solution in , where the summation is taken over all limiting states. Let {m}= arg min m1m k=1E{ yt1+kg[k] (Yt1)}2.If the noise takes value in a small neighbourhood of the origin, then {m}0,asm . Note that |f(y1|X0)f(y1|X0=Y0)| = 0 implies that f(y1, ..., y n|X0=Y0)=f(y1|X0=Y0)f(y2|X1=Y1)...f(yn|Xn1=Yn1), which challenges the commonly used (conditional) MLE. Equation ( 3.13) indicates that using high step ahead prediction can reduce the eect of noisy data (e.g. due to measurement errors), and provide a better approximation of the conditional distribution. The second part suggests that using high step ahead prediction errors in a criterion can reduce the bias caused by the presence of t. It also implies that any set of past values, e.g. ( yt1, ..., y tp) fort > p , can oer us an estimator with the rst summation in ( 3.12) removed. However, the summation over all past values is more ecient statistically. For further details, see Theorem C in the Appendix. There are other interesting special cases. For example, when the postulated model has a chaotic skeleton, the initial values play a crucial role. One approach is to treat the initial values as unknown parameters. See, e.g., Chan and Tong (2001) for more details. Another example is when the postulated model is nonlinear, and is driven by non-additive white noise with an unknown distribution. Here, the exact least squares multi-step-ahead prediction is quite dicult to obtain theoretically and time consuming to calculate numerically; see, e.g., Guo et al. (1999). In this case, the up-to- m-step-ahead prediction method is dicult to implement directly. However, our simulations suggest that approximating the multi-step- ahead prediction by its skeleton is sometimes helpful in feature matching, especially when the observed time series is quite cyclical (Chan et al. , 2009). 4 Issues of the estimation method We now turn to some theoretical issues and calculation problems. In conventional statisti- cal theory for parameter estimation, by consistency is generally meant that the estimated parameter vector converges to the true parameter vector in some sense as the sample size 15tends to innity. The postulated model is assumed to be the true model in the above conventional approach. In the absence of a true model and ipso facto true parameter vector, we propose an alternative denition of consistency. Specically, by consistency we mean that the estimated parameter vector will, in some sense, tend to the optimal parameter vector that represents the best achievable feature matching of the postulated model to the observable time series. To be more precise, for some positive integer m(which may be innite), we dene {wk}denes the weight function, typically positive and summing to unity. For ease of exposition, we assume that the solution to the above minimization is unique. Now, we say that an estimator is feature-consistent if it converges tom,win probability as the sample size tends to innity. It is easy to prove that under some regularity conditions, {m}is asymptotically normal, i.e. T1/2({m}m,w)DN(0,) for some positive denite matrix . For further details, see Theorem D in the Appendix. The optimal parameter depends on mand the weight function wk. As discussed in section 3.1, when the autocorrelation decays less slowly, we should consider using a larger m. Alternatively, we can consider assigning heavier weights for larger k. Our experience suggests that, for a postulated linear time series model, wkcan be selected as the absolute value of the sample ACF function. For a postulated nonlinear time series model aiming to match possibly high degrees of periodicity, wkcan be chosen as constant lasting for approximately 1, 2 or 3 periods. Note that by setting w1= 1 and all other wj's zero, the estimation is equivalent to the LSE, and the MLE in the case of exponential family of distributions. The above feature suggests that we may regard {m}as a maximum extended-likelihood estimator and functions such asT their equivalents as extended-likelihoods (orXT-likelihoods for short), with Whittle's likelihood as a precursor. An XT-likelihood carries with it the interpretation as a weighted average of likelihoods of a cluster of models around the postulated model. In this sense, it is related to Akaike's notion of the likelihood of a model. (Akaike, 1978). 16For the numerical calculation involved in ( 3.10) and ( 3.12), the gradient and the Hes- sian matrix of the loss function can be obtained recursively for dierent steps of predic- tion. Consider ( 3.12) an Let g[m] g[m] (yt1, ..., y ..., p, v k, = 1, ..., p +q. The Newton-Raphson method can then be used for the minimization. 5 Simulation study There are many dierent ways to measure the goodness of matching the observed by the postulated model, depending on the features of interest. We suggest two here. (1) The ACFs are clearly important features in the context of linear time series, and relevant even for nonlinear time series analysis. Therefore, a natural measure can be based on the dierences of the ACFs, for example, [N k=0{ry(k)rx(k)}2/N]1/2(5.14) for some N, suciently large or even innite, where ry(k) and rx(k) are the theoretical ACFs (if available) or sample ACFs. Clearly, we can use other distances to measure the dierences of the ACFs. (2) For highly cyclical {yt}, we can measure the dierences between the observed and the attractor (i.e. the limiting state) generated by the skeleton of postulated 17model, after allowing for possible phase shifts. Thus, we can use the following quasi-sample- path measure: min kT t=1|ytxt+k|/T, (5.15) where Tis the sample size as before. To check the eciency of estimation of parameters, especially in a simulation study, we can use an obvious measure: {()()/p}1/2for any estimator of= (1, ..., p). Obviously, it is a function of the number of steps min APE( m) or AYW( m). Note m= 1 corresponds to the commonly used estimation method based on the least squares, or the maximum likelihood when normality is assumed. Note that the MLE is also based on the one-step-ahead prediction for dynamical models that are driven by Gaussian white noise. In our plotting below, results for APE( 1) and AYW( 1) are not marked separately from those for APE( m) and AYW( m) with m > 1. Example 5.1 (model mis-speci cation) We postulate an AR( p) model to match data generated by fractionally integrated noise (1 B)dyt=t, where 0 .5> d > 0.5 and Bis the back-shift operator and {t}are IID N(0,1). The process is stationary, but has long- memory when 0 .5> d > 0. The closer is dto 0.5, the longer is the memory. For the use of low-order ARMA models for short-term prediction of this type of long memory model, see, e.g., Man (2002). Any AR( p) model with nite pis a 'wrong' model for the process. In the following analysis, the order pis assumed unknown and determined by AIC. The simulation results shown in Figure 1are based on 2000 replications. We have the following observations. (1) With a mis-specied model, the APE( m) and the AYW( m) with m > 1 show better matching of the ACFs than the APE( 1) and AYW( 1). When dis closer to 0 .5, the AR model is less likely to t the data well, thus necessitating a larger m. (2) When the autocorrelation is not strong, which is the case with dbeing close to zero, the AYW with large mshows better matching of the ACF than the APE; otherwise APE shows better matching. It is interesting to note that although APE does not target the ACF directly, it can match the ACF well in comparison with the AYW. (3) For small sample size or when dis not so close to 0 .5, the APE( m) with m > 1 show better matching than Whittle's estimator; otherwise the Whittle's estimator shows better 500.090.10.110.12T=200 0 500.080.090.1T=500 d=0.1 0 500.160.170.180.19difference between dierent sample size T, index dand the number of steps min AYW( m) or APE( m). In each panel, the dotted line, the solid line and the dash line correspond to the Whittle estimator, the APE and the AYW respectively. Example 5.2 (state-space model) Consider the AR(4) model with observation errors xt=1xt1+2xt2+3xt3+4xt4+t, y t=xt+t. This is also a special case of a state-space model. The estimation of the state model is of interest and has attracted considerable attention. See, for example, Durbin and Koopman (2001) and Staudenmayer and Buonaccorsi (2005). To cover as widely as possible all admissible values on the parameter space, we choose 1, 2, 3and4uniformly distributed in the stationary region. In the model, {t}is a sequence of independently and identically distributed random variables, each with a unit normal distribution, or IID N(0,1) for short; {t}is IID signal-noise ratio 2 /Var(yt) =snis xed. Again, we run the simulation 2000 times. The results are summarized in Figures 2and3. When pis known, Figure 2suggests that APE( m) and AYW( m) with m > 1 can usually produce models that better match the dynamics of the hidden state time series {xt}than APE( 1) and AYW( 1). When pis selected by 19020 400.190.20.210.22sn = 0.2ACF difference between the hidden dynamics and fitted020 400.290.30.310.32sn = 0.4 020 400.220.230.240.250.260.27sn = 0.6 T=50 020 400.120.130.140.150.16 m 020 400.10.120.140.16 m 020 400.10.120.140.160.18 T=100 m Figure 2: Results for Example 5.2when the order p= 4 is known. In each panel, the dotted line, the solid line and the dash line correspond respectively to the Kalman lter, the APE( m) and the AYW( m) over dierent m. 020 400.11 0.12 020400.06 = 0.2T=500 020 400.12 0.13 difference of ACFs between hidden state space020 400.1 0.11 0.09 sn 020 400.11 0.12 m 020400.090.10.11sn = 0.6 m Figure 3: Results for Example 5.2when the order pis selected by AIC. In each panel, the solid line is for APE( m) and the dash line for AYW( m). 20AIC, Figure 3suggests that APE( m) and AYW( m) with m > 1 can still lead to better matching than APE( 1) and AYW( 1). To compare with the Kalman lter approach which utilizes the maximum likelihood method or other methods such as the EM algorithm, we apply the R package \"dlm\" kindly provided by Professor Giovanni Petris. The results are shown by dotted lines in Figure 2. When the order is known, the Kalman lter shows good performance in estimating the coecients and in matching the ACF, but it shows very unstable performance when the sample size is small. Even worse, if the order is selected by the AIC, the Kalman lter appears to be incapable of producing reasonable matching, so much so that the results are outside the range in Figure 3. Example 5.3 (nonlinear time series model 1: smooth model) Consider the simple nonlinear model xt=b1xt1+b2x2 t1+0t; yt=xt+1t but tis truncated to lie in [-4, 4]. We replicate our simulation 1000 times for each set of variances 2 0and2 1. The matching results are shown in Figure 4. By coping well with noisy data due to 1, APE( m > 1) demonstrates substantial improvement on the parameter estimation (in Panel 1 of Figure 4), the ACF-matching of the hidden time series xt(panel 2 of Figure 4) and the ACF-matching of the observed time series (in panel 3 of Figure 4). It is not surprising that when the model is perfectly specied (i.e. 1= 0), the APE( 1) can provide better performance than APE( m) with m > 1 in terms of the parameter estimation and the ACF matching; see panels 4-5 of Figure 4. However, APE( m) with m > 1 is still useful in matching features of the observed time series as shown in the last panel. Our results suggest that APE( m) with m > 1 leads to less improvement over APE( 1) when 0(for the dynamic noise) is larger but greater improvement when 1(for the observation noise) is larger. Example 5.4 (nonlinear time series model 2: SETAR model) Now, we consider a self-exciting threshold autoregressive model (SETAR model) with xt={a0+b0xt1,ifxtdc, 202.221.81.61.41.2 m 1 for Example 5.3with T= 50 and dierent 0and1. The rst panel is the estimation error of ( b1, b2) with 1= 1; the second panel is the dierence of ACFs between the matching skeleton and the true ACF with 1= 1; the third panel is the dierence of ACFs between the matching skeleton and the estimated ACFs based on random realizations with 1= 1. Panels 4-6 are respectively the corresponding results of panels 1-3 but with 0= 0. where parameters a0= 3, b0= 1, a1=3, b1= 1 and c= 0. A realization is shown in the rst panel of Figure 5. It reveals a period of 6 when d= 2, and 10 (not shown) when d= 3. Suppose that we observe yt=xt+t,where {t}are IID N(0,1). A typical realization is also shown in the second panel of Figure 5. Using the APE approach to the simulated data, we denote the matching skeleton by xt and measure the matching error dened in ( 5.15) with T= 100. Based on 100 replications, we summarize the results in Table 1. The matching errors have means and standard devi- ations in the parenthesis in column 3; the average and standard error (in the parenthesis) of the periods in all the matching models are listed in column 4. Our results suggest that the APE( m) with m > 1 performs much better than the APE( 1), both in terms of 22matching the dynamic range and the periodicity. 0 10 20 30 40 5050510 txt 0 10 20 30 40 5050510 tyt Figure 5: The upper panel is a realization of the hidden skeleton in Example 5.4. The lower panel is an observed time series subject to additive measurement error from N(0, 1). Table 1. The simulation results for Example 5.4 model matching cycle frequency of setting method error periods correct periods (%) 6 Application to real data sets In this section, we study four real time series, some of which are very well known but others less so. They are the sea levels data, the annual sunspot numbers, Nicholson's blowflies 23data, and the measles infection data in London after the massive vaccination in the late 1960s. 6.1 Sea levels data Long-term mean sea level change is of considerable interest in the study of global climate change. Measurements of the change can provide an important corroboration of predictions by climate models of global warming. Starting from 1992, in each year 34 equally spaced observations were recorded. The data with the linear trend and seasonality removed are available at http://sealevel.colorado.edu/current/sl noib nsglobal.txt . The time series is depicted in the rst panel of Figure 6. Note that the data are subject to measurement errors of 3-4 mm. As an experiment with using a much less than ideal model to match this data set, let us postulate an AR model. By AIC, the order of the AR model is selected as 6. Next, we apply the MLE (equivalently the one-step-ahead prediction estimation method), the Whittle's method and the up-to- m-step-ahead prediction estimation method to the data. The results are shown in Figure 6. The sample spectral density function (SDF) is estimated by the method of Fan and Zhang (1999). The results show clear evidence of long memory with the singularity at the origin, which is well captured by all three methods. However, for the peak away from the origin, Whittle's estimation and APE( m) show very similar matching capability and both show much better match than the MLE. To investigate further, we build an AR(6) model for every span of observations of length T= 100 and make predictions from 1 step ahead to 30 steps ahead. For the dierent estimation methods, their averaged prediction errors based on all periods are displayed in the bottom panels of Figure 6. The MLE method shows clear superior performance for short-term prediction, while the reverse is true from 5 steps onward. 6.2 Annual sunspot numbers Sunspots, as an index of solar activity, are relatively cooler and darker areas on the sun's surface resulting from magnetic storms. Sunspots have a cycle of length varying from about 9 to 13 years. Statisticians have tted several models to predict sunspot numbers. They have also noticed that the time from the initial minimum of a cycle to its next maximum, called the rise time, and the time from a cycle maximum to its next minimum, called the 241994199619982000200220042006200815105051015 yearsea levels 0 2012SDF 0 2012 0 2012 5 10 15 20 25 300.9511.05 no. of steps aheadrelative prediction errorsFigure 6: Results for the sea level data. The data with linear trend and seasonality removed is shown in the rst panel. Panels 2-4 are the smoothed sample SDF and those of the tted models by MLE, the Whittle method and APE( 20) respectively. Panel 5 is the relative averaged multi-step ahead prediction errors by taking those of the one-step method as 1 unit. The curves marked by 'o', '\u00d7', '' and ' ' are for APE( 10), APE( 20), APE( 30) and APE( 50) respectively. 25fall time, are quite regular. Due to its link to other kinds of solar activity, sunspots are helpful in predicting space weather and the state of the ionosphere. Thus, sunspots can help predict conditions of short-wave radio propagation as well as satellite communications. Historical data of the sunspots have been recorded in dierent parts of the world. The data we use are the annual sunspot number for the period 1700 to 2008 which are obtainable from http://www.ngdc.noaa.gov/stp/SOLAR/ftpsunspotnumber.html . Yule (1927) was the rst statistician to model the sunspot number using a model, now known as the autoregressive model, with lag 2. Later renements of stationary linear models can be found in, e.g., Brockwell and Davis (1991) and others; higher-order AR models or ARMA models are used. Akaike (1978) suggested that the data are better modelled as non-stationary over a long period. Tong and Lim (1980) noticed nonlinearity in the data dynamics and proposed the use of a self-exciting threshold autoregressive model (or a SETAR model for short). In the following, we postulate a two-regime SETAR model of order 3 with delay parameter equal to 2 for the annual sunspot numbers xt={a0+b0xt1+c0xt2+d0xt3,ifxt20, a1+b1xt1+c1xt2+d1xt3,ifxt2> 0, where xt= log(no. of sunspots + 1). Note that Cheng and Tong (1992) recommended a nonparametric AR(4) model. We also tried SETAR model of order 4 with delay parameter equal to 2. The performances of both models are very similar. We use each xed span of Tobservations to t the postulated model and then use it to do a post-sample prediction based on the skeleton of the tted model. We measure the following: (1) the dierence of cycle periods between the data and the tted model; (2) the frequency of stable tted models; (3) The out-of-sample prediction errors based on the skeletons of models tted by the APE( m) for dierent m; (4) The dierence between the observed time series and the time series generated by the best tting skeleton by reference to (5.15). The results are shown in Figure 7and Table 2. We may draw the following conclusions. (1) When the observed time series is short (e.g. T= 20,35), APE( m) with m > 1 show better matching than APE( 1) in both one-step-ahead prediction and multi-step-ahead prediction; see panels 1 and 2 in Figure 7. When the length of the time series is longer (e.g. T= 50,100), APE( 1) can lead to tted models with better short-term (less than 4 steps ahead) prediction than APE( m) with m > 1, but for prediction beyond 4 steps ahead, 261 2 3 4 5 7 10 15 20 30 40 50102030405060T=20 1 2 3 4 5 7 10 15 20 30 40 501020304050 T=35 1 2 3 4 5 7 10 15 20 30 40 501020304050T=50 prediction horizonmatching and prediction errors 1 2 3 4 5 7 10 15 20 30 40 5010203040T=100 prediction horizonFigure 7: The dashed curves are the averaged prediction errors based on APE( 1), the solid curves are those based on APE( m) with m= 10,20,30,50 respectively. The horizontal dash lines are the matching errors for the APE( 1), the solid lines are those for APE( m) with m= 10 ,20,30,50 respectively. the reverse appears to be the case, in line with our understanding of the APE method. (2) When the observed time series is short, APE( m) with m > 1 shows its ability in avoiding unstable models; see the numbers in the square brackets of Table 2. (3) For both short time series and long time series, models tted by APE( m) with m > 1 show better matching of the observed time series in terms of their cycles; see Table 2 and the horizontal lines in Figure 7. Table 2. The averaged dierence (and their standard error) of cycle periods in the data and mathching models and the number of unstable matching models [in squared brackets]. min length of time series APE(m) 20 35 50 of the total number of blowflies (Lucilia cuprina) in a population under controlled laboratory conditions. The data represents counts for every second day. The developmental delay (from egg to adult) is between 14-15 days for the blowflies under the conditions employed (Gurney et al. 1980). Nicholson obtained 361 bi-daily recordings over a 2-year period (722 days). However, due to biological evolution (Stokes et al. , 1988), the whole series cannot be considered to represent the same system; a major transition appears to have occurred around day 400. Following Tong (1990), we consider the rst part of the time series (to day 400, thus T=200), for which the population has a 19 bi-days cycle; see Figure 8. Next, we postulate the single species animal population discrete model ( 1.2) with b(xt) = cx texp(xt/N0) as suggested by Gurney et al. (1980), and thus xt=cx texp(xt/N0)xtxt1, where we take = 8 (bi-days) corresponding to the time taken for an egg to develop into an adult. In the model, there are 4 parameters: c, , N 0and. The (one-step-ahead prediction) MLE estimates the parameters are c= 20.1192,N0= 589 .5553,= 0.2633. The skeletons based the postulated model with parameters estimated by above meth- ods are shown in panels 1 and 2 in Figure 8respectively. They show that APE( T) results in a model, whose skeleton matches the observed cycles to a much greater extent than APE(1). APE( 1) gives a period of 21 bi-days; APE( T) 19 bi-days, which is almost exactly the average period of the observed cycles. We have also postulated a SETAR model. With APE( T), the SETAR model can also capture the observed period very well, but again this is not the case with APE( 1). To investigate how the cycles change with the time needed by the fly to grow to maturity, we vary the time from 4 to 100 bi-days. The corresponding cycles (in bi-days) are shown in the last two panels of Figure 8. APE( T) shows a clear linearly increasing trend in the cycle-periods as increases, while APE( 1) 280501001502002503003504000500010000population Results for the Nicholson's blowflies data. In the rst two panels, the dashed lines are for the observed population; the solid lines are for realizations from models tted by APE( 1) and APE( T) respectively. The dashed lines in panels 3-4 are the periodograms of the observed data, and the solid lines are those of the models tted by APE( 1) and APE( T) respectively. In panels 5-6, for each marked in the x-axis, the vertical column is the periodogram with the values colour-coded, brighter colour (blue being dull) corresponding to higher power value. Thus the brightest point indicates the cycle-period of the dynamics at . 29shows strange excursions that are dicult to interpret. The linear relationship suggested by APE( T) may be helpful in throwing some light on the important but not completely resolved cycle problem of animal populations. We have also tried APE( m) with mequal to twice or thrice the cycle-period. Their results are similar to those of APE( T). 6.4 Measles dynamics in London It is well known that the continuous-time susceptible-infected-recovered (SIR) model using a set of ordinary dierential equations can describe qualitatively the behaviour of epidemics quite well. However, it is dicult to used it for real data modelling when the observations are made in discrete time. To bridge the gap between the theoretical model and real data tting, several discrete-time or chain models have been introduced. The Nicholson- Bailey host-parasite model (Nicholson and Bailey, 1935) is an early example. Bailey (1957), Bartlett (1960) and Finkenst\u00a8 adt and Grenfell (2000) proposed dierent types of discrete- time epidemic models. A general discrete-time or chain model can be written as follows. {St+1=St+BtIt+1, It+1=StP(It),(6.16) where It,StandBtare respectively the number of the infectious, the number of the sus- ceptible and the number of births, all at the tth time unit. There are many possible functional forms for the (probability) P(It). Examples are 1 (1r0/N)It(Bartlett,1960), 1exp(r0It/N) (Bartlett, 1956), r0It/N(Baily, 1957) and R0I t/N(Liu et al. 1987; Finkenst\u00a8 adt and Grenfell, 2000), where Nis the eective population of hosts, and r0is the basic reproductive rate. Next, we postulate the following (deterministic) discrete-time SIR model for the trans- mission of to indicate the seasonality force, with t,k= 1 if time tis at thekth season, 0 otherwise. For measles, the time unit for tis bi-weekly, based on the infection procedure of measle; see Finkenst\u00a8 adt and Grenfell (2000). Now, k= 1, ..., 26 bi- weeks corresponds to about 54 weeks in a year. Finkenst\u00a8 adt and Grenfell (2000) considered the same model but with the rst equation being It+1= exp( t,kk)StI t. Here, we take = 1 for two reasons. (1) If <1, Finkenst\u00a8 adt and Grenfell (2000) was unable to use the 30Table 3: Parameters in the measles transmission model method 1 2 3 4 5 6 the dynamics of measles in the massive vaccination era. (2) Experience with statistical modelling of ecological populations suggests that can be taken as 1 with improved interpretation; see Bj\u00f8nstad et al. (2002). In practice, Itmay not be observed directly; what can be observed is a random variable, say yt, that has mean It. For this observable yt, we postulate a model xtthat follows a Poisson distribution with mean It. There are some problems with the data. There is non-negligible observation error in the data due the under-reporting rate, which can be as high as 50%; see Finkenst\u00a8 adt and Grenfell (2000), where a method was proposed to recover the data. Following their method, the data was adjusted for the under-reporting rate. The adjusted data is shown in dash lines in panels 1 and 2 of Figure 9. It is known that the role of vaccination is equivalent to the reduction of the birth rate (Earn et al. , 2000). Thus, we adjust the number of births by multiplying it by the un-vaccination rate, i.e. 1 (vaccination rate). We show the adjusted births in the third panel of Figure 9. Another problem with the data is that the susceptible Stis unknown, which can also be re-constructed by the method in Finkenst\u00a8 adt and Grenfell (2000). Applying APE( T) and APE( 1) as described in the last example, we obtained parameter estimates for the model as listed in Table 3. The skeletons based on models tted by APE( 1) and APE( T) are shown in solid red lines in panel 1 and panel 2 of Figure 9respectively. APE( T) shows a much better match than APE( 1) in terms of outbreak scale and cycle period. The periodogram is also much better matched by 311970 1975 1980 1985 19900500010000measles cases in London 1970 1975 1980 1985 19900200040006000 1970 1975 1980 1985 19900100020003000adjusted biweekly births 0 50 100 150051015x 1010 period (biweeks/cycle) 0 50 100 1500246x (biweeks/cycle) Figure 9: Results for modelling the measles incidents in London. The dashed lines in panels 1 and 2 are the recovered incidents of measles; the solid lines are the realizations of the model based on APE( 1) and APE( T) respectively. Panel 3 is the adjusted birth rate by removing the vaccinated; in the bottom panels, the dashed lines are the periodograms of the data and the red lines are those of the matching skeleton by APE( 1) and APE( T) respectively. 320 2000 4000 6000 8000 100000123456 number of birthsperiod (years/cycle)Figure 10: Measles transmission. column is the periodogram with the values colour- coded, brighter colour corresponding to higher power. (Dark blue is considered a dull colour.) APE(T) than by APE( 1); see the last two panels of Figure 9. We have also tried APE(m) with mbeing twice or thrice of the cycle period (i.e. 26 bi-weeks). The results are similar to APE( T). An important feature in the measles transmission is that there were some big annual outbreaks in the 1950s when the birth rate was very high after the second world war, and some big bi-annual outbreaks in the middle of 1960s when the birth rate was relatively low. The dynamics before the massive vaccination in the late 1960s was modeled very well by a time series model in Finkenst\u00a8 adt and Grenfell (2000). The theory that relates population cycle length to birth rate has been well accepted in epidemiology and ecology. In epidemiology, the relationship will either prolong or shorten the cumulation procedure of susceptibles for a big outbreak. Observations from the other sources have lent support to this theory. For example the measles in New York have a 3-year or 4-year cycle when the birth rate is very low. As another supporting piece of evidence, in the vaccination era, the 33cycles lasted longer to 4 or 5 years because vaccination is equivalent to the reduction of birth rate in the transmission of disease. However, the dynamics after the massive vaccination is dicult to model due to the quickly changing birth rate. The method of Finkenst\u00a8 adt and Grenfell (2000) has failed to capture this change of cycles in the vaccination era. It is therefore worth noting that our modied model, with the aid of APE( m) with m > 1, shows satisfactory matching. To investigate further how the cycles change with the birth rate, for each xed number of births we run the estimated model and depict its periodogram and highlight the peaks by colour-coding (brigher colour for higher power). The peaks with the brightest points correspond to the cycles of the postulated model. Figure 10shows clearly that when the birth rate is high (from about 5000 upwards) the cycle is annual, but when the birth rate is medium at about 3000 to 4000, the cycles become two-year cycles. As the birth rate gets lower, the model shows that cycles become three-year cycles or even ve-year cycles. It seems that by tting a substantive model with the catch-all approach, we have obtained perhaps the rst discrete-time model that is capable of revealing the complete function linking birth-rates to the cyclicity of measles epidemics, thereby lending support to the general theory developed by Earn et al. (2000), which was based on dierential SIR equations in continuous time. 7 Concluding remarks and further problems In this paper, we adhere to Box's dictum and abandon, right from the very beginning, the assumption of either the postulated parametric model being true or the observations being error-free. Instead, we focus on ways to improve the feature matching of a postulated parametric model to the observable time series. We have introduced the notion of an optimal parameter in the absence of a true model and dened a new form of consistency. In particular, we have synthesized earlier attempts into a systematic approach of estimation of the optimal parameter, by reference to up-to- m-step-ahead predictions of the postulated model. We have also developed some general results with proofs. Conventional methods of estimation are typically based on just the one-step-ahead pre- diction. Our analysis, simulation study and real applications have convinced us that they are often found wanting in many situations, e.g. the absence of a true model, short data sets, observation errors, highly cyclical data and others. Our stated primary objective is feature matching. Prediction is secondary here. However, we have evidence to suggest that 34a model with good feature matching can stand a better chance of enjoying good medium to long-term prediction. Of course, if the aim is prediction with a speci ed horizon, say m0, then we simply set wm0= 1 and the rest zero. In that case, our catch-all approach really oers nothing new. Let us now take another look at the dierence between APE( m) with m > 1 and APE(1). Suppose we postulate the model xt=g(Xt1)+twhere Xt1= (xt1, ..., x tp) to . . . , y T}, APE( m) with m > 1 and with a constant wj>0, all j, estimates by minimizing the objective function that L1() is the commonly used objective function for APE( 1), while L+ 1() is the extra information provided by the dynamics. In terms of samples, L1() is based on sample {yt, Yt1:t=p+ 1, ..., T}. The extra term L+ 1() is associated with the extra pseudo designed samples {yt1+k, Yt1:t=p+ 1, ..., T, k = 1, ..., m}. If the data are actually generated by the postulated model (a rare event), then under some general conditions such astare IID normal, L1() will include all the information about . In that case, estimation based on L1() alone is the most ecient and that the extra term L+ 1() can provide no additional information. However, if the data are not exactly generated by the postulated model (a common event) the extra information provided by L+ 1() can indeed be very helpful and should be exploited. Despite evidence, both theoretical and practical, of the utility of the catch-all approach, much more remains to be done. Our paper should be seen as the rst word on feature match- ing. Although we have provided some concrete approaches, such as the catch-all approach, the ACF-matching approach and others, there are outstanding issues. For example, we can, at present, oer no theoretical guidance on the specication of the weights, {wm}. We have only oered some practical suggestions based on our experience. It would be interesting to investigate further possible connections with a prior in Bayesian statistics. 35We have been quite fortunate with our real examples using the APE method, thanks to our long-standing collaboration with ecologists and epidemiologists. However, we are conscious of the need for the accumulation of further experience. We are convinced that, especially in the area of substantive modelling, guidance by relevant subject scientists is paramount. Relevant references include He et al. (2010), King et al. (2008), Laneri et al. (2010) and others. Last but not least, future research should include at least the following: other weaker forms of (2 .4),choice of a suitable weaker form in a specic application, other criteria for model comparison, non-additive and/or heteroscedastic measurement errors, the relaxation of stationarity, the eect of pre-ltering of data, multiple time series, model selection among a set of wrong models (each tted by the catch-all method-perhaps the idea of model calibra- tion in econometrics might be useful here), possible extension to other types of dependent data, e.g. spatial data. Acknowledgements: HT gratefully acknowledges partial support from the National Uni- versity of Singapore (Saw Swee Hock Professorship) and the University of Hong Kong (Distinguished Visiting Professorship). We are grateful to the editor and two anonymous referees for constructive comments. REFERENCES Akaike, H. (1978). On the likelihood of a time series model. The Statistician ,27, 217-235. Alligood, K., Sauer, T. and Yorke, J. A. (1997). Chaos: an introduction to dynamical systems . New York: Springer. Anderson, R. M. and May, R. M. (1991). Infectious diseases of humans : Dynamics and control . Oxford: Oxford University Press. Bailey, N. T. J. (1957). The mathematical theory of epidemics . London: Grin. Bartlett, M.S. (1956). Deterministic and Stochastic models for recurrent epidemics. Proc. of the Third Berkeley Synp. on Mathemathcal Probability ,4, 81-108. 36Bartlett, M.S. (1957). Measles periodicity and community size. J. Roy. Statist. Soc. , Series A, 120, 48-70. Bartlett, M.S. (1960). The critical Community size for measles in the United States. J. Roy. Statist. Soc. , Series A, 123, 37-44. Bhansali, R. J. and Kokoszka, P. S. (2002). Computation of the forecast coecients for multistep prediction of long-range dependent time series. Int. J. Forecasting, 18, 181-206. Bj\u00f8nstad, O.N., Finkenst\u00a8 adt, B., Grenfell, B.T. (2002). Dynamics of measles epidemics: Estimating scaling of transmission rates using a time series SIR model. Ecological Monographs, 72, 169-184. Box, G.E.P. (1976). Science and statistics. J. Amer. Statist. Assoc. 33, 526-536. MR0431440 Box, G. E. P. and Jenkins, G. M. (1970). Time series analysis: Forecasting and control . San Francisco: Holden-Day. Brockwell, P. J. and Davis, R. A. (1991). Time Series: Theory and Methods . New York: Springer-Verlag. Canova, F. (2007). Methods for applied macroeconomic research . Princeton: Princeton University Press. Chan, K. S. and Tong, H. (2001). Chaos: A Statistical Perspective Series . New York: Springer. Chan, K. S., Tong, H. and Stenseth, N. C. (2009). Analyzing short time series data from periodically fluctuating rodent populations by threshold models: A nearest block bootstrap approach. Science in China. Series A. Mathematics ,52, 1085-1112. Chen, R., Yang, L. and Hafner, C. (2004). Nonparametric multi-step ahead prediction in time series analysis. J. Roy. Statist. Soc. , Series B, 66, 669-686. Cheng, B. and Tong, H. (1992). Consistent nonparametric order determination and chaos (with discussion) J. Roy. Statist. Soc. , Series B, 54, 427-474. 37Cox, D.R. (1961). Prediction by exponentially weighted moving averages and related methods. J. R. Statist. Soc. ,23, 414-422. Durbin, J. and Koopman, S. J. (2001). Time Series Analysis by State-Space Methods. Oxford: Oxford University Press. Dye, C. and Gay, N. (2003). Modeling the SARS Epidemic. Scinence Express online. Earn, D. J. D., Rohani, P., Bolker, B. M. and Grenfell, B. T. (2000). A simple model for complex dynamical transitions in epidemics. Science ,287, 667-670. Ellner, S. P. Seifu, Y., and Smith, R. H. (2002). Fitting population-dynamic models to time-series data by gradient matching. Ecology ,83, 2256-2270. Fan, J. and Zhang, W. (2004). Generalized likelihood ratio tests for spectral density. Biometrika ,91, 195-209. Friedlander, B. and Sharman, K. C. (1985). Performance evaluation of the modied Yule- Walker estimator. IEEE Transactions on Acoustics, , 33, 719-725. Finkenst\u00a8 adt, B.F., and Grenfell, B.T. (2000). Time series modelling of childhood diseases: a dynamical systems approach. J. Roy. Statist. Soc. , Series C, 49, 187-205. Georgiou, T. T. (2007). Distances and Riemannian Metrics for Spectral Density Functions. IEEE Trans. Sign. Proc. ,55, 3995-4003. Grenfell, B.T., Dynamics of measles epidemics: scaling noise, determinism and predictability with the TSIR model. Ecological Mono- graphs ,72, 185-202. Guo, M., Bai, Z. and An, H-Z. (1999). Multi-step prediciton for nonlinear autoregressive models based on empirical distributions. Statistica Sinica ,9, 559-570. Gurney, W. S. C., Blythe, P. B. and Nisbet, R. M. (1980). Nicholson's Blowflies revisited. Nature ,287, 17-21. Hall, A. R. (2005). Generalized Method of Moments . Oxford University Press. 38He, D., Ionides, E.L. (2010). Plug-and-play inference for disease dynamics: Measles in large and small towns as a case study. J. Roy. Soc. Interface ,7, 271-283. Isham, V. and Medley, G. (2008). Models for Infectious Human Diseases: Their Structure and Relation to Data . Cambridge: Cambridge University Press. Keeling, M. J. and Grenfell, B. T. (1997). Disease extinction and community size: mod- eling the persistence of measles. Science Iondides, E.L., Pascual, M. and Bouma, dynamics. Nature Prescott, E.C. (1996). The computational tool. Dhiman, R. and Pascual, M. (2010). Forcing versus feedback: Epidemic malaria and monsoon rains in NW India. PLoS Computational Biology ,6, e1000898. Liu, W. M., Hethcote, H. W. and Levin, S. A. (1987) Dynamical behaviour of epidemio- logical models with nonlinear incidence rates. J. Math. Biology ,25, 359-380. Man, K. S. (2002) Long memory time series and short tem forecasts. Int. J. Forecasting , 19, 477-491. May, R. M. (1976). Simple mathematical models with very complicated dynamics. Nature , 261, 459-467. Nicholson, A. J. and Bailey, V. A. (1935). The balance of animal populations-part 1. Proc.Zoo. Soc. London ,1, 551-598. Oster, G. and Ipaktchi, A. (1978). Population cycles. in Periodicities in Chemistry and Biology . edited by H. Eyring, New York: Academic Press, Francisco: Holden-Day. Rohani, P., Green, C. J., Mantilla-Beniers, N. B., & Grenfell, B. T. (2003). Ecological interference between fatal diseases. Nature ,422, 885-888. 39Romano, J. P. and Thombs, L. A. (1996). Inference For Autocorrelations Under Weak Assumptions. J. Amer. Statist. Assoc. ,91, 590-600 Sakai, H., Soeda, T. and Tokumaru, H. On the relation between tting autore- gression and periodogram with applications. Ann. Statist. ,7, 96-107. Slutsky, E. (1927). The summation of random causes as the source of cyclic processes. Econometrica ,5, 105-146. Staudenmayer, J. and Buonaccorsi, J. P. (2005). Measurement error in linear autoregres- sive models. J. Am. Statist. Ass. ,100, 841-852. Stoica, P. Moses, R. L. and Li, J. (1991). Optimal higher-order Yule-Walker estimation of sinusoidal frequencies. IEEE Transactions on Signal Processing ,39, 1360-1368. Stokes, T. G., Gurney, W. S. C., Nisbet, R. M. and Blythe, S. P. (1988). Parameter evolution in a laboratory insect population. Theor. Pop. Biol. ,34, 248-265. Tiao, G.C. and Xu, D. (1993). Robustness of maximum likelihood estimates for multi-step predictions: the exponential smoothing case. Biometrika ,80, 623-641. Tong, H. (1990). Nonlinear Time Series Analysis: a Dynamical System Approach . Oxford: Oxford University Press. Tong, H. and Lim, K. S. (1980). Threshold autoregression, limit cycles and cyclical data (with discussion). J. Roy. Statist. Soc. , Series B, 42, 245-292. Tsay, R. S. (1992). Model checking via parametric bootstraps in time series analysis. J. Roy. Statist. Soc. , Series C, 41, Uni- versity of California Press. Walker, A. M. (1960). Some consequences of superimposed error in time series analysis. Biometrika ,47, 33-43. Whittle, P. (1962). Gaussian estimation in stationary time series. Bull. Int. Statist. Inst. , 39, 105-129. 40Wood, S. N. (2001). Partially specied ecological models. Ecological Monographs ,71, 1-25. Yule G. U. (1927). On a method of investigating periodicities in disturbed series, with special reference to Wolfer's sunspot numbers. Phil. Trans. Roy. Soc. of London , Series A, 226, 267-298. Appendix: Outlines of theoretical justi cation We need the following assumptions. However, these assumptions can be relaxed with more complicated theoretical derivation. (C1) Time series {yt}is a strictly stationary and strongly mixing sequence with exponen- tially decreasing minimum point for in the parameter space . Theorem A. Suppose that {xt()}and{yt}have the same marginal distribution and each has second-order moments. Then DC(yt, xt())C1Q(yt, xt()), DF(yt, positive constants C1andC2. Moreover, if {xt()}and{yt}are linear AR models then there are some positive constants C3andC4such that Q(yt, xt())C3DC(yt, xt()),Q(yt, xt())C4DF(yt, xt()). 41Proof. By we have E(yt+m) =E(xt+m). (a.1) Since E[ the rst inequality of Theorem A. For ease of exposition, assume that {yt}and{xt()}are given by AR models with the same order, P. Otherwise we take the order as the larger of the two orders. So yt=1yt1+...+PytP+tandxt=1xt1+...+PxtP+t.Lete1= (1,0, 0 0 1 ... 0 0 ............... 0 0 ... 1 0 , = 12... P1P 1 0 ... 0 0 0 1 ... 0 0 ............... (Note: The IID assumption be relaxed at the expense of a much lengthier proof.) It follows that minimum eigenvalue of 0and the maximum eigen- value of respectively. Note max()<1. Therefore, Q()P1 min(0) m=0wm{y(k)x(k)}2=C3Dc(xt(), yt), for some wm0. The proof is completed. 2 Theorem B. Under assumptions (C1) and (C2), we have in distribution n{{m}} N(0,m), where = ( mm)1 mmand mis a positive de nite matrix. As a special case, if yt=xt+twithVar(t)>0andVar(t) =2 >0, then the above mm+ 22 p+4 I)1(p+2 I). 43Proof. To simplify the range of summation in the triangular array due to the lags with xed masT , we introduce =to denote the fact that the quantities on both sides of it have negligible dierence. By Theorem 3.1 of Romano and Thombs (1996), in an enlarged probability space we have m= m+n1/2Um+op(n1/2), m= m+n1/2Vm+op(n1/2), where UmandVmhave the same structure as with (k) being replaced by vkand ( vi+1, ...., v i+j) for any i, jbeing normal, with variance-covariance matrix given in Romano and Thombs (1996). linear combination of {vk}. Thus, Wis normally distributed with mean 0. This is the rst part of Theorem B. Ifyt=xt+t, letx(k) =n1n i=1xtxt+k, it is = 0,1, ..., Theorem 3.1 of Romano and Thombs (1996), in an enlarged probability space there are random variables k, kandksuch that ...,{k, 0,1, ...}, mutually Zkand as kwith x(k) k, k andkrespectively. Let Bkbe a k\u00d7pmatrix with the rst p\u00d7psubmatrix being 2 Ipand all the others 0. We have p) is normally distributed. We have proved the second part. 2 Theorem C. Suppose the system {xt=g0(xt1, ..., x tp)}has a nite dimensional state space and admits only limit cycles, but xtis observed as yt=xt+t, where {t}are independent with mean 0. Suppose that the function g(v1, ..., v p)has bounded derivatives in bothin the parameter space andv1, ..., v pin a neighbourhood of the state space. Suppose that the system zt=g(zt1, ..., z tp)has only negative Lyapunov exponents in a of ..., p)is taken as the initial values of {xt}, then for any n, f(ym+1, ..., y m+n|X0)f(ym+1|X0=Y0)...f(ym+n|X0=Y0)0 asm . 2.Suppose the equation Xt\u00001{g(Xt1)xt}2= 0 has a unique solution in , where the summation is taken over all limiting states. Let {m}=argmin m1m k=1E{ yt1+kg[k] (Yt1)}2.If the noise takes value in a small neighbourhood of the origin, then {m}0asm (Xt)| the kth step is g[k](Y0). Since the Lyapunov exponent is independent. the rst part of Theorem inequality of ( a.6) and the continuity, we have as 0andm , (Yt1)}20. (a.7) Next, we show ||0|| >0, then as m there a.8) by Suppose the period of the limit cycle is . For continuous dynamics, the assumption of a unique solution is equivalent to the statement that as i , i+ k=i+1{g(Xk1)xk}20 0. (a.9) If (a.8) does not hold, i.e., there is a such that m1m k=1E{g[k] (Xt)xt1+k}20, then there must ..., ij+ k=ij+1{g(xt+k1+et+k1, ..., x t+kp+et+kp)xt+k}20. By the j , we haveij+ k=ij+1{g(xt+k1, ..., x t+kp)xt+k}2= 0, which contradicts the assumption of a unique solution ( a.9). By (a.6), (a.7) and ( a.8), we have completed the proof of Theorem C. 2 Theorem D. Recall the notation ...,0)andNt= (t, ..., further assume that g(x)has bounded 47second order derivative with respect to in neighbour of for all possible values of yt. Suppose that the assumptions (C1)-(C4) hold. Then T1/2({m}m,w)DN(0,1(1)). Speci for for simplicity. It is easy to see that Qn()Q(). Following the same argument of Wu (1981), we have in probability. By the denition of , we have Qn()/= 0. By Taylor expansion, we have 0 =Qn() =Qn() +2Qn() (), (a.11) where i.e. Et,m= 0. (a.13) 48Since ytis a strongly mixing process with exponential decreasing mixing coecients, so is t,m. By (C2), we have E||t,m||<. It follows from Theorem 2.21 of Fan and Yao (2005, pp. 75) that T t=1t/ TDN(0, k=0(k)). On the other hand, we have by (C3) and Proposition 2.8 of Fan and Yao Xt+k= that Yt=Xt+Nt. It follows that ( Xt, t, t) is a stationary process and a strongly mixing sequence (Pham and Tran, 1985) with exponentially decreasing mixing coecients, ) :=t, t1, ..., tm}, it is easy to see that tis also a strongly mixing sequence with exponentially decreasing mixing coecients. Note that Et= 0 and E|t|<for some >2. By Theorem 2.21 of Fan and Yao (2005, pp. 75), we have T t=1t/ TDN(0, k=0(k)). On the other hand, we have model = 0. Thus Bm(xt, t) are independent with expectation 0. It is easy to see that m,t=Cm(Xtk, tk)t+Bm(Xt, t) is a martingale dierence. The have T1/2()DN{0,1E(m,t m,t)1}. We have completed the proof. 2 51 "}