{"title": "PDF", "author": "PDF", "url": "https://researchmgt.monash.edu/ws/portalfiles/portal/418462295/392421154_oa.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "Original Paper Vaccine Adverse Event Mining of Twitter 1Centre for Health Analytics, Melbourne Children' s Campus, Melbourne, Australia 2Department of General Practice, University of Melbourne, Melbourne, Australia 3Department of Human-Centred Computing, Faculty of Information Technology , Monash University , Melbourne, Australia 4Department of Paediatrics, University of Melbourne, Melbourne, Corr esponding Author: PhD for Health Analytics Melbourne Children' s Campus 50 Flemington Rd Melbourne, act Traditional monitoring for adverse events following immunization (AEFI) relies on various established reporting systems, where there is inevitable lag between an AEFI occurring and its potential reporting and subsequent processing of reports. AEFI safety signal detection strives to detect AEFI as early as possible, ideally close to real time. Monitoring social media data holds promise as a resource for this. Objecti ve: The primary aim of this study is to investig ate the utility of monitoring social media for gaining early insights into vaccine safety issues, by extracting vaccine adverse event mentions (VAEMs) from Twitter , using natural language processing techniques. The secondary aims are to document the natural language processing techniques used and identify the most effective of them for identifying tweets that contain VAEM, with a view to define an approach that might be applicable to other similar social media surveillance tasks. Methods: A VAEM-Mine method was developed that combines topic modeling with classif ication techniques to extract maximal VAEM posts from a vaccine-related Twitter stream, with high degree of confidence. The approach does not require a targeted search for specif ic vaccine reaction-indicati ve words, but instead, identif ies VAEM posts according to their language structure. Results: VAEM-Mine method isolated 8992 VAEMs posts of 0.91 in the classif ication phase. Conclusions: Social media can assist with the detection of vaccine safety signals as a valuable complementary source for monitoring mentions of vaccine adverse events. A social media-based VAEM data stream can be assessed for changes to detect possible emer ging vaccine safety signals, helping to address the well-recognized limitations of passi ve reporting systems, including lack of timeliness and media; Twitter; machine learning JMIR Med Inform 2022 | vol. 10 | iss. 6 | e34305 | p. 1 https://medinform.jmir .org/2022/6/e34305 (page number not for TICS XSLFO RenderXIntroduction Backgr ound Vaccines belong to the broad category of medicines, in a subcate gory known as biolo gicals [1]. Unlik e medicines that are prescribed to limited populations as a course of treatment for a disease, vaccines are given to both health y and vulnerable populations at large, sometimes over a short period, to enhance their immune systems' ability to combat a pathogen. In contrast to those who are taking a medicine to help to cure a disease or to treat unwanted symptoms, most people recei ving a vaccine are not ill. Therefore, there is a deferred individual benef it to taking a vaccine, and, consequently , a very low acceptance of risk regarding vaccines [2]. In addition, the pathoph ysiology of vaccine-related adverse events is not as well defined as those of adverse drug reactions\u2014a reaction triggered by a vaccine could be caused by any of its multiple ingredients, its underlying technology (eg, messenger RNA-based vs protein-based delivery), or even an error in administration [3]\u2014and some people are particularly prone to reacting to vaccine ingredients [4]. Furthermore, a vaccine' s time to mark etmay be curtailed, such as has occurred during the COVID-19 pandemic, and so provide less opportunities for studying potential vaccine side effects over a large population for a long time. Vaccine safety relies upon rigorous compliance to development and manuf acturing standards, well conducted clinical trials, thorough assessment, licensing, control, and administration of vaccines. Postlicensure vaccine safety surveillance is a key component of ensuring vaccine safety [5] and continues in a variety of forms after regulatory appro val or emer gency use authorization. It is the primary mechanism to identify serious or rare adverse events following immunization (AEFI) that are unlik ely to have been exposed by prelicensure trials, and it allows surveillance in populations that were unable to be included in the trials [6]. Identif ication of minor AEFI is potentially as important as those of severe adverse events, as minor AEFI may act as a surrog ate warning for more severe sequelae (eg, increased rates of fever may be a mark er for increased febrile seizures [7])\u2014that is, increased incidences of even minor events could indicate larger problems. Traditional passi ve (spontaneous) surveillance systems, where a voluntary reporting of AEFI is made by individuals or by their treating health professionals, are the main method of vaccine safety monitoring and have proven to be useful in early detection of vaccine-related and drug-related safety issues [8,9]. Although these systems are the backbone of drug safety monitoring, they suffer from major disadv antages, including underreporting, incomplete data, and time lag between an event happening and subsequent reporting of it [10]. Active surveillance systems survey vaccine recipients and vaccine administrators to determine the outcomes of recent vaccinations, irrespecti ve of any AEFI experience. Increasingly , alternate data sources are being added to surveillance systems, as they offer the potential to capture timely and additional measurements of the quantity of possible adverse events. Extensi ve use of social media has provided a platform for sharing and seeking health-related information. Social mediadata have consequently become a widely used source of data for public health research [11]. In comparison with established traditional surveillance systems, social media monitoring is inexpensi ve and near to real time and covers large populations [12], thus offering an easily accessible wide-ranging data source for tracking emer ging trends\u2014which may be unavailable or less noticeable in data gathered by traditional reporting systems [13]. Many researchers have used social media as a pharmaco vigilance source [14]. However, there is relati ve deficit in the use of social media for AEFI detection. Many investig ations of vaccine and vaccination-related social media posts are related to sentiments, attitudes, and opinions [15-21]. Studies on using social media for detection of adverse drug reaction have included vaccine-related words in keyword searches used for collecting data. An example is an annotated data set of tweets containing 250 drug-related keywords, including vaccine , for over a period of 4 months [22]. We downloaded and assessed these data sets, but they did not contain any AEFI data. A total of 2 recent studies have focused on detecting influenza [23] and COVID-19 [24] vaccine adverse events from Twitter . However, the emphasis of both these studies were on identifying specif ic vaccine adverse events using a lexicon of adverse reactions. Objecti ves In this paper , we use the term vaccine adver se event mention (VAEM) to refer to anyvaccine-related personal health mention, that is, VAEMs are conversations that contain personal health mentions in a vaccine conte xt. This distinguishes VAEM from the AEFI and adverse drug reaction signals used in previous studies on the use of social media for vaccine and drug reaction surveillance, as these are searching for specif ic adverse vaccine events and drug reactions. Although vaccine safety surveillance systems monitor for unexpected, rare, and late-onset events, they also aim to observ e changes in the rate of known and expected events, because \"while rare but particularly serious events can be detected through review of each individual report or active surveillance, an increased incidence in a more common AEFI is often more difficult to detect, and has been described as akin to 'finding a needle in the haystack'\" [13]. VAEM are conversations, ideally gathered in volume, that contain information that may be the common AEFI that are so elusive to traditional reporting, while also allowing the detection of previously unkno wn severe events. This paper presents the VAEM-Mine method, which encapsulates the workflo w and techniques required to enable detection of VAEM by applying natural language processing techniques to a relati vely unfocused social media stream, consisting of any vaccine-related Twitter conversation. The VAEM-Mine method detects likely VAEM based on their characteristics of being personal health mentions in a vaccination conte xt. VAEM-Mine has 2 components\u2014a topic modeling process that initially detects and filters for VAEM (described in a previous publication [25]) and a classif ication task that accurately identif ies VAEM in the filtered data\u2014which is described in detail in this paper . JMIR Med Inform 2022 | vol. 10 | iss. 6 | e34305 | p. 2 https://medinform.jmir .org/2022/6/e34305 (page number not for MEDICAL INFORMA TICS XSLFO RenderXMethods Ethics Approval Ethics appro val for this study was granted by Monash University Human Research Ethics Committee (project ID 11767). Data Collection The Twitter application program interf ace was used to collect English tweets with search terms vaccination, vaccinations, vaccine , vaccines, vax, vaxx, vaxine , vaccinated, vaccinated, flushot, and flu shot. These were general terms that were designed to collect a broadly representati ve sample of vaccine-related conversations. We included flu shot as a keyword because we found that this was most often used, rather than the term flu vaccine , whereas other vaccines were usually mentioned in conjunction with the word vaccine \u2014and thus, for them, we only needed to search for vaccine keywords. Upon examining the downloaded data for specif ic vaccine names, we found more records mentioning other vaccines than those mentioning the influenza vaccine. No specif ic reaction mentions were used. A total of 400,000 tweets were initially collected across 5 months, from February 7, 2018, to June 7, 2018, which wereused for an initial training and evaluation of topic models and classif iers. An additional 411,010 tweets were collected from August 9, 2018, to July 20, 2019, which were used to verify the trained topic models and classif iers and to train more powerful classif iers. The resulting data consisted of a total of 811,010 tweets and a daily average of 2906 tweets. The data were prepared by remo ving URLs and by converting to lower case. Duplicates were remo ved based on tweet ID and text. Other preparation included remo ving hashtags, punctuation, remo ved. N-grams were created for topic modeling; preparation for classif ication is explained in the following section. The final cleaned tweets were 82.21% (328,822/400,000) of the initial collection and 87.48% (359,535/411,010) of the second collection\u2014a total of 688,357. Table a sample of tweets that mention recei ving vaccinations or vaccines. The first 3 examples contain genuine VAEM, but the others do not\u2014e ven when the language is similar . Our goal was to first isolate the most likely records describing personal experiences of vaccination and then to refine that selection to those that are genuine adverse reaction mentions. Table 1. Sample of vaccine-related tweets. Type Tweet VAEMa \"Aw wtf my af my flu shot.\" VAEM \"Cannot lie on belly , baby gets squished; cannot lie on back, baby squishes; cannot lie on right side, i get heartb urn; cannot lie on left side, vax arm is sore; let the third trimester moaning begin!\" VAEM \"2 people recently , including my 88yo father , had flu shot and really bad reaction afterw ards. both said it was probably as bad as getting the flu!!! flu2018 maybe undercook ed the vaccine. \" Non-V AEM \"I got vaccinated as a kid. As a result, I'm now starting to gray and bald. My balding got so bad I had to shave my head. I've also gained weight. Because of vaccines I've started aging instead of dying as a baby .\" Non-V AEM \"Urgent vaccination plea after measles outbreak in West Yorkshire. \" Non-V AEM \"Researchers are developing a personalized vaccine which they hope could tackle ovarian cancer .\" aVAEM: vaccine adverse event mention. The topic modeling showed that VAEM and similar personal health mentions were a distinct topic (among 13 vaccine-related topics), and therefore, that topic models could be used to filter for the tweets that were most similar to VAEM. Taking tweets from only that topic meant that relati vely homogenous data sets could be created for labeling and subsequent training of classif iers. The use of topic modeling for filtering data before classif ication was adopted as a core component of the VAEM-Mine method. A previous publication [25] described the process of choosing the best performing topic models for the method, including a detailed description of the scoring method used to identify the best models. Classif ication Overview As described in the previous section, data were collected in 2 phases. Topic models were trained on the first-phase data and were used to filter that data and the subsequent second-phasedata into likely VAEM-containing data sets, which were then used for classif ication. Classif iers were trained and assessed with the filtered first-phase data set and the combined (filtered) first-phase and second-phase data sets. The following section describes the creation of these data sets; the subsequent section describes the classif iers. Classification Data Sets The original prepared (cleaned) data collections of 328,822 and 359,535 tweets were reduced, by applying topic model-based filtering, to data sets containing 18,801 (5.72%) and 80,372 (22.35%) tweets that were more likely to contain VAEMs\u2014a total of 99,173 tweets, which was only 14.41% (99,173/688,357) of the total original cleaned data. Therefore, filtering eliminated approximately 85.59% (589,184/688,357) of the data, which did not contain any signif icant numbers of VAEM. These more VAEM-focused data sets were binary labeled by the author (SKH), as either JMIR Med Inform 2022 | vol. 10 | iss. 6 | e34305 | p. 3 https://medinform.jmir .org/2022/6/e34305 (page number not for MEDICAL INFORMA TICS XSLFO RenderXVAEM or non-V AEM. All the labels were verified by the domain expert. Although only 10.07% (9991/99,173) of the tweets were identif ied as VAEM, this was a considerably better proportion of VAEM compared with the original cleaned data, which contained VAEM in only 1.45% (9991/688,357) of the tweets. Balanced data of 18.72% (3519/18,801) and 19.57% (15,730/80,372) of the tweets were created from these imbalanced data sets together with holdout test data sets\u2014these were an imbalanced test set of 3.27% (614/18,801) of the tweets and a balanced test set of 1.03% (828/80,372) of the tweets. The main data sets were named Phase-One and Phase-T wodata sets, and the test data sets were referred to as Phase-One Test and Phase-T wo Testdata sets.The imbalanced set of 3.27% (614/18,801) of the tweets were obtained from Victoria, Australia, in the period preceding and during the 2018 influenza immunization period. These tweets were assembled to enable comparison of tweet trends with statistics from the Australian Victorian vaccine authority , Surveillance of Adverse Events Following Vaccination In the Community . With 90 VAEM and 524 non-V AEM, the test set was imbalanced but reflected how the data were obtained through the topic model filtering process, without any subsequent balancing. The Phase-One Test data set was used as a benchmark throughout the classif ication testing. The data sets (Table 2) were combined to retrain classif iers and train transformer -based classif iers\u2014becoming a Combined data set of 19,249 tweets and a Combined Testdata set of 1442 tweets. The training data were split into training and validation data with a 75:25 ratio. Table 2. Data set numbers. Total, n Phase-T wo data, n (%) Phase-One data, n (%) After topic modeling 78,482 63,814 (81.31) 14,668 (18.69) (42.58) For testing Classifiers Our default data approach with traditional models (ie, not neural netw ork-based) was bag-of-wor ds[26], vectorizing libraries such as lowercase text for the standard classif iers. A grid or random search was used to ascertain the best combinations of vectorizer , remo val of stop words and numbers, and n-grams. The neural netw orks used dense word embedding the Word2V ec corpus used Gensim library functions [30] using all the Twitter data. The models used byte-pair -encoding [31]; the byte-pair -encoding tokens were derived only from the filtered texts we had retained from topic modeling. The classif iers are listed in Table 3, and details of their definitions and parameters are listed in Multimedia Appendix 1. JMIR Med Inform 2022 | vol. 10 | iss. 6 | e34305 | p. 4 https://medinform.jmir .org/2022/6/e34305 (page number not for TICS Regression Language Model. VAEM-Mine Method The classif ication models were the final component of a pipeline named the VAEM-Mine method (Figure 1), consisting of processes that started with data collection and cleaning, followed by processing through topic models to filter for data that were as close as possible to the VAEM, and then, a focused binary classif ication approach for isolating VAEM. The method included decision points to determine the appropriate direction, either the training process or the application of the trained models to incoming data. At the beginning of the topic modeling phase, a trained model did not exist; thus, the work of training the topic models began. The first step was to label some examples of the subject of interest (in this case, VAEM) and additional examples of other subjects. This enabled the application of a topic modeling scoring, whichmeasured how the VAEM-label of interest was distrib uted in the topics, compared with other labeled topics. A topic model was considered to score well if the VAEM were concentrated in only a few topics, and ideally in only 1 topic, with minimum data belonging to the other labels. Further refinement of the data was possible by a second stage of topic modeling on the data obtained from the top model of the first stage. The second stage identif ied topics that had a high ratio of VAEM to other subjects in the texts, but at the expense of losing some texts containing VAEM. Having trained the models, they could be applied to filter the incoming data, and it was up to the user whether they take only the output of the best topic (or topics) of the first-stage topic model or further refine the data by taking it from selected topics of the second-stage topic model. The topics of the first stage of topic modeling were also potentially useful to obtain a domain taxonomy . JMIR Med Inform 2022 | vol. 10 | iss. 6 | e34305 | p. 5 https://medinform.jmir .org/2022/6/e34305 (page number not for JMIR MEDICAL INFORMA TICS XSLFO RenderXFigur filtered data were handled by the classif ication phase, which also had the decision point for either training classif iers or using trained classif iers. When training, the choice of classif iers should relate to the quantity of available data, and if results are not as expected, a decision may be made to obtain more data. The method required the incoming filtered data to be labeled for the creation of data sets suitable to train the classif iers. It additionally required the creation of domain-specif ic embeddings. The VAEM-Mine method can be adopted as aworkflo w to tackle any similar task of identifying personal health mentions. Results Classif ication Analysis Classif ication training and evaluation was conducted twice; first, with the filtered data that were obtained from applying topic modeling to the initial phase of data collection and then, with the data obtained through topic model filtering over all the JMIR Med Inform 2022 | vol. 10 | iss. 6 | e34305 | p. 6 https://medinform.jmir .org/2022/6/e34305 (page number not for JMIR MEDICAL INFORMA TICS XSLFO RenderXcollected data. The following sections these as Phase-One and Phase-T wo classif ication. Phase-One Classification The first phase of classif ication experiments used a training set of 2639 records, a validation set of 880 records, and theimbalanced holdout Phase-One Test data set of 614 tweets. The F1scores for the models evaluated in this phase are listed in Table 4. Table 4. Phase-One F1 scores. Combined test Balanced test Descent. Support Vector Machine. lXGBoost: Extreme Gradient Boosting. Table 4includes subsequent tests of the models against the Phase-T wo Balanced testdata set and a Combined Testdata set that uses all the test data. F1scores were measured for the positi ve, VAEM class, rather than for both classes. The models are arranged in order of the best F1score over the test data sets; validation scores are also included, where available. Validation F1scores are not available for models using transfer learning\u2014the y used a cross-v alidation approach, and thus, weregiven combined training and validation data and were evaluated only against test data sets. The Ensemble model shown in the middle of Table 4was scored based on a maximum voting of the predictions of 5 traditional classif iers on the test data set\u2014consisting of the Na\u00efve Bayes Support Vector Machine, Linear Regression Cross Validation, Stochastic Gradient Descent, Linear Support Vector JMIR Med Inform 2022 | vol. 10 | iss. 6 | e34305 | p. 7 https://medinform.jmir .org/2022/6/e34305 (page number not for and Random Forest classif iers. It had the overall best score among the traditional classif iers on the large test data. All the deep learning models outperformed the best traditional classif ier on the Imbalanced Testdata set, by at least 6% and almost as much as 10%\u2014the impro vement was mostly owing to great capacity to correctly distinguish non-V AEM-related tweets, and thus obtain a greater precision. However, when evaluated against the Balanced and Combined Testsets, the results differed\u2014here, the traditional classif iers outperformed many of the deep learning models, especially the Ensemble, which was only surpassed by the top 3 deep learning models. Phase-T wo Classification The second phase of classif ication used 5 times as many records to train the models, by combining the 3519 training records from the first phase with another 15,730 records, resulting in a total of 19,249. Phase Two also introduced a large, more balanced test data set of 828 records. The greater amount of data allowed a proper assessment of neural netw orks, but it also impro ved model performance across the board (Table 5). The imbalanced chang eand combined chang ecolumns show the percentage increase in the models' F1score over the Imbalanced Testand Combined Testdata sets, compared with their Phase-One equivalents.There was a much greater consistenc y of scoring over all the test data sets, and the top models scored best over all the test data sets. The highest score was from the Robustly Optimized Bidirectional Encoder Representations Pretraining Approach (RoBER Ta) Large Transformer model, with an F1score of 0.919 on the Imbalanced data set; the standard RoBER Ta model was placed second. One of the most noteworthy effects of having more data was that the previously strong combinations of CNN with Bidirectional Gated Recurrent Unit and Bidirectional LSTM models were surpassed by the LSTM on the Imbalanced Test data set, both when combined with a CNN but most signif icantly as a stand-alone model. The LSTM in fifth position on the imbalanced test scoring was only 2.5% behind the score of the RoBER Ta Large model. One can fairly conclude that a CNN or hybrid CNN approach performs well when limited data are available but will likely be surpassed by architectures designed for sequential language processing as more data become available. A detailed analysis of the classif iers' performance is provided in Multimedia Appendix 2. JMIR Med Inform 2022 | vol. 10 | iss. 6 | e34305 | p. 8 https://medinform.jmir .org/2022/6/e34305 (page number not for MEDICAL INFORMA TICS XSLFO RenderXTable 5. Phase-T wo F1 scores. Combined change, % Imbalanced change, % Combined test Balanced test Imbalanced test bN/A: not applicable. cChange calculation was not performed because no previous figures existed. dXLNet: Generalized Autore gressi ve Pretraining Memory : Regression Cross Gradient Boosting. JMIR Med Inform 2022 | vol. 10 | iss. 6 | e34305 | p. 9 https://medinform.jmir .org/2022/6/e34305 (page number not for JMIR MEDICAL INFORMA TICS XSLFO RenderXVAEM-Mine Method Performance Here, we assess the overall effectiveness of the method, regarding the quantities of tweets having VAEMs that were progressi vely filtered out by the method. The values presented are the total numbers of tweets collected and processed via the method, with estimates where appropriate. Topic Modeling Phase Table 6depicts the numbers obtained from after data collection to the completion of the topic modeling. From the original811,010 records, 122,653 (15.12%) records were remo ved by data cleaning, and topic modeling was used to process 688,357 (84.87%) records. Stage 1 of topic modeling filtered out 82.86% (570,383/688,357) of the records to retain 17.14% (117,974/688,357) of the records likely to contain VAEM. The data were approximately 14.55% (117,974/811,010) of the original total and contained >99% of all the available VAEM (Multimedia Appendix 3). Table 6. Summary of topic modeling counts (N=811,010). Counts, n (% of initial data) Steps 811,010 (100) Tweets collected proportions\u2014non-v data; 1.23% of initial data). adverse event mention proportions\u2014in other stage 2 topics: 2367 and in best stage 2 topic: 7624 (76.31% of vaccine adverse event mention). To prepare for the first round of classif ication, additional 19,083 records were discarded\u2014those which were not in the top 3 topics of the stage 2 topic model. Subsequent labeling of the discarded topic most likely to contain VAEM (based on the distrib ution of topic model labels) showed only 1.49% (94/6274) of VAEM in the data, which was approximately 5.15% (94/1826) of the VAEM in the first round. For the second round of classif ication, all the records that were identif ied as likely VAEM by the topic model were retained. The resulting 12.19% (98,891/811,010) records retained over both rounds of topic modeling were labeled, and VAEM were found to be 10.10% (9991/98,891) of the retained data. The stage 2 topic models' topic numbers were assessed, and it was found that the best stage 2 topic of 14,498 tweets contained 76.31% (7624/9991) of the retained VAEM, were approximately 11.10% (7624/6874) more VAEM than non-V AEM in the topic. From these figures, we conclude that topic modeling is an effective filtering mechanism, as it identif ied approximately all the VAEM, while remo ving a lot of unwanted data. The filtered data were more manageable for labeling for classif ication than it would have otherwise been, and if needed, the filtered output of the stage 2 topic model can be used as it is, with the understanding that it discards some VAEM and still contains a small but similar number of non-V AEM. However, as discussed previously , classif ication is a more precise final step to obtain VAEM from the filtered records. Classification Phase To assess classif ier effectiveness regarding the total data, the recall and precision of the best classif ier, the RoBER Ta Largemodel, were applied to the total VAEM to obtain an estimate of its performance on the total VAEM. These were a precision score of 0.874 and a recall score of 0.948 for the combined test data: 1.Applying the recall score of 0.948 to the total 9991 VAEM-containing tweets, we estimate that (9472/9991) of would be correctly classif ied and 5.19% (519/9991) of the VAEM would be missed. 2.We find that 1.54% (1370/88,900) of the non-V AEM tweets would be added to the 9472 tweets to match to the precision score of 0.874 (9472/10,842). 3.These results of 94.81% (1370/88,900) of the non-V AEM in the predicted positi ve class were clearly superior to those obtained with the best topic of stage 2 topic modeling, where we saw the proportion of VAEM in the best topic was 76.31% (7624/9991) and the almost equal number of non-V AEM in the topic was approximately 7.70% (6847/88,900) of the non-V AEM. Combined Topic Modeling and Classification Effectiveness By measuring the combined effectiveness of topic modeling and classif ication, the following results are estimated: 1.As explained in Multimedia Appendix 3, counts of VAEM identif ied via topic modelling were estimated to be 99% of all likely VAEM; therefore, with 99% being represented as a count of 9991 VAEM, it is estimated that 10,090 VAEM originally existed. JMIR Med Inform 2022 | vol. 10 | iss. 6 | e34305 | p. 10 https://medinform.jmir .org/2022/6/e34305 (page number not for TICS XSLFO of 8992 VAEM are estimated to be identif ied via the combined effects of cleaning, topic modelling, and classif ication from the original 811,010 records, being at least 89.11% (8992/10,090) of all likely VAEM and 1.11% (8992/811,010) of the original data. A total of 98.89% (802,018/811,010) of the data were eliminated through cleaning, topic modeling, and classif ication. Totally , around 11% (1098/10,090) of the VAEM were also eliminated during this processing; the attrition is a consequence of the filtering and classif ication required to capture the estimated 89.12% (8992/10,090). 3.Overall, 98.89% (802,018/811,010) of data were eliminated as not containing VAEM, with a very small amount misidentif ied, to identify 1.11% (8992/811,010) of the data as having VAEM, with 90% success. The results indicate that the combined approach of topic modeling followed by classif ication effectively identif ies and isolates VAEMs from approximately all other vaccine-related Twitter posts. The VAEM-Mine method enables us to identify the most effective topic models and classif iers for the core task of isolating VAEM. In particular , the key to the method' s success is the topic modeling phase, which drastically reduces the amount of irrele vant data and thus delivers manageable data to the classif ication phase. As natural language processing technologies impro ve and new topic models and classif iers can be introduced, we assume that even these results will impro ve. Discussion The key objecti ve of this study was to contrib ute to research on vaccine safety surveillance, by illustrating that social media monitoring has the potential to augment existing surveillance systems. We have demonstrated a topic modeling and classif ication VAEM-Mine method for identifying VAEM with high degree of sensiti vity and specif icity following vaccination. Principal Findings The VAEM-Mine method approached the problem of finding sparse VAEMs by using topic modeling followed by classif ication. Topic modeling identif ied texts based on their semantic and syntactic nature. Then, it was used to extract those tweets that predominantly describe personal health issues in relation to vaccines. Classif ication identif ied VAEMs from the filtered texts with high degree of accurac y. Neither of the machine learning components were explicitly trained on specif ic reaction keywords, instead they identif ied texts owing to their innate capacity to detect patterns in language structure. Other studies on detecting influenza [23] and COVID-19 [24] have required purpose-b uilt machine learning classif iers that identify specif ic adverse event reactions from tweets. Their classif iers were trained to identify known reaction keywords derived from medical databases. Our approach relies on language features of the tweets to elicit the likely cohort and the power of modern transformer classif iers to determine the true signals. By tackling the problem of finding adverse events through the lens of the language used in personal healthmentions, we conclude that social media can provide a wealth of useful data. The VAEM-Mine method has signif icant capability to successi vely isolate from the massi ve amount of other vaccine-related Twitter posts. The topic modeling phase could isolate up to 99.02% (9991/10,090 [estimated]) of the Twitter posts that contained VAEM. The data identif ied by Stage 1 topic modelling as likely containing VAEM were only 14.55% (117,974/811,010) of the original data, thereby eliminating 85.45% (693,306/811,010) mostly irrele the 9991 VAEM with an F1score of 0.91. The combination of topic modelling and classif resulted in (8992/10,090 [estimated]) of the VAEM. Training the topic modeling component of the method is enabled by identifying the most effective topic models by using F1 scoring over a small number of labeled posts\u2014the scoring identif ies when topic models are most effective at grouping labeled VAEM into a topic. The topic modeling scoring method is an important contrib ution of this study . This study also presents detailed reporting, including comparisons, on a range of classif ication models, including traditional machine learning models and deep neural (deep learning) netw orks. Their effectiveness was measured against different-sized data sets, emulating data sizes that are likely to be available to other researchers [43], and we used charts (Multimedia Appendix 2) to illustrate how the amount of training data affects model recall and precision. Limitations There are unavoidable issues and potential biases that result from using any social media data. A limitation of this study is the use of only English-language tweets as data source; the approach needs to be validated by using other social media data sources and other languages. Although the data collection for this study spanned a year and included some potential trend patterns during influenza seasons, a long-term data collection would be better for any analysis of trends. At the time of the study , a full year' s data were required to properly train and evaluate the classif iers\u2014this was in part because of the limited pipeline of the Twitter application program interf ace and because data collection was from a period before the COVID-19 pandemic and signals were correspondingly less frequent compared with those found during the COVID-19 vaccines rollout. However, the proposed VAEM-Mine method can identify VAEM with F1score of 0.91 and is applicable to any similar problem of detecting personal health mentions in social media posts based on the language of conversations. Conclusions and Futur e Resear ch We have determined that the VAEM-Mine method is an effective approach for both identifying and applying the topic models and classif iers that, when combined, can filter out the vast amount of irrele vant vaccine-related conversations and isolate VAEMs. JMIR Med Inform 2022 | vol. 10 | iss. 6 | e34305 | p. 11 https://medinform.jmir .org/2022/6/e34305 (page number not for TICS XSLFO RenderXA key contrib ution of this study is that appropriately scored topic modeling is highly effective for identifying social posts that might contain VAEM. The technique of F1scoring of topic models based on a small number of labeled posts, identif ied in this study , is practical and easily implementable and can be used by other researchers to assist with identifying topic models that group texts on specif ic language features. The volume of social media posts regarding the current COVID-19 pandemic is immense, but those that are related to personally experiencing illness owing to the virus or vaccines are a small portion of these; however, they contain similar language. Currently , we are applying the VAEM-Mine method to both internally gathered and published [44] COVID-19vaccine-related Twitter data sets to examine trends in VAEM reporting. There are several ways in which the identif ied VAEM posts can be used for vaccine safety signal detection. Among them are (1) examining individual posts by domain experts; (2) further classifying the posts to identify adverse events of special interest, which include vascular , neurological, or allergic disorders and enhanced disease; and (3) measuring changes of post volumes that might indicate unfolding events. This paper interprets the success of the VAEM-Mine method in terms of percentages of data captured by the method and compares classif iers in terms of F1scores. Future studies can analyze the method' s success in terms of model explainability [45]. Ackno wledgments The authors would like to thank Christopher Palmer for providing technical advice for the project. This study did not recei ve any specif ic grant from funding agencies in the public, commercial, or not-for -prof it sectors. Conflicts of Inter est None declared. Multimedia Appendix 1 Model definitions and parameters. [DOCX File A, Wertheimer AI. Vaccines and drugs: characteristics of their use to meet public health goals. Health, Nutrition, and Population, The World Bank. Gould Szarfman A, Hauben M, Ouellet-Hellstrom R, et al. Perspecti ves on the use of data mining in pharmaco-vigilance. Drug Saf 2005;28(11):981-1007. [doi: 10.2165/00002018-200528110-00002 ] [Medline: 16231953 ] 4. Agmon-Le vin N, Paz Z, Israeli E, Shoenfeld Y. Vaccines and autoimmunity . [doi: 10.1038/nrrheum.2009.196 ] 19865091 ] 5. Griffin MR, Braun MM, Bart KJ. What should an ideal vaccine postlicensure safety system be? Am J Public 2:S345-S350. Zuber PL, Weibel DM, Enhancing vaccine safety capacity globally: AC, Enticott J, Lawrie J, Buttery JP. Use of telephone helpline data for syndromic surveillance of adverse events following immunization in Australia: a retrospecti ve study , 2009 to AC. Pharmaco vigilance: methods, recent developments and future Med Inform 2022 | vol. 10 | iss. 6 | e34305 | p. 12 https://medinform.jmir .org/2022/6/e34305 (page number not for JMIR MEDICAL INFORMA TICS XSLFO RenderX9. Clothier HJ, Crawford N, Russell MA, Buttery JP. Aller gic adverse events following 2015 seasonal influenza vaccine, Victoria, Australia. Euro Surveill 2017 Falzon D, Olsson S. WHO strate gy for collecting safety data in public health programmes: complementing spontaneous reporting systems. Drug Saf [doi: 10.1007/s40264-012-0014-6 ] [Medline: 23329541 ] 11. Conw ay M, Hu M, Chapman WW. Recent advances in using natural language processing to address public health research questions using social media and consumer generated data. Yearb Med Inform 2019 Aug;28(1):208-217 [FREE Full M. Social Monitoring for Public Health. In: Dredze M, Paul MJ, editors. Synthesis Lectures on Information Concepts, Retrie val, and Services. Williston, VT, USA: Morgan and Claypool Publishers; Aug 31, 2017:1-183. 13. Clothier HJ, Lawrie J, Russell MA, Kelly H, Buttery JP. Early signal detection of adverse events following influenza vaccination using proportional reporting ratio, Victoria, Australia. PLoS One 2019 Nov 1;14(11):e0224702 [FREE F, Asfari H, Souvignet J, Texier N, et al. Adverse drug reaction identif ication and extraction in social media: a scoping review. J Med Internet Res 2015 Salath\u00e9 M, Khandel wal S. Assessing vaccination sentiments with online social media: implications for infectious disease dynamics and control. ] Larson HJ, Smith DM, Paterson P, Cumming M, Eckersber ger E, Freifeld CC, et al. Measuring vaccine confidence: analysis of data obtained by a media surveillance system used to analyse public concerns about vaccines. Lancet Infect Dis 2013 Jul;13(7):606-613. [doi: 10.1016/S1473-3099(13)70108-7 ] [Medline: 23676442 ] 17. Du J, Xu J, Song HY, Tao C. Leveraging machine learning-based approaches to assess human papilloma virus vaccination sentiment trends with Twitter data. BMC Med Jamison A, Quinn SC, Broniato wski DA. Characterizing trends in Reddit an observ A, Crooks Delamater PL. The measles vaccination narrati ve in Twitter: a quantitati ve analysis. E, Clijnk R, De Melk er H, Paulussen T, et al. Disease detection or public opinion reflection? Content analysis of tweets, other social media, and online newspapers during the measles outbreak in The Netherlands in 2013. J Med Internet Res 2015 May 26;17(5):e128 [FREE Full Nguyen DQ, Kennedy G, Johnson M, Coiera E, Dunn AG. Characterizing Twitter discussions about HPV vaccines using topic modeling and community detection. J Med Internet Res 2016 Aug 29;18(8):e232 [FREE Full Gonzalez G. Portable automatic text classif ication for adverse drug reaction detection via multi-corpus training. Biomed Inform 10.1016/j.jbi.2014.11.002 ] [Medline: 25451103 J, Zhao L, Ye Y. Semi-supervised multi-instance interpretable models for flu shot adverse event detection. In: Proceedings of the 2018 IEEE International Conference on Big Data. 2018 Presented at: BigData '18; December 10-13, 2018; Seattle, WA, USA p. 851-860. [doi: 10.1109/bigdata.2018.8622434 ] 24. Lian AT, Du J, Tang L. Using a machine learning approach to monitor COVID-19 Vaccine Adverse Events (VAE) from Twitter data. Vaccines Twitter . In: Proceedings of the Australasian Computer at: ] 26. Zhai CX, Massung S. Text Data Management and Analysis. San Rafael, CA, USA: Morgan & Claypool Publishers; Jun 30, 2016:88-94. 27. Gramfort A, Michel V, Thirion B, Grisel O, et al. Scikit-learn: machine learning in Python. J Mach Learn Res Chen K, Corrado G, Dean J. Efficient estimation of word representations in vector space. In: Proceedings of the International Conference on Learning Representations. 2013 Jan 16 Presented at: ICLR Med 2022 | vol. 10 | iss. 6 | e34305 | p. 13 https://medinform.jmir .org/2022/6/e34305 (page number not for TICS XSLFO RenderX30.ehek R, Sojka P. Softw are frame work for topic modeling with large corpora. In: Proceedings of LREC 2010 workshop New Challenges for NLP Frame works. 2010 Presented at: LREC A. Neural machine translation of rare words with subw ord units. In: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. 2016 Presented at: ACL '16; C. XGBoost: a scalable tree boosting system. In: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Disco very and Data Mining. 2016 Presented at: KDD '16; August 13-17, 2016; San F, Lerer A, Bradb ury J, Chanan G, et al. PyTorch: an imperati ve style, high-performance deep learning library . In: Proceedings of the Advances in Neural Information Processing Systems 32. 2019 Presented at: NeurIPS '19; December 8 - Sanh V, Chaumond J, Delangue C, Moi A, et al. HuggingF ace's transformers: state-of-the-art natural language processing. [FREE Full text] [doi: 10.18653/v1/2020.emnlp-demos.6 ] 43. Magge A, Miranda-Escalada A, Al-Garadi MA, Alimo va I, Miftahutdino v Z, et al. Overvie w of the Sixth Social Media Mining for Health Applications (#SMM4H) Shared Tasks at NAACL 2021. In: Proceedings of the Sixth Social Media Mining for Health (#SMM4H) Workshop and Shared Task. 2021 Presented at: NAACL '21; 10, 2021; ] J, Axelrod D, N, et al. CoVaxxy: a collection of English-language Twitter posts about COVID-19 vaccines. In: Proceedings of the 15th International AAAI Conference on Web and Social Media. 2021 Jan Presented at: AAAI '21; June 7-10, 2021; Virtual p. 992-999. 45. Burkart N, Huber MF. A survey on the explainability of supervised machine learning. J Artif Bidirectional Encoder Representations Pretraining Approach VAEM: vaccine adverse event mention Edited by C Lovis; submitted 16.10.21; peer-reviewed by H Ayatollahi, F Velayati, M Elbattah, D Huang; comments to author 02.01.22; revised version received accepted vol. 10 | iss. 6 | e34305 | p. 14 https://medinform.jmir .org/2022/6/e34305 (page number not for This is an open-access article distrib uted under the terms of Commons Attrib ution License (https://creati vecommons.or g/licenses/by/4.0/), which permits unrestricted use, distrib ution, and reproduction in any medium, provided the original work, first published in JMIR Medical Informatics, is properly cited. The complete bibliographic information, a link to the original publication on https://medinform.jmir .org/, as well as this copyright and license information must be included. JMIR Med Inform 2022 | vol. 10 | iss. 6 | e34305 | p. 15 https://medinform.jmir .org/2022/6/e34305 (page number not for "}