{"title": "How 'men as default humans' threatens to undermine precision medicine", "author": "Swissinfo Ch; Clare O'Dea", "url": "https://www.swissinfo.ch/eng/sci-tech/why-sex-differences-matter-in-precision-medicine/45848036", "hostname": "swissinfo.ch", "description": "Humans have developed advanced technologies like artificial intelligence but failed to account for sex differences when training them.", "sitename": "swissinfo.ch", "date": "2020-06-21", "cleaned_text": "small doses](/eng/innovation-in-women-s-health-comes-in-small-doses/46302328) How 'men as default humans' threatens to undermine precision medicine While humans are clever enough to develop advanced technologies like artificial intelligence, they are failing to consider that sex differences matter in training those technologies for use in healthcare. Precision medicine takes account of health and disease differences between individuals that are due to genetic and environmental factors, and is said to be the next big thing in healthcare. Used well, it should mean that patients will benefit from tailor-made prevention, diagnosis and treatment. Chemotherapy, for example, is becoming much more targeted, with drugs developed for specific cancer types with certain genetic characteristics. Doctors will test patients for that specific genetic mix and only give the drug to those who have it. Apart from genetic testing, precision medicine also draws on electronic health records, big data analytics, and supercomputing. But flawed data threatens to prevent precision medicine from fulfilling its potential. One of the main obstacles is the historical blind spot towards women's bodies in medical research, among other issues. \"The problem is not just limited to how an algorithm is designed but also the sex and gender biases that reside in the data that is used,\" explained Davide Cirillo, co-author of a recent review published by the Women's Brain Project. 'A call to responsibility' The Women's Brain Project (WBP) is a Swiss-based non-profit organisation which aims to understand how sex and gender differences have an impact on brain and mental diseases. The organisation has raised a warning flag to the scientific community to take care not to import all the faults of contemporary society and medicine, such as the under-representation of women in clinical trials, into the next generation of medical care. \"When we develop AI solutions for health, we should have an ethical committee assessing the benefit and the risk as well the possibility of generating discrimination by its application in the same way as it is done for drug development,\" Antonella Santuccione Chadha, CEO of the WBP told swissinfo.ch. In the systematic review published in [NPJ Digital MedicineExternal link](https://www.nature.com/articles/s41746-020-0288-5) this month, representing two years of work, Cirillo, Silvina Catuara-Solarz and nine other researchers, have issued \"a call to responsibility\". \"The presence of artificial intelligence is so pervasive in our everyday life that we cannot just ignore the impact that the technology is having in our society, especially concerning medical research and decision-making in healthcare,\" said Cirillo of the Barcelona Supercomputing Centre. The review looked at big data, natural language processing and robotics, all of which experts predict will intrude into or enhance our lives more in the near future, depending on your perspective. Double-edged sword WBP researchers describe artificial intelligence as a double-edged sword. Deployed correctly, it could solve the problem of male-centric healthcare, in which women's heart attack symptoms, for example, are overlooked, or medicines are released to the market that have disproportionately adverse side effects for women. There is an opportunity here to mitigate inequalities by effectively integrating sex and gender differences into healthcare. Biomedical and clinical Big Data, for instance, have the potential to provide deeper insights into health and disease at an unprecedented scale. Yet, the initial signs are not good. Despite the significant scientific advances achieved so far, most of the currently used biomedical AI technologies do not account for bias detection, the review says. \"If these technologies are developed without removing the sex and gender biases that exist in the world, they can actually magnify and perpetuate some inequalities and stereotypes,\" neuroscientist Catuara-Solarz said, speaking at a [WBP webinarExternal link](https://youtu.be/-ZDdIjNkAVA) where the authors presented their findings. Sub-optimal results So what does this mean in practice? \"Failure in accounting for these differences will generate sub-optimal results and produce mistakes as well as discriminatory outcomes,\" the review said. Take Alzheimer's Disease, for example. More women suffer from Alzheimer's than men and symptoms and age of onset differ between the sexes. Yet clinical trials have historically been carried out on mostly male subjects. Using data based predominantly on male subjects to develop an AI-based screening system for Alzheimer's means it will not be as effective or helpful for women. Imagine this on a much wider scale. Evidence of sex and gender differences has been reported in a range of chronic diseases from diabetes to cardiovascular disorders to neurological diseases, not to mention mental health disorders, cancers, and autoimmunity. There are also lifestyle factors that are associated with sex and gender, such as diet, physical activity, tobacco use and alcohol consumption, which correlate with the epidemiology of diseases. Default humans In her 2019 book Invisible Women, Caroline Criado Perez focuses on the problems caused by the female data gap in many aspects of society. She writes of overwhelming evidence that women are being let down by the medical establishment. \"The bodies, symptoms and diseases that affect half the world's population are being dismissed, disbelieved and ignored. And it's all a result of the data gap, combined with the still prevalent belief, in the face of all the evidence that we do have, that men are the default humans.\" The WBP researchers, led by Santuccione Chadha, talk about desirable and undesirable biases in AI implementations that inform precision medicine. Desirable bias means using the available information about differences to provide effective treatments for each sex. Undesirable biases miss these differences and include claims which are based on insufficient or skewed evidence. Take the example of depression. Epidemiological studies indicate that there is a higher prevalence of depression among women. But this may be the result of clinical scales of depression measuring symptoms that occur more frequently among women. A level of nuance is required to properly interpret sex and gender difference in a way which will have a positive impact on patient wellbeing and access to healthcare. It is in everyone's interest that this work is carried out. To that end, the WBP is holding an international forum on women's brain and mental health in Zurich in September to further explore sex and gender differences as a pathway towards precision medicine. In compliance with the JTI standards More: [SWI swissinfo.ch "}