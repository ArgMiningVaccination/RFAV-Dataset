{"title": "A transformative training initiative", "author": "Ysis Gregory", "url": null, "hostname": null, "description": null, "sitename": null, "date": "2023-09-04", "cleaned_text": "an intended audience of around half a million civil servants of all skills levels. It is designed to equip civil servants with the skills they need to navigate the modern challenges of governance in line with the [Modern Civil Service reform missions](https://moderncivilservice.blog.gov.uk/2023/07/19/how-the-civil-service-is-changing-to-deliver-better-services-for-all/). Building data literacy and data science skills is at the heart of what we do through our [community](https://datasciencecampus.ons.gov.uk/capability/cross-government-and-public-sector-data-science-community/), [faculty](https://datasciencecampus.ons.gov.uk/capability/data-science-campus-faculty/), programmes and training initiatives, including our [Data Science Graduate Programme](https://datasciencecampus.ons.gov.uk/capability/data-science-graduate-programme/), [Data Science Accelerator](https://datasciencecampus.ons.gov.uk/capability/data-science-accelerator/), [Master's in Data Analytics for Government (MDataGov)](https://datasciencecampus.ons.gov.uk/capability/msc-in-data-analytics-for-government/) and [Data Masterclass](https://datasciencecampus.ons.gov.uk/capability/data-masterclass-for-senior-leaders/). This is why we were thrilled to get involved in creating nine practitioner-level data training modules for One Big Thing this year. The modules cover a wide range of topics, including data ethics, data storytelling, data quality and much more. You can access these modules through your [One Big Thing account](http://onebigthing.civilservice.gov.uk) from 4 September. Anna Kwiatkowska, Deputy Director for Data Science at HM Revenue and Customs We couldn't have done this without the contributions of our brilliant speakers who have generously shared their time, insights and knowledge. We start with Sir Ian Diamond, UK National Statistician, giving an overview of why data matters. Next, we explore the use of data in storytelling with Professor Jennifer Visser-Rogers, Head of Statistical Research at PHASTAR. We move on to discussing the Code of Practice for Statistics with Ed Humpherson, Director General for Regulation at the Office for Statistics Regulation (OSR), followed by Sir David Spiegelhalter, Emeritus Professor of Statistics at University of Cambridge on how to become a data translator. The next module focuses on data quality, with input from Government Data Quality Hub, leading to the topic of new frontiers in data with our very own Data Science Campus Director, Osama Rahman. Anna Kwiatkowska, Deputy Director for Data Science at HM Revenue and Customs offers points to consider on Artificial Intelligence (AI) ethics. We end with Tom Smith, Chief Data Officer at the Department for Levelling Up Housing and Communities (DLUHC), sharing five important lessons from running data teams. From left to right: Alison Watkins-Shanahan, Programme Manager at the ONS Data Science Campus, Ysis Gregory, Digital Content Officer at the ONS Data Science Campus, Alison Adams, Head of Capability at the ONS Data Science Campus. One of the most exciting aspects of this project was watching the modules' content come to life! This was One Big Project... and it took a huge amount of effort across many of our teams. The idea was to make the modules as informative and as engaging as possible to a wide audience. With the help of our communications team, we put together a content strategy, which involved creating training videos alongside supplementary learning resources and case studies. We quickly assembled a small group of in-house professional videographers and video editors. Within just two weeks, the team organised and conducted nine individual video shoots across various locations in the UK. The result is a series of high-quality, engaging videos, packed with useful information, featuring prominent speakers from the data and statistical communities. These modules will not only benefit civil servants during the One Big Thing initiative, but will also be used to update our popular Data Masterclass later in the year. The current version of the Data Masterclass has already reached over 10,000 people, mostly senior civil servants, and this update aims to widen its reach even further. The ONS core principles - radical, ambitious, inclusive and sustainable - underpin everything we do. Here is how our involvement in the One Big Thing initiative aligns with these principles: From September, civil servants will have access to the new 90-minute training programme. There will also be additional learning opportunities, such as events, conversations and a central list of existing learning and training resources. Learning will be available at a range of levels, providing an exciting opportunity for us all to upskill, regardless of our current level of expertise. If you're a civil servant, mark your calendar for 4 September and explore these training modules on your [One Big Thing account](http://onebigthing.civilservice.gov.uk/) [.](https://identity.learn.civilservice.gov.uk/login) Share your thoughts and feedback via Finally, remember, One Big Thing is an opportunity for all civil servants to take shared action to meet the government's vision of a more skilled, innovative, and ambitious Civil Service, equipped for the future.]]> We have been exploring how natural language processing (NLP) techniques and LLMs could be used in the future to improve website search experience for end-users. We developed \"StatsChat\" as an experimental search pipeline and front end web application to try and improve on the existing search engine capability of the Office for National Statistics (ONS) website. Today, we are releasing the code base for StatsChat as an open-source repository on [GitHub](https://github.com/datasciencecampus/statschat-app). We investigated if relevant text responses can be provided from search prompts using retrieved information from historical pages on the ONS website, though the same approach could be applied to any document store. We hope this work will inform and support collaboration with others who are looking at similar approaches to improve information retrieval, whether from websites or other document stores. Many websites have search engines that use algorithms based on how often individual keywords appear on a page. This may not reflect what the user meant to search for, or the information contained on the pages. Additionally, even if a user is taken to the correct page on a website, they may still struggle to find the right piece of information within that page. Our approach with StatsChat uses embedding search to interpret the semantic meaning of queries and documents together with an LLM. This returns to the user relevant sentences from shortlisted documents. For transparency reasons, the models used, their sources and limitations are openly available. The approach also ensures that data are only stored on the ONS infrastructure. This avoids relying on proprietary models and provides assurance of user data security. It's worth mentioning that the generative step of StatsChat is only being used in a very limited context: to find and retrieve the right parts of an ONS bulletin for the user. This is essential to ensure the system does not generate incorrect or biased information. Figure 1 shows a flow chart detailing our technical solution and an overview of our approach. We obtained and stored a historical archive of every publication on the ONS website, published since 2016, with accompanying metadata. Items in the document store were then partitioned into chunks of roughly 1000 characters and converted into vector embeddings using a [sentence transformers model](https://huggingface.co/sentence-transformers/all-mpnet-base-v2). This allowed us to run an embedding search algorithm to collect the most relevant web pages from the user query. Next, we conducted generative question-answering (GQA) using the open-source [Flan-T5-Large](https://huggingface.co/google/flan-t5-large) model from Google. The shortlisted documents and the user question were both fed into the model, and it was prompted to answer the user's question only using paraphrased sentences from the shortlisted documents. The application was served using Flask, with a simple HTML front end and rest API endpoint. The search results page currently provides a single free-text answer generated from the generative question answering step, as well as the full results from the embedding search stage, linked to metadata. This allows the user to gain easy access to the text on the relevant section on the webpage. The embedding search shows a clear improvement upon the current website performance in terms of picking out relevant sections of webpages from the user query. We have found it particularly effective at retrieving information for very specific queries. For example, Figure 2 shows results from a user request asking about the proportion of people that watched His Majesty King Charles III's coronation. This specific statistic has only been published once in one of our [regular public opinions and social trends bulletins](https://www.ons.gov.uk/peoplepopulationandcommunity/wellbeing/bulletins/publicopinionsandsocialtrendsgreatbritain/4to14may2023). In this example, StatsChat was more effective at identifying the bulletin relevant to the query and the right section within that bulletin. In contrast, we found that the search tool was less effective at returning succinct and accurate answers to very broad questions, for example, \"are we in recession?\". We are aiming to improve the performance of the tool over time, by introducing fine-tuning into the GQA model following internal testing. This will include being able to better link public queries to technical terms used by a national statistics institute. It is important to emphasise that the development of StatsChat is currently in early experimental stages. The code is being made publicly available solely for research purposes. We are actively working to ensure the tool meets rigorous tests of data security and ethics. Most notably, although we have made efforts to eliminate hallucinations in the GQA stage, we have not yet conducted enough testing and refinement to ensure this is always true for all search queries. We also intend to strengthen the resilience of the system to prompt injection attacks, ensuring there is no risk of the tool being used to generate misinformation. Finally, we intend to do further research and testing on the presence of bias in the models we have currently selected. The code repository is currently structured to be run in parts. A standalone pre-processing script covers the task of converting pages on the ONS website to embedding vectors. The front end Flask app is run from a single script, while the retrieval and GQA pipeline is its own module. Various parameters, including the choice of models, approach to converting documents into vector embeddings and the prompt for conducting GQA can be found in the configuration files. We have included a small test dataset of publicly available bulletins from the ONS website to demonstrate how documents could be stored and accessed by the search tool. It is conceptually possible for the tool to be used on a range of documents, but this would need some reconfiguration. Further information on compiling and running the code base can be found in the [README file on the Github repo](https://github.com/datasciencecampus/statschat-app). We are currently conducting further testing and refinement of StatsChat. This includes fine-tuning and dealing with the [risks and limitations](#risks-and-limitations) The first step is for us to ensure StatsChat meets the highest standards of data ethics and data security tests. Depending on the outcome of testing, we may look to gradually make this tool more widely available to users and will continue to inform on our progress with this project. If you are interested in this work or would like to collaborate with us on a similar project, get in touch with us [via email](mailto:datacampus@ons.gov.uk). For regular updates on our work, follow us on [newsletter](https://public.govdelivery.com/accounts/UKONS/subscribers/new). This new project aims to expand on our previous work by providing transport performance metrics for urban centres across the UK, as well as their international counterparts, also using consistent methods and open data. The motivation for the work is to provide metrics that can help answer the following research questions, two of which are featured in the [Levelling Up White Paper Technical Annex](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1054766/Technical_annex_-_missions_and_metrics.pdf): The project will build on [research performed by the European Commission](https://ec.europa.eu/regional_policy/en/information/publications/working-papers/2022/low-carbon-urban-accessibility) to improve data timeliness and frequency, incorporate updated methods and tools, and provide an open codebase for analysts. Initially, this project will explore public transport networks and how well they enable people to move in and around urban centres. In the future, we aim to include other transport modalities such as cycling, walking and private car. To produce international comparisons, we intend to work with open sources of data including [gridded population estimates](https://ghsl.jrc.ec.europa.eu/), [road network data](https://www.geofabrik.de/data/download.html) and public transport service feeds, such as the Department for Transport's (DfT) [Bus Open Data Service (BODS) platform](https://data.bus-data.dft.gov.uk/). We will communicate any limitations or assumptions made at the point of publication. In alignment with our mission to use data science for the public good, this work will be open, transparent and reproducible. We support the open-source development community, encouraging those interested in this area of study to engage with us in this public codebase. This allows for greater scrutiny of the methods, easier collaboration, improved quality and reuse of code. [The project codebase on GitHub](https://github.com/datasciencecampus/transport-network-performance) is currently under active development. We intend to release a software package providing flexibility for others in government and beyond to run similar analyses in their own areas of interest, assumptions and use-cases. This will be especially useful to those wishing to evaluate the transport-related component of urban productivity over time. We are also exploring the use of real-time public transport service data to allow the evaluation of service quality indicators relating to frequency and punctuality. This will allow comparisons between timetabled journeys and real-time performance. The initial work will focus on an area in England using DfT's Bus Open Data and [real-time transit feeds](https://developers.google.com/transit/gtfs-realtime). We plan to explore the use of real-time data in other countries to further improve international comparisons, if possible. If you are interested in this work or would like to collaborate with us, get in touch with us [via email](mailto:datacampus@ons.gov.uk). For more updates on this project, follow us on Using aggregate spatial modelling approaches, the Data Science Campus has produced an alternative estimation of the travel to work matrices which bridges this gap. We have produced experimental data for each year from 2012 to 2021 and have [published modelled estimates for 2021](https://www.ons.gov.uk/releases/estimationoftraveltoworkmatricesenglandandwales). When new data becomes available, the model can be updated to include 2022 onwards. This will provide complementary statistics to the 2021 Census travel to work data collected during the coronavirus (COVID-19) pandemic which contains a mixture of [pandemic and pre-pandemic behaviours](https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/employmentandemployeetypes/methodologies/traveltoworkqualityinformationforcensus2021). These modelled estimates for 2021 are the first release in a planned work programme of incremental improvements to the model and outputs. This blog briefly introduces the methods used, initial results, limitations and next steps. For a more detailed methodology, refer to the [technical report](https://datasciencecampus.ons.gov.uk/projects/technical-report-estimation-of-travel-to-work-matrices/). You can [download our estimated travel to work matrices](https://www.ons.gov.uk/releases/estimationoftraveltoworkmatricesenglandandwales) from the ONS website. We do not recommend that these data are used to inform decisions, and are publishing the statistics to enable feedback and input into methods. We [welcome feedback](mailto:datacampus@ons.gov.uk) from stakeholders on methods and outputs. We have developed a gravity model, calibrated using the 2011 Census travel to work data, to estimate travel to work matrices. A gravity model at its most basic level assumes that the number of trips made between two areas can be estimated by the number of resident workers at the origin (residential end), the number of employees working at the destination (workplace end) and the cost, such as travel time, travel distance or monetary cost (or a combination of these factors referred to as a generalised cost) of travelling between these two locations. Figure 1 shows the processing pipeline, that is, how the different sources of data feed into the model and generate the estimation of travel to work matrices. The pipeline consists of three core modules: Production and Attraction Estimation Module, Calibration Module and Doubly Constrained Model. The Production and Attraction Estimation Module estimates the number of resident workers travelling to a fixed workplace at each origin, and the number of employees working in each destination, using these assumptions: In the Calibration Module, the cost of travelling between the origin and destination is currently estimated using straight-line distance. The model is calibrated using a cost function that aims to replicate the relationship between distance between home and work and the number of commuters, as seen in the 2011 Census travel to work matrices. In later versions of the model, we plan to replace distance with better estimations of costs, in terms of time and money, of travelling between home and work. An iterative process, called the Doubly Constrained Model, then ensures that the estimated number of resident workers at all origins matches the number of employees working at all destinations. Our gravity model estimates the travel to work matrices of the usual residents aged 16 and above and in employment with a fixed workplace at the Middle Layer Super Output Area (MSOA) for England and Wales, annually from 2012 to 2021. It also provides estimations of resident workers with a fixed workplace, and employees working in each MSOA in England and Wales, annually from 2012 to 2021. Please note that the [2021 estimates that we have published](https://www.ons.gov.uk/releases/estimationoftraveltoworkmatricesenglandandwales) are the experimental results and should not be used for decision making purposes. The model combines pre-coronavirus (COVID-19) pandemic commuting behaviour (for example, the proportion of employees travelling to a fixed place of work) from the NTS (2018 to 2019) and 2021 population and employment estimates to provide a counterfactual of travel to work matrices in 2021, assuming pre-pandemic commuting behaviour. Figure 2 illustrates the estimated travel to work matrices for 2011 (from 2011 Census) and 2021 (under the assumption of the pre-pandemic commuting behaviours) respectively. The maps represent commuting flow between all home and work locations at MSOA level in England and Wales, with lighter lines indicating more commuters travelling to fixed workplaces. The maps provide a sense check on the estimated travel to work matrices for 2021, produced by the model. This is because, over time we would not expect commuting behaviour to change dramatically at aggregate level, so we would expect a similar picture to emerge from the travel to work matrices estimated for 2021, as we observe in 2011. While our initial experimental results provide a counterfactual of travel to work matrices assuming pre-pandemic commuting behaviour, the model can also estimate travel to work matrices assuming mid-pandemic commuting behaviour. This is achieved using mid-pandemic commuting behaviour from the NTS (2020 to 2021) and 2021 population and employment estimates. Figure 3 presents maps showing the number of workers who travel to a fixed workplace for MSOAs in England and Wales in 2021 under these two conditions, for instance, assuming commuting patterns pre- and mid-pandemic, respectively. According to the 2011 Census, 21.6 million (81%) people travelled to a fixed workplace in England and Wales. The 2021 Census reports that 15.1 million (54%) people travelled to a fixed workplace, a significant reduction over 2011. This is because at the time of the 2021 Census many people were working from home or furloughed,. Our initial experimental estimations using commuting behaviour pre and mid-pandemic are in line with plausible expectations. Our model estimates that in 2021 76% (21.1 million out of 27.8 million working adults) travel to a fixed workplace under the assumption of pre-pandemic travel behaviours, and 63% (17.6 million out of 27.8 million working adults) travel to a fixed workplace under the assumption of mid-pandemic travel behaviours. One major shortcoming of the estimated travel to work matrices is the lack of validation, which has not been possible in the absence of a representative survey of travel to work for 2021, because the Census 2021 contains a mixture of [pandemic and pre-pandemic responses on travel behaviours](https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/employmentandemployeetypes/methodologies/traveltoworkqualityinformationforcensus2021). To help validate the model, we are working on obtaining alternative data sources including mobile phone data. In addition, there are limitations relating to some of the input datasets we have used in the model, particularly at finer spatial granularities. For example, the NTS cannot be relied upon at geographies lower than region, because of survey sample size, response rate and spatial coverage. We therefore make assumptions about travel behaviour trends for aggregations of areas based on rural-urban area type, densities, and accessibility measures (see our [technical report](https://datasciencecampus.ons.gov.uk/projects/technical-report-estimation-of-travel-to-work-matrices/) for further details). Similar issues affect NTEM because of assumptions made regarding the distribution of growth in employment and workers. This will affect the reliability of the estimated travel to work matrices. We plan to address these issues in future versions of the model by working with stakeholders, and through model enhancements, for example through segmentation by transport modes, industry, occupancy, and socioeconomic characteristics. This segmentation will allow us to make better assumptions about travel behaviour trends by different types of commuters and allow the estimation of travel to work matrices by these segmentation groups. Our longer-term goals involve developing predictive models, to allow testing of 'what-if' policy questions and scenario-based analysis to enable decision making under uncertainties on future housing market, jobs market, economy, and technology developments. For example, by estimating and comparison of travel to work patterns under high or low growth in housing supply, jobs or economic performance.]]> Complementing the Data Science Accelerator, the Data Visualisation Accelerator was introduced in June 2021 to meet the growing demand for data visualisation mentoring. These programmes are open to all UK public sector employees, including those in central and local government. [The Autumn 2023 cohort](https://www.gov.uk/government/publications/data-science-accelerator-programme/introduction-to-the-data-science-accelerator-programme#how-to-apply) is currently accepting applications, providing an opportunity for aspiring analysts to propel their careers forward. In this guest blog post, Helen Lankester, a previous participant in the Data Science Accelerator programme, offers valuable insights into her journey, highlighting the real-world impact and career growth she experienced through her involvement in the programme. I am Helen, a graduate of the 2022 Data Science Accelerator Programme. In this blog, I want to share my perspective and experience of being on the Accelerator programme and the progression I have made in my early career since. I joined the UK Hydrographic Office (UKHO) after graduating with my MSc in Glaciology, which was my first introduction to coding using MATLAB to analyse the ice motion of the Greenland ice sheet. Since commencing my role at the UKHO in 2020, I was eager to enhance my coding proficiency. A colleague in our Data Science team encouraged me to enrol on an online Python coding course to improve my skills before applying for the Accelerator programme. The UKHO's Data Science team are very supportive of colleagues in non-data science teams gaining coding skills. A colleague in this team made me aware of the programme and helped support my application. My Accelerator project focused on automating the detection of Arctic icebergs using synthetic aperture radar (SAR) imagery to enable safe Arctic navigation. Trans-Arctic Ocean navigation is hazardous, and vessels are exposed to risks such as sea ice and icebergs. Currently, the only dataset produced by the UKHO regarding iceberg concentration provides monthly iceberg positions and is therefore unsuitable for navigation. Developing a near real-time iceberg detection data product to enable safe trans-Arctic maritime navigation was required. I began by researching what current ice products the UKHO offered to identify any areas for improvement. I wanted to work on a project that combined my previous glaciology knowledge, as I would understand the potential problems I could encounter while working with the SAR satellite imagery. The approach I took to find the icebergs was using an edge detection algorithm in Python, which works by detecting changes in brightness. In this case, ice is very bright compared with the dark water in the satellite images, and the algorithm detects these brightness changes to outline the icebergs. Throughout the Accelerator programme, I felt supported by the Accelerator team at the Office for National Statistics (ONS), from the initial cohort induction to the graduation presentations. The Accelerator team match you with a mentor who is an experienced data scientist. I organised weekly Teams meetings with my mentor, and we would virtually fix any bugs in my code. I found having a mentor very helpful to discuss ideas and help fix any project blockers. Our cohort had weekly Teams stand-ups delivered by the ONS, which were designed to help people experiencing issues with their projects. These weekly stand-ups were an excellent way to network with people across government. I enjoyed the weekly stand-ups with my Accelerator cohort, as I could learn about other projects across government, from organ donation tracking to improving the energy efficiency of historic buildings. My project was initially a proof of concept which proved successful. Therefore, we are continuing to work on the project at the UKHO. This is a great achievement, as I only had one day a week over three months to work on the project during the Accelerator programme. I highly recommend that you apply to the Accelerator to not only develop valuable data science skills, but to also gain an insight into what other government departments are working on. Before the Accelerator programme, I had limited coding experience and was finding it difficult to break into the world of data science. However, after completing the programme, I had the skills I needed to successfully gain a new role in the Bathymetry team in the Scientific Analysis Group at the UKHO. Within this new role, I have had the opportunity to use AI and machine-learning tools to identify sonar noise in bathymetric data. The advice I would give to potential applicants would be to attend Accelerator clinics and thoroughly research your project. Before applying, I researched different methodologies for iceberg monitoring by reading scientific articles and meeting with different teams at the UKHO to understand the product I was trying to improve. I hope this blog has given you an insight into why you should apply for the Accelerator programme, as it is an excellent opportunity to meet people across government and develop valuable data science skills.]]> Making government data publicly available has a host of benefits. Public sector bodies that own and publish datasets can unlock value by opening anonymised datasets for use by a range of stakeholders, including enquiring citizens and journalists, academics and educators. Open datasets can be used to better understand society, health, education, transport, the economy, and more. Open datasets are essential to evaluating policy in an open and reproducible way. Fully open data and analysis help to ensure data-driven research is democratically and scientifically accountable. The more people who are able to work on a dataset, the more likely we are to see these benefits unlocked. So, it is important that data are not just publicly available, but that they are accessible, in a form that encourages reproducible data science. This blog post uses transport data as a case study to show how, when it comes to delivering the maximum public good, making data open is only part of the story, and that making it accessible matters. Even when data sets are open, there can be barriers to analysing or comparing them. For example, [the Department for Transport's STAT19 datasets on road traffic casualties](https://www.data.gov.uk/dataset/cb7ae6f0-4be6-4935-9277-47e5ce24a11f/road-safety-data) are all openly available but are hard to use because they are provided in untagged .csv files. The stats19 R package, which has been peer reviewed and [published by the organisation rOpenSci](https://docs.ropensci.org/stats19/), makes it easy for anyone to access the data in a reproducible format. This \"packaging\" of code enables researchers and others to focus on the research and policy impact rather than \"reinventing the wheel\" by spending time cleaning data. The Department for Education (DfE) [school places scorecards](https://www.gov.uk/government/collections/school-places-scorecards) are also openly available, to provide another example. Comparing school ratings over time is still cumbersome because of differences in data formats and variables across different years. This can be challenging, particularly if you are trying to develop an analytical pipeline using a data science platform, which relies on a consistent data format. Therefore, simply making datasets open is not always enough to ensure they will be used. Additional value can be unlocked by making data both openly available and easily accessible for analysis - a principle that applies especially to the kind of open data that governments provide. To fully make use of open datasets in reproducible data science pipelines, data sets should be made available in analysis-ready formats that tools such as the R and Python programming languages can use. These languages dominate data science work in government, industry and academia. Our project demonstrates that data must be made accessible to maximise its impact and value. To this end, we use [data on Journey Time Statistics (JTS)](https://www.gov.uk/government/collections/journey-time-statistics), released by the Department for Transport, as an example of how further value can be added to open datasets by creating tools to easily analyse them. We have developed R and Python packages that are able to import, process and visualise the JTS data. These packages eliminate any processing step needed by anyone interested in working with JTS data, thus reducing entry barriers to working with the data, as well as allowing for a reproducible pipeline based on our packages, rather than individually developed, ad-hoc scripts. This improves efficiency, reduces the risk of errors in the processing of the data, and overall helps to improve the quality of the analytical pipeline. As an example, our packages allow easy retrieval and mapping of data on the average journey time to employment centres (with 100 to 499 jobs) by public transport simply by running the following lines of code. In R: install.packages(\"remotes\") remotes::install_github(\"datasciencecampus/jtstats\") library(jtstats) jts_geo sheet = 2017, geo = TRUE) names(jts_geo) # show the many columns available in the dataset jts_geo |> select(GPPT15pct) |> 1 shows a map of the United Kingdom displaying the percentage of people in different areas who can access a GP surgery within 15 minutes by public transport. The data are plotted at the Lower Layer Super Output Area (LSOA) and are plotted on a logarithmic scale for ease of visualisation. We can easily notice how urban areas, such as London and Manchester, have a much shorter travel time on average compared with rural areas, such as the North and South West of England. Figure 2 shows a map of the United Kingdom depicting how the average travel time to jobs by public transport varies in different LSOAs, plotted on a logarithmic scale. The map clearly illustrates the strong differences in accessibility to jobs between urban areas, such as London and Manchester, and rural areas, such as the South West and the North of England. The JTS data are originally released by DfT in the open document spreadsheet (ods) format in a large number of different tables and files. Our packages rely on the version of those files that we converted to the more commonly used comma separated values (csv) format, which are then imported and processed by the R and Python code. The command-line script used to convert the files is also openly available on the [JTSTATS repository](https://github.com/datasciencecampus/jtstats). While we believe our approach showcases the opportunities of developing these kinds of tools, there are always further improvements that could be implemented. First, removing the conversion step from ods format to csv would further improve the reproducibility of our tools and minimise pre-processing steps. In fact, we suggest that, in the future, an alternative option could be to make data from public bodies available in more data science-friendly and memory-efficient formats, such as Apache's Parquet format. However, it is also important to acknowledge that csv is a very widespread and popular format, which is unlikely to be replaced in the short term, so the development of reproducible tools based on csv files is going to remain relevant for most applications. Second, in the case of tools developed across multiple programming languages, rigorous multi-language tests should be implemented to ensure that results obtained are consistent across the different languages. The approach presented here demonstrates the potential of coupling open government data with open reproducible data science tools, and we hope to encourage the adoption of such practices across all public bodies. Building on our work, we advocate the creation of packages to support reproducible data science pipelines to allow a broader range of analysts, data scientists, and researchers, to use government datasets in their work. Such tools cannot only improve efficiency and reduce risks of errors in data processing, but crucially, can enable a broader audience to add value to public sector data. Read a [more detailed discussion of the jts package](https://arxiv.org/abs/2305.16205). The codes for [jtstats](https://github.com/datasciencecampus/jtstats), [jtstats-R](https://github.com/datasciencecampus/jtstats-r) and [jtstats-Py](https://github.com/datasciencecampus/jtstats-py) are available on GitHub. Nowcasting refers to generating estimates of the current (\"now\") state of the economy. It involves combining and using information released at a high frequency to estimate what a variable of interest that is available at a lower frequency might be doing in real-time. There are a variety of methods commonly used in economics to do this. Households, businesses, and policymakers need up-to-date information to make the best decisions. However, it takes time to collect and compile information that accurately represents the whole economy. In the UK, the ONS publishes monthly gross domestic product (GDP) estimates, released 40 days after the reference month, and quarterly GDP estimates, which are published around six weeks after the end of the quarter. These estimates are then updated as more information is incorporated ( [see our ] [GDP quality and methodology information](https://www.ons.gov.uk/economy/grossdomesticproductgdp/methodologies/grossdomesticproductgdpqmi)). However, there is a vast wealth of information about aspects of the economy that can be gleaned from indicators that are released more quickly and frequently than either monthly or quarterly GDP. The ONS publishes a selection in its weekly [Economic activity and social change in the UK, real-time indicators bulletin](https://www.ons.gov.uk/economy/economicoutputandproductivity/output/bulletins/economicactivityandsocialchangeintheukrealtimeindicators/latest), and others are available from other sources. We describe work looking at how we can use mathematical models to collate frequently released indicators to glean better information about what is happening in the economy now. Two of the challenges faced in nowcasting are the different frequencies of various datasets (some are available daily, weekly, monthly, quarterly) and missing or irregularly spaced data because of publication lags or collection methods. These challenges become more acute with the increased availability of alternative data sources, such as web-scraped data, scanner data, or financial transactions data. The signature method handles these challenges by embedding the observed data in continuous time. It first generates a \"path signature\" with a series of iterated integral terms, which capture the geometric properties of sequential data (for example, the potentially non-linear relationships between the indicators and time). One can then generate a nowcast for a variable of interest by applying regression methods on the path signature, (for example, a simple linear model on the nonlinear signature terms). Today, we release several outputs from this work. The first is an [academic paper](https://arxiv.org/pdf/2305.10256.pdf) that compares the signature method against other nowcasting methods mathematically and in various empirical applications. We show that the linear Kalman-Bucy filter can equivalently be written as a linear regression problem on the signature space. In a nowcast of US GDP growth, the signature method generates a lower root-mean-squared error over the evaluation period than a dynamic factor model. The signature method also generates a slightly lower root-mean-squared-error than an autoregressive integrated moving average model in nowcasting weekly UK road fuel prices. Our second release is a [technical report](https://datasciencecampus.ons.gov.uk/projects/technical-report-nowcasting-uk-household-income-using-the-new-signature-method/) details how the signature method performs in nowcasting UK household income, where it performs similarly to an autoregressive model. In this context, we find that the mixed-frequency data sampling (MIDAS) model performs best over the evaluation period, but still only offers a slight improvement over an autoregressive model. We will also release a [PYTHON code repo](https://github.com/datasciencecampus/SigNow_ONS_Turing), which enables others to apply the signature method to generate nowcasts for other variables of interest. Users can load in their own indicators and target variable, and the code will generate a nowcast of the target for periods of interest using the signature method. We hope this repo will help public sector users and others perform better nowcasts using this off-the-shelf code. The ONS and Alan Turing partnership on the economic nowcasting project has demonstrated how different techniques can help to overcome the challenges of understanding the economy quickly and explored some of the strengths and weaknesses of the signature method in this context. It has also provided reusable code to apply the signature method to different target variables in future. This understanding and code can help the ONS and others as we seek to develop the best early estimates of the state of the economy for decision makers. Thank you to all of our [contributors](https://datasciencecampus.ons.gov.uk/projects/technical-report-nowcasting-uk-household-income-using-the-new-signature-method/#section-5) from the ONS and the Alan Turing Institute for their collaboration on this project. The coronavirus (COVID-19) pandemic highlighted issues related to global supply chain risks, such as shortages in microchips and personal protective equipment. Additionally, other events can result in supply chain shocks, for instance, the Suez Canal crisis and the closure of major copper mines in the Democratic Republic of Congo and Zambia. It is therefore important to study global supply chains, to detect and mitigate related risks. In this project, we explored whether cutting-edge data science techniques, such as natural language processing (NLP) and transformer-based deep learning models, could enable us to construct supply chain networks from unstructured text. We applied these techniques to sentences from Reuters news, similar to the one used by [Wichmann et al. 2022](https://www.tandfonline.com/doi/abs/10.1080/00207543.2020.1720925), kindly provided by researchers from the [Supply Chain AI Lab of the University of Cambridge](https://www.ifm.eng.cam.ac.uk/research/supply-chain-ai-lab/) and a selection of sentences from the [BBC Monitoring database](https://monitoring.bbc.co.uk/). Additionally, we wanted to learn more about the opportunities and challenges associated with using such models, since they are potentially applicable to a wide range of use-cases. Our aim was to detect buyer-supplier relationships implied in sentences of news articles. This work can help with the validation of existing supply chain networks and the enrichment of the networks with previously unseen relationships. The project is affiliated with the Global Supply Chains Intelligence Pilot (GSCIP), run by DBT, which aims to explore the value of combining several government and external datasets, along with big data analytics, to map global supply chains. Several UK government organisations participate in the pilot, including Cabinet Office, Office for National Statistics, HM Revenue and Customs, Department for Business, Energy & Industrial Strategy and UK Export Finance. Our initial results indicate that, by applying the above-mentioned techniques, we can detect buyer-supplier relationships between enterprises in sentences from news articles with good accuracy, when these are relevant to themes or topics that our models encountered during training. Moreover, our model can recognise such relationships in unseen topics. Supply chains can be represented as knowledge graphs, for example [Kosasih et al](https://www.tandfonline.com/doi/full/10.1080/00207543.2022.2100841). A knowledge graph is a diagram of interlinked descriptions of these entities can include products, countries of origin, firms or transport modes and other characteristics To build the knowledge graph, it is necessary to determine the entities and the relations between them. In our analysis, these entities are enterprises, and our goal is to determine whether there exist buyer-supplier relationships between them. Potential pathways for future work include expansion of our analysis to other types of entities, such as products and countries of origin. During our analysis, we developed a sample pipeline, which can be used to build knowledge graphs from collections of free text. This pipeline consists of the following steps: Each of these steps can be completed with a variety of data science algorithms, although for the purpose of this work we haven't considered network analysis and entity filtering. This is a preliminary step that splits the text document into sentences and is necessary to extract entities with accuracy in the following step. It can be performed with sentence tokeniser tools, such as PunktSentenceTokenizer, implemented in the widely used NLTK package. During this step, entities of interest are extracted from sentences. This is a classification problem, which assigns words (typically, nouns) in a sentence to a number of predefined categories. These could represent names, companies, products or even numbers, for instance transaction values or revenues. This step can be performed with techniques from the families of sequence analysis (Bayesian models are commonly used, for example, hidden Markov models and conditional random fields). Deep learning (for instance, convolutional neural networks - an important step here is to convert words to word embeddings, which allows words with similar meanings to have a similar representation). And rule-based approaches (Brill's speech tagger is widely used here). In our case study, the entities of interest are enterprise names. It is expected that in collections of articles with diverse content, for instance, news articles, some extracted entities will not be relevant to global supply chains. To filter out irrelevant entities, one approach could be to discover the abstract topics that occur in the collection of articles (with topic-modelling techniques, such as latent Dirichlet allocation, latent semantic analysis, probabilistic latent semantic analysis) and then remove all terms related to irrelevant topics. Here we determine the relations between the detected entities. This can be achieved with three broad approaches, which are syntactic patterns (for example, Hearst patterns), supervised approaches (e.g., RNNs, LSTMs, transformers, these require a lot of training data) and weak supervision approaches (for instance, the algorithms by [Onishi et al](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6147111/). and [Riedel et al.](https://link.springer.com/chapter/10.1007/978-3-642-15939-8_10)). In our study, we use transformers for relation extraction. Transformers are attention-based models and improve on previous algorithms used for relation extraction. Their main advantages over [Recurrent neural networks networks (CNNs)](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf) are are that they do not suffer from long dependency issues such as long sentences and can be trained efficiently. Having detected the entities and their relations, the knowledge graph can be constructed with network visualisation tools (for example, the networkx library). The nodes of the network will be the entities and the edges between the nodes will be the relations between the nodes. Once the knowledge graph is constructed, it can be further analysed with network analysis techniques to solve problems relevant to supply chains such as identifying critical products, critical routes, and the strength of relations between entities. In the applications that follow, we apply the following steps: sentence segmentation, entities extraction, relations extraction and construction of knowledge graphs and the remaining steps may be explored in future work. We evaluated our pipeline's performance using a database of sentences from Reuters news. This is similar to the one used by [Wichmann et al. 2022](https://www.tandfonline.com/doi/abs/10.1080/00207543.2020.1720925), and was provided by researchers from the [Supply Chain AI Lab of the University of Cambridge](https://www.ifm.eng.cam.ac.uk/research/supply-chain-ai-lab/).\" The data comprised 7,274 aerospace and automotive news article sentences, pre-labelled with company names and relationships between them. Approximately 10% of relationships were directed supplier-customer relationships, 20% subsidiary or other specified relations, and the remaining 70% \"no relation\". Table 1 shows a full list of relation annotations contained in the data. |Label||Relation| |A supplies supplies relevant relation detected| Here is an example sentence from the database, with its annotations: Sentences were also provided in an alternative form, in which organisational entities were replaced with a mask, for example: We used a supervised learning approach to detect buyer-supplier relations in the data. That is, we used part of the database to build a model that detects relationships and then applied the model to the remaining part of the data to automatically extract the relations between entities in the text. Specifically, we used 70% of the data for training, 15% for validation and 15% for testing. We detected relationships between enterprises in the data with [transformer](https://arxiv.org/abs/1706.03762) neural networks within the spaCy NLP framework tied to pre-trained transformer models from the [huggingface](https://huggingface.co/models) library. The implementation for the relation extraction task was based on spaCy's relationship extraction template ( [rel_component](https://github.com/explosion/projects/tree/v3/tutorials/rel_component)), which fine tunes transformer models using training data. Relationships between entities were learnt either using all the words in a sentence (unmasked data), or only the non-entity words in a sentence (masked data). The use of organisational names might give clues as to the relations between entities, through the words themselves, such as \"ABC Airlines\", through the prevalence of the names in the dataset, or through background knowledge about the organisations, such as Boeing. On the other hand, excluding these names might help generalisation if the learned model is applied in a different domain. Challenges in the relation extraction task include the varied or ambiguous ways that supplier relations can be represented in text. For example, who is supplying whom in this sentence: \"GKN Aerospace has signed a GBP multi-million, long term agreement (LTA) with Kawasaki Heavy Industries (KHI) to supply titanium rotating parts for the PW1100G-JM and PW1400G-JM, Geared Turbofan (GTF) engines.\" This difficulty is partly evidenced by the variation in relation labelling between different labellers in the original dataset. Here, we present results for the default transformer model in the spaCy template, that is, [RoBERTa](https://arxiv.org/abs/1907.11692) (base) (\"A Robustly Optimized BERT Pretraining Approach\"), a refinement of [BERT](https://arxiv.org/abs/1810.04805?hl=uk) (Bidirectional Encoder Representation from Transformers). Table 2 shows full results for the base model, Roberta-base masked. This gives an \"A supplies B\" relation identification with precision of 0.961 and recall 0.85 and \"B supplies A\" identification with precision of 0.95 and recall of 0.83. It also includes results for subsidiary and \"other\" types of relation, though at a somewhat lower performance. in R to visualise the customer-supplier relations in the above data, for companies having at least four relations, as shown in Figure 1. Airbus and Boeing are the largest hubs, as well as car manufacturers BMW, GM, and Toyota, and there is separate sub-network for Apple. We also applied our model to a selection of sentences from the [BBC Monitoring database](https://monitoring.bbc.co.uk/), which is a collection of insights and reports from broadcast, press and social media sources from over 150 countries and 100 languages. It was challenging to build a database for our experiments because potential buyer-supplier relationships were scarce and difficult to identify within a big database of the size of BBC Monitoring. Therefore, we selected a few sentences by ensuring that each of them had at least two named entities and contained a phrase from a predefined list of key phrases that could imply buyer-supplier relationships. Our final database consisted of 897 samples. Note that for this experiment we used the model we had previously trained on Reuters data for our previous application. The BBC monitoring database and the selection of sentences we used for testing were completely unseen by our model. Ground truth for each sentence in the sample was provided by human annotators, who assigned a label to each pair of named entities in each sentence of the BBC monitoring sample. Each of these labels indicated the type of the relationship between the pair of named entities. The labels we used are shown in Table 1. The type of relation between two named entities in a sentence is often ambiguous. Therefore, each relation in the sample was annotated by three independent annotators and its final ground truth label was assigned by majority voting. Overall, our model was capable of correctly identifying the relationships between named entities implied in the sentences in 90.65% of the examples of our database, which indicated its capability of achieving high performance even for completely unseen data. In terms of identification of named entities, our model was able to identify them reliably in all cases. Tables 3a and 3b show initial results from the application of our model to the sample from the BBC monitoring database. The model's output is shown in table 3a and table 3b has some additional information relating to the analysis of the output and the sentence annotation process. As mentioned previously, the task of determining the type of relationship between two entities can be challenging even to a human. We can see that in the examples 7 and 10 of Tables 3a and 3b, the model did not find the type of the relationship specified by the majority of the human annotators but one of the human annotators specified the same relationship type as our model. It is noteworthy that the model can detect buyer-supplier relationships correctly from a multitude of completely different expressions, which can be more complex than the standard expression \"A supplies B\". In sentences 1, 2 and 8, the expressions \"among its clients are\", \"is implemented jointly with\" and \"produces super pure materials used by\" were used, respectively, and the implied relationships were correctly detected by the model. |Sentence||From||To||Relation identified| |1||Oracle is a developer of data storage systems, among its clients are the Ministry of Finance, the Central Bank, Russian Post, Sberbank, Rostelecom, Rosatom, etc.||Oracle||the Central Bank||A supplies B| implemented jointly with DTEK and Ericsson.||Vodafone||Ericsson||Other Relation| |3||Already in the financial statements for 2020, Ericsson introduced a warning that the Swedish blacklisting of Huawei may have a negative impact\" on \"Ericsson's financial interests.||Ericsson||Huawei||No Relation| |4||Atameken Business Channel carries business and financial news in cooperation with Bloomberg, Thomson Reuters, the Kazakh Stock Exchange and Russia's Interfax news agency.||Atameken Business Channel||Bloomberg||Other Relation| |5||By BBC Monitoring Russian state energy giant Gazprom says it will stop supplies of natural gas to the Dutch trader GasTerra due to its reported failure to pay for fuel it has already supplied.||Gazprom||GasTerra||B supplies A| |6||Interaction between the Finance Ministry, the National Bank and the Agency for Regulation and Development of the Financial Market should be strengthened to implement a plan of action for including government securities in international indexes,\" Tokayev said.||the Finance Ministry||the Agency for Regulation and Development of the Financial Market||No Relation| |7||During the drill, Sber simulated turning off IT infrastructure supported by Microsoft, Nvidia, VMware, SAP, Oracle and Intel, the paper said on 1 February.||Sber||Intel||No Relation| |8||Kupol General Director Fanil Ziyatdinov said that Kupol also produces super pure materials used by leading companies such as Intel, IBM, Samsung and Apple in smartphones.||Kupol||Apple||A supplies B| |9||KPN wanted to replace Huawei in its core network with equipment from Sweden's Ericsson anyway, and Vodafone barely used network components from China.||KPN||Vodafone||B supplies A| |10||Vodafone Spain opts for Ericsson instead of Huawei to test 5G network Vodafone Spain has chosen the Swedish technology company, Ericsson, for a test of its first 5G standalone core network, the Spanish business newspaper Expansion reported A||No| We have presented initial results for automatic extraction of buyer-supplier relationships from news articles using NLP techniques, with the aim to extract supply chain information. We showed that our model performed well for sentences from a domain relevant to the data used when training the model. Furthermore, the model is capable of correctly identifying relationships between entities in sentences extracted from databases unseen to the model. Naturally, we also discovered several challenges in our work. These include access to sources of text that describe rich, deep supply chains, constructing a high-quality labelled dataset, model explainability, technology requirements (including hardware) for larger-scale model training, model serving in production and keeping the derived supply chain network up to date. In future work, possible extensions could be to apply our method to domains and text types outside of the training data and to include other types of entities in our analysis, such as products and countries of origin. Additional contributions from team member Bernard Peat]]> To track progress on nature engagement, Defra has a set of [indicator](https://oifdata.defra.gov.uk/7-4-1/)s. The current indicators use data from Natural England's [People and Nature Survey](https://www.gov.uk/government/collections/people-and-nature-survey-for-england) which asks a nationally representative sample of 25,000 adults how often they spend time in the natural environment. Due to limitations in sample size, the data from this survey is not useful on small areas. The number of outdoor recreation and tourism visits are also made available for the UK and the four nations as part of [ONS' UK Natural Capital Accounts](http://xn--ons%20uk%20natural%20capital%20accounts-xe8x/). These estimates are also based on survey data and are broken down by habitat types, but do not provide estimates for specific locations. Automated people counters are used frequently to monitor pedestrian and cycling activity with a good temporal resolution. However, people counters are expensive to install and maintain and for this reason are only installed in a few strategic locations. Introducing an inexpensive and widely applicable data science method for monitoring visitor numbers would considerably enhance Defra's indicator for tracking nature engagement. DSC, Defra and Natural England have spent the last few months developing a novel, low-cost data science solution to measuring the number of people who visit England's natural spaces. Our model combines aggregated and anonymised data from [Strava Metro](https://metro.strava.com/) with carefully selected open or free-to-access spatial datasets such as automated people counters and indicators of local environmental and social conditions. These results are experimental, in order to produce more robust results to inform outcomes we need to incorporate a larger set of training data and datasets that cover the residential location of visitors. Figure 1 shows the process involves fusing a set of different datasets to develop a data science model, calibrating the model, evaluating the quality of estimation, and testing the model. This is an iterative process requires revisiting assumptions, incorporating new datasets, or selecting different techniques to improve estimation and testing the outcomes. We have provided a brief explanation of the data we used for developing the model. Automated people counter data is used as the target variable against which we evaluated our model performance. The other datasets are used as input to the model for estimating monthly average people count. Natural England's [National Trails](https://www.nationaltrail.co.uk/en_GB/) and the [North Downs Way](https://www.nationaltrail.co.uk/en_GB/trails/north-downs-way/) together have a good network of 36 automated people counters to monitor trail usage. The data from these counters was used as the ground-truth data in our model. As the quality of data from these people counters is variable only data from selected sites that met out data quality threshold was included. The approximate locations of people counters are shown in Figure 2. [Strava Metro](https://metro.strava.com/) provides controlled free access to the largest collection of human-powered transport information in the world. Metro aggregates, de-identifies and contextualizes [Strava](https://www.strava.com/) data and provides this data to public sector partners who promote active transport and lifestyles. Activity tracking and sharing apps, such as Strava, provide a growing source of data for mapping physical activities. However, the data is biased, generated from only app users. To overcome this challenge, we [recalibrated](https://www.sciencedirect.com/science/article/pii/S0968090X21000176) Strava activity data by integrating Strava Metro with other datasets on socioeconomic profile, land use characteristics, and weather conditions into our model to predict number of visitors in natural spaces. We carried out an extensive literature review and engaged closely with Natural England subject matter experts on green infrastructure, access, and recreation, to identify additional datasets relevant for our investigation. This is summarised in Figure 3. Our modelling approach involves estimating the monthly average people count (MAPC) to best replicate the visitor numbers from the automated people counters. The dataset used to train our model was created by extracting features from all datasets mentioned above in a five-kilometre area surrounding the location of the automated people counters. Five kilometres was selected based on evidence from the [ORVal Insights](https://randd.defra.gov.uk/ProjectDetails?ProjectId=20399) project, suggesting that the probability of an individual visiting a natural space decreased substantially when the location was further than five kilometres away. Some of the features extracted include Strava Metro data relating to the total number of journeys on foot, land and habitat classification data, socio-economic and demographic features, points of interest data and weather data. Using the data from this training dataset we created estimations of MAPC using an ensemble learning approach. The ensemble model combines the estimations of several machine learning models to improve generalisability and robustness when compared to a single model. To evaluate and calibrate the estimations made by our model we compared the model outcome to the visitor numbers from the automated people counters data. As the inputs to the training dataset are available for a much wider areas than the automated people counters, we are not limited to making estimations only for the locations with people counters (after calibrating the model against the places where people counters are installed). The model estimations can be generated for a diverse range of natural spaces across England. Full technical detail of our modelling approach, open-source code, sample data and a technical paper will be provided in the near future. Figure 4 shows the performance of the model. The model estimation of MAPC for each site is aggregated to a regional level and compared to the observational automated people counter data. The model performance is better in regions with a higher number of training sites (locations monitored with automated people counters). For example, model predictions in South East and South West regions are more similar to the Actual Count than the predictions in North West region. Across South East, South West and Yorkshire and the Humber regions the model predictions successfully capture annual seasonal trends present in the Actual Count data. In Figure 5 we have shown the error in the predictions from the model and the actual people counter numbers for different regions confirming the model performance is better in regions with more representative training sites. (a) (b) Model performance is strongly influenced by the availability of ground truth people counter data. In the next phase, we plan to work with a range of partners that maintain and can share people counter data to address this limitation. Over the next 12 months plans are in place to use additional sources of people counter data to improve the model estimations and recalibration of Strava Metro data. The outputs will then be used to develop a new [experimental statistic](https://www.ons.gov.uk/methodology/methodologytopicsandstatisticalconcepts/guidetoexperimentalstatistics) on visits to natural places. This project has successfully developed proof of concept machine learning model that can estimate monthly average people count for a diverse range of natural sites across England. The model developed has a higher spatial and temporal resolution than existing methods of measuring nature engagement and is also fully scalable to include more ground truth data as and when it becomes available. The approach is based entirely on crowdsourced and open datasets. We intend to publish the code alongside a further technical paper and the analysis is also fully reproducible. The outputs can aid decision making and offer a low-cost alternative to existing methods such as automated people counters. This approach has a wide range of potential uses. For example, measuring the use of new trails like the [England Coastal Path](https://www.nationaltrail.co.uk/en_GB/trails/england-coast-path/) or estimating or [nature reserves](https://designatedsites.naturalengland.org.uk/) . It could also offer a model for measuring general activity levels in a range of other policy settings such as health, active travel, recreation, and tourism. If you have any inquires about this project please contact: Tim Ashelford @ [Tim.Ashelford@defra.gov.uk](mailto:Tim.Ashelford@defra.gov.uk) Applications are now open for the Data Science Graduate Programme 2023 to 2025 on [Civil Service Jobs](https://www.civilservicejobs.service.gov.uk)! All the details on how to apply are available on the [job advert](https://www.civilservicejobs.service.gov.uk/csr/index.cgi?SID=c2VhcmNoc29ydD1zY29yZSZwYWdlY2xhc3M9Sm9icyZwYWdlYWN0aW9uPXZpZXd2YWNieWpvYmxpc3Qmc2VhcmNocGFnZT0xJm93bmVyPTUwNzAwMDAmam9ibGlzdF92aWV3X3ZhYz0xODUxMDczJnVzZXJzZWFyY2hjb250ZXh0PTMyNjc3MTMyJm93bmVydHlwZT1mYWlyJnJlcXNpZz0xNjgxODAxMzUyLTZjMmNiY2UyOWQxNTA5YzhhNDNmMmRhOWRjNTQ5OTg1YjVmMDBmMjk=). More information can be found on the [Graduate Programme information page](https://datasciencecampus.ons.gov.uk/capability/data-science-graduate-programme). In this guest blog post, Lilly Taylor, a graduate data scientist currently in her second year of the Graduate Programme, gives an account of what it is like to work as a graduate data scientist in the public sector. Lilly also shares an insight into her experience being part of the first cohort to have expanded outside the ONS, having completed her first year of the programme at HM Treasury, before securing a managerial role at the ONS during the second year of the programme. Hi, I'm Lilly and I will tell you a little bit about my own experience and perceptions of being on the Data Science Graduate Programme, the opportunities that being part of this programme have unlocked for me, and some general points, which I think are helpful for any graduate data scientist in the public sector to make the most of this opportunity. Given that all organisations are different, this means that there is a huge diversity of experience on mine and subsequent cohorts. So, if you ask a graduate data scientist what a day in their life is like, you're going to get different answers depending on whom you ask! I'll begin with some points to help you determine whether or not to make an application (and, I hope, encourage you to do so!) Perhaps you've come from a non-traditional data science background, or haven't had much coding experience, or have never worked in a data science role before. Rest assured, you will not be alone! Plenty of people on the programme are in this position. The programme isn't here for people who know everything already; it's designed to help you learn all the techniques you need to become a data scientist in the public sector, all within a supportive environment. You will be taught and supported by other data scientists and you will be able to ask as many questions as you like. Moreover, you'll be given lots of time to get up to speed in your role and certainly won't be expected to be proficient from day one. Personally, I came to the programme having studied chemistry while mostly coding as a hobby prior to starting and was keen to upskill myself in data science. The key ingredients are to be passionate about data science and have an enjoyment of solving problems. If you are, this programme is for you. Fight off imposter syndrome and put in an application - don't screen yourself out before you even apply! The programme is open to fresh graduates and seasoned professionals alike. You may be a new graduate with no experience in the workplace. Perhaps you don't consider yourself a graduate because it's been years since you finished your degree, and you've come from a different field or career path. You may be skilled in some areas the programme teaches but want to strengthen others. The programme is open to people from all of these situations. Having a diversity of participants on the programme makes it all the richer, so whether you're someone who has newly graduated, or you're looking for a career change to become a data scientist in the public sector, the programme is for you. The key ingredients are enthusiasm and curiosity. There are two routes into the public sector Data Science Graduate Programme; either as an external applicant, or the opportunity to partake in the training programme as an existing civil servant/public sector employee in your current role. Applying as an external applicant has the potential to unlock some excellent roles across the public sector. I was very fortunate in my allocation to HM Treasury. I found the Treasury an extremely exciting place to work, where you have the chance to work at the centre of government policymaking. I joined as one of four new data scientists in the newly established HM Treasury data science hub. In the time I was there, the team grew, including appointing a chief data officer to head up the team, which was a huge step. This year, HM Treasury opted to put a further 15 existing civil servants through the programme, which is a great development in building the organisation's data science capability. Given I was working within a central data science team within the Treasury, this meant that I was able to carry out a broad array of data science projects for different parts of the organisation. This made for a huge variety of work to get involved with, picking up different data science techniques along the way. In my first year on the programme, I worked on: Working across a variety of projects and techniques was great. Even if you don't get exposure to a broad range of data science projects within your role, the Graduate Programme is designed to provide additional opportunities including hackathons, coding club events, mini-projects and a final Kaggle competition. Lastly, regardless of what project you work on, the key benefit of working in the public sector is that you are working for the public good - something that really appealed to me when looking to join the civil service. What the programme does best is isolate lots of dedicated time purely for learning and development. You will have three full days per month in the first year to study the formal technical curriculum, followed by a lighter-touch syllabus in the second year to further your professional development. The curriculum is pretty much as broad as the field of data science itself. My favourite thing about the programme was that, as well as focusing on some of the traditional parts of data science, such as machine learning (ML) and natural language processing (NLP), it looked at the practical elements of being a data scientist. This included how to write clean and readable code, how to operate the command line, how to use Git version control, writing modular and reusable code and unit testing your code. As well as this, there were also modules on data engineering, including using SQL and working with big data in PySpark, for example. The combination of a formal curriculum, as well as coding in my day-to-day role, massively accelerated my development of technical skills. I came into the programme having already worked as an analyst (an [operational researcher](http://www.operational-research.gov.uk/recruitment)) in a couple of different government departments, which gave me an appreciation for the broader analytical community I'd be joining as a data scientist. Data science sits under both the [Government Analysis Function](https://analysisfunction.civilservice.gov.uk/careers/role-profiles-and-career-pathways/), and [Digital, Data and Technology function](https://www.civil-service-careers.gov.uk/professions/working-in-digital-data-and-technology/), enabling you to join a rich community of data and analysis professionals across government. There are lots of events and networks available to government analysts and data professionals which you can be involved with, giving you access to training opportunities, events and even new roles during your time in the public sector. There is also the [Government Data Science Community](https://datasciencecampus.ons.gov.uk/capability/cross-government-and-public-sector-data-science-community/) and interest groups for specialist techniques within this. Your own department may even have its own analytical or data science community for you to get involved in. The programme is two years long, and very much sets you up for success. Many graduates have progressed to more senior data science roles since joining the programme. For me personally, this has also been a great opportunity to accelerate my career. Having worked as an analyst in the civil service for a number of years, the Data Science Graduate Programme helped me plug a technical skills gap that I wanted to fill before going into a more senior role. After the first year of the programme, I was extremely fortunate to secure a leadership role at the ONS, where I have the opportunity to coach and mentor data scientists and analysts in my team. Going through the programme has given me an appreciation of the professional development needs of data scientists and supporting them has been my favourite part of my current role. The big picture stuff is well and good, but what is it actually like to be a graduate data scientist in the public sector, I hear you ask? While no two days are exactly the same, here is an illustrative example of a day I experienced as a graduate data scientist at HM Treasury. 09:00 to 10:00: Catching up on emails, noting what's in my calendar for the day and loading up my coding environments and scripts. 10:00 to 10.15: Daily stand-up - we'd set out what we are working on for the day and get any support we needed from the lead data scientist or our peers. 10.15 to 12:00: Coding on an individual project, often interspersed with reading up on some methodology that I'm not yet familiar with. 12:00 to 13:00: Lunch break 13:00 to 14:00: A team meeting so that we could be updated on any organisational issues and team plans, or pair programming with a colleague on a joint project. 14:00 to 15:00: Preparing a presentation for a key stakeholder. 15:00 to 16:00: Writing up some documentation for my work or installing some necessary packages. 16:00 to 17:00: Finishing up some coding tasks and saving my work before logging off! Push to make sure you get the chance to work on data science projects in your role, outside of the curriculum itself. It is when you apply the knowledge you're learning, that things really click, and stick with you! Consider volunteering as a programme rep on the Graduate Programme! This gives you the opportunity to be the voice of the cohort to enable the faculty to adapt the course content to what participants need. The faculty are really responsive, so you will have a real impact. Doing this is a great opportunity to develop your leadership skills! It's not all about technical skills! Once you get your feet under the table and start to think about how to progress as a data scientist in the public sector, it is great to work towards interacting with stakeholders and mentoring others. Keep in mind that you won't be working on machine learning problems the majority of the time. On any data science project, the bulk of time will be spent on preparing your data so that it is ready to analyse. As well as this, not all projects will lend themselves to machine learning, but perhaps to other domains such as automation and creating reproducible analytical pipelines. While you should accept that you won't always get to work on your first choice of technique, don't keep quiet about the things you are interested in learning. Flag this to your manager to maximise the chances of getting exposure to the techniques you particularly want to learn. Find yourself a mentor; these can be really great in fostering your career development, whether it be your technical skills or your wider skills as a public sector worker. I hope this has been helpful in determining whether the programme is right for you, and if you join us as a graduate data scientist, I hope it helps you to get the most out of it! It will be great to see a new batch of data professionals join the public sector. Whichever organisation you land in, you will have the opportunity to work on issues that positively impact the lives of the public, which is incredibly rewarding. To apply and for more information about the [Data Science Graduate Programme](https://datasciencecampus.ons.gov.uk/capability/data-science-graduate-programme), please visit the programme's information page. Our [Frequently Asked Questions (FAQs) page](https://datasciencecampus.ons.gov.uk/capability/data-science-graduate-programme-frequently-asked-questions-faqs/) may also be helpful if you have any queries. We have created a space on our [KnowledgeHub group](https://khub.net/group/government-data-science-festival), which is open to anyone with a government email address, where we can share [career resources](https://khub.net/group/government-data-science-festival/group-wiki/-/wiki/Main/Resources+for+Career+Development?p_r_p_http%3A%2F%2Fwww.liferay.com%2Fpublic-render-parameters%2Fwiki_nodeName=Main&p_r_p_http%3A%2F%2Fwww.liferay.com%2Fpublic-render-parameters%2Fwiki_title=Resources%20for%20Career%20Development). So far, these include the [questions from the panel event](https://khub.net/group/government-data-science-festival/group-wiki/-/wiki/Main/Career+Q%3CAMPERSAND%3EA?p_r_p_http%3A%2F%2Fwww.liferay.com%2Fpublic-render-parameters%2Fwiki_nodeName=Main&p_r_p_http%3A%2F%2Fwww.liferay.com%2Fpublic-render-parameters%2Fwiki_title=Career%20Q%26A) and advice for planning your career, developing your skills and finding roles in the public sector. The resources include signposts to a range of learning opportunities, including [the Analysis Function's learning pathways](https://analysisfunction.civilservice.gov.uk/learning-development/learning-pathways/). The community is a highly collaborative space that draws heavily on the resources, experience and knowledge of its members to serve their needs. We are inviting our members to contribute to our [career resources](https://khub.net/group/government-data-science-festival/group-wiki/-/wiki/Main/Resources+for+Career+Development?p_r_p_http%3A%2F%2Fwww.liferay.com%2Fpublic-render-parameters%2Fwiki_nodeName=Main&p_r_p_http%3A%2F%2Fwww.liferay.com%2Fpublic-render-parameters%2Fwiki_title=Resources%20for%20Career%20Development) by sharing what capability programmes are available across the public sector, which roles are available and how to access them. We think that the community's greatest strength is its potential to bring together peers who can support each other on their career journeys, which is why we are also working on ways to strengthen connections between our members, beginning with the Living Library. Mentorship is a powerful tool for development, as we have seen from the many successful [Accelerator](https://datasciencecampus.ons.gov.uk/capability/data-science-accelerator/) projects that have been showcased over the years. There are many members of the community who would benefit from both mentoring and being mentored by their peers, as we all have valuable experience to share. We will be tapping into this wealth of experience by launching a Living Library for the community on 26 April 2023. What does it mean to be a living book? Like a physical book, you will have a title, a blurb, and a table of contents. This might include your technical skills, tools that you have worked with or other skills such as leadership and project management. Visitors to the library will be able to \"check out\" your time, initially for a half-hour meeting. By being \"checked out\", you are providing valuable mentorship and advice to a member of the community who is interested in your experience. Please fill out the [Living Library expression of interest form](https://forms.office.com/Pages/ResponsePage.aspx?id=vweIB4LOiEa84A2BFoTcRqyZH350RK5LoLYHS7ST_B9UQkZRQ0VBWTRaMURLRExQMkxGTVhLWURIUC4u) to be a part of our Living Library. If you have any questions, [get in touch with the Data Science Community team](https://forms.office.com/Pages/ResponsePage.aspx?id=vweIB4LOiEa84A2BFoTcRqyZH350RK5LoLYHS7ST_B9UQkZRQ0VBWTRaMURLRExQMkxGTVhLWURIUC4u). The [Data Science Community](https://datasciencecampus.ons.gov.uk/capability/cross-government-and-public-sector-data-science-community/) is a vibrant space where those with an interest in data science, across the public sector, come together to share knowledge, exchange ideas, and build networks. The community and its associated subcommunities provide opportunities to develop skills and keep up to date with data science in government. Among the ways in which our members engage with the community is through our monthly meetups. The community meetups happen once a month on Teams and are great opportunities to showcase data science projects from across the public sector. Following feedback from our members who were looking for career, application and interview advice, last month's meetup was focused on supporting members with their career journeys.We hosted two panel discussions, one for early-career data scientists and one for those looking to progress into more senior roles. Both sessions were highly engaging and sparked lively discussions, and the panellists answered a variety of questions about skill development, when and how to apply for roles and typewriters. Our panellists in Room 1 had all engaged in capability programmes that had supported them in their career journeys. Jonathan Rees of Public Health Wales is a graduate of the level 6 Data Science Apprenticeship scheme, David Loughlin (HMRC) has completed a Master's degree in Data Analytics for Government (MDataGov), and Mia Noonan (NHS Digital) has taken part in the Data Science Accelerator programme. In this room, we discussed how analysts can build experience to move into the data science space and how it feels to be constantly learning new techniques. In Room 2, our panellists were Chris Beeley, Senior Lead Data Scientist at the Strategy Unit (NHS), Joseph Crispell, Senior Data Scientist at the Data Science Campus (Office for National Statistics), and Zoe Walker, Associate Data Science Product Manager at the Ministry of Justice. These panellists fielded questions about skill development, whether technical or non-technical, and their motivation to remain in the public sector. All our panellists were sent the questions that we did not have time to ask, and their answers are being shared on our [KnowledgeHub group](https://khub.net/group/government-data-science-festival). It was clear from both the fantastic attendance at the meet-up and the volume of questions for our panellists that public sector data scientists are seeking support for their career and skill development. The Data Science Campus offers a suite of programmes to build capability in the public sector, including the [Master's (MSc) in Data Analytics for Government (MDataGov)](https://datasciencecampus.ons.gov.uk/capability/msc-in-data-analytics-for-government/) and [Data Science and Data Visualisation Accelerator](https://datasciencecampus.ons.gov.uk/capability/data-science-accelerator/) programmes previously mentioned, and [the faculty's learning journeys](https://datasciencecampus.ons.gov.uk/capability/data-science-campus-faculty/). Through our work managing the community, we can help to draw people's attention to these programmes as well as raising awareness of opportunities across the public sector. For example, we recently started including links to vacancies in our [community newsletter](https://ons.us1.list-manage.com/subscribe?u=0f8869b47a9fed86f0fa1dc17&id=998edd3774), which we send at the end of every month. You can find all community-related information, links, and resources on the [Data Science Community page](https://datasciencecampus.ons.gov.uk/capability/cross-government-and-public-sector-data-science-community/). You can [register for our upcoming events on Eventbrite](https://www.eventbrite.com/cc/data-science-community-of-interest-1647559) and we welcome contributions from our members. If you have an interesting data science story or project to share, reach out to us at [government.data.science.community@ons.gov.uk](mailto:government.data.science.community@ons.gov.uk), and we will arrange for an opportunity to present it to our friendly and welcoming community. Our community are active on [the Gov Data Science Slack](https://govdatascience.slack.com/), and you can join the conversation by signing up with any government email address (if yours is not automatically accepted, send us a message). If you are interested in more technical discussions with peers who share your interests, have a look at our subcommunities by visiting their channels on our Slack workspace: Subcommunities are self-sufficient and run by members of our community. If you would like to run a subcommunity for people with a specialist interest, please get in touch. You can stay up to date with the Data Science Community by joining our [mailing list](https://ons.us1.list-manage.com/subscribe?u=0f8869b47a9fed86f0fa1dc17&id=998edd3774). Following a curriculum review and update of our learning materials in October 2022, which also led to the launch of our [accessibility process](https://datasciencecampus.ons.gov.uk/paving-the-way-for-accessible-data-science-training-in-the-public-sector/) for all our documentation and training materials, we have started to deliver instructor-led workshops for Introduction to R and Introduction to Python. These workshops, originally delivered by the Analysis Function, proved to be very successful and in high demand. They are a great way for analysts to continue to develop skills and build confidence with programming skills. The instructor-led workshop sessions guide participants at the start of their journey and aim to provide a springboard for analysts to continue to build sought-after data science skills following the programme. We offer the courses at entry level for those looking to take the first step into programming or refresh their knowledge for an upcoming data science project. This aligns with our goal to build data and data science skills across government and the wider public sector. Since October 2022, our lecturers have facilitated courses for over 170 participants across 15 government departments including the ONS, Home Office, Department for Environment, Food and Rural Affairs (Defra), NHS Wales and Scottish Government. Our instructor-led sessions are held online, once a month, and consist of four half-day sessions. The courses focus on applying skills and building confidence, independence and resilience with programming skills, so that students can continue learning beyond the classroom. More information about these sessions is available on our [faculty page](https://datasciencecampus.ons.gov.uk/capability/data-science-campus-faculty/). Read what some of our previous students have to say about our instructor-led sessions: \"I thought the lecturers were really good and engaging. They explained everything in a clear way and took the time and patience to help everyone when they had issues.\" \"I thought that course was great with an enthusiastic, patient, and knowledgeable trainer.\" \"The teaching was very clear, a combination of explanation of why functions or code is structured that way to give a base for understanding further work, asking questions and getting input from attendees.\" If you are interested in joining a instructor-led course or keen to upskill your department, please [email the Data Science Campus faculty team](mailto:Data.Science.Campus.Faculty@ons.gov.uk). Transactional-level and firm-level data with long time-series coverage are rarely used to analyse preference utilisation rates (PURs). An [analysis conducted by the Data Science Campus and the Department for International Trade](https://datasciencecampus.ons.gov.uk/projects/employing-data-science-to-analyse-the-use-of-preferential-tariffs-in-free-trade-agreements/) not only fills a gap in existing literature by using firm-level data from business register and transactional-level customs data to analyse the uptake of preferential tariffs by UK importers from non-EU countries, but it also establishes a longer time series that includes the period from 2009 to 2019. The HM Revenue and Customs (HMRC) trade in goods (TiG) data made available to us, which include all the relevant information required to conduct our analysis, cover the period ending 2019. HMRC has changed their data collection method since 2021, but our analysis focuses on the period before those changes. In this technical report, we go behind our analysis on the use of microdata for the examination of preference tariff utilisation and take a deep dive into challenges of drawing together new, administrative data sources to answer policy relevant questions. We also explain the reasons to use firm-level and transactional-level data to analyse PURs and the improvements that our analysis provides as compared with existing empirical studies. International trade plays an important role in the UK economy. Total UK trade in goods exports were \u00a3366.8 billion in 2019, of which \u00a3197.1 billion was from non-EU countries, while total UK trade in goods imports were \u00a3541.8 billion in 2019, of which \u00a3275.6 billion was from non-EU countries, as described in HMRC's [UK Overseas Trade in Goods Statistics Summary of 2019 Trade in Goods (PDF, 951 KB)](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/865366/OTS_2019_Annual_Summary.pdf). Using data from [the GDP quarterly national accounts, UK: July to September 2022 statistical bulletin (PDF, 1825KB)](https://www.ons.gov.uk/economy/grossdomesticproductgdp/bulletins/quarterlynationalaccounts/julytoseptember2022/pdf) we find that UK exports of goods as a percentage of GDP was 16.24% in 2019, while UK imports of goods as a percentage of GDP was 22.86% in 2019. These figures show the importance of trade as an economic activity, and how increases and decreases in trade activity are likely to have a large impact on the economy. [Wales, Black, Dolby and Awano (2018)](https://www.escoe.ac.uk/publications/uk-trade-in-goods-and-productivity-new-findings/) report that UK businesses that declare international trade in goods were found 70% more productive on average than those business that do not trade in 2016. It is therefore essential for policymakers to understand what can help to encourage trade activities, how current free trade agreements (FTAs) perform, and how the economic benefits of FTAs could be achieved. Free trade, or the elimination of trade barriers, can offer economic benefits. These include, for example, more exports, economies of scale, lower prices, and greater choice of products. PTAs enable countries to grant preferential tariffs to imports from their trading partners. Through PTAs, countries give tariffs lower than their most favoured nation (MFN) rates to their trading partners' products. These agreements are usually reciprocal in a customs union, which means all parties agree to give each other the benefits of lower tariffs. PTAs can also be offered to a trading partner unilaterally rather than on a reciprocal term. The General System of Preferences (GSP) scheme is an example in which developed countries offer preferential tariffs on imports from developing countries. By analysing the pattern of preference tariff utilisation, policymakers can: The full economic benefits of trade agreements can only be achieved if firms make use of preferential tariffs. However, studies show a significant variation in preference tariff utilisation across the member states of the European Union (EU) and other trade partners. The PUR measures the extent to which preferential tariffs, rather than MFN tariffs, are claimed for preference-eligible dutiable trades. We calculate PURs as the total transaction value of preferential imports divided by the total transaction value of preference-eligible imports. Using publicly available aggregate data on [preference utilisation on EU imports](https://trade.ec.europa.eu/doclib/html/159046.htm) that accompanies a [publication on EU trade agreement published by the European Commission](https://ec.europa.eu/commission/presscorner/detail/en/ip_20_2091), we find that the PUR of imports from all non-EU countries to the UK in 2019 is 82.4%. Although this figure reflects the fact that firms do not always use preferential rates even when they are available, it does not give further information that can help refine the design of policies. Having a better understanding of how the uptake of preferential tariffs varies across different firm characteristics could help to design policies that target different types of firms. For example, if preference uptakes are found to be quite low among small firms, then policy designed to encourage utilisation among these firms could be beneficial. Therefore, a detailed breakdown of aggregate PURs is required for better policy, though discovering the reasons behind the uptake of preferential rates is not within the scope of our study. Nevertheless, our findings provide a detailed picture of the uptake of PURs across different types of UK firms, laying the foundation for further investigations. Information about firm characteristics can either be obtained from surveys or from a business register. Our analysis uses the latter because it has a near-population coverage of UK firms. By linking a business register to transactional-level customs data, we obtain a representative picture of UK traders' decisions to use preferential tariffs. As pointed out in [National Board of Trade Sweden (2019)](https://www.kommerskollegium.se/globalassets/publikationer/rapporter/2019/publ-who-uses-the-eus-free-trade-agreements.pdf), details of individual trade transactions are usually hidden in aggregate trade data or trade statistics, whereas transactional-level data provide details of individual transactions or shipments that were declared to customs, the transaction value, frequency, traders' identifier, and product category. Combining firm-level information stored in business registers and transactional-level information stored in customs data, as well as a long time-series coverage, our analysis can provide answers to: A combined use of firm-level and transactional-level data to analyse PURs is rare in the growing literature on PURs. Transactional-level administrative data are usually not publicly available and access to them often requires special permission from authorities. Many existing studies in this topic use aggregate data for analysis. For example, [Ando and Urata (2018) ](https://www.rieti.go.jp/jp/publications/dp/18e078.pdf)use the [Trade Compass Database of Deloitte](https://www.deloittetradecompass.com/) to compute free trade agreement (FTA) utilisation rates as share of imports under FTA schemes in total imports at product level and obtain preference margin as the difference between FTA tariffs and MFN tariffs. Other studies on the utilisation of trade agreements use data from surveys that are based on defined samples. For example, [PricewaterhouseCoopers (PWC) (2018)](https://www.pwc.com.au/trade/free-trade-agreement-survey.html) has conducted a business survey that asks Australian firms about their experience with using FTAs, particularly with China, South Korea, and Japan. [Takahashi and Urata (2008)](https://www.rieti.go.jp/jp/publications/dp/08e002.pdf) base their analysis on data from a survey in which 469 firms were asked if they have used FTAs, the reasons for not using them, their experience in the ease of using FTAs, and the impact of FTAs on their sales, costs, and profits. However, the use of transactional-level data is still quite rare in existing PURs literature. [Albert and Nilsson (2016)](https://www.etsg.org/ETSG2016/Papers/090.pdf) use transactional-level data to study utilisation of preferential rates. They estimated the fixed-cost thresholds of using preferential tariffs using transactional-level data for EU exports for 2011 obtained from Iceland's custom authorities. [National Board of Trade Sweden (2019)](https://www.kommerskollegium.se/globalassets/publikationer/rapporter/2019/publ-who-uses-the-eus-free-trade-agreements.pdf) use detailed-level administrative data, merged with company-level data, to examine the use of the EU's FTAs in trade transactions with South Korea by Swedish importers in 2016. Their report gives a thorough analysis of how the use of preferential tariffs varies across firm characteristics. They investigate the importance of tariff preference on total imports; examine PURs across firms, products, and import modes; and obtain transaction values and preference margin by firm size and product. They also use a logit regression to examine the relationship between utilisation of tariff preferences and potential duty saving. Our study makes two improvements to existing PURs analysis. First, we draw our insights with the aid of data science methods that combine statistical and machine learning techniques. Secondly, we also make improvements in the use of data, which are: In the remaining part of this technical report, we will provide an overview of the microdata available in the UK for our analysis of PURs and the characteristics of these data. We will then discuss the challenges in using these data for our analysis. There are three main datasets that enable firm-level analysis of preferential tariff utilisation in the UK. Two of these, HM Revenue and Customs (HMRC) trade in goods and the Inter-Departmental Business Register, come from administrative records. The third is International Trade Centre's Market Access Map. UK trade in goods (TiG) data are collected by HMRC for administration and tax purposes. Although HMRC has changed their data collection method since 2021, our analysis focuses on the period before those changes. The TiG data cover a large proportion of UK trade in goods transactions and are used by HMRC for two National Statistic series: [Overseas Trade Statistics (OTS)](https://www.uktradeinfo.com/trade-data/overseas/) and [Regional Trade Statistics (RTS)](https://www.uktradeinfo.com/trade-data/regional/). RTS data provide a breakdown of UK imports and exports by UK region and are derived from the OTS. For information about the trade data sources, see this [publication by HMRC](https://www.uktradeinfo.com/trade-data/help-with-using-our-data/#our-data-sources). The TiG data cover three types of transactions. Firstly, TiG data cover import and export transactions between UK businesses and those within the European Union (EU); data on UK's trade in goods with EU member states are collected through VAT return submission of businesses. Businesses with a larger amount of trade, whose monthly value of trade usually crosses an administrative threshold, are required to report using the Intrastat monthly survey; this allows HMRC to collect more detailed data about their trading activity. For more information about the administrative thresholds and the three types of transaction included in the trade data, see also Section 3.3 in [Wales, Black, Dolby and Awano (2018)](https://www.escoe.ac.uk/publications/uk-trade-in-goods-and-productivity-new-findings/). Secondly, TiG data cover import and export transactions between UK businesses and those outside of the EU; businesses that import and export goods to and from non-EU countries are required to complete a custom declaration, mainly through the Custom Handling of Import and Export (CHIEF) system. These data are regarded as administrative records, unlike those collected from EU imports and exports that are from survey sources. Thirdly, TiG data cover estimates and adjustments; this includes estimates of total values of trade missing where businesses have not submitted their returns or have submitted incomplete returns, and those accounting for complex VAT fraud. It also includes estimates for businesses that operate below the reporting threshold of Intrastat. The TiG data contain a rich set of information about each trade transaction that crosses the UK border. Such information includes country of dispatch or destination, value of trade, commodity type as given by the commodity code, trader identifier, custom procedure code, and rate of duty being claimed. Rate of duty being claimed is a major variable in the analysis of preferential tariff utilisation as it indicates whether a preferential tariff is being claimed for the transaction. The UK TiG data have been used for trade analysis, see for example [Wales, Black, Dolby and Awano (2018)](https://www.escoe.ac.uk/publications/uk-trade-in-goods-and-productivity-new-findings/). They have also been used for statistical publication. But they have not been used for firm-level analysis of preferential tariff utilisation in the UK. Our project is the first in the UK to examine this topic using this transactional-level administrative data. While the TiG data contain information about trade transactions and information on whether preference tariffs have been claimed, they do not provide information about firm characteristics such as geographical location, turnover, and employment. Using these data alone do not allow us to examine how the uptake of preferential tariffs varies across different firms. There is a need to enrich these data with firm-level characteristics, prompting us to link them to a business register. The Inter-Departmental Business Register (IDBR) was developed in 1995 to replace the Value Added Tax (VAT)-based register of the Central Statistical Office and Pay As You Earn (PAYE)-based register of the employment departments. See [Review of the Inter-Departmental Business Register (PDF, 745KB)](https://www.ons.gov.uk/file?uri=/businessindustryandtrade/business/activitysizeandlocation/methodologies/ukbusinessactivitysizeandlocation/idbrbv2tcm77185685.pdf) for more details. It is a comprehensive administrative record with near-population coverage of UK businesses. The IDBR covers all businesses registered for VAT and/or PAYE schemes, but it does not cover those without VAT (for example, businesses fall below the VAT threshold) or without PAYE schemes (for example, self-employed or without employees). There are about three million live businesses registered on the IDBR as of December 2019. The register holds business information such as names, addresses, Standard Industrial Classification (SIC), employment, turnover, ownership, and legal status. Such information is drawn from different sources including HMRC VAT and PAYE schemes, Companies House data, Dunn and Bradstreet, and Office for National Statistics (ONS) surveys. A firm presents on the IDBR as different business units. The first type of business units is called statistical units, which consist of: The second type of business units is called administrative units, which consist of: The third type of business unit is called observation units, which are known as the reporting units. A reporting unit holds the mailing address to which official survey questionnaires are sent. In many cases, a reporting unit and an enterprise are the same in scope \u2014 this is true when a business has a simple structure on the IDBR. However, a large enterprise could arrange with the ONS to have separate reporting units. This is either to alleviate reporting burden or because the enterprise is involved in multiple business activities that belong to different industries according to the Standard Industrial Classification (SIC). For example, a manufacturing enterprise that also involves retail could have a separate reporting unit for its retail division to answer surveys that are specific for retailers. Figure 1 and 2 display examples of a simple and a complex firm in terms of IDBR units. Different information is stored in the IDBR under each of these units, in the form of data tables. These data tables are known as other government department (OGD) IDBR extracts; they are snapshot data taken from the register at a particular point in time. Those firms with a complex structure as in Figure 2 are usually large firms that are involved in multiple businesses activities. See also Appendix 1 in [Lui, Black, Lavendero-Mason and Shaft (2020) (PDF 2367KB)](https://escoe-website.s3.amazonaws.com/wp-content/uploads/2020/10/15063641/ESCoE-DP-2020-14.pdf) for discussion about the IDBR. While TiG data provide details of individual trade transactions, the IDBR contains a rich set of information about a firm, and this information is stored in separate data tables of its IDBR units. For our firm-level analysis, the information stored on the enterprise, reporting unit, and VAT units suffice. Figure 3 summarises the important information required from the two datasets for our study. The TiG data provide us with information about trade transactions declared by the VAT trader. The IDBR provides us with information about businesses. Our project makes use of the data about firm characteristics stored in the IDBR enterprise, reporting unit and VAT unit tables. We produce a linked IDBR dataset to gather details about firms stored in its separate business units using different IDBR identifiers. The TiG dataset can be merged with the linked IDBR dataset using the VAT reference number as the common identifier. Our firm-level analysis focuses on the uptake of preference tariffs of UK imports from non-EU countries. We make use of the IDBR and TiG administrative datasets. A linked IDBR-TIG dataset is constructed to investigate how different firm characteristics relate to businesses' uptake of preference tariffs on import transactions. Figure 4 summarises the construction of the IDBR-TiG linked dataset, we start the procedure by first combining the IDBR enterprise, reporting unit and VAT unit data tables using the enterprise reference number as a common identifier to create a linked IDBR dataset. We then merge the TiG data to this linked dataset via VAT reference number. Combining these two datasets would enable us to conduct detailed-level analysis. However, the linking process is not a straightforward exercise because of some data limitations. To establish an appropriate strategy to combine these data, it is crucial to understand these limitations. Moreover, a good knowledge of these issues and the challenges involved in using these data for firm-level analysis also enable us to understand the caveats to our findings. In the next section, we discuss the challenges we face in using these data. We need to identify the import transactions from the IDBR-TIG linked data that are eligible for preferential tariffs, as these are required for the estimation of preference utilisation rates, based on the definition we gave earlier. We achieve this by using the International Trade Centre's [Market Access Map (MAcMap)](https://m.macmap.org/), which is a database that provides information such as customs tariffs, tariff rate quotas, regulatory requirements and preferential tariffs that apply, for each product. We linked the IDBR-TIG database to MAcMap by matching the commodity code from IDBR-TIG to the product code from MAcMap at the 10-digit commodity level. Then, we removed all transactions not eligible for preferential tariffs by dropping transactions that do not have a corresponding preferential tariff rate in MAcMap based on the year, country and commodity code. The TiG data and the IDBR are commonly known as administrative data or administrative records. Administrative data are not designed for scientific research but are records created during some administrative operations. They can be used for statistical production, for example, the Overseas Trade in Goods Statistics published by HMRC. The compilation of statistics based on administrative sources is increasingly common. For example, the HMRC VAT returns data have been used for the production of national accounts, including short-term indicators and for gross domestic product (GDP). Administrative records are also used for other statistical operations, for example, the IDBR is the sampling frame of ONS business surveys. However, it is not until recent years that the use of administrative data for scientific research has become popular. There are pros and cons of using administrative data for analysis, and there are also challenges involved ( [see Hand (2018)](https://spiral.imperial.ac.uk/bitstream/10044/1/61527/2/Statistical%20challenges%20of%20administrative%20and%20transaction%20data%20FINAL%20version.pdf) and [K\u00fcnn (2015](https://wol.iza.org/uploads/articles/214/pdfs/challenges-of-linking-survey-and-administrative-data.pdf)) for a discussion of some of those issues). Access to administrative data usually requires special permission granted by official bodies. These data are not restricted by sample size and usually have population or near-population coverage. Hence, they allow us to build a representative picture of an economy or of the entities in the economy (for example, businesses and individuals). However, administrative data are also subject to human errors or misreporting. Quite often, these errors are not easily identified, and it is very difficult to verify the accuracy of administrative data. The Rotterdam Effect (which we are about to discuss) is an example of misreporting that affects official statistics. We focus our discussion here on the challenges specific to our study of preferential tariff utilisation in the UK using the data sources discussed in the previous section. The Rotterdam effect (also known as Rotterdam-Antwerp effect or transhipment effect) refers to the problem of misreporting trade when goods pass through major ports on their way to their final destinations. This problem distorts calculation of trade statistics. Rotterdam and Antwerp are import hubs for trade from non-EU countries before it is routed to other EU destinations. Misreporting occurs when, for example, goods trade flowing from Africa to the UK stops at the Netherlands for a short period of time and is wrongly recorded as UK trade with the Netherlands. Existing research has found a significant quantity of Dutch imports from EU and non-EU countries that were re-exported to the UK (see [Lemmers (2019)](https://www.escoe.ac.uk/dutch-imports/)). Moreover, using HMRC data from 2013, the ONS has estimated the impact of the Rotterdam effect on UK trade estimates with EU and non-EU countries compared with the actual published data; this showed that the Rotterdam effect might mean exports to non-EU countries are higher by 4.3 percentage points (from 49.6% to 53.9% of total trade in goods) and imports from non-EU countries higher by 4.2 percentage points (from 46.7% to 50.9% of total trade in goods). These estimates are based on an extreme assumption that 50% of UK trade with the Netherlands is related to non-EU countries; see Table 2 of the [UK Trade in Goods estimates and the 'Rotterdam Effect'](https://webarchive.nationalarchives.gov.uk/20160106003022/http:/www.ons.gov.uk/ons/rel/uktrade/uk-trade/december-2014/sty-trade-rotterdam-effect-.html) publication. The Rotterdam effect potentially affects the representativeness of any analysis using UK trade data, whether the focus is on imports from non-EU countries (underestimation) or imports from the EU (overestimation). Our study examines the uptake of preferential tariffs in UK imports from non-EU trading partners for the period 2009 to 2019. The Rotterdam effect implies that the TiG data on UK imports from non-EU trading partners may not include all UK import transactions with the non-EU countries. Developing methods to produce better estimates in the light of the Rotterdam effect is beyond the scope of our study. There are existing studies on developing methods to produce better estimates of the share of imports that are destined for re-export; see, for example, [Lemmers and Wong (2019)](https://www.niesr.ac.uk/publications/distinguishing-between-imports-domestic-use-and-re-exports-novel-method-illustrated-netherlands?type=national-institute-economic-review). Further analysis of PURs could make use of these methods. Firm-level analysis requires information stored in the different IDBR tables, and each of them is specific to a business unit of the same firm (enterprise, reporting unit, and VAT unit). Figure 1 and 2 illustrate how these different units of the same business relate. It is important to note that not all identity links displayed in the two figures are directly observed. For example, there is no direct link between the VAT unit, through which the TiG data are linked to the IDBR to create a dataset for our analysis, and the reporting unit that contains certain firm-level information. This is because, according to the IDBR structure, administrative units are directly related to or sit underneath the parent enterprise of their administrative headquarters, but they are not the part of the firm that is responsible for answering surveys. Moreover, different information is stored in different IDBR tables that are specific to the business units. That is, not all firm-level information of interest to our analysis is stored in the data tables of a single IDBR business unit. This is mainly because of how information is stored on the IDBR and from which channel the information is collected. For example, details about location and employment are not stored in the IDBR VAT data tables. While the IDBR reporting unit data tables contain reporting unit-level geographical information, this is not available in the enterprise data tables. Besides, information on the IDBR is not real-time or near real-time, even though administrative information is usually updated on an as-and-when basis. There is often a time lag in the arrival of information. Pooling information recorded in different business units within a firm is a challenging exercise. It requires us to first construct an IDBR-linked dataset to combine the enterprise, reporting unit, and VAT unit data tables to re-establish the \"lost\" identity links within the same firms. Once this is done, we can then match the TiG data to the linked IDBR dataset. Pooling data stored in different IDBR business units also requires us to understand the limitations of the information derived from these different business units. For example, whether this information applies to the whole firm or only part of the firm. This concern arises as not all firms on the register have the simple structures shown in Figure 1. Many firms on the register have complex structures similar to Figure 2, with multiple business units at levels below the enterprise. We will explain in more detail the complications this causes. The concept of \"firm\" appears to be quite elastic among existing firm-level analysis using the IDBR. For example, [Lui, Black, Lavendero-Mason and Shaft (2020) (PDF 2367KB)](https://escoe-website.s3.amazonaws.com/wp-content/uploads/2020/10/15063641/ESCoE-DP-2020-14.pdf) study business dynamism at the enterprise level, while the [ONS regional productivity analysis](https://www.ons.gov.uk/economy/nationalaccounts/uksectoraccounts/compendium/economicreview/april2018/regionalfirmlevelproductivityanalysisforthenonfinancialbusinesseconomygreatbritainapril2018%22%20/l%20%22results-firm-level-local-plant-productivity-by-industry-groups) uses the Annual Business Survey local unit dataset. Hence, a \"firm\" in an existing study could refer to a local unit, a reporting unit, an enterprise, or a VAT unit. It depends on which IDBR unit(s) the study draws its data from. This is not an issue if the analysis only requires information related to one IDBR business unit, and if an analysis focuses on firms with simple structures (as depicted in Figure 1). In this case, an enterprise has only one reporting unit, one local unit, one VAT unit, and one PAYE unit. Therefore, information stored in any of these data tables is applicable to the whole firm. However, many firms have complex structures like the one in Figure 2. In such cases, values directly related to one of the firm's reporting units or one of its VAT units are not applicable to the entire firm. An import transaction in the TiG data refers to a VAT trader rather than the whole firm, but firm characteristics derived from the IDBR do not always refer to a specific VAT trader. Our study adopts the assumption that an enterprise (headquarter) is the unit that makes the decision to trade. Therefore, when measuring firm-level characteristics, we prefer information, such as employment, region, and turnover, that is measured at the enterprise level. However, as previously mentioned this is not always possible. While the IDBR enterprise data table stores the enterprise-level number of employees primarily obtained from the Business Register and Employment Survey (BRES), region is only available at the reporting-unit level. Therefore, for enterprises with multiple reporting units with different region values attached to them, our UK regional results are indicative. Note that the IDBR also contains enterprise groups each consisting of multiple enterprises. However, not all enterprises belong to an enterprise group. Our study defines an enterprise as the highest level IDBR business unit. Turnover values are currently stored in the IDBR enterprise, reporting unit, and VAT tables. The source of such values in the enterprise and reporting unit data table are mainly from the Annual Business Survey (ABS) and HMRC VAT source if the firms are not sampled. The ABS contains about 62,000 firms each year. The survey covers all large firms with more than 250 employees with a random sample of smaller firms (including small- and medium-sized firms). The source of the turnover values stored in the IDBR VAT data tables are mainly from the HMRC VAT returns. Data from HMRC VAT returns are usually a preferred option over data from surveys as the former are more up to date and provide a consistent source of data for all firms. However, as well as having complex business structures, some firms also have complex VAT reporting structures. A complex VAT reporting structure is commonly observed for those enterprises that participate in multiple business activities. There are usually four different types of VAT reporting arrangements. Type 1: An enterprise has one or multiple standard VAT units. Each of these units reports turnover for the enterprise. Type 2: An enterprise is a member of a VAT group; that is, multiple enterprises share common VAT registration. A VAT group contains a representative VAT unit and some non-representative VAT units. Only the representative VAT unit reports for all the enterprises in the group. Representative VAT units report turnover to HMRC for the whole VAT group, but non-representative VAT units do not report to HMRC. The proportion of turnover reported by the representative VAT unit for each enterprise is unknown as these shares are not required in the submission to HMRC. Type 3: An enterprise has divisional VAT units. These VAT units could be found in a large firm that carries out its businesses through a number of divisions. These VAT units share the same Companies House number and hence should not be treated as individual VAT traders. Type 4: An enterprise has standard VAT unit(s) and, at the same time, belongs to a VAT group. For the first and third arrangement type, aggregation of VAT turnover to the enterprise level would be straightforward. However, obtaining enterprise-level turnover arrangements for the second and fourth type requires an accurate apportionment strategy. Establishment of such a strategy is beyond the scope of our analysis. Therefore, we take the decision to use turnover values from the IDBR enterprise data table, fully aware that these values are from a mix of survey and administrative sources. Besides, there is also another complication because of inconsistent VAT reference numbers in the two datasets. The VAT reference number in the IDBR has 12 digits with the last 3 digits constituting the sub VAT number (SVN) that is used to distinguish the representative VAT unit from the non-representative ones. However, VAT traders in the TiG data are only identified by 9-digit VAT reference numbers. This requires us to convert the 12-digit VAT reference in the IDBR data tables prior to merging the register with the TiG data. The [firm-level analysis](https://datasciencecampus.ons.gov.uk/projects/employing-data-science-to-analyse-the-use-of-preferential-tariffs-in-free-trade-agreements/) of preferential tariff utilisation conducted by the Data Science Campus and the Department for International Trade is the first of its kind in the UK that makes use of a rich set of information derived from administrative records. We explain in this technical report what drives us to study PURs using firm-level and transactional-level data, as well as the research questions these data allow us to answer that cannot be answered using aggregate data or statistics. We provide a brief overview of the data used in existing empirical studies that are largely aggregate data and survey-based data. We then explain the data improvements we have made in our study, along with some of the challenges we have encountered in making those improvements. We discuss the two UK administrative datasets, the trade in goods (TiG) and the Inter-Departmental Business Register (IDBR), used in our study. Our analysis focuses on UK import transactions form non-EU trading partners. We first construct an IDBR-linked dataset to bring together firm characteristics recorded in the data tables of each unit. The variables we take from the IDBR indicate employment size, geographic location, and turnover. We then link the IDBR to TiG data and use certain variables in the TiG data that give us details about whether a transaction has claimed preferential tariffs, its importer as identified by Value Added Tax (VAT) reference number, its value, the custom procedure involved, and its country of origin (or dispatch). There are limitations of the two sets of administrative records that we use. These issues include, for example, misreporting in trade data, \"lost\" identity links among IDBR business units, updating issues of the IDBR, and complications arising because of complex business structures and complex VAT reporting arrangements. Some of these issues we attempt to address in our study. For example, constructing a linking strategy to re-establish identity links among business units and a strategy to link TiG to IDBR in the face of an inconsistent format of VAT identifiers in the two datasets. We recognise that some improvements to the data could perhaps be made in future analytical work to increase the quality of microdata for this kind of analysis. For example, future work could establish an appropriate turnover apportionment strategy to better deal with the issues we face with enterprises with VAT group reporting arrangements and to use HM Revenue and Customs (HMRC) VAT turnover data. We also recognise that some of the data issues are because of how the administrative data are collected and recorded, and hence cannot easily be resolved by researchers and analysts. However, as administrative data are now routinely used in analysis and policymaking, those with responsibility for collecting administrative data should consider the wider public benefits that changes in collection and database design might yield. Regardless of the data challenges we faced, our preference utilisation rates (PURs) analysis shows how detailed-level administrative data can be used to conduct firm-level analysis of preferential tariffs and how data science techniques can be successfully applied to analyse these questions \u2014 laying the foundations for further analysis of preference utilisation in the UK.]]> In this blog post I want to celebrate this work and share our plans for the future, and I hope this will prompt further conversation so that together we can build and draw on talent from diverse backgrounds more effectively, to support data and analysis for the public good. The training we offer has reached from five-year-olds to permanent secretaries. It covers introductory material to understand data, all the way through to post-graduate level data science courses. The impact of our training has been seen through: It is a privilege to contribute to this important agenda and we are always striving to do more. Developing expertise in data is important, which is why the [Declaration on Government Reform](https://www.gov.uk/government/publications/declaration-on-government-reform) sets out plans on how government will do this. The [National Data Strategy](https://www.gov.uk/government/publications/uk-national-data-strategy/national-data-strategy) also highlights how data and data science skills will enable the UK to thrive. This includes \"developing world-leading capability in data and data science across central and local government, so that leaders understand its role, expert resource is widely available, [and] staff at all levels have the skills they need\". We have set out our vision to support this ambition: The public sector has the skills to tackle the challenges of a data rich world, enhancing decision making and improving delivery through data science for the public good. This means that: We will continue to support capability building in data science, while also further developing our offer beyond data science. An understanding of data and its value is critical to so many aspects of good government and underpins the public sector's ability to use data and data science well. By bringing together different aspects of data training, we can provide a more comprehensive and cohesive offer. We are now delivering a wider range of technical training on behalf of the Office for National Statistics (ONS) and the Government Analysis Function. We are also increasing our focus on data literacy, looking at how we can upskill individuals across professions, grades and geographies. For example, we are building a cross-public sector data literacy community of interest to allow colleagues to share best practice tips across the sector. We are also developing the Data Masterclass for Senior Leaders into a more accessible product that we can deliver to a broader audience across the public sector in the UK and internationally. Improving data skills, as well as understanding and confidence in data science, have the potential to be transformative for individuals and for what the public sector can do for citizens. We want to see this potential realised, and we want to do this in an inclusive and collaborative way. If you would like to engage in our work, there are lots of ways you can do this. [More information is available](https://datasciencecampus.ons.gov.uk/capability/) on our website, or you can [email us](mailto:datasciencecampus@ons.gov.uk). We would love to hear from you! We play an important role in enabling strong and meaningful partnerships between NSOs and other official bodies in order to accelerate change. We have been partnering with the [European Statistical System Network (ESSnet) Trusted Smart Statistics - Web Intelligence Network project (WIN)](https://ec.europa.eu/eurostat/cros/WIN) since April 2021. ESSnet was developed by Eurostat, the statistics division of the European Union (EU), with the objective of providing comparable statistics at EU level for all members. The WIN project's purpose is to provide a sustainable and fully operational platform, the Web Intelligence Hub (WIH), to enable the production of official statistics with data, which are sourced and structured from websites (web data) to benefit the ESSnet and beyond. The project covers experimental research, methodology and quality frameworks, knowledge sharing and capability building, and software development in the web intelligence space. The project is funded by the European Union until 2025 and led by Statistics Poland, in collaboration with partners from 17 organisations from 14 different countries. By the end of the project, ESSnet is expected to have a sustainable and fully operational environment for producing official statistics using web data at the European and national levels. The flexible and modular environment embodied in the WIH will deliver the desired outcome grounded in a solid methodological framework. The project has four work packages. [Work Package One](https://ec.europa.eu/eurostat/cros/content/work-package-1-%E2%80%93-coordination-support-and-dissemination_en) builds awareness of the WIN and WIH, focusing on capability building and user engagement. To support this work package, we have set up social media channels to promote the project and are delivering a selection of webinars. [Work Package Two](https://ec.europa.eu/eurostat/cros/content/work-package-2-%E2%80%93-oja-and-obec-software_en) develops software to gather data from online job advertisements (OJA) and online-based enterprises characteristics (OBEC). [Work Package Three](https://ec.europa.eu/eurostat/cros/content/work-package-3-%E2%80%93-new-use-cases_en) explores the potential of non-traditional new data sources to be integrated into the WIH to produce experimental statistics. The Campus team developed a version of its [Traffic Camera project](https://datasciencecampus.ons.gov.uk/projects/estimating-vehicle-and-pedestrian-activity-from-town-and-city-traffic-cameras/) that could be accessed without complicated infrastructure. It produced faster economic indicators by exploring open-source traffic camera data to understand the busyness in city centres around the UK and to provide insights on the levels of social distancing during the coronavirus (COVID-19) pandemic. It has also used the data to track the upturn of the economy as lockdown restrictions were relaxed. The team has made the [system](https://ec.europa.eu/eurostat/cros/content/issue-2-faster-economic-indicators-traffic-camera-data_en) more accessible to ESSnet users and has helped the Swedish NSO to adopt the project. [Work Package Four](https://ec.europa.eu/eurostat/cros/content/work-package-4-%E2%80%93-methodology-and-quality_en) is developing comprehensive business architecture, methodology, and quality framework for producing official statistics with web data. We supported this work reviewing quality frameworks for [Online Job Advertisements](https://ec.europa.eu/eurostat/cros/content/issue-5-path-quality-framework-oja-data-source_en). In June, the team met at Statistics Poland in Warsaw. It was a brilliant opportunity to enhance collaboration and knowledge sharing. Following this, we held an in-person [international meeting at the Data Science Campus](https://datasciencecampus.ons.gov.uk/bringing-the-world-to-ons-working-together-on-data-science-and-big-data/) to advance international collaboration. [Work Package One](https://ec.europa.eu/eurostat/cros/content/work-package-1-%E2%80%93-coordination-support-and-dissemination_en) took advantage of this to design capability building initiatives for 2022. This led to [our Communications](https://ec.europa.eu/eurostat/cros/content/communication-strategy_en) and [Capability strategies](https://ec.europa.eu/eurostat/cros/content/capability-strategy_en), [webinar February 2023 and an in-person [workshop](https://ec.europa.eu/eurostat/cros/content/web-intelligence-practice-how-use-content-web-enterprise-statistics_en) in Brussels in March 2023. The [training programme for 2023 to 2024](https://ec.europa.eu/eurostat/cros/content/training-events_en) is underway, so please [contact us](mailto:ESSnet.project@ons.gov.uk) for further information! Dominika Nowak, ESSnet WIN project lead, Statistics Poland said: \"The Campus is playing a critical role in the project with regards to building a community of the WIH users across the ESS and beyond. DSC is responsible for extensive networking, external communication, coordinating the development and provision of training on various aspects of the use of web data in official statistics. These activities are crucial for the project to achieve its ultimate goal, which is to ensure broadest possible employment of WIH services by European NSIs and other producers of official statistics. I look forward to continuing this productive and successful partnership for the next 2 years.\" The project delivers at least five training and networking events each year and presentations at important statistical conferences such as the [New Techniques and Technologies for Statistics 2023 Conference](https://ec.europa.eu/eurostat/cros/content/NTTS2023_en) and the [64th World Statistics Congress](http://isi2023.org/conferences/ottawa-2023/) to help grow awareness of research topics and training courses, encouraging use of WIN and WIH services to increasing project impact. The training events have been popular across NSOs, with the [first](https://ec.europa.eu/eurostat/cros/content/architecture-methodology-and-quality-overview_en) and [second](https://ec.europa.eu/eurostat/cros/content/enhancing-quality-statistical-business-registers-scraped-data-webinar_en) webinars attracting more than 200 delegates each, across 46 countries globally. Webinar recordings are available on [the WIN project's YouTube channel](https://www.youtube.com/channel/UC5fUzazBu7d1Arl17LdC4zQ). Christophe Bontemps, Statistician and Lecturer, UN Economic and Social Commission for Asia and the Pacific (ESCAP) said: \"I found remarkable the collaboration among many European experts so that the work can be used and easily adapted to any other statistical office.\" Camille Harris, Principal Statistical Methodologist, UK Office for National Statistics said: \"I thought the level at which it is pitched is perfect as it's accessible for people with various technical expertise.\" David Salgado, Subdirector General for Methodology and Sampling Design, Institute Nacional de Estadistica (INE), Spain said \"Very good presentations from experts that did not focus on the technical aspects too much but addressed the real issues and questions to ask beforehand.\" Leveraging global partners' technical skills and knowledge on the use and application of WIH services strengthens the global statistical system, produces better statistics, improves decision making and, ultimately, improves lives globally. We are so proud to be part of it!]]> Shipping instructions (or Bill of Lading) data detail the type, quantity and destination of goods being shipped in containers. These data were procured for UK imports and exports by DIT and the Department for Transport (DfT) in 2021, with Canadian company ThinkData Works (TDW) successful in their bid through an open tender process. This was the first time that shipping instructions data had been procured by the UK government, and the purchase was supported by the Treasury's Economic Data Innovation Fund. The ONS Data Science Campus is partly funded by DIT to support this work. This first blog post demonstrates the uniqueness of this data source and how data science techniques are being used to determine its data quality and potential cross-government uses to understand trade. We will show how shipping instructions can be used to map the trade routes of critical goods, understand our reliance on global ports for accessing specific products, and draw insights on the impact of important events such as strikes. By linking with automatic identification system (AIS) data, we can monitor the journey of containerised goods in near real-time. Finally, the data offer the possibility of improving our understanding of trans-shipment, where goods change ship in a port (for example, Rotterdam) on their way from origin to destination. The effect of trans-shipment on UK trade statistics can be considerable, and this is an important strand of work that the ONS Data Science Campus and DIT are researching further. Shipping instructions data are recorded in a legal document between the shipper (the seller of the goods) and the carrier (who transports them across the sea) and, as such, their primary use has not been for government analysis. There has been growing interest in better understanding the type of container goods being shipped into and out of the UK. Traditional trade sources, such as customs declarations, provide robust overall import and export figures. However, shipping instructions provide additional granular detail (for instance, the products in each container) and more detailed trade flows (for instance, the route that each ship takes). Both are crucial when understanding the impact of, for example, disruptions on supply chains. At present, marine traffic data are used by the ONS as an innovative data source to respond to the challenge of producing faster economic information. [Experimental indicators using ship position data are published weekly](https://www.ons.gov.uk/economy/economicoutputandproductivity/output/datasets/weeklyshippingindicators) to provide an early indication of the movement of goods into and out of the UK. However, ship position data do not provide any information on the goods carried by the ships, and they cannot follow the journey of a container that is transferred from one ship to another. Trade statistics are reported at an aggregate level, which is not sufficient to give insights into issues such as the passing of commodities through critical straits, trans-shipment activity, and supply chain issues. Linking ship position data to shipping instructions data may enable near real-time monitoring of goods carried by ships. TDW have shared data from December 2019 to November 2022 under the contract they have with DIT. The dataset covers the majority of ports in the UK. Ports are geographically dispersed and tend to be specialised based on geography. For example, the South East is dominated by freight vehicles given its proximity to mainland Europe, whereas Scotland is influenced by nearby North Sea oil and fishing industries. Given that ports are essential to local economies, understanding the contribution of critical goods and ports to the economy will help port policy. The largest container ports (which this dataset relates to) are geographically spread across the UK in areas such as London, Liverpool, and Southampton. These data will therefore help us identify specific goods and trading routes that are crucial to local economies in and around ports, as an important input to policymakers' interest in levelling up. Container ships carry around 15% of the UK's imports and exports by weight, and the shipping instructions dataset covers around half of the UK's container ship trade. In particular, the data have good coverage of the largest container ports in the UK, with details of approximately 50% of containers passing through Felixstowe, London Gateway, and Southampton. These are the three largest container ports in the UK, accounting for around 70% of UK container movements. Using shipping instructions data, we are able to count how many containers carry specific types of goods, as seen for UK imports in Figure 1. Customs data can show the weight and value of different types of goods, but container counts indicate the proportion of container port traffic involved. This can be further broken down by port of origin, showing the importance of each global port to each type of UK import. Policymakers would like to understand how important events, such as strait blockages or industrial action, can affect the flow of commodities into and out of the UK. Anomaly detection methods can be used to detect and draw insights on these disruptive events using the shipping instructions data. We need to distinguish between \"normal\" and anomalous patterns in the data, given that we expect to observe high (for example, in the lead up to Christmas) or low levels of container traffic during certain periods (for example, in the New Year). To achieve this, we built a pipeline that detects anomalies based on the differences between predicted and actual values of the smoothed container count (for instance, the residuals). The count was \"smoothed\" by generating the 30-day moving average to help remove random variations in the data. We obtained predicted values by fitting time-series models on the 30-day moving average using the [Prophet](https://peerj.com/preprints/3190.pdf) programme. Observations were then labelled as anomalous if the computed residuals fell outside three standard deviations from the mean value. Figure 2 shows how this method performs with data on inflowing containers at Felixstowe port. The algorithm detects several anomalies, which coincide with an eight-day strike that took place at Felixstowe between 21 and 29 August 2022. These anomalies imply, as expected, that container traffic was particularly low during the strike period. Encouragingly, the algorithm can deliver good predictions and, in turn, good anomaly detection results, despite modelling based on just under three years of data. This shows early potential in using shipping instructions data to analyse the impact of events such as strikes, political crises, natural disasters, or blockages. Wider tests on specific product flows also showed that this could help with understanding which goods were affected, which could provide useful insights into supply chain vulnerabilities. Linking ship position data to shipping instructions data will provide valuable information on what is carried by the container ships arriving and departing UK ports. This is expected to provide insights into issues such as the journey of goods through critical channels, global supply chain disruptions, and, alongside other sources, potentially improving our understanding of trans-shipment (where goods change ship on their way from origin to destination) in trade. A pipeline that will enable linking ship position data with shipping instructions data is currently in development. Information on the position of ships in real time is obtained from automatic identification system (AIS) data. The data are transmitted every few seconds by ships through onboard navigation safety devices and include information on their location, identification, and characteristics (for example, cargo ship or tanker). Linking AIS data with shipping instructions data is achieved by using ship unique identifiers, which are present in both databases. There are often ambiguities when matching ships in the two databases because unique ship identifiers are sometimes missing from shipping instructions data. Additional challenges arise because of inaccurate event timestamps recorded in both AIS and shipping instructions data. We handle these challenges by applying fuzzy matching techniques. Figure 3 shows initial outputs from our processing pipeline that links shipping instructions data with AIS data. In this example we track shipments of specific goods from Antwerp to Felixstowe (red line) and from Felixstowe to Rotterdam (orange line). DIT, DfT and the ONS have been engaged in several data validation exercises to understand how well the dataset represents shipping and container activity. As well as AIS data, shipping instructions data have been compared with other data sources on UK trade volumes, namely statistics used in DfT port freight publications and HM Revenue and Customs (HMRC) Overseas Trade Statistics (also known as Trade in Goods). These exercises have provided relatively consistent insights into the coverage and quality of the dataset. For example, approximately half of unique cargo vessel visits recorded in AIS data are present in shipping instructions data. This corresponds with comparisons with [DfT port freight statistics](https://www.gov.uk/government/collections/maritime-and-shipping-statistics), which suggest that the dataset covers around half of all container imports and exports to and from the UK. Regular interactions between TDW and the three departments have enabled data quality issues, such as duplicates and invalid observations, to be promptly flagged and addressed. DIT is also finalising a pipeline that enhances tables on container journeys. The pipeline removes implausible events and ensures that we can follow the movement of each container - from when it is first loaded to when it reaches its destination port - more easily and readily. Around 60% of Harmonized System (HS) codes, which are used to categorise the goods carried in the containers, are known. This means that we are not certain what type of goods are in around 40% of containers. We expect the algorithm used to derive HS codes (which is based on cargo descriptions and implemented by TDW) and HS code completeness to improve as more data are accessed. Given its potential cross-government utility, DIT and DfT have elected to extend the contract with TDW to receive shipping instructions data up to November 2023. The ONS, DIT and DfT will continue to use this dataset, in conjunction with AIS data, to better understand trade flows in and out of the UK. A second blog, planned for publication in Spring 2023, will demonstrate how this work has progressed. We would also like to thank David Bradnum (Data Science Campus) and Mark Purver (DIT) for their support with this project.]]> The Data Science Campus were asked to produce detail on how these areas vary for different travel times (increments of 15 minutes up to a maximum travel time of 60 minutes). Then, data was compiled for all four nations using comparable sources and methods, so that SDU could reproduce analysis for any place in the UK. To understand how access varied at a hyperlocal level, we needed to produce data at the most granular census area possible. This is currently output area (Census 2021 basis) for England and Wales, output area (2011 Census) for Scotland, and small area level (2011 Census basis) for Northern Ireland. This equates to areas that have groups of approximately 40 to 150 households. We compiled and reformatted existing, openly available, bus and train timetable data and used the open-source route planning software, [OpenTripPlanner](https://www.opentripplanner.org/). Using these, we converted the timetables into the entire feasible set of locations people can travel to, from a given starting point. We repeated this process for every output area in the UK, which equates to 239,768 different places. So that journeys going through the Republic of Ireland could be incorporated, we added bus and train timetables for the Republic of Ireland. This kept data and methods for all four nations of the UK consistent. Alternative public transport methods, such as tram and underground services, were also included when calculating the feasible travel area. Bus and train timetable data for Scotland, England, and Wales were sourced from the Department for Transport (DfT) and Rail Delivery Group, respectively. The Northern Ireland bus and train data were sourced from [OpenDataNI](https://www.opendatani.gov.uk/). Data for the Republic of Ireland were sourced from [Transport for Ireland](https://www.transportforireland.ie/). Timetable data were converted to a standardised [General Transit Feed Specification (GTFS)](https://developers.google.com/transit/gtfs) format using a range of tools, including [the R package, UK2GTFS](https://itsleeds.github.io/UK2GTFS/), developed by the University of Leeds. For England, Scotland, and Wales, travel area estimates were generated using timetable data for Tuesday 15 November 2022. For Northern Ireland, data for Tuesday 6 December 2022 was used. Both days were unaffected by temporary factors that could affect service levels, such as industrial action and weather events. The feasible travel areas calculated from OpenTripPlanner depended on a range of adjustable parameters. One of the most important was the choice of start time. In many places, buses and trains run less frequently than an hour. Therefore, producing travel areas from one single point in time (for example, 8am) was likely to lead to variation in results, depending on which services depart close to that single point in time. However, results should account for differences in the frequency of services. We took the approach to calculate the feasible travel areas for eight start times in 15-minute increments, between 7:15am and 9:15am inclusive. Once we obtained these eight travel areas, we took the union of the areas, which incorporates all the area generated from the eight instances. A second important parameter was the starting point. Our approach was to have the starting point default to the population-weighted centroid within each output area. This was to model the feasible travel area that could be achieved by an \"average household\" within an output area. However, it should be noted that as households are often unevenly geographically distributed, the centroid can be an unrepresentative starting point for some households within a given output area. The population-weighted centroid can also be positioned in inaccessible places, such as forests and car parks (one was even located in a prison). In these cases, we change the starting point to a nearby road. The final important parameter was the degree to which people can walk during the journey. We set this at 1.5 kilometres for the whole journey, which could be used up in a single stretch of walking, or multiple trips. One example would be walking from home to a departing train station, followed by another journey from the arrival train station to a different location. This is approximately the distance travelled by foot for the average commute in the UK. The full UK dataset produced for the Department for Levelling Up, Housing and Communities (DLUHC) contains feasible travel areas using public transport for 239,768 places across the UK. We have made these data publicly available on the [Office for National Statistics (ONS) GeoPortal](https://geoportal.statistics.gov.uk/) in the form of ESRI shapefiles (for information on shapefiles, see the [ArcGIS reference page](https://doc.arcgis.com/en/arcgis-online/reference/shapefiles.htm)). These shapefiles can be accessed either as a bulk dataset or by using the [GeoPortal application programming interface (API)](https://www.api.gov.uk/ons/open-geography-portal/#open-geography-portal). Further information on the data can be found in the accompanying metadata. Data can be accessed using two different approaches. Firstly, data can be accessed from the ONS GeoPortal's bulk download facility. Secondly, the data can be accessed via the ONS GeoPortal API, which has documentation on how subsets of the data can be queried. These data have been used for the recently conducted Department for Levelling Up, Housing and Communities (DLUHC) \"deep dive\" work in Grimsby, where policymakers worked with local stakeholders to identify barriers to growth and improve outcomes. The Data Science Campus supported this work by producing data on feasible travel areas for approximately 50 output areas in Grimsby and the nearby surrounding area. Figure 1 shows how public transport accessibility varies in Grimsby, by visualising the feasible travel area for two different starting locations. One location is in West Marsh, close to Grimsby Town train station, and one in Waltham, a suburb four miles south of Grimsby. These two travel areas show that there is wide variation in the locations that are available by public transport to households living in these areas. For example, places such as Louth and Barton-Upon-Humber are accessible to those living closer to the centre of the town, but not accessible by public transport for those living in Waltham. For further clarification on the methods, data sources, schema, and metadata for this project, we encourage contact by email at [datacampus@ons.gov.uk](mailto:datacampus@ons.gov.uk). Towards the end of 2021, the Welsh Government approached us with a project proposal to explore whether tree cover has changed in recent years in eastern Uganda, in response to a tree planting initiative they lead in the area. Identifying changes over time and at scale, such as deforestation, has [long been done using satellite and aerial images](https://www.science.org/doi/abs/10.1126/science.248.4952.212) (Green and Sussman, 1990). We were well placed to support this request because of prior experience in the Campus working on similar projects, including: The area surrounding Mbale, Uganda, is hilly and heavily vegetated (Figure 1). For many in the region, trees provide a source of fuel, food, and income. According to [Global Forest Watch](https://www.globalforestwatch.org/map/), who calculate tree cover change using 30-metre (m) resolution data, Mbale district has lost 727 hectares (ha) (a hectare is around the size of a football pitch) of tree cover between 2000 and 2021, equating to around 1.5% of its area. The loss of trees has an impact on the local area and residents, as well as contributing to the broader effects of climate change. In recent years, for example, fatal landslides in Mbale ( [Reuters, 2022](https://www.reuters.com/world/africa/floods-kill-least-24-uganda-red-cross-govt-officials-2022-08-01/)) and neighbouring districts ( [BBC, 2018](https://www.bbc.co.uk/news/world-africa-45836381)) are likely to have occurred because of heavy rainfall, combined with increased surface runoff caused by tree loss. To combat this tree loss, the [Mbale Trees Programme](https://experience.arcgis.com/experience/6f3657ae92bf488ba8f50f22be3672e9) was established in 2010 by the Welsh Government, in partnership with the Size of Wales and the [Mount Elgon Tree Growing Enterprise](https://www.metge.ug/) (METGE). The programme works in collaboration with local partners to freely distribute tree seedlings to local people for planting on smallholdings or community land. Since the programme began, 17 million seedlings have been distributed in local communities from tree nurseries. It is hoped that the planting of these seedlings will lead to increased tree cover. This will, in turn, help mitigate the risks of further landslides, provide an economic resource (through fuel, wood, and fruit), provide an ecological resource in more resilient habitats, and more broadly help to combat climate change. Although the Mbale Trees Programme was not developed to restore dense forests, it is hoped that it has helped to achieve this indirectly by reducing the need for locals to cut down trees from established forests. Although tree loss has been calculated yearly up to 2021 by Global Forest Watch, tree gain uses a different methodology and does not have data per year for the area around Mbale ( [Potapov, P. et al 2022](https://www.frontiersin.org/articles/10.3389/frsen.2022.856903/full)). Between 2000 and 2020, it was estimated that for the Mbale district, tree gain was around 684 ha (Table 2). Differences in methodologies mean it is difficult to directly compare tree loss and tree gain using Global Forest Watch; however, tree loss appears to be greater than tree gain since 2000. In this blog post we describe how we used 10m resolution Sentinel-2 satellite images to calculate the most recent changes in tree cover around Mbale from 2016 to 2022, and what we can infer about the Mbale Tree Programme from these findings. In this work we used the European Space Agency's open-access Copernicus [Sentinel-2](https://sentinel.esa.int/web/sentinel/missions/sentinel-2) satellite imagery. As Sentinel-2 has only been operational since 2015, it does not span the entire time of the Mbale Trees Programme (2010 onwards). We considered changes in tree cover between 2016 and 2022 and compared images from similar times of the year to avoid biases introduced by differing seasons. The resolution of the Sentinel-2 images (10m) means that only areas of trees can be identified, as opposed to small, single, or dispersed tree canopies (Figure 2). To calculate changes in tree cover we first classified the pixels in the 2016 and 2022 images that represented areas of trees, and then analysed where classifications were different using a computer script developed in Python. To identify pixels that were tree covered, we constructed a manual training set, and then (aptly) applied a random forest classifier to categorise the pixels as tree covered or not. After tuning, the algorithm was able to classify pixels of Sentinel-2 images with around 90% accuracy. Differences in tree and non-tree classifications between the 2016 and 2022 images could then be calculated to identify tree cover gain and loss (Figure 3 and Figure 4). To decrease errors because of misclassification, we only calculated differences for areas above 2,000 metres squared (around 4 by 4 pixels). Therefore, tree loss or gain in areas less than this threshold will not be considered. To understand the influence of the Mbale Trees Programme specifically, we compared changes in tree cover in areas surrounding nurseries, to areas understood to be away from reforestation projects. To do this we apply several buffer zones around each nursery and calculate the tree cover change for each zone. We will also explore changes to tree cover around Mbale at the district and sub-county levels. Changes in tree cover will be presented in units metres squared per ha. Another approach would be to use percentage change; however, because land cover in Mbale is mostly non-forest cover (20% forest cover according to Global Forest Watch) changes in tree cover are likely to result in small percent changes, and such values would be hard to read in the text below. Figure 5 shows a visual example of how to interpret the results, showing that a hectare is around the size of a football pitch. As 1 ha is 10,000 metres squared, the values can be changed into percentage change by dividing by 10 (for example, 50 metres squared per ha is equal to 0.5%). In all districts, tree cover gain is greater than tree cover loss (Figure 6a to 6c). Mbale district has a net change of 37.6 metres squared per ha (equivalent to an increase of 0.38 percentage points) - this equates to a net gain of 195 ha across the 51,780 ha district (Table 1 and Table 2). While the Mbale district has one of the largest net changes, Sironko is the district with the greatest net change (83 metres squared per ha, equivalent to an increase of 0.83 percentage points), and Bukedea the smallest (1.3 metres squared per ha). Each district can be broken down into several counties, and sub-counties (Figure 6d to 6f). The range of tree cover gain values in each of the sub-counties is large (0 to 384 metres squared per ha), but on average it is 56 metres squared per ha. The range of tree cover loss is smaller (0 to 193 metres squared per ha), with an average of 14 metres squared per ha. The sub-county with the greatest tree loss (Busulani) and tree gain (Buteza) were both within the Sironko district. Sub-counties in the Mbale district have a smaller range for tree cover gain (5 to 131 metres squared per ha) and loss (2 to 36 metres squared per ha), with Northern Division showing the greatest tree cover gain and Industrial Division the greatest tree loss. Our findings show that in the areas surrounding nurseries, tree cover gain and loss are both greater than in areas away from nurseries. However, gain is greater than loss, so the net effect is that tree cover has increased (Figure 7). Outside the 6-kilometre (km) buffer area, we found that the net change was a loss in tree cover. This trend could indicate that the programme is having a positive influence on tree cover in areas near (less than 6km from) nurseries. Some nurseries have been designated with \"super\" status, meaning they produce double the number of tree seedlings compared with other nurseries (120,000 per year compared with 60,000 per year). Comparing results for super nurseries to all nurseries, more tree cover gain is attributed to super nurseries than all nurseries (Figure 8). Tree loss values, however, are comparable to non-super nurseries (except for buffer zones less than 2km from nurseries, which are lower than all nurseries combined). We used [Global Forest Watch](https://www.globalforestwatch.org/map/) to validate our methods and results using the Mbale district. However, as explained by Global Forest Watch, \"due to variation in research methodology and date of content, tree cover, gain, and annual loss data sets cannot be compared accurately against each other. Accordingly, 'net [difference]' cannot be calculated by subtracting figures for tree cover gain from the annual tree cover loss data set\" using Global Forest Watch. When comparing tree loss and gain separately, between 2016 and 2021, Global Forest Watch calculates a total tree loss of 174 ha, whereas we found 73 ha between 2016 and 2022 (Table 1). Global Forest Watch does not have data for us to easily compare our tree gain data to, however, between 2000 and 2020 it estimates a tree gain of 684 ha (Table 2). Between 2016 and 2022 we found 268 ha using our method. |Method||Period||Tree loss (ha)| |Global gain (ha)| |Global Forest Watch (| The differences between our values and those of Global Forest Watch are likely because of the difference in data resolution, methods, and that we use two time periods, whereas Global Forest Watch uses yearly changes. We are confident that our findings are valid and our consistent methodology for tree loss and gain means net change can be calculated, which is not possible using Global Forest Watch. In the future we would aim to calculate yearly changes to further validate our tree loss findings to Global Forest Watch. Here, the stakeholder need was to help the Welsh Government quantify the impact of the Mbale Trees Programme on tree cover change. The main finding from this work is that between 2016 and 2022, there appears to have been a positive net change in tree cover in eastern Uganda. Furthermore, we found that the greatest positive change in tree cover occurred near to Mbale Tree Programmes nursery locations. It is important to recognise that this signifies correlation - but cannot directly be used to say that the programme was definitely a contributing factor to increased tree cover, though this result has some promise. To establish this causal relationship, a comparison between known areas of tree planting through the Mbale Trees Programme should be compared with a baseline area. Because of the resolution of Senintel-2 data (10m), we are unable to identify small areas of trees, or single-tree canopies, that may be more likely to have been planted through the programme. To account for these, higher resolution satellite images (sub-metre resolution) would be needed. In addition to this, to confidently know whether the identified trees were those planted through the programme, precise ground truth data would also be needed. These data would then also allow us to perform a more in-depth analysis too, such as success rate for different species types. In the last few years, the Welsh Government has made improvements to the field data they collect, meaning that this more detailed analysis might be possible in the future. We thank the Welsh Government for bringing our attention to this issue and providing us with the relevant information required to complete this work. If you have any questions about this project or any of the work referenced here, please contact the Data Science Campus on [datacampus@ons.gov.uk](mailto:datacampus@ons.gov.uk). Upgrading broadband infrastructure across the UK is a priority for the government, with a target set for gigabit broadband to be available nationwide by 2030. 85% of premises are expected to meet this by 2025. Local government institutions play a very important role in allocating investment for infrastructure improvement, especially when working with the private sector to identify potential interventions in areas that are more challenging to upgrade. To help NTCA with this task, we were asked to support with visualisation and analysis of broadband data for the region. NTCA incorporates the local authorities of Newcastle upon Tyne, North Tyneside, and Northumberland. The aim of the project was to help NTCA identify current levels of connectivity at a very granular subnational level and use different tools and data to identify areas that might benefit most from interventions. Although a significant amount of data are currently openly available from the Office of Communications (Ofcom), NTCA wanted to gain additional insight from these data based on their particular policy context. For example, understanding the implications of connectivity on labour market participation, skills and rural productivity. A main challenge NTCA and local institutions face is in identifying viable infrastructure solutions and installation sites (in the case of fixed-wireless access), which are important in improving households' access to higher speeds. From the outset, 30Mbit/s per premises was agreed by NTCA as a \"minimum\" acceptable download speed for citizens to fully access the opportunities in our modern, digital society. In order to inform decision-making in this area, we have provided NTCA with an interactive tool developed using Dash (Figure 1). This tool allows NTCA to search for any postcode within the combined authority area. It shows a range of broadband metrics alongside other data relating to the population in the postcode's output area (OA). In addition to the service levels for the selected postcode (and all surrounding postcodes), the radius to the third-nearest postcode where at least 50% of premises have access to gigabit capability is highlighted (a requirement from NTCA). Presenting the data in this way highlights areas that do not have gigabit-capable broadband but are relatively close to those that do. In addition, the tool has helped NTCA understand the impact of the Northumberland geography on the distribution of broadband access, including factors such as how rural different places are. The visualisation also helped to identify areas with relatively large numbers of premises without access to lower speeds such as 10Mbit/s (the Universal Service Obligation) and 30Mbit/s (Superfast Broadband download speeds). To give a better picture of broadband connectivity over time, we also delivered detailed local metrics to show how broadband availability has changed in the last year. This showed significant increases in gigabit broadband availability in wards within the Newcastle upon Tyne authority. However, it also demonstrated relatively slower progress in reducing the number of premises that are limited to accessing speeds of 30Mbit/s or lower. Finally, to help NTCA assess which areas might benefit the most from any interventions, we presented broadband data together with other demographic and socio-economic data that NTCA wanted to consider. These were presented in both the dashboard and a separate suite of interactive map visualisations. One of these visuals shows the co-occurrence of vulnerability indicators in areas where broadband coverage is poorest (Figure 2). We initially looked at the following five indicators: Note: for an area to score, one or both of the top two broadband indicators must be triggered. This has provided NTCA, and its constituent local authorities, with greater insight into their areas and helped inform deployment plans. The code allows flexibility for other indicators (such as long-term ill-health or ethnicity) to be added alongside broadband service levels and we have enabled NTCA colleagues to continue to develop the code as priorities change. Both the dashboard and interactive visualisations have been adopted by NTCA as a tool to support their ongoing work around connectivity. For further information on the project work undertaken for NTCA, or to get in touch with us about how this work might be able to support other local institutions in the UK, please email [datacampus@ons.gov.uk](mailto:datasciencecampus@ons.gov.uk). Competing remotely, [Michaela Lawrence](https://datasciencecampus.ons.gov.uk/author/michaela-lawrence/), [Mat Weldon](https://datasciencecampus.ons.gov.uk/author/mat-weldon/) and [Henry Wilde](https://datasciencecampus.ons.gov.uk/author/henry-wilde/) went up against nearly 200 international teams, including representatives from other national statistical organisations (NSOs), data science start-ups and academic research centres. Our team battled through to achieve an impressive third place, closely behind the first-placed Oxford University research team and a Canadian PETs consultancy in second. The event was organised by the UN PET Lab, a collection of NSOs and technology experts collaborating to modernise the way data are shared and statistics are produced. [PETs allow safe data sharing and collaboration across institutions and national borders, allowing organisations to benefit from enhanced data access, without compromising on data privacy.](https://unstats.un.org/bigdata/events/2022/conference/) PETs consist of many different techniques, including encryption, noise addition and methods that enable analysts to train machine-learning models without having direct access to data. The competition was devised to increase awareness of PETs and their potential for use by organisations to allow data access for tackling important societal and economic questions. It focused on survey data provided by the UN Refugee Agency (UNHCR) with detailed information about the refugee population in Kenya since the beginning of the coronavirus (COVID-19) pandemic. This is a sensitive dataset at household level, containing around 50 variables with detailed information of household composition, circumstances and living conditions. Teams were tasked with accurately predicting three sensitive variables in a \"test\" subset of the data, while only being able to make noisy queries on another subset of the data. The teams were not able to directly view the sensitive variables, but were able to interact with them through methods that are known to preserve privacy. This included making noisy queries and creating synthetic data. Each interaction with the data had a cost. The magnitude of this cost was determined by how much noise the teams were willing to have added to their queries - the noisier the query, the cheaper it was. Noise was added using a method called differential privacy, which provides a formal mathematical definition of disclosure risk. For example, to retrieve an estimate of the number of male and female respondents in the data, a random number centred on zero would be added to each count, in such a way that the ability of a snooper to learn about any individual in the data would be limited, no matter what other information they possessed. Adding more noise gives a stronger guarantee, whereas adding less noise (a random number closer to zero) gives a weaker guarantee and has a higher privacy cost. When there are many male and female respondents, this additional noise may not have a large impact on the accuracy of the estimate, but if we wanted to count many small categories, or occurrences of a rare event, the same amount of noise would have a bigger impact on accuracy. Final scores were determined by a trade-off between the accuracy of the predictions and the total cost of all the queries a team made. To finish third, our team used privacy-preserving versions of various methods to explore the data and improve its predictions, including data visualisation, principal components analysis, synthetic data and random forests. The hackathon brought together an international community of data scientists and introduced some of the tools and frameworks on offer to implement PETs, demonstrating how these can allow data analysis without sharing sensitive microdata. The insights gained will inform our ongoing work to explore how we can use PETs to enable more integrated analyses of linked data across the public sector, to improve decision-making without compromising citizens' privacy.]]> This well-established mentoring programme has now helped more than 350 participants to learn new data science skills, while over 100 different organisations have benefitted from the support their employees have received. We are excited to announce that applications for both the Data Science and Data Visualisation Accelerator programmes will be open from Monday 9 January until Thursday 2 February 2023. Both programmes will run concurrently for 12 weeks from Thursday 13 April until Thursday 29 June 2023. If you are interested in applying but are not sure if this programme is right for you, or if you have other questions, you can attend one of our project clinics on [Wednesday 21 December 2022](https://www.eventbrite.co.uk/e/data-science-accelerator-programme-project-clinic-tickets-475135532167) or [Monday 16 January 2023](https://www.eventbrite.co.uk/e/data-science-accelerator-programme-project-clinic-tickets-475136204177). The [Accelerator](https://www.gov.uk/government/publications/data-science-accelerator-programme/introduction-to-the-data-science-accelerator-programme) is an entry-level programme for analysts, currently employed in the public sector, to develop their data science and/or data visualisation skills. It is not suitable for those who already have data science experience. This is a 12-week programme where participants work one day a week on a data science or data visualisation project (of their own choice) with the support of an experienced mentor. There will be an opportunity to experiment with different tools, techniques and open-source software. The Accelerator is delivered remotely by the Office for National Statistics (ONS). Some of the benefits associated with the programme are: Applicants will need the support of their line manager, have a work-related (though not business-critical) project proposal and be able to confirm availability of all necessary data. You will also need to commit to spending one day a week for three months working on your project. Some coding experience would be beneficial, however successful applicants will receive access to online courses to help with this. Read what some participants from previous Accelerator cohorts have to say about the programme and how knowledge of data science and data visualisation helped them in their career. \"I found the Accelerator hugely beneficial. I had a highly skilled mentor who helped me work through the project in logical steps, and suggested resources to explore. I enjoyed the protected on-time learning and applying that knowledge directly to the problem. I'd highly recommend the programme to anyone that is passionate about analytics and is looking for a first step into understanding data science.\" \"Loved the programme. It helped with my project, and I am doing more technical data science modelling and predicting off the back of it. My data related to London underground trains. I loved my project and it is still part of my day job, having evolved further.\" \"My project was to develop a river flow dashboard using R Shiny to show historical and live flow and reveal the hidden long-term trend and pattern of data...which links with flooding and drought. I have learnt a lot about how to use R Shiny to develop a dashboard with the help from my experienced mentor. I feel that I have the knowledge and skills in R Shiny to develop any dashboard. I do encourage my colleagues and other people to apply for it.\" Successful applicants will be given access to the ONS Learning Hub platform. This will provide analytical and data science courses to support participants with their project work. Courses are provided by the Analysis Function and the ONS Data Science Campus. You can find more information on how to apply on our [our Accelerator page](https://datasciencecampus.ons.gov.uk/capability/data-science-accelerator/). Applications for the next cohort of both programmes will be open from Monday 9 January to Thursday 2 February 2023. Before applying, please ensure you have approval from your line manager and a senior manager or head of profession in your organisation. If you are interested in applying but are not sure if this programme is right for you, or if you have other questions, you can attend one of our project clinics on [Wednesday 21 December 2022](https://www.eventbrite.co.uk/e/data-science-accelerator-programme-project-clinic-tickets-475135532167) or [Monday 16 January 2023](https://www.eventbrite.co.uk/e/data-science-accelerator-programme-project-clinic-tickets-475136204177). These sessions will be hosted by the programme delivery team and a panel of experienced mentors. They will include an overview of the two Accelerator programmes, and they will help with general guidance and answers to questions about: If you have any more questions regarding the Data Science or Data Visualisation Accelerator, please email [Data.Science.Accelerator@ons.gov.uk](mailto:Data.Science.Accelerator@ons.gov.uk). For more information about our implementation of this accessibility process, read our [blog post](https://datasciencecampus.ons.gov.uk/paving-the-way-for-accessible-data-science-training-in-the-public-sector/). Before you start, generate a folder with accessibility reports for all existing material, listing the issues you have identified. This ensures a detailed record of any necessary improvements is available, which can be measured and reported once the work is complete. Use a tool like [wave webaim](https://wave.webaim.org/) to determine if the course or material has already had accessibility checks. If there is a list of accessibility issues available, skip to Stage 2. If not, go to step 2. If there is no record of any accessibility issues with your material, check that there are HTML versions available. Some formats, such as PDF, should be avoided as they are not accessible for those using screen readers. If there are HTML versions available, skip to step 4. If not, go to step 3. Create HTML versions of your material or course. These should be produced using R Markdown, which is knit to an HTML. If you are creating presentations, go to the [creating an accessible PowerPoint template](#powerpoint-template) section. Convert Jupyter notebook content for Python into R Markdowns, which support Python code. This is a manual task and can take some time, but it will only need to be done once, which makes maintenance and updates much easier to complete. There is a function called [convert_ipynb()](https://www.rdocumentation.org/packages/rmarkdown/versions/2.11/topics/convert_ipynb), which converts a Jupyter Notebook into an R Markdown. This could significantly reduce the work involved in this step, but there are a few caveats. Paste the HTML document's URL into the [wave webaim](https://wave.webaim.org/) tool to obtain a record of the accessibility issues in the HTML. The tool will respond with a list of the Web Content Accessibility Guideline Errors (WCAGE). The tool reports issues that would adversely impact anyone using a screen reader. Before using the R package or making edits to presentation templates, save this information into a word document to review and keep as evidence of the issues. Check the accessibility of your Word document (.doc) files. These are widely used and preferred over PDFs, but they can also present accessibility issues. Navigate to the 'Review' tab in Word, where you will find a \"Check Accessibility\" button. For more information, see Microsoft's [guidance on Word document accessibility](https://support.microsoft.com/en-us/office/make-your-word-documents-accessible-to-people-with-disabilities-d9bf3683-87ac-47ea-b91a-78dcacb3c66d). PowerPoint presentations are widely used in training courses, updates, show-and-tells and outreach events. To ensure your presentations are accessible, start by following steps 1 and 2 on S. Then, proceed with the following steps: Check if your organisation has a template for presentations. If there is a template, skip to step 3. If not, go to step 2. Create your accessible PowerPoint template. Once this is approved by the head of your department, skip to step 4. Evaluate the accessibility of your organisation's existing PowerPoint template. Check [the Microsoft PowerPoint guidance on checking accessibility](https://support.microsoft.com/en-us/office/make-your-powerpoint-presentations-accessible-to-people-with-disabilities-6f7772b2-2f33-4bd2-8ca7-dae3b2b3ef25). The Review tab in the ribbon has a \"Check Accessibility\" option that will display issues with your template, which should be pasted into a Word document. This tool can also be used for ad-hoc presentations, if necessary. Use [Microsoft support](https://support.microsoft.com/en-us/office/make-your-powerpoint-presentations-accessible-to-people-with-disabilities-6f7772b2-2f33-4bd2-8ca7-dae3b2b3ef25) to address as many accessibility issues as possible. Present and circulate the accessible template across your organisation to gain feedback, inspire and encourage others to improve accessibility in their department. Now that the paper trail has been established, you can begin solving accessibility issues using the R package \"accessrmd\". Our [GitHub repository](https://github.com/datasciencecampus/accessrmd) and [blog post](https://r-leyshon.github.io/access_rmd_docs/) have more detail about the functions contained in the package and examples of their use. If you are going through a curriculum review or update, complete this in R Markdown and confirm changes with stakeholders and your wider team before presenting the finished product. Remember to use convert_ipynb() or a copy and paste process for Python notebooks. \"Knit\" your final version to an HTML page, which will form the final course notes. Knitting is the process of converting a code script in R Markdown to an HTML webpage. Use the naming convention \"previousname_pre2022.html\" so there is a clear comparison with the newest version. Install \"accessrmd\" from CRAN into your R environment using the code 'install.packages (\"accessrmd\"). This only needs to be done once and from there on, it can be imported to a session of your choice using the code \"library(accessrmd)\". Apply functions from \"accessrmd\" to your course markdown and save the output as a new HTML with the naming convention \"previousname_2022.html\", so that it is easy to distinguish between them before and after the curriculum review. Test the new HTML in [wave webaim](https://wave.webaim.org/) and create a new Word document detailing the existing issues that \"accessrmd\" has no functions to solve (or issues that were supposed to work but didn't). This allows for maintenance documentation, as well as a paper trail for when new additions to this package are released in the future. You are now ready to upload and distribute the final course materials. This stage applies to everyone at your organisation and can be led by an accessibility champion. Commit to regular accessibility audits in line with current guidance on accessibility of HTMLs and presentations for screen readers. Maintain good collaboration and discussion with other departments and stakeholders around accessibility. Organisations such as the [Digital Accesibility Centre](https://digitalaccessibilitycentre.org/) (DAC) can test materials, provide accessibility audits and roadmaps, as well as updates in the field. Consulting with disability groups at your organisation could lead to a \"focus group\" where discussion and testing can take place. Bring new developments to the attention of the accessibility champion. That way, they can be collated in advance of the next audit or curriculum review, and multiple issues can be fixed at the same time, if resources allow. There should be at least one audit for accessibility purposes each year. This document will serve as a guide for each subsequent review. If there are no new courses to be added or written, begin at stage 2. There is an ongoing process to make improvements and resolve new issues with accessrmd. The package is functional and incredibly impactful, but there are some unresolved issues and potentially unidentified problems. New updates to the package, as well as issues solved, will be included in its documentation. This should be checked during each subsequent audit to ensure that the newest version can be used to further improve existing documentation. A better understanding of the social care workforce is important for employers, policy makers and researchers. Identifying specific roles within the sector can help target areas which are most in need of support. This would also consequently improve the quality-of-care users receive. In this guest blog post, former data science apprentice Evie Brown now working with the Social Care Analysis team at the Office for National Statistics (ONS) presents work on grouping online job adverts by social care role. This project was a significant part of her final year of the [Level Six Data Science Apprenticeship.](http://datasciencecampus.ons.gov.uk/capability/degree-data-science-apprenticeship/) The Level Six Data Science Apprenticeship combines teaching data science theory through a university programme with working with real world projects in a workplace. A mentor from the Data Science Campus was able to support the apprentice to complete this work. This included advice about defining the project's research questions and implementation of each classification method. The data for this project were from the Reed.co.uk Application Programming Interface (API) and specifically collected for this research purpose. For more information about the apprenticeships supported by the Data Science Campus please refer to our [apprenticeship pages](https://datasciencecampus.ons.gov.uk/capability/degree-data-science-apprenticeship/). [Previous research to categorise job adverts](https://www.bankofengland.co.uk/-/media/boe/files/working-paper/2018/using-job-vacancies-to-understand-the-effects-of-labour-market-mismatch-on-uk-output.pdf?la=en&hash=E062A2D54F8B772B2B6DDF5D671447678E66F2F4) have included assigning three-digit Standard Occupation Classification (SOC 2010) code to job adverts (using Reeddata) using Term Frequency - Inverse Document Frequency (TF-IDF). Developed by the Bank of England, this method used string matching (using known job titles), cosine similarity and fuzzy matching to assign an appropriate SOC code (Turrell, Speinger, Djumalieva, Copple & Thurgood, 2018). This method had an accuracy of 91% when compared to job adverts labelled using an Office for National Statistics (ONS) proprietary algorithm. Arthur (2021) also used Reed data to show how [job roles can be identified from job adverts using different machine learning models](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0251431). Supervised tree-based algorithms were trained using data labelled by identifying specific words in the job title of an advert. This method returned an accuracy of 92%. The [Data Science Campus has previously investigated how logistic regression models could be used to automate the labelling of job information fields](https://datasciencecampus.ons.gov.uk/projects/automated-coding-of-standard-industrial-and-occupational-classifications-sic-soc/) in ONS surveys to SIC (Standard Industry Classification, 2007) and SOC (2020) codes. This model had an overall accuracy of 84% when used on a test sample of census data. (Thanasis, Wood, 2021). This research aims to build on these papers to test the feasibility of identifying job roles in a specific sector or domain, social care, using a combination of a binary supervised classifier and a semi-supervised model. Job advertisement data were collected using the Reed Application Programming Interface (API). Reed is a recruitment agency used by employers to advertise jobs online. People can apply for jobs through Reed by searching for specific roles by job sector or title. A sample of social care and non-social care jobs were collected using the API publicly available through [Reed's developer website](https://www.reed.co.uk/developers). An initial sample of jobs was collected using the key term argument \"social care\". To clean the text fields in the data we: The sample of job adverts were quality checked. Prevalent non-social care jobs were removed by searching for specific non-social care key terms in the job title of each advert. After processing, duplicated job titles were removed from the data, leaving a final sample of 8,995 social care jobs. A sample of non-social care job adverts was also collected. These jobs were available through the Reed API but were not present when using the key term \"social care\". After processing (using the same steps described for social care jobs) and sampling (removing adverts at random to balance the two classes), the number of unique non-social care jobs in the sample was 8,995. Therefore, the total number of jobs in the data was 17,990. A new variable was created by combining the cleaned job title and cleaned job description from each job advert into a single document called \"jobTitleDescription\". Both embedding and frequency matrix models were tested as word vector representations: selection of parameters and inputs used in the TF-IDF model are: The data were split into two (14,392 jobs; 80%) and testing (3,598 jobs; 20%). Twelve different supervised machine learning classifiers were trained on features created by implementing the following word embedding methods on the \"jobTitleDescription\" variable: The models were used to predict a sector label for each job advert: \"social care\" (1) or \"not social care\" (0). After training and testing, four of the top five performing models (ranked on testing accuracy score) were trained on term frequency-inverse document frequency (TF-IDF) word embeddings. Conversely, four of the bottom five performing models were trained using FastText word embeddings. |Model||Hyperparameters||Word Embedding||Accuracy 0.1 objective = binary:logistic booster = gbtree |TF-IDF||1.0||0.96||1.0||0.95||1.0||0.97||1.0||0.96| |Support Vector Machine||C| = 1 kernel = rbf degree = 3 gamma = scale coef0 = 0 = -1 |TF-IDF||0.99||0.95||0.99||0.96||0.99||0.94||0.99||0.95| |Logistic Forest||n_estimators 1 max_features = sqrt max_depth = 30 bootstrap = False |TF-IDF||1.0||0.93||1.0||0.95||1.0||0.92||1.0||0.93| The performance of each classifier was measured through confidence density plots and confusion matrices. Figure 1 shows the confidence density plots for the top four models shown in Table 1. These graphs plot the prediction probabilities for each \"true positive\" (social care) and \"true negative\" (not social care) job advert in the data. Similarly, the confusion matrices of the same models show most test data job adverts correctly classified into \"social care\" or \"not social care\" roles, as shown in Figure 2. Considering each metric, an XGBoost classifier using TF-IDF word embeddings was selected as the best method in identifying adverts in the social care domain. This model was used to predict a \"social care\" and \"nonsocial\" label for each job advert collected. The job adverts predicted as \"social care\" were filtered from the sample (9,028 jobs). The next stage used a semi-supervised model to identify specific job roles. First, job roles were assigned to a random sample of \"social care\" job adverts by string matching. The key terms and relevant job role label searched for in the cleaned job title of each advert were: An \"Other\" category was created by taking a random sample of job adverts predicted as \"social care\" but could not be grouped into a job role category using the key term search. The categories were balanced using a random sampling method to reduce the size of the majority classes. Labelled job adverts, which were removed from the training set when sampled were added to the \"Not Labelled\" category in the was fitted on the training sample of data. A selection of parameters and inputs used in the Label Propagation model include: The overall testing accuracy of the semi supervised classifier (a sample of manually labelled job adverts; 468 jobs) was 56.00%. Table 3 is a classification report showing the model's performance for each job role. This report shows how certain classes, such as \"Nursing\" and \"Care Assistant\" are predicted better than other job of \"Community Care\" and \"Social Worker\" classes could be because of the similarity in the language used in these job adverts. For example, the type of work or location of job (at an individual's home) may be similar. Furthermore, \"Other\" types of job adverts may be ambiguous and difficult to separate from the specified job role types. Improvements could be made by training the initial classification model on more data to increase the variation of non-social care jobs. This would improve the accuracy of classifications on unseen text data from different sources. Furthermore, introducing a \"human-in-the-loop\" step with manual validation of the specific social care jobs could improve the quality of initial sample used to train the semi-supervised model. This would correct adverts that have been erroneously mislabelled through string matching. Also, testing the model on a \"gold standard\" sample would validate the actual accuracy of the classifier to predict job roles for specific social care job adverts labelled using expert domain knowledge. In summary, a binary classifier and semi supervised model could be used to group different job roles from a specific domain. However, it is apparent that better labelled data, particularly when assigning job roles to different adverts, is needed to ensure consistent and accurate predictions across all job role types. The outcome of this project includes the potential, and challenges, of using unstructured text data. This research is part of a [wider programme of on-going work at the ONS](https://blog.ons.gov.uk/2022/10/11/taking-care-of-the-carers-why-good-workforce-data-matters-in-supporting-social-care/) to help enhance the evidence base of the adult social care workforce. The findings from this project will help identify which data sources can be used to fill evidence gaps in this sector in the future. A large-scale accessibility audit of many courses and presentation templates on the Learning Hub and the ONS website in 2021 revealed many accessibility issues that would impact users of screen reader technology. Following the audit, Richard Leyshon, a former data science lecturer in the Campus faculty, began developing the [accessrmd](https://github.com/datasciencecampus/accessrmd) package, now published on the Comprehensive R Archive Network (CRAN). It can be applied to courses written in R Markdown, where it is used to mitigate accessibility issues before exporting them to HTML. It also corrects many issues that would be caused by the HTML course structure, such as missing alternative text for images, as well as issues with contrast and reading order, which conflict with screen reader technology used by many people in our training programmes. The package improves the accessibility of the content we produce and has had a big impact, not only on my team and our customers, but also the wider public sector. Before the 2021 audit, our Python content was produced in Jupyter Notebooks and exported as a HTML. This was saved as course notes we would share alongside the 'raw' Jupyter Notebook files (known as ipynb files, or I python notebook files). Unfortunately, the audit revealed issues with the HTMLs produced. When running this process in RMarkdown, the issues didn't exist (or were much easier to fix). R Markdown allows you to create Python content and export that to HTML, so this change was implemented immediately. No solution is perfect and there are still small issues that need to be addressed such as alternative text for images, contrast and colouring. The issues found in the RMarkdown HTML files prompted development of the accessrmd package to address them. Its functions will search for accessibility issues in your R Markdown and attempt to fix them so you can then re-render and produce a more accessible HTML file. The package can be developed further to solve some more niche issues and this work is ongoing. The package is still useful for resolving many issues now and has been published to ensure our materials are as accessible and inclusive as they can be now. The package is the centrepiece of the process I have worked to develop with the faculty team and disability groups and there is now a solution that is applicable for documentation in both languages. Whilst it is incredibly useful to have accessrmd to mitigate many issues with our documentation, we believe that documenting the errors themselves before and after its use will establish a paper trail for any accessibility champion to pick up going forward, as well as contribute to the updating of the package in the future. Guidance is available for using the [Wave Webaim](https://wave.webaim.org/) tool to document the accessibility errors before applying the package and keeping a record of those that remain. These can be added to the documentation of the accessrmd package to be worked on going forward. The Microsoft Office Suite is also important in developing training materials. For example, most of our show and tell meetings share slideshows and accompanying Word documents that are inaccessible. Following some investigation, I discovered the incredibly useful (but often overlooked) Review tab in the ribbon, which features a Check Accessibility option. The feature is very in depth, pointing you to the issues throughout your documentation or presentation and even providing tools to fix them in the same tab. I have included links to these pages in the process document to help users make accessible documentation at every level, not just for technical training. This is a first big step towards our commitment to accessibility and I hope it inspires you to better your practices not only at the individual level, but also across your entire team, so that you can have accessible HTML files, PowerPoint templates and Word documents. Changes like these have been a long time coming. For too long many have been excluded from the conversation and we want to do all we can to make sure Diversity and Inclusion are at the heart of everything we do. Whilst this is just the first step to tackling this issue across the Public Sector as a whole, I believe it is very important to highlight the process we are implementing. I hope you will be enlightened in the same way my colleagues and I have been in recognising the plight of those unable to engage with our materials and the tools to help them. If you want more information or need any guidance, please contact the Data Science Campus faculty. [Data.Science.Campus.Faculty@ons.gov.uk](mailto:Data.Science.Campus.Faculty@ons.gov.uk) The programme, which gives paid opportunities for early career Black data scientists, provides hands-on practical experience using real-world data. As a partnering organisation, the Office for National Statistics (ONS) hosted two interns during the summer of 2022. [Dr Brian Tendai Junior Mbanje](https://www.hdruk.ac.uk/people/dr-brian-tendai-junior-mbanje/) and [Dr Mustapha Muhammad](https://www.hdruk.ac.uk/people/dr-mustapha-muhammad/), who had both previously trained and practised medicine in their home countries of Zimbabwe and Nigeria, were embedded in the Data Science Campus over their eight-week internship. Like all professions, effective data science relies on a solid foundation in the tools of the trade. Based on conversations with the interns to understand their previous experience and what they were interested in learning, our [faculty team](https://datasciencecampus.ons.gov.uk/capability/data-science-campus-faculty/) developed a bespoke learning plan. With access to our extensive internal learning materials, both interns developed their essential data science skills, such as the use of GitHub, foundational learning in Python and R and data visualisation. Mustapha, who at the time of the internship was completing a Master's in epidemiology, explained, \"the learning plan was a useful guide for what to focus on. There was, unfortunately, not enough time to cover it all, but after the programme I will continue to develop these skills using online resources.\" The interns participated in a three-day hackathon hosted by the Department of Health and Social Care (DHSC) on NHS ambulance data. The event was framed around using hospital level discharge data, hospital level ambulance data and care home capacity data to explore the causes of the variation in discharge delays across various NHS Trusts. Brian, who was completing a Master's in heath data science, said of the hackathon, \"It provided an exciting opportunity to work on a data science problem with a tight deadline. I only had a few days to complete it rather than weeks, as I was used to for university assignments. I also got to work with a different type of data.\" Brian went on, \"It was a useful exercise in teamwork and highlighted the advantages of working in a well-managed team, where roles and responsibilities are divided between team members. Despite some frustrating technical issues with IT infrastructure on the first day, we persevered and succeeded in the end and, happily, our team won best presentation!\" For Mustapha, \"the hackathon was a valuable opportunity to work alongside experienced data scientists and learn how they approach a problem, and for me to apply my learning of data science tools\". Additionally, HDR UK provided an opportunity for the interns to participate in a team-based technical challenge. Interns across the full cohort were assigned into groups and tasked with developing a research question to explore and analyse, given a particular dataset. Mustapha, whose team worked on a machine learning approach to predicting cardiovascular disease, said, \"it was really interesting to work through the complete data science cycle; from identifying the problem, to cleaning the data, to creating visualisations and building models and, finally, presenting this as a report and presentation.\" He explained, \"I had never done any machine learning before, so it was good to see what that was all about.\" The Campus plays an important role in bringing the data science community across the UK public sector together, a recent case in point being the [Government Data Science Festival 2022](https://datasciencecampus.ons.gov.uk/the-government-data-science-community-in-2022/). Drawing on this network, we were able to provide Brian and Mustapha the opportunity to meet and discuss the work of data scientists from NHS Digital, the UK Health Security Agency and Public Health Wales. \"It was interesting to see a wide perspective on the health data science work carried out in the public sector\", said Brian. Brian and Mustapha also benefited from the weekly training sessions offered by HDR UK for the full cohort of interns, with guest speakers from across the public, private and academic sectors. Topics ranged from skill training to career development guidance to combating imposter syndrome. Drawing on their experience working in the healthcare sectors of Zimbabwe and Nigeria, the interns were tasked with presenting an overview of healthcare in their home countries to the ONS's [International Development Team](https://www.ons.gov.uk/aboutus/whatwedo/programmesandprojects/internationaldevelopmentteam). Supplementing their own lived experiences with some analysis of data from the [Demographic and Health Surveys](https://dhsprogram.com/Methodology/Survey-Types/DHS.cfm#:~:text=Demographic%20and%20Health%20Surveys%20(DHS,population%2C%20health%2C%20and%20nutrition.) (DHS), Brian and Mustapha outlined some of the main challenges facing healthcare, the progress made in child mortality rates and the state of health data collection in these countries. Not only good general practice for the interns, \"preparing for the presentation helped me develop my presentation style and working with DHS data provided an opportunity to learn geospatial mapping in R, which I had never done before\", remarked Brian. The presentations also provided useful insights for the International Development Team - whose remit includes scoping areas where the ONS can support developing nations on the generation of statistics. When asked to reflect on his experience of the internship, Mustapha, whose aim for the internship was to explore and better understand what it means to work in data science, described it as \"fabulous\". He went on, \"thinking about my general understanding of data science on a scale of 1 to 10, the internship brought it from one to seven or eight. I now better understand what data science is, what it means to be a data scientist and to work in a data science environment.\" \"The future of epidemiology is strongly linked to data science tools, so I will take the skills I learnt during the internship and develop them to use in my planned career in quantitative research,\" concluded Mustapha. Similarly, Brian remarked \"the internship was a good and valuable experience. It provided an opportunity to acquire knowledge and skills, and apply those in a practical sense. I was able to experience the practical version of data science, rather than the classroom version, and prepare for working in a professional environment.\" Here are some links where you can find more information about some of the programmes available to support the development of your data science skills: In this blog, the faculty shares more details of the successful delivery of our geospatial module as part of the Geography for Data Science and Analysis course. The module was a partnership between the Campus faculty, the Office for National Statistics' (ONS) Geography team and Ordnance Survey (OS), and it has received fantastic feedback from current graduates. The geospatial module was part of \"Special Topics\", contributed to by the wider data science community within government. The topics give the graduates additional practice within other areas of data science by drawing on the expertise of partner organisations. The Geography for Data Science and Analysis course that we produced with the ONS Geography team and OS has now been run twice - once as a pilot for our 2020 cohort in November 2021 and then in full for our 2021 cohort in June 2022, reaching 10 stakeholder organisations in just one year! For many graduates, this was their first encounter with geospatial analysis, and the module covered good practice, data management, spatial analysis, visualisation, design, and ethics. This tied in nicely with some other modules that were covered earlier in the graduate programme; for example, graduates could use their visualisation skills gained from the Statistics and Visualisation module to build upon their existing knowledge of static charts to create eye-catching, interactive maps. The course was delivered in both Python and R, giving the graduates the opportunity to code in the language they felt most comfortable in and build on skills that they could take back to their respective teams. The course was split into three days, with a different theme for each day: \"Location matters - an introduction to geographic data and methods\", covered important geography policies that underpin the best practice around using geography with statistics. \"Working with geospatial data - mapping, linking and managing the data\", covered geospatial data visualisation best practice and a \"Visualising the Spatial Distribution of Middle Layer Super Output Area (MSOA) Accessibility to Green Space\" challenge. \"Geospatial data in the real world - ethics, data sources and putting it all together\", involved a session focusing on the ethical considerations in the use of geospatial data for research and statistics, and an extended exercise to build on everything learned over the last few days. In particular, the ethics session was especially impactful for the graduates as it allowed them to consider complex ethical issues in a different area of data science to what they may be used to. Feedback from this year's graduates shows the success of the module: \"The module felt very complete and gave an excellent grounding in the discipline. I feel that this is an incredibly valuable module for data scientists as the need across the ONS and public sector for visualisations that involve geospatial and mapping elements is ever growing\", says Jake Marshall, trainee data science lecturer at the Campus. \"I thought the OS Day was fantastic, very well delivered and you could tell that a lot of preparation went into the material.\" \"There was a nice mixture of theory and practical teaching. We got lots of opportunity to work with hands on examples after walking through the concepts and ideas in a lecture format,\" says Lily Taylor from HM Treasury. \"Learning from people with geographical domain expertise really helped. It's all too easy to slip up as an analyst working with maps if you haven't learnt the specifics of representing data on a map.\" Having course trainers with expertise external to the faculty was valuable, and it brought a fresh perspective for the graduates. They received various OS resources in addition to a highly engaging and interactive delivery that challenged them in the different areas of geospatial analysis. Bringing in such a fresh, engaging module to the graduate programme has significantly improved the programme and our own analytical capability. We can also reuse the content provided by the ONS Geography team to create our own training that can be used for bootcamps and other training sessions that we provide for various stakeholders in the public sector. This will be invaluable as demand for geography for data science increases. The Data Science Campus faculty would like to give a huge thank you to Steve, Jess, Paul, Heather, and all of the facilitators from the OS and ONS Geography teams - we look forward to seeing you next year!]]> The Government Data Science Community is a vibrant UK public sector initiative, providing a space for analysts and data scientists to come together to support, share and learn from one another. Community meetups provide a great opportunity to do this. This autumn marks the launch of a new series of meetups, starting with a virtual event on 19 October, from 10am to 11.30am. You can find more information and details of how to register on [Eventbrite](https://www.eventbrite.co.uk/e/government-data-science-community-of-interest-meet-up-tickets-424067406027). In May 2022, the Government Data Science Festival gave a platform to the community, along with colleagues from the academic sector, to discuss the future of data science for public good. It was a festival for the community, by the community, enabled by the Office for National Statistics (ONS) Data Science Campus, in partnership with colleagues from HM Revenue and Customs (HMRC). The festival started with a panel of leading figures in data from government and academia addressing some big questions about the future: The panel included Sir Ian Diamond, the UK's National Statistician, Dr Laura Gilbert, Chief Analyst at 10 Downing Street (10DS) and Professor David J Hand from Imperial College London. During the two weeks of festival events and activities, these questions, and many others, were discussed across 85 sessions held by speakers from 33 organisations. The topics ranged from using spatial data to model land use change, synthetic data for healthcare analysis, data science to drive policymaking, to project management for data science. There was even a session on comedy writing for great communication! Data science skills development featured throughout the festival, and the Campus faculty team ran a programme of learning at all levels, from our \"Art of the possible\" session, through to advanced technical tutorials. People came together in social spaces, including yogalates, gaming sessions and well-being sessions. A series of community engagement workshops gave us valuable insights into what you want for the future of the community. A hackathon was held in collaboration with the Analysis Function's Analysis in Government month, with a theme of #AnalysisCollaborate. Eight groups from across government were given a data challenge to better understand the impact of the cost of living rises for households across the UK. Not only was this a great opportunity to work with people from different organisations, but it also gave the chance for teams to explore different techniques, learn and share from others. All this was organised with amazing support from a team of \"festival makers\", colleagues from across government and the public sector who gave their time to support the event. A huge thank you to everyone who was involved. The festival would not have been the success it was without the help from our speakers, festival makers and the organising team. After the festival, we formed a working group including colleagues from across government and the public sector, to help run the future programme for the data science community and develop a roadmap of activity. We have drafted a Community Charter, which outlines what the community is for, its values, and how it will work. We will share this at the next community meet-up. The charter will be owned by the community, so we would love to hear any thoughts you have before the final charter is published. For the community to continue to be a vibrant, supportive and inclusive space, we need your help. There are several ways to get involved and enable the community to keep supporting and learning from one another. This is a great way to gain experience and skills, widen your perspective and build your network. We will be sharing details of specific volunteering opportunities soon. Is there an area of special interest or expertise around data science that you would like to share with like-minded colleagues? We can support with tools and resources to help you run a sub-community. Are you looking to grow and develop a network of data science expertise in your organisation or across your region? We can support you to establish this and ensure you maintain links with the wider community. Tell us what you want! Drop us a line at [government.data.science.community@ons.gov.uk](mailto:Government.Data.Science.Community@ons.gov.uk) or join the dialogue on the [Gov Data Science Slack channel](https://govdatascience.slack.com/). You will need a public sector email address to join. You can simply come along or hold a session on a project, technique, idea, success, failure or challenge you are working on - come and share it at a community event! To keep in touch with community news and events, sign up to the [community mailing list](https://ons.us1.list-manage.com/subscribe?u=0f8869b47a9fed86f0fa1dc17&id=998edd3774). As ever, the predominant theme throughout the festival was the need to continue working together, sharing ideas, data, tools and techniques. Kirstine Dale from the Meteorological Office (Met Office) highlighted that \"data science is a transformative technology that is moving so fast, that no single organisation is going to be able to remain at the forefront or to address the challenges and opportunities that are presented. So, it is critical that we work in partnership.\" We think this quote sums up nicely why the data science community is so important. We are excited to move into the next chapter. With your help, we can keep offering a programme for the community, by the community. For more news and events across the data science community or to get involved please email us at [government.data.science.community@ons.gov.uk](mailto:government.data.science.community@ons.gov.uk) In July 2022, we hosted two A-level students for work experience; it was the week where temperatures hit 40 degrees Celsius in the UK, so this was a challenge in itself! We were keen to involve the students as much as possible with our work in the faculty, to give them an idea of what we get up to daily. One thing on our to-do list was to explore [Google Data Studio](https://datastudio.google.com/overview) as an option for dashboarding. This would allow us to understand its capabilities and potentially deliver training on that topic for stakeholders within the Civil Service. Our interns had a go at exploring this tool by using the dataset from the recent [experimental analysis on tracking the price of the lowest-cost grocery items in the UK](https://cy.ons.gov.uk/releases/trackingthelowestcostgroceryitemsanexperimentalanalysisukapril2021toapril2022). By the end of the week, they had come up with an incredible interactive dashboard, which they presented to our team alongside the pros and cons they had discovered along the way. This gave us a well-rounded insight of how we could use Google Data Studio both as a dashboarding tool and to create bespoke training for this tool, based on existing training. Following this successful pilot we are exploring what internship and placement opportunities we may be able to offer in future. Knowing that our interns were interested in studying Mathematics at university next year, we wanted to show how a degree in Mathematics can be useful in the Civil Service. During their time with us, we arranged opportunities for them to talk to colleagues from around the ONS about how their maths degrees had helped their career, both in and out of the Civil Service. This was particularly useful to the students, as it enabled them to understand the applications of maths and statistics to careers. One of the students said: \"I really enjoyed my time at the Campus. Not only were the staff extremely welcoming and friendly, but I got an insight into the kind of work I might pursue in my future. We were able to look around the office, and we spent time at Newport and London, which was very interesting as it showed some variation of workspaces and environments. I felt really supported throughout the week by the Data Science Campus, and they were extremely helpful and informative with whatever questions I had. They also took a strong interest in my university/career plans and set up meetings with experienced people who really helped me with my uni decisions.\". [Nuffield Research Placements](https://www.nuffieldresearchplacements.org/) are funded by the [Nuffield Foundation](https://www.nuffieldfoundation.org/) and delivered by [STEM Learning](https://www.stem.org.uk/). They are engaging, hands-on research projects, where Year 12 students from lower socioeconomic backgrounds can make a meaningful contribution towards the work of a host organisation, while at the same time developing subject understanding, research and quantitative skills to expand career projects, as well as learning more about higher education and different career paths. This year, two students were allocated to the ONS Data Development Unit (DDU), and two were allocated to us in the Campus, with interests ranging from studying chemistry, economics, computer science and medicine at university. During the three-week long placement in August, the interns were required to undertake a research project with a question set by us. The projects involved producing a report, a research poster and a presentation detailing the findings from their research and datasets used during their time with us. The Campus interns used the current cost of living discussion as the theme for their research; one student focused on the rising cost of groceries, and the other explored recent energy prices. We also organised talks from colleagues across the ONS, giving the students a chance to develop their skills in research, communicating statistics, presenting data and analysis, and much more. We provided Python training to enable our interns to learn basic data analysis skills through coding and develop visualisations with the data they were given. \"I had little knowledge of the ONS and its importance within data science prior to the placement. However, this placement has showed me the important role the ONS has in analysing different statistical data for the government and the greater public.\", said one of our Nuffield students. She also agreed that the placement had helped her understand more about her chosen career, saying \"it has made me think more about exploring the research element within medicine.\" This experience has also been vital for the development of our own faculty's trainee data science lecturers. Jake Marshall, who ran the Campus placement with me, said: \"It was a privilege to be able to supervise and manage interns for the Nuffield Research Programme this summer. It was an excellent opportunity to not only gain experience mentoring and managing, but also to showcase the fascinating world of data science in government to AS-level students. I found teaching them some data analysis skills in Python to be the most successful, with both interns engaging fully with the workbooks created. This was very rewarding for my progression as well, allowing me to try out different methods of teaching and delivery.\" We are hoping to host at least 10 students from the Nuffield Research Placements in 2023 across the ONS. We are extremely grateful to have the opportunity to work on closing the gender gap in STEM - out of the six students from this year, four were female. Hopefully, next year and beyond we can keep this trend going and continue to improve on contributing to greater female representation in data science. We are delighted to have sparked such an interest in both data science and the Civil Service. A huge thank you to Tom Dodkins, Jennifer Wright, Georgina Martin, Jake Marshall, Penny Holborn and Alison Adams for their support in these programmes over the summer. If you would like more information about outreach opportunities, or you are a school interested in engaging with us, please contact the [Data Science Campus faculty](mailto:data.science.campus.faculty@ons.gov.uk). We welcomed guests from 26 national and international organisations at our offices in Newport, including partners from Rwanda, Brazil, Thailand, Lebanon, Jordan and Canada. Our partners brought a wide range of skills from the world of Big Data and official statistics ranging from chief technology officers and methodology leads to data scientists and national statisticians. This wealth of knowledge and experience gave us a unique opportunity to learn about the data science journey each of the organisations had been on over the past five years. One of the highlights of the event was a panel discussion with senior leaders from Ghana, Ireland, UK and the Netherlands, sharing the lessons learned from their organisations' different experiences. Ronald Jansen, Assistant Director of the United Nations Statistics Division helped us understand how much progress official statistical organisations around the world have made come in building data capability. Across the three days a series of sprints and workshops focused on projects involving the Campus, other National Statistical Organisations, and the UN. These covered several core themes including capability, technology and new methods and data sources and were run by groups that included the UNECE (United Nations Economic Commission for Europe) Blue Sky Thinking Network, the UN Regional Hubs, the ONS-UNECE Machine Learning group. As a result of the work in Newport, the UNECE (BSTN) is now moving forward with a new project on cloud use for official statistics. The four UN Regional Hubs are stepping up activities to share experiences with each other to accelerate their development. Michael Reusens, Data Science Coordinator from Statistics Flanders, led the Machine Learning Group's web scraping data sprint, and commented: \"The in-person sprint was extremely motivational for our group. It was really valuable to work side-by-side with colleagues in the room compared to working alone or purely online\". Other participants spoke about being able to meet people from so many different organisations and projects and of having those informal conversations that really help build connections and create new ideas. The UN Regional Hubs delivered several outcomes. Ceri Regan, Data Science Campus, and UN TCCD Task Team on Training, Competencies and Capacity Development member commented: \"We promoted the UN Regional Hubs, learned how they could support each other and leverage synergies, discussed potential partnerships and promoted the capability building tools already available to NSOs. The depth of discussion was noted throughout - this never happens virtually!\" The event produced a wide range of outcomes in the areas of building capability and innovating with new techniques and data sources. Data science capability experts from the Campus including our International Development Squad and UN TCCD held insightful discussions on how best to deliver data science training, globally, on mass, in an online virtual world. The UK and UN experts also identified opportunities for stronger partnerships. \"This is one of the first large-scale meetings ONS has hosted at its offices since the start of the pandemic,\" commented Hannah Rogers, one of the event organisers. \"Preparations were significant and involved many ONS teams. It was great to see everything come together so well during the event itself.\" Many new connections were made, and existing relationships renewed. By expanding professional networks, the meeting has helped lay the ground for future collaboration and the generation of new ideas across the international statistical community. We are proud to say that over the three days we cemented our reputation as a leader in international data science for official statistics, shaping the statistical agenda, leading collaboration on the most urgent statistical challenges, and promoting the UK as a world leader in data science for official statistics.]]> Although a large amount of open data exists for rail travel, it can be difficult to visualise geospatial patterns of disruption on any given day. We produced maps that showed service levels at every station in Great Britain, using an existing daily feed of timetable data from Rail Delivery Group that gives departure and arrival times for every train running on a particular day. These data are typically stored in text format to be used for services such as journey planners. We used open-source software tools to calculate the total number of timetabled trains that would normally stop at a station on a given day, as published by train operating companies seasonally. To understand the extent of reductions in services on disrupted days, we also looked at any revisions to the daily schedules, which could include cancellations, additions and amendments. For every station, we visualised the latest planned service level as a proportion of the originally timetabled service levels. Figure 1 shows an interactive map of the number of scheduled services as a proportion of the timetabled services for Saturday 13 August 2022. The size of the circles on each station is proportional to the number of timetabled trains that typically stop in the station, while the colour of the circles relates to the proportion of timetabled trains that are due to be running that day (black circles indicate a station with no services running). The map has an address search, panning and zoom functionality, and stations can be clicked on to view additional information about them. In the top right corner, there is the option to change the base map between a version that highlights the train network and an option that is more accessible. We also produced a similar visualisation that cycles through the next 21 days to give a longer advance look at planned service levels. Figure 2 shows an interactive map illustrating the number of scheduled services as a proportion of the timetabled services from 11 August to 31 August 2022. Data have been obtained from the Rail Delivery Group via a daily feed, which is available for reuse. Data are made available to us overnight each day, from which we generate the visuals. Data are provided in a standardised [ATOC.CIF format](https://www.raildeliverygroup.com/files/Publications/services/rsp/RSPS5046_timetable_information_data_feed_interface_specification.pdf) (PDF, 1273KB) from which files could be read as text in Python. We developed a parser to aggregate the train schedule on any given day (after cancellations, exceptions, and amendments) and visualise the number of services scheduled at any given station. In addition, the inbound data are converted to General Transit Feed Specification (GTFS) format and interactive visualisations are generated using the Folium library. We intend to make the code open source as soon as possible. We define station \"service levels\" to be where a train is reported to have stopped at a station at any time during a day. Tube and bus replacement services (full or partial) are also typically captured as a service. It is important to note that these data have several caveats and limitations. The data are all based on individual train operating companies reporting changes to planned services. Therefore, data quality is determined by how often and how frequently this is done by each company. Analysis suggested that the frequency of train operators submitting schedule changes varied, but we could not infer any differences in quality from this. Visuals only illustrate the known schedules as of 11 August data; any changes after this point will not be present in the data. Any timetable entry, regardless of permanence, may be subject to further change as a date gets nearer, so a more accurate picture of station activity will develop over time. It is also possible for stations to have greater than 100% timetabled services running on a day, because of factors including emergency timetables, rerouting or additional services being added. Another exception arose on 30 July, when a regular shuttle service to and from Birmingham International offset significant service reduction at Birmingham New Street in the first weekend of the Commonwealth Games. We are currently exploring the feasibility of updating these visuals on a regular basis, and would welcome feedback and suggestions on this work by email to [datasciencecampus@ons.gov.uk](mailto:datasciencecampus@ons.gov.uk). This work is part of a wider project in the Campus looking at access to services using public transport across the UK, which open data such as these can also help to provide insight into. Data, analysis, and data science is essential in answering some of the biggest policy questions in Government and beyond. The Graduate Programme creates a talent pipeline for people with these skills to join and flourish in the public sector. Our two-year graduate programme is equipping graduates with the knowledge and skills needed to deliver crucial insight from a range of data sources. We are supporting individuals across the public sector to gain the capacity to develop and use data products for the public good. In the first year, our graduates complete a training curriculum in year one, with three protected learning days per month and working on projects in their home organisation the rest of the time. In year two, graduates are exposed to a professional development learning programme to develop the core civil service data science competencies. The programme launched in 2020, and individuals from the first cohort are now securing highly competitive data science jobs within the civil service. Our most recent graduates started in October 2021 and have now completed the first year learning modules. This is the first time we have welcomed participants outside the ONS including various government departments and covering existing civil servants and new hires recruited specifically to join the programme. Feedback has been very positive with learners impressed with the foundations they are developing right from the start: \"The curriculum not only teaches you the application of Data Science techniques but it first gives you a good grounding in the fundamentals of writing good code. You are equipped to create reproducible code, using best practice, and using version control. [...] the programme gives you an opportunity to work for some exciting organisations. I have had the opportunity to work at HM Treasury's new office in Darlington, which has been an amazing experience so far.\" says Lilly Taylor. To hear more of Lilly's thoughts on the programme please watch below: Graduates are applying this learning straight into the projects in their organisations: \"Although I had previously worked in R, I had little previous experience with the Python language when I joined the programme. Now, I analyse data using Python every day and have been doing this since my second or third week in the role. The curriculum has helped me to improve efficiency of my code, to produce clearer and more informative visualisations and to apply more complex modelling techniques in the projects I am working on.\" says Melissa Bui from the Data Science Campus. A recent survey has helped us understand the needs of our current graduates and the difference in knowledge between the newly recruited participants and the existing staff taking part in the programme. Graduates agreed that the earlier modules, such as Designing Effective Workflows, Statistics and Visualisation, and Reproducible Code and Best Practice, were particularly useful in improving their coding capabilities, as they provided useful information on best practice and collaboration. The success of a graduate Coding Club means we will incorporate it into the programme's main three days of training to allow as many graduates as possible to attend. The mid-point survey focused on improving the accessibility of the programme as we always want to ensure we are being as inclusive as we possibly can with the content we create and how we deliver it. The programme has gone from strength to strength over the last three years. From six graduates within the Office for National Statistics (ONS), to 50 across government and the public sector last year, to 170 places filled for the 2022 cohort starting in September 2022! Some of our new stakeholders include the Department for Health and Social Care (DHSC), Cabinet Office, NHS Wales, the Department for Business, Energy and Industrial Strategy (BEIS) and Tower Hamlets Council. We could not be carrying out the programme without our campus teams, Human Resources (HR) colleagues and stakeholders across government who have been supporting the recruitment and delivery of the programme. For the 2022 cohort of the graduate programme, we offered 170 places to stakeholders and received over 900 applications for the 55 places offered externally through 31 different organisations across government and the public sector. Of these, 200 were sifted and invited to interviews, which took place throughout June 2022. Unbelievably, we have received nearly 2,000 applications to the programme since it began. The word is spreading, and demand continues to grow. Keep an eye out for our communications on applications for next year's programme if you are interested in partaking as a home organisation or a participant on the programme!]]> The coronavirus (COVID-19) pandemic has meant that much of this work has had to be done online over the last couple of years. However, face-to-face gatherings have a special role in building the networks that enable effective international collaboration. We demonstrated this at our recent visit to the [World Expo 2020 in Dubai](https://www.expo2020dubai.com/), a global showcase for the latest innovation and technology from around the world. At the World Expo in Dubai, we supported other NSOs to develop their data science capability by delivering a series of workshops, training sessions and discussions. These were hosted by the United Arab Emirates' Federal Competitveness and Statistics Centre and were part of the work of the UN Committee of Experts on Big Data and Data Science. We have been leading international efforts to support NSOs around the world to adapt to the big data revolution. The Expo celebrated the launch of the UN Regional Hubs for the UN Global Platform - an initiative that the UK has been heavily involved in. The UN Regional Hubs provide NSOs with opportunities for training and collaborative hands-on project activities. The emergence of new technology and data science methods provides a way to take advantage of new data sources. However, NSOs need support with adopting them into their existing systems of statistical production. The UN Regional Hubs are located in Brazil, China, Rwanda and the United Arab Emirates (UAE). This regional structure makes it easier for countries to collaborate and receive training. Countries in the same region are closer to each other geographically and more familiar with each other's specific conditions. The UN Global Platform is a cloud-service ecosystem. It enables the global statistical community to collaborate on new data sources and methods where this might not be possible in their own organisations because of a lack of infrastructure. Its aim is to: The Campus International team delivered workshops to support the UN Regional Hubs with strategy, planning and business delivery. We also delivered technical demonstrations and training sessions covering topics from machine learning to how to use the UN Global Platform. The sessions were run by Ceri Regan and Eric Deeben along with UN colleagues. They gave the UN Regional Hubs the strategic and technical skills for using the platform, and enabled participants to think through what they needed to do and how to do it. Feedback from the UN Regional Hubs was very positive. It underlined the importance of being able to meet in person to have the interactive and in-depth discussions necessary for accelerating learning. A participant from the UAE commented: \"I really liked that it wasn't all presentations, but was much more interactive, I got much more out of it\". In a session for senior management, the [Office for National Statistics and United Nations Economic Commission for Europe (ONS-UNECE) Machine Learning Group](https://statswiki.unece.org/display/ML/Machine+Learning+Group+2022) presented some use cases from NSOs in Poland, Indonesia and the UK. The cases demonstrated how regional NSOs at the start of their machine learning (ML) journey can make best use of ML and some practical guidance on how to start exploring it. The \"Coffee and Coding\" sessions were particularly popular, attracting an enthusiastic and knowledgeable crowd of Emirati data scientists from government, enterprise and local universities to the dedicated Coders Hub at the Emirates Towers in Dubai. In the sessions, Campus experts Alex Noyvirt and Claus Sthamer demonstrated practical code examples and trained them to carry out the development processes by themselves. The Campus programme also connected with the next generation of data scientists when Deputy Director and Chief Data Scientist Louisa Nolan joined a lively and inspiring discussion on data science, big data and youth at a UN Youth Circle. We also had the opportunity to get feedback on our recently launched international mentoring schemes, and how they can be tailored to the different requirements of countries that are part of the UN Regional Hubs. We took time to expand the UK's networks in the global official statistics and data science community. We made new connections and strengthened existing relationships with colleagues working at all levels in NSOs in the UAE and wider Middle East region. After the hard work was over, the delegation was invited by its UAE hosts to tour the Expo site, visiting some of the exhibitions and national pavilions, and sitting down to enjoy a traditional Middle Eastern meal. We left Dubai with many new connections and plenty of new opportunities to take forward. The varied and in-depth programme delivered by the Campus was a brilliant showcase for promoting the excellence of the UK's work in statistical and data modernisation. It has helped accelerate our international capability building initiatives and strengthened the relationships which are vital to delivering them. As Yusuf Murangwa, Director General National Institute of Statistics Rwanda, said: \"You really are the best in the world, we have got so much from you\". Now our focus moves to the next steps in supporting the development of the UN Regional Hubs to build the capability needed for the effective mainstreaming of big data and data science into regional statistical systems. We will continue this work as part of our upcoming international meeting in July, Advancing International Collaboration in Data Science and Big Data for Official Statistics. During the event we will host international partners from around 30 countries to advance collaboration on important projects in data science and big data for official statistics. Interested in finding out more? Our EXPO2020 sessions are available on demand on the [UN Big Data YouTube channel](https://www.youtube.com/playlist?list=PLnhLUm82UgvDFVdb1U2_HsQn2Hmd5bcYs). Updated 9 June 2022 A version of this blog post was first published on 10 May 2022. It has been updated to include more detail on the background to this work, which is part of our collaboration with researchers from the Alan Turing Institute. SynthGauge is a Python library that provides a framework for evaluating the utility and privacy of synthetic datasets, using a range of metrics and visualisations. It's the first output of [our collaboration with researchers from the Alan Turing Institute](https://www.ons.gov.uk/news/news/officefornationalstatisticsandthealanturinginstitutejoinforcestoproducebetterandfasterestimatesofchangestooureconomy). You can [view the SynthGauge Python library](https://github.com/datasciencecampus/synthgauge) to learn more. Data synthesis is the process of replacing a private dataset with one that looks and behaves the same but does not reveal personal information about real individuals. Synthetic data is increasingly being adopted as a method to improve data access and security. One example is making available synthetic versions of data that cannot be shared; for instance, the [Clinical Practice Research Datalink (CPRD)](https://cprd.com/synthetic-data), who release synthetic healthcare records for training and code testing purposes. Another example is enhancing the privacy guarantees of published statistics, such as the [US Census](https://www.census.gov/library/fact-sheets/2021/differential-privacy-and-the-2020-census.html), where differential privacy has been adopted We are currently focusing on applying synthetic data to enable data access. This includes providing synthetic datasets to enable researchers to understand our data while awaiting accreditation to access the true data. It may include testing data pipelines on synthetic data while waiting for real data to become available; this expands on our [previous work where we built a synthetic Census dataset](https://datasciencecampus.github.io/projects/DSC-158-Producing-synthetic-data-for-Census-2021-rehearsal/) as a part of the 2019 Census rehearsal. Up to now, much of our research has focused on the methods for generating synthetic data. This includes our research into [the use of Generative Adversarial Networks](https://datasciencecampus.ons.gov.uk/projects/generative-adversarial-networks-gans-for-synthetic-dataset-generation-with-binary-classes/), and the Office for National Statistics (ONS) Methodology team's [pilot analysis testing Differential Privacy](https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/deaths/methodologies/applyingdifferentialprivacyprotectiontoonsmortalitydatapilotstudy). Before releasing synthetic data, we need to understand its limitations in terms of statistical accuracy and be confident about the privacy guarantees afforded to limit the risk of statistical disclosure. There is no one-size-fits-all approach to measuring how useful a synthetic dataset is. In some settings, privacy may be valued over statistical accuracy. In other applications, the opposite may be true. In general, there is a trade-off; synthetic data with a greater degree of privacy generally means it becomes less useful, and vice versa. We have created SynthGauage to provide a cohesive framework for evaluating synthetic data for utility and privacy. It will also enable users to understand the strengths and limitations of their methods, and make informed decisions before putting synthetic datasets to use. Through its Evaluator, SynthGauge provides an intuitive and consistent interface to evaluate synthetic datasets, implementing a range of recognised metrics as well as providing the functionality for user defined custom metrics. SynthGauge enables users to compare many datasets consistently and quickly to provide vital insight. SynthGauge will not make any decisions on behalf of the user or specify if one synthetic dataset is better than another. This decision is dataset- and purpose-dependent so can vary widely from user to user. Instead, SynthGauge is intended to support decision makers. With engagement from the open-source community, we hope the suite of metrics can be expanded and refined, contributing to the evolution of the package. To help you get started, the [SynthGauge repository](https://github.com/datasciencecampus/synthgauge) and [Application Programming Interfaces (API) reference documentation](https://datasciencecampus.github.io/synthgauge/) are available on GitHub. If you have any questions about SynthGauge or can help us to improve it, please contact us. You can [contact us by email](mailto:datacampus@ons.gov.uk). Decision-makers wanted fast answers to these questions. This meant daily updates without delay between the activity and the reporting, information on what was happening at a local level - something that is not usually possible with official statistics produced from processed survey data. While official estimates are accurate and reliable, the ONS' traditional survey approach could not provide the required speed and granularity for this challenge. BT stepped in to support the national fight against coronavirus (COVID-19) in March 2020, by making aggregate, anonymised mobility data available to the UK Government. These data helped to inform decision making at the highest level. The Office for National Statistics' (ONS') Data Science Campus, a hub for data science and innovation for the ONS and the wider public sector, quickly turned these data into daily updates, with only one day's delay between activity and the reporting of it. This was a completely unprecedented frequency and speed of reporting for the ONS. Adherence to high standards of ethics and privacy, as well as legal requirements, are very important to both the ONS and BT. BT never shared any data with the ONS in which any individual or individual business could be identified, and [have published details on how customers' data has been safeguarded](https://www.bt.com/about/coronavirus/our-customers). The ONS carried out an ethical review, and held and processed the data in compliance with our own [data principles](https://www.ons.gov.uk/aboutus/transparencyandgovernance/datastrategy/dataprinciples). This was to ensure that the privacy and confidentiality of data subjects was protected. With more than one quarter of the market share in the UK, BT Group is the largest mobile operator in the UK ( [Ofcom, 2021](https://www.ofcom.org.uk/__data/assets/pdf_file/0015/219102/technology-tracker-2021-data-tables.pdf)). This coverage helped us to develop meaningful metrics at speed. Aggregated mobile phone activity across 2G, 3G and 4G voice and data usage is at the origin of the mobile phone data. For contract holders, additional information such as age or gender may also be available. The data were anonymised and aggregated over time, geography, and potentially age or gender, to produce the anonymised, aggregate datasets that were provided to us. To make sure that the mobile phone data is representative of the UK population, it was weighted by geographical area, taking into account home locations, gender and age band, using [population estimates from the ONS](https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/populationestimatesforukenglandandwalesscotlandandnorthernireland). Finally, in compliance with the General Data Protection Regulation (GDPR), statistical disclosure control was applied to the aggregated data tables before they were delivered to the ONS, to further protect confidentiality. All cells in the data tables were rounded to the nearest 10 and cells with values of less than 20 are removed. We only shared analysis derived from this aggregated data with the approval of BT, and only for the purposes of the government (UK and devolved administrations) response to coronavirus (COVID-19). This included the Cabinet Office's Civil Contingencies Secretariat, and [the Civil Contingencies Committee (COBR or COBRA)](https://www.instituteforgovernment.org.uk/explainers/cobr-cobra). Here's how we tackled the three challenges we set out. We looked at the proportion of the UK population who stayed in their local area, by age band. Local area is defined as interactions with only one or two sectors (phone masts or cell towers) per day. This is the smallest geography possible with cell phone data. Figure 1 shows that between March and September 2020, older people, who are more vulnerable to coronavirus (COVID-19), have always been less likely to leave their local area than younger, working age populations. Following the first UK-wide lockdown that began on 23 March 2020, the proportion of those not leaving their local area grew by around 20 percentage points but fell at later stages. We used BT's aggregate cellular data from a set of specific locations. Figure 2 shows a jump in visits to London shopping centres when non-essential shops reopened in England on 15 July 2020. However, by the end of July, the number of unique users at these key locations was still only half of what it was prior to the start of the coronavirus (COVID-19) pandemic. Figure 3 shows how movement was more restricted in urban areas than rural areas in April 2020 but had increased in these areas by September 2020. The maps show the proportion of people who left their local area, by local geographies ( [middle layer super output areas, MSOAs](https://www.ons.gov.uk/methodology/geography/ukgeographies/censusgeography#super-output-area-soa)). The demand for real time indicators and for using sources of data that are new to us has never been greater. The use case for mobility data that we have presented here was for a very specific purpose - to meet the immediate demand for up-to-date information on the mobility of the UK population, particularly at the start of the coronavirus (COVID-19) pandemic. Through this work, we have learned much about the value of this type of mobility data. Our next steps are to assess new uses for this type of data. This includes: We are grateful to the BT team for all the support they have given, to help the nation tackle the coronavirus pandemic. We would be very happy to hear from other organisations who might be interested in [partnering with us](https://datasciencecampus.ons.gov.uk/partnerships/). A recent [working paper by the Data Science Campus](https://www.medrxiv.org/content/10.1101/2022.04.14.22273759v1) has shown that workers in care homes, warehouses, textile, and meat and fish processing tend to carry the biggest risk of infection from coronavirus (COVID-19) at community level across all urban and rural settlements. This has been a consistent pattern over the whole period of pandemic after controlling for a wide range of socioeconomic and demographic profiles, land use and travel patterns, vaccination rates, and real time mobility. We used a community-level analysis of influences on COVID-19 and a combination of statistical models to provide these insights. Understanding and monitoring the major influences on COVID-19 infection (number of cases) in communities is essential to inform policy making and evaluate the impact of non-pharmaceutical interventions (NPIs), such as mobility restrictions, closures of some industrial sectors and schools, social distancing and mandatory face coverings in public areas and on public transport. We can also use this analysis to understand potential health inequalities across diverse communities. For instance, it is of policy interest to understand whether the greater risk of infection for warehouse workers is due to the areas where warehouse workers are residing, factors related to the ethnicity of workers in those jobs, or the workplace and type of job. Producing a robust analysis of community level influences on COVID-19 incidents presents some major data and modelling challenges. The analysis requires a comprehensive dataset that can cover a wide range of influences, from socioeconomic and demographic profiles, area types, land use features, behavioural responses, and policy interventions, such as those reflected in mobility or vaccination rates. Methodologically, the analysis should consider the potential interrelations among influences. For instance, the analysis should account for self-selection and spatial sorting where residents choose their residential locations based on their travel attitudes and preferences, or social structure and inequality. As an example, in evaluating the influences on COVID-19 infection risk, an ideal model should distinguish the effect of living in dense urbanised areas from the impact of belonging to a specific ethnicity group that tends to have higher representation in more populated areas. The analysis should also consider the dynamic nature of the pandemic where influences and impacts changed over time in response to policies, and there were also developments such as the emergence of new variants of virus. This is a huge challenge, and the requirements are unlikely to be met with any single dataset. Individual and household-level surveys (such as the [Office for National Statistics (ONS) Covid Infection Survey](https://www.ons.gov.uk/peoplepopulationandcommunity/healthandsocialcare/conditionsanddiseases/bulletins/coronaviruscovid19infectionsurveypilot/previousReleases)) tend to have small sample sizes making it difficult to incorporate a wide range of influences with sufficient temporal and geographical segments. However, they can capture more detailed influences and interactions within communities which makes them a suitable choice for detailed epidemiological analysis and simulation. In addition, community level analysis can better reflect responses to policy interventions, such as changes in mobility patterns in neighbourhoods. In response, we developed a community-level analysis of COVID-19 influences through assembling a large set of static (socioeconomic and demographic profile and land use characteristics) and dynamic (mobility indicators, COVID-19 cases and vaccination uptake in real time) data in England. These data are integrated from a wider range of sources, including telecoms companies (we used anonymised, aggregated [O2 Motion data](https://datasciencecampus.ons.gov.uk/understanding-mobility-during-the-covid-19-pandemic/) for this study), test and trace data, national travel survey, and Census and Mid-Year estimates at small area geography (LSOA) level. To tackle the methodological challenges of highly interrelated influences, we have combined different statistical and machine learning techniques, creating a two-stage modelling framework: In the stage of selected features for the model, we also adopted Factor Analysis to understand and incorporate the communality across interrelated features. Our model is then split into distinct time periods based on changes in policies or the evolvement in pandemic so that we can evaluate variations over time. Our findings suggest that there exist significant spatial variations in risk influences with some being more consistent and persistent over time. Specifically, the analysis of industrial sectors shows that communities of workers in care homes and warehouses, and to a lesser extent, the textile and ready meals industries tend to carry a higher risk of infection across all urban and rural settlements and over the whole period of pandemic that we have modelled in this study. This demonstrates the important role of workplaces in defining the COVID-19 risk of infection after accounting for the major characteristics of workers' residential areas including land use characteristics, vaccination rate and mobility patterns. We have [published a working paper](https://www.medrxiv.org/content/10.1101/2022.04.14.22273759v1.full-text) in medRxiv, which contains the full findings from this study. Using job vacancy data made available by [Adzuna](https://www.adzuna.co.uk/), we have been able to provide specific insights into advert numbers and pay across different job roles, including HGV drivers and adult social care workers, throughout the UK and regions. The ONS has previously used Adzuna data to provide labour market insights as the COVID-19 pandemic has developed: We employed Natural Language Processing techniques to capture adverts relating to HGV drivers and adult social care workers specifically, using the job title and description fields provided in the dataset. By way of an example, in the case of HGV drivers, we defined 3 levels of regular expressions: (1) common terms (e.g. HGV, LGV or 7.5(t) (2) in conjunction with driver but (3) not including other alternative connections (e.g. with mechanic or technician). These 3 levels were combined into a single regular expression to filter rows of data specific to the role in scope. Reporting of vacancy trends fell into 3 broad time periods: Our assumption was that the number of adverts would fall dramatically at the time of the first national lockdown. While this was broadly true, when looking at the adverts for all sectors combined, we did find that adverts for some roles were much less affected. Along with those across the Transport & Logistics sector more broadly, adverts for HGV drivers decreased dramatically during the first national lockdown in 2020; the same as the picture for all sectors combined (around 40% of pre-pandemic [1](#footnote1) advert numbers by May 2020). However, Transport & Logistics advert numbers increased steeply during Summer 2020 and peaked at twice pre-pandemic levels by September 2020. After a return to pre-pandemic levels by early-2021, a further rapid increase occurred with a new peak in June 2021 for HGV driver adverts of around 350%. Although adverts in the Transport & Logistics sector continued to rise in the second half of 2021, HGV driver advert numbers were seen to fall. The pattern of change in HGV advert numbers was generally replicated across the UK regions. However, it was notable that the June 2021 peak was substantially higher in West Midlands (around 500% pre-pandemic levels) and North-East England (around 400%). While median salaries across all sectors (including Transport & Logistics) have risen marginally over the past 4 years, a notable change was detected in adverts specific to HGV driver roles: a rapid increase from around \u00a325,000 in March 2021 to around \u00a331,000 by November 2021 (Figure 1). Figure 1: Weekly median salaries for HGV driver, Transport and Logistics and All adverts, UK, 2018 to 2021 Note: Median salaries for adverts with salary information available, rounded to the nearest \u00a3100. The proportion of HGV driver adverts missing salary information during the 2018 to 2021 focus period ranged from around 7% to around 19%. Note that plateauing of the median salary (for example, \u00a325,000 for HGV drivers between July 2019 and March 2020) also reflects a common practice of salaries being advertised as rounded figures. Median salaries attributed to adult social care adverts were found to have increased from around \u00a319,500 in January 2019 and peaking twice at around \u00a325,000 in July and December 2020. This included a sharp increase in the later weeks of the first national lockdown. Since then, median salaries again fell to approximately \u00a321,500 by November 2021. While advert numbers fell to around 40% of their pre-pandemic baseline by May 2020 for all sectors combined, the Social Services & Care sector was much less affected: numbers falling to a minimum of around 75% of the sector baseline. After returning to pre-pandemic levels by May 2021, adverts for adult social care roles have increased more steadily than for other work areas (Figure 2). Figure 2: Relative weekly live adverts for Adult Social Care, Social Services and Care & All adverts, UK, 2019 to 2021 In further analysis, we found that the number of adult social care adverts citing qualifications (e.g. RGN, RMN, RNLD, NMC [2](#footnote2)) fell much more sharply than those where qualifications were not mentioned during the first national lockdown of 2020. For adverts citing qualifications, numbers dropped to around 50% pre-pandemic levels by May 2020; the decrease in adverts not citing qualifications was steadier, reaching around 70% of baseline in September 2020. Since May 2021, the increase in adverts where qualifications are not mentioned has been much more pronounced: reaching around 155% pre-pandemic levels, in contrast to approximately 110% for posts citing qualifications, by November 2021. Adult social care advert numbers returned to their pre-pandemic levels at very different times, according to region (for example, October 2020 in East Midlands and June 2021 in London). As of November 2021, numbers were at around 180% pre-pandemic levels in East Midlands and around 120% in London. Naturally, this might provoke some further questions (beyond the scope of our project): The greatest challenge in our work was capturing specific job roles in the data available. Each advert was pre-classified in categories, defined by Adzuna. We found some variation in the content of individual job descriptions and variability in the use of job titles in the advert data provided. Consequently, the regular expressions we engineered had to be sufficiently flexible to capture data rows for the roles in scope. For example, the term driver might relate to roles for HGV drivers, van drivers and supermarket delivery drivers so NLP techniques were employed to glean further context (e.g. HGV). Furthermore, adverts might be presented with or without job title, terms of employment, expected qualifications and so on. A considerable block of work was needed to define regular expressions to capture our roles in scope correctly while limiting errors: false negatives - for example, incorrectly flagging adverts for HGV drivers as non-HGV; false positives - for example, incorrectly labelling a non-HGV advert as HGV. Primary school teacher adverts (not typically requiring HGV driver qualifications) were originally captured given the use of the important term class in regular expressions. Class 1 and Class 2 qualifications are routinely referenced in HGV driver adverts. However, false positives were dramatically reduced when the token teach was excluded. Much time was also spent labelling samples of data in order to evaluate the accuracy of our code at filtering the data rows attributed to the job roles in scope. In summary, we have explored how both HGV driver and adult social care advert numbers have fared during the pandemic and, more importantly, their rates of recovery since the first national lockdown. Other breakdowns have included comparing advert prevalence with and without qualifications, salary changes over time and some contract terms e.g. full-time, part-time etc. This work has already provided valuable indicators to highlight potential vulnerabilities in the UK workforce. Our work has led to an innovative and reproducible approach to flagging changes in vacancy numbers across sectors (albeit requiring new regular expressions). The project has demonstrated a potential for further automation and application of similar methods across other job roles in the future. It has already helped to inform policy. [1 pre-pandemic denotes February 2020 figures] [2 RGN - Nurse] RMN - Registered Mental health Nurse RNLD - Registered Nurse for people with Learning Difficulties NMC - Nursing & Midwifery Council (registered to)]]> The paint was still wet on the walls of the Campus (to the detriment of at least one jacket!), we had an audience of UK and international data science leaders from across the public, private and academic sectors, a team of eight, some brilliant presentations, and a lot of excitement about doing Data Science for the Public Good. This was the [launch of the Data Science Campus five years ago](https://blog.ons.gov.uk/2017/03/31/new-resource-for-the-uks-decision-makers/). In 2016, the [Independent review of UK economic statistics (Bean, 2016)](https://www.gov.uk/government/publications/independent-review-of-uk-economic-statistics-final-report) called for the: 'recruitment of a cadre of data scientists ... active learning and experimentation ... facilitated through collaboration with relevant partners - in academia, the private and public sectors, and internationally.' And so, on 27 March 2017, the Data Science Campus was officially born. Our goal was to be the hub for data science across the UK public sector, building data science capability, developing new data science products, and testing out new tools, techniques and datasets. Data Science Campus HQ, 1 June 2017 (yes, this is still Newport in Wales!) This includes data scientists (of course), trainers and lecturers, content developers, software engineers, project and delivery managers, data engineers, and our outstanding business support team, led by Anya Crisp-Patterson, who are the backbone of the Campus. They have organised uncountable events (including the [MDataGov Symposium](https://datasciencecampus.ons.gov.uk/highlights-from-the-mdatagov-symposium-2019-in-manchester/) and the Government Data Science Conference - now a [virtual Festival](https://orcula.com/data-science-festival-2022/)), delivered our recruitment campaigns, supported international visits both to and from the Campus, resolved our issues, and even helped to design Campus HQ. That is a lot of projects. Roughly half the Campus team are data scientists, and we currently have our highest ever number in post. I am so proud of the volume, complexity, and sheer range of different products our skilful, committed team have produced. There isn't space here to list all of our projects but you can find out more by exploring our [website](https://datasciencecampus.ons.gov.uk/tag/projects/). I have attempted to pick a top five (have you spotted the theme yet?) of projects. It is a difficult task - a bit like choosing your favourite child! Our very capable Capability Team, have delivered training to more than 4,000 people! This includes: We have helped to develop data science as an attractive career in the public sector. You can hear more about this, and join the discussion on what is next, at the Government Data Science Festival 2022 from 27 April to 11 May 2022. [Register now](https://orcula.com/data-science-festival-2022/) as spaces are going fast! We are recognised as the hub of data science in the UK and are the first port of call for many public sector organisations looking for support on their data science journey. The Campus is recognised as a world leader in data science and big data in the public sector. Our International Team co-ordinates the United Nations Economic Commission for Europe (UNECE) [Machine Learning Group (ML 2022)](https://datasciencecampus.ons.gov.uk/how-international-collaboration-is-advancing-machine-learning-in-official-statistics/), which currently has more than 350 members, from over 45 different statistical organisations around the world. This shows how important data science and exploring new data sources is to a global audience. We are supporting low-and-middle-income countries, through our [Data Science Hub](https://datasciencecampus.ons.gov.uk/ons-fcdo-data-science-hub/) embedded with the Foreign, Commonwealth and Development Office (FCDO) and we have a long-standing relationship with the [National Institute for Statistics in Rwanda](https://datasciencecampus.ons.gov.uk/join-the-data-revolution-in-rwanda/). We support the development of the [UN's Global Platform](https://unstats.un.org/bigdata/un-global-platform.cshtml), and the creation of the [UN Regional Hubs for Big Data](https://unstats.un.org/bigdata/regional-hubs.cshtml). It has been fascinating to work with and learn from colleagues across the world, all of whom face very similar challenges to us. One of our goals was to develop strong links with academia, and we have done this through the Office for National Statistics' (ONS') strategic partnerships with [Cardiff University](https://www.cardiff.ac.uk/innovation/our-partnerships/office-for-national-statistics-ons#:~:text=Our%20partnership%20is%20focussed%20around,data%20science%20and%20public%20policy.) and the [Alan Turing Institute](https://www.turing.ac.uk/news/ons-and-turing-join-forces-produce-better-and-faster-estimates-economic-changes), as well as working with academics on individual projects like the [traffic cameras work](https://datasciencecampus.ons.gov.uk/projects/estimating-vehicle-and-pedestrian-activity-from-town-and-city-traffic-cameras/) and mobility. We have also worked with [Barclays Plc](https://datasciencecampus.ons.gov.uk/payments-data-for-public-good/), including a brilliant two-day hackathon, with 25 ONS staff and 25 Barclays staff tackling a variety of challenges. Our work with Barclays proved invaluable during the coronavirus pandemic, where their aggregate data helped to model travel services, while face-to-face interviewing was suspended. We also worked with [O2 Motion](https://datasciencecampus.ons.gov.uk/understanding-mobility-during-the-covid-19-pandemic/) and [glass.ai](https://datasciencecampus.ons.gov.uk/extracting-text-data-from-business-website-covid-19-notices/), among others, focussing on accessing interesting data sources. If you're interested in working with us, please [get in touch!](https://datasciencecampus.ons.gov.uk/partnerships/) Here are five things that we have learned along the way. Data science is a collective effort and, to work we absolutely need people with different skills, knowledge and ways of thinking. This includes both ends of data science (data and software engineering as well as mathematical modelling and statistics), but also subject matter experts, problem-owners, people who really understand the data, communicators, and of course, delivery managers. You will never get your use case nailed down, or be able to prioritise, or be able to handover the product, unless there is someone responsible for the product. We set out in the heady early days, thinking we would do very rapid projects. Even leaving aside the realities of data access and getting up to speed, only in very exceptional circumstances is this enough time to complete something worthwhile. See also 'it will only take two weeks' - this has never been true in the history of humanity! I want our data scientists to be doing data science, and so do they. Our delivery management team, led by the fabulous Sharon Hill, has developed agile processes for us which work in the research environment. This is one of our biggest successes. Our processes mean that we are transparent, clear about goals, deliverables and priorities, have good communication with our stakeholders, and deliver at pace. The evidence is in the number of projects we have been able to deliver. Our delivery managers also take the burden of the crucial non-data science activities, like data access or chasing stakeholders, from the data scientists, freeing up their time for actual data science. I cannot overstate the value of good delivery management. Prototyping is easy and fun. Scaling up often takes longer and requires different skills. But if you don't plan for the scale up and think about handover from the beginning, you are doomed. Doomed, if not to complete failure, to a very long and frustrating period of completely re-writing your code. If you follow good practice for coding standards, your future self (and your colleagues) will thank you. If you involve your customers from the start, and think about handover from the start, it will be less painful. Your code is only useful if others can use and understand it. This is the voice of experience! A small start-up team needs fewer processes than a large established team. Agreeing the minimum viable bureaucracy with the teams at each stage as the Campus has grown has been an important part of our development. I'd like to end with some thanks. First, to everyone who has ever been in the Campus, including Tom Smith, our (former) Managing Director, and Peter Fullerton and Dave Johnson, my predecessors, who made the Campus possible. And everyone who has worked in the Campus. I hope you all read this and take a moment to congratulate yourselves on what you have achieved. To cover everything we have done would require an enormous book (even longer than the [two-year report](https://datasciencecampus.ons.gov.uk/our-first-two-years/)!) but I hope this has reminded you of some of your achievements. Second, to everyone who has supported us at the ONS: the cloud architect and data access teams, who are so fundamental to everything we do; the commercial team who have responded so positively to every new and crazy request we've had; the Facilities team who built the physical Campus in such record time; and everyone else who has worked with us to build something truly new and innovative. Thirdly to the public sector data scientist community, who have been part of this journey, sharing knowledge and challenges, and with an enthusiasm for data science - I hope to see you at the [Government Data Science Festival 2022](https://orcula.com/data-science-festival-2022/), to discuss the Future of Data Science for Public Good. And finally, to all the people we have worked with, both in the UK and internationally, in academia, in the private sector and in other public sector organisations, and in other national statistics institutes. After five years in the Campus myself, my time here is coming to an end. But as I leave, the Campus is stronger than ever with a great team, with ambition and the skills to deliver on it. There are exciting developments afoot in our Capability team, there is our Turing programme to complete, including work on synthetic data and privacy preserving techniques, nowcasting and economic networks, and the potential of mobility data to transform our understanding of how populations move about the UK to be realised. The next five years will be exciting, challenging, and, I hope, as much fun as the first five years!]]> Following successful internal Graduate Programmes in 2019 and 2020, we launched our first UK Public Sector Data Science Graduate programme in 2021, offering 50 places and working with 10 public sector organisations. Our stakeholders have been with us every step of the way, supporting the design and agreeing the content of the programme. It offers a unique opportunity to develop sought-after data science skills and techniques, and put them into practice right at the heart of the public sector. Even in the first few months of the 2021 programme, the graduates and their teams across the public sector are already seeing an impact. For some, their journey to the Graduate Programme has come full circle. In 2018 a Royal Air Force (RAF) flight lieutenant took part in the cross-government Data Science Accelerator project-based mentoring programme. Their project showed potential, so it was developed into a [full data science project](https://datasciencecampus.ons.gov.uk/projects/technical-report-project-mertz-novel-use-of-historical-raf-flight-safety-records/) with Campus and the Office for National Statistics (ONS) colleagues. We now have seven graduates from the RAF taking part in the current programme so that they can create and embed their own data science skills and tools in house. The demand for data science skills shows no sign of slowing down, so this year we are casting the net even further, offering places in 17 public-sector organisations, including two local governments and councils. [Our Candidate Pack](https://files.civilservicejobs.service.gov.uk/admin/fairs/apptrack/download.cgi?SID=b3duZXI9NTA3MDAwMCZvd25lcnR5cGU9ZmFpciZkb2NfdHlwZT12YWMmZG9jX2lkPTEwMDA5NDkmdmVyaWZ5PWY1MGMwM2Y4N2QzNDViYzQ1YjI5NWVkMTMyOGI5ODhlJnJlcXNpZz0xNjQ2MjIxNzM0LWRmNTZiMjdlYWRkYTE1YzI3ZjM3YzJmZTI1NTAzYTkzMDc1NDFlZTA=) showcases all the public sector organisations that are recruiting in this year's campaign. You can [apply now](https://www.civilservicejobs.service.gov.uk/csr/index.cgi?SID=cGFnZWNsYXNzPUpvYnMmcGFnZWFjdGlvbj12aWV3dmFjYnlqb2JsaXN0JnVzZXJzZWFyY2hjb250ZXh0PTE0OTc3MDc1MSZvd25lcj01MDcwMDAwJmpvYmxpc3Rfdmlld192YWM9MTc3NTA3MCZvd25lcnR5cGU9ZmFpciZjc291cmNlPWNzcXNlYXJjaCZzZWFyY2hfc2xpY2VfY3VycmVudD0yJnJlcXNpZz0xNjQ2MjIxNjYwLTcyNTcwNjk0N2ZmODE5ZjhjNzA2MmMwY2RiOTE1YzhmNTVhNDQ1NDE=) for the 2022 Data Science Graduate Programme. Applications are open until 24 March 2022. Perhaps you are not sure if you have the right skills, experience, or background to apply. If you have a numerate or statistical background, and some basic coding knowledge, you are welcome to apply. Our current graduates arrived with varying levels of coding experience and have hit the ground running. Lilly Taylor, Graduate Data Scientist at HM Treasury said: \"I didn't come from a traditional data science background, but I found that hasn't been a problem. The course has been here to get you up to speed in the areas that you need to make a career in data science. So that's been fantastic.\" Lilly and other graduates spoke to us about the impact the programme has already had on them and their organisations in the first few months: Read more about the experiences of our current graduates on our [case study page](https://datasciencecampus.ons.gov.uk/capability/data-science-graduate-programme/case-studies-from-graduate-data-scientists/). If you want to know more about what the programme involves, our [applicant brochure](https://datasciencecampus.ons.gov.uk/capability/data-science-graduate-programme/data-science-graduate-programme-2022-applicant-brochure/) and [information page](https://datasciencecampus.ons.gov.uk/capability/data-science-graduate-programme/) gives an overview of the curriculum, benefits, and testimonials of current and past graduates. We're also holding two online webinars: If you are a prospective applicant, come along to: Please [book your place on Eventbrite](https://www.eventbrite.co.uk/e/public-sector-data-science-graduate-programme-information-webinar-tickets-275654719687). This webinar will give you all the hints and tips you will need to write a successful application and learn what to expect at the interview stage. Please [book your place on Eventbrite](https://www.eventbrite.co.uk/e/data-science-grad-programme-how-to-apply-session-tickets-266220270997). The Data Science Graduate Programme is a fantastic opportunity to join a public sector organisation and a truly diverse and dynamic community using data science skills for the public good. If you are passionate about data science and willing to learn, there is a place for you here.]]> So, what is the Data Masterclass, and why is it in such great demand? The Data Masterclass for Senior Leaders is an innovative online course created in 2020 by the Data Science Team at 10 Downing Street. To create the course, they worked with many different government departments, including the Data Science Campus at the Office for National Statistics. After a successful pilot, we took over the running of the programme, and are overseeing its roll out, with an aim to reach all senior leaders in the UK Government and public sector. The Data Masterclass is an innovative approach to improving data and analytical literacy in senior public-sector leaders. It is designed to help them create and champion a data culture in their organisation. The goal is to improve decision-making and drive better services for citizens across the UK public sector. The course is built around 10 keynote talks delivered by world-leading experts in data and analysis, including National Statistician Sir Ian Diamond, BBC presenter and Associate Professor of Mathematics at University College London Dr Hannah Fry, DeepMind Director of Robotics Research Dr Raia Hadsell, and Campus Managing Director Tom Smith. These keynote presentations are supported by engaging case studies and quizzes. The course is structured around three modules: Each module equips senior leaders in best practice and the power of using data. In addition, the learning platform's functionality is used to create communities for an exchange of ideas and experiences quite unlike anything previously available. The course has been rolled out on a departmental basis, and participating organisations allocate a 'champion' to recruit learners and create engagement around the course. All government departments have been approached and, so far, the programme has: Feedback from organisations and individuals on the impact of the programme has been very positive. Anna Kwiatkowska, Head of Data Science for HM Revenue and Customs (HMRC): \"I wholeheartedly endorse the Data Masterclass. Over 130 of HMRC's SCS signed up, and we received overwhelmingly positive feedback. Many reported having started applying their learning in their day-to-day role, including bringing business problems to explore yet another data-driven opportunity; the vast majority recommended it to their wider teams. The demand means we are about to embark on another cohort of learners to support the wider HMRC and HM Government agenda of growing data expertise and data-driven decision-making both in policy and operations. The Data Masterclass is a game changer\". Sian MacLeod, Her Majesty's Ambassador to Serbia: \"This is leaps ahead of any other HM Government online training I've done; I feel I've learnt something rather than ticked a box\". Demand for the programme continues to increase with government departments asking for additional cohorts as the interest grows in their organisations. Feedback is exceptional, with leaders highlighting how the scheme has improved their understanding and use of data. In the Foreign, Commonwealth and Development Office (FCDO): \"the Data Masterclass has given the [Data-Driven Diplomacy and Development] work a significant early boost\". The Data Masterclass has also sparked exciting new collaborations. High Commissioner Harriet Cross says, \"outcomes [have been] further engagement with [our] Behavioural Insights team [...] to inform policy, improve public services and tackle gender-based violence issues\". As the Masterclass enters its second year, we will work with organisations to gain more insights on the impact of the programme to inform its continuous improvement and application. We will also extend the reach of the programme to ensure that all public-sector leaders have the skills to drive data cultures to deliver better outcomes for citizens. Do you want to improve data literacy and decision-making in your organisation? You can email [data.masterclass@ons.gov.uk](mailto:data.masterclass@ons.gov.uk) to find out how your organisation can embrace the power of data to improve decision-making for the public good. The programme has been set up to help analysts from National Statistical Offices (NSOs) who are looking to improve their data science skills and potentially become a data scientist in the future. Our teams have been working successfully with international organisations to build data science skills and capacity for some time. For example, our data science hub based at the Foreign, Commonwealth and Development Office (FCDO) has spent the last 18 months mentoring colleagues in Vanuatu. This has not only helped to significantly improve the way they produce vital statistics, but they now have the skills to support this work internally by mentoring others. Building on the successful UK [Data Science and Data Visualisation Accelerator programmes](https://datasciencecampus.ons.gov.uk/capability/data-science-accelerator/), we have developed the programme in collaboration with the [United Nations (UN) Big Data Task Team on Training, Competencies and Capacity Development](https://unstats.un.org/bigdata/task-teams/training/index.cshtml), so other NSOs can realise the benefits of data science mentoring. While there was significant interest, setting up a remote mentoring programme across different countries and time zones was not without its challenges. To ensure we could run it effectively, we launched a 12-week pilot from 13 September to 3 December 2021. This involved four pairs of international mentors and mentees from various parts of the world (Ghana, Zimbabwe, Vietnam, Poland, Jordan and United Arab Emirates (UAE), coming together to add to the global development of Data Science. A graduation event was held in December 2021. National Statistician Ian Diamond, one of several high-profile speakers, offered his congratulations to the participants and expressed his support for this exciting initiative. In the final part of our [Accelerator blog series](https://datasciencecampus.ons.gov.uk/tag/mentoring-series/), we spoke to Fatima Al Taharhwa (Department of Statistics, Jordan) and her mentor Hatem El Sherif (Federal Competitiveness and Statistics Centre, United Arab Emirates), who took part in the pilot programme. Fatima tells us what her accelerator project was about: \"My project involved automating the data coding for various statistical classification activities, using Natural Language Processing and machine learning techniques. In the Department of Statistics in Jordan, we collect some data fields as text (Arabic text) such as occupation, scientific specialisation, and economic activity. These data fields must be transformed into a specific international or local standard coding. Usually, this is done manually by a specialised technical team as a one-off data cleaning and preparation stage. This process is costly, needs effort, and time-consuming. My aim was to try to automate and speed up this process by using new methods and develop the workflow.\" Remote mentoring can be challenging, particularly if there are difficulties with connections, or participants are in different time zones. Fatima and Hatem explain how they overcame these. Fatima: \"Our main challenges were time, and sometimes, the (internet) connection. It has been a challenge for both of us to find enough time to dedicate to this project. Our mentor inspired and guided us with his help and expertise. He managed to show us the easiest and most efficient path to solve some of the issues we faced and learn new techniques and tips to perform at a higher level. Flexibility from both sides meant that when the connection was bad, we rescheduled our meetings and managed to ensure we were not losing time.\" Hatem: \"Patience and realistic expectations are the key to ensuring any challenges are approached proactively, rather than worrying or stalling. We also discussed and created a solid plan with achievable goals in the timeframe given. That helped us to be clear on what we need to make our collaboration most efficient.\" Pairing mentees and mentors from different organisations can help participants gain new skills and perspectives. So, what did Fatima and Hatem get out of their mentoring relationship? Fatima: \"I am studying a data science masters and I aim to improve the work of my department using modern technologies, such as machine-learning, over some traditional methods. My department faces many challenges that make moving forward in this field difficult, despite the necessity for developing new work methods to keep up with the world, such as investing in modern technology to get the best results. Through this project, I managed to improve my skills in planning clear methodology for all stages of the project, by using professional tools like Chrisp. I discovered new open-source tools, and learnt when, why, which tool or software to choose.\" Hatem: \"It has given me great joy working with such a great and hardworking team. I am inspired by their determination and desire to learn, and pleased I managed to guide them to progress in the field. In the end, a mentor needs to guide and not drive, and this team of mentees has responded beautifully to any direction given.\" The mentor and mentee's organisations can benefit from the time they invest in the International Data Science Accelerator Programme. So how did it Fatima and Hatem's time on the programme benefit their organisations? Fatima: \"Our department learned a lot from this collaboration. We've insisted on having as many representatives from across the organisation involved in this, as it can help us develop a lot. We managed to get the right attention from our seniors, and they are now supporting us more in developing, implementing, and sustaining data science work within the organisation.\" Hatem: \"As our data department is working on becoming a regional hub, working with mentees from Jordan has created a solid bridge between the two departments. Our collaboration will continue in the future and hopefully become stronger and stronger.\" What advice do Fatima and Hatem have for colleagues and their organisations considering applying for the programme? Fatima: \"Definitely go for it! For us, it has been a great opportunity. We received so much in just 12 weeks and managed to learn a lot. It's brilliantly coordinated and provides a quality experience.\" Hatem: \"The International Data Science Accelerator Programme is a much-needed international initiative in this field. I am certain that any data science department around the globe will benefit from more insight and examples of how others are approaching, developing, and growing. Mentoring is a great way to do that - sharing experience, knowledge, and accessing a global platform where we can all help each other.\" Applications are open for the International Data Science Accelerator until 28 February 2022. The programme will start on 28 March 2022 and end on the 17 June 2022. Our dedicated [International Data Science Accelerator Programme web page](https://datasciencecampus.ons.gov.uk/capability/international/international-data-science-accelerator-programme/) has all the information you need, including the application forms for you to apply as a mentee or a mentor. You can [contact the team](International.Data.Science.Accelerator.Programme@ons.gov.uk) if you have any questions or are not sure if the programme is right for you. You can also read the other posts in our [Accelerator blog series](https://datasciencecampus.ons.gov.uk/tag/mentoring-series/). Updated 3 March 2022 Mentee applications are now open until 7 March. The deadline for mentor applications has been extended until 15 March.]]> Over the past three years, we have recruited eight level 6 data science apprentices and 12 level 4 data analyst apprentices into the Data Science Campus. More recently we have also welcomed two business administration apprentices, who are enabling teams across the Campus to deliver on their priorities with their enthusiasm and can-do approach. The apprentices have diverse career experiences and educational backgrounds. Some are school leavers who wanted to combine practical, on-the-job learning with academic study and earn a salary while studying for a degree. Others previously worked in different fields and were looking to upskill or change career paths. By bringing data science apprentices into the Campus, we looked beyond traditional hiring routes to embrace diversity. Our apprentices have brought fresh perspectives to invigorate our teams. They are a great example of how non-traditional routes can unlock fantastic long-term career options in data science and bring new talent to the organisation. The apprentices have gone from strength to strength over the past three years, taking on roles across the organisation, securing promotions and promoting the value of data science. In the last few months, the first level 6 degree apprentices have [successfully completed their degree at Cardiff Metropolitan University](https://www.cardiffmet.ac.uk/news/Pages/First-Data-Science-Degree-Apprentices.aspx). Their achievements were recognised at a celebration event, where the apprentices spoke with pride and passion about how the apprenticeship had transformed their career prospects. Their employers, including the Office for National Statistics (ONS), Welsh Government and Qualifications Wales have also benefitted from the skills and ideas that the apprentices have brought to the table. We are genuinely passionate about recognising potential and are determined to give our apprentices the best possible start to their data science careers. So how can we grow and develop the next generation of data science apprentices that can build the future? It is an area that we are highly passionate about as we believe inspiring future generations to engage in STEM subjects is not only crucial for a young person's educational development, but for the future of UK industries. It is vital to give young people the tools and information they need to make informed decisions about their future career opportunities, and to help ensure that they understand how important STEM is in our daily lives. We now have apprentices who can use their passion and experiences to inspire young people and be role models for the next generation of data scientists. During the coronavirus (COVID-19) pandemic, it has been difficult at times to think of ways to engage with the younger generation, especially from a remote working environment where school visits are not possible. In 2020 and 2021, when schools were delivering their lessons on-line and parents were home-schooling it was a very difficult time for many. So, during National Apprenticeship Week 2021, we wanted to help ONS staff by giving them some time back while we taught their children some data science. Our four apprentices developed and delivered a range of bitesize data science workshops for those aged 5 to 18 years. We were oversubscribed for the live workshops and received overwhelmingly good feedback. Today we are delighted to release these sessions as a series, available to stream at any time. To see more the series visit the [Bitesize page](https://datasciencecampus.ons.gov.uk/capability/bitesize-data-science-for-kids/) If you or your children benefit from these sessions, please share them with your schools, or other organisations that are helping to train and encourage young people through STEM subjects. Our apprentices are continuing to make a difference at the Campus, the ONS and beyond. This National Apprenticeship Week, we hope you experience their passion and desire to use data science for the public good, as they teach the next generation and build the future.]]> The programme meets the increasing demand for data visualisation mentoring and builds on the highly successful Data Science Accelerator model that has supported over 300 participants since 2015. Participants work on a data visualisation project that will benefit their organisation, with the support of an experienced mentor in the field. This increases the mentee and their organisation's data visualisation ability, but also the mentor's technical, mentoring, and coaching skills. Maria Jacob (Higher Statistical Officer at the Department for Transport) and her mentor George Wood (Data Scientist, Cabinet Office) were among the first participants on the programme. In part two of our [Accelerator blog series](https://datasciencecampus.ons.gov.uk/tag/mentoring-series/), they talk about their mentorship experience, and how the benefits of the programme are already being realised across the UK public sector. Here, Maria summarises their Accelerator project: \"I developed a dashboard to visualise and share large datasets with local authorities and their contractors. I wanted to come up with a minimum viable product which ended up using R and Shiny.\" Remote working has been the norm for many in the last two years. This can be daunting when learning and building an effective working relationship. Maria and George shared some of the tools they used to help establish their mentoring relationship. Maria: \"We used Microsoft Teams for catch ups and Github to share code. We were also able to meet in person occasionally and code together when restrictions allowed. That was a lot of fun, as well as being educational.\" George: \"Meeting in person was useful because it allowed us to do pair programming. However, most of our work was done remotely, and we shared screens a lot. Even when we were working on different things, we stayed on our Teams calls to replicate that feeling of being in a shared working environment.\" One of the biggest challenges of the Accelerator is overcoming unforeseen challenges quickly, to make the most of the limited time available. Maria and George shared how they tackled the challenges they encountered. Maria: \"Time management was my biggest challenge. Good diary management, planning my week flexibly, spreading my learning and development time flexibly over the week to prioritise other commitments, and good communication with my line manager all helped manage the demands on me. My mentor also supported me with ideas on how to manage the large dataset and how to make code more efficient. Colleagues in my department also gave alternatives on packages to help with optimisation.\" George: \"Maria's Minimum Viable Product goals for her team were clear even if the solutions to the challenges were not. Maria could have taken the easy route by using existing, familiar proprietary tools but by using R and open-source packages, she created a product that was extendable and reproducible in the long-run.\" The Accelerator programme doesn't just benefit the mentee. Even when coaching and mentoring others, mentors are learning and developing skills themselves. So what did Maria and George get out of their mentoring relationship? Maria: \"Even before the accelerator I really enjoyed coding, so this project gave me a chance to use those skills and improve them. I had no experience of Shiny or dashboarding which I thought would be useful in my current role. George also encouraged me to do what would be useful to me in my career in the long term. While I was used to coding, I was not using a lot of coding best practices, so George demonstrated how to set up code so others could collaborate with me and how to make it more readable.\" George: \"Maria was clear what she wanted out of the mentoring relationship from the start, which is really the best characteristic that a mentee can have! This was my first experience formally mentoring someone, and I've realised that I didn't need the perfect set of skills or knowledge. My previous experience combined with dedicated time on the project was enough to support Maria. She picked up new skills so quickly that I was often learning from her about how to use Shiny with large datasets. As someone with an interest in transport data, this was a great project for me to mentor on.\" The mentor and mentee's organisations can benefit from the time they invest in the Accelerator programme. So how did it benefit the Cabinet Office and Department for Transport? Maria: \"I changed roles while I was on the Accelerator, but there is already a need for dashboarding skills in my new role so my current team benefits from my knowledge on how to visualise data!\" George: \"I've started to look at how I can use these skills to train up other analysts through formal learning opportunities and building a data-oriented community within my directorate. I have also been evangelising the Accelerator throughout, so hopefully more people from my department will apply this year!\" If you're considering applying for the Data Visualisation Accelerator programme, Maria and George have some advice to help you. Maria: \"Apply for something that is really going to challenge you. That gives you the opportunity to develop the skills that are lacking in your team. For me, this was figuring out how to visualise large datasets. Our teams could create dashboards, but don't work with large datasets and hadn't developed tools that considered dataset size. The Accelerator is more than just time to do a project. You have a mentor whose experience you can use and the support of your fellow participants whose trials, errors and successes you can build on. Use all of that.\" George: \"If you want data science or data visualisation mentoring experience from outside your own organisation, the Accelerator programme is for you. As a mentor, you develop the soft skills of professionally supporting someone through listening, collaborating, and providing constructive feedback, but like the mentee, you are still continuing to develop your own technical skillset. Don't worry if you're not sure if you are technically \"qualified\". If you've worked as a government data scientist or data analyst long enough, you can help mentees - relaying your experience alone can be invaluable.\" Both Accelerator programmes are open for applications until 4 February 2022 (Data Science) and 11 February 2022 (Data Visualisation), respectively. Visit the [Accelerator page on Gov.UK](https://www.gov.uk/government/publications/data-science-accelerator-programme/introduction-to-the-data-science-accelerator-programme) for more information and to apply or [contact the team](mailto:data.science.accelerator@ons.gov.uk). The Accelerator programmes are delivered by the Campus and the [Analysis Function](https://www.gov.uk/government/organisations/government-analysis-function) on behalf of the Government Data Science Partnership (GDSP). In our final blog post we will hear from a mentor and mentee who took part in the pilot of the International Data Science Accelerator programme. It launched for its first full round of applications on 31 January 2022, adapting the successful model of the UK Data Science Accelerator programme. It is already making a significant impact on data science skills and capacity internationally. You can also read part one of our [Accelerator blog series](https://datasciencecampus.ons.gov.uk/tag/mentoring-series/), where Daniel O'Callaghan (Forestry Commission) and Sam Taylor (DWP) [talk about their mentoring relationship](https://datasciencecampus.ons.gov.uk/how-effective-mentoring-relationships-are-growing-data-science-skills-and-capacity/) and how that helped to deliver a successful data science project. The programme's success is not only down to the enthusiasm of participants wanting to learn new skills and help grow their organisation's capacity to make better use of data. It is also the willingness of experienced data scientists who take time out of their busy schedules to improve the data science skills of the public sector through coaching and mentoring. The relationship between the mentor and mentee is vital to a successful outcome, in an environment where time is limited and there can be challenges to overcome. In this blog we hear from Daniel O'Callaghan (Plant Health Economist, Forestry Commission) and his mentor Sam Taylor (Senior Data Scientist, Cyber Resilience Centre, Department for Work and Pensions) about their mentoring relationship and how it helped Daniel run a successful project for the Forestry Commission. Here, Daniel summarises his Accelerator project: \"Trade is a significant factor in the introduction of pests and diseases to trees and woodlands, so import intelligence plays an important part of the Forestry Commission's (FC's) biosecurity measures to minimise the probability of introducing pests or diseases. The project's objective was to automate the process of extracting information or data about firewood imports from shipping manifests that form part of this import intelligence work in my team. The project consisted of two parts: I used python as the main programming language, using regular expressions (regex) as the basis for extracting data from the manifests and Flask framework for the development of the app\". The coronavirus (COVID-19) pandemic has meant remote mentoring has taken place for the last 2 years, which can sometimes be daunting on a technical project. Daniel and Sam shared some of the tools they used to help their mentoring relationship. Daniel: \"A weekly catch-up meeting on Microsoft Teams worked quite well, as we could share our screens to discuss and work through topics and issues. We also made use of GitHub to share code easily.\" Sam: \"Live coding by using screen sharing on Microsoft Teams helped us to close the gap between the virtual and real world. Executable files are blocked by corporate networks which made working together on a piece of code tricky without something like GitHub so having access to this was incredibly important for this relationship.\" Even with a well-planned project, unforeseen challenges can sometimes occur and press what is already a very short timeline. Daniel and Sam shared how they tackled the challenges they encountered. Daniel: \"On the whole the project went mostly to plan. We were quickly able to write a program that allowed us to sift through the manifests and extract the data of interest. Changes to the manifests' format early in the project meant that most of the work we did on those was redundant. It took a while to get used to and understand the Flask framework which the app was developed on\". Sam: \"Despite the format of the data changing, we'd set up the project in such a way that the methodology that we were trying to implement still worked which certainly helped with the challenge that we were facing. Alongside this, we encountered data quality issues which are standard for a Machine Learning project!\" It's not only the mentee that benefits from the Accelerator programme. Mentors have told us that they learn so much through the process of mentoring. So, what were the main takeaways here? Daniel: \"I learned a lot in both learning a new programming language and the process of developing an app. I also used some old skills like HTML and CSS, something that I hadn't used since university! The weekly stand-up meetings with other Accelerator participants were really useful and insightful, as they allowed me to gain insight on other topics and issues across the public sector and data science techniques being used to tackle them.\" Sam: \"One of the reasons why I volunteered for this project was to learn something new. I hadn't done anything with PDF text extraction, so it was a good opportunity for me to expand my skillset. I truly believe that the best approach for learning is to teach something to someone else and this really pushed me to delve deeply into this topic to fully understand it\". Both the mentor and mentee's home organisations see great benefit from the Accelerator, from new tools to solve business problems, and staff being able to equip others with their new skills, increasing the data science capacity of the organisation. How did it benefit the Forestry Commission and the Department for Work and Pensions? Daniel: \"The programme has allowed me to use some of the skills I have learned to be used in other parts of my work at the Forestry Commission. The app will save a lot of time for my team, as the process of sifting through a manifest and extracting the data has been reduced to under 30 seconds. It has also highlighted the opportunities for using data science in tackling issues\". Sam: \"I'd say that the main benefit for the Department for Work and Pensions was the personal development of my softer skills. As a Senior Data Scientist, it's your responsibility to develop and mentor more junior member of your team so this is a brilliant opportunity to hone skills beyond just your technical ones.\" Are you considering applying for the Accelerator programme but not sure if it's right for you? Hopefully Daniel and Sam's experience will help you decide. Daniel: \"I would encourage anyone thinking of applying for the programme to do it. It is a great way to learn new skills, whilst delivering something useful to your department.\" Sam: \"Do It! Data Science is still very much an emerging discipline across government and as a community we have a responsibility to ensure that we're doing it in the right way, ethically and following best practice. You can play an active role in this through this programme.\" Both Accelerator programmes are open for applications until 4 February 2022 (Data Science) and 11 February 2022 (Data Visualisation) respectively. Visit the [Accelerator page](https://datasciencecampus.ons.gov.uk/capability/data-science-accelerator/) for more information and to apply or [contact the team](mailto:data.science.accelerator@ons.gov.uk). In our next blog we will hear from a mentor and mentee on the Data Visualisation Accelerator programme, and how this newly established branch of the programme is already making an impact.]]> In 2021, the Office for National Statistics (ONS) and the United Nations Economic Commission for Europe (UNECE) Machine Learning Group (ML 2021) demonstrated the benefits of international cooperation for technological advance. ML 2021 is coordinated by the ONS' [Data Science Campu](https://datasciencecampus.ons.gov.uk/)s and the [UNECE High-Level Group on Modernisation of Official Statistics (HLG-MOS)](https://statswiki.unece.org/display/hlgbas). It is a platform for international research collaboration, knowledge exchange, resource sharing and capacity building in the use of machine learning (ML) for official statistics. Established by the [UNECE in 2019](https://datasciencecampus.ons.gov.uk/ons-unece-machine-learning-2021-group/), it has quickly grown into a valuable platform for the global statistical community. The ONS took over coordination in 2021 and worked with UNECE [to expand its activities](https://datasciencecampus.ons.gov.uk/leading-international-collaboration-in-machine-learning-for-official-statistics/), with new research workstreams and the introduction of \"Coffee and Coding\" tutorials. Membership has more than doubled since January 2021 to 248 members from 33 countries, demonstrating high demand for its activities. As a result of its success, the group is now looking for new members in 2022. The Machine Learning Group aims to: Building on the group's earlier work, members conducted 18 separate projects in 2021. These projects demonstrated the added value of ML in coding and classification, and editing and imputation. The projects also explored how to tackle the challenges of taking ML solutions into production. \"Coding and classification\" was the most popular application area in this year's research of ML applications. New application areas that participants investigated included modelling for estimation and route optimisation. One study highlighted the benefit that NSOs gain from replicating ML projects from other NSOs. The workstream explored how to make the operationalisation of ML solutions smooth and efficient. It explored how to develop a user-friendly interface and how to build a data lake that data scientists can efficiently draw data from. It also produced a paper outlining typical steps that statistical organisations take from ML experimentation to deployment. High-level guidance was produced on ethical considerations that arise in ML projects to support analysts, researchers, data scientists, and statisticians. It has been [published by the UK Statistics Authority](https://uksa.statisticsauthority.gov.uk/publication/ethical-considerations-in-the-use-of-machine-learning-for-research-and-statistics/). A simulation study was carried out exploring how to identify the circumstances where an ML model should be retrained to maintain its predictive power and quality. In the 2019 to 2020 project, a quality framework was developed to compare different methods including ML. This year, a colleague from the National Institute of Statistics and Geography (INEGI) in Mexico tested the framework on a real-use case that used natural language processing to predict occupation and economic activity. The framework was used to assess the output of this project based on a standard set of five criteria: It reaffirmed the importance of having a holistic view, with quality dimension priorities varying between stakeholders at different stages of the production cycle. This year, the group has discussed and experimented on new application areas for the first time, such as route optimisation and modelling for estimation. The workstreams have also made progress on several new and under-explored production issues. These include how to obtain high-quality training data sets, how to monitor model decay once deployed, and how to develop user interfaces. The group's work has shown that ML will be essential for integrating big data into production in an efficient and accurate manner. Privacy and ethical concerns will grow as public awareness of artificial intelligence (AI) increases, so statistical organisations will also need to establish robust systems to address them. Machine learning (ML) is evolving quickly. In 2021, significant progress was made, but there are many more issues to explore before the full potential of ML is achieved within official statistics. The group will continue its work in 2022 (ML 2022), focusing on: We want to hear from anyone working in official statistics and data science communities with an interest in ML. You will receive invites to our meetings, regular updates on developments and opportunities, and access to the members-only area of our website. More information is available on [our website](https://statswiki.unece.org/display/ML/Machine+Learning+Group+2021) where you can find out more about last year's activities and [read the 2021 report](https://statswiki.unece.org/display/ML/Machine+Learning+Group+2021?preview=/293535864/337444898/ML%20Project%20Report.pdf). If you would like to join, please contact Alison Baily at the Office for National Statistics (ONS) and InKyung Choi at the United Nations Economic Commission for Europe (UNECE) by emailing [ML2022@ons.gov.uk](mailto:ML2022@ons.gov.uk). We also want to hear new ideas for activities in research, knowledge exchange and capacity building. Whether you are an ML expert or a relative beginner, we welcome proposals for activities that you could lead or organise with support from other members of the community in 2022. This can be anything from running your own research project to organising a study group or inviting an expert to give a one-off talk or tutorial. If you would like to submit an activity proposal, please [read the invitation letter and fill out the accompanying form](https://www.smartsurvey.co.uk/s/CSP3NN/) by Wednesday 19 January 2022. We aim to announce the programme and begin work at the end of January. Since 2015, the Data Science Accelerator programme has supported more than 280 public sector analysts from over 100 organisations to build data science skills through an impressive range of projects. A demand for data visualisation mentoring led to the creation of the Data Visualisation Accelerator, launched in June 2021. The Office for National Statistics (ONS) Data Science Campus and the Analysis Function partnered up to deliver this programme on behalf of the Government Data Science Partnership (GDSP*). Important dates Applications for both programmes will open again in January 2022. Data Science Accelerator Applications open on 10 January 2022 and close on 4 February 2022. The programme (project work) runs from 4 April to 24 June (12 weeks). Data Visualisation Accelerator Applications open on 17 January 2022 and close on 11 February 2022. The programme (project work) runs from 11 April to 1 July (12 weeks). The programmes are open to all UK public sector staff (including central and local government) currently in analytical roles, with an interest in developing data science and data visualisation skills. You will work on a data science or data visualisation project of your choosing for one day a week over a 12-week period. You will be supported by an experienced data science or data visualisation mentor, and you will have the opportunity to experiment with different data science techniques, visualisation techniques and open-source software. Why should I apply for the accelerator? Two recent mentees explain how the programme has helped them to learn new skills and connect with new contacts, given them new career prospects, and helped their organisation to embed data science skills. Kenneth Quan, NHS Digital said: \"My project was to develop an API to provide journey information for patients who are likely to miss their hospital appointments. The programme helped me to learn new skills in R and web scraping whilst supporting my organisation's business needs, and I am now using these skills for other projects at NHS Digital. I also had opportunities to talk to colleagues across the Civil Service and arm's length bodies, and understand how they work with projects and technologies. The knowledge has given me new opportunities in the field of data science in the public sector.\" Anthony Foster, HM Revenue and Customs (HMRC) said: \"I found the Accelerator hugely beneficial. I had a highly skilled mentor who helped me work through the project in logical steps, and suggested resources to explore when I needed to learn underpinning concepts. I enjoyed the protected on-time learning and applying that knowledge directly to the problem, rather than lecture style training. The accelerator is a highly practical approach to learning new skills, and the more effort I put in, the more benefit I got out. I'd highly recommend the programme to anyone that is passionate about analytics and is looking for a first step into understanding data science.\" Is the Accelerator for me? If you are interested in applying to either programme or not sure if it is for you, join our project clinic on Tuesday 11 January 2022. This session will be hosted by the programme delivery team and a panel of experienced mentors. It will include an overview of the two accelerator programmes, and the panel will be available to provide general guidance and answer questions on how to: To register for the clinic, please email [Data.Science.Accelerator@ons.gov.uk](mailto:Data.Science.Accelerator@ons.gov.uk). If you cannot make this date, please email your interest to be sent the slides and any additional information. Learning Programme Successful applicants will have access to the ONS Learning Hub to complete analytical and data science courses (provided by the Analysis Function and the ONS Data Science Campus) to support them with their project work. How do I apply? Visit the [Data Science Accelerator programme page](https://www.gov.uk/government/publications/data-science-accelerator-programme/introduction-to-the-data-science-accelerator-programme) to apply. You will need approval from your line manager and a senior manager/head of profession in your organisation. For more information, or to enquire about being a mentor for the programme, please contact [Data.Science.Mentoring@ons.gov.uk](mailto:Data.Science.Mentoring@ons.gov.uk). This is how Karen Bell, the British High Commissioner to Vanuatu described the impact of data science [work done by staff at the Vanuatu National Statistics Office (VNSO)](#Vanuatu). Our mentorship model has helped countries including Vanuatu and Rwanda to deliver data science projects with significant impact and created a flourishing sustainable ecosystem of data scientists. Our goal of building sustainable data science communities in developing countries, where resources are often limited, is a challenge. The [Office for National Statistics (ONS) and Foreign, Commonwealth and Development Office (FCDO) data science hub](https://datasciencecampus.ons.gov.uk/ons-fcdo-data-science-hub/) has been delivering mentorship and coaching as a technique for supporting partner countries in achieving this goal. Within international development there are many examples of ingenious and innovative data science projects. However, these projects are often driven, on a technical basis, by wealthier countries rather than the partner countries they work with. This can have several undesirable consequences: These consequences are summarised by the old adage: \"If you give a man a fish, you feed him for a day. If you teach a man to fish, you feed him for a lifetime.\" If we work with partners to develop their own skills, they can deliver the projects they prioritise themselves and maintain them internally. Many partner countries have voiced a desire for this and mentorship can help meet this need. Training programmes are effective when many individuals need to learn exactly the same thing. Training allows us to work \"broadly\", building fundamental skills for many. Meanwhile, our mentoring is focused on carefully selected mentees and their specific work objectives. What we teach is more directly relevant to their needs, but also dependent on the mentee using their own expertise to apply what they are learning. Usually, our training takes place with a group over a concentrated time period such as one week. During this time the staff are not working towards their everyday objectives, instead they are dedicated to training. Mentorship is distinct from this but complements it. The mentor and mentee agree in advance a goal for the project and the mentee's expected time commitment. Apart from that, the mentee has the flexibility to continue the rest of their day job. For example, they may meet once a week and the mentee will devote half a day a week to the project. There are many benefits to the longer-running flexibility of a mentoring project. For example, the mentee can meet and check their code, quality assure it, troubleshoot any problems they have, and receive effective project management support. In these types of coding projects, the majority of the code is written by the mentee, as they are designed to be development projects. Our mentoring projects work in an agile way. We can pause the project and restart it at an agreed time. For example, if a mentee is pulled on to urgent work, they can meet their mentor, place the work in a position where it can be easily resumed, and agree a time to check in when they can return to the project. Mentoring complements training best by bridging what has been taught and addressing practical needs. The deeper focus of mentoring is more resource-intensive than training, so the mentees and project need to be carefully selected with clear expectations established. For example, one project in Rwanda focused on developing a dashboard. The dashboard was used in census monitoring, and the opportunity gave the mentee valuable experience of the [statistical programming language R](https://www.r-project.org/), dashboards, and project delivery. Similarly, in the Vanuatu National Statistics Office, our mentees have built a [Reproducible Analytical Pipeline](https://gss.civilservice.gov.uk/reproducible-analytical-pipelines/) that reduces the time taken to produce the monthly trade statistics report from six weeks to less than one. The mentees also learned important data science skills that can be applied across projects. A critical part of a project is a mentorship agreement signed by both the mentor, the mentee, and their line managers. The agreement clarifies the project goals, expected timelines (which of course are flexible) and contact details. Here is an example of the expectations set out in an agreement: |What mentees can expect from us||What we need from mentees| |Support to deliver real projects that have genuine impact for their organisation||Agreement from management| |Regular check-in time||A flexible amount of time, for example half a day a week| |Project scoping||A clear vision, though we can help develop |Quality assurance||Enthusiasm!| |Support learning coding languages| |Project management| Passion, drive, and curiosity are more important to making the projects work than coding skills; we can teach you how to code and how to manage your projects. All of our successful mentee relationships have been driven by enthusiastic, clever, and motivated individuals. Figure 1 shows our process for creating and monitoring a mentoring project. These processes ensure that each mentoring project aligns to the needs of the mentee's organisation and are flexible to these needs. For example, in our mentoring programme with the Vanuatu National Statistics Office, our original project had weekly (early or late because of the time difference!) meetings providing basic data science training that three mentees applied to the trade statistics reporting. Our mentoring projects mimic our own project delivery. We meet with stakeholders to understand and articulate their needs. We then agree a timeframe for delivery of a first prototype addressing these needs, and then meet regularly to check in and discuss any unexpected challenges. An agile approach is critical for data science, but it is a cultural shift many institutions need support to embrace. Project scoping and deciding on what project to work on is an important part of mentorship. Often data science is presented as either a solution to all problems, or something that is too complex and difficult to use and apply. In reality, data science can deliver significant time savings on existing routine tasks, freeing up capacity to deliver new outputs and insights of use to the organisation. Successful projects have a couple of features in common; they have a clear stakeholder and they fit into the goals and mission of the organisation by clearly articulating who will use it, and what for. Our projects, and our mentees' projects, usually fall into one of two categories: Often referred to as Reproducible Analytical Pipelines (RAP), projects in this category will map out an existing workflow and look for efficiency gains. For example, automating an often-repeated task and/or streamlining a report generation process. These projects are usually very high impact; the resulting time and capacity gained can then be dedicated to training, mentorship, user engagement, or other projects. We encourage reinvestment of resources to promote the sustainable development of a data science community. These projects meet the goals of the institute that there was no capacity to deliver previously. For example, using small area estimation techniques to deliver higher resolution data for national statistics, or the use of dashboards to monitor the progress of projects like a national census in Rwanda. Projects that deliver these types of new outputs are often popular and particularly impactful for cases where a clear stakeholder has been identified. We use a variety of open-source methods, tools, and techniques across our mentorship portfolio, which are discussed and set out in the mentoring agreement. We encourage the use of git and GitHub for version control, collaborative coding, sharing code, and project management. The mentor can walk the mentee though git and GitHub if they are unfamiliar. Some countries, such as Vanuatu, have created [official GitHub organisation pages](https://github.com/Vanuatu-National-Statistics-Office) for the institute, which now function as a public portfolio of open-source projects maintained by the mentee organisation. In seeking to develop sustainable data science communities, one important principle has been that mentees, when their projects are finished, should be able to mentor others in their organisation. This \"mentor the mentor\" approach has been vital, and partners including [National Institute of Statistics of Rwanda (NISR)](https://www.statistics.gov.rw/) and [Vanuatu National Statistics Office (VNSO)](https://vnso.gov.vu/index.php/en/) have had mentees move on to mentor others in the organisation. There are several advantages to this approach. First, our ability to run projects increases exponentially. The initial project undertaken with the mentee is often aimed to free up resource (RAP, as described above). As each project is finished, more resource becomes available to undertake more mentoring, which, in turn, frees up further resource. Secondly, by having multiple people trained in data science, we build resilience and sustainability into the system. When one individual is the only competent coder in a group, there is a single point of failure. If they are sick, on annual leave, or leave for another job, it can be difficult to replace them. Having multiple individuals trained in different aspects of coding and data science means we can build resiliency and have the flexibility to have people work on different projects. Feedback from both mentees and their organisations have been very positive. Former mentees are now leading the implementation of data science projects independently and acting as mentors for others in their organisation. Improvement in capacity and capability for data science takes time. However, it leads to the sustainable embedding of ability and independence for partner countries. \"There were genuine gasps of amazement and spontaneous applause when they described how a report, which would previously have taken six weeks to produce, was now the work of a few seconds.\" This is how Karen Bell, the British High Commissioner to Vanuatu, described the impact of data science work done by staff at the Vanuatu National Statistics Office (VNSO). We initially helped three mentees automate and improve their monthly trade statistics reporting using open-source Reproducible Analytical Pipelines. The manual processes of producing trade statistics previously took around six weeks for each publication. With these new skills, mentees can now produce the report in just a few seconds. These skills have also been used to tabulate data for the National Housing and Population Census. This was the first time the census data were handled in-house. Our original three mentees are now mentoring nine others in the organisation to improve routine reporting for the market survey, consumer price index and tourism statistics. In addition, teams in other government departments are keen to learn from VNSO and apply data science tools to their own workflows. At a recent event launching Vanuatu's National Housing and Population Census data, all 12 mentees at the VNSO were presented with certificates by the British High Commissioner to Vanuatu. The certificates recognised their hard work in learning about, and promoting, reproducible data science practices across the office and beyond. The impact of this work made the [Vanuatu national news](https://www.dailypost.vu/news/2020-census-reports-launched/article_0ff3b07e-662c-5e5c-8108-4eba1abaa0d7.html), and has been recognised and applauded by members of the Vanuatu government: \"The Vanuatu National Statistics Office have been working with the UK's Data Science Campus for fifteen months. During that time, staff at the VNSO have gained the coding and analytical skills to produce in seconds a report which would previously have taken several weeks. I am proud of the dedication and hard work the VNSO team have put into the project and grateful to the UK government for their support. This partnership has delivered a genuine transfer of skills and capabilities to Vanuatu.\" Minister of Finance, Vanuatu Government Our mentoring now provides support on high-level future directions across the organisation and troubleshooting more tricky data science blockers. Read more on our [mentoring programme with the VNSO in their case study](https://unstats.un.org/capacity-development/admin-data/DetailedView/60e6f81efb05a20960dd40fe) published by the United Nations Statistics Division (UNSD) as part of their Collaborative on Use of Administrative Data for Statistics. It states: \"A small national statistics office, the Vanuatu National Statistics Office (VNSO), is making use of data science methodologies for the monthly trade statistics reports to increase efficiency, free up staff resources, and cut production time by 80%\". UNSD case study. As a model for sustainable international development, mentorship holds great potential. It requires a change in attitude from the mentor and mentee, and a considerable degree of flexibility, but has the potential to deliver significant return on investment. We aim to provide as much support to our partner countries as we can. We hope other organisations will engage in the mentorship model, and we will happily speak about our experience with anyone seeking to set up a similar programme. If you are interested in mentoring please email [Kevin Carolan](kevin.carolan@ons.gov.uk) or [Tim Harris](mailto:tim.harris@ons.gov.uk). The progamme was first initiated in 2019 when we recruited graduate data scientists into the Campus to work on research projects. Due to its success this continued for 2020 with graduates having a significant impact at the Campus and across Government, including Number 10 and HM Treasury. They worked on urgent requests during the height of the COVID-19 pandemic, and longer-term research ranging from [detecting trucks from satellites with machine learning](https://datasciencecampus.ons.gov.uk/detecting-trucks-in-east-africa/), to exploring [insights into mobility using Facebook data](https://datasciencecampus.ons.gov.uk/using-facebook-data-to-understand-changing-mobility-patterns/). Over the course of a year on the programme, graduates complete a formal curriculum created by the Data Science Campus Faculty and Analysis Function, which includes protected learning sessions three days per month. Curriculum topics range from reproducible programming practices and machine learning, to distributed computing and natural language processing. The demand for data science skills across government is continuing to grow. We are helping to meet this demand by developing early talent in data science, by both bringing in new graduates and training up experienced analysts. The organisations involved are: To celebrate the beginning of this new expanded cohort in October 2021, we ran an online induction event bringing together all participants from diverse backgrounds to introduce the programme, build relationships, and enthuse colleagues about data science. Three-day induction event The induction marked the beginning of the cohort and celebrated the significant work that had taken place across the Data Science Campus to scale up the programme. Some highlights of the sessions were the keynote speakers, including: Senior leaders highlighted what an exciting time it is for data science in the public sector, as more data is used to make decisions and inform public debate. They spoke about their experience in data, work throughout the coronavirus (COVID-19) pandemic and gave advice to the graduates. They also encouraged the participants to be curious and highlighted the opportunity they have to develop. The participants attended a question and answer session with the National and Deputy National Statisticians, asking them their opinions. Questions ranged from career experience, ethical uses of data and working with ministers. The induction week was structured to encourage participants to network and get to know one another, with informal discussions taking place alongside group work on a hackathon tackling council expenditure from open data. Colleagues in the Campus led sessions on inclusion - a core value of the programme. They also delivered sessions bringing participant well-being and reflection front and centre of the programme. It was important for the faculty team to set the tone of the programme from the beginning, fostering the best environment for everyone to get the most out of future training sessions. The talks from senior leaders showed the importance of the programme in the data capability development across government. Practical elements of the programme were shared with the participants too, laying out the communication channels that will be used, the content of the curriculum and available support. Starting the curriculum With the induction event completed, we now move on to starting the curriculum and onboarding of participants. This month, many of the participants will have joined their new organisations, settling into their way of working and preparing to work on their first projects. The first curriculum module, Data Science Foundations, has been delivered, offering a grounding in data science principles through a mix of lecturer-facilitated sessions and independent study. Feedback from the induction helped us to understand the participants' needs and preferences. When asked what they found most useful, the participants responded with a range of different favourite sessions, suggesting that the event catered for their diverse needs and interests. Programme participant Jake Marshall said: \"... I've never had a more engaging induction with no dead space or period without interesting tasks, speakers and group work to get us prepared for the year ahead! ... I surmise that if the induction was that good, I can only imagine how good the curriculum and projects will be!\" Daniel Suarez-Mash said: \"... Loved it and can honestly say it was better than any other type of induction I've had before. It ran like clockwork and I've never got to know so many people online in such a great environment with really fun activities (thanks Laura Clarke!). Looking forward to the rest of the programme.\" We are really excited for both the new recruits and those upskilling in data science, and for what they will learn from each other. We are looking forward to working closely with them to develop their skills and see the impact they make in their business areas. From a practical standpoint, we learned a lot about useful tools for online events and training, the value of co-ordinating our planning practicing delivery, and managing responsibility across several complex sessions and events. The induction highlighted to us the breadth of experience and backgrounds of participants on this programme and gave us some great insights for how to best deliver the curriculum.]]> This summer, the data science apprentices in the [faculty](https://datasciencecampus.ons.gov.uk/capability/data-science-campus-faculty/) worked with young people from disadvantaged socio-economic backgrounds, introducing them to data science and supporting them to start developing skills in the field. At the Campus, we offer opportunities to begin a career as a data scientist at every level of experience, through our apprenticeship, graduate, mentoring and masters programmes. These outreach initiatives were an ideal way to introduce data science to the participants and open their eyes to the possibility of data science as a career and how they could get started. Through two programmes of community outreach, we introduced young people to the day-to-day lives of data scientists, provided information about the different career pathways available at the Office for National Statistics (ONS), and gave insight into the skills and strengths of data scientists. We worked with the charity [upReach](https://upreach.org.uk/), and took part in the [EY Foundation](https://eyfoundation.ey.com/uk/en/home.html) Tech Smart Futures programme organised by the [Digital, Data and Technology](https://www.gov.uk/government/organisations/digital-data-and-technology-profession/about) (DDaT) profession within the ONS. [UpReach](https://upreach.org.uk/) is a charity that offers career support to undergraduates from less-advantaged backgrounds. Students from working-class backgrounds who achieve a first-class degree from a Russell Group university are less likely to enter a high-level occupation than students from privileged backgrounds who achieve a 2:2 degree from the same university. UpReach aims to close that gap. For example, their [Tech500](https://upreach.org.uk/news/upReach-and-the-Hg-Foundation-announce-major-new-partnership-to-boost-opportunities-for-disadvantaged-students-to-access-careers-in-the-technology-sector) programme provides comprehensive training, networking, and career support to 500 undergraduates interested in pursuing careers in tech. To support upReach's activities, we delivered two workshops, one for around 40 undergraduates interested in careers in the public sector, and another for around 40 Tech500 participants. Our Head of Talent [Alison Adams](https://datasciencecampus.ons.gov.uk/author/alison-adams/) gave an overview of career pathways through the ONS and schemes such as the [Graduate Programme](https://datasciencecampus.ons.gov.uk/capability/data-science-graduate-programme/) that provide an entry point for budding data scientists. Data Science Graduate Tom White shared his experience of the programme, giving the students a taste for life as a data scientist and advice for applying for the programme. Finally, Data Science Apprentice Mia Hatton discussed skills for data science, signposting useful resources and some examples of our projects. This section was interactive and encouraged the students to get involved in activities such as Google's [Quick, Draw](https://quickdraw.withgoogle.com/) and [Teachable Machine](https://teachablemachine.withgoogle.com/). We were delighted to hear from upReach that the feedback for these sessions was very positive, with 100% respondents rating the session Very Good or Excellent. Some of our favourite comments were: I learned a lot more about ONS as well as data science which I will now research further as I am intrigued by data scientist roles! Great insight into the stats office! The [EY Foundation](https://eyfoundation.ey.com/uk/en/home.html) works with young people from disadvantaged backgrounds. It aims to help them reach their career ambitions and transition into work, higher education or self-employment. DDaT arranged for the ONS to be involved in their Tech Smart Futures initiative, a 10-month long programme for 16- and 17-year-olds that includes paid work experience and employability skills training. We hosted a total of 9 interns, split into groups of 3 for two days each. Each group divided their time at the campus between training and applying what they had learned to a group task. In training, we introduced them to Python and how it can be used to process data. We also delivered an introduction to machine learning with interactive activities. The group work required them to apply their new Python skills by exploring a World Health Organisation (WHO) dataset and delivering a presentation about their findings to the facilitators. The highlight for many of the interns was a data ethics discussion in which we asked them to consider the benefits and risks of AI. We were lucky enough to have colleagues from across the campus visit the interns and give them valuable advice for pursuing a career in data science. We had wonderful feedback, with all the interns appreciative of the opportunity to see what it's like to work in tech from home and said that it was an \"amazing experience\" that allowed them to develop skills and knowledge in Python and machine learning. (And as a bonus, they came away knowing more than when they started!) Between these two streams we were able to offer short-term skill support for many participants as well as more comprehensive work experience for a smaller number of people. Many of them expressed interest in data science in the public sector because of their experience. We are delighted that we have sparked enthusiasm for data science and hope to see some of the participants again - next stop, Graduate Programme? We would like to thank Alison Adams and Tom White for supporting delivery of the upReach workshops, as well as Darren Weeks from the DDaT group for giving us the opportunity to get involved in the EY Foundation programme. If you have been inspired to run a similar outreach programme, you can view the training materials we used for the EY Foundation programme on [Kaggle](https://www.kaggle.com/miachatton/eyf-resources), and engage with the faculty's training materials on [GitHub](https://github.com/orgs/datasciencecampus/repositories?q=DSCA_&type=public&language=&sort=). For more information or to discuss outreach opportunities, please [contact the Data Science Campus](mailto:datacampus@ons.gov.uk). ]]> Mia Hatton and Georgina Dangerfield, Data Science Apprentices, Data Science Campus Faculty Building on the success of this work, we realise there may be potential for such data sources to enhance our statistics in the future. In this guest blog, Robyn Hunt from the Office for National Statistics' (ONS') travel and tourism review team looks at the use of O2 Motion crowd movement data to model estimates from the International Passenger Survey (IPS) as part of a wider [review of the ONS' travel and tourism statistics](https://www.ons.gov.uk/peoplepopulationandcommunity/leisureandtourism/articles/travelandtourismreview/october2021). A review of the ONS' travel and tourism statistics was started in response to recommendations from the Office for Statistics Regulation (OSR) made in October 2019, highlighting that our statistics did not sufficiently meet users' needs. Key issues reported included timeliness, accuracy and level of disaggregation as well as poor levels of user engagement. In early 2020, the coronavirus (COVID-19) pandemic and associated travel restrictions led to the suspension of most surveys used to estimate different components of travel and tourism industries. As a result, alternative sources of data that could be used to produce those estimates were sought, and travel and tourism statistics were published based solely on administrative data and modelling (as seen in [Overseas travel and tourism, provisional: April to June 2020](https://www.ons.gov.uk/peoplepopulationandcommunity/leisureandtourism/bulletins/overseastravelandtourism/apriltojune2020)). This approach builds on a transformation mindset across the ONS to improve our statistics by: In this article, we present and analyse aggregated and anonymised mobile phone data from a single network provider, for both inbound (foreign residents visiting the UK) and outbound (UK residents travelling abroad) tourism. The mobile phone data for inbound tourism consists of anonymised aggregated counts of foreign sim cards which are connected to the given network in the UK in a specified time period and is provided to us in an aggregated format across three variables: The aggregate count for outbound tourism is given as an expanded count, where the number of mobile phones detected has been weighted such that it represents the UK population. This weighting has been done by the provider before aggregating the data. The expansion process is not applicable to inbound tourism since the necessary weighting breakdowns, such as population and demographic information, associated with foreign residents is not presently available. The outbound tourism data has a similar structure to the data for inbound tourism, namely: Any combination of these three variables with fewer than 10 people are removed because of disclosure control, in order to ensure that no individual can be identified. As part of the travel and tourism review, we have access to weighted record-level data from the Office for National Statistics' (ONS) [International Passenger Survey (IPS)](https://www.ons.gov.uk/surveys/informationforhouseholdsandindividuals/householdandindividualsurveys/internationalpassengersurvey) which we have aggregated by month of UK departure and country of residence (for inbound tourism), or by month of UK arrival and travel destination (for outbound tourism). These weights are derived from a sample that is representative of the population of passengers. Since the sampling design for the IPS is optimised for quarterly estimates, monthly is the smallest time period we can aggregate at to maintain sufficiently narrow confidence intervals. To conduct equivalent comparisons between the IPS estimates and the mobile data, we have further aggregated the mobile data which was provided from weekly to monthly departures. Aggregation was additionally applied by country of residence (assumed to be the same as the country in which the sim card is registered) for inbound tourism comparison, and by destination country for outbound tourism estimates. We have access to aggregated mobility data from October 2019. Our analysis is therefore limited to a time-window of five months before the IPS was suspended because of the coronavirus (COVID-19) pandemic in mid-March 2020, for which we have both mobile and IPS data for comparisons. To examine the number of foreign visitors to the UK, we compared an absolute count of visits from the mobile phone data, which has partial population coverage, to the weighted estimate from the International Passenger Survey (IPS). A universal scaling factor of 2.97 which approximately corrects for this partial coverage was applied to the absolute mobile data counts based on a least-mean-squares best fit between the mobile data and IPS estimates for visitors from individual countries per month, so that trends can be compared more easily. The month of travel was based on the data collected for departures (at the end of the trip) for both datasets. We compared overall trends in the data as well as relationships for smaller groups of countries (based on geographical proximity). Errors have been estimated based on the sample design for IPS data, but unfortunately, since the mobile counts are summed directly, no estimate of variance can be calculated. Figure 2: The percentage change in the number of foreign residents (relative to the mean number of travellers over the same time period) from smaller country groups visiting the UK, as estimated by the IPS from month to month between October 2019 and February 2020, compared with traveller counts from mobile phone activity The relative changes in number of visits from month to month estimated from the mobile and IPS data, seen in Figures 1 and 2, are very similar at the overall level and when looking at groups of countries. There are some exceptions to this, for example, the group consisting of France, Belgium, and Luxembourg. The coverage of travellers from this group appears to be very small and different trends are seen in IPS and mobile data. In Figure 3, we can see that the difference between the total number of travellers derived from the IPS and the total number of travellers from the mobile data varies between country groups. Whilst estimates from the IPS and from the mobile data are similar across most areas of Europe, the mobile data indicates that more travellers are coming from Asia, Africa and the Middle East, and the USA compared with estimates derived from the IPS, whilst the opposite is true for travellers from France, Belgium and Luxembourg, South/Central America and Canada, and from Oceania (Australia, New Zealand and South Pacific islands). These discrepancies could likely be corrected by constructing specific weighting factors rather than applying a universal scaling factor, by researching and correcting for sources of bias in the coverage of travellers from individual countries within these groups and more detailed demographic information for travellers with mobile phones. However, this process is complex and the information necessary to calculate these weights is not readily available. For analysis of travel patterns for UK residents travelling abroad, a similar approach was taken to that for inbound tourism. This time, we compared a weighted estimate from mobile data (mobile contract holders weighted to UK population) to a weighted estimate from the International Passenger Survey (IPS) rather than a raw count of phones detected. For reasons similar to those described for inbound tourism, a universal scaling factor of 1.53 was applied to the mobile data using a similar fitting procedure. The month of travel was based on the data collected for arrivals (at the end of the trip) for both datasets. The results from this analysis were similar to those seen in the comparisons for inbound tourism. Again, relative trends of the number of visits abroad from month to month are consistent between the two data sources both overall and in country groups. Generally, the difference between the IPS and mobile estimates per group is much smaller than those seen for inbound tourism. This is likely because of weighting being applied to the mobile data which corrects for some of the variability because of demographics and coverage bias. The most obvious gap in mobile coverage is for Oceania, where we have almost no data and the estimate of travellers to Oceania from the IPS is very small. Some hypothesised reasons for this include the considerable travel distance and high mobile roaming charges; travellers to this area of the world are likely to stay for extended periods of time and may purchase a local sim card rather than using their home-registered SIM for the duration of their stay. However, it is not currently feasible to determine for certain the exact reasons for the differences between estimates. The most noticeable differences between mobile data and IPS are observed for January and February 2020, where IPS is higher in January and mobile data is higher in February. This work forms a small part of alternative data investigations for the travel and tourism review in the Office for National Statistics (ONS). We hope to further develop this work by combining the mobile data with other types of mobility or administrative data. We aim to use small area estimation techniques to break down International Passenger Survey (IPS) estimates for passenger counts for visits to UK regions with greater accuracy. Additional information on the review can be found in our [travel and tourism review article](https://www.ons.gov.uk/peoplepopulationandcommunity/leisureandtourism/articles/travelandtourismreview/october2021), [methods paper](https://www.ons.gov.uk/businessindustryandtrade/tourismindustry/methodologies/travelandtourismreviewmethodologicalresearchprogressupdate) and [consultation](https://consultations.ons.gov.uk/external-affairs/proposedfutureapproachtomeasuretravelandtourism). Our consultation into the proposed future approach to measure travel and tourism opens on 5 October and closes on 21 December 2021. In September 2019 we started discussions with Statistics Canada to understand how we could help them support data science skills building in the Caribbean Community through this initiative. The decision to work together on this programme was made following presentations from the Office for National Statistics (ONS) Data Science Campus at the Commonwealth Heads of Statistics conference in London in 2018. Statistics Canada saw that the ONS had a uniquely strong capability in data science and would be a great partner in delivering their programme's objectives. Before the coronavirus (COVID-19) pandemic, we planned to send a Campus Faculty lecturer and Statistics Canada staff member to Barbados to deliver an intensive week of data science training, with project and mentorship support being provided for the following three months. However, the onset of the pandemic dealt a cruel blow and these plans were paused for some time. As remote working became the norm, we revisited our discussions, revised the learning needs and discussed a virtual training programme. Through wider discussions with Caribbean National Statistics Offices (NSO), we agreed on a Reproducible Analytical Pipeline Learning (RAP) pathway in R. The Data Science Campus faculty team were aware of the unique challenges of remote delivery to international stakeholders, having delivered remote training to countries such as Rwanda and Kenya. We set up contingencies to mitigate poor connection and training accessibility. This included a dedicated Slack channel for peer and trainer support. We also recorded the lectures and made these available after the course. Armed with these remote technologies we set off ready to deliver to Caribbean National Statistics Offices across five time zones. There is an old adage in data science and software development that there are always at least two people working on a project - you and future you. The problem is that past you does not answer emails! Think about the last project or report you worked on. If your computer died and you lost the final report, how long would it take you or a colleague to reproduce the report? The answer depends on your response to these questions: Our diagram illustrates the current process many of us use in managing our projects or reports. Parts of the analysis are carried out in different software packages, multiple copies of the file and documents may be made, several emails containing copies of a report are sent between members of the team, and different parts of the analysis (plots, statistics, and images) are added to along the way. All this results in a complicated analytical maze that not even Hansel and Gretel's digital breadcrumbs can be used to retrace. Reproducible Analytical Pipelines (RAP) are becoming a more commonly used technique in the analytical space to create more robust and reproducible workflows. RAPs are reproducible frameworks that can be used to design and manage effective workflows with the potential to save NSOs hundreds of hours and thousands of pounds. There are a number of examples of successful RAP projects across government including at the [Centre for Crime and Justice](https://gss.civilservice.gov.uk/blog/the-nature-of-rap/) and the [Ministry of Housing Communities and Local Government (MHCLG).](https://dataingovernment.blog.gov.uk/2020/03/24/rappers-delight/) One of the main benefits of a RAP is that we can repeat our work easily and quickly. It is not reliant on a single individual, not even our past selves! The original data is never edited. The data processing and report production occur in one place. There's one version of the file and the steps are tracked and recorded from start to finish. It's fast and automated but not without sense checks. It's transparent and promotes trust because all steps are tracked and recorded from start to finish so that anyone can reproduce your results. The UK government has been a leader in promoting Reproducible Analytical Pipelines, [with RAP Champions.](https://gss.civilservice.gov.uk/about-us/champion-networks/reproducible-analytical-pipeline-rap-champions/) The RAP champions come from different departments across government and offer support and knowledge sharing for reproducible analysis. But how exactly do you teach Reproducible Analytical Pipelines? The Data Science Campus RAP learning pathway is designed to take coding novices through the essential building blocks needed to transform their existing workflows (which could be carried out using a combination of multiple tools such as STATA, SAS, Excel, Microsoft Access, and/or word) into a fully reproducible analytical pipeline in the software R. The aims of the course were for students to develop a reproducible mindset, become familiar with open source tools and best practice, and to build skills in: Artwork by @Alison_horst In total, 21 statisticians from 12 countries in the Caribbean took part in one of two course streams: Each National Statistics Office was invited to submit a project for the RAP course. Each team was supported by a mentor and each module was followed by a hands-on workshop where participants apply what they've learned to their project and problem-solve together. The courses paired traditional lectures with hands on workshops and project mentoring, helping participants to directly apply what they have learned. Each lesson was designed to help students meet key project milestones including importing and cleaning their data, creating graphics and tables, combining text and code into a reproducible report and adding unit tests. The hands-on workshops were designed to give participants the opportunity to bring their own data and problem solve together. One of the hardest skills to teach beginners is how to debug code, as programming error messages are notoriously difficult for beginners to decode. We incorporated plenty of opportunities for live coding to help normalise mistakes and allow students to see the problem-solving process in action (Wilson and others 2020). The hands-on workshops also allowed us to fill gaps in the curriculum and focus the content around the participant's projects. Shortly after receiving the proposals, we realised that many of the project reports included tables which were not covered by the planned courses. We were able to adapt the learning to include a short tutorial on creating tables using kableExtra in R. Students completed the pathway by applying their learning to their own project. At the start of the course, they had selected and presented a broad range of RAP transformation projects. These projects included producing quarterly trade bulletins to annual reports on vital statistics, labour force and household expenditure surveys. Details of the organisations pre-existing workflows were also provided. The mentoring process offered the lecturers insight on what subject matter had been readily assimilated by the student and which areas learners needed more support in. Mentors practised their coaching skills by assisting their mentees towards effective implementation of their skills, offering reproducible examples and scaffolding so mentees could effectively apply their learning. The trainee from Trinidad & Tobago directly applied her learning to her project, creating quarterly trade aggregates for her country's region by sector. The final pipeline will allow the National Statistics Office to automate the production of publication-quality data tables for reporting purposes. This automation will result in significant time savings for Trinidad and Tobago for future reports and in minimising human-error. The trainees from Belize incorporated the \"visdat\" and \"janitor\" packages in their Labour Force Survey dashboard to visualise missing data and check for inconsistencies. Since the course, they have been developing a [series of R tutorials](https://gaguilar2015.github.io/gaguilar2015/) for the Labour Force Survey team at Statistics Belize. Although many of us would happily swap winter in Canada, Wales, and Scotland for Barbados, moving to remote delivery during the pandemic allowed us to deliver training and support over a longer timescale. This gave students the extended support to gain these new skills and to integrate what they have learned gradually into their workflow. In their feedback, many of the participants found the recordings of the sessions beneficial as they provided an opportunity to go back and review what was taught at their own pace. If you are keen to develop your own Reproducible Analytical Pipeline, check out some of these helpful resources: Get involved in the UK government RAP champion network [here](https://gss.civilservice.gov.uk/about-us/champion-networks/reproducible-analytical-pipeline-rap-champions/). The [Office for National Statistics (ONS) and Foreign, Commonwealth and Development Office (FCDO) data science hub](https://datasciencecampus.ons.gov.uk/ons-fcdo-data-science-hub/) has been developing faster indicators of economic activity in UK [official development assistance (ODA)](https://www.gov.uk/government/publications/official-development-assistance/official-development-assistance) countries to support their response to the coronavirus (COVID-19) pandemic. Building on earlier [Faster Indicators projects,](https://datasciencecampus.ons.gov.uk/tag/faster-indicators-of-uk-economic-activity/) we set out to explore more timely estimates of economic activity using novel data sources, including automated identification systems (AIS) ship signals, Google Search Trends and open-source satellite data. One area we have been exploring is the use of 10 metre resolution satellite data from the European Space Agency's Sentinel 2 satellite to monitor changes in road traffic in ODA-eligible countries. Tracking the flow of traffic at a higher granularity could provide insights into economic activity in countries where road sensor or traffic camera data are not widely available. As well as understanding domestic and international trade, the methods we create could also be used to estimate emissions from road transport, providing vital data in tracking progress towards greenhouse gas emissions targets. Our truck detection work followed from [a project](https://www.esa.int/ESA_Multimedia/Images/2020/10/Truck_detection_using_data_from_Copernicus_Sentinel-2) by Henrik Fisser, an MSc student at the University of W\u00fcrzburg, which won an [Sentinel 2 hub innovation competition](https://www.sentinel-hub.com/develop/community/past-contests/#results-of-the-covid-19-custom-script-contest) for detecting reductions in road traffic following lockdowns in Germany and the Netherlands (Figure 1). The Sentinel 2 satellite captures the blue, green and red light from large moving vehicles at slightly different times, meaning when these light channels are combined each truck is seen as a \"rainbow\" sequence of pixels. Where these rainbow signatures are present against the background road, a large moving vehicle is very likely to be present. Traffic conditions in developing countries are different from those in the Netherlands and Germany. Therefore, we adapted the original work, developing our own methods for extracting Sentinel 2 images masked to road using open street map, engineering new image features and using random forest classifiers to estimate vehicle counts. Source: [hfisser github page](https://github.com/hfisser/Truck_Detection_Sentinel2_COVID19) We developed our method using two locations for predicting truck counts: The M1 was chosen due to availability of reliable [road sensor network data](https://webtris.highwaysengland.co.uk/) from Highways England to validate predictions. These data are disaggregated into vehicle size classes, so any vehicles under 5.2m were considered unlikely to be a commercial truck. Kenya was chosen due to our existing relationships with the [Kenya National Bureau of Statistics](https://www.knbs.or.ke/) and [Trademark East Africa](https://www.trademarkea.com/). Other advantages of the chosen location in Kenya were the availability of vehicle weighbridge data for ground-truthing and the road's position near the port of Mombasa, a major hub of trade into East Africa. We extracted open-source Sentinel 2 images for areas of interest for the full range of image dates available, which began in 2017 for the UK and 2019 for Kenya. Images were extracted in three of the bands available from the [Sentinel 2 surface reflectance collection](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR); These were chosen as they best distinguish trucks against the road - as a sequence of blue, green and red pixels against a grey/brown background. Additional bands for cloud probability and cloud shadow were extracted using the [Sentinel 2cloudless](https://developers.google.com/earth-engine/tutorials/community/sentinel-2-s2cloudless) algorithm from the Sentinel hub. The cloud probability band was used to mask out pixels above a threshold probability of 0.25 of being either cloud or cloud shadow. This threshold was chosen to balance the risk of more false positives generated by cloud edge at higher thresholds, and too much of the image being masked out at lower thresholds. To explore features and validate the model predictions made with the Sentinel 2 images, we manually labelled the blue, green and red pixels of each truck in image for 10km stretches of road in the UK (the M1 motorway) and two locations outside of Nairobi, Kenya (Figure 2). These data have many more non-truck pixels than truck pixels. This class imbalance was an important consideration when designing our classification method, as it can bias our evaluation of model performance. Our initial approach used an unsupervised classification algorithm directly in Google Earth Engine. This method uses hard-coded thresholds for hue, saturation, and brightness to automatically cluster images into truck or road pixels without prior labelling by eye. This generated predictions for whole countries very quickly, however it resulted in many false positives in cloudy images, due to the refraction of light at the edge of clouds producing a rainbow effect which was being misidentified as a truck (Figure 3). To develop an understanding of the truck effect, we engineered a set of features in the spatial and temporal dimensions to use in a supervised learning pipeline. The absolute colour of the truck pixels changes across time and space due to variability in weather, seasonality and terrain. For this reason we used the relative colour values (i.e. the ratio of red to green rather than red value) to distinguish truck pixels from road pixels. Exploratory analysis of labelled truck pixels confirmed that the derived colour ratio bands showed stronger signals both across the time series in the pixel locations where trucks were present. For example, the red truck pixels show a stronger peak in the red to green band than the red band (Figure 4a). The colour ratio bands also showed a stronger signal between truck and non-truck pixels within specific imaging dates (Figure 4b). To improve the ability of our model to distinguish truck from non-truck pixels, we wanted a feature to capture the colour of a truck pixel relative to the mean colour over all dates in that pixel location. This is because each pixel corresponds to the same location across images and for any pixel location it is very unlikely that more than one imaging date will have a truck present. To detect this temporal signal, we created a composite mean image from all rasters in the time series and subtracted the temporal mean values for each feature from the feature values in a specific date, giving a 'subtracted' image. Finally, we calculated a [Z-score](https://www.statology.org/interpret-z-scores/) for each pixel within this subtracted image: \\(\\) \\( Z = \\frac { x \\, - \\, \u00b5 }{ }\\) Where x is the pixel value in the subtracted image, \u00b5 is the mean value across all pixels in the subtracted image and is the standard deviation across the subtracted image. Some images can be brighter or darker so without the Z score, all pixels in an image at a given date could be much higher or lower than the temporal mean and this would not be a useful measure to highlight the trucks (Figure 5). A crucial property of the truck effect is that the blue, green and red pixels are connected within a limited kernel space of a few pixels, so we created a feature which extended a small kernel from each pixel and recorded the most green and the most red pixels. We then elaborated on this to look for max R:G and G:R Z-scores, thereby capturing the temporal and spatial dimensions of the signal. This works by expanding a kernel of a few pixels outwards from each pixel in the G:R Z-score band (Figure 6.1), finding the local maxima (Figure 6.2), creating a mask from a small kernel surrounding the max G:R Z-score pixel (Figure 6.3) and using this to mask the R:G layer and find the max R:G value from the unmasked pixels (Figure 6.4). We then derived these features in the labelled training data to train [random forest classifiers](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier) from the python scikit learn package. We chose random forest classifiers as they produced higher F1 scores than logistic regression and support vector machines. We assessed model performance in predicting trucks from unseen dates by running a temporal cross validation; in each iteration of the train-test split, a different set of dates from the full series was used to train the model. We compared results using different origin of training data, old or old and new features included and either a low (1:10,000) or high (1:10) ratio of truck to non-truck pixels included in training data. Under sampling the majority class in imbalanced data can improve predictive performance of the minority class. To fit the model we would use on our new area of interest, a 100km stretch of road outside of Mombasa, model performance was measured on predictions for a combined training set of both locations in Nairobi with [precision-recall area under the curve scores](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#:~:text=The%20precision-recall%20curve%20shows%20the%20tradeoff%20between%20precision,recall%20relates%20to%20a%20low%20false%20negative%20rate.) (PR AUC) calculated using [stratified K-fold cross validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) to ensure the class ratio was kept the same across folds. PR AUC visualises the trade-off between precision and recall for different probability thresholds of classification. PR AUC scores are advised over ROC AUC scores when using highly imbalanced data. After model predictions, we further calculated counts which were corrected by % cloud, so images with more cloud cover had boosted counts to compensate for lost image area: \\(Cloud \\, weighted \\, count = {predicted \\, count} \\left( \\frac {100}{ 100 \\, - \\, percentage \\, cloud }\\right)\\) To scale up the process, we modified the pipeline to split each image into small tiles, which allowed feature generation and modelling to be run in parallel, allowing us to make predictions for 100km stretches of road within a few hours. Although the Sentinel 2 mission takes images at each location at frequent (five to ten day) intervals, in many countries the roads are obscured by cloud on many days in the year. This limits the number of images on which models can be trained and tested. The low resolution of the images (roughly 10 metres per pixel) means the truck effect can be hard to distinguish. Light refraction at cloud edge produces a rainbow effect which can be misidentified as a truck. To address the issue of false positives generated by cloud edge, we coded a 100 metre buffer around the cloud pixels in the cloud masking process. For all dates in Mombasa, this reduced the Pearson's r correlation between % cloud pixels and truck probability from 0.63 to 0.005, and between % cloud pixels and cloud-weighted count from 0.33 to -0.04. The Sentinel 2 2A product was only available as an operational product in Kenya from the end of 2018. The weighbridge data for the same location were also limited due to intermittent failure of the automatic sensor leaving few dates with intersecting satellite images and weighbridge counts to compare (n=30 dates with intersecting Sentinel 2 and weighbridge data). Including our newly engineered features improved model performance in the two manually labelled locations in Nairobi but did not improve performance for the labelled M1 location (Table 1). |Location||Features included||Class ratio||Number showed that models performed poorly when a low ratio of truck to non-truck pixels (1:10,000) was used (Figure 7a), but PR AUC scores improved substantially when the road pixels were more heavily down-sampled in the training set (Figure 7b). However, when using this model to make new predictions on the longer 100km section of the same road from Mombasa, visual inspection of shapefiles indicated that a more heavily down-sampled model produced more false positives than models fitted to less balanced training data (Figure 8). This suggested heavily down-sampling was leading to overfitting. We tested how informative our predictions were by exploring whether we could see the expected drop in truck activity due to COVID-19 lockdowns. For a 100km stretch of the M1 motorway in the UK, we see a sustained drop in truck counts following the first national lockdown on 26 March, until the easing of restrictions is announced on 23 June. From this point, truck counts steadily increase until the announcement of Tier 4 restrictions around Christmas, followed by another sharp drop when the third national lockdown is announced (Figure 9). We then compared our predictions to established data for vehicle traffic from automatic sensors. For the M1, Highways England data were given for different classes of vehicle size. From 2020 to April 2021, the strongest correlation was with the smallest vehicle class (Table 2a), suggesting our method was performing best with smaller commercial vehicles on the M1, as shown in Figure 10a, and smaller trucks in Kenya as shown in Figure 10b. This is probably because the volume of the more numerous small vehicles was more heavily affected by lockdowns and restriction easing than commercial trucks, so there is greater signal in the change of small vehicles than large trucks over the pandemic, despite smaller vehicles being individually harder to detect. On the M1, predictions are highly correlated with predicted counts (Spearman's r=0.66) and cloud-weighted counts (Spearman's r=0.88), suggesting unresolved issues with cloud and cloud shadow generating false positive. |% cloud||0 - 520 work showed how Sentinel 2 imagery can be used with feature engineering and supervised learning methods to estimate traffic volumes on roads. Although our method was able to detect large changes to road traffic, such as the impact of lockdowns and easing of restrictions since the Covid-19 pandemic started, these methods are not robust enough to provide closer-to-real-time estimates as an alternative to traditional, sensor-based methods for road traffic estimation. We can attribute the low correspondence to scarcity in the ground-truth data for Mombasa, gaps in imaging due to cloud cover, correlation of M1 predictions with cloud and cloud shadow and ambiguity in the truck-effect. Access to ground truth data with better coverage and quality in developing countries, and improvements to the cloud shadow masking process are required to go forward with this project. While our method did not provide a clear solution for the intended use-case, processes developed in geospatial processing and classification of open-source sentinel 2 data could be used in a range of future data science projects and learning resources. For example, we have adapted the model fitting and evaluation scripts into a short course on supervised machine learning for next year's cohort of [graduate data scientists](https://datasciencecampus.ons.gov.uk/capability/data-science-graduate-programme/) at the Campus. A key lesson learned from the project is that working with novel data sources and methods requires planning evaluation from the start. Ensuring maximum coverage and quality of ground truthing data and identifying pitfalls in these data early on will determine whether the utility of new methods can be demonstrated effectively. Please get in contact with [Ruben Douglas](https://datasciencecampus.ons.gov.uk/author/ruben-douglas/) to discuss this project including any ideas for future applications. You will lead or work within multi-disciplinary delivery teams and collaborate with others in government, industry, academia, and charities, both in the UK and internationally. You will research, design, build and improve digital and data products. You will also contribute to building capability in data science through research, mentoring and training. The presently advertised roles will place candidates in a team using data science and analysis to deliver insights about population mobility and its interactions with economy, environment and society. However, we encourage applications from those interested to work in other areas of the Campus or wider ONS. A reserve list of applicants will be held for up to 12 months and may be used to fill any vacancies that arise in other teams. Data Scientists / Analyst (appointed at the Civil Service grade of Senior Executive Officer) are proficient in data science and/or data modelling and analysis. They have recognised ability in a number of data science specialisms and provide detailed technical advice on their area of expertise. They draw on other technical and analytical standards from across government and industry. They promote and present data science work both within and outside of the organisation. They engage with stakeholders to demonstrate the value of data science and propagate data science skills in other teams. They line manage and mentor Junior Data Scientists. As a Data Scientist/ Analyst with the Data Science Campus you will: Work as part of a cross-disciplinary team to deliver ground-breaking data science projects in population mobility; you also contribute in one or more of other core Campus themes: the economy, the environment, society. Deliver innovative data science for the public sector, exploring and applying new data sources, tools and techniques or approaches to meet our clients' needs, and using your coding and analytical skills. Develop software tools, hardware infrastructure or data products that exploit state of the art research to place technology in the hands of the operational users. Use Agile project delivery methodology to deliver effectively and efficiently. Ensure work delivers value by understanding and addressing user needs. Write and publish code to quality standards. Contribute to technical reports, working papers, and journal articles. Develop and deliver regular statistical or analytical outputs. There may be some line management associated with these posts. Some travel to other Campus and Government locations will be required at both grades. Although remote workers will not be attached to an office location, there is an expectation that you will occasionally attend meetings or other activities on-site. Person Specification Essential skills criteria and experience: For each of the criteria below we will assess you for significant experience. Please ensure that you provide as much evidence as you can of your skills and experience in the following: Data wrangling skills and experience. Data analytics - such as supervised and un-supervised machine learning (including deep learning). Experience in at least some of the following areas: natural language processing, image processing, geospatial analysis, econometrics and regression, microdata, network analysis, agent-based modelling, time series analysis, causal inference, data fusion. Storytelling and data visualisation - including the visualisation of insights drawn from data and the building of data driven products. Good knowledge and experience of coding in Python and/or R. Scientific research methods - analytical, critical, and curious analysis of data or modelling, ability to master the scientific literature, a track record of high-quality publications. A track record of delivering data science projects on time, to meet user needs, and overcoming any challenges. A demonstrable commitment to developing your knowledge and expertise as well as that of others. Experience of delivering statistical or analytical outputs to quality standards Ability to read and write code in Python and/or R. Desirable skills criteria: Data Science is an intensely multidisciplinary practice with a continually evolving skill set. You should be able to demonstrate ability and experience in at least one of the following areas. We do not expect any one person to cover all the skills. Assessments will be based on the breadth and depth of your experience. Visualisation knowledge and experience with: dashboarding, some experience in D3 and other Javascript visualisation libraries, technologies for web app creation (HTML, CSS, React, Vue, Dash, Django Flask). Software knowledge: version Control, cloud programming experience (BigQuery, cloud functions etc.), additional experience with other programming languages (Julia, Matlab, Javascript and other low & high-level languages). Data management/curation - such as the manipulation and analysis of complex, high volume and high dimensionality data, distributed processing, relational and non-relational databases, cloud storage and data management, interoperability and standardisation for data, metadata management, knowledge of UK datasets. Data engineering - such as the design of algorithms, implementation of big data solutions, multi-core/distributed processing, SQL and NoSQL database systems, statistical analysis languages and tooling. Qualifications: There are no strict qualification requirements. We encourage applications from people without formal qualifications, but with equivalent working experience. We also welcome applicants with a good degree, or equivalent, that includes components related to data science, computer science, or software engineering. This might include, but is not limited to, the following subjects: mathematics, statistics, computer science, data science, geospatial science, physics, economics, econometrics, chemistry, biology, and ecology. We are also interested in applicants with a higher degree (for example, MSc or PhD) in a related subject. We'll assess you against these behaviours during the selection process: We'll assess you against these technical skills during the selection process: There were estimated to be 12,000 new HIV infections per year in Cote d'Ivoire in 2019 and although overall rates are [steadily declining](https://www.unaids.org/en/regionscountries/countries/ctedivoire), levels [remain high in adolescents and young people](https://data.unicef.org/wp-content/uploads/2019/11/HIV-snapshot-WCAR_2019.pdf). HIV risk is driven by a complex range of [socio-economic factors](https://www.who.int/news-room/fact-sheets/detail/hiv-aids) and access to the effective testing and treatment remains a key issue. The 2018 [C\u00f4te d'Ivoire Population-based HIV Impact Assessment](https://phia.icap.columbia.edu/countries/cote-divoire/) (CIPHIA) survey provides nationally representative estimates of HIV levels, shown in Figure 1. These data inform national policy directions but are only produced every four to five years and aren't as useful for planning local interventions. Several small area estimation initiatives are exploring the feasibility of more routine local level estimates. These initiatives use additional data sources to improve the resolution of national estimates. For example, the United States Agency for International Development (USAID) have developed tools to [extend the data](http://spatialdata.dhsprogram.com/modeled-surfaces/) from [Demographic and Health Surveys](https://dhsprogram.com/methodology/survey/survey-display-311.cfm) (DHS) and the UNAIDS Spectrum modelling initiative has been adapted to feed sub-national estimates for a range of key HIV indicators into their [dashboard](http://aidsinfo.unaids.org/). Source: CIPHIA [summary sheet](https://phia.icap.columbia.edu/wp-content/uploads/2017/02/3673%E2%80%A2CIPHIA-Cote-DIvoire-SS-2020_v2.pdf) Our project, as part of the [Data for Children Collaborative with UNICEF](https://www.dataforchildrencollaborative.com/), aims to combine national HIV surveys with high resolution, publicly available data, to target local interventions more effectively. We're working with people around the world, with representatives from UNICEF, The Data Lab, Scottish Government, the Ministry of Health in C\u00f4te d'Ivoire and many more organisations, shown in Figure 2. Our aim was to build on the USAID and Spectrum initiatives and use machine learning techniques to generate high resolution maps of HIV risk in adolescents. Machine learning methods make fewer assumptions about the relationships between predictors and HIV risk than traditional small area estimation approaches, are generally faster and can handle bigger, more complex datasets. We are currently working with members of the [National Program for the Fight Against HIV](https://www.pnlsci.com/) (PNLS) to access the 2018 CIPHIA data, which should be [available soon](https://phia.icap.columbia.edu/surveys/timeline/). While we establish the data sharing agreements, we've based our preliminary analyses on historic HIV testing data from the [DHS survey conducted in 2012](https://dhsprogram.com/what-we-do/survey/survey-display-311.cfm) to explore the types of data and methods that we can use to model HIV risk. The CIPHIA survey data are not publicly available yet ( [a timeline is available](https://phia.icap.columbia.edu/surveys/timeline/)), so we have based our initial exploration and modelling on the [DHS survey](https://dhsprogram.com/methodology/survey/survey-display-311.cfm) completed in 2012. The DHS program gathers HIV testing data alongside a range of socio-economic indicators such as education levels, health status and indicators of wealth. We explored a range of publicly available datasets to identify potential predictor variables. The DHS HIV testing and public data were mapped onto a common spatial grid and fed into a Random Forest machine learning framework. Our initial modelling outputs had very limited predictive power. In this blog we consider our next steps. We also reflect on how to apply what we've learnt so far in our current and future projects. The DHS program gathers HIV testing data alongside a range of socio-economic indicators such as education levels, health status and indicators of wealth. These surveys have a similar [hierarchical structure](https://www.dhsprogram.com/Data/Guide-to-DHS-Statistics/Analyzing_DHS_Data.htm?rhtocid=_4_4_0#Sample_Design) to the PHIA surveys, where census enumeration areas are selected based on their population size and then a set number of households are randomly chosen. [Random displacement procedures](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4946438/pdf/nihms702386.pdf) are used to anonymise the spatial data for each survey. We used the [rdhs](https://github.com/ropensci/rdhs) R package to load the DHS data into [R](https://www.tutorialspoint.com/r/index.htm) and explore it. An initial selection of publicly available spatial datasets was collated to provide indicators that were potentially associated with HIV prevalence. These are shown in Table 1. Travel time surfaces were used to calculate travel times to health and education facilities, urban centres, and electricity grid components. Future work will draw upon these data and additional sources to capture as broader range of socio-economic indicators as possible. In addition, it's important to highlight that we have selected more recent data sources to derive potential risk indicators from (when compared to the DHS survey from 2012) since future analyses will use the CIPHIA data from 2018. We are assuming that the impact of the temporal gap will be limited for our preliminary analyses. |Name||Resolution||Owner||Year| Given the C\u00f4te d'Ivoire [country boundary](https://gadm.org/download_country_v3.html), we created a uniform 10 kilometres times 10 kilometres spatial grid using the [sf](https://r-spatial.github.io/sf/) R package. The grid is shown in Figure 3. The DHS HIV testing and public data were mapped onto the grid to create our response (HIV prevalence) and predictor variables, as shown in Figure 4. We generated two dummy variables by drawing randomly from uniform and exponential distributions (a summary of the predictor variables can be found in [Table 2](#Table2) in the appendix). Source: C\u00f4te d'Ivoire national boundary (blue) sourced from [GADM](https://gadm.org/download_country_v3.html). Note that only a sample of predictor variables are shown (summary of all predictors can be found in [Table 2](#Table2) in the appendix). Source: HIV prevalence was derived from the [DHS 2012 survey](https://dhsprogram.com/methodology/survey/survey-display-311.cfm) and open data sources are described in [Table 1](#Table1). The [Random Forest Spatial Interpolation](https://core.ac.uk/download/pdf/323363793.pdf) (RFSI) framework was selected for these initial analyses from the [ranger](https://www.rdocumentation.org/packages/ranger/versions/0.12.1/topics/ranger) R package. RFSI extends the standard Random Forest framework by including observations of, and distances to, the nearest n sampled locations, as shown in Figure 4. We selected 25 as the number of nearest neighbours to consider in our preliminary analyses. Nearest neighbours were identified for each grid cell using the travel times based on motor vehicles. The impact of varying the number of nearest neighbours will be investigated in further research but it has been found to be [limited as long as the value isn't too small](https://core.ac.uk/download/pdf/323363793.pdf). Future work will also the examine the impact of identifying nearest neighbours using different measures of distance, such as Euclidian distance or travel time based on walking. Source: Figure is taken directly from [Sekuli et al. 2020 Random Forest Spatial Interpolation](https://doi.org/10.3390/rs12101687). Source: [Demographic and Health Survey (DHS) 2012](https://dhsprogram.com/methodology/survey/survey-display-311.cfm) A hyper grid was constructed to identify the optimal parameters for the Random Forest model using the grid cells where HIV prevalence estimates were available (n=239). With the optimal parameters identified, a final model was constructed and used to predict the HIV prevalence in the grid cells where testing data were not available (n=2,727). As Figure 6 and Figure 7 demonstrate, the prevalence distribution was skewed and zero-inflated and the constructed model could not accurately predict HIV prevalence. The majority of grid cells across C\u00f4te d'Ivoire had broad prediction bounds, with the difference between the lower 2.5% and upper 97.5% bounds on the predictions being large, relative to the median predictions (Figure 7). Grid cells with a black border (appearing raised) are cells where estimates of HIV prevalence weren't predicted but derived from the [Demographic and Health Survey data](https://dhsprogram.com/methodology/survey/survey-display-311.cfm). Our preliminary results suggest there isn't a strong relationship between our initial set of predictors and HIV prevalence estimates from the DHS survey. While there are limitations to our approach, it is known that HIV prevalence is difficult to predict spatially particularly in low prevalence settings, as shown in the [DHS modelling advice](https://dhsprogram.com/pubs/pdf/SAR14/SAR14.pdf). These difficulties arise from HIV being a long-term disease driven by complex socio-economic factors. Our models could be improved by incorporating predictors that better capture aspects of human behaviour. Previous [research](https://www.nature.com/articles/srep19342) demonstrated strong links between predictors derived from mobile phone data and prevalence. Our team work on a diverse range of data science projects around the world. It is important with each project to consider how to apply what we've learnt in other settings. For example, the RFSI framework is a powerful tool that has an application to many [small area estimation](https://gss.civilservice.gov.uk/training/intermediate-small-area-estimation/) initiatives. The data we outlined in Table 1 has a broad range of potential applications: Our preliminary analyses help us to understand whether it is possible to use machine learning techniques to map HIV risk in C\u00f4te d'Ivoire. We've initially used DHS data and are working to access the CIPHIA data for a more up-to-date measure of HIV prevalence. In addition, we are currently considering: Conclusions While our initial results weren't what we had hoped, we have set out several next steps for continuing the project and improving our predictions. In addition, we've found that our approaches could potentially be applied in other contexts. We'll provide updates on the future progress of this work. If you have any questions or would like further information then please contact [Joseph Crispell](joseph.crispell@fcdo.gov.uk), data scientist at the [ONS-FCDO data science hub](https://datasciencecampus.ons.gov.uk/ons-fcdo-data-science-hub/). |Variable||Type||Description||Motivation| |Dummy variable - exponential||continuous||A random variable drawn from exponential distribution||Included to inform investigations into the informativeness of different variables| |Dummy variable - uniform||continuous||A random variable drawn from uniform distribution||Included to inform investigations into the informativeness of different variables| |Land cover type||factor||Discrete land cover type classifications from Copernicus Land Monitoring Service||Land use patterns likely to be linked to socio-economic status of different areas| |Population density of adolescents||continuous||Population density estimates from Facebook data for good initiatives||Population density linked to social connectedness patterns| |Total population density||continuous||Population density estimates (15-24yo) from Facebook data for good initiatives||Population density linked to social connectedness patterns| |Travel times to other grid cells (walking and by motor vehicle)||continuous||Travel times to all other grid cells by motor vehicle||Connectedness across country may be linked to HIV spread| |Travel times to education facilities (walking and by motor vehicle)||continuous||Travel times to education facilities by motor vehicle||Access to education could be linked to success of interventions| |Travel times to electricity grid components (walking and by motor vehicle)||continuous||Travel times to nearest electricity grid infrastructure by motor vehicle||The availability of electricity is an indicator of socio-economic status that may be linked to HIV risk| |Travel times to healthcare facilities (walking and by motor vehicle)||continuous||Travel times to health facilities by motor vehicle||Access to health facilities could be linked to success of interventions| |Travel times to urban centres (walking and by motor vehicle)||continuous||Travel times to urban centres by motor vehicle||The degree of connectedness to urban centres (>10,000 population size) could be linked to HIV risk| We welcomed our first six graduates in the autumn of 2019, and they are now progressing their careers as data scientists in various Government teams. We successfully recruited another six graduates in 2020 despite the challenges of the coronavirus (COVID-19) pandemic and having to deliver the programme remotely. Our graduates have passed the test with flying colours, completing a demanding learning curriculum. They've also gained valuable experience supporting our data scientists, delivering insights to decision-makers at the highest level for our [coronavirus response work](https://datasciencecampus.ons.gov.uk/tag/coronavirus/). Following the success of the 2019 and 2020 programmes, [applications for the 2021 Data Science Graduate Programme](https://www.civilservicejobs.service.gov.uk/csr/index.cgi?SID=am9ibGlzdF92aWV3X3ZhYz0xNzE5MjQ5JnNlYXJjaF9zbGljZV9jdXJyZW50PTEmcGFnZWFjdGlvbj12aWV3dmFjYnlqb2JsaXN0Jm93bmVydHlwZT1mYWlyJmNzb3VyY2U9Y3Nxc2VhcmNoJm93bmVyPTUwNzAwMDAmdXNlcnNlYXJjaGNvbnRleHQ9MTI2NzAyMjA5JnBhZ2VjbGFzcz1Kb2JzJnJlcXNpZz0xNjIwMTE1MzIzLWZkY2M4ZmQ3ZWFhNDE5ZWM2MzI4YmIwOTE5ODZjYWYyNDMyZmQxNTE=) are now open until 3 June 2021. Teams across government have seen the effect that the programme has had, so this year we are expanding it to offer places at several high-profile public-sector organisations. You'll have the opportunity to work with experienced data scientists at organisations including 10 Downing Street, HM Treasury, HM Revenue and Customs (HMRC), the Defence Science and Technology Laboratory (DSTL), Land Registry, and the Welsh Government. Perhaps you're not sure if you've got the right skills, experience or background to apply. Don't worry! There's no particular background you need to have and our current graduates have arrived with varying levels of coding experience and have hit the ground running. Here's what they have to say about their experience of the programme. If you want to know more about what the programme involves, our [applicant brochure (PDF, 442KB)](https://datasciencecampus.ons.gov.uk/wp-content/uploads/sites/10/2021/05/1487-Data-Science-Campus-Recruitment-Programme-brochure_v3_APPLICANT.pdf) and [information page](https://datasciencecampus.ons.gov.uk/capability/data-science-graduate-programme/) gives an overview of the curriculum, benefits and testimonials of current and past graduates. On 12 May, we held an open day for prospective applicants. You can [watch the recording of the event](http://tinyurl.com/DataScienceGraduateOpenDay) to: The Data Science Graduate Programme is a fantastic opportunity to join a wide range of government departments and a truly diverse and dynamic community that is using data science skills for the public good. If you're passionate about data science and willing to learn new things, there's a place for you here.]]> ML 2021, launched in January 2021, is led by the Office for National Statistics (ONS) Data Science Campus in partnership with the [UN Economic Commission for Europe High-Level Group for the Modernisation of Official Statistics (UNECE HLG-MOS)](https://statswiki.unece.org/display/hlgbas/High-Level+Group+for+the+Modernisation+of+Official+Statistics). ML 2021 provides a friendly platform for the global statistical community to develop research, build skills and share common challenges and solutions on machine learning developments and applications in the official statistics space. Here we share our recent progress, including the ML 2021 [structure (PPT, 52KB)](https://statswiki.unece.org/download/attachments/293535864/ML2021%20WS%20Diagram%20v3.1%20wo%20slide3.pptx?version=1&modificationDate=1619621680434&api=v2), [governance](https://statswiki.unece.org/display/ML/Machine+Learning+Group+2021?preview=/293535864/295634524/ML%202021_ToR.docx), and the research workstreams the group will explore. More information on recent developments and resources is available on our [public page](https://statswiki.unece.org/display/ML/Machine+Learning+Group+2021). As 2020 came to a close, an outreach exercise was conducted to promote the new group and refresh ML 2021 membership. In an amazing response from the international community the membership doubled, and ML 2021 now has 250 engaged members from 33 countries and 4 international organisations. Members were then asked to submit machine learning (ML) activity proposals outlining main objectives and outputs. These were used to help inform the group's governance structure and community-driven work schedule for 2021. These proposals were grouped into workstreams and members confirmed. ML 2021 has 18 research projects in progress across five workstreams. These are activities which are still in the proof of concept phase. Split into themes, they will benefit from existing good practice, knowledge and experiences of other group members. The themes include: This workstream explores how proven ML applications can be integrated into production models. Its objective is to determine a best practice workflow for the applications examined as part of the workstream. Data ethics and governance have been discussed regularly in recent years, but never fully explored. This workstream gives us that opportunity to consider existing ethical frameworks and determine ethical principles which can be applied to ML within the official statistics space. It is important to have good quality training data when developing ML models. This workstream will identify and describe circumstances where retraining of models is needed, how retraining needs can be detected, and whether objective criteria can be developed to enable retraining to be triggered automatically. This final workstream will explore dimensions of the Quality Framework for Statistical Algorithms (QF4SA) within a consolidated project and analyse the output based on a set of standard metrics and procedures. The group meets monthly to hear about the latest developments from workstream leads. Live polls and surveys consult on ways forward and guest speakers are also invited to keep the membership informed on global ML developments. Previous presentations are available on the ML 2021 [public wiki](https://statswiki.unece.org/display/ML/Machine+Learning+Group+2021). Workstream members are also encouraged to meet regularly to ensure progress is made, and draft interim reports detailing their findings to share with ML 2021 members. Now the group's core workstreams are established, we are providing the ML community with events and resources that can support the progress of their workstream and further share developments and expertise globally. Most events are open to non-members and feature ongoing work from the group itself. For example, we are hosting a workshop exploring the practical application of developing ethical principles, coffee & coding type events on the lifecycle of ML projects and demo sessions on relevant tools for the application of ML. The group is also developing a ML training courses catalogue to respond to the demand for a more structured and easily accessible training curriculum. An open 1 to 2 day webinar is also planned for December to showcase the projects carried out by the group.We are also making sure we build and maintain connections with other global initiatives such as the [UN Committee of Experts on Big Data and Data Science for Official Statistics (UN-CEBD)](https://unstats.un.org/bigdata/) and the [HLG-MOS Synthetic Data Project](https://statswiki.unece.org/display/hlgbas/Modernisation+Projects). To support the ML 2021 Group's progress, take part in events, and gain access to our working documents, [contact us](mailto:ML2021@ons.gov.uk). An official UNECE publication detailing the findings from the ML Project 2019 to 2020 and some ML 2021 activities is also planned for later this year - stay tuned! Our friends in [UNECE Statistics](https://unece.org/statistics) have also recently published a [news article](https://unece.org/statistics/news/machine-learning-paves-way-modern-efficient-statistical-production) detailing their work exploring the relevance of ML within the official statistical space. ]]> Oliver Mahoney, International Relations and Data Science This target was confirmed in the core pillars of the recently published [National Data Strategy](https://www.gov.uk/government/publications/uk-national-data-strategy/national-data-strategy), ensuring that the public sector has the right [data skills](https://www.gov.uk/government/publications/uk-national-data-strategy/national-data-strategy#data-1-2) to benefit from increasingly data-rich environments. Through a range of formal training programmes and mentoring opportunities, the Campus has now successfully upskilled 681 analysts in data science tools and techniques from working to advanced level. Even a switch to a fully remote working environment over the last year has not hindered progress. In fact, the coronavirus (COVID-19) pandemic has opened new doors of opportunity and increased the pace of delivery. So, what are these programmes, how have they contributed to this target and what's in store for the future? Our team of lecturers ( [the Data Science Campus Faculty](https://datasciencecampus.ons.gov.uk/capability/data-science-campus-faculty/)) deliver a number of learning programmes to build knowledge and capability in different data science tools and techniques. Our products include workshops on R or Python, Natural Language Processing and Machine Learning (amongst many others) and have helped upskill over 240 individual learners from across Government. Many attended multiple workshops, with more than 179 working days of learning delivered. The hugely successful [data science accelerator](https://datasciencecampus.ons.gov.uk/capability/data-science-accelerator/) programme has mentored more than 250 analysts since 2015, 48 of these since the Campus began administrating the programme in January 2020. A switch to completely remote mentoring in 2020 hasn't dampened appetite, with a record number of applications in February 2021. The accelerator programme is run with the Government Digital Service, part of a collaboration known as the Government Data Science Partnership (GDSP). The partnership exists to help government realise the potential of data science and support the development of skills and tools. The GDSP works across the [data science community](https://www.gov.uk/service-manual/communities/data-science-community) to bring data scientists together to share, challenge, encourage best practice and build capability. To date, more than 50 students have begun the full Master's (MSc) in Data Analytics for Government, with a further 295 attending one-off modules to strengthen their professional capability. Our university partners have responded to the current pandemic by using distance learning methods and [Glasgow University](https://datasciencecampus.ons.gov.uk/bringing-mdatagov-online-with-the-university-of-glasgow/) also offer the programme as a solely online scheme. Our [apprentice programme](https://datasciencecampus.ons.gov.uk/capability/degree-data-science-apprenticeship/) has gone from strength to strength with 28 apprentices entering the different schemes since 2017 and going on to secure permanent positions both in ONS and in other Government departments. Six [graduate data scientists](https://datasciencecampus.ons.gov.uk/capability/data-science-graduate-programme/) joined ONS in 2019, with an additional five learners accessing the curriculum from different areas of Government. The Data Science Campus recruited a further six graduates in October 2020, with existing graduates progressing their careers as Data Scientists in various Government teams. Our apprentices and graduates have not only joined challenging programmes in a remote environment, they have supported experienced data science teams in our [coronavirus response work](https://datasciencecampus.ons.gov.uk/tag/coronavirus/), delivering insights to decision-makers at the highest level. So much has been achieved over the last four years, but we aren't stopping now. Over the coming months we will scale up our Graduate Data Science Programme across the public sector, with departments and agencies committed to recruiting graduates or accessing the curriculum and equipping them with the skills needed to build a career in data science. We will also be working to provide aspects of the graduate curriculum to the [Civil Service Fast Stream](https://www.faststream.gov.uk/) - a high-profile and accelerated development programme. We will also be taking the lead in expanding the [Data Masterclass for Senior Leaders](https://osr.statisticsauthority.gov.uk/upskilling-government-leaders-in-data-and-statistical-literacy/) in partnership with Number 10's Data Science team as senior leaders across government become increasingly reliant on data to inform critical decisions. Our hugely successful [accelerator programme](https://www.gov.uk/government/publications/data-science-accelerator-programme/introduction-to-the-data-science-accelerator-programme), run in partnership with the [Government Digital Service](https://www.gov.uk/government/organisations/government-digital-service), offers two cohorts a year with plans to expand into new projects from September 2021. New initiatives, including expanding our learning offer through online technology will see even more people, from across the UK public sector, and our international partners, build their skills and capability as the Data Science Campus continues to create greater capacity in data science.]]> [Facebook Data for Good](https://dataforgood.fb.com/) is another source of mobility data that we have been investigating and initial insights from our work are included in the ONS publication \" [Comparing behaviours and economic activity during lockdown periods](https://www.ons.gov.uk/releases/comparingbehavioursandeconomicactivityduringlockdownperiodsmarch2021)\" published on 19 March 2021. The Facebook data provide timely insights that can rapidly help us understand patterns of change in how people are moving around the country and the impact of the lockdown restrictions. The data we receive is aggregated, de-identified and re-scaled, so that no individual or individual business can be identified. The data is provided by the Facebook Data for Good programme to [WorldPop](http://www.worldpop.org/) at the University of Southampton. WorldPop analysts carry out aggregation, re-scaling and analysis of the data that they receive via the [COVID-19 Mobility Data Network](https://www.covid19mobility.org/). These data have already been used in an experimental analysis on monitoring the [population density changes in coastal towns](https://www.ons.gov.uk/businessindustryandtrade/tourismindustry/articles/coastaltownsinenglandandwales/2020-10-06). We receive the aggregated, de-identified and re-scaled data on Facebook app users in the UK, who have location services activated on their smart phones. It provides a daily time series, starting from 10 March 2020. The location information uses the [Bing Maps Tile System](https://docs.microsoft.com/en-us/bingmaps/articles/bing-maps-tile-system) to allocate users to tiles within a regular grid across the UK. Based on the tile that a user spends the most time in during an eight-hour time period, the data include measures of: We have been experimenting with the best way to aggregate the tiles to administrative geographies such as [local authorities](https://geoportal.statistics.gov.uk/search?collection=Dataset&sort=name&tags=all(BDY_LAD%2CMAY_2020)), which we can link with other types of [demographical data](https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/populationestimatesforukenglandandwalesscotlandandnorthernireland) published by the ONS. This has enabled us to create a dataset of the changing relative numbers of journeys between local authorities. The Facebook data offers some different insights from some of the other data sources we have. This includes higher spatial resolution and eight-hour frequency. We also want to explore these data alongside our other mobility data sources, because we know that the different data sources will have different strengths, weakness and biases, and using a range of indicators helps us to triangulate the various sources. We want to fully understand these differences and are continuing to explore how the Facebook mobility data can be used to complement our other sources. The coronavirus pandemic has resulted in rapidly changing patterns of population movements and new data sources are needed to understand these changes. The Facebook data show patterns of the reduction of movement following changes in policy, such as the introduction of the tier system and the national lockdowns in England, in a more timely way than more robust traditional data sources. All data provided to the ONS are strictly de-identified and in an aggregated and re-scaled form so that no individual can be identified in any of our work, and only relative changes are analysed. We also carried out an ethical review to ensure that the use of these data was appropriate. We are grateful to Facebook Data for Good and the WorldPop team at the University of Southampton for providing the data and helping us understand and analyse it. We are exploring what further insights we can make available and hope to publish these soon. ]]> Cathy Atkinson, Senior Data Scientist Over the last 18 months, the [UNECE HLG-MOS Machine Learning Project](https://statswiki.unece.org/display/ML/HLG-MOS+Machine+Learning+Project) has brought together more than 120 members from 23 countries and 30 organisations to focus on the development and implementation of machine learning for the modernisation of official statistics. The project came to an end in December 2020 with an impressive range of outcomes across three working packages. These included [21 pilot studies](https://statswiki.unece.org/display/ML/WP1+-+Pilot+Studies), a [Quality Framework for Statistical Algorithms (QF4SA)](https://statswiki.unece.org/display/ML/WP2+-+Quality) and a report on the [Integration of Machine Learning into Production](https://statswiki.unece.org/display/ML/WP3+-+Integration). The UNECE High-Level Group for the Modernisation of Official Statistics is steered by committed chief statisticians from national statistics institutes around the world. Its Executive Board manages regular strategic activities, including ongoing working groups in specific themes and time-limited projects. The Machine Learning 2021 Group (ML 2021) will be led by the ONS Data Science Campus in partnership with the UNECE HLG-MOS from January to December 2021. Building on the work carried out by ML 2019 to 2020, ML 2021 aims to develop research, build skills and share resources on machine learning developments and applications for official statistics across the global statistical community. To ensure ML 2021 reflects the research interests and needs of the international community, we are inviting National Statistical Organisations (NSOs) to lead on one or more activities that are both relevant to their organisations and aligned with the objectives of the Group. Activity leads will be invited to meet virtually in January or February 2021 to group proposed activities into work packages and agree ways of working. The [UNECE Machine Learning for Official Statistics Wiki](https://statswiki.unece.org/pages/viewpage.action?spaceKey=ML&title=Machine+Learning+Group+2021) shows the work packages (WPs) investigated by ML 2019 to 2020 and potential themes to be explored by the ML 2021 Group. International organisations are invited to submit their [activity proposals](https://www.smartsurvey.co.uk/s/ML2021activity/) by 15 January 2021. Proposals may align to the [research areas](https://statswiki.unece.org/pages/viewpage.action?spaceKey=ML&title=Machine+Learning+Group+2021) but other topic suggestions are also welcome. To help shape the ML 2021 Group and take part in events and activities, contact [ML2021@ons.gov.uk](mailto:ML2021@ons.gov.uk), copying [UNECE](mailto:choii@un.org). You don't need to be an activity lead to take part. If you are already a member of the [HLG-MOS Machine Learning Project](https://statswiki.unece.org/display/ML/HLG-MOS+Machine+Learning+Project), you do not need to register again. If you would prefer to opt-out from further communications from the ML 2021 Group, please [let us know](mailto:choii@un.org). Join the [ML for Official Statistics Group](https://www.yammer.com/unstats/#/threads/inGroup?type=in_group&feedId=45511467008&view=all), part of the [Global Network of Data Officers and Statisticians](http://yammer.com/unstats). A [quick guide](https://worldstatisticsday.org/2020/docs/Quick-Guide-for-New-Members.pdf) on how to join the Global Network is also available. Announcements, news and public events from the ML 2021 Group, along with research, code, presentations and training resources from the ML 2019 to 2020 project, are publicly available in the [UNECE Machine Learning for Official Statistics Wiki](https://statswiki.unece.org/display/ML/Machine+Learning+Group+2021). Should you need further information, please do not hesitate to [contact us](mailto:ML2021@ons.gov.uk). Dr Solange Correa Onel, UK Office for Data Science Campus ]]> [InKyung Choi](choii@un.org), UNECE High-Level Group for the Modernisation of Official Statistics As the pandemic took hold in March 2020, the UK government and devolved administrations, and the [Scientific Advisory Group for Emergencies](https://www.gov.uk/government/organisations/scientific-advisory-group-for-emergencies) urgently needed to understand how well non-pharmaceutical interventions - such as mobility restrictions - were being observed, and what the impact of those restrictions was. To address this issue, the Campus, building on our experience partnering with the private sector, such as our work with [Barclays](https://datasciencecampus.ons.gov.uk/payments-data-for-public-good/) and [glass.ai](https://datasciencecampus.ons.gov.uk/extracting-text-data-from-business-website-covid-19-notices/), has been working with O2 Motion to explore the country's response to lockdown. We have only had access to anonymised and aggregated O2 Motion telecoms mobility data. With 25 million mobile phone customers, these anonymised and aggregated data have helped us to understand mobility trends in the UK population. The mobility data gave us close-to-real-time information, and were available at UK, national and local authority geographies. We were able to look at mobility patterns by age, gender, and whether trips were for commuting or other purposes. We used the data to explore some of the most urgent policy questions including: All the data provided to the Office for National Statistics (ONS) are strictly anonymised and in aggregated form so that no individual can be identified in any of our work, and an ethical review was carried out to ensure that the use of these data was appropriate. The underlying data and analysis used in this work remain confidential because of commercial restrictions, although we will explore what we might be able to make public, whilst respecting requirements for commercial confidentiality. We are grateful to the O2 Motion team for helping us to understand the data and to use it effectively. We would be very happy to hear from other organisations who might be interested in partnering with us.]]> One of the indicators that has, until now, remained unreported for the UK is indicator 6.6.1: Change in the extent of water-related ecosystems over time. It focuses on water-related ecosystems that provide an important service to society, including open waters (rivers and estuaries, lakes and reservoirs), wetlands (peatland and reedbeds) and groundwater aquifers. Recognising a global need for better data to measure this indicator, the Joint Research Centre and Google have developed the [Global Surface Water Explorer (GSWE)](https://global-surface-water.appspot.com/) dataset. This is based on satellite imagery from the past 35 years and measures changes in the distribution of inland open water, for example, lakes and reservoirs, a sub-indicator of 6.6.1. In this blog, we describe how we have assessed the quality of this novel data source to better understand its value and fitness-for-purpose, and then produced data that report the UK's position on indicator 6.6.1. The Global Surface Water Explorer (GSWE) was developed specifically to help countries report on indicator 6.6.1, recognising the lack of available data sources that monitor changes in both permanent and transient water. It was developed in partnership with the UN Environment Programme (UNEP), the European Commission Joint Research Centre and Google. The GSWE dataset, [built using a peer-reviewed consistent methodology](https://www.nature.com/articles/nature20584), is global and publicly available, for example, via the [Google Earth Engine](https://earthengine.google.com/). The GSWE tool quantifies monthly changes in global surface water since 1984 at 30-metre pixel resolution using around 3 million Landsat satellite images. It records the months and years when water was present, where occurrence changed and what form changes took in terms of seasonality and persistence. It classifies three different water types: We applied a number of processes to transform the imagery data from the GSWE into tables and maps that are reported via the UK [Sustainable Development Goal (SDG) national reporting platform](https://sdgdata.gov.uk/). These processes include constraining data to official high-water mark boundaries, which helps ensure that coastal water is not included in measures and mitigating the impact of persistent cloud cover. You can read more about the methods used to produce these data in the [quality and methodology report](https://datasciencecampus.ons.gov.uk/projects/quality-and-methodology-extent-and-change-of-surface-water-statistics) we have produced as part of our commitment to voluntarily apply the [Code of Practice for Statistics](https://code.statisticsauthority.gov.uk/) to our non-official outputs. This helps to provide transparency and improve the reporting capability of other National Statistical Institutes. The code for performing data extraction from Google Earth Engine and the computation of statistics for different geographic areas are available on our [GitHub pages](https://github.com/datasciencecampus/sdg_661_analysis_and_reporting). As of November 2020, the [Sustainable Development Goal (SDG)](https://www.un.org/sustainabledevelopment/sustainable-development-goals/) team at the Office for National Statistics (ONS) reported that the UK has published headline statistics against 80% of indicators. Often, indicators do not align with national data collection strategies, so innovative solutions and novel data sources such as global, open and geospatial datasets are increasingly being explored. The approach taken for this indicator (6.6.1) differs from methods traditionally used to capture water for topographic mapping, where trained surveyors measure the boundaries of every individual water feature either in the field or using very high-resolution aerial photography. The Global Surface Water Explorer (GSWE) data are not official statistics, so we opted to voluntarily review the dataset for the purpose of UK SDG reporting against the quality framework of the [Code of Practice for Statistics](https://code.statisticsauthority.gov.uk/). You can read more about the quality analysis in the [quality and methodology report](https://datasciencecampus.ons.gov.uk/projects/quality-and-methodology-extent-and-change-of-surface-water-statistics). The main strengths of the data are that they have been produced by water experts at the UN Environment Programme (UNEP) and European Commission Joint Research Centre specifically to monitor this indicator. The methods used to produce the data are comprehensively described and peer reviewed, and the accuracy of the model is high. Tested against 40,000 samples, it is estimated the model produces less than 1% false-positive detections of water and less than 5% false negatives. Furthermore, the data are open and available for the entire world and can therefore be compared internationally. This aligns with our work to support colleagues across the world to develop their capability. In using the GSWE data source certain quality trade-offs have had to be made. We favoured the ability to measure changes comprehensively over space and time instead of the highest spatial resolution. Spatial accuracy is related to the resolution at which the satellite imagery being classified was captured at, below which water features will not be detected. These data used Landsat imagery with a pixel resolution of 30m (900m2), which means that we do not have data for smaller water bodies (including small lakes, rivers and streams). In addition, the tool currently only gives data on open water, which cannot yet be separated into natural water bodies (for example, lakes) and man-made water bodies (for example, reservoirs). Using the source data, the presence of different types of inland surface water (permanent, seasonal and ephemeral) each year between 1984 to 2019 can be identified at the level of 30m pixels. Spatial extent is calculated by aggregating pixel counts from this level to [HydroBASINs](https://hydrosheds.org/page/hydrobasins), which are a series of polygon layers that depict watershed boundaries at a global scale. The HydroBASINs use the Pfafstetter coding system, which allows for analysis of catchment topology. Catchments can be broken down further into smaller sub-basins; with each subdivision, the Pfafstetter level increases. Here, a Pfafstetter level of six was used, giving us data for 38 catchments across the UK. Figure 1 shows the 2019 data on the extent of different types of surface water aggregated by HydroBASIN. Source: Global Surface Water Explorer data; European Commission Joint Research Centre; and Google Scotland accounts for most of the UK's surface water. From 1984 to 2019, 50% of the UK's permanent inland water occurred in Scotland, while Northern Ireland contained 31% and England and Wales together only contained 19%. Figure 1 shows that the HydroBASIN with the greatest spatial extent of permanent water fell in Northern Ireland, which contains Lough Neagh, the UK's largest lake by area. That HydroBASIN accounts for 66% of Northern Ireland's permanent inland waters. Conversely, England held an average of 57% and 43% of all ephemeral and seasonal inland waters, from 1984 to 2019. Wales contributed the least to each water type nationally: 5% seasonal and 3% ephemeral and permanent inland surface water, not including rivers and estuaries. Comparing spatial extent of each water type between years allows the second part of the sub-indicator, percentage change in spatial extent, to be calculated. The change in extent, described using the [indicator's monitoring methodology](https://files.habitatseven.com/unwater/SDG-Monitoring-Methodology-for-Indicator-6.6.1.pdf) is calculated as: \\(\\) \\( \\text{Percentage Spatial Extent} = \\frac{\\text{ - }}{\\text{}} \\) where: = the average national extent from 2001 to 2005 = the average national extent of any other five-year period Figure 2 shows that the source data contains two periods of anomalous data: 1991 to 1997 (excluding 1994) and 2004 to 2008. These are because of a lack of suitable Landsat images from which to derive water measurement, likely a result of persistent cloud cover. The base period of 2001 to 2005 includes the anomalous years 2004 and 2005. To mitigate the impact of variable cloud cover, we have taken the modal value of each pixel across the baseline years to calculate the average spatial extent per HydroBASIN (). Further details on the source data and mitigating the impacts of these anomalous periods is provided in the [quality and methodology report](https://datasciencecampus.ons.gov.uk/projects/quality-and-methodology-extent-and-change-of-surface-water-statistics). UK, 1984 to 2019 Source: Global Surface Water Explorer data; European Commission Joint Research Centre; and Google The code performing Google Earth Engine extraction and zonal statistics is available on the [Data Science Campus' GitHub](https://github.com/datasciencecampus/sdg_661_analysis_and_reporting). The extent of permanent water bodies in Great Britain is captured by the Ordnance Survey, but these data lack the time series provided by the Global Surface Water Explorer (GSWE). We have compared the coherence in locations of water between the two data sources, after having (approximately) accounted for differences in spatial resolutions. We identified errors of commission and omission of around 2% by area, though much of this can also be accounted for in terms of the approximations required to make the datasets a comparable resolution. A very small number of notable anomalies were identified related to artificial waterbodies, for example, a dockyard. Such occurrences were rare and within the stated accuracy levels of the source data. The UN Environment Programme (UNEP), European Commission Joint Research Centre and Google partnership recently released the [Freshwater Ecosystems Explorer.](https://www.sdg661.app/) This uses a similar methodology using the GSWE dataset and is able to estimate unobserved permanent and seasonal water. We have compared results using the method outlined earlier with those from that source and found less than 1% difference for seasonal waters and approximately a 2% difference for permanent water extent. The discrepancies likely arise from the use of a more generalised boundary - Global Administrative Unit Layers (GAUL) - when processing GSWE data, which means seawater is being included at coastal margins. The data we present through the UK [Sustainable Development Goal (SDG) reporting platform](https://sdgdata.gov.uk/) has been aggregated against the high-water-mark national boundaries produced by Ordnance Survey. This limits the misclassification of seawater and provides consistency in the standard approach for compiling [National Statistics](https://osr.statisticsauthority.gov.uk/national-statistics/). Insights from novel data sources, such as satellite imagery open exciting new possibilities for monitoring the SDGs. However, in using new data sources we must be sensitive to the different issues that arise in the collection and production of such data. In this work, we have applied the principles of the [Code of Practice for Statistics](https://code.statisticsauthority.gov.uk/) to assess the concerns and their impact on the fitness-for-purpose of the indicators produced. While the Code was not expressly developed for such data sources, we have nonetheless found it to be an excellent framework to help guide assessments and reporting of the quality of data science products. Estimates of economic activity often depend on survey data. Those who respond to surveys may have different characteristics from those who do not respond. In turbulent times such as the COVID-19 pandemic, we cannot be sure whether the businesses who do not respond to surveys are still active or are not responding because they have ceased trading. Both these issues can affect the quality of those estimates. A wide range of data sources are used by the Office for National Statistics (ONS) to better understand the state of the economy. In this work, we used text data from over 500,000 business websites to inform survey response-chasing efforts and gain insight into the impact of COVID-19. Here we discuss analysis of a dataset, provided by private sector partner [glass.ai](https://www.glass.ai/), consisting of text related to COVID-19 extracted from UK business websites. This work represents one part of a project combining data from various sources to aid ONS business survey-response chasing efforts. We do not present statistical outputs or draw conclusions about the wider population of UK businesses. Relevant statistical outputs based on a fortnightly survey of businesses can be found in [Coronavirus and the economic impacts on the UK](https://www.ons.gov.uk/businessindustryandtrade/business/businessservices/bulletins/coronavirusandtheeconomicimpactsontheuk/latest). As this project relied on data from the web that is then linked to official sources, rather than a random sample, we found that some industrial sectors were under-represented. This can be further compounded by differences in how different businesses use their websites for communication. For example, construction sector websites are both under-represented in this online data collection and less likely to use their websites to communicate about COVID-19. To build our understanding of the data source we applied several natural language processing techniques. Having applied topic modelling approaches we found some apparent topics for the COVID-19 text that conformed to our expectations about likely communications, such as announcing temporary closures or presenting government advice. We also trained a text classification approach to attempt to infer whether a text snippet was likely indicating business closure. Classifier performance was reasonable but not at a level that could be used to reliably compare sectors. Analysis of business impacts of COVID-19 is an active area of inquiry such as the work of [Nesta](https://www.nesta.org.uk/), [Measuring the economic Impact of COVID-19 in the UK with business website data](https://www.escoe.ac.uk/events/measuring-the-economic-impact-of-covid-19-in-the-uk-with-business-website-data/), presented at an Economic Statistics Centre of Excellence webinar. In their work, business website data are combined with Google search trends to highlight the differences in the challenges faced by different UK regions. Data for this project were provided by private sector partner [glass.ai](https://www.glass.ai/) who have built a smart resource crawler that identifies UK business websites. Their systems are able to collect various types of business data. For this project, text related to COVID-19 was extracted from the websites of around 500,000 UK businesses. The extraction process was repeated on a monthly basis from late April 2020 to September 2020. Text data were extracted using a set of manually defined keywords and phrases, for example: \"Covid\", \"lockdown\", and \"government advice\". This helped to avoid picking up data that were not relevant to the project. The keyword approach kept our data focused on COVID-19, but it does have limitations. The context of the lockdown and COVID-19 measures is often assumed so some website notices do not include obvious keywords even when the text is addressing their response to the virus. For this project we only used data from websites that the supplier was able to link to a company registered with Companies House. The data source consists of around 500,000 records, of which text related to COVID-19 was found for approximately 70,000. It is important to note that these data are not a random sample of all UK businesses. To better understand potential sources of bias and coverage issues, we compared counts of firms by [Standard Industrial Classification (SIC) 2007](https://www.ons.gov.uk/methodology/classificationsandstandards/ukstandardindustrialclassificationofeconomicactivities/uksic2007) and employment size band with those that we would expect to see if these data were a random sample of the population of businesses found on the Inter-Departmental Business Register (IDBR). Figure 1 shows top level SIC sections where the online based data source over and under-represents. We limited the plot to those SIC sections where we would expect at least 10,000 websites in the data were it a random sample from the IDBR. The plot shows what was observed relative to what would be expected for each section. Cases where a website could link to multiple SIC sections based on reporting unit were ignored. \"Construction\", \"manufacturing\", and \"agriculture, forestry and fishing\" are all significantly under-represented in the data. The examples of over-representation are less extreme, although businesses in \"other service activities\" do occur close to twice as often as would be expected if the data were from a random sample. Different businesses use their websites in different ways, with some more likely than others to use their website for COVID-19 communication. For example, a large museum with thousands of potential visitors may frequently update their website, while a small business operating a few contracts with other businesses may not. Separating the propensity for communication from the impact would be difficult and is an issue that [other researchers in this area](https://www.zew.de/en/publications/corona-pandemic-affects-companies-differently) have identified. Addressing this challenge is beyond the scope of our current work. The limitations of coverage and differences in communications between businesses prevented us from being able to make inferences about the general population of businesses from the data. It is also not always clear from the text on a website how severe the impact on a business is. While some notifications are unambiguous, many refer to specific impacts that would need further context to interpret. For example, closure of physical premises could effectively close off all revenue for some businesses, while others would be able to continue trading online at similar levels to before. Collecting business data from websites does come with its own set of ethical considerations. For this project: The ONS [Web Scraping Policy](https://www.ons.gov.uk/aboutus/transparencyandgovernance/datastrategy/datapolicies/webscrapingpolicy) covers many aspects of how we implement automated data collection from the web. Because of the urgency related to the COVID-19 pandemic, an exception to the notice period was applied following Section 5.2 of the Policy. This case was explained on [the ONS website](https://www.ons.gov.uk/file?uri=/aboutus/transparencyandgovernance/datastrategy/datapolicies/webscrapingpolicy/webscrapingcoronavirusupdate.pdf), inviting website owners to discuss any concerns they may have. Within our dataset of around 500,000 UK business websites, mentions of COVID-19 or related terms were identified in about 14% of cases. This proportion was relatively stable over time, although there were differences in terms of industry sector (see Table 1). In Table 1 the percentage of websites in each SIC section with COVID-19 matching text are shown. Note, we only show here a selection of SIC sections with a high number of records in the late May 2020 data collection. \"Manufacturing\" and \"information and communication\" had roughly an average amount of COVID-19 matching text on websites. \"Construction\" (6%) was well below average while, as would be expected, \"human health and social work activities\" (31%) were well above average. There are likely to be industry specific factors that influence how businesses use their websites, so differences here do not necessarily imply differences in terms of impact. Here we are only considering matching text in general, regardless of whether the text is positive (such as \"business as usual\") or negative (such as \"temporarily closed\"). For most of our analysis we first linked to the Inter-Departmental Business Register (IDBR); this reduced the dataset down to 360,000 websites. |SIC section||Percentage with text matching COVID-19 keyword| |Q: Human Health Work Activities||31| |P: Service Activities||21| |G: |I: Accommodation and Food |N: Administrative and Support Service Activities||13| |C: Manufacturing||13| and Communication||11| |F: Construction||6| The COVID-19 related text was classified according to trading status, based on the vocabulary of the matching text. While this approach was able to score text by how likely it is that the corresponding business was closed, there were many cases of scores that did not correspond well with the underlying ground truth (defined for a subset by manual inspection and survey data). To better understand the use of language in the snippets of text matching COVID-19 keywords, multiple techniques were applied: To get an idea of what businesses are including on their websites in relation to COVID-19, the Data Science Campus tool [pyGrams ](https://datasciencecampus.ons.gov.uk/projects/pygrams-an-open-source-tool-for-discovering-emerging-terminology-in-large-text-datasets/)was used to identify key terms and phrases in the text snippets. The pyGrams tool encapsulates several natural language processing techniques. The top 20 key terms identified using TF-IDF (Term Frequency-Inverse Document Frequency) vectors were: Text is standardised before processing so, all words are lowercase, some common words like \"as\" or \"the\" are removed, and words are lemmatized, for example, \"closed\" can become \"close\". At this level terms are mostly indicators that the text block is related to COVID-19 response. Some key terms are more likely to indicate business closures (for example, \"close until further\" is likely to come from \"closed until further notice\") while others are more likely to indicate continued trading (for example, \"business as usual\"). These are mixed in with terms that do not seem as likely to imply a positive or negative, such as \"statement\", \"response\" or \"announcement\". There are many records without clear indicator phrases, which motivated us to try topic modelling and text classification. We applied two standard topic models to the COVID-19 text data: [Non-negative Matrix Factorisation](https://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization) (NMF) and [Latent Dirichlet Allocation](https://www.jmlr.org/papers/v3/blei03a.html) (LDA). Of the topics identified by these approaches, some seemed to fall into identifiable categories: This is in line with manual inspection of the snippets. While these topics are reasonably well formed, using them to interpret individual records was often not clear cut. We also didn't apply any special treatment to the keywords used to find the initial text, so the choice of keywords is likely to influence the topics discovered. After developing our understanding of the data, we sought to train a model to classify notices according to trading status. Two separate datasets were used to train classifiers: The intention was to provide an indication of how likely a snippet was to indicate a severe impact to the business along with an understandable explanation of why. This model provides coefficients for individual vocabulary terms, so for any output the main words or phrases leading to a classification can be presented. In both cases the model treats the text as a bag of words and effectively scores each word based on whether it tends to be associated with business closures. The model applied was binary logistic regression (with L1 regularisation) applied to normalised TF-IDF vectors of words and word pairs present in the text. Here, L1 regularisation acts to reduce coefficients of unimportant terms to zero, which makes the explanation of the result from the model simpler. Model performance was reasonable, with a cross-validated Area Under Curve (AUC) over 0.8, although the level of class imbalance means that it is hard to achieve a high level of precision in the classifications without dropping recall substantially. From the distribution of scores for unseen data, it was clear that there were many cases that the model was not able to score correctly. This is likely to be because of some combination of the amount of text available and ambiguous or unusual vocabulary. To make significant improvements we would likely need to label more data, and possibly switch to a more sophisticated model that is able to go further in terms of parsing language rather than simply relying on the presence of terms or phrases. In the aggregate the model does show general trends, but without having a clear understanding of biases in the significant number of misclassifications, it would be too much of a leap to draw wider inferences. Data extracted from websites has a broad range of applications and has several important benefits. For example, collection tends to be low burden and the nature of that collection allows for timely analysis. Within the ONS, there are several projects that make use of data from the web in different ways. These range from targeted collection, such as is [the case for collecting price data](https://www.ons.gov.uk/economy/inflationandpriceindices/articles/introducingalternativedatasourcesintoconsumerpricestatistics/may2020), to more exploratory research projects, such as [understanding the characteristics of high growth companies](https://datasciencecampus.ons.gov.uk/projects/understanding-the-characteristics-of-high-growth-companies-using-non-traditional-data-sources/). As part of developing our understanding of the text data extracted from business websites, we were able to assess how different businesses, from various industrial sectors, use their websites to communicate their response to COVID-19 and related measures. Working with data extracted from websites is not without difficulties. Consideration needs to be given to how representative the data are of the wider population. In this project, linking to existing registers allowed us to quantify the extent of the relative over- and under-representation. To extend the work done so far to be able to make inferences from a model-based classification of COVID-19 related text, there are a number of areas that would need to be addressed: The authors would like to thank [Juan Mateos-Garcia](https://www.nesta.org.uk/team/juan-mateos-garcia/) and [Alex Bishop](https://www.nesta.org.uk/team/alex-bishop/) from [Nesta](https://www.nesta.org.uk/) for their insights into working with business website data. In this blog post, our [Office for National Statistics (ONS) and Foreign and Commonwealth Development Office (FCDO) Data Science Hub](https://datasciencecampus.ons.gov.uk/ons-fcdo-data-science-hub/) talks about exploring an innovative way of conducting a cattle census in South Sudan using satellite imagery. The ONS and FCDO Data Science Hub was set up in 2019 to promote the use of data science in international development by producing analytical tools and providing training and mentoring in data science to partner organisations. The team's work applies data science to help low- and middle-income countries work towards achieving the [Sustainable Development Goals (SDGs)](https://www.un.org/sustainabledevelopment/sustainable-development-goals/). One of our first projects has been to explore the possibility of conducting a cattle census in South Sudan using satellite imagery. Livestock are critical to the livelihoods of millions of South Sudanese, but the current livestock population is largely unknown as the last livestock census was conducted in the 1970s. New cattle estimates would allow a more accurate assessment of the contribution of livestock to South Sudan's economy. This would be useful to a range of stakeholders including the South Sudanese Government, the World Bank, and the International Monetary Fund. Other potential users include the UN Food and Agriculture Organisation (FAO), non-governmental organisations (NGOs) working in providing animal health services, and the UN Mission in South Sudan (UNMISS) who are keen to understand the role of the livestock economy in driving conflict. The current context in South Sudan makes it difficult to conduct a traditional livestock census, therefore, the possibility of using satellite imagery to do it remotely is appealing. And, if successful, there might also be significant cost savings over the previous methods. New methods inevitably bring new challenges. An important one in this situation is the sensitivity of the location of the cattle because of the risks of cattle raiding. So, while the methods proposed are to identify individual herds during the model design stage, the intention is to keep the final analysis at an aggregated level. The first step was to determine if suitable imagery could be acquired from various commercial and free suppliers. To do this, we considered the following issues: After our initial review of the available imagery, it was clear that the best approach would be to base the analysis on cattle camps - the corrals in which the cattle are held overnight and which, particularly during the dry season, the large herds may be in for weeks at a time. The approach aims to use different resolutions of imagery for different purposes, as shown in Figure 1. This approach has benefits in two areas: cost, and computer storage and processing. The low-resolution images are freely available, and these could be used to sift out the large areas of the country with no cattle camps. This reduces the area for which we would need to pay for expensive high-resolution images. In addition, maximising the use of lower-resolution images dramatically reduces the storage space and processing power that we needed to cover the whole country. We began our investigation into detecting cattle camps from lower-resolution (10 metre) Sentinel 2 imagery supplied by the European Space Agency. We created a training dataset of cattle camps from two sources: an initial set of example locations of cattle camps supplied by UN FAO, and manual identification of similar sites on satellite imagery available on Google Earth. Next, we verified these sites were visible on the latest Sentinel 2 images and captured polygons to build the training dataset. From visual inspection of the Sentinel 2 imagery, it was clear that the cattle camps could be distinguished from the surrounding landscape by the bare nature and lack of vegetation. Next, the team extracted the Sentinel 2 imagery pixel values for cattle camps and compared with sample polygons placed in the surrounding landscape. We looked at the distribution of pixel values of red, green, blue, near-infra red wavelengths. We also used derived indices indicating vegetation cover calculated from the imagery bands. Seasonality was important as the de-vegetated cattle camps have a much greater contrast with the surrounding landscape during the wet season. However, it is harder to acquire a cloud-free satellite image during the wet season, so the end of the wet season (around November) was a good compromise. We then developed a model to predict camp locations using a simple pixel-by-pixel classification method. The main corralled area of a cattle camp is quite small (0.5 to 4 hectares), so an appropriate method was chosen considering how many 10-metre pixels comprise a camp. This produced an output that indicated the probability that each pixel was part of a cattle camp. After that, we cleaned this initial output combining large and small kernel filters to emphasise the small cattle camp areas. When we tested the model against cattle camps and sample areas of the surrounding landscape unseen during training of the model, we found we could predict the location of cattle camps with over 90% accuracy. Having successfully shown we could identify the locations of cattle camps, we proceeded to the second stage: the feasibility of determining when a cattle camp is in use and when it is abandoned. We used medium three-metre resolution images from the supplier Planet. Planet re-images all of South Sudan every two to three days, so the team analysed a time series of images to see the changes in texture that we would expect to see from the disturbance by cattle when a camp is in use. This technique shows promising results. We now hope to validate these results with ground truth data. This will involve visits to a sample of cattle camps to determine the range of dates when they were active to compare with results predicted from the satellite images. This final stage will require the highest-resolution satellite images (0.3 metre or 0.5 metre), such as those supplied by Maxar. But, having determined the location of active cattle camps in stages one and two, we will be able to focus our resources on requesting and purchasing images in the appropriate areas. In Figure 3, it is possible to spot fire rings, structures and groups of animals. Local information provided so far indicates the camps have a consistent way of corralling the cattle, so the numbers they contain could be estimated by summing relevant areas discerned from the high-resolution images. This stage will require site visits to a sample of camps to estimate counts of animals and high-resolution imagery capture over the camp. The timings of site visit and imagery capture need to be coordinated to occur as closely together as possible. By combining the features seen inside the camp from the high-resolution imagery with the sample field surveys, we plan to develop a model to estimate a count of animals. The FCDO's East Africa Research Hub has now allocated funding to purchase high-resolution satellite imagery and to conduct the sample field surveys for the ground truth data. This will enable us to work on the final stage of this work in early 2021. Tom Wilson, Data Scientist, ONS FCDO Data Science Hub Tim Harris, User Engagement Lead, ONS FCDO Data Science Hub]]> To celebrate, a group of Campus data scientists at various stages of their coding journey talked about their experiences and any advice they have for people looking to start coding. My interest in coding was spurred by the idea of automation of tasks and processes and that a person did not need to be present for actions to be taken to achieve an outcome. I first realised this while playing a game called [Garry's Mod](https://store.steampowered.com/app/4000/Garrys_Mod/), where I was able to create automatic item dispensers. In a game, this was very profitable and fun, and the same methods and tools carry over to academic and professional environments, albeit with a bit more seriousness. For me, the first steps were the most difficult. When you begin learning to code, you typically do very simple tasks. I could not help but think \"What is the point in this? I can do this much more quickly in Excel\". It is only when you get over the initial few hurdles that you realise the true power and potential of coding. The next challenge was errors. Many errors and lots of intimidating red text. Sometimes, import pandas does not even work first time. For me, coding has always been about problem solving - problem, solution, problem, solution. One thing starts working and another breaks. This can become frustrating, but there is always a reason. It is important not to narrow your vision and to recognise there are usually multiple ways of doing things. Persistence is vital - it is extremely satisfying when your code finally runs. Preserve your code! At some point, you will attempt to make a simple fix to something in your code, which subsequently breaks things that you had working five minutes ago. It will happen. No matter how careful you are, you will find yourself in a position where you have just created a few more hours of work for yourself in a few well-intentioned keystrokes. It is nothing to be ashamed of, and it encourages tidiness later down the line (you will feel so silly, you will not make the same mistake again!). The easiest way to get around this for a newcomer would be to regularly save timestamped copies of your scripts somewhere as well as any outputs you create (csv data files, for example). Further down the line, using [GitHub](https://datasciencecampus.github.io/) or Git for version control can be critical but (certainly for me) can be a little intimidating at first! Be nosy. Wonder how things work. How does that game move things around? Where did that number come from? Then, start with something small - make it a small project, a challenge you can set yourself that you would like solved. What is my best time for a run? How often do I buy these ingredients? Can I make the lights come on in the house with my own controller? Can I water the plants on a timer? You can use a good teaching language (Python is great for this, it was designed for teaching and is very flexible - some might say too flexible), and scale upwards as you learn more. Python, R, Java all have freely available implementations and Integrated Development Environments, so you get a nice working environment very quickly. Once you have got something working and you are comfortable, then start worrying about the more formal side (functional programming, object-orientation, design patterns, loose coupling, unit testing). Also, try another language. For example, [Haskell](https://www.haskell.org/) is a functional language, so it enforces a particular style. Different languages have different pros and cons. Try a few, even if it is just a beginners' tutorial for an hour - it will really make you reconsider how you code and will help open you up to more possibilities. I love following my R \"heroes\" and researchers in the community on Twitter. There are so many interesting developments and applications out there to inspire you and learn! I look out especially for blogs and tutorials that people have made open. As a lecturer, I am constantly learning by teaching. Having to explain coding to students gives me the excuse to dive even deeper into my understanding of a topic and to learn new things! Another great place to look is YouTube. The [RStudio conference](https://rstudio.com/conference/) makes their talks and workshops available online. You can find me there during a lunch break or when I am looking to solve a new problem. Because of the impact of the coronavirus (COVID-19) pandemic in our society, there will not be any formal National Coding Week events this year. Instead, this year's theme is \"Fitness and Code\", to help you remember to stay fit while you code. It reminds you to be mindful about your well-being when working at the keyboard. Whether you are a beginner or more experienced with coding, check out our [Github page](http://github.com/datasciencecampus). We try to make our tools and code available as much as possible so you can use them for your own projects. When lockdown started and the Campus' expertise became integral to the response to the coronavirus, we knew it was more than just about getting the job done. We had to capture what we were learning about working under these circumstances in \"real time\", using what we were going through to inform both immediate and longer-term changes to improve our work. People are complex, emotional beings; getting under the skin of the real experience of operating at rapid pace in a hugely volatile environment required regular one-to-one conversation - a greater challenge during a time of remote working. Following an original idea from the Welsh Audit Office, I began conducting short (10-minute) chats with our senior data scientists leading their teams through this difficult situation. And the structure? Simplicity itself! Three questions, asked on a weekly basis: In just four weeks, a picture was emerging: \"people are feeling overwhelmed\". This isn't meant to be a superficial statement, it's the reality of the experiences of working at considerable pace, with changing demands and dwindling resources (so many of our team are parents, affected by the closure of schools and having to pick up home educating). Overwhelmed meant several things: We only had to look around and see the hours being built up, and annual leave being unused. Morale was also affected, with reports of unhappiness and stress. Burnout and an impact on the quality of our outputs was a risk. Yet throughout this entire experience, and as a direct result of this exercise, the Campus has emerged stronger. People wanted leaders to role-model taking their allocated time to rest and recuperate. They did, and now people have begun to use their leave and take some time back. People wanted improved lines of communication, so we've used our monthly whole-workforce meeting to focus on an agenda driven by the teams. We've introduced a new fortnightly newsletter (where lessons learned is now a regular feature), and managers are increasing their personal contact with team members. A new [Chief Data Scientist role](https://datasciencecampus.ons.gov.uk/about-us/were-hiring/) (applications open until 3 September 2020) is being created to provide greater ownership of the incoming demands and to assist prioritisation. By no means are all issues going to go away, but we know what they are, and we are addressing them. We're using what we've learned to help other ONS teams understand the experiences of their staff and make changes that will improve their working practices. We've also adopted the exercise across the cross-government [Data Science Accelerator](https://datasciencecampus.ons.gov.uk/capability/data-science-accelerator/) mentoring programme. Transitioning from a face-to-face to completely virtual delivery can be daunting for mentees, and we want to understand their experiences so we can continue to build data science capacity across the government at this challenging time. As a learning organisation, we are not just running courses. We are listening and we are acting; it's not always easy to hear some difficult messages, but far better that we do and change, than not learn the lessons from this extraordinary time in history.]]> One of the goals of the [Faster Indicators](https://datasciencecampus.ons.gov.uk/faster-indicators-of-uk-economic-activity/) programme is to identify new data sources that could provide insight into economic activity at a level of timeliness and granularity not currently possible with official economic statistics. A major component of the UK economy is consumer spending. The Office for National Statistics (ONS) Data Science Campus has been [working with Barclays Plc](https://blog.ons.gov.uk/2017/12/13/using-credit-card-payments-data-for-the-public-good/) for some time to explore the ability of aggregated and anonymised card transactions data to provide significantly quicker and more granular insight into UK consumer spending than previously available. All the data which have been provided to the ONS are strictly anonymised and in aggregated form, so that no one individual or company can be identified in any outputs we produce. Barclaycard data represent all UK spending processed through Barclays Point-of-Sale (POS) terminals and \"card-not-present\" channels such as ecommerce, mail or telephone orders. A rich range of breakdowns are available, including regional data, and these can give close-to-real-time insight into the impact of significant events on spending. While official estimates remain the most reliable source of consumer spending in the UK, these data could be considered as early and supplementary indicators providing insight into economic activities in close-to-real-time. These insights are providing valuable information to assist the ongoing government response to the coronavirus (COVID-19). We have also used the data to [model the International Passenger Survey](https://www.ons.gov.uk/economy/nationalaccounts/balanceofpayments/bulletins/uktrade/may2020#measuring-the-data) (IPS), currently suspended because of the coronavirus. The IPS is the main data source for travel services, making up around 8% of total UK trade. We extend our thanks to the staff of Barclays Plc who have been involved in this project, supporting us to access and understand these data.]]> We are pleased to announce that the [UK Statistics Authority](https://www.statisticsauthority.gov.uk/) is a host organisation for the 2021 Commonwealth Professional Fellowship programme. The Office for National Statistics (ONS) Data Science Campus will develop and deliver the 2021 programme in partnership with several ONS teams and other government departments. We are offering a six-week programme for mid-career analysts from Commonwealth National Statistical Institutes in [countries that are eligible for Official Development Assistance (ODA)](http://www.oecd.org/dac/financing-sustainable-development/development-finance-standards/DAC-List-of-ODA-Recipients-for-reporting-2020-flows.pdf) to enhance their understanding, knowledge, skills and expertise in the field of data science. Our experienced data scientists will provide guided support to Fellows on specific research problems relevant for their country, helping them to drive change within their organisation to produce faster, innovative and more accurate data to inform better decision-making and policy in areas such as climate change and measuring the Sustainable Development Goals (SDGs). The programme offered by the ONS is limited to nationals of an Official Development Assistance (ODA) eligible Commonwealth country who are: 1 February to 12 March 2021, Wales, UK. Please submit your application to the Commonwealth Scholarship Commission team using the [online application form](http://cscuk.dfid.gov.uk/apply/professional-fellowships/commonwealth-professional-fellowships/information-for-candidates/#linkage4). [Further information on the scheme](http://cscuk.dfid.gov.uk/apply/professional-fellowships/commonwealth-professional-fellowships/information-for-candidates/) is also available. Applications for the Fellowships are now open and will close on Monday 3 August 2020 at 4pm BST. For technical content of the programme, please email the [Data Science Campus](mailto:datacampus@ons.gov.uk). For any other queries about the ONS programme, please contact Kirsten Newton, UK Statistics Authority International Relations Team. For general queries about the Commonwealth Professional Fellowships, please contact the [Commonwealth Scholarship Commission](mailto:professional.fellowships@cscuk.org.uk). The adoption of a digital life by individuals, organisations and government departments means that more and more digital data are captured every day. Nearly all these data will have associated metadata, including a time stamp, which gives users a digital diary of activity. Although [the history of patents](https://onlinellm.usc.edu/blog/history-of-patent-law/) extends back to Ancient Greece, the introduction of the computer means that the various patent offices around the world hold digital copies of patent documents in the order of millions (for example, the [US Patent and Trademark Office (USPTO) has patent records](https://www.uspto.gov/patents-application-process/search-patents) from 1976). These electronically stored patents provide a fantastic timeline of innovation around the world. Analysing datasets such as patents can provide invaluable insights. Early identification of emerging technologies can inform decisions by policymakers or other decision-makers prior to large-scale take-up of technologies, components or their adoption into manufacturing processes. This early identification can allow organisations and individuals to allocate suitable resources to address future technological trends and requirements more efficiently. Cheap access to unmanned aerial vehicles (UAVs), such as drones, to the general public for example, meant the UK Civil Aviation Authority (CAA) had to create [a new set of guidance and regulations for users](https://www.caa.co.uk/Consumers/Unmanned-aircraft-and-drones/). However, finding a signal in the noise is challenging. PyGrams aims to tackle this issue, allowing users to extract, visualise and identify emerging terms within large document collections such as, but not restricted to, patents. This project is ongoing, and new updates will be published here when available. Our work here has been developed alongside domain experts at the [Intellectual Property Office (IPO)](https://www.gov.uk/government/organisations/intellectual-property-office). We provide an overview of [pyGrams](https://github.com/datasciencecampus/pyGrams) and how it can be used to extract emerging terminology from documents. We also explore how a time series approach can be used to nowcast term usage. We discuss two methods of analysing the time series of keywords gained from patent documents. We perform a number of experiments to show how these methods can be used to identify emerging and declining terminologies and technologies. You can read more about pyGrams in the previous links or by visiting the [pyGrams GitHub repository](https://github.com/datasciencecampus/pyGrams) or [GitHub document pages](https://datasciencecampus.github.io/pygrams/). They will offer the MDataGov from the 2020 to 2021 academic year as a part-time programme, delivered 100% online. [Individual MDataGov modules](https://datasciencecampus.ons.gov.uk/individual-modules-from-the-msc-in-data-analytics-for-government-mdatagov-programme/) will also be available to study online this summer. The programme offers more flexible learning programmes to our partners and has been developed in response to increasing demand for advanced data science and statistics skills. This is particularly important to support the work we are doing to build data science capability for [international development](https://datasciencecampus.ons.gov.uk/ai-for-international-development/). The University of Glasgow joins current 2020 to 2021](https://datasciencecampus.ons.gov.uk/cardiff-university-joins-the-mdatagov-framework/). All MDataGov providers offer three exit points in the programme: More information is available from each provider's website. The [MDataGov Framework](https://datasciencecampus.ons.gov.uk/capability/msc-in-data-analytics-for-government/) was launched in October 2017 as a collaborative project between the Office for National Statistics (ONS) and UK academic partners. It has been successfully building data science capability across government and internationally, training over 100 public sector workers each year in the important skills required from modern government data analysts. Along with the four core MDataGov modules (Data Science Foundations, Statistics in Government, Sampling Fundamentals and Statistical Programming), the programme at the University of Glasgow covers: The full programme is available on the [University of Glasgow website](https://www.gla.ac.uk/postgraduate/taught/dataanalyticsforgovernment/#tab=apply), and applications for the 2020 to 2021 academic year are now [open](https://www.gla.ac.uk/postgraduate/taught/dataanalyticsforgovernment/#tab=apply). Reduced fees are available for UK public sector employees studying either the full MDataGov programme, or individual modules taken as a standalone course (with or without assessment). The cost for the full MSc is \u00a310,000, and for each individual module is \u00a3556. The University of Glasgow is also offering MDataGov modules through distance learning this summer, subject to demand. The modules listed are available as non-credit-bearing courses (unassessed route) to home and international students. Full courses are priced at \u00a3556 and half courses are priced at \u00a3228. A minimum of 10 registrations per module is required for the courses to go ahead. The modules are: The full [module syllabus, software and hardware requirements](https://www.gla.ac.uk/schools/mathematicsstatistics/postgraduate/mdatagov/courses/) are provided on the university website. To register for a place, please complete the [registration form for individual courses (MDataGov)](https://www.gla.ac.uk/media/Media_721885_smxx.pdf) and send it by email to [maths-stats-analyticscpd@glasgow.ac.uk](mailto:maths-stats-analyticscpd@glasgow.ac.uk). The closing date for applications is 7 June 2020, with several courses beginning on 15 June 2020 and lasting 5 to 11 weeks.]]> Organised by the [International Telecommunication Union](https://www.itu.int/en/Pages/default.aspx) (a United Nations Agency), this year's virtual celebrations will highlight the importance of empowering women through technology and how role models and mentors can inspire girls and young women to take up careers in the tech field. Women such as [Ada Lovelace](https://www.biography.com/scholar/ada-lovelace), a pioneer of computer science, and more recently, [Dr Anne-Marie Imafidon](https://aimafidon.com/about/), the youngest girl ever to pass A-level computing and now founder of [STEMettes](https://stemettes.org/), are inspiring the next generation of girls and young women to make a difference in Science, Technology, Engineering and Mathematics (STEM) fields. At the Data Science Campus we have a team of talented data scientists who have come into the profession from many different backgrounds, sometimes beginning with limited coding experience. Through formal training, mentoring, and working with experienced data scientists on high-profile projects, they are now using their skills to provide important data to make decision-makers at the highest level of government. Harriet Sands is part of our first cohort of Graduate Data Scientists. She talks about her career journey so far, what it's like to work as a data scientist in government and how she would encourage a younger version of herself to get in to data science. At school, although I really liked maths, I preferred learning about systems and structures in society, so I pursued a degree in sociology and anthropology. My degree was very theoretical, conceptual, very hands-off. A change of direction happened for me, whilst at university, I managed to persuade a supermarket analytics company to hire me, despite not having the required \"numerate\" degree! I was fascinated by having such vast amounts of information about people at my fingertips and it was the first time I had ever really been exposed to the kind of data I now handle daily. I decided that I wanted to become a master data analyst (I hadn't really heard of data science then!), and work in government, using data to help inform some of the biggest policy decisions that could help benefit people's lives. But first, I had to become that great data analyst. I got a job in the same industry after graduating and got better at data analysis through hands-on experience, learning that coding wasn't just something to do with the internet, or building computers. Helped by an incredibly supportive manager, I was accepted onto the \" [Data Science for Social Good Fellowship](https://www.imperial.ac.uk/business-school/faculty-research/research-centres/gandhi-centre-inclusive-innovation/key-initiatives/data-science/)\" hosted by Imperial College, where I helped develop a model to detect people at risk of becoming dependent on emergency services. I was then accepted onto the [Data Science Campus Graduate Programme](https://datasciencecampus.ons.gov.uk/the-final-piece-of-the-jigsaw/), where I am now continuing to develop my data science skills, working on challenges that benefit society, with interesting opportunities to collaborate with other organisations, such as the United Nations! The work of a data scientist in government varies hugely. Not only in the Data Science Campus at the Office for National Statistics (ONS), but across many government departments and arms-length bodies. I love being able to turn a tangible thing that exists in the world - such as the movement of ships or changes in surface water - into tools and statistics that are used by thousands of people across the country. A ship coming into a port might not sound very exciting to many people, but it is for me and my team. We are analysing ship activities in almost-real-time, looking at the movement around UK ports as an [early indicator of economic activity](https://datasciencecampus.ons.gov.uk/projects/faster-indicators-of-uk-economic-activity-improving-the-shipping-indicators/). I've also been looking at satellite imagery and how this can be used to [detect surface water changes](https://datasciencecampus.github.io/projects/DSC-128-SDG-6.6.1.-Surface-water/), providing a novel source of data to support the work of the Sustainable Development Goals, both in the UK and internationally. It's really exciting to see these new data sources I've been working on inform research, policy design, and feeding into important decisions that can have a real effect on people's lives on a global scale. I have never really considered myself to be a \"woman in STEM or IT\" but I guess I am. I know there's a huge disparity in the numbers of girls and young women choosing STEM subjects at university, but I think we can also champion more people from different disciplines to get into data science through their own subject. Find a dataset that interests you, or an interesting problem you think could be solved by looking at some data. There are so many online forums to help you along the way, you really don't need formal training to get going in data science. You could be studying media, politics, linguistics, medicine, for example. You just have to be a bit curious! Are you looking to get started in data science? Below are some resources that our teams have found useful and could help you on your journey. This is a limited selection and there are many other resources available that may be more suitable for your own development. Learning resources and networks to help develop your skills Programmes for girls and young women Programmes run by the Data Science Campus and partner organisations Data Scientist Career Pathway in government Other learning resources and programmes The MDataGov framework was launched in October 2017 as a collaborative project between the Office for National Statistics (ONS) and a range of UK academic partners. The programme has been very successful in building data science capability across government by training more than 100 public sector workers every year in the key skills required from a modern government data analyst. Current MDataGov providers are [University of Southampton](https://gss.civilservice.gov.uk/wp-content/uploads/2017/07/MSc-Data-Analytics-for-Government-at-University-of-Southampton-v2-13July2017.pdf), [Oxford Brookes University](https://www.brookes.ac.uk/courses/postgraduate/data-analytics-for-government/) College offer the MDataGov as a full-time one-year programme beginning in the 2020/2021 academic year, with part-time options being available for the 2021/22 academic year. The programme consists of four core modules (Data Science Foundations, Statistics in Government, Survey Fundamentals and Statistical Programming) and a range of optional modules in data science and statistics. These include Time Series and Forecasting, Applied Machine Learning, Distributed and Cloud Computing, Data Visualisation, among others. Employees of the UK public sector are eligible to study the full MSc at a discounted price of \u00a38,730 (for study during the 2020/21 academic year). The four core modules will also be offered as assessed [standalone courses](https://www.cardiff.ac.uk/study/postgraduate/taught/standalone-modules/data-analytics-for-government) from 2020/2021 and the price is \u00a3550 per module. More information about the optional modules can be found [on the Cardiff University website](https://www.cardiff.ac.uk/study/postgraduate/taught/courses/course/data-analytics-for-government-msc). This course will form part of the new [Cardiff University Data Science Academy (DSA)](https://www.cardiff.ac.uk/data-science-academy), established in October 2019 to support the education of the next generation of experts in the fields of Data Science, Artificial Intelligence and Cybersecurity. Applications will open in June 2020 via Cardiff University's website. For more information, please contact the [Cardiff University admissions team](mailto:admissions@cardiff.ac.uk). Our colleagues at the ONS have started publishing [new data and analysis](http://www.ons.gov.uk/coronavirus) including the [counts of deaths involving COVID-19](https://blog.ons.gov.uk/2020/03/31/counting-deaths-involving-the-coronavirus-covid-19/) and a new, weekly release containing data and [experimental](https://www.ons.gov.uk/methodology/methodologytopicsandstatisticalconcepts/guidetoexperimentalstatistics) indicators about the [condition of the UK society and economy](https://www.ons.gov.uk/peoplepopulationandcommunity/healthandsocialcare/conditionsanddiseases/bulletins/coronavirustheukeconomyandsocietyfasterindicators/dataasat2april2020). At the Campus, we are exploring new data sources to strengthen the information that we have through surveys and other sources. These assist the government in several ways, such as providing more timely indicators in assessing the impact of social distancing, identifying the number of people in self-isolation, understanding changes to trade in goods and assessing the impact on businesses. One such data source is the set of global [Community Mobility Reports](https://www.gstatic.com/covid19/mobility/2020-03-29_GB_Mobility_Report_en.pdf) published by Google on 29 March 2020. These reports show the changing levels of people visiting different types of locations for areas around the UK and other countries. The data provides insight into the impact of social distancing measures, and are created with aggregated, anonymised data from users who have turned on the Location History setting (off by default). We have extracted the data from these reports for the UK and other countries and made these publicly available along with our code-base. This means users around the world can reuse the data in their work to support the COVID-19 response. A Python tool has been used to extract trend data from the graphs, and we have made this [tool](https://github.com/datasciencecampus/mobility-report-data-extractor) and the [data](https://github.com/datasciencecampus/google-mobility-reports-data) available on Github. We are also working with other government departments to deliver new insights and infrastructure vital to the COVID-19 response. We will continue to provide updates on this work alongside other projects and will publish more over the coming weeks. Of course, all ONS work is subject to appropriate safeguards and all our new projects are subject to ethical review to ensure that these safeguards are in place. Finally, we are making our core data science courses available online for ONS colleagues through the ONS Learning Hub on a self-learning basis. We will extend these to the Government Statistical Service (GSS) soon, with guided online learning from our data science lecturers to follow. We are also working to make our courses available for a wider government and international audience as soon as possible. We are reviewing a wide range of existing online and distance learning programmes that will complement these. Last month we marked the three-year anniversary of the Campus. In due course we will look back at the impact that we've had, but right now our focus is on doing everything possible to inform the UK response to COVID-19. The need for rapid data, analysis and insight means that the Campus work is supporting the biggest decisions - \"data science for public good\".]]> Our latest project investigates the use of machine learning techniques to predict missing energy performance scores. It also attempts to create a complete picture of the energy efficiency profile for domestic properties in Wales. We have produced a [report](https://datasciencecampus.ons.gov.uk/projects/using-machine-learning-to-predict-energy-efficiency) reviewing the data sources and techniques used. We are also making the code relating to this project available in a [Github repository](https://github.com/datasciencecampus/energy-efficiency) About 53% [1](#Footnote1) of properties in Wales do not currently have energy efficiency information. This gap in reporting makes it harder to achieve the Welsh Government's [ambition to reach net-zero carbon emissions by 2050](https://gov.wales/sites/default/files/publications/2019-07/independent-review-on-decarbonising-welsh-homes-report.pdf) in Wales. For this initiative to succeed, buildings will need to operate at close to zero emissions, as stated in [Prosperity for all: A low carbon Wales](https://gov.wales/sites/default/files/publications/2019-06/low-carbon-delivery-plan_1.pdf). [The UK residential sector accounts for 18% of greenhouse gas emissions](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/790626/2018-provisional-emissions-statistics-report.pdf), which come predominantly from heating homes, so an improvement in home energy efficiency in Wales could significantly help reach the net-zero carbon emissions target in the next three decades. [Results of our work showed that, although the current data sources do not give a conclusive answer, access to further supplementary data sources could enable machine learning techniques to predict (impute) the missing energy performance scores for domestic properties in Wales more effectively.] Footnote One of the most common misconceptions about apprenticeships among parents and young people is still that apprentices are \"just employed to make the tea\". If only, as I really like tea! I don't hire apprentices to make the tea. I hire apprentices because I want someone who is passionate about learning, numbers, statistics, data science and, perhaps most importantly, someone who is passionate about making a difference. When the Data Science Campus [first started their apprenticeship journey](https://datasciencecampus.ons.gov.uk/hello-we-are-the-data-science-campus-apprentices/) in 2016, it was through the delivery of the Level 4 Data Analyst Apprenticeship. That was a huge success; 12 apprentices graduated through the programme, and all [went on to secure permanent positions](https://datasciencecampus.ons.gov.uk/the-first-data-analytics-apprentices-where-are-they-now/), the majority of them on promotion. Throughout their time with us, the apprentices worked and contributed on many data science projects. In 2019, two of our graduates were recognised for their success: Charlotte O'Brien achieved the [Vocational Qualification Higher Apprentice of the Year](https://vqday.wales/2249/vocational-qualification-awards-winners-take-centre-stage/) for her outstanding work both in the Data Science Campus and in her business area. Joe Peskett was a finalist in the Tomorrow's Talent category at the [National Apprenticeship Awards in Wales](https://gov.wales/apprenticeship-awards-cymru/winners-and-finalists/2019-awards), and was commended for his fantastic contribution to the Urban Forest project. The next step was to introduce the into the [Level 6 Data Science Degree Apprenticeship](https://datasciencecampus.ons.gov.uk/innovative-data-science-degree-apprenticeship-for-wales-launches/) into the campus. I was proud to lead a Trailblazer Group (a group of employers from a variety of universities and private sector organisations) to [develop a new degree apprenticeship standard](https://datasciencecampus.ons.gov.uk/trailblazing-degree-apprenticeships/). The Welsh Government incorporated data science as part of their trail, and provided funding for the delivery of degree apprenticeships. This was an exciting and unique opportunity to collaborate with Cardiff Metropolitan University (our provider), the Welsh Government, and other government departments to develop a degree that would bring the apprenticeship standard alive and develop the data science knowledge, skills and behaviours that employers truly need. The Data Science Campus welcomed its first intake of four apprentices in March 2019 and they started their degrees in September. So, are our degree apprentices making the tea? They share their progress and the difference they are making at the Data Science Campus. \"Prior to the apprenticeship, I was working in a laboratory analyst role. I enjoyed my work there, but eventually it became evident that the long-term prospects were limited. Friends alerted me to the advertisement for the degree apprenticeship position. I felt that this could be a chance for me to re-train, without the financial burden that re-training usually carries. \"My first 10 months have been extremely rewarding, and have changed my expectations of what an apprentice is. I came into the job expecting to be working on small \"busy work\" tasks, but I've hit the ground running and started picking up useful skills almost instantly. I've also been asked to contribute my own opinions to how a data science project evolves, and the Data Science Campus has treated me as a part of the team from day one.\" \"I applied to the degree apprenticeship program having previously studied chemistry at university. I enjoyed analysing data and seeing how it can challenge people's perceptions in different areas, and thought the apprenticeship course would give me the opportunity to learn these skills and apply them in a real-world environment. \"Being an apprentice at the ONS has been a fantastic experience! I can work alongside experienced data scientists on projects using real-world datasets, learning how to apply the skills and techniques I learnt at university, and make a positive impact with data. My colleagues are always happy to talk through something I don't understand and are genuinely interested about the assignments we are set for university\". \"I studied mathematics at the University of Exeter. After I graduated I got a job at HMRC, but in that job I missed using the logic and problem-solving skills used in maths. \"The degree apprenticeship was exactly what I was looking for - a job using the same sorts of logical and problem-solving skills used in mathematics, and with real-world impact. I had very little experience of coding, but felt an apprenticeship would give me the opportunity to learn. \"During the week I spend one day studying at the university campus and the rest of the week at the Data Science Campus, working on projects alongside experienced data scientists. This gives me practical experience of using data science techniques, rather than just an academic understanding and knowledge of them.\" Why am I passionate about degree apprenticeships? Because they give people options. Options to study for a degree without the financial commitment, options to work alongside and learn from experienced data scientists. Options to start your career journey in a fast-moving environment and profession. Options to not make the tea, but to make a real difference. Want to know more? As part of National Apprenticeship Week, Alex Lardner (ONS' Head of Early Talent) explains how apprenticeships are [making an impact across ONS](https://blog.ons.gov.uk/2020/02/04/making-an-impact-with-apprenticeships-at-ons/). I worked at the NSA for three years leading the data processing team responsible for application development, database and data processing for all national surveys and censuses. During this time, I was always motivated to keep up to date with the trending techniques, methods and tools in the data analytics environment, such as the use of machine learning and natural language processing. With data science being such an emerging global discipline, the idea of studying overseas excited me, so I applied for and was granted a Chevening Scholarship, funded by the UK Foreign and Commonwealth Office (FCO), which gave me the opportunity to complete an MSc in Data Science at the University of Salford. As part of my master's degree, I had to complete a data science project, tackling a real data challenge. Through a mutual relationship between the NSA and the UK Office for National Statistics's (ONS) International Development team, I was fortunate to receive a three-month mentorship for my dissertation at the ONS Data Science Campus, based in Newport, South Wales. Namibia, like other developing countries, is often faced with various constraints when undertaking frequent data collection surveys and the census, leading to data gaps in reporting progress on the Sustainable Development Goals (SDGs). These data shortages present major challenges for African nations when responding to current issues and tackling problems. Agricultural statistics is one of the most affected areas because of the significant labour and cost involved in data collection. In Namibia and the rest of Sub-Saharan Africa, smallholder farmers who depend on crop production for nutrition and as the main source of household income are the most affected, with few statistics available to policymakers to account for their land use and crop production. It is crucial that African statistical institutions find more data-driven, innovative methods to tackle challenges. The objective of my study was to explore the potential use of Earth observation data to complement official agricultural statistics. The study integrated the use of Earth observation data, data science tools and techniques to extract statistics, such as land use, estimate plot areas and build a machine learning model for crop yields estimates on small farms. I used the Sentinel 2 satellite imagery from the European Space Agency (ESA) and to calculate vegetation indices, time series and ratios to detect crop or non-crop land. The findings show a promising start towards building a crop yield model, but the main constraint was the lack of ground truth data, so this had to be estimated using data sources with similar signature profiles. The statistics extracted are aimed at addressing the following Sustainable Development Goal (zero hunger) indicators: During my time at the ONS, I have been exposed to many opportunities, such as attending data science conferences, in-house training, visits and mentorship. Here, I have learned that data are treated as a service, tailor-made to different clients according to their needs. These are my main takeaways and what I believe are practices that could benefit many African statistical offices. Introduce training programs such as mentorships, graduate schemes and other short-term coaching opportunities, which allow theory and practice integration. This gives students the opportunity to access data for research and to work on real-life problems. Developing automated statistical production pipelines frees up more room for value-added data product deliverables, shortens lead times, creates reusable algorithms and improves documentation. For instance, if a statistical office can move towards using open-source programming languages, such as Python and R, they can redirect these funds onto training and the development of new data science techniques and methods. Making use of big data from various sources to create insights and help solve challenges faced by African countries. This will not happen overnight; data science is a new field, so constant research needs to be carried out to identify, compare and adopt techniques to fit the local context. Collaborating with other offices means that resources, best practices and skills can be shared among the data science community. A close working relationship with fellow National Statistics Offices (NSOs), local universities and the private sector is crucial for creating robust data-driven solutions. Sharing resources, experiences and complementing each other's skills in specialised areas can help African statistical offices to move forward in this era of data revolution, and it also avoids doubling up on work that has already been done by other statistical offices. Although the NSA is new, a lot of work has been done to ensure good quality statistics are being produced and that we are operating within the international statistical framework, policies and guidelines. The Agency has recently completed the General Statistical Business Process Model (GSBPM) assessment with the aim of aligning itself with the standards of the statistical value chain. Moving forward, I would like to see Namibia adopting more robust and coherent automated reproducible pipelines to improve efficiency and help us produce better statistics. With the use of data science, statistical offices have an opportunity to tap into various data sources available to bring new insights and make a profound difference when tackling social and environmental challenges faced in the African continent. Upon my return to Namibia, I will work to strengthen relationships with academic institutions. I believe collaborative work among NSOs, to build a cross-government data science community, will place African countries in a better place to progress towards becoming a data-driven nation and ensuring that no one is left behind.]]> The [report published today](https://www.ons.gov.uk/economy/environmentalaccounts/articles/sustainabledevelopmentgoalstakingstockprogressandpossibilities/november2019) by the Sustainable Development Goals team at the Office for National Statistics shows tremendous progress has been made in the UK by publishing headline statistics against three-quarters of indicators. However, for a number of the remaining indicators, new sources of data still need to be determined or methods found to provide data at a sufficient level of quality and granularity. This presents a worthy challenge for data science which we, at the Data Science Campus, have taken up with our colleagues in the Sustainable Development Goals team. One of the first Campus projects was to work with with the SDG team to develop a reusable platform to visualise the reporting status of the [Sustainable Development Goals in the UK](https://sustainabledevelopment-uk.github.io/). Now known as [Open SDG](https://open-sdg.readthedocs.io/en/latest/), the platform is the result of collaboration between the ONS, the US government and the non-profit Centre for Open Data Enterprise (CODE). Two years later, the project has been scaled up and there are now more than 10 countries using the Open SDG solution for reporting their SDG data, with interest from others. These countries include: The project is being further developed into a fully-fledged website by the Open SDG community. Since then, we've been helping to tackle the gaps in reporting in three main ways: Exploring the use of novel data sources to measure specific indicators The SDGs are a global challenge and are, in some cases, not aligned with current national data collections which are based on their relevance to UK policy issues. Reusing existing statistics or conducting new data collection campaigns can be difficult so innovative solutions using big data and alternative data sources are being explored. Our exploration of global, open, geospatial datasets are examples of this. Indicator 9.1.1. measures the proportion of the rural population in a country that can conveniently access the road network in all seasons. While we have good data for measuring this indicator within Great Britain, making international comparisons is more difficult. [Working with our colleagues in ONS Geography](https://www.ons.gov.uk/economy/environmentalaccounts/articles/usinginnovativemethodstoreportagainstthesustainabledevelopmentgoals/2018-10-22), we have investigated using global datasets such as Open Street Map, the Global Roads Inventory Project, and the Global Human Settlement Layer for this purpose. Indicator 6.6.1 tracks changes in the spatial extent of water-related ecosystems such as inland open waters. The need to understand how such systems have changed over time makes this a difficult indicator to measure with conventional mapping data. We have been [investigating the use of the Global Surface Water dataset](https://datasciencecampus.github.io/projects/DSC-128-SDG-6.6.1.-Surface-water/) for this purpose. Critical in each of these cases has been assessing quality of the datasets for the purpose of producing statistics. To do this we are investigating how quality assurance frameworks, [Quality Assurance for Administrative Data](https://www.statisticsauthority.gov.uk/osr/what-we-do/systemic-reviews/administrative-data-and-official-statistics/) (QAAD) and European Statistical Systems (ESS) [dimensions of quality](https://ec.europa.eu/eurostat/documents/64157/4392716/ESS-QAF-V1-2final.pdf/bbf5970c-1adf-46c8-afc3-58ce177a0646) can be applied to account for the novel and geospatial nature of these sources. Developing cross-cutting data science methods and tools to support measurement and disaggregation A principle of the SDGs is \"leave no one behind.\" Data science aims to help develop disaggregated indicators to ensure that those at risk of disadvantage because of their characteristics, location, or socio-economic status are recognised. This is a significant challenge as many statistics are currently only available at a headline national level. Data Science can look to address this through modelling against alternative data sources. For instance, accessibility is an issue that appears in several SDGs and which varies substantially among different groups. For example, indicators 1.4.1 and 3.8.1 relate to those with access to basic and health services, and indicators 9.1.1 and 11.2.1 relates to those with access to transport infrastructure. The Campus has developed a [reusable tool](https://datasciencecampus.ons.gov.uk/access-to-services-using-multimodal-transport-networks/) that uses open transport data and tools to determine how accessible service locations are for dispersed communities. We are working with the SDG team to explore how this tool could be applied to these indicators. Providing data and insight to support policies aimed at achieving the goals Data science can help support complex policy issues through the development of innovative new statistics. For example, improving our valuation of [green space in urban residential gardens](https://datasciencecampus.ons.gov.uk/projects/green-spaces-in-residential-gardens/) can inform policies aimed at progressing SDGs such as Goal 11, to make cities and human settlements inclusive, safe, resilient and sustainable, and Goal 13, to take urgent action to combat climate change and its impacts. However, the age and frequency at which indicators are published may mean that they cannot be used to drive early policy interventions or make operational decisions. This is an issue recognised by the recent establishment of the [Data For Now initiative](http://www.data4sdgs.org/initiatives/data-now). The [Global Surface Water dataset](https://www.sdg661.app/home) allows indicator 6.6.1 to be measured with a high accuracy across the world, but because of the complexity in producing it, changes are only reported annually. This means it is unable to provide early identification of emerging issues in the distribution and quantity of available water caused by events such as climate change, drought, flooding, or human activities. We are working with the UN Environment Programme to explore whether high-resolution, near real-time satellite imagery can address these limitations to provide rapid assessments of emerging issues and localised assessments in various countries. Continuing to build capability in data science The principle to \"leave no one behind\" could equally refer to the technological gap that limits developing countries to measure and report against the SDGs. Recognising this, we have looked to [help build capability in data science](https://datasciencecampus.ons.gov.uk/data-science-capability-for-africa/), and to favour solutions that have a capacity for reuse through the [UN Global Platform for Official Statistics](https://marketplace.officialstatistics.org/?utm_source=Data%20Science%20Campus%20blog&utm_medium=blog&utm_campaign=Data%20Science%20for%20Sustainable%20Development). For example, by providing worldwide access to global geospatial and earth observation datasets, as well as sharing the resulting algorithms and methodology via the methods service. In recent months, we've also welcomed the first recruits to our [AI for International Development hub](https://datasciencecampus.ons.gov.uk/ai-for-international-development/). The hub will enable us to scale up our work across the SDGs. The SDGs represent one of the greatest data challenges of our age. In addition to reporting, data must drive the policy changes and early action to see the SDGs achieved. Data science is essential to this effort by drawing new insight from novel data sources, and improving methods that can be shared and reused so that no one is left behind. Our work with international collaborations will help ensure solutions to such complex issues remain relevant and fit-for-purpose by a global audience.]]> The winners, Nina DiCara (Bristol University) and Tiff Massey (Ernst and Young), created novel metrics looking at the relationship between loneliness and movement for education and developed a 'school desirability score' (SDS) to model the quality of schooling in each area. Recent research has shown that loneliness is a common underlying factor for many illnesses and, whilst a direction of causality has not been established for this association, it has prompted an increased interest in understanding loneliness in our population. The ONS Data Science Campus has developed a ' [Loneliness Index](https://datasciencecampus.ons.gov.uk/developing-a-loneliness-prescription-index/)' which determines the levels of loneliness associated with each GP practice in England, using prescribing data for loneliness-related illnesses. This data is available for the years 2016 to 2018. The [data challenge](https://www.bristol.ac.uk/golding/get-involved/competitions/loneliness-and-movement-for-education-competition/) by the ONS and the Jean Golding Institute at the University of Bristol tasked us with exploring whether there was an association between the Loneliness Index scores and movement for the purposes of education. Details of the datasets and code used in this report can be found on our [GitHub repository](https://github.com/ninadicara/ons-data-challenge-2019). To develop our research question, we first considered the main reasons why people move for education: Bearing this in mind, we assumed that in most cases, movement for primary and secondary education is associated with upward social mobility. That is, moving to try to get into a better school than is available in the local area. Using this assumption, we decided to pursue the following research question, which is concerned with the movement of primary and secondary school children, and their families: \"Is community-level loneliness associated with the quality of local schools, and how far can this be attributed to the movement of families pursuing upward social mobility through education?\" To answer our research question using [open data](https://github.com/ninadicara/ons-data-challenge-2019#data-sources) we decided to create two new metrics: The first concern was how to model the movement of people so that it was representative of movement for education. We theorised that if loneliness was being created by frequent changes in communities due to very good or very poor education in the local area, then the net migration score would not represent this. For instance, if half the population moved away, and an equivalent number moved in the net migration would be zero, despite there being a huge change in the community. So, we decided to model population change as the sum of the inflow and outflow of people, against the total population. In order to capture those moving for primary and secondary education, in Figure 1 we decided to consider the movement of just 5 to 14-year-olds. We did not include 14 to 19-year-olds as this would capture the huge volume of people moving to university each year. Next, as shown in Figure 2, we developed a 'School Desirability Score' (SDS), to model the quality of schooling in each area. Using the [open data](https://github.com/ninadicara/ons-data-challenge-2019#data-sources) available we identified four variables which may relate to the quality of education, and thus its desirability. We standardised the variables, and then combined them to create an overall SDS for each school, and thus an overall score for each Local Authority. To demonstrate how these scores can be used to describe features of a local authority, Figure 3 shows the Mean Absolute Deviation (MAD) in SDS within Local Authorities, to give a sense of which local authorities experience a greater range of educational opportunities within their borders. Then, in Figure 4 there is an overview of how the population mobility varies between local authorities. You can see that some local authorities experience much more movement of young people relative to their populations, for instance Barking and Dagenham. After producing and exploring these metrics, as shown in Figure 5, we were interested to know whether Population Mobility could be explained by SDS. A linear regression model of this relationship (with three outliers removed) shows that whilst there is a significant (p < 0.005) positive association between these variables, SDS only explains a very small amount of the variance in population mobility. Prior to analysing the relationships between our scores and loneliness we mapped all the data to Local Education Authorities (LEAs) and removed some influential observations from the dataset. Particularly influential results came from areas with population mobility and/or had all the data we needed for 2017, we only included 2017 data in the analysis. Following removal of influential outliers, initial data exploration showed some interesting results that we were not expecting. For instance, that loneliness and the Index of Multiple Deprivation (IMD) score were not associated (p = 0.80, R2 = 0.000009), and neither were SDS and IMD (p = 0.45, R2 = 0.00008). We were expecting IMD to play an important role (positive or negative) in loneliness but were interested to find this was not the case. It did quickly become clear, though, that Urban/Rural classification was very relevant to loneliness. In Figure 6, we explored the use of our new measures by running linear regression models of the loneliness z-score developed by the ONS against the SDS and the population mobility for 5 to 14-year-olds. We found there was a small but highly significant association, with both the SDS (p < 0.001, adj R2 = 0.001) and population mobility scores (p < 0.001, adj R2 = 0.01). This suggests that the movement of school-aged children, and the educational quality available, have an impact on the loneliness in an area. It makes sense that these factors only explain a small amount of the variance, since a huge number of factors impact on loneliness in any one place, but the significance shows that movement for education may play a part. First, we ran the following multiple regression model: Loneliness Z-Score ~ SDS*Population Mobility + IMD + Urban/Rural + LEA Population We still saw that population mobility is highly significant (p < 0.001) with a small positive association, whilst SDS is no longer significant (p = 0.097). Urban/rural appears to exert the most influence on the model, which again suggests that whilst movement for education is important, it is not the most important factor in area-level loneliness. The adjusted R2 of this new model was 0.03. Next, we wanted to account for the hierarchical data structure that is inherent in the data we made, where GP level information is nested within LEAs. Here the data from 2016 was reintroduced. To manage this, we built a linear mixed model, with random effects that accounted for the nesting structure of GP within LEA. An ANOVA on the nested vs un-nested structure showed that the nesting structure was significant, so we produced the following: Loneliness Z-Score ~ SDS*Population Mobility + (1 | LEA / GP ) This model showed us that when random effects are accounted for in the model, the Population Mobility is still a significant addition to the model (t = 15.20), with a small positive association between mobility of 5 to 14-year-olds and loneliness. SDS is once again not significant in this model. The intra-class correlation coefficients for the groups are given below: |Group||ICC| |GP with LEA||0.66| |LEA||0.17| These show that the groupings are fairly ineffective for LEAs, but moderately effective for GPs within LEAs. Finally, we modelled the data using a decision tree. We were interested in how the decision tree would use the Population Mobility data and the SDS to make decisions on grouping loneliness in the data set. We ran the following model, using data aggregated to LEA level for 2017: Loneliness Z-Score ~ Population Mobility + SDS The decision tree has two levels, which correspond to the two variables. As shown in figure 7, for Local Authorities with Population Mobility less than 8.1 (which is around the mean), loneliness is relatively close to the population average. For those with high Population Mobility (above the mean) and better SDS scores loneliness appears higher than those with poor SDS scores. We have explored several models and created novel metrics to explore the relationship between loneliness and movement for education. We found that the population change caused by the moving of children aged 4 to 15 has an impact on loneliness in communities, though not a big one. We could hypothesise that the reason that children of this age move mostly to pursue better educational opportunities and so movement for the purpose of education in primary and secondary students is associated with loneliness. The decision tree suggests that places with 'better' schools (higher SDS) who experience high turnover of children, are more likely to be lonely than those with low turnover and those with high turnover and poorer schools. This would support our hypothesis that families moving into areas with better schools for upward social mobility through education creates more loneliness in those areas. We think it would very interesting to fully model the flow of people within the UK using metrics such as Population Mobility and a form of education desirability for all levels of education to get a better understanding of this phenomenon. However, there are some limitations in this open government data that would need addressing: For code and data please see our [GitHub repository](https://github.com/ninadicara/ons-data-challenge-2019). Nina DiCara, Bristol University Tiff Massey, Ernst and Young ]]> This article summarises the initial work we have carried out, exploring 3 datasets: HM Revenue and Customs (HMRC) Value Added Tax (VAT) returns, Ship tracking data from automated identification systems (AIS) and Road traffic sensor data for England. We publish this work as a monthly research output. The first report was published on 15 April 2019 and you can find the latest release and data on the [ONS website](https://www.ons.gov.uk/economy/economicoutputandproductivity/output/articles/economicactivityfasterindicatorsuk/previousReleases). The appetite for faster information on UK economic activity has never been higher. Policymakers and analysts demand faster insight into the state of the UK economy in order to make informed, timely decisions on matters, such as the setting of interest rates, which affect the whole UK. This was noted in the [Independent Review of UK Economic Statistics](https://www.gov.uk/government/publications/independent-review-of-uk-economic-statistics-final-report) (Bean, 2016), which stated that \"the longer a decision-maker has to wait for the statistics, the less useful are they likely to be\". With the growing availability of big data and large administrative datasets, and the tools, technology and skills to understand and process these, National Statistics Institutes are being challenged to produce outputs that meet the growing demand for more timely data. It is important to note that we are not attempting to forecast or predict gross domestic product (GDP) or other headline economic statistics here, and the indicators should not be interpreted in this way. Rather, by exploring big, closer-to-real-time datasets of activity likely to have an impact on the economy, we provide an early picture of a range of activities that supplement official economic statistics and may aid economic and monetary policymakers and analysts in interpreting the economic situation. Although some of the indicators we have developed track GDP and other economic statistics relatively well over some periods, there is sufficient difference that none should be used to predict GDP on their own. Rather, they should be considered early warning indicators providing timely insight into real activities in the economy, and their potential impact on headline GDP should be carefully interpreted. It may be that these indicators have the power to improve the performance of nowcasting or forecasting models, as components of these models, but we have not as yet tested this. We are now publishing [regular, monthly updates](https://www.ons.gov.uk/economy/economicoutputandproductivity/output/articles/economicactivityfasterindicatorsuk/previousReleases), as research outputs using the most recent available data. We [welcome feedback](mailto:Faster.Indicators@ons.gov.uk) on this work. A full description of the data, methodology and economic analysis, describing the time series, and the full datasets, can be found in the following articles: Section 2 outlines the data sources and methodology used to construct our new indicators. Key findings are presented in Section 3. In Section 4, we present our proposals for regular publication, including our proposed publication schedule. Finally, in Section 5, we suggest some future work for the project. This work is the first output from the project. As well as our proposals to extend the work on these data sources outlined in Section 5, we hope also to explore additional timely big data sources to supplement this work. In this section, we briefly describe the data and the indicators we have constructed. The proposed timetable for publication is presented in section 4. Most of our new series will be available one month before the corresponding official GDP estimate. We have constructed several monthly and quarterly [diffusion indices](https://www.investopedia.com/terms/d/diffusionindex.asp) from turnover and expenditure VAT returns. We have produced some novel indicators tracking changes in VAT reporting behaviour. These include: We have also constructed a proxy for firm births, based on new VAT reporters. Where possible, we have also created industry breakdowns of the new series. Turnover diffusion indicators are available from 2008. Expenditure-based diffusion indicators are available from 2013, and indices of reporting behavior are available from 2007. The diffusion indicators track firm turnover and expenditure growth, both important components of the economy. We explore whether VAT reporting behaviour changes under conditions of economic stress. For example, we might expect that during an economic downturn, turnover will be lower, and more firms might apply for VAT repayments. Figure 1 shows that the VAT turnover index does indeed capture the last recession quite well, but is less good at tracking small changes in GDP during periods of greater stability. A full description of the data, methodology and analysis of the VAT indicators is presented in ' [Faster indicators of UK economic activity: Value Added Tax returns](https://datasciencecampus.ons.gov.uk/projects/faster-indicators-of-uk-economic-activity-value-added-tax-returns)'. Quarterly and monthly indicators will be available one month (v1)before the official GDP estimate. A second \"vintage\" of the monthly diffusion indices (v2), taking advantage of increased numbers of returns, which is therefore potentially more robust, will be available in the same month as GDP. The automatic identification system (AIS) tracks ship location every few seconds whilst the ship is moving and every couple of minutes whilst it is in port. AIS is compulsory for all ships above 300 gross tonnes, and all passenger ships, and it is used voluntarily by many other vessels. In this work, we analyse two years of AIS data (July 2016 to August 2018) for UK ports, obtained from the [Maritime and Coastguard Agency](https://www.gov.uk/government/organisations/maritime-and-coastguard-agency). A full description and analysis of this is presented in ' [Faster indicators of UK economic activity: shipping](https://datasciencecampus.ons.gov.uk/projects/faster-indicators-of-uk-economic-activity-shipping)'. We also currently have access to real-time data from [ORBCOMM](https://www.orbcomm.com/), via the [United Nations Global Platform](https://www.officialstatistics.org/). We use the data to construct monthly indicators of the time spent in port by ships, and the frequency of visits to ports, for the 10 largest ports in the UK. These indicators are likely to be important in supplementing our understanding of international trade activity. They offer a fast indication of the level of shipping activity, which is, as we show, related to trade in goods, by individual port. We compare data for July 2016 to August 2018 to official statistics for gross value added (GVA) and trade statistics. We find a surprisingly good correlation between the shipping indicators and imports, particularly given the noisy nature of these variables. The Pearson correlation coefficient for the port traffic indicator and estimates of the import of trade in goods is 0.64. However, care must be taken in the interpretation. We do not have a sufficiently long time series to be able to seasonally adjust it and this is likely to have an impact on the correlation. Furthermore, as we see in Figure 2, although the overall correlation is reasonably good, individual points can deviate strongly. For these reasons, we do not recommend interpreting these indicators on their own as predictors of GDP or other headline economic statistics, although they do offer a fast indication of the level of shipping activity, which is, as we show, related to trade in goods, by individual port. The relationships between port traffic and international trade in goods could potentially be used in a mathematical model in combination with other indicators to estimate trends in trade. Given the fact that AIS can be obtained in timely fashion, in fact in near real time, the output of such a model can be a valuable tool for early economic trend discovery. These monthly indicators will be available one month in advance of official GDP estimates. We have used road traffic count data for England, from January 2007 to December 2018, published by [Highways England](http://tris.highwaysengland.co.uk/) to construct monthly indicators of average traffic counts and average traffic speeds for the whole of England and 13 main English ports. Understanding road traffic is clearly important for understanding domestic and international trade in goods in the UK economy. Our new indicators offer the opportunity to do this in a timely way, and for localised geographies. Furthermore, they also have the scope to offer a new understanding of the supply potential of the UK, and how traffic by different types of vehicle relate to local economic activity involving the transport of goods and people. Traffic activity around ports is of particular interest, as this may offer further insight into understanding the potential impacts of delays on trade and other economic activity. We find that the road traffic counts give us some interesting insights into road transport in England. Although correlations are weak, the average traffic counts for the largest vehicles are consistent with at least some economic events (the financial crisis), and the trend broadly follows that of headline official economic statistics, although care must be taken with interpretation. As we see in Figure 3, there is not a strong relationship between road traffic counts and GVA, and there is a large scatter. For this reason, we do not recommend interpreting these indicators as predictors of GDP or other headline economic statistics. A full description and analysis of this is presented in ' [Faster indicators of UK economic activity: road traffic in England](https://datasciencecampus.ons.gov.uk/projects/faster-indicators-of-uk-economic-activity-road-traffic-data-for-england)'. The indicators will be available in the same month as official GDP estimates, although we will investigate whether we can access the data faster, and reduce this time lag to one month. We have successfully identified a range of big data and administrative datasets, which have allowed us to construct useful, faster indicators of some types of economic activity. We have shown these are able to identify large changes to economic activity, and they may be used to provide insights to supplement and precede official economic statistics. However, some care should be used in interpreting the indicators, and they should not be considered a proxy for gross domestic product (GDP). Figure 4 shows the proposed publication schedule. Most of the majority of the new indicators are available one month in advance of official gross domestic product (GDP) estimates. The first publication is planned for mid-April 2019, with an article setting out the full set of faster indicators of UK economic activity (covering those based on VAT returns, road traffic data and shipping) and the format of the publication to be released in advance. Figure 5 presents the heatmap we propose as the headline output for the new indicators, shown for the VAT turnover diffusion indices. The colour scheme is defined in Table 1. The bands are derived from standard deviations from the mean of the diffusion indices, but it should be noted that i. the data are not normally distributed and ii. the thresholds have been set based on visual inspection of the data. We will continue to monitor the suitability of these bands as new data is added. We intend to add other indicators to the heatmap, which may then act as a warning panel for the economy: one amber square in a period may not be too much of a cause for concern, but a full set of red squares might require further investigation. White denotes where no data are available. We also plan to make the time series available at the same time as the heatmap in the regular publication. The data for the indicators presented in Figure 5 can be found in the ' [Faster indicators of UK economic activity: dataset](https://datasciencecampus.ons.gov.uk/wp-content/uploads/sites/10/2019/03/Faster_indicators_of_UK_economic_activity_combined_dataset_v2.xlsx)'. We anticipate our first regular monthly publication using the most up-to-date data to be published in mid-April 2019. Some potential areas for future work include: We welcome feedback on this work, which can be addressed to: [Faster.Indicators@ons.gov.uk](mailto:Faster.Indicators@ons.gov.uk). In January 2019 we published a [report](https://datasciencecampus.ons.gov.uk/projects/understanding-the-characteristics-of-high-growth-companies-using-non-traditional-data-sources/) exploring how non-traditional data sources and data science methods can be combined with more conventional business data to help understand the characteristics and behaviours of high-growth companies. In this update, we add in an additional dataset - the [Office for National Statistics (ONS) Management and Expectations Survey (MES)](https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/labourproductivity/articles/experimentaldataonthemanagementpracticesofmanufacturingbusinessesingreatbritain/2018-04-06) - to further explore the potential for identifying characteristics. In Figure 1 observations from our initial work showed that the term \"management\" seems to be used more by high-growth companies in descriptions, news articles, bios and job adverts on their websites. This raised the question of whether high-growth companies use specific or structured management approaches. We explored the relationship between management practices and high-growth by merging the responses from the MES with the Department for Business, Energy and Industrial Strategy (BEIS) high growth flag. High-growth is defined using the standard [OECD](http://www.oecd.org/sdd/business-stats/eurostat-oecdmanualonbusinessdemographystatistics.htm) definition. We explored questions referring to education, targets, training days, performance management and bonuses, and basis for promotion to find the differences between high-growth and regular businesses. Questions relating to business characteristics, targets and employment practices showed the biggest differences, whereas questions regarding key performance indicators and production delivery showed the smallest. For example, Figure 2 shows there was a 9% difference between high-growth and regular businesses giving out performance bonuses to other staff members based on a target (employment practices). However, there was only a difference of 0.4% between high-growth businesses and regular businesses that had managers reviewing production targets. The limitations of the merged dataset mean that caution should be observed when concluding that any of the individual management practices explored has a significant effect on the likelihood that a business will enter a period of high growth. However, based on our exploration, we can say that businesses that engage in certain management or employment practices were more likely to be classed as high growth from 2013 to 2016. Our exploration of this dataset can be found in the context of our [full report](https://datasciencecampus.ons.gov.uk/projects/understanding-the-characteristics-of-high-growth-companies-using-non-traditional-data-sources/). We would like to thank Data Science Campus apprentices [Jonathan Rees](https://datasciencecampus.ons.gov.uk/author/jonathan-rees/) and [Evie Brown](https://datasciencecampus.ons.gov.uk/author/evie-brown/), for completing this follow-up work. This is great news, and reflects the efforts made by organisations such as STEM Learning, Women in Science and Engineering (WISE) and STEMettes to encourage more girls to take up these subjects. Just last year, the Data Science Campus organised a [Girls into STEM workshop](https://datasciencecampus.ons.gov.uk/we-all-need-more-girls-in-stem/) in partnership with STEM Cymru and the Engineering Education Scheme Wales. However, overall boys still represent most of the STEM subjects entries with a majority of 56.7% in England and 56.6% in Wales. When looking more closely, there's more to it than just a gender disparity. Research suggests that students with a low [\"science capital\" (PDF, 6.65MB)](https://www.stem.org.uk/sites/default/files/pages/downloads/Science-Capital-Made-Clear.pdf) are less likely to aspire to continue with science post-GCSE and see a potential career for themselves in a STEM field. Science capital is a concept that can help us to understand why some young people participate in science post-age 16 years and others do not. It is thought of as having eight main dimensions: According to the Enterprising Science national survey of 3,658 11 to 15-year-olds in England, only 5% have high science capital (more likely to be male, South Asian and socially advantaged), while 68% have medium levels of science capital and 27% have low science capital. The Data Science Campus's new Schools Engagement Strategy aims to build science capital in primary-aged children by visiting schools to help pupils understand how numeracy and statistics have a role in everyday life and talking to them about working at the Office for National Statistics (ONS) and the Campus. We are also partnering with [Techniquest](https://www.techniquest.org/), an educational charity who provide links to schools in their network, activities for events and training for staff in organisations, such as the ONS, wanting to be involved in engagement with schools. In July 2019, the first teams of our newly trained STEM Ambassadors from across the ONS visited three schools in Newport, Cardiff and Sully. Each pair of ambassadors spoke to several classes of children aged from 8 to 10 years, describing the relevance of numeracy in the real world and exploring some of the work that the ONS and the Data Science Campus does. The ambassadors then gave the pupils a teamwork and problem-solving task - pretending they were managing Arctic research bases and ensuring that each base had enough scientists, food, and experiments. The pupils really enjoyed the problem-solving task, and it was fascinating to see their creative approach to problems that we, as adults, would not have considered. Pupils also explored the interactive [baby names tool](https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/livebirths/articles/babynamessince1904howhasyoursperformed/2016-09-02) on the ONS website. They found their own names, as well as those of their favourite celebrities and members of the Royal Family, and it was a great way to show them how to interpret a graph! Similarly, our STEM Ambassadors found the experience greatly rewarding: \"The STEM outreach opportunities have been really interesting, and I've enjoyed working with and inspiring young children.\" - Abbie Cochrane, Assistant Statistician, ONS \"I'm really grateful to have had the opportunity to participate in the schools outreach programme this year. Planning the session really opened my eyes to the impact that the ONS statistics have and this has stuck with me since. Visiting the school was energising; I found the students to be really engaged and interested in the session. Explaining our work and the power of statistics to a class of 10-year-olds was a different challenge to those that I usually face in the office! I'd recommend the experience to anyone. For a relatively low time-commitment there are noticeable benefits for both the students and yourself.\" - Ellen Horner, Data Collection Programme, ONS As the new school year begins, we plan to expand the work of the Schools Engagement Strategy, improving our offer for schools, visiting more of them and offering a wider range of different activities for different age-groups.]]> We are proud to have trained more than 200 civil servants from 20 government departments since last year, making the module series a great success. Experts with extensive experience in data science and statistics deliver to students using an interactive teaching approach. Modules are fully booked months in advance and students' feedback has been very positive. Here is what some of our most recent students have said: \"I only had a very limited knowledge of R prior to starting this module but I now feel quite confident in my ability to produce visualisations using the R language\". \"The structure and flow of the course was great. The lecturer did a great job to tie in previously learnt equations and topics. I enjoyed doing the practicals after each day as they challenged and tested my own understanding\". Building on the success of the past two years, we are again offering civil servants the opportunity to study [individual modules ](https://datasciencecampus.ons.gov.uk/individual-modules-from-the-msc-in-data-analytics-for-government-mdatagov-programme/)from the MDataGov in the 2019-20 academic year. The modules schedule for the 2019-20 programme is detailed below and will again be delivered by Oxford Brookes University at ONS (subject to demand). |Week commencing||Module Learning (P08821)||Cancelled| |22 June 2020||Data Science Foundations (P08801)||Cancelled| The closing date to apply for modules running in January 2020 is Friday 29 November 2019. The cost per module is \u00a3425 so please discuss funding for your studies with your line manager and budget holder before applying. For further information and to apply please see the [module descriptions](https://drive.google.com/file/d/1iH1T4uJihsaWeUnOpbZWNtJ7CS1F1dDh/view) and application form. Further information is available for the full [MDataGov programme](https://datasciencecampus.ons.gov.uk/capability/msc-in-data-analytics-for-government/). Since 2016, the UK Hydrographic Office (UKHO) has sent four analysts to the Data Science Campus to be mentored as part of the programme. They've worked on a range of projects, including the automated identification of objects in the sea. This has since been developed into a live system that has covered 881,280 square kilometres of ocean and uncovered 342 hazards that were unknown to the UKHO. Ciaran Evans, a software engineer at the UKHO, is part of the latest cohort assigned to the Campus. He writes about his recent accelerator project. My project is officially titled, \"Beach Composition Classification.\" Scary, right? I like to pitch it more simply as: \"What is the beach made of?\" As a software engineer at the UKHO, my day-to-day job involves solving problems all the time, but I wanted to solve something other than a continuous integration or deployment problem. After asking around the organisation, I found a problem faced by our Defence Team, who are responsible for providing data and products to defence users, like the Royal Navy. Our defence users often require reports on the composition, content and general geography of a beach for exercise planning and execution. Currently we provide information from open source data, such as [Open Street Map](https://www.openstreetmap.org/#map=6/54.910/-3.432) and ground photography, but this can prove difficult when data are not available for certain areas. My project looked at how we could fill in these gaps and give our users new information on what a beach may contain. To deal with the lack of data, I first looked at the European Space Agency's [Sentinel 2](https://sentinel.esa.int/web/sentinel/missions/sentinel-2) satellite imagery. This was too low a resolution (10 metres per pixel) for the problem, so I went to the [Channel Coast Observatory](https://www.channelcoast.org/) (CCO). The CCO provides coastal aerial imagery of the English coast at 12.5 centimetres per pixel - far better for identifying what a beach is composed of. I then needed to prepare this data for further analysis. To do this, I used [Python](https://en.wikipedia.org/wiki/Python_(programming_language)) (with a bunch of geospatial and raster packages) and [QGIS](https://en.wikipedia.org/wiki/QGIS). My process was: Next up came the fancy stuff - the deep learning! This is a machine learning technique that can be used to identify features from data including images, text or sound. So, by creating the right deep learning model, we'd be able to quickly identify sand from other geographic features in our aerial image. The model I made was based on the [U-Net architecture](https://en.wikipedia.org/wiki/U-Net). The U-Net had been used previously on a project to identify mangroves in satellite imagery and it worked well. You can find out more in this [post by UKHO data scientist Kari Dempsey](https://medium.com/@karijdempsey/mapping-mangroves-with-serverless-and-deep-learning-b868e7d567e4). The machine learning process goes like this: While this sounds straightforward, it involved a lot of picking apart of Python code and debugging confusing outputs, which gave me a newfound respect for what data scientists do! The proof, they say, is in the pudding: The first image shows what the model classified as sand (shown in white) and not-sand (shown in black). The second image shows the original label of what I determined was 100% sand overlaid on top. I was very pleased with the initial results; the model was not completely off, and I could understand why it had classified fields as sand. These areas would ideally be masked/removed completely before classification. I was particularly impressed with the clear definition of sand and not-sand on the right-hand side, where there is a large rocky outcrop. With more work, this could be a great way of classifying beaches for our defence customers going forward. I loved the whole experience of the Data Science Accelerator programme and learned more than I could fit in to a single blog post. It was nice to jump straight in at the deep end of deep learning, having already gained the programming knowledge from my day job. Not only did I get a better idea of what data scientists do day-to-day, but I now have a bigger appreciation for the work that is data preparation. My mentors, [Michael Hodge](https://datasciencecampus.ons.gov.uk/author/michael-hodge/) and [Alex Noyvirt](https://datasciencecampus.ons.gov.uk/author/an/) at the Data Science Campus were incredible, and happy to answer the many questions I had - even though I'm sure all the clicking from me drawing vectors was driving them to despair. It was also useful to have the UKHO experts on hand - Kari and the Data Science team had plenty of Skype messages from me throughout the 12 weeks. The programme was a huge springboard into my new role at the UKHO; I'll be moving on from software engineer to senior data engineer, harnessing Cloud technologies to process big data in pipelines, and productionising the work our Data Scientists do. The geospatial and Python skills I gained through the programme certainly made the interview less stressful! So, if you're looking for a challenge, I'd wholeheartedly recommend you [apply to be a part of the next cohort](https://www.gov.uk/government/publications/data-science-accelerator-programme/introduction-to-the-data-science-accelerator). You don't need any prior coding experience, just a willingness to learn and improve yourself! Being a part of people's career journey - be it straight from school, university or having a change of career and looking to re-train is something that I am hugely passionate about. Throughout my career I have thoroughly enjoyed developing programmes - including graduate and apprenticeship schemes - that will bring out the best in people and enable them to grow in to fully fledged professionals within their chosen specialism. The Data Science Campus offers various entry points to begin a career as a data scientist: However, there was always one thing missing - so today, we're excited to introduce our new two-year Data Science Graduate programme. The programme will provide graduates with highly valuable work experience, working alongside experienced data scientists on real world projects and problems. The structured learning pathway starts off with our induction, followed by a series of modules that act as building blocks to develop knowledge. Successful applicants will also take on four placements over a two-year period to get a broader sense of data science across ONS and other government departments. This is the final piece of the talent jigsaw and it means that we now have opportunities for individuals at every level of experience and ability, looking to start a career in data science. If you're a graduate, passionate about the world of data and want to work in an innovative environment that makes a difference for the public good, then apply for our Graduate programme today - [you can apply online](https://www.civilservicejobs.service.gov.uk/csr/index.cgi?SID=cGFnZWNsYXNzPUpvYnMmam9ibGlzdF92aWV3X3ZhYz0xNjM1NDUwJnBhZ2VhY3Rpb249dmlld3ZhY2J5am9ibGlzdCZjc291cmNlPWNzcXNlYXJjaCZvd25lcnR5cGU9ZmFpciZzZWFyY2hfc2xpY2VfY3VycmVudD0yJnVzZXJzZWFyY2hjb250ZXh0PTc5MTg3OTg5Jm93bmVyPTUwNzAwMDAmcmVxc2lnPTE1NTk4MzIxOTUtOTg1ZWU0N2NmZGNjOWZhNzNkMmUwMDliODcwYjQ2NWFiM2RhZTg1NA==) until Sunday 30 June. The Accelerator programme gives analysts from across the public sector the opportunity to develop their data science skills. It started in 2015 and is backed by the Government Digital Service (GDS), ONS and Government Office for Science and the Analysis Function. The programme runs within a number of regional hubs across the country, the Campus has been the South West and Wales hub since 2016 and has seen nearly 30 mentored projects completed since it began. You commit to spend one day a week for three months at the Campus, working on a data science project. This forms your protected learning and development time, ensuring that you have opportunity to develop your skills and achieve real outcomes for yourself and your department. What are the benefits? You'll be assigned to an experienced data scientist who will mentor you for the duration of the project. Our data scientists have diverse skill sets and backgrounds, so you'll work with the one who can best help you. Arturas Eidukas is a Data Scientist and mentor on the accelerator programme. He talks about his experience of the accelerator, and how being a mentee brouht about a change in direction for him. \"I was working as an Economist in the Office for National Statistics (ONS) and applied to the Accelerator as I was interested in programming and data analysis. The Accelerator was an intense, but ultimately amazing experience, and it allowed me to shift to my current role as a data scientist. It demystified the experience of applying models to data to get some reasonable insight. Moving from being a mentee to a mentor has been great experience; you get to see and support someone else's learning, but also you learn a lot yourself as you can choose which applications you can provide support on.\" Drew Turner is an information analyst specialist for substance misuse at Public Health Wales. he said: \"Having worked as an analyst for Public health Wales, I wanted an opportunity to develop skills in data science. My project is to predict infection in people in contact with substance misuses services. The ONS accelerator has allowed access to both time and expertise required to undertake this project. I am looking forward to demonstrating the usefulness of data science to my department and open the door to be able to complete future projects to continue my learning.\" Alex Westwood is a Data Analytics Apprentice at the ONS, he said: \"The accelerator program has been a very beneficial experience for me so far. Being relatively new to the work, having an experienced data scientist as a mentor has been a great deal of help, both with helping me increase my knowledge in the area as well as planning and structuring my project.\" If you have any questions about the Accelerator or you're interested in becoming a mentor on the programme, email [data-science-accelerator@digital.cabinet-office.gov.uk](mailto:data-science-accelerator@digital.cabinet-office.gov.uk). More about our mentored projects can be found in our [two-year review.](https://datasciencecampus.ons.gov.uk/our-first-two-years/) Applications for the [Data Science Accelerator](https://www.gov.uk/government/publications/data-science-accelerator-programme/introduction-to-the-data-science-accelerator) are now open and close on 3 June 2019. Apply on the Data Science Accelerator page. All you need is: - A project idea (with agreement from your home department) - Access to the data you need to make it happen - To be able to join one of the hubs for one day per week - just specify your preference on the application form. [New research from the Royal Society](https://royalsociety.org/topics-policy/projects/dynamics-of-data-science/) shows the increased demand for data science and advanced analytics skills in the job market and highlights case studies and options to increase data science skills and capability across the UK. The Campus welcomes this report, and it's excellent to see many of the areas of action line-up with our work programme to build data science capability for the UK. The Royal Society's report published this week - [Dynamics of data science skills](https://royalsociety.org/topics-policy/projects/dynamics-of-data-science/) - calls for action in key areas for the UK to maintain this position, and highlights the Campus as a model for others to follow in developing and advancing data science skills and nurturing talent. We recently launched a [degree level apprenticeship](https://datasciencecampus.ons.gov.uk/innovative-data-science-degree-apprenticeship-for-wales-launches/) in data science on behalf of the public and private sectors, with the first apprentices arriving a few weeks ago. This follows the success of our Level 4 (Diploma) Data Analytics apprenticeships Recent graduates Charlotte O'Brien - nominated for the VQ Wales Higher Learner of the Year award - and Alexis Fernquest - recently securing a second promotion in ONS - have seen further successes in the last few weeks. In a [case study for the report](https://royalsociety.org/-/media/policy/projects/dynamics-of-data-science/DES5847-3-Data-skills-case-studies-document.pdf), Alexis said: \"I started with a degree in economics and then went on to a graduate scheme in a small private company that was selling technology. I was there for a couple of months before I joined a larger organisation. Then an opportunity came up in the Office for National Statistics to get involved in a data analytics apprenticeship. It was the first of its kind in the UK. They were promising a huge amount of training involving different languages and coding. It was exactly what I was looking for. The apprenticeship officially lasts two years but I completed it ahead of that. I was made permanent and then promoted to data scientist.\" Our [recent symposium](https://datasciencecampus.ons.gov.uk/highlights-from-the-mdatagov-symposium-2019-in-manchester/) showed the impact of our MSc in Data Analytics for Government (MDataGov), which aims to build data science capability across government by equipping civil servants with key skills required from a modern government data analyst. We now have more than 120 home and international students through our partner universities, stretching across the public sector. The Royal Society report also shows the importance of our [extensive partnerships programme](https://datasciencecampus.ons.gov.uk/partnerships/), which is helping us to develop, research, innovate, and improve knowledge and skills. Our [partnership with the Alan Turing Institute](https://www.turing.ac.uk/news/turing-hsbc-and-office-national-statistics-award-funding-nine-new-projects-drive-forward) is helping to advance ground-breaking research in economic data science, and have further strengthened our academic collaborations in 2019 through working with ESPRC and UKRI Centres for Doctoral Training Centres in [AI, Statistics and Data Science](https://www.ukri.org/news/200m-to-create-a-new-generation-of-artificial-intelligence-leaders/). We are also providing technical support and resource to deliver this summer's Data Science for Social Good (DSSG), the University of Chicago's summer fellowship programme which has trained over 200 aspiring data scientists across the globe to work on data mining, machine learning, big data and data science projects with social impact. As well as building capability, we are involved in several collaborative projects with cross-sector universities and industry. Our [work with Barclays](https://blog.ons.gov.uk/2017/12/13/using-credit-card-payments-data-for-the-public-good/) illustrated how the rich data held by partners outside government can improve our understanding of the UK's economy - with our [Faster Indicators](https://datasciencecampus.ons.gov.uk/faster-indicators-of-uk-economic-activity/) project now a monthly research output in this area. We've also exchanged skills with secondees spending time with the Campus and Barclays respectively. In academia, we recently welcomed [Professor Jackie Carter](https://twitter.com/JackieCarter/status/1092482717311270913) from Manchester University to the Campus as an academic secondee, helping to develop proposals from our Public Sector Data Science Audit. The Royal Society's report highlights a clear need for collaborative, sustainable mechanisms to develop data talent in academia, and the charity, private and public sectors, and to allow data scientists to move across these sectors. Campus Managing Director Tom Smith, part of the working group for this report, said: \"One of the things that I have learned over the years is the importance of developing strong partnerships with people outside the organisation that you work with. In the public sector this is critical to delivery, as there are often many groups involved in any piece of work. This comes down to understanding what the missions and values of other organisations that you might be collaborating, competing or partnering with are and how they align with yours\". Our recent [two-year review](https://datasciencecampus.ons.gov.uk/our-first-two-years/) further highlights our progress made in this area in a short space of time, but we look forward to continuing with our valuable partnerships and creating more in the future to build data science skills across sectors. Which is why we're in Kigali this week along with colleagues from the UN Global Platform team and the Department for International Development, at the [fifth UN International Conference on Big Data for Official Statistics](https://unstats.un.org/unsd/bigdata/conferences/2019/default.asp), being hosted by our partners the [National Institute of Statistics of Rwanda](http://www.statistics.gov.rw/), (NISR). NISR are leading the [data revolution in Rwanda](https://datasciencecampus.ons.gov.uk/join-the-data-revolution-in-rwanda/), with ambitious plans to develop data science capability, and lead the way for others. The fact that they are hosting this important event in their fantastic new data science campus is a testimony to their passion for data science and its potential to improve data for decision-making. Through our successful partnership with NISR; ONS and the Data Science Campus have collaborated with them on all aspects of this vision: the legal and policy implications of sharing and using data safely, the IT requirements, capability building, and joint data science projects. The impact of this work is evident at the event: NISR presented their progress so far implementing Rwanda's Data Revolution Policy, results of some of our joint data science projects and communicated their exciting vision for the future to the vast range of international visitors. The UN Global Working Group on Big Data are also here to showcase the [UN Global Platform for Official Statistics](https://unstats.un.org/bigdata/taskteams/globalplatform/) as a collaborative environment to develop and test new data sources, methods and algorithms for the global statistical system. The Global Platform is supporting capacity building through a library of trusted training materials, methods and software applications. The platform reduces the infrastructure hurdle for all UN member states, especially developing countries, in accessing global data sets and state of the art tools and services. Building the capability to take advantage of these tools and services is essential. Throughout this week, we are showcasing how we are developing data science skills across the UK Government and internationally through collaboration and partnership. Our Campus Faculty are helping others become self-sufficient in their data science expertise, and we continually support development through programmes such as the Master's in Data Analytics for Government, our seminar series and the Data Science Accelerator programme. We are proud that the Campus, together with the [ONS International Development team](https://www.ons.gov.uk/idt) and through [our new hub based at the Foreign, Commonwealth & Development Office (FCDO)](https://datasciencecampus.ons.gov.uk/ai-for-international-development/), are working with partner countries, and key international partners, to support them as they build relevant data science capability, to help tackle the challenges and maximise the opportunities of the data revolution, to improve better decisions and support better lives around the world. The Data Science Campus sponsorship is subject to the MDataGov application being accepted by one of the partner universities. Successful candidates are required to take at least half of their optional module credits in Data Science related topics. More information can be found in the linked application form below. Campus-sponsored students of the MDataGov programme are expected to act as data science ambassadors and evangelists, not only in ONS but across government. You will work with fellow students across the programme to promote the use of data science in government for the benefit of public good. To apply for the Data Science Campus sponsorship: We will inform successful candidates in the week starting 13 May 2019. The MDataGov programme structure includes four compulsory modules (Data Science Foundations, Statistics in Government, Survey Fundamentals and Statistical Programming), and optional modules to be chosen from a range of courses in Statistics and Data Science. Projected fees: \u00a315,220. Please note that UCL will offer a reduced fee of \u00a310,500 to the top 5 MDataGov applications submitted to UCL. This is an internal UCL process and it is independent on the Campus sponsorship process. If you are successful in applying for the Campus sponsorship, please note that the Campus will sponsor up to a maximum of \u00a310,000 towards UCL fees. Your business area may be able to cover the rest. Please speak to your line manager about this when making your submission. Fees: \u00a37,650. The provisional list of modules for 2019/20 is: Semester 1: Data Science Foundations, Statistical Programming, Regression Modelling, Time Series Analysis, Introduction to Machine Learning, Data Visualisation. Semester 2: Statistics in Government, Survey Fundamentals, Advanced Statistical Modelling, Intro to Survey Research, Advanced Machine Learning, Introduction to Distributed Systems. Current and past students recently showcased their work at the [MDataGov Symposium in Manchester](https://datasciencecampus.ons.gov.uk/highlights-from-the-mdatagov-symposium-2019-in-manchester/). The blog provides highlights from the day, including the student's presentations. Six months after the launch of the [MDataGov programme](https://datasciencecampus.ons.gov.uk/capability/msc-in-data-analytics-for-government/), we hosted the first MDataGov Symposium in Newport, bringing together 13 Data Science Campus-funded master's students to discuss their experiences and to network. The event helped to establish a thriving and innovative community for the students. This led to the creation of a Slack channel to stay up to date, share ideas and identify two MDataGov reps from across government to support this growing community. Now with more than 40 civil servants registered on the full MSc programme, the community is stretching across the public sector. We also have more than 120 home and international students taking standalone MDataGov modules per academic year for professional development across the three provider universities. This year's symposium brought together a diverse group of more than 80 delegates from 16 government departments and 6 universities. The event offered a relaxed atmosphere for networking and learning. The symposium hosted 5 sessions with 11 talks where students showcased projects, skills learnt and the benefit of these to their workplaces. The quality of the projects was impressive, with topics presented including natural language processing, distributed computing platforms, advanced statistical modelling and machine learning. The full [programme](https://datasciencecampus.ons.gov.uk/wp-content/uploads/sites/10/2019/04/Programme_for_dissemination.pdf) and [presentations](https://datasciencecampus.ons.gov.uk/capability/msc-in-data-analytics-for-government/mdatagov-symposium-2019/) are now available. [Click here to see the full list of presentations.](https://datasciencecampus.ons.gov.uk/capability/msc-in-data-analytics-for-government/mdatagov-symposium-2019/) Attendees also voted for the best presentation and the winner was the MDataGov student Yuliagnis Wijaya from Badan Pusat Statistik (Statistics Indonesia) and Southampton University. His talk was entitled \"Using exploratory data analysis methods for an early warning in Indonesia's earthquakes disaster\". Yuliagnis will receive \u00a3200 worth of data science books. The event ended with a roundtable about \"how universities can enable government to embed data science in its processes?\", with Tom Smith, the Campus Managing Director, and Professor Jackie Carter, from Manchester University, engaging the audience in a thoughtful discussion. Tom also announced the Campus's second anniversary and the release of its [two-year report.](https://datasciencecampus.ons.gov.uk/our-first-two-years/) To the delight of the audience, following on from this announcement, a large Campus-branded cake was cut! We would like to thank the delegates and speakers for supporting the event and hope they enjoyed it. We look forward to seeing them next year. Solange Correa-Onel, Harrison Davies, Anthony Fitzroy (ONS), Wei Tony Guo (HMRC), Martin Wood (Home Office) MDataGov 2019 Organising Committee Further links: One programme that I'm particularly proud of is our collaboration with the National Institute of Statistics in Rwanda (NISR). We are working closely with colleagues in the [ONS International Development Team](https://www.ons.gov.uk/aboutus/whatwedo/programmesandprojects/internationaldevelopmentteam) and the Foreign, Commonwealth & Development Office (FCDO), to support the launch of NISR's own Data Science and Training Centre in Kigali. For the last two weeks two of our data scientists, Emily and Alex, have been in Kigali sharing their research and running training workshops. [This is just the latest in a series of exchanges](https://datasciencecampus.ons.gov.uk/join-the-data-revolution-in-rwanda/) which have been the most rewarding aspect of their work at the Campus. We see huge potential for global public good through the application of data science and AI to tackle some of the key challenges that we face as an international community, particularly across the Sustainable Development Goals in areas like health, education, agriculture, water, infrastructure, and sustainable fair economies. We also want to significantly scale our activities in this area, particularly in our support for international development programmes. To do this, we've partnered with the Department for International Development to launch a new Hub of the Data Science Campus focused exclusively on data science and AI for International Development, at the FCDO's office in East Kilbride, near Glasgow. The Hub will work with directly with the FCDO and with organisations at all levels of the aid sector, from key partners like the UN agencies, World Bank and National Statistics Institutes all the way through to small NGOs delivering interventions on the ground. It will explore the application of data science and AI to tackle the Sustainable Development Goals, support data science capacity building in global partner organisations and help make aid interventions more effective and better informed. The Hub will create a focal point where Campus data scientists have vital exposure to both the FCDO's aid delivery expertise and the practical realities of operational international development. This will enable us to collaborate directly with their data scientists, analysts, software engineers and data engineers, as well as the global community of digital specialists supporting the International Aid Transparency Initiative. We'll be sharing more about this collaboration, and our new AI for International Development programme, over the coming months. In the meantime, we have already started to recruit for a number of data scientist, data science lecturer and developer roles to launch the Hub, and [more information on these is available here.](https://datasciencecampus.ons.gov.uk/about-us/were-hiring/) This will help us to better understand loneliness in England, and in particular, the differences between regions. Loneliness is an internal feeling, that a person experiences when there is a mismatch between their desired level of social interaction, or emotional support from others, and the amount they actually get. Humans are social creatures; most of us need social support and interaction from others to stay happy and maintain emotional wellbeing. Some people don't need much, or any at all and that's fine, whereas some people need a lot and that's fine too. It's not about how many friends a person has, or how many people they are connected to. Loneliness arises when a person's required level of social interaction is not met. In the short-term loneliness is not a bad thing, most of us have experienced it at some point in our lives. It's a normal emotional and physical response when a person's social interaction or support levels are not at the level they need. In an ideal situation, the feeling of loneliness drives a person to seek out more social support and interaction in the same way hunger encourages us to eat or tiredness to sleep. Unfortunately, it's often not that easy; it can be hard to know how to find those connections, for example when moving to a new place or when spending a lot of time as a caregiver. This is when loneliness can become a problem. There are several things that make it more likely for a person to be lonely, such as being a caregiver, living alone, having a long-term disability, or having moved for work. When a person is lonely for a long time it can increase the risk for some medical conditions such as Alzheimer's disease, depression, high blood pressure, and insomnia. We chose to generate an outcome-based loneliness index using open prescription data rather than a risk factor index as it enables the effects of interventions to be investigated in a more timely manner. Open prescription data lists medicines, dressings and appliances prescribed by NHS England primary care facilities, including General Practices (GPs), each month. These data don't include any information about the person it was prescribed to, but are averaged for a whole GP practice. The data being monthly is a real bonus, as it enables investigation of seasonal effects. Many risk factor measures are only collected every 10 years during the census. Another useful feature of open prescription data is that these data are available for the last 10 years, allowing the investigation of historical patterns if needed. The index allows us to see how different GP practices compare to the English average for five conditions where loneliness has been shown to be a risk factor - Alzheimer's, depression, high blood pressure, anxiety and insomnia. When we take all the index values together we notice a general pattern: GP practices with high index values tend to be located near to other GP practices with high values and vice versa. There appear to be geographical patterns - hot spots and cold spots - in prescribing for loneliness related conditions. Hot-spots and cold-spots are geographically concentrated groups that either prescribe at a higher rate than the English average, or at a lower rate. If the \"Loneliness Prescription Index\" is reflective of loneliness levels it should be related to known risk factors for loneliness. It should be higher in areas where a higher proportion of people live alone, or lots of people are caregivers, or where there are greater barriers to housing and services, income is lower, the living environment is poorer, and where crime is higher. Once each category of loneliness related prescriptions had been shown to be related to one of the related factors they were included in the overall index of loneliness. An index was created for each condition by standardising the proportion of a practices prescriptions that were given for the condition relative to the levels in other practices (into z scores). The index for each condition had a value that was negative if prescribing was lower than typical and positive if it was greater than typical. The loneliness index is generated by summing together these standardised-scores for each condition. The loneliness indicator was verified by comparison to levels for risk factors; these explained 9% of the variation in the index for different parts of England. \"Living alone\" and \"barriers to housing and services\" each independently drove around 1% of the variation in the Loneliness Prescription Index. Each Lower Super Output Area (LSOA) in England is classed as being of one of eight supergroups that provide the most generic descriptions of [the population in the area](https://www.ons.gov.uk/file?uri=/methodology/geography/geographicalproducts/areaclassifications/2011areaclassifications/penportraitsandradialplots/penportraits.pdf) . The average Loneliness Prescription Index differed substantially between these areas. As shown in Figure 1. Cosmopolitan areas have the highest score, which reflects a significantly higher proportion of prescriptions for loneliness related conditions. Cosmopolitan areas also had relatively low levels of people living in couples (see Figure 2). Ideally, we want to link primary care-level prescribing data to administrative geographies in England to take advantage of the wealth of routinely compiled demographic and socio-economic statistics. To achieve this, we need to take the known data values for primary care facilities and infer what the data value is likely to be for each geographical area, like a district or ward. Transforming data observed for discrete locations to geographical areas is known as a 'change in support problem' - data observed at a set of point locations (e.g. GP surgeries) need to undergo a transformation to allow inference of those data values for areas. There are a number of ways to approach the change in support problem, but generally they fall into exact (simple algorithms) and statistical (probability-based) approaches. As a proof of concept, we used an exact method known as 'inverse distance weighting' to estimate the value of a data point at an unknown location based on the distance-weighted combination of data values at known points. These estimates are then combined to produce estimates of loneliness-rated condition prescribing for the UK Census 'Middle-Layer Super Output Area' (MSOA) geography. Testing the MSOA estimates reveals that they are geographically patterned. Loneliness-related condition prescribing is not random across England but is concentrated in particular areas (see Figure 3). We call this phenomenon spatially dependency, or spatial auto-correlation. Local Indictors of Spatial Autocorrelation (LISA) statistics are computed to reveal the presence of hot and cold spots - regions of England in which geographically concentrated groups of MSOAs exhibit higher-than-average or lower-than-average index values for loneliness-rated conditions. Currently the findings from the loneliness index are preliminary and may be subject to change as the project develops. We are excited about what we have done so far and are looking forward to exploring how meaningful a measure it is. The next steps are to explore and implement a more sophisticated geostatistical approach known as 'Kriging' (or gaussian process modelling) to tackle the change in support problem outlined above and make more robust estimates of loneliness related conditions at both MSOA and LSOA levels. We also plan to further develop the prescription types included over time to enable a more robust measure of changes in prescribing for loneliness related conditions over the last 10 years. For further information, please contact the [Data Science Campus](mailto:datasciencecampus@ons.gov.uk). ]]> [Jasmine Grimsley](https://datasciencecampus.ons.gov.uk/author/jasmine-grimsley/), Kirsty Hopkins, Elishama Tizora, Daniel Lewis Two years ago, I was approached by a colleague in the Cabinet Office to lead a Trailblazer Group - a group of employers - to develop a new degree apprenticeship standard. We had already seen the success of our flagship foundation apprenticeship in data analytics in Wales and to develop a degree apprenticeship in data science seemed like a logical next step. I took up the challenge of leading the group and we began to develop the apprenticeship - what a fantastic journey it has been! The first meeting was held in the Bank of England, in the Boardroom that Mark Carney holds his big important meetings. There must have been about 40 people from a variety of universities and private sector organisations - Unilever, GSK, Microsoft, BBC, EasyJet, TUI, Bank of England, John Lewis and Estee Lauder, to name a few. Together we agreed the role profile of a data scientist and the knowledge, skills and behaviours. I had plenty of help and great advice from Helen Pickering, a relationship manager from the Institute for Apprenticeships, and Becky Carpenter, from the Government Statistical Service (GSS) Careers team, who helped to bring together a diverse range of views, enabling us to develop and publish the standard within a year of starting. The Data Science Degree Apprenticeship is now live for delivery and several organisations are currently advertising for apprentices in England, including Nestle, Unilever and Santander. GSS Careers are tendering for a provider in England so that government departments can start the recruitment process. In Wales, I am exceptionally pleased that the Welsh Government are funding this apprenticeship as part of their degree apprenticeship trial. The Data Science Campus, Welsh Government and business areas in the Office for National Statistics (ONS) are the first adopters and our first new apprentices will start on 25 March 2019. Delivered by Cardiff Metropolitan University, the apprentices will benefit from blended and classroom learning and on-the-job training, with support from experienced data scientists. This is an exciting time for apprenticeships in general, but to be at the cutting edge of forging a new path for people to follow is really rewarding. \"The Data Analytics Apprenticeship, has been a great experience. It has allowed me to switch careers into an area I am passionate about, by giving me the tools I needed. I was given knowledge on R and Python, statistics, data analysis and data science, all of which I use in my everyday role. \"All of these skills have given me a basic foundation to work on, and by taking on the degree apprenticeship, I hope to further develop my skills in these areas, so I can be more effective in my everyday role. \"I am really passionate about finding new innovative ways to use statistics and data science in the workplace and I hope that the degree apprenticeship will inspire me to bring that innovation back to the office. \"When I first completed a degree after school I did not really know what I wanted to do, so I am intrigued to begin a new degree, in a subject that I am passionate about.\"]]> Today, we hear from some of our current cohort, who we recruited in September 2017. They have just finished their training modules and are well on their way to completing their apprenticeships. The apprentices are currently on rotation in the business areas and are using the knowledge, skills and behaviours they have learnt over the past 18 months to make a real difference. Lucy and Joe tell us about their journey so far. Before joining the ONS as a Data Analytics Apprentice I completed a degree in Maths at Aberystwyth University. During my time at the Data Science Campus I was able to gain a good understanding of some basic data science. I worked on a project that involved Twitter analysis, trying to find out what topics people talked about when they mentioned '#wales' in a tweet. I also worked on a project that involved supervised machine learning techniques, making a user interface that allowed users to classify items into groups in order to make a training data set. I am currently working on the Sustainable Development Goals team, where I have been automating processes using Python, working on a performance analytics project with Google Analytics and a global project with SDMX (Statistical Data and Metadata eXchange). I have also been given the opportunity to project lead. I have now completed the Data Analytics Level 4 Apprenticeship and have recently been offered a permanent role in the Sustainable Development Goals team. I graduated from Cardiff University in 2016 with a BSc in Neuroscience. During a year out working with a charity I became interested in the use of data science and data analytics and decided to pursue an apprenticeship to get hands-on experience. During my year in the Data Science Campus I worked on a number of projects, taking a particular focus on developing tools for interacting with Urban Forest data and analysis of aggregate bandwidth data for social and economic indicators. I then moved onto the UN Global Platform, looking at how my previous work could be scaled up on to the platform, moving into looking at satellite imagery, including ingestion of high resolution images, and creation of processes for training and deploying machine learning models. I secured a promotion in January 2019 and am now working as a Data Scientist in the International Development team. I joined ONS as a Data Analytics apprentice after completing A-Levels in Maths, French and Psychology. From a young age, I had always planned to go straight to university from school to study Maths. As I came to the end of my A-Levels, I started to doubt whether university was the right option for me at that time - I could study for a degree at any point in my life, so there was no rush. The Data Analytics Apprenticeship appealed to me as it is the perfect balance of studying and working, as I did not want to dive straight in to a full-time job so young. I had no programming experience before joining but I soon got up-to-speed when working on data science projects and learning how to analyse data using impressive techniques such as topic modelling and sentiment analysis. I have recently secured a permanent role in the Emerging Platforms team in the ONS and I have almost completed the Level 4 Data Analytics Apprenticeship. Do you want to learn new skills that can make a real impact in the world of data and statistics? More information about the Level 4 Apprenticeship programme is available on the [Data Science Campus website](https://datasciencecampus.ons.gov.uk/capability/). This week it's the 12th annual [National Apprenticeship Week](https://www.gov.uk/government/topical-events/national-apprenticeship-week-2019). The theme for the week is \"Blaze A Trail\", showcasing all the incredible opportunities an apprenticeship can bring - both for individuals firing up their careers and for employers reaping the benefits of the apprentices' new skills. Here in the Data Science Campus we have certainly been blazing a trail, working in partnership with our apprenticeship provider - ALS - to deliver our flagship Data Analyst apprenticeship programme. It's been two years since we recruited the first cohort of Level 4 apprentices. The eight that we recruited in that round were the trailblazers for the apprenticeship. It was the first recruitment campaign for apprentices in the Office for National Statistics (ONS), and perhaps more significantly, the first Data Analyst apprenticeship to be delivered in Wales! As well as classroom learning, the apprenticeship gives apprentices the opportunity to apply their new skills to projects across the ONS that are making a real difference. All members of the first cohort have now successfully completed their apprenticeship and have secured promotions into different roles. To mark National Apprenticeship Week 2019, we look at some of their stories. Prior to my apprenticeship I completed a postgraduate degree in Exercise Physiology. The apprenticeship was a complete change of direction for me, but it's been thoroughly rewarding. Over the course of my apprenticeship, I have completed a number of data analytics projects, using a range of state-of-the-art techniques including Optical Character Recognition and Natural Language Processing. I secured a role in the Data Development team on promotion following the successful completion of my apprenticeship. I am using my new skills to help improve the quality of business data by linking different sources, identifying new and emerging job titles and assigning classifications to them. I thoroughly enjoyed the Level 4 programme and the experience has inspired me to complete the Level 6 Degree Apprenticeship in Data Science in the future. I secured a promotion to a role in the Index Numbers team in the Methodology division. I work closely with both business and consumer prices colleagues on a variety of projects, most recently focused on alternative data sources, such as scanner and web data for use in official statistics. Prior to joining ONS, I completed a degree in economics at Swansea and then I worked as a long-term planning analyst for Lloyds banking group. Data analytics had always been an area of interest for me. The apprenticeship scheme gave me the opportunity to pursue my interest and apply new skills to various projects for National Accounts, conducting cluster analysis and time series analysis in R and Python. I've now secured a promotion to a new data scientist role within economic statistics, using new technology to build pipelines for processing big data within economic statistics, supporting the modernisation of statistics production. After leaving college I decided not to go to university and entered the workforce. Prior to joining ONS I worked as a manager in a Cardiff Law firm. The apprenticeship has given me the opportunity to shape a career at ONS and I developed a role within the integrated data division, where I recently secured a promotion. Before arriving at the ONS I completed my degree in Computing at the University of South Wales. It was hard for me to pass up the opportunity of beginning a career in an ever-growing field of data analytics and science. Within the last two years I have completed a range of projects within the ONS, as well as having the opportunity to join the Wales Audit Office to help set up their new data analytics lab. These two years have given me opportunity to develop so many new skills, and knowledge that will benefit my career for years to come! I highly recommend anyone interested in the apprenticeship to do it! We're pleased to see the impact that the first cohort's success is having in business areas across the ONS and beyond, as they use their new skills to improve business processes and statistical production. The second cohort are now at the end of their initial year-long training period and are now on the first of their placements across ONS. We'll hear more from them later this week and look forward to celebrating further successes in the near future!]]> Government organisations, businesses, academia, members of the public and other decision-making bodies require access to a wide variety of administrative and survey data to make informed and accurate decisions. However, the collecting bodies are often unable to share rich microdata without risking breaking legal and ethical confidentiality and consent requirements. This can often hinder the efforts of the data science community in providing more detailed and timely analysis to decision-makers to effectively tackle major challenges such as climate change, economic deprivation and global health. To address this, we have developed a methodology that generates synthetic data - data manufactured artificially rather than obtained by direct measurement. Synthetic data mimics essential characteristics from the original dataset, but creates new, substitute data that does not represent any real person, removing confidentiality requirements. This makes it suitable for processing and analysis, but without compromising legal, ethical and confidentiality requirements that would prevent the real data from being shared. Today we present the findings of our work, a complete system for synthetic data generation: In our main report, we provide an overview of our initial analysis and propose a system that generates synthetic data to replace real data for the purposes of processing and analysis. A complementary technical report with a more in-depth coverage of generative adversarial networks (GANs), one of the methods tested for synthetic data generation. GANs are more than a mathematical curiosity. Recently, the techniques were used to [create the 2018 painting \"Edmond de Belamy\", which was sold for $432,500](https://www.christies.com/features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx)! This opened up a potentially lucrative avenue for the wider artificial intelligence (AI) industry. In the future we plan to develop this work to include datasets with more complex variables, incorporate privacy preserving mechanisms and apply the methods tested here to large-scale datasets. If successful, the methods could be applied to sensitive datasets, to produce non-confidential data that can be used to provide more timely analysis to decision makers in important policy areas. For more information about this work, please contact the [Data Science Campus](mailto:datasciencecampus@ons.gov.uk). With social media being such a key part of everyday life and the data readily available online, it has the potential to change the way we collect information to understand society. However, it is paramount that data sources used in the production of official statistics are accurate, relevant, unbiased, and most importantly, they must be used ethically. On the [ONS National Statistical blog](https://blog.ons.gov.uk/2019/02/05/can-social-media-data-improve-official-statistics-not-yet-suggests-new-work-on-tourism/), data scientists [Lanthao Benedikt](https://datasciencecampus.ons.gov.uk/author/lanthao-benedikt/) and [Emily Tew](https://datasciencecampus.ons.gov.uk/author/emily-tew/) look at the potentials, limitations and ethical considerations of social media as a data source and to what extent it can be used to improve the way we produce statistics. The annual Symposium is an opportunity for former, current and prospective MDataGov students to showcase data science research and projects conducted within government, and to network. The Symposium is organised by students and supported by the Office for National Statistics (ONS) Data Science Campus. Delegates will be able to network with representatives from the three MDataGov providers (University of Southampton, University College London and Oxford Brookes University) and with a team from the ONS Data Science Campus. Date and venue 27 March 2019 at the Federation House, Manchester, M4 4BF. Presentations Masters students will present on how they have applied their new-found skills to data science challenges within government. MDataGov students engage in a wide variety of data science and analytics projects utilising a variety of tools, including distributed computing platforms, natural language processing, machine learning and advanced statistical modelling. Their presentations will highlight the value that these skills bring in working for the public good. The Symposium will also host a discussion session with senior members of academia, industry and government on challenges and next steps on growing data science skills across government. Interested? [Register now!](https://www.eventbrite.co.uk/e/mdatagov-symposium-2019-tickets-54750965612) Attendance is free, with lunch and refreshments provided. Want more Data Science? The GovDataSci Community of Interest Meetup will be held on 26 March 2019 in Manchester. It will host networking sessions and training courses. The Meetup is open to government employees only. For more information, please contact [datasciencecampus@ons.gov.uk](mailto:datasciencecampus@ons.gov.uk). Get in touch Don't hesitate to contact us at [MDataGovSymposium@ons.gov.uk](mailto:MDataGovSymposium@ons.gov.uk) should you need further information. Want to know more about the MDataGov? ]]> [More about the MDataGov and our academic partners](https://datasciencecampus.ons.gov.uk/capability/msc-in-data-analytics-for-government/) is available on the Campus website. In the last quarter of 2018 alone, the Campus welcomed delegates from China, the Republic of Korea, Singapore, New Zealand and Australia, as part of wider visits to ONS organized by our International team, and we have a formal Memorandum of Understanding (MOU) with a with a number of these. Statistics Indonesia (BPS) was the final delegation that we welcomed to the Campus in 2018, following an initial visit from senior officials Dr Adhi Lumaksono and Dr Setia Pramana, in September 2018. BPS are developing a new Masters programme to be launched in October 2019, so the purpose of the visit was to exchange experience in growing data science skills across government. They were particularly interested in the [MSc in Data Analytics for Government (MDataGov) Framework](https://datasciencecampus.ons.gov.uk/capability/msc-in-data-analytics-for-government/) - an innovative Masters programme designed for the UK government and launched by ONS in September 2017. As well as spending time at the Campus, they visited the three MDataGov provider Universities. Such was the success of the visit, they returned in late November with a delegation of 13, including methodologists, academics and IT experts. The visit was part of the World Bank project \"Statistical Capacity Building - Change and Reform for the Development of Statistics (STATCAP-CERDAS)\". A broad range of areas were covered during the visit, including: The group was welcomed by Heather Savory, Deputy National Statistician and Director General for Data Capability, with colleagues from across three ONS directorates (Data Science Campus; Methods, Data and Research; and Digital Services and Technology), contributing to sessions about important projects. The talks included a data science research showcase and capability initiatives, the ONS Data Access Platform and Data Architecture, the Administrative Data project and the Methods Library. Our visitors also delivered a presentation to Campus colleagues of Big Data developments in Statistics Indonesia and the BPS's amazing Statistics Training Centre. They met with our International team to start discussions on a Memorandum of Understanding to formalise a partnership between the two institutions and strengthen collaborations in research and capacity building. In mid-December, following the visit, the BPS Deputy Chief Statistician endorsed the creation of an Indonesia Centre for Big Data Statistics, to be led by BPS in collaboration with other government agencies. We are very pleased to have hosted the Indonesian colleagues and to see that sharing our experiences has contributed to them building their own Centre. We wish them success with the new centre and look forward to hearing all about it in the near future! If you would like to know more about our international collaborations, [please get in touch](mailto:datasciencecampus@ons.gov.uk). The work was carried out as part of a wider project led by the Department for Business, Energy and Industrial Strategy (BEIS) aiming to identify the characteristics of businesses with high growth potential using HM Revenue and Customs (HMRC) tax data. Our [full project report](https://datasciencecampus.ons.gov.uk/projects/understanding-the-characteristics-of-high-growth-companies-using-non-traditional-data-sources) outlines work that combined business administrative data with non-traditional datasets, such as geographical features and websites data, with the objective of understanding if this adds insight into the main features that characterise companies with high growth. An exploration of the datasets and the features engineered from their variables is described along with an assessment of whether they contribute to understanding high growth. A number of different classification models and data balancing techniques were used to investigate the main features that could characterise high growth companies. No improvement in classification was observed with the addition of company websites data, although company connection measures did appear as part of the top features, suggesting that high growth firms are more likely to have a bigger network. Using websites free text [[1]](#a1) it was observed that high growth companies tend to discuss general overview terms such as team and management more than specific terms like tax, law and manufacturing. This is regardless of whether they are describing the organisation, describing their people roles and biographies or in the news and jobs they post. This is an interesting first insight into the language used by businesses in their websites, and could suggest that high growth companies are more interested in people and processes rather than specific tools or terms. A wide distribution of both standard and high growth companies is observed across the UK, but using Office for National Statistics (ONS) rural urban indicator high growth companies are more likely to be found in major conurbations rather than cities, towns and in the fringes of towns. Using Ordnance Survey's retail cluster data for six districts of the UK we observe that the high growth companies are more likely to be located in a retail cluster. This rate is particularly the case for the two large conurbations investigated Birmingham and Glasgow. The understanding of what makes a company high growth is varied and complex. Our analysis has confirmed existing research that it's difficult to predict high growth firms, and that both clustering effects and being well networked are weakly associated to high growth firms. We have, nevertheless, uncovered some interesting relationships which might bear further investigation. Using new data sources such as Glass AI web data and new geographical measures do not give us a step change in this knowledge but do allow a small insight into the characteristics of these businesses. Given further data these insights could be developed further to help tailor targeting and policy to help businesses that could potentially be high growth. More detail is available in the of the web reading principles used to obtain the websites free text data are available in the [report appendix](https://datasciencecampus.ons.gov.uk/projects/understanding-the-characteristics-of-high-growth-companies-using-non-traditional-data-sources/#webreadingprinciples). What a great month November was for the Office for National Statistics (ONS) and Data Science Campus apprenticeship schemes: Large Employer Finalists at the Wales Apprenticeship Awards, the graduation of our [first data analyst level 4 apprentices](https://datasciencecampus.ons.gov.uk/hello-we-are-the-data-science-campus-apprentices/) after two years of hard work, and finally, we have [gone live with the recruitment for the first Data Science Degree Apprenticeship in Wales](https://www.civilservicejobs.service.gov.uk/csr/index.cgi?SID=b3duZXI9NTA3MDAwMCZwYWdlYWN0aW9uPXZpZXd2YWNieWpvYmxpc3QmcGFnZWNsYXNzPUpvYnMmY3NvdXJjZT1jc3FzZWFyY2gmc2VhcmNoX3NsaWNlX2N1cnJlbnQ9MiZvd25lcnR5cGU9ZmFpciZqb2JsaXN0X3ZpZXdfdmFjPTE2MTAwNjcmdXNlcnNlYXJjaGNvbnRleHQ9Njc1NTU2MTQmcmVxc2lnPTE1NDI3OTIwMzQtMmQyZjE5YmQ5MzYzYWRhOWEwZTgzODc0OGNhMjFkMGQ0Yzg3MjY2Mg==). So much to celebrate! At a ceremony hosted by the ONS Data Science Campus, graduates were joined by Eluned Morgan, Welsh Government Minister for Welsh Language and Lifelong Learning, and National Statistician John Pullinger to congratulate them on their achievement. John was pleased to be part of the ceremony and stated: \"Apprenticeships provide a real opportunity to shape how we hire, develop and retain our high performing people. This graduation is a fantastic way to celebrate the success of these pioneering apprenticeships at ONS, and I look forward to many more.\" All eight graduate apprentices have secured permanent jobs in the Civil Service - seven at ONS - and were full of praise for the scheme. | | | | Alex Rose said: \"I think it speaks wonders of the apprenticeship and of the first cohort that all eight have been offered permanent positions with the Civil Service, the majority with the teams they worked for on secondment.\" | | | | Alexis Fernquest said she couldn't see a downside to apprenticeships: \"You are getting paid to learn, it's applicable to an area you're interested in, and teams will have a member of staff who is keen to bring new knowledge to tackle problems from a fresh point of view. It seems like a win-win situation.\" The ceremony marks the end of a two-year, level 4 Data Analytics Apprenticeship Programme for the graduates, with a second cohort having recently reached the end of their initial year-long training period and now on initial placements across ONS. The data analytics level 4 apprenticeship was newly developed in Wales. ONS was the first adopter of the framework and collaborated with [ALS](https://www.alstraining.org.uk/) Training to develop and deliver an apprenticeship fit for the analyst world. One of the many skills the apprentices learned was to manipulate data in programming languages such as Python and R, so they can apply the latest data visualisation techniques to their work. The skills learnt provide the first steps on a career as a data scientist or statistician. The next piece of exciting news is the introduction of the level 6 Data Scientist Degree Apprenticeship. This is the first data scientist degree in Wales to be delivered, and ONS, the Data Science Campus and the Welsh Government are the first to recruit for this apprenticeship. Working in collaboration with partners Cardiff Metropolitan University we are developing a truly innovative apprenticeship. As a data science apprentice, you will have the opportunity to learn about the theory at university, as well as being able to put that theory into practice by working alongside experienced data scientists. If you are fascinated about data science and the tools and skills that aid problem-solving then this is an exciting opportunity to get into the world of work, earn money and gain a BSc degree through this apprenticeship. ONS and the Data Science Campus worked incredibly hard over the last two years to raise the profile of apprenticeships both within and outside the organisation. ONS now has over 100 apprentices in many different disciplines, and we were delighted to be nominated as finalists in the Large Employer of the Year, at the Wales Apprenticeship Awards. Being Finalists really shows that ONS is committed to the delivery of apprenticeships and, in particular, ensuring that these apprenticeships are of a high quality and provide the skills that are needed for employers across Wales.]]> One of the important areas for improvement in financial statistics is in the granularity of the sector breakdowns. In the current publications of UK financial statistics, more than 100,000 organisations in the UK financial sector are grouped into just three economic sub-sectors: The \"other financial institutions\" sub-sector includes businesses with a wide range of different activities. If these institutions can be further classified, more effective analysis of financial stability risk could be possible to inform financial policy. The project explores whether it is possible to classify financial corporations to their detailed [Standard Industry Classification 2007](https://www.ons.gov.uk/methodology/classificationsandstandards/ukstandardindustrialclassificationofeconomicactivities/uksic2007) (SIC2007) using financial assets, liabilities and other firm-level data. We used a number of unique features derived from both structured and unstructured text are used to determine the feasibility of doing this. The datasets used were the Financial Services Survey, conducted by the Office for National Statistics (ONS), ONS's Interdepartmental Business Register (IDBR) and the Financial Conduct Authority's register of regulatory approvals for financial activity. Typically, all businesses have Standard Industrial Classification (SIC) 2007 codes assigned to them at some point of their lifecycle, however this is a manual and labour-intensive process. Classifications need to be periodically re-evaluated to incorporate changes in the business activities over time. Failure to re-evaluate would result in obsolete classification for some businesses, skewed business groupings based on obsolete SIC codes and, subsequently, inaccurate statistical results. This affects the ability to monitor effectively flows of funds between the separate company groups and ultimately the level of risk in the sector. To address the problem, the focus of the project has been to investigate an automated method for identification of the companies whose classification needs manual re-evaluation. Data and methods After cleaning the data, the three datasets were joined together and we conducted a large-scale machine learning exercise to identify the most discriminative features (fine distinctions between different values of the feature) in the data. It explored various machine learning methods as well as cluster-based distributed computation to optimise the classification accuracy of the model. An exhaustive (or full) search was used to identify the most applicable feature engineering methods. Data quality and quantity challenges were major factors guiding the selection of the machine-learning algorithms. The [Random Forest](https://doi.org/10.1023/A:1010933404324) (RF) algorithm, a class from tree-learning ensemble methods, was the first choice. It was a reasonable balance between the model complexity and its ability to learn from the limited training dataset. At the same time, it reduced the decision trees' tendency of overfitting to the training set. We also applied the [XGBoost](#_Hlk521074998) algorithm, (a representative of the gradient-boosted trees (GBT) class of algorithms), to the data to evaluate its ability to limit the overfitting of the model further. More detail about the methods is available in the full report. After selecting the learning methods, we undertook further pre-processing measures, aimed at improving the overall performance of the model, as described below. The most important step was the feature selection procedure. Instead of using the full set of features, consisting of 250 individual candidates, the input to the algorithm had to be limited to only a few of the most discriminative ones. If all available features were fed simultaneously into the model as input, the algorithm was unable to learn to generalise sufficiently well due to limited amount of training data. This resulted in unsatisfactory accuracy on the test dataset - a problem known in machine learning as the \"curse of dimensionality\". Therefore, we considered it necessary that both optimisation of the number of input features and discovery of the most suitable feature combinations were needed to improve the accuracy of the model. After the feature selection, final adjustments of the model were carried out by hyper-parameter tuning in a grid search. The most discriminative features The five most discriminative features identified by the problem-solving algorithm (exhaustive search) in the feature space were found to be: Q1000, Q1065, Q1054, Q1012 and FTEempt. Their description in Table 1. |Feature||Description| |Q1000||The value of company's holdings of transferable deposits held with banks or building societies located in UK| |Q1065||The value of the holdings of listed equity in institutions or businesses located outside of UK| |Q1054||The outstanding balance receivable from loans with an original maturity of more than one year from businesses in UK| |Q1012||The value of the company's holdings of Treasury Bills issued by Her Majesty's Treasury (HMT)| |FTEempt||Number of employees, full-time equivalent| The features in Table 1 are presented graphically in figure 1. In the plots, the label class corresponding to the Classification 2007: SIC 2007 (frosic2007), representing the constant classification code over time of a company, is colour-coded to allow easier visual evaluation of the class members' distribution in each feature pair. When using only two features (in the two-dimensional feature space), the overlapping circles indicate that there is no obvious pair of features that clearly separate the label classes into well-defined clusters. These features would be depicted by separate circles on individual plots, if present. Therefore, the focus of search had to be directed on higher-dimensional feature spaces. Therefore, the focus of search had to be directed on multiple, higher level features as input to the classifier and evaluating its performance in an exhaustive search. After a large number of experiments, the most discriminative feature configurations and the highest-achieved accuracy for each case was recorded. The results are presented in figure 2. The experiments included the following configurations: The classification accuracy was evaluated for different levels of aggregation in SIC groups (three digits), SIC classes (four digits) and SIC subclasses (five digits), denoted by SIC3, SIC4 and SIC5 respectively in figure 2. Overall, the experiments have shown that although accuracy achieved from available data is not sufficient for full automation, anomaly detection in classification of certain types of companies is feasible. The recommendations made by the report identify the following benefits of this work: Our partners We worked with ONS' Enhanced Financial Accounts development team, who, in close collaboration with the Bank of England, are working on improving the quality, coverage and granularity of the UK's financial statistics.]]> I've been amazed at the amount of work that is taking place - from research projects using novel data sources and cutting-edge techniques, to partnerships, apprenticeships, training to build capability across ONS and far wider... the list goes on. [\"The month that was\" blog](https://datasciencecampus.ons.gov.uk/the-months-that-were-july-and-august-2018/) was doing a great job of sharing all of this, but when we evaluated its impact, we realised there was more we could be doing to reach the right people, with the right content at the right time. Over the last couple of months, we have been trialling mini newsletters to promote new content to users who have told us they have an interest in Data Science, and we've seen far greater engagement with our website content as a result. Our recent Optimus project report saw page views double in the first few days of publication as a direct result. Over the next few months, we will be conducting more extensive research into our impact, but it's clear that our users are keen to hear more about the work that we are doing. From today, we are pleased to introduce the Data Science Campus monthly newsletter. It'll include the latest on our research and capability programmes, opportunities to join the Campus, and any other relevant news from the world of ONS Data Science. Here's what we've just sent out as the ONS Digital Content team published [How Green Is Your Street](https://www.ons.gov.uk/economy/environmentalaccounts/articles/howgreenisyourstreet/2018-11-19) based on our research - [Mapping the urban forest at street level](https://datasciencecampus.ons.gov.uk/mapping-the-urban-forest-at-street-level/). [Sign up to our newsletter](https://public.govdelivery.com/accounts/UKONS/subscribers/new) if you want the latest from the ONS Data Science Campus directly to your inbox every month. We'll publish our first full newsletter in the first week of December... a great early Christmas present for the data science fanatic! Finally, we want to say a big thank you to the Design team at ONS have been working with us to get this up and running. We hope you enjoy it and we'd like to know "}