{"title": "PDF", "author": "PDF", "url": "https://www.nao.org.uk/wp-content/uploads/2002/10/01021235es.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "\u00a310.75Ordered by the House of Commons to be printed on 22 October 2002REPORT BY THE COMPTROLLER AND AUDITOR GENERAL HC 1235 Session 2001-2002: 25 October 2002Individual Learning Accounts executivesummaryINDIVIDUAL LEARNING ACCOUNTS 1executive summaryIntroduction 1 The Government introduced Individual Learning Accounts (ILAs) in England in September 2000, to widen participation in learning and to help overcomefinancial barriers to learning faced by individuals. Although anyone 1could open an account, the scheme was targeted at bringing back into learning thosepeople who had not done any for some time and those who lacked skills andqualifications. In October 2001 the Secretary of State for Education and Skillsannounced withdrawal of the scheme from 7 December 2001 because:demand for accounts was much higher than expected; there were concernsabout how the scheme was being promoted and sold; some learning providers 2 were abusing the system, offering low value, and poor quality learning; andthere were increasing numbers of complaints from learners. 2 The scheme was far more popular than expected. The Government's commitment to a million account holders undertaking learning over two yearswas achieved in September 2001, six months early. Two months later, take-uphad increased by 50 per cent. Total expenditure (as at June 2002) amounted to\u00a3273.4 million compared to a budget of \u00a3199 million. 3 In line with police advice, the Secretary of State closed the scheme with immediate effect on 23 November 2001, following allegations that a largenumber of account numbers had been extracted from the system and offeredfor sale. At the time the Department for Education and Skills 3(the Department) estimated that if the scheme was not closed immediately, the value offraudulent claims could run into tens of millions. 4 We examined the design, implementation and closure of the scheme in view of the substantial sums of public money at risk and concerns expressed by theCommittee of Public Accounts, learners and providers about the closure. Ourmethodology is summarised in Appendix 1. Our report contains wider lessons forthe design and implementation of new policies in the future.In this section Introduction 1 Overall conclusions 2 Background 3 Main findings 5 Recommendations 11 1 Aged 19 and over who satisfied residency requirements set out in the Regulations. 2 Any person, firm, company or other organisation offering training, teaching or other learning opportunities registered by the ILA Centre. 3 The Department for Education and Skills took over education responsibilities from the Department for Education and Employment in June 2001. 2executive summaryINDIVIDUAL LEARNING ACCOUNTS How individual learning accounts worked Marketing Opened account Registered on course Started courseAfter 7 days confirmed learning startedBooked course and identified incentiveLearner Learning Provider \u00a3 Received payment Decided to open accountOverall conclusions 5 Individual Learning Accounts represented innovative policy-making, which succeeded in attracting considerable new interest in learning.The emphasis on information technology (IT) in the programme alsoprovided a step towards increased \"IT literacy\" amongst the population,enabling future electronic delivery of services. The scheme had to bewithdrawn not because of its innovative nature but because of problemsarising from a variety of factors including: !pressure to implement the scheme quickly and inadequateplanning The scheme was implemented in response to a manifesto commitment over three years earlier. Two years spent on developingproposals which proved unpopular with the public and potentialproviders meant that the timetable for drawing up the specification,tendering and piloting the national scheme was too tight. Nobusiness model was drawn up evaluating costs and benefits andsecurity requirements were not specified in the contract; !risks in the design and implementation of the scheme which werenot actively managed The value of individual transactions was low, and initially the Department considered that the risks of fraud werelow. In deciding whether or not to accredit providers, theDepartment should have taken account of its recent experience withdistance learning (franchised provision) in the further educationsector. The Department did not respond fully to risks identified byconsultants in the Project Health Check, nor to bidders' concernsabout the very tight timetable for getting the scheme set up andrunning; !the relationship with Capita The Department regarded its relationship with Capita as a partnership, the risks in effect alwaysremained with the Department. The relationship bore littleresemblance to a partnership - Capita was not involved in theproject board and the Department left Capita to implement thesystem. In adopting a public-private partnership approach, theDepartment sought to comply with best practice at the time. For thesuccessor scheme, it is seeking to adopt appropriate aspects ofOffice of Government Commerce guidance on ICT 4procurement; !inadequate monitoring The Department should have monitored more closely the information supplied by Capita and the escalatingdemand for accounts, especially given the innovative nature of thescheme and increasing numbers of complaints. Capita was notrequired to undertake any spot checks on eligibility of learning norany basic validity checks to ensure bona fides of account holders.Lack of exception reporting meant that the Department wasunaware that 13 providers had registered over 10,000 accounts and20 had received payments in excess of \u00a31.5million; 6 The Department took prompt action to close the scheme when it ascertained the scale of potential fraud. Almost all providers throughwhom learning was started prior to closure of the scheme have nowbeen paid. The Department is checking claims from over 560 providers(as at 1 August 2002) and is investigating fully a relatively lowpercentage of providers with which it has concerns - some133 providers who have claimed \u00a367 million. It is likely to be up to twoyears before this work is completed and the full scale of fraud is known. 4 Information and communication technology.3executive summaryINDIVIDUAL LEARNING ACCOUNTS Created payment fileUpdated fileReview of management information Paid providerAdvertising Set up account fileDepartment for Education and SkillsCapita \u00a3Background 7 The Department set up Individual Learning Accounts in England5in response to the Government's 1997 Manifesto pledge to encouragepeople to invest in and take more responsibility for their learningthroughout their working lives. Individual Learning Accounts were to beavailable to everyone, including the self-employed, and were to be usedto pay for learning of the learner's choice. At the same time, theGovernment was keen to target people with particular learning or skillneeds; for example, young people without qualifications and in low-skill jobs, employees in small firms and those seeking to return to work. 8 In 1997, the Department sought the involvement of financial institutions in setting up accounts into which individuals could bank and savemoney for learning. After two years of research and testing of differentforms of accounts, the Department concluded that the savings to learnconcept was unpopular with individuals, providers and financialinstitutions. Instead, the Government adopted a system of subsidies,whilst retaining the name \"individual learning accounts\". In practicethey were \"virtual accounts\" for recording the discounts claimed byeach individual, and were subject to an upper limit on the totaldiscounts claimable. The scheme was to be funded from\u00a3127.5 million 6released from the wind-down of the Training and Enterprise Councils (TECs) together with additional funding of\u00a323 million (subsequently increased to \u00a340 million) and \u00a346 million in2000-01 and 2001-02 respectively. 9 To encourage innovation, the Department adopted a public-private partnership approach for the design and implementation of the scheme.But, by January 2000, after seeking competitive tenders, the Departmentwas left with only one bidder. In June 2000 the Department signed acontract with Capita to develop and operate the scheme. Capita was tooperate a call centre for enquiries about accounts as well as anadministrative centre for registering learners and providers, processingnew accounts, maintaining records of learning started and notifying theDepartment of amounts owing to providers. 10 Providers were free to market their services to prospective customers. Learners could also find out about learning opportunities from othersources such as libraries, , and UKonline centres 7. Anyone wishing to open an account had to apply to the Individual Learning Account Centre(the Centre) but had to register direct with the provider when they hadidentified the learning they wished to undertake. When registering forlearning, the account holder then gave his unique account number to theprovider and was required to pay the required minimum contribution tothe costs. Learners could register for more than one learning episode 8but had to pay the minimum contribution for each one. 11 Learners could book their learning episodes up to six months in advance. Providers were responsible for entering the proposed learningon the ILA database and the amount of the learner personalcontribution, but could not make a claim for the learning episode untilthey were able to confirm that the learner had started the learning.Capita compiled weekly and monthly payment files. The Departmentwas responsible for authorising and making payments. 5 7 November 2000. Subesquently the department's contract with Capita was amended in recognition of the signing of related contracts between Capita and Scottish Ministers andthe Northern Ireland Department for Employment and Learning. 6 The total UK figure was \u00a3150 million, of which the England share was \u00a3127.5 million. In practice the England share of the proceeds was \u00a3112.6 million, of which some \u00a329 millionis expected to be received in 2002-03 or 2003-04 as the TECs' accounts are wound up. 7 See Figure 2 overleaf.8 Course, module or unit of learning.4INDIVIDUAL LEARNING ACCOUNTSexecutive summary12 The balance between the individual's and the Government's contributions depended upon the learning to be undertaken. There were three incentiveschemes ( Figure 1 and Appendix 4). 13 The initiative was one of several designed to encourage lifelong learning (Figure 2) . 14 The Government wanted to encourage more flexible delivery of learning through a wider range of providers and in particular, those operating in smallerniche markets and those attracting new, non-traditional learners. It envisagedthat greater efficiency would result - inefficient or ineffective providers wouldmake room for new ones. The Department required providers to be registeredwith the ILA Centre and to produce evidence of public liability insurance, butit did not intend registration to be a guarantee of quality of provision. TheDepartment decided against requiring providers to be subject to qualityassurance. By November 2001, there were 8,910 registered ILA learningproviders, some of which were new ventures, with no previous involvement inpublicly funded education or training. There was no contractual relationshipbetween the Department or Capita and the providers.Financial incentive schemes available under the national ILA scheme1 Three financial incentives were available from September 2000: !an initial incentive of \u00a3150 towards the cost of eligible learning for the first million account users, with a small contribution of at least \u00a325 from the account holder; !a discount of 20 per cent on the cost of a broad range of learning capped at \u00a31009; and !a discount of 80 per cent on the cost of a limited list of basic IT and mathematics courses10, limited to a total of \u00a3200 discount per account from October 2000. NOTE Different arrangements applied to those transferring from individual learning accounts set up under the Training and Enterprise Councils. Source: Department for Education and Skills Initiatives to encourage lifelong learning Source: Department for Education and Skills2 UfI learndirect Career Development Loans UKonline centres Union expenditure million \u00a312.0 million \u00a38.1 million plus \u00a31million for basic skillsDescription of scheme Using new technologies to bring new opportunities to adults to enhance theirskills and education National learning advice service providing information and advice onlearning opportunities Deferred repayment bank loans with low interest rates to help individuals to pay forvocational education or training Centres contributing to the Prime Minister's pledge to ensure that 'everyonewho wants it has access to the Internet by2005'. They offer an introduction to theInternet and e-mail, with learner supportto help new users Promotes activity by trade unions to increase the take up of learning in the workplace 9 Appendix 4 10 Appendix 45executive summaryINDIVIDUAL LEARNING ACCOUNTS 15 The Department was responsible for formulating the policy, devising the framework for its implementation and overall design and monitoring of thescheme. The Department established a Project Board to manage the policy, thedesign and implementation, and oversee developments. It sought advice andproject management assistance from Oakleigh Consulting and from KPMG ondesigning and implementing the policy. 16 The Department's commitment was for a million people undertaking learning over two years. The final budget for England for the period was \u00a3199 million 11. Actual expenditure, as at June 2002, amounted to \u00a3273.4 million. Main findings 17 We examined three issues: a how far individual learning accounts met the policy objectives; b how well the Department managed risks in design and implementation of the scheme; c how well the Department handled the closure and wind-down of the scheme. a) How far Individual Learning Accounts met the policy objectives (Part 1) 18 The Department had strategic aims but, beyond commitment to one million account holders, the objectives were operational and were more about how thescheme would work rather than what it should achieve. No precise objectiveswere set for the overriding desired outcome of getting more people intolearning (paragraph 1.2). 19 Some 2.6 million accounts were opened, but only 58 per cent had been used by the time the scheme closed. Some had been emptied by unscrupulousproviders, but until investigations by the police and the Department's SpecialInvestigations and Compliance Units are complete, the Department is unableto determine how many of them there are affected. The Department will haveclearer view when it gets the results 12of its planned survey of users registered with providers with whom it has concerns (paragraph 1.5). 20 Although the Government made the scheme universal13, the Department targeted its marketing to specific groups (Figure 3 overleaf) . Quantified targets were not set for each group, but were drawn up for the pilot schemes whichwere established subsequently to attract specific groups of people. The SmallFirms Learning Account pilot had targets for the number of firms and thenumber of employees involved. Each group participating in the CommunityGroup pilots had to identify their own targets in advance. Similarly, individualUnion Learning Fund projects also set their own targets. 11 Includes \u00a3112.6 million from wind-down of the TECs - see Footnote 5 on page 3. 12 The Compliance Unit sample size is about 30,000 and the Special Investigation Unit sample is 20,000. Analysis of results of both is expected by mid-November 2002. 13 Open to everyone aged 19 or over, meeting the UK residency requirements as set out in the ILA Regulations, SI 2000 No. 2146 Individual Learning Accounts (England) Regulations 2000.6executive summaryINDIVIDUAL LEARNING ACCOUNTS 21 Comparison of target and actual beneficiaries is complicated by weaknesses in management information. Our analysis of available data and the Department'sresearch showed: ! the scheme encouraged people to undertake learning. Over half of the learningbooked for which data is available was entry level skills 14or Level 1 qualifications15(paragraph 1.7); ! the scheme successfully stimulated information technology learning activity -about 65 per cent was ICT 16(paragraph 1.8); ! a third of learners were aged between 19 and 30, and over a half were agedbetween 31 and 50. \"Low qualifications\" were never defined and data onhighest qualifications and other personal data were recorded and collatedwhere learners (60 per cent) had chosen to complete the relevant voluntaryfield on the form. Research 17evidence suggests that nine per cent of account users were young people with no qualifications, but the majority of learnershad level 2 qualifications (GCSEs at A*-C or equivalent NVQs) and a quarterwere graduates 18(paragraph 1.11-1.12); ! the Department sought to collect data from learners to enable it to assess theextent to which people from other target groups benefited from the scheme.However the data set was incomplete as some learners chose not to completesome voluntary fields on the application form. Research 19evidence suggests that some of the target groups have benefited (paragraph 1.13-1.16); ! The Department had planned further initiatives on targeted groups starting insummer/autumn 2001, but these initiatives were put on hold because theymight have added a lot of extra expenditure at a time when it became clear thatthe budget for the scheme would be exceeded. The Department also cancelleda planned initiative to promote ILAs to employers with a view to expandingILAs to more learners (paragraph 1.17-1.18).Target groups3 !young people Source: Department for Education and Skills 14 Numeracy and Information and Communication Technology. 15 Foundation skills.16 Information and Communications Technology.17 York Consulting.18 Capita survey of 600 learners, February to May 2002.19 York Consulting.7executive summaryINDIVIDUAL LEARNING ACCOUNTS b) How well the Department managed risks in design and implementation (Part 2) i) Policy making 22 Our analysis of the scheme design (Report Card 1) compares the Department's actions against current good practice guidance, rather than that available at thetime. We take account of the key factors, as identified in our recent reports, thatgovernment organisations should consider to prevent policy not delivering itsobjectives. Relevant extracts from our reports are included in Appendix 2. Ouroverall conclusion was that the Department had introduced innovative ideasbut that in making decisions on whether to subject providers to qualityassurance, the Department should have heeded recent experience of distancelearning (franchised provision) and its susceptibility to fraud. Report Card 1: The Department's performance measured against characteristics of modern policy-making Comments The Department piloted options through the Training and Enterprise Councils (TECs) and developed the \u00a3150 incentive to help stimulate demand. The Department recognised thescope for fraud but initially considered it low risk. In deciding whether or not providersshould be subject to any form of quality assurance, the Department should have takenaccount of its experience with overclaims in respect of distance learning (franchisedprovision) at Halton College (paragraph 2.3 to 2.9).The Department appears not to have consulted other government departments on how toprotect its systems from fraud (paragraph 2.10). Individual Learning Accounts was one of a number of initiatives to promote lifelong learning (paragraph 13). The Department sought to integrate the scheme with learndirect , but the information sets held within the databases were not compatible (paragraph 2.31-2.32). The Department generated very original ideas about client accounts and expanding the provider base (paragraphs 2.3-2.6). The Department sought risk assessment advice fromKPMG and commissioned a project health check from Oakleigh Consulting, only some ofwhich were addressed. The Department had strategic aims but beyond a commitment to 1 million account holders by April 2002, operational objectives were more about how the scheme would work, rather thanwhat it would achieve (paragraph 1.2). Options for national scheme were piloted in the TECs.The Department had commissioned KPMG to do some modelling but did not preparedetailed business process models or financial plans (paragraph 2.16). The Department prepared a rationale and objectives statement in the summer of 2000 setting out the aims of the scheme. It sought to encourage more and a wider range of typesof training providers for a wide range of clients (paragraphs 2.5 to 2.6). The Department commissioned studies during development stage to assess learner attitudes, and made limited use of evidence from pilot schemes to inform policy design(paragraphs 2.3 to 2.6). Options for a national scheme were tested through pilots in the TECs, but there were significant differences between the pilots and the national scheme as implemented(paragraph 2.4). The Department's rationale and objectives statement included proposals for evaluation of the scheme, including early satisfaction surveys, a follow-up study of a cohort of accountholders and analytical study of impacts (paragraph 2.5).The Department capped the 80 per cent discount scheme as soon as it was aware ofproblems (paragraph 2.41). The Department monitored the number of accounts opened, but it was not clear untilSummer 2001 that fraud and abuse was fuelling demand for accounts. The number ofcomplaints was relatively low compared to the number of open and active accounts, butearlier and more thorough analysis of them could have alerted the Department toemerging problems (paragraphs 2.46-2.47). The Department acted swiftly to close the scheme when it became aware of the potentiallevel of fraud (paragraph 2.42-2.50 and Part 3). Good practice 20 Departments should learn lessons - they should draw on existing knowledge and experience,taking account of internal and external views Policies should be joined-up - relationships to other policies should be considered and managed Policies should be innovative and creative , but identification and management of risks should be included within the design Policies should be forward looking - options should be developed and assessed Policies should be outward-looking - it should be clear what the policy is trying to achieve Policies should use evidence - through understanding the needs and characteristic of the client group and analysing the likelybehaviour of the client group Policies should be inclusive - the policy should have been tested prior to implementation to seehow it would work in practice Policies should be evaluated and reviewed - there should be early warning indicators to helpidentify where progress with implementation isnot as intended 20 Extracted from recent National Audit Office reports8executive summaryINDIVIDUAL LEARNING ACCOUNTS ii) Risk management 23 On effective risk management, including risks in implementing information technology projects (Report Card 2) , we refer to our findings on other procurement reports (Appendix 2). Our overall conclusion was that poor riskmanagement and an unclear relationship with Capita contributed to the closureof an innovative project due to allegations of potentially serious fraud and abuse. iii) Project management and performance 24 Our overall conclusion was that the system was implemented within a challenging timescale, but that pressure to do so resulted in corners being cut(Report card 3) . Report Card 2: The Department's performance measured against good practice on risk management Comments Users' views had been sought before implementation, and KPMG carried out a modelling exercise. Capita also drew up business plans which included the possibility of higherbusiness volumes. The Department appeared to take little notice of them, because itexpected to have difficulty attracting learners (paragraphs 2.16 to 2.17). The Department regarded Capita as a partner but in common with practice at the time, did not involve Capita staff in the Project Board. To do so would have avoided many problemsin this case (paragraph 2.23).We agree with the Education and Skills Select Committee that despite the outsourcing ofservice delivery, the form of the contract meant that the risks in effect always remainedwith the Department (paragraph 2.25). The design of the project was not informed by a formal risk analysis, although a risk register was set up and maintained prior to the scheme starting. There was no counter-fraud strategy (paragraph 2.15).Pre-launch, many risks involved in running the scheme were evaluated as low. Insufficientaction was taken on emerging issues (paragraphs 2.14- 2.15). The learning accounts were made available quickly. The Department decided against implementing quality assurance systems, but expected market forces to ensure that inefficientor ineffective providers would make room for new ones (paragraph 14). Although providers considered the sudden closure of the scheme an about turn, it was justa fortnight earlier than planned and the Department always intended implementing asuccessor (paragraphs 3.5 & 3.6-3.9). The Department acted swiftly to safeguard publicfunds as soon as it realised the potential for fraud if the scheme was not closed. After March 2000, there was a clearly identified Senior Responsible Owner in charge of the whole project. Senior management had a close interest in the success of the project(paragraph 2.11). The Department's project team did not have sufficient resources with appropriate skills for managing and implementing such a large project. KPMG and Oakleigh Consulting bothraised concerns about the adequacy of resourcing particularly in relation to contractmanagement during the lifetime of the scheme. The Department brought in more resourcesas the need for investigative resources on provider compliance became apparent(paragraph 2.13).Good practice Departments should prepare a realistic business case: !wide range of business volumes planned for !take account of user's views !not too complex !robust forecasts Department should consider risk sharing with partners: !clear partitioning of risks !top management of both organisationsinvolved in management Departments need to balance risk management and innovation: !formal risk analysis !risk monitoring !strategy for fraud Departments need to do contingency planning: !assuring for reasonable service standards and costs !adequate capacity for possible outcomes !full information to the public Departments should involve senior management: !clear senior officer !top management involved and committed Departments should ensure that the project is adequately staffed: !appropriate number of staff !suitably qualified staff9executive summaryINDIVIDUAL LEARNING ACCOUNTS Report Card 3: The Department's performance on project management and monitoring Comments Appropriate European Community tendering procedures were used following withdrawal of all but one bidder, the Department considered interim arrangementswhich might allow bidders longer to set up their systems, as well as alternatives toprivate sector delivery. The Department decided to proceed with a single bidder, anddeveloped contingency measures should the bidder withdraw, fail to demonstrategood value for money or there was a delay in implementation. KPMG carried out apublic sector comparator against which to assess reasonableness of Capita bid(paragraphs 2.18-2.22). The contract required Capita to comply with industry standards, but the Department did not specify clearly its information technology requirements, and should haveemployed information technology specialists who could have ensured that thesystem met the Department's requirements (paragraphs 2.36-2.39). The Department did not to act on KPMG's recommendation that the robustness ofinformation technology security arrangements should be fully tested (paragraph 2.37).The Department, KPMG and Capita underestimated the potential for abuse and theramifications of it. There were no processes in place to identify suspect accesspatterns and some providers exploited the system to their financial advantage(paragraphs 2.49 and 3.8). The project health check resulted in some changes in project management, but other conclusions were not followed up (paragraphs 2.13). Financial controls were inadequate, both at the Department and Capita and some which were planned were never implemented. Capita was not required under thecontract to carry out any spot checks on eligibility of learning nor any basic validitychecks to ensure the bona fides of account holders (paragraphs 2.33 and 2. 35). Although Capita produced system checks for duplicates, it was not required to carryout any such checks, nor any data validation checks as outlined in its proposal(paragraph 2.27 and Figure 10). The Department's Internal Audit postponed its planned audit of the system from April to October 2001 because of the need to investigate complaints. Early systemsaudit - although it would not necessarily have identified malpractice - may havehighlighted weaknesses in the controls before unscrupulous providers did (paragraphs2.52-2.53). The Department was under pressure to implement the scheme in autumn 2000. The Department employed commercial lawyers to draft a bespoke contract based on one developed by the former CCTA 21but with consultants' input on call centre technology issues. Records of agreed variations to contract were inadequate (paragraph 2.29). Capita regularly provided the Department with a range of management information on service provision (paragraph 2.51). The Department did not have the resources tostudy those reports.The lack of exception reports meant the Department was unaware of very large paymentsto some providers (20 providers had received \u00a31.5 million) (paragraphs 2.50-2.51). The scheme was more popular than expected. The Department acted quickly to impose cap on 80 per cent discount scheme (in first 6 weeks). The Department didnot act to ease demand until realised budget would be at least \u00a320 millionoverspent. Overspend exacerbated by decision to allow providers to complete bulkapplication forms on learners' behalf (paragraphs 2.41-44). Capita had responsibility for receiving and resolving complaints, except those about non-compliance with the programme rules. Capita maintained data on numbers ofcomplaints but the nature of them was not analysed until May 2001. (The numberreceived was less than one per cent of all accounts opened) (paragraphs 2.45-2.46).Good practice Departments should use rigorous tendering procedures !Compliance with requirement to advertise the project in the Official Journal of the EuropeanCommunities !Evaluation of competing bids Departments should ensure that they have specialist input as well as senior management commitment toinformation technology aspects of policy development,including security !Development of specification !Evaluation of bids which should include detailed plans !Ensure projects are not unreasonably large !Post-implementation review Departments should seek the opinion of an independent risk scrutineer or commission an independent project health check to report to senior management Departments should introduce good financial controls !Early advice from Internal Audit on financial controls !Internal Audit inspection of new scheme to confirm that financial controls are working properly Department should operate good contract management Departments should obtain good management information !timely reports !exception reports Departments should respond swiftly to emerging problems Departments should monitor complaints !clear responsibility for handling !analysis for common themes !adequate resources 21 Central Computer and Telecommunications Agency10executive summaryINDIVIDUAL LEARNING ACCOUNTS c) How well the Department handled the withdrawal, closure and wind-down of the scheme (Part 3) 25 Following advice from the police, the Department shut down the scheme with immediate effect on the 23rd of November 2001 due to allegations ofpotentially serious fraud and abuse. Registered learning providers had usedtheir access to the ILA database to obtain details of accounts for which theywere not authorised. To protect public funds, the Department froze allpayments to providers until validation arrangements could be put in place. Thedecision meant that some \u00a315 million was frozen temporarily as the IT systemwas shut down. Some providers told us, and the Education and Skills SelectCommittee, that this left them very short of funds. 26 The Department resumed some payments to providers on 21 December 2001, and some 95 per cent of providers' claims had been met by June 2002. As at1 August 2002, over 560 learning providers are being investigated by theDepartment's Compliance Unit. A further 133 cases are, or have been,examined by the Special Investigations Unit. Some 99 have been transferred tothe police, and one has resulted in successful prosecution. Due to the extent ofthe scheme and the volume of the complaints/police investigations it could be two years before the level of fraud or impropriety is fully known (paragraph 3.15). 27 The Department is committed to introducing a replacement ILA scheme as soon as possible. The intention is to make the scheme equally attractive topotential learners but with better expenditure controls and less potential forabuse. The Department has agreed in principle, to work with Capita indeveloping arrangements for a successor scheme. The decision on whether towork with Capita is however subject to satisfactory progress and the outcomeof negotiations with them. The Department will not finalise contractual termswith the partner, until it is satisfied that the risks involved in operating the newscheme have been minimised. The Department's conclusions so far on thelessons that need to be taken into account in developing the new one include: !the system needs stronger quality assurance mechanisms to preventunscrupulous providers benefiting from the scheme; !the Department needs better intelligence on unscrupulous providers; !the Department should derive a full business model to test how abuse could occur; !stronger IT security arrangements for a successor scheme; !better management of public/private contracts is necessary for the successor programme. 28 For development of the successor scheme, the Department is following advice from the Office of Government Commerce (OGC), under which procurementprojects are subject to review at key stages. The Department has designated theproject as \"high risk\" based on the OGC assessment criteria and subject toexternal assessment. The first reviews (business modelling and procurementstrategy) were underway in July 2002. 11 executive summaryINDIVIDUAL LEARNING ACCOUNTS Recommendations i) Departments wishing to implement innovative demand-led projects, for which there is very little or no relevant experience, should prepare detailed business process modelsand sensitivity analyses for a wide range of scenarios. They should also developcontingency plans in case the project does not proceed as expected, or expenditure issignificantly higher or lower than budget; ii) where they intend working with the private sector on a partnership basis, Departments should draw up an agreement of common purpose or \"partnering agreement\" 22which: !determines the aims, objectives and common goals of the relationship; !identifies the benefits to both the department and the supplier; iii) where all or almost all bidders drop out of competitive tendering for any innovative project, departments should revisit the design of the scheme and consider re-tenderinghaving taken account of the concerns of bidders as well as any implications for delays tothe timetable to accommodate a further tendering stage; iv) in the absence of more than one bid, departments should prepare a \"should cost model\". in addition to a public sector comparator. This represents a better simulation ofcompetition and the private sector approach; v) departments should ensure that risk registers are comprehensive and take account of recent relevant experience. They should be actively managed and counter-measuresconsidered and implemented where appropriate and departments should take action toaddress those risks, particularly those relating to fraud; vi) where they are seeking to rely on information technology, departments should obtain detailed technical advice from IT specialists, both in the preparation of specifications andassessing the feasibility of tenderers' proposals and the intended security systems; vii) departments should take an active role in contract management, recording fully any agreed changes or variations to the contract or its interpretation; viii) departments should monitor carefully any innovative programmes to ensure that they are meeting their objectives as well as commissioning exception reports to highlight anyunusual practices which might be indicative of fraud; ix) Internal Audit should be involved at project design and implementation stage to ensure adequacy of the financial controls. Early review of new systems should be carried out toensure that they are working as expected; x) departments should review any current initiatives that rely on information technology to ensure that they have adequate security controls protecting them against vulnerabilityto fraud; xi) the Department for Education and Skills should give priority to reviewing the provisions for distance learning or \"e-learning\", taking account of the inherent difficulties of verifyingthe existence of learners who do not attend classrooms and whether any learning activityhas taken place. 22 Best Practice on Managing Partnering Relationships guidance issued by the Office of Government Contracting. "}