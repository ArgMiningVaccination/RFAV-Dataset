{"title": "PDF", "author": "PDF", "url": "https://pure.uvt.nl/ws/portalfiles/portal/28429729/Dittrich_The_grass_30_11_2018.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "not always greener in the neighbor's yard Dittrich, D. Publication date: 2018 Document Version Publisher's PDF, also known as Version of record Link to publication in Tilburg University Research Portal Citation for published version (APA): Dittrich, D. (2018). The grass is not always greener in the neighbor's yard: Bayesian and frequentist inference methods for network autocorrelated data . Proefschriftmaken. General rights Copyright and moral rights for the publications made accessible in the public portal are retained by the authors and/or other copyright owners and it is a condition of accessing publications that users recognise and abide by the legal requirements associated with these rights. Users may download and print one copy of any publication from the public portal for the purpose of private study or research. You may not further distribute the material or use it for any profit-making activity or commercial gain You may freely distribute the URL identifying the publication in the public portal Take down policy If you believe that this document breaches copyright please contact us providing details, and we will remove access to the work immediately and investigate your claim. Download date: 16. Sep. 2023The grass is not always greener in the neighbor's yard: Bayesian and frequentist inference methods for network autocorrelated data Dino DittrichINVITATION to the public defense of my PhD thesis The grass is not always greener in the neighbor's yard: Bayesian and frequentist inference methods for 2018, Auditorium of Tilburg University Cobbenhagen building Warandelaan 2, Tilburg After the defense, you are cordially invited to the reception next to the auditorium. Dino Dittrich dino.dittrich@gmail.com Paranymphs Natasha Stamenkovikj Barend in the neighbor's yard: Bayesian and yard: Bayesian and frequentist inference methods for network autocorrelated data Dino DittrichINVITATION to the public defense of my PhD thesis The grass is not always greener in the neighbor's yard: Bayesian and frequentist inference methods for 2018, Auditorium of Tilburg University Cobbenhagen building Warandelaan 2, Tilburg After the defense, you are cordially invited to the reception next to the auditorium. Dino Dittrich dino.dittrich@gmail.com Paranymphs Natasha Stamenkovikj Barend in the neighbor's yard: Bayesian and yard: Bayesian and Dittrich Tilburg University Tilburg School of Social and Behavioral Sciences Department Methodology and StatisticsOriginal content: c 2018 Dino Dittrich, All rights reserved. Chapter 2: c 2016 Elsevier B.V. All rights reserved. Chapter 3: c 2017 SAGE Publications, CC-BY-NC supported by Tilburg is not always greener in the neighbor's yard: Bayesian and frequentist inference methods ter verkrijging van de graad van doctor aan Tilburg University op gezag van de rector magni cus, prof. E.H.L. Aarts, in het openbaar te verdedigen ten het college promoties commissie in de Aula van de Universiteit november 2018 dr. prof. dr. J.P. Elhorst prof. dr. H.A.J. Hoijtink dr. P. LeifeldIn memory of Majka.vii Contents 1 Introduction 1 1.1 factor model 102 Bayesian hypothesis exponential family model for network autocorrelated count data 113 1571 Chapter 1 Introduction On a quiet morning in April 2018, a few weeks before completing this thesis, I was travel- ing on country roads through north-eastern Bosnia. The sun was shining brightly, tra\u000ec was low, and I had time to observe the family homes, the restaurants, and the commercial areas that string together along the road between the towns of Ora\u0014 sje and Tuzla. Some of these looked abandoned, some were run-down, others appeared neat and tidy. Interest- ingly, or expectedly, the run-down as well as the neat properties seemed to cluster, and there were hardly any two of a di erent kind to be found next to each other. Certainly, knowing a household's income or a restaurant's revenue would have been a good indicator for the state of a property; at the same time, manpower and time are no scarce resources in Bosnia.1Hence, equally certainly, low nancial means could not have explained alone why some properties were run-down, while others seemed well-maintained. Instead, in ac- tively or passively determining their degree of engagement, households and estate owners are likely to also take into account their neighbors' behavior. This theoretical reasoning leads to the notion of network autocorrelation (Leenders, 1995; White et al., 1981). Network autocorrelation refers to the correlation of observations for a variable of in- terest among related actors in a network. In general, a network is characterized by a set of actors together with a set of ties, where a tie indicates that two actors are related to each other. For example, we could de ne a network as the set of households in a village with ties between two households based on property adjacency. Likewise, we could also de ne ties between households based on social similarity rather than property adjacency. In this thesis, we develop statistical methods for quantifying and testing the strength of the network autocorrelation of a variable of interest, as induced by a given network, while controlling for a set of explanatory variables, or covariates. This includes methods for continuous as well as count variables of interest and extends to settings in which multiple distinct networks give rise to multiple network autocorrelations. 1The unemployment rate in Bosnia and Herzegovina is one of the highest in Europe and reported to be 25.4% in 2016 by the International Labour Organization (ILO) at http://ilo.org/gateway/faces/home/ ctryHome?locale=EN&countryCode=BIH& adf.ctrl-state=2oss1sbtj 9.2 Chapter 1. Introduction 1.1 The network autocorrelation model Throughout the larger part of this thesis, we model network autocorrelation using the network autocorrelation model (Ord, 1975). Ever since its introduction, the network au- tocorrelation model has been indispensable for modeling network in uence on individual behavior and has been applied in many di erent elds, such as criminology (Tita & Radil, 2011), ecology (McPherson & Nieswiadomy, 2005), economics (Dall'erba et al., 2009), ge- ography (Mur et al., 2008), political science (Kowal, 2018), psychology (Barnett et al., 2014), public health (Myneni et al., 2015), and sociology (Mizruchi & Stearns, 2006). In the network autocorrelation model, actor observations, or responses, for a variable of interest are allowed to be correlated and a network autocorrelation parameter \u001ais es- timated, quantifying the network in uence on the variable of interest. Hence, an actor's response is assumed to be a function not only of a set of explanatory variables but also of the responses for the actor's neighbors, i.e., other actors in the network this actor is tied to. More precisely, the network autocorrelation model expands a standard linear regres- sion model by including an additional term that contains a weighted sum of the actors' neighbors' responses. The corresponding weights are given in a pre-de ned connectivity matrixwhose entries stand for the extent to which two actors in uence each other based on a particular in uence mechanism, e.g., geographic adjacency. Then, the dependence of an actor's response on its neighbors' responses is modeled using a variance-covariance matrix that is a function of the chosen connectivity matrix. Lety2Rgbe the vector of responses for gactors in a network, and let X2Rg\u0002k denote a matrix comprising values for the gactors on kcovariates (possibly including a column of ones for an intercept term). Furthermore, let W2Rg\u0002gbe a connectivity matrix with zero diagonal, where the elements Wijrepresent the in uence of actor jon actori; the larger Wij, the larger this in uence. Given the observed quantities y;X, and W, the standard, or rst-order , network autocorrelation model takes the form y=\u001aWy+X +\"; a scalar and called the network parameter, 2Rkis a vector of regression coe\u000ecients, and \"2Rgis a vector of independent and normally distributed error terms with zero mean and variance of \u001b2. The network autocorrelation parameter \u001ais the model's key parameter and quanti es the e ect of network ties on a variable of interest. When \u001a= 0, the network autocorrelation model in (1.1) reduces to a standard linear regression model with only the vector of regression coe\u000ecients and the error variance \u001b2to be estimated. 1.2 Inferential limitations in the network autocorrelation model While the network autocorrelation model has yielded valuable insights into the structure of in uence processes in numerous networks from a variety of elds, there was a lack of1.2. Inferential limitations in the network autocorrelation model 3 adequate statistical tools for applying the model in situations often encountered in empir- ical practice when starting to work on this thesis four years ago. First, the commonly used maximum likelihood estimator for the network autocorre- lation parameter \u001ahas been shown to be biased for high levels of network density and small network sizes (Mizruchi & Neuman, 2008; Neuman & Mizruchi, 2010; Smith, 2009). Moreover, in such scenarios the maximum likelihood estimator's sampling distribution has also been found to be strongly asymmetric (La Rocca et al., 2018), leading to dis- torted asymptotic standard errors and con dence intervals. Thus, relying on maximum likelihood-based inference when analyzing small and dense networks can result in incor- rect conclusions about the magnitude as well as the statistical signi cance of the network in uence on a variable of interest. Second, classical null hypothesis signi cance testing procedures for the network auto- correlation parameter can only be used to falsify the precise null hypothesis H0:\u001a= 0 of no network in uence. In practice though, researchers are often interested in testing multiple competing hypotheses on the network autocorrelation parameter against each other and in determining which out of these hypotheses is most supported by the data. For example, when interested in testing if the network in uence is zero, positive, or neg- ative, this could be done by testing H0:\u001a= 0 versus H1:\u001a >0 versus H2:\u001a <0 against one another. Classical null hypothesis signi cance testing procedures, however, can merely test hypothesis H1and hypothesis H2separately against the null, while they cannot quantify the amount of evidence in favor of any of the hypotheses tested (Wetzels & Wagenmakers, 2012). Third, in many network studies, di erent types of network in uence are likely to be present simultaneously. For example, two households can be tied to each other based on geographic adjacency and/or social similarity, where both associated networks might exert network in uence. These multiple in uence mechanisms can be modeled by adding as many connectivity matrices, representing the di erent in uence mechanisms, and net- work autocorrelation parameters to the rst-order network autocorrelation model in (1.1) as relevant to one's theory. This leads to so-called higher-order network autocorrelation models, which generally allow for a richer and more realistic modeling of network de- pendence. Most often, researchers then have expectations about the order of strength of the di erent in uence mechanisms that they would like to test explicitly. Such expecta- tions can be formulated as hypotheses on the network e.g., as H1:\u001a1> \u001a2>0,H2:\u001a1=\u001a2>0, orH3: 0< to the strength two in uence mechanisms, respectively. However, null hypothesis signi - cance testing procedures for the network autocorrelation model cannot be applied to test hypotheses on the relative strength of di erent in uence mechanisms. Fourth, the network autocorrelation model cannot be directly used to model count data, i.e., responses that can take only non-negative integer values. Nevertheless doing so when dealing with count data would lead to predicted non-integer and potentially negative responses. In some cases, it is possible to employ appropriate data transformation tech- niques to convert the original counts into approximately normally distributed data and4 Chapter 1. Introduction t the network autocorrelation model to the transformed data. In many cases though, these transformations are not suitable, e.g., when modeling rare events such as homicide, and the network autocorrelation model then also cannot be indirectly sensibly applied to count data. 1.3 Addressing the inferential limitations in the network autocorrelation model In this thesis, we will develop a Bayesian framework for rst- and higher-order network autocorrelation models to address the rst three inferential limitations in the network autocorrelation model outlined above. Furthermore, we will propose a discrete exponential family model to analyze network autocorrelated count data. We introduce the main ideas of the Bayesian and the discrete exponential family framework, and how these frameworks can help in overcoming the inferential limitations, next. 1.3.1 Bayesian estimation Bayesian estimation is fundamentally di erent from classical frequentist estimation. In Bayesian estimation, all parameters are modeled as random variables, where the informa- tion contained in the observed data is used to update the knowledge about the parameters. This prior, i.e., before observing the data, as well as posterior, i.e., after observing the data, knowledge is expressed in terms of probability distributions for the model param- eters. We denote the vector of model parameters by \u0012and the joint prior distribution for\u0012byp(\u0012). Sometimes, genuine prior knowledge is available, e.g., based on substan- tive theory or from previous empirical studies, which can be employed to specify so-called informative prior distributions. On the other hand, often such knowledge is absent and so-called non-informative prior distributions, representing prior ignorance, are relied upon instead. In a next step, the data yare taken to update the prior distribution for the model parameters and to obtain their posterior distribution . Applying elementary rules of prob- ability theory (Je reys, 1961), the posterior distribution for \u0012given the data y,p(\u0012jy), be written as p(\u0012jy) =p(\u0012)f(yj\u0012)R p(\u0012)f(yj\u0012)d\u0012; (1.2) wheref(yj\u0012) denotes the likelihood function of the data, and the denominator of (1.2) is known as the marginal likelihood that ensures that the posterior distribution integrates to unity (Kass & Raftery, 1995). In Bayesian estimation, the marginal likelihood can be ignored if it is nite, whereas it plays a central role in Bayesian hypothesis testing (Lynch, 2007). The posterior distribution p(\u0012jy) is used for all inference in the model. For example, it can be used to compute Bayesian point estimates of a model parameter, to construct so-called credible intervals , i.e., intervals in the domain of the posterior that contain an1.3. Addressing the inferential limitations in the network autocorrelation model 5 unknown model parameter with a speci c probability, or to quantify any other statistic of interest, such as p(\u0012jy)>0. Apart from axiomatic considerations, estimating the network autocorrelation model taking the Bayesian route is advantageous for at least two reasons. First, including empirical prior information can potentially mitigate the negative bias in the estimation of the network autocorrelation parameter \u001afor high levels of network density. Second, Bayesian inference is solely based on the posterior distribution and, in contrast to maxi- mum likelihood-based inference, does not rely on asymptotic theory for computing stan- dard errors or credible intervals. Consequently, uncertainty about the model parameters is appropriately accounted for even in small networks. 1.3.2 Bayesian hypothesis testing Bayesian hypothesis testing adheres to the same inherently Bayesian principle along the lines of the previous section: all hypotheses under consideration are assigned prior proba- bilities before the information in the observed data is used to update the initial probabil- ities and to obtain posterior probabilities for the hypotheses. Assume that we are inter- ested in testing T\u00152 competing hypotheses, H0;:::;HT\u00001, against each other and that one out of the Thypotheses under consideration is the true hypothesis. We denote the prior probability for a hypothesis Htbyp(Ht),t2 f0;:::;T\u00001g, wherePT\u00001 t=0p(Ht) = 1. In the absence of prior preferences for the hypotheses, these prior hypotheses probabilities are typically chosen uniformly, i.e., p(H0) =:::=p(HT\u00001) = 1=T(Berger & Sellke, 1987; Berger et al., 1997; Raftery, 1995). On the other hand, if relevant previous empirical evidence is available, it is also possible to formulate speci c prior hypotheses probabilities based on such evidence. Subsequently, the data yare used to update the prior probabilities for the hypotheses, and the posterior hypotheses probabilities are given the model parameters \u0012tunder hypothesis Ht andft(yj\u0012t) is the likelihood function of the data under hypothesis Ht. The marginal likelihood under hypothesis Htin (1.3), p(yjHt), can be seen as the average likelihood under hypothesis Htweighted by the corresponding prior pt(\u0012t) and represents the plau- sibility that the data ywere observed under hypothesis Ht; the larger p(yjHt), the more plausible that the data were observed under hypothesis Ht. The posterior hypotheses probabilities in (1.3) can then be used to quantify the plausibility of any hypothesis under consideration, including (order) hypotheses on one or multiple network autocorrelation parameters. When testing two hypotheses HtandHt0,t;t02 f0;:::;T\u00001g, against each other, theirposterior odds , i.e., the ratio of their posterior probabilities, measures to what extent hypothesis Htis favored over hypothesis Ht0. By (1.3), the posterior odds can be written6 Chapter 1. Introduction as p(Htjy) p(Ht0jy)=p(Ht) p(Ht0)p(yjHt) p(yjHt0): (1.4) The rst fraction on the right-hand side of (1.4), p(Ht)=p(Ht0), is theprior odds of the two hypotheses that indicate how much more, or less, likely one hypothesis is compared to the other prior to observing the data. The second fraction on the right-hand side of (1.4),p(yjHt)=p(yjHt0), is the ratio of the marginal likelihoods under the two competing hypotheses and is called the Bayes factor (Je reys, 1961). We denote the Bayes factor of hypothesis Htagainst hypothesis Ht0byBFtt0. As such, the Bayes factor measures to what extent the data change the prior odds to the posterior odds and can be interpreted as the amount of evidence in the data in support of hypothesis Htagainst hypothesis Ht0. For example, when Btt0= 3, the data are three times more likely to have occurred under hypothesis Htrather than hypothesis Ht0. Vice versa, when Btt0= 1=3, the data are three times more likely to have occurred under hypothesis Ht0rather than hypothesis Ht. The Bayes factor does not depend on and can be computed without specifying prior hypotheses probabilities. Hence, when testing two competing hypotheses against each other, the Bayes factor does not assume one of the hypotheses to be true but provides relative support for the two hypotheses based on the evidence in the data. However, the Bayes factor does depend on and is sensitive to the prior distribution for the model parameters under each hypothesis (Kass & Raftery, 1995). In fact, if improper priors , i.e., priors that do not integrate to a nite value, on the tested model parameters are imposed, theBayesfactordependsonunspeci edconstantsandisnotwell-de ned(O'Hagan,1995). Such improper priors are typically used when trying to represent the absence of prior information about the model parameters. One way to resolve this issue is to use part of theinformationintheobserveddatatoobtainaproperpriordistributionandsubsequently compute a pseudo-Bayes factor with the remaining information in the data (C. Han & Carlin, 2001; Robert, 2001). In Chapters 3 and 4, we will investigate the sensitivity of Bayes factor tests for the network autocorrelation parameter(s) to various priors for the latter. 1.3.3 The discrete exponential family The discrete exponential family is a widely used general formalism for modeling data with complex dependence structures (Butts, 2007; Robins, Pattison, et al., 2007; Strauss, 1986). In the context of this thesis, we rely on the formalism to specify the joint distribution for a random count variable Ythat can take only values in a nite set of count con gurations Y, i.e., we assume the count value each actor can have to be bounded. Under the formalism, the distribution for Yis written =exp\u0000 \u0012Tt(y)\u0001 P guration, \u0012is a vector of real-valued parameters,1.4. Outline of the thesis 7 andt(y) denotes a vector of su\u000ecient statistics. The denominator of (1.5) is a normalizing constant that ensures that the de ned probability distribution sums to unity. This probability distribution is formulated in terms of its su\u000ecient statistics that serve assummarymeasuresofstructuralpropertiesofajointcountcon guration. Whileinprin- ciple, there are no constraints on the choice of the su\u000ecient statistics, this choice is guided by including those su\u000ecient statistics that describe structural properties that are linked to mechanisms giving rise to an observed count con guration. In other words, and slightly abusing notation, the su\u000ecient statistics are speci ed such to represent structural prop- erties that are well-known to be enhanced, when \u0012>0, or suppressed, when \u0012<0, under certain mechanisms. Hence, the discrete exponential family formalism can be used to model network auto- correlated count data by constructing su\u000ecient statistics that appropriately capture the net tendency of tied actors to show similar (or dissimilar) counts, commonly understood as positive (or negative) network autocorrelation. Likewise, additional su\u000ecient statistics incorporating standard covariate or any other e ects on the counts can be designed. 1.4 Outline of the thesis The core of this thesis consists of the ensuing four chapters that have been written as journal articles and can be read comprehensibly independently from each other. Chapters 2, 3, and 4 focus on developing Bayesian methodology for the network autocorrelation model. Chapter 5 introduces a discrete exponential family model for analyzing network autocorrelated count data and is slightly less expository in style than the other chapters. In Chapter 2, we provide new Bayesian estimation methods for the network autocor- relation model that address the issues inherent to maximum likelihood estimation of the model. For any Bayesian estimator, the prior distribution for the model parameters im- pacts the properties and the performance of the estimator. Thus, we motivate and derive several priors for the parameters in the network autocorrelation model in this chapter. We rst derive two versions of Je reys prior (Je reys, 1961), Je reys rule prior andIndepen- dence Je reys prior , which have not yet been established for the network autocorrelation model. Je reys prior construes the concept of a non-informative prior in a formal way, and these priors can be used for a Bayesian estimation of the network autocorrelation model when prior information is unavailable. Second, we propose an informative prior for the network autocorrelation parameter \u001abased on a meta-analysis of empirical applications of the network autocorrelation model. This is the rst empirically justi ed informative prior for \u001ato be found in the literature and systematically shows that positive network autocorrelation is much more prevalent in empirical practice than negative network auto- correlation. All of the resulting posterior distributions do not belong to a family of known probability distributions and hence, summary measures for the posteriors, such as the mean or quantiles, are analytically not available. We present new and more e\u000ecient pro- cedures than currently to be found in the literature for sampling from the corresponding posterior distributions. Lastly, we conduct a simulation study to evaluate the performance8 Chapter 1. Introduction of the di erent Bayesian estimators as well as the maximum likelihood estimator. In Chapter 3, we introduce Bayesian hypothesis tests for the network autocorrelation parameter \u001a, including precise hypotheses, e.g., H0:\u001a= 0, as well as interval hypotheses, e.g.,H1: 0< \u001a <1. When testing such hypotheses on the autocorrelation pa- rameter using the Bayes factor, the Bayes factor can be sensitive to the choice of the prior distribution for \u001aunder interval hypotheses. We present three Bayes factors for testing the aforementioned hypotheses that are not yet available for the network autocorrelation model: rst, we consider a Bayes factor using the empirical informative prior from Chap- ter 2; second, a Bayes factor based on the standard uniform prior for \u001atypically used in the literature (Hepple, 1995a; Holloway et al., 2002; LeSage, 1997a); third, we develop a so-called fractional Bayes factor (O'Hagan, 1995) where a default prior for \u001ais auto- matically constructed by updating an improper prior with a fraction of the information contained in the observed data, while the fractional Bayes factor itself is computed using the remaining information in the data. Furthermore, we employ the empirical informative prior also for specifying prior probabilities for interval hypotheses, which is new to the literature. We show how the presented methodology can be straightforwardly adapted to test more than two hypotheses against each other, which is particularly relevant in the network autocorrelation model, as the literature suggests that the question is not if network autocorrelation occurs but to what extent. We carry out a simulation study to investigate numerical properties of these Bayes factors, and we demonstrate their use by re-analyzing three empirical data sets from the literature. In Chapter 4, we extend the developed methods for the rst-order network autocorre- lation model in Chapters 2 and 3 to higher-order network autocorrelation models involving multiple connectivity matrices and network autocorrelation parameters. As to that, we propose computationally e\u000ecient Bayesian estimation techniques for higher-order network autocorrelation models based on a general multivariate normal prior for the network au- tocorrelation paramaters. Moreover, we introduce adeptly implemented Bayes factors for simultaneously testing multiple order hypotheses on the network autocorrelation parame- ters against one another. Our Bayes factors are based on automatically constructed multi- variate normal default priors for the network autocorrelation paramaters, which eliminates the need for di\u000ecult prior elicitation under each hypothesis. As such, the proposed Bayes factors provide means for quantifying the relative evidence in the data in favor of any hy- pothesis on the network autocorrelations parameters, including equality constraints, e.g., H0:\u001a1=\u001a2= 0, inequality constraints, e.g., H1:\u001a1> \u001a2>0, or a combination of equality and inequality constraints, e.g., H2:\u001a1> \u001a2= 0. Subsequently, we investigate to what extent the Bayes factors provide evidence for a true data-generating hypothesis when tested against several competing hypotheses by means of a simulation study. Finally, we illustrate our methods on a data set from the economic growth theory, where we explore the structure of spatial autocorrelation of growth rates of labor productivity in service industry across 188 territorial units in the European Union. In Chapter 5, we present a discrete exponential family model for analyzing network au- tocorrelated count data. In our approach, we use the discrete exponential family to specify1.4. Outline of the thesis 9 the joint count distribution in terms of its su\u000ecient statistics. We propose various sets of su\u000ecient statistics representing network autocorrelation, standard covariate e ects, and basic structural properties of the counts, such as the central tendency, the dispersion, and the sparsity of the counts, that are deemed to have generated an observed count con gu- ration. Furthermore, we provide algorithms to simulate count con gurations and to carry out maximum likelihood-based inference in the model. In addition, we introduce tailored goodness-of- t measures based on the predictive distribution for the counts. Lastly, we illustrate the capability and the practical implementation of our model by re-investigating the causes of homicide in 343 neighborhoods in Chicago, Illinois. In Chapter 6, the nal chapter of this thesis, we summarize our main results and re ect upon their usefulness in resolving the inferential limitations in the network autocorrela- tion model that inspired this thesis. We conclude by pointing out remaining issues and by discussing future research topics related to network autocorrelation modeling.11 Chapter 2 Bayesian estimation of the network autcorrelation model Abstract The network autocorrelation model has been extensively used by researchers interested modeling social in uence e ects in social networks. The most common inferential method in the model is classical maximum likelihood estimation. This approach, however, has known problems such as negative bias of the network autocorrelation parameter and poor coverage of con dence intervals. In this chapter, we develop new Bayesian estimation techniques for the network autocorrelation model that address the issues inherent to max- imum likelihood estimation. A key ingredient of the Bayesian approach is the choice of the prior distribution. We derive two versions of Je reys prior, Je reys rule prior and Independence Je reys prior, which have not yet been developed for the network auto- correlation model. These priors can be used for Bayesian estimation of the model when prior information is unavailable. Moreover, we propose an informative as well as a weakly informative prior for the network autocorrelation parameter that are both based on an extensive literature review of empirical applications of the network autocorrelation model across many elds. Finally, we provide new and e\u000ecient Markov Chain Monte Carlo al- gorithms to sample from the resulting posterior distributions. Simulation results suggest that the considered Bayesian estimators outperform the maximum likelihood estimator with respect to bias of and frequentist coverage of credible and con dence intervals for the network autocorrelation parameter. This chapter is Mulder, J. (2017). 48(1): 213-236. http://doi.org/10.1016/j.socnet .2016.09.002 .12 Chapter 2. Bayesian estimation of the network autcorrelation model 2.1 Introduction Identifying and estimating network in uence on individual behavior is a common and im- portant challenge encountered in social network analysis. Throughout the last decades, a number of di erent models studying network in uence e ects have emerged, out of which the network autocorrelation model is probably the most popular one (Leenders, & Friedkin, 1993; Pl\u007f umper & Neumayer, 2010; W. Wang et al., 2014). A traditional and widely used technique for parameter estimation in the network au- tocorrelation model is maximum likelihood estimation (Doreian, 1981; Ord, 1975), which has also been implemented in common statistical software packages such as R (Bivand & Piras, 2015; Butts, Matos, 2015), MATLAB 1999), Python (Rey & Anselin, 2007), and Stata (Pisati, 2001). Despite the popularity and usefulness of maximum likelihood estimation, there are also important issues related to this estimation technique of the model. First, several simulation studies have suggested that the maximum likelihood estimator for the network autocorrelation parameter \u001ais negatively biased under many di erent scenarios, that the underestimation of \u001abecomes more severe for increasing network density, and that it oc- curs regardless of the network structure and the network size (Mizruchi & Neuman, 2008; Neuman & Mizruchi, 2010; Smith, 2009). Second, maximum likelihood-based precision estimates, such as con dence intervals, rely heavily on asymptotic theory. Consequently, the coverage of the associated con dence intervals may be distorted for small to medium samples that are often encountered in social science research, such as school classes, care teams, or members of an executive board. Notwithstanding the tremendous capability of the network autocorrelation model and the theoretical advances it has yielded for un- derstanding the structure of social in uence in social networks, the concerns regarding the maximum likelihood estimation approach may ultimately discourage researchers from utilizing the model at all. In this chapter, we develop Bayesian statistical estimation methods for the network autocorrelation model that may attenuate the issues which have been encountered with maximum likelihood estimation. The Bayesian approach has at least two attractive fea- tures that are not shared by classical methods. First, it allows researchers to incorporate external information about the model parameters via a prior distribution . For example, if previous research has suggested that people in a certain network are positively in uenced by each other, as is often the case in social networks, one could specify a prior distribu- tion that assumes positive values for the network autocorrelation \u001ato be more likely than negative ones. Indeed, as we will show in Section 2.4, the vast empirical literature on the model suggests that network e ects are much more likely, a priori, to be in certain intervals than in others. Second, Bayesian analysis provides \\exact\" inference without the need for asymptotic approximations (De Oliveira & Song, 2008). This characteristic is especially appealing for small- to moderate-sized groups and can be seen as a distinct advantage of the Bayesian approach over classical frequentist methods. In other words, when networks are small, Bayesian estimation of the network autocorrelation model is2.1. Introduction 13 statistically preferable over frequentist estimation. Bayesian statistics is a fundamentally di erent approach than classical statistics. In brief, a Bayesian data analysis is carried out as follows. First, a prior distribution, or simplyprior, for the model parameters is needed, where the prior distribution re ects the prior knowledge about the model parameters before observing the data. If prior informa- tion is available, e.g., based on published literature, an informative prior can be speci ed. On the other hand, if such information is absent, a so-called non-informative prior can be employed. After observing the data, Bayes' theorem is used to update the prior expec- tations with the information contained in the data to arrive at the posterior distribution , orposterior , for the model parameters. All inference is based on the posterior, and it is used to obtain Bayesian point estimates and credible intervals , the Bayesian equivalent to classical con dence intervals. Although the speci cation of the prior distribution is one of the most important steps in any Bayesian analysis, it has not received much attention in the literature on Bayesian estimation of the network autocorrelation model (X. Han & Lee, 2013; Hepple, 1995b; Holloway et al., 2002; LeSage, 2000; 2009), with the exception of LeSage (1997a) and LeSage & Parent (2007). In some cases, it is in fact di\u000ecult to elicit a prior, e.g., when prior information is absent, or when a researcher would like to add as little prior information as possible to the analysis. For these situations, non-informative priors are typically used to carry out a Bayesian analysis. In this chapter, we are the rst to derive two versions of Je reys prior (Je reys, 1961), called Je reys rule prior andIndependence Je reys prior , for the network autocorrelation model and to establish results on the pro- priety of the resulting posterior distributions. Je reys rule prior construes the concept of a non-informative prior in a formal way and is the most commonly used non-informative prior (De Oliveira & Song, 2008). Moreover, in several simulation studies of related au- toregressive models, Independence Je reys prior has been shown to result in superior in- ferences compared to those based on maximum likelihood estimation (De Oliveira, 2012; De Oliveira & Song, 2008). These ndings serve as another motivation to consider the two versions of Je reys prior for the network autocorrelation model as well. Furthermore, we provide a novel informative prior for the network e ect \u001abased on an extensive literature review of empirical applications of the network autocorrelation model. To the best of our knowledge, this is the rst empirically justi ed informative prior for \u001a to be found in the literature. Because of the empirical justi cation of this prior, it is a reasonable \\entry point\" for a Bayesian analysis of the network autocorrelation model, as it summarizes the currently available evidence about observed network autocorrelations from many di erent sources. Moreover, we introduce a related weakly informative prior for\u001athat can be used by a researcher who agrees that past ndings should not be dis- missed but who is at the same time reluctant and deliberately refrains from including all available prior information. In addition, we present e\u000ecient Markov Chain Monte Carlo (MCMC) algorithms for sampling from the resulting posterior distributions, which we nd to be computationally superior compared to existing schemes (LeSage, 2000; LeSage & Pace, 2009). We conduct14 Chapter 2. Bayesian estimation of the network autcorrelation model a simulation study to investigate numerical properties of Bayesian inferences about the network e ect \u001aand the error variance \u001b2based on the proposed priors and to compare them to inferences coming from maximum likelihood estimation. As will be shown, the Bayesian estimator based on the informative prior performs overall the best when network e ects are positive, while using the weakly informative prior eliminates virtually all the negative bias in the estimation of \u001ain case of no or marginal network e ects. We proceed as follows: in Section 2.2, we discuss the network autocorrelation model in more detail. We continue with a short introduction to the Bayesian approach in regard to the model in Section 2.3. In Section 2.4, we derive two versions of Je reys prior and propose an informative as well as a weakly informative prior for the network autocorre- lation parameter \u001abased on reported network e ects from the literature. Moreover, we state properties of these priors and their corresponding posteriors and provide compar- isons between the priors. In Section 2.5, we present e\u000ecient MCMC implementations for Bayesian estimation of the model. We assess the numerical performance of the Bayesian estimators and the maximum likelihood estimator in a simulation study in Section 2.6. Section 2.7 concludes. 2.2 The network autocorrelation model Originally developed by geographers (Ord, 1975), the network autocorrelation model has been used to address the problem of structured dependence ever since. In contrast to a standard linear regression model, the network autocorrelation model does not assume observations for a variable of interest to be independent from each other but allows for dependence among them. In a social network context, this has the interpretation that ego's opinion may not solely depend on exogenous variables; instead, ego's opinion might be in uenced by the opinions of other actors in the network as well. Thus, in the net- work autocorrelation model, ego's opinion is viewed as a combination of interaction and exogenous variables, formally expressed as y=\u001aWy+X +\";\"\u0018N\u0000 0g;\u001b2Ig\u0001 ; (2.1) where, as in standard linear regression, yis a vector of length gconsisting of values for a dependent variable for the gnetwork actors, Xis a (g\u0002k) matrix of values for the gactors on kcovariates (possibly including a vector of ones in the rst column for an intercept term), is a vector of regression coe\u000ecients of length k,0gis a vector of zeros of lengthg,Igsymbolizes the ( g\u0002g) identity matrix, and \"is a vector of length gcontaining independent and identically normally distributed error terms with zero mean and variance of\u001b2. Furthermore, Wdenotes a given ( g\u0002g)connectivity matrix representing social ties in a network, where each entry Wijstands for the degree of in uence of actor j(alter) on actori(ego). By convention, we exclude loops, i.e., relationships from an actor to himself, soWii= 0 for all i2 f1;:::;gg. Finally, the network autocorrelation parameter. Itisthekeyparameterofthemodelandmeasuresthelevelofnetworkin uence on a variable of interest for given y,W, andX. Note that when \u001a= 0, the model reduces2.3. Bayesian network autocorrelation modeling 15 to a standard linear regression model. The likelihood of the model in (2.1) is given jdet(A\u001a)jis non-zero and the model's likelihood function in (2.2) is well-de ned, there are restrictions on the feasible values for \u001a. In practice, the admissible range of \u001ais usually chosen as the interval containing \u001a= 0 for which A\u001ais non-singular LeSage & \u0015\u00001 W(Hepple, 1995a), and we follow this convention in the remainder of the chapter.1;2We denote the resulting set of model parameters by \u0012:=\u0000 \u001a;\u001b2; \u0001 and space has the remarkable property that it depends on properties, i.e., the eigenvalues, of the connectivity matrix W. Throughout the literature, the model is also referred to as mixed regressive-autoregres- sive model (Ord, 1975), spatial e ects model (Doreian, 1980), network e ects model (Dow et al., 1982), or spatial lag model (Anselin, 2002), and it has been applied in many di erent elds, such as criminology (Baller et 2010; Seldadyo et al., 2010), political science (Beck et al., 2006; Shin & Ward, 1999; Tam Cho, 2003), and sociology (Kirk & Papachristos, 2011; Land et al., 1991; Ruggles, 2007). 2.3 Bayesian network autocorrelation modeling ThestartingpointofeveryBayesiananalysisistheformulationofpriorexpectationsabout the parameters in a statistical model. Formally, these prior expectations are expressed in terms of probability distributions, where the resulting prior distributions represent the available knowledge about the model parameters before observing data. We denote the joint prior distribution for all model parameters by p(\u0012). In general, prior expectations can come from a researcher's beliefs or from accumulated empirical evidence from previous 1Toavoidunnecessarycomplications, werestrictourselvestoconnectivitymatriceswithrealeigenvalues. These include all Wthat are either symmetric or row standardizations , i.e., where each row sums to one, of symmetric matrices (Smith, 2009). Furthermore, we assume that \u00151>0, which includes all non-zero symmetric connectivity matrices (Smith, 2009), so \u0015g<0< \u00151since tr( W) = 0. In the common case of row-standardized connectivity matrices, it follows that \u00151= 1 (Anselin, 1982). 2It is mathematically not necessary to the space of \u001ato\u0000 \u0015\u00001 g;\u0015\u00001 1\u0001 eigenvalues of Wfrom the domain of \u001a, asA\u001ais singular only for those values (Leenders, 1995). Some authors prefer to restrict \u001ato (\u00001;1), as8\u001a2(\u00001;1) :A\u00001=P1 k=0\u001akWk, which implies an underlying 1979). We choose the interval\u0000 \u0015\u00001 g;\u0015\u00001 1\u0001 rather than (\u00001;1) as admissible range of \u001a, as the latter choice might yield estimates of \u001aat the lower boundary of the interval and considering the whole parameter space Rn\b \u00151\u00001;\u00152\u00001;:::;\u0015g\u00001 typically results 1\u0001 : det(A\u001a)>0, so we jA\u001ajforjdet(A\u001a)jin the remainder of the chapter.16 Chapter 2. Bayesian estimation of the network autcorrelation model studies in a eld. Alternatively, one might also (purposely) stay vague and opt for a non- informative prior distribution. The idea of a non-informative prior is that it is completely dominated by the data and di erent methods have been proposed how to construct such priors 1979; Box & 1996). After having speci ed a prior distribution, the data yare observed. Since the data contain information about the unknown parameters, they can be used to update the initial expectations. The information about the model parameters in the data is summarized by the likelihood function, f(yj\u0012). Linking information from the prior distribution and the data leads to the posterior distribution for the model parameters, which we denote by p(\u0012jy). Applying elementary rules of probability theory, the posterior can be written by Bayes' theorem as p(\u0012jy) =f(yj\u0012)p(\u0012) p(y): (2.3) The denominator of (2.3) is called the marginal likelihood and serves as normalizing constant to ensure that the posterior integrates to unity. However, as the normalizing con- stant does not depend on the model parameters and does not a ect parameter estimation, the expression in (2.3) can be simpli ed to p(\u0012jy)/f(yj\u0012)p(\u0012): (2.4) Hence, (2.4) means that the posterior distribution is proportional, with respect to the model parameters \u0012, to the prior distribution multiplied by the likelihood function. Formally, the normalizing constant can only be dropped if it is nite, i.e., if the posterior is integrable and thus a proper probability distribution. For the network autocorrelation model, this is the case when the network size, compared to the number of covariates, is large enough. We will come back to this in the following section. The posterior distribution can then be used to derive point estimates of the model parameters (e.g., the posterior mean or the posterior median), credible intervals (i.e., intervals in the domain of the posterior), or to get other statistics of interest, such as the probability that the network autocorrelation is positive for given data, p(\u001a >0jy). The latter statistic is quite useful for quantifying a researcher's belief that people in a network positively in uence each other with respect to some variable of interest. However, such a probability cannot be obtained when using classical frequentist methods but only when taking the Bayesian route. 2.4 Prior choices in the network autocorrelation model The speci cation of the prior distribution is one of the most important steps in a Bayesian analysis. Despite its importance, prior speci cation in the network autocorrelation model has been largely neglected. Most of the previous work on Bayesian estimation of the model has been based on using uniform priors for \u001a, , LeSage, 1997a, 2000). Only recently, X. Han & Lee (2013) and LeSage & Pace2.4. Prior choices in the network autocorrelation model 17 (2009) considered the standard normal inverse gamma priors for and\u001b2from linear regression, resulting in an inverse gamma prior for \u001b2and a normal prior for conditional on\u001b2, together with the standard uniform prior for \u001a. In this section, we brie y review the standard uniform prior for \u001a rst, before deriving two versions of Je reys prior and proposing two novel informative priors for the network e ect\u001a. 2.4.1 Flat prior Using at, oruniform,priorsis the simplest and most intuitive way to quantify prior ignorance about model parameters. A uniform prior assigns equal, or uniform, probabil- ity to all possible values a parameter can attain, resulting in a at prior density func- tion. Applying this rationale to the network autocorrelation model means that all possi- ble network e ects \u001aand regression coe\u000ecients are considered as equally likely before observing the data. In mathematical notation, we denote the at prior distributions for \u001aand bypF(\u001a)/1 andpF( )/1, respectively. As noted in the previous section, for estimation purposes it su\u000eces to give the prior distributions in these unnormalized forms. Furthermore, the error variance \u001b2is constrained to the positive axis, and it is customary to consider its logarithm and assign a at prior to this transformed variable (Fern\u0013 andez et al., 2001; Kass & Wasserman, 1996). Retransforming the at prior \u001b2\u0001 back in terms of \u001b2yieldspF\u0000 \u001b2\u0001 /1=\u001b2. Finally, under the at prior all parameters are assumed to be a priori independent. The at prior for \u0012=\u0000 \u001a;\u001b2; \u0001 is then written as pF(\u0012) =pF(\u001a)\u0002pF\u0000 \u001b2\u0001 \u0002pF( )/1=\u001b2: This prior is sometimes also referred to as the di use prior in the literature (Hepple, 1979; LeSage, 1997a, 2000). While it is obvious that the at prior itself is improper, i.e., the integral of pF(\u0012) on \u0002 is not nite, it is easy to verify that the resulting posterior distribution is proper under the very weak conditions stated in Corollary 2.1. Corollary 2.1. Consider the network autocorrelation model in (2.1). Then, (i) The at prior pF(\u0012)is unbounded and not integrable on the two mild regularity conditions in Corollary 2.1 (ii) hold, the at prior yields a proper posterior when the number of actors in a network is larger than the number of external covariates. While the rst regularity condition can be easily controlled for by avoiding perfect collinearity, the second one is of technical nature and needs to be checked for each data set.18 Chapter 2. Bayesian estimation of the network autcorrelation model 2.4.2 Je reys rule prior Flat priors are only one possible way to state prior ignorance; they are driven mainly by what intuitively seems to represent non-informativeness, rather than being based on a set of formal rules that de nes non-informativeness mathematically. The rst formal rule for specifying non-informative prior distributions was introduced by Sir Harold Je reys, and much of subsequent related work is based on modi cations of Je reys' scheme (Je reys, 1961; Kass & Wasserman, 1996). The main motivation for Je reys rule prior is that statistical inference should not depend on any speci c parametrization of the model, which could often be rather arbitrary. For example, if the network autocorrelation model is rewritten in terms of a precision parameter !:= 1=\u001b2, rather than \u001b2, applying Je reys rule prior to the model formulated with respect to !or\u001b2results in the same posterior conclusions about the network e ect. Hence, when using Je reys rule prior, there is no need to determine a privileged parametrization as the prior is parametrization-invariant. Formally, Je reys rule prior is de ned as pJ(\u0012)/p det(I(\u0012)); whereI(\u0012) denotes the model's Fisher information matrix. The exact analytical form of the prior is given in Theorem 2.1. Since Je reys rule prior for the network autocorrelation model is improper, the propriety of the resulting posterior needs to be checked and is veri ed in Corollary 2.2. Theorem 2.1. Consider the network autocorrelation model in (2.1)and assume that\u0000 XTX\u0001\u00001exists. in (2.1)and assume that\u0000 XTX\u0001\u00001exists. Then, (i) Je reys rule Je reys rule prior has the desirable property to be invariant under one-to-one parame- ter transformations and most often results in reasonable priors in one-dimensional mod-2.4. Prior choices in the network autocorrelation model 19 els. However, applying the rule in multi-parameter models may result in poor frequen- tist properties of Bayesian inferences (Berger et al., 2001; De Oliveira, 2010; De Oliveira & Song, 2008), or improper posteriors (Berger et al., 2001; Bolstad, 2009; Rubio & Steel, 2014). Thus, already Je reys himself argued that it is often better to consider certain blocks of parameters as a priori \\independent\" from each other and to compute the marginal prior for each parameter block using Je reys rule, assuming the other pa- rameters to be known (De Oliveira & Song, 2008). The resulting product of the marginal priors is then called Independence Je reys prior. Following Bayesian analyses of related autoregressive models (Berger et al., 2001; De Oliveira, 2012; De Oliveira & Song, 2008), we split the network autocorrelation model parameters into the two blocks\u0000 \u001a;\u001b2\u0001 and and derive Independence Je reys prior based on this partitioning of the model parame- ters. We give the prior's analytical form in Theorem 2.2 and provide its main theoretical properties in Corollary 2.3. Theorem 2.2. Consider the network autocorrelation model in (2.1). Then, Independence Je reys prior Consider the network autocorrelation model in (2.1). Then, (i) Independence Je reys prior pIJ(\u0012)is unbounded of Independence Je reys prior in (2.6) is similar, but slightly simpler, to the one of Je reys rule prior in (2.5). The major di erence between the two is that for Je reys rule prior the exponent of the error variance depends on the number of covariates, k, while it does not for Independence Je reys prior. For related models (Berger et al., 2001; De Oliveira, 2012; De Oliveira & Song, 2008), it has been shown that havingkin the exponent of \u001b2, as in Je reys rule prior, could result in an underestimation of the error variance. We will therefore investigate whether this is also the case in the network autocorrelation model, and if this underestimation occurs, whether it can be circumvented by using Independence Je reys prior. Hence, while Je reys rule prior is based on an invariance principle, Independence Je reys prior is a heuristic modi cation of Je reys rule prior that can result in better inferences.20 Chapter 2. Bayesian estimation of the network autcorrelation model 2.4.4 An informative prior for \u001a Having discussed three prominent non-informative priors above, in this subsection, we derive a population distribution for \u001abased on an extensive literature review of empirical applications of the network autocorrelation model. Subsequently, this population distri- bution is used as an informative prior for \u001a. In our literature search, we considered 81 peer-reviewed publications and a total of 183 estimated network autocorrelation parameters. The most important characteristics of this sample are summarized in Table 2.1.3As network e ects in one publication are usually from the same eld and closely related, this suggests that these network autocor- relations are more similar than network e ects coming from di erent studies. To take this into account, we relied on a hierarchical approach and used the following multilevel model (Gelman et al., 2003) to estimate the population distribution of the network e ects: Level 1: \u001aij\u0018N\u0000 \u001aj;\u001b2 f1;:::;81g,\u001aijis from eld j, andf\u001ajgj;\u0016\u001a;\u001b2 \u001a, and 2 \u001aare model parameters that have to be estimated. The distribu- tion in Level 1 corresponds to the empirical distribution of a network e ect in a speci c eld. The distribution in Level 2 denotes the overall population distribution in which we are ultimately interested in. We tted the model in R (R Core Team, 2017) relying on a Bayesian framework and using standard priors for \u0016\u001a; \u001a, and log\u0000 \u001b2 \u001a\u0001 2006). resulted in posterior mean estimates of \u0016\u001a=:36 and \u001a=:19.4The resulting informative prior for \u001a,pEI(\u001a)\u0018N\u0000 \u0016\u001a; 2 \u001a\u0001 , and the histogram of the average network e ects from each eld are plotted in Figure 2.1. As can be seen, the multilevel model in (2.7) provides a reasonably good t to the empirical data. Figure 2.1 also shows that there are substantially more reported positive network ef- fects than negative ones in the literature. This nding con icts with a at prior for \u001aon\u0000 \u0015\u00001 g;\u0015\u00001 1\u0001 , which typically implies that negative network e ects are a priori more likely than positive network e ects and is clearly unrealistic.5 We combine this empirical informative prior for \u001awith the standard non-informative prior for\u0000 \u001b2; \u0001 from Section 2.4.1, assuming all parameters to be a priori independent.6 3We did not attempt to be fully comprehensive here and do not claim to have included all available literature on empirical applications of the network autocorrelation model. Our selection features work that (i) used row-standardized connectivity matrices, (ii) speci ed the network size and the type of connectivity matrix, and (iii) employed appropriate estimation techniques for the given type of data. 4The associated 95% credible intervals g\u0014 \u00001 (Stewart, 2009, Property 10.1.2), and for most of the simulated data sets we considered, we observed that \u0015\u00001 g<\u00001. Thus, as \u0015\u00001 1= 1, in these cases the at prior assigns more probability mass to negative network e ects than to positive ones. 6Propriety of the resulting posterior distribution, under the conditions given in Corollary 2.1, follows immediatelyfromthecorollary'sproof. Ourinformativepriorfor \u001acanbeeasilycombinedwithinformative priors for \u001b2and as well. We use non-informative improper priors for the latter parameters because our main focus lies on estimating the network e ect \u001a.2.4. Prior choices in the network autocorrelation model 21 Density 0.5 0.0 0.5 1.00.00.51.01.52.02.5 Informative prior Figure 2.1 Histogram of the average network e ects from each eld\b \u001aj j,\u001aj:=Pnj i=1\u001aij=nj, and probability density function of the tted normal population distribution for\u001a. Hence, the resulting empirical informative prior for \u001a There may be cases in which a researcher does not expect a network e ect to be present in the data, or it may be that the researcher does not (want to) entertain the prior belief that the level of network autocorrelation in a data set is likely to t with the empirical literature at large. In these cases, a researcher might purposely prefer to use less prior knowledge than actually available in the literature and rely on a so-called weakly informative prior distribution (Gelman et al., 2003). We construct such a weakly informative prior for \u001aby imposing a normal prior that is centered around :36, as is the empirical informative prior, but with a deliberately much larger standard deviation, accounting for the uncertainty in one's prior beliefs. We set the weakly informative prior's standard deviation to :7, compared to :19 for the empirical informative prior, yielding a broad and fairly at prior that still results in at least 62% of prior probability mass being contained in the unit interval (0 ;1). As for the empirical informative prior, we impose standard non-informative priors for\u0000 \u001b2; \u0001 , assuming all =pWI(\u001a)\u0002pF\u0000 \u001b2\u0001 \u0002pF( )/N\u001a\u0000 of the network autcorrelation model Table 2.1 Characteristics of the studies used for the speci cation of the empirical informa- tive prior for \u001a. Study Field g Type of W Method \u001a 1 Andersson et al. (2010) Property prices 1,034 Inverse distance ML .52 2 Anselin (1984) House values 49 First-order contiguity ML .28 3 Anselin (1990) Wage rates 25 First-order contiguity ML -.62 4 & Le Gallo 115,732 First-order contiguity ML .44 103,867 First-order contiguity 2SLS 1,671 First-order contiguity HAC .24 7 Anselin et al. 89 Distance-based contiguity 2SLS .23 8.1 Arbia & Basile (2005) GDP growth rates 92 First-order contiguity ML .33 8.2 .18 8.3 .34 9 Armstrong & Rodr\u0013 \u0010guez (2006) Property values 1,860 Inverse distance ML .36 10.1 Baller et al. (2001) Homicide rates 1,412 Nearest neighbors IV .71 10.2 .65 10.3 .18 10.4 .23 11.1 Bernat Jr. (1996) Economic growth 49 Squared inverse distance ML .35 11.2 .42 11.3 .70 12.1 Bivand & Szymanski (2000) Garbage collection 324 First-order contiguity ML .15 12.2 .10 13 Bordignon et al. (2003) Tax rates 143 First-order contiguity ML .16 14.1 Brueckner & Saavedra (2001) Tax rates 70 Population weights ML .16 14.2 .04 14.3 .26 15.1 Buonanno et al. (2009) Crime patterns 103 Inverse traveling distance 2SLS -.54 15.2 .19 15.3 .21 16.1 Burt & Doreian (1982) Scienti c publishing 52 Structural equivalence ML .26 16.2 .21 16.3 .25 16.4 .45 16.5 .29 16.6 .31 16.7 .26 16.8 .54 17 Can (1992) House prices 563 Squared inverse distance ML .41 18 Carruthers & Clark (2010) House prices 28,165 Nearest neighbors 2SLS .17 19.1 Chang (2008) Water quality 94 First-order contiguity ML .19 19.2 .14 19.3 .49 19.4 .48 19.5 .56 19.6 .15 19.7 .42 19.8 .43 19.9 .37 19.10 .56 19.11 .44 19.12 .42 .51 19.25 .472.4. Prior choices in the network autocorrelation model 23 Table 2.1 (continued). Study Field g Type of W Method \u001a 20 Cohen & Coughlin (2008) House prices 508 Inverse distance ML .26 21 Conway et al. (2010) House prices 260 First-order contiguity ML .11 22 Dall'erba (2005) GDP growth rates 48 Most accessible neighbors ML .40 23 Doreian (1980) Huk rebellion 57 First-order contiguity ML .47 24.1 Doreian (1980) Voting behavior 64 First-order contiguity ML .61 24.2 .26 24.3 Doreian (1981) .12 24.4 .29 24.5 Leenders (2002) .31 25 Dow (2007) Income contributions 158 Lexical distance 2SLS .76 26 Easterly & Levine (1998) GDP growth rates 234 Economic size 2SLS .55 27 Elhorst (2014) Crime rates 49 First-order contiguity ML .43 28 Ertur et al. (2007) GDP growth rates 138 Nearest neighbors ML .75 29.1 Fingleton (2001) Economic growth 178 Economic size&distance 3SLS -.19 29.2 .56 29.3 .73 30 Fingleton et al. (2005) Change in employment 408 Squared inverse distance 2SLS .41 31 Fingleton & Le Gallo (2008) House prices 353 Economic distance ML .72 32 Florax et al. (2002) Agricultural yields 100 First-order contiguity ML .50 33 Ford & Rork (2010) Patent rates 186 First-order contiguity ML .08 34 Fornango (2010) Homicide rates 110 First-order contiguity ML .30 35 Gimpel & Schuknecht (2003) Voting turnout 363 Distance-based contiguity ML .67 36.1 Gould (1991) Battalion enlistment 20 Cross-district enlistment ML .29 36.2 .49 36.3 .49 37 Greenbaum (2002) Teacher salaries 483 Inverse income di erence ML .66 38 Heikkila & Kantiotou (1992) Police expenditures 57 First-order contiguity ML .43 39.1 & Vuchelen (1998) Tax rates 589 First-order contiguity 3SLS .67 39.2 .70 40 Holloway et al. (2002) Crop adoption 406 First-order contiguity Bayes .54 41 Hunt et al. (2005) Fishing trip prices 770 Inverse distance-based ML .80 42.1 Joines et al. (2003) Hospitalization rates 100 First-order contiguity ML .53 42.2 .51 43 Kalenkoski & Lacombe (2008) Youth employment 3,065 First-order contiguity ML .49 44.1 Kalnins (2003) Fast food prices 1,385 Distance&contiguity-based ML .11 44.2 .21 45.1 Kim & Goldsmith (2009) Property values 262 Nearest neighbors 2SLS .22 45.2 523 .19 45.3 730 .14 46 Kim & Zhang (2005) Land values 731 Nearest neighbors ML .39 47.1 Kirk & Papachristos (2011) Homicide rates 342 First-order contiguity ML .43 47.2 .33 48.1 Land et al. (1991) Church adherence 731 Inverse distance 2SLS .33 48.2 697 .29 48.3 663 .28 49 Lauridsen et al. (2010) Medical expenditures 400 Inverse distance ML .87 50 LeSage (1997b) House values 88 First-order contiguity ML .45 51 Levine et al. (1995) Road accidents 362 Squared inverse distance ML .22 52.1 Lin (2010) GPA scores 68,131 Friendship ML .30 52.2 49,559 .29 52.3 79,067 .30 53 Lu & Zhang (2011) Tree heights 3,982 Variogram ML .59 54 McMillen (2010) Land ratios 1,322 First-order contiguity ML .71 55.1 McMillen et al. (2007) Tuition fees 929 Distance&contiguity-based ML .22 55.2 .34 56.1 McPherson & Nieswiadomy (2005) Species threat 113 Shared border length ML .23 56.2 .16 57 Moreno & Trehan (1997) Worker output growth 89 Inverse distance ML .51 58.1 Moreno (2003) Birth weights 342 First-order contiguity 2SLS .53 58.2 .69 59.1 Mur et al. (2008) Purchasing power 1,274 Distance&contiguity-based ML .60 59.2 .61 60 Niebuhr (2010) 95 First-order contiguity ML .1624 Chapter 2. Bayesian estimation of the network autcorrelation model Table 2.1 (continued). Study Field g Type of W Method \u001a 61.1 Osland (2010) Voting patterns 1,691 Nearest neighbors ML .07 61.2 766 .06 62 Patton & McErlean (2003) Land prices 197 Squared inverse distance IV .66 63 Pl\u007f umper & Neumayer (2010) Tax .12 64.1 & Viladecans-Marsal (1999) GDP growth rates 74 First-order contiguity ML .23 64.2 .20 64.3 .17 65 Revelli (2003) Expenditure levels 238 Contiguity-based ML .11 66 Ruggles (2007) Co-residence behavior 276 Shared border length ML .15 67 Rupasingha et al. (2002) Income growth 2,995 First-order contiguity ML .49 68.1 Saavedra (2000) Welfare competition 47 First-order contiguity ML .28 68.2 .30 68.3 .32 69 Seldadyo et al. (2010) Governance patterns 188 Nearest neighbors ML .28 70 Shin & Ward (1999) Military spendings 95 Distance&contiguity-based ML .08 71.1 Tam Cho (2003) Campaign donations 671 Inverse distance 2SLS .06 71.2 455 ML ML .07 72 Tita & Greenbaum (2009) Gun violence 244 Gang rivalry ML .22 73 Varga (2000) Technology innovation 125 Distance-based contiguity IV .14 74 Halleck Vega & Elhorst (2015) Cigarette sales 1,380 First-order contiguity ML .20 75 Vitale et al. (2016) Student performance 66 Personal advice ML .31 76 Voss & Chi (2006) Population change 1,837 Nearest neighbors ML .27 77.1 Voss et al. (2006) Child poverty 3,136 First-order contiguity ML .31 77.2 .27 78 Wilhelmsson (2002) House prices 1,377 Inverse distance ML .95 79.1 Whitt (2010) Crime rates 85 First-order contiguity ML .37 79.2 .58 79.3 .50 79.4 .54 80 Won Kim et al. (2003) House prices 609 Distance&contiguity-based 2SLS .55 81.1 N. Yang et al. (2012) Wine prices 79 Nearest neighbors ML .33 81.2 876 Nearest neighbors .34 Note:g= IV = instrumental variables; ML = maximum likelihood.2.4. Prior choices in the network autocorrelation model 25 2.4.6 Graphical prior comparison In order to get more insight into the di erences between the discussed priors, we inspected them graphically. We base our visualization on a randomly generated network of 20 actors with four covariates, including an intercept term. The shape of these priors is essentially the same for other data sets that are generated under di erent speci cations of WandX (not shown). Figure 2.2 shows the at prior, the conditional Je reys rule prior, the conditional Inde- pendence Je reys prior, the empirical informative prior, and the weakly informative prior for\u001afor the simulated data set. We xed \u001b2to 1 and to (1,1,1,1) for both versions of Je reys prior as the corresponding marginal priors for \u001aare analytically not available. The graphs of the two versions of Je reys prior are \\bathtub-shaped\", contrary to the at prior and the informative priors for \u001a. In particular, pIJ\u0000 \u001aj\u001b2; \u0001 assigns substan- tial weight to values for \u001aclose to the boundaries of the admissible interval for \u001a, while pJ\u0000 \u001aj\u001b2; \u0001 does essentially the same but with slightly more weight for values for \u001aclose to the left boundary and less prior mass for values for \u001aclose to the right boundary.7 As the main analytical di erence between Je reys rule prior and Independence Je reys prioristhatforthelattertheexponentoftheerrorvariancedoesnotdependonthenumber of covariates, we also considered the bivariate conditional prior for\u0000 \u001a;\u001b2j = (1;1;1;1)\u0001 . In contrast to the conditional prior for \u001a,pJ\u0000 \u001a;\u001b2j \u0001 places more prior mass at expect the Bayesian posterior estimates of \u001aand \u001b2based on Je reys rule prior to tend more towards their respective boundary values compared to the estimates based on Independence Je reys prior. 1.5 1.0 0.5 0.0 0.5 1.00123456 DensityFlat prior Jeffreys rule prior Independence Jeffreys prior Informative prior Weakly informative prior Figure 2.2 Conditional prior distributions for\u0000 \u001aj\u001b2= 1; = (1;1;1;1)\u0001 for simulated data. 7The (inverse of the) eigenvalues of the simulated network yield ( \u00001:75;1) as the admissible interval for\u001aas de ned in Section 2.2.26 Chapter 2. Bayesian estimation of the network autcorrelation model 2.5 Bayesian computation In this section, we present an e\u000ecient algorithm for a Bayesian estimation of the network autocorrelation model. The methodology can be used to sample from the various arising posterior distributions based on the priors discussed in Section 2.4. As is common in Bayesian computation, the goal is to obtain a sample from the joint posterior for the unknown model parameters by sequentially drawing from the conditional posteriors, i.e., given the remaining parameters and the data (Gelfand & Smith, 1990; Geman & Geman, 1984). Thisisrepeateduntilasu\u000ecientlylargesampleisobtained.8Weproposetosample ande e = ( 2;:::; k) contains all the other regression coe\u000ecients. The reason for simultaneously sampling \u001aand 1in one block is the high posterior correlation between these parameters.9Sampling these parameters separately would result in slow mixing, i.e., moredrawswouldbeneededtogetbothagoodapproximationoftheposterior distribution and small estimation errors (Brooks, 1998; Gelman et al., 2003; Raftery & Lewis, 1996). Weillustratethesamplingalgorithmwhenusingthe atpriorandtheinformativeprior rsts, before discussing sampling from the more complex posteriors based on Je reys rule prior and Independence Je reys prior. For the former, the conditional posteriors are given by (see distribution and \u0016e and \u0006 e are given in Ap- pendix 2.C. Sampling from the inverse gamma distribution in (2.9) and the normal distribution in (2.10) is straightforward, whereas due to the appearance of the determinant in (2.8), the conditional posterior for ( \u001a; 1) does not have a well-known form. In order to e\u000e- ciently sample from this distribution, we rely on the Metropolis-Hastings algorithm (Hast- ings, 1970; Metropolis et al., 1953). In the algorithm, a candidate-generating distribution is chosen from which candidate values for the target distribution, here: the conditional posterior, are drawn. The speci cation of the candidate-generating distribution is crucial for the algorithm's e\u000eciency, where we aim to construct a distribution that closely ap- 8This approach is needed as for none of the priors previously discussed the corresponding posterior belongs to a family of known probability distributions. Geman & Geman (1984) showed that sampling from the sequence of conditional posteriors for all parameters indeed produces estimates that converge in the limit to the true marginal posteriors for the parameters. 9This correlation is particularly pronounced for high levels of network density and we have not found this issue being discussed in the literature before. Only Hepple (1995b) provided a plot of the bivariate marginal posterior density pF((\u001a; 1)jy) for an empirical data set that clearly shows this dependence.2.5. Bayesian computation 27 05001000150020001.00.50.00.51.0 Iteration 05001000150020001.00.50.00.51.0 Iteration Figure 2.3 Trace plots of posterior draws for \u001afor novel (left) and random walk scheme (right) for simulated data. proximates the actual conditional posterior target distribution, which typically results in e\u000ecient solutions (Chib & Greenberg, 1995). In(2.8), weapproximatelog( jA\u001aj)byasecond-orderTaylorpolynomialat \u001a= 0, which results in a normal approximation of the rst factor, jA\u001aj. The second factor, exp( \u0001), if considered as a function of ( \u001a; 1), has a bivariate normal kernel. The third factor, i.e., the marginal prior for \u001a, is ignored in the candidate-generating distribution when using the at prior and is normal for the informative priors. Hence, the overall product of these normal densities results in a bivariate normal candidate-generating distribution for ( \u001a; 1) that incorporates the dependence between the two parameters and is tailored to the con- ditional posterior for ( \u001a; 1). Due to the complex prior expression for both Je reys rule and Independence Je reys prior, a Metropolis-Hastings step is needed to sample from all three conditional posteri- ors when employing these priors. For the rst parameter block, ( \u001a; 1), we use the same candidate-generating distribution as for the at prior, as the prior information for ( \u001a; 1) is quite vague compared to the likelihood. For the conditional posteriors for \u001b2, we propose inverse gamma distributions as candidate-generating distributions but with di erent shape parameters than those used in (2.9), accounting for the di erent exponents of \u001b2in the two priors. Finally, we rely on the normal distribution in (2.10) as the candidate-generating distribution for the conditional posterior for e . All details and the full sampling schemes for all of the discussed priors can be found in Appendix 2.C. We implemented our approach and compared its performance to existing sampling schemes that do not block ( \u001a; 1) but build on a one-dimensional random walk algorithm to generate draws for \u001ainstead (Holloway et al., 2002; LeSage, 2000; LeSage & Pace, 2009). We found that our method produces well-mixed Markov chains with very low autocorrelations. Figure 2.3 displays sample trace plots of posterior draws for \u001abased on our algorithm (left panel) and based on existing schemes (right panel) when using the at28 Chapter 2. Bayesian estimation of the network autcorrelation model prior. As can be seen, our algorithm generates Markov chains that are moving quicker and explore the parameter space much faster compared to traditional methods.10 2.6 Simulation study We performed a thorough simulation study to examine properties of the Bayesian estima- tors based on the at prior, Je reys rule prior, Independence Je reys prior, the empirical informative prior, and the weakly informative prior, and compared them to those based on maximum likelihood estimation. The main focus in this study was to evaluate the bias of\u001aand the frequentist coverage of credible and con dence intervals for \u001afor the di erent estimators, i.e., the extent to which a true data-generating network e ect is contained in those intervals. Furthermore, as the most likely outcome of the negative bias in the esti- mation of \u001ais a Type II error, we considered the average of Type I and Type II errors as well.11Such average error rates are increasingly used as optimal decision criteria instead of the prevailing paradigm, which is xing Type I error probability and then minimizing Type II error probability (Chance & Rossman, 2006; DeGroot & Schervish, 2010; Per- icchi & Pereira, 2016). Lastly, we also investigated the bias in the estimation of \u001b2, as it is known that Je reys rule prior can result in poor estimates of the error variance in multi-parameter models (De Oliveira, 2012; De Oliveira & Song, 2008). 2.6.1 Study design In our study design, we largely followed setups from previous simulation studies of the network autocorrelation model (Mizruchi & Neuman, 2008; Neuman & Mizruchi, 2010; W. Wang et al., 2014). Hence, we generated data yby using random networks and varying the size of the network, the density of the network, the number of covariates, and the magnitude of \u001a. We did so by y= (Ig\u0000\u001aW)\u00001(X +\").12We considered three network sizes ( g2 f10;20;50g), three levels of network density ( d2 f:1;:3;:5g), two sets of covariates plus an intercept term ( k2 f4;7g), and three xed network e ect sizes (\u001a2 f0;:2;:5g).13We obtained random binary symmetric connectivity matrices with ze- ros in the diagonal entries by relying on the rgraph() function from the sna package in R (Butts, 2008) and subsequently row-normalized the raw connectivity matrices. Moreover, we drew independent values from a standard normal distribution for the elements of X (excluding the rst column of Xwhich is a vector of ones), , and\", so\u001b2= 1. In addi- tion to simulating data using a xed network e ect \u001a, we also allowed for uctuations in the underlying network e ects by sampling them from the estimated population distribu- 10Also note that there are no parameters to be tuned in the Metropolis-Hastings steps in our approach, such as the variances of candidate-generating distributions. This stands in stark contrast to existing schemes, where this is commonly done in order to achieve speci c acceptance rates. 11We thank an anonymous reviewer for this suggestion. 12For all simulated data sets we looked at, none of the regularity conditions needed for posterior propriety was violated, and it seems highly unlikely to encounter such a situation in empirical practice. 13Simulation results for negative values for \u001aand di erent speci cations of Ware available from the authors upon request. We do not present them here, as the analyses provide no additional, i.e., di erent, insights.2.6. Simulation study 29 tion from Section 2.4.4. As the true network autocorrelation is unknown in practice, this appears to be a much more realistic simulation setup compared to setting \u001ato a speci c value a priori.14In total, we considered 60 scenarios (1 network size \u00023 network densities \u00021 set of covariates \u00024 sampling schemes for \u001aand 2 network sizes \u00023 network densities \u00022 sets of covariates \u00024 sampling schemes for \u001a) and simulated 500 data sets for each scenario. For the Bayesian estimators, we drew 10,000 samples from the corresponding poste- riors, applying the sampling schemes described in Section 2.5. We used the marginal posterior median as point estimator and 95% equal-tailed credible intervals by discarding the 2.5% smallest and largest draws, respectively, for coverage analyses of \u001aand\u001b2. In contrast to that, we employed asymptotic standard errors based on the model's observed Fisher information matrix to obtain maximum likelihood-based con dence intervals for \u001a and\u001b2.15 2.6.2 Simulation results Table 2.2 shows the average bias of \u001afor the di erent estimators. Overall, the Bayesian estimators based on the non-informative priors yield similar results to those based on max- imum likelihood estimation. In particular, there is still some negative bias present, which is a well-known issue in the network autocorrelation model. On the other hand, if the true underlying \u001aequals zero, the Bayesian estimator based on the weakly informative prior eliminates virtually all the negative bias in the estimation of \u001a. Furthermore, when the data-generating network e ect is positive, using the empirical informative prior generally results in the least absolute bias of \u001a. Given our review of empirically observed network autocorrelations in Section 2.4.4, this is clearly the most common situation to be encoun- tered in practice. Lastly, we also observe a much smaller increase in bias for higher levels of network density for this estimator, compared to the non-informative Bayesian ones and the maximum likelihood estimator. Table2.3showstheempiricalfrequentistcoverageofequal-tailed95%credibleintervals for\u001afor the Bayesian estimators and the coverage of asymptotic 95% con dence intervals for\u001a. The coverage of credible intervals based on the at prior and Independence Je reys prior is very close to the nominal .95. In contrast to that, the coverage of credible intervals corresponding to Je reys rule prior and the coverage of maximum likelihood-based con- dence intervals are below nominal for all considered scenarios. The problem of subpar coverage of maximum likelihood-based con dence intervals for \u001ais completely resolved 14In fact, we sampled \u001afrom the estimated population distribution truncated to ( \u00001;1) to ensure that the generated network e ects always lied in the chosen admissible interval\u0000 \u0015\u00001 g;1\u0001 . Note that less than 0.1% of probability mass of the estimated population distribution actually falls outside ( \u00001;1). For each draw for \u001afrom this estimated population distribution, we recorded the drawn value for \u001a(which was the true value for \u001afor that particular draw) and base our simulation results on those recorded underlying network e ects. 15All computation was performed in R using self-written routines. We used maximum likelihood esti- mates as starting values for the MCMC procedures and discarded the rst 1,000 iterations as so-called burn-in values (Gelman et al., 2003). As most of the marginal posterior distributions for \u001aand\u001b2were skewed, we opted for the posterior median as Bayesian point estimator, which was a less extreme estimator than the posterior mean or the posterior mode.30 Chapter 2. Bayesian estimation of the network autcorrelation model when using Bayesian estimators based on the at prior or Independence Je reys prior. Table 2.4 reports the average empirical Type I and Type II error rates of \u001afor the di erent estimators. In general, the average error rates increase with the network density due to the negative bias in the estimation of \u001a, and they decrease for higher network autocorrelations as a result of higher power. For all considered scenarios, the Bayesian estimator based on the empirical informative prior clearly yields the smallest average Type I and Type II error rates across the board. The other estimators perform relatively sim- ilar to each other, with the maximum likelihood estimator having slightly smaller aver- age error rates than the remaining Bayesian ones but still considerably higher than the estimator based on the empirical informative prior. The greater power of the maximum likelihood estimator, compared to the Bayesian estimators based on the non-informative priors, comes at the price of underestimating the standard error of \u001a. In turn, this results in narrower con dence intervals for \u001a, leading to lower coverage but slightly higher power. Regardless, estimating \u001ausing the empirical informative prior yields the lowest average Type I and Type II error rates. Table 2.5 displays the average bias of \u001b2for the Bayesian estimators and the maximum likelihood estimator. The estimates of \u001b2corresponding to the use of the at prior, Inde- pendence Je reys prior, and the informative priors are nearly unbiased, while the results based on Je reys rule prior and maximum likelihood estimation exhibit a large negative bias. This bias is particularly pronounced for a higher number of covariates. We also investigated the associated coverage of Bayesian equal-tailed 95% credible intervals and asymptotic 95% con dence intervals for \u001b2. In line with the results for the average bias of \u001b2, we found that the coverage of credible intervals based on the at prior, Independence Je reys prior, and the informative priors is very close to the nominal .95. On the other hand, the coverage of credible intervals corresponding to Je reys rule prior and the cov- erage of maximum likelihood-based con dence intervals are well below the nominal rate for all considered scenarios. These results are not shown here but are available from the authors upon request. Basedonoursimulationoutput, wesuggestthefollowing: rst, ifaresearcheriswilling to expect that his, or her, study might have a network e ect along the lines of the overall distribution of network autocorrelation e ects across the literature at large, using the em- pirical informative prior is highly recommended as it leads to a dramatic decrease of the bias in the estimation of \u001a. Furthermore, the corresponding estimator exhibits by far the smallest average Type I and Type II error rates of \u001aand accurately estimates \u001b2. At the same time, applying the empirical informative prior can result in a mild overestimation of \u001afor small positive network e ects. However, we believe this to be less of a concern than falsely dismissing positive network e ects and stress that overall, this estimator performs clearly the best. Second, if a researcher does not expect a network e ect to be present in the data, or if the researcher does not (want to) entertain the prior belief that the level of network autocorrelation in a data set is likely to t with the extant empirical empirical literature, relying on the weakly informative prior yields nearly adequate point estimates of the net-2.7. Conclusions 31 work e ect in these cases. This does, however, require the researcher to sacri ce the Type I and Type II error rate reducing bene ts of the empirical informative prior. Third, if a researcher prefers to refrain from employing any empirical-based prior in- formation, we recommend using the non-informative Independence Je reys prior. While this does not attenuate the negative bias in the estimation of \u001a, the issue of poor coverage of con dence intervals, associated with maximum likelihood estimation of the model, can be completely eluded at least. We wish to emphasize that there is never a case in which maximum likelihood estimation can be recommended. Lastly, when analyzing a real data set, we advise researchers to estimate the model using all three recommended priors. If the resulting estimates of \u001aare close to each other, this implies that the data contain su\u000ecient information and the estimates are most likely highly reliable; else, this strongly points at (negative) bias in the estimation of the network e ect. 2.7 Conclusions In this chapter, we derived two versions of Je reys prior for the network autocorrelation model that provide default Bayesian analyses of the model. Moreover, we speci ed an empirical informative prior and a weakly informative prior for the network e ect \u001abased on reported network e ects from the literature. We evaluated the Bayesian estimators by means of a simulation study and compared their performance to the performance of the maximum likelihood estimator. We found that the Bayesian estimator based on the empirical informative prior performs superior and that the estimator based on the weakly informative prior can be a useful alternative. Concomitantly, we also provided a very e\u000ecient MCMC implementation of the Bayesian approach that is preferable to existing sampling schemes and ensures a fast and accurate Bayesian estimation of the network autocorrelation model. In order to allow researchers and practitioners to easily use the newly developed meth- ods in this chapter, it is essential to make them accessible in a statistical software package. In addition, as we primarily focused on Bayesian point estimation in this work, further work needs to be done in studying Bayesian model selection procedures for the discussed priors. Finally, despite the improved numerical properties of the Bayesian estimators, the negative bias of \u001ain the model is not entirely resolved. We did resolve much of the bias for data sets that are typical in the empirical literature at large, but more research is needed to untangle it completely. It remains a major challenge to investigate what causes this negative bias and why it becomes increasingly salient at high levels of network density.32 Chapter 2. Bayesian estimation of the network autcorrelation modelTable 2.2 Average bias of \u001abased on using the at prior (F), Je reys rule prior (J), Independence Je reys prior (IJ), the empirical informative prior (EI), the weakly informative prior (WI), and the maximum likelihood estimator (ML) for 500 simulated data sets. For each scenario, the smallest abso- lute bias is printed in bold 95% credible and con dence intervals for \u001abased on using the at prior (F), Je reys rule prior (J), Inde- pendence Je reys prior (IJ), the empirical informative prior (EI), the weakly informative prior (WI), and the maximum likelihood estimator (ML) for 500 simulated data sets. For each scenario, the most accurate coverage is printed in bold face. g= 10;k= 4 \u001a= IJ EI WI ML .1 .976 .860 .966.842 .984 .800 .978 .878 .964.992 .988 .800 .942 .836 .940 .966 .946.776 .946 .868 .946 .922 .950.820 .3 .976 .838 .956.880 .980 .784 .956.832 .942 .994 .978 .750 .948.870.948.988 .960 .802 .936 .834 .930 .934 .952.776 .5 .976 .854 .954.902 .992 .800 .974 .878 .952.996 .988 .816 .926 .856 .928 .990 .956.806 .936 IJ EI WI ML .962 .918 .952.876 .970 .900 .944.906 .934 .984 .956.896 .920 .906 .926 .944.924 .896 .946 .904 .938 .932 .950.864 .3 .962 .914 .950.862 .976 .892 .964 .918 .9561 .980 .894 .926 .906 .930 .972 .942.876 .934 .918 .940 .904 .952.892 .5 .970 .920 .964.930 .994 .886 .942.916.942.998 .986 .874 .922 .926 .932 1 .964.888 .926 .928 IJ EI WI ML .1 .964 .874 .954.900 .978 .852 .952.874 .946 .986 .968 .844 .932 .876 .942.932 .932 .850 .960 .872 .954 .954 .960 .850 .3 .962 .874 .954.870 .980 .842 .978 .914 .970.994 .984 .890 .946 .876 .948.986 .954 .890 .928 .880 .932 .924 .946.850 .5 .978 .886 .972.870 .998 .856 .954 .882 .948.998 .978 .848 .932 .906 .962 .950.904 IJ EI WI ML .1 .960 .948.958 .896 .968 .944 .940 .930 .934 .986 .946.928 .956 .946.956 .956 .956 .936 .944 .932 .928 .944 .946.924 .3 .948.930 .942 .856 .970 .924 .948.942 .944 .998 .984 .932 .926 .942 .936 .982 .946.928 .944 .946.938 .940 .966 .924 .5 .930.916 .928 .916 .988 .898 .946 .940 .9501 .978 .922 .892 .922 .910 .928 .882 .946.902 .962 .932 .956.972 .962 .918 .954 .930 .948.944 .954 .926 .946 .938 .948.940 .942 .924 .3 .958 .922 .948.856 .976 .906 .954 .936 .952.996 .974 .922 .948 .938 .950.982 .954 .926 .950.930.950.954 .958 .916 .5 .954 .932 .952.886 .990 .918 .964.904 .966 1 .984 .928 .954.962 .958 .988 .972 .942 .918 .928 .928 .916 .938.91634 Chapter 2. Bayesian estimation of the network autcorrelation modelTable 2.4 Average of empirical Type I and Type II error rates of \u001aresulting from 95% credible and con dence intervals for \u001abased on using the at prior (F), Je reys rule prior (J), Independence Je reys prior (IJ), the empirical informative prior (EI), the weakly informative prior (WI), and the maximum likelihood estimator (ML) for 500 simulated data sets. For the scenarios where the data-generating value for \u001ais zero, the empirical Type I error rate equals the proportion of times in which zero was not contained in the credible or con dence interval. For the scenarios where the data- generating value for \u001ais not zero, the Type II error rate equals the proportion of times in which zero was contained in the credible or con dence inter- val. For each scenario, the smallest average error rate is printed in bold face. g= 10;k= 4 IJ EI WI ML .482 .482 .413.478 .486 .364 .273 .323 .204.342 .269 .449 .320.450 .404 .5 .505 .522 .510 .452.500 .522 .502 .505 .505 .396.496 .495 .499 .502 EI WI ML .452 .431 .446 .321.440 .417 .164 .147 .152 .092.149 .141 .290 .263 .278 .200.280 .258 .3 .501 .506 .504 .421.498 .501 .426 .384 .412 .252.411 .374 .490 .426 .450 .318.443 .419 .5 .509 .503 .506 .452.499 .507 .498 .481 .346.482 IJ EI WI ML .1 .427 .390 .420 .293.410 .385 .141 .115 .124 .073.120 .122 .271 .223 .262 .173.256 .221 .3 .497 .487 .492 .380.481 .185.354 .302 .391 .431 .306.430 .385 .5 .504 .501 .501 .448.499 .499 .486 .447 .478 .323.472 .434 .493 IJ EI WI .393 .403 .295.396 .093 .095 .065.088 .087 .237 .223 .236 .172.229 .219 .497 .498 .423.494 .496 .413 .248.401 .400 .452 .436 .447 .299.437 .421 .5 .516 .516 .515 .451.496 .516 .512 .498 .506 .353.482 .494 .515 IJ EI WI ML .1 .351 .335 .351 .242.338 .326 .073 .066 .071 .064 .058.069 .193 .187 .190 .160.180 .188 .3 .486 .472 .479 .360.471 .470 .350 .312 .338 .167.323 .307 .404 .380 .398 .265.384 .381 .5 .509 .501 .502 .431.490 .504 .481 .435 .464 .269.451 .425 .490 .469 .490 .361.475 .4682.7. Conclusions 35Table 2.5 Average bias of \u001b2based on using the at prior (F), Je reys rule prior (J), Independence Je reys prior (IJ), the empirical informative prior (EI), the weakly informative prior (WI), and the maximum likelihood estimator (ML) for 500 simulated data sets. For each scenario, the smallest abso- lute bias is printed in bold estimation of the model idempotent. (2) LetAbe an invertible matrix, and let uandvbe two vectors. Then, A+uvTis invertible and (see e.g., Ding Zhou, det\u0000 A+uvT\u0001 =\u0000 1+vTA\u00001u\u0001 det(A): (3) LetZ\u0018N(\u0016;\u0006) and let Abe a symmetric matrix. Then (see e.g., Mathai & Provost, 1992, Corollary 3.2b.1), Then, the eigenvalues of Aare either 0 or 1 (see e.g., Harville, 1997, Theorem 21.8.2). Appendix 2.B Proofs Proof of Corollary 2.1 (i) Follows immediately from the prior's de nition and \u0002 =\u0000 (1995a) showed that if\u0000 XTX\u0001\u00001exists and g > marginal pF(\u001ajy)/ jA\u001ajyTAT (where m0\u00150 \u00151\u00001;\u00152\u00001;:::;\u0015g\u00001 only ifk < m 0\u00001, which is typically not the case. Proof of Theorem 2.1 The model's Fisher information Matrix for \u0012=\u0000 determinant properties of block matrices (see e.g., in the actual entries for the respective blocks yields38 Chapter 2. Bayesian estimation of with the de nition of Je reys rule prior, the result follows. Proof of Corollary 2.2 (i) From the de nition of Je reys rule prior, in (2.14) is the kernel of the probability density function of a multi- variate normal random variable Z\u0018N\u0010 ^ ;\u001b2\u0000 the integrand in (2.15) can be expressed as the expected value for the square root of a quadratic form involving Z. By using auxiliary fact (3) and Jensen's inequality, we can write40 Chapter 2. Bayesian estimation of semi- de nite, so tr\u0000 BT \u001aMB\u001aP\u0001 \u00150 by auxiliary fact (4). Combining these observations with (2.14) and (2.15), it follows that \u0000 \u001b2\u0001\u0000g+k terms involving \u001b2in (2.16) and (2.17) correspond to kernels of probability density functions of inverse gamma distributed random variables, so integrating on the right hand side of (2.18) and (2.19) are bounded for \u001a2\u0000 \u0015\u00001 g;\u0015\u00001 1\u0001 by assumption. Hence, it only remains show that the term jA\u001aj\u0012p h1(\u001a)+q Second, using auxiliary facts (4) and (6), the considerations above and the idempotence of Mand P, respectively. Finally, with auxiliary facts (4)-(6) and after some algebraic manip- ulations, 2. Bayesian estimation of the network autcorrelation model bounded itself by a multiple of the sum term in (2.20). Furthermore, if m1and mgdenote the algebraic for \u001a2\u0000 \u0015\u00001 g;\u0015\u00001 1\u0001 . This completes the proof. Proof of Theorem 2.2 The model's Fisher information )(\u0012)\u0001 /1. The result follows from these observations and by the de nition of Independence Je reys prior. Proof of Corollary 2.3 These results are proved in an identical way as the ones in Corollary 2.2 and follow almost immediately. Appendix 2.C Posterior sampling We outlined the sampling procedure and gave the conditional posteriors based on the at prior and the informative priors in Section 2.5. However, it remains to specify the exact forms of the candidate-generating distributions for the conditional posteriors for the parameter blocks ( \u001a; 1) to the conditional posterior for ( \u001a; 1) based on the at prior, we rst approximate log( jA\u001aj) by a second-order Taylor proportionality holds with respect to ( \u001a; 1),eXdenotes the matrix Xwith its rst column removed, e = ( 2;:::; g), and1gis the vector of ones of length g. The expression in (2.23) corresponds to the kernel of a bivariate normal density qF(\u001a; 1) with mean vector \u0016and covariance matrix \u0006. By equating coe\u000ecients and normal distribution also for the conditional posterior for (\u001a; 1) based on Je reys rule prior and Independence Je reys prior, as for these priors the prior information for ( \u001a; 1) is quite vague compared to the likelihood. Note that due to the chosen parameter space of \u001a,qF(\u001a; 1) is in fact truncated to\u0000 \u0015\u00001 g;\u0015\u00001 1\u0001 \u0002R. In the simulation study, we relied on the rtmvnorm() function from the tmvtnorm package in R to sample from this truncated distribution (Wilhelm & Manjunath, 2015). Similarly, we can obtain the corresponding mean vector and covariance matrix of the candidate- generating bivariate normal distribution for ( \u001a; 1) when using a normal prior for \u001a. The conditional posterior for e based on the at prior and the informative priors is a multivariate normal distribution and can be directly sampled from, for which we used the rmvnorm() function from the mvtnorm package in R (Genz et al., 2014). Its mean vector and covariance matrix are given (k\u00001)\u0002(k\u00001)! : For the same reasons as before, we use this candidate-generating distribution also for the conditional posterior for e based on Je reys rule prior and Independence Je reys prior. Combining (2.2) and (2.5), the full conditionals based on Je reys rule prior can be none of these full conditionals is of known analytical form, a Metropolis-Hastings step for each parameter (block) is needed. The candidate-generating distributions for the conditional posteriors for ( \u001a; 1) ande have already been also easily formulate the conditional posteriors based on Independence Je reys prior, Posterior sampling 45 We outline the full sampling algorithm based on using the at prior in the following: (1) Set starting values\u0000 \u001a0; 0 1\u0001 ;\u0000 \u001b2\u00010, ande 0, e.g., to their maximum likelihood esti- mates, and the number of draws N. (2) Repeat steps (3) - (5) for i= 1 :N. (3) Perform a Metropolis-Hastings step for ( 1) with the target (\u001a; the candidate-generating density Drawe i, given\u0000 \u001ai; i 1\u0001 and covariance matrix \u0006 e as in (2.24), (2.25). Note that when using Je reys rule prior or Independence Je reys prior, the direct sam- pling procedures in (4) and (5) are replaced by Metropolis-Hastings steps based on the corresponding candidate-generating densities.47 Chapter 3 Bayesian hypothesis testing in the network autocorrelation model Abstract Currently available (classical) testing procedures for the network autocorrelation param- eter can only be used to falsify a precise null hypothesis of no network e ect. Classical methods can be neither used to quantify evidence for the null nor to test multiple hy- potheses on the network autocorrelation parameter simultaneously. This article presents exible Bayes factor testing procedures that do not have these limitations. We propose Bayes factors based on an empirical and a uniform prior for the network e ect, respec- tively, rst. Next, we develop a fractional Bayes factor where a default prior is automati- cally constructed. Simulation results suggest that the rst two Bayes factors show superior performance and are the Bayes factors we recommend. We apply the recommended Bayes factors to three data sets from the literature and compare the results to those coming from classical analyses using p-values. R code for e\u000ecient computation of the Bayes factors is provided. This chapter is based on: Dittrich, D., Leenders, R.Th.A.J., and Mulder, J. (in press). Network Auto- correlation Modeling: A Bayes Factor Approach for Testing (Multiple) Precise and Interval Hypotheses. Sociological Methods & Research .http://doi.org/10.1177/0049124117729712 .48 Chapter 3. Bayesian hypothesis testing in the network autocorrelation model 3.1 Introduction The network autocorrelation model (Ord, 1975) has been extensively used to represent theories of social in uence throughout recent decades. It allows researchers to quantify the strength of a peer e ect in a network for a given theory of interpersonal in uence while controlling for sociological and other covariates. The identi cation and magnitude of the peer, or network, e ect \u001a, also known as the network autocorrelation , is often the focus of interest in model applications. Typically, a researcher aims to identify if there is social in uence present in the network, resulting in an inferential test of H0:\u001a= 0 versus H1:\u001a6= 0. Subsequently, if the null hypothesis is rejected, the researcher then concludes that there is evidence for some degree of social in uence. Even though the network autocorrelation model and this statistical approach have yielded many interesting and theoretically useful ndings, more intricate hypothesis tests areoftenmoreinformative. Forexample, whenaresearcherisinterestedintestingwhether the degree of social in uence is either zero, small, medium, or large, a more informative test would be H0:\u001a= 0 versus \u001a <1. This not only allows the researcher to conclude if there is evidence for a non-zero amount of network autocorrelation in the network, but it grants the researcher the opportunity to simultaneously test several strengths of social in uence against each other as well. This chapter focuses on Bayesian hypothesis testing procedures for such multiple precise and interval hypotheses on the network autocorrelation. The standard approach to testing a network e ect is null hypothesis signi cance test- ing. Classical null hypothesis signi cance tests such as the Wald test, the likelihood ratio test, or the Lagrange multiplier test are based on di erent test statistics, summary val- ues constructed from the sample, which have asymptotically known distributions under the null hypothesis (Leenders, 1995). Then, assuming the null hypothesis to be true, the probability of observing a test statistic at least as extreme as the observed test statistic is calculated. This probability is called the p-value. Subsequently, the p-value is compared to a pre-speci ed signi cance level , which is usually set to :05 (Weakliem, 2004). If the p-value is smaller than , the null hypothesis is rejected. In this case, one would conclude that there is enough evidence in the data to reject the null hypothesis of no network e ect. If thep-value is larger than , there is not enough evidence in the data to reject the null. Classical null hypothesis signi cance testing in the network autocorrelation model has a number of disadvantages. First, the procedure cannot be used to provide evidence in favor of the null hypothesis (Wetzels & Wagenmakers, 2012); it can only falsify the null hypothesis. If the p-value is larger than , this ultimately implies a state of ignorance where the null can be neither rejected nor supported by the data. For example, if the estimated autocorrelation parameter is ^ \u001a=:16 with a two-sided p-value of :08 (so the null hypothesis that \u001a= 0 would not be rejected based on =:05), this does not mean that the null hypothesis is \\accepted\"; it merely means that judgment regarding the rejection of this particular hypothesis is suspended and that no degree of belief in the hypothesis has been determined. On the other hand, if the p-value is smaller than , it is still not3.1. Introduction 49 possible to say how much evidence there is against the null (and certainly not how much evidencethereisinfavorof \u001abeing:16indeed), onlythatthereisenoughevidencetoreject the null that \u001a= 0 based on a chosen signi cance level. Second, classical null hypothesis signi cance tests are not consistent. If the null is true and the sample size grows to in nity, there is still a probability of (typically .05) of drawing the incorrect conclusion that the null is false. This is undesirable, as one should be able to draw more accurate conclusions with growing sample size. Third, p-values in the network autocorrelation model depend heavily on asymptotic theory and consequently, the Type I error rate is not controlled for in an accurate manner in the case of small networks (Dittrich et al., 2017). A nal important issue in the context of this chapter is that p-values cannot be adequately used when testing multiple competing hypotheses against each other (Sha er, 1995). Instead, one can only test each hypothesis against the null that does not answer the question which hypothesis, out of a set of precise and interval hypotheses, is most supported by the data. In this chapter, we propose Bayes factor tests (Je reys, 1961; Kass & Raftery, 1995; Mulder & Wagenmakers, 2016) as an alternative approach to classical null hypothesis sig- ni cance testing in the network autocorrelation model. The Bayes factor is a Bayesian hypothesis testing criterion that circumvents the aforementioned issues with null hypoth- esis signi cance testing. First, in contrast to classical null hypothesis signi cance test- ing, it allows the researcher to evaluate and quantify the relative evidence in the data in favor of the null, or any other, hypothesis against another hypothesis (Kuha, 2004). These hypotheses can be precise hypotheses, e.g., H0:\u001a= 0, or interval hypotheses, e.g., H1: 0< \u001a <1. For example, a Bayes factor of B01= 5 implies that it is ve times more likely to observe the data under the null hypothesis than under a speci c alternative hypothesis H1. Second, Bayes factors are consistent, i.e., if the null hypothesis is true, the Bayes factor B01tends to in nity as the sample size goes to in nity (Casella et al., 2009). In other words, the larger the sample size, the more do the data support one hypothesis over another. Third, the Bayes factor provides \\exact\" inference without the need for asymptotic approximations (De Oliveira & Song, 2008). Lastly, the Bayes factor can be straightforwardly extended to test more than two hypotheses against each other, e.g.,H0:\u001a= 0 versus al., 1997). This feature is of particular relevance in the network autocorrelation model, as in many network studies, researchers do not doubt that social in uence occurs but are interested in testing competing theories about its strength. In summary, these advantageous properties explain the increasing usage of Bayes factors in social science research, such as in ANOVA (Klugkist et al., 2005), linear regression models (Braeken et al., 2015), repeated measures (Mulder et al., 2009), or structural equation modeling (Gu et al., 2014). So far, only two Bayes factors in the network autocorrelation model have been de- veloped in the literature. Hepple (1995a) proposed a Bayes factor for testing competing connectivity matrices against each other, while LeSage & Parent (2007) provided Bayes factors for testing di erent explanatory variables. We have neither found any Bayes factor for the standard one-sided test H0:\u001a= 0 versus H1: 0< \u001a <1 nor for any multiple50 Chapter 3. Bayesian hypothesis testing in the network autocorrelation model hypothesis tests. This is surprising, as the network autocorrelation parameter is at the heart of the model and testing for network e ects is of crucial importance for network scientists when testing for and understanding theories of social in uence. In sum, the objective of this chapter is to provide methodology that \u000fmakes it possible to test multiple competing hypotheses on \u001aagainst each other and precisely quantify the amount of evidence in favor of any of the hypotheses tested (including a null hypothesis), \u000fworks for any combination of precise and/or interval hypotheses, and \u000fovercomes the problems with classical null hypothesis signi cance testing of \u001a. We also provide ready-to-use R code (R Core Team, 2017) to make the methodology easily applicable for applied researchers. In order to compute the Bayes factor, so-called prior distributions , or simply priors, for the unknown model parameters have to be speci ed under each hypothesis. These priors quantify which values for the parameters are most likely before observing the data. For the testing problems considered in this chapter, the prior for the network autocorrelation parameter \u001aunder the alternative(s) is most important. We develop and explore several Bayes factors for testing the network e ect: rst, a Bayes factor based on an empirical informative prior that stems from an extensive literature review of empirical applications of the network autocorrelation model; second, a Bayes factor based on a uniform prior that assumes every value for \u001ato be equally likely a priori; third, a so-called fractional Bayes factor(O'Hagan, 1995) that can be computed without needing to formulate a proper, i.e., integrable, priordistribution for \u001abased on one's prior beliefs. Subsequently, we conduct a simulation study to investigate the numerical properties of and di erences between the proposed Bayes factors and then use the Bayes factors to re-analyze three data sets from the literature. Finally, we give R code for the computation of the Bayes factors. The chapter is organized as follows: in Section 3.2, we discuss the network autocorre- lation model in more detail and continue with a short introduction to Bayesian hypothesis testing in Section 3.3. In Section 3.4, we motivate several prior choices for the network autocorrelation parameter \u001a. We assess the numerical performance of the Bayes factors in a simulation study in Section 3.5 and highlight their practical use with three examples in Section 3.6. Section 3.7 concludes. 3.2 The network autocorrelation model Most social phenomena are embedded within networks of interdependencies. Building from a standard linear regression model, the network autocorrelation model e ectively in- corporates such interdependencies between individuals. In the model, the network struc- ture is explicitly used to account for network in uence on a variable of interest and to estimate the magnitude of this in uence that is considered to be a model parameter, the network autocorrelation \u001a. Formally, the network autocorrelation model expressed as3.3. hypothesis testing 51 y=\u001aWy+X +\";\"\u0018N\u0000 0g;\u001b2Ig\u0001 ; (3.1) whereyis a (g\u00021) vector of values for a dependent variable for the gnetwork actors, Xis a (g\u0002k) matrix of values for the gactors on kcovariates (possibly including a column of ones for an intercept term), is a (k\u00021) vector of regression coe\u000ecients, 0gis a (g\u00021) vector of zeros, Igdenotes the ( g\u0002g) identity matrix, and \"is a (g\u00021) vector containing independent and identically normally distributed error terms with zero mean and variance of\u001b2. Furthermore, Wis a given ( g\u0002g)connectivity matrix representing social ties in a network, with Wijdenoting the degree of in uence of actor jon actor i.1Finally, the network autocorrelation \u001ais the key parameter of the model and quanti es the social in uence for given y,W, andX. We denote the resulting set of model parameters as \u0012:=\u0000 \u001a;\u001b2; \u0001 . Subsequently, we will repeatedly rely To ensure that the model is well-de ned, there are restrictions on the region of support for \u001a. Typically, this region is chosen as the interval containing \u001a= 0 for which A\u001ais non-singular (Hepple, 1995a; LeSage & Parent, 2007; Smith, 2009). In this case, the corresponding admissible interval for \u001ais given by\u0000 connectivity matrices W, i.e., where each row sum is one, it holds that\u00151= 1 (Anselin, 1982). Without loss of generality, we restrict ourselves to such commonly used row-standardized connectivity matrices in the remainder of this chapter. Hence, Throughout the model has also been named as mixed regressive-autore- gressive model (Ord, 1975), spatial e ects model (Doreian, 1980), network e ects model (Marsden & Friedkin, 1993), or spatial lag model (Anselin, 2002), and it has been applied in many di erent elds, such as criminology (Baller et al., 2001; Tita & Radil, 2011), geography (McMillen, 2010; Mur et al., 2008), political science (Beck et al., 2006; Gimpel & Schuknecht, 2003), or sociology (Duke, 1993; Kirk & Papachristos, 2011; Mizruchi & Stearns, 2006). 3.3 Bayesian hypothesis testing In many network studies, researchers have expectations about the magnitude of the net- work e ect. An interesting research question is whether the network e ect can be classi ed as zero, small, medium, or large. These expectations can be translated to a set of multiple 1By convention, we exclude loops, i.e., relationships from an actor to himself, so Wii= 0 for all i2 f1;:::;gg.52 Chapter 3. Bayesian hypothesis testing in the network autocorrelation model hypotheses on the network question to be answered is which of these hypotheses is most plausible. In general, such a test is much more insightful than the standard test of no network e ect versus \\some\" (positive) network e ect, H0:\u001a= 0 versusH1: 0< \u001a <1. In order to illustrate this, consider a situation in which the esti- mated network autocorrelation parameter is ^ \u001a=:16, with a \u001aof (\u0000:06;:37), Using the standard signi cance level of =:05, we would not reject the null hypothesis that \u001a= 0 and conclude that there is no statistically signi cant network e ect present in the data. Based on the con dence inter- val, however, we do have quite a lot of con dence that the network e ect may be positive. Hence, based on these classical outcomes, it is very di\u000ecult to state how plausible it is that the true network e ect is zero, small, medium, or large, which was the initial research question. The Bayes factor is a Bayesian hypothesis testing criterion that resolves this issue by providing a means to directly quantify how plausible each hypothesis is after observing the data. Suppose that we are interested in testing T\u00152 hypotheses, H0,H1,H2, ..., HT\u00001. First, in Bayesian hypothesis testing, prior probabilities have to be assigned to both the model parameters under each hypothesis and to the hypotheses themselves. We denote these latter prior hypotheses probabilities byp(H0),p(H1), ...,p(HT\u00001), withPT\u00001 t=0p(Ht) = 1, which re ect how plausible we believe each hypothesis to be (relative to each other) before observing the data. There are multiple ways to assign prior hypotheses probabilities, e.g., by assuming equal prior probabilities (re ecting prior ignorance), i.e., p(H0) =:::=p(HT\u00001) = 1=T(Hepple, 1995a; LeSage & Parent, 2007), or by formulat- ing speci c prior probabilities for the various hypotheses. We will discuss procedures for eliciting prior probabilities for interval hypotheses in Section 3.4. Next, after observing the data y, Bayes' theorem is applied to update the prior ex- pectations with the information contained in the data. The resulting posterior hypotheses probabilities ,p(Htjy), can then be f0;1;:::;T\u00001g:(3.2) These posterior probabilities quantify how probable each hypothesis is after observing the data, the quantity that researchers are typically interested in. The term p(yjHt) in (3.2) is called the marginal likelihood under hypothesis Htand denotes the probability that the data were observed under hypothesis Ht. It is computed by integrating the product of the model's likelihood function and the prior distribution for the model parameters under hypothesis Ht. Hence, the marginal likelihood can be seen as a weighted likelihood over the parameter space under hypothesis Ht, with the prior under hypothesis Htacting as a weight function. In formal notation,3.3. Bayesian hypothesis testing 53 p(yjHt) =Z \u0002tf(yj\u0012t)pt(\u0012tjHt)d\u0012t; (3.3) where\u0012tare the model parameters under hypothesis Ht,pt(\u0012tjHt) their prior density, and \u0002tthe corresponding parameter space. For example, for H0:\u001a= 0 and H1: 0< \u001a <1 in the two hypotheses HtandHt0, t;t02 f0;:::;T\u00001g, we can consider the ratio of the corresponding posterior hypotheses probabilities. In this case, the normalizing constant p(y) in (3.2) cancels out and we can write p(Htjy) p(Ht0jy)=p(yjHt) p(yjHt0)\u0002p(Ht) p(Ht0):=BFtt0\u0002p(Ht) p(Ht0): (3.4) The term p(Ht)=p(Ht0) in (3.4) is called the prior odds of the two hypotheses and quanti eshowmuchmore, orless, likelyaresearcherexpectshypothesis Httobecompared to hypothesis Ht0before observing the data. When a researcher does not a priori believe one to be more likely than the other, the prior odds can be set equal to one. The term p(Htjy)=p(Ht0jy) in (3.4) is known as the posterior odds and re ects how much more (if larger than one), or less (if smaller than one), likely hypothesis Htis than hypothesis Ht0 after taking the observed data into account. For example, if the posterior odds is ve, this means that hypothesis Htis ve times more likely than hypothesis Ht0for this data set. From (3.4) we can see that the posterior odds can be written as the prior odds multiplied by the Bayes factor, BFtt0, which is de ned as the ratio of two marginal likelihoods. Hence, the Bayes factor indicates to what extent the data change the prior odds to the posterior odds. Note that the Bayes factor can be used to quantify the relative evidence in the data in favor of the hypotheses without needing to specify how plausible they are before observing the data. If both models are considered as equally likely a priori, i.e., p(Ht) =p(Ht0), the Bayes factor equals the posterior odds.2 The Bayes factor is a measure of relative evidence; it quanti es the amount of evidence in the data in favor of one hypothesis relativeto another hypothesis. Je reys (1961) proposed a classi cation scheme to group Bayes factors into di erent categories, see Table 3.1. For example, there is \\substantial\" (relative) evidence in the data for hypothesis Ht when the Bayes factor BFtt0exceeds three and, equivalently, \\substantial\" evidence for hypothesis Ht0when the Bayes factor is less than 1 =3. These labels provide some rough guidelineswhenspeakingofrelativeevidenceinfavorofahypothesisbuttheinterpretation should ultimately depend on the context of the research question (Kass & Raftery, 1995). 2We use the terms hypothesis and model interchangeably throughout the chapter.54 Chapter 3. Bayesian hypothesis testing in the network autocorrelation model Table 3.1 Evidence categories for the Bayes factor BFtt0as given by Je reys (1961). BFtt0 log(BFtt0) Interpretation >100 >4.61 Decisive evidence for hypothesis Ht 30 - 100 3.40 - 4.61 Very strong evidence for hypothesis Ht 10 - 30 2.30 - 3.40 Strong evidence for hypothesis Ht 3 - 10 1.10 - 2.30 Substantial evidence for hypothesis Ht 1 - 3 0 - 1.10 Not worth more than a bare mention 1/3 - 1 -1.10 - 0 Not worth more than a bare mention 1/10 - 1/3 -2.30 - -1.10 Substantial evidence for hypothesis Ht0 1/30 - -3.40 1/100 - 1/30 -4.61 -3.40 Very strong evidence hypothesis Ht0 <1/100 <-4.61 Decisive evidence for hypothesis Ht0 3.4 Bayes factor tests for the network autocorrelation pa- rameter In this section, we propose three Bayes factor tests when testing precise hypotheses, Hprecise:\u001a=c, and interval hypotheses, Hinterval:a1< \u001a < a 2, on the network au- tocorrelation parameter. One of the most important steps in Bayesian hypothesis testing is the prior speci cation of the model parameters. In the network autocorrelation model (3.1), a prior for \u001amust be speci ed under an interval hypothesis, while no prior for \u001a needs to be formulated under a precise hypothesis, as \u001ais not a free parameter in this case. Despite its importance, prior speci cation of the network e ect \u001ahas been largely neglected in the scarce literature on Bayesian hypothesis testing in the network autocor- relation model. The previous works of Hepple (1995a), X. Han & Lee (2013), and LeSage (2014a) are exclusively based on a uniform prior for \u001awhen testing the plausibility of di erent connectivity matrices (Hepple, 1995a) and Lee, 2013; LeSage, 2014a), respectively. LeSage & Parent (2007) additionally employed a beta prior for \u001ain a variable selection problem. As these authors did not consider testing \u001ain particular, the prior choice was also less important in those contexts. In our setting, however, the prior for the network e ect \u001aunder the alternative(s) should be carefully chosen, as the Bayes factor can be sensitive to the prior for the tested parameter (Kass & Raftery, 1995; Liu & Aitkin, 2008; Sinharay Stern, 2002). Prior expectations about the network autocorrelation parameter can be formulated based on a researcher's beliefs or stem from previous empirical evidence from the litera- ture. On the other hand, if the available prior information is weak or a researcher prefers to avoid adding prior information to an analysis, so-called non-informative priors are of- ten used. Such non-informative priors are typically improper, i.e., they do not integrate to a nite value, and are supposed to be completely dominated by the data (Gelman et al., 2013). In the following, we rst present an empirical informative prior for \u001a, second, a vague proper prior for \u001a, and third, an improper prior for the network e ect. We combine these di erent marginal prior distributions for \u001awith the standard non-informative Bayes factor tests for the network autocorrelation parameter 55 independent (Hepple, 1995a; Holloway et al., 2002; LeSage, 1997a). However, note that the exact choice of the prior for the nuisance parameters hardly has an e ect on the Bayes factor as long as this prior is relatively vague (Kass & Raftery, 1995).3 3.4.1 The Bayes factor based on an empirical prior In our review of published empirical applications of the network autocorrelation model in Chapter 2, we showed that medium network e ects, e.g., \u001a\u0019:3, are much more likely to be found in real-world networks than larger e ects, e.g., \u001a\u0019:8, or negative e ects, e.g.,\u001a\u0019 \u0000:2. We also showed that the distribution of empirically observed network e ects is well-approximated by a normal distribution centered around :36 with a standard deviation of :19. Unless a new study considers a case that is fundamentally di erent from the networks studied in the literature at large to date, a network autocorrelation in a new study is likely to come from a population distribution for \u001athat resembles this normal distribution. This yields the empirically motivated prior pE(\u001ajHinterval)\u0018N\u0000 :36;:192\u0001 (a1;a2); (3.5) which is the aforementioned normal distribution with a mean of .36 and a standard de- viation of .19, truncated to the corresponding parameter space of \u001aunder an interval hy- pothesis. Based on this empirical prior, the marginal likelihoods under precise and under interval hypotheses on \u001a, respectively, and \b( \u0001) denotes the cumulative distribution function of the standard normal distribution (see e.g., Hepple, 1995a). The uni-dimensional integral in (3.7) does not have a closed-form solution and has to be evaluated numerically. This can be done by relying on standard numerical methods, e.g., Simpson's rule (Atkinson, 1989), and we present R code therefor in Appendix 3.A, allowing researchers to use the Bayes factor without having to deal with the formulae themselves. Subsequently, the desired Bayes factors are obtained through (3.4) by using the marginal likelihoods under the precise and interval hypotheses under consideration. 3Improper priors for nuisance parameters appearing in both the null and the alternative model(s) are routinely used in Bayesian hypothesis testing (Hepple, 1995a; Je reys, 1961).56 Chapter 3. Bayesian hypothesis testing in the network autocorrelation model Density .25 0 .25 .5 .75 10.511.522.5Unconstrained empirical prior Figure 3.1 Probability density function of the unconstrained empirical prior for \u001a,pE(\u001a)\u0018 N\u0000 :36;:192\u0001 . The shaded areas under the probability density function correspond to the probabilities of \u001afalling in the intervals ( :25;:5] (black) and ( :5;1) (gray), which are equal to :49 and:23, respectively. The unconstrained version of the empirical prior in (3.5), i.e., pE(\u001a)\u0018N\u0000 :36;:192\u0001 , can also be employed to determine prior probabilities for interval hypotheses. In this approach, the prior hypotheses probabilities are based on the probabilities of the tested model parameter falling in the respective intervals under a proper unconstrained prior. As an example, consider the two interval hypotheses H1::25< \u001a\u0014:5 andH2::5< \u001a <1. The intervals ( :25;:5] and (:5;1) under the unconstrained empirical prior are equal to :49 and:23, respectively, see Figure 3.1.4These probabilities giveaquanti cationoftheplausibilityofthehypothesesundertheunconstrainedempirical prior. Hence, the corresponding prior odds, p(H1)=p(H2), in this example is 2.12 ( \u0019 :49=:23). In other words, under the empirical prior and before considering the data, a value for \u001ainside the interval ( :25;:5] is 2.12 times as likely as \u001abeing inside ( :5;1). Thus, if we assume that either hypothesis H1or hypothesis H2is true and that their prior odds corresponds to 2.12, the prior probabilities for the hypotheses are p(H1) =:68 (\u0019:49=(:49+:23)) and p(H2) =:32 (\u0019:23=(:49+:23)). This seems reasonable, as medium e ects (hypothesis H1) are generally more plausible than large e ects (hypothesis H2) in social network research (Dittrich et al., 2017). To the best of our knowledge, using an unconstrained prior to specify prior odds of interval hypotheses is novel in the literature.5 In the remainder of this chapter, we rely on the following method to assign prior model probabilities when testing one precise null hypothesis and T\u00001 interval hypotheses. As 4In R, these probabilities are calculated as pnorm(:5;mean=:36;sd=:19)\u0000pnorm(:25;mean= :36;sd=:19) =:49 andpnorm(1;mean=:36;sd=:19)\u0000pnorm(:5;mean=:36;sd=:19) =:23. We rounded all probabilities to two decimal places in this chapter. 5Only Mulder (2014a) discussed a similar method for assigning prior probabilities to hypotheses with order constraints on the tested parameters.3.4. Bayes factor tests for the network autocorrelation parameter 57 there are Thypotheses in total, we set a prior probability of 1 =Tto the precise null hypothesis. Subsequently, the remaining probability of ( T\u00001)=Tis divided upon the interval hypotheses, H1;:::;HT\u00001, using the prior probabilities of the intervals under a proper unconstrained prior. For example, test ve hypotheses in total, so the null hypothesis is assigned a prior probability of 1 =5 =:2. The remaining probability of 4 =5 =:8 is split between the four interval hypotheses based on the probability mass contained in the four intervals under the unconstrained empirical prior. For the hypotheses considered above, the probabilities of \u001afalling in these intervals are:03,:25,:49, and:23. As we have already set p(H0) =:2, there is a total probability of .8 left for the remaining hypotheses. Rescaling and making them add up to .8 results in the prior model probabilities p(H1) =:02,p(H2) =:20,p(H3) =:39, andp(H4) =:19.6 Finally, when combining the prior hypotheses probabilities and the marginal likelihoods in (3.6) and (3.7), the corresponding posterior model probabilities can be calculated via (3.2). 3.4.2 The Bayes factor based on a uniform prior The uniform prior treats all possible network e ects under the alternative(s) as equally likely before observing the data, resulting in a uniform prior distribution for \u001a. As the region of support for \u001ais bounded, the uniform prior for the network autocorrelation is a vague proper prior. Hence, it is less informative than the empirical prior but also does not represent complete prior ignorance that is typically expressed by using improper priors. The uniform prior under an interval hypothesis is written as pU(\u001ajHinterval)\u0018U(a1;a2); whereU(a1;a2) denotes the uniform distribution on ( a1;a2). The marginal likelihood un- der a precise hypothesis Hpreciseremains the same as in (3.6), while the marginal likelihood under an interval hypothesis Hintervalin combination with a uniform prior for \u001ais is computed as the ratio of two marginal likelihoods based on theuniformpriorfor \u001a. Similarlyasfortheempiricalprior, anunconstraineduniformprior 6Note that the prior odds of any two interval hypotheses does not depend on the choice of the prior probability for the precise hypothesis.58 Chapter 3. Bayesian hypothesis testing in the network autocorrelation model can also be used to specify prior model probabilities. In the uniform prior setting, this implies that the prior odds of two interval hypotheses is equal to the ratio of their interval lengths. Posterior model probabilities can then be obtained via (3.2) by plugging in the marginal likelihoods under consideration and the prior probabilities for the hypotheses based on the uniform prior. 3.4.3 The fractional Bayes factor Finally, there may be situations in which a researcher does not have any prior beliefs about possible network e ects if the null were false, or in which a researcher prefers not to specify a proper prior for \u001abased on external knowledge. Such prior ignorance is usually re ected by employing improper priors. However, if improper priors for the tested parameters are imposed, the Bayes factor depends on unknown normalizing constants and is not well-de ned (O'Hagan, 1995). To that end, the fractional Bayes factor methodology was originally proposed by O'Hagan (1995) as a way to bypass this issue. In the fractional Bayesfactor,themainideaistosplittheinformationinthedataintotwodi erentfractions that sum up to one. The rst (small) fraction, denoted by b, is used to update the initial improper prior into a proper default prior; the second fraction, 1 \u0000b, is taken to evaluate the hypotheses under investigation based on this proper default prior. In mathematical notation, this comes down to rewriting the marginal likelihood in (3.3) as updated proper default prior. Thus, in order to compute the marginal likelihood in the network autocorrelation model in the fractional Bayes factor approach, one needs to choose a non- informative improper prior for \u001aand to specify the fraction b. As improper prior for \u001awe use pNI(\u001ajHinterval) = (1\u0000\u001a)\u000011(0;1)(\u001a): (3.10) This prior approximates the model's Independence Je reys prior very well (see Ap- pendix 3.C) that has been shown to outperform the standard uniform prior for \u001ain Bayesian estimation of the model in Chapter 2.7At the same time, Independence Je reys prior itself also imposes an a priori dependence structure between the model parameters (Dittrich et al., 2017), which makes it di\u000ecult to compare its inferences to those based 7The prior in (3.10) has the same asymptotic behavior as the model's conditional Independence Je reys prior for \u001afor\u001a!1, see Appendix 3.C for a proof.3.4. Bayes factor tests for the network autocorrelation parameter 59 on the previously proposed normal and uniform marginal priors for \u001a. For this reason, we rely on the marginal improper prior for \u001ain (3.10) as it relaxes this a priori dependence. Note that in the fractional Bayes factor approach, we consider Hinterval: 0< \u001a <1 as the only alternative interval hypothesis. Else, if a researcher had more precise expectations about the magnitude of the network e ect, e.g., Hinterval::25< \u001a < :5, it seems much more sensible to use a proper prior for \u001ainstead. Typically, the fraction bin the fractional Bayes factor is chosen as the smallest value for which the updated default prior in (3.9) is proper (Berger & Mortera, 1999; Mulder, 2014b; O'Hagan, 1995). This choice results in maximal possible use of the information in the data for hypothesis testing. If the proposed improper prior in (3.10) is combined with the standard non-informative ing prior in (3.9) is proper if b > k=g (see Appendix 3.D for a proof). The proof shows that this also holds for the updated prior in (3.9) under a precise hypothesis Hprecise. We denote the resulting choice for basb1= (k+1)=g. On the other hand, if misspeci cation of the improper prior is a concern, larger values for bmay be preferred, as they can reduce the sensitivity of the fractional Bayes factor to prior misspeci cation (Conigliani & O'Hagan, 2000; O'Hagan, 1995). Since empirical network autocorrelations are more likely to come from the estimated unconstrained population distribution for \u001a in (3.5) than from a distribution that resembles the improper prior in (3.10), prior mis- speci cation is indeed a valid concern here. In this case, O'Hagan (1995) suggested to useb2= max(k+1;ln(g))=g, which makes the fractional Bayes factor more robust but increases slowly with g, orb3= max\u0000 k+1;pg\u0001 =g, when sensitivity to misspeci cation of the prior is a serious concern. Finally, the marginal likelihoods under a precise hypothesis Hpreciseand under an interval hypothesis Hintervalin the fractional Bayes factor details about the computation of (3.12), we refer the reader to Appendix3.E. Asbefore, themarginallikelihoodsin(3.11)and(3.12)areusedtocalculate the fractional Bayes factor itself, which is again the ratio of two marginal likelihoods. If a researcher is also interested in obtaining posterior model probabilities, a default choice is to impose equal prior model probabilities, i.e., p(H0) =p(H1) =:5, while subjective prior model probabilities could be assigned if a researcher has clear beliefs about the plausibility of the null hypothesis of a zero network e ect.60 Chapter 3. Bayesian hypothesis testing in the network autocorrelation model 3.5 Simulation study Inthissection,wepresentresultsofasimulationstudythatinvestigatedtheperformanceof andthedi erencesbetweentheBayesfactorsdiscussedinSection3.4. Tothatend, we rst looked 0 versus H1: 0< particular, we explored which Bayes factor converges fastest to a true data-generating hypothesis and assessed the sensitivity of the fractional Bayes factor to the choice of b. Next, we considered a multiple hypothesis test B with a precise hypothesis and four interval hypotheses: H0:\u001a= 0 <1. Our primary goal here was to study how fast the posterior model probabilities converge to the true model for di erent data-generating hypotheses and to check how robust these ndings are to di erent marginal priors for \u001aas well as di erent prior model probabilities. 3.5.1 Study design In order to mimic realistic networks, we considered two di erent approaches to obtain con- nectivitymatrices WintestA.First, weusedthewell-known small-world structure(Watts & Strogatz, 1998) to generate simulated networks. Such networks are highly clustered, i.e., thereisatendencythatnetworkactorscreateverydensesubnetworksbutatthesametime have small path lengths, i.e., there is a high probability that any two actors in the network are connected by short paths of acquaintances (Watts & Strogatz, 1998). Typically, this results in networks in which most actors are linked to only a few others, while some actors, also known as hubs, have a lot of ties. These hubs function as connectors between di er- ent subnetworks and shorten the path lengths between two actors in the entire network. Small-world structures can be observed in online social networks (Fu et al., 2007), scienti c collaboration networks (Newman, 2001), or corporate elite networks (Davis et al., 2003). We obtained simulated small-world networks by relying on the watts.strogatz.game() func- tion from the igraph package in R (Cs\u0013 ardi & Nepusz, 2006). In the underlying algorithm, a ring lattice of gactors, each connected to its dnearest neighbors by undirected ties, is constructed rst. Next, with probability r, each tie in the network is randomly rewired. Following Neuman & Mizruchi (2010) and W. Wang et al. (2014), we set r=:1, which lead to highly clustered networks with low average path lengths. In our simulation study, we considered 14 network sizes ( g2 f25;50;75;100;150;200;300;:::;1000g) and two aver- age degrees ( d2 f4;8g). The simulated connectivity matrices were binary, i.e., Wij= 1 if there was a tie between actor iandjand zero otherwise. Subsequently, we row-normalized the generated symmetric raw connectivity matrices.8 Second, wealsoransimulationsusingtwoprominentcontiguity-basedspatialnetworks; the 49 neighborhoods in Columbus, Ohio, analyzed in e.g., Anselin (1988), Elhorst (2014), and Hepple (1995a), and the 64 Louisiana parishes studied in Doreian (1980), Howard (1971), and Leenders (2002), among others. In general, networks based on spatial conti- 8AccordingtoWatts&Strogatz(1998), small-worldnetworksareusuallylargeandsparsewith g d ln(g). Obviously, this relationship does not hold for all of our generated networks as e.g., ln(100) = 4 :61. However, weaimedtoconstructnetworkswithapartiallyrealistic, non-randomcon gurationandsimulated networks that at least resemble small-world structures.3.5. Simulation study 61 Figure 3.2 Simulated small-world network for g= 50,d= 4,r=:1 (left), the network of the 49 Columbus neighborhoods (middle), and the network of the 64 Louisiana parishes (right). guity do not exhibit small-world properties, as there may be no short path between two distant nodes. Thus, we relied on these two real-world networks to gain insights into the behavior of the Bayes factors for network con gurations that are di erent from typical small-world structures. We set Wijto one if area iis adjacent to area j, to zero otherwise, and row-standardized the raw adjacency matrices. Graphical representations of the two spatial networks and an example of a simulated small-world network appear in Figure 3.2.9 For each of the network types, we included three covariates plus an intercept term (sok= 4) and used three xed network e ect sizes ( \u001a2 f0;:25;:5g) to generate yvia y= (Ig\u0000\u001aW)\u00001(X +\") for test A. Furthermore, we also sampled network e ects from the estimated empirical population distribution from Section 3.4.1, truncated to (0 ;1), rather than xing \u001ato a speci c value. As the true network autocorrelation is unknown in practice, this is a more realistic setup than choosing speci c values for \u001aa priori. Finally, we drew independent values from a standard normal distribution for the elements of X (excluding the rst column which is a vector of ones), , and\". Hence, we considered 120 scenarios for test A in total (14 small-world networks \u00022 average degrees \u00024 sampling schemes for \u001aand 2 spatial networks \u00024 sampling schemes for \u001a) and simulated 1,000 data sets for each scenario. For test B, we generated network e ects using the empirical prior for \u001a, truncated to the corresponding parameter space under each hypothesis. We assigned prior probabilities to the hypotheses based on both the unconstrained empirical the uniform prior for \u001a. We drew values for the elements of X, , and\"as described in the previous paragraph, so for test B we examined 140 scenarios in total (14 small-world networks \u00022 average degrees \u00025 data-generating hypotheses) and generated 1,000 data sets for each scenario. 9We created the network plots using the plot.igraph() function from the igraph package in R.62 Chapter 3. Bayesian hypothesis testing in the network autocorrelation model 3.5.2 Simulation results Figure 3.3 and Table 3.2 show the average weight of evidence, i.e., the natural logarithm of the Bayes factor (Good, 1985), for the di erent Bayes factors and network structures for WoE 100300500700900050100150 3.3 Average weight of evidence (WoE) for BFE 10(thick solid line), BFU versus H1: 0< \u001a <1 for 1,000 simulated data sets using generated small-world networks. 10In Table 3.2, we do not present the results for the fractional Bayes factor based on b2, asb1=b2for both spatial networks when k= 4.3.5. Simulation study 63 Table 3.2 Average weight of evidence for BFE 10,BFU 10,FBFb1 <1 for 1,000 simulated data sets using the network of the 49 Columbus neighborhoods and the network of the 64 Louisiana parishes. Columbus neighborhoods Louisiana parishes \u001a= 0\u001a=:25\u001a=:5\u001a\u0018pE(\u001a)\u001a= 0\u001a=:25\u001a=:5\u001a\u0018pE(\u001a) -2.0 .2 6.2 3.8 -2.0 .5 7.7 5.0 We can conclude the following from these results. First, the Bayes factor based on the empirical prior, BFE 10(thick solid line), and the Bayes factor based on the uniform prior,BFU 10(thin solid line), show consistent behavior, i.e., the evidence for a true data- generating hypothesis is increasing with the network size. In addition, they almost always providemostevidenceforthetruehypothesis, exceptfor \u001a=:25andsomesmallernetwork sizes in the small-world networks. Second, the evidence for a true alternative hypothesis grows with the network size at a faster rate than the evidence for a true null, as is common in other statistical models (Johnson & Rossell, 2010) and for precise hypotheses in general. Third, the Bayes factor based on the empirical prior results in slightly even more evidence for a true hypothesis than the Bayes factor based on the uniform prior. Fourth, the smaller the average degree, the bigger the evidence for a true alternative hypothesis provided by bothBFE 10andBFU 10for xed gand\u001a. This behavior is due to the negative bias of \u001afor increasing network densities in the model (Mizruchi & Neuman, 2008; Neuman & Mizruchi, 2010; Smith, 2009). the fractional Bayes factors based on b1(dashed line) andb2(dotted line) yield very similar results. Overall, they provide less evidence for the alternative hypothesis compared to BFE 10, orBFU 10, and appear to be biased towards the null. For example, this bias is manifest from the fact that networks of approximately 300 nodes are needed before the fractional Bayes factors based on b1andb2result in evidence for the true alternative hypothesis when \u001aequals .25 and d= 8, see Figure 3.3. By way of comparison, the Bayes factors based on the empirical prior and the uniform prior already point towards evidence for the alternative for small networks in this scenario. Sixth, the fractional Bayes factor based on b3(dot-dashed line) does not show consistent behavior when the null is true. In particular, the evidence for a true null hypothesis does not increase with the network size but remains constant, or in some cases even decreases. In order to provide more insights into the behavior of the fractional Bayes factor, we investigated its behavior more thoroughly. To that end, we observe that for small values forb, the updated marginal prior for \u001ain the fractional Bayes factor approach in (3.9) is just proper, with most of its probability mass still at values close to one for which the likelihood function is vanishing, see Figure 3.4. As the marginal likelihood under hypothesis H1in the fractional Bayes factor approach is essentially an average weighted likelihood over (0 ;1), with the updated prior acting as weight function, the fractional Bayes factors based on b1andb2tend to favor the null by construction. On the other64 Chapter 3. Bayesian hypothesis testing in the integrated likelihood components f(yj\u001a)1\u0000b1(black dashed line), f(yj\u001a)1\u0000b3(black dot-dashed line), and the updated marginal priors p\u0000 \u001ajH1;yb1\u0001 (gray dashed line) under H1: 0< \u001a < 1 based on pNI(\u001ajH1) = data using generated small-world networks ( g= 100;d= 8). The integrated likelihood component and the updated marginal prior based onb2are not plotted, as they are graphically indistinguishable from the curves based on b1. hand, for large values for b, the updated marginal prior for \u001aexhibits a local maximum near the maximum likelihood estimate of \u001a, see Figure 3.4. When the data are generated under the null, this results in a relatively larger average weighted likelihood over (0 ;1) and considerable support for the alternative, which explains the inconsistent behavior of the fractional Bayes factor based on the fraction b3when the null is true. Given the results from our simulation study, we recommend using the Bayes factor based on the empirical prior for \u001awhen testing H0:\u001a= 0 versus H1: 0< \u001a <1, or the Bayes factor based on the uniform prior as a reasonable alternative. We do not recommend any of the fractional Bayes factors for this test, as they are either biased towards the null when the data are generated under the alternative or they show inconsistent behavior when the null is true. As a result, the fractional Bayes factors provide little improvement over classical null hypothesis signi cance testing, whereas the Bayes factors based on the empirical and the uniform prior for \u001aclearly do perform considerably well. Figure 3.5 reports the average posterior model probabilities for test B based on the em- pirical prior (left panel) and the ones based on the uniform prior (right panel) for di erent network sizes and data-generating hypotheses.11In general, the evidence for a true data- generating hypothesis is increasing with the sample size in all scenarios. Furthermore, the data-generating hypothesis always receives the most support, except for some very small network sizes and when the data are based on negative network e ects in combination with using the empirical prior for \u001a. In the latter case, the prior probability for hypothesis H1,pE(H1) =:02, is very small compared to the one for the null, pE(H0) =:20. This means that the data need to support hypothesis H1approximately 10 times more than 11Simulation results for d= 8 are available from the authors upon request. We do not present them here, as they do no provide any additional, i.e., di erent, insights.3.5. Simulation study 65 gAverage the hypotheses H0(solid line), H1(dashed line), H2(dotted line), H3(dot-dashed line), and empirical prior for \u001a,pE(Htjy);t2 f0;1;2;3;4g(left panel), and based on the uniform prior for \u001a,pU(Htjy) (right panel), for 1,000 simulated data sets using generated small-world networks. the null such that the hypotheses receive at least equal posterior probability. However, we believe this behavior not to be a real concern, as the empirical literature suggests that it is highly unlikely to observe negative values for \u001ain practice (Dittrich et al., 2017). Else, if a researcher deems such negative network autocorrelations to be more plausible than implied by pE(H1) =:02, hypothesis H1should accordingly be given a higher prior probability.66 Chapter 3. Bayesian hypothesis testing in the network autocorrelation model 3.6 Empirical examples In the following, we apply the Bayes factor based on the empirical prior for \u001ato three data sets from the literature to quantify the relative evidence in the data for competing hypotheses of interest. We tested the ve the notion of \\no network e ect\", a \\minor negative network e ect\", a \\minor (positive) network e ect\", a \\medium network e ect\", and a \\large network e ect\", respectively. We assigned prior probabilities to these hypotheses using the unconstrained empirical prior from Section 3.4, which yields pE(H0) =:20,pE(H1) =:02,pE(H2) =:20,pE(H3) =:39, andpE(H4) =:19. In order to check for robustness to the choice of the prior for \u001aand the prior model probabilities, we performed our analyses also using a uniform prior for the network autocorrelation parameter as well as for specifying prior model probabilities via the uniform unconstrained prior, i.e., pU(H0) =:20,pU(H1) =pU(H2) =pU(H3) =:16, andpU(H4) =:32. Finally, we compared results to those coming from classical tests usingp-values. 3.6.1 Crime data In the cross-sectional data set for 49 neighborhoods in Columbus, Ohio, rst analyzed by Anselin (1988), the network autocorrelation model was used to explain the 1980 neigh- borhood crime rates, operationalized as the combined total of residential burglaries and vehicle thefts per 1,000 households. This data set is openly accessible as part of the colum- bus data from the R package spdep (Bivand & Piras, 2015) and Figure 3.6 (left) shows the spatial distribution of the crime rates. Anselin (1988) modeled these crime rates as a function of household income and housing value (in 1,000USD$), plus an intercept term. In his study, both explanatory variables had a negative impact on the crime rate, while the maximum likelihood estimate of the network e ect was ^ \u001aML=:40, with a 95% con dence interval for \u001aof (:17;:64), and p=:0008.12 Using the empirical prior for \u001a, 6 times more plausible than hypothesis H0,H1,H2, andH4, respectively. Furthermore, the Bayes factor of hypothesis H3against hypothesis H0is 42.3, which is considered as very strong evidence in the data for hypothesis H3, and the Bayes factor of hypothesis H3against hypothesis H4(the second most supported hypothesis) is 2.6, which implies minor evidence for a medium e ect relative to a large e ect. R code for computing these posterior model probabilities and corresponding Bayes factors is provided in Ap- pendix 3.A. When relying on the uniform prior for \u001a, Again, hypothesis H3is by far the most likely hypothesis out of the ve, followed by 12All reported p-values are for the one-sided test H0:\u001a= 0 versus H1: 0< \u001a <1 and based on the Wald test statistic using the expected Fisher information matrix for computing standard errors.3.6. Empirical of residential burglaries and vehicle thefts per thousand households across 49 neighborhoods in Columbus, Ohio, in 1980 (left) and logarithm of voter turnout in the 1980 U.S. presidential election across 3,076 US counties (right). The shading color of an entity indicates to which quintile of the sample it belongs. hypothesis H4, which is approximately three times as unlikely as hypothesis H3. Thus, in line with the results from classical maximum likelihood-based inference, there is very strong evidence for a positive network e ect. Contrary to maximum likelihood-based in- ference, however, the Bayesian approach also allows one to draw conclusions as to how much support there is in the data for particular values for \u001a. In this data set, evidence is strong that the network e ect resides between :25 and:5, a conclusion that is neither a ected by the choice of the prior for \u001anor by the choice of the prior model probabilities. Ultimately, among these Columbus neighborhoods, there is the most evidence for medium autocorrelation (between :25 and:5) with respect to crime rates. Table 3.3 summarizes the ndings. 3.6.2 Threatened birds data In the following example, McPherson & Nieswiadomy (2005) studied the percentage of threatened birds in 113 countries around the globe in the year 2000 via the network au- tocorrelation model, considering that \\threats to a species in one country may spill over to neighboring countries' species\" (McPherson & Nieswiadomy, 2005, p.401). In this data set, the spatial connectivity matrix was based on the shared border length between two neighboring countries, which made several island countries isolates in the network.13In addition, the authors included 10, mainly socio-economic, explanatory variables in the analysis, plus an intercept term. The resulting maximum likelihood estimate of the net- work autocorrelation was ^ \u001aML=:16, with a interval for \u001aof (\u0000:06;:37), andp=:08, so \\in other words, threats to birds spill over into adjoining countries\" (McPherson & Nieswiadomy, 2005, p.405). 13All raw connectivity matrices in the examples were subsequently row-normalized by the authors.68 Chapter 3. Bayesian hypothesis testing in the network autocorrelation Table 3.3 ^ \u001aMLof\u001aand corresponding p-values for the crime data set, the threatened birds data set, and the voting data set. Crime data Threatened birds data Voting data H0H1H2H3H4H0H1H2H3H4H0H1H2H3H4 BFE t0 1 .4 12.5 42.3 16.3 1 .5 2.0 .5 0.0 1 0.0 >106>106>106 BFU t0 1 .2 9.4 42.0 6.4 1 .3 1.9 .5 0.0 1 0.0 >106>106>106 pE(Htjy) .01 .00 .11 .74 .14 .26 .01 .50 .23 .00 .00 .00 .00 .00 1 pU(Htjy) .02 .00 .14 .64 .20 .32 .07 .49 .12 .00 .00 .00 .00 .00 1 ML-based ^ \u001aML=:40;p=:0008 ^ \u001aML=:16;p=:08 ^ \u001aML=:61;p <10\u00006 Based on the empirical prior for \u001a, the data yield posterior =:50,pE(H3jy) =:23, andpE(H4jy) =:00. Hence, the hypothesis that there is a minor spillover e ect of threats to birds across ad- joining countries, i.e., H2: 0< \u001a\u0014:25, is most supported by the data and consequently results in the highest Bayes factor, see Table 3.3. However, the Bayes factor of a minor spillover e ect against no spillover e ect is only 2.0, so the support in the data for hypoth- esisH2is far from decisive. In case of considering a uniform for \u001a, the resulting posterior probabilities for the hypotheses are similar =:32,pU(H1jy) =:07, pU(H2jy) =:49,pU(H3jy) =:12, andpU(H4jy) =:00. Again, none of the alternative hypotheses receives convincing evidence to outweigh the null. Overall, the data provide most evidence for \u001abeing between 0 and :25 but the Bayes factors also show that the strength of this evidence is rather small. These ndings vividly illustrate the well-known issue that p-values tend to overestimate the evidence against the null (Berger & Sellke, 1987; Je reys, 2001; Wagenmakers, 2007). 3.6.3 Voting data The voting data set contains voter turnout in the 1980 U.S. presidential election from 3,107 U.S. counties. Pace & Barry (1997) employed a Spatial Durbin model, a variant of the network autocorrelation model given by y=\u001aWy+ 1+X +WX +\"(where denotes the model's intercept term, 1a of ones, and another vector of re- gression coe\u000ecients), to analyze the logarithm of the voter turnout (TURNOUT) across these U.S. counties.14The spatial distribution of the logarithm of the voter turnout is shown in Figure 3.6 (right).15As explanatory variables, the authors used the logarithm of, rst, the population of 18 years of age or older eligible to vote in each county (POP); second, the population of 25 years of age or older with a 12-th grade or higher education in each county (EDUCATION); third, the number of owner-occupied housing units in each county (HOUSES); fourth, the aggregate income of each county (INCOME), as well as the 14Note that a Spatial Durbin model can be represented as a network autocorrelation (3.1) by 15We created the U.S. county map by using the map() function from the maps package in R (Becker et al., 2016). The depicted county map does not include several very small counties in Virginia, which is why there are data for only 3,076, instead of the full 3,107, counties displayed.3.7. Conclusions 69 four corresponding spatially lagged variables. Furthermore, the connectivity matrix Win this example was constructed on the basis of the four nearest neighbors of each county.16 Except for POP and the spatially lagged HOUSES and INCOME variables, all other pre- dictors were found to have a positive impact on TURNOUT, with a maximum likelihood estimate of ^ \u001aML=:62 (Pace & Barry, 1997, p.242), an associated 95% con dence interval for\u001aof (:58;:65), and p <10\u00006. Computing corresponding posterior model probabilities underpins the decisive ev- idence for a as pE(H0jy) =pE(H1jy) =pE(H2jy) =pE(H3jy) =:00 andpE(H4jy) = 1. Accordingly, the concomitant Bayes factor of hypothesis H4against any other considered hypothesis exceeds 106, which provides \\decisive\" evidence in the data in favor of hypothesis H4compared to hypothesis H0,H1,H2, andH3, respectively. When using the uniform prior, the posterior model probabilities remain essentially un- changed, as the evidence in the data for a large network e ect is conclusive in this exam- ple. Although the implications of the Bayesian approach seem in line with the traditional approach, this is not the case completely: the only thing we can deduce from classical null hypothesis signi cance testing here is that we can reject the null hypothesis that \u001a= 0. On the other hand, the Bayesian approach gives us much more detail about which values for\u001aare most supported by the data and quanti es to what extent. 3.7 Conclusions In this chapter, we developed three Bayes factors for testing precise and interval hypothe- ses on the network e ect in the network autocorrelation model. The Bayesian approach to these tests comes with several practical advantages compared to classical null hypothesis signi cance testing. For example, the Bayes factors and the resulting posterior model probabilities allow us to quantify the amount of evidence for a precise null hypothesis, or any other hypothesis, and they allow us to test multiple precise and interval hypotheses simultaneously without any of the drawbacks of classical null hypothesis signi cance test- ing. We ran an extensive simulation study to evaluate the numerical behavior of the pre- sented Bayes factors for a wide range of network con gurations. We found that the Bayes factor based on an empirical prior for the network e ect, relying on a summary of pub- lished network autocorrelations from many di erent sources, is always consistent, displays superior performance, and is the Bayes factor we recommend. At the same time, using a uniform prior for \u001ainstead yields properties that are almost as good as those based on the empirical prior. Finally, we do not recommend employing improper priors for \u001ain combination with the fractional Bayes factor methodology. We illustrated the practical use of the recommended Bayes factors with three examples and provided computer code in R, making the proposed Bayes factors easily available to researchers interested in testing for the existence and magnitude of a network e ect in the network autocorrelation model. 16Data on the dependent and the independent variables were taken from the 1980 U.S. Census and are available along with a sparse matrix representation of Wfrom the Spatial Econometrics Toolbox for Matlab at http://spatial-econometrics.com/html/jplv7.zip , leselect.data andelect.ford .70 Chapter 3. Bayesian hypothesis testing in the network autocorrelation model Given the importance of the network autocorrelation model in a variety of elds, we believe there is much value to having available an approach that makes it possible for researchers to test hypotheses that go beyond the standard signi cance test H0:\u001a= 0 versusH1:\u001a6= 0, which is only useful for falsifying the null. The new Bayesian tests provide means for quantifying evidence in favor of any hypothesis and enable researchers to test multiple hypotheses against one another in a single analysis including, but not restricted to, any combination of precise and interval hypotheses. Overall, we hope that these tools will enrich the toolkit of researchers studying network e ects through the net- work autocorrelation model. Acknowledgment We thank Michael A. McPherson and Michael L. Nieswiadomy for sharing their data.3.A. Calculating Bayes factors using R 71 Appendix 3.A Calculating Bayes factors using R ## Function to compute the logarithm of the marginal likelihood ## under a precise hypothesis rho=c and data y, X, W lnmarglik.p <- function(y, X, - gminusk2*log(yAMAy)) return(lnml) } ## Function to compute the logarithm of the marginal likelihood under an ## interval hypothesis a1<rho<a2 for a normal prior (mean, sd) ## for rho, data y, X, W, and N grid points lnmarglik.n <- function(N=1e3, y, X, W, mean, sd, length(y) in the network autocorrelation model for (r in 1:100) { inth[r] int[r] + log(spread) + log(sum(int))) return(lnml) } ## Function to compute the logarithm of the marginal likelihood under an ## interval hypothesis a1<rho<a2 for a uniform prior for rho, ## data y, X, W, and N grid points lnmarglik.u <- function(N=1e3, y, X, W, c(4, 1)) int <- NULL for (r in 1:(2*N - 1)) { a1) - d + log(spread) + log(sum(int))) return(lnml) } For all of the scenarios considered in this chapter, using N= 1;000 equally spaced grid points for \u001aproved to be more than su\u000ecient to obtain reliable results for the marginal likelihoods given in (3.7) and (3.8). In addition, we also compared our numerical integra- tion scheme to an importance sampling procedure (A. Owen & Zhou, 2000). As to that, we approximated log( jA\u001aj) and log\u0000 yTAT \u001aMA\u001ay\u0001 by second-order at their maximum values, \u001a= 0 and \u001a=yTMWy=yWTMWy, respectively. This results in normal approximations of jA\u001ajandyTAT \u001aMA\u001ay\u0000(g\u0000k)=2. Hence, the overall expressions in (3.7) and (3.8) can be approximated by normal distributions, which we used as importance sampling distributions. R code therefor is available from the authors upon request. The two methods give virtually identical results and we thank an anonymous reviewer for this suggestion. We provide code for computing the logarithms of the marginal likelihoods only, as cal- culating the marginal likelihoods themselves directly might result in under ow in R. Ob- tainingtheBayesfactorfromtwologarithmsofthemarginallikelihoodsisstraightforward, while posterior probabilities for the e.g.,d= 650\u0000max t2f0;1;:::;T\u00001glog(p(yjHt)), might be added in case that the marginal likelihoods are too small to be distinguished from zero in R.74 Chapter 3. Bayesian hypothesis testing in the network autocorrelation model ## Run the script below to compute posterior model probabilities and ## Bayes factors based on the empirical prior for rho ## for the crime data is asymptotically of the same order as the conditional Independence Je reys prior for \u001a for\u001a!1. In particular, it is prior for\u001aand\u001b2 12R+and 12Rkare constants. Proof. (i) Applying auxiliary facts (1), (2), and using the functional form of the model's Inde- pendence Je reys prior Chapter testing multiplicity of the largest eigenvalue of W,\u00151= 1, is one. Then, there exists (1 i=2\u00152 i completes the proof. \u00043.D. Minimum bound for bin the fractional Bayes factor approach 77 Appendix 3.D Minimum bound for bin the fractional Bayes factor approach When using the proposed improper prior for \u001a,pNI(\u001ajHinterval) = (1\u0000\u001a)\u000011(0;1)(\u001a), in combination with the standard non-informative prior for the remaining nuisance param- eters,p\u0000 \u001b2; \u0001 /1=\u001b2, we can write for the the resulting updated prior in (3.9) the integrand in (3.13) is the kernel of the probability density function of a multivariate normal random variable Z\u0018N\u0010 ^ ;\u001b2 b\u0000 the terms in (3.14) involving \u001b2correspond to the kernel of the prob- ability density function of an inverse gamma distributed random variable when gb > k,78 Chapter 3. Bayesian hypothesis testing in the network autocorrelation model i.e., when b > k=g. In this in (3.15) is a quadratic polynomial in \u001a, it is bounded for \u001a2(0;1). Thus, it only remains to show that Z1 0(1\u0000\u001a)\u00001jA\u001ajbd\u001a=Z1 0(1\u0000\u001a)\u00001(1\u0000\u001a)bgY i=2(1\u0000\u001a\u0015i)bd\u001a <1:(3.16) Similarly to before, the last product in (3.16) is bounded for \u001a2(0;1), so it Fractional Bayes factor computation Computing the integral in the numerator of (3.12) can be done using standard numerical techniques. On the other hand, evaluating the integral in the denominator of (3.12) directly is numerically unstable, as the integrand approaches in nity at the upper bound. Integration by parts provides a simple solution that results in a new smooth integrand and is presented in the following. Without loss of generality, we assume that the multiplicity of the largest eigenvalue of W,\u00151= 1, is one. Then, the integral in the denominator of (3.12) can be written and H(\u001a) :=gQ i=2(1\u0000\u001a\u0015i)byTAT \u001aMA\u001ay\u0000gb\u0000k 2. After Chapter 4 Bayesian analysis of higher-order network autocorrelation models Abstract The network autocorrelation model has been the workhorse for estimating and testing the strength of theories of social in uence in a network. In many network studies, di erent types of social in uence are present simultaneously and can be modeled using various connectivity matrices. Often, researchers have expectations about the order of strength of these di erent in uence mechanisms. However, currently available methods cannot be applied to test a speci c order of social in uence in a network. In this chapter, we rst present exible Bayesian techniques for estimating network autocorrelation models with multiple network autocorrelation parameters. Second, we develop new Bayes factors that allow researchers to test hypotheses with order constraints on the network autocorrelation parameters in a direct manner. Concomitantly, we give e\u000ecient algorithms for sampling from the posterior distributions and for computing the Bayes factors. Simulation results suggest that frequentist properties of Bayesian estimators based on non-informative priors for the network autocorrelation parameters are overall slightly superior to those based on maximum likelihood estimation. Furthermore, when testing statistical hypotheses, the Bayes factors show consistent behavior with evidence for a true data-generating hypothesis increasing with the sample size. Finally, we illustrate our methods using a data set from the economic growth theory. This chapter is under review at Sociological Methodology (revise and resubmit) as: Dittrich, D., Leenders, R.Th.A.J., and Mulder, J. Network autocorrelation Bayesian techniques for estimating and testing multiple network autocorrelations.82 Chapter 4. Bayesian analysis of higher-order network autocorrelation models 4.1 Introduction Social network research plays an important role in understanding how persons, organiza- tions, or countries in uence each other's behavior, well-being. The network autocorrelation model (Ord, 1975; Doreian, 1981) has been the workhorse for estimating and testing the strength of social in uence in a given network (Fujimoto et al., 2011). In the network autocorrelation model, actors' behavior, opinions, or well-beings are assumed to be correlated and a network autocorrelation parameter \u001ais estimated, representing the strength of a social in uence mechanism in the network. The network autocorrelation model has been used to analyze network in uence on individual behavior across many di erent elds, such as criminology (Tita & Radil, 2011), ecology (McPher- son & Nieswiadomy, 2005), economics (Kalenkoski & Lacombe, 2008), geography (Mur et al., 2008), organization studies (Mizruchi & Stearns, 2006), political science (Gimpel & Schuknecht, 2003), and sociology (Burt & Doreian, 1982). While the network autocorrelation model has yielded many ndings, the stan- dard, or rst-order , speci cation of the model implicitly assumes the presence of a single network in uence mechanism on the outcome of interest only. However, this may be too restrictive in many cases, as di erent types of social in uence are likely to be present simultaneously. For example, an actor is often a member of multiple distinct but poten- tially overlapping networks, such as a friendship network, a collaboration network, or an information-sharing network. Similarly, ties need not only be de ned by social interaction but can also refer to geographical proximity, money ows, or joint memberships. Each of these networks may have some connection to the outcome of interest; hence, a model that ignores multiple social in uence mechanisms might be overly simplistic. Besides the fact that individuals are often members of multiple, potentially overlap- ping, networks, conversely it is also the case that many networks are characterized by sub- groups. For example, children in school classes may belong to separate social classes and we might ask if, with respect to school performance and petty crime, children of socially disadvantaged backgrounds in uence each other based on the same in uence mechanism, say friendship, stronger than those of a more privileged background? Another example of grouping can be found in economic growth theory, where, with respect to economic growth, central nations are expected to be subject to other processes than peripheral de- veloping nations (Dall'erba et al., 2009; Leenders, 1995). The network autocorrelation model can be straightforwardly extended to include mul- tiple in uence mechanisms and di erent subgroups within a network (McMillen et al., 2007). Badinger & Egger (2011), Elhorst et al. (2012), Hepple (1995a), and Lee & Liu (2010) provided theoretical discussions of and estimation procedures for these so-called higher-order network autocorrelation models, while empirical applications can be found in e.g., Beck et al. (2006), Dall'erba et al. (2009), Lacombe (2004), McMillen et al. (2007), and Tita & Radil (2011). In this chapter, we develop a fully Bayesian framework for estimating higher-order network autocorrelation models and for simultaneously testing multiple constraints on4.1. Introduction 83 the relative order of network e ects, such as H0:\u001a1=\u001a2= 0,H1:\u001a1> \u001a2= ferent in uence mechanisms, respectively. Using a Bayesian approach for estimating and testing higher-order network autocorrelation models has several advantages compared to classical methods such as maximum likelihood estimation and null hypothesis signi cance testing. First, in contrast to maximum likelihood estimation of higher-order models, rely- ing on Bayesian estimation eliminates the need to perform an optimization procedure over a constrained parameter space, the latter not always resulting in the optimal parameter estimates (LeSage & Pace, 2011). Second, opposed to null hypothesis signi cance testing, so-called Bayes factors allow researchers to quantify relative evidence in the data in favor of the null, or any other, hypothesis against another hypothesis (Kass & Raftery, 1995) and can also be easily extended to test more than two hypotheses against each other simul- taneously (Raftery et al., 1997). Hence, this enables researchers to precisely test multiple network operationalizations against each other. Third, Bayes factors have been proven to be very e ective for testing hypotheses with order constraints on the parameters of interest (Braeken et al., 2015; Klugkist et al., 2005; Mulder, 2016; Mulder & Wagenmakers, 2016). For example, this makes it possible to precisely test whether social in uence is larger among actors with low socio-economic status (SES) than from actors of high SES to those with low SES (or more complicated combinations of equality and inequality expectations). This cannot be done using classical tests and is of particular importance in higher-order network autocorrelation models, as in this setting, researchers often have expectations about the order of strength of di erent network e ects. Whereas such expectations have tended to remain implicit in most research, Bayes factors permit researchers to state them as actual hypotheses and then test them in a precise and straightforward manner. Thus, we propose Bayes factors for testing multiple hypotheses on the relative impor- tance of social in uence in a given network. The presented methodology not only allows a researcher to conclude if there is evidence in the data for, or against, non-zero network autocorrelations in the network, but it grants the researcher the opportunity to simulta- neously test any number of competing hypotheses on the relative strength of the network e ects against each other as well. Subsequently, we conduct an extensive simulation study to investigate and show the desirable numerical properties of the new procedures, which we then use to re-analyze a data set from the economic growth literature. We proceed as follows. In the next section, we present higher-order network autocorre- lation models in detail before introducing Bayesian estimation and hypothesis testing tech- niques for the model in Sections 4.3 and 4.4. Concomitantly, we provide e\u000ecient imple- mentations for estimating higher-order network autocorrelation models and for computing Bayes factors involving order hypotheses on the network autocorrelation parameters. We assess the numerical behavior of the proposed methods in Section 4.5. In Section 4.6, we illustrate our approaches with an empirical example and Section 4.7 concludes.84 Chapter 4. Bayesian analysis of higher-order network autocorrelation models 4.2 The network autocorrelation model 4.2.1 The rst-order network autocorrelation model Building on a standard linear regression model, the network autocorrelation model relaxes the assumption of independence of observations and allows for correlation between them by explicitly using the underlying network structure. More precisely, an actor's response is modeled as the weighted sum of the actor's neighbor responses and a linear combination of actor attributes. In mathematical notation, the rst-order network autocorrelation model is given by y=\u001aWy+X +\";\"\u0018N\u0000 0g;\u001b2Ig\u0001 ; (4.1) whereyis a vector of length gcontaining the observations for a variable of interest for the gactors in a network, X2Rg\u0002kis a standard design matrix (possibly including a vector of onesinthe rstcolumnforaninterceptterm), 2Rkisavectorof kregressioncoe\u000ecients as in standard linear regression, \"2Rgcomprises the error terms that are assumed to be independent and identically normally distributed with zero mean and variance of \u001b2,0gis a vector of zeros of length g, andIgdenotes the ( g\u0002g) identity matrix. Furthermore, W is a (g\u0002g)connectivity matrix , where a non-zero entry Wijamounts to the in uence of actorjon 0 for all i2 f1;:::;gg. Typically, Wisrow-standardized , i.e., all rows sum up to one, which in this case means that the term Wyrepresents the vector of the actors' neighbors' average responses. Finally, \u001ais called the network autocorrelation parameter and quanti es the magnitude of social in uence on a variable of interest in a given network as induced by W. For a substantive interpretation of the model, see Leenders (1995, 2002). The model's likelihood is multivariate normal and space of \u001ais chosen as the interval around \u001a= 0 for which A\u001ais non-singular (Hepple, 1995a; LeSage & Parent, 2007; Smith, 2009). The bounds of this feasible range of \u001aare determined by the eigenvalues of Wwith the smallest and largest real part, respectively, which means that\u001ahas to be contained in (1 =Re(\u0015g[W]);1=Re(\u00151[W])), where (1=Re(\u0015g[W]);1=Re(\u00151[W]))\u0002(0;1)\u0002Rk.1 1Except for Leenders (1995), the literature on the network autocorrelation model ignores the occurrence of potentially complex eigenvalues that can arise when considering non-symmetric connectivity matrices. IfWis row-standardized, it follows that Re(\u00151[W]) = 1. Lastly, as det( A\u001a)>0 for all \u001a2\u0002\u001a, we simply writejA\u001ajforjdet(A\u001a)jin the network autocorrelation model 85 4.2.2 Higher-order network autocorrelation models The standard, or rst-order, network autocorrelation model in (4.1) is limited to a single network autocorrelation parameter \u001aand a single connectivity matrix W. Hence, in this model the social in uence is assumed to be homogeneously distributed in the network based on a single in uence mechanism. Extending the rst-order model to higher-order network autocorrelation models allows for a richer dependence structure by including mul- tiple connectivity matrices, representing di erent in uence mechanisms, e.g., geographic adjacency and social similarity. This amounts to the functional form y=RX r=1\u001arWry+X +\";\"\u0018N\u0000 0g;\u001b2Ig\u0001 ; (4.3) wherefWrgrare distinct the corresponding network autocorre- lation parameters f\u001argrdenote the strength of the di erent in uence mechanisms. In practice, there can be overlap between connectivity matrices, i.e., di erent connec- tivity matrices may share common ties. While partially overlapping connectivity matrices do not pose identi cation problems as long as there is no complete overlap (Elhorst et al., 2012), overlap does make interpretability of the network autocorrelation parameters more di\u000ecult (Elhorst et al., 2012; LeSage & Pace, 2011). In particular, partial overlap may result in empirically unlikely negative autocorrelations (Dittrich et al., 2017; Elhorst et al., 2012). We will analyze the numerical e ect of overlapping connectivity matrices on the estimation of and hypothesis tests on \u001a:= (\u001a1;:::;\u001aR) in more detail in a simulation study in Section 4.5. Higher-order network autocorrelation models do not only allow to consider multiple in uence mechanisms but also to partition a network into several subgroups. In the lat- ter case, we include possible heterogeneity in social in uence strengths by allowing for di erent levels of network autocorrelation within and between subgroups for a given in- uence mechanism, e.g., geographic adjacency. Dividing the actors in a network into S subgroups, with sizes g1;:::;gSandPS s=1gs=g, we can express a model with multiple subgroups using the representation in (4.3) by the observations for the gsactors in the s-th subgroup of the network, Wss0is a (gs\u0002gs0) connectivity matrix de ning the in uence relationships between members of subgroup s0and members of subgroup s, and\u001ass0is the86 Chapter 4. Bayesian analysis of higher-order network autocorrelation models network autocorrelation parameter representing the strength of the social in uence of the actors in subgroup s0on the actors in subgroup s. As the sizes of the Ssubgroups poten- tially di er, each Wss0is typically row-standardized separately, which removes scale e ects and eases direct comparison between the network autocorrelation parameters (McMillen et al., 2007). The structure of the likelihood function of higher-order network autocorrelation mod- els remains the same as the one of the rst-order network autocorrelation model in (4.2), withA\u001abeing replaced by A\u001a:=Ig\u0000PR r=1\u001arWr. As in the rst-order model, we de ne theR-dimensional parameter space of \u001a= (\u001a1;:::;\u001aR) as the space containing the origin for which A\u001ais non-singular. Elhorst et al. (2012) provided a simple general procedure for checking if a point \u001a\u00032RR, givenW1;:::;WR, lies in the corresponding feasible parameter space nomic growth of labor productivity In this subsection, we introduce a data set from the economic growth literature that prompts questions readily answered using Bayes factors. Here, we merely describe the data set and the research questions, while we will come back and provide solutions to them in Section 4.6. Dall'erba et al. (2009) employed a second-order network autocorrelation model to ex- plain the growth rates of labor productivity in service industry across 188 European re- gions in 12 countries from 1980 to 2003. In order to adequately deal with interregional spillovers, the authors introduced two di erent spatial weight matrices, W1andW2, \\un- der the assumption that economic interactions decrease very substantially when a national border is passed\" (Dall'erba et al., 2009, p.337). Hence, W1was constructed using the three nearest neighbors of a region within the same country, while W2was based on the three nearest neighbors in the bordering countries. These raw binary connectivity matri- ces were subsequently row-normalized by the authors. In addition to an intercept term, Dall'erba et al. (2009) considered four more explanatory variables: the growth rate of market service output in a region, the initial labor productivity gap between the region and the leading region, a measure of urbanization of the region, and a measure of the accessibility of the region. Thus, their model is of growth rates of labor productivity in service industry across the 188 regions, 2R5represents the vector of the four regression coe\u000ecients plus an intercept term, X2R188\u00025contains the values for the explanatory variables for the 188 regions, where X:i;i2 f1;:::;5g, denotes the i-th column of X,02R188is a vector of zeros, and I2R188\u0002188represents the corresponding identity matrix. 2In Elhorst et al. (2012), the term tan( )=rmax[W\u0003] needs to be replaced by tan( )=rmin[W\u0003] in Equation (15) on page 213.4.3. Bayesian estimation of higher-order network autocorrelation models 87 The authors found that the estimate of \u001a1, re ecting interactions within the same country, waspositiveandstatisticallysigni cant, indicatingthepresenceofpositivespatial within-country spillover e ects. On the other hand, the estimate of \u001a2was very close to zero and statistically not signi cant. Dall'erba et al. (2009) concluded by saying that \\the results obtained also con rm the hypothesis that economic interactions decrease very substantially when a national border is passed (indeed, the coe\u000ecient re ecting external spillovers is not statistically signi cant)\" (Dall'erba et al., 2009, p.342). However, in order to draw this conclusion, one needs to directly test a corresponding hypothesis, e.g., H1:\u001a1> \u001a2= 0, against a (set of) competing hypothesis (hypotheses), such as H0:\u001a1= \u001a2= 0,H2:\u001a1> \u001a2>0, or (and) H3:\u001a1=\u001a2>0. These four hypotheses correspond to the notion of \\no network e ects\" (hypothesis H0), \\a positive within-country network e ect only\" (hypothesis H1), \\positive but decreasing network e ects after a national border is passed\" (hypothesis H2), and \\positive and equally strong within-country and between-countrynetworke ects\"(hypothesis H3). Currently, noformalstatisticalmethod is available to directly test such hypotheses on multiple network autocorrelations. In the remainder of this chapter, we develop a Bayesian framework for testing and quantifying the evidence in the data for such hypotheses involving equality and order constraints on the network e ects. We will come back to this empirical example and test these hypotheses against each other using Bayes factors in Section 4.6. Lastly, the authors stated that \\there is evidence that the coe\u000ecients in a growth model are potentially varying for di erent subsets of the total sample\" (Dall'erba et al., 2009, p.342). In Section 4.6, we will also investigate if there is such evidence in this data set by considering a network autocorrelation model with two subgroups, allowing for di ering levels of network autocorrelation within and between the two subgroups. 4.3 Bayesian estimation of higher-order network autocorre- lation models 4.3.1 Prior speci cation Bayesian estimation starts with formulating prior expectations about the parameters in a model that is done in terms of so-called prior distributions , orpriors. These priors summarize the (lack of) information about the model parameters before observing the data. If such prior information is available, e.g., based on previous literature, informative priorsfor the parameters of interest can be formulated. In Chapter 2, we performed a literature study for the rst-order network autocorrelation model, where we looked at the distribution of reported network autocorrelations across many di erent elds. Our results showed that most of the analyzed data in the literature exhibit positive network auto- correlation between 0 and .5, while it seems highly unlikely to observe negative network autocorrelation, as previously also noted by e.g., Neuman & Mizruchi (2010). This infor- mation could then be used to formulate an informative prior for \u001ain a rst-order network autocorrelation model (see e.g., Dittrich et al., in press).88 Chapter 4. Bayesian analysis of higher-order network autocorrelation models On the other hand, if such prior information is missing, or a researcher deliberately refrains from adding additional information to the model through the prior, usually so- callednon-informative priors are used (Gelman et al., 2003). In the network autocor- relation model, \u001b2and are commonly assigned 1997b, 2000). These priors assume that all possible values for log\u0000 \u001b2\u0001 and are equally likely a priori. We also do so throughout this chapter. Note that these priors are not properin the sense that they do not integrate to a nite value, but this does not a ect estimation of the model. We use a general R-variate normal prior for \u001a,p(\u001a) = \u0016;\u0006(\u001a) 1\u0002\u001a(\u001a)c\u00001, where \u0016;\u0006(\u0001) denotes the probability density function of a multivariate normal distribution with prior mean \u0016and prior covariance matrix \u0006, 1\u0001(\u0001) is the standard indicator function, andc:=R \u0002\u001a \u0016;\u0006(\u001a)d\u001ais a normalizing constant representing the probability mass of \u0016;\u0006(\u0001) contained in the network autocorrelation parameters' space \u0002 \u001a. If researchers have su\u000ecient prior information about the network autocorrelations, they can specify \u0016 and \u0006 directly. Alternatively, when specifying \u0006 vaguely enough, i.e., with very large diagonal elements, the prior becomes essentially identical to a proper uniform distribution for\u001aon the bounded parameter space \u0002 \u001a. In summary, we use the following priors for the model parameters, which we assume to be a priori independent from each other: p(\u001a) = \u0016;\u0006(\u001a) speci ed a prior distribution for the model parameters, the information con- tained in the observed data yis used to update the prior distribution and to arrive at the posterior distribution , or simply posterior . The posterior is used for all Bayesian inference in the model, e.g., to obtain point estimates of model parameters (the posterior mean or the posterior median), to construct Bayesian credible intervals (i.e., intervals in the do- main of the posterior), or to determine other statistics of interest, such as the probability that one network e ect is stronger than another one for given data, p(\u001a1> \u001a2jy). In this subsection, we specify the posterior for higher-order network autocorrelation models based on the priors from Section 4.3.1 and provide an automatic and e\u000ecient scheme to sample from this posterior. First, Bayes' theorem gives that the posterior is proportional to the prior multiplied by the likelihood, more precisely4.3. Bayesian estimation of integrates to unity. The marginal likelihood does not depend on any model parameters and can be ignored in Bayesian estimation. On the other hand, when testing hypotheses, the marginal likelihood does play a central role as it quanti es how plausible the data are under a speci c hypothesis, which we will discuss in the following section. Next, using the priors in (4.5), (4.6), (4.7), and the likelihood function in (4.2), we can express the posterior p\u0000 \u001a;\u001b2; distribution in (4.9) does not belong to a family of known prob- ability distributions, so we cannot directly infer its posterior mean, its quantiles, or other quantities of interest.3In this case, it is common to sample random draws from the pos- terior distribution and to use these posterior draws to approximate any desired statistic. An e\u000ecient method is to sequentially draw from the conditional posterior distributions, i.e., the posterior distribution of one parameter (block) given the remaining parameters and the data (Geman & Geman, 1984; Gelfand & Smith, 1990).4Extending the proposed method for the rst-order network autocorrelation model in Chapter 2 to higher-order models, we sample the model parameters according to the following blocks: ( \u001a; 1);\u001b2, ande ( 2;:::; k) contains the remain- ing regression coe\u000ecients. By simultaneously sampling \u001aand 1, we can better capture potential posterior correlation between the network e ects as well as potential correlation between the network e ects and the intercept (Dittrich et al., 2017). The conditional posteriors for the proposed blocks are then given by (see e.g., LeSage, 1997a) 3The posterior p\u0000 \u001a;\u001b2; jy\u0001 in (4.9) is proper given very mild regularity conditions. The proof for higher-order models is quasi-identical to and an adaptation of the one for the rst-order model in Chapter 2. 4This is iteratively repeated Ntimes for a large number N. Geman & Geman (1984) showed that as N! 1, the draws based on the sequence of conditional posteriors can be seen as samples from the actual marginal posteriors, i.e., the posteriors for a parameter (block) given the data, e.g., p(\u001ajy).90 Chapter 4. Bayesian of gamma distribution and \u0016e and \u0006 e are given in Ap- pendix 4.A. Drawing from the conditional posteriors in (4.11) and (4.12) can be done using stan- dard statistical software. In contrast, the conditional posterior in (4.10) does not have a well-known form and cannot be directly sampled from. Instead, we use the so-called Metropolis-Hastings algorithm (Hastings, 1970; Metropolis et al., 1953) to generate draws from the conditional posterior for ( \u001a; 1). In short, the algorithm generates candidate values for the conditional posterior from a candidate-generating distribution that can be easily sampled from and subsequently accepts, or rejects, the draws with a certain proba- bility. The algorithm's e\u000eciency mainly depends on the shape of the proposed candidate- generating distribution; if possible, exploiting the form of the conditional posterior and specifying a candidate-generating distribution that closely approximates it results in e\u000e- cient solutions (Chib & Greenberg, 1995). As to that, we rst approximate log( jA\u001aj) by a quadratic polynomial in \u001aby virtue of Jacobi's formula and the Mercator series, see Appendix 4.A. Next, we observe that the logarithm of the exponential in (4.10) can also be written as a quadratic polynomial in (\u001a; 1). Hence, the logarithm of the conditional posterior itself can be approximated by a quadratic polynomial in ( \u001a; 1). Finally, by equating coe\u000ecients of this quadratic polynomial with the log-kernel of the probability density function of a ( R+1)-variate nor- mal distribution, the density in (4.10) can be approximated by a ( R+1)-variate normal candidate-generating density for ( \u001a; 1) that is tailored to the conditional posterior for (\u001a; 1).5All details and the full sampling scheme can be found in Appendix 4.A. We implemented our proposed approach in R (R Core Team, 2017) and compared its performance to a sampling scheme that does not block the network autocorrelation parameters and the intercept but uses one-dimensional random walk algorithms to gen- erate draws for each network e ect sequentially, as in Zhang et al. (2013). Figure 4.1 shows exemplary trace plots of posterior draws for \u001a1and\u001a2based on the two sampling schemes and the data in Dall'erba et al. (2009) and model (4.4). We can observe that 5It can (rarely) happen that, after equating coe\u000ecients, the obtained covariance matrix of the normal candidate-generating distribution is not positive de nite, as the Hessian in the second-order approximation of log(jA\u001aj) itself is not always positive de nite, e.g., for W1=\u00120 0 1 0\u0013 andW2=\u00120 1 0 niteoneasthenormal candidate-generating covariance matrix. This can be done using the nearPD() function from the Matrix package in R (Bates & Maechler, 2017).4.4. Bayesian hypothesis testing of posterior draws for \u001a1and\u001a2based on our proposed scheme (top row) and a random walk algorithm (bottom row) for the data in Dall'erba et al. (2009) and model (4.4). our method results in a more e\u000ecient implementation than drawing each network e ect separately, as it generates Markov chains that explore the corresponding parameter space of (\u001a1;\u001a2) much faster. Lastly, our approach is fully automatic in the sense that there are no parameters to be tuned in the Metropolis-Hastings algorithm, such as the variances of candidate-generating distributions. To conclude, the presented sampling algorithm allows researchers to automatically and e\u000eciently draw from the posterior based on a general multivariate normal prior for the network autocorrelation parameters, including informative as well as non-informative speci cations. Such e\u000ecient sampling is essential for performing any Bayesian estimation of the model, which solely relies upon the generated posterior draws. 4.4 Bayesian hypothesis testing in higher-order network au- tocorrelation models In many network studies, researchers have competing theories about the speci c order of di erent network e ect strengths. These theories can be formulated as hypotheses on92 Chapter 4. Bayesian analysis of higher-order network autocorrelation models network e.g., as H1:\u001a1> \u001a2= 0,H2:\u001a1> \u001a2>0, or H3:\u001a1=\u001a2>0, and can include as many network autocorrelation parameters as relevant to one's theory. The focus of interest then lies on which substantive theory, or hypothesis, is most plausible and most supported by the data and how strongly. In this chapter, we consider T\u00152 constrained hypotheses on the network e ects, where a hypothesis Ht, t2 f0;:::;T\u00001g, contains qI tinequality t\u0002R\u0001 matrix and a vector of length R, respectively, containing the coe\u000ecients of the qI tinequality constraints under hypothesis Ht. coe\u000ecients of the qE tequality con- straints. For example, the constraints induced by the three hypotheses H1:\u001a1> \u001a2= 0, H2:\u001a1> \u001a2>0, andH3:\u001a1=\u001a2>0 The Bayes factor is a comparative Bayesian hypothesis testing criterion that directly quanti estherelativeevidenceforahypothesisinthedata. TheBayesfactorofhypothesis Htagainst hypothesis Ht0,t;t02 f0;:::;T\u00001g, is de ned as the ratio of the marginal likelihoods under the two hypotheses, i.e., in the network denotes prior density, and \u0002 \u001atthe corresponding parameter space (Kass & Raftery, 1995). We assume common priors for \u001b2and under both hypothesis Htand hypothesis Ht0as they are seen as nuisance parameters in the presented framework. The exact form of the priors for these nuisance parameters typically does not alter the magnitude of the Bayes factor (Kass & Raftery, 0 \u0002\u001a1+1\u0002\u001a2= 0. Together, this constitutes hypothesis H1. For hypothesis H2, we have 1 \u0002\u001a1\u00001\u0002\u001a2>0 and 0\u0002\u001a1+1\u0002\u001a2> Analogously, for hypothesis hypothesis testing in higher-order network autocorrelation models 93 Table 4.1 Evidence categories for the Bayes factor BFtt0as given by Je reys (1961). BFtt0 log(BFtt0) Interpretation >100 >4.61 Decisive evidence for hypothesis Ht 30 - 100 3.40 - 4.61 Very strong evidence for hypothesis Ht 10 - 30 2.30 - 3.40 Strong evidence for hypothesis Ht 3 - 10 1.10 - 2.30 Substantial evidence for hypothesis Ht 1 - 3 0 - 1.10 Not worth more than a bare mention 1/3 - 1 -1.10 - 0 Not worth more than a bare mention 1/10 - 1/3 -2.30 - -1.10 Substantial evidence for hypothesis Ht0 1/30 - -3.40 1/100 - 1/30 -4.61 -3.40 Very strong evidence hypothesis Ht0 <1/100 <-4.61 Decisive evidence for hypothesis Ht0 The marginal likelihood under hypothesis Ht,mt(y), is a weighted average likelihood over the parameter space under hypothesis Ht, with the prior pt(\u001at) under hypothesis Ht acting as a weight function. As such, it can be interpreted as the probability that the data were observed under hypothesis Ht. Hence, the Bayes factor, as the ratio of two marginal likelihoods, quanti es the relative evidence that the data were observed under hypothesis Htrather than hypothesis Ht0. For example, when Btt0= 5, this indicates that the data are ve times more likely to have occurred under hypothesis Htcompared to hypothesis Ht0. Conversely, when Btt0= 1=5, it is ve times more likely to have observed the data under hypothesis Ht0than under hypothesis Ht. In order to facilitate interpretation of the Bayes factor, Je reys (1961) proposed a classi cation scheme that groups Bayes factors into di erent categories, see Table 4.1. For example, there is \\strong\" evidence in the data for hypothesis Ht, relative to hypothesis Ht0, whenBtt0>10 and, equivalently, \\strong\" relative evidence in the data for hypothesis Ht0whenBtt0<1=10. This grouping provides verbal descriptions and rules of thumb when speaking of relative evidence in the data in favor of a hypothesis but is still somewhat arbitrary. Ultimately, the interpretation of the magnitude of a Bayes factor should hinge upon the context of the research question (Kass & Raftery, 1995). For some introductory texts on Bayes factor testing in social science research, we refer the interested reader to Raftery (1995), van de Schoot et al. (2011), or Wagenmakers (2007). 4.4.2 Bayes factor computation In this section, we present e\u000ecient methods to compute marginal likelihoods and Bayes factors in higher-order network autocorrelation models. Using out \u001b2and of hypothesis to94 ctandct0in (4.15) correspond to the prior probabilities that the unconstrained priors for \u001atunder hypothesis Htand for\u001at0under hypothesis Ht0,N(\u0016t;\u0006t) andN(\u0016t0;\u0006t0), are in agreement with the constraints imposed under the two hypotheses. They can be approximated by simple rejection sampling, i.e., by sampling draws from the unconstrained priors and recording the proportions of draws that are in agreement with the constraints. The remaining integrals in the numerator and the denominator of (4.15) do not have closed-form solutions and have to be evaluated numerically. For this purpose, we rely on an importance sampling procedure (A. Owen & Zhou, 2000) that is explained of (4.15) (all steps equivalently apply to ht0(\u001at0)). Then, we can write for the qt(\u0001) known as the impor- tance density ,E[ht(P)=qt(P)] denotes the expected value for ht(P)=qt(P), and\u001aiare draws from qt(\u0001), forming realizations of P. The speci cation of the importance density is crucial for the algorithm's e\u000eciency, where we aim to construct a density that closely follows the actual integrand but has heavier tails than the latter and is easy to sample from (A. Owen & Zhou, 2000). As in Section 4.3.2, we approximate log\u0000 jA\u001atj\u0001 by a second-order polynomial in \u001at at its maximum, the origin. This results in a normal approximation of A\u001at . We apply the same rationale to the third term in ht(\u001at),yTAT \u001atMA\u001aty\u0000(g\u0000k)=2. Hence, ht(\u001at) can be approximated by the product of three multivariate normal densities that itself is a multivariate normal density, which we use as importance density in (4.16).8Finally, as \u001at 7We can use improper parameters \u001b2and ,p\u0000 \u001b2; \u0001 /1=\u001b2, as they appear in both hypothesis Htand hypothesis Ht0and the corresponding normalizing constants cancel out after integrating out \u001b2and (Hepple, 1995a). Note that depending on the speci cations hypothesis Ht0, the dimensions \u0006 \u001a2>0. 8As in Section 4.3.2, if the resulting covariance matrix of the normal distribution approximating jA\u001atj is not positive de nite, we use its nearest positive de nite matrix as covariance matrix instead.4.4. Bayesian hypothesis testing in higher-order network autocorrelation models 95 approaches the boundary of \u0002 \u001at, the proposed normal importance density has heavier tails thanht(\u001at), since in this case A\u001at decreases toward zero, while the normal importance density does not. This ensures a nite variance of the importance sampling estimate bIt and reliable estimation of the associated Bayes factors. All details hereto can be found in Appendix 4.B. 4.4.3 A default prior for \u001a When testing multiple hypotheses against each other, a prior for the tested model param- eters has to be speci ed under each hypothesis. Arguably, eliciting a prior under each hypothesis directly can become di\u000ecult and cumbersome, especially with a large number of hypotheses at hand. As an alternative, we propose an automatic empirical Bayes proce- dure (Carlin & Louis, 2000) for constructing a default prior pt(\u001at) under each hypothesis Htsuch that the marginal likelihood under every hypothesis Htis maximized. First, we center the multivariate normal default prior pt(\u001at) under hypothesis Ht around the origin. The motivation for this choice is that the origin is located at the boundary of typical (in)equality constrained hypotheses in the network autocorrelation model, such as H1:\u001a1> \u001a2= 0,H2:\u001a1> \u001a2>0, orH3:\u001a1=\u001a2>0, and previous literature on order constrained hypothesis testing has suggested that \\there is a gain of evidence for the inequality constrained hypothesis that is supported by the data when the unconstrained prior is located on the boundary\" (Mulder, 2014b, p.452). Second, in contrast to Bayesian estimation, assigning very large values to the diagonal elements of the prior's covariance matrix \u0006 tis not feasible in hypothesis testing. In hypothesis test- ing, we need to explicitly calculate the normalizing constant ct=R \u0002\u001at \u0016t;\u0006t(\u001at)d\u001atand a vague formulation of \u0006 tmakes this computation either unstable or tremendously time consuming due to the fairly small parameter space \u0002 \u001at.9Instead, we set the prior \u0006 tof the free network a hypothesis, e.g., \u001a1under hypothesis H1:\u001a1> \u001a2= 0, to the product of the corresponding asymptotic variance-covariance matrix of the maximum likelihood estimate of \u001atand a hypothesis- speci c scaling factor \u001b2 t, similarly as in matrix I\u0000 \u001at;\u001b2; there is only one in the prior speci cation of \u0006 tleft,\u001b2 t. Following Hansen & Yu (2001) and Liang et al. (2008), we employ a local empirical Bayes approach and choose \u001b2 tsuch that the associated marginal likelihood mt(y) is maximized, avoiding arbitrary prior speci cation. As there is no analytical solution to this maximization problem, one way to approximate the maximum of mt(y) is to compute the marginal likelihood on a grid of increasing values for\u001b2 tuntil a stopping rule is reached, e.g., until the marginal likelihood is not increasing anymore, or until it is not increasing by more than some tolerance factor.10 9As \u0002\u001atis bounded and small, Bartlett's paradox (Bartlett, 1957) is not an issue in the considered tests on the network autocorrelations. 10The marginal likelihood mt(y) can be strictly increasing with \u001b2 t, which is why we cannot use more e\u000ecient optimization techniques, such as Newton's method or the BFGS algorithm (Nocedal & Wright, 2006).96 (\u001a1;\u001a2)2\u0002(\u001a1;\u001a2)as a \u001b2 t(left) and the logarithm of the Bayes factors log( BF1u);log(BF2u);and log( BF3u) as a function of\u001b2 t(right) for the data in Dall'erba et al. (2009) and model (4.4). Figure 4.2 shows the marginal likelihoods under the three constrained hypotheses H1:\u001a1> \u001a2= 0,H2:\u001a1> \u001a2>0, andH3:\u001a1=\u001a2>0, the marginal likelihood under an unconstrained hypothesis Hu: (\u001a1;\u001a2)2\u0002(\u001a1;\u001a2), and the logarithm of the Bayes factors of the three constrained hypotheses against the unconstrained hypothesis Huas a function of \u001b2 t,t2 f1;2;3;ug, for the data in Dall'erba et al. (2009) and model (4.4). As can be seen, all of the marginal likelihoods sharply increase for smaller values for\u001b2 tbefore they gradually decrease after having reached their respective maxima. At the same time, the associated Bayes factors, in which we are ultimately interested, appear fairly robust to the choice of \u001b2 t, except for extremely small values for \u001b2 t. For the vast majority of data sets we looked at, we observed essentially the same pattern with almost all of the optimal values for \u001b2 tlaying between 2 and 10. In summary, in this section we showed how researchers can use Bayes factors to test and quantify the evidence in the data for hypotheses with order constraints on the net- work autocorrelation parameters. Parallel hereto, we provided methodology to e\u000eciently compute such Bayes factors without any need to subjectively elicit priors for the network e ects. Altogether, this ultimately allows network scholars to test and verify any kind of expectations they have about the strength of di erent network e ects. 4.5 Simulation study We performed a simulation study to investigate the performance of the proposed Bayesian estimatorandtheproposedBayesfactorsinasecond-ordernetworkautocorrelationmodel. First, we compared the Bayesian estimator from Section 4.3.2 to the maximum likelihood estimator in terms of bias of the network e ects and frequentist coverage of the corre- sponding credible and con dence intervals. Here, we use the term coverage to indicate the proportion of times in which the true, i.e., data-generating, network e ects were contained in the credible and con dence intervals, respectively. Second, as researchers are generally4.5. Simulation study 97 interested in testing whether (some) network e ects are zero or whether one network e ect is larger than another one, we considered a multiple hypothesis test with the following ve if and how fast the di erent Bayes factors converge to a true data-generating hypothesis and how robust these ndings are to various degrees of overlap between two connectivity matrices. 4.5.1 Study design In our simulation study, we generated data yviay=A\u00001 (\u001a1;\u001a2)(X +\");\"\u0018N(0g;Ig), for four network sizes g(g2 overlap between W1and W2(0%, 20%, 40%), and both W1andW2having an average degree of four. We simulated random non-symmetric binary connectivity matrices using the rgraph() function from the sna package in R (Butts, 2008), randomly rearranged ties when accounting for overlap, and subsequently row-standardized the raw connectivity matrices. Furthermore, we drew independent values from a standard normal distribution for the elements of X2Rg\u00024 (excluding the rst column which is a vector of ones), 2R4, and\"2Rg. In our rst experiment, we set the two network e ects to ( \u001a1;\u001a2) = (:2;:2) and simu- lated 1,000 data sets for each of the 12 scenarios (4 network sizes \u00023 levels of overlap \u0002 1 network e ects size).11For the Bayesian the standard improper \u0001 /1=\u001b2for the nuisance parameters and a non-informative bivariate normal prior for ( \u001a1;\u001a2),p(\u001a1;\u001a2)/N(02;100\u0002I2), which essentially corresponds to a uniform prior for ( \u001a1;\u001a2)2\u0002(\u001a1;\u001a2). We drew 1,000 realizations from the resulting posteriors by re- lying on the methods described in Section 4.3.2, taking the maximum likelihood estimate of\u0000 (\u001a1;\u001a2);\u001b2; \u0001 as starting value in the sampling algorithm, see Appendix 4.A. We used the marginal posterior median as point estimator and the 95% equal-tailed credible interval for coverage analysis. We obtained the maximum likelihood estimates as well as their standard errors and associated asymptotic con dence intervals applying the lnam() function from the sna package in R. In our second experiment, we considered 41 network e ects sizes ( \u001a1;\u001a2) ((\u001a1;\u001a2)2 f(:4;0);(:39;:01):::;(0;:4)g) and simulated 100 data sets for each of the 492 scenarios (4 network sizes \u00023 levels of overlap \u000241 network e ects sizes). Figure 4.3 shows the tra- jectory of the network e ects and a graphical representation of the speci ed the prior under each of the ve hypotheses based on the proposed empirical Bayes procedure in Section 4.4.3.12In order to compute the normal- izing constants c2andc4, we generated draws from the unconstrained bivariate normal prior for ( \u001a1;\u001a2) until we obtained 1,000 draws in agreement with the constraints imposed 11Simulation results for di erent combinations of ( \u001a1;\u001a2) are available from the authors upon request. We do not present them here as they do not provide any additional insights. 12We used the lnam() function from the sna package in R to obtain the asymptotic variance-covariance matricesofthemaximumlikelihoodestimatesofthefreenetworkautocorrelationparameters. Furthermore, we started and kept increasing \u001b2 tby 1 until either the increment in the marginal likelihood mt(y) was less than .01 or \u001b2 treached the cut-o value 20.98 Chapter 4. network autocorrelation models H1:1>2=0H2:1>2>0H3:1=2>0H4:0<1<2H5:0=1<2 12 (0,0) (0.4,0)(0,0.4) Figure 4.3 Graphical representation of the admissible subspaces of ( \u001a1;\u001a2) under the ve constrained hypotheses and the trajectory of the data-generating network e ects ( \u001a1;\u001a2) = (:4;0) (dashed line). under hypothesis H4, respectively. Then, we approximated the nor- malizing constants by the reciprocals of the proportion of the total number of draws in agreement with the constraints. For the hypotheses with only one free network autocor- relation parameter, i.e., H1:\u001a1> \u001a2= 0,H3:\u001a1=\u001a2>0, andH5: 0 =\u001a1< \u001a2, we directly obtained the corresponding normalizing constants by using the pnorm() function in R, as the bounds of the feasible range of a single free network autocorrelation parameter are known exactly, see Section 4.2.1. Finally, for all hypotheses we drew 1,000 realiza- tions from their (unconstrained) importance densities and computed the logarithm of the Bayes factor of each constrained hypothesis against an unconstrained reference hypothesis Hu: (\u001a1;\u001a2)2\u0002(\u001a1;\u001a2).13 4.5.2 Simulation results Table 4.2 shows the average estimates and root mean squared errors of \u001a1and\u001a2for the Bayesian as well as the maximum likelihood estimator. Overall, the two estimators yield nearly identical results for all considered scenarios. As expected, the (negative) bias in the estimation of the network e ects and the associated root mean squared errors are decreasing with the network size, the bias being virtually non-existent for g= 400. Introducing 20% and 40% of overlap between two connectivity matrices does not appear to impact the estimation results, even if there is mild negative correlation between the estimated network e ects in these cases, see Figure 4.4. 13For the hypotheses with only one free network autocorrelation H1:\u001a1> \u001a2= 0, H3:\u001a1=\u001a2>0, andH5: 0 =\u001a1< \u001a2, we directly generated 1,000 draws in agreement with the respective constraints by using the rtruncnorm() function from the truncnorm package in R (Trautmann et al., 2015). As the unconstrained hypothesis Huonly serves as reference hypothesis to which all other hypotheses are compared to, we did not maximize over \u001b2 uwhen computing mu(y) but xed \u001b2 uto 5.4.5. Simulation study 99 Table 4.2 Average posterior median and maximum likelihood estimates of ( \u001a1;\u001a2) = (:2;:2) and corresponding average root mean squared errors (RMSE) for 1,000 simulated data sets. 0% overlap 20% overlap overlap RMSE \u001a1\u001a2\u001a1\u001a2\u001a1\u001a2\u001a1\u001a2\u001a1\u001a2\u001a1\u001a2 g= 50 Bayes .149 .152 .155 .157 .160 .148 .163 .151 .159 .166 .168 .168 MLE .157 .160 .156 .157 .167 .154 .164 .151 .164 .172 .168 .169 g= 100 Bayes .180 .182 .107 .104 .178 .184 .111 .107 .188 .183 .107 .107 MLE .182 .184 .108 .104 .179 .186 .111 .107 .189 .185 .108 .108 g= 200 Bayes .189 .187 .074 .074 .198 .190 .076 .075 .194 .195 .077 .077 MLE .190 .188 .074 .074 .198 .190 .076 .075 .194 .195 .078 .077 g= 400 Bayes .196 0.50.00.50.50.00.5 median estimates (black) of ( \u001a1;\u001a2) = (:2;:2) (gray) for 1,000 simu- lated Chapter 4. Bayesian analysis of higher-order network autocorrelation models Table 4.3 Empirical frequentist coverage of 95% credible and con dence intervals for \u001a1and \u001a2for 1,000 simulated data .953 .949 .936 .946 .948 .943 MLE .928 .928 .912 .937 .923 .930 g= 100 Bayes .949 .958 .949 .946 .957 .961 MLE .936 .950 .942 .936 .951 .955 g= 200 Bayes .943 .948 .947 .953 .954 .937 MLE .934 .943 .950 .951 .951 .932 g= 400 Bayes .954 .948 .964 .940 .953 .943 MLE .955 .949 .964 .946 .953 .943 Table 4.3 reports the empirical frequentist coverage of Bayesian for \u001a1 and\u001a2. The coverage of Bayesian credible intervals is very close to the nominal .95 for all considered scenarios, while the coverage of con dence intervals is below nominal for network sizes of 50. These observations are in line with the subpar coverage of maximum likelihood-based con dence intervals for small samples in the rst-order network autocor- relation model in Chapter 2. Based on the results from our rst simulation experiment, we draw two main con- clusions. First, we recommend using the non-informative Bayesian estimator over the maximum likelihood estimator, as both estimators yield nearly identical network e ect estimates but the coverage of Bayesian credible intervals appears accurate, whereas for smaller network sizes the coverage of maximum likelihood-based con dence intervals is not. Second, estimating second-order network autocorrelation models with moderately overlapping connectivity matrices, i.e., with up to 40% shared ties, does not alter the estimation of the network e ects. This second nding is of particular importance to social network researchers who often encounter distinct but partially overlapping networks in empirical practice. Figure 4.5 displays the average logarithm of the Bayes factors of the hypotheses H1 (thick solid line), H2(thick dashed line), H3(dotted line), H4(dashed line), and H5(solid line) against an unconstrained reference hypothesis Huas a function of network e ects (\u001a1;\u001a2) from (:4;0) to (;0:4). Overall, the results indicate that the Bayes factors show consistent behavior, i.e., there is the most evidence for the data-generating hypothesis if the network size is large enough. This evidence is monotonically increasing with the network size. In particular, there is little discrimination between the ve hypotheses forg= 50, while there is clear support for the data-generating hypothesis for network sizes of 200 and 400. Two of the lines in Figure 4.5 are discontinued due to numerical reasons: when computing the Bayes factor, we need to calculate the probability mass of the unconstrained importance density contained in the parameter space imposed by4.5. Average logarithm of the Bayes factors log( Btu),t2 f1;2;3;4;5g, of the (dotted ects ( \u001a1;\u001a2) from (:40;0) to (0;:40) for 100 simulated data sets. the constraints under a hypothesis, see Appendix 4.B. For the Bayes factors involving the H2:\u001a1> \u001a2>0 andH4: 0< \u001a1< \u001a2, we approximated these probabilities numerically by the proportion of 1,000 draws from the unconstrained importance densities that were in agreement with hypothesis H2and hypothesis H4, respectively. For some data sets, however, none of the draws were in agreement with hypothesis H2, or hypothesis H4, in which case we set the corresponding marginal likelihood to \u00001. If this happened for at least one of the 100 simulated data sets, then the average logarithm of the Bayes factor was \u00001as well. Finally, as in our rst simulation experiment, these ndings are robust to moderate degrees of overlap between two connectivity matrices.102 Chapter 4. Bayesian analysis of higher-order network autocorrelation models 4.6 Application revisited In this section, we re-analyze a data set from the economic growth literature initially studied by Dall'erba et al. (2009) and address the questions raised in Section 4.2.3. First, we re-estimated the second-order network autocorrelation model in (4.4) based on non- informative priors for all model parameters and compared the results to those coming from maximum likelihood estimation. Second, we used Bayes factors to quantify the relative evidence in the data for di erent competing hypotheses of interest with respect to this data set. Finally, we considered a network autocorrelation model with two subgroups, assuming only one dominant common in uence mechanism within and between the two subgroups. 4.6.1 Bayesian estimation of a second-order network autocorrelation model Table 4.4 displays the results of a Bayesian estimation of the second-order model in (4.4), along with the corresponding maximum likelihood estimates.14The Bayesian and the maximum likelihood estimates of all parameters are similar to each other, in line with the results from our simulation study in Section 4.5.2. In particular, the (Bayesian) esti- mate of\u001a1, re ecting interactions within the same country, is of large positive magnitude (.350), while the (Bayesian) estimate of \u001a2, re ecting spillovers from regions in neighbor- ing countries, is much smaller and close to zero (-.058). Dall'erba et al. (2009) concluded by saying that \\the results obtained also con rm the hypothesis that economic interac- tions decrease very substantially when a national border is passed (indeed, the coe\u000ecient re ecting external spillovers is not et 2009, model UsingBayesfactors, wequanti edtheevidenceinthedatafortwohypothesesrepresenting the notion of decreasing economic interactions once a national border is passed, H1:\u001a1> \u001a2= 0 and H2:\u001a1> \u001a2>0, and tested them against two competing hypotheses, H0:\u001a1=\u001a2= 0 and H3:\u001a1=\u001a2>0.15Furthermore, we also included a hypothesis Hc::(H0_H1_H2_H3)inourtestthatconsistsofthecomplementofallotherpossible hypotheses on ( \u001a1;\u001a2) except hypotheses H0;H1;H2, andH3, i.e., which contains all the orders of network e ects we did not hypothesize. Table 4.5 provides the Bayes factors for every pair out of the set of the ve considered hypotheses above using the prior speci cations from Sections 4.4.2 and 4.4.3. Notably, 14As in our simulation study in Section 4.5, we used the prior p\u0000 \u001a1;\u001a2;\u001b2; \u0001 /N(02;100\u0002I2)\u00021=\u001b2 and relied on the lnam() function from the sna package in R to compute the maximum likelihood estimates and the corresponding con dence intervals. 15We considered the hypothesis H2:\u001a1> \u001a2>0 rather than a hypothesis H20:\u001a1> \u001a2here, as the hypotheses H1andH20would not be unambiguous. This does not mean that hypothesis H20in itself cannot be tested against other hypotheses, only the combination of hypotheses in a given test has to be considered carefully.4.6. Application revisited 103 Table 4.4 Posterior median and maximum likelihood estimates and associated 95% Bayesian credible and con dence intervals (in brackets) for the data in Dall'erba et al. (2009) and model (4.4). Parameter andHc::(H0_H1_H2_H3) for the data in Dall'erba et al. (2009) and model (4.4). Hypothesis H0 H1 \u001a2= 0 is the hypothesis most supported by the data and approximately 5:283\u0002106, 160.746, 3 :117\u0002105, and 14.085 times more supported than hypothesis H0, H2,H3, andHc, respectively. Moreover, there is the least evidence for the null in the data. Consequently, regardless the speci cation of alternative expectations about \u001a1and \u001a2, the hypothesis that both network e ects are zero has to be strongly rejected. Although these implications seem in line with the authors' claim that network e ects are decreasing aftera national border ispassed, usingBayesfactorsprovidesuswithmuchmore extensive conclusions about the characteristic evidence in the data. Hence, we can now quantify how much more likely these conclusions are than competing conclusions (hypotheses) and how (un)likely it is that an entirely di erent mechanism Hcgenerated the data. Ultimately, in this data set there is the most and very strong evidence for a positive within-country network e ect only. 4.6.3 Bayesian hypothesis testing in a fourth-order network autocorre- lation model Dall'erba et al. (2009) also pointed out potentially asymmetric growth rates across the regions, depending on the initial productivity level of a region. Thus, the authors pro-104 Chapter 4. Bayesian analysis of higher-order network autocorrelation models Lower productivity Higher productivity Figure 4.6 Spatial distribution of productivity levels in 1980 across the 188 regions. ceeded by dividing the sample into two clusters; 111 initially more productive regions and 77 initially less productive regions, implying a core-periphery pattern, see Figure 4.6.16 Next, they separately estimated two second-order network autocorrelation models for the two clusters. Here, for illustrative purposes, we allow for varying levels of network auto- correlation within and between the two clusters and consider a model with two subgroups instead. For example, we could expect the network e ects among regions of the same sub- group to be larger than the network e ects between regions of di erent subgroups, or we could expect the initially more productive regions to in uence the initially less productive ones more strongly than the other way around. Our previous analyses in Section 4.6.2 suggested that there is very strong evidence for a positive within-country network e ect only, i.e., \u001a1>0 and\u001a2= 0. Thus, we merely 16We created the map of the European NUTS-2 regions by using Eurostat data from http://ec.europa .eu/eurostat/cache/GISCO/geodatafiles/NUTS 201060MSH.zip, leNUTSRG60M2010.shp , and the readOGR()functionfromthergdalpackageinR(Bivandetal.,2017). original 188 regions, as the Trentino-Alto Adige region in Italy has been divided into two NUTS-2 regions.4.6. Application revisited 105 consider spillover e ects within the same country, in other words, we assume that only W1 plays a role, not W2. We denote by \u001ahh;\u001ahl;\u001alh, and\u001allthe network e ect within regions with initially higher productivity levels, the network e ect of the initially less productive regions on the initially more productive regions, the network e ect of the initially more productive regions on the initially less productive ones, and the network e ect within regions with initially lower productivity levels, respectively. Accordingly, yh2R111and yl2R77contain the growth rates of labor productivity of the initially more and the ini- tiallylessproductiveregions, respectively, andwepartitioned W1, theunstandardizedcon- nectivity matrix using the three nearest neighbors of a region within the same state, into the four submatrices Whh2R111\u0002111,Whl2R111\u000277,Wlh2R77\u0002111, andWll2R77\u000277, representing ties within and between the two subgroups.17This resulted in the following expect the network e ects within the two subgroups to be larger than the network e ects between subgroups, i.e., f\u001ahh;\u001allg>f\u001ahl;\u001alhg, where the \\ >\" sign holds pairwise for any two elements of the rst and second set, respectively. Further- more, hypotheses of substantial interest might be based on expectations of positive net- work e ects within both subgroups but with potentially di ering magnitudes. We trans- lated these f\u001ahh=\u001all>0g^ff\u001ahh;\u001allg>f\u001ahl;\u001alhgg, andH3:f0< \u001ahh< \u001allg^ff\u001ahh;\u001allg>f\u001ahl;\u001alhgg.18 We supplemented these three the hypothesis of no network e ects, H0: \u001ahh=\u001ahl=\u001alh=\u001all= 0, and the complement of all the orders of network e ects we did not have hypotheses for, Hc::(H0_H1_H2_H3). Table 4.6 shows the Bayes factors for every pair out of the set of the ve considered hy- potheses. As can be seen, H2:f\u001ahh=\u001all>0g^ff\u001ahh;\u001allg>f\u001ahl;\u001alhggis the hypothesis that is most supported by the data and receives approximately 3 :149\u0002105, 3.222, 3.704, and 55.556 more support than hypothesis H0,H1,H3, andHc, respectively. Hence, there is no evidence in the data for di ering network e ects within the initially more and the initially less productive regions, while there is very strong evidence for the network e ects within the two subgroups to be larger than the network e ects between the subgroups. 17We row-standardized Whh,Whl,Wlh, andWllseparately. 18Another hypothesis of interest could be that (with respect to the growth of labor productivity) the initially more productive regions in uence the initially less productive ones stronger than the other way around, i.e., \u001alh> \u001ahl. We did not include this hypothesis, as it would overlap with the other considered hypotheses and because of the undesirable behavior of such overlapping-hypotheses Bayes factors (Morey & Rouder, 2011). Separate analyses showed, however, that there is actually no evidence for a hypothesis involving \u001alh> \u001ahl.106 Chapter 4. Bayesian analysis of higher-order network autocorrelation models Table 4.6 model (4.17). Hypothesis Hc 5:563\u0002103.058 .018 .067 - 4.7 Conclusions In this chapter, we developed Bayesian techniques for estimating and testing higher-order network autocorrelation models with multiple network autocorrelations. In particular, we provided default Bayes factors that enable researchers to test hypotheses with order constraints on the network e ects in a direct manner. Thus, the proposed methods allow researchers to simultaneously test any number of competing hypotheses on the relative strength of network e ects against each other and to quantify the amount of evidence in the data for any of these hypotheses. This has not yet been possible using the currently available statistical techniques in the literature on network autocorrelation models. We ran an extensive simulation study to evaluate the numerical behavior of the pre- sented Bayesian procedures for a number of di erent network speci cations, including varying network sizes and network overlap. First, we found that the Bayesian estimator based on a non-informative prior and the maximum likelihood estimator have comparable frequentist properties under most scenarios, except for smaller network sizes. For smaller network sizes, only the Bayesian estimator exhibits accurate coverage of credible intervals and overall shows slightly superior performance. Second, we observed that the introduced Bayes factors always result in the largest evidence for a true data-generating hypothe- sis, with this evidence increasing with the network size. Furthermore, we also provided e\u000ecient algorithms for sampling from the posterior distributions and for computing the Bayes factors. We illustrated the practical utility of the Bayes factors by applying them to a data set on economic growth in 188 European regions. This resulted in additional and more precise insights into how the various network e ects are related to each other in comparison to classical null hypothesis signi cance testing. Given the many, often implicit, expectations researchers have about the relative im- portance of di erent network e ects, we hope that by enabling researchers to test these ex- pectations directly and explicitly, higher-order network autocorrelation models will bring for a more thorough understanding of social contagion processes that goes beyond the current state of the art. Acknowledgment We thank Sandy Dall'erba, Marco Percoco, and Gianfranco Piras sampling 107 Appendix 4.A Posterior sampling We outlined the procedure for sampling from the full posterior p\u0000 \u001a;\u001b2; jy\u0001 for higher- order network autocorrelation models in Section 4.3.2. However, it remains to spec- ify the exact form of the candidate-generating distribution for the conditional posterior p\u0010 \u001a; 1j\u001b2;e the (4.12). Approximating the conditional posterior for (\u001a; 1) In the following, we show how to approximate p\u0010 \u001a; 1j\u001b2;e ;y\u0011 by a (R+1)-variate nor- mal distribution. by Jacobi's formula (see e.g., Hall, 2003, Theorem 2.11), for any complex matrix Xit holds that det(exp( X)) =jexp(X)j= exp(tr( X)). As we set the R-dimensional parameter space of \u001aas the space containing the origin for which A\u001ais non-singular, we know that jA\u001aj>0,A\u001ais invertible, and that log( A\u001a) exists (see e.g., Higham, 2008, Theorem 1.27). Thus, Mercator series for the matrix logarithm (see e.g., Hall, 2003, Theorem 2.7), we can rewrite (4.18) as sum terms in (4.19) are given m= a quadratic polynomial in \u001aas108 Chapter 4. in (4.21) holds with respect to \u001a, in (4.22) with respect to (\u001a; 1),eXdenotes the matrix Xwith its rst column removed, e = ( 2;:::; k), and1g is the vector of ones of length g. By equating the coe\u000ecients of the product of (4.20), (4.21), i.e., the approximated conditional posterior for ( \u001a; 1), to the kernel of the probability density function of a multivariate normal distribution N(\u0016MH;\u0006MH), we obtain for de nite, \u0006\u00001 MH, and conse- quently \u0006 MH, may not be positive de nite either. In this case, we consider the nearest positive de nite matrix to \u0006\u00001 MHas \u0006\u00001 MHinstead. Subsequently, we use qMH(\u001a; 1) as candidate-generating density in the Metropolis-Hastings algorithm.4.A. Posterior sampling 109 Sampling from the conditional posterior for e The (k\u00001)-variate normal conditional posterior for e in (4.12) can be directly sampled from, with its mean vector and covariance matrix given by \u0016e =\u0016 2+\u0006 posterior p\u0000 \u001a;\u001b2; jy\u0001 in higher-order network autocorrelation models starting values\u0000 \u001a0; 0 1\u0001 ;\u0000 \u001b2\u00010, ande 0, e.g., to their maximum likelihood esti- mates, and the number of draws N. (2) Repeat steps (3) - (5) for i=1:N. (3) Perform a Metropolis-Hastings step for ( \u001a; 1) with the target \u001a; the candidate-generating density covariance matrix \u0006 e as in (4.23), (4.24).110 Appendix 4.B Bayes factor computation In following, we show how the integral It=R \u0002\u001atht(\u001at)d\u001atin (4.16) can be e ectively approximated suitable importance density qt(\u0001). We specify qt(\u0001) such that it closely follows the integrand ht(\u001at) but has heavier tails than the latter, which ensures a reliable estimation of It. As in Appendix 4.A, we approximate log\u0000 jA\u001atj\u0001 by a quadratic polynomial in \u001at at its maximum value, the origin. This results in a normal approximation of the case thatTis not positive de nite, we use the nearest positive de nite matrix to Tin- stead. The second term in the denominator of (4.25) already equals the kernel of the probability density function of the normal distribution N(\u0016t;\u0006t). Lastly, we also ap- proximate the logarithm of the third term in ht(\u001at) by a second-order Taylor poly- nomial at its by a product of three multivariate normal densities that is multivariate under ow in R, which is why we show how to compute its logarithm only, next. We can write log\u0010 \u001aiMA\u001aiy\u0011 , which is added to prevent the marginal likelihood to become too small to be distinguished from zero in R. The auxiliary constant dis set in advance after generating the Ndraws from the unconstrained importance density N\u0000 \u0016ISt;\u0006ISt\u0001 rst.113 Chapter 5 A discrete exponential family model for network autocorrelated count data Abstract We introduce a discrete exponential family model for analyzing network autocorrelated count data. In our approach, we model the joint distribution for the counts using a dis- crete exponential family speci ed in terms of su\u000ecient statistics of a count con guration. We propose several su\u000ecient statistics representing key structural properties of a count con guration, such as lower-order moments, zero in ation, and network autocorrelation. As such, the approach does not rely on any distributional assumptions on the marginal or conditional counts and is exible enough to model a wide range of count patterns. We provide algorithms to simulate count con gurations from the model and to perform max- imum likelihood-based inference, along with goodness-of- t measures assessing the model t to observed data based on simulated count con gurations. Finally, we illustrate our model by re-analyzing the sources of reported homicide counts in 343 neighborhoods in Chicago, Illinois. This chapter will be submitted for publication as: Dittrich, D., Butts, C.T., Leenders, R.Th.A.J., and Mulder, J. discrete exponential family model for network autocorrelated count data.114 Chapter 5. Network autocorrelated count data modeling 5.1 Introduction Individual behavior, corporate decisions, or entries intro armed con ict do not happen in vacuum. Instead, individuals, rms, and countries interact and thereby in uence as well as are in uenced by each other. Out of the numerous models that address e ects of such social interaction on a variable of interest, the network autocorrelation model (Ord, 1975) has been the agship model for incorporating global network autocorrelation in cross- sectional data. It is also known as spatial e ects model (Doreian, 1980), network e ects model (Dow et al., 1982), mixed regressive-spatial autoregressive model (Anselin, 1988), or spatial lag model (Anselin, 2002), and has been widely applied in a variety of elds, such as criminology (Tita & Radil, 2011), ecology (McPherson & Nieswiadomy, 2005), economics (Conway et al., 2010), geography (Dall'erba, 2005), and sociology (Mizruchi & Stearns, 2006). For the moment, assume that we observed values for a variable of interest for gactors in a network, who may be tied to each other based on a given in uence mechanism, e.g., friendship. The network autocorrelation model expands a standard linear regression model and accommodates potential network autocorrelation , i.e., interdependence of the observations for the actors across the network, by including an additional endogenous covariate. For each actor in the network, the additional covariate consists of a weighted sum of the values for the variable of interest for this actor's neighbors, i.e., other actors in the network this actor is tied to. The associated regression coe\u000ecient is known as the network autocorrelation parameter \u001a. Thus, the network autocorrelation +\" (5.1) ,y= (Ig\u0000\u001aW)\u00001(X +\"); (5.2) wherey2Rgcontains the values for a dependent variable of interest for the gactors, X2Rg\u0002kcomprises values for the gactors on kcovariates, 2Rkis a vector of regression coe\u000ecients, \"2Rgis a vector of error terms, Ig2Rg\u0002gdenotes the identity matrix, and W2Rg\u0002gis an a priori de ned connectivity matrix , specifying the in uence relationships between the actors; the larger the entry Wij, the larger the in uence of actor jon actor i, where we exclude relationships from an actor to himself, i.e., Wii= 0 for all i2 f1;:::;gg. The scalar network autocorrelation parameter \u001aquanti es the magnitude of the network autocorrelation on the variable of interest in the network de ned by W. Under regularity conditions, the matrix inverse in the reduced form of the model in (5.2) can be rewritten using the so-called \\Leontief expansion\" as ( Ig\u0000\u001aW)\u00001=Ig+\u001aW+\u001a2W2+:::(see e.g., Gri\u000eth, 1979). Consequently, in the network autocorrelation model, a change in one actor's covariate value does not only a ect this actor's neighbors' values for a variable of interest but potentially, depending on the structure of W, also those for all other actors in the network, with the impact on the variable of interest decreasing with the network distance from the actor. Such a spillover pattern is also called a globalspillover (Anselin, 2003; Elhorst, 2010; LeSage, 2014b).5.1. Introduction 115 Despite the usefulness of the network autocorrelation model, an important limitation of the model is that it cannot be directly applied to count data, which would, among other issues, lead to predicted non-integer and potentially negative values for a variable of interest. As a potential ad-hoc remedy, some authors suggested to transform the counts into an approximately normal variable and then t a network autocorrelation model to the transformed variable (LeSage & Pace, 2008; Quddus, 2008). Often though, count data cannot be appropriately transformed to become approximately normal, e.g., when model- ing rare counts such as violent crimes or the number of sexual partners; merely transform- ing counts is of limited applicability in such complex real-life settings and also does not substantially address the problem of how to adequately deal with network autocorrelated counts. Hence, any prudent model for network autocorrelated count data has to forfeit a direct functional relationship between the dependent variable of interest and the covariates while retaining the network autocorrelation model's global spillover pattern. To be sure, a number of models for dealing with count data building on global spillover patterns have been proposed in the literature. McMillen (1992) was the rst to provide an extension of the network autocorrelation model for binary data and LeSage (2000) further re ned the method to allow modeling of heteroskedastic data.1More recently, Lambert et al. (2010) and Glaser (2017) developed spatial autoregressive count models for Poisson and negative binomial data. In both approaches, the conditional expected count for each actor is modeled as a function of the actor's neighbors' counts and actor covariates. Castro et al. (2012) and Bhat et al. (2014) considered models that are characterized by the counts being driven by a Gaussian latent variable that is assumed to follow the network autocorrelation model in (5.1). Subsequently, in all of the four latter approaches the authors constructed a pseudo-likelihood function by multiplying suitable conditional probability mass functions and maximized the resulting product to obtain a maximum pseudo-likelihood estimate of the model parameters. However, these maximum pseudo-likelihood estimates ignore dependencies between the conditional probability mass functions and cannot adequately capture the dependence in the data when network autocorrelation is strong. Liesenfeld et al. (2016) presented a model for spatially correlated Poisson and negative binomial data similar to the ones in Castro et al. (2012) and Bhat et al. (2014) but additionally provided a numerically accurate, albeit computationally very expensive, algorithm for full maxi- mum likelihood estimation of their model. In contrast, Bhati (2008) took a rather di er- ent approach when modeling spatially correlated counts by introducing a semi-parametric estimator based on a generalized cross-entropy formulation. In this chapter, we propose a discrete exponential family model for network autocor- related count data that uni es several ideas from the literature. In our proposed model, we directly model the joint distribution for all actor counts using a discrete exponential family speci ed by its su\u000ecient statistics. These su\u000ecient statistics are speci ed such to represent structural properties of a joint count con guration and that are characteristic of underlying processes believed to have generated an observed count con guration. For 1Martinetti & Geniaux (2016), McMillen (2013), and Wilhelm & Godinho de Matos (2015) implemented estimation procedures for the probit network autocorrelation model in R, while LeSage (1999) did so in MATLAB.116 Chapter 5. Network autocorrelated count data modeling example, under network autocorrelation, we would expect neighboring actors to exhibit fairly similar counts, which would be accordingly captured by a su\u000ecient statistic embody- ing network autocorrelation. There are several advantages to using a discrete exponential family for the joint count distribution for the actors. First, our model naturally incorpo- rates global spillover patterns across the network. Second, we do not (have to) make any restrictive and potentially limiting distributional assumptions on the conditional counts. Third, by choosing appropriate su\u000ecient statistics, our model is exible enough to ac- commodate highly skewed raw count distributions as well as count con gurations exhibit- ing excess zeros, making it particularly appealing when analyzing rare counts or events. Fourth, we are able to easily simulate joint count con gurations from the model and to compute accurate simulation-based maximum likelihood estimates, providing the basis for inference in the model. Hence, our model permits for principled inference in the presence of both strong network autocorrelation and complex real-life data structures going well beyond standard Poisson and negative binomial speci cations. We proceed as follows. In the next section, we motivate and describe our discrete expo- nential family model for network autocorrelated count data. In Section 5.3, we introduce several su\u000ecient statistics representing a range of structural count properties and show how to interpret them. In Section 5.4, we present simulation and maximum likelihood estimation procedures for the model as well as useful measures for assessing model t to observed data. We apply our model to re-analyze the drivers of homicide counts registered in 343 neighborhoods in Chicago, Illinois, in Section 5.5. We conclude this chapter with a short discussion of our main ndings and highlight directions for fruitful future research within our proposed framework in Section 5.6. 5.2 Model de nition Let us consider gactors and an associated g-variate random count variable of interest Y that can take values in f0;:::;m\u00001gg. We denote this set of attainable count con gura- tions by Y:=f0;:::;m\u00001ggand de ne an attainable count as an integer between 0 and m\u00001. Here, the upper bound m\u00001 for the maximum count each actor can have needs to be chosen in advance, such that the set of attainable count con gurations is large enough to contain all likely count con gurations. Under this general framework, we are interested in modeling a joint actor count con- guration while accounting for exogenous and endogenous mechanisms that have suppos- edly generated the count con guration. For this, we use a discrete exponential family that speci es the joint distribution for the counts precisely in terms of these potentially count-generating mechanisms. In the literature, the discrete exponential family has been extensively employed, e.g., to model various forms of relational data through exponential random graph models (Holland & Leinhardt, 1981; Krivitsky, 2012; Krivitsky probabilistic graphical models (Lauritzen, 1996), or to control the ar- rangement of \\objects\" into \\locations\" in generalized location systems (Butts, 2007). As we can reformulate the modeling task in this chapter as assigning actors to attainable5.3. Model speci cation and interpretation 117 counts, our approach is closely related to the one in generalized location systems and we will repeatedly draw parallels between the two. Using notation similar to that of Butts (2007) and Hummel et al. (2012), we de ne the probability of the random count variable Yoccupying a particular count con guration y as p(Y=yj\u0012) su\u000ecient statistics, and \u0014(\u0012) :=P y02Yexp\u0000 \u0012Tt(y0)\u0001 denotes a normalizing constant, which ensures that the probabilities of all attainable count con gurations in (5.3) sum to unity. The speci cation in (5.3) is a fairly general one, where the su\u000ecient statistics can be seen as summary measures of structural properties of a joint count con guration. In practice, the su\u000ecient statistics are chosen such to represent mechanisms that are hypothesized to have generated and can explain an observed count con guration, e.g., why some actors have zero counts, whyothersexhibithighcounts, orwhycertainactorcountstendtocluster. Theparameter \u0012ithen weights the relative importance of the corresponding su\u000ecient statistic ti(y). 5.3 Model speci cation and interpretation In this section, we rst motivate the choice for speci c su\u000ecient statistics embodying a variety of common structural properties of a count con guration that govern the count distribution, before we show how to properly interpret the corresponding model parame- ters. 5.3.1 Speci cation of su\u000ecient statistics Network autocorrelation We include network autocorrelation to our model by proposing a su\u000ecient statistic, orig- inally introduced slightly di erently in Butts (2007), that captures the tendency of con- nected actors to show similar (or di erent) counts. Let W2Rr\u0002g\u0002gbe an array of ra pri- ori de ned connectivity matrices specifying the in uence relationships between the actors, whereWijkamounts to the in uence of actor kon actor jbased on in uence mechanism i. Moreover, let R2Rm\u0002rbe a matrix containing values for the mattainable counts onrcount attributes, i.e., values that are functions of the counts. For example, Rcould simply contain the attainable counts (0 ;:::;m\u00001) in each of its rcolumns. Alternatively, when trying to account for the shape of the raw count distribution, Rcould also contain a reference count distribution's percentiles. We set the elements of the vector of statistics tNAC(y) data modeling whereyjis the count for actor jandRyjiis the value for this count's i-th attribute. We denotethecorrespondingparametervectorby a positive parameter value topositive networkautocorrelation.2In order toillustrate the behavior of the su\u000ecient statistics in (5.4), consider a network of urban neighborhoods equipped with a single binary adjacency matrix W, i.e.,Wjk= 1 if neighborhood j andkare adjacent and zero otherwise, and R= (0;:::;m\u00001). In this case, similar counts between adjacent neighborhoods result in relatively larger (less negative) values for the (scalar) su\u000ecient statistic, which would imply positive network autocorrelation across the neighborhood network. Equivalently, more divergent counts between adjacent neighborhoods would lead to smaller (more negative) values for the su\u000ecient statistic and reveal negative network autocorrelation. Accordingly, the magnitude of \u001aindicates the importance of network autocorrelation as underlying mechanism in explaining an observed count con guration. Lastly, the speci cation in (5.4) can include several connectivity matrices, e.g., basedongeographicadjacencyandsocialsimilaritybetweenneighborhoods, resulting in multiple network autocorrelations and adding to the model's exibility. Covariate modeling In addition to network autocorrelation, our model also needs to incorporate count homo- or heterogeneity based on exogenous actor attributes. We model such e ects by su\u000ecient statistics that are based on products of actor and count attributes.3LetX2Rg\u0002qcontain values for the gactors on qactor attributes (possible including columns of ones) and let Q2Rm\u0002qcarry values for the mattainable counts on qcount attributes. We de ne the elements of the vector of su\u000ecient statistics tCHG(y) f1;:::;qg; we denote the corresponding parameter vector by 2Rq. For example, consider again a network of urban neighborhoods with Q\u0001i0= (0;:::;m\u00001), where Q\u0001i0denotes the i0-th column of Q, and let X\u0001i0comprise values for a resource deprivation index of the neighborhoods. Then, ceteris paribus, i0>0 implies that more resource deprived neigh- borhoods are more likely to exhibit higher counts for a variable of interest, e.g., homicide counts, and less resource deprived ones are accordingly less likely so. If one or several columns of Xdo not vary across actors but are constant, i.e., equal to a vector of ones, the su\u000ecient statistics in (5.5) can also be used to capture basic en- dogenous forces that gave rise to an observed count con guration. These basic endoge- nous forces can be seen as control variables that govern the baseline shape of the count 2Thesu\u000ecientstatisticsin(5.4)alsobearresemblancetoGeary's c(Geary,1954), awell-knownmeasure of spatial autocorrelation, and more remotely to a su\u000ecient statistic in Krivitsky (2012) that models mutuality in directed valued exponential random graph models. 3Since the probability mass function in (5.3) is invariant up to additive constants, any su\u000ecient statistic that is invariant over Y, e.g., solely based on actor attributes such as age, gender, etc., can be left out (Butts, 2007). Instead, all relevant su\u000ecient statistics need to link actor and count attributes.5.3. Model speci cation and interpretation 119 distribution notwithstanding other, more substantive, e ects based on network autocor- relation or exogenous actor attributes, which may not always be available. We show how to attain some control over basic properties of the count con guration, such as the mean, the variance, and the sparsity of the counts, next. First, we can perfectly model the mean count of a count con guration by setting a column of Qto (0;:::;m\u00001), leading to a su\u000ecient statistic that is the sum of the actor counts, tAVG(y) :=Pg j=1yj. Second, we can reach partial control over the variance of the counts by taking a column of Qto be (0a;:::;(m\u00001)a);a6= 1, resulting in a su\u000ecient statistic of the form tVAR(y) =Pg j=1ya j. We have found experimentally that choosing a= 2 typically appropriately controls the variance of the counts. Third, we can capture count sparsity, i.e., the tendency of count con gurations to have excess zeros, by specifying a column of Qas the binary vector (1;0;:::;0). This produces a su\u000ecient statistic tZIF(y) :=Pg j=1 1(yj= 0), which simply equals the number of zero counts in a count con guration. Taken together, the su\u000ecient statistics in (5.4) and (5.5) can be substituted into (5.3) to fully determine the probability of observing a count con guration y, parameters In contrast to the standard network autocorrelation model, a parameter \u0012iin the discrete exponentialfamilymodelin(5.6)cannotbeinterpretedasthee ectthataone-unitchange in an actor attribute has on the expected actor counts in the network. Instead, the most direct way to interpret parameters in the model is in terms of the probability ratio of two count con gurations y;y02 Y. the associated su\u000ecient statistic.4While (5.7) gives a clear quantitative interpretation of the model parameters in terms of relative 4As the normalizing constant \u0014(\u0012) implicitly depends on X, the probability ratio in (5.7) involving a change in Xwould depend on the ratio of the corresponding intractable normalizing constants and \u0012i could not be interpreted in the same way.120 Chapter 5. Network autocorrelated count data modeling count con guration probabilities and changes in the su\u000ecient statistics, the changes in the su\u000ecient statistics are ultimately a result of changes in the counts themselves. Thus, it is more intuitive and insightful to consider the e ect that a model parameter has on the probability ratio in (5.7) based on increments, or reductions, in the counts. Let y2 Ybe a count con guration in which actor jhas count k. Using (5.7) and conditional on the counts for the remaining actors, we can express the conditional log-odds of actor jhaving an attainable count linstead other than element j. 5.4 Model inference 5.4.1 Simulation In order to perform maximum likelihood-based inference in the model, it is essential to be able to simulate count con gurations from the model given a particular param- eter value \u0012. Opposed to the standard network autocorrelation model, it is not pos- sible to simulate count con gurations from the model directly; however, count con g- urations can be straightforwardly simulated using the Metropolis algorithm (Metropolis et al., 1953). In the Metropolis algorithm, starting from an initial count con guration y02 Y, a candidate count con guration ^y2 Yfor the target distribution p(Yj\u0012) is proposed, rst. Next, the candidate count con guration ^yis accepted with probability := min\u0000 1;p(Y=^yj\u0012)=p\u0000 Y=y0j\u0012\u0001\u0001 the candidate count con guration is accepted, ^ybecomes the next element in the sequence of simulated count con gurations, i.e., y1=^y, elsey1=y0. This so-called Metropolis step is repeated a large number of times until the desired number of draws of count con gurations has been obtained. These draws can then be, possibly after an appropriate number of initial draws, regarded as realizations from the target distribution p(Yj\u0012) itself. Following similar simulation procedures for related discrete exponential family models (Butts, 2007; Snijders, 2002), we form a candidate count con guration ^y2 Y, given count con guration y2 Y, by assigning one randomly chosen actor ja random attainable count k, i.e., ^yj=k;^y\u0000j=y\u0000j. In each Metropolis step, the corresponding acceptance prob- ability can then be easily calculated using (5.8). However, as the described Metropolis algorithm often starts with a random count con guration and at most one actor's count is changed in each step of the algorithm, the rst simulated count con gurations are typically highly dependent on the initial count con guration and not representative of the target distribution p(Yj\u0012). Thus, an initial number of draws, known as the burn-in(Gelman et5.4. Model inference 121 al., 2003), is usually discarded.5Moreover, the sequence of simulated count con gurations may be sub-sampled, or thinned, i.e., every k\u00001 out of kdraws may be discarded, due to limitations in computer memory and storage, or due to intending to reduce the auto- correlation in the draws, e.g., when aiming to obtain (nearly) independent realizations. In general though, thinning does not improve statistical e\u000eciency (Geyer, 1992; Link & Eaton, 2012; A. B. Owen, 2017). 5.4.2 Estimation In this section, we present techniques for maximum (pseudo-)likelihood estimation of the model. While the availability of the full likelihood function in (5.3) readily per- mits likelihood-based inference in theory, the intractability of the normalizing constant \u0014(\u0012) makes direct evaluation or maximization of the likelihood function numerically in- feasible. One way to bypass this issue is to construct a pseudo-likelihood function de- ned as the product of the conditional likelihoods and to maximize this product to ob- tain the maximum pseudo-likelihood estimate of the model parameters. The maximum pseudo-likelihood estimator, however, is only identical to the maximum likelihood esti- mator in case of no network autocorrelation and has been shown to be generally inferior to the maximum likelihood estimator in structurally similar exponential random graph models (Desmarais & Cranmer, 2012b; Robins, Pattison, et al., 2007; van Duijn et al., 2009). Nevertheless, we rst establish the model's maximum pseudo-likelihood estima- tor, which will serve as an initial approximation to the maximum likelihood estimator. Subsequently, we describe a simulation-based stepping algorithm that, starting from the maximum pseudo-likelihood estimate, iteratively moves towards the maximum likelihood estimate. Maximum pseudo-likelihood estimation As explained in the previous paragraph, we rst need to specify the conditional likelihood for an actor given the counts for all other actors in the network. Following Butts (2007), the conditional likelihood for actor jis given di erences in the su\u000ecient statistics in (5.9) can be e\u000eciently evaluated using (5.8). Hence, the resulting pseudo-likelihood function equals ~p(Y=yj\u0012) :=gY j=1p\u0000 Yj=yjjY\u0000j=y\u0000j;\u0012\u0001 ; 5An informal but powerful empirical way to check for the algorithm's convergence is to inspect the trace plots of the su\u000ecient statistics of the simulated count con gurations. An overview on more formal convergence diagnostics can be found in Cowles & Carlin (1996).122 Chapter 5. Network autocorrelated count data modeling and the maximum pseudo-likelihood estimate ~\u0012is taken to be the maximizer of this function, which can be numerically obtained using standard optimization techniques such as Newton's method or trust region optimization (Nocedal & Wright, 2006). Maximum likelihood estimation Given that the maximum likelihood estimate ^\u0012exists, it is a well-known result that E^\u0012[t(Y)] =t\u0000 yobs\u0001 wheret\u0000 observed su\u000ecient statistics (Barndor -Nielsen, 1978). This results provides the theoretical justi cation for a heuristic approach for computing the maximum likelihood estimate in the model, which is based on simulating count con gurations given an initial parameter value and successive re nement of the initial value by comparing the simulated su\u000ecient statistics to the observed ones. For this, we rely on the stepping algorithm from Hummel et al. (2012) that has been origi- nally introduced for maximum likelihood estimation of exponential random graph models. In short, we set an arbitrary parameter value \u00120, consider the di erence between the log-likelihoods of the observed count con guration yobsgiven\u0012and\u00120, respectively, and subsequently maximize this di erence over \u0012. However, due to the appearance of the intractable normalizing constants \u0014(\u0012) and\u0014\u0000 \u00120\u0001 in the log-likelihood di erence, direct evaluation and maximization is impossible. Instead, we use an analytic law-of-large num- bers approximation provided tion in \u0012is \\close\" to \u00120(Geyer, 1992; Hummel et al., 2012). Worse, if the vector of observed su\u000ecient statistics t\u0000 yobs\u0001 is not contained in the convex hull of the vectors of simulated su\u000ecient statistics t\u0000 y1\u0001 ;:::;t(yn), the maximum likeli- not exist (Desmarais & Cranmer, 2012a; Hunter et al., 2012).6 Before describing a stepping that iteratively shifts \u00120closer to ^\u0012, the approx- imation in (5.10) itself can be improved by replacing it with a log-normal approximation (Hummel et al., 2012). This log-normal approximation is based on a normal approxima- tion of the vector of su\u000ecient statistics t(Y)\u0018N(m0;\u00060), where m0and \u00060are the mean vector and variance-covariance matrix of t(Y) given\u00120, respectively. Hence, in R (Handcock et al., 2017; Hunter et al., 2008) can be used to check whether a vector lies in the closure of the convex hull of a set of vectors.5.4. Model inference 123 where^m0and^\u00060are the sample estimators of m0and \u0006 0, yobs\u0001 \u0000^m0\u0001 . Thus, replacing (5.10) by (5.11) not only provides an improvement in terms of accuracy of the maximum likelihood estimate but also leads to a reduction in computation time, as it eliminates the need for a numerical optimization procedure. In the actual stepping algorithm, in each iteration tof the algorithm, the vector of observed su\u000ecient statistics t\u0000 yobs\u0001 is moved towards the sample mean of the su\u000ecient statistics t\u0000 two in the log-likelihood di erence in (5.11). Hummel et al. (2012) set a safety margin, 1.05, and chose the weight t2(0;1] in this convex combination adaptively as the largest value each iteration the di erence is maximized over \u0012. Once t= 1 for two consecutive iterations in the algorithm, the algorithm is terminated and the nal iterated maximum \u0012t+1is taken as the maximum likelihood estimate. The algorithm can be summarized in six steps as follows: (1) Settto zero and choose \u00120, e.g., as the maximum pseudo-likelihood estimate ~\u0012. (2) Simulate count con gurations y1;:::;yngiven\u0012t. (3) Compute the sample mean ^mtof the simulated su\u000ecient statistics, ^mt=n\u00001Pn i=1t\u0000 yi\u0001 . (4) tt\u0000 yobs\u0001 (for t >0), terminate and return the (approximate) maximum likelihood estimate ^\u0012=\u0012t+1. Else, set t=t+1 and return to step (2). After the maximum likelihood estimate ^\u0012has been obtained, we draw a nal sample of simulated count con gurations y1;:::;yngiven^\u0012to estimate the standard error of ^\u0012. The standard error consists of two components. First, the typical error resulting from uctuations in the maximum likelihood estimate's sampling distribution, and second, the error introduced by approximating the log-likelihood di erence in (5.11). Relying on standard asymptotic theory, the rst error component can be computed using the inverse of the model's Fisher information matrix I(\u0012), which itself can only be approximated by the variance-covariance matrix of the simulated count con gurations y1;:::;yngiven^\u0012,^\u0006t+1.8However, as is the case for exponential random graph models, it has not yet been shown that such asymptotic arguments can be legitimately employed for approximating the rst error component (Butts, 2007). Hummel et al. (2012) and Hunter 7More conservative, i.e., larger, values for the safety margin than 1.05 can be chosen if the iterated maximum \u0012tgets stuck, while values between 1 and 1.05 may lead to a faster convergence of the algorithm. 8More precisely, the approximate rst error component equals the square root of the diagonal of ^\u0006\u00001 t+1.124 Chapter 5. Network autocorrelated count data modeling & Handcock (2006) provided details on the computation of the second error component, which we experimentally found to be negligible in magnitude compared to the rst error component when drawing su\u000eciently large samples of count con gurations in step (2) of the above algorithm. Alternatively, approximate standard errors can also be obtained by running a parametric bootstrap procedure, i.e., by taking the standard deviation of max- imum likelihood estimates of repeatedly simulated count con gurations given ^\u0012, which naturally accommodates both error components but requires longer computation times. 5.4.3 Goodness-of- t Once the maximum likelihood estimate and its standard error are determined, it remains to assess how well the estimated model ts an observed count con guration. Traditional measures for assessing (relative) goodness-of- t such as the AIC (Akaike, 1974), the BIC (Schwarz, 1978), or chi-squared tests (Pearson, 1900) cannot be adequately used in our proposed model for one or several of the following reasons. First, the assumptions under- lying the derivation of all of these measures are violated here, as in general, the counts are not independent and identically distributed across the network. Second, network autocor- related data do not have a clear notion of sample size (Berger et al., 2014), which can lead to ambiguous conclusions depending on the de nition of e ective sample size adopted. Third, evaluating the model's likelihood function directly is infeasible and hinders practi- cal applicability of the AIC and the BIC. While several extensions of the above measures for correlated data exist, we instead turn to graphical goodness-of- t procedures based on the predictive count distribution that are straightforward to implement and interpret, and which provide a much richer picture of goodness-of- t than scalar summary measures. By construction of the stepping algorithm in Section 5.4.2, simulated su\u000ecient statis- tics given the maximum likelihood estimate will center around the observed su\u000ecient statistics. At the same time, some estimated models may still lead to simulated count con gurations that are vastly di erent from the observed count con guration and that typically exhibit a very high number of minimum and maximum attainable counts. This phenomenon is well-known in exponential random graph models and termed degeneracy (Handcock, 2003). In exponential random graph models, degeneracy problems largely stem from including certain su\u000ecient statistics such as triangleandk-starcounts (Krivit- sky, 2012) but we have not found that using any of the su\u000ecient statistics in Section 5.3.1 systematically results in degeneracy of our model. If the estimated model is deemed non-degenerate, su\u000ecient statistics that have not been added to the model are not guaranteed to be well-reproduced by the simulated count con gurations. However, if these unmodeled su\u000ecient statistics are recovered well, there is evidence that the modeled structural properties are the only ones necessary to adequately describe the count generating process (Robins, Snijders, et al., 2007). Else, this suggests re nements to the model, e.g., by including more parameters. In the following, we pro- pose two (sets of) su\u000ecient statistics for assessing model t that serve as independent goodness-of- t measures: the raw count distribution , andcount 2-stars .5.4. Model inference 125 Actor 1 Actor 2 Actor 3 Actor 4 Actor 5Count 1 Count 2 Figure 5.1 Hypothetical count con guration for ve actors (A) in a network, where dashed lines indicate ties between actors. Here, the neighbor count 2-stars are ( A1;A2) and (A3;A5). First, we would like our estimated model to properly capture the observed raw count distribution, irrespectively of the dependence of the counts. Accordingly, we denote the number of actors in a network having count the su\u000ecient statistic tC i(y) :=Pg j=1 1(yj=i);i2 f0;:::;m\u00001g. Second, we wish our model to appropriately reveal potential clustering tendencies in the counts. While the su\u000ecient statistics embodying network autocorrelation in (5.4) are designed to re ect such clustering tendencies for con- nected actors, we introduce a set of count 2-star su\u000ecient statistics that check if the model can reproduce various other forms of clustering in the data. We de ne a gen- eral count 2-star as a pair of actors that have the same count, adapting the de nition of ageneral event 2-star in exponential random graph models for a\u000eliation networks in Agneessens & Roose (2008). Since the total number of general count 2-stars in a count con guration is a function of the raw count distribution, modeling the number of general count 2-stars and the raw count distribution is equivalent though.9Instead, we consider more speci c count 2-stars that also take network properties and/or actor at- tributes into account. We de ne a neighbor count 2-star as a pair of tied actors, based on connectivity mechanism i, that have the same count. We set the associated su\u000e- cient statistic to the total number of neighbor count captures rather rigidly count clustering tendencies of tied actors and we have found that it only mildly correlates with the su\u000ecient statistic tNAC i(y) representing network autocorrela- tion.10Figure 5.1 visualizes neighbor count 2-stars for a simple hypothetical count and network con guration. Similarly, we can de ne attribute count 2-stars that include actor attributes and measure count clustering based on actor attributes, e.g., by counting the number of pairs of actors that not only have the same count but also the same covariate value. 9The total number of general count 2-stars in a count con guration :=Pm\u00001 i=0\u0000tC i(y) 2\u0001 . 10We ignored the ties in the de nition of t2\u0003W i(y), which could be easily modeled though by replacing 1(Wijk>0) withWijk.126 Chapter 5. Network autocorrelated count data modeling Figure 5.2 Spatial distribution of homicide counts for the years 1989 through 1991 across the 343 Chicago neighborhood clusters. 5.5 Application: Homicide in Chicago neighborhoods Inthissection,weillustrateourmodelbyreanalyzinghomicidedataforthecityofChicago, Illinois.11The data consist of aggregated homicide counts for the years 1989 through 1991 and socio-economic variables for 343 neighborhood clusters taken from the 1990 census. These neighborhood clusters are composed of the city's 865 census tracts that are geo- graphically adjacent and socially similar, resulting in fairly demographically-homogenous neighborhood clusters (Moreno et al., 2001). Figure 5.2 shows the spatial distribution of the homicide counts across the 343 neighborhoods, revealing that neighborhoods with similar homicide counts tend to cluster in space.12 Bhati(2008)employedageneralizedPoissonregressionmodelusingfoursocio-economic variables to explain the spatial patterns of homicide across the 343 neighborhoods. These were, rst, a neighborhood resource deprivation index (RDI); second, the residential sta- bility of a neighborhood (RST); third, young men aged 15 to 25 as a proportion of a neighborhood's total population (MEN); fourth, the logarithm of a neighborhood's pop- ulation (POP). As expected, all of these variables were found to be positively associated with homicide. In addition, Bhati (2008) considered more extended models that hinted at overdispersion, compared to a Poisson speci cation, and spatial autocorrelation in the counts. 11The data can be obtained from the Inter-university Consortium for Political and Social Research after submitting a data access proposal at http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies/4079 . 12The gure was copied from Bhati (2008) with kind permission from the author.5.5. Application: Homicide in Chicago neighborhoods 127 21012Normalized sufficient statistic RDIRSTMENPOPAVGVAR ZIFNAC Figure 5.3 Box plots of the normalized simulated su\u000ecient statistics for the Chicago homi- cide data set. The box plots show the median (thick black solid line), the interquartile range (black solid rectangle), as well as the 2.5-th and 97.5-th percentiles (short solid black lines). The thick grey lines show the normalized observed su\u000ecient statistics that are equal zero. We applied the proposed discrete exponential family model to explain the structural propertiesoftheChicagohomicidecountsasafunctionofexogenousandendogenousforces in the neighborhood network. We used the four socio-economic variables described above as actor attributes and accordingly speci ed su\u000ecient statistics of the form in (5.5), rep- resenting count heterogeneity based on actor attributes, where we took the corresponding elements of Qto be the attainable counts themselves.13Furthermore, we included three endogenous su\u000ecient statistics of the form in (5.5) to model the baseline shape of the count distribution: rst, the sum of all counts, controlling for the mean count (AVG); second, the sum of all squared counts, controlling for the variance of the counts (VAR); third, the number of zero counts, controlling for zero-in ation (ZIF). Lastly, we added a scalar su\u000ecient statistic of the form in (5.4) embodying network autocorrelation (NAC) to the model that is based on a binary spatial neighborhood adjacency matrix. We implemented our model and obtained the maximum likelihood estimate using the stepping algorithm in Section 5.4.2.14Subsequently, we simulated 25,000,000 count con- gurations given the maximum likelihood estimate and sub-sampled every 25,000-th draw to compute standard errors and assess goodness-of- t; Figure 5.3 depicts box plots of the corresponding normalized simulated su\u000ecient statistics, i.e., after subtracting the ob- served su\u000ecient statistics and dividing by the respective sample standard deviations. As is evident, their sample means closely follow the observed su\u000ecient statistics, which sug- gests that the stepping algorithm has indeed converged to the maximum likelihood esti- mate. Moreover, the simulated marginal predictive distributions for the homicide counts in Figure 5.4 do not indicate any degeneracy issues with our model speci cation. 13We set the attainable upper bound of the counts to twice the largest count value in the data, which is 33. Our results are also robust to larger values for the upper bound that lead to longer computation times though. 14We set the initial value \u00120to the maximum pseudo-likelihood estimate, the safety margin in the stepping algorithm to 10, and iteratively re ned \u00120until the stopping criterion was reached.128 Chapter 5. Network autocorrelated count data modeling NeighborhoodCount 10 20 30 40 50 60 70 80010203040 NeighborhoodCount 90 100 110 120 130 140 150 160 170010203040 NeighborhoodCount 180 190 200 210 220 230 240 250010203040 NeighborhoodCount 260 270 280 290 300 310 320 330 340010203040 Figure 5.4 Box plots of the simulated marginal homicide counts for the 343 Chicago neigh- borhoods. The box plots show the mode (thick black solid line), the interquartile range (black solid rectangle), as well as the 2.5-th and 97.5-th percentiles (short solid black line). The thick grey lines show the observed homicide counts.5.5. Application: Homicide in Chicago neighborhoods 129 Table 5.1 Maximum likelihood estimates and asymptotic as well as bootstrapped standard errors (SE) under the full model and under a reduced model that ignores network autocorre- lation for the Chicago homicide data set. Full model Reduced model Asymptotic Bootstrapped Asymptotic Bootstrapped Parameter Estimate SE reports the maximum likelihood estimates and their asymptotic standard errors. In addition, we computed bootstrapped standard errors based on the 1,000 drawn count con gurations given the maximum likelihood estimate, which are also included in Table 5.1. While the bootstrapped standard errors are consistently somewhat larger than their asymptotic counter parts, these di erences do not alter any of our substantive nd- ings. At the same time, this underlines that researchers should be cautious when interpret- ing asymptotic standard errors in the model and computer-intensive bootstrapped stan- dard errors are not available. In line with the results in Bhati (2008), the four covariates RDI, RST, MEN, and POP are also positively associated with higher levels of homicide in our model. The endogenous baseline terms are generally di\u000ecult to interpret but their negative coe\u000ecients suggest that the homicide counts are smaller, vary less, and exhibit fewer zeros than in typical count con gurations given a model that would ignore these baseline terms. Finally, the positive coe\u000ecient of the network autocorrelation parameter indicates that the spatial clustering in the homicide counts cannot be accounted for by socio-economic variability in the neighborhoods and the shape of the baseline count dis- tribution alone; instead, underlying network autocorrelation is central to explaining the non-random spatial homicide pattern in the data. We assessed the model t based on two independent goodness-of- t measures from Section 5.4.2, the raw count distribution and neighbor count-2 stars. Figure 5.5 (top row) shows the simulated sampling distribution of these quantities, along with the actual raw count distribution and the number of neighbor count 2-stars in the observed data. As can be seen, the model captures the raw count distribution very well, as is the case for the neighbor count 2-stars. Hence, the proposed model speci cation is able to reproduce a variety of distinct structural properties of the homicide counts besides the one explicitly modeled and can be said to adequately describe the count generating process. As the development of this model was primarily inspired by the desire to sensibly an- alyze network autocorrelated count data, we were particularly interested in understand- ing the e ect of network autocorrelation on structural properties of the homicide counts.130 Chapter 5. Network autocorrelated count data modeling Raw countFrequency 051015202530010203040506070 Neighbor Raw 2starsFrequency 80100120140160180050100150 Figure 5.5 Left panel: Box plots of the simulated raw count distribution under the full model (top row) and under a reduced model ignoring network autocorrelation (bottom) for the Chicago homicide data set. The box plots show the median (thick black solid line), the interquartile range (black solid rectangle), as well as the 2.5-th and 97.5-th percentiles (short solid black lines). The thick grey lines show the observed raw counts. Right panel: Histogram of the simulated number of neighbor count 2-stars under the full model (top) and under the reduced model (bottom). The thick grey lines show the observed number of neigh- bor count 2-stars. Therefore, we estimated a reduced model leaving out network autocorrelation and com- pared its inferences to those under the full model including network autocorrelation. The maximum likelihood estimates under the reduced model in Table 5.1 are overall qualita- tively similar to the ones under the full model, with the estimates of the four covariates being slightly in ated and the estimates of the baseline terms slightly de ated compared to the full model. Furthermore, Figure 5.5 (bottom row) shows that the reduced model preserves the raw count distribution, while it does not seem to accurately capture the number of neighbor count 2-stars, i.e., the number of adjacent neighborhoods that have the same count. In sum, these results provide further evidence that network autocorrela- tion is an essential mechanism underlying the spatial distribution of homicide in this data set.5.6. Conclusions 131 5.6 Conclusions In this chapter, we introduced a discrete exponential family model for analyzing network autocorrelated count data. In the model, we used a discrete exponential family to specify the joint count distribution, where we did not rely on any distributional assumptions on the marginal or conditional counts. We showed how to specify the joint distribution in terms of su\u000ecient statistics that capture a range of characteristic structural properties of a count con guration, such as network autocorrelation, the number of zero counts, or count homo- or heterogeneity through actor attributes variability. In addition, we pro- vided algorithms to simulate count con gurations from the model and to perform max- imum likelihood-based inference. We implemented and illustrated the usefulness of our model by analyzing the drivers of homicide across 343 neighborhoods in Chicago, Illinois, where we found that network autocorrelation was fundamental to understanding the spa- tial clustering of the homicide counts. The work in this chapter leaves room for several improvements and extensions of the model. First, we operationalized and modeled network autocorrelation through a statis- tic that is based on the sum of absolute di erences between counts, or generally count attributes, of tied actors. At the same time, this is only one possible way of capturing network autocorrelation in a count con guration, and it may well be that other formu- lations, e.g., along the lines of the introduced neighbor count 2-stars or building upon spatial association measures, are better suited in certain situations. It remains to system- atically analyze the capacity and power of di erent operationalizations and to formulate recommendations as to when to use which. Second, we relied upon a simple Metropolis algorithm to simulate count con gurations from the model that explores the space of at- tainable count con gurations rather slowly, in particular when the chosen upper bound for the counts is very high. Thus, developing adaptive algorithms that automatically nd \\good\" candidate count con gurations would be a valuable improvement of the model. Third, we implicitly used a discrete uniform base measure in the discrete exponential fam- ily that de nes the joint count distribution. Generalizing the model to include additional base measures, where the base measure represents the joint count distribution in absence of any other endogenous or exogenous forces, and thus allowing for even richer modeling is left for future work. Toconclude, wehopethatprovidingresearcherswitha exibleandinterpretablemodel foranalyzingnetworkautocorrelatedcountdataofmanifolddistributionalshapeswillcon- tribute to a better understanding of in uence patterns underlying many count processes.133 Chapter 6 Epilogue Inthisthesis,wedevelopedafullyBayesianframeworktomodelnetworkautocorrelationof avariableofinterestusingthenetworkautocorrelationmodel. Furthermore, weintroduced a discrete exponential family model for analyzing network autocorrelated count data for which the network autocorrelation model itself is not well-suited. In this nal chapter, we summarize our most important ndings, highlight the remaining limitations of our work, and outline future research directions for modeling network autocorrelation. 6.1 Bayesian analysis of the network autocorrelation model We have provided comprehensive Bayesian inference methods for the network autocorre- lation model in the rst three chapters of the body of the thesis. In Chapter 2, we focused on Bayesian estimation of a rst-order model and considered estimation of higher-order models in Chapter 4. Analogously, we presented Bayes factors for testing hypotheses on a single network autocorrelation parameter \u001ain a rst-order model in Chapter 3, which we then generalized to test equality and inequality constrained hypotheses on multiple net- work autocorrelation parameters in higher-order models in Chapter 4. For both Bayesian estimation of and hypothesis testing in the network autocorrelation model, the speci ca- tion of the prior for the network autocorrelation parameter(s) is a major challenge. Thus, we constructed several theoretically and empirically guided priors for the network auto- correlation parameter(s) and assessed the sensitivity of the performance of our methods to di erent prior choices. By means of an extensive simulation study, we found that the Bayesian estimators based on the two versions of the newly derived Je reys prior for the rst-order model do not perform substantially di erently than the maximum likelihood estimator with respect tobiasofthenetworkautocorrelationparameter; inparticular, relyingonthesepriorsdoes not lessen the severe negative bias in the estimation of \u001afor high levels of network density. At the same time, using Independence Je reys prior and the standard uniform prior for \u001aresults in accurate coverage of credible intervals for \u001aeven for high levels of network density and small network sizes, as opposed to the below-nominal coverage of maximum likelihood-based con dence intervals in such scenarios. We also observed that the Bayesian134 Chapter 6. Epilogue estimator based on the empirical informative prior for \u001adramatically decreases the bias in the estimation of \u001aif the expected network autocorrelation in a study is in line with previous empirical results on the magnitude of \u001a. Meanwhile, several authors (Bao, 2013; Z. Yang, 2015; Yu et al., 2015) have proposed di erent bias-corrected maximum likelihood estimation procedures that almost eliminate the bias in the estimation of \u001awhen network density is not excessively high, as is the case for most spatial networks. However, it re- mains to investigate if the good performance of these procedures also holds for very small and dense networks that are often encountered in social network research. Nevertheless, this stimulates the future development of similar bias-corrected Bayesian estimators in the network autocorrelation model. We did not pursue further the two versions of Je reys prior in higher-order models, as relying on these priors in a rst-order model merely marginally improves inferences compared to employing the uniform prior for \u001abut results in more complex posteriors and considerably longer computation times.1Moreover, higher-order models have not been ap- plied nearly as extensively in the literature as the rst-order model, and we saw little value in constructing an empirical reference prior for the network autocorrelation parameters here. Instead, we used a general multivariate normal prior for the network autocorrelation parameters in combination with standard non-informative priors for the remaining model parameters. Based on a non-informative and essentially uniform prior speci cation for the network autocorrelation parameters in a second-order model, we came to qualitatively same conclusions as in the rst-order model in terms of bias of the network autocorrela- tion parameters and coverage of the corresponding credible intervals. In addition, these conclusions are robust to modest overlap between two connectivity matrices. Apart from enabling researchers to include various amounts of prior knowledge about the model parameters to their analyses, our advocated Bayesian framework also permits researchers to simultaneously test multiple competing hypotheses on the network autocor- relation parameter(s), which allows for much richer and more nuanced insights compared to classical null hypothesis signi cance testing. First, we proposed several Bayes factors for the rst-order model that quantify the amount of relative evidence in the data for precise and interval hypotheses on \u001a. Similar as in Bayesian estimation, the amount of evidence for interval hypotheses, such as H1: 0< \u001a <1, is sensitive to the chosen prior for\u001athough. We conducted a large simulation study and found that Bayes factors based on the empirical informative prior and the uniform prior for \u001aprovide the largest evidence for a true data-generating hypothesis and show consistent behavior, i.e., the evidence for a true data-generating hypothesis is increasing with the network size. On the other hand, we also noticed that using a fractional Bayes factor based on an improper prior for \u001aresults in sub-optimal inferences and is therefore not recommended. Second, we presented Bayes factors based on automatically constructed multivariate normal priors for the network au- tocorrelation parameters for testing any number of equality and inequality constrained hy- potheses on them in higher-order models, such as H1:\u001a1> 0 and H2:\u001a1> \u001a2>0. 1The derivation of Je reys rule prior and Independence Je reys prior in higher-order network autocor- relation models is a straightforward exercise and analogous to the derivation in the rst-order model.6.2. Network autocorrelation modeling of count data 135 As in the rst-order model, the analyzed Bayes factors appear to be consistent but require somewhat larger network sizes to provide substantial evidence for a true-data generating hypothesis. At the same time, both in rst-order and higher-order models, the evidence for a true data-generating hypothesis is also decreasing with the network density, owing to the increasingly distorted (concentrated) likelihood function. Hence, future work on Bayesian bias-correction procedures would not only be of great value for reducing the negative bias in the estimation of the network autocorrelation parameter(s) but equally bene cial for improving inference about them using Bayes factors. All of our proposed methods in the network autocorrelation model rely on the as- sumption that the variable of interest is normally distributed and can be modeled assum- ing homogeneous statistical errors across the network. Needless to say, this assumption may often not be met in empirical practice and more research is needed to examine how robust our ndings are to violations of these underlying conjectures. While it may seem tempting to simply expand our methods to accommodate variables of interest following other continuous distributions, such as the beta, the gamma, or the log-normal, using gen- eralized linear models theory, such approaches would usually build upon pseudo-likelihood inference and may not appropriately capture complex dependencies in the data. Instead, a more promising approach could be based on generalizing the discrete exponential family model from Chapter 5 to continuous data, allowing for full likelihood-based inference and retaining distributional exibility.2 6.2 Network autocorrelation modeling of count data In Chapter 5, we made use of an entirely di erent formalism to model network autocor- related count data, the discrete exponential family. In contrast to most network auto- correlation count models currently available in the literature, relying on the discrete ex- ponential formalism allows for full likelihood-based inference, and we demonstrated how the formalism can be utilized to model network autocorrelated count data. In particular, we showed how to incorporate network autocorrelation and covariate e ects by de ning the joint count distribution as a discrete exponential family speci ed in terms of suitable su\u000ecient statistics representing these e ects. Hence, even though leaving the network autocorrelation model framework and taking a rather di erent modeling approach might make this thesis appear somewhat less consistent at rst sight, we believe this stride makes it in fact methodologically more sound upon second thought. One considerable strength of our proposed model is that no potentially restrictive dis- tributional assumptions on the marginal or conditional counts need to be made, but the model is able to handle a wide range of di erent count con gurations. On the other hand, we implicitly assumed a discrete uniform base measure in the discrete exponential family formulation of the joint count distribution. The choice of this base measure determines the joint count distribution net of any other e ects in the model and likewise, at least par- 2Interestingly, recent research on the network autocorrelation model has focused more on developing model extensions for non-continuous data such as ordinal data (Dow, 2008) and multinomial data (Y. Wang et al., 2014).136 Chapter 6. Epilogue tially, governs the shape of the marginal count distributions under a fully speci ed model that is, however, in general analytically unavailable. The derivation of other meaningful base measures, e.g., along the lines of Krivitsky (2012) and yielding Poisson-like marginal count distributions, is an important topic left for future research. This especially applies to a more general model with no a priori upper bound for the counts, where certain base measures, in combination with particular parameter con gurations, may lead to non- nite normalizing constants. Finally, we provided maximum likelihood-based inference methods for the model in Chapter 5 only, as opposed to proposing Bayesian inferential tools for the network au- tocorrelation model in Chapters 2, 3, and 4. Here, practical implementation of similar Bayesian tools is greatly hindered by the intractability of the normalizing constant in the model's likelihood, resulting in so-called doubly intractable posteriors (Murray et al., 2006) due to an additional parameter-dependent normalizing constant. For the future, adapting existing algorithms for Bayesian analyses of related exponential random graph models (Caimo & Friel, 2011) would be a valuable addition to the inferential toolbox for the model. 6.3 Concluding thoughts In addition to introducing new methodology, we devoted considerable e ort to developing e\u000ecient implementations of these methods, which we meticulously described throughout the thesis. While, in principle, this allows researchers to straightforwardly reconstruct our implementations in their familiar software environment and apply our methods in practice, we are aware that it is rather the wish being the father to the thought here; merely pro- viding verbal and symbolic guidance will hardly bridge the gap between presented theory and practical application. Thus, a major overarching goal for future research is to bundle our existing implementations in a freely available software package to help disseminate our methods within the network science community and facilitate obtaining more profound insights into the structure of network autocorrelation. An obvious thought that comes to mind is how these insights can be actually used to answer substantive research problems encountered in empirical practice. Admittedly, this raises questions that go beyond the scope of this thesis and primarily need to be addressed by applied network researchers and policy makers. To conclude, we nevertheless hope that the methods developed in this thesis can ultimately help policy makers in conducting targeted interventions taking into account the structure of network autocorrelation.137 References Agneessens, F., & Roose, H. (2008). Local Structural Properties and Attribute Charac- teristics in 2-mode Networks: p* Models to Map Choices of Theater Events. Journal of Mathematical Sociology ,32(3), 204-237. Akaike, H. (1974). A new look at the statistical model identi cation. IEEE Transactions on Automatic Control \u007fOgren, M. (2010). PropertyPricesandExposuretoMultiple Noise Sources: Hedonic Regression with Road and Railway Noise. Environmental and Resource Economics ,45(1), 73-89. Anselin, L. (1982). A Note on Small Sample Properties of Estimators in a First-Order Spatial Autoregressive Model. Environment and Planning A ,14(8), 1023-1030. Anselin, L. (1984). Speci cationtestsonthestructureofinteractioninspatialeconometric models. Papers of the Regional Science Association ,54(1), 165-182. Anselin, L. (1988). Spatial Econometrics: Dordrecht, The Nether- lands: Springer. Anselin, L. (1990). Some robust approaches to testing and estimation in spatial econo- metrics. Regional Science and Urban Economics ,20(2), 141-163. Anselin, L. (2002). Under the hood: Issues in the speci cation and interpretation of spatial regression models. Agricultural Economics ,27(3), 247-267. Anselin, L. (2003). Spatial Externalities, Spatial Multipliers, And Spatial Econometrics. International Regional Science Review ,26(2), 153-166. Anselin, L., & Le Gallo, J. (2006). Interpolation of Air Quality Measures in Hedonic House Price Models: Spatial Aspects. Spatial Economic Analysis ,1(1), 31-52. Anselin, L., & Lozano-Gracia, N. (2008). Errors in variables and spatial e ects in hedonic house price models of ambient air quality. Empirical Economics ,34(1), 5-34. Anselin, L., Lozano-Gracia, N., Deichmann, U., & Lall, S. (2010). Valuing Access to Water - A Spatial Hedonic Approach, with an Application to Bangalore, India. Spatial Economic Analysis ,5(2), 161-179. Anselin, L., Varga, A., & Acs, Z. (2000). Geographical and sectoral characteristics of academic knowledge externalities. Papers in Regional Science ,79(4), 435-443.138 References Arbia, G., & Basile, R. (2005). Spatial dependence and non-linearities in regional growth behaviour in Italy. Statistica ,65(2), 145-167. Armstrong, R. J., & Rodr\u0013 \u0010guez, D. A. (2006). An evaluation of the Accessibility Bene ts of Commuter Rail in Eastern Massachusetts using Spatial Hedonic Price Functions. Transportation ,33(1), 21-43. Atkinson, K. E. (1989). An Introduction to Numerical Analysis (Second ed.). New York, NY: John Wiley & Sons. Badinger, H., & Egger, P. (2011). Estimation of higher-order spatial autoregressive cross- section models with heteroscedastic disturbances. Papers in Regional Science ,90(1), 213-235. Baller, R. D., Anselin, L., Messner, S. F., Deane, G., & Hawkins, D. F. (2001). Structural Covariates of U.S. County Homicide Rates: Incorporating Spatial E ects. Criminology , 39(3), 561-588. Bao, Y. (2013). Finite Sample Bias of the QMLE in Spatial Autoregressive Models. Econometric Theory ,29(1), 68-88. Barndor -Nielsen, O. E. (1978). Information and Exponential Families in Statistical Theory. New York, NY: John Wiley & Sons. Barnett, N. P., Ott, M. Q., Rogers, M. L., Loxley, M., Linkletter, C., & Clark, M. A. (2014). Peer Associations for Substance Use and Exercise in a College Student Social Network. Health Psychology ,33(10), 1134-1142. Bartlett, M. S. (1957). A comment on D. V. Lindley's statistical paradox. Biometrika , 44(3-4), 533-534. Bates, D., & Maechler, M. (2017). Matrix: Sparse and Dense Matrix Classes and Methods [Computer software manual]. Retrieved from http://CRAN.R-project.org/package= Matrix (R package version 1.2-8) Beck, N., Gleditsch, K. S., & Beardsley, K. (2006). Space is More than Geography: Using Spatial Econometrics in the Study of Political Economy. International Studies Quarterly ,50(1), 27-44. Becker, R. A., Brownrigg, R., Deckmyn, A., Minka, T. P., & Wilks, A. R. (2016). maps: Draw Geographical Maps [Computer software manual]. Retrieved from http://CRAN.R -project.org/package=maps (R package version 3.1.1) Berger, J. O., Bayarri, M. J., & Pericchi, L. R. (2014). The E ective Sample Size. Econometric Reviews ,33(1-4), 197-217. Berger, J. O., Boukai, B., & Wang, Y. (1997). Uni ed Frequentist and Bayesian Testing of a Precise Hypothesis. Statistical Science ,12(3), 133-160.References 139 Berger, J.O., deOliveira, V.,&Sans\u0013 o, B. (2001). Objective BayesianAnalysisofSpatially CorrelatedData. Journal of the American Statistical Association ,96(456), 1361-1374. Berger, J. O., & Mortera, J. (1999). Default Bayes Factors for Nonnested Hypothesis Testing. Journal of the American Statistical Association ,94(446), 542-554. Berger, J. O., & Sellke, T. (1987). Testing a Point Null Hypothesis: The Irreconcilability of P Values and Evidence. Journal of the American Statistical Association ,82(397), 112-122. Bernardo, J. M. (1979). Reference Posterior Distributions for Bayesian Inference. Journal of the Royal Statistical Society. Series B (Statistical Methodology) ,41(2), 113-147. Bernat Jr., G. A. (1996). Does Manufacturing Matter? A Spatial Econometric View of Kaldor's Laws. Journal of Regional Science ,36(3), 463-477. Bhat, C. R., Paleti, R., & Singh, P. (2014). A Spatial Multivariate Count model for Firm Location Decisions. Journal of Regional Science ,54(3), 462-502. Bhati, A. S. (2008). A Generalized Cross-Entropy Approach Modeling Spatially Correlated Counts. Econometric Reviews the [Computer Retrieved from http://CRAN .R-project.org/package=rgdal (R package version 1.2-8) Bivand, R., & Piras, G. (2015). Comparing Implementations of Estimation Methods for Spatial Econometrics. Journal of Statistical Software ,63(18), 1-36. Bivand, R., & Szymanski, S. (2000). Modelling the spatial impact of the introduction of Compulsory Competitive Tendering. Regional Science and Urban Economics ,30(2), 203-219. Bolstad, W. M. (2009). Understanding Computational Bayesian York, NY: John Wiley & Sons. Bordignon, M., Cerniglia, F., & Revelli, F. (2003). In search of yardstick competition: a spatial analysis of Italian municipality property tax setting. Journal of Urban Eco- nomics,54(2), 199-217. Box, G. E., & Tiao, G. C. (1973). Bayesian Inference in Statistical Analysis . New York, NY: John Wiley & Sons. Braeken, J., Mulder, J., & Wood, S. (2015). Relative E ects at Work: Bayes Factors for Order Hypotheses. Journal of Management ,41(2), 544-573. Brooks, S. P. (1998). Markov chain Monte carlo method and its application. Journal of the Royal Statistical Society. Series D (The Statistician) ,47(1), 69-100.140 References Brueckner, J. K., & Saavedra, L. A. (2001). Do Local Governments Engage in Strategic Property-Tax Competition? National Tax Journal ,54(2), 203-229. Buonanno, P., Montolio, D., & Vanin, P. (2009). Does Social Capital Reduce Crime? Journal of Law and Economics ,52(1), 145-170. Burt, R. S., & Doreian, P. (1982). Testing a structural model of perception: Conformity and deviance with respect to Journal norms in elite sociological methodology. Quality and Quantity ,16(2), 109-150. Butts, C. T. (2007). Models for Generalized Location Systems. Sociological Methodology , 37(1), 283-348. Butts, C. T. (2008). Social Network Analysis with sna. Journal of Statistical Software , 24(6), 1-51. Caimo, A., & Friel, N. (2011). Bayesian for exponential random graph models. Social Networks ,33(1), 41-55. Can, A. (1992). Speci cation and estimation of hedonic housing price models. Regional Science and Urban Economics ,22(3), 453-474. Carlin, B. C., & Louis, T. A. (2000). Empirical Bayes: Past, Present and Future. Journal of the American Statistical Association ,95(452), 1286-1289. Carruthers, J. I., & Clark, D. E. (2010). Valuing Environmental Quality: A Space-based Strategy. Journal of Regional Science ,50(4), 801-832. Casella, G., Gir\u0013 on, F. J., Mart\u0013 \u0010nez, M. L., & Moreno, E. (2009). Consistency of Bayesian procedures for variable selection. The Annals of Statistics ,37(3), 1207-1228. Castro, M., Paleti, R.,&Bhat, C.R. (2012). Alatentvariablerepresentationofcountdata models to accommodate spatial and temporal dependence: Application to predicting crashfrequencyatintersections. Transportation Research Part B: Methodological ,46(1), 253-272. Chance, B. L., & Rossman, A. J. (2006). Investigating Statistical Concepts, Applications, and Methods . Belmont, CA: Duxbury Press. Chang, H. (2008). Spatial analysis of water quality trends in the Han River basin, South Korea.Water Research ,42(13), 3285-3304. Chib, S., & Greenberg, E. (1995). Understanding the Metropolis-Hastings Algorithm. The American Statistician ,49(4), 327-335. Cohen, J. P., & Coughlin, C. C. (2008). Spatial Hedonic Models of Airport Noise, Prox- imity, and Housing Prices. Journal of Regional Science ,48(5), 859-878. Conigliani, C., & O'Hagan, A. (2000). Sensitivity of the Fractional Bayes Factor to Prior Distributions. The Canadian Journal of Statistics ,28(2), 343-352.References 141 Conway, D., Li, C. Q., Wolch, J., Kahle, C., & Jerrett, M. (2010). A Spatial Autocorrela- tion Approach for Examining the E ects of Urban Greenspace on Residential Property Values.The Journal of Real Estate Finance and Economics ,41(2), 150-169. Cowles, M. K., & Carlin, B. P. (1996). Markov Chain Monte Carlo Convergence Diagnos- tics: A Comparative Review. Journal of the American Statistical Association ,91(434), 883-904. Cs\u0013 ardi, G., & Nepusz, T. (2006). The igraph software package for complex network research. InterJournal ,Complex Systems , 1695. Retrieved from http://igraph.org Dall'erba, S. (2005). Productivity convergence and spatial dependence among Spanish regions. Journal of Geographical Systems ,7(2), 207-227. Dall'erba, S., Percoco, M., & Piras, G. (2009). Service industry and cumulative growth in the regions of Europe. Entrepreneurship & Regional Development ,21(4), 333-349. Davis, G.F., Yoo, 301-326. DeGroot, M. H., & Schervish, M. J. (2010). Probability and Statistics (Fourth ed.). Boston, MA: Addison-Wesley. De Oliveira, V. (2010). Objective Bayesian Analysis for Gaussian Random Fields. In M.-H. Chen, P. M\u007f uller, D. Sun, K. Ye, & D. K. Dey (Eds.), Frontiers of Statistical Decision Making and Bayesian Analysis: In Honor of James O. Berger (p. 497-511). New York, NY: Springer. De Oliveira, V. (2012). Bayesian analysis of conditional autoregressive models. Annals of the Institute of Statistical Mathematics ,64(1), 107-133. De Oliveira, V., & Song, J. J. (2008). Bayesian Analysis of Simultaneous Autoregressive Models. Sankhya: The Indian Journal of Statistics, Series B (2008-) ,70(2), 323-350. Desmarais, B. A., Inference for Valued-Edge Net- works: and its Applications ,391(4), 1865- 1876. Ding, J., & Zhou, A. (2007). Eigenvalues of rank-one updated matrices with some T., & Mulder, J. (2017). Bayesian estimation of the network autocorrelation model. Social Networks ,48, 213-236. Dittrich, D., Leenders, R. T., & Mulder, J. (in press). Network Autocorrelation Model- ing: A Bayes Factor Approach for Testing (Multiple) Precise and Interval Hypotheses. Sociological Methods & Research .142 References Doreian, P. (1980). Linear Models with Spatially Distributed Data: Spatial Disturbances or Spatial E ects? Sociological Methods & Research ,9(1), 29-60. Doreian,P. (1981). EstimatingLinearModelswithSpatiallyDistributedData. Sociological Methodology ,12, 359-388. Dow, M. M. (2007). Galton's Problem as Multiple Network Autocorrelation E ects: Cultural Trait Transmission and Ecological Constraint. Cross-Cultural Research ,41(4), 336-363. Dow, M. M. (2008). Network Autocorrelation Regression With Binary and Ordinal De- pendent Variables. Cross-Cultural Research ,42(4), 394-419. Dow, M. M., White, D. R., & Burton, M. L. (1982). Multivariate Modeling with Interde- pendent Network Data. Cross-Cultural Research ,17(3-4), 216-245. Duke, J. B. (1993). Estimation of the Network E ects Model in a Large Data Set. Sociological Methods & Research ,21(4), 465-481. Easterly, W., & Levine, R. (1998). Troubles with the Neighbours: Africa's Problem, Africa's Opportunity. Journal of African Economies ,7(1), 120-142. Elhorst, J. P. (2010). Applied Spatial Econometrics: Raising the Bar. Spatial Economic Analysis,5(1), 9-28. Elhorst, J. P. (2014). Spatial Econometrics: From Cross-Sectional Data to Spatial Panels . Heidelberg, Germany: Springer. Elhorst, J. P., Lacombe, D. J., & Piras, (2012). On model speci cation and parameter Regional 211-220. Ertur, C., Le Gallo, J., & LeSage, J. P. (2007). Local versus Global Convergence in Europe: A Bayesian Spatial Econometric Approach. The Review of Regional Studies , 37(1), 82-108. Fern\u0013 andez, C., Ley, E., & Steel, M. F. (2001). Model uncertainty in cross-country growth regressions. Journal of Applied Econometrics ,16(5), 563-576. Fingleton, B. (2001). Theoretical economic geography and spatial econometrics: dynamic perspectives. Journal of Economic Geography ,1(2), 201-225. Fingleton, B., Igliori, D., & Moore, B. (2005). Cluster Dynamics: New Evidence and Projections for Computing Services in Great Britain. Journal of Regional Science , 45(2), 283-311. Fingleton, B., & Le Gallo, J. (2008). Estimating spatial models with endogenous variables, a spatial lag and spatially dependent disturbances: Finite sample properties. Papers in Regional Science ,87(3), 319-339.References 143 Florax, R. J., Voortman, R. L., & Brouwer, J. (2002). Spatial dimensions of precision agriculture: a spatial econometric analysis of millet yield on Sahelian coversands. Agri- cultural Economics ,27(3), 425-443. Ford, T. C., & Rork, J. C. (2010). Why buy what you can get for free? The e ect of foreign direct investment on state patent rates. Journal of Urban Economics ,68(1), 72-81. Fornango, R. J. (2010). When Space Matters: Spatial Dependence, Diagnostics, and Regression Models. Journal of Criminal Justice Education ,21(2), 117-135. Fu, F., Chen, X., Liu, L., & Wang, L. (2007). Social dilemmas in an online social network: The structure and evolution of cooperation. Physics Letters A ,371(1-2), 58-64. Fujimoto, K., Chou, C.-P., & Valente, T. The network autocorrelation model using two-mode data: A\u000eliation exposure and potential bias in the autocorrelation parameter. Social Networks ,33, 231-243. Geary, R. C. (1954). The Contiguity Ratio and Statistical Mapping. The Incorporated Statistician ,5(3), 115-145. Gelfand, A. E., & Smith, A. F. (1990). Sampling-Based Approaches to Calculating Marginal Densities. Journal of the American Statistical Association ,85(410), 398- 409. Gelman, A. (2006). Prior distributions for variance parameters in hierarchical models. Bayesian Analysis ,1(3), 515-533. Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (Third ed.). Boca Raton, FL: Chapman & Hall/CRC Press. Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (2003). Bayesian Data Analysis (Second ed.). Boca Raton, FL: Chapman & Hall/CRC Press. Geman, S., & Geman, D. (1984). Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images. IEEE Transactions on Pattern Analysis and Machine Intelligence ,6(6), 721-741. Genz, A., Bretz, F., Miwa, T., Mi, X., Scheipl, F., & Hothorn, T. (2014). mvt- norm: Normal and t Distributions software manual]. Retrieved fromhttp://CRAN.R-project.org/package=mvtnorm (R package version 1.0-2) Geyer, C. J. (1992). Practical Markov Chain Monte Carlo. Statistical Science ,7(4), 473-483. Gimpel, J. G., & Schuknecht, J. E. (2003). Political participation and the accessibility of the ballot box. Political Geography ,22(5), 471-488.144 References Glaser, S. (2017). Modelling of Spatial E ects in Count Data (Unpublished doctoral dissertation). Universit\u007f at Hohenheim. Good, I. (1985). Weight of Evidence: A Brief Survey. In J. M. Bernardo, M. H. DeGroot, D. V. Lindley, & A. F. M. Smith (Eds.), Bayesian Statistics 2 (p. 249-269). Amsterdam, The Netherlands: North-Holland. Gould, R. V. (1991). Multiple Networks and Mobilization in the Paris Commune, 1871. American Sociological Review ,56(6), 716-729. Greenbaum, R. T. (2002). A spatial study of teachers' salaries in Pennsylvania school districts. Journal of Labor Research ,23(1), 69-86. Gri\u000eth, D. A. (1979). Urban Dominance, Spatial Structure, and Spatial Dynamics: Some Theoretical Conjectures and Empirical Implications. Economic Geography ,55(2), 95- 113. Gu, X., Mulder, J., Dekovi\u0013 c, M., & Hoijtink, H. (2014). Bayesian evaluation of inequality constrained hypotheses. Psychological Methods ,19(4), 511-527. Hall, B. C. (2003). Lie Groups, Lie Algebras, and Representations: An Elementary Introduction . New York, NY: Springer. Halleck Vega, S., & Elhorst, J. P. (2015). The SLX model. Journal of Regional Science , 55(3), 339-363. Han, C., & Carlin, B. P. (2001). Markov Chain Monte Carlo Methods for Computing Bayes Factors. Journal of the American Statistical Association ,96(455), 1122-1132. Han, X., & Lee, L.-F. (2013). Bayesian estimation and model selection for spatial Durbin error model with nite distributed lags. Regional Science and Urban Economics ,43(5), 816-837. Handcock, M.S. (2003). P. Pattison (Eds.), Dynamic Social Network Modelling and Analysis: Workshop Summary and Papers (p. 229-240). Washington, D.C.: National Academies Press. Handcock, M. S., Hunter, D. R., Butts, C. T., Goodreau, S. M., Krivitsky, P. N., & Morris, M. (2017). ergm: Fit, Simulate and Diagnose Exponential-Family Models for Networks [Computer software manual]. Retrieved from http://CRAN.R-project.org/ package=ergm (R package version 3.8.0) Hansen, M. H., & Yu, B. (2001). Model Selection and the Principle of Minimum Descrip- tion Length. Journal of the American Statistical Association ,96(454), 746-774. Harville, D. A. (1997). Matrix Algebra From a Statistician's Perspective . New York, NY: Springer.References 145 Hastings, W. (1970). Monte Carlo Sampling Methods Using Markov Chains and Their Applications. Biometrika ,57(1), 97-109. Heikkila, E. J., & Kantiotou, C. (1992). Calculating scal impacts where spatial e ects are present. Regional Science and Urban Economics ,22(3), 475-490. Hepple, L. W. (1979). Bayesian analysis of the linear model with spatial dependence. In C. P. A. Bartels & R. H. Ketellapper (Eds.), Exploratory and explanatory statistical analysis of spatial data (p. 179-199). Dordrecht, The Netherlands: Springer. Hepple, L. W. (1995a). Bayesian Techniques in Spatial and Network Econometrics: 1. Model Comparison and Posterior Odds. Environment and Planning A: Economy and Space,27(3), 447-469. Hepple, L. W. (1995b). Bayesian Techniques in Spatial and Network Econometrics: 2. Computational Methods and Algorithms. Environment and Planning A: Economy and Space,27(4), 615-644. Heyndels, B., & Vuchelen, J. (1998). Tax Mimicking Among Belgian Municipalities. National Tax Journal ,51(1), 89-101. Higham, N. J. (2008). Functions of Matrices: Theory and Computation . Philadelphia, PA: Society for Industrial and Applied Mathematics. Holland, P. W., & Leinhardt, S. (1981). An Exponential Family of Probability Distri- butions for Directed Graphs. Journal of the American Statistical Association ,76(373), 33-50. Holloway, G., Shankar, B., & Rahman, S. (2002). Bayesian spatial probit estimation: a primer and an application to HYV rice adoption. Agricultural Economics ,27(3), 383-402. Howard, P. H. (1971). Political Tendencies in Louisiana . Baton Rouge, LA: Louisiana State University Press. Hummel, R. M., Hunter, D. R., & Handcock, M. S. (2012). Improving Simulation-Based Algorithms for Fitting ERGMs. Journal of Computational and Graphical Statistics , 21(4), 920-939. Hunt, L. M., Boxall, P., Englin, J., & Haider, W. (2005). Remote tourism and forest management: a spatial hedonic analysis. Ecological Economics ,53(1), 101-113. Hunter, D. R., & Handcock, M. S. (2006). Inference in Curved Exponential Family Models for Networks. Journal of Computational and Graphical Statistics ergm: A Package to Fit, Simulate and Diagnose Exponential-Family Models for Networks. Journal of Statistical Software ,24(3), 1-29.146 References Hunter, D. R., Krivitsky, P. N., & Schweinberger, M. (2012). Computational Statistical Methods for Social Network Models. Journal of Computational and Graphical Statistics , 21(4), 856-882. Je reys, H. (1961). Theory of Probability (Third ed.). Oxford, UK: Oxford University Press. Johnson, V. E., & Rossell, D. (2010). On the use of non-local prior densities in Bayesian hypothesis tests. Journal of the Royal Statistical Society: Series B (Statistical Method- ology),72(2), 143-170. Joines, J. D., Hertz-Picciotto, I., Carey, T. S., Gesler, W., & Suchindran, C. (2003). A spatial analysis of county-level variation in hospitalization rates for low back problems in North Carolina. Social Science & Medicine ,56(12), 2541-2553. Kalenkoski, C. M., & Lacombe, D. J. (2008). E ects of Minimum Wages on Youth Employment: the Importance of Accounting for Spatial Correlation. Journal of Labor Research ,29(4), 303-317. Kalnins, A. (2003). Hamburger Prices and Spatial Econometrics. Journal of Economics & Management Strategy ,12(4), 591-616. Kass, R. E., & Raftery, A. E. (1995). Bayes Factors. Journal of the American Statistical Association ,90(430), 773-795. Kass, R. E., & Wasserman, L. (1996). The Selection of Prior Distributions by Formal Rules.Journal of the American Statistical Association ,91(435), 1343-1370. Kim, J., & Goldsmith, P. (2009). A Spatial Hedonic Approach to Assess the Impact of Swine Production on Residential Property Values. Environmental and Resource Eco- nomics,42(4), 509-534. Kim, J., & Zhang, M. (2005). Determining Transit's Impact on Seoul Commercial Land Values: An Application of Spatial Econometrics. International Real Estate Review , 8(1), 1-26. Kirk, D. S., & Papachristos, A. V. (2011). Cultural Mechanisms and the Persistence of Neighborhood Violence. American Journal of Sociology ,116(4), 1190-1233. Klugkist,I.,Laudy,O.,&Hoijtink,H. (2005). InequalityConstrainedAnalysisofVariance: A Bayesian Approach. Psychological 477-493. Kowal, M. S. (2018). Corporate politicking, together: trade association ties, lobbying, and campaign giving. Business and Politics ,20(1), 98-131. Krivitsky, P. N. (2012). Exponential-family random graph models for valued networks. Electronic Journal of Statistics ,6, 1100-1128.References 147 Krivitsky, P. N., & Butts, C. T. (2017). Exponential-family Random Graph Models for Rank-order Relational Data. Sociological Methodology ,47(1), 68-112. Kuha,J. (2004). AICandBIC:ComparisonsofAssumptionsandPerformance. Sociological Methods & Research ,33(2), 188-229. Lacombe, D. J. (2004). Does Econometric Methodology Matter? An Analysis of Public Policy Using Spatial Econometric Techniques. Geographical Analysis ,36(2), 105-118. Lambert, D. M., Brown, J. P., & Florax, R. J. (2010). A two-step estimator for a spatial lag model of counts: Theory, small sample performance and an application. Regional Science and Urban Economics ,40(4), 241-252. Land, K. C., Deane, G., & Blau, J. R. (1991). Religious Pluralism and Church Member- ship: A Spatial Di usion Model. American Sociological Review ,56(2), 237-249. La Rocca, M., Porzio, G. C., Vitale, M. P., & Doreian, P. (2018). Finite Sample Behavior of MLE in Network Autocorrelation Models. In F. Mola, C. Conversano, & M. Vichi (Eds.),Classi cation, (Big) Data and Learning Switzerland: Springer. Lauridsen, J., Mat\u0013 e M. Public pharmaceutical expenditure: identi cation of spatial e ects. Journal of Geographical Systems ,12(2), 175-188. Lauritzen, S. L. (1996). Graphical Models . Oxford, Clarendon Press. Lee, L.-F. (2004). Asymptotic Distributions for Spatial Models. Econometrica ,72(6), 1899-1925. Lee, L.-F.,&Liu, X. disturbances. Econometric Theory ,26(1), 187-230. Leenders, R. T. (1995). Structure and In uence: Statistical models for the dynamics of actor attributes, network structure and their interdependence . Amsterdam, The Nether- lands: Thela Thesis. Leenders, R. T. (2002). Modeling social in uence through network autocorrelation: con- structing the weight matrix. Social Networks ,24(1), 21-47. Leifeld, P., Cranmer, S. J., & Desmarais, B. A. (2015). xergm: Extensions for Exponential Random Graph Models [Computer software manual]. Retrieved from http://CRAN.R -project.org/package=xergm (R package version BayesianEstimationofSpatialAutoregressiveModels. Science Review ,20(1-2), 113-129. LeSage, J. P. (1997b). Regression analysis of spatial data. Journal of Regional Analysis and Policy ,27(2), 83-94.148 References LeSage, J. P. (1999). Spatial Econometrics. (http://www.rri.wvu.edu/WebBook/ LeSage/spatial/wbook.pdf ) LeSage, J. P. (2000). Bayesian Estimation of Limited Dependent Variable Spatial Autore- gressive Models. Geographical Analysis ,32(1), 19-35. LeSage, J. P. Spatial econometric panel data model speci cation: A Bayesian approach. Spatial Statistics ,9, 122-145. LeSage, J. P. (2014b). What Regional Scientists Need to Know About Spatial Economet- rics.The Review of Regional Studies ,44(1), 13-32. LeSage, J. P., & Pace, R. K. (2008). Spatial Econometric Modeling of Origin-Destination Flows.Journal of Regional Science ,48(5), 941-967. LeSage, J. P., & Pace, R. K. (2009). Introduction to Spatial Econometrics . Boca Raton, FL: Chapman & Hall/CRC Press. LeSage, J. P., & Pace, R. K. (2011). Pitfalls in Higher Order Model Extensions of Basic Spatial Regression Methodology. The Review of Regional Studies ,41(1), 13-26. LeSage, J. P., & Parent, O. (2007). Bayesian Model Averaging for Spatial Econometric Models. Geographical Analysis ,39(3), 241-267. Levine, N., Kim, K. E., & Nitz, L. H. (1995). Spatial analysis of Honolulu motor vehicle crashes: II. Zonal generators. Accident Analysis and Prevention ,27(5), 675-685. Liang, F., Paulo, R., Molina, G., Clyde, M. A., & Berger, J. O. (2008). Mixtures of g Priors for Bayesian Variable Selection. Journal of the American Statistical Association , 103(481), 410-423. Liesenfeld, R., Richard, J.-F., & Vogler, J. (2016). Likelihood Evaluation of High- Dimensional Spatial Latent Gaussian Models with Non-Gaussian Response Variables. In B. H. Baltagi, J. P. LeSage, & R. K. Pace (Eds.), Spatial Econometrics: Qualitative and Limited Dependent Variables (p. 35-77). Bingley, UK: Emerald Group Publishing Limited. Lin, X. (2010). Identifying Peer E ects in Student Academic Achievement by Spatial Autoregressive Models with Group Unobservables. Journal of Labor Economics ,28(4), 825-860. Link, W. A., & Eaton, M. J. (2012). On thinning of chains in MCMC. Methods in Ecology and Evolution ,3(1), 112-115. Liu, C.C.,&Aitkin, M. (2008). Bayesfactors: Priorsensitivityandmodelgeneralizability. Journal of Mathematical Psychology ,52(6), 362-375. Lu, J., & Zhang, L. (2011). Modeling and Prediction of Tree Height{Diameter Relation- ships Using Spatial Autoregressive Models. Forest Science ,57(3), 252-264.References 149 Lynch, S. M. (2007). Introduction to Applied Bayesian Statistics and Estimation for Social Scientists . New York, NY: Springer. Marsden, P. V., & Friedkin, N. E. (1993). Network Studies of Social In uence. Sociological Methods & Research ,22(1), 127-151. Martinetti, D., & Geniaux, G. (2016). ProbitSpatial: Probit with Spatial Dependence, SAR and SEM Models [Computer software manual]. Retrieved from http://CRAN.R -project.org/package=ProbitSpatial (R package version 1.0) Mathai, A. M., & Provost, S. B. (1992). Quadratic Forms in Random Variables: Theory and Applications . New York, NY: Marcel Dekker. McMillen, D. P. (1992). Probit with Spatial Autocorrelation. Journal of Regional Science , 32(3), 335-348. McMillen, D. P. (2010). Issues in Spatial Data Analysis. Journal of Regional Science , 50(1), 119-141. McMillen, D. P. (2013). McSpatial: Nonparametric spatial data analysis [Computer software manual]. Retrieved from http://CRAN.R-project.org/package=McSpatial (R package version 2.0) McMillen, D. P., Singell Jr., L. D., & Waddell, G. R. (2007). Spatial Competition and the Price of College. Economic Inquiry ,45(4), 817-833. McPherson, M. A., & Nieswiadomy, M. L. (2005). Kuznets curve: threat- ened species and spatial e ects. ,55(3), 395-407. Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equations of State Calculations by Fast Computing Machines. Journal of Chemical Physics,21(6), 1087-1092. Mizruchi, M. S., & Neuman, E. J. (2008). The e ect of density on the level of bias in the network autocorrelation model. Social Networks ,30(3), 190-200. Mizruchi, M. S., & Stearns, L. B. (2006). The Conditional Nature of Embeddedness: A Study of Borrowing by Large U.S. Firms, 1973-1994. American Sociological Review , 71(2), 310-333. Moreno, R., & Trehan, B. (1997). Location and the Growth of Nations. Journal of Economic Growth ,2(4), 399-418. Moreno , J. D. (2003). Neighborhood Mechanisms and the Spatial Dynamics of Birth Weight. American Journal of Sociology ,108(5), 976-1017. Moreno , J. D., Sampson, R. J., & Raudenbusch, S. W. (2001). Neighborhood Inequality, Collective E\u000ecacy, and the Spatial Dynamics of Urban Violence. Criminology ,39(3), 517-558.150 References Morey, R. D., & Rouder, J. N. (2011). Bayes factor approaches for testing interval null hypotheses. Psychological Methods ,16(4), 406-419. Mulder, J. (2014a). Bayes factors for testing inequality constrained hypotheses: Issues with prior speci cation. British Journal of Mathematical and Statistical Psychology , 67(1), 153-171. Mulder, J. (2014b). Prior adjusted default Bayes factors for testing (in)equality con- strained hypotheses. Computational Statistics and Data Analysis ,71, 448-463. Mulder, J. (2016). Bayes factors for testing order-constrained hypotheses on correlations. Journal of Mathematical Psychology ,72, 104-115. Mulder, J., Klugkist, I., van de Schoot, R., Meeus, W. H., Selfhout, M., & Hoijtink, H. (2009). Bayesian model selection of informative hypotheses for repeated measurements. Journal of Mathematical Psychology ,53(6), 530-546. Mulder, J., & Wagenmakers, E.-J. (2016). Editors' introduction to the special issue \\Bayes factors for testing hypotheses in psychological research: Practical relevance and new developments\". Journal of Mathematical Psychology ,72, 1-5. Mur, J., L\u0013 opez, F., & Angulo, A. (2008). Symptoms of Instability in Models of Spatial Dependence. Geographical Analysis ,40(2), 189-211. Murray, I., Ghahramani, Z., & MacKay, D. J. C. (2006). MCMC for doubly-intractable distributions. In Proceedings of the Twenty-Second Conference on Uncertainty in Arti- cial Intelligence (p. 359-366). Arlington, VA: AUAI Press. Myneni, S., Fujimoto, K., Cobb, N., & Cohen, T. (2015). Content-Driven Analysis of an Online Community for Smoking Cessation: Integration of Qualitative Techniques, AutomatedTextAnalysis, andA\u000eliationNetworks. American Journal Structureandbiasinthenetworkautocorrelation model.Social Networks ,32(4), M. E. J. (2001). The structure of scienti c collaboration networks. Proceedings of the National Academy of Sciences of the United States of America ,98(2), 404-409. Niebuhr, A. (2010). Migration and innovation: Does cultural diversity matter for regional R&D activity? Papers in Regional Science ,89(3), 563-585. Nocedal, J., & Wright, S. (2006). Numerical Optimization (Second ed.). New York, NY: Springer. O'Hagan, A. (1995). Fractional Bayes Factors for Model Comparison. Journal of the Royal Statistical Society. Series B (Statistical Methodology) ,57(1), 99-138.References 151 Ord, K. (1975). Estimation Methods for Models of Spatial Interaction. Journal of the American Statistical Association ,70(349), 120-126. Osland, L. (2010). An Application of Spatial Econometrics in Relation to Hedonic House Price Modeling. Journal of Real Estate Research ,32(3), 289-320. Owen, A., & Zhou, Y. (2000). Safe and E ective Importance Sampling. Journal of the American Statistical Association ,95(449), 135-143. Owen, A. B. (2017). Statistically E\u000ecient Thinning of a Markov Chain Sampler. Journal of Computational and Graphical Statistics ,26(3), 738-744. Pace, R. K., & Barry, R. (1997). Quick Computation of Spatial Autoregressive Estimators. Geographical Analysis ,29(3), 232-247. Patton, M., & McErlean, S. (2003). Spatial E ects within the Agricultural Land Market in Northern Ireland. Journal of Agricultural Economics ,54(1), 35-54. Pearson, K. (1900). On the criterion that a given system of deviations from the probable in the case of a correlated system of variables is such that it can be reasonably supposed to have arisen from random sampling. Philosophical Magazine ,50(302), 157-175. Pericchi, L., & Pereira, levels using optimal decision rules: Balancing by weighting the error probabilities. Brazilian Journal of Probability and Statistics ,30(1), 70-90. Pisati, M. (2001). Tools for spatial data analysis. Stata Technical Bulletin ,60, 21-37. Pl\u007f umper, T., & Neumayer, E. (2010). Model speci cation in the analysis of spatial dependence. European Journal of Political Research ,49(3), 418-442. Pons-Novell, J., & Viladecans-Marsal, E. (1999). Kaldor's Laws and Spatial Dependence: Evidence for the European Regions. Regional Studies ,33(5), 443-451. Quddus, M. A. (2008). Modelling area-wide count outcomes with spatial correlation and heterogeneity: An analysis of London crash data. Accident Analysis and Prevention , 40(4), 1486-1497. R Core Team. (2017). R: A Language and Environment for Statistical Computing [Computer software manual]. Vienna, Austria. Retrieved from http://www.R-project .org/ Raftery, A. E. (1995). Bayesian Model Selection in Social Research. Sociological Method- ology,25, 111-163. Raftery, A. E., & Lewis, S. M. (1996). Implementing MCMC. In W. Gilks, S. Richardson, & D. Spiegelhalter (Eds.), Markov Chain Monte Carlo in Practice (p. 115-130). Boca Raton, FL: Chapman & Hall/CRC Press.152 References Raftery, A. E., Madigan, D., & Hoeting, J. A. (1997). Bayesian Model Averaging for Linear Regression Models. Journal of the American Statistical Association ,92(437), 179-191. Revelli, F. (2003). Reaction or interaction? Spatial process identi cation in multi-tired government structures. Journal of Urban Economics ,53(1), 29-53. Rey, S. J., & Anselin, L. (2007). PySAL: A Python Library of Spatial Analytical Methods. The Review of Regional Studies ,37(1), 5-27. Robert, C. (2001). The Bayesian Choice: From Decision-Theoretic Foundations to Com- putational Implementation . New York, NY: Springer. Robins, G., Pattison, P., Kalish, Y., & Lusher, D. (2007). An introduction to exponential random graph (p*) models for social networks. Social Networks ,29(2), 173-191. Robins, G., Snijders, T., Wang, P., Handcock, M., & Pattison, P. (2007). Recent develop- ments in exponential random graph (p*) models for social networks. Social Networks , 29(2), 192-215. Rouder, J. N., Speckman, P. L., Sun, D., Morey, R. D., & Iverson, G. (2009). Bayesian t tests for accepting and rejecting the null hypothesis. Psychonomic Bulletin & Review , 16(2), 225-237. Rubio, F. J., & Steel, M. F. in Two-Piece Location-Scale Ruggles, S. (2007). The Decline of Intergenerational Coresidence in the United States, 1850 to 2000. American Sociological Review ,72(6), 964-989. Rupasingha, A., Goetz, S. J., & Freshwater, D. (2002). Social and institutional factors as determinants of economic growth: Evidence from the United States counties. Papers in Regional Science ,81(2), 139-155. Saavedra, L. A. (2000). A Model of Welfare Competition with Evidence from AFDC. Journal of Urban Economics ,47(2), 248-279. Schwarz, G. (1978). Estimating the Dimension of a Model. The Annals of Statistics ,6(2), 461-464. Seldadyo, H., Elhorst, J. P., & De Haan, J. (2010). Geography and governance: Does space matter? Papers in Regional Science ,89(3), 625-640. Sellke, T., Bayarri, M. J., & Berger, J. O. (2001). Calibration of p Values for Testing Precise Null Hypotheses. The American Statistician ,55(1), 62-71. Sha er, J. P. (1995). Multiple Hypothesis Testing. Annual Review of Psychology ,46, 561-584.References 153 Shin, M., & Ward, M. D. (1999). Lost in Space: Political Geography and the Defense- Growth Trade-O . The Journal of Con ict Resolution ,43(6), 793-817. Sinharay, S., & Stern, H. S. (2002). On the Sensitivity of Bayes Factors to the Prior Distributions. The American Statistician ,56(3), 196-201. Smith, T. E. (2009). Estimation Bias in Spatial Models with Strongly Connected Weight Matrices. Geographical Analysis ,41(3), 307-332. Snijders, T. A. B. (2002). Markov Chain Monte Carlo Estimation of Exponential Random Graph Models. Journal of Social Structure ,3(2). Stewart, W. J. (2009). Probability, Markov Chains, Queues, and Simulation: The Math- ematical Basis of Performance Modeling . Princeton, NJ: Princeton University Press. Strauss, D. (1986). On a General Class of Models for Interaction. SIAM Review ,28(4), 513-527. Tam Cho, W. K. (2003). Contagion E ects and Ethnic Contribution Networks. American Journal of Political Science ,47(2), 368-387. Tita, G. E., & Greenbaum, R. T. (2009). Crime, Neighborhoods, and Units of Analysis: Putting Space in Its Place. In D. Weisburd, W. Bernasco, & G. J. Bruinsma (Eds.), Putting Crime in its Place (p. 145-170). New York, NY: Springer. Tita, G. E., & Radil, S. M. (2011). Spatializing the Social Networks of Gangs to Explore Patterns of Violence. Journal of Quantitative Criminology ,27(4), 521-545. Trautmann, H., Steuer, D., Mersmann, distribution [Computer software manual]. Retrieved from http:// (R package version 1.0-7) van de Schoot, R., Mulder, J., Hoijtink, H., van Aken, M. A., J. S., Orobio de Castro, B., ... Romeijn, J.-W. (2011). An introduction to Bayesian model selection for evaluating informative hypotheses. European Journal of Developmental Psychology , 8(6), 713-729. van Duijn, M. A. J., Gile, K. J., & Handcock, M. S. (2009). A framework for the compar- ison of maximum pseudo-likelihood and maximum likelihood estimation of exponential family random graph models. Social Networks ,31(1), 52-62. Varga, A. (2000). Local Academic Knowledge Transfers and the Concentration of Eco- nomic Activity. Journal of Regional Science ,40(2), 289-309. Vitale, M. P., Porzio, G. C., & Doreian, P. (2016). Examining the e ect of social in uence on student performance through network autocorrelation models. Journal of Applied Statistics ,43(1), 115-127.154 References Voss, P. R., & Chi, G. (2006). Highways and Population Change. Rural Sociology ,71(1), 33-58. Voss, P. R., Long, D. D., Hammer, R. B., & Friedman, S. (2006). County child poverty rates in the US: a spatial regression approach. Population Research and Policy Review , 25(4), 369-391. Wagenmakers, E.-J. (2007). A practical solution to the pervasive problems of p values. Psychonomic Bulletin & Review ,14(5), 779-804. Wang, W., Neuman, E. J., & Newman, D. A. (2014). Statistical power of the social network autocorrelation model. Social Networks ,38, 88-99. Wang, Y., Kockelman, K. M., & Damien, P. (2014). A spatial autoregressive multinomial probit model for anticipating land-use change in Austin, Texas. The Annals of Regional Science,52(1), 251-278. Watts, D. J., & Strogatz, S. H. (1998). Collective dynamics of `small-world networks'. Nature,393, 440-442. Weakliem, D. L. (2004). Introduction to the Special Issue on Model Selection. Sociological Methods & Research ,33(2), 167-187. Wetzels, R., & Wagenmakers, E.-J. (2012). A test for corre- and partial correlations. Psychonomic Bulletin & Review ,19(6), 1057-1064. White, D. R., Burton, M. L., & Dow, M. M. (1981). Sexual Division of Labor in African Agriculture: A Network Autocorrelation Analysis. American Anthropologist ,83(4), 824-849. Whitt, H. P. (2010). The Civilizing Process and Its Discontents: Suicide and Crimes against Persons in France, 1825{1830. American Journal of Sociology ,116(1), 130- 186. Wilhelm, S., & Godinho de Matos, M. (2015). spatialprobit: Spatial Probit Models [Computer manual]. Retrieved from http://CRAN.R-project.org/package= spatialprobit (R package version Wilhelm, S., & Manjunath, B. (2015). tmvtnorm: Truncated Multivariate Normal and Student t Distribution [Computer software Retrieved from http://CRAN.R -project.org/package=tmvtnorm (R package version 1.4-10) Wilhelmsson, M. (2002). Spatial Models in Real Estate Economics. Housing, Theory and Society,19(2), 92-101. Won Kim, C., Phipps, T. T., & Anselin, L. (2003). Measuring the bene ts of air quality improvement: a spatial hedonic approach. Journal of Environmental Economics and Management ,45(1), 24-39.References 155 Yang, N., McCluskey, J. J., & Brady, M. P. (2012). The Value of Good Neighbors: A Spatial Analysis of the California and Washington State Wine Industries. Land Economics ,88(4), 674-684. Yang, X. (2000). A Matrix Trace Inequality. Journal of Mathematical Analysis and Applications ,250(1), 372-374. Yang, Z. (2015). A general method for third-order bias and variance corrections on a nonlinear estimator. Journal of Econometrics ,186(1), 178-200. Yu, D., Bai, P., & Ding, C. (2015). Adjusted quasi-maximum likelihood estimator for mixed regressive, spatial autoregressive model and its small sample bias. Computational Statistics and Data Analysis ,87, 116-135. Zellner, A. (1986). On Assessing Prior Distributions and Bayesian Regression Analysis with g-Prior Distributions. In P. K. Goel & A. Zellner (Eds.), Bayesian Inference and Decision Techniques: Essays in Honor of Bruno de Finetti (p. 233-243). Amsterdam, The Netherlands: North-Holland. Zhang, B., Thomas, A. C., Doreian, P., Krackhardt, D., & Krishnan, R. (2013). Contrast- ing Multiple Social Network Autocorrelations for Binary Outcomes, With Applications To Technology Adoption. ACM Transactions on Management Information Systems , 3(4), 18:1{18:21.157 Acknowledgments I would like to take the opportunity and thank several people who shaped the past four years and contributed to this thesis in di erent ways. First, I would like to thank my promotors and copromotor. Joris, thank you for your continuous academic guidance, the con dence shown in me, and both the attention and freedom you gave me. I am happy that our relationship grew beyond the o\u000ece over the years, helping me not only develop as a researcher but also as a person. Roger, thank you for bringing up football data in the research project description that probably gave way to my time in Tilburg to start with. The football data are still to be analyzed by the three of us but you steadily encouraged me to also take the perspective of a more applied researcher from time to time, which greatly improved the comprehensibility of my writing. Jeroen, your door was always open and I would like to thank you for supporting my personal development by facilitating teaching opportunities, summer school visits, and research stays. In fall 2017, I had the chance to visit Professor George Tita and Professor Carter Butts at UC Irvine. George, thank you for inviting me to Irvine without having met me in person, for introducing me to dozens of your colleagues and asking every single one of them to share empirical data with us, and for showing me Irvine's nest gourmet places. Carter, thank you for the warm welcome, for allowing me to join your lab group, and for the many stimulating and fruitful discussions. Mario, thank you for hosting me in Irvine and the fun times in Southern California and beyond. I hope that our friendship will continue to last across seas and continents in spite of near apartment burn downs, sh poisonings, and late-night o\u000ecer chats. Furthermore, I would like to thank the members of the Bayes lab group for taking their time to read and give feedback on several draft papers over the years. It was always motivatingtopresentandexchangethoughtswithyouandreceivewell-intentionedreviews on early stage research. I am especially grateful to Davide, Florian, Geert, Jesper, Kyle, Lianne, Reza, Sara, and Xynthia. To all of my other (former) colleagues at the department: thank you for being such an easy-going group of guys and girls, creating an atmosphere in which we saw each other much more as friends rather than competitors. To Mattis, thank you for being a great o\u000ece mate and a great friend, being there in times of need, nearby or far away. To Jaap Joris, thankyoufortheenthusiasmandthefreshideasyoubroughttoouro\u000eceinthepast two years as well as the always entertaining out-of-o\u000ece hours spent together. To Erwin, thank you for sharing your thesis template and thereby making this thesis look somewhat tidy. To Luc, thank you for boosting my teaching self-con dence and for nudging me into158 Acknowledgments becoming a supporter of Willem II. To Paulette, thank you for answering my countless questions before moving to Tilburg and for being so hospitable. To Reza, thank you for radiating so much positive energy every time we see each other, you are an inspiration. To Robbie, thank you for all the sports talk and action, I hope to join you in more data-driven reasoning soon. To Ruslan pa\u0018 sa, thank you for bringing back music making to my life, I cannot overstate how much this means to me. To Zsuzsa, thank you for motivating me to keep exploring the world and trying out something new. To Anne-Marie, Liesbeth, and Marieke, thank you for all the patience, kindness, and help when I was bogged down in paper work. Finding joy beyond work has always been very important to me, and I cherish the friendships I made in Tilburg outside the o\u000ece that also gave inspiration for times spent in the o\u000ece. Alem, I think we can both safely say \\it is a small world\", and thank you for being an anchor for me in Tilburg. Diogo, you became my rst friend in Tilburg and I miss our dinners, spontaneous trips, and listening to your guitar playing. Gijs, I admire the dedication you have, which made me look forward to our practices for days. Roland, I still have to gure out if and when you sleep but that left more time to have fun on and o the tennis court. Dear Yugo band, dear Asmir, Du\u0014 san, Jovana, Marko, Nata\u0014 sa, Neboj\u0014 sa, and Stevan, thank you for the Wednesday lunches, for the nights out, for the trips together, and for all the laughs, you rock. I would also like to thank Christina, Francesca, and Gaby for your friendship. To my ski ninjas, Mario, Moritz, Nora, Ozren, and Peter B., thank you for brightening up winters in the lowlands and for not being a complete d\u0013 ebutant in powder anymore. To Akan, Antonio, Feli, Isai, Jason, Juan, Michael S., Miles, Olaf, and Pedro, thank you for the good times in Irvine. To Annalisa, thank you for helping me grow as a person in so many ways. To my \\old\" Munich friends, Alex D., Alex G., Beni, Dorde, Fabio, Matthias, Michael C., Peter L., Robert, and Verena, thank you for the nights out back home, for the spontaneous visits, and for the many memorable travels. You always made me return in high spirits from shorter or longer home o\u000ece stays. Nata\u0014 sa and Barend, I am very happy that you are holding my back on defense day. Although we stayed at di erent departments and barely understood each other's research, we shared the ups and downs of academic life and the two of you made me feel comfortable to reach out at any time for whatever reason there was. Nata\u0014 sa, thank you for being the good and caring person you are. Barend, thank you for the always active and fun times spent together, from A(rmbrustsch\u007f utzenzelt) to Z(aventem). Finally, I wish to express my gratitude to my family. To my sister, Irma, thank you for always believing in my academic skills and especially for your support throughout the last few months of writing. To my parents, thank you for putting things into perspective from time to time and for always putting my well-being rst. I am grateful for the opportunities you created for me and my sister from early childhood on, which eventually allowed me to be able to pursue a Ph.D. The three of you mean everything to me.The grass is not always greener in the neighbor's yard: Bayesian and frequentist inference methods for network autocorrelated data Dino DittrichINVITATION to the public defense of my PhD thesis The grass is not always greener in the neighbor's yard: Bayesian and frequentist inference methods for 2018, Auditorium of Tilburg University Cobbenhagen building Warandelaan 2, Tilburg After the defense, you are cordially invited to the reception next to the auditorium. Dino Dittrich dino.dittrich@gmail.com Paranymphs Natasha Stamenkovikj Barend in the neighbor's yard: Bayesian and yard: Bayesian and frequentist inference methods for network autocorrelated data Dino DittrichINVITATION to the public defense of my PhD thesis The grass is not always greener in the neighbor's yard: Bayesian and frequentist inference methods for 2018, Auditorium of Tilburg University Cobbenhagen building Warandelaan 2, Tilburg After the defense, you are cordially invited to the reception next to the auditorium. Dino Dittrich dino.dittrich@gmail.com Paranymphs Natasha Stamenkovikj Barend in the neighbor's yard: Bayesian and "}