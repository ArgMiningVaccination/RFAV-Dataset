{"title": "PDF", "author": "PDF", "url": "https://thesis.library.caltech.edu/14001/3/Navid_Azizan_2020_Thesis.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "Optimization Algorithms Thesis by Navid Azizan In Partial Fulllment of the Requirements for the Degree of Doctor of Philosophy CALIFORNIA INSTITUTE OF TECHNOLOGY Pasadena, California 2021 Defended August 25, 2020ii \u00a92021 Navid Azizan rights reserved except where otherwise notediii ACKNOWLEDGEMENTS I think anyone who has been to Caltech would agree that it is truly an exceptional environment, andI consider myself luckyto have had theopportunity to spend ve years of my life here and interact with such an extraordinary group of scholars. So, I wish to thank numerousindividuals, withoutwhom this thesis would not havebeen possible. First, and foremost, I would like to express my deepest gratitude to my two advisors, Adam Wierman and Babak Hassibi, for their generous and continuous support, guidance, and encouragement throughout my PhD, and for giving me complete freedominpursuingmydiverseinterests. Theyhavealwaysbeenavailableforany helpdespitetheirbusyschedules,andtheiradviceextendedbeyondresearchtocareer planning and even personal matters. They invested a great deal of time and eort in molding me into a successful researcher and academic, and I am forever indebted to them for that. The depth and the breadth of their knowledge, their clarity of thought, their careful comments and questions, their passion for research and education, their infective energy, and their kindness have always inspired and continue to inspire me, both professionally and personally. Iamalsodeeplyindebtedtothechairofmythesiscommittee,StevenLow,whoin many ways acted as another advisor for me, and was in no small part responsible for my transformative experience at Caltech. I am grateful for his always thoughtful and insightful comments and for his unwavering willingness to help. I am also very gratefultoYisongYueforhissupportandguidance,hisvaluablefeedbackonmy job talk, for giving me the opportunity to supervise student projects in his class, and for serving on my thesis committee. Beyondmycommittee,IamverygratefultootherCaltechfacultymembers,especially VenkatChandrasekaran,K.ManiChandy,RichardM.Murray,JohnDoyle,JoelA. Ali Hajimiri, for guidance and for providing a stimulating environment for my intellectual growth. The work in this thesis is the result of many collaborations. I would like to thank my wonderful collaborators and friends, Yu Su, Sahin Farshad Lahouti. Special thanks are also due to the CMS administrative sta, especiallyiv MariaLopez,Sheila Shull,SydneyGarstang, andChristineOrtega,for takingcare mybrother, for allthe years oflove and support.v ABSTRACT The expansion of large-scale technological systems such as electrical grids, trans- portationnetworks,healthcaresystems,telecommunicationnetworks,theInternet (of things), and other societal networks has created numerous challenges and op- portunities at the same time. These systems are often not yet as robust, ecient, sustainable, or smart as we would want them to be. Fueled by the massive amounts of data generated by all these systems, and with the recent advances in making senseoutofdata,thereisastrongdesiretomakethemmoreintelligent. However, developing large-scaleintelligentsystems isamultifacetedproblem,involvingseveral major challenges. First, large-scale systems typically exhibit complex dynamics due to the large number of entities interacting over a network. Second, because thesystemiscomposedofmanyinteractingentities,thatmakedecentralized(and oftenself-interested)decisions,onehastoproperlydesign incentivesandmarkets for such systems. Third, the massive computational needs caused by the scale of thesystemnecessitateperformingcomputationsina distributed fashion,whichin turn requires devising new algorithms. Finally, one has to create algorithms that canlearn from the copious amounts of data and generalize well. This thesis makes several contributions related to each of these four challenges. Analyzing and understanding the network dynamics exhibited in societal systems is crucial for developing systems that are robust and ecient. In Part I of this thesis,westudyoneofthemostimportantfamiliesofnetworkdynamics,namely, thatofepidemics ,orspreadingprocesses . Studyingsuchprocessesisrelevantfor understanding and controlling the spread e.g., contagious diseases among people, ideasorfakenewsinonlinesocialnetworks,computervirusesincomputernetworks, orcascadingfailuresinsocietalnetworks. Weestablishseveralresultsontheexact Markov chain model and the nonlinear of SEIRS, SIV, SEIV, and their variants). Designing incentives and markets for large-scale systems is critical for their ecient operationandensuringanalignmentbetweentheagents'decentralizeddecisionsand theglobalgoalsofthesystem. Tothatend,inPartIIofthisthesis,westudythese issues in markets with non-convex costs as well as networked markets, which are of vitalimportancefor,e.g.,thesmartgrid. Weproposenovelpricingschemesforsuch markets, which satisfy all the desired market properties. We also reveal issues in the currentincentivesfordistributedenergyresources,suchasrenewables,anddesignvi optimization algorithms for ecient management of aggregators of such resources. With the growing amounts of data generated by large-scale systems, and the fact that the data may already be dispersed across many units, it is becoming increasingly necessary to run computational tasks in a distributed fashion. Part III concerns developingalgorithmsfordistributedcomputation. Weproposeanovelconsensus- basedalgorithmforthetaskofsolvinglarge-scale systemsoflinearequations ,which is one of the most fundamental problems in linear algebra, and a key step at the heart of many algorithms in scientic computing, machine learning, and beyond. In addition, in order to deal with the issue of heterogeneous delays in distributed computation, caused by slow machines, we develop a new coded computation technique. Inbothcases,theproposedmethodsoersignicantspeed-upsrelative to the existing approaches. Over the past decade, deep learning methods have become the most successful learning algorithms in a wide variety of tasks. However, the reasons behind their success(aswellastheirfailuresinsomerespects)arelargelyunexplained. Itiswidely believed that the success of deep learning is not just due to the deep architecture of the models, but also due to the behavior of the optimization algorithms, such as stochastic gradient descent (SGD), used for training them. In Part IV of CONTRIBUTIONS [1]Navid Azizan. \"Optimization Algorithms for Systems: /d.sc/o.sc/i.sc:10.1109/ICASSP40776.2020.9053864 . N.A. contributed to the conception of the project, designing the methods, performing the analysis, and writing the manuscript. [3]Navid Azizan et al. \"Optimal Pricing in Markets (2020), pp. 480-496. /d.sc/o.sc/i.sc:10.1287/opre.2019. 1900. N.A. contributed to the conception of the project, designing the methods, performing the analysis, and writing the manuscript. [4]Navid Azizan and Babak Hassibi. \"A Characterization of Stochastic Algorithms and Convergence Properties\". In: 2019 IEEE Inter- national Conferenceon /d.sc/o.sc/i.sc:10.1109/ICASSP.2019.8682271 . N.A. contributed to the conception of the project, designing the methods, performing the analysis, and writing the manuscript. [5]Navid Azizan and 3960-3965. /d.sc/o.sc/i.sc:10.1109/ CDC40024.2019.9030229 . N.A. contributed to the conception of the project, designing the methods, performing the analysis, and writing the manuscript. 2019. N.A. contributed to the conception of the project, designing the methods, performing the analysis, and writing the manuscript. [7]Navid Azizan et al. \"Distributed Solution of Large-Scale Linear Systems via Accelerated Projection-Based Consensus\". /d.sc/o.sc/i.sc:10.1109/TSP.2019. 2917855. N.A. contributed to the conception of the project, designing the methods, performing the analysis, and writing the manuscript.viii [8]NavidAzizanetal.\"OptimalPricinginMarketswithNon-ConvexCosts\".In: Proceedingsofthe2019ACMConferenceonEconomicsandComputation (EC). Phoenix, /d.sc/o.sc/i.sc: 10.1145/3328526.3329575 . N.A. contributed to the conception of the project, designing the methods, performing the analysis, and writing the manuscript. [9]Navid Azizan et al. \"Stochastic Mirror 2019InternationalConferenceonMachineLearning(ICML)Generalization Workshop . 2019. N.A. contributed to the conception of the project, designing the methods, performing the analysis, and writing the manuscript. [10]Navid Information Processing Systems (NeurIPS) Deep Learning Theory Workshop . 2018. N.A. contributed to the conception of the project, designing the methods, performing the analysis, and writing the manuscript. [11]Navid Azizan et al. \"Distributed Solution of Large-Scale Linear Systems via Accelerated Projection-Based Consensus\". In: 2018 IEEE International Conference on 2018, pp. 6358-6362. /d.sc/o.sc/i.sc:10.1109/ICASSP.2018.8462630 . N.A. contributed to the conception of the project, designing the methods, performing the analysis, and writing the manuscript. [12]NavidAzizanetal.\"OpportunitiesforPriceManipulationbyAggregators in Electricity Markets\". In: IEEE Transactions (2018), pp. 5687-5698. /d.sc/o.sc/i.sc:10.1109/TSG.2017.2694043 . N.A. contributed to the conception of the project, designing the methods, performing the analysis, and writing the manuscript. [13]WaelHalbawi etal.\"ImprovingDistributed contributed to the conception of the project, designing the methods, performing the analysis, and writing the manuscript. [14]NavidAzizanetal.\"Analysisofexactandapproximatedepidemicmodels over to the conception of the project, designing the methods, performing the analysis, and writing the manuscript. [15]Navid Azizan et al. \"Improved bounds on the epidemic threshold of exact SIS models on complex networks\". In: 2016 55th IEEE Conference on Decision and . 2016, pp. 3560-3565. /d.sc/o.sc/i.sc:10.1109/CDC. 2016.7798804 .ix N.A. contributed to the conception of the project, designing the methods, performing the analysis, and writing the manuscript. [16]NavidAzizanetal.\"OpportunitiesforPriceManipulationbyAggregatorsin contributed to the conception of the project, designing the methods, performing the analysis, and writing the manuscript. [17]NavidAzizanandBabakHassibi.\"SIRSepidemicsoncomplexnetworks: Concurrence of exact Markov N.A. contributed to the conception of the project, designing the methods, performing the analysis, and writing the manuscript.x TABLE Chapter II: Epidemics over Complex Networks: Analysis of Improved Bounds on the Epidemic Threshold of the Exact Models 40 3.1 . 55 Chapter IV: Optimal Pricing in Large-Scale Systems . . . 178 8.4 Main Result: General Characterization of Stochastic Mirror Descent 183 8.5ConvergenceandImplicitRegularizationinOver-ParameterizedModels diagram of a single node in dierent models. Wavy arrows rep- resent exogenous (network-based) transition. (stands for susceptible (healthy),\u001afor exposed, for infected/infectious, and 'for recovered. 15 2.2 Reduced Markov chain of a single node in the steady . . . X. MC stands the Markov example of the evolution of an SIS epidemic over an Erds- R\u00e9nyi graph with ==2000nodes contrast,whenV_max\u00b9\u0016\u00ba X\u00a11(e.g.,V=0\u0095056,X=0\u00959),theepidemic doesnotexhibitconvergencetothedisease-freestateinanyobservable time (red curve). In fact, the epidemic keeps spreading around the nontrivial (vaccination-dominant) epidemics over an Erds-R\u00e9nyi graph with ==2000nodes. The blue curves show fast extinction of the epidemic. The red curves show epidemic spread around the nontrivial of a single node in the SIS model, and the transition rates. Wavyarrowrepresentsexogenous(neighbor-based)transition. V:probability of infection per infected link, X:probability of recovery. 42 3.2Evolution of the SIS epidemic over a star graph withtwovaluesof d\u00b9\"0\u00babelowandabove1. When d\u00b9\"0\u00ba=0\u009599\u009f1, weobservefastextinctionoftheepidemic(bluecurve). Thecondition alsoseemsverytight,asfor d\u00b9\"0\u00ba=1\u009505\u00a11,theepidemicdoesnot die out (red curve). This is while the previously known bound is not informative at all (V_max\u00b9\u0016\u00ba X=1\u009593\u00a11for the rst case, and 2\u009533\u00a11 with 3 non-convex cost functions. Thethreebluecurves arethecostfunctions. The(dashed and solid) red lines lie below all the cost functions and their slopes tree dened by Algorithm 1 for ==8. The faded circles correspond to the lies below the function (because of convexity). The red (solid) linethatpassesthroughtheoriginistheuniformpricefunction,which is parallel to the An example with cost functions of the form of linear plus startup cost. 86 4.5An example with cost functions of the form of quadratic for two connected markets with a constraint tree to a binary tree. . . . . 97 5.1The 6-bus example condition and under (optimal) strategic curtailment, as a function of size of the in IEEEtest casenetworks: a) IEEE 57-Bus Case. The dierence of the impact of coordinated curtailment on the prices in the IEEE 14-bus network. Aggregator nodes are 2, 7, 10, and 14. . . 111 5.5The LMP at bus 8as a function of curtailed generation at that bus. Shadedareasindicatetheaggregator'srevenueatthenormalcondition optimal solution as a function of the running time of the algorithm, in the 9-bus the <machines/cores. Each machine 8has only \u00bb\u00168\u009618\u00bc. . . 132 6.2The decay of the error for dierent distributed algorithms, on two real problems from Matrix Market [141] (QC324: the delay is characterized byC0=0\u0095001andb=1\u00951. Theoptimizerofthisfunctionaspredicted by (7.26) isU\u0003=0\u00951477. This point is denote by the star symbol. . . 171 7.3The comparison between the test error of dierent schemes as a func- tion of time, for a softmax regression model trained using distributed gradient descent on ==80machines. The model was trained on 12000examplesfromtheMNISTdatabase[121]andvalidatedona testsetofsize10000. TheReed-Solomonbasedscheme(Coded-RS) waits for5RS=68machines, while the one corresponding to [197] (Coded - MDS) waits for 5MDS=33.5RSand5MDSwere of Lemma 38. Each step of SGD can be viewed as a transformation of the uncertainties with the right coecients. . . . . 180 8.2The training loss and actual error of stochastic mirror descent for compressed sensing. SMD recovers the signal. dataset using ResNet-18. \u001210performs consistently better, while\u00121performs consistently worse. The red line shows the state of the art on \u00121-SMD inducessparsityontheweights. SGDappearstoleadtoaGaussian distribution on the weights. \u00123-SMD starts to reduce the sparsity, and \u001210shifts the distribution of the weights signicantly, so much so that almost all the closestglobal minimumto F0(in Bregmandivergence), and of \u0019!8\u00b9F\u0096F0\u00ba\u00150in a local region in Assumption 1. . 208 9.5 An illustration of the experiments in a particular initial point and all the nal points obtained by both dierentinitializations and dierent mirrors. The smallestdistance,amongallinitializationsandallmirrors,corresponds exactlytothenalpointobtainedfromthatinitialpointbySGD.This trend is observed consistently for all other mirror descents and all initializations (see the results in Tables 9.8 and 9.9 in the appendix). . 213 9.8DierentBregmandivergencesbetweenallthenalpointsandallthe initial points for dierent mirrors in MNIST dataset using a standard CNN. Note that the smallest element in every single row is on the diagonal, which conrms the all the nal points and all the initial points for dierent mirrors in CIFAR-10 dataset using ResNet-18. Notethatthesmallestelementineverysinglerowison the each initialization F0, we ran dierent SMD algorithms until convergence to a point on the setW(zero training error). We then measured all the pairwise distances from dierent F1to dierentF0, in dierent Bregman divergences. The closest point (among all initializations and all mirrors) to any particular initialization the absolute value of the nal weights in the network for dierent SMD algorithms: (a) \u00121-SMD, (b)\u00122-SMD (SGD), (c) \u00123-SMD, starts to reduce the sparsity, and \u001210shifts the distribution of the weights signicantly, so much so that almost all the CIFAR-10 dataset for the Euclidean distance; in general the \"closest\" the proposed bounds \"0and\"00in comparison with thepreviousbound \". Boldfacevaluesshowanimprovementover \". Thesignsnextto their properties. . . . . . 82 4.2Summary new cost functions in the modied Scarf's example. . 86 6.1A summary of the convergence rates of dierent methods. DGD: BlockCim- minoMethod,APC:AcceleratedProjection-basedConsensus. The smaller the convergence rate is, the faster is the method. Note number of-is typically much smaller (better). Remarkably, the dierence is even more pronounced when \u0016has non-zero mean. . . . convergence time )(=1 \u0000logd) of dierent methods on real and synthetic examples. Boldface values show the smallest convergence time. QC324: Model of \u00b8 2in an Electromagnetic Field. ORSIRR 1: Oil Reservoir Simulation. ASH608: Original Harwell (Fig.9.5),measuredindierentBregmandivergences(rows). First Row: The closest point to F0in\u00121Bregman divergence, among the four nal points, is exactly the one obtained by SMD with 1- norm potential. Second Row: The closest point F0in\u00122Bregman Fourth Row: The closest pointtoF0in\u001210Bregmandivergence,amongthefournalpoints,is exactly the one nal points obtained from them by SGD (Fig. 9.6). Row i: Theclosestnalpointtotheinitialpoint 8,amongalltheeightnal points, is exactly the one obtained by the algorithm from initialization 8.212 Divergence Between the Initial Points and the Between the Initial Points and Between the Initial Points and Between the Initial Points and the Between the Initial Points and the Between the Initial Points and the Between the Initial Points and the pte r 1 INTRODUCTION Our technological systems are arguably at the dawn of a major transformation. We have built complex systems such as electrical grids, transportation networks, health care systems, telecommunication networks, the Internet (of things), and other societal networks, which have enabled connecting large numbers of entities or people. While immensely helpful, these systems are, in many senses, not yet asrobust,ecient,sustainable , orsmartas we would want them to be. However, that is beginning to change. The formation of these large-scale systems, while posingenormouschallenges(suchashowtomanagethemeciently),hascreated tremendous opportunities for developing \"more intelligent\" systems. With the massiveamountsofdatageneratedbyallthesesystems,andwiththemajoradvances during the recent years in areas such as machine learning and data science, network science, and market design, we are at a unique time in history to revolutionize these systems and pave the way for the development of what can be referred to as large-scaleintelligentsystems . Thisthesisisbroadlyaimedataddressingsomeof the key challenges towards realizing this goal, and laying a foundation for analyzing and designing such systems. 1.1 Major Challenges Developing large-scale intelligent systems is a multifaceted problem and requires a confluence of disciplines. In particular, over the past few decade, we have seen remarkableprogressinthisinterdisciplinaryendeavorfromvariouseldssuchas networks science, machine learning, statistics, optimization, control theory, and game theory, among others. Despite this progress, we are still far from realizing that vision. Someofthekeychallengesindesigninglarge-scaleintelligentsystemscan be summarized as follows. 1.Complex Dynamics: Large-scale systems typically exhibit complex dynamics, caused by the large number of entities interacting with one another, often over anetwork. Analyzingandunderstandingthesedynamicsiscrucialforcreating systems that are ecient and robust. system. 3.Distributed Computation: The massive computational needs due to the scale of the system (and the fact that the data may be dispersed across many entities) make it virtually impossible to carry out computations at a central unit. Therefore, devising algorithms that can run in a distributed or parallel fashion is of vital importance for such systems. 4.Learning from Data: Lastly, an important aspect of an intelligent system is the abilitytolearnfromdata,andtheenormousamountofdatageneratedbythese large-scale systems makes them uniquely appealing for this purpose. Creating learning algorithms that can generalize well is an ongoing enterprise, with notable successes and many unsolved problems. Someofthecommonlower-levelobstaclesthatoftenariseinaddressingtheabove challenges are those of networks and/ornon-convexities . These issues, as will be discussed later, complicate both understanding the behavior of these systems as well as designing suitable algorithms for them. This thesis is organized into four main parts, based on the four major challenges discussedabove. Whilerelated,thefourpartsneednotbereadinorder(orintheir entirety) when reading this thesis. To further allow for a modular reading, each chapter is aimed to be self-contained. /one.supIn what follows, we summarize the main contributions of the thesis in each part. 1.2 Synopsis of Part I: Network Dynamics As mentioned earlier, understanding and analyzing the dynamics of networks is crucial for developing societal systems that are ecient and robust. In Part I, we study one of the most prominent families of network dynamics, namely, that of spreadingprocesses ,orepidemics . Studyingsuchprocessesisofgreatimportancefor understanding and controlling how, e.g., contagious diseases spread among humans, ideas or fake news spread in online social networks, cascading failures happen in power networks, or computer viruses spread in computer networks, and thus has 1In doing so, some minor redundancy across chapters has been introduced.3 applicationsinmanyareassuchasepidemiology[29],informationpropagation[109, 56], 175], and network spreading processes can be normally described by Markov chains with an exponential number disease-free xed point, whose number of states are linear in the number as a sucient condition for fast extinction of the epidemic in theexact Markov chain model , for the aforementioned propagation models (SIS, SIRS, SEIRS, SIV, and SEIV). In particular, we show that for most propagation models, the global dynamics of the nonlinear model coincides with the stability of the linear model, and takes on one of two forms: either the epidemicdiesout,oritconvergestoanotheruniquexedpoint(theso-calledendemic state where a constant fraction of the nodes remain infected). We tie in these results with the exact Markov chain model by showing that the linear model provides an upper-bound on the true marginal probabilities of infection, and that this is the tightest upper-bound that involves only marginals, in the \"low-infection\" regime. Thisboundimpliesthatunderthespecicthresholdwherethedisease-freestateis aglobally-stablexedpointofthemean-eldmodel,theexactunderlyingMarkov chain has a sublinear mixing time, which means the epidemic dies out quickly. ThethresholdconditionforfastmixingoftheMarkovchainhasbeenshownnotto be tight in several cases, such as in a star network. In Chapter 3 , we Incentives and Markets Asdiscussedearlier,acriticalaspectofdevelopinglarge-scaleintelligentsystems isdesigningincentivesandmarkets,insuchawaythatensuresecientoperation ofthesystemandeectivemanagementoftheavailableresources. Oneofthekey challenges that arises in such markets (and is of critical importance for, e.g., energy markets)isthatof non-convexities . Non-convexitiesincostfunctionsarisedueto start-up or economies of scale,andtheremaybenolinearpricesthatsupportacompetitivemarketequilibrium in their presence[46, 83]. Another important challenge in these markets is that there arenetworkconstraints that have to be taken into account. Despitethelargebodyofworkonthepricingproblem(especiallyduringthepast decade,motivatedbythederegulationoftheelectricitymarketsintheUSandaround the world), the existing schemes have several shortcomings. Most of the existing schemesareproposedfor specicclassesofnon-convexcostfunctions,and cannot handle more general non-convexities. Furthermore, even the ones that are applicable for general cost functions fail to satisfy some of the key desired properties of the market, such as economic eciency or supporting a competitive equilibrium. In addition,noneoftheexistingschemesisaccompaniedbyacomputationallytractable algorithm for general non-convex costs. InChapter 4 , we propose a pricing scheme called Equilibrium-Constrained (EC) pricingfor markets with general non-convex costs that designs arbitrary parametric price functions and addresses all the aforementioned issues. Optimizing simultane- ously for the quantities (allocations) and the price parameters allows our scheme to nd prices that are typically economically more ecient. Further, the ability to use arbitrarilyspeciedparametricpricefunctions(e.g.,piece-wiselinear,quadratic,etc.) enablesourapproachtodesignpricefunctionsthatarelessdiscriminatory,whilestill supportingacompetitiveequilibrium. Further,ourpricingschemeisaccompaniedby acomputationallyecient(polynomial-time)approximationalgorithmwhichallows onetondtheapproximately-optimalscheduleandpricesforgeneralnon-convex cost functions. The proposed framework applies to the case of networked markets as well, which, to the best of our knowledge, had not been considered in previous work. Increasing the penetration of distributed, renewable energy resources into the electricity grid is a crucial part of building a sustainable energy landscape, and the entities that have been most successful at this are aggregators a variety of5 important roles in the construction of a sustainable grid: (1) they are on the front linesofthebattletopromotewidespreadadoptionofdistributedenergyresourcesby householdsandbusinesses,and(2)theyprovideasingleinterfacepointwhereutilities and Independent System Operators (ISOs) can interact with a fleet of distributed energy resources across the network in order to obtain a variety of services, from renewable generation capacity to demand response. However, in addition to the benets they provide, aggregators also create new challenges. On the side of the aggregator,themanagementofageographicallydiversefleetofdistributedenergy resources is a dicult algorithmic challenge. On the side of the operator, the participationofaggregatorsinelectricitymarketspresentsuniquechallengesinterms of monitoring and mitigating the potential of exercising market power. In particular, unlike traditional generation resources, the ISO cannot verify the availability of the generation resources of aggregators, and this creates signicant opportunities for the aggregators to manipulate prices through strategic curtailment of the resources. InChapter 5 , we address both the algorithmic challenge of managing an aggregator andtheeconomicchallengeofmeasuringthepotentialforanaggregatortomanipulate prices. Specically, we provide a new algorithmic framework for managing the participation of an aggregator in electricity markets, and use this framework to evaluatethepotentialforaggregatorstoexercisemarketpower. Tothoseends,we make three main contributions. First, we introduce a new model for studying the market behavior of aggregators of distributed generation in the real-time market. Second,we quantifyopportunitiesforpricemanipulation bytheaggregators. Our results reveal that, in practical scenarios, strategic curtailment can have a signicant impact on prices, and yield much higher prots for the aggregators. In particular, the prices can be impacted up to a few tens of $/MWh in some cases, and there is often more than 25% higher prot, even with curtailments limited to 1%. Third, we provide a novel approach for managing the participation of an aggregator in the market. TheproblemisNP-hardingeneralandisabilevelquadraticprogram,which isnotoriouslydicultinpractice. However,wedevelopanecientalgorithmfor aggregatorsinradialnetworkswhichcanbeusedby theaggregatortoapproximate the optimal allocation strategy and also by the operator to assess the potential for strategic curtailment. 1.4 Synopsis of Part III: Distributed Computation Distributedcomputationisanintegralpartoflarge-scaleintelligentsystems. With thegrowingsizeofdatasets,duetohighcomputationaland/ormemoryrequirements,6 it is increasingly necessary to run the tasks in a distributed fashion. For this reason, parallelanddistributedcomputationhasattractedalotofattentioninrecentyears forlarge-scalecomputingapplications,such asformachine learning [44,173,228, 77]. In order to devise ecient distributed algorithms, one has to address a number ofkeyquestionssuchas: Whatcomputationshouldeachprocessorcarryout? ,What messagesshouldbecommunicatedbetweentheprocessorsandthetaskmaster? ,How does the distributed implementation fare in terms of computational complexity? , What is the rate of convergence in the case of iterative algorithms? , andHow to handle delays and straggling workers? One of the most fundamental problems in linear algebra, which also a key step at the heartofmanyalgorithmsinoptimization,machinelearning,scienticcomputing, andbeyond,isthatofsolvinga large-scalesystemoflinearequations . InChapter6 , we consider a common scenario in which a taskmaster intends to solve a large- scale system of linear equations by distributing subsets of the equations among a number of computing machines/cores. propose a novel algorithm called AcceleratedProjection-basedConsensus(APC) forsolvingthisproblem. Whileeach machinecaneasilynd\"a\"solutiontoitsownunderdeterminedproblem,theoverall solution should be a solution to every machine's problem. The idea is based on a carefully-constructedconsensus,whichensuresthateachmachine'svariableremains a solution to its problem, while moving towards the solutions of the other machines. The convergence behavior of the proposed algorithm is analyzed in detail and is analytically shown to compare favorably with the convergence rate of alternative distributed methods, namely distributed gradient descent, distributed versions of Nesterov's accelerated gradient descent and heavy-ball method, the block Cimmino method, and ADMM. On randomly chosen linear systems, as well as on real-world data sets, the proposed method oers order-of-magnitude speed-up relative to the aforementioned methods. When a task is divided among a number of machines, while the computation time of eachmachineissignicantlyreduced,thetaskmasterhastowaitforallthemachines in order to be able to recover the desired computation. One issue faced in practice is the delay incurred due to the presence of slow machines, known as stragglers . In the face of substantial or heterogeneous delays, distributed computing may suer from being slow, which defeats the purpose. Several approaches have been proposed totacklethisproblem. Onenaiveyetcommonwayistonotwaitforallmachines, and ignore the straggling machines. One may hope that in this way, on average, the7 taskmaster receives enough information from everyone; however, in many cases, the overall performance may be negatively impacted because of the lost updates. Analternativeandmoreappropriatewaytoresolvethisissueistointroducesome redundancy in the computation of the machines, in order to eciently trade o computation time for less wait time, and to be able to recover the correct update using only a few machines. Over the past few decades, coding theory was developed to address similar challenges in other domains such as mobile communication, storage, data transmission, and broadcast systems. Recently, [198] considered a distributedgradientdescentsetting forlarge-scalemachinelearning,andproposed the idea of gradient coding , which uses coding theory to cleverly distribute each gradient iteration across a number of machines in an ecient way. However, the computationalcomplexityoftheirdecodingalgorithmwasquitehigh(cubicinthe number of returning machines). InChapter 7 , we develop a deterministic scheme that, for a prescribed per-machine computational eort, recovers the gradient from the least number of machines theoretically permissible , via a decoding algorithm that is an order of magnitude fasterthanthestateoftheart. TheideaisbasedonasuitablydesignedReed-Solomon code that has a sparsest and balanced generator matrix [88]. Empirical results have demonstrated the clear advantage of our method over competing schemes. 1.5 Synopsis of Part IV: Learning from Data During the past decade, machine learning, and largely deep learning , has made a remarkable impact in many domains, and has enjoyed a great deal of success in a wide variety of tasks, such as computer vision, speech recognition, natural languageprocessing,recommendersystems,bioinformatics,andvideo-andboard- game playing. While incredibly successful in many respects, the reasons behind the greatsuccessof thesemethods(aswellastheirfailures insomeotherrespects) are largely unexplained. A theoretical foundation that backs these methods is crucial for understandingtheircapabilitiesandlimitations,andformakingthemapplicableto domainsinwhichtheyhavenotbeenyetsuccessful,andultimatelyboostingprogress towards intelligent systems. Due to the nonlinear nature of deep neural networks, their loss function is in general highlynon-convex . However, empirically, practitioners often obtain zero training error,i.e.,a globalminimum ofthetrainingloss,acrossvariousdatasets,architectures, and settings [224]. This phenomenon is due to the heavy overparameterization8 presentintypicaldeepmodels(\"tensofmillions\"ofparametersfor\"tensofthousands\" of data points). In other words, these highly overparameterized models have a lot of capacity, which allows them to perfectly t/interpolate the training data, so much so that this regime has been called the interpolating regime [138]. What is surprising, however, is that, contrary to the conventional wisdom which says achieving zero trainingerror(akaovertting)isharmfulforgeneralization(out-of-sampleerror), these deep models, trained with simple stochastic gradient descent (SGD) or its variants,generalize quitewelltounseendata. Thelossfunctionofthesedeepmodels has in fact (innitely) which can have drastically dierent generalizationproperties(infact,therearemanyglobalminimathatperformvery poorlyonthetestset),andstochasticdescentalgorithmsseemtoconvergeto\"special\" ones that generalize well, even in the absence of any explicit regularization or conditions, and which implies the minimax optimality of SMD (and SGD) for suciently small step size, and for a general class oflossfunctionsandgeneralnonlinearmodels. Wefurthershowthatthisidentity can be used to naturally establish other properties of SMD (and SGD), namely convergence and implicit regularization for over-parameterized linear models (in what is now being called the \"interpolating regime\"), some of which have been shown in certain cases in prior literature. InChapter 9 , we show that, for highly overparameterized nonlinear models, the SMD algorithm for any particular potential function converges to a global minimum that is approximately the closest one to theinitialization, in termsof the Bregman divergence corresponding to the potential used. For the special case of SGD, this means that it converges to a global minimum which is approximately the closest one to the initialization in the usual Euclidean sense. This result further implies that, wheninitializedaroundzero, SGDactsasan \u00122-normregularizer ,aphenomenon referred to as implicit regularization (in linear models [85, 194]). Similarly, by choosing other mirrors, one obtains dierent forms of implicit regularization, which mayhavedierentperformances onthetestdata. Ourexperimentalresults9 indeed showed a clear dierence in the generalization performance of the solutions obtainedviadierentSMDregularizers. dierent generalization performance than the minimum- \u00121-norm solution. This surprising result strongly suggests the importance of developing a generalization theory for the overparameterized/interpolating regime and the choice of regularizers. InChapter 10 , we exhibit a new interpretation of SMD, namely that it is a risk- sensitiveoptimal estimatorwhentheunknownweightvectorandadditivenoiseare non-Gaussian and belong to the exponential family of distributions. The analysis also suggests a modied version of SMD, which we refer to as symmetric SMD (SSMD). The proofs rely on some simple properties of Bregman divergence, which allow us to extend results from quadratics and Gaussians to certain convex functions andexponentialfamiliesinaratherseamlessway. Furthermore,forvanishingstep sizeSMD,andinthestandardstochasticoptimizationsetting,wegiveadirectand proof of convergence for SMD to the \"true\" parameter vector, which avoids ergodic averaging or appealing to stochastic dierential equations.Part I Network Dynamics 1011 C h a pte r 2 EPIDEMICS OVER COMPLEX NETWORKS: ANALYSIS OF EXACT AND APPROXIMATE MODELS [1]NavidAzizanandBabakHassibi.\"SIRSepidemicsoncomplexnetworks: Concurrence of exact Markov . Understanding and analyzing the dynamics of networks is crucial for developing societalsystemsthatarerobustandecient. Here,westudyoneofthemostimportant familiesofnetworkdynamics,namely,thatofspreadingprocesses,orepidemics. We considerthespreadofdiscrete-timeepidemicsoverarbitrarynetworksforwell-known propagation iscomplicated,variouslinearandnonlinearlower-dimensionalapproximationsof them have been proposed and studied in the literature. The most common of these is thenonlinear\"mean-eld\"approximationanditslinearizationaroundthedisease-free xedpoint,whosenumbersofstatesarelinearinthenumberofnodes. Theresultswe review are for both the exact models and the approximated ones, with a focus on the connectionsbetweenthem. Sincethelinearmodelistherst-orderapproximationof the nonlinear mean-eld one at the disease-free equilibrium, its stability determines thelocalstabilityofthenonlinearmodel. Furthermore,formostpropagationmodels, theglobaldynamicsofthenonlinearmodelalsocoincideswiththestabilityofthe linear model, and takes on one of two forms: either the epidemic dies out, or it convergestoanotheruniquexedpoint(theso-calledendemicstatewhereaconstant Markovchainmodel. Weshowthatthelinearmodelprovidesanupper-boundonthe truemarginalprobabilitiesofinfection,andthat(inacertainregime)itisthetightest though the nonlinear modelisnotanupper-boundonthetrueprobabilitiesingeneral,itdoesprovidean12 upper-bound on the probability of the chain not being in the all-healthy state. These bounds also imply the well-known result of sublinear mixing time of the Markov chain (epidemic extinction) when the disease-free xed point is globally stable in the mean-eld model. We compare these results for dierent propagation models in detail and provide a concise summary of them. 2.1 Introduction Epidemicmodelshavebeenextensivelystudiedsincearstmathematicalformulation was introduced in 1927 by Kermack and McKendrick [113]. Although the classical models mostly neglected the underlying network structure, and assumed a uniformly mixed population, a huge body of work on more realistic networked models has emerged in the recent years. Modeling and analysis of epidemics plays a key role inmanyareassuchasepidemiology[29],informationpropagation[109,56],viral marketing[168,175],andnetworksecurity[8,2]. Inparticular,themodelsdeveloped intheliteraturecanbeusedtounderstandvariousspreadingprocessesovernetworks such as the adoption of an idea or fake news in an online social network (Facebook, Twitter,etc.),theconsumptionofanewproductinamarket,orthespreadofcomputer viruses over the Internet. Questions of interest include the existence of xed points, stability(whethertheepidemicdiesoutorspreads),transientbehavior,thecostofan epidemic [40, 43], how best to control an epidemic [66, 156], etc. As in the majority of the literature, we adopt the terminologies of infectious diseases throughout thischapter. Theresults thatwe In the basic SIS model, each node in the network is in one of two dierent states: susceptible (healthy) or infected. A healthy node has a chance of getting infected if it has infected neighbors in the network. The probability of gettinginfectedincreasesasthenumberofinfectedneighborsincreases. Aninfected node also has a chance of recovering, after which it still has a chance of getting infectedbyitsneighbors(thefluisanexampleofthismodel). SIRandSIRSmodels haveanextrarecoveredstate,whichcorrespondstothenodesthathaverecovered from the disease and are not susceptible to it (mumps and pertussis respectively are examples of SIR and SIRS epidemics [102]). In some models, such as SEIRS, exposed(E)andinfected/infectious(I). Thenodesinanexposedstatehavebeenexposedtothediseasebutarenotinfectious13 yet. Additionally, in SIV and SEIV models, there is a random vaccination (either permanentortemporary)whichpermitsdirecttransitionfromthesusceptiblestate to the recovered (vaccinated) state. EventheSIScase,whichisthesimplestoftheabovemodels,foranetworkwith = nodes,yieldsaMarkovchainwith 2=states,sometimescalledtheexactor\"stochastic\" model. This is a discrete-space model, as there are two possible states of \"0\" and \"1\" for healthy and infected. Ostensibly, because analyzing this Markov chain is toocomplicated,various =-dimensionallinearandnon-linearapproximationshave been proposed in the literature. The most common of these is the =-dimensional non-linearmean-eldapproximationanditscorrespondinglinearizationaboutthe disease-freexedpoint,whichareoftenreferredtoas\"deterministic\"models. These are continuous-space models, that take real numbers between 0 and 1, which can be understood as the marginal probability for being infected (or the infected fraction of the8-th subpopulation). Itisworthnotingthatalltheabovemodelshavealsobeenstudiedintwodierent settings: continuous-time and discrete-time. In [76, 205,72, 187, 5, 170, 6]) epidemics. Even though the models are similar in many aspects, depending on the application in hand, it may make more sense to use one or the other. Here, we choose to focus on discrete-time models, but most of the results have counterparts in continuous-time as well. The results we review are for both the exact and approximated models, with a focus on the connections between them. It is well known that, in many cases, the linear modelisanupper-boundonthenonlinearmean-eldapproximation. Itisalsoknown that,dependingonthelargesteigenvalueoftheunderlyinggraphadjacencymatrix and the epidemic parameters, the global dynamics of the mean-eld approximation takesononeoftwoforms: eithertheepidemicdiesout(disease-freexedpoint)orit convergestoanotheruniquexedpointwhereaconstantfractionofthenodesremain infected (endemic state). As for the exact Markov chain model, the linear model providesanupper-boundonthetruemarginalprobabilitiesofinfection,andweshow that this is the tightestupper-bound using the marginals only, when the infection probabilities are not too high. Furthermore, even though the nonlinear model is not an upper-bound on the true probabilities in general, it does provide an upper-bound ontheprobabilityofthechainnotbeingabsorbed(somenodesbeinginfected). A consequence of these upper-bounds is that when the approximated model is stable to14 the disease-free xed point, the Markov chain has a mixing time of $\u00b9log=\u00ba, which means the epidemic dies out fast in the true model as well. In Section 2.2, we review the main epidemic models introduced in the literature. Foreachoneofthesespreadingprocesses,westatetheexactMarkovchainmodel, thenonlinearmean-eldapproximation,andthelatter'slinearization. Section2.3 concerns the results on the nonlinear model (and its connection to the linear model) for dierent spreading processes mentioned earlier. We rst describe the case where theepidemicdiesout,andthenthecasewheretheall-healthyxedpointisnotstable andthereexistsauniquenontrivialxedpointwhichistypicallystable. Returning backtotheexactMarkovchainmodel,inSection2.4,weestablishtheconnection betweenthatandtheapproximatedmodels. Inparticular,werststatetheconnection to the linear marginals, and the sucient conditionforfastmixing),andthenproceedtotheconnectiontothenonlinearmodel (upper-boundontheprobabilityofthechainnotbeingabsorbed). Wealsoreviewthe extensions to heterogeneous models in Section 2.5, and mention higher-order (such as pairwise) approximations in Section 2.6. We nally summarize and conclude in Section 2.7. 2.2 Models Inthissection,wediscusssomeofthemainepidemicmodels. Additionalmodels can be found in Appendix 2.A. 2.2.1.1 Exact Markov Chain represents the state ofa node at time C, i.e.,8is infected if b8\u00b9C\u00ba=1, and it is healthy if b8\u00b9C\u00ba=0. Given the current state b\u00b9C\u00ba, the infection probability of each node in the next step is determinedindependently,andthereforethetransitionmatrix (ofthisMarkovchain has elements (-\u0096.=P\u00b9b\u00b9C\u00b81\u00ba=.jb\u00b9C\u00ba=-\u00baof the following form: P\u00b9b\u00b9C\u00b81\u00ba=.jb\u00b9C\u00ba=-\u00ba==\u00d6 8=1P\u00b9b8\u00b9C\u00b81\u00ba=.8jb\u00b9C\u00ba=-\u00ba\u0096(2.1)15 Figure 2.1: State diagram of a in dierent models. Wavy arrows representexogenous(network-based)transition. (standsforsusceptible(healthy), \u001a for exposed, for infected/infectious, and 'for recovered. for any two state vectors -\u0096.2f0\u00961g=. A healthy node remains healthy if all its neighbors are healthy. During each time epoch, nodes in the healthy (susceptible) state can be infected by their infected neighbors according to independent events with probability V(theinfection rate ) each. Moreover, nodes that are infected can recover during each such time epoch withprobability X(therecoveryrate ),iftheydonotgetinfectedagainatthesame node 8, and16 S\u00b9-\u00ba=f8:-8=1gis the support of -2f0\u00961g=, i.e., the set of infected nodes. This Markov chain has a unique absorbing state, which is the state where all the nodes in the network are healthy with probability 1. This is an absorbing state since there is a non-zero probability of reaching it from any other state in a single step, andbecauseonceallthenodesarehealthy,nonodewillbeexposedtothedisease, and they will always stay healthy. This means that the disease will die out if we wait longenough. However, thisresultisnotveryrevealing, sinceitmaytakealongtime for the diseaseto die out, and therefore, the more importantquestion is whether the Markov chain is fast-mixing or whether its mixing time is exponentially large. Comparingthediscrete-timeMarkovchainmodeltothecontinuous-timeMarkov chain model described in [76], the continuous-time Markov chain model allows only oneflipofeachnode'sepidemicstateateachmoment. However,thediscrete-time model allows change of epidemic states for more than one node at each time step. The reason being that the change of epidemic state for two or more nodes can occur at same time interval, even though they do not happen at the same moment. The transition matrix ofthe embeddedMarkovchain ofthe continuous-timemodel has nonzero entries only where the Hamming distance of the row coordinate and the column coordinate is 1 (they dier in only one element). However, the transition matrixofthediscrete-timeMarkovchainmodelcanhavenonzeroentrieseverywhere (except the row of the absorbing state). Let us denote the probability that node 8is infected at time Cby?8\u00b9C\u00ba=P\u00b9b8\u00b9C\u00ba=1\u00ba. The probability of node 8being infected at time C\u00b81can then be written as ?8\u00b9C\u00b81\u00ba=P\u00b9b8\u00b9C\u00b81\u00ba=1jb8\u00b9C\u00ba=1\u00baP\u00b9b8\u00b9C\u00ba=1\u00ba \u00b8P\u00b9b8\u00b9C\u00b81\u00ba=1jb8\u00b9C\u00ba=0\u00baP\u00b9b8\u00b9C\u00ba=0\u00ba\u0095 (2.3) By marginalizing out the state of the other nodes, we can write this model that requires only knowledge of the model assumes that the events that the neighbors are infected are independent. We use capital %for the approximated probabilities, to distinguish them from the exact probabilities of the Markov chain, ?. Itissometimesconvenienttodeneandworkwithamap \b:\u00bb0\u00961\u00bc=!\u00bb0\u00961\u00bc=with elements dened as \b8\u00b9G\u00ba=\u00b91\u0000X\u00baG8\u00b8\u00b91\u0000\u00b91\u0000X\u00baG8\u00ba 1\u0000\u00d6 \u0095(2.6) that MFA becomes %8\u00b9C\u00b81\u00ba= \b8\u00b9\u00bb%1\u00b9C\u00ba\u0096\u0095\u0095\u0095\u0096%=\u00b9C\u00ba\u00bc)\u00ba. The MFA is an =-dimensional demandingthanthetrue 2=-dimensionalmodel. TheMFAhasbeenstudiedin[57, 208,5]amongothers. Theorigin( %1\u00b9C\u00ba=\u0095\u0095\u0095\u0096=%=\u00b9C\u00ba=0)isatrivialxedpoint of the above model, which is consistent with the absorbing state of the Markov chain model. 2.2.1.3 Linear Model Onestepfurtheristoapproximatetheprecedingequationsbylinearizing (2.5)around the origin, which results in the following mapping: %8\u00b9C\u00b81\u00ba=\u00b91\u0000X\u00ba%8\u00b9C\u00ba\u00b8V \u00d5 92#8%9\u00b9C\u00ba! (2.7) Putting together the equations of this form for all 8, one can see this as %\u00b9C\u00b81\u00ba=\u00b9\u00b91\u0000X\u00ba =\u00b8V\u0016\u00ba%\u00b9C\u00ba\u0096 (2.8) where %\u00b9C\u00ba=\u00bb%1\u00b9C\u00ba\u0096\u0095\u0095\u0095\u0096 %=\u00b9C\u00ba\u00bc). Note that\u00b91\u0000X\u00ba =\u00b8V\u0016is in the origin.18 2.2.2 Susceptible-Infected-Recovered-Susceptible (SIRS) In the SIRS model, there is an additional \"recovered\" (R) state (see Fig. 2.1). As before, nodes in the susceptible state can be infected by their infected neighbors accordingtoindependenteventswithprobability Veach. Nodesthatareinfectedcan recover with probability X, and nodes in the recovered state can randomly transition to the susceptible state with probability W(immunization loss ). 2.2.2.1 Exact Markov Chain Model We start again with the exact Markov chain model. The state of node 8at time C, denoted by b8\u00b9C\u00ba, can take one of ,1for Infected(or Infectious), and 2forRecovered , i.e.,b8\u00b9C\u00ba2f0\u00961\u00962g. The of the entire network can be represented as: b\u00b9C\u00ba=\u00b9b8\u00b9C\u00ba\u0096\u0095\u0095\u0095\u0096b=\u00b9C\u00ba\u00ba2f0\u00961\u00962g=\u0095 (2.9) The3=\u00023=state transition matrix (of the Markov chain has elements of the form state at19 timeC, respectively. Then, ?(\u00968\u00b9C\u00bais determined by the other two probabilities as 1\u0000?'\u00968\u00b9C\u00ba\u0000? \u00968\u00b9C\u00ba. Basedontheabove-mentionedtransitionrates,wecancalculate the two marginal 2.2.2.2 Nonlinear Themean-eldapproximationoftheabovemarginalprobabilitieshasbeencommonly considered, which nonlinear mapping with 2=states (rather than 3=states). 2.2.2.3 Linear Model Linearizations of Eqs. (2.14)and(2.15)around the origin can be considered as well, which results in the mapping %'\u00968\u00b9C\u00b81\u00ba=\u00b91\u0000W\u00ba%'\u00968\u00b9C\u00ba\u00b8X% \u00968\u00b9C\u00ba\u0096 (2.16) % for all 8can in a matrix form as \"%'\u00b9C\u00b81\u00ba % =\"\"%'\u00b9C\u00ba SIV model accounts for the eect of vaccination by incorporating direct immunization into the SIRS model. In other words, the transition from (to'is also permitted in this model (see Fig. 2.1). Depending on the value of W, this model can represent temporary ( W<0) or permanent ( W=0) immunization. Based on the ecacy of the vaccine, there are two variants of this model: infection-dominant and vaccination-dominant. In the infection-dominant case, if a susceptible node receives both infection and vaccine at the same time, it gets infected. In this case, the elements of the state transition matrix are (-\u0096.=P\u00b9b\u00b9C\u00b81\u00ba=.jb\u00b9C\u00ba=-\u00ba==\u00d6 Eq. (2.11) in the rst and third cases, and it reduces to the SIRS model for \\=0. Thesteady-statebehaviorinthepresenceofimmunizationisratherdierentfrom the previous models, in which all the nodes became susceptible. In this model, once there is no node in the infected state, the Markov chain reduces to a simpler Markov chain, wherethe nodesare In an independent transitionprobability between (and'. The stationary distribution of each single node is then 8=1\u00b9W W\u00b8\\\u00baI\u00b9-8=0\u00ba\u00010I\u00b9-8=1\u00ba\u0001\u00b9\\ W\u00b8\\\u00baI\u00b9-8=2\u00ba\u0095 Figure 2.2: Reduced Markov chain a single node in the steady state. veried that one xed point of this nonlinear map occurs at %'\u00968\u00b9C\u00ba=%\u0003 \u0096 which is the the notation D\u0016Eto indicate D8\u0014E8for all82f1\u0096\u0095\u0095\u0095\u0096=g, andD E, if the Dening %\u00b9C\u00ba=\u00bb%1\u00b9C\u00ba\u0096\u0095\u0095\u0095\u0096%=\u00b9C\u00ba\u00bc), we have %\u00b9C\u00b81\u00ba\u0016\u00b9\u00b9 1\u0000X\u00ba =\u00b8V\u0016\u00ba%\u00b9C\u00ba\u0096 (2.26) which leads to the following well-known result. Proposition 1. IfV_max\u00b9\u0016\u00ba X\u009f1, the origin is a globally asymptotically stable xed point for both the linear SIS model (2.8)and the nonlinear SIS model (2.5). Theorigin,thetrivialxedpointofthenonlinearmodel,isunstablewhen _<0G\u00b9\u00b91\u0000 X\u00ba =\u00b8V\u0016\u00ba\u00a11. Moreover, if so, it is not clear in general whether there exists any23 Figure2.3: Summaryofknownresultsfordierentmodels. approximation (the nonlinear model). other xed point, or how many xed points there are. It has been shown in the literature (e.g., in [5]) that there exists a unique nontrivial xed point, and it is stable. Theorem2. IfV_max\u00b9\u0016\u00ba X\u00a11,thenonlinearSISmodel (2.5)hasaseconduniquexed point. Furthermore, the xed point is globally asymptotically stable from all initial points (except the origin). 2.3.2 SIRS/SEIRS/Immune-Admitting-SIS Similar to the previous (immune-free) SIS model, for the immune-admitting-SIS, SIRS,andSEIRSepidemics, thelinearmodelisanupper-boundonthenonlinear one, and therefore the origin is stable for the nonlinear model when the linear model is stable. Proposition 3. IfV_max\u00b9\u0016\u00ba X\u009f1, the origin is a globally andthe nonlinearmodelforimmune-admitting-SIS, SIRS, and SEIRS epidemics. In this case, when the origin is not stable, even though there still exists a unique nontrivial xed point, it is not stable in general [5, 16]. Theorem 4. IfV_max\u00b9\u0016\u00ba X\u00a11,thenonlinearmodelforimmune-admitting-SIS,SIRS, and SEIRS epidemics has a second unique xed point.24 The following is an example of an unstable nontrivial xed point for the immune- admitting-SIS model [4, p. 64]. A=\u00a9\u00ad\u00ad \u00ab0 1 0 of \u00001\u0095059, which means that %\u0003is not locally stable. It can beshownthatforanyinitialconditionothertheoriginand %\u0003,%\u00b9C\u00baconvergestoa cycle. Eventhoughthenontrivialxedpointisnotstableingeneral,itisknowntobestable with high probability for a general family of random graphs [4, p. 66]. Theorem 5 (Ahn and Hassibi [5]) .Suppose that \u00b9=\u00bais a random graph with = vertices, and let 3\u00b9=\u00ba minand3\u00b9=\u00ba maxdenote the minimum and xed VandX. One can think of several random graph models that satisfy the condition of Theorem 5. Forexample,iftherandomgraphhasauniformdegreethatgrowswith =,then the minimum degree and maximum degree are identical and the ratio32 min 3max=3will growwithany =andexceed0withhighprobability. Similarly,forrandomgraphs where the degree distribution of the nodes are identical and concentrate, so that we can expect the maximum degree and the minimum degree to be proportional to the expected degree,32 min 3maxgrows if the expected degree increases unbounded with =. In particular, the Erd\u00f6s-R\u00e9nyi random graph \u00b9=\u00ba= \u00b9=\u0096?\u00b9=\u00ba\u00bahas identical degree distribution, and we have the following result [4, p. 69]. Corollary 6 (Ahn and Hassibi graph xed VandX. Since?=2log= =for2=1is also the threshold for connectivity, we can say that connected Erd\u00f6s-R\u00e9nyi graphs have a nontrivial stable xed point with high probability. Therandomgeometricgraph \u00b9=\u00ba= \u00b9=\u0096A\u00b9=\u00ba\u00baalsohasidenticaldegreedistribution if each node is distributed uniformly. Such random graphs have maximum and minimumdegreeswhichareproportionaltotheexpecteddegreewithhighprobability ifA\u00b9=\u00baissmallerthanthethresholdofconnectivity[167],and,similartoErd\u00f6s-R\u00e9nyi graphs, it has high probability of having a nontrivial stable xed point if the degree grows with=. 2.3.3 SIV/SEIV (Infection-Dominant) Since the linear model is always the Jacobian of the nonlinear one, its stability determines the local stability of the nonlinear model. However, global stability is hardertoshow. Thefollowingresultsummarizesthestabilityofthenonlinearmodel. Proposition 7. The disease-free xed point of the nonlinear model for the infection- dominant SIV and the epidemics is a) stable, ifV X\u00a11,themainxedpointofthenonlinearmapisnotstable,and again, there exists a unique non-trivial xed point. This result has been proven in [16] for the SIV case, and it extends to the SEIV model in a similar fashion. Theorem 8. IfW W\u00b8\\V_max\u00b9\u0016\u00ba X\u00a11, the the infection-dominant SEIV epidemics has a second unique xed point. The middle panel in Figure 2.3 shows a summary of the above results. 2.3.4 SIV/SEIV locally stable, if \u00b91\u0000\\\u00baW dominantSIVandthevaccination-dominantSEIVepidemicshasasecondunique xed point. Bothoftheaboveresultshavebeenprovenin[16]fortheSIVcase,andtheproof extends to the SEIV case with some modication. The lower panel in Figure 2.3 shows a summary of these results. 2.4 Results on the Exact Markov Chain Model ReturningbacktotheMarkovchainmodel,inthissection,westudythetruemarginal probabilities of infection and how they relate to the nonlinear and linear models. For the sake of simplicity, we state the results for the SIS model, but they have counterparts for other propagation models as well. 2.4.1 Connection to the Linear Model It is well-known that the linear model provides an upper-bound on the true marginal probabilities of infection [6]. Proposition 11. For SIS epidemics, the linear model is an upper-bound on the true marginal probabilities of infection, i.e., ?8\u00b9C\u00b81\u00ba\u0014\u00b9 1\u0000X\u00ba?8\u00b9C\u00ba\u00b8V\u00d5 92#8?9\u00b9C\u00ba\u0096 for8=1\u0096\u0095\u0095\u0095\u0096=, and any time C. This can be equivalently expressed in vector form as ?\u00b9C\u00b81\u00ba\u0016\u00b9\u00b9 1\u0000X\u00ba =\u00b8V\u0016\u00ba?\u00b9C\u00ba\u0095 (2.28) \u00b91\u0000X\u00ba =\u00b8V\u0016is the system matrix of the linear model. A natural question to ask about the above bound is how tight is it. It is clear that the bound cannot be tight in general, as we are ignoring the higher-order dependencies27 (e.g.,pairwiseinfectionprobabilities,etc.). However,wecanaskhowtightisitamong all the bounds that involve only the marginal probabilities. It turns out that when the infection probabilities are not too high, this bound is indeed the tightest bound using marginals only. In other words,if in the SIS model, we maximize ?8\u00b9C\u00b81\u00baover all distributions with xed marginals ?1\u00b9C\u00ba\u0096\u0095\u0095\u0095\u0096?=\u00b9C\u00ba, in the low-infection regime, we obtain the same bound. Theorem12. For SIS epidemics, if\u00cd= 8=1?8\u00b9C\u00ba\u009f1, then the tightest upper-bound on ?8\u00b9C\u00b81\u00bathat involves only the marginal probabilities at time Cis ?8\u00b9C\u00b81\u00ba\u0014\u00b9 1\u0000X\u00ba?8\u00b9C\u00ba\u00b8V\u00d5 92#8?9\u00b9C\u00ba\u0096 for any8=1\u0096\u0095\u0095\u0095\u0096=. It has been shown that when the linear and nonlinear models are stable (i.e., V_max\u00b9\u0016\u00ba X\u009f1), then the epidemic dies out quickly. More specically under this condition,theMarkovchainhasfast\"mixing\"totheall-healthystate. Themixing time of as (2.29) where`is any initial probability distribution dened on the state space, and cis the stationary distribution. k\u0001k)+is total variation distance which measures distance of two probability distributions. Total variation distance of two probability measures ` and`0is dened by k`\u0000`0k)+=1 2\u00d5 Gj`\u00b9G\u00ba\u0000`0\u00b9G\u00baj (2.30) whereGis any possible state in the probability space. In fact, C<8G\u00b9n\u00bais the smallest timewheredistancebetweenthestationarydistributionandprobabilitydistributionat timeCfromanyinitialdistributionissmallerthanorequalto n. Roughlyspeaking,the mixing time measures how fast initial distribution converges to the limit distribution. The fast (logarithmic) mixing-time result was rst shown by Ganesh et al [76]. Theorem13. IfV_max\u00b9\u0016\u00ba X\u009f1, the mixing time of the Markov chain whose transition matrix(is described by Eqs. (2.1)and(2.2)is$\u00b9log=\u00ba. The above condition for fast extinction of the epidemic seems to be quite tight in many cases, suchas in Erds-R\u00e9nyi random graphs. In particular, Figure 2.4 shows28 0 200 400 600 800 100001002003004005006007008009001000 Time StepNumber of Infected Nodes /bardblA/bardbl = 1.01 /bardblA/bardbl = 0.99 Figure 2.4: A typical example of the evolution of an SIS epidemic over an Erds- R\u00e9nyi graph with ==2000nodes and_max\u00b9\u0016\u00ba=16\u0095159. When (e.g., V=0\u0095055,X=0\u00959) the epidemic decays exponentially, and out quickly (blue curve). In contrast, whenV_max\u00b9\u0016\u00ba X\u00a11(e.g.,V=0\u0095056, X=0\u00959), the epidemic does not exhibit convergence to the disease-free state in anyobservabletime(redcurve). Infact,theepidemickeepsspreadingaroundthe and (2) whenV_max\u00b9\u0016\u00ba X=1\u009501. As one can see, there is a sharp phase transition happening around this critical value. In other words, the epidemic does not seem to die out in any reasonable amount of time onceV_max\u00b9\u0016\u00ba Xis somewhat above 1. 2.4.2 Connection to the Nonlinear Model The nonlinear model is not an upper-bound on the true probabilities ?8\u00b9C\u00bain general. However, it turns out that it does provide an upper-bound on the probability that the chain is not in the all-healthy state (i.e., existence of infection) [4], if one initializes the nonlinear model from the all-infected state. Theorem 14. For any time Cand any initial state -, we have P\u00b9b\u00b9C\u00ba<\u00af0jb\u00b90\u00ba=-\u00ba\u00141\u0000\u00d6 82S\u00b9-\u00ba\u00001\u0000\bC 8\u00b91=\u00ba\u0001\u009629 where\b\u00b9\u0095\u00bais the nonlinear approximate model. Using this bound, the same mixing time result as in (13) can also be established. We should nally remark that the reason why it is possible for the nonlinear map toconvergetoauniquenon-originxedpointwhenV_max\u00b9\u0016\u00ba X\u00a11,eventhoughthe original Markov chain model always converges to the all-healthy state, is that this is only an upper bound on P\u00b9b\u00b9C\u00ba<\u00af0jb\u00b90\u00ba=-\u00ba. In other words, if the origin is globally stable in the epidemic map \b, we can infer that the Markov chain model mixesfast. However,iftheoriginintheepidemicmapisunstable,wecannotinfer anything about the mixing time. 2.5 Heterogeneous Network Models In the models discussed throughout the chapter, the epidemic parameters V\u0096X\u0096W\u0096n\u0096\\ werehomogeneousacrossthenetwork,i.e.,theywerethesameforallnodes. However, many of the results have been extended to more general heterogeneous models. FortheSISmodel,muchofthebehaviorofthemodelswasdeterminedbythelargest eigenvalue of \"=\u00b91\u0000X\u00ba =\u00b8V\u0016.\"is dened by V, the infection theadjacency infection matrix where <8\u009692\u00bb0\u00961\u00bcrepresents the infection probability that 8is infected at time C\u00b81when9is the only infected node at time C. In this setting, each diagonal entry <8\u00968represents self-infection rate. In other words, 1\u0000<8\u00968is the recovery rate of node 8, and<8\u00968is the probability that 8stays infected when there are no other infected nodes in the network. We also assume that probability of infection of each node given the current state b\u00b9C\u00bais independent. More precisely, for any two state vectors -\u0096.2f0\u00961g=, P\u00b9b\u00b9C\u00b81\u00ba=.jb\u00b9C\u00ba=-\u00ba==\u00d6 8=1P\u00b9b8\u00b9C\u00b81\u00ba=.8jb\u00b9C\u00ba=-\u00ba(2.31) Probability transition from given state P\u00b9b8\u00b9C\u00b81\u00ba=.8jb\u00b9C\u00ba=-\u00ba=8>>>> < >>>>:\u00d6 of \b\u00b9\"\u00ba\u00b9\u0001\u00baat the origin which gives an upper bound, i.e., \b\u00b9\"\u00ba\u00b9G\u00ba\u0016\"G. The origin is the unique xed point which is globally stable if the largest eigenvalue of \"is smaller than 1. It also has a unique nontrivial xed point which is globally stable if the largest eigenvalue of \"is greater than 1. Similartothepreviouscases, _max\u00b9\"\u00ba\u009f1guaranteesthatthemixingtimeofthe Markov chain by the transition Pairwise and Higher-Order Approximate Models EventhoughthethresholdconditionofTheorem13forfastextinctionoftheepidemic (sublinear mixing time of the Markov chain) appears to be tight for the Erds-R\u00e9nyi random graph and some other networks, it is known to not be tight for several other cases, such as the star graph [23]. Inordertoobtaintighterthresholdconditions,onecankeeptrackoftermsthatareof a higher order than the marginals, such as pairwise probabilities of infection, triples, etc. Of course, this comes at the cost of an increased number of states (quadratic, cubic, etc. in the number of nodes), and there is a trade-o between the tightness oftheboundandthecomplexityofthemodel. Intheory,ifonetakesintoaccount all marginals, pairs, triples, and higher-order terms, we get back to the original exponential-state Markov chain model. Tighterboundsusingpairwiseprobabilitieswillbethesubjectofthenextchapter. Theseboundswererstintroducedin[23],andhavebeenextendedtoheterogeneous modelsin[160]. Otherpairwiseapproximationshavealsobeenstudiedin[54]but they do not provide any bound on the exact probabilities. 2.7 Summary and Conclusion We studied the networked SIS, SIRS, SEIRS, SIV, and SEIV epidemics and their using their exact Markov chain models, and their well-known linear and nonlinearmean-eldapproximations. Belowathreshold,thedisease-freexedpoint is globally stable for the nonlinear model, and also the mixing time of the exact Markov chain is $\u00b9log=\u00ba, which means the epidemic dies out fast. Furthermore,31 100101102103100101102103 Time StepNumber of Infected 0.99<1 Time Erds-R\u00e9nyi graph with ==2000nodes. The blue curves show fast extinction of the epidemic. The red curves show epidemic spread around the nontrivial xed point.32 aboveathreshold,thedisease-freexedpointisnotstableforthelinearandnonlinear models, and there exists a second unique xed point, which corresponds to the endemic state. This nontrivial xed point is also stable in most cases. Figure 2.3 summarizes all the results. Typical examples of the spread ofthe epidemic for all dierent propagation models studied throughout the chapter have been demonstrated in Figure 2.5. For the SIRS and SEIRS models, the threshold condition isVk\u0016k X\u009f1, which is the same as that of theSISone,anditmeanshavinganadditionalrecoveredstatedoesnotnecessarily make the system more stable. For the infection-dominant SIV and SEIV models, we observethesameexponentialdecayoftheinfectionwhenW W\u00b8\\Vk\u0016k thevaccination-dominant models, under\u00b91\u0000\\\u00baW W\u00b8\\Vk\u0016k X\u009f1(e.g.,V=0\u009522), we observe the fast convergence again, which conrms that the system is even more stable when vaccination is dominant. As plots show, for above-the-threshold cases (e.g., V=0\u009507for SIRS, 0\u009513forSIV-infection-dominant,and 0\u009529forSIV-vaccination-dominant),wedonot observe epidemic extinction in any reasonable time, and eectively, the epidemic remains endemic. Finally, we should remark that characterizing the exact epidemic threshold of the Markov chain model is still an open problem. Extensive numerical simulations suggesttheexistenceofsuchathresholdandaphasetransitionbehavior. Eventhough in certain networks, such as the Erds-R\u00e9nyi random graphs, the epidemic threshold seemstocoincidewiththeconditionforlocalstabilityofthenonlinearmean-eld model (global stability of the linear model), it is dierent from that condition in general. Forthisreason,pairwise(andevenhigher-order)approximationsmaybe sought, which provide tighter bounds on the epidemic threshold.33 2.A Additional Models We review additional epidemic models, namely the immune-admitting variant of the SISmodel,theSIERSmodel,thevaccination-dominantvariantoftheSIVmodel, and the SEIV model. SIS 2.A.1.1 Exact Markov Chain Model AvariantoftheSISmodelisthe\"immune-admitting\"SIS,whichissimilartothe previousmodelexceptthatanodedoesnotgetinfectedfromitsneighborsifithas just recovered from the disease (see Fig. 2.1). In other words, the probability of recovering from the disease is X. That is P\u00b9b8\u00b9C\u00b81\u00ba=.8jb\u00b9C\u00ba=-\u00ba =8>>>>>> < >>>>>>:\u00b91\u0000V\u00ba<8if\u00b9-8\u0096.8\u00ba=\u00b90\u00960\u00ba\u0096j#8\\S\u00b9-\u00baj=<8\u0096 1\u0000\u00b91\u0000V\u00ba<8if\u00b9-8\u0096.8\u00ba=\u00b90\u00961\u00ba\u0096j#8\\S\u00b9-\u00baj=<8\u0096 Xif\u00b9-8\u0096.8\u00ba=\u00b91\u00960\u00ba\u0096 1\u0000Xif\u00b9-8\u0096.8\u00ba=\u00b91\u00961\u00ba\u0095(2.34) and, as before, the elements of the transition matrix are dened as P\u00b9b\u00b9C\u00b81\u00ba=.jb\u00b9C\u00ba=-\u00ba==\u00d6 8=1P\u00b9b8\u00b9C\u00b81\u00ba=.8jb\u00b9C\u00ba=-\u00ba\u0095 (2.35) In this model, the probability that a node becomes healthy from infected ( X) is larger than that of the \"immune-free\" model ( X\u00b91\u0000V\u00ba<8). Therefore, roughly speaking, theimmune-admittingmodelismorelikelythantheimmune-freemodeltohitthe absorbing Nonlinear Model A mean-eld approximation for the immune-admitting model can be studied as which is dened as %8\u00b9C\u00b81\u00ba=\u00b91\u0000X\u00ba%8\u00b9C\u00ba\u00b8\u00b91\u0000%8\u00b9C\u00ba\u00ba 1\u0000\u00d6 has elements of the form (-\u0096.=P\u00b9b\u00b9C\u00b81\u00ba=.jb\u00b9C\u00ba=-\u00ba==\u00d6 8=1P\u00b9b8\u00b9C\u00b81\u00ba=.8jb\u00b9C\u00ba=-\u00ba\u0096(2.38) as before. Here of equations around the origin is In the vaccination-dominant variant of the model, the assumption is that if a susceptiblenodereceivesbothinfectionandvaccine atthesametime, itbecomes vaccinated. Although in the context of contagious diseases, this variation might make less sense, in other applications, there are scenarios for which this model is more relevant. The transition probabilities of the Markov chain are again (-\u0096.=P\u00b9b\u00b9C\u00b81\u00ba=.jb\u00b9C\u00ba=-\u00ba==\u00d6 8=1P\u00b9b8\u00b9C\u00b81\u00ba=.8jb\u00b9C\u00ba=-\u00ba\u0096(2.40) with that for the vaccination-dominant model, the steady state of the Markov chain and the main xed point of the mapping are exactly the same as those oftheinfection-dominantmodel. However,asonemayexpect,itturnsoutthatthe vaccination-dominant model around the main xed point is as follows The vaccination-dominant variant of the model has the following EXACT MODELS [1]Navid Azizan et al. \"Improved bounds on the epidemic threshold of exact SIS models on complex networks\". In: 2016 55th IEEE Conference on Decision 2016, pp. 3560-3565. /d.sc/o.sc/i.sc:10.1109/CDC. 2016.7798804 . The SIS (susceptible-infected-susceptible) epidemic model on an arbitrary network, without making approximations, is a 2=-state Markov chain with a unique absorbing state (the all-healthy state). This makes analysis of the SIS model and, in particular, determining the threshold of epidemic spread, quite challenging. We saw in the previous chapter that the exact marginal probabilities of infection can be upper bounded by an =-dimensional linear time-invariant system, a consequence of which isthattheMarkovchainis\"fast-mixing\"whentheLTIsystemisstable,i.e.,when V X\u009f1 _max\u00b9\u0016\u00ba(whereVis the infection rate per link, Xis the recovery rate, and _max\u00b9\u0016\u00bais the largest eigenvalue of the network's adjacency matrix). This well- known threshold has been recently shown not to be tight in several cases, such as in a star network. In this chapter, we provide tighter upper bounds on the exact marginalprobabilitiesofinfection,byalsotakingpairwiseinfectionprobabilitiesinto account. Based on this improved bound, we derive tighter eigenvalue conditions that guarantee fastmixing (i.e., logarithmic mixingtime) ofthe chain. We demonstrate theimprovementofthethresholdconditionbycomparingthenewboundwiththe known one on various networks with various epidemic parameters. 3.1 Introduction Themathematical modelingandanalysisof epidemicspreadisof greatimportance in understating attracted signicant interest from dierent communities in recent years. The studyofepidemicsplaysakeyroleinmanyareasbeyondepidemiology[29],such as viral marketing [168, 175], network security [8, 2], and information propagation [109, 56]. Although there is a huge body of work on epidemic models, classical ones mostly neglect the underlying network structure and assume a uniformly mixed41 population, which is obviously far from reality. However, in recent years, more realisticnetworkedmodelshavebeenintroduced,andmanyinterestingresultsare now known [155, 165]. Inthesimplestcase(thebinary-stateorSISmodel),eachnodeisinoneoftwodierent states: susceptible (S) or infected (I). During any time interval, each susceptible (healthy)nodehasachanceofbeingindependentlyinfectedbyanyofitsinfected neighbors (with probability V). Further, during any time interval, each infected node has a chance of recovering (with probability X) and becoming susceptible again. For a network with =nodes, this yields a Markov chain with 2=states, which is referred toastheexactor\"stochastic\"model. Sinceanalyzingthismodelisquitechallenging, mostresearchershaveresortedto =-dimensionallinearandnonlinearapproximations (the most common being the \"mean-eld\" approximation), which are sometimes called \"deterministic\" models. This chapter focuses on improving known bounds on the exact model. Thespreadingprocesscanbeconsideredeitherasadiscrete-timeMarkovchainor a continuous-time one. Although the discrete-time model is sometimes argued to be more realistic [79, 4], there is no fundamental dierence between the two, and similar results have been shown for both. We focus on the discrete-time Markov chain here. out, which may seem to be odd at rst. However, what this means isthatthequestionoftheepidemicdyingoutisnotinteresting;whatisinteresting isthequestionof howlongittakesfortheepidemictodieout. Inparticular,ifthe mixing time of the Markov chain is exponentially large, one will not see it dying out in any reasonable time. Therefore, the right question to ask is what is the mixing time of the Markov chain (or, equivalently, its mean-time-to-absorption); it turns out that the threshold g2corresponds to the phase transition between \"slow mixing\" (exponential time) and \"fast mixing\" (logarithmic time) of the MC [64, 204, 205]. The epidemic threshold (critical value) of general networks is still an open problem. However,lower-andupper-boundshavebeenfoundusingdierenttechniques[64,42 Figure 3.1: State diagram of a single node in the SIS model, and the transition rates. Wavy arrow represents exogenous (neighbor-based) transition. V:probability of infection per infected link, X:probability of recovery. 205]. The best known lower-bound is1\u009d_max\u00b9\u0016\u00ba, i.e., inverse of the leading eigenvalueoftheadjacencymatrix,whichisderivedby upper-bounding themarginal probabilitiesofinfectionandusingalineardynamicalsystem. Infact,thismethod relies on keeping track of =variables which are upper bounds on the marginal probability of infection for any of the nodes. In this chapter, we focus on improving this upper-bound on the infection probabilities and ultimately the lower-bound on theepidemicthreshold. Thekeyideaistomaintainthe\"pairwise\"probabilitiesof nodes'infections,inadditiontothemarginals. Thiscomesatthecostofincreased, yet still perfectly feasible, computation. There is a trade-o between the tightness of the bound and the complexity, and in theory if one takes into account all marginals, pairs, triples, and higher-order terms, we get back to the original 2=-state Markov chain. Werstbrieflyreviewtheknownboundwithmarginals,andshowasimplealternative approach for deriving it. We then move on to pairs and use the machinery developed inSection3.2toderivetighterboundsontheprobabilitiesandconnectthemwiththe mixing time of the Markov chain (Sections 3.3 and 3.4). Finally, we demonstrate the improvementoftheboundsthroughextensivesimulations(Section3.5)andconclude with future directions. 3.2 The Markov Chain and Marginal Probabilities of Infection Let =\u00b9+\u0096\u001a\u00babe an arbitrary connected undirected network with =nodes, and with adjacency matrix \u0016. Each node can be in a state of health, represented by \"0,\" or a state of infection, represented by \"1.\" The state of the entire network can be represented by a binary n-tuple b\u00b9C\u00ba=\u00b9b1\u00b9C\u00ba\u0096\u0001\u0001\u0001\u0096b=\u00b9C\u00ba\u00ba2f 0\u00961g=, where each of the entries represents the state of a node at time C, i.e.,8is infected if b8\u00b9C\u00ba=1and it is healthy ifb8\u00b9C\u00ba=0. Giventhecurrentstate withprobability Vperinfectedlink,andan infectednode can recover from the That is P\u00b9b8\u00b9C\u00b81\u00ba=.8jb\u00b9C\u00ba=-\u00ba= 8>>>>>> < >>>>>>:\u00b91\u0000V\u00ba<8if\u00b9-8\u0096.8\u00ba=\u00b90\u00960\u00ba\u0096j#8\\S\u00b9-\u00baj=<8\u0096 -2f0\u00961g=, ?8\u00b9C\u00b81\u00ba), per se are not very interesting because they do not provide any guarantee on the behavior of the exact Markov chain model. What is more important is whether one canobtainaboundonthesetrueprobabilities,whichcanguarantee,forexample,fast extinction of the disease. The most common upper-bound, which has been shown to be the tightest linear upper-bound with marginals only (using a be written in a matrix form as ?\u00b9C\u00b81\u00ba\u0016\"?\u00b9C\u00ba\u0096 (3.4) where \"=\u00b91\u0000X\u00ba =\u00b8V\u0016\u0095 (3.5) 3.2.1 An Alternative Bounding Technique Thederivationof (3.3)in[6,16]involvesalinearprogrammingtechnique. Inthis chapter, we provide an alternative technique to bound the infection probabilities usingindicatorvariablesandconditionalexpectation,whichismoreintuitiveand direct. Importantly, as will be shown later, this technique can be used to obtain tighter bounds on the exact probabilities of infections using pairwise inflectional probabilities. Before that, it is instructive to derive (3.3)using this alternative approach. Let82+. We start by conditioning on the state of the same node 8at timeC, as follows: ?8\u00b9C\u00b81\u00ba=P\u00b9-8\u00b9C\u00b81\u00ba=1j-8\u00b9C\u00ba=1\u00baP\u00b9-8\u00b9C\u00ba=1\u00ba \u00b8P\u00b9-8\u00b9C\u00b81\u00ba=1j-8\u00b9C\u00ba=0\u00baP\u00b9-8\u00b9C\u00ba=0\u00ba\u0095 Theprobabilitythataninfectednoderemainsinfectedis 1\u0000X,andtheprobability that a susceptible node does not receive infection from an infected neighbor is 1\u0000V. We denote9neighbor of8by9\u00188. The expression above can be written as ?8\u00b9C\u00b81\u00ba=\u00b91\u0000X\u00ba?8\u00b9C\u00ba\u00b8E-\u00008\u00b9C\u00baj-8\u00b9C\u00ba=0\u0014 1\u0000\u00d6 9\u00188\u00b91\u0000V 1-9\u00b9C\u00ba\u00ba\u0015 P\u00b9-8\u00b9C\u00ba=0\u00ba\u0095(3.6) The conditional expectation is on the joint probability of all nodes other than 8 (denoted by -\u00008), given node 8being healthy ( -8=0). is stillexact,andwehavenotdoneanyapproximationyet. Itcanbeeasilycheckedthat \u00d6 9\u00188\u00b91\u0000V 1-9\u00b9C\u00ba\u00ba\u00151\u0000V\u00d5 9\u001881-9\u00b9C\u00ba\u0095 Combining this with (3.6) bound ?8\u00b9C\u00b81\u00ba\u0014\u00b9 1\u0000X\u00ba?8\u00b9C\u00ba\u00b8V\u00d5 9\u00188P\u00b9-8\u00b9C\u00ba=0\u0096-9\u00b9C\u00ba=1\u00ba (3.7) \u0014\u00b91\u0000X\u00ba?8\u00b9C\u00ba\u00b8V\u00d5 9\u00188?9\u00b9C\u00ba\u009545 3.2.2 Connection to Mixing Time of the Markov Chain Uptothispoint,wejusttalkedaboutboundingthemarginalprobabilitiesofinfection, and it is not clearhow a bound on themarginal probabilities relatesto the mixing timeoftheMarkovchain. of mixing time [126]: C<8G\u00b9n\u00ba=minfC: sup `k`(C\u0000ck)+\u0014ng\u0096 (3.8) where`is any initial probability distribution dened on the state space, and cis the stationary distribution; k`\u0000`0k)+is the total variation distance of any two probability measures `and`0, and is dened by k`\u0000`0k)+=1 2\u00d5 Gj`\u00b9G\u00ba\u0000`0\u00b9G\u00baj\u0096 whereGis any possible state in the probability space. In fact C<8G\u00b9n\u00bais the minimum time instant for which the distance between the stationary distribution and the probability distribution at time Cfrom any initial distribution is smaller than or equal ton. Roughlyspeaking,themixingtimemeasureshowfasttheinitialdistribution converges to the limit distribution, which, in our case, means how quickly the epidemic dies out. Since, in the stationary distribution, the all-healthy state has probability 1, it can be shown [6] that sup `k`(C\u0000ck)+=P\u0010 some nodes are infected at time Cj all nodes were infected at time 0\u0011 (3.9) which highlights the fact that the worst initial distribution (i.e., the `that maximizes above quantity) is the all-infected state. Now, for any C \u009fC<8G\u00b9n\u00bawe have n \u009fP\u0010 some nodes are infected at time Cj all nodes were infected at time 0\u0011 \u0014=\u00d5 8=1P\u0010 node8is infected at time Cj infected at time 0\u0011 =1) =?\u00b9C\u00bagiven that?\u00b90\u00ba=1=\u0096 (3.10) where we have used the union bound, and 1=denotes the all-ones vector of size =. Back to the upper-bound on the marginals (3.4), we get 1) =?\u00b9C\u00ba\u00141) =\"?\u00b9C\u00001\u00ba. Furthermore, since \"has non-negative entries (we write this as \"\u00150), we can \"propagate\" the bound to nd that 1) =?\u00b9C\u00ba\u00141) =\"?\u00b9C\u00001\u00ba\u00141) =\"2?\u00b9C\u00002\u00ba\u0014\u0001\u0001\u0001\u0014 1) =\"C?\u00b90\u00ba\u009546 As n \u009f1) (3.11) matrix % 0such that\")%\"\u0000% 0. Letting%1\u009d2denotetheuniquepositivesquarerootof %and (Here,k#k2denotesthespectralnormof #.) ?89) InSection3.2, weshowedhowaboundonmarginalprobabilitiesofinfection canbe obtained, and how this bound translates to the threshold condition for fast mixing of theMarkovchain. Asmentionedbefore,thebound (3.4)hasbeenprovedtobethe tightestlinearboundonecangetwithmarginals. Anaturalideatoimprovethisbound is to go to higher-order terms (i.e., pairs, triples, etc.). In principle, maintaining higher-ordertermsisadvantageousbecauseitmeanskeepingmoreinformationfrom the original chain, but of course at the cost of increased complexity. We dene thepairwiseprobabilityofinfectionoftwonodes,inadditiontothemarginals,as follows. For\u00b98\u00969\u00ba2\u001a, ?89\u00b9C\u00ba:=P\u00b9-8\u00b9C\u00ba=1\u0096-9\u00b9C\u00ba=1\u00ba\u0095 Note that out of the\u0000= 2\u0001possible pairs of nodes, we only consider the ones that correspond to edges in the graph. Based on this denition, P\u00b9-8\u00b9C\u00ba=0\u0096-9\u00b9C\u00ba= 1\u00ba=?9\u00b9C\u00ba\u0000?89\u00b9C\u00ba, and it follows easily from (3.7) that ?8\u00b9C\u00b81\u00ba\u0014\u00b9 1\u0000X\u00ba?8\u00b9C\u00ba\u00b8V\u00d5 9\u00188?9\u00b9C\u00ba\u0000V\u00d5 9\u00188?89\u00b9C\u00ba\u0095 (3.12)47 Of course, this bound is at least as tight as the one in (3.3). Now, in order to strictly improveuponthelatter,weneedalowerboundonthepairwiseinfectionprobabilities at timeC\u00b81in terms of marginals and pairwise probabilities at time C, which is derived next. 3.3.1 A Lower Bound on the ?89's To construct a lower bound on the pairwise marginal probabilities ?89\u00b9C\u00b81\u00ba, we usethesameapproachaswasintroducedinSection3.2.1,butthistimeappliedto pairwise infection follows \u00d5 G2f0\u00961g H2f0\u00961gP\u00b9-8\u00b9C\u00b81\u00ba=1\u0096-9\u00b9C\u00b81\u00ba=1\u0096-8\u00b9C\u00ba=G\u0096-9\u00b9C\u00ba=H\u00ba\u0095 For convenience, denote each one of the summands above by BGH. Also, let2GH represent the corresponding conditional probability P\u00b9-8\u00b9C\u00b81\u00ba=1\u0096-9\u00b9C\u00b81\u00ba= 1j-8\u00b9C\u00ba=G\u0096-9\u00b9C\u00ba=H\u00ba\u0095In what follows, we lower bound each one of BGH's. We writeEGHfor the conditional expectation E-\u00008\u0096\u00009\u00b9C\u00bajf-8\u00b9C\u00ba=G\u0096-9\u00b9C\u00ba=Hg. \u000f(x=0,y=0): Trivially,B00\u00150. \u000f(x=0,y=1): As before, the probability of not getting infected from each infected neighbor is\u00b91\u0000V\u00ba, and the probability that an infected node remains infected \u0015V\u00b91\u0000X\u00ba?9\u00b9C\u00ba\u0000V\u00b91\u0000X\u00ba?89\u00b9C\u00ba\u0095 \u000f(x=1,y=0): By symmetry, the exact same argument as above implies B10\u0015V\u00b91\u0000X\u00ba?8\u00b9C\u00ba\u0000V\u00b91\u0000X\u00ba?89\u00b9C\u00ba\u0095 \u000f(x=1,y=1): Clearly211=\u00b91\u0000X\u00ba2\u0096which gives B11\u0015\u00b91\u0000X\u00ba2?89\u00b9C\u00ba\u009548 Summing all the above terms yields the following lower bound for all \u00b98\u00969\u00ba2\u001aand C\u00150: ?89\u00b9C\u00b81\u00ba\u0015\u00b9 1\u0000X\u00baV\u00b9?8\u00b9C\u00ba\u00b8?9\u00b9C\u00ba\u00ba\u00b8\u00b9 1\u0000X\u00ba\u00b91\u0000X\u00002V\u00ba?89\u00b9C\u00ba\u0095(3.13) 3.3.2 Back to In order to express Eqs. (3.12)and(3.13)for all8and9's together ?\u001a\u00b9C\u00ba=vec\u00b9?89\u00b9C\u00ba:\u00b98\u00969\u00ba2\u001a\u00ba. Notethat?89\u00b9C\u00ba=?98\u00b9C\u00ba,soforeachedgeweonlykeeptrackofoneofthetwoterms. (3.14) The matrix\"0, after a little bit of thought, can be expressed in the , which is formally dened as \u00178\u00964=8>> < >>:1if8is an of 4\u0096 0otherwise\u0096 for all82+and42\u001a. By accounting for pairwise infection probabilities, the bound derived in (3.14)is tighter when compared to the one in (3.4). In order to connect this to the the mixing time of the underlying Markov chain, observe that 1) =?\u00b9C\u00ba=h 1) =0) j\u001aji\" signs of all the =\u00b8j\u001ajinequalities in (3.14)are preserved.49 Withthisnote,itbecomesclearthatinordertobeabletopropagatetheboundsfor the remaining time instances C\u00002\u0096C\u00003\u0096\u0095\u0095\u0095\u0096 0, a \u00b9\"0\u00baC\u00150\u0096for \u00b9\"0\u00baC\" ?\u00b90\u00ba \u0000?\u001a\u00b90\u00ba# \u0095 (3.18) Subsequently, the same argument as in Section 3.2.2 concludes the following result. Theorem 15. Assume that (3.17)holds. Ifd\u00b9\"0\u00ba\u009f1, then the mixing time of the Markov chain whose transition matrix (is described by Eqs. (3.1)and(3.2)is $\u00b9log=\u00ba. Fromthestandardboundwithonlymarginals,itwasknownthatwhen d\u00b9\"\u00ba\u009f1,the Markov chain is fast-mixing. Now, addition to that, the above theorem states that whend\u00b9\"0\u00ba\u009f1, the Markov chain mixes fast again. Of course, this is informative only when there is a case where d\u00b9\"\u00ba\u00a11butd\u00b9\"0\u00ba\u009f1. As it will be shown in Section 3.5, this is indeed the case. Note that, in the proof of Theorem 15, we used the assumption that (3.17)holds. As will be shown in the simulations section, in many cases this is a reasonable assumption. However,whentheassumptiondoesnotholdwecannotappealtothis theorem. Forthisreason,weproposeanotherboundusinganalternativepairwise probability, which does not require such a condition. 3.4 An Alternative Pairwise Probability ( @89) As it was discussed above, when the assumption (3.17)does not hold, we seek an alternative bound. Let us dene @89\u00b9C\u00ba:=P\u00b9-8\u00b9C\u00ba=0\u0096-9\u00b9C\u00ba=1\u00ba\u0095 Wecanusethesameapproachasbeforetoobtainboundsfor ?8,@89's. Intuitively, lower bounding ?89\u00b9C\u00b81\u00bais equivalent with upper bounding @89\u00b9C\u00b81\u00ba, and it turns out that it is what we need. The next lemma summarizes the bounds on these probabilities.50 Lemma 16. For convenience, denote each the summands above by BGH. Also, let2GH denote the corresponding conditional probabilities P\u00b9-8\u00b9C\u00b81\u00ba=0\u0096-9\u00b9C\u00b81\u00ba= 1j-8\u00b9C\u00ba=G\u0096-9\u00b9C\u00ba=H\u00ba\u0095In what follows, we upper bound each one of the BGH's; this willimmediatelyyield (3.20). Allexpectationsbelowareconditionalontheevent f-8\u00b9C\u00ba=G\u0096-9\u00b9C\u00ba=Hg, which is omitted for the sake of convenience. \u000f(x=0,y=0): Using the fact that a vector @\u001a\u00b9C\u00ba2R2j\u001ajas@\u001a\u00b9C\u00ba=vec\u00b9@89\u00b9C\u00ba:\u00b98\u00969\u00ba2 \u001a\u00ba, we can express (3.19) conclude with the following theorem. Theorem 17. Ifd\u00b9\"00\u00ba\u009f1and1\u0000X\u0000V\u00150, then the mixing time of the Markov chain whose transition matrix (is described by Eqs. (3.1)and(3.2)is$\u00b9log=\u00ba. 3.5 Experimental Results Inthissection,wedemonstratetheperformanceoftheproposedboundsbyevaluating themonavarietyofnetworkssuchasclique,Erds-R\u00e9nyi,Watts-Strogatz,stargraph, linegraph,cycle,andstar-linegraph,withvariousparameters VandX. Asmentioned before, in order for any of the two threshold conditions proposed in Sections 3.3 and 3.4 to be an improvement, we need to check if there are cases where the spectral radiusof\"0or\"00islessthan1,whilethespectralradiusof \"isgreaterthan 1(or equivalentlyV_max\u00b9\u0016\u00ba X\u00a11). Indeed, extensive simulations on our rst bound ( \"0) suggest that not only are there such cases, but interestingly always d\u00b9\"0\u00ba\u0014d\u00b9\"\u00ba. In order to compare \"0with\", we setd\u00b9\"\u00ba=1\u00b8n \u00a11for some small value of n, and observe the value of d\u00b9\"0\u00ba. Table 3.1 lists the values of spectral radii for the three matrices. The positive sign next to d\u00b9\"0\u00baindicates that the non-negativity condition (3.17)holds. Forthecasesthattheconditionholds(+),wecanconclude that\"0has clearly improved. For the cases where the condition does not hold (-) we evaluatethesecondproposedbound \"00, whichagainshowsclearimprovementover thed\u00b9\"\u00ba\u009f1condition. Inordertodemonstratehowtightthenewconditionis,Fig.3.2plotstheevolution of the epidemic over a star graph, for which the d\u00b9\"\u00ba\u009f1condition is known not to be tight. The parameters in the two cases are X=0\u00953\u0096V=0\u00950130, and X=0\u00953\u0096V=0\u00950157. ItcanbeseenthatwhilethevalueofV_max\u00b9\u0016\u00ba 3.1: Performance of the proposed bounds \"0and\"00in comparison with the previousbound \". Boldfacevaluesshowanimprovementover \". Thesignsnextto d\u00b9\"0\u00baindicate whether the non-negativity 200 300 400 500 600 700 800 900 1000 Time Step01002003004005006007008009001000Number of Infected Nodes(M) = 1.05>1 (M) = 0.99<1 Figure 3.2: Evolution of the SIS epidemic over a star graph with ==2000nodes, with two values of d\u00b9\"0\u00babelow and above 1. When d\u00b9\"0\u00ba=0\u009599\u009f1, we observe fast extinction of the epidemic (blue curve). The condition also seems very tight, as ford\u00b9\"0\u00ba=1\u009505\u00a11,theepidemicdoesnotdieout(redcurve). Thisiswhilethe previously known bound is not informative at all (V_max\u00b9\u0016\u00ba X=1\u009593\u00a11for the rst case, and 2\u009533\u00a11for the second one). 3.6 Conclusion and Future Work In this chapter, we rst proposed a simple technique using conditional expectations tosystematicallyconstructboundsontheexactprobabilitiesofinfection,uptoany desiredorder. Usingthisapproach,weshowedthatkeepinghigher-orderterms(such aspairs)indeed and pairwise probabilities, which has improved over the well-known bounds. Based on this new bound, we provided a new condition for fast mixing of the Markov chain to the all-healthy state, which, through extensive simulations, was shown to be tighter than the so-calledV_max\u00b9\u0016\u00ba X\u009f1condition. Clearly,onepossibleextensionofthisworkwouldbetoconstructaboundconsisting of marginals, pairs, and triples, which in theory should result in an improvement. In fact, keeping all higher-order terms eventually takes us back to the 2=-state Markov chain. Therefore, there is a trade-o between the complexity and the accuracy of the includes all terms rather than just the marginals. As a last comment, basedonthesimulations,weconjecturethatcondition (3.17)mayberelaxed,and other future work may concern its proof.Part II Incentives and Markets 5556 C h a pte r 4 OPTIMAL PRICING IN MARKETS WITH NON-CONVEX COSTS [1]NavidAzizanetal.\"OptimalPricinginMarketswithNon-ConvexCosts\".In: Proceedingsofthe2019ACMConferenceonEconomicsandComputation (EC). Operations Research 68.2 (2020), pp. 480-496. /d.sc/o.sc/i.sc:10.1287/opre.2019. 1900. Designing markets and incentives crucial for ecient operationofthesystem. Inthischapter,weconsideramarketrunbyanoperator,who seekstosatisfyagivenconsumerdemandforacommoditybypurchasingtheneeded amountfromagroupofcompetingsupplierswithnon-convexcostfunctions. The operatorknowsthesuppliers'costfunctionsandannouncesaprice/paymentfunction for each supplier, which determines the payment to that supplier for producing dierent quantities. Each supplier then makes an individual decision about how much to produce, in order to maximize its own prot. The key question is how to design the price functions. To that end, we propose a new pricing scheme, which is applicable to general non-convex costs, and allows using general parametric pricing functions. Optimizing for the quantities and the price parameters simultaneously, and the ability to use general parametric pricing functions, allows our scheme to nd prices that are typically economically more ecient and less discriminatory than those of the existing schemes. In addition, we supplement the proposed method with a polynomial-time approximation algorithm, which can be used to approximate theoptimalquantitiesandprices. Ourframeworkextendstothecaseofnetworked markets,which,tothebestofourknowledge,hasnotbeenconsideredinprevious work. 4.1 Introduction Whiletherehasbeenalonghistoryofstudyingmarketsunderconvexityassumptions (such as convexity of cost functions, preferences, etc.) in economic theory, non- convexities are ubiquitous in most real-world markets. Non-convexities in cost57 functions arise due to start-up or shut-down costs, indivisibilities, avoidable costs, or simply economies of scale. It has been widely noted in the literature that in the presence of non-convexities, there may be no linear prices (constant per quantity) that support a competitive market equilibrium [e.g., 46, 83], and it was suggested as early as the 1980s that in these markets, one needs to consider using price functions , as opposed to the conventional prices [212]. Following the work of [178, 179], there have been many pricing schemes proposed in the literature. In particular, during the past decade, motivated by the deregulation of the electricity markets in the US and around the world, the problemof pricing innon-convexmarkets has attracted renewedinterest fromresearchers,andtherehasbeenconsiderableworkonthisproblem[131]. These pricing schemes are deployed in practice, and the operation and eciency of our electricity markets relies on them. Formally, the non-convex pricing problem is that, given an inelastic demand for a commodity from a number of consumers, a market operator seeks to satisfy the demand by purchasing the required amount from a group of competing suppliers withnon-convexcostfunctions. Theoperatorknowsthesuppliers'costfunctions, anditannouncesaprice/paymentfunctionforeachsupplier,whichdeterminesthe paymenttothatsupplierforproducingdierentquantities. Eachsupplierthenmakes an individual decision about how much to produce in order to maximize its own prot. Thekeydesignquestionishowtodevisethepricefunctionsinordertoensure certain economic properties for the market. We should remark that this problem isquitedierentfrommechanismdesign,sincethecostfunctionsofthesuppliers areknowntothemarketoperator,andtheplayerscaninfluencethemarketonlyby choosing their production level. However, as we shall see, the design of the price functions in these markets is challenging. Animportantearlyapproachtothepricingproblemwastheworkof[159],sometimes referred to as integer programming (IP) pricing, which considered the class of non- convexitiesthatarisefromthestart-upcostsofthesuppliers(withlinearmarginal costs). Thepaperproposesacleverpricingrule,basedonsolvingamixed-integer linearprogramandforcingtheintegralvariablestotheiroptimalvaluesasaconstraint. Theschemeiseconomicallyecientandhasanicedualinterpretation. Modied versions of IP pricing have been proposed by [39, 38] and others. Another approach, proposedforthemoregeneralclassofnon-convexcostfunctionsthatareintheform of a start-up plus a convex (rather than linear) cost, is the minimum-uplift (MU)58 pricing of [103], and its closely related renement of [81], known as convex hull (CH) pricing. These schemes provide discriminatory uplifts to dierent suppliers to incentivize production, and the uplifts are minimal in a specic sense [181]. Thepossibilityofhavingbothpositiveandnegativeupliftswasalsoconsideredby [145, andtheprimal-dual(PD)approach of[177]. Theseschemesseek to nd uniform linear prices that are revenue-adequate (but not supporting of the equilibrium). A survey on all the above pricing schemes was recently written by [131]. However, the overall desired properties, as well as the properties that each of theschemessatisfy,werenotexaminedthere. Weformalizethedesiredproperties consideredintheliteratureinSection4.2anddiscuss thepropertiesof theexisting schemes in Section 4.5. Table 4.1 summarizes the common schemes and their properties. Despitethelargebodyofworkonthepricingproblem,theexistingschemeshave several shortcomings. For example, most of the existing schemesmentioned above areproposedforspecicclassesofnon-convexcostfunctionsandcannothandlemore general non-convexities. Furthermore, even the ones that are applicable for general costfunctionsfailtosatisfysomeofthekeydesiredpropertiesofthemarket,suchas economiceciencyorsupportingacompetitiveequilibrium. Inaddition,noneof theexistingschemesisaccompaniedbyacomputationallytractablealgorithmfor general non-convexities, and they typically rely on o-the-shelf heuristic solvers for mixed-integer programs that Inthischapter,weproposeapricingschemeformarketswithgeneralnon-convex coststhatdesignsarbitraryparametricpricefunctionsandaddressesalltheissues mentionedabove. Ourapproachseekstondtheoptimalschedule(allocation)andthe optimalpricingrulesimultaneously,whichgenerallyallowsfornding economically more ecient solutions. The ability to use arbitrarily specied parametric price functions (e.g., piece-wise linear, quadratic, etc.) enables our approach to design price functions that are less discriminatory , while still supporting a competitive equilibrium . Furthermore, our pricing scheme is accompanied by a computationally ecient(polynomial-time) approximation algorithm which allows one to nd the approximately-optimalscheduleandpricesforgeneralnon-convexcostfunctions. Lastly, we extend the proposed pricing rule to networked markets, which, to the best of our knowledge, are not considered in any of the existing work. Specically, this chapter makes the following contributions.59 1.Weproposeaframeworkforpricinginmarketswith generalnon-convexcosts, usinggeneralprice functions (Section 4.3.1). Our scheme seeks to nd the optimal price functions and allocations simultaneously, while imposing the equilibriumconditionsasconstraints. Forthisreason,ourapproachisgenerally economically more ecient than the existing methods, while satisfying the equilibriumconditions. Moreover,theabilitytousegeneralpriceformsallows one to obtain more uniform prices (smaller \"uplifts\"). 2.Wesupplementourpricingschemewithacomputationallyecient(polynomial- time) approximation algorithm for nding the allocations and (Sec- tion 4.3.2). 3.We extend our framework to networked markets, and also propose an approxi- mationalgorithmthatcancomputethesolutionecientlyforacyclicnetworks, a common scenario in electric distribution networks (Section 4.4). 4.We survey the common pricing schemes proposed in the literature for markets with non-convex costs and provide a compact summary of their properties (Section 4.5). 5.We evaluate the proposed method through extensive numerical examples and show how it compares with the existing methods (Section 4.6). 4.2 Market Description and Pricing Objectives While our goal in this chapter is to design an economically and computationally ecient pricing scheme for non-convex networked markets, we begin with the problem of designing one for a singlemarket, which is dicult in its own right. We return to the case of networked markets in Section 4.4. When the cost functions are non-convex, even this seemingly simple problem has proven to be challenging, and a wide variety of pricing schemes have been proposed for it in the literature. In the following, we describe the market model and survey the desired market properties. 4.2.1 Market Model We consider a single market consisting of =competing suppliers (often referred to as rms or generators). The market is run by a market operator that seeks to satisfy a deterministic and inelastic demand 3for a commodity in a single period. Eachsupplier 8hasacostfunction 28\u00b9@8\u00baforproducingquantity @8,whichmaybe non-convex.60 Thesuppliers'costfunctionsareknownbytheoperator,andtheoperatorusesthemto determine the prices. In particular, the operator announces price/payment functions ?8\u00b9@8\u00ba, which determine the payment to supplier 8when producing @8. Note that, in general, the price functions can be dierent for dierent suppliers, but it is often desired to close-to-uniform prices. Upon theannouncement ofthe pricefunctions, eachsupplier 8makes anindividual decision, on the price function ?8\u00b9\u0001\u00baand the cost function 28\u00b9\u0001\u00ba, about how much to produce (and whether to participate in the market), in order to maximize itsownprot,i.e., ?8\u00b9@8\u00ba\u000028\u00b9@8\u00ba. Thesuppliersarethenpaidfortheirproduction accordingtothepaymentfunction,andthedemand(consumers)ischargedforthe total payment. This modelis classical, and hasbeen studied in awide variety ofcontexts,initially under the assumption of convex cost functions for production and linear pricing functions, but more recently under non-convex cost functions. Non-convex cost functions are particularly important in the context of electricity markets. As a result,thereisalargeliteraturefocusingonnon-convexpricinginelectricitymarkets (see [131] for a recent survey). Often this literature assumes specic forms of non-convexities(e.g.,startup/xedcosts)andspecicformsofpaymentfunctions (e.g.,linearplusuplift). Theresults from thisliteraturehaveguidedthedesignand operation of electricity markets across the world today. 4.2.2 Pricing Objectives The key design question in the market described above is how to devise the payment functions. Thegoaloftheoperatoristo(1)ndtheoptimalquantities @\u0003 8,and(2) designthepaymentfunctions ?8\u00b9\u0001\u00bathatensurethatthesuppliersproducetheoptimal quantities@\u0003 8. Thereisahugedesignspaceforsuchpaymentfunctions,andthereisalargeliterature evaluating the context of non-convex cost functions, e.g., [159, 103, 39, 81, 10, 177, 131, 181, 107]. Fromthisliteraturehasemergedavarietyofdesirablepropertieswhichpricingrules attempt to satisfy. The following is a summary of the most sought-after properties in thisliterature. Notethatnoexistingrulessatisfyallofthesepropertiesforgeneral non-convex markets.61 1.Market Clearing (a.k.a.Load Balancing ): The to the demand, i.e.,\u00cd= 8=1@\u0003 8=3. 2.Economic Eciency a)Minimal Production Cost (Suppliers' Total Cost) : The total production cost of the suppliers, i.e.,\u00cd= 8=128\u00b9@\u0003 8\u00ba, is minimal. b)Minimal Payment (Total Paid Cost) : The total cost that is paid to the suppliers for the commodity, i.e.,\u00cd= 8=1?8\u00b9@\u0003 8\u00ba, is minimal. 3.Incentivizing a)Revenue Adequacy : For every supplier, the net prot at the optimum is nonnegative, i.e., ?8\u00b9@\u0003 8\u00ba\u000028\u00b9@\u0003 8\u00ba\u00150, for8=1\u0096\u0095\u0095\u0095\u0096=. b)Support a Competitive Equilibrium : The optimum production quan- tity for each supplier is a maximizer of Tractability : Theoptimalquantitiesandpricefunctionscan be computed/approximated in time that is polynomial in =. A few remarks about these properties are warranted. Property 1 ensures that the demand is met. Property 2 is somewhat more elaborate and concerns the economic eciency of the scheme, in terms of total expenditure. Even though in certain cases (e.g., in IP pricing of [159] for startup-plus-linear costs), the suppliers' total cost\u00cd= 8=128\u00b9@8\u00baand the total paid cost\u00cd= 8=1?8\u00b9@8\u00bamatch and are both minimal, there is an inevitable gap between the two in general. Ultimately, the quantity which determines the cost of satisfying the demand is the total payment to the suppliers\u00cd= 8=1?8\u00b9@8\u00ba, and therefore Property 2b is arguably more crucial than Property 2a. However, ostensibly, because the price functions are not directly available while computingtheoptimalquantities,manypricingschemeshaveresortedtominimizing the total suppliers' cost\u00cd= 8=128\u00b9@8\u00baas a surrogate for the paid cost. In this work, we advocate a direct approach for minimizing the total payment.62 Property 3 incentivizes the suppliers to follow the dispatch and produce the socially- optimalquantities. Morespecically,Property3aensuresthatthesuppliersdonot lose by producing @\u0003 8, and further, Property 3b assures that it is in each supplier's bestinteresttofollowthedispatch. minimize the uplifts D8. As Property 4 is subjective by its nature, we allow arbitrary parametrizedprice functionsinourscheme. However, we alsoexamineour schemewhenappliedtothepopularminimal-upliftapproach. NotethatProperty4 alsorulesouttheuseof\"dictatorial\"prices,inwhichtheoperatorpaysthecost(plus ann) only at the desired amount, and pays nothing for any other amount produced. The nal property, Computational Tractability, is particularly challenging to address in the context of non-convex markets. Nearly all standard approaches work by computing the optimal production quantities and then deriving the prices from these quantitiesinsomeway. Undergeneralnon-convexcostfunctions,thisrststepis already computationally intractable. Thus, it is important to consider relaxations (approximations)ofotherpropertiesifthegoalistoenforcecomputationaltractability. Tothatend,weconsiderapproximateversionsoftheIncentivizingandEconomic Eciency conditions, which we discuss in Section 4.3.2. We propose an algorithm that satises these approximate versions, while being computationally tractable. 4.3 Proposed Scheme: Equilibrium-Constrained Pricing Most existing schemes in the literature (see Section 4.5 for a detailed summary) are proposed for specic classes of non-convexities, and are not applicable for more generalnon-convexcosts. Furthermore,eventheonesthatareapplicableformore generalcostfunctionseitheralreadylacksomeofthekeyproperties(suchaseconomic eciency) or they lose those properties for more general costs. Additionally, the existing schemes are not accompanied by a computationally tractable algorithm for general non-convexities, and they typically rely on o-the-shelf heuristic solvers for mixed-integer programs that are NP-hard. This serves to emphasize that no existing pricing scheme satises the desired properties described in Section 4.2.2. Themaincontributionofthischapteristheintroductionofanewpricingscheme, Equilibrium-Constrained(EC)pricing ,whichisapplicabletogeneralnon-convex63 costs,allowsusinggeneralparametricpricefunctions,andsatisesallthedesired propertiesoutlinedbefore,aslongasthepriceclassisgeneralenough. Thename of this scheme stems from the fact that we directly impose all the equilibrium conditions as constraints in the optimization problem for nding the best allocations, as opposed to adjusting the prices later to make the allocations an equilibrium. Theoptimizationproblemis,ofcourse,non-convex,andnon-convexproblemsare intractable in general. However, we also present a tractable approximation algorithm for approximately solving the proposed optimization. WepresenttheformulationoftheoptimizationatthecoreofEquilibrium-Constrained pricing in Section 4.3.1, and then develop an ecient algorithm for solving the optimization problem approximately in Section 4.3.2. 4.3.1 Pricing Formulation In this section, we propose a systematic approach for determining a pricing rule under generic non-convex costs that minimizes payments and satises the properties outlined in Section 4.2.2, while allowing flexibility in the choice of the form of price functions. Specically, consider a class of desired price functions, denoted by P, which can be an arbitrary class such as linear, linear plus uplift, piece-wise linear, etc. This choice canbeduetointerpretability/uniformityreasonsorotherpracticalconsiderations. The core of Equilibrium-Constrained pricing is an optimization problem for nding thebestpricefunctionsin Pandthebestallocationsatthesametime. Theoperatoris buying the commodity from the suppliers, on behalf of the consumers, and therefore its objective is to minimize the total cost incurred (total payment), subject to the equilibrium constraints. The optimization problem can be expressed as follows. expressed as 8=1\u0096\u0095\u0095\u0095\u0096=\u0095 (4.2) The key dierence between EC pricing and the existing methods for pricing in non-convex markets is that it directly minimizes the total paid cost and seeks to nd both the optimal allocations @\u0003 8and the optimal price functions ?\u0003 8\u00b9\u0095\u00basimultaneously. The scheme enforces the desired economic properties as constraints, while allowing theuseofanyclassofpricefunctions,ratherthanimposingaxedformfortheprice. Sincethisschememinimizesthetotalpayments,anddoesnotimposeanyexplicit constraint on the total production cost, it would be natural to ask what happens to latter quantity as we minimize the former. The minimum total production cost is dened production cost\" solution. Remark. It is easy to see, by relaxing the last constraint (4.1d), and using con- straint(4.1c), that the optimal value of the optimization problem (4.1)is bounded below by the minimum total production cost. Mathematically, we have ?\u0003\u0015 the total production cost is always upper-bounded by the total payment. Therefore, minimizing the total payment puts a cap on the total production costaswell,whiletheoppositeisnottrueingeneral(minimizingthetotalproduction cost can result in very high payments, which can be seen in, e.g., the case studies in Figs. 4.4a and 4.5a).65 Remark. We have imposed nearly all the desired properties as constraints in the optimization problem (4.1), and it might not be clear whether this optimization problemhasasolutionatall. Indeed,therealwaysexistsaclassofpricefunctionsfor whichproblem (4.1)hasasolution,andfurther,theboundmentionedinRemark4.3.1 is achieved. A naive choice of price function, often referred to as dictatorial pricing, is enough to prove this claim. In fact, one can check that for any price function of the form ?8\u00b9@8\u00ba8>> < >>:=28\u00b9@8\u00bafor@8=@0 8 \u001428\u00b9@8\u00bafor@8<@0 8\u0096 problem(4.1)has an optimal solution and it achieves the bound ?\u0003=2\u0003. While Remark 4.3.1 asserts the existence of an optimal price function in general, the problem may not have a solution for certain specic classes of price functions. The keypointisthatproblem (4.1)alwaysallowsusingmoresophisticatedpriceforms (e.g., piece-wise linear) for which it will have a solution; and for any given choice of price form, it nds the best one, along with the optimal quantities. Remark. Whileinmostscenarios,theoperatorisbuyingthecommodityfromthe suppliersonbehalfoftheconsumers,anditmakessensetominimizethetotalpayments\u00cd= 8=1?8\u00b9@8\u00ba, in general one may seek to balance between the consumers' and the suppliers'costs. Inotherwords,onecantaketheobjectivetobealinearcombination of the convex) combination \u00b91\u0000\\\u00ba\u00cd= 8=1?8\u00b9@8\u00ba\u00b8\\\u00cd= 8=1\u00b928\u00b9@8\u00ba\u0000?8\u00b9@8\u00ba\u00ba with parameter \\. The 8\u00bafrom the optimization problem(4.1)matchesthelowerbound 2\u0003=\u00cd= Section 4.3.1.1), the solution from (4.4)is the same as that of (4.1), and the prices will be insensitive to parameter \\. It is worth mentioning that our algorithm proposed in Section 4.3.2 for solving (4.1) is also capable of handling the weighted problem (4.4). However, for the sake of simplicity, we focus on the case of \\=0. Tobemoreexplicitabouttheclassofpricefunctions,weconsiderageneralparametric form forP, specied by ?8\u00b9@8\u00ba:=?\u00b9@8;U\u0096V8\u00bawith two types of parameters U2R;1, andV82R;2for8=1\u0096\u0095\u0095\u0095\u0096=,whereparameter Uissharedamongallthesuppliers, and it constitutes the uniform component of the price, while parameter V8is specic to supplier8. The parameters are in general to be in some bounded setsA\u0012R;1andB\u0012R;2, i.e.,U2A, andV82Bfor all8=1\u0096\u0095\u0095\u0095\u0096=. This parametric form is general enough that it encompasses all the assumed price forms in the literature. In particular, the linear-plus-uplift form ( ?8\u00b9@8\u00ba=_@8\u00b8D8 1@8=@8) is aspecialcaseofthisform,wherethesharedparameteristheuniformprice _,and the individual parameters are the amount and location of the uplifts D8\u0096@8. Using class of linear-plus-uplift price functions, which has been a standard form considered in the electricity markets literature [e.g., in 103, 81], and minimize the uplifts. We derive closed-form solutions for the optimal quantities and prices67 (for general cost functions). In this case, the total payment matches the total cost, which is the lowest theoretically possible. In contrast, the convex hull (CH) and minimum-uplift (MU) pricing schemes, which are the most closely related schemes and use the same type of price functions fail to achieve this bound and typically exhibit a large gap. The integer programming (IP) pricing, on the other hand, is capableofachievingthebound,butonlyforstartup+linearcostfunctions,andnot formoregeneralcostfunctionssuchasstartup+convex. (SeeSection4.5formore details on the existing schemes and their uplift coincides with the desired production level,whichisintuitive(seetheappendixforproof). Theoptimizationproblem (4.5) can _= 0\u0096 D8=28\u00b9@0 8\u00ba88corresponds to which is equivalent to havingnouniformpriceandpayingeachsupplierforitsowncost. Toobtainprice functions that are close to uniform, it is desirable to pick a solution for which the uplifts are minimum (in \u00121sense, for example). That is equivalent to adding a layer on top of the optimization problem (4.6) to pick the minimal-uplift solution among68 Figure 4.1: An illustration of the set \u0003for an example with 3 non-convex cost functions. Thethreebluecurvesarethecostfunctions. The(dashedandsolid)red lines lie below all the cost functions and their slopes are in \u0003. The (slope of the) solid red line corresponds to the largest element of \u0003. all the solutions, i.e., min of all _'s for which the linear price _@lies below all the cost functions, i.e., \u0003=f_\u00150j_@\u001428\u00b9@\u00ba\u00968@\u009688g\u0095 (4.8) Figure 4.1 illustrates this set for an example with three non-convex costs. The solutions to problems (4.6)and(4.7)can be found in closed-form, and the following summarizes the results. Proposition 18. The set of optimal solutions of problem (4.6)is for proofs. Note that there were two potential alternatives to the two-stage optimization in (4.7) forpickingaminimum-upliftsolution. Onemayhaveattemptedtoenforceuniformity asaconstraint. However,theproblemwiththisisthatimposing,forexample,box constraintson Drequiresknowledgeofreasonableupper-boundsontheuplifts,which may not be available; and on the other hand, insisting on exact uniformity makes the probleminfeasibleinmostnon-convexcases. Theotheralternativeistominimize a combination of the two objectives in (4.6)and(4.7). In this case, the weighted objective becomes\u00cd= 8=1\u00b9_@8\u00b8WD8\u00bafor some appropriate constant W, and it is not hard to show that the solution will be the same as that of the proposed two-stage optimization. 4.3.2 An Ecient Approximation Algorithm The optimization problem desired propertiesinanynon-convexmarket. Forspecicclassesofcostfunctions,similarto theexistingapproaches,onemaybeabletosolvethisoptimizationproblemusingo- the-shelfsolvers. problem (4.5)to optimality. Furthermore, even nding an approximate solution, e.g., by discretizating the variables, requires a brute-force search, which quickly becomes intractable. In this section, we design acomputationallyecientalgorithmforsolvingtheproblem (4.5)approximately, basedondecomposingitintosmallerpieces,whichworksforgeneralnon-convex cost functions. Thisapproximationalgorithmcan alsobe usedtoprovidetractable calculations of some of the other non-convex pricing rules such as IP pricing. Before going through the details of the algorithm, let us dene the notion of an approximate solution to (4.5), which we consider. One could dene an approximate solution as a value that is close enough, in a certain sense, to the optimal solution \u00b9@\u0003 1\u0096\u0095\u0095\u0095\u0096@\u0003 =\u0096U\u0003\u0096V\u0003 1\u0096\u0095\u0095\u0095\u0096V\u0003 =\u00ba. However, no matter how close that approximation is to the optimal solution, that per se does not guarantee anything about the properties that the scheme will satisfy. Instead, we dene an approximate solution to (4.5) as a set of quantities @1\u0096\u0095\u0095\u0095\u0096@=and price parameters U\u0096V 1\u0096\u0095\u0095\u0095\u0096V=for which the MarketClearingconditionholdsexactly,theRevenueAdequacyandCompetitive Equilibrium conditions are relaxed by an n, and the total payment is at most =naway from the optimal. More formally, it is dened as Denition ( @8\u0096V8) for each 8. AlthoughtheMarketClearingconditionstillcouplesthevariablestogether,this observation xed value of Uand@8, the optimization over V8can be done individually, as in (4.10). What remains to address, however, is the coupling of the variables as a result of the Market Clearing constraint. One naive approach would be to simply try all possible choices of \u00b9@1\u0096\u0095\u0095\u0095\u0096@=\u00baand pick the one that has theminimumobjectivevalue. Thisisveryinecient. Instead,wetakeadynamic programmingapproach,andgrouppairsofvariablestogether,deninganewvariable71 Figure 4.2: An example of the binary tree dened by Algorithm 1 for ==8. The faded circles correspond to the added dummy nodes. astheirparent. Wethengrouptheparentstogether,andcontinuethisprocessuntil we reach the root, i.e., where there is only one node. During this procedure, at each new node8, we need to solve the following (small) problem 68\u00b9@;U\u00ba=min s.t.@9\u00b8@:=@\u0096(4.11) forevery@, where9and:arethechildrenof8. Attherootofthetree, wewillbe able to compute 6root\u00b93;U\u00ba. Figure 4.2 shows an example of the created binary tree forthisprocedurefor ==8. Thisprocedurecanberepeatedfordierentvaluesof U, and the optimal value as minU6root\u00b93;U\u00ba. The problem (4.11)is that it requires an innite-dimensional compu- tation at every step, since the values of 68\u00b9@;U\u00baneed to be computed for every @. To get around this issue, we note that the variables @8live in the bounded set \u00bb0\u00963\u00bc, and hencecan be &, such thatevery possible @8is at mostX\u00b9n\u00baaway from some point in &. Similarly, if appendix for details. For nding an if:=;then68\u00b9\u0095;U\u00ba=69\u00b9\u0095;U\u00ba 12: else, compute 68\u00b9@;U\u00bafor all@in&, using (4.13) \u009dit children 13: 14: end for (4.12)by18\u00b9@;U\u00ba, and the optimizer of(4.13), which is a pair of quantities \u00b9@9\u0096@:\u00ba, byG8\u00b9@;U\u00ba. The full procedure is summarized in pseudocode in Algorithm 1. Whilenotimmediatelyclear,theproposedapproximationalgorithmcanbeshown to run in time that is polynomial in both =and1\u009dn(in fact, linear in =). Further, the solution it provides is n-accurate under a mild smoothness assumption on the cost and price functions, which holds true for almost any function considered in the literature. These two results are summarized in the following theorem, which is proven in the appendix. Theorem 20. Consider28\u00b9\u0095\u00baand?\u00b9\u0095;\u0095\u00bathat have at ;1and;2are the number of shared and individual parameters in the price, respectively. It isworth emphasizing thatwhile there are ;1\u00b8=;2variables inthe price functions in total, parameters ;1and;2do not scale with =, and are typically very small constants. Forexample,fortheso-calledlinear-plus-upliftpricefunctions ;1=;2=1. Therefore, the algorithm is very ecient. We should also remark that if one requires the total payment in Denition 1 to be at mostn(rather than=n) away from the optimal ?\u0003, the running time of our algorithm will still be polynomial in both =and1\u009dn, i.e.,$\u0010 =3\u00b91 n\u00ba;1\u00b8;2\u00b82\u0011 . See the Thenetworkedmarketweconsiderhas =suppliers,located at the nodes (vertices) +=f1\u0096\u0095\u0095\u0095\u0096=gof a network, and connected through lines (edges)\u001a, where, without loss of generality, the edges are dened to be from the smaller node to the larger node (i.e., 8\u00b98\u00969\u00ba2\u001a\u0096 8 \u009f 9). The8-th supplier has a cost function28\u00b9@8\u00bafor producing quantity @8, which may be non-convex, as before, and74 thereisaninelasticdemand 38ateachnode 8. Thelinesconnectingthenodescan possibly have certain capacities for the flows they can carry. We denote theflow of any line4=\u00b98\u00969\u00ba, from8to9, by54, by 54and54(the flow from9to8is\u000054). Notethatiftherearemultiplesuppliersco-locatedinamarket, wecansimplyassign them each their own vertex, and connect them through paths with innite capacities. Inotherwords,anodewithmultiplesupplierscanbesimplyreplacedwitha\"line graph\" composed of those suppliers and innite-capacity edges. 4.4.1 Pricing Formulation A key benet of EC pricing is the ease of generalization to the networked setting. There are no current pricing rules that can be readily applied to the networked case. In this setting,our Equilibrium-Constrainedpricing canbe is the total payment, as discussed before, and the optimization is over quantities@8, line flows54, and price functions ?82P. Constraint (4.14b)is the Market Clearing condition (or Flow Conservation) for each individual node, i.e., the net production at each node should be equal to its outgoing flow. Constraint (4.14c) enforcesthelinelimits(CapacityConstraints). Constraints (4.14d)and(4.14e)are RevenueAdequacyandCompetitiveEquilibrium,respectively,asbefore. Thekey dierence between the networked setting and the single-market one is that here, the Market Clearing condition is spread across the network, and we have to solve the problem for the flows as well.75 Remark. Whenthecapacityconstraints (4.14c)arerelaxed( 54=\u00001\u009654=1\u0096842 \u001a),thenetworkedproblemreducestothesingle-marketone. Inthiscase,thesolution to the optimization problem (4.14)reduces to that of (4.1). That is because the only constraintinvolvingtheflowswouldbe (4.14b),andwecanalwaysndsflowsthat satisfyit,aslongas\u00cd= 8=1@8\u0000\u00cd= 8=138=0,whichistheconventionalMarketClearing condition. Assuming a of non-convexities, the optimization problem (4.15)can still be solved using o-the-shelf solvers, similar to those used in the other methods for the no-network case. However, those algorithms cannot handle more general classesofnon-convexities. Inthissection,wedevelopacomputationallyecient approximationalgorithmforgeneralnon-convexcosts,foraspecialclassofnetworks. Aspecialyetimportantclassofnetworksare acyclicnetworks,whichareatypical topology Acyclic networkshavea treetopology(theydonothavecycles),whichallowsustodevisean ecient algorithm for them. In the remainder of this section, we limit our attention to these networks. The main ideas extend directly to more general networks, as76 long as there are not \"too many cycles\" in the network in some sense (i.e., bounded tree-width networks). We have focused on the acyclic case due to space constraints. Without loss of generality, let us denote the rst node as the rootof the tree, and nodes with only one neighbor as the leaves. Every node (except the root) has a uniqueparent,denedastherstnodeontheuniquepathconnectingittotheroot node. The saidto benode 8's children. It can be shown that any tree with arbitrary degree can be transformed into abinary tree , i.e., a tree where each node has a unique parent and at most 2 children, with$\u00b9=\u00banodes (see the appendix). Thus, we can focus on binary trees. Foranode8,letch1\u00b98\u00ba\u0096ch2\u00b98\u00badenoteitschildren( ch1\u00b98\u00ba=;and/or ch2\u00b98\u00ba=;when 8has less than two children). The problem the denition in the single-market case is that the Market Clearing condition has been replaced with n-Load Balancing and exact Flow Limit conditions here. Note that the minimization over the variables V8in problem (4.16)can be done \"internally,\" and the The key insight is that the tree structure of the constraints (4.17b)allows us to write the optimization problem in a recursive form as follows: ?\u0003=min U\u0011root\u00b90;U\u00ba (4.19)78 Algorithm 2 Now, this recursive form is amenable to dynamic programming. However, since the variablesarecontinuous,eachstepstillrequiresaninnite-dimensionalsearch. In order to tackle this issue, we can discretize the variables and solve the following approximate versions. \u00118\u00b958;U\u00ba= min @82&8 5ch1\u00b98\u00ba2\u001bch1\u00b98\u00ba 5ch2\u00b98\u00ba2\u001bch2\u00b98\u00ba68\u00b9@8;U\u00ba\u00b8\u0011ch1\u00b98\u00ba\u00b95ch1\u00b98\u00ba;U\u00ba\u00b8\u0011ch2\u00b98\u00ba\u00b95ch2\u00b98\u00ba;U\u00ba(4.21a) s.t.j@8\u000038\u00005ch1\u00b98\u00ba\u00005ch2\u00b98\u00ba\u00b858j\u0014n 18\u00b9@;U\u00ba. ThestepsoftheprocedurearesummarizedinpseudocodeinAlgorithm2,andthe the number of shared and individual parameters in the price, respectively. It is worth mentioning that the network algorithm developed in this section suggests anotherwayofsolvingtheno-networkcaseaswell,byreplacingthesinglemarket with a line graph with innite capacities. This algorithm will in turn have time complexity$\u0010 =\u00b91 n\u00ba;1\u00b8;2\u00b82\u0011 , which is the same as that of the one developed in Section 4.3.2. 4.5 Existing Pricing Schemes Inthissection,wereviewtheexistingpricingschemesintheliteratureandsummarize theirproperties. Nopriorpricingruleforgeneralnon-convexmarketssatisesall thepropertiesdiscussedinSection4.2.2. However,itispossibletoachieveallthe propertiesinthecasewhenthecostfunctionsareconvexviaaclassicalapproach: shadow pricing . We rst briefly illustrate how shadow pricing works for the convex case,andthensurveysomeprominentapproachesintheliteraturethatseektoextend thepropertiesofshadowpricingtothenon-convexcase,contrastingthemwiththe EC scheme. 4.5.1 Pricing in Convex Markets referred to as shadow pricing ormarginal-cost pricing [201, 32], can achieve all the above-mentioned properties. The pricing scheme works as follows. The operator80 rst solves the Let @\u0003 1\u0096\u0095\u0095\u0095\u0096@\u0003 =and_\u0003denote an optimal primal-dual pair of this problem (if there are multiple dual solutions, take _\u0003to be the smallest). A payment function of the form ?8\u00b9@8\u00ba=_\u0003@88=1\u0096\u0095\u0095\u0095\u0096= (4.24) satisesallthepropertiesoutlinedinSection4.2.2,anditisrelativelystraightforward to see that. (4.23) satises the following max @8_\u0003@8\u000028\u00b9@8\u00ba\u0095 Since28\u00b9\u0095\u00bais convex, the objective is concave, and any the derivative iszeroisaglobalmaximizer. Inparticular,thederivativeat @\u0003 8iszero,becauseofthe KKTconditions,andthereforethatisasolutiontothesupplier 8'sprot-maximization problem. As a result, the scheme supports a competitive equilibrium that clears the marketandminimizestheproductioncost,whileusingapriceformthatissimple anduniform. Figure4.3illustratestheoptimalquantitiesandthepricefunctionfor an example with three suppliers. Note that the total payment of this scheme is\u00cd= 8=1?8\u00b9@\u0003 8\u00ba=_\u00033, which can be generally higher than\u00cd= 8=128\u00b9@\u0003 8\u00ba. One can always opt for However, if one requires a uniform and linear price function, it can be shown that ?8\u00b9@8\u00ba=_\u0003@8has thelowest total payment among all such functions.81 Figure 4.3: An illustration of shadow pricing for the case of 3 convex cost functions. Thepointsindicatedby \u0003showtheoptimalquantities. The3functionshavethesame derivative at their optimal quantities, and the tangent line lies below the function (because of convexity). The red (solid) line that passes through the origin is the uniform price function, which is parallel to the three lines. 4.5.2 Pricing in Non-Convex Markets If the cost functions are non-convex, the approach of shadow pricing, described above, fails. This is because the net prot of each supplier is no longer a concave function, and itsstationary context of non-convex cost functions. We review the most promising ones here. Some of the schemes maintain a uniform pricing rule with additional discriminatory side-payments called \"uplifts\" for incentivizing the suppliers to follow the dispatch, whileothersraisetheuniformpricesothatitisrevenue-adequate. Asummaryofthe pricing schemes, along with their properties, is provided in Table 4.1. Integer Programming (IP) [159]proposedapricingschemefornon-convexcostfunctionsthatareintheformof axed(start-up)costplusalinearmarginalcost,sometimesreferredtoas\"IPpricing.\" Thisschemeusesuniformmarginalpricingforthecommodityanddiscriminatory82 Table 4.1: Summary of common pricing schemes and their properties. SchemenProperty Price form ?8\u00b9@8\u00ba=Proposed Theresultsinthistableassumesolvingthe formulation for each scheme exactly. However, in practice, these schemes rely on numerical solvers for their problems, and if the problem is non-convex, there is no guarantee of maintaining these properties in general. In particular, the IP scheme requiresa non-convex solver. The MU/CH, SLR, and PD schemes, for the cost functions that they are proposed for (i.e., startup+convex or startup+linear), require only convex solvers and thereforesatisfythecheckedpropertiesexactly. TheECschemeisaccompaniedbyanecientalgorithm for solving the non-convex problem for general cost functions, which satises the exact Market Clearing property and the n-approximate versions of the other three properties (see Section 4.3.2). pricing for the integral activity of the suppliers. It is based on (i) formulating an optimizationsimilarto (4.23),asamixedintegerlinearprogram(MILP)andsolving it for optimal allocations, (ii) reformulating the original MILP as an LP by replacing the integral constraints with forcing commitment choices equal to their optimal values, and (iii) solving the LP problem and using the dual variable _of Market Clearing constraint as the uniform price and the dual variables fD\u0003 8gof the forced equality constraints as discriminatory uplifts: ?8\u00b9@8\u00ba=_\u0003@8\u00b8D\u0003 81f@8\u00a10g. IP pricing uses a uniform price plus a discriminatory uplift to clear the market ecientlysuchthateverysupplier'snetprotiszero. Asaresult,bothtotalpayments and total production costs are minimized at the same time. [159] show that the optimal solutions generated by IP pricing are optimal to the decentralized prot maximization problems for every supplier, and thus they support a competitive equilibrium. However, IP pricing assumes knowledge of the optimal solutions to the unitcommitmentproblemandthusisnotintendedasapracticalapproachtondthe optimalallocation. [103]pointoutthatuniformpricegeneratedunderIPpricingcan be volatile (i.e., a small change in demand could lead to a big change in the uniform price) and uplifts could be generally very large.83 Minimum Uplift (MU) / Convex Hull (CH) To avoid the unwanted properties of IP pricing (i.e., volatility and instability), a pricing scheme, proposed in [103] for the (non-convex) class of startup-plus-convex costfunctions,oersminimumupliftsthatincentivizeeachsuppliertofollowthe dispatchratherthanmaximizetheirownprotsintheabsenceofuplifts. Thescheme is based on solving the mixed-integer program minimizing the total production cost andminimizingtotaluplifts. Givenaxeduniformprice _,eachsupplierchooses between following the dispatch to receive the uplifts or not. The uplifts can be viewedastheextrapotentialprotthatthesupplierscanmakebyself-schedulingand maximizing their own prot. [81] rened the MU pricing and proposed the concept ofConvexHullpricing,whichisbasedon(i)replacingthenon-convexcostofthe original program with its convex hull to formulate a new LP and (ii) solving the new LP and using the dual variable of the Market Clearing constraint as the marginal price and deriving the lost opportunity cost as the minimum uplifts to incentivize suppliers' compliance. The nal end up being high, and the payments can be much higher than those of the other schemes. In general, the total payments under this scheme might end up being muchhigherthanthetotalproductioncosts,whichdefeatsthepurposeofminimizing thecosts. Evenfortheclassofstartup-plus-linearcostfunctions,whereIPpricing is optimal (the total payment is equal to the total production cost, and they are bothminimal),MUpricingisnoteconomicallyecient,asitfailstominimizethe payments. On the computational side, although [107] propose a polynomially-solvable primal formulation for the Lagrangian dual problem by explicitly describing the convex hullforpiecewiselinearorquadraticcostfunctions,describingtheconvexhullof cost functions could be very challenging in general and thus makes the problem computationally intractable. As an aside, MU and CH would not be equivalent if the Market Clearing constraint wasaninequality. Inthatcase,theside-paymentsinCHwouldbetypicallylarger than those in MU, due to Product Revenue Shortfall [181].84 Semi-Lagrangean Relaxation (SLR) [10] introduced a semi-Lagrangean relaxation approach to nd a uniform price that is revenue-adequate at the same solution for quantity and commitment choices as the original optimization problem, for cost functions of startup-plus-linear form. The scheme is based on formulating and solving the SLR of the mixed-integer programbysemi-relaxingtheMarketClearingconstraintwithstandardLagrange multiplier_. The solution under SLR satises the constraints in the original MIP and makes the duality gap between MILP and SLR zero. Though the payment function?8\u00b9@8\u00ba=_\u0003@8underSLRpricingishighenoughtoavoidnegativeprots for suppliers, it incentivizes the suppliers to deviate and operate at full capacity, and total payments usually end up being much higher than total costs of production. Primal-Dual (PD) Anotherrevenue-adequatepricingscheme,proposedby[177],exploitsaprimal-dual approach to derive a uniform price to guarantee that dispatched suppliers are willing toremaininthemarket(revenueadequacy). Theschemeworksforcostfunctions with the form of start-up cost plus linear cost, and the prices have shown not to deviate muchfrom thatof [159]. The approachis based on(i) relaxingthe integral constraint of the original MILP to formulate a primal LP problem, (ii) deriving the dual LP problem of the primal LP problem, (iii) formulating a new LP problem that seeks to minimize the duality gap between the primal and dual problems subject to bothprimalanddualconstraints,and(iv)addingbacktheintegralconstraintsaswell as nonlinear constraints to ensure that no supplier incurs loss and solving the new problem for optimal solutions @\u0003 8\u0096I\u0003 8and_\u0003. Though this scheme may be implemented using standard branch-and-cut solvers, it is computationally intractable in general. The prices ?8\u00b9@8\u00ba=_\u0003@8and prots producedunderPDdonotsignicantlydeviatefromdualpricesifintegralconstraints arerelaxedandthusarealwaysbounded. However,asarevenue-adequatepricing scheme, PD fails to form a competitive equilibrium as suppliers are incentivized to operate at full capacity. In general, total payments are much higher than total production costs. 4.6 Experimental Results In this section, we compare and contrast EC pricing with the existing approaches using numerical experiments on common case studies. Specically, we compare85 the payments and uplifts generated from dierent pricing schemes, including IP, CH,SLR,PD,andEC.Amongalltheseschemes,onlyECallowsflexibilityofthe paymentform. Asaresult,wefurtherdivideECintoonewithapaymentfunctionin the form of linear marginal price plus uplifts and another pricing with a payment form ofpiecewise linear marginal pricesplus uplifts. Inpractice, specic limits on thenumberofsectionsandthemaximumslopeamongallsectionscanbeusedto further restrict EC. For convenience, we name these variations of EC in terms of number of piecewise sections of its payment form, e.g., EC2 refers to EC with a payment function in the form of 2 piecewise sections plus uplifts. First, we apply all these pricing schemes to a singlemarket example from [103], which is a modication of Scarf's example developed in [179]. Second, we adapt costfunctionsinthemodiedScarf'sexampletobequadraticplusstartupcostin order to further explore how these schemes generalize to dierent cost functions. Finally, we consider a further generalization to a simple 2-node networked market. 4.6.1 Case 1: Linear plus startup cost Table4.2: SummaryoftheproductioncharacteristicsinthemodiedScarf'sexample. Type Smokestack High Tech Med Tech Capacity 16 7 6 Minimum output 0 0 2 Startup cost 53 30 0 Marginal cost 3 2 7 Quantity 6 5 5 WeconsideramodiedScarf'sexample,asproposedin[103]. Theparametersare listedinTable4.2. Weassumethatdemandisinelasticwithamaximumcapacity of 161 units. We restrict the payment function of EC1, EC2, EC3, and EC4 to respectively have one, two, three, and four sections and impose that the marginal price of any section cannot exceed the maximum marginal price for any supplier operating at full capacity. Figure 4.4a shows total payments for dierent demand levels, while Figure 4.4c shows the corresponding uplifts of the pricing schemes thatapply,i.e.,CH,EC1,EC2,EC3,andEC4. Paymentsoftworevenue-adequate pricingschemes,includingSLRandPD,arehigherthantotalcostsingeneral. IP, EC1,EC2,EC3,andEC4achievetheminimumpaymentsequaltototalcosts. CH achievestheminimumpaymentsatlowdemandlevels,anditstotalpaymentssurpass total costs as demand gets high. As for uplifts, EC4 achieves the smallest among86 the ve pricing schemes. Total uplifts of CH and EC1 are close to each other at a low demand level and that of EC1 increases signicantly when demand approaches capacity. This is not surprising, as total payments of CH go above total costs at a highdemand,makingitpossibleforrelativelysmallertotaluplifts. Itisworthnoting thatstartuppricesandmarginalpricesforIParevolatileandunstable. Figure4.4d and 4.4e demonstrate that the more complex we allow payment functions of the EC family,thesmallertotalupliftswecanachieve,whichmeansmoreuniformprices are acrosssuppliers. In practice, there isapparently a trade-obetween complexity and uniformity of payment functions among the EC family, and this will be a design choicefortheindependentsystemoperator(ISO).Overall,EC4outperformsother pricing schemes in terms of total payments and total uplifts. (a)Total payments as a function of demand. (b)Payment dierence in percent- age w.r.t Figure 4.4: An example with cost functions of the form of linear plus startup cost. 4.6.2 Case 2: Quadratic plus startup cost Table 4.3: Summary of the new cost functions in the modied Scarf's example. Type Smokestack High Tech 16@2\u00b853\u00031f@ \u00a10g2 7@2\u00b830\u00031f@ \u00a10g7 (b)Payment dierence in percent- age w.r.t Tofurtherexplorehowthesepricingschemesgeneralizetodierentcostfunctions, we modify the cost functions of the example above. Table 4.3 describes the new cost functions for each supplier. Since it is not clear how to generalize SLR and PD, we focus on a comparison among IP, CH, EC1, EC2, EC3, and EC4. We of EC1, EC2, EC3, and EC4 withthe marginalprice ofany sectionbounded by the maximum of marginal price for any supplier operating at full capacity. As can be seeninFigure4.5a,EC1EC2,EC3,andEC4achievethepossibleminimumtotal payments equal to total costs. Total payments of IP and CH are both above total costs, and the gap between total payments and costs grows as demand increases. Observethatthedemandhererangesfrom1to160becausemarginalpriceofCH increases dramatically at the capacity level, and the plot over the interval \u00b91\u0096160\u00ba would be a flat line if the whole range were covered. Figure 4.5c shows that total uplifts of EC1 are much larger than that of CH and EC2. At a low demand level, uplifts of EC1 and EC2 are close to each other. As demand increases, uplifts of EC2 arealittlelargerthanthoseofCH,inordertomaintainasmalleroverallpayment. Thereisatrade-obetweenminimizingtotalpaymentsandminimizingtotalcosts. Allowing the flexibility of payment function form enables EC2 to perform better than eitherCH or EC1 Figure 4.6: A schematic drawing for two connected markets with a constraint on flow capacity. show a relationship between complexity of payment function form and magnitude of totalupliftsamongtheECfamilypricingschemes. Asinthecaseofcostfunction being start-up plus linear cost, it is not surprising to see that more complex payment functionstendtoallowsmallertotaluplifts,i.e.,moreuniformpricesacrosssuppliers. 4.6.3 A Networked Market with Capacity Constraints OneadvantageEChasoveralltheotherpricingschemesisitsgenerality. Specically, EC can be applied tonetworked markets. In this section, we divide a single market with a xed total demand 60as described earlier into one market with only med tech suppliersandtheotheronewiththesmokestackandhigh-techsuppliers. Thecost functions of the suppliers are the same as dened earlier, i.e., linear plus startup cost. As pictured in Figure 4.6, these two markets are connected via a flow capacity constraint. We consider two dierent cases of non-uniform marginal pricing and uniformmarginalpricingforthesetwomarkets. Figure4.7showshowtotalpayments, total uplifts and flow between these two connected markets vary as flow capacity increasesfornonuniformanduniformmarginalpricingsettings. Theresultsshow that the totalpayments andtotal allowed between thesetwomarketsuntilitreachesthedemandofonemarket,whichmeansonemarket alonemeetsthetotaldemand. Allowingnon-uniformpricingdoesnotfurtherreduce total payments, as total payments are minimal and equal the total costs. However, it helps reduce total uplifts, as we can see in Figure 4.7b.89 (a)Total payments as a function of flow capacity. (b)Total uplifts as a function of flow capacity. (c)Flow between two markets as a function of flow capacity. Figure 4.7: An example of two connected markets with a constraint on the flow capacity. 4.7 Concluding Remarks We study the problemof pricingin single and networked marketswith non-convex costs. Our key contribution is the proposal of a novel scheme, Equilibrium- Constrained (EC) pricing, which optimizes for the allocations and price parameters at the same time, while imposing the equilibrium conditions as constraints. Our pricing framework isgeneral in the sensethat: (i) it can beused for pricing general non-convexcostfunctions,(ii)itallowsforusinggeneralpriceclasses,(iii)canbe computedinpolynomial-timeregardlessofthesourceofthenon-convexities,and (iv) it extends easily to networked markets. This work opens up a variety of important directions for future work. First, as this framework enables one to use general price classes, it would be interesting to apply it to specic classes of price functions (e.g., quadratic plus uplift, piece- wise,etc.) andcharacterizethesolutiontheoreticallyand/ornumerically. Onecan then investigate the potential trade-os between the complexity of the class and the economic eciency or the uniformity of the price. Second, since electricity marketsareanimportantapplicationofthepricingproblemstudiedhere,itwould be interesting to evaluate the proposed scheme in practical settings for electricity markets. Ourpreliminaryexplorationshowsthatwecanachievemoreecient(lower total payments) and less discriminatory (lower uplifts) prices with, for instance, piece-wise linear functions. More evaluations in large-scale, practical settings should be carried out in order to evaluate the potential of deployment. Another importantdirectiontopursueistheextensionofourresultstonetworkedmarketswith moregeneralnetwork structures. Ouralgorithm currentlyapplies tonetworks with bounded tree-width; however beyond such networks, new ideas are needed. Finally, our proposed pricing scheme has broader implications for non-convex distributed optimization algorithms in the non-convex setting.91 4.A Supplement to Section 4.3.1 In this section, we formally prove the reduction of the optimization problem for the class of linear-plus-uplift functions to (4.6), and then show Propositions 18 and 19. 4.A.1 Reduction Here,weshowthatfortheclassoflinear-plus-upliftpricefunctions ?\u00b9@8;_\u0096D8\u0096@8\u00ba= _@8\u00b8D8 generality, and therefore the optimization problem (4.5)reduces to (4.6)for this class. The optimization problem(4.5)for price shows that this optimization problem can be reduced to (4.6), and the optimal uplifts of (4.6) are no larger than those of (4.25). Lemma 22. Given any solution \u00b9q\u0003\u0096_\u0003\u0096u\u0003\u0096^q\u0003\u00bato the optimization problem (4.25), \u00b9q\u0003\u0096_\u0003\u0096u\u0096q\u0003\u00bais also a solution, where D8=8>> < >>:D\u0003 8\u0096if@\u0003 8=@\u0003 8 0\u0096o.w.\u0095 Proof of Lemma 22. Let us rst show the feasibility of \u00b9q\u0003\u0096_\u0003\u0096u\u0096q\u0003\u00ba. For any8 such that @\u0003 is the as that of \u00b9q\u0003\u0096_\u0003\u0096u\u0003\u0096^q\u0003\u00ba, and is therefore optimal. \u0003 Based on this lemma, the optimization problem (4.25) can be reduced to (4.6). 4.A.2 Closed-Form Solutions Proof of Proposition 18. Intheoptimizationproblem (4.6),theorderofvariablesin the minimizations does not matter, and further, for every xed @1\u0096\u0095\u0095\u0095\u0096@=and_, the minimizationovereach D8canbedoneseparately. Therefore,thisprogramcanbe of _and@8. Therefore, we have min _\u00150=\u00d5 8=168\u00b9@8;_\u00ba==\u00d5 8=128\u00b9@8\u00ba\u0096 and @0 8<@8_@0 which are exactly the elements of \u0003 =f_\u00150j_@\u001428\u00b9@\u00ba\u00968@\u009688g(Figure 4.1 provides a pictorial descriptionof these values.) Finally, we have the last minimization, which one, except that the additional minimizer picks the _with the smallest total uplift\u00cd= 8=1D8\u00b9_\u00ba, which corresponds to the largest element of \u0003. 4.B Supplement to Section 4.3.2 Algorithm 1 nds an n-approximate solution, and we quantify the sizes of these sets as a function of n. In the second part, we analyze the running time of Algorithm 1. 4.B.1n-Accuracy Let us rst state a simple but useful lemma. Lemma 23 (X-discretization) .Given a setC\u0012\u00bb!1\u0096!1\u00bc\u0002\u0001\u0001\u0001\u0002\u00bb!:\u0096!:\u00bc, for any X\u00a10, set C0such that 8I2C\u00969I02C0s.t.kI\u0000I0k1\u0014X\u0096 andfurther,C0containsatmost +\u009dX:points,where +=\u00ce: 8=1\u00b9!8\u0000!8\u00baisaconstant (the volume be a X-discretization ofC. Let&,A0,andB0denotesome X-discretizationsofsets exist@02&,U02A0, andV02B0, such thatj@\u0000@0j\u0014X,kU\u0000U0k1\u0014X, andkV\u0000V0k1\u0014X. We can combine all these inequalities as k\u00b9@\u0096U\u0096V\u00ba\u0000\u00b9@0\u0096U0\u0096V0\u00bak1\u0014X\u0095 On the other hand, given that the cost function 28\u00b9\u0095\u00bafor each8is Lipschitz on each continuous piece of its domain, there exists a positive constant 8such that j28\u00b9@\u00ba\u000028\u00b9@0\u00baj\u0014 8j@\u0000@0j, is larger than ?\u0003at most by= X. As a result, this point will be an constraints altogether enforce an upper bound on the value of Xas X\u0014\u0018n\u0096 for some constant \u0018. Therefore if we pick has #@=d\u0003e3 \u0018n\u00b81=$\u00121 n\u0013 points. The nice thing about this particular choice of X isthatnow3canbewrittenasasumof =elementsin&(becausealltheelements, including3, are multiples of X), which allows us to satisfy the Market to our discrete sets &,A0, andB0, and since there are at most a nite number of them, the sizes of the sets remain in the same order, the time complexity of Algorithm 1 running on these discrete showthatAlgorithm1hasatimecomplexityof $\u0010 =\u00b91 n\u00ba;1\u00b8;2\u00b82\u0011 have the following computations: 1.The leaves: We need to compute each 68\u00b9@;U\u00ba(i.e., for xed 8\u0096@\u0096U) takes$\u00b9#V#@\u00ba. The reason for that is we have to search over all V82\u00170, and for each In each new level, there are at most half as many (+1) nodes as in the previous level. For each node 8in this level, we need to compute68\u00b9@;U\u00bafor every@2&. For every xed @, there are$\u00b9#@\u00ba possible pairs of\u00b9@9\u0096@:\u00bathat add up to @, and therefore we need to (a) sum $\u00b9#@\u00bapairsofobjectivevalues,and(b)ndtheminimumamongthem,which take$\u00b9#@\u00ba. Hence, the computation for each There are $\u00b9= 2\u00b8= 4\u00b8\u0001\u0001\u0001\u00b8 2\u00ba=$\u00b9=\u00baintermediate nodes in total, and therefore the total complexity of this part is $\u00b9=#2 @\u00ba. 3.The root: Finally at the root, we need to compute 6root\u00b93;U\u00ba. There are#@ possible pairs of\u00b9@9\u0096@:\u00bathat add up to 3. Therefore, we need to compute #@sums,andndtheminimumamongtheresulting #@values,whichtakes $\u00b9#@\u00ba. Putting the pieces together, the values of Utakes#U\u0002\u0010 $\u00b9=#V#2 @\u00ba\u00b8$\u00b9=#2 @\u00ba\u00b8$\u00b9#@\u00ba\u0011 , which in turn is $\u00b9=#U#V#2 @\u00ba. Finally, nd- ing the minimum among the #Uvalues simply takes $\u00b9#U\u00ba. Thebackwardprocedure,whichndsthequantities @8andtheparameters V8,takes just$\u00b9=\u00ba, since it is just a substitution for every node. As a result, the total running timeis$\u00b9=#U#V#2 @\u00ba,whichbasedontherstpart(Section4.B.1)is $\u0010 =\u00b91 n\u00ba;1\u00b8;2\u00b82\u0011 . 4.B.3 Remark on As mentioned at the end of Section 4.3.2, if one requires the total enforced by the constraints will be X\u0014\u0018n =\u0096 for some constant \u0018. In this Xwould beX=3 d\u0003e3= \u0018n\u0096and hence#@=$\u0010= n\u0011 .#Uand#Vremain $\u00b9=#U#V#2 @\u00ba,ascomputedpreviously,whichinthiscasewouldbe $\u0010 =3\u00b91 n\u00ba;1\u00b8;2\u00b82\u0011 .97 Figure 4.8: The transformation of an arbitrary-degree tree to a binary tree. 4.C Supplement to Section 4.4 In this section, we rst show the transformation of the problem on a tree to one on a binary tree, and then prove Theorem 21. 4.C.1 Transformation into Binary Tree Lemma 24. Given any tree with =nodes (suppliers), there exists a binary tree with additional nodes which has the same solution \u00b9@\u0003 8\u0096\u0095\u0095\u0095\u0096@\u0003 =\u0096U\u0003\u0096V1\u0096\u0095\u0095\u0095\u0096V=\u00bafor those nodes as the original network. The binary tree has $\u00b9=\u00banodes. Proof.Take any node 8that has:8\u00a12children. For any two children, introduce adummyparentnode. Foranytwodummyparentnodes,introduceanewlevelof dummy parent nodes. Continue this process until there are 2 or less nodes in the uppermostlayer,andthenconnectthemtonode 8(seeFig.4.8). Thecapacitiesof the lines immediately connected to the children are the same as those in the original graph. The capacities of the new lines are innite. The total number of introduced dummy nodes by this procedure is $\u00b9:8 2\u00b8:8 4\u00b8\u0001\u0001\u0001\u00b8 2\u00ba=$\u00b9:8\u00ba\u0095 Since there are 1\u00b8:1\u00b8:2\u00b8\u0001\u0001\u0001\u00b8:===nodes in total in the original tree, the number of introduced additional nodes is $\u00b9:1\u00b8\u0001\u0001\u0001\u00b8:=\u00ba=$\u00b9=\u00ba. Therefore the total number of nodes in the new (binary) tree is $\u00b9=\u00ba. \u0003 4.C.2 Proof of Theorem 21 Most of the proof is similar to the one presented in Section 4.B. For this reason, we only highlight the main points. The proof consists of n-accuracy and run-time, as before.98 on of XasX\u0014\u0018n\u0096for some constant \u0018. Based on Lemma (23), the sizes of the every xed U, the run-time of the required computations is as follows. 1.The time complexity of computing 68\u00b9@8;U\u00bafor each 5ch2\u00b98\u00ba\u00ba(@8is automaticallydeterminedastheclosestpointin &8to38\u00b85ch1\u00b98\u00ba\u00b85ch2\u00b98\u00ba\u000058). Therefore, its overall computation for all nodes and all values takes $\u00b9=#3 5\u00ba. As a result, a pte r MANAGING AGGREGATORS IN THE SMART (2018), pp. 5687-5698. /d.sc/o.sc/i.sc:10.1109/TSG.2017.2694043 . Aggregators of distributed generation are playing an increasingly crucial role in the integration of renewable energy in power systems. However, the intermittent nature ofrenewablegenerationmakesmarketinteractionsofaggregatorsdiculttomonitor andregulate,raisingconcernsaboutpotentialmarketmanipulationbyaggregators. In this chapter, we study this issue by quantifying the prot an aggregator can obtain throughstrategiccurtailmentofgenerationinanelectricitymarket. Weshowthat, while the problem of maximizing the benet from curtailment is hard in general, ecientalgorithmsexistwhenthetopologyofthenetworkisradial(acyclic). Further, we highlight that signicant increases in prot are possible via strategic curtailment in practical settings. 5.1 Introduction Increasing the penetration of distributed, renewable energy resources into the electricity grid is a crucial part of building a sustainable energy landscape. To date, the entities that have been most successful at promoting and facilitating the adoption of renewable resources have been aggregators energy resources [192, 1], and the market is expected to triple in size by 2020 [133, 104]. Aggregatorsplayavarietyofimportantrolesintheconstructionofasustainablegrid. First,andforemost,theyareonthefrontlinesofthebattletopromoteinstallation of rooftop solar and household energy storage, pushing for widespread adoption100 ofdistributedenergyresourcesbyhouseholdsandbusinesses. Second,andjustas importantly, they provide a single interface point where utilities and Independent System Operators (ISOs) can interact with a fleet of distributed energy resources acrossthenetworkinordertoobtainavarietyofservices,fromrenewablegeneration capacitytodemandresponse. Thisserviceiscrucialforenablingsystemoperators to manage the challenges that result from unpredictable, intermittent renewable generation, e.g., wind and solar. However, in addition to the benets they provide, aggregators also create new challenges-bothfromtheperspectiveoftheaggregatorandtheperspectiveofthe system operator. On the side of the aggregator, the management of a geographically diverse fleet of distributed energy resources is a dicult algorithmic challenge. On the side of the operator, the participation of aggregators in electricity markets presents unique challenges in terms of monitoring and mitigating the potential of exercisingmarketpower. Inparticular,unliketraditionalgenerationresources,the ISO cannot verify the availability of the generation resources of aggregators. While the repair schedule of a conventional generator can be made public, the downtime of asolargenerationplantandthetimeswhensolargenerationisnotavailablecannotbe scheduledorveriedafterthefact. Thus,aggregatorshavetheabilitytostrategically curtailgenerationresourceswithouttheknowledgeoftheISO,andthispotentially creates signicant opportunities for them to manipulate prices. These issues are particularly salient given current proposals for distribution systems. Distributionsystems(whicharetypicallyradialnetworks)areheavilyimpactedby theintroductionofdistributedenergyresources. Asaresult,thereareavarietyof currentproposalstostartdistribution-levelpowermarkets(see,forexample[105] [106]), operated by Distribution System A future grid may even involveahierarchy ofsystem operatorsdealingwithprogressivelylargerareas, net load and net generation. In such a scenario, aggregators could end up having a signicant proportion of the market share, and such markets may be particularly vulnerable to strategic bidding practices of the aggregators. Thus, understanding the potentialfortheseaggregatorstoexercisemarketpowerisofgreatimportance,so that regulatory authorities can take appropriate steps to mitigate it as needed. 5.1.1 Summary of Contributions Thischapteraddressesboththealgorithmicchallengeofmanaginganaggregatorand theeconomicchallengeofmeasuringthepotentialforanaggregatortomanipulate101 prices. Specically,this work providesa newalgorithmic frameworkfor managing the participation of an aggregator in electricity markets, and uses this framework to evaluatethepotentialforaggregatorstoexercisemarketpower. Tothoseends,the chapter makes three main contributions. First, we introduce a new model for studying the market behavior of aggregators of distributed generation (renewables) in the real-time market. Second, we quantify opportunities for price manipulation (via strategic curtailment) by the aggregators. Our results highlight that, in practical scenarios, strategic curtailmentcanhaveasignicantimpactonprices,andyieldmuchhigherprotsfor the aggregators. In particular, the prices can be impacted up to a few tens of $/MWh insomecases,andthereisoftenmorethan25%higherprot,evenwithcurtailments limited to 1%. Third, we provide a novel algorithm for managing the participation of an aggregator in the market. The problem is NP-hard in general and is a bilevel quadratic program, whichisnotoriouslydicultinpractice. However,wedevelopanecientalgorithm that can be used by the aggregators in radial networks to approximate the optimal curtailment strategy and maximize their prot (Section 5.5). Note that the algorithm is not just relevant for aggregators; it can also be used by the operator to assess the potential for strategic curtailment. The key insight in the algorithm is that the optimization problem can be decomposed into \"local\" pieces and be solved approximately using a dynamic programming over the graph. We also provide an exact algorithm for the case of single-bus aggregators in general networks. Further,ourresultsexposeaconnectionbetweentheprotachievableviacurtailment and a new market power measure introduced in [221], which is discussed in Appendix 5.A. 5.1.2 Related Work Thischapterconnectsto,andbuildson,workinfourrelatedareas: 1)quantifying andmitigatingmarketpower,2)cyber-attacksinthegrid,3)algorithmsformanaging distributed and 4) algorithms for bilevel programs. 5.1.2.1 Quantifying Market Power in Electricity Markets Thereisalargevolumeofliteraturethatfocusesonidentifyingandmeasuringmarket power for generators in an electricity market, see [203] for a recent survey.102 Earlyworksonmarketpoweranalysis,emergedfrommicroeconomictheory,suggest measures that ignore transmission constraints. For example, [48] introduced the pivotalsupplierindex (PSI),whichisabinaryvalueindicatingwhetherthecapacityof ageneratorislargerthanthesupplysurplus,and[184]laterrenedPSIbyproposing residential supply index (RSI). RSI is used by the California ISO to assure price competitiveness[49]. TheelectricityreliabilitycouncilofTexasusesthe element competitiveness index (ECI) [71], which is based on the Herndahl-Hirschmann index(HHI) [182]. Market power measures considering transmission constraints have emerged more recently. Some examples include, e.g., [180, 41, 161, 52, 218], and [219]. Interested readers can refer to [42], which proposes a functional measure that unies the structural indices measuring market power on a transmission constrained network in the previous work. Incontrasttothelargeliteraturediscussedabove,theliteraturefocusedonmarket powerofrenewablegenerationproducersislimited. Existingworkssuchas[221]and [202]studymarketpowerofwindpowerproducersignoringtransmissionconstraints. The key dierentiator of the work in this chapter is that the use of the Locational MarginalPrice(LMP)framework,whichisstandardpracticeintheelectricitymarket [162,226],allowsthisworktooerinsightaboutmarketpowerofaggregatorswhen transmission capacity is limited. 5.1.2.2 Cyber-Attacks in the Grid The model and analysis in this chapter is also strongly connected to the cyber security research community, which has studied how and when a malicious party can manipulate the spot price in electricity markets by compromising the state measurement of the power grid via false data injection [35, 36, 216, 217, 136]. In particular, [216, 217] shows that if a malicious party can corrupt sensor data, then it can create an arbitrage opportunity. Further, [35] shows that such attacks can impact both the real time spot price and future prices by causing line congestions. Inthiswork,wedonotallowaggregatorstocorruptthestatemeasurementsofthe power system, rather we consider a perfectly legal approach for price manipulation: strategic curtailment. However, strategiccurtailment in the ex-postmarketcan gain extraprottothedetrimentofthepowersystem,whichisasimilarmechanismtothose highlighted in cyber attack literature. Technically, the work in this chapter makes103 signicant algorithmic contributions to the cyber-attack literature. In particular, guarantees. Incontrast,ourworkpresentsapolynomial-timealgorithmthatprovably maximizes the prot of the aggregator. 5.1.2.3 Algorithms for Managing Distributed Energy Resources There has been much work studying optimal strategies for managing demand response and distributed generation resources to oer regulation services to the power grid. This work covers a variety of contexts. For example, researchers have studied frequency regulation [132][92] and voltage regulation (or volt-VAR control)[223][12]. Aseparatelineofworkhasbeenworkondesigningincentives toencouragedistributedresourcestoprovideservicestothepowergrid[148][59]. However, the current chapter is distinct from all the work above in that we study strategic behavior by an aggregator of distributed resources. Prior work does not model the strategic manipulation of prices by the aggregator. 5.1.2.4 Algorithms for Bilevel Programs Theoptimizationproblemthatthestrategicaggregatorsolvesisabilevelprogram, since the objective (aggregator's prot) depends on the locational prices (LMPs). The LMPs are constrained to be equal to optimal dual variables arising from economic dispatch-based market clearing procedure. These types of problems have beenextensivelystudiedintheliterature,andfallundertheclassofMathematical Programs with Equilibrium Constraints (MPECs) [73]. Even if the optimization problems at the two levels are linear, the problem is known to be NP-hard [34]. Global optimization algorithms [84] can be used to solve these problems to arbitrary accuracy(computealowerboundontheobjectivewithinaspeciedtoleranceofthe globaloptimum). However,thesealgorithmsuseaspatialbranchandboundstrategy, and can take exponential time in general. In contrast, solvers like PATH [63], while practically ecient for many problems, are only guaranteed to nd a local optimum. In this chapter, we show that for tree-structured networks (distribution networks), an n-approximation of the global optimum can be computed in time linear in the size of the network and polynomial in1 n. 5.2 System Model In this section, we dene the power system model that serves as the basis for the chapter and describe how we model the way the Independent System Operator (ISO)104 computes the Locational Marginal Prices (LMPs). Locational marginal pricing is adopted by the majority of power markets in the Unites States [226], and our model is meant to mimic the operation of two-stage markets like ISO New England, PJM Interconnection, and Midcontinent ISO, that use ex-post pricing strategy for correcting the ex-ante prices [162, 226]. 5.2.1 Preliminaries We consider a power system with =nodes (buses) and Ctransmission lines. The generation and load at set of buses f1\u0096\u0095\u0095\u0095\u0096=g. The focus of this chapter is on the behavior of an aggregator in the real-time market, which owns generation capacity, possibly at multiple nodes. We assume that the aggregator has the ability to curtail generation, e.g., by curtailing the amount of wind/solar generation or by not calling on demand response opportunities, without penalty. This is because in many of today's markets, the renewable generation (e.g., solar) can be sold at the real-time price without having to commit to the ex-ante market (see for example CAISO Participating by U8, where 0\u0014U8\u0014?0 8. We dene our processof the aggregator with respectto curtailment in Section5.3. Together, the net generation delivered to the grid is represented by p\u0000\", where U9=0898#0. The flow of lines is denoted by f=h 51\u0096\u0095\u0095\u0095\u0096 , where5; represents the flow of line ;:f=G\u00b9p\u0000\"\u0000d\u00ba\u0096where G2RC\u0002=is the matrix of generation shift factors [186]. We also dene B2R=\u0002Cas the link-to-node incidence matrix that transforms line flows back to the net injections as p\u0000\"\u0000d=Bf\u0095 5.2.2 Real-Time Market Price Foreverydispatchinterval,theISOobtainsthecurrentvaluesofgeneration,demands, and flows from the state estimator, in real time. Based on this information, it solves a constrained optimization problem for market clearing. The objective of the optimizationistominimizethetotalcostofthenetwork,basedonthecurrentstateof the system. The ex-post LMPs are announced as a function of the optimal Lagrange multipliers of this optimization. Mathematically, the following program has to be105 solved. minimize 28is the oer price for the generator 8.5;is the desired flow of line ;, and Bf=p\u00b8\u0001p\u0000\"\u0000d, where\u0001?8is the desired amount of change in the generation of node 8. Constraint (5.1b)enforces the upper and lower limits on the changeofgenerations,andconstraint (5.1c)keepstheflowswithinthelinelimits. In practice,\u0001?8and\u0001?8are usually set to be a constant value for all 8(e.g.,\u0001?8=\u00002 and\u0001?8=0\u00951,88[166, p. 100]). The last constraint ensures constraints (5.1b), (5.1c), and (5.1d). Note that the ISO does not physically redispatch the generations, and the optimal values of the above program are just the desired values. In fact, by announcing the (ex-post) LMPs, the ISO provides incentives for the generators to adjust their generation according to its goals [226]. Denition3. Theex-postlocationalmarginalprice(LMP) ofnode8atcurtailment 8\u00b9U\u00ba\u0000_\u0000 8\u00b9U\u00ba\u0095 (5.2) We assume that the LMPs are unique. Non-uniqueness of LMPs happens only under veryspecialdegenerateconditions,andcanbexedinpracticebyaddingaquadratic penalty term to the objective to make it convex [50]. 5.3 The Market Behavior of the Aggregator The key feature of our model is the behavior of the aggregator. As mentioned before, aggregatorshavegenerationresourcesatmultiplelocationsinthenetworkandcan oftencurtailgenerationresourceswithouttheknowledgeoftheISO.Ofcourse,such curtailment may not be in the best interest of the aggregator, since it means oering lessgenerationtothemarket. But,ifthroughcurtailment,pricescanbeimpacted,106 then the aggregator may be able to receive higher prices for the generation oered or make money through arbitrage of the price dierential. To quantify the prot that the aggregator makes due to the curtailment, let us take a look at the total revenue in dierent production levels. Denition 4. We dene the curtailment prot (CP) as the change in prot a result of curtailment: 8\u0000U8\u00ba\u0000_8\u00b90\u00ba\u0001?0 8\u0001\u0095 (5.3) Note that the curtailment prot can be positive or negative in general. We say a curtailment level \"\u00a10is protable if W\u00b9\"\u00bais strictly positive. The curtailment prot is important for understanding when it is benecial for the aggregatorstocurtail. Notethatwearenotconcernedaboutthecostofgeneration here,asrenewableshavezeromarginalcost. However,ifthereisacostforgeneration, then that results in an additional prot during curtailment, which makes strategic curtailment more likely. While our setup may seem divorced from the notion of market power, it turns out that there is a fundamental relationship between the curtailment prot introduced above and market power. See Appendix 5.A details. 5.3.1 A Prot-Maximizing LMPs and curtailment constraints. Since LMPs are the solution to an optimization problem themselves, the aggregator's problem is a bilevel optimization problem. Inordertobeabletoexpressthisoptimizationinanexplicitform,letus rst write the KKT conditions of nullspace of H. UsingtheKKTconditionsderivedabove,theaggregator'sproblemcanbeformulated as (5.3). Constraints (5.5b)and (5.5c)indicate that the aggregator can only curtail generation at its own nodes, and the amount of curtailment cannot exceed the amount of generation available to it. Constraints (5.5d),whicharetheKKTconditions,enforcethelocationalmarginal pricing adopted by the ISO. Note that if there is a curtailment limit above which, for example,curtailmentcanbedetectedbytheISO,onecansimplyreplace ?0 8in(5.5b) byminf?0 8\u0096g8gto account for it. An important note about this problem is that we have assumed the aggregator has completeknowledgeofthenetworktopology( G)andstateestimates( pandd). This is,perhaps,optimistic;howeveronewouldhopethatthemarketdesignissuchthat aggregators do not have protable manipulations even with such knowledge. The results in this chapter indicate that this is not the case.108 The 6-bus example network from [35], used to illustrate the eect of curtailment. 5.4 The Impact of Strategic Curtailment In this section, we demonstrate the potential impact of strategic curtailment in practical settings. We rstprovide an illustrative exampleof how curtailment leads to a larger prot for a simple single-bus aggregator in a small, 6-bus, network. Then we show the eect of strategic curtailment in more realistic settings, using IEEE 14-, 30-, and 57-bus test cases and their enhanced versions from NICTA Energy System Test case Archive [60]. 5.4.1 An Illustrative Example Fig. 5.1 shows a 6-bus example network from [35], in which the amounts of generation are 375.20, 73.00, 299.60, 84.80, 250.00, and 397.40 \",. The loads and the original oer prices for the generators are shown in the gure. At the normal conditions, the lines ;12,;14and;56are carrying their maximum flow, and the real-time 25.0, 25.0, respectively. Assume that the aggregator owns node 1 and aims to increase its W=25\u00958\u0002375\u009505\u000020\u0002375\u009520 Wesimulatethebehaviorofaggregatorswithdierentsizes,i.e.,dierentnumber ofbuses,inanumberofdierentnetworks. WeusetheIEEE14-,30-,and57-bus test cases. Since studying market manipulation makes sense only when there is congestion in the network, we scale the demand (or equivalently the line flow limits) until there is some congestion in the network. In order to examine the prot and market power of aggregator as a function of its size, we assume that the way the aggregator grows is by sequentially adding random buses to its set (more or less like the way, for example, a solar rm grows). Then, at any xed set of buses, it can choosedierentcurtailmentstrategiestomaximizeitsprot. Inotherwords,foreach of its nodes, it should decide whether to curtail or not (assuming that the amount of curtailmenthasbeenxedtoasmallportion). Weassumethatthetotalgeneration of the aggregator in each bus is 10 \",, and it is able to curtail 1% of it (0.1 \",). Foreachofthethreenetworks,Fig. 5.3showstheprotforarandomsequenceof nodes. Comparing the no-curtailment prot with the strategic-curtailment prot reveals an interesting phenomenon. As the size of the aggregator (number of its buses) grows, not only does the prot increase (which is expected), but also the 1 2 3 4 5 60510152025303540 Bus No.LMP ($/MWh) Normal Curtailment Figure5.2: Thelocationalmarginalpricesforthe6-busexamplebeforeandafterthe curtailment.110 0 10 20 30 40 50 60 70 80 90 100 110 1200100020003000400050006000700080009000 Aggregator Size (MW)Profit ($/h) Strategic Curtailment Normal 0 10 20 30 40 50 60 70 80 90 100 110 12005001000150020002500 Aggregator Size (MW)Profit ($/h) Strategic Curtailment Normal 010 20 30 40 50 60 70 80 90100 110 120 130 140 15000.511.522.53x 104 Aggregator Size (MW)Profit ($/h) Strategic Curtailment Normal Figure 5.3: The prot under the normal (no-curtailment) condition and under case networks: a) IEEE b) and c) IEEE 57-Bus Case. The dierence prot.111 IEEE 14-bus networkThe aggregator Figure 5.4: A heat map of the impact of coordinated curtailment on the prices in the IEEE 14-bus network. Aggregator nodes are 2, 7, 10, and 14. dierence between the two curves increases, which is the \"curtailment prot.\" More specically, the latter does not need to happen in theory. However in practice, it is observed most of the time, and it highlights that larger aggregators have higher incentive to behave strategically, and they can indeed gain more from curtailment. The other important question is what the impact of strategic curtailment on the price ofeachbusofthenetwork(notnecessarilyjusttheaggregator'sbuses)is. Thisis importantinmanyscenarios,liketheeectofsuchcoordinatedmanipulationson consumersortheeectofcompetingrmsoneachother. Fig. 5.4showsaheatmap of an aggregator's impact on the prices in the IEEE 14-bus network. As one can see, the price of other buses can often be highly impacted as well. 5.5 Optimizing Curtailment Prot The aggregator's prot maximization problem is challenging to analyze, as one wouldexpectgivenitsbilevelform. Infact,bilevellinearprogrammingisNP-hard to approximate up to any constant multiplicative factor in general [61]. Furthermore, the objective of the program (5.5)is quadratic (bilinear) in the variables, rather than linear. This combination of diculties means that we cannot hope to provide a completeanalyticcharacterizationofthebehaviorofaprot-maximizingaggregator. In this section, we begin with the case of a single-bus aggregator and build to the case of general multi-bus aggregators in acyclic networks. For networks (e.g., distribution networks). 5.5.1 AnExactAlgorithmforSingle-NodeAggregatorsinArbitraryNetworks Even in the simplest case, when the aggregator has only a single node, i.e., its entire generation is located in a single bus, it is not trivial how to solve the aggregator's prot maximization problem. Therststeptowardsolvingtheproblemisalreadydicult. Inparticular,inorder to understand the eect of curtailment on the prot, we rst need to understand howcurtailmentimpactstheprices\u2014animpactwhichisnotmonotonicingeneral. Although LMPs are not monotonic in general, it turns out that in single-bus curtailment,theLMPisindeedmonotonicwithrespecttothecurtailment. Theproof of the 9=U9for all9=\u00bb=\u00bcnf8g. A consequence of lemma is that the price _8is a monotonically increasing staircase function of U8, for any bus 8, as depicted in Fig. 5.5. As U8increases, if thebindingconstraintsof (5.1)donotchange,thedualvariablesremainthesame, and thus the LMPs remain the same (constant intervals). Once a constraint becomes binding/non-binding, the LMP jumps to the next level. In Fig. 5.5, the two shaded areas show prot at the normal condition and at the curtailment. The dierence between the two areas is the curtailment prot. In particular,iftheredareaislargerthantheblueone,theaggregatorisabletoearn a positive The optimal curtailment U\u0003 8also happens where the red area is maximized. It should be clear that the optimal curtailment alwayshappensatthevergeofapricechange,notinthemiddleofaconstantinterval (otherwise, it can be increased by curtailing less). Giventheknowledgeofthenetworkandstateestimates,itispossibletondthejump points (i.e., where the binding constraints change) and evaluate them for protability.113 Figure5.5: TheLMPatbus 8asafunctionofcurtailedgenerationatthatbus. Shaded areasindicatetheaggregator'srevenueatthenormalconditionandatthecurtailment. Therefore,iftherearenottoomanyjumps,anexhaustivesearchoverthejumppoints can yield the optimal curtailment. Based on this observation, we have the following theorem, which is proven in Appendix 5.C. Theorem 26. The exact optimal curtailment for with a single bus, in anarbitrarynetworkwith Clines,canbefoundbyanalgorithmwithrunningtime $\u00b9C3\u0095373\u00ba. Clearly, this approach does not extend to large multi-bus aggregators. The following section uses a dierent and more sophisticated algorithmic approach for that setting. 5.5.2 AnApproximationAlgorithmforMulti-BusAggregatorsinRadialNet- works Inthissection,weshowthattheaggregatorprotmaximizationproblem,whilehardin general,canbesolvedinanapproximatesensetodetermineanapproximately-feasible approximately-optimalcurtailmentstrategyinpolynomialtimeusinganapproach based on dynamic programming. In particular, we show that an n-approximation of the optimal curtailment prot can be obtained using an algorithm with running time that is linear in the size of the network and polynomial in1 n. Before we state the main result of this section, we introduce the notion of an approximate solution to (5.5) in the following denition. Denition 5. A solution\u00b9U\u0096 5\u0096_\u0000\u0096_\u00b8\u0096`\u0000\u0096`\u00b8\u0096a\u00bato(5.5)is ann-accurate solution if the constraints are violated by at most nandW\u00b9U\u00ba\u0015W\u0003\u0000n.114 Note that, if one is simply interested in approximating W\u0003(as a market regulator wouldbe),the n-constraintviolationisofnoconsequence,andan n-accuratesolution running time 2=\u0010 1 n\u00119 ,where2isaconstantthatdependsontheparameters ?0 8\u0096\u0017\u00963\u0096?\u0096 5\u00965. On a linear (feeder line) the running time reduces to 2=\u0010 1 n\u00116 . We now give an informal description of the approximation algorithm. Consider a radialdistributionnetworkwithnodeslabeled 82\u00bb=\u00bc(where 1denotesthesubstation bus, where the radial network connects to the transmission grid). Radial distribution networkshavea treetopology(theydonothavecycles). Wedenotebus 1astheroot of the tree, and buses with only one neighbor as leaves. Every node (except the root) has a unique parent, dened as the rst node on the unique path connecting it to the root node. The set of nodes :that have a given node 8as its parent are said to be itschildren. It can be shown that the strategic curtailment problem on any radial distribution network can be expressed as an equivalent problem on a network where eachnodehasmaximumdegree 3(knownasa binarytree ,seeAppendix5.D). Thus, wecanlimitourattentiontonetworksofthistype,whereeverynodehasaunique parent and at For a node8, let21\u00b98\u00ba\u009622\u00b98\u00badenote its children (where 21=;,22=;is allowed since a node can have fewer than two children). We use the shorthand ?=4C\u00b98\u00ba=521\u00b98\u00ba\u00b8522\u00b98\u00ba\u000058\u0000\u00b9?8\u0000U8\u000038\u00ba\u0095 Constraint (5.4a)reduces to\u0001?8\u0014?=4C\u00b98\u00ba\u0014\u0001?8, where51=0and5;=0. The matrix in(5.4c)is an empty matrix (the nullspace of the matrix \u0017is of dimension 0), so this constraint can be dropped. Using this additional structure, the problem115 (5.5) can be rewritten (after some algebra) at bus 8. Note that we assumed that there is some aggregator generation and potential curtailment at every bus (however this is not restrictive, since we can simply set ?0 8=0at buses where the aggregator owns no assets). DeneG8=\u00b9_8\u0096 58\u0096U8\u00ba, it is easy to see that (5.6) is of the form max G=\u00d5 8=168\u00b9G8\u00ba s.t.\u00118\u0000G8\u0096G21\u00b98\u00ba\u0096G22\u00b98\u00ba\u0001\u00140\u0096 82\u00bb=\u00bc for some functions 68\u00b9\u0095\u00baand\u00118\u00b9\u0095\u00ba. This form is amenable to dynamic programming, since, if we x the value of G8, the optimization problem for the subtree everyvalueofG. variables _8\u0096 58\u0096U8are be discretized to lie in a116 Figure 5.6: The representation of a binary tree. For any node 8, and its children denoted21\u00b98\u00ba\u009622\u00b98\u00ba. certainsetX8suchthateveryfeasible G8isatmostX\u00b9n8\u00baaway(ininnity-normsense) fromsomepointin X8(Lemma29). Thediscretizationerrorcanbequantied,and this error bound can be used to relax the constraint to \u00118\u00b9G8\u0096G8\u00b81\u00ba\u0014n, guaranteeing that any solution to (5.5)is feasible for the relaxed constraint. This allows us to dene a dynamic program (Algorithm 3). Algorithm 3 Dynamic programming The algorithm essentially starts at the leaves of the tree and proceeds towards the root,ateachstageupdating ^fornodeswhosechildrenhavealreadybeenupdated (stopping at root). Along with the discretization error analysis in Appendix 5.D, this essentially concludes Theorem 27. It is worth noting that previous work on distribution level markets have used AC power flow models (at least in some approximate form) due to the importance of voltage constraints and reactive power in a distribution system [158]. Our approach117 extendsinastraightforwardwaytothissettingaswell,asthedynamicprogramming structure remains preserved (the KKT conditions will simply be replaced by the corresponding conditions for the AC-based market clearing mechanism). 5.5.3 Evaluation of the Approximation Algorithm Toevaluatetheperformanceofourapproximationalgorithmonacyclicnetworks,we runitonanumberofsmalltestnetworksandcomparetheresultswiththebrute-force optimalvalues. Thealgorithmindeedndssolutionswithintheprespeciederror range (and often exact) in reasonable time. As an example, for an acyclic version of the IEEE 9-bus network (taken from [116]), we demonstrate the suboptimality gap of the solution versus the running time in Fig. 5.8. Ateachpointofthegraph,theerrorpercentage(y-axis)isboundedbya constant factor of n. Clearly, the smaller nwe choose, the longer the running time is, but the smaller the error becomes. As one can see, the error drops pretty quickly. Figure 5.7: The 9-bus acyclic network from [116], used for the evaluation of the proposed approximation algorithm. We should remark that the network chosen here was small in order to allow for comparisonwiththeoptimalvalue. However,themainadvantageofouralgorithm is that it is scalable, while the brute-force becomes intractable quickly. 5.6 Concluding Remarks Understanding the potential for market manipulation by aggregators is crucial for electricity marketeciency inthe newera of renewable energy. In thischapter, we118 0 2 4 6 8 10 12 14 16 Time (s)0102030405060708090100%age error in optimal value Figure 5.8: The dierence from the optimal solution as a function of the running time of the algorithm, in the 9-bus network with 1% curtailment allowance. characterizedtheprotanaggregatorcanmakebystrategicallycurtailinggeneration in the ex-post market as the outcome of a bi-level optimization problem. This model captures the realistic price clearing mechanism in the electricity market. We showed through simulations on realistic test cases that there is potentially large prot for aggregators by manipulating the LMPs in the electricity market. When the aggregator is located in a single bus, we have shown that the locational marginalpriceismonotonicallyincreasingwiththecurtailment,andwehaveanexact polynomial-time algorithm to solve the aggregators prot maximization problem. The aggregator's strategic curtailment problem in a general setting is a dicult bi-level optimization problem, which is intractable. However, we showed that for radialdistributionnetworks(whereaggregatorsarelikelylocated),thereisanecient algorithmtoapproximatethesolutionuptoarbitraryprecision. Wealsodemonstrated viasimulationonadistributiontestcasethatouralgorithmcanecientlyndthe approximately optimal curtailment strategy. We view this work as a rst step in understanding market power of aggregators, and more generally, towards market design for integrating renewable energy and demand response from geographically distributed sources. With the result of this work, it is interesting to ask what the operator can do to address this problem, and in particular, how to design market rules for aggregators to maximize the contribution of renewable energy yet mitigate the exercise of market power. Also, extending theanalysistothecaseofmultipleaggregatorsinthemarketisanotherinteresting direction for future research.119 5.A Connections between Curtailment Prot and Market Power As mentioned earlier, there has been signicant work on market power in electricity markets, but work is only beginning to emerge on the market power of renewable generation producers. One important work from this literature is [221], and the following is the proposed notion of market power from that work. Denition 6. ForU\u0003 8\u00150, themarket power Inthisdenition,thevalueof [8capturestheabilityofthegenerator/aggregatorto exercise market power. Intuitively, in a market with high value of [8, the aggregator can signicantly increase the price by curtailing a small amount of generation. Interestingly, the optimal curtailment prot is closely related to this notion of market power. We summarize the relationship in the following proposition. Proposition 28. If the curtailment prot Wis positive, then the market power [8\u00a11. Furthermore, the larger the curtailment prot is, the higher the market power. Proof.From the denition of W\u00b9U\u0003\u00ba=_8\u00b9U\u0003\u00ba\u00b9?0 is clear that the larger the value of W\u00b9U\u0003\u00bais, the higher small with respect to the generation; however, the right-hand side expression (5.8)is an upper bound on the left-hand side anyway, and the result holds exactly. \u0003 This proposition highlights that the notion of market power in [221] is consistent withanaggregatorseekingtomaximizeitscurtailmentprot,andhighercurtailment prot corresponds to more market 25 (Monotonicity of LMP) LetustakealookattheISO'soptimizationproblem (5.1),whichisalinearprogram. It is not hard to see that the dual of this problem is as follows. maximize ,\u0000\u0096,\u00b8\u0096-\u0000\u0096-\u00b8\u0096.\u00b9\u0001p\u00b8p\u0000\"\u0000d\u00ba),\u0000\u00b8 \u00b9\u0000p\u00b8\"\u00b8d\u0000\u0001p\u00ba),\u00b8\u00b8f)-\u0000\u0000f)-\u00b8(5.9a) subject to B)\u00b9c\u00b8,\u00b8\u0000,\u0000\u00ba\u0000-\u0000\u00b8-\u00b8\u00b8H).=0 (5.9b) ,\u0000\u0096,\u00b8\u0096-\u0000\u0096-\u00b8\u00150 (5.9c) If one focuses on the terms involving U8for a certain 8, the objective of the above optimizationproblemisintheform: \u00b9\u0001?8\u00b8?8\u0000U8\u000038\u00ba_\u0000 8\u00b8\u00b9\u0000?8\u00b8U8\u00b838\u0000\u0001?8\u00ba_\u00b8 8 plusalinearfunctionoftherestofthevariables(i.e.,therestof ,\u0000\u0096,\u00b8, aswellas -\u0000\u0096-\u00b8\u0096.). There is no \"in the constraints, and the rst two terms of this objective are the only parts where U8appears (and with opposite way of contradiction 2\u0096G\u0003=4F 3\u00bais not the optimal solution of (5.11), and it is a contradiction. As a result,G\u0003=4F 2\u0000G\u0003=4F 1\u0015G\u0003 2\u0000G\u0003 Sinceweareinthesingle-buscurtailmentregime, Uhasonlyonenonzerocomponent. For the sake of convenience, we denote that element itself by a scalar Uthroughout this proof (no Uis vector in this proof). The proof consists of the following two pieces: 1) From each jump point, the point where the next jump happens can be computed in polynomial time and 2) There are at most polynomially (in this case even linearly) many jumps. Assumingthatthesolutiontotheprogram (5.1)isunique,foranyxedvalueof U, exactlyCof the constraints (5.1b),(5.1c), and(5.1d)are binding (active). We can express these binding constraints as \u00165=1\u00b9U\u00ba\u0096 where\u00162RC\u0002Cis an invertible matrix, and 1\u00b9U\u00ba2RCis a vector that depends on U. Aslongasthebindingconstraintsdonotchange,thematrix \u0016isxed,andthe optimal solution is linear in U(i.e.,5=\u0016\u000011\u00b9U\u00ba). Then, for simplicity, we can express the solution as 5\u00b9U\u00ba=50\u00b8U0, for someC-vectors50and0. Now,ifwelookatthenon-binding(inactive)constraintsof (5.1),theycanalsobe expressed \u0016and vector 1of appropriate dimensions. Inserting 5into this set of inequalities yields \u001650\u00b8U\u00160 \u009f 1, or equivalently U\u00b9\u00160\u00ba8\u009f18\u0000\u00b9\u001650\u00ba8\u0096 for all8=1\u00962\u0096\u0095\u0095\u0095\u0096\u00b92=\u00b82C\u0000A0=:\u00b9 \u00ba\u00ba. Now we need to gure out that, with increasing U, which of the non-binding constraints becomes binding rst and with exactly how much of an increase in U. If for some8we have\u00b9\u00160\u00ba8\u00140, then it is clear that increasing Ucannot make constraint8binding. If\u00b9\u00160\u00ba8\u00a10then the constraint the lowest bound among all the constraints. Hence the complexity is $\u00b9C2\u0095373\u00ba. The above procedure describes how the next jump point can be computed eciently fromthecurrentpoint. Theexactsameprocedurecanberepeatedforreachingthe subsequentjumppoints. Allthatremainsistoshowthesecondpieceoftheproof, which of jump points are bounded polynomially. To show the last part, note that by increasing U, if a binding constraint becomes non-binding, it will not become binding again. As a result, each constraint can change at most twice, and therefore, the number of jumps is at most twice the number of constraints. Thus, the number of jumps is $\u00b9=\u00b8C\u00ba, and the overall complexity of the algorithm is$\u00b9\u00b9=\u00b8C\u00baC2\u0095373\u00ba=$\u00b9C3\u0095373\u00ba. +\u009dX:points, where +=\u00ce: 8=1\u00b9!8\u0000!8\u00bais a constant (the volume of the box). Xis said to be an X-discretization of \u0018and written asX\u00b9X\u00ba. Lemma 30 (Reduction to Binary Tree) .Any tree with arbitrary degrees can be reduced to a binary tree by introducing additional dummy nodes to the network. Proof.Takeanynode 1inthetreewithsomeparent 0and: some<. We will show that this subgraph can be made a binary tree by introducing $\u00b9:\u00badummy nodes (in <levels) between1and its children. The additional nodes is transparently a binary tree with $\u00b9:\u00banodes. Each of the new nodes has zero injection, and eectively the incoming flow from its parent is just split in some waybetweenitschildren. Thisinfactenforcestheflowconservationconstraintat 1. Similarconstructioncanbeappliedtoanynodeofthetreewithmorethantwo children, until no such node exists. It can be seen that the number of nodes in the new graph is still linear in =. \u0003 So any tree can be transformed to a binary one by the above procedure. For the rest of the analysis, we focus on the n-approximation of the dynamic program on the resultingbinarytree. Theoptimizationproblem (5.5)onabinarytree,canbewritten after some algebra box where G8=\u00b9_8\u0096 58\u0096U8\u00balives. Then, an n-accurate solution is a solution to the following problem. max ,\u0096f\u0096U=\u00d5 8=1_8\u00b9?8\u0000U8\u00ba X-discretization of the constraint set, each of the constraints (as well asn-accuracy of the objective) imposes a bound on the value of X. For example, constraint (5.13c)requires 4X\u0014n. (Note that we could have dened dierent deltas X_\u0096X5\u0096XUfor dierent variables, and in that case, we would have had 3X5\u00b8XU\u0014n, but for simplicity, we took all the deltas to be the same.) Similar bounds on Xcan be obtainedfromtheotherconstraints,andtakingthelowestupperboundimpliesthe existence of a constant 20(that depends on the parameters) such that X\u0014n\u009d20. As a result, we have a X-discretization with jXj=+\u009dX3=203+\u009dn3number of points, foranynode. Therefore,thecomputationalcomplexityoveranynodewillbe jXj3, because we havejXjmany values for the node itself and jXjmany values for any of its two children. Since there are =nodes, the overall complexity of the algorithm will simply be =jXj3==209+3\u009dn9=2=\u009dn9. \u0003Part III Distributed Computation 128129 C h a pte r 6 DISTRIBUTED SOLUTION OF LARGE-SCALE SYSTEMS OF EQUATIONS [1]Navid Azizan et al. \"Distributed via Accelerated Projection-Based Consensus\". In: 2018 IEEE International Conference on via Accelerated Projection-Based Consensus\". 2917855. Solving a large-scale system of linear equations is a key step at the heart of many algorithmsinscienticcomputing,machinelearning,andbeyond. Whentheproblem dimensionislarge, computationaland/ormemoryconstraintsmakeitdesirable, or even necessary, to perform the task in a distributed fashion. In this chapter, we consider a common scenario in which a taskmaster intends to solve a large-scale algorithm called Accelerated Projection-based Consensus (APC) , in which, at each iteration, every machine updatesitssolutionbyaddingascaledversionoftheprojectionofanerrorsignal onto the nullspace of its system of equations, and the taskmaster conducts an averaging over the solutions with momentum. The convergence behavior of the proposedalgorithmisanalyzedindetailandanalyticallyshowntocomparefavorably with the convergence rate of alternative distributed methods, namely distributed gradient descent, distributed versions of Nesterov's accelerated gradient descent and heavy-ball method, the block Cimmino method, and ADMM. On randomly chosen linear systems, as well as on real-world data sets, the proposed method oers signicant speed-up relative to all the aforementioned methods. Finally, our analysis suggests a novel variation of the distributed heavy-ball method, which employs a particular distributed preconditioning, and which achieves the same theoretical convergence rate as the proposed consensus-based method.130 6.1 Introduction With the advent of big data, many analytical tasks of interest rely on distributed computationsovermultipleprocessingcoresormachines. Thisiseitherduetothe inherent complexity of the problem, in terms of computation and/or memory, or due to the nature of the data sets themselves that may already be dispersed across machines. Mostalgorithmsintheliteraturehavebeendesignedtoruninasequential fashion,asaresultofwhich,inmanycases,theirdistributedcounterpartshaveyetto be devised. In order to devise ecient distributed algorithms, one has to address a number of key questions, such as: (a) What computation should each worker carry out, (b) What is the communication architecture, and what messages should be communicated between the processors, (c) How does the distributed implementation fareintermsofcomputationalcomplexity,and(d)Whatistherateofconvergence in the case of iterative algorithms. Inthischapter,wefocusonsolvingalarge-scalesystemoflinearequations,which isoneofthemostfundamentalproblemsinnumericalcomputation,andliesatthe heart of many algorithms in engineering and the sciences. In particular, we consider thesettinginwhichataskmasterintendstosolvealarge-scalesystemofequationsin adistributedwaywiththehelpofasetofcomputingmachines/cores(Figure6.1). This is a common setting in many computing applications, and the task is mainly distributed because of high computational and/or memory requirements (rather than physical location as in sensor networks). This problem can in general be cast as an optimization problem, with a cost function that is separable in the data /one.sup(but not in the variables). Hence, there are general approachestoconstructdistributedalgorithmsforthisproblem,suchasdistributed versions of gradient descent [228, 173, 222] and its variants (e.g., Nesterov's accelerated gradient [151] and well as the so-called AlternatingDirectionMethodofMultipliers(ADMM)[44]anditsvariants. ADMM hasbeenwidelyused[100,62,225]forsolvingvariousconvexoptimizationproblems in a distributed way, and in particular for consensus optimization [144, 185, 139], which is the relevant one for the type of separation that we have here. In addition totheoptimization-basedmethods,thereareafewdistributedalgorithmsdesigned specicallyforsolvingsystemsoflinearequations. Themostfamousoneofthese is what is known as the block Cimmino method [69, 191, 11], which is a block 1Solving a system of linear equations, \u0016G=1, can be set up as the optimization problem minGk\u0016G\u00001k2=minG\u00cd 8k\u00b9\u0016G\u00ba8\u000018k2.131 row-projection method [45], and is in a way a distributed implementation of the Kaczmarz method [111]. Another algorithm has been recently proposed in [134, 146], where a consensus-based scheme is used to solve a system of linear equations over a network of autonomous agents. Our algorithm bears some resemblance to all of these methods, but as it will be explained in detail, it has much faster convergence than any of them. Our maincontribution is the designand analysis of anew algorithm for distributed solution of large-scale systems of linear equations, which is signicantly faster thanalltheexistingmethods. Inourmethodology,thetaskmasterassignsasubset of equations to each of the machines and invokes a distributed consensus-based algorithmtoobtainthesolutiontotheoriginalprobleminaniterativemanner. At each iteration, each machine updates its solution by adding a scaled version of theprojectionofanerrorsignalontothenullspaceofitssystemofequations,and the taskmaster conducts an averaging over the solutions with momentum. The incorporation of a momentum term in both projection and averaging steps results inacceleratedconvergenceofourmethod,comparedtotheotherprojection-based methods. Forthisreason,werefertothismethodas AcceleratedProjection-based Consensus(APC) .WeprovideacompleteanalysisoftheconvergencerateofAPC (Section 6.3), as well as a detailed comparison with all the other distributed methods mentionedabove(Section6.4). Also,byempiricalevaluationsoverbothrandomly chosen linear systems and real-world data sets, we demonstrate the signicant speed-ups from the proposed algorithm, relative to the other distributed methods (Section 6.6). Finally, as a further implication of our results, we propose a novel distributed preconditioning method (Section 6.7), which can be used to improve the convergence rate of distributed gradient-based methods. 6.2 The Setup We consider the problem of solving a large-scale system of linear equations \u0016G=1\u0096 (6.1) where\u00162R#\u0002=,G2R=, and12R#. While we will generally take #\u0015=, we will assume that the system has a unique solution. For this reason, we will most often consider the square case ( #==). The case where # \u009f =, and there are multiple (innitely many) solutions, is discussed in Section 6.5. Asmentionedbefore,forlarge-scaleproblems(when #\u0096= 1),itishighlydesirable, or even necessary, to solve the problem in a distributed fashion. Assuming we have132 Figure6.1: Schematicrepresentationofthetaskmasterandthe <machines/cores. Each machine the equations, i.e., \u00bb\u00168\u009618\u00bc. <machines (as in Figure 6.1), the equations can be partitioned so that each machine gets a disjoint subset of them. In other words, we can write on dierent machines in such a fashion. For the sake of simplicity, we assume that <divides#, and that the equations are distributed evenly among the machines, so that each machine gets ?=# <equations. Therefore \u001682R?\u0002=and 182R?for every8=1\u0096\u0095\u0095\u0095<. It is helpful to think of ?as being relatively small compared to =. In fact, each machine has a system of equations which is highly under-determined. 6.3 initial solution by G8\u00b90\u00ba. Clearly adding any vector in the right the estimate onto the nullspace, and taking a weighted step in that direction (which behaves as a \"momentum\"). Mathematically G8\u00b9C\u00b81\u00ba=G8\u00b9C\u00ba\u00b8W%8\u00b9\u00afG\u00b9C\u00ba\u0000G8\u00b9C\u00ba\u00ba\u0096 where %8= \u0000\u0016) 8\u00b9\u00168\u0016) 8\u00ba\u00001\u00168 (6.2) is the projection matrix onto the nullspace of \u00168(it is easy to check that \u00168%8=0 and%2 8=%8). Although this might bear some resemblance to the block Cimmino method because oftheprojectionmatrices,APChasamuchfasterconvergenceratethantheblock Cimmino method (i.e., convergence time smaller by a square root), as will be shown in Section 6.4. Moreover, it turns out that the block Cimmino method is in fact a special case of APC for W=1(Section 6.4.5). Theupdateruleof G8\u00b9C\u00b81\u00badescribedabovecanbealsothoughtofasthesolutionto an optimization problem with two terms: the distance from the global estimate \u00afG\u00b9C\u00ba, and the distance from the previous solution G8\u00b9C\u00ba. In other words, one can show that G8\u00b9C\u00b81\u00ba=argmin G8kG8\u0000\u00afG\u00b9C\u00bak2\u00b81\u0000W WkG8\u0000G8\u00b9C\u00bak2 s.t.\u00168G8=18 Thesecondtermintheobjectiveiswhatdistinguishesthismethodfromtheblock Cimmino method. If one sets to 1(which is the reduction to the block Cimmino method), the second term disappears altogether, and the update no longer dependsonG8\u00b9C\u00ba. Aswewillshow,thiscanhaveadramaticimpactontheconvergence rate. Aftereachiteration,themastercollectstheupdatedvalues G8\u00b9C\u00b81\u00batoformanew estimate \u00afG\u00b9C\u00b81\u00ba. A plausible choice for this is to simply take the average of the values as the new estimate, i.e., \u00afG\u00b9C\u00b81\u00ba=1 <\u00cd< 8=1G8\u00b9C\u00b81\u00ba\u0095This update works, and is what appears both in ADMM and in the consensus method of [134, 146]. But itturnsoutthatitisextremelyslow. Instead,wetakeananecombinationofthe average and <<\u00d5 master: \u00afG\u00b9C\u00ba [ <\u00cd< 8=1G8\u00b9C\u00ba\u00b8\u00b91\u0000[\u00ba\u00afG\u00b9C\u00001\u00ba end for which introduces a one-step memory, and again behaves as a momentum. The resulting update rule is therefore G8\u00b9C\u00b81\u00ba=G8\u00b9C\u00ba\u00b8W%8\u00b9\u00afG\u00b9C\u00ba\u0000G8\u00b9C\u00ba\u00ba\u0096 82\u00bb<\u00bc\u0096 (6.3a) Analysis Weanalyzetheconvergenceoftheproposedalgorithmandprovethatithaslinear convergence (i.e., the error decays exponentially), with no additional assumption imposed. We also derive the rate of convergence explicitly. Let us dene the matrix -2R=\u0002=as -,1 <<\u00d5 8=1\u0016) 8\u00b9\u00168\u0016) 8\u00ba\u00001\u00168\u0095 (6.4) As it will become clear soon, the condition number of this matrix predicts ?8\u00b9_\u00ba=0amongevery 8islessthan 1, vectors. Using this notation, Eq. (6.3a) can be rewritten as 48\u00b9C\u00b81\u00ba=48\u00b9C\u00ba\u00b8W%8\u00b9\u00af4\u00b9C\u00ba\u000048\u00b9C\u00ba\u00ba\u0096 8=1\u0096\u0095\u0095\u0095\u0096<\u0095 Note that G\u0003andG8\u00b9C\u00baare solutions to \u00168G=18. Therefore, their dierence, whichis48\u00b9C\u00ba,isinthenullspaceof \u00168,anditremainsunchangedunderprojection onto the nullspace. As a result, %848\u00b9C\u00ba=48\u00b9C\u00ba, we have 48\u00b9C\u00b81\u00ba=\u00b91\u0000W\u00ba48\u00b9C\u00ba\u00b8W%8\u00af4\u00b9C\u00ba\u0096 8=1\u0096\u0095\u0095\u0095\u0096<\u0095 (6.8) Similarly, the recursion (6.3b) can be expressed up all the <vectors48along with the average \u00af4together, as a vector4\u00b9C\u00ba)=\u00bb41\u00b9C\u00ba)\u009642\u00b9C\u00ba)\u0096\u0095\u0095\u0095\u00964<\u00b9C\u00ba)\u0096\u00af4\u00b9C\u00ba)\u00bc2R\u00b9<\u00b81\u00ba=. The update matrix in (6.10). The eigenvalues_8of this matrix are indeed the solutions to the following of determinant, the characteristic137 equation 1\u0000W, and the remaining 2= solutions to 0=det\u00b9\u0000[W_\u00b9 \u0000-\u00ba\u00b8\u00b91\u0000W\u0000_\u00ba\u00b91\u0000[\u0000_\u00ba \u00ba =det\u00b9[W_-\u00b8\u00b9\u00b91\u0000W\u0000_\u00ba\u00b91\u0000[\u0000_\u00ba\u0000[W_\u00ba \u00ba\u0095 Whenever we have dropped the subscript of the identity matrix, it is of size =. Recall that the eigenvalues of -are 0==\u00d6 8=1[W_`8\u00b8\u00b91\u0000W\u0000_\u00ba\u00b91\u0000[\u0000_\u00ba\u0000[W_\u0095 Therefore,therearetwoeigenvalues _8\u00961\u0096_8\u00962asthesolutiontothequadraticequation _2\u00b8\u00b9\u0000[W\u00b91\u0000`8\u00ba\u00b8W\u00001\u00b8[\u00001\u00ba_\u00b8\u00b9W\u00001\u00ba\u00b9[\u00001\u00ba=0 for every8=1\u0096\u0095\u0095\u0095\u0096=, which will 2=eigenvalues. When all these eigenvalues, along with 1\u0000W, are less than 1, the error converges to zero dC, with dbeingthelargestmagnitudeeigenvalue(spectralradius). Therefore,Algorithm4138 convergestothetruesolution G\u0003asfastasdCconvergesto 0,asC!1,ifandonlyif \u00b9W\u0096[\u00ba2(. Theoptimalrateofconvergenceisachievedwhenthespectralradiusisminimum. For that to happen, all the above eigenvalues should be complex and have magnitude j_8\u00961j=j_8\u00962j=p \u00b9W\u00001\u00ba\u00b9[\u00001\u00ba=d. It implies that we should have \u00b9W\u00b8[\u0000[W\u00b91\u0000`8\u00ba\u00002\u00ba2\u00144\u00b9W\u00001\u00ba\u00b9[\u00001\u00ba\u009688\u0096 or equivalently \u00002p \u00b9W\u00001\u00ba\u00b9[\u00001\u00ba\u0014W\u00b8[\u0000[W\u00b91\u0000`8\u00ba\u00142p \u00b9W\u00001\u00ba\u00b9[\u00001\u00ba for all8. The expression in the middle is an increasing function of `8, and therefore fortheaboveboundstohold,itisenoughforthelowerboundtoholdforthe `min and the upper bound to for `max, i.e., 8>> < >>:W\u00b8[\u0000[W\u00b91\u0000`max\u00ba\u00002=2p \u00b9W\u00001\u00ba\u00b9[\u00001\u00ba 2\u00b8[W\u00b91\u0000`min\u00ba\u0000W\u0000[=2p \u00b9W\u00001\u00ba\u00b9[\u00001\u00ba\u0096 ^\u00b9-\u00ba\u00b81\u0096 and that concludes the proof. \u0003 We should remark that, while in theory, the optimal values of Wand[depend on the valuesofthesmallestandlargesteigenvaluesof -,inpractice,onewillalmostnever compute these eigenvalues. Rather, one will use surrogate heuristics (such as using theeigenvaluesofanappropriate-sizerandommatrix)tochoosethestepsize. (In fact, theothermethods, suchasdistributedgradientdescentanditsvariants, have the same issue as well.)139 Table 6.1: A summary of the convergence rates of dierent methods. DGD: Distributed Gradient Descent, D-NAG: Distributed Nesterov's Accelerated Gradient Descent, D-HBM: Distributed Heavy-Ball Method, et Consensus B-Cimmino: Block Cimmino Method, APC: Accelerated Projection-based Consensus. The smaller the convergence rate is, the faster is the method. Note that dGD\u0015dNAG\u0015dHBManddMou\u0015dCim\u0015dAPC. DGD D-NAG addition to the convergence rate, or equivalently the number of iterations until 8\u00b9\u00168\u0016) 8\u00ba\u00001iscomputed only once). Thus the overall each iteration is 2?=. We shouldremark thatthe computationdone ateach machine duringeach iteration is essentially a projection, which has condition number one and is as numerically stable as a matrix vector multiplication can be. Finally,thecommunicationcostofthealgorithm,periteration,isasfollows. After computing the update, each of the <machines sends an =-dimensional vector to the master, and receives back another =-dimensional vector, which is the new average. As we will see, the per-iteration computation and communication complexity of the other algorithms are similar to APC; however, APC requires fewer iterations, because of its faster rate of convergence. 6.4 Comparison with Related Methods 6.4.1 Distributed Gradient Descent (DGD) As mentioned earlier, (6.1)can also be viewed as an optimization problem of the form minimize Gk\u0016G\u00001k2\u0096 andsincetheobjectiveisseparableinthedata,i.e., k\u0016G\u00001k2=\u00cd< 8=1k\u00168G\u000018k2, generic distributed optimization methods such as distributed gradient descent apply140 well to the problem. Theregularorfullgradientdescenthastheupdaterule G\u00b9C\u00b81\u00ba=G\u00b9C\u00ba\u0000U\u0016)\u00b9\u0016G\u00b9C\u00ba\u0000 1\u00ba, whereU\u00a10is the step size or learning rate. of gradient descentisoneinwhicheachmachine 8hasonlyasubsetoftheequations \u00bb\u00168\u009618\u00bc, 8=1\u0016) 8\u00b9\u00168G\u00b9C\u00ba\u000018\u00ba\u0095 (6.11) One can show that this also has linear convergence, and the rate of convergence is dGD=^\u00b9\u0016)\u0016\u00ba\u00001 ^\u00b9\u0016)\u0016\u00ba\u00b81\u00191\u00002 ^\u00b9\u0016)\u0016\u00ba\u0095 (6.12) We should mention that since needs to compute \u0016) 8\u00b9\u00168G\u00b9C\u00ba\u000018\u00baat eachiteration C,thecomputationalcomplexityperiterationis 2?=,whichisidentical to Nesterov's Accelerated Gradient Descent (D-NAG) A popular variant of gradient descent is Nesterov's accelerated gradient descent [151], which has a memory term, works as follows: 8=1\u0016) 8\u00b9\u00168G\u00b9C\u00ba\u000018\u00ba\u0096 convergence rate of this method is dNAG=1\u00002p 3^\u00b9\u0016)\u0016\u00ba\u00b81\u0096 (6.14) which is improved over the regular distributed gradient descent (one can check that ^\u00b9\u0016)\u0016\u00ba\u00001 ^\u00b9\u0016)\u0016\u00ba\u00b81\u00151\u00002p 3^\u00b9\u0016)\u0016\u00ba\u00b81). 6.4.3 Distributed Heavy-Ball Method (D-HBM) The heavy-ball [169], otherwise known as the gradient descent with momen- tum, is another accelerated variant of gradient descent as follows: I\u00b9C\u00b81\u00ba=VI\u00b9C\u00ba\u00b8<\u00d5 8=1\u0016) 8\u00b9\u00168G\u00b9C\u00ba\u000018\u00ba\u0096 (6.15a) [125] that the optimal rate of convergence of this method is dHBM=p ^\u00b9\u0016)\u0016\u00ba\u00001p ^\u00b9\u0016)\u0016\u00ba\u00b81\u00191\u00002p ^\u00b9\u0016)\u0016\u00ba\u0096 (6.16) which (^\u00b9\u0016)\u0016\u00ba\u00001 ^\u00b9\u0016)\u0016\u00ba\u00b81\u00151\u00002p 3^\u00b9\u0016)\u0016\u00ba\u00b81\u0015 p ^\u00b9\u0016)\u0016\u00ba\u00001p ^\u00b9\u0016)\u0016\u00ba\u00b81). This is similar to, but not the same as, the rate ofconvergence of APC. The dierence is that the the case and that the condition number of -is often signicantly better (see Table 6.2). 6.4.4 Alternating Direction Method of Multipliers (ADMM) Alternating Direction Method of Multipliers (more specically, consensus ADMM [185, 44]), is another generic method for solving optimization problems with separable cost function 5\u00b9G\u00ba=\u00cd< 8=158\u00b9G\u00badistributedly, hand. One can check that when system (6.1)has a solution, all the H8variablesconvergetozeroinsteadystate. Therefore,setting H8'stozerocanspeed up the convergence signicantly. We use this modied version in Section 6.6 for comparison. We should also note that the computational complexity of ADMM is $\u00b9?=\u00baper iteration (the inverse is computed using matrix inversion lemma), which is again the same as that of gradient-type methods and APC.142 6.4.5 Block Cimmino Method TheBlockCimminomethod[69,191,11],whichisaparallelmethodspecically forsolvinglinearsystemsofequations,isperhapstheclosestalgorithminspiritto APC. It is, in a way, a distributed of the so-called Kaczmarz method [111]. TheconvergenceoftheCimminomethodisslowerbyanorderincomparison withAPC(itsconvergencetimeisthesquareofthatofAPC),anditturnsoutthat APC includes this method as a special case when W=1. The block Cimmino equation, we used the fact that G8is always a solution to \u00168G=18. Notice thattheaboveequationisnolongeran\"update\"intheusualsense,i.e., G8\u00b9C\u00b81\u00badoes not depend on G8\u00b9C\u00badirectly. This 8\u00b9\u00168\u0016) 8\u00ba\u00001as G8\u00b9C\u00b81\u00ba=\u00afG\u00b9C\u00ba\u00b8\u0016\u00b8 see from the Cimmino's equation (6.18a) that A8\u00b9C\u00ba=G8\u00b9C\u00b81\u00ba\u0000\u00afG\u00b9C\u00ba\u0095143 Therefore, the update \u00afG\u00b9C\u00b81\u00ba=\u00afG\u00b9C\u00ba\u00b8a<\u00d5 8=1A8\u00b9C\u00ba =\u00afG\u00b9C\u00ba\u00b8a<\u00d5 8=1\u00b9G8\u00b9C\u00b81\u00ba\u0000\u00afG\u00b9C\u00ba\u00ba =\u00b91\u0000<a\u00ba\u00afG\u00b9C\u00ba\u00b8a<\u00d5 8=1G8\u00b9C\u00b81\u00ba\u0096 which is nothing but the same update rule as in (6.3b) with [=<a.\u0003 It is not hard to show that optimal rate of convergence of the Cimmino method is dCim=^\u00b9-\u00ba\u00001 ^\u00b9-\u00ba\u00b81\u00191\u00002 ^\u00b9-\u00ba\u0096 (6.19) which is slower (by an of APC (p ^\u00b9-\u00ba\u00001p ^\u00b9-\u00ba\u00b81\u00191\u00002p ^\u00b9-\u00ba). 6.4.6 Consensus Algorithm of Mou et al. As mentioned earlier, a projection-based consensus algorithm for solving linear systems over a network was recently proposed by Mou et al. [146, 134]. For the master-worker setting studied here, the corresponding network would be a clique, and the algorithm 82\u00bb<\u00bc\u0096 \u00afG\u00b9C\u00b81\u00ba=1 <<\u00d5 8=1G8\u00b9C\u00b81\u00ba\u0096 It is straightforward to show that the rate of convergence in this case is dMou=1\u0000`min\u00b9-\u00ba (6.21) which is much slower than the block Cimmino method and APC. One can easily check that 1\u0000`min\u00b9-\u00ba\u0015^\u00b9-\u00ba\u00001 ^\u00b9-\u00ba\u00b81\u0015p ^\u00b9-\u00ba\u00001p ^\u00b9-\u00ba\u00b81\u0095144 Even though this algorithm is slow, it is useful for applications where a fully- distributed(networked)solutionisdesired. Anothernetworkedalgorithmforsolving a least-squares problem has been recently proposed in [207]. A summary of the convergence rates of all the related methods discussed in this section is provided in Table 6.1. 6.5 Underdetermined System Inthissection,weconsiderthecasewhen # \u009f=andrank\u00b9\u0016\u00ba=#,i.e.,thesystemis underdetermined and there are innitely many solutions. We prove that in this case, eachmachinestillconvergesto\"a\"(global)solution,andfurther,allthemachines converge to the same solution. The convergence is again linear (i.e., the error decays exponentially fast), and the rate of convergence is similar to the previous case. Recall that the matrix -2R=\u0002=dened earlier can be new matrix .2R#\u0002# .,1 <\u0016\u0016)26666664\u00b9\u00161\u0016) 33. Suppose# \u009f=andrank\u00b9\u0016\u00ba=#. Each one of G1\u00b9C\u00ba\u0096\u0095\u0095\u0095\u0096G<\u00b9C\u00ba\u0096\u00afG\u00b9C\u00ba in Algorithm 4 converges to a solution as fast as dCconverges to 0, asC!1, for somed2\u00b90\u00961\u00ba,ifandonlyif\u00b9W\u0096[\u00ba2(. Furthermore,thesolutionsconvergedto are the same. d=p ^\u00b9.\u00ba\u00001p ^\u00b9.\u00ba\u00b81\u00191\u00002p ^\u00b9.\u00ba\u0096 (6.23)145 Table 6.2: A comparison numbers of \u0016)\u0016and-for some examples.<is the number vectors 48\u00b9C\u00ba=G8\u00b9C\u00ba\u0000G\u0003for all8=1\u0095\u0095\u0095<, and \u00af4\u00b9C\u00ba=\u00afG\u00b9C\u00ba\u0000G\u0003, as before, but this time show that \u001648\u00b9C\u00ba! 0 and\u0016\u00af4\u00b9C\u00ba! 0. Recursion (6.3a) can be rewritten as 48\u00b9C\u00b81\u00ba=48\u00b9C\u00ba\u00b8W%8\u00b9\u00af4\u00b9C\u00ba\u000048\u00b9C\u00ba\u00ba\u0096 8=1\u0096\u0095\u0095\u0095\u0096<\u0096 as before. Since both G\u0003andG8\u00b9C\u00baare solutions to \u00168G=18, their dierence 48\u00b9C\u00bais in the nullspace of \u00168, and it remains unchanged under projection onto the nullspace. As a result,%848\u00b9C\u00ba=48\u00b9C\u00ba, and we have 48\u00b9C\u00b81\u00ba=\u00b91\u0000W\u00ba48\u00b9C\u00ba\u00b8W%8\u00af4\u00b9C\u00ba\u0096 8=1\u0096\u0095\u0095\u0095\u0096<\u0095 (6.24)147 solutions to 0=det\u00b9\u0000[W_\u00b9 \u0000.\u00ba\u00b8\u00b91\u0000W\u0000_\u00ba\u00b91\u0000[\u0000_\u00ba \u00ba =det\u00b9[W_.\u00b8\u00b9\u00b91\u0000W\u0000_\u00ba\u00b91\u0000[\u0000_\u00ba\u0000[W_\u00ba \u00ba\u0095 Notice that this is exactly the same as the one in the proof of Theorem 31, with - replaced with .. It follows that the \u001641\u00b9C\u00ba\u0096\u0095\u0095\u0095\u0096\u00164<\u00b9C\u00ba\u0096\u0016\u00af4\u00b9C\u00baconverge to zero as fast as dCif and only if\u00b9W\u0096[\u00ba2(, and the optimal rate of convergence is d=p ^\u00b9.\u00ba\u00001p ^\u00b9.\u00ba\u00b81\u0095 Convergence of \u001641\u00b9C\u00ba\u0096\u0095\u0095\u0095\u0096\u00164<\u00b9C\u00ba\u0096\u0016\u00af4\u00b9C\u00bato zero means that each machine and the master converge to a solution, but the solutions reached may not be the same.149 What remains to show is that the only steady state is the \"consensus steady state.\" From(6.3), it is easy to see that the steady state G1\u00b91\u00ba\u0096\u0095\u0095\u0095\u0096G<\u00b91\u00ba\u0096\u00afG\u00b91\u00basatises the following equation. 8>> < >>:%8\u00b9\u00afG\u00b91\u00ba\u0000G8\u00b91\u00ba\u00ba=0\u0096 82\u00bb<\u00bc \u00afG\u00b91\u00ba=1 <\u00cd< 8=1G8\u00b91\u00ba(6.25) which can form as 2666666664%1\u0000%1 \u0095\u0095\u0095\u0095\u0095\u0095 a consensus steady state G1\u00b91\u00ba=\u0001\u0001\u0001=G<\u00b91\u00ba=\u00afG\u00b91\u00ba=E. Therefore, the nullspace of the above matrix is at least =dimensional, or in other words, it has =zero eigenvalues. We will argue that this matrix has only =zero eigenvalues, and therefore any steady-state solution must be a consensus. To nd the eigenvalues_8we have to solve the 1, and remaining that in the underdeterminedcase, -has=\u0000#zeroeigenvalues. Therefore, =\u0000#of1\u0006p 1\u0000`8 are zero. As a result, the overall number of zero eigenvalues is #\u00b8\u00b9=\u0000#\u00ba==. This implies that the nullity of the matrix in (6.26)is=and any steady-state solution must be a consensus solution, which completes the proof. \u0003 6.6 Experimental Results Inthissection,weevaluatetheproposedmethod(APC)bycomparingitwiththeother distributed methods discussed throughout the chapter, namely DGD, D-NAG, D- HBM, modied ADMM, and block Cimmino methods. We use randomly-generated problems as well as real-world ones from the National Institute of Standards and Technology (NIST) repository, Matrix Market [141]. complexity. Table 6.3 shows the values of the convergence times for a number of synthetic and real-world problems with dierent sizes. It can be seen that APC has a much faster convergence, often by orders of magnitude. As expected from the analysis, the APC's closest competitor is the distributed heavy-ball method. Notably, in randomly-generated problems, when the mean is not zero, the gap is much larger.151 Figure6.2: Thedecayoftheerrorfordierentdistributedalgorithms,ontworeal problemsfromMatrixMarket[141](QC324: Modelof #=#of equations,<=#of workers,?=#of equations per worker.152 To further verify the performance of the proposed algorithm, we also run all the algorithms on multiple problems, and observe the actual decay of the error. Fig. 6.2 shows the relative error (the distance from the true solution, divided by the true solution, in \u00122norm) for all the methods, on two examples from the repository. Again, to make the comparison fair, all the methods have been tuned to their optimal parameters. As one can see, APC outperforms the other methods by a wide margin, which is consistent with the order-of-magnitude dierences in the convergence times of Table 6.3. We should also remark that initialization does not seem to aect the convergence behavior of our algorithm. Lastly, we should mention that our experiments on cases where there are missing updates (\"straggler\" machines) indicatethatAPCisatleastasrobustastheotheralgorithmstotheseeects,andthe convergence curves look qualitatively the same as in Fig. 6.2. 6.7 A Distributed Preconditioning to Improve Gradient-Based Methods ThenoticeablesimilaritybetweentheoptimalconvergencerateofAPC(p ^\u00b9-\u00ba\u00001p ^\u00b9-\u00ba\u00b81) and that of D-HBM (p ^\u00b9\u0016)\u0016\u00ba\u00001p ^\u00b9\u0016)\u0016\u00ba\u00b81) suggests that there might be a connection between thetwo. Itturnsoutthatthereis,andweproposea distributedpreconditioning for D-HBM, which makes it achieve the same convergence rate as APC. The algorithm works as follows. Prior to starting the iterative process, each machine 8can premultiply its own set of equations \u00168G=18by\u00b9\u00168\u0016) 8\u00ba\u00001\u009d2, which can be done in parallel (locally) with $\u00b9?2=\u00baoperations. This transforms the global system of equations system can then be solved using distributed heavy-ball method, which will achieve the same rate of convergence as APC, i.e.,p^\u00001p^\u00b81where^=^\u00b9\u0018)\u0018\u00ba=^\u00b9-\u00ba.153 6.8 Conclusion Weconsideredtheproblemofsolvingalarge-scalesystemoflinearequationsbya taskmaster with the help of a number of computing machines/cores, in a distributed way. We proposed an accelerated projection-based consensus algorithm for this problem, and fully analyzed its convergence rate. Analytical and experimental comparisonswiththeotherknowndistributedmethodsconrmsignicantlyfaster convergenceoftheproposedscheme. Finally,ouranalysissuggestsanoveldistributed preconditioning for improving the convergence of heavy-ball method toachievethesametheoreticalperformanceastheproposedconsensus-basedmethod. Weshouldnallyremarkthatwhilethesettingstudiedherewasamaster-workers one,thesamealgorithmcanbeimplementedinanetworkedsettingwherethereis 215]).154 C h a pte r 7 CODED COMPUTATION GRADIENT in a distributed manner. In principle, a computational task is divided into subtasks which are distributed over a cluster operated by a taskmaster. One issuefacedinpracticeis thedelay incurreddue tothepresenceof slowmachines, known as stragglers . Several schemes, including those based on replication, have been proposed in the literature to mitigate the eects of stragglers and more recently, those inspired by coding theory have begun to gain traction. In this chapter, we consideradistributedgradientdescentsettingsuitableforawideclassofmachine learning problems. We adopt the framework of Tandon et al. [197] and present a deterministic scheme that, for a prescribed per-machine computational eort, recovers the gradient from the least number of machines 5theoretically permissible, via an$\u00b952\u00badecoding algorithm. We also provide a theoretical delay model which can be used to minimize the expected waiting time per computation by optimally choosing the parameters of the scheme. Finally, we supplement our theoretical ndingswithnumericalresultsthatdemonstratetheecacyofthemethodandits advantages over competing schemes. 7.1 Introduction Withthesizeoftoday'sdatasets,duetohighcomputationand/ormemoryrequire- ments,itisvirtuallyimpossibletorunlarge-scalelearningtasksonasinglemachine; and even if that is possible, the learning process can be extremely slow due to its sequential nature. Therefore, it is highly desirable or, even necessary, to run the tasksinadistributedfashiononmultiplemachines/cores. Forthisreason,parallel and distributed computing has attracted a lot of attention in recent years from the machine learning, and other, communities [44, 173, 22, 228, 77]. When a task is divided among a number of machines, the \"computation time\" is155 clearly reduced signicantly, since the task is being processed in parallel rather than sequentially. However, the taskmaster has to wait for all the machines in order to be abletorecovertheexactdesiredcomputation. Therefore,inthefaceofsubstantial or heterogeneous delays, distributed computing may suer from being slow, which defeats the purpose of the exercise. Several approaches have been proposed to tackle this problem. One naive yet common way, especially when the task consists of many iterations,istonotwaitforallmachines,andignorethe stragglingmachines . One may hope that in this way on average the taskmaster receives enough information fromeveryone;however,itisclearthattheperformanceofthelearningalgorithm may be signicantly impacted in many cases because of lost updates. An alternative and more appropriate way to resolve this issue, is to introduce some redundancy in the computation of the machines, in order to eciently trade o computation time for less wait time, and to be able to recover the correct update using only a few machines. But the great challenge here is to design a clever scheme for distributing the task among the machines, such that the computation can be recovered using a few machines, independent of which machines they are. Over the past few decades, coding theory has been developed to address similar challenges in other domains, and has had enormous success in many applications suchasmobilecommunication,storage,datatransmission,andbroadcastsystems. Despite the existence of a great set of tools developed in coding theory which can be used in many machine learning problems, researchers had not looked at this area until very recently [123, 197, 70, 128]. This work is aimed at bridging the gap betweendistributedmachinelearningandcodingtheory,byintroducingacarefully designed coding scheme for eciently distributing a learning task among a number of machines. More specically, we consider gradient-based methods for additively separable cost functions,whicharethemostcommonwayoftraininganymodelinmachinelearning, and use coding to cleverly distribute each gradient iteration across =machines in an ecient way. To that end, we propose a deterministic construction based on Reed-Solomon codes [174] accompanied with an ecient decoder, which is used to recover the full gradient update from a xed number of returning machines. Furthermore,weprovideanewdelaymodelbasedonheavy-taildistributionsthat alsoincorporatesthetimerequiredfordecoding. Weanalyzethismodeltheoretically and use it to optimally pick our scheme's parameters. We compare the performance of our method on the MNIST dataset [121] with other approaches, namely: 1)156 Ignoring the straggling machines [164], 2) Waiting for all the machines, and 3) G/r.sc/a.sc/d.sc/i.sc/e.sc/n.sc/t.scC/o.sc/d.sc/i.sc/n.sc/g.sc as proposedby Tandon etal. [197]. Our numericalresults show that, for the same training time, our scheme achieves better test errors. 7.1.1 Related Work Asmentionedearlier,codingtheoryinmachinelearningisarelativelynewarea. We summarizetherecentrelatedworkhere. Leeetal.[123]recentlyemployedacoding- theoretic method in two specic distributed tasks, namely matrix multiplication and data shuing. They showed signicant speed-ups are possible in those two tasks by using coding. Dutta et al. [70] proposed a method that speeds up distributed matrixmultiplicationbysparsifyingtheinnerproductscomputedateachmachine. Polynomial codes has been proposed by Yu et al. [220], which uses a carefully- designed Reed-Solomon code for matrix multiplication. They have shown that their framework achieves the minimum recovery threshold while allowing ecient decoding using polynomial interpolation. A coded MapReduce framework was introduced by Li et al in [128] which is used to facilitate data shuing in distributed computing. TheclosestworktoourframeworkistheworkofTandonetal.[197], which aims at mitigating the eect of stragglers in distributed gradient descent using Maximum-Distance Separable (MDS) codes. of stragglers. In addition, theauthors present a clever scheme, based on adjacency matrices of expander graphs, to compute an approximation of the gradient in the presence of stragglers. We mention that our schemediersinthethewaytheworkloadisdistributedacrossthedierentmachines: weadvocateaload-balancedapproachinwhicheverymachineperformsthesame amount of work. We show that this is possible for any number of machines =and prespecied workload F. 7.1.2 Statement of Contributions In this work, we make the following three main contributions. 1.Weconstructadeterministiccodingschemeforecientlydistributinggradient descent over a given number of machines. Our scheme is optimal in the sense that it can recover the gradient from the smallest possible number of returning157 machines,5, given a prespecied an ecient online decoder, with time complexity $\u00b952\u00bafor recovering the gradient from any 5machines, which is faster than the best known method [197], $\u00b953\u00ba. 3.Weanalyzethetotalcomputationtime,andprovideamethodforndingthe optimal coding parameters. We consider heavy-tailed delays, which have been widely observed in CPU job runtimes in practice [124, 93, 94]. The rest of the chapter is organized as follows. In Section 7.2, we describe the problem setup and explain the design objectives in detail. Section 7.3, provides the construction of our coding scheme, using the idea of balanced Reed-Solomon codes. Our ecient online decoder is presented in Section 7.4. We then characterize the total computation time, and describe the optimal choice of coding parameters, in Section7.5. Finally,weprovideournumericalresultsinSection7.6,andconclude in Section 7.7. 7.2 Preliminaries 7.2.1 Problem Setup Figure 7.1: Schematic representation as in Fig. 7.1. The158 masterintendstotrainamodelusinggradientdescentbydistributingthegradient updates amongst the workers. More precisely, consider a typical scenario, where we want to learn parameters V2R?by minimizing a generic loss function !\u00b9D;V\u00ba over a given dataset D=f\u00b9G8\u0096H8\u00bag# 8=1, whereG82R?andH82R. The loss function can be expressed as the sum of the losses for individual data points, i.e. !\u00b9D;V\u00ba=\u00cd# 8=1\u0012\u00b9G8\u0096H8;V\u00ba\u0095Therefore,thefullgradient,withrespectto V,isgiven by r!\u00b9D;V\u00ba=#\u00d5 8=1r\u0012\u00b9G8\u0096H8;V\u00ba\u0095 (7.1) The data can be divided into :(disjoint) chunksfD1\u0096\u0095\u0095\u0095\u0096D:gof size# :, and clearly the gradient can also be written as r!\u00b9D;V\u00ba=\u00cd: 8=1\u00cd \u00b9G\u0096H\u00ba2D8r\u0012\u00b9G\u0096H;V\u00ba. Dene68:=\u00cd 2\u0096\u0095\u0095\u0095\u00966) :\u00bc, where68is a row vector r!\u00b9D;V\u00ba=11\u0002:6. Now suppose each worker ,8is assignedFdata partitions fD81\u0096\u0095\u0095\u0095\u0096D8Fg, it computes the partial gradients f681\u0096682\u0096\u0095\u0095\u0095\u009668Fg. Note thatthe\"redundancy\"incomputationisintroducedhere,sinceeachchunkisallowed to be assigned to multiple workers. Each worker then has to compute its partial gradients, and return a prespecied linear combination of them knowledge about the stragglers, i.e., we shall design a scheme that enables master to recover the gradient from any set of 5machines. It is known [197] that for any xed:andF, an upper-bound on the number of stragglers that any is: Fnonzero 5rowsof Bcontainstheall-onevectorof length:,11\u0002:.159 The values of these nonzero entries prescribe the linear combination sent by ,8. In other words, the coded partial gradient sent from,8to\"is given by 28=:\u00d5 9=1B8\u0096969=B86\u0096 (7.3) where B8denotesthe8throw chosen as follows: let of the returning machines andlet BFbethesub-matrixof Bwithrowsindexedby F. If11\u0002:isinthelinear space generated asthe secondpropertysuggests, aFischosen such that aFBF=11\u0002:. As a result, anyset ofindices F\u001a\u00bb=\u00bcof size5, itmeans thegradient can be recovered from the set of 5machines that return fastest. ThepseudocodelistingofAlgorithm5outlinestheoverallprocedureforimplementing our scheme, as just described. Algorithm 5 Pseudocode of the proposed scheme Require: fD1\u0096\u0095\u0095\u0095\u0096D:g: Dataset Encoding distributed scheme that does not employ redundancy, the taskmaster has to wait for all the workers to nish in order to compute the full gradient. However, in the scheme outlined above, the taskmaster needs to wait for the fastest 5machines to recoverthefull gradient. Clearly,thisrequiresmore computationbyeachmachine. Note that inthe uncoded the amount ofcomputation that each worker does is1 =of the total work, whereas in the coded setting each machine performs aF : fraction of the total work. From (7.2), we know that if a scheme can tolerate B stragglers, the fraction of computation that each worker does isF :\u0015B\u00b81 =. Therefore, the computation load of each worker increases by a factor of \u00b9B\u00b81\u00ba. As will be explainedfurtherinSection7.5, thereisasweetspotforF :(andconsequently B)that minimizestheexpectedtotaltimethatthemasterwaitsinordertorecoverthefull gradient update. Itisworthnotingthatitisoftenassumed[197,123,70]thatthedecodingvectorsare precomputed for all possible combinations of returning machines, and the decoding cost is not taken into account in the total computation time. In a practical system, however, it is not very reasonable to compute and store all the decoding vectors, especiallyasthereare\u0000= 5\u0001suchvectors,whichgrowsquicklywith =. Inthiswork, we introduce an online algorithm for computing the decoding vectors on the fly, for the indices of the 5workers that respond rst. The approach is based on the decoding vectors faF:F\u001a\u00bb=\u00bc\u0096jFj=5g. 7.3 Code Construction The basic building block of our encoding scheme is a matrix M2f0\u00961g=\u0002:, where each row is of weight F, which serves as a maskfor the matrix B, whereFis the number of data partitions that is assigned to every machine. Each column of Bwill be chosen as a codeword from a suitable Reed-Solomon Code over the complex eld, with support dictated by the corresponding column in M. Whereas the authors of[197]choosethe rowsofBascodewordsfromasuitableMDScode,thisapproach does not immediately work when :is not equal to =.161 7.3.1 Balanced Mask Matrices We will utilize techniques from [90, 91] to construct the matrix M(and then B). For that, we present the following denition. Denition7 (Balanced Matrix) .A matrix Then, Mis given by M=266666666666666666641 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 137777777777777777775\u0096 (7.5) whereeachcolumnisofweight=F :=6. Thefollowingalgorithmproducesabalanced mask matrix. For a xed column weight 3, each row has weight 3ischosenas=F :2Z,allrowswillbeofweight F. Asanexample, the matrix Min(7.5)is generated by calling R/o.sc/w.scB/a.sc/l.sc/a.sc/n.sc/c.sc/e.sc/d.scM/a.sc/s.sc/k.scM/a.sc/t.sc/r.sc/i.sc/x.sc (8,4,6,0).162 Algorithm 6 can be used to generate a mask matrix Mfor the encoding matrix B: The9thcolumn of Bwill be chosen as a Reed-Solomon codeword whose support is that of the9thcolumn of M. 7.3.2 Correctness of Algorithm 6 To lighten notation, we prove correctness for C=0. The general case follows immediately. Proposition 34. Let:\u00963and=be integers where 3 \u009f=. The row weights of matrix M2f0\u00961g=\u0002:produced by wherethesubscript =denotesreducingtheelementsofthesetmodulo =. Collectively, the nonzero indices in all oftimes. Asa result,thoseindices correspondto Hence, the two cases of F8are identical along with their corresponding index sets. In the case where =-:3, each of the rst\u0004:3 =\u0005 =elements, after reducing modulo =, appears the same number of times. As a result, the nonzero f0\u0096\u0095\u0095\u0095\u0096\u00b9:3\u00001\u00ba=g. Finally, we have Now consider the case when Cis not necessarily equal to zero. This amounts to shifting(cyclically)theentriesineachcolumnby Cpositionsdownwards. Asaresult, the rows themselves are shifted by the same amount, allowing us to conclude the following.163 Corollary 35. Let:\u00963,and=beintegerswhere 3 \u009f=. quick overview of Reed-Solomon Codes. A Reed- Solomon code of length 5evaluationsfC\u00b9U81\u00ba\u0096\u0095\u0095\u0095\u0096C\u00b9U85\u00bagof a polynomial C\u00b9G\u00baof degree at most5\u00001characterizes it. In particular, xing 5\u00001evaluations of the polynomial to zero characterizes C\u00b9G\u00bauniquely up to scaling. This property will give us the ability to construct Bfrom M. 7.3.4 General construction In case3=F: =8Z, the chosen row weight Fprevents the existence of Mwhere each column weight is minimal. We have to resort to Algorithm 7 that yields M comprised of two matrices M\u0011andM;according M=h M\u0011M;i \u0095 The weight3\u0011:=\u0006=F :\u0007and each column of M;has weight3;:=\u0004=F :\u0005. Note that according to (7.2), we require 3;\u00152in order to tolerate a positive number of stragglers.164 Algorithm 7 Column-balanced Mask Matrix M Number of rows :: Number of columns end procedure The output of Algorithm 7 can now be used in Algorithm 8 instead of R/o.sc/w.scB/a.sc/l.sc- /a.sc/n.sc/c.sc/e.sc/d.scM/a.sc/s.sc/k.scM/a.sc/t.sc/r.sc/i.sc/x.sc to generate the appropriate mask mastrix M. 7.3.5 Correctness of Algorithm 7 According to the algorithm, the condition :j=Fimplies that :\u0011=0leading to \"=\";, which is constructed using Algorithm 6. Moving on to the general case, the matrix Mgiven by h M\u0011M;i where each matrix is row-balanced. The particular choice of CinM;aligns the \"heavy\" rows of M\u0011with the \"light\" rows of M;, and vice-versa. The algorithm works because the choice of parameters equates the number of heavy rows =\u0011ofM; to the number of light rows =;ofM\u0011. The following lemma is \"heavy\" row of M\u0011along with a \"light\" row ofM;results in one that is of weight F. It remains to show that the concatenation of M\u0011andM;results of rows of this type only. Wewillassumethat =-:\u00113\u0011holds. FromProposition34,wehave =;==\u0000\u00b9:\u00113\u0011\u00ba= and=\u0011=\u00b9:;3;\u00ba=. We will show that the two quantities are in fact equal. Indeed, we can express=;as =\u0000\u00b9:\u00113\u0011\u00ba===\u0000:\u00113\u0011\u00b8\u0016:\u00113\u0011 C, the \"light\" rows of M\u0011align with the \"heavy\" rows of M;, and vice-versa. Furthermore, Lemma 36 guarantees that each row of weightl :\u00113\u0011 =m \u00b8j :;3; =k =F. The same rows, using the fact thatdGe\u00b8bHc=bGc\u00b8dHewhen bothGandHare non-integers.166 7.3.6 Building the Encoding Matrix from the Mask Matrix Onceamaskmatrix MhasbeendeterminedusingAlgorithm6,theencodingmatrix Bcan be built by picking appropriate codewords from RS\u00bb=\u0096 5\u00bc. Consider Min (7.5) and C1\u00b9G\u00ba=^1\u00b9G\u0000U6\u00ba\u00b9G\u0000U7\u00ba\u0096 C2\u00b9G\u00ba=^2\u00b9G\u0000U4\u00ba\u00b9G\u0000U5\u00ba\u0096 (7.13) C3\u00b9G\u00ba=^3\u00b9G\u0000U2\u00ba\u00b9G\u0000U3\u00ba\u0096 (7.14) C4\u00b9G\u00ba=^4\u00b9G\u00001\u00ba\u00b9G\u0000U\u00ba\u0095 (7.15) The constant ^9is chosen such that the constant term of C9\u00b9G\u00ba, i.e.C9\u00b90\u00ba, is equal to 1. The evaluations of C9\u00b9G\u00baonf1\u0096U\u0096\u0095\u0095\u0095\u0096U7gare collected in the vector \u00b9C9\u00b91\u00ba\u0096C9\u00b9U\u00ba\u0096\u0095\u0095\u0095\u0096C9\u00b9U7\u00ba\u00ba)which sits as the 9thcolumn of B. The validity of this process can be conrmed using (7.6), and is generalized in Algorithm 8. Algorithm E/n.sc/c.sc/o.sc/d.sc/i.sc/n.sc/g.scM/a.sc/t.sc/r.sc/i.sc/x.sc (=,:,F) Row weight U:=throot of unity Output: end for return B Once the matrix Bis specied, the corresponding decoding vectors required for computing the gradient at the taskmaster have to be characterized. 7.4 Ecient Online Decoding We exploit the fact that Bis constructed using Reed-Solomon codewords and show that each decoding vector aFcan be in $\u00b952\u00batime. any5survivingmachines, indexed byF \u0012\u00bb=\u00bc, according to of Bis determined by167 a polynomial C9\u00b9G\u00ba=\u00cd5\u00001 8=0C9\u00968G8whereC9\u00960=1. We can write BasB=GT, t1\u0001\u0001\u0001t:i andt9is vector of (7.6). Nowconsider (7.16) Indeed, the matrix GFin the above product in general, can be numerically unstable. However,theVandermondesystemsthatwedealwithhereareveryspecicones, i.e. their elements are all roots of unity, meaning that the Vandermonde matrix is a subset of the rows of a Fourier matrix, which matrices builtfrom an of unity allows us to compute the required decoding vector in a space ecient manner. This is demonstrated in the next subsection. 7.4.1 Space-Ecient Algorithm Note that a) Fis nothing but the rst row of the inverse of GF, which can be built from a set of polynomials fE1\u00b9G\u00ba\u0096\u0095\u0095\u0095\u0096E5\u00b9G\u00bag. Let the;thcolumn of G\u00001 condition GFv;=e;, where e;is the;thelementary basis vector of length 5, vanish onfU81\u0096\u0095\u0095\u0095\u0096U85gnfU8;g. Specically, the constant term observation proposes that the master should precompute and store the set f\u00b91\u0000U8\u00ba\u00001g=\u00001 8=1, and then compute each E;\u00960by utilizing lookup operations. The following algorithm outlines this procedure. Algorithm 9 D/e.sc/c.sc/o.sc/d.sc/i.sc/n.sc/g.scV/e.sc/c.sc/t.sc/o.sc/r.sc (F) Input: F: Ordered set of surviving for return a 7.5 Analysis of Total Computation Time In this section, we provide a theoretical model which can be used to optimize the choiceofparametersthatdenetheencodingscheme. Forthispurpose,wemodel the response time of a single computing machine as )=)delay\u00b8)comp\u0095 (7.19) Here, the quantity )compis the time required for a machine to compute its portion of thegradient. Thisquantityisequalto 26#F :,where26=26\u00b9\u0012\u0096?\u00baisaconstantthat indicatesthetimeofcomputingthegradientforasingledatapointwhichdepends on the dimension of datapoints, ?, as well as theloss function, \u0012. The )delayreflectstherandomdelayincurredbeforethemachinereturnswiththeresult ofitscomputation. WemodelthisdelayasaParetodistributedrandomvariablewith \u001b\u00b9C\u00ba=%A\u00b9)delay\u0014C\u00ba=1\u0000\u0010C0 C\u0011b forC\u0015C0\u0096 (7.20) where the quantity C0can be thought of the fundamental delay of the machine, i.e. theminimumtimerequiredforamachinetoreturninperfectconditions. Previous169 works[123,130]modelthereturntimeofamachineasashiftedexponentialrandom variable. Weproposeusingthisapproachsincetheheavy-tailednatureofCPUjob runtime [124, 93, 94]. large and dene U:=F :as the fraction of the dataset assigned to each machine. For this value of U, the number of machines required for successful recovery of the gradient is given by 5\u00b9U\u00ba=d\u00b91\u0000U\u00ba=e\u00b81\u0096 (7.22) wheredGereturnsthesmallestintegergreaterthanorequalto G. Wecanshowthe following result which approximates E\u00bb)\u00b95\u00ba of Proposition37. Theexpectedvalueofthe 4\u0011G \u0095 Furthermore, (7.2)implies that the of machines we wait for is 5=\u00b91\u0000U\u00ba=, for rst two terms in the product converge to 4\u0000band4b, respectively, which yields lim =!1E\u00bb)\u00b95\u00ba delay\u00bc=C0U\u00001 b\u0095 \u0003 Using this result, we can approximate )5, for= 1, )5\u0019C0U\u00001 b\u00b826#U\u00b82<\u00b91\u0000U\u00ba2=2\u0096 (7.24) where we assume that the taskmaster uses Algorithm 9 for decoding. If we assume2<is the time required for one FLOP, the total decoding time is given by 2<\u00b95\u00001\u00ba5\u00192<\u00b91\u0000U\u00ba2=2. SinceUisboundedfromabovebythememoryofeach machine, one can nd the optimal computation time, subject to memory constraints, by minimizing )5with respect to U. 7.5.1 b\u00b826#U\u0095 (7.25) This function can be minimized with respect to Uby standard calculus to give U\u0003=\u0012C0 26#b\u0013b 1\u00b8b \u0095 (7.26) Note that this quantity is valid (less than one) if and only if one hasC0 26#b\u009f1. It has been observed in practice that the parameter bis close to one. Therefore, this assumption holds because #is assumed to be large. For illustrative purposes, we plot the function )5from(7.25)for a given set of parameters and indicate the optimal point. This plot is given in Figure 7.2.171 0 0.2 0.4 0.6 0.8 1Tf 00.010.020.030.040.050.060.07 Figure 7.2: This plot corresponds to a setup where the number of training examples is#=12000and26=3\u000210\u00006to give#26=0\u0095035. denote by the star symbol. 7.6 Numerical Results Todemonstratetheeectivenessofthescheme,weperformednumericalsimulations on a simple learning task, with realistic delays. We train a softmax regression model onadistributedclustercomposedof ==80processorstoclassify10000handwritten digitsfromtheMNISTdataset[121],whilesyntheticallyintroducingcomputation delays according to a model adopted from the literature. The delay model (and its parameters), adopted from [124, 93, 94], has a Pareto distribution (7.20)with parametersb=1\u00951andC0=0\u0095001. We compare the proposed Reed-Solomonscheme (Coded - RS) with the following schemes, by running each of them on the same dataset for a xed amount of time (in seconds), and then measuring the test error. U/n.sc/c.sc/o.sc/d.sc/e.sc/d.sc - W/a.sc/i.sc/t.sc /f.sc/o.sc/r.sc /a.sc/l.sc/l.sc : 3Test Error 10-1100 Uncoded - Wait for fRS Uncoded - Wait for fMDS Uncoded - Wait for all Coded - RS Coded - MDS Figure 7.3: The comparison between the test error of dierent schemes as a function oftime,forasoftmaxregressionmodeltrainedusingdistributedgradientdescent on==80machines. atest set ofsize 10000. Reed-Solomon based scheme (Coded - RS) waits for 5RS=68machines, while the one corresponding to [197] (Coded - MDS) waits for 5MDS=33.5RSand5MDSwere obtained by numerically optimizing (7.21). The two coded schemes outperform the uncoded ones. Coded-RS denotes the proposed scheme. U/n.sc/c.sc/o.sc/d.sc/e.sc/d.sc - W/a.sc/i.sc/t.sc /f.sc/o.sc/r.sc 5MDS: is distributed equally amongst =machines - Wait for5MDSmachines. Similarto[197],theknowledgeoftheentiregradientallowsustoemployaccelerated gradient methods such as the one proposed by Nesterov [152]. Details of the experiment are given in the accompanying description of Figure 7.3. The Reed-Solomon based scheme (Coded - RS) waits for 5RS=68machines, while theone correspondingto [197] (Coded- MDS) waits for 5MDS=33. These quantities were obtained by numerically optimizing the expected total computation time, mentioned in (7.21). It isworth mentioningthat ourexperiments show that,even onthis relatively small dataset,adistributedcodedsolutionoutperformsthescenariowherethecomputation is performed on a single machine. However, the single-machine scenario is not very interesting, as we mostly care about cases where performing the computation on one machine is infeasible.173 7.7 Conclusion We presented a straggler mitigation scheme that facilitates the implementation of distributed gradient descent in a computing cluster. For a xed per-machine computational eort, the taskmaster recovers the full gradient from the least number of machines theoretically required, which is done via an algorithm that is ecient in bothspaceandtime. Furthermore,weproposeatheoreticaldelaymodelbasedon heavy-tailed distributions and incorporates the decoding time, which allows us to minimize the expected running time of the algorithm.Part IV Learning from Data 174175 C h a pte r 8 MINIMAX Information Processing Systems (NeurIPS) Deep 2019. Stochastic descent methods (of the gradient and mirror varieties) have become increasingly popular in optimization. In fact, it is now widely recognized that the successofdeeplearningisnotonlyduetothespecialdeeparchitectureofthemodels, butalsoduetothebehaviorofthestochasticdescentmethodsused,whichplayakey role in reaching \"good\" solutions that generalize well to unseen data. In an attempt to shed some light on why this is the case, we revisit some minimax properties of stochasticgradientdescent(SGD)forthesquarelossoflinearmodels\u2014originally developedinthe1990s\u2014andextendthemto generalstochasticmirrordescent(SMD) algorithms for generalloss functions and nonlinear models. In particular, we show that there is a fundamental identity which holds for SMD (and SGD) for over-parameterized linear what is now being called the \"interpolating regime\"), some of which have been shown in certain cases in prior literature. 8.1 Introduction Deep learning has proven to be extremely successful in a wide variety of tasks [118, 119, 143, 189, 213]. Despite its tremendous success, the reasons behind the good generalization properties of these methods to unseen data is not fully understood (and, arguably, remains somewhat of a mystery to this day). Initially, this success was mostly attributed to the special deep architecture of these models. However, in the past few years, it has been widely noted that the architecture is only part176 of the story, and, in fact, the optimization algorithms used to train these models, typicallystochasticgradientdescent(SGD)anditsvariants,playakeyroleinlearning parameters that generalize well. In particular, it has been observed that since these deep models are highly over- parameterized , they have a lot of capacity, and can t to virtually any (even random) set of data points [224]. In other words, highly over-parameterized models can \"interpolate\" the data, so much so that this regime has been called the interesting is that not only do these stochastic descent algorithms converge there is a discrepancyinthesolutionsachievedbydierentalgorithmsandtheirgeneralization capabilities [211], which again highlights the important role of the optimization algorithm in generalization. Therehavebeenmanyattemptsinrecentyearstoexplainthebehaviorandproperties of these stochastic optimization algorithms, and many interesting insights have been obtained [3, 58, 188, 193]. In particular, it has been argued that the optimization algorithms perform an implicit regularization [154, 137, 87, 85, 194, 86] while optimizing the loss function, which is perhaps why the solution generalizes well. Despitethisrecentprogress,mostresultsexplainingthebehavioroftheoptimization algorithm, even for SGD, are limited to linear or very simplistic models. Therefore, a general characterization of the behavior of stochastic descent algorithms for more general models would be of great interest.177 8.1.1 Our Contribution Inthischapter,wepresentanalternativeexplanationofthebehaviorofSGD,and more generally, the stochastic mirror control theory [98, 190, 97], and we generalize several results from thisliterature, e.g.,[96, 115]. Furthermore,weshowthatmanypropertiesrecently proven in the learning/optimization literature, such as the implicit regularization ofSMDintheover-parameterizedlinearcase\u2014whenconvergencehappens\u2014[85], naturally follow from this theory. The theory also allows us to establish new results, such as the convergence (in a deterministic sense) of SMD in the over-parameterized linear case. We also use the theory developed in this chapter to provide some speculative arguments into why SMD (and SGD) may have similar convergence andimplicitregularizationpropertiesintheso-called\"highlyover-parameterized\" nonlinearsetting(wherethenumberofparametersfarexceedsthenumberofdata points) common to deep learning. Inanattempttomakethechaptereasiertofollow,werstdescribethemainideas and results in a simpler setting, namely, SGD on the square loss of linear Thefullresults,forSMDon ageneral classofloss functionsandfor generalnonlinearmodels, arepresentedin Section 8.4. We demonstrate some implications of this theory, such as deterministic convergenceandimplicitregularization,inSection8.5,andwenallyconcludewith someremarksinSection8.6. Mostoftheformalproofsarerelegatedtotheappendix. 8.2 Preliminaries Denote the training the inputs, noiseE8, i.e.,H8=5\u00b9G8\u0096F\u00ba\u00b8E8for8=1\u0096\u0095\u0095\u0095\u0096=. The noise can be due to actual measurement error, or it can be due to modeling error (if the model 5\u00b9G8\u0096\u0001\u00bais not rich enough to fully represent the data), or it can be a combination of both. As a result, we do not make any assumptions on the noise (such as stationarity, whiteness,178 Gaussianity, etc.). Since typical deep models have a lot of capacity and are highly over-parameterized, we are particularly interested in parameter vectors by W=fF2R<jH8=5\u00b9G8\u0096F\u00ba\u0096 8=1\u0096\u0095\u0095\u0095\u0096=g\u0095 (8.1) (Note the absence of the noise term, since in this regime we can fully interpolate the data.) The setWis typically an ( <\u0000=)-dimensional manifold and depends only on the training dataf\u00b9G8\u0096H8\u00ba:8=1\u0096\u0095\u0095\u0095\u0096=gand nonlinear model 5\u00b9\u0001\u0096\u0001\u00ba. The total loss on the training set (empirical risk) can be denoted by !\u00b9F\u00ba=\u00cd= 8=1!8\u00b9F\u00ba, where!8\u00b9\u0001\u00bais the loss on the individual data point 8. We assume that theloss!8\u00b9\u0001\u00badependsonlyontheresidual,i.e.,thedierencebetweentheprediction and the true label. In other words, !8\u00b9F\u00ba=;\u00b9H8\u00005\u00b9G8\u0096F\u00ba\u00ba\u0096 (8.2) where;\u00b9\u0001\u00bacan be any nonnegative dierentiable function with ;\u00b90\u00ba=0. Typical examples of ;\u00b9\u0001\u00bainclude square ( ;2) loss, Huber loss, etc. We remark that, in the interpolatingregime,everyparametervectorintheset Wrenderseachindividual loss zero, i.e., !8\u00b9F\u00ba=0, for allF2W. 8.3 Warm-up: Revisiting SGD on Square Loss of Linear Models In this section, we describe the main ideas and results in a simple setting, i.e., stochastic gradient descent (SGD) for the square loss of a linear model, and we revisit some of the results from 1theory [98, 190]. In this case, the data model isH8=G) 8F\u00b8E8,8=1\u0096\u0095\u0095\u0095\u0096=(where there is no assumption on E8), and the loss function is!8\u00b9F\u00ba=1 2\u00b9H8\u0000G) 8F\u00ba2. Assuming the data is indexed randomly, the SGD updates are dened as F8= F8\u00001\u0000[r!8\u00b9F8\u00001\u00ba,where[\u00a10isthestepsizeorlearningrate. G8\u0096 (8.3) for8\u00151(for8 \u00a1=, we can either cycle through the data, or select them at random). 1For the sake of simplicity of presentation, we present the results for constant step size. We show in the appendix that all the results extend to the case of time-varying step-size.179 Remark. Weshould point out that, when thestepsize [is xed, the SGD recursions have no hope of converging, unless there exists a weight vector Fwhich perfectly interpolatesthe data f\u00b9G8\u0096H8\u00ba:8=1\u0096\u0095\u0095\u0095\u0096=g. Thereasonbeing that, if this isnot the case, for any estimated weight vector in SGD, there will exist at least one data point that has a nonzero instantaneous gradient and that will therefore move the estimate by a non-vanishing amount. /two.supIt is for this reason that the results on the convergence of SGD and SMD (Sections 8.3.3 and 8.5) pertain to the interpolating regime. 8.3.1 Conservation of Uncertainty Priortothe8-thstepofanyoptimizationalgorithm,wehavetwosourcesofuncertainty: our uncertainty about the unknown parameter vector F, which we can represent byF\u0000F8\u00001, and our uncertainty about the 8-th data point\u00b9G8\u0096H8\u00ba, which we can represent by the noise E8. After the8-th step, the uncertainty about Fis transformed toF\u0000F8. But what about the uncertainty in E8? What is it transformed to? In fact, we will view any optimization algorithm as one which redistributes the uncertainties at time8\u00001to new uncertainties at time 8. The two uncertainties, or error terms, we will consider are 48and4?\u00968, dened as follows. 48:=H8\u0000G) 8F8\u00001\u0096and4?\u00968:=G) 8F\u0000G) 8F8\u00001\u0095 (8.4) 48is often referred to as the innvovations and is the error in predicting H8, given the inputG8.4?\u00968is sometimes called the prediction error , since it is the error in predicting the noiseless output G) 8F, i.e., in predicting what the best output of the model is. In the absence of noise, 48and4?\u00968coincide. One can show that SGD transforms theuncertainties in the fashionspecied by the following lemma, which was ?\u00968\u009688\u00151\u0095(8.5) As illustrated in Figure 8.1, this means that each step of SGD can be thought of as a losslesstransformationoftheinputuncertaintiestotheoutputuncertainties,withthe specied [8!0. However,inthis case, convergence is not surprising\u2014since, eectively, after a while, the weights are no longer being updated\u2014and the more interesting question is \"what\" the recursion converges to.180 Figure 8.1: Illustration of Lemma 38. Each step of SGD can be viewed as a transformation of the uncertainties with the 8F8\u00001\u00ba\u0095 (8.6) On the other hand, subtracting both sides of the update rule (8.3) from Fyields F\u0000F8=\u00b9F\u0000F8\u00001\u00ba\u0000[\u0010 H8\u0000G) 8F8\u00001\u0011 G8\u0095 (8.7) Squaring both sides of (8.6)and(8.7), and subtracting the results leads to Equa- tion As we will show next, this identity captures most properties of SGD, and implies several important results in a very transparent fashion. For this reason, this relation can be viewed as a \"fundamental identity\" for SGD. 8.3.2 Minimax Optimality of the theory of 1control and estimation [74, 98, 31]. The denominator of the cost function can be interpreted as the energy of the uncertainties and consists of two terms, kF\u0000F0k2, the energy of our uncertainty of the unknown weight vector at the beginning of learning when wehavenot yetobserved thedata,and\u00cd) 8=1E2 8,the energyof theuncertaintyin the measurements. The numerator denotes the energy of the estimation errors in an online setting . The rst term,kF\u0000F)k2, is the energy of our the two energy terms relative to each other. In this minimax problem, nature has access to the unknown weight vector Fand the noise sequence E8andwouldliketomaximizetheenergygainfromtheuncertaintiestoprediction errors (so that the estimator behaves poorly), whereas the estimator attempts to minimize the energy gain. Such an estimator is referred to as 1-optimal and is robust because it safeguards against the worst-case noise. It is also conservative, for the exact same reason. /three.sup Theorem 40. For any initialization F0, and any numberofsteps fF8ggiveninEq. (8.3) are the optimal solution to the minimax problem (8.9). Furthermore, the optimal minimax value (achieved by SGD) is 1. ThistheoremexplainstheobservedrobustnessandconservatismofSGD.Despite the conservativeness of safeguarding against the worst-case disturbance, this choice may actually be the rational thing to do in situations where we do not have much knowledge about the disturbances, which is the case in many machine learning tasks. Theorem 40 holds for any horizon )\u00151. A variation of this result, i.e., when )!1and without thekF\u0000F)k2term in the numerator, was rst shown in [96, 97]. that the minimax problem is in fact the 1 normof the transfer operator that maps the unknown disturbances \u00b9F\u0000F0\u0096fp[E8g\u00ba to the prediction errors fp[4?\u00968g. 3The setting described is somewhat similar to the setting of online learning, where one considers therelativeperformanceofanonlinelearnerwhoneedstopredict,comparedtoaclairvoyantonewho has access to the entire data set [183, 99]. In online learning, the relative performance is described as a dierence, rather than as a ratio in 1theory, and is referred to as regret.182 WeendthissectionwithastochasticinterpretationofSGD[97]. Assumethatthe true weight vector hasa normal distributionwith [ , and that the noise E8are iid standard 2is possible, in the sense that no estimator can keep the expectedcostnite. Thismeansthat,intheGaussiansetting,SGDminimizesthe expected value of an exponential quadratic cost. The algorithm is thus very adverse tolargeestimationerrors,astheyarepenalizedexponentiallylargerthanmoderate ones. 8.3.3 Convergence and Implicit Regularization The over-parameterized (interpolating) linear regression regime is a simple but instructive setting, recently considered in some papers [85, 224]. In this setting, we can show that, for suciently small step, 39. To see that, note that in the interpolating case the E8are zero, and we have 48= H8\u0000G) 8\u0096 (8.11) for allF2W. updates in(8.3)vanish and we get convergence, i.e., F!F1. Further, again because 48!0, all the data points are being t, which means F12W. Moreover, it is again very straightforward to see from (8.11)that the solution converged to is the onewithminimumEuclideannormfromtheinitialpoint. Toseethat,noticethatthe summationterminEq. (8.11)isindependentof F(itdependsonlyon G8\u0096H8,andF0). Therefore, by taking )!1and both sides with respect to F2W, we get F1=arg min to the ;2-norm solution, among all the solutions. 8.4 Main Result: General Characterization of Stochastic Mirror Descent Stochastic Mirror Descent (SMD) [149, 33, 55, 227] is one of the most widely used families of algorithms for stochastic optimization, which includes SGD asa special case. In this section, we provide a characterization of the behavior of general SMD, ongenerallossfunctionsand generalnonlinearmodels,intermsofafundamental identity and minimax optimality. For dierentiable potential k\u00b9\u0001\u00ba, corresponding SMD updates are dened as F8=arg min F[F)r!8\u00b9F8\u00001\u00ba\u00b8\u0019k\u00b9F\u0096F8\u00001\u00ba\u0096 (8.13) where \u0019k\u00b9F\u0096F8\u00001\u00ba=k\u00b9F\u00ba\u0000k\u00b9F8\u00001\u00ba\u0000rk\u00b9F8\u00001\u00ba)\u00b9F\u0000F8\u00001\u00ba(8.14) is the Bregman divergence with respect to the potential function k\u00b9\u0001\u00ba. Note that \u0019k\u00b9\u0001\u0096\u0001\u00baisnon-negative,convexinitsrstargument,andthat,duetostrictconvexity, \u0019k\u00b9F\u0096F0\u00ba=0iF=F0. Moreover, the updates can be equivalently written as rk\u00b9F8\u00ba=rk\u00b9F8\u00001\u00ba\u0000[r!8\u00b9F8\u00001\u00ba\u0096 (8.15) which are uniquely dened because of the invertibility of rk(again, implied by the strict convexity of k\u00b9\u0001\u00ba). In other words, stochastic mirror descent can be thought of as withamirror as we will see, result in dierent implicit regularizations. To name a few examples: For the potential function k\u00b9F\u00ba=1 2kFk2, the Bregman divergence is\u0019k\u00b9F\u0096F0\u00ba=1 2kF\u0000F0k2, and the update to an equivalent \"conservation law\" for SMD, similar to the identity (8.5), we rst need to dene a new measure for the dierence between the parameter vectorsFandF0according to the loss function !8\u00b9\u0001\u00ba. To that necessarily non-negative. The followingresult,whichisthegeneralcounterpartofLemma38,statestheidentity that characterizes SMD updates in the general setting. Lemma 41. For any (nonlinear) model 5\u00b9\u0001\u0096\u0001\u00ba, any dierentiable loss ;\u00b9\u0001\u00ba, any parameterFand noise valuesfE8gthat satisfyH8=5\u00b9G8\u0096F\u00ba\u00b8E8for8=1\u0096\u0095\u0095\u0095\u0096=, and any step size [\u00a10, the following relation holds for the SMD \u001a8\u00b9F8\u0096F8\u00001\u00baisnotafunctionof F. Furthermore, even though it does not have to be nonnegative in general, for [ suciently small, it becomes nonnegative, because the Bregman divergence \u0019k\u00b9\u0095\u0096\u0095\u00ba is nonnegative. Summing Equation (8.17)over all8=1\u0096\u0095\u0095\u0095\u0096)leads to the following identity, which is the general counterpart of Lemma 39. Lemma 42. For any (nonlinear) easy to verify that for linear models and quadratic loss we obtain \u0019!8\u00b9F\u0096F0\u00ba=\u00b9G) 8F\u0000 G) 8F0\u00ba2.185 relation We should reiterate that Lemma 42 is a fundamental property of SMD, which allows one to prove many important results, in a direct way. In particular, in this setting, we can show that SMD is minimax optimal in a manner that generalizes Theorem 40 of Section 8.3, in the following 3 ways: 1) General potentialk\u00b9\u0001\u00ba,2)Generalmodel the optimal value (achieved by SMD) is 1. The proof is provided in Appendix 8.B. For the case of square loss and a linear model, the result reduces to the following form. Corollary 44. For!8\u00b9F\u00ba=1 2\u00b9H8\u0000G) 8F\u00ba2, for any initialization F0, any i.e., 0\u009f[\u0014U by SMD) is 1. WeshouldremarkthatTheorem43andCorollary44generalizeseveralknownresults in the literature. In particular, as mentioned in Section 8.3, the result of [96] is a186 special case of Corollary 44 for k\u00b9F\u00ba=1 2kFk2. Furthermore, our result generalizes the result of [115], which is the special case for the ?-norm algorithms, again, with square loss and a linear model. Another interesting connection to the literature is thatitwasshownin[95]thatSGDis locallyminimaxoptimal,withrespecttothe 1norm. Strictly speaking, our result is not a generalization of that result; however, Theorem43canbeinterpretedasSGD/SMDbeing globallyminimaxoptimal,but with respect to dierent metrics in the numerator and denominator. Namely, the uncertaintyabouttheweightvector FismeasuredbytheBregmandivergenceofthe potential, the uncertainty about the noise by the loss, and the prediction error by the \"Bregman-divergence-like\" expression of the loss. 8.5 ConvergenceandImplicitRegularizationinOver-ParameterizedModels In this section, we show some of the implications of the theory developed in the previous section. In particular, we show convergence and implicit regularization, in theover-parameterized(so-calledinterpolating)regime /five.sup,forgeneralSMDalgorithms. Asa result, we can easily minimizeboth sides of Eq. (8.22) with respect to F2W, which for)!1leads to the following result. 5In the classical under-parameterized (online streaming) case with white noise, the same theory can be used to establish convergence to the true parameter under the so-called Robbins-Monro conditions (\u00cd1 8=1[8=1\u0096\u00cd1 8=1[2 8\u009f1) in a very direct and simple way (see [14]).187 Proposition 45. For any dierentiable loss ;\u00b9\u0001\u00ba, any initialization F0, and any the SMD iterates given in Eq. (8.15)with respect to any strictly convex potential k\u00b9\u0001\u00ba. If the iterates converge to a solution F12W, then F1=arg min F2W\u0019k\u00b9F\u0096F 0\u00ba\u0095 (8.26) Remark. In particular, for the initialization F0=arg minF2R<k\u00b9F\u00ba, if the iterates converge to a solution F12W, then F1=arg min F2Wk\u00b9F\u00ba\u0095 (8.27) An equivalent form of Proposition 45 has been shown recently in, e.g., [85]. /six.sup Other implicit regularization results have been shown in [86, 194] for classication problems, which are not discussed here. Note that the result of [85] does not say anything about whether the algorithm converges or not . However, our fundamental identityofSMD(Lemma42)allowsustoalsoestablishconvergencetotheregularized point, for some common cases, which will be shown next. WhatProposition45saysisthatdependingonthechoiceofthepotentialfunction k\u00b9\u0001\u00ba, the optimization algorithm can perform an implicit regularization without any explicit regularization term. In other words, for any desired regularizer, if onechoosesapotentialfunctionthatapproximatestheregularizer,wecanrunthe optimization without explicit regularization, and if it converges to a solution, the solution must be the one with the minimum potential. Inprinciple,onecanchoosethepotentialfunctioninSMDfor anydesiredconvex regularization. Forexample,wecanndthemaximumentropysolutionbytaking the potential to be the negative entropy. Another illustrative example follows. Example [Compressed Sensing]: In compressed sensing, one seeks the sparsest solution to an under-determined (over-parameterized) system of linear equations. The surrogate used. Figure 4 shows a compressed 6To be precise, the authors in [85] assume convergence to a global minimizer of the loss function !\u00b9F\u00ba=\u00cd= 8=1;\u00b9H8\u0000G) 8F\u00ba, which, with their assumption of the loss function ;\u00b9\u0001\u00bahaving a unique nite root, is equivalent to assuming convergence to a point F12W.188 sensing example, with ==50,<=100, and sparsity with a stepsizeof[=0\u0095001andthepotentialfunctionwas k\u00b9\u0001\u00ba=k\u0001k 1\u00951. SMDconverged to the true sparse solution after around 10,000 iterations. On this example, it was an order of magnitude faster than standard ;1optimization. Figure 8.2: The training loss and actual error of stochastic mirror descent for compressed sensing. SMD recovers the actual sparse signal. Next we establish convergence to the regularized point for the convex case. Proposition 46. Consider the following two cases. (i);\u00b9\u0001\u00bais dierentiable and convex and has a unique k\u00b9\u0001\u00bais strictly and[\u00a10is 8F8\u00001j kG8k2j;0\u00b9H8\u0000G) 8F8\u00001\u00baj. If either (ii) holds, then for any F0, the SMD iterates given in Eq. (8.15) converge to F1=arg min F2W\u0019k\u00b9F\u0096F 0\u00ba\u0095 (8.29) The proof is provided [8,withminimalmodication. Inparticular,itiseasyto show in this case, the identity (the counterpart of Eq. (8.19)) becomes \u0019k\u00b9F\u0096F that the in this case is the convexity of k\u00b9F\u00ba\u0000[8!8\u00b9F\u00bafor all8, and the SMD with time-varying step size will be the optimal solution to the minimax the analysisdevelopedhereisgeneral,intermsofthe model,thelossfunction ,andthe potential function . Therefore, it would be interesting to study the implications of thistheoryforspecicclassesofmodels(suchasdierentneuralnetworks),specic losses, and specic mirror maps (which induce dierent regularization biases).190 8.A Proof of Lemma 41 (Fundamental Identity) Proof.Let us start by expanding the Bregman divergence \u0019k\u00b9F\u0096F8\u00babased denition \u0019k\u00b9F\u0096F8\u00ba=k\u00b9F\u00ba\u0000k\u00b9F8\u00ba\u0000rk\u00b9F8\u00ba)\u00b9F\u0000F8\u00ba\u0095 By \u0019k\u00b9F\u0096F8\u00ba=k\u00b9F\u00ba\u0000k\u00b9F8\u00ba\u0000rk\u00b9F8\u00001\u00ba)\u00b9F\u0000F8\u00ba\u00b8[r!8\u00b9F8\u00001\u00ba)\u00b9F\u0000F8\u00ba\u0095(8.32) denition of Bregman divergence for \u00b9F\u0096F8\u00001\u00baand\u00b9F8\u0096F8\u00001\u00ba, i.e., \u0019k\u00b9F\u0096F8\u00001\u00ba=k\u00b9F\u00ba\u0000k\u00b9F8\u00001\u00ba\u0000rk\u00b9F8\u00001\u00ba)\u00b9F\u0000F8\u00001\u00baand\u0019k\u00b9F8\u0096F8\u00001\u00ba=k\u00b9F8\u00ba\u0000 k\u00b9F8\u00001\u00ba\u0000rk\u00b9F8\u00001\u00ba)\u00b9F8\u0000F8\u00001\u00ba, can write the above equality as \u0019k\u00b9F\u0096F8\u00ba=\u0019k\u00b9F\u0096F8\u00001\u00ba\u0000\u001a8\u00b9F8\u0096F8\u00001\u00ba\u00b8[\u0000!8\u00b9F\u00ba\u0000\u0019!8\u00b9F\u0096F8\u00001\u00ba\u0001\u0095(8.39)191 Notice that for any model class with additive noise, and any loss function !8 that depends only on the residual (i.e., the dierence between the prediction and the true label), the term !8\u00b9F\u00badepends only on the noise term, for any \"true\" parameterF. In other words, for all Fthat satisfyH8=5\u00b9G8\u0096F\u00ba\u00b8E8, we have !8\u00b9F\u00ba=;\u00b9H8\u00005\u00b9G8\u0096F\u00ba\u00ba=;\u00b9H8\u0000\u00b9H8\u0000E8\u00ba\u00ba=;\u00b9E8\u00ba. Finally, reordering the terms leads to \u0019k\u00b9F\u0096F8\u00ba\u00b8[\u0019!8\u00b9F\u0096F8\u00001\u00ba\u00b8\u001a8\u00b9F8\u0096F8\u00001\u00ba=\u0019k\u00b9F\u0096F8\u00001\u00ba\u00b8[;\u00b9E8\u00ba\u0096(8.40) which concludes the proof. \u0003192 8.B Proof of Theorem 43 (Minimax Optimality) Proof.We prove the theorem in two parts. First, we show that the value of the minimaxisatleast 1. Thenweprovethatthevalueisatmost 1,andisachievedby stochastic mirror descent for small enough step size. 1. Consider the maximization problem max F\u0096fE8g\u0019k\u00b9F\u0096F)\u00ba\u00b8[\u00cd) 8=1\u0019!8\u00b9F\u0096F8\u00001\u00ba \u0019k\u00b9F\u0096F 0\u00ba\u00b8[\u00cd) 8=1;\u00b9E8\u00ba\u0095 Clearly, the optimal functionof fF8g. Similarly,we canalsochoosefeasiblepoints that depend onfF8g. Any feasible point \u00b9F\u0096fE8g\u00bagives a lower boundonthevalueoftheproblem. Beforechoosingafeasiblepoint,letusrst expand the\u0019!8\u00b9F\u0096F8\u00001\u00baterm in the \u0019!8\u00b9F\u0096F8\u00001\u00ba=;\u00b9E8\u00ba\u0000;\u00b9H8\u000058\u00b9F8\u00001\u00ba\u00ba\u00b8;0\u00b9H8\u000058\u00b9F8\u00001\u00ba\u00bar5\u00b9F8\u00001\u00ba)\u00b9F\u0000F8\u00001\u00ba\u0096 (8.41) wherewehaveusedthefact that ;\u00b9H8\u000058\u00b9F\u00ba\u00ba=;\u00b9E8\u00baforall consistent F,in the rst term. Now, we choose a feasible point as follows E8=58\u00b9F8\u00001\u00ba\u000058\u00b9F\u00ba\u0096 (8.42) where Fisthechoiceof F,aswillbedescribedsoon. Thereasonforchoosing this value for the noise is that it \"fools\" the estimator by making its loss on the corresponding data point zero. In other words, for this choice, we have \u0019!8\u00b9F\u0096F8\u00001\u00ba=;\u00b9E8\u00ba\u0000;\u00b90\u00ba\u00b8;0\u00b90\u00bar5\u00b9F8\u00001\u00ba)\u00b9F\u0000F8\u00001\u00ba =;\u00b9E8\u00ba because;\u00b90\u00ba=;0\u00b90\u00ba=0. Itshouldbeclearatthispointthatthischoicemakes the second terms in the numerator and the denominator equal, independent of the choice of F. What remains to do, in order to show the 1lower- bound, is to take care of the other two terms, i.e., \u0019k\u00b9F\u0096F)\u00baand\u0019k\u00b9F\u0096F 0\u00ba. As we would like to make the ratio equal to one, we would like to have \u0019k\u00b9F\u0096F)\u00ba=\u0019k\u00b9F\u0096F 0\u00ba, which is equivalent to having k\u00b9F\u00ba\u0000k\u00b9F)\u00ba\u0000rk\u00b9F)\u00ba)\u00b9F\u0000F)\u00ba=k\u00b9F\u00ba\u0000k\u00b9F0\u00ba\u0000rk\u00b9F0\u00ba)\u00b9F\u0000F0\u00ba193 which is, in turn, equivalent to \u00b9rk\u00b9F)\u00ba\u0000rk\u00b9F0\u00ba\u00ba)F=\u0000k\u00b9F)\u00ba\u00b8k\u00b9F0\u00ba\u00b8rk\u00b9F)\u00ba)F)\u0000rk\u00b9F0\u00ba)F0\u0095 (8.43) Sincerkis an invertible function, rk\u00b9F)\u00ba\u0000rk\u00b9F0\u00ba<0, ifF)<F0. Therefore, the above equation has a solution for F, ifF)<F0. As a result, choosing Ftobeasolutionto (8.43)makes\u0019k\u00b9F\u0096F)\u00ba=\u0019k\u00b9F\u0096F 0\u00ba,ifF)< F0. For the case when \u0019k\u00b9F\u0096F)\u00ba=\u0019k\u00b9F\u0096F 0\u00bafor anychoiceof F. Inthiscase,weonlyneedtochoose Ftobedierentfrom F0, to avoid making the ratio0 0. Hence, we have the following choice F=8>> < >>:a solution of (8.43) for F)<F0 F0\u00b8XFfor someXF<0forF)=F0(8.44) Choosing the feasible point F\u0096fE8gaccording to (8.44) of both sides with respect to fF8g, we from the fact the that the optimal solution of the minimization either has F\u0003 )=F0orF\u0003 )<F0, and in both cases the ratio is equal to 1. 2.Now we prove that, under the small step size condition (convexity of k\u00b9F\u00ba\u0000 [!8\u00b9F\u00bafor all8), SMD makes the minimax value at most 1, which means that it is indeed an optimal solution. Recall from Lemma 42 that \u0019k\u00b9F\u0096F 0\u00ba\u00b8[)\u00d5 8=1;\u00b9E8\u00ba=\u0019k\u00b9F\u0096F)\u00ba\u00b8)\u00d5 8=1\u001a8\u00b9F8\u0096F8\u00001\u00ba\u00b8[)\u00d5 8=1\u0019!8\u00b9F\u0096F8\u00001\u00ba\u0096 where that when k\u00b9F\u00ba\u0000[!8\u00b9F\u00bais convex,\u0019k\u00b9F8\u0096F8\u00001\u00ba\u0000 [\u0019!8\u00b9F8\u0096F8\u00001\u00bais in fact a Bregman divergence (i.e., the Bregman divergence withrespecttothepotential k\u00b9F\u00ba\u0000[!8\u00b9F\u00ba),andthereforeitisnonnegative for anyF8andF8\u00001. Furthermore, we also nonnegativeforall F8. Itfollowsthat \u001a8\u00b9F8\u0096F8\u00001\u00baisnonnegativeforallvalues ofF8\u0096F8\u00001and8. As 0\u00ba\u00b8[)\u00d5 8=1;\u00b9E8\u00ba\u0015\u0019k\u00b9F\u0096F)\u00ba\u00b8[)\u00d5 the left-hand \u0019k\u00b9F\u0096F 0\u00ba\u00b8[\u00cd) 8=1;\u00b9E8\u00ba\u00141\u0095 (8.48) Infact,thismeansthat,independentofthechoiceofthemaximizer(i.e.,for allfE8gandF), as long as the step size condition is met, SMD makes the ratio less than or equal to 1. Combining the results of 1 and 2 above concludes the proof. \u0003 8.B.1 Proof of Theorem 40 Proof.This result is a special case of Theorem 43, which was proven above. to the result. \u0003195 8.C Proof of Proposition 46 (Convergence) Proof.To prove convergence, we appeal again to Equation (8.22), i.e., \u0019k\u00b9F\u0096F 0\u00ba=\u0019k\u00b9F\u0096F)\u00ba\u00b8)\u00d5 8=1\u0000\u001a8\u00b9F8\u0096F8\u00001\u00ba\u00b8[\u0019!8\u00b9F\u0096F8\u00001\u00ba\u0001\u0096(8.49) for allF2W. We prove the two cases When ;\u00b9\u0001\u00baisdierentiableandconvex, also in Eq. (8.49)is nonnegative and thus has to go to zero for8!1. That is because as )!1, the sum should remain bounded, i.e.,\u00cd1 8=1\u0000\u001a8\u00b9F8\u0096F8\u00001\u00ba\u00b8[\u0019!8\u00b9F\u0096F8\u00001\u00ba\u0001\u0014\u0019k\u00b9F\u0096F 0\u00ba. As a result of the non-negativity of both terms in the sum, we have both \u001a8\u00b9F8\u0096F8\u00001\u00ba! 0 and\u0019!8\u00b9F\u0096F8\u00001\u00ba! 0as8!1, the latter of which implies !8\u00b9F8\u00001\u00ba! 0. This implies that the updates in (8.15)vanish and we get convergence, i.e., F8!F1. Further,againbecause !8\u00b9F8\u00001\u00ba! 0,and0istheuniquerootof ;\u00b9\u0001\u00ba, all the data point are being t, which means F12W. 2. To prove case (ii), note that we from (8.52) and (8.55) that the summand in Equation (8.49) is \u001a8\u00b9F8\u0096F8\u00001\u00ba\u00b8[\u0019!8\u00b9F\u0096F8\u00001\u00ba=\u0019k\u00b9F8\u0096F8\u00001\u00ba\u00b8[;0\u00b9H8\u0000G) 8F8\u00001\u00ba\u00b9H8\u0000G) 8F8\u00ba\u0095 (8.56)196 ThersttermisaBregmandivergenceandisthereforenonnegative. Inorderto establish convergence, one needs sign are the same. Note that by the denition of U-strong convexity of k\u00b9\u0001\u00ba, we have \u00b9rk\u00b9F8\u00ba\u0000rk\u00b9F8\u00001\u00ba\u00ba)\u00b9F8\u0000F8\u00001\u00ba\u0015UkF8\u0000F8\u00001k2\u0096(8.57) which implies \u0000[r!8\u00b9F8\u00001\u00ba)\u00b9F8\u0000F8\u00001\u00ba\u0015UkF8\u0000F8\u00001k2\u0096 (8.58) by substituting from the SMD update rule. Upper-bounding the left-hand side by[kr!8\u00b9F8\u00001\u00bakk\u00b9F8\u0000F8\u00001\u00bakimplies [kr!8\u00b9F8\u00001\u00bak\u0015UkF8\u0000F8\u00001k\u0095 (8.59) This implies that we have in the statement of the proposition. Nowthatwehavearguedthatthesummandisnonnegative,theconvergence toF12Wis immediate. The reason Step-Size The update rule for the stochastic mirror descent with time-varying step size is as follows. F8=arg min F[8F)r!8\u00b9F8\u00001\u00ba\u00b8\u0019k\u00b9F\u0096F8\u00001\u00ba\u0096 (8.61) whichcanbeequivalentlyexpressedas rk\u00b9F8\u00ba=rk\u00b9F8\u00001\u00ba\u0000[8r!8\u00b9F8\u00001\u00ba,forall8. The main results in this case are as follows. Lemma 47. For any (nonlinear) model 5\u00b9\u0001\u0096\u0001\u00ba, any any size sequence f[8g, and any number of steps )\u00151, the following relation holds for proof is by summing the following equation for all 8=1\u0096\u0095\u0095\u0095\u0096) \u0019k\u00b9F\u0096F8\u00001\u00ba\u00b8[8;\u00b9E8\u00ba=\u0019k\u00b9F\u0096F8\u00ba\u00b8\u001a8\u00b9F8\u0096F8\u00001\u00ba\u00b8[8\u0019!8\u00b9F\u0096F8\u00001\u00ba\u0096(8.63) which can be easily shown in the same way as in the proof of Lemma 41 any sequencef[8gforwhichk\u00b9F\u00ba\u0000[8!8\u00b9F\u00baisconvexforall 8,theSMDiteratesfF8g given by Eq. (8.61)are the optimal solution F\u0096fE8g\u0019k\u00b9F\u0096F)\u00ba\u00b8\u00cd) 8=1[8\u0019!8\u00b9F\u0096F8\u00001\u00ba \u0019k\u00b9F\u0096F 0\u00ba\u00b8\u00cd) 8=1[8;\u00b9E8\u00ba\u0095 (8.64) (achieved by SMD) is 1. Proof.The proof is similar to that of Theorem 43, \u0019k\u00b9F\u0096F 0\u00ba\u00b8\u00cd) 8=1[8;\u00b9E8\u00ba\u00141 (8.65) for SMD updates, which concludes the proof. \u0003198 Theconvergenceandimplicitregularizationresultsholdsimilarly,andcanbeformally stated as follows. Proposition 49. Consider the following two cases. (i);\u00b9\u0001\u00bais dierentiable and convex and has a unique root at 0, k\u00b9\u0001\u00bais strictly convex, and the positive sequence then for any initialization F0, the SMD 2019InternationalConferenceonMachineLearning(ICML)Generalization Workshop . 2019. Mostmodernlearningproblemsarehighlyoverparameterized,i.e.,themodelhas many more parameters than the number of training data points, and the training loss has innitely many global minima. Therefore, it is important to understand which interpolatingsolutions we convergeto, how they dependon the initialization and learning algorithm, and whether they yield dierent generalization errors. In this chapter, we study these questions for the family of stochastic mirror descent (SMD) algorithms, of which stochastic gradient descent (SGD) is a special case. As we saw in the previous chapter, for overparameterized linearmodels, SMD converges to the closest global minimum to the initialization point, where closeness is in terms of the Bregman divergence corresponding to the potential function of the mirror descent. For initialization points around \"zero\" (i.e., the minimizer of the potential), this means convergence to the minimum-potential interpolating solution, a phenomenon referred to as implicit regularization. Our contributions in this chapter are both theoretical and experimental. On the theory side, we show that for overparameterized nonlinear models, if the model is suciently overparameterized so that a random initialization is w.h.p. close to the manifold of global minima, SMDwitha(sucientlysmall) xedstepsizeconvergestoaglobalminimumthatis approximatelytheclosestoneinBregmandivergence,thusattaining approximate implicit regularization . On the experimental side, our extensive experiments on the MNISTandCIFAR-10datasetsconsistentlyconrmthatthisphenomenonoccurs in practical scenarios. They further indicate a clear dierence Euclidean and \u001210to discourage large components, consistently show that \u001210-SMD has better generalization performance than SGD, which in turn generalizes better than\u00121-SMD. 9.1 Introduction Deep learning has demonstrably enjoyed a great deal of success in a wide variety of tasks [9, 80, 118, 143, 189, 213, 119]. Despite its tremendous success, the reasonsbehindthegoodperformanceofthesemethodsonunseendataisnotfully understood (and, arguably, remains somewhat of a mystery). While the special deep architectureofthesemodelsseemstobeimportanttothesuccessofdeeplearning, the architecture is only part of the story, and it has been now widely recognized that the optimization algorithms used to train these models, typically stochastic gradient descent(SGD)anditsvariants,playakeyroleinlearningparametersthatgeneralize well. Sincethesedeepmodelsare overparameterized models can \"interpolate\" the training data, so much so that this regime has been called the \"interpolating regime\" [138]. In fact, on a given dataset, the loss function typically has (innitely) many global minima , which, however, can have drastically dierent generalization properties (many of them perform poorly on the test set). Which minimum among all the possible minima weconvergetoinpracticeisdeterminedbytheinitializationandtheoptimization algorithm that we use for training the model. Since the loss functions of deep neural networks are non-convex\u2014sometimes even non-smooth\u2014in theory, one may expect the optimization algorithms to get stuck in localminimaorsaddlepoints. Inpractice,however,suchsimplestochasticdescent algorithms almost always reach zero training error , i.e., aglobal minimum of the training loss [224, 122]. More remarkably, even in the absence of any explicit regularization, dropout, or early stopping [224], the global minima obtained by these algorithms seem to generalize quite well (contrary to some other \"bad\" global minima). Ithasbeenalsoobservedthatevenamongdierentoptimizationalgorithms, i.e.,SGDanditsvariants,thereisadiscrepancyinthesolutionsachievedbydierent algorithms and choiceof potential function,there is acorresponding We train a standard ResNet-18 descents with and\u001210norm. Inallthecases,wetrainthenetworkforasucientlylargenumber of steps, with a suciently small step size, until we converge to an interpolating solution(globalminima). Comparisonsbetweenthehistogramsofthesedierent globalminimashowthattheyarevastlydierent. Inparticular,thesolutionobtained by\u00121-SMD is very sparse, and on the contrary, the solution obtained by the \u001210 does not have any zero components. More importantly, there is a clear gap in the generalization performance of these algorithms. In fact, surprisingly and somewhat counterintuitively, the solution obtained by the \u001210-SMD, which uses the entire overparameterization in thenetwork, consistentlyoutperforms SGD, which inturn performs better than the SMD with \u00121norm, i.e., the sparser one. Therefore, it is importanttoask: Whichglobalminimadothesealgorithmsconvergeto,andwhat properties do they have? On the theory side, we show that, for overparameterized nonlinear models, if the model is suciently overparameterized so that the random initialization point is w.h.p. closetothemanifoldofinterpolatingsolutions(somethingthatisoccasionally referred to as \"the blessing of dimensionality\"), then the SMD algorithm for any particularpotentialfunctionconvergestoaglobalminimumthatisapproximately the closest one to the initialization, in Bregman divergence corresponding to the potential. For the special case of SGD, this means that it converges to a global minimum which is approximately the closest one to the initialization in the usual Euclidean sense. We perform extensive systematic experiments with various initial points and various mirror descent algorithms for the MNIST and CIFAR-10 datasets using standard o- the-shelf deep neural network architectures for these datasets with standard random initialization,andwemeasurealltheresultingpairwiseBregmandivergences. We found that every single result is exactly consistent with the above theory. Indeed, in all our experiments, the global minimum achieved by any particular mirror descent algorithmistheclosest,amongallotherglobalminimaobtainedbyothermirrorsand otherinitializations,toitsinitializationinthecorrespondingBregmandivergence. Inparticular,theglobalminimumobtainedbySGDfromanyparticularinitialization is closest to the initialization in Euclidean sense, both among the global minima obtained by dierent mirrors and among the global minima obtained by dierent202 initializations. This result, proven theoretically and backed up by extensive experiments, further implies that, even in the absence of any explicit regularization, these algorithms perform an implicit regularization . In particular, it implies that, when initialized around zero, SGD acts as an approximate \u00122-norm regularizer on the weights. Similarly, by choosing other mirrors, one can obtain any desired form of implicit regularization (such as \u00121or\u00121), which is consistent with the observations about the histograms. 9.2 Background Let us denote the training dataset by whereG82R3are theinputs,and H82Rarethelabels. Themodel(whichcanbe,e.g.,linear,adeep network, 5\u00b9G8\u0096F\u00ba=58\u00b9F\u00bawith some parametervector F2R<. Sincetypicaldeepmodelshavealotofcapacityandare highly overparameterized, we are < \u00a1=(often< =). Inthiscase,there aremanyparametervectors Fthatareconsistentwiththetrainingdatapoints. set of these parameter vectors by W=fF2R<j5\u00b9G8\u0096F\u00ba=H8\u00968=1\u0096\u0095\u0095\u0095\u0096=g\u0095 (9.1) This is a high-dimensional set (e.g., a \u00b9<\u0000=\u00ba-dimensional manifold) in R<and depends only on the training data f\u00b9G8\u0096H8\u00ba:8=1\u0096\u0095\u0095\u0095\u0096=gand the model 5\u00b9\u0001\u0096\u0001\u00ba. The total loss on the training set (empirical risk) can be expressed a global minimum at zero (such as square loss, Huber loss, etc.). In this case, !\u00b9F\u00ba=\u00cd= 8=1\u0012\u00b9H8\u00005\u00b9G8\u0096F\u00ba\u00ba\u0095For example, the conventional gradient descent (GD) algorithm can be used as an attempt to minimize !\u00b9\u0001\u00baoverF. An important generalization of GD is the mirror descent (MD) algorithm, rst introduced by Nemirovski and Yudin [149] and widely used since then [33, 55, 227], can be described as follows. Consider a strictly convex dierentiable function k\u00b9\u0001\u00ba, called the potential function . Then MD is given by the following recursion rk\u00b9F8\u00ba=rk\u00b9F8\u00001\u00ba\u0000[r!\u00b9F8\u00001\u00ba\u0096 F 0 (9.2)203 where[ \u00a10is known as the step size or learning rate. Note that, due to the strict convexityofk\u00b9\u0001\u00ba,thegradientrk\u00b9\u0001\u00badenesaninvertiblemapsothattherecursionin (9.2) yields a unique F8at each iteration, i.e., F8=rk\u00001\u00b9rk\u00b9F8\u00001\u00ba\u0000[r!\u00b9F8\u00001\u00ba\u00ba. Compared to classical GD, rather than update the weight vector along the direction of the negative gradient, the update is done in the \"mirrored\" domain determined bytheinvertibletransformation rk\u00b9\u0001\u00ba. Mirrordescentwasoriginallyconceivedto exploitthegeometricalstructureoftheproblembychoosinganappropriatepotential. Note that MD reduces to GD k\u00b9F\u00ba=1 2kFk2, since the gradient is simply theidentitymap. Otherexamplesincludetheexponentiatedgradientdescent(also known as the exponential weights) versionofMDhasbeenintroduced,aptlycalled stochasticmirrordescent (SMD), which can be considered the straightforward generalization of stochastic gradient descent (SGD): rk\u00b9F8\u00ba=rk\u00b9F8\u00001\u00ba\u0000[r!8\u00b9F8\u00001\u00ba\u0096 F 0 (9.3) In the oine setting, the various instantaneous loss functions !8\u00b9\u0001\u00bacan either be drawn at random or cycled through periodically. Alternatively, the update rule (9.3) can be expressed as F8=arg min F[F)r!8\u00b9F8\u00001\u00ba\u00b8\u0019k\u00b9F\u0096F8\u00001\u00ba\u0096 (9.4) where \u0019k\u00b9F\u0096F8\u00001\u00ba:=k\u00b9F\u00ba\u0000k\u00b9F8\u00001\u00ba\u0000rk\u00b9F8\u00001\u00ba)\u00b9F\u0000F8\u00001\u00ba(9.5) is the Bregman divergence with respect to the potential function k\u00b9\u0001\u00ba. Note that \u0019k\u00b9\u0001\u0096\u0001\u00baisnon-negative,convexinitsrstargument,andthat,duetostrictconvexity, \u0019k\u00b9F\u0096F0\u00ba=0iF=F0. 9.3 Training Deep Neural Networks with SMD Asmentionedearlier,theheavyoverparameterizationintypicaldeepneuralnetworks means that the loss function for such architectures typically has innitely many global minima, and these dierent minima can have very dierent properties and generalizationperformances. Motivatedbythisfact,weproposetrainingdeepneural networks with other members of the family of stochastic mirror descent, to see if they lead to dierent global minima.204 We take the popular CIFAR-10 dataset and the standard ResNet-18 architecture for this dataset. We initialize the network with small random weights and train it withmirrordescentswiththefollowing4dierentpotentialfunctions: \u00121norm,\u00122 norm(SGD), \u00123norm,and\u001210norm. Inallthecases,wechoosethestepsizetobe suciently small, and we train for a suciently large number of steps, so that we converge to an interpolating solution (global minimum). Wecomparethegeneralizationperformanceofthesedierentsolutionsonthetest set. Fig. 9.1 shows the test accuracies of dierent algorithms with eight random initializationsaroundzero. Thereisacleargapinthegeneralizationperformance of these algorithms, and SMD with \u001210-norm consistently performs better than SGD, which in turn performs better than the SMD with \u00121-norm. In fact, perhaps surprisingly, by virtue of changing the optimizer from SGD to \u001210-SMD, without any additional tricks, we outperform the state of the art for ResNet-18 on CIFAR-10. Thisisparticularlyremarkablegiventhatthisveryarchitecturehadbeendesigned with training with SGD in mind. Figure 9.1: Generalization performance of dierent SMD algorithms on the CIFAR- 10 dataset consistently better, while \u00121performs consistentlyworse. TheredlineshowsthestateoftheartonResNet-18forCIFAR-10 (93.02%)[135]. One may be curious to see how the weights obtained by these dierent mirrors205 Figure 9.2: Histogram of the absolute value of the nal weights in the network for dierent SMD algorithm with dierent potentials. Note that each of the four histograms corresponds to an 11\u0002106-dimensional weight vector that perfectly interpolatesthedata. Eventhoughtheweightsremainquitesmall,thehistograms aredrasticallydierent. \u00121-SMDinducessparsityontheweights. SGDappearsto lead to a Gaussian distribution the weights. \u00123-SMD starts to reduce the sparsity, and\u001210shifts the distribution of the weights signicantly, so much so that almost all the weights are non-zero. look. Fig. 9.2 shows the histogram of the absolute value of the weights for these four dierent SMDs, initialized by the exact sameset of weights. The histograms ofthenalweightslooksubstantiallydierentand,sincetheyallstartedfromthe same initial weights and they all interpolate the same data set, this dierence is fully attributable to the dierent mirrors used. The histogram of the \u00121-SMD has more weights at and around zero, i.e., it is very sparse. The histogram of the \u00122-SMD (SGD) looks almost perfectly Gaussian. The one corresponding to \u00123has somewhat shiftedtotheright,andthe \u001210hashascompletelymovedawayfromzero,i.e.,all the weights in the \u001210solution are non-zero. The fact that the \u001210solution, which uses the entire overparameterization available in the network, generalizes better than the sparser ones is very surprising.206 9.4 Theoretical Results Inthissection,weprovideourmaintheoreticalresults. Inparticular,weshowthat for highly overparameterized models: (1) SMD converges to a global minimum and (2) the global minimum obtained by SMD is approximately the closest one to the initialization in Bregman divergence corresponding to the converges to [18, 85]. Proposition50. min F2W\u0019k\u00b9F\u0096F 0\u00ba\u0095 Note that the step size condition, i.e., the convexity of k\u00b9\u0001\u00ba\u0000[!8\u00b9\u0001\u00ba, In particular, for the initialization F0=arg minF2R?k\u00b9F\u00ba, under the conditions of Proposition 50, the SMD iterates converge to F1=arg min F2Wk\u00b9F\u00ba\u0095 (9.6) This means that running SMD for a linear model with the aforementioned F0, withoutanyexplicitregularization,resultsinasolutionthathasthesmallestpotential k\u00b9\u0001\u00baamong all solutions, i.e., SMD implicitly regularizes the solution with k\u00b9\u0001\u00ba. In particular, this means that SGD initialized around zero acts as an \u00122-norm regularizer. In this chapter, we show that these results continue to hold for highly overparameterized nonlinear models in an approximate sense. 9.4.2 F\u0003is the closest global minimum to F0(in Bregman divergence), and F1is the minimum that SMD converges to. which is dened in a similar way to a Bregman divergence for the loss function. The dierencethoughisthat,unlikethepotentialfunctionoftheBregmandivergence, the loss function !8\u00b9\u0001\u00ba=\u0012\u00b9H8\u00005\u00b9G8\u0096\u0001\u00ba\u00baneed not be convex (even when due to the nonlinearity of 5\u00b9\u0001\u0096\u0001\u00ba. Ithasbeenarguedinseveralrecentpapersthatinhighlyoverparameterizedneural networks,becauseWisveryhigh-dimensional,anyrandominitialization F0isclose to it, with high probability [129, 67, 7, 51]. In other words, one can show that, under certainconditions,thedistanceofarandominitializationpoint F0tothemanifold scales as Denote the initial point by F0. There exists F2Wand a region B=fF02R?j\u0019k\u00b9F\u0096F0\u00ba\u0014ngcontainingF0, such that\u0019!8\u00b9F\u0096F0\u00ba\u0015 0\u00968= 1\u0096\u0095\u0095\u0095\u0096=, for allF02B. It is important to understand what this assumption means. Since !8\u00b9\u0001\u00bais not necessarily convex, it is certainly not neighborhood \u0019!8\u00b9F\u0096F0\u00ba\u00150(see Fig. 9.4 for an illustration). What we are requiring is that the initialization F0be inside the intersection of all suchneighborhoodsfor toW.208 Figure 9.4: An illustration of \u0019!8\u00b9F\u0096F0\u00ba\u00150in a local region in Assumption 1. Oursecondassumptionstatesthatinthislocalregion,therstandsecondderivatives of is a mild assumption, which is assumed in other related work such as [163] as well. Note that we do notrequireUto be positive (just its boundedness). The following theorem states that under Assumption 1, SMD converges to a minimum. Theorem52. Considerthesetofinterpolatingparameters W=fF2R<j5\u00b9G8\u0096F\u00ba= H8\u00968=1\u0096\u0095\u0095\u0095\u0096=g, and the SMD iterates given every data point is revisitedaftersomesteps. UnderAssumption1,forsucientlysmallstepsize,i.e., forany[\u00a10forwhichk\u00b9\u0001\u00ba\u0000[!8\u00b9\u0001\u00baisstrictlyconvexon Bforalli,thefollowing holds. 1. All the iteratesfF8gremain inB. 2. The iterates converge (to F1). 3.F12W. Note that, while convergence (to some point) with decaying step size is almost trivial,thisresultestablishesconvergencetothesolutionsetwitha xedstepsize. Furthermore, the convergence is deterministic , and is not in expectation or with high probability. For example, this result also applies to the case where we cycle through the data deterministically.209 We should also remark that the choice of distance in the denition of the \"ball\" Bwas important to be the Bregman divergence with respect to k\u00b9\u0001\u00baand in that particular order. In fact, one cannot guarantee that the SMD iterates get closer to an interpolating Fat every step in the usual Euclidean sense. However, one can establish that it gets closer in \u0019k\u00b9F\u0096\u0001\u00ba. Finally, it is important to note that we need the step size to be small enough to guarantee the strict convexity of k\u00b9\u0001\u00ba\u0000[!8\u00b9\u0001\u00bain B, not globally. DenotetheglobalminimumthatisclosesttotheinitializationinBregmandivergence byF\u0003, i.e., F\u0003=arg min F2W\u0019k\u00b9F\u0096F 0\u00ba\u0095 (9.9) Recall that in the linear case, this was what SMD converges to. We show that in the nonlinear case, under Assumptions 1 and 2, SMD converges to the following holds: 1.\u0019k\u00b9F1\u0096F0\u00ba=\u0019k\u00b9F\u0003\u0096F0\u00ba\u00b8>\u00b9n\u00ba, 2.\u0019k\u00b9F\u0003\u0096F1\u00ba=>\u00b9n\u00ba. In other words, if we start with initialization that is $\u00b9n\u00baaway fromW(in Bregmandivergence),weconvergetoapoint F12Wthatis>\u00b9n\u00baawayfromF\u0003. The Bregman divergence of this point is >\u00b9n\u00bafrom the minimum value it can take. Corollary 54. Fortheinitialization F0=arg minF2R?k\u00b9F\u00ba,undertheconditions 9.4.3 Fundamental Identity of SMD An important tool used in our proofs is a \"fundamental identity\" that governs the behavior of the iterates of SMD, which holds under very general conditions. Lemma 55. For any model 5\u00b9\u0001\u0096\u0001\u00ba, to the appendix. Theideasbehindthisidentityarerelatedto 1estimationtheory[98,190],which was originally developed in the 1990s in the context of robust control theory. In fact, it hasconnections tothe minimaxoptimality ofSGD, whichwas shownby [96]for linear models, and extended to nonlinear models and general mirrors by [18]. 9.5 Related Work Therehavebeenmanyeortsinthepastfewyearstostudydeeplearningfroman optimization perspective, e.g., [3, 58, 188, 7, 163, 138, 67, 129, 51]. While it is not possible to review all the contributions here, we comment on the ones that are most closely related to ours and highlight the distinctions between our results and those. Many recent papers have studied the convergence of the (S)GD algorithm in the so-called \"overparameterized\" setting (or \"interpolating\" regime), which is common in deep learning [163, 7, 193, 138]. All these works, similar to ours, assume that the initialization is close to the solution space (of global minima), which is a reasonable assumption in highly overparameterized models. However, our results are more general because they extend to SMD. Figure 9.5: An illustration of the obtained bydierentalgorithms(columns)fromthesameinitialization(Fig.9.5),measured in dierent Bregman divergences (rows). First Row: The closest point to F0in\u00121 Bregman divergence, among the four nal points, is exactly the one obtained by SMDwith1-normpotential. SecondRow: Theclosestpointto F0in\u00122Bregman divergence (Euclidean distance), among the four nal points, is exactly the one obtained by SGD. Third Row: The closest point to F0in\u00123Bregman divergence, amongthefournalpoints,isexactlytheoneobtainedbySMDwith3-normpotential. Fourth Row: The closest point to F0in\u001210Bregman divergence, among the four nal points, is exactly the one obtained by SMD with 10-norm potential. Furthermore, even for the case of SGD, our results are stronger than those in this literature, in the sense that not only do we show convergence to a global minimum, but we also show that the weight vector we converge to, F1, say, is close to the interpolating weight vector closest to the initialization, F\u0003, initialization statement that kF1\u0000F0k=kF\u0003\u0000F0k\u00b8>\u00b9kF\u0003\u0000F0k\u00ba. We further showthatF1andF\u0003areveryclosetooneanother,viz. kF1\u0000F\u0003k2=>\u00b9kF\u0003\u0000F0k\u00ba), something that could not be inferred from the previous work. Thereexistanumberofresultsthatcharacterizetheimplicitregularizationproperties of dierentalgorithms indierent contexts [154, 137, 87, 85, 194, 18, The closestonestoourresults,sincetheyconcernmirrordescent,aretheworksof[85, 18]. The authors in [85] consider linearoverparameterized models, and show that if SMDhappenstoconvergetoaglobalminimum,thenthatglobalminimumwillbe theonethatisclosestinBregmandivergencetotheinitialization,aresulttheyobtain by examining the KKT conditions. However, they do not provide any conditions for convergence and whether SMD converges with a xed step size or not. [18] also study linear models, but derive conditions on the step size for which SMD converges totheaforementionedglobalminimum. Ourresultsextendtheaforementionedto nonlinear overparametrized models, and show that, for small enough xedstep size, and for initializations close enough to the space of interpolating solutions, SMD212 converges to a global minimum, something which had not been shown in any of the previouswork. Assumingeverydatapointisrevisitedoftenenough,theconvergence we establish is deterministic . Finally, we show that the solution we converge to exhibits approximate implicit regularization, something that was not known for nonlinear models. 9.6 Experimental Results In this section, we evaluate the theoretical claims by running systematic experiments fordierentinitializationsanddierentmirrorsandcomputingthedistancesbetween the global minima achieved and the initializations, in dierent Bregman divergences. Whileaccessingallthepointson Wandndingtheclosestoneisimpossible,we design systematic experiments to test this claim. We run experiments on some standard deep learning problems, namely, a standard CNN on MNIST [120] and the ResNet-18 [101] on CIFAR-10 [117]. models from dierent initializations, and dierent mirror 100%trainingaccuracy,i.e.,apointon W. theparametersofthenetworksaroundzero. Wechoose6independentinitializations for the CNN, and 8 for ResNet-18, and for each initialization, we run dierent SMD algorithms with the following four potential functions: (a) \u00121norm, (b)\u00122 norm (which is SGD), (c) \u00123norm, and (d) \u001210norm (as a surrogate for \u00121). See Appendix 9.B for more details on the experiments. Final 1 Final 2 Final 3 Final 4 Final 5 Final 6 Final 7 Final 8 Initial 1 6\u00021022\u00959\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u0002103 Initial 2 2\u00958\u00021036\u00951\u00021022\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u0002103 Initial 3 2\u00958\u00021032\u00959\u00021035\u00956\u00021022\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u0002103 Initial 4 2\u00958\u00021032\u00959\u00021032\u00958\u00021035\u00959\u00021022\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u0002103 Initial 5 2\u00958\u00021032\u00959\u00021032\u00958\u00021032\u00958\u00021035\u00957\u00021022\u00958\u00021032\u00958\u00021032\u00958\u0002103 Initial 6 2\u00958\u00021032\u00959\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021035\u00956\u00021022\u00958\u00021032\u00958\u0002103 Initial 7 8 9.2: Fixed Mirror: SGD. Pairwise distances between dierent initial points and the nal points obtained from them by SGD (Fig. 9.6). Row i: The closest nal pointtotheinitialpoint 8,amongalltheeightnalpoints,isexactlytheoneobtained by the algorithm in dierent Bregman divergences. Table 9.1, and Table 9.2 show some examples among dierent mirrors and dierent initializations, respectively. Fig. 9.7 shows the distances between a particular initial213 Figure 9.6: An illustration of the experiments in Table 9.2. point and all the nal points obtained from dierent initializations and dierent mirrors (the distances are often orders of magnitude dierent, so we show them in logarithmic scale). The global minimum achieved by any mirror from any initialization is the closest in the correct Bregman divergence, among all mirrors, amongallinitializations,andamongboth. Thistrendisveryconsistentamongall our experiments, which can be found in Appendix 9.B. MNIST. SGD Starting from Initial 4 CIFAR-10. SGD Starting from Initial 2 Figure 9.7: Distances between a particular initial point and all the nal points obtainedbybothdierentinitializationsanddierentmirrors. Thesmallestdistance, among all initializations and all mirrors, corresponds exactly to the nal point obtainedfromthatinitialpointbySGD.Thistrendisobservedconsistentlyforall othermirrordescentsandallinitializations(seetheresultsinTables9.8and9.9in the appendix).214 9.7 Conclusion In this chapter, we studied the convergence and implicit regularization properties of the family of stochastic mirror descent (SMD) for highly overparameterized nonlinear models. From a theoretical perspective, we showed that, under reasonable assumptions, SMD with suciently small step size (1) converges to a global minimum and (2) the global minimum converged to is approximately the closest to the initialization in Bregman divergence sense. Furthermore, our extensive experimental results, on various initializations, various mirror descents, and various Bregmandivergences,revealedthatthisphenomenonindeedhappensindeeplearning, and the solution SMD converges to is the closest to the initialization in Bregman divergencecorrespondingtothatmirror. Thisfurtherimpliesthatdierentmirror descent algorithms act as dierent regularizers, a property that is referred to as implicit regularization . The fact that the \u00121-regularized solution showed a better generalization performance than the other ones, while \u00121was the opposite, suggests theimportanceofacomprehensivestudyoftheroleofregularization,andthechoice of the best regularizer, to improve the generalization performance of deep neural networks.215 9.A Proofs of the Theoretical Results In this section, we prove the main theoretical results. The proofs are based on a fundamental identity about the iterates of SMD, which holds for all mirrors and all overparametereized (even nonlinear) models (Lemma 55). We rst prove this identity, and then use it to prove the convergence and implicit regularization results. 9.A.1 Fundamental Identity of SMD Let us prove the fundamental identity. Lemma 55. For any model 5\u00b9\u0001\u0096\u0001\u00ba, this,we \u0019k\u00b9F\u0096F8\u00ba=k\u00b9F\u00ba\u0000k\u00b9F8\u00ba\u0000rk\u00b9F8\u00001\u00ba)\u00b9F\u0000F8\u00ba\u00b8[r!8\u00b9F8\u00001\u00ba)\u00b9F\u0000F8\u00ba\u0095(9.11) denition of Bregman divergence for \u00b9F\u0096F8\u00001\u00baand\u00b9F8\u0096F8\u00001\u00ba, i.e., have!8\u00b9F\u00ba=0. Therefore, for all F2W \u0019k\u00b9F\u0096F8\u00ba=\u0019k\u00b9F\u0096F8\u00001\u00ba\u0000\u0019k\u00b9F8\u0096F8\u00001\u00ba\u0000[\u0019!8\u00b9F\u0096F8\u00001\u00ba\u0000[!8\u00b9F8\u00ba\u00b8[\u0019!8\u00b9F8\u0096F8\u00001\u00ba\u0095 (9.18) Combining the second and the last terms in the right-hand side leads to \u0019k\u00b9F\u0096F8\u00ba=\u0019k\u00b9F\u0096F8\u00001\u00ba\u0000\u0019k\u0000[!8\u00b9F8\u0096F8\u00001\u00ba\u0000[\u0019!8\u00b9F\u0096F8\u00001\u00ba\u0000[!8\u00b9F8\u00ba\u0096(9.19) for allF2W, which concludes the proof. \u0003 9.A.2 Convergence of SMD to the Interpolating Set Now that we have proved Lemma 55, we can use it to prove our main results, in a remarkably simple fashion. Letus rst prove the convergence ofSMD to the set of solutions. Assumption 1. Denote the initial point by F0. There exists F2Wand every data point is revisitedaftersomesteps. UnderAssumption1,forsucientlysmallstepsize,i.e., for any[\u00a10for whichk\u00b9\u0001\u00ba\u0000[!8\u00b9\u0001\u00bais strictly convex for all i, the following holds: 1. All the iteratesfF8gremain inB;217 2. The iterates converge (to F1); 3.F12W. Proof of Theorem 52. First we show that all the iterates wil remain in B. Recall the identity of SMD from Lemma 55: \u0019k\u00b9F\u0096F8\u00001\u00ba=\u0019k\u00b9F\u0096F8\u00ba\u00b8\u0019k\u0000[!8\u00b9F8\u0096F8\u00001\u00ba\u00b8[!8\u00b9F8\u00ba\u00b8[\u0019!8\u00b9F\u0096F8\u00001\u00ba(9.10) which holds for all F2W. IfF8\u00001is in the regionB, we know that the last term \u0019!8\u00b9F\u0096F8\u00001\u00bais non-negative. Furthermore, if the step size is small enough that k\u00b9\u0001\u00ba\u0000[!8\u00b9\u0001\u00bais strictly convex, the second term \u0019k\u0000[!8\u00b9F8\u0096F8\u00001\u00bais a Bregman divergence and is non-negative. Since the loss is non-negative, [!8\u00b9F8\u00bais always non-negative. As a result, we have \u0019k\u00b9F\u0096F8\u00001\u00ba\u0015\u0019k\u00b9F\u0096F8\u00ba\u0096 implies that \u0019k\u00b9F\u0096F8\u00ba\u0014n, which means will be inB, therefore, F2will inB, and similarly all the iterates will remain inB. Next, we prove that the iterates converge and F12W. If we sum up identity (9.10) for all8=1\u0096\u0095\u0095\u0095\u0096), the rst termson the right- and left-hand because of the non-negativity of the loss. Finally, the last term \u0019!8\u00b9F\u0096F8\u00001\u00bais non-negative because F8\u000012Bfor all8. Hence, all the three terms in the summand are non-negative, and because the sum is bounded, they should go to zero as 8!1. In particular, \u0019k\u0000[!8\u00b9F8\u0096F8\u00001\u00ba! 0 (9.23)218 impliesF8!F8\u00001,i.e.,convergence( F8!F1)(Notethatthefunctions k\u0000[!8 do not go to zero, as there is a xed number, i.e., =, of them). Further, [!8\u00b9F8\u00ba! 0\u0095 (9.24) This implies that all the individual losses are going to zero, and since every data pointisbeingrevisitedaftersomesteps,allthedatapointsarebeingt. Therefore, F12W. \u0003 9.A.3 Closeness of the Final Point to the Regularized Solution In this section, we show that with the additional Assumption 2 (which is equivalent to58\u00b9\u0001\u00bahaving bounded Hessian in B), not only do the iterates remain in Band convergetotheset W,butalsotheyconvergetoapointwhichisverycloseto F\u0003 (the closest solution to the initial point, in Bregman divergence). The proof is again based on our fundamental the assumptions of 52, and Assumption 2, the following holds: 1.\u0019k\u00b9F1\u0096F0\u00ba=\u0019k\u00b9F\u0003\u0096F0\u00ba\u00b8>\u00b9n\u00ba, 2.\u0019k\u00b9F\u0003\u0096F1\u00ba=>\u00b9n\u00ba. Proof of Theorem 53. Recall the identity of SMD from Lemma 55: \u0019k\u00b9F\u0096F8\u00001\u00ba=\u0019k\u00b9F\u0096F8\u00ba\u00b8\u0019k\u0000[!8\u00b9F8\u0096F8\u00001\u00ba\u00b8[!8\u00b9F8\u00ba\u00b8[\u0019!8\u00b9F\u0096F8\u00001\u00ba(9.10) which holds for all F2W. We will argue that, within B, the dependence on Fin the last term is weak and equality is from taking the derivative of !8\u00b9\u0001\u00ba=\u0012\u00b9H8\u000058\u00b9\u0001\u00ba\u00baand evaluating it at F8\u00001. ByTaylorexpansionof 58\u00b9F\u00baaroundF8\u00001andusingTaylor'stheorem(Lagrange's 2\u00b9F\u0000F8\u00001\u00ba) 58\u00b9F8\u00ba\u00b9F\u0000F8\u00001\u00ba\u0011 (9.30) for allF2W. Finally, by plugging this back into the identity (9.25), have 0\u00ba=\u0019k\u00b9F\u0096F1\u00ba\u00b8\u0018\u00001\u00d5 8=11 2[\u00120\u00b9H8\u000058\u00b9F8\u00001\u00ba\u00ba\u00b9F\u0000F8\u00001\u00ba) \u0019k\u0000[!8\u00b9F8\u0096F8\u00001\u00ba\u00b8[!8\u00b9F8\u00ba\u0000[!8\u00b9F8\u00001\u00ba\u00b8[\u00120\u00b9H8\u000058\u00b9F8\u00001\u00ba\u00ba\u00b9H8\u000058\u00b9F8\u00001\u00ba\u00ba\u0003 \u0095 From Theorem 52, we know that F12 W. Therefore, by plugging it into equation (9.32), and using the fact that \u0019k\u00b9F1\u0096F1\u00ba=0, into convB, by \u00b9F\u0003\u0000F8\u00001\u00ba) 58\u00b9F00 of F\u0003. The second term \u0019k\u00b9F\u0003\u0096F1\u00bais non-negative by convexity of k. Since both terms are non-negative and their sum is >\u00b9n\u00ba, each one of them is at most >\u00b9n\u00ba, i.e., 8>> < >>:\u0019k\u00b9F1\u0096F0\u00ba\u0000\u0019k\u00b9F\u0003\u0096F0\u00ba=>\u00b9n\u00ba \u0019k\u00b9F\u0003\u0096F1\u00ba=>\u00b9n\u00ba(9.40) which concludes the following holds. 1.k\u00b9F1\u00ba=k\u00b9F\u0003\u00ba\u00b8>\u00b9n\u00ba 2.\u0019k\u00b9F\u0003\u0096F1\u00ba=>\u00b9n\u00ba Proof of Corollary 54. The proof is a straightforward application of Theorem 53. Note that we have \u0019k\u00b9F\u0096F 0\u00ba=k\u00b9F\u00ba\u0000k\u00b9F0\u00ba\u0000rk\u00b9F0\u00ba)\u00b9F\u0000F0\u00ba plugging in F1andF\u0003, we have\u0019k\u00b9F1\u0096F0\u00ba=k\u00b9F1\u00ba\u0000k\u00b9F0\u00ba and\u0019k\u00b9F\u0003\u0096F0\u00ba=k\u00b9F\u0003\u00ba\u0000k\u00b9F0\u00ba. Subtractingthetwoequationsfromeachother yields \u0019k\u00b9F1\u0096F0\u00ba\u0000\u0019k\u00b9F\u0003\u0096F0\u00ba=k\u00b9F1\u00ba\u0000k\u00b9F\u0003\u00ba\u0096 (9.43) which, along with the application of Theorem 53, concludes the proof. \u0003 9.A.4 ClosenesstotheInterpolatingSetinHighlyOverparameterizedModels As we mentioned earlier, it has been argued in a number of recent papers that for highly overparameterized models, any random initial point is, w.h.p., close to the solutionsetW[18,129,67,7,51]. Inthehighlyoverparameterizedregime, < =, andsothedimensionofthemanifold W,whichis<\u0000=,isverylarge. Forsimplicity, we outline an argument for the case of Euclidean distance, bearing in mind that a similarargumentcanbeusedforgeneralBregmandivergence. Notethatthedistance of an arbitrarily chosen F0toWis given by min FkF\u0000F0k2 s.t.H=5\u00b9G\u0096F\u00ba whereH=vec\u00b9H8\u00968=1\u0096\u0095\u0095\u0095\u0096=\u00baand5\u00b9G\u0096F\u00ba=vec\u00b95\u00b9G8\u0096F\u00ba\u00968=1\u0096\u0095\u0095\u0095\u0096=\u00ba. wherer5\u00b9G\u0096F 0\u00ba)=vec\u00b9r5\u00b9G8\u0096F\u00ba)\u00968=1\u0096\u0095\u0095\u0095\u0096=\u00bais the=\u0002<Jacobian of <outer products. When the G8are suciently random, and < =, it is not unreasonable to assume that w.h.p. _min\u0010 r5\u00b9G\u0096F 0\u00ba)r5\u00b9G\u0096F the Experimental Results Inordertoevaluatetheclaim,werunsystematicexperimentsonsomestandarddeep learning problems. Datasets. We use the standard MNIST CIFAR-10 [117] datasets. Architectures. ForMNIST,weusea4-layerconvolutionalneuralnetwork(CNN) with 2 convolution layers and 2 fully connected layers. The convolutional layers and the fully connected layers are picked wide enough to obtain 2\u0002106trainable parameters. Since MNIST dataset has 60,000 training samples, the number of parameters is signicantly larger than the number of training data points, and the problemishighlyoverparameterized. FortheCIFAR-10dataset,weusethestandard ResNet-18 thetotalnumberof 11\u0002106parametersinResNet-18, the problem is again highly overparameterized. Loss Function. We use the cross-entropy loss as the loss function in our training. We train the models from dierent initializations, and with dierent mirror descents from each particular initialization, until we reach 100%training accuracy, i.e., until we hitW. Initialization. We randomly initialize the parameters of the networks around zero (N\u00b90\u00960\u00950001\u00ba). We choose 6 independent initializations for the CNN, and 8 for ResNet-18, and for each initialization, we run the following 4 dierent SMD algorithms. Algorithms. We use the mirror descent algorithms dened by the norm potential k\u00b9F\u00ba=1 @kFk@ a surrogate for \u00121norm). The update rule can be expressed as 1 Dierent Mirror Descents with Fixed Initialization We provide the distances from nal points (global minima) obtained by dierent algorithms from the same initialization, measured in dierent Bregman divergences for MNIST classication task using a standard CNN. Note that, in all the tables, the smallest element in each row is on the diagonal, which means the point achieved by each mirror has the smallest Bregman divergence to the initialization corresponding to that mirror, among all mirrors. Tables 9.3, 9.4, 9.5, 9.6, 9.7, and 9.8 depict these resultsfor6dierentinitializations. Therowsarethedistancemetricsusedasthe Bregman Divergences with specied potentials. The columns are minima obtained using specied SMD algorithms. Mirror Weprovidethepairwisedistancesbetweendierentinitialpointsandthenalpoints (global minima) obtained by using xed SMD algorithms in MNIST dataset using a standard CNN. Note that the smallest element in each row is on the diagonal, which means the closest nal point to each initialization, among all the nalpoints, is the one corresponding to that point. Tables 9.9, 9.10, 9.11, and 9.12 depict these results for 4 dierent SMD algorithms. The rows are the initial points, and the columns are the nal points corresponding to each initialization. 9.B.1.3 Closest Minimum for Dierent Initializations and minima) obtained by thenal pointobtainedby that mirror from that initialization, among all the mirrors and all the initial points.226 Table9.9: MNIST1-normBregmanDivergenceBetweentheInitialPointsandthe Final Points obtained by SMD 1-norm. Final 1 Final 2 Final 3 Final 4 Final 5 Final 6 Initial Point 1 2.7671 20311 Between the Initial Points and the Final Points obtained by SMD 2-norm (SGD). Final 1 Final 2 Final 3 Final 4 Final 5 Final 6 Initial Point 1 58.608 670.75 Between the Initial Points and the Final Points obtained by SMD 3-norm. Final 1 Final 2 Final 3 Final 4 Final 5 Final 6 Initial Point 1 7.143 35.302 by SMD 10-norm. Final 1 Final 2 Final 3 Final 4 Final 5 Final 6 Initial Point 1 0.00354 0.37 0.403 DierentBregmandivergencesbetweenallthenalpointsandalltheinitialpointsfordierentmirrorsinMNISTdataset using a standard CNN. Note that the smallest element in every single row is on the diagonal, which conrms the theoretical results.228 9.B.2 CIFAR-10 Experiments 9.B.2.1 Closest Minimum for Dierent Mirror Descents with Fixed Initialization We provide the distances from nal points (global minima) obtained by dierent algorithms from the same initialization, measured dierent Bregman divergences for CIFAR-10 classication task using ResNet-18. Note that in all the tables, the smallest element in each row is on the diagonal, which means the point achieved by each mirror has the smallest Bregman divergence to the initialization corresponding to that mirror, among all mirrors. Tables 9.13, 9.14, 9.15, 9.16, 9.17, 9.18, 9.19, and 9.20 depict these results for 8 dierent initializations. The rows are the distance metricsused as the Bregman Divergences with speciedpotentials. The columns are the global minima obtained using specied SMD algorithms. Mirror Weprovidethepairwisedistancesbetweendierentinitialpointsandthenalpoints (globalminima)obtainedbyusingxedSMDalgorithmsinCIFAR-10datasetusing ResNet-18. Note that the smallest element in each row is on the diagonal, which means the closest nal point to each initialization, among all the nalpoints, is the onecorrespondingtothatpoint. Tables9.21,9.22,9.23,and9.24depicttheseresults for 4 dierent SMD algorithms. The rows are the initial points and the columns are the nal points corresponding to each initialization. Table9.21: CIFAR-101-normBregmanDivergenceBetweentheInitial Pointsand the Final Points obtained by SMD 1-norm. Final 1 Final 2 Final 3 Final 4 Final 5 Final 6 Final 7 Final 8 Initial 1 1\u00959\u00021028\u00951\u00021048\u00951\u00021048\u00954\u00021048\u00021048\u00952\u00021047\u00958\u00021047\u00958\u0002104 Initial 2 8\u00951\u00021042\u00957\u00021028\u00951\u00021048\u00953\u00021048\u00021048\u00952\u00021047\u00958\u00021047\u00959\u0002104 Initial 3 8\u00951\u00021048\u00951\u00021041\u00954\u00021028\u00954\u00021048\u00021048\u00951\u00021047\u00958\u00021047\u00958\u0002104 Initial 4 8\u00951\u00021048\u00951\u00021048\u00951\u00021042\u00955\u00021028\u00021048\u00952\u00021047\u00958\u00021047\u00959\u0002104 Initial 5 8\u00951\u00021048\u00951\u00021048\u00951\u00021048\u00953\u00021041\u00951\u00021028\u00951\u00021047\u00958\u00021047\u00958\u0002104 Initial 6 7 8\u00951\u00021048\u00951\u00021048\u00951\u00021048\u00954\u00021048\u00021048\u00951\u00021042\u00952\u00021027\u00958\u0002104 Initial 8 8\u00951\u00021048\u00951\u00021048\u00951\u00021048\u00954\u00021047\u00959\u00021048\u00951\u00021047\u00958\u00021041\u00955\u0002102 Final Points obtained by SMD 2-norm (SGD). Final 1 Final 2 Final 3 Final 4 Final 5 Final 6 Final 7 Final 8 Initial 1 6\u00021022\u00959\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u0002103 Initial 2 2\u00958\u00021036\u00951\u00021022\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u0002103 Initial 3 2\u00958\u00021032\u00959\u00021035\u00956\u00021022\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u0002103 Initial 4 2\u00958\u00021032\u00959\u00021032\u00958\u00021035\u00959\u00021022\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u0002103 Initial 5 2\u00958\u00021032\u00959\u00021032\u00958\u00021032\u00958\u00021035\u00957\u00021022\u00958\u00021032\u00958\u00021032\u00958\u0002103 Initial 6 7 2\u00958\u00021032\u00959\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021036\u00021022\u00958\u0002103 Initial 8 2\u00958\u00021032\u00959\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021032\u00958\u00021035\u00958\u0002102 CIFAR-103-normBregmanDivergenceBetweentheInitial Pointsand the Final Points obtained by SMD 3-norm. Final 1 Final 2 Final 3 Final 4 Final 5 Final 6 Final 7 Final 8 Initial 1 55.844 Between the Initial Points and the Final Points obtained by SMD 10-norm. Final 1 Final 2 Final 3 Final 4 Final 5 Final 6 Final 7 Final 8 Initial 1 2\u009564\u000210\u000082\u009589\u000210\u000082\u009599\u000210\u000082\u009581\u000210\u000082\u009585\u000210\u000082\u009582\u000210\u000082\u009566\u000210\u000082\u009582\u000210\u00008 Initial 2 2\u009579\u000210\u000082\u009565\u000210\u000082\u009583\u000210\u000082\u009583\u000210\u000082\u009571\u000210\u000082\u009574\u000210\u000082\u009569\u000210\u000082\u009588\u000210\u00008 Initial 3 2\u009589\u000210\u000082\u009587\u000210\u000082\u009572\u000210\u000082\u009594\u000210\u000082\u009584\u000210\u000082\u009589\u000210\u000082\u009578\u000210\u000082\u009594\u000210\u00008 Initial 4 2\u009579\u000210\u000082\u009586\u000210\u000082\u009592\u000210\u000082\u009567\u000210\u000082\u009584\u000210\u000082\u009581\u000210\u000082\u009569\u000210\u000082\u009585\u000210\u00008 Initial 5 2\u009576\u000210\u000082\u009588\u000210\u000082\u009595\u000210\u000082\u009593\u000210\u000082\u009561\u000210\u000082\u009573\u000210\u000082\u009566\u000210\u000082\u009583\u000210\u00008 Initial 6 2\u009580\u000210\u000082\u009576\u000210\u000082\u009593\u000210\u000082\u009579\u000210\u000082\u009576\u000210\u000082\u009562\u000210\u000082\u009571\u000210\u000082\u009585\u000210\u00008 Initial 7 2\u009573\u000210\u000082\u009576\u000210\u000082\u009582\u000210\u000082\u009579\u000210\u000082\u009571\u000210\u000082\u009577\u000210\u000082\u009555\u000210\u000082\u009583\u000210\u00008 Initial 8 2\u009573\u000210\u000082\u009579\u000210\u000082\u009585\u000210\u000082\u009578\u000210\u000082\u009575\u000210\u000082\u009574\u000210\u000082\u009573\u000210\u000082\u009564\u000210\u00008 Closest Dierent Initializations minima) obtained by thenal pointobtainedby that mirror from that initialization, among all the mirrors and all the initial points.232 Figure 9.9: Dierent Bregman divergences between all the nal points and all the initial points for dierent mirrors in CIFAR-10 dataset using ResNet-18. Note that the smallest element in every single row is on the diagonal, which conrms the theoretical results.233 Figure 9.10: An illustration of the experimental results. For each initialization F0, we ran dierent SMD algorithms until convergence to a point on the set W (zero training error). We then measured all the pairwise distances from dierent F1to dierentF0, in dierent Bregman divergences. The closest point (among all initializations and to any of the Final Weights of the Network One may be curious to see how the nal weights obtained by these dierent mirrors look,andwhether,forexample,mirrordescentcorrespondingtothe \u00121-normpotential induces sparsity. We examine the distribution of the weights in the network for these algorithmsstartingfromthesameinitialization. Fig.9.11showsthehistogramof theinitial weights,whichfollowsahalf-normaldistribution. Figs.9.12 (a),(b),(c), and weights for \u00121-SMD,\u00122-SMD (SGD), \u00123-SMD, and\u001210-SMD, respectively. Note that each of However,aswillbeshowninthenextsection, this is not necessarily good for generalization (in fact, it turns out that \u001210-SMD has a much better generalization). The histogram of the \u00122-SMD (SGD) looks almost identical to the histogram of the initialization, whereas the \u00123and\u001210histograms are shifted to the right, so much so that almost all weights in the \u001210solution are non-zero and in the range of 0.005 to 0.04. For comparison, all the distributions are shown together in Fig. 9.12(e).234 Figure 9.11: Histogram of the absolute value of the initial weights in the network (half-normal distribution).235 (a) (b) (c) (d) (e) Figure 9.12: Histogram of the absolute value of the nal weights in the network for dierentSMDalgorithms: (a) \u00121-SMD,(b)\u00122-SMD(SGD),(c) \u00123-SMD,and(d) \u001210- SMD. Note that each four histograms corresponds to an 11\u0002106-dimensional weightvectorthatperfectlyinterpolatesthedata. Eventhoughtheweightsremain quite small, the the weights signicantly, so much so that almost all the weights are non-zero.236 9.B.4 Generalization Errors of Dierent Mirrors/Regularizers Inthissection,wecomparetheperformanceoftheSMDalgorithmsdiscussedbefore the generalization of deep networks. ForMNIST,perhapsnotsurprisingly,allthefourSMDalgorithmsachievearound 99%or higher accuracy. For CIFAR-10, however, there is a signicant dierence between the test errors of dierent mirrors/regularizers on the same architecture. Fig. 9.13 shows the test accuracies of dierent algorithms with eight random initializations around zero, as discussed before. Counter-intuitively, \u001210performs consistently best, while \u00121performs consistently worse. We should reiterate that the loss function is exactly the same in all these experiments, and all of them have been trained to t the training set perfectly (zero training error). Therefore, the dierence in generalization errors is purely the eect of implicit regularization by dierent algorithms. Thisresultsuggeststheimportanceofacomprehensivestudyoftherole ofregularization,andthechoiceofthebestregularizer,toimprovethegeneralization performance Figure9.13: 10 using ResNet-18. \u001210performs consistently better, while \u00121performs consistently worse.237 r \"A Algorithms and Convergence Properties\". In: 2019 IEEE Inter- national Conferenceon of updating the weight vector along the negative direction of the stochastic gradient, the update is performed in a \"mirror domain\" dened by the gradient of a (strictly convex) potential function. This potential function, and the mirror domain it yields, provides considerable flexibility in the algorithm compared to SGD. In this chapter, we exhibit a new interpretation of SMD, namely that it is a risk-sensitive optimal estimator when the unknown weight vector and additive noise are non-Gaussian and belong to the exponential family of distributions. The analysis also suggests a modied version of SMD, which we refer to as symmetric SMD (SSMD). The proofs rely on some simple properties of Bregman divergence, which allow us to extend results from quadratics and Gaussians to certain convex functions and exponential families in a rather seamless way. Furthermore, for vanishing step size, and in the standard stochastic optimization setting, we give a direct and elementary proof for convergence of SMD to the \"true\" parameter vector which avoids ergodic averaging or appealing to stochastic dierential equations. 10.1 Introduction Stochasticmirrordescent(SMD)hasbecomeoneofthemostwidelyusedfamilies of algorithms for optimization, machine learning, and beyond [149, 33, 55, 227, 147, 14, 171], which includes the popular stochastic gradient descent (SGD) as a special238 case. The convergence behavior of such algorithms has been extensively studied in theliterature[150,153], undervariousassumptions. Severalotherpropertiesand interpretationsofSMDhaverecentlybeenprovenintheliterature[214,85]. Inearlier provide a of SMD, symmetric SMD (SSMD), whichis suggested by our analysis. The chapter is organized as follows. We review the main properties of SMD and the notionof Bregmandivergence inSection10.2. Therisk-sensitiveoptimalityresult another stochastic result about SMD, i.e., its mean-square convergence in the stochastic setting, in Section 10.5, and conclude in Section 10.6. 10.2 Background Consideraseparablelossfunctionofsomeunknownparameter(orweight)vector F2R<: !\u00b9F\u00ba==\u00d5 8=1!8\u00b9F\u00ba\u0096 where the!8\u00b9\u0001\u00baare called the instantaneous (or local) loss functions, and where our goal is to minimize !\u00b9\u0001\u00baoverF. For example, the conventional gradient descent (GD) algorithm can be used as an attempt to perform such minimization. A generalizationofGD,calledthe mirrordescent (MD)algorithm,wasrstintroduced by Nemirovski and Yudin [149] and can be described as follows. Consider a strictly convex dierentiable function k\u00b9\u0001\u00ba, called the potential function . Then MD is given by the following recursion rk\u00b9F8\u00ba=rk\u00b9F8\u00001\u00ba\u0000[r!\u00b9F8\u00001\u00ba\u0096 F 0 (10.1) where[ \u00a10is known as the step size or learning rate. Note that, due to the strict convexity of k\u00b9\u0001\u00ba, the gradientrk\u00b9\u0001\u00badenes an invertible map so that the recursion in (10.1) yields a unique F8at each iteration. Compared to classical since the gradient is simply the identity map. Other examples include the exponentiated gradient descent (also knownas the exponential weights) and the?-norms algorithm [82, 78]. As with GD, it is straightforward to show that MD converges to a local minimum of !\u00b9\u0001\u00ba, provided the step size [is small enough. When=islarge,computationoftheentiregradientmaybecumbersome. Alternatively, !\u00b9\u0001\u00bamaynotbeavailableandonlythe 0 (10.2) In the oine setting, the various instantaneous loss functions !8\u00b9\u0001\u00bacan either be drawn at random, or cycled through periodically. In the online setting, they are provided at each iteration. Unlike MD (and GD), for a xed step size [, SMD does not generally converge, unless there exists a Fthatsimultaneously minimizes every local loss function !8\u00b9\u0001\u00ba./one.supFor this reason, SMD with vanishing learning rate has also been considered rk\u00b9F8\u00ba=rk\u00b9F8\u00001\u00ba\u0000[8r!8\u00b9F8\u00001\u00ba\u0096 F 0 (10.3) wherethelearningrateischosensuchthat [8!0. Withavanishinglearningrate,it isnotsurprisingthatonecanattainconvergence(sinceafterawhile,thealgorithmis barelyupdatingtheweightvector). Whatismoreinterestingisthefactthatunder suitably decaying rates, one can obtain convergence to a local minimum of !\u00b9\u0001\u00ba (more on this below). 10.2.1 Bregman Divergence For any given strictly convex dierentiable potential (10.4) Inotherwords,theBregmandivergenceisthedierencebetweenthevalueofthe functionk\u00b9\u0001\u00baatapointFandthevalueofitslinear(orrstorder)approximation 1Since if this is not the case, even if the current estimate were at a local minimum of global loss function!\u00b9\u0001\u00ba,F\u0003,say,anyofthelocalgradients r!8\u00b9F\u0003\u00bacouldbenonzero,whichwouldmoveus away fromF\u0003.240 aroundanotherpoint F0(seeFig.10.1). Sinceadeningpropertyofaconvexfunction is that its linear approximations always lie below it, we have that \u0019k\u00b9F\u0096F0\u00ba\u00150. Furthermore, since k\u00b9\u0001\u00bais strictly convex, we have that \u0019k\u00b9F\u0096F0\u00ba=0iF=F0. Finally, it can be observed that \u0019k\u00b9\u0001\u0096\u0001\u00bais convex in its rst argument (but not necessarily in the second). Since the Bregman divergence retains the quadratic (and higher order) terms in the error of the linear approximation of k\u00b9F\u00baaroundF0, itinherits many of the properties of quadratics For unique solution to the equation r\u00b9k1\u00b8k2\u00ba\u00b9F\u0003\u00ba=rk1\u00b9F1\u00ba\u00b8rk2\u00b9F2\u00ba\u0095 (10.7) Proof.The identities can be veried by straightforward calculation. The uniqueness ofF\u0003follows fromthe fact that k1\u00b9\u0001\u00ba\u00b8k2\u00b9\u0001\u00bais strictly convex, since itis the sum of two such functions. \u0003 For example, if k\u00b9F\u00ba=kFk2then\u0019\u00b9F\u0096F0\u00ba=kF\u0000F0k2, and ifk\u00b9?\u00ba=\u0000 \u00b9?\u00ba, where?is a F\u00184\u0000\u0019k\u00b9\u0001\u0096F0\u00ba(i.e.,?\u00b9F\u00ba=24\u0000\u0019k\u00b9F\u0096F 0\u00ba for a suitable normalization constant 2) is a member of the exponential family of distributions, and satises the property Erk\u00b9F\u00ba=rk\u00b9F0\u00ba\u0095 (10.8) In other words, F0is the point whose mirror is the mean of the mirror map.241 Figure 10.1: Bregman divergence. 10.2.2 Parametric Models It will now be useful to introduce some parametric models and make our loss functions more explicit. To this end, assume we have a collection of data points f\u00b9G8\u0096H8\u00ba\u00968=1\u0096\u0095\u0095\u0095=g whereG82R3is the input and H82Ris the output. We will assume that the pairs \u00b9G8\u0096H8\u00baare related through some parametric model H8=5\u00b9G8\u0096F\u00ba\u00b8E8\u0096 8=1\u0096\u0095\u0095\u0095= (10.9) where5\u00b9\u0001\u0096\u0001\u00baisagivenfunctionandrepresentsthemodelingclassweareconsidering, F2R<is the unknown weight vector (or parameter), and E8represents both measurement noise and modeling errors. In this setting, the global loss function can be written as minimum at zero. In this case, !\u00b9F\u00ba==\u00d5 8=1\u0012\u00b9H8\u00005\u00b9G8\u0096F\u00ba\u00ba\u0095 (10.11) For example, for quadratic loss we obtain !\u00b9F\u00ba=\u00cd= 8=11 2\u00b9H8\u00005\u00b9G8\u0096F\u00ba\u00ba2. For (10.11), the explicit form rk\u00b9F8\u00ba=rk\u00b9F8\u00001\u00ba\u00b8[m5\u00b9G8\u0096F8\u00001\u00ba mF\u00120\u00b9H8\u00005\u00b9G8\u0096F8\u00001\u00ba\u00ba\u0096 F 0\u0095 (10.12)242 An important special case is of linear models H8=G) 8F\u00b8E8\u0096 8=1\u0096\u0095\u0095\u0095\u0096= (10.13) where SMD takes the form rk\u00b9F8\u00ba=rk\u00b9F8\u00001\u00ba\u00b8[G8\u00120\u00b9H8\u0000G) 8F8\u00001\u00ba\u0096 F 0\u0095 (10.14) We will often consider two uncertainties, or error terms, 48and4?\u00968, dened as follows. 48:=H8\u0000G) 8F8\u00001\u0096and4?\u00968:=G) 8F\u0000G) 8F8\u00001\u0095 48is often referred to as the innvovations and is the error in predicting H8, given the inputG8.4?\u00968is sometimes called the prediction error , since it is the error in predicting the noiseless output G) 8F, i.e., in predicting what the best output of the model is. In the absence of noise, 48and4?\u00968coincide. 10.2.3 Local and Global Interpretations of SMD It is straightforward to show that at each iteration, SMD solves the following optimization problem: F8=argmin F\u0019k\u00b9F\u0096F8\u00001\u00ba\u00b8[F)r!8\u00b9F8\u00001\u00ba\u0096 (10.15) which can be veried by setting the gradient of the right hand side of (10.15) to zero. What the above relation shows is that the SMD iterates try to align themselves with the direction of the instantaneous gradient, while also trying to stay close to the previousiterateinBregmandivergence. (Thelearningraterelativelyweightsthese two objectives.) We refer to (10.15) as the local interpretation of SMD. We have recently shown that SMD satises the following local conservation law . [18, 14]. Lemma57 (Local Conservation Law [18]) .Even function !8\u00b9F\u00ba= \u0012\u00b9H8\u00005\u00b9G8\u0096F\u00ba\u00bamay not be convex, dene the Bregman divergence \u0019!8\u00b9F\u0096F0\u00bain the usual way. Further dene the quantity \u001a8\u00b9F8\u0096F8\u00001\u00ba:=\u0019k\u0000[!8\u00b9F8\u0096F8\u00001\u00ba\u00b8[!8\u00b9F8\u00ba\u0095 (10.16) Then for each iteration of the SMD updates (10.12), it holds that \u0019k\u00b9F\u0096F8\u00001\u00ba\u00b8[\u0012\u00b9E8\u00ba=\u0019k\u00b9F\u0096F8\u00ba\u00b8[\u0019!8\u00b9F\u0096F8\u00001\u00ba\u00b8\u001a8\u00b9F8\u0096F8\u00001\u00ba\u0095(10.17)243 Summing the local identities in (10.17) from time 1 to time )leads to the following global conservation law \u0019k\u00b9F\u0096F 0\u00ba\u00b8[)\u00d5 8=1\u0012\u00b9E8\u00ba=\u0019k\u00b9F\u0096F)\u00ba\u00b8[)\u00d5 8=1\u0019!8\u00b9F\u0096F8\u00001\u00ba\u00b8)\u00d5 8=1\u001a8\u00b9F8\u0096F8\u00001\u00ba (10.18) Note that (10.18) holds for anyhorizon). We refer to it as the global interpretation ofSMD.Itcanbeusedtoshowseveralremarkable deterministic propertiesofthe SMD algorithm. We now mention a couple. 10.2: Conservation Law of SMD. 10.2.4 Minimax Optimality of SMD Using the aforementioned global identity, in [18, 14], the following has been shown. Theorem58 (Minimax .For any), provided[is small enough minimax optimal algorithm achieving the above. Theorem 58 is a generalization of the 1-optimality of the SGD algorithm for linear models and quadratic loss, where it is referred to as LMS [98, 97, 96], to SMD and general models and general losses. When the potential and loss are quadratic, we have \u0019k\u00b9F\u0096F 0\u00ba=kF\u0000F0k2and\u0012\u00b9E8\u00ba=E2 8. simplication, takes on the form \u0019!8\u00b9F\u0096F8\u00001\u00ba=\u00b9G) 8\u00b9F\u0000F8\u00001\u00ba\u00ba2\u0096 which is the square of the so-called prediction error . In this case, we recover the 1-optimality of LMS, namely that it solves min 8\u00b9F\u0000F8\u00001\u00ba\u00ba2 kF\u0000F0k2\u00b8[\u00cd) 8=1E2 8(10.20)244 As mentioned above, Theorem 58 generalizes 1- optimality in three ways: it holds for general potential, general loss function, and general nonlinear model. 10.2.5 Convergence and Implicit Regularization AnotherinterestingpropertyofSMD,whichagaincanbeprovenusingtheglobal conservation law (10.18), is what is referred to as implicit regularization . In over- parameterized(underdetermined)models,whicharecommonincompressedsensing and modern deep learning problems, there are (typically a lot) more parameters (unknowns) than data points (measurements). That means there are many parameter vectors (in fact innitely many) that are unique strictly convex, and [\u00a10is such that k\u0000[!8is convex for all 8. Then for any F0, iterates converge to particular, the initialization F0=arg minF2R<k\u00b9F\u00ba, under the conditions of Theorem iterates converge to F1=arg min F2Wk\u00b9F\u00ba\u0095 (10.22) This means that running SMD, without nd the maximum entropy solution by taking the potential to be the negative entropy, or do compressed sensing with k\u00b9F\u00ba=kFk1\u00b8n[18, 14]. We should remark that the result extends to quasi-convex losses \u0012\u00b9\u0001\u00ba, and it holds locally (in an approximate sense) even for nonlinear models (non-convex cost).245 Figure 10.3: F1is the closest solution (among all solutions W) toF0. Note that this picture is only for the Euclidean distance; in general the \"closest\" is measured in Bregman divergence. 10.3 Risk-Sensitive Optimality of SMD The results about SMD discussed in the previous section were deterministic in nature. In this section,we give a stochastic interpretation ofSMD, and show that it risk-sensitive optimal. Consider a stochastic model H8=G) 8F\u00b8E8\u00968\u00151, whereFandfE8gare [\u0019k\u00b9\u0001\u0096F0\u00baandE8\u00184\u0000\u0012\u00b9\u0001\u00ba, which are membersoftheexponentialfamily(notethatwhenthepotentialfunction k\u00b9\u0001\u00baandthe loss\u0012\u00b9\u0001\u00baare square, both of these are Gaussian). A conventional quadratic estimator is one that minimizes the expected sum of squared prediction errors, i.e., min fI8gEjfH8g\" 1 2)\u00d5 8=1\u00b9G) 8F\u0000I8\u00ba2# \u0096 (10.23) where the expectation taken over FandfE8gconditioned on the observations, and eachI8intheminimizationcanonlybeafunctionofobservationsuntiltime 8\u00001. For various problems, one may be interested in cost functions more general than quadratic, i.e., min fI8gEjfH8g\")\u00d5 8=1\u0019\u0012\u00b9H8\u0000G) 8F\u0096H8\u0000I8\u00ba# \u0095 An alternative the \"risk-sensitive\" (or exponential cost) criterion, which wasrstintroducedin[108]andstudiedin[196,210,195]. Inparticular,anestimator246 that solves \u0096 (10.25) iscalleda\"risk-averse\"estimator. Thereasonisthatinsuchacriterion,verylarge placed on large errors, and hence, the estimator is more concerned about large values of error (their rare occurrence) than the moderate values of error. Similarasin (10.24),onecanconsiderexponentialcostoferrorsmeasuredwitha more general distance risk-sensitive optimal. Formally, the result is as follows. Theorem 61 (Hassibi et al. [98]) .Consider where F0and0and variances[ that fG8gare persistently exciting and0\u009f[\u009f1 kG8k2\u009688. Then the solution to the following optimization further remark that no larger exponent than 1\u009d2is possible (no algorithm can attain a nite cost if the exponent is larger than 1\u009d2). Thefollowingresultgeneralizestherisk-sensitiveoptimalityofSGDforquadratic errors, to that of SMD for general Bregman-divergence errors. Theorem 62. Consider the model H8=G) 8F\u00b8E8\u00968\u00151, fG8garepersistentlyexciting,and k\u0000[!8isstrictlyconvexfor all8. Then the Theorem 62 The expected exponential cost that needs to be minimized in Theorem 62 is constant that guarantees we are integrating the cost against a conditional distribution. The challenge in evaluating the above integral overFis thatFappears in all three terms of the exponent. In order to facilitate thecomputationofthisintegral,itwillbeusefultousethecompletion-of-squares formula of Lemma 56 to gather Finto a single term. The following lemma provides precisely what we need. Lemma 63. either veried directly or obtained through two successive uses of Lemma 56. \u0003248 As promised, Lemma 63 gathers Finto a single term so that the It is not clear how to do so from the above expression. The next lemma provides an identity that makes this recursive minimization straightforward. Lemma 64. It any time 8, the only term that I8has control over (in the sense that it is a term that depends only on past H9) is the term \u0019\u0012\u00b9H8\u0000G) 8F8\u00001\u0096H8\u0000I8\u00ba\u0095 (The other terms that are influenced by I8, such asF8, are influenced also by H8\u2014see (10.27)\u2014so that I8cannot knowledgeably minimize them.) The term \u0019\u0012\u00b9H8\u0000G) 8F8\u00001\u0096H8\u0000I8\u00bacan be minimized, and in fact set to zero, by taking I8=G) 8F8\u00001\u0096 (10.28) which when plugging into (10.27) yields SMD. This completes the proof. (The attentivereaderwillhavenoticedthatweneededLemma64sinceitwasnotclear how to minimize \u0019\u0012\u00b9H8\u0000G) 8F8\u0096H8\u0000I8\u00baoverI8, because we could not have taken I8=G) not allowed to.)249 10.4 Symmetric SMD (SSMD) Ourproofoftherisk-sensitiveoptimalityofSMDhasledustoanalternative,and more symmetric version, of the algorithm that we refer to as symmetric SMD similar to that of Theorem 62 and is omitted for brevity. \u0003 We note that the dierence between SMD and SSMD is that the noise is now distributedaccordingto E8\u00184\u0000\u0019\u0012\u00b9G) 8F\u0096H8\u00ba,ratherthan E8\u00184\u0000\u0012\u00b9H8\u0000G) 8F\u00ba,andthatthe exponent of \u0019\u0012\u00b9G) 8F\u0096I8\u00ba, rather than \u0019\u0012\u00b9H\u0000G) 8F\u0096H8\u0000I8\u00ba. The distributions and costs for SSMD appear to be more natural. 10.5 Mean-Square Convergence of SMD Intheprevioussections,weshowedseveralfundamentaldeterministicandstochastic propertiesofSMD.Onemayaskhowdotheseresultsrelatetotheconventionalmean- square convergence results, such as [150]. It turns out that the fundamental identity (conservation law (10.18)) of SMD allows proving such stochastic convergence resultsinadirectway(whichavoidsappealingtostochasticdierentialequations and ergodic averaging). The time-varying version of the fundamental identity of whether the algorithm converges to anything interesting. It turns out that when the data points are generated according to a stochastic model withwhitenoise,SMDconvergestothe\"true\"parameter. sequence. Proposition 66. ConsiderH8=G) 8F\u00b8E8\u00968\u00151\u0096where E\u00bbE8\u00bc=0,E\u00bbE8E9\u00bc=f2X89, and theG8are persistently exciting. The potential k\u00b9\u0001\u00ba,for asquareloss, Robbins-Monro [176] conditions. Proof.For the square loss and a linear model, after some simple algebra, the identity (10.30) reduces to 8\u00b9F8\u0000F8\u00001\u00ba\u00b8[842 used the fact that 48=4?\u00968\u00b8E8. On the other hand, the update rule rk\u00b9F8\u00ba=rk\u00b9F8\u00001\u00ba\u00b8[8\u00b94?\u00968\u00b8E8\u00baG8can be expressed, using a Taylor both sides, noting that 4?\u00968andF8\u00001are independent of E8, 42 ?\u00968i goes to zero. If the inputs are persistently exciting, this implies that E\u0002 kF\u0000F8\u00001k2\u0003 !0, which means SMD converges to the in mean-square sense. \u0003 10.6 Conclusion In thischapter, we reviewed several fundamentalproperties of thestochastic mirror descent (SMD) family of algorithms, and provided a new stochastic interpretation of them, namely, that they are risk-sensitive optimal. We also provided a direct and elementary proof of the stochastic convergence of SMD to the true parameter for vanishing step size in the standard stochastic optimization setting. The risk-sensitive optimality result generalizes a known result in the literature about the special case of SGD(akaLMS).Ouranalysisinspiredanewalgorithm,whichisa\"moresymmetric\" variant of SMD. Future work may concern studying this new algorithm and its convergence properties in more detail.252 BIBLIOGRAPHY [1]2015Top500NorthAmericanSolarContractors .http://www.solarpowerworldonline. com. [2]Daron Acemoglu et al. Network security and contagion . Tech. rep. National Bureau of Economic Research, 2013. 2014. [5]Hyoung Jun Ahn and Babak \"Global dynamics of epidemic spread over complex networks\". In: Decision and Control (CDC), 2013 IEEE 52nd Annual Conference on . IEEE. 2013, pp. 4579-4585. [6]HyoungJunAhnandBabakHassibi.\"OntheMixingTimeoftheSISMarkov Chain Model for Epidemic Spread\". In: Decision and Control (CDC), 2014 IEEE 53rd Annual Conference on . IEEE. 2014. [7]ZeyuanAllen-Zhuetal.\"Aconvergencetheoryfordeeplearningviaover- parameterization\". In: Proceedings of the on Learning . PMLR, 2019. [8]Tansu Alpcan and Tamer decision and theoretic approach . Cambridge University Press, 2010. [9]Dario Amodei et al. \"Deep speech 2: for price discovery in markets with non-convexities\". In: European Journal of Opera- tional 411-417. [11]MarioAriolietal.\"Ablockprojectionmethodforsparsematrices\".In: SIAM and Statistical Computing 13.1 (1992), pp. 47-70. [12]D. B. Arnold et al. \"Model-Free Optimal Control of VAR Resources in Distribution Systems: An Extremum Seeking Approach\". In: IEEE Algorithms and Convergence Properties\". In: 2019 IEEE Inter- national Conferenceon /d.sc/o.sc/i.sc:10.1109/ Information Processing Systems (NeurIPS) Deep via Accelerated Projection-Based Consensus\". In: 2018 IEEE International Conference on via Accelerated Projection-Based Consensus\". [23]Navid Azizan et al. \"Improved bounds on the epidemic threshold of exact SIS models on complex networks\". In: 2016 55th IEEE Conference on Decision and . [26]NavidAzizanetal.\"OptimalPricinginMarketswithNon-ConvexCosts\".In: 2019InternationalConferenceonMachineLearning(ICML)Generalization Workshop . 2019. [29]Norman TJ Bailey et al. The mathematical theory of infectious diseases and itsapplications .CharlesGrin&CompanyLtd,5aCrendonStreet,High Wycombe, Bucks HP13 H-innity optimal 556-560. [35]Suzhi Bi and Ying Jun Zhang. \"False-data injection attack to control real- time price in electricity market\". In: Global Communications pp. 772-777. Malicious Attacks on DC State Estimation\". In: Selected Areas in Communications, J\u00f6rnsten. pp. 768-789. [40]Elizabeth \"Minimizing the cost of an epidemic\". In:Game Theory for Networks . Springer, (2013). [44]Stephen Boyd et and statistical learning via the alternatingdirectionmethodofmultipliers\".In: FoundationsandTrends \u00ae in Machine Learning Ahmed Sameh. \"Row pp. 168-193. Bullis. Why SolarCity Is and strategic interaction in electricity networks\". In: Resource and energy 056111. [55]Nicolo Cesa-Bianchi et al. \"Mirror descent feels noregret)\".In: AdvancesinNeuralInformationProcessingSystems .2012, pp. 980-988. [56]Meeyoung of gationintheflickrsocialnetwork\".In: Proceedingsofthe18thinternational to limit cycles for deep networks\". In: International Conference on Learning Representations . 2018. [59]Yue Chen et al. \"Individual risk in mean eld control with application to automated demand response\". In: Decision and Control (CDC), 2014 IEEE 53rd . Springer, 2015. [62]Wei Deng and Wotao Yin. \"On the global and linear convergence of the generalized alternating direction method of multipliers\". In: Journal of Scientic Computing (2012). [63]Steven P Dirkse Michael C Ferris. \"The path solver: a nommonotone stabilizationschemeformixedcomplementarityproblems\".In: Optimization Methods and 123-156. [64]Moez Draief and Laurent Massouli. Epidemics and rumours in complex networks. Cambridge University Press, 2010. [65]MoezDraiefetal.\"Thresholdsforvirusspreadonnetworks\".In: Proceedings of the 1st international conference on Performance evaluation methodolgies and tools. ACM. 2006, p. 51. [66]Kimon Drakopoulos et \"An ecient curing policy for epidemics on graphs\". In: Network Science and Engineering, IEEE Transactions on 1.2 (2014), pp. 67-75.257 [67]Simon S Du et al. \"Gradient online learning and stochastic optimization\". In: of Machine Learning Research 12.Jul Using Coded Short Products\". Information Processing Systems . 2016, .http://www. ercot.com . 2001. [72]AFalletal.\"EpidemiologicalmodelsandLyapunovfunctions\".In: Math. 2.1 (2007), pp. 62-68. [73]MichaelCFerrisetal.\"Mathematicalprogramswithequilibriumconstraints: Automatic reformulation and solution via constrained optimization\". In: (2002). [74]Bruce A Francis. A course in . Berlin; New York: Springer-Verlag, the spread of epidemics\". In: INFOCOM 2005. 24th Annual Joint Conference of the IEEE Computer and Communications Societies. Proceedings IEEE . Vol. descent\". In: Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining . ACM. 2011, pp. al. \"Discrete-time Markov in 2013, pp. In: (2007). [82]Adam results for linear 1827-1836. [86]Suriya Gunasekar preprint \"Ancillary service for the grid via control of commercial building hvac systems\". In: American Control [93]MorHarchol-Balter.\"The EectofHeavy-TailedJobSizeDistributions on ComputerSystemDesign.\"In: Economics, Engineering and Statistics . 1999. [94]Mor Harchol-Balter and Allen B Downey. \"Exploiting their Relation to Backpropagation\". In: Advances in Neural Information 44.2 (1996), Hassibi et al. Indenite-Quadratic Estimation and Unied Approach to H2 and H-innity Theories \"On minimum-uplift pricing for electricity Transactions control 18.2 tolerant networks\". (1937), pp. Kawaguchi. \"Deep learning without poor minima\". Neural Information Processing Systems 586-594. [113]WilliamOKermackandAndersonGMcKendrick.\"Acontributiontothe mathematical theory of epidemics\". In: Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering Sciences . Vol. 115. 772. The Royal Society. 1927, pp. 700-721. [114]Diederik P Kingma [116]B. Kocuk et al. \"Inexactness of Inequalities for Optimal Power Flow\". In: IEEE Transactions of features from tiny images . Tech. rep. Citeseer, 2009. [118]Alex database of handwritten digits . 1998. [122]Jason D Lee et al. \"Gradient descent only converges to minimizers\". In: al. \"Analysis and design algorithms viaintegralquadraticconstraints\".In: SIAMJournalonOptimization 26.1 (2016), pp. 57-95. [126]David Asher Levin et al. Markov chains and mixing times . American Mathematical Soc., 2009.261 [127]Chun-Hsien Li et al. \"Analysis of epidemic spreading of an SIRS model in complex heterogeneous networks\". In: Communications in Nonlinear Science and Numerical Simulation 1042-1054. SmartGrid,IEEETransactions on6.2 algorithm for solving a linear algebraic equation\". In: Decision and Control (CDC), 2013 IEEE on Information and System Security (TISSEC) 14.1 (2011), p. 13. [137]Cong Ma et in Nonconvex Statistical of SGD in Modern Over-parametrized Learning\". In: Proceedings of the 35th International Conference on Machine Learning . Vol. 80. consensus optimization in presence of error\". In: Proceedings of the 2016 IEEE Confs. Audio, Speech and Signal Processing (ICASSP) . Implicit Bias of Dropout\". In: International Conference on Machine Learning . 2018, pp. 3537-3545. [143]Volodymyr Mnih [145]Alexis L Motto and Francisco \"Equilibrium of auction mar- kets with unit commitment: The need for augmented pricing\". In: IEEE Transactions on Power Systems 17.3 (2002), pp. 798-805. [146]Shaoshuai Mou et al. \"A Nesterov. \"A method of with convergence rate $\u00b91\u009d:2\u00ba\". In:Soviet Mathematics [152]YuriiNesterov. Introductorylecturesonconvexoptimization:Abasiccourse . Vol. 87. Nesterov. \"Primal-dual subgradient methods and Control of Epidemics: A sur- vey of spreading on arXiv:1505.00768 (2015). [157] Cameron Nowzari et analysis of generalized epidemic models over directed networks\". In: Decision and Control (CDC), 2014 IEEE 53rd Decision and Control (CDC), 2014 IEEE 53rd Annual Conference on . IEEE. 2014, pp. 1687-1694. [159]Richard P O'Neill market-clearing prices in markets with nonconvexities\". In: European operational research 164.1 Ogura of passive transmission rights in congested electricity systems with competitive generation\". In: The Energy Journal(1997), pp. 63-83. [162]Andrew L PJM system design, and implementation\". In: Power Systems, IEEE Transactions on In:Reviews of modern physics 87.3 (2015), p. 925. [166]David B Patton et al. \"2013 assessment of the electricity markets in new england\". In: electronicword-of-mouthadver- and motivations to pass along email\". In:Journal of advertising research 44.04 (2004), pp. 333-348. [169]Boris T Polyak. \"Some methods of speeding up the convergence of iteration methods\". In: USSR Computational Mathematics and Mathematical Physics 1-17. [170]B Aditya Prakash et al. \"Threshold conditions for arbitrary cascade models on arbitrary networks\". In: Knowledge and information systems 33.3 gradient descent\". Information Processing 2011, pp. 693-701. [174]Irving Reed and Gus Solomon. \"Polynomial codes over certain nite elds\". In:Journal of the Society for Industrial & Applied Mathematics (1960). [175]Matthew Richardson and Pedro Domingos. \"Mining knowledge-sharing sites for viral marketing\". In: Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining . ACM. 2002, pp. 61-70. al. \"Pricing non-convexities in Scarf. \"Mathematical pp. 377-385. [179]Herbert E Scarf. \"The allocation of resources in the presence of indivis- ibilities\". In: The Journal of Economic Perspectives 8.4 [180]DavidTSchemanandPabloTSpiller.\"Geographicmarketdenitionunder theUSDepartmentofJusticeMergerGuidelines\".In: in deregulated wholesale electricity of Economics (1984), in wholesale electricity markets\". In: Proc. of the Western Conference of the Advances in Regulation and Competition, South Lake models using Lyapunov on the game of Go with deep neural networks and search\". 2006. [191]Fridrich Sloboda. \"A projection of the Cimmino type In: Parallel (2017). [194]Daniel Soudry et noise using exponential performance criteria\". In: IEEE Transactions running average of its recent magnitude\". In: COURSERA: Neural networks 26-31. [200]John Nikolas Tsitsiklis. Problems in decentralized decision making and computation. Tech. rep. Massachusetts Inst of Tech Cambridge Lab for Information and Decision Systems, 1984. [201]Ralph Turvey. \"Marginal Policy 38.7 (2010), pp. 3198-3210. [203]Paul Twomey et al. A Review of the Monitoring of Market Power: The Possible Roles of TSOs in Monitoring for Market Power Issues in Congested Transmission Systems . Tech. Report. 2015. a Pareto distribution\". In: Journal of the American networks: An eigenvalue viewpoint\". In: Reliable Distributed Systems, 2003. Proceedings. Wiley & Son Ltd, 1990.267 [211]Ashia C Wilson et al. \"The marginal value of adaptive gradient methods in machine learning\". In: Advances in Neural Programming 20.1 pp. 173- al. \"Google's neural machine translation system: Bridg- ing the preprint arXiv:1609.08144 (2016). 11.Oct (2010), pp. In:Systems & Control [216]LeXieetal.\"Falsedatainjectionattacksinelectricitymarkets\".In: Smart Grid Communications (SmartGridComm), 2010 . IEEE. 2010, pp. 226-231. 659-666. [218]Lin Xu and Yixin Yu. \"Transmission constrained linear supply function equilibrium in power markets: method and example\". In: Power System Technology,2002.Proceedings.PowerCon2002.InternationalConference on. pp. 1-5. [222]Kun Yuan the convergence of decentralized gradient descent\". In: SIAM Journal on Optimization 26.3 (2016), pp. 1835-1854. [223]BaosenZhangetal.\"Anoptimalanddistributedmethodforvoltageregulation in power distribution systems\". 30.4 (2015), pp. "}