{"title": "PDF", "author": "PDF", "url": "https://www.ohchr.org/sites/default/files/documents/hrbodies/hrcouncil/advisorycommittee/neurotechnology/02-nhris/ac-submission-nhri-australia.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "602 Level 3, 175 Pitt Street, Sydney NSW 2000 GPO Box 5218, Sydney NSW 2001 General enquiries 1300 369 711 Complaints info line 1300 65 6 419 TTY 1800 620 241 Protecting Cognition : Human Rights and Neurotechnology Australian Human Rights Commission Submission to the United Nations ' Advisory Committee to the Human Rights Council 02 July 2023 Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 2 Contents 1 Commission introduction ................................ ................................ ......... 4 2 to neurotechnology and 7 4.1 Protecting the 10 4.2 Neurorights mental Neu 8 Human rights impacted by ....... 20 8.1 Right to privacy ................................ ................................ ...................... 21 8.2 Freedom of thought, conscience and religion or belief ........................ 25 8.3 Right to equality and non -discrimination ................................ ............. 27 9 Greater regulation for consumer markets ................................ ........... 28 10 Vulnerable groups ................................ ................................ ................... 31 10.1 People with disability ................................ ................................ 31 10.2 Young people and children ................................ ................................ .... 35 10.3 Socioeconomic disadvantaged and marginalised groups ..................... 37 11 Risk assessments ................................ ................................ ..................... 38 11.1 Human rights impact assessments ................................ ....................... 38 11.2 Communication ................................ ................................ ..................... 39 12 Reaping the benefits, while minimising the harms ............................. 40 Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 3 13 Is the Australian national framework adequate? ................................ 41 13.1 Therapeutic Goods Act 1989 (Cth) ................................ ......................... 41 13.2 Proposed human rights act ................................ ... 42 13.3 Australian Consumer Law ................................ ................................ ..... 42 14 Menta l privacy and personal brain data ................................ ............... 44 14.1 Privacy Act 1 988 (Cth) Review Report ................................ .................... 45 15 National Human Rights Act ................................ 46 15.1 Right to privacy ................................ ................................ ...................... 47 15.2 Freedom of thought, conscience, religion and belief ............................ 48 16 International regulatory framework ................................ .................... 49 17 International cooperation United Nations ................................ ................................ ...................... 51 Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 4 1 Commission i ntroduction 1. The Australian Human Rights Commission (Commission) welcomes the opportunity to make this submission to the United Nat ions' Advisory Committee to the Human Rights Council in respect of the call for input on neurotechnology and human rights (Call for Input) . 2. The r ole of the Commission is to work towards a world in which human rights are respected, protected and pro moted. While the Commission has expertise and knowledge in the area of human rights generally, relevant to th e Call for Input , it has also developed spec ific expertise in respect of human rights and technolog y. 3. This can be seen in the Commission's Human Rights and Technology Project, which was a three -year, national investigation that culminated with the release of the Human Rights and Technology Project Final Report in 2021 (Final Report) . 4. More recently the Commission, in partnership with the Actuaries Institute, published guidance on AI and discr imination in insurance pricing and underwriting . 5. The Commission has continued its work in 2023 on human rights and technology. This submission is in addition to other 2023 submissions to date, including : Human Rights in the Digital Age : Global Digital Compact submission to the United Nations' Office of the Secretary -General's Envoy on Technology . Tackling Technology -facilitated Slavery : submission to the United Nations' Special Rapporteur on Slavery on contemp orary forms of slavery, including its causes and consequences in response to its call for input on t he use of technology in facilitating and preventing contemporary forms of slavery . Safeguarding the Right to Privacy : submission to the Attorney - Genera l's Department in response to the Privacy Act Review Report 2022 . Foreign Interference through Social Media : submission to the Senate Select Committee on Foreign Interference through Social Media . Privacy Risks in the Metaverse : submission to the Australian Competition and Consumer Commission as part of the Digital Platform Services Inquiry 2020 -25. Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 5 6. This submission builds upon the previous work of the Commission to advocate for human rights -centred design and deployment of new and emerging technologies. 7. In this submission the Commi ssion addresses several questions posed by the Call for Input's questionnaire. The Commission welcomes further opportunities to provide submissions to the Advisory Committee and Human Rights Council in respect of neurotechnology and human rights . 2 Consultat ions 8. The positions presented in this submission are those of the Commission, informed by the views and opinions expressed by participants throughout a consultation process run by the Commission . 9. The Commission facilitated two broad consultations with a ra nge of stakeholders and experts from civil society , business , regulators and government in June 2023 . Further targeted consultations were also held with certain stakeholders. 10. Participants were provided with a Consultation Invitation when they were invited to attend. The Consultation Invitation set out what the C ommission requested stakeholders to bear in mind when engaging in the consultations . It emphasised that participants should consider questions four - eight raised in the 'Impact, opportunities a nd challenges' section of the questionnaire. However, it is im portant to note that this submission also answer s questions not raised during consultations. 11. The Commission encouraged invitees to provide written input via email where they were unable to atte nd the online consultations, or if they wished to further expa nd upon what was discussed. 12. Across all consultations , 47 participants engaged in the Commission's consultations. A further 12 stakeholders provided written submissions. 3 Definitions 13. The Call f or Input questionnaire specifically defines neurotechnologies as: those devices and procedures used to access, monitor, investigate, assess, manipulate and/or emulate the structure and function of the neural systems of natural persons.1 They are meant to either record signals from the brain and 'translate ' them into technical control commands, or to manipulate brain activity by applying electrical or optical stimuli.2 Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 6 14. Throughout this submission the Commission has adopted the same definition . However, it is necessary to further understand and define the different forms of neurotechnology which currently exist . 15. Broadly speaking there are three central types of neurotechnology: Devices which monitor brain activity Devices which intervene in brain activity Devi ces which are a combination of the preceding two types. 3 3.1 Brain -computer interfaces 16. At the core of neurotechnologies are brain -computer interfaces (BCIs).4 BCIs are devices which connect an individual's brain to a computer or device (e.g. a smartphone) ext ernal to the human body. BCIs facilitate bi -directional communication between the brain and an external device - either transmitting brain data or possibl y alter ing brain activity.5 This can operate either by implantation inside of a person's skull or via a non -implantable wearable device (similar to a helmet).6 3.2 Non -implantable BCIs 17. BCIs can either be implantable or non -implantable. A non -implantable BCI will generally sit on an individual's head - often in the form of wearable technology such as helmets, g lasses and wristbands. It is these less invasive wearable BCIs which currently dominate the consumer neurotechnology market.7 18. Such technology may assist peop le with expressive or communicative disabilities to better communicate by decoding images in a per son's mind.8 These devices have already been used to successfully share images and words between people in different rooms via non -implantable BCI devices - enabling individuals to effectively exchange thoughts.9 3.3 Implantable BCIs 19. Some BCIs are implanted via surgery inside of a person's skull and placed directly on the brain.10 These electrodes then send brain data to a computer for analysis and decoding. 20. Implantable BCIs are not new and have been utilised in medicine for some time. For example, deep brain simulators have been used to assist people with Parkinson's disease to re gain mobility.11 Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 7 3.4 Metaverse 21. The Metaverse is not defined in the Call for Input. For the purposes of this submission the Commission draws upon the definition provided by the XR Safety Initiative : The Metaverse is a network of interconnected virtual worlds with the following key characteristics: Presence, Persistence, Immersion and Interoperability. Metaverse is the next iteratio n of the internet enabled by several c onverging technologies such as Extended Reality (XR), Artificial Intelligence (AI), Decentralised Ledger Technologies (DLTs), neuro -technologies, optics, bio -sensing technologies, improved computer graphics, hardware, and network capabilities. Metaverse h as four main aspects; presence, persistence, immersion and interoperability. Presence is the feeling of being present or physically located within a digital environment. Through stimulating realistic sensory experience s and enabling participants to interac t with objects and other participants, it creates a sense of immersion and engagement within the virtual world, as if participants were in the same physical space. The sense of presence is carried out through technolo gies such as virtual reality glasses. Persistence refers to the ability of virtual objects, environments, and experiences to assist over time, even when participants are not actively interacting with them. It allows participants to make progress, own virtu al property, and build ongoing relatio nships. Immersion refers to the degree to which a participant is fully engaged and absorbed in a virtual environment, to the point where the individual may forget about their physical surroundings. A sense of immersion is created through technologies such as virtual reality (VR) headsets, haptic feedback devices, and 3D audio. Interoperability refers to the ability of different virtual worlds and systems to communicate and interact with each other seamlessly, allowing i ndividuals to move freely between different digital environments and experiences. It is essential for creating a cohesive and interconnected virtual world that allows individuals to seamlessly move between different experiences and platforms.12 4 Introduction to neurotechnology and neurorights 22. Broadly speaking neurotechnology is a scientific discipline which consolidates and connects electronic devices with the nervous system.13 This is usually done via implantable or non -implantable BCIs . Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 8 23. The rapid advancemen t of neuroscience and neurotechnology in recent years has created significant and new opportunities for collecting, maintaining and utilising brain data to understand and/or manipulate the human mind .14 Such applications potentially have immense benefits fo r both individuals and the broader community . It is not uncommon to see articles about the profoundly positive impacts of the technology - such as people being able to walk again15 or improving our understanding of how to treat chronic pain .16 24. However, neuro technologies also raise profound human rights problems which may require the international community to rethink its very approach to modern human rights. 25. Brain implants are not a fundamentally new technology and have been used in medical p rocedures for so me time . For example, deep brain stimulation has been eliminating tremors associated with Parkinson's via electric impulses to the basal ganglia of the brain since 1997.17 26. However as technologies improve, the potential application of neurotechnologies multi ples. This is especially so when BCIs are utilised in conjunction with artificial intelligence (AI) , which is still new and largely untested.18 27. For example , a recent experiment has seen the integrated use of neurotechnology and large language model A I to translate brain activity into words.19 In this experiment AI was capable of translating private thoughts into readable language by analysing fMRI scans, which measure the flow of blood to different regions of the brain.20 Unlike past technologies which requir e implantation to allow paralysed people to write by thinking, this new language deco der did not require implantation. As part of this experiment, participants listened to a recording while undergoing fMRI scans. Researchers were interested in how closely the AI translation reflected the actual recording. While most of the words were out o f place , the basic meaning of the passage was largely preserved. Effectively the AI was paraphrasing. 28. The original transcript of the recording stated: I got up from the ai r mattress and pressed my face against the glass of the bedroom window expecting to s ee eyes staring back at me but instead only finding darkness.21 29. The decoded brain activity produced: I just continued to walk up to the window and open the glass I stood on my toes and peered out I didn't see anything and looked up again I saw nothing.22 Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 9 30. However, this isn't the only recent example of the capabilities of neurotechnology : There have already been proof -of-concept studies demonstrating brain -to-brain interaction facilitated by neurotechnology.23 Scientists have recorded the neural activity of individuals watching movies, and using that neural activity , managed to play back hazy images of the movie using only the brain activity.24 Human brains have been directly con nected to cockroach brains. This allowed the human to control certain behaviours, such as steering their paths by thought alone.25 Invasive BCIs can also be used to control the actions of laboratory animals such as mice. While a mouse was engaging in a task , such as eating food, a BCI recorded its brain data. That data was then used to reactivate and stimulate the same parts of the brain that were previously recorded . This forced the mouse to eat again - even if it did not want to eat.26 Researchers have foun d ways to use BCIs to implant artificial memories or images into a mouse's brain - generating hallucinations and false memories of fear .27 31. These are just a few examples of the increasing sophistication of these technologies and their ability to revolutionis e the way human s live and communicate. Howeve r, these examples also demonstrate that neurotechnologies are replete with possible human rights violations .28 For example, if mice can be controlled, could the technology be improved to manipulate human thoughts and actions? 32. Not only is neurotechnology's capabilities astounding, so is its application. It is likely that neurotechnology will have a role in: Medical treatment of a range of conditions Consumer gaming, education and meditation Socialising Criminal ju stice as a potential tool for interrogation Military operations to cognitively enhance combatants or to be used for covert brain -to-brain communication.29 33. The need to scrutinise the human rights risks of neurotechnolo gy is of unprecedented importance. This is largely due to the technologies capacity to: Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 10 access mental states of a person verify subjective reports on those mental states verify subjective (or first -person) reports regarding the nature and content of those states contest first -person authority r egarding mental states by overriding such introspective reports control decoded mental states by providing input behaviourally or through direct brain stimulation.30 34. Neurotechnology, especially when used in conjunction with AI, challenge s what it means to b e human and draw s into question the traditional boundaries placed around an individual's internal thoughts and processes. There is a growing body of literature and international policy which considers the need to ensure that the human rights framework prot ects the mind of the individual . 35. It is likely that neurotechnologies will only become more pervasive and embedded in the everyday lives of individuals over the coming decade.31 While it is important to harness the benefits of neurotechnologies, there must also be greater scrutiny of the ethical and legal implications of its development and deployment. 36. Government, academics, policymakers and civil society are starting to work towards protecting the human mind from the human rights risks. However, despite th e sig nificant discourse in this field there are divergent opinions. 4.1 Protecting the human mind 37. There are three broad approaches to protecting the human mind from the adverse impacts of neurotechnologies according to the relevant literature . 38. The first scho ol of thought advances that novel human rights (also known as 'neurorights') specifically protecting the brain are necessary . Advocates claim that existing fundamental rights and freedoms are insufficie nt to protect against the misuse of neurotechnology. T hose who advance neurorights rightly note that when traditional rights and freedoms were introduced the ability to monitor and manipulate brain activity was science fiction, barely conceivable as being real. Accordingly, new rights are necessary to reflect the monumental shift in what it means to be human due to the impact of neurotechnologies.32 The proposal of neurorights ha s generated lively debate as many question their necessity, effectiveness and i f it might lead to 'rights inflation '.33 Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 11 39. The second scho ol of thought provides that adaptive interpretations and applications of existing rights and freedoms are required to protect the brain - but novel neurorights are not. Those proposing such an approac h are generally in agreement with those of the prior pos ition that existing rights and freedoms in their current form and application offer inadequate protection. However, these advocates believe it better to update our interpretations of existing human ri ghts and apply them to neurotechnologies. There are cert ainly existing rights which can be positioned to address neurotechnologies , with the right to privacy and the right to freedom of thought, the right to bodily integrity being clear examples .34 40. Howeve r, such a n interpretive approach to extend existing right s and freedoms will require a conscious effort by policy makers across jurisdictions and may be slow to advance - with the risk of being outpaced by the rate of technological advancement. 41. The final group consider that no novel rights or new interpretation s are necessary to protect the human mind. This position is largely outdated and rarely raised.35 4.2 Neurorights 42. 'Neurorights' is an umbrella term which encompasses novel rights which protect the human mind.36 While it is possible that existing human rights ma y apply to neurotechnologies, advocates for neurorights hi ghlight the heightened risk profile of the technology and question the sufficiency of existing rights.37 43. When genuinely considering if it is best to introduce novel neurorights or to adapt existing human rights it is necessary to carefully consider which approach is most appropriate. One key risk of introducing new rights is that it may contribute to the phenomenon of 'rights inflation' which threatens diluting the core idea (and universal nature) of human rights.38 44. Broadly speaking , proponents of neurorights suggest that existing treaties do not offer the robust and comprehensive human rights protection that a neurotechnological world requires. Instead, they advocat e that today's era calls for a novel protective framework of neurorights.39 45. Given th e profound ways in which neurotechnology will change the way we live our lives and what it means to be human, there has been great attention paid to how the boundaries of the brain and mental lives of people c an be protected. Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 12 46. The Universal Declaration of Human Rights ( UDHR ) has provided a set of agreed fundamental rights and freedoms to guide how all humans should treat other s and be treated. Since its adoption in 1948 , it was followed by binding international human rights instruments , such as the International Covenant on Civil and Political Rights (ICCPR ), which has been adopted by 173 countries, covering 90% of the world's population.40 47. Since 1948, t echnology has redefined how humans live and interact with on e another. While much of this usage has led to improvements in quality of life, its widespread adoption also brings significant challenges , including to human rights . 48. Neurotechnology poses an especially novel risk to human rights as it can leap the bound ary between the external world and the internal human mind, invading our private emotions, thoughts and memories . The brain is like no other organ - it is what makes us who we are as individual human beings . While neurotechnologies present boundless opport unities for scientific and medical breakthroughs, human rights must be protected as this technology poses unique risks by the way that it interacts with the human brain . 49. The real challenge of this technology will be how to create frameworks and guardrails to protect against human rights violations - responding to the current risks posed by the technology, and forward th inking and flexible enough to adapt as the technology improves. 50. Current literature focuses largely on the neurorights of mental integrity, mental privacy and cognitive liberty as partly protected by international instruments such as the: UDHR ICCPR American Convention on Human Rights (ACHR) European Convention on Human Rights (ECHR) Charter of Fundamental Rights of the European Union (CFR) .41 51. This has been further built upon by projects to determi ne the prospective scope of establishing human rights in respect of thoughts, emotions, and other mental states, both now and in the future.42 These projects have been initiated by organisations such as the: United Nations Inter -American Juridical Committee Committee on Bioethics of the Council of Europe Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 13 United Nations Educational, Scientific and Cultural Organization (UNESCO ) Organization for Economic Co -operation and Development (OECD).43 52. There are esta blished human rights which should be applicab le to many uses of neurotechnology, such as the rights to: Bodily integrity Privacy Personal identity Freedom of thought Autonomy.44 53. Advocates of neurorights argue that these rights are insufficient given the uniqueness of neurotec hnologies. The significant attention currently being focused on neurotechnology and human rights is largely in response to the novel challenges the technology poses.45 Dr Allan McCay, an expert on neurotechnology and Deputy Director of the Sydney Institute of Criminology , poses just some of the legal and ethical questions that must be considered , asking: what if a person commits a criminal act by using the implanted microchip. Who would be responsible for the criminal violation? So, if another person somehow manages to control the electronic device to commit a violation, how would the courts address the le gal issues? In essence, how do we regulate human mental capacity? There are other questions that can come up when implementing this technology. For example, could solicitors one day be instructed to use a microchip to enhance their mental capabilities? Could the courts force known offenders to use special microchips, so their brain activities are monitored and controlled by a government a gency?46 54. There has been serious consideration of the application of neurotechnology in the criminal just ice system . Academics have questioned if the police may deploy neurotechnology to analyse brain data and make inferences about suspects and witnesses (such as truthfulness ) in their investigation s. Some have gone further and raised concern s that neurotechn ologies may be used in sentencing and post -imprisonment conduct : for example, a closed -loop device could be used to monitor the brain of an offender and intervene upon it in order to avert an angry outburst that might precipitate an offense .47 Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 14 55. There is increasing discussion globally of how to protect the human mind from neurotechnology : Chile has been working on introducing neurorights into its national legal system via reform to its constitution. Senator Girardi pointed to the failure to regulate social media and internet platforms in the past, to highlight why it is important to regulate technology before it becomes a problem.48 Spain has included neuro data specific sections in its Digital Rights Charter.49 The United Nations, InterAmerican Juridi cal Committee and the Council of Europe are all exploring whether existing human rights and freedoms provide sufficient legal protection from neurotechnologies.50 UNESCO has recently made its report on the risks and challenges of neurotechnologies for human rights.51 The United Kingdom's Information Commissioner's Office (UK ICO) recently published a paper on neurotechnology. 56. Although there are some divergences, neurorights often settle around the discussion of the right to mental privacy, mental int egrity and cognitive liberty. 4.3 What is m ental privacy ? 57. Mental privacy simply refers to the righ t to private thoughts, feelings, memories, emotions and brain data. 58. Vint Cerf, Vice President and Chief Internet Evangelist at Google, once stated that 'privacy may actually be an anomaly'.52 In a world of heightened data collection and surveillance, eith er by government or corporate entities, it seems possible that this statement will come true as brain data becomes the next piece of personal data to be harvested by organisations seeking to monetise it. 59. There is already significant commentary and calls f or legislative reform about how to protect personal information online.53 It seems a natural progression for those discourses to extend now to the protection of brain data. 60. Availability o f brain data will likely give companies and governments the ability to make inferences about users of neurotechnologies. This can extend to their predisposition to neurological and psychiatric conditions or future behaviour.54 Such insights put those with access to the brain data in a powerful position to manipulate people either through direct intervention Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 15 through neurotechnologies or by utilising the brain data to subversively push people towards certain decisions. 61. We already know that algorithms are abl e to make inferences about us and suggest content we are most likely to engage with. While problematic, this issue is exacerbated where such tailored content or 'nudges' are made on the basis of brain data. Such breaches of mental p rivacy can result in man ipulation or even physical harm to users.55 62. While there is no recognised express right to mental privacy , our feelings, thoughts and mental states may obtain implicit protection under the rights to: privacy freedom of thought freed om of expression. 4.4 What is m ental integrity ? 63. Where the right to bodily integrity protects against interference with on e's body , the right to mental integrity protects against interference with one's mind.56 Sceptics argue that the mind is already protected b y way of the brain being contained within the body, and propose that an additional protection for the mind would be superfluous.57 64. Such criticism ignores that with the advent of neurotechnology, interference with the mind may not interfere with the body. For example, non-implantable BCIs can interfere with brain activity and behaviour in intrusive ways , severely violating one's right m ental integrity. However, because non-implantable BCIs are often wearable and non -intrusive they may not violate the right t o bodily integrity despite having serious impacts on a person's mind.58 65. While the right to bodily integrity may protect the mind fr om interference from some neurotechnology, it is unlikely it could extend to other forms of the technology such as non -implant able BCIs which are non -invasive in nature. 66. Unlike the right to mental privacy, the right to mental integrity has been recognised by various human rights instruments. 67. Article 17 of the Convention on the Rights of Persons with Disabilities ( CRPD ) states t hat: Every person with disabilities has a right to respect for his or her physical and mental integrity on an equal basis with others . Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 16 68. Further , article 5(1) of the ACHR states: Every person has the right to have his physical, mental, and moral integrity re spected. 69. Articl e 8 of the ECHR states: Everyone has the right to respect for his private and family life, his home and his correspondence. There shall be no interference by a public authority with the exercise of this right except such as is in accordance with the law an d is necessary in a democratic society in the interests of national security, public safety or the economic well -being of the country, for the prevention of disorder or crime, for the protection of health or morals, or for the protection of the rights and freedoms of others. 70. Jurisprudence of the European Court of Human Rights has recognised the right to mental integrity alongside the right to bodily integrity within article 8 of the ECHR.59 71. The Charter of Fundamental Rights of the European Union (CFR ) article 3(1) states: Everyone has the right to respect for his or her physical and mental integrity.60 72. Despite being recognised by multiple instruments, the exact scope of the right is unclear. However, the EU Network of Independent Experts on Fund amental Rights (set up by the European Commission ) has determined that the right to mental integrity pursuant to article 3(1) CFR is a broad right.61 4.5 What is c ognitive liberty ? 73. While the right to mental privacy may better protect the inspection and access o f the mind, the right to cognitive liberty seeks to protect mental states from influence and interference.62 74. Although the exact parameters of cognitive liberty are often contested, Bublitz claims the right comprises of two fundamental and interrelated principles: the right of individuals to freely use emerging neurotechnologies the protection of individu als from coercive or unconsented use of such technologies .63 75. Effectively the right to cognitive liberty contains both positive and negative freedoms. It cont ains a negative right to be free from external coercive Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 17 control or interference - while also including a positive right to freely control one's own brain .64 76. Currently there are no express rights to cognitive liberty in human rights instruments or at law. Ho wever, it may receive some protection under the human right to : Freedom of thought Freedom of expression Self-determination . 5 Australia's response to neurotechnology Has your country taken any policy action or initiative in relation to neurotechnology and human rights at the national level? 77. The Australian government has taken limited policy action or initiative directly associated with the regulation of neurotechnology as an emerging technolo gy. 78. There are also no Australian institutional responses to th e human rights implications of neurotechnologies.65 This has led to criticism of Australia's responses to human rights and neurotechnology as being under -theorised and lacking a response form regulatory or human rights institutions.66 79. The Commission's Human Rights and Scrutiny Team is considering a project which seeks to address neurotechnology and human rights . This project would active ly consult with relevant st akeholder s, as recommended by UNESCO and scholars .67 80. Broadly speaking the outcome of such a projec t will be to produce a final report on human rights and neurotechnology - including recommendations to best protect human rights in the neurotechnology field. 6 Australia's neurotechnology market Is there any actor in the public or private sector developing this kind of technology in your country? 81. With one in eight people living with a neurological disorder,68 it is unsurprising that from 2014 to 2021 there has been a 700% increase in neurotechnology investment globally .69 The broad range of potential applicat ions of neurotechnology increases its viability as an investment option . Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 18 82. The UK ICO cites the Regulatory Horizons Council 's prediction that the neurotechnology market as a whole could be valued at $17.1 billion USD by 2026 , with the largest segments being neuromodulation, neuroprosthesis and neurosensing.70 6.1 Public sector neurotechnology organisations 83. Many g overnments are investing heavily in neurotechnologies as organisations race to innovate, scale and secure market share. The industry is greatly assisted by govern ment initiatives such as the U S government's BRAIN Initiative and the Human Brain Project by the E U, which will contribute $6.6 billion USD and \u20ac1.19 billion respectively.71 Further : China will invest $1 billion USD until 2030 in the China Brain Project72 Japan will invest 40 billion JPY in its Brain Initiative73 Canada invest ed 267 million CAD in the Canad a Brain Research Fund in 202174 the UK invested 98 million E UROS between 2011 and 2020.75 84. According to Grand View Research , the global market size of BCIs (excluding BRAIN Initiatives) was valued at $1.52 billion USD in 2021, and expected to grow at a compou nd annual growth rate of 17.16%.76 Based on this data, the NeuroRights Foundation has estimated an expected market value of $3.93 billion by 2027.77 85. The Australian federal government recently announced its first National Quantum Strategy , which will see investment of $101 million AUD in the responsible development of Australia's quantum and artificial intelligence industries.78 This will work in tandem with the federal government 's $15 billion AUD National Reconstruction Fund which aims to finance projects which will transform Australia's indus try and economy.79 One of the priority fund ing areas is noted as being medical science , however it should be noted that there is no identifiable tied funding for neurotechnology government initiatives . 86. From 2016 to Private sector neurotechnology organisations 87. There has also been significant investment and market value in private companies. According to NeuroTech Analytics' recent report, investment in neurotechnology compani es has incre ased from $331 million USD to $7.3 Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 19 billion USD over just 10 years.81 The current overall investment in neurotechnology companies now sits at $33.2 billion USD , indicating its meteoric expansion and ease in attracting significant capital.82 Of 1,4 00 existin g neurotechnology companies, most of them are located in the US (50%) and Europe and the UK (35%).83 88. The top five BCI companies by total investments as of 2021, according to NeuroTech Analytics are: Neuralink - $363 million USD Synchron - $130 mil lion USD Kernel - $107 million USD Paradromics - $58.3 million USD Blackrock Neurotech - $10 million USD .84 89. Four of the above five companies are based in the U S. 6.3 Synchron 90. Synchron is an Australian company. It works on implantable BCI devices and is an end ovascular BC I leader .85 Synchron is developing the 'Stentrode' which can be inserted into the brain via blood vessels and used for controlling computers and treating neurological disorders such as paralysis.86 91. In July 2022 Synchron was the first to utilise a n endovascular BCI approach in the U.S. after successfu l implantation. This will have significant implications for the scalability of BCIs as this approach does not require open -brain surgery.87 92. The technology's assessments measures the i mpact of tasks such as: texting emailing online shopping accessing telehealth services ability to live independently.88 93. There are other neurotechnology organisations in the country , with Australia being placed in the top 10 countries world -wide in terms of the number of neurotechnology organisations.89 One other example is Omniscient Neurotechnology which is currently working on personalised brain maps to better understand neurological disease, mental health an d brain potential.90 Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 20 7 Awareness of Neurotechnology Indicate your level of awareness (high/medium/low) in relation to the state of development of neurotechnologies and preparedness to tackle the challenges posed by the early commercialization of these tech nologies. 94. The Commission's level of awareness of neurotechnologic al development is high - as is its preparedness to engage with the human rights challenges of the technology itself. 95. Australian Human Rights Commission President, Emeritus Professor Rosalind Croucher AM, spoke at 'Neurotechnology and the Law Forum ' on 0 1 December 2022 and again at 'Buzzwords: Neurotechn ology ' on 29 March 2023 about the human rights implications of neurotechnology. 96. Australian Human Rights Commissioner, Lorraine Finlay, spoke at ' HELP (Human Rights, Ethics, Law and Policy) ' on 17 May 2023 on human rights law and neurotechnology. Commissioner Finlay was also quoted in a recent article noting the profoundly positive imp acts of neurotechnology, and calling for caution given the potential human rights risks .91 97. The Commission also ran consultati ons with key stakeholders (as discussed above at [ 2]) to inform its position for this submission. 98. The Human Rights and Scrutiny Team within the Commission is seeking to develop a key project on human rights and neurotechnology in the coming years. This project is still in the development phase and subject to funding. 99. The Commission has expertise in assessing and mitigating the human rights risks of new and emerging technologies as part of its Technology and Human Rights portfolio . 8 Human rights impacted by neurotechnology What human rights will be mostly impacted by the development and use of neurotechnologies? Identify the three rights most impacted and briefly explain why. 100. A key theme in the discourse on human rights and neurotechnology is whether it is b etter to understand human rights risks in respect of existing human rights (which ma y not be fit for purpose) or under new neurorights.92 For the purpose of answering this question, the focus has been in respect of existing rights. However there must be mo re considered engagement on the question of whether to introduce novel neurorights. T his is especially Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 21 important as it is still unclear on how exactly the technology could undermine human rights.93 101. Although there is a diversity of rights which will be impa cted, for the purposes of answering the questionnaire we have limited our discussion t o just three existing human rights - noting that neurorights are not currently human rights enshrined in international instruments. 8.1 Right to p rivacy 102. The boundary between the external world and one's internal mental cognition has traditionally been an impe netrable one. Mental privacy is the last true bastion of protected information which is secret to ourselves. However, neurotechnologies challenge this. Unchallengeable statements about internal thoughts and feelings such as ' that's how I feel' can now be analysed, examined and tested.94 103. This ability to examine brain data and determine private thoughts, feelings and behaviours places human rights at risk. The right to privacy is a cornerstone human right. As noted by the Office of the Australian Information Commissioner (OAIC), it also und erpins freedoms of association, thought and expression, as well as freedom from discrimination.95 104. The right to privacy developed over centuries. For example, in the fourth century B CE, Aristotle drew the distinction between t he public sphere of politics and the private sphere of domestic life. Thousands of years later, the 'fourth industrial revolution' is characterised by rapid technological development. These changes have arguably reinforced the central importance of the rig ht to privacy. 105. The right to p rivacy in respect of neurotechnology has become of such interest that even the UK ICO recently published its paper ICO Tech F utures: Neurotechnology on the risk to privacy. 106. It is due to the unprecedented ability to challenge internal thoughts that brain data is more sensitive and valuable than all other categories of personal data.96 The collection of brain data will make it po ssible to track, analyse and predict the actions and attitudes of individuals about anything from political leaning, sexual orientation or health status.97 The risk to privacy is of the utmost concern in respect of brain data due to its implied use. 107. Neurote chnology products will record vast quantities and varieties of mental data which may be accessed without genuine consent .98 There are already issues about individuals 'giving away' their online personal data to third parties through collection notices. Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 22 108. The usage of such neuro data could range from marketing companies using 'nudging' techniques to steer users towards certain products, employers seeking to mon itor employee concentration in the workplace or even schools seeking to ensure children are paying att ention and learning in class. The risks become more drastic when considering the usage of brain data by governments - especially those with poor human rig hts records. 109. It is possible that the decoding of brain data will one day be able to reveal informatio n such as (for example) someone's sexual orientation, leading to possible discrimination and prejudicial treatment.99 There has already been research claiming that computer -vision algorithms could predict sexuality from a single image of a person's face.100 It is also possible that other personal information such as political affiliations or religious commitments could also be inferred from neurotechnologies in coordination with other technologi es - however sexual orientation is used as an example of the risks below . 110. The 2020 update of the Global Legislation Overview of the State -Sponsored Homophobia Report concluded that there were 67 Member States with provisions criminalising consensual same -sex conduct, and six UN Member States that continue to impose the death penalty for consensual same -sex conduct.101 This is in addition to the many countries where individuals continue to face persecution and violence on a daily basis becaus e of their sexual orientation or gender identity. 111. If mental privacy is not protect ed, the technology could lead to a widespread abil ity to identify, isolate and even kill people based on an assessment of their sexual orientation . 112. Even if such neurotechnologies are developed, the inaccuracy of such neurological tools do es not reduce the risk of persecution and violence against individuals who might be targeted by this technology - whether on the basis of sexual orientation or other characteristics. 113. Although the collection, maintenance and usage of brain data raises ethical questions in i solation , the Commission has concern s about how this information will be used in tandem with other forms of personal data. For example, the gathering of seemingly s mall and innocuous pieces of personal data (browser history, biometric information etc) can, accumulatively, provide a detailed profile of an individual - dubbed the 'mosaic effect'.102 114. Many wearable devices , such as smart watches, now record bodily functio ns and are openly accepted by consumers. While this allows for the collection of information such as heart rate, geolocation and movement , with Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 23 the inclusion of brain data, this will allow sensitive personal information to be extracted or inferred about a person on an unprecedented scale.103 115. Article 12 UDHR states: No one shall be subjected to arbit rary interference with his privacy, family, home or correspondence, nor to attacks upon his honor and reputation. Everyone has the right to the protection of the law against such interference or attacks. 116. Similarly , article 17 ICCPR states: No one shall be subjected to arbitrary or unlawful interference with his privacy, family, home or correspondence, nor to unlawful attac ks on his honour and reputation. Everyone has the right to the protection of the law against such interference or attacks. 117. Despite the im portance of private brain data in making us who we are, article 17 is silent o n mental privacy. 118. The right to privacy is also protected in many other international instruments.104 The UN Human Rights Council also indicates that privacy is of increasing impor tance in a digital age where: digital tools can be turned against them, exposing them to new forms of monitoring, profiling and control.105 119. Mental privacy will be of ever -increa sing concern as neurotechnologies improve , and organisations and government are b etter able to commercialise the collection, maintenance and usage of brain data. 120. When considering brain data, a privacy model which places the onus on individuals to be respo nsible for the protection of their data, and to make informed decisions , is insuf ficient due to the heightened importance of that information. 121. The Commission's concern is predicated upon several matters: the 'privacy paradox' lack of competition/alternati ves which are more data secure the illusion of choice power imbalances. 122. The 'priv acy paradox' refers to the phenomenon that, despite understanding the privacy risks of a product or service, there is no obvious influence upon an individual's behaviour.106 Namely, individuals will still engage with privacy -adverse products and services eve n where they are Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 24 highly aware of the risks. This does not mean that individuals do not care about their privacy. For example, 74% of individuals have safety concerns in relat ion to being targeted by products or services.107 A further 76% consider it is unfai r when personal information is used to make predictions about them, while a further 85% consider it is unfair or very unfair for their personal information to be shared with other companies.108 It is possible that with the usage of neurotechnology these rate s of concern would only increase. 123. Furthermore, even where individuals do not genuinely understand how their data is being used, people will still disapprove of its misuse. Individuals have been shown to have a very strong negative reaction when confronted with the difference between: how their data is actually being used their perception of how it is being used.109 124. This is particularly the case where the difference becomes explicit and too contrasting.110 Many consumers willingly shared data on Facebook, howev er when the use of that data by Cambridge Analytica came to light , there was public outcry, with Facebook being required to appear at hearings before both the U S congress and U K Parliament.111 125. Despite being aware of the risks, and disapproving of those risks to privacy, individuals are often unwilling, or unable, to stop using appliances or services which threaten their privacy.112 This is especially so in respect of implantable BCIs which are invasive and dif ficult to remove - often requiring medical intervent ion, such as brain surgery. 126. This reluctance, or inability, to avoid products or services which threaten privacy may be partly in response to a lack of effective competition or alternative. The A ustralia n Competition and Consumer Commission has previously found that a lack of competition and unavailability of reasonable alternatives (which may better protect privacy) can lead consumers to accept undesirable terms of use.113 In addition, terms of use may be provided on a 'take -it-or-leave -it' basis across int errelated services which potentially leads to excessive data collection inconsistent with the wishes of the individual consumer.114 127. This affords individuals very little ability to 'choose' neurotechnolog y services and products which enable mental augmentati on for consumer or medical reasons without risking privacy. It is also an unfair to ask someone with disability to 'choose' between their privacy and possibly lifechanging products. Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 25 128. The traditional mode l of privacy regulation places great emphasis on infor med 'choice' as an effective safeguard for data and privacy.115 However, the privacy paradox and numerous behavioural studies demonstrate that placing the onus on individuals to protect their own data is insufficient.116 129. Such a model also does not acknowledge the substantial power difference between large companies and individual consumers - especially where mental augmentation will vastly improve quality of life for consumers or patients . Even where an i ndividual understands how their data will be used, this power imbalance remains, as 'one party controls the design of applications and the other must operate within that design'.117 130. The privacy paradox, illusion of choice and power imbalances may all contr ibute to individuals being unable to utilise neurotechnol ogy without relinquishing their privacy. 131. The Consumer Policy Research Centre in its In whose interest? Why businesses need to keep consumers safe and treat their data with care (Working Paper) put f orward two alternative approaches to protecting data in Australia - which may have global application. 132. The Working Paper canvasses the creation of a duty of care or best -interest duty, which would operate s imilarly to fiduciary duties in the finance secto r to hold businesses accountable for how they collect, share and use consumer data.118 133. The Working Paper also advocates for a : Privacy Safety Regime which utilises concepts from product intervention powers and product safety interventions, proposing option s that would allow governments and regulators to stop or limit obviously harmful uses of data as well as a process for regulators to proactively restrict and test new harmful practices a s they evolve.119 134. While the Working Paper is specific to Australia and d oes not discuss neurotechnology, the Commission would call upon the Human Rights Council to consider how similar models may be applicable, or could be adapted, to inform the better prot ection of brain data globally. 8.2 Freedom of thought, conscience and relig ion or belief 135. Neurotechnology will potentially challenge what it means to have freedom of thought and agency over our own lives. As discussed above at [ 30] BCIs can be used to override the thoughts and actions o f laboratory mice. The application of neurotechnologies goes further and has the potential to Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 26 decipher and alter perceptions, behaviours, emotions, cognition and memory - all fundamental aspects of what make s us who we are.120 136. This will allow the technology to one day man ipulate people's beliefs, motivations and desires.121 This has led to disquiet about the possibility of unique forms of sophisticated mind control - highlighting the need to better protect freedom of thought. As is rightly noted by UNESCO when discussing freedom of thought in this context: It is noteworthy that freedom of thought is not to be understood here merely in the traditional sense that people should be free to express their opinions or beliefs ( forum externum ), but in the literal sense of the freedo m to think by themselves without being monitored by others (forum internum ).122 137. Not all neurological manipulation will be negative , as patients experiencing treatment -resistant depression can now be treated using deep brain stimulation technique s (similarly to those used for Parkinson's disease). For example, treatment of this sort has led to severely depressed patients exhibiting a signi ficant improvement in depression symptoms.123 138. While there is a well -articulated field of discourse on the freedo m of thought, it is unclear if consideration has been given expressly to neurotechnology.124 139. Article 18 (1)-(2) ICCPR state : Everyone shall have the right to freedom of thought, conscience and religion. This right shall include freedom to have or to adopt a religion or belief of his choice, and freedom, either individually or in community with others and in public or private, to manifest his religi on or belief in worship, observance, practice and teaching. No one shall be subject to coercion which would impai r his freedom to have or to adopt a religion or belief of his choice. 140. Despite article 18(2) expressly stating that a person shall not b e subject to coercion which impedes their ability to adopt a belief , there is no mention in the General Comment on Articl e 18 that would consider this in respect of neurological interference to coerce a decision - nor any mention of technological means of doing so.125 141. With an increasing understanding of the brain , it is possible that neurotechnologies in coordination with oth er technology (geotracking, data gathering etc) may be capable of not only coercing or manipulating a person's decisions but also discerning their internal thoughts o r beliefs . It is Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 27 concerning that , despite the protection in Article 18 , this could lead to persecution based on a person's belief. 8.3 Right to equality and non-discrimination 142. In addition to the rights above, there is significant speculati on on how neurotechnology may deepen social and economic divides in a way that violates the right to equality and non -discrimination. 143. Particularly, article 25 UDHR stipulates : everyone has the right to a s tandard of living adequate for the health and well -being of himself and of his family 144. Article 2 also s tates: everyone is entitled to all the rights and freedo ms ... without distinction of any kind such as race, colour, sex, language, religion, political or other opinion, national or social origin, property, birth or other status. 145. To prevent deepening inequality , the right to equal access to mental augmentation has been proposed by NeuroRights Foundation and the Neurotechnology Ethics taskforce.126 146. While neurotechnology can restore and improve brain function , these products may well be expensive and limited only to those who can afford it.127 This may result in peop le from lower socioeconomic areas or developing countries being unable to access life changing medical care and enhancements. 147. As neurotechnology continues to be integrated into society, wage disparity may deepen the equity gaps in society. The exact cost o f neurotechnology products is currently hard to ascertai n. As an example, it has costed roughly $40,000 USD for some users to replace an ATI-made neurostimulator implant that was rendered obsolete after an implanting company shut down , and its software was no longer accessible .128 148. Inherent bias created by the cost of technology may cause companies to operate under a social media business model , that allows free services in exchange for collection and use of data. Neurotechnology companies may advertise d iscou nted products if customers consent for them to use their brain data. This is a dangerous possibility that means already vulnerable communities may be faced with making decision s to effectively compromise their right to privacy in order to access beneficial technology . 149. If lower socioeconomic groups are priced out of neurotechnolog ical products and services , the data collected and any future changes made Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 28 based on this data , will be biased. Because medical intervention with neurotechnology is very new, it is r easonable to bel ieve that reforms and upgrades will be made to the technology predicated on this biased data - which favours those who can afford the relevant products or services . The inherent problem is that changes will be made to suit the demographic o f data that is b eing collected and will disenfranchise those not yet engaging with neurotechnology. Harvard Researchers have discussed how algorithmic bias will be evident in any form of AI as it impacts medical data.129 Bias must be acknowledged and mitigat ed to ens ure that it does not 'exclude, oppress or denigrate' vulnerable populations. 150. The UK ICO raise s the prospect that data will be largely harvested from neurotypical people, leaving neurodivergent customers with potentially biased and ill -equipped products.130 Discrimination may also take place if devices are not trialled on varied and numerous groups of people.131 151. Regulations should be in place to ensure that researchers and companies are actively working against inputting any bias in to future produc ts, services or upgrades . This can be done by ensuring there is regular discussion about possible biases in data collection and that researchers are from diverse background and are aware of potential data bias. 9 Greater regulation for consumer markets What are the biggest challen ges and risks that the development, test and use of neurotechnologies pose to human rights? Will such risks be amplified by the development of consumer -oriented neurotechnologies? 152. Some of the biggest risks of neurotechnology will be rea lised as products are developed and deployed outside of therapeutic and medical fields and provided to consumers more broadly. The medical appl ications of neurotechnologies are quite stringently regulated in Australia and other countries, however consumer products operate in an environment largely free of the types of targeted regulation or guardrails that are seen in the therapeutic and medical contexts. 153. The Commission is concerned by how consumer -oriented BCIs, especially non-implantable BCIs, are not su fficiently regulated. Unlike implantable BCIs or those with medical applications, consumer products operate in an insufficient regulatory envi ronment.132 154. There are already regulations in Australia for development, testing and use of neurotechnologies in medi cal applications (see [ 13.1 ]). Human rights risks Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 29 are li kely to be amplified as neurotechnologies are adapted for broader consumer consumption without the same level of regulation in place. 155. Neurotechnolog ical intellectual prop erty, which is developed for medical application, can be pivoted and adapted to a consumer market. For example , while some BCIs allow users who are paralysed to operate computers , it isn't difficult to imagine this same technology being sold to gamers for hands -free gaming. 156. While the risks of prod ucts which are purely consumer -oriented are troubling, attention must also be paid to medical products which will be adapted for consumer products. Large -scale neurotechnological products will likely become common place in the not -so-distant future. For example, Neuralink just won appro val on 26 May 2023 from the US Food and Drugs Administration (FDA) to conduct its first tests on humans.133 Although Neuralink 's products may have aims to assist patients , it is possibl e this technology may also be pivoted to a consumer market in the futu re. 157. Irrespective of how the technology makes its way to consumers, neurotechnologies are becoming increasingly available for direct -to- consumer products for recreational or mental augme ntation purposes.134 Without the rigorous safeguards in place for medical purposes the effects of these consumer products remain unclear. 158. For example, non-invasive BCI products are rapidly proliferating outside of a regulated environment. Although non -invasi ve BCIs will often b e used for similar purposes as invasive BCIs, because they do not require medical implantation they often fall outside of medical regulation in consumer settings.135 This is especially true for neurostimulation commercial devices using TM S or transcranial d irect current stimulation for which the effects are not fully understood - possibly causing adverse consequences for users.136 159. One risk to consumers is where neurological products overpromise on their capability to improve health and wellb eing , which can lead to negative outcomes for consumers, especially where the BCI is implant ed. Further, the risks and obstacles of products must not be underestimated or this too will lead to adverse outcomes.137 160. Equally , brain data collected by consumer pr oducts could be monetised and exploited by companies , employers or governments. The combination of brain data and other personal data collected online ( from web browsing, smart phones, smart watched etc) might allo w certain brain characteristics to be iden tified such as attention or vigilance.138 This may lead to 'neurotype' profiles being created about users to allow for 'neuromarketing' or other exploitative tailored digital targeting.139 While the use of such infor mation for Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 30 marketing is problematic, if take n a step further it becomes disturbing. For example, t he use of such information may allow political parties to better manipulate voters with highly personalised messaging . Moreover, this data could be used to identify individuals based on certain characte ristics, such as the example of sexual orientation outlined above , leading to discrimination by certain state and non -state actors. 161. Furthermore the implantation of non -therapeutic inv asive neurotechnology involving a medical procedure (e .g. surgery to inse rt an implant into the brain) will require the surgeon to obtain informed consent regarding the procedure to insert the device, but not the operation and terms and conditions relating to the device once it has been implanted. There are a number of risks th at consumers will need to be aware of in deciding to implant a device - including service life, the availability of spare parts, what will happen if the company responsible for the de vice has been deregistered. Concerns arise that significant decisions suc h as this ought not be left to boilerplate contracts with fine print terms . 162. The regulatory gap between medical and consumer neurotechnological products must be addressed. The intro duction of consumer protection regulations and laws across the globe must be ready for a wave of neurotechnological products in the future. 163. Consideration should be given to the creation of, or improved resourcing of, a Therapeutic Goods Administration (as discussed below at [ 13.1 ]) style government bo dy to : assess and ensure the safety of non -therapeutic neurotechnology ensure that entities selling neurotechnology are appropriately insured and/or have the financial means to compensate consumers oversee a government 'safety net' fund to assist and prote ct consumers when the companies responsible for legacy technology are no longer around to remove legacy technology o r replace parts implement information standards relating to neurotechnology (potentially adopting an informed consent model for the level of information and warnings consumers can expect when purchasing neurotechnology for non -therapeutic uses). 164. Without sufficient regulations in place, it is likely that countries will fall into the same cycle of failing to regulate proactively and then have to play catch - up as people experience harm . Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 31 10 Vulnerable groups What groups are more vulnerable or at risk? Please, identify three and explain why. 165. Given the complex and interdisciplinary application of neurotechnology, it is both difficult and problematic t o identify just three groups that are more vulnerable to risk. However, given the structure of the questionnaire we have limited our response to our areas of expertise and which reflect matters discussed during consultation. 10.1 People with disability 166. It is es timated that approximately 4.4 million Australians have a disability.140 Substance abuse and neurological disorders account for more than 10% of the global disease burden - with the two most common mental disorders being anxiety and depression.141 However neur otechnology offers greater possibility to treat and prevent many of these conditions . 10.1.1 Benefits 167. There are numerous positive examples of neurotechnologies being used to improve the lives of people with disability. This submission will briefly summari se just some examples to highlight how impactful the technology can be. 168. In one instance , neurotechnology has been used to restore the vision of a user who had been completely unable to see for over 16 years, allowing them to discern shapes and letters agai n.142 Similarly, cochlear implants have also been used to restore functional hearing to an estimated 1 million people world wide.143 169. People suffering from paralysis are experiencing quality of life improvements thanks to neurotechnology. The technology has been developed to allow devices to decode speech from brain activity , allowing people to communicate with the external world again.144 170. One res earch participant and recipient of a neurotechnological product , Mr Copeland, demonstrates the potential of the technol ogy. Mr Copeland was left a paraplegic after a car accident. He has since become the first person to control a robotic arm and recover his sensations of touch though brain implantation in the cortex of the brain.145 Mr Copeland described the neuroprosethetic as Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 32 very intuitive to co ntrol, ... I don't have to strain, it really is just as easy as thinking move and grasp; so in that way, it is kind of an extension of myself, but I also see it as a tool that I'm controlling that is separate from myself .146 171. This has allowed Mr Copeland to play video games, fight in a 'lightsabre' duel and even shake hands with former President Barack Obama.147 172. Neurotechnology can also led to greater understanding of how memories are stored. This has led to neurotechnologies capable of i mproving memory performance by up to 20%.148 For patients suffering conditions such as Alzheimer's disease, stroke or head injuries, this is a promising treatment. 173. It is due to these profound capabilities of neurotechnologies t hat people with disability are most at risk to the harms of the technology. When faced with the opportunity to treat previously untreatable conditions or regain dignity and quality of life it is hard to imagine that few will say 'no'. This inherently creat es a power imbalance between pe ople with disability seeking treatment or improvement of life and those that develop , deplo y and maintain the products. Such imbalances raise further questions . 10.1.2 Risks 174. Despite the potentially positive impacts for people with disability, several pertinent risks arise which must be questioned when engaging with the technology. What processes are in place to ensure that neurotechnology users, who often receive implantable BCIs, are supported for t he life of the device? How will updates be transmitted to the implanted BCI? What will happen to BCIs as they become replaced by more advanced BCIs ? How can users be protected in the event of a neurotech comp any's dissolution? Can genuine informed consent be obtained? 175. The physical health risks of implantable BCI s are well noted and physical harms are already being realised. One example is Second Sight, which provided visually impaired users with a form of a rtificial vision to help them see again.149 With over 350 patients globally , this neurotechnology profoundly assisted many people. However , in 2019 -2020 Second Sight discontinued its product and nearly went insolvent. This resulted in some users literally having their implants 'turned off' as their artificial vision went dark. While some report that the implants s till work, at this stage there is little indication that users can have the technology fixed if it malfunctions.150 176. Difficulties may also arise whe n an implantable device is removed. NeuroVista was a company which made a device which signalled to users when an epileptic fit was about to occur , allowing users to take measures to avoid or minimise it.151 In 2013 , NeuroVista ran out of money and began Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 33 forcibly removing the implantable device s. One user spoke of her sense of deep trauma and grieving after having t he device forcibly removed , claiming she would have done anything to keep it - she even attempted to re - mortgage her house to buy the dev ice to evade removal .152 The device had allowed her to live confidently and happily , but after its removal she stated: I have never again felt as safe and secure ... nor am I the happy, outgoing, confident woman I was ... I still get emotional thinking and talking about my device ... I'm missing and it's missing.153 177. The removal , decommissioning or end of life of an invasive BCI rais es issues under article 25 CRPD to the enjoyment of the highest attainable standard of health rights - especially where removal results in disability or physical or mental injury returning or being experienced. 178. A key difficulty highlighted here is that ne urotechnology users require significant and continued support for the life of the device , irrespective of the economic viability of the product itself. This may leave people to fend for themselves if they are left with redundant technology in their heads w ith little means of seeking remittance or support. 179. One option may be to create an independent body, entirely funded by neurotechnology companies . This body could continue to provide support for users for the life of a product so that users are not left be hind when a particular product is no longer profitable. Another option may be to ensure interoperability of neurotechnologies to allow for continued maintenance and support across organisations . 180. It should also be noted that given the impact neurotechnolog ies will have on people with disability , they should be actively involved in the design and deployment of the technology alongside continuing governance processes. 10.1.3 Informed consent and impaired decision making 181. Article 12 CRPD recognises that people with disability enjoy legal capacity on an equal basis with others in all aspects of life. Article 12 directs State Parties to ensure that all measures relating to the exercise of decision - making capacity provide for appropriate, eff ective and necessary s afeguards. It is critical that this be applied in the context of neurotechnological treatments . 182. International tr eaty bodies and experts, such as Special Rapporteurs, continue to recommend targeted and concrete measures to reduce and eliminate medical coer cion and forced psychiatric treatment. It is imperative that the provision of neurotechnological treatments alig n with human rights obligations. Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 34 183. Generally speaking , inappropriate expectations about a product or device have been identified as a genuine impa irment to informed consent.154 Users of BCIs may also have pre -existing cognitive impairment which can adversely impact their ability to provide initial and continuing informed consent - more concerning is the proposition that by way of the implantation proc ess, associated cognitive changes may disru pt such informed consent processes.155 A person should be supported to make informed decisions , consistent with article 12 . 184. In the exercise of informed consent, power asymmetries at play in the context of medical d ecision -making need to be addressed.156 Pow er imbalances undermine users as passive recipients of care instead of active right holders. 185. Informed consent is especially important as it allows people to choose whether or not to engage with neurotechnology. Any such consent may be illusory when people with disability must make a choice that is starkly binary : consent to the conditions set or do not receive the technology. There will likely be many people who are considered to be 'neurodivergent' who rightly do no t consider neurological treatment via BCIs necessary or desirable. It is of the utmost importance that the medical profession respects the needs and desires of all people and do not force neurological devices onto people. 186. In addition to being provid ed wit h the necessary supports in decision - making , any treatment provided to people with disability/mental health disorders should align with a recover y-based model and preferably be provided in a community sett ing. The Special Rapporteur on Health recommended c oncerted efforts continue to be exercised globally to shift mental health care away from the predominant medical model.157 187. People with disability must not be assumed to lack decision -making ability on the basis of having a disability. All people should be pr ovided with the appropriate supports to exercise their legal capacity , and a person's decision - making ability must be considered in the context of a vailable supports. In practice, this would mean that a person is considered to have decision - making capacity if they can exercise that capacity with the provision of supports. Supported decision -making is encouraged to support people with disability to mak e, communicate and participate in decisions that affect their lives.158 188. Given the risks associated with inform ed and impaired decision -making , stringent risk assessments must be conducted before any implantation . Surgery must not be performed unless an individual is completely and undoubtedly aware of all possible consequences of implantation. Legislation relating to the exercise of decision -maki ng capacity in the context of Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 35 treatment provision must include the necessary safeguards . Where possible less invasive means of implantation should be utilised , such as endovascular implantation, where the same goals can be achieved. 10.2 Young people and children 189. Young people and children may be especially vulnerable to any side effects of long -term use of neurotechnologies as their minds are still developing . Although such side effec ts are unknown, if they exist at all, the best interests of children must be central to any use of neurotechnology (in alignment with article 3 of the Convention on the Rights of the Child (CRC) ). This is especially urgent as neurotechnologies are already being used by children and young people. 10.2.1 Education 190. Neurotechnologies may be used in the education sector in the hope that academic performance can be improved . 191. Primary school children in China were being required to wear non - implantable BCI headsets which record concentration levels du ring class.159 The collected brain data was stored on a teacher's computer and was later shared with parents without the child's consent.160 192. The UK ICO notes that there is increasing interest in the use of neurotechnology in the education sector. It further notes t he likelihood in the long -term (five to seven years) of the higher education sector using BCIs to monitor student concentration and stress levels and to further improve cognitive process es to boost student performance.161 193. Education is not the only applicatio n of neurotechnology for children. Virtual and augmented reality systems can also be supported by brain control for entertainment purposes.162 With the risk of metaverse and extended reality technologies, it can be expected that the interaction of children w ith neurotechnologies will only increase. 10.2. 2 Metaverse 194. New and emerging technologies (such as the metaverse) provide organisations with increased opportunities to accumul ate and utilise the personal information of children - including brain data.163 The risk of privacy and security invasions for children and young people in the metaverse (inherited from underlying technologies or emerging from the new digital ecology) may be prolific.164 Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 36 195. In the metaverse, children and young people face a wide range of priva cy intrusions and security risks, including: the management of massive data streams pervasive user profiling activities unfair outcomes o f AI algorithms safety of physical infrastructures and human bodies.165 196. The personal data involved in the metaverse will likely be 'more granular and unprecedentedly ubiquitous to build a digital copy of the real world'.166 This especially the case a s metaverse technologies collect and process data such as brain wave patterns .167 197. It is likely that there will be an increase in t he use of neurotechnology to connect brain waves to gaming and metaverse experiences to allow for immersive experiences for use rs.168 198. The UK ICO has noted that neurotechnology is being used for games which allow players to operate drones remotely via neurot echnology.169 It is expected that there will be greater uptake of such technology for gaming in the medium term (four to five years) , with more significant uptake in the use of neurotechnology of modulating technologies aimed at gaming.170 10.2. 3 The rights of children 199. Online privacy and safety measures in respect of neurotechnology should be developed in accordance with article 3 CRC, which requires that the 'best interests' of the child be a primary consideration in all actions concerning them. This is one of the four guiding principles of the CRC and should be a primary consideration in the digital environment.171 200. When considering the best interests of the child, regard should be had to 'all children's rights, including their right to seek, receive and impart information, to be protected from harm and to have their views given due weight' in addition to ensuring transparency over the criteria applied to determine best interests.172 Where rights are limited to protect children from online harms, limitations must be lawful, necessary and proportionate. Maximising children's privacy and securing their person al data is itself a 'crucial means of acting in their best interests'.173 201. Children's privacy should not be construed narrowly as relating only to data protection measures, and should recognise the importance of children's autonomy and choice over their private lives. A best interests approach may require implementing clear bound aries to prevent practices that both infringe upon children's rights and are contrary to their best interests, Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 37 including by curtailing routine and indiscriminate digital surveillance measures.174 10.2. 4 Neuromarketing and children 202. The rise of targeted mark eting and the negative impacts such advertising can have on children is well reported - such as increasing problems such as obesity, early alcohol consumption or smoking cigarettes or e -cigarettes.175 203. The Special Rapporteur on the right to privacy estimated that The online advertising market for children could be worth 1.7 billion by 2021, wit h more than 72 million pieces of data collected for each child by online advertising companies before the child reaches the age of 13.176 204. However, the use of neurotechnologies to collect brain data which can be sold and used by companies to advertise to children could allow microtargeted advertising on a scale and impact not yet seen, with serious effect s on children an d young people as their minds and sense of self develops. 205. General comment No. 25 (2021) on children's rights in relation to the digital environment states : Practices that rely on neuromarketing, emotional analytics, immersive advertising and advertising in virtual and augmented reality environments to promote products, applications and services should also be prohibited from engagement dire ctly or indirectly with children.177 10.3 Socioeconomic disadvantaged and marginalised groups 206. Socioeconomically disadvantaged and marginalised communities may be disproportio nately affected by neurotech nology policies due to the anticipated high price of products and services . Such expense may force those wishing to enjoy the benefits of neurotechnology to waive their rights to privacy in exchange for discounted or free products . Such a business model has operated in social media where the product /service/platfor m is free to join and use - but organisations monetise user data for profit. 207. Brain data is an especially sensitive form of personal data. While the risks of waiving one's right t o privacy online is problematic, to do so in respect of brain data may have serious and unintended consequences. The Commission is deeply concerned by any neurotechnology service or product whose business model is built on the monetisation of brain data. Such a business Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 38 model will only perpetuate existing social inequalities and ma y even create entirely new problems not yet considered. 11 Risk assessments What methods can be used to identify and assess the potential risks and impact of these technologies on human rights, in particular the human rights of persons with disabilities and o ther groups in vulnerable situations? Will such risks be amplified by the development of consumer -oriented neurotechnologies? 208. One of the most integral ways to best identify, assess and mitigate the adverse impacts of neurotechnologies is to implement a rob ust regulatory regime which covers the technology in medical, consumer and industrial settings. Any such regulation should also consider the profound ly positive impact this technology can have on people, especially those living with disab ility. Such regula tion does not necessarily have to be a barrier to innovation and can also be a key enabler .178 11.1 Human rights impact assessments 209. A key strategy of protecting human rights in the context of neurotechnologies is the effective use of human rights impact assessmen ts (HRIAs).179 A HRIA tool assesses how a new product, service, law or policy will engage human rights. They also provide a framework for ensuring adequate rights protections.180 210. HRIAs are increasingly being used by government, the private sector and civil soc iety organisations to measure the risk to human rights posed by their activities, ensure that measures are put in place to address human rights risks, and support the availability of remedies for any human ri ghts infringements.181 211. The Commission's previous work has found strong support from the public and private sectors, for the develop ment of HRIA tool s and associated guidance.182 HRIA tools will help to identify and address human rights issues at the earliest stage of the design, development and deployment of new and emerging technologies - such as neurotechnology . 212. There has already been support for the use of HRIAs in privacy se ttings and in respect of facial recognition technology (FRT) . In the Commission's recent submission to the Attorney -General 's Department on proposed reform to the Privacy Act 1988 (Cth) , the Commission provided in -principle support for the Human Technology Institute's Model Law on facial recognition technology . In Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 39 particular, the Model Law require s organisations to conduct a Facial Recognition Impact Assessment (FRI A) of the potential harms, inclu ding the potential human rights risk s. This FRIA would be registered, publicly available and could be challenged by the regulator or interested parties. 213. As the name would indicate, the FRIA is a more streamlined version of a n HRIA specific to FRT technolog ies. Privacy Impact Assessments are also becoming increasingly common place to ensure the safety of user personal information and data. 214. The Commission considers HRIA tools to be fundamental for protecting human rights in a m ore holistic way . Specifica lly, HRIA tools could address risks to people with disability and other groups in vulnerable situations. 215. It is also of note that such due diligence processes are in line with the recently updated OECD Guidelines for Mul tinational Enterprises on Responsible Business Conduct in respect of actual and potential adverse impacts related to scien ce, technology and innovation.183 11.2 Communication 216. In addition to regulation and the use of HRIAs, stro ng communications measures must be in place to communicate human rights and other risks to potential users. UNESCO notes that the following proactive communic ation measures should be followed by meeting the following steps: Introduce a fair communication/i nformation process which outlines the risks and benefits of a neurotechnology product through institutional channels where experts are directly available. Mak e available to people competent medical supervision in case of side effects . Provide honest and tr ansparent information regarding the commercial interests of large -scale diffusion of direct -to-consumer products. Provide a clear explanation of the current s tate of scientific progress in bio-enhancing techniques to mitigate misunderstandings or manipulat ion of lay people. Neurotechnologies accessing brain data should be ethically designed by default.184 Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 40 12 Reaping the benefits, while minimising the harms From a hu man rights perspective, what opportunities could the use of neurotechnologies bring? Can these op portunities be balanced against the identified risks and impact? 217. Neurotechnology has the potential to vastly improve our understanding of the human mind. This technology has already led to scientists t o actively developing treatments for conditions such a s: Alzheimer's disease schizophrenia stroke post-traumatic stress disorder depression addiction .185 218. If these treatments are effective , there are a myriad of ways in which human rights could be amplified, let alone the positive impact it would have in improving the quality of life for people experiencing mental illness or neurological disorders. 219. Research teams are also developing BCIs to allow people with paralysi s to spell words on computers and regain the control of limbs - be they organic or artificial.186 Equally neurotechnology which is able to 'read' the mind and transcribe thought into langua ge will be life -changing for those who have lost their capacity to co mmunicate or move . 220. Neurotechnologies will help to return capacity to many people, especially those with disability , enabling them to improve and enforce their human rights. Such technologies will undoubtedly improve human rights for many. However, there ar e also serious human rights risks if guardrails are not put in place. 221. To eff ectively 'balance' risks against positive outcomes it is necessary that: human rights be interpreted to apply to neurotechnologies consideration be given to the creation of a set of neurorights HRIAs be adopted by those developing and d eploying neurotechnology regulation be introduced for the medical, consumer and industrial application s of neurotechnology. Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 41 13 Is the Australian national framework adequate? Is the national legal framew ork adequate to face the challenges that the development, test and use of neurotechnologies pose to human rights? Please explain briefly and indicate the relevant pieces of legislation and whether there are plans to develop any (or further) legislation. 222. Generally speaking the brain can be protected via: international human rights law domestic constitutions ordinary domestic law a combination of the above option.187 223. When considering Australia's ordinary domestic laws, the Commission considers that the exist ing national framework is in sufficient to address the human rights challenges posed by neurotechnologies. 13.1 Therapeutic Goods Act 1989 (Cth) 224. The Therapeutic Goods Act 1989 (Cth) is federal legislation that governs products defined as therapeutic goods, whic h can include medicines, medical devices and biologicals in Australia. 225. The Therapeutic Goods Regulations 2002 (Cth) do not appear to have an y express human rights considerations and instead intend to regulate the medical device from the perspective of the physical safety of the user . 226. The Therapeutic Goods Administration (TGA) is the authority responsible for evaluating, assessing and monitoring products that are defined as therapeutic goods. The TGA regulate medicines, medical devices and biologicals to help Australians stay healthy and safe.188 However, there are non-therapeutic uses of neurotechnology which will not be governed by the Therapeutic Goods Act 1989 (Cth). 227. Neither the legislation nor regulation provide ade quate human rights protections in respect of neurotechnology - beyond medical safety standards mechanisms and obligations . Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 42 13.2 Proposed human rights act 228. The Commission has launched its Position Paper: A Human Rights Act for Australia (Position Paper) on 9 March , including a model for a federal Human Rights Act for Australia. 229. The proposed Human Rights Act model forms part of a review by the is to be reviewed by the Parliamentary Joint C ommittee on Human Rights ( PJCHR ), which accepted submissions until 01 July 2023 . It is possible that an outcome of this review will relate to the human rights risks of neurotechnology. The impact of the proposed Hu man Rights Act is discussed in greater detail from [254]. 13.3 Australian Consumer Law 230. The Australian Consumer Law ( ACL) is contained in schedule 2 of the Com petition and Consumer Act 2010 (Cth) and will likely apply to consumer neurotechnologies and the Australian Competition and Consumer Commission (ACCC) and Product Safety Australia regulate the supply of consumer goods. 231. The ACL applies to corporations and p ersons carrying on a business within a State or Territory and to 'consumer s' as defined by the Act.189 It is questionable if users paying for neurotechnologies will meet the statutory definition of 'consumer' as this often requires that they are acquiring go ods or services , the price of which is less than $40,000 AUD .190 However it is possible that neurotechnologies for consumers will naturally aim to reach a price point below $40,000 to ensure greater take up by consumers. 232. In particular the ACL provides guaran tees regarding the supply of goods in respect of (amongst others) acceptable quality and fitness for purpose which may impact consumer -oriented neurotechnologies .191 233. Acceptable quality means that a product : is safe, durable and free from defects has an acce ptable appearance and finish does everything that similar products are commonly used fo r.192 234. However there are no set rules for deciding whether a product is of acceptable quality, or how long a product should last - which is problematic when considering imp lantable BCIs which will necessarily require a longer product life. Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 43 235. To determine if a product meets acceptable quality, the following factors need to be c onsidered: What kind of product is it, and how does it compare to similar products? What is it made o f and how was it made, and how does this compare to similar products? How much did it cost, and how does it compare to products of a similar price? What ma intenance may be needed to keep the product operating? Did the business or manufacturer make any clai ms about quality, or how long the product could last for? Did the business warn the consumer about any defects, or warn against the product's use in a cert ain manner? How old is the product, and how long do similar products normally last? Was the product s old new or second -hand? Has the product been used in a way it wasn't designed for?193 236. It is likely that consumer -oriented neuroethological products would n eed to answer such questions to ensure they are of acceptable quality for consumers. 237. The fitness for pu rpose guarantee will also be important as this guarantee applies when: a consumer tells a business they want to use a product for a particular purpose the consumer buys the product based on the advice of the business the business advertises in any way that the product can be used for a particular purpose.194 238. Where a supplier fails to meet a guarantee, such as acceptable quality or fitness for purpose, the r emedy may be repair, replacement or refund and/or compensation for damages and loss.195 Obviously, replace ment parts and expertise need to be available for consumers to avail themselves of repairs. Of concern when it comes to neurotechnology is the availability of these remedies if the supplier goes into liquidation (as discussed above in re spect of people wit h disability). A consumer might be left with a degrading piece of technology in their body on which they have come to rely which may not be able to be repaired. Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 44 239. At least in theory, the remedies available under the ACL to protect consumer s appear to be adeq uate to compensate consumers in case of failure (an entitlement to repairs, spare parts, damages and consequential losses). 240. However, given the stakes when neurotechnologies are implanted into the brain, additional protections are appropriate (such as a gov ernment entity to ensure safety of products and that an entity has appropriate insurance and/or capacity to pay damages into the millions) in addition to TGA -style assessment of the efficacy of the technology ought to be undertak en before a consumer produc t may go to market. 241. The ACL also contains a product safety scheme to all consumer goods and product related services supplied in Australia. The ACCC and state and territory consumer protection agencies are responsible for monitor ing the market to detect un safe goods and identify ways to address hazards or encourage safe practices. This can be through consumer awareness campaigns, safety warning notices, product recalls, product bans or mandatory safety standards. 242. The relevant Commonwealth Minister may also make 'information standards '. Information standards require a person not to supply, offer for supply, or manufacture, possess, or have control of goods or services which do not comply with a relevant information stan dard.196 The issuing of a comprehensive in formation standard for neurotechnology is one way that neurotechnology might be regulated to protect consumers utilising non - therapeutic neurotechnology. 14 Mental privacy and personal brain data Does national legis lation on privacy and data protection cover mental privacy and/or personal brain data? Please explain. 243. The Privacy Act 1988 (Cth) is the foundational piece of privacy legislation in Australia. Currently the Privacy Act has no express protection for brain data or mental privacy. 244. However, the current definition of Personal Information and its subset class of Sensitive Information may include brain data in limited circumstances - primarily related to information about the health of individuals. A number of provisions may operate to limit the circumstan ces in which Personal Information/Sensitive Information about the health of individua ls is covered , for example in respect of certain research activities .197 245. 'Personal information ' is broadly defined within the Privacy Act as: Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 45 information or an opinion about an identified individual, or any individual who is readily identifiable: (a) whether the information or opinion is true or not; and (b) whether the information or opinion is recorded in a material form or not .198 246. Accordingly, what is considered as personal information will vary on whether the person can be identified or is reaso nably identifiable in the circumstances. Common examples of personal information are an individual's name, signature, address, telephone number, date of birth, bank account details, employment details, commentary or opinion about a person and 'sensitive information ' - which includes (amongst other things) health or genetic information.199 247. Accordingly, while not expressly referred to, the current definitions of Personal Information and Sensitive Information would appear to cover brain data obtained in a medical context. 14.1 Privacy Act 1988 (Cth) Review Report 248. The Australian Attorney -General's Department is currently undertaking a review of the Privacy Act , which would see it updated and fit -for-purpose in respect of an increasingly digitised world. 249. If certain proposals are adopted as part of this review, brain data and mental privacy may receiv e better protection by way of implication. For example, one possible amendment is to introduce a non -exhaustive, high level, principles -base d, technology -neutral list of Personal Information.200 In particular this non-exhaustive list would include: One or mo re features specific to the physical, physiological, genetic, mental, behavioural, economic, cultural or social identity or characteristics of a person .201 250. It is possible that physical, physiological, genetic, mental and/or behavioural characteristics of a p erson may extend to include brain data and protect mental privacy. While the exact language of the final list is not finalised it is plausible that this list is broad enough to capture brain data and even protect mental privacy. 251. The Attorney -General's Depa rtment review report also recommends the inclusion of a statutory tort for serious invasions of privacy202 that are intentional or reckless in the Privacy Act .203 The Commission provided input on this very issue and noted the need for the tort to include negligent acts of Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 46 privacy invasion, in addition to the need for the tort to be non -restrictive .204 It is an open questio n on how such a tort could be used to protect mental privacy and brain data. 252. The Attorney -General's Department also intends to amend the Privacy Act to require that the collection, use and disclosure of personal information must be fair and reasonable in the circumstances .205 This would require entities captured by the Privacy Act to consider the foreseeable risks to individuals caused by information handling through neurotechnology . Accordingly, this may provide a baseline protection of brain data and mental privacy . This test would also requir e consider ation of the kind, sensitivity and amount of personal information being collected, used or disclos ed and the risk of unjustified adverse impact of harm, among other considerations. 253. While the Privacy Act may not expressly protect brain data or men tal privacy , it may do so implicitly. It is expected that if proposed reforms to the Privacy Act are adopted, the protection of mental privacy and brain data may also be improved. 15 National Human Rights Act Is your national institutional framework for human rights well -equipped to address the new challenges posed by neurotechnologies? 254. Australia does not currently have a cohesive federal human rights framework. 255. However the Commission launched its Position Paper: A Human Rights Act for Australia (Position Paper) on 9 March , proposing a model for a federal Human Rights Act for Australia. 256. The Commission's model includes a legislative obligation for public authorities to act compatibly w ith the human rights expressed in the Human Rights Act (such as the right to 'privacy and reputation ' and the 'freedom of thought, conscience, religion and b elief' ) and consider human rights when making decisions.206 This is known as a 'positive duty' and co mpliance with it would be judicially reviewable. 257. The positive duty builds upon the understanding of human rights over more than 10 years of engagement in t he parliamentary scrutiny process involving statements of compatibility and review by the Parliament ary Joint Committee on Human Rights (PJCHR). 258. The requirement to give 'proper consideration' to human rights applies to making decisions and implementing legislation and policy - it is a procedural obligation. The requirement to 'act compatibly' with human rights is a Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 47 substantive obligation on public authorities. Under the proposed Human Rights Act, public authorities would also be required to engage in participation processes where the proposed 'participation duty' is relevant, as part of the 'proper consid eration' limb. Compliance with the positive d uty would be reviewable by courts (and possibly by tribunals). The positive duty would require decision makers to consider human rights at an early stage, helping to prevent breaches from occurring.207 Further det ails can be found in the Commission's Position Paper . 259. The Position Paper proposes the inclusion of an interpretive clause in the Human Rights Act stating that courts are to prefer an interpreta tion that is compatible with human rights, provided that this is consistent with the intention of Parliament, as expressed through the statute under analysis.208 This approach is consistent with, and builds on, the 'principle of legality', a common law prin ciple of statutory interpretation that presumes Parliament 'does not intend to interfere with common law rights and freedoms except by clear and unequivocal language'.209 15.1 Right to privacy 260. The proposed right to privacy and reputation outlined in the Human R ights Act states: A person has the right \u2014 (a) not to have the person's privacy, family, home or correspondence unlawfully or arbitrarily interfered with; and (b) not to have the person's reputation unlawfully attacked. Note: The right to privacy applies to the collection, processing or retention of personal data through all forms of technology, and includes state surveillance measures .210 261. This proposed right to privacy and reputation implements art icle 17 of the ICCPR (to which Australia has signed and ratified). The proposed right draws on the wording used in s 13 Victorian Charter of Human Rights and Responsibilities Act 2006 (Vic), s 25 Human Rights Act 2019 (Qld) and s 12 Human Rights Act 2004 (ACT).211 262. The 'note ' in the proposed rig ht to privacy and reputation clarifies that privacy rights extend to technological surveillance measures, noting the increased capacity of the state collect personal data and make decisions based on that data through AI.212 Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 48 263. It does not include express mention of neurotechnol ogies nor refer to the right to mental privacy. 'Personal data' is not specifically defined in the proposed Human Rights Act, but it could be interpreted to include brain data which is collected and uti lised by neurotechnology. 264. The inclusion of a right t o privacy in the proposed Human Rights Act is especially relevant given previous PJCHR findings in relation to the Committee's review of proposed legislation for compatib ility with human rights . The PJCHR's annual report sets out the most commonly listed r ights engaged by the legislation which the PJCHR examined and substantively commented on during the year. The 2020 annual report , for example, evidenced the right to privacy as the most commonly engaged with right at 28%.213 This was also true in 2021.214 Howe ver, as far back as 2016 the right to privacy has been one of the most commonly engaged right s each year.215 265. Accordingly, the proposed Human Rights Act is capable of protecting brain data, but given the rapid pace with which neurotechnologies are developing , the consideration of any future draft legislation could include whether more express references to the right to mental privacy and neurotechnology are needed . 15.2 Freedom of thought, conscience, religion and belief 266. The proposed right to privacy and reputatio n outlined in the model Human Rights Act states: Every person has the right to freedom of thought, conscience, religion and belief. This right includes \u2014 (a) the freedom to have or to adopt a religion or belief of their choice; and (b) the freedom to ma nifest their religion or belief in worship, observance, practice and teaching, either individually or as part of a community and whether in public or private. No-one may be coerced in a way that would impair their freedom to have or adopt a religion or be lief in worship, observance, practice or teaching.216 267. This proposed right implements art icle 18 of the ICCPR (to which Australia has signed and ratified). The p roposed right draws on the wording used in s 14 Victorian Charter of Human Rights and Responsibili ties Act 2006 (Vic), s 20 Human Rights Act 2019 (Qld) and s 1 4 Human Rights Act 2004 (ACT).217 Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 49 268. Freedom of thought, conscience, rel igion and belief could possibly be interpreted as protecting against mental manipulation via neurotechnology . However, this is u nlikely to be the case given the complexities of protecting mental integrity and freedom of thought (as discussed at [4.4] and [ 8.2] respectively) . 16 International regulatory framework What are the m ain international regulatory and governance gaps that you have identified as regards neurotechnology and human rights? 269. The NeuroRights Foundation published the repo rt, Public Gap Analysis of Existing Human Rights and Neurotechnology , on 6 May 2022. 270. This extensive report expressly considers the international regulatory and governance gaps in respect of neurotechnology and human rights. It methodically analyses the: ICCPR Convention against To rture and other Cruel, Inhumane or Degrading Treatment or Pu nishment ICESCR CRPD International Convention on the Elimination of all Forms of Racial Discrimination Convention on the Elimination of All Forms of Discrimination against Women CRC. 17 Internationa l cooperation What actions would you advocate for to address these gaps and potential human rights impact at the international level? Please elaborate on specific normative or institutional measures you would propose and assess the feasibility of their imp lementation. 271. The OECD published its Recommendation on Responsible Innovation in Neurotechnology in 2019 . It is the first inter national standard for government and industry , which places emphasis on : safeguarding brain data Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 50 safety assessments inclusivity scientific collaboration stewardship and trust across the public and private sector anticipating and monitoring unintended use and/or misuse .218 272. The Recommendation on Responsible Innovation in Neurotechnology embodies nine principles which focus on: promoting responsible innovation prioritizing safety assessment promoting inclusivity fostering scientific collaboration enabling societal deliberation enabling the capacity of oversight and advisory bodies safeguarding personal brain data and other information promoting cultures of stewar dship and trust across the public and private sector anticipating and monitoring potential unintended use and/or misuse.219 273. These principles provide the fo undation of how to maximise benefits , while minimising the harms of neurotechnology.220 17.1 Defining 'neurorights ' 274. As noted above , there is divergence on whether it is best to interpret existing rights to apply to neurotechnolog ies, create new neurorights or some combination of the two approaches. 275. Regardless of which approach is taken , greater consideration of the scope of rights a imed at protecting the mind is needed to protect the brain from current and future risks. 276. Specific ally, if neurorights are introduced into human rights instruments, they must be flexibly defined both in scope and applica tion to ensure such rights have broad application as neurotechnologies develop . 277. National human rights institute s and international hu man rights organisation s have an important role to play in bringing together relevant stakeholders in a consultative way t o define neurorights and the best way to Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 51 protect them . The Commission expects that its future work on neurotechnology will assist in t his regard and contribute to helping further this conversation . 278. Individual countries have already provided some definitions. Chile has a proposed law and constitutional amendment mandating neuroprotection, while the Spanish Digital Rights Charter will als o incorporate neurorights (as noted above at [55]).221 279. The key is to ensure that our und erstanding of neurorights, or how existing rights might be defined under existing instruments, is given urgent attention. 17.2 United Nations 280. The United Nations should give a specific focus to addressing human rights and neurotechnology , such as action to expand the understanding of traditional human rights to apply to neurotechnology, or the creation of specific neurorights. 281. The Office of the S ecretary -General's Envoy on Technology should dedicate resources and expertise towards advancing the protection and promotion of neurorights and/or expressly developing an interpretation of existing rights which protect the human mind . In addition to desig nating funding to do so, the Envoy should del iver a comprehensive framework on human rights and neurotechnology. 282. The United Nations should also consider appointing a Special Rapporteur on Neurotechnology and Human Rights. The Special Rapporteur could trav el to countries to monitor neurote chnological progress and human rights violations - with an aim to publish reports and ensure that there is public awareness and scrutiny of such developments . 283. Existing treaty bodies , such as the United Nations Committee Ag ainst Torture, should be encourage d to adopt General Comments on neuro technology and its interactions with their relevant treaty instruments . This may assist interpretation of existing treaties to apply to neurotechnology. 284. A collaborative and internationa l approach is necessary to avoid gaps in human rights regulations being exploited by individuals or organisations. Such gaps may result in que stionable neurotechnology products or services being offered in some jurisdictions and not in others. This could h ave the unintended effect of creating a 'black market' or see individuals and organisations engage in compliance -regime shopping to avoid huma n rights frameworks or regulation. Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 52 Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 53 Endnotes 1 Organisation for Economic Co -operation and Development (OECD ), 'Recommendation Responsible Innovation in Neurotechnology ' (OECD Legal Instrument, 2019 ); OECD , 'Neurotech nology and Society: Strengthening Responsible Innovation in Brain Science ' (po licy papers, November 2017 ) 49. 2 United Nations Educational, Scientific and Cultural Organization (UNESCO ), 'Report of the International Bioethics Committee of UNESCO ( IBC) on t he Ethical Issues of Neurotechnology ' (Report, 2021 ) 5. 3 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 3. 4 The N eurorights Foundation, ' Market Analysis Neu rotechnology ' (Report , March 2023 ) 3. 5 The N eurorights Foundation, ' Market Analysis Neurotechnology ' (Report , March 2023 ) 3. 6 Allan McCay, 'Neurotechnology, Law and the Legal Profession' ( Horizon Report for The Law Society , August 2022 ) The Law Society o f England and Wales 4; The N eurorights Foundation, 'Market Analysis Neurotechnology ' (Report , March 2023 ) 3. 7 The N eurorights Foundation, ' Market Analysis Neurotechnology ' (Report , March 2023 ) 5. 8 The N eurorights Foundation, ' Market Analysis Neurotechnol ogy' (Report , March 2023 ) 5. 9 The N eurorights Foundation, ' Market Analysis Neurotechnology ' (Report , March 2023 ) 5. 10 The N eurorights Foundation, ' Market Analysis Neurotechnology ' (Report , March 2023 ) 14. 11 The N eurorights Foun dation, ' Market Analysis Neu rotechnology ' (Report , March 2023 ) 14. Safety Initiative <https://xrsi.org/definition/the -metaverse and the Legal Professi on' ( Horizon Report for The Law Society , August 2022) The Law Society of England and Wales 3. 14 Marcello Ienca & Ro berto Andorno, 'Towards New Age of Neuroscience and Neurotechnology' (2017) 13(5) Life Sciences, Society and Policy 1, 1. 15 Oliver Whang , 'Brain Implants Allow Paralyzed Man to Walk Using His Thoughts ' The New York Times (online, 24 May 2023) <https://www.nytimes.com/2023/05/24/science/ paralysis -brain - implants -ai.html >. 16 Nidhi Subbaraman, ' In the Brain, Scientists Find New Clues to Treating Chronic Pain ' The Wall Street Journal (online, 22 May 2023) < https://www.wsj.com/articles/brain -study -finds -clues -to- treating -chronic -pain -a19be9fb?st=cm5zi978o6pwc50&reflink=desktopwebshare_permalink >. 17 UNESCO et al., ' The Risks and Challenges o f Neurotechnologies for Human Rights ' (Report , 2023) 10. 18 Allan McCay, 'Neurotechnology, Law and the Legal Profession' ( Horizon Report for The Law Society , August 2022) The Law Society of England and Wales 3. 19 Oliver Whang , 'A.I. Is Getting Better at Min d-Reading ' (01 May 2023) New York Time s <https://www.nytimes.com/2023/05/01/science/ai -speech -language.html >. 20 See generally Jerry Tang et al., ' Semantic Reconstruction of Continuous Language from Non- invasive Brain Recordings ' (2023) 26 Nature Neuroscience . 21 See Jerry Tang et al., ' Semantic Reconstruction of Continuous Language from Non-invasive Brain Recordings ' (2023) 26 Nature Neuroscience . 22 See Jerry Tang et al., ' Sem antic Reconstruction of Continuous Language from Non-invasive Brain Recordings ' (2023) 26 Nature Neuroscience . 23 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 4 citing Mashat MEM, Li G & Zhang D ., Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 54 'Human -to-human Closed -loop Control Based on Brain-to-brain Interface and Muscle -to-muscle Interface ' (2017) 7(1) Scientific Reports 11001. 24 Allan 'Neurotechnology, Law and the Legal Profession' ( Horizon Repo rt for The Law Society , August 2022) The Law Society of England and Wales 9 citing Yasmin Anwar, ' Scientists use Brain Imaging to Reveal the Movies in our Mind' Berkeley News (online 22 September 2022) <https://news.berkeley.edu/2011/09/22/brain -movies/ >. 25 Allan McCay, 'Neurotechnology, Law and the Legal Profession' ( Horizon Re port for The Law Society , August 2022) The Law Society of England and Wales 10 citing Guangye Li & Dingguo Zhang, ' Brain-Computer Interface Controlled Cyborg: Establishing a Functional Information Transfer Pathway from Human Brain to Cockroach Brain ' (2016 ) Plus One . 26 Centre for International Relations and Sustainable Development (CIRSD ), 'It's eurorights Foundation, ' Market Analysis Neurotechnology ' (Report , March 2023 ) 'It's Time for 29 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neuroright s' (2023) Cambridge Quarterly of Healthcare Ethics 1, 4. 30 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 2. 31 Marcello Ienca & Roberto Andorno, 'Towards New Human Rights in the Age of Neuroscience and Neurotechnology' (2017) 13(5) Life Sciences, Society and Policy 1, 5. 32 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethic s 1, 4. 33 UNESCO et al., ' The Risks and Challenges of Neurotechnologies for Human Rights ' (Report 2023) 35. 34 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 4-5. 35 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 5. 36 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 4. 37 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 2. 38 UNESCO et al., ' The Risks and Challenges of Neurotechnol ogies for Human Rights ' (Report , 2023) 30. 39 Rafael Yuste, Jared Genser 'It's Time for Neuro (2021 18 Horizons 40 Rafael & Stephanie Herrmann, 'It's Time for (2021) 41 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 2. 42 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 2. 43 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Camb ridge Quarterly of Healthcare Ethics 1, 2. Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 55 44 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 4. 45 Allan McCay, 'Neurotechnology, Law and the Legal Profession' (Horizon Report for The Law Society , August 2022) The Law Society of England and Wales 3. 46 Allan McCay, 'Neurotechnology, Law and the Legal Profession' ( Horizon Report for The Law Society , August 2022) The Law Society of England and Wales 3. 47 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quar terly of Healthcare Ethics 1, 2. 48 Avi Asher -Schapiro , 'Out of My Mind: Advances in Brain Tech Spur Calls for ' Neuro -rights' ' Reuters (onlin e, -tech -lawmaking - analysis -trfn-idUSKBN2BL1RH >. 49 United Kingdom the Information Commissioner's Office (UK ICO), ' ICO Tech Futures: Neurotechnology ' (Report, 01 June 2023) 33. 50 Sjors Ligthart et al., 'Minding Righ ts: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 2-3 citing Report on Respecting, Protecting and Fulfilling the Right to Freedom of Thought, to the 76th Sessio n of the General Assembly expected in July 2021; Declaration of the Interamerican Juridical Committee on Neuroscience, Neurotechnologies and Human Rights: New Legal Challenges for the Americas, CJI/DEC. 01 (XCIX -O/21, August 11, 202 1. 51 International Bioet hics Committee of UNESCO , 'Ethical Is sues ' (Report December 2021 ). 52 Jacob Kastrenakes, 'Google's chief internet evangelist says 'privacy may actually be an anomaly'' The Verge (online, 21 November 2013) <https://www.theverge.com/2013/11/20/5125922/vint -cerf-google -internet -evangelist -says - privacy -may -be-anomaly >. See generally Australian Human Rights Commission, ' Safegua rding the Right to Privacy: Submissions to the Attorney -General's Department Privacy Review Report ' (Submission , 05 April 2023). 54 Allan McCay, 'Neurotechnology, Law and the Legal Profession' ( Horizon Report for The Law Society , August 2022) The Law Societ y of England and Wales 5. 55 Brandon King, Gemma Read & Paul Salmon, 'The Risks Associated with the Use of Brain - Computer Interface s: A Systematic Review' (2022) International Journal of Human -Computer Interaction 1, 10. 56 Sjors Ligthart et al., 'Minding Ri ghts: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 6. 57 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethic s 1, 6. 58 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 6. 59 ECtHR 12 October 2006, appl.no. et a l., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 9. 61 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quart erly of H ealthcare Ethics 1, 9 quoting EU Network of Independent Experts on Fundamental Rights , 'Commentary of the Charter of Fundamental Rights of the European Union ' (European Commission , 2006 ). Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 56 62 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical a nd Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 7-8. 63 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 8 quoting Bublit z J-C., 'My Mind is Mine!? Cognitive Liberty as a Legal Concept ' In Hildt E, Franke AG, 'Cognitive Enhancement: An et al., 'Minding Rights: Mapping E thical and Legal Foundations of Neurorights' (2023) Cambri dge Quarterly of Healthcare Ethics 1, 5-6. 65 Allan McCay, ' Neurotechnology and Human Rights: Developments Overseas and the Challenge for Australia ' (2023) Australian Journal of Human Rights 1, 1. 66 Allan McCay, ' Neurotechnology and Human Rights: Developmen ts Overseas and the Challenge for Australia ' (2023) Australian Journal of Human Rights 1, 6. 67 UNESCO, 'Report of the International Bioethics Committee of UNESCO (IBC) on the Ethical Issues of Neurotechnology ' (Report, 2021) < https://unesdoc.unesco.org/ark:/48223/pf0000378724 >; Allan McCay, ' Neurotechnology and Human Rights: Developments Overs eas and the Challenge for Australia ' (2023) Australian Journal of Human Rights 1, 7. 68 UNESCO, ' Ethic s of Neurotechnology ' (Website) < https://www.unesco.org/en/ethics - neurotech?TSPD_101_R0=080713870fab20004e25f843aef6fb7dcda85f9486f2cba20802a3b86e2 9d76215b545251d0105510859e6882d143000c587b1fd7309c1f3fab0d97fb9da5119a2c2e670c4 3dab4e14776e4993c04a5aa0 38c215a4c6da9b006ccf7776714ab2 >. 69 UNESCO, ' (Website) < https://www.unesco.org/en/ethics - neurotech?TSPD_101_R0=080713870fab20004e25f843aef6fb7dcda85f9486f2cba20802a3b86e2 9d76215b545251d0105510859e6882d143000c587b1fd7309c1f 3fab0d97fb9da5119a2c2e670c4 3dab4e14776e4993c04a5aa038c215a4c6da9b006ccf7776714ab2 >. 70 UK ICO, ' ICO Tech Futures: Neurotechnology ' (Report, 01 June 2023) 24 citing Regulatory Horizons Council, 'Neurotechnology Regulation ' (Report, November 2022) 9. 71 Strat egic Market Researc h, 'Brain -computer Interface Market will Attain a Value of USD 5.34 Billion by 2030 ' (Research, 06 July 2023) . 72 Strategic Market Research, ' Brain -computer Interface Market will Attain a Value of USD 5.34 Billion by 2030 ' (Research, 06 J uly 2023). 73 Strategic Market Research, ' Brain -computer Interface Market will Attain a Value of USD 5.34 Billion by 2030 ' (Research, 06 July 2023). 74 Strategic Market Research, ' Brain -computer Interface Market will Attain a Value of USD 5.34 Billion by 203 0' (Research , 06 July 2023). 75 UK ICO, ' ICO Tech Futures: Neurotechnology ' (Report, 01 June 2023) 24. 76 Grand View R esearch, ' Brain Computer Interface Market Report, 2022 -2030 ' (Report, 2020 ). 77 The N eurorights Foundation, ' Market Analysis Neurotechnology ' (Report , March 2023 ) 2. 78 The Hon Ed Husic MP, ' Investing in Industry Growth ' (Media Release, 09 May 2023) <https://www.minister.industry.gov.au/m inisters/husic/media -releases/investing -industry - growth >. 79 The Hon Ed Husic MP, ' Investing in Industry Growth ' (Media Release, 09 May 2023) <https ://www.minister.industry.gov.au/ministers/husic/media -releases/investing -industry - growth >. 80 UK ICO, ' ICO Tech Futures: Neurotechnology ' (Report, 01 June 2023) 25. 81 NeuroTech Analytics, ' NeuroTech Industry Global NeuroTech Industry Investment Digest 2021 ' (Report , 2021 ) 3. Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 57 82 NeuroTech Analytics, ' NeuroTech Industry Global NeuroTech Industry Investment Digest 2021 ' (Report) , 2021 3; UNESCO, ' neurotech?TSPD_101_R0=080713870fab20004 e25f843aef6fb7dcda85f 9486f2cba20802a3b86e2 9d76215b545251d0105510859e6882d143000c587b1fd7309c1f3fab0d97fb9da5119a2c2e670c4 3dab4e14776e4993c04a5aa038c215a4c6da9b006ccf7776714ab2 >. 83 < https://w ww.unesco.org /en/ethics NeuroTech Industry Industry Investment Digest 2021 ' (Report , 2021 ). 85 The N eurorights Foundation, ' Market Analysis Neurotechnology ' (Report , March 2023 ) 18. 86 The N eurorights Foundation, ' Market Analysis Neurotechnology ' (Report , March 2023 ) 4; see also Synchron, ' Unlocking the Natural Highways of the Brain ' (Website) < https://synchron.com/ >. 87 Kimberly Ha & Tyler Hubin, ' Synchron Announces First Human U.S. Brain -Computer Interface Implant ' Business Wire (online, 18 July Foundation, Analysis Neurotechnology ' (Report , March 2023 ) 18. 88 The N eurorights Foundation, ' Market Analysis Neurotechnology ' (Report , March 2023 ) 18 citing Synchron, ' Unlocking the Nat ural Highw ays of the Brain ' (Website) < https://synchron.com/ >. 89 UK ICO, ' ICO Tech Futures: Neurotechnology ' (Report, 01 June 2023) 26. 90 Omniscient Neurotechnology, ' Unlocking the Power of Brain Mapping ' (Website) <https://www.o8t.com/ >. 91 Casey Tonkins, ' Mind -reading Technology Raises Huge Privacy Concerns ' ACS (online, 13 June 2023) < https://ia.acs.org.au/article/2023/mind -reading -technology -raises -huge -privacy - concerns.html >. 92 UNESCO et al., ' The Risks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023) 29; Allan McCay, 'Neurotechnology, Law and the Legal Profession' (Horizon Report for The Law Society , August 2022) The Law Society of England and Wales 5. 93 UNESCO et al., ' The Risks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023) 10. 94 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Leg al Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 6. 95 Office of the Australian Informatio n Commissioner (OAIC), ' What is Privacy?' (Website) <https://www.oaic.gov.au/privacy/your -rights/what -is-privacy >. 96 UNESCO et al ., 'The Risks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023) 30. 97 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations o f Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 7. 98 UNESCO et al., ' The Risks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023) 29. 99 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neu rorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 7. Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 58 100 See generally Yilun Wang & Michal Kosinski, 'Deep Neural Networks are more Accurate than Humans at Detect ing Sexual Orientation from Facial Images' (2018) 114(2) Journal of Personality and S ocial Ilia Savelev and Daron Tan, ' State -Sponsored Homo phobia 2020: Global Legislation Overview Update ' (Geneva: ILGA, December 2020) 25. 102 AHRC, 'Human Rights and Technology Final Report 2021 ' (Final Report, 2021) 115; See David Pozen, 'The Mosaic Theory, National Security, and the Freedom of Information Act ' (2005) 115 Yale Law Journal 628. 103 UNESCO et al., ' The Risks and Challenges of Neur otechnologies for Human Rights ' (Report , 2023) 39. 104 See Convention on the Rights of the Child art 16 ; International Convention on the Protection of the Rights of All Migrant Workers and Members of Their Families art 14 ; Convention on the Rights of Persons with Disabilities art 22 ; African Charter on the Rights and Welfare of the Child art 10 ; American Convention on Human Rights art 11 ; Convention for the Protection of Human Rights and Fundamental Freedoms art 8 . 105 Office of the United Nations High Commissi oner for Human Right, ' The Right to Privacy In the Digital Age ' (Report , A/HRC/51/17 , 04 August 2022) 2. 106 Li Li, et al., ' I Will Only Know After Using It: The Repeat Purchasers of Smart Home Appliances and the Privacy Paradox Problem ' (2023) 128 Computers & Security 1. 107 Consumer Policy Research Centre, ' 2020 Data and Technology Consumer Survey ' (Survey, December 2020) 33. 108 Consumer Policy Research Centre, ' 2020 Data and Technology Consumer Survey ' (Survey, December 2020) 26. 109 Lik-Hang Lee, et al., 'All One Needs to Know about Metaverse: A Complete Survey on Technological Singularity, Virtual Ecosystem, and Research Agenda' 2021 arXIV 37. 110 Lik-Hang Lee, et al., 'All One Needs to Know about Metaverse: A Complete Survey on Technological Singularity, Virtua l Ecosystem, and Research Agenda' 2021 arXIV 37. 111 Lik-Hang Lee, et al., 'All One Needs to Know about Metaverse: A Complete Survey on Technological Singularity, Virtual Ecosystem, and Research Agenda' 2021 arXIV 37. 112 Li Li, et al., ' I Will Only Know After Using It: The Repeat Purchasers of Smart Home Appliances and the Privacy Paradox Problem ' (2023) 128 Computers & Security 1. 113 Australian Competition and Consumer Commission ( ACCC ), 'Digital Platform Services Inquiry - September 2023 Report on the expandi ng ecosystems of digita l platform service providers ' (Commonwealth of Australia, Issues Paper, March 2023) 7 citing ACCC, Digital Platform Services Inquiry Fifth Interim Report (Commonwealth of Australia, Firth Interim Report, 11 November 2022) 44. 114 ACCC, 'Digital Platform Services Inquiry - September 2023 Report on the expanding ecosystems of digital platform service providers ' (Commonwealth of Australia, Issues Paper, March 2023) 7 -8. 115 Consumer Policy Research Centre, ' In Whose Interest? Why Businesses Need to Keep Consumers Safe and Treat their Data with Care' (Working Paper, March 2023) 4 citing Anthony Nadler & Lee McGuigan, 'An Impulse to Exploit: The Behavioral Turn in Data-driven Marketing' (2018) 35(2) Critical Studies in Media Communication 151-165. 116 Cons umer Policy Research Centre, ' In Whose Interest? Why Businesses Need to Keep Consumers Safe and Treat their Data with Care' (Working Paper, March 2023) 4. Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 59 117 Consumer Policy Research Centre, ' In Whose Interest? Why Businesses Need to Keep Consumer s Safe and Treat their Data with Care' (Working Paper, March 2023) 10 citing Jack Balkin, 'The Fiduciary Model of Privacy' (2020) 134(11) Harvard Law Review Forum 12. 118 Consumer Policy Research Centre, ' In Whose Interest? Why Businesses Need to Keep Consum ers Safe and Treat their Data with Care' (Working Paper, March 2023) 4. 119 Consumer Policy Research Centre, ' In Whose Interest? Why Businesses Need to Keep Consumers Safe and Treat their Data with Care' (Working Paper, March 2023) 4. 120 UNESCO et al., ' The R isks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023) 13. 121 UNESCO et al., ' The Risks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023) 13 & 30 . 122 UNESCO et al., ' The Risks and Challenges of Neurotechnologies for Huma n Rights ' (Report , 2023) 29. 123 UNESCO et al., ' The Risks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023) 12. 124 CIRSD, ' It's Time for Neurorights ' (Webpage) 'Equal Access to Mental Augmentation: Shou ld it be a Fundamental Right?' (2023) Brain Stimulati on Journal 1. 127 Kelly Metcalf & Anna Iles, ' How Advances in Neurotech Will Impact Human Rights ' BSR (online, 14 ) The human cost of Katherine J. Igoe, 'Algrothimic Bias in Health Care Exacerbates Social Inequities - How to Prevent It' Harvard School of Public Health (online, 21 March 2021 ) <https://www.hsph.harvard.edu/ecpe/how -to-prevent -algorithmic -bias-in-health ICO Tech Futures: Neurotechnol ogy' (Report, 01 June 2023) 19. 131 UK ICO, ' ICO Tech Futures: Neurotechnology ' (Report, 01 June 2023) 19. 132 CIRSD, ' It's Time for Neurorights ' (Webpage) winter Elon Musk's Brain Chip Firm Wins US Approval for Human Study' BBC News (online, 26 May) <https://www.bbc.com/news/health -65717487 >. 134 UNESCO e t al., ' The Risks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023) 3. 135 Rafael Yuste, Jared Ge nser Herrmann, 'It's Time for Neuro -Rights' (2021 ) 18 Horizons 1, 157. 136 UNESCO et al., ' The Risks and Challenges of Neurotechnolo gies for Human Rights ' (Report , 2023) 13. 137 UNESCO et al., ' The Risks and Challenges of Neurotechnologies for Huma n Rights ' (Report , 2023) 19. 138 UNESCO et al., ' The Risks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023) 40-41. 139 UNESCO et al., ' The Risks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023) 40-41. Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 60 140 Australian Institute of Health and Welfare, 'People with Disability et al., ' The Risks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023 ) 7. 142 UNESCO et al., ' The Risks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023) 10-11. 143 Regulatory Horizons Council, ' Neurotechnology Regulation ' (Report, November 2022) 2. 144 UNESCO et al., ' The Risks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023) 11. 145 UNESCO et al., ' The Risks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023) 11. 146 UNESCO et al., ' The Risks and Challenges of Neur otechnologies for Human Rights ' (Report , 2023) 11. 147 UNESCO et al., ' The Risks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023) 11. 148 UNESCO et al., ' The Risks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023) 12. 149 Eliza Strickland & Mark Harris, ' Their Bionic Eyes are now Obsolete and Unsupported ' IEEE Spectrum (online, 15 February 202 2) <https://spectrum.ieee.org/bionic -eye-obsolete#toggle - gdpr >. 150 Eliza Strickland & Mark Harris, ' Their Bionic Eyes are now Obsolete and Unsupported ' IEEE Spectrum (online, 15 February 2022) < https://spectrum.ieee.org/bionic gdpr >. 151 Jessica Hamzelou , 'A Brain Implant Changed her Life. Then it was Removed Against her Will' MIT Technology Review (online, 25 May 2023) Brain Implant Changed her Life. Then it was Removed Against her Will' MIT Technology Review (online, 25 May 2023) <https://ww w.technologyreview.com/2023/05/25/1073634/brain Ienca & Mark Cook, ' How I Became Myself after Merging with a Computer: Does Human -machine Symbios is Raise Human Rights Issues? ' (2023) 16(3) Brain Stimulation 783-789. 153 Fredric Gilbert, Marcello Ienca & Mark Cook, ' How I Became Myself after Merging with a Computer: Does Human -machine Symbiosis Raise Human Rights Issues? ' (2023) 16(3) Brain Stimulation 783, 785. 154 Brandon King, Gemma Read & Paul Salmon, 'The Risks Assoicated with the Use of Brain - Computer Interfaces: A Systematic Review' (2022) International Journal of Human -Computer Inter action 1, 9. 155 Brandon King, Gemma Read & Paul Salmon, 'The Risks Assoicated with the Use of Brain - Computer Interfaces: A Systematic Review' (2022) International Journal of Human -Computer Interaction 1, 9. 156 See Generally Special Rapporteur on the right of everyone to the enjoyment of the highest attainable s tandard of physical and mental health, 'Report of the Special Rapporteur on the right of everyone to the enjoyment of the highest attainable standard of physical and mental health' (United Nations, A/HR C/35/21 , 28 March 2017). Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 61 157 See Generally Special Rappo rteur on the right of everyone to the enjoyment of the highest attainable standard of physical and mental health, 'Report of the Special Rapporteur on the right of everyone to the enjoyment of the highe st attainable standard of physical and mental health' (United Nations, A/HRC/35/21 , 28 March 2017). 158 Australian Law Reform Commission, ' Equality, Capacity and Disability in Commonwealth Laws ' (Final Report, August 2014) 11. 159 CIRSD, ' It's Time for Neurori ghts' ICO Tech Futures: Neurotec hnology ' (Report, 01 June 2023) 15. 162 UNESCO et al., ' The Risks and Challenges of Neuro technologies for Human Rights ' (Report , 2023) 7. 163 See generally Yavuz Canbay, Anil Pelin Canbay, 'Privacy Metaverse: A Review ' 15th Inte rnational Conference on Information Security and Cryptography (Conference Paper, 2022) 80 -81. 164 Yuntao Wang, et al., ' A Survey on Metaverse: Fundamentals, Security, and Privacy ' (2023) 25(1) IEEE Communications Surveys & Tutorials, Communications Surveys & Tutorials 319. 165 Yuntao Wang, et al., ' A Survey on Metaverse: Fundamentals, Security, and Privacy ' (2023) 25(1) IEEE Communications Surveys & Tutorials, Communications Surveys & Tutorials 320. 166 Yuntao Wang, et al., ' A Survey on Metaverse: Fundamentals, S ecurity, and Priv acy' (2023) 25(1) IEEE Communications Surveys & Tutorials, Communications & Tutorials also Yavuz Canbay, Anil Concerns and Measures in Metaverse: A Review ' 15th International Conference on Inf ormation Security and Cryptography (Conference Concerns and Measures in Metaverse: A Review ' 15th International Conference on Information Security and Cryptography (Conference Paper, 2022) 84. 168 Divya Chan der, ' I Think, Therefore I am - Neural Sovereignty and Neural Rights in the 21st Century ' In 'Ethics @ Work' (2022) 198. 169 UK ICO, ' ICO Tech Futures: Neurotechnology ' (Report, 01 June 2023) 15. 170 UK ICO, ' ICO Tech Futures: Neurotechnology ' (Report, 01 June 2023) 15. 171 Committee on the Rights of the Child, General Comment No. 25 (2021) UN Doc CRC/C/GC/25 (CRC General Comment 25) 12-13. 172 CRC General Comment 25 13. 173 Human Rights Council, Report of the Special Rapporteur on the Right to Priva cy, Joseph Cannataci, on Artificial Intelligence and Privacy, and Children's Privacy (2021) UN Doc A/HRC/46/37 116. 174 CRC General Comment 25 75. 175 OAIC Submission to the Attorney -General's Department, Discussion Paper (Commonwealth of Australia, Discussion Paper, October ) 120. 176 Human Rights Council, Report of the Special Rapporteur on the Right to Privacy , Joseph Cannataci, on Artificial Intelligence and Privacy, and Children's Privacy (2021) UN Doc A/HRC/46/37 14. 177 General comment 25 7 -8. 178 Regulatory Ho rizons Council, ' Neurotechnology Regulation ' (Report, November 2022) 2. 179 AHRC, ' Human Rights and Technology Final Report 2021 ' (Final Report, 2021) 98-99. 180 AHRC, ' Human Rights and Technology Final Report 2021 ' (Final Report, 2021) 98 -99. Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 62 181 AHRC, ' Human R ights and Technology Final Report 2021 ' (Fina l Report, 2021) 98 -99. 182 AHRC, ' Human Rights and Technology Final Report 2021 ' (Final Report, 2021) 98 -99. 183 OECD, ' OECD Guidelines for Multinational Enterprises on Responsible Business Conduct ' (Guidelines, 08 June 2023) 46. 184 UNESCO et al., ' The Risks and Challenges of Neurotechnologies for Human Rights ' (Report , 2023) 34. 185 The N eurorights Foundation, ' Market Analysis Neurotechnology ' (Report , March 2023 ) 1. 186 The N eurorights Foundation, ' Market Analysis Neuro technology ' (Rep ort, March 2023 ) 24. 187 Sjors Ligthart et al., 'Minding Rights: Mapping Ethical and Legal Foundations of Neurorights' (2023) Cambridge Quarterly of Healthcare Ethics 1, 4. 188 Therapeutic Goods Administration, 'Therapeutic Goods Administration ' (Website) <https://www.tga.gov.au/ >. 189 Competition and Consumer Act 2010 (Cth) sch 2, Australian Consumer Law s 3. 190 Competit ion and Consumer Act 2010 (Cth) sch 2, Australian Consumer Law s 3. 191 See generally Compet ition and Consumer Act 2010 (Cth) sch 2, Australian Consumer Law ss 54 & 61. 192 See generally Competition and Consumer Act 2010 (Cth) sch 2, Australian Consumer Law ss 54(2) & 54(7). 193 ACCC, ' Consumer rights and guarantees ' (Website) <https://www.accc.gov.au/consumers/buying -products -and-services/co nsumer -rights -and- guarantees >. 194 See generally Competition and Consumer Act 2010 (Cth) sch 2, Australi an Consumer Law s 61. 195 Competition and Consumer Act 2010 (Cth) sch 2, Australian Consumer Law s 64A. 196 See generally Competition and Consumer Act 2010 (Cth) sch 2, Australian Consumer Law pt 3-4. 197 Privacy Act 1988 (Cth) ss 95A -95AA. 198 Privacy Act 1988 (Cth) s 6(1). 199 Privacy Act 1988 (Cth) s 6(1). 200 Attorney -General's Department, ' Privacy Act Review Report 2022 ' (Report, 2023) 28. 201 Attorney -General's Department, ' Privacy Act Review Report 2022 ' (Report, 2023) 28 -29. 202 See generally A ustralian Law Reform C ommission , 'Serious Invasions of Privacy in the Digital Era (ALRC Report 123) ' (Report, 03 September 2014); 203 See generally Attorney -General's Department, ' Privacy Act Review Report 2022 ' (Report, 2023) 280-286. 204 See AHRC, ' Safeguarding the Right to Privacy in Australia ' (Submission to Attorney -General's Department Privacy Act Review Report 2022 , 2023) 46-48. 205 See generally Attorney -General's Department, ' Privacy Act Review Report 2022 ' (Report, 2023) 110. 206 AHRC , 'Position Paper ' (Position Paper, March 2023) 139. 207 AHRC , 'Position Paper ' (Position Paper, March 2023) 20. 208 AHRC , 'Position Paper ' (Position Paper, March 2023) 23. 209 Momcilovic v The Queen (2011) 245 CLR 1, [43] (French CJ). 210 AHRC , 'Position Paper ' (Position Paper, March 2023) 111 & 347. 211 AHRC , 'Position Paper ' (Position Paper, March 2023) 347. 212 AHRC , 'Position Paper ' (Position Paper, March 2023) . 213 AHRC , 'Position Paper ' (Position Paper, March 2023) 308; Parliament Joint Committee on Human Rights, ' Annual Report 2020 ' (Commonwealth of Aust ralia, Report, 13 May 2021) 16 Figure 3.1. Australian Human Rights Commission Protecting Cognition: Human Rights and Neurotechnology , 02 July 2023 63 214 Parliament Joint Committee on Human Rights, ' Annual Report 202 1' (Commonwealth of Australia, Report, 28 September 2022) 15. 215 AHRC , 'Position Paper ' (Position Paper, March 2023) 309. 216 AHRC , 'Position Paper ' (Position Paper, March 2023) 111. 217 AHRC , 'Position Paper ' (Position Paper, March 2023) 349. 218 See generally OECD, 'Recommendation Responsible Innovation in Neurotechnology ' (OECD Legal Instrument, 2019 ). 219 See generally OECD, 'Recommendation Responsible Inn ovation in Neurotechnology ' (OECD Legal Instrument, 2019 ). 220 OECD, ' Recommendation of the Council on OECD Legal Instruments Responsible Innovation in Neurotechnology' (OECD Legal Instruments, 2022). 221 CIRSD, ' It's Time for Neurorights ' https://www.cirsd.org/en/horizons/horizons - winter -2021 -issue -no-18/its-time -for-neuro --rights >. "}