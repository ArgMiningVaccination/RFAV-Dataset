{"title": "PDF", "author": "PDF", "url": "https://biostat.app.vumc.org/wiki/pub/Main/OsakaUnivSummer2015/OsakaClinTrials2015.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "CLINICAL TRIALS OSAKA UNIVERSITY BIOSTATISTICS Tatsuki Koyama, PhD Center for Quantitative Sciences Vanderbilt University School of Medicine tatsuki.koyama@vanderbilt.edu 7/6/15\u00187/10/15 Copyright 2015. T Koyama. All Rights Reserved. Updated June 18, 2015Contents 1 Observational Studies and Experimental Studies analysis following a two-stage design in phase II clinical crossover design for the comparison of two active and Experimental Studies 1.1 Denitions Observational study A study design in which the investigator does not control the as- signment of treatment of individual study subjects (Piantadosi) Experiment A study in which the investigator makes a series of careful observations under controlled or arranged conditions. In particular, the investigator controls the treatment or exposure applied to the subject(s) by design and then carefully and thoroughly records outcome measurements. Clinical trial An experiment in humans designed to accurately assess the effects of a treatment or treatments by reducing random error and bias. (Piantadosi) Clinical trial A prospective study comparing the effect and value of an intervention against a control in human subjects. (Friedman) Clinical trial An experiment designed to assess the efcacy of a test treatment by comparing its effects with those produced using some other test or control treatment in comparable groups of human beings. (Meinert CL 1994) 1CHAPTER 1. OBSERVATIONAL STUDIES AND EXPERIMENTAL STUDIES 2 1.2 Observational studies 1.2.1 Advantages of observational studies \u000fLower cost \u000fGreater timeliness \u000fA broader range of patient \u000fIt may be applied when a controlled clinical trial would be impossible or unethical 1.2.2 PCOS Prostate cancer is the second leading cause of cancer death among American men (be- hind lung cancer). The common treatment choices for localized disease are surgery, radi- ation and observation. Suppose we are interested in comparing effectiveness of surgery and radiation therapies. The Prostate Cancer Outcomes Study (PCOS): Subjects were identied through six sites participating in the NCI's SEER program. (diagnosed with Prostate cancer from 1994/10/1 to 1995/10/31). N=1;655. Alive Dead Radiation 240 (49%) 251 (51%) Surgery 838 (72%) 326 (28%) Can that Surgery is better? c2=80:2,p<0:001. Odds ratio: 2:69(2:15;3:36). In general, it is difcult to establish a cause-and-effect association from an observational study because of confounders .CHAPTER 1. OBSERVATIONAL STUDIES AND EXPERIMENTAL STUDIES 3 Confounder A prognostic factor that is associated with both response (e.g. survival) and explanatory variable (e.g. treatment choice). Radiation Surgery P-value N=491 N=1164 Age 2 (110) (44) 8% (60) radiation surgery5560657075n=295 n=705CHAPTER 1. OBSERVATIONAL STUDIES AND EXPERIMENTAL STUDIES 4 radiation Alive radiation Dead surgery Alive surgery Dead5560657075n=132 n=163 n=521 n=184Age Let's analyze the data with a method that account for the baseline difference in the two treatment groups. Survival\u0018Treatment\u0003(Age + PSA + Tumor grade + Gleason score) Many statistical methods exist to establish causal relationship from an observational study. (e.g., propensity score, instrumental variable) \u000fPropensity score analysis -propensity score matching -propensity score as weights -propensity score as additional variableCHAPTER 1. OBSERVATIONAL STUDIES AND EXPERIMENTAL STUDIES 5 50 25 0 25 50 75 100Radiation Surgery 0.00.20.40.60.81.0 Can observational studies establish a cause-effect association? \"PM USA agrees with the overwhelming medical and scientic consensus that cigarette smoking causes lung cancer, heart disease, emphysema and other serious diseases in smokers. Smokers are far more likely to develop serious diseases, like lung cancer, than non-smokers. There is no safe cigarette.\"CHAPTER 1. OBSERVATIONAL STUDIES AND EXPERIMENTAL STUDIES 6 \"Smoking and health\" by JT The Ministry of Health's claim that smoking is a risk factor for many diseases is primarily based on epidemiological studies of comparisons between smokers and non-smokers on disease rate. Epidemiological studies are useful in establishing exploratory associations between a disease and risk factors, but they can not establish a cause-and-effect associ- ation without controlling for other factors such as genetic factors, diet, exercise and stress. Moreover, epidemiological studies are intended to compare populations and do not reveal the risk of disease for individual smokers. 1.3 Clinical trials 1.3.1 Essential requirements for clinical trials \u000fHuman subjects \u000fDesigned \u000fInvolves intervention \u000fComparable treatment groups \u000fProspective follow-up for a specied outcome Types of study designs that are notclinical trials. \u000fCase report \u000fCross-sectional study \u000fCase-control study \u000fGeneral observational study (prospective study) \u000fAnimal studyCHAPTER 1. OBSERVATIONAL STUDIES AND EXPERIMENTAL STUDIES 7 Some typical characteristics of human studies \u000fLarge variation among subjects \u000fLengthy disease process \u000fRare disease \u000fNon-compliance / dropouts \u000fEthical issues Advantages of clinical trials \u000fCan establish a cause-effect association (free of confounding) 1.3.2 Some unique issues with clinical trials \u000fEthics -Randomization -Placebo -One patient and the society -When accumulating data show trends, what should we do? \u000fSafety / toxicity \u000fPatient consent \u000fPatient compliance \u000fQuality of lifeCHAPTER 1. OBSERVATIONAL STUDIES AND EXPERIMENTAL STUDIES 8 1.3.3 PIVOT Prostate Cancer Intervention Versus Observation Trial (PIVOT): \u000fResults presented at American Urological Association Annual Meeting (May 2011) \u000fWilt et al. (PIVOT Study Group). \"Radical prostatectomy versus observation for localized prostate cancer\" N Engl J Med . 2012. 367(3):203-213. Erratum N Engl J Med . 2012. 367(6):582. \u000fPatients with localized prostate cancer (enrollment 1994 - 2002), the last observation was made in 2010. \u000fInclusion criteria: 75 years or younger Localized disease PSA <50mg/mL Diagnosed within 12 months Radical prostatectomy candidate \u000fEndpoint: All cause mortality \u000fintention-to-treat analysis The study objective was \"Among men with clinically localized prostate cancer detected during the early PSA era, does the intent to treat with radical prostatectomy reduce all- cause & prostate cancer mortality compared to observation?\" \u000f5,023 were eligible, 4,292 declined Prostatectomy was performed 281 (77%) of 364 in group 1 and 35 (10%) of 367 in group 2.CHAPTER 1. OBSERVATIONAL STUDIES AND EXPERIMENTAL STUDIES 9 Actual Treatment Assigned Treatment Surgery Observation Surgery 281 (77%) 83 (23%) 364 (50%) Observation 35 analysis compares 364surgery patients and 367observation patients based on the assigned treatments. On-treatment analysis compares 316surgery patients and 415observation patients based on the actual treatments. Per-protocol analysis compares 281surgery patients and 332observation patients who adhered to the protocol. \u000fNo statistically signicant difference in baseline patient characteristics (age / race / marital status / comorbidities / PSA / stage). \u000fMedian mortality between the treatments. \u000fSignicant difference (all surgery better) was found. -All-cause mortality among low-risk patients. -Prostate cancer specic mortality in high-risk patients. -Prostate cancer specic mortality in PSA high patients. \"While surgery did not reduce mortality more than observation in men with low PSA or low risk prostate cancer, our results suggest a benet from surgery in men with higher PSA or higher risk disease.\"Chapter 2 Clinical trial Aclinical trial is an experiment testing a medical treatment on human subjects. The opposite term is perhaps a nonexperimental study , not an observational study. 2.1 Phases of clinical trials Usually, clinical trials are often classied into phase (I to IV). This terminology may be inadequate but very widely used. 2.1.1 Phase I The main objective of phase I clinical trial is to establish safety. (to estimate MTD) These studies should provide information on the pharmacokinetics of the drug in humans. They may provide preliminary information the pharmacodynamics of the drug. Pharmacokinetics What the body does to drug. The process by which the drug is ab- 10CHAPTER 2. CLINICAL TRIAL 11 sorbed, distributed, metabolized, and eliminated by the body. Some commonly used parameters to study pharmacokinetics are: Concentration of drug (in plasma); Bio- logical half-life, Cmax, the peak plasma concentration of a drug; tmax, time to achieve Cmax. Pharmacodynamics What drug does to the body. Effects of drugs on living organisms and systems. Subjects for phase I study are usually normal healthy volunteers. In oncology studies, patients may participate. Single arm dose escalation (dose determination) trials are com- mon in phase I studies. Historically, 3+3 designs have been frequently used; however, Bayesian designs, namely, the continual reassessment method and the modied toxicity probability interval, are gaining popularity. 2.1.2 Phase II Phase II trials primarily look for evidence of efcacy (activity), but safety should also be closely monitored. Sometimes, phase II trials are divided to phase IIa and IIb trials. Phase IIa The primary objective is to establish a safe (and effective) dose. Phase IIb The primary objective is to assess efcacy of the drug. Phase II trials are often single-arm trials, where the response rate is compared to a his- torical control. They can be multi-arm with a placebo control. Two-stage and multi-stage designs are often applied to expedite a decision of futility. 2.1.3 Phase III Phase III clinical trials are considered pivotal, and the new treatment is compared to standard treatment or placebo to establish effectiveness of the new treatment. TheseCHAPTER 2. CLINICAL TRIAL 12 trials are often multi-center trials involving hundreds to thousands of patients. When there is already a good conventional treatment, establishing noninferiority -as opposed tosuperiority -, may be the primary objective. 2.1.4 Phase IV Phase IV is a postmarketing surveillance, often to look for uncommon but serious side- effects. Phase I/II trials and phase II/III trials have become popular. 2.2 Clinical trial terminologies \u000fClinical trial protocols \u000fData \u000fPatient populations treated / Treatment received -Intention to treat (ITT) -Per protocol / Adherers only \u000fHypothesis of interest -Superiority -Non-inferiority -EquivalenceCHAPTER 2. CLINICAL TRIAL 13 \u000fMasking / Blinding \u000fRegulatory body -FDA (Food and Drug Administration) -EMA (European Medicines Agency) -PMDA (Pharmaceuticals and Medical Devices Agency) \u000fICH (International Conference on -ICH E9: reports 2.2.1 Intention-to-Treat (ITT) Intention to treat is the idea that patients on a randomized clinical trial should be analyzed as part of the treatment group to which they were assigned, even if they did not actually receive the intended treatment. (Piantadosi). Randomization in clinical trial should eliminate observable and unobservable bias, there- fore, if some patients are excluded or allowed to switch assignments, potential for bias is re-introduced. In practice, oftentimes, ITT only includes the patients who took at least one dose of treat- ment and provided any data. \u000fAll patients screened \u000fAll patients randomized -ITT (largest group of patients intended for treatment)CHAPTER 2. CLINICAL TRIAL 14 -Perhaps overly conservative compared to the dention below \u000fAll patients receiving at least one dose of the study drug -Practical denition of ITT. May induce some bias. Some patients may be missing some data, and imputation is required. Reasons that may prompt exclusion: \u000fprotocol violation \u000fincorrect drug administration \u000fuse of disallowed medication \u000fpoor compliance \u000fdrop out due to adverse event \u000fdrop out due to perceived lack of efcacyChapter 3 Selected topics in basic statistics 3.1 Stop when signicant Suppose we would like to test H0:p=0:1;H1:p>0:1by taking a random sample of size 40from a Bernoulli (p). Under H0, the number of \"successes\" out of 40 has a Binomial (40;0:1)distribution. Moreover, we compute P0[X\u00158] =0:042, so the test that rejects H0ifX\u00158has a type I error rate of 0:042. The data were observed sequentially, and the 8th \"success\" was observed after N= 32, and we decided to reject H0and terminate the study. The conclusion was that p was signicantly greater than 0:1, and p=8=32=0:25with a method (note: use p= (X+2)=(N+4)) 15CHAPTER 3. SELECTED TOPICS IN BASIC STATISTICS 16 \u000fClopper-Pearson (exact) method Given xand N, the exact method condence such that H0:p=p\u0003would not be rejected by the observed data. Suppose p\u0003<p, we need to nd p\u0003such that P[X\u00158jp=p\u0003] =0:05. And p\u0003>p, we need to nd P[X\u00148jp=p\u0003]. 1 - pbinom(7, 32, 0.10) # or sum( dbinom(8:32, 32, 0.10) ) ## [1] 0.01168545 This needs to be 0.05. 1 - pbinom(7, 32, 0.12) # or sum( dbinom(8:32, 32, 0.12) ) ## [1] 0.03193625 This needs to be 0.05. To solve for p\u0003, we can use the following relationship between a Binomial random variable and a Beta random variable. If X\u0018Binomial (n;p)andY\u0018Beta(k;n\u0000k+1), then P[X\u0015k] =P[Y\u0014p]: So instead of solving p\u0003]. qbeta(0.05, 8, 32-8+1) # [1] 0.1309329 QuestionsCHAPTER 3. SELECTED TOPICS IN BASIC STATISTICS 17 \u000fWas type I error rate controlled? \u000fWas 0.8 1.00.0000.0050.0100.0150.0200.0250.030 True BiasCHAPTER 3. SELECTED TOPICS IN BASIC STATISTICS 18 3.2 Repeat until signicance Suppose Xis a random sample of size 10from Normal (m;s2). IfH0:m=0is not rejected, take another sample of size 15and test again with n=25. If each test has one-sided a=0:05, what is the actual type I error rate of this procedure? \u000fIf we have ksignicance test of size a, the probability of at least one false positive result is 1\u0000(1\u0000a)kFora=0:05, k 1 2 3 4 5 10 P[false positive] 0:05 0 :0975 0 :143 0 :186 0 :401 We given Zt=pn1pntz1+pn2pntZ2;CHAPTER 3. SELECTED TOPICS IN BASIC STATISTICS 19 andZt>cis equivalent to Z2>pntpn2c\u0000pn1pn2z1: Theconditional type I error rate given Z1=z1is P\u0014 Z2>pntpn2c\u0000pn1pn2z1 Z1=z1\u0015 : And by intergrating this conditional type I error rate with respect to the distribution of Z1, we get unconditional type I error rate for the second stage ( a2): a2=Zc \u0000\u00a5\u0014 1\u0000F\u0012pntpn2c\u0000pn1pn2z1\u0013\u0015 f(z1)dz1: If to a2=Zc \u0000\u00a5(1\u0000F(c))f(z1)dz1= (1\u0000F(c))F(c): Divide by the control mean Suppose we are interested in comparing two treatment groups. Take random samples of size 9 from each group ( x11;\u0001\u0001\u0001;x19;x21;\u0001\u0001\u0001;x29). We want to test H0:m1=m2. But weCHAPTER 3. SELECTED TOPICS IN BASIC STATISTICS 20 may be worried that the \"background noise\" is different for these two groups, so we take random samples of size 3 representing background. c11;c12;c13and c21;c22;c23. Then we may \"normalize\" x's by dividing by the average of the corresponding control group. yi j=xi j=\u00afci\u0001.i=1;2;j=1;\u0001\u0001\u0001;9. Suppose Xi\u0018Normal (mi;s2 x), and Ci\u0018Normal (ni;s2 c). What is the distribution of Y? Suppose that m1=m2=120,n1=n2=30;sx=4;sc=3. Then if we use a t-test on yi j, type I error rate is about ... . NxNcsxsca 9 3 4 3 0:69 9 3 4 0 :40:08 9 3 4 0 0:05 90 30 4 3 0:72 9 300 4 3 0:05 A simple remedy is to use a regression approach (analysis of variance). Y=b0+b1Xg+b2Xt+b12XgXt+e; where Xg=0if group 1, 1otherwise; Xt=0if control, 1otherwise. Then the expected group means are Control Treatment Group 1 b0 b0+b2 Group 2 b0+b1b0+b1+b2+b12 Interpretation of the regression parameters: b0Group 1 control meanCHAPTER 3. SELECTED TOPICS IN BASIC STATISTICS 21 b1Difference of control means b2Treatment - Control in group 1 b12Group 2T - Group 1T - Difference of control means Thus testing b12=0is testing for the treatment difference taking into account the control difference. Type I error rate by simulation ( B=10;000) unweighted weighted ( 1=s2) weighted ( 9 3 4 3 0:026 0 :051 0 :063 9 3 4 0 :4 0:002 0 :052 0 :053 90 30 4 3 0:024 0 :050 0 :050 200 30 4 3 0:050 0 :051 0 :053 90 200 4 3 0:083 0 :050 0 :055 90 200 4 0 :054 0 :054 If 'fold change' is desired like in this example, perhaps, we can take logarithm of all values before tting the regression model. log(Y) Brief introduction to simple Bayesian analysis 4.1 Introduction \u000fWhat is the philosophical difference between frequentist and Bayesian statistics? To a frequentist, unknown model parameters are xed, and only estimable by repli- cations of data from some experiment. A Bayesian thinks of parameters as random that have distributions like the data. \u000fHow does it work? -Start with a prior guess for q(usually a distribution). -Update the information by combining it with the data X. -Obtain a posterior distribution of q. -All statistical inferences follow from the posterior distribution. \u000fAdvantages of Bayesian methods. -ability to incorporate prior information -stopping early does not affect the inference in the way frequentist approaches do (e.g., inflation of type I error rate). -Interpretation of the result is easier 22CHAPTER 4. BRIEF INTRODUCTION TO SIMPLE this theorem, you can switch the event of interest and condition. For instance, we are usually interested in P[disease jtest positive], but the observed data are usually P[test positivejdisease]. As long as you can compute P[test positive] and know P[disease], you can make the switch. In terms of updating distributions, the theorem is written as p(qjy) =p(yjq)p(q) p(y); where p(q)is the prior distribution, p(yjq)is the likelihood, and p(qjy)is the posterior distribution. It is often written as p(qjy)\u00b5p(yjq)p(q): 4.3 Example 4.3.1 Normal distributions Suppose we are interested in the long-term systolic blood pressure (SBP) in mmHg of a particular 60 year old female. We take two independent readings 6 weeks apart, and their mean is 130. We know that SBP is measured with a standard deviation s=5. (from \"Bayesian Approaches to Clinical Trials and Health-Care Evaluation\" by Speigelhalter, et al.) With a Frequentist approach, 95% condence interval is 130\u00061:96(5=p 2) = 123:1;136:9):CHAPTER 4. BRIEF INTRODUCTION TO SIMPLE BAYESIAN ANAL YSIS 24 With a Bayesian approach, we can incorporate a prior belief that females aged 60 have a mean long-term SBP of 120 with standard deviation 10. Let's also assume that the prior distribution is normal. (prior = normal, likelihood = normal), that is, qis Normal\u0012n0q0+my n0+m;s2 n0+m\u0013 : In general, if the prior distribution is q\u0018N(q0;t2)and the likelihood is y\u0018N(q;s2 m), then the posterior distribution is p(qjy)\u0018N\u0012q0=t2+y=s2 m 1=t2+1=s2m;1 1=t2+1s2m\u0013 : Going back to the current example, we have as the prior distribution and the likelihood, q\u0018N(120;102); yjq\u0018N(130;52=2): (We can solve for n0to get n0=52=10=0:25, which implies that the prior information is equivalent to a sample of size 0:25.)CHAPTER 4. BRIEF INTRODUCTION TO SIMPLE BAYESIAN ANAL YSIS 25 Continuing, we have =n0q0+my as: 128:9\u00061:96(3:33) = ( 122:4;135:4); and say the probability that qis between 122:4and 135:4is95% and mean it.CHAPTER 4. BRIEF INTRODUCTION TO SIMPLE BAYESIAN ANAL YSIS 26 100 110 120 130 140 Prior distribution 100 110 120 130 140 Likelihood 100 110 120 130 140 Posterior distribution 4.3.2 Beta-Binomial In the last example, we start with a normal prior, use a normal likelihood, and arrive at a normal posterior. Things are not always that nice. Oftentimes, the posterior distribu- tion does not have a closed form. The last example is a case of a conjugate analysis.CHAPTER 4. BRIEF INTRODUCTION TO SIMPLE BAYESIAN ANAL YSIS 27 Conjugate models occur when the posterior distribution is of the same family as the prior distribution. Other examples include: prior likelihood posterior Normal Normal Normal Beta Binomial Beta Gamma Poisson Gamma In a phase I or II clinical trial, the response of interest is often a probability (e.g., probability of a toxic reaction and of a positive response), and we would like to use a Binomial dis- tribution to model the number of certain events of interest. There, a Beta-binomial model can be used Example In a safety study, we would like to estimate the probability of severe drug-related adverse event associated with a treatment of interest. We have an access to the data from another similar study that showed 7out of 117had a severe adverse event. LetXbe the number of toxic reactions out of mpatients in our study, and we have Xjp\u0018Binomial (m;p): And let the prior distribution of It can be shown that the expectation and variance of a Beta random variable are E[p] =a a+b; integer k,G(a+k) =G(a)a(a+1)(a+2)\u0001\u0001\u0001(a+k\u00001).) Therefore, the posterior distribution of pisBeta(a+x;b+m\u0000x). What do aandbmean in relation to xandm\u0000x? If we chose to use Beta(7;110), this prior gives equal weight for the two studies, i.e., a patient in the previous study counts as much as a patient in the new study. If we want to almost completely disregard the prior information, we would use e.g., Beta(1;1), which is equivalent to having a sample size of 2 (one response / one non-response). Suppose we want to use the prior information, but discount it so that it is only equivalent to 20 patients with P[toxicity ] =7=117. So the prior distribution of pisBeta(1:2;18:8) Let's say in our study with sample of size 40, there were 5 toxicity reactions. Thus the likelihood function is f(p) =p5(1\u0000p)35, and the posterior distribution is f(pjx) BRIEF INTRODUCTION TO SIMPLE BAYESIAN ANAL YSIS 29 0.0 0.1 0.2 0.3 0.4 0.5 Prior distribution 0.0 0.1 0.2 0.3 0.4 0.5 Likelihood 0.0 0.1 0.2 0.3 0.4 0.5 Posterior distribution Using the posterior distribution, Beta(6:2;53:8), we YSIS 30 From the data alone, a frequentist condence interval on pis(0:042;0:27). A Bayesian credible interval is (0:04;0:19), which is much narrower.Chapter 5 Randomization in clinical trials 5.1 Introduction Randomization assignment of patients or experimental subjects to two or more treat- ments by chance alone. Main advantages of randomization \u000fIt removes the potential of bias in the allocation of participants to the intervention group or to the control group (allocation bias). \u000fIt tends to produce similar (compatible) groups in terms of measured as well as unmeasured confounders See confounding by indication in observational studies. \u000fIt guarantees the validity of statistical tests of signicance e.g., t-test for comparing two means can be justied on the basis of randomiza- tion alone without further assumptions about the distribution of baseline variables. (Permutation test / randomization test) 31CHAPTER 5. RANDOMIZATION IN CLINICAL TRIALS 32 Randomization is considered so important that the intention-to-treat principle considered sacrosanct: \"Analyze by assigned treatments irrespective of actual treatment received.\" Perceived disadvantages of randomization are often about emotional and ethical issues. !randomization before consent 5.2 Example: The Salk Vaccine Field Trial \u000fIn 1954, the Public Health Service decided to organize an experiment to test the polio vaccine developed by Jonas Salk. \u000f2 million children in selected school districts throughout the US were involved. -Should all children have been vaccinated? 60,000 cases in 1952; about half in 1953. -Needed the parents' consent. -Half of the children with consent were randomized into vaccine. \u000fThe National Foundation for Infantile Paralysis (NFIP) wanted to vaccinate all grade 2 children with consent with grades 1 and 3 acting as controls. -Polio is a contagious disease! -Grades 1 and 3 children did not require consent. Systematic differences between groups. -No way to blind the study. the Results of the SVF trial source: Freedman et al. Statistics second edition The randomized controlled double-blind experiment size Rate1 Treatment 200;000 26 Control 200;000 71 No consent 350;000 46CHAPTER 5. RANDOMIZATION IN CLINICAL TRIALS 33 The NFIP design size Rate1 Grade 2 (vaccine) 225;000 25 Grade 1 & 3 (control) 725;000 54 Grade 2 No consent 125;000 44 1Rate of polio cases per 100;000. 5.3 Simple randomization For each subject, flip a coin to determine treatment assignment. P[treatment 1] =\u0001\u0001\u0001= P[treatment k] =1=k. https://cqs.mc.vanderbilt.edu/shiny/GOLD Problems and how to deal with them. \u000fImbalance in treatment allocation -replacement randomization -block randomization -adaptive randomization (biased coin / patient characteristics -stratied adaptive randomization (play the winner)CHAPTER 5. RANDOMIZATION IN CLINICAL TRIALS 34 5.4 Imbalance in treatment allocation If the number of patients, Nis20,P[10and 10] =0:18.Xt\u0018Binomial (20;:5). The probability of7to13split worse is The treatment effect variance as 10-10 split. Even if treatment allocation is balanced at the end of trial, there may be a (severe) imbal- ance at some point. Because we monitor trials over time, we prefer to have balance over time. 5.4.1 Block randomization To ensure a better balance (in terms of number of patients) across groups over time, consider a block randomization (random permuted blocks). Block randomization ensures approximate balance between treatments by forcing balance after a small number of patients (say 4 or 6). For example, the rst 4 patients are allocated to treatment A or B sequentially based on AABB . There are 6 sequences of A,A,B,B, and let each sequence have 1/6 chance of being selected. AABB ABAB ABBA BAAB BABA BBAA \u000fWhat's wrong with block size of 2? block size of 200? \u000fEasily applicable to more than 2 groups ( A,B,C) \u000fEasily applicable to unequal group sizes ( Na=40andNb=20).CHAPTER 5. RANDOMIZATION IN CLINICAL TRIALS 35 Why might we want unequal group sizes? \u000fWe may want to have a better estimate of the effect for the new treatment. \u000fTreatment costs may be greatly different. Given the total sample size and the relative cost of treatment 2 to treatment 1, we can nd the optimal allocation ratio to minimize the total cost. (More in sample size computation) \u000fVariances may be different. Suppose the means, m1andm2, of treatment groups are being compared using Z=(\u00afX1\u0000\u00afX2)\u0000(m1\u0000m2)q s2 1=n1+s2 2=n2: For a given N=n1+n2, the test statistic is maximized when the denominator is minimized. Solving \u00b6 \u00b6n1\u0012s2 2 Therefore, the optimal allocation ratio is r=n1=n2=s1=s2. Analysis should account for the randomization scheme but often does not. Matts and McHugh (1978 J Chronic Dis ) point out that \u000fbecause blocking guarantees balance between groups and increases the power of a study, blocked randomization with the appropriate analysis is more powerful than not blocking at all or blocking and ignoring it in the analysis. \u000fnot accounting for blocking in analysis is conservative.CHAPTER 5. RANDOMIZATION IN CLINICAL TRIALS 36 5.4.2 Biased coin and urn model These techniques are sometimes classied as \"adaptive randomization\". Allocation of i-th patient depends on how many have been randomized to group A ( na) and group B ( nb). Any given time, the probability of allocation to group A may be P[A] =nb na+nb: Or the rule may =2=3when nb\u0000na>5, and P[B] =2=3when na\u0000nb>5. Characteristics of such a randomization scheme are often studied by simulations. An urn model is one type of biased coin randomization. \u000fPrepare an urn with one Amber ball and one Blue ball. \u000fPick one ball and make the corresponding treatment assignment (A/B). \u000fPut a ball of the opposite color in the urn. 5.5 Imbalance in baseline patient characteristics Block randomization and biased coin model ensure that the group sizes are reasonably balanced. In order to facilitate the comparison of treatment effects, balance on important baseline variables is sometimes desired. \u000fRandomization does not guarantee all the measured variables will be balanced. And imbalance does not mean randomization did not work.CHAPTER 5. RANDOMIZATION IN CLINICAL TRIALS 37 \u000fQuoting Senn (1994), \"It is argued that this practice [testing baseline homogeneity] is philosophically unsound, of no practical value and potentially misleading. Instead it is recommended that prognostic variables be identied in the trial plan and t- ted in an analysis of covariance regardless of their baseline distribution (statistical signicance).\" \u000fQuoting Piantadosi, \"These methods, while theoretically unnecessary, encourage covariate balance in the treatment groups, which tends to enhance the credibility of trial results.\" 5.5.1 Stratied randomization Stratied randomization is applied to ensure that the groups are balanced on baseline variables that are thought to be signicant. \u000fCreate strata based on the variables for which balance is sought. e.g., (Male, 65 or younger), (Male, older), (Female, younger), (Female older) \u000fRandomize to treatments within each stratum. Use block randomization! What's wrong with -using simple randomization within a stratum? -using too many strata? \u000fStratication should accounted for in analysis. -Pre-randomization stratication and post-randomization stratication (at time of analysis) has no clear winner. -If trial is large, stratication may not be necessary -Stratication by center is a good idea from practical viewpoints. \u0003allows randomization to be hosted at each site \u0003allows sites to be removed and still maintains balance \u0003If each stratum has a target size, plans need to be in place to close down recruitment based on the baseline characteristics. e.g., \"We do not need any more (Male, older)\".CHAPTER 5. RANDOMIZATION IN CLINICAL TRIALS 38 -Block randomization is a special type of stratied randomization where strata are dened by ... . 5.5.2 Adaptive and minimization randomization Adaptive randomization can be used to reduce baseline imbalance: \u000fDene an imbalance function based on factors thought to be important \u000fThen use a rule to dene P[treatment A] so that the next assignment is more likely to reduce imbalance. For example, the factors to balance are sex (male/female) and hypertension (yes/no), and let the imbalance function be I=2\u0002(sex imbalance )+3\u0002(hypertension imbalance ): The patients randomized so far are Sex Hypertension male female yes no Group 1 10 3 8 5 Group 2 8 3 6 5 The next patient is male-non hypertensive. The imbalance will be I=2\u0002(11\u00008)+3\u0002(6\u00005) =9if group group 2. Thus let P[Group 2] =2=3. Minimization randomization uses the same idea but use P[Group 2] = 1, to eliminate randomness when there is some imbalance. Randomize only when to assign the next patient to either group gives the same value of I.CHAPTER 5. RANDOMIZATION IN CLINICAL TRIALS 39 5.6 Response adaptive randomization As the name suggests, response adaptive randomization methods use the information about the response so far to allocate the next patient. Play the winner : The idea is to allocate more patients in the treatment that seems to be working better. To apply these methods, it is necessary to have a response rather quickly. Urn model can be used to make treatment assignment imbalance based on the results (success/failure) of each treatment so far. (e.g., put one blue ball if the treatment B yields success.) Instead of updating the probabilities of treatment assignment after each patient, we can update them after a group of patients' results are available to reduce administrative bur- den. In a phase II clinical trial, play the winner design may be used to reduce the number of treatments in consideration. (e.g., only retain the treatment arms that have P[positive response] >0:4.)Drop the loser has a rule like, \"drop the treatments from further con- sideration if P[positive response] <0:2.Chapter 6 Phase I clinical trials 6.1 Introduction Phase I clinical trial is the rst study in which a new drug is administered in humans. The primary objectives of phase I studies are 1) to collect pharmacokinetic and pharma- cokynamic data, and 2) to establish safety with a specic goal to estimate the maximum tolerated dose (MTD). Customarily, the MTD is the dose level at which the probability of dose-limiting toxicity (DLT) is 33% (or maybe 20%). Assumption Higher dose is more effective. We assume that the highest safe dose is the dose most likely to be effective, in other words, we are using dose-related toxicity as a surrogate for efcacy. Phase I clinical trial is also known as ... Treatment mechanism Early developmental trial that investigates mechanism of treat- ment effect. (e.g., pharmacokinetics) 40CHAPTER 6. PHASE I CLINICAL TRIALS 41 Dose escalation Design that species methods for increase in dose for subsequent sub- jects. Dose-ranging Design that tests some or all of a prespecied set of doses (xed doses) Dose-nding Design that titrates dose to a prespecied optimum based on biological or clinical considerations In oncology and AIDS trials, patients usually participate in phase I trials, but in other disease areas, data are gathered on healthy volunteers. Reasons patients do not participate in \"other\" phase I trials \u000fIt may be difcult to recruit from patient population. \u000fLow risk of serious adverse events justies participation of healthy volunteers. \u000fNo potential confounding of adverse events with disease or concomitant medica- tions. The primary reason to recruit patients into a phase I clinical trial is known toxicity. (cyto- toxic drug) Who are the healthy volunteers? \u000fusually 18-35 years \u000fusually male \u000fnon-smoker / non substance abuse \u000fno symptoms of disease \u000fno laboratory abnormalitiesCHAPTER 6. PHASE I CLINICAL TRIALS 42 FDA uses the terminology, \"normal volunteers\" (Guidance for industry: General consider- ations for the clinical evaluation of drugs), but who are normal? \"With respect to the use of 'normal' subjects it should be recognized that few people are literally normal in all respects. This term should be interpreted with caution and should mean volunteers who are free from abnormalities which would complicate the interpreta- tion of the experiment or which might increase the sensitivity of the subject to the toxic potential of the drug.\" 6.2 Non-cancer, non-AIDS phase I Most phase I studies are placebo controlled to reduce observer bias and facilitate com- parison between active drug and placebo. In a typical design, subjects are assigned to a cohort of size 8 to 10; 6 to 8 subjects are assigned to the active treatment (same dose) and 2 to placebo. If deemed safe, the next cohort of the same size are given one higher dose. The trial is stopped when an unacceptable number of adverse events is observed; the highest safe dose is the target dose that will be recommended for future trials. More complex dose administration patters involve the administration of multiple doses to one patient. (Grouped crossover escalation) Starting dose One popular starting dose is based on the dose that causes 10% mortality in rodents on amg=m2(per body surface) basis ( LD10). Usually we use LD10=10as the starting dose. An FDA document (Guidance for industry. Estimating the maximum safe starting dose in initial clinical trials for therapeutics in adult healthy volunteers) provides a conversion table for this purpose. Increments Linear (arithmetic) D,2D,3D,4D,\u0001\u0001\u0001(known toxic drug) Log (geometric) D,2D,4D,8D,\u0001\u0001\u0001(typical)CHAPTER 6. PHASE I CLINICAL TRIALS 43 Table 6.1: Conversion of animal dose to human equivalent doses based on body surface area Species mg=kgtomg=m2animal mg=kgto HED mg=kg Multiply by Multiply by Human 37 - Child ( 20kg)\u000325 - Mouse 3 0:08 Hamster 5 0:13 Rat 6 0:16 Ferret 7 0:54 TGN1412 disaster Some highlights of the story \u000fintended for the treatment of B cell chronic lymphocytic leukemia and rheumatoid arthritis \u000fphase I clinical trial in Britain on March 13, 2006 \u000f6 healthy volunteers took a sub-clinical dose of 0:1mg=kg(1=500of the dose found safe in animals) -all male, aged 19 to 34 (median 29.5) \u000fDrugs were given by intravenous infusion with an interval of around 10 minutes between patients \u000fAll men suffered from a cytokine storm (the men's white blood cells had vanished almost completely several hours after administration of TGN1412.)CHAPTER 6. PHASE I CLINICAL TRIALS 44 \u000fAll men were hospitalized, but none died. 6.3 3 + 3 design Many variations exist to these so-called \"up-and-down designs\" / \"3+3\" designs, but the basic idea is: 1. 3 patients are allocated to a dose level. (a) If there is 0 toxicity reaction then 3 patients will be assigned to the next dose level. (b) If there is 1 toxicity reaction then 3 patients will be assigned to the current dose level. (c) If there are 2 or 3 toxicity reactions, then the current dose will be closed (too toxic) and 3 patients will be assigned to the previous dose level. 2. Continue until \u000fthe next dose already has had 6 patients. \u000fthere is no more higher/lower dose 3. The MTD is the highest dose with at most 1 toxicity reaction out of 6. (Generally, the MTD has to have data from 6 patients.) In general there are four components to the typical dose ranging design: 1. selection of a starting dose 2. specication of the dose increments and cohort sizes 3. denition of dose limiting toxicities Toxicities that, due to their severity or duration, are considered unacceptable and limit further dose escalation within the subject. (These need to be pre-dened.)CHAPTER 6. PHASE I CLINICAL TRIALS 45 4. decision rules for escalation and de-escalation Notes: \u000fThe starting dose is usually the lowest dose, but it does not have to be. \u000fThe dose level for the next patient may not be known when he/she is available to be allocated. \u000fThe best outcome is selection of the dose level that is closest but does not exceed the MTD. \u000fThis design is not motivated with statistics in mind. The probability of selecting the right dose can be very low. The right dose may not even have the highest probability of being selected. \u000fEstimation of the true dose or the true probability of a toxicity reaction for a given dose is difcult. This process usually underestimates the MTD. \u000fThe frequency of stopping escalation at a certain dose level depends on toxicity rate at that dose as well as the rates at all levels below. \u000fOn average the dose chosen by the 3+3 design has the probability of toxicity of about 20% to25%. The operating characteristics studied by Reiner et al. (1999); Lin and Shih (2001); Kang and Ahn (2001, 2002). Modied Fibonacci dosing In addition to arithmetic and geometric sequence, the Fibonacci sequence is often used. Fn=0;1;1;2;3;5;8;13;21;\u0001\u0001\u0001 Based on this sequence, one possible dose escalation isCHAPTER 6. PHASE I CLINICAL TRIALS 46 Dose D2\u0002D 2468 Dose 1 2 3 4 5 6 71Relative dose escalation log linear m.fCHAPTER 6. PHASE I CLINICAL TRIALS 47 6.3.1 Accelerated titration The basic idea is the same as the up-and-down design, and the key modication is that a cohort of one patient is used until the rst toxicity reaction is observed. Dose escalation may be at 100% or40%in the accelerated steps. Another improvement from 3+3 design is that this design allows intra-patient dose escalation if no dose-limiting toxicity is observed for that patient. 6.4 Bayesian approach: CRM Because of their sequential nature, \"3+3\" design and its variant tend to yield a biased underestimate of the target dose when estimating the MTD. One dose-nding (ranging) design that is not subject to this bias as much is the continual reassessment method (CRM). One obvious advantage of the CRM is its use of an explicit mathematical model describing the relationship between dose and toxicity. Parameters underlying a dose-toxicity curve are given as priors. These prior values are updated sequentially and used to nd the current \"best\" estimate of dose that would produce the acceptable risk of a toxic event. The CRM is an algorithm for updating the best guess regarding the optimal dose. It does not require a set of xed dose levels. The CRM algorithms make no assumptions about 1. the actual dose used 2. the cohort size 3. ordering of doses 4. integer responsesCHAPTER 6. PHASE I CLINICAL TRIALS 48 6.4.1 Example (Dougherty et al. (2000)) Suppose we want to nd the dose that is associated with 20% toxicity, and the available doses are 0:25,0:50,0:75, and 1:00. The dose-toxicity relationship is written with a one- parameter logistic response model log\u0012pi 1\u0000pi\u0013 =3+adi; where diis the dose level ( i=1;2;3;4) and piis the toxicity probability for dose i, and a is an unknown parameter. 0.00.20.40.60.81.0 Dose levelsProbability of toxicity a=0.75 a=1.00 a=1.25 a=1.50 For the prior distribtion of awe choose to use an exponential distribution with mean 1. The actual prior information is usually written in terms of the prior probabilities of toxicity at each dose. In this example, let's say we have 10%,20%,40%, and 80% for each of theCHAPTER 6. PHASE I CLINICAL TRIALS 49 four dose levels ( p0 i). At ithdose, we have di=logit(p0 i)\u00003 Dose Prior Level Actual dose p0 i(prior guess) di 1 0 :25 0:10\u00005:20 2 0 :50 0:20\u00004:39 3 0 :75 0:40\u00003:41 4 1 :00 0:80\u00001:61 0.00.20.40.60.81.0 Dose levelsProbability of toxicity 12 3 4Prior (a=1) Other possible model is pi=f(tan\u00001xi+1)=2ga:CHAPTER 6. PHASE I CLINICAL TRIALS 50 If we let the prior value of a=1, we can solve for the corresponding xiof each pi, xi=tan(2p0 i\u00001) Dose Prior Level Actual dose p0 i(prior guess) xi 1 0 :25 0:10\u00001:03 2 0 :50 0:20\u00000:68 3 0 :75 0:40\u00000:20 4 1 :00 0:80 0 :68CHAPTER 6. PHASE I CLINICAL TRIALS 51 0.00.20.40.60.81.0 Dose levelsProbability of toxicity 123 4Prior (a=1) 0.00.20.40.60.81.0 a=0.50 a=1.00 a=1.50 a=2.00CHAPTER 6. PHASE I CLINICAL TRIALS 52 Steps for updating information 1. Treat a cohort of 1 patient at the lowest dose. 2. Obtain a posterior distribution of a. 3. Find the optimal dose that gives 20% toxicity using the posterior distribution. 4. Treat another patient at the dose closest to the optimal dose. 5. Repeat steps 2, 3, 4. The trial continues until a predetermined xed sample size is reached, or some other trial terminating condition is satised. With regard to step 2 (nding the posterior distribution), we only need the expected value ofaso that it can be plugged into the dose-toxicity equation, and expectation of ais E[a] =R\u00a5 0aL(a;dj;tj)g(a)daR\u00a5 0L(a;dj;tj)g(a)da; where Lis likelihood as L(a;dj;tj) =J \u00d5 j=1[f(dj;a)]tj[1\u0000f(dj;a)]1\u0000tj; where 0otherwise for the jthpatient; and f(dj;a) =exp(3+adj) 1+exp(3+adj): This is usually beyond analytical solution, so we use simulations. One result from such simulation is given below: \u000fThe posterior means of pishow strong agreement with the prior.CHAPTER 6. PHASE I CLINICAL TRIALS 53 Dose Prior Observed data Posterior Level Actual dose p0 i(prior guess) di # patients # toxicity mean sd 1 0 :25 0:10\u00005:20 4 0 0:10 0 :05 2 0 :50 0:20\u00004:39 18 3 0:19 0 :08 3 0 :75 0:40\u00003:41 3 2 0:38 0 :09 4 1 :00 0:80\u00001:61 0 0 0:79 0 :03 \u000fThe actual doses do not enter into the model. \u000fA tolerability for dose 4 is estimated with considerable accuracy, even though no one was ever given the dose. -!This method should be used with great caution. The CRM method is sometimes criticized for begin falsely precise. However, it has been demonstrated that the CRM is more efcient and less biased than classic designs. Using R A number of packages and functions are available in R. Over a hundred packages are listed on cran.r-project.org/web/views/Bayesian.html . For analysis (as opposed to design) of the data, bcrm (Bayesian continuous reassessment method) seems compre- hensive and easy to use. An alternative is CRMavailalbe at https://biostatistics.mdanderson.org/SoftwareDownload/ . Let's continue with the same example with four dose levels. Recall the prior guess of toxicity probabilities are 10%,20%,40%, and 80% for each of the four dose levels. Doses are0:25,0:50,0:75,1:00. The function, bcrm, is used to compute prior distribution sequentially. The key inputs are: NThe nal sample size toxnumber of toxicity reactions for each doseCHAPTER 6. PHASE I CLINICAL TRIALS 54 notox number of patients with no toxicity reactions p.tox0 prior probabilities dose actual dose for plotting purposes fffunctional form of the dose-response curve. ( logit1 ) prior.alpha prior distribution for a. (Uniform ) cohort the size of each cohort target.tox the target toxicity probability constrain whether if dose skipping is allowed 6.5 Modied Toxicity Probability Interval Design \u000fJi Y , Li Y , Bekele BN. Dose-nding in phase I clinical trials based proba- bility intervals. Clinical Trials . 2007; A modied toxicity probability nding trials. Clinical Trials . 2010; 7:653-63. 3 + 3 design is known to underestimate the MTD. In the following, the probabilities of concluding a dose as the MTD are studied. Suppose that our task is to select one dose out of 5 as the MTD. The true dose-toxicity associations are depicted below. The pink one is the desired dose at which the toxicity probability is 33%.CHAPTER 6. PHASE I CLINICAL TRIALS 55 Scenario 1 True toxicity Dose levels10%30%50% 12345Scenario 2 True toxicity Dose levels10%30%50% 12345 Scenario 3 True toxicity 10%30%50% 12345Scenario 4 True toxicity 10%30%50% 12345 The line indicates the probability of concluding each dose as the MTD. The point at left of dose 1 shows the probability of even the lowest dose to be declared too toxic. It is well-known (among statisticians) that 3 + 3 designs are horrible. CRM has not gained much acceptance from the clinical investigators. The mTPI is placed somewhere in be- tween these two approaches. 3 + 3 CRM mTPI Bayesian \u2014 Y es Y es Model based \u2014 Y es \u2014 Coherent P[Tox] \u2014 Y es \u2014 Estimate P[Tox] \u2014 Y es Y es Any target \u2014 Y es Y es Any sample size \u2014 Y es Y es Any cohort size \u2014 Y es Y es Easy Y es \u2014 Y es Estimation of P[Toxcitiy] at each dose in mTPI uses the Beta-Binomial conjugate model. Typically, we use a non-informative prior for each dose level.CHAPTER 6. PHASE I CLINICAL TRIALS 56 0.00.20.40.60.81.0 P[Toxicity]Prior / 5 0.00.20.40.60.81.0 P[Toxicity]2 / 8 0.00.20.40.60.81.0 P[Toxicity]4 / 12 Decision to go up or down or stay at the current dose is based on the Unit Probability Mass (UPM) computed with the posterior distribution. First, an interval around the target dose is dened as the \"target interval\". For example, with Target =20%, we may choose to use 14%to22% as the target interval. Then anywhere below 14% will be \"too low\", and anywhere above 22% will be \"too high\". And when a decision is sought, we cmpute the UPM for each of the three interval and pick the maximum UPM. The UPM is basically \"Area\" =\"Width\" cmoputed using the distribution.CHAPTER 6. PHASE I CLINICAL TRIALS 57 0.00.20.40.60.81.0 P[Toxicity]4/9 For this example, we have Too low 0:12 Just right 0:74 Too high 1:18 Thus, so the decision is to de-escalate. With mTPI, the \"escalate/stay/de-escalate\" decision is simple, and it only depends on the data at that dose. We can compute for each n-xcombination the UPM and specify the course of action. The following table summarizes the design for the target toxicity probability of 33% and 33%\u00065%as the target interval. Example: Target =33%CHAPTER 6. PHASE I CLINICAL TRIALS 58 Cumulative sample size Cumulative Toxicity 1 2 3 4 5 6 7 8 9 \u0001\u0001\u0001 0 E E E E E E E E E 1 D S S S S E E E E 2 DU D S S S S S S 3 DU DU D S S S S 4 DU DU DU D S S 5 DU DU DU DU D 6 DU DU DU DU 7 DU DU DU 8 DU DU 9 DU mTPI is simple and ... \u0001\u0001\u0001 \u000fAllows estimation of toxicity probability. \u000fTends to require a larger sample size than 3 + 3. \u000fSeems to have favorable characteristics. It is still unclear (as of June, 2015), how the regulatory body sees the mTPI. The following is a letter from CTEP (Cancer Therapy Evaluation Program -NCI) that provides some guidelines when CRM or mTPI is proposed. \"CTEP appreciates the desire to improve clinical trial designs. At the same time safety of patients and resource management are CTEP's priority.\" 1. New patients should not be assigned to a dose level at which 4 or more patients have been fully evaluated and \u001533% of the patients have experienced a DLT. 2. New patients should not be assigned to a dose level above a dose level where \u001533% of the fully evaluated patients have experienced a DLT. 3. At any dose level, limit the number of patients that should be enrolled (preferably no more than 12).CHAPTER 6. PHASE I CLINICAL TRIALS 59 4. After the rst 3 patients have been fully evaluated for DLT, if 1 out of 3 DLTs have been observed then up to 3 additional patients may be accrued to the dose level.Chapter 7 Phase II clinical trials 7.1 Introduction Phase II clinical trial A clinical trial designed to test the feasibility of, and level of activity of, a new agent or procedure. (safety and activity) Some characteristics of a typical phase II clinical trial include: \u000fit includes a placebo and two to four doses of the test drug. \u000fwhen the response is observed quickly, adaptive designs may be benecial and used because they -improve quality of estimation of the MED (minimum effective dose (lowest dose of a drug that produces the desired clinical effect) -increase number of patients allocated to MED. -allow for early stopping for futility. The primary objectives of phase II trials are: 60CHAPTER 7. PHASE II CLINICAL TRIALS 61 \u000fto determine whether the drug is worthy of further study in phase III trial. Signicant treatment effect? / dose-response relationship? \u000fto gather information to help design phase III trial -determine dose(s) to carry forward -determine the primary and secondary endpoints -estimate treatment effects for power/sample size analysis -estimate recruitment rate -examine feasibility of treatment (logistics of administration and cost) -learn about side effects and toxicity In phase II clinical trials, parallel group designs, crossover designs, and factorial designs are often used. 7.2 Phase II trials in oncology A phase II clinical trial in oncology generally uses a xed dose chosen in a phase I trial. The primary objective is to assess therapeutic response to treatment. In the simplest case, a single treatment arm is compared to a historical control. In other cases, a control group and/or multiple doses are included. The treatment efcacy is often evaluated on surrogate markers for a timely (quick) evalu- ation of efcacy. Surrogate outcome an outcome measurement in a clinical trial that substitutes for a denitive clinical outcome or disease status \u000fCD4 counts in AIDS study \u000fPSA (prostatic specic antigen) in prostate cancer study \u000fblood pressure in cardiovascular diseaseCHAPTER 7. PHASE II CLINICAL TRIALS 62 \u000f3 months survival (binary) for survival \u000ftumor shrinkage for survival Tumor response to treatment is evaluated according to Response Evaluation Criteria in Solid Tumors (RECIST) Complete response (CR) Disappearance of all target lesions Partial response (PR) At least a 30% decrease in the sum of the longest diameter (LD) of target lesions, taking as reference the baseline sum LD Stable disease (SD) Neither sufcient shrinkage to qualify for PR nor sufcient increase to qualify for PD, taking as reference the smallest sum LD since the treatment started Progressive disease (PD) At least a 20% increase in the sum of the LD of target lesions, taking as reference the smallest sum LD recorded since the treatment started or the appearance of one or more new lesions Generally, objective tumor response is dened as CR or PR in RECIST so that the re- sponse variable has a binary endpoint. In the rest of chapter, we will consider a single arm trial with a binary response. The hypothesis of interest is one-sided H1:p>p0, and the type I error rate is usually 5to10%. The power is usually 80to90%. 7.3 Two-stage designs It is crucial that these phase II studies have an opportunity to stop early for toxicity, and that is accomplished by Data Monitoring Committee (DMC), aka, Data and Safety Monitor- ing Board (DSMB). It is also desired to discard ineffective treatment early, and two-stage designs with a futility stop has been popular. We will discuss the designs proposed by Gehan (1961), Fleming (1982), and Simon (1989), using the following unied notation:CHAPTER 7. PHASE II CLINICAL TRIALS 63 \u000fstage I sample size \u0001\u0001\u0001n1. \u000fstage I data\u0001\u0001\u0001X1\u0018Binomial (n1;p). \u000fstage I critical value \u0001\u0001\u0001r1so that if X1\u0014r1then terminate the study for futility. \u000fstage II sample size value \u0001\u0001\u0001rtso that if Xt\u0014rtthen terminate the study for futility, other- wise conclude efcacy. 7.3.1 Gehan's design It is old (1961) and outdated but may be ok to use in limited situations. The design calls for the rst stage with n1=14and r1=0, i.e., if no positive response is observed in 14, then stop for futility. The rational is that if true response rate is at least 20%, then X1=0 is unlikely. In fact, it is 0:044. The second stage sample size depends on the desired precision for estimating p, and it ranges between 1and 86. A typical n2is14so that nt=25. With nt=25, a standard error of pis approximately 0:10; such a standard error leads to a very wide condence interval. 7.3.2 Fleming's design Fleming (1982) proposed a multistage design for phase II clinical trials. One of its key characteristics is stopping early for efcacy. Example H0:p=0:15,H1:p=0:30. (powered at 0:30) a=:05,b=:2 (Reject H0in stage 1 if X1\u0015s1.CHAPTER 7. PHASE II CLINICAL TRIALS 64 n1r1s1ntrt a 1\u0000b E0[N]E1[N] 29 4 9 :8013 36:6 36 :9 7.3.3 Simon's design In his 1989 paper, Simon introduced two criteria to choose a 2 stage design for single arm and one sided tests. The optimal design has the smallest expected sample size under H0(n1+Ep0[n2]), and the minimax design has the smallest total p0=0:15and 0 :68 50:2 0 11 0:046 0 :804 34:5 0 :54 46:7 0 11 0:048 0 :819 48:0 0 :00 48:0 0 :00 Conditional power To nd a good design (sample sizes and critical values), we need to understand the conditional power of a design. The conditional power is the probability of rejecting H0 (in stage 2) given the stage 1 result, i.e., conditioned on X1=x1. Clearly, when X1>rt, conditional power is 1, and when X1\u0014r1(futility stop), conditional power is 0. a function of p,x1andn2as well as rt To obtain the unconditional power, we need to integrate (sum) the conditional power overCHAPTER 7. PHASE II CLINICAL TRIALS 65 so that r(p0)\u0014aandr(p1)\u00151\u0000b. Unlike in a single-stage situation, there may be more than one good design. Simon used theoptimal andminimax to choose two reasonable designs among many satisfying the type I error rate and power constraints. Expected sample size under the null can be written as Ep0[nt] =n1+n2P[continue 0.7463 TRIALS 66 0.0655 0.9069 0.9984 CLINICAL TRIALS 67 0 5 10 150.00.20.40.60.81.0 x1conditional power Given a design, computing operational characteristics such as type I error rate, power, expected sample size is not difcult; however, solving for the optimal, minimax, and other preferable designs is not trivial. Simon's original papers show how to do this. A very good webpage is http://www.cscc.unc.edu/cscc/aivanova/SimonsTwoStageDesign.aspxCHAPTER 7. PHASE II CLINICAL TRIALS 68 Something in between The two criteria, optimal and minimax, give two designs that are extreme, and neither may t the investigators' needs. For example, for testing H0:p=0:3witha=0:05andb=0:10 atp1=0:45, 60:8 0 :70 balanced 53 0:043 0 :903 64:4 0 :78 minimax :901 78:5 0 :86 The optimal design tends to have a small n1and the minimax design tends to have a large n1. Therefore, a simple approach to nd a good alternative design is to force n1=n2. (balanced design of Y e and Shyr, 2007) A more systematic approach is to express the criteria for optimization as q(w) =w\u0002(nt)+(1\u0000w)\u0002E0[N]; where 0\u0014w\u00141.q(0)and tively. Computation shows that the minimax design is the best design with respect to q(w) forw2(0:827;1]. In between the optimal and minimax designs, the following \"admissible\" designs exist that optimize q(w)for certain ranges of w. (Jung, Lee, Kim, George, 2004) n1 r1 ntrt a 1\u0000bE0[N]pet0 w optimal 0 :901 60:8 0 :70 (0;0:006) admissible 1 104 38 0:050 0 :903 60:8 0 :70(0:006;0:136) admissible 2 48 16 101 37 0:050 0 :901 61:3 0 :75(0:136;0:182) admissible 3 40 12 94 35 0:048 0 :902 62:8 0 :58(0:182;0:303) admissible 4 46 34 0:049 0 :902 64:1 0 :60(0:304;0:827) minimax :900 90:0 0 :00CHAPTER 7. PHASE II CLINICAL TRIALS 69 7.4 Data analysis following a two-stage design in phase II clinical trials The primary objective of a (cancer) phase II clinical trial is to make a correct \"go/no- go\" decision; however, making a good inference for pis advantageous for planning the following phase III trial. We have seen before (Chapter 3) that when we terminate a study based on an interim summary of the data, a usual statistic that we often compute may be biased. In this section, we will look at the issue of bias in two-stage design in phase II clinical trial in detail. Simon's design will be our focus, but many general discussions can be applied to other designs as well. 7.4.1 p-value If we ignore the fact that the data were gathered in a two-stage design and compute ap-value as if X\u0018Binomial (nt;p), it is bigger than the true p-value with the following denition/interpretation. p-value the probability under the null hypothesis that we would observe the data as or more extreme than what we have observed The term \"as or more extreme\" can be interpreted as \"as big or bigger evidence against H0\". In a simple single-stage design, the meaning of this is usually straightforward. We can all agree that Z=2:0is more extreme (more evidence against H0) than Z=1:9. However, in two-stage designs, understanding the denition of p-value sometimes gets tricky. Example: H0:p=0:3,H1:p>0:3;a=0:05and the power is 0:80atp=0:5. Then the optimal design is:n1=15,r1=5,nt=46,rt=18.CHAPTER 7. PHASE II CLINICAL TRIALS 70 Now suppose that we observe X1=7in stage 1 so that we move on to the second stage. And in stage 2, we observe additional 12positive responses in n2=31patients ( 19in46 total) so that H0is rejected because Xt=19>rt. If we compute a p-value without taking into account the study design, we might but this p-value is greater than a. To see this inconsistency clearly, we will rewrite above as pc=P0[X\u001519] =15 \u00e5 x1=0P0[X2\u001519\u0000x1jX1=x1]P0[X1=x1]: From this expression we see that in computing pc, we include sample paths that can not be realized with this Simon's design, namely, X1=0,X2\u001519;X1=1,X2\u001518;\u0001\u0001\u0001;X2=5, X2\u001514. Aproper p-value that takes into account the actual sampling scheme used may be pp=15 \u00e5 x1=6P0[X2\u001519\u0000x1jX1=x1]P0[X1=x1]: In general, for calculated pp=n1 \u00e5 x1=r1+1P0[X2\u0015xt\u0000x1jX1=x1]P0[X1=x1]; ifx1>r1(i.e., if there is a second stage). The following simple R script computes this p-value:CHAPTER 7. PHASE II that the trial is terminated in stage 1, we can dene pp=P0[X1\u0015x1]: Thus we think that \"moving on to the second stage\" has more evidence against H0than \"terminating in the rst stage for futility\", which makes Theproper p-value ( pp) has the following characteristics: \u000fIt is always smaller than or equal to pc. \u000fIt is consistent with the hypothesis testing, i.e., pp\u0014aif and only if H0is rejected. \u000fIfXt=rt+1, then ppis equal to the level of the test (so-called the actual type I error rate). \u000fIt does not distinguish different sample paths that lead to the same Xt. That is, evidence against H0is identical if xtis the same regardless of x1. For example, X1=8,X2=12andX1=10,X2=10yield the same p-values. When does this ( pp) break down? It breaks down when we allow n2to be different for various values of X1. In some modica- tions of Simon's design (e.g., Banerjee A, Tsiatis AA. Stat Med 2006), the stage 2 sampleCHAPTER 7. PHASE II CLINICAL TRIALS 72 size varies with x1. Then, ppcan not be computed because we cannot order the sample paths simply based on Xt. A bigger concern is that this ppcannot be used when n2is changed from that planned. An even bigger concern is if the actual n2is different from that planned, how can we re-compute the critical value, rt, to control type I error rate? The answer is not simple! 7.4.2 Point estimate Because the results from a phase II clinical trial are often used in planning a phase III clinical trial, a good estimate of pis often of interest. MLE In a single stage design, the MLE of pisp=x=n. For a Simon's design, we can write the likelihood, letting Yidenote the individual datum from pis p(x) =( x1=n1ifx1\u0014r1 xt=ntifx1>r1 We have seen before that this p(x)has a downward bias, i.e., Ep[p(x)]\u0014p. A simple explanation is that when pis small at the end of stage 1, we tend to terminate the study,CHAPTER 7. PHASE II CLINICAL TRIALS 73 and this downward bias tends to remain; however when pis large at the end of stage 1, more data are gathered and the upward bias of stage 1 tends to be corrected. Example :p0=0:3,p1=0:5,a=0:05,b=0:2. Then the minimax design is X1=8andX2=12so that Xt=20. p=20 39=0:513: Whitehead We can write the bias of the MLE estimator as: B(p) =Ep[p(x)]\u0000p: So a good estimator would be p=p\u0000B(p): However, B(p)is unknown, so we need to estimate it. Let's use the current estimate of p inB(p). That is pw=p\u0000B(pw): This is Whitehead's estimator (1986 Biometrika). We can write pw; which leads to Epw[p(x)] = p: To nd pw, we need pw=0:520.CHAPTER 7. PHASE II CLINICAL TRIALS 74 Koyama We can write the bias of the MLE estimator as: B(p) =Ep[p(x)]\u0000p: So a good estimator would be p=p\u0000B(p): However, B(p)is unknown, so let's use B(p), that is pk=p\u0000B(p): This is simpler and more straightforward than Whitehead's estimator. We can write pk=p\u0000Ep[p(x)]+ p =2 p\u0000Ep[p(x)]: 2 p. In the current example, pk=0:521. Unbiased estimator For a general multistage design with early stopping for futility and efcacy, Jung and Kim (2004 Stat Med) found the unbiased estimator of p. They showed that the pair ( M,S), where Mis the number of stage (when terminated) and Sthe number of successes, is complete and sufcient for p. And clearly x1=n1is unbiased for p, the uniformly minimum variance unbiased estimator (UMVUE) is found through Rao-Blackwell theorem. The for pubis complex, but for Simon's two-stage design (two-stage with only futility stop), it x1=(r1+1)_(xt\u0000n2)\u0000n1\u00001 x1\u00001\u0001\u0000n2 xt\u0000x1\u0001 \u00e5n1^xt x1=(r1+1)_(xt\u0000n2)\u0000n1 where a^b=min(a;b)anda_b=max(a;b). For the current example, max(r1+1;xt\u0000n2) 0such that the p-value for testing H0:p=p\u0003 0 is0:5by the realized sample path. Many adaptive designs for phase II clinical trials were originally motivated as a hypothesis testing procedure, and computing this estimator should be fairly simple in many designs. If the test statistic is continuous, this estimator is known as the median unbiased estimator (Cox and Hinkley 1974). It is unbiased for the true median. The proof uses the fact that the p-value is distributed Uni f(0;1)under H0. II CLINICAL TRIALS 76 Comparisons To compare these methods, we compute the bias of each estimator for various true values ofp. Use bias and mean squared error = var + bias2to compare them. For each estimator, compute pfor every sample (dened by Xin[0;nt]) and compute Ep[p] =nt \u00e5 x=0p(x)Pp[X=x]: MSE p[p(x)] =nt \u00e5 x=0(p\u0000p)2Pp[X=x]: The following two plots show bias and MSE for the current example.CHAPTER 7. PHASE II CLINICAL TRIALS 77 0.2 0.3 0.4 0.5 0.60.030.020.010.000.01 true pbias MLE Whitehead Unbiased Koyama Median 0.2 0.3 0.4 0.5 0.60.0060.0070.0080.0090.0100.011 true pMSE MLE Whitehead Unbiased Koyama MedianChapter 8 Treatment effects monitoring 8.1 Introduction A phase III clinical trial (comparative treatment efcacy phase) is a type of trial design that assesses the efcacy of a new treatment relative to an alternative, placebo, standard therapy, or no treatment. DSMB Data and safety monitoring board DMC Data monitoring committee TEMC Treatment effects monitoring committee \u000fDMC should have no formal involvement with subjects or investigators. \u000fDMC should interact actively in data analysis, request additional analyses if neces- sary. \u000fDMC usually meets two to three times a year (or after set number of patients con- tribute the data) 78CHAPTER 8. TREATMENT EFFECTS MONITORING 79 Motivations for monitoring treatment effects \u000fCheck protocol compliance (baseline variables) Baseline imbalances alone are not likely to be a cause for much concern, but it can undermine the credibility of a trial, some intervention might be proposed to correct them. \u000fReview accrual Accrual tends to be slow at the beginning of the trial. The dropout rate may be higher than expected; the event rate may be lower than planned. Remedial actions include to prolong the accrual length and to add study centers. \u000fReview resource availability Money! Human resources (loss of irreplaceable expertise), difculty obtaining rare drugs. \u000fReview data quality DMC checks patient eligibility (minor deviations are common), minor deviations in baseline data acquisition, randomization, misdiagnosis. Deviations occurring more than 10% of all patients may be a sign of internal quality control problem. Treatment compliance/adherence. \u000fReport adverse events Frequent side effects of low intensity may trigger dose reduction. In contrast, a rarely occurring fatal toxicity could be intolerable in studies where patients are basically healthy / have a long life expectancy. \u000fMonitor treatment efcacy After all the previously mentioned checks the trial continue? There may be secondary outputs from the trial such as secondary questions, database.CHAPTER 8. TREATMENT EFFECTS MONITORING 80 \u000fShould the protocol modied? e.g., terminating one of many arms; adjusting timing or frequency of diagnostic tests changing consent process, improving quality of data collection, ... \u000fDoes the TEMC need other views of the data? \u000fShould the TEMC meet more/less frequently? If the timing is based on \"information time\" the meeting may not occur at the recommended intervals (calendar time) Reasons for stopping a trial (Table 14.1) \u000fTreatments are found to be convincingly different. \u000fTreatments are found to be convincingly not different. \u000fSide effects are too severe. \u000fThe data are of poor quality. \u000fAccrual is too slow. \u000fDenitive information about the treatment becomes available making the study un- ethical or unnecessary. \u000fThe scientic questions are no longer important. \u000fAdherence to the treatment is unacceptably poor. \u000fResources to perform the study are no longer available. \u000fThe study integrity has been undermined. Factors to consider before terminating a study \u000fDelays in reporting. \u000fBaseline differences. \u000fBias in response assessment.CHAPTER 8. TREATMENT EFFECTS MONITORING 81 \u000fMissing data. \u000fCredibility of results if stopped early. Reasons for not stopping early: Increasing precision and reducing errors Subgroup analyses, interaction effects, secondary endpoints Examples ECMO (extracorporeal membrane oxygenation) vs standard treatment. 39 newborn in- fants were enrolled in a trial, and the trial was terminated when 4 deaths in 10 infants the standard group compared with 0 of 9 on ECMO. fisher.test(cbind(c(0,9),c(4,6)), alt='less') One sided p-value is of TEMC = DMC TEMC is intellectually and nancially independent of the study investigators so that it can provide objective assessments. Who should TEMC make recommendations to? Trial sponsor or trial investigators or both? \"The TEMC has an obligation to inform the investigators of their opinions and recommen- dations about actions that carry ethics implications.\" FDA's 1989 guideline has a very brief description of data monitoring and DMCs. NIH policy (1998)CHAPTER 8. TREATMENT EFFECTS MONITORING 82 \u000fAll sponsored trials must have a monitoring system for safety, efcacy and validity ICH guidelines (1998) \"When a sponsor assumes the role of monitoring efcacy or safety comparisons and therefore has access to unblinded comparative information, particular care should be taken to protect the integrity of the trial...\" \"Any interim analysis that is not planned appropriately (with or without the consequences of stopping the trial early) may flaw the results of a trial and possibly weaken condence in the conclusions drawn. \u0001\u0001\u0001If unplanned interim analysis is conducted, the clinical study report should explain why it was necessary, the degree to which blindness had to be broken, provide an assessment of the potential magnitude of bias introduced, and the impact on the interpretation of the results. \" \"The IDMC should have written operating procedures and main records of all its meetings, ...\" \"The IDMC is a separate entity from an Institutional Review Board (IRB) or an Indepen- dent Ethics Committee (IEC0, and its composition should include clinical trial scientists knowledgeable in the appropriate disciplines including statistics.\" DMC membership Data monitoring is a complex decision process and requires a variety of expertise in medicine, basic science, biostatistics, epidemiology, and medical ethics. (Additionally representative from a regulatory body) DMC condentiality In general, interim data must remain condential. DMC rarely releases interim data, and its members must not share interim data with anyone outside of DMC. Data leaks may affect \u000fPatient recruitment \u000fProtocol compliance \u000fOutcome assessmentCHAPTER 8. TREATMENT EFFECTS MONITORING 83 \u000fMarket value Then why not have DMC only use blinded data? Complete objectivity 6=ethical Revisit the question, \"Should DMC include the study investigators?\" FDA draft guidance \"Knowledge of unblinded interim comparisons from a clinical trial is not necessary for those conducting or those sponsoring the trial; further, such knowledge can bias the outcome of the study by inappropriately influencing its continuing conduct or the plan of analyses. Therefore, interim data and the results of interim analyses should generally not be accessible by anyone other than DMC members.\" Guessing the between-group difference only using blinded data. Suppose in order to check data quality, the pooled variance was computed and reported in the DMC. For example, \"We originally anticipated s2=20; however, the pooled variance after n1=50from each group was s2 1p=25. If the clinical trial scientist or the sponsor has an access to this information how bad is it? By itself it is not too bad; if data are from normal populations, variance estimate and mean estimate are independent. However, without breaking the blind, they can compute the overall mean blinded data -Sponsor, Executive committee, DMC, SACCHAPTER 8. TREATMENT EFFECTS MONITORING 84 \u000fClosed session -Unblinded data -DMC and SAC -Sponsor ? \u000fExecutive session -DMC only \u000fDebrieng session -DMC chair, Sponsor representative, Executive committee representativeChapter 9 Group Sequential Method 9.1 Introduction Fully sequential method A test of signicance is repeated after each observation. Group sequential method A test of signicance is repeated after a group of observa- tions. Some basic characteristics of a group sequential method \u000fThe response variable needs to be observed immediately. \u000fNumber of stages (or looks) can be 2 to 20. \u000fLooks are equally spaced. (This is not a critical requirement.) \u000fAt each interim (and nal) analysis, compute summary statistic based on the cumu- lative data (This is not a critical requirement.) \u000fA group sequential method is a strategy to stop early as opposed to an \"adaptive design\" is often viewed as a strategy to extend the study if necessary. 85CHAPTER 9. GROUP SEQUENTIAL METHOD 86 \u000fA set of critical values are computed so that the overall ais as specied. -Haybittle-Peto (1971) This is an ad hoc method in which a very conservative critical value (e.g., Z>3) is used at every interim test. At the nal analysis, no adjustment is used (i.e., Z>1:96) It is highly unlikely to stop early. -Pocock (1977) A \"repeated test of signicance\" at a constant signicance level to analyze ac- cumulating data. -O'Brien-Fleming (1979) The signicance levels increase as the study progress.CHAPTER 9. GROUP SEQUENTIAL METHOD 87 9.2 Example 0.0 0.2 0.4 0.6 0.8 1.0 1.242024 Information FractionBoundaryGroup sequential boundaries PocockO'BrienFleming O'Brien-Fleming Sample size Analysis Fraction n Z Nominal pSpend 1 0 :205 70 4 :56 0 :0000 0 :0000 2 0 :411 139 3 :23 0 :0006 0 :0006 3 0 :616 208 2 :63 0 :0042 0 :0038 4 0 :821 277 2 :28 0 :0113 0 :0083 5 1 :026 346 2 :04 0 :0207 0 :0122 Total 0:0250CHAPTER 9. GROUP SEQUENTIAL METHOD 88 Pocock Sample size Analysis Fraction n Z Nominal pSpend 1 0 :241 82 2 :41 0 :0079 0 :0079 2 0 :483 163 2 :41 0 :0079 0 :0059 3 0 :724 244 2 :41 0 :0079 0 :0045 4 0 :965 325 2 :41 0 :0079 0 :0037 5 1 :207 407 2 :41 0 :0079 0 :0031 Total 0:0250 Sample size is expressed in terms of ratios to sample size of single stage procedure. Suppose we want to test H0:mt\u0000mc=0andH1:mt\u0000mc=1when Xt\u0018Normal (mt;s2)and Xc\u0018Normal (mc;s2), where s=4. Then for a single stage procedure with equal sample size for the two groups (one-sided a=2:5%,b=10%), (p46of the 9. GROUP SEQUENTIAL METHOD 89 0.0 0.2 0.4 0.6 0.8 1.0 1.20.0000.0050.0100.0150.0200.025 Information FractionCumulative type I errorAlphaspending functions 9.3 General applications Letk=1;\u0001\u0001\u0001;Kbe denote the stages where ntkand nckare the cumulative sample sizes for the treatment and control groups. Note that this is not a conditional distribution but a marginal distribution. Dene \"information\" as Ik= (s2=ntk+s2=nck)\u00001. Roughly speaking, information is square of what appears in the denominator of the test statistic, Z. When nk=ntk=nck,Ik= (2s2=nk)\u00001. Dene the test because each Zkis a linear combination of the independent normal variates XtiandXci. The marginal distribution of Zkis Zk\u0018Normal\u0010 General decision rule a group sequential design is After group k=1;\u0001\u0001\u0001;K\u00001 ifjZkj\u0015ckstop and reject H0. otherwise continue to group k+1. After group K ifjZkj\u0015cKstop and reject H0. otherwise stop for futility. The test's type I error rate can be expressed as PfjZkj\u0015ckfor some k=1;\u0001\u0001\u0001;Kg: The critical values, ck, are chosen so that the above probability is equal to a. And the power of the study at d1is P(K[ k=1\u0000 jZjj<cj;forj=1;\u0001\u0001\u0001;k\u00001andjZkj\u0014ck\u0001) : Evaluation of this probability requires knowing the distribution of (Z1;\u0001\u0001\u0001;ZK). Refer to tables of cKvalues or a computer software. For a Pocock method, the critical values are constant, so ck=CP(K;a). For the example above, CP(5;0:05) =2:41. For an O'Brien-Fleming method, the critical values have the form, ck=CB(K;a)p K=k. For the same example, we have CB(5;0:05) =2:04. From this we can compute the critical values, 2:04p 5=4=2:28;2:04p 5=3=2:63, and so on. More generally, if stage sample sizes are different, use Ik, that is, ck=CB(K;a;I)p IK=Ik.CHAPTER 9. GROUP SEQUENTIAL METHOD 92 9.3.1 Beta blocker heart attack trial Seven analyses (including the nal one) were planned (corresponding to the timing of the DMC meetings) using O'Brien-Fleming bounds with two-sided type I error rate of 5%. The primary outcome was survival, and log-rank test was used. If Pocock boundary had been used, N=7anda=0:05give Z=2:485. Therefore, the trail would have been stopped at the same point. 9.3.2 non-Hodgkin's lymphoma Pocock 1983 Clinical Trials: A Practical Approach . A trial was conducted in patients with non-Hodgkin's lymphoma for two drug combinations (cytoxanprednisone -CP- and cytoxan-vincristine-prednisone -CVP-). The primary endpoint was tumor shrinkage (Y es/No). Statistical analyses were planned after approximately 25 patients. With 5 looks and one- sided a=0:05. The Pocock procedure requires a signicance level of 0.0169 at each Alpha-spending \"Classical\" group sequential designs have equal information (sample size) at every stage, but we may want to be a little more flexible. And when Ikis not a constant we might want to change aspent accordingly. Decompose the rejection region. R=PfjZkj\u0015ckfor some k=1;\u0001\u0001\u0001;Kg =Pf(jZ1j\u0015c1)or(jZ1j<c1andjZ2j\u0015c2)or\u0001\u0001\u0001g =PfjZ1j\u0015c1g+PfjZ1j<c1andjZ2j\u0015c2g+PfjZ1j<c1andjZ2j<c2andjZ3j\u0015c3g+\u0001\u0001\u0001 =a(I1)+(a(I2)\u0000a(I1))+( a(I3)\u0000a(I2)\u0000a(I1))+\u0001\u0001\u0001 The biggest alpha-spending approach is its flexibility; neither the number nor timing of the interim analyses need to be specied in advance. The monitoring plan can be changed during the trial and still type I error rate is preserved. 0.4 0.6 0.8 1.00.0000.0050.0100.0150.0200.025 Information fractionalpha spendingOF Pocock Power (1) Power (0.5) Power (2) HSDC (4) HSDC (4)alpha spending functions 9.5 One-sided test If \"stop for futility\" is not an option, the same boundary can be used. If a futility stop is an option, thenCHAPTER 9. GROUP SEQUENTIAL METHOD 95 After group k=1;\u0001\u0001\u0001;K\u00001 ifZk\u0015bkstop and reject H0. ifZk\u0014akstop for futility (accept H0). After group K ifZk\u0015bKstop and reject H0. ifZk<aKstop for futility. Note that aK=bKensures that the test terminates at analysis K. 9.6 Repeated condence intervals If we compute unadjusted condence intervals \u00afXso far\u00061:96s=pnso far at the end of each stage, we get low coverage probabilities. Armitage, McPherson, Rowe (\"Repeated signif- icance tests actual coverage proba- bilities (Table 2). Number of looks Overall probability that all intervals contain q 1 0 :95 2 0 :92 3 0 :89 4 0 :87 5 0 :86 10 0 :81 20 0 :75 50 0 :68 \u00a5 0 The idea of repeated condence intervals (RCIs) is to use an adjusted value, ck(a;K), instead of 1:96so that the overall coverage probability is 1\u0000a=2. The value of ck(a;K)is the critical value (border) for each stage and depends on aand Kif Pocock boundary is used, and additionally kif O'Brien-Fleming boundary is used. Example:CHAPTER 9. GROUP SEQUENTIAL METHOD 96 Suppose we use a 6-stage group sequential design of O'Brien-Fleming type with a two- sided a=5%. The critical values > gsDesign(k=6, test.type=2, alpha=0.025, sfu='OF') Symmetric two-sided group sequential design with 90 % power and 2.5 % Type I Error. Spending computations assume trial stops if a bound is crossed. Sample Size Analysis Ratio* Z Nominal p Spend 1 0.172 5.03 0.0000 spending: O'Brien-Fleming boundary * Sample size ratio compared to fixed design with no interim The critical values are 5:03,3:56,2:90,2:51,2:25,2:05. First, let's conrm that the critical values have the form ck=COB(K;a)p IK=Ik. The - nal critical value COB(6;a) =2:05, and assuming the looks are equi-distant (same group we would use 5:03in place of the regular 1:96when computing a 95%CHAPTER 9. GROUP SEQUENTIAL METHOD 97 condence interval. In general after stage k(k=1;\u0001\u0001\u0001;6), (\u00afxkt\u0000\u00afxkc)\u0006ckp 2s2 p mk; where mis per-group sample size for each stage. With a Pocock design, the critical value ckis a constant. ( ck=2:45fork=1;\u0001\u0001\u0001;6) This method (RCI) is consistent with the corresponding hypothesis testing. Only when is H0rejected in stage k, the condence interval for that stage will exclude the null value. Thus, we can use the idea of \"inverting hypothesis test\" to get the same condence inter- val. (more later) 9.7 P-values Recall how we construct a proper p-value for a Simon's two-stage design in phase II methodology. We needed to dene \"more or as extreme as the observed data\". To be able to do this, we need to have an ordering of all the sample paths. In a simple single- stage design, the ordering is usually based on z-values (or absolute value of z-values if two-sided test), i.e., the bigger the observed z, the stronger the evidence against H0. Then a one-sided p-value is computed by p=P0[Z\u0015z]: With a group sequential design, or more generally, with a multi-stage design with pre- specied group-wise sample sizes, the is true: 1.k0=kandz0\u0015z.CHAPTER 9. GROUP SEQUENTIAL METHOD 98 2.k0<kandz0\u0015bk0(upper critical value). 3.k0>kandz\u0014ak(lower critical value). \u000fMLE ordering. (k0;z0) (k;z)ifz0=pIk0>z=pIk. Originally proposed in connection with a test for a binomial proportion The bigger value of the MLE gets a higher order. Sometimes called \"sample mean ordering\" because this is equivalent to ordering based on the sample mean (one-sample) or the difference of sample means (two-samples). \u000fLikelihood ratio ordering. (k0;z0) (k;z)ifz0>z. (Stages do not matter.) \u000fScore test ordering. (k0;z0) (k;z)ifzpIk0>zpIk. Whichever ordering is used, we can compute a one-sided p-value is P0[(T;ZT) (k\u0003;z\u0003)] For example, if we use a stage-wise ordering and test terminates in the K\u00001stage with p=Z\u00a5 b1g1(z;0)dz+\u0001\u0001\u0001+Z\u00a5 z\u0003gK\u00001(z;0)dz: In the above expression, gk(z;q)is a density function of zin stage k. Conceptually, the density function of zinkstage depends on all the data in the previous stages, 1\u0001\u0001\u0001k\u00001, requiring multivariate integration. Armitage, McPherson, Rowe (1969) derived a recursive formula so that the computation is much simplied, requiring only a =Z Ck1gk\u00001(m;q)pIkpDKf\u0012zpIk\u0000mpIk\u00001\u0000DkqpDk\u0013 region the stage k1, and Dkis the increment information, Ik\u0000Ik\u00001. If stage-wise ordering is used, it automatically ensures that item the p-value is less than the signicance level aif and only if H0is rejected.CHAPTER 9. GROUP SEQUENTIAL METHOD 99 Once we dene the ordering to use with the group sequential test then we can compute a p-value for testing H0:q=0by \"inverting hypothesis test\". A (1\u0000a=2)condence q0 0such that H0 0:q=q0 0would be accepted with the observed sample path. (More details with the adaptive designs next chapter)Chapter 10 Two-stage adaptive designs 10.1 Introduction Much of discussion in the literature for flexible designs in phase III clinical trial methodolo- gies revolves around 2 stage designs. Practically speaking, implementing flexible clinical trials beyond two stages is difcult, and perhaps these multi-stage flexible designs add only little to the designs with just two stages. Moreover, phase III clinical trials are for conrmatory purposes, and adaptively changing the design more than once in the middle of a conrmatory trial is not seen favorable by the regulatory gure. So we will only consider two-stage adaptive designs. Two-stage group sequential designs are examples of such designs. 10.2 Background We will look at unmasked (unblinded) two stage designs in which all the information from stage 1 is available. Design of the second stage (sample size and critical value) may be 100CHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS 101 specied as functions of stage 1 data. If both sample size and critical value are constants in stage 1 data, then it reduces to a two-stage group sequential design. Adaptive designs can be categorized into the following two types: \u000fprespecied designs Design of the second stage (e.g., sample size and critical value) is specied before the rst stage. There is nothing to decide at the end of stage 1. The design of the second stage is dened flexibility as functions of stage 1 data. Group sequential designs fall into this category. \u000funspecied designs Design of the second stage is not specied in advance and determined after stage 1 data are observed. Characteristics of these types of designs: prespecied designs \u000fType I error can be controlled. \u000fType II error can be controlled. (you can specify the power.) \u000fY ou can compute design characteristics of the design (e.g., expected and maximum sample size) prior to initiation of the study. unspecied designs \u000fType I error can be controlled. \u000fThese designs give much flexibility to handle unexpected situations (e.g., variance much bigger than anticipated). Something in between: Not specifying the stage 2 sample size is unrealistic because it makes it impossible to budget such a clinical trial. Instead of leaving the stage 2 unspeci- ed, maybe we should specify the maximum sample size. And perhaps, we may want toCHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS 102 specify the minimum of the power for the second stage, P[Reject H0in stage 2jStage 1 data]. With these specications, unspecied designs start to look like prespecied ones. What do they say about adaptive designs PhRMA (2006) \"A clinical study design that uses accumulating data to decide how to modify aspects of the study as it continues, without undermining the validity and integrity of the trial.\" \"... changes are made by design, and not on an ad hoc basis; therefore, adaptation is a design feature aimed to enhance the trial, not a remedy for inadequate planning.\" EMA (2006) \"A study design is called 'adaptive' if statistical methodology allows the mod- ication of a design element (e.g. sample-size, randomisation ratio, number of treat- ment arms) at an interim analysis with full control of type I error rate.\" \"adaptive designs should not be seen as a means to alleviate the burden of rigorous planning of clinical trials.\" FDA (2010) \"... adaptive design clinical study is dened as a study that includes a prospectively planned opportunity for modication of one or more aspects of the study design and hypotheses based on analysis of data (usually interim data) from subjects in the study.\" 10.3 Toward conditional power What are good two-stage adaptive designs? \u000fWhat do we use to compare different designs? -Power between m0andm1 -Expected sample size at different ms. \u000fDesign of stage 1 tends to be more influential in terms of these characteristics.CHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS 103 \u000f\"Optimality\" is not the only driving force to choose a design. A design with a very small n1may have different objectives than those with a large n1. (Ambitious designs vs. Insurance-type designs) To test H0:d=0, where d=mt\u0000mc, we take random samples from Xt\u0018Normal (mt;s2 t) Xc\u0018Normal (mc;s2 c): and known: s2 t=s2 c=s2. Also assume the sample sizes are equal in the control and treatment groups: n1t=n1c=n. Then \u00afX1t\u0018Normal x=d=p 2s. Also dene z=pn1xfor the stage 1. In stage 1, we observe Z1and use the following decision rule: \u000fIfZ1<k1, stop for futility. \u000fIfZ1>k2, stop and reject H0. \u000fIfk1<Z1<k2then continue to stage 2. In stage 2, we take a sample of size n2(z1)from each arm, and dene Z2=p n2(z1)(\u00afX2t\u0000\u00afX2c)p 2s: Conditioned on Z1=z12(k1;k2), Z2\u0018Normal (p n2(z1)x;1): The decision rule at the end of stage 2 is:CHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS 104 \u000fIfZ2\u0014c(z1), stop and conclude futility. \u000fIfZ2>c(z1), stop and conclude efcacy. We can use Z1and Z2to construct a two-stage design, and we can also construct a test statistic that combines the test statistics from both stages. Let Zw=Z1+Z2p 2: IfZ1andZ2are independent Zw\u0018Normal xpn1+p n2(z1)p 2;1! Under H0,Zwhas the standard normal distribution. Zwis rarely used because it weights stage 1 and stage 2 data differently. To give equal weight to every datum, we should construct a test statistic n1+n2(z1)Yp 2s;CHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS 105 then we have Zu\u0018Normal\u0010p n1+n2(z1)x;1\u0011 ; ifZ1andZ2are independent. It is useful to write weighted average of Z1andZ2as follows: Zu=pn1p n1+n2(z1)Z1+p n2(z1)p n1+n2(z1)Z2 Because even the existence of the second stage depends on Z1, we need to think about stage 2 conditioned on stage 1 data. Conditioned original decision rule at the end of stage 2 was written in terms of Z2, i.e., Z2>c(z1) then reject H0. This can be written in terms of Zu. Suppose the critical value that goes with Zuiscu(z1). Conditioned on Z1=z1we have cu(z1) =pn1p n1+n2(z1)z1+p n2(z1)p n1+n2(z1)c(z1): The decision rule at the end of stage 2 can be written in terms with Z2andZu. There exist many different normalization schemes. For example, Zucan be rescaled to have a variance n2(z1)Zu\u0018Normal pn1p n2(z1)z1+p n2(z1)x;1!CHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS 106 10.4 Conditional power functions Conditional power is the probability of rejecting H0in stage 2 conditioned on the rst stage data. Let A(z1;x)to denote the conditional power at xgiven Z1=z1. Then we =Px[Z2>c(z1)jZ1=z1]: The A(z1;x) =1\u0000Fh c(z1)\u0000p type I error is A(z1;x0). Specically, when x0=0, we have A(z1;0) =1\u0000F[c(z1)]: The the alternative, x1, is A(z1;x1) =1\u0000Fh c(z1)\u0000p n2(z1)x1i : To specify a design that has type I error rate of a, we need to pick the conditional power functions (and other design parameters such as critical values and sample sizes) so that a=Z\u00a5 k2g1(z1;x0)dz1+Zk2 k1A(z1;x0)g1(z1;x0)dz1 =a1+Zk2 k1A(z1;0)g1(z1;0)dz1; where g1(z1;x)is the probability density of Z1\u0018Normal (pn1x;1). Similarly, to ensure power of k2g1(z1;x1)dz1+Zk2 k1A(z1;x1)g1(z1;x1)dz1 =r1+Zk2 k1A(z1;x1)g1(z1;x1)dz1;CHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS stage 1 is already designed ( n1,k1and k2), we can choose to use any A(z1;0)and A(z1;x1)as long as they satisfy these aandrconditions. Then we can nd the critical value and sample size for stage A(z1;x0) =1\u0000Fh c(z1)\u0000p n2(z1)x0i A(z1;x1) =1\u0000Fh c(z1)\u0000p and solve for n2(z1)and c(z1); however, we can specify any two of the four \"design elements\" and solve for the remaining two. Perhaps, we want to specify A(z1;x0)so that the type I error rate is controlled and n2(z1) so that the sample size is controlled. In this case, we have c(z1) =zA(z1;x0)+x0p H1:mt\u0000mc>0. Assume sis known to be 4. We want one sided ato be 0:025and power to be 0:90atmt\u0000mc\u00001. x0=0 x1=1=p 2s=1=4p 2=0:1768. For a single stage design, the sample size is N=(z0:025+z0:10)2 0:17682=337 Let's decide to look at the data when n1=135observations are available from each group. (approximately 40%ofN) We also need to decide how much of aandbwe want to \"spend\"CHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS 108 in stage 1. Let's a1=0:01andb1=0:025. k1=0:094. Also let's set the maximum sample size to be 500 (approximately 50% increase from N). 0.0 0.5 1.0 1.5 2.00.00.20.40.60.81.0 z1Conditional power 0k1 1k2CHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS 109 0.5 1.0 1.5 2.00100200300400500 z1n1+n2(z1) 0 k1 1 k2n1N First, let's look at some stage 1 design characteristics: Some stage 1 characteristics Stage 1 m x z Accept Continue Reject 0 0 0 0:538 0 :453 0 :010 0 :582 0 :393CHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS 110 If we use a flat A(z1x0), we need the conditional type I error rate to be Af lat(z1;x0) =0:015=0:5374 =0:0331 Similarly, a =z0:0331=1:837 Design with flat A0and flat A1 Stage 1 Stage 2 This design Single stage m x n1Accept Continue Reject Reject Power E[N]Max NPower N 0 0 0:538 0:025 0 :582 0 :393 0:507 0:900 299 :1 417 of the form A(z1;x0) =a0+a1(z1\u0000k1)2andA(z1;x1) =b0+b1(z1\u0000 k1). We can use any Afunctions as long as they satisfy aand power conditions. First we pick a0(the value of A(z1;x0)atz1=k1to be 0:002and solve for nds a1=5:2547 A(z1;x0) =0:002+5:2547(z1\u0000k1)2:CHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS 111 Similarly specifying b0=0:75, we nd b1=1:004so that A(z1;x1) =0:75+1:004(z1\u0000k1): Using these two Afunctions, we can compute n2(z1), and it turns out maxfn1+n2(z1)g> 500, and we need to modify the design a little. It is relatively simple to make small modi- cations to the design because we understand how the design elements A(z1;x0),A(z1;x1), n2(z1), and c(z1), are interrelated. First while xing A(z1;x0), we \"tap\" n2(z1)so that maxfn1+n2(z1)g=500. This action changes A(z1;x1)slightly resulting a smaller power than 0:90. To make the power 0:90 again, we add a constant to the new A(z1;x1)but capping the resulting n1+n2(z1)at500. The nal design is shown below graphically.CHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS 112 0.0 0.5 0k1 1k2A(z1, 0)A(z1, *)A(z1, 1)CHAPTER 1.5 2.00100200300400500 z1n1+n2(z1) 0k1 1k2n1N Design with flat A0and flat A1 Stage 1 Stage 2 This design Single stage m x n1Accept Continue Reject Reject Power E[N]Max NPower N 0 0 0:538 0:507 0:900 337 In the literature, many specic Afunctions have been proposed. A few examples include:CHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS under the current trend\" 10.5 Unspecied designs The minimum requirement to control type I error rate is to pre-specify A(z1;x0)function that satises acondition. Then after the rst stage, when the actual z1from the data are available, pick n2(z1)so that conditional powers at any a value of x(other than x0) can be set. If we allow even A(z1;x0)to be specied after the st stage, type I error rate cannot be controlled. There exist many (in fact innite number of) A(z1;x0)functions that give the desired value of a1(0:01in our example). Depending on z1the required sample size to guarantee a certain conditional power differs. We cannot choose an A(z1;x0)function that gives the minimum sample size for the observed z1. Roughly speaking, when the conditional type I error rate at the observed z1is large, the required sample size is small for the same conditional power. All three conditional type I error rates in the following plot givea=0:025.CHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS 115 0.0 0.5 1.0 1.5 2.00.000.050.100.150.200.25 z1Conditional power 0k1 1k2 10.6 Ordering of sample space To compute p-values and condence interval (through inverting hypothesis tests), we need to dene an ordering of sample space; however, this task is difcult because of sample size difference for potential values of z1. One useful fact (not too difcult to show) is that the decision rule, \"reject if Z2>c(z1)\" is equivalent to the rule \"reject if stage 2 (conditional) p-value is less than A(z1;x0)evaluated at the observed z1.\" So we can compute a (conditional) p-value just using the stage 2 data,CHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS 116 P0[Z2>z2], and compare it to the conditional type I error rate computed at the observed z1. Suppose the red line in the previous plot is used as A(z1;x0), then \u000fifz1=2:0and stage 2 conditional p-value is 0:10then H0will be rejected because thisp-value is less than A(z1;x0)i.e., below the red line. \u000fifz1=1:0and stage 2 conditional p-value is 0:10then H0will not be rejected. Therefore, we need an ordering of the sample space that takes into account not only the sample size of stage 2, n2(z1), but also the conditional type I error rate for the stage 2, A(z1;x0). Suppose we choose to use A(z1;x0)andA(z1;x1)shown in the plot below. 0.0 0.5 1.0 1.5 2.0 2.50.00.20.40.60.81.0 Z1Conditional PowersA(z1,1) A(z1,0)=.005+.1118(z 1k1)2CHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS 117 And let's consider the following 5 sample paths indicated by the conditional pvalues. Can we order the strength of evidence against H0for these data? 0.0 0.5 1.0 1.5 2.0 2.50.00.20.40.60.81.0 Z1Conditional PowersA(z1,0)=.005+.1118(z 1k1)2 \u000fWhen z1is the same, the second stage sample size is the same, so it should be simple to order the sampling paths. The smaller pvalue, the stronger evidence against H0. Blue Red Y ellow. \u000fWhen the conditional pvalues are the same, then we can order them by the strength of evidence in the rst stage. Blue Black Green. \u000fThe black and red dots should indicate equal strength of evidence because they both result in \"just\" rejecting H0. So in the above picture, the only unclear ordering is between Green and Y ellow.CHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS 118 The third rule gives a hint as to how to proceed; the data leading to the black and red dots indicate that those data have just enough evidence to reject H0. The blue dot is for a sampling path that gives stronger evidence against H0; we could reject H0 0that is more extreme. We can nd a value of x\u0003 0(equivalently, m\u0003 0) so that A(z1;x\u0003 0)goes through the blue dot, and say we could have rejected H\u0003 0:m=m\u0003 0. Technically speaking, we can that p=P0[Z2>z2], and once a value of z1is observed, we can evaluate c(z1)and n2(z1), so the only unknown quantity in the above expression is x\u0003 0. From the above picture, we know the ordering is: Blue Red=Black Green Y ellow. And \"some as or more extreme\" than the observed is anything on and below the line, and we can compute the p-value by computing Z\u00a5 k2g1(z1;x0)dz1+Zk2 k1A(z1;x\u0003 0)g1(z1;x0)dz1CHAPTER 10. TWO-STAGE ADAPTIVE 2.50.00.20.40.60.81.0 Z1Conditional PowersA(z1,2.29) A(z1,.42) A(z1,.29) A(z1,0) A(z1,.22) This method (ordering) guarantees that the p-value and the corresponding hypothesis testing are consistent ( p-value <aiffH0is rejected). And it can be shown that when n2(z1)and cu(z1){critical value for the combined statistic} are constants, this ordering reduces to the stage-wise ordering. 10.7 Predictive power With an unspecied design, some people are reluctant to use the conditional power to determine the design of the second stage. One issue is that where to compute the condi- tional power is not always clear. The original alternative is usually a reasonable choice ( A(z1;x1)). However, when theCHAPTER 10. TWO-STAGE ADAPTIVE DESIGNS 120 observed z1is much different (smaller) from x1we may not be interested in the conditional power at x1but at some smaller value that is still clinically meaningful. (Minimum clinically relevant alternative =x 1) Another popular choice isx\u0011z1=pn1(\"alternative under the current trend\"). Or maybe we should compute the conditional power at somewhere in between x1andx 1. Average? Now we are talking like a Bayesian because we are talking about an average ofxs which are, for a frequentist, parameters. Maybe we have a prior distribution of x (or equivalently m). and a posterior distribution of xafter the rst stage, p(xjz1), and we can compute a weighted average of the conditional power with respect to the posterior distribution. Something like Z\u00a5 \u0000\u00a5A(z1;x)p(xjz1)dx; and this is often called a predictive power given the stage one data. The conditional power is a frequentist concept, and it is computed at one value of x. The predictive power is a Bayesian concept, and it is a weighted average of the conditional power with respect to a posterior distribution of x.Chapter 11 Factorial design Factorial clinical trials (Piantadosi) Experiments that test the effect of more than one treatment using a design that permits an assessment of interactions among the treatments The simplest example of a factorial design is 2 treatment, 2 treatment groups (2 by 2) designs. With this design, one group receives both treatment, a second group receives neither, and the other two groups receive one of A or B. Treatment B Treatment A No Y es Total No n n 2n Y es n n 2n Total 2n 2n 4n Four treatment groups and sample sizes in a 2\u00022balanced factorial design Alternatives to a 2\u00022factorial design \u000fTwo separate trials (for A and for B) \u000fThree arm trial (A, B, neither) 121CHAPTER 11. FACTORIAL DESIGN 122 Two major advantages of factorial design (but not simultaneously) \u000fallows investigation of interactions (drug synergy) Drug synergy occurs when drugs interact in ways that enhance effects or side- effects of those drugs. \u000freduces the cost (sample size) if the drugs do not interact. Some requirements for conducting a clinical trial with factorial design \u000fThe side effects of two drugs are not cumulative to make the combination unsafe to administer. \u000fThe treatments need to be administered in combination without changing dosage of the individual drugs. \u000fIt is ethical not to administer the individual drugs. A and B may be given in addition to a standard drug so all groups receive some treatment. \u000fWe need to be genuinely interested in studying drug combination , otherwise some treatment combinations are unnecessary. Some terminology \u000fFactors (how many different treatments are in consideration) \u000fLevels (2 if yes/no) \u000f2kfactorial studies have kfactors, each with two levels (presence/absence) \u000fFull factorial design has no empty cells. \u000fUnreplicated study has one sample per cell (obviously not very common in clinical studies) \u000fFractional factorial designs (some cells are left empty by design)CHAPTER 11. FACTORIAL DESIGN 123 \u000fComplete block designs / Incomplete block designs \u000fLatin squares 11.1 Notation using cell means Notation (cell means) Treatment B Treatment A No Y es No h00 h01 Y es h10 h11 Here, hrepresents the mean of each treatment group. Consider a saturated model: hi j=m+ai+bj+gi j; where i=0;1, and j=0;1. Treatment B Treatment A No Y es No m+a0+b0+g00m+a0+b1+g01 Y es m+a1+b0+g10m+a1+b1+g11 Then we have 8parameters to estimate from 4 data, and we need to propose some restrictions so the parameters are estimable. One such restriction, a0=0,b0=0,g00= g01=g10=0, leads to: Treatment B Treatment A No Y es No m m +b1 Y es m+a1m+a1+b1+g11CHAPTER 11. FACTORIAL DESIGN 124 anda1,b1, m=h00 a1=h10\u0000h00 b1=h01\u0000h00 g11=h11\u0000h01\u0000h10+h00 With this formulation, a1is the effect of treatment A, b1is the effect of treatment B, and g11 is the interaction effect. (If the effects of A and B are additive with no interaction, g11=0.) For each cell, the observations are Y0i=m+e0i can test for anytreat- ment effect by testing H0=a1=b1=g11=0. 11.2 Efciency when no interaction The observed mean responses are: Treatment B Treatment A No Y es No \u00afY0\u00afYB Y es \u00afYA\u00afYAB Note if we assume the sample size in each cell is n, Var(\u00afY0) =Var(\u00afYA) =Var(\u00afYB) =Var(\u00afYAB) =s2 nCHAPTER 11. FACTORIAL DESIGN 125 the interaction effect may be estimated by g11= (\u00afYAB\u0000\u00afYB)\u0000(\u00afYA\u0000\u00afY0) and Var(g11) =4s2 n The treatment A effect can be estimated as a1=\u00afYA\u0000\u00afY0; and its variance is Var(a1) =2s2 n: If no interaction is present then g11\u00190, and a1=\u00afYAB\u0000\u00afYBcan also be used to estimate a1. If we use the average of a1and a1to estimate a, this estimator to have the same efciency in a two-arm trial (A vs. placebo), we would need 2n patients in each treatment arm. var(a1) =2s2 2n=s2 n: So if we were to test A and B in two separate experiments we would need 2nper arm\u00024 arms (A and placebo, B and placebo), totaling 8nsubjects. Noticing we are repeating the placebo in these hypothetical experiments, we decide to use a 3-arm experiment with A, B, and placebo arms. Then we would require a total of 6nsubjects for the same precision. ExampleCHAPTER 11. FACTORIAL DESIGN 126 Treatment B Treatment A No Y es No 10 40 Y es 30 60 If there is a synergistic effect, then h11>60. Treatment B Treatment A No Y es No 10 40 Y es 30 80 Treatment B Treatment A No Y es No 10 40 Y es 30 120 In the last situation, the treatment effects may be multiplicative. Treatment B Treatment A No Y es No log(10) =1 log (40) =1:60 Y es log(30) =1:48 log (120) =2:08 Suppose the samples of size 20yield the following estimates of the cell means. Treatment B Treatment A No Y es No 9:83 40 :05 Y es 28:94 59 :76CHAPTER 11. FACTORIAL DESIGN 127 Assuming no interaction, to estimate the drug A effect we compute either a1=\u00afYA\u0000\u00afY0=28:94\u00009:83=19:11 or a1=\u00afYAB\u0000\u00afYB=59:76\u000040:05=19:71 or their average (19:11+19:71)=2=19:41. How bad is it to estimate a1this way when there is Physician's Health Study I (1989) Read all about it on http://phs.bwh.harvard.edu/ . The Physician's Health Study was a randomized clinical trial designed to test the following two theories: \u000fdaily low-dose aspirin use reduces the risk of cardiovascular disease \u000fbeta carotene reduces the risk of cancer Population hierarchy \u000f261,248 US male MDs aged 40 to 84 \u000f112,528 responded to questionnairesCHAPTER 11. FACTORIAL DESIGN 128 \u000f59,285 willing to participate \u000f33,332 willing and eligible MDs enrolled in run-in (18 weeks of active aspirin and beta-carotene placebo) run-in period Eligible patients are monitored for treatment compliance \u000f22;071randomized Beta-carotene Aspirin Active Placebo Total Active 5;517 DSMB stopped the aspirin arm several years ahead of schedule on 1988/1/25 because it was clear that aspirin had a signicant effect on the risk of a rst myocardial infarction. (reduced the risk by 44%) \u000fThere were too few strokes or deaths to base sound clinical judgement regarding aspirin and stroke or mortality. \u000fThe beta-carotene arm terminated as scheduled on 1995/12/12 with the conclusion that 13 years of supplementation with beta-carotene produced neither benet nor harm. Beta-carotene alone was not responsible for the health benet seen among people who ate plenty of fruits and vegetables. \u000fOver 300 other ndings have emerged from the trial so far. 11.4 Treatment interactions Factorial designs are the only way to study treatment interactions. Recall the interaction term is estimated by g11= (\u00afYAB\u0000\u00afYB)\u0000(\u00afYA\u0000\u00afY0), and its variance is DESIGN 129 variance is 4times as large as for the either AorBmain effect, and to have the same precision for an estimate of an interaction effect, the sample size has to be four times as large. This means, the two main advantages of the factorial designs (efciency and interaction objectives) cannot be satised simultaneously. When there is an ABinteraction, we cannot use the estimators, a1and b1, which are only valid with no interaction effect. In fact, we cannot talk about an overall main effect in the presence of an interaction. Instead, we can talk about the effect of Ain the absent of B, a1=\u00afYA\u0000\u00afY0; or the effect of Ain the presence of B a0 1=a1+g11=\u00afYAB\u0000\u00afYB: Some additional notes \u000fIn the 2\u00022\u00022design ( 23design), there are 3 main effects and 4 interactions pos- sible. The number of high order interactions will grow quickly with k, but oftentimes, they are (assumed to be) 0. \u000fA \"quantitative\" interaction does not affect the direction of the treatment effect. For example when treatment B is effective either with or without treatment A, but the magnitude of its effectiveness changes. \u000fWith a \"qualitative\" interaction, the effects of A are reversed with the presence of B. In this case, an overall treatment A effect does not make sense. \u000fThe factorial design can be analyzed with linear models (analysis of variance mod- els). Limitations of factorial designs \u000fA higher level design can get complex quickly. \u000fTest for interaction requires a large sample size (or have a very low power if the study is powered for the main effects).CHAPTER 11. FACTORIAL DESIGN 130 \u000fCombination therapy may be considered as a treatment in its own right. Of further interest... \u000fPartial (fractional) factorial designs have missing cells by design (especially when higher order interactions are assumed to be zero)Chapter 12 Crossover design Crossover trials are those in which each patient is given more than one treatment, each at different times in the study, with the intent of estimating differences between them. In a simple 2\u00022design (or AB/BA design), patients are randomized to either \"A then B\" group or \"B then A\" group. Period Group I II AB Treatment A Treatment B BA Treatment B Treatment A2 Treatments / 2 Periods / 2 Sequences P1P2 S1A B n1 S2B A n2 4 2 Sequences P1P2P3P4 S1A B A B n1 S2B A B A n2 131CHAPTER 12. CROSSOVER DESIGN 132 12.1 Some characteristics of crossover design \u000fAll subjects receive more than one treatment (not simultaneously) \u000fEach subject acts as own control. Therefore, the treatment groups are comparable without relying on randomization. -Treatment periods (order of AandB) are often randomly assigned. -Baseline characteristics are identical with regard to many patient characteris- tics, but not with regard to their recent history of exposure to other potentially effective treatments. carryover effects -The comparability of the treatment groups is not guaranteed by the structure of the trial alone. The investigators need to estimate the carryover effects. \u000fCrossover designs are not used ... -with any condition that treatment could effect considerable change. -for acute illness \u000fCrossover designs are most suitable for treatments intended for rapid relief of symp- toms in chronic diseases, where the long-term condition of the patient remains fairly stable. Precision The primary strength of crossover trials is increased efciency. Suppose the treatment effects are Xt\u0018Normal (mt;s2) Xc\u0018Normal (mc;s2); and we are interested in mt\u0000mc. In a parallel design (with per group sample size of n), we have D=\u00afXt\u0000\u00afXc\u0018Normal\u0012 mt\u0000mc;2s2 n\u0013 : With a TC=CTcrossover design n, var(D) =2s2 n\u00002cov(\u00afXt;\u00afXc) n(1\u0000rtc);CHAPTER 12. CROSSOVER DESIGN 133 the within-subject correlation of responses on treatments TandC. Therefore, a crossover design is more efcient given rtc>1. Recruitment Some patients may hesitate to participate in a clinical trial if there is a 50% probability of not receiving any effective treatment. With a crossover design, everyone is guaranteed to receive the test drug. On the other hand, the patients may hesitate to participate in a crossover trial because they will go through more than one treatment, especially when outcomes are assessed with diagnostic procedures such as X-ray, blood drawing, lengthy questionnaires. Carryover effects The biggest concern is the possibility that the treatment effect from one period might continue to be present during the following period. A sufciently long \"washout\" period between the treatments may prevent signicant carryover effects (but how long is suf- ciently long?). If there are baseline measurements that represent patient's disease status, this can be checked against their baseline levels. If the treatment effects a permanent change or cure in the underlying condition, the treat- ment given after could look articially superior. Dropouts In a crossover design, the trial duration tends to be longer than a comparable study using independent groups, which may cause more dropouts. Also because every patient take more than one treatment, dropouts due to severe side effects may also increase. The consequences of dropouts are more severe in crossover trial; a simple analysis cannot use only the data from the rst period. And in general analysis is more complex.CHAPTER 12. CROSSOVER DESIGN 134 12.2 Analysis b2\u0001\u0001\u0001Period effect b3\u0001\u0001\u0001Carryover effect Treatment Beffect is b0+b1.b2may be considered as carryover effect for S1. We cannot estimate the treatment-period interaction because that term would only appear in \u00afYA2cell and would not be separately estimable from b3. Suppose no treatment by period interaction , i.e., the carryover effects are the same for both sequences. This means that b3=0. We can then estimate b2(period effect) by b2=1 2(\u00afYB2\u0000\u00afYB1+\u00afYA2\u0000\u00afYA1) There are two estimates of the increment of treatment effect (or B-effect\u0000A-effect), one from each period. We use their average to estimate b1. b1=1 2(\u00afYB2\u0000\u00afYA2+\u00afYB1\u0000\u00afYA1): Similarly, there are two estimates for b0, which we can take average of to get b0=1 2(\u00afYA1+(\u00afYB1+\u00afYA2\u0000\u00afYB2)): More generally, we need to consider the case when carryover effect is non-zero This means that the incremental effects are different for treatment Aand for B. We can estimate b3by b3=\u00afYA2\u0000\u00afYB2+\u00afYB1\u0000\u00afYA1CHAPTER 12. CROSSOVER DESIGN 135 Ifb3is not 0, then we must estimate the treatment difference ( b1) as b1=\u00afYB1\u0000\u00afYA1; using only the data from the rst period. Obviously, b0is estimated by \u00afYA1. And the period effect is estimated by b2=\u00afYB2\u0000\u00afYB1: Variances Suppose that each \u00afYis estimated with variance s2=nand that the within-person which is at least twice as large as Varfb2gforr\u00150. Therefore, any crossover trial de- signed to detect main effects of treatment will have lower power for carryover effect, which is critical to detect because its presence affects both the analysis and interpretation of the trial. With the presence of a clinically important carryover effects, a crossover design is no more efcient than an independent-groups trial. A two-stage procedure may be used: the presence of carryover effects is tested rst with a type I error rate of 5\u001810% before moving on to the primary hypothesis testing of the treatment effects. Estimates will be different depending on the conclusion from the rst stage. 12.3 Examples Capecitabine/Erlotinib Followed of Gemcitabine Versus Gemcitabine/Erlotinib Fol- lowed of Capecitabine is in advanced and metastatic pancreatic cancer not pre- viously exposed to chemotherapy. The study compares a standard arm with gemcitabine plus erlotinib to an experimental arm with capecitabine plus erlotinib. It is the rst trial of its kind to incorporate second-line treatment into the study design. Patient who fail on rst-line therapy are switched to the comparator chemotherapy without erlotinib. The trial therefore not only compares two different regimens of rst-line treatment, it also compares two sequential treatment Colchicine Method: patients were randomized at the study entry to take either colchicine or placebo. At 4 months, they were crossed over. Those who were taking colchicine went on placebo and those on placebo went on colchicine. Each patient tried therefore, both colchicine and placebo. The primary outcome was the effect of colchicine on the disease activity index, the IBDDAM (16-17). To calculate the overall IBDDAM of the baseline, the IBDDAM ofCHAPTER 12. CROSSOVER DESIGN 137 the last 12 months (prior to the study) of each manifestation was calculated and added together. The overall disease activity index was then divided to the number of months (12 months) to have the mean activity index per month. IBDDAM was then measured every 2 months (in the middle and at the end, in each arm of the study). The total IBBDAM of the 4 months was then divided by 4 to have the mean activity index per month. The secondary outcome was to see how the individual symptoms responded to colchicine (IBDDAM of each manifestation). Statistical analysis: The analysis was done by the intention to treat method. As the differ- ence between IBDDAM before and after treatment had normal distribution Student T test for paired samples were used to evaluate the outcome in the colchicine and the placebo group. As the Levene's test showed the homogeneity of variance, ANOVA (one way) was used to test the effect of treatment (colchicine and placebo) and gender on patients' out- come. The dependent variable was the difference between IBDDAM (before and after the treatment). The independent variables were the treatment, and the gender. SPSS 15 was used for all statistical calculations. A Placebo-Controlled, Cross-Over Trial of Aripiprazole http://clinicaltrials.gov/ct2/show/record/NCT00351936 Primary endpoint: Evaluate the effects of aripiprazole on weight, Body Mass Index (BMI), and waist/hip circumference. This study is a ten-week, placebo-controlled, cross-over, randomized trial of the aripiprazole, added to 20 obese stable olanzapine-treated patients with schizophrenia or schizoaffective disorder. The advantage of the crossover design is that each subject will act as their own control and fewer subjects will be required. The double-blind, placebo-controlled, crossover study will consist of two random order 4-week treatment arms (aripiprazole 15 mg or placebo) separated by a 2-week adjuvant treatment washout. Following baseline, subjects will be randomized, double-blind, to ei- ther aripiprazole or placebo for 4 weeks. After the initial 4 weeks of medication patients will be reassessed, have a 2-week washout period and then crossover to the other treatment for another 4 weeks. Data management and statistical analysis will be provided by Dr. David Schoenfeld from the Massachusetts General Hospital, Biostatistics Center.CHAPTER 12. CROSSOVER DESIGN 138 12.4 Analysis of simple crossover design AnAB=BAcrossover design may be analyzed using a regression model of the form, E[Y] =b0+b1T+b2P+b3T\u0002P; where Yis the response, and Tand Pare indicator variables for treatment group and period, respectively. The carryover effect is the treatment by period interaction. Because observations within a subject are correlated, weighted least squares estimates must be obtained using an appropriate covariance matrix. b= (X0S\u00001X)\u00001X0S\u00001Y: A popular choice for Sis the block diagonal structure where within each individual obser- vations are assumed to have a correlation of rand between individuals the observations are assumed to be independent. S=s2\u00022 6666641r0 0\u0001\u0001\u0001 r1 0 0\u0001\u0001\u0001 0 0 1 0 r1\u0001\u0001\u0001 ...............3 777775 The form of bdepends on the model parametrization. If T=( 1 2if Treatment DESIGN 139 \u000fClinical trial of the effect of 3 hypnotic drugs on duration of sleep -Study population: inmates of the Michigan Asylum for Insane -Patients were given an active treatment on each alternate evening. A typical treatment plan was: X C X C X C Y C Y C Y C Z C Z C Z C X Y Z X Y Z X Y Z, where 'C' is the control evening where no treatment was given. \u000fThese data were used in \"The probable error of a mean\" (1908) Biometrika .6(1): 1-25. The original table of the data Controls Drug X Drug Y Drug Z patient Nmean Nmean increase Nmean increase Nmean increase 1 9 0.6 6 1.3 0.7 6 2.5 1.9 6 2.1 1.5 2 9 3.0 6 1.4 -1.6 6 3.8 0.8 6 4.4 1.4 3 8 4.7 6 4.5 -0.2 6 5.8 1.1 6 4.7 0.0 4 9 5.5 3 4.3 -1.2 3 5.6 0.1 3 4.8 -0.7 5 9 6.2 3 6.1 -0.1 3 6.1 -0.1 3 6.7 0.5 6 8 3.2 4 6.6 3.4 3 7.6 4.4 3 8.3 5.1 7 8 2.5 3 6.2 3.7 3 8.0 5.5 3 8.2 5.7 8 7 2.8 6 3.6 0.8 6 4.4 1.6 5 4.3 1.5 9 8 1.1 5 1.1 0.0 6 5.7 4.6 5 5.8 4.7 10 9 2.9 5 4.9 2.0 5 6.3 3.4 6 6.4 3.5 11 - - 2 6.3 - 2 6.8 - 2 7.3 -CHAPTER 12. CROSSOVER DESIGN 140 02468Hours of sleep 12345678910 Remarks \u000fEthical issues? Potential risks of giving drugs to the mentally ill \u000fThe primary interest was to study differences between treatments; treatment se- quences were of incidental interest \u000fDrug X seem to have no effect, and Drugs Y and Z seem to have about the sameCHAPTER 12. CROSSOVER DESIGN 141 positive influence in inducing sleep \u000fSequences were not wisely chosen. X C X C X C Y C Y C Y C Z C Z C Z C X Y Z X Y Z X Y Z \u000fPatients did not receive an equal number of treatments (missing data?) Example: Hills and Armitage (1979) Hills M, Armitage P \u000fChildren with enuresis were treated with a new drug or placebo for 14 days \u000fThe primary data are number of dry nights out of 14. An estimate of within-subject differences (treatment effects) is d=YA\u0000YB. The period effects may be estimated by Z1=\u00afd1\u0000\u00afd2q var(\u00afd1)+var(\u00afd2); andZis approximately normally distributed under H0. Similarly the overall treatment effect can be estimated by Z2=\u00afd1+\u00afd2q var(\u00afd1)+var(\u00afd2); and this is approximately normal under H0. z1=2:82\u00001:25p 0:84122+0:86272=3:38CHAPTER 12. CROSSOVER DESIGN 142 12.5 A two-period crossover design for the comparison of two active treatments and placebo By GG Koch, IA Amara, BW Brown, T Colton, and DB Gillings (1989). Consider sequences of treatments TT, TC, and CT. 1. The rst period is parallel group design to address direct use in all patients 2. The second period for TT versus TC is a parallel group comparison design to ad- dress T versus C for patients who received T during the rst period. 3. The second period for TT versus CT enables \"delayed start\" assessment of T relative to C if dropout during the rst period is minimal and non-informative. 4. The second period for CT versus TC is for assessment of T relative C if carryover effects are small. 5. If T\u0000C from 1, 2, 4 are similar (carryover effects of T to T, T to C, C to T are small), then an overall analysis of treatment effect differences have a very high power. 6. More patients are allocated to receive T within each period. T. b2\u0001\u0001\u0001Period effect (for C) b3\u0001\u0001\u0001Carryover effect (for T)CHAPTER 12. CROSSOVER DESIGN 143 tcould represent additional treatment effects for longer duration. Period 1 comparison between T and C is for primary treatment effects, and period 2 comparisons address effects of delayed start (CT vs. TT) and of long-duration effects. Now consider TT, TC, CT, and CC. 1. This design can estimate all the parameters in the TT, TC, CT case. 2. CC vs. CT enables estimation of treatment effects with run-in period. 3. Relatively unethical to have many patients assigned to receive C. to T. b2\u0001\u0001\u0001Period effect (for C) b3\u0001\u0001\u0001Carryover effect (for T) tcould represent additional treatment effects for longer duration. Example: Pincus T et al. (2004) \"Patient preference for placebo, (parac- etamol) or celecoxib (PACES): two randomised, double blind, placebo controlled, crossover clinical trials in patients with knee or hip osteoarthritis\". Ann Rheum Dis.63: 931-939.CHAPTER 12. CROSSOVER DESIGN 144 12.6 Latin squares When there are ktreatments and each patient is to receive all ktreatments. Then there arek!possible sequences. Three treatments yield 6sequences, four treatments yield 24, and ve yield 120. k=3: ABC, ACB, BAC, BCA, CAB, CBA The idea is to use a reduced number of sequences (reduced sample size) but maintain a good \"representation\", i.e., every treatment is represented in every period with the same frequency. P1P2P3 S1A B C S2B C A S3C A BP1P2P3 S1A C B S2B A C S3C B A There are 6!=(3!)(3!) =20ways to choose 3 sequences from 6, but only 2 of those are Latin squares. 12.7 Optimal designs There is an extensive literature on optimal choice of sequences for measuring treatment effects in the presence of carryover. \u000fMore advanced theory \u0001\u0001\u0001 \u000fOptimality depends on assumptions about carryover effects Concerns about carryover can be reduced by using designs with more than two periods. (Laska E, Meisner M, Kushner HB. (1983) 1087-1091.CHAPTER 12. two sequences: AABB and BBAA . This design is not uniquely optimal, but it can be used to estimate treatment effects with more efciency than using data from period 1. P1 P2 P3 P4 AABB m11=m+p1+tam12=m+p2+ta+lam13=m+p3+tb+lam14=m+p4+tb+lb BBAA m21=m+p1+tbm22=m+p2+tb+lbm23=m+p3+ta+lbm24=m+p4+ta+la Note mis the overall mean, pis the period effect, tis the treatment effect, and lis the carryover effect. To obtain an unadjusted (for carryover effect) treatment effect ( B\u0000A), use the following to form a contrast B\u0000A. \u000fWeights are present, we can construct weights so that carryover effects will be number patients per sequence. period 2\b 12+02+02+02 s2 n=2s2 n: The adjusted estimator has slightly higher variance, but it is unbiased with presence of carryover.CHAPTER 12. CROSSOVER DESIGN 147 William's square When an even number of treatments are considered in the same number of periods, William's square gives an optimal design. (Williams EJ (1949). \"Experimental designs balanced for the estimation of residual effects of treatments\". Australian Journal of Scien- tic Research. Series A2 . 149-168.) It is a Latin square design in which every treatment precedes every other treatments exactly once. P1P2P3P4 sequence 1 A B C D sequence 2 B D A C sequence 3 C A D B sequence 4 D C B AChapter 13 Pragmatic clinical trials Compare and contrast pragmatic trials and explanatory trials on... \u000fInclusion criteria \u000fInterventions \u000fFollow-up \u000fIntention-to-treat 148CHAPTER 13. PRAGMATIC CLINICAL TRIALS 149 13.1 and Equivalence 13.1.1 Hypotheses Superiority H0:mt\u0000mc=0: H0:pt\u0000pc=0: H1:mt\u0000mc>0: H1:pt\u0000pc>0: Powered at mt\u0000mc=ds. To increase likelihood positive conclusion ( H1) in a superiority trial: H1:pt\u0000pc>\u0000di mt\u0000mc=0. To ( H1) in a noninferiority trial: \u000fSmall H0:pt\u0000pc<\u0000deor pt\u0000pc>de H1:\u0000de\u0014mt\u0000mc\u0014de: H1:\u0000de\u0014pt\u0000pc\u0014deCHAPTER 13. PRAGMATIC CLINICAL TRIALS 150 Powered at mt\u0000mc=0. To increase likelihood of positive conclusion ( H1) in an equivalence trial: \u000fSmall s \u000fSmalljmt\u0000mcjfrom the relevant populations (assuming mt<mc). 13.2 Sample size Sample size formula for a continuous endpoint: 1 Nt+1 not depend on the values of d1andd0. What matters is their difference. For the test regarding proportions N=\u0010 zap 2 \u00afp(1\u0000\u00afp)+zbp pt(1\u0000pt)+pc(1\u0000pc)\u00112 (pt\u0000pc)2; (13.2) for different values of ptand pceven when their differences are the same. Suppose we are testing H0:pt=pc,H1:pt>pcwitha=0:025andb=0:10when pt\u0000pc= 0:20. pc0:01 0 :05 0 :10 0 :20 0 :30 0 :40 0 :50 0 :60 pt0:021 0 :025 0 :30 0 :40 0 :50 0 :60 0 :70 0 :80 N 50 65 82 108 124 130 124 108CHAPTER 13. PRAGMATIC CLINICAL TRIALS 151 Sample size is larger near 0:5because the variance of a Binomial random variable is np(1\u0000p), which is maximized at p=0:5. Sometimes, test for proportions are parameterized in odds ratios or risk ratios. Odds ratio 2 2 2 2 2 2 2 2 pc 0:01 0 :05 0 :10 0 :20 0 :30 0 :40 0 :50 0 :60 pt 0:0198 0 :0952 0 :182 0 :750 N 3210 691 377 231 187 178 182 203 Risk ratio 1:98 1 :90 1 :82 1 :67 1 :54 1 :43 1 :33 1 :25 Difference 0:0098 0 :0452 0 :082 0 :133 0 :162 0 0 :150 Sample for equivalence (a;b;d) =Sample size for superiority (a;b=2;d). 13.2.1 Sample size adjustment for ITT analysis Dropouts and drop-ins have no effect on the numerator of (13.1), and only a small effect on the numerator of (13.2) but pose a major impact on the denominators, which are the expected difference of the means and proportions under the alternative, and they get diluted with dropouts and drop-ins. Suppose RtcandRctdenote the proportions of the subjects switching from treatment group to control group, from control group to treatment group, respectively. In the following, let \u00afX0 tand \u00afX0 cbe the observed averages of those assigned to tgroup and cgroup; let \u00afXtand \u00afXcbe the averages of those receiving each treatment. \u00afX0 t=\u00afXt(1\u0000Rtc)+\u00afXcRtc; \u00afX0 c=\u00afXc(1\u0000Rct)+\u00afXtRct;CHAPTER 13. necessary sample size will increase by the factor 1=(1\u0000(Rtc+Rct))2. For exam- ple, if you guess Rtc=0:05and Rct=0:10, then the nal sample size will be close to 40% more. 1=(1\u0000:10\u0000:05)2=1:38. Rtc+Rct0:05 0 :10 0 :15 0 :20 0 :25 0 :30 0 :50 Multiplier 1:11 1 :23 1 :38 1 :56 1 :78 2 :04 4 :00 We can also compute the power of the study as a function of Rtc+Rctwhen the sample size is computed assuming Rtc+Rct=0. Assuming wlog d0=0,s=1andr=1in (13.1) and solving for zb, we get zb=p Np 2d1\u0000za: (13.3) With subjects switching the treatment groups, we have d0 1=d1(1\u0000(Rtc+Rct)), where d1is the true treatment difference under the alternative for a treatment-received analysis, andCHAPTER 13. PRAGMATIC CLINICAL TRIALS 153 d0 1is the true treatment difference for an intention-to-treat analysis. And the actual power of the study is a function of zb0=p Np 2d0 1\u0000za: (13.4) Solving for b0in (13.4) d\u0000za: = (za+zb)(1\u0000(Rtc+Rct))\u0000za =zb(1\u0000(Rtc+Rct))\u0000za(Rtc+Rct): Fora=0:025, the following table shows decrease in power as a function of Rtc+Rct. Rtc+Rct 0 0 :05 0 :10 0 :15 0 :20 0 :25 0 :30 0 :50 Power 0:90 0 :87 0 :83 0 :79 0 :74 0 :76 0 :71 0 :66 0 :61 0 :56 0 :50 0 :29 Price et al. (2011) \"Leukotriene "}