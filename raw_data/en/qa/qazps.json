{"title": "PDF", "author": "PDF", "url": "https://ipilab.usc.edu/files/2018/04/IPILab_AnnualReport_2010-1gyfbqu.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "cleaned_text": "SOUTHERN CALIFORNIAImage Processing and Informatics Laboratory (IPI) Annual Progress Report February 2010 Image Processing and Informatics Lab Department of Radiology, Keck School of Medicine University of Southern California Suite 105, CSC/IGM, 2250 Alcaz ar St, Los Angeles, California 90033 323 442-2928 Office, 323 442-2575 Fax DEPARTMENT OF RADIOLOGY A ND BIOMEDICAL ENGINEERING UNIVERSITY OF SO UTHERN CALIFORNIA 2010 Annual Report Image Processing and Informatics Laboratory 2250 Alcazar Street, CSC 105, Los Angeles, CA 90033. Tel: (323) 442-2928 Fax: (323) 442-2575 SUMMARY The Image Processing and Informatics Laboratory (IP ILab) continues to thrive within the Health Science Campus, USC in the hub of major clinical healthcare and re search facilities such as the University Hospital, Healthcare Consultation Cent ers I and II, Norris Cancer Center, and the Zilka Neurogenetic Institute. IPILab has continued to maintain its course with research support and establishing new collaborati ons and hosting visito rs interested in Imaging Informatics training and research. Some of the accomplishments are detailed: 1. Education and Training IPILab is entering its fifth and final year of a T32 Training Grant from th e National Institute of Biomedical Imaging and Bioengineering (NIBIB), National Institutes of Health (NIH), DHHS entitled: \"Biomedical Imaging Informatics Training Progr am\" effective September, 1, 2005 - August 31, 2010, totaling about US$1.6 million. Existi ng trainees continue receiving recognition as first author in nati onal presentations, proceedings pape rs and peer-reviewed chapters and papers. We have successfully recruited f our additional T32 trainees - Three are T32 Postdoctoral Fellows, 1) Jorge Documet, Ph.D., graduating from USC Biomedical Engineering Department, Viterbi Engineering School; 2) James Fernandez, MD, who graduated from University of Hawaii School of Medicine and accepted to the USC Radiology Residency Program. He postponed his reside ncy training and has returned for a second year training working on computer-aided diagnosis; and 3) Ali Maziad, MD who completed his Orthopedic Surgery Residency at Ain Shams University Medical School, Egypt working on clinical aspect of MISS. As for the pre-doctoral fellows, Syed Ashr afulla, who graduated from University of Texas and is currently a PhD student in the Viterbi Sc hool of Engineering, USC working on informatics aspect of image reconstruction, has joined us. Two current USC BME Ph.D. students, Jasper Lee working on Data Grid of molecular imagi ng, and Kevin Ma working on Informatics model of Multiple Sclerosis, are continuing in the T32 training program. Summer activities are the height of our academ ic year for recruiting new and young blood into the IPILab for research collaborations. IPIL ab welcomed Mr. Colin Jacobs, a Biomedical Engineering Master's student from the University of Eindhoven in the Ne therlands to a 15-week internship where he collaborated on image processing and system design for Multiple Sclerosis CAD. The USC Summer Undergraduate Research Programs continues to fund our efforts to recruit and to foster bright young undergraduate students searching for fu ture academic research directions. The previous summer we were able to recruit two undergraduate students from the BME program who remained as Stud ent Assistants in IPILab after the summer. These students were accepted into the Master's Program for bot h the Electrical Engineering and the Biomedical Engineering departments respectively to continue their graduate career. In addition, an entering USC freshman was recruited this last summer, who was the youngest intern ever in the history of IPILab. Finally, Chiafen Tsai, MD, a visiting faculty from the Department of Psychiatry, Taipei Veterans General Hospital and National Ya ng-Ming University Schools of Medicine collaborated with us in Imaging Informatics resear ch during her stay here with the Department of Neurology, USC and presented a joint project with our lab at RSNA in November 2009. 1Other new additions to our lab, which are a direct result of being closer on the Health Science Campus, include Ruchi Deshpande, Young Woo Par k, Alex Zhong, and Kruti Shah, all Master's student interns from the BME graduate program. In addition to the milestones mentioned above in the T32 training program, Dr. Jorge Documet completed his Ph.D. in BME and is now a T32 Post Doctoral fellow with IPILab. Two other of our BME Ph.D. students have passed their qua lifying Ph.D. examinations. Dr. Brent Liu continues in the position as co-Chair for the \"Advanced PACS-based Imaging Informatics and Therapeutic Application\" Conference of the SPIE Medical Imaging Conference. Finally, last but not least, Dr . Bernie Huang completed and p ublished his long-awaited and new book titled \"PACS and Imaging Informatics\" Second Edition, John Wiley & Sons, Publisher January 2010. The cover of the book is included in this annual report for reference. Bernie has just become Professor Emeritus, USC. 2. Research Projects We have continued in our areas of Medical Imaging Informatics research: 1) a DICOM-RT based ePR system with Decision Support for Managing patients treated with Proton Beam Therapy; 2) CAD systems for Multiple Sclerosis detection in MRI and for small Acute Intracranial Hemorrhage detection on CT; 3) CAD- PACS Integration 4) A surgical ePR system for Image-Assisted Minimally Invasive Sp inal Surgery (MISS), the the first system has been used in daily surgical operation at th e California Spine Instit ute, 2009; and 5) The development of an eFolder System for MS Pati ents, and 6) dedicated breast MRI Data Grid system (BIDG). This year we had two papers accepted for publication in JCARS for both the CAD-PACS Toolkit and the surgical ePR syst em for MISS. We enjoyed another successful RSNA conference in November 2009 with a total of seven presentations. In addition, one paper was accepted to the ASTRO conference imme diately preceding the RSNA conference. Other existing long term research projects such as the Data Grid have continued to progress, and have expanded clinical applications in imaging-based clinical trials, small animal imaging, and Breast Cancer imaging. Some of the research work continues to be supported by extramural finds including NIH, U.S. Army Medical Research a nd Materiel Command, a nd the private industry. We are establishing new collaborations in the area of Rehabilitative Science and Physical Therapy since multi-media data is utilized in the research field in addition to Patient-related imaging informatics data. 3. Industrial Collaborations IPILab has continued R & D collaborations with the private industry incl uding but not limited to: Fujifilm, USA in the development of PACS tools; Calgary Scientific, Inc. in 3-D thin-client server system with iPhone display technology; and SurgMatix, USA in the development of an ePR System for minimally invasive spinal su rgery; and Southern Ta iwan University of Technology, Taiwan and Aurora Imaging Technol ogy, Boston in collaborating on a dedicated breast imaging data grid for healthcare of mobile breast cancer patients. As described in the Table of Contents, this 2010 Annua l Report includes materials related to the IPILab, IPILab R & D plans and current results, selected published and in-press peer-reviewed 2papers during the year, as well as preprints to appear in the Proceedings of the International Society for Optical Engineering (SPIE) in Medical Imaging , San Diego, California, February 13- 18, 2010. Our research has been supported Research Award No. 22-2149-6044 USCRA Research Fund 3051-00 Southern Taiwan University of Technology, Taiwan Fujifilm, USA MI2, USA SurgMatix, USA 3Table of Contents SUMMARY ....................................................................................................................... ............ 1 TABLE OF CONTENTS ............................................................................................................. 4 STAFF AND COLLABORATORS............................................................................................. 7 IPILAB NEW LOCATION & COLLABORATIONS .............................................................. 8 IPILAB WEBSITE ................................................................................................................ 9 10 SPIE 2010 PREPRINTS ........................................................................................................... 18 Multi-site evaluation of a computer aide d detection (CAD) algorithm for small Acute Intra-cranial Hemorrhage and Development of a stand-alone CAD system ready for deployment in a clinical environment Ruchi Deshpande, James Fernandez, Joon K Lee, Tao Chan, Brent Liu, H.K. Huang ........... 19 ePR for Data Grid Breast Imaging: Design and Specifications Jorge Documet, Brent Liu ......................................................................................................... 27 Migration from a Prototype ePR for IA-MISS System to Alpha Version Jorge Documet, Brent Liu, Anh Le ........................................................................................... 34 An automatic quantification system for Mult iple Sclerosis lesions with integrated DICOM structured reporting (DICOM-SR) for implementation within a clinical environment Colin Jacobs,Kevin Ma, Paymann Moin, Brent Liu ................................................................. 42 Decision support tools for proton therapy eP R: intelligent treatment planning navigator and radiation toxicity tool for evaluating of prostate cancer treatment Anh Le, Ruchi Deshpande, Brent Liu ........................................................................................ 50 Performance evaluation for volumetric segmenta tion of multiple sclerosis lesions using MATLAB and computing engine in the graphical processing unit (GPU) Anh Le, Young W Park, Kevin Ma, Colin Jacobs, Brent Liu .................................................... 58 Data Migration and Persistence Management in a Medical Imaging Informatics Data Grid Jasper Lee, Jorge Documet, Brent Liu ..................................................................................... 64 An Investigator-centric Data Model for Organizing Multimodality Images and Metadata in Small Animal Imaging Facilities Jasper Lee, Alparslan Gurbuz, Brent Liu ................................................................................. 71 A Zero-footprint 3D Visualization System Utilizing Mobile Display Technology for Timely Evaluation of Stroke Patients 4Young Woo Park, Bing Guo, Monique Mogens en, Kevin Wang, Meng Law, Brent Liu .......... 76 Computer-aided Bone-Age Assessment for Ethnically Diverse Older Children Using Integrated Fuzzy Logic System Kevin Ma, Paymann Moin, Aifeng Zhang, Brent Liu ............................................................... 83 The Development of a Disease-oriented eFold er for Multiple Sclerosis Decision Support Kevin Ma, Colin Jacobs, James Fernandez, Lilyana Amezcua, Brent Liu ............................... 92 Content-based numerical report searching for image enabled case retrieval Liang Xue, Tonghui Ling, Jianguo Zhang .............................................................................. 100 SELECTED PEER REVI EWED REPRINTS ....................................................................... 111 A multimedia electronic patient record (e PR) system for image-assisted minimally invasive spinal surgery International Journal of Computer Assisted Radiology and Surgery, Accepted: Published Online First, printed publication pending Jorge Documet, Anh Le, Brent Liu, John Chiu, H.K. Huang ................................................. 112 DICOM-RT-based Electronic Patient Reco rd Information System for Radiation Therapy RadioGraphics 2009; 29:961-972 Maria Y.Y. Law, Brent Liu, Lawrence W. Chan ..................................................................... 127 DICOM-RT and Its Utilization in Radiation Therapy RadioGraphics 2009; 29:655-667 Maria Y.Y. Law, of computer-aided diagnosis/dete ction (CAD) results in a PACS environment using CAD-PACS toolkit and DICOM SR International Journal of Computer Assisted Radiology and Surgery (2009) 4:317-329 Anh H.T. Le, Brent Liu, H.K. Huang ...................................................................................... 154 Cross-Racial Differences in Growth Patterns of Children Based on Bone Age Assessment J Radiology, 2009, 290, 1, 228-235 Aifeng Zhang, James W. Sayre, Linda Vachon, Brent J. Liu, H.K.Huang . ............................ 167 Feature Selection and Performance Evaluation of Support Vector Machine (SVM)- Based Classifier for Differentiating Benign and Malignant Pulmonary Nodules by Computed Tomography Journal of Digital Imaging , Vol No (February), 2010: pp Yongqiang Zhang, Jianguo Zhang ................................................................................................................................................. 175 SELECTED BOOK EXCERPT .............................................................................................. 190 5PACS and Imaging Informatics: Prin ciples and Applications. 2nd Ed John Wiley & Sons, Publisher January 2010 H.K. Huang ............................................................................................................................. 191 6STAFF AND COLLABORATORS Faculty and Administration Edward G. Grant, M.D., FACR. Professor and Chairman, Department of Radiology H.K. Huang, D.Sc., FRCR (Hon.), FAIMBE Professor Emeritus of Radiology and BME Chair Professor of Medical Informatics, Hong Kong Polytechnic University; and Honorary Professor, Shanghai Institute of Technical Physics, The Chinese Academy of Sciences James William Hill, M.D., J.D. Clinical Assistant Professor, Department of Radiology James Sayre, Ph.D. Professor of Biostatistics and Radiological Science, University of California, Los Angeles (UCLA) Consultant Cammy Huang, Ph.D. Lecturer, Computer Science Dept, Director of Scientific Outreach, WGLN Stanford University Consultant Angelica Virgen Administrative Manager Michael C.K. Khoo, Ph.D. Professor and Chairman, Department of Biomedical Engineering (BME) Brent J. Liu, Ph.D. Associate Professor of Radiology and BME Director, IPILab Greg T. Mogel, M.D. of BME Ewa Pietka, Ph.D. D.Sc. Professor, Technical University of Silesia, Poland Visiting Professor of Radiology Jianguo Zhang, Ph.D. Professor, Shanghai Institute of Technical Physics, The Chinese Academy of Science Visiting Professor of Radiology, USC Maria YY Law, MPhil, BRS, Ph.D. Associate Professor, Hong Kong Polytechnic University President, Hong Kong College of Radiography and Radiation Therapy Visiting Associate Professor of Radiology, USC Heinz U. Lemke, Ph.D. Technical University Berlin Visiting Research Professor of Radiology, USC Visiting Fellows Post Doctoral Fellows Tao Chan, M.D., Ph.D. Assistant Professor, Department of Radiology Hong Kong University Marco A. Gutierrez, Ph.D. Invited Professor Heart Institute of University of San Paulo Visiting Distinguished Research Fellow Jorge Documet, Ph.D. (T32 Fellow) Lab Manager Paymann Moin, M.D. Radiology James Fernandez, M.D. (T32 Fellow) Radiology Resident Ali Maziad, M.D (T32 Fellow) Surgery Fellow Research Assistants/PhD Candidates Graduate Student Assistants Anh Le, M.S. Ph.D. Candidate Jasper Lee, M.S. (T32 Fellow) B.S. Colin Jacobs, B.S. University of Eindhoven, The Netherlands Alex Zhong, B.S. B.S. 7IPILAB NEW LOCATION & COLLABORATIONS Street, CSC 105, Los Angeles, CA 90033 8IPILAB WEBSITE 9 RSNA 2009 POSTERS AND PAMPHLET 10 11 12 13 14 15 16 17 SPIE 2010 PREPRINTS 18Multi-site evaluation of a comput er aided detection (CAD) algorithm for small Acute Intra-cranial He morrhage and development of a stand-alone CAD system ready for deployment in a clinical environment Ruchi R. Deshpandea, James Fernandeza, Alcazar Street, CSC 105, Los Angeles, CA 90033 bDept. of Health Technology and Informatics, The Hong Kong Polytechnic University, Hong Kong, SAR, China ABSTRACT Timely detection of Acute Intr a-cranial Hemorrhage (AIH) in an emergency environment is essential for the triage of patients suffering from Traumatic Brain Injury. Moreover, the small size of lesions and lack of experience on the reader's part could lead to difficulties in the detection of AIH. A CT based CAD algorithm for the detection of AIH has been developed in order to improve upon the current standard of identification and treatment of AIH. A retrospective analysis of the algorithm ha s already been carried out with 135 AIH CT studies with 135 matched normal head CT studies from the Los Angeles County General Hospital/ Univer sity of Southern California Hospital System (LAC/USC). In the next step, AIH studies have been collected from Walter Reed Army Me dical Center, and are currently being processed using the AIH CAD system as part of implemen ting a multi-site assessment and evaluation of the performance of the algorithm. The sensitivity and specificity numbers from the Walter Reed study will be compared with the numbers from the LAC/USC study to determine if there are differences in the presentation and detection due to the difference in the nature of trauma between the two sites.. Simultaneously, a stand-alone system with a user friendly GUI has been developed to facilitate implementation in a clinical setting. Keywords: Computer Aided Detection, Acute Inter-cranial Hemorrhage, CT, Brain 1. INTRODUCTION Acute Intra-cranial hemorrhage (AIH) can lead to significant morbidity and mortality unless detected and treated in a timely manner. Heavy emphasis is placed on AIH detection and identification in patients suffering from head trauma and neurological disturbances since it has a direct bearing on further management and treatment strategies. This is especially so in the military and in emergency rooms where triage of patie nts is crucial. This vital step is often carried out initially by emergency physicians, internists and neurosurgeons. It has been shown that the competence provided by these acute care physicians in reading brain CT scans may not be optimum [1]. Since CT is the modality of choice in diagnosing AIH [2,3], the challenge can be remedied by a computer aided detection system which targets these physicians and enhances their brain CT interpretations. In the event of the AIH lesions being too small or inconspicuous, this system augments the skills of both acute care physicians and ra diologists in addition to rendering consistency to their interpretations. 2. THE CAD ALGORITHM The CAD algorithm for AIH detection was developed and tested with MATLAB (The MathWorks, Inc., Natick, MA, USA). The algorithm accepts a series of CT images in the DICOM format, as input. The system output is again a series of DICOM images, which are secondary captures of the Computer Aided Det ection. These images graphically highlight the areas positively identified by the algorithm as AIH lesions. Figure 1 depicts a flowchart of the algorithm, and Table 1 summarizes the image processing t echniques involved in each step. 19 Figure 1: Schematic diagram of the CAD system. Inte rmediary outputs of an image showing ri ght basal ganglia hemorrhage illustrate the effect of individual steps [4]. Table 1: Details of individual image processing and analysis steps in the CAD system outlined in Figure 1 [4] Steps Methods Purposes Segmentation of intracranial contents Global thresholding and morphological operations Remove structures not contiguous with the main central bulk of intracranial contents Remove bones of skull and face Remove scalp, orbits, and other head and neck soft tissue Preprocessing of intracranial contents Median filtering Adjustment of intensity according to distance from the skull Denoising Correction for CT cupping artifacts Automatic realignment of images Automatic localization of limits of brain, ventricles, floor of anterior intracranial fossa, mid-sagittal plane Align the brain into normal position Extraction of candidate AIH Top-hat transformation Subtraction between the two sides Highlight local high density regions Extract asymmetrically high density regions Localization of candidate AIH Registration of the brain in question against a normalized coordinate system Render the candidate AIH anatomical information Knowledge-based classification of AIH Rule-based system with i nputs of image features and anatomical coordinates of the extracted candidates Distinguish genuine AIH from false positives resulting from noise, artifacts, and normal variants 20 3. DEVELOPMENT OF A CAD SYSTEM FO R INTEGRATION WITH A CLINICAL ENVIRONMENT The previous implementation of the CAD algorithm was a static MATLAB program which needed to be run manually for each series in each study individua lly; following which, the results were pulled up and linked to the unprocessed images by the user. There was no facility for cataloguing im age metadata; no service which maintains a link between the unprocessed and processed studies; and no interface for view ing processed results. The goal of building an automated system is to facilitate integration of a stand-alone CAD system into a clinical environment for testing, and ultimately, for long term use. 3.1 Design issues to be considered when building an automated system for CAD (1) Ensuring that only the appropriate stud ies sent by PACS to the workstation get accepted. For instance, this application should only accept CT head image studies. (2) Once accepted, they must be sorted and stored in a suitable file folder hier archy and relevant metadata must be recorded somewhere for future reference (3) A continuous check must be carried out for recently acqui red images in order to process studies as and when they arrive (4) There needs to be a mechanism to post-process the results to resolve any metadata conflicts, and to store the results in a pre-determined manner such that the resultant series are linked to the unp rocessed, original series. (5) The CAD process needs to run continuou sly in the backgro und. On the front end, a graphical user interface is required to enable browsing through the acquired and processed studies, and to attach notes or comments to the results. (6) A web server is required for remo te access to the CAD workstation. 3.2 System Architecture The automated CAD package is comprised of the following co mponents integrated into one system, the components of which will be described in more detail below, each component being represented by the Re d Circle Numbering as shown in Figure 2. 1. DICOM Receiver The DICOM Receiver is a service which listens on a specifie d port for incoming DICOM studies and routes them to a pre-specified folder - the \"raw\" repository . This is the root folder that the control service scans every 5 minutes to check for new images. 2. Pre-processing unit The studies received from PACS may not be ready for being processed by the CAD algorithm. The studies may be non brain CT studies, sent to the CAD workstation erroneously. Su ch studies need to be weeded out before they crash the system. The DICOM metadata of the received images must be scanned to ensure that it will be accepted by the algorithm. Once these conditions are satisfied, the images may be passed on to the Control Service. 21FILE SYSTEMDATABASE DICOM RECEIVERWEB SERVER MODALITYCD ROM IMPORT CONTROL USERSLOCAL USERS 7 6 i ii AIH CAD STAND ALONE SYSTEM13 5 4 2 PRE- PROCESSING UNIT ABCD EFGH IJK L MA Figure 2: Architecture and workflow diagram for an automa ted Acute Inter-cranial Hemorrh age Computer Aided Diagnosis System 3. Database The data model, outlined in Figure 3 wa s formed along the lines of the DICOM data model of the real world. The figure illustrates that there may be two types of series - un processed (original) and processed (secondary captures). 22 Figure 3: The data model for the CAD application developed along the lines of the DICOM model of the real world, with a few additional non DICOM parameters. As shown, there are two types at the series level - the original, unprocessed series and the resulting, processed series. 4. File System The storage system is divided into two main partitions - the raw repository, which gathers all the DICOM files received from the CT/ PACS; and the \"sorted\" repository, which contains the same files as in the ra w repository organized in a file-folder hierarchy which mimics the DICOM model of the real world. 5. Control Service The Control Service is the heart of the automated CAD sy stem, and recurs at a time interval specified in the configuration file, coordinating dataflow between individual components of the system. It sorts the incoming files into an appropriate hierarchy of folders; catalogues DICOM metadata and other non-DICOM attributes in the database; initiates the running of the algorithm at regular time interval s by keeping track of which studies are complete and ready for processing; thus regulating the automation. 6. (i) GUI The graphical user interface provides a vi ew of the original unprocessed series juxtaposed with the secondary capture series, and the mouse wheel is programmed to navigate through the images in a series. The interface can be used both for 23viewing the results generated by the control service, or to intercede and run a series through the CAD manually. The study list is programmed to update itself automatically every 5 minutes, and can also be refreshed manually. 7. Web Server The web server will enable viewing of CAD results remotely, eliminating the need for users to physically man the workstation. This piece of th e application is currently in a developmental stage. 3.3 Workflow The green arrows and alphabetical indicators in Figure 2 illustrate the workflow of an automated CAD system. A. Head CT studies are sent by the PA CS to the DICOM Receiver unit in the workstation. Alternatively, studies may be imported from a CD ROM manually via the GUI into the temporary storage area. B. The DICOM Receiver passes the studies to the Pre-processing Unit which remove s and flags suspicious files. If studies are imported from a CD ROM drive, the user needs to carry out this step manually. C. Files cleared by the Pre Processing unit are then routed to a temporary storag e sector on the file system, where they lie unsorted. D. Studies situated in the temporary st orage area are then pulled up by the control service, parsed, sorted, and placed in the permanent section of the file system. E. Metadata retrieved in step D is inserted into the database. F. The control service directs the algor ithm in the AIH module to pull up specific studies from the storage area, process them, and save the resu lts at a particular location. G. The algorithm processes the required stud ies as directed by the Control Servi ce in step F, and saves the results. H. The user runs the GUI. I. The GUI queries the database for existing studies and creates a work-list. J. The GUI retrieves studies and results from th e file system as per the user's requests. K. Users access the system through a web GUI. L. The web server routes queries to the database and returns the results. M. The web server retrieves appropriate files from the file system for remote users to view. 3.4 Technical Specifications The system runs on a Windows XP/Vista platform, and requires the .NET Framework Run Time Environment. The workstation will also require a MySQL server. The DICOM receiver module fr om DCM4CHE was utilized. The control service was built in Visual C#, and incorporates the origin al MATLAB CAD code compiled to a dynamic link library. 4. MULTI-SITE VALIDATION AND EVALUATION To verify the efficacy of the CAD algorith m, a two part validation study was conduc ted. The first part of the study dealt with cases from the Los Angeles County/University of Southern California Hospital System, while the second part dealt with cases from Walter Reed Army Medical Center, Washingt on DC. These cases were matched with an equal number of normal control cases and processed by the CAD program. Th e results were then analyzed in order to identify trouble 24spots which need fine-tuning, to provide insight into developing a CAD package for installation at a clinical site, and most importantly, to ascertain the effectiveness of the algorithm. Performance of the algorithm was evaluated both on a per patient and on a per lesion basis. Evaluation on a per patient basis is of greater clinical relevance because the presence or absence of AIH dictates triage and further clinical management. On a per patient basis, if at least one lesion was correctly identified, the case was counted as one amongst the true positives irrespective of whether the rest of the lesi ons were false positives or not. If the algorithm detected AIH, but there was none, the case was classified as a false positive. If the algorithm did not detect lesions which did exist, the case was counted as a false negative, and if it did not detect lesions where none were present, that counted as a true negative. The gold standard for determining presence of lesions was the radiologists' report. Another factor that demands consideratio n is that the algorithm correctly identified lesions at times, but incorrectly classified them as not being AIH. This could arise due to incorrect registration, which would then lead to incorrect application of the knowledge based rules, ultimately resulting in false negatives. 4.1 Evaluation at LAC/ USC One hundred and thirty five CT head studies of patients diagnosed with AIH were obtained from LAC/USC and matched with a hundred and thirty five normal cases (also from LAC/USC). These studies were captured with a Picker PQ 5000 or 6000 single-slice CT scanner with 5 mm collimation, at 130 kV, and with beam currents of 30 mA. Results Table 2: Summary of CAD results for LAC/USC cases on per patient and per lesion bases [4] Overall Sensitivity Sensitivity after co nsidering correctly identified by incorrectly categorized lesions Per patient basis 77% 89.6% Per lesion basis 69.6% 84.2% The control cases yielded a 100% false positive result majorly around the falx, most likely due to incorrect registration and alignment. 4.2 Evaluation at WRAMC Eight CT head studies of patients diagnosed with AIH were obtained from WRAMC and matched with eight normal cases (also from WRAMC). Another 13 CT head studies of patients diagnosed with AIH and matched with 13 normal cases has been obtained and are currently being evaluated at the time of the writing of this report. Results Table 3: Summary of CAD results for WRAMC cases on a per patient basis True Positives 10/10 False Positives 7/10 True Negatives 1/10 False Negatives 0/10 25 Table 4: Summary of CAD results for WRAMC cases on per patient and per lesion bases Overall Sensitivity Sensitivity after considering correctly identified by incorrectly categorized lesions Per patient basis 100% 100% Per lesion basis 100% 100% The control cases yielded a 87.5% false positive result majorly around the falx, likely due to reasons mentioned above. 4.3 Conclusion The system was tested with cases from both LA County Hospital and Walter Reed Army Medical Center. The results generated by the automated system match the results generated by the fundamental MATLAB encoded program. Consequently, a conclusion may be drawn that the new system retains the integrity of the original system while significantly improving the clinical an d research workflow efficiency. Although the initial sample size obtained from WRAMC is small, the CAD system was highly sensitive in detecting AIH. At this time it is difficult to make a comparison between those studies obtained from LAC/USC and WRAMC due to the small size of the WRAMC image data set. Such comparison can be done in the future as the WRAMC dataset is increasing and currently being evaluated by the CAD system. 5. FUTURE WORK In summary, a Computer Aided Diagnosis algorithm has been developed and validated across two clinical sites, and incorporated into a system which automates the workflow, facilitating its utilization in a c linical environment. Future work includes installing the system at WRAMC to carry out a small pilot study for evaluating both the algorithm and the system. REFERENCES [1] Perry JJ, et al., \"Attitudes and judgment of emergency physicians in the management of patients with acute headache,\" Acad Emerg Me d 12(1), 33-7 (2005). [2] Perry JJ, et al., \"Attitudes and judgment of emergency physicians in the management of patients with acute headache,\" Acad Emerg Me Mandel A., \"A new clinical scoring system fails to differentiate hemorrhagic from ischemic stroke when used in the acute care setting,\" J Emerg Med 16(1), 9-13 (1998). [4] Chan T., \"Computer aided detection of small acute in tracranial hemorrhage on computer tomography of brain,\" Computerized medical Imaging an d Graphics 31, 285-298 (2007). [5] Joon K. Lee, et al., \"Evaluatio n of a computer-aided detection algor ithm for timely of small acute intracranial hemorrhage computed tomogr aphy in a 26ePR for Data Grid Breast Imagi ng: design and specifications Jorge R. Documet*a, Brent J. Liua aImage Processing & Informatics (IPI) Laboratory, Ra diology Department, University of Southern California, Los Angeles, CA 90033, USA ABSTRACT The utilization of breast MRI is increasing in the diagnostic evaluation of suspicious breast findings. As more imaging centers implement dedicated breast MR, the need for managing data on a large scale, nationally and even some times internationally, has become more apparent. Our design proposal is to utilize the data grid for managing the storage of the medical images and an ePR that provides the interface to mana ge the health data of Breast Cancer Patients. In this paper, we present the data grid for DICOM images and DI COM-SR data and the image-intensive web-based ePR system technologies utilizing the simulation of a three-site dedicated breast MR outpatient centers as the clinical application. The implementation of the two technologies the ePR system together with the Breast Imaging Data Grid (BIDG) can provide a global solution that is portable for the Breast Cancer patient including aggregation of Mammo, US, MR, CAD, BI-RADS, and clinical related reports data to form a powerful platform for data mining and outcomes research. Keywords: ePR, System Integration, Breast Imaging, Data Grid 1. INTRODUCTION More than 250,000 women are newly-diagnosed with breast cancer in the United States each year. Currently, conventional mammography is the imaging modality of choice to evaluate the extent and size of the breast cancer prior to surgery. The surgeon largely relies on the mammogram to delineate the extent of the cancer and identify additional tumor foci. Unfortunately, the accuracy of mammography to detect cancer decreases as the breast density increases and dense breast tissue is more common in pre-menopausal women. Contrast Enhanced (CE) MRI of the breast is becoming a significant imaging adjunct to mammogra phy because of its high sensitivity (93-10 0%) in the detection of malignancy. The ability of CE-MRI to depict symptomatic \"macroscopic cysts\" may lead to the prevention of unnecessary biopsies through its characterization of target masses and breast anatomy and possibly provide a higher detection rate of other lesion types including solid le sions and carcinomas. Additionally, it is of great clinical importance to successfully preoperatively identify women who need wider surgical excision or a mastectomy, as complete tumor removal is mandatory to avoid tumor recurrence and improve survival. Grid computing is the integrated use of geographically distributed computers, networks, and storage systems to create a virtual computing and communication system environment for solving large-scale, data-intensive problems, for example, in various medical image applications [1]. This paper focuses on the Data Grid, a subset of Grid computing. The Image Processing and Informatics Laboratory (IPILab) has been on the forefront for developing applications of the Data Grid for both Tier-2 Enterprise storage as well as Imaging-based C linical trials of clinical imaging data. The application in this paper is to develop a system that simulates a multi-s ite enterprise level fault-tolerant Breast Imaging Data Grid (BIDG) to support standalone dedicated breast MRI imagin g systems and related quantitative breast imaging data for archive and image distribution management . The Globus 4.0 [2] five-layered op en source toolkit for Grid Computing integrated with customized DICOM [3] technology and IHE (Integrating the Healthcare Enterprise) [4] workflow profiles forms the infrastructure of the BIDG. The benefits of BIDG for current and future developments are: 1) It provides an enterprise-level dedicated breast MRI fault-tolerant archive and image/data distribution capability. 2) It allows the integration of all related breast images and data of every patient belongs into a central repository by means of a patient record in an open architecture DICOM Web-based eP R system. This record can be retrieved systematically from any wo rkstation that has access to the central repository. 273) It possesses data mining capability to perform individual and group patient outcome analysis. 2. METHODS AND MATERIALS 2.1 The BIDG The DICOM-based Breast Imaging Data Grid (BIDG) is an in novative infrastructure that s upports an enterprise level Web-based ePR (Electronic Patie nt Record) system for large-scale breast imaging archive and distribution management. The BIDG has the following functions: 1) It archives 3-D dedicated breast MRI images, and patient records related to the MRI study including other modality type breast images in DICOM format and diagnostic reports. 2) The Data Grid provides fault-tolerance to all archived data. 3) The BIDG also utilizes DICOM Structured Report (SR) standard and IHE workflow profiles linking special quantitative DICOM metadata, reports and breast images for patient record distribution through the ePR. 4) Within the BIDG, any site can access patient record including images a nd reports from other sites provided permission has been granted by the enterp rise. In addition, access rights to patie nt records from different sites can be controlled through security protocols within the BIDG. 5) Following Item 4, any CAD or Post-processing workstation (WS) can display 3-D dedicated breast MRI images from other sites including the quantitative metadata through DICOM-SR. 6) This work has been done in collaboration with AURORA, an specialized vendor for dedicated breast MRI. 2.2 The components of the BIDG The BIDG utilizes open source software Globus 4.1, DCIOM image standard, IHE (Integrating the Healthcare Enterprise) Workflow profiles, and SAN storage technology [5 ] for customized clinical and research applications. This technology has been developed in our Laboratory for over four years, and has been applied as a solution for second-tier PACS backup, Imaging Center Resource for clinical trial, and Molecular Imaging Center Archive. Figure 1 bottom right depicts the concept of the customized Breast Imaging DATA GRID (BIDG), the SA N P2 dedicated to the Data Grid for the backup archive of other sites conn ected to the BIDG, and additional com ponents required in each of the three proposed clinical sites. 28 Figure 1. The infrastructure of a three-site Dedicated Brea st (DB) MRI Systems (more sites in the future) enterprise. Three Dedicated Breast Imaging sites operate independently and separately and are connected by the Breast Imaging Data Grid. Each site has a standalone DB Breast MRI System with its own server and storage device. It can also acquire other breast imaging related data of the same patient. Aurora workstations (WS) display 3-D MRI breast images. SAN (Storage Area Network) is used for its own archive (P1), and storage backup for other sites (P 2). In the enterprise Breast Imaging Data Grid (BIDG), a WS at each site can Q/R images from its own SAN for image display. A WS of any three systems can also Q/R images from any sites belonging to the BIDG. The BIDG maintains interconnectivity of these three systems in real-time without human intervention. There are two types of dedicated breast DB GAP (Grid Assess Point) in this architecture, DICOM GAP (bottom) and DB GAP (middle left). The former is for DICOM WS to transfer from other DICOM-compliant breast imaging systems, the latter can be customized to transfer MRI images to the Data Grid. 2.3 Breast Imaging Data Grid and Related Components 1) Storage Nodes: Server/SAN storage devices provide st orage resources for the Data Grid. In this case, each acquired image at a site has three copies, the primary one is in its own SAN P1 (Site 1), and two backup copies are in two other SANs P2 (Sites 2 and 3) within the Data Grid. 2) Database Services: A Service that keeps track of DICO M metadata as well as file lo cations of different storage nodes within the Data Grid (See com ponents within the big ellipse from Fi gure 1). Dynamic and robust access to data is provided by the Data Access Interface (DAI) in the Globus toolkit integrated with the database. 3) Dedicated Breast (DB) MRI and DICOM Grid Access Point (GAP): The DB MRI GAP provides Storage and Query/Retrieve services for any DICOM-compliant WS of any Breast Imaging system to access data within the Data Grid. There are multiple GAPs in the Data Grid and can be used as the backup for each other. The DICOM 29GAP provides the transfer of DICOM files from other DI COM-compliant breast imaging modality. If the multi-site enterprise conforms to the DICOM standard in the fo reseeable future, the DICOM GAP may not be necessary. 4) ePR Web Server: A Web-based electroni c patient record system manages all breast patients in the enterprise as well as the BIDG services and comp onents. In addition, an y CAD or Post-Processing WS can easily access a patient's record at any site from the BIDG through a DG MR I GAP. The ePR also keeps a log of all patient records transaction within the Data Grid. This function can be used for future data mining applications and patient outcome studies. In addition, the ePR web server can perform diagnostics and management of the BIDG and related components. 2.4 Additional Components at each site 1) Web Clients: A web client is used for easy access to the ePR Web Server for patient records including breast imaging data and quantitative DICOM metadata. In addition, the web client can access the ePR web server for diagnostics and management logs of the BIDG and related components. 2) DICOM Conversion Unit (DCU): The DCU converts 3-D MRI images or any other related breast images (DM, US, and others) of the patient to DICOM standard if necessa ry. It also converts a speci alized MRI report to DICOM Structured Report (SR) format allowing the linkage be tween the report, images, and quantitative metadata. This feature allows a) tracking the patient progress from mu ltiple studies, b) performing data mining for patient outcome analysis, and c) developing breast imaging teaching files. The converter also covert s 3-D MRI DICOM images to CAD or Post-Processing WS display format. 3) SAN with P1 and P2 partitions: The SAN storage device at each site is di vided into two partitions, P1 and P2. P1 is used for its own patients' records, and P2 is contributed to other sites for their backup archive within the BIDG. Each image in each site has three copies, one in its own SAN P1 and two in SANs P2 of two other sites that are stored within the BIDG. Note th at P2 in each SAN is physically locat ed in the SAN of the site, however, logically, once P2 is committed to the BIDG for other sited backup, it serves only the BIDG. 2.5 The workflow The BIDG has three major functions: image/data archiv e and backup, query/retrieve , and disaster recovery. 1) Archive and Data Backup Under normal operation condition (Figure 2, left, solid lines), th e first copy of MRI 3-D breast images after acquired at Site 1 are sent to Partition 1 of its own SAN, the second a nd third backup copies are sent utilizing the GAP 1 to P2 of SAN 2 and P2 of SAN 3 contributed by other clinical sites to the Data Grid. The fault-tole rance (FT) of the GAP can be depicted by the dotted lines in Figure 2. During the backup procedure, suppose GAP 1 fails (cross-lines), then the Data Grid would automatically assign GAP 2 to replace GAP 1. GAP 2 would then complete the task original assigned to GAP 1 by storing copy 2 to P2 of SAN 2, and P2 of SAN 3. 2) Query/Retrieve (Q/R) Figure 3 solid lines (left) shows the normal operation of DICOM Q/R from WS at Site 1. If the image file is in its own SAN 1 P1, then it is normal PACS operations. The FT of SA N 1: If SAN 1 P1 fails, Q/R will go through GAP 1 to SAN 2 P2, or SAN 3 P2 for Site 1 images. If the image file is from other clinical sites, then the Q/R wi ll be initiated with GAP 1 to the Data Grid to query and then retrieve the image file from the storage nodes, in this exam ple, SAN 2, P1. The FT of SAN 2 P1: If during the process, SAN 2 fails (cross-lines), Data Grid can identify SAN 3, P1 with the image file, from which the file is then retrieved (dotted lines). If during the off site Q/ R, GAP 1 fails, GAP 2 will replace the function of GAP 1 as described in Figure 2. 30 Figure 2. Image archive and b ackup: Solid lines (left), show the normal arch ive and backup operations, the first copy of the image file is sent from the MRI acquisition to its SAN 1 P1, and two backup copies to the Data Grid SAN 2 P2, and SAN 3 P2 for backup storage through its designated GAP1. Dotted lines show when GAP 1 fails (cross-lines), and GAP 2 takes over GAP 1 functions automatically. 31 Figure 3. Query/retrieve: Solid lines (left) show the norm al operation, WS queries Site 1 images from SAN 1, P1. Off- site images are Q/R from SAN 2, P1 in the Data Grid thro ugh GAP1. Dotted lines show if SAN 2 fails (cross-lines), GAP 1 finds SAN 3 automatically and completes the Q/R task from SAN 3 P1 (dotted lines). 3. RESULTS Currently the BIDG system has been designed and developed based on the application for three clinical sites. We utilized data obtained from an AURORA CAD workstations as well as an Aurora dedicated breast MRI system to test and evaluate the BIDG simulator. In addition we eval uated other modality types including breast US and digital Mammography studies in DICOM format to create a virtual pa tient record by utilizing the IPILab PACS Simulator. The BIDG Simulator is currently being evaluated together with the breast ePR system utilizing workflow scenarios including: 1) Storing of dedicated breast MR studies into the BIDG 2) Storing of Post-Processed data into the BIDG 3) Storing of report into the BIDG 4) Storing of other DICOM studies such US and Mammo 5) Querying and Retrieving of dedicated breast MR studies 6) Querying and Retrieving of Post-Processed data 7) Querying and Retrieving of reports 32 8) Querying and Retrieving of other DICOM studies 9) Displaying all breast imaging patient cases in the ePR system Figure 4. The schematic for the BIDG Simula tor. At the top the components that simula te the DICOM data coming from the Breast MRI. The components inside the ellipse simulate the Data Grid. At the bottom, the other GAP acts as the entry point for the dev ices present in the IPILab PACS Simulator. 4. CONCLUSION The data grid implemented with a web-based ePR system can provide a robust platform for managing Breast Cancer Patient's globally and providing an infrastructure for imagi ng and informatics data that provides future outcomes and data mining research. Future work incl udes extending the BIDG simulator from the laboratory environment into a three- site clinical environment and evaluating the testing results. REFERENCES [1] Foster I, Kesselman C, Nick J, Tuecke S, The Physiology of the Grid: An Open Grid Services Architecture for Distributed Systems Integration. In Open Grid Service Infrastructure WG, Global Grid Forum, June 22, 2002. [2] Globus Toolkit 4, http://www.globus.org/toolkit/docs/4.0/ [3] IHE, http://www.ihe.net/, acce 33Migration from a prototype ePR for IA-MISS system to alpha version Jorge R. Documet*a, Anh Lea, Brent J. Liua aImage Processing & Informatics (IPI) Laborator y, Radiology Department, University of Southern California, Los Angeles, CA 90033, USA ABSTRACT Last year we presented a paper that describes the design and clinical implementation of an ePR (Electronic Patient Record) system for Image-Assisted Mi nimally Invasive Spinal Surgery (IA-M ISS). The goal of this ePR is to improve the workflow efficien cy by providing all the necessary data of a surgical procedure from the preparation stage until the recovery stage. The mentioned ePR has been implemented and installed clinically and it has been in use for more than 16 months. In this paper, we will desc ribe the migration process from a prototype version of the system to a more stable and ea sily-to-replicate alpha version. Keywords: ePR, System Post-Op Surgical Wo rkflow, Image-Assisted Minimally Invasive Spine Surgery 1. INTRODUCTION 1.1 Current Challenges in Image-Assisted Minimally Invasive Spinal Surgery Image-Assisted Minimally Invasive Spinal Surgery (IA-MISS) is a mi crodecompressive spinal discectomy procedure for decompressing nerve roots constricted by spinal disc protrusions. This image-assisted procedure utilizes a variety of still and live real-time imaging devi ces and methods including X-Ray, CT, MRI, 3-D modeling, digital fluoroscopy and digital endoscopic video. These techniques, when integrated, provide magnification, guidance and real-time course intervention to assist the surgeon with the insertion of a small tube (6 mm diameter) into the disc to remove its offending portion. IA-MISS is di fferent from standard spinal disc surgery because there is no traumatic muscle dissection, bone removal, or bone fusion . The incision is tiny enough to close with sutures and then covered with a small band-aid. Therefore, most of the complications that occur with conventional spine surgery are virtually eliminated with the IA-MI SS procedure. Over the past eight years, there have been stepwise technical and clinical advances in IA-MISS demonstrating the potential for significantly improved spinal surgical outcomes. However, there still remain large gaps along the clinical continuum from diagnosis to surgical treatment to postoperative follow-up that can be more fully addressed by the integration of a variety of advanced medical and imaging informatics technologies. The following paragraphs in this chapter will first introduce the IA-MISS workflow, data utilized, and the challenges relating to this clinical procedure. Then, a general introduction to the concept of the image-intensive electronic patient record (ePR) will be presented as a potential solution for IA-MISS and related issues. 1.2 Current Challenges in Image-Assisted Minimally Invasive Spinal Surgery Despite the overall benefits from MISS in terms of recovery time and successful patient outcomes, there are still challenges remaining that need to be addressed and are described as follows: 1. Current scattered systems within the operating room (O R) including multiple sour ces of images, video, and waveforms. This is similar to general surgery. 2. The need for enhanced workflow with data acquisition, management, and distribution all in a single system. 3. The need for an integrated data repository in a one-s top source during all stages of the surgical workflow (eg, before, during, and after). 4. The need to develop outcomes analysis for patients undergoing MISS since it is a relatively new field of expertise. 345. The need for training of new adopters in MISS. 1.3 General workflow for Image-Assisted Mi nimally Invasive Spinal Surgery The following paragraphs describe the general workflow with the steps involved in a typical MISS procedure. Figure 1 depicts this workflow. Figure 1 The Workflow of the MISS procedure showing all th e different stages: before surgery, during the surgery (including the preparation) and post surgery The workflow can be broken down into three phases: 1) Pre-Op (Before surgery), which is the phase in the surgical workflow when the patient goes for consultation and is determined that the patient needs to undergo surgery. At this time, the physician assistant(s) in agreement with the surgeon(s) plan the surgical procedure with the assistance of information gathered from different sources such as medical images (CR, CT, MRI) and patient's relevant information including pain sources, allergies, weight and height. 2) Intra-Op (During surgery), which is the phase when the surgeon performs the surgery on the different disc(s) in order to alleviate the patient's pain. While the surgery occurs, the ePR system is continuously acquiring data from the different assisting devices that are present in the OR, and these data is displayed live while at the same time is archived in the ePR for later review. A clinical su rgery last in average 30 minutes per vertebrae. 3) Post-Op (After surgery), which is the last stage of the clinical procedure where the patients recover from the surgical procedure. A set of pain assessment forms are handled to the patients to gather the new intensity levels of pain (if any) in order to make a judgment of the success of the operation; these pain forms are entered digitally into the ePR. The recovery period after surgery lasts from 45 minutes to one hour, after that the patient is discharged. Therapy can begin the next day and the patient can go back to work within 2 to 3 days. 1.4 Need for data integration As mentioned before there exists challenges that need to be covered in order to improve the overall workflow efficiency of IA-MISS and patient outcomes. One such concept that addresses these challenges and shed some light on possible advancements within the field is the concept of an image-intensive ePR (Electronic Patient Record) system with image distribution. 2. METHODS AND MATERIALS 2.1 The ePR System for IA-MISS The ePR system serves the purpose of integrating clinical data into a single source, by combining data from different sources to a centralized server. Even though ePR servers have been implemented by initiatives coming from different departments, such as radiology or cardiology; there is currently no such ePR system that has been specifically tailored for surgical data. This concept was fi rst proposed in 2001 [1], but required technologies were not readily available for system design and clinical impl ementation. The efforts done this year were aimed to improve the user experience when using the ePR and at the same time being more robust and reliable. The proposed ePR for MISS has been designed to overcome the challenges presented in section 1.2 which are currently not being designed or implemented by any ava ilable system, either from the research arena or as a commercial product. Scattered systems in the OR: The proposed ePR acq uires all Pre-Op, Intra-Op, and Post-Op pertinent available data and presents them on two organized large LCD monitors, one for Pre-Op and the second for 35real-time Intra-Op. The data is also organized and saved in the ePR based on the DICOM (Digital Imaging and Communications in Medicine) data model. The need for enhanced workflow: The proposed ePR can perform work flow analysis of a surgical procedure in OR. Additionally, it provides the necessary infrastructure to properly acquire, manage and distribute all contents to the users. Another important aspect of the workflow is regarding proper patient verification at the OR and filling out survey pain in digital form; both aspects have been considered and implemented in this Alpha release. The need for an integrated data repository: The prop osed ePR keeps all relevant information from Pre-Op, Intra-Op, and Post-Op, and stores the data in a databa se with a filesystem. In addition, the system keeps biometric information of the patients in the form of fingerprints. The need for training of new personnel for MISS: The proposed ePR is aimed to be a simple-to-use but powerful application that will make the utilization of MISS more attractive for general surgery personnel to adopt. This ePR is currently being implemented at a clinical site. The need to develop outcomes analysis: The proposed ePR brings a new and unique application in MISS surgery that will allow patient surgical outcomes analysis. Actual data collection for the outcomes analysis is in progress. 2.2 Standards used Interoperability of devices is important when data needs to be shared, accessed, and stored in an efficient and convenient manner. In addition, standards are a comprehe nsive set of rules that allow devices and especially software components to communicate between each other. Thus, standards become crucial for a robust system integration that will eventually lead to reduced costs, risks, and developmental time. The proposed ePR has been designed with the concept of utilizing available standards whenever possible. Currently we are using the following standards: 1. DICOM (Digital Imaging and Communications in Medicine): As previously mentioned in the ePR data model design, DICOM is the de facto standard for communications in medicine for medical images. Even though it was originally mainly utilized by Radiology, other clinical departments are beginning to utilize it on a daily basis. For the proposed ePR system the DICOM standard is used as the communication protocol when receiving images from the PACS (Picture Arch iving and Communication System) archive in addition to the aforementioned data model design. 2. HTTPS (Hypertext Transfer Protocol Secured): The eP R itself is a web application that allows users to obtain clinical information about patients from a single interface. The users connect to the ePR server and utilize a client browser, (ie Internet Explorer or Mozilla Firefox). All the communication are established using HTTPS for security reasons. This protocol also serves as the foundation for the communication protocol used to transfer the data from the Integration Unit (IU) to the ePR. 3. JPEG (Joint Photographic Expert Group), GIF (Graphics Interchange Format) and PNG (Portable Network Graphics): Due to the web-based nature of the ePR and the lack of native support of DICOM images on web browsers, all images are converted to formats we b browsers can understand. The format of choice for medical images is jpeg. For other type of images such as icons the gif or png formats are used. 4. RS-232 (Recommended Standard 232): This standard is used by some of the peripheral devices on the OR to transmit data out, however, even though the transmission is standard, the protocols from machine to machine can vary significantly. Thus, it is important to note that currently the vendors do not have implemented a common standard protocol to share the acquired data (data point values and video streams) for the devices within the OR. This has been a major challenge in the clinical environment and one of the major reasons for this research work in system integration and ePR development. 2.3 System architecture From the system architecture point of view, the ePR system should be designed for efficiency, effectiveness, and reliability of system operations. For these reasons, although system workflow is separate d into Pre-Op, Intra-Op, and Post-Op stages, some modules which handle multiple workfl ow stages may be combined to share system workload and reliability. For example, the fault-tolerant requirement of each component in the system is better designed to 36support other existing components of the system for easy system back-up and cost containment. Also, although there are four major components and three operational work flow phases in the ePR system, many of the software have similar design backbones, and some software may be bundled together for easier programming effort and faster system execution time. For these reasons, the ePR System architecture has b een designed from the dataflow shown in Figure 2. Figure 2 The ePR system architecture showing three operation phases: Pre-Op, Intra-Op and Post-Op (Left); as well as four operation modules, some modules are bundled up together fo r ease of data transfer and fault-tolerant back-up. The arrows show the data flow during the three phases of operati on. The outside light gray color side-way \"U\" band is the Display module backbone with fi ve subunits. Inside the opening of the \"U\" in dark gray are the Integration Unit (IU), Fault-tolerant Gateway, and Fault-tolerant ePR Server. Within the Gateway and the ePR Server, the Database and Filesystem software ar e interrelated and shared by both components. The four major components in the MISS ePR System are: 1) Data Input Integration Unit (IU); 2) Fault-tolerant Gateway server; 3) Fault-tolerant ePR Server, and 4) Vi sualization and Display. Both the Input Gateway and the ePR Server include data storage and arch ive, system database, system security , system fault-tolerance, continuous availability and failover. The GUI and display module resi des within the ePR Server. All data input systems like medical imaging, surgical video, vital signs waveform recorders, and textual data recorder generate Pre-Op, Intra- Op, and Post-Op data, and they are all categorized as input data. The imaging and data systems that generate information are existing peripheral surgical supported equipment already within the OR but they do not belong to the MISS ePR system. However, the ePR system must integrat e these systems in order to receive the input data that is acquired before, during, and after surgery to support the surgical procedure. 2.4 Improvements for the Alpha version of the ePR The following aspects went through a redesign for the Alpha version of the ePR. The previous version will be referred to as Prototype 1: The Integration Unit (IU): The IU improvements come in two different aspects of this component. o Software: \u0083 Saving both video sources: The IU Alpha version of the ePR stores both image sources at the same time for a surgical procedure comp ared to a single source being saved in the Prototype 1. In the Prototype 1 version of the IU the users had to manually select which video source was active (selecting between C-Arm and endoscope) which sometimes led to having the unused video feed as selected wh en was not used at that moment. With both sources of video being stored in the ePR we also added the benefit of comparison when the surgeon wants to take a C-ARM image while utilizing the endoscope device. 37\u0083 Additional timestamps: In order to address the challenge of performing outcome analysis, as mentioned on the section 1.2, we needed to accurately and reliably store the beginning and ending timestamps for ea ch surgical procedure. \u0083 Data acquisition using multi-threads: Alpha version of the ePR was improved significantly with the development of data acquisition from different devices in parallel using multiple threads as compared to the sequential mode used for Prototype 1. This improvement allowed us to collect data in 1-second intervals. \u0083 Communication protocol between the IU and the ePR: The communication protocol used to store all the data captured by the IU (images and datapoints) was migrated from a proprietary protocol to web services. With this change we gained flexibility and reliability for the data collection. o Hardware: The main goal for the hardware change was to provide system redundancy in case of failure; all the different data sources have dual inputs to the IU, thus, in case one of the servers in the IU fails, the other will take over from that poi nt further. However, at the time of writing, the failover is done via manual switching between the servers. We are studying the feasibility to provide an automatic mechanism for this task. The new mobile IU is shown in Figure 3. Figure 3 The Mobile IU at the OR with the different pieces that . Patient Biometrics: We implemented a biometrics registration and verification toolkit to provide an easier way to launch the clinical Pre-Op data for a patient in the OR while at the same time reducing any possibility of patient misidentifi cation. This module was implemented using CrossMatch fingerprint scanners and a corresponding SDK. Post-Op Authoring toolkit: Having the IU being able of collecting more data, by means of higher frequency collection intervals and saving both video feeds at the same time, the Post-Op had to be redesigned as well. The main challenge was to include both sources of video in the screen while showing the waveforms in a synchronized manner. Figure 6 in the Results section show the screenshot of the new Post-Op Authoring toolkit. 3. RESULTS Since October 2008, the ePR system has been deployed at a clinical site, California Spine Institute (CSI). For the Pre-Op stage the users can register new patients, create new surgical procedures, add key images to those procedures with their corresponding annotations, add patients' survey s form into the ePR, and include whiteboard data. All these data are being displayed during live surgical procedures. The Intra-Op module is currently under clinical 38evaluation and data from the surgical procedures are being collected for an alysis and Post-Op authoring module evaluation. Due to the high sensitivity of the data being displayed, the IU is undergoing some performance improvements to handle different input sources adequately and more efficiently. The feedback loop is being carried on with the clinical staff. Certain refinements related to interconnectivity of some peripheral surgical devices are being done with clinical feedback. The 3 major stages on the surgical workfl ow: Pre-Op, Intra-Op, and Post-Op are explained below with the developed GUI and corresponding screenshots. 1. The Pre-Op stage of a MISS procedur e is where all necessary information prior to the surgery procedure is collected and organized in a patient e-folder. The Pre-Op happens days prior to the surgery and involves querying, interviewing, collecting, and storing of pre-surgical medical images, patient demographic information as well as other pertinent data value that would assist the surgery during the procedure, such as patients' fingerprints. Figure 4 below shows a screen shot of this stage utilizing the Pre-OP authoring toolkit. Figure 4 The Neuro-navigator tool, which is a part of the Pre-Op authoring toolkit, allows the correlation of the position of the lesion in the sagittal (left) and the axial view (right). 2. The Intra-Op stage is defined by the time during which the surgical pr ocedure is being performed by the surgeon in the OR. All information collected during the Pre-Op are displaye d in the Pre-Op display Monitor in OR. In addition live data from different input devices during the surgery are collected by the Integration unit (IU) and displayed in the Intra-Op m onitor screen. Before the surgery starts, the patient's fingerprint is captured in the OR and verified with the biometric data acquired during the Pre-Op stage. This is an important step towards reducing errors and insuring correct patient identification prior to surgery. Figure 5 below depicts a screenshot of the Intra-OP Live Display. 39 Figure 5 A mock-up example of the Intra-Op Live Display as seen on the Intra-Op large monitor in OR. Top row: Waveforms of six vital signs, BIS, and IVF, the horizontal axis is time. Middl e row: Waveform EMG, Fluoroscopic image, and endoscopic Bo ttom row: Laser output values. 3. The Post-Op stage takes place after th e completion of the surgical procedure. There are three substages: 1) Patient in the recovery area and then discharged, 2) the Surgeon documents the surgical results, and 3) follow up pain surveys. In addition, with the Post-Op authoring toolkit, the surgeon can create image reports which can include important Pre-Op and Intra-Op data. Figure 6 The Post-Op interface that show s the different waveforms from the vita l signs datapoints collected during the surgical procedure. This interface also shows the 2 video feeds that were captured by the IU. All the data shown above is synchronized in time for easier review. The darker secti on at the right of the displayed waveforms indicates the actual duration of the clinical procedure from the time the surgeon initiates the procedure until the end of it. 404. CONCLUSION An ePR system tailored for Minimally Invasive Spinal Surgery has been migrated from its prototype version 1 to a more robust and mature alpha release. The data model still follows the DICOM standard with new data objects designed specifically to address the surgical procedure; in addition, the database schema has been modified to include all the datapoints and image captures acquired during a surgical procedure. The system was implemented at a clinical site that performs MISS and the surgical data is currently being captured and stored within the ePR system. From the technical point of view, the ePR system is more stable and robust due to the fact of migrating to a more reliable communication protocol between the IU and the ePR/ Gateway servers. The Alpha release of the system was implemented in October last year and the evaluation and analysis of the data collected is currently ongoing. The total number of cases performed since the inception of the Alpha version of the ePR system is 22 cases. REFERENCES [1] Huang H.K., 2001. PACS, Informatics, and the Neurosurgery Command Module. J. Mini Invasive Spinal Technique. Vo1 1, 62-67 41An automatic quantification system for MS lesions with integrated DICOM structured reporting (DICOM -SR) for implementation within a clinical Colin Jacobsa, Kevin Mab, Paymann Moinb, Brent 5612 AZ, The Netherlands of Radiology, USC, 2250 Alcazar Street, CSC 105 Los Angeles, CA 90033 ABSTRACT Multiple Sclerosis (MS) is a common neurological disease affecting the central nervous system characterized by pathologic changes including demyelination and axonal injury. MR imaging has become the most important tool to evaluate the disease progression of MS which is characterized by the occurr ence of white matter lesions. Currently, radiologists evaluate and assess the multiple sclerosis lesions manually by estimating the lesion volume and amount of lesions. This process is extremely time-consuming and sensitive to intra- and inter-observe r variability. Therefore, there is a need for automatic segmentation of the MS lesions follo wed by lesion quantification. We have developed a fully automatic segmentation algorithm to identify the MS lesions. Ch aracterized quantification of the lesions is performed. The quantification results, which include lesion volume and amount of lesions, are stored in a structured report together with the lesion location in the brain to establish a standardi zed representation of the disease progression of the patient. The development of this structured report in collaboration with radiologists aims to facilitate outcome analysis and treatment assessment of the disease and will be standardized based on DICOM-SR. The results can be distributed to other DICOM-compliant clinical systems that support DICOM- SR such as PACS. In addition, the implementation of a fully automatic segmentation and quantification system together with a method for storing, distributing, and visualizing key imaging and informatics data in DICOM-SR for MS lesions improves the clinical workflow of radiologists and visualizations of the lesion segmentations and will provide 3-D insight into the distribution of lesions in the brain. Keywords: Multiple Sclerosis, MR, white matter, lesion, segmentation, quantification, DICOM-SR 1. INTRODUCTION 1.1 Multiple Sclerosis Multiple Sclerosis (MS) is a common neurological disease affec ting the central nervous system. It is considered as an inflammatory autoimmune disease that is characterized by several pathologic changes including demyelination and axonal injury. The disease affects approximately 2,500,000 people worldwide between the age of 17 and 65 years old, according to the National Multiple Sclerosis Society in the USA. A recent study has conf irmed the traditional thought that MS occurs more in women than in men and more in regions more distant from the equator. 1 At present, the exact cause of MS remains unknown. The life expectance of MS patients is nevertheless not lower than the unaffected population although certain consequences of the disease could lead to early death. As mentioned, the disease is characterized by demyelinati on, and this causes the axons to be unable to effectively conduct signals through the brain. This is leading to a broad range of symptoms including sensorial, visual, cerebellar and motor symptoms. These symptoms often occur intermittent and the periodicity of the symptoms differs strongly among patients. After the demyelination, the damaged myelin sheath degenerates and forms scar tissue (sclerosis). The areas of scar tissue are referred to as \"plaques\" or lesions and the amount and size of the lesions give an indication of the disease condition and progression. The size of a lesion is usually referred to as lesion load. MS lesions occur primarily in the white matter (WM) of the brain with a preference in the periventricular area. However, lesions are also frequently found in the corpus callosum, subcortical region, brain stem, U-fibers, optic nerves and the visual pathway. 421.2 Multiple Sclerosis and MRI Multiple sclerosis lesions can be detected with MR imaging w ith great sensitivity and this has proven to be an important clinical tool to assess the condition of the disease in a patient. After a patient undergoes a MR examination, the radiologists will observe the acquired images and investigate the patients for MS lesions. During this process, the radiologists manually contour the lesions and try to estimat e the size and amount of lesions that are present in the patient's brain. This will give insight into the disease condition and using follow-up studies, the progression of the disease can be studied. However, the quantification of the MS lesions is difficult, time-consuming and sensitive to intra- and inter-observer variability. For those reasons, a lot of research has been done into designing either manual, semi- automatic of fully automatic MS lesion segmentation algorithms. The different research projects have been using different input images such as PD-wei ghted images, T1-weighted images, T2-w eighted images or Fluid Attenuated Inversion Recovery (FLAIR) images. In addition, the projects could be focused e ither on 2-D images or 3-D datasets. 1.3 Computer Aided Diagnosis for Multiple Sclerosis In this project, a fully automatic Computer Aided Diagnosis (CAD) algorithm is designed and developed. The focus of the algorithm will be on T1-weighted, T2-weighted and/ or Fluid Attenuated Inversion Recovery (FLAIR) three- dimensional datasets. MS lesions occur as hyperintense on T2-weighted images, but the distinction between lesions and cerebrospinal fluid (CSF) is difficult beca use CSF occurs as hyperintense as well. However, the CSF is suppressed with the FLAIR sequence thereby making the border between CS F and lesions clearly visible on these images. On T1- weighted images, the lesions normally a ppear as isointense to the normal white matter although certain circumstances such as chronic tissue injury or severe inflam matory edema can lead to a hypointense signal.2 The algorithm uses the intensity values and spatial information from the three diffe rent MR sequences to determine a classification for each voxel in the MR image. To do this accurately, several pr eprocessing steps are applied to guarantee spatial correlation between the different datasets. When a successful CAD algorith m is designed, the CAD algorithm will be integrated into an e-Folder system together with other clinical related data. The e-Folder system is a disease centric clinically tailored imaging and informatics system in a hea lth care enterprise which has many func tions such as accepting direct digital input of patient data and providing clinical decision sup port. By integrating the CAD algorithm and its results, the system is able to provide key clinical imaging informatics data for outcomes analysis and treatment assessment. 1.4 DICOM Structure Reporting The MS e-Folder that is described in further detail in \"T he Development of a Disease Oriented eFolder for Multiple Sclerosis Decision Support,\" a fellow SPIE 2010 conference presentation. The CAD algorithm produces output data that needs to be standardized and integrated with other system components as well as querable. DICOM structured reporting (DICOM-SR) provides templates to include quantification results in a standardized format3. The structured reporting would allow searching, storage, and comp arison with other similar data better than traditional paper report format. A sample diagram of how a sample DICOM-SR is modeled. Figure 1. DICOM-SR mode l in the real world.8 43 Integrating CAD results with Picture Archiving and Communication System (PACS) using DICOM-SR has been accomplished previously4. The CAD-PACS toolkit was designed to streamline the CAD workflow in PACS, from generating CAD worklist from RIS/PACS to storing CAD results in PACS as DICOM-SR objects. For this project, an integration of MS CAD with DICOM-SR is designed and implemented to directly store CAD results in a tabulated format in the database, as well as to produce DICOM structured reports that may be displayed from a PACS workstation and stored in a conventional PACS. 2. METHODS 2.1 Image alignment using the midsagittal plane A first and crucial aspect of the algor ithm is that the different images have to correspond spatially, because the final classification evaluates the different voxel intensities and positions in the T1-weighted image, T2-weighted image and FLAIR image. Evidently, a voxel at a certain position in th e T1-weighted image has to correspond to the same position in the brain in the T2-weighted image and so on. Therefore, the images are aligned according to the midsagittal plane. The extraction of the midsagittal plane is fully automatic and is based on an algorithm designed by Hu et al. in 20035. Using the midsagittal plane, the different yaw, pitch and ro ll angles are calculated and a rigid body transformation is applied to ensure registration of the different images. 2.2 Brain segmentation After aligning the images, a segmentation of the human brain is needed to select the region of the head where the MS lesions can occur. Although Multiple Sclerosis lesions occur mainly in the white matter, the choice is made to segment both the gray matter as the white matter. The reason for this is ma inly because the distinction between white matter and gray matter is difficult and lesions can al so occur on the border of gray and wh ite matter which makes the decision to segment both white and gray matter obvious. The segmentation of the brain is based on an article by Shan et al. in 2002 6. The authors describe an automated histogram-based brain segmentation algorithm that uses T1-weighted three- dimensional MR head images. Although the authors bring out a high accuracy using the T1-w images only, the brain segmentation in this system uses the FLAIR images also. Th e main reason for this is that the FLAIR sequence generates a better distinction in intensity between CSF and GM which is of major importance in the algorithm. 2.3 Probabilistic segmentation of multiple sclerosis lesions After the brain is extracted from the 3-D volume data, a method is designed to classify the voxels within the brain mask. As mentioned in the introduction, the method uses the information from the T1-weighted, T2-weighted and FLAIR image. The classification method is based on an article by Anbeek et al. in 20037. The authors proposed a method in which they use K-Nearest Neighbor classification to build a fully automatic segmentation algorithm for white matter lesions. KNN classification is a non-parametric classification technique often used in image processing which builds a feature space and calculates the nearest ne ighbors to a certain target point within this feature space. The amount of neighbors that is searched for is defined by K. The actual classification is performed by comparing the target to its K nearest neighbors to attain an estimate for the class of the target. Using the information from th e MR images, each voxel can be represented by a six dimensional vector containing the intensity values in respectively the T1-w, T2-w and FLAIR im age and the spatial position coordinates x, y and z. So, the feature space is a six dimensional space wherein a voxel can be represented as a point in th is space. Using this feature space, the probability that a voxe l is an MS lesion is in concept calculated by the fraction of the classes of its nearest neighbors in the feature space that are cons idered to be part of a MS lesion. To be able to do a classification, a feature space has to build from other datasets in which the classificati on of the voxels is known. These datasets are referred to as learning datasets. In a particular learning dataset, all voxels are classified either to be part of a MS lesion or not and thes e voxels are put into the featur e space. When a sufficient amou nt of learning points are put into the feat ure space, a voxel is classified by placing in into the f eature space and calculating its K nearest neighbors. Subsequently, the fraction of the K nearest neighbors that are classified as part of a MS lesion determines the probability of the target voxel to be part of a MS lesion. In principal, the brain of a radiologist does the sa me thing since radiologists also compare and relate a case to 44other cases from their past and knowledge to make a diagno sis. Finally, thresholding of the probability map will give you to the final binary segmentation containing the MS lesions. Figure 2 depicts the probabilistic segmentation process. Figure 2. Example of probabilistic segmentation of the multiple sclerosis lesions. The left image is the FLAIR image where the lesions are clearly visible. The middle im age displays the probability map for this specific slice. The right image shows the segmentation which is acquired by applying a threshold of 0.7 to the probability map. In addition, we use kd-trees to accelerat e the KNN classification process. Using th is kd-tree technique, a more intelligent nearest neighbor search can be done on th is tree structure which allows you to only search a few of the 'leafs' of the total tree and thereby saving a lot on computation time. 2.4 Quantification The voxels in the binary segmentation are clustered in 3-D using 26-connectivity and all clusters smaller than 10 voxels are removed from the segmentation. Subsequently, the lesion load and the number of lesions can be calculated using these clusters. Evidently, the amount of clusters corresponds to the amount of lesions that are present. The lesions are divided into several groups. These groups are created to supply information about the size of the different lesions. The lesion load of each lesion is calculated by multiplying the number of voxels by the voxel size which can be extracted from the DICOM-headers. Finally, the total lesion load is calculated. In conclusion, the final result of the algorithm will contain the amount of lesions of the different groups and the total lesion load in cm 3. 2.5 DICOM Structured Reporting for CAD Output The initial output of the MS CAD program is a text file containing total lesion load, lesion coordinates, volume of each lesion, number of lesions, 2D MR slices containing lesions and le sion representation in 3D space. A DICOM-SR template is required for converting CAD outputs. The MS CAD DICOM-SR template is presented in Figure 3 . 45 Figure 3. DICOM-SR template used for MS CAD application8, as published by Le, A. (2009). The figure shows the tree structure that can be stored in DICOM-compliant file structure. There are four parent nodes in the template: detections, analyses, finding summary and image library. Under each parent nodes, different numbers of child nodes are attached based on number of actions performed in the case. The detection branch records the detection methods used, the analyses branch records all quantitative analyses performed, and the finding summary branch records the detection and analyses re sults. The structure format is obtained directly from the DICOM standard, as detailed in DICOM supplement 23 9. 3. RESULTS More than 20 cases are collected from US C Health Consultation Center in Los Ange les, CA. Each case are of different patients. Slice thickness are 3mm without no gaps in between slices, which is important for voxel size calculation and quantification accuracy. Each image sequen ce has around 50 slices. In those cases, four are used for training purposes and 10 cases total are used in outputting data for the MS eFolder, complete with patient information. MS CAD has been performed on the 10 image cases and lesion detection results are computed. Table 1 lists the quantifiable data of CAD results. Figure 4 is a screenshot of CAD result in 3D space, displayed by the open-source ITK-SNAP tool10. Table 1. Sample MS CAD output of one patient Total lesion load 32.63 cm3 Total Number of lesions 12 Number of Lesions < 1cm3 10 Number of Lesions > 1cm3 but < 5cm3 0 Number of Lesions > 5cm3 2 46 Figure 4 Screenshot of identified MS lesion voxels bei ng rendered three-dimensionally by ITK-SNAP tool. The top left image is the axial viewof the FLAIR sequence (original image), while the top right image is the coronal view and bottom right image is the sagittal view, which are calculated from the axial view. The bottom left image is the 3D rendered image of lesion voxels. The rendered image can be rotated to view from different angles. While the CAD algorithm is written in MATLAB\u00ae, the use of IT K-SNAP tool is to more easily present the 3D view of lesions. The DICOM MR images are c onverted to ANALYZE files for easier ITK-SNAP handling and lesion image overlapping. As of the time of this writing, the CAD results ha ve not been validated with radiologists and neurologists. There remains some shortcomings of the CAD algorithm, such as the long runtime to do numerous recursive calls by MATLAB. The speed aspect of MS CAD performance is desc ribed in detail in SPIE 2010 project titled \"Performance evaluation for volumetric segmentation of multiple sclerosis lesions using MATLAB and computing engine in the graphical processing unit (GPU).\" The quantification results are successfu lly incorporated into a structured report based on DICOM-SR using the developed MS module. Figure 5 presents a series of screen shots of resulting DICOM-SR outputs. 47 Figure 5. Screenshot of sample DICOM-SR for MS CAD results The structure report is stored in the MS eFolder database as the output of CAD algorithm. DICOM-SR result is currently in the prototyping stage and has not been tested with other DICOM-compliant tools, such as PACS. The in-lab simulation of DICOM-SR workflow is still ongoing. 4. CONCLUSION This paper presents a novel approach of a standardized representation of the disease condition of Multiple Sclerosis using DICOM-compliant structured reporting of quantification results derived by fully or semi-automatic quantification of MS lesions from MR images. The structured report is based on DICOM-SR and this makes it suitable for distribution among other DICOM-compliant systems that support DICOM-SR such as PACS. With DICOM-SR, quantification results can be queried by lesion load, loca tions of lesions, and volume of each cont our. This allows data mining for cases with specific criteria previously not ava ilable to clinicians and researchers. Th e workflow of the radiologists can be improved and accelerated using the CAD system. Besides that, the quantification of the MS lesions is extremely helpful for outcome analysis and disease treatment. The results for the CAD algorithm will be integrated into an e-Folder system together with other clinical related data and this will cr eate a system that provides key clinical imaging data to specialists. Furthermore, the system provides additional data to radiologists in the decision-making process. Future works include a clinical validation of the MS CAD method, an improvement in CAD performance in terms of efficiency and practicality, and the clinical validation of fully-integrated MS CAD with DICOM-SR in a PACS 48 environment. The DICOM-SR output will also be integrated a nd stored into the MS eFolder database, where the contents of CAD results can be queried and displayed within the Ms eFolder system. REFERENCES [1] Alonso A. and Hernn. M.A. \"Temporal trends in th e incidence of multiple sclerosis: a systematic review.\" Neurology, 71(2):129-135, Jul 2008. [2] Ge Y. Multiple sclerosis: \"The role of MR imaging. \" American Journal of Neuroradiology, 27:1165-1176, Jun-Jul 2006. [3] Hussein, R., Structured Reporting\" Radiographics, 24, 891-896 (May 2004) [4] Zhou Z, Liu B, Le A. \"CAD-PACS Integration Tool Kit Based on DICOM Secondary Capture, Structured Report and IHE Workflow Profiles\" Co mputerized Medical Imaging an d algorithm for robust and automatic extraction of the midsagittal plane of the human cerebrum from neuroimages based on local symmetry and outlier removal.\" NeuroImage, 20(4):2153{2165, Dec 2003. [6] Zu Y. Shan, Guang H. Yue, and Jing Z. Liu. Automated histogram-based brain segmentation in t1-weighted three- dimensional magnetic resonance head images. NeuroImage, 17(3):1587{1598, Nov 2002. [7] Petronella and Jeroen van der Grond. white matter lesions in MR imaging.\" NeuroImage, 21(3):1037{1044, Mar 2004. [8] Le A, Liu B, Huang HK, \"Integration of computer-aided diagnosis/detection (CAD) results in a PACS environment using CAD-PACS and DICOM SR\" Int J CARS (2009) 4:317-329 [9] Digital Imaging and Communications in Medicine (DICOM) Supplement 23: Structured Reporting Storage SOP Classes ett, Rachel Gimpel Smith, Sean Ho, James C. Gee, and Guido Gerig. User-guided 3D active contour segmentation of anatomical structures: Significantly improved efficiency and reliability. Neuroimage 2006 Jul 1;31(3):1116-28. 49Decision support tools for proton therapy ePR: intelligent treatment planning navigator and radiation toxicity tool for evaluating of prostate cancer treatment Anh H. Le*, Ruchi Deshpande, Brent J. Liu Image Processing and Informatics Laboratory, 2250 Alcazar St reet, Los Angeles, CA, USA 90033; Depts. of Radiology and Biomedical Engineering, University of S outhern California, Los Angeles, CA, USA 90033 ABSTRACT The electronic patient record (ePR) has been developed for prostate cancer patients treated with proton therapy. The ePR has functionality to accept digital input fr om patient data, perform outcome analys is and patient and physician profiling, provide clinical decision support and suggest courses of trea tment, and distribute information across different platforms and health information systems. In previous years, we have presented the infrastructure of a medical imaging informatics based ePR for PT with func tionality to accept digital patient informat ion and distribute this information across geographical location using Internet protocol. In this paper, we present the ePR decision support tools which utilize the imaging processing tools and data collected in th e ePR. The two decision support tools including the treatment plan navigator and radiation toxicity tool are presented to evaluate prostate cancer treatment to improve proton therapy operation and improve treatment outcomes analysis. Keywords: DICOM-RT, DICOM-RT -ION, ePR, Proton Therapy, Prostate, Decision Support 1. INTRODUCTION The current workflow of proton therapy has four main phases: Consultation, Treatment Planning, Treatment Delivery and Follow-up. After the Follow-up phase, patient data are usually collected by research department to do further analysis for improvement in treatment methodology and quality of care. Many treatment protocol s used in radiation therapy ne eds to go through an acceptance process whet her a protocol is adequate to deliver the total dose to patient without new side effects or radiation toxicity. At the James M. Slater, M.D. Proton Treatment and Research Center, th e escalation dose treatment protocol, in which the current total dose has been increased to 80 Gy, has been utilized in clinical treatment for many years and this protocol has proven to have minimum radiation toxicity compared to lower do se. The current practice is to give the patient one fraction, 2 Gy, of total dose each day, five days a week until the patient receives all pres cribed dose. This treatment du ration usually consists of 40 fractions in 40 days, approximately 2 months. The duration has been a problem for many patients since most of them are not local. Another treatment pr otocol has been introduced and is undergoing evaluation and acceptance process. This new method, called hypo-fractionation dose protocol, allows patient to receive higher dose pe r day; therefore, decreases the total fractions of PT. [1] In order of evaluate the new protocol for prostate cancer, res earchers need to collect all the clinical information, images and treatment plans data. The pr oblem arises when the data is scattered among many systems. Furthermore, there is no system to collect all the data in one source for doing ou tcome analysis and QA in treat ment planning that can be transferred to multiple locations. The ePR is an effective sy stem that provides a centrali zed archive for all data of prostate cancer patient treated with proton therapy. On top of that, the ePR is constructed with decision support tools which foster the process of treatment planning and data anal ysis. Two examples will be disc ussed in this paper are an intelligent treatment plan navigator (ITPN) and radiation toxicity tool (RTT). *anhhle@usc.edu; phone 1 323 442-2936; fax 1 323 442-2575; ipilab.org 50 Figure 1. Screenshots illustrate ITPN workflow (a) Feature 1: Single DVH curve navigation along x-axis and y-axis using arrow buttons; (b) Feature 2: Multiple DVH curves navigation; (c) Feature 3: Display 3D su rface of chos en critical structure, dose distribution; (d) Feature 4: Display 2D CT Im ages with contours and isodose cu rve overlaid; (e) Feature 5: Display quantitative measurement of overdose volume in critic al structures. (Orange-bladder; Green-rectum; Pink-prostate; Brown-isodose surface). 512. METHODOLOGY 2.1 The ePR Architecture We have developed an ePR system with DICOM compliance that can archive patient images and related treatment planning and clinical outcomes data. The visualization tools, such as MR/CT image fusion, RT and RT-ION objects interpretation module, and a knowledge database to foster treatment planning process, are developed based on DICOM images, DICOM-RT and DICOM- RT-ION objects with clinical collaboratio n from James M. Slater, M.D. Proton Treatment and Research Center, Loma Linda, CA and its on cologists and physicists. The data includes two DICOM image objects and four DICOM RT and RT-ION objects. In addition, clinical outcomes data collected from select PT cases are included in the overall databa se knowledge for future outcomes analys is. For example, th e ePR provides an interface for clinician to input follow-up data and outcome data, and uses these data to determine the rectal toxicity based on the Common Terminology Criteria for Adverse Events v3.0 (CTCAE). Through analysis of rectal toxicity of previous patients, clinicians can improve treatment plans on cu rrent patient who has similar ch aracteristics, such as age, prostate size and radiated rectal volum e. A Graphical User Interface (GUI) application embedded in the ePR allows clinicians to manipulate DICOM images, review contours, isodose and dose-volume histogram (DVH) curves, and render 3D dose images. The ePR system utilizes the Web-based technology; hence, the patient data can be visualized through web browser and distributed across multiple locations by the local area network and Internet. [2-4] 2.2 The Intelligent Treatment Plan Navigator Design In order to plan the treatment of hypo-fractionation and dose escalation protocols, both physicist and oncologist need to ensure that the 90% isodose curve needs to cover entire pros tate gland; the critical structures, such as bladder and rectum, fall under approved clinical ranges; and the plan has no overdose regions. The current treatment tools are limited in their ability to provide in telligent navigation of data for the necessary evaluation. Therefor e, we designed and developed the ITPN utilized the DICOM-compliant ePR platform and patient data stored in ePR database to enhance the treatment planning process, therefore, improve PT workflow. The features of the INTP include: - Navigate along a single DVH curve to verify dose of the tumor and critical structures along with correlated dose distribution volumes in 2D and 3D, - Navigate through multiple DVH curves with the same co rresponding volume or dose along with correlated dose distribution volumes in 2D and 3D, - Visualization and quantification of overlapped or non-overlapped region between the structure volume and isodose using 3D surface rendering, - Automatic visualization and qu antification of overdose regi ons in critical structures. Figure 1 shows the features of the Intelligent Treatment Plan Navigator (ITPN) with examples of what the graphical user interface (GUI) provides for each of the features. 2.3 Radiation Toxicity Tool In order to assess the effectiveness of the hypo-fractionation protocol, one must analyze the outcome data, which are depicted by the radiation toxicity of the treatment. The radiation toxicity is usually graded on a scale from 1 to 5. Grade refers to the severity of the adverse event (AE). The Cancer Radiation Therap y Program, National Cancer Institute has published the Common Terminology Criteria for Adverse Events (CTCAE) (formerly known as Common Toxicity Criteria) as standards used to grade, assign attribution and repo rt side effects or radiation toxicity experienced by patients in clinical trials. The version used in the Radiation Toxicity Tool of the ePR is CTCAE v.3 published on August 9, 2006, including all AE applicable to all oncology trials regardless of chronicity or modality [5]. The radiation toxicity is usually graded on a scale from 1 to 5. Grade re fers to the severity of the adverse event (AE). The toxicity grade is most important measurement for the e ffectiveness and efficiency of PT treatment in radiation treatment. However, the current method of determining this grade is to manually read the CTCAE guideline and assign a 52grade for each symptom dependent on its severity. This process is not only tedious and time consuming but also prone to mistakes due to human error. Furthermore, user cannot query or relate patient data and toxicity grade with treatment plans to do futher analysis. The Radiation Toxicity Tool (RTT) is developed to eliminate problem in this process using simple database table and query approach. The RTT uses the CTCAE v.3 as a guide line to create the ctacaemap table, as shown in Figure 2, for querying the toxicity grade according to the AEType, AE and severity of these AEs. Figure 2 also shows examples of information stored in this table. The features of the radiation toxicity tool include: - A digital form for clinician to enter outcome data, - A automatic engine to determine radiation toxicity grade according the CTCAE v.3 guideline, - A report graphical user interface to show the pa tient outcome summay and worst toxicity grade. - A query tool to relate toxicity grade and patient treatment plan data. Figure 2. Radiation toxicity tool database schema. Top: ctcaemap table structure contains the information published in CTCAE v.3 to evaluate radiation toxicity grade. Bottom: examples of data stored in ctcaemap table. 3. DATA The ePR system is a centralized system that integrates all disparate data and provides a \"one-stop-shop\" for data of prostate cancer patients treated with proton therapy. All the data utilized in my research is collected at the James M. Slater, M.D. Proton Treat ment and Research Center, Loma Linda University Medical Center (LLUMC). A prostate cancer patient's data set includes an Initial Data Form, CT images, a RT Dose, a RT Structure Set, a RT ION Plan, one or two RT Images, RT ION Treatment Record, an d Initial Data Form and Follow-up Data Forms. Table 1 summarizes all data collected from one patient. Currently, there are more than 30 patient data sets in total of 50 patient data sets has been collected. These data is used to evaluate the ePR system, including the intelligent treatment plan navigator and radiation toxicity tool. The 50 patient data sets will be used in a pilot study of evaluation hypo- fractionation treat 53Table 1. Proton therapy data collected from one prostate cancer patient. Name Media Type Digital Format Location Patient Initial Data Form Text Pre-treatment Clinical Data No Research Spreadsheet CT DICOM Files Image Yes PT Data Server RT Structure Set DICOM File Contours Yes TPS WS RT-ION Yes Image DICOM File RT Image Yes TPS WS RT Dose DICOM Dose Image Yes TPS WS RT-ION Treatment Record* DICOM File Treatment Record No Patient Chart Follow-up Data Form Text Outcom e Data No Research Spreadsheet (* not currently collected since this data type is not significant for current status of the system) 4. RESULTS The 30 collected patient data sets, mentioned in Section 3, are imported into the ePR system to evaluate the system and testing the two developed tools. The following sections wi ll discuss the graphical user interface (GUI) and interaction steps of the ITPN to evaluate treatment plan and RTT to assess outcome data. 4.1 Intelligent Treatment Plan Navigator GUI The ITPN allows a user to intelligently navigate between DVH curves and corresponding 3D dose distribution volumes along with quantified volume data of overdosed regions for better evaluation of complex treatment plans. Figure 3 shows a clinical example of graphical user inte rface (GUI) of ITPN and below are steps th at the user can interact with the GUI to evaluate the treatment plan. 1. Step 1: Utilizing the ITPN, the user can first review the DVH curves of the tumor and critical structures (rectum and bladder), in region (1) of the GUI. 2. Step 2: In addition to the DVH curve, the corresponding 3D dose distribution is displayed together with the prostate and critical structures in region (3). In this case, the 3D dose distributio n (see the blue arrow) shows some dose outside of the prostate volume indicating possible dose to neighboring critical structures. 3. Step 3: The user can then include the DVH of the r ectum critical structure in region (1). Again, the corresponding 3D volume of the rectum critical structure is displayed showing how the 3D dose distribution volume overlapped into the 3D rectum critical structure volume in region (3). 4. Step 4: The 3D views are also accompan ied by 2D slice views with isodose curves overlaid. The user can use the function toolbox, region (2), to control the appearance on both the 2D view and the 3D view to properly assess any overdose regions 5. Step 5: Additionally, the quantified volume of dose that is overlapped into the rectum critical structure volume is displayed in region (5) along with the results as shown in the DVH curve. 54Isodose volume surface 312 54 Figure 3. Prototype GUI of ITPN (1) Function toolbox; (2) DVH display region; (3) 3D Rende ring image display; (4) 2D image display with contours and isodose curve over laid; (5) Quantitative measurement display. 4.2 Radiation Toxicity Tool Usage The radiation toxicity tool (RTT) allows the user to enter five adverse event types (AEType) for query purposes, which are gastrointestinal, urinary, skin, constitutional and sex fu nction. These AEs are specifically collected for prostate cancer patients treated with proton ther apy at LLUMC. Figure 4 shows the RTT GUI. Before completing the form using the \"Submit\" button, the user will do the following: - Enter the prostate specific antigen (PSA) level , - Choose the date for the form, - Choose the AEType, - For each AEType, a list of adverse event (AE) will appear, the user will then select severity of each AE from the drop down list. 55 Figure 4. Digital form for user to determine radiation toxicity grade. On this figure, the Constitutional Criteria is currently opened, the left shows the list of AE in this criteria and the drop box list contained the severity of each AE. Using this form , the user can also select the data for the form and enter prostate specific antigen level. Figure 5. The summary page includes outcome data from diffe rent dates with determined radiation toxicity grade. After the user submits the form, the RTT automatically dete rmines the radiation toxicity grade for each AEType and determine to worst grade for that patient's outcome. This calculation is based on ctcaemap stored the CTCAE v.3 guideline. After the calculations are completed, an outcome data summary page is generated, as shown in Figure 5. The summary page shows all the forms with different dates have been filled for that current patient. The RTT also provides user a GUI to query existing patient data stored in ePR to give insight for treatment of the new patient. Assuming there is a new case prostate cancer patient who will be treated with hypofractionation protocols and receives 60 Gy in total we can perform th e following search: Find all patients with toxicity grade greater than 3 that have received 60Gy total dose, as shown in Figure 6. The query gives a list of patients who has toxicity grade 3 and had 56 received total dose of 60 Gy. At that moment, user will use the ITPN to review the plan and make adjustment to new patient treatment plan to possible improve outcome of new patient or ensure the new patient get the same minimize radiation toxicity grade. Figure 6. Query GUI illustrates data mining query for patient with toxicity grade greater than 3 and received 60Gy total dose. 5. CONCLUSIONS The proton therapy ePR with images and clinical data has been developed and currently deployed at LLUMC for initial ePR system evaluation. The INTP and RTT are two decision support tools has been developed and tested within the ePR system. The successful implementation of these tools will facilita te the proton workflow for both treatment planning and outcome analysis. The centralized ePR system not only provides methods for physician and physicist to review and evaluate treatment plans but also deci sion support tools for researcher to access images, treatment plans and outcome data more efficient and improve the acceptance process of new treatment protocol. REFERENCES [1] Slater, J.D., Schulte, Reinhard W., \"Proton-Beam vs Oncology 22(7), (2008). [2] Le, A., Documet, J., A., and Liu, B., \"A prototyp e of image-guided outcome analysis for prostate al., \"Image-assisted knowledge discovery and decision support in radiation therapy planning.\" Computerized Medical Imaging and Gr aphics, 31(4-5), 311-321 (2007). [4] Le, A., Liu B., \"A Proton Therapy Electronic Patient Record Based On DICOM-RT And DICOM-RT-Ion For Archiving, Distributing And Visualizing Treatment Pl ans And Outcome Data\". Presented at the 51st ASTRO Annual Meeting November 1-5, 2009, West McCormick Place, Chicago (2009). [5] \"National Cancer Institute. Cancer Therapy Evaluation Program: segmentation of multiple sclerosis lesions using MATLAB and computing engine in the graphical processing unit (GPU) Anh H. Le*, Young W. Park, Kevin Ma, Colin Jacobs, Brent J. Liu Image Processing and Informatics Laboratory, 2250 Alcazar St reet, Los Angeles, CA, USA 90033; Depts. of Radiology and Biomedical Engineering, University of S outhern California, Los Angeles, CA, USA 90033 ABSTRACT Multiple Sclerosis (MS) is a progressive neurological disease affecting myelin pathways in the brain. Multiple lesions in the white matter can cause paralysis and severe motor di sabilities of the affected patient. To solve the issue of inconsistency and user-dependency in manual lesion measurement of MRI, we have proposed a 3-D automated lesion quantification algorithm to enable obj ective lesion volume trackin g. The computer-aided detection (CAD) of MS, written in MATLAB, utilizes K-Nearest Neighbors (K NN) method to compute the probability of lesions on a per-voxel basis. Despite the highly optimized algorithm of imaging processing that is used in CAD development, MS CAD integration and evaluation in clinical workflow is technically challenging due to the requirement of high computation rates and memory bandwidth in the recursive nature of the algorithm. In this paper, we present the development and evaluation of using a computing engine in the graphical processing unit (GPU) with MATLAB for segmentation of MS lesions. The paper investigates the utili zation of a high-end GPU for parallel computing of KNN in the MATLAB environment to improve algorithm performance. The integration is accomplished using NVIDIA's CUDA developmental toolkit for MATLAB. The results of this study will validate the practicality and effectiveness of the prototype MS CAD in a clinical setting. The GPU method may allow MS CAD to rapidly integrate in an electronic patient record or any disease- centric health care system. Keywords: Multiple Sclerosis, GPU, Matlab, CAD 1. INTRODUCTION 1.1 Multiple sclerosis and multiple sc lerosis computer-aided diagnosis Multiple Sclerosis (MS) is a progressive neurological disease affecting myelin pathways in the brain. According to the National Multiple Sclerosis Society, USA, this disease affects approximately 2,500,000 people worldwide between age of 17 and 65 years old. The affected patients usually have multiple lesions in the while matter which can cause paralysis and severe motor disabilities. The symptoms include change s in sensation, visual problems, muscle weakness and depression. The exact cause of MS currently remains unknown [1]. At present, MRI T1 and FLAIR pulse sequence are used for radiological diagnosis. In these images, MS appears as multiple white lesions in the white matter of the brain. MRI can also be used to follow-up and monitor progress of the disease and the effectiveness of the drug therapy treatment. Since MRI provides excellent delineation of MS, it is fairly easy for radiologist to make a diagnosis. However, due to larg e number of multiple lesions in the MRI 3-D volume set of the brain, it is tedious and time consuming to identify the 3-D aspect of each lesion and quantify the number and size of these lesions. Furthermore, the quantitative reproducibility is not consistent due to human-observance variability [2]. Therefore, augmenting computer aided detection (CAD) with imaging informatics methods, a 3-D CAD MS package would facilitate the physician's timely diagnosis, improv e accuracy, and assess quantitatively the progress of drug therapy treatment. Despite the highly optimized algorithm of imaging processing that is used in CAD development, MS CAD integration and evaluation in clinical workflow is technically challenging due to the requirement of high computation rates and memory bandwidth. *anhhle@usc.edu; phone 1 323 442-2936; fax 1 323 442-2575; ipilab.org 581.2 Graphical Processing Unit A Graphical Processing Units (GPU) is a specialized processor attached to a graphics card dedicated to performing graphics rendering from the microprocessor. A GPU implements a number of graphics primitive operations; therefore, makes the graphics drawing directly to th e screen much faster than using the host computer processing unit (CPU) [3]. Figure 1. The diffecence in CPU and GPU architecture (ALU: Athrimetic Logic Unit) Figure 1 shows the architecture different of CPU and GPU. A CPU is expected to process a task as fast as possible whereas a GPU must be capable of processing a maximum of ta sks on a large scale of data. The priority for the two is not the same, their respective architectures show that point. GPU increase the nu mber of processing units and the CPU develop control and expend its cache. Currently, a GPU contained a much higher number of microprocessors than on a CPU, allowing a higher number of computational processes to be performed in the same amount of time. Utilizing this characteristic, one could develop a CAD specifically used the co mputational power of GPU. In this paper, we investigate challenges of using a computing engine in the graphical processing unit with MATLAB for parallel computing in MS CAD 2. METHODS AND MATERIALS We have developed a CAD system that automatically quantifies MS lesions, displays 3-D lesion map to original images according to current DICOM standard. The CAD is currently developed under MATLAB enviro nment and MATLAB imaging processing toolbox. A second version of MS CAD is also developed using computation engine within the NDIVIA graphic card with the CU DA toolkit. The algorithm of MS CAD develo ped is discussed in more detail in SPIE 2010 project titled \"An automatic quantification system for MS lesions with integrated DICOM structured reporting (DICOM-SR) for implementation w ithin a clinical environment.\" 2.1 Hardware The performance evaluation MS CAD utilized the GPU power is performed on a dedicated Lenovo workstation with NVIDA card installed. The speci fication of this workstation include two Intel\u00ae Xeon X5560 CPU at 2.8 GHz , 16.0 GB installed memory, Windows 7 64-bit operating system, and a NVIDIA Tesla C1060, a dedicated GPU computational card. The Lenovo workstation and NVIDIA Tesla card were donated to Image Processing and Informatics Laboratory, University of Southern California by Lenovo, USA [4] and NVIDIA Professor Partnership Program [5], respectively. Another regular workstation is used to run the CAD for perfor mance comparison. The specification of this Intel\u00ae Core2 6420 at 2.13 GHz, 3GB installed operating system, and a NVIDIA GeForce 8600 GT graphics card. 592.2 NVIDIA CUDA Architecture CUDA (Compute Unified Device Architecture) is a parallel computing architect developed by NVIDIA. NVIDIA provide a fully SDK (Software Development Kit) for a high layer programming. The NVIDA CUDA Architecture, as shown in Figure 2, shows both a low level API (Application Progr amming Interface) and a high level API support from CUDA SDK. They provide libraries, comparator and specifi c driver to take care of all the communication between applications with the graphics card. Figure 2. NVIDIA CUDA Architecture 2.3 GPU Implementation using Jacket Figure 3. GPU Implementation using Jacket; (a) Jacket algorit hm development process; (b) Jacket implementation steps Using Accelereye software's Jacket plugin [6], implementation of CUDA was done in relatively easy processes. Figure 3a shows the algorithm development process of an application using Jacket; developer can bypass the steps of compiling, functions optimization and re-programming. Using J acket's built in functions, variables could be declared on GPU's onboard and executed using GPU core. For example, while the function \"ones()\" declares a double array in system's memory, function \"gones()\" declares an array of doubles in GPU space. Jacket can also perform distributed 60parallel processing using functions such as \"gfor()\" for performing loops function. The steps of using Jacket developing Matlab application are shown in Figure 3b. 2.4 GPU Implementation using Matlab-MEX Implementation of CUDA within Matlab could also be don e using Matlab's MEX tool, which allows Matlab to access functions written using c/c++ - based languages. Utiliza tion of CUDA through MEX were made possible by using CUDA's C/C++ libraries and CUDA-MEX compiler executabl e called \"NVMEX\", which are available in nVidia's website. CUDA incorporated C/C++ codes were compiled using NVMEX and made system calls to the Matlab environment for execution [7]. As shown in Figure 4, after the initial equipment setup a nd software installation, the implementation of CUDA-MEX was done in two steps. First, conversion of existing Matlab based k-nearest neighbor function was converted in C++ code to run under regular MEX environment without GPU. Once conversion to C-based code is completed, incorporation into CUDA using CUDA librari es was performed to implement CUDA-MEX. Setup equipments & CUDA software Identify point for improvement in the CAD code Write the main function to MEX (C/C++) file Verify output Incorporate CUDA in MEX(C/C++) file Verify output Compile using MEX compiler Re-compile using NVMEX compiler Fix C/C++ code Fix C/C++ codeerror error STEP 1 STEP 2 Figure 4. GPU implementatio n steps using Matlab-MEX 2.5 Performance Evaluation The performance experiments were to evaluate the CAD performance between a high power workstation (Lenovo brand workstation with Intel\u00ae X5560 CPU) and a regular workstation (with Intel\u00ae 6420 CPU) using non-GPU implementation, and between non-GPU and GPU implementation on a high power workstation. In the first evaluation, total four MS cases were used to run the MS CAD on two workstations. A total time variable is implemented in the CAD source code to output the time from begi nning to the end of running each MS case into a file. The second evaluation is performed in a similar fashion, except two application packages, a non-GPU version and a GPU version, were used to run four cases on the same high-power workstation. The conclusions would be drawn from the average elapsed time in seconds of four cases. The MS cases used in these evaluations were collected from the USC Health Consultation Center in Los Angeles, CA. 613. RESULTS AND DISCUSSION 3.1 Preliminary Results For the first evaluation, figure 5 shows the time performance of running MS CAD with non-GPU implementation on a normal desktop computer and dedicated Lenovo WS, mentioned in Section 2.1. The total execution time of the MS CAD was cut by one-third on a Lenovo Workstation. According to PassMark Computer BenchMark, a computer benchmarking tool, the CPU scores of the Intel Xeon X5560 is over 9 times faster than the Intel Core2 6420 [8]. This finding suggested that an increase in CPU power is not proportional to the CAD running time. In fact, this time improvement does not justify the cost and the power of the high end CPU workstation. Furthermore, the 5.5 hour average running time of MS CAD on a high end workstati on with non-GPU implementation are not yet feasible to integrate the MS CAD in clinical environment. Figure 5. Computer benchmark in relation to CAD time performance in two workstation (WS) For the second evaluation, the MS CAD was divided into five different tasks for time measurement. Table shows status and time duration of each task for only one MS case. The results show that the GPU implementation was slightly better in the brain segmentation task but failed in performing KNN classification to find MS lesions. Table 1. Time measurement of each CAD tasks in GPU implementation vs . non-GPU implementation Tasks GPU Time (s) non-GPU Time (s) File Import 14.2 14.4 Image Alignment 89 88 Brain Segmentation 9 29 Probabilistic segmentation of MS lesions(using kd-trees and KNN classification) (failed to run) 36443 Total Time n/a 36620 3.2 GPU implementation challenges The segmentation of MS lesion is mainly based on classi fication of features space using K nearest neighbors (KNN) method. Each voxel in the 3-D volume set needs to be compared to the features space to determine whether it belongs to 62 an MS lesion. In order to accomplish this, the conventiona l non-GPU implementation uses the recursive call for each voxel. However, the CUDA does not allow for recursion du e to the nature of GPU architecture with limited stack size and memory preserved for each calculatio n. Recursion is unattractive in a massi vely parallel kernel because providing stack space for the tens of thousands of threads that may be active would require substantial amounts of memory. Serial algorithms that are normally expressed using recursion, such as quicksort, are typically best implemented using nested data parallelism rather than explicit recursion [9-10]. This is a significant challenge because current KNN sear ch implementation in current MS CAD heavily relies on recursive calling. Even though two methods have been tested, one using commercial Matlab plug-in and one using NVMEX calling directly in Matlab environment, both methods could not succes sfully run without crashing the CAD application. 4. SUMMARY We have investigated two methods of GPU implementation us ing CUDA library indirectly through a commercial Matlab plugin and directly though MEX functionality and C/C++ code. The time evaluation of MS CAD on two different systems suggested that the CAD development would not be efficient using just CPU power of high end workstation. However, the evaluation experiment of using GPU for KNN lesion classification was not successful due to using recursive calls. It is important to notice that the GPU is a highly parallel architecture designed with more processing units than allocated memory in cache and smalle r size control units for computation than a CPU. It has been well established that the GPU technology is be neficial for 3D display and parallel computations. However, for some image processing algorithm, i.e. recursion, utilizing lots of memory and requiring more processing control, the results of this study show that the GPU does not perform significantly better as compared to conventional CPU systems and even fail to perform the calculation due to memory overloading. Even th ough recursion methods are attractive towards reducing CPU running time, these methods require the system to provide cache for thousands of threads running in multiple microprocessors of a GPU which ultimately ne gates its computation power capabilities. Serial and parallel computation should also be addressed carefully in implem enting an algorithm for CAD using GPU technology, lots of processing units, smaller size cach e and limited size control units. REFERENCES [1] Alonso A. and Hernn. M.A. \"Temporal trends in the in cidence of review.\" L., Gertych, A., and Liu, B., \"The development of an MRI lesion quantifying system for multiple (2009). 63Data Migration and Persistence Ma nagement in a Medical Imaging Informatics Data Grid Jasper Lee*a, Jorge Documet a, Brent Liu a a Image Processing & Inform atics Laboratory, USC 90033, CA ABSTRACT The Medical Imaging Informatics Data Grid project is an ente rprise infrastructure solution developed at the University of Southern California for archiving digital medical images and structured reports. Migration methodology and policies are needed to maintain continuous data availability as data volumes are being copied and/or moved within a data grid's multi-site storage devices. In the event a st orage device is unavailable, a copy of its contents should be available at a live secondary storage device within the data grid to provide con tinuous data availability. In the event a storage device within the data grid is running out of space, select data volumes should be moved seamlessly to a tier-2 storage device for long-term storage, without interruption to front-end users. Thus the database and file migration processes involved must not disrupt the existing workflows in the data grid model. Th is paper discusses the challenges, policies, and protocols required to provide data persistence through data mi gration in the Medical Imaging Informatics Data Grid. Keyword : Data Grid, PACS, Data Migration, Data Persistence, Continuous Availability 1. INTRODUCTION 1.1 Data Grid in the Clinical PACS Environment The clinical application of data grid technology in the medical imaging informatics field, specifically in radiology, is gradually becoming more usable and robust over the past few years. Its progress has been encouraged by the increased utility of the Internet in medicine, and the push for digitized and sharable medical health records. Since 2005 at the University of Southern California, the Image Processing and Informatics Laboratory has developed a Medical Imaging Informatics Data Grid for radiology by building DICOM compliant software packages upon an open-source grid backbone called the Globus Toolkit (GTK). The Data Grid can connect radiology imaging studies securely and seamlessly between multiple Picture Archiving and Communication Systems (PACS) in an enterprise radiology environment. The results have been off-site back-up of sensitive patient imaging studies that is cost-effective for clinical radiology institutions by utilizing exis ting SAN infrastructure, and an enterprise DICOM image sharing solution for multi-site PACS consortiums. Major components in the first version of the Medical Imagin g Informatics Data Grid system were designed to achieve preliminary tasks to meet DICOM compliance, create a metadata database modeled for real-world DICOM objects, and secure DICOM file delivery across the wide-area-network (WAN) using GTK pack ages. Functionality at the user-level, including DICOM C-Store, C-Find, and C-Move, were implemented using DCM4CHE tools 1. Figure 1 below diagrams this system architecture with its components and services categorized into 5 design layers - application, collective, connectivity, resource, and fabric. *jasperle@usc.edu; phone 1 323 442-2928; fax 1 323 442-2575; www.ipilab.org 641.2 Data Migration and Persistence Management The Data Grid design now includes data file management feat ures such as long-term data migration and data persistence management of imaging studies archived within the Data Grid. In a data grid system, data persistence is achieved through redundancy of all data content stored at two or more distinct storage locations in order to provide higher data availability in the event of primary hardware or network failure at a participating grid site. This paper discusses the new components, highlighted in Figure 1 in boxes, and data management features that have been added to the Medical Imaging Informatics Data Grid. The ability to monitor, handle, and maintain continuous availability of data amongst the multiple storage devices are important in a Data Grid for implementation in the clinical environment. This new system infrastructure with data management services has added dynamics, policies and dataflow, and will be presented in the following methodology section. Figure 1 IPILab Data Grid 5-Layered Infrast ructure Integrating Globus Toolkit and DICOM. 2. METHODOLOGY Native data management in medical imaging informatics systems requires integration with clinical workflows such that internal movement of data does not negatively impact data availability and performance of essential user functionality. The objective of the Medical Imaging Informatics Data Grid system in radiology is to provide an enterprise solution that enables multiple PACS at geographically distributed healthcare provider sites to share and retrieve patient DICOM images for authorized radiologists, clin icians and referring physicians. Local PACS systems at each site remain the primary image archive and provider for a ll local patient imaging requests, while the Medical Imaging Informatics Data Grid is accessed to retrieve or recovery patient imaging studies archived in its internally distributed storage devices. Thus, data management features for the Medical Imaging Informatics Data Grid should optimize data and storage resource availability within the Medical Imaging Informatics Data Grid wit hout compromising perf ormance and data 65security in storage and retrieval of DICOM studies. Figure 2 below is a general use-case overview to demonstrate utilization of the Medical Imaging Info rmatics Data Grid in an enterprise healthcare provider environment. Figure 2 Components, connectivity, and general dataflow with tw o clinical radiology sites shar ing a Medical Imaging Informatic s Data Grid implementation. Step 1) New imaging studies in the loca l PACS server at site 'A' are replicated to the local GAP serv er. Step 2) Services in the GAP server update the Data Grid databases with DICOM and file metadata. Step 3) DICOM images are securely and efficiently sent to one or more storage repositorie s in the grid. Steps 4,5,6) PACS administrators at site 'B' que ry and retrieve imaging studies to be downloaded over DICOM to their local PACS server for radiologist , clinicians, and referring phys icians to access. 2.1 System Architecture The system architecture shown in Figure 1 has 5 data management components that have been added to the Medical Imaging Informatics Data Grid design. These components are a web-based user interface at the application layer, a Data Persistence Manager at the collective layer, Grid Resources Monitoring service at the core middleware layer, and Resource Monitor database and tier-2 storage devices at the fabric layer. The web-based user interface is used by PACS administrato rs to query and select archived imaging studies to be retrieved into their local PACS servers. The user interface is run in a web-server on the local GAP server and requires users to log-in, creating an audit trail of all user activity. Another purpose of the web-based user interface is for authorized Medical Imaging Informatics Data Grid administra tors to selectively migrate antiquated imaging studies to dedicated long-term storage devices, also belonging to the Medical Imaging Informatics Data Grid, so as to free up storage space on a primary storage device. The Data Persistence Manager in the collective layer is a group of services installed on primary data grid storage devices to conduct two data management services - data migrati on for long-term data archival and data persistence for 66guaranteeing data redundancy within the Medical Imaging Info rmatics Data Grid. The details and dataflow for these two services are presented in the following sections. At the connectivity and resources layer, grid resource mon itoring services are automated to periodically ping the DICOM metadata database, Replica Location Service database, and multiple storage devices to monitor uptime and real- time storage capacities. The findings are written to a centra lized and redundant database, and thereby enabling the Data Persistence Manager at the collective layer to intelligently copy or move DICOM imaging studies from one remote storage device to another. In the event of component or network failures, achieving data persistence and long-term storage guarantees a secondary physical storage location of all files which can be queried to retrieve a DICOM study to a remote site. Support for tier-2 storage devices in the fabric layer means antiquated imaging studies can be migrated from local primary storage devices to off-site long-term storage solutions that are more cost-effective than purchasing additional primary disk infrastructure. 2.2 Data Persistence In order to maximize hardware utilization, the Data Persisten ce Manager is installed on every primary storage server and designated for managing only data content residing within its local storage device. The process of maintaining two or more copies of all DICOM imaging studies archived in the Medical Imaging Informatics Data Grid requires the Data Persistence Manager to have access to shared metadata databa ses, Globus file transfer services, and all storage device repositories. Each Data Persistence Manager instance periodically scans the Medical Imagin g Informatics Data Grid's Replica Location Service (RLS) databases for the existence of a second copy of files already residing on its local storage device. If a second remote copy of an imaging study is mi ssing, the Data Persistence Manager will schedule and initiate replication of that local file automatically to a second primary storage device within the Medical Imaging Informatics Data Grid. The selection of that second copy's destination device is drawn from the Grid Resources Monitoring database and is based on the storage device with highest storage capacity percentage remaining. Upon successful replication of its files to the second location, the initiating Data Persistenc e Manager will update the RLS databases of the new file instance. 67 Figure 3 Data Persistence Manager Dataflow Steps: 1. DICOM imaging studies are sent into the GAP server from the PACS server at site 'A' 2. Metadata and Globus Replica Location Service (RLS) databases are updated for the new imaging studies 3. Imaging study files are archived to a primar y storage device with RAID 5 redundancy 4. Data Persistence Manager for storage device 'X' periodically queries the RLS database for files archived on 'X', looking for files without a second copy 5. Data Persistence Manager queries the real-time grid monitoring database to find another primary storage device 'Y' with highest storage capacity percentage remaining 6. Data Persistence Manager performs Grid FTP file transfer from 'X' to 'Y' 7. New second copy of imaging study files are written into RLS databases 2.3 Data Migration In order to give grid administrators the option of alloca ting long-term storage to a re mote and dedicated long-term storage device within the Medical Imaging Informatics Data Grid, as opposed to adding disks to an existing site's SAN infrastructure, a data migration service is needed for th e Medical Imaging Informatics Data Grid. When a storage capacity threshold is exceeded in a primary storage device, the Data Persistence Manager's data migration service on that server will query th e shared metadata database and select imaging st udies that have not been accessed for more than a given period of time, such as two years. Thereafter, a gr id administrator can log into the Data Persistence Manager's web-based user interface and authorize, or deny, the migration of these selected studies to a designated tier-2 storage device within the Medical Imaging Informatics Data Grid. 68 Data Storage Grid Services and ResourcesClinical Radiology Site A Radiology Imaging Modality WorkstationPACS Server Data Grid GAP ServerPACS Archive Data Persistence Manager for 'X' Long-Term Storage Device 'Z' Metadata & RLS Databases Primary Storage Device 'X' RAID 5 redundancy3,6 51 PACS & Data Grid Administrator Grid Resources Monitoring Service24 85% Full Figure 4 Long-Term Data Migration Dataflow Steps: 1. Grid Resources Monitoring Service identifies primary storage device 'X' as runn ing out of storage space 2. Data Persistence Manager is notified of the lack of remain ing storage capacity 3. Data Persistence Manager searches th e Metadata database for imaging stud ies residing on 'X' with a last- accessed date older than a given duration (ex. 2 years) 4. PACS & Data Grid administrator logs into the web-base d interface of the Data Persistence Manager for 'X' to authorize or deny the migration of antiquated imaging studies to long-term storage device 'Z' 5. Authorized imaging studies for migration are moved from 'X' to 'Z', and the source copy is deleted upon completion of the file migration 6. Changes in file location due to the migration are reflected in the RLS databases 3. RESULTS and DISCUSSION A method to manage a growing data volume set within a mu lti-node Medical Imaging Informatics Data Grid is being evaluated in the laboratory environment at the University of Southern California's IPILab. The data sample includes DICOM imaging studies from clinical imaging modalities and post-processing applications. The test environment is made up of three PACS simulators and a single Medical Imaging Informatics Data Grid implementation connecting them. Within the data grid are three Grid-Access-Point servers, for communica ting with each simulated PACS site, a database server, a Globus services server, and three digita l storage devices. Two of the storage devices act as primary archives with RAID 5 data re dundancy, and the third storage device acts as the secondary and long-term archive without 69any internal data redundancy. A Data Persistence Manager is initiated at both of the two primary storage devices. Using testing scenarios described below, evaluation of the Data Persistence Manager is currently ongoing. Networking and hardware limitations must be factored into both evaluations. 3.1 Evaluating Data Persistence Data persistence is being evaluated for the length of time a st udy is archived in the data grid, but not replicated at two distinct storage devices. There are two possible scenarios for evaluation. When a DICOM imaging study is sent into the Medical Imaging Informatics Data Grid for the first time, and when a copy of a study is deleted due to simulated network or storage device failure. It takes the Data Persistence Manager at least one scan cycle before file replication is initiated from one storage device to the second. Thus, meas ured length of time is taken from initial completion of archival, or deletion of an existing copy, until the completion of full redundancy. 3.2 Evaluating Data Migration Data migration is being evaluated for the length of a phys ical copy of a DICOM study is unavailable due to the data migration processes. For simulation purposes, archived studies that have been kept at a primary storage location for longer than one week is marked as antiquated by the Data Pe rsistence Manager. The antiquated study is then migrated to the designated long-term storage device, and consequently removed from the primary storage's physical disk upon completion. The length of time measured is the time of initialization to completion of data migration, during which the physical dataset is unavailable to Gr id-Access-Point servers for retrieval. 4. CONCLUSION A data migration policy and protocol is designed and presented for handling data persistence of DICOM imaging studies within the Medical Imaging Informatics Data Grid infrastructure. The data management techniques will ensure continuous availability of stor age space and optimizing the persistence of data stored on data grid storage nodes by maintaining at least two copies of all imaging studies archived within the Medical Imaging Informatics Data Grid. Due to the extensible number of storage devices and varying storage capacities within the Medical Imaging Informatics Data Grid, an automated data management tool is essential to the maintenance and robustness of the Medical Imaging Informatics Data Grid system in the clinical environment. 5. REFERENCES [1] Huang, H.K., \"Utilization of Medical Imaging Informatic s and Biometrics Technologies in Healthcare Delivery,\" Int J CARS. 3:27-39 (2008). [2] Huang HK, Zhang A, Liu BJ, et al., \"Data Grid for Large-Scale Medical Image Archive and Analysis,\" Proceedings of the 13th ACM International Conf erence on Multimedia. pp 1005-1013 (2005). [3] Zhou, Z., Lee, J., Huang, H.K., et al., \"A Data Grid C., et al., \"The Data Grid: Towards an Architecture for the Distributed Management and Analysis of Large Scientific Datasets,\" Journal of Network and Computer Applications, 23:187- 200 (2001). [5] Zhou, Z., Documet, J., Chan, L., et al., \"The Role of a Data Grid in Worldwide Imaging-Based Clinical Trials,\" USC UPU: Marina del Rey (2006). [6] Liu, B., Zhou, Z., Documet, J., \"Utilizing Data Grid Ar chitecture for the Backup and Recovery of Clinical Image Data,\" Computerized Medical Imaging and Graphics 29, 95-102 (2005). 70A Study-Centric Database Model fo r Organizing Multimodality Images and Metadata in Animal Imaging Research Facilities Jasper Lee*a, Alparslan Gurbuzb, Brent Liua a Image Processing & Inform atics Laboratory, USC 90033, CA b Molecular Imaging Center, USC 90033, CA ABSTRACT Research images and findings reports generated during imaging-based small animal imaging experiments are typically kept by imaging facilities on workstations or by investigat ors on burned DVD's. There usually lacks structure and organization to these data content, and are limited to directory and file names to help users find their data files. A study-centric database design is a fundamental step towards imaging systems integration and also a research data grid infrastructure for multi-institution collaborations and translational research. This paper will present a novel relational database model to maintain experimental metadata for studies, raw imaging files, post-processed images, and quantitative findings, all generated during most imaging-base d animal-model studies. The integration of experimental metadata into a single database can alleviate current inve stigative dependency on hand-written records for current and previous experimental data. Furthermore, imaging workstations and systems that are integrated with this database can be streamlined in their data workflow with automated query serv ices. This novel database model is being implemented in a molecular imaging data grid for evaluation with animal-model imaging studies provided from the Molecular Imaging Center at USC. Keywords : Animal-Model Imaging, Data Mining, Database Model 1. INTRODUCTION 1.1 Imaging-Based Animal-Model Research Medical research today almost always involves a pre-clinical trials phase that precedes testing in humans, and quite often requires in vivo and in vitro imaging of animal models. This phase is a proof-of-concept step that must be carried out and validated before any pharmaceutical or therapeutic experimentation can be done on humans. Therefore the imaging facilities, often called molecular imaging centers, and resources that provide investigators with these services are many and specialized. Most medical research institutions operate an animal imaging facilities for its researchers to use. However, regardless of the experimental factors and object ives, animal-models are purchased, prepared, and scanned by scientific investigators in a generic scientific workflow at animal imaging facilities. The essence of this workflow is to capture images of a live animal 's physiological and pathological activity an d identify the biomarkers in the image that can be used for quantitative and/or qualitative conclusions. Figu re 1 outlines this generic workflow that is followed in most animal-model experiments by investigators and in collab oration with staff at the small animal imaging facilities. Figure 1. General workflow of imag ing-based animal-model experiments *jasperle@usc.edu; 323 442-2575; www.ipilab.org 71With discoveries of new radiopharmaceutical labels and hi gher-resolution imaging modali ties, the utility of animal- model imaging studies and the quantity of data being generated across research is expanding. Being able to archive these datasets and share them in a long-term archiving reposito ry would be invaluable to new and established medical investigators. However, the current limitations in storage ar chive solutions hinder animal-model imaging datasets from being stored long-term and shared after publication. 1.2 Imaging Informatics in Animal Imaging Facilities Most animal imaging facilities provide on-site imaging worksta tions for investigators to process, visualize, and analyze their images. Depending on the modality and type of image file format, such as 2-dimension optical images or 3- dimension microCT volume sets, investigators at the animal imaging facilities use different and often dedicated software to access these images. Consequently, the animal imaging work stations, software applications, and data files are not usually well integrated with one another and limit the organization and sharing capabilities of image datasets, even within a single animal imaging facility. 1.2.1 Imaging Modalities Most of the imaging modalities in animal imaging facilities are similar to the modalities used in clinical radiology. For example, the microCT, microPET, micr o-ultrasound, and fundament ally the same as the human-sized modalities, only with smaller bore diameters and higher reso lutions. The autoradiography modality, shown in Figure 2.f, is essentially a digital x-ray machine with digitized film cartr idges. Optical imaging, shown in Figure 2.e, is the main animal imaging modality that is not popularly used in clinical radiology due to its shallow-to-surface imaging capability. A B C D E F Figure 2. a) MicroPET b) MicroCT c) MicroMRI d) MicroUS e) Optical Imaging f) Autoradiography Courtesy of Molecular Imaging Center , USC for Fig. 1 a,b,d,e,f, and Molecular Imaging Program at Stanford, Stanford University for Fig.1c. Despite these physical similarities in modality design, the workflow and software tools surrounding the animal imaging scanners are not as sophisticated and well integrated as in ra diology. The lack of file fo rmat standards and the emphasis on keeping pre-processed raw datasets has translated into proprietary visualization methods and limited understanding of foreign data between users and software applications. With little accessibility and utility out side of an experiment's scope, these animal-model imaging data files are typically kept untouched at these animal imaging facilities or burned onto DVD's for investigators. The results are lost experimental datasets and redundant experimentation on animals. 721.2.2 Data Storage Solutions Current informatics solutions in animal imaging facilities vary between institutions based on investigator pool size, data accessibility requirements, and workflow protocols. Facilities with more investigators usi ng their modalities, workstations and services typically have log-in user domain accounts on their workstations and some form of user interface on their workstations for scheduling their experiments and accessing created data. Facilities on a smaller operational scale may perform most of their scans by staff, where investigators participate in the imaging and analysis processes. The storage solutions for these animal imag ing facilities, however, are typically the same. A central networked storage device is shared internally by the fac ility's workstations for archiving new image data files under investigator names and study folders. Files of diverse format s are copied into the storage device from modality and post- processing workstations, and copied out for post-processing, viewing, or analysis at user software workstations. Experimental logs, parameters and findings are primarily recorded on individual log-books because there lacks an integrated archiving system and database for maintaining su ch metadata. This paper presents a study-centric metadata database model for animal imaging datasets that can be used to catalog and navigate previously unorganized multi-modality imaging data files. 2. METHODOLOGY 2.1 Data Object Formats Due to non-standardized file formats in animal-model imagin g studies, the archival and sharing of data in animal imaging facilities have been a challenge. Raw acquisition im ages, acquisition header files, intermediate reconstruction files, post-processing workflow files, analysis ROI files, and varying displa y formats all have metadata associated with them and add to the complexities of crea ting a centralized database archive for organizing and finding imaging datasets. Table 1 lists some common modalities, and their file format s and descriptions, based on the USC Molecular Imaging Center facility. With these differ ent file formats identified, a database model can be built to describe the metadata fields attached to each modality file type. Table 1. Common file formats for five small animal imaging modalities. Modality Type File Format *.img MicroCT *.cat + *.cat.hdr *.img MicroPET/CT *.img *.img *.xif PET Input file Co-registered Image Optical *.tif *.txt *.png Acquisition files Processing Parameters Final Overlay Image Ultrasound *.avi *.tif *.dcm Recorded video clips Screenshots Screenshots a metadata database schema enables data-mining and study-specific management of animal-model imaging files. To accommodate multi-modality and multi-vendor ac quisition parameters and post-processing parameters in molecular imaging, the proposed metadata database schema u tilizes a linked series of tables that is both comprehensive and extensible in design. The parent table for the entire da tabase schema is the 'study' table, containing metadata descriptors for each imaging study with fields such as the unique study ID, study descrip tion, region-of-interest, and study status. Imaging investigators are given an investigator ID that is pointed to the imaging studies they have access to, forming a unique primary key combination in the 'investigator' table. A child of the 'study' table is the 'subject' table that describes the animal groups used in each study. On e study may have multiple subject groups, each requiring an 73authorization IACUC 3 number. Another child of the 'study' table is the 'r eport' table that lists analysis files and report files, but is limited in its data field content, due to the vari able nature of experimental objectives, to analyst's name, the report filenames, and the date of when a particular report file was created. Figure 3. Database Model fo r Animal Imaging Datasets 74For each modality type, there may be different acquisitio n formats between vendors and even between acquisition software versions; so the 'acquisition format' table is a ma pping of modality ID's to one-or-more acquisition types. For each acquisition type, there are one-or-more parameters that need to be recorded such as bin factors and scan duration; so the 'acquisition parameters' table is a mapping of acquisition types to parameters. And finally, the 'acquisition values' table records the actual parameter values a ssociated with each scan ID. A similar se ries of table structures is used for organizing file reconstruction parameter values. Each m odality has different reconstruction methods, listed in the 'reconstruction format' table; each recons truction method has its own set of parameters, listed in the 'recon parameters' table; and the actual reconstruction values are recorded in the 'recon values' table, along with the unique file ID. 3. RESULTS This metadata database model is implemented in a molecula r imaging data grid at the Image Processing and Informatics Laboratory at USC. The metadata database supports imaging studies from microPET, microCT, micro-ultrasound, and optical imaging modalities. Small animal imaging studies are uploaded and archived into the data grid through a web- based user interface, which allows study-related metadata and experimental findings ca n be inputted along with the imaging files. Ten sample datasets from each of the five supported modalities are used fo r evaluation, and include study images and comprehensive experimental metadata. The collected study datasets vary in disease type, experimental scope, and animal subject type to te st support for diverse experimental objectives . Metadata from image files are extracted and updated to a centralized metadata database server before the physical files are archived into the grid's storage devices. 3.1 Data Searching and Retrieval The ability to search for complex imaging studies in the mol ecular imaging data grid has been enabled by the metadata database. Through a web-based interface, authorized users enter filtering parameter values, such as animal type and disease type, to search the data grid's metadata database fo r specific study datasets archived in the data grid. Resulting study datasets that meet those search parameters can be retrieval and downloaded through the same web-based interface, alleviating investigators imaging facility staff from relyi ng on written records for accessing historic and published imaging data files. The metadata database significantly reduces the workflow for investigators trying to mine for data. 3.2 Data Management The internal management of imaging datasets within a small animal imaging facility is improved with study-specific information provided by the metadata database model, such as file creation timestamps, study status updates, and inter- file relationships. Data management features such as long-term data storage can be automated for studies with complete and published datasets. Furthermore, any unfinished analysis re ports or post-processing files can be quickly identified as the cause for incomplete studies and corrected by the animal-imaging facility staff through monitoring of individual study status'. Therefore, maintaining complete datasets for each animal-model imaging study is more attainable and the archival of these datasets within integrated storage infrastru cture is more automated. 4. CONCLUSIONS We have implemented a study-centric database model to consolidate small animal imaging metadata, files and findings into a database schema around the investigators. Providin g more information about a small animal imaging facility's archived files is the first step towards improved systems in tegration and interoperability of multimodality data in pre- clinical medical research. Specifically, a metadata database makes data accessible for data management, post-processing, and data-mining in translational sciences. With a growing interest in multimodality datasets, yet a myriad of incompatible file formats, a study-centric database model is essential to organizing, centralizing and streamline the data workflow in small animal imaging facilities. 5. REFERENCES [1] Yang, J., Yang, M., Arabnia, H., Deng, Y., \"Genomics, molecular imaging, bioinformatics, and bio-nano-info integration are synergistic components G., Abrams, D., \"Int erdisciplinarity and Systems Science to Improve Population Health,\" Am J Prev Med. 35:S211-S224 (2008). [3] Stout, D., Chatziioannou, A., La T., et al, \"Small Animal Imaging Ce nter Design: The Facility at the Crump Imaging,\" Mol Imaging Biol. 7:393-402 (2005). Tulipano, K., Tao, Y., Millar, W., et al, \"Natural Language Processing and Visualization in the Molecular Imaging Domain,\" J Biomed Informatics. 40:270-281 (2007). [5] Peng, and Unification of Multilevel Mechanisms and Data in Medical Physics,\" Med Phys. 35:8:3444-3452 (2008). 76A Zero-Footprint 3D Visualization System Utilizing Mobile Display Technology for Timely Evalua tion of Stroke Patients Young Woo Park*a, Mogensenb, Kevin Wangb, Meng a. and Informatics Laboratory, Univ. of Southern California, 2250 Alcazar St., CSC/IGM 105, Los Angeles, California 90033 b. Department of Radiology, Univ. of Southern California, 1520 San Pablo Street, Los Angeles, CA 90033 ABSTRACT When a patient is accepted in the emergency room suspected of stroke, time is of the utmost importance. The infarct brain area suffers irreparable damage as soon as three hour s after the onset of stroke symptoms. A CT scan is one of standard first line of investigations with imaging and is crucial to identify and proper ly triage stroke cases. The availability of an expert Radiologist in the emergency environment to diagnose the stroke patient in a timely manner only increases the challenges within the cl inical workflow. Therefore, a truly zero-footprint web-based system with powerful advanced visualization tools for volumetric imaging including 2D. MIP/MPR, 3D display can greatly facilitate this dynamic clinical workflow for stroke pa tients. Together with mobile technology, the proper visualization tools can be delivered at the point of decisi on anywhere and anytime. We will present a small pilot project to evaluate the use of mobile technologies using devices such as iPhones in evaluating stroke patients. The results of the evaluation as well as any challenges in setting up the system will also be discussed. Keywords: Stroke, Mobile display technologies, Web-based visualization tools 1. INTRODUCTION 1.1 Background information on stroke Stroke has become one of major health issues in the mode rn society. According to Am erican Stroke Association, about 795,000 Americans suffer from stroke annually. Among them, more than 137,000 cases have resulted in death, making stroke third most common cause of death behind heart diseases and cancer. There are two major types of strokes: hemorrhagic and ischemic strokes. Hemorrhagic stroke makes up for about 13 percent of all stroke cases. Ischemia results in death of brain tissue, and therefore is often called as cerebral infarction (tissue death) instead. Ischemic stroke makes up for 87 percent of all stroke cases. There are several guidelines for treatment of stroke pati ents. American Heart Asso ciation/ American Stroke Association (AHA/ASA) guideline 1, which is observed by many hospitals, specifies following timelines when treating stroke patients. In stroke cases, speed is one of the most important factors in determining the success of treatment in patients. The infarct brain could suffer irre placeable damage as soon as th ree hours after the onset of stroke symptoms. rtPA, which is the only drug approved by Food and Drug Administration (FDA) for treatment of cerebral infarction, should ideally be administered within 3 hours of symptom onset2. The following table shows the benchmark treatment time for NIH - National Institu te of Neurological Disorders and Stroke (NINDS) for cerebral infarction with rtPA. Table 1. Maximum Interv als Recommended by NINDS Maximum Intervals Recommended by NINDS Door-to-doctor first sees the patient 10 min Door-to-CT completed 25 min Door-to-CT read 45 min Door-to-thrombolytic therapy starts (rtPA) 60 min Physical Examination +15 min 77Neurosurgical expertise available +2 hours Admitted to monitored bed +3 hours The above chart assumes that from the onset of the stroke to arrival and transportation of stroke patient to hospital took slightly less than two hours. If discovery and transportation of the patient has taken more than two hours, hospital workflow should be hastened to accommodate the delay. As shown in the above chart, CT read should be completed in 20 minutes or less to ensure that thrombolytic therapy could start within 3 hours from the onset of infarction. 1.2 Current workflow for treating stroke patients At LA County - USC (LAC+USC) hospital, where all stroke patients around metro LA are sent, the stroke patient treatment workflow follows the guideline set by AHA/ASA. Figure 1 summarizes workflow involving stroke patients at LAC+USC hospital from the onset of the stroke to review step by neurologists for determining treatment options. Figure 1. Stroke Patient Wo rkflow at LAC+USC Hospital <1> Stroke occurs and emergency services are called in. <2> Emergency crews arrive for stroke patient; in metro politan Los Angeles, they would take the patient to LAC+USC hospital's ER. <3> At the ER, the patient would be sent to CT if suspected of stroke after examination by attending physician. <4> CT scan is performed on the patient: LAC+USC hospita l currently has 2 32-slice and 2 64-slice CT scanners, with 64-slice scanners being primarily used on stroke cases. <5> Once images are taken and ready to be reviewed at a PACS workstation, neuroradiologists will review the study and prepare the report. During after hours when neuroradiologists are not available, ED and/or neuro fellows will read the study instead. <6> After the study is read, it will be sent to neurologists to have them decide which treatment should be taken next. Because many different procedures and personnel are involved in handling stroke cases, there are many factors that could cause delays from the onset of the stroke to the review by neurologists. For example, if the patient suffers stroke during non-business hours, (i.e. after 6PM until 9AM the following day) ED and neuro-fellows, instead of 78neuroradiologists will be in attendance to read CT scans (Step 5). If fellows would want a second opinion during off hours, they would either have to page neuroradiologists to come in, wait until the regular business hours to proceed, which would result in additional delays. Additionally , there could also be delays between Steps 5 and 6, in which neurologists face delays in accessing CT images. This could cause further delays in determining and starting treatment for stroke patients. Mobile display technology could improve stroke treatment experiences by reducing aforementioned delays. During after hours, neuroradiologists could review cases over their mobile phones when requested, which would eliminate the need to halt the procedure until the next business day. In addition, mobile display technology could allow neurologists to access stroke images co nveniently anywhere with cellular phone coverage, and set up treatment plans if they are not present at the hospital. 1.3 Mobile Display technology One possible solution to overcome aforementioned issues would be to employ a mobile display technology using PDAs and smartphones. Mobile technology could enhance treatment experiences by reducing the time for studies to be evaluated by radiologists, especially during non-work hours. However, since imaging information that's being shared across devices contains patients' private medical information, implementing mobile display technology in the field of medicine should comply with HIPAA Security Guidance for Remote Use of and Access to Electronic Protected Health Information (EPHI) 3. The guideline specifies that mobile devices should employ security measures such as encryption and password protection as we ll as leaving minimal data (cache) on the device itself to avoid loss of private data when the device is lost. Many mobile medical display options adhere the first two requirements on encryption and password protection. However, avoid creating local cache is a difficult option b ecause of retrieving and ha ndling DICOM image format. Many currently available mobile medical display solutions implemented solution that store downloaded medical images on the devices' memories. The advantage of this solution is it allows fast and smooth access to images once they are downloaded to devices' memories. However, this solution may cause security concerns if the device is lost or stolen and loss of patients' EPHI. Because of such risks, applications with local cashing of EPHI may not comply with requirements set out in the HIPAA security guideline. One possible solution for mobile display technology, while meeting HIPAA requirements, is to employ zero- footprint technology. Zero-footprint solution is a type of implementation, where any relevant information is stored in the server and accessible only at the ti me of use. No software application installation is required, all the image manipulation is done at the server side and a jpg (the most suitable for medical images) is displayed on the web browser. Because there is no application data cached on the device, there is no EPHI on the device after execution, which complies with the HIPAA security guideline. However, the downside for zero-footprint solution is its heavy reliance in network connectivity, as it requ ires an Internet access to operate and re trieve information. This type of approach has the follo wing characteristics: a. It is less restricted to the browser vendor used. Some browser incompatibilities issues might need to be resolved but it has the benefit of working in a variety of Operating Systems (OS) and browsers. b. Quality of the images is not enough for Radiologi cal readings; however it is suitable for review and training. c. Standard web protocols are used, no extra knowledge is required for handling the communication between the server and the client. d. The cache mechanisms are inherent from the browsers and the settings set by the user. This could be an issue if a high number of images are needed to be downloaded. e. The bandwidth usage can be considered low becaus e there is no need to send the native DICOM images to the client, only the jpeg images. f. Minimal requirements are set for the hardware of the client PC. Because the processing is done at the server side, the clients do not require having high-end components in order to display the images. Figure 2 shows the communication scheme in a thin-client or \"zero footprint\" system. 79 Figure 2 - True Thin Client or \" zero footprint\" communication scheme In this study, we employed Calgary Scientific Inc's zero- footprint mobile display solution for iPhone and iPod touch devices and examined the feasibility of incorporating the technology in time-critical applications such as stroke-diagnosis. 2. METHODS 2.1 Hardware Overview For this trial, we used iPhone 3GS de vices with 3.5-inch display with 480-by -320-pixel resolution at 163ppi. All devices were under AT&T 3G (UMTS/HSDPA) coverage and equipped with Wi-Fi (802.11b/g) capability. The CSI server which processed the 3D volumes and supports the zero footprint technology is a Xeon 8-way SMP 3.2 GHz multiple processor server with 16GB RAM and 4GPU NVIDIA 9800GX2 graphics card with a 2.5 TB RAID running 64bit OS. The medical images were first collect ed in the CD forms and load ed onto experimental Fuji PACS at Healthcare Consultation Center 2 (HCC2). Then, images were pushed from Vincent PACS to a server provided by Calgary Scientific where DICOM images were converted and ready to be reviewed on iPhone mobile devices. Finally, PC workstations with grayscale LCD display of 1600 x 1200 pixels (163ppi) were used to view CT stroke images in traditional radiology viewing conditions. 2.2 Clinical Evaluation of using mobile device For this pilot project, a retrospective study on stroke cases from LAC+USC hospital were utilized. Three fellowship-trained neuroradiologists (R1, R2 and R3) from USC radiology department reviewed studies using their iPhone displays, and then their diagnoses with iPhones were compared with actual radiology reports to find any discrepancies between the two. After completion of iPhone display diagnosis, radiologists checked their iPhone-based reads against results using full PACS workst ation to see any differences in their reads. A total of 33 stroke cases were used for this retrospec tive study. Studies were collected from LAC+USC hospital, with 33 cases of non-contrast CT-head scans of the patients presenting to the emergency department with signs of an acute stroke. Radiology reports of each study were also collected and used to identify and categor ize patients. Four main categories were identified including hemorrhage, normal, subtle and obvious infarctions. Out of 33 studies used: Table 2. Four main categories TOTAL 33 Hemorrhagic 8 Subtle Infarct 9 Obvious Infarct 8 Normal 8 Lists of patients from the 4 different sub-groups were combined to form a single list. Then the list was re-arranged alphabetically based on last names of stroke patients. This was to ensure that radiologists were not biased when filling out the survey form. All radiologists were asked to record any abnormalities after reviewing the cases, 80locations of each abnormality (if exis ts), and the confidence score between 1 (lowest) and 4 (highest) of their diagnostics. Also, they recorded loca tion of affected area, adjacent effect and grading of stroke from scale of 1 (Least severe) to 3 (Most severe) based on its size and severity (Table 3). Table 3. Sample Evaluation Sheet Last Name First Name Infarct (Y/ Read Started (Time) Confidence (1 lowest, 4 highest) Misc Comments DOE JOHN Y L cerebellum Mass effect with compression 4th vent N 3 10/21/ 09 22:03 4 WiFi Retrospective CT images used during this study were not officially randomized like in a true receiver operator characteristic (ROC) study. This was just an initial pilot feasibility study to determine the mobile technology and whether it could be used in emergency clinical environments. Additionally, radiologists were asked to run the software in various locations, using both cellular (AT&T 3G UMTS/HSPA) and Wi-Fi network modes to gather th eir feedback on accessibility in various conditions. 2.3 Gathering Feedback on diagnosing strokes on the mobile device Another survey form was handed out to radiologists to gather their feedback on using the software and possible room for improvements. Feedback survey form was created and distributed electronically (Table 4). The result will be discussed in Results and Discussion section. Table 4. Feedback Survey Form 1 (greatly diminished), 2 (somewhat diminished), 3 (equivalent), 4 (improved) Display characteristics Display size Resolution Contrast Brightness Comments Viewing functionality - 2D Window/level Slice scrolling Pan Zoom Comments Viewing functionality - 3D Window/level Visualizaton presets Volume rotation Pan Zoom Comments Solution characteristics 81Mobility of solution Access to patient imaging data Potential as collaborative tool Time to diagnose (from page) Time to diagnose (once read started) Image quality Product performance (Wi-Fi) Product performance (3G) Intuitiveness of viewing interface In-product viewing instructions Comments 3. RESULTS AND DISCUSSION Between October and December of 2009 , three (R1, R2 and R3) radiologists reviewed 33 stroke cases over their mobile devices (iPhones) as well as PC workstations at the HCC2. Results were then compared against a grading sheet compiled using radiology reports of individual cases from LAC+USC ho spital to evaluate the accuracy of iPhone reads. Simple intra-observer agreement between the interpretation on iPhone and PC workstation was high for all readers (R1=100%, R2=91%, R3=94%). There were no discrepancies (100% in R1, R2 and R3) between reports from LAC+USC hospital and PC workstation, and therefore inte rpretation agreement between iPhone and reports were same as previous case (R1=100%, R2=91%, R3=94%). Diff erences in simple agreement were primarily secondary to subtle infarcts not seen during interpretation on the m obile device. All acute abnormalities reported on the mobile device were seen on the standard PC workstation clinical application. Average confidence levels of interpretations on the mobile device versus the PC workstation were as follows: R1=3.60 versus 3.79, R2=3.73 versus 3.91, and R3=3.40 versus 3.73, in a range of 1 to 4 with 1 lowest and 4 highest level confidence in reading (Is this scor ing range correct? Please verify). The result highlights that all radiologists had higher confidence levels with studies read on PC Work station than with their iPhones. However, the confidence levels with iPhones are still above three and showed it maintained a good level of confidence from all three radiologists. User experience gathered from feedback survey form (Tab le 4) showed that while all three radiologists were satisfied with the mobility and the software's ease of access, there were some issues in the hardware limitation, software functionality and network connectivity. Radiologists found iPhone's screen too small to view images, as they needed to constantly zoom in and out of slides. Additionally, radiologists wanted some changes in the interface layout and inclusion of several featur es such as contrast presets for stroke cases. The network connectivity was the most critical issue as poor performance over AT&T's cellular network hindered the use of the application. Since the software was a zero-footprint solution, which needed to pull image data frequently from the server, delays in cellular network (3G/ EDGE) caused delayed responses in almost every aspect of the application, including browsing and zooming of slides, and changing contrasts. However, the application's performance over Wi-Fi connections was significantly better than over cellular network, which resulted having most of the reads for this study to be done under Wi-Fi. 4. CONCLUSION The results of this pilot study shows that while reading studies from mobile devices such as iPhones were lacking compared to reading studies from radiology workstations, the performance were still competitive enough. This is shown by the fact that reads over iPhone and PC workstation did not completely agree on two out of three radiologists. In addition, reads on the iPhone had lo wer overall confidence score over a PC workstation, which shows radiologists still prefer red reviewing cases on PC workstations. However, more than 90% agreements for all 82readers (R1=100%, R2=91%, R3=94%), and confidence of versus 3.79, R2=3.73 versus 3.91, and R3=3.40 versus 3.73) on the iPhone, showed that reviewing cases over iPhones were competitive against reviewing on PC workstations. Therefore, mobile display technology could successfully be integrated into radiology workflow of diagnosing and treating stroke patients. In contrast, there were some issues with regard to us ing a zero-footprint solution for mobile display. The zero- footprint solution's heavy reliance on network connection became an issue wh en the connection was not perfect. All radiologists found the application to be slow and lagging over cellular connection, and had to use Wi-Fi connection to complete their reads for this trial. Mobile display technology should be accessible anywhere, in order for the mobile display to be effective. Because Wi-Fi has limited range, sometime the iPhone must rely on cellular technology to retrieve information. Calgary Scientific has been improving their mobile display solution with incorporation of many features we requested during this pilot study, including performance enhancement. They are looking at having a temporary image cache on the device's RAM to ease application's network traffic and have faster interface interactions. Mobile display's competitive results during this study, as well as possible improvem ents from Calgary Scientific have shown that the device could successfu lly be integrated into stroke workflow . Therefore, futu re work includes a prospective trial of stroke patients at LAC+USC hospital in 2010. REFERENCES [1] Summers, D., et al., \"C omprehensive Overview of Nursing and Interdisciplinary Care of the Acute Ischemic Stroke Patient: A Scientific Statement From the American Heart Association,\" Jo urnal of American Heart Association, Retrieved from , (2009). [2] Bederson, Management of Aneurysmal Subarachnoid Hemorrhage: A Statement for Healthcare Professionals From a Special Writing Group of the Stroke Council, American Heart Association,\" Journal of American Heart Association, Retrieved from http://stroke.ahajournals.org/cgi/content/full/40/3/994 , (2009). [3] U.S. Department of Health and Human Services - Centers for Medicare and Medicaid Services., \"HIPAA Security Guidance for Remote Use of and Access to Electronic Pr otected Health Information,\" Retrieved from http://www.cms.hhs.gov/SecurityStandard/Downloads /SecurityGuidanceforRemoteUseFinal122806rev.pdf , (12/28/2006). 83Computer-aided Bone Age Assessment for Ethnically Diverse Older Children Using Integrated Fuzzy Logic System Kevin Ma*a, Paymann Moina, Aifeng Zhangb, Radiology, Univ. of Southern California, 2250 St. Los Angeles, CA 90033 bDept of Psychiatry-CS, Univ. of Illinois at Chicago, Chicago, IL 60612 ABSTRACT Bone Age Assessment (BAA) of children is a clinical procedure frequently performed in pediatric radiology to evaluate the stage of skeletal maturation based on the left hand x-ray radiograph. The current BAA standard in the US is using the Greulich & Pyle (G&P) Hand Atlas, which was developed fifty years ago and was only based on Caucasian population from the Midwest US. To bring the BAA procedure up-to-da te with today's population, a Digital Hand Atlas (DHA) consisting of 1400 hand images of normal children of different ethnicities, age, and gender. Based on the DHA and to solve inter- and intra-observer reading di screpancies, an automatic computer-aid ed bone age assessment system has been developed and tested in clinical environments. The algorithm utilizes features extracted from three regions of interests: phalanges, carpal, and radius. The features are aggregated into a fuzzy logic system, which outputs the calculated bone age. The previous BAA system only uses features from phalanges and carpal, thus BAA result for children over age of 15 is less accurate. In this project, the new radius features are incorporated into the overall BAA system. The bone age results, calculated from the new fuzzy logi c system, are compared against radiologists' readings based on G&P atlas, and exhibits an improvement in reading accuracy for older children. Keywords: bone age assessment, image processing, fuzzy logic system, system integration 1. INTRODUCTION This project presents an objective and automated computer-aided diagnos is (CAD) system for bone age assessment (BAA). The system aims to improve current clinical practi ces of bone age assessment and introduces the use of fuzzy logic algorithm for computing CAD outputs. 1.1 Bone Age Assessment Bone Age Assessment (BAA) of children is a common clinical procedure performed in pediatric radiology to evaluate the stage of skeletal maturation of children. The clinical importance of BAA can help diagnose endocrinological problems and growth disorders of children. A difference between the chronological age a nd the skeletal age of the subject suggests abnormal development. BAA can also be used in monitoring growth hormone therapies and may be used in pediatric surgeries. The current standard for BAA in the Unite d States is for radiologists to compare the patient's left hand radiograph with the Greulich & Pyle (G&P) Hand Atlas 1. The atlas contains left-hand radiographs of normal children of both male and female ranged from newborn to 18 years of age. G&P Atlas, while widely accepted, have some disadvantages. First, the atlas contains left hand images that were collected over 50 years ago. Previous studies have shown that there have been discrepancies between the G&P atlas and the development stages of modern children2. Second, the subjects were only Caucasians from the American Midwest region. In today's urban environment and ethnic diversity, the Atlas may not be adequate enough to evaluate childrens of different races. Thirdly, because BAA is based on visual comparison of closest matched image to the Atlas, there are inter- and intra-pers onal reading discrepancies. Using the G&P atlas, inter- observer readings can differentiate from 0.37 to 0.6 years, and intra-observer differences can range from 0.25 to 0.47 years3,4. Based on the shortcomings, a solution is needed that both defines a new standard for today's ethnically diverse population and eliminates su bjective comparison analysis for assessing bone age. 841.2 Computer-aided Diagnosis of Bone Age A complete computer-aided diagnosis for bone age assessment has been previously designed and implemented. The project has taken place over the span of mo re than ten years, from data collection to algorithm development and clinical validation and implementation of web-based CAD system in a clinical setting. The detailed history and components of BAA CAD system are listed here. 1.2.1 Digital Hand Atlas In order to develop an objective BAA CAD system, data collection of normal children's left hand images is needed to replace the G&P Atlas as the standard and the first option for BAA. The result is a digital hand atlas (DHA). DHA is a collection of 1400 normal children's left-hand radiographs2. Subjects include both male and female children of different ethnic backgrounds: African American, Asian American, Caucasian, and Hispan ic. The subjects are aged from zero to 18 and are all from the Greater Los Angeles area. The result is an ethnically diverse and rich hand atlas that is more suitable for today's children in an urban setting. The data collection process began in the late 1990s and continued through the middle of 2000s. The subjects were considered having normal skeletal development based on trunk heights, body height and weight, and tanner index, the latter of which was used by clinical endocrinologists. The images are taken at Children's Hospital of Los Angeles, and film images are digitized using a film scanner (Array, Tokyo, Japan). In DICOM header fields, patient's demographic information was manually entered, along with patient's physical measurements. The data was obtain ed in two cycles: the first cycle cont ained a set number of hand images per age group, gender, and ethnicity, while the second cycle was completed to co mplement the first cycle results by increasing the number of cases for children between the ages of 5 to 14, due to the rapid development of bone features during this developmental stage. The database of digital hand atlas is viewable online at http://www.ipilab.org/BAAweb . The DICOM images are converted to JPEG format for online view ing. Figure 1 is a screenshot of the DHA database showing all cases of 10- year-old Asian female subjects. Figure 1. Collection of hand images in Digital Hand Atlas, available online 85Performance of DHA has been evaluated. Two radiologists read all of the DHA cases using the G&P atlas for Asian American (AS), African American (AA), and Hispanic subjects (HI) of both genders, and the results have been stored in the DHA database to show cross-racial reading discrepa ncies between G&P atlas module: Image Processing Algorithm BAA CAD system uses data collected from Digital Hand Atla s to establish an objective and reliable algorithm that assesses bone age of children. The goal of CAD is to aid radiologists performing BAA by offering a second opinion that is consistent for all cases. The system examines three region s of interests: carpal bones, pha langes, and wrist joint. Each region of interests display different level of importance in evaluating bone age for different age groups. Table 1 displays the three regions of interests and the ar ea of where they are most effective in. Table 1. Clinical reliability of using the three ROIs for BAA in different age groups Age group Phalangeal ROIs Carpal ROI Distal Radius ROI 0 - 5 (female) 0 - 7 (male) Feature analysis of epi- metaphysis - NOT reliable Size & shape analysis of carpal bones - Reliable 6 - 13 (female) 8 - 15 (male) Feature analysis of epi- metaphysis - Reliable Degree of overlapping of carpal bones - NOT reliable 14 - 18 (female) 16 - 18 (male) Feature analysis of epi- metaphysis - NOT sufficient Feature analysis of epi- diaphysis - Reliable The phalangeal ROI is one of the first criteria in assessing bone age. The shape, size, and development of epiphysis in relation to metaphysis in the middle three fingers are used to evaluate bone development. During infancy, the epiphysis has not been formed and thus cannot be used in BAA. As bone ages, the epiphysis would st art to increase in size, and finally it fuses with metaphysis when the subject enters adol escence. Therefore, the phalan geal ROI analysis is best suited for children in the middle age groups. The carpal ROI is more reliable for younger children of less th an 5 years old for female and less than 7 year old for male children. Carpal bones grow as the infant grows, and the bones begin to overlap with each other starting at the age of 5. The difficulty in distinguishing different carpal bones in the ROI makes the method only suitable for BAA of younger children. After the epiphysis and metaphysis have fused in the phalangeal ROI, epiphysis and metaphysis do not fully fuse in the wrist joint region until the child's development is fully mature. In other words, analysis on the degree of fusion between epiphysis and metaphysis on radius is used best for BAA of older children. 1.3 Use of Fuzzy Logic in computing Bone Age The BAA CAD system needs to intelligently put weight on results from the thr ee ROI analyses to accurately assess bone age. Relationship between extracted features and assessed bone age is also nonlinear. The three analysis components are arranged in a modular fuzzy logic system that integrates results and computes bone age for patients of different age, gender, and ethnicity. The fuzzy logic concept is derived fr om inherently imprecise measurements that exist in the natural, biological world9. A fuzzy logic system uses a set of rule-based classifications (various if...then.. statements) and mathematical equations to derive outputs evaluating imprecise outcomes. Fuzzy logic is commonly used in engineering as a means for computing systems to output qualitative assessment, rather than quantitative data 11. For BAA CAD, a rule-based fuzzy logic system has been developed to compute outputs from feature analyses. The results need to be aggregated and a fina l bone age is computed from the integr ated fuzzy logic syst em. Previously, CAD algorithm has been completed for each co mponents and fuzzy logic has been desi gned for each components. This paper focuses on the development of the complete algorithm that has been used in developing the BAA CAD system, 86incorporating all three ROI analyses, and to include the implementation and results of an integrated fuzzy logic system for results analysis. 2. METHODS 2.1 Data Collection Normal left-hand images are collected fr om the Digital Hand Atlas. All DHA images are collected for training of the algorithm. Additionally, around 75 of both normal and abnormal cases are collected at LAC+USC Medical center as recent as 2008. The im ages are normal hand images in DICOM format a nd have been determined by radiologists using the G&P atlas for visual comparison. The LAC images are used for system evaluation. 2.2 Feature Extractions The overall CAD system contains three components. Figure 2 shows how each components are evaluated in the CAD system. Figure 2. The BAA CAD system workflow diagram The left hand image first goes through the pre-processing st ep. In this step, the hand is segmented, and a knowledge- based segmentation step is used to identify the three regions of interests. 2.2.1 Phalanges ROI The middle and distal epimetaphyseal regions of the middle thr ee digits are localized and extr acted from the hang image. A total of six sub-regions of interest are identified and segmented. Region features are then acquired: eight quantitative size and shape features and ten wavelet features (once the epip hysis starts to fuse with metaphysis). Wavelet features, in image processing, are used in determining texture and pattern of the examined image, making it suitable for examining degree of fusion in the epimetaphyseal regions13. Figure 3 summarizes the features extracted, the quantitative calculations involved, and the aggregation of all six sub-ROIs for the bone age assessment based on only phalanges ROI. The bone age output from phalange analysis is named BA1. 2.2.2 Carpal ROI Two bones, the capitates and hamate, are th e focal points in the carpal ROI analysis . The two bones are the first to ossify during development in the carpal region, thus making it ideal candidates for assessing bone age for small children. The two bones are segmented during carpal ROI analysis, and size and shape features are extracted. The two features are aggregated and passed through a fuzzy logi c classifier for assessing the bone age based solely on carpal ROI analysis results. Figure 4 presents the summary and diagram of how BA is calculated based on carpal region. The bone age output from this analysis is BA2. 2.2.3 Wrist Joint ROI Wrist joint ROI analysis consists of ev aluating the growth plate region of the radius, which is similar to what has be done in the phalangeal ROI. Ten wave let features are extracted from the wr ist ROI, which has been segmented and 87radius has been identified. Figure 5 shows the diagram of wrist joint ROI analysis in computing the BAA output. In addition, the correlation coefficients of the ten wavelet features are comput ed to determine if each feature are independent of each other. Independent features are then input into the fuzzy classifier to computer BA3. Aggregation distal IV distal III distal II middle IV middle III middle II BA1 Figure 3. Diagrams of feature extraction from phalangeal ROI. Left: quantifiable features extracted from one epimetaphyseal sub-ROI2. Figure 4. Diagram of carpal ROI region analysis. The top two images are the carpal ROI on the original image and the segmented outline of carpal bones. The bottom diagra m shows how features extracted from capitates and hamate are used to calculate bone age. 88 Figure 5. Diagram of Wrist Joint Analysis and computation of BA3. 2.3 Fuzzy Logic Subsystems Design As mentioned in the previous sections, each ROI analysis is co mpleted by a fuzzy logic classi fier at the end to compute a bone age based on the features unique to those ROIs alone. In this section, fuzzy logic classifiers' designs are explained in more detail. Each fuzzy logic classifier employs rules-based membership functions that categorize output results based on the input values. Because of the diverse ethnicity and different ge nders, eight fuzzy subsystems are separately designed and trained for an ROI fuzzy system: (ASM, ASF, AAM, AAF, CAUM, CAUF, HIM, and HIF). In the second step, the rules are generated based on input data used for training. Using the carpal ROI analysis for example, one of the defining tules can be that if the output of capitates subsystem is A and hama te subsystem is B, then the output bone age is C. Table 2 illustrated the inference rules that govern the carpal fuzzy logic system. Table 2. Six inference rules of capitate sub-system for Caucasian males. Numeral represents the age group. Rule 1 : If (size is 0 1) and (eccentricity is 0 1) and (triangularity is 0 1) then (Age is 0 1) Rule 2 : If (size is 2) and (eccentricity is 2 3) and (triangularity is 2) then (Age is 2) Rule 3 : If (size is 3) and (eccentricity is 2 3) and (triangularity is 3) then (Age is 3) Rule 4 : If (size is 4) and (eccentricity is 4) an d (triangularity is 4) then (Age is 4) Rule 5 : If (size is 5) and (eccentricity is 5 6 7) and (triangularity is 5) then (Age is 5) Rule 6 : If (size is 6 7) and (eccentricity is 5 6 7) and (triangularity is 6 7) then (Age is 6 7) Fuzzy logic contains membership functions that compute the probability of the patient being under a certain age group. Each age group is represented by one membership function fr om 0 to 1. The larger the membership value is, the more the input feature reflects the correspond ing age group. Each membership function is Gaussian distributed, and the training method is to automatically perform feature extraction on all images corresponding to the target group (gender, race, and age), find the mean and standard deviation, and construct the membersh ip function. Figure 6 shows a sample membership function distribution for size feature of capitates for Caucasian boys seven years old and younger. Figure 6. Membership function distribution of capitates size corresponding to bone age assessment for Caucasian boys. The vertical axis shows the membership function valu e between 0 to 1, and the horizontal axis is the value of corresponding feature. 892.4 Integrated System Figure 7 shows the aggregation process of assessing the final bone age output using an integrated fuzzy logic system. Figure 7. Diagram of final bone age assessed by all three ROI analyses The integrated fuzzy logic is designed to take the three BA outputs and calculate the final bone age. However, since not all regions of interests are used to assess all of the age group s, new rules are put in the system: when assessed bone age is more than 14 years old for male and 12 years old for female, then BA2 from carpal ROI analysis is not included in the evaluation because of its ineffectiveness in evaluating bone age of older children. If the subject is older than 5years for female and 7 years for male, then wrist joint ROI system is not included. The selective BAA criteria aim to improve on assessment accuracy. Using only BA subsystem outputs as aggression inputs may not be robust enough; thus the aggregated fuzzy logic system evaluates the features and other input values us ed to create BA1, BA2, and/or BA3. However, too many inputs can also blur set differences between membership functions, and thus the number of inputs is being limited. Since the wrist joint subsystem is newly completed, BAA results of older children are specifically evaluated. 3. RESULTS AND DISCUSSION The system has been designed and implemented using MATLAB's Fuzzy Logic Toolkit. The integrated fuzzy logic system features from phalangeal, carpal, and wrist regions and assesses the bo ne age. Eight different fuzzy logic classifiers are created based on different ethnicities and genders. The first phase of fuzzy logic system evaluation is to assess BA of the DHA cases. The integrated CAD results are compared with the average of two radiologists' readings an d the chronological age. Figure 8 shows the BAA comparison graphs of both Asian and Caucasian males. Table 3 shows the mean difference between CAD and the chronological age for Asian male and Caucasian male. The other six evaluations are still ongoing at time of writing. Additionally, the evaluation process will include comparing CAD results with integrated fuzzy logic system and CAD results with the three individual fuzzy logic subsystems. The results show that while BAA CAD is able to assess bone age of children of different ethnicity, the results are still not as accurate as radiologists' readings from the G&P hand atlas. It should be noted that CAD results follows the radiologists' readings more closely than the chronological ages. 90There are several future works to be completed. The system 's performance will be evaluated from cases other than DHA cases. Integrated fuzzy logic system has room for adjustments in input values, rule defining, and membership functions. Not all ROIs are successfully segmented, thus the image processing algorithm has room for improvements. Table 2. CAD evaluation for two genders with four races combined. Values in the table are the mean differences between chronological age and e ach reading, and CAD result in year. Mean Difference with Chr. AgeF M Reading 1 CAD BA 1.137 1.098 No. of Cases 700 690 0 2 4 6 8 10 12 14 16 18 2002468101214161820BAA CAD output vs. Radiologist Reading for Caucasian Male Chronological Age (years)Reading (years) CAD Reading Radiologist Reading Normal 0 2 4 6 8 10 12 14 16 18 2002468101214161820BAA CAD output v s. Radiologist Reading for Asian Male Chronological Age (years)Reading (years) CAD Reading Radiologist Reading Normal Figure 8. Left: CAD results for Caucasian male, vers us radiologists' readings from G&P atlas and the chronological age. Right: Results for Asian male Both gra phs are linearly interpolated to show the linear graphs. 4. CONCLUSION The standard of bone age assessment in the US has been the use of Greulich & Pyle Hand A tlas, which is outdated and not suitable to evaluate skeletal development of children of other ethnicities. Digital Hand Atlas has been created as an alternative method for BAA. Based on DHA, an automated and objective CAD algorithm has been designed. The system uses fuzzy logic classifiers on both subsystem and systematic levels to convert image processing results into assessed bone age. In this paper, design and development of fuzzy logic systems have been presented and discussed. Integration of three different ROI analyses have been completed. With refinements in CAD algorithm and fuzzy logic system design, the BAA CAD system shows promise as a second opinion for radiologists to consult. REFERENCES [1] Greulich W. and Pyle S. Radiographic atlas of skeletal development of hand wrist. Stanford, CA: Stanford University Press, (1959) [2] Gertych, A., Zhang A., Sayre, J et al. \"Bone age assessment of children using a digital hand atlas\" Computerized Medical Imaging and Graphics 31:322-331 (2007) 91 [3] Roch A., Rochman C. Davila G. \"Effect of training of replicability of assessment of skeletal maturity (Greulich- Pyle)\". Am J Roentgenol 108:511-515 (1970) [4] King D., Steventon D., O'Sullivan M., et al. \"Reproducibility of bone ages when performed by radiology registrars: an audit of Tanner and Whitehouse II versus and Pyle methods\". Br J Radiol Piettka E. \"Digital hand atla s and web-based and implementation\" Comput Med Graph 24:297-307 (2000) [6] M, Pietka E, et. \"Computer-assisted phalangeal analysis 10:616-620 (1991) E, Kaabi L, Kuo M, et al. \"Computer assist ed bone age assessment: image preprocessing and A, Pospiech S, al. \"Computer automated approach to the extracton of epiphyseal regions in hand radiographs.\" J Digit Imag Eng 1:98-100 (1989) [10] Mamdani E., \"Application of fuzzy algorithms for of simple dynamic plant\". Proc IEEE 121:1585-1588 (1974) [11] Baldwin, J. \"Fuzzy logic and fuzzy reasoning\", in Fuzzy Reasoning and Its Applications, E.H. Mamdani and B.R. Gaines (eds.) London: Academic Press, 1981 [12] Zhang A, Gertych A, Liu B. \"Automatic bone age assessment for young children from newborn to 7-year-old using carpal bones.\" Comput Med Imag and Manjunath B., \"A comparison of wavelet transform features for texture image annotation\" Int Conf on Image Process (1995) 92The Development of a Disease Oriented eFolder for Multiple Sclerosis Decision Support Kevin Ma*a, Colin Jacobsb, Fernandeza, Lilyana Amezcuac, Radiology, Univ. of Southern California, 2250 Alcazar St. Los Angeles, CA 90033 bEindhoven University of Den Dolech The Netherlands cDept. of Neurology, Univ. of Southern California, 1520 San Pablo St. Los Angeles, CA 90033 ABSTRACT Multiple sclerosis (MS) is a demyelinating disease of the ce ntral nervous system. The chroni c nature of MS necessitates multiple MRI studies to track disease progression. Currently, MRI assessment of multiple sclerosis requires manual lesion measurement and yields an estimate of lesion volume and change that is highly variable and user-dependent. In the setting of a longitudinal study, disease trends and changes become difficult to extrapolate from the lesions. In addition, it is difficult to establish a correlation between these imaged lesions and clinical factors such as treatment course. To address these clinical needs, an MS specific eFolder for decision support in the evaluation and assessment of MS has been developed. An eFolder is a disease-centric electronic medical record in contrast to a patient-centric electronic health record. Along with an MS lesion computer aided detection (CAD) package for lesion load, location, and volume, clinical parameters such as patient demographics , disease history, clinical course, and treatment history are incorporated to make the e-Folder comprehensive. With the in tegration of MRI studies together with related clinical data and informatics tools designed for monitoring longitudinal multiple sclerosis studies, it provides a platform to improve the detection of treatment response in patients with MS. The design and deployment of MS eFolder aims to standardize MS lesion data and disease progression to aid in decision making and MS-related research. Keywords: multiple sclerosis, electronic patient record, database design, computer-aided detection, system integration, MRI 1. INTRODUCTION The goal of this paper is to present the development of an imaging informatics-based eFolder specifically for multiple sclerosis patients. The system would store MS patients' data, such as demographics, social history, clinical findings, disease history, as well as patients' MR images and quantita tive results of MS lesion detection including lesion load, volume, and location. This comprehensive informatics tool can benefit physicians and radiologists in decision support, treatment assessment, outcome analysis, quantified lesion tr acking, and a data repository for clinical researches. 1.1 Multiple Sclerosis Multiple Sclerosis (MS) is an autoimmune neurological dis ease that affects approximately 2.5 million people worldwide. The body's own immune system attacked the central nervous system, causing da mages and scar tissues in the brain, spinal cord, and optic nerves1. Its symptoms vary greatly and in the most severe cases can be disabling and life- threatening. MS manifests itself di fferently amongst different ethnicities2, such as different prevalent symptoms, differences in disabilities, MS lesion locations, and response to treatments3. Factors in environmental exposures also may result in MS taking different forms and progressions. Magenetic Resonance Imaging (MRI) is a commonly-used tool in diagnosing and detecting MS. Studies have shown that the mean time between first brain MRI to first clinically isolated MS syndrome is 2.3 years4. Scarred tissue, or lesion, in white matter appears hyperintense in MR sequences T2 and FLAIR, while lesions may appear hypointense in T1 sequences. Figure 1 shows a MS patie nt's MRI in the three sequences. 93 Figure 1. MR brain images of a multiple sclerosis patient . From left to right are T1, T2, and FLAIR sequences. Lesions appear brighter in FLAIR, which suppresses intensity of CSF 1.2 Importance for developing a comprehensive tool for MS treatment and research In evaluating severity of MS using MRI, radiologists need to quantify MS lesions in the MR images, and in the current protocol, rulers are used manually to measure a lesion volume. The process is tedious and often prone to human errors. In a longitudinal study, comparison with historical cases of the same patient is also completed by hand. In order to have a more accurate and objective way of tracking patient's MS progression, there is a need for a lesion detection and analysis tool that objectively quantifies lesions. With accurate and efficient lesion tracking, the patient's disease progression can be accurately repo rted. The results may help with treatment pl anning and decision support. An example would be a physician may be able to research for the best and most effective course of treatment for a patient by looking up other patients with similar conditions and backgrounds. The imaging and quantification data, combined with patient demographic data, social and medical history, can provide a powerful data repository for clinical research. Data can be queried based on a variety of search criteria, including lesion location, treatment, personal backgrounds, medical history, etc. An automated quantification tool can also be used as a data mining tool for clinical trials, to effectively and objectively quantify any improvements based on the treatment trials. Based on the needs, we propose an imaging informatics-based comprehensive system to integrate patient information, images, and computer-aided detection (CAD) to aid clinicians and researchers in various tasks related to multiple sclerosis treatment and research. 1.3 eFolder Concept The concept of eFolder is derived from electronic patient records (ePR). EPR is a comprehensive patient record database that includes patient's demographic information, medical history, disease history, and any information that is needed in today's clinical environment. The advantages of ePR are 1. it is paperless and easily accessible anywhere with a connection to the database server 2. is comprehensive and can be designed to hold any information and 3. allows telecommunications between different departments using the same system, acting as a record-keeping and master database for the enterprise environment. The eFolder differs from ePR in several ways. First, the eFolder is specifically designed for patients diagnosed for a specific disease, in this case, MS. The system thus is required to store data that are relate d to the disease. ePR, on the other hand, is designed for patients in a certain geographical environment or a certain facility. Second, the eFolder is designed for data mining for the specific disease characteristics. This allows a more powerful tool for gather data for 94research specifically on the disease. The eFolder, therefore, has a unique capability of decision support and treatment planning for the disease. The proposed MS eFolder combines three components: patient data database, patient images, and CAD results into one comprehensive system. The system would simply workflow for physicians in making follow up evaluations of multiple sclerosis patients, decide course of treatment for patients, track lesion changes over several imaging studies, and making objective comparison studies for patients of different backgrounds and ethnicities. 2. METHOD This section describes how the system is designed, and how each component connects with each other to present information required by the users. The system is designed as a tool for several ongoing research projects, including a study for Hispanic MS patients and how MS symptoms and lesions are presented differently in the Hispanic population in the Los Angeles area. 2.1 Database Design The most basic component of the MS eFolder system is the database. It stores text data such as patient history, images, and CAD results. The text data follows the HL7 standard, while the images are stored in DICOM format, and CAD outputs are stored in both text and structured reports (DICOM-SR). The system is written in MySQL for its open source environment and easy web-based development. The database design consists of three parts: 2.1.1 Patient Demographic Data The patient demographic data is the center of database, as a ll other information is based on the single patient's records. The information stored in demographic da ta includes race, sex, ethnicity, birthplace, childhood illnesses, vaccines, and other past medical histories. The database then includes the patient's MS history, consisting of the year of first diagnosis, and family members with MS, MS type, MS symptoms and frequency, treatment history, and so forth. Data gathering is done by patient interviews and paper forms, reading of medical reports, and physician inputs. Columned items are collected on the recommendations of leading neurologists and re search project leaders. Several of the stored data follows SNOMED nomenclature to standardize names and codes for symptoms, race, country of origin, vaccines, and etc. This allows an easier and universal way of storing and querying data of that nature. 2.1.2 Imaging Database The imaging database stores all MR images of the patients. The database structure is designed following the DICOM format: from patient to study, series, and finally images. Si nce only MR images are stored, studies do not need to be categorized by modality. The columns, such as study instance UID and SO P class UID are taken directly from DICOM headers. 2.1.3 Lesion Quantification Results Database The paper introduces a novel approach to storing quantification data in the database. The system organizes MS patient data, enables data query by quantification results, and visu alizes imaging and CAD results. Quantitative results stored include total lesion load, number of lesions, size of each lesions, 3D locatio n of each lesions, secondary captures of lesion contours overlaid on top of original images, and 3D rendering of the quantification study. Figure 2 displays the overall database design of MS eFolder. The database is structured such that all tables are interconnected based on individual patients. 95 Figure 2. The graph shows the simplifie d database schema of MS eFolder. The colors indicate the different portions of database: red is the CAD qua ntified results database, green is imaging database, and blue indicates the patient information database. The arrows show how each table is interconnected with each other. 2.2 Computer-aided Detection The computer-aided detection uses image processing and analysis to automatically quantify MS lesions in the MR brain images. The CAD algorithm is described in detail in SPIE 2010 presentation \"An automatic quantification system for MS lesions with integrated DICOM structured reporting (DICOM-SR) for implementation within a clinical environment\". In this section, the CAD algorithm is summarized. Three MR sequences are used in the CAD algorithm: T1, T2, and FLAIR. The images first go through a preprocessing step. It includes image realignment to the midsaggital plane and brain segmentation. The second step is to construc t probability map of each voxels being lesions in the brain. This is don e using the theory of K-Nearest Neighbors, or KNN 5. Initially, training cases are used to manually segment out lesion voxels. For each voxel, six features are extracted: in T1, T2, FLAIR, and the voxel coordinates (x,y,z) in 3D space. This training step, once completed, does not need to be repeated each time a CAD analysis is performed. When the CAD system receives a new set of images and preprocessing is completed, the six features are extracted from each voxels to find the K voxels in the training set that have the most similar f eatures as the current voxel. In this case, K is 100. The number of lesion voxels out of 100 closest neighbors determines the probability of the current voxel being a lesion. Once analysis is completed, a pre-set threshold valu e is applied to the probability map to filter out non-lesion voxels. After post-processing steps, such as morphological filte rs and lesion size filters (lesions too small are considered noise signal and thus is thrown out), the result is the le sion voxels for the particular case. Figure 3 shows the KNN process of segmenting lesions. 2.3 Graphical User Interface A graphical user interface (GUI ) is needed to display all the information available in the eFolder, as it ties everything together in a presentable and user-friendly way for navigation. There are three requirements for an eFolder GUI: The GUI need to be web-based to allow remote access an d requires no additional installing of software. All computations and visualizations are completed on the server side for a light-weight GUI. The GUI needs to be comprehensive. It needs to display text data, imaging data, and CAD results on the same interface. It allows physicians and radiologists to access all of the information related to the query. 96 The system needs to be dynamic and allow display of 3D images and manipulations of images presented for being more user-friendly. An attractive viewi ng interface allows a more clarified presentation A web-based GUI has been designed and is being developed for th is purpose. Based on PHP because of its vast functionalities with MySQL databases and large number of libraries, the dynamic GUI guides the user to look up a specific patient's disease history with im ages, and it allows querying for patients with various different criteria. Viewing of DICOM images allows zoom, pan, window/level, scrolling. The 3D rendering allows users to rotate the 3D image with lesions, and a crosshair pointer allows users to select a specific region to view. The program has been written in PHP and the dynamic element is based on jQuery toolkit in Javascript. Figure 4 shows a screen shot of the current GUI design. Figure 3. The lesion segmenting process. The left most figure is the original FLAIR image. The middle image is the probability map for lesion voxels, and the right image is the segmented lesion overlaid on the original image. In this case, the applied threshold value is 0.70. Figure 4. MS eFolder User Interface 973. RESULTS 3.1 Data Collection A total of 18 MR cases have been co llected at the USC Academic Medical Center. The imaging protocol is 3mm continuous slices(no gaps). Among the 18 cases, 10 are accompanied with complete patient interview data and thus have been entered in the eFolder system. The 10 patients are of Hispanic, Caucasian, and African American backgrounds. CAD analysis have been completed on all 10 patients. 3.2 Current status of development for eFolder At present, the CAD algorithm has been completed and is integrated with the database schema. Four cases have been used for training purposes with more training cases planned in the near future . Because of the complex nature of the algorithm, the CAD program currently takes between 8.5 to 9 hours and thus needs improvement. Results of CAD are in the process of validation by experts in multiple sclerosis. Several system performance improvements have been implemen ted and more are being sought upon, such as computing KNN using a tree structure, and exploring the possibility of using graphical processing unit (GPU) to compute the 3-D data. Another SPIE 2010 presentation, \"Performance evaluation for volumetric segmentation of multiple sclerosis lesions using MATLAB and computing engine in the graphical processing unit (GPU)\", provides details in performance evaluation and improvement of MS CAD. The graphical user interface is under de velopment including a 3D viewing of le sion contours which is accomplished by using the ITK-SNAP open-source software 8. Figure 5 shows the ITK-SNAP software used in 3D representation. Figure 5. CAD results rendered by ITK-SNAP tool Data collection is also ongoing to co llect 100 MS cases at LAC+USC Hospital and the USC Academic Medical Center. The 100 patients will have longitudinal imaging studies, whic h will be used to design and evaluate lesion tracking and treatment effectiveness. 3.3 Future work The MS eFolder system architecture has been designed, and several components have been developed. Additional refinements and pieces can be added into the eFolder system as future work. For example, an image registration 98 technique needs to be developed in order to standardize all images of the same patient for better lesion tracking. A lesion registration algorithm also needs to be designed and developed in order to pinpoint specific lesion volume changes in a longitudinal study. Several system evaluations include CAD pe rformance evaluation, GUI user feedbacks, and efficiency and time saved from using the system as opposite of manually segmenting lesions and pulling historical data from PACS to do comparison studies. 4. CONCLUSION This paper describes the design and development a comprehensive imaging-informatics based eFolder system for Multiple Sclerosis decision support. It combines the concept of electronic patient record along with disease-centric database design, MR images, and an objective automated lesi on quantification tool for an eas ier, more efficient system for disease tracking and decision support, specifically for multiple sclerosis pa tients. The eFolder serves as a evaluation tool and data repository for conducting MS research, including differences of MS between different racial and ethnic groups. The system is HL-7 and DICO M-complaint, while being completely web-based to allow remote access and telemedicine. The prototype MS lesion detection and quantification system has been developed in MATLAB, using the concept of K-Nearest Neighbors. Imaging data and patient di sease data have been collected and inputted in the system, while a graphical user interface is being developed to bri ng ease of access and user-frien dliness to the MS eFolder. While the current state of development is incomplete and se veral improvements are needed, the eFolder concept aims to improve on MS diagnosis, tracking, and research. The eFolder will bring a novel and comprehensive approach to observe longitudinal Ms lesion changes in MR, and deciding treatment plans that best suit the MS patient's profile. REFERENCES [1] National Multiple Sclerosis Society http://www.nationalmssociety.org/about-multiple-sclerosis/index.aspx [2] Cree B, Khan O, Bourdette D, et al. \"Clinical character istics of African Americans vs Caucasian Americans with Multiple Sclerosis\" Neurology 63:2039-2045 (2004) [3] Yamasaki K, Kira J, Kawano Y et al. \"Western versus asian types of multiple sclerosis: Immunogenetically and clinically disorders\" S, Brassat D, de Seze J, et al. Association between clinical conversion to multiple sclerosis in radiologically isolated syndrome and magnetic resonance imaging, cerebrospinal fluid, and visual evoked potential: follow-up of Jeroen van der Grond. white matter lesions in MR imaging.\" NeuroImage, 21(3):1037{1044, Mar 2004. [6] Wong A, Gertych A, Zee CS, Guo B, Liu BJ, \"A CAD system for assessment of MRI findings to track the progression of multiple sclerosis,\" Proceedings of SPIE Medical Imaging, 65142U-1-7 (2007). [7] Moin P, Ma K, Amezcua L, et al. \"The Development of an MRI Lesion Quantifying Sy stem for Multiple Sclerosis Patients Undergoing Treatment\" Proceedings of SPIE Medical Imaging, Vol. 7264-72640J Piven, Heather Cody Hazle tt, Rachel Gimpel Smith, S ean Ho, James C. Gee, and Guido Gerig. User-guided 3D active contour segmentation of anatomical structures: Significantly improved efficiency and reliability. Neuroimage 2006 Jul 1;31(3):1116-28. 99Content-based numerical report searching for image enabled case retrieval Liang Xue, Tonghui Ling, Jianguo Zhang Laboratory for Medical Imaging Informatics, Shanghai Institute of Technical Physics, Chinese Academy of Science, Shanghai Abstract One way to improve accuracy of diagnosis and pr ovide better medical treatment to patients is to recall or find records of previous patient s with similar disease features from healthcare information systems which already have confirmed diagnostic results. In most situations, features of disease may be described by other kinds of information or data types such as numerical reports or a simple or complicated SR (Structure Repo rts) generated from Ultras ound Information System (USIS) or from computer assisted detection (CAD) components, or laboratory information system (LIS). In this presentation, we described a new approach to search and retrieve numerical reports based on the contents of parameters from large database of numerical reports. We have tested this approach by using numerical data from an ultrasound information system (USIS) and got desired results both in accuracy and performance. The sy stem can be wrapped as a web service and is being integrated into a USIS and EMR for clinic al evaluation without interrupting the normal operations of USIS/RIS/PACS. We give the design architecture and implementation strategy of this novel framework to provide feature based case retrieval capability in an integrated healthcare information system. Keywords: Numerical Record Retrieval, High Dimensional Indexing, V A-Trie, Ultrasound Information System(USIS), Cardiology Examination 1. Introduction The CBIR (Content-based image retrieval) technology has been proposed for retrieve images for decision support in imaging diagnosis. Also, the text retrieval technology has been used for text reports searching in RIS (Radiological Inform ation System) and CIS (Clinical Information System). However, features of disease may be described by other kinds of information or data types such as numerical reports, a simple or complicated SR (Structure Reports) generated from Ultrasound Information System (USIS) or from computer assisted detection (CAD) components, or laboratory information system (LIS). The content-based search ing and retrieval for Structured Report are also crucial for medical professional s to find similar cases from medical information systems. A structured report usually has tables and contains multiple dimension information, e.g., some dimensions just having two values such as 1 or 0, other dimensions being texts to describe the characters of test items, but most dimensions having numerical values measured by specific modalities. Figure 1 shows an ultrasound report about cardiology examination, which contains 8 dimensions of numerical values. 100 Figure 1. Ultrasound report of cardiology examination Similarly with RIS, it was usually using key words such as patient ID, study ID, and Procedure codes to search and query USIS to find reports. It is difficult to use multiple dimension numerical values or similar content to search and find the similar cases in USIS. We had developed a novel method combining text retrieval and typical CBIR techniques to search large-scale medical image database in integrated RIS/PACS for computed aided decision support and presented this research work in PACS and Imaging Informatics of 2009 SPIE conference on Medical Imaging[3]. The text retrieval process in the first phase was used as a navigation method for finding relevant candidate images, and similarity computing was processed between user query image and the candidate images. In this paper, we presented a new approach to search and query image-enabled cases from USIS with content of SR of US, gave the preliminary testing results and discussed how to integrate this capability into clinical environment. 2 High Dimensional Information Indexing 2.1 Brief of High Dimensional Indexing In last decade, many new technologies have been developed to enable content-based multimedia information retrieva1, and meanwhile, there were still many difficult problems having not being solved, such as high dimensional space indexing efficiently to support large scale high dimensional content-based similarity query and retrieval So, there are many indexing methods have been proposed to solve this problem such as R-Tree [1] and A-Tree [2] VA-File [4], etc Most high dimensional algorithms are based on da ta-partitioning such as R-Tree and A-Tree. For example, in the algorithm of R-Tree, neighbor vectors are covered by MBRs (Minimum Bounding Rectangles) which are organized in a hierarch ical tree structure. The VA-File (Vector 101Approximation File) is another kind of algorithm s to index high dimensional vectors. VA-File divides the data space into cells and allocates a bit-string to each cell. The vectors inside a cell are approximated by the cell, and the VA-File itself is simply n array of these geometric approximations. During searching, the entire VA-File is scanned to select candidate vectors. Those candidates are then verified by accessing the vector files. Structured report searching or numerical conten t-based retrieval has similar problem of high dimension indexing such as CBIR in medical image, but the most CBIR algorithms can't be used here for the following reasons: (1) Data-partitioning based algorithms can only index and retrieve data with fixed dimensions. For example, if one creates an index with 10 dimensions, one can only fill the index with 10 dimensional vectors, and also one can only retrieval data with 10 dimensional vectors. But in medical records, most structured reports may have numerical data with various data types and various dimensions. In this situation, some dime nsions or parameters of a patient report may be null in the report, and others may have values, and other patients may have different parameters in their reports. (2) We have tested most of high dimensional indexing algorithms and concluded that the performance of query and retrieval was good if th e number of dimensions were less 20, but the performance would decrease as the more dimensions were considered. It is well-known as the \"dimensional curse\" After doing research on different high dimensional indexing methods, we adopted VA-Trie indexing algorithm in our research for numerical report content-based searching and retrieval 2.2 Structure, Operation and Advantage of VA-Trie Algorithm The key of VA-Trie is to adopt the VA concept in VA-File and then employing the Trie structure to organize and manage the approximations. VA-Trie Structure: Figure 2 shows the structure of V A-Trie. Figure 2. Structure of V A-Trie 102The VA-Trie consists of two components: The Trie layer and the VA layer. The Trie layer is used for searching the addresses of vectors on V A layer and the V A layer is used to store approximated vectors. (1) Trie layer: The Trie layer is a tree structure. The depth of the tree is the same as the dimensionality of the indexed vector. Root node represents the dimension 1 of a vector, the son nodes of the root represent the dimension 2, and so on. There are M+1 partition points in dimension i to divide this dimension into M segments and there is a son node in dimension i+1 linked to each segment of the nodes in this dimension. The larger tree would be, the higher dimensionality and the number of segments of each dimension are. However, in high dimensional space, only few nodes are not null, so the scale of the tree is limited. There isn't any son node in leaf nodes, but some values point to particular blocks in the VA layer. (2) VA layer: The VA layer is a file on the hard disk and is consist of blocks. Records stored in one block are site to each other and the size of each block is fixed. If one block is full, a new block will be created to store new record and the former block will have a tag pointing to the new block. VA-Trie Operations: Here we introduce two basic operations on VA-Trie: inserting and searching (1) It is easy to insert a vector into VA-Trie: First, we get an approximation of the vector according to the partition points of each dimensi on. Second, find out the path of the approximated vector in Trie layer. Third, write the id information of the vector into the corresponding block of the path in the VA layer. (2) The searching algorithm is based on the distance of two vectors. We define the distance between two vectors as follows: 12 1 qp == qprr i i ( 1 ) Where D is the Manhattan distance, and re presents the distance of vector qrand . The is the i-th component of ,n is the dimensionality . pr iq qr We also defined a parameter called Dmax which represents the searching range for a search operation. The search procedure starts from the ro ot node of the Trie layer according to the method shown in Figure 3. Figure 3. Search algorithm in a Trie node 103In Figure 3, the search procedure gets to a node in dimension i with query vector and range Dmax. For range rj in dimension i , we compare D i,j with Dmax. vv 1 ,1 11|| ||ij i i j i i jij iij i jDp p v DD v p p v p p Dv p p v p p + =+ < + > 1p p + ( 2 ) Here, Di-1 is the distance generated in first i-1 dimensions, vi is the i-th component of and ppj is the j-th partition point in dimension i. The search procedure will switch to corresponding son node of rj if Di,j is lower than D max. This procedure will continue until we get to leaf nodes. The search procedure in Trie layer will guide us to the position of the approximated vectors on the VA layer and the approximated vectors will be achieved in the returned result set. vv Advantages: (1) This VA based algorithm s(R- Tree) especially when the dimensionality is high. Also, vectors with some dimensions empty can also been indexed in this algorithm. (2) The VA-Trie algorithm inherits the method of VA from VA-File. Instead of scanning the entire VA-File for search, it uses a tree structure to manage the cells. It will avoid the unnecessary scanning time when the number of cells becomes very large. 3 Content-Based Numerical Repo rt Searching and Retrieval In this section, we presented a framework to build content-based searching and retrieval in an integrated USIS/PACS environment using the algor ithm of V A-Trie described in section 2. We first discussed the procedure of indexing and searching. Then, we presented a similarity computation algorithm to verify the query results. 3.1 Indexing The USIS is widely used in ultrasound department to manage the workflow as well as diagnostic reports. In our design for numerical reports or SR searching and retrieval, we created index according to the following steps: First, all ultras ound reports of the spec ific examination were analyzed statistically on each dimension. Second, we found proper partition points and range on each dimension using the deviation, the maximum value, the minimum value and the statistical distribution from the first step. The best partition of one dimension was to make all reports uniformly distributed in a specific range. Third, we selected the parameters of the VA-Trie with the partition points of each dimension. Last, each report was inserted into the index. Figure 4 shows the indexing procedure. 104 Figure 4: Indexing procedure 3.2 Searching and Retrieval Figure 5: Retrieval procedure Figure 5 shows the searching and retrieval proc edure. When a new case was available from a modality or a clinical PACS and was viewed on PACS/USIS workstation, the doctor might want to find the similar cases with similar measured parameters from USIS and PACS. So, the query parameters input from user should contain the following information: the query vector of the report( ), the query range(D max), and weight of each dimension( ). vv 11,, . . .n ww w We did some improvements to the Manhattan distance of two vectors: 12 i i iD q q q p p p w qps == qpi i ( 3 ) si is the deviation of dimension i. We introduced deviation here because of the difference between the statistical distribution of dimensions. The wi is the weight of dimension i and represents the importance of dimension i in this search. The output of VA-Trie index is a set of vectors. If the distances between the input vector and the queried vectors are lower than or around Dmax, then, the candidate report similarity is calculated as follows: (,) e x ( 4 ) The vectors which are near to the input vector will have high similarity. The queried results are then sorted by report similarities and returned to user. 4. Implementation In our clinical practice, we developed a prototype system of content-based retrieval for US numerical reports or SR about cardiology examin ation and tested it in Jian-Gong hospital in Shanghai. The System included High Dimensional Retrieval server, PACS and USIS. Figure 6 105showed the diagram of the prototype system. WorkStation PACS USIS High Dimensional Index Web Services VA-Trie Indexhttp Dicom Figure 6. Integration of High Dimensional Index, PACS and USIS To index the reports, we first scaned the USIS and constructed a vector for each cardiology report. Then we did statistical analysis on each dimension of the vectors and built the structure of the index. Existing Reports of cardiology examination were then inserted into the index. Every new generated cardiology report could be indexed into the index server. The high dimensional index service could be accessed from USIS clients through a web server. We built a search GUI and integrated it into the USIS workstation. When an user viewed reports and images through USIS workstat ion, he or she could use search GUI to adjust the parameters and its' ranges for specific pathology. The parameters then input into the high dimensional index server, and a list of similar cases were returned and sorted by similarities. Users could get contents and images of each query result from USIS and PACS. All these works were done without interrupting the normal operation of USIS and PACS. 5. Results In our preliminary testing, we had 60,000 records included and indexed in the High Dimensional Index Server and each record was 8-dimensional vector. In order to achieve a better performance, we divided the value range of each dimension into 10 segments. A Dell PowerEdge Server R200 with Intel Xeon 3050 CPU(2.13GHz), 2 GB RAM, and 160GB 7200rpm HD was used to create index and to provid e search service to clients, and the operating system of the server was windows server 2003. Figure 7 shows the images and contents of the qu ery. Figure 8 shows the search GUI and search results with medium query range. 106 Figure 7. The input report with images Figure 8. The queried list of results with medium range In Figure 8, we got 5 similar reports with the various values in each dimension. The last column shows the similarity of each result report. The first row shown in the list is just the query report for a perfect match. 107 Figure 9. Queried Results with high query range Figure 10. The queried results with high query range and different weights In Figure 9, we set query range to little bits of high. We got a result set with 79 reports. Comparing with Figure 8, the queried results contained more reports which had lower similarity. In Figure 10, the query range was higher and we set the weight of the last dimension (Ejection Fraction) to 10.0. We got 32 results this time. 108 Figure 11. Retrieved report with corresponding images If the feature similarities of a queried report were close to that of the input report, the pathologies described by queried report may also similar to that described by the input report. Figure 11 shows the report text and image related to the queried report which has a similarity of 0.456 with that of Figure 7 under default weight 1.0. The impresses of both reports showed that these two patients had the same pathologies of: (1) Declination of diastolic of Aortic insufficiency . (3) Mild regurgitation. Figure 12. Sensitivity of con Figure 12 shows the performance of querying different reports in the 60,000 reports which was measured by the average respon ding times and averaging number of retrieved results v.s. 109maximum distance. The horizontal axis shows the maximum distance defined in equation (3) , the left vertical axis shows the number of results, and the right vertical axis shows the time required. In this testing, the weight of each dimension was 1.0, and the maximum distance was changed from 1.0 to 4.0. The querying times depends on the querying range set in dimension. The larger the similarity range between the input and candidate reports, the more number of queried reports would be retrieved, and the longer the responding times would take for searching. So, the developed prototype system would have good performance in content-based numerical report querying and retrieval if the similarities were properly set up. 6. Conclusions In this presentation, we presented the design me thod of content-based numerical report searching and retrieval system. We chose V A-Trie as th e indexing and searching algorithm and did some improvement for medical applications. We developed a prototype system of content-based retrieval for ultrasound information system which managed US numerical reports. We tested and evaluated this system by using numerical data of cardiology examinations in ultrasound information system (USIS) and got desired results both in accuracy and performance. The accessing interfaces of this system were wrapped as web services, and the developed system could be integrated into a USIS for clinical evalua tion without interrupting the normal operations of USIS/RIS/PACS. 7. Acknowledgement This research was supported in part by National Nature Science Foundation of China (Grant No. 30570512), Department of Science and Technology of Shanghai (No. 05DZ19510), and Department of Science and Technology of China (No. 2007BAH06B01/B02/B03). 8 . Reference 1. A.Guttman, R-trees: a dynamic index structure for spatial searching, Proceedings of the 1984 ACM SIGMOD international conference on Management of data Boston, Massachusetts. 2. Sakurai, Yasushi and Yoshikawa, Masatoshi and Uemura, The A-tree: An Index Struct ure for High-Dimensional Spaces Using Relative Approximation. VLDB 2000, Proceedings of 26th International Conference on Very Large Data Bases, September 10-14, 2000 . 3. Zhenyu He, Yanjie Zhu, Tonghui Ling, Jianguo Zhang, Combining Text Retrieval and Content-based Image Retrieval for Searching Larg e-scale Medical Image Database in Integrated RIS/PACS Environment SPIE 2009 4. Weber, Roger and Blott, Stephen (1998) A Quantitative Analysis and Performance Study for Similarity-Search Methods in High-Dimensional Spaces . In VLDB 98: Proceedings of the 24rd International Conference on Very Large Data Bases 5. Dong Daoguo Liu Zhenzhong and Xue Xiangyang, VA-Trie: A New and Efficient High Dimensional Index Structure for Approximate k Nearest Neighbor Query, Journal of Computer Research and Development 42(12)2213~2218,2005 110 SELECTED PEER REVIEWED REPRINTS 111Int J CARS DOI 10.1007/s11548-009-0387-x ORIGINAL ARTICLE A multimedia electronic patient record (ePR) system for image-assisted minimally invasive spinal surgery Jorge Documet \u00b7Anh Le \u00b7Brent Liu \u00b7John Chiu \u00b7 H. K. Huang Received: 23 April 2009 / Accepted: 21 June 2009 \u00a9 CARS 2009 Abstract Purpose This paper presents the concept of bridging the gap between diagnostic images and image-assisted surgicaltreatment through the development of a one-stop multimediaelectronic patient record (ePR) system that manages and dis- tributes the real-time multimodality imaging and informat- ics data that assists the surgeon during all clinical phases ofthe operation from planning Intra-Op to post-care follow-up.We present the concept of this multimedia ePR for surgery by rst focusing on image-assisted minimally invasive spinal surgery as a clinical application.Methods Three clinical phases of minimally invasive spinal surgery workflow in Pre-Op, Intra-Op, and Post-Op are dis-cussed. The ePR architecture was based on thethree-phased workflow, which includes the Pre-Op, Intra- Op, and Post-Op modules and four components comprising of the input integration unit, fault-tolerant gateway server,fault-tolerant ePR server, and the visualization and display.A prototype was built and deployed to a minimally invasive spinal surgery clinical site with user training and support for daily use.Summary A step-by-step approach was introduced to develop a multimedia ePR system for imaging-assisted min-imally invasive spinal surgery that includes images, clinicalforms, waveforms, and textual data for planning the surgery, two imaging techniques (digital fluoroscopic, DF) J. Huang IPILab, Department of Radiology, Keck School of Medicine, University of Southern California,1450 San Pablo Street, Suite DEI 2100,Los Angeles, CA 90033, USAe-mail: documet@usc.edu J. Chiu California Spine Institute Medical Center Inc,1001 Newbury Road, Thousand Oaks, CA 91320, USAand endoscope video images (Endo), and more than half a dozen live vital signs of the patient during surgery. Clinical implementation experiences and challenges were also dis- cussed. Keywords ePR \u00b7System integration \u00b7 Pre-, Intra- surgical workflow \u00b7 Minimally invasive spinal surgery Abbreviations API Application program interface BIS Bispectral index system CO2 Carbon dioxide CR Computed radiography CSI California Spine Institute CSS Cascading style sheetCT Computed tomography DICOM Digital imaging and communications in medicine EMG ElectromyographyePR Electronic patient record GIF Graphics interchange formatGUI Graphical user interfaceHIPAA Health Insurance Portability and Accountability Act HIS Hospital information systemHTML Hyper text markup language HTTP Hyper text transfer protocol HTTPS Hyper text transfer protocol securedICT Information and communication technology IA-MISS Image-assisted minimally invasive spinal surgery IPILab Image Processing and Informatics Laboratory IRB Institutional Review Board IT Information technology 123 112Int J CARS IU Integration unit IVF Intravenous fluidJPEG Joint Photographic Expert Group LCD Liquid crystal display MB MegabytesmmHg Millimeters of mercuryMRI Magnetic resonance imaging OR Operating room PACS Picture archiving and communication systemPHP PHP: hypertext preprocessor PNG Portable network graphics RAM Random access memoryRIS Radiology information system RS232 Recommended Standard 232 SC Secondary captureSDK Software development kitTB Terabytes USC University of Southern California V AS Visual analog scaleVGA Video graphics array Introduction Bridging the gap between diagnostic images and surgical treatment This paper presents the concept of bridging the gap between diagnostic images and image-assisted surgical treatment through the development of a one-stop multimedia electronic patient record (ePR) system that manages and distributes thereal-time multimodality imaging and informatics data thatassists the surgeon during all clinical phases of the operation from planning Intra-Op to post-care follow-up. We present the concept of this multimedia ePR for surgery by rst focus-ing on image-assisted minimally invasive spinal surgery as a clinical application. For this particular surgical procedure, in addition to images, clinical forms, waveforms, and tex-tual data for planning the surgery, two real-time imaging techniques (digital fluoroscopic, DF) and endoscope video images (Endo), and more than half a dozen live vital signs ofthe patient during surgery are needed to assist and monitorthe surgery. All these data have to be acquired, displayed and archived in real-time as well. Minimally invasive spinal surgery Back and neck pain is the price human beings pay for poor posture, prolonged sitting, lifting, repeated bending, obes-ity, and injury from accidents. This ailment gives the United States with a massive economic headache. Approximately 85% of inhabitants of the Western world are afflicted withsome degree of back or neck pain at some point in their lives[1]. About 25% of our population has been incapacitated for2 weeks or more due to back pain and an estimated 8 to 10million people have a permanent disability from it [ 2-5]. The economic impact is obvious. In most cases, simple treatmentssuch as bed rest, exercise, physiotherapy, and pain medica-tion bring relief. Many sufferers are not so fortunate. If oneor more of their vertebral discs ruptures and presses on nerve roots, the pain radiating from the back or neck and down the limbs can be incapacitating and severe. Until recently,the only treatment was surgical removal of part of the rup- tured disc, a major operation that required general anesthesia, the dissection of muscle, removal of bone, manipulation ofnerve roots, and, at times, bone fusion. In an effort to over- come the disadvantages of traditional surgical techniques, the scientic medical community began exploring the use ofendoscopy (arthroscopy) for minimally invasive spinal sur-gery surgical operation [ 6,7]. An endoscope provides clear visualization and magni- cation of deep structures in real-time. With the advance-ment of scientic technology and miniaturization, including ber optics, video imaging technology, laser treatment and experience gained through minimally invasive spinal sur-gery, there is a less traumatic discectomy procedure for some patients with disc problems. In the recent years, develop- ment of image-assisted surgery has improved the precisionand reduced surgical tissue trauma. Figure 1depicts the cer- vical, thoracic and lumbar (Post-Op) the endoscopic-guide spinal discectomy. The lesion(s) at each spinal region is clearly cured after thesurgery. Rationale for a multimedia ePR system for image-assisted minimally invasive spinal surgery Minimally invasive spinal surgery will be the method of choice for future spinal surgery to treat cases of herniatedlumbar discs, post fusion junctional disc herniation, neural compression, tumor, synovial cysts and othertypes of spinal traumas. Despite the overall advantageous and benets of minimally invasive spinal surgery compared to conventional open spinal surgery, there are challengesremained in minimally invasive spinal surgery including (1)integration of Pre-, Intra-, and Post-Op surgical data from scattered data acquisition systems, (2) overcoming the dif- culty of real-time data collection during the surgery, and(3) the efciency of surgical workflow. An inte- multimedia ePR system is an ideal solu- tion to overcome these challenges. If successful, it will takeMinimally Invasive Spinal Surgery to a higher level of excel- lence by combining surgical expertise in minimally invasive spinal surgery with the frontier advancements in imaginginformatics. 123 113Int J CARS Fig. 1 Minimally invasive spinal surgery on cervical, thoracic, and lumbar spines. Upper row Pre-operation arrows show the areas where the discprotrudes the spine. Lower row Post-endoscopic-assisted spinalsurgery shows the lesions havebeen cured The goals of the ePR The two goals of this research development are: (1) To develop a totally integrated multimedia ePR system for image-assisted minimally invasive spinal surgery. All data collected for the patient from Pre-Op, Intra-Op and Post-Op will be acquired, displayed, and archivedduring each clinical phase of the surgical workflow. Any data record of the patient in the ePR can be retrieved instantaneously anytime and anywhere. (2) To deploy the ePR at a clinical site for daily clinical use. Figure 2depicts the ePR prototype system running at the Minimally Invasive Spinal Surgery Operating Room(OR) of a clinical site, with two large LCDs (liquid crys-tal display), one for the Pre-Op consultation integrated display, and the second for the Live Intra-Op integrated display. Materials and methods General minimally invasive spinal surgery workflow The minimally invasive spinal surgery current high-level operation workflow includes pre-surgical consultation, pre- operation preparation, intra-operation image and vital signs acquisition and display, post-surgery documentation topatient recovery monitoring. The workflow can be broken down into three phases [ 8,9]: (1) before surgery, (2) during surgery (including the preparation) and (3) post surgery. Each of the three clinical phases will be discussed below.(1) Before surgery (Pre-Op): this phase is the workflow involved prior to the actual surgical procedure. In thePre-Op workflow, usually the patient presents with a problem and is evaluated by the physician to determine whether Minimally Invasive Spinal Surgery is neededand whether it would be helpful to the patient. If this caseis true, then a procedure is scheduled. At this stage the surgeon or surgeons in combination with the physician assistant plan the surgical procedure using digital diag-nostic images such as CR, CT and MRI. In addition to the information obtained from the medical studies, the patients also ll out a set of surveys that determine thelevel of pain that they feel. (2) During surgery (Intra-Op): during the surgical proce- dure, the surgeon(s) operate on the different disc(s) thatneed to be corrected. While operating, there is a signif-icant amount of data being acquired that help monitor the body response of the patient to the procedure. This includes video and image data acquired with the endo-scope. A single vertebrae procedure usually lasts 30 min on average. (3) After surgery (Post-Op): during this Phase the patient recovers from surgery. The patient is continuously mon-itored in the recovery area to assure all vitals signs are stable. In addition, a set of tests are also performedto assess the outcome of the surgical procedure whichincludes an additional set of forms that the patient lls out. The recovery period after surgery lasts from 45 min to 1 h. The patient is then discharged. Therapy can begin the nextday and the patient can go back to work within 2-3 days. 123 114Int J CARS Operating TableEndoscope Display / Stor age Laser Genera tor EEG/ Display 2800 mm .Large intra-op image/dataSelecte d Im aging/ dictation sy stemVideo Mixin Surgical Video Camera / Display EKG/ Disp layVital signals and DisplayAuthorin g document LCD Intra-op 52\" LCD 1) Anesthesiolo gist 2) Assistant 3) Surgeon 4) Scrub nurse 5) Circ ulator 1 2 3 45 Fig. 2 Schematic of the dynamic multimedia ePR system for image- assisted minimally invasive spinal surgery. The ePR prototype system is running at the minimally invasive spinal surgery OR of CSI, withtwo large LCDs (liquid crystal display), one for the Pre-Op consulta-tion integrated display, and the second for the Live Intra-Op integrateddisplay Fig. 3 The data model of the ePR system. It extends theschema of DICOM toaccommodate surgicalinformation including livewaveform and several standardsurgical forms. Additionalentities have been augmented tot h ed a t am o d e l Data model of ePR system The data model of the ePR for Minimally Invasive Spinal Surgery has been designed to extend the DICOM data model due to the similarities that exists for medical imaging dataat CSI utilizing DICOM. From the DICOM data model the ePR for Minimally Invasive Spinal Surgery follows the rela- tionship between the patient, the medical studies, series andimages. The modied data model utilized for the current ePRcontains additional entities that describe the data required forminimally invasive spinal surgery. These new elements thatare added to the data model include the surgical proceduretype, waveforms, the key image, survey forms for pain, and user information for access to the system. The data model is shown in Fig. 3. The ePR dataflow The initial data flow utilized by the ePR system was based on the concept of the workflow presented in the general 123 115Int J CARS Fig. 4 Dataflow of the ePR system for minimally invasive spinal surgery. There are three time phases (vertical ): Pre-Op, Intra-Op and Post-Op; and fouroperational modules(horizontal ): input units, gateway, ePR Server anddatabase, and visualization anddisplay, which forms a 3 \u00d74 matrix. Each numeral represents one event in the dataflowexplained in the textPre-Op Historical 1 1)eP R Ser ver g ve/dat abase Intra -Op (IU) Post-Op 10 8 Gateway Fault-tolerant 7 3 Pre-Op ta Post-Op authorin Display minimally invasive spinal surgery workflow and is shown in Fig. 4where each numeral represents a dataflow event. There are three time phases, from the top down: the Pre- Op image/data module, the Intra-Op module, and the Post-Opmodule. Each of these modules contains four components:input module, input gateway, ePR server, and the visualiza- tion and display module. Pre-Op workflow Following Fig. 4. (1) Historical medical imaging studies in DICOM format are acquired from the PACS (picture archiving and com- munications system). (2) The gateway, which is a component of the ePR sys- tem, receives the DICOM images and processes themaccordingly. The original image is kept in the ePR anda JPEG version is utilized for display purposes via the web interface of the ePR. All DICOM header infor- mation and metadata are extracted and recorded in thedatabase. (3) Pre-Op authoring is performed by the surgeon(s) and the physician assistants. The surgical procedure informa-tion is entered into the ePR. At this Phase the patient'ssurvey pain forms are also entered into the system. The surgeon selects some key images and authors annota- tions overlaid on the key images that will ultimatelybe utilized during surgery. The authorized images/data are displayed in the OR utilizing a 52-in. LCD display (see Fig. 1). (4) Authorized images/data are archived in the ePR server. Intra-Op workflow (5), (6) and (7) The integration unit (IU) is connected to all clinical devices in the OR and continuously gathers livedata signals from them during the entire surgical proce- dure, and display them in real-time on the second large52-in. digital display (see Fig. 1). (6) The gateway Server receives the data from the IU and stores the data values and images in real-time at thedatabase within the ePR system. Post-Op workflow (8) While the patient is in the recovery area, the system con- tinues gathering some vital signs that are transferred to the gateway server. (9) The gateway server receives the data and stores the data into the database of the ePR system. (10) The surgeon uses the Post-Op authoring module to create a nal report out of the data gathered during the Pre-, Intra-, and Post-Op phases. (11) The nal report will be kept in digital format at the ePR Server as the patients' permanent surgical record. Minimally invasive spinal surgery ePR system architecture Recalling Fig. 4which depicts the workflow and data flow model of the minimally invasive spinal surgery ePR system represented by a 3 \u00d74 dimension matrix model. The three rows are Pre-Op, Intra-Op, and Post-Op workflow processPhases; and the four columns are the input data integration unit (IU), input gateway, ePR server, and image/data display. From the system architecture point of view, the ePR systemshould be designed for efciency, effectiveness, and reliabil- ity of system operations. The fault-tolerant requirement of each component in the system is designed to support otherexisting components of the system for easy system back-up and cost containment. The ePR System architecture is shown in Fig. 5and will be discussed in detail in the following para- graphs. 123 116Int J CARS Fig. 5 The ePR system architecture showing three operation phases (rst column): Pre-Op, Intra-Op and Post-Op; as well as four operation modules (partitioned and scattered systematically). Some partitionedmodules are bundled up together for ease of data transfer and fault-tol-erant back-up. The arrows show the data flow during the three phases of operation. The outside light gray color side-way \"U\" band is the dis-play module backbone with ve rectangular box subunits. Inside the opening of the \"U\" in dark gray are the integration unit, fault-tolerant gateway, and fault-tolerant ePR server. Within the gateway and the ePRserver, the Database and Filesystem software are interrelated and sharedby both components Four major components in the minimally invasive spinal surgery ePR system The four major components in the Minimally Invasive Spinal Surgery ePR System are: (1) integration unit (IU), (2)fault-tolerant gateway server, (3) fault-tolerant ePR server, and (4) Visualization and Display. Both the input gateway and the ePR server include data storage and archive, systemdatabase, system security, system fault-tolerance, continuousavailability and failover. The GUI and display module resides within the ePR Server. All data input systems like medical imaging, surgical video, vital signs waveform recorders, andtextual data recorder generate Pre-Op, Intra-Op, and Post-Op data, and they are all categorized as input data. The imag- ing and data systems that generate information are existingperipheral surgical supported equipment already within the OR but they do not belong to the Minimally Invasive Spinal Surgery ePR system. However, the ePR system must inte-grate these devices in order to receive the input data that isacquired before, during, and after surgery that support the surgical procedure. Integration unit (IU) This component is responsible for acquiring all data from dif- ferent peripheral devices that are presented in the OR during surgery (Intra-Op) that continuously measure all live vital signs, waveform signals, and surgical related images of thepatient undergoing a procedure. The data acquired by theIU from all input devices are synchronized through a masterclock and displayed live onto a customized interface usinga 52-in. LCD (liquid crystal display) screen (called Intra-Op live display) in the OR. The data gathered during surgery include the following: \u007fDigital (bi- index), and vitals (blood pressure, heart rate,respiratory rate, pulseOX, body temperature and partial pressure of carbon dioxide). The images, videos and data points mentioned above are transferred automatically and continuously from the various input sources of the different data devices in the OR during operation that are attached to the data input IU. The data isimmediately saved into IU memory. The IU software dis-plays the waveforms, images, and streamed videos properly every second (which is a default value) on the large Intra-Op LCD, and also makes a copy from the memory to the IU localhard drive with 1.5 TB (Terabytes) of storage space every 5 s (which is also a default value). These two default values can be adjusted interactively depending on clinical demands. Normal procedures for a single vertebra surgery take about 30 min on average. This Intra-Op data is sent continuouslyto the gateway where the images are processed if needed andthen placed in a data folder shared with the ePR server where 123 117Int J CARS they will be permanently archived. The data values are also extracted and saved to the ePR system database. In addition to the one second input display refresh-rate described in the last section, the IU features a rule-basedalert-mechanism that checks each input waveform for datathat is out of the normal range. The IU has a set of rules basedon clinical accepted medical practice that determines when a given signal is considered within the normal range for a patient. If at any given time during the surgical procedure, asignal falls outside the safe range, the IU will trigger an alert message on the Intra-Op Live display. This assists the sur- geon and key personnel in the OR to take necessary actionsduring the surgical procedure. It is noted that the default val- ues might not be considered normal for all patients; thus, during the Pre-Op patient consultation time, these defaultvalues can be revised and properly adjusted as necessary. The fault-tolerant gateway server The functions of the input gateway are receiving, staging, managing, and transferring input data during the three clin- ical workflow phases of the surgery: Pre-Op phase The gateway receives DICOM images and diagnostic reports from PACS. Once images are received by the gateway, a Pre-Op script is automatically launched by the gateway to properly extract all the information from theheaders of the DICOM les. This data is then saved into thedatabase. This whole process is automated at the gateway and does not require any user intervention. Intra-Op phase During Intra-Op, the gateway receives live data from the IU using an API (application program inter- face). The transfer protocol used is the HTTPS (hypertext transfer protocol secure) Standard. Before any data is sentto the Gateway, the IU needs to properly authenticate itselfin order to avoid conflict with other possible input devices. Once the data is received by the gateway server, the API will place the data in a specic location in the ePR where a scriptwill be executed to process the data accordingly. Post-Op phase During Post-Op, the patient is under obser- vation in the recovery area by a nurse and the surgeon. The vital signs and other monitoring equipment are used to eval-uate the patient Post-Op condition. During the 45 min to 1 h observation, live data of the patient is continuously received and displayed at the bedside monitor by the Post-Op module. The fault-tolerant ePR server The ePR Server is the heart of the Minimally Invasive Spinal Surgery ePR System and is the front-end of the system wherethe users will login to perform all the necessary tasks duringthe surgical workflow. The ePR Server allows access to thePre-Op authoring module, the Pre-Op display in the OR and the Post-Op authoring module (see Fig. 5). Administrative tasks such as giving the users access to the system, regis- tration of patient information, scheduling, among others arealso included. The ePR by definition allows the participants to obtain any necessary information about the patient from a singleinterface, i.e., the information follows the patient. The ePR not only shows information about the medical examinations for the patients, but also any other related data such as clin-ical history and pain surveys acquired during the surgical procedure. The ePR is developed utilizing PHP (PHP: hypertext pre- processor) as the backend programming language. The data values are stored using a MySQL database [ 10]. The web pages are structured with HTML (hyper text markup lan-guage), and they are styled using CSS (cascading style sheet).The interfaces are dynamically updated using JavaScript. The web server utilized is Apache 2.2 [11]. Data storage and archive and system database Managing the data acquired by the ePR system is a critical task. There- fore, a dual-system back-up mechanism is implemented as follows. First, the ePR server has the server hardware, andthe Gateway has the Gateway hardware. Two identical server software packages are implemented, one in the ePR server hardware as the primary and the other in the Gateway hard-ware as the back-up. By the same token, two Gateway soft- ware packages are implemented, the primary package is in the Gateway hardware, and the secondary package is in theePR Server hardware as the back-up. Refer to the middlerow of Fig. 5, the Gateway and the ePR server each has its own hardware, where each hardware piece is housing boththe ePR server software and the Gateway software; one is theback-up of the other. Figure 6shows the dual-system backup mechanism. The input data rst comes to the Gateway hardware, where the Gateway software categorizes them by images, live wave- form information, and textual information. Images include DICOM images in their original DICOM format as well asin JPEG format for web display; as well as endoscopic endoscopic single frame images, and digital C-arm fluo- roscopic images. The metadata in the DICOM images and other data are stored in the database disks. All acquired dataand metadata are immediately backed up by the ePR Server hardware. System security The system security has been considered carefully during the design in order to comply with the HIPAA (Health Insurance Portability and AccountabilityAct) requirement. Only the users who have been granted 123 118Int J CARS Fig. 6 The dual-system back-up schema with two hardware pieces: ePR server Each hardware piecehas ofsoftware: ePR Server softwareand gateway software; and atandem database with hard drivefor data and metadata archive permission are allowed access to the system. At the same time the privacy of the communications are kept to avoid any non-authorized receiver to obtain a given patient's private information. To guarantee the security of the data, web accessto the ePR is established with HTTPS that encrypts allcommunication between the server and the clients (web browsers). In addition, the ePR system handles permissions that will allow users to perform different tasks on the system.Different user groups in the system have a different set of enabled permissions, however, permissions can be overwrit- ten for individual users by the system manager if necessaryproviding a greater level of flexibility. System fault-tolerance and continuous availability and failover The information that is kept in the ePR is unique and cannot be obtained from any other sources if lost. Toovercome any possible loss of data, a fault-tolerant solutionthat replicates the data of the ePR to more than one placehas been implemented. The primary Gateway serves as the backup for the primary ePR server, and vice versa. In addition to having the data being stored with more than one copy, system redundancy with automatic failover mech-anism has been designed to access the data in case of the failure of any component in the system to guarantee systemcontinuous availability. Visualization and display The last of the four components in the ePR System is the graphic user interface (GUI) and Display. In order to have theePR system to be utilized as an effective tool that can improvethe workflow of the Surgery Department, it is important tohave a user-friendly GUI that presents all necessary contents for the surgery in an easy to use manner. For this reason, the ePR system is designed with this concept to achieve this goal. Because the entire ePR system operates in three interre- lated Phases during a surgical procedure, from planning (Pre- Op), to surgery (Intra-Op), to patient recovery (Post-Op); the interface design between these three Phases are critical.The Display interface design (see Fig. 5) includes the main page, the Pre-Op display at the patient consultation room,the Pre-Op display at the OR, the Intra-Op display at theOR, the Post-Op at the patient recovery area, the Post-Op at the OR for surgical documentation, and the administrative pages. Pre-Op authoring module The Pre-Op Phase of a mini- mally invasive spinal surgery procedure is where all neces- sary information prior to the surgery procedure is collected and organized in a patient e-folder. The Pre-Op happens days prior to the surgery and involves querying, interviewing, col-lecting, and storing of pre-surgical medical images, patientdemographic information as well as other pertinent data value that would assist the surgery during the procedure. Traditionally, surgeons have been relying on their memory for localization of where the procedure should be performed.They review the MRI and X-ray images the day before sur- gery and studied the approach to be taken during the proce-dure. These images are also brought to the OR for reference. But they are displayed in hard copy in an unorganized fash- ion scattered throughout the OR. The next few paragraphsfocus on the organization of the Pre-Op patient information 123 119Int J CARS Fig. 7 (Left, a) The Pre-Op authoring module page. The upper left hand text list depicts the surgical data model showing the studies and procedures. After the user clicks an item in the list, the proper image, in this case, a sagittal MRI is shown on the right .(Right ,b) The neuro-navigator tool allows the correlation of the position of the lesion inthe sagittal ( left) and the axial view (right ). The red lines are the two corresponding sagittal and axial sections which requires a preparation process. This process should not be done during the time of surgery and the informationshould be saved in advance with the display streamlined and organized for efciency purposes. Creating a surgical procedure in the pre-Op authoring toolkit The interface allows the users to create the surgi- cal procedures by rst selecting the key images as well asadding annotations to those key images as shown in Fig. 7. On this screen the PACS image and surgical procedures had been combined into one display in the Pre-Op module. Image studies related to the surgical procedure are shown on the lefthand side based on the surgical data model (see Fig. 7). To view an image in a study, the users can either drag the studyshown on the list from the left to the viewing pane on the righthand side or by double clicking the study from the list on theleft. Figure 7displays a sagittal MRI image with patient's ID above the image. The toolbar with icons at the top ofthe viewing pane allows the users to perform certain tasksaccordingly to the current status of the editing module. (1) To view images in a study: the two icons on both the right and the left sides allow the user to preview images in the study series. (2) To perform image manipulation: the toolbar for the Pre- Op include some basic image manipulation tools suchas window/level, pan, and zoom. With this functional- ity, the images can be displayed optimally at the exactlocation of the lesion.During a minimally invasive spinal surgery operation, it isimportant to correlate the axial view with the correspondingsagittal view of an MRI study. The neuro-navigator tool in the Pre-Op module allows such correlation through the display as show in Fig. 7. In addition to the input data described earlier, one type of Pre-Op data which is critical during surgery is the hand written whiteboard information located at the entrance of the OR which contains a very short summary of the patient suchas name, gender, age, weight, height, any allergies, comor- bidity and pain. Normally, the white board should contain all patients' information to be operated during the day. ThePre-Op authoring module described has been designed to integrate the whiteboard information onto the same Pre-Op screen for display in the OR during the surgery. The follow-ing survey measures are also included: 1. Visual analog scale (V AS): is a psychometric response scale to describe the amount of pain a patient is feeling from a specic part of her/his body. 2. Oswestry disability index: a survey to identify how the pain in the back or legs is affecting the patient in his/herdaily activities. The design concept of the ePR system is user-friendly but effective at the same time. For these reasons, the criterion of the user interface is to minimize the number of mouse clicksneeded to perform a certain task and to aggregate informa- tion adequately into a single interface whenever possible. The current Pre-Op authoring module is a self-contained inter-face where the users can download, edit, add, and delete the 123 120Int J CARS Fig. 8 The Pre-Op display organized during patient consultation as seen on the Pre-OP display monitor in the OR during Intra-OP. Top text row patient general information, second text row whiteboard infor-mation, bottom row images and annotation during Pre-Op consultation; image, middle sagittal MRI with annotation and right transverse MRI contents as needed. The Pre-Op has two major interfaces, one for editing and one for display in the OR. Pre-Op display A minimally invasive spinal surgery pro- cedure requires multimedia data during the Pre-Op phase including patient history, images, and consultation results.These data should be organized and displayed in the Pre- Op display during surgery. An example is shown in Fig. 8 which depicts the general patient information (rst top row), whiteboard information outside of the OR (second top row),as well as the key images selected from the MRI study with their annotations during consultation (center). The term that is used for this display is the Pre-Op display since the Pre-Op authored data is actually displayed during the Intra-Op workflow Phase. Intra-Op live display Figure 9shows a mock up example of the Intra-Op live display with waveforms and images. The horizontal axis is time. The stream from the vital signs deviceis displayed at the top row (left) and to the right there are ve groups of waveform: three vital signs with blood pressure, pulse oxygen concentration and pCO2, as well as BIS, IVF(intravenous fluid). Every dot in the waveform represents a data point over a one second interval. In the middle row, there are two images, the C-Arm fluoroscopic (right) and theendoscopic video images (middle), and one EMG waveform in the left. In the lower row, there is laser energy in joules. The video is updated on the Intra-Op live display with a framerate of 30 per second (a default value). Rule-based alert mechanism If a signal falls outside its safe range a three stage mechanism will alert personnel in the OR about that situation.(1) Warning mode: if the numeral falls outside the safe range it will change its color to red (as seen with thePulseOX and blood pressure in the gure) (2) Emergency mode: if the condition falls to a value greater or lower in 25% of the safe range then the Intra-Op live display will place an alert message on top of thescreen. (3) Critical mode: If the data signal value is either greater or lower in 50% to the values in the safe range then thealert message will cover the whole screen. Post-Op module The Post-Op phase takes place after the completion of the surgical procedure, normally, the next sev- eral days after the surgery. There are three time substages: (1) patient in the recovery area and then discharged, (2) thesurgeon documents the surgical results, and (3) follow uppain surveys after Post-Op for several months. Post-Op authoring toolkit When the surgeon performs Post-Op documentation, he/she can retrieve information from the Post-Op module pertinent to the surgery using the GUI. This process involves four major steps: (1) Finding the patient from the ePR System. The correct patient can be located from the ePR via the worklist. (2) Selecting images. From this GUI, the surgeon can select endoscopic images that will be included in the nal report by clicking the star at the top left corner of theviewing pane. As shown in Fig. 10, that image has been selected for the nal report. (3) Selecting waveforms. The waveforms are displayed at the bottom of the GUI (Fig. 10). They can be 123 121Int J CARS Fig. 9 A mock-up example of the Intra-Op live display as seen on the Intra-Op large monitor in OR. Top row from lefttoright video stream of vital signs andsix waveforms coming fromthree vital signs, BIS and IVF;thehorizontal axis is time. Middle row from lefttoright waveform of EMG, endoscopicimage and fluoroscopic image.Bottom row laser output values dynamically selected by clicking their corresponding boxes on the upper right side of the interface. (4) Data synchronization. A slider at the bottom of the graph (green pointer in Fig. 10) would allow for synchronized viewing of all the image and waveform data being dis-played. The data that was displayed and selected for documentationin Fig. 10includes a C-Arm fluoroscopic X-ray image, heart rate, diastole and systole blood pressures, respiratory rate,BIS score value, oxygen pressure and partial pressure of car-bon dioxide. The curve shown at the bottom of Fig. 10(heart rate) is a waveform obtained from another Intra-Op device. Figure 10shown contains real-patient data with anonymized acquisition date and time and patient demographics. Nurses and Front-desk personnel perform surveys several times after the surgery and enter the pain surveys data into the Post-Op module of the ePR system as a follow-up of theprogress of the patient. The collective information can be used for future patient outcome analysis. Results Clinical site for developing and implementing the minimally invasive spinal surgery ePR system The design and implementation has been in collaboration with the California Spinal Institute (CSI), Thousand Oaks, CA. CSI is a full self-sufcient independent spinal surgery institute and performs between 5 and 10 minimally invasivespinal surgeries per week. It has its own diagnostic imag- ing facility including conventional X-rays, CT and MRI ser- vices and a commercial PACS. CSI also provides patientswith the full in-house services for spinal surgery from Pre-Op consultation to Post-OP evaluation, check-up and therapy.The concept of developing the multimedia ePR system forimage-assisted Minimally Invasive Spinal Surgery was con- ceived 5 years ago but technologies were not available until recently [9]. The go head development decision was made inearly 2007. Many parameters used in the design were based on daily clinical experiences at CSI during the past 5 years. The ePRsystem can be modied for Minimally Invasive Spinal Sur-gery operation at other similar healthcare facilities, and image-guided surgery ORs (operation room). System deployment The prototype system was deployed in August 2008 to the California Spine Institute (CSI) located in Thousand Oaks, California, which is the only clinical site in Southern California that performs Minimally Invasive Spinal Surgery.This site served as an initial approach to understand the gen- eral workflow of the surgical procedure. Because the goal of the system is to be able of being installed in other locations,the workflow and implementation was kept in its more gen- eral instance, avoiding any specic-related design for CSI. In the case that a particular part of the implementation wastailored for this site, the options were congured to be flexi-ble. The customization of the modules used in the ePR will allow having the system implemented in different locations where other vendors are used. This section summarizes the highlights. Planning and design phase The ePR system for minimally invasive spinal surgery was developed at the IPILab, USC.IPILab and CSI have had close collaboration for more than5 years. There are three phases of the implementation. First, 123 122Int J CARS Fig. 10 The Post-Op authoring module displaying a patient case show- ing data acquired during the surgery. The xaxis represent the time, while the yaxis represent the numerical value of the data points. The green mark represents the time frame when this page was captured. Thismodule can be utilized by the surgeon to create an image and waveform Post-Op results document in pdf format. The graph showed at the bot- tomis the sequence of respiratory rate values over the whole procedure time to test the functionality of the ePR system, a prototype for each of the ePR components was developed and integrated atthe CSI research facility; in addition, mockup data was col- lected at CSI that included an Intra-Op signal simulator for the IU device. Second, once the system was tested fully in thelaboratory environment, it was then deployed in the OR to obtain user feedback and clinical evaluation. The hardware and software components consist of the Gateway Server, theePR server, and the IU. In addition, other software packages include the ePR web pages, the IU application, the database, and the web server. The nal stage of the clinical implementation was to deploy the ePR system in the OR. This stage has been chal- lenging, since the OR is continuous in use for minimally invasive spinal surgery, both the clinical team and the engi-neering team have to work together to circumvent the clinical schedule minimizing the risk of any possible disruption of the clinical service through coordinating of various tasks amongthe teams member; this is especially true in the nal stage of implementation, when the ePR has actually been used taking care of some regular duties usually reserved by the traditionalsurgical method. Hardware installation The ePR and Gateway servers were installed at CSI on a rack at their Server Room. Figure 11 shows the installation in progress and the nal location of those servers.In addition to the two servers above, the IU was also installed in one of the ORs at CSI. The IU needs to be con-nected to all required peripheral devices that are presented in the OR for monitoring the real-time patients' response dur- ing the clinical procedure. The IU, located in the OR, and itsconnection to input devices are shown in Fig. 12. Software installation Once the servers were installed at the clinical facility, the next step was to congure all necessary software components of the ePR system. Those components include: (1) ePR server . The server requires the installation of the web server (Apache) and the database (MySQL). (2) Gateway server. Composed of a software DICOM lis-tener that receives incoming DICOM studies sent fromthe PACS and a set of scripts to extract the metadata information and store it at the database. (3) Integration unit . Software developed in C++ is utilized to make low level system calls to the different interfacesdepending on performance requirements to display real- time data in the OR. Training and support for clinical users The following users were among those trained for the use of the ePR system: (1) Surgeons. They received training on the Pre- and Post-Op authoring modules. In addition, they were taught to 123 123Int J CARS Fig. 11 The ePR Server installation at the server room of CSI. J. Documet was installing the servers Fig. 12 Integration unit (IU, leftinside the red ring ) installed in the OR connected to differentinput sources (middle input units cables are connected to the backof the IU; right vital Signs device is being connected) properly interpret the two large Pre-OP and Intra-Op LCD displays. (2) Physician assistants. They were involved in both groupand individual training sessions for Pre-Op authoringmodule. (3) Nurses. They were trained to properly enter informa- tion related to the patient's whiteboard data and survey forms. (4) Front-desk assistants. They received training for sched- uling of surgical procedures, input of pain surveys for Pre-Op and Post-Op Phases as well as patient registra-tion. (5) Technicians . The training given to them was on how to correctly understand the data presented at the LCDmonitor displays at the OR. (6) Administrative staff. They were given training on how to add or remove a user from the ePR system and to manage the permissions for the different user types ora specic user as well. The engineering team provided 3 months on-site baby-sit- ting of the ePR system as well as assisted the duty staff toprepare Pre-Op module. Figure 13shows a typical training session. Clinical Implementation of the Post-Op module is currently ongoing. Clinical implementation experiences (1) The implementation phases were planned based accord- ingly on the three workflow stages to provide a good understanding of the features included in the ePRSystem and at the same time to address any positivefeedback from the users. Phase one implementation was included the Pre-Op authoring and display toolkit as well as general ePR features such as worklist navi-gation and DICOM Query/Retrieve. Phase two imple-mentation included the Intra-Op display as well as the Pre-Op display on large LCD monitors. Finally, phase three included the Post-Op authoring and display toolkitand is currently undergoing training sessions. Since the ePR System was installed in August 2008 at CSI, every surgical operation has utilized the Pre-OpDisplay module within the OR. This is a direct result of the clinical staff performing the Pre-Op authoring one day prior to surgery. In the same amount of time, theIntra-Op live display has been used to show a centralizedview of all the data obtained from peripheral devices. Data captured from the IU module is currently stored in the ePR System automatically since May 2009. (2) Even though there was no formal evaluation from the users' training, all the people that were trained had beenusing the ePR with no major complaints. After a 1-yearclinical operation with sufcient and meaningful data collected, a more formal user acceptance survey will be conducted targeted for a follow-up clinical experiencepaper. (3) The chief surgeon who is one of the architects of this system has monthly meeting with the ePR team to pro-vide suggestions, input and user experience for systemrenement and upgrades. He has been the champion of the project. 123 124Int J CARS Fig. 13 Group training in Pre-Op authoring at the consultation room Next steps in research and development Prototype version 2 for integration unit. The integration unit (IU) is a very critical component in the ePR system, but at the same time is very complex and needs to be rened to satisfy the ePR System requirements. The prototype version2 of the IU has been designed to provide continuous avail- ability, improve the performance for data collection, visu- alization and storage with expanded flexibility in order tosupport a larger set of devices and congurations. Difference between current version and the version 2 of the integration unit. The main difference between the two ver- sions of the Integration Unit is the capability of handling faulttolerance and continuous availability: the rst prototype of the IU did not provide any fault tolerance. The second pro- totype provides fault tolerance by adding a second set of keypieces from the IU. This is similar to what have been done to the PACS [12]. Among the pieces added are: more robust UPS (uninterruptible power supply); NAS (network attachedstorage) for storage; the main processing unit is provided by means of two identical clustered blade servers. In case of any failover the recovery is done automatically. In addition,the second prototype is assembled in a self-contained mobilecart that enhances the flexibility for implementation in dif- ferent environments. At the same time the second prototype has increased the number of ports to include more peripheraldevices present in the operating room. The software that acquires, displays, and stores the data also requires an update to handle the new infrastructure forthe second prototype. Upon completion of the second proto- type, one copy will replace the existing rst prototype within CSI and the second copy will be deployed at a second clinicalsite to be determined.Discussion Lessons learned Much of the experience gained and many lessons learned in developing the multimedia ePR for image-assisted min-imally invasive spinal surgery are similar to that of early times when PACS was developed and deployed in radiology departments, and later to hospitals. However, there are somedifferences due to the fact that ePR users are mostly local and not hospital-wide. Among these, are listed in the following as well as any comments on the differences and similaritiesbetween them whenever appropriate. (1) Lack of standards from peripheral data and imagingdevices used in the OR. This was the major obstacle dur- ing the implementation phase. There are many vendors who sell peripheral devices to ORs where no data formator communication standard compliance is required. Dif- ferent vendors export their data in different ways, add- ing complexity to the mechanisms for data retrieval andlimiting the interoperability to certain vendors and prod-ucts. In imaging, most ORs still use Pre-Op hardcopy for reference during the surgery. the Intra-Op endoscopic and C-Arm radiographicimages are for assisting the surgeon during the surgery, and there is no requirement for keeping hard or soft cop- ies for surgical document. The multimedia ePR systemfor minimally invasive spinal surgery, on the other hand, keeps all live data during the surgery in the database, they will be selected by the surgeon to include in thepatient report during Post-Op authoring. Therefore, ithad been a major challenge for acquiring data from real- time peripheral devices as well as images from endo- scope and C-Arm radiography in the OR during surgery.In PACS installation, similar problems were encoun- tered in imaging modalities connectivity, but this issue was resolved by the mandated compliance to DICOMstandard in almost all the purchases in imaging systems and PACS in the late 1990s. The development of the Integration Unit (IU) in the ePR system prototype is therst step allowing all devices to be integrated. We antic-ipate several years down the road, surgical OR may see the advantages of data integration in the ePR and enforce vendors to output data with certain standards. (2) The clinical environment was different from the labora- tory environment. When the ePR prototype was moved from the laboratory environment to the clinical site, the engineering team encountered a culture shock. In the former, the laboratory environment was under control and debugging and modications could be performedeasily. Whereas in the latter, the reality of the real world 123 125Int J CARS sank in, and it was very difcult to make modications for two reasons: (1) once the ePR was installed, the clin-ical use of the system has always been with the highest priority, any modications were secondary, (2) users were reluctant to continuously adopting new changes.Unlike PACS installation which has long passed thisR&D mode, nowadays a prototype system would be rarely installed in the clinical site without extensive test at the manufacturer site rst. (3) The clinical institution was not always in control of its computer and ICT (information and communica- tion technology) equipment . Installing new applications in clinical computers might sometimes require admin- istrative privileges. In addition, conguring and add- ing new servers to CSI might need to be performedby a third party IT (information technology) team thatcould cause implementation issues. This issue would be encountered in many PACS installation as well. (4) User acceptance. Whenever a new application in the ePR was implemented at CSI, users might be reluctantto fully embrace the new application. It is because it would temporarily disrupt their normal routine clinicalworkflow even if the system would ultimately improve their clinical workflow in the long run. The user accep- tance is easier in PACS now since the healthcare com-munity has gained more than 15 years of experience. (5) Graphical user interface challenging for new users . When a new application was developed, trainingbecomes crucial since users were not familiar with theinterface and functionality. This issue is 100% the same as PACS when the user is rst time or switches to a new PACS, or a new GUI is installed. Design principles and reproducibility (1) The design principle. The design principles of the ePR system are modularity and reproducibility. The system has three major components, Pre-Op, Intra-Op, andPost-Op, they are operated as a complete system. In order for the Post-Op to function properly, both Pre-Op and Intra-Op have to be operable. In the same token,in order for the Intra-Op to be functional, Pre-Op hasto be operable. However, Pre-Op can be used without the Intra-Op and Post-Op in operation. In this case, no data from the Pre-Op would be input to the Intra-Opand Post-Op modules. (2) Reproducibility. The infrastructure applicable to most image-assisted minimally invasivesurgical operation rooms. However, certain customiza- tion may be required. For example, different surgical input including images, waveforms and textual data mayneed new designs for various input device interfaces.The Integration unit (IU) infrastructure has been testedto handle up to a combined total of 12 waveforms datapoints, imaging inputs and video streaming sources. In addition, the Display format and GUI need to be rede- signed to suit various surgical requirements. Conclusion A step-by-step approach was introduced to develop a multi- media ePR system for imaging-assisted minimally invasivespinal surgery. First, the clinical need for the Minimally Inva-sive Spinal Surgery ePR was introduced. Then, the three clinical phases of minimally invasive spinal surgery work- flow in Pre-Op, Intra-Op, and Post-Op were discussed. Thethree-phased modules; and the four components: the input integration unit, fault-tolerant gateway server, fault-tolerant ePR server, and the visualization and display component.A prototype was built and deployed to a Minimally Invasive Spinal Surgery clinical site with user training and support for daily use. Finally, special experience gained and lessonslearned from developing the system were discussed. Thismethodology can be extended to other image-assisted mini- mally invasive surgery. References 1. Vallfors B (1985) Acute, subacute and chronic low back pain: clin- ical symptoms, absenteeism and working environment. Scan J Rehab Med Suppl 11:1-98 2. Chiu J, Savitz MH (2005) Use of laser in minimally invasive spinal surgery and pain management. In: Kambin P (ed) Arthroscopic andendoscopic spinal edn, Humana Press,New Jersey, pp 259-269 3. Chiu J (2004) Anterior endoscopic cervical microdiscectomy. In: Kim D, Fessler R, Regan J (eds) Endoscopic spine surgery andinstrumentation, vol 5. Thieme Medical Publisher, New York, pp48-58 4. Chiu J (2004) Endoscopic lumbar foraminoplasty. In: Kim D, Fess- ler R, Regan J (eds) Endoscopic spine surgery and instrumentation,Chap 19, Thieme Medical Publisher New York, pp 212-229 5. Chiu J, Clifford T, Greenspan M (2000) Percutaneous microde- compressive endoscopic cervical discectomy with laser JW, Ryken TC, Vanier MW (2001) Image-guided surgery of the spine. J Min Invasive Spinal Tech 1(1):87-92 7. Jaikumar S, Kim D, Kam A (2002) History of minimally invasive spine surgery. Neurosurg Supp 2002 5(2):1-14 8. Huang HK (2004) PACS and imaging informatics: principles and applications. Wiley, Hoboken, p 704 9. Huang HK (2001) PACS, informatics, and the neurosurgery com- mand module. J Mini Invasive Spinal Tech 1:62-67 10. MySQL AB, Sun Solaris Microsystems Inc. http://dev.mysql.org 11. Apache web server, Apache software foundation http://httpd. apache.org 12. Liu BJ, Huang HK, Cao F, Zhou MZ, Zhang J, Mogel G (2004) A complete continuous-availability (CA) PACS archive serversolution. Radiographics 24(4):1203-1209 123 126Note: This copy is for your personal, non-commercial use only. To order presentation-ready copies for distribution to your colleagues, use the RadioGraphics Reprints form at the end of this article. 961 INFORMATICS Maria Y . Y . Law, PhD Brent Liu, PhD Lawrence W . Chan, PhD Comprehensive clinical imaging data and additional relevant informa- tion are crucial for the planning and delivery of radiation therapy in patients with cancer. Multiple stand-alone systems that make use of technologic advances in imaging, treatment planning, and treatment delivery acquire or generate key data during the course of radiation therapy. However, the data are scattered in various systems through-out the radiation therapy department, thereby compromising effi-cient clinical work flow. In 1997 and 1999, the Digital Imaging and Communications in Medicine (DICOM) standard was extended from radiology to radiation therapy with the ratification of seven DICOM-RT objects. These objects helped set the standard for (a) data integra-tion and interoperability between radiation therapy equipment and information systems from different manufacturers, and (b) the use of DICOM diagnostic images in radiation therapy. More recently, key radiation therapy imaging and informatics data have been integrated to form an open-architecture comprehensive radiation therapy elec-tronic patient record (ePR) system. The benefits of such a DICOM-RT-based ePR system are threefold: it can be used as a foundation for performing effective and efficient clinical services, as a common platform for radiation therapy data exchange and expert consultation, and for medical imaging informatics research in developing innovative decision support tools and a knowledge base for improved treatment with radiation therapy. \u00a9RSNA, 2009 radiographics.rsnajnls.orgInformatics in Radiology DICOM-RT-based Electronic Patient Record Information System for Radiation Therapy 1 Abbreviations: DICOM = Digital Imaging and Communications in Medicine, ePR = electronic patient record, GUI = graphical user interface, IHE = Integrating the Healthcare Enterprise, PACS = picture archiving and communications system, TPS = treatment planning system RadioGraphics 2009; 29:961-972 Published online 10.1148/rg.294085073 Content Codes: 1From the Department of Health Technology and Informatics, Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong (M.Y .Y .L., L.W .C.); and Image Processing and Informatics Laboratory, Keck School of Medicine, University of Southern California at Health Sciences Campus, Los Angeles, Calif (B.L.). Presented as an education exhibit at the 2006 RSNA Annual Meeting. Received March 27, 2008; revision re - quested September 16; final revision received January 6, 2009; accepted January 22. All authors have no financial relationships to disclose. Address correspondence to M.Y .Y .L. (e-mail: July-August 2009 Introduction With advances in technology allowing more ac- curate treatment and better patient care, more and more images are being generated and used in radiation therapy, which is becoming increasingly image intensive. Comprehensive clinical imaging data and relevant information in radiation thera-py are crucial for treatment planning and delivery in patients with cancer. Radiation therapy makes use of some of the greatest technologic advances in diagnostic imaging, image processing, thera-peutic radiation, and computerization in this con-text. All of these advances add to the complexity of the collection and navigation of pertinent ra-diation therapy data. Currently in many radiation therapy departments, radiation oncologists need to go to dedicated workstations to approve treat-ment plans or portal images, and radiation thera-pists cannot view the patient's treatment plan or other images at the treatment workstation. Patient data generated during a course of treat-ment reside at the individual system or worksta-tion where they are used, and thus are scattered (1). The data may be \"integrated\" through the hard-copy patient folder or film images; however, the data crucial for a clinical decision may be re-source intensive and time-consuming to retrieve, temporarily missing, or even lost. All of these is-sues compromise efficient clinical work flow. One potential way of addressing these issues is to view radiology as setting the precedent in terms of its adoption of the DICOM (Digital Imaging and Communications in Medicine) imaging standard, which has led to the successful development and utilization of picture archiving and communica-tion systems (PACS) (2). The PACS has become an indispensable inte- grated imaging system in radiology and hospital operations. The field of radiation therapy has benefited from the PACS and the DICOM stan-dard by making use of clinical images from radi-ology (3). However, the real benefit to a radiation therapy department is the extension of the expe-rience and knowledge gained from integration of the PACS and different modalities to the various sources of clinical data dispersed throughout the department. A system integration infrastructure based on standards is crucial for streamlining clinical work flow and for the establishment of medical informatics research related to outcomes for future radiation therapy patients. In 1997 and 1999, the DICOM standard was extended from radiology to radiation therapy with the ratifica-tion of seven DICOM-RT objects (4-8), thereby making a patient-centric integrated solution such as an electronic patient record (ePR) system fea-sible. A DICOM-RT-based ePR system would be an effective and efficient \"one-stop\" source for tracking the treatment progress of cancer patients by integrating data from the various sources and presenting them in a graphical user interface (GUI) that is designed for ease of use. Such a system would also provide a foundation of standardized data objects, with which to build a knowledge base, and data mining tools for future clinical decision support and outcome analysis. To date, the implementation of a DICOM- RT-based ePR system has been hindered by the complex clinical work flow and data in radiation therapy; insufficient information technology ex-pertise in radiation therapy-related applications; and the scarcity of manufacturers in radiation therapy, each of whom is competing to be the major or sole provider. Although several manu-facturers have tried to develop a more compre-hensive radiation therapy information system, most of these systems have been intended for implementation with a single source vendor's equipment, and their interoperability with other vendors' equipment is at times doubtful. In this article, we review the work flow in radiation therapy; discuss and illustrate the functions and benefits of a DICOM-RT-based ePR system; and describe the development of such a system in terms of system design, implementation, testing, and evaluation. Radiation Therapy Work Flow Radiology work flow mainly involves the genera-tion of images and reports, whereas radiation therapy work flow deals with much more infor-mation of different types over a much longer time span. To facilitate an understanding of the need for and benefits of an ePR system, the work flow for a patient with prostate cancer is shown in Figure 1. Radiation therapy work flow generally consists of two stages: treatment planning and treatment delivery. Radiation treatment planning may require a few patient visits for the acquisition of images, such as the planning computed tomographic (CT) scans or magnetic resonance (MR) im-ages and the treatment simulation image. The 128RG Volume 29 Number 4 Law et al 963 CT scans or MR images will be transferred to the TPS for treatment field and dosimetric plan-ning. This leads to the generation of DICOM objects such as the DICOM diagnostic images, RT Image, RT Structure Set, and RT Plan with or without RT Dose (Fig 1, steps 3-17). The work flow involves the participation of radiation therapists, dosimetrists or medical physicists, and radiation oncologists. Radiation treatment can last for several weeks, during which time verification of treatment is performed on several occasions with the acquisi-tion of portal images. This leads to the generation of RT Beams Treatment Record, RT Treatment Summary Record, and RT Image (when portal imaging is performed) (Fig 1, steps 18-29). The radiation treatment is delivered by the radiation therapist. Approval of treatment plans (Fig 1, step 13), signing of the prescription for radiation treatment (Fig 1, step 15), and approval of veri-fication on the basis of portal imaging findings (Fig 1, step 24) are all performed by the radiation oncologist, who will also review the case on a weekly basis during the course of treatment (Fig 1, step 27) and at later follow-up visits (Fig 1, step 30). This would necessitate referencing the patient's record, including the treatment plan, images, and treatment records. Figure 1. Chart illustrates the radiation therapy work flow for a patient with prostate cancer. The work flow consists of two stages, treatment plan-ning (steps 1-18) and treat-ment delivery (steps 19-30), and is broken down into steps that can be used to evaluate the efficiency of the system once it is implemented. The work flow starts when the ra-diation oncologist decides at consultation that the patient is to receive radiation treatment (step 2). Gray boxes indicate steps that are performed by the radiation oncologist. Of these steps, steps 9 and 13 are incorporated into the treat-ment planning system (TPS) in most cases, but steps 15, 24, 27, and 30 either require hard-copy records or radia-tion therapy information that may not be readily accessible. DRR = digitally reconstructed radiograph, DVH assurance. 2009 radiographics.rsnajnls.org Functions and Benefits of a DICOM-RT-based ePR System Functions Figure 3 illustrates the treatment plan for the pa- tient with prostate cancer (cf Fig 2), with isodose curves overlaid on the patient's CT scans. Figure 4 provides a detailed depiction of the setup of the treatment fields. By reviewing the treatment plan (and the details of the treatment fields) from the ePR system, the radiation oncologist was able to prescribe the radiation treatment without having to go to the treatment planning room. Note that data generated by radiation therapy equipment from different manufacturers at different steps can be integrated into a single ePR system and reviewed at one workstation. The patient's treatment sessions were then scheduled in the treatment management system and transferred to the treatment unit. On the first In the current clinical environment, a patient's information is stored at the workstations or sys-tems where they are generated, in electronic for-mat or even as hard copies (Fig 1). Consequently, the oncologist at the clinic is unable to access any of the appropriate radiation therapy treatment plans or images except the hard-copy treatment record. On the other hand, with an ePR inte-grated system, all information about the patient could be accessed from a single source. Figure 2 illustrates a timeline overview of the ePR for a 52-year-old man undergoing radiation therapy. Every time a new or repeat procedure is per-formed, a new object is created, with the study date as one of its essential attributes. The radia-tion therapy information is displayed in a time se-quence, which can function as a summary of the patient's visits and the procedures performed. Figure 2. Screen shot of a World Wide Web client application page from the DICOM-RT-based ePR system prototype illustrates the timeline overview of the ePR for a 52-year-old man undergoing radia-tion therapy. In this case, CT was performed on June 11 and the CT scans transferred to the TPS, a dosi-metric plan was completed on June 20, a digitally reconstructed radio-graph (DRR) was generated on June 21, and a portal image was obtained on June 26, at which point treatment was initiated. Six radiation treat-ments were delivered, on June 26-29 and July 1-2, and are numbered consecutively so that the number of treatments can be seen at a glance. In addition, key data extracted from some of the DICOM-RT objects are displayed as thumbnail images for the user to select and review in greater detail using the Web cli-ent application. In Review Update (lower left), the oncologist indicates whether to continue treatment. There is also an area of free text (bottom) where the oncologist can input comments or prescribe drugs or care. Brachy = brachytherapy, MR = magnetic resonance, Sim = simulator. 130RG Volume 29 Number 4 Law et al 965 Figure 3. Screen shot (same patient as in Fig 2) illustrates the radiation dose distribution against a set of planning CT scans obtained at different levels of the pelvis. The isodense lines are decoded from the RT Dose object and are displayed with reference to the CT scans. The tumor (red) and the organs at risk (bladder [anterior to the tumor, shown in blue] and rectum [poster-ior to the tumor]) are decoded from the RT Structure object. All of these structures are overlaid on the plan-ning CT scans and can be viewed together as a whole. Figure 4. Screen shot (same patient as in Fig 2) illustrates a detailed prescription and plan for the radiation field. The data are extracted from the RT Plan ob-ject produced by a manufacturer's information system and are used for treatment setup at the linear accelerator. 131966 July-August 2009 radiographics.rsnajnls.org portal film images, and compare treatment im- ages with diagnostic images to monitor treatment progress. The most important point to be gleaned from Figures 2-5, which illustrate how the ePR system is integrated with the radiation therapy work flow shown in Figure 1, is that all pertinent imaging and informatics data needed for decision making during radiation therapy are available in a single integrated system and are standardized in DICOM-RT format. The DICOM-RT-based ePR system, besides integrating all relevant local data into a single sys-tem, can enhance patient care by accepting treat-ment planning information from other clinical centers for real-time expert consultation. It can also serve as a common platform for cross-center clinical research in radiation therapy, since the data are now standardized in DICOM-RT for-mat. The efficient and coherent collection of dose distribution images and dose-volume histograms generated by the TPS could pave the way for large-scale analysis of normal tissue toxicity and evaluation of treatment outcomes. Development of a DICOM-RT-based ePR System The mission of the ePR system is to allow all ra-diation therapy-related information on a patient to be viewed within a single system; that is, the pertinent imaging and informatics data (includ-ing treatment plans, graphs, images, records, and clinician remarks) can be integrated from different radiation therapy sources to form an ePR with the data standardized in DICOM-RT day of treatment (and weekly thereafter), portal images of the treatment fields were obtained at the linear accelerator for comparison with the reference images (digitally reconstructed radio-graphs) to verify the accuracy of setup (Fig 5). The radiation oncologist indicated approval by clicking on a button marked \"Approved,\" after which treatment was begun. Benefits Current radiation therapy information and man-agement systems or record-and-verify systems may contain some of the DICOM-RT data. However, an ePR system is comprehensive and more robust because it presents the entire gamut of DICOM-RT data objects in a timeline format for navigation and review of both historical and new treatment data for the cancer patient. With this system, all radiation therapy information can be reviewed at any client workstation. Because all radiation therapy-related information on the patient can be accessed and viewed from a single ePR system, the system can improve the work flow of the radiation therapy department by pro-viding a one-stop source for viewing the data dur-ing work flow steps such as chart rounds, portal image checks, and on-treatment visits, which data currently need to be viewed by means of various stand-alone systems and paper-based folders. In addition, by using this prototype ePR system, the oncologist can approve plans, review and approve Figure 5. Screen shot (same patient as in Fig 2) illustrates how comparison of the reference image with the electronic portal image is used to verify the treatment field. The reference image (digitally re-constructed radiograph) was gener-ated from the CT scan as an RT Image object, and the electronic portal image (also an RT Image object) was obtained at the linear accelerator. The results can then be stored in the ePR database and displayed for review. Note the \"Approved\" button, which allows the radiation oncologist to indicate his or her approval. Teaching Point 132RG Volume 29 Number 4 Law et al 967 the design of the GUI. This initial stage of system design provides the conceptual model for the sys-tem and requires detailed input from clinicians. The next step is the architectural design of the data flow through the various components of the ePR system and the physical data model for central storage (the DICOM-RT archive server). Given the DICOM standard with its information object definitions defined for radiation therapy, the development of the physical data model could be similar to that of the PACS, the architecture of which could be used for the DICOM-RT-based ePR system. PACS as a Model for Architectural Design.\u2014A PACS consists of imaging modali-ties that generate images, an acquisition gateway, a PACS server-archive, and display subsystems, all of which are integrated by a network as shown in Figure 6 (2). format. System development involves system design, implementation, testing, and evaluation (9-11), all of which are described in the following paragraphs. System Design System design consists of work flow and needs analysis and the basic architectural design of the system. The process starts with the analysis of the work flow functions, from which the needs and requirements of the users (radiation oncologists, medical physicists, and radiation therapists) are defined. For example, after a dosimetric plan has been generated, the radiation oncologist needs to approve the plan. The system designer should create a route whereby the radiation oncologist can access the system to perform such a task. In addition, the data on treatment planning and delivery are best visualized in a timeline format, along with the patient's demographic informa-tion. All pertinent events and tasks should be listed, and the framework should be drafted for Figure 6. Top diagram illustrates PACS data flow and the key PACS compo- nents that are currently being used successfully as part of the radiology work flow. Note that the Web server is used mostly for the review of radiologic studies for the referring physician. Bottom diagram illustrates DICOM-RT-based ePR sys-tem data flow and components. Most of the radiation therapy components follow the PACS data model (modules 1, 2, and 3 correspond to Imaging Modalities, Acquisition Gateway, and PACS Server, respectively) due to similarities in the use of the DICOM data model. The ePR system platform is used to extract informa-tion from the DICOM-RT archive server to develop the Web-based ePR system. Note that the RT Web application server (see Fig 8) is more complex than the Web server used in the PACS data model, since the radiation therapy data contain more complex imaging and informatics data objects, whereas the PACS Web server con-tains only diagnostic imaging studies and reports. In addition, there are different Web application pages within the Web client workstations (WS) that are used in the department by oncologists, radiation therapists, and medical physicists based on their different needs. Teaching Point 133968 July-August 2009 radiographics.rsnajnls.org RT Archive Server.\u2014A database schema for the DICOM-RT archive server (Fig 6, module 3) can be constructed by following the pattern for the DICOM hierarchic structure. The schema consists of four levels\u2014Patient, Study, Series, and RT Objects\u2014and 11 modules (12,13), rep-resented by the boxes in Figure 7. The schema follows the DICOM data model of the real world but includes the seven DICOM-RT data objects and the DICOM diagnostic images. It is im-portant to note that most current PACS do not support DICOM-RT objects (except DICOM-RT Image); hence, it is necessary to have a more highly developed schema specifically for a DICOM-RT archive server. PACS manufacturers can begin to incorporate the DICOM-RT objects to turn their PACS server into a DICOM-RT ar-chive server. For the archive server, a SUN Ultra 2 comput- er (Sun Microsystems, Santa Clara, Calif) with SCSI (small computer system interface) hard disk and 100-Mbyte Ethernet adapter operating under SunOS 5.8 was used. The software includ-ed SUN Workshop Compilers CC++, a PACS programming library, and an Oracle8i release 8.1.7 database management system. The archive server is used mostly for the management and storage of objects rather than for processing the radiation therapy data (attributes) encapsulated in the objects. Upon receiving DICOM-RT ob-jects and images from DICOM-RT Gateway, the archive server abstracts only the essential aspects of these entities for the necessary transactions and \"autoroutes\" all the data to the Web applica-tion server to be processed for display on the Web client application. RT Web Application Server.\u2014Whereas the DICOM-RT archive server is responsible for storage and transmission of DICOM images and DICOM-RT objects, the RT Web application server (Fig 6, module 4 ) receives the objects, de- codes them to the corresponding position in the RT Web application database, and organizes the data into the Web viewing mode for display on the client workstations (Fig 8). In this respect, the Web application server is the \"brain\" for the DICOM-RT-based ePR system, since all actions are pro-cessed here. Microsoft Access 2000 (Microsoft, Redmond, Wash) was used as the database for the application server. Windows Internet Information Server (Microsoft) was used for distribution of radiation therapy information, and the data were sent using hypertext transfer protocol.extensions of the DICOM standard, so that the data model and the data flow of the PACS can serve as a guide for the design of the radia-tion therapy data flow as shown in Figure 6 (9). Likewise, the DICOM-RT-based ePR system will receive data input from different radiation therapy information systems and equipment. These data will be integrated through DICOM-RT Gateway with the archive server to form the ePR system. Figure 6 illustrates the similarities and differ- ences between a PACS and the DICOM-RT-based ePR system. The latter is patterned after the generic PACS data flow design and consists of DICOM-RT Objects Input, DICOM-RT Gateway, and the DICOM-RT-based ePR sys-tem platform. The system platform in turn con-sists of three major components: the DICOM-RT archive server, the RT Web application server, and the Web-based client workstations. These three components correspond to the archive serv-er, the Web server, and the review workstations in a PACS (Fig 6). The specific differences are in the design of the RT Web application server, which must handle more complex imaging and informatics data than a Web server for a PACS. The major components of the DICOM-RT-based ePR system are described in the following paragraphs. DICOM-RT Objects Input and DICOM-RT Gateway.\u2014From the work flow diagram in Figure 1, the radiation therapy objects are identi-fied and are input into the ePR system (Fig 6, module 1) through DICOM-RT Gateway (Fig 6, module 2). The functional requirements (eg, treatment plan approval by the radiation oncolo-gist) in the work flow review are converted into the technical details of the system based on the DICOM-RT information object definitions and the data flow of the objects. The DICOM stan-dard service classes (eg, DICOM storage and query-retrieve) are incorporated into each com-ponent of the ePR system. After receiving the radiation therapy objects, the gateway extracts information from the objects and puts them into the radiation therapy data model as required in the DICOM-RT archive server. It also converts any nonstandard data objects to the standard re-quired by the DICOM-RT server. Teaching Pointin Figure 6 (2). The DICOM-RT objects are 134RG Volume 29 Number 4 Law et al 969 Figure 8. Diagram illustrates the architecture of the RT Web applica- tion server of the DICOM-RT-based ePR system. Six key components are shown within the server, which is more complex than a PACS Web server in that it must handle the image and informatics data from the seven DICOM-RT objects in addition to the DICOM images from diagnostic radiology. DICOM-RT objects and DICOM diagnostic images are received by Service Class Provider (SCP) Object Receiver (1), the objects are decoded by the decoder (2), and the data are arranged in RT Tables and the RT Database (3). The data from the tables will be superimposed on the corresponding por-tions of the DICOM images by the RT Converter (4) and sent by the Web server (5) to the client workstations. Service Class User (SCU) Object Sender (6) allows updated objects to be sent to the DICOM-RT archive server via the gateway for storage. HTTP = hypertext transfer protocol, IIS = Internet Information Server.Figure 7. Schematic illustrates the DICOM-RT archive server database. The schema is based on the DICOM data model of the real world. Note that the seven DICOM-RT objects (gray boxes) are inte-grated within the Series (Modality) module, along with the Diagnostic Image object (white box, lower left). In other words, each object is grouped under the attribute \"mo-dality\" in the \"series\" similar to the modality of CT or MR imaging (8). Brachy = brachytherapy. 135970 July-August 2009 radiographics.rsnajnls.org displays are created by plotting coordinates onto the referenced diagnostic CT scan. The data objects from the Web-based applica- tion can be used to develop quantified knowledge and metadata that can be added to the database schema. Further outcomes data can also be added to the overall database schema. Therefore, it is important to design the database schema to be as flexible as possible to allow the addition of a knowledge base and outcomes data that are not part of the DICOM standard. RT Web Client Workstation. \u2014For the RT Web client workstations (Fig 6, module 5), the GUI is designed for users to access information within the database according to the functional require-ments of radiation therapists, dosimetrists or physicists, and oncologists. On the basis of the user requirements documentation, all necessary data are included in the database tables of the Web application server. The radiation therapy work flow also serves to drive the GUI design (Figs 2-5). System Implementation A laboratory DICOM-RT-based ePR system prototype (Fig 9) was implemented that incorpo-rates the infrastructure and components shown in Figure 6. Note that RT Object Simulator was used to simulate the input of DICOM-RT ob-jects into the system. System Testing Development of the ePR system is subject to many iterative stages of testing, refinement, and evaluation before the system can be implemented in the clinical environment for further evaluation. The transmission of radiation therapy objects through the system was tested manually on an object-by-object basis. The real DICOM-RT objects were tested first. Next, the non-DICOM The DICOM standard has grouped various radiation therapy attributes into modules and information object definitions (6). The overall da-tabase schema of the RT Web application server adopts what is defined by the DICOM data model and consists of 72 tables (in the prototype system) to facilitate Web viewing on the client workstations (12,13). This information includes key data items such as treatment plan param-eters, beam records, isodose curves, region of in-terests (including tumor volume and the contours of organs at risk), dose-volume histograms, and so on. These data are parsed from the DICOM-RT objects as needed for display in the Web client application. For the prototype system, our team designed the Web-based display and database structure at the front end, and the data objects, struc-ture, communication protocol, and encoding-decoding with open standards at the back end. Within the Web application server, the graphical illustrations of (for example) dosimetric plans are created, stored, and displayed in a JPEG (Joint Photographic Experts Group) format. They result from the overlay of the DICOM CT Image, RT Structure Set, RT Plan, and RT Dose objects. The DICOM standard inherently provides cross-referencing among these objects. Decoding-encoding software applications were developed on the basis of the DICOM informa-tion object definitions. When multiple data items are required on a given display (eg, the dosimet-ric plan), the DICOM objects containing the tar-get volumes, contours of the organs at risk, and isodose distribution are decoded to and encoded from the database records of the coordinates in the Web application server based on the defini-tion of the DICOM sequences. These Web-based Figure 9. Photograph illustrates the DICOM-RT-based ePR system prototype. Note that the components corre - spond to the elements of the conceptual diagram in Figure 6. 136RG Volume 29 Number 4 Law et al 971 to view key treatment-related data, the decision maker (eg, the oncologist) can view all related data in one system with one application. The DICOM-RT-based ePR system has to a certain extent demonstrated the interoperability of systems that can output DICOM-compliant information. The prototype was developed on the basis of radiation therapy work flow in daily practice so that the user can view key treatment-related data in one system. A technical framework for implementation of established standards is currently being drafted for radiation oncology to help carry out specific clinical tasks assigned by the Integrating the Healthcare Enterprise (IHE) initiative. It identi-fies subsets of functional components (called \"actors\" [eg, Geometric Planner or Archive]) and specifies their interactions in terms of transac-tions. For example, after creating a geometric plan on the CT scan, the user of the Geometric Planner wants to store the plan, which involves a Geometric Plan Storage transaction. The Geometric Planner sends the newly created geometric plan to the archive for storage (14). The IHE technical framework defines only \"those functions associated with integrating information systems\" and not necessarily the clinical work flow in general. In this sense, the DICOM-RT-based ePR system described in this article is different from the work being done by IHE. However, the IHE technical framework would help smooth out the integration process. Although it is true that the IHE initiative has the greatest impact on work flow efficiency, without the DICOM and HL7 (Health Level 7) standards, the IHE radiology work flow pro-files cannot be realized. Similarly, the challenges that exist in radiation oncology departments are related to stand-alone and proprietary systems with key data elements that are not standardized. The goal is to first standardize the data objects with DICOM-RT, and then begin integrating the DICOM-RT objects into the work flow. In fact, IHE-RO (radiation oncology) has been established to demonstrate the importance of DICOM-RT and work flow profiles for radiation oncology departments. Our radiation therapy ePR system is the first comprehensive step to-ward this goal. These innovations, along with our integrated ePR system, can give impetus to the movement toward full standardization among all manufacturers. In addition, our research and development team has followed these technologic files were translated into a DICOM object prior to evaluation. Each object type was sent through RT Object Simulator. The arrival of the object at the DICOM-RT archive server and then at the RT Web application server was tracked and the date and time of insertion examined. The system has been tested with different types of object sources from four different vendors. These object sources include VARiS Vision (Varian Medical Systems, Palo Alto, Calif); Precise Canada); and Pinnacle 3 (ADAC Laboratories, Milpitas, Calif). At the time of test-ing, not all DICOM-RT objects had been imple-mented by all vendors, especially RT Dose and RT Records. However, we managed to acquire or create all of the objects from various sources. System Evaluation The system has been evaluated on the basis of data from 10 \"virtual patients\" who were created using our data sources. The arrival and integrity of all the data were verified using the GUIs at the Web client workstation. Two radiation therapists and an oncologist were invited to evaluate the system as end-users. They were asked to rate the usefulness of the system and the degree to which it improved patient service. The average rating was 8 out of 10. Suggestions for improvement and further refinement were also collected. The results indicate that the system would be very useful and quite likely to improve patient service. Discussion The prototype system can query-retrieve and receive diagnostic DICOM images from a com-mercial PACS in the same manner as a TPS. As shown in Figure 6, the entire system includes the DICOM-RT gateway, archive server, Web ap-plication server, and client workstations. During current clinical radiation therapy work flow steps, the diagnostic images within the TPS may be altered and images within the series removed, making them unavailable for future review. Our system would contain the entire diagnostic data set in case the oncologist would like to review the studies without having to access the commercial PACS application again to view them. In addi-tion, imaging and informatics data from all the different stand-alone radiation therapy-related systems in the oncology department can be sent to the system with use of the DICOM-RT stan-dard (Fig 6). Therefore, in an ideal situation, rather than moving from one system to another Teaching Point 137972 July-August 2009 radiographics.rsnajnls.org effective and efficient clinical services; (b) as a common platform for radiation therapy data ex-change, expert consultation, and clinical research; and (c) for medical imaging informatics research in developing innovative decision support tools and a knowledge base for improved radiation therapy treatment.References 1. Nagata Y, Okajima K, Murata R, et al. Develop - ment of an integrated radiotherapy network sys- tem. Int J Radiat Oncol Biol 1105-1111. 2. Huang HK. informatics: basic principles and applications. Hoboken, NJ: Wiley-Liss, 2004. 3. Schultheiss TE, Coia LR, Martin EE, Lau HY, Hanks GE. Clinical applications of picture archival and communications systems in radiation oncol-ogy. Semin Radiat Oncol 1997;7(1):39-48. 4. Digital Imaging and Communications in Medicine (DICOM) Supplement 11. Radiotherapy objects. 5. Digital Imaging and Communications in Medicine (DICOM) Supplement 29. Radiotherapy treat-ment record and media extensions. 6. DICOM in radiotherapy. Available at: http:// medical.nema.org/dicom/geninfo/brochure/rtaapm.doc. Accessed March 1, 2007. 7. Digital Imaging and Communications in Medicine (DICOM) Part 3. Information object definitions. Available at: http://medical.nema.org/dicom/2007/. Accessed January 20, 2008. 8. Law MYY, Liu BJ. Informatics in radiology: DI - COM-RT and its utilization in radiation therapy. RadioGraphics 2009 Mar 6 [Epub ahead of print]. 9. Kushniruk A. Evaluation in the design of health information systems: application of approaches emerging from usability engineering. Comput Biol Med 2002;32(3):141-149. 10. Wasson CS. System analysis, design, and develop - ment: concepts, principles, and practices. Hobo-ken, NJ: Wiley, 2006. 11. Dennis A, Wixom BH, Roth RM. Systems analysis and design. 3rd ed. Hoboken, NJ: Wiley, 2006. 12. Law MY . A model of DICOM-based electronic patient record in radiation therapy. Comput Med Imaging Graph 2005;29(2-3):125-136. 13. Law MYY . The design and implementation of a DICOM-based integrated radiotherapy informa-tion system. Thesis. Chinese Academy of Sciences, Beijing, China, 2004. 14. ASTRO. Integrating the Healthcare Enterprise. IHE-Radiation Oncology Technical Framework Volumes 1-2: draft for trial implementation. Avail-able at: http://www.ihe.net/Technical_Framework /upload/IHE_RO_TF_v1.pdf. Accessed August 18, 2007.advances closely, and the system will continue to be updated and refined to adhere to these newly developed IHE-RO work flow profiles once they are officially established. Our system prototype represents a major step forward in that it im-proves integration, since it can both convert pro-prietary data objects from the various stand-alone systems into DICOM-RT objects and receive de-veloped DICOM-RT objects from other systems that have already begun to standardize their data. Conclusions Radiation therapy is an image-intensive treatment method for which the development and system integration of standardized data is similar to that for radiology. For prompt, accurate treatment, it is crucial to pay close attention to every detail in the radiation therapy work flow, which has an im-pact on patient outcomes. By providing compre-hensive and up-to-date medical information, the DICOM-based ePR system can not only improve physician efficiency and the quality of patient care, but also cultivate excellence in the delivery of radiation therapy services. DICOM-RT is the standard used to build an open-architecture DICOM-RT-based ePR system. With the DICOM-RT standard, the ePR system can enhance application interoperability among multivendor modalities, providing a truly open environment for seamless data exchange, so that a radiation therapy department will not be restricted to a single manufacturer's systems. The open architecture based on the DICOM-RT standard also facilitates consultation or clinical research across institutions. The DICOM-RT-based ePR system with standardized radiation therapy data can be leveraged for further research that can be performed to extract and quantify knowledge for decision support tools as well as outcome analysis, ultimately making this system a research and clinical tool that is even more pow-erful than existing clinical methods. In summary, the benefits of a DICOM- RT-based ePR system are threefold: the system can be used (a) as a foundation for performing Teaching Point 138RG Volume 29 Number 4 July-August 2009 Law et al Informatics in Radiology DICOM-RT\u2014based Electronic Patient Record Information System for Radiation Therapy Maria Y. Y. Law, PhD, et al Page 966 The most important point to be gleaned from Figu res 2--5, which illustrate how the ePR system is integrated with the radiation therapy work flow show n in Figure 1, is that all pertinent imaging and informatics data needed for deci sion making during radiation th erapy are available in a single integrated system a nd are standardized in DICOM-RT format. Page 967 System development involves system design , implementation, testing, and evaluation. Pages 968 The DICOM-RT objects are extensio ns of the DICOM standard, so that the data model and the data flow of the PACS can serve as a guide for the design of the radiation therapy data flow as shown in Figure 6 (9). Page 971 [T]he challenges that ex ist in radiation oncology departments are related to stand-alone and proprietary systems with key data el ements that are not st andardized. The goal is to first standardize the data objects with DICOM-RT, and then begin integrating the DICOM-RT objects into the work flow. Page 972 [T]he benefits of a DICOM-RT\u2014based ePR syst em are threefold: the system can be used (a) as a foundation for performing effectiv e and efficient clinical services; (b) as a common platform for radiation therapy data exchange, expert consultation, and clinical research; and (c) for medical imaging informatics research in developing innovative decision su pport tools and a knowledge base for improved radiation therapy treatment. RadioGraphics 2009; 29:961-972 Published online 10.1148/rg.294085073 Content Codes: 139Note: This copy is for your personal, non-commercial use only. To order presentation-ready copies for distribution to your colleagues, use the RadioGraphics Reprints form at the end of this article. 655 INFORMATICS Maria Y . Y. Law, PhD Brent Liu, PhD The Digital Imaging and Communications in Medicine (DICOM) standard is now widely implemented in radiology as the standard for diagnostic imaging. It has also been extended for use in various sub-specialties. One of the first extensions was applied to radiation therapy and is known as DICOM-RT. In addition to the protocol used in the DICOM standard, seven DICOM-RT objects\u2014namely, RT Image, RT Structure Set, RT Plan, RT Dose, RT Beams Treatment Record, RT Brachy Treatment Record, and RT Treatment Summary Record\u2014have been created, each with a well-defined data model. The data models set the standard for integration of radiation therapy informa-tion for an electronic patient record and would facilitate the interoper-ability of different radiation therapy systems, thus making possible the sharing of information from different systems. \u00a9RSNA, 2009 radiographics.rsnajnls.orgInformatics in Radiology DICOM-RT and Its Utilization in Radiation Therapy1 Abbreviations: CTV = clinical target volume, DICOM = Digital Imaging and Communications in Medicine, DRR = digitally reconstructed radio - graph, ePR = electronic patient record, IHE = Integrating the Healthcare Enterprise, OAR = organ at risk, PACS = picture archiving and communi - cation system, PTV = planning target volume, ROI = region of interest, TPS = treatment planning system RadioGraphics 2009; 29:655-667 Published online 10.1148/rg.293075172 Content Codes: 1From the Department of Health Technology and Informatics, the Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong (M.Y .Y .L.); and Image Processing and Informatics Laboratory, Keck School of Medicine, University of Southern California at Health Sciences Campus, Los Angeles, Calif (B.L.). Presented as an Informatics exhibit at the 2006 RSNA Annual Meeting. Received August 13, 2007; revision re - quested November 20; final revision received November 17, 2008; accepted December 18. Both authors have no financial relationships to disclose. Address correspondence to M.Y .Y .L. (e-mail: May-June 2009 Introduction The Digital Imaging and Communications in Medicine (DICOM) standard is used for transmis - sion of medical images. Its predecessor, the ACR-NEMA (American College of Radiology-National Electrical Manufacturers Association) standard, was published in 1982, followed by a second ver-sion, ACR-NEMA 2.0, in 1988 (1-3), neither of which addressed computer networking issues. A major revision named DICOM that incorporated the existing network standard was introduced in 1992, specifying standards for digital imaging systems in medicine for information handling and transmission. For details regarding the DICOM standard, readers are referred to the technical and nontechnical introduction to DICOM in two pre-vious articles published in this journal (1,2). DICOM is the cornerstone of the successful implementation of picture archiving and com-munication systems (PACS) in radiology, allowing communication between equipment from different vendors. In recent years, the DICOM standard has been extended to incorporate many medical spe-cialties such as radiation therapy (4,5), cardiology (6,7), pathology (8,9), and ophthalmology (10,11) and allow the viewing of images together with specialty-specific information. Because radiation therapy is image intensive, it was the first specialty to be incorporated into the DICOM standard after radiology, with the creation of four DICOM-RT objects in 1997 (4) and three more in 1999 (5). In 2006, two additional objects were defined for ion therapy (12). Because this article is intended to serve as an introduction to the DICOM-RT standard, only the first seven objects for radiation therapy will be described. For communication of radiation therapy data, the transfer protocol will largely follow the stan-dard used in DICOM for communication of medical images, which will not be revisited in this article. It is the unique information in radiation therapy such as text, graphs, and isodose lines and their superimposition on medical images that gives rise to the creation of specific radiation therapy information object definitions and their attributes. In this article, we describe the work flow in radiation therapy compared with that in radiology and the DICOM-RT objects that are generated in the radiation therapy work flow. In addition, we discuss and illustrate the utilization of DICOM-RT in a sample case of prostate can-cer and discuss the need to integrate radiation therapy information with use of DICOM-RT. Radiology Work Flow versus Radia- tion Therapy Work Flow Radiology Work Flow The DICOM-RT objects are extensions of the DICOM standard, which, as mentioned ear-lier, was first implemented for use in radiology. Figure 1. Chart illustrates the impact of a PACS on clinical work flow in a radiology department. Step 1, patient arrives at hospital; step 2, patient registers with hospital information system; step 3, examination is ordered at radiology information system; step 4, tech-nologist receives information from clerk; step 5, patient is escorted into modality room; step 6, technologist performs examination; step 7, examination is com-pleted; step 8, clerk pulls out old films; step 9, clerk prepares all necessary papers and films for radiologist; step 10, films are hung up for radiologist's review; step 11, radiologist reviews films, reads examinations, and dictates reports; step 12, transcriptionist types draft report from the dictation; step 13, radiologist reviews and signs off on report; step 14, final reports are input into radiology information system for clinical viewing. With the implementation of a PACS, steps 4, 8-10, 12, and 14 can be eliminated, making work flow more ef-ficient. (Modified, with permission, from reference 3.) 141RG Volume 29 Number 3 Law and Liu 657 Reviewing the work flow in radiology before discussing the work flow in radiation therapy will help readers understand the similarities and dif-ferences between the information requirements of these two specialties in medicine. Steps 1-14 in Figure 1 depict film-based radi- ology work flow without a PACS. With the imple-mentation of digital radiography and a PACS, the work flow is greatly simplified. After the patient arrives at the hospital (step 1) and is registered with the hospital information system (step 2) and radiology information system (step 3), his or her personal information and the request for ex-amination will be transmitted to the appropriate modality (step 5), saving the technologists from having to obtain the patient information from the reception counter (step 4). When the examination is performed (step 6), an image is generated (step 7). This image, together with any previous im-ages, will be sent by the PACS to the workstation for reading by the radiologist (step 11), thereby saving steps 8-10. The prefetching of previous images by clerical staff is no longer required, and preparatory work for image reading is reduced. The radiologist can easily use some templates or a structured report at the reading workstation to type out the imaging findings (step 13), thereby saving steps 12 and 14. In addition to saving both time and manpower in searching for old films and preparing reports, the implementation of digital radiography and a PACS allows integration of images from differ-ent modalities and vendors under the patient's unique identifier. These images can easily be re-trieved without fear of losing data or film. Radiation Therapy Work Flow Radiation therapy consists of three modalities: external beam therapy, nuclear medicine, and brachytherapy. Upon being referred by a general physician for consultation, the patient is sched-uled for an appointment. On the appointed day, the patient registers at the oncology department. The radiation oncologist sees the patient and determines the most appropriate modality for the patient on the basis of prior investigation results and treatment protocol. In general, radiation therapy entails treatment planning and delivery. Thus, when the oncologist decides that the pa-tient should proceed with radiation therapy, the patient will be scheduled for treatment planning before undergoing treatment. External beam therapy accounts for over 90% of the workload in a radiation therapy depart-ment. Brachytherapy often plays a supplemen-tary role and is often used in the treatment of gynecologic cancers. Nuclear medicine has be-come independent of radiation therapy in many hospitals. Thus, for the sake of simplicity, only the work flow of external beam therapy will be considered. Figure 2 provides a brief overview of patient treatment in a radiation oncology de-partment once the type of treatment has been determined. In some cases, the patient may receive both chemotherapy and radiation therapy. Figure 3 shows the general procedures involved in the planning and delivery of external beam therapy in a specific clinical case of prostate cancer. Figure 2. Chart illustrates cancer treatment work flow. Note that in some cases, the patient can receive both chemotherapy and radiation therapy as part of treatment. Whichever radiation therapy modality is chosen, the work flow involves treatment planning and delivery. HIS = hospital information system. 142658 May-June 2009 radiographics.rsnajnls.org volume coverage and sparing of OARs. Each plan should be evaluated carefully with use of dose-volume histograms and planar dose distributions. Although they do not provide spatial information, dose-volume histograms provide a global view as to whether the resultant plan meets the dose-Note how different radiation therapy data are generated within the work flow. The data are categorized and \"contained\" in the various DICOM-RT objects as defined by the DICOM standard (Fig 3). Treatment Planning (Steps 1-5).\u2014The goal of treatment planning is to deliver the highest and most uniform radiation dose possible to the tu-mor-bearing site but the smallest dose possible to the surrounding healthy tissue, especially critical and radiosensitive structures (the urinary bladder and rectum in cases of prostate cancer). Information from medical images is crucial to the radiation therapy planning process. The process starts with the localization of the prostate tumor volume. For this purpose, the oncologist will order a CT study of the pelvis, performed on either the CT simulator or a CT scanner. The pa-tient's information is delivered to the CT simula-tor room, where the radiation therapist positions the patient for scanning. The pelvic CT scans are generated as DICOM images and stored either in a PACS or in the workstation there (step 1). The CT scans are then transferred to a computer treatment planning system (TPS) (step 2) for radiation field planning. Previous diagnostic im-ages, CT scans, magnetic resonance (MR) im-ages, or positron emission tomographic (PET) scans may also be retrieved to aid in the delinea-tion of tumor volume. At the TPS workstation, the tumor volume and the organs at risk (OARs) (urinary bladder and rectum) are delineated. Treatment fields of appropriate size and optimal gantry or collimator angles are determined. The TPS will compute the radiation dose distribution within the body region to be treated (step 2). Determining the best ra-diation therapy plan requires a clinical judgment based on the balance between adequate target Figure 3. Chart illustrates radiation therapy work flow. Y ellow boxes indicate the DICOM-RT objects that could be generated within the work flow. A radia-tion therapy treatment plan (step 2) with radiation dose distribution involves the superposition of the radiation therapy objects RT Plan, RT Structure Set, and RT Dose on the corresponding set of DICOM computed tomographic (CT) scans according to the coordinates in the DICOM-RT standard. Because the work flow is for external beam therapy, the RT Brachy Treatment Record information object is not shown. DRR = digitally reconstructed radiograph, DVH = dose-volume 29 Number 3 Law and Liu 659 will be recorded, as well as the radiation dose and the cumulative dose to date (step 8). During the course of treatment, weekly veri- fication images are acquired to ensure accuracy. The oncologist will also review the patient's prog-ress and prescribe whatever medicine is required. Upon being completed, the patient's course of treatment will be summarized and filed. A follow-up appointment will usually be made with the patient for review purposes. Comparison of Work Flow Radiology mainly involves the generation of medi-cal images and reporting of the diagnosis, whereas in radiation therapy, the images are used for treat-ment planning and specific kinds of images are generated for treatment verification. In radiology, the procedure is considered complete as soon as the imaging findings have been reported, but this is only the beginning for radiation therapy. Treatment planning and delivery, consultation, and follow-up are additional procedures in radia-tion therapy that generate information quite dif-ferent from that in radiology. Table 1 compares radiology and radiation therapy in terms of the nature of the work involved and the requirements for information integration. In contrast to the radiology work flow, in which the data are mostly images and are generated together, the radiation therapy work flow entails additional imaging and informatics data that are generated over an ex-tended period of time due to the many more steps involved. Although its framework looks similar in many areas, the DICOM information object is different. In radiology, the same DICOM image object information entity is deployed to accommo-date the different modules of attributes. In radia-tion therapy, there are different objects to group the different types of information (Table 2).volume criteria. A detailed slice-by-slice analysis of isodose distribution is crucial for examining target volume coverage and identifying the exact location of \"hot\" and \"cold\" spots with respect to radiation dose. When the OARs overlap with or are in proximity to the target volume, the dose is often limited by ranking the OARs in terms of relative importance. Images similar to projectional images can be re- constructed from the CT scans to show the treat-ment field positions and are called digitally recon-structed radiographs (DRRs) (step 3). A DRR, or simulator image obtained for treatment planning, will serve as the reference image for treatment verification later. The finished plan is presented to the radiation oncologist for evaluation and approv-al. If the plan is found satisfactory, the oncologist prescribes the treatment (step 4) on the radiation therapy prescription sheet. A treatment record with all treatment details is prepared with the pre-scription. Treatment sessions are scheduled in the treatment information system (step 5) and trans-ferred to the radiation treatment unit or linear ac-celerator, either through the department network or by manual paper delivery. Treatment Delivery (Steps 6-12).\u2014Before the actual radiation treatment commences, the accu-racy of the treatment plan in terms of field sizes, setup, shielding positions, and so on needs to be verified at the linear accelerator. For such verifi-cation, a portal image is obtained at the linear ac-celerator (step 6), either as a film image or (with an electronic portal imaging device installed in the linear accelerator) as a digital portal image. The image is then compared with the reference DRR or simulator image. When the irradiated portal aligns correctly with the portal on the ref-erence images, the oncologist will approve the verification. Radiation treatment can then pro-ceed (step 7). Otherwise, a repeat portal image may be requested. Normally, the patient will be treated five times a week for 7-8 weeks. At each treatment session, each of the treatment beams 144660 May-June 2009 radiographics.rsnajnls.org DICOM-RT Objects There are significant differences in the types of information required for radiology and radia-tion therapy as well as differences in the time at which and frequency with which the information is obtained. The different types of information require different categorization. On the basis of the standard DICOM query-retrieve model, the radiation therapy information is defined in seven information objects known as DICOM-RT Table 2 Image Object versus an RT Object IOD Module Information Entity of DICOM Image ObjectModule * (MR Imaging)Information Entity of DICOM-RT ObjectModule * (RT Structure Set) Patient Patient Patient Patient Study General Study Study General Study Series General Series Series RT Series Frame of Reference Frame of Reference ... ... Equipment General Equipment Equipment General Equipment Image General Image, Imaging Plane, Image Pixel, MR Image, SOP Common (13)Structure Set Structure Set, ROI Contour, RT ROI Observations, SOP Common (13) *Only mandatory modules are listed. A module groups related information together. For example, the Patient module contains attributes related to the patient, such as Patient's Name, Patient ID, Patient's Birth Date, Pa- tient's Sex, and so on. The modules for the image Information Entity depend on the modality concerned. In this table, the modality of interest is MR imaging; thus, in addition to the General Image module, Information Entity has a specific MR Image module and other related modules. Structure Set is one of the DICOM-RT objects and includes Structure Set, ROI Contour, and RT ROI Observations as its specific modules. IOD = information object definition, ROI = region of interest, SOP = service-object pair. objects for the transfer of data (10,11,13). These information objects include RT Structure Set, RT Plan, RT Dose, RT Image, and RT Treatment Record, which is further divided into RT Beams Treatment Record, RT Brachy Treatment Record, and RT Treatment Summary Record. Figure 4 shows these objects, how they are extensions of the DICOM model in radiology, and how they relate to each other and to the image object in radiology. The information in the DICOM-RT objects is described in the following paragraphs and illustrated in Figures 5-9.Table 1 Requirements for Information Integration in Radiology versus Radiation Therapy Radiology Radiation Therapy Imaging informatics based: image and informatics data for diagnosis, historical studies for diagnosis, computer-aided detection/diagnosis or decision support during diagnosisImaging informatics based: image and informatics data for treatment, historical plans for treatment planning, quantified knowledge or decision support during course of treatment Modalities: radiography, computed radiography, CT, MR imaging, ultrasonography, PET, beam therapy, brachytherapy, ion therapy Standards: Work Flow Profiles Standards: DICOM-RT, DICOM, HL7, IHE Work Flow Profiles Key informatics data objects: DICOM Image, DICOM-SR, Image, other reports Customers: patient, referring physician, radiologists Customers: patient, referring physician, radiation oncologists System integration necessary for improved work flow System integration necessary for improved work flow Solution: PACS Solution: DICOM-RT electronic patient record (ePR) system Note.\u2014Data generated within the radiation therapy clinical work flow contain additional imaging and infor - matics data that are crucial for the work flow, which necessitates the DICOM-RT standard as well as an ePR system. HL7 = Health Level 7, IHE = Integrating the Healthcare Enterprise, SR = structured report. Teaching Point Teaching PointRG Volume 29 Number 3 Law and Liu 661 Figure 4. Chart illustrates DICOM-RT objects as an extension of the DICOM standard. Note that RT Plan, which contains all RT -related information, is an important object that is needed from the start of radiation therapy planning to the completion of treatment and is thus related to all other objects. Figure 5. CT scan with super- imposed color coding shows an RT Structure Set, which includes tumor volume (outlined in red), OARs (femoral heads [green and pink], rectum [purple], bladder [blue]), and body contour. Figure 6. RT Plan. (a) Chart illustrates an RT Plan. Coll = colli-mator rotation, fr = fraction, ID = identification, I.L. = isodose level, IMRT = intensity-modulated ra-diation therapy, LA = linear accel-erator, MU = monitor unit, RT = radiation therapy, SSD = source-skin distance, X and Y = collima- tor leaves in the x and y directions. (b) Information from RT Plan superimposed on RT Structure Set and a CT scan. Nine radiation beams (attribute of RT Plan) are each indicated by a red label and three yellow lines. 146662 May-June 2009 radiographics.rsnajnls.org or clinically demonstrable extent and location of a tumor. The CTV contains the demonstrable gross target volume plus a margin for subclinical disease spread, which cannot be fully imaged. The PTV is a geometric concept designed to ensure actual delivery of radiation therapy dose to the CTV and contains the CTV plus a margin to take into ac-count uncertainties due to internal organ motion, patient motion, and setup error. In cases of pros-tate cancer, the target volume is the prostate gland and any periglandular cancerous areas. The OARs are the urinary bladder, the rectum, and the femo-ral heads. Each structure will be associated with a frame of reference, with or without reference to the diagnostic images.RT Structure Set The RT Structure Set information object (Fig 5) defines a set of areas of significance in ra-diation therapy, such as body contours, tumor volumes (eg, gross target volume, clinical target volume [CTV], planning target volume [PTV]), OARs, and other ROIs. The target volumes are defined in accordance with the guidelines in International Commission on Radiation Units and Measurements Reports 50 and 62. The gross tar-get volume is essentially the gross palpable, visible, Figure 7. RT Dose. (a) CT scan with superimposed color coding shows radiation dose data from a TPS. Isodose curves are shown in yellow, pink, green, magenta, and blue. Red shaded area indicates tumor volume (RT Structure Set). (b) A dose-volume histogram (which also belongs to the RT Dose object) is used for evaluation of a treatment plan. Such evaluation is key in determining whether a proper radiation dose is being applied to the tar-get tumor while limiting the dose to surrounding critical healthy tissue and organs. Red line indicates that most of the tumor volume is receiving over 7500 cGy of radiation. Orange, green, magenta, and yellow lines show the dose received by the rectum, right femoral head, left femoral head, and bladder, respectively (OARs). Max = maximum, Min = minimum, Std Dev = standard deviation. 147RG Volume 29 Number 3 Law and Liu 663 Figure 8. RT Image. Projectional simulator image (a), DRR from a CT scan (b), and portal image acquired at a linear accelerator (c) show the field to be irradiated and are examples of images \"acquired or calculated using con-ical geometry\" (13). Multileaf collimators are seen on the DRR (blue lines in b) and are an attribute of RT Image. Portal images verify the accuracy of the placement of the treatment portal; oftentimes only the irradiated portal will be exposed. Portal images should be compared with refer-ence images from the simulator or with the DRRs. Figure 9. An RT Beams Treatment Record is used to record the dose (in monitor units [MU]) delivered to each of the radiation fields (top row) at each treatment session (dates shown in first column). The last four col - umns (radiation fields 12-15) show a second phase of treatment involving only four radiation fields. RT Plan As explained earlier, treatment planning is a process for determining the best placement of the radiation beam for optimal dose distribu-tion. The procedure involves localization of the tumor and OARs, as well as the design (in terms of position and size) of radiation beams and their dose weighting with respect to the PTV and OARs. A clinical treatment plan may include all of the structures marked on the CT scan, the 148664 May-June 2009 radiographics.rsnajnls.org lows the transmission of \"a 3D [three-dimension- al] array of dose data as a set of 2D [two-dimen-sional] dose planes that may or may not be related to the CT or MR imaging planes\" (Fig 7) (13). RT Image Although RT Image has in common some of the framework used for radiology images in the DICOM standard (Table 2), it specifies the at-tributes of those images that are \"acquired or calculated using conical geometry\" (13) in radia-tion therapy. Such images include projectional simulator images (Fig 8a), DRRs generated from CT scans by a TPS (Fig 8b), and portal images acquired at linear accelerators (Fig 8c). Note that CT images generated with CT simulators are considered to be ordinary CT scans. In contrast to a DICOM image object, RT Image includes not only image information, but also the presen-tation of the image (ie, position, plane, and orien-tation of image; distance from radiation machine source to imaging plane). If necessary, RT Image will include the table position, isocenter position, and patient position, and the type of device used to limit the radiation therapy beam (eg, multileaf jaw pairs) (Fig 8b).beam positions and sizes, and the dose distribu-tion displayed on the image. In the DICOM-RT standard, information about the structures of interest is contained in RT Structure Set and dose distribution in RT Dose, which requires the coordinates for placing their positions in relation to each other. Thus, the RT Plan object refers only to the textual information in treatment plans, whether generated manually or by a TPS. Such information includes treatment beams, frac-tionation scheme, prescription, accessories used, and patient setup in external beam therapy or brachytherapy (Fig 6a). In Figure 6b, information from RT Plan is superimposed on RT Structure Set and a CT scan to create a graphical presenta-tion for better visualization. RT Dose The distribution of radiation dose for a treatment is represented by isodose lines expressed as a per-centage or in dose units (grays). The isodose lines can be displayed in relation to the tumor volume and OARs and superimposed on images. RT Dose contains such radiation dose data from TPSs. It al- Figure 10. Chart illustrates the seven DICOM-RT objects and their associated modules. Note that the various radiation therapy data generated during the clinical work flow are distributed over the seven objects. DVH = dose-volume histo-gram, LUT = look-up table, VOI = volume of interest. Understanding how to extract key information from each of the DICOM-RT modules is crucial. The properties or attributes of each module are described in de-tail in reference 13. Teaching Point 149RG Volume 29 Number 3 Law and Liu 665 RT Treatment Record The RT Treatment Record information object (Fig 9) includes RT Beams Treatment Record, RT Brachy Treatment Record, and RT Treatment Summary Record. RT Beams Treatment Record.\u2014RT Beams Treatment Record consists mainly of textual data that constitute a treatment session report. The information can be generated by a treatment verification system during the course of external beam therapy or gathered during treatment de-livery. Such information includes machine used, radiation type and energy used, date and time of treatment, external beam details, treatment beam accessories, treatment fraction details, monitor units (dose), calculated dose, cumulative dose, ver-ification image obtained, and treatment summary (optional). Each treatment is represented as an in-stance in an RT Beams Treatment Record object. RT Brachy Treatment Record.\u2014The RT Brachy Treatment Record information object is similar to RT Beams Treatment Record but con-sists mainly of information acquired during the course of brachytherapy, along with an optional treatment summary.RT Treatment Summary Record.\u2014The RT Treatment Summary Record information object summarizes cumulative information concerning the radiation treatment, including both external beam therapy and brachytherapy. RT Object Modules In the DICOM standard, each information object contains modules of information related to the object, including both modules that are common to all modalities in radiology (eg, Patient, General Study, General Equipment) and modules that are specific to each imaging modality (eg, CT Image module for CT, MR Image module for MR imaging). In these modality-specific mod-ules, the properties (also known as attributes) of the images are specified. For example, the MR Image module contains both attributes that are found in other modalities (eg, Image Type, Samples per Pixel) and attributes of its own (eg, MR Acquisition Type, Magnetic Field Strength, Repetition Time, Echo Time). In radiation ther-apy objects, in addition to the common modules, each object contains several associated modules. Table 2 compares the modules in a DICOM image object (MR imaging) with those in a DICOM-RT object (RT Structure Set). Figure 10 shows the seven DICOM-RT objects and their associated modules. For example, RT Structure Set includes Struc- ture Set, ROI Contour, RT ROI Observations, and Approval modules as specific to the object (T able 3). The Structure Set module provides a framework for defining a set of areas of signifi-cance, each of which is associated with a frame of reference with or without reference to the images. If the set of structures have reference to the im-ages, they can be displayed as an overlay on an image as in Figure 5, in which the tumor and the OARs are the ROIs, each with a unique identifi-cation number. In the ROI Contour module, the ROIs are a single contour or a sequence of two or more contours. These contours will be referenced to the ROI identification number in the Structure Set and to the CT images containing the con-tours (Fig 5). The RT ROI Observations module helps distinguish between individual instances or classes of ROIs specified in the previous two modules (Structure Set and ROI Contour)\u2014for example, PTV1 and PTV2. The Approval module is a simple module that addresses the status of ap-proval of the delineation of an important structure Table 3 RT Structure Set IOD Module Entity Module Usage * Patient Patient M Clinical Trial Subject U Study General Study M Patient Study U Clinical Trial Study U Series RT Series M Clinical Trial Series U Frame of ReferenceFrame of Reference U Equipment General Equipment M RT Structure SetStructure Set ROI ContourM M RT ROI Observations M Approval U SOP Common M Source.\u2014Reference 13. IOD = information object definition. *C = conditional, M = mandatory, U = optional. Modules specific to the RT Structure Set DI- COM-RT object. All other modules are common modules similar to those in other DICOM objects. Service-object pair. 150666 May-June 2009 radiographics.rsnajnls.org involves all three systems will be stored in three different places. Currently, such treatment infor-mation is normally \"linked\" by a paper record or folder on the patient. The foregoing description does not take into account the hard-copy film im-ages that are stored separately in the film library, a practice that is common in many radiation therapy departments. Even so, if the paper record is lost, the patient's treatment information \"dis-integrates.\" What is more disturbing is that treat-ment plans from an old TPS cannot be retrieved for review after a system upgrade. Basically, this results in the treatment plans being \"lost.\" The radiation therapy department needs a \"bridge\" system to fill the gap, integrate all the disparate data, and provide a \"one-stop shop\" for historical treatment plans and key related data. Ideally, information and records scattered throughout the different systems could be inte-grated and a live summary of the patient's treatment record could be displayed when required. Such an endeavor would help save time and effort spent in searching and minimize the loss of records and films. However, interoperability between systems from different manufacturers is an issue if there is no standard or there is noncompliance with the dedicated DICOM-RT standard. It could be ar-gued that purchasing all equipment from a single manufacturer would solve the problem. However, the matter is not that simple. First, the department would be \"tied down\" to one manufacturer and would have to accept whatever service the manu-facturer provides. This is not a healthy situation from the user's perspective. Second, when there is a need for the exchange of radiation therapy pa-tient records or for research collaboration between institutions, the problem still exists. The current trend in information technology is toward ePRs, electronic medical records, or electronic health records (14), in which all medi-cal and health information about a patient is organized under the patient's name or identifica-tion number. When a patient's name is queried, all reports and records are displayed without the need to go into different systems. With the ma-turity of the DICOM standard, PACS, and IHE (Integrating the Healthcare Enterprise) work flow profiles, researchers and even manufacturers are now working toward incorporating medical im-ages (eg, radiologic, endoscopic, and microscopic images) into the ePRs.(eg, the PTV), a treatment plan, or a verification image and shows the reviewer's name and the date of approval. The Approval module is also included in the RT Image, RT Structure Set, and RT Plan objects (Fig 10). Information Encoding All DICOM objects are composed of DICOM el-ements (units of information). The DICOM stan-dard defines the attributes of each module and assigns names and data element tags to the attri-butes. For example, the tag for Patient's Name is (0010,0010), and that for Patient ID (identifica-tion) is (0010,0020). During treatment planning, contours (an RT Structure Set attribute) are drawn around the ROIs (eg, bladder, rectum), which are OARs of significance. A number with its respective name is assigned to each ROI. The DICOM encoder will insert the ROI (identification) number against the element tag (3006,0022), the ROI name against (3006,0026), the contour number against (3006,0048), the contour image sequence against (3006,0016), and so on. The contour image se-quence introduces the sequence of images con-taining the contour. Other attributes are similarly encoded into their corresponding tags as defined by the DICOM standard. With the encoded in-formation and reference to the corresponding CT scan, the structure sets can be reproduced on the CT scan as shown in Figure 5. Utilization of DICOM- RT Objects in a Radiation Therapy-based ePR System In a radiation therapy department, often there are different proprietary and stand-alone infor-mation systems for single-purpose applications (eg, a separate TPS for each of several treat-ment modalities, such as external beam therapy, brachytherapy, or stereotactic radiation therapy-radiosurgery). Each system has its own \"storage area\" for the plans performed at its workstation. Oftentimes these systems are stand-alone sys-tems and have only limited interface with other systems. Typically, the treatment plans are stored in the conventional TPS, with treatment records stored in another information system. The treat-ment information for a patient whose treatment 151RG Volume 29 Number 3 Law and Liu 667 Using the DICOM-RT standard and follow- ing the model of the PACS makes integration of radiation therapy information possible (15,16). All radiation therapy information and images from various sources can be converted to the DICOM-RT standard and integrated into a DICOM-based database. This information can be displayed as a radiation therapy ePR. From the database, connection to other radiation thera-py systems and exchange of radiation therapy pa-tient information are also possible with DICOM-RT and a DICOM-based radiation therapy ePR system. The collection of radiation therapy information in the DICOM-RT objects will lead to further initiatives in informatics research in radiation therapy. With the increasing popularity of proton beam therapy, two more RT objects\u2014namely, RT Ion Plan and RT Ion Beams Treatment Record\u2014have been defined. The implementation of these objects in a proton beam therapy system is be-ing researched, and it is hoped that, with use of the DICOM standard, information from proton beam therapy can be integrated with that from conventional radiation therapy. Conclusions In addition to being image intensive, radiation therapy is highly technical, and its use of radia-tion also involves radiobiologic factors. All of these parameters have to be recorded for future reference regarding the treatment of cancer pa-tients with radiation therapy. Hence, along with textual information, all related treatment plan-ning information (including isodose lines, graphs, and so on) and images need to go into a single electronic folder on the patient. Like the DICOM standard in radiology, the DICOM-RT standard is ratified for integration, archival, and sharing of information. Given the small number of vendors and the rapidly develop - ing technology in radiation therapy, the industry tends to focus more on technologic development; thus, the adoption of the DICOM-RT standard is slow and incomplete in most cases. For objects that have been implemented, a user interface called \"DICOM export/DICOM import\" may exist in some TPSs for the conversion of infor-mation from a vendor-specific format to the DICOM format. With manufacturers' collabora-tion, radiation therapy information can, like di-agnostic images, be linked to the ePR to produce a complete radiation therapy patient record. The DICOM-based radiation therapy database can provide a platform for data sharing and for future medical imaging informatics research and out-come analysis of standardized data. References 1. WD, 2. computers and IV . A nontechnical introduction to DI-COM. RadioGraphics 1997;17:1297-1309. 3. Huang HK. PACS and imaging informatics: basic principles and applications. Hoboken, NJ: Wiley-Liss, 2004; 175. 4. Digital Imaging and Communications in Medicine (DICOM) Supplement 11. Radiotherapy objects. 5. Digital Imaging and Communications in Medicine (DICOM) Supplement 29. Radiotherapy treat-ment records and radiotherapy media extensions. 6. Digital Imaging and Communications in Medicine (DICOM) Supplement 30. Waveform interchange. 7. Digital Imaging and Communications in Medicine (DICOM) Supplement 48. Intravascular ultrasound (IVUS). 8. Digital Imaging and Communications in Medicine (DICOM) Supplement 15. Visible light image for endoscopy, microscopy, and photography. 9. Digital Imaging and Communications in Medicine (DICOM) Supplement 122. Specimen identifica-tion and revised pathology. 10. Digital Imaging and Communications in Medicine (DICOM) Supplement 91. Ophthalmic photogra-phy SOP classes. 11. Digital Imaging and Communications in Medicine (DICOM) Supplement 110. Ophthalmic coher-ence tomography (OCT) storage SOP class. 12. Digital Imaging and Communications in Medicine (DICOM) Supplement 102. Radiotherapy exten-sions for ion therapy. 13. Digital Imaging and Communications in Medicine (DICOM) Part 3. Information object definitions. PS3.3-2008. 14. Kuzmak PM, Dayhoff RE. The use of digital imag - ing and communications in medicine (DICOM) in the integration of imaging into the electronic pa-tient record at the Department of Veterans Affairs. J Digit Imaging 2000;13(2 suppl 1):133-137. 15. Law MY, Huang HK. Concept of a PACS and im - aging informatics-based server for radiation thera-py. Comput Med Imaging Graph 2003;27:1-9. 16. Law MY . A model of DICOM-based electronic patient record in radiation therapy. Comput Med Imaging Graph 2005;29:125-136. Teaching Point Teaching Point 152RG Volume 29 Number 3 May-June 2009 Law and Liu et al DICOM-RT and Its Utilizat ion in Radiation Therapy Maria Y. Y. Law, PhD and Brent Liu, PhD Page 660 There are significant differences in the types of information required for radiology and radiation therapy as well as differences in the time at wh ich and frequency with which the information is obtained. Page 660 On the basis of the standard DI COM query-retrieve model, the ra diation therapy information is defined in seven information objects known as DICOM-RT objects for the transfer of data (10,11,13). These information objects include RT St ructure Set, RT Plan, RT Dose, RT Image, and RT Treatment Record, which is further divided into RT Beams Treatment Record, RT Brachy Treatment Record, and RT Treatment Summary Record. Page 664 Although RT Image has in common some of the framework used for radiology images in the DICOM standard (Table 2), it specifies th e attributes of those images that are \"acquired or calculated using conical geometry\" (13) in radiation therapy. Such images include projectional si mulator images (Fig 8a), DRRs generated from CT scans by a TPS (F ig 8b), and portal images acquired at linear accelerators (Fig 8c). Page 667 Using the DICOM-RT standa rd and following the mode l of the PACS makes integration of radiation therapy information possible (15,16). All radiatio n therapy information an d images from various sources can be converted to the DICOM-RT standard and integrated into a DICOM-based database. This information can be displayed as a radiation therapy ePR. Page 667 The DICOM-based radiation therapy database can prov ide a platform for data sharing and for future medical imaging informatics research and outcome analysis of standardized data. RadioGraphics 2009; 29:655-667 Published online 10.1148/rg.293075172 Content Codes: 153Int J DOI 10.1007/s11548-009-0297-y ORIGINAL ARTICLE Integration of computer-aided diagnosis/detection (CAD) results in a PACS environment using CAD-PACS toolkit and DICOM SR A n hH .T .L e \u00b7Brent Liu \u00b7H. K. Huang Received: 15 September 2008 / Accepted: 11 March 2009 / Published online: 15 April 2009 \u00a9 CARS 2009 Abstract Purpose Picture Archiving and Communication System (PACS) is a mature technology in health care delivery fordaily clinical imaging service and data management.Computer-aided detection and diagnosis (CAD) utilizes computer methods to obtain quantitative measurements from medical images and clinical information to assist clinicians toassess a patient's clinical state more objectively. CAD needsimage input and related information from PACS to improve its accuracy; and PACS benets from CAD results online and available at the PACS workstation as a second reader toassist physicians in the decision making process. Currently, these two technologies remain as two separate independent systems with only minimal system integration. This paperdescribes a universal method to integrate CAD results with PACS in its daily clinical environment. Methods The method is based on Health Level 7 (HL7) and Digital imaging and communications in medicine (DI-COM) standards, and Integrating the Healthcare Enterprise (IHE) workflow proles. In addition, the integration method is Health Insurance Portability and Accountability Act(HIPAA) compliant. Summary The paper presents (1) the clinical value and advantages of integrating CAD results in a PACS environ- ment, (2) DICOM Structured Reporting formats and some important IHE workflow proles utilized in the system Presented as \"Tutorial on CAD-PACS integration\" at: CARS 2007, Berlin, Germany, June 27-30, 2007; and CARS 2008, CARS 2008,Barcelona, Spain, June 25-28, 2008. A. H. T. Le ( B)\u00b7B. Liu \u00b7H. K. Huang Image Processing and Informatics Laboratory (IPILab),Departments of Radiology and Biomedical Engineering,Keck School of Medicine, University of Southern California,1450 San Pablo Street, Suite DEI 2100, Los Angeles, CA 90033, USAe-mail: (3) the methodology using the CAD-PACS toolkit, and (4) clinical examples with step-by-step of this integration. Keywords PACS \u00b7Computer-aid-diagnosis (CAD) \u00b7 DICOM structured reporting (SR) \u00b7CAD-PACS surgeryDICOM Digital imaging and communications in DICOM structured reportingFLAIR Fluid attenuated inversion recovery HIPAA Health insurance portability and accountability act HIS Hospital information systemHL7 Health level 7 IHE Integrating the Healthcare EnterpriseIRB Institutional Review BoardIOD Information object definition KIN Key image note MRI Magnetic resonance imagingMS Multiple sclerosis PPM Post-processing manager PWF Post-processing workflowsRIS Radiology information system SINR Simple image and numeric report SC DICOM secondary captureSR Structured report object/documentWS Workstation XML Extensible markup language 123 154318 Int J CARS (2009) 4:317-329 Computer-aided detection/diagnosis Computer-aided detection (CADe) and computer-aided diagnosis (CADx) utilize computer methods to obtain quan-titative measurements from medical images along with clin- ical information to assist clinicians and radiologists in the decision-making process of a patient. CADe is closely relatedto the process of automatic segmentation to indicate the loca- tion of possible abnormalities within a medical image. The classication, diagnosis, and patient care decisions are leftto the radiologist. CADx involves quantication processes utilizing computer analysis to classify a region or lesion which is the ultimate goal of radiological examinations. Thenal diagnosis and patient care decision are also left to theradiologist [2]. The purpose of this paper is not to focus on CADe or CADx methodologies, or methods to allow CAD to directly query the Picture Archiving and CommunicationSystem (PACS) database to improve the performance of the CAD, but the integration of CADe or CADx results to facil- itate PACS daily clinical service utilizing the Health level7 (HL7) standard [ 7], Digital imaging and communications in medicine (DICOM) standard [17], HIS/RIS/PACS tech-nologies, and Integrating the Healthcare Enterprise (IHE)workflow proles [13 ]. Throughout this paper, we will use CAD as the generic term to represent both CADe and CADx; PACS in short for HIS/RIS/PACS as the integrated system, and DICOM for DICOM standard and IHE for IHE workflowproles. The need for CAD-PACS integration Computer-aided detection and diagnosis software can be implemented within a stand-alone CAD Workstation (WS), a CAD server, or be integrated in PACS as PACS-based CAD.In order to utilize CAD results more efciently and timely, it is commonly agreed that CAD should be integrated with the daily clinical PACS operation [ 2]. Currently, some PACS and CAD companies have had some success in integrating several CAD applications within the PACS operation, but the solu- tions are either in a CAD specic WS, or in a closed PACSoperation environment using proprietary software. For exam-ple, in mammography, CAD has become an integral part of a routine clinical assessment of breast cancer in many hospitals and clinics across the United States and abroad [6]. However,the value and effectiveness of CAD applications are still hin- dered due to the inconvenience of the standalone CAD WS or server. The wide usage of DICOM, PACS, and IHE tech-nologies as an integral part of daily clinical operation sheds some light on how to overcome such obstacles. The CAD-PACS integration has many distinct advanta- ges, among them are:(1) PACS is a mature technology which consists of pow- erful computers and high speed networks dedicated to the storage, retrieval, distribution, and presentation of clinical image, (2) the integration allows the use of built-in PACS-based easy query/retrieve tools providing user with images and related patient data obtained from CAD results, (3) the DICOM structured reporting (SR) and IHE work- flow proles can be readily applied to facilitate theCAD-PACS integration, and (4) CAD-PACS integration results can be directly viewed and utilized at the PACS WS together with the PACSdatabase. Although it is also advantageous to integrate CAD to utilize PACS data to improve the CAD algorithm resulting in bet- ter diagnosis and improved CAD performance, this paper'smain focus is describing how to integrate CAD-PACS in order to achieve those aforementioned purposes. Further- more, integrating CAD in the clinical PACS environmentwould facilitate radiologists and healthcare providers in their daily operation. Clinical examples to illustrate the importance and usefulness of the CAD-PACS Toolkit will be discussed infurther detail in Sect. \"Examples of integrating using CAD-PACS toolkit\". DICOM standard and IHE workflow proles CAD-HIS/RIS/PACS integration certain basic ingredients from HL7 [7] standard for textual data, DICOM[17] standard for image, and IHE [13] workflow prolesin order to comply with the Health insurance portability and accountability act (HIPAA) [ 12] requirements to be a healthcare system. Among the DICOM standard and IHE workflow proles, DICOM structured reporting (DICOM- SR), and IHE Key image note (KIN), Simple image and numeric report (SINR), and Post-processing workflows(PWF) are important in CAD-HIS/RIS/PACS integration. Section \"DICOM structured reporting (DICOM-SR)\" rst discusses the DICOM-SR, followed by the three IHE work-flow proles in Sect. \"IHE proles\". DICOM structured reporting (DICOM-SR) The scope of DICOM-SR is the standardization of SR documents in the imaging environment. SR documents record observations made for an imaging-based diagnostic or inter- ventional procedure, particularly those that describe or refer-ence images, waveforms, or specic regions of interest (ROI). DICOM-SR was rst introduced in 1994 and marked its exis- tence when Supplement 23 was adopted into DICOM stan-dard in 1999 as the rst DICOM-SR for clinical reports [ 3]. 123 155Int J CARS (2009) 4:317-329 319 Fig. 1 DICOM structured reporting objects in the DICOM Model of the Real World. The light green box is where the SRdocument is located in theDICOM data module which is inthe same level as DICOM Image The DICOM Committee has initiated more than 12 supplements to dene specic SR document templates. Among these, two of them related to capturing CAD results:the Mammography CAD SR (Supplement 50, 2000) [ 4] and Chest CT CAD SR (Supplement 65, 2001) [ 5] had been rat- ied. In practice, the use of structured forms for reportinghas shown to be benecial in reducing the ambiguity of nat- ural language format reporting by enhancing the precision, clarity and value of the clinical document. DICOM structured reporting is generalized using DICOM information object definitions (IODs) and services for the storage and transmission of structured reports. Figure 1illus- trates the simplied version of the DICOM Model of the real world [ 17], showing where DICOM-SR objects reside. The most important part of an SR object is the SR Document Con-tent which is the \"SR Templates\" consisted of design withdifferent patterns for various applications. Thus, for example, once the CAD results with images, graphs, and text have been translated into a SR templatedesigned for this application, the data in the specic templatecan be treated as a DICOM object stored in the worklist of the DICOM model (see boxes with light green background in Fig.1) and it can be displayed for review by a PACS WS with the SR Display function. The viewing requires the original images from which the CAD results were generated so that the results can be overlaid onto the images. The SR Displayfunction can link and download these images from the PACS archive and display them as well on the WS. IHE proles Three IHE proles useful for CAD-PACS integration are: (1) Key image note (KIN) prole allows users to flag images as significant (e.g., for referring, for surgery, etc.) and adds a note. (2) Simple image and numeric report (SINR) prole speci- es how Diagnostic Radiology Reports (includingimages and data) are created, exchanged, andused.(3) Post-processing workflow (PWF) prole provides worklist, status and result tracking for post-acquisitiontasks, such as Computer-Aided Detection or ImageProcessing. These proles will be used and explained in Sect. \"Examplesof integrating using CAD-PACS toolkit\" when examples are given. The CAD-PACS \u00a9integration toolkit Computer-aided detection and diagnosis software can be in a stand-alone CAD WS, CAD server, or integrated within the PACS as PACS-based CAD. Regardless where the CAD software is installed, the goal is to have CAD results inte-grated with daily clinical PACS operation. In this section, the CAD workflow in current practice is rst described fol- lowed by the presentation of a CAD-PACS integration tool-kit extending the CAD workflow to PACS environment.The CAD-PACS toolkit is a software package that has been developed and tested at Image Processing and Informatics Laboratory (IPILab) since 2006. The CAD-PACS integra-tion applications had also been presented at RSNA Annual Meeting in 2006 and 2007 [25, 16]; and given as tutorials at Computer-assisted radiology and surgery (CARS) Annual Meeting in 2007 and 2008 [ 8,9]. Current CAD workflow Figure 2depicts the PACS environment (blue box) and CAD WS/Server location (red box) which is outside the realm of PACS. These two systems are usually disjoint. When animage is needed for CAD processing (See numbers in Fig. 2), then the following occurs (See Fig. 2): (1) CAD processes the exam ordered through Radiology information system (RIS), or directly from Modality. (2) Technologist or radiologist transmits the original image from PACS server or PACS WS to CAD WS for 123 156320 Int J CARS (2009) 4:317-329 Fig. 2 CAD (red ) Workflow (numbers, see text for detail) in the PACS environment (blue ) with the CAD-PACS toolkit (purple). See color code used in Fig. 3 processing. Results are stored within the CAD domain since the CAD WS or Server is a closed system and the clinicians need to physically go to the CAD WS to view results. (3) Consider now there exists a CAD-PACS toolkit (pur- ple box) such that it can integrate with the PACS server,PACS WS, and the CAD Server/WS together via theDICOM standard and IHE Proles. Then, the CAD- PACS Toolkit would provide connectivity to push CAD results to the PACS Server for archival and the PACSWS for viewing; and query/retrieve original imagesf r o mP A C Ss e r v e rt oP A C SW St ob eo v e r l a i dw i t ht h e CAD results. In addition, it could also automatically push images directly from the PACS server or PACSWS to the CAD WS for processing. The rest of Sect. \"The CAD-PACS toolkit\" describes the concept and dataflow of CAD-PACS toolkit; its different editions and software modules; as well as the PACS and CAD components involved. Concept CAD-PACS\u00a9is a software toolkit using ] standard for textual information; DICOM standard [17 ] for various types of data format including images, waveform, graphics, anno- tations, and others; and IHE [13 ] workflow proles described in the aforementioned section for the integration of CAD results within the PACS workflow. This CAD software tool- kit is modularized and its components can be installed in vedifferent congurations: (1) In a standalone CAD worksta- tion, (2) In a CAD server, (3) In a PACS workstation, (4) In a PACS server, or (5) In a blended mixture of the previous fourcongurations above. In general, a CAD manufacturer would be more comfortable with the rst two approaches because there is very little collaboration needed with the PACS soft-ware which is quite complex for CAD manufacturers. On theother hand, a PACS manufacturer would prefer to use an in-house CAD or acquire the CAD from outside and integrateit with its own PACS with the latter three approaches. The infrastructure The CAD-PACS \u00a9toolkit has three C A DTM, i-PPMTM, Receive-SRTM, and Display-SRTM[18,19,15]. Each Edition consists of some or all of the software modules. Figure 3 shows the architecture of the toolkit. The toolkit is classied into three different Editions for different levels of PACS integration requirements. Table 1 shows the comparisons of these three integration approaches. The 1st Edition is for simple screen capture output\u2014the CAD quantitative results are not stored for future use. The 2nd Edition is for full CAD-PACS integration\u2014elaborated inte-gration efforts are needed between the CAD developer and the PACS manufacturer. This Edition will allow for the future potential for CAD to query PACS database and improving theCAD performance. The 3rd Edition does not require elabo-rated integration efforts between both parties\u2014the proper use of the CAD-PACS toolkit would be sufcient which is favored by independent CAD developers. Functions of the three editions DICOM-SC TM, 1st Edition The rst Edition utilized the i-CAD-SCTMsoftware module which relies on the DICOM screen capture (SC) service. It is simple to design and implement but with limitation in clin- ical research as it uses screen capture to store CAD results for viewing purposes only. DICOM-PACS-IHETM, 2nd Edition The second Edition consists of four software modules: i-CADTM, i-PPMTM, Receive-SRTM, and Display-SRTM.I t utilizes the DICOM-SR service and several IHE WorkflowProles, the methodology is elegant but requires installa-tion of four modules within the PACS server including the i-PPM TMmodule (post-processing manager). This module requires thorough understanding of the entire PACS work- flow which would need intensive collaboration with the PACS manufacturer during integration. The integration would require patience and perseverance from the integratorbecause of the protective culture of the PACS business. 123 157Int J CARS (2009) 4:317-329 321 Fig. 3 Rightmost four levels of the CAD-PACS Integration toolkit. Purple CAD-PACS Integration toolkit; green three CAD-PACS\u00a9Edi- yellow ve software modules; redCAD components and results, components. Left the CAD-PACS\u00a9toolkit rst Edi- tion DICOM-SCTMutilizes DICOM screen capture service to view CAD results. This Edition is easy to integrate, but the CAD output is not in a database for future retrieval. Middle second Edition DICOM- PACS-IHETMutilized for integration with a full PACS. It consists of four CAD-PACS software modules. It is suitable for a PACS manufac-turer to integrate an existing CAD into its own PACS. Right the third Edition DICOM-CAD-IHE TMutilized for integration with the CADserver. This component is independent from the PACS manufactureras long as the PACS workstation is DICOM-SR Compliant. The CADresults can then be viewed at a PACS WS. It is favored by the CADmanufacturers or research laboratories for integration. The three mod-ules i-CAD TM, Receive-SRTM, and Display-SRTMare Post-pro- cessing manager (PPM) allows the integration of CAD results with thePACS server which is PACS specic and would require PACS vendor'sassistance for implementation. In the lower level components, either inPACS or in CAD, proper toolkit software modules can be installed in the corresponding system components for CAD-PACS integration Table 1 Comparison of the three CAD-PACS integration editions Specications CAD-PACS Edition DICOM-SC DICOM-PACS-IHE DICOM-CAD-IHE1st Edition 2nd Edition 3rd Edition Using secondary captured image /check to store CAD results Using DICOM SR /check/check PACS without SR support /check/check PACS with SR support /check Display referenced Toggling between image and annotation /check/check DICOM-CAD-IHETM, 3rd third Edition comprises three software modules: i-CADTM, Receive-SRTM, Display-SRTM. It utilizes DICOM-SR and Key image note IHE prole, this methodreduces the necessity of altering the current PACS Server,but CAD results are stored in the CAD server and not in PACS. DICOM-SR links PACS image/data and CAD results for viewing. This Edition is favored by CAD manufacturersbecause they have the ability to install the toolkit in their CAD server and integrate CAD results with the PACS clini- cal workflow without the complexity of the previous Edition.DICOM-SR provides the data format allowing CAD results,text, images, graphics, and annotations to be directly archived within the DICOM-SR compliant CAD server. The second and the third Editions are the correct methods of integrating CAD with PACS because the availability ofdirect CAD results in daily clinical workflow would enhance the PACS operation, and allow future PACS research capa-bility.Data flow of the three editions DICOM-SC TM, 1st Edition The data flow within the DICOM-SCTMis simple and straight forward. The PACS WS pushes the image to the CAD WS or CAD Server. Results are screen captured by i-CAD-SC residing in the CAD WS as a DICOM image object and sent to PACS server for archive and it can be viewed by the PACSWS. In this Edition, results can only be viewed, and data cannot be used for other purposes. DICOM-PACS-IHE TM, 2nd Edition Figure 4shows the workflow of this edition. The four soft- ware modules are needed to be installed in the appropriate PACS and CAD components rst if those PACS components do not have the required functions. The challenge of this ver-sion is that the CAD developer has to collaborate closely with 123 158322 Int J CARS (2009) 4:317-329 Fig. 4 Data flow of the DICOM-PACS-IHETM2nd Edition and loca- tions of the four modules (yellow) of DICOM-PACS-IHETMin the CAD and PACS components (see also color code used in Fig. 3); numbers represent data flow steps during the integration. 1CAD Requests, 2 Query CAD worklist, work item claimed; 3Retrieve images for CAD; 4Worklist images/CAD results [18,19] Fig. 5 T h ed a t afl o wD I C O M - C A D - I H ETM3rd Edition shows the locations of the three software modules (yellow)i nt h eC A DS Rs e r v e r and PACS, respectively (see also color code used in Fig. 3); and the data flow steps (numbers). 1PACS Server pushes the CT image to CAD results to CAD SR Server which consists of the with a original images in the DICOM-SR CAD results in the PACS Serverfor reviewing both original images and SR. In this Edition, CAD SRServer also keeps all CAD results in SR format the PACS server manufacturer to fully understand the PACS workflow, which is different from the CAD-PACS integra- tion integrate CAD results i-PPM TMis not an easy task. DICOM-CAD-IHETM, 3rd Edition Figure 5shows the data flow. In this edition, the CAD has two components, the CAD WS and CAD SR Server. The lattertakes care of monitoring and archiving of CAD results, andretrieving original images and data from PACS. Examples of integrating using CAD-PACS toolkit Introduction to the examples This section shows two different examples of integrating CAD results into PACS clinical environment using the CAD- PACS integration toolkit. DICOM-SR is the ultimate CAD output required as the exchange object for integration, andthe assumption is that original images in which the CADresults were obtained are already stored in PACS. Both exam- ples require the use of several components of the toolkit to integrate the CAD system with the PACS system. The rstexample is easier to integrate because the CAD developed by a manufacturer has already converted CAD results to DICOM-SR format [ 8]. Whereas in the second example, the CAD is developed by an R&D research laboratory and it requires the use of the toolkit to convert CAD results to DICOM-SR format rst before the integration [ 9]. Table 2 summarizes different specications of integration of the CADwith PACS in these two examples. In order to have seamless integration between the two sys- tems, CAD and PACS, the following steps and componentsfrom the toolkit are required: (1) assign a DICOM node for the SR server, (2) establish connections between PACS and SR Server for image query and retrieval, (3) activate the CADWS/Server and the CAD SR Server to receive DICOM-SR objects, and (4) setting up Display-SR at the PACS WS. Integration of commercial CADs with PACS Example 1 demonstrates two CAD cases, CAD detection of lesions on chest CT images from a CAD application from GEHealthcare, Waukesha, WI (note: the algorithm was devel- oped by R2 Technology, Inc., Santa Clara, CA and was acquired by GE Healthcare) and CAD diagnosis of breastcancer on mammogram developed by a single CAD manufac- turer, Hologic's R2 Technology, Inc., Santa Clara, CA (note: the CAD method was developed by R2, the product wasacquired by Hologic) [10 ]. In both cases available CAD out- puts are already converted to DICOM-SR format by the man- ufacturer, and original images are already stored in PACS. The CAD-PACS integration can be summarized by thesesteps: (1) CAD WS or Server completes the CAD process and sends the DICOM-SR document contained CAD results to the SR Server (CAD-PACS toolkit), (2) SR Server utilizesthe Receive-SR module (toolkit) to store the DICOM-SR CAD results and automatically prefetches reference images from PACS, (3) CAD results are ready for viewing on PACSWS using Display-SR module (toolkit). 123 159Int J CARS (2009) 4:317-329 323 Table 2 Tasks and requirements for integrating CAD with PACS systems in the two examples Example Tasks & Requirements CAD algorithm CAD output format Integration tasks 1. Commercial CAD: Lesions on Chest CT & Developed Proprietary DICOM-SR document Store SR les in SR server and display Breast Cancer on mammogram SR on PACS WS 2. Research CAD Multiple sclerosis (MS) Developed Proprietary Text or Extensible markup Create SR Template and SR les, on MRI language (XML), Images Store SR les in SR server (DICOM/Bitmap) and display SR on PACS WS Fig. 6 Manufacturer's Chest CAD Report already in DICOM-SR format ( left) with referenced image and annotation (right ). Annotation (red circle) in the DICOM-SR allows the user to toggle it on or off. (Courtesy of: Hologic's R2 Technology, Inc., Santa Clara, CA for case materials) Figures 6and 7show the screenshots of a Chest CAD and a Mammogram CAD results in DICOM-SR format dis- played on a PACS WS, respectively. The top of each imageshows the patient information, whereas the left side displays the structured report and the right depicts the DICOM images with nodule/lesion identied with overlaid annotations. As shown in Fig. 6, the location of the chest nodule is extracted from DICOM-SR object and sent to the Display- SR module to display as annotations (red circle) on top of the original CT image. This information is stored separatelyfrom the DICOM images and allows annotation to be toggled on/off from the original image that is displayed. Similar for the case of mammography CAD in which the locations ofthe breast lesions are shown in blue crosses. The difference between Chest CAD and Mammography CAD are that (1) the CAD algorithms are different for different tissues/organs andfor different modalities, and (2) the structures of DICOM-SRobject are also different (see rectangular box annotation on the left of each gure). For example, Chest CAD SR does not reference the whole CT Chest Study but only those fewCT images (red fonts) with nodules detected; whereas Mam- mography CAD DICOM-SR object includes all four images (red fonts) in a screening mammography study. One of thereasons is that a CT study has many images and the SR shouldonly reference those images where the lesions were detected. Therefore, each CAD algorithm or CAD for a different body region should have a different SR template to present com-plete and precise CAD results. Integration of research laboratory CAD with PACS The second example is the integration of PACS with CAD of Multiple sclerosis (MS) on Magnetic resonance imag-ing (MRI) studies. MS is a progressive neurological disease 123 160324 Int J CARS (2009) 4:317-329 Fig. 7 Manufacturer's Mammography CAD Report already in DICOM-SR (left) with referenced image andannotation (right ). Note that the DICOM-SR format is differentfrom that in the CAD on CT(red fonts). Annotation (bluecrosses) in the DICOM-SRallows oroff (courtesy of: Hologic's R2Technology, Inc., Santa Clara,CA for case materials) affecting myelin pathways in the brain. Multiple lesions in the white matter can cause paralysis and severe motor disabil- ities of the affected patient. Symptoms are changes in sen-sation, visual problems, muscle weakness, and depression.Currently, MRI T1 and Fluid attenuated inversion recovery (FLAIR) pulse sequences are used for radiological diagnosis. In these images, MS appears as multiple white lesions in thewhite matter area of the brain. MRI is also used to follow-up and monitor the progress of the disease and the effective- ness of therapy after the patient is treated with drugs. SinceMRI provides excellent delineation of MS, it is fairly easy for radiologists to make the diagnosis. However, due to the possibility of a large number of multiple lesions in the MRI3-D volume set of the brain, it is tedious and time consum-ing to identify the 3-D aspect of each lesion and quantify the number and size of these lesions. Moreover, the quantitative reproducibility through human observers is poor. Augment-ing CAD with imaging informatics methods, a 3-D CAD MS package would facilitate the physician's timely diagno- sis, improve accuracy, and assess quantitatively the progressof drug therapy treatment. Figure 8shows the most common data obtained from 3-D CAD results. The data includes theoriginal 3-D MRI data set (Fig. 8a shows one MRI FLAIR image, CAD detected multiple lesions (Fig. 8b), radiologist identied lesions (Fig. 8c, normally not shown in the results, depicted here only for comparison purposes); color-codedMS lesions on each 2-D image (Fig. 8d, one slice; Fig. 8e, two slices; and Fig. 8f, all 26 slices). Figure 8g is the quan- titative results of all lesions detected by CAD. Figure 8hi s three 2-D oblique views of the brain overlaid with 26 MSlesions. The CAD results were generated through collabora- tion with Guardian Technologies, Inc. to develop the CAD algorithm.Currently, these results can be shown on the specialized MS detection CAD WS, but cannot be linked or viewed inthe daily clinical PACS WS. The PACS database does notcontain these results as DICOM objects, and the CAD WSor database does not know what other data the patient may have within the PACS. Generating the DICOM-SR document In this case, the CAD generates results as shown in Fig. 8 which includes number of lesions, 3-D coordinates of the lesions, volume of each lesion, and their 2-D presentationsin each detected MR slice at various oblique angles which canbe used to display for 3-D viewing on a 2-D monitor. They are in a text le and not in DICOM-SR format. The rst task in the integration is to convert these results to DICOM-SRformat. To convert the text le into DICOM-SR format, a special MS CAD template was rst dened which was tailored to sat-isfy the specic need for presenting complete results. Figure 9 shows an SR template for the MS application as discussedabove. Referencing to two ratied CAD SR in standard shownin Figs. 6and7, a new MS DICOM-SR object for this appli- cation based on the tree structure was dened, designed, andimplemented. This design, which utilizes the DICOM Stan-dard Supplement 23 and Computer Science terminologies, has a document root MS CAD (see Fig. 9) which branches into four parent nodes (detections, analyses, summary, and image library). For example, within this context, the detec- tions performed can have one or more child nodes, detection performed (1 n), with various detailed algorithms used for lesions detection. By the same token, the analyses performed 123 161Int J CARS (2009) 4:317-329 325 Fig. 8 The most commonly obtained data from 3-D MS CAD results. The data includes the original 3-D MRI data set.aA MRI FLAIR image; bCAD detected multiple lesions;cRadiologist identied lesions (normally not shown in theresults, depicted here forcomparison purpose only).dColor-coded MS lesions on a 2-D image; eOn two slices; fOn all slices. gThe quantitative results of all 26 lesions detectedby CAD. hThree oblique views of 2-D images with all 26 MSoverlaid. Green color shows theventricles (data source: courtesyof Drs. A. Gertych and B. Guo;and Guardian TechnologiesInternational Inc., Herndon, V A) parent node describes one or more methods of quantitative analysis performed on each lesion. Each analysis performedcan be further branched to one or multiple (1 n) grandchild nodes, single image nding. The nding summary parentnode is the most important part of an SR which includesCAD results. This node can branch into multiple child nodes(1n), each containing the name of the detection and anal- ysis methods together with detailed results of each lesion oneach single image nding. The detailed results include num- ber, size, location, and referenced image. The Image Library parent node is optional; however, in the MS SR, it is usedto reference original images where the CAD was performed 123 162326 Int J CARS (2009) 4:317-329 Fig. 9 Multiple sclerosis (MS) CAD SR Template. The SR template is designed following a tree structure starting from theDocument Root, which branchesinto four parent nodes; eachparent node branches to (1 n) child nodes and so forth Fig. 10 Use the PACS Simulator to verify the data flowbetween the integrated PACS and CAD systems [18 ,19].Top the PACS Simulator displayed Scientic Exhibitannually from 2000-2004[1,11,20-23].Bottom Workflow of CAD-PACS modules. The integration stepsin numerals are described in thetext on. The data structure format of each child can be obtained directly from the DICOM standard, Supplement 23. Using the CAD-PACS toolkit After the SR template was dened and designed, integrating the CAD with PACS can be implemented by using the tool- kit. The rst step is to use a PACS Simulator [1, 11,20-24]t o verify the data flow as shown in Fig. 10. The PACS Simulator has been a training tool for PACS and Imaging Informaticssince 2000 [1, 11,20-23] including to verify the HIPAA com- pliance [12 ,24] and is currently utilized as a research tool in CAD-PACS integration. The integrating steps can be summarized as follows: (1) conguration of i-CAD module with the MS SR templateand all data (measurements, nodule images, and summary)to create the DICOM-SR Object, (2) conguration of CADWS to run the CAD application automatically after receiving DICOM images from Modality Simulator or PACS simulator, (3) based on the SR Template, i-CAD module automaticallystarts to create an SR upon completion of the CAD process and the results are sent in DICOM-SR format to Receive-SR for storage, (4) SR-Server prefetches referenced images fromthe PACS Server, and (5) CAD results are ready for viewingon PACS WS. Figure 11is a screenshot of CAD MS results at the PACS WS which shows an example of MS DICOM-SR Object withone 3-D view of multiple oblique 2-D images obtained using DICOM SC (see Fig. 8h). Although, this example only dis- plays the 2-D oblique images, theoretically, the DICOM-SR specication includes image references and CAD results 123 163Int J CARS (2009) 4:317-329 327 Fig. 11 Multiple sclerosis (MS) CAD Report in DICOM-SR format (left) and a 2-D oblique image (right ). Refer to Fig. 8for original images and CAD results which can be used to display real time 3-D rendered images [9]. Discussion Currently, CAD and PACS are two separate independent sys- tems with only minimal communications between them. In this paper we described a CAD-PACS toolkit as a universal method to integrate CAD results with PACS in its daily clini-cal environment. The toolkit utilizes HL7 standard for textual data and the DICOM standard for imaging so that it follows the industrial standard for data format and communications.The method needs the DICOM-SR standard to reformat CAD results into an SR template so that they can be integrated as a component in the DICOM data mode for viewing on thePACS workstations. It also uses three IHE workflow pro-les: KIN, SINR, and PWF to facilitate data transmission and communication in clinical workflow. We have shown CAD examples to illustrate explicitly how to integrate exist-ing CAD results into PACS daily clinical operation. Picture Archiving and Communication System is a mature healthcare technology which continues accumulating treme-ndous amount of imaging data daily. Unfortunately, the vast majority of this data in PACS is hardly utilized except for daily clinical service. There are many other advantages forthe integrating CAD results with PACS. CAD is a grow-ing eld, its applications range from chest, breast, colon, brain, liver, skeletal, vascular, etc. Doi, in his 2007 survey [2], reports that the number of presentations in CAD at theAnnual RSNA (Radiological Society of North America) Sci- entic Assembly increased from 59 in 2000 to 163 in 2005, and it continues to grow at a rapid rate into 2006 and 2007. Atthe view point of a CAD developer, PACS has tremendously large databases that can help further improve the research and development of these new CAD methods. Integrating CADresults only adds to these databases by now providing quan-tied results that were previously unavailable through the standard DICOM image of a PACS study. In future, the CAD- PACS integration would also allow CAD to directly assessPACS data from algorithm development and validation. How- ever, to allow the CAD to directly query the PACS database still requires much further work mostly in administration andmanagement issues due to patient privacy and PACS man- ufactures closely guarding their respective proprietary data format. Because of the rich contents in the DICOM-SR, it benets CAD developers to produce a comprehensive and standard- ized results ndings and quantitative values in DICOM-SR format. The DICOM standard and template will guide theCAD developers to apply their knowledge in building a high quality and valuable reports for many other purposes. Post-processing of medical images after generated by the imaging modalities are often performed to enhance their 123 164328 Int J CARS (2009) 4:317-329 diagnosis values. Post-processing of medical images are dif- ferent from CAD in the sense that it produces some formsof display, some quantitative measurements, but does not provide detection nor diagnosis. To date, there are new tech- nologies available for quantitative measurements obtainedfrom post-processing or CAD that still reside within thepost-processing workstation or the CAD server in the clinical environment. There has been some collaboration between post-processing and CAD manufacturers with PACS manu-facturers to improve PACS workflow by providing an inte- grated PACS workstation. However, the integration has resulted in poor image quality performance and a return tostandalone post-processing workstations. With the introduc- tion of the CAD-PACS toolkit, even these results could be converted to DICOM-SR format and readily available fordirect query by PACS WS and thus revolutionizing clinicalworkflow from single event patient-based queries to longi- tudinal-based queries on valuable metadata and quantitative measurements. In addition, the trend of CAD and PACS integration is to incorporate CAD ndings and DICOM key image referenc-ing into its DICOM-compliant databases and services in theform of data objects. Using DICOM-SR, con- tent-based query/retrieval of DICOM imaging studies can be performed based on quantitative ndings rather than patientidentication and/or disease category; a demonstration appli-cation from our IPILab was presented at RSNA 2008 [ 14]. The advantages of query/retrieving content-based imagingdata can be a great benet for medical imaging research andclinical practice. The challenges we may face in this direction are several. Among them include: (1) advanced CAD meth- ods development in data mining to search for meaningfuldata within PACS for specic applications, (2) addressing the Institutional Review Board (IRB) issue of using human sub- jects for research with almost unlimited information withinthe PACS database, and (3) collaboration with medical cen-ters' PACS management and PACS manufacturers to open the PACS database for data access. Acknowledgments This research was and has been partially sup- ported by the National Institutes AAMTI - IAA, TATRC. References 1. Cao F, Huang HK, Liu B, Zhou Z, Zhang J, Mogel G (2001) Fault- tolerant PACS server, InfoRAD exhibit. The radiological societyof North America 87th scientic assembly and annual meeting,November 25-30, p 737 2. Doi K (2007) Computer-aided diagnosis in medical imaging: his- torical review, current doi: 10.1016/j.compmedimag. 2007.02.0023. DICOM Standard (2000) Supplement 50: Mammography CAD5. DICOM Standard (2001) Supplement 65: Chest CAD SR SOP Class 6. Huang HK, Doi K (2007) Editorial and special issue on CAD and image-guided decision support (2007). Comput Med Imag-ing Graph 31(4-5):195-197. doi:10.1016/j.compmedimag.2007.02.001 7. Health Level 7 (2008). http://www.hl7.org/ 8. Huang HK (2007) Tutorial on CAD-PACS integration. Computer assisted radiology and surgery, CARS 2007. Berlin, Germany, June27-30 9. Huang HK (2008) Tutorial on CAD-PACS integration. Computer assisted radiology and surgery, CARS 2008. Barcelona, Spain, June25-28 10. Hologic R 2 Home. http://www.r2tech.com/main/home/index.php 11. Huang HK, Cao F, Liu BJ, Zhou Z et al (2000) PACS simulator: a standalone educational tool, InfoRAD exhibit. The radiologi-cal society of North America 86th scientic assembly and annualmeeting, November 26-December 1, HHS\u2014Ofce of civil rights\u2014HIPAA (2008). http://www.hhs.gov/ ocr/hipaa 13. IHE (2008). http://www.ihe.net 14. Lee J, Le A, Liu BJ, Huang HK (2008) Integration of content- based DICOM-SR for CAD in the medical imaging informaticsdata grid with examples in CT chest, mammography, and bone-ageassessment, education exhibit. The radiological society of NorthAmerica 94th scientic assembly and annual meeting, November30-December 5, p 912 15. Le A, Mai L, Liu B, Huang HK (2008) The workflow and pro- cedures for automatic integration of a computer-aided diagnosisworkstation with a clinical PACS with real world examples. ProcSPIE Med Imaging 6919, 69190U:1-7 16. Le A, Zhou Z, Liu BJ, Huang HK, Le A (2007) A DICOM struc- tured report viewer and automatic workflow for CAD-PACS inte-gration in a clinical environment based on IHE proles. The radi-ological society of North America 93rd scientic assembly andannual meeting, November 25-30, p 835 17. Standards DICOM (2008). http://medical.nema.org/medical/ dicom/2008 18. Zhou Z, Le A, Liu B, Huang HK (2007) PACS-CAD toolkit for integrating an independent CAD workstation to diagnosis work-flow. Proc SPIE Med Imaging 6516, 651609:1-8 19. Zhou Z, Liu BJ, Le A (2007) CAD-PACS integration tool kit-based on DICOM screen capture (SC) and structured report(SR) and J Comput Med Imaging Graph 31(4-5):346-352. doi: 10.1016/j.compmedimag.2007.02.015 20. Zhou Z, Law M, Huang HK, Cao F, Liu B, Zhang J (2002) An educational RIS/PACS simulator, InfoRAD exhibit. The radiolog- ical society of North America 88th scientic assembly and annualmeeting, December 1-6, p 753 21. Zhou Z, Huang HK, Cao F, Liu BJ et al (2003) An educa- tional RIS/PACS simulator with web-based image distribution anddisplay exhibit. The radiological society of NorthAmerica 89th scientic assembly and annual meeting, November30-December 5, p 796 22. Zhou Z, Liu BJ, Huang HK, Zhang J (2004) Educational RIS/PACS simulator integrated with HIPAA compliant architecture (HCA)for auditing, InfoRad exhibit. The radiological society of NorthAmerica 90th scientic assembly and annual meeting, November28-December 3, p 827 23. Zhou Z, Huang HK, Liu BJ, Cao F, Zhang J, Mogel G, Law MA (2004) RIS/PACS simulator with web-based image distribution anddisplay system for education. Proceedings of the SPIE, vol 5371,pp 372-381 123 165Int J CARS (2009) 4:317-329 329 24. Zhou Z, Liu BJ, Huang HK, Zhang J (2005) Educational RIS/PACS simulator integrated with the HIPAA compliant auditing (HCA) SPIE 5748:491-500. doi:10.1117/12.595383 25. Zhou Z, Huang HK, Le A (2006) A PACS-CAD toolkit for integrating an independent CAD workstation to diagnosisworkflow based on DICOM SR and IHE proles. The radiologi-cal society of North America 93rd scientic assembly and annualmeeting, November 26-December 1, p 795 123 166Racial Differences in Growth Patterns of Children Assessedon the Basis of Bone Age 1 Aifeng Zhang, PhD James W. Sayre, PhDLinda Vachon, MDBrent J. Liu, PhDH. K. Huang, DScPurpose: To collect up-to-date data in healthy children to create a digital hand atlas (DHA) that can be used to evaluate, onthe basis of the Greulich and Pyle atlas method, racialdifferences in skeletal growth patterns of Asian, AfricanAmerican, white, and Hispanic children in the UnitedStates. Materials and Methods:This retrospective study was HIPAA compliant and ap-proved by the institutional review board. Informed con-sent was obtained from all subjects or their guardians.From May 1997 to March 2008, a DHA containing 1390hand and wrist radiographs obtained in male and femaleAsian, African American, white, and Hispanic childrenwith normal skeletal development was developed. The ageof subjects ranged from 1 day to 18 years. Each image wasread by two pediatric radiologists working independentlyand without knowledge of the subject's chronologic age,and evaluation was based on their experience with theGreulich and Pyle atlas. Statistical analyses were per-formed with the paired-samples ttest and analysis of vari- ance to study racial differences in growth patterns. P/H11349.05 indicated a signicant difference. Results: Bone age (P /H11349.05) was signicantly overestimated in Asian and Hispanic children. These children appear tomature sooner than their African American and whitepeers. This was seen in both male and female subjects,especially in girls aged 10-13 years and boys aged 11-15years. Conclusion: Ethnic and racial differences in growth patterns exist atcertain ages; however, the Greulich and Pyle atlas does notrecognize this fact. Assessment of bone age in childrenwith use of the Greulich and Pyle atlas can be improved byconsidering the subject's ethnicity. /H23040RSNA, 20081From the Image Processing and Informatics Lab, De- partment of Radiology, University of Southern California, 1450 San Pablo St, Suite 2100, Los Angeles, CA 90292(A.Z., B.J.L., H.K.H.); Department of Biostatistics and Ra-diological Sciences, University of California, Los Angeles,School of Public Health, Los Angeles, Calif (J.W.S.); andDepartment of Radiology, Los Angeles County Hospitaland University of Southern California Medical Center, LosAngeles, Calif (L.V.). From the 2007 RSNA Annual Meet-ing. Received March 10, 2008; revision requested May 1;revision received April 3; accepted June 20; nal versionaccepted July 9. Supported by 1\u2014January 2009Note: This copy is for your personal, non-commercial use only. To order presentation-ready copies for distribution to your colleagues or clients, use the Radiology Reprints form at the end of this article. 167Assessment of bone age is a clinical procedure used in pediatric radi-ology to evaluate skeletal matu- rity on the basis of bone growth in theleft hand and wrist, as seen on a radio-graph. The determination of skeletalmaturity (also referred to as bone age)plays an important role in the diagnosisand treatment of endocrinologic abnor-malities and growth disorders in chil-dren (1,2). In clinical practice, themethod most commonly used to assessbone age is matching of a radiograph ofthe left hand and wrist with the Greulichand Pyle atlas (3), which contains a ref-erence set of standard hand images col-lected in the 1950s in healthy white chil-dren who were members of the middleor upper class population. Over the past 30 years, many au- thors have questioned the appropriate-ness of using the Greulich and Pyle atlasfor bone age assessment in contempo-rary children. In 1975, Roche et al (4)showed that the average child in theUnited States was less physically maturethan the children in the Greulich andPyle atlas. In 1996, Ontell et al (5) ex-amined the applicability of the Greulichand Pyle standards to ethnically diversechildren. However, these studies andvarious others (6-8) did not provide alarge-scale systematic method for vali-dation. Thus, the purpose of our studywas to collect up-to-date data in healthychildren to create a digital hand atlas(DHA) that can be used to evaluate, onthe basis of the Greulich and Pyle atlasmethod, racial differences in skeletalgrowth patterns of Asian, AfricanAmerican, white, and Hispanic childrenin the United States. Materials and Methods The protocol of this retrospective studywas approved and has been renewedannually by the institutional reviewboards of our institutions, and writteninformed consent was obtained from allsubjects or their legal guardians. Thisstudy was compliant with the Health In-surance Portability and AccountabilityAct. Subject anonymity was achieved byreplacing the subject name and othertraceable information with a data en-cryption method. Subject Recruitment During the past 10 years (May 1997 toMarch 2008), a DHA has been developedthat contains 1390 hand and wrist radio-graphs obtained in healthy Asian, AfricanAmerican, white, and Hispanic boys andgirls. All subjects (age range, 1 day to 18years) were recruited from public schoolsin Los Angeles County, California, start-ing in the late 1990s (9-15). Case Selection Criteria Before the hand was examined with ra-diography, a physical examination wasperformed to determine the health andTanner maturity index (16) of the sub-ject to ensure that he or she was healthyand that his or her skeletal developmentwas normal. Height, trunk height, andweight were measured and used to cal-culate the body mass index. Image Acquisition Each radiograph of the hand and wristwas obtained with a rigorous data col-lection protocol (9). The radiographswere obtained with an x-ray generator(Polyphos 50; Siemens, Erlangen, Ger-many) at 55 kVp and 1.2 mAs. The radi-ation dose delivered per image was lessthan 1 mrem (0.01 mSv), which isequivalent to approximately 1 day ofnatural background radiation. The handwas adjusted to the correct position,which required the subject to keep hisor her ngers spread apart and main-tain hand straightness as much as possi-ble; no hand jewelry was worn. The dis-tance between the x-ray tube and theimage cassette was 40 inches. The handof a normal child was less than 1 inchthick; therefore, the magnication fac-tor was approximately 1. Image Interpretation After a radiograph of the hand was ac-quired in each subject, two experiencedpediatric radiologists (each with morethan 25 years of experience in bone ageassessment) performed independent Published online before print -235 Abbreviations: DHA/H11005digital and Communications in Medicine Author contributions:Guarantors of integrity of entire study, A.Z., B.J.L., H.K.H.;study concepts/study design or data acquisition or dataanalysis/interpretation, all authors; manuscript drafting ormanuscript revision for important intellectual content, allauthors; manuscript nal version approval, all research was supported by Health (grant nos. R01 LM stated no nancial relationship to disclose.Advances in Knowledge /H18546A digital hand atlas (DHA) of 1390 hand-wrist radiographs ob-tained in Asian, African Ameri-can, white, and Hispanic boys andgirls with normal skeletal develop-ment has been developed to pro-vide an up-to-date standard withwhich to assess growth and devel-opment and is accessible athttp://www.ipilab.org/BAAweb. /H18546Radiologists assigned a bone agethat was relatively close to thechronologic age in African Ameri-can and white children; however,cross-racial differences indicatedthat Asian and Hispanic childrenmature sooner than do AfricanAmerican and white children, es-pecially between 10 and 13 yearsof age in girls and between 11 and15 years of age in boys. Implication for Patient Care /H18546The discovery of cross-racial dif- ferences at different age rangessheds light on the possibility thatbone age assessment in childrencan be improved by considering achild's ethnicity, especially whenaccurate assessment of bone ageis crucial to patient care (optimalsurgical intervention in childrenwith leg length discrepancies).PEDIATRIC IMAGING: Differences in Growth Patterns Zhang et al Radiology: Volume 250: Number 1\u2014January 2009 229 168readings based on Greulich and Pyle at- las standards. During reading, radiolo-gists were blinded to the subject's chro-nologic age, race, and other pertinentinformation. The subject's bone age, as deter- mined by the radiologist, was comparedwith the subject's chronologic age. Theimage was selected and accepted tothe DHA only if the difference betweenthe subject's bone age, as determinedby the radiologist, and the subject's chro-nologic age was less than 3 years. Theacceptance rate was higher than 90%. Image Digitization For data analysis, Web-based imageand data distribution, and communica-tion in the clinical environment andpublic domain, each accepted radio-graph (subject name and identicationwere covered with black tape) was digi-tized into the Digital Imaging and Com-munications in Medicine (DICOM) for-mat by using a laser lm (Ar-ray, Tokyo, furthermore, eachsubject's information (excluding name and identication, as well asany other traceable data) was put in theDICOM header (17-19). We used thefollowing parameters: 12 bits per pixel,optical density of 0.0-4.0, and 100- /H9262m pixel spacing. The size of the image cor-responded to the size of the original ra-diograph. Table 1 contains the pertinentinformation of four 14-year-old boys ofdifferent races. The corresponding ra-diographs of their hands are shown inFigure 1. Data Collection Summary There were two cycles of data collection,each of which had eight categories (Asianboys, Asian girls, African-American boys,African-American girls, white boys, whitegirls, Hispanic boys, and Hispanic girls).Each category contained 19 age groups(one for subjects younger than 1 year and18 set at 1-year intervals for subjects aged1-18 years). The two pediatric radiolo-gists independently read all images ob-tained in each cycle. Cycle 1 consisted of1103 digitized hand images with demo-graphic data. Five cases for each youngerage group (1-9 years) and 10 cases foreach older age group (10-18 years) wereincluded. The sample sizes were chosento achieve a precision of approximately0.20 for all age groups, with a 95% con-dence interval when using the digital handatlas to compare bone age with chrono-logic age. Precision is dened as the con-dence interval width divided by the esti-mated mean value of chronologic age.Subjects younger than 1 year were con-sidered infants, and their data were notused for analysis. In order to study the active growth period in children aged 5-14 yearsmore carefully to yield better statistics, Figure 1 Figure 1: Examples of radiographs obtained in (a)a 14.13-year-old Asian boy, (b)a boy,(c)a 14.79-year-old white boy, and (d)a 14.64-year-old Hispanic boy. Corresponding demographic data and bone age, as assigned by two radiologists, are included in the DICOM image header (Table 1).PEDIATRIC IMAGING: Differences in Growth Patterns Zhang et al 230 Radiology: Volume 250: Number 1\u2014January 2009 169data were collected in 287 subjects dur- ing the second cycle after the rst cyclehad been completed. Thus, a total of1390 cases were included in the DHA.The breakdown of cases was as follows:167 Asian girls, 167 Asian boys, 174African American girls, 184 AfricanAmerican boys, 166 white girls, 167white boys, 183 Hispanic girls, and 182Hispanic boys. These 1390 cases wereused to derive the results described inthis article.Statistical Analysis Statistical analysis was performed withcomputer software (SPSS, Software,Reading, Pa). Two of analysis, thepaired-samples ttest and analysis of vari- ance, were performed by using chrono-logic age as the reference standard. Datafrom subjects in the newborn group werenot used for analysis. P/H11349.05 indicated a signicant difference. Data acquired in both cycles for each race and a given sex were com-bined with data for the entire age range(1-18 years), and the paired-samples t test was performed on a case-by-casebasis to nd the mean difference be-tween the average bone age of two read-ings and the chronologic age. This re-sulted in eight categories for compari-son: Asian boys, Asian girls, AfricanAmerican boys, African American girls,white boys, white girls, Hispanic boys,and Hispanic girls, each depicting theoverall view of differences between theradiologists' average bone age readingagainst the chronologic age for subjectsof each race and sex. On the basis of the effects of the growth factor and sexual hormones, as well as ourobservations in the phalangeal, carpal, andwrist joint regions (9-15), we divided theentire growth age ranging from 1 year to 18years into four age subsets, as shown inFigure 2. These subsets were used to studydifferences in growth patterns of children ofdifferent races in a given subset. Analysis ofvariance was used to study the cross-racialcomparisons for a given subset of growthrange on the basis of differences betweenchronologic age and bone age. Results Radiologist Interpretation Table 2 shows the mean difference inage between the average bone age as-Figure 2 Figure 2: Charts show the four divided age subsets for (a)girls and (b)boys. These charts provide a road map for use in the study of racial differences during different growth periods. Ina, purple indicates 1-5 years of age; orange, 6 -9years of age; green, 10 -13 years of age; and blue,14 -18 years of age. In b, purple indicates 1-7 years of age; orange, 8 -10 years of age; green,11-15 years of age; and blue, 16 -18 years of age. Table 1 Pertinent Information in Four 14-year-old Boys of Different Races Subject No. Race Sex Birth Date Examination DateChronologicAge (y)TannerMaturityIndex ScoreHeight(cm)TrunkHeight(cm)Weight(kg)Bone AgeAssigned byReader 1 (y)Bone AgeAssigned byReader 2 (y) 1 Asian Male May 26, 1987 July 12, 2001 14.13 5 170.00 88.90 55.50 15.75 15.50 2 African American Male June 18, 1981 December 3, 1995 14.46 3.5 168.00 82.55 49.30 13.25 14.003 White Male 19, 1994 14.79 4 169.00 86.70 56.00 14.00 14.50 4 Hispanic Male September 13, 1983 May 6, 1998 14.64 5 168.40 demographic and health-related information, as well as the bone age assigned by the radiologists. These data, along with the corresponding image, can be retrieved from the Web-based DHA.Table 2 Mean Difference between Bone Age Assigned by Radiologists and Chronologic Age according to Race and Sex CharacteristicAsian African American White Hispanic Girls Boys Girls Boys Girls Boys Girls Boys Mean difference between bone age assigned by radiologists andchronologic age (y)0.24* 0.41* 0.03 /H110020.02 /H110020.15* 0.01 0.24* 0.30* No. of cases 166 165 170 179 163 164 182 178 * Mean difference between bone age assigned by radiologists and chronologic age was signicant ( P/H11349.05). Infants (patients younger than 1 year) were excluded from analysis.PEDIATRIC IMAGING: Differences in Growth Patterns Zhang et al Radiology: Volume 250: Number 1\u2014January 2009 231 170signed by two radiologists and the chro- nologic age for each of the eight catego-ries separated by race and sex. Since wecollected data in children with normalskeletal development, the differenceswith asterisks shown in Table 2 arewithin 2 standard deviations betweenthe normal chronologic age and the av-erage bone age (see the Case SelectionCriteria section) and may not be impor-tant from a clinical perspective. How-ever, we were able to conclude that theradiologists had a slight tendency,which was statistically signicant, tooverestimate bone age in the Asian andHispanic populations as a whole. Cross-racial Comparisons The cross-racial differences assessedwith analysis of variance among the fourraces in the four divided age subsets(Fig 2) are presented in Figure 3. Figure 3a shows that in girls, signi- cant mean differences of average read-ing between races were observed in thethird age subset (10-13 years). Radiol-ogists overestimated bone age in Asiangirls in comparison with their AfricanAmerican and white peers by approxi-mately 0.59 year and 0.70 year, respec-tively. Similarly, radiologists overesti-mated bone age by 0.58 year in Hispanicgirls when compared with AfricanAmerican girls. Figure 4 shows plots ofbone age versus chronologic age inAsian girls versus white girls, Asian girlsversus African American girls, and His-panic girls versus African Americangirls. In each comparison, the gure onthe left covers the entire age range(1-18 years), whereas the gure on theright shows a close-up view of the thirdage subset (10-13 years). Similar patterns were also observed in boys (Fig 3). In the third age subset(11-15 years), signicant overestima-tion of bone age of 0.97 year and 0.83year was observed in Asian and His-panic boys, respectively, when com-pared with African American boys.Overestimation of 0.65 year continueduntil the fourth age subset (16-18years) when Asian boys were comparedwith African American boys. Further-more, comparison of white boys withAsian and Hispanic boys in the third agesubset (11-15 years) resulted in signif-icant overreading of 0.59 year and 0.46year, respectively. Figure 5 shows boneage versus chronologic age in four racialpairs: (a)Hispanic boys versus African American boys, (b)Asian boys versusAfrican American boys, (c)Asian boys versus white boys, and (d) Hispanic boys versus white boys. Discussion An up-to-date DHA for four ethnicgroups has been developed with 1390hand and wrist radiographs obtained inAsian, African American, white andHispanic boys and girls with normalskeletal development aged between 1day and 18 years. Each case was read bytwo pediatric radiologists working inde-pendently on the basis of the Greulichand Pyle atlas standard. The normalityand consistency of the data were en-sured by radiologists' readings and a rig-orous quality assurance data collectionprotocol. Hand radiographs were digi-tized and stored in the DICOM format,which facilitates image viewing andtransmission in the clinical environmentfor training and image-assisted dailyclinical operation. Previous studies, in which research- ers examined the applicability of theGreulich and Pyle atlas for use in con-temporary children, have been per-formed: Mora et al (7) examined 534children of European and African de-Figure 3 Figure 3: Charts show cross-racial comparisons of (a)girls and (b)boys. Data are shown only if differences are signicant (P /H11349.05). Each racial block was divided into four age groups, as described in Figure 2. The plus and minus signs indicate under- and overestimation of bone age, respectively, by radiologists in comparing rows with columns. AAF/H11005African American girl, AAM/H11005African American boy, ASF/H11005Asian HIF/H11005Hispanic girl,HIM/H11005Hispanic boy.PEDIATRIC IMAGING: Differences in Radiology: Volume 250: Number 1\u2014January 2009 171scent, and Ontell et al (5) collected data in 765 trauma patients of four races.Both of these studies are similar to ourstudy in that they involved use and eval-uation of the Greulich and Pyle atlas ineach of the racial groups. However, inneither study did the authors comparecross-racial differences. Our study dif-fered from the aforementioned studiesin that our study consisted of a robustlydesigned database of 1390 carefullychosen healthy subjects and we com-pared cross-racial growth differences. By using the DHA, we observed dif-ferences in the readings of two pediatricradiologists in subjects of four races onthe basis of the Greulich and Pyle atlasstandard, and we recorded these differ-ences systematically. Our results showthe cross-racial differences betweenskeletal growth patterns of Asian andHispanic children and skeletal growthpatterns of white and African Americanchildren. Radiologists assigned a boneage that was relatively close to the chro-nologic age of African American andwhite children. However, bone age andchronologic age were signicantly dif-ferent in Asian and Hispanic children.Cross-racial differences in four age sub-sets indicate that Asian and Hispanicchildren mature earlier than AfricanAmerican and white children. Thisholds true for girls and boys, especiallythose aged 10-13 years and 11-15years, respectively. Genetic differences, diet, and nutri- tional intake may influence variations inthe bone growth pattern. This calls intoquestion the applicability of the Greu-lich and Pyle atlas as a reference forchildren of different races. Our resultssuggest that bone age assessment inchildren can be improved by consider-ing the ethnic population. An institu-tional review board-approved clinicalvalidation study of the usefulness of theDHA is being performed at our institu-tion (Los Angeles County Women's andChildren's Hospital, Los Angeles, Calif). Our study had limitations that should be considered in future re-search. First, all subjects enrolled inthis study were from the Los Angelesmetropolitan area. Further studies withdata collection from different geo-graphic regions are necessary to studyregional factors in skeletal develop-ment. Second, mixed ethnicity was notconsidered. This issue should be ad-dressed in future studies, with a viewtoward comparison of skeletal develop-ment in children with mixed ethnicitywith that in children of their parents'ethnicities. Third, we investigated theeffect of ethnicity in only those childrenwhose skeletal development was con-sidered normal on the basis of the Greu-lich and Pyle atlas. Fourth, a subject'sethnicity is usually unavailable in daily Figure 4 Figure 4: Graphs show comparisons of three racial pairs. The x-axis shows the chronologic age, the y-axis shows the average bone age, and the thin 45\u00b0 dotted line shows the normal standard comparison in (a)Asian girls (ASF) versus white girls (CAF), (b)Asian girls versus African American girls (AAF), and(c)Hispanic girls (HIF) versus African American girls. The graphs on the left show the plots for the entire age range, whereas the graphs on the right are close-up plots for the third age subset (10 -13 years).PEDIATRIC IMAGING: Differences in Growth Patterns Zhang al Radiology: Volume 250: Number 1\u2014January 2009 233 172practice. This limits future applications of the DHA in clinical practice. This is-sue needs to be addressed in patientcare when enough attention has beenbrought to the racial factor in bone ageassessment in children. The DHA provides an up-to-date standard with which to classify normalbone growth and development in chil-dren. Currently, the DHA is accessiblefrom the World Wide Web for onlinelearning and teaching. Also, a computer-assisted bone age assessment system foruse with the DHA has been developedand distributed to several internationalinstitutions (20) for use in a multicenterstudy. Acknowledgments: We thank the National In- stitutes of Health for supporting this research; the Bone Development Group at the ChildrensHospital, Los Angeles, Calif, for data collection;and James Hill, MD, JD, for his assistance in theliterature search and manuscript revision. References 1. Tanner JM, Healy MJR, Goldstein H, Cameron N. Assessment of skeletal maturity and predic- tion of adult height (TW3 method). London,England: Saunders, 2001. 2. Kirks D. Practical pediatric imaging. In: Di- agnostic radiology of and 3. Greulich WW, Pyle SI. Radiographic atlas of skeletal development of the hand and wrist.Stanford, Calif: Stanford University Press,1959. 4. Roche AF, Roberts J, PV. Skeletal maturity of children 6-11 years: racial, geo-graphic area and socioeconomic differen-tials. In: National Health Survey. Rockville,Md: Health Resources Administration, Na-tional Center for Health Statistics, 1975;1-38. 5. Ontell FK, Ivanovic M, Ablin DS, Barlow TW. Bone age in children of diverse ethnic-ity. AJR Am J Roentgenol 1996;167:1395-1398. 6. Loder RT, Estle Morrison K, et Appli- cability of the Greulich and Pyle skeletal agestandards to black and white children of to-day. Am J Dis Child 1993;147:1329-1333. 7. Mora S, Boechat MI, Pietka E, Huang HK, Gilsanz V. Skeletal age determinations inchildren of European and African of the Greulich and Pyle stan-dards. Pediatr Res 2001;50:624-628.Figure 5 Figure 5: Comparisons (as in Fig 4) of (a)Hispanic (HIM) versus African American boys (AAM), (b)Asian (ASM) versus African American boys; (c)Asian versus white boys (CAM); and(d)Hispanic versus white boys. Left: entire age range. Right: third age subset (11-15 years) (a, c, d) and third and fourth age subsets (11-18 years) (b).PEDIATRIC IMAGING: Differences in Growth Patterns Zhang al 234 Radiology: Volume 250: Number 1\u2014January 2009 1738. Masse G, Hunt EE. Skeletal maturation of the hand and wrist in West African children. Hum Biol 1963;35:3-25. 9. Gertych A, Zhang A, Sayre J, Pospiech- Kurkowska S, Huang HK. Bone age assess-ment of children using a digital hand atlas.Comput Med Imaging Graph 2007;31:322-331. 10. Zhang A, Tsao S, Sayre J, Gertych A, Liu BJ, Huang HK. Is Greulich and Pyle atlas still for 11. Pietka E, Pospiech-Kurkowska F, Huang HK. Pietka BE, Pospiech S, Cao F, Huang HK, Gilsanz V. Computer automatedapproach to the extraction of epiphyseal re-gions in hand radiographs. J Digit Imaging2001;14:165-172. 13. Zhang A, Gertych A, Liu BJ. Automatic bone age assessment for young children from new-born to 7-year-old using carpal bones. Com-put Med Imaging Graph 2007;31:299-310. 14. Huang HK, Zhang A, Liu BJ, et al. Data grid for large-scale medical image archive and analysis.Proceedings of the 13th ACM InternationalConference on Multimedia. Singapore: Associ-ation for Computing Machinery, 2005; 1005-1013. 15. Zhang A, Gertych A, Liu BJ, Huang HK. Data mining and visualization of average images ina digital hand atlas. In: Ratib OM, Horii SC,eds. Engineering, JM. Growth at adolescence. Oxford, England: Blackwell Scientic Publications,1962.17. Huang HK. PACS and imaging informatics: basic principles and applications. Hoboken,NJ: Wiley, 2004; 504-507. 18. Zhang A, Zhou Z, Gertych A, Liu BJ, Huang HK. Integration of bone age assessmentCAD results with the PACS diagnostic work-flow utilizing DICOM structure report [ab-str]. In: Radiological Society of North Amer-ica scientic assembly and annual meetingprogram. Oak Brook, Ill: Radiological Soci-ety of North America, 2006; 909. 19. Zhou Z, Liu BJ, Le AH. CAD-PACS integra- tion tool kit based on DICOM secondary cap-ture, structured report and IHE workflowproles. Comput Med Imaging Graph 2007;31:346-352. 20. Law M, Chan T, Tang FH, Lau TY, Huang HK, Zhang A. A retrospective study of boneage assessment of Chinese children in HongKong using a digital hand atlas [abstr]. In:Radiological Society of North America scien-tic assembly and annual meeting program.Oak Brook, Ill: Radiological Society of NorthAmerica, 2006; 909.PEDIATRIC IMAGING: Differences in Patterns Zhang Radiology: Volume 250: Number 1\u2014January 2009 235 174Feature Selection and Performance Evaluation of Support Vector Machine (SVM)-Based Classifier for Differentiating Benign and are lots of work being done to develop computer- assisted diagnosis and detection (CAD) technologies andsystems to improve the diagnostic quality for pulmonarynodules. Another way to improve accuracy of diagnosis on new images is to recall or find images with similar features from archived historical images which alreadyhave confirmed diagnostic results, and the content-based image retrieval (CBIR) technology has been proposed for this purpose. In this paper, we present a method to find and select texture features of solitarypulmonary nodules (SPNs) detected by computed to- mography (CT) performance of support classifiers in differentiatingbenign from malignant SPNs. Seventy-seven biopsy-confirmed CT cases of SPNs were included in this study. A total of 67 features were extracted by a feature extraction procedure, and around 25 features werefinally selected after 300 genetic generations. Weconstructed the SVM-based classifier with the selected features and evaluated the performance of the classifier by comparing the classification results of the SVM-based classifier with six senior radiologists observa- tions. The evaluation results not only showed that most of the selected features are characteristics frequently considered by radiologists and used in CAD analysespreviously reported in classifying SPNs, but also indicat- ed that some newly found features have important contribution in differentiating benign from malignantSPNs in SVM-based feature space. The results of thisresearch can be used to build the highly efficient feature index of a CBIR system for CT images with pulmonary nodules. KEY WORDS: Feature selection, content-based image retrieval, classification, CT images, lung diseases INTRODUCTION Solitary pulmonary nodules (SPNs) are com- mon findings in thoracic imaging. The volu- metric computed tomography (CT) technique hasintroduced spiral scans which shorten the scantime and, when used in thoracic imaging, reduce the artifacts caused by partial volume effects, cardiac motion, and unequal respiratory cycles.For these reasons, spiral CT is useful in identifyingand characterizing SPNs. However, it is still difficult for radiologists to distinguish malignant from benign nodules. Dif-ferentiating malignant nodules from benign onesby visual examination is subjective and the results vary between different observers and in different cases. In general, experienced radiologists classifynodules more accurately than resident radiologists.The necessity for reliable and objective analysishas prompted the development of computer-aidedsystems. It is reported that two radiologists working together outperform any independent radiologist. The computer-assisted diagnosis and detection (CAD) system can provide a \"second opinion, \" which might improve the radiologist' s perfor- mance. One study has demonstrated that radiolog-ists more accurately classified SPNs (as measuredby area under the receiving operating characteristic 1From the Shanghai Institute of Technical Physics, Chinese Academy of Sciences, 500 Yu Tian Road, Shanghai, 200083, China. 2From the Department of Radiology, Huadong Hospital, Shanghai, China. Correspondence to: Jianguo Zhang, Shanghai Institute of Technical Physics, Chinese Academy of Sciences, 500 Yu Tian Road, Shanghai, Informatics in Medicine Online publication 26 February 2009doi: 10.1007/s10278-009-9185-9 Journal of Digital Imaging, Vol 23, No 1 (February), 2010: pp 51 Y65 51 175(ROC) curve (AUC)) with CAD assistance.1Recent studies have focused on the role of CAD in differentiating and characterizing pulmonary nod-ules. These reports discuss characteristics ofnodules demonstrated to be relevant to theirclassification. 2-8For example, the presence of calcification and/or fat indicates that the noduleis likely to be benign, while irregular marginsand heterogeneous attenuation are signs of ma-lignancy. 9Another way to improve accuracy of diagnosis on new images is to recall or findimages with similar features from archived his-torical images which already have confirmeddiagnostic results, 10and content-based image retrieval (CBIR) technology is now proposed forthis purpose in digital imaging and managementenvironment. 11,12 Selecting the right features and constructing the higher performed classifier of pulmonary nodulesare very important in developing the qualifiedCAD and CBIR systems. For example, most of theCAD systems consist of two steps: feature extrac- tion and classification. In CBIR, the large amount of visual features such as shape, texture, andgranulometry are usually included to build thesearching index. 13 Some studies have been done on finding and selecting features and evaluating the performanceof classifiers of lung nodule and tissues for CADand CBIR purposes. 14-20In feature selection studies, most researches focused on differentiatingthe visual features of pulmonary nodules andtissues, and there were few considerations aboutthe differentiating features for classifying benignfrom malignant SPNs. In classifier for lung artificial neural networks (ANN) werestudied intensively. 2-8However, in LDA, the complex decision surface might not be linear. InANN, it was difficult to determine the number ofunits in the hidden layer and its gradient-basedalgorithm might be trapped in local minima. In this paper, we present a method for selecting pattern features of pulmonary nodules of CTimages and evaluate the performance of supportvector machine (SVM)-based classifiers in differ- entiating structed the SVM-based classifier with the selectedfeatures using a genetic generation procedure andevaluated the performance of the classifier bycomparing the classification results of the SVM-based classifier with two groups of senior andjunior radiologists observations, as well as the results of the neural-network-based classifier. Theresults of this research are not only helpful toimprove CAD for diagnosis on SPNs but alsouseful to build the highly efficient feature index of a CBIR system for CT images with pulmonary nodules. We discussed the impacts of nodulesegmentation results and kernel function selectionon the performances of SVM-based classifier indifferentiating benign from malignant SPNs. MATERIALS AND METHODS Materials High-resolution scans of 77 patients with soli- tary pulmonary nodules mostly less than 3 cmperformed between October 1999 and December2006 were included in our study. The selectioncriteria included the following: nodules weresolitary, and there was no calcification or artifacts from cardiac motion or beam hardening from adjacent bone. Definitive diagnoses were obtainedin each case by cytological or histopathologicalexamination of surgical specimens and CT-guidedtransthoracic needle aspiration biopsy or based onclinical data such as no radiological evidence ofnodular growth during two or more years offollow-up. Among the 77 patients, 48 were men and 29 were women (age range, 27 -86 years; mean, 57.97 years). There were 43 malignant cases (27adenocarcinoma, nine squamous cell carcinoma,four small cell carcinoma, and three adenosqua-mous carcinoma). Thirty-four cases were benign(17 pulmonary hamartomas, eight cases of pulmo-nary tuberculosis, five cases of inflammatory pseudotumor, and four cases of pneumonia). Four of the 77 cases were larger than 3 cm. The largestwas 4.48 cm; the smallest was 0.54 cm and themean diameter was 1.90 cm. Among the 77 cases,31 were larger than 2 cm, while seven out of the31 cases were benign and 24 were malignant.Large nodules were inclined to be malignant,which dovetailed with the radiologists 'knowledge. The images were obtained by Somatom Plus (Siemens AG, Germany) and Somatom 16 (Sie-mens AG, Germany) CT scanners with thefollowing parameters: 120 kV, 100 mA, 1-s52 ZHU ET AL. 176scanning time, and a standard reconstruction algorithm for the Somatom Plus scanner and120 kV, 250 mA, 0.5-s scanning time, and astandard reconstruction algorithm (B41f) for theSomatom 16 scanner. Some patients had additionalscans covering the tumors. Nodule Segmentation We used two methods to perform nodule segmentation in our study: the region-grow andthe snake techniques. First, we can identify theboundary of most nodules by using the region-grow method from a user-specified seed pointinside the nodule with adjustable thresholds. Thisregion-grow method has also been used in otherlung nodule segmentation applications. 2,7Howev- er, the region-grow technique could not be appliedif the nodule contacted with vessels or the chestwall. In those cases, we applied the snake approachafter using region grow. We have 77 cases ofimages; 61 of these case images can be segmentedby using region grow, and 14 should be segmentedby using both region-grow method and snakeapproach, and only two cases of images must be segmented by user interactively. The times required to segment a nodule with our region-grow soft-ware program were about 4 s averagely. Figure 1 shows two examples of nodules for which theborders were identified by each of these twotechniques.Due to partial volume averaging effects, the spikes of some nodules had much lower attenu-ations than the center of the nodule. As a result, theborder of the spikes identified by the region-growmethod was not sharp. The snake methoddepended on its initial border and did not trace the exact border of the nodule in some cases, but, in such cases, we reinitialized the process to get asatisfied result. The segmentation results coveredmost of the nodule area and captured mostcharacteristics of the borders. In our study, thesegmentation results were all approved by anexperienced radiologist. Feature Extraction In image pattern recognition, feature extraction is the first step in image classification. The visualfeatures of lung nodules, such as the size, shape,and internal texture, were considered in our study,as such characteristics would be considered by theradiologist when classifying a nodule as malignantor benign. For example, nodules with calcificationor fat are more likely to be benign, whereas irregularborders suggest malignancy. To characterize nod- ules, we also tried to capture other features that may suggest malignancy, such as attenuation statistics,Gabor filter responses, w avelet decomposition features, multiscale Hurst parameters, and so on. We performed specific feature extraction of lung CT images with nodules based on the following Fig 1. The segmentation results of two pulmonary nodules.FEATURE SELECTION AND PERFORMANCE EVALUATION OF SVM-BASED CLASSIFIER 53 177parameters: the first-order statistics features (fea- ture 1 to feature 14) describe the attenuationdistribution and the shape of the histogram; thesecond-order statistics features (feature 15 tofeature 34) describe the spatial dependency ofpixel values, particularly, entropy features repre- sent the smoothness of the region of interest (ROI); the Gabor features (feature 35 to feature 46)capture the directional information at differentscales; the wavelet frame decomposition features(feature 47 to feature 55) represent the energy ofthe decomposed image; the multiscale Hurstfeatures (feature 56 to feature 61) describe theroughness of the ROI at different scales; and shape features represent the area, perimeter, irregularity of the border, and size of the ROI. A complete listof the features is provided in Table 1. Some features have good discriminant power, whileother features contribute little to the classification.Therefore, the extracted features must be subjectedto an optimal selection procedure before beingused in classification. This selection procedure is further described in the next section.Algorithms of Feature Selection, Statistical Classification, and Analysis We enrolled 77 cases of SPNs in this study and extracted 67 features for each image. Thus, therewas a high possibility of overfitting during the classification step due to the low number ofsamples relative to the number of featuresextracted. For this reason, it was necessary toreduce the high dimensionality of the input featurevectors. In this study, we employed a genetic-algorithm- based feature selection technique to recreate multiple groups of feature subsets with different numbers of features (between five and 30 of thetotal 67 features were used in each analysis). Thisallows us to evaluate the performance of eachclassifier built by different groups of featuresubsets. We also introduced the support-vector-machine-based classifier in this section to classifythe SPNs as well and its related algorithm. In order to evaluate the performance of the classifiers in differentiating the malignant nodules from SPNs,the ROC analysis was also included in this section. Genetic Algorithm for Feature Selection Feature selection is a combinational optimiza- tion approach to a problem that is difficult to solvedirectly. The genetic algorithm is a generaloptimization method that is useful especially for computation-intensive applications. It mimics the evolution process in biology by representing thesolution of the problem as genomes. The crossoverof good genomes (indicated by small fitness value)tends to yield better results, and a certain proba-bility of mutation allows for exploration of thewhole solution space. After many generations ofcrossover and mutation, the algorithm yields an acceptable solution. In this study, each generation had the same number of features, and the fitness function was defined as the misclassification rate of a tenfoldcross-validation procedure. In this procedure, thesamples were divided randomly into ten groups,while one group was used as test data; the rest ofthe samples were used to fit a multivariate normal- density function. The test data were classified based on likelihood ratios. After each group hadacted as test group exactly once, the fitnessfunction was calculated as the misclassification Table 1. A Complete List of Features Extracted for Lung Nodules in CT Images Feature extraction methods Feature no. Feature First-order statistics110 HIST1, MIND 67 MAXD54 ZHU ET AL. 178rate. The smaller the value was, the better the was fitness of the genome. Figure 2showed an evolution process of mean fitness and best fitnesswith the increasing of generations, in which thenumber of features was fixed to 25, and thenumber of genomes in each population was 100, and the number of generations was 300. It demonstrates that both the mean fitness and thebest fitness values drop drastically after about 50generations. Support Vector Machine Support vector machine is based on the structural risk minimization principle. It is reported that SVM outperforms other classifiers in many studies. 21,22 The SVM approach enjoys many attributes. It is less computationally intense in comparison to artificialneural networks. It performs well in high-dimen-sional spaces and also well on both training dataand testing data but does not suffer from the smallsize of training dataset as do other kinds ofclassifiers since the decision surface of SVM-based classifier is determined by the inner product of training data. The basic idea of SVM is to construct a hyperplane that maximizes the margin betweennegative and positive examples. The hyperplane isdetermined by the examples called support vectorsthat are closest to the decision surface. Thedecision surface is determined by the inner productof training data, which enables us to map the inputvectors through function into a higher-dimen- sional inner product space called feature space. The feature space could be implicitly defined by kernel K(x,y). To tolerate noise and outliers and to avoid overfitting, slack variables iare introduced which allows the margin constraints to be violated.23 Consider the training samples ( xi,yi),i=1,...,m, where each point xiis an input vector with label yi {1, 1}. The decision surface has the form:23 y\u00bc/C20x;w\u00f0\u00de \u00fe b \u00f01\u00de The decision surface is the solution of the following optimization problem: minimize :1 2/C20w;w\u00f0\u00de \u00fe a parameter chosen by the user to penalize decision errors and 8is the mapping Fig 2. The evolution of best fitness and mean fitness value with increasing numbers of generations, in which the number of features was fixed to 25; the number of genomes in each population was 100, and the number of generations was 300.FEATURE SELECTION AND PERFORMANCE EVALUATION OF SVM-BASED CLASSIFIER 55 179determined by the kernel function. The most popular kernel is the Gaussian kernel functionwhich is defined by: /C20x;y\u00f0\u00de \u00bc e /C0/C13x/C0y\u00f0\u00dekk2\u00f04\u00de where is also chosen by the user. In our study, the value of Cwas chosen to be 50 and the value of was chosen to be 1, and those values had good performance in the application.We will discuss in more detail why we chooseGaussian kernel function in \"Reliability of Nodule Segmentation and Its Impact on the SVM-BasedClassifier .\" ROC Analysis An ROC graph is a technique for visualizing the performance of classifiers and is useful to comparethe performance of different classifiers in medicaldecision-making systems. The graph depicts thetradeoff between the true-positive and false-positive rates. While an ROC graph is a two-dimensional description of classifier performance, it is often useful to reduce it to one scalar value. The AUC is largely adopted to represent theexpected performance of a classifier. The AUC ofa classifier is equivalent to the probability that theclassifier will rank a randomly chosen positiveinstance higher than a randomly chosen negativeinstance. 24 RESULTS Feature Selection of CT Images with SPN We enrolled 77 cases in this study as described in\"Materials \"and extracted 67 features for each SPN. Since the dimensionality of the feature space is comparable to the number of samples, feature selection was carried out using a genetic algorithmas mentioned in \"Genetic Algorithm for Feature Selection .\"The results of some selected feature subsets are shown in Table 2. There are about 30 subsets and each of the subset contains the numberof selected features from five to 30. The next stepis to determine the relevance of each selected feature to the process of differentiating benign and malignant nodules. During the evaluation process by using the genetic algorithm, some features may be selectedmany times as the number of generation increases.The more times it was selected, the more importantit contributed to the final generation of selectedfeatures. The number of times each feature wasselected is provided in Table 3. From Table 3,w e see that HIST1, HIST4, HIST10, ENTR3, ENTR4,GAB2, COMP, and MEAND were present in morethan half of the feature subsets. The feature selection results were consistent with the knowl- edge of the radiologists. For example, the fourthhistogram feature which indicated the presence offat existed in most feature subsets. This isconsistent with radiologists 'knowledge that the presence of fat suggests that a SPN is benign. Wewill discuss the selected features and comparethem with previous reported studies further in \"Discussion .\" SVM-Based Classifiers for CT Images with SPN The basic idea of using SVM to classify the patterns in SVM-based feature space is to con- struct a hyperplane that maximizes the marginbetween negative and positive examples. Thehyperplane is determined by the examples calledsupport vectors that are most close to the decisionsurface. We employed the SVM-KM toolbox 25as the SVM implementation based on the decisionsurface solution given by Eqs. 1to4and the features selected in \"Feature Selection of CT Images with SPN \"to construct SVM-based clas-Table 2. The Subsets of Feature Selection Carried Out by Using a Genetic Algorithm Mentioned in \"Genetic Algorithm for Feature Selection \"with The Evolution of Best Fitness and Mean Fitness Value of Genetic Generations as Indicated by Fig. 2 Subset num. Label num. (#) of selected features 5 1, 6, 10, 15, 36 6 10, 11, 23, 32, 33, 36 7 1, 4, 6, 10, 14, 18, 31 8 2, 3, 10, 11, 17, 23, 33, 36 9 1, 4, 10, 13, 29, 33, 34, 45, 64 10 4, 10, 11, 13, 20, 29, 34, 36, 62, 65 ...... There are about 30 subsets and each of subset contains the number of selected features from five to 30. The no. of subsets means that there are five features in this subset if the no. is five,and the selected features in each subset means that the kinds of the features listed in Table 1 are contained in this subset56 ZHU ET AL. 180sifier. The parameter Cwas set to be 50 and set to be 1 throughout this study. Figure 3showed the decision surface of SVM- based classification by using HIST1 and HIST10 in SVM-based feature space. The upper-right partin Fig. 3indicates that the output of the classifier is positive, and down-left part indicates that theoutput of the classifier is negative. The circlesymbol \"o\"indicates true-positive samples and plus symbol \"+\"represents true-negative samples, the features of which were used to train the SVM-based classifier. All the features are scaled to therange [0, 1]. The HIST1 feature represents thepercentage of pixels in the nodule that are less than 185 HU, and the feature is scaled to the range [0, 1]. Higher values of HIST1 mean that a higher percentage of pixels are in a single bin of thehistogram. The HIST10 represented the percentageof pixels above 136 HU which was in the range ofcalcification and indicated that high percentage ofcalcification and low attenuation pixels suggestedthat the nodule was benign. Performance Evaluation of for Differentiating SPNs Comparison of SVM- and BP-ANN-Based Classifiers In classifier construction studies for lung CAD, the ANN was usually used, 3,4so we compared the performance of SVM-based classifier with ANN-based in the following. We employed a two-layered feedforward neural network whichcontained one input layer, one hidden layer, andone output layer. The number of inputs in the inputlayer equaled the dimensionality of the inputvector. The output layer contained one unit tooutput a score that indicated the malignancy of an input nodule, and the number of units in the hidden layer was chosen from three to 18 so that the areaunder the ROC curve was maximized. The neuralnetwork toolbox of Matlab\u00ae was used in thisstudy Now, we compared the performance of SVM and back propagation (BP)-ANN in differentiatingsolitary pulmonary nodules in terms of AUC using the selected feature subsets with leave-one-out procedure. A leave-one-out procedure was carried out in which one nodule was used for test purpose and Table 3. The Number of Times each Feature Was Selected in the 300 Genetic Generation Procedure Feature times 18 3 4 22 6 3 2 2 5 25 13 2 21 10 3 Feature 2 11 7 11 7 2 8 7 12 2 5 5 4 18 3 Feature 5 10 21 3 17 2 4 2 2 1 3 3 3 5 Feature 11 5 1 4 3 3 1 3 0 3 2 2 3 3 3 Feature name HS3 AREA PERI COMP MEAND MIND MAXD Selected times 11 11 13 18 20 4 1FEATURE SELECTION AND PERFORMANCE EVALUATION OF SVM-BASED CLASSIFIER 57 181the others were used for training the SVM- and ANN-based classifiers until each example wasused for test only once. For a subset of features, the AUCs of SVM and ANN could be calculated using ROCKET. 26Thus, the AUCs of SVM and ANN using different feature subsets were calcu-lated. We selected 26 subsets of features, whichcontained different number of features, rangingfrom five to 30. Each subset of features was usedto train the SVM and the AUCs of the two classifiers were calculated and listed in Table 4, and the related bar graph was shown in Fig. 4and Fig. 5illustrated the ROC curves of SVM and ANN with tenselected features. From Figs. 4and5, we see that the performance of SVM-based classifier in differ-entiating SPNs is better than that classifier.Comparison of SVM-Based Classifier with the Radiologists 'Observation In order to evaluate the performance of SVM- based classifier in differentiating SPNs comparedto radiologists 'observation, we set up an experi- ment to let two groups of radiologists read the 77 cases of CT images with SPNs. Group one had three senior radiologists who had more than20 years of experience in reading lung CT imagesin radiology department of Huadong Hospital inShanghai; group two had three junior radiologistswho had 2 to 5 years in reading lung CT images.All of these two groups of radiologists had neverread these images before. They used PACS diag- nostic workstations with high-resolution monitors to read these images and marked the pathology ofnodules as benignancy with 1 and malignancy with 1 independently. The senior radiologists had Fig 3. The decision surface of SVM is indicated in feature space by using HIST1 and HIST10. The upper -right part in the figure indicates that the output of the classifier is positive, and down -left part indicates that the output of the classifier is negative. The circle symbol indicates true-positive samples and plus symbol represents true-negative samples, the features of which were used to train the SVM-based classifier. This figure indicated that the high percentage of calcification and low attenuation pixels suggested that the nodule was benign.58 ZHU ET AL. 182better performance in differentiating SPNs than juniors. To represent the performance of seniorand junior radiologists respectively, we used the averaged results of senior radiologists and junior radiologists, respectively, as the likelihood ofmalignancy to generate the ROC curves for them.Figure 6illustrated the ROC curves of senior and junior radiologists 'performance, as well as the SVM-based classifier with 17 selected features.From Fig. 6, we see that the SVM-based classifier had better performance in differentiating SPNs than radiologists.DISCUSSION Comparison of the Selected Features with Other Reported Results CAD studies have offered insight in differenti- ating benign and malignant SPNs. For example, McNitt-Gray et al.2considered density distribu- tion, area, and texture to classify 31 nodules bymeans of linear discriminant analysis, achieving anaccuracy of 90.3%. As presented in \"Feature Selection of CT Images with SPN ,\"these most Fig 4. The ROC curves of SVM- and BP-ANN-based classifiers using ten selected features by the leave-one-out method.Table 4. The AUC of SVM and ANN by Leave-one-out Procedure Using Different Feature Subsets Subset num. 5 6 OF SVM-BASED CLASSIFIER 59 183frequently selected features in our research are the characteristics most commonly considered byradiologists in distinguishing benign from malig- nant nodules and also are consistent with data inthe published literature. 3,5,6,9Except for these, we found that seven features (GAB2, HS2, CORR2, CORR4, GAB12, and HM3) represented space also have Fig 5. The AUCs of SVM- and BP-ANN-based classifiers by the leave-one-out method using different feature subsets. Fig 6. The ROC curves of radiologists average performance and the SVM-based classifier with 13 selected features. The SVM-based classifier had better performance in differentiating SPNs than average of radiologists.60 ZHU ET AL. 184important impact on differentiating SPNs, and these newly found features should be included infeature index of a CBIR system for SPNs. Table 5 gives the comparison of the features selected(including times selected in evaluation process byusing the genetic algorithm) in our research with the published literature. Kernel Function Selection in SVM Classifier Construction Although we chose the Gaussian kernel function to construct the SVM-based classifier in \"ROC Analysis ,\"the feature distributions of selected features in SVM-based feature space depend on the kernel functions which map the selected features to SVM feature space. So, the perfor- mance of SVM-based classifier in differentiatingSPNs may rely on selected kernel function. In thissection, we will select the different kernel func-tions to construct and evaluate the SVM-basedclassifiers to see whether there is significantdifference between these kernel functions indifferentiating SPNs. Usually, there are multiple kernels that can be selected, and the potential candidate kernels can be linear, multiple polyno-mial, Gaussian, We used these kernel functions one by one to construct the SVM-based classifiers with differentselected feature sets and then used these classifiersto classify the SPNs. We used a leave-one-out procedure to carry out the evaluation in which one nodule was used for test purpose and the others were used for training the SVM-based classifiers until each example was usedfor test only once, same as Comparison of SVM- and BP-ANN-Based Classifiers . For calculatedusing results of AUCs of classifiers withdifferent kernel functions on six subsets with featurenumbers from five to 30. From Table 6, we can see that there is no significant difference between these kernel functions in differentiating SPNs since the average AUCs of SVM-based classifiers withdifferent kernel functions are almost the same. The reasons of selecting Gaussian kernel func- tion in our research are: (1) the Gaussian modelonly has one parameter, and it easy to constructthe Gaussian SVM classifier compared to polyno-mial model which has multiple parameters; (2) the linear kernel function is a specific example of Gaussian model; (3) although both Gaussian andsigmoid models can realize the nonlinear mappingin high-dimensional space, there is less limitationin using Gaussian kernel function, but sigmoidmay have invalidation values in some parameters.So, it is reasonable to choose Gaussian kernelfunction in constructing SVM-based classifier. Reliability of Nodule Segmentation and Its Impact on the SVM-Based Classifier Since the segmentation results of lung CT images with nodules would impact the featureextraction and selection for constructing SVM- orANN-based classifiers, we should investigate thereliability of segmentation methods used in our research. In the following, we will perform some steps to evaluate whether our segmentation methodsare reliable and how they impact on the SVM-basedclassifier. In region-grow method, the threshold 800 was used as common value to perform the segmenta-tion, but a user can adjust the threshold onindividual case of image a little bit based on his or her visual evaluation on the results of segment- ed nodules. We chose four users to perform thesegmentation on 77 cases of images, respectively.These four users can identify the boundary of mostnodules by using the region-grow method from auser-specified seed point inside the nodule withadjustable thresholds or apply snake approach torefine the segmentation results on some (14 images) nodule images. So, we got four groups of segmented 77 cases of images which may havedifferent segmentation results on these images. Weperformed feature extraction and feature selectionFEATURE SELECTION AND PERFORMANCE EVALUATION OF SVM-BASED CLASSIFIER 61 185Table 5. The Comparison of the Features Selected in SVM-based Space in Evaluation Process by Using the Genetic Algorithm in our Research with Published Literature. Seven New Features Represented in SVM-based Feature Space have been Found to be Important on Differentiating SPNs, and these Features should also be Included in Feature Index of a CBIR System for SPNs Feature name Times selected Literature published Description Significance HIST10 24 Matsuki et al.1Pixel range [136 HU, Shape HIST4 22 Nakamura et al.,3Kawata et al.5Pixel range [ 104 HU, 65 HU] The range of fat ENTR4 21 McNitt-Gray et al.2The entropy of averaged concurrence matrix, step=4 Uniformity or complexity of the texture MEAND 19Matsuki HIST1 18 McNitt-Gray et et al.2The entropy of averaged concurrence matrix, step=3 Uniformity or complexity of texture GAB2 17 Small Gabor filter responses at 45\u00b0 The spectrum of local image COMP 16 Nakamura et al.3Compactness of nodule Roundness of the nodule ENTR1 al.2The entropy of averaged concurrence matrix, step=1 Uniformity or complexity of the texture PERI 12Matsuki et et al.,2Nakamura McNitt-Gray et al.2The entropy of averaged concurrence matrix, step=2 Uniformity or complexity of the texture MEANV 10 Matsuki et al.,1McNitt-Gray et al.,2Nakamura et nodule pixels Mean of nodule density CORR1 10 The correlation of averaged concurrence matrix, step=1 Correlation of local image HS2 10 The standard deviation of Hurst parameters, scale=2 Roughness of an image CORR2 8 The correlation of averaged concurrence matrix, step=2 Correlation of local image CORR4 8 The correlation of averaged concurrence matrix, step=4 Correlation of local image GAB12 8 Small Gabor filter responses at 135\u00b0 The spectrum of local image HIST3 7 Nakamura et al.,3Kawata et al.5Pixel range [ 144 HU, 105 HU] Nodule density HIST5 7 Nakamura et al.,3Kawata et al.5Pixel range [ 64 HU, 25 HU] Nodule density IDM2 7 Nakamura et al.3The inverse difference moment of averaged concurrence matrix, step=2 Homogeneity of the texture IDM3 7 Nakamura et al.3The inverse difference moment of averaged concurrence matrix, step=3 Homogeneity of the texture HM3 7 The mean of Hurst parameters, scale=3 Roughness of an image62 ZHU ET AL. 186on each of these four groups of images and used the selected features from each of the four groupsto construct SVM-based classifier, respectively,then used classifiers toevaluate their performance on differentiatingSPNs. Table 7shows the results of the comparison between four feature groups related to four user nodule segmentation results with region-grow and snake methods. From Table 7, we can see that our nodule segmentation methods are reliable for differentqualified users to segment the SPNs on most lungCT images since the differences of segmentationresults from different users with region-grow andsnake segmentation methods have no significant impact statistically on the results of differentiating SPNs by using the SVM-based classifier. Selected Features Potentially Used in CBIR System In a medical CBIR system, the large amount of visual features and low-level image characterfeatures such as shape, texture, and granulometryare usually included to build the image-searchingindex, 13which is a multiple-dimension feature vector database and is linked to an image database storing related historical images with confirmed diagnostic results. The working principle of CBIRis to look for candidate images from the CBIRimage database, the features of which are similarwith that of an input image. As the numbers ofcharacter features of an image are usually verylarge such as more than hundreds or thousands,some of features are useful to label the image characters, and some are not. The image-searching efficiency (iteration times and costs of similaritycalculation of every searching) of finding the rightimages from CBIR system are mostly dependenton the dimension numbers of feature vectors andselected correct features used to label imagecharacters. 10The fewer the dimension numbers of feature vectors are, the less are the costs ofsimilarity calculation of every searching. The morecorrect the features used to label image charactersare, the more few are the itinerate searching timesin CBIR searching procedure. So, it will greatly improve the performance of a CBIR system if we used more correct features to label image charac-ters with fewer numbers of the features in buildingimage-searching index. With the results of this paper, we can use selected pattern features of SPNs to build search-ing index in a CBIR system for lung cancer CTimages, which would have more searching effi- ciency than that without optimally selecting pattern features of SPNs from CT images, 12as the number of selected features are reduced from 67 to 17without sacrificing the performance of classifiersin differentiating lung nodules. CONCLUSIONS In this paper, we presented a method for optimally selecting pattern features of SPNs fromTable 6. The AUCs of SVM-based Classifiers with Different Kernel Functions by Leave-one-out Procedures Using Different Feature Subsets Feature num. in of SVM-based Classifiers Constructed from Four Groups the Features of which were Extracted and Selected Based on Four Users Nodule Segmentation Results, Respectively Feature num. in a subset User 1 User 2 User 3 User 4 OF SVM-BASED CLASSIFIER 63 187CT images, determined the usefulness of various selected pattern features for a CAD in differenti-ating SPNs or for a CBIR system in feature nodules, and evaluated Seventy-seven biopsy-confirmed CT cases of SPNs were included in this study. A total of 67features were extracted by a feature extractionprocedure, and 25 features were finally selectedfrom these 67 features after 300 genetic gener-ations. We constructed the SVM-based classifierwith the selected features and evaluated theperformance of the classifier by comparing the classification results of the SVM-based classifier with six radiologists 'observations and ANN-based classifier. The results showed that theSVM-based classifier had good performance indifferentiating the benign from malignant SPNscompared to an average performance of radiolog-ists in our research and was more accurate than theANN-based classifier in distinguishing benign from malignant SPNs. This study results not only showed that most of the selected features arecharacteristics frequently considered by radiolog-ists in classifying SPNs which are also consistentwith the finding of CAD analyses previouslyreported but also indicated that some newly foundfeatures have important contribution to differenti-ating benign from malignant SPNs in SVM-based feature space. The results of this research are not only helpful to improve CAD for diagnosis on SPNs but also useful to build the highly efficient feature index ofa CBIR system for CT images with pulmonarynodules. We discussed the impacts of nodulesegmentation results and kernel function selectionon the performances of SVM-based classifier in differentiating benign from malignant SPNs. ACKNOWLEDGEMENTS The project was supported by the grants from the National Nature Science Foundation of China (grant no. 30570512) and Shanghai Science and Techno logy Committee (grant no. 064119658, 06SN07111). The authors would like to thank Dr. Xiaojun Ge for providing the CT images used in this study. REFERENCES 1. Matsuki Y, Nakamura K, Watanabe H, Aoki T, Nakata H, Katsuragawa S, Doi K: Usefulness of an artificial neuralnetwork for differentiating benign from malignant pulmonarynodules on high-resolution CT: evaluation with receiveroperating characteristic analysis. Am J Roentgenol 178 (3):657 -663, 2002 2. McNitt-Gray MF, Hart EM, Goldin JG, Yao CW, Aberle DR: A pattern classification approach to Engelmann R, MacMahon H: Computerized analysis of the likelihood of malignancy in solitary pulmonary nodules with use of artificial neural net- works. Radiology 214:823 -830, 2000 4. Shiraishi J, Abe H, Englemann R, Aoyama M: Computer- aided diagnosis to distinguish benign from malignant solitary pulmonary nodules on radiographs: ROC analysis of radiologists performance Kusumoto M, et al: Hybrid classification appro ach of malignant and benign pulmonary Comparison of FLDA, nodule. Sci 3587:285 -294, 2005 7. Shah SK, McNitt-Gray MF, Rogers SR: Computer aided characterization of the solitary pulmonary nodule using volu- metric and contrast enhancement features. Acad Radiol 12 (10):1310 -1319, 2005 8. Yamashita Tsuda T, Nemoto T: Solitary pulmonary nodule: preliminary of evaluation with incremental dynamic CT. Radiology -405, 1995 N, Bandon D: A review of content- based image retrieval system in medical applications-clinical benefits and future directions. Int J Med Informatics 73(1):1 - 23, 2004 11. Fisher B, Deserno T, Ott B, et al: Integration of a research CBIR system with RIS and PACS for radiologicalroutine. Proc SPIE 6919:691914 -1-691914-10, 2008 12. Tan Y, Zhang J, Hua Y, Zhang G: Content-based image retrieval in picture archiving and communication system. ProcSPIE 6145:614515 -1-614515-8, 2006 13. Deserno Antani S, Long RL: Ontology of gaps in content-based image retrieval. J Digit Imaging (in press), 2007 14. Depeusinge A, Lavindrasana J, Hidki A, et al: A classification framework for lung tissue categorization. ProcSPIE 6919:69190C1 -69190C12, 2008 15. Silva AC, Carvalho PCP, Gattass M: Diagnosis of lung nodule using -38, 2005 -804, 1979 17. Clausi 33:1835 -1849, 2000 18. Manjunath B, Ma W: Texture features for browsing and retrieval of image data. IEEE Trans Pattern Analysis MachIntell 18(8):837 -842, 1996 19. Unser M: Texture classification and wavelet frames. IEEE Trans Image Processing 4:1549 Kaplan LM, segmentation using multi- features. Conf Image Process 3:205 -208, 1997 21. Joachims T: Text categorization with support vector machines. In: Proceedings of European Conference on Machine Learning (ECML), 1998 22. Brown M, Grundy W, Lin D, Cristianini N, Sugnet C, Furey T, Ares M, Haussler D: Knowledge-based analysis ofmicroarray gene expression data using support vector machines.1999. http://www.cse.ucsc.edu/research/compbio/genex/genex. html. Santa Cruz, University of California, Department of Computer Science and Engineering23. Shawe-Taylor J, Cristianini N: Kernel methods for pattern analysis, Cambridge: Cambridge University Press,2004 24. Fawcett T: ROC graphs: notes and practical consider- ations for data mining researchers. Technical report HPL-2003-4 HP Labs, 2003. 25. Canu S, Grandvalet Y, Guigue OF SVM-BASED CLASSIFIER 65 189 SELECTED BOOK EXCERPT 190Second Edition PACS and Imaging Informatics Basic Principles and Applications H. K. Huang , D.Sc., FRCR (Hon.), FAIMBEHuang Second Edition PACS and Imaging Informatics Basic Principles and ApplicationsThe denitive guide to PACS\u2014now with more clinically applicable material In recent years the eld of picture archiving and communications systems\u2014PACS\u2014and image informatics has advanced due to both conceptual and technological advancements. This edition of PACS and Imaging Informatics: Basic Principles and Applications addresses the latest in this exciting eld. In contrast to the previous edition, this updated text uses the framework of image informatics, not physics or engineering principles, to explain PACS. It is the only resource that thoroughly covers the critical issues of hardware/software design and implementation in a systematic and easily comprehensible manner. To strengthen and update the book, the author: s\u0000 emphasizes clinical applications of PACS and integrates clinical examples throughout the text s\u0000 reflects the many changes in the eld, with new chapters on web-based PACS, security, inte-grating the healthcare enterprise, clinical management systems, and the electronic patient record s\u0000 uses the framework of imaging informatics to explain PACS, making the book accessible to those without advanced knowledge of physics, engineering, math, or information technology s explains how PACS can improve workflow, therapy, and treatment With the most systematic and thorough coverage of practical applications available, this text is the complete guide for all those involved in designing, implementing, and using PACS. Professionals in medical and allied health imaging informatics; radiologists and their technical staff; surgeons and oncologists and their teams; medical and electronic engineers; medical informaticians; and fellows, graduate students, and advanced undergraduates will all benet from this valuable resource. \" An excellent book for people involved in the design, implementation, or simply the opera- tions of PACS and an appropriate textbook.\" \u2014 from a review of the previous edition in IEEE Engineering in Medicine and Biology \" The strength of the book lies in the vast experience of the author, who has implemented PACS at numerous institutions in the United States and abroad.\" \u2014 from a review of the previous edition in Radiology Huang flast.tex V3 - 10/28/2009 2:20am Page li ACKNOWLEDGMENTS Many people have provided valuable assistance during the preparation of this book, in particular, many of my past graduate students, postdoctoral fellows, and col- leagues, from whom I have learned the most. Chapter 1, Introduction, and Part I, Medical Imaging Principles (Chapters 2-6), have been revised substantially fromthe original book P ACS and Imaging Informatics: Basic Principles and Applications , published, 2004. Part II, PACS Fundamentals (Chapters 7-13), consists of materials based on revised industrial standards and workflow proles, updated technologies, and current clinical experience of other researchers and ourselves. Part III, PACSOperation (Chapters 14-19), are mostly our group's personal experience over the past six years in planning, design, implementation, and operating large-scale PAC systems. Part IV, PACS-based and DICOM- based Imaging Informatics (Chapters 20-28), presents systematic overview of current trends in medical imaging infor-matics research learned from colleagues and other researchers, as well as our own research and development. Materials retained from the last edition were contributed by K. S. Chuang, Ben Lo, Ricky Taira, Brent Stewart, Paul Cho, Shyh-Liang Andrew Lou, Albert W. K. Wong, Jun Wang, Xiaoming Zhu, Johannes Stahl, Jianguo Zhang, Ewa Pietka, X. Q. Zhou, F.Yu, Fei Cao, Brent Liu, Maria Y.Y. Law, Lawrence Chan, Harold Rutherford, Minglin Li, Michael F. McNitt-Gray, Christopher Carr, Eliot Siegel, Heinz Lemke,Kiyonari Inamura, and Cammy Huang. For the new materials, I am thankful for contributions by the following individuals: Brent Liu (Chapters 7, 18, 19, 24, Sections 9.4, 9.5, 11.6, 18.6, 18. 7.1, 18.7.2, 18.7.3, 18.8, 19.2, 19.3, 19.4, 21.4, 28.3.1), Jia nguo Zhang (Sections 12.7), Maria Y.Y. Law (Chapter 23, Section 28.3.2), Cammy Huang (Section 28.5), Michael Z. Zhou(Chapter 17, Sections 8.6, 21.3, 21.4, 21.5, 26.3, 28.2), Lucy Aifeng Zhang (Sections 20.4.3, 26.7, 26.8), Jorge Documet (Sections 8.6, 14.6, Chapter 24, Chapter 27),Anh Le (24.3, 26.3, 26.5), Jasper Lee (Sections 4.9, 5.4.4, 21.6), Kevin Ma (Section26.8), Bing Guo (Chapter 27, Sections 12.8, 26.5, 26.6), Kevin Wong (Sections18.7.3, 19.4), John Chiu (Chapter 24), N T Cheung (Sections 16.11, 22.3), Tao Chan (Sections 16.11, 25.4, 25.5), Anthony Chan (Sections 18.7.4). Paymann Moin and Richard Lee contributed discussions in clinical radiology and some art work andimages. A special thank you must go to Mariam Fleshman and Ashley Sullivanwho contributed some creative art work, read through all chapters to extract the lists of acronyms and the index, and organized the references, to Angelica Visgen for editorial assistance, to Jim Sayre for numerous data collections and statisticalanalysis, and to Maria Y. Y. Law, who read through and edited the Introduction, andPart I and Part IV chapters. li 192Huang flast1.tex V3 - 10/28/2009 2:21am Page lii This book was written with the assistance of the following staff members and con- sultants of the Imaging Processing and Informatics Laboratory, USC: Brent J. Liu, Ph.D . Associate Professor, USC Jianguo Zhang, Ph.D. Professor, Shanghai Institute of Technical Physics, The Chinese Academy of Science, Visiting Professor, USC Maria Y. Y. Law, Ph.D. M.Phil., BRS., Teach Dip., Associate Professor, Hong Kong Polytechnic University Visiting Associate Professor, USC Jorge Document, Ph.D . Postdoctoral Director of Scientic Outreach, WGLN; and Virtual Labs Project Director Center for Innovations in Learning Lecturer, Department of Computer Science, Stanford University 193Huang flast2.tex V3 - 10/28/2009 2:22am Page liii H. K. SHORT BIOGRAPHY H. K. (Bernie) Huang , FRCR(Hon.); FAIMBE; Professor of Radiology and Biomed- ical of Ima ging Informatics, Department of Radiol- ogy; and Director MS Program, Medical Imaging and Imaging Informatics, Depart- ment of Biomedical Engineering, University of Southern California, Los Angeles, Chair Professor of Medical Informatics, The Hong Kong Polytechnic University; and Honorary Professor, Shanghai Institute of Technical Physics, The Chinese Academyof Sciences. Dr. Huang pioneered in picture archiving and communication system (PACS) and imaging informatics research. He developed the PACS at UCLA in 1991, andthe hospital-integrated PACS at UCSF in 1995, and started imaging informaticsresearch in 1999. Dr. Huang has taught at Georgetown University (1971-80); Uni-versity of Iowa (1981-82); UCLA (1982-92); UC Berkeley and UC San Francisco (1992-99); Hong Kong Polytechnic University (2000-present); and the University of Southern California (2000-present). His current research interests are in tele-imaging and telemedicine, fault-tolerant PACS server, PACS ASP model, Internet 2,PACS-based CAD and surgery, imaging informatics, image recovery during disas- ter, image integrity, Data Grid, grid computing, HIPAA compliance, patient tracking system, radiation therapy information system, PDA Web-based image managementand distribution, ePR, and image-guided minimally invasive spinal surgery. He hasco-authored and authored eight books, published over 200 peer-reviewed articles, and received several patents. His book: P ACS and Imaging Informatics published by John Wiley & Sons in 2004 has been the only textbook in this eld. Over the past 25 years Dr. Huang has received over U.S. $21 million dollars in PACS, medicalimaging informatics, tele-imaging, and image processing related research grants and contracts, as well as imaging informatics training grants from the U.S. federal and state governments, and private industry. He has mentored 24 PhD students and over30 postdoctoral fellows from around the world. Dr. Huang has been a consultant formany national and international hospitals, and imaging manufacturers in the design and implementation of PAC systems, enterprise-level ePR with image distribution, and image-based therapy and treatment ePR systems. Dr. Huang was inducted into the Royal College of Radiologists, London as an Honorary Fellow, for his contribution in PACS research and development, in November 1992; the American Institute of Medical and Biological Engineering as a Founding Fellow, for his contribution in medical imaging, in March 1993; theEuroPACS Society as an Honorary Member for his contribution in PACS, in October1996; Honorary President, 2003 International CARS Congress, London; and Presi- dent, 2007 First Iranian Imaging Informatics Conference. Dr. Huang has been Visiting Professor in many leading universities around the world, and a Board Member inleading medical imaging manufacturers. liii 194Huang frs.tex V3 - 10/28/2009 1:21am Page iii PACS AND IMAGING INFORMATICS BASIC PRINCIPLES AND APPLICATIONS Second Edition H. K. Huang, D.Sc., FRCR (Hon.), FAIMBE Professor of Radiology and Biomedical Engineering University of Southern California Chair Professor of Medical Informatics The Hong Kong Polytechnic University Honorary Professor, Shanghai Institute of Technical Physics The Chinese Academy of Sciences A John Wiley & Sons, Inc., Publication 195Huang frs.tex V3 - 10/28/2009 1:21am Page iv Copyright \u00a92010 by John Wiley & Sons, Inc. All rights reserved Published by John Wiley & Sons, Inc., Hoboken, New Jersey Published simultaneously in Canada No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as permittedunder Section 107 or 108 of the 1976 United States C opyright Act, without either the prior written permission of the Publisher, or authorization t hrough payment of the appropriate per-copy fee to the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax (978)750-4470, or on the web at www.copyright.com. Requests to the Publisher for permission should beaddressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030, (201) 748-6011, fax (201) 748-6008, or online at www.wiley.com/go/permissions. Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best efforts in preparing this book, they make no representations or wa rranties with respect to the accuracy or completeness of the contents of this book and specically disclaim an y implied warranties of merchantability or tness for a particular purpose. No warranty may be created or extende d by sales representatives or written sales materials. The advice and strategies contained herein may not be suitable for your situation. You should consult with a professional where appropriate. Neither the publisher nor author shall be liable for any loss of prot or any other commercial damages, including but not limited to sp ecial, incidental, consequential, or other damages. For general information on our other products and services or for technical support, please cantact ourCustomer Care Department within the United States at (800) 762-2974, outside the United States at (317)572-3993 or fax (317) 572-4002. Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may not be available in electronic formats. For more information about Wiley products, visit our web site atwww.wiley.com. Library of Congress Cataloging-in-Publication Data:Huang, H. K., 1939- PACS and imaging informatics : basic principle s and applications / H.K. Huang. - 2nd ed. rev. p. ; cm. Includes bibliographical references and index. ISBN 978-0-470-37372-9 (cloth) 1. Picture archiving and communication systems in me dicine. 2. Imaging systems in medicine. I. Title. II. Title: Picture archiving and communi cation system and imaging informatics. [DNLM: 1. Radiology Information Systems. 2. Diagnostic Imaging. 3. Medical Records Systems, Computerized. WN 26.5 H874p 2010] R857.P52H82 2010616.07 /prime54-dc22 2009022463 0987654321 196Huang frs.tex V3 - 10/28/2009 1:21am Page v To my wife, Fong, for her support and understanding, my daughter, Cammy, for her growing wisdom and ambitious spirit, and my grandchildren Tilden and Calleigh, for their calming innocence. 197Huang frs.tex V3 - 10/28/2009 1:21am Page vi PART I MEDICAL IMAGING PRINCIPLES Imaging Basics Chapter 22-D Images Chapter 33-D Images Chapter 4Compression Chapter 6 HIS/RIS/PACS Integration & ePR Chapter 13Image/Data Acquisition Gateway Chapter 10PACS Server & Archive Chapter 11Display Workstation Chapter 12PART II PACS FUNDAMENTALS Implementation & Evaluation Chapter 18Clinical Experience/ Pitfalls/Bottlenecks Chapter 19PART III PACS OPERATION PART IV PACS- AND DICOM-BASED IMAGING INFORMATICSINTRODUCTION Chapter 1 Fault-Tolerant & Enterprise PACS Chapter 16 Data Management & Web-Based PACS Chapter 14 Image/Data Security Chapter 17Telemedicine & Teleradiology Chapter 154-D Images & Image Fusion Chapter 5 PACS Fundamentals Chapter 7DICOM, HL7 and IHE Chapter 9Communication & Networks Chapter 8 Medical Imaging Informatics Chapter 20DICOM RT ePR Chapter 23Computing & Data Grid Chapter 21 Multimedia ePR Chapter 22Image-Assisted Surgery ePR Chapter 24 Biometric Tracking Chapter 27Education/ Learning Chapter 28Image-Based CAD Chapter 25CAD-PACS Integration Chapter 26 198 "}